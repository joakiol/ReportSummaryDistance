Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 19?26,Prague, June 2007. c?2007 Association for Computational LinguisticsA Language Independent Approach for Name Categorization andDiscriminationZornitsa KozarevaDepartamento de Lenguajesy Sistemas Informa?ticosUniversidad de AlicanteAlicante, Spainzkozareva@dlsi.ua.esSonia Va?zquezDepartamento de Lenguajesy Sistemas Informa?ticosUniversidad de AlicanteAlicante, Spainsvazquez@dlsi.ua.esAndre?s MontoyoDepartamento de Lenguajesy Sistemas Informa?ticosUniversidad de AlicanteAlicante, Spainmontoyo@dlsi.ua.esAbstractWe present a language independent ap-proach for fine-grained categorization anddiscrimination of names on the basis of textsemantic similarity information.
The exper-iments are conducted for languages from theRomance (Spanish) and Slavonic (Bulgar-ian) language groups.
Despite the fact thatthese languages have specific characteristicsas word-order and grammar, the obtainedresults are encouraging and show that ourname entity method is scalable not only todifferent categories, but also to different lan-guages.
In an exhaustive experimental eval-uation, we have demonstrated that our ap-proach yields better results compared to abaseline system.1 Introduction1.1 BackgroundNamed Entity (NE) recognition concerns the detec-tion and classification of names into a set of cate-gories.
Presently, most of the successful NE ap-proaches employ machine learning techniques andhandle simply the person, organization, location andmiscellaneous categories.
However, the need ofthe current Natural Language Applications impedesspecialized NE extractors which can help for in-stance an information retrieval system to determinethat a query about ?Jim Henriques guitars?
is relatedto the person ?Jim Henriques?
with the semantic cat-egory musician, and not ?Jim Henriques?
the com-poser.
Such classification can aid the system to rankor return relevant answers in a more accurate andappropriate way.So far, the state-of-art NE recognizers identifythat ?Jim Henriques?
is a person, but do not sub-categorize it.
There are numerous drawbacks re-lated to the fine-grained NE issue.
First, the sys-tems need hand annotated data which are not avail-able for multiple categories, because their creation istime-consuming, requires supervision by experts, apredefined fine-grained hierarchical structure or on-tology.
Second, there is a significant lack of freelyavailable or developed resources for languages otherthan English, and especially for the Eastern Euro-pean ones.The World Wide Web is a vast, multilingualsource of unstructured information which we con-sult daily in our native language to understand whatthe weather in our city is or how our favourite soccerteam performed.
Therefore, the need of multilingualand specialized NE extractors remains and we haveto focus on the development of language indepen-dent approaches.Together with the specialized NE categorization,we face the problem of name ambiguity which isrelated to queries for different people, locations orcompanies that share the same name.
For instance,Cambridge is a city in the United Kingdom, butalso in the United States of America.
ACL refersto ?The Association of Computational Linguistics?,?The Association of Christian Librarians?
or to the?Automotive Components Limited?.
Googling thename ?Boyan Bonev?
returns thousands of docu-ments where some are related to a member of a robotvision group in Alicante, a teacher at the School19of Biomedical Science, a Bulgarian schoolboy thatparticipated in computer science competition amongothers.
So far, we have to open the documents oneby one, skim the text and decide to which ?BoyanBonev?
the documents are related to.
However, ifwe resolve the name disambiguation issue, this canlead to an automatic clustering of web pages talkingabout the same individual, location or ogranization.1.2 Related WorkPreviously, (Pedersen et al, 2005) tackled the namediscrimination task by developing a language inde-pendent approach based on the context in which theambiguous name occurred.
They construct secondorder co-occurrence features according to which theentities are clustered and associated to different un-derlying names.
The performance of this methodranges from 51% to 73% depending on the pair ofnamed entities that have to be disambiguated.
Simi-lar approach was developed by (Bagga and Baldwin,1998), who created first order context vectors thatrepresent the instance in which the ambiguous nameoccurs.
Their approach is evaluated on 35 differentmentions of John Smith, and the f-score is 84%.For fine-grained person NE categorization, (Fleis-chman and Hovy, 2002) carried out a supervisedlearning for which they deduced features from thelocal context in which the entity resides, as well assemantic information derived from the topic signa-tures and WordNet.
According to their results, toimprove the 70% coverage for person name catego-rization, more sophisticated features are needed, to-gether with a more solid data generation procedure.
(Tanev and Magnini, 2006) classified geographiclocation and person names into several subclasses.They use syntactic information and observed howoften a syntactic pattern co-occurs with certainmember of a given class.
Their method reaches 65%accuracy.
(Pasca, 2004) presented a lightly super-vised lexico-syntactic method for named entity cat-egorization which reaches 76% when evaluated withunstructured text of Web documents.
(Mann, 2002) populated a fine-grained propernoun ontology using common noun patterns and fol-lowing the hierarchy of WordNet.
They studied theinfluence of the newly generated person ontology ina Question Answering system.
According to the ob-tained results, the precision of the ontology is high,but still suffers in coverage.
A similar approach forthe population of the CyC Knowledge Base (KB)was presented in (Shah et al, 2006).
They usedinformation from the Web and other electronicallyavailable text corpora to gather facts about particu-lar named entities, to validate and finally to add themto the CyC KB.In this paper, we present a new text semantic simi-larity approach for fine-grained person name catego-rization and discrimination which is similar to thoseof (Pedersen et al, 2005) and (Bagga and Baldwin,1998), but instead of simple word co-occurrences,we consider the whole text segment and relate thededuced semantic information of Latent Seman-tic Analysis (LSA) to trace the text cohesion be-tween thousands of sentences containing named en-tities which belong to different fine-grained cate-gories or individuals.
Our method is based on theword sense discrimination hypothesis of Miller andCharles (1991) according to which words with sim-ilar meaning are used in similar context, hence inour approach we assume that the same person orthe same fine-grained person category appears in thesimilar context.2 NE categorization and discriminationwith Latent Semantic AnalysisLSA has been applied successfully in many areasof Natural Language Processing such as Informa-tion Retrieval (Deerwester et al, 1990), Informa-tion Filtering (Dumais, 1995) , Word Sense Disam-biguation (Shu?tze, 1998) among others.
This is pos-sible because LSA is a fully automatic mathemati-cal/statistical technique for extracting and inferringrelations of expected contextual usage of words indiscourse.
It uses no humanly constructed dictionar-ies or knowledge bases, semantic networks, syntac-tic or morphological analyzers, because it takes onlyas input raw text which is parsed into words and isseparated into meaningful passages.
On the basis ofthis information, LSA extracts a list of semanticallyrelated word pairs or rank documents related to thesame topic.LSA represents explicitly terms and documentsin a rich, highly dimensional space, allowing theunderlying ?latent?, semantic relationships betweenterms and documents to be exploited.
LSA relies20on the constituent terms of a document to suggestthe document?s semantic content.
However, the LSAmodel views the terms in a document as somewhatunreliable indicators of the concepts contained in thedocument.
It assumes that the variability of wordchoice partially obscures the semantic structure ofthe document.
By reducing the original dimen-sionality of the term-document space with SingularValue Decomposition to a matrix of 300 columns,the underlying, semantic relationships between doc-uments are revealed, and much of the ?noise?
(dif-ferences in word usage, terms that do not help distin-guish documents, etc.)
is eliminated.
LSA statisti-cally analyzes the patterns of word usage across theentire document collection, placing documents withsimilar word usage patterns near to each other in theterm-document space, and allowing semantically-related documents to be closer even though they maynot share terms.Taking into consideration these properties ofLSA, we thought that instead of constructing thetraditional term-document matrix, we can constructa term-sentence matrix with which we can find aset of sentences that are semantically related andtalk about the same person.
The rows of the term-sentence matrix correspond to the words of the sen-tence where the NE has to be categorized or discrim-inated (we call this sentence target sentence), whilethe columns correspond to the rest of the sentenceswith NEs.
The cells of the matrix show the num-ber of times a given word from the target sentenceco-occurs in the rest of the sentences.
When twocolumns of the term-sentence matrix are similar, thismeans that the two sentences contain similar wordsand are therefore likely to be semantically related.When two rows are similar, then the correspondingwords occur in most of the same sentences and arelikely to be semantically related.In this way, we can obtain semantic evidenceabout the words which characterize a given person.For instance, a football player is related to wordsas ball, match, soccer, goal, and is seen in phrasessuch as ?X scores a goal?, ?Y is penalized?.
Mean-while, a surgeon is related to words as hospital, pa-tient, operation, surgery and is seen in phrases suchas ?X operates Y?, ?X transplants?.
Evidently, thecategory football player can be distinguished easilyfrom that of the surgeon, because both person namesoccur and relate semantically to different words.Another advantage of LSA is its property of lan-guage independence, and the ability to link sev-eral flexions or declanations of the same term.This is especially useful for the balto-slavonic lan-guages which have rich morphology.
Once the term-sentence approach is developed, practically there isno restrain for LSA to be applied and extended toother languages.
As our research focuses not onlyon the resolution of the NE categorization and dis-crimination problems as a whole, but also on the lan-guage independence issue, we considered the LSA?susage are very appropriate.3 Development Data SetFor the development of our name discrimination andclassification approach, we used the Spanish lan-guage.
The corpora we worked with is the EFE94-95Spanish news corpora, which were previously usedin the CLEF competitions1.
In order to identify thenamed entities in the corpora, we used a machinelearning based named entity recognizer (Kozareva etal., 2007).For the NE categorization and discrimination ex-periments, we used six different named entities, forwhich we assumed a-priory to belong to one of thetwo fine-grained NE categories PERSON SINGERand PERSON PRESIDENT.
The president namesare Bill Clinton, George Bush and Fidel Castro, andthe singer names are Madonna, Julio Iglesias andEnrique Iglesias.
We have selected these names forour experiment, because of their high frequency inthe corpora and low level of ambiguity.Once we have selected the names, we have col-lected a context of 10, 25, 50 and 100 words fromthe left and from the right of the NEs.
This is donein order to study the influence of the context for theNE discrimination and categorization tasks, and es-pecially how the context window affects LSA?s per-formance.
We should note that the context for theNEs is obtained from the text situated between thetext tags.
During the creation of the context win-dow, we used only the words that belong to the docu-ment in which the NE is detected.
This restriction isimposed, because if we use words from previous orfollowing documents, this can influence and change1http://www.clef-campaign.org/21the domain and the topic in which the NE is seen.Therefore, NE examples for which the number ofcontext words does not correspond to 10, 25, 50 or100 are directly discarded.From the compiled data, we have randomly se-lected different NE examples and we have createdtwo data sets: one with 100 and another with 200examples per NE.
In the fine-grained classification,we have substituted the occurrence of the presi-dent and singer names with the obfuscated formPresident Singer.
While for the NE discrim-ination task, we have replaced the names with theM EI JI BC GB FC label.
The first label indicatesthat a given sentence can belong to the president orto the singer category, while the second label indi-cates that behind it can stand one of the six namedentities.
The NE categorization and discriminationexperiments are carried out in a completely unsuper-vised way, meaning that we did not use the correctname and name category until evaluation.4 Experimental Evaluation4.1 Experimental SettingsAs mentioned in Section 2, to establish the semanticsimilarity relation between a sentence with an ob-fuscated name and the rest of the sentences, we useLSA2.
The output of LSA is a list of sentences thatbest matches the target sentence (e.g.
the sentencewith the name that has to be classified or discrim-inated) ordered by their semantic similarity score.Strongly similar sentences have values close to 1,and dissimilar sentences have values close to 0.In order to group the most semantically similarsentences which we expect to refer to the same per-son or the same fine-grained category, we apply thegraph-based clustering algorithm PoBOC (Cleuziouet al, 2004).
We construct a new quadratic sentence-sentence similarity matrix where the rows stand forthe sentence we want to classify, the columns standfor the sentences in the whole corpus and the valuesof the cells represent the semantic similarity scoresderived from LSA.On the basis of this information, PoBOC formstwo clusters whose performance is evaluated interms of precision, recall, f-score and accuracywhich can be derived from Table 1.2http://infomap-nlp.sourceforge.net/number of Correct PRESIDENT Correct SINGERAssigned PRESIDENT a bAssigned SINGER c dTable 1: Contingency tableWe have used the same experimental setting forthe name categorization and discrimination prob-lems.4.2 Spanish name categorizationIn Table 2, we show the results for the Spanish fine-grained categorization.
The detailed results are forthe context window of 50 words with 100 and 200examples.
All runs, outperform a simple baselinesystem which returns for half of the examples thefine-grained category PRESIDENT and for the restSINGER.
This 50% baseline performance is due tothe balanced corpus we have created.
In the columndiff., we show the difference between the 50% base-line and the f-score of the category.
As can be seenthe f-scores reaches 90%, which is with 40% morethan the baseline.
According to the z?
statistics withconfidence level of 0.975, the improvement over thebaseline is statistically significant.SPANISHcont/ex Category P. R. A. F. diff.50/100PRESIDENT 90.38 87.67 88.83 89.00SINGER 87.94 90.00 88.33 88.96 +39.0050/200PRESIDENT 90.10 94.33 91.92 92.18SINGER 94.04 89.50 91.91 91.71 +42.00Table 2: Spanish NE categorizationDuring the error analysis, we found out that thePERSON PRESIDENT and PERSON SINGER cat-egories are distinguishable and separable becauseof the well-established semantic similarity relationamong the words with which the NE occurs.A pair of president sentences has lots of stronglyrelated words such as president:meeting, presi-dent:government, which indicates high text cohe-sion, while the majority of words in a president?singer pair are weakly related, for instance presi-dent:famous, president:concert.
But still we foundout ambiguous pairs such as president:company,where the president relates to a president of a coun-try, while the company refers to a musical enter-22name c10 c25 c50 c100Madonna 63.63 61.61 63.16 79.45Julio Iglesias 58.96 56.68 66.00 79.19Enrique Iglesias 77.27 80.17 84.36 90.54Bill Clinton 52.72 48.81 74.74 73.91George Bush 49.45 41.38 60.20 67.90Fidel Castro 61.20 62.44 77.08 82.41Table 3: Spanish NE discriminationprize.
Such information confuses LSA?s categoriza-tion process and decreases the NE categorizationperformance.4.3 Spanish name discriminationIn a continuation, we present in Table 3 the f-scoresfor the Spanish NE discrimination task with the 10,25, 50 and 100 context windows.
The results showthat the semantic similarity method we employ isvery reliable and suitable not only for the NE cat-egorization, but also for the NE discrimination.
Abaseline which always returns one and the same per-son name during the NE discrimination task is 17%.From the table can be seen that all names outperformthis baseline.
The f-score performance per individ-ual name ranges from 42% to 90%.
The results arevery good, as the conflated names (three presidentsand three singers) can be easily obfuscated, becausethey share the same domain and occur with the samesemantically related words.The three best discriminated names are EnriqueIglesias, Fidel Castro and Madonna.
The name FidelCastro is easily discriminated due to its characteriz-ing words Cuba, CIA, Cuban president, revolution,tyrant.
All sentences having these words or syn-onyms related to them are associated to Fidel Cas-tro.Bill Clinton occurred many times with the wordsdemocracy, Boris Yeltsin, Halifax, Chelsea (thedaughter of Bill Clinton), White House, whileGeorge Bush appeared with republican, RonaldReigan, Pentagon, war in Vietnam, Barbara Bush(the wife of George Bush).During the data compilation process, the exam-ples for Enrique Iglesias are considered to belong tothe Spanish singer.
However, in reality some exam-ples of Enrique Iglesias talked about the president ofa financial company in Uruguay or political issues.Therefore, this name was confused with Bill Clin-ton, because they shared semantically related wordssuch as bank, general secretary, meeting, decision,appointment.The discrimination process for the singer names isgood, though Madonna and Julio Iglesias appearedin the context of concerts, famous, artist, maga-zine, scene, backstage.
The characterizing words forJulio Iglesias are Chabeli (the daughter of Julio Igle-sias), Spanish, Madrid, Iberoamerican.
The nameMadonna occurred with words related to a pictureof Madonna, a statue in a church of Madonna, themovie Evita.Looking at the effect of the context window forthe NE discrimination task, it can be seen that thebest performances of 90% for Enrique Iglesias, 82%for Fidel Castro and 79% for Madonna are achievedwith 100 words from the left and from the right ofthe NE.
This shows that the larger context has betterdiscrimination power.4.4 DiscussionAfter the error analysis, we saw that the performanceof our approach depends on the quality of the datasource we worked with.
Although, we have selectednames with low degree of ambiguity, during the datacompilation process for which we assumed that theyrefer 100% to the SINGER or PRESIDENT cate-gories, during the experiments we found out that oneand the same name can refer to three different in-dividuals.
This was the case of Madonna and En-rique Iglesias.
From one side this impeded the fine-grained categorization and discrimination processes,but opened a new line for research.In conclusion, the conducted experiments re-vealed a series of important observations.
The firstone is that the LSA?s term-sentence approach per-forms better with a higher number of examples, be-cause they provide more semantic information.
Inaddition to the number of examples, the experimentsshow that the influence of the context window for thename discrimination is significant.
The discrimina-tion power is better for larger context windows andthis is also related to the expressiveness of the lan-guage.Second, our name categorization and discrimina-tion approach outperforms the baseline with 30%.Finally, LSA is a very appropriate approximationfor the resolution of the NE categorization and dis-23crimination tasks.
LSA also gives logical explana-tion about the classification decision of the personnames, providing a set of words characterizing thecategory or simply a list of words describing the in-dividual we want to classify.5 Adaptation to Bulgarian5.1 MotivationSo far, we have discussed and described the develop-ment and the performance of our approach with theSpanish language.
The obtained results and observa-tions, serve as a base for the context extraction andthe experimental setup for the rest of the languageswhich we want to study.
However, to verify the mul-tilingual performance of the approach, we decidedto carry out an experiment with a language which isvery different from the Romance family.For this reason, we choose the Bulgarian lan-guage, which is the earliest written Slavic language.It dates back from the creation of the old Bulgarianalphabet Glagolista, which was later replaced by theCyrillic alphabet.
The most typical characteristics ofthe Bulgarian language are the elimination of noundeclension, suffixed definite article, lack of a verbinfinitive and complicated verb system.The Bulgarian name discrimination data is ex-tracted from the news corpus Sega2002.
This corpusis originally prepared and used in the CLEF compe-titions.
The corpus consists of news articles orga-nized in different XML files depending on the year,month, and day of the publication of the news.
Wemerged all files into a single one, and consideredonly the text between the text tags.
In order to easethe text processing and to avoid encoding problems,we transliterated the Cyrillic characters into Latinones.The discrimination data in this experiment con-sists of the city, country, party, river and mountaincategories.
We were interested in studying not onlythe multilingual issue of our approach, but also howscalable it is with other categories.
The majorityof the categories are locations and only one corre-sponds to organization.
In Table 4, we shows thenumber of names which we extracted for each oneof the categories.5.2 Bulgarian dataThe cities include the capital of Bulgaria ?
Sofia, thesecond and third biggest Bulgarian cities ?
Plovdivand Varna, a city from the southern parts of Bulgaria?
Haskovo, the capital of England ?
London andthe capital of Russia ?
Moskva.
The occurrences ofthese examples are conflated in the ambiguous nameCITY.For countries we choose Russia (Rusiya)3, Ger-many (Germaniya), France (Franciya), Turkey (Tur-ciya) and England (Angliya).
The five names areconflated into COUNTRY.The organizations we worked with are the twoleading Bulgarian political parties.
BSP (Balgar-ska Socialisticeska Partija, or Bulgarian SocialistParty) is the left leaning party and the successor tothe Bulgarian Communist Party.
SDS (Sayuz nademokratichnite sili, or The Union of DemocraticForces) is the right leaning political party.
The twoorganizations are conflated into PARTY.For the RIVER category we choose Danube(Dunav) which is the second longest river in Eu-rope and passes by Bulgaria, Maritsa which is thelongest river that runs solely in the interior of theBalkans, Struma and Mesta which run in Bulgariaand Greece.The final category consists of the oldest Bulgarianmountain situated in the southern part of Bulgaria ?Rhodope (Rodopi), Rila which is the highest moun-tain in Bulgaria and on the whole Balkan Penin-sula, and Pirin which is the second highest Bulgarianmountain after Rila.
The three mountain names areconflated and substituted with the label MOUNTAIN.5.3 Bulgarian name discriminationThe experimental settings coincide with those pre-sented in Section 4 and the obtained results areshown in Table 4.
The performance of our approachranges from 32 to 81%.
For the five categories, thebest performance is achieved for those names thathave the majority number of examples.For instance, for the CITY category, the best per-formance of 79% is reached with Sofia.
TAs wehave previously mentioned, this is due to the fact thatLSA has more evidence about the context in whichSofia appears.
It is interesting to note that the city3this is the Bulgarian transliteration for Russia24Category Instance Total P R FCityPlovdiv 1822 44.42 83.87 58.08Sofiya 5633 71.39 89.79 79.54Varna 1042 32.02 82.64 46.17Haskovo 140 21.09 69.29 32.33London 751 31.32 84.82 45.74Moskva 1087 39.47 88.22 54.53CountryRusiya 2043 55.83 86.19 67.77Germaniya 1588 40.72 77.96 53.50Francia 1352 37.27 77.81 50.39Turciya 1162 43.23 84.08 57.10Angliya 655 29.67 72.67 42.14PartyBSP 2323 42.54 99.35 59.57SDS 3916 64.86 98.85 78.32RiverDunav 403 85.39 76.92 80.94Marica 203 77.88 83.25 80.47Mesta 81 63.64 95.06 76.24Struma 37 56.67 91.89 70.10MountainRila 101 70.22 91.09 79.31Pirin 294 75.11 57.48 65.12Rodopi 135 71.04 96.29 81.76Table 4: Bulgarian NE discriminationVarna forms part of weak named entities such as theUniversity of Varna, the Major house of Varna.
Al-though, this strong entity is embedded into the weakones, practically Varna changes its semantic cate-gory from a city into university, major house.
Thiscreates additional ambiguity in our already conflatedand ambiguous names.
In order to improve the per-formance, we need a better data generation processwhere the mixture of weak and strong entities willbe avoided.The same effect of best classification for major-ity sense is observed with the COUNTRY category.The best performance of 67% is obtained for Rus-sia.
The other country which is distinguished sig-nificantly well is Turkey.
The 57% performance isfrom 5 to 10% higher compared to the performancesof Germany, England and France.
This is due to thecontext in which the names occur.
Turkey is relatedto trading with Bulgaria and emigration, meanwhilethe other countries appear in the context of the Eu-ropean Union, the visit of the Bulgarian president inthese countries.During the error analysis, we noticed that in thecontext of the political parties, SDS appeared manytimes in with the names of the political leader or therepresentatives of the BSP party and vice versa.
Thisimpeded LSA?s classification, because of the similarcontext.Among all categories, RIVER and MOUNTAINobtained the best performances.
The rivers Dunavand Maritsa reached 80%, while the mountainsRodopi achieved 81.76% f-score.
Looking at thediscrimination results for the other names in thesecategories, it can be seen that their performances aremuch higher compared to the names of the CITY,COUNTY and PARTY categories.
This experimentshows that the discrimination power is related to thetype of the NE category we want to resolve.6 ConclusionsIn this paper, we have presented a language indepen-dent approach for person name categorization anddiscrimination.
This approach is based on the sen-tence semantic similarity information derived fromLSA.
The approach is evaluated with different NEexamples for the Spanish and Bulgarian languages.We have observed the discrimination performance ofLSA not only with the SINGER and PRESIDENTcompanies, but also with the CITY, COUNTRY,MOUNTAIN, RIVER and PARTY.
This is the firstapproach which focuses on the resolution of thesecategories for the Bulgarian language.The obtained results both for Spanish and Bulgar-ian are very promising.
The baselines are outper-formed with 25%.
The person fine-grained catego-rization reaches 90% while the name discriminationvaries from 42% to 90%.
This variability is relatedto the degree of the name ambiguity among the con-flated names and similar behaviour is observed in theco-occurence approach of (Pedersen et al, 2005).During the experimental evaluation, we found outthat the 100% name purity (e.g.
that one name be-longs only to one and the same semantic category)which we accept during the data creation in real-ity contains 9% noise.
These observations are con-firmed in the additional experimental study we haveconducted with the Bulgarian language.
Accordingto the obtained results, our text semantic similarityapproach performs very well and practically thereis no restrain to be adapted to other languages, datasets or even new categories.7 Future WorkIn the future, we want to relate the name discrimi-nation and categorization processes, by first encoun-tering the different underlying meanings of a name25and then grouping together the sentences that belongto the same semantic category.
This process will in-crease the performance of the NE fine-grained cat-egorization, and will reduce the errors we encoun-tered during the classification of the singers EnriqueIglesias and Madonna.
In addition to this experi-ment, we want to cluster web pages on the basis ofname ambiguity.
For instance, we want to processthe result for the Google?s query George Miller, andform three separate clusters obtained on the basis ofa fine-grained and name discrimination.
Thus wecan form the clusters for GeorgeMiller the congress-man, the movie director and the father of WordNet.This study will include also techniques for automaticcluster stopping.Moreover, LSA?s ability of language indepen-dence can be exploited to resolve cross-languageNE categorization and discrimination from whichwe can extract cross-language pairs of semanticallyrelated words characterizing a person e.g.
GeorgeBush is seen with White House in English, la CasaBlanca in Spanish, a Casa Branka in Portuguese andBeliat Dom in Bulgarian.With LSA, we can also observe the time consis-tency property of a person which changes its se-mantic category across time.
For instance, a stu-dent turns into a PhD student, teaching assistant andthen university professor, or as in the case of ArnoldSchwarzenegger from actor to governor.AcknowledgementsWe would like to thank the three anonymous re-viewers for their useful comments and suggestions.This work was partially funded by the EuropeanUnion under the project QALLME number FP6 IST-033860 and by the Spanish Ministry of Science andTechnology under the project TEX-MESS numberTIN2006-15265-C06-01.ReferencesA.
Bagga and B. Baldwin.
1998.
Entity-based cross-document coreferencing using the vector space model.In Proceedings of the Thirty-Sixth Annual Meeting ofthe ACL and Seventeenth International Conference onComputational Linguistics, pages 79?85.G.
Cleuziou, L. Martin, and C. Vrain.
2004.
Poboc: Anoverlapping clustering algorithm, application to rule-based classification and textual data.
In ECAI, pages440?444.S.
Deerwester, S. Dumais, G. Furnas, T. Landauer, andR.
Harshman.
1990.
Indexing by latent semantic anal-ysis.
In Journal of the American Society for Informa-tion Science, volume 41, pages 391?407.S.
Dumais.
1995.
Using lsi for information filtering:Trec-3 experiments.
In The Third Text Retrieval Con-ference (TREC-3), pages 219?230.M.
Fleischman and E. Hovy.
2002.
Fine grained classifi-cation of named entities.
In Proceedings of the 19th in-ternational conference on Computational linguistics,pages 1?7.Z.
Kozareva, O. Ferra?ndeza, A. Montoyo, R. Mun?oz,A.
Sua?rez, and J.
Go?mez.
2007.
Combining data-driven systems for improving named entity recogni-tion.
Data and Knowledge Engineering, 61(3):449?466, June.G.
Mann.
2002.
Fine-grained proper noun ontologies forquestion answering.
In COLING-02 on SEMANET,pages 1?7.G.
Miller and W. Charles.
1991.
Contextual correlates ofsemantic similarity.
In Language and Cognitive Pro-cesses, pages 1?28.M.
Pasca.
2004.
Acquisition of categorized named enti-ties for web search.
In CIKM ?04: Proceedings of thethirteenth ACM international conference on Informa-tion and knowledge management, pages 137?145.T.
Pedersen, A. Purandare, and A. Kulkarni.
2005.
Namediscrimination by clustering similar contexts.
In CI-CLing, pages 226?237.P.
Shah, D. Schneider, C. Matuszek, R.C.
Kahlert,B.
Aldag, D. Baxter, J. Cabral, M. Witbrock, andJ.
Curtis.
2006.
Automated population of cyc: Ex-tracting information about named-entities from theweb.
In Proceedings of the Nineteenth InternationalFLAIRS Conference, pages 153?158.H.
Shu?tze.
1998.
Automatic word sense discrimination.In Journal of computational linguistics, volume 24.H.
Tanev and B. Magnini.
2006.
Weakly supervised ap-proaches for ontology population.
In Proceeding of11th Conference of the European Chapter of the Asso-ciation for Computational Linguistics, pages 17?24.26
