Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 29?32,Paris, October 2009. c?2009 Association for Computational LinguisticsLearning Stochastic Bracketing Inversion Transduction Grammarswith a Cubic Time Biparsing AlgorithmMarkus SAERS Joakim NIVREDept.
of Linguistics and PhilologyUppsala UniversitySwedenfirst.last@lingfil.uu.seDekai WUHuman Language Technology CenterDept.
of Computer Science and EngineeringHKUSTHong Kongdekai@cs.ust.hkAbstractWe present a biparsing algorithm forStochastic Bracketing Inversion Transduc-tion Grammars that runs in O(bn3) timeinstead of O(n6).
Transduction gram-mars learned via an EM estimation proce-dure based on this biparsing algorithm areevaluated directly on the translation task,by building a phrase-based statistical MTsystem on top of the alignments dictatedby Viterbi parses under the induced bi-grammars.
Translation quality at differentlevels of pruning are compared, showingimprovements over a conventional wordaligner even at heavy pruning levels.1 IntroductionAs demonstrated by Saers & Wu (2009) thereis something to be gained by applying structuralmodels such as Inversion Transduction Grammars(ITG) to the problem of word alignment.
One is-sue is that na?
?ve methods for inducing ITGs fromparallel data can be very time consuming.
We in-troduce a parsing algorithm for inducing Stochas-tic Bracketing ITGs from parallel data in O(bn3)time instead ofO(n6), where b is a pruning param-eter (lower = tighter pruning).
We try out differentvalues for b, and evaluate the results on a transla-tion tasks.In section 2 we summarize the ITG framework;in section 3 we present our algorithm, whose timecomplexity is analyzed in section 4.
In section 5we describe how the algorithm is evaluated, and insection 6, the empirical results are given.2 Inversion Transduction GrammarsInversion transductions are a theoretically inter-esting and empirically useful equivalence class oftransductions, with expressiveness and computa-tional complexity characteristics lying intermedi-ate between finite-state transductions and syntax-directed transductions.
An Inversion Transduc-tion Grammar (ITG) can be used to synchronouslygenerate sentence pairs, synchronously parse sen-tence pairs, or transduce from a sentence in onelanguage to a sentence in another.1The equivalence class of inversion transduc-tions can be described by restricting Syntax-Directed Transduction Grammars (SDTG)2 in var-ious equivalent ways to the special cases of (a) bi-nary SDTGs, (b) ternary SDTGs, or (c) SDTGswhose transduction rules are restricted to straightand inverted permutations only.Thus on one hand, any binary or ternary SDTGis an ITG.
Conversely, any ITG can be stated inbinary two-normal form (Wu, 1997).
Only threekinds of rules are present in the normal form:A?
[BC]A?
?BC?A?
e/fOn the other hand, under characterization (c),what distinguishes ITGs is that the permutation ofconstituents is restricted in such a way that all chil-dren of a node must be read either left-to-right, orright-to-left.
The movement only applies to one ofthe languages, the other is fixed.
Formally, an ITGis a tuple ?N,V,?, S?, where N is a set of nonter-minal symbols, ?
is a set of rewrite rules, S ?
Nis the start symbol and V ?
VE ?
VF is a set ofbiterminal symbols, where VE is the vocabulary ofE and VF is the vocabulary of F .
We will write abiterminal as e/f , where e ?
VE and f ?
VF .
Asentence pair will be written as e/f , and a bispanas es..t/fu..v.Each rule ?
?
?
is a tuple ?X, ?, ??
whereX ?
N is the right hand side of the rule, ?
?1All transduction grammars (a.k.a.
synchronous gram-mars, or simply bigrammars) can be interpreted as modelsfor generation, recognition, or transduction.2SDTGs (Lewis & Stearns (1968); Aho & Ullman (1969),(1972)) are also recently called synchronous CFGs.29{N ?
V }?
is a series of nonterminal and biter-minal symbols representing the production of therule and ?
?
{?, [], ??}
denotes the orientation (ax-iomatic, straight or inverted) of the rule.
Straightrules are read left-to-right in both languages, whileinverted rules are read left-to-right in E and right-to-left in F .
The direction of the axiomatic rules isundefined, as they must be completely made up ofterminals.
For notational convenience, the orien-tation of the rule is written as surrounding the pro-duction, like so: X ?
?, X ?
[?]
and X ?
??
?.The vocabularies of the languages may both in-clude the empty token , allowing for deletionsand insertions.
The empty biterminal, / is notallowed.2.1 Stochastic ITGsIn a Stochastic ITG (SITG), each rule is also asso-ciated with a probability, such that?
?Pr(X ?
?)
= 1for all X ?
N .
The probability of a deriva-tion S ??
e/f is defined as the production ofthe probabilities of all rules used.
As shown byWu (1995), it is possible to fit the parameters ofa SITG to a parallel corpus via EM (expectation-maximization) estimation.2.2 Bracketing ITGsAn ITG where there is only one nonterminal (otherthan the start symbol) is called a bracketing ITG(BITG).
Since the one nonterminal is devoid ofinformation, it can only be used to group its chil-dren together, imposing a bracketing on the sen-tence pairs.3 Parsing SBITGsIn this section we present a biparsing algorithmfor Stochastic Bracketing Inversion TransductionGrammars (SBITGs) in normal form which incor-porates a pruning parameter b.
The algorithm isbasically an agenda-based bottom-up chart parser,where the pruning parameter controls the numberof active items of a given length.To parse a sentence pair e/f , the parser needsa chart C and a series of T + V agendasA1, A2, .
.
.
, AT+V , where T = |e| and V = |f |.An item is defined as a nonterminal symbol (weuse X to denote the anonymous nonterminal sym-bol of the bracketing ITG) and one span in eachlanguage, written as Xstuv where 0 ?
s ?
t ?
Tcorresponds to the span es..t and 0 ?
u ?
v ?
Vcorresponds to the span fu..v. The length of anitem is defined as |Xstuv| = (t?s)+(v?u).
Sinceitems are grouped by their length, highly skewedlinks (eg.
6:1) will be competing with very evenlinks (eg.
4:3).
Skewed links are generally bad(and should be pruned), or have a high probability(which means they are likely to survive pruning).An item may be active or passive, the active itemsare present in the agendas and the chart, whereasthe passive items are only present in the chart.The parser starts by asserting items from all lex-ical rules (X ?
e/f ), and placing them on theirrespective agendas.
After the initial seeding, theagendas are processed in order.
When an agendais processed, it is first pruned, so that only the bbest items are kept active.
After pruning, the re-maining active items are allowed to be extended.When extended, the item combines with an adja-cent item in the chart to form a larger item.
Thenewly created item is considered active, and addedto both the chart and the appropriate agenda.
Oncean item has been processed it goes from being ac-tive to being passive.
The process is halted whenthe goal item S0T0V is reached, or when no activeitems remain.
To build the forest corresponding tothe parse process, back-pointers are used.3.1 InitializationIn the initial step, the set of lexical items L is built.All lexical items i ?
L are then activated by plac-ing them on their corresponding agenda A|i|.L =???Xstuv??????0?s?
t?T,0?u?v?V,X ?
es..t/fu..v ?
???
?By limiting the length of phrasal terminals to somethreshold ?, the variables t and v can be limited tos+?
and u+?
respectively, limiting the complexityof the initialization step from O(n4) to O(n2).3.2 RecursionIn the recursive step we build a set of extensionsE(i) for all active items i.
All items in E(i)are then activated by placing them on their cor-responding agenda (i ?
A|i|).E(Xstuv) ={XStUv|0?S?s, 0?U?u,XSsUu ?
C} ?
{XsSuU |t?S?T, v?U?V,XtSvU ?
C} ?
{XsSUv|t?S?T, 0?U?u,XtSUu ?
C} ?
{XStuU |0?S?s, v?U?V,XSsvU ?
C}30Since we are processing the agendas in order, anyitem in the chart will be as long as or shorter thanthe item being extended.
This fact can be exploitedto limit the number of possible siblings explored,but has no impact on time complexity.3.3 Viterbi parsingWhen doing Viterbi parsing, all derivations butthe most probable are discarded.
This gives anunambiguous parse, which dictates exactly onealignment between e and f .
The alignment ofthe Viterbi parse can be used to substitute that ofother word aligners (Saers and Wu, 2009) such asGIZA++ (Och and Ney, 2003).4 AnalysisLooking at the algorithm, it is clear that there willbe a total of T + V = O(n) agendas, each con-taining items of a certain length.
The items in anagenda can start anywhere in the alignment space:O(n2) possible starting points, but once the endpoint in one language is set, the end point in theother follows from that, adding a factor O(n).This means that each agenda contains O(n3) ac-tive items.
Each active item has to go through allpossible siblings in the recursive step.
Since thestart point of the sibling is determined by the itemitself (it has to be adjacent), only the O(n2) pos-sible end points have to be explored.
This meansthat each active item takes O(n2) time to process.The total time is thus O(n6): O(n) agendas,containing O(n3) active items, requiring O(n2)time to process.
This is also the time complex-ity reported for ITGs in previous work (Wu, 1995;Wu, 1997).The pruning works by limiting the number ofactive items in an agenda to a constant b, meaningthat there are O(n) agendas, containing O(b) ac-tive items, requiring O(n2) time to process.
Thisgives a total time complexity of O(bn3).5 EvaluationWe evaluate the parser on a translation task(WMT?08 shared task3).
In order to evaluate ona translation task, a translation system has to bebuilt.
We use the alignments from the Viterbiparses of the training corpus to substitute thealignments of GIZA++.
This is the same approachas taken in Saers & Wu (2009).
We will evalu-ate the resulting translations with two automatic3http://www.statmt.org/wmt08/metrics: BLEU (Papineni et al, 2002) and NIST(Doddington, 2002).6 Empirical resultsIn this section we describe the experimental setupas well as the outcomes.6.1 SetupWe use the Moses Toolkit (Koehn et al, 2007) totrain our phrase-based SMT models.
The toolkitalso includes scripts for applying GIZA++ (Ochand Ney, 2003) as a word aligner.
We havetrained several systems, one using GIZA++ (ourbaseline system), one with no pruning at all, and6 different values of b (1, 10, 25, 50, 75 and100).
We used the grow-diag-final-andmethod to extract phrases from the word align-ment, and MERT (Och, 2003) to optimize the re-sulting model.
We trained a 5-gram SRI languagemodel (Stolcke, 2002) using the corpus suppliedfor this purpose by the shared task organizers.
Allof the above is consistent with the guidelines forbuilding a baseline system for the WMT?08 sharedtask.The translation tasks we applied the aboveprocedure to are all taken from the Europarlcorpus (Koehn, 2005).
We selected the tasksGerman-English, French-English and Spanish-English.
Furthermore, we restricted the trainingsentence pairs so that none of the sentences ex-ceeded length 10.
This was necessary to be able tocarry out exhaustive search.
The total amount oftraining data was roughly 100,000 sentence pairsin each language pair, which is a relatively smallcorpus, but by no means a toy example.6.2 Grammar inductionIt is possible to set the parameters of a SBITGby applying EM to an initial guess (Wu, 1995).As our initial guess, we used word co-occurrencecounts, assuming that there was one empty tokenin each sentence.
This gave an estimate of the lex-ical rules.
The probability mass was divided sothat the lexical rules could share half of it, whilethe other half was shared equally by the two struc-tural rules (X ?
[XX] and X ?
?XX?
).Several training runs were made with differentpruning parameters.
The EM process was haltedwhen a relative improvement in log-likelihood of10?3 was no longer achieved over the previous it-eration.31Baseline Different values of b for SBITGsMetric (GIZA++) ?
100 75 50 25 10 1Spanish-EnglishBLEU 0.2597 0.2663 0.2671 0.2661 0.2653 0.2655 0.2608 0.1234NIST 6.6352 6.7407 6.7445 6.7329 6.7101 6.7312 6.6439 3.9705time 03:20:00 02:40:00 02:00:00 01:20:00 00:38:00 00:17:00 00:03:10German-EnglishBLEU 0.2059 0.2113 0.2094 0.2091 0.2090 0.2091 0.2050 0.0926NIST 5.8668 5.9380 5.9086 5.8955 5.8947 5.9292 5.8743 3.4297time 03:40:00 02:45:00 02:10:00 01:25:00 00:41:00 00:17:00 00:03:20French-EnglishBLEU 0.2603 0.2663 0.2655 0.2668 0.2669 0.2654 0.2632 0.1268NIST 6.6907 6.8151 6.8068 6.8068 6.8065 6.7013 6.7136 4.0849time 03:10:00 02:45:00 02:10:00 01:25:00 00:42:00 00:17:00 00:03:25Table 1: Results.
Time measures are approximate time per iteration.Once the EM process terminated, Viterbi parseswere calculated for the training corpus, and thealignments from them outputted in the same for-mat produced by GIZA++.6.3 ResultsThe results are presented in Table 1.
GIZA++generally terminates within minutes (6?7) on thetraining corpora used, making it faster than anyof the SBITGs (they generally required 4?6 iter-ations to terminate, making even the fastest onesslower than GIZA++).
To put the times in per-spective, about 6 iterations were needed to getthe ITGs to converge, making the longest trainingtime about 16?17 hours.
The time it takes to ex-tract the phrases and tune the model using MERTis about 14 hours for these data sets.Looking at translation quality, we see a sharpinitial rise as b grows to 10.
At this point theSBITG system is on par with GIZA++.
It con-tinues to rise up to b = 25, but after that is more orless levels out.
From this we conclude that the pos-itive results reported in Saers & Wu (2009) holdunder harsh pruning.7 ConclusionsWe have presented a SBITG biparsing algorithmthat uses a novel form of pruning to cut the com-plexity of EM-estimation from O(n6) to O(bn3).Translation quality using the resulting learnedSBITG models is improved over using conven-tional word alignments, even under harsh levels ofpruning.AcknowledgmentsThe authors are grateful for the comments made by the two anonymous review-ers.
This work was funded by the Swedish National Graduate School of Lan-guage Technology, the Defense Advanced Research Projects Agency (DARPA)under GALE Contract No.
HR0011-06-C-0023, and the Hong Kong ResearchGrants Council (RGC) under research grants GRF621008, DAG03/04.EG09,RGC6256/00E, and RGC6083/99E.
Any opinions, findings and conclusions orrecommendations expressed in this material are those of the authors and donot necessarily reflect the views of the Defense Advanced Research ProjectsAgency.ReferencesAlfred V. Aho and Jeffrey D. Ullman.
1969.
Syntax-directed translationsand the pushdown assembler.
Journal of Computer and System Sciences,3(1):37?56.Alfred V. Aho and Jeffrey D. Ullman.
1972.
The Theory of Parsing, Transla-tion, and Compiling (Volumes 1 and 2).
Prentice-Halll, Englewood Cliffs,NJ.George Doddington.
2002.
Automatic evaluation of machine translation qual-ity using n-gram co-occurrence statistics.
In Human Language Technologyconference (HLT-2002), San Diego, CA.Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, MarcelloFederico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and EvanHerbst.
2007.
Moses: Open source toolkit for statistical machine trans-lation.
In ACL-2007 Demo and Poster Sessions, pages 177?180, Prague,Jun.Philipp Koehn.
2005.
Europarl: A parallel corpus for statistical machine trans-lation.
In Machine Translation Summit X, Phuket, Thailand, September.Philip M. Lewis and Richard E. Stearns.
1968.
Syntax-directed transduction.Journal of the Association for Computing Machinery, 15(3):465?488.Franz Josef Och and Hermann Ney.
2003.
A systematic comparison of variousstatistical alignment models.
Computational Linguistics, 29(1):19?52.Franz Josef Och.
2003.
Minimum error rate training in statistical machinetranslation.
In 41st Annual Meeting of the Association for ComputationalLinguistics, pages 160?167, Sapporo, Japan, Jul.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU:A method for automatic evaluation of machine translations.
In 40th AnnualMeeting of the Association for Computational Linguistics (ACL-2002),pages 311?318, Philadelphia, Jul.Markus Saers and Dekai Wu.
2009.
Improving phrase-based translation viaword alignments from Stochastic Inversion Transduction Grammars.
InProceedings of SSST-3, Third Workshop on Syntax and Structure in Statis-tical Translation (at NAACL HLT 2009), pages 28?36, Boulder, CO, Jun.Andreas Stolcke.
2002.
SRILM ?
an extensible language modeling toolkit.In International Conference on Spoken Language Processing, Denver, CO,Sep.Dekai Wu.
1995.
Trainable coarse bilingual grammars for parallel text brack-eting.
In Third Annual Workshop on Very Large Corpora (WVLC-3), pages69?81, Cambridge, MA, Jun.Dekai Wu.
1997.
Stochastic Inversion Transduction Grammars and bilingualparsing of parallel corpora.
Computational Linguistics, 23(3):377?404,Sep.32
