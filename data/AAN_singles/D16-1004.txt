Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 33?43,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsUsing Left-corner Parsing to Encode Universal Structural Constraintsin Grammar InductionHiroshi NojiGraduate School of Information ScienceNara Institute of Science and Technologynoji@is.naist.jpYusuke MiyaoNational Institute of Informaticsyusuke@nii.ac.jpMark JohnsonDepartment of ComputingMacquarie Universitymark.johnson@mq.edu.auAbstractCenter-embedding is difficult to process and isknown as a rare syntactic construction acrosslanguages.
In this paper we describe a methodto incorporate this assumption into the gram-mar induction tasks by restricting the searchspace of a model to trees with limited center-embedding.
The key idea is the tabulationof left-corner parsing, which captures the de-gree of center-embedding of a parse via itsstack depth.
We apply the technique to learn-ing of famous generative model, the depen-dency model with valence (Klein and Man-ning, 2004).
Cross-linguistic experiments onUniversal Dependencies show that often ourmethod boosts the performance from the base-line, and competes with the current state-of-the-art model in a number of languages.1 IntroductionHuman languages in the world are divergent, butthey also exhibit many striking similarities (Green-berg, 1963; Hawkins, 2014).
At the level of syn-tax, one attractive hypothesis for such regularities isthat any grammars of languages have evolved un-der the pressures, or biases, to avoid structures thatare difficult to process.
For example it is known thatmany languages have a preference for shorter depen-dencies (Gildea and Temperley, 2010; Futrell et al,2015), which originates from the difficulty in pro-cessing longer dependencies (Gibson, 2000).Such syntactic regularities can also be useful inapplications, in particular in unsupervised (Kleinand Manning, 2004; Marec?ek and Z?abokrtsky?,2012; Bisk and Hockenmaier, 2013) or weakly-supervised (Garrette et al, 2015) grammar induc-tion tasks, where the models try to recover the syn-tactic structure of language without access to thesyntactically annotated data, e.g., from raw or part-of-speech tagged text only.
In these settings, find-ing better syntactic regularities universal across lan-guages is essential, as they work as a small cue tothe correct linguistic structures.
A preference ex-ploited in many previous works is favoring shorterdependencies, which has been encoded in variousways, e.g., initialization of EM (Klein and Man-ning, 2004), or model parameters (Smith and Eis-ner, 2006), and this has been the key to success oflearning (Gimpel and Smith, 2012).In this paper, we explore the utility for anotheruniversal syntactic bias that has not yet been ex-ploited in grammar induction: a bias against center-embedding.
Center-embedding is a syntactic con-struction on which a clause is embedded into anotherone.
An example is ?The reporter [who the senator[who Mary met] attacked] ignored the president.
?,where ?who Mary met?
is embedded in a largerrelative clause.
These constructions are known tocause memory overflow (Miller and Chomsky, 1963;Gibson, 2000), and also are rarely observed cross-linguistically (Karlsson, 2007; Noji and Miyao,2014).
Our learning method exploits this universalproperty of language.
Intuitively during learning ourmodels explore the restricted search space, whichexcludes linguistically implausible trees, i.e., thosewith deeper levels of center-embedding.We describe how these constraints can be imposedin EM with the inside-outside algorithm.
The central33SHIFT ?d?1 a7??
?d?1|Ad A?
a ?
PSCAN ?d?1|B/Ad a7??
?d?1|Bd A?
a ?
PPRED ?d?1|Ad ?7??
?d?1|B/Cd B ?
A C ?
PCOMP ?d?1|D/Bd|Ad+1 ?7??
?d?1|D/Cd B ?
A C ?
PFigure 1: A set of transitions in left-corner parsing.The rules on the right side are the side conditions, inwhich P is the set of rules of a given CFG.idea is to tabulate left-corner parsing, on which itsstack depth captures the degree of center-embeddingof a partial parse.
Each chart item keeps the cur-rent stack depth and we discard all items where thedepth exceeds some threshold.
The technique is gen-eral and can be applicable to any model on PCFG;in this paper, specifically, we describe how to ap-ply the idea on the dependency model with valence(DMV) (Klein and Manning, 2004), a famous gen-erative model for dependency grammar induction.We focus our evaluation on grammar inductionfrom part-of-speech tagged text, comparing the ef-fect of several biases including the one againstlonger dependencies.
Our main empirical finding isthat though two biases, avoiding center-embeddingand favoring shorter dependencies, are conceptuallysimilar (both favor simpler grammars), often theycapture different aspects of syntax, leading to dif-ferent grammars.
In particular our bias cooperateswell with additional small syntactic cue such as theone that the sentence root tends to be a verb ora noun, with which our models compete with thestrong baseline relying on a larger number of handcrafted rules on POS tags (Naseem et al, 2010).Our contributions are: the idea to utilize left-corner parsing for a tool to constrain the models ofsyntax (Section 3), the formulation of this idea forDMV (Section 4), and cross-linguistic experimentsacross 25 languages to evaluate the universality ofthe proposed approach (Sections 5 and 6).2 Left-corner parsingWe first describe (arc-eager) left-corner (LC) pars-ing as a push-down automaton (PDA), and then re-formulate it as a grammar transform.
In previouswork this algorithm has been called right-cornerparsing (e.g., Schuler et al (2010)); we avoid thisterm and instead treat it as a variant of LC parsingfollowing more recent studies, e.g., van SchijndelDBi jAj + 1 kCOMP===?DBi jCAj + 1 kFigure 2: COMP combines two subtrees on the topof the stack.
i, j, k are indices of spans.and Schuler (2013).
The central motivation for thistechnique is to detect center-embedding in a parseefficiently.
We describe this mechanism after pro-viding the algorithm itself.
We then give historicalnotes on LC parsing at the end of this section.PDA Let us assume a CFG is given, and it is inCNF.
We formulate LC parsing as a set of transi-tions between configurations, each of which is a pairof the stack and the input position (next input sym-bol).
In Figure 1 a transition ?1 a7??
?2 means thatthe stack is changed from ?1 to ?2 by reading thenext input symbol a.
We use a vertical bar to sig-nify the append operation, e.g., ?
= ?
?|?1 denotes?1 is the topmost symbol of ?.
Each stack symbol iseither a nonterminal, or a pair of nonterminals, e.g.,A/B, which represents a subtree rooted at A and isawaiting symbol B.
We also decorate each symbolwith depth; for example, ?d?1|Ad means the currentstack depth is d, and the depth of the topmost sym-bol in ?
is d?
1.
The bottom symbol on the stack isalways the empty symbol ?0 with depth 0.
Parsingbegins with ?0.
Given the start symbol of CFG S, itfinishes when S1 is found on the stack.The key transition here is COMP (Figure 2).1 Ba-sically the algorithm builds a tree by expanding thehypothesis from left to right.
In COMP, a subtreerooted at A is combined with the second top subtree(D/B) on the stack.
This can be done by first pre-dicting that A?s parent symbol is B and its sibling isC; then it unifies two different Bs to combine them.PRED is simpler, and it just predicts the parent andsibling symbols of A.
The input symbols are readby SHIFT and SCAN: SHIFT addes a new elementon the stack while SCAN fills in the predicted sib-ling symbol.
For an example, Figure 3 shows how1van Schijndel and Schuler (2013) employ different transi-tion names, e.g., L- and L+; we avoid them as they are lessinformative.34Step Transition Stack Next input symbol0 ?
e1 SHIFT E1 f2 PRED D/B1 f3 SHIFT D/B1 F 2 g4 PRED D/B1 A/G2 g5 SCAN D/B1 A2 c6 COMP D/C1 c7 SCAN D1Figure 3: Sequence of transitions in LC PDA toparse the tree in Figure 4(a).DBCcAGgFfEe(a)D1cD/C1A2gA/G2F 2fD/B1E1e(b)Figure 4: An example of LC transform: (a) the orig-inal parse; and (b) the transformed parse.this PDA works for parsing a tree in Figure 4(a).Grammar transform The algorithm above can bereformulated as a grammar transform, which be-comes the starting point for our application to gram-mar induction.
This can be done by extracting theoperated top symbols on the stack in each transition:SHIFT: Ad ?
a (A?
a ?
P );SCAN: Bd ?
B/Ad a (A?
a ?
P );PRED: B/Cd ?
Ad (B ?
A C ?
P );COMP: D/Cd ?
D/Bd Ad+1 (B ?
A C ?
P ).where a rule on the right side is a condition given theset of rules P in the CFG.Figure 4 shows an example of this transform.
Theessential point is that each CFG rule in the trans-formed parse (b) corresponds to a transition in theoriginal algorithm (Figure 1).
For example a ruleD/C1 ?
D/B1 A2 in the parse indicates that thestack configuration D/B1|A2 occurs during parsing(just corresponding to the step 5 in Figure 3) andCOMP is then applied.
This can also be seen as aninstantiation of Figure 2.Stack depth and center-embedding We use theterm center-embedding to distinguish just the treestructures, i.e., ignoring symbols.
That is, the treein Figure 4(a) is the minimal, one degree of center-embedded tree, where the constituent rooted at Ais embedded into a larger constituent rooted at D.Multiple, or degree ?
2 of center-embedding oc-curs if this constituent is also embedded into anotherlarger constituent.Note that it is only COMP that consumes the toptwo symbols on the stack.
This means that a largerstack depth occurs only when COMP is needed.
Fur-thermore, from Figure 2 COMP always induces asubtree involving new center-embedding, and this isthe underlying mechanism that the stack depth of thealgorithm captures the degree of center-embedding.One thing to note is that to precisely associate thestack depth and the degree of center-embedding thedepth calculation in COMP should be revised as:COMP: D/Cd ?
D/Bd Ad?
(B ?
A C ?
P )d?
={d (SPANLEN(A) = 1)d+ 1 (otherwise), (1)where SPANLEN(A) calculates the span length ofthe constituent rooted atA, which is 2 in Figure 4(b).This modification is necessary since COMP for a sin-gle token occurs for building purely right-branchingstructures.2 Formally, then, given a tree with de-gree ?
of center-embedding the largest stack depthd?
during parsing this tree is: d?
= ?+ 1.Schuler et al (2010) found that on English tree-banks larger stack depth such as 3 or 4 rarely oc-curs while Noji and Miyao (2014) validated the lan-guage universality of this observation through cross-linguistic experiments.
These suggest we may uti-lize LC parsing as a tool for exploiting universal syn-tactic biases as we discuss in Section 3.Historical notes Rosenkrantz and Lewis (1970)first presented the idea of LC parsing as a gram-mar transform.
This is arc-standard, and has norelevance to center-embedding; Resnik (1992) andJohnson (1998) formulated an arc-eager variant byextending this algorithm.
The presented algorithmhere is the same as Schuler et al (2010), and isslightly different from Johnson (1998).
The dif-ference is in the start and end conditions: while2Schuler et al (2010) skip this subtlety by only concerningstack depth after PRED or COMP.
We do not take this approachsince ours allows a flexible extension described in Section 3.35our parser begins with an empty symbol, Johnson?sparser begins with the predicted start symbol, andfinishes with an empty symbol.3 Learning with structural constraintsNow we discuss how to utilize LC parsing for gram-mar induction in general.
An important observationin the above transform is that if we perform chartparsing, e.g., CKY, we can detect center-embeddedtrees efficiently in a chart.
For example, by set-ting a threshold of stack depth ?, we can eliminateany parses involving center-embedding up to degree??1.
Note that in a probabilistic setting, each weightof a transformed rule comes from the correspondingunderlying CFG rule (i.e., the condition).For learning, our goal is to estimate ?
of a gen-erative model p(z, x|?)
for parse z and its yields(words) x.
We take an EM-based simplest approach,and multiply the original model by a constraint fac-tor f(z, x) ?
[0, 1] to obtain a new model:p?
(z, x|?)
?
p(z, x|?
)f(z, x), (2)and then optimize ?
based on p?
(z, x|?).
This isessentially the same approach as Smith and Eisner(2006).
As shown in Smith (2006), when trainingwith EM we can increase the likelihood of p?
(z, x|?
)by just using the expected counts from an E-step onthe unnormalized distribution p(z, x|?
)f(z, x).We investigate the following constraints in our ex-periments:f(z, x) ={0 (d?z > ?
)1 (otherwise), (3)where d?z is the largest stack depth for z in LC pars-ing and ?
is the threshold.
This is a hard constraint,and can easily be achieved by removing all chartitems (of LC transformed grammar) on which thedepth of the symbol exceeds ?.
For example, when?
= 1 the model only explores trees without center-embedding, i.e., right- or left-linear trees.Length-based constraints By ?
= 2, the model isallowed to explore trees with one degree of center-embedding.
Besides these simple ones, we also in-vestigate relaxing ?
= 1 that results in an intermedi-ate between ?
= 1 and 2.
Specifically, we relax thedepth calculation in COMP (Eq.
1) as follows:d?
={d (SPANLEN(A) ?
?
)d+ 1 (otherwise), (4)where ?
?
1 controls the minimal length of a spanregarded as embedded into another one.
For exam-ple, when ?
= 2, the parse in Figure 4(a) is not re-garded as center-embedded because the span lengthof the constituent reduced by COMP (i.e., A) is 2.This modification is motivated with our observa-tion that in many cases center-embedded construc-tions arise due to embedding of small chunks, ratherthan clauses.
An example is ?...
prepared [the cat?s] dinner?, where ?the cat ?s?
is center-embeddedin our definition.
For this sentence, by relaxing thecondition with, e.g., ?
= 3, we can suppress the in-crease of stack depth.
We treat ?
as a hyperparameterin our experiments, and in practice, we find that thisrelaxed constraint leads to higher performance.4 Dependency grammar inductionIn this section we discuss how we can formulatethe dependency model with valence (DMV) (Kleinand Manning, 2004), a famous generative modelfor dependency grammar induction, on LC parsing.Though as we will see, applying LC parsing for a de-pendency model is a little involved compared to sim-ple PCFG models, dependency models have beenthe central for the grammar induction tasks, and weconsider it is most appropriate for assessing effec-tiveness of our approach.DMV is a head-outward generative model of adependency tree, controlled by two types of multi-nomial distributions.
For stop ?
{STOP,?STOP},?S(stop|h, dir, adj) is a Bernoulli random variable todecide whether or not to attach further dependentsin dir ?
{?,?}
direction.
The adjacency adj ?
{TRUE, FALSE} is the key factor to distinguish thedistributions of the first and the other dependents,which is TRUE if h has no dependent yet in dir di-rection.
Another type of parameter is ?A(a|h, dir), aprobability that h takes a as a dependent in dir di-rection.For this particular model, we take the followingapproach to formulate it in LC parsing: 1) convert-ing a dependency tree into a binary CFG parse; 2)applying LC transform on it; and 3) encoding DMV36X[ran]X[fast]fastX[ran]X[ran]ranX[dogs]dogs(a)X[ran]1fastX[ran/fast]1X[ran]1ranX[ran/ran]1X[dogs]1dogs(b)X[ran]X[ran]X[fast]fastX[ran]ranX[dogs]dogs(c)X[ran]1fastX[ran/fast]1X[ran]1ranX[ran/ran]1X[dogs]1dogs(d)Figure 5: Two CFG parses for ?dogs ran fast?
andthe results of LC transform ((a) ?
(b); (c) ?
(d)).X[a/b] is an abbreviation for X[a]/X[b].parameters into each CFG rule of the transformedgrammar.3 Below we discuss a problem for (1) and(2), and then consider parameterization.4Spurious ambiguity The central issue for apply-ing LC parsing is the spurious ambiguity in depen-dency grammars.
That is, there are more than one(binary) CFG parses corresponding to a given de-pendency tree.
This is problematic mainly for tworeasons: 1) we cannot specify the degree of center-embedding in a dependency tree uniquely; and2) this one-to-many mapping prevents the inside-outside algorithm to work correctly (Eisner, 2000).As a concrete example, Figures 5(a) and 5(c)show two CFG parses corresponding to the depen-dency tree dogsxranyfast.
We approach this prob-lem by first providing a grammar transform, whichgenerates all valid LC transformed parses (e.g., Fig-ures 5(b) and 5(d)) and then restricting the grammar3Another approach might be just applying the technique inSection 3 to some PCFG that encodes DMV, e.g., Headden IIIet al (2009).
The problem with this approach, in particularwith split-head grammars (Johnson, 2007), is that the calculatedstack depth no longer reflects the degree of center-embedding inthe original parse correctly.
As we discuss later, instead, we canspeed up inference by applying head-splitting after obtainingthe LC transformed grammar.4Technical details including the chart algorithm for split-head grammars can be found in the Ph.D. thesis of the first au-thor (Noji, 2016).X[wh]i h jX[wh/wp]i h j pX[wp/wp]i j pFigure 6: The senses of the symbols as a chart item.X[wh/wp] predicts the next dependent outside of thespan while X[wp/wp] predicts the head.a b c d e ROOTbddedcbbaFigure 7: Implicit binarization of the restrictedgrammar.
For each token, if its parent is in the rightside (e.g., b), it attaches all left children first.
The be-havior is opposed when the parent is in its left (e.g.,d).
A dummy root token is placed at the end.for generating particular parses only.Naive method Let us begin with the grammar be-low, which suffers from the spurious ambiguity:SHIFT: X[wh]d ?
whSCAN: X[wh]d ?
X[wh/wp]d wpL-PRED: X[wp/wp]d ?
X[wh]d (wxh wp);R-PRED: X[wh/wp]d ?
X[wh]d (wyh wp);L-COMP: X[wh/wp]d ?
X[wh/wp]dX[wa]d?
(wxa wp);R-COMP: X[wh/wa]d ?
X[wh/wp]dX[wp]d?
(wyp wa).Here X[a/b] denotes X[a]/X[b] while wh denotesthe h-th word in the sentence w. We can interpretthese rules as the operations on chart items (Figure6).
Note that only PRED and COMP create new de-pendency arcs and we divide them depending on thedirection of the created arcs (L and R).
d?
is calcu-lated by Eq.
4.
Note also that for L-COMP and R-COMP h might equal p; X[ran/fast]1 ?
X[ran/ran]1X[ran]2 in Figure 5(d) is such a case for R-COMP.Removing spurious ambiguity We can show thatby restricting conditions for some rules, the spuriousambiguity can be eliminated (the proof is omitted).1.
Prohibit R-COMP when h = p;2.
Assume the span of X[wp]d?
is (i, j) (i ?
p ?j).
Then allow R-COMP only when i = p.Intuitively, these conditions constraint the order thateach word collects its left and right children.
For37example, by the condition 1, this grammar is pro-hibited to generate the parse of Figure 5(d).Binarization Note that two CFG parses in Fig-ures 5(a) and 5(c) differ in how we binarize a givendependency tree.
This observation indicates thatour restricted grammar implicitly binarizes a depen-dency tree, and the incurred stack depth (or the de-gree of center-embedding) is determined based onthe structure of the binarized tree.
Specifically, wecan show that the presented grammar performs op-timal binarization; i.e., it minimizes the incurredstack depth.
Figure 7 shows an example, which isnot regarded as center-embedded in our procedure.In summary, our method detects center-embeddingfor a dependency tree, but the degree is determinedbased on the structure of the binarized CFG parse.Parameterization We can encode DMV parame-ters into each rule.
A new arc is introduced by oneof {L/R}-{PRED/COMP}, and the stop probabilitiescan be assigned appropriately in each rule by cal-culating the valence from indices in the rule.
Forexample, after L-PRED, wh does not take any rightdependents so ?S(stop|wh,?, h = j), where j is theright span index of X[wh], is multiplied.Improvement Though we omit the details, we canimprove the time complexity of the above grammarfrom O(n6) to O(n4) applying the technique simi-lar to Eisner and Satta (1999) without changing thebinarization mechanism mentioned above.
We im-plemented this improved grammar.5 Experimental setupA sound evaluation metric in grammar induction isknown as an open problem (Schwartz et al, 2011;Bisk and Hockenmaier, 2013), which essentiallyarises from the ambiguity in the notion of head.
Forexample, Universal dependencies (UD) is the recentstandard in annotation and prefers content words tobe heads, but as shown below this is very differentfrom the conventional style, e.g., the one in CoNLLshared tasks (Johansson and Nugues, 2007):Ivan is the best dancernsbj cop det amodsbj nmod nmodprdUDCONLLThe problem is that both trees are correct undersome linguistic theories but the standard metric, un-labeled attachment score (UAS), only takes into ac-count the annotation of the current gold data.Our goal in this experiment is to assess the ef-fect of our structural constraints.
To this end, we tryto eliminate such arbitrariness in our evaluation asmuch as possible in the following way:?
We experiment on UD, in which every treebankfollows the consistent UD style annotation.?
We restrict the model to explore only trees thatfollow the UD style annotation during learn-ing5, by prohibiting every function word6 in asentence to have any dependents.?
We calculate UAS in a standard way.We use UD of version 1.2.
Some treebanks are verysmall, so we select the top 25 largest languages.The input to the model is coarse universal POS tags.Punctuations are stripped off.
All models are trainedon sentences of length ?
15 and tested on ?
40.Initialization Much previous work of dependencygrammar induction relies on the technique calledharmonic initialization, which also biases the modeltowards shorter dependencies (Klein and Manning,2004).
Since our focus is to see the effect of struc-tural constraints, we do not try this and initializemodels uniformly.
However, we add a baselinemodel with this initialization in our comparison tosee the relative strength of our approach.Models For the baseline, we employ a variant ofDMV with features (Berg-Kirkpatrick et al, 2010),which is simple yet known to boost the performancewell.
The feature templates are almost the same;the only change is that we add backoff features forSTOP probabilities that ignore both direction and ad-jacency, which we found slightly improves the per-formance in a preliminary experiment.
We set theregularization parameter to 10 though in practice wefound the model is less sensitive to this value.
Werun 100 iterations of EM for each setting.
The dif-5We remove the restriction at test time though we found itdoes not affect the performance.6A word with one of the following POS tags: ADP, AUX,CONJ, DET, PART, and SCONJ.38ference of each model is then the type of constraintsimposed during the E-step7, or initialization:?
Baseline (FUNC): Function word constraints;?
HARM: FUNC with harmonic initialization;?
DEP: FUNC + stack depth constraints (Eq.
3);?
LEN: FUNC + soft dependency length bias,which we describe below.For DEP, we use ?
= 1.?
to denote the relaxed max-imum depth allowing span length up to ?
(Eq.
4).LEN is the previously explored structural bias(Smith and Eisner, 2006), which penalizes longerdependencies by modifying each attachment score:?
?A(a|h, dir) = ?A(a|h, dir) ?
e???
(|h?a|?1), (5)where ?
(?
0) determines the strength of the biasand |h?
a| is (string) distance between h and a.Note that DEP and LEN are closely related; gen-erally center-embedded constructions are accompa-nied by longer dependencies so LEN also penalizescenter-embedding implicitly.
However, the oppositeis not true and there exist many constructions withlonger dependencies without center-embedding.
Bycomparing these two settings, we discuss the worthof focusing on constraining center-embedding rela-tive to the simpler bias on dependency length.Finally we also add the system of Naseem et al(2010) in our comparison.
This system encodesmany manually crafted rules between POS tags withthe posterior regularization technique.
For example,the model is encouraged to find NOUN ?
ADJ re-lationship.
Our systems cannot access to these coregrammatical rules so it is our strongest baseline.8Constraining root word We also see the effectsof the constraints when a small amount of grammat-ical rule is provided.
In particular, we restrict thecandidate root words of the sentence to a noun or averb; similar rules have been encoded in past worksuch as Gimpel and Smith (2012) and the CCG in-duction system of Bisk and Hockenmaier (2013).7We again remove the restrictions at decoding as we ob-served that the effects are very small.8We encode the customized rules that follow UD scheme.The following 13 rules are used: ROOT ?
VERB, ROOT ?NOUN, VERB?
NOUN, VERB?
ADV, VERB?
VERB, VERB?
AUX, NOUN?
ADJ, NOUN?
DET, NOUN?
NUM, NOUN?
NOUN, NOUN?
CONJ, NOUN?
ADP, ADJ?
ADV.00 10.1 1.20.2 1.30.3 1.40.4 20.5Parameters (upper=?
; bottom=?
)2030405060UAS(%) Depth bound ?Length bias ?Figure 8: UAS for various settings on (UD) WSJ.Hyperparameters Selecting hyperparameters inmultilingual grammar induction is difficult; someworks tune values for each language based on thedevelopment set (Smith and Eisner, 2006; Bisk etal., 2015), but this violates the assumption of unsu-pervised learning.
We instead follow many works(Marec?ek and Z?abokrtsky?, 2012; Naseem et al,2010) and select the values with the English data.For this, we use the WSJ data, which we obtain inUD style from the Stanford CoreNLP (ver.
3.6.0).96 ExperimentsWSJ Figure 8 shows the result on WSJ.
Both DEPand LEN have one parameter: the maximum depth?, and ?
(Eq.
5), and the figure shows the sensitivityon them.
Note that x-axis = 0 represents FUNC.For LEN, we can see the optimal parameter ?
is0.1, and degrades the performance when increasingthe value; i.e., the small bias is the best.
For DEP, wefind the best setting is 1.3, i.e., allowing embeddedconstituents of length 3 or less (?
= 3 in Eq.
4).
Wecan see that allowing depth 2 degrades the perfor-mance, indicating that depth 2 allows too many treesand does not reduce the search space effectively.10Multilingual results Table 1 shows the main mul-tilingual results.
When we see ?No root constraint?block, we notice that our DEP boosts the perfor-mance in many languages (e.g., Bulgarian, French,9Note that the English data in UD is Web Treebank (Silveiraet al, 2014), not the standard WSJ Penn treebank.10We see the same effects when training with longer sen-tences (e.g., length ?
20).
This is probably because a looserconstraint does nothing for shorter sentences.
In other words,the model can restrict the search space only for longer sen-tences, which are relatively small in the data.39No root constraint + root constraintFUNC DEP LEN HARM FUNC DEP LEN HARM N10A-Greek 35.9 31.6 34.7 37.8 37.9 45.0 34.4 37.7 40.1Arabic 48.6 38.7 49.8 42.8 45.9 44.3 49.6 31.4 37.8Basque 41.7 46.1 45.0 24.9 42.5 44.8 44.8 25.3 50.1Bulgarian 45.6 69.0 64.8 66.4 69.1 71.1 61.9 68.0 58.6Croatian 40.8 32.2 50.7 47.8 40.7 42.2 47.6 47.7 41.0Czech 56.0 62.0 52.7 53.7 47.2 62.2 56.0 52.2 52.0Danish 42.5 42.7 42.3 47.2 42.6 42.8 42.3 46.6 42.8Dutch 25.7 26.6 28.0 26.2 25.7 27.5 28.7 26.4 40.6English 37.2 39.8 52.1 37.5 37.5 40.0 38.4 38.2 51.4Estonian 68.5 67.4 68.0 68.6 68.0 67.8 65.1 68.5 67.3Finnish 26.2 24.5 27.9 25.7 25.7 27.3 27.9 20.5 44.6French 36.7 48.0 36.8 36.5 36.5 54.6 36.3 36.7 53.3German 44.6 48.0 46.3 43.6 43.9 50.4 47.9 43.9 53.5Hebrew 58.4 54.4 58.5 59.1 55.4 59.7 59.4 59.0 56.9Hindi 54.7 52.6 16.0 55.8 55.8 52.6 48.8 55.7 55.8Indonesian 36.0 52.9 45.6 40.1 30.4 53.1 40.5 40.0 51.1Italian 63.8 67.8 68.4 65.0 63.1 65.7 68.8 62.9 56.3Japanese 46.8 44.5 73.8 47.9 47.6 46.7 72.3 47.9 51.3Latin-ITT 42.3 43.8 42.1 41.0 42.4 43.7 38.4 41.6 38.4Norwegian 44.7 45.3 45.1 51.9 44.8 45.4 45.2 45.7 55.4Persian 44.9 39.0 37.3 36.6 44.1 46.6 37.2 43.6 55.2Portuguese 48.4 61.1 61.6 55.9 49.2 61.1 61.4 44.6 47.1Slovenian 65.6 61.0 50.1 62.7 65.1 60.7 49.4 63.6 53.1Spanish 52.2 54.6 62.5 49.1 44.4 53.8 60.0 48.4 55.3Swedish 42.7 48.1 51.4 48.1 43.1 42.8 42.7 47.6 46.7Avg 46.0 48.1 48.5 46.9 45.9 50.1 48.2 45.8 50.2Table 1: Attachment scores on UD with or withoutroot POS constraints.
A-Greek = Ancient Greek.N10 = Naseem et al (2010) with modified rules.Indonesian, and Portuguese), though LEN performsequally well and in average, LEN performs slightlybetter.
Harmonic initialization does not work well.We then move on to the settings with the con-straint on root tags.
Interestingly, in these settingsDEP performs the best.
The model competes withNaseem et al?s system in average, and outperformsit in many languages, e.g., Bulgarian, Czech, etc.LEN, on the other hand, decreases the average score.Analysis Why does DEP perform well in particu-lar with the restriction on root candidates?
To shedlight on this, we inspected the output parses of En-glish with no root constraints, and found that thetypes of errors are very different across constraints.Figure 9 shows a typical example of the differ-ence.
One difference between trees is in the con-structions of phrase ?On ... pictures?.
LEN pre-dicts that ?On the next two?
comprises a constituent,which modifies ?pictures?
while DEP predicts that?the ... pictures?
comprises a constituent, which iscorrect, although the head of the determiner is in-correctly predicted.
On the other hand, LEN workswell to find more primitive dependency arcs betweenPOS tags, such as arcs from verbs to nouns, whichare often incorrectly recognized by DEP.These observations may partially answer theOn the next two pictures he took ...ADP DET ADJ NUM NOUN PRON VERB ...DEPLENFigure 9: A comparison of output parses by DEPand LEN (with no root constraints).
Dashed arcs aremisclassified ones.Prec.
Recall F1FUNC (English) 11.6 18.4 14.1DEP (English) 22.4 37.1 27.9LEN (English) 21.6 31.0 25.5FUNC (Avg.)
22.5 30.0 25.6DEP (Avg.)
27.8 34.5 30.5LEN (Avg.)
24.0 33.7 27.9FUNC + ROOT (Avg.)
22.0 29.4 25.0DEP + ROOT (Avg.)
28.1 35.2 31.0LEN + ROOT (Avg.)
21.8 31.2 25.6Table 2: Unlabeled bracket scores in various set-tings.
Avg.
is the average score across languages.question above.
The main source of improvementsby DEP is detections of constituents, but this con-straint itself does not help to resolve some coredependency relationships, e.g., arcs from verbs tonouns.
The constraint on root POS tags is thus or-thogonal to this approach, and it may help to findsuch core dependencies.
On the other hand, the de-pendency length bias is the most effective to findbasic dependency relationships between POS tagswhile the resulting tree may involve implausibleconstituents.
Thus the effect of the length bias seemssomewhat overlapped with the root POS constraints,which may be the reason why they do not well col-laborate with each other.Bracket scores We verify the above intuitionquantitatively.
To this end, we convert both the pre-dicted and gold dependency trees into the unlabeledbracket structures, and then compare them on thestandard PARSEVAL metrics.
This bracket tree isnot binarized; for example, we extract (X a b (Xc d)) from the tree axbycyd.
Table 2 shows theresults, and we can see that DEP always performsthe best, showing that DEP leads to the models thatfind better constituent structures.
Of particular note40UAS F1DEP 48.1 30.5LEN 48.5 27.9DEP+LEN 49.2 27.0Table 3: Average scores of DEP, LEN, and the com-bination.is in Enlgish the bracket and dependency scores areonly loosely correlated.
In Table 1, UASs for FUNC,DEP, and LEN are 37.2, 39.8, and 52.1, respectively,though F1 of DEP is substantially higher.
This sug-gests that DEP often finds more linguistically plausi-ble structures even when the improvement in UAS ismodest.
We conjecture that this performance changebetween constraints essentially arise due to the na-ture of DEP, which eliminates center-embedding,i.e., implausible constituent structures, rather thandependency arcs.Combining DEP and LEN These results suggestDEP and LEN capture different aspects of syntax.
Tofuruther understand this difference, we now evaluatethe models with both constraints.
Table 3 shows theaverage scores across languages (without root con-straints).
Interestingly, the combination (DEP+LEN)performs the best in UAS while the worst in bracketF1.
This indicates the ability of DEP to find goodconstituent boundaries is diminished by combiningLEN.
We feel the results are expected observing thatcenter-embedded constructions are a special case oflonger dependency constructions.
In other words,LEN is a stronger constraint than DEP in that thestructures penalized by DEP are only a subset ofstructures penalized by LEN.
Thus when LEN andDEP are combined LEN overwhelms, and the ad-vantage of DEP is weakened.
This also suggests notpenalizing all longer dependencies is important forlearning accurate grammars.
The improvement ofUAS suggests there are also collaborative effects insome aspect.7 ConclusionWe have shown that a syntactic constraint that elim-inates center-embedding is helpful in dependencygrammar induction.
In particular, we found thatour method facilitates to find linguistically correctconstituent structures, and given an additional cueon dependency, the models compete with the sys-tem relying on a significant amount of prior lin-guistic knowledge.
Future work includes applyingour DEP constraint into other PCFG-based gram-mar induction tasks beyond dependency grammars.In particular, it would be fruitful to apply our ideainto constituent structure induction for which, toour knowledge, there has been no successful PCFG-based learning algorithm.
As discussed in de Mar-cken (1999) one reason for the failures of previouswork is the lack of necessary syntactic biases, andour approach could be useful to alleviate this issue.Finally, though we have focused on unsupervisedlearning for simplicity, we believe our syntactic biasalso leads to better learning in more practical scenar-ios, e.g., weakly supervised learning (Garrette et al,2015).AcknowledgementsWe would like to thank John Pate for the help inpreliminary work, as well as Taylor Berg-Kirkpatricfor sharing his code.
We are also grateful to EdsonMiyamoto and Makoto Kanazawa for the valuablefeedbacks.
The first author was supported by JSPSKAKENHI Gran-in-Aid for JSPS Fellows (GrantNumbers 15J07986), and MOU Grant in NationalInstitute of Informatics.ReferencesTaylor Berg-Kirkpatrick, Alexandre Bouchard-Co?te?,John DeNero, and Dan Klein.
2010.
Painless unsu-pervised learning with features.
In Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the Association for Com-putational Linguistics, pages 582?590, Los Angeles,California, June.
Association for Computational Lin-guistics.Yonatan Bisk and Julia Hockenmaier.
2013.
An hdpmodel for inducing combinatory categorial grammars.Transactions of the Association for ComputationalLinguistics, 1:75?88.Yonatan Bisk, Christos Christodoulopoulos, and JuliaHockenmaier.
2015.
Labeled grammar induction withminimal supervision.
In Proceedings of the 53rd An-nual Meeting of the Association for ComputationalLinguistics and the 7th International Joint Conferenceon Natural Language Processing (Volume 2: Short Pa-pers), pages 870?876, Beijing,China, July.C.
de Marcken.
1999.
On the unsupervised inductionof phrase-structure grammars.
In Susan Armstrong,41Kenneth Church, Pierre Isabelle, Sandra Manzi, Eve-lyne Tzoukermann, and David Yarowsky, editors, Nat-ural Language Processing Using Very Large Corpora,volume 11 of Text, Speech and Language Technology,pages 191?208.
Springer Netherlands.Jason Eisner and Giorgio Satta.
1999.
Efficient pars-ing for bilexical context-free grammars and head au-tomaton grammars.
In Proceedings of the 37th An-nual Meeting of the Association for ComputationalLinguistics on Computational Linguistics, ACL ?99,pages 457?464, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Jason Eisner.
2000.
Bilexical Grammars and TheirCubic-Time Parsing Algorithms.
In Harry Bunt andAnton Nijholt, editors, Advances in Probabilistic andOther Parsing Technologies, pages 29?62.
KluwerAcademic Publishers, October.Richard Futrell, Kyle Mahowald, and Edward Gibson.2015.
Large-scale evidence of dependency lengthminimization in 37 languages.
Proceedings of the Na-tional Academy of Sciences, 112(33):10336?10341.Dan Garrette, Chris Dyer, Jason Baldridge, and NoahSmith.
2015.
Weakly-supervised grammar-informedbayesian ccg parser learning.E.
Gibson.
2000.
The dependency locality theory: Adistance-based theory of linguistic complexity.
In Im-age, language, brain: Papers from the first mind artic-ulation project symposium, pages 95?126.Daniel Gildea and David Temperley.
2010.
Do gram-mars minimize dependency length?
Cognitive Sci-ence, 34(2):286?310.Kevin Gimpel and Noah A. Smith.
2012.
Concavityand initialization for unsupervised dependency pars-ing.
In Proceedings of the 2012 Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 577?581, Montre?al, Canada, June.
Asso-ciation for Computational Linguistics.Joseph H. Greenberg.
1963.
Some universals of gram-mar with particular reference to the order of meaning-ful elements.
In Joseph H. Greenberg, editor, Univer-sals of Human Language, pages 73?113.
MIT Press,Cambridge, Mass.John A Hawkins.
2014.
Cross-linguistic variatoin andefficiency.
Oxford University Press, jan.William P. Headden III, Mark Johnson, and David Mc-Closky.
2009.
Improving unsupervised dependencyparsing with richer contexts and smoothing.
In Pro-ceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages101?109, Boulder, Colorado, June.
Association forComputational Linguistics.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProceedings of NODALIDA 2007, Tartu, Estonia, May.Mark Johnson.
1998.
Finite-state approximation ofconstraint-based grammars using left-corner grammartransforms.
In Christian Boitet and Pete Whitelock,editors, COLING-ACL, pages 619?623.
Morgan Kauf-mann Publishers / ACL.Mark Johnson.
2007.
Transforming projective bilexicaldependency grammars into efficiently-parsable cfgswith unfold-fold.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 168?175, Prague, Czech Republic, June.Association for Computational Linguistics.Fred Karlsson.
2007.
Constraints on multiple center-embedding of clauses.
Journal of Linguistics,43(2):365?392.Dan Klein and Christopher Manning.
2004.
Corpus-based induction of syntactic structure: Models of de-pendency and constituency.
In Proceedings of the42nd Meeting of the Association for ComputationalLinguistics (ACL?04), Main Volume, pages 478?485,Barcelona, Spain, July.David Marec?ek and Zdene?k Z?abokrtsky?.
2012.
Ex-ploiting reducibility in unsupervised dependency pars-ing.
In Proceedings of the 2012 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning,pages 297?307, Jeju Island, Korea, July.
Associationfor Computational Linguistics.George A. Miller and Noam Chomsky.
1963.
Finitarymodels of language users.
In D. Luce, editor, Hand-book of Mathematical Psychology, pages 2?419.
JohnWiley & Sons.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowl-edge to guide grammar induction.
In Proceedings ofthe 2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 1234?1244, Cambridge,MA, October.
Association for Computational Linguis-tics.Hiroshi Noji and Yusuke Miyao.
2014.
Left-cornertransitions on dependency parsing.
In Proceedings ofCOLING 2014, the 25th International Conference onComputational Linguistics: Technical Papers, pages2140?2150, Dublin, Ireland, August.
Dublin City Uni-versity and Association for Computational Linguistics.Hiroshi Noji.
2016.
Left-corner Methods for Syntac-tic Modeling with Universal Structural Constraints.Ph.D.
thesis, Graduate University for Advanced Stud-ies, Tokyo, Japan, March.Philip Resnik.
1992.
Left-corner parsing and psycholog-ical plausibility.
In COLING, pages 191?197.42D.J.
Rosenkrantz and P.M. Lewis.
1970.
Deterministicleft corner parsing.
In Switching and Automata The-ory, 1970., IEEE Conference Record of 11th AnnualSymposium on, pages 139?152, Oct.William Schuler, Samir AbdelRahman, Tim Miller, andLane Schwartz.
2010.
Broad-coverage parsing usinghuman-like memory constraints.
Computational Lin-guistics, 36(1):1?30.Roy Schwartz, Omri Abend, Roi Reichart, and Ari Rap-poport.
2011.
Neutralizing linguistically problem-atic annotations in unsupervised dependency parsingevaluation.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies, pages 663?672, Port-land, Oregon, USA, June.
Association for Computa-tional Linguistics.Natalia Silveira, Timothy Dozat, Marie-Catherinede Marneffe, Samuel Bowman, Miriam Connor, JohnBauer, and Christopher D. Manning.
2014.
A goldstandard dependency corpus for English.
In Proceed-ings of the Ninth International Conference on Lan-guage Resources and Evaluation (LREC-2014).Noah A. Smith and Jason Eisner.
2006.
Annealingstructural bias in multilingual weighted grammar in-duction.
In Proceedings of the International Confer-ence on Computational Linguistics and the Associ-ation for Computational Linguistics (COLING-ACL),pages 569?576, Sydney, July.Noah A. Smith.
2006.
Novel Estimation Methods forUnsupervised Discovery of Latent Structure in Natu-ral Language Text.
Ph.D. thesis, Johns Hopkins Uni-versity, Baltimore, MD, October.Marten van Schijndel and William Schuler.
2013.
Ananalysis of frequency- and memory-based processingcosts.
In Proceedings of the 2013 Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 95?105, Atlanta, Georgia, June.
Associa-tion for Computational Linguistics.43
