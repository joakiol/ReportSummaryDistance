Parsing Spoken Language'a Semantic Caseframe ApproachPhilip J. Hayes, Alexander G. Hauptmann, Jaime G. Carbonell, and Masaru TomitaComputer Science DepartmentCarnegie-Mellon UniversityPittsburgh, PA 15213, USAAbstractParsing spoken input introduces serious problems not present inparsing typed natural language.
In particular, indeterminacies andinaccuracies of acoustic recognition must be handled in an integralmanner.
Many techniques for parsing typed natural anguage do notadapt Well to these extra demands.
This paper describes anextension of semantic caseframe parsing to restricted-domainspoken input.
The semantic caseframe grammar representation isthe same as that used for earlier work on robust parsing of typedinput.
Due to the uncertainty inherent in speech recognition, thecaseframe grammar is applied in a quite different way, emphasizingisland growing from caseframe headers.
This radical change inapplication is possible due to the high degree of abstraction in thecaseframe representation.
The approach presented was testedsuccessfully in a preliminary implementation.1.
The Need for Parsing in SpeechUnderstandingFor a computer to understand and respond to a wide range ofspoken natural language, it is not sufficient merely to recognizewhich words were spoken.
As in the ea,se of typed natural languageinput, it is necessary to determine the meaning of the input utterancetaken as a whole.
The field of natural language processinrj isdevoted to ?
!etermining the meanings of word sequences typed into acomputer.
It seems, therefore, natural to apply the techniquesalready developed in processing typed language to (tetermining themeaning of spoken input.Urffortunately, it is not possible to apply techniques for parsingtyped natural language to spoken input in a straightforward manner,We list some problems below.
We assume the existence of a speechrecognizer that transforms a spoken input into a word lattice - -  a setof hypothesized words thnt may be present, to,ether with theirstarting and ending times and the prob~,bility of each word beingcorrect.
In general, there will be several competing word hypothesesfor each point in the input signal.
This assumption is somewhatsimplistic in that it does not provide any way for a parser to influencethe lower levels of speech processing.
However, the separationassumption helps to illustrate the following problems in adaptingparsing techniques for typed input to spoken input:~, lexical ambiguity: Mere than one word may be produced bythe speech recognizer fur a given segment of speech.
If theambiguities were simply between different word choices, thiscould be handled by the natural language processingtechniques used for word sense ~.mbiguity (e.g.
"b:.mk" may bea place to put money, the side of ~ river, an action of placingtrust, tilting a vehicle sideways, etc.).
However, not only canmultiple words be hypothesized, but the competing hypothesescan occur at overlapping, adjoining, or separate segments ofthe input signal, without a consistent set of word boundaries.There is no parallel phenomenon for typed natural anguage.e probabi l i ty measures: Speech processing systems typicallyprovide a relative likelihood of the correctness of each wordhypothesis.
These probabilities or scores are based on criteriasuch as the quality of the match between speech signal andphonemic dictionary expectations.
Since a t~peeeh recognitionsystem may hypothesize many words for the same segment ofspeech, and since these word scores may differ considerably,they are important in limiting the s.earch.
However, there is nonatural' way to make use of such likelihood scores in mostnatural language processing techniques,,, unrecognized words: Because of hurried prenunciati0n orco-articulation effects, a speech recognizer may completely failto recognize some words in an utterance.
"rhe missed words areusually (though not always) short, unstressed, "function" wordsrather than longer "content" words, This emission is notI;andled by standard natural language processing lechniques.However, new techniques for processing typed, butgrammatically imperfect, input may be adaptable to this purposesince they are also designed 1o deal with missing words.umj~ammatical input: In addition to the word omissions fromimpeHect word hypothesization, spoken inpu~ tends to containmore real gramrnatical deficiencies than typed input, Oncespoken, words c~rrnot be easily retracted, bul tyl)ed utterancescan be conectod if the user notices the error in time.
Thus,fail-soft techniques for recovery from grammatical errors innt~tur~J Io.nguage proces.
('ing are particulc, rly pertinent whenextended to the interpretatien of spoken input.The.~e difficulties argue against the sirnplistic appro~tch .ofatta(:hing a 8poe(.h.recognition module to a traditional naturallanpu~.t~je analyzer designed fer words ent~:red as unan~biguousAS;.II characters.
No matter hew good e,';teh may be in isolation, thetwo will not inlegrate successfully if the I.
'-~.tter cannot providesemar~tie xpectations to the former, cannot handle ma.ssive lexiealarnL',ifrrity, or cannot tolerate errors of recognition and grammaticaldevk~don.
Moreover, with adequate integration, i'eedback from ana~u~'.l language analysis component can substantially improve theperfcnn::u~ce of a COllnected speech recognizer.
This performanceellh\[incemoi"lt is b~J(\]ly needed since no preseht connected speechrecognition method comes close to human abiiil:ies.
And evenhLii~lt'.'.!
:; of'fen fail t<) rGcegnize function words e?lracted from theirsurro~tndit\]g conte?t.
The applic~tion of linguistic knowledge andsemantic expectat!ohs through natural language ~,.nalysis techniquesis thus necded to cen~plement ~cousti?
recognition methods bycon:4r;~ining the set cf possible (anp!
.3#!
)sib!e) hdct pletadon,'; of thewords in an input utterance.2.
Problems with Network-based Parsing ofSpoken InputThe case for substantial integration of natural anguage processingwith speech recognition is clear, The issue is how to adapt naturallanguage parsing techniques to cope with the special problems ofspoken input as described above, Most such adaptation efforts untilnew have been based on transition network parsing.
Essentially,they encode the expectations of the parser in a transition networkwhose arcs are labelled by syntactic or semantic categories of wordsor constituents.
An input is analyzed by finding a path through thenetwork the4 corresponds to the sequence of words in the input.587Constituent labels on arcs are associated with their ownsubnetworks, and traversing the arc in the top-level network isaccomplished by traversing the corresponding subnetwork.Typically, transition net parsers operate by traversing the networkfrom left to right in step with the input, exploring subnetworks in atop.down manner as they go.
Well known examples of transition-netparsers include ATN \[14\] parsers (as used in the LUNAR system\[15\]), the RUS parser\[I\], and the parser used in LIFER \[8\].
TheHARPY system \[9\] used an integrated network encoding for linguisticand acoustic information.A major problem with transitionmet parsers for speech recognitionlies in the difficulty they have in handling input that does not meettheir grammatical expectations.
Frequently a word may be missingdue to acoustic misrecognition or actual omission.
If a network isbeing explored left to right, finding the correct path through thenetwork would then involve skipping over the arc that correspondedte the rnissing word.
If simple skipping were all that was involved, theproblem might well be tractable, but the problem is compounded by'the typical n'rilt\]pHcity of possible parses, especk, l!y if the word latticecontains many alternative words for the same speech segment.
Themethod tlsed to detect a non-viable parse in tile search is inability tofollow any arc from the current node --.
precisely the situation mostlikely with a missing word, Thus, network parses can no Ioqger cisethe standard halting criteria for non.productive (constraint violating)searches.
A furi.her compounding of the pi'oblem arises if the wordafter the missing word allows a spurious arc to be followed from thenetwork node at which the missing word should have beenrecognized.
In this case, it will generally he very hard to find outwhere the errer really occurred.
Other forms of ungrammaticatity,either actually spoken or mia-recoonition artifacts, result in similarproblems.
\]he absence of consistent word boundalies from theacoustic analysis I~hase complicates things further.Various methods have been tried to adapt network parsing to theseproblems, including on-demand insertion of extra arcs (e.g.
\[13, 12\]).Perhaps the most promising modification for speech input is thereplacement of left-to-right tracing techniques by center-outtechniques that work from words with high certainty according to theacoustic component \[16\].
However, semantic importance has neverbeen combined with acoustic certainty in selecting these islands.Island growing, attractive in theory, presents serious practicalproblems for ATN parsers, not the least of which is the requirementof running ATNs from right to left.
This method of interpreting thenetworks, necessary with center-out teehr4ques, fails when testsdepend on registers that have not yet been set, No modifications tonetwork-based techniques have been totally successful.3.
Semantic Caseframe ParsingOur approach is quite different from the transition networkapproach and is derived from recent work at Carnegie-MellonUniversity by Carbonell, Hayes, and others \[3, 7, 6, 2\] onunderstanding typed, restricted domain natural language, with aparticular concentration on handling ill-formed input.
The techniquethat makes it possible to process sensible but potentially imperfect orincomplete uttere.nces is called semantic caseframe instantiation.Unlike network-based techniques, caseframe methods er~able aparser to anchor its interpretation on the most significant input parts,and to grow its islands of interpretation to the less significantsegments.
Since the more significant words tend to be longer andtherefore more likely to be recognized reliably, the islands ofsignificance are correlated with islands of certainty.
In the process,semantic and syntactic expectations generated from the moremeaningful parts of the input can be used to discriminate aridhypothesize the meaning o\[ troublesome segments.The essential difference between caseframe and transition networktechniques is the level of encoding of the syntactic and semanticinformation they both use.
Caseframe techniques encode theinformation at a more abstract level and thus are able to interpret it inmultiple ways.
Network techniques "compile" the information intonetwmks at a much lower an d more rigid level, and thus do not havenearly as niuch fleedom in iriterpreting the same knowledge inmultiple ways, As we will show, the ability to apply syntactic andsemantic information in an interpietive way is the key to thesuccessful integration 0!
speech and naturaI language processing.The central notion behind a caseframe is that of a head conceptmodified by a set of related concepts or cases, bearing well-definedsemantic relations to the head concept.
The original linguisticconcept of a caseframe as first described by Fillmore \[4\], relied on asmall set of universally applicable cases.
The recent work at CMUadapts this idea to restricted domain situations by allowingspecialized cases for each concept related to a head concept.Consider, for instance, the caseframe shown in Figure 1.#S ( EDName ForwardActionType verbSemanticCases (#s(scName Agent ;~.he senderInstanceOf (MailAdrOesc)SyntaxCase (Subject))#s(scName MsgObj ;a messageInstanceOf" (MsgOb..iDe sc)SyntaxCase (D i rec tOb ject ) )#S(SCName MsgReci pien t.Obj ; the rece iverInstanceOf (Mai lAdrDesc)S~/ntaxCase ( Ind i rec t :Ob ject  PrepO)CaseMarker ( to ) )#S(SCName CCRecipientObj ;the CarbonCopyInstanceOF (Mai lAdrDesc) ; rece iverSyntaxCase (PrepO)CaseMarker (cc ing copy ing) ) )RequiredSC (MsgObj NsgRecipienl;Obj Agent))IteadForms ( forward resend))Figure1: Caseframefor forwardFigure 1 defines the forward action of an electronic mail system.The notation is that of the casefrLtme speech pa.is~'r described later.Without going into notational dmtails, the caseframe is identified as averb or clausal caseframe corresponding to the verbs (HeadForms)"forward" or "resend".
It also has four cases: Agent (the persondoing the sending), MsgObj (the message being forwarded),MsgRecipientObj (the person the message is beMg forwarded to),and CCRecipientObj (the people who get a copy of the forwardedmessage).
The MsgObj case must be filled (hlstanceOf) by aMsgObjDesc (defined by another caseframe, see below), and theother cases must be filled by a MailAchDesc (the caseframerepresenting a peison or "mail address").
All the cases are required,except CCRecipientObj, which is optional.
In addition, to this pLIrelysemantic information, the casefr~me contains sorne ,",yutu.cUcinformation: the Agent case is \[mt~d\[ested as ~l~e .
';yntactic subject;MsgObj as the direct object; MsgRecipientObj as either the indirectobject or as the object (PrepO) of a prepositional phrase, whosepreposition (CaseMarker) is "to"; CCRecipientObj as a prepositional588phrase with "prepositions" either ccing or copying.#S(EOName NsgObjDescType NounSemant;i :Cases (#s(scName Descr ip torsPat tern  (new recent  o ld  unexamined examined)Synl;axCase (prenomtna l ) )#s(scName DeterminersPat tern  ( the  th i s  that  any a every}SynbaxCase (prenominal))#s(sc?
Name MsgOr ig inObj  ; where the mai lIns tanceOf  (Ma i lAdr l )esc )  ; came fromCaseNarker  ( f rom)Synt.axCase (PrepO))#s(scName TimeObjIns tanceOt  ( l lour l )esc Nonthl)esc OayDesc)Casei'4arker ( f rom before  a f t .or  s ince  on a t )SyntaxCase (P repO) ) )HeadForms (message n la i \ ] ) )Figu re 2: Caseirame for messageIn addition t,_) actions, we also use caseframes to describe objectsFigure 2 shows a nominal caseframe for the message object of ourelectronic mall system.
This has the same fern\] as the verbcaseframe, except that its HeadForms correspond to the head nounsof a noun phrase describing an electronic mail message.
In addition,the Descriptors case has a new SyntaxCase, prenominal, whichimplies that the elements of Pattern (new, re;-ent, etc.)
may appear inthe adjective position in this caseframe.With a suitable caseframe for MailAdrPesc and knowledge of whatthings like clause, noun phrase, direct object, adjective position, etc.mean, the above caseframes clearly contain enough information toproduce analyses of sentences like:Forward to Jones at CMUA the messages from Smith.Did Brown resend any new me.ssage,.~ to Oreen at BI3N?What mail did Jones forward to ,?mith?Brown is forwarding the re, cent mes@oges to Green,l~he central question is how to combine the information in thecaseframe definitions with syntactic knowledge and thus analyze thesentences into a set of caseframe instances.The approach taken in earlier caseframe work at CMU has been toembed the syntactic knowledge in the parser code and let the parserinterpret he caseframes using that knowledge.
E.g.
the algorithms in\[3\] use semantic caseframes and focus on prepositions ascasemarkers as well as the order of subject, verb, indirect object anddirect object for parsing.
Unfortunately, prepositions tend to be smallfunction words that are often poorly enunciated and recognized.Therefore we have adopted the same general approach for ourspeech parsing work, but modified the parsing algorithms.
The samecaseframes are used, but with a somewhat different interpretationprocess.The ability to apply multiple recognition methods is a centraladvantage of caseframe parsing.
Since the restricted-domainlanguage description embodied in the caseframes is at such a highlevel of abstraction, we are free to interpret it in a way appropriate tothe particular situation.
The caseframes tell us whet componen.ts tolook for and constrains where we can look for them.
But exactlyhow we look for them is adaptable so that it can be driven by themost reliable information we have.4.
Applying casel'rames to speech iqputWe can summarize the previous two sections as follows:~, caseframes of the kind we have described contain the rightamount of information at the right level of abslraction to parserestricL~d-domain spoken input;,,the algorithms that have been developed for using suchcaseframes in parsing typed natural language input areunsuiiable for spoken input because the algorithms rely on thepresence of small function words that are recognized at bestunreliably by word hypothesizers.The trial implementation o\[ our approach applies caseframes to theinput, but does it in a novel way by:1. examin!ng the lattice of words !typothesized by the speechrecognizer for these that correspond to caseframe headers"2. combining all the case.frames correzponding to the words foundin all semantically and syntactically plausible ways3.
for each caseframe eornbinatien thus formed, attempting toaccount for the gaps between the cqseframe header words thatwere involved in its formation by parsing words from the gapsagainst empty semantic and syntac\[.ic roles in the caselramecembinatiorl4.
selecting as the final parse those c~seframe instances that bestaccount for the tel)at, based on hew much input they cover andthe acoustic scores of the words in that parse.This multi-stage approach avoids the problems of the caseframeparsing algorithms for typed input by anchoring the parse oncaseframe headers.
Caseframe headers are verbs (for clausalcaseframes} and nouns (for nominal caseframes).
These are contentbearing words that tend to be stressed in speech and are often multi-syllabic.
This improves their chances of recognition above that ofshort, unstressed function werds.
The anchor points are thuscorrelated to the most acoustically certain words.The idea of forming one or more parses at a skeleton level andinstantiating the one (or ones) that satisfy all constraints down to thelexical level is akin to the ABSTRIPS \[10\] and NOAH \[t 1\] plannersthat first established a general plan and later worked in all tile detailcalled for in the situation.
That way, the parser does not waste timein.
hypothesizing local details that cannot possibly fit into a globalparse.An additional advantage associated with working from caseframeheaders is that tile resulting caseframe combinations form a ready.made semantic interpretation of the input.
The interpretation istypically incomplete until it is filled out in the subsequent gap-fillingstage.
However, if the recognition of some or all of the rernainingwords is so poor that the semantic interpretation is never fullycompleted; then the parser still has something to report.
Dependingon the application domain, a skeleton interpretation could besufficient for the application, or would at least form the basis of aIocussed t~eguest for confirmation or clarification to the user \[5\].In the remainder of this section, we examine irJ more detail ourcurrent implemental.ion of,.the approach outlined above, starting firstwith a description of the word lattice that drives our casefl'am(.
'-basedparser for spoken input.
This parser operates in the context of" acomplete speech understanding system Hint handles sp~akerindependent continuous speech with a 200 word vocabulary in anelectronic mail domain.5894.1.
The word latticeTile input to our caseframe speech parser can be viewed as a two-dimensional attice of words.
Each word has a begin time, an endtime, and a likelihood score.
The begin/end times slate where theword was detected in the utterance.
The score indicates hew certes.inwe are that the word is correct, based on acoustic-phoneticinformation.
In the sample lattice below, the I~erizontal din~eP.sion istime, and the vertical dimension corresponds to certainly ofrecognition of individual words by the speech recognizer (F;neratingthe lattice.
This word lattice was consbucted by har=d fordemonstration purposes.Ttme in mi l l i secondsO 500 1000 1500 2000. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.  )
,HI RECEIVEDLOFigure 3:USERSFORWARDPRINTMESSAGE,RECIPIFNTSTHETOATLINEPRINTEBSMITHCOPYINGA simplified word lattice containing different kindsof words.
Header words are underlined4.2.
Header combinationTo start its processing, the parser selects from the word lattice allheader words above a recognition likelihood threshold.
Theseheaders correspond to caseframes, but only some combinations ofthe hypothesized caseframes are possible in the domain.
Tocalculate the legal caseframe combinations, a set of phrase structurerules were derived that apply at the frame level (rather than at themore detailcd word level).To make matters more concrete, let us refer to the sample latticeabove.
In this lattice, the underlined header words would becombined to form the nuclei of sentences like: "Forward messageSmith CMUA" and "Print message lineprinter."
Caseframes cancombine in this way if one is of the right type (as defined by theInstanceOf attribute for the case) to fill a case of another.
Whencombining caseframes associated with header words, the parser alsouses knowledge about word order to limit the possible combinations.In our example, the forward caseframe (as defined in Figure 1) has aslot for a MsgObjDesc as a DirectObject.
Tile order restrictions builtinto the parser only allow for the direct object after the verb.
Themessage caseframe (Figure 2) fulfills these requirements.
It is aMsgObjDesc, whose HeadForm "message" occurs after the forwardcaseframe HeadForm "forward" in the lattice.
Thus the two can becombined, ~s long as the constraint of the required MsgRecipientObjcan be satisfied (by "Smith").Each time a valid sequence of headers is found, it is given anoverall likelihood score and merged with the previous ones.
At theend of the header combination phase, we have a list of orderedpartial phrases, containing all the legal sequences of header wordsthat can be found in the word lattice.
Each partial phrase isrepresented as a set of nested caseframe instances.
For instance,three combinations would be formed from the header words:Forward message Smith CMUAand these would have the nesting structure:\[ForwardActionHeadForm FORWARDMsgObj \[MsgObjDescHeadForm MESSAGE\]MsgRecipientObj \[MaiIAdrOescHeadForm SMITHllost \[LocationDescHeadForm CMUA\]\]\]\[ForwardAct ionHeadForm FORWARDMsgObj \[MsgObjDescHeadForm MESSAGE\]CCRecipientOb.j \ [Mai lAdrDBscHeadForm S,M I TItHost \[Locat.
i  onDescHeadEorm CMUA\]\]\]\ [ForwardAct iontleadForn~ FORWARDMsgObj \[MsgObjDescHeadForm MESSAGEMsgOriginObj\ [Ma i lAdrgescHeadForm SMITltItost \ [Locat ionDescHeadForm CMUA\]\]\]\]where square brackets indicate c.~seframo instances and tile r~estingis convoyed by textual inclusion,A routine,t() check word iunctures is used (:luring the headercombination phase.
Whenever two header words are combined for ap~rtial phrase, tile juncture between these words is chocked toascertain whether they overlap (indicating an illegal combination),abut, or have a gap between them (indicating .,significant interveningspeech events).
This check also enables the p~;r'ser to deal efficientlywith co-articuI~ted phonemes as in "some messages".
Thesepho~lemes are merged in pronunciation, resulting in a pair ofow:rlapping but valid word candidates.
These word juncture checkscomprise a tap-down feedback mechanism to improve the speechrecognition.4.3.
Casemarker connectionOnce caseframe combinations have been formed, the next step isto fill in the gaps between the words of the corresponding partialphrase.
We take each combination in turn, starting with the one withmaximal-likelihood.
The caseframe speech parser first tries to fill Incasemarkers, which are usually prepositions.Let us continue our example with the first header combinationformed from the phrase "Forward message Smith CMUA".
For thisphrase, casemarkers may appear before the prepositionally markedcases "Smith" and "CMUA'.
The requirement that the casemarkersmust appear between the header words of the containing andcontained caseframes is a strong constraint on the possible locationsof.the casemarkers.
Thet:e are generally strong limitations on whatwords could possibly serve as markers for these cases.
In ourexample, using the caseframe definitions of the previous section, theparser would thus try to verify one of the words "to", "from ", "ccing"or "copying" between "message" and "Smith" and one of the words"on" or "at" between "Smith" and "CMUA ".Whenever a set of words are predicted by the parser in a givensegment, a word verification module is called.
This module hasknowl#dge of the complete word lattice.
A word that matches theprediction is sought from the lattice in the specified gap.
In addition,590the acoustic-phonetic data is consulted to give an indication whether~e word is a perfect fit for the gap, a left or right anchored fit, or ifthere are intervening significant speech events on the left or right.This information allows the parser to determine how much input hasbeen accounted for by a given partial phrase hypothesis.Every successfully verified casemarker causes the parser to spaCvnanother partial phrase hypothesis.
The word could be a spuriouslyhypothesized word, i.e.
one that was "recognized" even though itwas never spoken (also known as a false alarm).
Therefore we leavethe old partial phrase without the casemarker in the ordered list ofpartial phrases and merge a new partial phrase into the list.
The newpartial phrase is a copy of the old one, with the casemarker also filledin.
A new likelihood score is computed for this phrase.The score for a partial phrase is currently computed as the sum ofthe time normalized probabilities of each word divided by the time ofthe total utterance.
Thus the probability of each word is multiplied bythe duration of the word, summed over all words and divided by theduration of the utterance.
This favors longer partial phrases overshorter ones.
However, even extremely low scoring long phrasecandidates are favored over well scoring shorter phrases.
We arecurrently al';o exploring other alternative scoring procedures for4.3.
Casemarker  connectionOnce caseframe combinations have been formed, the next step isto fill in the gaps between the words of the corresponding partialphrase.
We take each combination in turn, starting with the one withmaximal-likelihood.
The caseframe speech parser first tries to fill incasemarker,% which are usually prepositions.Let LIS continue our example with the first header combinationformed from the phrase "Forward message Snffth CMUA'.
For thisphrase, cas~;markers may appear before the prepositionally markedcases "Smith" and "CMUA'.
The requirement hat the casemarkersmust appear between the header words of the containing andcontained caseframes is a strong constraint on the possible locationsof.
the casemarkers.
rhet:e are generally strong limitations on whatwords could possibly serve as markers for these cases.
In ourexample, using the caseframe definitions of the previous section, theparser would thus try to verify one of the words "to', "from", "ccing"or "copying" between "message" and "Smith" and one of the words"on" or "at" between "Smith" and "CMUA ".Whenever a set of words are predicted by the parser in a givensegment, a word verification module is called.
This module hasknowledgc-' of the complete word lattice.
A word that matches theprediction is sought from the lattice in the specified gPp.
In r-~dditlon,the acoustic-phoneiic data is consulted to give an indication whetherthe word is a perfect fit for the gap, a left or right anchored fit, or ifthere are intervening significant speech events on the left or right.This information allows the parser to determine how much input hasbeen accounted for by a given patti,t1 phrase hypothesis.Every succ~:ssfully w~rified casemarker causes the parser to spawnanother partial phrase Ilypothesis.
1he word could be a spuriouslyhypothesized word, i.o.
one that was "recognized" even though itwas never spoken (also known as a false alarrn).
Therefore we leavethe old partial phrase without the cus(.~marker in tile ordered list ofparti&l phr~tses and merge a new p~,.t tial phr.t,..se into the list.
The newpartial i)hrase is a copy of the old one, will\] the cas,:.marker also filledin.
A new likelihood score it computed for this phrase.The score for a partial phrase is cunently computed as the ann ofthe time normalized probabilities or each word d!vided by the time ofthe total utterance.
Th~s the probability of each word is multiplied bythe dHt alien of tt~o word, summed over all words and divided by theduration of the utter~.'.nce.
This favors longer pmtial phrases eversi~oHt.,r enos.
However, even exhenlely low scoring long phrasec~tHdi:!al,~?S are favored over w~ll :~ccring shelh'~r phrases.
We areeurr,?ntty also ~:~xFl,),ing other aht:!lDativ9 SCOIJll(J ptocedLtres forpartial phrases.
These methods will recognize the tradeoff betweenlong, low scoring utterances that seem to account for all the inputand short phrase hypotheses with excellent scores that leave gaps inthe utterance unaccounted for.
An ideal scoring function would alsouse semantic and syntactic wellformedness as criteria.Sometimes, none of the case markers being verified are found.This may moan that:+ the speech recognizer failed to detect the marker.
Unvoicedco-articulated monosyllabic words (such as prepositions) oftengo undetected;+ or, the most-likely parse at the case-header level was indeedincorrect, and a lower likelihood parse should be explored tosee if it is more consistent with the acoustic data.At present only the second choice is considered, but we are.exploring the possibility of an enhanced verifier to re-invoke thelower level processes (acoustic analysis or word hypothesizermodules) with shong expectalions (one or two words) at aprespecified window in the input.
We llope that such a process candetect words missed in a more cursory general scan --- and thus usesen\]antic and syntactic expectations to drive the recognition of themost difficult segraents of the input.
If the verifier were \[o return witha recognized case rnarl-~er, but too low u hkelihood, the overalllikelihood value o\[ the next parse couM rnal,~e it the preferr(~d one.4.4, Pronominal  fi l l ingThe next phase fills it\] the prenornirml sections of the partiali;,hrasos, The parser looks for prcnominals in the following order:Predeterminer DeterminP.r Ordinal Cardinal Adjective *A lexicon associates each potential prenominal word with the correcttype.
Thus we first look for all possible predeterminers to.g, 'all')within the available gal) before the corresponding header word,Again the succe.
':',sful verification of s,lch ~ prediction spqwns a newpartial phrase, just as described for casemarker& the  old partialphrase relnains ill the list as a precaution against false al,'u'nls.
Itshould be notcd that remaining old phrases ac~;ounting for les::~ inputreceive a lower global likelihood value because unaccounted forinput is penalized,Then deiernliners are examined.
In our exanlple, the determiner"th,.
:" will succu:s~,\[ully be foHnd to modify the nI,P, SS~i,~O ca:~,~\[rLulle,The other prenumirml types are lilted it\] the same way.
Post.nominalmodifiers (i.e., pruposJtiolial phr4ses) ~re parsed by the ca.
';eframeinstantiation inclhod above, as nominal an,I sunteadal caselrames~.,.re treated in mucit lhe same w!G.4,5.
Extending coverage to simple questionsAlthough we have not made completeness of syntactic coverage afocus in this work (see next section), we made some simpleextensions to gain some idea of the difficulty in syntactic extension.In particular, we extended the system to deal with simpleinterrogatives as welt as imperatives and declaratives.
No changes tothe casehames themselves were necessary, just to the parsingalgorithm.
We introduced a separate stage in processing to look591exclusively for question words.
These words may be,'the standardwh-words (who, what, when, ...) or sentence-initial auxiliary verbs toindicate a yes/no question (do, does, is, will, ...).Tile word order rules in the header combination phase alsorequired extension.
These rules now have to allow fronted casesWhat messages did Smith sendand questions where the HeadForm of the case is collapsed into aquestion wordWho sent this message?
Finally, we added a new module to fill auxiliary verbs in the correctlocations.
It operates just like the casemarker connection moduleand will not be described further here.
By providing the parser withconstraints governing the agreement of subject/verb, of auxiliaryverb/main verb, and of pronominal/noun, the number of plausiblealternatives is kept low.5.
Summary and Future DirectionsWe have explored an approach to parsing restricted-domainspeech based on semantic caseframes.
The approach was showncapable of dealing with the uncertainties and ambiguities of speechand the common ungrammaticalities.
We argued thai a caseframeapproach was better suited to these problems than more traditional.network-based approaches.
This suitability was attributed to thehigh degree of abstraction with which caseframes represen't theirlinguistic information, and the corresponding flexibility ininterpretation this allows.
A simple implementation using thisapproach was described with a worked example.We envision continued development of cur system andenhancements to our approach in several directions:Our current approach relies too heavily on finding caseframeheader words.
While most are multi-syllable and easilyrecognizable at the acoustic level, many (e.g.
'send') are not.We are looking at ways to drive the recognition from the mostreliably recognized words, whether they correspond tocaseframe headers or not.?
* Most of tile syntactic knowledge used by our current system isembedded in the code.
While this makes for elficient and robustrecognition, it poses obvious problems for syntactic extensibilityand maintainability.
We are looking at ways of separating outthe syntactic knowledge, while retaining the power and flexibilityinherent in specifying a restricted-domain language throughcaseframes, rather than (say) rewrite rules.o The nature of the interpretation performgd by the presentsystem causes it to operate at large multiples of real.time.
Weare looking at methods of compiling the caseframe grammarinto more efficient recognition systems, with the eventual goal ofreal.time operation, while retaining our current flexibility androbustness.6.
AcknowledgementsThe authors wish to express their debt to all the other nlembers ofthe speech.n2.tural language project at CMU.
J. Siegei programmedlarge parts of the system with L. B~umeister ~nd H. Saito, R. Reddyand R. Stern coordinated the natural language and speech parts ofthe syslem.
A. Rudnicky and others provided the acoustic data~:.nalysis n the word-lattice form.This research was sponsored by Defense A(I,~d~ced f:~ose~rchProjects Agency Contract N00039-85-C-0163.
The views andconclusions contained in this document are those of tile o.uthors andshould not be interpreted as representing the ef!icial policies, eitherexpressed or implied, of the Defense Advanc.~d Research ProjectsAgency or the US Government.Re fer<~nces1.
Bobrow, R. J.
The RIJS System.
BBN Report 3878, Bolt, F\]eranek,and Newman, 1978.2.
Carbonell, J. G. and Itayes, P. J.
"Recovery Strategies forP~r~irl.q Extragramrna\[ical l.angu~.~9,:~".
Computation~-dLinguistics 10(1984).3.
C'~*rbonell, J. G. an(\] Hayes, P. J.
\[bynsmic Strategy Selection inFlexible Parsing.
Prec.
of 19th/mn,:al Meeting of ihe Assoc.
forComput.
Ling., Stanio,d iJoiw.-rni',y: ,h ule, 198 I, pp.
!43-147.4.
Fillmore, C. The C:~..;e for C,z::u. I. Universaf.~ :.,,'~ IingldstieTheory, Bach and I.Ltrms, Ed., HeR, !\[inoh~rt, \[~nd v~tinston, NewYork, 1968, pp.
1-90.5.
Hayes P. J.
A Construction Specific Approach to FocusedInteraction in Flexible Parsing.
Prec.
of 19th Annual Meeting of theAssoc.
for Conlput.
Ling., Stanford University, June, 1981, pp.149-152.6.
Hayes, P. J. Entity-Oriented Parsing.
COLING84, StanfordUniversity, July, 1984,7.
Hayes, P. J. and Carbonell, J. G. Multi-Strategy Construction.Specific Parsing for Flexible Data Base Query and Update.
Prec.Seventh Int.
Jt.
Conf.
on Artificial Intelligence, Univ.
of BritishColumbia, Vancouver, August, 1981, pp.
432-439.8.
Hendrix, G. G. Human Engineering for Applied Natural LanguageProcessing.
Prec.
Fifth Int.
Jt.
Conf.
on Artificial Intelligence, MIT,1977, pp.
183-191.9.
Lowerre, B.
The HARPY Speech Recognition System.
Compute~Science Department, Carnegie-Mellon University, April, 1976.10.
Sacerdoti, E. D. "Planning in a Hierarchy of AbstractionSpaces".
Artificial Intelligence 5, 2 (1974), 1 15-135.1 1.
Sacerdoti, E. D.. A Structure for Plans and Bel~avior.Amsterdam: North-Holland, 1977.12.
Weischedel, R, M. and Sondheimer, H. K. "Mete-Rules ~..s aBasis for Processing Ill-formed Input".
Computational Linguistics 10(1984).13.
Weischedel, R. M. and Black, J.
"Responding to Pot~ntiallyIJnparseabte Sentences".
American Journal of ComputationalLinguistics 6 (1980), 97-109.14.
Woods, W. A, "Transition l'letwerk Grammars for NaturalLanguage Analysis".
Comm.
ACM 13, 10 (Oct. 1970), 591-f~OO.15.
Woods, W. A., Kapian, R. M., and Nash-Webber, B.
The LunarSciences Language System: Final Report.
2378, Bolt, Beranek, andNewman, Inc., Cambridge, M~lss., 1972.16.
Woods, W. A., Bates, M., Brown, G., Bruce, B., Cook, C.,Klovstad, J., Makhoul, J., Nash-Webber, B., Schwartz, R., Wolf, J.,and Zue, V. Speech Understanding Systems - Final TechnicalReport.
3,138, Bolt, Beranek, e.ud Newnlan, Inc., Cambrid~-je, Mass.,1976.592
