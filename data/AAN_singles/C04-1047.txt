Using a Mixture of N-Best Lists from Multiple MT Systemsin Rank-Sum-Based Confidence Measure for MT Outputs ?Yasuhiro Akiba?,?, Eiichiro Sumita?, Hiromi Nakaiwa?,Seiichi Yamamoto?, and Hiroshi G.
Okuno??
ATR Spoken Language Translation Research Laboratories2-2-2 Hikaridai, Keihana Science City, Kyoto 619-0288, Japan?
Graduate School of Informatics, Kyoto UniversityYoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan{yasuhiro.akiba, eiichiro.sumita, hiromi.nakaiwa seiichi.yamamoto}@atr.jp, and okuno@i.kyoto-u.ac.jpAbstractThis paper addressees the problem of eliminat-ing unsatisfactory outputs from machine trans-lation (MT) systems.
The authors intend toeliminate unsatisfactory MT outputs by usingconfidence measures.
Confidence measures forMT outputs include the rank-sum-based confi-dence measure (RSCM) for statistical machinetranslation (SMT) systems.
RSCM can be ap-plied to non-SMT systems but does not alwayswork well on them.
This paper proposes analternative RSCM that adopts a mixture of theN-best lists from multiple MT systems insteadof a single-system?s N-best list in the exist-ing RSCM.
In most cases, the proposed RSCMproved to work better than the existing RSCMon two non-SMT systems and to work as wellas the existing RSCM on an SMT system.1 IntroductionThis paper addresses the challenging problem ofeliminating unsatisfactory outputs from machinetranslation (MT) systems, which are subsystems ofa speech-to-speech machine translation (S2SMT)system.
The permissible range of translation qualityby MT/S2SMT systems depends on the user.
Someusers permit only perfect translations, while otherusers permit even translations with flawed grammar.Unsatisfactory MT outputs are those whose transla-tion quality is worse than the level the user can per-mit.In this paper, the authors intend to eliminate un-satisfactory outputs by using confidence measuresfor MT outputs.
The confidence measures1 indicatehow perfect/satisfactory the MT outputs are.
In the?
This research was supported in part by the Ministry of PublicManagement, Home Affairs, Posts and Telecommunications,Japan.1These confidence measures are a kind of automatic evalu-ator such as mWER (Niessen et al, 2000) and BLEU (Papineniet al, 2001).
While mWER and BLEU cannot be used online,these confidence measures can.
This is because the former arebased on reference translations, while the latter is not.discipline of MT, confidence measures for MT out-puts have rarely been investigated.The few existing confidence measures includethe rank-sum-based confidence measure (RSCM)for statistical machine translation (SMT) systems,Crank in (Ueffing et al, 2003).
The basic ideaof this confidence measure is to roughly calculatethe word posterior probability by using ranks ofMT outputs in an N-best list from an SMT system.In the discipline of non-parametric statistical test,ranks of numerical values are commonly used in-stead of the numerical values themselves for statis-tical tests.
In the case of the existing RSCM, theranks of probabilities of MT outputs in the N-bestlist were used instead of the probabilities of the out-puts themselves.
The existing RSCM scores eachword in an MT output by summing the comple-mented ranks of candidates in the N-best list thatcontain the same word in a Levenshtein-aligned po-sition (Levenshtein, 1966).
When the confidencevalues of all words in the MT output are larger thana fixed threshold, the MT output is judged as cor-rect/perfect.
Otherwise, the output is judged as in-correct/imperfect.The existing RSCM does not always work well00.20.40.60.810 0.2 0.4 0.6 0.8 1Correctrejection rate: yCorrect acceptance rate: xPerformance of existing method (A|BCD)J2E SAT + Existing methodJ2E HPAT + Existing methodJ2E D3 + Existing methodFigure 1: Performance of the existing RSCM on threedifferent types of Japanese-to-English (J2E) MT sys-tems: D3, HPAT, and SAT.
The existing RSCM tried toaccept perfect MT outputs (grade A in Section 4) and toreject imperfect MT outputs (grades B, C, and D in Sec-tion 4).on types of MT systems other than SMT systems.Figure 1 shows the differences among the perfor-mances, indicated by the Receiver Operating Char-acteristics (ROC) curve (Section 4.1), of the exist-ing RSCM on each of three MT systems (Section4.2.1): D3, HPAT, and SAT (Doi and Sumita, 2003;Imamura et al, 2003; Watanabe et al, 2003).
OnlySAT is an SMT system; the others are not.
The idealROC curve is a square (0,1), (1,1), (1,0); thus, thecloser the curve is to a square, the better the perfor-mance of the RSCM is.
The performances of theexisting RSCM on the non-SMT systems, D3 andHPAT, are much worse than that on the SMT sys-tem, SAT.The performance of the existing RSCM dependson the goodness/density of MT outputs in the N-best list from the system.
However, the system?sN-best list does not always give a good approxi-mation of the total summation of the probabilityof all candidate translations given the source sen-tence/utterance.
The N-best list is expected to ap-proximate the total summation as closely as possi-ble.This paper proposes a method that eliminatesunsatisfactory top output by using an alternativeRSCM based on a mixture of N-best lists from mul-tiple MT systems (Figure 2).
The elimination sys-tem is intended to be used in the selector architec-ture, as in (Akiba et al, 2002).
The total transla-tion quality of the selector architecture proved to bebetter than the translation quality of each elementMT system.
The final output from the selection sys-tem is the best among the satisfactory top2 outputsfrom the elimination system.
In the case of Fig-ure 2, the selection system can receive zero to threetop MT outputs.
When the selection system receivefewer than two top MT outputs, the selection sys-tem merely passes a null output or the one top MToutput.The proposed RSCM differs from the existingRSCM in its N-best list.
The proposed RSCM re-2To distinguish the best output from the selection system,the MT output in the first place in each N-best list (e.g., N-bestlista in Figure 2 ) refers to the top MT output.The best outputElimination SystemSelection SystemSatisfactory top outputsMTa MTb MTcThe top outputa?The M-th best outputaInputM-best listaThe top outputb?The M-th best outputbM-best listbThe top outputc?The M-th best outputcM-best listcFigure 2: Image of our eliminatorceives an M-best list from each element MT sys-tem.
Next, it sorts the mixture of the MT outputs inall M-best lists in the order of the average product(Section 3.2) of the scores of a language model anda translation model (Akiba et al, 2002).
This sortedmixture is used instead of the system?s N-best list inthe existing RSCM.To experimentally evaluate the proposed RSCM,the authors applied the proposed RSCM and the ex-isting RSCM to a test set of the Basic Travel Ex-pression Corpus (Takezawa et al, 2002).
The pro-posed RSCM proved to work better than the exist-ing RSCM on the non-SMT systems and to work aswell as the existing RSCM on the SMT system.The next section outlines the existing RSCM.Section 3 proposes our RSCM.
Experimental resultsare shown and discussed in Section 4.
Finally, ourconclusions are presented in Section 5.2 The Existing RSCMThe existing confidence measures include the rank-sum-based confidence measure (RSCM) for SMTsystems (Ueffing et al, 2003).
The basic idea ofthis RSCM is to roughly calculate the word poste-rior probability by using ranks of MT outputs in theN-best list of an SMT system.
That is, the ranks ofprobabilities of MT outputs in the N-best list wereused instead of the probabilities of the outputs them-selves, as in the non-parametric statistical test.Hereafter, e?I1 and wIn1 denote the top output2and the n-th best output in the N-best list, respec-tively.
e?i denotes the i-th word in the top MT outpute?I1.
Li(e?I1, wIn1 ) denote the Levenshtein alignment3(Levenshtein, 1966) of e?i on the n-th best outputwIn1 according to the top output e?I1.
The existingRSCM of the word e?i is the sum of the ranks of MToutputs in an N-best list containing the word e?i in aposition that is aligned to i in the Levenshtein align-ment, which is normalized by the total rank sum:Crank(e?i) =?Nn=1(N ?
n) ?
?
(e?i, Li(e?I1, wIn1 ))N(N + 1)/2 ,where ?
(?, ?)
is the Kronecker function, that is, ifwords/morphemes x and y are the same, ?
(x, y) =1; otherwise, ?
(x, y) = 0.
Thus, only in the casewhere e?i and Li(e?I1, wIn1 ) are the same, the rank ofthe MT output wIn1 , N ?
n, is summed.
In thecalculation of Crank, N ?
n is summed instead ofthe rank n because ranks near the top of the N-bestlist contribute more to the score Crank.3This is the word on the n-th best output wIn1 , aligned withthe i-th word e?i, in the calculation of edit distance from the topMT output e?I1 to the n-th best output wIn1 .In this paper, the calculation of Crank is slightlymodified to sum N ?
n + 1 so that the total sum-mation is equal to N(N + 1)/2.
Moreover, whenthere are MT outputs that have the same score, suchMT outputs are assigned the average rank as in thediscipline of non-parametric statistical test.As shown in Section 1, the existing RSCM doesnot always work well on types of MT systems otherthan SMT systems.
This is because the system?sN-best list does not always give a good approxi-mation of the total summation of the probabilityof all candidate translations given the source sen-tence/utterance.
The N-best list is expected to ap-proximate the total summation as closely as possi-ble.3 Proposed MethodIn this section, the authors propose a method thateliminates unsatisfactory top output by using an al-ternative RSCM based on a mixture of N-best listsfrom multiple MT systems.
The judgment thatthe top output is satisfactory is based on the samethreshold comparison as the judgment that the topoutput is perfect, as mentioned in Section 1.
Theelimination system and the alternative RSCM areexplained in Sections 3.1 and 3.2, respectively.3.1 Elimination systemThis section proposes a method that eliminatesunsatisfactory top outputs by using an alternativeRSCM based on a mixture of N-best lists from mul-tiple MT systems (Figure 3).
This elimination sys-tem is intended to be used in the selector architec-ture (Figure 2).
The elimination system receivesan M-best list from each element MT system andoutputs only top2 outputs whose translation qualityis better than or as good as that which the user canpermit.
In the case of Figure 3, the number of MTsystems is three; thus, the elimination system canoutput zero to three top MT outputs, which dependson the number of the eliminated top outputs.MTa MTb MTcThe top outputa?The M-th best outputaInputSatisfactory top outputsM-best listaThe top outputb?The M-th best outputbM-best listbThe top outputc?The M-th best outputcM-best listc3M outputs sorted in the higher orderSorter based on SMT?s scoring systemChecker based on rank sumElimination SystemFigure 3: Proposed RSCMThe proposed elimination system judges whethera top output is satisfactory by using a thresholdcomparison, as in (Ueffing et al, 2003).
Whenthe confidence values of all words in the top out-put, which are calculated by using the alternativeRSCM explained in Section 3.2, are larger than afixed threshold, the top output is judged as satisfac-tory.
Otherwise, the top output is judged as unsatis-factory.
The threshold was optimized on a develop-ment corpus.3.2 The proposed RSCMThe proposed RSCM is an extension of the existingRSCM outlined in Section 2.
The proposed RSCMdiffers from the existing RSCM in the adopted N-best list (Figure 3).
The proposed RSCM receivesan M-best list from each element MT system.
Nextthe proposed RSCM sorts the mixture of all the MToutputs in the order of the average product of thescores of a language model and a translation model(Akiba et al, 2002).
This sorted mixture is alter-natively used instead of the system?s N-best list inthe existing RSCM.
That is, the proposed RSCMchecks whether it accepts/rejects each top MT out-put in the original M-best lists by using the sortedmixture; on the other hand, the existing RSCMchecks whether it accepts/rejects the top MT out-put in the system?s N-best list by using the system?sN-best.For scoring MT outputs, the proposed RSCMuses a score based on a translation model calledIBM4 (Brown et al, 1993) (TM-score) and a scorebased on a language model for the translation tar-get language (LM-score).
As Akiba et al (2002)reported, the products of TM-scores and LM-scoresare statistical variables.
Even in the case where thetranslation model (TM) and the language model forthe translation target language (LM) are trained ona sub-corpus of the same size, changing the trainingcorpus also changes the TM-score, the LM-score,and their product.
Each pair of TM-score and LM-score differently order the MT outputs.For robust scoring, the authors adopt the multi-ple scoring technique presented in (Akiba et al,2002).
The multiple scoring technique preparesC1 CkCk-fold Cross Validation?..TM1LM1 TMkLMk?..C0TM0LM0Parallel corpusFigure 4: Method for training multiple pairs of Lan-guage Models (LMs) and Translation Models (TMs)(Akiba et al, 2002).multiple subsets of the full parallel corpus accord-ing to k-fold cross validation (Mitchell, 1997) andtrains both TM and LM on each subset.
EachMT output is scored in k ways.
For example, thefull parallel corpus C is divided into three subsetsVi (i = 0, 1, 2).
For each i, the proposed methodtrains a translation model TMi on Ci (= C ?
Vi)and a language model LMi on the target-languagepart of Ci (Figure 4).
MT outputs in the mixture aresorted by using the average of the product scoresby TMi and LMi for each i.
In (Akiba et al, 2002),this multiple scoring technique was shown to selectthe best translation better than a single scoring tech-nique that uses TM and LM trained from a full cor-pus.4 Experimental ComparisonThe authors conducted an experimental compari-son between the proposed RSCM and the existingRSCM in the framework of the elimination system.The task of both RSCMs was to judge whether eachtop2 MT output from an MT system is satisfactory,that is, whether the translation quality of the top MToutput is better than or as good as that which theuser can permit.In this experiment, the translation quality of MToutputs was assigned one of four grades: A, B,C, or D as follows: (A) Perfect: no problems ineither information or grammar; (B) Fair: easy-to-understand, with either some unimportant informa-tion missing or flawed grammar; (C) Acceptable:broken, but understandable with effort; (D) Non-sense: important information has been translated in-correctly.
This evaluation standard was introducedby Sumita et al (1999) to evaluate S2SMT systems.In advance, each top MT output was evaluated bynine native speakers of the target language, whowere also familiar with the source language, andthen assigned the median grade of the nine grades.To conduct a fair comparison, the number of MToutputs in the system?s N-best list and the numberof MT outputs in the mixture are expected to bethe same.
Thus, the authors used either a three-best list from each of three MT systems or a five-best list from each of two non-SMT MT systemsfor the proposed RSCM and a ten-best list for theexisting RSCM.
Naturally, this setting4 is not disad-vantageous for the existing RSCM.4In the future, we will conduct a large-scale experiment toinvestigate how both RSCMs work while increasing the size ofthe system?s N-best list and the mixture of M-best lists.Table 1: Confusion matrixAccept Reject SubtotalSatisfactory Vs,a Vs,r Vs (= Vs,a + Vs,r)Unsatisfactory Vu,a Vu,r Vu (= Vu,a + Vu,r)4.1 Evaluation metricsThe performances of both RSCMs were evaluatedby using three different metrics: ROC Curve, H-mean, and Accuracy.
For each MT system, thesemetrics were separately calculated by using a con-fusion matrix (Table 1).
For example, for J2ED3 (Section 4.2.1), the proposed RSCM checkedeach top MT output from J2E D3 by using the inputmixture of three-best lists from the three J2E MTsystems (Section 4.2.1); on the other hand, the ex-isting RSCM checked each top MT output from J2ED3 by using the input ten-best list from J2E D3.
ForJ2E D3, the results were counted up into the con-fusion matrix of each RSCM, and the metrics werecalculated as follows:ROC Curve plots the correct acceptance rate ver-sus the correct rejection rate for different values ofthe threshold.
Correct acceptance rate (CAR) isdefined as the number of satisfactory outputs thathave been accepted, divided by the total number ofsatisfactory outputs, that is, Vs,a/Vs (Table 1).
Cor-rect rejection rate (CRR) is defined as the numberof unsatisfactory outputs that have been rejected, di-vided by the total number of unsatisfactory outputs,that is, Vu,r/Vu (Table 1).H-mean is defined as a harmonic mean5 ofthe CAR and the CRR (Table 1), 2 ?
CAR ?CRR/(CAR + CRR).Accuracy is defined as a weighted mean6 of theCAR and the CRR (Table 1), (Vs ?
CAR + Vu ?CRR)/(Vs + Vu) = (Vs,a + Vu,r)/(Vs + Vu).For each performance of H-mean and Accuracy,10-fold cross validation was conducted.
The thresh-old was fixed such that the performance was maxi-mized on each non-held-out subset, and the perfor-mance was calculated on the corresponding held-outsubset.
To statistically test the differences in per-formance (H-mean or Accuracy) between the confi-dence measures, the authors conducted a pairwise t-test (Mitchell, 1997), which was based on the resultsof 10-fold cross validation.
When the difference inperformance meets the following condition, the dif-ference is statistically different at a confidence level5This harmonic mean is used for summarizing two mea-sures, each of which has a trade-off relationship with eachother.
For example, F-measure is the harmonic mean of pre-cision and recall, which is well used in the discipline of Infor-mation Retrieval.6This weighted mean is used for evaluating classificationtasks in the discipline of Machine Learning.00.20.40.60.810 0.2 0.4 0.6 0.8 1Correctrejection rate: yCorrect acceptance rate: xJ2E-D3 (A|BCD)0.80.7y=xExisting methodProposed method (D3+HPAT+SAT)Proposed method (D3+HPAT)Existing method + reorderingContours by H-meanFigure 5: ROC Curves of bothRSCMs for J2E-D300.20.40.60.810 0.2 0.4 0.6 0.8 1Correctrejection rate: yCorrect acceptance rate: xJ2E-HPAT (A|BCD)0.80.7y=xExisting methodProposed method (D3+HPAT+SAT)Proposed method (D3+HPAT)Existing method + reorderingContours by H-meanFigure 6: ROC Curves of bothRSCMs for J2E-HPAT00.20.40.60.810 0.2 0.4 0.6 0.8 1Correctrejection rate: yCorrect acceptance rate: xJ2E-SAT (A|BCD)0.80.7y=xExisting methodProposed method (D3+HPAT+SAT)Contours by H-meanFigure 7: ROC Curves of bothRSCMs for J2E-SATTable 2: Performance of MT systems: Each numberin the AB row indicates the ratio of A-or-B-gradedtranslation by each MT system.
Each number in theother rows similarly indicates corresponding ratios.J2E MT systems E2J MT systemsD3 HPAT SAT D3 HPAT SATA 63.7 42.5 67.2 58.4 59.6 69.8AB 72.1 63.7 74.7 72.9 75.4 81.1ABC 78.8 79.0 82.5 83.3 86.8 88.0of 1-?%.|ppro ?
pext| > t(?,10?1) ?
S/?10,where ppro and pext, respectively, denote the aver-age performance of the proposed RSCM and the ex-isting RSCM, t(?,10?1) denotes the upper ?
point ofthe Student?s t-distribution with (10 ?
1) degrees offreedom, and S denotes the estimated standard de-viation of the average difference in performance.4.2 Experimental conditions4.2.1 MT systemsThree English-to-Japanese (E2J) MT systems andthree Japanese-to-English (J2E) MT systems of thethree types described below were used.
Table 2shows the performances of these MT systems.D3 (DP-match Driven transDucer) is anexample-based MT system using online-generated translation patterns (Doi and Sumita,2003).HPAT (Hierarchical Phrase Alignment basedTranslation) is a pattern-based system using au-tomatically generated syntactic transfer (Imamuraet al, 2003).SAT (Statistical ATR Translator) is an SMTsystem using a retrieved seed translation as thestart point for decoding/translation (Watanabe et al,2003).4.2.2 Test setThe test set used consists of five hundred and tenpairs of English and Japanese sentences, whichTable 3: Corpora for training TMs and LMs: BasicTravel Expression Corpus Nos.
1-3 (Takezawa et al,2002), Travel Reservation Corpus (Takezawa, 1999), andMT-Aided Dialogue Corpus No.
1 (Kikui et al, 2003).Japanese English# of sentences 449,357# of words 3,471,996 2,978,517Vocabulary size 43,812 28,217Ave.
sent.
length 7.7 6.6were randomly selected from the Basic Travel Ex-pression Corpus (BTEC) (Takezawa et al, 2002).BTEC contains a variety of expressions used in anumber of situations related to overseas travel.4.2.3 Training TMs and LMsThe corpora used for training TMs and LMs de-scribed in Section 3.2 were merged corpora (Table3).
The number of trained TMs/LMs was three.The translation models and language models werelearned by using GIZA++ (Och and Ney, 2000) andthe CMU-Cambridge Toolkit (Clarkson and Rosen-feld, 1997), respectively.4.3 Experimental results and discussion4.3.1 ROC CurveIn order to plot the ROC Curve, the authors con-ducted the same experiment as shown in Figure 1.That is, in the case where the grade of satisfactorytranslations is only grade A, each of the proposedand existing RSCMs tried to accept grade A MToutputs and to reject grade B, C, or D MT outputs.Figures 5 to 7 show the ROC Curves for each of thethree J2E MT systems (D3, HPAT, and SAT).The curves with diamond marks, cross marks,triangle marks, and circle marks show the ROCCurves for the existing RSCM, the proposed RSCMby using the mixture of three-best lists from D3,HPAT and SAT, the proposed RSCM by using themixture of five-best lists from D3 and HPAT, andthe existing RSCM with reordering, respectively.
Inthe existing RSCM with reordering, the system?sTable 4: Ten-fold cross-validated pairwise t-test of H-mean: Each set of three columns corresponds to the experimen-tal results of each of the three MT systems: D3, HPAT, and SAT.
Each floating number in the first to third column ofeach MT system indicates the average performance of the proposed RSCM, the average difference of the performanceof the proposed RSCM from that of the existing RSCM, and the t-value of the left-next difference, respectively.
Thebold floating numbers indicate that the left-next difference is significant at a confidence level of 95%.
The floatingnumbers on the three rows for each MT system, whose row heads are ?A | BCD?, ?AB | CD?, or ?ABC | D?, corre-spond to the three types of experiments in which each RSCM tried to accept/reject the MT output assigned one of thegrades left/right of ?|?, respectively.E2J-D3 E2J-HPAT E2J-SATSeparating point Ave. Diff.
T-val.
Ave. Diff.
T-val.
Ave. Diff.
T-val.A | BCD 76.2 15.7 4.424 73.2 14.1 5.099 65.5 0.3 0.108AB | CD 77.3 16.5 5.154 72.6 14.3 3.865 66.9 2.8e-5 0.002ABC | D 74.9 11.4 5.963 74.7 16.6 4.906 73.2 5.5 2.281J2E-D3 J2E-HPAT J2E-SATSeparating point Ave. Diff.
T-val.
Ave. Diff.
T-val.
Ave. Diff.
T-val.A | BCD 76.8 16.1 4.928 75.5 25.8 9.218 70.2 -3.3 1.618AB | CD 79.6 15.9 4.985 70.8 28.9 6.885 66.0 -5.9 2.545ABC | D 77.7 14.4 4.177 71.0 22.6 4.598 72.1 1.7 0.588Table 5: Ten-fold cross-validated pairwise t-test of Accuracy: The description of this figure is the same as that ofTable 4 except that Accuracy is used instead of H-mean.E2J-D3 E2J-HPAT E2J-SATSeparating point Ave. Diff.
T-val.
Ave. Diff.
T-val.
Ave. Diff.
T-val.A | BCD 77.4 10.5 4.354 71.1 15.4 5.667 76.4 1.1 1.000AB | CD 78.2 4.9 2.953 78.2 2.5 2.176 81.1 0.0 0.000ABC | D 85.0 1.3 1.172 84.1 -2.9 2.182 88.0 0.0 0.000J2E-D3 J2E-HPAT J2E-SATSeparating point Ave. Diff.
T-val.
Ave. Diff.
T-val.
Ave. Diff.
T-val.A | BCD 78.8 15.8 8.243 76.2 18.2 8.118 76.4 3.1 1.041AB | CD 77.8 4.1 3.279 72.7 8.8 3.288 77.6 -1.5 0.537ABC | D 83.3 2.9 1.771 77.4 -1.7 1.646 82.7 0.1 0.428original N-best list was sorted by using the aver-age of the product scores from the multiple scor-ing technique described in Section 3.2, and the ex-isting RSCM with reordering used this sorted sys-tem?s N-best instead of the system?s original N-best.The dotted lines indicate the contours by H-meanfrom 0.7 to 0.8.
The ideal ROC curve is a square(0, 1), (1, 1), (1, 0); thus, the closer the curve is to asquare, the better the performance of the RSCM is.In Figures 5 and 6, the curves of the proposedRSCM by using the mixture of three-best lists fromthe three MT systems are much closer to a squarethan that of the existing RSCM; moreover, thecurves of the proposed RSCM by using the mixtureof five-best lists from the two MT systems are muchcloser to a square than that of the existing RSCM.Note that the superiority of the proposed RSCM tothe existing RSCM is maintained even in the casewhere an M-best list from the SMT system was notused.
The curves of the existing RSCM with re-ordering are closer to a square than those of the ex-isting RSCM.
Thus the performance of the proposedRSCM on the non-SMT systems, D3 and HPAT, aremuch better than that of the existing RSCM.
Thedifference between the performance of the proposedand existing RSCMs is due to both resorting the MToutputs and using a mixture of N-best lists.In Figure 7, the curve of the proposed RSCM is alittle closer when CRR is larger than CAR; and thecurve of the existing RSCM is a little closer whenCAR is larger than CRR.
Thus, the performanceof the proposed RSCM on the SMT system, SAT,is a little better than that of the existing RSCM inthe case where CRR is regarded as important; sim-ilarly, the performance of the proposed RSCM onthe SMT system is a little worse than that of the ex-isting RSCM in the case where CAR is regarded asimportant.4.3.2 H-mean and AccuracyTables 4 and 5 show the experimental results of ten-fold cross-validated pairwise t-tests of the perfor-mance of H-mean and Accuracy, respectively.On the non-SMT systems, Table 4 shows that atevery level of translation quality that the user wouldpermit, the H-mean of the proposed RSCM is sig-nificantly better than that of the existing RSCM.
Onthe SMT MT system, Table 4 shows that at everypermitted level of translation quality, there is no sig-nificant difference between the H-mean of the pro-posed RSCM and that of the existing RSCM exceptfor two cases: ?ABC | D?
for E2J- SAT and ?AB |CD?
for J2E- SAT.Table 5 shows almost the same tendency as Table4.
As for difference, in the case where the transla-tion quality that the user would permit is better thanD, there is no significant difference between the Ac-curacy of the proposed RSCM and that of the exist-ing RSCM except in the one case of ?ABC | D?
forE2J-HPAT.As defined in Section 4.1, Accuracy is an eval-uation metric whose value is sensitive/inclined tothe ratio of the number of satisfactory translationsand unsatisfactory translations.
H-mean is an eval-uation metric whose value is independent/natural tothis ratio.
We need to use these different evaluationmetrics according to the situations encountered.
Forgeneral purposes, the natural evaluation metric, H-mean, is better.
In the case where the test set reflectsspecial situations encountered, Accuracy is useful.Regardless of whether we encounter any specialsituation, in most cases on a non-SMT system, theproposed RSCM proved to be significantly betterthan the existing RSCM.
In most cases on an SMTsystem, the proposed RSCM proved to be as goodin performance as the existing RSCM.This paper reports a case study in which a mixtureof N-best lists from multiple MT systems boostedthe performance of the RSCM for MT outputs.
Theauthors believe the proposed RSCM will work wellonly when each of the element MT systems comple-ments the others, but the authors leave the questionof the best combination of complementary MT sys-tems open for future study.5 ConclusionsThis paper addressed the problem of eliminating un-satisfactory outputs from MT systems.
It proposeda method that eliminates unsatisfactory outputs byusing an alternative RSCM based on a mixture ofN-best lists from multiple MT systems.
The au-thors compared the proposed and existing RSCMsin the framework of an elimination system.
Whenthe number of MT outputs both in the N-best list forthe existing RSCM and in the mixture of N-best listsfor the proposed RSCM is almost the same number,i.e.
ten, in most cases, the proposed RSCM provedto work better than the existing RSCM on two non-SMT systems and to work as well as the existingRSCM on an SMT system.In the future, the authors will conduct the follow-ing experiments: (1) investigating how the proposedRSCM works when the size of the M-best lists isincreased, and (2) seeing how the proposed RSCMinfluences the performance of the selection system.ReferencesYasuhiro Akiba, Taro Watanabe, and Eiichiro Sumita.
2002.Using language and translation models to select the bestamong outputs from multiple MT systems.
In Proc.COLING-2002, pages 8?14.Peter F. Brown, Stephen Della Pietra, Vincent J. Della Pietra,and Robert L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
ComputationalLinguistics, 19(2):263?311.Philip Clarkson and Ronald Rosenfeld.
1997.
Statistical lan-guage modeling using the CMU-Cambridge toolkit.
InProc.
EUROSPEECH-1997, pages 2707?2710.Takao Doi and Eiichiro Sumita.
2003.
Input sentence splittingand translating.
In Proc.
the HLT-NAACL 2003 Workshopon DDMT, pages 104?110.Kenji Imamura, Eiichiro Sumita, and Yuji Matsumoto.
2003.Feedback cleaning of machine translation rules using auto-matic evaluation.
In Proc.
ACL-2003, pages 447?454.Genichiro Kikui, Eiichiro Sumita, Toshiyuki Takezawa, andSeiichi Yamamoto.
2003.
Creating corpora for speech-to-speech translation.
In Proc.
EUROSPEECH-2003, vol-ume 1, pages 381?384.Vladimir I. Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions and reversals.
Soviet PhysicsDoklady, 10(8):707?710.Tom M. Mitchell.
1997.
Machine Learning.
The McGraw-HillCompanies Inc., New York, USA.Sonja Niessen, Franz J. Och, G. Leusch, and Hermann Ney.2000.
An evaluation tool for machine translation: Fast eval-uation for machine translation research.
In Proc.
LREC-2000, pages 39?45.Franz Josef Och and Hermann Ney.
2000.
Improved statisticalalignment models.
In Proc.
ACL-2000, pages 440?447.Kishore A. Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2001.
Bleu: a method for automatic evaluation of ma-chine translation.
In Technical Report RC22176 (W0109-022), IBM Research Division, Thomas J. Watson ResearchCenter, Yorktown Heights, NY, pages 257?258.Eiichiro Sumita, Setsuo Yamada, Kazuhiro Yamamoto,Michael Paul, Hideki Kashioka, Kai Ishikawa, and SatoshiShirai.
1999.
Solutions to problems inherent in spoken-language translation: The ATR-MATRIX approach.
InProc.
MT Summit VII, pages 229?235.Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sugaya, Hiro-fumi Yamamoto, and Seiichi Yamamoto.
2002.
Toward abroad-coverage bilingual corpus for speech translation oftravel conversations in the real world.
In Proc.
LREC-2002,pages 147?152.Toshiyuki Takezawa.
1999.
Building a bilingual travel conver-sation database for speech translation research.
In Proc.
theOriental COCOSDA Workshop-1999, pages 17?20.Nicola Ueffing, Klaus Macherey, and Hermann Ney.
2003.Confidence measures for statistical machine translation.
InProc.
MT Summit IX, pages 394?401.Taro Watanabe, Eiichiro Sumita, and Hiroshi G. Okuno.
2003.Chunk-based statistical translation.
In Proc.
MT Summit IX,pages 410?417.
