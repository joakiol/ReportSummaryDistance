Multilingual Noise-Robust Supervised Morphological Analysisusing the WordFrame ModelRichard WicentowskiSwarthmore CollegeSwarthmore, Pennsylvania, USA 19081richardw@cs.swarthmore.eduAbstractThis paper presents the WordFrame model, a noise-robust supervised algorithm capable of inducingmorphological analyses for languages which exhibitprefixation, suffixation, and internal vowel shifts.
Incombination with a na?ive approach to suffix-basedmorphology, this algorithm is shown to be remark-ably effective across a broad range of languages, in-cluding those exhibiting infixation and partial redu-plication.
Results are presented for over 30 lan-guages with a median accuracy of 97.5% on testsets including both regular and irregular verbal in-flections.
Because the proposed method trains ex-tremely well under conditions of high noise, it is anideal candidate for use in co-training with unsuper-vised algorithms.1 IntroductionThis paper presents the WordFrame model, a novelalgorithm capable of inducing morphological anal-yses for a large number of the world?s languages.The WordFrame model learns a set of string trans-ductions from inflection-root pairs and uses these totransform unseen inflections into their correspond-ing root forms.
These string transductions directlymodel prefixation, suffixation, associated point-of-affixation changes and stem-internal vowel shifts.Though not explicitly modeled, patterns extractedfrom large amounts of noisy training data can behighly effective at aligning inflections with roots inlanguages which exhibit vowel harmony, agglutina-tion, and partial word reduplication.The WordFrame model contains no language-specific parameters.
While we make no claims thatthe model works equally well for all languages, itsability to analyze inflections in 32 diverse languageswith a median accuracy of 97.5% attests to its flex-ibility in learning a wide range of morphologicalphenomena.The effectiveness of the model when trained fromnoisy data makes it well-suited for co-training withlow-accuracy unsupervised algorithms.2 Previous WorkThe development of the WordFrame model was mo-tivated by work originally presented in Yarowskyand Wicentowski (2000).
In that work, a suite ofunsupervised learning algorithms and a supervisedmorphological learner are co-trained to achieve highaccuracies for English and Spanish verb inflec-tions.
The supervised learner employed a na?
?veapproach to morphology, only capable of learningword-final stem changes between inflections androots.
This ?end-of-string model?
of morphologywas used again in Yarowsky et al (2001) where itwas applied to English, French and Czech.
(Morecomplete details of the end-of-string model are pre-sented in Section 3.3.1.
)Though simplistic, this end-of-string model is ro-bust to noise, especially important in co-trainingwith low-accuracy unsupervised learners.
However,the end-of-string model relied heavily upon exter-nally provided, noise-free lists of affixes in order tocorrectly align inflections to roots.
The WordFramemodel allows, but does not require, such affix lists,thereby eliminating direct human supervision.Much previous work has been done in automat-ically acquiring such affix lists, most recently thegenerative models built by Snover and Brent (2001)which are able to identify suffixes in English andPolish.
Schone and Jurafsky (2001) use latent se-mantic analysis to find prefixes, suffixes and cir-cumfixes in German, Dutch and English.
Ba-roni (2003) treats morphology as a data compres-sion problem to find English prefixes.Goldsmith (2001) uses minimum descriptionlength to successfully find paradigmatic classes ofsuffixes in a number of European languages, includ-ing Dutch and Russian, though the approach hasbeen less successful in handling prefixation.The Boas project (Oflazer et al, 2001), (Hakkani-Tu?r et al, 2000), and (Oflazer and Nirenburg, 1999)has produced excellent results bootstrapping a mor-phological analyzer, but rely on direct human su-pervision to produce two-level rules (Koskenniemi,Barcelona, July 2004Association for Computations LinguisticsACL Special Interest Group on Computational Phonology (SIGPHON)Proceedings of the Workshop of the1983) which are then compiled into a finite state ma-chine.3 The WordFrame Algorithm3.1 MotivationThe supervised morphological learner presentedin Yarowsky and Wicentowski (2000) modeledlemmatization as a word-final stem change plus asuffix taken from a (possibly empty) list of potentialsuffixes.
Though effective for suffixation, this end-of-string (EOS) based model can not model othermorphological phenomena, such as prefixation.By including a pre-specified list of prefixes, wecan extend the EOS model to handle simple prefix-ation: For each inflection, an analysis is performedon the original string, plus on each substring re-sulting from removing exactly one matching prefixtaken from the list of prefixes.
While effective forsome simple prefixal morphologies, this extensioncannot model word-initial stem changes at the pointof prefixation.
In contrast, the WordFrame (WF) al-gorithm can isolate a potential prefix and model anypotential point-of-prefixation stem changes directly,without pre-specified lists of prefixes.The EOS model also fails to capture word-internal vowel changes found in many languages.The WF model directly models stem-internal vowelchanges in order to to learn higher-quality, lesssparse, transformation rules.training pair EOS analysis WF analysisacuerto?acortar uerto?ortar ue?oapruebo?aprobar uebo?obar ue?omuestro?mostrar uestro?ostrar ue?oTable 1: The above Spanish examples are misana-lyzed by the EOS algorithm, which results in learn-ing rules with low productivity.
The WF algo-rithm is able to identify the productive ue?o stem-internal vowel change.3.2 Required and Optional Resourcesa.
Training data of the form <inflection,root> isrequired for the WordFrame algorithm.
Ideally,this data should be high-quality and noise-free,but algorithm is robust to noise, which allowsone to use lower-quality pairs extracted fromunsupervised techniques.b.
Pre-specified lists of prefixes and suffixes canbe incorporated, but are not required.c.
Precision can be improved (at the expense ofcoverage) by providing a list of potential rootsextracted from a dictionary or large corpus.d.
In order to allow for word-internal vowelchanges, the WordFrame model requires a listof the vowels of the language.3.3 Formal PresentationThe WordFrame model is constructed explicitly asan extension to the end-of-string model proposed byYarowsky and Wicentowski (2000); as such, we firstgive a brief presentation of the model, then intro-duce the WordFrame model.In the discussion below, if affix lists are not ex-plicitly provided, they are assumed to contain thesingle element  (the empty string).3.3.1 The end-of-string modelThe end-of-string model makes use of two optionalexternally provided sets: a set of acceptable suf-fixes, ?
?s, and a set of ?canonical root endings?, ?s.The inclusion of a list of canonical root endings ismotivated by languages where verb roots can end inonly a limited number of ways (e.g.
-er, -ir and -rein French).From inflection-root training pairs, a determinis-tic analysis is made by removing the longest match-ing suffix (?
?s ?
?
?s) from the inflection, removingthe longest matching canonical ending (?s ?
?s)from the root, and removing the longest commoninitial substring (?)
from both words.
The remain-ing strings represent the word-final stem change(?
?s ?
?s) necessary to transform the inflection(???s?
?s) into the root (??s?s).
The word-final stemchanges are stored in a hierarchically-smoothed suf-fix trie representing P (?
?s ?
?s|??
?s).A simple extension allows the EOS model tohandle purely concatenative prefixation: the analy-sis begins by removing the longest matching prefixtaken from a given set of prefixes (?
?p ?
?
?p), thencontinuing as above.
This changes the inflection to??p???s?
?s, and leaves the root as ??s?s.
(See Table 2for an overview of this notation.
)Given a previously unseen inflection, one findsthe root that maximizes P (??s?s|??p???s??s).
Bymaking strong independence assumptions and someapproximations, and assuming that all prefixes andsuffixes are equally likely, this is equivalent to:1P (??s?s|??p???s?
?s) = max??p,???s,?
?sP (?
?s ?
?s|??
?s)Note we are using a slightly different, but equiv-alent, notation to that used in Yarowsky and Wicen-towski (2000).
Simply, we use ?
?s rather than ?, andwe use ?
?s ?
?s rather than ?
?
?.
This changewas made in order to make the formalization of theWF model more clear.1Full details available in (Wicentowski, 2002).point-of- secondary primary point-of-prefixation common vowel common suffixation suffix/prefix change substring change substring change endingExtended inflection ?
?p ?s ?
?s ?
?sEOS root ?s ?sWordFrame inflection ?
?p ?
?p ?p ?
?v ?s ?
?s ?
?sroot ?p ?v ?s ?sTable 2: Overview of the analyzed components of the inflection and root using the end-of-string (EOS)model extended to allow for simple prefixation, and the WordFrame model.
If lists of prefixes, suffixes andendings are not specified, the prefix, suffix and ending are set to .3.3.2 The WordFrame modelThe WordFrame model fills two major gaps in theEOS model: the inability to model prefixation with-out a list of provided prefixes, and the inability tomodel stem-internal vowel shifts.While not required, the WordFrame model doesallow for the inclusion of lists of prefixes, and whenprovided, can automatically discover the point-of-prefixation stem change, ?
?p ?
?p.
When a listof prefixes is not provided, the word-initial stemchange will model both the prefix and stem change.Formally, this requires the inclusion of the point-of-prefixation stem change into the notation used inthe EOS model.
When presented with an inflection-root pair, the longest common substring in the in-flection and root, ?, is assumed to be the stem.
Thestring preceding the stem is the prefix and point-of-prefixation stem change, ??p?
?p; the string followingthe stem is the suffix and point-of-suffixation stemchange, ??s??s.
Combining these parts, the inflectioncan be represented as ??p??p???s?
?s, and the root as?p?
?s?s.In addition, the WordFrame model allows for asingle word-internal vowel change within the stem.To accommodate this, the longest common sub-string of the inflection and root, ?, is allowed to besplit in a single location to allow the vowel change?
?v ?
?v where ?
?v and ?v are taken from a prede-termined list of vowels for the language.2 The por-tions of the stem located before and after the vowelchange are now ?p and ?s, respectively.Both ?
?v and ?v may contain more than vowel,thereby allowing vowel changes such as ee?e.However, as presented here, the WF model does notallow for the insertion of vowels into the stem wherethere were no vowels previously; more formally,both ?
?v and ?v must contain at least one vowel, orthey both must be .
Though this restriction can2If one wishes to model arbitrary internal changes, this?vowel?
list could be made to include every letter in the al-phabet; results are not presented for this configuration.be removed, initial results (not presented here) in-dicated a significant drop in accuracy when entirevowels clusters could be removed or inserted.
Inaddition, the vowel change must be internal to thestem, and cannot be located at the boundary of thestem; formally, unless both ?
?v and ?v are , bothportions of the split stem (?p and ?s) must containat least one letter.
This prevents confusion between?stem-internal?
vowel changes and stem-changes atthe point of affixation.As with the EOS model, a deterministic analy-sis is made from inflection-root training pairs.
Ifprovided, the longest matching prefix and suffix areremoved from the inflection, and the longest match-ing canonical ending is removed from the root.3 Theremaining string must then be analyzed to find thelongest common substring with at most one vowelchange, which we call the WordFrame.The WordFrame (?p?
?v?s, ?p?v?s) is defined tobe the longest common substring with at most oneinternal vowel cluster (V ?
?
V ?)
transformation.Should there be multiple ?longest?
substrings, thesubstring closest to the start of the inflection is cho-sen.4 In practice, there is rarely more than one such?longest?
substring.The remaining strings at the start and end of thecommon substring form the point-of-prefixation andpoint-of-suffixation stem changes.The final representation of the inflection-root pairin the WF model is shown in Table 2.Given an unseen inflection, one finds the rootthat maximizes P (?p?p?v?s?s?s|??p?s??s??s).
If wemake the simplifying assumption that all prefixes,suffixes and endings are equally likely and remove3A canonical prefix is not included in the model because weknew of no language in which this occurred; introducing it tothe model would be straight-forward.4This places a bias in favor of end-of-string changes and ismotivated by the number of languages which are suffixal andthe relative few that are not; this could be adjusted for prefixallanguages.END-OF-STRING?
?p ?
?p ?
?p ?p ?
?v ?
?v ?s ?
?s ?
?s ?
?s ?
?sEnglish kept?keep ke p?ep t?
sang?sing s ang?ingSpanish acuerto?acortar ac uert?ort o?armuestro?mostrar m uestr?ostr o?arGerman gestunken?stinken gestunk?stink en?engefielt?gefallen gef iel?all t?enWORDFRAME?
?p ?
?p ?
?p ?p ?
?v ?
?v ?s ?
?s ?
?s ?
?s ?
?sEnglish kept?keep k e?ee p t?
sang?sing s a?i ngSpanish acuerto?acortar ac ue?o rt o?armuestro?mostrar m ue?o str o?arGerman gestunken?stinken ge?
 st u?i nk en?engefielt?gefallen gef ie?a l ?l t?enTable 3: End-of-string and WordFrame analysis of training data assuming no provided lists of prefixes.
TheEOS analysis yields non-productive rules such as gestunk?stink.
The WF analysis captures the productiveSpanish vowel change ue ?
o, the German prefix ge, and English vowel changes e?ee and a?i.the longest possible affixes deterministically, this isequivalent to:P (?p?p?v?s?s|??p?p??v?s?
?s)= P (?
?v ?
?v, ?
?p ?
?p, ?
?s ?
?s|??p?p??v?s?
?s)This can be expanded using the chain rule.
Asbefore, the point-of-suffixation probabilities areimplicitly conditioned on the applicability of thechange to ??p?p??v?s?
?s, and are taken from a suf-fix trie created during training.
The point-of-prefixation probabilities are implicitly conditionedon the applicability of the change to ??p?p?
?v?s, i.e.once ?
?s has been removed, and are taken from ananalogous prefix trie.
The vowel change probabilityis conditioned on the applicability of the change to?p??v?s.
In the current implementation, this is ap-proximated using the conditional probability of thevowel change P (?v|?
?v) without regard to the localcontext.
This is a major weakness in the current sys-tem and one that will be addressed in future work.The WordFrame model?s ability to capture stem-internal vowel changes allows for proper analysis ofthe Spanish examples from Table 1, and also allowsfor the analysis of prefixes without the use of a pre-specified list of prefixes, as shown in Table 3.4 Experimental EvaluationAll of the experimental results presented here weredone using 10-fold cross-validation on the trainingdata.
The majority of the training data used herepoint-of-prefixation change ge ?
point-of-suffixation change ?
lvowel changes u ?
iie ?
aTable 4: String transductions derived from the Ger-man examples listed in Table 3.was obtained from web sources, although some hasbeen hand-entered or scanned from printed materi-als then hand-corrected.
All of the data used wereinflected verbs; there was no derivational morphol-ogy in this evaluation.5 Unless otherwise specified,all results are system accuracies at 100% coverage ?Section 5.3 addresses precision at lower coverages.Space limits the number of results that can bepresented here since most of the evaluations havebeen carried out in each of the 32 languages.
There-fore, in comparing the models, results will only beshown for only a representative subset of the lan-guages.
When appropriate, a median or average forall languages will also be given.
Table 10 presentsthe final results for all languages.5Examples of derivational morphology, as well as nominaland adjectival inflectional morphology, are excluded from thispresentation due to the lack of available training data for morethan a small number of well-studied languages.4.1 End-of-string vs. WordFrameThe most striking difference in performance be-tween the EOS model and WordFrame model comesfrom the evaluation of languages with prefixal mor-phologies.
The EOS model cannot handle prefixa-tion without pre-specified lists of prefixes, so whenthese are omitted, the WF model drastically outper-forms the EOS model (Table 5).w/o Affixes w/ AffixesLanguage EOS WF EOS WFTagalog 1.6% 89.9% 92.0% 96.0%Swahili 2.9% 96.8% 93.8% 96.9%Irish 45.7% 89.5% - -Spanish 94.7% 90.2% 96.5% 95.2%Portuguese 97.4% 97.9% 97.3% 97.5%Table 5: Accuracy of the EOS model vs the WFmodel without and with pre-specified lists of affixes(if available for that language).Table 5 also shows that the simple EOS modelcan sometimes significantly outperform the WFmodel (e.g.
in Spanish).
Making things more dif-ficult, predicting which model will be more suc-cessful for a particular language and set of train-ing data may not be possible, as illustrated by thefact that EOS model performed better for Spanish,but the closely-related Portuguese was better han-dled by the WF model.
Additionally, as illustratedby the Portuguese example, it is not always benefi-cial to include lists of affixes, making selection ofthe model problematic.Lists of prefixes and suffixes were not avail-able for all languages.6 However, for the 25 lan-guages where such lists were available, the Word-Frame model performed equally or better on only 17(68%).
Evidence suggests that this occurs when theaffix lists have missing prefixes or suffixes.
Sincethese lists were extracted from printed grammars,such gaps were unavoidable.Regardless of whether or not affix lists were in-cluded, the WordFrame model only outperformedthe EOS model for just over half the languages.
Anexamination of the output of the WF model suggeststhat the relative parity in performance of the twomodels is due to the poor estimation of the vowelchange probability which is approximated withoutregard to the contextual clues.6The affix lists used in this evaluation were hand-enteredfrom grammar references and were only available for 25 of the32 languages evaluated here; therefore, the results presentedin this section omit these seven languages: Norwegian, Hindi,Sanskrit, Tamil, Russian, Irish, and Welsh.5 WordFrame + EOSOne of our goals in designing the WordFramemodel was to reduce or eliminate the dependenceon externally supplied affix lists.
However, the re-sults presented in Section 4.1 indicate that the WFmodel outperforms the EOS model for just over half(17/32) of the evaluated languages, even when affixlists are included.Predicting which model worked better for a par-ticular language proved difficult, so we created anew analyzer by combining our WordFrame modelwith the end-of-string model.
For each inflection,the root which received the highest probability us-ing an equally-weighted linear combination was se-lected as the final analysis.This new combination analyzer outperformedboth stand-alone models for 21 of the 25 languageswith significant overall accuracy improvements asshown in Table 6(a).w/o Affixes EOS WF Combined(a) Average 79.2% 91.0% 93.0%Median 93.6% 95.9% 97.4%w/ Affixes EOS WF Combined(b) Average 95.1% 95.0% 96.8%Median 96.7% 96.7% 97.6%Table 6: Average and median accuracy of the indi-vidual models vs. the combined model (a) with and(b) without affix lists.When affix lists are available, combining theWordFrame model and the end-of-string modelyielded very similar results: the combined modeloutperformed either model on its own for 23 of the25 languages.
Of the two remaining languages, thestand-alone WF model outperformed the combinedmodel by just one example out of 5197 in Danish,and just 4 examples out of 9497 in Tagalog.
Asbefore, the combined model showed significant ac-curacy increases over either stand-alone model, asshown in Table 6(b).Finally, we build the WordFrame+EOS classifier,by combining all four individual classifiers (EOSwith and without affix lists, and WF with and with-out affix lists) using a simple equally-weighted lin-ear combination.
This is motivated from our ini-tial observation that using affix lists does not alwaysimprove overall accuracy.
Cumulative results areshown below in Table 7, and results for each indi-vidual language is shown in Table 10.WF + EOS w/o Affixes w/ Affixes CombinedAverage 93.0% 96.8% 97.2%Median 97.4% 97.6% 97.9%Table 7: Accuracy of the combined models, plus acombination of the combined models in the 25 lan-guages for which affix lists were available.5.1 Robustness to NoiseThe WordFrame model was designed as an alter-native to the end-of-string model.
In Yarowskyand Wicentowski (2000), the end-of-string model istrained from inflection-root pairs acquired throughunsupervised methods.
None of those previouslypresented unsupervised models yielded high accura-cies on their own, so it was important that the end-of-string model was robust enough to learn stringtransduction rules even in the presence of largeamounts of noise.In order for the WF+EOS model to be an ade-quate replacement for the end-of-string model, itmust also be robust to noise.
To test this, we firstran the WF+EOS model as before on all of the datausing 10-fold cross-validation.
Then, we introducednoise by randomly assigning a certain percentage ofthe inflections to the roots of other inflections.
Forexample, the correct pair menaced-menace becamethe incorrect pair menaced-move.
The results of in-troducing this noise are presented in Table 9 andFigure 1.Noise 0% 10% 25% 50% 75%English 99.1% 98.6% 98.6% 98.4% 97.6%French 99.6% 99.5% 99.5% 99.3% 98.9%Estonian 96.8% 94.7% 94.3% 92.0% 87.0%Turkish 99.5% 98.5% 98.2% 97.1% 91.4%Table 9: The combined WordFrame and EOS modelmaintains high accuracy in the presence noise.Above, up to 75% of the inflections in the trainingdata have been assigned incorrect roots.As one might expect, the effect of introduc-ing noise is particularly pronounced for highly in-flected languages such as Estonian, as well as withthe vowel-harmony morphology found in Turkish7.However, languages with minimal inflection (En-glish) or a fairly regular inflection space (French)show much less pronounced drops in accuracy asnoise increases.7All of the data is inflectional verb morphology, making theTurkish task substantially easier than most other attempts atmodeling Turkish morphology.100%98%96%95%94%92%90%75%50%25%10%0%RelativeAccuracyPercent NoiseFrenchEnglishTurkishEstonianFigure 1: The WF+EOS algorithm?s robustness tonoise yields only a 5% reduction in performanceeven when 50% of the training samples are replacedwith noise.It is important to point out that the incorrect pairswere not added in addition to the correct pairs;rather, they replaced the correct pairs.
For exam-ple, the Estonian training data was comprised of5932 inflection-root pairs.
When testing at 50%noise, there were only 2966 correct training pairs,and 2966 incorrect pairs.
This means that real sizeof the training data was also reduced, further lower-ing accuracy, and making the model?s effective ro-bustness to noise more impressive.5.2 Regular vs. Irregular InflectionsFor 13 of the languages evaluated, the inflectionswere classified as either regular, irregular, or semi-regular.
As an example, the English pair jumped-jump was classified as regular, the pair hopped-hopwas semi-regular (because of the doubling of thefinal-p), and the pair threw-throw was labeled irreg-ular.8Table 8 shows the accuracy of the WF+EOSmodel in each of the three categories, as well asfor all data in total.9 As expected, the WF+EOSmodel performs very well on regular inflections andreasonably well on the semi-regular inflections formost languages.The performance on the irregular verbs, thoughclearly not as good as on the regular or semi-regular verbs, was surprisingly good, most notablyin French, and to a lesser extent, Spanish and Ital-8These classifications were assigned by the provider of ourtraining pairs, not by us.9The small discrepancy between the data in Table 8 and Ta-ble 10 is due to the fact that some of the inflection-root pairswere not labeled.
The ?All?
column of Table 8 reflects onlylabeled inflections.All Regular Semi IrregularLanguage accuracy types accuracy types accuracy types accuracy typesSpanish 97.28% 58589 97.60% 52709 95.38% 1665 93.40% 3861Catalan 90.65% 4066 96.31% 2898 84.35% 230 74.73% 938Occitan 93.39% 7583 98.46% 6096 97.55% 654 52.58% 795French 99.58% 63644 99.79% 57255 99.95% 2221 97.00% 3866Italian 98.43% 62920 98.75% 54643 99.58% 3335 93.64% 4496Romanian 97.84% 24000 98.95% 21237 94.78% 920 85.36% 1660English 98.95% 3703 99.45% 3073 99.50% 597 40.62% 32Danish 97.87% 4185 98.59% 3760 95.00% 220 87.80% 205Norwegian 95.85% 1954 97.57% 1731 90.62% 96 76.38% 127Icelandic 92.58% 3692 97.78% 2884 97.79% 226 64.78% 582Hindi 84.77% 256 98.58% 212 33.33% 9 14.29% 35Turkish 99.46% 29131 99.95% 26134 95.66% 2811 88.71% 186Welsh 88.55% 45812 89.27% 44060 86.69% 1180 32.84% 536Table 8: Accuracy of WF+EOS on different types of inflectionsian.
This is due in large part because our test set in-cluded many irregular verbs which shared the sameirregularity.
For example, in French, the inflection-root pair prit-prendre is irregular; however, the pairsapprit-apprendre and comprit-comprendre both fol-low the same irregular rule.
The inclusion of justone of these three pairs in the training data will al-low the WF+EOS model to correctly find the rootform of the other two.
Our French test set includedmany examples of this, including roots that ended-tenir, -venir, -mettre, and -duire.For most languages however, the performance onthe irregular set was not that good.
We proposeno new solutions to handling irregular verb forms,but suggest using non-string-based techniques, suchas those presented in (Yarowsky and Wicentowski,2000), (Baroni et al, 2002) and (Wicentowski,2002).5.3 Accuracy, Precision and CoverageAll of the previous results assumed that each inflec-tion must be aligned to exactly one root, though onecan improve precision by relaxing this constraint.The WF+EOS model transforms an inflection intoa new string which we can compare against a dic-tionary, wordlist, or large corpus.
In determiningthe final inflection-root alignment, we can down-weight, or even throw away, all proposed rootswhich are are not found in such a wordlist.
Whilethis will adversely affect coverage, precision maybe more important in early iterations of co-training.Given a sufficiently large wordlist, such a weight-ing scheme cannot discard correct analyses.
In ad-dition, a large majority of the incorrectly analyzedinflections are proposed roots which are not actuallywords.
By excluding all proposed roots which werenot found in a broad coverage wordlist (available for19 languages), median coverage fell to 97.4%, butmedian precision increased from 97.5% to 99.1%.6 ConclusionsWe have presented the WordFrame model, a noise-robust supervised morphological analyzer which ishighly successful across a broad range of languages.We have shown our model effective at learningmorphologies which exhibit prefixation, suffixation,and stem-internal vowel changes.
In addition, theWordFrame model was successful in handling theagglutination, infixation and partial reduplicationfound in languages such as Tagalog without explic-itly modeling these phenomena.
Most importantly,the WordFrame model is robust to large amountsof noise, making it an ideal candidate for use inco-training with lower-accuracy unsupervised algo-rithms.ReferencesM.
Baroni, J. Matiasek, and T. Harald.
2002.
Un-supervised discovery of morphologically relatedwords based on orthographic and semantic simi-larity.
In Proceedings of the Workshop on Mor-phological and Phonological Learning, pages48?57.M.
Baroni.
2003.
Distribution-driven morphemediscovery: A computational/experimental study.Yearbook of Morphology, pages 213?248.J.
Goldsmith.
2001.
Unsupervised learning of themorphology of a natural language.
Computa-tional Linguistics, 27(2):153?198.Wordlist Training DataLanguage Accuracy Entries Roots InflsSpanish 97.3% 32895 1190 57224Portuguese 97.9% 30145 584 22135Catalan 90.7% - 103 4058Occitan 93.4% - 180 7559French 99.6% 27548 1829 63559Italian 98.5% 27221 1582 62658Romanian 97.9% 25228 1070 24877Latin 91.4% - 279 26818English 99.1% 264075 1218 4915Danish 97.9% 51351 1062 5197Norwegian 95.9% - 547 2489Swedish 98.5% 46009 4035 13871Icelandic 92.6% - 314 3987Hindi 84.8% - 15 255Sanskrit 89.5% - 867 1968Tamil 91.0% - 24 602Estonian 96.9% 344 147 5932Finnish 97.5% - 1434 79734Turkish 99.5% 25497 87 29130Uzbek 99.5% - 434 27296Basque 96.1% 33020 1185 5842Czech 98.7% 29066 5715 23786Polish 97.6% 42005 601 23725Russian 90.8% 42740 191 3068Greek 100% 35245 9 201German 98.0% 45779 1213 14120Dutch 98.4% 41962 1016 5768Irish 95.5% - 54 1376Welsh 88.6% - 1053 44295Tagalog 97.5% - 212 9479Swahili 97.0% 24985 818 27773Klingon 100% 2114 699 5135Table 10: For each language, the accuracy of theWordFrame model combined with the end-of-stringmodel, the number of wordlist entries available(Section 5.3), and the total training size used forcross-validation.D.
Hakkani-Tu?r, K. Oflazer, and G. Tu?r.
2000.
Sta-tistical morphological disambiguation for agglu-tinative languages.
In 18th International Confer-ence on Computational Linguistics.K.
Koskenniemi.
1983.
Two-level morphology: AGeneral Computational Model for Word-FormRecognition and Production.
Ph.D. thesis, De-partment of Linguistics, University of Helsinki,Finland.K.
Oflazer and S. Nirenburg.
1999.
Practical boot-strapping of morphological analyzers.
In Confer-ence on Natural Language Learning.K.
Oflazer, S. Nirenberg, and M. McShane.
2001.Bootstrapping morphological analyzers by com-bining human elicitation and maching learning.Computational Linguistics, 27(1):59?84.P.
Schone and D. Jurafsky.
2001.
Knowledge-freeinduction of inflectional morphologies.
In Pro-ceedings of the North American Chapter of theAssociation of Computational Linguistics.M.
Snover and M. R. Brent.
2001.
A bayesianmodel for morpheme and paradigm identifica-tion.
In Proceedings of the Annual Meeting of theAssociation of Computational Linguistics, vol-ume 39, pages 482?490.R.
Wicentowski.
2002.
Modeling and LearningMultilingual Inflectional Morphology in a Mini-mally Supervised Framework.
Ph.D. thesis, TheJohns Hopkins University.D.
Yarowsky and R. Wicentowski.
2000.
Mini-mally supervised morphological analysis by mul-timodal alignment.
In Proceedings of the AnnualMeeting of the Association of Computational Lin-guistics, pages 207?216.D.
Yarowsky, G. Ngai, and R. Wicentowski.
2001.Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
In Pro-ceedings of the Human Language TechnologyConference, pages 161?168.
