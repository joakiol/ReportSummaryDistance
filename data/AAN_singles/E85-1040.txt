USER MODELLING, DIALOG STRUCTURE, ANDDIALOG STRATEGY IN RAM-ANSKatharina MorikTechnische Universitaet BerlinProject group KIT , Sekr.
FR 5-8Franklinstr.
28/29D-IO00 Berlin i0 (Fed.
Rep. Germany)ABSTRACTAI dialog systems are now developing fromquestion-answering systems toward advisingsystems.
This includes:discussed here, but see (Jameson, Wahlster 1982).The second part of  this paper presents usermodelling with respect to a dialog strategy whichselects and verbalizes the appropriate speech actof recommendation.- structuring dialog- understanding and generating a wider range ofspeech acts than simply information request andanswer- user modellingUser modelling in HAM-ANS is closely connected todialog structure and dialog strategy.
In advisingthe user, the system generates and verbalizesspeech acts.
The choice of the speech act isguided by the user profile and the dialog strategyof the system.INTRODUCTIONThe HAMburg Application-oriented Natural languageSystem (HAM-ANS) which has been developed for 3years is now accomplished.
We could performnumerous dialogs with the system thus determiningthe advantages and shortcomings of our approach(Hoeppner at al.
|984).
So now the time has cometo show the open problems and what we have learnedas did the EUFID group when they accomplishedtheir system (Templeton, Burger 1983).
This paperdoes not evaluate the overall HAM-ANS but isrestricted to the aspect of dialog structuring anduser modelling.Dialog structure is represented at two levels: theoutline of the dialog is explicitly represented bya top (evel routine, embedded sub-dialogs are aresult of the processing strategy of HAM-ANS.
Theoverall dialog structure is utilized fordetermining the appropriate degree of detail ofthe referential knowledge for a particular dialogphase.
The embedded sub-dialogs refer to otherknowledge sources than the referential knowledge.In the first part of this paper dialog structuringin HAM-ANS is described.
Handling of dialogphenomena as ellipsis and anaphora is notDIALOG STRUCTUREIn one of its three applications HAM-ANS plays therole of a hotel clerk who advises the user inselecting a suitable room.
The task of advisingcan be seen here as a comparison of the demandsmade on an object by the client and the advisor'sknowledge about available objects, performed inorder to determine the suitability of an objectfor the client.
Dialogs between hotel clerks atthe reception and the becoming hotel guest areusually short and stereotyped but offer someflexibility as well because the ~ruests do notestablish a homogeneous group.
With recourse tothis restricted dialog type we modelled theoutline of the dialog.
Dialog structure is notrepresented in terms of some actions the usermight want to perform as did Grosz (1977), Allen(1979), Litman,Allen (1984) nor in terms ofinformation goals of the user as did Pollack(1984), but we represent and use knowledge about adialog type.
For formal dialogs in a well definedcomunicat ion setting this is possible.
For apractical application the dialog phases and stepsshould be empirically determined.
We do notconsider the hotel reservation situation anexample for real application.
We just wanted toshow the feasibility of recurring to linguisticknowledge about types of texts or dialogs.
Realclerk - guest dialogs show some features we didnot concern.
Features of informal man-man-communication as, e.g., narratives and role-defining utterances of dialog partners wereexcluded from the model of  the dialog.
Man-machine-interaction is seen as formal as opposedto informal communication, and there is no way ofredefining it as personal talk.The outline of the dialog is a structure at threedifferent levels: there are three dialog phases,each consisting of several dialog steps (seeFig.
l).
Each dialog step can be performed byseveral dialog acts.
* The work on HAM-ANS has been supported by theBMFT (Bundesministerium fuer Forschung undTechnologic) under contract 08it15038.Although the outline of the dialog is fixed, thereis also flexibility to some extent:268GREETINGFINDING OUT WHAT THE USER WANTSCONFIRMATIONRECOMMENDING A ROOM\giving the initiative\ANSWERING QUESTIONS ABOUT THAT PARTICULAR ROOM/taking the initiativeBOOKING THE ROOM (OR NOT):GOOD-BYEFig.
l outline of the dialog- The dialog step "Finding out what the userwants" consists of as many questions of thesystem as are necessary- If the confirmation step does not succeed it isjumped back to the dialog act where the userinitializes the dialog step "Finding out whatthe user wants- In the dialog phase concerning a particularroom the sys tem asks for regaining theinitiative.
If the user denies the questioningphase is continued.The advantages of fully utilizing knowledge aboutthe dialog type are the reduction of complexity,i.e.
the system does not have to recognize thedialog step, realistic response time because noadditional processing has to be done for planningthe dialog, and the explicit representation of thedialog structure.
The declarative representationof dialog structure allows for modelling differentdegrees of detail of the world knowledge attachedto the dialog phases.Views of the domainWe believe that the degree of detail ofreferential knowledge is constituing a dialogphase.
In other words, different degrees of detailor abstraction seperate dialog phases.
Reichmancould have made this point, because her empiricaldata do support this observation (Reichman 1978).In focus is not only a certain portion of a tasktree or a certain step in a plan, but also acertain view of the matter.
Therefore, attachedto the dialog phases are different knowledge basesaccessable in these phases.
World knowledgecontains for the first and the last phase overviewknowledge about the hotel and its room categories,for the second phase detailed knowledge about oneinstance of a room category, i.e.
a particularroom.The room categories are derived from theindividual rooms by an extraction process whichdisregards location and special features ofobjects as, e.g., colour.
But representingoverview knowledge is not just leaving out sometypes of arcs in the referential semantic network!One capability of the extraction process is togroup objects together if there is an availableword to identify the group and to identify objectswhich are members of the group not just parts of awhole.
An example may clarify this.One advantage of some of the rooms is that theyhave a comfortable seating arrangement made up ofvarious objects: couch, chairs, coffee table, etc.HAM-ANS can abstract from this grouping of objectsand identify it as a "Sitzecke" - a kind of cozycorner, a common concept and an every-day word inGerman.
Another example of a group is the concept"Zimmerbar" (room bar) consisting of arefrigirator, drinking glasses and drinks.Another difference between overview knowledge anddetailed knowledge is that some properties ofobjects are inherited to the room category.
Forexample, what can be seen out of the window isabstracted to the view of the room category.
Aroom category has a view of the Alster, one of thetwo rivers of Hamburg, if at least one windowfaces the Alster.While selecting a suitable room for the user thesystem accesses the abstracted referentialknowledge.
Not until the dialog focuses on oneparticular room, does the system answer in detailquestions about, e.g.
the location of furniture,its appearance, comfort,etc.
Thus differentdegrees of detail are associated with differentdialog phases because the tasks for which thereferential knowledge is needed differ.
The linkbetween the overview information, e.g.
that a roomcategory has a desk, a seating arrangement("Sitzecke") etc., and the detailed referentialknowledge about a particular room of thatcategory, e.g., that there is a desk named DESKI,that there are three arm chairs and a coffee tableetc., is established by an inverse process to theextraction process.
This inverse process findstokens or derives implicit types, for which inturn the corresponding tokens are found.
Wheninitiative is given to the user, the tokens ofobjects mentioned in the preceeding dialog areentered into the dialog memories which keep trackof what is mutually known by system and user.Thus, if the seating arrangement ("Sitzecke") hasbeen introduced into the dialog the user may ask,where "the coffee table" is located using thedefinite description, because by naming theseating arrangement the coffee table is implicitlyintroduced.The procedural connection between overview anddetailed knowledge entails, however, a problem.First, while semantic relations between conceptsare represented in the conceptual network thusdetermining noun meaning, the meaning of "groupnouns" could not be represented in the sameformalism.
Second, inversing the extractionprocess and entering tokens into a dialog memory269leads to a problem of ambiguous referents.
If a"Sitzecke" has been mentioned - which arm chairsor couchs are introduced and how many?
The systemmay infer the tokens, but not the user.
For him, adefault description of a "Sitzecke", which isconcretized only if an object is named by theuser, should be entered into the dialog memory.SubdialogsWe have seen the outline of the dialog, but alsoinside the questioning phase there is a dialogstructure.
The system initiates a clarificationdialog if it could not understand the user input.This could be, for instance, a lexicon updatedialog.
The user may start a subdialog in puttinga meta-question as, e.g., "What was my lastquestion?"
or "What is meant by carpet?".
Maim-questions are recognized by clue patterns.
Here,too, attached to the subdialogs are differentknowledge sources: subdialogs are not referringto the referential knowledge (about a particularroom) but to the lexical update package, thedialog memories, or the conceptual knowledge.Subdialogs are embedded dialogs which can be seenin the system behavior regarding anaphora, forinstance.
They are processed in bypassing thenormal procedure of parsing, interpretation andgenerating.
This solution should be replaced by adialog manager module which decides as a result ofthe interpretation process which knowledge sourceis to be taken as a basis for finding the answer.USER MODELLINGUser modelling in AI most often concerns theuser's familiarity with a computer system (Finin1983, Wilensky 1984) or his/her knowledge of thedomain (Goldstein 1982, Clancey 1982, Paris 1983).These are, of course, important aspects of usermodelling, but the system must in addition modelthe user-assessment aspect.Value judgementsThe claim of philosophers and linguists (Hare1952, Grewendorf 1978, Zillig 1982) that valuejudgements refer to some sort of an evaluationstandard are not sufficient.
In AI, the questionsare :- how to recognize evaluation standards- how to represent them- how to use them for generating speech actsevaluations should be used to select those objectswhich might interest the user.
For example, whichinformation about a hotel room is presented to theuser depends on the interests of the user and hisrequirements, which can be inferred from his/herevaluation standard.
The information to beoutputted can be selected on the basis of user'srequirements rather than on the basis of freedomof redundancy given the user's knowledge.
Thus,the choice of the relevant objects as well as thechoice of the appropriate value judgement requiresthe modelling of the user's evaluation standards.A system which performs recommendations of fictionbooks is Rich's GRUNDY (Rich 1979).
The basisheuristic underlying the consultative function isthat people are interested in books in whichcharacters have the same type of personality asthey themselves have, or where characters arefacing a situation similar to their o~en.Therefore, recognizing the personality type of auser is a central concern for GRUNDY and can beused directly for the evaluation of books.
We'llsee that for HAM-ANS the utilization of knowledgeabout the user is not so straightforward.
Neitheris HAM-ANS interested in the personality type ofthe user nor is there any plausible direct matchbetween personality type and room category.
Wewant to distinguish the user facts, which isknowledge about the user and his wants givenexplicitly by himself, the user profile, which isknowledge about the user inferred by the system,and the interest profile, which is the user'sevaluation standard as it is inferred by thesystem.
One has to be inferred from the other.Building the  in teres t  profileLet us look at an example of the first dialogphase:SYS :USER:SYS :USER:SYS :USER:SYS :\[t is well known that recommendations rely on thepresumed evaluation standards of the hearer.
Ifthese speech acts are to be actually implemented USER:in the system and not just read into the systemresponses by the user, the system must be able to SYS :reco~ni=e the user's stRndards of evaluation,derive the demands placed by the user on objectsor situations which form the subject with the USER:demands.
\[t would be overinformative to outputevaluations about every possible object.
Rather, SYS :HOTEL ALSTERBLICK, GUTEN ABEND!At the sign of Hotel Alsterblick, goodeven ing'Hallo hier Doktor Heine von IBM Heidelberg,Hello this is Doctor Heine from IBMHeidelbergWAS KANN ICH FUER SIE TUN?What can I do for you?Ich moechte ein Doppelzimmer mit Bad fuerzwei Tage.I would like a single room with bath for twodays .UND AB WANN WIRD DAS ZIMMER BENOETIGT?And for when would you like the room?Ab morganFor tomorrowUND AUF WELCHEN NAMEN SOLL DAS ZI~4ERGEBUCHT WERDEN?And in  whose  name shou ld  the  room be booked?Auf meinen.In mine.EIN DOPPELZIMMER BIS Zt~1 25.4.
HAETTEN SIEGERN?You would like a double room until april 25?Ja.Yes.UNSER HOTEL WIRD IHNEN GEFALLEN UND WIR270HABEN AUCH NOCH EIN ZIMMER FREI.
DAS ZIMMERHAT KEIN FERNSEHGERAET ABER EINE ZI~@4ERBAR,EINEN SCHREIBTISCH, EIN TELEFON UND EINESITZECKE.
HABEN SIE ZU DIESEM ZIMMER NOCHEINE FRAGE?You will enjoy our hotel and there is stilla room available.
The room has no TV but aroom bar, a desk, a telephone, and a seatingarrangement.
Do you have questionsconcerning this room?In this dialog phase the user first informs thesystem about his concerns and indirectly give somehints about his standards.
The facts, i.e.
fromwhen to when what kind of a room should be bookedfor whom, are stored in a data structure under theheading GUEST.
If the user has not given all thenecessary information, the system asks for it.The way the user introduces himself may give ahint as to what kind of user he is.
But the systemwould not ask for title or firm or location if theuser has not volunteered the information.
Fromthese data some inference processes are initiated,estimating independently profession (here,manager) financial status (here, rich), andpurpose of trip (here, transit).
The estimationsare stored under the heading SUPPOSE.
They can beviewed as stereotypes in that they arecharcteristics of a person, relating him/her to acertain group to which a number of features areassigned (Gerard, Jones 1967).
As I mentionedearlier the application of stereotypes is not asstraightforward as in Rich's approach.
Two stepsare required.
We've just seen the first step, thegeneration of SUPPOSE data.
As opposed to GUESTdata, the SUPPOSE ata are not certain, thussupposed data and facts are divided.In the second step, each of the SUPPOSE dataindependently triggers inferences, that deriverequirements presumably placed on a room and onthe hotel by the user.
The requirements areroughly weighed as very important, important andsurplus (extras).
If the same requirement isderived by more than one inference and withdifferent weights, the next higher weight iscreated or the stronger weight is chosen,respectively.
This is, of course, a rathersimplified way of handling reinforcement.
But amore finely treatment would yield no practicalresults in this domain.
The requirements for theroom category and for the hotel are storedseperately in semantic networks.
An excerpt of thenetworks corresponding to the dialog exampleabove:((WICHTIG (HAT Z FERNSEHGERAET).I)((SEHR-WICHTIG (HAT Z TELEFON).I)((SEHR-WICHTIG (HAT Z SCHREIBTISCH).I)((SURPLUS (HAP HOTEL1 FREIZEITANGEBOT-2).I)((SEHR-WICHTIG (IST HOTEL1 IN/ ZENTRALER/ LAGE).I)The requirements are then tested against theknowledge about the hotel and the room categories.Some requirements correspond directly to storedfeatures.
Others as here, for instance, theleisure opportunities nt~mber 2 or the centrallocation of the hotel are expanded to somefeatures by inference procedures.
Thus here, too,there is an abstraction process.
The requirementstogether with their expansions represent theconcretized evaluation standard of the user.
Theyare called the interest profile of the user.Generating recommendationsNow, let's see what the system does with this.First, it matches the requirements against theroom or hotel features thus yielding an evaluationfrom every room category of the requested kind(here, double room).
The evaluation of a roomcategory consists of two lists, the one of thefulfilled criteria and the one of the unfulfilledcriteria.Secondly, based on this evaluation speech acts areselected.
The speech act recommendation is splitup into STRONG RECO~NDATION,  WEAK RECO~4EN-DATION, RESTRICTED RECOMMENDATION, and NEGATIVERECO~NDATION.
The speech acts as they are knownin linguistics are not fine grinned enough.
Havingonly one speech act for recommending would leaveimportant information to the propositionalcontent.
The appropriate recommendation is chosenaccording to the following algorithm:- if all the criteria are fulfilled, a STRONGRECO~NDATION is generated- if no criteria are fulfilled, a NEGATIVERECOMMENDATION is generated- if all very important criteria are fulfilled,but there are violated criteria, too, aRESTRICTED RECOM~NDATION is generated- if there are some criteria fulfilled, but evenvery important criteria are violated, a WEAKRECO~NDATION is generatedThis process is executed both for the possibleroom categories and for the hotel.
The resutt is apossible recommendation for each room category andthe hotel.
Out of these possible recommendationsthe best choice is taken.Third, a rudimentary dialog strategy selects themost adequate speech act for verbalization.
Forinstance, if there is nothing particularly good tosay about a room but there are features of thehotel to be worth landing, then the hotel will berecommended.
The hotel recommendation is onlyverbalized, iff it suits perfectly and the bestpossible recommendation for a room category is notextreme, i.e.
neither strong nor negative.
Thenegative recommendation has priority over thehotel recommendation because an application-oriented system should not persuade a user nor hasa goal for its own - although this is aninteresting matter for experimental work and canbe modelled within our framework.In our example dialog the best recommendation of aroom category is the restricted recommendation forroom category 4.
The hotel fulfills all theinferred requirements and can be recommendedstrongly.
These speech acts have to be Verbalizednow.
For verbalization, too, a dialog strategy is271applied:The better the evaluationthe shorter the recommendation.The most positive recommendation is realized as:DA HABEN WIR GENAU DAS PASSENDE ZI~9~ERFREI.
(We have just the room for you.
)FUER SIEIn our example the recommendation can't be soshort, because the disadvantages should bepresented to the user so that he can decidewhether the room is sufficient for hisrequirements.
Therefore, the room category isdescribed.
Among all the features of the room onlythose are verbalized which correspond to theuser's interest profile.
In order to verbalizethe restricted recommendation, a "but" constructof the internal representation language SURF ofHAM-ANS is built (Fig.
2).From this structure the HAM-ANS verbalizationcomponent creates a verbalized structure which isthen transformed into a preterminal string fromwhich the natural language surface is built andthen outputted (Busemann 1984).
The verbalizationcomponent includes the updating of the dialogmemories.~af-d: IS(t-s: (q-d: D-) (lambda: x4 (af-a: ISA x4ZI~R) ) )(lambda: x4(af-a: HAT x4(t-o: BUT(t-s: (q-qt: KEIN) (lambda: x4 (af-a: ISA x4FERNSEHGERAET)))(t-o: AND(t-s: (q-qt: E-) (lambda: x4 (af-a: ISA x4ZIMMERBAR)))(t-o: AND(t-s: (q-qt: E-) (lambda: x4 (af-a: ISA x4SCHREIBTISCH)))(t-o: AND(t-s: (q-qt: E-) (lambda: x4 (af-a: ISA x4TELEFON)))(t-s: (q-qt: E-) (lambda: x4 (af-a: ISA x4S ITZECKE) ) ) ) ) ) ) ) ) )Fig.2 SURF structureAfter the dialog strategy has selected the mostposltive recommendation it can fairly giveregarding the evaluation form of the room categorywhich suits best the (implicit) demands of theuser and has chosen the appropriate formulationfor the recommendation, it prepares to give theinitiative to the user thus entering thequestioning dialog phase.
That is: it is focusedon the selected room category and the moredetailed data about an instance of that particularroom category are loaded.
In our example, thereferential network and the spatial data of room 4are accessed.OPEN QUESTIONSThe problems that have yet to be solved may bedivided into three groups: those that could besolved within this framework, those that require achange in system architecture and those that areof principle nature.A problem which seems to fit into the first groupis the explanation of the suppositions.
The usershould get an answer to the questions:Who do you think I am?How do you come to believe that I am a manager?How do you come to believe that I need a desk?The first question may be answered by verbalizingthe SUPPOSE data.
The second and the thirdquestion must be answered on the basis of theinferences taking into account the reinforcementas did Wahlster (1981).The third question may be a rejection of thesupposed requirement rather than a request forjustification or explanation.
Understandingrejections of supposed requirements includes themodification of the requirement networks.
Forexample, the user could say after the restrictedrecommendation:But I don't need a TV!Then the room category 4 fits perfectly well andmay be strongly recommended.Or the user could state:But I don't want a desk.
I would like to have aTV instead.In this case the requirement net of the roomcategories is to be changed:REMOVE ( ?
(HAT Z DESK))ADD (VERY-IMPORTANT (HAT Z TV))With this the room categories have to evaluatedagain and perhaps another room category will thenbe recommended.A type of requirements that is yet to be modelledis the requirement that something is not the case.For example, the requirement that there should beno air-conditioning (because it's noisy).A change in system architecture is required if theadvising is to be integrated into the questioningphase.
The reason why this is not possible by nowis, for one part, of practical nature: memorycapacity does not allow to hold overview knowledgeand detail knowledge at once.
The other part,however, is the increase of complexity.
Questionsare then to be understood as implicitrequirements.
For example:The room isn't dark?ADD ( IMPORTANT ( IST Z BRIGHT))The hard problem we are then confronted with is an272instance of the frame problem (Hayes 1971:495,Raphael 1971).
When does the overall evaluation ofa room category not hold any longer?
When are allthe room categories to be evaluated againaccording to a modified interest profile?
Whenshould it be switched from one selected roomcategory to another?
These are problems ofprinciple nature which have yet to be solved.Further research is urgently needed.REFERENCESHARE,HAYES,Meltzer, D. MichieIntelligence 6, pp.495.ALLEN, J.F.
(1979): A Plan Based Approach to SpeechAct Recognition.
Univ.
of Toronto,Techn.
Rep. No.131/79.BUSEMANN, S.(1984): Surface Transformations DuringThe Generation Of Written German Sentences.Hamburg Univ., Research Unit for InformationScience and Artificial Intelligence, Rep.ANS-27.CLANCEY, W.J.
(1982): Tutoring Rules For Guiding ACase Method Dialogue.
In: D. Sleeman, J.S.Brown (eds): Intelligent Tutoring Systems,pp.201FININ, T. (1983): Providing Help and Advice inTask Oriented Systems.
In: Procs.
8thIJCAI, Karlsruhe, pp.176.GERARD, R.B., JONES, E.E.
(1967): Foundations ofSocial Psychology.
New York, London.GOLDSTEIN, I.
(1982): The Genetic Graph: ARepresentation For The Evaluation OfProcedural Knowledge.
In: D. Sleeman, J.S.Brown (eds) Intelligent Tutoring Systems,pp.51.GREWENDORF, G. (1978): Zur Semantik vonWertaeusserungen.
In: GermanistischeLinguistik 2-5, pp.155.GROSZ, B.J.
(1977): The Representation And Use OfFocus In Dialog Understanding.
SRI, Techn.Note No.
151.R.M.
(1952): The Language Of Morals.
GermanI1972), Frankfurt a.M.P.
(1971): A Logic Of Actions.
In: B.
(eds): MachineHOEPPNER, W., CHRISTALLER, T., MARBURGER, H.,MORIK, K.,NEBEL, B., O'LEARY, M., WAHLSTER,W.
(1983):Beyond Domain-Independence: Experience WithThe Development Of A German Language AccessSystem To Highly Diverse Background Systems.In: Procs.
8th IJCAI, Karlsruhe, pp.
588.JAMESON, A., WAHLSTER, W. (1982): User Modell ingIn Anaphora Generation: Ellipsis AndDefinite Description.
In: Procs.
ECA\[-82,Orsay, pp.222.LITMAN, D.J.,ALLEN, J .F .
(1984): A PlanRecognition Model For ClarificationSubdialogs.
In: Procs.
COLING-84, Stanford,pp.
302.PARIS, J.J. (1983): Determining The Level OfExpertise For Question Answering.
New York(no report number).POLLACK, M. E. (1984): Good Answers To BadOuestions: Goal Inference In Expert Advice-Giving.
In: Procs.
Canadian Conference onAI, pp.20.RAPHAEL, B.
(1971): The Frame Problem in ProblemSolving Systems.
In: N. Findler, B. Meltzer(eds): Artificial Intelligence and HeuristicProgramming, pp.
159.REICHMAN, R. (1978): Conversational Coherency.
In:Cognitive Science 2, pp.283.RICH, E. (1979): Building And Exploiting UserModels.
Carnegie Mellon Univ.
Rep. No.
CMU-C3-79-I19.TEMPLETON, M., BURGER, J.
(1983): Problems InNatural-Language Interface To DBMS WithExamples From EUFID.
In: Procs.
Conferenceon Applied Natural Language Processing,Santa Monica, pp.3.WAHLSTER, W. (1981): NatuerlichsprachlicheArgumentation in Dialogsystemen - KI-Verfahren zur Rekonstruktion und Erklaerungapproximativer Inferenzprozesse.
Berlin,Heidelberg, New York.WILENSKY ,R. (1984): Talking To UNIX In English:An Overview Of An Online UNIX Consultant.In: The AI Maganzine, VoI.V, No.
l, pp.29.ZILLIG, W. (1982): Bewerten - Spreehakttypen derbewertenden Rede.
Tuebingen.273
