Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 51?57,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsAutomatically Generated Customizable Online DictionariesEniko?
He?jaDept.
of Language TechnologyResearch Institute for Linguistics, HASP.O.Box.
360 H-1394, Budapesteheja@nytud.huDa?vid Taka?csDept.
of Language TechnologyResearch Institute for Linguistics, HASP.O.Box.
360 H-1394, Budapesttakdavid@nytud.huAbstractThe aim of our software presentation isto demonstrate that corpus-driven bilingualdictionaries generated fully by automaticmeans are suitable for human use.
Pre-vious experiments have proven that bilin-gual lexicons can be created by applyingword alignment on parallel corpora.
Suchan approach, especially the corpus-drivennature of it, yields several advantages overmore traditional approaches.
Most im-portantly, automatically attained translationprobabilities are able to guarantee that themost frequently used translations come firstwithin an entry.
However, the proposedtechnique have to face some difficulties, aswell.
In particular, the scarce availability ofparallel texts for medium density languagesimposes limitations on the size of the result-ing dictionary.
Our objective is to designand implement a dictionary building work-flow and a query system that is apt to ex-ploit the additional benefits of the methodand overcome the disadvantages of it.1 IntroductionThe work presented here is part of the pilot projectEFNILEX 1 launched in 2008.
The project objec-tive was to investigate to what extent LT methodsare capable of supporting the creation of bilingualdictionaries.
Need for such dictionaries shows upspecifically in the case of lesser used languageswhere it does not pay off for publishers to in-vest into the production of dictionaries due to thelow demand.
The targeted size of the dictionariesis between 15,000 and 25,000 entries.
Since the1EFNILEX is financed by EFNILcompletely automatic generation of clean bilin-gual resources is not possible according to thestate of the art, we have decided to provide lex-icographers with bilingual resources that can fa-cilitate their work.
These kind of lexical resourceswill be referred to as proto-dictionaries hencefor-ward.After investigating some alternative approachese.g.
hub-and-spoke model (Martin, 2007), align-ment of WordNets, we have decided to use wordalignment on parallel corpora.
Former experi-ments (He?ja, 2010) have proven that word align-ment is not only able to help the dictionary cre-ation process itself, but the proposed techniquealso yields some definite advantages over moretraditional approaches.
The main motivation be-hind our choice was that the corpus-driven natureof the method decreases the reliance on human in-tuition during lexicographic work.
Although thecareful investigation of large monolingual corporamight have the same effect, being tedious andtime-cosuming it is not affordable in the case oflesser used languages.In spite of the fact that word alignment hasbeen widely used for more than a decade withinthe NLP community to produce bilingual lexi-cons e.g.
Wu and Xia (1994) and several ex-perts claimed that such resources might also beuseful for lexicographic purposes e.g.
Bertels etal.
(2009), as far as we know, this technique hasnot been exploited in large-scale lexicographicprojects yet e.g.
Atkins and Rundell (2008).Earlier experiments has shown that althoughword alignment has definite advantages over moretraditional approaches, there are also some diffi-culties that have to be dealt with: The method initself does not handle multi-word expressions and51the proto-dictionaries comprise incorrect trans-lation candidates, as well.
In fact, in a given paral-lel corpus the number of incorrect translation can-didates strongly depends on the size of the proto-dictionary, as there is a trade-off between preci-sion and recall.Accordingly, our objective is to design and im-plement a dictionary query system that is apt toexploit the benefits of the method and overcomethe disadvantages of it.
Hopefully, such a sys-tem renders the proto-dictionaries helpful for notonly lexicographers, but also for ordinary dictio-nary users.In Section 2 the basic generation process is in-troduced along with the difficulties we have todeal with.
The various features of the DictionaryQuery System are detailed in Section 3.
Finally,a conclusion is given and future work is listed inSection 4.The proto-dictionaries are available at:http://efnilex.efnil.org2 Generating Proto-Dictionaries ?One-Token Translation Pairs2.1 Input dataSince the amount of available parallel data is cru-cial for this approach, in the first phase of theproject we have experimented with two diffe-rent language pairs.
The Dutch-French languagepair represents well-resourced languages whilethe Hungarian-Lithuaninan language pair repre-sents medium density languages.
As for the for-mer, we have exploited the French-Dutch paral-lel corpus which forms subpart of the Dutch Pa-rallel Corpus (Macken et al 2007).
It consistsof 3,606,000 French tokens, 3,215,000 Dutch to-kens and 186,945 translation units2 (TUs).
As forHungarian and Lithuanian we have built a paral-lel corpus comprising 4,189,000 Hungarian and3,544,000 Lithuanian tokens and 262,423 TUs.Because our original intention is to compile dic-tionaries covering every-day language, we havedecided to focus on literature while collecting thetexts.
However, due to the scarce availabilityof parallel texts we made some concessions thatmight be questionable from a translation point ofview.
First, we did not confine ourselves purely2The size of the parallel corpora is given in terms of trans-lation units instead of in terms of sentence pairs, for many-to-many alignment was allowed, too.to the literary domain: The parallel corpus com-prises also philosophical works.
Secondly, in-stead of focusing on direct translations betweenLithuanian and Hungarian we have relied mainlyon translations from a third language.
Thirdly, wehave treated every parallel text alike, regardless ofthe direction of the translation, although the DPCcontains that information.2.2 The Generation ProcessAs already has been mentioned in Section 1,word alignment in itself deals only with one-tokenunits.
A detailed description of the generationprocess of such proto-dictionaries has been givenin previous papers, e. g. He?ja (2010).
In thepresent paper we confine ourselves to a schematicoverview.
In the first step the lemmatized versionsof each input text have been created by means ofmorhological analysis and disambiguation3.In the second step parallel corpora have beencreated.
We used Hunalign (Varga et al 2005)for sentence alignment.In the next step word alignment has been per-formed with GIZA++ (Och and Ney, 2003).
Dur-ing word alignment GIZA++ builds a dictionary-file that stores translation candidates, i.e.
sourceand target language lemmata along with theirtranslation probabilities.
We used this dictio-nary file as the starting point to create the proto-dictionaries.In the fourth step the proto-dictionaries havebeen created.
Only the most likely translationcandidates were kept on the basis of some suit-able heuristics, which has been developed whileevaluating the results manually.Finally, the relevant example sentences wereprovided in a concordance to give hints on the useof the translation candidates.2.3 Trade-off between Precision and RecallAt this stage of the workflow some suitableheuristics need to be introduced to find the besttranslation candidates without the loss of toomany correct pairs.
Therefore, several evaluationswere carried out.3The analysis of the Lithuanian texts was performedby the Lithuanian Centre of Computational Linguistics(Zinkevic?ius et al 2005).
The Hungarian texts were anno-tated with the tool-chain of the Research Institute for Lin-guistics, HAS (Oravecz and Dienes, 2002).52It is important to note that throughout the man-ual evaluation we have focused on lexicographi-cally useful translation candidates instead of per-fect translations.
The reason behind this is thattranslation synonymy is rare in general languagee.g.
Atkins and Rundell (2008, p. 467), thus othersemantic relations, such as hyponymy or hyper-onymy, were also considered.
Moreover, since theword alignment method does not handle MWEs initself, partial matching between SL and TL trans-lation candidates occurs frequently.
In either case,provided example sentences make possible to findthe right translation.We considered three parameters when search-ing for the best translations: translational proba-bility, source language lemma frequency and tar-get language lemma frequency (ptr, Fs and Ft,respectively).The lemma frequency had to be taken into ac-count for at least two reasons.
First, a minimalamount of data was necessary for the word align-ment algorithm to be able to estimate the transla-tional probability.
Secondly, in the case of rarelyused TL lemmas the alignment algorithm mightassign high translational probabilities to incor-rect lemma pairs if the source lemma occurs fre-quently in the corpus and both members of thelemma pair recurrently show up in aligned units.Results of the first evaluation showed thattranslation pairs with relatively low frequencyand with a relatively high translational probabilityyielded cc.
85% lexicographically useful trans-lation pairs.
Although the precision was ratherconvincing, it has also turned out that the size ofthe resulting proto-dictionaries might be a seriousbottleneck of the method (He?ja, 2010).
Whereasthe targeted size of the dictionaries is between15,000 and 25,000 entries, the proto-dictionariescomprised only 5,521 Hungarian-Lithuanian and7,007 French-Dutch translation candidates withthe predefined parameters.
Accordingly, the cov-erage of the proto-dictionaries should be aug-mented.According to our hypothesis in the case of morefrequent source lemmata even lower values oftranslation probability might yield the same resultin terms of precision as in the case of lower fre-quency source lemmata.
Hence, different evalua-tion domains need to be determined as a functionof source lemma frequency.
That is:1.
The refinement of the parameters yields ap-proximately the same proportion of correcttranslation candidates as the basic parametersetting,2.
The refinement of the parameters ensures agreater coverage.Detailed evaluation of the French-Dutch trans-lation candidates confirmed the first part of ourhypothesis.
We have chosen a parameter setting inaccordance with (1) (see Table 1).
6934 French-Dutch translation candidates met the given con-ditions.
10 % of the relevant pairs was manuallyevaluated.
The results are presented in Table 1.?OK?
denotes the lexicographically useful transla-tion candidates.
For instance, the first evaluationrange (1st row of Table 1) comprised translationcandidates where the source lemma occurs at least10 times and at most 20 times in the parallel cor-pus.
With these parameters only those pairs wereconsidered where the translation probability wasat least 0.4.
As the 1st and 2nd rows of Table 1show, using different ptr values as cut-off param-eters give similar results (87%), if the two sourcelemma frequencies also differ.Fs ptr OK10 ?
LF ?
20 p ?
0.4 83%100 ?
LF ?
200 p ?
0.06 87%500 ?
LF p ?
0.02 87.5%Table 1: Evaluation results of the refined French-Dutch proto-dictionary.The manual evaluation of the Hungarian-Lithuanian translation candidates yielded thesame result.
We have used this proto-dictionaryto confirm the 2nd part of our hypothesis, i.e.
thatthe refinement of these parameters may increasethe size of the proto-dictionary.
Table 2 presentsthe results.
Expected refers to the expectednumber of correct translation candidates, esti-mated on the basis of the evaluation sample.
800translation candidates were evaluated altogether,200 from each evaluation domain.
As Table 2shows, it is possible to increase the size of thedictionary through refining the parameters: withfine-tuned parameters the estimated number ofuseful translation candidates was 13,605 insteadof 5,521.53Fs ptr OK Expected5 ?
LF < 30 p > 0.3 64% 4,29630 ?
LF < 90 p > 0.1 80% 4,14490 ?
LF < 300 p > 0.07 89% 3,026300 ?
LF p > 0.04 79% 2,13913,605Table 2: Evaluation results of the refined Hungarian-Lithuanian proto-dictionary.However, we should keep in mind when search-ing for the optimal values for these parametersthat while we aim at including as many translationcandidates as possible, we also expect the gener-ated resource to be as clean as possible.
That is, inthe case of proto-dictionaries there is a trade-offbetween precision and recall: the size of the re-sulting proto-dictionaries can be increased only atthe cost of more incorrect translation candidates.This leads us to the question of what parame-ter settings are useful for what usage scenarios?We think that the proto-dictionaries generated bythis method with various settings match well dif-ferent user needs.
For instance, when the settingsare strict so that the minimal frequencies and pro-babilities are set high, the dictionary will containless translation pairs, resulting in high precisionand relatively low coverage, with only the mostfrequently used words and their most frequenttranslations.
Such a dictionary is especially usefulfor a novice language learner.
Professional trans-lators are able to judge whether a translation iscorrect or not.
They might be rather interested inspecial uses of words, lexicographically useful butnot perfect translation candidates, and more sub-tle cross-language semantic relations, while at thesame time, looking at the concordance providedalong with the translation pairs, they can easilycatch wrong translations which are the side-effectof the method.
This kind of work may be sup-ported by a proto-dictionary with increased recalleven at the cost of a lower precision.Thus, the Dictionary Query System describedin Section 3 in more detail, should support varioususer needs.However, user satisfaction has to be evaluatedin order to confirm this hypothesis.
It forms partof our future tasks.Figure 1: The customized dictionary: the distribu-tion of the Lithuanian-Hungarian translation candi-dates.
Logarithmic frequency of the source words onthe x-axis, translation probability on the y-axis.3 Dictionary Query SystemAs earlier has been mentioned, the proposedmethod has several benefits compared to more tra-ditional approaches:1.
A parallel corpus of appropriate size gua-rantees that the most relevant translations beincluded in the dictionary.2.
Based on the translational probabilities it ispossible to rank translation candidates ensur-ing that the most likely used translation va-riants go first within an entry.3.
All the relevant example sentences from theparallel corpora are easily accessible facili-tating the selection of the most appropriatetranslations from possible translation candi-dates.Accordingly, the Dictionary Query Systempresents some novel features.
On the one hand,users can select the best proto-dictionary for theirpurposes on the Cut Board Page.
On the otherhand, the innovative representation of the gene-rated bilingual information helps to find the besttranslation for a specific user in the DictionaryBrowser Window.3.1 Customizable proto-dictionaries: the CutBoard PageThe dictionary can be customized on the CutBoard Page.
Two different charts are displayed54Figure 2: The customized dictionary: the distributionof the candidates.
Logarithmic frequency ratio of thesource and target words on the x-axis, translation prob-ability on the y-axis.here showing the distribution of all word pairs ofthe selected proto-dictionary.1.
Plot 1 visualizes the distribution of the log-arithmic frequency of the source words andthe relevant translation probability for eachword pair, selected by the given custom cri-teria.2.
Plot 2 visualizes the distribution of thelogarithmic frequency ratio of the targetand source words and the correspondingtranslation probability for each word pair,selected by the given custom criteria..Proto-dictionaries are customizable by the follow-ing criteria:1.
Maximum and minimum ratio of the relativefrequencies of the source and target words(left and right boundary on Plot 1).2.
Overall minimum frequency of either thesource and the target words (left boundaryon Plot 2).3.
Overall minimum translation probability(bottom boundary on both plots).4.
Several more cut off intervals can be definedin the space represented by Plot 2: wordpairs falling in rectangles given by their left,right and top boundaries are cut off.After submitting the given parameters the chartsare refreshed giving a feedback to the user andthe parameters are stored for the session, i. e. thedictionary page shows only word pairs fitting theselected criteria.3.2 Dictionary BrowserThe Dictionary Browser displays four differenttypes of information.1.
List of the translation candidates ranked bytheir translation probabilities.
This guaran-tees that most often used translations comefirst in the list (from top to bottom).
Abso-lute corpus frequencies are also displayed.2.
A plot displaying the distribution of the po-ssible translations of the source word accord-ing to translation probability and the ratio ofcorpus ferquency between the source wordand the corresponding translation candidate.3.
Word cloud reflecting semantic relations bet-ween source and target lemmata.
Words inthe word cloud vary in two ways.First, their size depends on their translationprobabilities: the higher the probability ofthe target word, the bigger the font size is.Secondly, colours are assigned to targetwords according to their frequency ratios rel-ative to the source word: less frequent targetwords are cool-coloured (dark blue and lightblue) while more frequent target words arewarm-coloured (red, orange).
Target wordswith a frequency close to that of the sourceword get gray colour.4.
Provided example sentences with the sourceand target words highlighted, displayed byclicking one of the translation candidates.According to our hypothesis the frequency ra-tios provide the user with hints about the se-mantic relations between source and target wordswhich might be particularly important when cre-ating texts in a foreign language.
For instance,the Lithuanian lemma karieta has four Hungar-ian eqivalents: ?kocsi?
(word with general mean-ing, e.g.
?car?, ?railway wagon?, ?horse-drown ve-hicle?
), ?hinto??
(?carriage?
), ?konflis?
(?a horse-drawn vehicle for public hire?
), ?ja?rmu??
(?vehi-cle?).
The various colours of the candidates indi-cate different semantic relations: the red colour of55Figure 3: The Dictionary Browser?kocsi?
marks that the meaning of the target wordis more general than that of the source word.
Con-versely, the dark blue colour of ?konflis?
showsthat the meaning of the target word is more spe-cial.
However, this hypothesis should be tested inthe future which makes part of our future work.3.3 ImplementationThe online research tool is based on the LAMPweb architecture.
We use a relational databaseto store all the data: the multilingual corpus text,sentences and their translations, the word formsand lemmata and all the relations between them.The implementation of such a data structure andthe formulation of the queries is straightforwardand efficient.
The data displayed in the dictionarybrowser as well as the distributional dataset pre-sented on the charts is selected on-the-fly.
Thesize of the database is log-linear with the size ofthe corpus and the dictionary.4 Conclusions and Future WorkPrevious experiments have proven that corpus-driven bilingual resources generated fully by au-tomatic means are apt to facilitate lexicographicwork when compiling bilingual dictionaries.We think that the proto-dictionaries generatedby this technique with various settings match welldifferent user needs, and consequently, beside lex-icographers, they might also be useful for endusers, both for language learners and for profes-sional translators.
A possible future work is tofurther evaluate the dictionaries in real world usecases.Some new assumptions can be formulatedwhich connect the statistical properties of thetranslation pairs, e.g.
their frequency ratios andthe cross-language semantic relations betweenthem.
Based on the generated dictionaries suchhypotheses may be further examined in the future.In order to demonstrate the generated proto-dictionaries, we have designed and implementedan online dictionary query system, which exploitsthe advantages of the data-driven nature of the ap-plied technique.
It provides different visualiza-tions of the possible translations based on theirtranslation probabilities and frequencies, alongwith their relevant contexts in the corpus.
By pre-setting different selection criteria the contents ofthe dictionaries are customizable to suit varioususage scenarios.The dictionaries are publicly available athttp://efnilex.efnil.org.56ReferencesBeryl T. Sue Atkins and Michael Rundell.
2008.
TheOxford Guide to Practical Lexicography.
OUP Ox-ford.Ann Bertels, Ce?drick Fairon, Jo?rg Tiedemann, andSerge Verlinde.
2009.
Corpus paralle`les et corpuscible?s au secours du dictionnaire de traduction.
InCahiers de lexicologie, number 94 in Revues, pages199?219.
Classiques Garnier.Eniko?
He?ja.
2010.
The role of parallel corpora inbilingual lexicography.
In Nicoletta Calzolari (Con-ference Chair), Khalid Choukri, Bente Maegaard,Joseph Mariani, Jan Odijk, Stelios Piperidis, MikeRosner, and Daniel Tapias, editors, Proceedingsof the Seventh International Conference on Lan-guage Resources and Evaluation (LREC?10), Val-letta, Malta, may.
European Language ResourcesAssociation (ELRA).Lieve Macken, Julia Trushkina, Hans Paulussen, LidiaRura, Piet Desmet, and Willy Vandeweghe.
2007.Dutch parallel corpus : a multilingual annotatedcorpus.
In Proceedings of Corpus Linguistics 2007.Willy Martin.
2007.
Government policy and the plan-ning and production of bilingual dictionaries : Thedutch approach as a case in point.
InternationalJournal of Lexicography, 20(3):221?237.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Csaba Oravecz and Pe?ter Dienes.
2002.
Efficientstochastic part-of-speech tagging for hungarian.
InProceedings of the Third International Conferenceon Language Resources and Evaluation, pages710?717, Las Palmas.Da?niel Varga, La?szlo?
Ne?meth, Pe?ter Hala?csy, Andra?sKornai, Viktor Tro?n, and Viktor Nagy.
2005.
Par-allel corpora for medium density languages.
InRecent Advances in Natural Language Processing(RANLP 2005), pages 590?596.Dekai Wu and Xuanyin Xia.
1994.
Learning anenglish-chinese lexicon from a parallel corpus.
InIn Proceedings of the First Conference of the As-sociation for Machine Translation in the Americas,pages 206?213.Vytautas Zinkevic?ius, Vidas Daudaravic?ius, and ErikaRimkute?.
2005.
The Morphologically annotatedLithuanian Corpus.
In Proceedings of The SecondBaltic Conference on Human Language Technolo-gies, pages 365?370.57
