SESS ION 11: CONTINUOUS SPEECHRECOGNIT ION AND EVALUATION I*Clifford J. Weinstein, ChairLincoln Laboratory, M.I.T.Lexington, MA 02173-9108This was the first of two companion sessions which markedan important transition in the continuous peech recogni-tion (CSR) component of the DARPA Spoken LanguageProgram.
Since 1987, DARPA CSR systems have beendeveloped and evaluated on the Resource Management(RM) CSR corpus, which has become a de .facto standardfor comparison of speech recognizers, widely accepted andused both within and outside the DARPA research com-munity, and internationally.
The RM corpus has servedthe community well, but due to its limitations (e.g., 1000-word vocabulary, restricted task domain), it has becomeclear that more challenging tasks were needed to driveCSR research.
The papers in this session reported on thedesign and preliminary development and analysis of a newlarge-vocabulary CSR corpus for the 90s, which is aimedat meeting the needs of CSR research, and at serving ina complementary ole to the corpora being collected inthe interactive Air Travel Information System (ATIS) do-main.The first major component of the new speech corpus isbased on a very large Wall Street Journal (WSJ) text cor-pus, and supports recognition vocabularies of 5,000 and20,000 words and higher.
Actual corpus collection beganin October 1991, and by the time of this February 1992workshop, not only had a pilot WSJ corpus of 80 hoursof speech (under varied conditions) been collected anddistributed, but also a dry run evaluation of a numberof CSR systems had been conducted; the papers in Ses-sion 12 describe those systems, tests, and results.
Thisis a very significant accomplishment on such a short timescale, which was achieved through a multi-site ffort fea-turing strong and effective cooperation in the context ofmultiple, sometimes conflicting oals, and some outstand-ing individual efforts.The first paper in Session 11, presented by Janet Bakerand Doug Paul, reported on the design of the WSJ-basedCSR corpus, and of the pilot portion of the WSJ cor-pus.
The paper described the efforts of the CSR Corpus*This work was sponsored by the Defense Advanced Re-search Projects Agency.
The views expressed are those of theauthor and do not reflect he official policy or position of theU.S.
Government.Committee (chaired by Janet Baker, and including repre-sentatives from all the participating sites) in working outa design to meet multiple research goals.
Key elements ofthe design which were outlined include: variable vocabu-lary sizes and perplexities; variable amounts of data perspeaker to support speaker-dependent, speaker-adaptive,and speaker independent recognition paradigms; speechcollected both with and without verbalized punctuation;simultaneous close-talking microphones and multiple sec-ondary microphones; and numerous additional features.The paper described the text-processing steps performedat Lincoln on the original WSJ text CD-ROM to producethe texts and the language models which were deliveredto the recording and testing sites.
The paper summarizedthe materials delivered to the collecting and testing sites,which included: prompting texts for recording; truth textsfor training, recognition, and scoring; a 33,000-word ic-tionary, provided by Dragon Systems, to cover trainingand test sets; a specification of training and test sets; andbaseline language models for research and cross-site com-parative testing.The next paper, presented by George Doddington, de-scribed the work of the continuous peech corpus coor-dinating committee (CCCC), which was formed in Octo-ber 1991 to oversee the actual development of the cor-pus and the subsequent test and evaluation.
Doddington,chair of the CCCC, described the efforts of the commit-tee and acknowledged the specific efforts of the individualsand sites involved.
The February 1992 goals for the pi-lot corpus were met and exceeded.
The collecting sites(MIT, SRI, and TI) had an initial target of about 45hours, but actually collected a total of about 80 hoursof read speech, while SRI collected a substantial corpusof spontaneous speech in the general WSJ domain.
At theclose of his talk, Doddington outlined several corpus is-sues to be reviewed, based on the pilot corpus experience,in proceeding with the full corpus collection and evalua-tion.
These issues included: verbalized punctuation (VP)vs non-verbalized punctuation (NVP); natural vs prepro-cessed prompting text; mix of spontaneous v  read speech;and multiplicity of evaluation conditions.
The discussionof these issues was tabled until the end of Session 12.355The next paper, presented by Jim Glass, described collec-tion and analyses of WSJ-CSR data at MIT.
Close atten-tion was paid to development of an easy-to-use computerinterface which enabled efficient data collection with min-imal supervision of users.
This interface was quite suc-cessful, and is currently being used by SRI and by NIST,as well as MIT.
MIT collected 33 hours of speech anddelivered the data to other sites on in-house-producedCD-ROM-compatible WORM disks.
Experiments weredescribed to investigate the effects of the text preprocess-ing performed on the WSJ text, by comparing sentencesspoken with and without text preprocessing.
The resultsshowed a substantial variation in the readings of the un-processed text, relative to the processed prompting text.Finally, Jared Bernstein described experiments at SRI In-ternational in collection of spontaneous speech for theCSR corpus.
The methods proved sufficient o collect flu-ent spontaneous speech, although at significantly greatercost and with significantly greater variation than the readspeech.
In particular, good subjects were hard to find.The paper described the procedures and quantified theeffects.
A number of interesting and entertaining samplesof spontaneous renditions of news articles were played.A few of the items raised in discussion were:1.
How about recording a paragraph at a time?D.
Paul :  The recording of sentence-at-a-time within paragraphs was more con-venient for collection and for current re-search recognizers which are oriented toone sentence-per-file.V.
Zue: Subjects were presentedwith highlighted paragraphs, and movedquickly from sentence to sentence.2.
Short discussion on verbalized punctuation.Janet  Baker :  People who dictate, dopunctuate.
Would like to see some datacollected in a realistic dictation task (e.g.,tell a reporter that a story due tomorrowmorning must be dictated).3.
Roger  Moore :  Can Europeans get this data andtools?General encouragement on sharing thedata, and on cooperative fforts.4.
P. Pr ice:  How about a description of the TI collec-tion effort?R.
Ra jasekaran:  TI used automaticendpointing rather than push-to-talk;most subjects didn't like verbalized punc-tuation.Rest of discussion tabled till after dinner.An unscheduled video presentation following Bernstein'stalk entertained the group with Victor Borge's renditionof the sounds of punctuation.
This video, courtesy of RichSchwartz of BBN, was an excellent lead-in to the dinnerbreak.356
