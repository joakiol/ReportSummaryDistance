Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 289?296,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsOnline Error Detection of Barge-In Utterances by UsingIndividual Users?
Utterance Histories in Spoken Dialogue SystemKazunori Komatani?
Hiroshi G. OkunoKyoto UniversityYoshida-Hommachi, Sakyo, Kyoto 606-8501, Japan{komatani,okuno}@kuis.kyoto-u.ac.jpAbstractWe develop a method to detect erroneousinterpretation results of user utterancesby exploiting utterance histories of indi-vidual users in spoken dialogue systemsthat were deployed for the general pub-lic and repeatedly utilized.
More specifi-cally, we classify barge-in utterances intocorrectly and erroneously interpreted onesby using features of individual users?
utter-ance histories such as their barge-in ratesand estimated automatic speech recogni-tion (ASR) accuracies.
Online detectionis enabled by making these features ob-tainable without any manual annotationor labeling.
We experimentally compareclassification accuracies for several caseswhen an ASR confidence measure is usedalone or in combination with the featuresbased on the user?s utterance history.
Theerror reduction rate was 15% when the ut-terance history was used.1 IntroductionMany researchers have tackled the problem ofautomatic speech recognition (ASR) errors bydeveloping ASR confidence measures based onutterance-level (Komatani and Kawahara, 2000)or dialogue-level information (Litman et al, 1999;Walker et al, 2000; Hazen et al, 2000).
Especiallyin systems deployed for the general public such asthose of (Komatani et al, 2005; Raux et al, 2006),the systems need to correctly detect interpretationerrors caused by various utterances made by var-ious users, including novices.
Error detection us-ing individual user models would be a promisingway of improving performance in such systems?Currently with Graduate School of Engineering, NagoyaUniversity, Furo-cho, Chikusa-ku, Nagoya 464-8603, Japan.komatani@nuee.nagoya-u.ac.jpbecause users often access them repeatedly (Ko-matani et al, 2007).We choose to detect interpretation errors ofbarge-in utterances, mostly caused by ASR er-rors, as a task for showing the effectiveness ofthe user?s utterance histories.
We try to improvethe accuracy of classifying barge-in utterances intocorrectly and erroneously interpreted ones with-out any manual labeling.
By classifying utter-ances accurately, the system can reduce erroneousresponses caused by the errors and unnecessaryconfirmations.
Here, a ?barge-in utterance?
is auser utterance that interrupts the system?s prompt.In this situation, the system stops its prompt andstarts recognizing the user utterance.In this study, we combine the ASR confidencemeasure with features obtained from the user?s ut-terance history, i.e., the estimated ASR accuracyand the barge-in rate, to detect interpretation er-rors of barge-in utterances.
We show that the fea-tures are still effective when they are used togetherwith the ASR confidence measure, which is usu-ally used to detect erroneous ASR results.
Thecharacteristics of our method are summarized asfollows:1.
The user?s utterance history used as his/herprofile: The user?s current barge-in rate andASR accuracy are used for error detection.2.
Online user modeling: We try to obtain theuser profiles listed above without any man-ual labeling after the dialogue has been com-pleted.
This means that the system can im-prove its performance while it is deployed.In our earlier report (Komatani and Rudnicky,2009), we defined the estimated ASR accuracyand showed that it is helpful in improving the ac-curacy of classifying barge-in utterances into cor-rectly and erroneously interpreted ones, by using itin conjunction with the user?s barge-in rate.
In this289Table 1: ASR accuracy per barge-inCorrect Incorrect Total Accuracyw/o barge-in 16,694 3,612 20,306 (82.2%)w/ barge-in 3,281 3,912 7,193 (45.6%)Total 19,975 7,524 27,499 (72.6%)report, we verify our approach when the ASR con-fidence measure is also incorporated into it.
Thus,we show the individual user?s utterance history ishelpful as a user profile and works as prior infor-mation for the ASR confidence.2 Barge-in Utterance and its ErrorsBarge-in utterances were often incorrectly inter-preted mainly because of ASR errors in our dataas shown in Table 1.
The table lists the ASRaccuracy per utterance for two cases: when thesystem prompts were played to the end (denotedas ?w/o barge-in?)
and when the system promptswere barged in (?w/ barge-in?).
Here, an utter-ance is assumed to be correct only when all con-tent words in the utterance are correctly recog-nized; one is counted as an error if any word in itis misrecognized.
Table 1 shows that barge-in ut-terances amounted to 26.2% (7,193/27,499) of allutterances, and half of those utterances containedASR errors in their content words.This result implies that many false barge-ins oc-curred despite the user?s intention.
Specifically,the false barge-ins included instances when back-ground noises were incorrectly regarded as barge-ins and the system?s prompt stopped.
Such in-stances often occur when the user accesses thesystem using mobile phones in crowded places.Breathing and whispering were also prone to beincorrectly regarded as barge-ins.
Moreover, dis-fluency in one utterance may be unintentionally di-vided into two portions, which causes further mis-recognitions and unexpected system actions.
Theabovementioned phenomena, except backgroundnoises, are caused by the user?s unfamiliarity withthe system.
That is, some novice users are notunaware of the timing at which to utter, and thiscauses the system to misrecognize the utterance.On the other hand, users who have already becomeaccustomed to the system often use the barge-in functions intentionally and, accordingly, maketheir dialogues more efficient.The results in Table 2 show the relationship be-tween barge-in rate per user and the correspond-ing ASR accuracies of barge-in utterances.
WeTable 2: ASR accuracy of barge-in utterances fordifferent barge-in ratesBarge-in rate Correct Incorrect Acc.
(%)0.0 - 0.2 407 1,750 18.90.2 - 0.4 205 842 19.60.4 - 0.6 1,602 880 64.50.6 - 0.8 1,065 388 73.30.8 - 1.0 2 36 5.31.0 0 16 0.0Total 3,281 3,912 45.6here ignore a small number of users whose barge-in rates were greater than 0.8, which means al-most all utterances were barge-ins, because mostof their utterances were misrecognized becauseof severe background noises and accordingly theygave up using the system.
We thus focus on userswhose barge-in rates were less than 0.8.
The ASRaccuracy of barge-in utterances was high for userswho frequently barged-in.
This suggests that thebarge-ins were intentional.
On the other hand, theASR accuracies of barge-in utterances were lessthan 20% for users whose barge-in rates were lessthan 0.4.
This suggests that the barge-ins of theseusers were unintentional.A user study conducted by Rose andKim (2003) revealed that there are many moredisfluencies when users barge in compared withwhen users wait until the system prompt ends.Because such disfluencies and resulting utterancefragments are parts of human speech, it is difficultto select erroneous utterances to be rejected byusing a classifier that distinguishes speech fromnoise on the basis of the Gaussian Mixture Model(Lee et al, 2004).
These errors cannot be detectedby using only bottom-up information obtainedfrom single utterances such as acoustic featuresand ASR results.To cope with the problem, we use individualusers?
utterance histories as their profiles.
Morespecifically, we use each user?s average barge-inrate and ASR accuracy from the time the userstarted using the system until the current utterance.The barge-in rate intuitively corresponds to the de-gree to which the user is accustomed to using thesystem, especially to using its barge-in function.That is, this reflects the tendency shown in Table2; that is, the ASR accuracy of barge-in utterancesis higher for users whose barge-in rates are higher.Each user?s ASR accuracy also indicates the user?shabituation.
This corresponds to an empirical ten-dency that ASR accuracies of more accustomed290timeA user?sutterancescurrentUtterance historyClassification:Current utterance is?Correctly interpreted??Erroneous?2.
the user?s ASR accuracy1.
the user?s barge-in rate3.
ASR confidenceFigure 1: Overview of detecting interpretation errorsusers are higher (Komatani et al, 2007; Levow,2003).
To account for another fact that some ex-pert users have low barge-in rates, and, accord-ingly, not all expert users barge in frequently (Ko-matani et al, 2007), we use both the user?s barge-in rate and ASR accuracy to represent degree ofhabituation, and verify their effectiveness as priorinformation for detecting erroneous interpretationresults when they are used together with an ASRconfidence measure.To obtain the user?s ASR accuracy without anymanual labeling, we exploit certain dialogue pat-terns indicating that ASR results at certain po-sitions are reliable.
For example, Sudoh andNakano (2005) proposed a ?post-dialogue con-fidence scoring?
in which ASR results corre-sponding to the user?s intention upon dialoguecompletion are assumed to be correct and areused for confidence scoring.
Bohus and Rud-nicky (2007) proposed ?implicitly supervisedlearning?
in which user responses following thesystem?s explicit confirmations are used for confi-dence scoring.
If the ASR results can be regardedas reliable after the dialogue, machine learning al-gorithms can use them as teacher signals.
This ap-proach does not need any manual labeling or tran-scription, a task which requires much time and la-bor when spoken dialogue systems are being de-veloped.
We focus on users?
affirmative and neg-ative responses to the system?s explicit confirma-tions, and estimated the user?s ASR accuracy onthe basis of his or her history of responses (Ko-matani and Rudnicky, 2009).
This estimated ASRaccuracy can be also used as an online feature rep-resenting a user?s utterance history.3 Detecting Errors by using the User?sUtterance HistoryWe detect interpretation errors of barge-in utter-ances by using the following three informationsources:1. the current user?s barge-in rate,2.
the current user?s ASR accuracy, and3.
ASR confidence of the current utterance.The error detection method is depicted in Figure1.
Barge-in rate and ASR accuracy are accumu-lated and averaged from the beginning until thecurrent utterance and are used as each user?s ut-terance history.
Then, at every point a user makesan utterance, the barge-in utterances are classifiedinto correctly or erroneously interpreted ones byusing a logistic regression function:P =11 + exp(?
(a1x1+ a2x2+ a3x3+ b)),(1)where x1, x2and x3denote the barge-in rate, theASR accuracy until the current utterance, and theASR confidence measure of the current utterance,respectively.
Coefficients aiand b are determinedby 10-fold cross validation on evaluation data.
Inthe following subsections, we describe how to ob-tain these features.3.1 Barge-In RateThe barge-in rate is defined as the ratio of the num-ber of barge-in utterances to all the user?s utter-ances until the current utterance.
Note that thecurrent utterance itself is included in this calcula-tion.
We confirmed that the barge-in rate changesas the user becomes accustomed to the system291U1: 205.
(Number 100)S1: Will you use bus number 100?U2: No.
(No)S2: Please tell me your bus stop or bus route number.U3: Nishioji Matsu... [disfluency] (Rejected)S3: Please tell me your bus stop or bus route number.U4: From Nishioji Matsubara.
(From Nishioji Matsubara)S4: Do you get on a bus at Nishioji Matsubara?U5: Yes.
(Yes)Initial characters ?U?
and ?S?
denote the user and system utterance.A string in parentheses denotes the ASR result of the utterance.Figure 2: Example dialogue(Komatani et al, 2007).
To take these tempo-ral changes into consideration, we set a windowwhen calculating the rate (Komatani et al, 2008).That is, when the window width is N , the rate iscalculated on the basis of only the last N utter-ances, and utterances before those ones are dis-carded.
When the window width exceeds the totalnumber of utterances by the user, the barge-in rateis calculated on the basis of all the user?s utter-ances.
Thus, when the width exceeds 2,838, themaximum number of utterances made by one userin our data, the barge-in rates equal the averagerates of all utterances by the user.3.2 ASR AccuracyASR accuracy is calculated per utterance.
It is de-fined as the ratio of the number of correctly rec-ognized utterances to all the user?s utterances untilthe previous utterance.
Note that the current utter-ance is not included in this calculation.
The ?cor-rectly recognized?
utterance denotes a case whenevery content word in the ASR result of the ut-terance was correctly recognized and no contentword was incorrectly inserted.
The ASR accuracyof the user?s initial utterance is regarded as 0, be-cause there is no utterance before it.
We do not setany window when calculating the ASR accuracies,because classification accuracy did not improve asa result of setting one (Komatani and Rudnicky,2009).
This is because each users?
ASR accura-cies tend to converge faster than the barge-in ratesdo (Komatani et al, 2007), and the changes in theASR accuracies are relatively small in comparisonwith those of the barge-in rates.We use two kinds of ASR accuracies:1. actual ASR accuracy and2.
estimated ASR accuracy (Komatani and Rud-nicky, 2009).The actual ASR accuracy is calculated from man-ual transcriptions for investigating the upper limitof improvement of the classification accuracywhen ASR accuracy is used.
Thus, it cannot beobtained online because manual transcriptions arerequired.The estimated ASR accuracy is calculated onthe basis of the user?s utterance history.
This isobtainable online, that is, without the need formanual transcriptions after collecting the utter-ances.
We focus on users?
affirmative or negativeresponses following the system?s explicit confir-mations, such as ?Leaving from Kyoto Station.
Isthat correct??
To estimate the accuracy, we makethree assumptions as follows:1.
The ASR results of the users?
affirmative ornegative responses are correctly recognized.This assumption will be verified in Section4.2.2.
A user utterance corresponding to the contentof the affirmative responses is also correctlyrecognized, because the user affirms the sys-tem?s explicit confirmation for it.3.
The remaining utterances are not correctlyrecognized.
This corresponds to when usersdo not just say ?no?
in response to explicitconfirmations with incorrect content and in-stead use other expressions.To summarize the above, we assume that theASR results of the following utterances are cor-rect: an affirmative response, its corresponding ut-terance which is immediately preceded by it, and292Table 3: Distribution of ASR confidence measuresfor barge-in utterancesConfidence measure Correct Incorrect (%)0.0 - 0.1 0 1491 0.00.1 - 0.2 0 69 0.00.2 - 0.3 0 265 0.00.3 - 0.4 0 708 0.00.4 - 0.5 241 958 20.10.5 - 0.6 639 333 65.70.6 - 0.7 1038 68 93.90.7 - 0.8 1079 20 98.20.8 - 0.9 284 0 100.00.9 - 1.0 0 0 ?Total 3281 3912 45.6a negative response.
All other utterances are as-sumed to be incorrect.
We thus calculate the user?sestimated ASR accuracy as follows:(Estimated ASR accuracy)=2 ?
(#affirmatives) + (#negatives)(#all utterances) (2)Here is an example of the calculation for the ex-ample dialogue shown in Figure 2.
U2 is a neg-ative response, and U5 is an affirmative response.When the dialogue reaches the point of U5, U2and U5 are regarded as correctly recognized on thebasis of the first assumption.
Next, U4 is regardedas correct on the basis of the second assumption,because the explicit confirmation for it (S4) wasaffirmed by the user as U5.
Then, the remainingU1 and U3 are regarded as misrecognized on thebasis of the third assumption.
As a result, the esti-mated ASR accuracy at U5 is 60%.The estimated ASR accuracy is updated for ev-ery affirmative or negative response by the user.For a neither affirmative nor negative response, thelatest estimated accuracy before it was used in-stead.3.3 ASR Confidence MeasureWe use an ASR confidence measure calculated perutterance.
Specifically, we use the one derivedfrom the ASR engine in the Voice Web Server, aproduct of Nuance Communications, Inc.1Table 3 shows the distribution of ASR confi-dence measures for barge-in utterances.
By us-ing this ASR confidence, even a naive method canhave high classification accuracy (90.8%) in whichjust one threshold (?
= 0.516) is set and utter-ances whose confidence measure is greater than1http://www.nuance.com/Table 4: ASR accuracy by user response typeCorrect Incorrect Total (Acc.
)Affirmative 9,055 243 9,298 (97.4%)Negative 2,006 286 2,292 (87.5%)Other 8,914 6,995 15,909 (56.0%)Total 19,975 7,524 27,499 (72.6%)the threshold are accepted.
This accuracy is re-garded as the baseline.4 Experimental Evaluation4.1 DataWe used data collected by the Kyoto City Bus In-formation System (Komatani et al, 2005).
Thissystem locates a bus that a user wants to ride andtells the user how long it will be before the busarrives.
The system was accessible to the publicby telephone.
It adopted the safest strategy to pre-vent erroneous responses; that is, it makes explicitconfirmations for every user utterance except foraffirmative or negative responses such as ?Yes?
or?No?.We used 27,499 utterances that did not involvecalls whose phone numbers were not recorded orthose the system developer used for debugging.The data contained 7,988 valid calls from 671users.
Out of these, there were 7,193 barge-in ut-terances (Table 1).
All the utterances were manu-ally transcribed for evaluation; human annotatorsdecided whether every content word in the ASRresults was correctly recognized or not.The phone numbers of most of the calls wererecorded, and we assumed that each number cor-responded to one individual.
Most of the numberswere those of mobile phones, which are usuallynot shared; thus, the assumption seems reasonable.4.2 Verifying Assumption in CalculatingEstimated ASR AccuracyWe confirmed our assumption that the ASR re-sults of affirmative or negative responses follow-ing explicit confirmations are correct.
We clas-sified the user utterances into affirmatives, nega-tives, and other, and calculated the ASR accura-cies (precision rates) per utterance as shown in Ta-ble 4.
Affirmatives include hai (?yes?
), soudesu(?that?s right?
), OK, etc; and negatives include iie(?no?
), chigaimasu (?I don?t agree?
), dame (?Nogood?
), etc.
The table indicates that the ASR ac-curacies of affirmatives and negatives were high.One of the reasons for the high accuracy was that29300.10.20.30.40.50.60.70.80.910  0.2  0.4  0.6  0.8  1EstimatedASRAccuracyActual ASR AccuracyFigure 3: Correlation between actual and esti-mated ASR accuracythese utterances are much shorter than other con-tent words, so they were less confused with othercontent words.
Another reason was that the systemoften gave help messages such as ?Please answeryes or no.
?We then analyzed the correlation between theactual ASR accuracy and the estimated ASR accu-racy based on Equation 2.
We plotted the two ASRaccuracies (Figure 3) for 26,231 utterances madeafter at least one affirmative/negative response bythe user.
The correlation coefficient between themwas 0.806.
Although the assumption that all ASRresults of affirmative/negative responses are cor-rect might be rather strong, the estimated ASR ac-curacy had a high correlation with the actual ASRaccuracy.4.3 Comparing Classification AccuraciesWhen the Used Features VaryWe investigated the classification accuracy of the7,193 barge-in utterances.
The classification accu-racies are shown in Table 5 in descending order forvarious sets of features xiused as input into Equa-tion 1.
The conditions for when barge-in rates areused also show the window width w for the high-est classification accuracy.
The mean average er-ror (MAE) is also listed, which is the average ofthe differences between an output of the logisticregression function Xjand a reference label man-ually given X?j(0 or 1):MAE =1mm?j|X?j?
Xj|, (3)where m denotes the total number of barge-in ut-terances.
This indicates how well the output of9090.59191.59292.51 10 100 1000ClassificationAccuracy[%]Window width (# utterance)(1) actual ASR + barge-in + CM(2) estimated ASR + barge-in + CM(4) barge-in + CM(6) only CMFigure 4: Classification accuracy when windowwidth varies used to calculate barge-in ratethe logistic regression function (Equation 1) dis-tributes.
Regarding Condition (12) in Table 5 (ma-jority baseline), the MAE was calculated by as-suming Xj= 0.456, which is the average ASRaccuracy, for all j.
Its classification accuracy isthe majority baseline; that is, all interpretation re-sults are regarded as incorrect.4.4 Experimental ResultsThe results are shown in Table 5.
First, we can seethat the classification accuracies for Conditions (1)to (6) are high because the ASR confidence mea-sure (CM) works well (Table 3).
The MAEs arealso small, which means the outputs of the logis-tic regression functions are good indicators of thereliability of the interpretation result.Upon comparing Condition (6) with Conditions(1) to (5), we can see that the classification accura-cies improve as a result of incorporating the user?sutterance histories such as barge-in rates and ASRaccuracies.
Table 6 lists p-values of the differenceswhen the barge-in rate and the estimated ASR ac-curacy were used in addition to the CM.
The sig-nificance test was based on the McNemar test.
Asshown in the table, all the differences were statisti-cally significant (p < 0.01).
That is, it was exper-imentally shown that these utterance histories ofusers are different information sources from thoseof single utterances and that they contribute toimproving the classification accuracy even whenused together with ASR confidence measures.
Therelative improvement in the error reduction ratewas 15.2% between Conditions (2) and (6), that is,by adding the barge-in rate and the estimated ASRaccuracy, both of which can be obtained withoutmanual labeling.294Table 5: Best classification accuracy for each condition and optimal window widthConditions Window Classification MAE(features used) width accuracy (%)(1) CM + barge-in rate + actual ASR acc.
w=40 92.6 0.112(2) CM + barge-in rate + estimated ASR acc w=30 92.2 0.119(3) CM + actual ASR acc.
- 91.7 0.121(4) CM + barge-in rate w=30 91.6 0.126(5) CM + estimated ASR acc.
- 91.2 0.128(6) CM - 90.8 0.134(7) barge-in rate + actual ASR acc.
w=50 80.0 0.312(8) barge-in rate + estimated ASR acc.
w=50 77.7 0.338(9) actual ASR acc.
- 72.8 0.402(10) barge-in rate w=30 71.8 0.404(11) estimated ASR acc.
- 57.6 0.431(12) majority baseline - 54.4 0.496CM: confidence measureMAE: mean absolute errorTable 6: Results of significance testCondition pair p-value(2) vs (4) 0.00066(2) vs (5) 0.00003(4) vs (6) 0.00017(5) vs (6) 0.00876Figure 4 shows the results in more detail; theclassification accuracies for Conditions (1), (2),(4), and (6) are shown for various window widths.Under Condition (6), the classification accuracydoes not depend on the window width because thebarge-in rate is not used.
Under Conditions (1),(2), and (4), the accuracies depend on the windowwidth for the barge-in rate and are highest whenthe width is 30 or 40.
These results show the effec-tiveness of the window, which indicates that tem-poral changes in user behaviors should be takeninto consideration, and match those of our earlierreports (Komatani et al, 2008; Komatani and Rud-nicky, 2009): the user?s utterance history becomeseffective after he/she uses the system about tentimes because the average number of utterancesper dialogue is around five.By comparing Conditions (2) and (4), we cansee that the classification accuracy improves af-ter adding the estimated ASR accuracy to Condi-tion (4).
This shows that the estimated ASR accu-racy also contributes to improving the classifica-tion accuracy.
By comparing Conditions (1) and(2), we can see that Condition (1), in which the ac-tual ASR accuracy is used, outperforms Condition(2), in which the estimated one is used.
This sug-gests that the classification accuracy, whose upperlimit is Condition (1), can be improved by makingthe ASR accuracy estimation shown in Section 3.2more accurate.5 ConclusionWe described a method of detecting interpretationerrors of barge-in utterances by exploiting the ut-terance histories of individual users, such as theirbarge-in rate and ASR accuracy.
The estimatedASR accuracy as well as the barge-in rate andthe ASR confidence measure is obtainable online.Thus, the detection method does not require man-ual labeling.
We showed through experiments thatthe utterance history of each user is helpful for de-tecting interpretation errors even when the ASRconfidence measure is used.The proposed method is effective in systemsthat are repeatedly used by the same user over 10times, as indicated by the results of Figure 4.
It isalso assumed that the user?s ID is known (we usedtheir telephone number).
The part of our methodthat estimates the user?s ASR accuracy assumesthat the system?s dialogue strategy is to make ex-plicit confirmations about every utterance by theuser and that all affirmative and negative responsesfollowed by explicit confirmations are correctlyrecognized.
Our future work will attempt to re-duce or remove these assumptions and to enhancethe generality of our method.
The experimental295result was shown only in the Kyoto City Bus do-main, in which dialogues were rather well struc-tured.
Experimental evaluations in other domainswill assure the generality.AcknowledgmentsWe are grateful to Prof. Tatsuya Kawahara of Ky-oto University who led the Kyoto City Bus Infor-mation System project.
The evaluation data usedin this study was collected during the project.
Thisresearch was partly supported by Grants-in-Aidfor Scientific Research (KAKENHI).ReferencesDanBohus andAlexander Rudnicky.
2007.
Implicitly-supervised learning in spoken language interfaces:an application to the confidence annotation problem.In Proc.
SIGdial Workshop on Discourse and Dia-logue, pages 256?264.Timothy J. Hazen, Theresa Burianek, Joseph Polifroni,and Stephanie Seneff.
2000.
Integrating recognitionconfidence scoring with language understanding anddialogue modeling.
In Proc.
Int?l Conf.
Spoken Lan-guage Processing (ICSLP), pages 1042?1045, Bei-jing, China.Kazunori Komatani and Tatsuya Kawahara.
2000.Flexible mixed-initiative dialogue management us-ing concept-level confidence measures of speechrecognizer output.
In Proc.
Int?l Conf.
Computa-tional Linguistics (COLING), pages 467?473.Kazunori Komatani and Alexander I. Rudnicky.2009.
Predicting barge-in utterance errors by usingimpricitly-supervised asr accuracy and barge-in rateper user.
In Proc.
ACL-IJCNLP, pages 89?92.Kazunori Komatani, Shinichi Ueno, Tatsuya Kawa-hara, and Hiroshi G. Okuno.
2005.
User modelingin spoken dialogue systems to generate flexible guid-ance.
User Modeling andUser-Adapted Interaction,15(1):169?183.Kazunori Komatani, Tatuya Kawahara, and Hiroshi G.Okuno.
2007.
Analyzing temporal transition ofreal user?s behaviors in a spoken dialogue sys-tem.
In Proc.
Annual Conference of the Interna-tional Speech Communication Association (INTER-SPEECH), pages 142?145.Kazunori Komatani, Tatuya Kawahara, and Hiroshi G.Okuno.
2008.
Predicting asr errors by exploitingbarge-in rate of individual users for spoken dialoguesystems.
In Proc.
Annual Conference of the Interna-tional Speech Communication Association (INTER-SPEECH), pages 183?186.Akinobu Lee, Keisuke Nakamura, Ryuichi Nisimura,Hiroshi Saruwatari, and Kiyohiro Shikano.
2004.Noice robust real world spoken dialogue system us-ing GMM based rejection of unintended inputs.
InProc.
Int?l Conf.
Spoken Language Processing (IC-SLP), pages 173?176.Gina-Anne Levow.
2003.
Learning to speak to a spo-ken language system: Vocabulary convergence innovice users.
In Proc.
4th SIGdial Workshop on Dis-course and Dialogue, pages 149?153.Diane J. Litman, Marilyn A. Walker, and Michael S.Kearns.
1999.
Automatic detection of poor speechrecognition at the dialogue level.
In Proc.
AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 309?316.Antoine Raux, Dan Bohus, Brian Langner, Alan W.Black, and Maxine Eskenazi.
2006.
Doing researchon a deployed spoken dialogue system: One year ofLet?s Go!
experience.
In Proc.
Int?l Conf.
SpokenLanguage Processing (INTERSPEECH).Richard C. Rose and Hong Kook Kim.
2003.
A hy-brid barge-in procedure for more reliable turn-takingin human-machine dialog systems.
In Proc.
IEEEAutomatic Speech Recognition and UnderstandingWorkshop (ASRU), pages 198?203.Katsuhito Sudoh and Mikio Nakano.
2005.
Post-dialogue confidence scoring for unsupervised statis-tical language model training.
Speech Communica-tion, 45:387?400.Marilyn Walker, Irene Langkilde, Jerry Wright, AllenGorin, and Diane Litman.
2000.
Learning to predictproblematic situations in a spoken dialogue system:Experiments with How May I Help You?
In Proc.North American Chapter of Association for Compu-tational Linguistics (NAACL), pages 210?217.296
