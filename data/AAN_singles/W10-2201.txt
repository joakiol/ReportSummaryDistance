Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 1?8,Uppsala, Sweden, 15 July 2010.c?2010 Association for Computational LinguisticsInstance-based acquisition of vowel harmonyFr?ed?eric MailhotInstitute of Cognitive ScienceCarleton UniversityOttawa, ON, Canadafmailhot@connect.carleton.caAbstractI present LIBPHON, a nonparametricregression-based model of phonologi-cal acquisition that induces a gener-alised and productive pattern of vowelharmony?including opaque and transpar-ent neutrality?on the basis of simplifiedformant data.
The model quickly learns togenerate harmonically correct morpholog-ically complex forms to which it has notbeen exposed.1 Explaining phonological patternsHow do infants learn the phonetic categoriesand phonotactic patterns of their native lan-guages?
How strong are the biases that learn-ers bring to the task of phonological acquis-tion?
Phonologists from the rationalist traditionthat dominated the past half-century of linguis-tic research typically posit strong biases in ac-quisition, with language learners using innately-given, domain-specific representations (Chomskyand Halle, 1968), constraints (Prince and Smolen-sky, 2004) and learning algorithms (Tesar andSmolensky, 2000; Dresher, 1999) to learn abstractrules or constraint rankings from which they canclassify or produce novel instances.In the last decade, however, there has been ashift toward empiricist approaches to phonologi-cal acquisition, use and knowledge.
In this liter-ature, eager learning algorithms (Aha, 1997), inwhich training data are used to update intensionalrepresentations of functions or categories then dis-carded, have been the norm.1However, researchin related fields?particularly speech perception?indicates that speakers?
knowledge and use oflanguage, both in production and comprehen-sion, is at least partly episodic, or instance-based(Goldinger, 1996; Johnson, 1997).
Additionally,1Daelemans et al (1994) is a notable exception.motivation for instance-based models of categori-sation has a lengthy history in cognitive psychol-ogy (Medin and Schaffer, 1978), and these meth-ods are well-known in the statistical and machinelearning literature, having been studied for overhalf a century (Fix and Hodges, 1951; Cover andHart, 1967; Hastie et al, 2009).
Consequently, itseems a worthy endeavour applying an instance-based method to a problem that is of interest totraditional phonologists, the acquisition and useof vowel harmony, while simultaneously effectinga rapprochement with adjacent disicplines in thecognitive sciences.
In sections 2 and 3 I give somebrief background on vowel harmony and instance-based models, respectively.
Section 4 introducesmy model, LIBPHON, and section 5 the languagesit learns.
I discuss some simulations and results insection 6, and conclude in section 7.2 Vowel harmonyVowel harmony is a phonological phenomenon inwhich there are co-occurrence constraints on vow-els within words.2The vowels in a language withvowel harmony can be classified into disjoint sets,such that words contain vowels from only one ofthe sets.
The Finnish system of vowel harmony ex-emplified by the forms in Table 1 provides a stan-dard example from the literature (van der Hulstand van de Weijer, 1995).surface form glossa.
tuhmasta ?naughty?
(elative)b. tu?hma?sta?
?stupid?
(elative)Table 1: Finnish backness harmonyCrucially, the elative case marker alternatessystematically between front and back vowel2?Word?
is used pre-theoretically here; harmony can oc-cur over both supra- and sublexical domains.1variants?as -st?a or -sta?depending on whetherthe stem has front {?u, ?a} or back {u, a} vowels.2.1 Neutral vowelsIn most languages with vowel harmony, there areone or more vowels that systematically fail toalternate.
These are called neutral vowels, andare typically further subclassified according towhether or not they induce further harmonic al-ternations in other vowels.3 Instance-based modelsInstance-based approaches to cognitive process-ing, also called memory-based, case-based, andexemplar-based models, have their modern originsin psychological theories and models of percep-tual categorisation and episodic memory (Medinand Schaffer, 1978; Nosofsky, 1986), althoughthe earliest explicit discussion seems to be (Se-mon, 1921); a theory of memory that anticipatesmany features of contemporary models.
The corefeatures of these models are: (i) explicit stor-age/memorisation (viz.
extensional representa-tion) of training data, (ii) classification/processingof novel data via similarity-based computation,and (iii) lazy evaluation (Aha, 1997), wherebyall computations are deferred until the model isqueried with data.3Instance-based models were introduced to lin-guistics via research in speech perception suggest-ing that at least some aspects of linguistic perfor-mance rely on remembered experiential episodes(Johnson and Mullenix, 1997).
The models imple-mented to date in phonetics and phonology havelargely focused on perception (e.g.
speaker nor-malisation in Johnson (1997)), or on diachronicprocesses (e.g.
lenition in Pierrehumbert (2001),chain shifts in Ettlinger (2007)), leaving the typesof phenomena that typically interest ?traditional?phonologists, viz.
productive, generalised pat-terns, comparatively neglected.44 LIBPHONLIBPHON, the Lazy Instance-based Phonologist,is a lazy learning algorithm whose purpose (in the3Compare eager learners, e.g.
connectionist systems,which build a global intensional representation of the func-tion being learned on the basis of training data which are sub-sequently discarded.4Kirchner and Moore (2009) give a model of a syn-chronic lenition process, and Daelemans and colleaguesgive memory-based analyses of several linguistic phenomena(Daelemans and van den Bosch, 2005).context of the simulations described here) is tomodel an instance-based approach to the core as-pects of the acquisition and subsequent productiveusage of vowel harmony.4.1 Decisions & mechanismsAs discussed in (Johnson, 2007), there are somedecisions that need to be made in implementing aninstance-based model of phonological knowledgeinvolving the basic units of analysis (e.g.
theirsize), the relevant type of these units (e.g.
discreteor continuous), and the mechanisms for similarity-matching and activation spread in the lexicon.Units The arguments given by Johnson (2007)and V?alimaa-Blum (2009) for the ?word-sized?
(rather than e.g.
segmental) experience of lan-guage, suggest that ?words?
are the correct basicunit of analysis in instance-based langugage mod-els (a fortiori in LIBPHON).
Stronger evidencecomes from the wealth of psycholinguistic data(reviewed in (Lodge, 2009)) showing that illiter-ates and literates of non-alphabetic writing sys-tems have poor phonemic (or at least segmental)awareness, both in monitoring and manipulation.On this basis, I take meaning-bearing unanalysedacoustic chunks to be the relevant units of repre-sentation for LIBPHON.5Feature type Having determined the size ofLIBPHON?s basic unit, I move now to its em-bedding space, where distinctive features presentthemselves as obvious candidate dimensions.Since the middle of the 20thcentury (ca.
Chom-sky and Halle (1968)), phonological theories havenearly all supposed that lexical representations arestored in terms of articulatory features (cf.
(Halle,1997) for explicit discussion of this viewpoint).Coleman (1998), citing evidence from the neuro-scientific and psycholinguistic literatures on lexi-cal representation, claims that evidence for this po-sition (e.g.
from speech perception and phonememonitoring experiments) is weak at best, and thatlexical representations are more likely to be acous-tic than articulatory.
In addition, Phillips et al(2000) review neurolinguistic evidence for the roleof acoustic cortex in phonetics and phonology, and5The assumption that word-level segmentation of thespeech signal is available to the language learner prior to ac-quisition of phonological phenomena is relatively uncontro-versial, although there is evidence for the development of atleast some phonotactic knowledge prior to the emergence ofa productive lexicon (Jusczyk, 1999).2Mielke (2008) discusses several aspects of the in-duction of distinctive phonological features fromacoustic representations.
Recognising that the is-sue is far from resolved, for the purposes of thesimulations run here, I take LIBPHON?s instancespace to be acoustically-based, and use formantvalues as the embedding dimension.
Vowels arespecified by their midpoint formant values,6andconsonants are specified by so-called ?locus?
val-ues, which can be identified by inspecting the tra-jectories of consonant-vowel transitions in speech(Sussman et al, 1998).
Since I am modellingpalatal harmony in particular, and F2 magnitude isthe primary acoustic correlate of vowel palatality, Iomit F3 and F4, restricting LIBPHON?s acousticrepresentations to sequences of (F1, F2) values,henceforth trajectories.Similarity Given that LIBPHON?s instance-space is continuous, and has a fairly intuitivemetric, I take simple Euclidean distance to beLIBPHON?s similarity (or rather, dissimilarity)function.7Fixed-rate representations For the simulationsdescribed here, I use fixed-rate trajectories, inwhich consonants and vowels are representedin a temporally coarse-grained manner with sin-gle (F1, F2) tuples.
Evidently, consonants andvowels in actual human speech unfold in time,but modelling segments at this level introducesthe problem of temporal variability; repeated to-kens of a given word?both within and acrossspeakers?vary widely in duration.
This variabil-ity is one of the main obstacles in the develop-ment of instance-based models of speech produc-tion, due to the difficulty of aligning variable-length forms.
Although algorithms exist for align-ing variable-length sequences, these require cog-nitively implausible dynamic programming al-gorithms, e.g.
dynamic time warping (DTW)6A reviewer asks about the psychological plausibility ofHz-based formant represetations and the choice of point val-ues for vowel and consonant representations, e.g.
rather thanformant values at 20% and 80% of the vowel.
These arepurely in the interests of simplicity for the work reportedhere.
As discussed below, future work with real speech ex-emplars in psychophysically-motivated representational for-mats, e.g.
perceptual linear predictive coding (Hermansky,1990), will render this issue moot.7Often the measure of similarity in an instance-basedmodel is an exponential function of distance, d(xi, xj) of theform exp(?cd(xi, xj)), so that increasing distance yields de-creasing similarity (Nosofsky, 1986).
The Euclidean measurehere is sufficient for the purpose at hand, although the shapeof the similarity measure is ultimately an empirical question.and hidden Markov models (Rabiner and Juang,1993).
Even as proofs of concept, these maybe empirically inadequate; Kirchner and Moore(2009) use DTW to good effect in an instance-based production model of spirantisation usingreal, temporally variable, speech signals.
How-ever, their inputs were all the same length in termsof segmental content, and the model was only re-quired to generalise within a word type.
I amcurrently investigating whether DTW can func-tion as a proof of concept in a problem domainlike that addressed here, which involves learn-ing about variably-sized ?pieces?
of morphologyacross class labels.4.2 Perception/categorisationLIBPHON?s method of perception/categorisationof inputs is a relatively standard nearest-neighbour-based classification algorithm.
See Al-gorithm 1 for a description in pseudocode.Algorithm 1 PERCEIVE(input, k)Require: input as (LABEL ?
[LEX](PL)[NOM |ACC], instance ?
Z2x{8,10,12}), k ?
Zif LABEL is not empty thenif LABEL /?
lexicon thenCreate LABEL in lexiconend ifAssociate(instance, LABEL)elseneighbours ?
k-nearest neighbours ofinstanceLABEL ?
majority class label ofneighboursAssociate(instance,LABEL)end ifIf LABEL is not empty, LIBPHON checks its lex-icon to see whether it knows the word being pre-sented to it, i.e.
whether it exists as a class label.If so, it simply appends the input acoustic form tothe set of forms associated with the input mean-ing/label.
If it has no corresponding entry, a newlexical entry is created for the input meaning, andthe input trajectory is added as its sole associatedacoustic form.If LABEL is empty, LIBPHON assignsinstance to the majority class of its knearest neighbours in acoustic space.34.3 ProductionIn production, LIBPHON is provided with a LA-BEL and has to generate a suitable instance forit.
LABELs are decomposable, signalling an ar-bitrary ?lexical?
meaning, an optional plural mor-pheme, PL, and an obligatory case marker from{NOM, ACC}.
Thus, there are several differentpossibilities to consider in generating output forsome queried meaning.In the two simplest cases, either the full queriedmeaning (viz.
lexical label with all inflections)is already in the lexicon, or else there are noclass LABELs with the same lexical meaning (i.e.LIBPHON is being asked to produce a word that itdoesn?t know).
In the former case, a stored trajec-tory is uniform8randomly selected from the list ofacoustic forms associated with the queried label asa seed token, the entire set of associated acousticforms is used as the analogical set, and an outputis generated by taking a distance-weighted meanover the seed?s k nearest neighbours.9In the casewhere the lexical meaning of the queried LABELis unknown, the query is ignored.In the more interesting cases, LIBPHON has aLABEL in its lexicon with the same lexical mean-ing, but with differing inflectional specification.Consider the case in which LIBPHON knows onlythe singular NOM form of a query label that isspecified as PL ACC.
A seed instance is (uni-form) randomly selected from the set of trajec-tories associated to the NOM entry in the agent?slexicon, as this is the only entry with the corre-sponding lexical meaning, and it is a variant of thismeaning that LIBPHON must produce.
In this casethe analogical set, the set of instances from whichthe final output is computed, is composed of theseed?s nearest neighbours in the set of all trajec-tories associated with LABELs of the form [LEXPL ACC].
Once again, the output produced is adistance-weighted mean of the analogical set.This general procedure (viz.
seed from a knownitem with same lexical meaning, analogical setfrom all items with desired inflection) is carriedout in parallel cases with all other possible LA-BEL mismatches, e.g.
a singular LABEL queried,8Exemplar models often bias the selection of seed to-kens with degrees of ?activation?
that take into account re-cency and frequency.
Although the results discussed belowshow that this is not necessary for ultimate attainment, it islikely that this kind of bias will need to be incorporated intoLIBPHON to accurately model more nuanced aspects of theacquisition path.9k = 5 for all results reported here.but only a plural LABEL in the lexicon, a NOMquery with only an ACC form in the lexicon, etc.In the cases where the lexicon contains multipleentries with the same lexical meaning, but not thequery, the seed is selected from the LABEL withthe closest ?semantic?
match.
Algorithm 2 givespseudocode for LIBPHON?s production algorithm.Algorithm 2 PRODUCE(LABEL, k)Require: LABEL?
[LEX](PL)[NOM | ACC], k ?Zif LABEL ?
lexicon thenseed ?
uniform random selection frominstances associated to LABELcloud?
all instances associated to LA-BELelse if ?
LABEL??
lexicon s.t.
lex(LABEL?)
=lex(LABEL) thenseed ?
uniform random selection frominstances associated to LABEL?
)cloud ?
all instances associated toplural(LABEL) ?
case(LABEL)elsepassend ifneighbours?
k-nearest neighbours of seed incloudreturn distance-weighted mean of neighbours4.4 Production as regressionThe final steps in LIBPHON?s production algo-rithm, finding the analogical set and computing theoutput as a weighted average, together constitutea technique known in the statistical learning lit-erature as kernel-smoothed nearest-neighbour re-gression, and in particular are closely related to thewell-known Nadaraya-Watson estimator (Hastie etal., 2009):?f(x) =?Ni=1K?
(x, xi)yi?Ni=1K?
(x, xi)with inverse-distance as the kernel smoother, K,and the bandwidth function, h?
(x) determined bythe number k of nearest neighbours.
This link tothe statistical learning literature puts LIBPHON onsound theoretical footing and opens the door to avariety of future research paths, e.g.
experiment-ing with different kernel shapes, or formal analysisof LIBPHON?s expected error bounds.45 The languagesOn the view taken here, phonological knowledgeis taken to emerge from generalisation over lexicalitems, and so the key to acquiring some phono-logical pattern lies in learning a lexicon (Jusczyk,2000).
Consequently, the languages learned inLIBPHON abstract away from sentence-level phe-nomena, and the training data are simply labelledformant trajectories, (LABEL, instance).In order to get at the essence of the problem (viz.the acquisition of vowel harmony as characterisedby morphophonological alternations), and in theinterests of computational tractability/efficiency,the artificial languages learned by LIBPHON arehighly simplified, displaying only enough struc-ture to capture the phenomena of interest.5.1 Phonological inventoryThe phonological inventory consists of three con-sonants, {b, d, g}, and four vowels?two with highF2 and two with low F2?which I label {i, e, u,o}, for convenience.10The formant values usedwere generated from formant synthesis equationsin (de Boer, 2000), and from the locus equationsfor CV-transitions in (Sussman et al, 1998).5.2 Lexical itemsLIBPHON?s lexicon is populated with instancetrajectories consisting of four-syllable11?roots?with zero, one or two one-syllable ?affixes?.
Thesetrajectories have associated class labels, whichfrom a formal point of view are contentless in-dices.
Rather than employing e.g.
natural num-bers as labels, I use character strings which corre-spond more or less to the English pronounciationsof their associated trajectories.
LABELs func-tion, metaphorically-speaking, as ?meanings?.These are compositional, comprising a ?lexicalmeaning?
(arbitrary CVCVCVCV string from thephoneme set listed above), one of two obligato-rily present ?case markers?
(NOM|ACC), and anoptionally present ?plural marker?
(PL).
Hence,word categories in the artificial languages come infour forms, NOM-SG, NOM-PL, ACC-SG, and ACC-PL.10Because LIBPHON?s representations lack F3, the pri-mary acoustic correlate of rounding, the back vowels wouldbe more standardly represented as /7, W/, but these are com-paratively uncommon IPA symbols, so we will use the sym-bols for the rounded variants.
Nothing in the results or dis-cussion hinges on this.11All syllables are CV-shaped.0 2 4 6 8 10 12050010001500200025003000GIDEGEBI NOMgidegebiF1F20 2 4 6 8 10 12050010001500200025003000GIDEGEBI ACCgidegebibeF1F2Figure 1: Graphical representation of singularforms of GIDEGEBI, as produced by teacher agentFigure 1 gives examples of the singular NOMand ACC forms of a high-F2 word.
The NOM-labelled trajectory has no suffixal morphology, andcorresponds to a bare form.
The trajectory is eightsegments long,12and the vowels in this case haveall high F2 (as in lexical front/back vowel har-mony).13Note also that ACC is realised with highF2, in agreement with the root vowels.5.3 Neutral vowelsThe harmony processes seen thus far are in somesense ?local?, being describable in terms of voweladjacency e.g.
adjacency on a hypothesised au-tosegmental tier (although the presence of inter-vening consonants still renders the harmony pro-cess ?nonlocal?
in some more concrete articula-tory sense).
One of the hallmarks of vowel har-mony, as discussed in subsection 2.1, is the phe-nomenon of neutral vowels.
These vowels fail toalternate, and may or may not induce harmonic al-ternations in vowels that precede or follow them.To introduce a neutral vowel, I added a categorylabel, PL, whose realisation corresponds roughlyto [gu], and which is treated as being either opaqueor transparent in the simulations described below.Figures 2 and 3 show the ?plural inflected?forms of the same root as in 1.
We see that the12The even-numbered indices on the x-axis correspond toconsonants and the odd-numbered indices, the ?pinches?
inthe graphs, correspond to vowels.13The languages LIBPHON learns have only harmonicsingular forms.
This is unrealistic, as speakers of vowelharmony languages typically have some exceptional dishar-monic forms in their lexicons.
The effect of these forms onLIBPHON?s performance is currently being investigated.5realisation of PL has fixed, low F2, and that therealisation of ACC has alternating F2, which real-isations corresponding roughly to [be] (high F2)and [bo] (low F2).Figure 2: Graphical representation of plural formsof GIDEGEBI, as produced by teacher agent, withopaque PL realisation.0 2 4 6 8 10 12050010001500200025003000GIDEGEBI NOMgidegebiguF1F20 2 4 6 8 10 12050010001500200025003000GIDEGEBI ACCgidegebigubeF1F2Figure 3: Graphical representation of plural formsof GIDEGEBI, as produced by teacher agent, withtransparent PL realisation.These figures also illustrate the difference be-tween languages with opaque versus transparentPL, as reflected in the realisation of the word-finalACC marker in the two lower graphs, which agreesin F2 with the realised form of the PL or root, re-spectively.6 The experimentsAssessing successful learning/generalisation in acomputational model requires some measurableoutcome that can be tracked over time.
BecauseLIBPHON is an output-oriented model, its cate-gorisation of inputs is a poor indicator of the ex-tent to which it has learned a productive ?rule?
ofvowel harmony.
In lieu of this measure, I haveopted to pursue two difference courses of evalua-tion.For the harmony cases, LIBPHON is queried ona held-out test set of 500 previously unseen LA-BELs and its output is compared to the mean valueof the teacher?s stored trajectories for the same LA-BELs.
In particular, given some LABEL which wasnot in the training data, we can query LIBPHONat various stages of acquisition (viz.
with lexiconsof increasing size) by having it produce an outputfor that LABEL, and track the change in its perfor-mance over time.The actual measure of error taken is the root-mean-squared deviation between the learner?s out-put, y and the mean, t, of the teacher?s storedforms for some label, l, over all of the consonantsand vowels within a word, averaged across the re-maining unseen items of the test set:RMSE =1N?l?lex??i(ti?
yi)2len(t)Figures 4 and 5 show RMSE vs. lexicon sizefor both opaque and transparent neutrality (cf.
thecases in Figures 2 and 3), for five simulation runseach.
We can see clearly that error drops as thelexicon grows, hence that LIBPHON is learning tomake its outputs more like those of the teacher,but the informativity of this measure stops there.From a linguistic point of view, we are interestedin what LIBPHON?s outputs look like, viz.
has itlearned vowel harmony?Figure 4: RMSE 1000-word lexicon.
Opaque neu-trality.60 10 20 30 40 50 60 70 80 90 100 110 120Lexicon size/103004005006007008009001000RMSEperwordLearner 0Learner 1Learner 2Learner 3Learner 4Figure 5: RMSE 1000-word lexicon.
Transparentneutrality.Figures 6 and 7 show that vowel harmony islearned, and moreover quite quickly, after goingthrough a brief initial phase of spurious outputs.
Inthese figures, LIBPHON is being asked to produceoutputs for all forms of the label GUBOGOBU.
Forthe particular run shown here, at the 10-word stage(i.e.
when LIBPHON had seen tokens from 10 la-bels), the only tokens marked PL-ACC were fromhigh F2 (?front?)
trajectories.
Hence the nearestneighbour calculation in the production algorithmresulted in a fronted form being output.
Althoughacquisition research in vowel harmony languagesis relatively rare, or inaccessible to us due to lan-guage barriers, what research there is seems to in-dicate that harmony is mastered very quickly, withvirtually no errors by 2 years of age, hence it is un-clear what status to assign to output patterns likethe one discussed here.
Moreover, given the well-known facts that (i) comprehension precedes pro-duction, and (ii) infants avoid saying unfamiliarwords, it is unlikely that an infant could be coaxedinto producing an output form for such an early-stage class.7 Discussion and future workThe experiments discussed here show that on thebasis of limited input data, LIBPHON, an instance-based learner that produces output via kernel-smoothed nearest-neighbour regression, learns toproduce harmonically correct novel outputs.
Inparticular, it is able to generalise and produce cor-rect morphologically complex forms to which ithas not been exposed in its training data, i.e.
apreviously unseen case-marked form will be out-put with harmonically correct F2, including neu-trality (opaque or transparent).
In ongoing re-0 2 4 6 8 10 1205001000150020002500 NOMACCPL NOMPL ACCFigure 6: Evolution of gubogobu in early acqui-sition: 10 wordsFigure 7: Evolution of gubogobu in early acqui-sition: 30 wordssearch I am (i) evaluating LIBPHON?s perfor-mance with respect to more traditional measures,in particular F -score, on held-out data as the lexi-con grows, and (ii) assessing the viability of DTW-based alignment for preprocessing real speech to-kens as inputs to LIBPHON.AcknowledgmentsMany thanks to Ash Asudeh, Lev Blumenfeld,Andrea Gormley, Jeff Mielke, Alan Hogue andAndy Wedel for discussion and comments on thisline of research, and to three anonymous refereesfor feedback that greatly improved this paper.
Thiswork carried out with the support of NSERC Dis-covery Grant 371969 to Dr. Ash Asudeh.ReferencesDavid Aha.
1997.
Lazy learning.
In Lazy Learning,pages 7?10.
Kluwer Academic Publishers.7Noam Chomsky and Morris Halle.
1968.
The SoundPattern of English.
Harper and Row.John Coleman.
1998.
Cognitive reality and the phono-logical lexicon: A review.
Journal of Neurolinguis-tics, 11(3):295?-320.Thomas Cover and Peter Hart.
1967.
Nearest neighborpattern classification.
IEEE Transactions on Infor-mation Theory, 13:21?27.Walter Daelemans and Antal van den Bosch.
2005.Memory-Based Language Processing.
Studies inNatural Language Processing.
Cambridge Univer-sity Press.Walter Daelemans, Steven Gillis, and Gert Durieux.1994.
The acquisition of stress: A data-oriented ap-proach.
Computational Linguistics, 20(3).Bart de Boer.
2000.
Self-organization in vowel sys-tems.
Journal of Phonetics, 28:441?465.B.
Elan Dresher.
1999.
Charing the learning path:Cues to parameter setting.
Linguistic Inquiry,30(1):27?67.Marc Ettlinger.
2007.
An exemplar-based model ofchain shifts.
In Proceedings of the 16th Interna-tional Congress of the Phonetic Science, pages 685?688.Evelyn Fix and J.L.
Hodges.
1951.
Discrimina-tory analysis, nonparametric discrimination: Con-sistency properties.
Technical Report 4, USAFSchool of Aviation Medicine.Stephen Goldinger.
1996.
Words and voices: Episodictraces in spoken word identification and recogni-tion memory.
Journal of Experimental Psychology:Learning, Memory, and Cognition, 22:1166?1183.Morris Halle.
1997.
Some consequences of the repre-sentation of words in memory.
Lingua, 100:91?100.Trevor Hastie, Robert Tibshirani, and Jerome Fried-man.
2009.
Elements of Statistical Learning.Springer Series in Statistics.
Springer-Verlag, 2 edi-tion.Hynek Hermansky.
1990.
Perceptual linear predictive(plp) analysis of speech.
Journal of the AcousticalSociety of America, 87(4):1738?1752.Keith Johnson and John W. Mullenix, editors.
1997.Talker Variability in Speech Processing.
AcademicPress.Keith Johnson.
1997.
Speech perception withoutspeaker normalization: an exemplar model.
InTalker Variability in Speech Processing, chapter 8,pages 145?166.
Academic Press.Keith Johnson, 2007.
Decision and Mechanisms inExemplar-based Phonology, chapter 3, pages 25?40.Oxford University Press.Peter Jusczyk.
1999.
How infants begin to extractwords from speech.
Trends in Cognitive Sciences,3(9):323?328.Peter Jusczyk.
2000.
The Discovery of Spoken Lan-guage.
MIT Press.Robert Kirchner and Roger Moore.
2009.
Computingphonological generalization over real speech exem-plars.
ms.Ken Lodge.
2009.
Fundamental Concepts in Phonol-ogy: Sameness and difference.
Edinburgh Univer-sity Press.Douglas Medin and Marguerite Schaffer.
1978.
Con-text theory of classification learning.
PsychologicalReview, 85(3):207?238.Jeff Mielke.
2008.
The Emergence of Distinctive Fea-tures.
Oxford Studies in Typology and LinguisticTheory.
Oxford University Press.Robert Nosofsky.
1986.
Attention, similarity, and theidentification-categorization relationship.
Journalof Experimental Psychology: General, 115(1):39?57.Colin Phillips, Thomas Pellathy, Alec Marantz, El-ron Yellin, Kenneth Wexler, David Poeppel, MarthaMcGinnis, and Timothy Roberts.
2000.
Auditorycortex accesses phonological categories: An megmismatch study.
Journal of Cognitive Neuroscience,12(6):1038?1055.Janet Pierrehumbert.
2001.
Exemplar dynamics: Wordfrequency, lenition, and contrast.
In Frequency ef-fects and the emergence of linguistic structure, pages137?157.
John Benjamins.Alan Prince and Paul Smolensky.
2004.
OptimalityTheory: Constraint interaction in generative gram-mar.
Blackwell.Lawrence Rabiner and Biing-Hwang Juang.
1993.Fundamentals of Speech Recognition.
Prentice Hall.Richard Semon.
1921.
The Mneme.
George Allen andUnwin.Harvey Sussman, David Fruchter, Jon Hilbert, andJoseph Sirosh.
1998.
Linear correlates in the speechsignal: The orderly output constraint.
Behavioraland Brain Sciences, 21:241?299.Bruce Tesar and Paul Smolensky.
2000.
Learnabilityin Optimality Theory.
MIT Press.Riitta V?alimaa-Blum.
2009.
The phoneme in cognitivephonology: episodic memories of both meaningfuland meaningless units?
Cognitextes, 2.Harry van der Hulst and Jeroen van de Weijer.
1995.Vowel harmony.
In John Goldsmith, editor, Hand-book of Phonological Theory.
Blackwell.8
