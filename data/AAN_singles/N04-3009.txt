Spoken Dialogue for Simulation Control and Conversational TutoringElizabeth Owen Bratt Karl Schultz Brady ClarkCSLI,Stanford University,Stanford, CA 94305CSLI,Stanford University,Stanford, CA 94305CSLI,Stanford University,Stanford, CA 94305ebratt@csli.stanford.edu schultzk@csli.stanford.edu bzack@csli.stanford.eduAbstractThis demonstration shows a flexible tutoringsystem for studying the effects of differenttutoring strategies enhanced by a spokenlanguage interface.
The hypothesis is thatspoken language increases the effectivenessof automated tutoring.
The domain is Navydamage control.1 Technical ContentThis demonstration shows a flexible tutoringsystem for studying the effects of different tutoringstrategies enhanced by a spoken language interface.The hypothesis is that spoken language increases theeffectiveness of automated tutoring.
Our focus is onthe SCoT-DC spoken language tutor for Navydamage control; however,  because SCoT-DCperforms reflective tutoring on DC-Train simulatorsessions, we have also developed a speech interfacefor the existing DC-Train damage control simulator,to promote ease of use as well as consistency ofinterface.Our tutor is developed within the Architecture forConversational Intelligence (Lemon et al 2001).
Weuse the Open Agent Architecture (Martin et al 1999)for communication between agents based on theNuance speech recognizer, the Gemini naturallanguage system (Dowding et al 1993), and Festivalspeech synthesis.
Our tutor adds its own dialoguemanager agent, for general principles ofconversational intelligence, and a tutor agent, whichuses tutoring strategies and tactics to plan out anappropriate review and react to the student's answersto questions and desired topics.The SCoT-DC tutor, in Socratic style, asksquestions rather than giving explanations.
The tutorhas a repertoire of hinting tactics to deploy inresponse to student answers to questions, andidentifies and iscusses repeated mistakes.
Thestudent is able to ask "why" questions after certaintutor explanations, and  to alter the tutorial plan byrequesting that the tutor skip discussion of certaintopics.
In DC-Train, the system uses several windowsto provide information graphically, in addition to thespoken messages.
In SCoT-DC, the Ship Displayfrom DC-Train is used for both multimodal input andoutput.Both DC-Train and SCoT-DC use the sameoverall Gemini grammar, with distinct top-levelgrammars producing appropriate subsets for eachapplication.
Our Gemini grammar currently has 166grammar rules and 811 distinct words.
In a Nuancelanguage model compiled from the Gemini grammar(Moore 1998), different top-level grammars are usedin SCoT-DC to enhance speech recognition based onexpected answers.2 Performance AssessmentExperiments to assess the effectiveness of SCoT-DC tutoring are underway in March 2004, with 15subjects currently scheduled.
In July 2003, studentsin the Repair Locker Head class at the Navy FleetTraining Center in San Diego ran 12 sessions withDC-Train.
Sessions ranged from 1 to 65 userutterances, with an average of  21.
The averageutterance length was 7 words.
In speech recognition,about 22% of utterances were rejected, and thesentences with a recognition hypothesis had a worderror rate of 27%.
The transcribed data, combinedwith developer test run data, gave us 327 unique out-of-grammar sentences.
Of these, we found 79examples where the automatic Nuance endpointingcut off an utterance too early, and 20 examples ofdisfluent speech.
118 sentences were determined tobe potentially useful phrasings to add to the grammar,while 73 sentences were found to lie outside thescope of the application.To address these issues, w have added newphrasings to the grammar.
We also intend to useNuance?s Listen & Learn offline grammar adaptationtool, to give higher probabilities to likely sentenceswhile retaining broad grammar-based coverage.
Wemay also adjust endpointing time, based on partialspeech recognition hypothesis, to give extra time tothe kinds of sentences typically occurring with moreinternal pauses.
Disfluencies may decrease as usersbecome more familiar with DC-Train and SCoT-DCduring the comparatively longer use xpected fromeach user in a typical tutoring sessionThe graphical interface for the DC-Trainsimulator is shown in Figure 1.Figure 1: DC-Train simulator GUIEach window on the screen is modeled on asource of information available to a real-lifeDCA ona ship, including as a detailed drawing of the severalhundred compartments on the ship, a record of allcommunications to and from the DCA, a hazarddetection panel showing the locations of alarmswhich have occurred, and a panel showing thefiremain, i.e.
the pipes carrying water throughout theship, and the valves and pumps controlling the flowof the water.
The window depicting heads representsthe other personnel in the same room as the DCA,who are available to receive and transmit messages.While in the original version of DC-Train,the DCA?s orders and communications to otherpersonnel on the ship took place through a menusystem, this demo presents the newer spokendialogue interface.
Spoken commands take the formof actual Navy commands, thus enabling the Navystudent to train in the same manner as they wouldperform these duties through radio communicationson a ship.The user clicks a button to begin speaking,and the speech is recognized by Nuance, using agrammar-based language model automaticallyderived from the Gemini grammar used for parsingand interpretation of the commands.
A dialoguemanager then maps the Gemini logical forms intoDC-Train commands.
To allow the student tomonitor the success of the speech recognizer, the textof the utterance is displayed.
Responses from thesimulated personnel are spoken by Festival speechsynthesis, and also displayed as text on the screen.Most spoken interactions with DC-Traininvolve the student DCA giving single commandswithout any use of dialogue structure; however, thesystem will query the student for missing  requiredparameters of commmands, such as the repair teamwho is to perform the action, or the number of  thepump to start on the firemain.
If the student does notrespond to these queries, the system will provide thecontext of the command missing the parameter aspart of a more informative request.
The studentretains the ability to issue other commands at thistime, and need not respond to the system if there is amore pressing crisis elsewhere.At the end of a DC-Train session, thestudent can then receive customized feedback andtutoring from SCoT-DC, based on a record of thestudent?s actions compared to what an expert DCAwould have done at each point, based on  rulesaccounting for the state of the simulation.
The goal ofthe tutorial interaction is to identify and remediateany gaps in the student?s understanding of damagecontrol doctrine, and to improve the student?sperformance in issuing the correct commands withouthesitation.The graphical interface to the SCoT-DCtutor is shown in Figure 2.Figure 2: ScoT-DC tutor GUISCoT-DC uses two instances of the Ship Displayfrom DC-Train, seen in Figure 3, one to give anoverall view of the ship and one to zoom in onaffected compartments, with color indicating the typeof crisis in a compartment and the state of damagecontrol there.
The student can click on acompartment in the Ship Display as a way ofindicating that compartment to the system.
Theautomated tutor and the student communicatethrough speech, while the lower window displays thetext of both sides of the interaction, and permits theuser to scroll back through the entire tutorial session.Figure 3: Highlighted CompartmentThe tutor can also display bulkheads used to setboundaries for firefighting, as in Figure 4.Figure 4:  Highlighted Bulkhead WallsA third kind of graphical information that thetutor may convey to the student involves regions ofjurisdiction for repair  teams, shown in Figure 5.Figure 5: Repair Team Jurisdiction RegionsAs in DC-Train, the student clicks to beginspeaking, then Nuance speech recognition provides astring of words to be interpreted by a Geminigrammar.
Also as in DC-Train, responses from thetutor are  synthesized by Festival, although the tutorspeaks with a more natural voice provided byFestVox limited domain synthesis, in which largeunits of the tutor?s utterances may be taken fromprompts recorded for this application.Interpretation of the Gemini interpretedforms is handled by a more complex dialoguemanager in SCoT-DC than in DC-Train, with astructured representation of the dialogue, which isused to guide the system?s use of discourse markers,among other things.
The dialogue is mainly drivenby the tutor agent?s strategies, though the student canrequest to move on to future topics withoutcompleting the current discussion, and also ask a?Why?
question after some explanations.Tutorial strategies generally guide theoverall path of the conversation, such as choosingwhich crises to discuss based on the errors made bythe student.
Tutorial tactics apply at a lower-levelthroughout the dialogue, for example, when a studentgives an incorrect answer, the tutor will give ageneral hint and repos the question.
If the studentanswers incorrectly a second time the tutor will givea more specific hint and ask the question again.
Ifthe student fails a third time the tutor will give thecorrect answer, and proceed.Running a  full DC-Train scenario takes 20-40 minutes, and has the flavor of the followingexcerpt:[buzzing alarm goes off, it is a fire alarm]DCCO: Fire in compartment 2-78-01-L.Student: Net80 to repair locker 2, investigatecompartment 2-78-01-L.Repair Locker 2: Reports, fire in compartment 2-78-01-L.Repair Locker 2: Reports, smoke in compartment 2-78-01-L.Student: Net80 to repair locker 2, fight the fire incompartment 2-78-01-L.Student: Net80 to repair locker 2, set fire and smokeboundaries on primary forward 78, primary aft 126,secondary forward 42, secondary aft 174, above 1,below 2.A reflective dialogue with the tutor will takesaround 10 minutes.
The following gives a sample ofthe kind of tutorial interaction.Tutor: Hello, we are about to review your sessionfrom earlier today.Tutor: All right, are you ready?Student: Yes.Tutor: In this session there were 5 primary crises and1 secondary crisis.Tutor: 5 of the 6 crises were resolved.Tutor: Most of your actions were correct, howeveryou made several mistakes.Tutor: OK, let?s discuss a few of those crises.Tutor: The first crisis was a fire here in Crew Livingspace No.
1.
[centers on this compartment]Tutor: This fire was not contained early enough.Tutor: As a result, the fire spread to the adjacentCombat sytem equipment room No.
2.
[highlights2nd compartment]Tutor: OK, let?s review how to handle this crisis.
[removes highlight from 2nd compartment]Tutor: What?s the first thing you should do when thefire alarm sounds?Student: Send repair two to investigate.Tutor: Yes, that?s right.Tutor: However, you failed to do this during thesession.Tutor: This is a mistake you made more than once.Tutor: Remember, alarms need to be verified first.Tutor: OK, suppose that there is a fire.Tutor: What?s the next step?Student: Set fire and smoke boundaries.Tutor: Yes.
That?s what you did during the session.Tutor: OK, what else needs to be done?Student: The repair team should fight the fire.Tutor: No, you missed a step.Tutor: Remember, the crisis might interfere withother ship systems.Tutor: Let?s try again.Tutor: What else needs to be done?Student: I don?t know.Tutor: Well.Tutor: You should order repair five to mechanicallyand electrically isolate the compartment.A video clip of an older version of the ScoT-DCsystem is available at http://www-csli.stanford.edu/semlab/muri/November2002Demo.html3 AcknowledgementsThis work is supported by the Department of theNavy under research grant N000140010660, amultidisciplinary university research initiative onnatural language interaction with intelligent tutoringsystems.3.1 ReferencesA.
Black and K. Lenzo, 1999.
Building Voices in theFestival Speech Synthesis System (DRAFT)Available athttp://www.cstr.ed.ac.uk/projects/festival/papers.html.A.
Black and P. Taylor.
1997.
Festival speechsynthesis system: system documentation (1.1.1).Technical Report Technical Report HCRC/TR-83, University of Edinburgh HumanCommunication Research Centre.V.
V. Bulitko and D. C. Wilkins.
1999.
Automatedinstructor assistant for ship damage control.
InProceedings of AAAI-99.J.
Dowding, M. Gawron, D. Appelt, L. Cherny, R.Moore, and D. Moran.
1993.
Gemini: A naturallanguage system for spoken languageunderstanding.
In Procdgs of ACL 31.Oliver Lemon, Alexander Gruenstein, and StanleyPeters.
2002.
Collaborative Activities and Multi-tasking in Dialogue Systems , TraitementAutomatique des Langues (TAL), 43(2):131- 54,special issue on dialogue.D.
Martin, A. Cheyer, and D. Moran.
1999.
``Theopen agent architecture: A framework forbuilding distributed software systems,'' AppliedArtificial Intelligence, v.13:91-128.Robert C. Moore.
1998.
Using Natural LanguageKnowledge Sources in Speech Recognition.
"Proceedings of the NATO Advanced StudyInstitute.Karl Schultz, Elizabeth Owen Bratt, Brady Clark,Stanley Peters, Heather Pon-Barry, and PucktadaTreeratpituk.
2003.
A Scalable, Reusable SpokenConversational Tutor: SCoT.
In AIED 2003Supplementary Procdgs.
(V. Aleven et aleds).Univ.
of Sydney.
367-377.
