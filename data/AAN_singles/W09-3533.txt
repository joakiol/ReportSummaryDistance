Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152?160,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPName Matching Between Chinese and Roman Scripts:Machine Complements HumanKen Samuel, Alan Rubenstein, Sherri Condon, and Alex YehThe MITRE Corporation; M/S H305; 7515 Colshire Drive; McLean, Virginia 22102-7508samuel@mitre.org, rubenstein@mitre.org, scondon@mitre.org, and asy@mitre.orgAbstractThere are generally many ways to translite-rate a name from one language script intoanother.
The resulting ambiguity can make itvery difficult to ?untransliterate?
a name byreverse engineering the process.
In this paper,we present a highly successful cross-scriptname matching system that we developed bycombining the creativity of human intuitionwith the power of machine learning.
Our sys-tem determines whether a name in Romanscript and a name in Chinese script matcheach other with an F-score of 96%.
In addi-tion, for name pairs that satisfy a computa-tional test, the F-score is 98%.1 IntroductionThere are generally many ways to transliterate aperson?s name from one language script intoanother.
For example, writers have transliteratedthe Arabic name, ?????
?, into Roman charactersin at least 13 ways, such as Al Choukri, Ash-shukri, and al-Schoukri.
This ambiguity canmake it very difficult to ?untransliterate?
a nameby reverse engineering the process.We focused on a task that is related to transli-teration.
Cross-script name matching aims to de-termine whether a given name part in Romanscript matches a given name part in Chinese(Mandarin) script,1 where a name part is a single?word?
in a person?s name (such as a surname),and two names match if one is a transliteration ofthe other.2 Cross-script name matching has many1 In this paper, we often use the word ?Roman?
to refer to?Roman script?, and similarly, ?Chinese?
usually standsfor ?Chinese script?.2 Sometimes a third script comes between the Roman andChinese versions of the name.
For example, a Romanname might be transliterated into Arabic, which is thentransliterated into Chinese, or an Arabic name could betransliterated into Roman and Chinese independently.applications, such as identity matching, improv-ing search engines, and aligning parallel corpora.We combine a) the creative power of humanintuition, which can come up with clever ideasand b) the computational power of machinelearning, which can analyze large quantities ofdata.
Wan and Verspoor (1998) provided thehuman intuition by designing an algorithm todivide names into pieces that are just the rightsize for Roman-Chinese name matching (Section2.2.).
Armed with Wan and Verspoor?s algo-rithm, a machine learning approach analyzeshundreds of thousands of matched name pairs tobuild a Roman-Chinese name matching system(Section 3).Our experimental results are in Section 4.
Thesystem correctly determines whether a Romanname and a Chinese name match each other withF = 96.5%.3 And F = 97.6% for name pairs thatsatisfy the Perfect Alignment hypothesis condi-tion, which is defined in Section 2.2.2 Related WorkWan and Verspoor?s (1998) work had a greatimpact on our research, and we explain how weuse it in Section 2.2.
In Section 2.1, we identifyother related work.2.1 Chinese-English Name MatchingCondon et al (2006) wrote a paper about thechallenges of matching names across Roman andChinese scripts.
In Section 6 of their paper, theyoffered an overview of several papers related toRoman-Chinese name matching.
(Cohen et al,2003; Gao et al, 2004;  Goto et al, 2003; Jung etal., 2000; Kang and Choi, 2000; Knight andGraehl, 1997; Kondrak, 2000; Kondrak andDorr, 2004; Li et al, 2004; Meng et al, 2001; Oh3 F stands for F-score, which is a popular evaluation metric.
(Andrade et al, 2009)152and Choi, 2006; Virga and Khudanpur, 2003;Wellner et al, 2005; Winkler, 2002)The Levenshtein algorithm is a popular way tocompute string edit distance.
(Levenshtein, 1966)It can quantify the similarity between two names.However, this algorithm does not work when thenames are written in different scripts.
So Free-man et al (2006) developed a strategy for Ro-man-Arabic  string matching that uses equiva-lence classes of characters to normalize thenames so that Levenshtein?s method can be ap-plied.
Later, Mani et al (2006) transformed thatsystem from Roman-Arabic to Roman-Chinesename matching and extended the Levenshteinapproach, attaining F = 85.2%.
Then when theytrained a machine learning algorithm on the out-put, the performance improved to F = 93.1%Mani et al also tried applying a phonologicalalignment system (Kondrak, 2000) to the Ro-man-Chinese name matching task, and they re-ported an F-score of 91.2%.
However, when theytrained a machine learning approach on that sys-tem?s output, the F-score was only 90.6%.It is important to recognize that it would be in-appropriate to present a side-by-side comparisonbetween Mani?s work and ours (F = 96.5%), be-cause there are many differences, such as thedata that was used for evaluation.2.2 Subsyllable UnitsTransliteration is usually based on the waynames are pronounced.4 However, each characterin a Roman name generally corresponds to a sin-gle phoneme, while a Chinese character (CC)generally corresponds to a subsyllable unit(SSU).
A phoneme is the smallest meaningfulunit of sound, and a subsyllable unit is a se-quence of one to three phonemes that conform tothe following three constraints.
(Wan and Vers-poor, 1998)4  Of course, there are exceptions.
For example, when aname happens to be a word, sometimes that name is trans-lated (rather than transliterated) into the other language.But our experimental results suggest that the exceptionsare quite rare.
(1) There is exactly one vowel phoneme.5(2) At most, one consonant phoneme may pre-cede the vowel phoneme.
(3) The vowel phoneme may be followed by, atmost, one nasal phoneme.6Consider the example in Table 1.
The name?Albertson?
consists of eight phonemes in threesyllables.7 The last syllable, SAHN, satisfies thedefinition of SSU, and the other two are split intosmaller pieces, resulting in a total of five SSUs.There are also five CCs in the Chinese version,?????.
We note that the fourth and sixth rowsin the table show similarities in their pronuncia-tions.
For example, the first SSU, AE, soundslike the first CC, /a/.
And, although the soundsare not always identical, such as BER and /pei/,Wan and Verspoor claimed that these SSU-CCcorrespondences can be generalized in the fol-lowing way:Perfect Alignment (PA) hypothesisIf a Roman name corresponds to a sequence of nSSUs, S1, S2, ..., Sn, and the Chinese form of thatname is a sequence of n CCs, C1, C2, ..., Cn, thenCi matches Si for all 1 ?
i ?
n.In Section 4, we show that the PA hypothesisworks very well.
However, it is not uncommonto have more SSUs than CCs in a matching namepair, in which case, the PA hypothesis does notapply.
Often this happens because an SSU is leftout of the Chinese transliteration, perhaps be-cause it is a sound that is not common in Chi-nese.
For example, suppose ?Carlberg?
(KAA,R,L,BER,G) is transliterated as ????
.
Inthis example, the SSU, R, does not corres-pond to any of the CCs.
We generalize thisphenomenon with another hypothesis:SSUs Deletion (SSUD) hypothesisIf a Roman name corresponds to a sequence ofn+k  SSUs (k>0), S1, S2, ..., Sn+k, and the Chineseform of that name is a sequence of n CCs, C1, C2,..., Cn, then, for some set of k Si?s, if those SSUsare removed from the sequence of SSUs, then thePA hypothesis holds.And in the case where the number of CCs isgreater than the number of SSUs, we make the5 Wan and Verspoor treat the phoneme, /?r/, as in Albertson,as a vowel phoneme.6 The nasal phonemes are /n/ and /?/, as in ?nothing?.7 To represent phonemes, we use two different standards inthis paper.
The symbols between slashes (like /?r/) are inthe IPA format (International Phonetic Association,1999).
And the phonemes written in capital letters (likeER) are in the ARPABET format (Klatt, 1990).Roman Characters: AlbertsonPhonemes: AE,L,B,ER,T,S,AH,NSyllables: AEL,BERT,SAHNSubsyllable Units: AE,L,BER,T,SAHNChinese: ????
?Chinese Phonemes: /a/,/?r/,/pei/,/th?/,/su?/Table 1.
Subsyllable Units153corresponding CCs Deletion (CCD) hypothesis.In the next section, we show how we utilize thesehypotheses.3 Machine LearningWe designed a machine learning algorithm toestablish a mapping between SSUs and CCs.
InSection 3.1, we show how our system can doRoman-Chinese name matching, and then wepresent the training procedure in Section 3.2.3.1 Application ModeGiven a Roman-Chinese name pair, our systemcomputes a match score, which is a number be-tween 0 and 1 that is meant to represent the like-lihood that two names match.
This is accom-plished via the process presented in Figure 1.Starting in the upper-left node of the diagramwith a Roman name and a Chinese name, thesystem determines how the Roman name shouldbe pronounced by running it through the Festivalsystem.
(Black et al, 1999) Next, two algorithmsdesigned by Wan and Verspoor (1998) join thephonemes to form syllables and divide the syl-lables into SSUs.8 If the number of SSUs is equalto the number of characters in the Chinesename,9 we apply the PA hypothesis to align eachSSU with a CC.The system computes a match score using adata structure called the SSU-CC matrix (subsyl-lable unit ?
Chinese character matrix), which hasa nonnegative number for each SSU-CC pair,and this value should represent the strength ofthe correspondence between the SSU and theCC.
Table 2 shows an example of an SSU-CCmatrix.
With this matrix, the name pair <Albert,???
?> receives a relatively high match score,because the SSUs in Albert are AE, L, BER, andT, and the numbers in the SSU-CC matrix for<AE,?>, <L,?>, <BER,?> and <T,?> are 2, 2,3, and 2, respectively.10 Alternatively, the systemassigns a very low match score to <Albert,???
?>, because the values of <AE,?>, <L,?>,<BER,?>, and <T,?> are all 0.3.2 Training ModeTo generate an SSU-CC matrix, we train our sys-tem on a corpus of Roman-Chinese name pairs8  This procedure passes through three separate modules,each of which introduces errors, so we would expect thesystem to suffer from compounding errors.
However, theexcellent evaluation results in Section 4 suggest  other-wise.
This may be because the system encounters thesame kinds of errors during training that it sees in the ap-plication mode, so perhaps it can learn to compensate forthem.9 Section 3.3 discusses the procedure used when these num-bers are not equal.10 The equation used to derive the match score from thesevalues can be found in Section 5.Figure 2.
Training ModeFigure 1.
Application ModeAEBEREH GKAA LLAHNLIYNAH RSAHN T?
0 0 0 0 0 0 1 0 0 0 0 0?
0 0 0 0 0 0 0 1 0 0 0 0?
0 0 0 0 1 0 0 0 0 0 0 0?
0 0 1 0 0 0 0 0 0 0 0 0?
0 0 1 0 0 0 0 0 0 0 0 0?
0 0 0 0 0 0 0 0 1 0 0 0?
0 0 0 0 0 2 0 0 0 1 0 0?
0 0 0 0 0 0 0 0 0 0 1 0?
0 0 0 0 0 0 0 0 0 0 0 2?
0 3 0 0 0 0 0 0 0 0 0 0?
0 0 0 0 0 0 1 0 0 0 0 0?
0 0 0 1 0 0 0 0 0 0 0 0?
2 0 0 0 0 0 0 0 0 0 0 0Table 2.
SSU-CC Matrix #1154that match.
Figure 2 shows a diagram of thetraining system.
The procedure for transformingthe Roman name into a sequence of SSUs isidentical to that presented in Section 3.1.
Then, ifthe number of SSUs is the same as the number ofCCs,9 we apply the PA hypothesis to pair theSSUs with the CCs.
For example, the third namepair in Table 3 has three SSU-CC pairs: <KAA,?>, <R,?>, and <LIY,?>.
So the system mod-ifies the SSU-CC matrix by adding 1 to each cellthat corresponds to one of these SSU-CC pairs.Training on the five name pairs in Table 3 pro-duces the SSU-CC matrix in Table 2.3.3 Imperfect AlignmentThe system makes two passes through the train-ing data.
In the first pass, whenever the PA hypo-thesis does not apply to a name pair (because thenumber of SSUs differs from the number ofCCs), that name pair is skipped.Then, in the second pass, the system buildsanother SSU-CC matrix.
The procedure forprocessing each name pair that satisfies the PAhypothesis?s condition is exactly the same as inthe first pass (Section 3.2).
But the other namepairs require the SSUD hypothesis or the CCDhypothesis to delete SSUs or CCs.
For a givenRoman-Chinese name pair:where D is the set of all deletion sets that makethe PA hypothesis applicable.
Note that the sizeof D grows exponentially as the difference be-tween the number of SSUs and CCs grows.As an example, consider adding the name pair<Carlberg, ???
?> to the data in Table 3.
Carl-berg has five SSUs: KAA,R,L,BER,G, but ???-?
has only four CCs.
So the PA hypothesis is notapplicable, and the system ignores this name pairin the first pass.
Table 2 shows the values in Ma-trix #1 when it is completed.In the second pass, we must apply the SSUDhypothesis to <Carlberg, ???
?> by deletingone of the SSUs.
There are five ways to do this,as shown in the five rows of Table 4.
(For in-stance, the last row represents the case where Gis deleted ?
the SSU-CC pairs are <KAA,?>,<R,?>, <L,?>, <BER,?>, and <G,?>.11)Each of the five options are evaluated usingthe values in Matrix #1 (Table 2) to produce thescores in the second column of Table 4.
Then the11 The ?
represents a deleted SSU.
We include a row andcolumn named ?
in Matrix #2 to record values for thecases in which the SSUs and CCs are deleted.For every d in D:Temporarily make the deletions in d.Evaluate the resulting name pair with Matrix #1.Scale the evaluation scores of the d?s to sum to 1.For every d in D:Temporarily make the deletions in d.For every SSU-CC pair, ssu-cc, in the result:Add d?s scaled score to cell [ssu,cc] in Matrix #2.Example # 1 2 3 4 5RomanCharactersAlbert Albertson Carly Elena EllenbergSubsyllableUnitsAE,L,BER,T AE,L,BER,T,SAHN KAA,R,LIY EH,LAHN,NAH EH,LAHN,BER,GChineseCharacters????
?????
???
???
???
?Table 3.
Training DataCCs Score Scaled Score?????
0.00 0.00?????
0.90 0.54?????
0.76 0.46?????
0.00 0.00?????
0.00 0.00Table 4.
Subsyllable Unit Deletion?BER GKAA L R ...?
0.00 0.00 0.00 0.46 0.54?
0.00 0.00 0.00 2.00 0.00 0.00?
0.00 0.00 0.00 0.00 2.54 1.46?
0.00 4.00 0.00 0.00 0.00 0.00?
0.00 0.00 2.00 0.00 0.00 0.00...Table 5.
SSU-CC Matrix #2155system scales the scores to sum to 1, as shown inthe third column, and it uses those values asweights to determine how much impact each ofthe five options has on the second matrix.
Table5 shows part of Matrix #2.In application mode, when the system encoun-ters a name pair that does not satisfy the PA hy-pothesis?s condition it tries all possible deletionsets and selects the one that produces the highestmatch score.3.4 Considering ContextIt might be easier to estimate the likelihood thatan SSU-CC pair is a match by using informationfound in surrounding SSU-CC pairs, such as theSSU that follows a given SSU-CC pair.
We dothis by increasing the number of columns in theSSU-CC matrix to separate the examples basedon the surrounding context.For example, in Table 2, we cannot determinewhether LAHN should map to ?
or ?.
But theSSU that follows LAHN clears up the ambiguity,because when LAHN immediately precedesBER, it maps to  ?, but when it is followed byNAH, it corresponds to ?.
Table 6 displays aportion of the SSU-CC matrix that accounts forthe contextual information provided by the SSUthat follows an SSU-CC pair.3.5 The ThresholdGiven an SSU-CC name pair, the system produc-es a number between 0 and 1.
But in order toevaluate the system in terms of precision, recall,and F-score, we need the system to return a yes(a match) or no (not a match) response.
So weuse a threshold value to separate those two cases.The threshold value can be manually selectedby a human, but this is often difficult to do effec-tively.
So we developed the following automatedapproach to choose the threshold.
After the train-ing phase finishes developing Matrix #2, the sys-tem processes the training data12 one more time.12 We tried selecting the threshold with data that was notused in training, and we found no statistically significantimprovement.But this time it runs in application mode (Section3.1), computing a match score for each trainingexample.
Then the system considers all possibleways to separate the yes and no responses with athreshold, selecting the threshold value that is themost effective on the training data.Building the SSU-CC matrices does not re-quire any negative examples (name pairs that donot match).
However, we do require negativeexamples in order to determine the threshold andto evaluate the system.
Our technique for gene-rating negative examples involves randomlyrearranging the names in the data.134 Evaluation of the SystemWe ran several experiments to test our systemunder a variety of different conditions.
After de-scribing our data and experimental method, wepresent some of our most interesting experimen-tal results.We used a set of nearly 500,000 Roman-Chinese person name pairs collected from Xin-hua News Agency newswire texts.
(Huang,2005) Table 7 shows the distribution of the databased on alignment.
Note that the PA hypothesisapplies to more than 60% of the data.We used the popular 10-fold cross validationapproach 14  to obtain ten different evaluationscores.
For each experiment we present the aver-age of these scores.Our system?s precision (P), recall (R), and F-score (F) are: P = 98.19%, R = 94.83%, and F =96.48%.
These scores are much better than weoriginally expected to see for the challengingtask of Roman-Chinese name matching.Table 8 shows P, R, and F for subsets of thetest data, organized by the number of SSUs mi-13 Unfortunately, there is no standard way to generate nega-tive examples.14 The data is divided into ten subsets of approximately thesame size, testing the system on each subset when trainedon the other nine.LAHN(BER)LAHN(NAH)BER(G)BER(T)?
1 0 0 0?
0 0 1 2?
0 1 0 0Table 6.
Considering ContextAlignment % of Data#SSUs - #CCs ?
3 1.62%#SSUs - #CCs = 2 6.66%#SSUs - #CCs = 1 20.00%#SSUs - #CCs = 0 60.60%#SSUs - #CCs = -1 10.48%#SSUs - #CCs = -2 0.61%#SSUs - #CCs ?
-3 0.02%Table 7.
Statistics of the Data156nus the number of CCs in the name pairs.
Thedifferences between scores in adjacent rows ofeach column are statistically significant.15  Per-fectly aligned name pairs proved to be the ea-siest, with F = 97.55%, but the system was alsovery successful on the examples with the numberof SSUs and the number of CCs differing by one(F = 96.08% and F = 97.37%).
These three casesaccount for more than 91% of the positive exam-ples in our data set.
(See Table 7.
)4.1 Deletion HypothesesWe ran tests to determine whether the secondpass through the training data (in which theSSUD and CCD hypotheses are applied) is effec-tive.
Table 9 shows the results on the completeset of test data, and all of the differences betweenthe scores are statistically significant.The first row of Table 9 presents F when thesystem made only one pass through the trainingdata.
The second row?s experiments utilized theCCD hypothesis but ignored examples with moreSSUs than CCs during training.
For the thirdrow, we used the SSUD hypothesis, but not theCCD hypothesis, and the last row corresponds tosystem runs that used all of the training exam-ples.
From these results, it is clear that both ofthe deletion hypotheses are useful, particularlythe SSUD hypothesis.4.2 ContextIn Section 3.4, we suggested that contextual in-formation might be useful.
So we ran some tests,obtaining the results shown in Table 10.
For thesecond row, we used no contextual information.Row 5 corresponds to the case where we gavethe system access to the SSU immediately fol-lowing the SSU-CC pair being analyzed.
In row15 We use the homoscedastic t test (?Student?s t Test?, 2009)to decide whether the difference between two results isstatistically significant.6?s experiment, we used the SSU immediatelypreceding the SSU-CC pair under consideration,and row 7 corresponds to system runs that ac-counted for both surrounding SSUs.We also tried simplifying the contextual in-formation to boolean values that specify whetheran SSU-CC pair is at a boundary of its name ornot, and rows 1, 3, and 4 of Table 10 show thoseresults.
?Left Border?
is true if and only if theSSU-CC pair is at the beginning of its name,?Right Border?
is true if and only if the SSU-CCpair is at the end of its name, and ?Both Borders?is true if and only if the SSU-CC pair is at thebeginning or end of its name.
All differences inthe table are statistically significant, except forthose between rows 2, 3, and 4.
These resultssuggest that the right border provides no usefulinformation, even if the left border is also in-cluded in the SSU-CC matrix.
But when theSSU-CC matrix only accounted for the left bor-der, the F-score was significantly higher than thebaseline.
Providing more specific information inthe form of SSUs actually made the scores godown significantly.4.3 Sparse DataWe were initially surprised to discover that usingthe rich information in the surrounding SSUsmade the results worse.
The explanation for thisis that adding contextual information increasesthe size of the SSU-CC matrix, and so several ofthe numbers in the matrix become smaller.
(Forexample, compare the values in the ?BER?
col-umns in Table 2 and Table 6.)
This means thatthe system might have been suffering from asparse data problem, which is a situation wherethere are not enough training examples to distin-guish correct answers from incorrect answers,and so incorrect answers can appear to be correctby random chance.There are two factors that can contribute to asparse data problem.
One is the amount of train-ing data available ?
as the quantity of trainingdata increases, the sparse data problem becomesless severe.
The other factor is the complexity ofAlignment P R F#SSUs - #CCs ?
3 72.38% 94.02% 81.79%#SSUs - #CCs = 2 95.26% 92.67% 93.95%#SSUs - #CCs = 1 99.07% 93.27% 96.08%#SSUs - #CCs = 0 99.87% 95.33% 97.55%#SSUs - #CCs = -1 98.33% 96.42% 97.37%#SSUs - #CCs = -2 73.80% 94.98% 83.04%#SSUs - #CCs ?
-3 7.54% 78.04% 13.71%Table 8.
Varying Alignment of Name Pairs# Contextual Information F1 Left Border 96.48%2 No Context 96.25%3 Both Borders 96.24%4 Right Border 96.19%5 Next SSU 87.53%6 Previous SSU 85.89%7 Previous SSU and Next SSU 47.89%Table 10.
Evaluation with ContextHypotheses FPA 75.25%PA & CCD 83.74%PA & SSUD 92.86%PA & CCD & SSUD 96.48%Table 9.
Varying the Training Data157the learned model ?
as the model becomes morecomplex, the sparse data problem worsens.Our system?s model is the SSU-CC matrix,and a reasonable measure of the its complexity isthe number of entries in the matrix.
The secondcolumn of Table 11 shows the number of SSU-CC pairs in training divided by the number ofcells in the SSU-CC matrix.
These ratios arequite low, suggesting that there is a sparse dataproblem.
Even without using any context, thereare nearly 8 cells for each SSU-CC pair, on aver-age.16It might be more reasonable to ignore cellswith extremely low values, since we can assumethat these values are effectively zero.
The thirdcolumn of Table 11 only counts cells that havevalues above 10-7.
The numbers in that columnlook better, as the ratio of cells to training pairsis better than 1:4 when no context is used.
How-ever, when using the previous SSU, there are stillmore cells than training pairs.Another standard way to test for sparse data isto compare the system?s results as a function ofthe quantity of training data.
As the amount oftraining data increases, we expect the F-score torise, until there is so much training data that theF-score is at its optimal value.17 Figure 3 showsthe results of all of the context experiments thatwe ran, varying the amount of training data.
(90% of the training data was used to get the F-scores in Table 10.)
The t test tells us that ?NoContext?
is the only curve that does not increasesignificantly on the right end.
This suggests thatall of the other curves might continue increasingif we used more training data.
So even the ?BothSSUs?
case could potentially achieve a competi-tive score, given enough training examples.
Also,16 It is true that a name pair can have multiple SSU-CCpairs, but even if the average number of SSU-CC pairs pername pair is as high as 8 (and it is not), one training namepair per SSU-CC matrix cell is still insufficient.17 Note that this value may not be 100%, because there arefactors that can make perfection difficult to achieve, suchas errors in the data.more training data could produce higher scoresthan 96.48%.5 SummaryWe designed a system that achieved an F-scoreof 96.48%, and F = 97.55% on the 60.61% of thedata that satisfies the PA hypothesis?s condition.Due to the paper length restriction, we can on-ly provide short summaries of the other experi-ments that that we ran.1) We experimentally compared six differentequations for computing match scores andfound that the best of them is an arithmeticor geometric average of Prob(SSU|CC) andProb(CC|SSU).2) We attempted to make use of two simplehandcrafted rules, but they caused the sys-tem?s performance to drop significantly.3) We compared two approaches for automati-cally computing the pronunciation of a Ro-man name and found that using the Festivalsystem (Black et al, 1999) alone is just as ef-fective as using the CMU Pronunciation Dic-tionary (CMUdict, 1997) supplemented byFestival.4) We tried computing the threshold value withdata that was not used in training the system.However, this failed to improve the system?sperformance significantly.6 Future WorkThere are so many things that we still want to do,including:1. modifying our system for the task oftransliteration (Section 6.1),2. running fair comparisons between ourwork and related research,3.
using Levenshtein?s algorithm (Levensh-tein, 1966) to implement the SSUD andContextual Info.
All Cells  Cells > 10-7No Context 0.128 4.35Right Border 0.071 3.45Left Border 0.069 3.45Both Borders 0.040 3.13Next SSU 0.002 1.12Previous SSU 0.001 0.78Both SSUs far less far lessTable 11.
Num.
SSU-CC Pairs  per Matrix CellFigure 3.
Testing for Sparse Data40%50%60%70%80%90%100%10% 20% 30% 40% 50% 60% 70% 80% 90%F-ScoreTraining Set Size (% of available data)Left Border Next SSUNo Context Previous SSURight Border Both SSUsBoth Borders158CCD hypotheses, instead of exhaustivelyevaluating all possible deletion sets (Sec-tion 3.3),184. developing a standard methodology forcreating negative examples,5.
when using contextual information, split-ting rows or columns of the SSU-CCmatrix only when they are ambiguousaccording to a metric such as Informa-tion Gain (Section 3.4),196. combining our system with other Ro-man-Chinese name matching systems ina voting structure (Van Halteren, Zavrel,and Daelemans, 1998),7. independently evaluating the modulesthat determine pronunciation, constructsyllables, and separate subsyllable units(Section 3),8. converting phonemes into feature vectors(Aberdeen, 2006),9. modifying our methodology to apply itto other similar languages, such as Japa-nese, Korean, Vietnamese, and Ha-waiian.10.
manually creating rules based on infor-mation in the SSU-CC matrix, and11.
utilizing graphemic information.6.1 TransliterationWe would like to modify our system to enableit to transliterate a given Roman name into Chi-nese in the following way.
First, the systemcomputes the SSUs as in Section 3.1.
Then itproduces a match score for every possible se-quence of CCs that has the same length as thesequence of SSUs, returning all of the CC se-quences with match scores that satisfy a prede-termined threshold restriction.For example, in a preliminary experiment,given the Roman name Ellen, the matcher pro-duced the transliterations below, with the matchscores in parentheses.20?
?
(0.32)?
?
(0.14)?
?
(0.11)?
?
(0.05)18 We thank a reviewer for suggesting this method of im-proving efficiency.19 We thank a reviewer for this clever way to control thesize of the SSU-CC matrix when context is considered.20 A manually-set threshold of 0.05 was used in this experi-ment.Based on our data, the first and fourth resultsare true transliterations of Ellen, and the onlytrue transliteration that failed to make the list is?
?.7 ConclusionThere was a time when computational linguisticsresearch rarely used machine learning.
Research-ers developed programs and then showed howthey could successfully handle a few examples,knowing that their programs were unable to ge-neralize much further.
Then the language com-munity became aware of the advantages of ma-chine learning, and statistical systems almostcompletely took over the field.
Researcherssolved all kinds of problems by tapping into thecomputer?s power to process huge corpora ofdata.
But eventually, the machine learning sys-tems reached their limits.We believe that, in the future, the most suc-cessful systems will be those developed bypeople cooperating with machines.
Such systemscan solve problems by combining the computer?sability to process massive quantities of data withthe human?s ability to intuitively come up withnew ideas.Our system is a success story of human-computer cooperation.
The computer tirelesslyprocesses hundreds of thousands of training ex-amples to generate the SSU-CC matrix.
But itcannot work at all without the insights of Wanand Verspoor.
And together, they made a systemthat is successful more than 96% of the time.ReferencesAberdeen, J.
(2006) ?geometric-featurechart-jsa-20060616.xls?.
Unpublished.Andrade, Miguel.
Smith, S. Paul.
Cowlisha, Mike F.Gantner, Zeno.
O?Brien, Philip.
Farmbrough, Rich.et al ?F1 Score.?
(2009) Wikipedia: The Free En-cyclopedia.
http://en.wikipedia.org/wiki/F-score.Black, Alan W. Taylor, Paul.
Caley, Richard.
(1999)The Festival Speech Synthesis System: System Do-cumentation.
Centre for Speech Technology Re-search (CSTR).
The University of Edinburgh.http://www.cstr.ed.ac.uk/projects/festival/manualCMUdict.
(1997) The CMU Pronouncing Dictionary.v0.6.
The Carnegie Mellon Speech Group.http://www.speech.cs.cmu.edu/cgi-bin/cmudict.Cohen, W. Ravikumar, P. Fienberg, S. (2003) ?AComparison of String Distance Metrics for Name-159Matching Tasks.?
Proceedings of the IJCAI-03Workshop on Information Integration on the Web.Eds.
Kambhampati, S. Knoblock, C. 73-78.Condon, Sherri.
Aberdeen, John.
Albin, Matthew.Freeman, Andy.
Mani, Inderjeet.
Rubenstein, Alan.Sarver, Keri.
Sexton, Mike.
Yeh, Alex.
(2006)?Multilingual Name Matching Mid-Year StatusReport.
?Condon, S. Freeman, A. Rubenstein, A. Yeh, A.
(2006) ?Strategies for Chinese Name Matching.
?Freeman, A. Condon, S. Ackermann, C. (2006)"Cross Linguistic Name Matching in English andArabic: A ?One to Many Mapping?
Extension ofthe Levenshtein Edit Distance Algorithm."
Pro-ceedings of NAACL/HLT.Gao, W. Wong, K. Lam, W. (2004) ?Phoneme-BasedTransliteration of Foreign Names for OOV Prob-lem.?
Proceedings of the First International JointConference on Natural Language Processing.Goto, I. Kato, N. Uratani, N. Ehara, T. (2003) ?Trans-literation Considering Context Information Basedon the Maximum Entropy Method.?
Proceedingsof MT-Summit IX.Huang, Shudong.
(2005) ?LDC2005T34: Chinese <->English Named Entity Lists v 1.0.?
Linguistics Da-ta Consortium.
Philadelphia, Pennsylvania.
ISBN#1-58563-368-2.
http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2005T34.International Phonetic Association.
(1999) Handbookof the International Phonetic Association : A Guideto the Use of the International Phonetic Alphabet.Cambridge University Press, UK.
ISBN0521652367.
http://www.cambridge.org/uk/catalogue/catalogue.asp?isbn=0521652367.Jung, S. Hong, S. Paek, E. (2000) ?An English to Ko-rean Transliteration Model of Extended MarkovWindow.?
Proceedings of COLING.Kang, B.J.
Choi, K.S.
(2000) ?Automatic Translitera-tion and Back-Transliteration by Decision TreeLearning.?
Proceedings of the 2nd InternationalConference on Language Resources and Evalua-tion.Klatt, D.H. (1990) ?Review of the ARPA Speech Un-derstanding Project.?
Readings in Speech Recogni-tion.
Morgan Kaufmann Publishers Inc. San Fran-cisco, CA.
ISBN 1-55860-124-4.
554-575.Knight, K. Graehl, J.
(1997) ?Machine Translitera-tion.?
Proceedings of the Conference of the Asso-ciation for Computational Linguistics (ACL).Kondrak, G. (2000) ?A New Algorithm for theAlignment of Phonetic Sequences.?
Proceedings ofthe First Meeting of the North American Chapterof the Association for Computational Linguistics(NAACL).
Seattle, Washington.
288-295.Kondrak, G. Dorr, B.
(2004) ?Identification of Con-fusable Drug Names: A New Approach and Evalu-ation Methodology.?
Proceedings of the TwentiethInternational Conference on Computational Lin-guistics (COLING).
952-958.Levenshtein, V.I.
(1966) ?Binary Codes Capable ofCorrecting Deletions, Insertions and Reversals.?Sov.
Phys.
Dokl.
6.
707-710.Li, H. Zhang, M. Su, J.
(2004) ?A Joint Source-Channel Model for Machine Transliteration.?
Pro-ceedings of ACL 2004.Mani, Inderjeet.
Yeh, Alexander.
Condon, Sherri.
(2006) "Machine Learning from String Edit Dis-tance and Phonological Similarity.
"Meng, H. Lo, W. Chen, B. Tang, T. (2001) ?Generat-ing Phonetic Cognates to Handle Named Entities inEnglish-Chinese Cross-Language Spoken Docu-ment Retrieval.?
Proceedings of ASRU.Oh, Jong-Hoon.
Choi, Key-Sun.
(2006) ?An Ensem-ble of Transliteration Models for Information Re-trieval.?
Information Processing & Management.42(4).
980-1002.?Student?s t Test.?
(2009) Wikipedia: The Free En-cyclopedia.
http://en.wikipedia.org/wiki/T_test#Equal_sample_sizes.2C_equal_variance.Van Halteren, H., Zavrel, J. Daelemans, W. (1998)?Improving Data Driven Word-Class Tagging bySystem Combination.?
Proceedings of the 36thAnnual Meeting of the Association for Computa-tional Linguistics and the 17th International Con-ference on Computational Linguistics.
Montr?al,Qu?bec, Canada.
491-497.Virga, P. Khudanpur, S. (2003) ?Transliteration ofProper Names in Cross-Lingual Information Re-trieval.?
Proceedings of the ACL Workshop onMulti-lingual Named Entity Recognition.Wan, Stephen.
Verspoor, Cornelia Maria.
(1998).
"Automatic English-Chinese Name Transliterationfor Development of Multilingual Resources."
Pro-ceedings of the 36th Annual Meeting of the Associ-ation for Computational Linguistics.
Montr?al,Qu?bec, Canada.Wellner, B. Castano, J. Pustejovsky, J.
(2005) ?Adap-tive String Similarity Metrics for Biomedical Ref-erence Resolution.?
Proceedings of the ACL-ISMBWorkshop on Linking Biological Literature, Ontol-ogies, and Databases: Mining Biological Seman-tics.
9-16. http://www.cs.brandeis.edu/~wellner/pubs/Wellner-StringSim-BioLINK.pdf.Winkler, W. ?Methods for Record Linkage and Baye-sian Networks.?
(2002) Proceedings of the Sectionon Survey Research Methods, American StatisticalAssociation.
http://www.census.gov/srd/www/byyear.html.160
