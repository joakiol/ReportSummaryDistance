CONTROLLED TRANSFORMATIONAL SENTENCE GENERATIONMadeleine BatesBolt Beranek and Newman, Inc.Robert IngriaDepartment of Linguistics, MITI.
INTRODUCTIONThis paper describes a sentence generator thatwas built primari ly to focus on syntactic formand syntactic relationships.
Our main goal wasto produce a tutorial system for the Englishlanguage; the intended users of the system arepeople with language delaying handicaps such asdeafness, and people learning English as aforeign language.
For these populations,extensive exposure to standard Englishconstructions (negatives, questions,relatlvization, etc.)
and their interactionsis necessary.
?
The purpose of the generator wasto serve as a powerful resource for tutorialprograms that need examples of particularconstructions and/or related sentences to embedin exercises or examples for the student.
Thefocus of the generator is thus not so much onwhat to express as on how to express it inacceptable English.
This is quite differentfrom the focus of most other languagegeneration systems.
Nonetheless, our systemcould be interfaced to a more goal-directedsemantic component.The mechanism of transformational grammar waschosen because it offered both a way toexercise tight control over the surfacesyntactic form of a sentence and a good modelfor the production of groups of sentences thatare syntactical ly related (e.g.
the active andpassive forms of a transitive sentence).
Bycontrol l ing (at a very high level) the rulesthat are applied and by examining the detailedsyntactic relationships in the tree structuresat each end of the derivation, the tutorialpart of the system accesses a great deal ofinformation about the syntax of the sentencesthat are produced by the generator; thisknowledge is used to give explanations andhints to the user in the context of theparticular exercise that the student isattempting.The transformational generator is composed ofthree magor parts: a base component thatproduces base trees, a transformer that appliestransformational rules to the  trees to derive asurface tree, and a set of mechanisms tocontrol the operation of the first twocomponents.
We will discuss each of thecomponents of this system separately.2.
THE BASE COMPONENTThe base component is a set of functions thatimplicitly embody context free rules forcreating a tree structure (phrase marker) inthe X-bar framework (as discussed by Chomsky(1970), Jackendoff (1974), Bresnan (1975) andothers.)
In this system, the major syntacticcategories (N(oun), V(erb), A(djective) andP(reposltion)) are treated as complex symbolswhich are decomposable into the features \[~N\]and \[~V\].
This yields the following cross-classif ication of these categories:This work was sponsored by BEH grant ~G007904514.V?IFigure i.
Features in the X-bar SystemThe feature "N" marks a given category as"nounlike" (and thus corresponds to thetraditional grammatical notion of"substantive") while "V" marks a category as"verblike."
Nouns and Adjectives are \[?N\]because they share certain properties (e.g.Adjectives can be used in nominal contexts; inhighly inflected languages, Adjectives andNouns typically share the same inflectlonalparadigms, etc.)
Adjectives and Verbs are \[+V\]because they share (among other things) variousmorphological traits (e.g.
certain verbalforms, such as participles, have adjectivalproperties).
Verbs and Preposit ions are I-N\]because they display common complementselection attributes (e.g.
they both regularlytake Nominal complements that bear AccusativeCase.)
(For further discussion of the issue offeature decomposition, and for some alternativeproposals, see Jackendoff (1978) and George(1980a, Section 2; 1980b, Section 2).
)In addition, each syntactic category contains aspecif ication of its rank (given in terms ofnumber of bars, hence the term "X-bar" system).For instance, a Noun (N) is of rank 0 and ismarked with no bars whereas the Noun Phrasewhich it heads is of the same category butdifferent (higher) rank.
Intermediatestructures are also permitted; for instance, V *(read "V bar") is that portion of the VerbPhrase which consists of a Verb and itscomplements (e.g.
direct and indirect objects,clausal complements, preposit ional phrases,etc.)
while V ~ (read "V double bar") includesV ~ as well as Auxil iary elements.
For ourpurposes, we have adopted a uniform two-levelstructure across categories~ that is, eachcategory X is taken to have X ~* as its highestrank, so that Noun Phrase (NP) in our system isN ~,  Verb Phrase is V ~', etc.
Minor categories(such as DET(erminer), AUX(ilfary), NEG(ative),etc.)
stand outside this system, as doS(entence) and S ~ (a sort of super sentence,which contains S and clause introducingelements (or "subordinating conjunctions") suchas that).
These categories are notdecomposable into the features \[?N\] and \[+V\],and, except for S and S" , they -do  not ~avedifferent ranks.
(It should be noted that theadoption of a uniform two-level hypothesis andthe placlng of S and S ~ outside of the normalX-bar system are not uncontroversial--see e.g.Jackendoff (1978) and George (1980a, Section 2;1980b, Section 2).
However, these assumptionsare found in many variants of the X-barframework and are adequate for our purposes.
)153An example of the internal structure of the P'"corresponding to the phrase "to the sad boys"is given below:p'" \[ -v -N \]P" \[ -V -N \]P \[ -V -N  \]toN ~ \[ ~N -V PER.
3 +DEF WU.PL+HUMAN GENDER.MALE \]DET \[ +DEF \]theA ~" \[ +N +V \]A ~ \[ +N +V \]A \[ +N +V \]sadN ~ \[ +N -V PER.
3 +DEF NU.PL+HUMAN GENDER.MALE \]N \[ +N -V PER.
3 +DEF NU.PL+HUMAN GENDER.MALE \]boyFigure 2.
Part of A Sample Base StructureThis system of cross-c lass i f icat ion by featuresand by rank permits the creat ion oftransformations which can refer to a specif icrank or feature without referring to a specif icmajor category.
(See Bresnan (1975) forfurther discussion of this point.)
Forexample, the transformation which fronts WH-words to form WH-Quest ions treats any X ~category as its target and, hence, can be usedto question any of the major categories (e.g.A'~--"how big is it?
"; N' ' - -"what did they do?
""which men left?
"; P~'--"to whom did you giveit?").
Similarly, the transformation whichmarks Accusative Case on pronouns applies onlyto those N~'s which fol low a I-N\] category;i.e.
only to those N~s  which are the objectsof Verbs or Preposit ions.
This al lows us tocreate extremely versat i le transformationswhich apply in a variety of contexts, and freesus from the necessity of creat ing severaltransformations, each of which essential lyrepl icates the Structural  Descr ipt ion andStructural  Change of the others, di f fer ing onlyin the category of the affected term.A set of constraints (discussed further below)is the input to the base component anddetermines the type of base structure which isproduced.
A base structure has both the usualfeatures on the nodes (category features suchas \[+N\] and \[-v\], and select ional features suchas \[+PROPER\]) and some addit ional  diacr i t icfeatures (such as \[-C\], for case marking) whichare used to ,govern the appl icat ion of certaintransformations.Lexical insertion is an integral part of theconstruct ion of the tree by the base component.It is not essential  that words be chosen forthe sentence at this time, but it is convenientbecause addit ional features in the structure(such as \[+HUMAN\], \[+MALE\]) are needed to guidesome transformations (for instance, theinsertion of the correct form of oronouns.
)In our current system, the choice of words tobe inserted in the base structure is control ledby a dict ionary and a semantic networM whichembodies a l imited number of semantic classrelat ionships and case restr ict ions to orohibitthe production of utterances like "The answersaw the angry cookie."
The network nodes arechosen at random for each sentence that isgenerated, but a more powerful semanticcomponent could be used to convey particular"messages," provided only that it could findlexical items to be inserted in the smallnumber of posit ions required by the baseconstraints.3.
THE TRANSFORMATIONAL COMPONENTEach transformational rule has a StructuralDescription, Structural  Change, and (optional)Condition; however rules are not marked asoptional or obligatory, as they were intradit ional transformational theory (e.g.Chomsky (1955)).
Obl igatory transformationswhose structural descript ions were met wouldapply necessari ly; optional transformationswould apply at random.
Moreover, variousversions of transformational grammar haveemployed transformations as "fi lters" onpossible derivations.
In older work (e.g.
theso-cal led "Standard Theory" (ST) of Chomsk7(1965)) derivations in which a transformationrequired in a given syntactic conf igurat ionfailed to apply would block, causing the resultto be ruled out as ungrammatical  (op.
clt.,p.
138).In more recent theories (e.g.
the "ExtendedStandard Theory" (EST) of Chomsky (1977) andChomsky and Lasnik (1977)) all t ransformationsare optional, freely ordered and may apply atrandom.
Those derivations in which atransformation misappl ies are ruled out byindependent condit ions on the structuresproduced by the operat ion of thetransformational  component (Chomsky (1977,p.
76)).
These frameworks adopt a "generateand test" approach, wherein the misappl icat ionof transformations during the course of aderivat ion (e.g.
the failure of a requiredtransformation to apply (ST, EST) or theappl icat ion of a transformation in a prohibitedsyntactic conf igurat ion (EST)) wil l  result in arejection of this possible derivation.
Theappl icat ion of di f ferent optionaltransformations results in the production of avariety of surface forms.There are two reasons why we do not use thisgenerate and test approach.
The first is thatit is computat ional ly ineff icient to al low thetransformations to apply at random and to checkthe result to make sure that it is grammatical.More importantly, we view the transformationsas tools to be used by a process outs ide thesentence generator .
itself.
That is, anexternal process determines what the surfacesyntactic form of a given base structure shouldbe; the transformations are not independententit ies which make this decis ion on their own.For example, a focus mechanism should be ableto select or prohibit passive sentences, adialogue mechanism should be able to causeagent-deletion, and so on.
In OUr application,tutorial programs select the character ist ics  ofthe sentences to be produced on the basis ofthe syntactic ru le  or rules being exercised inthe particular tutorial.The Structural Change of each transformationconsists of one or more functions, analogous tothe transformational elementar ies oftradit ional transformational theory (Chomskv(1955, pp.
402-407, Section 93.1)).
We have154not adopted the restriction on the StructuralChange of transformations proposed by morerecent work in generative grammar (e.g.
Chomsky(1980, p. 4)) which prohibits "compounding ofelementaries"; i.e.
which limits the StructuralChange of a transformation to a singleoperation.
This would require breaking up manytransformations into several transformations,each of which would have to apply in thederivation of a particular syntacticconstruction rather than having onetransformation that performs the requiredoperations.
Inasmuch as we are interested inutilizing the generative capacity oftransformational grammar to produce specificconstructions, this break up of more general,overarching transformations into smaller, morespecific operations is undeslrable.The operations that are performed by the rulesare a combination of classic transformationaloperations (substitution, adjunction, deletion,insertion of non-lexical elements such as"there" and "do") and operations that llnguistssometimes relegate to the base or post-transformational processes (insertion ofpronouns, morphing of inflected forms).
Bymaking these operations rule-speclflc, manyrelated forms can be produced from the samebase tree and the control mechanisms outsidethe generator itself can speclfv which formsare to be produced.
(Figure 3 shows some ofthe transformations currently in the system.
)SUBJECT-AUX-INVERSIONSD: (S ~ (FEATS (TRANS.1)) COMP (FEATS (WH.+))1 2(S N *~ TNS (OPT NODE (FEATS (M.+)))))3 4 5 6SC: (DeleteNode 6)(DeleteNode 5)(LChomsk7 2 6)(LChomsky 2 5)Condition: \[NOT (EQ (QUOTE +)(FeatureValue (QUOTE WR)(RootFeats 4\]RELATIVE-PRONOUN-SPELL-OUT \[REPEATABLE\]SD: (S* XX (N "~ N "~ (S" (COMP X (N ~"1 2 3 4 5 6(FEATS (WH .
+)) WH)))))7SC: (DeleteSons 6)(LSon 6 (if (EQ "+(GetFeat 6 ~ HUMAN))then "whoelse ~whlch))Figure 3.
Sample TransformationsThose transformations which affect thesyntactic form of sentences are apnliedcyclically (see (Chomsky (1965, p. 143) formore details).
Thus transformations apply fromthe "bottom up" durinq the course of athe transformations are strictly iandextrinsically) ordered.
In addition to thecyclic syntactic transformations there exists aset of post-cyclic transformations, which applyafter all the cyclic syntactic transformationshave applied.
These post-cyclictransformations, whose domain of operationranges over the entire syntactic tree, supplythe correct morphological forms of all lexicaland grammatical items.
This includes qlvlnathe correct plural forms of nouns, theinflected forms of verbs, the proper forms ofpronouns (e.g.
"he," "she" and "they" insubject position and "him," "her," and "them"in object position), etc.
While it has beenrelatively rare in recent transformationalanalyses to utilize transformations to effectthis type of morphological "spell-out," thismechanism was first proposed in the earliestwork in generative grammar (Chomsky (1955)).Moreover, recent work by George (1980a; 1980b)and Ingria (in preparation) suggests that thisis indeed the correct way of handling suchmorphological processes.The transformations as a whole are divided upinto "families" of related transformations.For example, there is a family oftransformations which apply in the derivationof questions (all beginning with the prefixWH-); there is a family of morphlngtransformations (similarly beginning with theflagged mnemonic prefix MORPH-).
These"families" of transformations provide detailedcontrol over the generation process.
Forexample, all transformations of the W~- familywill apply to a single syntactic position thatmay be questioned (e.g.
subject, direct object,object of preposition, etc.
), resulting inquestions of the form "Who died" and "To whomdid she speak."
This familial characterizationof transformations is similar to the classicaltransformational approach (Chomsky (1955,p.
381, Section 90.1)) wherein families oftransformations were first postulated, becauseof the condition imposed within that frameworkthat each transformation must be a single-valued mapping.Our current sentence generator producesdeclarative sentences, passive sentences (withand without agent deletion), dative movementsentences, yes-no questions and wh-queetlons(including multlple-wh questions such as "Whogave what to whom?
'), there-insertlonsentences, negated sentences (including bothcontracted and emphatic forms), relativeclauses, finite and infinitival complements(e.g., "The teacher wanted Kathy to hurry.
'),imperative sentences, various complexauxiliaries (progressive, perfective, andmodals), predicate adjectives, and predicatenominals.
Although not all of theseconstructions are handled in completegenerality, the generator produces a very largeand natural subset of English.
It is importantto note that the interactions among all thesetransformations have been taken into account,so that any meaningful co~blnatlon of them willproduce a meaningful, grammatical sentence.
(Appendix A lists some of the sentences whichhave been produced by the interaction ofvarious transformations.
)derivation, applying first in the most embedded In our application, there is a need to generateclause and then working upwards until the ungrammatical utterances occasionally (formatrix clause is reached.
Within each cycle example, in a tutorial exercising the student's155abil ity to judge ?
the grammatical i tv  ofutterances).
To this end, we have developed anaddit ional set of transformations that can heused to generate utterances which mimic theungrammatical  forms found in the writ ing of thelanguage delayed populat ions for which thissystem is intended.
For example, deaf andhearing- impaired chi ldren often have dif f icultywith negative sentences, and replace the not ofStandard English negation with no and/or placethe negative element in posit ions in which itdoes not occur in Standard Engl ish (e.g.
"Themouse is no a big animal," "The girl no hasgone," "Dogs not can build trees").
The factthat these ungrammatical  forms may be model ledwith transformations is highly signif icant, andlends support to the claim (Chapman (1974),Fromkin (1973)) that ungrammatical  utterancesare rule-driven.4.
HIGHER LEVELS OF CONTROLIn order to manage the creat ion of the basetrees and the appl icat ion of thetransformational  rules, we have developedseveral layers of control  mechanisms.
Thefirst of these is a set of constraints thatdirects the operation of the base comoonent andindicates which transformations to try.
Atransformational  constraint  merely turns apart icular transformation on or off.
The factthat a transformation is turned on does notguarantee that it wi l l  apply; it merelyindicates that the Structural  Descr ipt ion andCondit ion of that transformation are to betried.
Base constraints can have either atomicindicators or a list of constraints as theirvalues.
For example, the direct objectconstraint (DIROBJ (PER 3) (NU PL) ...)specif ies all the base constraints necessary toproduce the N'" subtree for the direct objectposit ion in the base structure.There are a number of dependencies which existamong constraints.
For example, if thetransformational  constraint  for the passivetransformation is turned on, then the basecomponent must be instructed to produce adirect object and to choose a main verb thatmay be passivized; if the base constraint  for adirect object is turned off, then the baseconstraint for an indirect object must beturned off as well.
A data base ofimplications controls the appl icat ion ofconstraints so that whenever a constraint isset (or turned off), the base and/ortransformational  constraints that its valueimplies are also set.The notion of a part icular syntacticconstruct ion transcends the dist inct ion betweenbase and transformational  constraints.
The"natural" speci f icat ion of a syntacticconstruct ion such as passive or relative clauseshould be made without requir inq detai ledknowledge of the constraints or "theirimplications.
In addition, one might want torequest, say, a relative clause on the subject,without specifying whether the target ofrelat iv izat ion is to be the subject or objectof the embedded clause.We have developed a data base of structurescalled synspecs (for "syntacticspecif ications") which embody, at a very highlevel, the notion of a syntactic construction.These construct ions cannot be identif ied with asingle constraint or its implied constraints.
( Implications specify necessary dependencies;synspecs specify possible but not necessarychoices on the part of the system designersabout what combinations of constraints shouldbe invoked under a general name.)
A synspeccan contain an element of choice.
The choicecan be made by any user-def ined function,though in our practice most of the choices aremade at random.
One example of this is asynspec called wh-quest ion which decides whichof the synspecs that actual ly set up theconstraints for a wh-quest ion (question-on-subject, question-on-object,  quest ion-on-dative, etc.)
should be used.
The synspecsalso provide convenient hooks on which to hangother information associated with a syntacticconstruction: sentences exempl i fy ing theconstruction, a descr ipt ion of the construct ionfor purposes of documentation, etc.
Figure 4snows how several of the synspecs look whenprinted for the user.wh-quest ionCompute : (PickOne "(quest ion-on-subjectquest ion-on-objectquest ion-on-dative))Descr ipt ion : (This SynSpec wil l  create anyone of the questions withWH-words.
)second-person- imperat iveBaseConstraints : (( IMPERATIVE .
2)(TNS))TransConstraints :( (REQUEST-VOCATIVE-DELETION .
+}(REQUEST-EXCLAMATION-INSERTION .
+)(REQUEST-YOU-DELETION .
+))Examples : ('Open the door!
")Figure 4.
Sample SynSpecsSynspecs are invoked through a simple mechanismthat is avai lable to the tutorial component ofthe system.
Each tutorial specif ies the rangeof construct ions relevant to its topic andchooses among them for each sentence that is tobe generated.
To produce related sentences,the generator is restarted at thetransformational  component (using the previousbase tree) after the synspecs specifying therelat ionship have been processed.
)Just as  constraints have implications, so dosynspecs.
The relat ionships that hold amongsynspecs include exclusion (e.g.
transit ive-sentence excludes predicate-nominal-sentence),requirement (e.g.
extraposed-relat ive requiresrelative-clause-on-subject or relat lve-clause-on-object),  and permission (e.g.
predicate-adverb-sentence al lows there-insertion).
Amechanism similar to the implications forconstraints refines a set of candidate synspecsso that the user (or the tutorlals) can makechoices which are consistent.
Thus the userdoes not have to know, understand, or rememberwhich combinations of choices are allowed.156Once some constraints have been set (eitherdirectly or through synspecs), a command can begiven to generate a sentence.
The generatorfirst assigns values to the constraints thatthe user did not specify7 the values chosen areguaranteed to be compatible with the previouschoices, and the implications of these choicesensure that contradictory specifications cannotbe made.
Once all constraints have been set, abase tree is generated and saved before thetransformations are applied.
Because the basestructure has been saved, the transformationalconstraints can be reset and the generatorcalled to start at the transformationalcomponent, producing a different surfacesentence from the same base tree.
As manysentences as are wanted can be produced in thisway.5.
DEVELOPMENT TOOLSAs one side effect of the development of thegenerative system, we have built a debuggingenvironment called the syntactic playground inwhich a user can develop and test variouscomponents of the generator.
This environmenthas become more important than the tutorials intesting syntactic hypotheses and exploring thepower of the language generator.
In it,dictionary entries, transformations,implications and synspecs can be created,edited, and saved using interactive routinesthat ensure the correct format of those datatypes.
It is also possible here to givecommands to activate synspecs; this operationuses exactly the same interface as programs(e.g.
tutorials) that use the generator.Commands exist in the playground to set baseconstraints to specific values and to turnindividual transformations on and off withoutactivating the implications of thoseoperations.
This allows the system programmeror linguist to have complete control over allaspects of the generation process.Because the full power of the Interlisp systemis available to the playground user, the basetree can be edited directly, as can any versionof the tree during the derivation process.Transformations can also be "broken" likefunctions, so that when a transformation isabout to be tried the generator goes into a"break" and conducts an interactive dialoguewith the user who can control the matching ofthe Structural Description, examine the resultof the match, allow (or not) the application ofthe Structural Change, edit the transformationand try it again, and perform many of theoperations that are available in the generalplayground.
In addition to thetransformational break package there is a traceoption which, if used, prints the constraintsselected by the system, the words, and thetransformations that are tried as they apply orfail.
The playground has proved to be apowerful tool for exploring the interaction ofvarious rules and the efficacy of the wholegeneration package.6.
CONCLUSIONThis is the most syntactically powerfulgenerator that we know of.
It produces sets ofrelated sentences maintaining detailedknowledge of the choices that have been madeand the structure(s) that have been produced.Because the notion of "syntactic construction"is embodied in an appropriately high level ofsyntactic specification, the generator can beexternally controlled.
It is fast, efficient,and very easy to modify and maintain; it hasbeen implemented in both Interlisp on aDECSystem-20 and UCSD Pascal on the Cromemcoand Apple computers.
It forms the core of aset of tutorial programs for English now beingused by deaf children in a classroom setting,and thus is one of the first applications ofcomputational linguistics to be used in anactual educational environment.ReferencesBresnan, Joan (1975) "Transformations andCategories in Syntax," in R. Butts andJ.
Hintikka, eds.
Proceedings of the FifthInternational Congress of Lo@ic-~- Me- -~od~and Philosophy of Sc~-ence, University ofW-~tern Ontario, Lo -ndon,~ io .Chapman, Robin S. (1974) The Interpretation ofDeviant Sentences ~ ~ :  A~rmat iona l  Approach~- Janus Linguarum~Series Minor, Volume 189, Mouton, The Hague.Chomsky, Noam (1955) The Logical Structure ofLinguistic Theory, unpublished manuscript",microfilmed, MIT Libraries, partially publishedby Plenum Press, New York, 1975.Chomsky, Noam (1965) ~ of the Theory ofS~ntax, MIT Press, Cambrldge, Ma'ssa---6~usetts.
--Chomsky, Noam (1970) "Remarks onNominalization", in R .A .
Jacobs and P .S .Rosenbaum, eds., Readings inTransformational Grammar, G inn- -and  Co.,Waltham, Mass.Chomsky, Noam (1973) "Conditions onTransformations", in S .A .
Anderson andP.
Kiparsky, eds., A Festschrlft for MorrisHalle, Holt, Rinehart--and Winston, New~Yor-~.Chomsky, Noam (1977) "On WR-Movement", inP.
Culicover, T. Wasow and A'~'AkmaJian, eds.Formal S~ntax, Academic Press, Inc., New York.Chomsky, Noam (1980) "On Binding," LinguisticInquiry ll.Chomsky, Noam and Howard Lasnik (1977) "Filtersand Control", Linguistic Inquiry 8.Fromkin, Victoria A.
(1973) Speech Errors asLinguistic Evidence, Janua Ln~u~,  ~-eri~major, Volume 77, Mouton, The Hague.George, Leland M. (1980a) AnalogicalGeneralization in Natural Langua_qe Syntax,unpublished Doct6~'al D lsser '~aton ,~.George, Leland M. (1980b) AnalogicalGeneralizations of Natural Language Syntax,unpublished manus6"Fip6"7-~.Ingria, Robert (in preparation) SententialComplementation in Modern Greek, DoctoralDissertation, MIT.Jackendoff, Ray S. (1974) "Introduction to theX" Convention", distributed by IndianaUniversity Linguistics Club, Bloomington.Jackendoff, Ray S. (1978) X" ~ S  ntax: --A Study_ ofPhrase Structure, Linguistic Inqulry Monograp-~157 ~ MIT Press, Cambridge, Mass.A~end ix  A: Sample Sentences 6.
Superlat ive Sentencesi.
Transit ive Sentencesi.
The bull ies chased the girl.2.
What did the bul l ies do to thegirl?3.
They chased her.4.
Who chased the girl?5.
The bull ies chased her.6.
Who did they chase?7.
Whom did they chase?8.
They chased the girl.9.
How many bull ies chased thegirl?10.
Eight bull ies chased the girl.Ii.
How many bull ies chased her?12.
Eight bull ies chased her.13.
Who got chased?14.
The girl got chased.15.
She was chased by the bullies.16.
The girl was being chased bythe bullies.2.
Intransit ive Sentencesi.
What did the girl  do?2.
She cried.3.
Who cried?4.
The girl cried.3.
Indirect Discoursei.
Dan said that the girl  is sad.2.
Dan said that she is sad.3.
Who said that the girl  is sad?4.
Transit ive Sentence with IndirectObjecti.
The generous boy gave a doll tothe girl.2.
The generous boy gave the g i r la doll.3.
The girl was given a doll.4.
A doll was given to the girl.5.
Who gave the girl  a doll?6.
Who gave what to whom?7.
What did the generous boy givethe girl?8.
He gave her a doll.9.
What did the generous boy giveto the girl?i0.
He gave a doll to her.ii.
Who gave a doll to the girl?12.
Who gave the girl a doll?13.
Which boy gave the girl  a doll?14.
The generous boy gave her adoll.15.
Which boy gave a doll to thegirl?16.
The generous boy gave it tohe-.17.
How many dolls did the generousboy give the girl?18.
He gave her one doll.5.
Comparative Sentences!.
The soldier was better.2.
The gentleman wil l  be moreunhappy.3.
Al icia is hungrier than Jake.4.
The chi ldren were angrier thanAndy.158I.
A pol iceman caught the nicestbutterfl ies.2.
A sheepdog was the sickest pet.3.
The fire chief looks mostgenerous.4.
The smartest man swore.5.
The oldest bulldog broke thedolls.7.
Sentences with Inf init ivesI.
The teacher wanted Kathy tohurry.2.
The gentleman promised the ladyto close the door.3.
The girls were hard toridicule.8.
Relative ClausesI.
Whoever embraced the kids wil lembrace the ladies.2.
The girl who was intel l igentcheated the adults.3.
The woman who greased thetr icycle mumbled.4.
The teacher who lost thebul ldogs swears.9.
Negative Sentencesi.
Kim won't help.2.
Claire didn't help.3.
The chi ldren won't shout.4.
Do not slap the ~oodles.5.
Do not cry.i0.
Var iet ies of Quantl f iersi.
No toy breaks.2.
Some excited boys kissed thewomen.3.
Some hungry people eat.4.
Two men cried.5.
Every new toy broke.6.
Not every man slips.7.
The boy won't give the dogs anyoranges.8.
The girl  doesn't see any cats.9.
The old men didn't tell theboys any thing.i0.
The girl  didn't love any body.ii.
Var iet ies of Pronounsi.
Bette is the sad one.2.
Glor ia is the happy one.3.
Kevin is the saddest.4.
Kathy is the most cheerful.5.
Varda liked the sweet apple.6.
Varda liked the sweet one.12.
T~u~RE Sentencesi.
There were some toys in thedirt.2.
There were no toys in the dirt.3.
There weren't any toys in thedirt.
