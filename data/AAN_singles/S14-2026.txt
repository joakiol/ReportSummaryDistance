Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 171?175,Dublin, Ireland, August 23-24, 2014.Citius: A Naive-Bayes Strategy for Sentiment Analysis on English Tweets?Pablo GamalloCITIUSUniv.
de Santiago de Compostelapablo.gamallo@usc.esMarcos GarciaCilenis Language Technology, S.L.marcos.garcia@cilenis.comAbstractThis article describes a strategy based on anaive-bayes classifier for detecting the po-larity of English tweets.
The experimentshave shown that the best performance isachieved by using a binary classifier be-tween just two sharp polarity categories:positive and negative.
In addition, in or-der to detect tweets with and without po-larity, the system makes use of a very basicrule that searchs for polarity words withinthe analysed tweets/texts.
When the clas-sifier is provided with a polarity lexiconand multiwords it achieves 63% F-score.1 IntroductionSentiment Analysis consists in finding the opin-ion (e.g.
positive, negative, or neutral) from textdocuments such as movie reviews or product re-views.
Opinions about movies, products, etc.
canbe found in web blogs, social networks, discus-sion forums, and so on.
Companies can improvetheir products and services on the basis of the re-views and comments of their costumers.
Recently,many works have stressed the microblogging ser-vice Twitter.
As Twitter can be seen as a largesource of short texts (tweets) containing user opin-ions, most of these works make sentiment analysisby identifying user attitudes and opinions towarda particular topic or product (Go et al., 2009).
Thetask of making sentiment analysis from tweets is ahard challenge.
On the one hand, as in any senti-ment analysis framework, we have to deal with hu-man subjectivity.
Even humans often disagree on?This work has been supported by the projects: HPC-PLN: Ref:EM13/041 (Program Emergentes, Xunta de Gali-cia), Celtic: Ref:2012-CE138 and Plastic: Ref:2013-CE298(Program Feder-Innterconecta)This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/the categorization of the positive or negative sen-timent that is supposed to be expressed on a giventext (Villena-Rom?an et al., 2013).
On the otherhand, tweets are too short text to be linguisticallyanalyzed, and it makes the task of finding relevantinformation (e.g.
opinions) much harder.The SemEval-2014 task ?Sentiment Analysisin Twitter?
is an evaluation competition that in-cludes a specific task directly related to sentimentanalyisis.
In particular, subtask B, called ?Mes-sage Polarity Classification?, consists in classify-ing whether a given message is of positive, neg-ative, or neutral sentiment.
For messages con-veying both a positive and negative sentiment, thestronger sentiment should be chosen.
The resultsof our system in this task are situated in the aver-age out of 51 evaluated systems.In this article, we describe the learning strate-gies we developed so as to perform this task, all ofthem based on bayesian classification.2 Naive Bayes ClassifierMost of the algorithms for sentiment analysisare based on a classifier trained using a collec-tion of annotated text data.
Before training, datais preprocessed so as to extract the main fea-tures.
Some classification methods have been pro-posed: Naive Bayes, Support Vector Machines, K-Nearest Neighbors, etc.
However, and accordingto (Go et al., 2009), it is not clear which of theseclassification strategies is the more appropriate toperform sentiment analysis.We decided to use a classification strategy basedon Naive Bayes (NB) because it is a simple andintuitive method whose performance is similar toother approaches.
NB combines efficiency (opti-mal time performance) with reasonable accuracy.The main theoretical drawback of NB methods isthat it assumes conditional independence amongthe linguistic features.
If the main features are thetokens extracted from texts, it is evident that they171cannot be considered as independent, since wordsco-occuring in a text are somehow linked by dif-ferent types of syntactic and semantic dependen-cies.
However, even if NB produces an oversim-plified model, its classification decisions are sur-prinsingly accurate (Manning et al., 2008).2.1 StrategyTwo different naive bayes classifiers have beenbuilt, according to two different strategies:Baseline This is a naive bayes classifier thatlearns from the original training corpus howto classify the three categories found in thecorpus: Positive, Negative, and Neutral.
So,no modification has been introduced in thetraining corpus.Binary The second classifier was trained on asimplified training corpus and makes use ofa polarity lexicon.
The corpus was simpli-fied since only positive and negative tweetswere considered.
Neutral tweets were nottaken into account.
As a result, a basic bi-nary (or boolean) classifier which only iden-tifies both Positive and Negative tweets wastrained.
In order to detect tweets without po-larity (or Neutral), the following basic rule isused: if the tweet contains at least one wordthat is also found in the polarity lexicon, thenthe tweet has some degree of polarity.
Othe-wise, the tweet has no polarity at all and isclassified as Neutral.
The binary classifieris actually suited to specify the basic polar-ity between positive and negative, reaching aprecision of more than 80% in a corpus withjust these two categories.3 PreprocessingAs we will describe in the next section, the mainfeatures of the model are lemmas extracted usinglemmatization.
Given that the language of mi-croblogging requires a special treatment, we pro-pose a pre-processing task to correct and normal-ize the tweets before lemmatizing them.The main preprocessing tasks we considered arethe following:?
removing urls, references to usernames, andhashtags?
reduction of replicated characters (e.g.looooveeee?
love)?
identifying emoticons and interjections andreplacing them with polarity or sentiment ex-pressions (e.g.
:-)?
good)4 FeaturesThe features considered by the classifier are lem-mas, multiwords, polarity lexicons, and valenceshifters.4.1 Lemmas (UL)To characterise the main features underlying theclassifier, we make use of unigrams of lemmas in-stead of tokens to minimize the problems derivedfrom the sparse distribution of words.
Moreover,only lemmas belonging to lexical categories areselected as features, namely nouns, verbs, adjec-tives, and adverbs.
So, grammatical words, suchas determiners, conjunctions, and prepositions areremoved from the model.To configure the feature representation, the fre-quency of each selected lemma in a tweet is stored.4.2 Multiwords (MW)There is no agreement on which is the best optionfor sentiment analysis (unigrams, bigrams, ...).
In(Pak and Paroubek, 2010), the best performanceis achieved with bigrams, while (Go et al., 2009)show that the better results are reached with uni-grams.
An alternative option is to make use of aselected set of n-grams (or multiwords) identifiedby means of regular patterns of PoS tags.
Multi-word expressions identified by means of PoS tagspatterns can be conceived as linguistically moti-vated terms, since most of them are pairs of wordslinked by syntactic dependencies.So, in addition to unigrams of lemmas, we alsoconsider multiwords extracted by an algorithmbased on patterns of PoS tags.
In particular, weused the following set of patterns:?
NOUN-ADJ?
NOUN-NOUN?
ADJ-NOUN?
NOUN-PRP-NOUN?
VERB-NOUN?
VERB-PRP-NOUNThe instances of bigrams and trigrams extractedwith these patterns ared added to the unigrams172to build the language model.
Multiword extrac-tion was performed using our tool GaleXtra1, re-leased under GPL license and described in (MarioBarcala and Eva Dom?
?nguez and Pablo Gamalloand Marisol L?opez and Eduardo Moscoso andGuillermo Rojo and Paula Santalla and SusanaSotelo, 2007).4.3 Polarity Lexicon (LEX)We have built a polarity lexicon with both Positiveand Negative entries from different sources:?
AFINN-1112contains 2, 477 word forms,which were lemmatized and converted into1, 520, positive and negative lemmas.?
Hedonometer3contains about 10, 000 fre-quent words extracted from tweets whichwere classified as expressing some degree ofhapiness (Dodds et al., 2011).
We selectedthe 300 most positive lemmas from the initiallist.?
Hu&Liu list (Liu et al., 2005) contains over6, 800 words out of which 5 positive and neg-ative lemmas were selected 5, 695.?
Sentiwordnet-3.0 (Baccianella et al., 2010)contains more than 100, 000 entries.
We se-lected a subset of 6, 600 positive and negativelemmas with the highest polarity values.?
Finally, we have built a polarity lexicon with10, 850 entries by merging the previous ones.The final polarity lexicon is used in two differ-ent ways: on the one hand, it is used to identifyneutral tweets, since a tweet is considered as beingneutral if it does not contain any lemma appearingin the polarity lexicon.
On the other hand, we havebuilt artificial tweets as follows: each entry of thelexicon is converted into an artificial tweet withjust one lemma inheriting the polarity (positive ornegative) from the lexicon.
The frequency of theword in each new tweet is the average frequencyof lemmas in the training corpus.
These artificialtweets will be taken into account for training theclassifiers.1http://gramatica.usc.es/\?gamallo/gale-extra/index.htm2http://arxiv.org/abs/1103.29033http://www.hedonometer.org/4.4 Valence Shifters (VS)We take into account negative words that can shiftthe polarity of specific lemmas in a tweet.
Inthe presented work, we will make use of onlythose valence shifters that reverse the sentiment ofwords, namely negations.
The strategy to identifythe scope of negations relies on the PoS tags of thenegative word as well as of those words appearingto its right in the sequence.
The algorithm is asfollows:Whenever a negative word is found, its PoS tagis considered and, according to its syntactic prop-erties, we search for a polarity word (noun, verb,or adjective) within a window of 2 words after thenegation.
If a polarity word is found and is syntac-tically linked to the negative word, then its polarityis reversed.
For instance, if the negation word isthe adverb ?not?, the system only reverses the po-larity of verbs or adjectives appearing to its right.Nouns are not syntactically linked to this adverb.By contrast, if the negation is the determiner ?no?or ?none?, only the polarity of nouns can be re-versed.
Our strategy to deal with negation scopeis not so basic as those described in (Yang, 2008)and (Anta et al., 2013), which are just based ona rigid window after the negation word: 1 and 3words, respectively.5 Experiments and Evaluation5.1 Training corpusIn our preliminary experiments we have used thetraining dataset of tweets provided by SemEval-2014 organization (tweeti-b.dist.tsv).
This setcontains 6, 408 tweets, which were tagged withthe following polarity values: Positive, Nega-tive, Neutral, Objective, and Neutral-or-Objective.In order to fill the requirements of the task, wetransformed Neutral, Objective, and Natural-or-Objective into a single tag: Neutral.
In addi-tion, we also used a selection of annotated tweets(namely 5, 050 positive and negative ones), whichwere compiled from an external source (Narr et al.,2012).
Using the terminology provided by the or-ganizers of SemEval-2014, we call ?constrained?the systems trained with only the dataset providedby the organization and ?unconstrained?
the sys-tems trained with both datasets.5.2 Evaluated classifiersWe have implemented and evaluated several clas-sifiers by making use of the two strategies de-173scribed in section 2, combined with the featuresdefined in 4.
We also distinguished those clas-sifiers trained with only tweeti-b.dist.tsv (con-strained systems) from those trained with both in-ternal and external datasets (unconstrained).
As aresult, we implemented the following classifiers:CONSTRAINED-BASELINE: This systemwas implemented on the basis of the ?Base-line?
strategy and the following two features:unigrams of lemmas (UL) and valenceshifters (VS).CONSTRAINED-BASELINE-LEX: This sys-tem was implemented on the basis of the?Baseline?
strategy and the following threefeatures: unigrams of lemmas (UL), polaritylexicon (LEX), and valence shifters (VS).CONSTRAINED-BINARY-LEX: This systemwas implemented on the basis of the ?Base-line?
strategy and the following three fea-tures: unigrams of lemmas (UL), polaritylexicon (LEX), and valence shifters (VS).CONSTRAINED-BINARY-LEX-MW: Thissystem was implemented on the basis of the?Binary?
strategy and the following features:unigrams of lemmas (UL), multiwords(MW), polarity lexicon (LEX), and valenceshifters (VS).UNCONSTRAINED-BINARY-LEX: This sys-tem was implemented on the basis of the?Binary?
strategy and the following features:unigrams of lemmas (UL), polarity lexicon(LEX), and valence shifters (VS).UNCONSTRAINED-BINARY-LEX-MW:This system was implemented on the basis ofthe ?Binary?
strategy and the following fea-tures: unigrams of lemmas (UL), multiwords(MW), polarity lexicon (LEX), and valenceshifters (VS).All the classifers have been implemented withPerl language.
They rely on the naive-bayes algo-rithm and incorporate the preprocessing tasks de-fined in section 3.5.3 EvaluationTo evaluate the classification performance of theseclassifiers, we used as test corpus another datasetprovided by the organization: tweeti-b.devel.tsv.The results are shown in table 1, where the namesof the evaluated systems are in the first column andF-Score in the second one.System F-scoreCONSTR-BASE .49CONSTR-BASE-LEX .56CONSTR-BIN-LEX .57CONSTR-BIN-LEX-MW .61UNCONSTR-BIN-LEX .58UNCONSTR-BIN-LEX-MW .63Table 1: Results of our six systems.The results show that there is an improve-ment in performance when the classifiers are im-plemented with the Binary strategy, when theyuse a polarity lexicon, and when multiwords areconsidered as features.
The two systems sub-mmited to Semeval competition were those ob-tained the best scores: CONSTR-BIN-LEX-MWand UNCONSTR-BIN-LEX-MW.
The scores ob-tained by these two systems in the competitionare very similar to those obtained in the experi-ments depicted in Table 1.
More precisely, in theTweets2014 test corpus, the constrained systemreached 0.62 F-score while the unconstrained ver-sion achieved 0.63.
Our best system was rankedas 26th from 53 systems.
A Spanish version ofthis system (Gamallo et al., 2013) also participatedin the TASS-2013 competition (Villena-Rom?an etal., 2013), where it was ranked as the 3th best sys-tem out of 13 participants.6 ConclusionsWe have presented a family of naive-bayes classi-fiers for detecting the polarity of English tweets.The experiments have shown that the best per-formance is achieved by using a binary classi-fier trained to detect just two categories: posi-tive and negative.
In order to detect tweets withand without polarity we used a very basic strat-egy based on searching for polarity lemmas withinthe text/tweet.
If the tweet does not contain atleast one lemma also found in an external polaritylexicon, then the tweet has not any polarity and,thereby, is tagged with the Neutral value.
The useof both a polarity lexicon and multiwords also im-proves the results in a significant way.
Our sys-tem is being used by Cilenis S.L, a company spe-cialised in natural language technology, and beingapplied to four languages: English, Spanish, Por-tuguese, and Galician.174ReferencesAntonio Fern?andez Anta, Luis N?u?nez Chiroque,Philippe Morere, and Agust?
?n Santos.
2013.
Sen-timent Analysis and Topic Detection of SpanishTweets: A Comparative Study of NLP Techniques.Procesamiento del Lenguaje Natural, 50:45?52.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
SentiWordNet 3.0: An Enhanced Lex-ical Resource for Sentiment Analysis and OpinionMining.
In Human Language Technology Confer-ence - North American chapter of the Associationfor Computational Linguistics, pages 2200?2204.Peter Sheridan Dodds, Kameron Decker Harris, Is-abel M. Kloumann, Catherine A. Bliss, and Christo-pher M. Danforth.
2011.
Temporal patterns ofhappiness and information in a global social net-work: Hedonometrics and Twitter.
PLoS ONE,6(12):e26752.Pablo Gamallo, Marcos Garcia, and SantiagoFern?andez-Lanza.
2013.
TASS: A Naive-Bayesstrategy for sentiment analysis on Spanish tweets.In Workshop on Sentiment Analysis at SEPLN(TASS2013), pages 126?132, Madrid, Spain.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.In CS224N Technical report.
Standford.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: Analyzing and comparing opin-ions on the web.
In 14th International World WideWeb conference (WWW-2005), pages 342?351, NewYork, NY, USA.Chris Manning, Prabhakar Raghadvan, and HinrichSch?utze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, Cambridge,MA, USA.Mario Barcala and Eva Dom?
?nguez and Pablo Gamalloand Marisol L?opez and Eduardo Moscoso andGuillermo Rojo and Paula Santalla and SusanaSotelo.
2007.
A Corpus and Lexical Resources forMulti-word Terminology Extraction in the Field ofEconomy.
In 3rd Language & Technology Confer-ence (LeTC?2007), pages 355?359, Poznan, Poland.Sascha Narr, Michael Hulfenhaus, and Sahin Albayrak.2012.
Language-Independent Twitter SentimentAnalysis.
In Knowledge Discovery and MachineLearning (KDML), LWA, pages 12?14, Dortmund,Germany.Alexander Pak and Patrick Paroubek.
2010.
Twitter asa Corpus for Sentiment Analysis and Opinion Min-ing.
In LREC-2010, Valletta, Malta.Julio Villena-Rom?an, Sara Lana, Eugeinio Mart?
?nez-C?amara, and Juan Carlos Gonz?alez-Crist?obal.
2013.TASS - Workshop on Sentiment Analysis at SEPLN.Procesamiento del Lenguaje Natural, 50:37?44.Kiduk Yang.
2008.
WIDIT in TREC 2008 blogtrack: Leveraging Multiple Sources of Opinion Ev-idence.
In The Seventeenth Text Retrieval Confer-ence (TREC-2008), Gaithersburg, Maryland, USA.175
