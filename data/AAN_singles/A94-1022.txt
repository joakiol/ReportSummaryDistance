The Delphi Natural Language Understanding SystemMadeleine Bates, Robert Bobrow, Robert Ingria and David StallardBBN Systems and Technologies, Inc.70 Fawcett St.Cambridge, MA 02138AbstractThis paper presents Delphi, the naturallanguage component of the BBN SpokenLanguage System.
Delphi is a domain-independent natural language question an-swering system that is solidly based onlinguistic principles, yet which is also ro-bust to ungrammatical input.
It includesa domain-independent, broad-coverage ram-mar of English.
Analysis components includean agenda-based best-first parser and a fall-back component for partial understanding thatworks by fragment combination.
Delphi hasbeen formally evaluated in the ARPA SpokenLanguage program's ATIS (Airline Travel In-formation System) domain, and has performedwell.
Delphi has also been ported to a spo-ken language demonstration system in an AirForce Resource Management domain.
We dis-cuss results of the evaluation as well as theporting process.1 IntroductionDelphi is a natural language understanding system basedon general linguistic principles which is adaptable to anyquestion-answering domain.
It incorporates a number ofdomain-independent k owledge bases, including a gen-eral, broad-coverage rammar of English with a pow-erful and flexible handling of complementation.
Unlikemost other linguistically motivated systems, however,Delphi is also highly robust, allowing for partial under-standing when an input is ungrammatical, disfluent, ornot properly transcribed by a speech recognizer.
Thus,Delphi can be used for a spoken language applicationas readily as for a written one.
Furthermore, Delphi'spartial understanding component, called the SemanticLinker, is driven off the same system of semantic rulesas Delphi's regular best-first parser.
Building a robustapplication therefore requires no additional effort.There are several components of the system, whichis diagrammed in Figure 1.
First are the parser andSemantic Linker, which output an intermediate r pre-sentation we call a "semantic graph".
The semanticZtI  ..EL L.J1DATABASE \]1RESPONSEFigure 1: System Diagramgraph is passed to a quantification stage which pro-duces a fully scoped logical form from it.
The logicalform is then passed to the discourse stage, which re-solves pronominal references and performs other typesof task-dependent constraint resolution to produce thefinal logical form.
The final logical form is then passedto the backend translator, and then to the applicationsystem which produces the response.
Several knowl-edge bases are employed by these analysis components,including grammar, "realization rules" and the domainmodel, which represents the set of classes and binaryrelations of the given application domain.Delphi differs from most other linguistically moti-vated systems in the role that is played by syntax.The primary function of Delphi's parser and syntac-tic knowledge bases is not to produce a parse tree, butrather to constrain the search for an appropriate semanticgraph interpretation f the utterance.
Semantic graphsare produced not by rule-to-rule compositionality, butby what might be called "relation-to-relation" compo-sitionality - the association of grammatical relations inthe syntactic structure with semantic relations in the se-132mantic graph.This more incremental view of the syntax/semanticsinterface has three crucial advantages.
First, there ismuch more flexibility with respect o ordering and op-tionality of constituents.
Second, because relation-to-relation translations are simple, the task of porting thesystem is greatly simplified.
Third and finally, partialor fragmentary analyses can be represented, and a com-plete semantic graph interpretation for the utterance pro-duced even when a complete syntactic analyses is notavailable.In the remainder of the paper, we describe Del-phi's main processing components, representational for-malisms, and knowledge bases.2 Grammar  And The  Syntax /Semant icsInterfaceThe Delphi grammar is a broad coverage, domain inde-pendent grammar of English written in a version of theDefinite Clause Grammar formalism (Pereira and War-ren, 1980) that has been extended to include labeling ofright-hand side elements with the grammatical relationsthey bear to the head of the construction.
An exampleis:(S ?arg ?mood)->subject: (NP ?arg ?mood etc.
)head: (VP ?agr ?mood etc.
)In this rule, there is a head VP and an NP whichbears the SUBJECT relation to it.
Other grammati-cal relations include the familar DIRECT-OBJECT andINDIRECT-OBJECT as well as the prepositions, uchas TO, FROM, WITH and so on.Annotating sub-constituents with grammatical rela-tions regularizes the syntactic structure with respect oparticular grammatical rules, and allows a "relation-to-relation" form of compositionality, as opposed to themore traditional "rule-to-rule" version that is exempli-fied by such systems as Gemini (Dowding et al 1993)and the Core Language Engine (Alshawi, 1992).
Inrelation-to-relation compositionality, each grammaticalrelation in the syntactic structure corresponds to a se-mantic relation in a parallel semantic structure we calla "semantic graph".
The terminal nodes of the seman-tic graph are the word meanings, corresponding to thelexical heads of syntactic structure.An example of a semantic graph, representing themeaning of "What flights fly from Boston to Denver",may be seen in Figure 2.
The semantic graph is not afully quantified formula; rather it may be thought of asa form of predicate-argument representation, with quan-tifiers in place, from which a fully quantified formulacan be generated.
The allowed class and relation labelscome from the domain model.This view of the syntax/semantics interface hasmarked advantages.
For one thing, because the syn-tactic/semantic structure is built up one argument at aflight-ofFLY ~g ~ FLIGHTde.st-ofFigure 2: Semantic Graphquant~'WHtime, it becomes much easier to accomodate such phe-nomena s order-variation and optionality of argumentsthat are difficult for other approachesThe importance of this feature may be seen in theexamples of argument order-variation and optionalitythat abound in real data.
Consider the following fromthe ATIS domain, in which complements can vary freelyin order:What flights fly from Boston to Denver?What flights fly to Denver from Boston?or be separated from the head by a modifier typicallyregarded as an adjunct:What flights fly at 3 pm from Boston to Denver?In some cases, modifiers can be omitted, as in:What flights fly from Boston ?What flights fly to Denver?and sometimes the omission of an argument can haveanaphoric onsequences, as in:What restrictions apply?which cannot be felicitously uttered except in a con-text where there is something in the discourse that arestriction could "apply" to.Conventional approaches to subcategorization, suchas Definite Clause Grammar (Pereira and Warren,1980), Categorial Grammar (Ades and Steedman, 1982),PATR-II (Shieber, 1986), and lexicalized TAG (Schabeset al 1988) all deal with complementation by includ-ing in one form or another a notion of "subcategoriza-tion frame" that specifies a sequence of complementphrases and constraints on them.
Handling all the pos-sible variations in complement distribution in such for-malisms inevitably leads to an explosion in the numberof such frames, and a correspondingly more difficulttask in porting to a new domain.In our approach, on the other hand, it becomes pos-sible to view subcategorization f a lexical item as aset of constraints on the outgoing arcs of its semanticgraph node.
Different ypes of constraints - order of ar-guments, optionality of arguments, emantic-class con-straints and semantic effects of arguments - can all berepresented separately, instead of enumerating all pos-sible argument sequences in a set of alternative subcat-egorization frames.133Subcategorization constraints in Delphi are encodedin lexical entries using a structure called a "map" (Stal-lard and Bobrow, 1991).
Below is part of the lexicalentry for "fly" in the ATIS domain:FLYsub jec t  : FL IGHT-OFto : DEST-OFfrom: ORIG-OFcomplet ion: (and (f i l led fl ight-of)(or (f i l led dest-of)(f i l led orig-of) )Map entries have "translation", realization" and "com-pletion" components.
The translation part of this entryspecifies that the lexical head "fly" is to correspond to asemantic-graph node labeled with event-class FLY.
Therealization part of the entry specifies what grammati-cal relations the lexical item takes, and what semanticrelations these correspond to, or "realize", in the se-mantic graph.
Here, the entry specifies that "fly" takesSUBJECT, TO, and FROM complements, and that thesegrammatical relations correspond to the semantic rela-tions FLIGHT-OF, DEST-OF, and ORIG-OF respec-tively.
Semantic selectional restrictions in these argu-ment positions - that the filler of DEST-OF be a city,for example - are implicit from the declarations of therelations in the domain model.The "completion" part of the entry specifies what out-going arcs are required for the node.
Here, the entry re-quires that the FLIGHT-OF role be filled, and that eitherthe DEST-OF or ORIG-OF roles be filled (forbiddingthe intransitive "the flight flies").
More complex op-tionality cases are encoded with other completion pred-icates.
For example, the case where an anaphor mustbe present ("What restrictions apply") is encoded by thepredicate FILLED-OR-ANAPHOR.Some realization rules are tied to semantic lassesrather than lexical translations, and require for their ap-plication only that semantic lass restrictions implicitfrom the domain and range of the realized relation besatisfied.
Typical examples are the rules governing nounmodifier meanings, such as "Delta flights", "Delta'sflights", "the flights on/aboard Delta".
These would allbe handled by the global realization rule:{NOM-COMP POSS ABOARD ON ...}-....}AIRLINE-OFDetermining what semantic relation a given grammat-ical relation instance corresponds to is most generallyviewed as a form of goal-solving in Delphi, in whicha chain of rules can be invoked.
For example, syntac-tic constructions such as "X with Y", "X has Y" and"X's Y" are interpreted by first appealing to a rule map-ping them to a pseudo-relation called GENERALIZED-POSSESSION, and then seeking a realization for it thatis compatible with the classes of X and Y.
This avoidshaving to write three different versions of the same re-alization rule.BOSTON:TODENVERairline-ofDELTA~l~wr~ MONDAY:ONday-of.weekFigure 3: Fragment GraphsAn important advantage of the realization rule for-mulation, apart from its its power and flexibility, is itssimplicity.
Realization rules are very simple to write,and make maximal use both of knowledge about thedomain and general knowledge of language.3 Ill-Formedness Handling: TheSemantic LinkerWhen an utterance cannot be parsed with Delphi's best-first parser (Bobrow, 1991) - either because it is ill-formed, mis-recognized by the speech system, or sim-ply because it is outside the coverage of the grammar -it can still be partially understood by the system, oftenwell enough to give the correct response.
The compo-nent responsible for partial understanding in the Delphisystem is called the Semantic Linker (Stallard and Bo-brow, 1993).After a parse fails there is a set of fragmentary con-stituents left over in the chart, corresponding to a set ofsemantic graphs.
The Semantic Linker seeks to connectthese sub-graphs into a single connected one by addinglinks between odes in the different sub-graphs.At top-level, this is the same thing that the parserand grammar do.
The difference is that the parser andgrammar have an idea of what the grammatical rela-tionship between constituents i , based on requirementsof their proximity in the string and other syntactic ev-idence.
The Semantic Linker does not have these re-quirements, being a looser form of combination thatcan ignore fragment order and skip over intervening,unanalyzable material with ease.Although it is a very different algorithm, the Seman-tic Linker uses the same set of realization rules thatdrives the regular parser.
Using the realization rules,the Linker determines for each pair of nodes in dif-ferent semantic graphs the set of all links which canconnect hem.
It then uses an A* search to find themost plausible set of links which produce a completegraph.Suppose for example, we have the three fragments"to Boston", "Denver" and "Delta flights on Mon-day".
Then the three corresponding sub-graphs arethose shown in Figure 3 where a PP is treated as itsNP object with the preposition as a tag.
For this set offragmentary sub-graphs, the possible links are:la.
FL IGHTS1-- -  DEST-OF -> BOSTON:TO134lb.
FL IGHTS1- - -  OR IG-OF  ->  BOSTON:TO2a.
FL IGHTS1- - -  DEST-OF  -> DENVER2b.
FL IGHTS1- - -  OR IG-OF  -> DENVER3a.
DENVER- - -  NEARBY-TO -> BOSTON:TOwhere the links are grouped together in a ordered listaccording to the fragment-pairs they connect.The plausibility of a given link is a function of anumber of different features, including penalities fromassumptions made in its computation (e.g.
that a givenpreposition can be ignored or assumed) and empiricallydetermined probabilities for the given link (e.g.
thatgiven an AIRLINE and a FLIGHT they are most prob-ably linked by the relation AIRLINE-OF).The semantic linker may also "hallucinate" a newnode to bridge two fragments between whom no linkscan otherwise be computed.
For example, for the utter-ance "from Boston to Denver", which has no explicitFLIGHT-object, a FLIGHT node can be inserted be-tween the fragments to make sense of the utterance.Because the Semantic Linker uses the same set ofrealization rules as the rest of the system, when thesystem is ported to a new domain the Semantic Linkercan be used immediately - a distinct advantage oversome other approaches to fallback understanding, suchas (Stallard and Bobrow, 1992) or (Jackson et al 1991).In formal experiments (as we discuss subsequently)the Semantic Linker has been show to dramatically im-prove Delphi's performance.4 QuantificationThe quantifier scoping module in Delphi takes a se-mantic graph and produces a fully-scoped expressionin the logical language FMRL.
The basic strategy forquantifier scoping is a descendant of that used in theLUNAR system (Woods et al 1978).
This is madepossible by the use of the semantic graph as a com-mon underlying representation for both the grammaticaland ill-formod parts of fragmentary utterances.
Delphi'sscoping module traps quantifiers from relative clauses,makes the quantifiers from PPs etc.
outscope the NPquantifier, and resolves the scope of quantifiers fromparallel constituents in terms of left-to-right order inthe input.
These general rules are modified to take intoaccount differing strengths of quantifiers such as EACH.Left-to-right ordering and syntactic structure forgrammatical portions of the utterance are recoveredfrom the semantic graph by backpointers to the lexicalitems and grammatical relations from which the graphwas produced.
Links established by the semantic linkerare treated by the quantification mechanism as if theconstituency is indeterminate, so that only left-to-rightscoping rules and individual quantifier preferences takeeffect.The resulting mechanism is robust, and quantifica-tional scoping has been an insignificant source of errorin the official ARPA blind-test evaluations of the ATISsystem.
More complex strategies have been proposedand implemented in the last two decades, and could inprinciple be modifed to work with ill-formed input, butthe simple and robust LUNAR approach andles essen-tially all the phenomena seen in the tens of thousands ofsentences of ATIS training collected uring experimentswith non-linguist users.5 DiscourseThe discourse mechanism of Delphi consists of severalcomponents: resolution of local ambiguities, pronomi-nal and deictic antecedent resolution, ellipsis handlingand discourse constraint propagation.The most common case of local ambiguity in theATIS domain involves temporal phrases as in "the nineo'clock flight".
The resolution mechanism searchesboth for linguistic information in the current and previ-ous sentences, as well as properties of entities in previ-ous answers, to resolve whether "nine o'clock" is AMor PM.The pronourddeictic resolution mechanism used inDelphi makes use of locally expressed or implied se-mantic constraints to search through a set of candidateantecedents.
The current mechanism ignores syntac-tic number as a cue, because mpirically in the ATIScorpus (and we suspect in other spontaneous speech ap-plications) it is often in error.
A simple-minded focuscomponent is used, primarily based on recency, and sec-ondarily based on grammatical relations within an utter-ance.
Because of the strength of semantic ues and theprevalence of ill-formed input, the use of syntactic uesfor focus is limited.The interpretation of later sentences often must in-clude information from previous entences, without ex-plicit linguistic cues.
This is especially true in "designdialogues", where the goal is to find a description ofa set of objects that will meet some set of implicit orexplicit constraints.
Consider for example the followingdiscourse from the ATIS domain.Show Delta fights from Boston to Dallas tomorrow.Can I leave in the morning?Is there a nonstop flight?Show me the American flights.I want to go from Dallas to Chicago on WednesdayNote that the constraints of prior sentences (such as onairline, origin, destination etc.)
are implicit for subse-quent sentences unless contradicted by information inthe current sentence (e.g.
"American" overrides the"Delta" from the first sentence) or until there is evidencethat a new problem is being solved (the new origin anddestination in the last sentence indicates that all previ-ous constraints can be dropped).
Delphi has a "contexttracker" that maintains a stack of the constraints fromprevious utterances, and has a set of rules for whenconstraints are to be modified or deleted before beingmerged with the current sentence.Finally, we handle ellipsis as a special case of seman-tic linking.
If we have the two utterances:135Show me the meals on the morning flight.on American at 12:30We can treat these as if they were one run-on ill-formed input and link "American" to "flight", and re-place "morning" with "12:30", using a minor variant ofthe Semantic Linker linker which allows for later con-straints to overwrite arlier ones of the same type.
Thisstrategy has been very effective, and covers a large classof elliptical constructions.6 Backend MappingIn order to get a response to a user query, the completeFMRL interpretation of an utterance must be translatedto an expression of a target query language which can beevaluated irectly against he tabular database to retrievethe answer.A key step is bridging the gap in conceptual vo-cabulary between the two representations.
For exam-ple, the FMRL interpretation of the query "How manyflights on Delta serve meals" has one-place predicateslike FLIGHT and AIRLINE, and two-place predicateslike AIRLINE-OF and MEAL-OF.
The database for theATIS domain, on the other hand, only has a single tableFLIGHT with fields containing airline and meal infor-mation.
Delphi bridges this gap between representationswith a system of local mapping rules which translatethe one- and two-place predicates of the FMRL into ex-pressions of a relational algebra target language whichretrieve the extensions of these predicates.Sometimes, however, some combination of FMRLpredicates has a correspondence in the database but theindividual predicates themselves do not.
For example,in the database for the SPLINT domain a table relatingaircraft-types to their physical characteristics has a fieldfor the number of engines the aircraft has, but no rep-resentation for the engines themselves.
If we now ask"How many engines does an F-16 have?
", there is nolocal translation of the FMRL predicate ENGINE.To deal with this, Delphi has a system of global trans-formations that are applied first, rewriting subsets of theFMRL clauses to a form that can be handled with localtranslation.
The rule that handles this example is:(is-a :e engine number)(aircraft-engine-of :a :e)(is-a *count* number)(eq (number-engines-of :a) *count*)7 Interface To A Speech RecognizerIn spoken language applications, Delphi is interfacedto the output of the Byblos speech recognition system(Bates et al 1993).
The N-best paradigm is used, inwhich the recognizer outputs in order its top N guessesat the transcription of the sentence, for some value of N(usually 5).
Delphi then runs over these transcriptions inthe order they have been ranked, first with the SemanticLinker disabled so that only grammatical utterances are136allowed, and if none is found, runs over them againwith the Semantic Linker enabled.8 Results Of Formal Evaluation On ATISOur complete system including the Semantic Linker wasevaluated in the December 1993 ARPA ATIS evalua-tion.
Prior to evaluation, ATIS versions of the system'sdomain model, lexicon and realization rules had beendeveloped using several thousand utterances of trainingdata collected from users of ATIS.
An approximately1000-utterance s t was held aside as a blind test set onwhich all participating sites were evaluated.Error rate in this evaluation was defined as F+NA,where F was the percentage of queries answered incor-rectly, and NA the percentage of queries not answeredat all.
There were two evaluations on the same corpususing this metric: one of NL text understanding alone,and the other of a complete spoken language system(SLS) comprised of Delphi and the Byblos recognizer.Our system achieved an official result of 14.7% on theNL test, which was the third-lowest error rate achieved.The SLS error rate was 17.5%.Our own experiments show that using the SemanticLinker reduced our system's error rate on the NL test by43%.
This was largely achieved by dramatically low-ering the no-answer rate NA from 18.7% to 2.3%.
Justover 80% of this increment of sentences answered wereanswered correctly, so the Linker showed considerableaccuracy.9 Porting Delphi to the SPLINT DomainThe SPLINT (Speech and Language Integration) do-main is concerned with Air Force units and their com-ponent aircraft, weaponry and other physical attributesof aircraft, ordnance, and facilities (such as air bases,runways, bunkers, etc.).
The SPLINT database has 106fields in 23 tables.Some example utterances in the SPLINT domain are:What aircraft types are assigned to the 32nd?Which base has a unit carrying mavericks?Can a Stealth use Langley's runway 1 ?In order to port Delphi to the SPLINT domain,SPLINT-specific versions of the domain model, lexicon,realization rules and db-mapping rules were needed.
Forthe speech-understanding part of the application, wordpronunciations were also neccesary, as well as word-class membership for a statistical n-gram class gram-mar.
Delphi includes "core" versions of some of theseknowledge bases: a core domain model with commonclasses like NUMBER and TIME-OF-DAY and rela-tions like GREATER, a core lexicon with closed-classitems such as prepositions as well as words appropri-ate to question-answering i  general such as "show", towhich domain-specific items have to be added.In porting to SPLINT, 60 classes and 65 relationswere added to the domain model.
400 words were addedto the lexicon.
Of these, approximately half were de-rived from database field values.
118 realization ruleswere added.The grammar did not need to be modified, with theexception of adding one rule (for constructions such as"Mach 1").The entire process took about a person month to get90% coverage on a 1400 sentence corpus, developed in-dependently by a non-NL person.
An additional personweek was required to develop the speech-related knowl-edge bases.
A complete spoken language system withDelphi as the understanding component, plus a Motif-based user interface, was succesfully demonstrated atthe 1994 ARPA Human Language Technology meeting,and at Rome Labs in New York.
The porting process isdescribed in more detail in (Bates, 1994).This effort demonstrates that, given an appropriatesystem design, it is possible to build a complete spokenlanguage system that is robust o speech and productionerrors, and to do so rapidly and straightforwardly.10 Conclusion And SummaryIn conclusion, we have developed a technology thatmakes maximal use of general linguistic knowledge toimprove portability, while at the same time maintainingrobustness in the face of the type of input one can ex-pect from a real-life spoken language application.
Thesystem has been shown to reach high levels of perfor-mance in objective blind-test evaluation on the ATISdomain.
The system has also been shown to be rapidlyportable to a new domain, SPLINT.
This did not re-quire any changes in the underlying system code, andwas done with a relatively small effort.This work shows that computational linguistic meth-ods, based on general knowledge of language, can beused in large, robust spoken language systems, and thatspecial-purpose NL understanding systems do not haveto be built for each new task.11 AcknowledgmentsThe work reported here was supported by the AdvancedResearch Projects Agency and was monitored by theOffice of Naval Research under Contract No.
N00014-92-C-0035.
The views and conclusions contained in thisdocument are those of the authors and should not be in-terpreted as necessarily representing the official policies,either expressed or implied, of the Defense AdvancedResearch Projects Agency or the United States Govern-ment.ReferencesAdes, A. E. and Steedman, M. J.
1982.
On the Orderof Words.
In Linguistics and Philosophy 44.3, 1982,pp.
517-558.Alshawi, Hiyan (ed).
1992.
The Core Language Engine,MIT Press, Cambridge.137Bates, Madeleine t al.
1993.
The BBN/HARC SpokenLanguage Understanding System.
In Proceedings ofIEEE ICASSP-93 Minneapolis, MN, April 1993, pp.111-114, vol.
II.Bates, M. Beginning to Port a Spoken LanguageDatabase Interface In 4th Annual Dual Use Tech-nologies and Applications Conference, Utica NY May1994Bobrow, Robert.
1991.
Statistical Agenda ParsingIn Proceedings 4th DARPA Workshop on Speech andNatural LanguageDowding, John et al Gemini: A Natural LanguageUnderstanding System for Spoken Language Under-standing.
In Proceedings of the 31st Annual Meet-ing of the Association for Computational Linguistics,Columbus, OHJackson, Eric, Appelt, Douglas, Bear, John, Moore,Robert, and A. Podlozny.
A Template Matcher forRobust NL Interpretation.
In Proceedings Speech andNatural Language Workshop February 1991Pereira, F. C. N. and Warren, D. H. D. 1980.
DefiniteClause Grammars for Language Analysis--A Surveyof the Formalism and a Comparison with AugmentedTransition Networks.
In Artificial Intelligence 13,1980, pp.
231-278.Schabes, Y., Abeille, A., and Joshi, A. K. ParsingStrategies with 'Lexicalized' Grammars': Applica-tion to Tree Adjoining Grammars.
1988 In COLINGBudapest: PROCEEDINGS of the 12th InternationalConference on Computational Linguistics, Associa-tion for Computational Linguistics, Morristown, NJ,1988, pp.
578-583.Shieber, S. M. 1986.
An Introduction to Unification-Based Approaches to Grammar.
Center for the Studyof Language and Information, Stanford, CA, 1986.Stallard, David and Bobrow, Robert.
1991.
TheMapping Unit Approach to Subcategorization.
InProceedings Speech and Natural Language WorkshopMarch 1991Stallard, David and Bobrow, Robert.
1992.
FragmentProcessing in the DELPHI System.
In ProceedingsSpeech and Natural Language Workshop February1992Stallard, David and Bobrow, Robert.
1993.
The Seman-tic Linker - a New Fragment Combining Method.
InProceedings Human Language Technology WorkshopMarch 1993Woods, William A., Kaplan, Robert A., and Nash-Webber, B.
1978.
The Lunar Sciences Natural Lan-guage Information System: Final Report.
Report2378, Bolt, Beranek and Newman, Cambridge, MA.
