Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 411?418, Vancouver, October 2005. c?2005 Association for Computational LinguisticsUnsupervised Large-Vocabulary Word Sense Disambiguationwith Graph-based Algorithms for Sequence Data LabelingRada MihalceaDepartment of Computer ScienceUniversity of North Texasrada@cs.unt.eduAbstractThis paper introduces a graph-based algo-rithm for sequence data labeling, using ran-dom walks on graphs encoding label de-pendencies.
The algorithm is illustratedand tested in the context of an unsuper-vised word sense disambiguation problem,and shown to significantly outperform theaccuracy achieved through individual labelassignment, as measured on standard sense-annotated data sets.1 IntroductionMany natural language processing tasks consist of la-beling sequences of words with linguistic annotations,e.g.
word sense disambiguation, part-of-speech tag-ging, named entity recognition, and others.
Typicallabeling algorithms attempt to formulate the annota-tion task as a traditional learning problem, where thecorrect label is individually determined for each wordin the sequence using a learning process, usually con-ducted independent of the labels assigned to the otherwords in the sequence.
Such algorithms do not havethe ability to encode and thereby exploit dependen-cies across labels corresponding to the words in thesequence, which potentially limits their performancein applications where such dependencies can influencethe selection of the correct set of labels.In this paper, we introduce a graph-based sequencedata labeling algorithm well suited for such naturallanguage annotation tasks.
The algorithm simultane-ously annotates all the words in a sequence by ex-ploiting relations identified among word labels, us-ing random walks on graphs encoding label dependen-cies.
The random walks are mathematically modeledthrough iterative graph-based algorithms, which areapplied on the label graph associated with the givensequence of words, resulting in a stationary distribu-tion over label probabilities.
These probabilities arethen used to simultaneously select the most probableset of labels for the words in the input sequence.The annotation method is illustrated and tested onan unsupervised word sense disambiguation prob-lem, targeting the annotation of all open-class wordsin unrestricted text using information derived exclu-sively from dictionary definitions.
The graph-basedsequence data labeling algorithm significantly outper-forms the accuracy achieved through individual datalabeling, resulting in an error reduction of 10.7%, asmeasured on standard sense-annotated data sets.
Themethod is also shown to exceed the performance ofother previously proposed unsupervised word sensedisambiguation algorithms.2 Iterative Graphical Algorithms forSequence Data LabelingIn this section, we introduce the iterative graphical al-gorithm for sequence data labeling.
The algorithm issuccinctly illustrated using a sample sequence for ageneric annotation problem, with a more extensive il-lustration and evaluation provided in Section 3.Given a sequence of words W = {w1, w2, ..., wn},each word wi with corresponding admissible labelsLwi = {l1wi , l2wi , ..., lNwiwi }, we define a label graph G= (V,E) such that there is a vertex v ?
V for every pos-sible label ljwi , i = 1..n, j = 1..Nwi .
Dependenciesbetween pairs of labels are represented as directed orindirected edges e ?
E, defined over the set of vertexpairs V ?
V .
Such label dependencies can be learnedfrom annotated data, or derived by other means, as il-lustrated later.
Figure 1 shows an example of a graph-4111w12321 1 124w 2 w 3 w 4w1w13w1lllw2w2llw3l w4w4w4w4llll1.10.40.20.50.20.11.30.90.60.71.6[1.12][1.39][0.86][1.13][1.38][1.56] [0.40][1.05][0.58][0.48]Figure 1: Sample graph built on the set of possiblelabels (shaded nodes) for a sequence of four words(unshaded nodes).
Label dependencies are indicatedas edge weights.
Scores computed by the graph-basedalgorithm are shown in brackets, next to each label.ical structure derived over the set of labels for a se-quence of four words.
Note that the graph does nothave to be fully connected, as not all label pairs canbe related by a dependency.Given such a label graph associated with a sequenceof words, the likelihood of each label can be recur-sively determined using an iterative graph-based rank-ing algorithm, which runs over the graph of labels andidentifies the importance of each label (vertex) in thegraph.
The iterative graphical algorithm is modeling arandom walk, leading to a stationary distribution overlabel probabilities, represented as scores attached tovertices in the graph.
These scores are then used toidentify the most probable label for each word, result-ing in the annotation of all the words in the input se-quence.
For instance, for the graph drawn in Figure 1,the word w1 will be assigned with label l1w1 , since thescore associated with this label (1.39) is the maximumamong the scores assigned to all admissible labels as-sociated with this word.A remarkable property that makes these iterativegraphical algorithms appealing for sequence data la-beling is the fact that they take into account globalinformation recursively drawn from the entire graph,rather than relying on local vertex-specific informa-tion.
Through the random walk performed on the la-bel graph, these iterative algorithms attempt to collec-tively exploit the dependencies drawn between all la-bels in the graph, which makes them superior to otherapproaches that rely only on local information, indi-vidually derived for each word in the sequence.2.1 Graph-based RankingThe basic idea implemented by an iterative graph-based ranking algorithm is that of ?voting?
or ?recom-mendation?.
When one vertex links to another one, itis basically casting a vote for that other vertex.
Thehigher the number of votes that are cast for a vertex,the higher the importance of the vertex.
Moreover,the importance of the vertex casting a vote determineshow important the vote itself is, and this informationis also taken into account by the ranking algorithm.While there are several graph-based ranking algo-rithms previously proposed in the literature, we focuson only one such algorithm, namely PageRank (Brinand Page, 1998), as it was previously found success-ful in a number of applications, including Web linkanalysis, social networks, citation analysis, and morerecently in several text processing applications.Given a graph G = (V,E), let In(Va) be the setof vertices that point to vertex Va (predecessors), andlet Out(Va) be the set of vertices that vertex Va pointsto (successors).
The PageRank score associated withthe vertex Va is then defined using a recursive functionthat integrates the scores of its predecessors:P (Va) = (1 ?
d) + d ?
?Vb?In(Va)P (Vb)|Out(Vb)|(1)where d is a parameter that is set between 0 and 11.This vertex scoring scheme is based on a randomwalk model, where a walker takes random steps on thegraph G, with the walk being modeled as a Markovprocess ?
that is, the decision on what edge to followis solely based on the vertex where the walker is cur-rently located.
Under certain conditions, this modelconverges to a stationary distribution of probabilities,associated with vertices in the graph.
Based on theErgodic theorem for Markov chains (Grimmett andStirzaker, 1989), the algorithm is guaranteed to con-verge if the graph is both aperiodic and irreducible.The first condition is achieved for any graph that is anon-bipartite graph, while the second condition holdsfor any strongly connected graph ?
property achievedby PageRank through the random jumps introducedby the (1 ?
d) factor.
In matrix notation, the PageR-ank vector of stationary probabilities is the principaleigenvector for the matrix Arow, which is obtainedfrom the adjacency matrix A representing the graph,with all rows normalized to sum to 1: (P = ATrowP ).Intuitively, the stationary probability associatedwith a vertex in the graph represents the probability1The typical value for d is 0.85 (Brin and Page, 1998), and thisis the value we are also using in our implementation.412of finding the walker at that vertex during the ran-dom walk, and thus it represents the importance of thevertex within the graph.
In the context of sequencedata labeling, the random walk is performed on thelabel graph associated with a sequence of words, andthus the resulting stationary distribution of probabili-ties can be used to decide on the most probable set oflabels for the given sequence.2.2 Ranking on Weighted GraphsIn a weighted graph, the decision on what edge to fol-low during a random walk is also taking into accountthe weights of outgoing edges, with a higher likeli-hood of following an edge that has a larger weight.The weighted version of the ranking algorithm isparticularly useful for sequence data labeling, sincethe dependencies between pairs of labels are morenaturally modeled through weights indicating theirstrength, rather than binary 0/1 values.
Given a set ofweights wab associated with edges connecting verticesVa and Vb, the weighted PageRank score is determinedas:WP (Va) = (1?d)+d?Vb?In(Va)wba?Vc?Out(Vb)wbcWP (Vb) (2)2.3 Algorithm for Sequence Data LabelingGiven a sequence of words with their correspondingadmissible labels, the algorithm for sequence data la-beling seeks to identify a graph of label dependencieson which a random walk can be performed, resultingin a set of scores that can be used for label assignment.Algorithm 1 shows the pseudocode for the labelingprocess.
The algorithm consists of three main steps:(1) construction of label dependencies graph; (2) la-bel scoring using graph-based ranking algorithms; (3)label assignment.First, a weighted graph of label dependencies isbuilt by adding a vertex for each admissible label, andan edge for each pair of labels for which a dependencyis identified.
A maximum allowable distance can beset (MaxDist), indicating a constraint over the dis-tance between words for which a label dependencyis sought.
For instance, if MaxDist is set to 3, noedges will be drawn between labels corresponding towords that are more than three words apart, countingall running words.
Label dependencies are determinedthrough the Dependency function, whose definitiondepends on the application and type of resources avail-able (see Section 2.4).Next, scores are assigned to vertices using a graph-based ranking algorithm.
Current experiments areAlgorithm 1 Graph-based Sequence Data LabelingInput: Sequence W = {wi|i = 1..N}Input: Admissible labels Lwi = {ltwi |t = 1..Nwi},i = 1..NOutput: Sequence of labels L = {lwi |i = 1..N}, with label lwicorresponding to word wi from the input sequence.Build graph G of label dependencies1: for i = 1 to N do2: for j = i + 1 to N do3: if j ?
i > MaxDist then4: break5: end if6: for t = 1 to Nwi do7: for s = 1 to Nwj do8: weight?
Dependency(ltwi , lswj , wi, wj)9: if weight > 0 then10: AddEdge(G, ltwi , lswj , weight)11: end if12: end for13: end for14: end for15: end forScore vertices in G1: repeat2: for all Va ?
V ertices(G) do3: WP (Va) = (1?
d) + d?
?Vb?In(Va)wbaWP (Vb)/?Vc?Out(Vb)wbc4: end for5: until convergence of scores WP (Va)Label assignment1: for i = 1 to N do2: lwi ?
argmax{WP (ltwi)|t = 1..Nwi}3: end forbased on PageRank, but other ranking algorithms canbe used as well.Finally, the most likely set of labels is determinedby identifying for each word the label that has thehighest score.
Note that all admissible labels corre-sponding to the words in the input sequence are as-signed with a score, and thus the selection of two ormore most likely labels for a word is also possible.2.4 Label DependenciesLabel dependencies can be defined in various ways,depending on the application at hand and on theknowledge sources that are available.
If an annotatedcorpus is available, dependencies can be defined aslabel co-occurrence probabilities approximated withfrequency counts P (ltwi , lswj ), or as conditional prob-abilities P (ltwi |lswj ).
Optionally, these dependenciescan be lexicalized by taking into account the corre-sponding words in the sequence, e.g.
P (ltwi |lswj ) ?P (wi|ltwi).
In the absence of an annotated corpus, de-pendencies can be derived by other means, e.g.
part-413of-speech probabilities can be approximated from araw corpus as in (Cutting et al, 1992), word-sense de-pendencies can be derived as definition-based similar-ities, etc.
Label dependencies are set as weights onthe arcs drawn between corresponding labels.
Arcscan be directed or undirected for joint probabilities orsimilarity measures, and are usually directed for con-ditional probabilities.2.5 Labeling ExampleConsider again the example from Figure 1, consistingof a sequence of four words, and their possible cor-responding labels.
In the first step of the algorithm,label dependencies are determined, and let us assumethat the values for these dependencies are as indicatedthrough the edge weights in Figure 1.
Next, verticesin the graph are scored using an iterative ranking al-gorithm, resulting in a score attached to each label,shown in brackets next to each vertex.
Finally, themost probable label for each word is selected.
Wordw1 is thus assigned with label l1w1 , since the score ofthis label (1.39) is the maximum among the scores as-sociated with all its possible labels (1.39, 1.12, 0.86).Similarly, word w2 is assigned with label l2w2 , w3 withlabel l1w3 , and w4 receives label l2w4 .2.6 Efficiency ConsiderationsFor a sequence of words W = {w1, w2, ..., wn}, eachword wi with Nwi admissible labels, the running timeof the graph-based sequence data labeling algorithmis proportional with O(Cn?i=1i+MaxDist?j=i+1(Nwi ?
Nwj ))(the time spent in building the label graph and iteratingthe algorithm for a constant number of times C).
Thisis order of magnitudes better than the running timeof O(n?i=1Nwi) for algorithms that attempt to select thebest sequence of labels by searching through the en-tire space of possible label combinations, although itcan be significantly higher than the running time ofO(n?i=1Nwi) for individual data labeling.2.7 Other Algorithms for Sequence DataLabelingIt is interesting to contrast our algorithm with previ-ously proposed models for sequence data labeling, e.g.Hidden Markov Models, Maximum Entropy MarkovModels, or Conditional Random Fields.
Althoughthey differ in the model used (generative, discrimina-tive, or dual), and the type of probabilities involved(joint or conditional), these previous algorithms areall parameterized algorithms that typically require pa-rameter training through maximization of likelihoodon training examples.
In these models, parameters thatmaximize sequence probabilities are learned from acorpus during a training phase, and then applied tothe annotation of new unseen data.
Instead, in thealgorithm proposed in this paper, the likelihood of asequence of labels is determined during test phase,through random walks performed on the label graphbuilt for the data to be annotated.
While current eval-uations of our algorithm are performed on an unsuper-vised labeling task, future work will consider the eval-uation of the algorithm in the presence of an annotatedcorpus, which will allow for direct comparison withthese previously proposed models for sequence datalabeling.3 Experiments in Word SenseDisambiguationThe algorithm for sequence data labeling is illustratedand tested on an all-words word sense disambiguationproblem.
Word sense disambiguation is a labeling taskconsisting of assigning the correct meaning to eachopen-class word in a sequence (usually a sentence).Most of the efforts for solving this problem were con-centrated so far toward targeted supervised learning,where each sense tagged occurrence of a particularword is transformed into a feature vector used in anautomatic learning process.
The applicability of suchsupervised algorithms is however limited to those fewwords for which sense tagged data is available, andtheir accuracy is strongly connected to the amount oflabeled data available at hand.
Instead, algorithms thatattempt to disambiguate all-words in unrestricted texthave received significantly less attention, as the devel-opment and success of such algorithms has been hin-dered by both (a) lack of resources (training data), and(b) efficiency aspects resulting from the large size ofthe problem.3.1 Graph-based Sequence Data Labeling forUnsupervised Word Sense DisambiguationTo apply the graph-based sequence data labeling algo-rithm to the disambiguation of an input text, we needinformation on labels (word senses) and dependencies(word sense dependencies).
Word senses can be eas-ily obtained from any sense inventory, e.g.
WordNetor LDOCE.
Sense dependencies can be derived in var-ious ways, depending on the type of resources avail-able for the language and/or domain at hand.
In thispaper, we explore the unsupervised derivation of sense414dependencies using information drawn from machinereadable dictionaries, which is general and can be ap-plied to any language or domain for which a sense in-ventory is available.Relying exclusively on a machine readable dictio-nary, a sense dependency can be defined as a measureof similarity between word senses.
There are severalmetrics that can be used for this purpose, see for in-stance (Budanitsky and Hirst, 2001) for an overview.However, most of them rely on measures of seman-tic distance computed on semantic networks, and thusthey are limited by the availability of explicitly en-coded semantic relations (e.g.
is-a, part-of).
Tomaintain the unsupervised aspect of the algorithm, wechose instead to use a measure of similarity based onsense definitions, which can be computed on any dic-tionary, and can be evaluated across different parts-of-speech.Given two word senses and their corresponding def-initions, the sense similarity is determined as a func-tion of definition overlap, measured as the number ofcommon tokens between the two definitions, after run-ning them through a simple filter that eliminates allstop-words.
To avoid promoting long definitions, wealso use a normalization factor, and divide the contentoverlap of the two definitions with the length of eachdefinition.
This sense similarity measure is inspiredby the definition of the Lesk algorithm (Lesk, 1986).Starting with a sense inventory and a function forcomputing sense dependencies, the application of thesequence data labeling algorithm to the unsuperviseddisambiguation of a new text proceeds as follows.First, for the given text, a label graph is built byadding a vertex for each possible sense for all open-class words in the text.
Next, weighted edges aredrawn using the definition-based semantic similaritymeasure, computed for all pairs of senses for wordsfound within a certain distance (MaxDist, as definedin Algorithm 1).
Once the graph is constructed, thegraph-based ranking algorithm is applied, and a scoreis determined for all word senses in the graph.
Finally,for each open-class word in the text, we select the ver-tex in the label graph which has the highest score, andlabel the word with the corresponding word sense.3.2 An ExampleConsider the task of assigning senses to the wordsin the text The church bells no longer rung on Sun-days2.
For the purpose of illustration, we assume at2Example drawn from the data set provided during theSENSEVAL-2 English all-words task.
Manual sense annotationsThe church bells no longer rung on Sundays.church1: one of the groups of Christians who have their own beliefsand forms of worship2: a place for public (especially Christian) worship3: a service conducted in a churchbell1: a hollow device made of metal that makes a ringing soundwhen struck2: a push button at an outer door that gives a ringing or buzzingsignal when pushed3: the sound of a bellring1: make a ringing sound2: ring or echo with sound3: make (bells) ring, often for the purposes of musical edifica-tionSunday1: first day of the week; observed as a day of rest and worshipby most Christiansbell ring[1.46][0.99][0.96] [2.56][0.63][0.58][0.42][0.67]SundaychurchS2S1s3s2s3s2S3s1 S1s10.350.501.060.400.190.341.010.55 [0.73]0.30[0.93]0.350.310.800.850.23Figure 2: The label graph for assigning senses towords in the sentence The church bells no longer rungon Sundays.most three senses for each word, which are shown inFigure 2.
Word senses and definitions are obtainedfrom the WordNet sense inventory (Miller, 1995).
Allword senses are added as vertices in the label graph,and weighted edges are drawn as dependencies amongword senses, derived using the definition-based sim-ilarity measure (no edges are drawn between wordsenses with a similarity of zero).
The resulting labelgraph is an undirected weighted graph, as shown inFigure 2.
After running the ranking algorithm, scoresare identified for each word-sense in the graph, indi-cated between brackets next to each node.
Selectingfor each word the sense with the largest score results inthe following sense assignment: The church#2 bells#1were also made available for this data.415no longer rung#3 on Sundays#1, which is correct ac-cording to annotations performed by professional lex-icographers.3.3 Results and DiscussionThe algorithm was primarily evaluated on theSENSEVAL-2 English all-words data set, consistingof three documents from Penn Treebank, with 2,456open-class words (Palmer et al, 2001).
Unlike othersense-annotated data sets, e.g.
SENSEVAL-3 or Sem-Cor, SENSEVAL-2 is the only testbed for all-wordsword sense disambiguation that includes a sense map,which allows for additional coarse-grained sense eval-uations.
Moreover, there is a larger body of previouswork that was evaluated on this data set, which can beused as a base of comparison.The performance of our algorithm is compared withthe disambiguation accuracy obtained with a variationof the Lesk algorithm3 (Lesk, 1986), which selects themeaning of an open-class word by finding the wordsense that leads to the highest overlap between the cor-responding dictionary definition and the current con-text.
Similar to the definition similarity function usedin the graph-based disambiguation algorithm (Section3.1), the overlap measure used in the Lesk implemen-tation does not take into account stop-words, and it isnormalized with the length of each definition to avoidpromoting longer definitions.We are thus comparing the performance of se-quence data labeling, which takes into account labeldependencies, with individual data labeling, where alabel is selected independent of the other labels inthe text.
Note that both algorithms rely on the sameknowledge source, i.e.
dictionary definitions, and thusthey are directly comparable.
Moreover, none of thealgorithms take into account the dictionary sense order(e.g.
the most frequent sense provided by WordNet),and therefore they are both fully unsupervised.Table 1 shows precision and recall figures4 for a3Given a sequence of words, the original Lesk algorithm at-tempts to identify the combination of word senses that maxi-mizes the redundancy (overlap) across all corresponding defini-tions.
The algorithm was later improved through a method forsimulated annealing (Cowie et al, 1992), which solved the com-binatorial explosion of word senses, while still finding an optimalsolution.
However, recent comparative evaluations of differentvariants of the Lesk algorithm have shown that the performanceof the original algorithm is significantly exceeded by an algorithmvariation that relies on the overlap between word senses and cur-rent context (Vasilescu et al, 2004).
We are thus using this latterLesk variant in our implementation.4Recall is particularly low for each individual part-of-speechbecause it is calculated with respect to the entire data set.
Theoverall precision and recall figures coincide, reflecting the 100%coverage of the algorithm.context size (MaxDist) equal to the length of eachsentence, using: (a) sequence data labeling with itera-tive graph-based algorithms; (b) individual data label-ing with a version of the Lesk algorithm; (c) randombaseline.
Evaluations are run for both fine-grainedand coarse-grained sense distinctions, to determinethe algorithm performance under different classifica-tion granularities.The accuracy of the graph-based sequence data la-beling algorithm exceeds by a large margin the indi-vidual data labeling algorithm, resulting in 10.7% er-ror rate reduction for fine-grained sense distinctions,which is statistically significant (p < 0.0001, pairedt-test).
Performance improvements are equally dis-tributed across all parts-of-speech, with comparableimprovements obtained for nouns, verbs, and adjec-tives.
A similar error rate reduction of 11.0% is ob-tained for coarse-grained sense distinctions, whichsuggests that the performance of the graph-based se-quence data labeling algorithm does not depend onclassification granularity, and similar improvementsover individual data labeling can be obtained regard-less of the average number of labels per word.We also measured the variation of performance withcontext size, and evaluated the disambiguation ac-curacy for both algorithms for a window size rang-ing from two words to an entire sentence.
The win-dow size parameter limits the number of surround-ing words considered when seeking label dependen-cies (sequence data labeling), or the words countedin the measure of definition?context overlap (individ-ual data labeling).
Figure 3 plots the disambiguationaccuracy of the two algorithms as a function of con-text size.
As seen in the figure, both algorithms ben-efit from larger contexts, with a steady increase inperformance observed for increasingly larger windowsizes.
Although the initial growth observed for the se-quence data labeling algorithm is somewhat sharper,the gap between the two curves stabilizes for windowsizes larger than five words, which suggests that theimprovement in performance achieved with sequencedata labeling over individual data labeling does not de-pend on the size of available context.The algorithm was also evaluated on two otherdata sets, SENSEVAL-3 English all-words data(Snyder and Palmer, 2004) and a subset of SemCor(Miller et al, 1993), although only fine-grained senseevaluations could be conducted on these test sets.The disambiguation precision on the SENSEVAL-3data was measured at 52.2% using sequence datalabeling, compared to 48.1% obtained with individual416Fine-grained sense distinctions Coarse-grained sense distinctionsRandom Individual Sequence Random Individual SequencePart-of baseline (Lesk) (graph-based) baseline (Lesk) (graph-based)speech P R P R P R P R P R P RNoun 41.4% 19.4% 50.3% 23.6% 57.5% 27.0% 42.7% 20.0% 51.4% 24.1% 58.8% 27.5%Verb 20.7% 3.9% 30.5% 5.7% 36.5% 6.9% 22.8% 4.3% 31.9% 6.0% 37.9% 7.1%Adjective 41.3% 9.3% 49.1% 11.0% 56.7% 12.7% 42.6% 42.6% 49.8% 11.2% 57.6% 12.9%Adverb 44.6% 5.2% 64.6% 7.6% 70.9% 8.3% 40.7% 4.8% 65.3% 7.7% 71.9% 8.5%ALL 37.9% 37.9% 48.7% 48.7% 54.2% 54.2% 38.7% 38.7% 49.8% 49.8% 55.3% 55.3%Table 1: Precision and recall for graph-based sequence data labeling, individual data labeling, and randombaseline, for fine-grained and coarse-grained sense distinctions.3540455055600  5  10  15  20  25  30Disambiguationprecision(%)Window sizesequenceindividualrandomFigure 3: Disambiguation results using sequence datalabeling, individual labeling, and random baseline, forvarious context sizes.data labeling, and 34.3% achieved through randomsense assignment.
The average disambiguation figureobtained on all the words in a random subset of 10SemCor documents, covering different domains, was56.5% for sequence data labeling, 47.4% for individ-ual labeling, and 35.3% for the random baseline.Comparison with Related WorkFor a given sequence of ambiguous words, the origi-nal definition of the Lesk algorithm (Lesk, 1986), andmore recent improvements based on simulated anneal-ing (Cowie et al, 1992), seek to identify the combina-tion of senses that maximizes the overlap among theirdictionary definitions.
Tests performed with this algo-rithm on the SENSEVAL-2 data set resulted in a dis-ambiguation accuracy of 39.5%.
This precision is ex-ceeded by the Lesk algorithm variation used in the ex-periments reported in this paper, which measures theoverlap between sense definitions and the current con-text, for a precision of 48.7% on the same data set (seeTable 1).
In the SENSEVAL-2 evaluations, the bestperforming fully unsupervised algorithm5 was devel-oped by (Litkowski, 2001), who combines analysis ofmultiword units and contextual clues based on collo-cations and content words from dictionary definitionsand examples, for an overall precision and recall of45.1%.
More recently, (McCarthy et al, 2004) reportsone of the best results on the SENSEVAL-2 data set,using an algorithm that automatically derives the mostfrequent sense for a word using distributional similari-ties learned from a large raw corpus, for a disambigua-tion precision of 53.0% and a recall of 49.0%.Another related line of work consists of the disam-biguation algorithms based on lexical chains (Morrisand Hirst, 1991), and the more recent improvementsreported in (Galley and McKeown, 2003) ?
wherethreads of meaning are identified throughout a text.Lexical chains however only take into account con-nections between concepts identified in a static way,without considering the importance of the conceptsthat participate in a relation, which is recursively de-termined in our algorithm.
Moreover, the constructionof lexical chains requires structured dictionaries suchas WordNet, with explicitly defined semantic relationsbetween word senses, whereas our algorithm can alsowork with simple unstructured dictionaries that pro-vide only word sense definitions.
(Galley and McK-eown, 2003) evaluated their algorithm on the nounsfrom a subset of SEMCOR, reporting 62.09% dis-ambiguation precision.
The performance of our al-gorithm on the same subset of SEMCOR nouns wasmeasured at 64.2%6.
Finally, another disambiguationmethod relying on graph algorithms that exploit the5Algorithms that integrate the most frequent sense in Word-Net are not considered here, since this represents a supervisedknowledge source (WordNet sense frequencies are derived from asense-annotated corpus).6Note that the results are not directly comparable, since (Gal-ley and McKeown, 2003) used the WordNet sense order to breakthe ties, whereas we assume that such sense order frequency is notavailable, and thus we break the ties through random choice.417structure of semantic networks was proposed in (Mi-halcea et al, 2004), with a disambiguation accuracy of50.9% measured on all the words in the SENSEVAL-2data set.Although it relies exclusively on dictionary defini-tions, the graph-based sequence data labeling algo-rithm proposed in this paper, with its overall perfor-mance of 54.2%, exceeds significantly the accuracyof all these previously proposed unsupervised wordsense disambiguation methods, proving the benefits oftaking into account label dependencies when annotat-ing sequence data.
An additional interesting benefit ofthe algorithm is that it provides a ranking over wordsenses, and thus the selection of two or more mostprobable senses for each word is also possible.4 ConclusionsWe proposed a graphical algorithm for sequence datalabeling that relies on random walks on graphs encod-ing label dependencies.
Through the label graphs itbuilds for a given sequence of words, the algorithm ex-ploits relations between word labels, and implementsa concept of recommendation.
A label recommendsother related labels, and the strength of the recom-mendation is recursively computed based on the im-portance of the labels making the recommendation.In this way, the algorithm simultaneously annotatesall the words in an input sequence, by identifying themost probable (most recommended) set of labels.The algorithm was illustrated and tested on an unsu-pervised word sense disambiguation problem, target-ing the annotation of all words in unrestricted texts.Through experiments performed on standard sense-annotated data sets, the graph-based sequence data la-beling algorithm was shown to significantly outper-form the accuracy achieved through individual data la-beling, resulting in a statistically significant error ratereduction of 10.7%.
The disambiguation method wasalso shown to exceed the performance of previouslyproposed unsupervised word sense disambiguation al-gorithms.
Moreover, comparative results obtained un-der various experimental settings have shown that thealgorithm is robust to changes in classification granu-larity and context size.AcknowledgmentsThis work was partially supported by a National Sci-ence Foundation grant IIS-0336793.ReferencesS.
Brin and L. Page.
1998.
The anatomy of a large-scalehypertextual Web search engine.
Computer Networksand ISDN Systems, 30(1?7).A.
Budanitsky and G. Hirst.
2001.
Semantic distance inwordnet: An experimental, application-oriented evalu-ation of five measures.
In Proceedings of the NAACLWorkshop on WordNet and Other Lexical Resources,Pittsburgh.J.
Cowie, L. Guthrie, and J. Guthrie.
1992.
Lexical disam-biguation using simulated annealing.
In Proceedings ofthe 5th International Conference on Computational Lin-guistics (COLING 1992).D.
Cutting, J. Kupiec, J. Pedersen, and P. Sibun.
1992.A practical part-of-speech tagger.
In Proceedings ofthe Third Conference on Applied Natural Language Pro-cessing ANLP-92.M.
Galley and K. McKeown.
2003.
Improving word sensedisambiguation in lexical chaining.
In Proceedings ofthe 18th International Joint Conference on Artificial In-telligence (IJCAI 2003), Acapulco, Mexico, August.G.
Grimmett and D. Stirzaker.
1989.
Probability and Ran-dom Processes.
Oxford University Press.M.E.
Lesk.
1986.
Automatic sense disambiguation usingmachine readable dictionaries: How to tell a pine conefrom an ice cream cone.
In Proceedings of the SIGDOCConference 1986, Toronto.K.
Litkowski.
2001.
Use of machine readable dictionariesin word sense disambiguation for Senseval-2.
In Pro-ceedings of ACL/SIGLEX Senseval-2, Toulouse, France.D.
McCarthy, R. Koeling, J. Weeds, and J. Carroll.2004.
Using automatically acquired predominant sensesfor word sense disambiguation.
In Proceedings ofACL/SIGLEX Senseval-3, Barcelona, Spain.R.
Mihalcea, P. Tarau, and E. Figa.
2004.
PageRank on se-mantic networks, with application to word sense disam-biguation.
In Proceedings of the 20st International Con-ference on Computational Linguistics (COLING 2004).G.
Miller, C. Leacock, T. Randee, and R. Bunker.
1993.A semantic concordance.
In Proceedings of the 3rdDARPA Workshop on Human Language Technology,Plainsboro, New Jersey.G.
Miller.
1995.
Wordnet: A lexical database.
Communi-cation of the ACM, 38(11):39?41.J.
Morris and G. Hirst.
1991.
Lexical cohesion, the the-saurus, and the structure of text.
Computational Lin-guistics, 17(1):21?48.M.
Palmer, C. Fellbaum, S. Cotton, L. Delfs, and H.T.Dang.
2001.
English tasks: all-words and verb lexi-cal sample.
In Proceedings of ACL/SIGLEX Senseval-2,Toulouse, France.B.
Snyder and M. Palmer.
2004.
The English all-words task.
In Proceedings of ACL/SIGLEX Senseval-3,Barcelona, Spain.F.
Vasilescu, P. Langlais, and G. Lapalme.
2004.
Evalu-ating variants of the Lesk approach for disambiguatingwords.
In Proceedings of the Conference of LanguageResources and Evaluations (LREC 2004).418
