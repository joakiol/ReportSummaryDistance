Resolving Ambiguities of Chinese Conjunctive Structures by Divide-and-conquer ApproachesDuen-Chi Yang, Yu-Ming Hsieh, Keh-Jiann ChenInstitute of Information Science, Academia Sinica, Taipei{ydc, morris, kchen}@iis.sinica.edu.twAbstractThis paper presents a method to enhance aChinese parser in parsing conjunctivestructures.
Long conjunctive structurescause long-distance dependencies and tre-mendous syntactic ambiguities.
Pure syn-tactic approaches hardly can determineboundaries of conjunctive phrases properly.In this paper, we propose a divide-and-conquer approach which overcomes the dif-ficulty of data-sparseness of the trainingdata and uses both syntactic symmetry andsemantic reasonableness to evaluate am-biguous conjunctive structures.
In compar-ing with the performances of the PCFGparser without using the divide-and-conquer approach, the precision of the con-junctive boundary detection is improvedfrom 53.47% to 83.17%, and the bracketingf-score of sentences with conjunctive struc-tures is raised up about 11 %.1 IntroductionParsing a sentence with long conjunctive structureis difficult, since it is inadequate for a context-freegrammar to represent context-sensitive-like coordi-nation structures, such as ?a b c?
and a?
b?
c??
?.It causes long-distance dependencies and tremen-dous syntactic ambiguities (a large number of al-ternatives).
Pure syntactic approaches cannot de-termine boundaries of conjunctive phrases properly.It is obvious that both syntactic and semantic in-formation are necessary for resolving ambiguousboundaries of conjunctive structures.Some analysis methods of the detection of con-junctive structures have been studied for a while.Despite of using different resources and tools, thesemethods mainly make use of the similarity ofwords or word categories on both sides of conjunc-tive structure (Agarwal et al, 1992; Kurohashi etal., 1994; Delden, 2002; Steiner 2003).
They as-sumed that two sides of conjuncts should havesimilar syntactic and semantic structures.
Somepapers also suggest that certain key word patternscan be used to decide the boundaries (Wu 2003).Agarwal et al (1992) used a semantic tagger and asyntactic chunker to label syntactic and semanticchunks.
And then they defined multi-level (cate-gory to category or semantic type to semantic type)similarity matching to find the structure boundaries.Delden (2002) included semantic analysis byapplying WordNet (Miller 1993) information.These presented methods used similarity measuresheuristically according to the property of the lan-guages.
However detecting conjunctive boundarieswith a similar method in Chinese may meet someproblems, since a Chinese word may play differentsyntactic functions without inflection.
It results thatsyntactic symmetry is not enough to resolve ambi-guities of conjunctive structures and semantic rea-sonableness is hard to be evaluated.
Therefore wepropose a divide-and-conquer approach whichtakes the advantage of using structure informationof partial sentences located at both sides of con-junction.
Furthermore we believe that simple casescan be solved by simple methods which are effi-cient and only complex cases require deep syntac-tic and semantic analysis.
Therefore we develop analgorithm to discriminate simple cases and com-plex cases first.
We then use a sophisticated algo-rithm to handle complex cases only.For simple cases, we use conventional patternmatching approach to speedup process.
For com-plex conjunctive structures, we propose a divide-and-conquer approach to resolve the problem.
Aninput sentence with complex conjunctive structure715is first divided into two parts, one to the left of theconjunctive and one to the right, and then parsedindependently to detect possible candidates of twoconjuncts.
The particular property of complex con-junctive structures of Chinese language allows usto parse and to produce syntactic structures of twopartial sentences, since according to our observa-tions and experiments the syntactic structures ofpartial sentences at either side of a complex con-junctive construction are grammatical most of thetimes.
Figure 1 shows an instance.
The parsing re-sults not only reduce the possible ambiguousboundaries but also provide global structural in-formation for checking the properness of both sidesof conjunctive structure.
Another important pointworth mentioning is that since the size of availableTreebank is small, a two-stage approach is pro-posed to resolve the data sparseness problems inevaluating syntactic symmetry and semantic rea-sonableness.
At the first stage, a Conditional Ran-dom Fields model is trained and used to generate aset of candidate boundaries.
At the second stage, aword-association model is trained from a giga-word corpus to evaluate the semantic properness ofcandidates.
The proposed divide-and-conquer algo-rithm avoids parsing full complex conjunctivestructures and handles conjunctive structures withdeep structural and semantic analysis.The extraction method for context-dependentrules is described in Section 2 and detail of the di-vide-and-conquer approach is stated in Section 3.In Section 4, we introduce our experimental envi-ronment and show the results of our experiment.We also make some discussions about our observa-tions in Section 4.
Finally, we offer our conclusionand future work in Section 5.2 Boundary Detection for Simple Con-junctive PhrasesThe aim of this phase of approach is to determine ifsimple conjunctive phrases exist in input sentencesand then identify their boundaries by matchingcontext-dependent rules.
To derive a set of context-dependent rules for conjunctive phrases, a na?veapproach is to extract all conjunctive patterns withtheir contextual constraints from Treebank.
How-ever such a set of extracted rules suffers a low cov-erage rate, since limited size of training data causeszero frequency of long n-gram PoS patterns.2.1 Rule extraction and generalizationAgarwal et al, (1992), Kurohashi et al, (1994),and Delden (2002) had shown that the properties oflikeness and symmetry in both syntactic types andlengths for example, exist in most conjunctivecases.
Hence we use both properties as the condi-tions in deciding boundaries of conjunctive phrases.When we observe Sinica Treebank (Chen et al,2003), we also find that this property is more obvi-ous in simple conjunctive cases than in complexcases.First, we use a simple algorithm to detect theboundaries of completely symmetric conjunctivephrases.
If PoS patterns of ?A B C and A B C?
or?A B and A B?
occurred in the input sentence, weconsider patterns of such structures are legitimateconjunctive structures regardless whether the PoSsequences ?A B C and A B C?
or ?A B and A B?ever occurred in the Treebank.
For other cases weuse context-dependent rule patterns to determineboundaries of conjunctive structures.Statistical context-dependent PoS-based rule pat-terns are extracted automatically from Sinica Tree-bank.
Each rule contains the PoS pattern of a con-junctive phrase and its left/right contextual con-straints.
The occurrence frequency of the rule andits correct identification rate are also associated.
e.g.
[VC] (Na Caa Nc) [DE]1 ;  12; 11This rule says that PoS sequence Na Caa Ncforms a conjunctive phrase when its left context isa VC and its right context is a DE.
Such patternoccurred 12 times in the training corpus and 11 outof 12 times (Na Caa Nc) are correct conjunctivephrases.Context-dependent rule patterns are generatedand generalized by the following procedure.Rule Generation and GeneralizationFor each conjunctive structure in the Treebank, weconsider a window pattern of at most 9 words.
Thispattern contains conjunction in the center and atmost 4 words at each side of the conjunction.
ThePoS sequence of these 9 words forms a context-dependent rule.
For instance, the conjunctive struc-ture shown in Figure 1 will generate the pattern (1).
(1) [Vc DM] (VH  Na  Caa Neu Na) [DE Na]The long pattern has low applicability and hardly1 Caa is a PoS for coordinate conjunction.
Na is a commonnoun; Nc denotes place noun, and Vc is a transitive verb.
DEdenotes the relativizer ??
?.716can evaluate its precision.
Therefore a rule gener-alization process is applied.
Two kinds of generali-zations are available.
One is reducing the length ofcontextual constrains and the other is to reduce afine-grained PoS constraint to a coarse-grained PoS.Some instances, shown in (2), are the generalizedpatterns of (1).
(2)  [DM] (VH  Na  Caa Neu Na) [DE];1;1(VH  Na  Caa Neu Na); 10; 5[DM] (V  N  Caa N N) [DE]; 3; 2Then the applicability and precision of rules higherthan threshold values will be selected.
The thresholdvalues for the rule selection are determined by test-ing results on the development data.3 Resolution of Complex ConjunctiveStructuresComplex structures are cases whose boundaries cannot be identified by the pattern matching at phase-1.We propose a divide-and-conquer approach to re-solve the problem.
An input sentence with complexconjunctive structure was first divided into twoparts with each part containing one of the conjunctsand then parsed independently to produce theirsyntactic structures for detecting possible bounda-ries of two conjuncts.
Then ambiguous candidatestructures are generated and the best conjunctivestructure is selected by evaluating syntactic sym-metry and semantic reasonableness of the candi-dates.
Since the two parts of the partial sentencesare simple without conjunctive structure and nor-mally grammatical 2 , hence they can be easilyparsed by a PCFG parser.Here we illustrate the divide-and-conquer algo-rithm by the following example.
For instance, theexample shown in Figure 1 has complex conjunc-tive structure and it was first split into two parts (1a)and (1b) at conjunction marker ?
??.
(1a) ??
if (Cbb) ?
I (Nh) ??
invent (VC) ??
akind (DM) ?
low (VH) ??
pollution (Na)(1b) ?
null (Neu) ??
accident (Na) ?
(DE) ?
?car (Na)The two parts of partial sentences are thenparsed to produce their syntactic structures asshown in Figure 1.
Then a CRF model trained fromSinica Treebank for checking syntactic symmetry2 According to our experiments only 0.8% of the complextesting data and development data are failed to parse theirpartial structures at both sides of conjunction.was derived to pick the top-N candidates accordingto the syntactic information of both sides of partialsentences.
Then at the second stage, a semanticevaluation model is proposed to select the bestcandidate.
The detail of the semantic evaluationmodel is described in the section 3.2.
The reasonfor using a two-stage approach is that the size ofthe Treebank is limited, but the semantic evaluationmodel requires the values of association strengthsbetween words.
The current Treebank cannot pro-vide enough coverage and reliable values of word-association strengths.3.1  Derive and evaluate possible candidatesCRF is a well-known probabilistic framework forsegmenting and labeling sequence data (Lafferty, etal.
2001).
In our experiments, we regard the prob-lem of boundary detection as a chunking-like prob-lem (Lee et al, 2005).
Due to this reason, we useCRF model to generate candidates and their ranks.The features used in CRF model included someglobal syntactic information, such as syntacticcategory of a partial structure and its phrasal head.Such global syntactic information is crucial for thesuccess of boundary detection and is not availableif without the step of parsing process.Figure 1.
The syntactic structures of 5(a) and 5(b)produced by a PCFG parser.The features used are:WL,i ; CL,i; WR,j ; CR,j : The left(i)/right(j) most wordand its pos category of the left/right conjunct.PL, ; PR,: The phrasal category of the left/right con-junct.HwL ; HcL ; HwR ; HcR: The phrasal head and its poscategory of the left/right conjunct.DL ; DR: The length of the left/right conjunct.Three types of feature patterns are used for CRF.The first type is feature patterns regarding individ-WL,i+1 (WLi WL,i-1 ?.
WL1    W0   WR1 ?WR,j )WR,j+1,Some example feature values of the above hypothesis boundaries.WLi  = ?
; CLi  =Nh; WR,j  =??
; CR,j  =Na;PL, =S; PR, =NP;HwL=??
; HcL= VC; HwR =??
; HcR=Na;DL = 5; DR = 2;717ual conjuncts.
The second type is feature patternsregarding symmetry between two conjuncts.
Thethird type is feature patterns regarding contextualproperness of a conjunctive structure.Type1: WLi, WLi-1, WLi+1, CLi, CLi-1, CLi-2, CLi-1CLi-2, CLi+1, CLi+2,CLi+1CLi+2, CLiCLi-1CLi-2, CLi-1CLiCLi+1, CLiCLi+1CLi+2,WLiHwL, CLiHcL, and WRj, WRj-1, WRj+1, CRj, CRj-1, CRj-2, CRj-1CRj-2, CRj+1, CRj+2, CRj+1CRj+2, CRjCRj-1CRj-2, CRj-1CRjCRj+1,CRjCRj+1CRj+2, WRjHwR, CRjHcR..Type 2: PL PR, HwLHwR, HcLHcR, DLDR.Type 3: WL,i+1HwRj, WR,j+1HwLi, WL,1WR,j, WR,1WL,j,WL,1WR,j+1, WR,1WL,j+1, WL,1WR,jWR,j+1,WR,1WL,iWL,i+1, WL,1WR,j-1WR,j, WR,1WL,i-1WL,i,CL,i-1HcRj, CR,j-1HcLi, CL,i+1HcRj, CR,j+1HcLi,CL,iCL,i+1HcRj, CR,jCR,j+1HcLi, CL,1CR,j, CR,1CL,j,CL,1CR,j+1, CR,1CL,j+1, CL,1CR,jCR,j+1, CR,1CL,iCL,i+1,CL,1CR,j-1CR,j, CR,1CL,i-1CL,i.A CRF model is trained from the Sinica Tree-bank and estimated the probabilities of hypothesisconjunctive boundary pairs by the feature patternslisted above.
The top ranked candidates are se-lected according to the CRF model.
In general, forfurther improvement, a final step of semanticevaluation will be performed to select the best can-didate from top-N boundary structures ranked bythe CRF model, which is described in the next sec-tion.3.2 The word-association evaluation modelFor the purpose of selecting the best candidates ofcomplex conjunctive structures, a word associationevaluation model is adopted (Hsieh et al 2007).The word-to-word association data is learnedautomatically by parsing texts from the TaiwanCentral News Agency corpus (traditional charac-ters), which contains 735 million characters.
Thesyntactically dependent words-pairs are extractedfrom the parsed trees.
The word-pairs are phrasalheads and their arguments or modifiers.
Though thedata is imperfect (due to some errors produced byauto-tagging system and parser), the amount ofdata is large enough to compensate parsing errorsand reliably exhibit strength between twowords/concepts.37,489,408 sentences in CNA (Central NewsAgency) corpus are successfully parsed and thenumber of extracted word associations is221,482,591.
The word association probabilities isestimated by eq.(1).
)(),()|(HeadfreqModifyHeadfreqHeadModifyP =        (1)?freq(Head)?
means Head word frequency in thecorpus and ?freq(Head,Modify)?
is the cooccur-rence frequency of Head and Modify/Argument.The final evaluation is done by combining threescores, i.e.
(1) the probability produced by PCFGparser, (2) the scores of CRF classifier and (3) thescores of semantic evaluation.
The detail is de-scribed in Section 4.2.4 Experiments3,484 sentences of the Sinica Treebank are used astraining data.
The development data and testingdata are extracted from three different set of cor-pora the Sinica corpus, Sinorama magazines andtextbooks of elementary school (Hsieh et al 2005).They are totally 202 sentences (244 conjunctions)with 6-10 words and 107 sentences (159 conjunc-tions) with more than 11 words.
We only test thesentences which contain the coordinate conjunctioncategory or categories.We adopt the standard PARSEVAL metrics(Manning et al, 1999) including bracket f-score toevaluate the performance of the tree structures ofsentences and accuracies of boundary detection ofconjunction structures.4.1 Phase-1 experimental resultsFor the phase-1 experiments, the context-dependent rules are extracted and generalized fromSinica treebank.
We then use the development datato evaluate the performances for different sets ofrules selected by different threshold values.
Theresults show that the threshold values of occurrenceonce and precision 70% performed best.
Thismeans any context-dependent rule with precisiongreater than or equal to 70% is used for the futureprocesses.
39941 rules are in the set.
In Table 1, wecompare the phase-1 result with the baseline modelon test data.
It is shown that the boundary detectionprecision is very high, but the recall rate is com-paratively low, since the phase-1 process cannothandle the complex cases.
We also compare theprocessing time between the baseline model andthe phase-1 parsing processes in Table 2.
Markingconjunctive boundaries before parsing can limit thesearch range for parser and save processing time.The effect is more obvious when parsing long sen-tences.
Because long sentences generate more am-718biguous paths than shorter sentences, these surelyspend much more time.6-10 words more than 11 words Test dataBaseline phase1 Baseline phase1C-boundaryf-score55.74 84.43 50.0 63.75S-bracketf-score72.67 84.44 71.20 79.40Table 1.
The comparison between the baselinePCFG model and the phase1 parsing process .6-10 words more than 11 words unit: secondBaseline  phase1  Baseline  phase1development data 14 12 34 23test data 14 11 34 24Table 2.
The comparison of processing time be-tween the baseline model and the phase1 parsingprocess.4.2 Phase-2 experimental resultsComplex cases cannot be matched by context-dependent rules at the phrase-1 which will be han-dled by the phase-2 algorithms mentioned in Sec-tion 3.
We use the CRF++ tool (Kudo, 2006) totrain our CRF model.
The CRF model can producethe N-best candidates for an input conjunctive sen-tence.
We experiment on the models of Top1-CRFand TopN-CRF where the Top1-CRF algorithmmeans that the final output is the best candidateproduced by CRF model and the TopN-CRF meansthat the final output is the best candidate producedby the structure evaluation process described below.For each N-best candidate structure, threeevaluation scores is derived: (a) the probabilityscore generated from the PCFG parser, i.e.RuleScore, (b) the probability score generated fromthe CRF classifier, i.e.
CRF-Score, and (c) theword association score, i.e.
WA-Score.
We normal-ize each of the three scores by eq.
(2):minmaxmin)(ScoreScoreScoreScoreScorenormal ii ?
?=                 (2)Scorei means the score of the i-th candidate, andScoremin and Scoremax mean the worst and the bestscore in the candidate set for a target conjunctivesentence.
The normalized scores are between 0 and1.
After normalization, we combine the threescores with different weights:Total Score = w1*RuleScore + w2*CRF-Score +w3*WA-Score                                   (3)The w1, w2 and w3 are regarded as the degree ofimportance of the three types of information.
Weuse development data to determine the best combi-nation of w1, w2, w3.
Due to limit amount of de-velopment data, many local maximum and globalmaximum are achieved by different values of w1,w2, w3.
Therefore we use a clustering algorithm tocluster the grid points of (w1, w2, w3) which pro-duce the best performance.
We then pick the larg-est cluster and calculate its centroid as our finalweights which are shown at Table 3.Top N w1 w2 w36-10words N = 3 0.11 0.64 0.2511- words N = 3 0.18 0.76 0.06Table 3.
The best weights determined by the devel-opment data for the sentences with differentlengths using the best-3 candidates.The performance results of the testing data areshown in Table 4.
In comparing with the results ofthe baseline model shown in Table 1, the conjunc-tion boundary f-score increased from about 53% to83% for the testing data.
The processes also im-prove the overall parsing f-scores from 72% to83%.
The results of Table 4 also show that theevaluation function indeed improves the perform-ances but marginally.
However the experiments aredone under the condition that the input sentencesare perfectly word segmented and pos tagged.
Inreal practices, parser may accept sentences withambiguous word segmentation and pos tagging toavoid the error accumulation due to early commit-ment on word segmentation and pos tagging.Therefore parsers require much more informationto resolve much more ambiguous conditions.
Arobust evaluation function may play a very impor-tant role.
We will do more researches in the future.Top1CRF TopNCRFC-boundary f-score 85.57 89.55 Develop-ment data S-bracket f-score 80.10 82.34C-boundary f-score 82.18 83.17 Test dataS-bracket f-score 83.15 83.45Table 4.
The final results of our overall processes.Another point worth mentioning, the perform-ances of ?CRF?
(using CRF model without phase-1)and ?phase1+CRF?
(using CRF model after phase-1) algorithms are comparable.
However ?phase1+CRF?
algorithm is much more efficient, since?phase1+CRF?
algorithm can determine the simpleconjunctive structures by pattern matching andmost of conjunctive structures are simple.
On theother hand, the ?CRF?
model requires twice partialsentence parsing, generates candidates with CRF719classifier and evaluates structure with three syntac-tic and semantic scores.5 ConclusionConjunctive boundary detection is not a simpletask.
It is not only time consuming but also knowl-edge intensive.
Therefore we propose a context-dependent rules matching approach to handle sim-ple cases to get fast returns.
For complex cases, weuse a knowledge intensive divide-and-conquer ap-proach.
To resolve the problems of inadequateknowledge and data sparseness due to limit amountof structure annotated training data, we extractword/concept associations from CNA corpus.In our experiments, the proposed model workswell.
Most conjunctive phrases are simple casesand can be matched by context-dependent rules andindeed avoid unnecessary calculation.
Comparedwith the baseline method of straight forward PCFGparsing, the f-score of conjunctive boundary detec-tion can be raised about 22%.
For the complexcases, the boundaries f-score is further raised about7% after phase-2 processes.
The experimental re-sults show that the method not only works well onboundary resolution for conjunctive phrases butalso improves the total performances of syntacticparsing.Our solutions include the rule-based method andcooperate with semantic and syntactic analyses.Therefore in the future we will try to enhance thesyntactic and semantic analyses.
For syntacticanalysis, we still need to find more effective meth-ods to improve the performance of our parser.
Forthe semantic analysis, we will try to refine the wordassociation data and discover a better semanticevaluation model.AcknowledgementsThis research was supported in part by NationalDigital Archives Program (NDAP, Taiwan) spon-sored by the National Science Council of Taiwanunder NSC Grants: NSC95-2422-H-001-031-.ReferencesAgarwal, Rajeev and Boggess, Lois.
1992.
A Simple butUseful Approach to Conjunct Identification.
In Pro-ceedings of 30th Annual Meeting of Association forComputational Linguistics, pages 15-21.Chen, Keh-Jiann, Huang, Chu-Ren, Chen, Feng-Yi, Luo,Chi-Ching, Chang, Ming-Chung, Chen, Chao-Jan andGao, Zhao-Ming.
2003.
Sinica Treebank: design cri-teria, representational issues and implementation.
InAnne Abeille, (ed.
): Building and Using Parsed Cor-pora.
Text, Speech and Language Technology.20:231-248, pages 231-248.Hsieh,Yu-Min, Yang, Duen-Chi and Chen, Keh-Jiann.2005.
Linguistically-motivated grammar extraction,generalization and adaptation.
In Proceedings of theSecond International Join Conference on NaturalLanguage Processing (IJCNLP2005), pages 177-187,Jeju Island, Republic of Korea.Hsieh, Yu-Ming, Duen-Chi Yang and Keh-Jiann Chen.2007.
Improve Parsing Performance by Self-Learning.International Journal of Computational Linguisticsand Chinese Language Processing, Vol.
12, #2,pages 195-216.Kurohashi, Sadao, and Nagao, Makoto.
1994.
A Syntac-tic Analysis Method of Long Japanese SentencesBased on the Detection of Conjunctive Structure.Computational Linguistics 20(4), pages 507-534.Kudo, Taku.
2006.
(software)CRF++: Yet Another CRFtoolkit http://chasen.org/~taku/software/CRF++/.Lafferty, John, McCallum, Andrew, Pereira, Fernando.2001.
Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data.In Proceedings of the 18th International Conferenceon Machine Learning (ICML-01), pages 282-289.Lee, Yong-Hun, Kim, Mi-Young and Lee, Jong-Hyeok.2005.
Chunking Using Conditional Random Fields inKorea Texts.
In Proceedings of the Second Interna-tional Join Conference on Natural Language Proc-essing (IJCNLP2005), pages 155-164, Jeju Island,Republic of Korea.Manning, Christopher D., and Schutze, Hinrich.
1999.Foundations of Statistical Natural Language process-ing.
The MIT Press, Cambridge, Massachusetts.Miller, Geroge, 1993.
Introduction to WordNet: AnOnline Lexical Database.
Princeton, CSL Report 43.Steiner, Ilona.
2003.
Parsing Syntactic Redundancies inCoordinate Structures.
Poster presentation at theEuropean Cognitive Science Conference (Euro-CogSci03).Van Delden, Sebastian.
2002.
A Hybrid Approach toPre-Conjunct Identification.
In Proceedings of the2002 Language Engineering Conference (LEC 2002),pages 72-77, University of Hyderabad, India.Wu, Yunfang.
2003.
Contextual Information of Coordi-nate Structure.
Advances on the Research of MachineTranslation, pages 103-109, Publishing house ofElectronics Industry.720
