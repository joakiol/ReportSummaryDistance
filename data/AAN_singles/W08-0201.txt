Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 1?9,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsTeaching computational linguistics to a large, diverse student body:courses, tools, and interdepartmental interactionJason Baldridge and Katrin ErkDepartment of LinguisticsThe University of Texas at Austin{jbaldrid,erk}@mail.utexas.eduAbstractWe describe course adaptation and develop-ment for teaching computational linguisticsfor the diverse body of undergraduate andgraduate students the Department of Linguis-tics at the University of Texas at Austin.
Wealso discuss classroom tools and teaching aidswe have used and created, and we mentionour efforts to develop a campus-wide compu-tational linguistics program.1 IntroductionWe teach computational linguistics courses in thelinguistics department of the University of Texasat Austin, one of the largest American universi-ties.
This presents many challenges and opportu-nities; in this paper, we discuss issues and strate-gies for designing courses in our context and build-ing a campus-wide program.1 The main theme ofour experience is that courses should be targeted to-ward specific groups of students whenever possible.This means identifying specific needs and design-ing the course around them rather than trying to sat-isfy a diverse set of students in each course.
To thisend, we have split general computational linguisticscourses into more specific ones, e.g., working withcorpora, a non-technical overview of language tech-nology applications, and natural language process-ing.
In section 2, we outline how we have stratifiedour courses at both the graduate and undergraduatelevels.1Links to the courses, tools, and resources described in thispaper can be found on our main website:http://comp.ling.utexas.eduAs part of this strategy, it is crucial to ensure thatthe appropriate student populations are reached andthat the courses fulfill degree requirements.
For ex-ample, our Language and Computers course fulfillsa Liberal Arts science requirement and our NaturalLanguage Processing is cross-listed with computerscience.
This is an excellent way to get students inthe door and ensure that courses meet or exceed min-imum enrollments.
We find that many get hookedand go on to specialize in computational linguistics.Even for targeted CL courses, there is still usuallysignificant diversity of backgrounds among the stu-dents taking them.
Thus, it is still important to care-fully consider the teaching tools that are used; in sec-tion 3, we discuss our experience with several stan-dard tools and two of our own.
Finally, we describeour efforts to build a campus-wide CL program thatprovides visibility for CL across the university andprovides coherence in our course offerings.2 CoursesOur courses are based on those initiated by JonasKuhn between 2002 and 2005.
Since 2005, we havecreated several spin-off courses for students withdifferent backgrounds.
Our broad goals for thesecourses are to communicate both the practical util-ity of computational linguistics and its promise forimproving our understanding of human languages.2.1 GraduateWe started with two primary graduate courses, Com-putational Linguistics I and II.
The first introducescentral algorithms and data structures in computa-tional linguistics, while the second focuses on learn-1Figure 1: Flow for non-seminar courses.
Left: graduatecourses, right: undergraduate courses.ing and disambiguation.
This served a computation-ally savvy segment of the student population quitewell.
However, we view one of our key teachingcontributions as computational linguists in a linguis-tics department to be providing non-computationalstudents with technical and formal skills useful fortheir research.
We discovered quickly that our firstcomputational linguistics course did not fill theseneeds, and the second is not even accessible to moststudents.
The graduate linguistics students did putin the effort to learn Python for Computational Lin-guistics I, but many would have preferred a (much)gentler introduction and also more coverage of is-sues connected to their linguistic concerns.
This ledus to create a new course, Working with Corpora.Still, there is a need for the primary courses,which receive interest from many students in com-puter science and also graduate students from otherdepartments such as German and English.
One ofthe great surprises for us in our graduate courses hasbeen the interest from excellent linguistics and com-puter science undergraduates.We have sought to encourage our students to beactive in the academic community outside of UTAustin.
One way we do this is to have a finalproject for each course (and most seminars) that hasfour distinct stages: (i) a project proposal halfwaythrough the semester, (ii) a progress report three-quarters of the way through, (iii) a 10-minute pre-sentation during the last week of class, and (iv) afinal report at the end.
We have found that havingcourse projects done in this staged manner ensuresthat students think very thoroughly about what theirtopic is early on, receive significant feedback fromus, and then still have enough time to do significantimplementation for their project, rather than rushingeverything in last minute.
Also, by having studentsdo presentations on their work before they hand inthe final report, they can incorporate feedback fromother students.
A useful strategy we have found forscoring these projects is to use standard conferencereviews in Computational Linguistics II.
The finalprojects have led to several workshops and confer-ence publications for the students so far, as wellas honors theses.
The topics have been quite var-ied (in line with our varied student body), includinglexicon induction using genetic algorithms (Ponvert,2007), alignment-and-transfer for bootstrapping tag-gers (Moon and Baldridge, 2007), lemmatization us-ing parallel corpora (Moon and Erk, 2008), graphi-cal visualization of articles using syntactic depen-dencies (Jeff Rego, CS honors thesis), and featureextraction for semantic role labeling (Trevor Foun-tain, CS honors thesis).Working with corpora.
Computational linguis-tics skills and techniques are tremendously valuablefor linguists using corpora.
Ideally, a linguist shouldbe able to extract the relevant data, count occur-rences of phenomena, and do statistical analyses.The intersection of these skills and needs is the coreof this course, which covers corpus formats (XML,bracket formats for syntax, ?word/POS?
formats forpart-of-speech information), query languages andtools (regular expressions, cqp, tregex), and somestatistical analysis techniques.
It also teaches Pythongently for liberal arts students who have never pro-grammed and have only limited or no knowledge oftext processing.
Other main topics are the compi-lation of corpora and corpus annotation, with issueslike representativity and what meta-data to include.At the end of this course, students are prepared forour primary computational courses.We observed the tremendous teaching potentialof effective visualization in this course with the Rstatistics package.
It was used for statistical anal-yses: students loved it because they could producemeaningful results immediately and visualize them.The course includes only a very short two-sessionintroduction to working with R. We were worriedthat this would overtax students because R is its own2programming language.
But interestingly they hadno problems with learning this second programminglanguage (after Python).
This is particularly strikingas most of the students had no programming experi-ence prior to the class.We have not yet used the Natural LanguageToolkit (Loper and Bird, 2002) (see Section 3.1) inthis course.
But as it, too, offers visualization andrapid access to meaningful results, we intend to useit in the future.
In particular, the NLTK allows veryeasy access to Toolbox data (Robinson et al, 2007),which we feel will greatly improve the utility andappeal of the course for the significant number ofdocumentary linguistics students in the department.Seminars.
We also offer several seminars inour areas of interest.
These include CategorialGrammar, Computational Syntax, and Lexical Ac-quisition.
These courses have attracted ?non-computational?
linguistics students with related in-terests, and have served as the launching point forseveral qualifying papers and masters theses.
Itis important to offer these courses so that thesestudents gain a view into computational linguisticsfrom the standpoint of a topic with which they al-ready have some mastery; it also ensures healthierenrollments from students in our own department.We are currently co-teaching a seminar calledSpinning Straw into Gold: Automated Syntax-Semantics Analysis, that is designed to overlap withthe CoNLL-2008 shared task on joint dependencyparsing and semantic role labeling.
The entire classis participating in the actual competition, and wehave been particularly pleased with how this exter-nal facet of the course motivates students to considerthe topics we cover very carefully ?
the papers trulymatter for the system we are building.
It provides anexcellent framework with which to judge the contri-butions of recent research in both areas and compu-tational linguistics more generally.2.2 UndergraduateOur first undergraduate course was Introduction toComputational Linguistics in Fall 2006.
Our expe-rience with this course, which had to deal with theclassic divide in computational linguistics coursesbetween students with liberal arts versus computerscience backgrounds, led us to split it into twocourses.
We briefly outline some of the misstepswith this first course (and what worked well) andhow we are addressing them with new courses.Introduction to Computational Linguistics.This course is a boiled-down version of the graduateComputational Linguistics I taught in Fall 2006.Topics included Python programming, regularexpressions, finite-state transducers, part-of-speechtagging, context-free grammar, categorial grammar,meaning representations, and machine translation.Overall, the course went well, but enrollmentdropped after the mid-term.
As many have foundteaching such courses, some students truly struggledwith the course material while others were ready forit to go much faster.
Several students had interpreted?introduction?
to mean that it was going to be aboutcomputational linguistics, but that they would notactually have to do computational linguistics.
Manystayed with it, but there were still others who couldhave gone much further if it had not been necessaryto slow down to cover basic material like for loops.Note that several linguistics majors were among thecompationally savvy students.In fairness to the students who struggled, it wascertainly ill-advised to ask students with no previousbackground to learn Python and XFST in a singlesemester.
One of the key points of confusion wasregular expression syntax.
The syntax used in thetextbook (Jurafsky and Martin, 2000) transfers eas-ily to regular expressions in Python, but is radicallydifferent from that of XFST.
For students who hadnever coded anything in their life, this proved ex-tremely frustrating.
On the other hand, for computa-tionally savvy students, XFST was great fun, and itwas an interesting new challenge after having to sitthrough very basic Python lectures.On the other hand, the use of NLTK to drive learn-ing about Python and NLP tasks (like building POS-taggers) significantly eased the burden for new pro-grammers.
Many of them were highly satisfied thatthey could build interesting programs and experi-ment with their behavior so easily.Language and Computers.
We had fortunatelyalready planned the first replacement course: Lan-guage and Computers, based on the course designedat the Department of Linguistics at the Ohio StateUniversity (Brew et al, 2005).
This course intro-3duces computational linguistics to a general audi-ence and is ideal for students who want exposureto computational methods without having to learnto program.
We designed and taught it jointly, andadded several new aspects to the course.
WhereasOSU?s course fulfills a Mathematical and LogicalAnalysis requirement, our course fulfills a Sciencerequirement for liberal arts majors.
These require-ments were met by course content that requires un-derstanding and thinking about formal methods.The topics we added to our course were questionanswering, cryptography,2 and world knowledge.The course provides ample opportunity to discusshigh-level issues in language technology with low-level aspects such as understanding particular algo-rithms (e.g., computing edit distance with dynamicprogramming) and fundamental concepts (such asregular languages and frequency distributions).In addition to its target audience, the coursenonetheless attracts students who are already well-versed in many of the low-level concepts.
The high-level material plays an important role for such stu-dents: while they find the low-level problems quiteeasy, many find a new challenge in thinking aboutand communicating clearly the wider role that suchtechnologies play.
The high-level material is evenmore crucial for holding the interest of less formallyminded students.
It gives them the motivation towork through and understand calculations and com-putations that might otherwise bore them.
Finally,it provides an excellent way to encourage class dis-cussion.
For example, this year?s class became veryanimated on the question of ?Can a machine think?
?that we discussed with respect to dialogue systems.Though the course does not require students todo any programming, we do show them short pro-grams that accomplish (simplified versions of) someof the tasks discussed in the course; for example,short programs for document retrieval and creatinga list of email address from US census data.
Thegoal is to give students a glimpse into such applica-tions, demonstrate that they are not hugely compli-cated magical systems, and hopefully entice some ofthem to learn how to do it for themselves.The 2007 course was quite successful: it filled2The idea to cover cryptography came from a discussionwith Chris Brew; he now teaches an entire course on it at OSU.up (40 students) and received very positive feedbackfrom the students.
It filled up again for this year?sSpring 2008 offering.
The major challenge is thelack of a textbook, which means that students mustrely heavily on lecture slides and notes.Words in a Haystack: Methods and Tools forWorking with Corpora.
This advanced under-graduate version of Working with corpora was of-fered because we felt that graduate and undergrad-uate linguistics students were actually on an equalfooting in their prior knowledge, and could profitequally from a gentle introduction to programming.Although the undergraduate students were activeand engaged in the class, they did not benefit asmuch from it as the graduate students.
This is likelybecause graduate students had already experiencedthe need for extracting information from corpora fortheir research and the consequent frustration whenthey did not have the skills to do so.Natural Language Processing.
This is an de-manding course that will be taught in Fall 2008.
Itis cross-listed with computer science and assumesknowledge of programming and formal methods incomputer science, mathematics, or linguistics.
It isdesigned for the significant number of students whowish to carry on further from the courses describedpreviously.
It is also an appropriate course for un-dergraduates who have ended up taking our graduatecourses for lack of such an option.Much of the material from Introduction to Com-putational Linguistics will be covered in this course,but it will be done at a faster pace and in greaterdetail since programming and appropriate thinkingskills are assumed.
A significant portion of the grad-uate course Computational Linguistics II also formspart of the syllabus, including machine learningmethods for classification tasks, language modeling,hidden Markov models, and probabilistic parsing.We see cross-listing the course with computer sci-ence as key to its success.
Though there are manycomputationally savvy students in our liberal artscollege, we expect cross-listing to encourage signif-icantly more computer science students to try out acourse that they would otherwise overlook or be un-able to use for fulfilling degree requirements.43 Teaching Tools and TutorialsWe have used a range of external tools and haveadapted tools from our own research for various as-pects of our courses.
In this section, we describe ourexperience using these as part of our courses.We have used Python as the common language inour courses.
We are pleased with it: it is straight-forward for beginning programmers to learn, its in-teractive prompt facilitates in-class instruction, it istext-processing friendly, and it is useful for gluingtogether other (e.g., Java and C++) applications.3.1 External tools and resourcesNLTK.
We use the Natural Language Toolkit(NLTK) (Loper and Bird, 2002; Bird et al, 2008) inboth undergraduate and graduate courses for in-classdemos, tutorials, and homework assignments.
Weuse the toolkit and tutorials for several course com-ponents, including introductory Python program-ming, text processing, rule-based part-of-speech tag-ging and chunking, and grammars and parsing.NLTK is ideal for both novice and advanced pro-grammers.
The tutorials and extensive documenta-tion provide novices with plenty of support outsideof the classroom, and the toolkit is powerful enoughto give plenty of room for advanced students to play.The demos are also very useful in classes and serveto make many of the concepts, e.g.
parsing algo-rithms, much more concrete and apparent.
Somestudents also use NLTK for course projects.
In all,NLTK has made course development and executionsignificantly easier and more effective.XFST.
A core part of several courses is finite-statetransducers.
FSTs have unique qualities for coursesabout computational linguistics that are taught inlinguistics department.
They are an elegant exten-sion of finite-state automata and are simple enoughthat their core aspects and capabilities can be ex-pressed in just a few lectures.
Computer science stu-dents immediately get excited about being able torelate string languages rather than just recognizingthem.
More importantly, they can be used to ele-gantly solve problems in phonology and morphol-ogy that linguistics students can readily appreciate.We use the Xerox Finite State Toolkit (XFST)(Beesley and Karttunen, 2003) for in-class demon-strations and homeworks for FSTs.
A great aspect ofusing XFST is that it can be used to show that differ-ent representations (e.g., two-level rules versus cas-caded rules) can be used to define the same regularrelation.
This exercise injects some healthy skepti-cism into linguistics students who may have to dealwith formalism wars in their own linguistic subfield.Also, XFST allows one to use lenient composition toencode Optimality Theory constraints and in so do-ing show interesting and direct contrasts and com-parisons between paper-and-pencil linguistics andrigorous computational implementations.As with other implementation-oriented activitiesin our classes, we created a wiki page for XFST tu-torials.3 These were adapted and expanded fromXe-rox PARC materials and Mark Gawron?s examples.Eisner?s HMM Materials.
Simply put: thespreadsheet designed by Jason Eisner (Eisner, 2002)for teaching hidden Markov models is fantastic.
Weused that plus Eisner?s HMM homework assignmentfor Computational Linguistics II in Fall 2007.
Thespreadsheet is great for interactive classroom explo-ration of HMMs?students were very engaged.
Thehomework allows students to implement an HMMfrom scratch, giving enough detail to alleviate muchof the needless frustration that could occur with thistask while ensuring that students need to put in sig-nificant effort and understand the concepts in orderto make it work.
It also helps that the new editionof Jurafsky and Martin?s textbook discusses Eisner?sice cream scenario as part of its much improvedexplanation of HMMs.
Students had very positivefeedback on the use of all these materials.Unix command line.
We feel it is important tomake sure students are well aware of the mightyUnix command line and the tools that are availablefor it.
We usually have at least one homework as-signment per course that involves doing the sametask with a Python script versus a pipeline usingcommand line tools like tr, sort, grep and awk.This gives students students an appreciation for thepower of these tools and for the fact that they are attimes preferable to writing scripts that handle every-thing, and they can see how scripts they write canform part of such pipelines.
As part of this module,3http://comp.ling.utexas.edu/wiki/doku.php/xfst5we have students work through the exercises in thedraft chapter on command line tools in Chris Brewand Marc Moens?
Data-Intensive Linguistics coursenotes or Ken Church?s Unix for Poets tutorial.43.2 Internal toolsGrammar engineering with OpenCCG.
Thegrammar engineering component of ComputationalSyntax in Spring 2006 used OpenCCG,5 a catego-rial grammar parsing system that Baldridge createdwith Gann Bierner and Michael White.
The prob-lem with using OpenCCG is that its native grammarspecification format is XML designed for machines,not people.
Students in the course persevered andmanaged to complete the assignments; nonetheless,it became glaringly apparent that the non-intuitiveXML specification language was a major stumblingblock that held students back from more interestingaspects of grammar engineering.One student, Ben Wing, was unhappy enough us-ing the XML format that he devised a new specifica-tion language, DotCCG, and a converter to generatethe XML from it.
DotCCG is not only simpler?italso uses several interesting devices, including sup-port for regular expressions and string expansions.This expressivity makes it possible to encode a sig-nificant amount of morphology in the specificationlanguage and reduce redundancy in the grammar.The DotCCG specification language and con-verter became the core of a project funded by UTAustin?s Liberal Arts Instructional Technology Ser-vices to create a web and graphical user interface,VisCCG, and develop instructional materials forgrammar engineering.
The goal was to provide suit-able interfaces and a graduated series of activitiesand assignments that would allow students to learnvery basic grammar engineering and then grow intothe full capabilities of an established parsing system.A web interface provided an initial stage that al-lowed students in the undergraduate Introduction toComputational Linguistics course (Fall 2006) to testtheir grammars in a grammar writing assignment.This simple interface allows students to first writeout a grammar on paper and then implement it andtest it on a set of sentences.
Students grasped the4http://research.microsoft.com/users/church/wwwfiles/tutorials/unix for poets.ps5http://openccg.sf.netconcepts and seemed to enjoy seeing the grammar?scoverage improve as they added more lexical entriesor added features to constrain them appropriately.
Amajor advantage of this interface, of course, is thatit was not necessary for students to come to the labor install any software on their own computers.The second major development was VisCCG,a graphical user interface for writing full-fledgedOpenCCG grammars.
It has special support forDotCCG, including error checking, and it displaysgrammatical information at various levels of granu-larity while still allowing direct source text editingof the grammar.The third component was several onlinetutorials?written on as publicly available wikipages?for writing grammars with VisCCG andDotCCG.
A pleasant discovery was the tremendousutility of the wiki-based tutorials.
It was very easyto quickly create tutorial drafts and improve themwith the graduate assistant employed for creatinginstructional materials for the project, regardless ofwhere we were.
More importantly, it was possibleto fix bugs or add clarifications while students werefollowing the tutorials in the lab.
Furthermore,students could add their own tips for other studentsand share their grammars on the wiki.These tools and tutorials were used for two grad-uate courses in Spring 2007, Categorial Grammarand Computational Linguistics I.
Students caught onquickly to using VisCCG and DotCCG, which was ahuge contrast over the previous year.
Students wereable to create and test grammars of reasonable com-plexity very quickly and with much greater ease.
Weare continuing to develop and improve these materi-als for current courses.The resources we created have been not only ef-fective for classroom instruction: they are also be-ing used by researchers that use OpenCCG for pars-ing and realization.
The work we did produced sev-eral innovations for grammar engineering that wereported at the workshop on Grammar EngineeringAcross the Frameworks (Baldridge et al, 2007).3.3 A lexical semantics workbench:ShalmaneserIn the lexical semantics sections of our classes, wordsense and predicate-argument structure are core top-ics.
Until now, we had only discussed word sense6disambiguation and semantic role labeling theoret-ically.
However, it would be preferable to give thestudents hands-on experience with the tasks, as wellas a sense of what does and does not work, and whythe tasks are difficult.
So, we are now extendingShalmaneser (Erk and Pado, 2006), a SHALlow se-MANtic parSER that does word sense and semanticrole assignment using FrameNet frames and roles,to be a teaching tool.
Shalmaneser already offers agraphical representation of the assigned predicate-argument structure.
Supported by an instructionaltechnology grant from UT Austin, we are extend-ing the system with two graphical interfaces thatwill allow students to experiment with a variety offeatures, settings and machine learning paradigms.Courses that only do a short segment on lexical se-mantic analysis will be able to use the web inter-face, which does not offer the full functionality ofShalmaneser (in particular, no training of new clas-sifiers), but does not require any setup.
In addition,there will be a stand-alone graphical user interfacefor a more in-depth treatment of lexical semanticanalysis.
We plan to have the new platform readyfor use for Fall 2008.Besides a GUI and tutorial documents, there isone more component to the new Shalmaneser sys-tem, an adaptation of the idea of grammar engi-neering workbenches to predicate-argument struc-ture.
Grammar engineering workbenches allow stu-dents to specify grammars declaratively.
For seman-tic role labeling, the only possibility that has beenavailable so far for experimenting with new featuresis to program.
But, since semantic role labeling fea-tures typically refer to parts of the syntactic struc-ture, it should be possible to describe them declar-atively using a tree description language.
We arenow developing such a language and workbench aspart of Shalmaneser.
We aim for a system that willbe usable not only in the classroom but also by re-searchers who develop semantic role labeling sys-tems or who need an automatic predicate-argumentstructure analysis system.4 University-wide programThe University of Texas at Austin has a long tra-dition in the field of computational linguistics thatgoes back to 1961, when a major machine transla-tion project was undertaken at the university?s Lin-guistics Research Center under the direction of Win-fred Lehman.
Lauri Karttunen, Stan Peters, andBob Wall were all on the faculty of the linguisticsdepartment in the late 1960?s, and Bob Simmonswas in the computer science department during thistime.
Overall activity was quite strong throughoutthe 1970?s and 1980?s.
After Bob Wall retired in themid-1990?s, there was virtually no computationalwork in the linguistics department, but Ray Mooneyand his students in computer science remained veryactive during this period.6The linguistics department decided in 2000 torevive computational linguistics in the department,and consequently hired Jonas Kuhn in 2002.
Hisefforts, along with those of Hans Boas in the Ger-man department, succeeded in producing a com-putational linguistics curriculum, funding research,(re)establishing links with computer science, and at-tracting an enthusiastic group of linguistics students.Nonetheless, there is still no formal interdepart-mental program in computational linguistics at UTAustin.
Altogether, we have a sizable group offaculty and students working on topics related tocomputational linguistics, including many other lin-guists, computer scientists, psychologists and oth-ers who have interests directly related to issues incomputational linguistics, including our strong arti-ficial intelligence group.
Despite this, it was easyto overlook if one was considering only an individ-ual department.
We thus set up a site7 to improvethe visibility of our CL-related faculty and researchacross the university.
There are plans to create an ac-tual program spanning the various departments anddrawing on the strengths of UT Austin?s languagedepartments.
For now, the web site is a low-cost andlow-effort but effective starting point.As part of these efforts, we are working to in-tegrate our course offerings, including the cross-listing of the undergraduate NLP course.
Our stu-dents regularly take Machine Learning and othercourses from the computer science department.
RayMooney will teach a graduate NLP course in Fall2008 that will offer students a different perspectiveand we hope that it will drum up further interest6For a detailed account, see: http://comp.ling.utexas.edu/wiki/doku.php/austin compling history7http://comp.ling.utexas.edu7in CL in the computer science department and thuslead to further interest in our other courses.As part of the web page, we also created a wiki.8We have already mentioned its use in teaching andtutorials.
Other uses include lab information, arepository of programming tips and tricks, list of im-portant NLP papers, collaboration areas for projects,and general information about computational lin-guistics.
We see the wiki as an important reposi-tory of knowledge that will accumulate over timeand continue to benefit us and our students as itgrows.
It simplifies our job since we answer manystudent questions on the wiki: when questions getasked again, we just point to the relevant page.5 ConclusionOur experience as computational linguists teachingand doing research in a linguistics department at alarge university has given us ample opportunity tolearn a number of general lessons for teaching com-putational linguistics to a diverse audience.The main lesson is to stratify courses accordingto the backgrounds different populations of studentshave with respect to programming and formal think-ing.
A key component of this is to make expec-tations about the level of technical difficulty of acourse clear before the start of classes and restatethis information on the first day of class.
This is im-portant not only to ensure students do not take toochallenging a course: other reasons include (a) re-assuring programming-wary students that a coursewill introduce them to programming gently, (b) en-suring that programming-savvy students know whenthere will be little programming involved or formalproblem solving they are likely to have already ac-quired, and (c) providing awareness of other coursesstudents may be more interested in right away or af-ter they have completed the current course.Another key lesson we have learned is that the for-mal categorization of a course within a universitycourse schedule and departmental degree programare massive factors in enrollment, both at the under-graduate and graduate level.
Computational linguis-tics is rarely a required course, but when taught in aliberal arts college it can easily satisify undergradu-ate math and/or science requirements (as Language8http://comp.ling.utexas.edu/wiki/doku.phpand Computers does at OSU and UT Austin, respec-tively).
However, for highly technical courses taughtin a liberal arts college (e.g., Natural Language Pro-cessing) it is useful to cross-list them with computerscience or related areas in order to ensure that the ap-propriate student population is reached.
At the grad-uate level, it is also important to provide structureand context for each course.
We are now coordinat-ing with Ray Mooney to define a core set of com-putational linguistics courses that we offer regularlyand can suggest to incoming graduate students.
Thiswill not be part of a formal degree program per se,but will provide necessary structure for students toprogress through either the linguistics or computerscience program in a timely fashion while takingcourses relevant to their research interests.One of the big questions that hovers over nearlyall discussions of teaching computational linguisticsis: how do we teach the computer science to thelinguistics students and teach the linguistics to thecomputer science students?
Or, rather, the questionis how to teach both groups computational linguis-tics.
This involves getting students to understand theimportance of a strong formal basis, ranging fromunderstanding what a tight syntax-semantics inter-face really means to how machine learning mod-els relate to questions of actual language acquisi-tion to how corpus data can or should inform lin-guistic analyses.
It also involves revealing the cre-ativity and complexity of language to students whothink it should be easy to deal with.
And it involvesshowing linguistics students how familiar conceptsfrom linguistics translate to technical questions (forexample, addressing agreement using feature log-ics), and showing computer science students howfamiliar friends like finite-state automata and dy-namic programming are crucial for analyzing nat-ural language phenomena and managing complexityand ambiguity.
The key is to target the courses sothat the background needs of each type of studentcan be met appropriately without needing to skimpon linguistic or computational complexity for thosewho are ready to learn about it.Acknowledgments.
We would like to thank HansBoas, Bob Harms, Ray Mooney, Elias Ponvert, TonyWoodbury, and the anonymous reviewers for theirhelp and feedback.8ReferencesJason Baldridge, Sudipta Chatterjee, Alexis Palmer, andBen Wing.
2007.
DotCCG and VisCCG: Wiki andprogramming paradigms for improved grammar engi-neering with OpenCCG.
In Proceeings of the GEAF2007 Workshop.Kenneth R. Beesley and Lauri Karttunen.
2003.
FiniteState Morphology.
CSLI Publications.Steven Bird, Ewan Klein, Edward Loper, and JasonBaldridge.
2008.
Multidisciplinary instruction withthe Natural Language Toolkit.
In Proceedings of theThird Workshop on Issues in Teaching ComputationalLinguistics.
Association for Computational Linguis-tics.C.
Brew, M. Dickinson, and W. D. Meurers.
2005.
Lan-guage and computers: Creating an introduction for ageneral undergraduate audience.
In Proceedings of theWorkshop on Effective Tools and Methodologies forTeaching Natural Language Processing And Compu-tational Linguistics, Ann Arbor, Michigan.Jason Eisner.
2002.
An interactive spreadsheet for teach-ing the forward-backward algorithm.
In DragomirRadev and Chris Brew, editors, Proceedings of theACL Workshop on Effective Tools and Methodologiesfor Teaching NLP and CL, pages 10?18.Katrin Erk and Sebastian Pado.
2006.
Shalmaneser ?
aflexible toolbox for semantic role assignment.
In Pro-ceedings of LREC-2006, Genoa, Italy.D.
Jurafsky and J. H. Martin.
2000.
Speech and languageprocessing: An Introduction to Natural LanguageProcessing, Computational Linguistics, and SpeechRecognition.
Prentice-Hall, Upper Saddle River, NJ.Edward Loper and Steven Bird.
2002.
NLTK: The natu-ral language toolkit.
In Proceedings of the ACL Work-shop on Effective Tools and Methodologies for Teach-ing Natural Language Processing and ComputationalLinguistics, pages 62?69.
Somerset, NJ: Associationfor Computational Linguistics.Taesun Moon and Jason Baldridge.
2007.
Part-of-speechtagging for middle English through alignment and pro-jection of parallel diachronic texts.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL), pages390?399.Taesun Moon and Katrin Erk.
2008.
Minimally super-vised lemmatization scheme induction through bilin-gual parallel corpora.
In Proceedings of the Interna-tional Conference on Global Interoperability for Lan-guage Resources.Elias Ponvert.
2007.
Inducing Combinatory CategorialGrammars with genetic algorithms.
In Proceedingsof the ACL 2007 Student Research Workshop, pages7?12, Prague, Czech Republic, June.
Association forComputational Linguistics.Stuart Robinson, Greg Aumann, and Steven Bird.
2007.Managing fieldwork data with Toolbox and the Natu-ral Language Toolkit.
Language Documentation andConservation, 1:44?57.9
