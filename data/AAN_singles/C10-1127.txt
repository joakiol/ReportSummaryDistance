Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1128?1136,Beijing, August 2010Efficient Statement Identification for Automatic Market ForecastingHenning WachsmuthUniversita?t PaderbornSoftware Quality Labhwachsmuth@slab.upb.dePeter Prettenhofer and Benno SteinBauhaus-Universita?t WeimarWeb Technology & Information Systemsbenno.stein@uni-weimar.deAbstractStrategic business decision making in-volves the analysis of market forecasts.Today, the identification and aggregationof relevant market statements is done byhuman experts, often by analyzing doc-uments from the World Wide Web.
Wepresent an efficient information extrac-tion chain to automate this complex nat-ural language processing task and showresults for the identification part.
Basedon time and money extraction, we iden-tify sentences that represent statements onrevenue using support vector classifica-tion.
We provide a corpus with Germanonline news articles, in which more than2,000 such sentences are annotated by do-main experts from the industry.
On thetest data, our statement identification al-gorithm achieves an overall precision andrecall of 0.86 and 0.87 respectively.1 IntroductionTouch screen market to hit $9B by 2015.
50 sup-pliers provide multi-touch screens, and that num-ber is likely to rise.1Strategic business decision making is a highlycomplex process that requires experience as wellas an overall view of economics, politics, andtechnological developments.
Clearly, for the timebeing this process cannot be done by a computer atthe level of a human expert.
However, importanttasks may be automated such as market forecast-ing, which relies on identifying and aggregatingrelevant information from the World Wide Web(Berekoven et.
al., 2001).
An analyst who inter-prets the respective data can get a reasonable ideaabout the future market volume, for example.
The1Adapted from http://industry.bnet.com.problem is that a manually conducted Web searchis time-consuming and usually far from being ex-haustive.
With our research we seek to developan efficient system that finds and analyzes marketforecast information with retrieval, extraction andnatural language processing (NLP) techniques.We contribute to the following situation.
For agiven product, technology, or industry sector weidentify and aggregate statements on its marketdevelopment found on relevant websites.
In par-ticular, we extract time information (?by 2015?
)and money information (?$9B?)
and use supportvector classification to identify sentences that rep-resent market statements.
The statements?
sub-jects (?touch screen?)
are found by relating recog-nized named entities to the time and money infor-mation, which we then normalize and aggregate.In this paper we report on results for the statementidentification.
To the best of our knowledge nodata for the investigation of such market analysistasks has been made publicly available until now.We provide such a corpus with statements on rev-enue annotated in news articles from the Web; thecorpus was created in close collaboration with ourindustry partner Resolto Informatik GmbH.We pursue two objectives, namely, to supporthuman experts with respect to the effectivenessand completeness of their analysis, and to estab-lish a technological basis upon which more intri-cate analysis tasks can be automated.
To summa-rize, the main contributions of this paper are:1.
We show how to decompose the identifi-cation and aggregation of forecasts into re-trieval, extraction, and normalization tasks.2.
We introduce a manually annotated Germancorpus for computational linguistics researchon market information.3.
We offer empirical evidence that classifica-tion and extraction techniques can be com-1128bined to precisely identify statements on rev-enue.1.1 Related WorkStein et.
al.
(2005) were among the first to con-sider information extraction for automatic mar-ket forecasting.
Unlike us, the authors put muchemphasis on retrieval aspects and applied depen-dency grammar parsing to identify market state-ments.
As a consequence their approach suffersfrom the limitation to a small number of prede-fined sentence structures.While we obtain market forecasts by extract-ing expert statements from the Web, related ap-proaches derive them from past market behaviorand quantitative news data.
Koppel and Shtrim-berg (2004) studied the effect of news on finan-cial markets.
Lavrenko et al (2000) used time-series analysis and language models to predictstock market prices and, similarly, Lerman et al(2008) proposed a system for forecasting publicopinion based on concurrent modeling of news ar-ticles and market history.
Another related field isopinion mining in the sense that it relies on the ag-gregation of individual statements.
Glance et al(2005) inferred marketing intelligence from opin-ions in online discussions.
Liu et al (2007) exam-ined the effect of Weblogs on box office revenuesand combined time-series with sentiment analysisto predict the sales performance of movies.The mentioned approaches are intended to re-flect or to predict present developments and,therefore, primarily help for operative decisionmaking.
In contrast, we aim at predicting long-term market developments, which are essential forstrategic decision making.2 The ProblemMarket forecasts depend on two parameters, thetopic of interest and the criterion to look at.
Atopic is either an organization or a market.
Undera market we unite branches, products, and tech-nologies, because the distinction between these isnot clear in general (e.g., for semiconductors).
Incontrast, we define a criterion to be a metric at-tribute that can be measured over time.
Here weare interested in financial criteria such as revenue,profit, and the like.
The ambitious overall task thatwe want to solve is as follows:Task description: Given a topic ?
and a finan-cial criterion ?, find information for ?
on the de-velopment of ?.
Aggregate the found values on ?with respect to time.We omit the limitation to forecasts because wecould miss useful information otherwise:(1) In 2008, the Egyptian automobile industryachieved US$ 9.96bn in sales.
(2) Egypt?s automotive sales will rise by 97%from 2008 to 2013.Both sentences have the same topic.
In Particu-lar, the 2008 amount of money from example (1)can be aggregated with the forecast in (2) to inferthe predicted amount in 2013.As in these examples, market information canoften only be found in running text; the majorsource for this is the Web.
Thus, we seek tofind web pages with sentences that represent state-ments on a financial criterion ?
and to makethese statements processable.
Conceptually, sucha statement is a 5-tuple S?
= (S, g, T,M, td),where S is the topical subject, which may have ageographic scope g, T is a period of time, M con-sists of a growth rate and/or an amount of moneyto be achieved during T with respect to ?, and tdis the statement time, i.e., the point in time whenthe statement was made.3 ApproachOur goal is to find and aggregate statements ona criterion ?
for a topic ?
.
In close collaborationwith two companies from the semantic technologyfield, we identified eight high-level subtasks in theoverall process as explained in the following.
Anoverview is given in Table 1.3.1 Find Candidate DocumentsTo find web pages that are likely to contain state-ments on ?
and ?
, we propose to perform a meta-search by starting from a set of characteristicterms of the domain and then using query expan-sion techniques such as local context analysis (Xuand Croft, 2000).
As Stein et.
al.
(2005) describe,1129Subtask Applied technologies1 Find candidate documents meta-search, query expansion, genre analysis2 Preprocess content content extraction, sentence splitting, tokenization, POS tagging and chunking3 Extract entities time and money extraction, named entity recognition of organizations and markets4 Identify statements statistical classification based on lexical and distance features5 Determine statement type relation extraction based on dependency parse trees, matching of word lists6 Fill statement templates template filling, anaphora resolution, matching of word lists7 Normalize values time and money normalization, coreference resolution8 Aggregate information chronological merging and averaging, inference from subtopic to topicTable 1: Subtasks of the identification and aggregation of market statements for a specified topic.Experiments in this paper cover the subtasks written in black.a genre analysis, which classifies a document withrespect to its form, style, and targeted audience,may be deployed afterwards to further improvethe quality of the result list efficiently.
In this way,we only maintain candidate documents that lookpromising on the surface.3.2 Preprocess ContentPreprocessing is needed for accurate access to thedocument text.
Our overall task incorporates re-lating information from different document areas,so mixing up a web page?s main frame and side-bars should be avoided.
We choose DocumentSlope Curve (DSC) for content detection, whichlooks for plateaus in the HTML tag distribution.Gottron (2007) has offered evidence that DSCis currently the best algorithm in terms of pre-cision.
Afterwards, the sentences are split withrules that consider the specific characteristics ofreports, press releases and the like, such as head-lines between short paragraphs.
In succeedingsubtasks, tokens as well as their Part-of-Speechand chunk tags are also used, but we see no pointin not relying on standard algorithms here.3.3 Extract EntitiesThe key to identify a statement S?
on a finan-cial criterion ?
is the extraction of temporal andmonetary entities.
Recent works report that sta-tistical approaches to this task can compete withhand-crafted rules (Ahn et.
al., 2005; Cramer et.al., 2007).
In the financial domain, however, thefocus is only on dates and periods as time infor-mation, along with currency numbers, currencyterms, or fractions as money information.
Wefound that with regular expressions, which rep-resent the complex but finite structures of suchphrases, we can achieve nearly perfect recall inrecognition (see Section 5).We apply named entity recognition (NER) oforganizations and markets in this stage, too, so wecan relate statements to the appropriate subjects,later on.
Note that market names do not follow aunique naming scheme, but we observed that theyoften involve similar phrase patterns that can beexploited as features.
NER is usually done by se-quence labeling, and we use heuristic beam searchdue to our effort to design a highly efficient overallsystem.
Ratinov and Roth (2009) have shown forthe CoNLL-2003 shared task that Greedy decod-ing (i.e., beam search of width 1) is competitiveto the widely used Viterbi algorithm while beingover 100 times faster at the same time.3.4 Identify StatementsBased on time and money information, sentencesthat represent a statement S?
can be identified.Such a sentence gives us valuable hints on whichtemporal and monetary entity stick together andhow to interpret them in relation.
Additionally,it serves as evidence for the statement?s correct-ness (or incorrectness).
Every sentence with atleast one temporal and one monetary entity is acandidate.
Criteria such as revenue usually implysmall core vocabularies Lpos, which indicate thata sentence is on that criterion or which often ap-pear close to it.
On the contrary, there are sets ofwords Lneg that suggest a different criterion.
Fora given text collection with known statements on?, both Lpos and Lneg can be found by computingthe most discriminant terms with respect to ?.
Areasonable first approach is then to filter sentences1130that contain terms from Lpos and lack terms fromLneg, but problems arise when terms from differ-ent vocabularies co-occur or statements on differ-ent criteria are attached to one another.Instead, we propose a statistical learning ap-proach.
Support Vector Machines (SVMs) havebeen proven to yield very good performance inboth general classification and sentence extractionwhile being immune to overfitting (Steinwart andChristmann, 2008; Hirao et.
al., 2001).
For ourcandidates, we compute lexical and distance fea-tures based on Lpos, Lneg, and the time and moneyinformation.
Then we let an SVM use these fea-tures to distinguish between sentences with state-ments on ?
and others.
At least for online newsarticles, this works reasonably well as we demon-strate in Section 5.
Note that classification is notused to match the right entities, but to filter thesmall set of sentences on ?.3.5 Determine Statement TypeThe statement type implies what information wecan process.
If a sentence contains more than onetemporal or monetary entity, we need to relate thecorrect T and M to each S?, now.
The type of S?then depends on the available money information,its trend and the time direction.We consider four types of money information.?
refers to a period of time that results in a newamount A of money in contrast to its precedingamount Ap.
The difference between A and Apmay be specified as an incremental amount ?Aor as a relative growth rate r. M can span anycombination of A, Ap, ?A and r, and at least Aand r constitute a reasonable entity on their own.Sometimes the trend of r (i.e.
decreasing or in-creasing) cannot be derived from the given val-ues.
However, this information can mostly be ob-tained from a nearby indicator word (e.g.
?plus?
or?decreased?)
and, therefore, we address this prob-lem with appropriate word lists.
Once the trend isknown, any two types imply the others.Though we are predominantly interested inforecasts, statements also often represent a decla-ration on achieved results.
This distinction is es-sential and can be based on time-directional indi-cators (e.g.
?next?)
and the tense of leading verbs.For this, we test both feature and kernel methodson dependency parse trees, thereby determining Tand M at the same time.
We only parse the iden-tified sentences, though.
Hence, we avoid runninginto efficiency problems.3.6 Fill Statement TemplatesThe remaining subtasks are ongoing work, so weonly present basic concepts here.Besides T and M , the subject S and the state-ment time td have to be determined.
S may befound within the previously extracted named enti-ties using the dependency parse tree from Section3.5 or by anaphora resolution.
Possible limitationsto a geographic scope g can be recognized withword lists.
In market analysis, the approximatetd suffices, and for most news articles td is simi-lar to their release date.
Thus, if no date is in theparse tree, we search the extracted temporal enti-ties for the release date, which is often mentionedat the beginning or end of the document?s content.We fill one template (S, g, T,M, td) for each S?where we have at least S, T , and M .3.7 Normalize ValuesSince we base the extraction on regular expres-sions, we can normalize most monetary entitieswith a predefined set of rules.
Section 3.5 impliesthat M?
= (A?, r?)
is a reasonable normalizedform where A?
is A specified in million US-$ andr?
is r as percentage with a fixed number of deci-mals.2 Time normalization is more complex.
Anyperiod should be transformed to T ?
= (t?s, t?e)consisting of the start date t?s and end date t?e .Following Ahn et.
al.
(2005), we consider fullyqualified, deictic and anaphoric periods.
Whilenormalization of fully qualified periods like ?fromApr to Jun 1999?
is straightforward, deictic (e.g.
?since 2005?, ?next year?)
and anaphoric men-tions (e.g.
?in the reported time?)
require a refer-ence time.
Approaches to resolve such referencesrely on dates or fully qualified periods in the pre-ceding text (Saquete et.
al., 2003; Mani and Wil-son, 2000).32Translating the currency requires exchange rates at state-ment time.
We need access to such information or omit thetranslation if only one currency is relevant.3References to fiscal years even involve a whole searchproblem if no look-up table on such data is available.1131without interferencewith interference024AA?pA?Apt 024t024AA?Ap=A?pt 024tmill.US-$ mill.US-$mill.US-$ mill.US-$Figure 1: Example for merging monetary values.91011A?A?
?Atmill.US-$-10%0%10%trFigure 2: Example for the inference of relative in-formation from absolute values.If we cannot normalize M or T , we discard thecorresponding statement templates.
For the oth-ers, we have to resolve synonymous co-references(e.g.
?Loewe AG?
and ?Loewe?)
before we canproceed to the last step.3.8 Aggregate InformationWe can aggregate the normalized values in eithertwo or three dimensions depending on whetherto separate statements with respect to td.
Aggre-gation then incorporates two challenges, namely,how to merge values and how to infer informationon a topic from values of a subtopic.We say that two statements on the same topic?
and criterion ?
interfere if the contained peri-ods of time intersect and the according monetaryvalues do not coincide.
In case of declarations,this means that we extracted incorrect values orextracted values incorrectly.
For forecasts, on thecontrary, we are exactly onto such information.In both cases, an intuitive solution is to computethe average (or median) and deviations.
Figure 1graphically illustrates such merging.
The subtopicchallenge is based on the assumption that a mean-ingful number of statements on a certain subtopicof ?
implies relative information on ?
, as shown inFigure 2.
One of the most interesting relations areorganizations as subtopics of markets they pro-duce for, because it is quite usual to search forStatements Total Forecasts DeclarationsComplete corpus 2075 523 (25.2%) 1552 (74.8%)Training set 1366 306 (22.4%) 1060 (77.6%)Validation set 362 113 (31.2%) 249 (68.8%)Test set 347 104 (30.0%) 243 (70.0%)Table 2: Statements on revenue in the corpus.information on a market, but only receive state-ments on companies.
Approaches to this relationmay rely e.g.
on the web page co-occurrence andterm frequencies of the markets and companies.Altogether, we return the aggregated valueslinked to the sentences in which we found them.In this way, we make the results verifiable and,thereby, compensate for possible inaccuracies.4 CorpusTo evaluate the given and related tasks, we builta manually annotated corpus with online news ar-ticles on the revenues of organizations and mar-kets.
The compilation aims at being representa-tive for target documents, a search engine returnsto queries on revenue.
The purpose of the corpusis to investigate both the structure of sentences onfinancial criteria and the distribution of associatedinformation over the text.The corpus consists of 1,128 German news ar-ticles from the years 2003 to 2009, which weretaken from 29 news websites like www.spiegel.deor www.capital.de.
The content of each documentcomes as unicode plain text with appended URLfor access to the HTML source code.
Annotationsare given in a standard XMI file preformatted forthe Unstructured Information Management Archi-tecture (Ferrucci and Lally, 2004).
We created asplit, in which 2/3 of the documents constitute thetraining set and each 1/6 refers to the validationand test set.
To simulate real conditions, the train-ing documents were randomly chosen from onlythe seven most represented websites, while thevalidation and test data both cover all 29 sources.Table 2 shows some corpus statistics, which givea hint that the validation and test set differ sig-nificantly from the training set.
The corpus isfree for scientific use and can be downloaded athttp://infexba.upb.de.1132Loewe AG: Vorla?ufige Neun-Monats-ZahlenKronach, [6.
November 2007]REF ?
Das Ergebnis vorZinsen und Steuern (EBIT) des Loewe Konzerns konntein den ersten 9 Monaten 2007 um 41% gesteigert wer-den.
Vor diesem Hintergrund hebt die [Loewe AG]ORGihre EBIT-Prognose fu?r das laufende Gescha?ftsjahr auf20 Mio.
Euro an.
Beim Umsatz strebt Konzernchef[Rainer Hecker]AUTH [fu?r das Gesamtjahr]TIME einho?her als urspru?nglich geplantes [Wachstum]TREND[von 10% auf ca.
380 Mio.
Euro]MONEY an.
(...)Figure 3: An annotated document in the corpus.The text is taken from www.boerse-online.de, buthas been modified for clarification.4.1 AnnotationsIn each document, every sentence that includes atemporal entity T and a monetary entity M andthat represents a forecast or declaration on therevenue of an organization or market is markedas such.
T and M are annotated themselves andlinked to the sentence.
Accordingly, the subjectis tagged (and linked) within the sentence bound-aries if available, otherwise its last mention in thepreceding text.
The same holds for optional en-tities, namely a reference time, a trend indicatorand the author of a statement.
Altogether, 2,075statements are tagged in this way.
As in Figure3, only information that refers to a statement onrevenue (typed in bold face) is annotated.
Theseannotations may be spread across the text.The source documents were manually selectedand prepared by our industrial partners, and twoof their employees annotated the plain documenttext.
With respect to the statement annotations,a preceding pilot study yielded substantial inter-annotator agreement, as indicated by the value?
= 0.79 of the conservative measure Cohen?sKappa (Carletta, 1996).
Additionally, we per-formed a manual correction process for each an-notated document to improve consistency.5 ExperimentsWe now present experiments for the statementidentification, which were conducted on our cor-pus.
The goal was to evaluate whether our com-bined extraction and classification approach suc-ceeds in the precise identification of sentences thatcomprise a statement on revenue, while keepingrecall high.
Only exact matches of the annotatedtext spans were considered to be correct identifi-cations.
Unlike in Section 3, we only worked onplain text, though.5.1 Experimental SetupTo find candidate sentences, we implemented asentence splitter that can handle article elementssuch as subheadings, URLs, or bracketed sen-tences.
We then constructed sophisticated, butefficient regular expressions for time and money.They do not represent correct language, in gen-eral, but model the structure of temporal and mon-etary entities, and use word lists provided by do-main experts on the lowest level.4 For featurecomputation, we assumed that the closest pair oftemporal and monetary entity refers to the enclos-ing candidate sentence.5 Since only positive in-stances IP of statements on revenue are annotatedin our corpus, we declared all candidates, whichhave no counterpart in the annotated data, to con-stitute the negative class IN , and balanced IP andIN by ?randomly?
(seed 42) removing instancesfrom IN .6For the vocabularies Lpos = {P1, P2} we firstcounted the frequencies of all words in the unbal-anced sets IP and IN .
From these, we deletednamed entities, numbers and adjectives.
If the pre-fix (e.g.
?Umsatz?)
of a word (?Umsatzplus?)
oc-curred, we only kept the prefix.
We then filteredall terms that appeared in at least 1.25% of the in-stances in IP and more than 3.5 times as much inIP as in IN .
The remaining words were manuallypartitioned into two lists:P1 = {umgesetzt, Umsatz, Umsa?tze, setzte} (allof these are terms for revenue)P2 = {Billionen, meldet, Mitarbeiter, Verband}(trillions, announce, employee, association)Lneg = {N1, N2} was built accordingly.
In ad-dition, we set up a list G1 with genitive pronouns4More details are given at http://infexba.upb.de.555% of the candidate sentences in the training set con-tain more than one temporal and/or monetary entity, so thisassumption may lead to errors.6We both tested undersampling and oversampling tech-niques but saw no effective differences in the results.1133and determiners.
Based on Lpos, Lneg and G1,we computed the following 43 features for everycandidate sentence s:?
1-8: Number of terms from P1 (N1) in s aswell as in the two preceding sentences and inthe following sentence.?
9-10: Number of terms from P2 (N2) in s.?
11: Occurrence of term from G1 next to themonetary entity.?
12-19: Forward (backward) distance in to-kens between the monetary (temporal) entityin s and a term from P1 (N1).?
20-27: Forward (backward) distance in num-ber of symbols from O1 = {?.?,???,?!?}
be-tween the monetary (temporal) entity in sand a term from P1 (N1).?
28-43: Same as 20-27 for O2 = {?:?,?;?}
andO3 = {?,?
}, respectively.We trained a linear SVM with cost parameterC = 0.3 (selected during validation) on these fea-tures using the Weka integration of LibSVM (Hallet.
al., 2009; Fan et.
al., 2001).
Further featureswere evaluated, e.g.
occurrences of contraposi-tions or comparisons, but they did not improve theclassifier.
Instead, we noticed that we can avoidsome complex cases when we apply two rules af-ter entity extraction:R1: Delete temporal and monetary entities thatare directly surrounded by brackets.R2: Delete temporal entities that contain theword ?Vorjahr?
(?preceding year?
).Now, we evaluated the following five statementidentification algorithms:?
Na?
?ve: Simply return all candidate sentences(to estimate the relative frequency of state-ments on revenue in the corpus).?
Baseline: Return all candidate sentences thatcontain a term from the list P1.?
NEG: Use the results from Baseline.
Returnall sentences that lack terms from N1.Recall Training Validation TestSentences 0.98 0.98 0.96Temporal entities 0.97 (0.95) 0.97 (0.94) 0.98 (0.96)Monetary entities 0.96 (0.96) 0.96 (0.96) 0.95 (0.94)Table 3: Recall of sentence and entity extraction.In brackets: Recall after applying R1 and R2.?
RB: Filter candidates using R1 and R2.
Thenapply NEG.?
SVM: Filter candidates using R1 and R2.Then classify sentences with the SVM.5.2 ResultsTable 3 shows that we found at least 95% of thesentences, time and money information, which re-fer to a statement on revenue, in all datasets.7 Wecould not measure precision for these since not allsentences and entities are annotated in the corpus,as mentioned in Section 4.Results for the statement identification aregiven in Figure 4.
Generally, the test values aresomewhat lower than the validation values, butanalog in distribution.
Nearly all statements wererecognized by the Na?
?ve algorithm, but only witha precision of 0.35.
In contrast, both for Baselineand NEG already around 80% of the found state-ments were correct.
The latter paid a small gain inprecision with a significant loss in recall.
WhileRB and SVM both achieved 86% precision on thetest set, SVM tends to be a little more precise assuggested by the validation results.
In terms of re-call, SVM clearly outperformed RB with valuesof 89% and 87% and was only a little worse thanthe Baseline.
Altogether, the F1-Measure valuesshow that SVM was the best performing algorithmin our evaluation.5.3 Error AnalysisTo assess the influence of the sentence, time andmoney extraction, we compared precision and re-call of the classifier on the manually annotated andthe extracted data, respectively.
Table 4 shows7We intentionally did not search for unusual entities like?am 1.
Handelstag nach dem Erntedankfest?
(?the 1st tradingday after Thanksgiving?)
in order not to develop techniquesthat are tailored to individual cases.
Also, money amountsthat lack a currency term were not recognized.11340,750,800,850,900,951,00TestValidationNa?veNa?veBaselineBaselineNEGNEGRBRBSVMSVMRecall.89.87.83.830,30,40,50,60,70,80,9TestValidationNa?veNa?veBaselineBaselineNEGNEGRBRBSVMSVMPrecision.89 .90.86 .860,50,60,70,80,9TestValidationNa?veNa?veBaselineBaselineNEGNEGRBRBSVMSVMF1-Measure.89.86.84.86.79 .77.92.89.85.83Figure 4: Precision, recall and F1-Measure of the five evaluated statement identification algorithms.SVM is best in precision both on validation and test data and outperforms RB in recall significantly.that only recall differs significantly.
We found thatfalse statement identifications referred to the fol-lowing noteworthy error cases.False match: Most false positives result frommatchings of temporal and monetary entities thatactually do not refer to the same statement.Missing criterion: Some texts describe the de-velopment of revenue without ever mentioningrevenue.
Surrogate words like ?market?
may beused, but they are not discriminative enough.Multiple criteria: Though we aimed at dis-carding sentences, in which revenue is mentionedwithout comprising a statement on it, in somecases our features did not work out, mainly dueto intricate sentence structure.Traps: Some sentences contain numeric valueson revenue, but not the ones looked for, as in ?10%of the revenue?.
We tackled these cases, but hadstill some false classifications left.Hidden boundaries: Finally, we did not findall correct sentence boundaries, which can lead toboth false positives and false negatives.
The pre-dominant problem was to separate headlines fromparagraph beginnings and is partly caused by themissing access to markup tags.5.4 EfficiencyWe ran the identification algorithm on the wholecorpus using a 2 GHz Intel Core 2 Duo MacBookwith 4 GB RAM.
The 1,128 corpus documentscontain 33,370 sentences as counted by our algo-rithm itself.
Tokenization, sentence splitting, timeand money extraction took only 55.2 seconds, i.e.,more than 20 documents or 600 sentences eachsecond.
Since our feature computation is not op-timized yet, the complete identification process isa little less efficient with 7.35 documents or 218Candidates Data Precision RecallAnnotated validation data 0.91 0.94test data 0.87 0.93Extracted validation data 0.90 0.89test data 0.86 0.87Table 4: Precision and recall of the statementidentification on manually annotated data and onautomatically extracted data, respectively.sentences per second.
However, it is fast enoughto be used in online applications, which was ourgoal in the end.6 ConclusionWe presented a multi-stage approach for the au-tomatic identification and aggregation of marketstatements and introduced a manually annotatedGerman corpus for related tasks.
The approachhas been influenced by industry and is orientedtowards practical applications, but is, in general,not specific to the German language.
It relies onefficient retrieval, extraction and NLP techniques.By now, we can precisely identify most sentencesthat represent statements on revenue.
This alreadyallows for the support of strategists, e.g.
by high-lighting such sentences in web pages, which wecurrently implement as a Firefox extension.
Theoverall problem is complex, though, and we areaware that human experts can do better at present.Nevertheless, time-consuming tasks can be auto-mated and, in this respect, the results on our cor-pus are very promising.Acknowledgement: This work was funded bythe project ?InfexBA?
of the German Federal Min-istry of Education and Research (BMBF) undercontract number 01IS08007A.1135ReferencesAhn, David, Sisay F. Adafre, and Maarten de Rijke.2005.
Extracting Temporal Information from OpenDomain Text: A Comparative Exploration.
Journalof Digital Information Management, 3(1): 14?20.Berekoven, Ludwig, Werner Eckert, and Peter El-lenrieder.
2001.
Marktforschung: MethodischeGrundlagen und praktische Anwendung, 9th Edi-tion, Gabler, Wiesbaden, Germany.Carletta, Jean.
1996.
Assessing Agreement on Classi-fication Tasks: The Kappa Statistic.
ComputationalLinguistics, 22: 249?254.Cramer, Irene M., Stefan Schacht, and AndreasMerkel.
2007.
Classifying Number Expressions inGerman Corpora.
In Proceedings of the 31st An-nual Conference of the German Classification Soci-ety on Data Analysis, Machine Learning, and Appli-cations, pages 553?560.Fan, Rong-En, Pai-Hsuen Chen, and Chih-Jen Lin.2001.
Working Set Selection Using Second OrderInformation for Training Support Vector Machines.Journal of Machine Learning Research, 6: 1889?1918.Ferrucci, David and Adam Lally.
2004.
UIMA:An Architectural Approach to Unstructured Infor-mation Processing in the Corporate Research Envi-ronment.
Natural Language Engineering, 10(3?4):pages 327?348.Glance, Natalie, Matthew Hurst, Kamal Nigam,Matthew Siegler, Robert Stockton, and TakashiTomokiyo.
2005.
Deriving Marketing Intelligencefrom Online Discussion.
In Proceedings of theEleventh International Conference on KnowledgeDiscovery in Data Mining, pages 419?428.Gottron, Thomas.
2007.
Evaluating Content Extrac-tion on HTML Documents.
In Proceedings of the2nd International Conference on Internet Technolo-gies and Applications, pages 123?132.Hall, Mark, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: An Up-date.
SIGKDD Explorations, 11(1).Hirao, Tsutomu, Hideki Isozaki, Eisaku Maeda andYuji Matsumoto.
2002.
Extracting Important Sen-tences with Support Vector Machines.
In Proceed-ings of the 19th International Conference on Com-putational linguistics, pages 342?348.Koppel, Moshe and Itai Shtrimberg.
2004.
GoodNews or Bad News?
Let the Market Decide.
In Pro-ceedings of the AAAI Spring Symposium on Explor-ing Attitude and Affect in Text: Theories and Appli-cations, pages 86?88.Lavrenko, Victor, Matt Schmill, Dawn Lawrie, PaulOgilvie, David Jensen, and James Allan.
2000.Mining of Concurrent Text and Time Series.
InProceedings of the 6th ACM SIGKDD Interna-tional Conference on Knowledge Discovery andData Mining Workshop on Text Mining, pages 37?44.Lerman, Kevin, Ari Gilder, Mark Dredze, and Fer-nando Pereira.
2008.
Reading the Markets: Fore-casting Public Opinion of Political Candidates byNews Analysis.
In Proceedings of the 22nd Inter-national Conference on Computational Linguistics,pages 473?480.Liu, Yang, Xiangji Huang, Aijun An, and Xiaohui Yu.2007.
Arsa: A Sentiment-Aware Model for Predict-ing Sales Performance Using Blogs.
In Proceedingsof the 30th Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, pages 607?614.Mani, Inderjeet and George Wilson.
2000.
Ro-bust Temporal Processing of News.
In Proceedingsof the 38th Annual Meeting of the Association forComputational Linguistics, pages 69?76.Ratinov, Lev and Dan Roth.
2009.
Design Chal-lenges and Misconceptions in Named Entity Recog-nition.
In Proceedings of the Thirteenth Confer-ence on Computational Natural Language Learn-ing, pages 147?155.Saquete, Estela, Rafael Mun?oz, and Patricio Mart??nez-Barco.
2003.
TERSEO: Temporal Expression Res-olution System Applied to Event Ordering.
Text,Speech and Dialogue, Springer, Berlin / Heidelberg,Germany, pages 220?228.Stein, Benno, Sven Meyer zu Eissen, Gernot Gra?fe,and Frank Wissbrock.
2005.
Automating MarketForecast Summarization from Internet Data.
FourthInternational Conference on WWW/Internet, pages395?402.Steinwart, Ingo and Andreas Christmann.
2008.
Sup-port Vector Machines, Springer, New York, NY.Xu, Jinxi and Bruce W. Croft 2000.
Improving the ef-fectiveness of information retrieval with local con-text analysis.
ACM Transactions on InformationSystems, 18(1): 79-112.1136
