Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 116?124,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsCare Episode RetrievalHans Moen1, Erwin Marsi1, Filip Ginter2,Laura-Maria Murtola3,4, Tapio Salakoski2, Sanna Salanter?a3,4,1Dept.
of Computer and Information Science,Norwegian University of Science and Technology, Norway2Dept.
of Information Technology, University of Turku, Finland3Dept.
of Nursing Science, University of Turku, Finland4Turku University Hospital, Finland{hans.moen,emarsi}@idi.ntnu.no, ginter@cs.utu.fi,{lmemur,tapio.salakoski,sansala}@utu.fiAbstractThe documentation of a care episode con-sists of clinical notes concerning patientcare, concluded with a discharge sum-mary.
Care episodes are stored electron-ically and used throughout the health caresector by patients, administrators and pro-fessionals from different areas, primarilyfor clinical purposes, but also for sec-ondary purposes such as decision supportand research.
A common use case is, givena ?
possibly unfinished ?
care episode,to retrieve the most similar care episodesamong the records.
This paper presentsseveral methods for information retrieval,focusing on care episode retrieval, basedon textual similarity, where similarity ismeasured through domain-specific mod-elling of the distributional semantics ofwords.
Models include variants of randomindexing and a semantic neural networkmodel called word2vec.
A novel method isintroduced that utilizes the ICD-10 codesattached to care episodes to better inducedomain-specificity in the semantic model.We report on an experimental evaluationof care episode retrieval that circumventsthe lack of human judgements regardingepisode relevance by exploiting (1) ICD-10 codes of care episodes and (2) seman-tic similarity between their discharge sum-maries.
Results suggest that several of themethods proposed outperform a state-of-the art search engine (Lucene) on the re-trieval task.1 IntroductionInformation retrieval (IR) aims at retrieving andranking documents relative to a textual query ex-pressing the information need of a user (Manninget al., 2008).
IR has become a crucial technologyfor many organisations that deal with vast amountsof partly structured and unstructured (free text)data stored in electronic format, including hospi-tals and other health care providers.
IR is an es-sential part of the clinical practice; e.g., on-line IRsystems are associated with substantial improve-ments in clinicians decision-making concerningclinical problems (Westbrook et al., 2005).The different stages of the clinical care of a pa-tient are documented in clinical care notes, con-sisting mainly of free text.
A care episode consistsof a sequence of individual clinical care notes,concluded by a discharge summary, as illustratedin Figure 1.
Care episodes are stored in elec-tronic format in electronic health record (EHR)systems.
These systems are used throughout thehealth care sector by patients, administrators andprofessionals from different areas, primarily forclinical purposes, but also for secondary purposessuch as decision support and research (H?ayrinen etal., 2008).
IR from EHR in general is therefore acommon and important task.This paper focuses on the particular task of re-trieving those care episodes that are most similarto the sequence of clinical notes for a given pa-tient, which we will call care episode retrieval.In conventional IR, the query typically consists ofseveral keywords or a short phrase, while the re-trievable units are typically documents.
In con-trast, in care episode retrieval, the query consist ofthe clinical notes contained in a care episode.
Thedischarge summary is used separately for evalu-116ABTimeClinical notes DischargesummaryFigure 1: Illustration of care episode retrieval.
Thetwo care episodes (A and B) are composed ofa number of individual clinical notes and a sin-gle discharge summary.
Given an ongoing careepisode (minus the discharge summary), the taskis to retrieve other, similar care episodes.ation purposes, and is assumed to be unavailablefor constructing a query at retrieval time.
Retriev-able units are thus complete care episodes withoutsummaries.We envision a number of different use cases fora care episode retrieval system.
Firstly, it could fa-cilitate clinicians in decision-making.
For exam-ple, given a patient that is being treated in a hos-pital, an involved clinician may want to find previ-ous patients that are similar in terms of their healthhistory, symptoms or received treatments.
Supple-mentary input from the clinician would enable thesystem to give heightened weight to keywords ofparticular interest within the care episodes, whichwould further be emphasized in the semantic sim-ilarity calculation during IR.
It may help consider-ably to see what similar patients have received interms of medication and further treatment, whatrelated issues such as bi-conditions or risks oc-curred, how other clinicians have described cer-tain aspects, what clinical practice guidelines havebeen utilized, and so on.
This relates to the un-derlying principle in textual case-based reasoning(Lenz et al., 1998).
Secondly, it could help man-agement to get almost real time information con-cerning the overall situation on the unit for a spe-cific follow-up period.
Such a system could for ex-ample support managerial decision-making withstatistical information concerning care trends onthe unit, adverse events or infections.
Thirdly, itcould facilitate knowledge discovery and research.For instance, it could enable researchers to mapor cluster similar care episodes to find commonsymptoms or conditions.
In sum, care episode re-trieval is likely to improve care quality and consis-tency in hospitals.From the perspective of NLP, care episode re-trieval ?
and IR from EHRs in general ?
is achallenging task.
It differs from general-purposeweb search in that the vocabulary, the informa-tion needs and the queries of clinicians are highlyspecialised (Yang et al., 2011).
Clinical notescontain highly domain-specific terminology (Rec-tor, 1999; Friedman et al., 2002; Allvin et al.,2010) and generic text processing resources aretherefore often suboptimal or inadequate (Shatkay,2005).
At the same time, development of dedi-cated clinical NLP tools and resources is often dif-ficult and costly.
For example, popular data-drivenapproaches to NLP are based on supervised learn-ing, which requires substantial amounts of tailoredtraining data, typically built through manual anno-tation by annotators who need both linguistic andclinical knowledge.
Additionally, variations in thelanguage and terminology used in sub-domainswithin and across health care organisations greatlylimit the scope of applicability of such trainingdata (Rector, 1999).Recent work has shown that distributional mod-els of semantics, induced in an unsupervised man-ner from large corpora of clinical and/or medicaltext, are well suited as a resource-light approachto capturing and representing domain-specific ter-minology (Pedersen et al., 2007; Koopman et al.,2012; Henriksson et al., 2014).
This raises thequestion to what extent distributional models ofsemantics can alleviate the aforementioned prob-lems of NLP in the clinical domain.
The workreported here investigates to what extent distribu-tional models of semantics, built from a corpus ofclinical text in an fully unsupervised manner, canbe used for care episode retrieval.
Models includeseveral variants of random indexing and a seman-tic neural network model called word2vec, whichwill be described in more detail in Section 4.It has been argued that clinical NLP should ex-ploit existing knowledge resources such as knowl-edge bases about medications, treatments, dis-eases, symptoms and care plans, despite these nothaving been explicitly built for doing clinical NLP(Friedman et al., 2013).
Along these lines, a novelmethod is proposed here that utilizes the ICD-10codes ?
diagnostic labels attached to care episodesby clinicians ?
to better induce domain-specificityin the semantic model.
Experimental results sug-gest that this method outperforms a state-of-the artsearch engine (Lucene) on the task of care episode117retrieval.Apart from issues related to clinical terminol-ogy, another problem in care episode retrieval isthe lack of benchmark data, such as the relevancescores produced by human judges commonly usedfor evaluation of IR systems.
Although collec-tions of care episodes may be available, producinggold standard similarity scores required for evalu-ation is costly.
Another contribution of this paperis the proposal of evaluation procedures that cir-cumvent the lack of human judgements regardingepisode similarity.
This is accomplished by ex-ploiting either (1) ICD-10 codes of care episodesor (2) semantic similarity between their dischargesummaries.
Despite our focus on the specific taskof care episode retrieval, we hypothesize that themethods and models proposed here have the po-tential to increase performance of IR on clinicaltext in general.2 DataThe data set used in this study consists of the elec-tronic health records from patients with any typeof heart related problem that were admitted to oneparticular university hospital in Finland betweenthe years 2005-2009.
Of these, only the clini-cal notes written by physician are used.
A sup-porting statement for the research was obtainedfrom the Ethics Committee of the Hospital District(17.2.2009 ?67) and permission to conduct the re-search was obtained from the Medical Director ofthe Hospital District (2/2009).
The total set consistof 66884 care episodes, which amounts to 398040notes and 64 million words in total.
This full setwas used for training of the semantic models.
Tomake the experimentation more convenient, wechose to use a subset for evaluation.
This com-prises 26530 care episodes, amounting to 155562notes and 25.7 million words in total.Notes are mostly unstructured, consisting offree text in Finnish.
Some meta-data ?
such asnames of the authors, dates, wards, and so on ?
ispresent, but is not used for retrieval.Care episodes have been manually labeled ac-cording to the 10th revision of the InternationalClassification of Diseases (ICD-10) (World HealthOrganization and others, 2013), a standardisedtool of diagnostic codes for classifying diseases.Codes are normally applied at the end of the pa-tient?s stay, or even after the patient has been dis-charged from the hospital.
Care episodes haveone primary ICD-10 code attached and optionallya number of additionally relevant codes.
In thisstudy, only the primary one is used, because ex-traction of the secondary codes is non-trivial.ICD-10 codes have an internal structure that re-flects the classification system ranging from broadcategories down to fine-grained subjects.
For ex-ample, the first character (J) of the code J21.1signals that it belongs to the broad category Dis-eases of the respiratory system.
The next twodigits (21) classify the subject as belonging tothe subcategory Acute bronchiolitis.
Finally, thelast digit after the dot (1) means that it belongsto the sub-subclass Acute bronchiolitis due to hu-man metapneumovirus.
There are 356 unique ?pri-mary?
ICD-10 codes in the evaluation data set.3 TaskThe task addressed in this study is retrieval of careepisodes that are similar to each other.
In con-trast to the normal IR setting, where the searchquery is derived from a text stating the user?s in-formation need, here the query is based on an-other care episode, which we refer to as the queryepisode.
As the query episode may document on-going treatment, and thus lack a discharge sum-mary and ICD-10 code, neither of these informa-tion sources can be relied upon for constructingthe query.
The task is therefore to retrieve the mostsimilar care episodes using only the informationcontained in the free text of the clinical notes inthe query episode.Evaluation of retrieval results generally re-quires an assessment of their relevancy to thequery.
Since similarity judgements by humansare currently lacking, and obtaining these is time-consuming and costly, we explored alternativeways of evaluating performance on the task.
Thefirst alternative is to assume that care episodes aresimilar if they have the same ICD-10 code.
That is,a retrieved care episode is considered correct if itsICD-10 code is identical to the code of the queryepisode.
It should be noted that ICD-10 codes arenot used in the query in any of the experiments.Closer inspection shows that the free text con-tent in care episodes with the same ICD-10 codeis indeed quite similar in many cases, but not al-ways.
Considering all of them equally similaramounts to an arguably coarse approximation ofrelevance.
The second alternative tries to remedythis issue by measuring the similarity between dis-118charge summaries.
That is, if the discharge sum-mary of a retrieved episode is semantically simi-lar to the discharge summary of the query episode,the retrieved episode is assumed to be correct.In practice, textual similarity between dischargesummaries, and therefore the relevance score, iscontinuous rather than binary.
It is measured usingthe same models of distributional semantics usedfor retrieval, which will be described in Section 4.It should be stressed that the discharge summariesare not taken into consideration during retrieval inany of the experiments and are only used for eval-uation.4 Method4.1 Semantic modelsA crucial part in retrieving similar care episodesis having a good similarity measure.
Here similar-ity between care episodes is measured as the sim-ilarity between the words they contain (see Sec-tion 4.2).
Semantic similarity between words is inturn measured through the use of word space mod-els (WSM), without performing an explicit queryexpansion step.
Several variants of these modelswere tested, utilizing different techniques and pa-rameters for building them.
The models trainedand tested in this paper are: (1) classic randomindexing with a sliding window using term in-dex vectors and term context vectors (RI-Word);(2) random indexing with index vectors for doc-uments (RI-Doc); (3) random indexing with in-dex vectors for ICD-10 codes (RI-ICD); (4) a ver-sion of random indexing where only the term in-dex vectors are used (RI-Index); and (5) a seman-tic neural network model, using word2vec to buildword context vectors (Word2vec).RI-WordRandom Indexing (RI) (Kanerva et al., 2000) isa method for building a (pre) compressed WSMwith a fixed dimensionality, done in an incremen-tal fashion.
RI consist of the following two steps:First, instead of allocating one dimension in themultidimensional vector space to a single word,each word is assigned an ?index vector?
as itsunique signature in the vector space.
Index vectorsare generated vectors consisting of mostly zerostogether with a randomly distributed set of several1?s and -1?s, uniquely distributed for each uniqueword; The second step is to induce ?context vec-tors?
for each word.
A context vector representsthe contextual meaning of a word in the WSM.This is done using a sliding window of a fixed sizeto traverse a training corpus, inducing context vec-tors for the center/target word of the sliding win-dow by summing the index vectors of the neigh-bouring words in the window.As the dimensionality of the index vectors isfixed, the dimensionality of the vector space willnot grow beyond the size W ?Dim, where W isthe number of unique words in the vocabulary, andDim being the pre-selected dimensionality to usefor the index vectors.
As a result, RI models aresignificantly smaller than plain word space mod-els, making them a lot less computationally expen-sive.
Additionally, the method is fully incremental(additional training data can be added at any giventime without having to retrain the existing model),easy to parallelize, and scalable, meaning that it isfast and can be trained on large amounts of text inan on-line fashion.RI-DocContrary to sliding window approach used in RI-Word, a RI model built with document index vec-tors first assigns unique index vectors to everydocument in the training corpus.
In the trainingphase, each word in a document get the respectivedocument vector added to its context vector.
Theresulting WSM is thus a compressed version of aterm-by-document matrix.RI-ICDBased on the principle of RI with document indexvectors, we here explore a novel way of construct-ing a WSM by exploiting the ICD-10 code classi-fication done by clinicians.
Instead of using doc-ument index vectors, we here use ICD-code indexvectors.
First, a unique index vector is assigned toeach chapter and sub-chapter in the ICD-10 taxon-omy.
This means assigning a unique index vectorto each ?node?
in the ICD-10 taxonomy, as illus-trated in Figure 2.
For each clinical note in thetraining corpus, the index vector of the their pri-mary ICD-10 code is added to all words within it.In addition, all the index vectors for the ICD-codeshigher in the taxonomy are added, each weightedaccording to their position in the hierarchy.
Aweight of 1 is given to the full code, while theweight is halved for each step upwards in the hi-erarchy.
The motivation for the latter is to capturea certain degree of similarity between codes thatshare an initial path in the taxonomy.
As a result,119J?0.125?
0.25?
0.5?
1?
Weight?2?1?0?1?1?0?J21.1?0?Figure 2: Weighting applied to ICD-code indexvectors when training WSMs based on ICD-10codes (RI-ICD).this similarity is encoded in the resulting WSM.As a example: for a clinical note labelled with thecode J21.1, we add the following index vectorsto the context vectors of all its constituting words:iv(J)?
0.125, iv(J2)?
0.25, iv(J21)?
0.5 andiv(J21.1) ?
1.0.
The underlying hypothesis forbuilding a WSM in this way is that it may cap-ture relations between words in a way that bet-ter reflects the clinical domain, compared to theother domain-independent methods for construct-ing a WSM.RI-IndexAs an alternative to using word?s (semantic) con-text vectors, we simply only use their index vec-tors as their ?contextual meaning?.
When con-structing document vectors directly from word in-dex vectors (see Section 4.2), the resulting docu-ment vectors represent a compressed version of adocument-by-term matrix.Word2vecRecently, a novel method for inducing WSMs wasintroduced by Mikolov et al.
(2013a), stemmingfrom the research in deep learning and neural net-work language models.
While the overall objec-tive of learning a continuous vector space repre-sentation for each word based on its textual con-text remains, the underlying algorithms are sub-stantially different from traditional methods suchas Latent Semantic Analysis and RI.
Considering,in turn, every word in the training data as a targetword, the method induces the representations bytraining a simplified neural network to predict thenearby context words of each target word (skip-gram architecture), or alternatively the target wordbased on all words in its immediate context (BoWarchitecture).
The vector space representation issubsequently extracted from the learned weightswithin the neural network.
One of the main prac-tical advantages of the word2vec method lies inits scalability, allowing quick training on largeamounts of text, setting it apart from the majorityof other methods of distributional semantics.
Ad-ditionally, the word2vec method has been shownto produce representations that surpass in qualitytraditional methods such as Latent Semantic Anal-ysis, especially on tasks measuring the preserva-tion of important linguistic regularities (Mikolovet al., 2013b).4.2 Computing care episode similarityAfter having computed a WSM, the next step isto build episode vectors to use for the actual re-trieval task.
This is done by first normalizing theword vectors and multiplying them with a word?sTF*IDF weight.
An episode vector is then ob-tained by summing the word vectors of all itswords and dividing the result by the total num-ber of words in the episode.
Similarity betweenepisodes is determined by computing the cosinesimilarity between their vectors.4.3 BaselinesTwo baselines were used in this study.
The firstone is random retrieval of care episodes, whichcan be expected to give very low scores and servesmerely as a sanity check.
The second one isApache Lucene (Cutting, 1999), a state-of-the-artsearch engine based on look-up of similar docu-ments through a reverse index and relevance rank-ing based on a TF*IDF-weighted vector spacemodel.
Care episodes were indexed using Lucene.Similar to the other models/methods, all of the freetext in the query episode, excluding the dischargesummary, served as the query string provided toLucene.
Being a state-of-the-art IR system, thescores achieved by Lucene in these experimentsshould indicate the difficulty of the task.5 ExperimentsIn these experiments we strove to have a setupthat was as comparable as possible for all modelsand systems, both in terms of text pre-processingand in terms of the target model dimensionalitywhen inducing the vector space models.
The clin-120ical notes are split into sentences, tokenized, andlemmatized using a Constraint-Grammar basedmorphological analyzer and tagger extended withclinical vocabulary (Karlsson, 1995).
After stopwords were removed1, the total training corpuscontained 39 million words (minus the queryepisodes), while the evaluation subset contained18.5 million words.
The vocabulary consisted of0.6 million unique terms.
Twenty care episodeswere randomly selected to serve as the queryepisodes during testing, with the requirement thateach had different ICD-10 codes and consisted of aminimum of six clinical notes.
The average num-ber of words per query episode is 830.RI-based and word2vec models have a prede-fined dimensionality of 800.
For RI-based mod-els, 4 non-zeros were used in the index vectors.For the RI-Word model, a narrow context win-dow was employed (5 left + 5 right), weightingindex vectors according to their distance to the tar-get word (weighti= 21?distit).
In addition, theindex vectors were shifted once left or right de-pending on what side of the target word they werelocated, similar to direction vectors as describedin (Sahlgren et al., 2008) These parameters for RIwere chosen based on previous work on semantictextual similarity (Moen et al., 2013).
Also a muchlarger window of 20+20 was tested, but withoutnoteworthy improvements.
The word2vec modelis trained with the BoW architecture and otherwisedefault parameters.
In addition to Apache Lucene(version 4.2.0)2, the word2vec tool3was used totrain the word2vec model, and the RI-based meth-ods utilized the JavaSDM package4.
Scores werecalculated using the trec eval tool5.5.1 Experiment 1: ICD-10 code overlapIn this experiment retrieved episodes with a pri-mary ICD-10 code identical to that of the queryepisode were considered to be correct.
The num-ber of correct episodes varies between 49 and1654.
The total is 7721, and the average is386.
The high total is mainly due to three queryepisodes with ICD-10 codes that occur very fre-quently in the episode collection (896, 1590, and1http://www.nettiapina.fi/finnish-stopword-list/2http://archive.apache.org/dist/lucene/java/3https://code.google.com/p/word2vec/4http://www.nada.kth.se/?xmartin/java/5http://trec.nist.gov/trec_eval/IR model MAP P@10Lucene 0.1379 0.3000RI-Word 0.0911 0.2650RI-Doc 0.1015 0.3300RI-ICD 0.3261 0.5150RI-Index 0.1187 0.3200Word2vec 0.1768 0.3350Random 0.0154 0.0200Table 1: Mean average precision and precision at10 for retrieval of care episodes with the same pri-mary ICD-10 code as the query episode1654 times).
When conducting the experiment allcare episodes were retrieved for each of the 20query episodes.Performance was measured in terms of meanaverage precision (MAP) and precision amongthe top-10 results (P@10), averaged over all 20queries, as shown in in Table 1.
The best MAPscore is achieved by RI-ICD, almost twice that ofword2vec, which achieved the second best MAPscore, whereas RI-Word performed worst of all.All models score well above the random baseline,whereas RI-ICD outperforms Lucene by a largemargin.
P@10 scores follow the same ranking.The latter scores are more representative for mostuse cases where users will only inspect the top-nretrieval results.5.2 Experiment 2: Discharge summaryoverlapIn this experiment retrieved episodes with a dis-charge summary similar to that of the queryepisode were considered to be correct.
Using thedischarge summaries of the query episodes, thetop 100 care episodes with the most similar dis-charge summary were selected as the most simi-lar care episodes (disregarding the query episode).This was repeated for each of the methods ?
i.e.the five different semantic models and Lucene ?resulting in six different tests.
The top 100 wasused rather than a threshold on the similarity score,because otherwise six different thresholds wouldhave to be chosen.
This procedure thus resulted insix different test collections, each consisting of 20query episodes with their corresponding 100 mostsimilar collection episodes.Subsequently a 6-by-6 experimental design wasfollowed where each retrieval method was testedagainst each test set construction method.
At re-trieval time, for each query episode, the system re-trieves and ranks 1000 care episodes.
It can be ex-pected that when identical methods are used for re-121trieval and test set construction, the resulting biasgives rise to relatively high scores.
In contrast,averaging over the scores for all six constructionmethods is assumed to be a less biased indicatorof performance.Table 2 shows the number of correctly retrievedepisodes by the different models, with the maxi-mum being 2000 (20 queries times 100 most sim-ilar episodes).
This gives an indication of the re-call among a 1000 retrieved episodes per query,but without caring about precision or ranking.
Ingeneral, the numbers are relatively good when thesame model is used for both retrieval and construc-tion of the test set (cf.
values on the diagonal), al-though in a couple of cases (e.g.
with word2vec)results are better with different models.
The RI-ICD model performs best when used for both re-trieval and test construction.
Looking at the av-erages, which presumably are less biased indica-tors, RI-ICD and word2vec seem to have compa-rable performance, with both of them outperform-ing Lucene.
Other models are less successful, al-though still much better than the random baseline.The MAP scores in Table 3 show similar re-sults, although here RI-ICD yields the best aver-age score.
Both models RI-ICD and word2vecoutperform Lucene.
Again the RI-ICD model per-forms exceptionally well when used for both re-trieval and test construction.Finally Table 4 presents precision for top-10 re-trieved care episodes.
Here RI-Doc yields the bestaverage scores, while RI-ICD and word2vec bothperform slightly worse.6 DiscussionThe goal of the experiments was primarily todetermine which distributional semantic modelswork best for care episode retrieval.
The exper-imental results show that several models outper-form Lucene at the care episode retrieval task.This suggests that models of higher order seman-tics contribute positively to calculating documentsimilarities in the clinical domain, compared withstraight forward boolean word matching (cf.
RI-Index and Lucene).The relatively good performance of the RI-ICDmodel, particularly in Experiment 1, suggests thatexploiting structured or encoded information inbuilding semantic models for clinical NLP is apromising direction that calls for further investi-gation.
This approach concurs with the argumentsin favor of reuse of existing information sourcesin Friedman et al.
(2013).
On the one hand, itmay not be surprising that the RI-ICD model isperforming well on Experiment 1, given how it in-duces semantic relations between words occurringin episodes with the same ICD-10 code.
On theother hand, being able to accurately retrieve careepisodes with similar ICD-10 codes evidently haspractical value from a clinical perspective.The different ranking of models in experiments1 versus 2 confirms that there is a difference be-tween the two indicators of episode similarity,i.e.
similarity in terms of their ICD-10 codesversus similarity with regard to their dischargesummaries.
In our data a single care episodecan potentially span across several hospital wards.A better correlation between the similarity mea-sures is to be expected when narrowing the def-inition of a care episode to only a single ward.Also, taking into consideration all ICD-10 codesfor care episodes ?
not only the primary one ?could potentially improve discrimination amongcare episodes.
This could be useful in two ways:(1) to create more precise test sets of the type usedin Experiment 1; (2) to extend RI-ICD modelswith index vectors also for the secondary ICD-10codes.Input to the models for training was limited tothe free text in the clinical notes, with the ex-ception of the use of ICD-10 codes in the RI-ICD model.
Other sources of information could,and probably should, be utilized in a practicalcare episode retrieval system applied in a hospi-tal, such as the structured and coded informationcommonly found in EHR systems.
Another po-tential information source is the internal structureof the care episodes, as episodes containing sim-ilar notes in the same sequential order are intu-itively more likely to be similar.
We tried comput-ing exhaustive pairwise similarities between theindividual notes from two episodes and then tak-ing the average of these as a similarity measurefor the episodes.
However, this did not improveperformance on any measure.
An alternative ap-proach may be to apply sequence alignment algo-rithms, as commonly used in bioinformatics (Gus-field, 1997), in order to detect if both episodescontain similar notes in the same temporal order.We leave this to future work.122IR model \ Test set Lucene RI-Word RI-Doc RI-ICD RI-Index Word2vec Average RankLucene 889 700 670 687 484 920 725 2RI-Word 643 800 586 600 384 849 644 5RI-Doc 665 630 859 697 436 795 680 4RI-ICD 635 459 659 1191 490 813 707 3RI-Index 690 491 607 654 576 758 629 6Word2vec 789 703 702 870 516 1113 782 1Random 74 83 86 67 84 85 79 7Table 2: Number of correctly retrieved episodes (max 2000) for different IR models (rows) when usingdifferent models for measuring discharge summary similarity (columns)IR model \ Test set Lucene RI-Word RI-Doc RI-ICD RI-Index Word2vec Average RankLucene 0.0856 0.0357 0.0405 0.0578 0.0269 0.0833 0.0550 3RI-Word 0.0392 0.0492 0.0312 0.0412 0.0151 0.0735 0.0416 6RI-Doc 0.0493 0.0302 0.0677 0.0610 0.0220 0.0698 0.0500 4RI-ICD 0.0497 0.0202 0.0416 0.1704 0.0261 0.0712 0.0632 1RI-Index 0.0655 0.0230 0.0401 0.0504 0.0399 0.0652 0.0473 5Word2vec 0.0667 0.0357 0.0404 0.0818 0.0293 0.1193 0.0622 2Random 0.0003 0.0003 0.0005 0.0002 0.0003 0.0004 0.0003 7Table 3: Mean average precision for different IR models (rows) when using different models for measur-ing discharge summary similarity (columns)IR model \ Test set Lucene RI-Word RI-Doc RI-ICD RI-Index Word2vec Average RankLucene 0.2450 0.1350 0.1200 0.1650 0.0950 0.1900 0.1583 5RI-Word 0.1350 0.1500 0.1000 0.1350 0.0600 0.2100 0.1316 6RI-Doc 0.2000 0.1250 0.2050 0.2200 0.0900 0.2400 0.1800 1RI-ICD 0.1700 0.0650 0.1350 0.3400 0.0950 0.2050 0.1683 2RI-Index 0.2000 0.1250 0.1550 0.1250 0.1700 0.2050 0.1633 3Word2vec 0.1800 0.1200 0.1150 0.2100 0.0850 0.2650 0.1625 4Random 0.0000 0.0000 0.0050 0.0000 0.0000 0.0000 0.0008 7Table 4: Precision at top-10 retrieved episodes for different IR models (rows) when using differentmodels for measuring discharge summary similarity (columns)7 Conclusion and future workIn this paper we proposed the task of care episoderetrieval as a way of evaluating several distribu-tional semantic models in their performance at IR.As manually constructing a proper test set of clas-sified care episodes is costly, we experimentedwith building test sets by exploiting either ICD-10code overlap or semantic similarity of dischargesummaries.
A novel method for generating se-mantic models utilizing the ICD-10 codes of careepisodes in the training corpus was presented (RI-ICD).
The models, as well as the Lucene searchengine, were applied to the care episode retrievaltask and their performance was evaluated againstthe test sets using different evaluation measures.The results suggest that the RI-ICD model is bet-ter suited to IR tasks in the clinical domain com-pared with models trained on local distributions ofwords, or those relying on direct word matching.The word2vec model performed relatively welland outperformed Lucene in both experiments.In the results reported here, the internal se-quence of clinical notes is ignored.
Future workshould focus on exploring the temporal (sub-) se-quence similarities between care episode pairs fordoing care episode retrieval.
Further work shouldalso focus on expanding on the RI-ICD methodby exploiting other types of structured and/or en-coded information related to clinical notes fortraining semantic models tailored for NLP in theclinical domain.AcknowledgmentsThis study was partly supported by the ResearchCouncil of Norway through the EviCare project(NFR project no.
193022), the Turku UniversityHospital (EVO 2014), and the Academy of Fin-land (project no.
140323).
The study is a partof the research projects of the Ikitik consortium(http://www.ikitik.fi).
We would liketo thank Juho Heimonen for assisting us in pre-processing the data and the reviewers for theirhelpful comments.123ReferencesHelen Allvin, Elin Carlsson, Hercules Dalianis, Ri-itta Danielsson-Ojala, Vidas Daudaravi?cius, Mar-tin Hassel, Dimitrios Kokkinakis, Helj?a Lundgren-Laine, Gunnar Nilsson, ?ystein Nytr?, et al.
2010.Characteristics and analysis of finnish and swedishclinical intensive care nursing narratives.
In Pro-ceedings of the NAACL HLT 2010 Second LouhiWorkshop on Text and Data Mining of Health Docu-ments, pages 53?60.
Association for ComputationalLinguistics.Doug Cutting.
1999.
Apache Lucene open sourcepackage.Carol Friedman, Pauline Kra, and Andrey Rzhetsky.2002.
Two biomedical sublanguages: a descriptionbased on the theories of zellig harris.
Journal ofbiomedical informatics, 35(4):222?235.Carol Friedman, Thomas C Rindflesch, and Mil-ton Corn.
2013.
Natural language process-ing: State of the art and prospects for significantprogress, a workshop sponsored by the national li-brary of medicine.
Journal of biomedical informat-ics, 46(5):765?773.Dan Gusfield.
1997.
Algorithms on strings, trees andsequences: computer science and computational bi-ology.
Cambridge University Press.Kristiina H?ayrinen, Kaija Saranto, and PirkkoNyk?anen.
2008.
Definition, structure, content, useand impacts of electronic health records: a reviewof the research literature.
International journal ofmedical informatics, 77(5):291?304.Aron Henriksson, Hans Moen, Maria Skeppstedt, Vi-das Daudaravi, Martin Duneld, et al.
2014.
Syn-onym extraction and abbreviation expansion withensembles of semantic spaces.
Journal of biomed-ical semantics, 5(1):6.Pentti Kanerva, Jan Kristofersson, and Anders Holst.2000.
Random indexing of text samples for latentsemantic analysis.
In Proceedings of 22nd AnnualConference of the Cognitive Science Society, page1036.Fred Karlsson.
1995.
Constraint grammar: alanguage-independent system for parsing unre-stricted text.
Mouton de Gruyter, Berlin and NewYork.Bevan Koopman, Guido Zuccon, Peter Bruza, Lauri-anne Sitbon, and Michael Lawley.
2012.
An evalu-ation of corpus-driven measures of medical conceptsimilarity for information retrieval.
In Proceedingsof the 21st ACM international conference on Infor-mation and knowledge management, pages 2439?2442.
ACM.Mario Lenz, Andr?e H?ubner, and Mirjam Kunze.
1998.Textual cbr.
In Case-based reasoning technology,pages 115?137.
Springer.Christopher D Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to informationretrieval, volume 1.
Cambridge University PressCambridge.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-rado, and Jeff Dean.
2013a.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems 26, pages 3111?3119.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013b.
Linguistic regularities in continuous spaceword representations.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 746?751.
Associa-tion for Computational Linguistics, June.Hans Moen, Erwin Marsi, and Bj?orn Gamb?ack.
2013.Towards dynamic word sense discrimination withrandom indexing.
ACL 2013, page 83.Ted Pedersen, Serguei VS Pakhomov, Siddharth Pat-wardhan, and Christopher G Chute.
2007.
Mea-sures of semantic similarity and relatedness in thebiomedical domain.
Journal of biomedical infor-matics, 40(3):288?299.Alan L Rector.
1999.
Clinical terminology: why isit so hard?
Methods of information in medicine,38(4/5):239?252.Magnus Sahlgren, Anders Holst, and Pentti Kanerva.2008.
Permutations as a means to encode order inword space.
In Proceedings of the Annual Meetingof the Cognitive Science Society.Hagit Shatkay.
2005.
Hairpins in bookstacks: infor-mation retrieval from biomedical text.
Briefings inBioinformatics, 6(3):222?238.Johanna I Westbrook, Enrico W Coiera, and A So-phie Gosling.
2005.
Do online information retrievalsystems help experienced clinicians answer clinicalquestions?
Journal of the American Medical Infor-matics Association, 12(3):315?321.World Health Organization and others.
2013.
Interna-tional classification of diseases (icd).Lei Yang, Qiaozhu Mei, Kai Zheng, and David AHanauer.
2011.
Query log analysis of an electronichealth record search engine.
In AMIA Annual Sym-posium Proceedings, volume 2011, page 915.
Amer-ican Medical Informatics Association.124
