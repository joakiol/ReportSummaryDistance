BALLGAME: A Corpus for Computational SemanticsEzra Keshet, Terry Szymanski, and Stephen TyndallUniversity of MichiganE-mail: {ekeshet,tdszyman,styndall}@umich.eduAbstractIn this paper, we describe the Baseball Announcers?
Language Linked with General Annotation ofMeaningful Events (BALLGAME) project ?
a text corpus for research in computional semantics.We collected pitch-by-pitch event data for a sample of baseball games and used this data to build anannotated corpus composed of transcripts of radio broadcasts of these games.
Our annotation linkstext from the broadcast to events in a formal representation of the semantics of the baseball game.
Wedescribe our corpus model, the annotation tool used to create the corpus, and conclude by discussingapplications of this corpus in semantics research and natural language processing.1 IntroductionThe use of large annotated corpora and treebanks has led to many fruitful research programs in compu-tational linguistics.
At the time of this writing, Marcus et al (1993), which introduces the University ofPennsylvania Treebank,1 has been cited by over 3000 subsequent papers.2 Such treebanks are invaluablefor the training and testing of large-scale syntactic parsers and numerous other applications in the fieldof Computational Syntax.Unfortunately for the field of Computational Semantics, there are few corresponding annotated cor-pora or treebanks representing the formalized meaning of natural language sentences, mainly becausethere is very little agreement on what such a representation of meaning would look like for arbitrarytext.
To overcome this obstacle, several recent studies have turned to the arena of sports, pairing naturallanguage with game statistics in several domains, including RoboCup soccer (Liang et al, 2009; Chenet al, 2010), soccer (Theune and Klabbers, 1998; Saggion et al, 2003), American football (Barzilay andLapata, 2005; Liang et al, 2009), and baseball (Fleischman, 2007).We have adapted this approach in the creation of a semantics-oriented corpus, using the domain ofmajor-league baseball.
The information state of a baseball game can be represented with a small numberof variables, such as who is on which base, who is batting, who is playing each position, and the currentscore and inning.
There is even a standard way of representing updates to this information state.3 Thismakes baseball a logical stepping stone to a fuller representation of the world.
We also chose baseballfor this corpus because of the volume of data available, in the form of both natural language descriptionsof events and language-independent game statistics.
Most of professional baseball?s thousands of gamesper year have at least two television broadcasts (home and away) and at least two radio broadcasts, oftenin multiple languages.
The scorecard statistics for each game are also kept and made available on theinternet, along with complete ordered lists of in-game events.
These resources, coupled with a high-coverage syntactic parser, allow one to link natural language utterances with representations of theirsyntax and semantics.1http://www.cis.upenn.edu/?treebank/2http://scholar.google.com/scholar?cites=71245591114603413533See example scorecards at http://swingleydev.com/baseball/tutorial.php.3402 Corpus DesignThe basic design of the BALLGAME corpus is a mapping between spans of text and events in a baseballgame.
The raw text comes from the transcribed speech of announcers broadcasting the radio play-by-play of a professional baseball game.
This text is chunked into spans, and these spans are then labeledaccording to the following scheme:?
Event is the label given to a span that describes an event in our representation of the game for thefirst time.
(Examples of events are simultaneous descriptions of pitches, plays, and stolen bases.)?
Recap is the label given to a span that correlates with prior events in the game.
(Examples of recapsare when the announcer states the current score or strike count, or summarizes the current batter?sprevious at-bats.)?
Banter is the label given to a span that does not relate to an event in the game.
The majority ofspans are labeled as banter.
(Examples of banters are ?color?
commentary, any discussion of theday?s news, other baseball games, advertisements, etc.
)The term ?span?
has no linguistic significance, although spans often turn out to be sentences or clauses.Each span from the text that is labeled as an event is linked to one or more events in the model of thegame as shown in Figure 1.
Not every event is linked to a span of text, since some events go unmentionedby the announcers.Figure 1: Illustration of a portion of the corpus: event spans of the text (on the left) are associated withevents from a standardized description of the ballgame (on the right).We model each game as a time-ordered sequence of baseball events, designed so that the state of thegame at any given point, while not explicitly represented, can be computed given the events from thestart of the game up to that point.
We use a simple event model inspired by the comprehensive scoringsystem developed by Retrosheet,4 but modified to match our needs and data resources.
For example,most baseball scoring systems are at-bat-based, but this system is too coarse-grained for our purposes.Therefore, we use a system in which the fundamental event type is the pitch.
Every baseball action fromthe start of the pitcher?s motion until the end of the play (a hit or an out) is categorized as a PITCH event.Several other event types exist to accommodate other plays (e.g.
balks, pick-offs), non-play actions (e.g.coaching visits to the mound, rain delays), and procedural activities (e.g.
ejections, player substitutions).In addition to a category, each event has multiple attribute values.
The possible attributes depend onthe category.
A PITCH event, for example, has attributes describing the type, speed, and location of thepitch as well as whether it results in a ball, strike, play, etc.
If the result is a play, then there are additional4http://www.retrosheet.org341attributes describing the fielders involved in the defensive play.
On the other hand, a PICKOFF event hasdifferent attributes, describing which base the ball was thrown to, whether it resulted in an out, etc.dealsCC curveballa lowadvmodnsubj dobj det<PLAYER pos='pitcher' team='home' firstname='CC' ...><PITCH type='curve' zone='12' result='ball' ...>Events:...Figure 2: Example of a dependency parsed transcript line and corresponding events.In the future, we plan to add syntactic parse information for each span such as that generated usingthe Stanford Parser (De Marneffe et al, 2006).
Using an explicit syntactic representation, like the oneillustrated in figure 2, it will be possible to label more detailed correlations between the text and themeaning.
Even without explicit annotation, statistical learning methods could be used to infer, e.g., thatthe word ?curveball?
in the sentence in figure 2 correlates with the semantic attribute type=?curve?,or that the word ?CC?
correlates with a specific PLAYER entity.
While the annotations in the corpusexist only at the sentence or phrase level, this type of further processing could push the annotation downto the word level, facilitating the study of lexical semantics and semantic transformations of syntacticstructures.3 Corpus CreationStudent transcribers use a custom-created transcription and annotation tool, illustrated in Figure 3, to adddata to the corpus.
They listen to and transcribe the radio broadcast, while simultaneously chunking thetext into spans as described above.
Each span is labeled banter, event, or recap, and, if the span describesan event, the student selects the corresponding event(s) from the event column.Annotators have access to a style guide to encourage consistency.
This guide sets out two main prin-ciples: first, the transcript of an inning, taken as a whole, should be read like a well-edited, consistentlyformatted document; and second, all and only the events explicitly mentioned by the radio announcersshould be linked to events in the game model.Although spans are displayed as separate lines in the transcription tool, in order to maintain thisfirst style principle, we ask the students to imagine that all spans of the transcript are pasted together insequence to form a normal transcript of the game.
Thus, they are asked not to put ellipses or dashes atthe end of spans nor to capitalize the beginnings of spans that do not begin sentences.
Also included inthis principle is a standardized formatting style for baseball statistics, such as strike counts, scores, andbatting averages, so that, for instance, ?the count is two and oh?
is transcribed ?the count is 2-0?.The second principle set out in the annotation style guide is meant to ensure that the events linked toa particular utterance are as close as possible to the ?meaning?
of that utterance.
Integral to this processis consistently distinguishing the categories of event, recap and banter.
Since recap and banter spans donot relate to events in the model, it is important to keep them separate from the event spans to get themost accurate data.
Even given the descriptions of these categories from section 2, ambiguous cases stilldo arise on occasion.
For instance, one common difficulty is distinguishing event from recap when anannouncer discusses a play immediately after it happens.
In such cases, in keeping with our annotationprinciple, we use the rule of thumb that only new information is annotated as event; old information isrecap.
We also adopt the rule that only game events that are explicitly stated by the announcer shouldbe linked to spans; for example, if the announcer merely states the name of the batter (e.g.
?Cust takes afirst-pitch strike?)
in the process of describing the first pitch of his at-bat, then this should not referencethe ATBAT event that indicates the arrival of a new batter at the plate.
On the other hand, an explicitmention (e.g.
?Here?s Cust.?)
should.In the final steps of the annotation process, each transcript is reviewed and corrected by a secondannotator to reduce errors and further promote consistency across annotators.342Figure 3: Screen shot of online annotation tool.4 Potential ApplicationsSince this corpus links natural language utterances with complete semantic representations which fullydescribe the state of the baseball game, it has a number of applications for research in computationalsemantics.
While the domain is limited, and the ?meaning?
of a baseball game does not approach thecomplexity of the possible ?meanings?
in the real world, nevertheless this corpus should be a usefulresource both for developing NLP tools and for studying theories of language and meaning.One application domain for this type of data is natural language generation and understanding, andmuch prior work connecting sports commentaries to statistics or events falls into this domain.
Onerelated generation task is to generate textual summaries of complete games: Theune and Klabbers (1998)generated spoken Dutch summaries of soccer matches, and Barzilay and Lapata (2005) investigate therelationship between textual NFL recaps and the box scores of the games.
More similar to our projectis the RoboCup announcer system of Chen et al (2010), which produces play-by-play commentary (inEnglish and Korean) of simulated RoboCup soccer matches.
Our corpus could certainly be used to trainsystems that predict the event structure given the text of the commentary, or vice-versa.In the domain of information extraction, our corpus could be used to train systems to infer repre-sentations of meaning from texts.
In many domains, the same word or phrase can appear in a varietyof different contexts with different ramifications.
For example, the phrase ?home run?
in a baseballcommentary may mean that a home run has just occurred, or it may refer to a home run in a previousgame, or a player?s home-run totals for the season, etc.. Fleischman (2007), using a collection of video343broadcasts of baseball games, combines natural language processing with artificial vision technology toresolve when events like home runs actually occur, in order to facilitate retrieval of relevant video clips.Using our corpus, one could design a system to perform the same task based purely on the textual data,perhaps to extend this same task to radio broadcasts as well as television broadcasts.
Given the corpuslabels of event, recap, and banter, a classifier could be built to identify only the event regions, and anextraction system could identify the relevant semantic features (e.g.
player names, types of events).While generation and understanding are tasks most applicable to this corpus, we hope researcherswill find additional innovative uses of the corpus.
For example, given that we plan to incorporate a num-ber of baseball games with commentary both in English and Spanish, there is a potential connection tomachine translation, particularly approaches that utilize comparable (rather than parallel) corpora.
In ourcorpus, the comparable sections (i.e.
the event-labeled regions) are explicitly aligned with one another,which is not usually the case in comparable corpora.
Also, the corpus could prove useful for research onformal semantics, despite the fact the meaning representation is not particularly rich compared to modernsemantic theory, and the jargon and speech styles are very specific to the domain of baseball sportscasts.5 ConclusionWe have presented an overview of the BALLGAME annotated corpus for research in computationalsemantics, as well as a description of our procedure for annotation and the specialized annotation toolwe developed for this purpose.
To date, the corpus contains sixteen three- to four-hour-long majorleague baseball radio broadcasts, transcribed and annotated as described above.
This represents 237,100transcribed words in 13,382 spans (6,511 banter; 3,994 event; 2,877 recap).
Work is ongoing, and thegoal is to complete fifty games by the end of the year.
We believe this corpus, by pairing natural languagetext with formalized representations of meaning, will prove useful for many types of NLP research.ReferencesBarzilay, R. and M. Lapata (2005).
Collective content selection for concept-to-text generation.
In Pro-ceedings of HLT/EMNLP, pp.
331?338.Chen, D., J. Kim, and R. Mooney (2010).
Training a multilingual sportscaster: Using perceptual contextto learn language.
Journal of Artificial Intelligence Research 37(1), 397?436.De Marneffe, M., B. MacCartney, and C. Manning (2006).
Generating typed dependency parses fromphrase structure parses.
In LREC 2006.Fleischman, M. (2007).
Situated models of meaning for sports video retrieval.
In NAACL-HLT 2007, pp.37?40.Liang, P., M. Jordan, and D. Klein (2009).
Learning semantic correspondences with less supervision.
InProceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processing of the AFNLP: Volume 1, pp.
91?99.Marcus, M., B. Santorini, and M. Marcinkiewicz (1993).
Building a large annotated corpus of English:The Penn Treebank.
Computational linguistics 19(2), 313?330.Saggion, H., J. Kuper, H. Cunningham, T. Declerck, P. Wittenburg, M. Puts, E. Hoenkamp, F. de Jong,and Y. Wilks (2003).
Event-coreference across multiple, multi-lingual sources in the Mumis project.In Proceedings of the tenth conference on European chapter of the Association for ComputationalLinguistics: Volume 2, pp.
239?242.Theune, M. and E. Klabbers (1998).
GoalGetter: Generation of spoken soccer reports.
In Proceedingsof the Ninth International Workshop on Natural Language Generation, pp.
292?295.344
