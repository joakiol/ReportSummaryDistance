Automatic construction of parallel English-Chinese corpus forcross-language information retrievalJ i ang  Chen and  J ian -Yun  N ieD~partement d ' In format ique et Recherche Op~rationnel leUniversit~ de MontrealC.P.
6128, succursale CENTRE-V ILLEMontreal  (Quebec), Canada  H3C 3J7{chen, nie} @iro.
umontreal, caAbst rac tA major obstacle to the construction ofa probabilis-tic translation model is the lack of large parallel cor-pora.
In this paper we first describe a parallel textmining system that finds parallel texts automaticallyon the Web.
The generated Chinese-English paral-lel corpus is used to train a probabilistic translationmodel which translates queries for Chinese-Englishcross-language information retrieval (CLIR).
We willdiscuss ome problems in translation model trainingand show the preliminary CUR results.1 In t roduct ionParallel texts have been used in a number of studiesin computational linguistics.
Brown et al (1993)defined a series of probabilistic translation modelsfor MT purposes.
While people may question theeffectiveness of using these models for a full-blownMT system, the models are certainly valuable for de-veloping translation assistance tools.
For example,we can use such a translation model to help com-plete target ext being drafted by a human transla-tor (Langlais et al, 2000).Another utilization is in cross-language informa-tion retrieval (CLIR) where queries have to be trans-lated from one language to another language inwhich the documents are written.
In CLIR, the qual-ity requirement for translation is relatively low.
Forexample, the syntactic aspect is irrelevant.
Even ifthe translated word is not a true translation but isstrongly related to the original query, it is still help-ful.
Therefore, CLIR is a suitable application forsuch a translation model.However, a major obstacle to this approach is thelack of parallel corpora for model training.
Onlya few such corpora exist, including the HansardEnglish-French corpus and the HKUST English-Chinese corpus (Wu, 1994).
In this paper, we willdescribe a method which automatically searches forparallel texts on the Web.
We will discuss the textmining algorithm we adopted, some issues in trans-lation model training using the generated parallelcorpus, and finally the translation model's perfor-mance in CLIR.2 Para l le l  Text  M in ing  A lgor i thmThe PTMiner system is an intelligent Web agentthat is designed to search for large amounts of paral-lel text on the Web.
The mining algorithm is largelylanguage independent.
It can thus be adapted toother language pairs with only minor modifications.Taking advantage ofWeb search engines as muchas possible, PTMiner implements he following steps(illustrated in Fig.
1):1 Search for candidate sites - Using existing Websearch engines, search for the candidate sitesthat may contain parallel pages;2 File name fetching - For each candidate site,fetch the URLs of Web pages that are indexedby the search engines;3 Host crawling - Starting from the URLs col-lected in the previous tep, search through eachcandidate site separately for more URLs;4 Pair scan - From the obtained URLs of eachsite, scan for possible parallel pairs;5 Download and verifying - Download the parallelpages, determine file size, language, and charac-ter set of each page, and filter out non-parallelpairs.2.1 Search for candidate SitesWe take advantage of the huge number of Web sitesindexed by existing search engines in determiningcandidate sites.
This is done by submitting someparticular equests to the search engines.
The re-quests are determined according to the following ob-servations.
In the sites where parallel text exists,there are normally some pages in one language con-taining links to the parallel version in the other lan-guage.
These are usually indicated by those links'anchor texts 1.
For example, on some English pagethere may be a link to its Chinese version withthe anchor text "Chinese Version" or "in Chinese".1An anchor text  is a piece of text on a Web page which,when clicked on, will take you to another linked page.
Tobe helpful, it usual ly  contains the key information about thel inked page.21Figure 1: The workflow of the mining process.The same phenomenon can be observed on Chinesepages.
Chances are that a site with parallel textswill contain such links in some of its documents.This fact is used as the criterion in searching forcandidate sites.Therefore, to determine possible sites for English-Chinese parallel texts, we can request an Englishdocument containing the following anchor:anchor : "engl ish version H \["in english", ...\].Similar requests are sent for Chinese documents.From the two sets of pages obtained by the abovequeries we extract wo sets of Web sites.
The unionof these two sets constitutes then the candidate sites.That  is to say, a site is a candidate site when itis found to have either an English page linking toits Chinese version or a Chinese page linking to itsEnglish version.2.2 File Name FetchingWe now assume that a pair of parallel texts exists onthe same site.
To search for parallel pairs on a site,PTMiner first has to obtain all (or at least part of)the HTML file names on the site.
From these namespairs are scanned.
It is possible to use a Web crawlerto explore the candidate sites completely.
However,we can take advantage of the search engines again toaccelerate the process.
As the first step, we submitthe following query to the search engines:host : hostnameto fetch the Web pages that they indexed from thissite.
If we only require a small amount of paralleltexts, this result may be sufficient.
For our purpose,however, we need to explore the sites more thor-oughly using a host crawler.
Therefore, we continueour search for files with a host crawler which usesthe documents found by the search engines as thestarting point.2.3 Host CrawlingA host crawler is slightly different from a Webcrawler.
Web crawlers go through innumerablepages and hosts on the Web.
A host crawler is aWeb crawler that crawls through documents on agiven host only.
A breadth-first crawling algorithmis applied in PTMiner as host crawler.
The principleis that when a link to an unexplored ocument onthe same site is found in a document, it is added toa list that will be explored later.
In this way, mostfile names from the candidate sites are obtained.2.4 Pair ScanAfter collecting file names for each candidate site,the next task is to determine the parallel pairs.Again, we try to use some heuristic rules to guesswhich files may be parallel texts before downloadingthem.
The rules are based on external features ofthe documents.
By external feature, we mean thosefeatures which may be known without analyzing thecontents of the file, such as its URL, size, and date.This is in contrast with the internal features, such aslanguage, character set, and HTML structure, whichcannot be known until we have downloaded the pageand analyzed its contents.The heuristic criterion comes from the followingobservation: We observe that parallel text pairs usu-ally have similar name patterns.
The difference be-tween the names of two parailel pages usually liesin a segment which indicates the language.
For ex-ample, "file-ch.html" (in Chinese) vs. "file-en.html"(in English).
The difference may also appear in thepath, such as ".../chinese/.../fi le.html" vs. ".../en-glish/.../f i le.html'.
The name patterns describedabove are commonly used by webmasters to help or-ganize their sites.
Hence, we can suppose that apair of pages with this kind of pattern are probablyparallel texts.22First, we establish four lists for English pre-fixes, English suffixes, Chinese prefixes and Chi-nese suffixes.
For example: Engl ish P re f ix  ={e, en, e_, en_, e - ,  en - ,  ...}.
For each file in one lan-guage, if a segment in its name corresponds to oneof the language affixes, several new names are gener-ated by changing the segment to the possible corre-sponding affixes of the other language.
If a generatedname corresponds to an existing file, then the file isconsidered as a candidate parallel document of theoriginal file.2.5 FilteringNext, we further examine the contents of the pairedfiles to determine if they are really parallel accordingto various external and internal features.
This mayfurther improve the pairing precision.
The followingmethods have been implemented in our system.2.5.1 Text LengthParallel files often have similar file lengths.
One sim-ple way to filter out incorrect pairs is to comparethe lengths of the two files.
The only problem is toset a reasonable threshold that will not discard toomany good pairs, i.e.
balance recall and precision.The usual difference ratio depends on the languagepairs we are dealing with.
For example, Chinese-English parallel texts usually have a larger differ-ence ratio than English-French parallel texts.
Thefiltering threshold had to be determined empirically,from the actual observations.
For Chinese-English,a difference up to 50% is tolerated.2.5.2 Language and  Character SetIt is also obvious that the two files of a pair haveto be in the two languages of interest.
By auto-matically identifying language and character set, wecan filter out the pairs that do not satisfy this basiccriterion.
Some Web pages explicitly indicate thelanguage and the character set.
More often suchinformation is omitted by authors.
We need somelanguage identification tool for this task.SILC is a language and encoding identificationsystem developed by the RALI laboratory at theUniversity of Montreal.
It employs a probabilisticmodel estimated on tri-grams.
Using these mod-els, the system is able to determine the most proba-ble language and encoding of a text (Isabelle et al,1997).2.5.3 HTML Structure and AlignmentIn the STRAND system (Resnik, 1998), the candi-date pairs are evaluated by aligning them accordingto their HTML structures and computing confidencevalues.
Pairs are assumed to be wrong if they havetoo many mismatching markups or low confidencevalues.Comparing HTML structures seems to be a soundway to evaluate candidate pairs since parallel pairsusually have similar HTML structures.
However, wealso noticed that parallel texts may have quite dif-ferent HTML structures.
One of the reasons is thatthe two files may be created using two HTML ed-itors.
For example, one may be used for Englishand another for Chinese, depending on the languagehandling capability of the editors.
Therefore, cau-tion is required when measuring structure differencenumerically.Parallel text alignment is still an experimentalarea.
Measuring the confidence values of an align-ment is even more complicated.
For example, thealignment algorithm we used in the training of thestatistical translation model produces acceptablealignment results but it does not provide a confi-dence value that we can "confidently" use as an eval-uation criterion.
So, for the moment his criterion isnot used in candidate pair evaluation.3 Generated  Corpus  and Trans la t ionMode l  Tra in ingIn this section, we describe the results of our paralleltext mining and translation model training.3.1 The CorpusUsing the above approach for Chinese-English, 185candidate sites were searched from the domain hk.We limited the mining domain to hk because HongKong is a bilingual English-Chinese city where highquality parallel Web sites exist.
Because of the smallnumber of candidate sites, the host crawler was usedto thoroughly explore each site.
The resulting cor-pus contains 14820 pairs of texts including 117.2MbChinese texts and 136.5Mb English texts.
The entiremining process lasted about a week.
Using lengthcomparison and language identification, we refinedthe precision of the corpus to about 90%.
The preci-sion is estimated by examining 367 randomly pickedpairs.3.2 Statistical Translation ModelMany approaches in computational linguistics try toextract ranslation knowledge from previous trans-lation examples.
Most work of this kind establishesprobabilistic models from parallel corpora.
Basedon one of the statistical models proposed by Brownet al (1993), the basic principle of our translationmodel is the following: given a corpus of aligned sen-tences, if two words often co-occur in the source andtarget sentences, there is a good likelihood that theyare translations of each other.
In the simplest case(model 1), the model earns the probability, p(tls), ofhaving a word t in the translation of a sentence con-taining a word s. For an input sentence, the modelthen calculates a sequence of words that are mostprobable to appear in its translation.
Using a sim-ilar statistical model, Wu (1995) extracted a large-scale English-Chinese l xicon from the HKUST cor-23<s id="00~"><HTML> <HEAD><META HTrP-EQUIV="Content-type"CONTENT="text/html; charset--iso-8859-1"><META HTI'P-EQUIV="Content-language"CONTENT="Western"></s><s id="0001"><TITLE>Journal of Primary Education 1996,VoI., No.
l&2, pp.
19-27 </TITLE></HEAD></s><s id="0002"><BODY BACKGROUND=".Jgif/pejbg.jpg"TEXT="#000(3(O" BGCOLOR="#ffffff"><CENTER></s><s id="0003"><HI>Journal of Primary Education </HI></s><s id="0004"><HR> <B>Volume 6, No l&2, pp.
19-27 (May,1996) </B> <HR></s><s id="0005"><H3>Principles for Redesigning TeacherEducation </H3> Alan TOM </CENTER></s><s id="0006"><P> <B> <I> Abstract </I> </B></s><s id="0000"><HTML> <HEAD><META H'ITP-EQUW="Content-type"CONTENT="text/html; charset=bigS"><META HTTP-EQUIV="Content-language"CONTENT="zh"><Is><s id="0001"><TITLE> Journal of Primary Education 1996,Vol., No.
l&2, Page 19-27 </TITLE></HEAD></s><s id="0002"><BODY BACKGROUND=".Jgif/pejbg.jpg"TEXT="#000000" BGCOLOR="#ffffff"> <AHREF="/erdpej/b2g__pej.phtml?URL=%2fen%2fpej%2f0601%2f0601019c.htm"><IMG SRC="/en/gif/kan.gif" ALT="~"BORDER=0 ALIGN=R IGHT> </A> <CENTER></s><s id="0003"><H2>~ ~ 11I ~ O.</H2></s><s id="0004"><HR> (~:~h-fv-c?.JLJl) ~,-\]'?~..</s><s id="0005">~ 19-27\]~ <I-1R></s>Figure 2: An alignment example using pure length-based method.pus which is built manually.
In our case, the prob-abilistic translation model will be used for CLIR.The requirement on our translation model may beless demanding: it is not absolutely necessary thata word t with high p(tls ) always be a true trans-lation of s. It is still useful if t is strongly relatedto s. For example, although "railway" is not a truetranslation of "train" (in French), it is highly usefulto include "railway" in the translation of a query on"train".
This is one of the reasons why we think aless controlled parallel corpus can be used to train atranslation model for CLIR.3.3 Parallel Text Al ignmentBefore the mined documents can be aligned into par-allel sentences, the raw texts have to undergo a se-ries of some preprocessing, which, to some extent, islanguage dependent.
For example, the major opera-tions on the Chinese-English corpus include encod-ing scheme transformation (for Chinese), sentencelevel segmentation, parallel text alignment, Chineseword segmentation (Nie et al, 1999) and Englishexpression extraction.The parallel Web pages we collected from vari-ous sites are not all of the same quality.
Some arehighly parallel and easy to align while others can bevery noisy.
Aligning English-Chinese parallel textsis already very difficult because of the great differ-ences in the syntactic structures and writing sys-tems of the two languages.
A number of alignmenttechniques have been proposed, varying from statis-tical methods (Brown et al, 1991; Gale and Church,1991) to lexical methods (Kay and RSscheisen, 1993;Chen, 1993).
The method we adopted is that ofSimard et al (1992).
Because it considers bothlength similarity and cognateness as alignment cri-teria, the method is more robust and better ableto deal with noise than pure length-based methods.Cognates are identical sequences of characters in cor-responding words in two languages.
They are com-monly found in English and French.
In the case ofEnglish-Chinese alignment, where there are no cog-nates shared by the two languages, only the HTMLmarkup in both texts are taken as cognates.
Be-cause the HTML structures of parallel pages are nor-mally similar, the markup was found to be helpfulfor alignment.To illustrate how markup can help with the align-ment, we align the same pair with both the purelength-based method of Gale & Church (Fig.
2),and the method of Simard et al (Fig.
3).
First ofall, we observe from the figures that the two texts are24<s id="0000"><HTML> <HEAD><META HTTP-EQUIV="Content-type"CONTENT="text/html; charset=iso-8859-1 "><META HTTP-EQUIV="Content-language"CONTENT="Westem"></s><s id="0001"><TITLE>Journal of Primary Education 1996,Vol., No.
l&2, pp.
19-27 </TITLE></HEAD></s><s id="0002"><BODY BACKGROUND=-".
Jgif/pejbg.jpg"TEXT="#000000" BGCOLOR="#ffffff"><CENTER></s><s id="0003"><H 1 >Journal of Primary Education </H 1 ><Is><s id="0004"><HR> <B>Volume 6,No l&2, pp.
19-27 (May,1996) </B> <HR></$><s id="0000"><HTML> <HEAD><META HTrP-EQUIV="Content-type"CONTENT="text/html; charset=big5"><META H'lTP-EQUIV="Content-language"CONTENT="zh"><Is><s id="0001">:<TITLE> Journal of Primary Education 1996,Vol., No.
l&2, Page 19-27 </TITLE></HEAD></s><s id="0002"><BODY BACKGROUND=-".
Jgiffpejbg.jpg"TEXT="#O00000" BGCOLOR="#fffffff> <AHREF="/ergpej/b2g_pej.phtml?URL=%2fen%2fpej %2f0601%2 f0601019c.htm"><IMG SRC="/erdgif/kan.gif" ALT="~k"BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~</s><s id="0003"><H2>~k ~ ~ ~\[1.</H2></s><s id="0004"><HR> (~t~-~?-#cJL.~) ,-~?~.</s><s id="0005">~ $ ~  19-27 \]~ <HR><\]s><s id="0005"> <s id="0006"><H3>Principles for Redesigning Teacher <H3>.~ k~4Vt ~'~ ~ ~J </H3> Alan TOMEducation </H3> Alan TOM </CENTER> </CENTER><Is> <Is><s id="0006"> <s id="0007"><P> <B> <I> Abstract </I> </B> <P> <I> <B> ~4\[- </B> </I> <P></s> </s>Figure 3: An alignment example considering cognates.divided into sentences.
The sentences are marked by<s id="xxxx"> and </s>.
Note that we determinesentences not only by periods, but also by means ofHTML markup.We further notice that it is difficult to align sen-tences 0002.
The sentence in the Chinese page ismuch longer than its counterpart in the English pagebecause some additional information (font) is added.The length-based method thus tends to take sen-tence 0002, 0003, and 0004 in the English page asthe translation of sentence 0002 in the Chinese page(Fig.
2), which is wrong.
This in turn provocatedthe three following incorrect alignments.
As we cansee in Fig.
3, the cognate method did not make thesame mistake because of the noise in sentence 0002.Despite their large length difference, the two 0002sentences are still aligned as a 1-1 pair, because thesentences in the following 4 alignments (0003 - 0003;0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) haverather similar HTML markups and are taken by theprogram to be the most likely alignments.Beside HTML markups, other criteria may alsobe incorporated.
For example, it would be helpfulto consider strong correspondence b tween certainEnglish and Chinese words, as in (Wu, 1994).
Wehope to implement such correspondences in our fu-ture research.3.4 Lex icon  Eva luat ionTo evaluate the precision of the English-Chinesetranslation model trained on the Web corpus, weexamined two sample lexicons of 200 words, one ineach direction.
The 200 words for each lexicon wererandomly selected from the training source.
We ex-amined the most probable translation for each word.The Chinese-English lexicon was found to have aprecision of 77%.
The English-Chinese l xicon hasa higher precision of 81.5%.
Part of the lexiconsare shown in Fig.
4, where t / f  indicates whether atranslation is true or false.These precisions seem to be reasonably high.They are quite comparable to that obtained by Wu(1994) using a manual Chinese-English parallel cor-pus.3.5 Effect  o f  S topwordsWe also found that stop-lists have significant effecton the translation model.
Stop-list is a set of themost frequent words that we remove from the train-2fiEnglish worda .n l .accessadaptationaddadoptagentagreeairlineamendment, applianceapplyattendanceauditor- ,averagebase_ont/ftfttttttttttftfTranslmion Probability Chinese word~'~- 0.201472 ~t l :~"  0.071705 "~"~f~.,~ 0.179633 JllL~0.317435~ 0.231637 ~.~1~tA~ 0.224902 4J~'~0.365690.3440010.367518J~ 4~ 0.136319i~.~I 0.19448 J~~',1~ 0.171769 ,~- JJ~*~ 0.15011 -~-~~- ~ 0.467646 * *~0.107304Figure 4: Part of the evaluation lexicons.t/ftttttftftttttttTranslation Probabilityoffice 0.375868protection 0.343071report 0.358592prepare 0.189513loca l  0.421837follow 0.023685standard 0.445453adu l t  0.044959inadequate 0.093012part 0.313676financial 0.16608visit 0.309642bill 0.401997vehicle 0.467034saving 0.176695Figure 5: Effect of stop lists in C-E translation.ing source.
Because these words exist in most align-ments, the statistical model cannot derive correcttranslations for them.
More importantly, their ex-istence greatly affects the accuracy of other transla-tions.
They can be taken as translations for manywords.A priori, it would seem that both the English andChinese stop-lists hould be applied to eliminate thenoise caused by them.
Interestingly, from our ob-servation and analysis we concluded that for betterprecision, only the stop-list of the target languageshould be applied in the model training.We first explain why the stop-list of the target lan-guage has to be applied.
On the left side of Fig.
5,if the Chinese word C exists in the same alignmentswith the English word E more than any other Chi-nese words, C will be the most probable translationfor E. Because of their frequent appearance, someChinese stopwords may have more chances to be inthe same alignments with E. The probability of thetranslation E --+ C is then reduced (maybe ven lessthan those of the incorrect ones).
This is the reasonwhy many English words are translated to "~ '  (of)by the translation model trained without using theChinese stop-list.We also found that it is not necessary to removethe stopwords of the source language.
In fact, as il-lustrated on the right side of Fig.
5, the existence ofthe English stopwords has two effects on the proba-bility of the translation E -~ C:1 They may often be found together with the Chi-nese word C. Owing to the Expectation Maxi-mization algorithm, the probability of E -~ Cmay therefore be reduced.2 On the other hand, there is a greater likelihoodthat English stopwords will be found togetherwith the most frequent Chinese words.
Here,we use the term "Chinese frequent words" in-stead of "Chinese stopwords" because ven if astop-list is applied, there may still remain somecommon words that have the same effect as thestopwords.
The coexistence ofEnglish and Chi-nese frequent words reduces the probability thatthe Chinese frequent words are the translationsof E, and thus raise the probability of E -+ C.The second effect was found to be more signifi-cant than the first, since the model trained withoutthe English stopwords has better precision than themodel trained with the English stopwords.
For thecorrect ranslations given by both models, the model26Mono-Lingual IRTranslation ModelDictionaryC-E CLIR0.38610.1504 (39.0%mono)0.1530 (39.6%mono)0.2583 (66.9%mono)E-C CLIR0.39760.1841 (46.3%mono)0.1427 (35.9%mono)0.2232 (56.1%mono)Table 1: CLIR results.trained without considering the English stopwordsgives higher probabilities.4 Eng l i sh -Ch inese  CL IR  Resu l tsOur final goal was to test the performance of thetranslation models trained on the Web parallel cor-pora in CLIR.
We conducted CLIR experiments u -ing the Smart IR system.4.1 ResultsThe English test corpus (for C-E CLIR) was theAP corpus used in TREC6 and TREC7.
The shortEnglish queries were translated manually into Chi-nese and then translated back to English by thetranslation model.
The Chinese test corpus was theone used in the TREC5 and TREC6 Chinese track.It contains both Chinese queries and their Englishtranslations.Our experiments on these two corpora producedthe results hown in Tab.
1.
The precision of mono-lingual IR is given as benchmark.
In both E-C andC-E CLIR, the translation model achieved around40% of monolingual precision.
To compare with thedictionary-based approach, we employed a Chinese-English dictionary, CEDICT (Denisowski, 1999),and an English-Chinese online dictionary (Anony-mous, 1999a) to translate queries.
For each wordof the source query, all the possible translationsgiven by the dictionary are included in the translatedquery.
The Chinese-English dictionary has aboutthe same performace as the translation model, whilethe English-Chinese dictionary has lower precisionthan that of the translation model.We also tried to combine the translations given bythe translation model and the dictionary.
In bothC-E and E-C CLIR, significant improvements wereachieved (as shown in Tab.
1).
The improvementsshow that the translations given by the translationmodel and the dictionary complement each otherwell for IR purposes.
The translation model maygive either exact ranslations orincorrect but relatedwords.
Even though these words are not correct inthe sense of translation, they are very possibly re-lated to the subject of the query and thus helpfulfor IR purposes.
The dictionary-based approach ex-pands a query along another dimension.
It givesall the possible translations for each word includingthose that are missed by the translation model.4.2 Comparison Wi th  MT SystemsOne advantage of a parallel text-based translationmodel is that it is easier to build than an MT system.Now that we have examined the CLIR performanceof the translation model, we will compare it withtwo existing MT systems.
Both systems were testedin E-C CLIR.4.2.1 Sunshine WebTran ServerUsing the Sunshine WebTran server (Anonymous,1999b), an online Engiish-Chinese MT system, totranslate the 54 English queries, we obtained anaverage precision of 0.2001, which is 50.3% of themono-lingual precision.
The precision is higher thanthat obtained using the translation model (0.1804)or the dictionary (0.1427) alone, but lower than theprecison obtained using them together (0.2232).4.2.2 TransperfectKwok (1999) investigated the CLIR performance ofan English-Chinese MT software called Transper-fect, using the same TREC Chinese collection as weused in this study.
Using the MT software alone,Kwok achieved 56% of monolingual precision.
Theprecision is improved to 62% by refining the trans-lation with a dictionary.
Kwok also adopted pre-translation query expansion, which further improvedthe precison to 70% of the monolingual results.In our case, the best E-C CLIR precison using thetranslation model (and dictionary) is 56.1%.
It islower than what Kwok achieved using Transperfect,however, the difference is not large.4.3 Further  ProblemsThe Chinese-English translation model has a faxlower CLIR performance than that of the English-French model established using the same method(Nie et al, 1999).
The principal reason for this is thefact that English and Chinese are much more differ-ent than English and French.
This problem surfacedin many phases of this work, from text alignment toquery translation.
Below, we list some further fac-tors affecting CLIR precision.?
The Web-collected corpus is noisy and it is dif-ficult to align English-Chinese t xts.
The align-ment method we employed has performed morepoorly than on English-French alignment.
Thisin turn leads to poorer performance of the trans-lation model.
In general, we observe a higher27variability in Chinese-English translations thanin English-French translations.?
For E-C CLIR, although queries in both lan-guages were provided, the English queries werenot strictly translated from the original Chi-nese ones.
For example, A Jg ,~ (human rightsituation) was translated into human right is-sue.
We cannot expect he translation modelto translate issue back to ~ (situation).?
The training source and the CLIR collectionswere from different domains.
The Web cor-pus are retrieved from the parallel sites in HongKong while the Chinese collection is from Peo-ple's Daily and Xinhua News Agency, which arepublished in mainland China.
As the result,some important erms such as ~$ $ (most-favored-nation) and --- I!!
~ ~ (one-nation-two-systems) in the collection are not known by themodel.5 SummaryThe goal of this work was to investigate he feasibil-ity of using a statistical translation model trained ona Web-collected corpus to do English-Chinese CLIR.In this paper, we have described the algorithm andimplementation we used for parallel text mining,translation model training, and some results we ob-tained in CLIR experiments.
Although further workremains to be done, we can conclude that it is pos-sible to automatically construct a Chinese-Englishparallel corpus from the Web.
The current systemcan be easily adapted to other language pairs.
De-spite the noisy nature of the corpus and the greatdifference in the languages, the evaluation lexiconsgenerated by the translation model produced accept-able precision.
While the current CLIR results arenot as encouraging asthose of English-French CLIR,they could be improved in various ways, such as im-proving the alignment method by adapting cognatedefinitions to HTML markup, incorporating a lexi-con and/or removing some common function wordsin translated queries.We hope to be able to demonstrate in the nearfuture that a fine-tuned English-Chinese translationmodel can provide query translations for CLIR withthe same quality produced by MT systems.Re ferencesAnonymous.
1999a.
Sunrain.net - English-Chinesedictionary, http://sunrain.net/r_ecdict _e.htm.Anonymous.
1999b.
Sunshine WebTran server.http://www.readworld.com/translate.htm.P.
F. Brown, J. C. Lai, and R. L. Mercer.
1991.Aligning sentences in parallel corpora.
In 29thAnnual Meeting of the Association for Computa-tional Linguistics, pages 89-94, Berkeley, Calif.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra,and R. L. Mercer.
1993.
The mathematics of ma-chine translation: Parameter estimation.
Compu-tational Linguistics, 19:263-311.S.
F. Chen.
1993.
Aligning sentences in bilingualcorpora using lexical information.
In Proceedingsof the 31th Annual Meeting of the Association forComputational Linguistics, pages 9-16, Colum-bus, Ohio.Paul Denisowski.
1999.
Cedict (chinese-english dic-tionary) project, http://www.mindspring.com/paul_denisowski/cedict.html.William A. Gale and Kenneth W. Church.
1991.
Aprogram for aligning sentences in bilingual cor-pora.
In Proceedings of the 29th Annual Meetingof the Association for Computational Linguistics,pages 177-184, Berkeley, Calif.P.
Isabelle, G. Foster, and P. Plamondon.1997.
SILC: un syst~me d'identificationde la langue et du codage, http://www-rali.iro.umontreal.ca/ProjetSILC.en.html.M.
Kay and M. RSscheisen.
1993.
Text-translationalignment.
Computational Linguistics, 19:121-142.K.
L. Kwok.
1999.
English-chinese cross-languageretrieval based on a translation package.
In Work-shop of Machine Translation for Cross LanguageInformation Retrieval, Machine Translation Sum-mit VII, Singapore.P.
Langlais, G. Foster, and G. Lapalme.
2000.
Unitcompletion for a computer-aided translation typ-ing system.
In Applied Natural Language Pro-cessing Conference (ANLP), Seattle, Washington,May.Jianyun Nie, Michel Simard, Pierre Isabelle, andRichard Durand.
1999.
Cross-language informa-tion retrieval based on parallel texts and auto-matic mining parallel texts from the Web.
InACM SIGIR '99, pages 74-81, August.Philip Resnik.
1998.
Parallel stands: A preliminaryinvestigation i to mining the Web for bilingualtext.
In AMTA '98, October.Michel Simard, George F. Foster, and Pierre Is-abelle.
1992.
Using cognates to align sentencesin bilingual corpora.
In Proceedings of TMI-92,Montreal, Quebec.Dekai Wu.
1994.
Aligning a parallel English-Chinese corpus statistically with lexical criteria.In ACL-9$: 32nd Annual Meeting of the Assoc.for Computational Linguistics, pages 80-87, LasCruces, NM, June.Dekai Wu.
1995.
Large-scale automatic extractionof an English-Chinese l xicon.
Machine Transla-tion, 9(3-4):285-313.28
