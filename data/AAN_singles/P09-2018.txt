Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 69?72,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPDirectional Distributional Similarity for Lexical ExpansionLili Kotlerman, Ido Dagan, Idan SzpektorDepartment of Computer ScienceBar-Ilan UniversityRamat Gan, Israellili.dav@gmail.com{dagan,szpekti}@cs.biu.ac.ilMaayan Zhitomirsky-GeffetDepartment of Information ScienceBar-Ilan UniversityRamat Gan, Israelmaayan.geffet@gmail.comAbstractDistributional word similarity is mostcommonly perceived as a symmetric re-lation.
Yet, one of its major applicationsis lexical expansion, which is generallyasymmetric.
This paper investigates thenature of directional (asymmetric) similar-ity measures, which aim to quantify distri-butional feature inclusion.
We identify de-sired properties of such measures, specifya particular one based on averaged preci-sion, and demonstrate the empirical bene-fit of directional measures for expansion.1 IntroductionMuch work on automatic identification of seman-tically similar terms exploits Distributional Simi-larity, assuming that such terms appear in similarcontexts.
This has been now an active researcharea for a couple of decades (Hindle, 1990; Lin,1998; Weeds and Weir, 2003).This paper is motivated by one of the prominentapplications of distributional similarity, namelyidentifying lexical expansions.
Lexical expansionlooks for terms whose meaning implies that of agiven target term, such as a query.
It is widelyemployed to overcome lexical variability in ap-plications like Information Retrieval (IR), Infor-mation Extraction (IE) and Question Answering(QA).
Often, distributional similarity measures areused to identify expanding terms (e.g.
(Xu andCroft, 1996; Mandala et al, 1999)).
Here we de-note the relation between an expanding term u andan expanded term v as ?u ?
v?.While distributional similarity is most promi-nently modeled by symmetric measures, lexicalexpansion is in general a directional relation.
InIR, for instance, a user looking for ?baby food?will be satisfied with documents about ?baby pap?or ?baby juice?
(?pap ?
food?, ?juice ?
food?
);but when looking for ?frozen juice?
she will notbe satisfied by ?frozen food?.
More generally, di-rectional relations are abundant in NLP settings,making symmetric similarity measures less suit-able for their identification.Despite the need for directional similarity mea-sures, their investigation counts, to the best ofour knowledge, only few works (Weeds and Weir,2003; Geffet and Dagan, 2005; Bhagat et al,2007; Szpektor and Dagan, 2008; Michelbacher etal., 2007) and is utterly lacking.
From an expan-sion perspective, the common expectation is thatthe context features characterizing an expandingword should be largely included in those of the ex-panded word.This paper investigates the nature of directionalsimilarity measures.
We identify their desiredproperties, design a novel measure based on theseproperties, and demonstrate its empirical advan-tage in expansion settings over state-of-the-artmeasures1.
In broader prospect, we suggest thatasymmetric measures might be more suitable thansymmetric ones for many other settings as well.2 BackgroundThe distributional word similarity scheme followstwo steps.
First, a feature vector is constructedfor each word by collecting context words as fea-tures.
Each feature is assigned a weight indicatingits ?relevance?
(or association) to the given word.Then, word vectors are compared by some vectorsimilarity measure.1Our directional term-similarity resource will be availableat http://aclweb.org/aclwiki/index.php?title=Textual_Entailment_Resource_Pool69To date, most distributional similarity researchconcentrated on symmetric measures, such as thewidely cited and competitive (as shown in (Weedsand Weir, 2003)) LIN measure (Lin, 1998):LIN(u, v) =?f?FVu?FVv[wu(f) + wv(f)]?f?FVuwu(f) +?f?FVvwv(f)where FVxis the feature vector of a word x andwx(f) is the weight of the feature f in that word?svector, set to their pointwise mutual information.Few works investigated a directional similarityapproach.
Weeds and Weir (2003) and Weeds etal.
(2004) proposed a precision measure, denotedhere WeedsPrec, for identifying the hyponymy re-lation and other generalization/specification cases.It quantifies the weighted coverage (or inclusion)of the candidate hyponym?s features (u) by the hy-pernym?s (v) features:WeedsPrec(u ?
v) =?f?FVu?FVvwu(f)?f?FVuwu(f)The assumption behind WeedsPrec is that if oneword is indeed a generalization of the other thenthe features of the more specific word are likely tobe included in those of the more general one (butnot necessarily vice versa).Extending this rationale to the textual entail-ment setting, Geffet and Dagan (2005) expectedthat if the meaning of a word u entails that ofv then all its prominent context features (undera certain notion of ?prominence?)
would be in-cluded in the feature vector of v as well.
Theirexperiments indeed revealed a strong empiricalcorrelation between such complete inclusion ofprominent features and lexical entailment, basedon web data.
Yet, such complete inclusion cannotbe feasibly assessed using an off-line corpus, dueto the huge amount of required data.Recently, (Szpektor and Dagan, 2008) triedidentifying the entailment relation betweenlexical-syntactic templates using WeedsPrec, butobserved that it tends to promote unreliable rela-tions involving infrequent templates.
To remedythis, they proposed to balance the directionalWeedsPrec measure by multiplying it with thesymmetric LIN measure, denoted here balPrec:balPrec(u?v)=?LIN(u, v)?WeedsPrec(u?v)Effectively, this measure penalizes infrequent tem-plates having short feature vectors, as those usu-ally yield low symmetric similarity with the longervectors of more common templates.3 A Statistical Inclusion MeasureOur research goal was to develop a directionalsimilarity measure suitable for learning asymmet-ric relations, focusing empirically on lexical ex-pansion.
Thus, we aimed to quantify most effec-tively the above notion of feature inclusion.For a candidate pair ?u ?
v?, we will refer tothe set of u?s features, which are those tested forinclusion, as tested features.
Amongst these fea-tures, those found in v?s feature vector are termedincluded features.In preliminary data analysis of pairs of featurevectors, which correspond to a known set of validand invalid expansions, we identified the follow-ing desired properties for a distributional inclusionmeasure.
Such measure should reflect:1. the proportion of included features amongstthe tested ones (the core inclusion idea).2. the relevance of included features to the ex-panding word.3.
the relevance of included features to the ex-panded word.4.
that inclusion detection is less reliable if thenumber of features of either expanding or ex-panded word is small.3.1 Average Precision as the Basis for anInclusion MeasureAs our starting point we adapted the AveragePrecision (AP) metric, commonly used to scoreranked lists such as query search results.
Thismeasure combines precision, relevance rankingand overall recall (Voorhees and Harman, 1999):AP =?Nr=1[P (r) ?
rel(r)]total number of relevant documentswhere r is the rank of a retrieved documentamongst the N retrieved, rel(r) is an indicatorfunction for the relevance of that document, andP (r) is precision at the given cut-off rank r.In our case the feature vector of the expandedword is analogous to the set of all relevant docu-ments while tested features correspond to retrieveddocuments.
Included features thus correspond torelevant retrieved documents, yielding the follow-70ing analogous measure in our terminology:AP (u ?
v) =?|FVu|r=1[P (r) ?
rel(fr)]|FVv|rel(f) ={1, if f ?
FVv0, if f /?
FVvP (r) =|included features in ranks 1 to r|rwhere fris the feature at rank r in FVu.This analogy yields a feature inclusion measurethat partly addresses the above desired properties.Its score increases with a larger number of in-cluded features (correlating with the 1stproperty),while giving higher weight to highly ranked fea-tures of the expanding word (2ndproperty).To better meet the desired properties we in-troduce two modifications to the above measure.First, we use the number of tested features |FVu|for normalization instead of |FVv|.
This capturesbetter the notion of feature inclusion (1stproperty),which targets the proportion of included featuresrelative to the tested ones.Second, in the classical AP formula all relevantdocuments are considered relevant to the same ex-tent.
However, features of the expanded word dif-fer in their relevance within its vector (3rdprop-erty).
We thus reformulate rel(f) to give higherrelevance to highly ranked features in |FVv|:rel?
(f) ={1 ?rank(f,FVv)|FVv|+1, if f ?
FVv0 , if f /?
FVvwhere rank(f, FVv) is the rank of f in FVv.Incorporating these twomodifications yields theAPinc measure:APinc(u?v)=?|FVu|r=1[P (r) ?
rel?
(fr)]|FVu|Finally, we adopt the balancing approach in(Szpektor and Dagan, 2008), which, as explainedin Section 2, penalizes similarity for infrequentwords having fewer features (4thproperty) (in ourversion, we truncated LIN similarity lists after top1000 words).
This yields our proposed directionalmeasure balAPinc:balAPinc(u?v) =?LIN(u, v) ?
APinc(u?v)4 Evaluation and Results4.1 Evaluation SettingWe tested our similarity measure by evaluating itsutility for lexical expansion, compared with base-lines of the LIN, WeedsPrec and balPrec measures(Section 2) and a balanced version of AP (Sec-tion 3), denoted balAP.
Feature vectors were cre-ated by parsing the Reuters RCV1 corpus and tak-ing the words related to each term through a de-pendency relation as its features (coupled with therelation name and direction, as in (Lin, 1998)).
Weconsidered for expansion only terms that occur atleast 10 times in the corpus, and as features onlyterms that occur at least twice.As a typical lexical expansion task we usedthe ACE 2005 events dataset2.
This standard IEdataset specifies 33 event types, such as Attack,Divorce, and Law Suit, with all event mentionsannotated in the corpus.
For our lexical expan-sion evaluation we considered the first IE subtaskof finding sentences that mention the event.For each event we specified a set of representa-tive words (seeds), by selecting typical terms forthe event (4 on average) from its ACE definition.Next, for each similarity measure, the terms foundsimilar to any of the event?s seeds (?u ?
seed?
)were taken as expansion terms.
Finally, to mea-sure the sole contribution of expansion, we re-moved from the corpus all sentences that containa seed word and then extracted all sentences thatcontain expansion terms as mentioning the event.Each of these sentences was scored by the sum ofsimilarity scores of its expansion terms.To evaluate expansion quality we compared theranked list of sentences for each event to the gold-standard annotation of event mentions, using thestandard Average Precision (AP) evaluation mea-sure.
We report Mean Average Precision (MAP)for all events whose AP value is at least 0.1 for atleast one of the tested measures3.4.1.1 ResultsTable 1 presents the results for the different testedmeasures over the ACE experiment.
It shows thatthe symmetric LIN measure performs significantlyworse than the directional measures, assessing thata directional approach is more suitable for the ex-pansion task.
In addition, balanced measures con-sistently perform better than unbalanced ones.According to the results, balAPinc is the best-performing measure.
Its improvement over allother measures is statistically significant accord-ing to the two-sided Wilcoxon signed-rank test2http://projects.ldc.upenn.edu/ace/, training part.3The remaining events seemed useless for our compar-ative evaluation, since suitable expansion lists could not befound for them by any of the distributional methods.71LIN WeedsPrec balPrec AP balAP balAPinc0.068 0.044 0.237 0.089 0.202 0.312Table 1: MAP scores of the tested measures on theACE experiment.seed LIN balAPincdeath murder, killing, inci-dent, arrest, violencesuicide, killing, fatal-ity, murder, mortalitymarry divorce, murder, love, divorce, remarry,dress, abduct father, kiss, care forarrest detain, sentence,charge, jail, convictdetain, extradite,round up, apprehend,imprisonbirth abortion, pregnancy, wedding day,resumption, seizure, dilation, birthdate,passage circumcision, tripletinjure wound, kill, shoot, wound, maim, beatdetain, burn up, stab, gun downTable 2: Top 5 expansion terms learned by LINand balAPinc for a sample of ACE seed words.
(Wilcoxon, 1945) at the 0.01 level.
Table 2presents a sample of the top expansion termslearned for some ACE seeds with either LIN orbalAPinc, demonstrating the more accurate ex-pansions generated by balAPinc.
These resultssupport the design of our measure, based on thedesired properties that emerged from preliminarydata analysis for lexical expansion.Finally, we note that in related experiments weobserved statistically significant advantages of thebalAPincmeasure for an unsupervised text catego-rization task (on the 10 most frequent categories inthe Reuters-21578 collection).
In this setting, cat-egory names were taken as seeds and expanded bydistributional similarity, further measuring cosinesimilarity with categorized documents similarly toIR query expansion.
These experiments fall be-yond the scope of this paper and will be includedin a later and broader description of our work.5 Conclusions and Future workThis paper advocates the use of directional similar-ity measures for lexical expansion, and potentiallyfor other tasks, based on distributional inclusion offeature vectors.
We first identified desired proper-ties for an inclusion measure and accordingly de-signed a novel directional measure based on av-eraged precision.
This measure yielded the bestperformance in our evaluations.
More generally,the evaluations supported the advantage of multi-ple directional measures over the typical symmet-ric LIN measure.Error analysis showed that many false sentenceextractions were caused by ambiguous expandingand expanded words.
In future work we plan toapply disambiguation techniques to address thisproblem.
We also plan to evaluate the performanceof directional measures in additional tasks, andcompare it with additional symmetric measures.AcknowledgementsThis work was partially supported by the NEGEVproject (www.negev-initiative.org), the PASCAL-2 Network of Excellence of the European Com-munity FP7-ICT-2007-1-216886 and by the IsraelScience Foundation grant 1112/08.ReferencesR.
Bhagat, P. Pantel, and E. Hovy.
2007.
LEDIR: Anunsupervised algorithm for learning directionality ofinference rules.
In Proceedings of EMNLP-CoNLL.M.
Geffet and I. Dagan.
2005.
The distributional in-clusion hypotheses and lexical entailment.
In Pro-ceedings of ACL.D.
Hindle.
1990.
Noun classification from predicate-argument structures.
In Proceedings of ACL.D.
Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of COLING-ACL.R.
Mandala, T. Tokunaga, and H. Tanaka.
1999.
Com-bining multiple evidence from different types of the-saurus for query expansion.
In Proceedings of SI-GIR.L.
Michelbacher, S. Evert, and H. Schutze.
2007.Asymmetric association measures.
In Proceedingsof RANLP.I.
Szpektor and I. Dagan.
2008.
Learning entailmentrules for unary templates.
In Proceedings of COL-ING.E.
M. Voorhees and D. K. Harman, editors.
1999.
TheSeventh Text REtrieval Conference (TREC-7), vol-ume 7.
NIST.J.
Weeds and D. Weir.
2003.
A general framework fordistributional similarity.
In Proceedings of EMNLP.J.
Weeds, D. Weir, and D. McCarthy.
2004.
Character-ising measures of lexical distributional similarity.
InProceedings of COLING.F.
Wilcoxon.
1945.
Individual comparisons by rankingmethods.
Biometrics Bulletin, 1:80?83.J.
Xu and W. B. Croft.
1996.
Query expansion usinglocal and global document analysis.
In Proceedingsof SIGIR.72
