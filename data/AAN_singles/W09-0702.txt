Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ?
AfLaT 2009, pages 9?16,Athens, Greece, 31 March 2009. c?2009 Association for Computational LinguisticsThe SAWA Corpus: a Parallel Corpus English - SwahiliGuy De PauwCNTS - Language Technology Group, University of Antwerp, BelgiumSchool of Computing and Informatics, University of Nairobi, Kenyaguy.depauw@ua.ac.bePeter Waiganjo WagachaSchool of Computing and Informatics, University of Nairobi, Kenyawaiganjo@uonbi.ac.keGilles-Maurice de SchryverAfrican Languages and Cultures, Ghent University, BelgiumXhosa Department, University of the Western Cape, South Africagillesmaurice.deschryver@ugent.beAbstractResearch in data-driven methods for Ma-chine Translation has greatly benefitedfrom the increasing availability of paral-lel corpora.
Processing the same text intwo different languages yields useful in-formation on how words and phrases aretranslated from a source language into atarget language.
To investigate this, a par-allel corpus is typically aligned by linkinglinguistic tokens in the source language tothe corresponding units in the target lan-guage.
An aligned parallel corpus there-fore facilitates the automatic developmentof a machine translation system and canalso bootstrap annotation through projec-tion.
In this paper, we describe data col-lection and annotation efforts and prelim-inary experimental results with a parallelcorpus English - Swahili.1 IntroductionLanguage technology applications such as ma-chine translation can provide an invaluable, butall too often ignored, impetus in bridging the dig-ital divide between the Western world and Africa.Quite a few localization efforts are currently un-derway that improve ICT access in local Africanlanguages.
Vernacular content is now increasinglybeing published on the Internet, and the need forrobust language technology applications that canprocess this data is high.For a language like Swahili, digital resourceshave become increasingly important in everydaylife, both in urban and rural areas, particularlythanks to the increasing number of web-enabledmobile phone users in the language area.
But mostresearch efforts in the field of natural languageprocessing (NLP) for African languages are stillfirmly rooted in the rule-based paradigm.
Lan-guage technology components in this sense areusually straight implementations of insights de-rived from grammarians.
While the rule-basedapproach definitely has its merits, particularly interms of design transparency, it has the distinctdisadvantage of being highly language-dependentand costly to develop, as it typically involves a lotof expert manual effort.Furthermore, many of these systems are decid-edly competence-based.
The systems are oftentweaked and tuned towards a small set of idealsample words or sentences, ignoring the fact thatreal-world language technology applications haveto be principally able to handle the performanceaspect of language.
Many researchers in the fieldare quite rightly growing weary of publicationsthat ignore quantitative evaluation on real-worlddata or that report incredulously high accuracyscores, excused by the erroneously perceived reg-ularity of African languages.In a linguistically diverse and increasingly com-puterized continent such as Africa, the need for amore empirical approach to language technologyis high.
The data-driven, corpus-based approachdescribed in this paper establishes such an alter-native, so far not yet extensively investigated forAfrican languages.
The main advantage of this9approach is its language independence: all that isneeded is (linguistically annotated) language data,which is fairly cheap to compile.
Given this data,existing state-of-the-art algorithms and resourcescan consequently be re-used to quickly develop ro-bust language applications and tools.Most African languages are however resource-scarce, meaning that digital text resources are few.An increasing number of publications however areshowing that carefully selected procedures can in-deed bootstrap language technology for Swahili(De Pauw et al, 2006; De Pauw and de Schryver,2008), Northern Sotho (de Schryver and De Pauw,2007) and smaller African languages (Wagacha etal., 2006a; Wagacha et al, 2006b; De Pauw andWagacha, 2007; De Pauw et al, 2007a; De Pauwet al, 2007b).In this paper we outline on-going research onthe development of a parallel corpus English -Swahili.
The parallel corpus is designed to boot-strap a data-driven machine translation system forthe language pair in question, as well as open uppossibilities for projection of annotation.We start off with a short survey of the differentapproaches to machine translation (Section 2) andshowcase the possibility of projection of annota-tion (Section 3).
We then concentrate on the re-quired data collection and annotation efforts (Sec-tion 4) and describe preliminary experiments onsentence, word and morpheme alignment (Sec-tions 5 and 6).
We conclude with a discussion ofthe current limitations to the approach and providepointers for future research (Section 7).2 Machine TranslationThe main task of Machine Translation (MT) canbe defined as having a computer take a text in-put in one language, the Source language (SL),decode its meaning and re-encode it producing asoutput a similar-meaning text in another language,the Target language (TL).
The idea of buildingan application to automatically convert text fromone language to an equivalent text-meaning ina second language traces its roots back to ColdWar intelligence efforts in the 1950?s and 60?s forRussian-English text translations.
Since then alarge number of MT systems have been developedwith varying degrees of success.
For an excellentoverview of the history of MT, we refer the readerto Hutchins (1986).The original dream of creating a fully automaticMT system has long since been abandoned andmost research in the field currently concentrateson minimizing human pre- and post-processing ef-fort.
A human translator is thus considered towork alongside the MT system to produce fasterand more consistent translations.The Internet brought in an interesting new di-mension to the purpose of MT.
In the mid 1990s,free on-line translation services began to surfacewith an increasing number of MT vendors.
Themost famous example is Yahoo!
?s Babelfish , of-fering on-line versions of Systran to translate En-glish, French, German, Spanish and other Indo-European languages.
Currently Google.inc is alsooffering translation services.
While these systemsprovide far from perfect output, they can oftengive readers a sense of what is being talked abouton a web page in a language (and often even char-acter set) foreign to them.There are roughly three types of approaches tomachine translation:1.
Rule-based methods perform translation us-ing extensive lexicons with morphological,syntactic and semantic information, and largesets of manually compiled rules, makingthem very labor intensive to develop.2.
Statistical methods entail the collection andstatistical analysis of bilingual text corpora,i.e.
parallel corpora.
The technique triesto find the highest probability translation ofa sentence or phrase among the exponentialnumber of choices.3.
Example-based methods are similar to sta-tistical methods in that they are parallel cor-pus driven.
An Example-Based MachineTranslator (EBMT) scans for patterns in bothlanguages and relates them in a translationmemory.Most MT systems currently under developmentare based on methods (2) and/or (3).
Researchin these fields has greatly benefited from the in-creasing availability of parallel corpora, which areneeded to bootstrap these approaches.
Such a par-allel corpus is typically aligned by linking, eitherautomatically or manually, linguistic tokens in thesource language to the corresponding units in thetarget language.
Processing this data enables thedevelopment of fast and effective MT systems inboth directions with a minimum of human involve-ment.10English Swahili English SwahiliSentences Sentences Words WordsNew Testament 7.9k 189.2k 151.1kQuran 6.2k 165.5k 124.3kDeclaration of HR 0.2k 1.8k 1.8kKamusi.org 5.6k 35.5k 26.7kMovie Subtitles 9.0k 72.2k 58.4kInvestment Reports 3.2k 3.1k 52.9k 54.9kLocal Translator 1.5k 1.6k 25.0k 25.7kFull Corpus Total 33.6k 33.6k 542.1k 442.9kTable 1: Overview of the data in the SAWA Corpus3 Projection of AnnotationWhile machine translation constitutes the moststraightforward application of a parallel corpus,projection of annotation has recently become aninteresting alternative use of this type of resource.As previously mentioned, most African languagesare resource-scarce: annotated data is not only un-available, but commercial interest to develop theseresources is limited.
Unsupervised approachescan be used to bootstrap annotation of a resource-scarce language (De Pauw and Wagacha, 2007; DePauw et al, 2007a) by automatically finding lin-guistic patterns in large amounts of raw text.Projection of annotation attempts to achieve thesame goal, but through the use of a parallel cor-pus.
These techniques try to transport the annota-tion of a well resourced source language, such asEnglish, to texts in a target language.
As a natu-ral extension of the domain of machine translation,these methods employ parallel corpora which arealigned at the sentence and word level.
The di-rect correspondence assumption coined in Hwa etal.
(2002) hypothesizes that words that are alignedbetween source and target language, must sharelinguistic features as well.
It therefore allows forthe annotation of the words in the source languageto be projected unto the text in the target language.The following general principle holds: the closersource and target language are related, the moreaccurate this projection can be performed.
Eventhough lexical and structural differences betweenlanguages prevent a simple one-to-one mapping,knowledge transfer is often able to generate a welldirected annotation of the target language.This holds particular promise for the annotationof dependency analyses for Swahili, as exempli-fied in Figure 1, since dependency grammar fo-root The cat fell into the waterroot Paka alianguka ndani ya majimaindt subj pp dtcompmainsubj ppcomp?
?Figure 1: Projection of Dependency Analysis An-notationcuses on semantic relationships, rather than coresyntactic properties, that are much more trouble-some to project across languages.
The idea is thata relationship that holds between two words in thesource language (for instance the subj relationshipbetween cat and fell), also holds for the corre-sponding linguistic tokens in the target language,i.e.
paka and alianguka.In the next section we describe data collectionand preprocessing efforts on the SAWA Corpus,a parallel corpus English - Swahili (cf.
Table 1),which will enable this type of projection of anno-tation, as well as the development of a data-drivenmachine translation system.4 Data Collection and AnnotationWhile digital data is increasingly becoming avail-able for Swahili on the Internet, sourcing useful11Figure 2: Manual word alignment using the UMIACS interfacebilingual data is far from trivial.
At this stage inthe development of the MT system, it is paramountto use faithfully translated material, as this benefitsfurther automated processing.
The corpus-basedMT approaches we wish to employ, require wordalignment to be performed on the texts, duringwhich the words in the source language are linkedto the corresponding words in the target language(also see Figures 1 and 2).But before we can do this, we need to performsentence-alignment, during which we establish anunambiguous mapping between the sentences inthe source text and the sentences in the target text.While some data is inherently sentence-aligned,other texts require significant preprocessing beforeword alignment can be performed.The SAWA Corpus currently consists of a rea-sonable amount of data (roughly half a millionwords in each language), although this is notcomparable to the resources available to Indo-European language pairs, such as the Hansard cor-pus (Roukos et al, 1997) (2.87 million sentencepairs).
Table 1 gives an overview of the data avail-able in the SAWA Corpus.
For each segment it liststhe number of sentences and words in the respec-tive languages.4.1 Sentence-aligned ResourcesWe found digitally available Swahili versions ofthe New Testament and the Quran for which wesourced the English counterparts.
This is not atrivial task when, as in the case of the Swahilidocuments, the exact source of the translation isnot provided.
By carefully examining subtle dif-ferences in the English versions, we were how-ever able to track down the most likely candidate.While religious material has a specific register andmay not constitute ideal training material for anopen-ended MT system, it does have the advan-tage of being inherently aligned on the verse level,facilitating further sentence alignment.
Anothertypical bilingual text is the UN Declaration of Hu-man Rights, which is available in many of theworld?s languages, including Swahili.
The manualsentence alignment of this text is greatly facilitatedby the fixed structure of the document.The downloadable version of the on-line dictio-nary English-Swahili (Benjamin, 2009) containsindividual example sentences associated with thedictionary entries.
These can be extracted andused as parallel data in the SAWA corpus.
Sinceat a later point, we also wish to study the specificlinguistic aspects of spoken language, we optedto have some movie subtitles manually translated.These can be extracted from DVDs and while the12language is compressed to fit on screen and con-stitutes scripted language, they nevertheless pro-vide a reasonable approximation of spoken lan-guage.
Another advantage of this data is that itis inherently sentence-aligned, thanks to the tech-nical time-coding information.
It also opens uppossibilities for MT systems with other languagepairs, since a commercial DVD typically containssubtitles for a large number of other languages aswell.4.2 Paragraph-aligned ResourcesThe rest of the material consists of paragraph-aligned data, which was manually sentence-aligned.
We obtained a substantial amount of datafrom a local Kenyan translator.
Finally, we alsoincluded Kenyan investment reports.
These areyearly reports from local companies and are pre-sented in both English and Swahili.
A major dif-ficulty was extracting the data from these docu-ments.
The company reports are presented in col-orful brochures in PDF format, meaning automatictext exports require manual post-processing andparagraph alignment (Figure 3).
They neverthe-less provide a valuable resource, since they comefrom a fairly specific domain and are a good sam-ple of the type of text the projected MT systemmay need to process in a practical setting.The reader may note that there is a very diversevariety of texts within the SAWA corpus, rangingfrom movie subtitles to religious texts.
While itcertainly benefits the evaluation to use data fromtexts in one specific language register, we havechosen to maintain variety in the language data atthis point.
Upon evaluating the decoder at a laterstage, we will however investigate the bias intro-duced by the specific language registers in the cor-pus.4.3 Word AlignmentAll of the data in the corpus was subsequentlytokenized, which involves automatically cleaningup the texts, conversion to UTF-8, and splittingpunctuation from word forms.
The next step in-volved scanning for sentence boundaries in theparagraph-aligned text, to facilitate the automaticsentence alignment method described in Section 5.While not necessary for further processing, wealso performed manual word-alignment annota-tion.
This task can be done automatically, but itis useful to have a gold-standard reference againstwhich we can evaluate the automated method.Figure 3: Text Extraction from Bilingual Invest-ment ReportMonitoring the accuracy of the automatic word-alignment method against the human reference,will allow us to tweak parameters to arrive at theoptimal settings for this language pair.We used the UMIACS word alignment interface(Hwa and Madnani, 2004) for this purpose andasked the annotators to link the words between thetwo sentences (Figure 2).
Given the linguistic dif-ferences between English and Swahili, this is byno means a trivial task.
Particularly the morpho-logical richness of Swahili means that there is a lotof convergence from words in English to wordsin Swahili (also see Section 6).
This alignmentwas done on some of the manual translations ofmovie subtitles, giving us a gold-standard word-alignment reference of about 5,000 words.
Eachannotator?s work was cross-checked by anotherannotator to improve correctness and consistency.5 Alignment ExperimentsThere are a number of packages available toprocess parallel corpora.
To preprocess theparagraph-aligned texts, we used Microsoft?sbilingual sentence aligner (Moore, 2002).
The13Precision Recall F(?
= 1)39.4% 44.5% 41.79%Table 2: Precision, Recall and F-score for theword-alignment task using GIZA++output of the sentence alignment was conse-quently manually corrected.
We found that 95% ofthe sentences were correctly aligned with most er-rors being made on sentences that were not presentin English, i.e.
instances where the translator de-cided to add an extra clarifying sentence to the di-rect translation from English.
This also explainswhy there are more Swahili words in the paragraphaligned texts than in English, while the situation isreversed for the sentence aligned data.For word-alignment, the state-of-the-art methodis GIZA++ (Och and Ney, 2003), which imple-ments the word alignment methods IBM1 to IBM5and HMM.
While this method has a strong Indo-European bias, it is nevertheless interesting to seehow far we can get with the default approach usedin statistical MT.We evaluate by looking at the word alignmentsproposed by GIZA++ and compare them to themanually word-aligned section of the SAWA Cor-pus.
We can quantify the evaluation by calculat-ing precision and recall and their harmonic mean,the F-score (Table 2).
The former expresses howmany links are correct, divided by the total num-ber of links suggested by GIZA++.
The latter iscalculated by dividing the number of correct links,by the total number of links in the manual annota-tion.
The underwhelming results presented in Ta-ble 2 can be attributed to the strong Indo-Europeanbias of the current approaches.
It is clear that extralinguistic data sources and a more elaborate explo-ration of the experimental parameters of GIZA++will be needed, as well as a different approach toword-alignment.
In the next section, we describea potential solution to the problem by defining theproblem on the level of the morpheme.6 Alignment into an AgglutinatingLanguageThe main problem in training a GIZA++ model forthe language pair English - Swahili is the strongagglutinating nature of the latter.
Alignment pat-terns such as the one in Figures 1 and 2 are notimpossible to retrieve.
But no corpus is exhaus-tive enough to provide enough linguistic evidencePrecision Recall F(?
= 1)50.2% 64.5% 55.8%Table 3: Precision, Recall and F-score for themorpheme/word-alignment task using GIZA++to unearth strongly converging alignment patterns,such as the one in Example 1.
(1) I have turned him downNimemkataliaMorphologically deconstructing the word how-ever can greatly relieve the sparse data problem forthis task:(2) I have turned him downNi- me- m- kataliaThe isolated Swahili morphemes can more eas-ily be linked to their English counterparts, sincethere will be more linguistic evidence in the par-allel corpus, linking for example ni to I and mto him.
To perform this kind of morphologicalanalysis, we developed a machine learning systemtrained and evaluated on the Helsinki corpus ofSwahili (Hurskainen, 2004).
Experimental resultsshow that the data-driven approach achieves state-of-the-art performance in a direct comparison witha rule-based method, with the added advantage ofbeing robust to word forms for previously unseenlemmas (De Pauw and de Schryver, 2008).
Wecan consequently use morphological deconstruc-tion as a preprocessing step for the alignment task,similar to the method described by Goldwater andMcClosky (2005), Oflazer (2008) and Stymne etal.
(2008).We have no morphologically aligned paralleldata available, so evaluation of the morphology-based approach needs to be done in a roundaboutway.
We first morphologically decompose theSwahili data and run GIZA++ again.
Then we re-compile the Swahili words from the morphemesand group the word alignment links accordingly.Incompatible linkages are removed.
The updatedscores are presented in Table 3.
While this cer-tainly improves on the scores in Table 2, we needto be aware of the difficulty that the morphologicalpreprocessing step will introduce in the decodingphase, necessitating the introduction of a languagemodel that not only works on the word level, but14also on the level of the morpheme.For the purpose of projection of annotation, thisis however not an issue.
We performed a prelim-inary experiment with a dependency-parsed En-glish corpus, projected unto the morphologicallydecompounded tokens in Swahili.
We are cur-rently lacking the annotated gold-standard data toperform quantitative evaluation, but have observedinteresting annotation results, that open up pos-sibilities for the morphological analysis of moreresource-scarce languages.7 DiscussionIn this paper we presented parallel corpus collec-tion work that will enable the construction of amachine translation system for the language pairEnglish - Swahili, as well as open up the possibil-ity of corpus annotation through projection.
Weare confident that we are approaching a criticalamount of data that will enable good word align-ment that can subsequently be used as a model foran MT decoding system, such as the Moses pack-age (Koehn et al, 2007).
While the currently re-ported scores are not yet state-of-the-art, we areconfident that further experimentation and the ad-dition of more bilingual data as well as the intro-duction of extra linguistic features will raise theaccuracy level of the proposed MT system.Apart from the morphological deconstructiondescribed in Section 6, the most straightforwardaddition is the introduction of part-of-speech tagsas an extra layer of linguistic description, whichcan be used in word alignment model IBM5.
Thecurrent word alignment method tries to link wordforms, but knowing that for instance a word in thesource language is a noun, will facilitate linkingit to a corresponding noun in the target language,rather than considering a verb as a possible match.Both for English (Ratnaparkhi, 1996) and Swahili(De Pauw et al, 2006), we have highly accuratepart-of-speech taggers available.Another extra information source that we haveso far ignored is a digital dictionary as a seed forthe word alignment.
The kamusiproject.org elec-tronic dictionary will be included in further word-alignment experiments and will undoubtedly im-prove the quality of the output.Once we have a stable word alignment mod-ule, we will further conduct learning curve exper-iments, in which we train the system with grad-ually increasing amounts of data.
This will pro-vide us with information on how much more datawe need to achieve state-of-the-art performance.This additional data can be automatically foundby parallel web mining, for which a few sys-tems have recently become available (Resnik andSmith, 2003).Furthermore, we will also look into the useof comparable corpora, i.e.
bilingual texts thatare not straight translations, but deal with thesame subject matter.
These have been found towork as additional material within a parallel cor-pus (McEnery and Xiao, 2007) and may furtherhelp improve the development of a robust, open-ended and bidirectional machine translation sys-tem for the language pair English - Swahili.
Themost innovative prospect of the parallel corpus isthe annotation of dependency analysis in Swahili,not only on the syntactic level, but also on thelevel of the morphology.
The preliminary exper-iments indicate that this approach might provide avaluable technique to bootstrap annotation in trulyresource-scarce languages.AcknowledgmentsThe research presented in this paper was madepossible through the support of the VLIR-IUC-UON program and was partly funded by the SAWABOF UA-2007 project.
The first author is fundedas a Postdoctoral Fellow of the Research Founda-tion - Flanders (FWO).
We are greatly indebted toDr.
James Omboga Zaja for contributing some ofhis translated data, to Mahmoud Shokrollahi-Farfor his advice on the Quran and to Anne Kimani,Chris Wangai Njoka and Naomi Maajabu for theirannotation efforts.ReferencesM.
Benjamin.
2009.
The Kamusi Project.
Available at:http://www.kamusiproject.org (Accessed: 14 Jan-uary 2009).G.
De Pauw and G.-M. de Schryver.
2008.
Improv-ing the computational morphological analysis of aSwahili corpus for lexicographic purposes.
Lexikos,18:303?318.G.
De Pauw and P.W.
Wagacha.
2007.
Bootstrappingmorphological analysis of G??ku?yu?
using unsuper-vised maximum entropy learning.
In Proceedingsof the eighth INTERSPEECH conference, Antwerp,Belgium.G.
De Pauw, G.-M. de Schryver, and P.W.
Wa-gacha.
2006.
Data-driven part-of-speech tagging of15Kiswahili.
In P. Sojka, I. Kopec?ek, and K. Pala, edi-tors, Proceedings of Text, Speech and Dialogue, 9thInternational Conference, volume 4188 of LectureNotes in Computer Science, pages 197?204, Berlin,Germany.
Springer Verlag.G.
De Pauw, P.W.
Wagacha, and D.A.
Abade.
2007a.Unsupervised induction of Dholuo word classesusing maximum entropy learning.
In K. Getaoand E. Omwenga, editors, Proceedings of the FirstInternational Computer Science and ICT Confer-ence, pages 139?143, Nairobi, Kenya.
University ofNairobi.G.
De Pauw, P.W.
Wagacha, and G.-M. de Schryver.2007b.
Automatic diacritic restoration for resource-scarce languages.
In Va?clav Matous?ek and PavelMautner, editors, Proceedings of Text, Speech andDialogue, Tenth International Conference, volume4629 of Lecture Notes in Computer Science, pages170?179, Heidelberg, Germany.
Springer Verlag.G.-M. de Schryver and G. De Pauw.
2007.
Dictio-nary writing system (DWS) + corpus query package(CQP): The case of Tshwanelex.
Lexikos, 17:226?246.S.
Goldwater and D. McClosky.
2005.
Improving sta-tistical MT through morphological analysis.
In Pro-ceedings of the Human Language Technology Con-ference and Conference on Empirical Methods inNatural Language Processing, pages 676?683, Van-couver, Canada.Google.
2009.
Google Translate.
Availableat http://www.google.com/translate (Accessed: 14January 2009.A.
Hurskainen.
2004.
HCS 2004 ?
Helsinki Corpus ofSwahili.
Technical report, Compilers: Institute forAsian and African Studies (University of Helsinki)and CSC.W.J.
Hutchins.
1986.
Machine translation: past,present, future.
Ellis, Chichester.R.
Hwa and N. Madnani.
2004.
The UMI-ACS Word Alignment Interface.
Available at:http://www.umiacs.umd.edu/?nmadnani/alignment/forclip.htm (Accessed: 14 January 2009).R.
Hwa, Ph.
Resnik, A. Weinberg, and O. Kolak.
2002.Evaluating translational correspondence using anno-tation projection.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics, pages 392?399, Philadelphia, PA, USA.Ph.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Annual Meet-ing of the Association for Computational Linguistics(ACL), demonstration session, Prague, Czech Re-public.A.M.
McEnery and R.Z Xiao.
2007.
Parallel andcomparable corpora: What are they up to?
In In-corporating Corpora: Translation and the Linguist.Translating Europe.
Multilingual Matters, Cleve-don, UK.R.C.
Moore.
2002.
Fast and accurate sentence align-ment of bilingual corpora.
In Proceedings of the 5thConference of the Association for Machine Transla-tion in the Americas on Machine Translation: FromResearch to Real Users, volume 2499 of LectureNotes in Computer Science, pages 135?144, Berlin,Germany.
Springer Verlag.F.J.
Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.K.
Oflazer.
2008.
Statistical machine translation intoa morphologically complex language.
In Compu-tational Linguistics and Intelligent Text Processing,pages 376?388, Berlin, Germany.
Springer Verlag.A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In E. Brill and K. Church,editors, Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages133?142.
Association for Computational Linguis-tics.Ph.
Resnik and N.A.
Smith.
2003.
The web as a par-allel corpus.
Computational Linguistics, 29(1):349?380.S.
Roukos, D. Graff, and D. Melamed.
1997.Hansard French/English.
Available at:http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC95T20 (Accessed: 14 January2009).S.
Stymne, M. Holmqvist, and L. Ahrenberg.
2008.Effects of morphological analysis in translation be-tween German and English.
In Proceedings of theThird Workshop on Statistical Machine Translation,pages 135?138, Columbus, USA.P.W.
Wagacha, G. De Pauw, and K. Getao.
2006a.Development of a corpus for G??ku?yu?
using machinelearning techniques.
In J.C. Roux, editor, Proceed-ings of LREC workshop - Networking the develop-ment of language resources for African languages,pages 27?30, Genoa, Italy, May, 2006.
EuropeanLanguage Resources Association, ELRA.P.W.
Wagacha, G. De Pauw, and P.W.
Githinji.
2006b.A grapheme-based approach for accent restorationin G??ku?yu?.
In Proceedings of the Fifth InternationalConference on Language Resources and Evaluation,pages 1937?1940, Genoa, Italy, May, 2006.
Euro-pean Language Resources Association, ELRA.Yahoo!
2009.
Babelfish.
Available athttp://babelfish.yahoo.com (Accessed: 14 January2009).16
