Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 190?197,Columbus, June 2008. c?2008 Association for Computational LinguisticsThe Effect of Dialogue System Output Style Variationon Users?
Evaluation Judgments and Input StyleIvana Kruijff-Korbayova?
and Olga KukinaDepartment of Computational LinguisticsSaarland University, Germany{korbay|olgak}@coli.uni-sb.deAbstractA dialogue system can present itself and/oraddress the user as an active agent by meansof linguistic constructions in personal style, orsuppress agentivity by using impersonal style.We compare system evaluation judgments andinput style alignment of users interacting withan in-car dialogue system generating output inpersonal vs. impersonal style.
Although ourresults are consistent with earlier findings ob-tained with simulated systems, the effects areweaker.1 IntroductionOne of the goals in developing dialogue systems thatusers find appealing and natural is to endow the sys-tems with natural and contextually appropriate out-put.
This encompasses a broad range of researchissues.
The one we address in this paper pertainsto style in the interpersonal dimension: does usingpersonal vs. impersonal style of system output havean effect on dialogue system users, in particular, ontheir judgments about the system and on the waythey formulate their input to the system?We define the personal/impersonal style di-chotomy as reflecting primarily a distinction withrespect to agentivity: personal style involves the ex-plicit realization of an agent, whereas impersonalstyle avoids it.
In the simplest way it is manifestedby the presence of explicit reference to the dialogueparticipants (typically by means of personal pro-nouns) vs. its absence, respectively.
More generally,active voice and finite verb forms are typical for per-sonal style, whereas impersonal style often, thoughnot exclusively, employs passive constructions or in-finite verb forms:(1) Typical personal style constructions:a. I found 20 albums.b.
You have 20 albums.c.
Please search for albums by The Beatles.
(2) Typical impersonal style constructions:a.
20 albums have been found.b.
There are 20 albums.c.
The database contains 20 albums.d.
20 albums found.The designer of a dialogue system has the choiceto make it manifest (its own and the user?s) agen-tivity linguistically through the use of personal con-structions or not.Previous experiments with simulated systemshave shown that a natural language interface witha synthesized voice should not say ?I?
(Nass andBrave, 2005) and that users align the style of theirinput to that of the system output (Brennan andOhaeri, 1994).
(See Section 2 for more detail.
)The dialogue system SAMMIE developed in theTALK project (Becker et al, 2007) can use either per-sonal or impersonal output style.
In personal style, itgenerates constructions making explicit reference tothe agent (both the user and the system itself), suchas (1a?1c); in impersonal style, it avoids explicit ref-erence to any agent, as in (2a?2d).
The system canbe set either to use one style consistently throughouta dialogue session, or to align to the user?s style, i.e.,mimic the user?s style on a turn-by-turn basis.Inspired by the earlier results obtained with sim-ulated systems (Nass and Brave, 2005; Brennan and190Ohaeri, 1994), we ran an experiment to test the ef-fects of style manipulation in the SAMMIE system.In this paper, we compare two versions of the sys-tem, one using consistently the personal output styleand the other the impersonal style.
We designedour experiment to test (i) whether the users?
judg-ments of the system?s usability and performance dif-fer among the system versions using the personal vs.impersonal style, and (ii) whether users align to thesystem style.In Section 2 we review previous experiments con-cerning the effect of system output style on users?judgments and style.
We describe our own experi-ment in Section 3, present the results in Section 4,and provide a discussion and conclusions in Sec-tion 5.2 Previous Work(Nass and Brave, 2005) address the issue whether avoice interface should say ?I?
by investigating sev-eral dimensions of user attitudes to their simulatedsystem with a synthetic vs. recorded voice.
Gen-erally, agents that use ?I?
are perceived more likea person than those that do not.
However, systemstend to be more positively rated when consistentwith respect to such parameters as personality, gen-der, ontology (human vs. machine), etc.
A systemwith a recorded voice is perceived as more human-like and thus entitled to the use of ?I?, whereas asynthetic-voice interface is not perceived as humanenough to use ?I?
to refer to itself (Nass et al, 2006).Another question is whether system output styleinfluences users?
input formulation, as would be ex-pected due to the phenomenon of alignment, whichis generally considered a basic principle in naturallanguage dialogue (Garrod and Pickering, 2004).1Experiments targeting human-human conversa-tion show that in spite of the variety of linguisticexpressions available, speakers in spontaneous dia-logues tend to express themselves in similar ways atlexical and syntactic levels.
For example, the sur-face form of a question can affect the format of theanswer: the question ?What time do you close??
willmore likely get the response ?Five o?clock?
than?At1This dialogue phenomenon goes under a variety of terms inthe literature, besides alignment, e.g., accommodation, adapta-tion, convergence, entrainment or shaping (used, e.g., by (Bren-nan and Ohaeri, 1994)).five o?clock?.
On the other hand, ?At five o?clock?is a more probable answer to ?At what time do youclose??
(Levelt and Kelter, 1982).
There is evi-dence that alignment happens automatically as a re-sult of priming, e.g., (Hadelich et al, 2004) for lexi-cal alignment.Lexical and syntactic alignment is present inhuman-computer interaction, too.
(Brennan, 1996)suggested that users adopt system?s terms to avoiderrors, expecting the system to be inflexible.
How-ever, recent experiments show that alignment inhuman-computer interaction is also automatic andits strength is comparable to that in human-humancommunication (Branigan et al, 2003; Pearson etal., 2006).Early results concerning users?
alignment to sys-tem output style in the interpersonal dimension arereported in (Brennan and Ohaeri, 1994): They dis-tinguish three styles: anthropomorphic (the systemrefers to itself using first person pronouns, like in(1a) above, fluent (complete sentences, but no self-reference) and telegraphic, like (2d).
They found nodifference in users?
perception of the system?s in-telligence across the different conditions.
However,they observed that the anthropomorphic group wasmore than twice as likely to refer to the computerusing the second person pronoun ?you?
and it usedmore indirect requests and conventional politenessthen the other groups.
They concluded that the an-thropomorphic style is undesirable for dialogue sys-tems because it encourages more complex user inputwhich is harder to recognize and interpret.The described experiments used either theWizard-of-Oz paradigm (Brennan, 1996) or prepro-grammed system output (Branigan et al, 2003; Nassand Brave, 2005) and involved written communica-tion.
Such methods allow one to test assumptionsabout idealized human-computer interaction.
Thepurpose of our experiment was to test whether sim-ilar effects arise in an interaction with an actual di-alogue system, which may be plagued, among otherfactors, by speech recognition problems.3 ExperimentDialogue System We used the SAMMIE in-car sys-tem developed in the TALK project (Becker et al,2006; Becker et al, 2007).
SAMMIE provides a mul-191timodal interface to an MP3 player through speechand haptic input with a button which can be turned,pushed down and pushed sideways in four direc-tions.
System output is by speech and a graphicaldisplay.
The user can perform a range of tasks: con-trol the MP3 player (play/stop/pause playing song,next/previous/go-to track, turn shuffle mode on/off),search and browse by looking for various fields inthe MP3 database (song, artist, album, etc.
), searchand select playlists, edit them or construct new ones.The SAMMIE system was designed with the aimto support natural, intuitive mixed-initiative interac-tion.
Input can be given through any modality atany point and is not restricted to answers to sys-tem queries: the user can initiate new tasks as wellas give any information relevant to the current taskat any time.
A sample interaction is shown below(Becker et al, 2006).
(3) U: Show me the Beatles albums.S: I have these four Beatles albums.
[shows a listof album names]U: Which songs are on this one?
[selects the RedAlbum]S: The Red Album contains these songs [shows alist of the songs]U: Play the third one.S: [song ?From Me To You?
plays]The SAMMIE system has a German and an En-glish version which both provide the same function-ality.
The experiment employed the German ver-sion.
See (Kruijff-Korbayova?
et al, 2008) for a de-scription of the natural language generation module.Setup Figure 1 shows a picture of the experimentsetup.
To simulate the driving situation, we usedthe ?3D-Fahrschule?
software.2 The driving simu-lator visuals were projected on a wall-sized back-projection screen.
The graphical interface of theSAMMIE system was shown on a display next to thesteering wheel.
Participants wore headphones witha microphone for the spoken input and output.
Thebutton for manual input was positioned to the rightof their chair.
The experimenter was sitting in an ad-jacent room and could see and hear everything hap-pening in the experiment lab.
The subjects could not2http://www.3d-fahrschule.de/index.htmFigure 1: Experiment setupsee the experimenter, but heard her instructions, in-cluding the task assignments, from loudspeakers.
Ifnecessary, the subjects were able to talk to the ex-perimenter.Participants A total of 28 participants were paidto take part in the experiment.
All were native Ger-man speakers, 22 female and 6 male, 22 students ofthe Saarland University and 6 employees.
All buttwo participants had a driver?s license and 20 partic-ipants reported driving more than 500km a year.
10participants had previous experience with a drivingsimulation and 6 had used a dialogue system before.Each participant was assigned to one style condition,14 to personal and 14 to impersonal style.
To ensureas even a distribution as possible, there were 11 fe-male and 3 male participants in each style condition,one of whom was a non-driver.
There were 4 em-ployees in impersonal style condition and 2 in thepersonal one.Procedure Each participant was welcomed by theexperimenter, seated in the experiment lab, andgiven brief written instructions concerning the driv-ing simulator, the SAMMIE system and the evalua-tion procedure.
The participants were instructed touse mainly spoken input to accomplish the tasks, al-though they were allowed to use manual input, too.The participants first made a ca.
2-minute driveto get familiar with the driving simulator.
Then theywere asked to chose a destination city (Amsterdam,Madrid or London) and drive there on a highway.During the driving, the experimenter successively192read to the participant 2 trial tasks and 11 experi-mental tasks to be solved using the SAMMIE system.The tasks involved exploring the contents of adatabase of about 25 music albums and were of fourtypes: (1) finding some specified title(s); (2) select-ing some title(s) satisfying certain constraints; (3)manipulating the playlists by adding or removingsongs and (4) free-use of the system.The experimental tasks were presented to eachparticipant in randomized order apart from the freeuse of the system, which was always the last task.To avoid priming by the style of the task formula-tion, and to help the participants memorize the task,the experimenter (E) repeated each task assignmenttwice to the participant, once in personal and oncein impersonal style, as shown in the example below.
(4) E: Bitte frage das System nach den Liedern von?Pur?.
Du willst also wissen welche Lieder von?Pur?
es gibt.E: Please ask the the system about the songs by?Pur?.
You would like to know which songs by?Pur?
there are.The time the participants spent completing the in-dividual tasks was not constrained.
It took themabout 40 minutes to complete all the tasks.Afterwards, each participant was asked to fill in aquestionnaire about their attitudes towards the sys-tem, consisting of questions with a 6-point scaleranging from 1 (low grade) to 6 (high grade).
Thequestions were a subset of those used in (Nass andBrave, 2005) and (Mutschler et al, 2007), for ex-ample: How do you assess the system in general:technical (1) ?
human-like (6); Communication withthe system seemed to you: boring (1) ?
exciting (6);In terms of usability, the system is: inefficient (1)?efficient(6).Upon completing the questionnaire, the partici-pant was paid and discharged.Collected data The questionnaire responses havebeen tabulated and the dialogues of the subjects withthe system have been recorded and transcribed.3The utterances of the participants (on average 95per session) were subsequently manually anno-tated with the following features for further analysis:3We did not record the data from the driving simulator.?
Construction type:Personal (+/-) Is the utterance a complete sen-tence in active voice or imperative formImpersonal (+/-) Is the utterance expressedby passive voice, infinite verb form (e.g.,?Lied abspielen?
(lit.
?song play?
)), or ex-pletive ?es-gibt?
(?there-is?)
constructionTelegraphic (+/-) Is the utterance expressedby a phrase, e.g., ?weiter?
(?next?)?
Personal pronouns: (+/-) Does the utterancecontain a first or second person pronoun?
Politeness marking: (+/-) Does the utterancecontain a politeness marker, such as ?bitte?(?please?
), ?danke?
(?thanks?)
and verbs insubjunctive mood (eg.
?ich ha?tte gerne?
)4 Results4.1 Style and Users?
AttitudesThe first issue addressed in the experiment waswhether the users have different judgments of thepersonal vs. impersonal version of the system.
Sincethe system used a synthetic voice, the judgmentswere expected to be more positive in the impersonalstyle condition (Nass and Brave, 2005).
Based onfactor analysis performed on attitudinal data fromthe user questionnaires we created the six indiceslisted below.
All indices were meaningful and re-liable1.
General satisfaction with the communicationwith the system was composed of 3 pairs ofadjectives describing communication with thesystem: disappointing/motivating, uninterest-ing/interesting and boring/exciting (Cronbach?s?=0.86; t(26)=0.29, p=0.39 (one-tailed))2.
Ease of communication with the system com-prised 5 parameters: naturalness of the commu-nication with the system, formality/informalityand indifference/sympathy of the system?scommunicative style, participants feelings dur-ing the conversation: tensed/relaxed and pleas-ant/unpleasant (?=0.83; t(26)=0.00, p=0.5(one-tailed))3.
Usability of the system consisted of 1pair of adjectives referring to the success193Figure 2: Perceived humanness of the system dependingon system output styleof communication with the system: un-successful/successful, and 4 pairs of adjec-tives describing the usability of the sys-tem: unpractical/practical, inefficient/efficient,complicated/simple, inconvenient/convenient(?=0.76; t(26)=0.08, p=0.47 (one-tailed))4.
Clarity of the system?s speech comprised 2pairs of adjectives describing the system?sspeech: unpredictable/predictable and confus-ing/clear (?=0.88; t(25)=0.87, p=0.2 (one-tailed))5.
Perceived ?humanness?
of the system wascomposed of 3 parameters: perceived tech-nicality/humanness, perceived unfriend-liness/friendliness and attributed conser-vatism/innovation (?=0.69; t(25)=1.64, p=0.06(one-tailed))6.
System?s perceived flexibility and creativitycomprised 3 parameters: rigidness/flexibilityof system?s speech, perceived creativity of thesystem and intelligence attributed to the system(?=0.78; t(26)=0.40, p=0.35 (one-tailed))We did not find any significant influence of sys-tem output style on users?
attitudes.
The only in-dex with a weak tendency in the predicted directionis perceived humanness of the system (t(25)=1.64,p=.06 (one-tailed); see Figure 2).
This goes in linewith the earlier observation that an interface thatrefers to itself by means of a personal pronoun isperceived to be more human-like than one that doesFigure 3: Distribution chart for syntactic constructiontypes in user utterances depending on system output stylenot (Nass and Brave, 2005).4.2 Style and AlignmentThe next issue we investigated was whether the usersformulated their input differently with the personalvs.
impersonal system version.
For each dialoguesession, we calculated the percentage of utterancescontaining the feature of interest relative to the totalnumber of user utterances in the session.First we analyzed the distribution of personal,impersonal and telegraphic constructions across thepersonal and impersonal style conditions.
(The rea-son we separated telegraphic constructions is be-cause they seem to be neutral with respect to style.
)We compared the means of the obtained numbers be-tween the two style conditions.
Figure 3 shows thedistribution of the types of syntactic constructionsacross the system output style conditions.1.
We expected the participants to use more per-sonal constructions with the personal style ver-sion of the system.
Independent samples t-test showed a significant result in the predicteddirection (t(19)=1.8, p=0.05 (one-tailed); seeFigure 3).2.
We expected to find the reverse effect withregard to the proportion of impersonal verbforms: participants using the personal style194version of the system were expected to haveless infinite, passive and ?es-gibt?
forms thanthose in the impersonal style condition.
How-ever, we did not find any significant differencebetween the two style conditions (t(26)=1.0,p=0.17 (one-tailed)).3.
According to expectation we also did not findany significant difference in the proportion oftelegraphic constructions per style condition(t(26)=1.4, p=0.09 (one-tailed)).4.
In the impersonal style condition we founda significantly lower proportion of verb-containing utterances than utterances in tele-graphic form (t(13)=3.5, p=0.00 (one-tailed)).But in the personal style condition there was nostatistically significant difference (t(13)=0.7,p=0.25 (one-tailed)).Next we analyzed the distribution of first and sec-ond person pronouns across style conditions.
We ex-pected to find more personal pronouns in personalthan in impersonal style condition (Brennan andOhaeri, 1994).
However, the results showed no sta-tistically significant difference (t(26)=0.67, p=0.25(one-tailed)).Another prediction based on (Brennan andOhaeri, 1994) was to find more politeness markersin the personal style.
However, the analysis showedthat participants in the personal style condition didnot use significantly more politeness markers thanthose in the impersonal style condition (t(20)=1.06,p=0.15 (one-tailed)).Finally, (Brennan and Ohaeri, 1994) predictedthat personal style, being more flexible, might causemore speech recognition problems than input in im-personal style.
We checked whether participants inthe personal style condition had a higher rate of un-recognized utterances than those in the impersonalstyle condition and found no significant difference(t(26)=0.60, p = 0.28 (one-tailed)).To summarize, we observed a significant differ-ence in the number of personal constructions acrossstyle conditions, in accordance with the expectationbased on style alignment in terms of agentivity.
Butwe did not find a significant difference in the distri-bution of impersonal constructions across style con-ditions.
Not surprisingly, there was also no signifi-cant difference in the distribution of telegraphic con-structions.
An unexpected finding was the higherproportion of telegraphic constructions than verb-containing ones within the impersonal style condi-tion.
However, the personal style condition showedno significant effect.
Contrary to expectations, wealso did not find any significant effect of style-manipulation on the number of personal pronouns,nor on the number of politeness markers.4.3 Style Alignment over TimeSince alignment can also be seen as a process ofgradual adjustment among dialogue participants inthe course of their interaction, we were interestedin whether participants tended to converge to usingparticular constructions as their session with the sys-tem progressed.
For each participant we divided thetranscribed conversation in two halves.
Using pairedsamples t-test, we compared the proportion of per-sonal, impersonal and telegraphic constructions inthe first and second halves of the conversations forboth style conditions.In the personal style condition, we found no sig-nificant change in the usage of construction typesbetween the first and the second half of the dialogue.In the impersonal style condition, we did not findany significant difference in the distribution of im-personal and telegraphic constructions either.
How-ever, we found a significant change in the numberof personal constructions (t(13)=2.5, p=0.02 (one-tailed)): The participants cut down on the use of per-sonal constructions in the second half.5 Discussion and ConclusionsWe presented the results of an experiment with thein-car multimodal dialogue system SAMMIE, aimedto test whether we obtain effects similar to earlierfindings concerning the influence of system outputstyle in the interpersonal dimension on the users?subjective judgments of a system (Nass and Brave,2005) as well as their formulation of input (Bren-nan and Ohaeri, 1994).
Although our results are notconclusive, they point at a range of issues for furtherresearch.Regarding users?
attitudes to the system, wefound no significant difference among the styles.This is similar to (Brennan and Ohaeri, 1994) who195found no difference in intelligence attributed to thesystem by the users, but it is at odds with the earlierfinding that a synthetic voice interface was judgedto be more useful when avoiding self-reference bypersonal pronouns (Nass and Brave, 2005).Whereas (Brennan and Ohaeri, 1994) used a flightreservation dialogue system, (Nass and Brave, 2005)used a phone-based auction system which read outan introduction and five object descriptions.
Thereare two points to note: First, the subjects were ex-posed to system output that was a read out contin-uous text rather than turns in an interaction.
Thismay have reinforced the activation of particular stylefeatures.
Second, the auction task may have sensi-bilized the subjects to the distinction between sub-jective (the system?s) vs. objective information pre-sentation, and thus make them more sensitive towhether the system presents itself as an active agentor not.Regarding the question whether users align theirstyle to that of the system, where previous experi-ments showed strong effects of alignment (Brennanand Ohaeri, 1994), our experiment shows some ef-fects, but some of the results seem conflicting.
Onthe one hand, subjects interacting with the personalstyle version of the system used more personal con-structions than those interacting with the impersonalstyle version.
However, subjects in either condi-tion did not show any significant difference with re-spect to the use of impersonal constructions or tele-graphic forms.
We also found a higher proportion oftelegraphic constructions than verb-containing oneswithin the impersonal style condition, but no suchdifference in the personal style.
Finally, when weconsider alignment over time, we find no change inconstruction usage in the personal style, whereas wefind a decrease in the use of personal constructionsin the impersonal style.That there is no difference in the use of tele-graphic constructions across conditions is not sur-prising.
Being just phrasal sentence fragments, theseconstructions are neutral with respect to style.
Butwhy does there seem to be an alignment effect forpersonal constructions and not for others?
One wayof explaining this is that (some of) the constructionsthat we counted as impersonal are common in bothstyles.
Besides their deliberate use as means to avoidexplicit reference to oneself, the constructions typi-cal for impersonal style also have their normal, neu-tral usage, and therefore, some of the utterances thatwe have classified as impersonal style might just beneutral formulations, rather than cases of distancingor ?de-agentivization?.
However, we could not testthis hypothesis, because we have not found a wayto reliably distinguish between neutral and marked,truly impersonal utterances.
This is an issue requir-ing further work.The difference between our results concerningalignment and those of (Brennan and Ohaeri, 1994)is not likely to be due to a difference in the degreeof interactivity (as with (Nass and Brave, 2005)).We now comment on other differences between oursystems, which might have contributed to the differ-ences in results.One aspect where we differ concerns our distinc-tion between personal and impersonal style, both inthe implementation of the SAMMIE system and inthe experiment: We include the presence/absenceof agentivity not only in the system?s reference toitself (akin to (Nass and Brave, 2005) and (Bren-nan and Ohaeri, 1994)), but also in addressing theuser.
This concept of the personal/impersonal dis-tinction was inspired by such differences observedin a study of instructional texts in several languages(Kruijff et al, 1999), where the latter dimension ispredominant.
The present experiment results makeit pertinent that more research into the motives be-hind expressing or suppressing agentivity in both di-mensions is needed.Apart from the linguistic design of the system?soutput, other factors influence users?
behavior andperception of the system, and thus might confoundexperiment results, e.g., functionality, design, er-gonomics, speech synthesis and speech recognition.Earlier experiments reported in (Nass and Brave,2005) suggest that a system with synthesized speechshould be more positively rated when it does notrefer to itself as an active agent by personal con-structions.
Whereas the system used by (Brennanand Ohaeri, 1994) used written interaction, we usedthe MARY text-to-speech synthesis system (Schro?derand Trouvain, 2003) with an MBROLA diphonesynthesizer, which produces an acceptable thoughnot outstanding output quality.
But as discussed ear-lier, contrary to (Nass and Brave, 2005) we have notobserved a difference in the users?
attitudes depend-196ing on style.
It thus remains an open issue what ef-fect speech output quality has on on the users?
atti-tudes and alignment behavior.Regarding a possible influence of speech recogni-tion on our results, we performed a post-hoc analysis(Kruijff-Korbayova?
et al, 2008), which did not re-veal significant differences in user attitudes or align-ment behavior depending on better or worse speechrecognition performance experienced by the users.A future experiment should address the possibilityof an interaction between system style and speechrecognition performance as both factors might be in-fluencing the user simultaneously.One radical difference between our experimentand the earlier ones is that the users of our systemare occupied by the driving task, and therefore onlyhave a limited cognitive capacity left to devote to theinteraction with the system.
This may make themless susceptible to the subtleties of style manipula-tion than would be the case if they were free of othertasks.
A possible future experiment could addressthis issue by including a non-driving condition.Finally, as we pointed out in the introduction,the SAMMIE system can also be used in an style-alignment mode, where it mimics the user?s style onturn-to-turn basis.
We plan to present experimentalresults comparing the alignment-mode with the fixedpersonal/impersonal style in a future publication.AcknowledgmentsThis work was carried out in the TALK project(www.talk-project.org) funded by the EU as projectNo.
IST-507802 within the 6th Framework Program.ReferencesT.
Becker, N. Blaylock, C. Gerstenberger, I.
Kruijff-Korbayova?, A. Korthauer, M. Pinkal, M. Pitz, P. Poller,and J. Schehl.
2006.
Natural and intuitive multimodaldialogue for in-car applications: The SAMMIE system.In Proceedings of ECAI, PAIS Special section.T.
Becker, N. Blaylock, C. Gerstenberger, A. Korthauer,M.
Pitz, P. Poller, J. Schehl, F. Steffens, R. Stegmann,and J. Steigner.
2007.
Deliverable D5.3: In-carshowcase based on TALK libraries.
Technical report,TALK Project, EU FP6, IST-507802.H.
Branigan, M. Pickering, J. Pearson, J. F. McLean, andC.
Nass.
2003.
Syntactic alignment between com-puter and people: the role of belief about mental states.In Proceedings of the Annual Conference of the Cog-nitive Science Society.S.
Brennan and J.O.
Ohaeri.
1994.
Effects of mes-sage style on user?s attribution toward agents.
In Pro-ceedings of CHI?94 Conference Companion HumanFactors in Computing Systems, pages 281?282.
ACMPress.S.
Brennan.
1996.
Lexical entrainment in spontaneousdialogue.
In Proceedings of the International Sympo-sium on Spoken Dialogue (ISSD-96), pages 41?44.S.
Garrod and M. Pickering.
2004.
Why is conversationso easy?
TRENDS in Cognitive Sciences, 8.K.
Hadelich, H. Branigan, M. Pickering, and M. Crocker.2004.
Alignment in dialogue: Effects of feedbackon lexical overlap within and between participants.In Proceedings of the AMLaP Conference.
Aix enProvence, France.G.J.M.
Kruijff, I.
Kruijff-Korbayova?, J. Bateman,D.
Dochev, N. Gromova, T. Hartley, E. Teich,S.
Sharoff, L. Sokolova, and K. Staykova.
1999.Deliverable TEXS2: Specification of elaborated textstructures.
Technical report, AGILE Project, EUINCO COPERNICUS PL961104.I.
Kruijff-Korbayova?, C. Gerstenberger, O. Kukina, andJ.
Schehl.
2008.
Generation of output style variationin the SAMMIE dialogue system.
In Proceedings ofINLG?08, Salt Fork Resort, Ohio.W.J.M.
Levelt and S. Kelter.
1982.
Surface form andmemory in question answering.
Cognitive Psychol-ogy, 14:78?106.H.
Mutschler, F. Steffens, and A. Korthauer.
2007.
De-liverable D6.4: Final report on multimodal experi-ments Part I: Evaluation of the SAMMIE system.
Tech-nical report, TALK Project, EU FP6, IST-507802.C.
Nass and S. Brave, 2005.
Should voice interfaces say?I??
Recorded and synthetic voice interfaces?
claimsto humanity, chapter 10, pages 113?124.
The MITPress, Cambridge.C.
Nass, S. Brave, and L. Takayama.
2006.
Socializingconsistency: from technical homogeneity to humanepitome.
In P. Zhang & D. Galletta (Eds.
), Human-computer interaction in management information sys-tems: Foundations, pages 373?390.
Armonk, NY: M.E.
Sharpe.J.
Pearson, J. Hu, H. Branigan, M. J. Pickering, and C. I.Nass.
2006.
Adaptive language behavior in HCI: howexpectations and beliefs about a system affect users?word choice.
In CHI ?06: Proceedings of the SIGCHIconference on Human Factors in computing systems,pages 1177?1180, New York, NY, USA.
ACM.M.
Schro?der and J. Trouvain.
2003.
The German text-to-speech synthesis system MARY: A tool for research,development and teaching.
International Journal ofSpeech Technology, 6:365?377.197
