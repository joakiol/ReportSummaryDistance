Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 284?292,Sydney, July 2006. c?2006 Association for Computational LinguisticsAutomatic Construction of Predicate-argument Structure Patternsfor Biomedical Information ExtractionAkane Yakushiji?
?
Yusuke Miyao?
Tomoko Ohta?
?Department of Computer Science, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 JAPAN?
School of Informatics, University of ManchesterPOBox 88, Sackville St, MANCHESTER M60 1QD, UK{akane, yusuke, okap, yucca, tsujii}@is.s.u-tokyo.ac.jpYuka Tateisi?
?
Jun?ichi Tsujii?
?AbstractThis paper presents a method of automat-ically constructing information extractionpatterns on predicate-argument structures(PASs) obtained by full parsing from asmaller training corpus.
Because PASsrepresent generalized structures for syn-tactical variants, patterns on PASs are ex-pected to be more generalized than thoseon surface words.
In addition, patternsare divided into components to improverecall and we introduce a Support VectorMachine to learn a prediction model usingpattern matching results.
In this paper, wepresent experimental results and analyzethem on how well protein-protein interac-tions were extracted from MEDLINE ab-stracts.
The results demonstrated that ourmethod improved accuracy compared to amachine learning approach using surfaceword/part-of-speech patterns.1 IntroductionOne primitive approach to Information Extrac-tion (IE) is to manually craft numerous extrac-tion patterns for particular applications and thisis presently one of the main streams of biomedi-cal IE (Blaschke and Valencia, 2002; Koike et al,2003).
Although such IE attempts have demon-strated near-practical performance, the same setsof patterns cannot be applied to different kinds ofinformation.
A real-world task requires severalkinds of IE, thus manually engineering extractionCurrent Affiliation:?
FUJITSU LABORATORIES LTD.?
Faculty of Informatics, Kogakuin Universitypatterns, which is tedious and time-consumingprocess, is not really practical.Techniques based on machine learning (Zhou etal., 2005; Hao et al, 2005; Bunescu and Mooney,2006) are expected to alleviate this problem inmanually crafted IE.
However, in most cases, thecost of manually crafting patterns is simply trans-ferred to that for constructing a large amount oftraining data, which requires tedious amount ofmanual labor to annotate text.To systematically reduce the necessary amountof training data, we divided the task of construct-ing extraction patterns into a subtask that generalnatural language processing techniques can solveand a subtask that has specific properties accord-ing to the information to be extracted.
The formersubtask is of full parsing (i.e.
recognizing syntacticstructures of sentences), and the latter subtask is ofconstructing specific extraction patterns (i.e.
find-ing clue words to extract information) based on theobtained syntactic structures.We adopted full parsing from various levelsof parsing, because we believe that it offers thebest utility to generalize sentences into normal-ized syntactic relations.
We also divided patternsinto components to improve recall and we intro-duced machine learning with a Support VectorMachine (SVM) to learn a prediction model us-ing the matching results of extraction patterns.
Asan actual IE task, we extracted pairs of interactingprotein names from biomedical text.2 Full Parsing2.1 Necessity for Full ParsingA technique that many previous approaches haveused is shallow parsing (Koike et al, 2003; Yaoet al, 2004; Zhou et al, 2005).
Their assertion is284Distance Count (%) Sum (%)?1 54 5.0 5.00 8 0.7 5.71 170 15.7 21.42?5 337 31.1 52.56?10 267 24.6 77.111?
248 22.9 100.0Distance ?1 means protein word has been annotated as in-teracting with itself (e.g.
?actin polymerization?).
Distance 0means words of the interacting proteins are directly next toone another.
Multi-word protein names are concatenated aslong as they do not cross tags to annotate proteins.Table 1: Distance between Interacting Proteinsthat shallow parsers are more robust and would besufficient for IE.
However, their claims that shal-low parsers are sufficient, or that full parsers donot contribute to application tasks, have not beenfully proved by experimental results.Zhou et al (2005) argued that most informa-tion useful for IE derived from full parsing wasshallow.
However, they only used dependencytrees and paths on full parse trees in their experi-ment.
Such structures did not include informationof semantic subjects/objects, which full parsingcan recognize.
Additionally, most relations theyextracted from the ACE corpus (Linguistic DataConsortium, 2005) on broadcasts and newswireswere within very short word-distance (70% wheretwo entities are embedded in each other or sep-arated by at most one word), and therefore shal-low information was beneficial.
However, Table 1shows that the word distance is long between in-teracting protein names annotated on the AImedcorpus (Bunescu and Mooney, 2004), and we haveto treat long-distance relations for information likeprotein-protein interactions.Full parsing is more effective for acquiring gen-eralized data from long-length words than shallowparsing.
The sentences at left in Figure 1 exem-plify the advantages of full parsing.
The gerund?activating?
in the last sentence takes a non-localsemantic subject ?ENTITY1?, and shallow parsingcannot recognize this relation because ?ENTITY1?and ?activating?
are in different phrases.
Full pars-ing, on the other hand, can identify both the sub-ject of the whole sentence and the semantic subjectof ?activating?
have been shared.2.2 Predicate-argument StructuresWe applied Enju (Tsujii Laboratory, 2005a) asa full parser which outputs predicate-argumentstructures (PASs).
PASs are well normalizedforms that represent syntactic relations.
Enjuis based on Head-driven Phrase Structure Gram-mar (Sag and Wasow, 1999), and it has beentrained on the Penn Treebank (PTB) (Marcus etal., 1994) and a biomedical corpus, the GENIATreebank (GTB) (Tsujii Laboratory, 2005b).
Weused a part-of-speech (POS) tagger trained on theGENIA corpus (Tsujii Laboratory, 2005b) as apreprocessor for Enju.
On predicate-argument re-lations, Enju achieved 88.0% precision and 87.2%recall on PTB, and 87.1% precision and 85.4% re-call on GTB.The illustration at right in Figure 1 is a PASexample, which represents the relation between?activate?, ?ENTITY1?
and ?ENTITY2?
of all sen-tences to the left.
The predicate and its argu-ments are words converted to their base forms,augmented by their POSs.
The arrows denotethe connections from predicates to their argumentsand the types of arguments are indicated as arrowlabels, i.e., ARGn (n = 1, 2, .
.
.
), MOD.
For ex-ample, the semantic subject of a transitive verb isARG1 and the semantic object is ARG2.What is important here is, thanks to the strongnormalization of syntactic variations, that we canexpect that the construction algorithm for extract-ing patterns that works on PASs will need a muchsmaller training corpus than those working onsurface-word sequences.
Furthermore, because ofthe reduced diversity of surface-word sequences atthe PAS level, any IE system at this level shoulddemonstrate improved recall.3 Related WorkSudo et al (2003), Culotta and Sorensen (2004)and Bunescu and Mooney (2005) acquired sub-structures derived from dependency trees as ex-traction patterns for IE in general domains.
Theirapproaches were similar to our approach usingPASs derived from full parsing.
However, oneproblem with their systems is that they couldnot treat non-local dependencies such as seman-tic subjects of gerund constructions (discussed inSection 2), and thus rules acquired from the con-structions were partial.Bunescu and Mooney (2006) also learned ex-traction patterns for protein-protein interactionsby SVM with a generalized subsequence kernel.Their patterns are sequences of words, POSs, en-tity types, etc., and they heuristically restrictedlength and word positions of the patterns.
Al-285ENTITY1 recognizes and activates ENTITY2.ENTITY2 activated by ENTITY1 are not well characterized.The herpesvirus encodes a functional ENTITY1 that activates human ENTITY2.ENTITY1 can functionally cooperate to synergistically activate ENTITY2.The ENTITY1 plays key roles by activating ENTITY2.ENTITY1/NNactivate/VB ENTITY2/NNARG1 ARG2Figure 1: Syntactical Variations of ?activate?though they achieved about 60% precision andabout 40% recall, these heuristic restrictions couldnot be guaranteed to be applied to other IE tasks.Hao et al (2005) learned extraction patternsfor protein-protein interactions as sequences ofwords, POSs, entity tags and gaps by dynamicprogramming, and reduced/merged them using aminimum description length-based algorithm.
Al-though they achieved 79.8% precision and 59.5%recall, sentences in their test corpus have toomany positive instances and some of the pat-terns they claimed to have been successfully con-structed went against linguistic or biomedical in-tuition.
(e.g.
?ENTITY1 and interacts with EN-TITY2?
should be replaced by a more general pat-tern because they aimed to reduce the number ofpatterns.
)4 MethodWe automatically construct patterns to extractprotein-protein interactions from an annotatedtraining corpus.
The corpus needs to be tagged todenote which protein words are interacting pairs.We follow five steps in constructing extractionpatterns from the training corpus.
(1) Sentencesin the training corpus are parsed into PASs andwe extract raw patterns from the PASs.
(2) Wedivide the raw patterns to generate both combi-nation and fragmental patterns.
Because obtainedpatterns include inappropriate ones (wrongly gen-erated or too general), (3) we apply both kinds ofpatterns to PASs of sentences in the training cor-pus, (4) calculate the scores for matching resultsof combination patterns, and (5) make a predictionmodel with SVM using these matching results andscores.We extract pairs of interacting proteins from atarget text in the actual IE phase, in three steps.
(1) Sentences in the target corpus are parsed intoPASs.
(2) We apply both kinds of extraction pat-terns to these PASs and (3) calculate scores forcombination pattern matching.
(4) We use the pre-diction model to predict interacting pairs.ENTITY1ENTITY2CD4/NN protein/NNinteract/VBwith/IN polymorphic/JJregion/NNof/INMHCII/NNMOD ARG1 ARG1 ARG2 ARG1 ARG2ARG1Parsing ResultRaw PatternCD4 protein interacts with polymorphic regions of MHCII .ENTITY1ENTITY2Sentence in Training Corpusprotein/NNinteract/VBwith/INregion/NNof/INMOD ARG1 ARG1 ARG2 ARG1 ARG2(1) (2) (3) (4) (5) (6)p0p1p2p3p4p5p6ENTITY2/NNENTITY1/NNFigure 2: Extraction of Raw Pattern4.1 Full Parsing and Extraction of RawPatternsAs the first step in both the construction phase andapplication phase of extraction patterns, we parsesentences into PASs using Enju.1 We label allPASs of the protein names as protein PASs.After parsing, we extract the smallest set ofPASs, which connect words that denote interact-ing proteins, and make it a raw pattern.
We takethe same method to extract and refine raw patternsas Yakushiji et al (2005).
Connecting means wecan trace predicate-argument relations from oneprotein word to the other in an interacting pair.The procedure to obtain a raw pattern (p0, .
.
.
, pn)is as follows:predicate(p): PASs that have p as their argumentargument(p): PASs that p has as its arguments1.
pi = p0 is the PAS of a word correspondentto one of interacting proteins, and we obtaincandidates of the raw pattern as follows:1-1.
If pi is of the word of the other interact-ing protein, (p0, .
.
.
, pi) is a candidateof the raw pattern.1-2.
If not, make pattern candidatesfor each pi+1 ?
predicate(pi) ?argument(pi) ?
{p0, .
.
.
, pi} byreturning to 1-1.2.
Select the pattern candidate of the smallestset as the raw pattern.1Before parsing, we concatenate each multi-word proteinname into the one word as long as the concatenation does notcross name boundaries.2863.
Substitute variables (ENTITY1, ENTITY2) forthe predicates of PASs correspondent to theinteracting proteins.The lower part of Figure 2 shows an exampleof the extraction of a raw pattern.
?CD4?
and?MHCII?
are words representing interacting pro-teins.
First, we set the PAS of ?CD4?
as p0.argument(p0) includes the PAS of ?protein?, andwe set it as p1 (in other words, tracing the arrow(1)).
Next, predicate(p1) includes the PAS of ?in-teract?
(tracing the arrow (2) back), so we set itas p2.
We continue similarly until we reach thePAS of ?MHCII?
(p6).
The result of the extractedraw pattern is the set of p0, .
.
.
, p6 with substitut-ing variables ENTITY1 and ENTITY2 for ?CD4?and ?MHCII?.There are some cases where an extracted rawpattern is not appropriate and we need to re-fine it.
One case is when unnecessary coordi-nations/parentheses are included in the pattern,e.g.
two interactions are described in a combinedrepresentation (?ENTITY1 binds this protein andENTITY2?).
Another is when two interacting pro-teins are connected directly by a conjunction oronly one protein participates in an interaction.
Insuch cases, we refine patterns by unfolding of co-ordinations/parentheses and extension of patterns,respectively.
We have omitted detailed explana-tions because of space limitations.
The details aredescribed in the work of Yakushiji et al (2005).4.2 Division of PatternsDivision for generating combination patterns isbased on observation of Yakushiji et al (2005) thatthere are many cases where combinations of verbsand certain nouns form IE patterns.
In the workof Yakushiji et al (2005), we divided only patternsthat include only one verb.
We have extended thedivision process to also treat nominal patterns orpatterns that include more than one verb.Combination patterns are not appropriate forutilizing individual word information because theyare always used in rather strictly combined ways.Therefore we have newly introduced fragmentalpatterns which consist of independent PASs fromraw patterns, in order to use individual word infor-mation for higher recall.4.2.1 Division for Generating CombinationPatternsRaw patterns are divided into some compo-nents and the components are combined to con-ENTITY1/NN protein/NN interact/VBwith/IN region/NNof/INENTITY2/NNMOD ARG1 ARG1 ARG2 ARG1 ARG2*/VBwith/INARG1ARG2*/NNENTITY/NNprotein/NNMODregion/NN of/INENTITY/NNARG1ARG2interact/VBARG1=*/NN*/VBARG1*/NN=$X$XMainPrepEntityEntityEntityMainEntity MainMainEntityRaw PatternCombination PatternFigure 3: Division of Raw Pattern into Combina-tion Pattern Components (Entity-Main-Entity)struct combination patterns according to types ofthe division.
There are three types of division ofraw patterns for generating combination patterns.These are:(a) Two-entity Division(a-1) Entity-Main-Entity Division(a-2) Main-Entity-Entity Division(b) Single-entity Division, and(c) No Division (Naive Patterns).Most raw patterns, where entities are at bothends of the patterns, are divided into Entity-Main-Entity.
Main-Entity-Entity are for the cases wherethere are PASs other than entities at the ends ofthe patterns (e.g.
?interaction between ENTITY1and ENTITY2?).
Single-entity is a special Main-Entity-Entity for interactions with only one partic-ipant (e.g.
?ENTITY1 dimerization?
).There is an example of Entity-Main-Entity divi-sion in Figure 3.
First, the main component fromthe raw pattern is the syntactic head PAS of theraw pattern.
If the raw pattern corresponds to asentence, the syntactic head PAS is the PAS of themain verb.
We underspecify the arguments of themain component, to enable them to unify with thePASs of any words with the same POSs.
Next, ifthere are PASs of prepositions connecting to themain component, they become prep components.If there is no PAS of a preposition next to the maincomponent on the connecting link from the maincomponent to an entity, we make the pseudo PASof a null preposition the prep component.
The leftprep component ($X) in Figure 3 is a pseudo PASof a null preposition.
We also underspecify the ar-guments of prep components.
Finally, the remain-ing two parts, which are typically noun phrases, ofthe raw pattern become entity components.
PASs287corresponding to the entities of the original pairare labeled as only unifiable with the entities ofother pairs.Main-Entity-Entity division is similar, exceptwe distinguish only one prep component as adouble-prep component and the PAS of the coor-dinate conjunction between entities becomes thecoord component.
Single-entity division is simi-lar to Main-Entity-Entity division and the differ-ence is that single-entity division produces no co-ord and one entity component.
Naive patterns arepatterns without division, where no division can beapplied (e.g.
?ENTITY1/NN in/IN complexes/NNwith/IN ENTITY2/NN?
).All PASs on boundaries of components are la-beled to determine which PAS on a boundary ofanother component can be unified.
Labels are rep-resented by subscriptions in Figure 3.
These re-strictions on component connection are used in thestep of constructing combination patterns.Constructing combination patterns by combin-ing components is equal to reconstructing orig-inal raw patterns with the original combinationof components, or constructing new raw patternswith new combinations of components.
For exam-ple, an Entity-Main-Entity pattern is constructedby combination of any main, any two prep and anytwo entity components.
Actually, this constructionprocess by combination is executed in the patternmatching step.
That is, we do not off-line con-struct all possible combination patterns from thecomponents and only construct the combinationpatterns that are able to match the target.4.2.2 Division for Generating FragmentalPatternsA raw pattern is splitted into individual PASsand each PAS becomes a fragmental pattern.
Wealso prepare underspecified patterns where one ormore of the arguments of the original are under-specified, i.e., are able to match any words ofthe same POSs and the same label of protein/not-protein.
We underspecify the PASs of entities infragmental patterns to enable them to unify withany PASs with the same POSs and a protein la-bel, although in combination patterns we retain thePASs of entities as only unifiable with entities ofpairs.
This is because fragmental patterns are de-signed to be less strict than combination patterns.4.3 Pattern MatchingMatching of combination patterns is executed asa process to match and combine combination pat-tern components according to their division types(Entity-Main-Entity, Main-Entity-Entity, Single-entity and No Division).
Fragmental matching ismatching all fragmental patterns to PASs derivedfrom sentences.4.4 Scoring for Combination MatchingWe next calculate the score of each combinationmatching to estimate the adequacy of the combina-tion of components.
This is because new combina-tion of components may form inadequate patterns.(e.g.
?ENTITY1 be ENTITY2?
can be formed ofcomponents from ?ENTITY1 be ENTITY2 recep-tor?.)
Scores are derived from the results of com-bination matching to the source training corpus.We apply the combination patterns to the train-ing corpus, and count pairs of True Positives (TP)and False Positives (FP).
The scores are calculatedbasically by the following formula:Score = TP/(TP + FP ) + ?
?
TPThis formula is based on the precision of the pat-tern on the training corpus, i.e., an estimated pre-cision on a test corpus.
?
works for smoothing,that is, to accept only patterns of large TP whenFP = 0. ?
is set as 0.01 empirically.
The formulais similar to the Apriori algorithm (Agrawal andSrikant, 1995) that learns association rules from adatabase.
The first term corresponds to the confi-dence of the algorithm, and the second term corre-sponds to the support.For patterns where TP = FP = 0, whichare not matched to PASs in the training corpus(i.e., newly produced by combinations of com-ponents), we estimates TP ?
and FP ?
by usingthe confidence of the main and entity compo-nents.
This is because main and entity componentstend to contain pattern meanings, whereas prep,double-prep and coord components are ratherfunctional.
The formulas to calculate the scoresfor all cases are:Score =8>>><>>>:TP/(TP + FP ) + ?
?
TP(TP + FP ?= 0)TP ?/(TP ?
+ FP ?
)(TP = FP = 0, TP ?
+ FP ?
?= 0)0 (TP = FP = TP ?
= FP ?
= 0)288Combination Pattern(1) Combination of components in combinationmatching(2) Main component in combination matching(3) Entity components in combination matching(4) Score for combination matching (SCORE)Fragmental Pattern(5) Matched fragmental patterns(6) Number of PASs of example that are not matchedin fragmental matchingRaw Pattern(7) Length of raw pattern derived from exampleTable 2: Features for SVM Learning of PredictionModelTP ?
=8><>:TP ?main + TP ?entity1(+TP ?entity2)(for Two-entity, Single-entity)0 (for Naive)FP ?
= (similar to TP ?
but TP ?x is replaced by FP ?x)TP ?main =8>>>>><>>>>>:TPmain:two/(TPmain:two + FPmain:two)TPmain:two + FPmain:two ?= 0,for Two-entity!TPmain:single/(TPmain:single + FPmain:single)TPmain:single + FPmain:single ?= 0,for Single-entity!0 (other cases)TP ?entityi =8><>:TPentityi/(TPentityi + FPentityi)?TPentityi + FPentityi ?= 0?0 (other cases)FP ?x =?similar to TP ?x but TP ?y in thenumerators is replaced by FP ?y??
TP : number of TPs by the combination of components?
TPmain:two: sum of TPs by two-entity combinationsthat include the same main component?
TPmain:single: sum of TPs by single-entity combina-tions that include the same main component?
TPentityi: sum of TPs by combinations that includethe same entity component which is not the straight en-tity component?
FPx: similar to TPx but TP is replaced by FPThe entity component ?ENTITY/NN?, whichonly consists of the PAS of an entity, adds no infor-mation to combinations of components.
We callthis component a straight entity component andexclude its effect from the scores.4.5 Construction of Prediction ModelWe use an SVM to learn a prediction model to de-termine whether a new protein pair is interacting.We used SV M light (Joachims, 1999) with an rbfkernel, which is known as the best kernel for mosttasks.
The prediction model is based on the fea-tures of Table 2.0.10.20.30.40.50.60.70.80.910  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1PrecisionRecallALLSCOREERKFigure 4: Results of IE ExperimentENTITY1FGF-2/NNbind well to FGFR1 butinteract/VB with/INpoorly/RBENTITY2KGFR/NNARG1 ARG1 ARG2Figure 5: Example Demonstrating Advantages ofFull Parsing5 Results and Discussion5.1 Experimental Results on the AImedCorpusTo evaluate extraction patterns automatically con-structed with our method, we used the AImed cor-pus, which consists of 225 MEDLINE (U.S. Na-tional Library of Medicine, 2006) abstracts (1969sentences) annotated with protein names andprotein-protein interactions, for the training/testcorpora.
We used tags for the protein names given.We measured the accuracy of the IE task usingthe same criterion as Bunescu andMooney (2006),who used an SVM to construct extraction patternson word/POS/type sequences from the AImed cor-pus.
That is, an extracted interaction from an ab-stract is correct if the proteins are tagged as inter-acting with each other somewhere in that abstract(document-level measure).Figure 4 plots our 10-fold cross validation andthe results of Bunescu and Mooney (2006).
Theline ALL represents results when we used all fea-tures for SVM learning.
The line SCORE repre-sents results when we extracted pairs with highercombination matching scores than various thresh-old values.
And the line ERK represents resultsby Bunescu and Mooney (2006).The line ALL obtained our best overall F-measure 57.3%, with 71.8% precision and 48.4%recall.
Our method was significantly better thanBunescu and Mooney (2006) for precision be-289tween 50% and 80%.
It also needs to be notedthat SCORE, which did not use SVM learningand only used the combination patterns, achievedperformance comparable to that by Bunescu andMooney (2006) for the precision range from 50%to 80%.
And for this range, introducing the frag-mental patterns with SVM learning raised the re-call.
This range of precision is practical for theIE task, because precision is more important thanrecall for significant interactions that tend to bedescribed in many abstracts (as shown by thenext experiment), and too-low recall accompa-nying too-high precision requires an excessivelylarge source text.Figure 5 shows the advantage of introducingfull parsing.
?FGF-2?
and ?KGFR?
is an interact-ing protein pair.
The pattern ?ENTITY1 interactwith ENTITY2?
based on PASs successfully ex-tracts this pair.
However, it is difficult to extractthis pair with patterns based on surface words, be-cause there are 5 words between ?FGF-2?
and ?in-teract?.5.2 Experimental Results on Abstracts ofMEDLINEWe also conducted an experiment to extract in-teracting protein pairs from a large amount ofbiomedical text, i.e.
about 14 million titles and8 million abstracts in MEDLINE.
We constructedcombination patterns from all 225 abstracts of theAImed corpus, and calculated a threshold valueof combination scores that produced about 70%precision and 30% recall on the training corpus.We extracted protein pairs with higher combi-nation scores than the threshold value.
We ex-cluded single-protein interactions to reduce timeconsumption and we used a protein name recog-nizer in this experiment2.We compared the extracted pairs with a man-ually curated database, Reactome (Joshi-Tope etal., 2005), which published 16,564 human pro-tein interaction pairs as pairs of Entrez GeneIDs (U.S. National Library of Medicine, 2006).We converted our extracted protein pairs into pairsof Entrez Gene IDs by the protein name recog-nizer.3 Because there may be pairs missed by Re-2Because protein names were recognized after the pars-ing, multi-word protein names were not concatenated.3Although the same protein names are used for humansand other species, these are considered to be human proteinswithout checking the context.
This is a fair assumption be-cause Reactome itself infers human interaction events fromexperiments on model organisms such as mice.Total 89Parsing Error/Failure 35(Related to coordinations) (14)Lack of Combination Pattern Component 33Requiring Anaphora Resolution 9Error in Prediction Model 8Requiring Attributive Adjectives 5Others 10More than one cause can occur in one error, thus the sum ofall causes is larger than the total number of False Negatives.Table 3: Causes of Error for FNsactome or pairs that our processed text did not in-clude, we excluded extracted pairs of IDs that arenot included in Reactome and excluded Reactomepairs of IDs that do not co-occur in the sentencesof our processed text.After this postprocessing, we found that we hadextracted 7775 human protein pairs.
Of them, 155pairs were also included in Reactome ([a] pseudoTPs) and 7620 pairs were not included in Reac-tome ([b] pseudo FPs).
947 pairs of Reactomewere not extracted by our system ([c] pseudo FalseNegatives (FNs)).
However, these results includedpairs that Reactome missed or those that only co-occurred and were not interacting pairs in the text.There may also have been errors with ID assign-ment.To determine such cases, a biologist investi-gated 100 pairs randomly selected from pairs ofpseudo TPs, FPs and FNs retaining their ratio ofnumbers.
She also checked correctness of the as-signed IDs.
2 pairs were selected from pseudoTPs, 88 pairs were from pseudo FPs and 10 pairswere from pseudo FNs.
The biologist found that57 pairs were actual TPs (2 pairs of pseudo TPsand 55 pairs of pseudo FPs) and 32 pairs were ac-tual FPs of the pseudo FPs.
Thus, the precisionwas 64.0% in this sample set.
Furthermore, evenif we assume that all pseudo FNs are actual FNs,the recall can be estimated by actual TPs / (actualTPs + pseudo FNs) ?
100 = 83.8%.These results mean that the recall of an IE sys-tem for interacting proteins is improved for a largeamount of text even if it is low for a small corpus.Thus, this justifies our assertion that a high degreeof precision in the low-recall range is important.5.3 Error AnalysisTables 3 and 4 list causes of error for FNs/FPs ona test set of the AImed corpus using the predic-tion model with the best F-measure with all the290Total 35Requiring Attributive Adjectives 13Corpus Error 11Error in Prediction Model 5Requiring Negation Words 2Parsing Error 1Others 3Table 4: Causes of Error for FPsfeatures.
Different to Subsection 5.1, we individ-ually checked each occurring pair of interactingproteins.
The biggest problems were parsing er-ror/failure, lack of necessary patterns and learningof inappropriate patterns.5.3.1 Parsing ErrorAs listed in Table 3, 14 (40%) of the 35 pars-ing errors/failures were related to coordinations.Many of these were caused by differences in thecharacteristics of the PTB/GTB, the training cor-pora for Enju, and the AImed Corpus.
For ex-ample, Enju failed to obtain the correct structurefor ?the ENTITY1 / ENTITY1 complex?
becausewords in the PTB/GTB are not segmented with?/?
and Enju could not be trained on such a case.One method to solve this problem is to avoid seg-menting words with ?/?
and introducing extractionpatterns based on surface characters, such as ?EN-TITY1/ENTITY2 complex?.Parsing errors are intrinsic problems to IE meth-ods using parsing.
However, from Table 3, we canconclude that the key to gaining better accuracyis refining of the method with which the PAS pat-terns are constructed (there were 46 related FNs)rather than improving parsing (there were 35 FNs).5.3.2 Lack of Necessary Patterns andLearning of Inappropriate PatternsThere are two different reasons causing theproblems with the lack of necessary patterns andthe learning of inappropriate patterns: (1) thetraining corpus was not sufficiently large to sat-urate IE accuracy and (2) our method of patternconstruction was too limited.Effect of Training Corpus Size To investigatewhether the training corpus was large enough tomaximize IE accuracy, we conducted experimentson training corpora of various sizes.
Figure 6 plotsgraphs of F-measures by SCORE and Figure 7plots the number of combination patterns on train-ing corpora of various sizes.
From Figures 6 and 7,the training corpus (207 abstracts at a maximum)0.350.40.450.50.550  50  100  150  200F-measurebySCORETraining Corpus Size (Number of Abstracts)Figure 6: Effect of Training Corpus Size (1)01002003004005006000  50  100  150  200NumberTraining Corpus Size (Number of Abstracts)Raw Patterns (before division)Main ComponentEntity ComponentOther ComponentNaive PatternFigure 7: Effect of Training Corpus Size (2)is not large enough.
Thus increasing corpus sizewill further improve IE accuracy.Limitation of the Present Pattern Construc-tion The limitations with our pattern construc-tion method are revealed by the fact that wecould not achieve a high precision like Bunescuand Mooney (2006) within the high-recall range.Compared to theirs, one of our problems is that ourmethod could not handle attributives.
One exam-ple is ?binding property of ENTITY1 to ENTITY2?.We could not obtain ?binding?
because the small-est set of PASs connecting ?ENTITY1?
and ?EN-TITY2?
includes only the PASs of ?property?, ?of?and ?to?.
To handle these attributives, we need dis-tinguish necessary attributives from those that aregeneral4 by semantic analysis or bootstrapping.Another approach to improve our method is toinclude local information in sentences, such assurface words between protein names.
Zhao andGrishman (2005) reported that adding local infor-mation to deep syntactic information improved IEresults.
This approach is also applicable to IE inother domains, where related entities are in a short4Consider the case where a source sentence for a pattern is?ENTITY1 is an important homodimeric protein.?
(?homod-imeric?
represents that two molecules of ?ENTITY1?
interactwith each other.
)291distance like the work of Zhou et al (2005).6 ConclusionWe proposed the use of PASs to construct pat-terns as extraction rules, utilizing their ability toabstract syntactical variants with the same rela-tion.
In addition, we divided the patterns for gen-eralization, and used matching results for SVMlearning.
In experiments on extracting of protein-protein interactions, we obtained 71.8% precisionand 48.4% recall on a small corpus and 64.0% pre-cision and 83.8% recall estimated on a large text,which demonstrated the obvious advantages of ourmethod.AcknowledgementThis work was partially supported by Grant-in-Aidfor Scientific Research on Priority Areas ?Sys-tems Genomics?
(MEXT, Japan) and Solution-Oriented Research for Science and Technology(JST, Japan).ReferencesR.
Agrawal and R Srikant.
1995.
Mining SequentialPatterns.
In Proc.
the 11th International Conferenceon Data Engineering, pages 3?14.Christian Blaschke and Alfonso Valencia.
2002.
TheFrame-Based Module of the SUISEKI Informa-tion Extraction System.
IEEE Intelligent Systems,17(2):14?20.Razvan Bunescu and Raymond J. Mooney.
2004.Collective information extraction with relationalmarkov networks.
In Proc.
ACL?04, pages 439?446.Razvan C. Bunescu and Raymond J. Mooney.
2005.
AShortest Path Dependency Kernel for Relation Ex-traction.
In Proc.
HLT/EMNLP 2005, pages 724?731.Razvan Bunescu and Raymond Mooney.
2006.
Subse-quence kernels for relation extraction.
In Advancesin Neural Information Processing Systems 18, pages171?178.
MIT Press.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proc.
ACL?04,pages 423?429.Yu Hao, Xiaoyan Zhu, Minlie Huang, and MingLi.
2005.
Discovering patterns to extract protein-protein interactions from the literature: Part II.Bioinformatics, 21(15):3294?3300.Thorsten Joachims.
1999.
Making Large-Scale SVMLearning Practical.
In Advances in Kernel Methods?
Support Vector Learning.
MIT-Press.G Joshi-Tope, M Gillespie, I Vastrik, P D?Eustachio,E Schmidt, B de Bono, B Jassal, GR Gopinath,GR Wu, L Matthews, S Lewis, E Birney, and SteinL.
2005.
Reactome: a knowledgebase of biologi-cal pathways.
Nucleic Acids Research, 33(DatabaseIssue):D428?D432.Asako Koike, Yoshiyuki Kobayashi, and ToshihisaTakagi.
2003.
Kinase Pathway Database: AnIntegrated Protein-Kinase and NLP-Based Protein-Interaction Resource.
Genome Research, 13:1231?1243.Linguistic Data Consortium.
2005.
ACE Program.http://projects.ldc.upenn.edu/ace/.Mitchell Marcus, Grace Kim, Mary AnnMarcinkiewicz, Robert MacIntyre, Ann Bies,Mark Ferguson, Karen Katz, and Britta Schas-berger.
1994.
The Penn Treebank: Annotatingpredicate argument structure.
In Proc.
AAI ?94.Ivan A.
Sag and Thomas Wasow.
1999.
Syntactic The-ory.
CSLI publications.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An improved extraction pattern representa-tion model for automatic IE pattern acquisition.
InProc.
ACL 2003, pages 224?231.Tsujii Laboratory.
2005a.
Enju - A practical HPSGparser.
http://www-tsujii.is.s.u-tokyo.ac.jp/enju/.Tsujii Laboratory.
2005b.
GENIA Project.http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/.U.S.
National Library of Medicine.
2006.
PubMed.http://www.pubmed.gov.Akane Yakushiji, Yusuke Miyao, Yuka Tateisi, andJun?ichi Tsujii.
2005.
Biomedical information ex-traction with predicate-argument structure patterns.In Proc.
SMBM 2005, pages 60?69.Daming Yao, Jingbo Wang, Yanmei Lu, Nathan No-ble, Huandong Sun, Xiaoyan Zhu, Nan Lin, Don-ald G. Payan, Ming Li, and Kunbin Qu.
2004.
Path-wayFinder: Paving The Way Towards AutomaticPathway Extraction.
In Bioinformatics 2004: Proc.the 2nd APBC, volume 29 of CRPIT, pages 53?62.Shubin Zhao and Ralph Grishman.
2005.
Extractingrelations with integrated information using kernelmethods.
In Proc.
ACL?05, pages 419?426.GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang.2005.
Exploring various knowledge in relation ex-traction.
In Proc.
ACL?05, pages 427?434.292
