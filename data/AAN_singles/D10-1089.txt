Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 913?922,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsWikiWars: A New Corpus for Research on Temporal ExpressionsPawe?
Mazur1,21Institute of Applied Informatics,Wroc?aw University of TechnologyWyb.
Wyspian?skiego 27,50-370 Wroc?aw, Polandpawel@mazur.wroclaw.plRobert Dale22Centre for Language Technology,Macquarie University,NSW 2109, Sydney, AustraliaPawel.Mazur@mq.edu.auRobert.Dale@mq.edu.auAbstractThe reliable extraction of knowledge from textrequires an appropriate treatment of the timeat which reported events take place.
Unfortu-nately, there are very few annotated data setsthat support the development of techniques forevent time-stamping and tracking the progres-sion of time through a narrative.
In this paper,we present a new corpus of temporally-richdocuments sourced from English Wikipedia,which we have annotated with TIMEX2 tags.The corpus contains around 120000 tokens,and 2600 TIMEX2 expressions, thus compar-ing favourably in size to other existing corporaused in these areas.
We describe the prepa-ration of the corpus, and compare the profileof the data with other existing temporally an-notated corpora.
We also report the resultsobtained when we use DANTE, our temporalexpression tagger, to process this corpus, andpoint to where further work is required.
Thecorpus is publicly available for research pur-poses.1 IntroductionThe reliable processing of temporal information isan important step in many NLP applications, suchas information extraction, question answering, anddocument summarisation.
Consequently, the tasksof identifying and assigning values to temporal ex-pressions have recently received significant attention,resulting in the creation of mature corpus annotationguidelines (e.g.
TIMEX21 and TimeML2), publicly1See http://fofoca.mitre.org.2See http://timeml.org.available annotated corpora (ACE,3 TimeBank4) anda number of automatic taggers (see, for example,(Mani and Wilson, 2000; Schilder, 2004; Hacioglu etal., 2005; Negri and Marseglia, 2005; Saquete, 2005;Han et al, 2006; Ahn et al, 2007)).However, existing corpora have their limitations.In particular, the documents in these corpora tend tobe limited in length and, in consequence, discoursestructure.
This impacts on the number, range andvariety of temporal expressions they contain.
Ex-isting research carried out on the interpretation oftemporal expressions, e.g.
by (Baldwin, 2002; Ahnet al, 2005; Mazur and Dale, 2008), suggests thatmany temporal expressions in documents, especiallynews stories, can be interpreted fairly simply as be-ing relative to a reference date that is typically thedocument creation date.
This phenomenon does notcarry over to longer, more narrative-style documentsthat describe extended sequences of events, as found,for example, in biographies or descriptions of pro-tracted geo-political events.
Consequently, existingcorpora are not ideal as development data for systemsintended to work on such historical narrations.In this paper we introduce a new annotated corpusof temporal expressions that is intended to addressthis shortfall.
The corpus, which we call WikiWars,consists of 22 documents from English Wikipediathat describe the historical course of wars.
Despitethe small number of documents, their length meansthat the corpus yields a large number of temporalexpressions, and poses new challenges for tracking3See corpora LDC2005T07 and LDC2006T06 in the LDCcatalogue (http://www.ldc.upenn.edu).4See corpus LDC2006T08 in the LDC catalogue.913temporal focus through extended texts.
The corpushas been made available for others to use;5 to givean indication of the difficulty of processing the tem-poral phenomena in the texts, we also report on theperformance of DANTE, our temporal expressiontagger, on detecting and interpreting the temporalexpressions in the corpus.The rest of this paper is organised as follows.
InSection 2 we describe related work, focusing on theTIMEX2 annotation scheme, and existing corporathat contain annotations of temporal expressions us-ing this scheme.
Section 3 describes the process ofcreation of the WikiWars corpus.
In Section 4 wecomment on some artefacts of Wikipedia articles thatimpact on the annotation process and the use of thiscorpus.
Then, in Section 5 we analyse the differencesbetween the WikiWars corpus and the widely-usedACE corpora.
In Section 6 we report on the perfor-mance of our temporal expression tagger on this dataset.
Finally, in Section 7, we conclude.2 Related WorkAt the time of writing, there are two mature, wide-coverage schemes for the annotation of temporal in-formation in texts: TIMEX2 (Ferro et al, 2005) andTimeML (Pustejovsky et al, 2003; Boguraev et al,2005), which is soon to become an ISO standard(Pustejovsky et al, 2010).These schemes were used to annotate corpora thatare often used in research on temporal expressionrecognition and normalisation: the series of corporaused for training and evaluation in the AutomaticContent Extraction (ACE) program6 run in 2004,2005 and 2007, and the TimeBank Corpus.The ACE corpora were prepared for the devel-opment and evaluation of systems participating inthe ACE program.
However, the evaluation corporahave never been publicly released, and thus are cur-rently, for all practical purposes, unavailable.
TheACE 2004 corpus contains news data only (broad-cast news, newspaper and newswire), while the ACE2005 and 2007 corpora contain news (broadcast andnewswire), conversations (broadcast and telephone),UseNet discussions and web blogs.
The 2005 and2007 ACE corpora are annotated with the latest ver-5See www.TimexPortal.info/WikiWars.6See www.itl.nist.gov/iad/mig/tests/ace.sion of TIMEX2 (2005), while the 2004 corpus isannotated with the older 2003 version of TIMEX2;however, the differences are not very significant.Apart from the unavailability of the evaluationdata, there are two issues with the ACE corpora.
Oneis that most of the documents are relatively short, sothat the average number of temporal expressions perdocument is low (typically between seven and nineper document, including the document time stampas a metadata element).
This results in very lim-ited temporal discourse structure, and relatively fewunderspecified and relative temporal expressions.
Un-fortunately, these are the more difficult temporal ex-pressions to handle, and so the ACE corpora maynot serve as a good baseline for performance moregenerally.A second problem is that the ACE corpora appearto contain a significant number of errors in the goldstandard annotations, with respect to both the anno-tated extents and the semantic values assigned, whichdo not always follow the TIMEX2 guidelines.TimeBank v1.2 is a revised and improved versionof TimeBank 1.1 resulting in a number of errors fixedand inconsistencies removed (see (Boguraev et al,2007)).
Unfortunely, this corpus has the same lim-itations as the ACE corpora in regard to documentlength and complexity of discourse structure.
Fur-ther, TimeBank is annotated with TimeML, a schememore complex than TIMEX2 since it also encom-passes the tagging of events and temporal relations.However, TIMEX2 is sufficiently sophisticated forthe annotation of most types of temporal expressions,and our review of the literature reveals that the ma-jority of existing temporal taggers output TIMEX2annotations.
Since automatic conversion betweenTIMEX2 and TimeML annotations is not straightfor-ward, TimeBank is of limited use for those who workspecifically with TIMEX2.3 Creating WikiWarsGiven the above concerns, we were particularly inter-ested in developing a corpus that would allow morerigorous testing of techniques for tracking time acrossextended narratives, since these give rise to morecomplex temporal phenomena than are found in sim-pler documents.
To avoid copyright issues that mightarise in the development and distribution of such a914corpus, we decided to use Wikipedia as a source.
Af-ter considering various types of historical narrative,we settled on descriptions of the course of wars andconflicts as being particularly rich in the kinds ofphenomena we wanted to explore.3.1 Selecting DataWe queried Google with two phrases, ?most famouswars in history?
and ?the biggest wars?, and in eachcase chose the top-ranked result.
One of the pagesfound proposed a list of the 10 most famous warsin history, and the other listed the names of the 20biggest wars that happened in the 20th century, mea-sured in terms of the number of military deaths.
Wecombined the two lists, eliminated duplicates, andsearched Wikipedia for articles describing these wars.Wikipedia did not contain an article for one war, andwe considered two articles as inappropriate for ourpurposes since they did not describe the course of thewars, but rather some general information about theconflicts.
This resulted in a final set of 22 articles.More details of the selection process and the URLsof the chosen Wikipedia articles are provided in thedocumentation distributed with the corpus.3.2 Text Extraction and PreprocessingTo prepare the corpus, we first manually copied textfrom those sections of the webpages that describedthe course of the wars.
This involved manual re-moval of picture captions and cross-page links.
Wethen ran a script over the results of this extraction pro-cess to convert some Unicode characters into ASCII(ligatures, spaces, apostrophes, hyphens and otherpunctuation marks), and to remove citation links anda variety of other Wikipedia annotations.Finally, we converted each of the text files intoan SGML file: each document was wrapped in oneDOC tag, inside which there are DOCID, DOCTYPEand DATETIME tags.
The document time stamp is thedate and time at which we downloaded the page fromWikipedia to our local repository.
The proper contentof the article is wrapped in a TEXT tag.
This docu-ment structure intentionally follows that of the ACE2005 and 2007 documents, so as to make the pro-cessing and evaluation of the WikiWars data highlycompatible with the tools used to process the ACEcorpora.3.3 Creating Gold Standard AnnotationsHaving prepared the input SGML documents, wethen processed them with the DANTE temporalexpression tagger (see Mazur and Dale (2007)).DANTE outputs the original SGML documents aug-mented with an inline TIMEX2 annotation for eachtemporal expression found.
These output files canbe imported to Callisto,7 an annotation tool that sup-ports TIMEX2 annotations.
Using a temporal ex-pression tagger as a first-pass annotation tool notonly significantly reduces the amount of human an-notation effort required (creating a tag from scratchrequires a number of clicks in the annotation tool),but also helps to minimize the number of errors thatarise from overlooking markable expressions through?annotator blindness?.
The annotations produced byDANTE were then manually corrected in Callistovia the following process.
First, Annotator 1 (thefirst author) corrected all the annotations producedby DANTE, both in terms of extent and the valuesprovided for TIMEX2 attributes.
This process alsoincluded the annotation of any temporal expressionmissed by the automatic tagger, and the removal ofspurious matches.
Then, Annotator 2 (the second au-thor) checked all the revised annotations and prepareda list of errors found and doubts or queries in regardto potentially problematic annotations.
Annotator 1then verified and fixed the errors, after discussion inthe case of disagreements.The final SGML files containing inline annotationswere then transformed into ACE APF XML annota-tion files, this being the stand-off markup formatdeveloped for ACE evaluations.
This transformationwas carried out using the tern2apf tool developedby NIST for the ACE 2004 evaluations, with somemodifications introduced by us to adjust the tool tosupport ACE 2005 documents and to add a documentID as part of the ID of a TIMEX2 annotation (so thatall annotations would have corpus-wide unique IDs).The resulting corpus is thus available in two for-mats: one contains the original documents enrichedwith inline annotations, and the other consists ofstand-off annotations in the ACE APF format.7See http://callisto.mitre.org.9153.4 Some Deficiencies of TIMEX2The annotation process described above revealedsome issues with the use of TIMEX2 in practice.First, the flexibility of the TIMEX2 scheme, whichcan be at first seen as an advantage, actually makesit ambiguous.
One instance of this phenomenon re-lates to the fact that the TIMEX2 guidelines state thatthe provision of some attribute values for what arecalled event-based expressions (such as three weeksafter the siege of Boston began or the first year of theAmerican invasion) is optional.
Since our corpus hasa significant number of such expressions, the deci-sion as to whether or not to provide semantic valuesin such cases has a potentially large impact on theperceived performance of a tagger.
In such cases,we decided only to provide the value when it is veryclear from the article itself what the value should be.Another area where TIMEX2 is not ideal is inregard to the annotation of time zones.
First, onlywhole-hour time differences are supported, whicheliminates some time zones (e.g.
Afghanistan liesin UTC+04:30).
Second, time zone information issupposed to be marked only for expressions whichhave it explicitly stated.
However, it can often beinferred from the context that subsequent unadornedtime references should inherit the same time zone asan earlier time reference.We also found that, in a not insignificant numberof cases, it is impossible to provide a precise andcorrect value for a temporal expression.
For example,the TIMEX2 guidelines stipulate that the anchorsof durations cannot have a MOD attribute, so if theanchor is mid-August, the value of the anchor mustrefer to August, which is not entirely correct as thesemantics of mid- is lost.TIMEX2 only supports nonspecific expressionswhich have explicit information about granularity.Expressions such as a very short time or a shortperiod of time therefore cannot be provided with anyvalue, since the context does not indicate whether theperiod involved should be measured in days, weeks,or months.
One might consider using the typicaldurations of events of the corresponding types insuch cases, but this solution also has problems (see(Pan et al, 2006)).As is acknowledged in the TIMEX2 guidelines,the treatment of set expressions (i.e.
recurring timesand durations and frequencies, e.g.
twice a month) isunderdeveloped.
One rule states that set expressionsshould not be anchored (Ferro et al, 2005, p. 42);this has the consequence that the full semantics of theexpression annually since 1955 cannot be provided,and the expression is therefore treated as two separateexpressions, annually and 1955.Finally, alternative calendars are not supported, soan expression like February in the pre-revolutionaryRussian calendar cannot receive a value unless it ap-pears in an appositive construction which providesan alternative description.
Similarly, consider Exam-ple (1):(1) On 9 November 1799 (18 Brumaire of the Year VIII)Napoleon Bonaparte staged the coup of 18 Brumairewhich installed the Consulate.Here, 18 Brumaire of the Year VIII is a date in analternative calendar used in France, but we annotatedonly the Year VIII based on the trigger year.
Notethat 18 Brumaire also occurs later in the sentence,but is not annotated.3.5 Corpus StatisticsThe corpus contains 22 documents with a total ofalmost 120,000 tokens8 and 2,671 temporal expres-sions annotated in TIMEX2 format.
In Table 1 wecompare the WikiWars corpus with the other exist-ing corpora.
While the ACE 2005 Training corpusremains the largest corpus, WikiWars is larger thanthe ACE 2005 and 2007 evaluation corpora and theTimeBank v1.2 corpus, both in terms of number oftokens and TIMEX2 annotations.
WikiWars has anorder of magnitude more temporal expressions ineach document, and a slightly higher density of tem-poral expressions than the other corpora.Table 2 presents statistics on the individual doc-uments that make up the corpus.
The documentsvary considerably in size, the smallest consisting ofonly 1,455 tokens, and the largest being eight timeslarger at 11,640 tokens.
The density of TIMEX2 an-notations varies from 1 in 23.1 tokens to 1 in 72.1tokens, but for the majority of documents the ratiolies between 30 and 60.8All token counts presented in Tables 1 and 2 were obtainedusing GATE?s default English tokeniser; hyphenated words, e.g.British-held and co-operation, were treated as single tokens.
Formore information on GATE see (Cunningham et al, 2002).916Corpus Docs KB TokensTemp.Expr.TokensTIMEXTIMEXDocACE05 Train.
599 1,733 318,785 5,469 58.3 9.13ACE05 Eval.
155 350 63,217 1,154 54.8 7.45ACE07 Eval.
254 561 104,779 2,028 51.7 7.98WikiWars 22 631 119,468 2,671 44.7 121.41TimeBank1.2 183 816 78,444 1,414 55.5 7.73Table 1: Statistics of the Wikipedia War corpus comparedto those of other corpora.4 The Nature of Wikipedia ArticlesWikipedia articles may be edited by a large numberof people over a significant number of revisions.
Wechecked how often the articles constituting WikiWarswere modified in the period from January 2008 toFebruary 2010.
On average, each article was changedalmost 52 times per month, with the monthly numberof changes for a single article ranging from 1 to 372.9The minimum average for an individual documentwas 13.08 (17 AlgerianWar), and the maximum was171.77 (07 IraqWar).The nature of the revision process in Wikipedialeads to some artefacts that may be not typicalof other document sources, such as news, wherethe text is usually carefully prepared by its authorand checked by an editor.
This is not to say thatWikipedia content is necessarily of low quality; thisis an encyclopedia with many people and bots con-trolling its quality, and there exist manuals of stylefor authors to help them avoid errors and ambigu-ity and to ensure maximum consistency.10 However,given the large number of editors with various de-grees of fluency and experience in writing and edit-ing, it would not be surprising if some parts of thetexts are not perfect.
In the process of preparing thegold standard annotations for the WikiWars corpus,we have made the following observations.9Note that these numbers are for the articles as a whole,and not just the sections which we extracted (although theseare usually the major part of the article).
Additionally, theseedits include both major changes (e.g.
adding a new section),minor changes (e.g.
correcting a grammar error or adding acomma), vandalism (deletion of the page content or the on-purpose provision of false information) and restoring the pageafter an act of vandalism has been detected.10See, for example, the manual of style concerning format-ing dates and numbers, located at http://en.wikipedia.org/wiki/Wikipedia:DATE.Document ID Tokens TIMEX2 TokensTIMEX201 WW2 5,593 169 33.102 WW1 10,370 264 39.303 AmCivWar 3,529 75 47.104 AmRevWar 5,695 146 39.005 VietnamWar 11,640 243 47.906 KoreanWar 5,992 147 40.807 IraqWar 8,404 247 34.008 FrenchRev 9,631 174 55.409 GrecoPersian 7,393 129 57.310 PunicWars 3,475 57 61.011 ChineseCivWar 3,905 103 37.912 IranIraq 4,508 98 46.013 RussianCivWar 3,924 103 38.114 FirstIndochinaWar 3,085 70 44.115 MexicanRev 3,910 77 50.816 SpanishCivilWar 1,455 63 23.117 AlgerianWar 7,716 130 59.418 SovietsInAfghanistan 5,306 110 48.219 RussoJap 2,760 62 44.520 PolishSoviet 5,137 106 48.521 NigerianCivilWar 2,091 29 72.122 2ndItaloAbyssinianWar 3,949 69 57.2Total for the whole corpus 119,468 2,671 44.7Average per document 5,430 121 ?Standard deviation 2,663 63 ?Table 2: Statistics of the Wikipedia War corpus.4.1 Broken NarrativesIn some articles we have found situations where asentence does not appear to cohere with those oneither side of it.
This may be the result of a num-ber of modifications made by different authors, orit may be due to a lack of writing skill on the partof the person who wrote the paragraph in question.Example (2) below provides an example of this phe-nomenon: the sentence about de Gaulle being electedpresident contains a temporal expression which pro-gresses the temporal focus in the narrative to 1959,but the later context of the article strongly suggeststhat the subsequent reference to October is in factOctober 1958.
(2) ALN commandos committed numer-ous acts of sabotage in France inAugust[1958], and the FLN mounted a desper-ate campaign of terror in Algeria to intimidateMuslims into boycotting the referendum.
Despitethreats of reprisal, however, 80 percent of the Muslimelectorate turned out to vote in September[1958], andof these 96 percent approved the constitution.
InFebruary 1959, de Gaulle was elected president ofthe new Fifth Republic.
He visited Constantine in917October[1958] to announce a program to end the warand create an Algeria closely linked to France.It would appear that the reference to February 1959 isa later addition to the text which has been made with-out the surrounding text being appropriately revisedto accommodate this change.
Clearly such instancesof incoherence will cause problems for any processthat attempts to track the temporal focus.4.2 Ambiguous WritingWe have also found cases of a lack of precision inwriting, which leads to ambiguous statements.
Con-sider the following example:(3) The Afghan government, having secured a treaty inDecember 1978 that allowed them to call on Sovietforces, repeatedly requested the introduction of troopsin Afghanistan in the spring and summer of 1979.They requested Soviet troops to provide security andto assist in the fight against the mujahideen rebels.On April 14, 1979, the Afghan government requestedthat the USSR send 15 to 20 helicopters with theircrews to Afghanistan, and on June 16, the Soviet gov-ernment responded and sent a detachment of tanks,BMPs, and crews to guard the government in Kabuland to secure the Bagram and Shindand airfields.
Inresponse to this request, an airborne battalion, com-manded by Lieutenant Colonel A. Lomakin, arrivedat the Bagram Air Base on July 7.
[.
.
.
]After a month, the Afghan requests were no longerfor individual crews and subunits, but for regimentsand larger units.
In July, the Afghan governmentrequested that two motorized rifle divisions be sentto Afghanistan.
The following day, they requested anairborne division in addition to the earlier requests.Here, in the first paragraph there are four temporalexpressions related to the Afghan government askingfor troops and equipment.
There is also one daterelated to the Soviets?
reply to these requests andsending of tanks, and one date related to the arrivalof an airborne battalion.
The second paragraph startswith after a month; the first possible interpretation isthat this is a month after the 7th July mentioned inthe previous paragraph; i.e.
the month would end onthe 6th of August.
But the following sentence revealsthat this is not the case, as it mentions some requestsfor larger units that were made in July.
Usually anarrative progresses forwards in time, not backwards,so the month must start either on 14th April or 16thJune: if the second sentence elaborates the first one,then it is a month from 16th June; if it just mentionsone of the requests for larger units, then it is probablya month from 14th April.It is also unclear whether the second paragraphtalks about the same request for airborne forces whichwas mentioned in the first paragraph: both theseevents are dated July.
The phrase In response tothis request is in fact placed very oddly, as its pre-ceding sentence does not mention any request, butrather talks about the Soviets?
response to requests.This may suggest that what at first looks just like acareless and ambiguous use of the expression after amonth is in fact a larger problem of lack of coherencyin these two paragraphs.4.3 Use of Deictic ExpressionsOne of the articles, 07 IraqWar, contained a num-ber of deictic temporal expressions, indicative of thefact that the events described were happening con-temporaneously to the time of writing (as is often thecase in news stories); for example:(4) a. Democrats plan to push legislation this springthat would force the Iraqi government to spendits own surplus to rebuild.b.
A protester said that despite the approval of theInterim Security pact, the Iraqi people wouldbreak it in a referendum next year.Obviously, after some time these expressions will nolonger make sense, since there is no ?at-the-time-of-writing?
time stamp associated with these sentences:for the reader of a Wikipedia article, the referencedate is the time of reading.
In the case of the aboveexample, these sentences were written in April andDecember 2008, respectively.11 Arguably, these sen-tences should be corrected, making the temporal ex-pressions fully-specified (e.g.
in spring of 2009 andin 2009), or context-dependent (e.g.
in spring ofthat year and the following year) if there is a contextin the article which supports their correct interpreta-tion.
Of course, not only the temporal expressionsneed to be revised, but also the tense and aspect ofthe verbs used in the sentences.
In the gold stan-dard annotations, however, we provided the valuesby interpreting these expressions with respect to thedocument time stamp (i.e.
2010-SP and 2010), asthe text itself does not provide any evidence that otherdates were intended.11Somewhat laborious document archaeology allows this in-formation to be extracted from Wikipedia?s archive.918Pos Count Token class or lexical form1 4650 NUMBER DIGIT 22 1942 :3 1499 -4 1329 NUMBER DIGIT 45 828 ARTICLE6 765 TEMPORALUNIT7 634 TEMPORALUNIT PLURAL8 555 PREPOSITION9 528 now10 411 t11 403 WEEKDAYNAME12 335 NUMBER WORD13 329 MONTHNAME14 242 MONTHNAME ABBR15 240 DAYPART16 233 DEMONSTRATIVE17 224 ,Pos Count Token class or lexical form18 222 today19 202 NUMBER DIGIT 120 191 last21 171 WEEKDAYNAME ABBR22 145 NUMBER DIGIT 823 113 ago24 108 former25 96 time26 79 right27 69 new28 69 future29 67 gmt30 65 next31 63 past32 61 yesterday33 59 few34 50 everyPos Count Token class or lexical form35 49 AMPM36 48 ORDINAL DIGIT37 48 ?38 45 recently39 43 year-old40 42 later41 41 tonight42 39 christmas43 36 tomorrow44 36 current45 35 couple46 34 recent47 33 earlier48 32 and49 31 early50 31 DIRECT FREQ51 31 ?sTable 3: The most frequent tokens in TEs in the ACE 2005 Training corpus.Pos Count Token class or lexical form1 1181 MONTHNAME2 1157 NUMBER DIGIT 43 674 NUMBER DIGIT 24 490 ARTICLE5 288 PREPOSITION6 221 NUMBER DIGIT 17 211 TEMPORALUNIT8 206 TEMPORALUNIT PLURAL9 165 ,10 133 NUMBER WORD11 99 SEASON12 98 NUMBER DIGIT 313 82 bc14 76 now15 70 time16 67 early17 63 DEMONSTRATIVEPos Count Token class or lexical form18 59 :19 51 end20 49 -21 47 late22 37 DAYPART23 36 later24 36 former25 32 next26 27 same27 25 period28 22 t29 20 mid-30 18 war31 18 few32 14 following33 14 ORDINAL DIGIT34 13 sPos Count Token class or lexical form35 13 first36 11 future37 11 earlier38 11 .39 11 ?s40 9 previous41 9 christmas42 8 last43 8 AMPM44 7 battle45 7 DIRECT FREQ46 6 short47 6 several48 6 season49 6 recent50 6 past51 6 ?Table 4: The most frequent tokens in TEs in the WikiWars corpus.4.4 Use of Time Zone InformationConsider the following example, which comes fromthe article 01 WW2:(5) On December 7 (December 8 in Asian time zones),1941, Japan attacked British and American holdingswith near simultaneous offensives against SoutheastAsia and the Central Pacific.The italicized temporal expression is difficult to de-tect, and it is not clear how it should be annotated.But it is also imprecise with respect to which timezone is intended: Asia encompasses 10 time zones.Therefore it is impossible to fully interpret the ex-pression.
Note also that the expression combines atime zone with a date, rather than with a time.
Whileuncommon, this is not incorrect; but the TIMEX2guidelines do not explicitly allow for this circum-stance.4.5 Quotes Missing a Time StampOccasionally it happens that an article contains aquoted utterance, but there is no indication of whenthe utterance was made.
For example, in the docu-ment 05 VietnamWar we find the following:(6) Nixon said in an announcement, ?I am tonight an-nouncing plans for the withdrawal of an additional150,000 American troops to be completed during the919spring of next year.
This will bring a total reductionof 265,500 men in our armed forces in Vietnam belowthe level that existed when we took office 15 monthsago.
?It is impossible to determine what dates are meantby the three temporal expressions present in the an-nouncement.
In some cases this information may beprovided in citation footnotes, but this is not alwaysthe case; when this is absent, such expressions canonly be annotated at the level of textual extent and alocalised, context-dependent semantics.5 Comparing WikiWars to the ACE DataA comparison of WikiWars with the ACE corporareveals some interesting differences.5.1 Vocabulary DifferencesFirst, we found differences on the level of the lexicaltriggers that signal the presence of temporal expres-sions.
Because of space limitations, we provide hereonly the main findings.Tables 3 and 4 present the 51 most frequent to-kens, including punctuation, in the ACE 2005 Train-ing and WikiWars corpus, respectively.
Some to-kens are combined into what we call trigger classes;for example, all weekday names belong to the classWEEKDAYNAME.12We can see that there are many classes that fallinto the top 51 positions for both corpora, e.g.
thenames of temporal units (such as month and year).But there are also clear differences.
Month namesare the most frequent class in WikiWars, while theyare not so frequent in ACE.
Similarly, year seasonsranked very highly in WikiWars, but do not figurein the rankings shown for ACE.
On the other hand,weekday names are quite frequent in the ACE corpus,but do not occur in the table for WikiWars.
Thissuggests that these corpora make different use oftemporal expressions: in WikiWars we find manyreferences to the more distant past, thus the high useof month names, but ACE documents tend to discuss12The entries in the table correspond to the lexical and punctu-ation clues that drive detection of temporal expressions: the highrank of colons and dashes comes from their use in documenttime stamps, which are considered markable by the TIMEX2guidelines.
The T token is a separator that often occurs in times-tamps, e.g.
2005-01-25T11:08:00; the question mark appearsvery often because some of the ACE timestamps are of the form????-??-?
?T19:33:00.temporally local issues, so they are more likely torefer to days in the weeks preceding and followingthe reference date.Looking at individual tokens, we can see that de-ictic expressions such as today, tonight, yesterdayand tomorrow are in the top 51 positions for ACE,but almost never occur in WikiWars: there are onlythree instances of today, two of tomorrow and oneof tonight in the corpus, and all of these appear onlyin quoted speech.
Similarly, ago occurred 113 timesin ACE, but only twice in WikiWars: once in quotedspeech, and once used incorrectly instead of earlier ina context-dependent expression.
Other tokens whichare frequent in ACE but rare in WikiWars are recent,recently, current and currently.5.2 Temporal Discourse StructureA more interesting property that WikiWars exhibits,and which is noticeably absent from the simpler ACEdata, is what we might think of as a discourse mech-anism for resetting the temporal focus.
This is afeature of complex texts in general, rather than some-thing that is specific to Wikipedia as a source.
Inthese cases, the discourse does not follow a singleglobal timeline from the beginning to the end of thedocument, but is rather divided into subdiscourseswhich describe separate chains of events that oftenhave common temporal starting points.
This is typi-cal in the description of big, often international, con-flicts, where one can distinguish several theaters ofthe war, i.e.
the eastern and western theaters.In most cases the switch to a different ?part of thestory?
can be determined not only by analysing theevents and their geographic locations, but by recog-nizing that the first date appearing in the new subdis-course is generally fully specified.
This is, however,not always the case, as shown in the following exam-ple extracted from the article 01 WW2:(7) In northern Serbia, the Red Army, with limited sup-port from Bulgarian forces, assisted the partisans in ajoint liberation of the capital city of Belgrade on Oc-tober 20[1944].
A few days later, the Soviets launcheda massive assault against German-occupied Hungarythat lasted until the fall of Budapest in February 1945.[.
.
.
]By the start of July[1944], Commonwealth forces inSoutheast Asia had repelled the Japanese sieges in As-sam, pushing the Japanese back to the Chindwin Riverwhile the Chinese captured Myitkyina.
In China, theJapanese were having greater successes, having fi-920nally captured Changsha in mid-June[1944] and thecity of Hengyang by early August[1944].
Soon after,they [.
.
. ]
by the end of November[1944] and success-fully linking up their forces in China and Indochinaby the middle of December[1944].Clearly, quite sophisticated processing is required tohandle this phenomenon adequately.6 Automated Processing of WikiWarsAfter we developed the WikiWars corpus, we used itto evaluate our temporal expression tagger, DANTE,which had been developed for participation in ACE.Performance at finding temporal expressions in text istraditionally reported, for example by (Mani and Wil-son, 2000; Negri and Marseglia, 2005; Teisse`dre etal., 2010), in terms of precision, recall and F-measure.These can, however, be calculated in two ways, le-nient and strict, corresponding to two tasks: detec-tion (where a single character overlap between thegold standard and system annotation counts as a cor-rect answer) and recognition (where an exact overlapis required).Table 5 shows our tagger?s initial performance onthe data.
While the lenient F-measure for extentrecognition was comparable to that obtained for theACE 2005 Training corpus (0.82 vs 0.78), the recallwas much lower: 0.75 vs 0.87.
The difference instrict results was even larger, where both precisionand recall were lower for WikiWars than for ACE,resulting in an F-measure of 0.38.
When evaluatingalso the VAL attribute, the strict F-measure was quitelow for both corpora, but significantly lower for Wiki-Wars: 0.17 vs 0.33.
This illustrates how illusive itmay be to trust the performance of a tagger measuredon a single, possibly biased, data set.In the light of the results of our comparison in Sec-tion 5, it is clear that at some of the performance losshere is simply due to domain differences with respectto lexical triggers.
So, we extended DANTE?s cov-erage with approximately 20 temporal triggers andmodifiers to include the more common vocabularythat appeared in the WikiWars data; we also modifiedthe recognition grammar to reduce the number ofspurious matches and extent errors.
These changesresulted in the improvements shown in Table 6.
Theperformance on extent recognition improves signif-icantly for both sets of data, but the gap betweenextent recognition and evaluation of the VAL attributeLenient StrictCorpus and Task Prec Rec F Prec Rec FWW - Extent only 0.90 0.75 0.82 0.42 0.35 0.38WW - Extent + VAL 0.22 0.18 0.20 0.19 0.16 0.17ACE - Extent only 0.71 0.87 0.78 0.53 0.65 0.58ACE - Extent +VAL 0.34 0.42 0.37 0.30 0.36 0.33Table 5: Initial performance of DANTE on WikiWars andthe ACE 2005 Training corpus.Lenient StrictCorpus and Task Prec Rec F Prec Rec FWW - Extent only 0.98 0.99 0.99 0.95 0.95 0.95WW - Extent + VAL 0.59 0.60 0.59 0.58 0.59 0.58ACE - Extent only 0.88 0.93 0.90 0.75 0.79 0.77ACE - Extent +VAL 0.63 0.67 0.65 0.57 0.60 0.58Table 6: Current performance of DANTE on WikiWarsand the ACE 2005 Training corpus.is much larger on WikiWars.
This is most likely be-cause the strategy of using the document time stampfor the interpretation of context-dependent expres-sions does not work at all for WikiWars documents,whereas it works well for ACE documents, in linewith our earlier comments in regard to the genres ofthe documents.
This emphasises the need to developsophisticated methods for temporal focus tracking ifwe are to extend current time-stamping technologiesbeyond the relatively simplistic temporal structuresfound in currently available corpora.7 Conclusions and Future WorkWe have presented a new corpus based on the his-torical descriptions of 22 wars sourced from En-glish Wikipedia, and we have described in detailthe methodology adopted to construct the corpus; thecorpus can be easily extended in the same way.
Weannotated temporal expressions in these documentswith TIMEX2 tags, which provide both the textualextents and the semantics of the expressions in thecontext of whole article.Following an analysis of the differences betweenour new corpus and existing data sets, we then pre-sented the results of automatic processing of the cor-pus.
This demonstrates that differences in the vo-cabulary used for temporal expressions can be fairlystraightforwardly incorporated in a tagging tool, butthat appropriate processing of temporal structure incomplex documents requires more sophisticated tech-niques than those required to handle existing corpora.The WikiWars Corpus provides data that tests thesecapabilities.921ReferencesDavid Ahn, Sisay Fissaha Adafre, and Maarten de Rijke.2005.
Recognizing and Interpreting Temporal Expres-sions in Open Domain Texts.
In We Will Show Them:Essays in Honour of Dov Gabbay, Vol 1, pages 31?50,October.David Ahn, Joris van Rantwijk, and Maarten de Rijke.2007.
A cascaded machine learning approach to in-terpreting temporal expressions.
In Proceedings ofHuman Language Technologies: The Annual Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics (NAACL-HLT 2007),Rochester, NY, USA, April.Jennifer Baldwin.
2002.
Learning Temporal Annotationof French News.
Master?s thesis, Dept.
of Linguistics,Georgetown University, April.Branimir Boguraev, Jose Castan?o, Rob Gaizauskas, BobIngria, Graham Katz, Bob Knippen, Jessica Littman,Inderjeet Mani, James Pustejovsky, Antonio Sanfil-ippo, Andrew See, Andrea Setzer, Roser Saur?
?, Am-ber Stubbs, Beth Sundheim, Svetlana Symonenko, andMarc Verhagen.
2005.
TimeML 1.2.1 ?
A FormalSpecification Language for Events and Temporal Ex-pressions, October.Branimir Boguraev, James Pustejovsky, Rie Ando, andMarc Verhagen.
2007.
TimeBank evolution as a com-munity resource for TimeML parsing.
Language Re-sources and Evaluation, 41(1):91?115, 02.Hamish Cunningham, Diana Maynard, Kalina Bontcheva,and Valentin Tablan.
2002.
GATE: A framework andgraphical development environment for robust NLPtools and applications.
In Proceedings of the 40th An-niversary Meeting of the ACL.Lisa Ferro, L. Gerber, I. Mani, B. Sundheim, and G. Wil-son.
2005.
TIDES 2005 Standard for the Annotationof Temporal Expressions.
Technical report, MITRE,September.Kadri Hacioglu, Ying Chen, and Benjamin Douglas.
2005.Automatic time expression labeling for english andchinese text.
In Alexander F. Gelbukh, editor, Compu-tational Linguistics and Intelligent Text Processing, 6thInternational Conference, CICLing?05, Lecture Notesin Computer Science, pages 548?559, Mexico City,Mexico, February.
Springer.Benjamin Han, Donna Gates, and Lori Levin.
2006.
Fromlanguage to time: A temporal expression anchorer.
InProceedings of the Thirteenth International Symposiumon Temporal Representation and Reasoning (TIME?06),pages 196?203.
IEEE Computer Society, June.Inderjeet Mani and George Wilson.
2000.
Robust tem-poral processing of news.
In Proceedings of the 38thAnnual Meeting on Association for Computational Lin-guistics (ACL ?00), pages 69?76, Morristown, NJ, USA,October.
Association for Computational Linguistics.Pawel Mazur and Robert Dale.
2007.
The DANTE Tem-poral Expression Tagger.
In Zygmunt Vetulani, editor,Proceedings of the 3rd Language And Technology Con-ference (LTC), Poznan, Poland, October.Pawel Mazur and Robert Dale.
2008.
What?s the Date?High Accuracy Interpretation of Weekday Names.
InProceedings of the 22nd International Conference onComputational Linguistics (Coling 2008), pages 553?560, Manchester, UK, August.
Coling 2008 OrganizingCommittee.Matteo Negri and Luca Marseglia.
2005.
Recognitionand normalization of time expressions: Itc-irst at tern2004.
Technical Report WP3.7, Information SocietyTechnologies, February.Feng Pan, R. Mulkar, and J. R. Hobbs.
2006.
Learningevent durations from event descriptions.
In Proceed-ings of the 21st International Conference on Computa-tional Linguistics and 44th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 393?400,Sydney, Australia, July.
Association for ComputationalLinguistics.James Pustejovsky, J. Castan?o, R. Ingria, R.
Saur??,R.
Gaizauskas, A. Setzer, and G. Katz.
2003.
TimeML:Robust Specification of Event and Temporal Expres-sions in Text.
In IWCS-5, Fifth International Workshopon Computational Semantics, Tilburg, The Netherlands,January.James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-rent Romary.
2010.
ISO-TimeML: An InternationalStandard for Semantic Annotation.
In Bente MaegaardJoseph Mariani Jan Odjik Stelios Piperidis Mike RosnerDaniel Tapias Nicoletta Calzolari (Conference Chair),Khalid Choukri, editor, Proceedings of the Seventhconference on International Language Resources andEvaluation (LREC?10), Valletta, Malta, May.
EuropeanLanguage Resources Association (ELRA).Estela Saquete.
2005.
Temporal Expression Recognitionand Resolution applied to Event Ordering.
Ph.D. thesis,Departamento de Lenguages y Sistemas Informaticos,Universidad de Alicante, June.Frank Schilder.
2004.
Extracting meaning from temporalnouns and temporal prepositions.
ACM Transactionson Asian Language Information Processing (TALIP),3(1):33?50, March.Charles Teisse`dre, Delphine Battistelli, and Jean-LucMinel.
2010.
Resources for calendar expressions se-mantic tagging and temporal navigation through texts.In Proceedings of LREC2010, May.922
