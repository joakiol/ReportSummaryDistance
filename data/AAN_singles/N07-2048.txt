Proceedings of NAACL HLT 2007, Companion Volume, pages 189?192,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsModifying SO-PMI for Japanese Weblog Opinion Mining by Using aBalancing Factor and Detecting Neutral ExpressionsGuangwei WangGraduate School of InformationScience and TechnologyHokkaido UniversitySapporo, Japan 060-0814wgw@media.eng.hokudai.ac.jpKenji ArakiGraduate School of InformationScience and TechnologyHokkaido UniversitySapporo, Japan 060-0814araki@media.eng.hokudai.ac.jpAbstractWe propose a variation of the SO-PMI al-gorithm for Japanese, for use in WeblogOpinion Mining.
SO-PMI is an unsuper-vised approach proposed by Turney thathas been shown to work well for English.We first used the SO-PMI algorithm onJapanese in a way very similar to Turney?soriginal idea.
The result of this trial leanedheavily toward positive opinions.
We thenexpanded the reference words to be sets ofwords, tried to introduce a balancing fac-tor and to detect neutral expressions.
Afterthese modifications, we achieved a well-balanced result: both positive and negativeaccuracy exceeded 70%.
This shows thatour proposed approach not only adaptedthe SO-PMI for Japanese, but also modi-fied it to analyze Japanese opinions moreeffectively.1 IntroductionRecently, more and more websites add informationin the form of personal opinions to the Web, e.g.customer reviews of products, forums, discussiongroups, and blogs.
Here, we use the term Weblog forthese sites.
This type of information is often useful.However, we have to deal with an enormous amountof unstructured and/or semi-structured data.
Thesedata are subjective, in free format and mostly tex-tual, thus using them is difficult and time consum-ing.
Therefore, how to mine the Weblog opinionsautomatically more effectively has attracted moreand more attention (Gamon, 2005; Popescu, 2005;Chaovalit, 2005).Turney (2002) has presented an unsupervisedopinion classification algorithm called SO-PMI (Se-mantic Orientation Using Pointwise Mutual Infor-mation).
The main use of SO-PMI is to estimatethe semantic orientation (i.e.
positive or negative)of a phrase by measuring the hits returned from asearch engine of pairs of words or phrases, based onthe mutual information theory.
This approach haspreviously been successfully used on English.
Theaverage accuracy was 74% when evaluated on 410reviews from Epinions1.However, according to our preliminary experi-ment, directly translating Turney?s original idea intoJapanese gave a very slanted result, with a positiveaccuracy of 95% and a negative accuracy of only8%.
We found that the balance between the posi-tive and negative sides is influenced greatly by thepage hits of reference words/sets, since a search en-gine is used.
Therefore, we introduced a balancingfactor according for the difference in occurrence be-tween positive and negative words.
And then weadded several threshold rules to detect neutral ex-pressions.
The proposed approach is evaluated on200 positive and 200 negative Japanese opinion sen-tences and yielded a well-balanced result.In the remainder of this paper, we review the SO-PMI Algorithm in Section 2, then adapt the SO-PMIfor Japanese and present the modifications in Sec-tion 3.
In section 4, we evaluate and discuss theexperimental results.
Section 5 gives concluding re-marks.2 Details of the SO-PMI AlgorithmThe SO-PMI algorithm (Turney, 2002) is used to es-timate the semantic orientation (SO) of a phrase by1http://www.epinions.com189measuring the similarity of pairs of words or phrasesusing the following formula:PMI(word1,word2)=log2[p(word1&word2)p(word1)p(word2)](1)SO(phrase) = PMI(phrase,?excellent?)?PMI(phrase,?poor?)
(2)The reference words ?excellent?
and ?poor?
areused, thus SO is positive when a phrase is morestrongly associated with ?excellent?
and negativewhen a phrase is more strongly associated with?poor?.
Let hits(query) be the number of hits re-turned when using a search engine, the followingestimate of SO can be derived from Formula (2) and(1) with some minor algebraic manipulation.SO(phrase) = log2 [A]A = hits(phrase NEAR?excellent?)?hits(?poor?
)hits(phrase NEAR?poor?)?hits(?excellent?)
(3)Turney used AltaVista2 search engine because ithas a NEAR operator.
This operator constrains thesearch to documents that contain the words withinten words of one another, in either order.
Turney?sprevious work has shown that NEAR performs bet-ter than AND when measuring the strength of se-mantic association between words.3 Our Proposed ApproachThe first step of our approach is to extract opin-ion phrases using word POS (part of speech) tem-plates based on our analysis of opinions in JapaneseWeblog and the results of related work (Kobayashi,2003; Taku, 2002; Wang, 2006).
The second step isto estimate the semantic orientation of the extractedphrases, using the SO-PMI algorithm.3.1 Adapting SO-PMI for JapaneseFollowing Turney?s original idea, we first translatedthe SO formula to the one shown in Formula (4) forJapanese.SO(phrase) = log2 [B] (4)We used the Google search engine3 to get thehits(query) even though Google does not have aNEAR operator.
The AltaVista NEAR operator doesnot work well for Japanese and Google indexes more2http://www.altavista.com/sites/search/adv3http://www.google.co.jp/pages than AltaVista, thus we used Google and re-placed the NEAR operator with the AND operator inthe SO formula.
?
?
and ?
?
were se-lected because they correspond to the English words?excellent?
and ?poor?.For testing the performance of this trial, we used200 positive and 200 negative Japanese opinion sen-tences which have been labeled by hand.
The re-sults were very slanted.
Many phrases, whether pos-itive or negative in meaning, still received a posi-tive SO.
Some possible causes could be that ?(poor)?
has more hits than ?
(excellent)?,as shown in Table 1, and that the AND operator isless useful than the NEAR operator.3.2 Modifying SO-PMI for JapaneseIn Japanese, there are many expressions whenpeople evaluate something.
For example, ?
(good)?, ?
(good)?, ?
(satisfaction)?
, ?(excellent)?
are usually used when some-one wants to convey a positive opinion.
Hencewe tried to replace the reference words ?excellent?and ?poor?
with two reference sets: ?p?basic?
and?n?basic?
:SO(phrase) = log2 [C]C = hits(phrase ANDp?basic)?hits(n?basic)hits(phrase ANDn?basic)?hits(p?basic) (5)?p?basic?
is a set of common strong positivewords in Japanese.
?n?basic?
is a set of commonweak negative words.
The hit counts of these wordsfrom Google is shown in Table 1 (All data from2007/01/12).
The hits(query) was calculated byhits(phrase AND (?
(good)?
OR ?
(like)?
)OR ?
(good)?
OR ...).Table 1: Frequency of p?basic/n?basic words on the Web2.57 26,000?????
(excellent)2.81 28,400?????
(interesting)5.89 59,500????
(happy)7.40 74,700??
(lovely)7.48 75,500???
(happy)7.89 79,700???
(interesting)7.98 80,600??
(satisfaction)9.59 96,900??
(good)10.20 103,000??
(good)10.59 107,000???
(delightful)11.39 115,000???
(want)11.39 115,000???
(favorite)14.85 150,000??
(charm)20.89 211,000??
(good)23.96 242,000??
(like)36.83 372,000??
(good)R(%)Hits (K)p_basic words1.02 10,300 ???
(bad)1.54 15,600 ???
(not good)1.64 16,600 ???
(fault)2.05 20,700 ??
(worst)2.20 22,200 ??
(dissatisfaction)2.58 26,100 ??
(dissatisfaction)2.62 26,500 ??
(painful)2.62 26,500 ??
(useless)3.67 37,100 ??
(dislike)3.75 37,900 ????
(not good)6.44 65,000 ?
(dislike)7.68 77,600 ???
(hard)7.71 77,900 ??
(fault)8.22 83,000 ??
(worry)10.89 110,000 ??
(bad)11.78 119,000 ??
(poor)R(%)Hits (K)n_basic wordsWe evaluated this modification using the same190data as in Section 3.1.
We obtained a slightly bet-ter result.
However the SO values were still slanted.This time many phrases, whether positive or nega-tive in meaning, still received a negative SO.
All ofthese test results are shown in detail in Section 4.2.In the experiments above, we obtained heavilyslanted results.
We consider that the large differ-ence in page hits between the positive and negativereference words/sets are the main cause for this phe-nomenon.
To mitigate this problem, we decided tointroduce a balancing factor to adjust the balance be-tween the positive and negative sides.
The SO for-mula was modified from (5) to (6).SO(phrase) = log2 [C] + f (?)
(6)The balancing factor f(?)
was calculated by For-mula (7).f (?)
= ?
?
log2[hits(p?basic)hits(n?basic)](7)The log2 of ?p?basic?
and ?n?basic?
is a fac-tor that adjusts the balance of the similarity of?p?basic?/?n?basic?
and phrases automatically bythe hits of ?p?basic?/?n?basic?
itself.
?
is a weightvalue.
We evaluated different values of ?
from ?0.0?to ?1.0?
on the benchmark dataset, which is shownin detail in Section 4.2.From these preliminary trials, we also found thatmany neutral phrases often receive positive or neg-ative SO.
Therefore we added detection of neu-tral expressions.
The idea is that if the phrase isstrongly or faintly associated with both ?p?basic?and ?n?basic?, it is considered a neutral phrase.
Be-cause this means that this phrase has an ambiguousconnection with both ?p?basic?
and ?n?basic?.
Weuse the following rules (Figure 1) to separate neutralphrases from positive/negative phrases.
The thresh-old values ta, tb and tc are obtained from a small,hand-labeled corpus.1.
hits( phrase AND p_basic) > ta AND hits( phrase AND n_basic) > ta2.
hits( phrase AND p_basic) < tb AND  hits( phrase AND n_basic) < tb3.
| hits( phrase AND p_basic) ?
hits( phrase AND n_basic) | < tc4.
SO( phrase ) = 0Figure 1: Rules for Detecting Neutral Expressions4 Experimental Performance Evaluation4.1 Gold Standard and Evaluation MetricsAs a gold standard, we collected a benchmarkdataset which has 200 positive opinion sentencesand 200 negative opinion sentences from the reviewsabout Electronic Dictionary and MP3 Player prod-ucts that have been labeled as either positive or neg-ative reviews in ?Kakaku.com?4.
?Kakaku.com?
isthe largest Japanese Weblog specializing in productcomparison of consumer goods, including price anduser opinions, etc.
Lots of people exchange mis-cellaneous product information and reviews.
Thesereviews are classified as questions, positive re-views, negative reviews, rumors, sale information or?other?
category.To classify a sentence as positive (P) or negative(N), the average SO of the phrases in the sentence isused.
If the average SO is P, the sentence is a posi-tive sentence; otherwise it is a negative sentence.
Asevaluation metrics, we measured our proposed ap-proach?s performance by accuracy.
accuracy wasmeasured as the number of sentences correctly clas-sified as P/N sentences to the total number of P/Nsentences in the benchmark dataset (200).
PA meanspositive accuracy, NA means negative accuracy, i.e.the accuracy on only positive or negative sentencesrespectively.4.2 Experiments and ResultsFirst we did the balancing factor experiment todetermine the value of ??
?, using the benchmarkdataset.
The results are shown in Figure 2.
(a)and (b) show the dashed line indicates average ac-curacy (74%) on English Data from Turney?s Study(2002).
Turney didn?t evaluate positive and nega-tive accuracy respectively.
The full drawn line indi-cates the result after translating the original SO-PMIto Japanese (PA:95%, NA: 8%).
PA series (the linewith triangle mark)/NA series (the line with circlemark) when values of ???
from ?0.0?
to ?1.0?
wereused.Changing the ?
tends to be a tradeoff, loweringPA when NA is improved and vice versa.
There-fore, we used Harmonic?Mean by the followingformula to find a proper value of ??
?.Harmonic?Mean = 2 ?
PA ?NAPA+NA (8)Figure 2, (c) shows PA, NA andHarmonic?Mean curves for different values4http://www.kakaku.com/1910.000.100.200.300.400.500.600.700.800.901.000.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0?AccuracyPositive Accuracy by Modified SO-PMI (PA)Positive Accuracy by Original SO-PMI for JapaneseAccuracy on English Data from Turney's Study0.000.100.200.300.400.500.600.700.800.901.000.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0?AccuracyNegative Accuracy by modified SO-PMI (NA)Negative Accuracy by Original SO-PMI for JapaneseAccuracy on English Data from Turney's Study0.000.100.200.300.400.500.600.700.800.901.000.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0?AccuracyHarmonic_Mean of PA & NAPositive Accuracy by Modified SO-PMI (PA)Negative Accuracy by Modified SO-PMI (NA)(a) Positive Accuracy (PA) (b) Negative Accuracy (NA) (c) Harmonic-Mean of PA/NAFigure 2: Experiment for ?
in Balance Factorof ???.
We selected the ??=0.9?
giving the highestHarmonic?Mean value, thus giving a goodbalance between PA (75%) and NA (70%).The comparative experiment results between theSO-PMI for Japanese (Test 1), and our modifications(Test 2, 3, 4) are shown in Table 2.Table 2: Comparative Experiment Results7278Test 3 + Modification 3: Neutral Phrase DetectionTest 4PA: Positive Accuracy         NA: Negative AccuracyTest 3Test 2Test 19912Modification 1: Two Reference Sets7075Test 2 + Modification 2: Balancing Factor [?
=  0.9]895Naive translation of Turney?s Approach for JapaneseNA(%)PA(%)Test ContentIn Test 1 and 2, we obtained extreme results, lean-ing to the positive or negative end, whether using theTurney?s original approach or expanding the refer-ence word as ?p?basic?
and ?n?basic?.
In Test 3,we added a balancing factor as described in section3.2, and obtained a comparatively well-balanced re-sult.
Finally, after adding the neutral expressions de-tection, we achieved a PA of 78% and NA of 72%(Test 4).
The balance between positive and negativesides was quite improved by contrast with Test 1 and2.5 ConclusionsThis study first proposed a modified unsupervisedapproach (SO-PMI) for Japanese Weblog OpinionMining.
Some parts of Turney?s approach, such asthe NEAR operator, does not work for Japanese,thus some modifications must be done.
In a prelim-inary experiment, the negative accuracy (8%) wasvery poor while the positive accuracy (95%) washigh.
To deal with this phenomenon, we presentedthree modifications based on the characteristics ofJapanese and the results of related work.
The ex-periment results (positive accuracy: 78%, negativeaccuracy: 72%) show that our proposal achieveda considerably improved performance, comparingwith directly translating the SO-PMI.
Hence itwould be expected that the balancing factor and neu-tral expressions detection would work effectivelyalso for other reference words or languages.
In thefuture, we will evaluate different choices of wordsfor the sets of positive and negative reference words.We also plan to appraise our proposal on other lan-guages.ReferencesPeter D. Turney.
2002.
Thumbs up or thumbs down?
Semanticorientation applied to unsupervised classification of reviews.Proceedings 40th Annual Meeting of the ACL, pp.
417-424.Popescu, Ana-Maria, and Oren Etzioni.
2005.
Extracting Prod-uct Features and Opinions from Reviews.
Proceedings ofHLT-EMNLP.Michael Gamon, Anthony Aue, Simon Corston-Oliver and EricK.
Ringger.
2005.
Pulse: Mining Customer Opinions fromFree Text.
Proceedings of the 2005 Conference on IntelligentData Analysis (IDA), pp.121-132.Pimwadee Chaovalit and Lina Zhou.
2005.
Movie Review Min-ing: a Comparison between Supervised and UnsupervisedClassification Approaches.
Proceedings of the 38th AnnualHICSS.Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, KenjiTateishi and Toshikazu Fukushima.
2003.
Collecting eval-uative expressions by a text mining technique.
IPSJ SIGNOTE, Vol.154, No.12, In Japanese.Taku Kudoh and Yuji Matsumoto.
2002.
Applying CascadedChunking to Japanese Dependency Structure Analysis.
In-formation Processing Society of Japan (IPSJ)AcademicJournals, Vol 43, No 6, pp.
1834-1842, In Japanese.Guangwei Wang and Kenji Araki.
2006.
A Decision SupportSystem Using Text Mining Technology.
IEICE SIG NotesWI2-2006-6, pp.
55-56.192
