Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 110?118,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsOn the Impact of Sentiment and Emotion Based Features inDetecting Online Sexual PredatorsDasha BogdanovaUniversity ofSaint Petersburgdasha.bogdanova@gmail.comPaolo RossoNLE Lab - ELiRFUniversitatPolite`cnica de Vale`nciaprosso@dsic.upv.esThamar SolorioCoRAL LabUniversity ofAlabama at Birminghamsolorio@cis.uab.eduAbstractAccording to previous work on pedophile psy-chology and cyberpedophilia, sentiments andemotions in texts could be a good clue to de-tect online sexual predation.
In this paper, wehave suggested a list of high-level features, in-cluding sentiment and emotion based ones, fordetection of online sexual predation.
In partic-ular, since pedophiles are known to be emo-tionally unstable, we were interested in inves-tigating if emotion-based features could helpin their detection.
We have used a corpus ofpredators?
chats with pseudo-victims down-loaded from www.perverted-justice.com andtwo negative datasets of different nature: cy-bersex logs available online and the NPS chatcorpus.
Naive Bayes classification based onthe proposed features achieves accuracies ofup to 94% while baseline systems of word andcharacter n-grams can only reach up to 72%.1 IntroductionChild sexual abuse and pedophilia are both problemsof great social concern.
On the one hand, law en-forcement is working on prosecuting and preventingchild sexual abuse.
On the other hand, psycholo-gists and mental specialists are investigating the phe-nomenon of pedophilia.
Even though the pedophiliahas been studied from different research points, it re-mains to be a very important problem which requiresfurther research, especially from the automatic de-tection point of view.Previous studies report that in the majority ofcases of sexual assaults the victims are under-aged (Snyder, 2000).
On the Internet, attemptsto solicit children have become common as well.Mitchell (2001) found out that 19% of children havebeen sexually approached online.
However, manualmonitoring of each conversation is impossible, dueto the massive amount of data and privacy issues.
Agood alternative is the development of reliable toolsfor detecting pedophilia in online social media is ofgreat importance.In this paper, we address the problem of detectingpedophiles with natural language processing (NLP)techniques.
This problem becomes even more chal-lenging because of the chat data specificity.
Chatconversations are very different not only from thewritten text but also from other types of social mediainteractions, such as blogs and forums, since chat-ting in the Internet usually involves very fast typing.The data usually contains a large amount of mis-takes, misspellings, specific slang, character flood-ing etc.
Therefore, accurate processing of this datawith automated syntactic analyzers is rather chal-lenging.Previous research on pedophilia reports that theexpression of certain emotions in text could be help-ful to detect pedophiles in social media (Egan et al,2011).
Following these insights we suggest a listof features, including sentiments as well as othercontent-based features.
We investigate the impactof these features on the problem of automatic detec-tion of online sexual predation.
Our experimentalresults show that classification based on such fea-tures discriminates pedophiles from non-pedophileswith high accuracy.The remainder of the paper is structured as fol-lows: Section 2 overviews related work on the topic,110Section 3 outlines the profile of a pedophile based onthe previous research.
Our approach to the problemof detecting pedophiles in social media on the ba-sis of high-level features is presented in Section 4.Experimental data is described in Section 5.
Weshow the results of the conducted experiments inSection 6; they are followed by discussion and plansfor future research in Section 7.
We finally drawsome conclusions in Section 8.2 Related ResearchThe problem of automatic detection of pedophilesin social media has been rarely addressed so far.
Inpart, this is due to the difficulties involved in hav-ing access to useful data.
There is an Americanfoundation called Perverted Justice (PJ).
It investi-gates cases of online sexual predation: adult volun-teers enter chat rooms as juveniles (usually 12-15year old) and if they are sexually solicited by adults,they work with the police to prosecute the offenders.Some chat conversations with online sexual preda-tors are available at www.perverted-justice.com andthey have been the subject of analysis of recent re-search on this topic.Pendar (2007) experimented with PJ data.
He sep-arated the lines written by pedophiles from thosewritten by pseudo-victims and used a kNN classi-fier based on word n-grams to distinguish betweenthem.Another related research has been carried out byMcGhee et al (2011).
The chat lines from PJ weremanually classified into the following categories:1.
Exchange of personal information2.
Grooming3.
Approach4.
None of the listed above classesTheir experiments have shown that kNN classifi-cation achieves up to 83% accuracy and outperformsa rule-based approach.As it was already mentioned, pedophiles oftencreate false profiles and pretend to be younger orof another gender.
Moreover, they try to copychildren?s behavior.
Automatically detecting ageand gender in chat conversations could then be thefirst step in detecting online predators.
Peersmanet al (2011) have analyzed chats from the Bel-gium Netlog social network.
Discrimination be-tween those who are older than 16 from those whoare younger based on a Support Vector Machineclassification yields 71.3% accuracy.
The accuracyis even higher when the age gap is increased (e.g.the accuracy of classifying those who are less than16 from those who are older than 25 is 88.2%).
Theyhave also investigated the issues of the minimumamount of training data needed.
Their experimentshave shown that with 50% of the original dataset theaccuracy remains almost the same, and with only10% it is still much better than the random baselineperformance.NLP techniques were as well applied to capturechild sexual abuse data in P2P networks (Panchenkoet al, 2012).
The proposed text classification systemis able to predict with high accuracy if a file containschild pornography by analyzing its name and textualdescription.Our work neither aims at classification of chatlines into categories as it was done by McGhee etal.
(2011) nor at discriminating between victim andpredator as it was done by Pendar (2007), but at dis-tinguishing between pedophile?s and not pedophile?schats, in particular, by utilizing clues provided bypsychology and sentiment analysis.3 Profiling the PedophilePedophilia is a ?disorder of adult personality and be-havior?
which is characterized by sexual interest inprepubescent children (International statistical clas-sification of diseases and related health problems,1988).
Even though solicitation of children is not amedical diagnosis, Abel and Harlow (2001) reportedthat 88% of child sexual abuse cases are commit-ted by pedophiles.
Therefore, we believe that under-standing behavior of pedophiles could help to detectand prevent online sexual predation.
Even though anonline sexual offender is not always a pedophile, inthis paper we use these terms as synonyms.Previous research reports that about 94% of sex-ual offenders are males.
With respect to female sex-ual molesters, it is reported, that they tend to beyoung and, in these cases, men are often involvedas well (Vandiver and Kercher, 2004).
Sexual as-111sault offenders are more often adults (77%), thoughin 23% of cases children are solicited by other juve-niles.Analysis of pedophiles?
personality characterizesthem with feelings of inferiority, isolation, lone-liness, low self-esteem and emotional immaturity.Moreover, 60%-80% of them suffer from other psy-chiatric illnesses (Hall and Hall, 2007).
In general,pedophiles are less emotionally stable than mentallyhealthy people.3.1 Profile of the Online Sexual PredatorHall and Hall (2007) noticed that five main typesof computer-based sexual offenders can be distin-guished: (1) the stalkers, who approach children inchat rooms in order to get physical access to them;(2) the cruisers, who are interested in online sexualmolestation and not willing to meet children offline;(3) the masturbators, who watch child pornography;(4) the networkers or swappers, who trade informa-tion, pornography, and children; and (5) a combi-nation of the four types.
In this study we are in-terested in detecting stalkers (type (1)) and cruisers(type (2)).The language sexual offenders use was analyzedby Egan et al (2011).
The authors considered thechats available from PJ.
The analysis of the chatsrevealed several characteristics of predators?
lan-guage:?
Implicit/explicit content.
On the one hand,predators shift gradually to the sexual conversa-tion, starting with more ordinary compliments:Predator: hey you are really cutePredator: u are prettyPredator: hi sexyOn the other hand, the conversa-tion then becomes overtly related tosex.
They do not hide their intentions:Predator: can we have sex?Predator: you ok with sex with me anddrinking??
Fixated discourse.
Predators are not willing tostep aside from the sexual conversation.
Forexample, in this conversation the predator al-most ignores the question of pseudo-victim andcomes back to the sex-related conversation:Predator: licking dont hurtPredator: its like u lick ice creamPseudo-victim: do u care that im 13 inmarch and not yet?
i lied a little bit b4Predator: its all coolPredator: i can lick hard?
Offenders often understand that what they aredoing is not moral:Predator: i would help but its not moral?
They transfer responsibility to the victim:Pseudo-victim: what ya wanta do when ucome overPredator: whatever?movies, games, drink,play around?it?s up to you?what would youlike to do?Pseudo-victim: that all sounds goodPseudo-victim: lolPredator: maybe get some sexy pics of you:-PPredator: would you let me take pictures ofyou?
of you naked?
of me and you playing?:-D?
Predators often behave as children, copyingtheir linguistic style.
Colloquialisms appear of-ten in their messages:Predator: howwwww dy...Predator: i know PITY MEEEE?
They try to minimize the risk of being prose-cuted: they ask to delete chat logs and warnvictims not to tell anyone about the talk:112Predator: don?t tell anyone we have beentalkingPseudo-victim: kPseudo-victim: lol who would i tell?
noone?s here.Predator: well I want it to be our secret?
Though they finally stop being cautious and in-sist on meeting offline:Predator: well let me come see youPseudo-victim: why u want 2 comeover so bad?Predator: i wanna see youIn general Egan et al (Egan et al, 2011) havefound online solicitation to be more direct, while inreal life children seduction is more deceitful.4 Our ApproachWe address the problem of automatic detection ofonline sexual predation.
While previous studieswere focused on classifying chat lines into differ-ent categories (McGheeet al, 2011) or distinguish-ing between offender and victim (Pendar, 2007), inthis work we address the problem of detecting sex-ual predators.We formulate the problem of detecting pedophilesin social media as the task of binary text categoriza-tion: given a text (a set of chat lines), the aim is topredict whether it is a case of cyberpedophilia or not.4.1 FeaturesOn the basis of previous analysis of pedophiles?
per-sonality (described in previous section), we consideras features those emotional markers that could un-veil a certain degree of emotional instability, suchas feelings of inferiority, isolation, loneliness, lowself-esteem and emotional immaturity.On the one hand, pedophiles try to be nice with avictim and make compliments, at least in the begin-ning of a conversation.
Therefore, the use of posi-tive words is expected.
On the other hand, as it wasdescribed earlier, pedophiles tend to be emotionallyunstable and prone to lose temper, hence they mightstart using words expressing anger and negative lex-icon.
Other emotions can be as well a clue to detectpedophiles.
For example, offenders often demon-strate fear, especially with respect to being prose-cuted, and they often lose temper and express anger:Pseudo-victim: u sad didnt car if im 13. now u car.Predator: well, I am just scared about being introuble or going to jailPseudo-victim: u sad run away now u say no.
igues i dont no what u doinPredator: I got scaredPredator: we would get caugth sometimeIn this example pseudo-victim is not answering:Predator: helloPredator: r u therePredator:Predator: thnx a lotPredator: thanx a lotPredator:Predator: u just wast my timePredator: drive down therePredator: can u not im any moreHere the offender is angry because the pseudo-victim did not call him:Predator: u didnt callPredator: i m angry with uTherefore, we have decided to use markers ofbasic emotions as features.
At the SemEval 2007task on ?Affective Text?
(Strapparava and Mihal-cea, 2007) the problem of fine-grained emotion an-notation was defined: given a set of news titles,the system is to label each title with the appropri-ate emotion out of the following list: ANGER, DIS-GUST, FEAR, JOY, SADNESS, SURPRISE.
In thisresearch work we only use the percentages of themarkers of each emotion.We have also borrowed several features fromMcGhee et al (2011):?
Percentage of approach words.
Approachwords include verbs such as come and meet andsuch nouns as car and hotel.?
Percentage of relationship words.
These wordsrefer to dating (e.g.
boyfriend, date).113?
Percentage of family words.
These words arethe names of family members (e.g.
mum, dad,brother).?
Percentage of communicative desensitizationwords.
These are explicit sexual terms offend-ers use in order to desensitize the victim (e.g.penis, sex).?
Percentage of words expressing sharing infor-mation.
This implies sharing basic information,such as age, gender and location, and sendingphotos.
The words include asl, pic.Since pedophiles are known to be emotionally un-stable and suffer from psychological problems, weconsider features reported to be helpful to detectneuroticism level by Argamon et al (2009).
In par-ticular, the features include percentages of personaland reflexive pronouns and modal obligation verbs(have to, has to, had to, must, should, mustn?t, andshouldn?t).We consider the use of imperative sentences andemoticons to capture the predators tendencies tobe dominant and copy childrens?
behaviour respec-tively.The study of Egan et al (Egan et al, 2011) hasrevealed several recurrent themes that appear in PJchats.
Among them, fixated discourse: the unwill-ingness of the predator to change the topic.
In (Bog-danova et al, 2012) we present experiments on mod-eling the fixated discourse.
We have constructed lex-ical chains (Morris and Hirst, 1991) starting withthe anchor word ?sex?
in the first WordNet mean-ing: ?sexual activity, sexual practice, sex, sex activ-ity (activities associated with sexual intercourse)?.We have finally used as a feature the length of thelexical chain constructed with the Resnik similaritymeasure (Resnik, 1995) with the threshold = 0.7.The full list of features is presented in Table 1.5 DatasetsPendar (2007) has summarized the possible types ofchat interactions with sexually explicit content:1.
Predator/Other(a) Predator/Victim (victim is underaged)(b) Predator/Volunteer posing as a children(c) Predator/Law enforcement officer posingas a child2.
Adult/Adult (consensual relationship)The most interesting from our research point ofview is data of the type 1a, but obtaining suchdata is not easy.
However, the data of the type 1bis freely available at the web site www.perverted-justice.com.
For our study, we have extracted chatlogs from the perverted-justice website.
Since thevictim is not real, we considered only the chat lineswritten by predators.Since our goal is to distinguish sex related chatconversations where one of the parties involved is apedophile, the ideal negative dataset would be chatconversations of type 2 (consensual relations amongadults) and the PJ data will not meet this conditionfor the negative instances.
We need additional chatlogs to build the negative dataset.
We used two neg-ative datasets in our experiments: cybersex chat logsand the NPS chat corpus.We downloaded the cybersex chat logs availableat www.oocities.org/urgrl21f/.
The archive contains34 one-on-one cybersex logs.
We have separatedlines of different authors, thereby obtaining 68 files.We have also used the subset the of NPS chat cor-pus (Forsythand and Martell, 2007), though it is notof type 2.
We have extracted chat lines only for thoseadult authors who had more than 30 lines written.Finally the dataset consisted of 65 authors.
Fromeach dataset we have left 20 files for testing.6 ExperimentsTo distinguish between predators and not predatorswe used a Naive Bayes classifier, already success-fully utilized for analyzing chats by previous re-search (Lin, 2007).
To extract positive and nega-tive words, we used SentiWordNet (Baccianella etal., 2010).
The features borrowed from McGhee etal.
(2011), were detected with the list of words au-thors made available for us.
Imperative sentenceswere detected as affirmative sentences starting withverbs.
Emoticons were captured with simple regularexpressions.Our dataset is imbalanced, the majority of the chatlogs are from PJ.
To make the experimental datamore balanced, we have created 5 subsets of PJ cor-114Feature Class Feature Example ResourceEmotional Positive Words cute, pretty SentiWordNetMarkers Negative Words dangerous, annoying (Baccianella et al, 2010)JOY words happy, cheer WordNet-AffectSADNESS words bored, sad (Strapparava andANGER words annoying, furious Valitutti, 2004)SURPRISE words astonished, wonderDISGUST words yucky, nauseaFEAR words scared, panicFeatures borrowed Approach words meet, car McGhee et al (2011)from McGhee Relationship nouns boyfriend, dateet al (2011) Family words mum, dadCommunicative desensitization words sex.
penisInformation words asl, homeFeatures helpful Personal pronouns I, you Argamon et al (2009)to detect Reflexive pronouns myself, yourselfneuroticism level Obligation verbs must, have toFeatures derived Fixated Discourse see in Section 3.1 Bogdanova et al (2012)from pedophile?spsychological profileOther Emoticons 8), :(Imperative sentences Do it!Table 1: Features used in the experiments.pus, each of which contained chat lines from 60 ran-domly selected predators.For the cybersex logs, half of the chat sessionsbelong to the same author.
We used this author fortraining, and the rest for testing, in order to preventthe classification algorithm from learning to distin-guish this author from pedophiles.For comparison purposes, we experimented withseveral baseline systems using low-level featuresbased on n-grams at the word and character level,which were reported as useful features by related re-search (Peersman et al, 2011).
We trained naiveBayes classifiers using word level unigrams, bi-grams and trigrams.
We also trained naive Bayesclassifiers using character level bigrams and tri-grams.The classification results are presented in Tables 2and 3.
The high-level features outperform all thelow-level ones in both the cybersex logs and the NPSchat datasets and achieve 94% and 90% accuracy onthese datasets respectively.Cybersex chat logs are data of type 2 (see previ-ous section), they contain sexual content and, there-fore, share same of the same vocabulary with theperverted-justice data, whilst the NPS data gener-ally is not sex-related.
Therefore, we expected low-level features to provide better results on the NPSdata.
The experiments have shown that, except forthe character bigrams, all low-level features consid-ered indeed work worse in case of cybersex logs(see the average rows in both tables).
The aver-age accuracy in this case varies between 48% and58%.
Surprisingly, low-level features do not workas good as we expected in case of the NPS chatdataset: bag of words provides only 61% accuracy.Among other low-level features, character trigramsprovide the highest accuracy of 72%, which is stillmuch lower than the one of the high-level features(90%).
The high-level features yield a lower accu-racy (90% accuracy) on the PJ-NPS dataset than inthe case of PJ-cybersex logs (94% accuracy).
This isprobably due to the data diversity: cybersex chat isa very particular type of a conversation, though NPSchat corpora can contain any type of conversationsup to sexual predation.115AccuracyHigh-level Bag of Term Term Character Characterfeatures words bigrams trigrams bigrams trigramsRun 1 0.93 0.38 0.55 0.60 0.73 0.78Run 2 0.95 0.40 0.50 0.53 0.75 0.45Run 3 0.95 0.70 0.45 0.53 0.48 0.50Run 4 0.98 0.43 0.53 0.53 0.50 0.38Run 5 0.90 0.50 0.48 0.53 0.45 0.50Average 0.94 0.48 0.50 0.54 0.58 0.52Table 2: Results of Naive Bayes classification applied to perverted-justice data and cybersex chat logs.AccuracyHigh-level Bag of Term Term Character Characterfeatures words bigrams trigrams bigrams trigramsRun 1 0.93 0.73 0.60 0.60 0.68 0.75Run 2 0.95 0.68 0.53 0.53 0.48 0.45Run 3 0.95 0.58 0.53 0.53 0.48 0.85Run 4 0.98 0.53 0.53 0.53 0.23 0.80Run 5 0.90 0.53 0.53 0.53 0.25 0.75Average 0.92 0.61 0.54 0.54 0.42 0.72Table 3: Results of Naive Bayes classification applied to perverted-justice data and NPS chats.7 Discussion and Future WorkWe have conducted experiments on detecting pe-dophiles in social media with a binary classificationalgorithm.
In the experiments we used two negativedatasets of different nature: the first one is more ap-propriate, it contains one-on-one cybersex conversa-tions, while the second dataset is extracted from theNPS chat corpus and contains logs from chat rooms,and, therefore, is less appropriate since the conver-sations are not even one on one.It is reasonable to expect that in the case of thenegative data consisting of cybersex logs, distin-guishing cyberpedophiles is a harder task, than in thecase of the NPS data.
The results obtained with thebaseline systems support this assumption: we obtainhigher accuracy for the NPS chats in all but characterbi-grams.
The interesting insight from these resultsis that our proposed higher-level features are able toboost accuracy to 94% on the seemingly more chal-lenging task.Our error analysis showed that the NPS logs mis-classified with the high-level features are also mis-classified by the baseline systems.
These instanceseither share the same lexicon or are about the sametopics.
Therefore they are more similar to cyberpe-dophiles training data than the training data of theNPS corpus, which is very diverse.
These examplesare taken from misclassified NPS chat logs:User: love me like a bomb baby come on get it on...User: ryaon so sexyUser: you are so analUser: obviously i didn?t get itUser: just loosen up babe...User: i want to make love to himUser: right field wrong park lol j/kUser: not me i put them in the jail lolUser: or at least tell the cops where to go to get thebad guys lolIn the future we plan to further investigate themisclassified data.
The feature extraction we haveimplemented does not use any word sense disam-biguation.
This can as well cause mistakes sincethe markers are not just lemmas but words in par-ticular senses, since for example the lemma ?fit?can be either a positive marker (?a fit candidate?
)or negative (?a fit of epilepsy?
), depending on the116context.
Therefore we plan to employ word sensedisambiguation techniques during the feature extrac-tion phase.So far we have only seen that the list of fea-tures we have suggested provides good results.They outperform all thelow-level features consid-ered.
Among those low-level features, character tri-grams provide the best results on the NPS data (72%accuracy), though on the cybersex logs they achieveonly 54%.
We plan to merge low-level and high-level features in order to see if this could improvethe results.In the future we plan also to explore the impact ofeach high-level feature.
To better understand whichones carry more discriminative power and if we canreduce the number of features.
All these experi-ments will be done employing naive Bayes as wellas Support Vector Machines as classifiers.8 ConclusionsThis paper presents some results of an ongoing re-search project on the detection of online sexual pre-dation, a problem the research community is inter-ested in, as the PAN task on Sexual Predator Identi-fication1 suggests.Following the clues given by psychological re-search, we have suggested a list of high-level fea-tures that should take into account the level of emo-tional instability of pedophiles, as well as their feel-ings of inferiority, isolation, loneliness, low self-esteem etc.
We have considered as well such low-level features as character bigrams and trigrams andword unigrams, bigrams and trigrams.
The NaiveBayes classification based on high-level featuresachieves 90% and 94% accuracy when using NPSchat corpus and the cybersex chat logs as a nega-tive dataset respectively, whereas low-level featuresachieve only 42%-72% and 48%-58% accuracy onthe same data.AcknowledgementsThe research of Dasha Bogdanova was carried outduring the 3-month internship at the UniversitatPolite`cnica de Vale`ncia (scholarship of the Univer-sity of St.Petersburg).
Her research was partially1http://pan.webis.de/supported by Google Research Award.
The collab-oration with Thamar Solorio was possible thanksto her one-month research visit at the Universi-tat Polite`cnica de Vale`ncia (program PAID-PAID-02-11 award n. 1932).
The research work ofPaolo Rosso was done in the framework of the Eu-ropean Commission WIQ-EI IRSES project (grantno.
269180) within the FP 7 Marie Curie People,the MICINN research project TEXT-ENTERPRISE2.0 TIN2009-13391-C04-03(Plan I+D+i), and theVLC/CAMPUS Microcluster on Multimodal Inter-action in Intelligent Systems.ReferencesGene G. Abel and Nora Harlow.
The Abel and Har-low child molestation prevention study.
Philadelphia,Xlibris, 2001.Shlomo Argamon, Moshe Koppel, James Pennebaker,and Jonathan Schler.
Automatically profiling the au-thor of an anonymous text.
Communications of theACM, 52 (2):119?123, 2009.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
Sentiwordnet 3.0: An enhanced lexical resourcefor sentiment analysis and opinion mining.
the Sev-enth International conference on Language Resourcesand Evaluation, 2010.Regina Barzilay and Michael Elhadad.
Using lexicalchains for text summarization.
In Proceedings ofthe Intelligent Scalable Text Summarization Workshop,1997.Dasha Bogdanova, Paolo Rosso, Thamar Solorio.
Mod-elling Fixated Discourse in Chats with Cyberpe-dophiles.
Proceedings of the Workshop on Compu-tational Approaches to Deception Detection, EACL,2012.Vincent Egan, James Hoskinson, and David Shewan.Perverted justice: A content analysis of the languageused by offenders detected attempting to solicit chil-dren for sex.
Antisocial Behavior: Causes, Correla-tions and Treatments, 2011.Eric N Forsythand and Craig H Martell.
Lexical and dis-course analysis of online chat dialog.
InternationalConference on Semantic Computing ICSC 2007, pages19?26, 2007.Michel Galley and Kathleen McKeown.
Improving wordsense disambiguation in lexical chaining.
In Proceed-ings of IJCAI-2003, 2003.Ryan C. W. Hall and Richard C. W. Hall.
A profileof pedophilia: Definition, characteristics of offenders,recidivism, treatment outcomes, and forensic issues.Mayo Clinic Proceedings, 2007.117David Hope.
Java wordnet similarity library.http://www.cogs.susx.ac.uk/users/drh21.Claudia Leacock and Martin Chodorow.
C-rater: Auto-mated scoring of short-answer questions.
Computersand the Humanities, 37(4):389?405, 2003.Timothy Leary.
Interpersonal diagnosis of personality;a functional theory and methodology for personalityevaluation.
Oxford, England: Ronald Press, 1957.Jane Lin.
Automatic author profiling of online chat logs.PhD thesis, 2007.India McGhee, Jennifer Bayzick, April Kontostathis,Lynne Edwards, Alexandra McBride and EmmaJakubowski.
Learning to identify Internet sexual pre-dation.
International Journal on Electronic Commerce2011.Kimberly J. Mitchell, David Finkelhor, and Janis Wolak.Risk factors for and impact of online sexual solicita-tion of youth.
Journal of the American Medical Asso-ciation, 285:3011?3014, 2001.Jane Morris and Graeme Hirst.
Lexical cohesion com-puted by thesaural relations as an indicator of the struc-ture of text.
Computational Linguistics, 17(1):21?43,1991.Ted Pedersen, Siddharth Patwardhan, Jason Miche-lizzi, and Satanjeev Banerjee.
Wordnet:similarity.http://wn-similarity.sourceforge.net/.Claudia Peersman, Walter Daelemans, and Leona VanVaerenbergh.
Predicting age and gender in online so-cial networks.
In Proceedings of the 3rd Workshop onSearch and Mining User-Generated Contents, 2011.Nick Pendar.
Toward spotting the pedophile: Telling vic-tim from predator in text chats.
In Proceedings ofthe International Conference on Semantic Computing,pages 235?241, Irvine, California, 2007.Alexander Panchenko, Richard Beaufort, Cedrick Fairon.Detection of Child Sexual Abuse Media on P2P Net-works: Normalization and Classification of AssociatedFilenames.
In Proceedings of the LREC Workshop onLanguage Resources for Public Security Applications,2012.Philip Resnik.
Using information content to evaluate se-mantic similarity in a taxonomy.
In IJCAI, pages 448?453, 1995.Howard N. Snyder.
Sexual assault of young children asreported to law enforcement: Victim, incident, and of-fender characteristics.
a nibrs statistical report.
Bureauof Justice Statistics Clearinghouse, 2000.Carlo Strapparava and Rada Mihalcea.
Semeval-2007task 14: affective text.
In Proceedings of the 4th In-ternational Workshop on Semantic Evaluations, Se-mEval?07, pages 70?74, 2007.Carlo Strapparava and Alessandro Valitutti.
Wordnet-affect: an affective extension of wordnet.
In Proceed-ings of the 4th International Conference on LanguageRe-sources and Evaluation, 2004.Frederik Vaassen and Walter Daelemans.
Automaticemotion classification for interpersonal communica-tion.
In Proceedings of the 2nd Workshop on Com-putational Approaches to Subjectivity and SentimentAnalysis (WASSA 2.011), pages 104?110.
Associationfor Computational Linguistics, 2011.Donna M. Vandiver and Glen Kercher.
Offender and vic-tim characteristics of registered female sexual offend-ers in Texas: A proposed typology of female sexualoffenders.
Sex Abuse, 16:121?137, 2004World health organization, international statistical clas-sification of diseases and related health problems: Icd-10 section f65.4: Paedophilia.
1988.118
