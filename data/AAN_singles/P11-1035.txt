Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 340?349,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsContrasting Opposing Views of News Articles on Contentious IssuesSouneil Park1, KyungSoon Lee2, Junehwa Song11Korea Advanced Institute ofScience and Technology2Chonbuk NationalUniversity291 Daehak-ro, Yuseong-gu, 664-14 1ga Deokjin-dong Jeonju,Daejeon, Republic of Korea Jeonbuk, Republic of Korea{spark,junesong}@nclab.kaist.ac.kr selfsolee@chonbuk.ac.krAbstractWe present disputant relation-based meth-od for classifying news articles on conten-tious issues.
We observe that the disputantsof a contention are an important feature forunderstanding the discourse.
It performsunsupervised classification on news articlesbased on disputant relations, and helpsreaders intuitively view the articles throughthe opponent-based frame.
The readers canattain balanced understanding on the con-tention, free from a specific biased view.We applied a modified version of HITS al-gorithm and an SVM classifier trained withpseudo-relevant data for article analysis.1 IntroductionThe coverage of contentious issues of a communityis an essential function of journalism.
Contentiousissues continuously arise in various domains, suchas politics, economy, environment; each issue in-volves diverse participants and their different com-plex arguments.
However, news articles arefrequently biased and fail to fairly deliver conflict-ing arguments of the issue.
It is difficult for ordi-nary readers to analyze the conflicting argumentsand understand the contention; they mostly per-ceive the issue passively, often through a singlearticle.
Advanced news delivery models are re-quired to increase awareness on conflicting views.In this paper, we present disputant relation-based method for classifying news articles on con-tentious issues.
We observe that the disputants of acontention, i.e., people who take a position andparticipate in the contention such as politicians,companies, stakeholders, civic groups, experts,commentators, etc., are an important feature forunderstanding the discourse.
News producers pri-marily shape an article on a contention by selectingand covering specific disputants (Baker.
1994).Readers also intuitively understand the contentionby identifying who the opposing disputants are.The method helps readers intuitively view thenews articles through the opponent-based frame.
Itperforms classification in an unsupervised manner:it dynamically identifies opposing disputant groupsand classifies the articles according to their posi-tions.
As such, it effectively helps readers contrastarticles of a contention and attain balanced under-standing, free from specific biased viewpoints.The proposed method differs from those used inrelated tasks as it aims to perform classificationunder the opponent-based frame.
Research on sen-timent classification and debate stance recognitiontakes a topic-oriented view, and attempts to per-form classification under the ?positive vs. negative?or ?for vs. against?
frame for the given topic, e.g.,positive vs. negative about iPhone.However, such frames are often not appropriatefor classifying news articles of a contention.
Thecoverage of a contention often spans over differenttopics (Miller.
2001).
For the contention on thehealth care bill, an article may discuss the enlargedcoverage whereas another may discuss the increaseof insurance premiums.
In addition, we observethat opposing arguments of a contention are oftencomplex to classify under these frames.
For exam-340ple, in a political contention on holding a referen-dum on the Sejong project1, the opposition partiesstrongly opposed and criticized the president office.Meanwhile, the president office argued that theywere not considering holding the referendum andthe contention arose from a misunderstanding.
Insuch a case, it is difficult to classify any argumentto the ?positive?
category of the frame.We demonstrate that the opponent-based frameis clear and effective for contrasting opposingviews of contentious issues.
For the contention onthe referendum, ?president office vs. oppositionparties?
provides an intuitive frame to understandthe contention.
The frame does not require thedocuments to discuss common topics nor the op-posing arguments to be positive vs. negative.Under the proposed frame, it becomes importantto analyze which side is more centrally covered inan article.
Unlike debate posts or product reviewsnews articles, in general, do not take a positionexplicitly (except a few types such as editorials).They instead quote a specific side, elaborate them,and provide supportive facts.
On the other hand,the opposing disputants compete for news cover-age to influence more readers and gain support(Miller et al 2001).
Thus, the method focuses onidentifying the disputants of each side and classify-ing the articles based on the side it covers.We applied a modified version of HITS algo-rithm to identify the key opponents of an issue, andused disputant extraction techniques combinedwith an SVM classifier for article analysis.
Weobserve that the method achieves acceptable per-formance for practical use with basic language re-sources and tools, i.e., Named Entity Recognizer(Lee et al 2006), POS tagger (Shim et al 2002),and a translated positive/negative lexicon.
As wedeal with non-English (Korean) news articles, it isdifficult to obtain rich resources and tools, e.g.,WordNet, dependency parser, annotated corpussuch as MPQA.
When applied to English, we be-lieve the method could be further improved byadopting them.2 Background and Related WorkResearch has been made on sentiment classifica-tion in document-level (Turney et al, 2002, Panget al, 2002, Seki et al 2008, Ounis et al 2006).
Itaims to automatically identify and classify the sen-1 http://www.koreatimes.co.kr/www/news/nation/2010/07/116_61649.htmltiment of documents into positive or negative.Opinion summarization aims a similar goal, toidentify different opinions on a topic and generatesummaries of them.
Paul et al (2010) developed anunsupervised method for generating summaries ofcontrastive opinions on a common topic.
Theseworks make a number of assumptions that are dif-ficult to apply to the discourse of contentious newsissues.
They assume that the input documents havea common opinion target, e.g., a movie.
Many ofthem primarily deal with documents which explic-itly reveal opinions on the selected target, e.g.,movie reviews.
They usually apply one static clas-sification frame, positive vs. negative, to the topic.The discourse of contentious issues in news arti-cles show different characteristics from that stud-ied in the sentiment classification tasks.
First, theopponents of a contentious issue often discuss dif-ferent topics, as discussed in the example above.Research in mass communication has showed thatopposing disputants talk across each other, not bydialogue, i.e., they martial different facts and inter-pretations rather than to give different answers tothe same topics (Schon et al, 1994).Second, the frame of argument is not fixed as?positive vs. negative?.
We frequently observedboth sides of a contention articulating negative ar-guments attacking each other.
The forms of argu-ments are also complex and diverse to classifythem as positive or negative; for example, an ar-gument may just neglect the opponent?s argumentwithout positive or negative expressions, or em-phasize a different discussion point.In addition, a position of a contention can becommunicated without explicit expression of opin-ion or sentiment.
It is often conveyed through ob-jective sentences that include carefully selectedfacts.
For example, a news article can cast a nega-tive light on a government program simply by cov-ering the increase of deficit caused by it.A number of works deal with debate stancerecognition, which is a closely related task.
Theyattempt to identify a position of a debate, such asideological (Somasundaran et al, 2010, Lin et al,2006) or product comparison debate (So-masundaran et al, 2009).
They assume a debateframe, which is similar to the frame of the senti-ment classification task, i.e., for vs. against the de-bate topic.
All articles of a debate in their corpuscover a coherent debate topic, e.g., iPhone vs.Blackberry, and explicitly express opinions for or341against to the topic, e.g., for or against iPhone orBlackberry.
The proposed methods assume that thedebate frame is known apriori.
This debate frameis often not appropriate for contentious issues forsimilar reasons as the positive/negative frame.
Incontrast, our method does not assume a fixed de-bate frame, and rather develops one based on theopponents of the contention at hand.The news corpus is also different from the de-bate corpus.
News articles of a contentious issueare more diverse than debate articles conveyingexplicit argument of a specific side.
There arenews articles which cover both sides, facts withoutexplicit opinions, and different topics unrelated tothe arguments of either side.Several works have used the relation betweenspeakers or authors for classifying their debatestance (Thomas et al, 2006, Agrawal et al, 2003).However, these works also assume the same debateframe and use the debate corpus, e.g., floor debatesin the House of Representatives, online debate fo-rums.
Their approaches are also supervised, andrequire training data for relation analysis, e.g., vot-ing records of congresspeople.3 Argument Frame ComparisonEstablishing an appropriate argument frame is im-portant.
It provides a framework which enablereaders to intuitively understand the contention.
Italso determines how classification methods shouldclassify articles of the issue.We conducted a user study to compare the op-ponent-based frame and the positive (for) vs. nega-tive (against) frame.
In the experiment, multiplehuman annotators classified the same set of newsarticles under each of the two frames.
We com-pared which frame is clearer for the classification,and more effective for exposing opposing views.We selected 14 contentious issues from NaverNews (a popular news portal in Korea) issue ar-chive.
We randomly sampled about 20 articles pereach issue, for a total of 250 articles.
The selectedissues range over diverse domains such as politics,local, diplomacy, economy; to name a few for ex-ample, the contention on the 4 river project, ofwhich the key opponents are the government vs.catholic church; the entrance of big retailers to thesupermarket business, of which the key opponentsare the small store owners vs. big retail companies;the refusal to approve an integrated civil servants?union, of which the key opponents are governmentvs.
Korean government employees?
union.We use an internationally known contention, i.e.,the dispute about the Cheonan sinking incident, asan example to give more details on the disputants.Our data set includes 25 articles that were pub-lished after the South Korea?s announcement oftheir investigation result.
Many disputants appearin the articles, e.g., South Korean Government,South Korea defense secretary, North KoreanGovernment, United States officials, Chinese ex-perts, political parties of South Korea, etc.Three annotators performed the classification.All of them were students.
For impartiality, two ofthem were recruited from outside the team, whowere not aware of this research.The annotators performed two subtasks for clas-sification.
As for the positive vs. negative frame,first, we asked them to designate the main topic ofthe contention.
Second, they classified the articleswhich mainly deliver arguments for the topic to the?positive?
category and those delivering argumentsagainst the topic to the ?negative?
category.
Thearticles are classified to the ?Other?
category ifthey do not deal with the main topic nor cover pos-itive or negative arguments.As for the opponent-based frame, first, we askedthem to designate the competing opponents.
Se-cond, we asked to classify articles to a specific sideif the articles cover only the positions, arguments,or information supportive of that side or if theycover information detrimental or criticism to itsopposite side.
Other articles were classified to the?Other?
category.
Examples of this category in-clude articles covering both sides fairly, describinggeneral background or implications of the issue.Issue #Free-marginal kappaIssue #Free-marginal kappaPos.-Neg.
Opponent Pos.-Neg.
Opponent1 0.83 0.67 8 0.26 0.582 0.57 0.48 9 0.07 1.003 0.44 0.95 10 0.48 0.844 0.75 0.87 11 0.71 0.865 0.36 0.64 12 0.71 0.716 0.30 0.70 13 0.63 0.797 0.18 0.96 14 0.48 0.87Avg.
0.50 0.78Table 1.
Inter-rater agreement result.The agreement in classification was higher forthe opponent-based frame in most issues.
This in-dicates that the annotators could apply the framemore clearly, resulting in smaller difference be-tween them.
The kappa measure was 0.78 on aver-342age.
The kappa measure near 0.8 indicates a sub-stantial level of agreement, and the value can beachieved, for example, when 8 or 9 out of 10 itemsare annotated equally (Table 1).In addition, fewer articles were classified to the?Other?
category under the opponent-based frame.The annotators classified about half of the articlesto this category under the positive vs. negativeframe whereas they classified about 35% to thecategory under the opponent-based frame.
This isbecause the frame is more flexible to classify di-verse articles of an issue, such as those coveringarguments on different points, and those coveringdetrimental facts to a specific side without explicitpositive or negative arguments.The kappa measure was less than 0.5 for nearhalf of the issues under the positive-negative frame.The agreement was low especially when the maintopic of the contention was interpreted differentlyamong the annotators; the main topic was inter-preted differently for issue 3, 7, 8, and 9.
Evenwhen the topic was interpreted identically, the an-notators were confused in judging complex argu-ments either as positive or negative.
One annotatorcommented that ?it was confusing as the argu-ments were not clearly for or against the topic of-ten.
Even when a disputant was assumed to have apositive attitude towards the topic, the disputant?smain argument was not about the topic but aboutattacking the opponent?
The annotators all agreedthat the opponent-based frame is more effective tounderstand the contention.4 Disputant relation-based methodDisputant relation-based method adopts the oppo-nent-based frame for classification.
It attempts toidentify the two opposing groups of the issue athand, and analyzes whether an article more reflectsthe position of a specific side.
The method is basedon the observation that there exists two opposinggroups of disputants, and the groups compete fornews coverage.
They strive to influence readers?interpretation, evaluation of the issue and gainsupport from them (Miller et al 2001).
In thiscompeting process, news articles may give morechance of speaking to a specific side, explain orelaborate them, or provide supportive facts of thatside (Baker 1994).The proposed method is performed in threestages: the first stage, disputant extraction, extractsthe disputants appearing in an article set; the se-cond stage, disputant partition, partitions the ex-tracted disputants into two opposing groups; lastly,the news classification stage classifies the articlesinto three categories, i.e., two for the articles bi-ased to each group, and one for the others.4.1 Disputant ExtractionIn this stage, the disputants who participate in thecontention have to be extracted.
We utilize thatmany disputants appear as the subject of quotes inthe news article set.
The articles actively quote orcover their action in order to deliver the contentionlively.
We used straight forward methods for ex-traction of subjects.
The methods were effective inpractice as quotes of articles frequently had a regu-lar pattern.The subjects of direct and indirect quotes are ex-tracted.
The sentences including an utterance in-side double quotes are considered as direct quotes.The sentences which convey an utterance with-out double quotes, and those describing the actionof a disputant are considered as indirect quotes(See the translated example 1 below).
The indirectquotes are identified based on the morphology ofthe ending word.
The ending word of the indirectquotes frequently has a verb as its root or includesa verbalization suffix.
Other sentences, typically,those describing the reporter?s interpretation orcomments are not considered as quotes.
(See ex-ample sentence 2.
The ending word of the originalsentence is written in boldface).
(1) The government clarified that there won?t beany talks unless North Korea apologizes forthe attack.
(2) The government?s belief is that a stern re-sponse is the only solution for the current crisisA named entity combined with a topic particleor a subject particle is identified as the subject ofthese quotes.
We detect the name of an organiza-tion, person, or country using the Korean NamedEntity Recognizer (Lee et al 2006).
A simpleanaphora resolution is conducted to identify sub-jects also from abbreviated references or pronounsin subsequent quotes.4.2 Disputant PartitioningWe develop key opponent-based partitioningmethod for disputant partitioning.
The method firstidentifies two key opponents, each representing343one side, and uses them as a pivot for partitioningother disputants.
The other disputants are dividedaccording to their relation with the key opponents,i.e., which key opponent they stand for or against.The intuition behind the method is that thereusually exists key opponents who represent thecontention, and many participants argue about thekey opponents whereas they seldom recognize andtalk about minor disputants.
For instance, in thecontention on ?investigation result of the Cheonansinking incident?, the government of North Koreaand that of South Korea are the key opponents;other disputants, such as politicians, experts, civicgroup of South Korea, the government of U.S., andthat of China, mostly speak about the key oppo-nents.
Thus, it is effective to analyze where thedisputants stand regarding their attitude toward thekey opponents.Selecting key opponents: In order to identifythe key opponents of the issue, we search for thedisputants who frequently criticize, and are alsocriticized by other disputants.
As the key oppo-nents get more news coverage, they have morechance to articulate their argument, and also havemore chance to face counter-arguments by otherdisputants.This is done in two steps.
First, for each dispu-tant, we analyze whom he or she criticizes and bywhom he or she is criticized.
The method goesthrough each sentence of the article set and search-es for both disputant?s criticisms and the criticismsabout the disputant.
Based on the criticisms, it ana-lyzes relationships among disputants.A sentence is considered to express the dispu-tant?s criticism to another disputant if the follow-ing holds: 1) the sentence is a quote, 2) thedisputant is the subject of the quote, 3) anotherdisputant appears in the quote, and 4) a negativelexicon appears in the sentence.On the other hand, if the disputant is not the sub-ject but appears in the quote, the sentence is con-sidered to express a criticism about the disputantmade by another disputant (See example 3.
Thedisputants are written in italic, and negative wordsare in boldface.).
(3) the government defined that ?the attack ofNorth Korea is an act of invasion and also aviolation of North-South Basic Agreement?The negative lexicon we use is carefully builtfrom the Wilson lexicon (Wilson et al 2005).
Wetranslated all the terms in it using the Google trans-lation, and manually inspected the translated resultto filter out inappropriate translations and the termsthat are not negative in the Korean context.Second, we apply an adapted version of HITSgraph algorithm to find major disputants.
For this,the criticizing relationships obtained in the firststep are represented in a graph.
Each disputant ismodeled as a node, and a link is made from a criti-cizing disputant to a criticized disputant.South KoreagovernmentNorth KoreagovernmentMinistry ofDefenseChinaOppositionparty(A: 0.3, H: 0.2)(A: 0, H: 0.1)(A: 0.28, H: 0.15)(A: 0, H: 0.1)A: Authority scoreH: Hub scoreFigure 1.
Example HITS graph illustrationOriginally, the HITS algorithm (Kleinberg,1999) is designed to rate Web pages regarding thelink structure.
The feature of the algorithm is that itseparately models the value of outlinks and inlinks.Each node, i.e., a web page, has two scores: theauthority score, which reflects the value of inlinkstoward itself, and the hub score, which reflects thevalue of its outlinks to others.
The hub score of anode increases if it links to nodes with high author-ity score, and the authority score increases if it ispointed by many nodes with high hub score.We adopt the HITS algorithm due to above fea-ture.
It enables us to separately measure the signif-icance of a disputant?s criticism (using the hubscore) and the criticism about the disputant (usingthe authority score).
We aim to find the nodeswhich have both high hub score and high authorityscore; the key opponents will have many links toothers and also be pointed by many nodes.The modified HITS algorithm is shown in Fig-ure 2.
We make some adaptation to make the algo-rithm reflect the disputants?
characteristics.
Theinitial hub score of a node is set to the number ofquotes in which the corresponding disputant is thesubject.
The initial authority score is set to thenumber of quotes in which the disputant appearsbut not as the subject.
In addition, the weight ofeach link (from a criticizing disputant to a criti-cized disputant) is set to the number of sentencesthat express such criticism.We select the nodes which show relatively highhub score and high authority score compared toother nodes.
We rank the nodes according to thesum of hub and authority scores, and select from344the top ranking node.
The node is not selected if itshub or authority score is zero.
The selection is fin-ished if more than two nodes are selected and thesum of hub and authority scores is less than half ofthe sum of the previously selected node.Modified HITS(G,W,k)G = <V, E> whereV is a set of vertex, a vertex virepresents a disputantE is a set of edges, an edge eijrepresents a criticizing quotefrom disputant i to jW = {wij| weight of edge eij}For all viVAuth1(vi) = # of quotes of  which the subject is disputant iHub1(vi) = # of quotes of  which disputant i appears, butnot as the subjectF t = 1 to k:Autht+1(vi) =Hubt+1(vi) =Normalize Autht+1(vi) and Hubt+1(vi)Figure 2.
Algorithm of the Modified HITSMore than two disputants can be selected ifmore than one disputant is active from a specificside.
In such cases, we choose the two disputantswhose criticizing relationship is the strongestamong the selected ones, i.e., the two who showthe highest ratio of criticism between them.Partitioning minor disputants: Given the twokey opponents, we partition the rest of disputantsbased on their relations with the key opponents.For this, we identify whether each disputant haspositive or negative relations with the key oppo-nents.
The disputant is classified to the side of thekey opponent who shows more positive relations.If the disputant shows more negative relations, thedisputant is classified to the opposite side.We analyze the relationship not only from thearticle set but also from the web news search re-sults.
The minor disputants may not be coveredimportantly in the article set; hence, it can be diffi-cult to obtain sufficient data for analysis.
The webnews search results provide supplementary data forthe analysis of relationships.We develop four features to capture the positiveand negative relationships between the disputants.1) Positive Quote Rate (PQRab): Given two dis-putants (a key opponent a, and a minor disputant b),the feature measures the ratio of positive quotesbetween them.
A sentence is considered as a posi-tive quote if the following conditions hold: the sen-tence is a direct or indirect quote, the twodisputants appear in the sentence, one is the subjectof the quote, and a positive lexicon appears in thesentence.
The number of such sentences is dividedby the number of all quotes in which the two dis-putants appear and one appears as the subject.2) Negative Quote Rate (NQRab): This feature isan opposite version of PQR.
It measures the ratioof negative quotes between the two disputants.
Thesame conditions are considered to detect negativequotes except that negative lexicon is used insteadof positive lexicon.3) Frequency of Standing Together (FSTab):This feature attempts to capture whether the twodisputants share a position, e.g., ?South Korea andU.S.
both criticized North Korea for??
It countshow many times they are co-located or connectedwith the conjunction ?and?
in the sentences.4) Frequency of Division (FDab): This feature isan opposite version of the FST.
It counts howmany times they are not co-located in the sentences.The same features are also calculated from theweb news search results; we collect news articlesof which the title includes the two disputants, i.e., akey opponent a and a minor disputant b.The calculation method of PQR and NQR isslightly adapted since the titles are mostly notcomplete sentences.
For PQR (NQR), it counts thetitles which the two disputants appear with a posi-tive (negative) lexicon.
The counted number is di-vided by the number of total search results.
Thecalculation method of FST and FD is the same ex-cept that they are calculated from the titles.We combine the features obtained from webnews search with the corresponding ones obtainedfrom the article set by calculating a weighted sum.We currently give equal weights.The disputants are partitioned by the followingrule: given a minor disputant a, and the two keyopponents b and c,classify a to b?s side if,(PQRab ?
NQRab) > (PQRac ?
NQRac) or((FSTab > FDab) and (FSTac = 0));classify a to c?s side if,(PQRac ?
NQRac) > (PQRab ?
NQRab) or((FSTac > FDac) and (FSTab = 0));classify a to other, otherwise.4.3 Article ClassificationEach news article of the set is classified by analyz-ing which side is importantly covered.
The methodclassifies the articles into three categories, either toone of the two sides or the category ?other?.345We observed that the major components whichshape an article on a contention are quotes fromdisputants and journalists?
commentary.
Thus, ourmethod considers two points for classification: first,from which side the article?s quotes came; second,for the rest of the article?s text, the similarity of thetext to the arguments of each side.As for the quotes of an article, the method calcu-lates the proportion of the quotes from each sidebased on the disputant partitioning result.
As forthe rest of the sentences, a similarity analysis isconducted with an SVM classifier.
The classifiertakes a sentence as input, determines its class toone of the three categories, i.e., one of the twosides, or other.
It is trained with the quotes fromeach side (tf.idf of unigram and bigram is used asfeatures).
The same number of quotes from eachside is used for training.
The training data is pseu-do-relevant: it is automatically obtained based onthe partitioning result of the previous stage.An article is classified to a specific side if moreof its quotes are from that side and more sentencesare similar to that side: given an article a, and thetwo sides b and c,classify a to b  ifclassify a to c  ifclassify a to other, otherwise.where SU: number of all sentences of the articleQi: number of quotes from the side i.Qij: number of quotes from either side i or j.Si: number of sentences classified to i by SVM.Sij:: number of sentences classified to either i or j.We currently set the parameters heuristically.We set 0.7 and 0.6 for the two parameters ?
and ?respectively.
Thus, for an article written purelywith quotes, the article is classified to a specificside if more than 70% of the quotes are from thatside.
On the other hand, for an article which doesnot include quotes from any side, more than 60%of the sentences have to be determined similar to aspecific side?s quotes.
We set a lower value for ?to classify articles with less number of biased sen-tences (Articles often include non-quote sentencesunrelated to any side to give basic information).5 Evaluation and DiscussionOur evaluation of the method is twofold: first, weevaluate the disputant partitioning results, second,the accuracy of classification.
The method wasevaluated using the same data set used for the clas-sification frame comparison experiment.A gold result was created through the three hu-man annotators.
To evaluate the disputant parti-tioning results, we had the annotators to extract thedisputants of each issue, divide them into opposingtwo groups.
We then created a gold partitioningresult, by taking a union of the three annotators?results.
A gold classification is also created fromthe classification of the annotators.
We resolvedthe disagreements between the annotators?
resultsby following the decision of the majority.5.1 Evaluation of Disputant PartitioningWe evaluated the partitioning result of the two op-posing groups, denoted as G1 and G2.
The perfor-mance is measured using precision and recall.Table 2 presents the results.
The precision of thepartitioning was about 70% on average.
The falsepositives were mostly the disputants who appearonly a few times both in the article set and thenews search results.
As they appeared rarely, therewas not enough data to infer their position.
Theeffect of these false positives in article classifica-tion was limited.The recall was slightly lower than precision.This was mainly because some disputants wereomitted in the disputant extraction stage.
The NERwe used occasionally missed the names of unpopu-lar organizations, e.g., civic groups, and the extrac-tion rule failed to capture the subject in somecomplex sentences.
However, most disputants whofrequently appear in the article set were extractedand partitioned appropriately.Table 2.
Disputant Partitioning Result5.2 Evaluation of Article ClassificationWe evaluate our method and compare it with twounsupervised methods below.Similarity-based clustering (Sim.
): The meth-od implements a typical method.
It clusters articlesof an issue into three groups based on text similari346Issue#Method wFGroup 1 Group 2 OtherIssue#Method wFGroup 1 Group 2 OtherF P R F P R F P R F P R F P R F P R1DrC 0.47 0.64 0.47 1.00 0.62 1.00 0.44 N/A 0.00 0.008DrC 0.90 0.86 0.75 1.00 1.00 1.00 1.00 0.86 1.00 0.75QbC 0.50 0.62 0.47 0.89 0.71 1.00 0.55 N/A 0.00 0.00 QbC 0.48 0.57 0.50 0.67 0.57 0.50 0.67 0.33 0.50 0.25Sim.
0.27 0.20 1.00 0.11 0.20 1.00 0.11 0.47 0.30 1.00 Sim.
0.56 0.67 0.67 0.67 0.50 0.40 0.67 0.50 1.00 0.332DrC 0.65 0.67 0.62 0.73 0.86 1.00 0.75 0.53 0.57 0.509DrC 0.77 N/A 0.00 N/A 0.57 0.50 0.67 0.82 1.00 0.70QbC 0.65 0.76 0.80 0.73 0.60 0.50 0.75 0.53 0.57 0.50 QbC 0.79 N/A 0.00 N/A 0.67 0.67 0.67 0.82 1.00 0.70Sim.
0.37 0.63 0.48 0.91 N/A 0.00 0.00 0.22 1.00 0.13 Sim.
0.49 N/A 0.00 N/A 0.00 0.00 0.00 0.63 0.67 0.603DrC 0.72 0.57 0.40 1.00 0.67 1.00 0.50 0.86 0.75 1.0010DrC 0.66 0.71 0.56 1.00 0.73 1.00 0.57 0.40 0.50 0.33QbC 0.74 0.57 0.40 1.00 0.75 1.00 0.60 0.77 0.71 0.83 QbC 0.72 0.77 0.63 1.00 0.77 0.83 0.71 0.50 1.00 0.33Sim.
0.59 N/A 0.00 0.00 0.70 0.62 0.80 0.60 0.75 0.50 Sim.
0.40 0.33 1.00 0.20 0.44 1.00 0.29 0.40 0.25 1.004DrC 0.80 0.82 0.69 1.00 0.86 1.00 0.75 0.57 0.67 0.5011DrC 0.61 0.73 0.80 0.67 0.50 0.43 0.60 0.57 0.67 0.50QbC 0.81 0.90 0.82 1.00 0.86 1.00 0.75 0.44 0.40 0.50 QbC 0.39 0.62 0.57 0.67 0.20 0.20 0.20 0.29 0.33 0.25Sim.
0.67 0.80 1.00 0.67 0.80 0.67 1.00 N/A 0.00 0.00 Sim.
0.47 0.63 0.46 1.00 0.33 1.00 0.20 0.40 1.00 0.255DrC 0.60 0.63 0.50 0.83 0.71 0.83 0.63 0.33 0.50 0.2512DrC 0.67 0.29 0.20 0.50 0.67 0.67 0.67 0.77 1.00 0.63QbC 0.55 0.40 0.50 0.33 0.71 0.67 0.75 0.44 0.40 0.50 QbC 0.38 0.33 0.25 0.50 0.44 0.33 0.67 0.36 0.47 0.25Sim.
0.51 0.63 0.46 1.00 0.67 1.00 0.50 N/A 0.00 0.00 Sim.
0.43 N/A 0.00 0.00 0.55 0.38 1.00 0.50 0.75 0.386DrC 0.89 N/A 0.00 N/A 0.89 1.00 0.80 0.89 1.00 0.8013DrC 0.65 0.79 0.69 0.92 0.33 1.00 0.20 0.67 1.00 0.50QbC 0.50 N/A 0.00 N/A 0.50 0.67 0.40 0.50 0.67 0.40 QbC 0.59 0.75 0.75 0.75 0.33 1.00 0.20 0.29 0.20 0.50Sim.
0.55 N/A 0.00 N/A 0.77 0.63 1.00 0.33 1.00 0.20 Sim.
0.54 0.71 0.63 0.83 0.33 1.00 0.20 N/A 0.00 0.007DrC 0.48 0.67 1.00 0.50 0.71 0.55 1.00 N/A N/A 0.0014DrC 0.61 0.77 0.77 0.77 0.50 0.57 0.44 0.25 0.20 0.33QbC 0.48 0.67 1.00 0.50 0.62 0.53 0.73 0.17 0.20 0.14 QbC 0.66 0.83 0.75 0.92 0.53 0.67 0.44 0.33 0.33 0.33Sim.
0.44 0.40 0.27 0.75 0.57 0.60 0.55 0.25 1.00 0.14 Sim.
0.37 0.29 1.00 0.17 0.60 0.43 1.00 N/A 0.00 0.00Issue#Total G1 G2 Other1 24 9 9 62 23 11 4 83 18 2 10 64 25 9 12 45 18 5 9 46 10 0 5 57 22 4 11 78 10 3 3 49 13 0 3 1010 15 5 7 311 15 6 5 412 13 2 3 813 19 12 5 214 25 13 10 2*N/A: The metric could not be calculated in some cases.
This happened when no articles were classified to a category.Table 3.
Number of articles of each issue and group (left), and classification performance (right)ty.
It uses tf.idf of unigram and bigram as features,and cosine similarity as the similarity measure.We used the K-means clustering algorithm.Quote-based classification (QbC.
): The meth-od is a partial implementation of our method.
Thedisputant extraction and disputant partitioning isperformed identically; however, it classifies newsarticles merely based on quotes.
An article is clas-sified to one of the two opposing sides if morethan 70% of the quotes are from that side, or tothe ?other?
category otherwise.Results: We evaluated the classification resultof the three categories, the two groups G1 and G2,and the category Other.
The performance is meas-ured using precision, recall, and f-measure.
Weadditionally used the weighted f-measure (wF) toaggregate the f-measure of the three categories.
Itis the weighted average of the three f-measures.The weight is proportional to the number of arti-cles in each category of the gold result.The disputant relation-based method (DrC) per-formed better than the two comparison methods.The overall average of the weighted f-measureamong issues was 0.68, 0.59, and 0.48 for the DrC,QbC, and Sim.
method, respectively (See Table 3).The performance of the similarity-based clusteringwas lower than that of the other two in most issues.A number of works have reported that text sim-ilarity is reliable in stance classification in politi-cal domains.
These experiments were conductedin political debate corpus (Lin et al 2006).
How-ever, news article set includes a number of articlescovering different topics irrelevant to the argu-ments of the disputants.
For example, there can bean article describing general background of thecontention.
Similarity-based clustering approachreacted sensitively to such articles and failed tocapture the difference of the covered side.Quote-based classification performs better thansimilarity-based approach as it classifies articlesprimarily based on the quoted disputants.
The per-formance is comparable to DrC in many issues.The method performs similarly to DrC if mostarticles of an issue include many qutes.
DrC per-forms better for other issues which include anumber of articles with only a few quotes.Error analysis: As for our method, we ob-served three main reasons of misclassification.1) Articles with few quotes: Although the pro-posed method better classifies such articles thanthe quote-based classification, there were somemisclassifications.
There are sentences that are notdirectly related to the argument of any side, e.g.,plain description of an event, summarizing thedevelopment of the issue, etc.
The method madeerrors while trying to decide to which side thesesentences are close to.
Detecting such sentencesand avoiding decisions for them would be oneway of improvement.
Research on classification347of subjective and objective sentences would behelpful (Wiebe et al 99).2) Article criticizing the quoted disputants: Therewere some articles criticizing the quoted dispu-tants.
For example, an article quoted the presidentfrequently but occasionally criticized him betweenthe quotes.
The method misclassified such articlesas it interpreted that the article is mainly deliver-ing the president?s argument.3) Errors in disputant partitioning: Some misclas-sifications were made due to the errors in the dis-putant partitioning stage, specifically, those whowere classified to a wrong side.
Articles whichrefer to such disputants many times were misclas-sified.6 ConclusionWe study the problem of classifying news articleson contentious issues.
It involves new challengesas the discourse of contentious issues is complex,and news articles show different characteristicsfrom commonly studied corpus, such as productreviews.
We propose opponent-based frame, anddemonstrate that it is a clear and effective classifi-cation frame to contrast arguments of contentiousissues.
We develop disputant relation-based clas-sification and show that the method outperforms atext similarity-based approach.Our method assumes polarization for conten-tious issues.
This assumption was valid for mostof the tested issues.
For a few issues, there weresome participants who do not belong to eitherside; however, they usually did not take a particu-lar position nor make strong arguments.
Thus, theeffect on classification performance was limited.Discovering and developing methods for issueswhich involve more than two disputants groups isa future work.ReferencesRakesh Agrawal, Sridhar Rajagopalan, Rama-krishnan Srikant, and Yirong Xu.
2003.
Miningnewsgroups using networks arising from socialbehavior.
In Proceedings of WWW.Baker, B.
1994.
How to Identify, Expose and Cor-rect Liberal Media Bias.
Media Research Cen-ter.Mohit Bansal, Claire Cardie, and Lillian Lee.2008.
The power of negative thinking: Exploit-ing label disagreement in the min-cutclassification framework.
In Proceedings of the22nd International Conference on Computa-tional Linguistics (COLING-2008).Jon M. Kleinberg.
1999.
Authoritative sources ina hyperlinked environment.
In Journal of ACM,46(5): 604-632.Landis JR, Koch G. 1977.
The measurement ofobserver agreement for categorical data.
Bio-metrics 33:159-174.Changki Lee, Yi-Gyu Hwang, Hyo-Jung Oh, Soo-jong Lim, Jeong Heo, Chung-Hee Lee, Hyeon-Jin Kim, Ji-Hyun Wang, Myung-Gil Jang.
2006.Fine-Grained Named Entity Recognition usingConditional Random Fields for Question An-swering,  In Proceedings of Human & Cogni-tive Language Technology (HCLT), pp.268~272.
(in Korean)Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side areyou on?
Identifying perspectives at the docu-ment and sentence levels.
In Proceedings of the10th Conference on Computational NaturalLanguage Learning (CoNLL-2006), pages 109?116, New York.Mark M. Miller and Bonnie P. Riechert.
2001.Spiral Opportunity and Frame Resonance:Mapping Issue Cycle in News and Public Dis-course.
In Framing Public Life: Perspectives onMedia and our Understanding of the SocialWorld, NJ: Lawrence Erlbaum Associates.I Ounis, M de Rijke, C Macdonald, G Mishne, andI Soboroff.
2006.
Overview of the TREC-2006Blog Track.
In Proceedings of TREC.Pang, Bo, Lillian Lee, and Shivakumar Vaithya-nathan.
2002.
Thumbs up?
Sentiment Classifi-cation using Machine Learning Techniques,Proceedings of the 2002 Conference on Empir-ical Methods in Natural Language Processing(EMNLP).Paul, M. J., Zhai, C., Girju, R. 2010.
SummarizingContrastive Viewpoints in Opinionated Text.
InProceedings of the 2010 Conference on Empir-ical Methods in Natural Language Processing(EMNLP).348Schon, D.A., and Rien, M. 1994.
Frame reflec-tion: Toward the resolution of intractable policycontroversies.
New York: Basic Books.Y.
Seki, D. Evans, L. Ku, L. Sun, H. Chen, and N.Kando.
2008.
Overview of Multilingual Opin-ion Analysis Task at NTCIR-7.
In Proceedingsof 7th NTCIR Evaluation Workshop, pages 185-203Kwangseob Shim and Jaehyung Yang.
2002.MACH : A Supersonic Korean MorphologicalAnalyzer, Proceedings of the 19th InternationalConference on Computational Linguistics(COLING-2002), pp.939-945.Swapna Somasundaran and Janyce Wiebe.
2009.Recognizing stances in online debates.
In Pro-ceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th Inter-national Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 226?234, Suntec, Singapore, August.
Associationfor Computational Linguistics.Swapna Somasundaran and Janyce Wiebe.
2010.Recognizing stances in ideological online de-bates.
In Proceedings of the NAACL HLT 2010Workshop on Computational Approaches toAnalysis and Generation of Emotion in Text(CAAGET ?10).Matt Thomas, Bo Pang, and Lillian Lee.
2006.Get outthe vote: Determining support or oppo-sition from congressional floor-debate tran-scripts.
In Proceedings of the 2006 Conferenceon Empirical Methods in Natural LanguageProcessing, pages 327?335, Sydney, Australia,July.
Association for Computational Linguistics.Turney, Peter D. 2002.
Thumbs up or thumbsdown?
Semantic orientation applied to unsu-pervised classification of reviews,  Proceedingsof ACL-02, Philadelphia, Pennsylvania, 417-424Wiebe, Janyce M., Bruce, Rebecca F., & O'Hara,Thomas P. 1999.
Development and use of agold standard data set for subjectivity classifi-cations.
In Proc.
37th Annual Meeting of theAssoc.
for Computational Linguistics (ACL-99).June, pp.
246-253.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of the Con-ference on Empirical Methods in Natural Lan-guage Processing (EMNLP).349
