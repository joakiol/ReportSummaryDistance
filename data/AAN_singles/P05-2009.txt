Proceedings of the ACL Student Research Workshop, pages 49?54,Ann Arbor, Michigan, June 2005. c?2005 Association for Computational LinguisticsLearning Meronyms from Biomedical TextAngus RobertsDepartment of Computer Science, University of Sheffield,Regent Court, 211 Portobello Street, Sheffield S1 4DPa.roberts@dcs.shef.ac.ukAbstractThe part-whole relation is of special im-portance in biomedicine: structure andprocess are organised along partitive axes.Anatomy, for example, is rich in part-whole relations.
This paper reports pre-liminary experiments on part-whole ex-traction from a corpus of anatomy defi-nitions, using a fully automatic iterativealgorithm to learn simple lexico-syntacticpatterns from multiword terms.
The ex-periments show that meronyms can be ex-tracted using these patterns.
A failureanalysis points out factors that could con-tribute to improvements in both precisionand recall, including pattern generalisa-tion, pattern pruning, and term match-ing.
The analysis gives insights into therelationship between domain terminologyand lexical relations, and into evaluationstrategies for relation learning.1 IntroductionWe are used to seeing words listed alphabeticallyin dictionaries.
In terms of meaning, this order-ing has little relevance beyond shared roots.
In theOED, jam is sandwiched between jalpaite (asulphide) and jama (a cotton gown).
It is a longway from bread and raspberry1.
Vocabular-ies, however, do have a natural structure: one thatwe rely on for language understanding.
This struc-ture is defined in part by lexical, or sense, relations,1Oxford English Dictionary, Second Edition, 1989.such as the familiar relations of synonymy and hy-ponymy (Cruse, 2000).
Meronymy relates the lex-ical item for a part to that for a whole, equivalentto the conceptual relation of partOf 2.
Example 1shows a meronym.
When we read the text, we un-derstand that the frontal lobes are not a newentity unrelated to what has gone before, but part ofthe previously mentioned brain.
(1) MRI sections were taken through thebrain.
Frontal lobe shrinkage suggests ageneralised cerebral atrophy.The research described in this paper considersmeronymy, and its extraction from text.
It is tak-ing place in the context of the Clinical e-ScienceFramework (CLEF) project 3, which is developinginformation extraction (IE) tools to allow queryingof medical records.
Both IE and querying requiredomain knowledge, whether encoded explicitly orimplicitly.
In IE, domain knowledge is required toresolve co-references between textual entities, suchas those in Example 1.
In querying, domain knowl-edge is required to expand and constrain user expres-sions.
For example, the query in Example 2 shouldretrieve sarcomas in the pelvis, but not in limbs.
(2) Retrieve patients on Gemcitabine with ad-vanced sarcomas in the trunk of the body.The part-whole relation is critical to domainknowledge in biomedicine: the structure and func-tion of biological organisms are organised along par-titive axes.
The relation is modelled in several medi-cal knowledge resources (Rogers and Rector, 2000),2Although it is generally held that partOf is not just a singlesimple relation, this will not be considered here.3http://www.clef-user.com/49but they are incomplete, costly to maintain, and un-suitable for language engineering.
This paper looksat simple lexico-syntactic techniques for learningmeronyms.
Section 2 considers background and re-lated work; Section 3 introduces an algorithm forrelation extraction, and its implementation in thePartEx system; Section 4 considers materials andmethods used for experiments with PartEx.
Theexperiments are reported in Section 5, followed byconclusions and suggestions for future work.2 Related WorkEarly work on knowledge extraction from elec-tronic dictionaries used lexico-syntactic patterns tobuild relational records from definitions.
This in-cluded some work on partOf (Evens, 1988).
Lex-ical relation extraction has, however, concentratedon hyponym extraction.
A widely cited methodis that of Hearst (1992), who argues that specificlexical relations are expressed in well-known intra-sentential lexico-syntactic patterns.
Hearst success-fully extracted hyponym relations, but had little suc-cess with meronymy, finding that meronymic con-texts are ambiguous (for example, cat?s paw andcat?s dinner).
Morin (1999) reported a semi-automatic implementation of Hearst?s algorithm.Recent work has applied lexical relation extractionto ontology learning (Maedche and Staab, 2004).Berland and Charniak (1999) report what they be-lieved to be the first work finding part-whole rela-tions from unlabelled corpora.
The method used issimilar to that of Hearst, but includes metrics forranking proposed part-whole relations.
They report55% accuracy for the top 50 ranked relations, usingonly the two best extraction patterns.Girju (2003) reports a relation discovery algo-rithm based on Hearst.
Girju contends that the am-biguity of part-whole patterns means that more in-formation is needed to distinguish meronymic fromnon-meronymic contexts.
She developed an algo-rithm to learn semantic constraints for this differen-tiation, achieving 83% precision and 98% recall witha small set of manually selected patterns.
Othershave looked specifically at meronymy in anaphoraresolution (e.g.
Poesio et al(2002)).The algorithm presented here learns relations di-rectly between semantically typed multiword terms,Input:?
A lexicon?
Relations betweenterms?
Corpus from whichto learnOutput:?
New relations?
New terms?
Context patternsSteps:1.
Using input resources(a) Label terms(b) Label relations2.
For a fixed number of iterations or until nonew relations are learned(a) Identify contexts that contain bothparticipants in a relation(b) Create patterns describing contexts(c) Generalise the patterns(d) Use generalised patterns to identify newrelation instances(e) Label new terms(f) Label new relationsFigure 1: PartEx algorithm for relation discoveryand itself contributes to term recognition.
Learningis automatic, with neither manual selection of bestpatterns, nor expert validation of patterns.
In theserespects, it differs from earlier work.
Hearst andothers learn relations between either noun phrasesor single words, while Morin (1999) discusses howhypernyms learnt between single words can be pro-jected onto multi-word terms.
Earlier algorithms in-clude manual selection of initial or ?best?
patterns.The experiments differ from others in that they arerestricted to a well defined domain, anatomy, anduse existing domain knowledge resources.3 AlgorithmInput to the algorithm consists of existing lexical andrelational resources, such as terminologies and on-tologies.
These are used to label text with trainingrelations.
The context of these relations are foundautomatically, and patterns created to describe thesecontexts.
These patterns are generalised and usedto discover new relations, which are fed back itera-tively into the algorithm.
The algorithm is given inFigure 1.
An example iteration is shown in Figure 2.3.1 Discovering New TermsStep 2e in Figure 1 labels new terms, which may bediscovered as a by-product of identifying new rela-50Figure 2: PartEx relation discovery between terms,patterns represented by tokens and parts of speech.tion instances.
This is possible because there is adistinction between the lexical item used to find thepattern context (Step 2a), and the pattern elementagainst which new relations are matched (Step 2d).For example, a pattern could be found from the con-text (term relation term), and expressed as (nounrelation adjective noun).
When applied to thetext to learn new relation instances, sequences of to-kens taking part in this relation will be found, andmay be inferred to be terms for the next iteration.3.2 Implementation: PartExImplementation was independent of any specific re-lation, but configured, as the PartEx system, to dis-cover partOf.
Relations were usually learned be-tween terms, although this was varied in some exper-iments.
The algorithm was implemented using theGATE NLP framework (Cunningham et al, 2002)and texts preprocessed using the tokeniser, sentencesplitter, and part-of-speech (POS) tagger providedwith GATE.
In training, terms were labelled usingMMTx, which uses lexical variant generation to mapnoun phrases to candidate terms and concepts at-tested in a terminology database.
Final candidateselection is based on linguistic matching metrics,and concept resolution on filtering ambiguity fromthe MMTx source terminologies (Aronson, 2001).Training relations were labelled from an existingmeronymy.
Simple contexts of up to five tokensbetween the participants in the relation were identi-fied using JAPE, a regular expression language inte-grated into GATE.
For some experiments, relationswere considered between noun phrases, labelled us-ing LT CHUNK (Mikheev and Finch, 1997).
GATEwrappers for MMTx, LT CHUNK, and other PartExmodules are freely available 4.Patterns describing contexts were expressed asshallow lexico-syntactic patterns in JAPE, and aJAPE transducer used to find new relations.
A typi-cal pattern consisted of a sequence of parts of speechand words.
Pattern generalisation was minimal, re-moving only those patterns that were either identicalto another pattern, or that had more specific lexico-syntactic elements of another pattern.
To simplifypattern creation for the experiments reported here,patterns only used context between the relation par-ticipants, and did not use regular expression quan-tifiers.
New terms found during relation discoverywere labelled using a finite state machine createdwith the Termino compiler (Harkema et al, 2004).4 Materials and MethodLexical and relational resources were provided bythe Unified Medical Language System (UMLS), acollection of medical terminologies 5.
Term lookupin the training phase was carried out using MMTx.Experiments made particular use of The Univer-sity of Washington Digital Anatomist FoundationalModel (UWDA), a knowledge base of anatomy in-cluded in UMLS.
Relation labelling in the trainingphase used a meronymy derived by computing thetransitive closure of that provided with the UWDA.The UWDA gives definitions for some terms, asheadless phrases that do not include the term be-ing defined.
A corpus was constructed from these,for learning and evaluation.
This corpus used thefirst 300 UWDA terms with a definition, that had aUMLS semantic type of ?Body Part?.
These termsincluded synonyms and orthographic variants giventhe same definition.
Complete definitions were con-structed by prepending terms to definitions with thecopula ?is?.
An example is shown in Figure 2.4http://www.dcs.shef.ac.uk/?angus5Version 2003AC, http://www.nlm.nih.gov/research/umls/51Experiments were carried out using cross valida-tion over ten random unseen folds, with 71 uniquemeronyms across all ten folds.
Definitions werepre-processed by tokenising, sentence splitting, POStagging and term labelling.
Evaluation was carriedout by comparison of relations learned in the heldback fold, to those in an artificially generated goldstandard (described below).
Evaluation was typebased, rather than instance based: unique relationinstances in the gold standard were compared withunique relation instances found by PartEx, i.e.
iden-tical relation instances found within the same foldwere treated as a single type.
Evaluation thereforemeasures domain knowledge discovery.Gold standard relations were generated using thesame context window as for Step 2a of the al-gorithm.
Pairs of terms from each context werechecked automatically for a relation in UWDA, andthis added to the gold standard.
This evaluationstrategy is not ideal.
First, the presence of a partand a whole in a context does not mean that they arebeing meronymically related (for example, ?foundin the hand and finger?).
The number of spuriousmeronyms in the gold standard has not yet been as-certained.
Second, a true relation in the text may notappear in a limited resource such as the UWDA (al-though this can be overcome through a failure anal-ysis, as described in Section 4.1).
Although a bettergold standard would be based on expert mark up ofthe text, the one used serves to give quick feedbackwith minimal cost.
Standard evaluation metrics wereused.
The accuracy of initial term and relation la-belling were not evaluated, as these are identical inboth gold standard creation and in experiments.4.1 Failure AnalysisFor some experiments, a failure analysis was carriedout on missing and spurious relations.
The reasonsfor failure were hypothesised by examining the sen-tence in which the relation occurred, the pattern thatled to its discovery, and the source of the pattern.Some spurious relations appeared to be correct,even though they were not in the gold standard.This is because the gold standard is based on a re-source which itself has limits.
One of the aims ofthe work is to supplement such resources: the algo-rithm should find correct relations that are not inthe resource.
Proper evaluation of these relations re-quires care, and methodologies are currently beinginvestigated.
A quick measure of their contributionwas, however, found by applying a simple method-ology, based on the source texts being definitional,authoritative, and describing relations in unambigu-ous language.
The methodology adjusts the numberof spurious relations, and calculates a corrected pre-cision.
By leaving the number of actual relationsunchanged, corrected precision still reflects the pro-portion of discovered relations that were correct rel-ative to the gold standard, but also reflects the num-ber of correct relations not in the gold standard.
Themethodology followed the steps in Figure 3.1.
Examine the context of the relation.2.
If the text gives a clear statement ofmeronomy, the relation is not spurious.3.
If the text is clearly not a statement ofmeronomy, the relation is spurious.4.
If the text is ambiguous, refer to a secondauthoritative resource6.
If this gives aclear statement of meronomy, the relation isnot spurious.5.
If none of these apply, the relation isspurious.6.
Calculate corrected precision from the newnumber of spurious relations.Figure 3: Calculating corrected precision.5 Experimental ResultsTable 3 shows the results of running PartEx in var-ious configurations, and evaluating over the sameten folds.
The first configuration, labelled BASE,used PartEx as described in Section 3.2, to give arecall of 0.80 and precision of 0.25.
A failure anal-ysis for this configuration is given in Table 2.
Itshows that the largest contribution to spurious re-lations (i.e.
to lack of precision), was due to re-lations discovered by some pattern that is ambigu-ous for meronymy (category PATTERN).
For exam-ple, the pattern ?
[noun] and [noun]?
finds theincorrect meronym ?median partOf lateral?from the text ?median and lateral glossoepiglotticfolds?.
The algorithm learned the pattern from a cor-rect meronym, and applying it in the next iteration,learned spurious relations, compounding the error.6In this case, Clinically Oriented Anatomy.
K. Moore andA.
Dalley.
4th Edition.
1999.
Lippincott Williams and Wilkins.52Category Description Count %SPECIFIC There are one or more variant patterns that come close to matching this relation, but none specific to it.
10 50%DISCARD Patterns that could have picked these up were discarded, as they were also generating spurious patterns.
7 35%SCARCE The context is unique in the corpus, and so a pattern could not be learnt without generalisation.
3 15%COMPOUND The relation is within a compound noun.
These are not recognised by the discovery algorithm.
1 5%COMPLEX Complex context, which is beyond the simple current ?part token* whole?
context.
1 5%Table 1: Failure analysis of 20 missing relations over ten folds, using PartEx configuration FILT.Category Description BASE FILTCount % Count %PATTERN The pattern used to discover the relation does not encode partonomy in this case (Patterns involving:is 33 (69%); and 10 (21%); or 3 (6%); other 2 (4%)).48 43% 0 0%CORRECT Although not in the gold standard, the relation is clearly correct, either from an unambiguous state-ment of fact in the text from which it was mined, or by reference to a standard anatomy textbook.30 27% 33 49%DEEP The relation is within a deeper structure than the surface patterns considered.
The algorithm hasfound an incorrect relation that relates to this deep structure.
For example, the text ?limen nasi issubdivision of surface of viscerocranial mucosa?
leads to (limen nasi partOf surface).12 11% 14 21%FRAGMENT:DEEP A combination of the FRAGMENT and DEEP categories.
For example, given the text ?nucleus ofnerve is subdivision of neural tree?, it has learnt that (subdivision partOf neural).10 9% 4 6%FRAGMENT The relation is a fragment of one in the text.
For example, ?plica salpingopalatine is subdivision ofviscerocranial mucosa?
leads to (plica salpingopalatine partOf viscerocranial).9 8% 12 18%OTHER Other reason.
4 4% 3 5%Table 2: Failure analysis of spurious part-whole relations found by PartEx, for configuration BASE (overhalf the spurious relations across ten folds) and configuration FILT (all spurious relations in ten folds).
Ineach case, a small number of relations are in two categories.Possible Actual Missing Spurious P RBASE 71 56 15 168 0.25 0.80FILT 71 51 20 67 0.43 0.73CORR 71 51 20 34 0.58 0.73ITR1 71 45 26 66 0.39 0.62ITR2 71 51 20 67 0.43 0.73TERM 71 51 20 213 0.20 0.74TOK 30 26 4 266 0.09 0.88NP 32 27 5 393 0.07 0.81POS 71 21 50 749 0.03 0.32Table 3: Evaluation of PartEx.
Total number of re-lations, mean precision (P) and mean recall (R) forvarious configurations, as discussed in the text.The bulk of the spurious results of this type werelearnt from patterns using the tokens and, is, and or.This problem needs a principled solution, perhapsbased on pruning patterns against a held-out portionof training data, or by learning ambiguous patternsfrom a large general corpus.
Such a solution is be-ing developed.
In order to mimic it for the purposeof these experiments, a filter was built to remove pat-terns derived from problematic contexts.
Table 3shows the results of this change, as configurationFILT: precision rose to 0.43, and recall dropped.
Allother experiments reported used this filter.A failure analysis of missing relations from con-figuration FILT is shown in Table 1.
The drop inrecall is explained by PartEx filtering ambiguouspatterns.
The biggest contribution to lack of recallwas over-specific patterns (for example, the pattern?
[term] is part of [term]?
would not identifythe meronym in ?finger is a part of the hand?.
Gen-eralisation of patterns is essential to improve recall.Improvements could also be made with more sophis-ticated context, and by examining compounds.A failure analysis of spurious relations for config-uration FILT is shown in Table 2.
The biggest im-pact on precision was made by relations that couldbe considered correct, as discussed in Section 4.1.A corrected precision of 0.58 was calculated, shownas configuration CORR in Table 3.
Two other fac-tors affecting precision can be deduced from Ta-ble 2.
First, some relations were encoded in deeperlinguistic structures than those considered (categoryDEEP).
Improvements could be made to precisionby considering these deeper structures.
Second,some spurious relations were found between frag-ments of terms, due to failure of term recognition.The algorithm used by PartEx is iterative, the im-plementation completing in two iterations.
Config-urations ITR1 and ITR2 in Table 3 show that bothrecall and precision increase as learning progresses.Four other experiments were run, to assess the im-pact of term recognition.
Results are shown in Ta-ble 3.
Configuration TERM continued to label termsin the training phase, but did not label new termsfound during iteration (as discussed in Section 3.1).53TOK and NP used no term recognition, instead find-ing relations between tokens and noun phrases re-spectively (the gold standard being amended to re-flect the new task).
POS omitted part-of-speech tagsfrom patterns.
In all cases, there was a large in-crease in spurious results, impacting precision.
Termrecognition seemed to provide a constraint in rela-tion discovery, although the nature of this is unclear.6 ConclusionsThe PartEx system is capable of fully automatedlearning of meronyms between semantically typedterms, from the experimental corpus.
With simu-lated pattern pruning, it achieves a recall of 0.73 anda precision of 0.58.
In contrast to earlier work, theseresults were achieved without manual labelling ofthe corpus, and without direct manual selection ofhigh performance patterns.
Although the cost of thisautomation is lower results than the earlier work,failure analyses provide insights into the algorithmand scope for its further improvement.Current work includes: automated pattern prun-ing, extending pattern context and generalisation; in-corporating deeper analyses of the text, such as se-mantic labelling (c.f.
Girju (2003)) and the use ofdependency structures; investigating the ro?le of termrecognition in relation discovery; measures for eval-uating new relation discovery; extraction of putativesub-relations of meronymy.
Work to scale the algo-rithm to larger corpora is also under way, in recogni-tion of the fact that the corpus used was small, highlyregularised, and unusually rich in meronyms.AcknowledgementsThis work was supported by a UK Medical ResearchCouncil studentship.
The author thanks his supervi-sor Robert Gaizauskas for useful discussions, andthe reviewers for their comments.ReferencesA.
Aronson.
2001.
Effective Mapping of BiomedicalText to the UMLS Metathesaurus: The MetaMap Pro-gram.
In Proceedings of the 2001 American Medi-cal Informatics Association Annual Symposium, pages17?21, Bethesda, MD.M.
Berland and E. Charniak.
1999.
Finding Parts in VeryLarge Corpora.
In Proceedings of the 37th AnnualMeeting of the Association for Computational Linguis-tics, pages 57?64, College Park, MD.D.
Cruse.
2000.
Meaning in Language: An Introduc-tion to Semantics and Pragmatics.
Oxford UniversityPress.H.
Cunningham, D. Maynard, K. Bontcheva, andV.
Tablan.
2002.
GATE: A Framework and GraphicalDevelopment Environment for Robust NLP Tools andApplications.
In Proceedings of the 40th AnniversaryMeeting of the Association for Computational Linguis-tics, pages 168?175, Philadelphia, PA.M.
Evens, editor.
1988.
Relational Models of the Lexi-con: Representing Knowledge in Semantic Networks.Cambridge University Press.R.
Girju, A. Badulescu, and D. Moldovan.
2003.
Learn-ing Semantic Constraints for the Automatic Discoveryof Part-Whole Relations.
In Proceedings of the Hu-man Language Technology Conference / North Ameri-can Chapter of the Association for Computational Lin-guistics Conference, Edmonton, Canada.H.
Harkema, R. Gaizauskas, M. Hepple, N. Davis,Y.
Guo, A. Roberts, and I. Roberts.
2004.
A Large-Scale Resource for Storing and Recognizing Techni-cal Terminology.
In Proceedings of 4th InternationalConference on Language Resources and Evaluation,Lisbon, Portugal.M.
Hearst.
1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora.
In Proceedings ofthe Fourteenth International Conference on Computa-tional Linguistics, pages 539?545, Nantes, France.A.
Maedche and S. Staab.
2004.
Ontology Learning.
InHandbook on Ontologies, pages 173?190.
Springer.A.
Mikheev and S. Finch.
1997.
A Workbench for Find-ing Structure in Texts.
In Proceedings of the FifthConference on Applied Natural Language Processing,pages 372?379, Washington D.C.E.
Morin and C. Jacquemin.
1999.
Projecting Corpus-based Semantic Links on a Thesaurus.
In Proceed-ings of the 37th Annual Meeting of the Associationfor Computational Linguistics, pages 389?396, Col-lege Park, MD.M.
Poesio, T. Ishikawa, S. Schulte im Walde, andR.
Vieira.
2002.
Acquiring Lexical Knowledge forAnaphora Resolution.
In Proceedings of the Third In-ternational Conference on Language Resources andEvaluation, Las Palmas, Canary Islands.J.
Rogers and A. Rector.
2000.
GALEN?s Model ofParts and Wholes: Experience and Comparisons.
InProceedings of the 2000 American Medical Informat-ics Association Annual Symposium, pages 714?718,Philadelphia, PA.54
