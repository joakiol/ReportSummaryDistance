Transactions of the Association for Computational Linguistics, 1 (2013) 13?24.
Action Editor: Giorgio Satta.Submitted 11/2012; Published 3/2013.
c?2013 Association for Computational Linguistics.Finding Optimal 1-Endpoint-Crossing TreesEmily Pitler, Sampath Kannan, Mitchell MarcusComputer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104epitler,kannan,mitch@seas.upenn.eduAbstractDependency parsing algorithms capable ofproducing the types of crossing dependenciesseen in natural language sentences have tra-ditionally been orders of magnitude slowerthan algorithms for projective trees.
For 95.8-99.8% of dependency parses in various nat-ural language treebanks, whenever an edgeis crossed, the edges that cross it all have acommon vertex.
The optimal dependency treethat satisfies this 1-Endpoint-Crossing prop-erty can be found with an O(n4) parsing al-gorithm that recursively combines forests overintervals with one exterior point.
1-Endpoint-Crossing trees also have natural connectionsto linguistics and another class of graphs thathas been studied in NLP.1 IntroductionDependency parsing is one of the fundamental prob-lems in natural language processing today, with ap-plications such as machine translation (Ding andPalmer, 2005), information extraction (Culotta andSorensen, 2004), and question answering (Cui etal., 2005).
Most high-accuracy graph-based depen-dency parsers (Koo and Collins, 2010; Rush andPetrov, 2012; Zhang and McDonald, 2012) find thehighest-scoring projective trees (in which no edgescross), despite the fact that a large proportion of nat-ural language sentences are non-projective.
Projec-tive trees can be found in O(n3) time (Eisner, 2000),but cover only 63.6% of sentences in some naturallanguage treebanks (Table 1).The class of directed spanning trees covers alltreebank trees and can be parsed in O(n2) withedge-based features (McDonald et al 2005), but itis NP-hard to find the maximum scoring such treewith grandparent or sibling features (McDonald andPereira, 2006; McDonald and Satta, 2007).There are various existing definitions of mildlynon-projective trees with better empirical coveragethan projective trees that do not have the hardness ofextensibility that spanning trees do.
However, thesehave had parsing algorithms that are orders of mag-nitude slower than the projective case or the edge-based spanning tree case.
For example, well-nesteddependency trees with block degree 2 (Kuhlmann,2013) cover at least 95.4% of natural language struc-tures, but have a parsing time of O(n7) (G?mez-Rodr?guez et al 2011).No previously defined class of trees simultane-ously has high coverage and low-degree polynomialalgorithms for parsing, allowing grandparent or sib-ling features.We propose 1-Endpoint-Crossing trees, in whichfor any edge that is crossed, all other edges thatcross that edge share an endpoint.
While simpleto state, this property covers 95.8% or more of de-pendency parses in natural language treebanks (Ta-ble 1).
The optimal 1-Endpoint-Crossing tree canbe found in faster asymptotic time than any previ-ously proposed mildly non-projective dependencyparsing algorithm.
We show how any 1-Endpoint-Crossing tree can be decomposed into isolated setsof intervals with one exterior point (Section 3).
Thisis the key insight that allows efficient parsing; theO(n4) parsing algorithm is presented in Section 4.1-Endpoint-Crossing trees are a subclass of 2-planargraphs (Section 5.1), a class that has been studied13in NLP.
1-Endpoint-Crossing trees also have somelinguistic interpretation (pairs of cross serial verbsproduce 1-Endpoint-Crossing trees, Section 5.2).2 Definitions of Non-ProjectivityDefinition 1.
Edges e and f cross if e and f havedistinct endpoints and exactly one of the endpointsof f lies between the endpoints of e.Definition 2.
A dependency tree is 1-Endpoint-Crossing if for any edge e, all edges that cross eshare an endpoint p.Table 1 shows the percentage of dependencyparses in the CoNLL-X training sets that are 1-Endpoint-Crossing trees.
Across six languages withvarying amounts of non-projectivity, 95.8-99.8%of dependency parses in treebanks are 1-Endpoint-Crossing trees.1We next review and compare other relevant def-initions of non-projectivity from prior work: well-nested with block degree 2, gap-minding, projective,and 2-planar.The definitions of block degree and well-nestedness are given below:Definition 3.
For each node u in the tree, a block ofthe node is ?a longest segment consisting of descen-dants of u.?
(Kuhlmann, 2013).
The block-degree ofu is ?the number of distinct blocks of u?.
The blockdegree of a tree is the maximum block degree of anyof its nodes.
The gap degree is the number of gapsbetween these blocks, and so by definition is one lessthan the block degree.
(Kuhlmann, 2013)Definition 4.
Two trees ?T1 and T2 interleave iffthere are nodes l1,r1 ?
T1 and l2,r2 ?
T2 such thatl1 < l2 < r1 < r2.?
A tree is well-nested if no twodisjoint subtrees interleave.
(Bodirsky et al 2005)As can be seen in Table 1, 95.4%-99.9% of depen-dency parses across treebanks are both well-nestedand have block degree 2.
The optimal such tree canbe found in O(n7) time and O(n5) space (G?mez-Rodr?guez et al 2011).1Conventional edges from the artificial root node to theroot(s) of the sentence reduce the empirical coverage of 1-Endpoint-Crossing trees.
Excluding these artificial root edges,the empirical coverage for Dutch rises to 12949 (97.0%).
Theseedges have no effect on the coverage of well-nested trees withblock degree at most 2, gap-minding trees, or projective trees.a c d e fb g(a)a b c d fe g h(b)Figure 1: 1a is 1-Endpoint-Crossing, but is neitherblock degree 2 nor well-nested; 1b is gap-mindingbut not 2-planar.Definition 5.
A tree is gap-minding if it is well-nested, has gap degree at most 1, and has gap inher-itance degree 0.
Gap inheritance degree 0 requiresthat there are no child nodes with descendants inmore than one of their parent?s blocks.
(Pitler etal., 2012)Gap-minding trees can be parsed in O(n5) (Pitleret al 2012).
They have slightly less empirical cov-erage, however: 90.4-97.7% (Table 1).Definition 6.
A tree is projective if it has block de-gree 1 (gap degree 0).This definition has the least coverage (as low as63.6% for Dutch), but can be parsed in O(n3) (Eis-ner, 2000).Definition 7.
A tree is 2-planar if each edge can bedrawn either above or below the sentence such thatno edges cross (G?mez-Rodr?guez and Nivre, 2010).G?mez-Rodr?guez and Nivre (2010) presented atransition-based parser for 2-planar trees, but thereis no known globally optimal parsing algorithm for2-planar trees.Clearly projective ( gap-minding ( well-nestedwith block degree at most 2.
In Section 5.1, weprove the somewhat surprising fact that 1-Endpoint-Crossing ( 2-planar.
These are two distinct hi-erarchies capturing different dimensions of non-projectivity: 1-Endpoint-Crossing 6?
well-nestedwith block degree 2 (Figure 1a), and gap-minding6?
2-planar (Figure 1b).3 Edges (and their Crossing Point) DefineIsolated Crossing RegionsWe introduce notation to facilitate the discussion:14Arabic Czech Danish Dutch Portuguese Swedish Parsing1-Endpoint-Crossing 1457 (99.8) 71810 (98.8) 5144 (99.1) 12785 (95.8) 9007 (99.3) 10902 (98.7) O(n4)Well-nested, block degree 2 1458 (99.9) 72321 (99.5) 5175 (99.7) 12896 (96.6) 8650 (95.4) 10955 (99.2) O(n7)Gap-Minding 1394 (95.5) 70695 (97.2) 4985 (96.1) 12068 (90.4) 8481 (93.5) 10787 (97.7) O(n5)Projective 1297 (88.8) 55872 (76.8) 4379 (84.4) 8484 (63.6) 7353 (81.1) 9963 (90.2) O(n3)Sentences 1460 72703 5190 13349 9071 11042Table 1: Over 95% of the dependency parse trees in the CoNLL-X training sets are 1-Endpoint-Crossingtrees.
Coverage statistics and parsing times of previously proposed properties are shown for comparison.Definition 8.
Within a 1-Endpoint-Crossing tree,the (crossing) pencil2 of an edge e (P(e)) is definedas the set of edges (sharing an endpoint) that cross e.The (crossing pencil) point of an edge e (Pt(e)) isdefined as the endpoint that all edges in P(e) share.We will use euv to indicate an edge in either direc-tion between u and v, i.e., either u?
v or u?
v.Before defining the parsing algorithm, we firstgive some intuition by analogy to parsing for pro-jective trees.
(This argument mirrors that of Eisner(2000, pps.38-39).)
Projective trees can be producedusing dynamic programming over intervals.
Inter-vals are sufficient for projective trees: consider anyedge euv in a projective tree.The vertices in (u, v) must only have edges tovertices in [u, v].
If there were an edge between avertex in (u, v) and a vertex outside [u, v], such anedge would cross euv, which would contradict theassumption of projectivity.
Thus every edge in aprojective tree creates one interior interval isolatedfrom the rest of the tree, allowing dynamic program-ming over intervals.
We can analyze the case of 1-Endpoint-Crossing trees in a similar fashion:Definition 9.
An isolated interval [i, j] has no edgesbetween the vertices in (i, j) and the vertices out-side of [i, j].
An interval and one exterior vertex[i, j] ?
{x} is called an isolated crossing region ifthe following two conditions are satisfied:1.
There are no edges between the vertices?
(i, j)and vertices /?
[i, j] ?
{x}2.
None of the edges between x and vertices ?
(i, j) are crossed by any edges with both end-points ?
(i, j)2This notation comes from an analogy to geometry: ?A setof distinct, coplanar, concurrent lines is a pencil of lines?
(Rin-genberg, 1967, p. 221); concurrent lines all intersect at the samesingle point.u v p(a) [u, v] ?
{p}u v p(b) [v, p] ?
{u}u p v(c) [u, p] ?
{v}u p v(d) [p, v] ?
{u}Figure 2: An edge euv and Pt(euv) = p form twosets of isolated crossing regions (Lemma 1).
2a and2b show p /?
(u, v); 2c and 2d show p ?
(u, v).Lemma 1.
Consider any edge euv and Pt(euv) = pin a 1-Endpoint-Crossing forest F .
Let l, r, and mdenote the leftmost, rightmost, and middle point outof {u, v, p}, respectively.
Then the three points u,v, and p define two isolated crossing regions: (1)[l,m] ?
{r}, and (2) [m, r] ?
{l}.Proof.
First note that as p = Pt(euv), P(euv) isnon-empty: there must be at least one edge betweenvertices ?
(u, v) and vertices /?
[u, v].
p is either/?
[u, v] (i.e., p = l?p = r) or?
(u, v) (i.e., p = m):Case 1: p = l ?
p = r: Assume without loss ofgenerality that u < v < p (i.e., p = r).
(a) [u, v] ?
{p} is an isolated crossing region(Figure 2a): Condition 1: Assume for the sake ofcontradiction that there were an edge between a ver-tex?
(u, v) and a vertex /?
[u, v]?{p}.
Then such anedge would cross euv without having an endpoint atp, which contradicts the 1-Endpoint-Crossing prop-erty for euv.Condition 2: Assume that for some epa such thata ?
(u, v), epa was crossed by an edge in the interiorof (u, v).
The interior edge would not share an end-point with euv; since euv also crosses epa, this con-tradicts the 1-Endpoint-Crossing property for epa.15(b) [v, p] ?
{u} is an isolated crossing region(Figure 2b): Condition 1: Assume there were anedge eab with a ?
(v, p) and b /?
[v, p] ?
{u}.
bcannot be in (u, v) (by above).
Thus, b /?
[u, p],which implies that eab crosses the edges in P(euv);as euv does not share a vertex with eab, this contra-dicts the 1-Endpoint-Crossing property for all edgesin P(euv).Condition 2: Assume that for some eua such thata ?
(v, p), eua was crossed by an edge in the interiorof (v, p).
eua would also be crossed by all the edgesin P(euv); as the interior edge would not share anendpoint with any of the edges inP(euv), this wouldcontradict the 1-Endpoint-Crossing property for eua.Case 2: p = m :(a) [u, p] ?
{v} is an isolated crossing region(Figure 2c): Condition 1: Assume there were anedge eab with a ?
(u, p) and b /?
[u, p] ?
{v}(b ?
(p, v) ?
b /?
[u, v]).
First assume b ?
(p, v).Then eab crosses all edges in P(euv); as eab does notshare an endpoint with euv, this contradicts the 1-Endpoint-Crossing property for the edges inP(euv).Next assume b /?
[u, v].
Then eab crosses euv; sincea 6= p?b 6= p, this violates the 1-Endpoint-Crossingproperty for euv.Condition 2: Assume that for some eva with a ?
(u, p), eva was crossed by an edge in the interior of(u, v).
eva is also crossed by all the edges inP(euv);as the interior edge will not share an endpoint withthe edges inP(euv), this contradicts the 1-Endpoint-Crossing property for eva.
(b) [p, v] ?
{u} is an isolated crossing region(Figure 2d): Symmetric to the above.4 Parsing AlgorithmThe optimal 1-Endpoint-Crossing tree can be foundusing a dynamic programming algorithm that ex-ploits the fact that edges and their crossing pointsdefine intervals and isolated crossing regions.
Thissection assumes an arc-factored model, in which thescore of a tree is defined as the sum of the scores ofits edges; scoring functions for edges are generallylearned from data.
(a) Only edges inci-dent to the Left pointof the interval maycross the edges fromthe exterior point(b) Only edges in-cident to the Rightpoint of the inter-val may cross theedges from the exte-rior point(c) both (LR) (d) NeitherFigure 3: Isolated crossing region sub-problems.The dynamic program uses five types of sub-problems: interval sub-problems for each interval[i, j], denoted Int[i, j], and four types of isolatedcrossing region sub-problems for each interval andexterior point [i, j] ?
{x}, which differ in whetheredges from the exterior point may be crossed byedges with an endpoint at the Left point of the inter-val, the Right point, both LR, or Neither (Figure 3).L[i, j, x], for example, refers to an isolated crossingregion over the interval [i, j] with an exterior pointof x, in which edges incident to i (the left boundarypoint) can cross edges between x and (i, j).These distinctions allow the 1-Endpoint-Crossingproperty to be globally enforced; crossing edges inone region may constrain edges in another.
For ex-ample, consider that Figure 2a allows edges with anendpoint at v to cross the edges from p, while Figure2b allows edges from u into (v, p).
Both simultane-ously would cause a 1-Endpoint-Crossing violationfor the edges in P(euv).
Figures 4 and 5 show validcombinations of the sub-problems in Figure 3.The full dynamic program is shown in AppendixA.
The final answer must be a valid dependency tree,which requires each word to have exactly one parentand prohibits cycles.
We use booleans (bi, bj , bx) foreach sub-problem, in which the boolean is set to trueif and only if the solution to the sub-problem mustcontain the incoming (parent) edge for the corre-sponding boundary point.
We use the suffix AFromBfor a sub-problem to enforce that a boundary point Amust be descended from boundary point B (to avoidcycles).
We will occasionally mention these issues,16(a) If l ?
(k, j]:ki l j(b) If l ?
(i, k):li k j(i) If the dashed edge exists:All the edges from l into (i, k) must choose kas their Pt.
The interval decomposes intoS[eik] +R[i, k, l] + Int[k, l] + L[l, j, k]:ki l j(ii) If no edges like the dashed edge exist:All edges from l into (i, k) may choose either ior k as their Pt.
The interval decomposes intoS[eik] + LR[i, k, l] + Int[k, l] + Int[l, j]:i k l j(i) If dashed edge exists: All the edges from l into(k, j] must choose i as their Pt.
The interval decom-poses into S[eik] + Int[i, l] + L[l, k, i] +N [k, j, l]:li k j(ii) If no edges like the dashed edge exist: All edgesfrom l may choose k as their Pt.
The interval decom-poses into S[eik] +R[i, l, k] + Int[l, k] + L[k, j, l]:li k jFigure 4: Decomposing an Int[i, j] sub-problem, with Pt(eik) = lbut for simplicity focus the discussion on the decom-position into crossing regions and the maintenanceof the 1-Endpoint-Crossing property.
Edge directiondoes not affect these points of focus, and so we willrefer simply to S[euv] to mean the score of either theedge from u to v or vice-versa.In the following subsections, we show that the op-timal parse for each type of sub-problem can be de-composed into smaller valid sub-problems.
If wetake the maximum over all these possible combina-tions of smaller solutions, we can find the maximumscoring parse for that sub-problem.
Note that theoverall tree is a valid sub-problem (over the inter-val [0, n]), so the argument will also hold for findingthe optimal overall tree.
Each individual vertex andeach pair of adjacent vertices (with no edges) triv-ially form isolated intervals (as there is no interior);this forms the base case of the dynamic program.The overall dynamic program takes O(n4) time:there are O(n2) interval sub-problems, each ofwhich needs two free split points to find the max-imum, and O(n3) region sub-problems, each ofwhich is a maximization over one free split point.4.1 Decomposing an Int sub-problemConsider an isolated interval sub-problem Int[i, j].There are three cases: (1) there are no edges betweeni and the rest of the interval, (2) the longest edge in-cident to i is not crossed, (3) the longest edge inci-dent to i is crossed.
An Int sub-problem can be de-composed into smaller valid sub-problems in each ofthese three cases.
Finding the optimal Int forest canbe done by taking the maximum over these cases:No edges between i and [i + 1, j]: The same setof edges is also a valid Int[i + 1, j] sub-problem.bi must be true for the Int[i + 1, j] sub-problem toensure i+ 1 receives a parent.Furthest edge from i is not crossed: If the furthestedge is to j, the problem can be decomposed intoS[eij ] + Int[i, j], as that edge has no effect on theinterior of the interval.
Clearly, this is only appli-cable if the boundary point needed a parent (as in-dicated by the booleans) and the boolean must thenbe updated accordingly.
If the furthest edge is tosome k in (i, j), the problem is decomposed intoS[eik] + Int[i, k] + Int[k, j].Furthest edge from i is crossed: This is the most17interesting case, which uses two split points: theother endpoint of the edge (k), and l = Pt(eik).
Thedynamic program depends on the order of k and l.l /?
(i,k) (Figure 4a): By Lemma 1, [i, k]?
{l} and[k, l]?
{i} form isolated regions.
(l, j] is the remain-der of the interval, and the only vertex from [i, l) thatcan have edges into (l, j] is k: (i, k) and (k, l) arepart of isolated regions, and i is ruled out because kwas i?s furthest neighbor.If at least one edge from k into (l, j] (the dashedline in Figure 4a) exists, the decomposition is as inFigure 4a, Case i; otherwise, it is as in Figure 4a,Case ii.
In Case i, eik and the edge(s) between k and(l, j] force all of the edges between l and (i, k) tohave k as their Pt.
Thus, the region [i, k]?
{l}mustbe a sub-problem of type R (Figure 3b), as theseedges from l can only be crossed by edges with anendpoint at k (the right endpoint of [i, k]).
All of theedges between k and (l, j] have l as their Pt, as theyare crossed by all the edges in P(eik), and so thesub-problem corresponding to the region [l, j]?
{k}is of type L (Figure 3a).
In Case ii, each of the edgesin P(eik) may choose either i or k as their Pt, so thesub-problem [i, k] ?
{l} is of type LR (Figure 3c).Note that l = j is a special case of Case ii in whichthe rightmost interval Int[l, j] is empty.l ?
(i,k) (Figure 4b): [i, l] ?
{k} and [l, k] ?
{i}form isolated crossing regions by Lemma 1.
Therecannot both be edges between i and (l, k) and be-tween k and (i, l), as this would violate 1-Endpoint-Crossing for the edges in P(eik).
If there are anyedges between i and (l, k) (i.e., Case i in Figure 4b),then all of the edges in P(eik) must choose i as theirPt, and so these edges cannot be crossed at all inthe region [k, j]?
{l}, and there cannot be any edgesfrom k into (i, l).
If there are no such edges (Caseii in 4b), then k must be a valid Pt for all edges inP(eik), and so there can both be edges from k into(i, l) and [k, j] ?
{l} may be of type L (allowingcrossings with an endpoint at k).4.2 Decomposing an LR sub-problemAn LR sub-problem is over an isolated crossing re-gion [i, j] ?
{x}, such that edges from x into (i, j)may be crossed by edges with an endpoint at either ior j.
This sub-problem is only defined when neitheri nor j get their parent from this sub-problem.
Froma top-down perspective, this case is only used whenthere will be an edge between i and j (as in one ofthe sub-problems in Figure 4a, Case ii).If none of the edges from x are crossed by anyedges with an endpoint at i, this can be consideredan R problem.
Similarly, if none are crossed by anyedges with an endpoint at j, this may be consideredan L sub-problem.
The only case which needs dis-cussion is when both edges with an endpoint at i andalso at j cross edges from x; see Figure 3c for aschematic.
In that scenario, there must exist a splitpoint such that: (1) to the left of the point, all edgescrossing x-edges have an endpoint at i, and to theright of the point, all such edges have an endpoint atj, and (2) no edges in the region cross the split point.Let ri be i?s rightmost child in (i, j); let lj bej?s leftmost child in (i, j).
Every edge from x into(i, ri) is crossed by eiri ; every edge between x and(lj , j) is crossed by eljj .
eiri cannot cross eljj , asthat would either violate 1-Endpoint-Crossing (be-cause of the x-interior edges) or create a cycle (ifboth children are also connected by an edge to x).
riand lj also cannot be equal: as neither i nor j maybe assigned a parent, they must both be in the direc-tion of the child, and the child cannot have multipleparents.
Thus, ri is to the left of lj .Any split point between ri and lj clearly satis-fies (1).
There is at least one point within [ri, lj ]that satisfies (2) as long as there is not a chainof crossing edges from eiri to eljj .
The proof isomitted for space reasons, but such a chain can beruled out using a counting argument similar to thatin the proof in Section 5.1.
The decomposition is:L[i, k, x] +R[k, j, x] for some k ?
(i, j).4.3 Decomposing an N sub-problemConsider the maximum scoring forest of type Nover [i, j] ?
{x} (Figure 3d; no edges from x arecrossed in this sub-problem).
If there are no edgesfrom x, then it is also a valid Int[i, j] sub-problem.If there are edges between x and the endpoints i or j,then the forest with that edge removed is still a validN sub-problem (with the ancestor and parent book-keeping updated).
Otherwise, if there are edges be-tween x and (i, j), choose the neighbor of x closestto j (call it k).
Since the edge exk is not crossed,there are no edges from [i, k) into (k, j]; since k wasthe neighbor of x closest to j, there are no edgesfrom x into (k, j].
Thus, the region decomposes into18x k ji(i) If dashed edge exists: All the edges from i into(k, j] must choose x as their Pt.
The interval decom-poses into S[exk] + L[i, k, x] +N [k, j, i]:x k ji(ii) If no edges like the dashed edge exist: Edgesfrom i into (k, j] may choose k as their Pt.
The in-terval decomposes into S[exk]+Int[i, k]+L[k, j, i]:x k jiFigure 5: An L sub-problem over [i, j] ?
{x}, k isthe neighbor of x furthest from i in the interval.S[eik] + Int[k, j] +N [i, k, x].As an aside, if bx was true (x needed a parentfrom this sub-problem), and k was a child of x,then x?s parent must come from the [i, k]?
{x} sub-problem.
However, it cannot be a descendant of k,as that would cause a cycle.
Thus in this case, wecall the sub-problem a N_XFromI problem, to in-dicate that x needs a parent, i and k do not, and xmust be descended from i, not k.4.4 Decomposing an L or R sub-problemAn L sub-problem over [i, j]?
{x} requires that anyedges in this region that cross an edge with an end-point at x have an endpoint at i (the left endpoint).
Ifthere are no edges between x and [i, j] in an L sub-problem, then it is also a valid Int sub-problem over[i, j].
If there are edges between x and i or j, thenthe sub-problem can be decomposed into that edgeplus the rest of the forest with that edge removed.The interesting case is when there are edges be-tween x and the interior (Figure 5).
Let k be theneighbor of x within (i, j) that is furthest from i. Asall edges that cross exk will have an endpoint at i,there are no edges between (i, k) and (k, j].
Com-bined with the fact that k was the neighbor of x clos-est to j, we have that [i, k] ?
{x} must form an iso-a b c d e fFigure 6: 2-planar but not 1-Endpoint-Crossinglated crossing region, as must [k, j] ?
{i}.If there are additional edges between x and the in-terior (Case i in 5), all of the edges from i into (k, j]cross both the edge exk and the other edges from xinto (i, k).
The Pt for all these edges must there-fore be x, and as x is not in the region [k, j] ?
{i},those edges cannot be crossed at all in that region(i.e., [k, j] ?
{i} must be of type N ).
If there are noadditional edges from x into (i, k) (Case ii in Fig-ure 5), then all of the edges from i into (k, j) mustchoose either x or k as their Pt.
As there will be nomore edges from x, choosing k as their Pt allowsstrictly more trees, and so [k, j]?
{i} can be of typeL (allowing edges from i to be crossed in that regionby edges with an endpoint at k).An R sub-problem is identical, with k insteadchosen to be the neighbor of x furthest from j.5 Connections5.1 Graph Theory: All 1-Endpoint-CrossingTrees are 2-PlanarThe 2-planar characterization of dependency struc-tures in G?mez-Rodr?guez and Nivre (2010) exactlycorrespond to 2-page book embeddings in graph the-ory: an embedding of the vertices in a graph ontoa line (by analogy, along the spine of a book), andthe edges of the graph onto one of 2 (more gener-ally, k) half-planes (pages of the book) such that noedges on the same page cross (Bernhart and Kainen,1979).
The problem of finding an embedding thatminimizes the number of pages required is a naturalformulation of many problems arising in disparateareas of computer science, for example, sorting a se-quence using the minimum number of stacks (Evenand Itai, 1971), or constructing fault-tolerant layoutsin VLSI design (Chung et al 1987).In this section we prove 1-Endpoint-Crossing ?2-planar.
These classes are not equal (Figure 6).We first prove some properties about the crossingsgraphs (G?mez-Rodr?guez and Nivre, 2010) of 1-Endpoint-Crossing trees.
The crossings graph of a19(a,b) (a,c)(b,d) (c,e)(d,f)(a)(a,b) (a,c)(b,e)(g,d)(h,f)(b,g)(g,h)(b)Figure 7: The crossing graphs for Figures 1a and 1b.graph has a vertex corresponding to each edge inthe original, and an edge between two vertices if thetwo edges they correspond to cross.
The crossingsgraphs for the dependency trees in Figures 1a and1b are shown in Figures 7a and 7b, respectively.Lemma 2.
No 1-Endpoint-Crossing tree has a cycleof length 3 in its crossings graph.Proof.
Assume there existed a cycle e1, e2, e3.
e1and e3 must share an endpoint, as they both crosse2.
Since e1 and e3 share an endpoint, e1 and e3 donot cross.
Contradiction.Lemma 3.
Any odd cycle of size n (n ?
4) in acrossings graph of a 1-Endpoint-Crossing tree usesat most n distinct vertices in the original graph.Proof.
Let e1, e2, ..., en be an odd cycle in a cross-ings graph of a 1-Endpoint-Crossing tree with n ?4.
Since n ?
4, e1, e2, en?1, and en are distinctedges.
Let a be the vertex that e1 and en?1 share(because they both cross en) and let b be the vertexthat e2 and en share (both cross e1).
Note that e1and en?1 cannot contain b and that e2 and en cannotcontain a (otherwise they would not cross an edgeadjacent to them along the cycle).We will now consider how many vertices eachedge can introduce that are distinct from all verticespreviously seen in the cycle.
e1 and e2 necessarilyintroduce two distinct vertices each.Let eo be the first odd edge that contains b (weknow one exists since en contains b).
(o is at least 3,since e1 does not contain b.)
eo?s other vertex mustbe the one shared with eo?2 (eo?2 does not contain b,since eo was the first odd edge to contain b).
There-fore, both of eo?s vertices have already been seenalong the cycle.Similarly, let ee be the first even edge that con-tains an a.
By the same reasoning, ee must not in-troduce any new vertices.All other edges ei such that i > 2 and ei 6= eo andei 6= ee introduce at most one new vertex, since onemust be shared with the edge ei?2.
There are n ?
4such edges.Counting up all possibilities, the maximum num-ber of distinct vertices is 4 + (n?
4) = n.Theorem 1.
1-Endpoint-Crossing trees ?
2-planar.Proof.
Assume there existed an odd cycle in thecrossings graph of a 1-Endpoint-Crossing tree.
Thecycle has size at least 5 (by Lemma 2).
There areat least as many edges as vertices in the subgraph ofthe forest induced by the vertices used in the cycle(by Lemma 3).
That implies the existence of a cyclein the original graph, contradicting that the originalgraph was a tree.Since there are no odd cycles in the crossingsgraph, the crossings graph of edges is bipartite.
Eachside of the bipartite graph can be assigned to a page,such that no two edges on the same page cross.Therefore, the original graph was 2-planar.5.2 Linguistics: Cross-serial VerbConstructions and Successive CyclicityCross-serial verb constructions were used to provideevidence for the ?non-context-freeness?
of naturallanguage (Shieber, 1985).
Cross-serial verb con-structions with two verbs form 1-Endpoint-Crossingtrees.
Below is a cross-serial sentence from Swiss-German, from (1) in Shieber (1985):das mer em Hans es huus h?lfed aastriichethat we HansDAT the houseACC helped paintThe edges (that , helped), (helped ,we), and(helped ,Hans) are each only crossed by an edgewith an endpoint at paint; the edge (paint , house)is only crossed by edges with an endpoint at helped.More generally, with a set of two cross serial verbsin a subordinate clause, each verb should suffice asthe crossing point for all edges incident to the otherverb that are crossed.Cross-serial constructions with three or moreverbs would have dependency trees that violate 1-20What did say BA C ... Z ate t ?nsaid 1 said 2t1 t2Figure 8: An example of wh-movement over a poten-tially unbounded number of clauses.
The edges be-tween the heads of each clause cross the edges fromtrace to trace, but all obey 1-Endpoint-Crossing.Endpoint-Crossing.
Psycholinguistically, betweentwo and three verbs is exactly where there is a largechange in the sentence processing abilities of humanlisteners (based on both grammatical judgments andscores on a comprehension task) (Bach et al 1986).More speculatively, there may be a connectionbetween the form of 1-Endpoint-Crossing trees andphases (roughly, propositional units such as clauses)in Minimalism (Chomsky et al 1998).
Figure 8shows an example of wh-movement over a poten-tially unbounded number of clauses.
The phase-impenetrability condition (PIC) states that only thehead of the phase and elements that have moved toits edge are accessible to the rest of the sentence(Chomsky et al 1998, p.22).
Movement is there-fore required to be successive cyclic, with a movedelement leaving a chain of traces at the edge ofeach clause on its way to its final pronounced loca-tion (Chomsky, 1981).
In Figure 8, notice that thecrossing edges form a repeated pattern that obeysthe 1-Endpoint-Crossing property.
More generally,we suspect that trees satisfying the PIC will tend toalso be 1-Endpoint-Crossing.
Furthermore, if thetraces were not at the edge of each clause, and in-stead were positioned between a head and one ofits arguments, 1-Endpoint-Crossing would be vio-lated.
For example, if t2 in Figure 8 were be-tween C and said2, then the edge (t1, t2) would cross(say, said1), (said1, said2), and (C, said2), whichdo not all share an endpoint.
An exploration of theselinguistic connections may be an interesting avenuefor further research.6 Conclusions1-Endpoint-Crossing trees characterize over 95% ofstructures found in natural language treebank, andcan be parsed in only a factor of n more time thanprojective trees.
The dynamic programming algo-rithm for projective trees (Eisner, 2000) has beenextended to handle higher order factors (McDonaldand Pereira, 2006; Carreras, 2007; Koo and Collins,2010), adding at most a factor of n to the edge-based running time; it would be interesting to ex-tend the algorithm presented here to include higherorder factors.
1-Endpoint-Crossing is a conditionon edges, while properties such as well-nestednessor block degree are framed in terms of subtrees.Three edges will always suffice as a certificate of a1-Endpoint-Crossing violation (two vertex-disjointedges that both cross a third).
In contrast, for aproperty like ill-nestedness, two nodes might havea least common ancestor arbitrarily far away, and soone might need the entire graph to verify whetherthe sub-trees rooted at those nodes are disjoint andill-nested.
We have discussed cross-serial depen-dencies; a further exploration of which linguisticphenomena would and would not have 1-Endpoint-Crossing dependency trees may be revealing.AcknowledgmentsWe would like to thank Julie Legate for an in-teresting discussion.
This material is based uponwork supported under a National Science Foun-dation Graduate Research Fellowship, NSF AwardCCF 1137084, and Army Research Office MURIgrant W911NF-07-1-0216.A Dynamic Program to find the maximumscoring 1-Endpoint-Crossing TreeInput: Matrix S: S[i, j] is the score of the directed edge (i, j)Output: Maximum score of a 1-Endpoint-Crossing tree oververtices [0, n], rooted at 0Init: ?i Int[i, i, F, F ] = Int[i, i+ 1, F, F ] = 0Int[i, i, T, F ] = Int[i, i, F, T ] = Int[i, i, T, T ] = ?
?Final: Int[0, n, F, T ]Shorthand for booleans: T F (x, S) :=if x = T , exactly one of the set S is trueif x = F , all of the set S must be falsebi, bj , bx are true iff the corresponding boundary point has itsincoming edge (parent) in that sub-problem.
For the LR sub-problem, bi and bj are always false, and so omitted.
For allsub-problems with the suffix AFromB, the boundary point Ahas its parent edge in the sub-problem solution; the other twoboundary points do not.
For example, L_XFromI would cor-respond to having booleans bi = bj = F and bx = T , with therestriction that x must be a descendant of i.21Int[i, j, F, bj ]?
max????????????????????
?Int[i+ 1, j, T, F ] if bj = FS[i, j] + Int[i, j, F, F ] if bj = Tmaxk?
(i,j)S[i, k]+??????????????
?Int[i, k, F, F ] + Int[k, j, F, bj ]maxT F (bj ,{bl,br})LR[i, k, j, bl] + Int[k, j, F, br]maxl?
(k,j),T F (T,{bl,bm,br}){R[i, k, l, F, F, bl] + Int[k, l, F, bm] + L[l, j, k, br, bj , F ]LR[i, k, l, bl] + Int[k, l, F, bm] + Int[l, j, br, bj ]maxl?
(i,k),T F (T,{bl,bm,br}){Int[i, l, F, bl] + L[l, k, i, bm, F, F ] +N [k, j, l, F, bj , br]R[i, l, k, F, bl, F ] + Int[l, k, bm, F ] + L[k, j, l, F, bj , br]Int[i, j, T, F ]?
symmetric to Int[i, j, F, T ]Int[i, j, T, T ]?
?
?LR[i, j, x, bx]?
max????
?L[i, j, x, F, F, bx]R[i, j, x, F, F, bx]maxk?
(i,j),T F (bx,{bxl,bxr}),T F (T,{bkl,bkr})L[i, k, x, F, bkl, bxl] +R[k, j, x, bkr, F, bxr]N [i, j, x, bi, bj , F ]?
max??????
?Int[i, j, bi, bj ]S[x, i] +N [i, j, x, F, bj , F ] if bi = TS[x, j] +N [i, j, x, bi, F, F ] if bj = Tmaxk?
(i,j)S[x, k] +N [i, k, x, bi, F, F ] + Int[k, j, F, bj ]N [i, j, x, F, bj , T ]?
max??????????????
?S[i, x] +N [i, j, x, F, bj , F ]S[x, j] +N_XFromI[i, j, x] if bj = TS[j, x] +N [i, j, x, F, F, F ] if bj = FS[j, x] + Int[i, j, F, T ] if bj = Tmaxk?
(i,j)S[x, k] +N_XFromI[i, k, x] + Int[k, j, F, bj ]maxk?
(i,j)S[k, x]+{Int[i, k, F, T ] + Int[k, j, F, bj ]N [i, k, x, F, F, F ] + Int[k, j, T, bj ]N [i, j, x, T, F, T ]?
symmetric to N [i, j, x, F, T, T ]N [i, j, x, T, T, T ]?
?
?N_XFromI[i, j, x]?
max????
?S[i, x] +N [i, j, x, F, F, F ]maxk?
(i,j){S[x, k] +N_XFromI[i, k, x] + Int[k, j, F, F ]S[k, x] + Int[i, k, F, T ] + Int[k, j, F, F ]N_IFromX[i, j, x]?
max{S[x, i] +N [i, j, x, F, F, F ]maxk?
(i,j)S[x, k] +N [i, k, x, T, F, F ] + Int[k, j, F, F ]N_XFromJ [i, j, x]?
symmetric to N_XFromI[i, j, x]N_JFromX[i, j, x]?
symmetric to N_IFromX[i, j, x]L[i, j, x, bi, bj , F ]?
max??????????
?Int[i, j, bi, bj ]S[x, i] + L[i, j, x, F, bj , F ] if bi = TS[x, j] + L[i, j, x, bi, F, F ] if bj = Tmaxk?
(i,j),T F (bi,{bl,br})S[x, k]+{L[i, k, x, bl, F, F ] +N [k, j, i, F, bj , br]Int[i, k, bl, F ] + L[k, j, i, F, bj , br]L[i, j, x, F, bj , T ]?
max??????????????????
?S[i, x] + L[i, j, x, F, bj , F ]S[x, j] + L_XFromI[i, j, x] if bj = TS[j, x] + L[i, j, x, F, F, F ] if bj = FS[j, x] + L_JFromI[i, j, x] if bj = Tmaxk?
(i,j)S[x, k] + L_XFromI[i, k, x] +N [k, j, i, F, bj , F ]maxk?
(i,j)S[k, x]+????
?L_JFromI[i, k, x] +N [k, j, i, F, bj , F ]L[i, k, x, F, F, F ] +N [k, j, i, T, bj , F ]maxT F (T,{bl,br})Int[i, k, F, bl] + L[k, j, i, br, bj , F ]L[i, j, x, T, bj , T ]?
not reachableL_XFromI[i, j, x]?
max????????????
?S[i, x] + L[i, j, x, F, F, F ]maxk?
(i,j)S[x, k] + L_XFromI[i, k, x] +N [k, j, i, F, F, F ]maxk?
(i,j)S[k, x]+????
?L_JFromI[i, k, x] +N [k, j, i, F, F, F ]L[i, k, x, F, F, F ] +N_IFromX[k, j, i]Int[i, k, F, T ] + L[k, j, i, F, F, F ]Int[i, k, F, F ] + L_IFromX[k, j, i]L_IFromX[i, j, x]?
max??????????
?S[x, i] + L[i, j, x, F, F, F ]maxk?
(i,j)S[x, k]+????
?L[i, k, x, T, F, F ] +N [k, j, i, F, F, F ]L[i, k, x, F, F, F ] +N_XFromI[k, j, i]Int[i, k, T, F ] + L[k, j, i, F, F, F ]Int[i, k, F, F ] + L_XFromI[k, j, i]L_JFromX[i, j, x]?
max??????
?S[x, j] + L[i, j, x, F, F, F ]maxk?
(i,j)S[x, k]+{L[i, k, x, F, F, F ] + Int[k, j, F, T ]Int[i, k, F, F ] + L_JFromI[k, j, i]L_JFromI[i, j, x]?
max??????
?Int[i, j, F, T ]maxk?
(i,j)S[x, k]+{L[i, k, x, F, F, F ] +N_JFromX[k, j, i]Int[i, k, F, F ] + L_JFromX[k, j, i]22R[i, j, x, bi, bj , F ]?
symmetric to L[i, j, x, bi, bj , F ]R[i, j, x, bi, F, T ]?
symmetric to L[i, j, x, F, bj , T ]R[i, j, x, bi, T, T ]?
not reachableR_XFromJ [i, j, x]?
symmetric to L_XFromI[i, j, x]R_JFromX[i, j, x]?
symmetric to L_IFromX[i, j, x]R_IFromX[i, j, x]?
symmetric to L_JFromX[i, j, x]R_IFromJ [i, j, x]?
symmetric to L_JFromI[i, j, x]ReferencesE.
Bach, C. Brown, and W. Marslen-Wilson.
1986.Crossed and nested dependencies in german and dutch:A psycholinguistic study.
Language and CognitiveProcesses, 1(4):249?262.F.
Bernhart and P.C.
Kainen.
1979.
The book thicknessof a graph.
Journal of Combinatorial Theory, SeriesB, 27(3):320 ?
331.M.
Bodirsky, M. Kuhlmann, and M. M?hl.
2005.
Well-nested drawings as models of syntactic structure.
InIn Tenth Conference on Formal Grammar and NinthMeeting on Mathematics of Language, pages 88?1.University Press.X.
Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of theCoNLL Shared Task Session of EMNLP-CoNLL, vol-ume 7, pages 957?961.N.
Chomsky, Massachusetts Institute of Technology.Dept.
of Linguistics, and Philosophy.
1998.
Minimal-ist inquiries: the framework.
MIT occasional papersin linguistics.
Distributed by MIT Working Papers inLinguistics, MIT, Dept.
of Linguistics.N.
Chomsky.
1981.
Lectures on Government and Bind-ing.
Dordrecht: Foris.F.
Chung, F. Leighton, and A. Rosenberg.
1987.
Em-bedding graphs in books: A layout problem with ap-plications to VLSI design.
SIAM Journal on AlgebraicDiscrete Methods, 8(1):33?58.H.
Cui, R. Sun, K. Li, M.Y.
Kan, and T.S.
Chua.
2005.Question answering passage retrieval using depen-dency relations.
In Proceedings of the 28th annualinternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 400?407.ACM.A.
Culotta and J. Sorensen.
2004.
Dependency treekernels for relation extraction.
In Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, page 423.
Association for Compu-tational Linguistics.Y.
Ding and M. Palmer.
2005.
Machine translation usingprobabilistic synchronous dependency insertion gram-mars.
In Proceedings of the 43rd Annual Meetingon Association for Computational Linguistics, pages541?548.
Association for Computational Linguistics.J.
Eisner.
2000.
Bilexical grammars and their cubic-time parsing algorithms.
In Harry Bunt and AntonNijholt, editors, Advances in Probabilistic and OtherParsing Technologies, pages 29?62.
Kluwer AcademicPublishers, October.S.
Even and A. Itai.
1971.
Queues, stacks, and graphs.In Proc.
International Symp.
on Theory of Machinesand Computations, pages 71?86.C.
G?mez-Rodr?guez and J. Nivre.
2010.
A transition-based parser for 2-planar dependency structures.
InProceedings of ACL, pages 1492?1501.C.
G?mez-Rodr?guez, J. Carroll, and D. Weir.
2011.
De-pendency parsing schemata and mildly non-projectivedependency parsing.
Computational Linguistics,37(3):541?586.T.
Koo and M. Collins.
2010.
Efficient third-order de-pendency parsers.
In Proceedings of ACL, pages 1?11.M.
Kuhlmann.
2013.
Mildly non-projective dependencygrammar.
Computational Linguistics, 39(2).R.
McDonald and F. Pereira.
2006.
Online learning ofapproximate dependency parsing algorithms.
In Pro-ceedings of EACL, pages 81?88.R.
McDonald and G. Satta.
2007.
On the complexityof non-projective data-driven dependency parsing.
InProceedings of the 10th International Conference onParsing Technologies, pages 121?132.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005.Non-projective dependency parsing using spanningtree algorithms.
In Proceedings of the conference onHuman Language Technology and Empirical Methodsin Natural Language Processing, pages 523?530.
As-sociation for Computational Linguistics.E.
Pitler, S. Kannan, and M. Marcus.
2012.
Dynamicprogramming for higher order parsing of gap-mindingtrees.
In Proceedings of EMNLP, pages 478?488.L.A.
Ringenberg.
1967.
College geometry.
Wiley.A.
Rush and S. Petrov.
2012.
Vine pruning for effi-cient multi-pass dependency parsing.
In Proceedingsof NAACL, pages 498?507.S.M.
Shieber.
1985.
Evidence against the context-freeness of natural language.
Linguistics and Philoso-phy, 8(3):333?343.H.
Zhang and R. McDonald.
2012.
Generalized higher-order dependency parsing with cube pruning.
In Pro-ceedings of EMNLP, pages 320?331.2324
