EL IC IT ING NATURAL SPEECH FROM NON-NATIVEUSERS:  COLLECT ING SPEECH DATA FOR LVCSRLaura  Mayf ie ld  Tomok iyo  and Susanne BurgerInteractive Systems LaboratoriesLanguage Technologies Inst i tuteCarnegie Mellon UniversityP i t tsburgh,  PA 15213 USA{laura,sburger}@cs.cmu.eduAbst rac tIn this paper, we discuss the design of a databaseof recorded and transcribed read and sponta-neous speech of semi-fluent, strongly-accentednon-native speakers of English.
While manyspeech applications work best with a recognizerthat expects native-like usage, others could ben-efit from a speech recognition component that isforgiving of the sorts of errors that are not abarrier to communication; in order to train sucha recognizer a database of non-native speech isneeded.
We examine how collecting data fromnon-native speakers must necessarily differ fromcollection from native speakers, and describework we did to develop an appropriate scenario,recording setup, and optimal surroundings dur-ing recording.1 In t roduct ionAs part of work in improving speech recognitionperformance for non-native speakers, we wantedto develop a database that captures ways inwhich non-native language use differs from na-tive language use in a specific domain.
Featureswe were interested in include pronunciation, lex-ical choice, syntax, expressive goals, and strate-gies speakers use when they are unsure of theappropriate English expression.
We wanted therecorded ata to be appropriate for LVCSR sys-tem training, which means that the signal qual-ity should be good and the speech should be asclose as possible in terms of style and contentto speech that will be used in the target ap-plication, a tourist information query system.We also wanted to elicit data which would con-tain examples of systematic and unsystematicvariation in the speech of low- to mid-fluencynon-native speakers.One of the most interesting aspects of theseexperiments was the ways in which we found5ourselves needing to adapt our usual data col-lection strategies to the needs of our speakers,whose English abilities varied from beginningto near-native.
It is important o be aware ofa number of assumptions that are commonlymade which do not necessarily hold for non-native speakers, and which it is important oaddress when designing a data collection proto-col.The  act of  speak ing  is not  diff icult.When recording native speakers peaking spon-taneously for standard LVCSR projects (that is,not projects geared towards pecial populationsor difficult tasks), it is assumed that the the actof speaking does not in and of itself representa major cognitive load for the speaker.
Thiscan be very untrue of non-native speakers, andwe had several speakers ask to quit in the mid-dle of the recording because they felt unable tocontinue.
The researcher needs to make a deci-sion about what to do in such a situation, andpossibly prepare an alternate task.There  is l i tt le r isk of  a l ienat ing thecommuni ty .
Local communities of non-nativespeakers are not always large, and if it is closeknit, word can quickly spread if the task istoo hard or embarassing.
Also, it is impor-tant to de-emphasize the fact that we are in-terested, among other things, in imperfectionsin the speaker's peech, or risk offending thecommunity.The  task  is not  perce ived as a test .Again, when speaking spontaneously, few nativespeakers of nonstigmatized varieties of Englishwould feel that they are being evaluated on thecorrectness of their speech.
Many non-nativespeakers will feel tested, and as this can makethem nervous and affect their speech, it is im-portant o reassure them as far as possible thatthey are not being tested and that the data isbeing anonymized.The  speaker  knows what  to say.
Mostspontaneous collection tasks are chosen becausethey are tasks speakers can be expected to havedone before and be comfortable with.
Althougha non-native speaker has probably made an air-plane reservation i  his native language before,it is entirely possible that he has never doneso in the target language, and does not have agood idea of what he should say in that situ-ation.
If he were really planning to make anairplane reservation in the target language, hewould probably think about what to say in ad-vance and might even ask someone, which hemay not have a chance to do during the datacollection.
This undermines the representative-ness of the database.We carried out a number of exploratory ex-periments to try to determine the format whichwas the most comfortable for the speaJ~ers andwhich resulted in elicitation of the most natu-ral data; two of these experiments are describedin Section 3.
For these experiments we workedwith native speakers of Japanese.
The protocolthat we settled on, which we feel is very effec-tive for non-native speakers, is described in Sec-tion 4.
Although transcription and analysis ofthis data is at the beginning stages, we have al-ready seen patterns that will be useful for devel-oping acoustic and language models.
Examplesare shown in Section 5.2 Re la ted  WorkByrne et al(Byrne and others, 1998) describea conversational English data collection pro-tocol with native speakers of Spanish as itstargets.
They identified their speakers withone of three skill levels and had them per-form level-appropriate asks designed to elicitspecific grammatical structures.
Participantsspoke over the telephone with other non-nativespeakers, forcing them to communicate usingspeech.
They found that this was an effec-tive way to elicit spontaneous speech from non-native speakers of all fluency levels in a purelyconversational domain.A number of studies discuss techniques forcollecting spoken data from non-native speak-ers in the context of a language tutoring sys-tem.
Most such systems ((Eskenazi, 1997; Witt6and Young, 1997; Kawai and Hirose, 1997) areexamples) ask users to read a prompt or nar-rowly constrain what the user is allowed to say.Neumeyer et al (Neumeyer et al, 1998) de-scribe a system that evaulates students' pronun-ciation in text-independent speech.
They col-lected a database of read speech, both newspa-per and conversational sentences, and imitatedspeech, in which students imitated the speech ofnative speakers; as subjects, they used Ameri-can students of French.Aist et al (Aist and others, 1998) discussconsiderations in collecting speech from chil-dren, pointing out that children may be uncoop-erative and easily bored, and may have difficultyreading.
They describe an unsupervised atacollection method in which recognized speechis compared to the transcript that the childis expected to read, and utterances in whichpart or all of hypothesis match the transcriptare used for additional system training.
Thistype of technique is not as effective for a systemthat handles completely spontaneous queries,but their observations about children's abilities(especially articulatory and reading difficulties)and reaction to formalized ata collection par-allel ours in our study of non-native speakers.Outside the field of speech recognition, muchresearch as been done into methods for elicit-ing natural speech.
Briggs (Briggs, 1986) em-phasizes the importance of understanding themeaning of the speech event for the speaker.Recording for a research project may be a fa-miliar event for the researcher, but not forthe speaker.
Reading aloud is commonplacein American schools, but participants of differ-ent backgrounds may be intimidated or even of-fended when asked to read aloud.
While nativespeakers of English certainly vary in their com-fort reading and speaking, when the researchersare also native speakers of English, there are farfewer cultural variables that can lead to misun-derstanding and compromise the integrity of thedata.In his description of the field methodologyin the project on linguistic change and varia-tion, Labov (Labov, 1984) describes a numberof issues in spoken data collection, mentioningamong other things the long-term relationshipwith the speaker pool.
This is of course impor-tant for both longitudinal studies; also, whenstudying the speech of a restricted group, it isimportant hat people do not come out of thedata collection experience f eling that they havebeen objectified or misunderstood.
Labov re-turns to this point in the context of ethical con-siderations in data collection.What exactly does "natural speech" mean inthe case of the non-native speaker?
Wolfson(Wolfson, 1976) defines the notion of naturalspeech "as properly equivalent o that of ap-propriate speech; as not equivalent o unself-conscious peech."
That is, in some situations,it is natural to speak carefully, and that care-ful speech in such contexts hould not be con-sidered unnatural.
For semi-fluent non-nativespeakers, whether they are at a real informa-tion desk or recording a contrived scenario, theirspeech will most likely be planned.3 P i lo t  Exper iments3.1 Record ing  SetupAll recordings were taken by a DAT recorder;speakers wore a Sennheiser headset.
Recordingswere done in a small computer lab with someincidental noise but no excessive outside noise.On some occasions there were other people inthe room when the recording was being done;this will be discussed further below.
In non-interactive recordings, users were seated at atable with the instruction sheets, pen or pencil,and water.
Speakers were permitted to stop andrestart recording at any time.We did two pilot experiments which greatlyhelped us to understand the needs of our speak-ers and how we could make them more com-fortable, in turn improving the quality of ourdata.
For these experiments, we recorded na-tive speakers of Japanese.3.1.1 P i lot  exper iment  oneIn the first experiment, we drew from a human-machine collection task that we had had successwith for native speakers in a similar applica-tion in another domain.
Speakers were providedwith prompts such as the following:?
Ask how to get to the museum?
Find out where you can exchange money?
Ask where to get a ticket for the subwaySpeakers came in on two different occasionsand gave us feedback after both.
The firsttime they came in, they were given the prompts7in English.
As we had predicted, they werestrongly influenced in their word choice by thephrasings used in the prompts.
The secondtime they came in, they were given the promptsin their native language .
They felt that thistask was much harder; they perceived it as atranslation task in which they were expected togive a correct answer, whereas with the Englishprompts they were effectively given the correctanswer.
Their productions, however, were morevaried, different both from each other and fromthe original English prompt.In addition to the prompt-based task, we hadspeakers read from a local travel guide, specifi-cally about the university area so that the con-text would be somewhat familiar.
We foundthat there were indeed reading errors of the typethat would not occur in spontanous speech.We observed that some speakers were stum-bling over words that they obviously didn'tknow.
We attempted to normalize for this byhaving them read utterances that had been pre-viously recorded and transcribed, hoping thatthey would be more likely to be familiar withwords that other speakers of similar fluency hadused.
We still found that they had some dif-ficulty in reading.
Our speakers were nativespeaker s of Japanese, however, which has a dif-ferent writing system; this would have some in-fluence.There was also a fair amount of stumblingover words in the prompted tasks, especiallywith proper nouns, and we have not yet lookedat the correspondence between stumbling inread speech of familiar words and stumbling inspontaneous speech.
It may be the case thatthey are more closely related than they are fornative speakers.3.1.2 P i lot  exper iment  twoIn the second pilot experiment, we attempted awizard-of-oz collection using an interactive map;the speakers could ask for locations and routesto be highlighted in the map, and there was atext screen to which the wizard could send mes-sages to answer speaker queries.
Instead of a listof prompts, the speakers were given a sheet ofpaper listing some points of interest in the city,hotel names, some features that they could askabout (business hours, location, etc.)
and thedates that they would be in the city.
Their taskwas to plan a weekend, finding hotels, restau-rants, and things to do.
Our thought was thatperhaps peakers would speak more naturally inan information-gathering task, where they areactually trying to communicate instead of sim-ply producing sentences.Our general impression was that although thevisual highlighting of the locations was a fea-ture that the users enjoyed, and which helpedthem to become involved in the task, the utter-ances could not be characterized as more nat-ural than those given in the prompted task.
Itwas also our feeling that speakers were less sureof what to do in a less structured task; bothlack of confidence in speaking and unfamiliar-ity with a "just say whatever comes to mind"approach contributed to their general discom-fort.
It took time to read and understand theresponses from the wizard; also, speakers wereaware that someone (the wizard) was listeningin.
Both of these factors were additional sourcesof self-consciousness.
Although we thought hatthe repair dialogues that came about when thewizard misunderstood the speaker were valuabledata, and that someone trained to provide re-sponses geared toward the fluency level of thespeaker would have more success as a wizard, itwas our opinion that given the range of fluencylevels we were targeting, wizard-of-oz collectionwould not be ideal for the following two reasons:?
communication and speaker confidencebreak down when the speaker is really hav-ing trouble expressing himself and the wiz-ard cannot understand?
simulating a real-life experience, such asmaking a hotel reservation, without thereal goal of wanting to stay in a hoteland background knowledge about the trip,can be very difficult depending on languageability and cultural background4 F ina l  P ro toco lThe final data collection protocol that we set-tled on has three parts.
The first is a seriesof scenarios, in each of which a situation is de-scribed in the speaker's native language (L1)and a list is given in bullet form of things rele-vant to the situation that the speaker is to askabout.
For instance, if the situation is a Pitts-burgh Steelers game, the speakers would see thebullets?
arena location?
ticket price?
seat availability?
transportation?
game timeThe bullets are made as short as possible sothat the speakers absorb them in a glance andcan concentrate onformulating an original ques-tion instead of on translating a specific phraseor sentence.The second part is a read task.
There wasno doubt left after the pilot experiments hatthe amount of patience speakers had with theprompted task was limited; after the noveltywore off speakers tired quickly.
Although spon-taneous data would be better than read data,read data would be better than no data, andspeakers eemed willing to continue at leastas long again reading as they had with theprompted task.
We considered two types ofmaterial for the reading.
Some sort of pho-netically balanced text is often used for datacollection, so that the system is trained with awide variety of phonetic contexts.
Given thatour speakers are even more restricted in theirphrasings than native speakers are in conversa-tional speech, it is likely that some phonetic on-texts are extremely sparsely represented in ourdata.
However, it may be the case that semi-fluent speakers avoid some constructions pre-cisely because they are difficult to pronounce,and a sparsity in the training data probably isa good predictor of a sparsity in unseen data;even with new words, which may have as-yet-unseen phonetic contexts, non-native speakersmay not pronounce them at all in the way thatthe designer of the phonetically balanced texthad anticipated.
We chose a 1000-word versionof the fairy tale Snow White for our read texts;it had the highest syllable growth rate of any ofthe fairy tales we looked at and we augmentedthe syllable inventory by replacing some wordswith others, trying to ensure at the same timethat all of the words were ones our speakers werelikely to have encountered before.Finally, we ask speakers to read a selection ofpreviously recorded and transcribed utterancesfrom the prompted task, both by native speak-ers and non-native speakers, randomly selected8and with small modifications made to preserveanonymity.
Our objective here was threefold: toquantify the difference between read dialoguesand spontaneous dialogues; to quantify the dif-ference between read dialogues and read prose;and to compare the performance of the endrecognizer on native grammar with non-nativepronunciation with performance on non-nativegrammar with non-native pronunciation.We have recorded 23 speakers o far in thepost-pilot phase of data collection, and all haveexpressed satisfaction with the protocol.5 Ana lys i s  and  ExamplesAlthough transcription and analysis of the datawe have collected so far is in the beginningstages, we have observed patterns that lead usto believe that our protocol is meeting our goalsof eliciting speech from non-native speakers thatis representative of what they would use in a realsystem and that begins to uncover patterns thatare different from those native speakers use andwill be useful in acoustic and language model-ing.The analysis in this section is based on tran-scribed data from 12 speakers.
For compari-son, we recorded three native speakers doing thesame task the non-native speakers did (with En-glish prompts).
This is not a large sample, butgives us some evidence to support our intuitionsabout what native speakers would be likely tosay.5.1 Qua l i ta t ive  Analys isExamples 1-3 show some sample utterancesproduced by the non-native speakers.
Ineach example, the first sentence represents theprompt that would have been used for elicita-tion (speakers were actually given short bullets).Example 1 was selected t o exemplify how speak-ers were influenced in their use of phrasal andcolloquial verbs when given an Englishprompt.We observed that when prompted to ask for di-rections or travel time, native speakers almostalways used the expression "get to."
Non-nativespeakers often used this form when given anEnglish prompt containing it, but almost neverwhen given an L1 prompt.1.
Ask  how to get to the aquarium.How do I get the aquarium?Please let me know how do you go theaquarium?I'd like to go to Aquarium.I want to go to the aquarium so pleaselet me know how to go to thereIn the data we have transcribed so far, 25 of55 uses of get to were by non-native speakers,while 45 of 56 uses of go to were by non-nativespeakers.Example 2 illustrates how number agreementcan be influenced by the Enghsh prompt.
Al-though nativespeakers often misspeak and dis-obey agreement rules in conversational speech,there are situations in which we observed thatthey are consistently careful, and the patternany + Npl, when appropriate, was one.
Thenon-native speakers, on the other hand, consis-tently produced any + Nsing when not primedby an English prompt.
"Any" was also oftenused where a native speaker would use "a."2.
Ask  if there  are any  \ [ restaurantsnearby  / t ickets ava i lab le .
.
.
\].Is there any restaurant around here?is there any good place to visitis there any available ticketdo you have any special exhibitionnowis there any subway aroundOf the 105 instances of use of the word "any,"52 were followed inappropriately by a singularnoun.
When the pattern "any place" is removedfrom the list, 52 out of 81 instances were gram-matically incorrect in this way.
To compare,1 of 21 instances in the native sample weregrammatically incorrect.
Prescriptively incor-rect grammar is expected in spontaneous speecheven by native speakers.
However, when non-native speech consistently strays from patternsobserved in native speech, the bigram and tri-gram contexts used to model language at thesentence l vel can no longer be relied upon.Of course, by using an L1 prompt we areinfluencing the speakers in the opposite direc-tion, priming them to produce a translation ofan L1 word and form an awkward English sen-tence around it when they might not do so inspontaneous system use.
It is difficult to knowwhether this is the case with example 3.
Onthe one hand, the speaker is clearly translating9the Japanese term nyuujouryou (entrance fee).On the other hand, speakers consistently built asentence around the word "fee" where a nativespeaker would use the pattern "how much doesX cost" regardless of what Japanese term wasused.3.
Ask  how much admission costsHow much is the fee for entrance?How much is fee for entering?How much is the fee for admission?Although it was the element of the task thatthe speakers liked the least, the handling of un-familiar expressions showed us how important iwas to prompt users with specific queries thatthey might not know how to express.
In real-world use, an application would have to handlesuch utterances, but in a more free-form datacollection scenario speakers might avoid askingsuch questions altogether.
We included amongthe Japanese prompts expressions which haveno obvious English equivalent in order to ob-serve how speakers expressed themselves whenthey did not know what the right English ex-pression would be.
Speakers were very inventiveand almost always cameup with an understand-able English utterance, as shown in Figure 1(displayed on the following page).?
.~ .~y~ .
.
.
.
.
.35O3OO2502OO150|COSOo i i * i iFigure 2: Vocabulary growth for native andnon-native speakers in the tourist informationtask.
Corpus size is displayed on the x axis andvocabulary size is displayed on the y axis.5.2 Quantitative AnalysisFigure 2 shows the vocabulary growth rate fornative and non-native speakers in the touristinformation task that was our domain forthese experiments.
Interestingly, the vocabu-lary growth seems to be faster for non-native10speakers than for native speakers.
The curvefor native speakers in another similar domain(travel arrangement) for which we have muchmore data was similar to the curve for nativespeakers hown in Fig.
2; in fact, the vocabu-lary size for this bigger corpus did not reach thesize of the non-native corpus at 5600 words until10,000 word tokens had been seen.We also looked at trigram perplexity of thedata collected in the different pilot experimentsmeasured with respect o a model built on thelarge travel arrangement data set.
Although thetest corpora were very small, we found that thecorpus collected from non-native speakers usingEnglish prompts was very similar in terms ofperplexity to the corpus collected from nativespeakers in the tourist information task.
Con-versely, the corpus collected from non-nativespeakers using Japanese prompts showed over1.5 times the perplexity of the native corpus.This indicates that the character of the two non-native corpora are quite different, and that in-corporating the Ll-prompted data in traininga statistical anguage model will increase thepredictive power of the model with respect onon-native speakers.6 D iscuss ionA final question is how many of our observa-tions are Ll-dependent.
It is true that Japanesespeakers how some common patterns in theirspeech and tend to be very self-conscious aboutspeaking.
Japanese is written with a non-romanscript and this probably influences both com-prehension in the spontaneous tasks and read-ing accuracy in the read tasks.
Japanese is verydifferent from English grammatically, pragmat-ically, and phonotactically.
Many of our obser-vations may not be consistent with observationsin collection with native speakers of German, forexample.
In this respect, though, it is really anideal case study for the purposes of uncoveringall the stumbling blocks we may encounter whendesigning data collection for non-native speak-ers.
We found that speakers' reading ability wasgenerally much higher than their conversationalability; Byrne's study (1998) found that theirlowest skill level speakers had some conversa-tional ability but no reading ability.
The im-portant thing to recognize is that the readinglevel - speaking level correspondence is amongthe variables that should be evaluated in orderwhat_sort_of appearance with go should QuEsWhat should I wear?Do we need to wear the formal dress or we can wear the casual one?What kind of clothes do I have to wear for there?In .what kind of dresses hould I go there?Should I oh should I go formal with formal style?What should I wear to go there?bus/boat/train etc.
GEN last_trip GEN timeWhat time is the last return train/bus/ferry?What time is the last train to go back to my house?What time is the last transportation from there?Do you know what time is the last bus ships or trains to return?When does the final bus or ship or train?What time is the final bus?child discountIs there a children's discount?Is there any discount for the for childDo they have a discount for childrenWhen I buy the ticket for children are there any discountIs there special children costHow much is the fee for childrenFigure 1: Inventive expressions.
The Japanese prompt and an English gloss are shown with asample English response at the top of each series.to design an effective data collection protocol.Re ferencesGreg Aist et al 1998.
How Effective is Un-supervised Data Collection for Children'sSpeech Recognition?
In Proceedings of IC-SLP.Charles Briggs.
1986.
Learning How to Ask: ASociolinguistic Appraisal of the Role of theInterview in Social Science Research.
Cam-bridge University Press, Cambridge.William Byrne et al 1998.
Is Automatic SpeechRecognition Ready for Non-Native Speech?A Data Collection Effort and Initial Exper-iments in Modeling Conversational HispanicEnglish.
In Proceedings of Speech Technologyin Language Learning (STILL).Maxine Eskenazi.
1997.
Detection of ForeignSpeakers' Pronunciation Errors for SecondLanguage Training- Preliminary Results.
InProceedings of Eurospeech.Gob Kawai and Keikichi Hirose.
1997.
A CALLSystem Using Speech Recognition to Trainthe Pronunciation of Japanese Long Vowels,the mora nasal and mora obstruents.
In Pro-ceedings of Eurospeech, Rhodes.William Labov.
1984.
Field methods of theproject on linguistic change and variation.
InLanguage in Use: Readings in Sociolinguis-tics, pages 28 - 66.
Prentice-Hall.Leonardo Neumeyer, Horacio Franco, MitchelWeintraug, and Patti Price.
1998.
AutomaticText-independent Pronunciation Scoring ofForeign Language Student Speech.
In Pro-ceedings of ICSLP.Silke Witt and Steve Young.
1997.
LanguageLearning Based on Non-Native Speech Recog-nition.
In Proceedings of Eurospeech, Rhodes.Nessa Wolfson.
1976.
Speech Events and Natu-ral Speech: Some Implications for Sociolin-guistic Methodology.
Language in Society,5:188 - 209.11
