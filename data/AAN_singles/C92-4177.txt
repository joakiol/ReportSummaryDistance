Degrees of Stativity: The Lexical Representation ofVerb AspectJudith L. Klavans and Martin ChodorowIBM T.J.Watson ResearchYorktown Heights, NYand~Hunter College of the City University of New YorkAbstractL'acqnisition automatique de connaissancelexicale h partir de larges corpus s'estessentiellement oceup& des phfinom~nesde co-occurrence, aux dfipens des traitslexicaux inh~rents.
Nous prfisentons iciune m&hodologie qui permet d'obtenirl'information sfimantique sur l'aspect duverbe en analysa~t automatiquement uncorpus et en appliquant des tests lin-guistiques h l'aide d'une stifle d'outilsd'anrdyse structura\]e. Lorsque ces deuxt~:hes sont accomplies, nous proposonsune rfipresentation de l'aspect du verbeqni associe une valeur de mesure pour lesdifffirents types d'fiv~nements.
Les mesureszefl~tent l'usage typique du verbe, et parconsfiquent une mesure de rfisistance oude non-r~sistance h la coercion dans leeontexte de la phrase.
Les rfisultats quenous rapportons ici ont fitfi obtenus dedeux mani~res: en extrayant l'informationn&essrSre h partir du corpus &iquetfi deFrancis and Ku~era (1982), et en fais~nttourner un analyseur syntaxlque (MeCord1980, 1990) sur le corpus du Reader's Di-gest afin d'extraire une information pluspr&ise sur l'usage du verbe dans le texte.Notre travail iUustre deux aspects:1.
Les ptopri6t6s lexicales inh6rentespeuvent fitre dfitermin&s en appli-qurmt aux textes une s&ie de testsllngnistiques bien &ablis.
Cela donnel'analyse de corpus une dimensionsuppl~mentaire qui va au-delh desph~nom~nes de coocurrence (eommepar example information mutuelle,substitutabilitfi).2.
Une propri~t~ lexieale n'a pas be-soin d'etre discrete mats peut &rerepr~sent~e en tant que valeur ~ in-terprdter comme une tendance ouprobabilitY; de cette mani~re, \]e oh-.jet lexieal exprime la propri~t~ donn~edarts un contexte non-marqu& Lesvaleurs der/v~es du corpus sont vari-ables, e'est-h-dire des valeurs h degr~s.Des tests linguistiques ont &~ automa-tiquement appliques aux corpus analys~sde mani~re k d&erminer la valeur initialede l'aspect pour la stativit~, et ce, pour unensenble de verbes frequents, repr~sentantplus de 90% des occurrences de verbes dansun corpus d'un million de roots.ACTES DE COLING-92, NArTr~.
23-28 AOl~r 1992 1 1 2 6 PROC.
OF COLING-92.
NANTES, AUG. 23-28, 1992Degrees of Stativity: The Lexical Representation f Verb AspectJudith L. Klavans and Martin Chodorow tIBM T.J.Watson ResearchYorktown Heights, NYamd~Hunter College of the City University of New YorkAbst ractThe automatic acquisition of lexiced knowledgefrom large corpora has dealt primarily withcoocurrence phenomena, t the expense of inher-ent lexic~l features.
We present here u method-ology for obtaining semantic information on verbaspect by parsing a corpus and automatically up-plying linguistic tests with a set of structural anal-ysis tools.
Once applied, we propose a represen-tation for verb aspect hat associates a value withweights for event types.
Weights reflect typicalverb use, and thus represent a measure of the resis-tance or ease of coercion in sentential context.
Theresults we report here have been obtained in twoways: by extracting relevant information from thetagged Brown corpus (Francis and Ka~era 1982),and by running ~ parser (McCord 1980, 1990) onthe Reader's Digest corpus to extract more accu-rate information on verb usage in text.1 Overv iewOur work illustrates two points:1.
Inherent lexical properties can be deterufinedby applying a battery of established hnguistictests to corpora~ This adds to the utility ofcorpus analysis a dimension beyond coocnr-fence phenomena (e.g.
mutual information,substitutability).2.
A \]exical property need not be discrete batcan be represented as a value to be inter-preted as a tendency or probability for thelexical item to exhibit the given property inan unmarked context.
Corpus-derived valuesare variable, i.e.
DEGREE ValU~Linguistic tests have been automatically appliedto parsed corpora to determine an initial aspectualvalue for stativity for u set of frequent verbs, cov-eting over 90% of verb occurrences in a one millionword corpus.2 Event  typesAspect can be informally defined as a propertywhich reflects the temporal organization of anevent, such as duration (whether an event involveschange over time), telicity (whether it has a defi-nite endpoint or is ongoing), iteratlvlty (whetheror not it is repetitive) and so on (see Comrie 1976.
)We assume three event types, following Vendler1967, refined by many others, and recently re-cast from the perspective of computational lexiconbuilding by Pastejovsky 1991, and Pustejovskyand Boguraev (to appear) 1:S ta te (S) :  knon, resemble, b~, l oveProcess(P) :  run,  walk, eviMTrans i t ion(T) :  g ive ,  open, bu i ld ,  dest royA verb can enter into u construction which maychange the overall phrasal or sentential eventstructure, as ttte result of event-coercion.
Coer-cion can be defined as the process by which verbsin context appear to demonstrate some regularambiguities, i.e.
they appear to change categories.Pustejovsky argues that u verb is inherently (lex-fealty) specified as being of a certain event type(e-type).Schema: e- type(Verb)  - SIPITe- type(reeenb le)  ~ Se- type( run)  ~ Pe-type(give)  - TFigure OneINolice that accomplishment verbs (e.g.
~palnt ?
pie-ture"), and Itchleveme, t veltbw ("reach a goM") are bothconsidered tr~neition verbi,AcrEs DE COLING-92.
NANIJ?S.
23-28 AO~I 1992 1 1 2 7 PnOC.
OF COLING-92, NAhrrgs, AUG. 23-28, 1992We call this the NON-DEGREE APPROACH, sincethere is no degree specified.
Our claim is that,rather than the representation in Figure One, theevent structure is a vector of values, e-type (Verb)= (S,P,T).
We deal here only with the statics/non-statics distinction, since there are regular differ-ences between states versus activities and accom-plishments (Lakoff 1965).
We propose a simplifiedrepresentation e-type(Verb)=Vo(x) with a singlevalue for stativity, Vs, the non-statics value beingmerely the complement, i.e.
1I, + V~s = 1.
Ourposition can be summarized as:Schema: e-type(Verb) ~ Vs(Z)where 0 < Vs(X)< 1 andnhore VH + V~s = 1 .Figure T~oWe call our position the DEGREE APPROACHsince a numeric value or DEGREE iS specifted.
Weagree with the notion of assuming basic verb types,with coercions, rostra the position proposed byDowry 1979 that there be different entries for dif-ferent usages.To allow the process interpretation i  sentenceslike:(i) The chi ld iv being a fool  today.
(2) She i~ resembling her mothezmore and more each day.the phrase "more (and more)" in (2), a temporalexpression, acts to "coerce" or force a non-stativeevent (in this case a process).
~ In fact, the verb"be", often touted as fundamentally the most sta-tics verb in the language is frequently coerced intoprocess and transition.3 Computational LexiconsThe work reported here is part of an ongoingproject in the bexical Systems Group at IBM Re-search to extract and represent lexical knowledgein CompLex, a computational lexicon which willbe able to provide information to natural languageprocessing systems.
The seeds of this project arepresented in Klavans 1988, where it is argued thatthe building of a computational lexicon requires~Our position might be viewed in terms of ~signingprobabilities tothe arc tranmltions in ~ system luck as thatproposed by Moths and Steedman 1988, in which coercions~re recursive but carefully constrained along several key pa-r~neters defining possible transitions within a finite-statetrtmsition etwork.mapping of resources into a common central lexi-cat datu base, rather than being dictionary bound.The view is further expanded in Byrd 1989.
Puste-jovsky and Boguraev (to appear) argue that a the~ory of lexlcal semantics making use of a knowl-edge representation framework offers an expressivevocabulary for the representation f such lexicalinformation.
They outline a concrete frameworkconsisting of four levels of lexlcal meaning: (1) Ar-gument Structure; (2) Event Structure; (3) QuailsStructure; and (d) Lexical Inheritance Structure.Pustejovsky 1991 provides formal details of theevent structure specification for verbs, with a for-real explanation of semantic type coercion.Specification of verb and phrasal aspect mat-ter to NLP systems in several ways.
For example,when a stative verb is used in the present ense,it involves only one occasion of the event.
In con-trust, a non-stative usage involves a frequentative,iterative, or repetitive interpretation.
Thus:John knous the answers.
( s ing le)John runs.
( repet i t i ve )Sue builds houses.
( repet i t i ve )It is necessary to understand the interpretation fstatlvity for several reasons.
In language genera-tion, adverbial adjuncts which have a durationalinterpretation are, under most circumstances, dis-allowed:*John knew the answers for  three days.John ran for  three hours.Sue bu i l t  houses for  three decades.For text analysis, if a verb which is usually stativeis used with a non-statlve adverb, such as "de-liberately", it can be inferred that the event isnon-stative, and not the reverse.
If the event isnon-statics, then it can be inferred that it couldbe a repetitive or iterative vent.
This can effectnot only the semantic interpretation of the text it-self, but also translation and the choice of adverb.33Many of these issues are discussed in the CL SpecialIssue on Tense and Aspect (June, 1988) in articles by Hin-niche, Moens and Steedman, Nakhimovsky, Passoneau, andWebber.
For example, Passoneau demonstrates how, with-out an ~ccurate specification f the ~pectual tendenciesof the verb coupled with the effect of temporal nd aspec-tual adjuncts, messages, which tend to be in the presenttense, ttre not correctly understood nor generated in thePUNDIT system.
For instance, "the pressure is low" mustbe interpreted at statlve, whereas "the pump operates"must be interpreted as a process.
In machine translation,for example, the verb parecerse meaning 'to resemble oneanother' is even leHs statics in Spanish than in English.Thus, sentence (2) above should be translated into SpanishACRES DE COLING-92, NAntES, 23-28 AO'dr 1992 1 1 2 8 PRec.
OF COLING-92, NANTES.
AUG. 23-28, 1992Aspect is complex.
Stativity is not u simplefeature such as an imate(+/ - ) .
To ob .
.
.
.
.
this,it suffices to look in any comprehensive grammar,for example, Quirk et al 1972, in wtfich lexiealverbs are divided into the classes "dynamic" and"stative", with the caveat hat "it would be moreaccurate to speak of 'dynamic' and "stative' usesof verbs" (p. 94-95).
Dowty 1979 observes that theissue of interpretation and aspect involves " thethorny problems of polysemy and honrophony"(p.62).
Since some verbs are "more statlve" thanothers, meaning that the most common unmarkeduse is as a marker of sentential or event stativity,the lexicon must embody this lexieal fact.
Ourproposal provides the capability in the lexicon ofrepresenting that variability, combined with auto-matic means of inducing variability values.4 ProcedureSome standard tests for the stative/nou-statlvedistinction are given in Dowty 1979, suchas the progressive, imperative, cmnplement offorce/persuade, intentionM adverbs, and pseudo-cleft, as in: 4Progress ive : non-s ta t ives* John is kneeing the anuuer.John in running.John in building s house.Complement of force/persuadu:* flail forced John to know the ansner.flail pursuadud Amy to run.John forced Bi l l  to bui ld a house,Adverbs, e-g- de l iberate ly ,  carufu l ly :* Gull do l iburatu ly  knou the anBeer.Evelyn ran care fu l ly .Sue care fu l ly  bu i l t  a house.Even though tests for stativity involve interactionsbetween semantic and syntactic facets of a sen-tence, we have chosen three tests for stativlty, themost robust being the tendency for a verb to occurin the progressive.
Unlike other tests, the progres-sive itself is a statement of duration and process.We hypothesized that degree of stativity, i.e.
avalue for stativity Vo, conld be inferred by deter-mining the ratio of total frequency of occurrenceof a verb in a progressive usage, past or present,in the simple present, not the progre,mive, a~i*t EngllJh.eada d~a .
l l a  se parsee I~s  a ?~ ~dre .For activity verbs, the progressive in EngliJh translates tothe progressive in SpalfiJh.4 Activltes and accompllshmentl aresubject to other dim-tinguilhing tests which are not the wubject of this paper.over its frequency as a verb in the same corpus:F(Verb(X)whore 0 < V, < 1A value closer to 0 indicates that a verb prefers ta-tivlty.
\]'his basic value can be modified by othertests, such the force/persuade test, and the delib-erately/carefully test.We are aware that this is an overMmplificatlonof the property of stativity.
Ilowever, our goal isto search for the most robust and pragmaticallypossible tests to start with.
Our technique hasgiven results which concur with our intuitions, al-though there are limitations discussed below, s Inorder to do this, we needed u text tagged for partof speech.
Otherwise, instances uch as "hear-ing aid", '% knowing look" would be taken as in-stances of progressive verbs.5 Resu l tsTagged Ku~era and Francis DataThe Brown corpus  provided a convenient s artingpoint, since words are tagged for part of speech.ltowever, a closer look at the tag set itself revealsa weakness which could bias our results.
Thetag VBG is used to tag "verb, present partici-ple, and gerund."
Thus, there is no distinctionin the label for the different usages of the "-ing"form, although some "-ing" forms are labelled NNfor noun or JJ for adjective.
Despite this prob-lem, we chose to use the Brown data, knowingthat the numbers aright be distorted.
We startedwith a list of the 100 most frequent words la-belled as verbs (i.e.
the 100 most frequent verbs,which account for over 90verbs which have beendiscussed in the literature on stativity (such as"resemble", "matter", "intend").
Figure Threelists some results, ordered by degree of stativity.e - type( t ry )= Vs(.3326)u-type(work)= V0(.3064)e - typu(n i t )= V,(.2929)u-type(run)= V, (.2853)e - typu(p lay) -  Vs(.2552)aPustejovsky, personM communication, hem pointed outsome problem cases where the progressive fMsely indicatesthat root is non-Jtative, such as lie/sit verbs (The book islying on the shelf, The c~p is sitting on the cownteO, andmental attitude verbs (John il thinking that he should 90home now, Sdohn is knowing that he should go home note,Marll is suspecting that John will propose tonight. )
Suchproblemt van be rewolved by fine-tuning testJ.
?We thank Slav~ Kate for pointin\[ us to this resource.ACTES DE COLING-92, NANTES, 23-28 AOt~V 1992 1 1 2 9 PROC.
OF COLING-92, NANTES, AUO.
23-28, 1992e-type(move)= Vs(.2326)e - type(go)= 11,(.2304)e - type( fo l low)= V,(.1234)e - type(g ive)= V,(.0783)e-type(become)= V,(.0718)e - type(hoar )= V,(,0669)e- type(~ee l )= V,(.0637)e-type(uppettr)= V,(.0481)e-type(know)= 1/',(.0332)e - type(vent )= V,(.0253)e- type(need)= Vw(.0197)e - type(be)= V,(.0173)e- type(eeem)= V,(.Ol20)Figure ThreeAs can be seen, the ranking roughly reflects in-tuitions about stativity, so, for example, seem ismore stative than hear ,  which is in turn more st~tire than run .Pars ing  w i th  Eng l i sh  S lo t  GrammarThe second more refined method utilizes a parserto analyze text, and to record verb usages.
For thispurpose, we used the English Slot Grammar (Me-Cord 1980, 19901 a broad-coverage parser writ-ten in PKOLOG.
7 To obtain counts of verb us-ages from the representations produced by ESG,we used a tool for querying trees (QT), built bythe second author, also in PROLOG.
The cor-pus is the Reader's Digest (RD) corpus, consist-ing of just over one million words.
We took thesame llst of the 115 most frequent and most fre-quently discussed verbs that was used for ob-taining values from the Brown corpus.
We ex-tracted all sentences under 30 words containingthe inflectional variants of these verbs from theRD corpus.
We then ran the parser on this sub-corpus, ran QT, and obtained values for the dif-ferent verb usages.
Unlike the Brown data, dis-tinctions are made between the gerundive andparticipial usages.
Figure Four gives results forsome verbs, listed in the same order as in FigureThree, with n indicating the number of tokens:e - type( t ry )= V,(.2167) (n = 286)e - type(york)= V,(.1311) (n ffi 244)e-type(s i t )= Vs(.1506) (n = 146)e-type(run)= V,(.1565) (n = 230)e- type(p lay)= V,(.2315) (n = 95)e-type(move)= V,(.0798) (n = 2131TAn exception to the quality it imperatives, **here therewere some errors in the parsing; they were removed fromour cMculationt.e - type(go)= 1I,(.2901) (n = 107t)e - type( fo i le r )= 1I,(.0375) (n = t33)e - type(g ive)= V,(.0209) (n = 430)e-type(become)= V,(.0507) (n = 493)e - type(hear )= V,(.OO00) (n = 242)o - type( fee l )= V,(.0317) (n = 315)e-type(uppenm)= V,(.0272) (n = 147)e- type(knov)= V,(.OOO0) (n = 630)e- type(want)= V,(.0000) (n = 466)o-type(need) = V,(.O000) (n = 258)e-type(be)= V,(.0124) (n = 12482)e-type(seem)= V,(.0000) (n = 260)Figure FourAdditional Syntactic TestsThe progressive test is only one of several tests,and in and of itself is certainly inadequate.
Sev-eral tests mast be run, and then event values mustbe computed for each linguistic test.
Two param-eters are involved: the strength of each test as anindicator of e-type, and the sparsity of data.We have preliminary results on two tutditionaltests: the force/persuade t st and the deliber-ately/carefully test.
Synonyms and taxonymswere collected for each (ad)verb, data were ex-tracted frmn the corpus and parsed.
For example,the following shows how a sentence with "force"was analyzed.
However, more datais  needed, froma larger corpus, for the results to be significant.The same applies for the adverb test.D i f f i cu l t iue  forced him to abandon .
.
.verb( fo rce)  inf_ camp_verb (abandon)Figure Five - Verb "Force"Results of running and computing the weights ofdifferent tests on larger corpora will be reportedin future publications.6 D iscuss ionAs expected, the results from each corpus dif-fer considerably; we believe this is due primarilyto surface tagging vs. full parsing.
The resultsfrom the second method using ESG do not carrythe noise from the ambiguous VBG tag from theBrown corpus.
However, there are two importantpoints to be made: (1) One million words is simplynot enough.
More data need to be (and will be)run to get a more complete and accurate count.These are to be viewed as preliminary data, us~able but not complete.
(2) The value V,(.0000)AcrEs DF.COLING-92, NANTES, 23-28 Aour 1992 l 1 3 0 PREC.
OV COL1NG-92, NANTES, AUG. 23-28, 1992cannot be considered categorical.
Verbs are gen-erally adaptable in context, s It is a known factthat value* either for words with low frequenciesor words in low frequency constructions must becomputed on very large corpora (Liberman 1989.
)The current limitations of this approach mustbe clearly stated.
First of all, this method con-rates the polysemons usages of certain verbs and,in English, of the verb-particle construction.
Itcould be argued that with enough corpus data,this would become unimportant, but we believethis position not correct.
What is required is afuller analysis of adjuncts in order to know if nverb has been coerced.
For example, it couldbe the case that a verb which is S in the an-marked case (i.e.
in a neutral context) tends toappear as a T verb frequently, since that verbmight not occur frequently in a null context atall.
As another example, consider the case of atypical stative verb "know".
With the object "an-swer", "know" becomes typically inchoative, e.g.
"know the answer by tomorrow" meaning "be-come knowledgeable of the answer", or it couldbe used in the transition sense, e.g.
"he will knowthe answer by tomorrow" meaning "he does notknow now and will know then."
Thus, it couldbe underlying semantic structure, and not sur-face syntactic behavior, that determines coercionpossibilities.
9 In conclusion, The DEGREE AP-PROACH captures the fact that verbs have degreesof e-type, i.e.
that some verbs are more pliablethan others.
Thus, rather than the non-degreevalues in Figure One, we argue for entries like:e -eype( reeeab lo )  = V,(.0740)e - typo(go)  = V#(.2304)e-type(seem)= V,(.012O)A corpus-breed method can be used to antomatl-cally derive values for e-type, i.e.
under n certaincut-off, the verb is stative, but alternbh in con-text.
More importantly, it gives a degree of likeli-hood that given any context, the verb will be usedstatively or non-statively.
*This is a tact which any semanticist who is trying toargue a firm point can at*el* to.tAho, there appear to be some clashes on the resultingvalues and intuitions, thus leading to the suggeJtion thateither our intuitions are not correct or that the method itunreliable.
We have not, in fact, addressed the issue ofunderlyin~ semantic representation (e.g.
in terms of prim.itivea) in this paper.
It has been suggested that syntactictests \[or aspect might be flawed, and that the only wayto distinguish aspectual c asses it via the semantic onse-quences ot a restive vs. non0tative proposition.
If correct,the approach of extracting values based on syntactic testswill fail by definition, regardless of whether the value, areassigned manually or automatically.7 References1.
Byrd, Roy.
1989.
"Discovering Relationshipsunsung Word Sense*", Dictionaries in the Elec-tronic Age: Proceedings of the Fifth Annual Con-Jerenec o\] the University of Waterloo Centre \]orthe New Oxford English Dictionary2.
Comrie, Bernard 1976.
Aspect.
CambridgeUniversity Press: Cambridge, English.3.
Dowry, David.
1979.
Word Meaning and Mon.
*ague Grammar.
Dordrecht: tlolland.4.
Francis, W. Nelson and Henry Ku6era.
1982.Frequency Analysis of Enlglish Usage: Lexiconand Grammar.
t longhton Mifflin: Boston.5.
Klavaas, Judith L. (1988) "Building a Corn-puts*loaM Lexicon using Machine Readable Dic-tionaries", Proceedings of the Third InternationalCongress of the European Association for Lexicog-raphy.
Budapest, Hungary.6.
Lakoff, George.
1965.
"On the Nature ofSyntactic Irregularity", PhD Dissertation, Depart-meat of Linguistics.
Indiana University: Bloom-ingtoa, Indiana.7.
Liberman, Mark.
1989.
"How Many Words DoPeople Know?"
Invited Talk delivered at the 27thAnnus.l Meeting of the Association for Compata~*tonal Linguistics.
Vancouver, B.C., Canada.8.
McCord, M. C. 1980.
"Slot Grammars" Com-putational Linguistlcs, Vol 6:31-43.9.
MeCord, M. C. 1990.
"SLOT GRAMMAR:A System for Simpler Construction of Practi-cal Natural Language Grammar*," in R.
Sender(Ed.
), International Symposium on Natural Lan-guage and Logic, Lecture Notes in Computer Sci-ence, Springer Verlag.10.
Moensp Marc and Marc Steedman.
1988"Temporal Ontology and Temporal Reference"Computational Linguistics.
Vol.
14:2:15-28.11.
Pustejovsky, James.
1991.
"The Syntax ofEvent Structure" Cognition Vol.
41:103:47-82.12.
Pustejovsky, James and Bran Bognrnev.
toappear.
"Lexical Knowledge l~.epreaentation a dNatural Language Processing" IBM Journal ofResearch and Development.13.
Quirk, Randolph, Sidney Greenbaum, Geof-frey Leech, Jan Svartvik.
1972.
A Comprehen-sive Grammar of the English Language, Longman:London.14.
Teany, Carol Lee.
1987.
"GrnmmatlcalizingAspect and Affectedness", PhD Dissertation, De~par*men* of Linguistics.
M.I.T., Cambridge: Mas-sachusetts.15.
Vendler, Zeno.
1967.
Linguistics iu Philoso.phy, Coruell University Press: Ithaca, New York.ACTES DE COLING-92, NAgrES, 23-28 ho~rr 1992 1 1 3 1 PROC.
oF COLING.92, NANTES.
AUG. 23-28, 1992
