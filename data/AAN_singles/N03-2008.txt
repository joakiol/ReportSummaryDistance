A Maximum Entropy Approach to FrameNet TaggingMichael Fleischman and Eduard HovyUSC Information Science Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{fleisch, hovy }@ISI.eduAbstractThe development of FrameNet, a largedatabase of semantically annotated sentences,has primed research into statistical methodsfor semantic tagging.
We advance previouswork by adopting a Maximum Entropyapproach and by using Viterbi search to findthe highest probability tag sequence for agiven sentence.
Further we examine the useof syntactic pattern based re-ranking to furtherincrease performance.
We analyze ourstrategy using both extracted and humangenerated syntactic features.
Experimentsindicate 85.7% accuracy using humanannotations on a held out test set.1 IntroductionThe ability to develop automatic methods for semanticclassification has been hampered by the lack of largesemantically annotated corpora.
Recent work in thedevelopment of FrameNet, a large database ofsemantically annotated sentences, has laid thefoundation for the use of statistical approaches toautomatic semantic classification.The FrameNet project seeks to annotate a largesubset of the British National Corpus with semanticinformation.
Annotations are based on FrameSemantics (Fillmore, 1976), in which frames are definedas schematic representations of situations involvingvarious Frame Elements such as participants, props, andother conceptual roles.In each FrameNet sentence, a single targetpredicate is identified and all of its relevant FrameElements are tagged with their element-type (e.g.,Agent, Judge), their syntactic Phrase Type (e.g., NP,PP), and their Grammatical Function (e.g., ExternalArgument, Object Argument).
Figure 1 shows anexample of an annotated sentence and its appropriatesemantic frame.To our knowledge, Gildea and Jurafsky (2000) isthe only work that uses FrameNet to build a statisticalsemantic classifier.
They split the problem into twodistinct sub-tasks: Frame Element identification andFrame Element classification.
In the identificationphase, they use syntactic information extracted from aparse tree to learn the boundaries of Frame Elements insentences.
The work presented here, focuses only onthe second phase: classification.Gildea and Jurafsky (2000) describe a system thatuses completely syntactic features to classify the FrameElements in a sentence.
They extract features from aparse tree and model the conditional probability of asemantic role given those features.
They report anaccuracy of 76.9% on a held out test set.She  clapped  her hands  in inspiration.Frame:        Body-MovementFrame Elements:Agent     Body Part Cause-NP             -NP   -PP-Ext.
-Obj.
-Comp.Figure 1.
Frame for lemma ?clap?
shown with three core FrameElements and a sentence annotated with element type, phrasetype, and grammatical function.We extend Gildea and Jurafsky (2000)?s initialeffort in three ways.
First, we adopt a MaximumEntropy (ME) framework to better learn the featureweights associated with the classification model.Second, we recast the classification task as a taggingproblem in which an n-gram model of Frame Elementsis applied to find the most probable tag sequence (asopposed to the most probable individual tags).
Finally,we implement a re-ranking system that takes advantageof the sentence-level syntactic patterns of eachsequence.
We analyze our results using syntacticfeatures extracted from a parse tree generated by Collinsparser (Collins, 1997) and compare those to modelsbuilt using features extracted from FrameNet?s humanannotations.2 Method2.12.2Training (32,251 sentences), development (3,491sentences), and held out test sets (3,398 sentences) weregenerated from the June 2002 FrameNet releasefollowing the divisions used in Gildea and Jurafsky(2000) 1 .
Because human-annotated syntacticinformation could only be obtained for a subset of theirdata, the training, development, and test sets used hereare approximately 10% smaller than those used inGildea and Jurafsky (2000).2  There are on average 2.2Frame Elements per sentence, falling into one of 126unique classes.Maximum EntropyME models implement the intuition that the best modelwill be the one that is consistent with all the evidence,but otherwise, is as uniform as possible.
(Berger et al,1996).
Following recent successes using it for manyNLP tasks (Och and Ney, 2002; Koeling, 2000), we useME to implement a Frame Element classifier.We use the YASMET ME package (Och,2002) to train an approximation of the model below:P(r| pt, voice, position, target, gf, h)Here r indicates the element type, pt the phrase type, gfthe grammatical function, h the head word, and targetthe target predicate.
Due to data sparsity issues, we donot calculate this model directly, but rather, modelvarious feature combinations as described in Gildea andJurafsky (2000).The classifier was trained, using only features thathad a frequency in training of one or more, and untilperformance on the development set ceased to improve.Feature weights were smoothed using a Bayesianmethod, such that weight limits are Gaussian distributedwith mean 0 and standard deviation 1.TaggingFrame Elements do not occur in isolation, but rather,depend very much on what other Elements occur in asentence.
For example, if a Frame Element is tagged asan Agent it is highly unlikely that the next Element willalso be an Agent.
We exploit this dependency bytreating the Frame Element classification task as atagging problem.The YASMET MEtagger was used to apply an n-gram tag model to the classification task (Bender et al,2003).
The feature set for the training data was2.33 Results1 Divisions given by Dan Gildea via personal communication.2  Gildea and Jurafsky (2000) use 36995 training, 4000development, and 3865 test sentences.
They do not reportresults using hand annotated syntactic information.augmented to include information about the tags of theprevious one and two Frame Elements in the sentence:P(r| pt, voice, position, target, gf, h, r -1,r -1+r -2)Viterbi search was then used to find the most probabletag sequence through all possible sequences.Pattern FeaturesA great deal of information useful for classification canbe found in the syntactic patterns associated with eachsequence of Frame Elements.
A typical syntacticpattern is exhibited by the sentence ?Alexandra bent herhead.?
Here ?Alexandra?
is an external argument NounPhrase, ?bent?
is the target, and ?her head?
is an objectargument Noun Phrase.
In the training data, a syntacticpattern of NP-ext, target, NP-obj, given the predicatebend, was associated 100% of the time with the FrameElement pattern: ?Agent target BodyPart?, thus,providing powerful evidence as to the classification ofthose Frame Elements.We exploit these sentence-level patterns byimplementing a re-ranking system that chooses amongthe n-best tagger outputs.
The re-ranker was trained ona development corpus, which was first tagged using theMEtagger described above.
For each sentence in thedevelopment corpus, the 10 best tag sequences areoutput by the classifier and described by threeprobabilities: 3  1) the sequence?s probability given bythe ME classifier (ME); 2) the conditional probability ofthat sequence given the syntactic pattern and the targetpredicate (pat+target); 3) a back off conditionalprobability of the tag sequence given just the syntacticpattern (pat).
A ME model is then used to combine thelog of these probabilities to give a model of the form:P(tag-seq| ME, pat+target, pat)Figure 2 shows the performance of the base ME model,the base model within a tagging framework, and thebase model within a tagging framework plus the re-ranker.
Results are shown for data sets trained andtested using human annotated syntactic features andtrained and tested using automatically extractedsyntactic features.
In both cases the training and testsets are identical.For both the extracted and human conditions,adopting a tagging framework improves results by over1%.
However, while the syntactic pattern based re-ranker increases performance using human annotationsby nearly 2%, the effect when using automaticallyextracted information is only 0.5%.
This is reasonable3  Using n-best lists of 50 and 100 showed no significantdifference in performance.considering that the re-ranker?s effectiveness iscorrelated with the level of noise in the syntacticpatterns upon which it is based.The difference in performance between the modelsunder both human and extracted conditions wasrelatively consistent: averaging 8.7% with a standarddeviation of 0.7.As a further analysis, we have examined theperformance of our base ME model on the same test setas that used in Gildea and Jurafsky (2000).
Using onlyextracted information, we achieve an accuracy of74.9%, two percent lower than their reported results.This result is not unreasonable, however, because, dueto limited time, very little effort was spent tuning theparameters of the model.Figure 2.
Performance of models on held out test data.
ME refersto results of the base Maximum Entropy model, Tagger to acombined ME and Viterbi search model, Re-Rank to the Taggeraugmented with a re-ranker.
Extracted refers to models trainedusing features extracted from parse trees, Human to models usingfeatures from FrameNet?s human annotations.4 ConclusionIt is clear that using a tagging framework and syntacticpatterns improves performance of the semantic classifierwhen features are extracted from either automaticallygenerated parse trees or human annotations.
The moststriking result of these experiments, however, is thedramatic decrease in performance associated with usingfeatures extracted from a parse tree.This decrease in performance can be traced to atleast two aspects of the automatic extraction process:noisy parser output and limited grammaticalinformation.To compensate for noisy parser output, our currentwork is focusing on two strategies.
First, we arelooking at using shallower but more reliable methodsfor syntactic feature generation, such as part of speechtagging and text chunking, to either replace or augmentthe syntactic parser.
Second, we are using ontologicalinformation, such as word classes and synonyms, in thehopes that semantic information may supplement thenoisy syntactic information.The models trained on features extracted from parsetrees do not have access to rich grammaticalinformation.
Following Gildea and Jurafsky (2000),automatic extraction of grammatical information here islimited to the governing category of a Noun Phrase.The FrameNet annotations, however, are much richerand include information about complements, modifiers,etc.
We are looking at ways to include such informationeither by using alternative parsers (Hermjakob, 1997) oras a post processing task (Blaheta and Charniak, 2000).In future work, we will extend the strategiesoutlined here to incorporate Frame Elementidentification into our model.
By treating semanticclassification as a single tagging problem, we hope tocreate a unified, practical, and high performance systemfor Frame Element tagging.76.375.87485.783.882.66870727476788082848688ME Tagger Re-Rank%CorrectExtracted HumanAcknowledgmentsThe authors would like to thank Dan Gildea whogenerously allowed us access to his data files and OliverBender for making the MEtagger software publiclyavailable.
Finally, we thank Franz Och whose help andexpertise were invaluable.ReferencesO.
Bender, K. Macherey, F. J. Och, and H. Ney.
2003.Comparison of Alignment Templates and MaximumEntropy Models for Natural Language Processing.
EACL-2003.
Budapest, Hungary.A.
Berger, S. Della Pietra and V. Della Pietra, 1996.
AMaximum Entropy Approach to Natural LanguageProcessing.
Computational Linguistics, vol.
22, no.
1.D.
Blaheta and E. Charniak.
2000.
Assigning Function Tags toParsed Text, In Proc.
of the 1st NAACL, Seattle, WA.M.
Collins.
1997.
Three generative, lexicalized models forstatistical parsing.
In Proc.
of the 35th Annual Meeting ofthe ACL.C.
Fillmore 1976.
Frame semantics and the nature oflanguage.
In Annals of the New York Academy of Sciences:Conference on the Origin and Development of Languageand Speech, Volume 280 (pp.
20-32).D.
Gildea and D. Jurafsky.
2000.
Automatic Labeling ofSemantic Roles, ACL-2000, Hong Kong.U.
Hermjakob, 1997.
Learning Parse and TranslationDecisions from Examples with Rich Context.
Ph.D.Dissertation, University of Texas at Austin, Austin, TX.R.
Koeling.
2000.
Chunking with maximum entropy models.CoNLL-2000.
Lisbon, Portugal.F.J.
Och, H. Ney.
2002.
Discriminative Training andMaximum Entropy Models for Statistical MachineTranslation.
ACL-2002.
Philadelphia, PA.F.J.
Och.
2002.
Yet another maxent toolkit: YASMET.
www-i6.informatik.rwth-aachen.de/Colleagues/och/.
