Proceedings of NAACL HLT 2009: Short Papers, pages 73?76,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMinimum Bayes Risk Combination of Translation Hypotheses fromAlternative Morphological DecompositionsAdria` de Gispert?
Sami Virpioja??
University of Cambridge.
Dept.
of Engineering.
CB2 1PZ Cambridge, U.K.{ad465,wjb31}@eng.cam.ac.uk?
Helsinki University of Technology.
Adaptive Informatics Research CentreP.O.Box 5400, 02015 TKK, Finland{sami.virpioja,mikko.kurimo}@tkk.fiMikko Kurimo?
William Byrne?AbstractWe describe a simple strategy to achieve trans-lation performance improvements by combin-ing output from identical statistical machinetranslation systems trained on alternative mor-phological decompositions of the source lan-guage.
Combination is done by means of Min-imum Bayes Risk decoding over a shared N-best list.
When translating into English fromtwo highly inflected languages such as Ara-bic and Finnish we obtain significant improve-ments over simply selecting the best morpho-logical decomposition.1 IntroductionMorphologically rich languages pose significantchallenges for natural language processing.
The ex-tensive use of inflection, derivation, and composi-tion leads to a huge vocabulary, and sparsity in mod-els estimated from data.
Statistical machine transla-tion (SMT) systems estimated from parallel text areaffected by this.
This is particularly acute when ei-ther the source or the target language, or both, aremorphologically complex.Owing to these difficulties and to the natural in-terest researchers take in complex linguistic phe-nomena, many approaches to morphological anal-ysis have been developed and evaluated.
We fo-cus on applications to SMT in Section 1.1, but wenote the recent general survey (Roark and Sproat,2007) and the Morpho Challenge competitive evalu-ations1.
Prior evaluations of morphological analyz-ers have focused on determining which analyzer was1See http://www.cis.hut.fi/morphochallenge2009/ and linksbest suited for some particular task.
For translation,we take a different approach and investigate whethercompeting analyzers might have complementary in-formation.
Our method is straightforward.
We traintwo identical SMT systems with two versions ofthe same parallel corpus, each with a different mor-phological decomposition of the source language.We combine their translation hypotheses perform-ing Minimum Bayes Risk decoding over merged N-best lists.
Results are reported in the NIST 2008Arabic-to-English MT task and an European Parlia-ment Finnish-to-English task, with significant gainsover each individual system.1.1 Prior WorkSeveral earlier works investigate word segmenta-tion and transformation schemes, which may includePart-Of-Speech or other information, to alleviatethe effect of morphological variation on translationmodels.
With different training corpus sizes, theyfocus on translation into English from Arabic (Lee,2004; Habash and Sadat, 2006; Zollmann et al,2006), Czech (Goldwater and McClosky, 2005; Tal-bot and Osborne, 2006), German (Nie?en and Ney,2004) or Catalan, Spanish and Serbian (Popovicand Ney, 2004).
Some address the generationchallenge when translating from English into Span-ish (Ueffing and Ney, 2003; de Gispert and Marin?o,2008).
Unsupervised morphology learning is pro-posed as a language-independent solution to reducethe problems of rich morphology in (Virpioja et al,there to earlier workshops.
The combination scheme describedin this paper will be one of the evaluation tracks in the upcomingworkshop.73Arabic wqrrt An tn$A ljnp tHDyryp jAmEp lljmEyp AlEAmp fY dwrthA AlvAnyp wAlxmsynMADA D2 w+ qrrt >n tn$A ljnp tHDyryp jAmEp l+ AljmEyp AlEAmp fy dwrthA AlvAnyp w+ AlxmsynSAKHR w+ qrrt An tn$A ljnp tHDyryp jAmEp l*l+ jmEyp Al+ EAmp fY dwrt +hA Al+ vAnyp w*Al+ xmsynEnglish a preparatory committee of the whole of the general assembly is to be established at its fifty-second sessionTable 1: Example of alternative segmentation schemes for a given Arabic sentence, in Buckwalter transliteration.2007).
Factored models are introduced in (Koehnand Hoang, 2007) for better integration of morpho-syntactic information.Gime?nez and Ma`rquez (2005) merge mul-tiple word alignments obtained from severallinguistically-tagged versions of a Spanish-Englishcorpus, but only standard tokens are used in decod-ing.
Dyer et al (2008) report improvements frommultiple Arabic segmentations in translation to En-glish translation, but their goal was to demonstratethe value of lattice-based translation.
From a model-ing perspective their approach is unwieldy: multipleanalyses of the parallel text collections are mergedto create a large, heterogeneous training set; a sin-gle set of models and alignments is produced; latticetranslation is then performed using a single systemto translate all morphological analyses.
We find thatsimilar gains can be obtained much more easily.The approach we take is Minimum Bayes Risk(MBR) System Combination (Sim et al, 2007).
N-best lists from multiple SMT systems are merged;the posterior distributions over the individual listsare interpolated to form a new distribution over themerged list.
MBR hypotheses selection is then per-formed using sentence-level BLEU score (Kumarand Byrne, 2004).
It is very likely that even greatergains can be achieved by more complicated combi-nation schemes (Rosti et al, 2007), although signif-icantly more effort in tuning would be required.2 Arabic-to-English TranslationFor Arabic-to-English translation, we consider twoalternative segmentations of the Arabic words.
Wefirst use the MADA toolkit (Habash and Rambow,2005).
After tagging, we split word prefixes and suf-fixes according to scheme ?D2?
(Habash and Sadat,2006).
Secondly, we take the segmentation gener-ated by Sakhr Software in Egypt using their ArabicMorphological Tagger, as an alternative segmenta-tion into subword units.
This scheme generates moretokens as it segments all Arabic articles which other-wise remain attached in the MADA D2 scheme (Ta-ble 1).Translation experiments are based on the NISTMT08 Arabic-to-English translation task, includ-ing all allowed parallel data as training material(?150M English words, and 153M or 178M Arabicwords for MADA-segmented and Sakhr-segmentedtext, respectively).
In addition to the MT08 set itself,we take the NIST MT02 through MT05 evaluationsets and divide them into a development set (odd-numbered sentences) and a test set (even-numberedsentences), each containing ?2k sentences.The SMT system used is HiFST, a hierarchicalphrase-based system implemented with WeightedFinite-State Transducers (Iglesias et al, 2009).
Twoidentical systems are trained from each parallel cor-pus, i.e.
MADA-based and SAKHR-based.
Bothsystems use the same standard features and sharethe first-pass English language model, a 4-gram es-timated over the parallel text and a 965 million wordsubset of monolingual data from the English Giga-word Third Edition.
Minimum Error Training pa-rameter estimation under IBM BLEU is performedon the development set (mt02-05-tune), and the out-put translation lattice is rescored with large languagemodels estimated using ?4.7B words of Englishnewswire text, in the same fashion as (Iglesias etal., 2009).
Finally, the first 1000-best hypothesesare rescored with MBR, taking the negative sentencelevel BLEU score as the loss function to minimise.For system combination, we obtain two sets of N-best lists of depth N=500, one from each system.Both lists are obtained after large-LM lattice rescor-ing, i.e.
prior to individual MBR.
A joint MBR de-coding is then carried out on the aggregated 1000-best list with equal weight assigned to the posteriordistribution assigned to the hypotheses by each sys-tem.
Results are shown in Table 2.As shown, the scores obtained via MBR combi-nation outperform significantly those achieved viaMBR for the best-performing system (MADA).
The74mt02-05--tune -test mt08MADA-based 53.3 52.7 43.7+MBR 53.7 53.3 44.0SAKHR-based 52.7 52.8 43.3+MBR 53.2 53.2 43.8MBR-combined 54.6 54.6 45.6Table 2: Arabic-to-English translation results.
Lower-cased IBM BLEU reported.mixed case BLEU-4 for the MBR-combined systemon mt08 is 44.1.
This is directly comparable to theofficial MT08 Constrained Training Track evalua-tion results.23 Finnish-to-English TranslationFinnish is a highly-inflecting, agglutinative lan-guage.
It has dozens of both inflectional andderivational suffixes, that are concatenated togetherwith only moderately small changes in the sur-face forms.
For instance, one can inflect theword ?kauppa?
(shop) into ?kaupa+ssa+mme+kin?
(also in our shop) by glueing the suffixes to theend.
In addition, Finnish has many compoundwords, sometimes consisting of several parts, suchas ?ulko+maa+n+kauppa+politiikka?
(foreign tradepolicy).
Due to these properties, the number of dif-ferent word forms that can be observed is enormous.Morfessor (Creutz and Lagus, 2007) is a methodfor modeling concatenative morphology in an un-supervised manner.
It tries to find morpheme-likeunits, morphs, that are segments of the words.
In-spired by the minimum description length principle,Morfessor tries to find a concise lexicon of morphsthat can effectively code the words in the train-ing data.
Unlike other unsupervised methods (e.g.,Goldsmith (2001)), there is no restrictions on howmany morphs a word can have.
After training themodel, the most likely segmentation of new wordsto morphs can be found using the Viterbi algorithm.There exist a few different versions of Morfessor.The baseline algorithm has been found to be veryuseful in automatic speech recognition of agglutina-tive languages (Kurimo et al, 2006).
However, it2Full MT08 results are available at http://www.nist.gov/speech/tests/mt/2008/doc/mt08 official results v0.htmloften oversegments morphemes that are rare or notseen at all in the training data.
Following the ap-proach in (Virpioja et al, 2007), we use the Morfes-sor Categories-MAP algorithm (Creutz and Lagus,2005).
It applies a hierarchical model with three sur-face categories (prefix, stem and suffix), that allowthe algorithm to treat out-of-vocabulary words in aconvenient manner.
For instance, if we encounter anew name with a known suffix, it can usually sepa-rate the suffix and leave the actual name intact.Similarly to the Arabic-to-English task, we traintwo identical HiFST systems.
In this case, whereasone is trained on Finnish morphs decomposed byMorfessor (morph-based), the other is trained onstandard, unprocessed Finnish (word-based).
Forthis task we use the EuParl parallel corpus .
Portionsfrom Q4/2000 was reserved for testing and Septem-ber 2000 for development, both containing around3,000 sentences.
The training data comprised 23MEnglish words, and 17M or 27M Finnish tokens forword-based or morph-based text, respectively.The training set was also used to train the mor-phological segmentation.
The quality of the seg-mentation is evaluated in (Virpioja et al, 2007).
Aprecision of 78.72% and recall of 52.29% was mea-sured for the segmentation boundaries with respectto a linguistic reference segmentation.
As the recallis not very high, the segmentation is more conserva-tive than the linguistic reference.
Table 4 shows anexample for a phrase in the training data.Results are shown in Table 3, where again signifi-cant gains are achieved when simply combining out-put N-best lists via MBR.
Only one reference wasavailable for scoring.
In this case we did not ap-ply large-LM rescoring, as no large additional par-liamentary data was available.
Individual MBR didnot yield gains for each of the systems.devel testWord-based 30.2 27.9Morph-based 29.4 27.4MBR-combined 30.5 28.9Table 3: Finnish-to-English translation results.
Lower-cased IBM BLEU reported.75Finnish vaarallisten aineiden kuljetusten turvallisuusneuvonantajaMorfessor vaaraSTM llistenSTM aineSTM idenSUF kuljetusPRE tenSTM turvallisuusPRE neuvoSTM nSUF antajaSTMLinguistic vaara llis t en aine i den kuljet us t en turva llis uus neuvo n anta jaEnglish safety adviser for the transport of dangerous goodsTable 4: Example of Morfessor Categories-MAP segmentation and linguistic segmentation for a Finnish phrase.
Sub-scripts show the morph categories given by Morfessor: stem (STM), prefix (PRE) and suffix (SUF).4 ConclusionsWe demonstrated that multiple morphological anal-yses can be the basis for SMT system combination.These results will be of interest to researchers devel-oping morphological analyzers, as it provides a new,and potentially profitable way to evaluate compet-ing analysers.
The results should also interest SMTresearchers.
SMT system combination is an activearea of research, but good gains from combinationusually require very different system architectures;this can be a barrier to developing competitive sys-tems.
We find that the same architecture trained ontwo different analyses is adequate to generate the di-verse hypotheses needed for system combination.Acknowledgments.
This work was supported by the GALEprogram of DARPA (HR0011-06-C-0022), the GSLT and AIRCin the Academy of Finland, and the EMIME project and PAS-CAL2 NoE in the EC?s FP7.ReferencesM.
Creutz and K. Lagus.
2005.
Inducing the morpho-logical lexicon of a natural language from unannotatedtext.
In Conf.
on Adaptive Knowledge Representationand Reasoning (AKRR).M.
Creutz and K. Lagus.
2007.
Unsupervised modelsfor morpheme segmentation and morphology learning.ACM Trans.
Speech and Language Processing, 4(1).A.
de Gispert and J.B. Marin?o.
2008.
On the impactof morphology in English to Spanish statistical MT.Speech Communication, 50.C.
Dyer, S. Muresan, and P. Resnik.
2008.
Generalizingword lattice translation.
In ACL-HLT.J.
Gime?nez and Ll.
Ma`rquez.
2005.
Combining linguis-tic data views for phrase-based SMT.
In ACL Work-shop on Building and Using Parallel Texts.J.
Goldsmith.
2001.
Unsupervised learning of the mor-phology of a natural language.
Computational Lin-guistics, 27(2).S.
Goldwater and D. McClosky.
2005.
Improving sta-tistical MT through morphological analysis.
In HLT-EMNLP.N.
Habash and O. Rambow.
2005.
Arabic tokeniza-tion, part-of-speech tagging and morphological disam-biguation in one fell swoop.
In ACL.N.
Habash and F. Sadat.
2006.
Arabic preprocessingschemes for statistical machine translation.
In HLT-NAACL: Short Papers.G.
Iglesias, A. de Gispert, E.R.
Banga, and W. Byrne.2009.
Hierarchical phrase-based translation withweighted finite state transducers.
In HLT-NAACL.P.
Koehn and H. Hoang.
2007.
Factored translation mod-els.
In EMNLP.S.
Kumar and W. Byrne.
2004.
Minimum Bayes-riskdecoding for statistical machine translation.
In HLT-NAACL.M.
Kurimo, A. Puurula, E. Arisoy, V. Siivola, T. Hir-sima?ki, J. Pylkko?nen, T. Aluma?e, and M. Saraclar.2006.
Unlimited vocabulary speech recognition foragglutinative languages.
In HLT-NAACL.Y.-S. Lee.
2004.
Morphological analysis for statisticalmachine translation.
In HLT-NAACL: Short Papers.S.
Nie?en and H. Ney.
2004.
Statistical machine transla-tion with scarce resources using morpho-syntactic in-formation.
Computational Linguistics, 30(2).M.
Popovic and H. Ney.
2004.
Towards the use of wordstems and suffixes for statistical machine translation.In LREC.B.
Roark and R. Sproat.
2007.
Computational Ap-proaches to Morphology and Syntax.
Oxford Univer-sity Press.A.V.
Rosti, S. Matsoukas, and R. Schwartz.
2007.
Im-proved word-level system combination for machinetranslation.
In ACL.K.C.
Sim, W. Byrne, M. Gales, H. Sahbi, and P. C. Wood-land.
2007.
Consensus network decoding for sta-tistical machine translation system combination.
InICASSP, volume 4.D.
Talbot and M. Osborne.
2006.
Modelling lexical re-dundancy for machine translation.
In ACL.N.
Ueffing and H. Ney.
2003.
Using POS information forSMT into morphologically rich languages.
In EACL.S.
Virpioja, J.J. Va?yrynen, M. Creutz, and M. Sadeniemi.2007.
Morphology-aware statistical machine transla-tion based on morphs induced in an unsupervised man-ner.
In MT Summit XI.A.
Zollmann, A. Venugopal, and S. Vogel.
2006.
Bridg-ing the inflection morphology gap for Arabic statisticalmachine translation.
In HLT-NAACL: Short Papers.76
