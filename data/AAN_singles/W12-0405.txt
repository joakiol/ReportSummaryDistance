Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 31?38,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsBuilding a Data Collection for Deception ResearchEileen Fitzpatrick Joan BachenkoMontclair State University Linguistech Consortium, Inc.Montclair, NJ 07043 Oxford, NJ 07863fitzpatricke@mail.montclair.edu jbachenko@linguistech.comAbstractResearch in high stakes deception has beenheld back by the sparsity of ground truthverification for data collected from real worldsources.
We describe a set of guidelines foracquiring and developing corpora that willenable researchers to build and test models ofdeceptive narrative while avoiding theproblem of sanctioned lying that is typicallyrequired in a controlled experiment.
Ourproposals are drawn from our experience inobtaining data from court cases and othertestimony, and uncovering the backgroundinformation that enabled us to annotateclaims made in the narratives as true or false.1 IntroductionThe ability to spot deception is an issue in manyimportant venues: in police, security, bordercrossing, customs, and asylum interviews; incongressional hearings; in financial reporting; inlegal depositions; in human resource evaluation;and in predatory communications, includingInternet scams, identity theft, and fraud.
Theneed for rapid, reliable deception detection inthese high stakes venues calls for thedevelopment of computational applications thatcan distinguish true from false claims.Our ability to test such applications is,however, hampered by a basic issue: the groundtruth problem.
To be able to recognize the lie, theresearcher must not only identify distinctivebehavior when someone is lying but mustascertain whether the statement being made istrue or not.The prevailing method for handling theground truth problem is the controlledexperiment, where truth and lies can bemanaged.
While controlled laboratoryexperiments have yielded important insights intodeceptive behavior, ethical and proprietary issueshave put limits on the extent to which controlledexperiments can model deception in the "realworld".
High stakes deception cannot besimulated in the laboratory without serious ethicsviolations.
Hence the motivation to lie is weaksince subjects have no personal loss or gain atstake.
Motivation is further compromised whenthe lies are sanctioned by the experimenter whodirects and condones the lying behavior (Stiff etal., 1994).
With respect to the studiesthemselves, replication of laboratory deceptionresearch is rarely done due to differences in datasets and subjects used by different researchgroups.
The result, as Vrij (2008) points out, is alack of generalizability across studies.We believe that many of the issues holdingback deception research could be resolvedthrough the construction of standardized corporathat would provide a base for expandingdeception studies, comparing differentapproaches and testing new methods.
As a firststep towards standardization, we offer a set ofpractical guidelines for building corpora that arecustomized for studies of high stakes deception.The guidelines are based on our experiences increating a corpus of real world language data thatwe used for testing the deception detectionapproach described in Bachenko et al (2008),Fitzpatrick and Bachenko (2010).
We hope thatour experience will encourage other researchersto build and contribute corpora with the goal ofestablishing a shared resource that passes the testof ecological validity.Section 2 of the paper describes the datacollection initiative we are engaged in, section 3describes the methods used to corroborate theclaims in the data, section 4 concludes ouraccount and covers lessons learned.We should point out that the ethicalconsiderations that govern our data collection aresubject to the United States Code of Federal31Regulations (CFRs) for the protection of humansubjects and may differ in some respects fromthose in other countries.2 Collecting High-Stakes DataWe are building a corpus of spoken and writtennarrative data used in real world high stakescases in which many of the claims in the corpushave been corroborated as True or False.
Wehave corroborated claims in almost 35,090 wordsof narrative.
These narratives include statementsto police, a legal deposition, and congressionaltestimony.In assembling and managing our corpus, twoissues have been paramount: the availability ofdata and constraints on its use.
Several types ofinformation must be publicly available, includingthe primary linguistic data, backgroundinformation used to determine ground truth, andgeneral information about the case or situationfrom which the data is taken.
In addition, thedata must be narrative intensive.
There are alsoseveral considerations about the data that mustbe taken into account, including the mode(written or spoken) of the narrative, andconsiderations involving the needs of the users ofthe data.To ensure unconstrained access, datacollection must be exempt from humanparticipant restrictions.
The restrictions we mustadhere to are the regulations of Title 46 of theCFRs.1 46 CFR 102 lists the data that is exemptfrom human participant restrictions.
Exempt dataincludes ?
[r]esearch involving the collection orstudy of existing data, documents, records,pathological specimens, or diagnostic specimens,if these sources are publicly available or if theinformation is recorded by the investigator insuch a manner that subjects cannot be identified,directly or through identifiers linked to thesubjects.
?46 CFR 111, section 7 covers protection ofprivacy: ?When appropriate, there are adequateprovisions to protect the privacy of subjects andto maintain the confidentiality of data.
?It is conceivable that a ?real world?
highstakes study could involve subjects whoseidentifiable data would be removed from thecollection, but it is highly unlikely that the1 These regulations are enforced either by the InstitutionalReview Board (IRB) of the institution where the researchtakes place or by an independent IRB contracted by theresearchers if there is no housing institution.subjects would consent to having their data ?even if sanitized ?
made available on theInternet.
We have therefore used only exemptdata, i.e., data that is publicly available with noexpectation of privacy on the part of the peopleinvolved.2.1 Public availability of dataThere is a large body of narrative data in thepublic domain, data that is also likely to have arich source of ground truth evidence and generalbackground information.
Typical public sourcesfor this data would be crime investigationwebsites, published police interviews, legalwebsites, including findlaw.com and justice.gov,quarterly earnings conference calls, and the U.S.Congressional Record.
Such data includespublicly available?
Face-to-face interviews?
Depositions?
Court and other public testimony?
Phone conversations2?
Recorded statements to police?
Written statements to police?
Debates of political figures and candidatesfor public office?
Online product endorsements?
Blogs?
WebpagesHigh profile cases are particularly wellrepresented on websites.
In the U.S., policereports, which are a matter of public record, mayalso be obtained for a small fee from local policedepartments.
Other data aggregators, likeFactSet.com, provide data for higher fees.2.2 Types of Data2.2.1 Primary linguistic dataThe narrative data is the data to be analyzed forcues to deception.
Written data is, of course,available as text, but spoken data may also onlybe available as transcripts.
Our current datasetincludes recorded data only from the Enrontestimony, but ideally speech data would includehigh quality recorded speech to enable analysisof the prosodic qualities of the speech.To support robust analysis, it is important thatthe data be narrative intense.
The ?yes?/?no?2 For example, the quarterly earnings conference callsanalyzed in Larcker and Zakolyukina (2010).32responses of a polygraph interview are not usablefor language analysis.Additionally, we have so far limited ourcollection to spontaneously produced data.Prepared, rehearsed narrative provides theopportunity to carefully craft the narrativeputting the narrator in control not only of thestory but of the language used to convey thestory.
This enables the speaker/writer to avoidthe cues that we are looking for.
We would beopen to adding prepared data to the collection,but have not considered the guidelines for it.2.2.2 Background dataBackground information on the primary data isthe basis for the ground truth annotation of theclaims made in the primary data.
Ground truthinvestigation can use various types ofinformation, including that coming frominterviews, police reports, public records postedon local and national government web sites, factchecking sites like FactCheck.org 3 andPolitiFact.com4 that analyze political claims andprovide sources for the information they use intheir own judgments, and websites such astruTV.com that offer the facts of a case, the finalcourt judgment, and interviews with the peopleinvolved in the case.Many of these sources are available on theweb ?
an advantage of using data where there isno expectation of privacy.5 Some data requiresfiling for a police report or a court document.The sources for our current data set are given inAppendix A.Another source of verification can be thenarrative itself in situations where the narratorcontradicts a prior claim.
For example, onenarrator, after denying a theft for most of theinterview, says ?All right, man, I did it,?enabling us to mark his previous denials as False.2.2.3 General information about thecase/situationIdeally, the corpus will include backgroundinformation on the situation covered by thenarrative.
If the situation is a legal case, thebackground information should include theverdict of the judge or jury, the judgment of3 FactCheck is a project of the Annenberg Public PolicyCenter of the University of Pennsylvania.4 PolitiFact is sponsored by the Tampa Bay Times.5 Information may be withdrawn from the web, however, ifthere are changes in a case, such as the filing of an appeal orsimply fading interest in the case.conviction given by the judge, and the sentence.If the case is on appeal, then that should benoted.Information on the amount of control thenarrator has over the story is also valuable.
Is thenarrative elicited or freely given?
The formergives the narrator less control over the narrative,possibly increasing the odds for the appearanceof cues to deception.
Is the narrator offering amonologue or a written statement, both of whichgive the author more control of the narrative thanan interview.2.2.4 Speaker informationGeneral information on the speaker can bevaluable in gauging the performance of adeception model, including information ongender, age, and education.
We foundinformation on first language background andculture to be useful in analyzing the speech ofnon-native speakers of English, whose secondlanguage speech characteristics sometimes alignwith deception cues.
Other sociolinguistic traitsmay also be important, although we have foundthat, while sociolinguistic background maydetermine word choice, the deceptive behavior isinvariant.
We have not encountered issues ofcompetency to stand trial in the criminal caseswe have included, but such evaluations should benoted if the issue arises in a legal case.2.2.5 Spoken and written dataTwo of the narratives in our current collectionare written; the others are spoken.
Both writtenstatements were produced as parts of a policeinterview.
The purpose of requesting thestatement is to obtain an account in theinterviewee's own words and to do this beforetime and questioning affect the interviewee'sthinking.
Hence the written statement isanalogous to a lengthy interview answer, and thelanguage used is much closer to speech thanwriting, as the opening of the Routier statementillustrates:Darin and my sister Dana came home fromworking at the shop.
The boys were playing withthe neighborhood kids outside.
I was finishingup dinner.2.3 Other considerationsIn providing data for general use by researchers,the collector must be aware of varying needs ofresearchers using the data.
The general needs we33consider are the ground truth yield and thequestion of the scope of the True/False label.2.3.1 Ground truth yieldThe amount of background data that can begathered to yield ground truth judgments canvary widely depending on the type of narrativedata collected.
We have worked with privatecriminal data where the ratio of verifiedpropositions to words in the primary data is ashigh as .049 and with private job interview datawhere the ratio is as low as .00043.
The lowyield may be problematic for some types ofexperiment, as well as frustrating for the datacollector.
It is important to have some assurancethat there are a reasonable number of resourcesthat can provide ground truth data beforecollecting the narrative data, particularly if thenarrative data is difficult to collect.2.3.2 The Scope of the T/F labelWith the exception of Fornaciari and Poesio(2011), Hirschberg et al (2005), Bachenko et al(2008) and Fitzpatrick and Bachenko (2010), theML/NLP deception literature distinguishes Truefrom False at the level of the narrative, not theproposition.
In other words, most of the studiesidentify the liar, not the lie.
For real world data,the choice to label the full narrative as True orFalse usually depends on the length of thenarrative; a narrator giving trial testimony or ajob interview will have many claims, whilesomeone endorsing a product may have just one:this product is good.There are high stakes narratives that are short,such as TSA airport interviews.
However, thecomputational models of such data will bedifferent from those of longer narratives wheretrue and false statements are interspersedthroughout.
We currently have no data of thistype.3 Providing Ground TruthIn longer real-world narratives people lieselectively and the interviewer usually needs tofigure out which statements, or propositions, arelies.
To enable the capture of this situation in amodel, we engage in a two-step process: thescope of selected verifiable propositions in thedata is marked, and then the claim in eachproposition is verified or refuted in thebackground investigation.3.1 Marking the scope of each propositionWe currently mark the scope of verifiablepropositions in the narrative that are likely tohave supporting background ground truthinformation before we establish the ground truth.For example, statements made about a domesticdisturbance that involved the police are likely tohave a police report to supply backgroundinformation, while ?my mother walked me toschool every day,?
while technically verifiable,will not.A verifiable proposition, or claim, is anylinguistic form that can be assigned a truth value.Propositions can be short; the transcribedanswers below are all fragmented ground truthunits:{my neck%T}{Correct%T}{Yep%T}Examples such as these are common in spokendialogue.
Although they do not correspondsyntactically to a full proposition, they havepropositional content.Propositions can also be quite long.
Forexample, in the 34 words of the sentenceAny LJM transaction that involved a cashdisbursement that would have been within mysigning authority either had to be signed by meor someone else higher in the hierarchical chainof the company.there is only a single claim: I or someone aboveme had to sign LJM transactions that involvedcash disbursements.Some material is excluded from propositiontagging.
Utterances that attest only to the frameof mind of the narrator, e.g.
expressions such as Ithink, it?s my belief, cannot be refuted orconfirmed empirically.
Similarly, a sentence likeMs.
Watkins said that rumor had it contains anassertion (rumor had it) not made by the narratorand therefore has no value in testing a verbaldeception hypothesis.
For the same reason, directquotes are excluded from verification.3.2 Marking the Ground TruthOnce the scope of the propositions in a narrativeis marked, the annotated narrative is checkedagainst the background ground truth information,and each proposition that can be verified ismarked as T or F. We represent this judgment asfollows:34But as far as the relationship between {JeffMcMahon moving from the finance group intothe industrial products group%T}, {there was noconnection whatsoever%F} (Enron){At that time Philip Morris owned the ClarkGum Company%T} and {we were trying to getinto the candy business%T} (Johnston)3.2.1 The fact checkerIt is critical that the person who marks theground truth has no contact with the persons whoare checking the narrative for markers ofdeception ?
to the extent that the latter task isdone by hand.We have employed a law student to fact checkthe claims in the one legal deposition (Johnston)we have in our current data set.
We plan toemploy an accounting student with a backgroundin forensic accounting to fact check LehmannBros.
quarterly earnings conference calls (seeLarcker and Zakolyukina (2010) for similardata).
For the other data, we have employedgraduate assistants in linguistics who do notwork on the deception markers.3.2.2 Sources of background informationAt a minimum, the background information usedto mark the ground truth should include thesource of the data used to establish the truth.That said, no data source is perfect.
A confessionmay be coerced, an eyewitness may forget, ajudgment may be faulty.
However, at some point,we have to make a decision as to what a crediblesource is.
We have assumed that the sourcesgiven in section 2.2.2 above, as well as claimsmade by the narrator that refute prior claims, allfunction as reliable sources of backgroundinformation upon which to make decisions aboutthe truth of a claim.3.2.3 Verifying a claimTo verify a claim, we use both direct andcircumstantial evidence.
However, the latter isused only to direct us to a potentially false claimand must be supported by additional, direct facts.Direct evidence requires no additionalinferencing.
In a narrative we have studied butnot marked for ground truth, the police return tothe apartment from which the suspect?s wife hasgone missing to find her body in the closet, atwhich point the suspect admits to suffocating hiswife and describes the events leading up to themurder.
His narrative prior to the confessiondescribed contrasting events that occurred in thesame timeframe; this will enable us to mark theseas False based on the direct evidence of the bodyand the confession.Circumstantial evidence requires that a fact beinferred.
For example, in his testimony beforethe U.S. Congress, Jeffrey Skilling claims thatwhen he left Enron four months before thecompany collapsed, he thought ?the companywas in good shape.?
Circumstantial evidence ofSkilling?s reputation as an astute businessmanand the well-known knowledge of his deepinvolvement with the company make thisunlikely, as the interviewing congressman pointsout.
However, we relied as well on directtestimony from other members of the EnronBoard of Directors to affirm that Skilling knewthe disastrous state of Enron when he left.Verifying claims is a difficult, time consumingand sometimes tedious process.
For the 35,090words of narrative data currently in ourcollection, we have been able to verify 184propositions, 110 as True and 74 as False.Appendix B gives the T/F counts for each of ournarratives.3.3 Enron: Examples of verificationJeffrey Skilling was the Chief Operating Officerof the Enron Corporation as it was failing in2001; he left the company in August 2001.
In histestimony before the U.S. Congress the followingyear, which we used as our primary narrativedata, Skilling made several important claims thatwere contradicted either by multiple partiesinvolved in the case or by facts on record.
Thissection illustrates how we apply the evidence toseveral of Skilling?s claims.1.
The financial condition of Enron at the timeof Skilling?s departure.MR.
SKILLING: Congressman, I can just say itagain ?
{on the date I left I absolutely,unequivocally thought the company was in goodshape.F%}Congressman Edward Markey providescircumstantial evidence that this claim is false,stating that Skilling?s reputation, competence andhands-on knowledge makes this claim hard tobelieve.
Direct evidence comes from JeffreyMcMahon, a former Enron treasurer, and JordanMintz, a senior attorney, who testified that theyhad told Skilling their concerns that limited35partnerships that the company was involved increated a conflict of interest for certain Enronboard members, and were damaging Enron itself.2.
The presence of Mr. Skilling at a criticalmeeting to discuss these limited partnerships,which enabled Enron to hide its losses.MR.
SKILLING: Well, {there?s an issue as towhether I was actually at a%F} -- the particularmeeting that you're talking about was in Florida,Palm Beach, Florida.
.
.
.But when Greenwood brandished a copy of themeeting's minutes, which confirmed Skilling'spresence, the former COO hedged his answer,saying,MR.
SKILLING: "I could have been there for aportion of the meeting.
Was I there for the entiremeeting?
I don't know."3.
The issue of whether Skilling, as Enron?sChief Operating Officer, was required to approveEnron-LJM limited partnership transactions.Mr.
SKILLING: {I was not required to approvethose transactions.%F}Minutes of the Finance Committee of Enron?sBoard of Directors, October 6, 2000 (referencedin the congressional testimony) show that?Misters Buy, Causey, and Skilling approve alltransactions between the company and LJMfunds.
?4 Conclusion and lessons learnedResearch in high stakes deception has been heldback by the difficulty of ground truthverification.
Finding suitable data "in the wild"and conducting the fact checks to obtain groundtruth is costly, time-consuming and laborintensive.
This is not an unknown problem incomputational linguistics.
Other research effortsthat rely on fact checking, such as Sauri andPustejovsky (2009), face similar ground truthchallenges.We have described our work in building acorpus customized for high stakes deceptionstudies in hopes of encouraging other researchersto build and share similar corpora.
We envisionthe eventual goal as a multi-language resourcewith standardized methods and corpora availableto the community at little or no cost.We have made several mistakes that we hopewe and others can avoid in collecting high stakesdata.
Some errors cost us time and othersaggravating work trying to correct them.Our first lesson was to establish a strictseparation between the people who annotate thedata for ground truth and those who mark it fordeception ?
if any portion of the latter is beingdone manually.
It is important that the factcheckers are not influenced by anything in thelanguage of the narrator that might skew themtoward marking a claim one way or the other.With respect to the narrative data, it isimportant in selecting new data for annotatingand ground truth checking to establish that thedata is of the types approved by the researchinstitution?s compliance board; in the UnitedStates, this is the Institutional Review Board ofthe housing institution.It is also important to have assurance thatthere is a robust body of background data withwhich to establish ground truth.
While it isimpressive to be able to find 13 of the 15verifiably false statements in 240,000 words ofnarrative?a situation we experienced with aprivate data set?it does not give us the statisticalrobustness we would hope for.We also found it important to save the datasources locally.
Websites disappear and thepossibility of further fact checking goes withthem.Finally, it is important to provide formaltraining for proposition tagging and ground truthtagging to ensure consistency and quality.Tutorials, user manuals and careful supervisionshould be available at all times.AcknowledgmentsWe are thankful to the anonymous EACLreviewers for their incisive and helpfulcomments.
Any errors or oversights are strictlythe responsibility of the authors.ReferencesJoan Bachenko, Eileen Fitzpatrick and MichaelSchonwetter.
2008.
Verification andImplementation of Language-based DeceptionIndicators in Civil and Criminal Narratives.Proceedings of the 22nd International Conferenceon Computational Linguistics (COLING 2008).University of Manchester, Manchester, UK.Eileen Fitzpatrick and Joan Bachenko.
2010.
Buildinga Forensic Corpus to Test Language-basedIndicators of Deception.
Corpus Linguistics in36North America 2008: Selections from the SeventhNorth American Symposium of the AmericanAssociation for Corpus Linguistics.
Gries, S., S.Wulff and M. Davies (eds.).
Series in Languageand Computers.
Rodopi.Tommaso Fornaciari and Massimo Poesio.
2011.Lexical vs.
Surface Features in DeceptiveLanguage Analysis, Workshop: Legal Applicationsof Human Language Technology.
13thInternational Conference on Artificial Intelligenceand Law.
June 6-10.
University of Pittsburgh.Julia Hirschberg, Stefan Benus, Jason M. Brenier,Frank Enos, Sarah Friedman, Sarah Gilman,Cynthia Girand, Martin Graciarena, AndreasKathol, Laura Michaelis, Bryan L. Pellom,Elizabeth Shriberg, Andreas Stolcke.
2005.?Distinguishing Deceptive from Non-DeceptiveSpeech,?
INTERSPEECH 2005, Lisbon,September.David F. Larcker and Anastasia A. Zakolyukina.2010.
Detecting deceptive discussions inconference calls.
Rock Center for CorporateGovernance.
Working Paper Series No.
83.Roser Sauri and James Pustejovsky.
2009.
FactBank1.0.
Linguistic Data Consortium, Philadelphia.James B.
Stiff, Steve Corman, Robert Krizek, andEric Snider.
1994.
Individual differences andchanges in nonverbal behavior; Unmasking thechanging faces of deception.
CommunicationResearch, 21, 555-581.Aldert Vrij.
2008.
Detecting Lies and Deceit: Pitfallsand Opportunities, 2nd.
Edition.
Wiley-Interscience.Code of Federal Regulations.
Retrieved Jan. 26, 2012http://www.hhs.gov/ohrp/humansubjects/guidance/45cfr46.html#46.102Appendix A.
Sources of Background Data that has been verified6Case SourceJohnston Documents available from the State of Minnesota and Blue Cross and Blue Shield ofMinnesota v Philip Morris Inc et alduring the discovery process of the trial.Routier Police report from first responder, Sgt.
Matthew Walling.
No longer available onlineEnron7 Kenneth L. Lay and Jeffrey K. Skilling Jury Trial ?
Govt.
Exhibits8Enron Special Investigations Report (The Powers Report)Employee letters and emailsKennedy Police report from Edgartown MA, and transcript of the inquestPetersonModesto Police Dept.
websiteGomez Peterson interviewSawyer Peterson interviewFindlaw.comInternational call code databaseMobile number lookupMapquestU.S.
Time ZonesLivermore Chevron StationAppendix B.
Distribution of T and F Propositions in CollectionCase Words Trues FalsesJohnston 12,762 34 48Routier 1,026 8 2Enron 7,476 23 21Kennedy 245 8 2Peterson 13,581 37 1TOTAL 35,090 110 746 We included data from two cases of theft in the original set, which was collected prior to the creation of an IRB at ouruniversity.
Incomplete documentation requires us to exclude these cases.
Another case, which we called ?Guilty Nurse,?
wasnot sufficiently sourced to be included.7 http://news.findlaw.com/legalnews/lit/enron/#documents8 http://www.justice.gov/enron/37Appendix C. Attributes of the Data SetS=spoken; W=writtenCase Case Type Mode NarratorJohnston Civil; saleof tobaccoto teensS Male 60+; retired tobacco CEORoutier Criminal;murderW Female 26; homemakerEnron (Skilling) Criminal;fraudS Male 53; former Enron COOKennedy Criminal;leaving thescene of anaccidentW Male 37; former US Senator, deceasedPetersonCriminal;murderS Male 30; agriculture chemical salesman38
