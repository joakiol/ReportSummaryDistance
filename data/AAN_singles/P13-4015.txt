Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 85?90,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSORT: An Interactive Source-Rewriting Tool for Improved TranslationShachar Mirkin, Sriram Venkatapathy, Marc Dymetman, Ioan CalapodescuXerox Research Centre Europe6 Chemin de Maupertuis38240 Meylan, Francefirstname.lastname@xrce.xerox.comAbstractThe quality of automatic translation is af-fected by many factors.
One is the diver-gence between the specific source and tar-get languages.
Another lies in the sourcetext itself, as some texts are more com-plex than others.
One way to handle suchtexts is to modify them prior to transla-tion.
Yet, an important factor that is of-ten overlooked is the source translatabil-ity with respect to the specific translationsystem and the specific model that are be-ing used.
In this paper we present an in-teractive system where source modifica-tions are induced by confidence estimatesthat are derived from the translation modelin use.
Modifications are automaticallygenerated and proposed for the user?s ap-proval.
Such a system can reduce post-editing effort, replacing it by cost-effectivepre-editing that can be done by monolin-guals.1 IntroductionWhile Machine Translation (MT) systems are con-stantly improving, they are still facing many dif-ficulties, such as out-of-vocabulary words (i.e.words unseen at training time), lack of sufficientin-domain data, ambiguities that the MT modelcannot resolve, and the like.
An important sourceof problems lies in the source text itself ?
sometexts are more complex to translate than others.Consider the following English-to-Frenchtranslation by a popular service, BING TRANS-LATOR:1 Head of Mali defense seeks more arms?
D?fense de la t?te du Mali cherche bras plus.There, apart from syntactic problems, both headand arms have been translated as if they were1http://www.bing.com/translator, accessedon 4/4/2013.body parts (t?te and bras).
However, supposethat we express the same English meaning in thefollowing way: Chief of Mali defense wants moreweapons.
Then BING produces a much bettertranslation: Chef d?
?tat-major de la d?fense duMali veut plus d?armes.The fact that the formulation of the source canstrongly influence the quality of the translation haslong been known, and there have been studies in-dicating that adherence to so-called ?ControlledLanguage?
guidelines, such as Simplified Techni-cal English2 can reduce the MT post-edition ef-fort.
However, as one such study (O?Brien, 2006)notes, it is unfortunately not sufficient to just ?ap-ply the rules [i.e.
guidelines] and press Translate.We need to analyze the effect that rules are hav-ing on different language pairs and MT systems,and we need to tune our rule sets and texts ac-cordingly?.In the software system presented here, SORT(SOurce Rewriting Tool), we build on the basic in-sight that formulation of the source needs to begeared to the specific MT model being used, andpropose the following approach.
First, we assumethat the original source text in English (say) is notnecessarily under the user?s control, but may begiven to her.
While she is a fluent English speaker,she does not know at all the target language, butuses an MT system; crucially, this system is ableto provide estimates of the quality of its transla-tions (Specia et al 2009).
SORT then automati-cally produces a number of rewritings of each En-glish sentence, translates them with the MT sys-tem, and displays to the user those rewritings forwhich the translation quality estimates are higherthan the estimate for the original source.
The userthen interactively selects one such rewriting persentence, checking that it does not distort the orig-inal meaning, and finally the translations of these2http://www.asd-ste100.org85reformulations are made available.One advantage of this framework is that theproposed rewritings are implicitly ?aware?
of theunderlying strengths and limitations of the spe-cific MT model.
A good quality estimation3component, for instance, will feel more confidentabout the translation of an unambiguous word likeweapon than about that of an ambiguous one suchas arm, or about the translation of a known termin its domain than about a term not seen duringtraining.Such a tool is especially relevant for businesssituations where post-edition costs are very high,for instance because of lack of people both ex-pert in the domain and competent in the target lan-guage.
Post-edition must be reserved for the mostdifficult cases, while pre-edition may be easier toorganize.
While the setup cannot fully guaranteethe accuracy of all translations, it can reduce thenumber of sentences that need to go through post-edition and the overall cost of this task.2 The rewriting toolIn this section we describe SORT, our implemen-tation of the aforementioned rewriting approach.While the entire process can in principle be fullyautomated, we focus here on an interactive pro-cess where the user views and approves suggestedrewritings.
The details of the rewriting methodsand of the quality estimation used in the currentimplementation are described in Sections 3 and 4.Figure 1 presents the system?s interface, whichis accessed as a web application.
With this in-terface, the user uploads the document that needsto be translated.
The translation confidence ofeach sentence is computed and displayed next toit.
The confidence scores are color-coded to en-able quickly focusing on the sentences that requiremore attention.
Green denotes sentences for whichthe translation confidence is high, and are thus ex-pected to produce good translations.
Red markssentences that are estimated to be poorly trans-lated, and all those in between are marked withan orange label.We attempt to suggest rewritings only for sen-tences that are estimated to be not so well trans-lated.
When we are able to propose rewriting(s)with higher translation confidence than the origi-nal, a magnifying glass icon is displayed next to thesentence.
Clicking it displays, on the right side of3Also known as confidence estimation.the screen, an ordered list of the more confidentrewritings, along with their corresponding confi-dence estimations.
The first sentence on the listis always the original one, to let it be edited, andto make it easier to view the difference betweenthe original and the rewritings.
An example isshown on the right side of Figure 1, where we seea rewriting suggestion for the fourth sentence inthe document.
Here, the suggestion is simply toreplace the word captured with the word caught, arewriting that is estimated to improve the transla-tion of the sentence.The user can select one of the suggestions orchoose to edit either the original or one of therewritings.
The current sentence which is beingexamined is marked with a different color and thealternative under focus is marked with a small icon(the bidirectional arrows).
The differences betweenthe alternatives and the original are highlighted.After the user?s confirmation (with the check markicon), the display of the document on the left-handside is updated based on her selection, includingthe updated confidence estimation.
At any time,the user (if she speaks the target language) canclick on the cogwheel icon and view the transla-tion of the source or of its rewritten version.
Whendone, the user can save the edited text or its trans-lation.
Moses Release 1.0 of an English-SpanishEuroparl-trained model4 was used in this work toobtain English-Spanish translations.2.1 System and software architectureSORT is implemented as a web application, usingan MVC (Model View Controller) software archi-tecture.
The Model part is formed by Java classesrepresenting the application state (user input, se-lected text lines, associated rewriting propositionsand scores).
The Controller consists of severalservlet components handling each user interactionwith the backend server (file uploads, SMT toolscalls via XML-RPC or use of the embedded Javalibrary that handles the actual rewritings).
Finally,the View is built with standard web technologies:HTML5, JavaScript (AJAX) and CSS style sheets.The application was developed and deployed onLinux (CentOS release 6.4), with a Java Runtime6 (Java HotSpot 64-Bit Server VM), within a Tom-cat 7.0 Application Server, and tested with Firefoxas the web client both on Linux and Windows 7.Figure 2 shows the system architecture of SORT,4http://www.statmt.org/moses/RELEASE-1.0/model/86Figure 1: SORT?s interfaceFigure 2: SORT?s system architecture.
For simplicity, onlypartial input-output details are shown.with some details of the current implementation.The entire process is performed via a client-serverarchitecture in order to provide responsiveness, asrequired in an interactive system.
The user com-municates with the system through the interfaceshown in Figure 1.
When a document is loaded,its sentences are translated in parallel by an SMTMoses server (Koehn et al 2007).
Then, thesource and the target are sent to the confidence es-timator, and the translation model information isalso made available to it.
The confidence estima-tor extracts features from that input and returns aconfidence score.
Specifically, the language modelfeatures are computed with two SRILM servers(Stolcke, 2002), one for the source language andone for the target language.
Rewritings are pro-duced by the rewriting modules (see Section 3 forthe implemented rewriting methods).
For eachrewriting, the same process of translation and con-fidence estimation is performed.
Translations arecached during the session; thus, when the userwishes to view a translation or download the trans-lations of the entire document, the response is im-mediate.3 Source rewritingVarious methods can be used to rewrite a sourcetext.
In what follows we describe two rewritingmethods, based on Text Simplification techniques,which we implemented and integrated in the cur-rent version of SORT.
Simplification operationsinclude the replacement of words by simpler ones,removal of complicated syntactic structures, short-ening of sentences etc.
(Feng, 2008).
Our assump-tion is that simpler sentences are more likely toyield higher quality translations.
Clearly, this isnot always the case; yet, we leave this decision tothe confidence estimation component.Sentence-level simplification (Specia, 2010)has proposed to model text simplification as a Sta-tistical Machine Translation (SMT) task where thegoal is to translate sentences to their simplifiedversion in the same language.
In this approach, asimplification model is learnt from a parallel cor-pus of texts and their simplified versions.
Apply-87ing this method, we train an SMT model from En-glish to Simple English, based on the PWKP par-allel corpus generated from Wikipedia (Zhu et al2010);5 we use only alignments involving a singlesentence on each side.
This results in a phrase ta-ble containing many entries where source and tar-get phrases are identical, but also phrase-pairs thatare mapping complex phrases to their simplifiedcounterparts, such as the following:?
due to its location on?
because it was on?
primarily dry and secondarily cold ?
bothcold and dry?
the high mountainous alps?
the alpsAlso, the language model is trained with SimpleEnglish sentences to encourage the generation ofsimpler texts.
Given a source text, it is translatedto its simpler version, and its n-best translationsare assessed by the confidence estimation compo-nent.Lexical simplification One of the primary oper-ations for text-simplification is lexical substitution(Table 2 in (Specia, 2010)).
Hence, in addition torewriting a full sentence using the previous tech-nique, we implemented a second method, address-ing lexical simplification directly, and only modi-fying local aspects of the source sentence.
The ap-proach here is to extract relevant synonyms fromour trained SMT model of English to SimplifiedEnglish, and use them as substitutions to simplifynew sentences.
We extract all single token map-pings from the phrase table of the trained model,removing punctuations, numbers and stop-words.We check whether their lemmas were synonymsin WordNet (Fellbaum, 1998) (with all possibleparts-of-speech as this information was not avail-able in the SMT model).
Only those are left asvalid substitution pairs.
When a match of an En-glish word is found in the source sentence it is re-placed with its simpler synonym to generate an al-ternative for the source.
For example, using thisrewriting method for the source sentence ?Why theGalileo research program superseded rival pro-grams,?
three rewritings of the sentence are gen-erated when rival is substituted by competitor orsuperseded by replaced, and when both substitu-tions occur together.5Downloaded from:http://www.ukp.tu-darmstadt.de/data/sentence-simplificationIn the current version of SORT, both sentence-level and lexical simplification methods are usedin conjunction to suggest rewritings for sentenceswith low confidence scores.4 Confidence estimationOur confidence estimator is based on the systemand data provided for the 2012 Quality estima-tion shared task (Callison-Burch et al 2012).
Inthis task, participants were required to estimate thequality of automated translations.
Their estimateswere compared to human scores of the translationwhich referred to the suitability of the translationfor post-editing.
The scores ranged from 1 to 5,where 1 corresponded to translation that practi-cally needs to be done from scratch, and 5 to trans-lations that requires little to no editing.The task?s training set consisted of approxi-mately 1800 source sentences in English, theirMoses translations to Spanish and the scores givento the translations by the three judges.
With thisdata we trained an SVM regression model usingSVMlight (Joachims, 1999).
Features were ex-tracted with the task?s feature-extraction baselinemodule.
Two types of features are used in thismodule (i) black-box features, which do not as-sume access to the translation system, such asthe length of the source and the target, numberof punctuation marks and language model prob-abilities, and (ii) glass-box features, which are ex-tracted from the translation model, such as theaverage number of translations per source word(Specia et al 2009).5 Initial evaluation and analysisWe performed an initial evaluation of our ap-proach in an English to Spanish translation setting,using the 2008 News Commentary data.6 First,two annotators who speak English but not Spanishused SORT to rewrite an English text.
They re-viewed the proposed rewritings for 960 sentencesand were instructed to ?trust the judgment?
of theconfidence estimator; that is, reviewing the sug-gestions from the most to the least confident one,they accepted the first rewriting that was fluent andpreserved the meaning of the source document asa whole.
440 pairs of the original sentence andthe selected alternative were then both translatedto Spanish and were presented as competitors to6Available at http://www.statmt.org88three native Spanish speakers.
The sentences wereplaced within their context in the original docu-ment, taken from the Spanish side of the corpus.The order of presentation of the two competitorswas random.
In this evaluation, the translation ofthe original was preferred 20.6% of the cases, therewriting 30.4% of them, and for 49% of the sen-tences, no clear winner was chosen.7 Among thetwo rewriting methods, the sentence-level methodmore often resulted in preferred translations.These results suggest that rewriting is esti-mated to improve translation quality.
However,the amount of preferred original translations indi-cates that the confidence estimator is not alwaysdiscriminative enough: by construction, for everyrewriting that is displayed, the confidence compo-nent estimates the translation of the original to beless accurate than that of the rewriting; yet, this isnot always reflected in the preferences of the eval-uators.
On a different dimension than translationquality, the large number of cases with no clearwinner, and the analysis we conducted, indicatethat the user?s cognitive effort would be decreasedif we only displayed those rewritings associatedwith a substantial improvement in confidence; dueto the nature of our methods, frequently, identi-cal or near-identical translations were generated,with only marginal differences in confidence, e.g.,when two source synonyms were translated to thesame target word.
Also, often a wrong synonymwas suggested as a replacement for a word (e.g.Christmas air for Christmas atmosphere).
Thiswas somewhat surprising as we had expected thelanguage model features of the confidence estima-tor to help removing these cases.
While they werefiltered by the English-speaking users, and thusdid not present a problem for translation, they cre-ated unnecessary workload.
Putting more empha-sis on context features in the confidence estimationor explicitly verifying context-suitability of a lex-ical substitutions could help addressing this issue.6 Related workSome related approaches focus on the authoringprocess and control a priori the range of possibletexts, either by interactively enforcing lexical andsyntactic constraints on the source that simplifythe operations of a rule-based translation system(Carbonell et al 1997), or by semantically guid-7One should consider these figures with caution, as thenumbers may be too small to be statistically meaningful.ing a monolingual author in the generation of mul-tilingual texts (Power and Scott, 1998; Dymetmanet al 2000).
A recent approach (Venkatapathyand Mirkin, 2012) proposes an authoring tool thatconsults the MT system itself to propose phrasesthat should be used during composition to obtainbetter translations.
All these methods address theauthoring of the source text from scratch.
Thisis inherently different from the objective of ourwork where an existing text is modified to improveits translatability.
Moving away from authoringapproaches, (Choumane et al 2005) propose aninteractive system where the author helps a rule-based translation system disambiguate a sourcetext inside a structured document editor.
Thetechniques are generic and are not automaticallyadapted to a specific MT system or model.
Closerto our approach of modifying the source text, oneapproach is to paraphrase the source or to gener-ate sentences entailed by it (Callison-Burch et al2006; Mirkin et al 2009; Marton et al 2009;Aziz et al 2010).
These works, however, fo-cus on handling out-of-vocabulary (OOV) words,do not assess the translatability of the source sen-tence and are not interactive.8 The MonoTrans2project (Hu et al 2011) proposes monolingual-based editing for translation.
Monolingual speak-ers of the source and target language collaborateto improve the translation.
Unlike our approach,here both the feedback for poorly translated sen-tences and the actual modification of the sourceis done by humans.
This contrasts with the auto-matic handling (albeit less accurate) of both thesetasks in our work.7 Conclusions and future workWe introduced a system for rewriting texts fortranslation under the control of a confidence esti-mator.
While we focused on an interactive mode,where a monolingual user is asked to check thequality of the source reformulations, in an exten-sion of this approach, the quality of the reformu-lations could also be assessed automatically, re-moving the interactive aspects at the cost of an in-creased risk of rewriting errors.
For future workwe wish to add more powerful rewriting tech-niques that are able to explore a larger space ofpossible reformulations, but compensate this ex-8Another way to use paraphrases for improved translationhas been proposed by (Max, 2010) who uses paraphrasing ofthe source text to increase the number of training examplesfor the SMT system.89panded space by robust filtering methods.
Basedon an evaluation of the quality of the generated al-ternatives as well as on user selection decisions,we may be able to learn a quality estimator forthe rewriting operations themselves.
Such meth-ods could be useful both in an interactive mode,to minimize the effort of the monolingual sourceuser, as well as in an automatic mode, to avoidmisinterpretation.
In this work we used an avail-able baseline feature extraction module for confi-dence estimation.
A better estimator could bene-fit our system significantly, as we argued above.Lastly, we wish to further improve the user inter-face of the tool, based on feedback from actualusers.References[Aziz et al010] Wilker Aziz, Marc Dymetman,Shachar Mirkin, Lucia Specia, Nicola Cancedda,and Ido Dagan.
2010.
Learning an expert fromhuman annotations in statistical machine translation:the case of out-of-vocabularywords.
In Proceedingsof EAMT.
[Callison-Burch et al006] Chris Callison-Burch,Philipp Koehn, and Miles Osborne.
2006.
Improvedstatistical machine translation using paraphrases.
InProceedings of HLT-NAACL.
[Callison-Burch et al012] Chris Callison-Burch,Philipp Koehn, Christof Monz, Matt Post, RaduSoricut, and Lucia Specia.
2012.
Findings of the2012 workshop on statistical machine translation.In Proceedings of WMT.
[Carbonell et al997] Jaime G Carbonell, Sharlene LGallup, Timothy J Harris, James W Higdon, Den-nis A Hill, David C Hudson, David Nasjleti,Mervin L Rennich, Peggy M Andersen, Michael MBauer, et al1997.
Integrated authoring and transla-tion system.
US Patent 5,677,835.
[Choumane et al005] Ali Choumane, Herv?
Blan-chon, and C?cile Roisin.
2005.
Integrating transla-tion services within a structured editor.
In Proceed-ings of the ACM symposium on Document engineer-ing.
ACM.
[Dymetman et al000] Marc Dymetman, VeronikaLux, and Aarne Ranta.
2000.
Xml and multilin-gual document authoring: Convergent trends.
InProceedings of COLING.
[Fellbaum1998] Christiane Fellbaum, editor.
1998.WordNet: An Electronic Lexical Database (Lan-guage, Speech, and Communication).
The MITPress.
[Feng2008] Lijun Feng.
2008.
Text simplification: Asurvey.
Technical report, CUNY.
[Hu et al011] Chang Hu, Philip Resnik, Yakov Kro-nrod, Vladimir Eidelman, Olivia Buzek, and Ben-jamin B. Bederson.
2011.
The value of monolingualcrowdsourcing in a real-world translation scenario:simulation using haitian creole emergency sms mes-sages.
In Proceedings of WMT.
[Joachims1999] T. Joachims.
1999.
Making large-scale SVM learning practical.
In B. Sch?lkopf,C.
Burges, and A. Smola, editors, Advances in Ker-nel Methods - Support Vector Learning, chapter 11,pages 169?184.
MIT Press.
[Koehn et al007] Philipp Koehn, Hieu Hoang,Alexandra Birch, Chris Callison-Burch, MarcelloFederico, Nicola Bertoldi, Brooke Cowan, WadeShen, Christine Moran, Richard Zens, Chris Dyer,Ondrej Bojar, Alexandra Constantin, and EvanHerbst.
2007.
Moses: Open source toolkit forstatistical machine translation.
In Proceedings ofACL, Demo and Poster Sessions.
[Marton et al009] Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009.
Improved sta-tistical machine translation using monolingually-derived paraphrases.
In Proceedings of EMNLP.
[Max2010] Aur?lien Max.
2010.
Example-based para-phrasing for improved phrase-based statistical ma-chine translation.
In Proceedings of EMNLP.
[Mirkin et al009] Shachar Mirkin, Lucia Specia,Nicola Cancedda, Ido Dagan, Marc Dymetman, andIdan Szpektor.
2009.
Source-language entailmentmodeling for translating unknown terms.
In Pro-ceedings of ACL-IJCNLP.
[O?Brien2006] Sharon O?Brien.
2006.
Controlled Lan-guage and Post-Editing.
Multilingual, 17(7):17?19.
[Power and Scott1998] Richard Power and Donia Scott.1998.
Multilingual authoring using feedback texts.In Proceedings of ACL.
[Specia et al009] Lucia Specia, Nicola Cancedda,Marc Dymetman, Marco Turchi, and Nello Cristian-ini.
2009.
Estimating the sentence-level qualityof machine translation systems.
In Proceedings ofEAMT.
[Specia2010] Lucia Specia.
2010.
Translating fromcomplex to simplified sentences.
In Proceedings ofPROPOR.
[Stolcke2002] Andreas Stolcke.
2002.
SRILM - anextensible language modeling toolkit.
In INTER-SPEECH.
[Venkatapathy and Mirkin2012] Sriram Venkatapathyand Shachar Mirkin.
2012.
An SMT-drivenauthoring tool.
In Proceedings of COLING 2012:Demonstration Papers.
[Zhu et al010] Zhemin Zhu, Delphine Bernhard, andIryna Gurevych.
2010.
A monolingual tree-basedtranslation model for sentence simplification.
InProceedings of COLING.90
