Natural Language Access to Software ApplicationsPaul SchmidtUniversity of Mainz, An der Hechschule 2,D-76711 Germersheimschmidtp@usun2, fask.
uni-mainz, deMarius Groenendijk, Peter Phelan, Henrik SchulzAnite Systems, 13, rue Robert StumperL-2557 Luxembourg{ marius;peter;henrik} @anite-systems.luSibylle Rieder, Axel TheofilidisIAI, Martin-Luther-Str.
14D-66111 SaarbrOcken{ sibylle;axel } @iai.uni-sb.deThierry DeclerckDeutsches Forschungszentrum fttr KID-66123 Saarbrtickendeclerck@dtki.uni-sb.deAndrew BredenkampUniversity of Essex, Wivenhoe Park, Colchester, CO4 3 SQandrewb@essex.ac.ukAbst rac tThis paper reports on the ESPRIT projectMELISSA (Methods and Tools for Natural-Language Interfacing with Standard SoftwareApplications) ~.MELISSA aims at developingthe technology and tools enabling end users tointerface with computer applications, using natu-ral-language (NL), and to obtain a pre-competitive product validated in selected end-user applications.
This paper gives an overviewof the approach to solving (NL) interfacingproblem and outlines ome of the methods andsoftware components developed in the project.IntroductionThe major goal of MELISSA is to provide thetechnology and tools enabling software develop-ers to provide a Natural Language (NL) interfacefor new products, as well as for legacy applica-tions.
The project is based on the conviction thatNL is the most user friendly interface for specificsoftware applications and for a specific kind ofusers.
NL is 'generic' requiring little or no train-ing.
Integrated with speech recognition and speechgeneration the NL interface is optimally conven-ient and allows for easy access to software systemsby all kinds of (non-expert) users as well as forusers with specific disabilities (e.g.
visual, motor).MELISSA will deliver three main components: acore of linguistic processing machinery and ge-neric linguistic resources for Spanish, English andGerman; a set of methods and tools for acquiringand representing the knowledge about the hostapplication and specific linguistic resources re-quired for this application; a set of methods and1 This project is sponsored by the Commission of the EU underESPRIT-22252.
Project partners are Software AG, Espana, SEMA,France/Spairt, Anite-Systems, Luxembourg, IAI, Germany, ONCE,Spain and the City of Cologne.tools for integrating the MELISSA core, the appli-cation knowledge, and the host application usingthe CORBA interoperability standard.
The overallarchitecture of a MELISSA-based NL interfaceconsists of the following software modules:?
Speech Recognition Module (SRM), which isa commercial product, providing a continuousspeech interface for the other NL modules?
Linguistic Processing Module (LPM) consistingof the linguistic processing machinery and thelinguistic resources?
Semantic Analysis Module (SAM) interpretingLPM output using application knowledge?
Function Generator Module (FGM) convertingSAM output into executable function calls?
Application Knowledge Repository (AKR) con-taining all the relevant application specificknowledge being used by SAM and FGM?
Front-End Module (FEM) responsible for in-voking requested operations in the application?
Controller Module (CTR) co-ordinating the co-operation between the previous modules?
End-User Interface (EUI) in which the user typesor dictates his NL queries to target applicationThe focus of MELISSA is on understanding NL.In that, MELISSA addresses problems fromknowledge representation and linguistic process-ing.
In the following we concentrate on the designand the interrelation of the linguistic and knowl-edge-based modules (SRM, LPM, SAM, AKR).The MELISSA tools are designed to be genericsuch that they support development of NL inter-faces for a broad range of software applications.This requires an application independent encodingof linguistic resources, and an elaboratemodularization scheme supporting flexible con-figuration of these resources for different softwareapplications.1193Furthermore, successful NL interface must meetwith user acceptance requirements regarding re-sponse time.
This poses a major challenge on thedeployment of sophisticated, competence-grammarbased NLP technologies as envisaged inMELISSA.
One aspect of ensuring efficient per-formance of a NL interface consists in limiting itscapabilities in terms of linguistic coverage.
Toavoid false (positive or negative) expectations suchrestrictions must be obviofis to the user.
In addi-tion, any restriction in terms of linguistic resourcesmust warrant naturalness of expression.1 The Speech Recognition ModuleSpeech is the most natural form of communicationfor people and is felt to greatly extend the range ofpotential applications suitable for an NL interface.MELISSA currently adopts a 'black-box' approachto speech recognition, viz., speech is just an alter-native to a keyboard.
The results of speech recog-nition are stored and can be retrieved by sending arequest o the component.
The speech componentitself can be controlled by voice commands.
Be-fore using the SRM, speakers have to 'train' it inorder to adjust he general voice model to the spe-cific speaker's voice characteristics.The speech interface sends recognized utterancesas strings to other MELISSA components, but isnot able to interact on a higher level with thosecomponents.
In a subsequent phase the feedbackand co-operation between the MELISSA corecomponents and the SRM will be addressed.2 The Linguistic Processing ModuleThe core of the LPM is based on the AdvancedLanguage Engineering Platform (ALEP), the EUCommission's standard NLP development platform\[Simpkins 94\].
ALEP provides the functionalityfor efficient NLP: a 'lean' linguistic formalism(with term unification) providing typed featurestructures (TFSs), an efficient head scheme basedparser, rule indexation mechanisms, a number ofdevices supporting modularization and configura-tion of linguistic resources, e.g.
an interface formatsupporting information flow from SGML-encodeddata structures to TFSs (thus enabling straightfor-ward integration of 'low-level' processing withdeep linguistic analysis), the refinement facilityallowing for separating parsing and 'semanticdecoration', and the specifier mechanism allowingfor multi-dimensional partitioning of linguisticresources into specialized sub-modules.For the first time ALEP is used in an industrialcontext.
In the first place, core components ofALEP (parser, feature interpreter, linguistic for-malism) are used as the basis of the MELISSALPM.
In the second place, ALEP is used as thedevelopment platform for the MELISSA lingware.The coverage of the linguistic resources for thefirst MELISSA prototype was determined by athorough user needs analysis.
The application dealtwith was an administrative purchase and acquisi-tion handling system at the Spanish organization ofblind people, ONCE.The following is an outline of solutions realized inthe LPM for text handling, linguistic analysis andsemantic representation.2.1 Text HandlingThe TH modules for MELISSA (treating phenom-ena like dates, measures, codes (pro-nr.
123/98-al-T4), abbreviations, but also multiple word unitsand fixed phrases come as independent Perl pre-processors for pattern recognition, resulting in adrastic improvement of efficiency and a dramaticexpansion of coverage.Within the general mark up strategy for words amodule has been added which allows the treatmentof specific sequences of words building units.Once those patterns have been recognized andconcatenated into one single unit, it is easy to con-vert them to some code required by the applica-tion.
Precisely this latter information is then deliv-ered to the grammar for further processing.
Forone application in MELISSA it is, for example,required to recognize distinct types of proposalsand to convert them into numeric codes (e.g.
'6rdenes de viaje' into the number '2019'.
)The TH components allow for an expansion of thecoverage of the NLP components.
Experimentshave already been made in integrating simplePOS-tagging components and in passing this in-formation to the ALEP system \[Declerck & Maas97\].
Unknown words predictable for their syntacticbehaviour can be identified, marked and repre-sented by a single default lexical entry in theALEP lexicon.
In one practical experiment, hismeant he deletion of thousands of lexieal entries.The default mechanism in ALEP works as follows,during parsing ALEP applies the result of lexieallook-up to each of the terminal nodes; if this failsthen ALEP will look at lexical entries which con-tain a default specifier to see whether any of themmatches (typically these are underspecifed forstring value, but fully specified for syntactic ate-gory etc.).
Clearly without valency informationsuch an approach is limited (but nevertheless use-ful).
Future work will focus on the (semi)-1194automatic identification of this information in thepre-processing.The modular design of the TH components (dis-tinction of application specific TH phenomena andgeneral ones) allows for a controlled extension toother languages and other applications.2.2 Linguistic AnalysisBased on experiences from previous projects\[Schmidt et al 96\], mainstream linguistic onceptssuch as HPSG are adopted and combined withstrategies from the "lean formalism paradigm'.For MELISSA, a major issue is to design linguisticresources which are transparent, flexible and easilyadaptable to specific applications.
In order tominimize configuration and extension costs, ling-ware for different languages i designed accordingto the same strategies, guaranteeing maximal uni-formity.
This is realized in semantics.
All languagemodules use the same type and feature system.Macros provide an important means of supportingmodularity and transparency.
They are extensivelyused for encoding lexieal entries as well as struc-tural rules.
Structural macros mostly encodeHPSG-like ID schemes pelled out in category-specific grammar rules.
Structural macros arelargely language-independent, but also lexicalmacros will be 'standardized' in order to supporttransparency and easy maintenance.The second major issue in linguistic analysis isefficiency of linguistic processing.
Efficiency isachieved e.g.
by exploiting the lingware partition-ing mechanisms of ALEP.
Specifier feature struc-tures encode which subpart of the lingware a rulebelongs to.
Thus for each processing step, only theappropriate subset of rules is activated.Efficient processing of NL input is also supportedby separation of the 'analysis' stage and one orseveral 'refinement" stages.
During the analysisstage, a structural representation f the NL input isbuilt by a el.
grammar, while the refinementstage(s) enriches the representation with additionalinformation.
Currently, this is implemented as atwo-step approach, where the analysis stage com-putes purely syntactic information, and the refine-ment adds semantic information (keeping syntacticand semantic ambiguities eparate).
In the futurewe will use further refinement steps for addingapplication-specific linguistic information.2.3 Semantic RepresentationDuring linguistic analysis, compositional semanticrepresentations are simultaneously encoded byreeursive mbedding of semantic feature structuresas well as by a number of features encoding dis-tinct types of semantic facts (e.g.
predications,argument relations) in terms of a unique wrapperdata type, so called 'sf-terms' (SFs).
Links be-tween semantic facts arc established through vari-able sharings as (2) shows:(i) Elaborate new proposal(2) t sem: {indx => sf( indx(event,E)) ,pred => sf(pred(elaborate,E,A,B)),arg2 => t sem:{arg => sf(arg(theme,E,B)) ,pred => sf(pred(proposal ,B)) ,mods => \[ t sem: {mod => sfTmod(qual i ty,  B,M)),pred => sf(pred(new, M))} \] }}The flat list of all SFs representing the meaning ofan NL  input expression is the input data structurefor the SAM.Besides predicate argument structure and modifi-cation, the semantic model includes functionalsemantic information (negation, determination,quantification, tense and aspect) and lexical se-mantics.
The SF-encoding scheme carries over tothese facets of semantic information as well.Special data types which are re, cognized andmarked up during TH and which typically corre-spond to basic data types in the application func-tionality model, are diacritically encoded by thespecial wrapper-type 'type', as illustrated in (4) foran instance of a code expression:(3) proposal of type 2019(4) t sem:{pred => sf(pred(proposal ,P)) ,mods => \[ t sem: {mod => sfTmod(concern,  P,M)),pred => sf( type(proptype(2Ol9) ,M))  } \] }3 Model l ing of Appl icat ion KnowledgeTwo distinct but related models of the host appli-cation are required within MELISSA.
On the onehand, MELISSA has to understand which (if any)function the user is trying to execute.
On the otherhand, MELISSA needs to know whether such afunctional request can  be executed at that instant.The basic ontological assumption underpinningeach model is that any application comprises anumber of functions, each of which requires zeroor more parameters.3.1 The SAM ModelThe output of the LPM is basically applicationindependent.
The SAM has to interpret the seman-tic output of the LPM in terms of a specific appli-cation.
Fragments of NL are inherently ambiguous.Thus, in general, this LPM output will consist of anumber of possible interpretations.
The goal of theSAM is to identify a unique function call for thespecific application.
This is achieved by a (do-1195main-independent) matching process, which at-tempts to unify each of the LPM results with oneor more so-called mapping rules.
Heuristic riteria,embodied within the SAM algorithm, enable thebest interpretation to be identified.
An examplecriterion is the principle of 'Maximal Consump-tion', by which rules matching a greater proportionof the SFs in an LPM result are preferred.Analysis of the multiple, application-independentsemantic interpretations depends on the matchingprocedure performed by the SAM, and on themapping rules.
(5) is a mapping rule:(5) ru le (e laborate (3) ,  -- (a)\ [e laborate,  e laborat ion ,  make, create,creat ion,  in t roduce\ ] ,  -- (b)\[arg (agent, e laborate ,  ),a rg( theme,  e laborate ,  p roposa l ) ,mod(concern ,  proposa l ,type (proptype ( P ropType  ) ) ) \] , -- (c)\[ new_proposa l _ type  (p roptype(PropType)  ) \] ) .
-- (d)Each mapping rule consists of an identifier (a), alist of normalised function-word synonyms (b), alist of SFs (e), and finally, a simple term repre-senting the application function to be called, to-gether with its parameters (d).The SAM receives a list of SF lists from the LPM.Each list is considered in turn, and the best inter-pretation sought for each.
All of the individual'best results' are assessed, and the overall bestresult returned.
This overall best is passed on to theFGM, which can either execute, or start a dialogue.The SFs embody structural semantic information,but also very important constraint information,derived from the text-handling.
Thus in the exam-ple rule above, it can clearly be seen that the valueof 'PropType" must already have been identified(i.e.
during text handling) as being of the type'proptype'.
In particular cases this allows for dis-ambiguation.3.2 The Application State ModelIt is obvious that NL interfaces have to respond ina manner as intelligent as possible.
Clearly, certainfunctions can only be called if the application is ina certain state (e.g.
it is a precondition of the func-tion call 'print_file' that the relevant file exists andis printable).
These 'application states' provide ameans for assessing whether or not a function callis currently permitted.A standard application can reasonably be describedas a deterministic finite state automaton.
A statecan only be changed by the execution of one of thefunctions of the application.
This allows for mod-elling an application in a monotonic fashion andthus calls for a representation i  terms of thepredicate calculus.
From amongst a number ofalternatives, the New Event Calculus (NEC) waschosen \[Sadri & Kowalski 95\] as an appropriatelypowerful formalism for supporting this state mod-elling.
NEC allows for the representation ofevents, preconditions, postcondifions and timeintervals between events.
NEC is appropriate formodelling concurrent, event-driven transitionsbetween states.
However, for single-user applica-ions, without concurrent functionality, a muchsimpler formalism, such as, for example, STRIPS-like operators, will be perfectly adequate.In terms of implementation methodology, the workto be done is to specify the application specificpredicates.
The state model of the applicationcontains as components a set of functions whichcomprise the application, a set of precondmonsthat must be fulfilled in order to allow the execu-tion of each function, and a set of consequencesthat results from the execution of a function.Both preconditions and consequences are com-posed of a subset of the set of propositions whichcomprise the current application state.
There existsa set of relations between the components: Afunction must fulfil preconditions and produces aset of consequences.
The set of preconditions i -composed-of facts.
The same holds for the set ofconsequences and the application state.
(6) gives asummary for a simple text editor.
('F' = some file).
(6) P recond i t ions :c reate(F) ,  \[not (exists(F))  \] ).open  (F) , \ [exists  (F) , not (open (F)) \] ) .c lose(F) ,  \ [ex i s ts (F ) ,open(F ) \ ]  ).de le te (F ) ,  \ [exists(F) \ ]  ).ed i t (F) ,  \ [exists (F) ,open(F)  \] ).save(F) ,  \ [ex i s ts (F ) ,open(F ) ,mod i f ied(F ) \ ]  ).spe l l _check(F ) ,  \ [exists(F)  ,open(F)  \] ) .a) Pos tcond i t ions :  Facts to be addedadd(create(F ) ,  \ [exists(F) \ ]  ) .add (open (F) , \[open (F) \] ) .add(c lose(F ) ,  \[\] ).add(de le te (F ) ,  \[\] ).add (edit (F), \ [modi f ied  (F) \] ) .add(save(F ) ,  \ [saved(F)\]  ) .add(spe l l _check(F ) ,  \ [modi f ied(F) \ ]  ).b) Pos tcond i t ions :  Facts  to be de le tedde l (c reate(F ) ,  \[\] ).de l (open(F ) ,  \[\] ).de l  (c lose (F), \ [open (F) \] ) .del  (delete (F) , \ [exists  (F) \] ) .de l  (edit (F), \[\] ).de l  (save (F), \ [modi f ied  (F) \] ) .de l ( spe l l _check(F ) ,  \[\] ) .A simple planner can be used to generate remedialsuggestion to the user, in eases where the desiredfunction is currently disabled.4 Adopted Solutions4.1 Standardisation and MethodologiesThroughout he design phase of the project anobject oriented approach as been followed using1196the Unified Modelling Language \[Beech et al 97\]as a suitable notation.
It is equally foreseen toactually propose an extension to this standard no-tation with linguistic and knowledge related as-pects.
This activity covers part of the 'Methodol-ogy and Standards' aspects of the project.Other activities related to this aspect are concernedwith 'knowledge ngineering', 'knowledge mod-elling', and 'language ngineering' (e.g.
linguisticcoverage analysis).
Methodologies are being de-veloped that define the steps (and how to carrythem out) from a systematic application analysis (akind of reverse-engineering) to the implementationof a usable (logical and physical) model of theapplication.
This model can be directly exploitedby the MELISSA software components.4.2 InteroperabilityAs stated in the introduction, CORBA \[Ben-Natan1995\] is used as the interoperability standard inorder for the different components o co-operate.The component approach, together with CORBA,allows a very flexible (e.g.
distributed) deploymentof the MELISSA system.
CORBA allows softwarecomponents to invoke methods (functionality) inremote objects (applications) regardless of themachine and architecture the called objects resideon.
This is particularly relevant for calling func-tious in the 'hosting' application.
The NL inputprocessing by the MELISSA core components(themselves communicating through CORBA)must eventually lead to the invoking of somefunction in the targeted application.
In many casesthis can be achieved through CORBAinteroperability techniques (e.g.
object wrapping).This approach will enable developers to provideexisting (legacy) applications with an NL interfacewithout having to re-implement or reverse engi-neer such applications.
New applications, devel-oped with components and distributed processingin mind, can integrate MELISSA components withlittle development effort.4.3 Design and ImplementationThe software design of all components has fol-lowed the object-oriented paradigm.
The SRM forexample is implemented based on a hierarchicalcollection of classes.
These classes cover for in-stances software structures focused on speechrecognition and distributed computing usingCORBA.
In particular the speech recognitionclasses were implemented to be independent ofvarious speech recognition programming inter-faces, and are expandable.
Vocabularies, diction-aries and user specific settings are handled byspecific classes to support he main speech appli-cation class.
Commands can easily be mapped tothe desired functionality.
Speech recognition re-suits are stored in conjunction with scores, con-fumed words and their alternatives.
OtherMELISSA components can access these resultsthrough CORBA calls.5 ConclusionsMELISSA represents a unique combination ofhigh quality NLP and state-of-the-art software- andknowledge-engineering techniques.
It potentiallyprovides a solution to the problem of re-usinglegacy applications.
The project realizes a system-atic approach to solving the problems of NL inter-facing: define a methodology, provide tools andapply them to build NL interfaces.
The productionof the first working prototype has proven thesoundness of the concept.MELISSA addresses a highly relevant area wrt.future developments in human-computer interac-tion, providing users with an intuitive way of ac-cessing the functionalities ofcomputers.Future work will focus on refinement of method-ologies, production of knowledge acquisition tools,improvement and extension of the SAM function-ality, robustness and extension of the LPM output.Contonuous user assessment will guide the devel-opment.References\[Ben-Natan 1995\] Ben-Natan, Ron (1995) CORBA : Aguide to common object request broker architecture.McCn'aw-Hill, ISBN 0-07-005427-4\[Booch et al 97\] Booch, G., Rumbaugh, J. Jacebson, I.
(1997) The Unified Modelling Language User Guide.Addison Wesley, est.
publication December 1997.\[Declerck & Maas 97\] Declerck, T. and Maas, H.D.
(1997) The Integration of a Part-of-Speech Taggerinto the ALEP Platform.
In: Proceedings of the 3rdALEP User Group Workshop, Saarbracken 1997.\[Sadd & Kowalski 95\] Sadri, F. and Kowalski, R.,(1995) Variants of the Event Calculus.
TechnicalNote, Imperial College, London.\[Schmidt et al 96\] Schmidt, P., Theofilidis, A., Rieder,S., Declerck T. (1996) Lean Formalisms, LinguisticTheory, and Applications.
Grammar Development inALF.P.
In: Proceedings of the 16th COLING, Copen-hagen 1996.\[Simpkins 94\] Simpkins, N.K.
(1994) Linguistic Devel-opment and Processing.
ALEP-2 User Guide.
CEC,Luxembourg1197
