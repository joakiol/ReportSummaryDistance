Optimizing Synonym Extraction Using Monolingual and BilingualResourcesHua WU, Ming ZHOUMicrosoft Research Asia5F Sigma Center, No.49 Zhichun Road, Haidian DistrictBeijing, 100080, Chinawu_hua_@msn.com, mingzhou@microsoft.comAbstractAutomatically acquiring synonymous words(synonyms) from corpora is a challenging task.For this task, methods that use only one kindof resources are inadequate because of lowprecision or low recall.
To improve the per-formance of synonym extraction, we proposea method to extract synonyms with multipleresources including a monolingual dictionary,a bilingual corpus, and a large monolingualcorpus.
This approach uses an ensemble tocombine the synonyms extracted by individ-ual extractors which use the three resources.Experimental results prove that the three re-sources are complementary to each other onsynonym extraction, and that the ensemblemethod we used is very effective to improveboth precisions and recalls of extractedsynonyms.1 IntroductionThis paper addresses the problem of extractingsynonymous English words (synonyms) frommultiple resources: a monolingual dictionary, aparallel bilingual corpus, and a monolingual cor-pus.
The extracted synonyms can be used in anumber of NLP applications.
In information re-trieval and question answering, the synonymouswords are employed to bridge the expressionsgaps between the query space and the documentspace (Mandala et al, 1999; Radev et al, 2001;Kiyota et al, 2002).
In automatic text summari-zation, synonymous words are employed to iden-tify repetitive information in order to avoid re-dundant contents in a summary (Barzilay andElhadad, 1997).
In language generation, syno-nyms are employed to create more varied texts(Langkilde and Knight, 1998).Up to our knowledge, there are few studies in-vestigating the combination of different resourcesfor synonym extraction.
However, many studiesinvestigate synonym extraction from only oneresource.
The most frequently used resource forsynonym extraction is large monolingual corpora(Hindle, 1990; Crouch and Yang, 1992; Grefen-statte, 1994; Park and Choi, 1997; Gasperin et al,2001 and Lin, 1998).
The methods used the con-texts around the investigated words to discoversynonyms.
The problem of the methods is that theprecision of the extracted synonymous words islow because it extracts many word pairs such as?cat?
and ?dog?, which are similar but not syn-onymous.Other resources are also used for synonym ex-traction.
Barzilay and Mckeown (2001), and Shi-mohata and Sumita (2002) used bilingual corporato extract synonyms.
However, these methods canonly extract synonyms which occur in the bilingualcorpus.
Thus, the extracted synonyms are limited.Besides, Blondel and Sennelart (2002) used mono-lingual dictionaries to extract synonyms.
Althoughthe precision of this method is high, the coverage islow because the result of this method heavily de-pends on the definitions of words.In order to improve the performance of syno-nym extraction, Curran (2002) used an ensemblemethod to combine the results of different methodsusing a monolingual corpus.
Although Curran(2002) showed that the ensemble extractors out-performed the individual extractors, it still cannotovercome the deficiency of the methods using themonolingual corpus.To overcome the deficiencies of the methodsusing only one resource, our approach combinesboth monolingual and bilingual resources to auto-matically extract synonymous words.
By combin-ing the synonyms extracted by the individual ex-tractors using the three resources, our approach cancombine the merits of the individual extractors toimprove the performance of synonym extraction.In fact, our approach can be considered as anensemble of different resources for synonymextraction.
Experimental results prove that thethree resources are complementary to each otheron synonym extraction, and that the ensemblemethod we used is very effective to improve bothprecisions and recalls of extracted synonyms.The remainder of this paper is organized asfollows.
The next section presents our approachfor synonym extraction.
Section 3 describes animplementation of the three individual extractors.Section 4 presents the evaluation results.
Section 5discusses our method.
In the last section, we drawthe conclusions of this work.2 Our ApproachInstead of using only one kind of resource toextract synonyms, we combine both monolingualand bilingual resources for synonym extraction.The resources include a monolingual dictionary,an English-Chinese bilingual corpus, and a largecorpus of monolingual documents.
Before com-bining them, we first propose three methods toextract synonyms from the three resources.
Espe-cially, a novel method is proposed to increase thecoverage of the extracted synonyms using thebilingual corpus.
Next, we develop an ensemblemethod to combine the individual extractors.
Theadvantage of our approach is that it can combinethe merits of the individual extractors to improvethe precision and recalls of the extracted syno-nyms.2.1 Synonym Extraction with a Monolin-gual DictionaryThis section proposes a method to extract syno-nyms from a monolingual dictionary.
In a mono-lingual dictionary, each entry is defined by otherwords and may also be used in the definitions forother words.
For a word in the dictionary, thewords used to define it are called hubs and thewords whose definitions include this word arecalled authorities as in (Blondel and Sennelart,2002).
We use the hubs and authorities of a wordto represent its meaning.
The assumption behindthis method is that two words are similar if theyhave common hubs and authorities.
In this paper,we only use content words as members of hubs andauthorities.We take these hubs and authorities as features ofa word.
The vector constructed with them is re-ferred to as the feature vector of a word.
The simi-larity between two words is calculated throughtheir feature vectors with the cosine measure asshown in Equation (1).===jjiiwwjivvvvFFwwsimji22212121211*)*(),cos(),(21(1)where),( ... ),,( ),,( 2211 >=< imimiiiii vwvwvwFFi is the feature vector of wi;1=ijv if word ijw is a hub or an authority of theword wi; else, 0=ijv ;2.2 Synonym Extraction with a BilingualCorpusThis section proposes a novel method to extractsynonyms from a bilingual corpus.
It uses thetranslations of a word to express its meaning.
Theassumption of this method is that two words aresynonymous if their translations are similar.Given an English word, we get their translationswith an English-Chinese bilingual dictionary.
Eachtranslation is assigned a translation probability,which is trained with a bilingual English-Chinesecorpus based on the result of word alignment.
Thealigner use the model described in (Wang et al,2001).
In order to deal with the problem of datasparseness, we conduct a simple smoothing byadding 0.5 to the counts of each translation pair asin (2).|_|*5.0)(5.0),()|(ctransecounteccountecp++=       (2)where),( eccount  represents the co-occurring fre-quency of the Chinese word c and the Englishword e in the sentence pairs.
)(ecount  represents the frequency of the Englishword e occurring in the bilingual corpus.|_| ctrans  represents the number of Chinesetranslations for a given English word e.The translations and the translation probabili-ties of a word are used to construct its featurevector.
The similarity of two words is estimatedthrough their feature vectors with the cosinemeasure as shown in (3).===jjiiccjippppFFwwsimji22212121212*)*(),cos(),(21              (3)where),( ... ),,( ),,( 2211 >=< imimiiiii pcpcpcFFi is the feature vector of wi;ijc is the jth Chinese translation of the word wi;ijp is the translation probability of the word wiis translated into ijcFor example, the feature vectors of two words?
abandon?
and ?
forsake?
are:forsake: < ( , 0.1333),  ( , 0.1333),  ( ,0.0667) ( , 0.0667), ( , 0.0667), ?>abandon:  <( , 0.3018), ( , 0.1126), ( ,0.0405), ( , 0.0225), ( , 0.0135),?>2.3 Synonym Extraction with a Monolin-gual CorpusThe context method described in Section 1 is alsoused for synonym extraction from large mono-lingual corpora of documents.
This method relieson the assumption that synonymous words tend tohave similar contexts.
In this paper, we use thewords which have dependency relationships withthe investigated word as contexts.
The contexts areobtained by parsing the monolingual documents.The parsing results are represented by dependencytriples which are denoted as <w1, Relation Type,w2>.
For example, the sentence ?
I declined theinvitation?
is transformed into three triples afterparsing: <decline, SUBJ, I>, <decline, OBJ, invi-tation> and <invitation, DET, the>.
If we name<Relation Type, w2> as an attribute of the word w1,the verb ?
decline?
in the above sentence has twoattributes <OBJ, invitation> and <SUBJ, I> .
Thus,the contexts of a word can be expressed using itsattributes.
In this case, two words are synonymousif they have similar attributes.We use a weighted version of the Dice measureto calculate the similarity of two words.),(),()),(),((),(2)2(1)1(21)2()1(213jwAjattiwAiattkkwAwAkattattwWattwWattwWattwWwwsim??
?++=(4)wherekji attattatt  , ,  stands for  attributes of  words.
),( ji attwW indicates the association strengthbetween the attribute attj with the word iw .
)( iwA denotes the attribute set of the word iw .The measure used to measure the associationstrength between a word and its attributes isweighted mutual information (WMI) (Fung andMckeown, 1997) as described in (5).
)()(),(log*),(),(),(jijijijijiattpwpattwpattwpattwWMIattwW?==(5)whereNwcountwp ii,*,*)()( =Nwrcountattp j),(*,)( =,),( wratt j =),(*, wrcount : frequency of the triples havingdependency relation r with the word w.,*,*)( iwcount : frequency of the triples includingword iw .N: number of triples in the corpus.We use it instead of point-wise mutual informationin Lin (1998) because the latter tends to overesti-mate the association between two parts with lowfrequencies.
Weighted mutual information melio-rates this effect by adding ),( ji attwp .2.4 Combining the Three ExtractorsIn terms of combining the outputs of the differentmethods, the ensemble method is a good candidate.Originally, the ensemble method is a machinelearning technique of combining the outputs ofseveral classifiers to improve the classificationperformance (Dietterich, 2000).
It has been suc-cessfully used in many NLP tasks.
For example,(Curran, 2002) proved that the ensembles of indi-vidual extractors using different contexts in themonolingual corpus improve the performance ofsynonym extraction.In fact, we can consider the extractors in theprevious sections as binary classifiers.
Thus, weuse the ensemble method to combine the output ofthe individual extractors described in the previoussections for synonym extraction.
The method isdescribed in Equation (6).
)),((),(312121 =?=iii wwsimawwsim             (6)where3) 2, 1,(i ),( 21 =wwsim i stands for the differentsimilarity measure using different resourcesdescribed in the previous sections.
)1 and ,3 ,2 ,1(i == ii aia is the weight for theindividual extractors.The reasons that we use the weighted ensemblemethod are as follows: (1) If the majority of threeextractors select the same word as a synonym of ainvestigated word, it tend to be a real synonym.This method can ensure it has a high similarityscore.
Thus, it will improve the precision of theextracted synonyms.
(2) With this method, it canimprove the coverage of the extracted synonyms.This is because if the similarity score of a candi-date with the investigated word is higher than athreshold, our method can select the candidate as asynonym even though it is only suggested by oneextractor.3 Implementation of IndividualExtractorsFor the extractor employing a monolingual dic-tionary, we use the same online dictionary as in(Blondel and Sennelart, 2002), which is named theOnline Plain Text Dictionary.
The dictionaryconsists of 27 HTML files, which is availablefrom the web site http://www.gutenberg.net/.
Withthe method described in Section 2.1, the result forthe extracted synonyms is shown in Table 1 whenthe similarity threshold is set to 0.04.
An exampleis shown as follows:acclimatize:(acclimate, 0.1481;  habituate, 0.0976)The numbers in the example are the similarityscores of two words.Table 1.
Synonyms Extracted from the MonolingualDictionaryCategory # Entries # AverageSynonymsNoun 16963 4.7Verb 5084 7.1For synonym extraction from the bilingualcorpus, we use an English-Chinese lexicon, whichincludes 219,404 English words with each sourceword having 3 translations on average.
The wordtranslation probabilities are estimated from a bi-lingual corpus that obtains 170,025 pairs of Chi-nese-English sentences, including about 2.1 millionEnglish words and about 2.5 million Chinese words.With the method described in Section 2.2, weextracted synonyms as shown in Table 2 when thesimilarity threshold is set to 0.04.Table 2.
Synonyms Extracted from the BilingualcorpusCategory #Entries #AverageSynonymsNoun 26253 10.2Verb 7364 14.8For synonym extraction from a monolingualcorpus, we use the Wall Street Journal from 1987 to1992, the size of which is about 500M bytes.
Inorder to get contexts of words, we parse the corpuswith an English parser ?NLPWIN 1 .
From theparsing results, we extracted the following fourtypes of dependency triples.
(a) <verb, OBJ, noun>(b) <verb, SUBJ, noun>(c) <noun, ATTRIB, adjective>(d)  <verb, MODS, adjunct>The statistics are shown in Table 3.
Tokenmeans the total number of triples in the triple setand type means a unique instance of triple in thecorpus.
These triples are used as contexts of wordsto calculate the similarity between words as de-scribed in Section 2.3.
The result is shown in Table4 when the similarity threshold is set to 0.1.1The NLPWIN parser is developed at Microsoft Re-search.
Its output can be a phrase structure parse tree or alogical form which is represented with dependencytriples.Table 3.
Statistics for Triples# Token # TypeOBJ 7,041,382 1,487,543SUBJ 7,180,572 2,116,761ATTRIB 4,976,822 1,393,188MODS 3,557,737 94,004Total 22,756,512 5,937,496Table 4.
Synonyms Extracted from the MonolingualCorpusCategory Entries AverageSynonymsNoun 16963 4.6Verb 5084 7.14 Evaluation4.1 The Gold StandardThe simplest evaluation measure is direct com-parison of the extracted synonyms with the manu-ally created thesaurus.
However, the thesauruscoverage is a problem.
In this paper, we combinedtwo thesauri as a gold stardard: WordNet 1.6http://www.cogsci.princeton.edu/~wn/) and Roget(Roget?s II: The New Thesaurus, 1995.http://www.bartleby.com/thesauri/).In WordNet, one synset consists of severalsynonyms which represent a single sense.
There-fore, a polysemous word occurs in more than onesynsets.
For example, the polysemous word?
abandon?
occur in five different synsets:(abandon,  forsake,  desolate,  desert,  lurch)(vacate,  empty,  abandon)(abandon,  give up, give)(abandon,  give up)(abandon)For a given word, we combine its synonyms fromall synsets including the word.
Thus, we get thesynonyms of the word ?
abandon?
as follows:abandon forsake, desolate, desert, lurch, vacate,empty, give up, giveFor synonyms in Roget, we also combine thesynonyms in different synsets into one set as wedo for WordNet.
Thus, we get the synonyms of theword ?
abandon?
as follows:abandonbreak off, desist, discontinue, give up, leaveoff, quit, relinquish, remit, stop, desert, forsake, leave,throw over, abdicate, cede, demit, forswear, hand over,quitclaim, render, renounce, resign, surrender, waive,yield, give over, forgo, lay downCombining the results of WordNet and Roget,we can get the synonyms of the word ?
abandon?
asfollows.abandon desolate, lurch, vacate, empty, give, abdicate,break off, cede, demit, desert, desist, discontinue, forgo,forsake, forswear, give up, give over, hand over, laydown, lay off, leave off, leave, quit, quitclaim, relinquish,remit, stop, swear off, throw over, render, renounce,resign, surrender, waive, yield4.2 Evaluation MeasuresThe evaluation metrics are precision, recall, andf-measure.
If we use S to indicate the synonymsthat our method extracts for a word and GS  todenote the synonyms of the word in WordNet andRoget, the methods to calculate the precision, recall,and f-measure of our methods are shown in Equa-tion (7), (8), and (9).
To investigate the results ofmore than one word, we calculate the averageprecision, recall and f-measure, which sum theindividual values divided by the number of theinvestigated words.|S||SS| G?=precision          (7)|S||SS|GG?=recall        (8)recallprecisionrecallprecision2measure-f+?
?=(9)4.3 Test SetIn order to evaluate our methods, we build up a testset which includes three parts:(a) high-frequency words: occurring more than100 times;(b) middle-frequency words: occurring more than10 times and not greater than 100 times;(c) low-frequency words: occurring no greaterthan 10 times.Table 5.
Statistics for Nouns and VerbsHigh Fre-quencyMiddleFrequencyLowFrequencyNoun 600 2000 1000Verb 340 1300 800The frequency counts are estimated from WallStreet Journal (1987-1992), from which we ran-domly extracted 3600 nouns and 2440 verbs.
TheseTable 6.
Evaluation Results for NounsHigh-Frequency Nouns Middle-Frequency Nouns Low-Frequency NounsPre Rec F Pre Rec F Pre Rec F1 0.174 0.140 0.155 0.212 0.137 0.167 0.198 0.119 0.1492 0.225 0.209 0.217 0.242 0.212 0.226 0.207 0.212 0.2093 0.118 0.109 0.114 0.117 0.104 0.109 0.099 0.096 0.0981+2+3 0.240 0.201 0.219 0.271 0.220 0.243 0.222 0.232 0.227Table 7.
Evaluation Results for VerbsHigh-Frequency Verbs Middle-Frequency Verbs Low-Frequency VerbsPre Rec F Pre Rec F Pre Rec F1 0.228 0.243 0.235 0.272 0.233 0.251 0.209 0.216 0.2122 0.226 0.312 0.262 0.224 0.292 0.253 0.184 0.275 0.2203 0.143 0.166 0.154 0.162 0.127 0.142 0.128 0.135 0.1321+2+3 0.295 0.323 0.308 0.311 0.304 0.307 0.238 0.302 0.266Note: 1, 2, and 3 represent the extractor using the monolingual dictionary, the bilingual corpus, and the monolingualcorpus respectively.
The symbols ?
Pre?
, ?
Rec?
, and ?
F?
represent precision, recall, and f-measure scores.00.050.10.150.20.250.30.350.40.450 0.1 0.2 0.3 0.4 0.5RecallPrecision2 1 3 1+2+3Figure 1.
Recall-Precision curves for nounsFigure 2.
Recall-Precision curves for verbswords have synonyms both in our results extractedfrom the three resources and in the thesauriWordNet and Roget.
The statistics of the test setare shown in Table 5.4.4 Experimental  ResultsIn this section, we compare the extracted syno-nyms of the nouns and verbs in the test set withthose in WordNet and Roget.
For each method, weselect those as synonyms whose similarity scoreswith the investigated word are larger than a giventhreshold.
A development set is used to determinethe thresholds of each method.
The thresholds forgetting highest f-measure scores on the develop-ment set are selected.
In our experiments, we get0.04, 0.04, 0.1 and 0.04 for Method 1, Method 2,Method 3 and the combined approach, respectively.The evaluation results for the individual extractorsand the ensemble extractor are shown in Table 6and Table 7.
We set a1=0.4, a2=0.4 and a3=0.2 inEquation (6) for the ensemble to combine the re-sults from the three resources.
The weights are alsoobtained with the development set.In order to examine the performance of eachmethod in more details, we also get the precisionsand recalls under different thresholds.
Figure 1 andFigure 2 shows the precision values under differentrecall values (different thresholds) for all nouns andverbs, respectively.Among all of the methods, the method com-bining all of the three resources gets the best resultsin terms of both precision and recall.
The effect issimilar to the ensemble methods for synonym00.050.10.150.20.250.30.350.40.450 0.1 0.2 0.3 0.4 0.5 0.6 0.7RecallPrecision2 1 3 1+2+3extraction in (Curran 2002).
However, our methoduses an ensemble of different resources instead ofone single resource.
During the experiments, wealso find the ensemble combining all of the threeextractors outperforms the ensembles only com-bining any two of the three extractors.
This indi-cates that the extractors using the three differentresources are complementary to each other.
Forexample, the extractor using the monolingualdictionary gets a high precision and the extractorusing the bilingual corpus gets a high recall.
Al-though the extractor using the monolingual corpusachieved much lower precision and recall onsynonym extraction, it is still useful to be includedin the ensemble.
This shows that the monolingualcorpus is complementary to the other two re-sources on synonym extraction.
The success ofour method also indicates that our ensemblemethod by weighting all extractors is effective forsynonym extraction.Among the methods only using one kind ofresource, Method 2, which uses the bilingualcorpus, has the highest f-measure scores on bothnouns and verbs.
From the results in Figure 1 andFigure 2, we can see that the coverage of syno-nyms extracted by Method 2 is the highest.
Al-though it has lower precisions than Method 1under low recalls, its precisions are higher thanthose of Method 1 under higher recalls.
Thisshows that Method 2 can get a good compromisebetween precision and recall.
We also note that themaximum recall of Method 2 is much larger thanthat of Method 1.
This is because (1) in Method 1,the words used in the definitions are highly limited.Thus, the coverage of the synonyms is limited; (2)the advantage of Method 2 is that the coverage ofextracted synonyms is high because it can extractthe synonyms not occurring in the corpus.
It isdifferent from the method in (Barzilay andMckeown, 2001; Shimohata and Sumita, 2002),which can only extract the synonyms in the bi-lingual corpus.The performance of Method 3 is the worst.
It iscaused by two factors: (1) the context model ofMethod 3 introduces much noise because of theerrors of the parser; (2) this method is unable todistinguish synonyms, antonyms, and similarwords because they tend to have similar contexts.From the contexts it uses, method 3 is suitable toextract related words which have the similar us-ages from the view of syntax.5 DiscussionsThis paper uses three different methods and re-sources for synonym extraction.
By using the cor-pus-based method, we can get some synonyms ornear synonyms which can not be found in thehand-built thesauri.
For Example: ?
handspring handstand?
, ?
audiology   otology?
, ?
roisterer carouser?
and ?
parmesan  gouda?
.
Thesekinds of synonyms are difficult for hand-builtthesauri to cover because they occur too infrequentto be caught by humans.
In addition, this cor-pus-based method can get synonyms in specificdomains while the general thesauri don?t providesuch fine-grained knowledge.Comparing the results with the human-builtthesauri is not the best way to evaluate synonymextraction because the coverage of the human-builtthesaurus is also limited.
However, manuallyevaluating the results is time consuming.
And italso cannot get the precise evaluation of the ex-tracted synonyms.
Although the human-builtthesauri cannot help to precisely evaluate the re-sults, they can still be used to detect the effective-ness of extraction methods.ConclusionThis paper proposes a new method to extractsynonyms from three resources: a monolingualdictionary, a bilingual corpus, and a large mono-lingual corpus.
This method uses a weighted en-semble to combine all of the results of the indi-vidual extractors using one of the three resourcesrespectively.
Experimental results prove that thethree resources are complementary to each other onsynonym extraction, and that the ensemble methodwe used is very effective to improve both preci-sions and recalls when the results are comparedwith the manually-built thesauri WordNet andRoget.Further, we also propose a new method to ex-tract synonyms from a bilingual corpus.
Thismethod uses the translations of a word to representits meaning.
The translation probabilities aretrained with the bilingual corpus.
The advantage ofthis method is that it can improve the coverage ofthe extracted synonyms.
Experiments indicate thatthis method outperforms the other methods using amonolingual corpus or a monolingual dictionary.The contribution of this work lies in three as-pects: (1) develop a method to combine the resultsof individual extractors using the three resourceson synonym extraction; (2) investigate the per-formance of the three extraction methods usingdifferent resources, exposing the merits and de-merits of each method; (3) propose a new methodto extract synonyms from a bilingual corpus,which greatly improves the coverage of the ex-tracted synonyms.ReferencesBarzilay R. and Elhadad M. 1997.
Using lexical chainsfor text summarization.
In proceedings of the ACLWorkshop on Intelligent Scalable Text Summariza-tion, pp10-17.Barzilay R. and McKeown K. 2001.
Extracting Para-phrases from a Parallel Corpus.
In Proc.
ofACL/EACL.Blondel V. D. and Sennelart P. 2002.
Automatic ex-traction of synonyms in a dictionary.
In Proc.
of theSIAM Workshop on Text Mining.Crouch C. J. and Yang B.
1992.
Experiments in auto-matic statistical thesaurus construction.
In Proc.
ofthe 15th Annual International ACM SIGIR confer-ence on Research and Development in InformationRetrieval, pp77-88.Curran J.
2002 Ensemble Methods for Automatic The-saurus Extraction.
In Proc.
of the Conference onEmpirical Methods in Natural Language Processing.pp.
222-229.Dietterich T. 2000.
Ensemble Methods in MachineLearning.
In Proc.
of the First International Work-shop on Multiple Classier Systems.
pp 1-15.Fung P., Mckeown K. 1997.
A Technical Word- andTerm- Translation Aid Using Noisy Parallel Corporaacross Language Groups.
In: Machine Translation,Vol.1-2 (special issue), pp53-87.Gasperin C., Gamallo P., Agustini A., Lopes G., LimaV.
2001 Using Syntactic Contexts for MeasuringWord Similarity.
Workshop on Knowledge Acquisi-tion & Categorization, ESSLLI.Grefenstette G. 1994 Explorations in Automatic The-saurus Discovery.
Kluwer Academic Press.Hindle D. 1990.
Noun Classification from Predi-cate-Argument Structure.
In Proc.
of the 28th AnnualMeeting of the Association for Computational Lin-guistics.Kiyota Y., Kurohashi S., Kido F. 2002.
"Dialog Navi-gator":  A Question Answering System Based onLarge Text Knowledge Base.
In Proc.
of the 19thInternational Conference on Computational Linguis-tics.Langkilde I. and Knight K. 1998.
Generation that Ex-ploits Corpus-based Statistical Knowledge.
In Proc.
ofthe COLING-ACL.Lin D. 1998 Automatic Retrieval and Clustering ofSimilar Words.
In Proc.
of the 36th Annual Meeting ofthe Association for Computational Linguistics.Mandala R., Tokunaga T. Tanaka H. 1999.
CombiningMultiple Evidence from Different Type of Thesaurusfor Query Expansion.
In Proc.
of the 22nd annual in-ternational ACM SIGIR conference on Research anddevelopment in information retrieval.Park Y.C.
and Choi K. S. 1997.
Automatic ThesaurusConstruction Using Baysian Networks.
InformationProcessing & Management.
Vol.
32.Radev D., Qi H., Zheng Z., Goldensohn S., Zhang Z.,Fan W., Prager J.
2001.
Mining the Web for Answersto Natural Language Questions.
In the Tenth Interna-tional ACM Conference on Information and Knowl-edge Management.Shimohata M. and Sumita E. 2002.
Automatic Para-phrasing Based on Parallel Corpus for Normalization.In Proc.
of the Third International Conference onLanguage Resources and Evaluation.Wang W., Huang J., Zhou M., Huang C.N.
2001.
Find-ing Target Language Correspondence for LexicalizedEBMT System.
In Proc.
of the 6th Natural LanguageProcessing Pacific Rim Symposium.
