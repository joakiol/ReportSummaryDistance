Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 351?361,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsPaCCSS?IT: A Parallel Corpus of Complex?Simple Sentences for AutomaticText SimplificationDominique Brunato, Andrea Cimino, Felice Dell?Orletta, Giulia VenturiIstituto di Linguistica Computazionale ?Antonio Zampolli?
(ILC?CNR)ItaliaNLP Lab - www.italianlp.it{name.surname}@ilc.cnr.itAbstractIn this paper we present PaCCSS?IT, a Paral-lel Corpus of Complex?Simple Sentences forITalian.
To build the resource we develop anew method for automatically acquiring a cor-pus of complex?simple paired sentences ableto intercept structural transformations and par-ticularly suitable for text simplification.
Themethod requires a wide amount of texts thatcan be easily extracted from the web making itsuitable also for less?resourced languages.
Wetest it on the Italian language making avail-able the biggest Italian corpus for automatictext simplification.1 IntroductionThe availability of monolingual parallel corpora isa prerequisite for research on automatic text sim-plification (ATS), i.e.
the task of reducing sentencecomplexity by preserving the original meaning.
Thishas been recently shown for different languages, e.g.English (Zhu et al, 2010; Woodsend and Lapata,2011; Wubben et al, 2012; Siddharthan and An-grosh, 2014), Spanish (Bott and Saggion, 2011; Bottand Saggion, 2014), French (Brouwers et al, 2014),Portuguese (Caseli et al, 2009), Danish (Klerkeand S?gaard, 2012), Italian (Brunato et al, 2015).While English can rely on large datasets like thewell-known Parallel Wikipedia Simplification cor-pus (Coster and Kauchak, 2011; Zhu et al, 2010)and, more recently, the Newsela corpus (Xu et al,2015), for other languages similar resources are dif-ficult to acquire and tend to be very small, thus pre-venting the application of data?driven techniques toautomatically induce simplification operations.
Thisis true for the language we are considering, i.e.Italian, where the only documented corpus for textsimplification contains approximately 1,000 alignedoriginal and manually simplified sentences (Brunatoet al, 2015).In this paper we present PaCCSS?IT, a ParallelCorpus of Complex?Simple Aligned Sentences forITalian.
To build the resource we developed a newapproach for automatically acquiring a large corpusof paired sentences containing structural transfor-mations which can be used as a developmental re-source for text simplification systems.
The proposedapproach relies on monolingual sentence alignmenttechniques which have been exploited in differentscenarios such as e.g.
paraphrase detection (Ganitke-vitch et al, 2013; Barzilay and Lee, 2003; Dolan etal., 2004) and evaluation (Chen and Dolan, 2011),question answering (Fader et al, 2013), textual en-tailment (Bosma and Callison-Burch, 2007), ma-chine translation (Marton et al, 2009), short answerscoring (Koleva et al, 2014), domain adaptation ofdependency parsing (Choe and McClosky, 2015).Specifically in ATS, these techniques are typicallyapplied to already existing parallel corpora; in thiscase the task of aligning the original sentence to itscorresponding simple version can be tackled by ap-plying similarity metrics that consider the TF/IDFscore of the words in the sentence (Barzilay and El-hadad, 2003; Nelken and Shieber, 2006; Coster andKauchak, 2011) or methods taking into account alsothe order in which information is presented (Bottand Saggion, 2011).Differently from these methods, our approach351contains two important novelties: the typology ofthe starting data and consequently the methodol-ogy developed to build the complex?simple alignedcorpus.
To overcome the scarcity of large paral-lel corpora of complex and simple texts in less?resourced languages like Italian, we started from awide amount of texts that can be easily extractedfrom the web for all languages.
This makes ourmethod less expensive since it does not need a man-ually created corpus of aligned documents.The proposed alignment method has beenstrongly shaped by the perspective from which weinvestigate text simplification, i.e.
syntactic ratherthan lexical simplification.
While lexical simplifi-cation aims at the substitution of complex words bysimpler synonyms, syntactic simplification attemptsto reduce complexity at grammatical level (Bott andSaggion, 2014).
As shown by comparative analy-ses of monolingual parallel corpora in many lan-guages, syntactic simplification concerns transfor-mations affecting e.g.
verbal features, the order ofphrases or the deletion of redundant or unnecessarywords (Brunato et al, 2015; Bott and Saggion, 2014;Coster and Kauchak, 2011; Caseli et al, 2009).
Fol-lowing this second perspective we define a methodfor bootstrapping and pairing sentences that inter-cepts simplification operations at morpho?syntacticand syntactic level typically used by human expertswhen simplify real texts.Section 2 illustrates the approach to automaticallyacquire the corpus of complex?simple aligned sen-tences.
In Section 3, the approach is tested and tunedon a development corpus.
In Section 4, our approachis applied on a large corpus thus obtaining the finalcorpus of paired sentences, named PaCCSS?IT.
Inthis last section, we also provide a global evaluationof the whole process and a qualitative analysis of thelinguistic phenomena related to sentence complexitythat we intercepted.2 The ApproachOur approach for automatically acquiring the collec-tion of paired sentences combines three steps.
Ina first step, we devised an unsupervised methodol-ogy i) to collect pools of sentences from a large cor-pus with overlapping lexicon but possible differentstructures; ii) to rank the resulting candidate sen-tences according to a similarity metric intended tobootstrap lexical?equivalent pairs undergoing struc-tural transformations.
In the second step, the top?listof the ranked pairs was manually revised and usedto develop a classifier based on lexical, morpho?syntactic and syntactic features to detect the sen-tences correctly paired.
In the third step, the indi-vidual sentences of each pair were ordered with re-spect to linguistic complexity computed by using anautomatic readability assessment tool.This approach has been tuned on PAISA`1 (Ly-ding et al, 2014) and tested on ItWaC (Baroni etal., 2009).
The two analysed corpora were auto-matically POS tagged by the Part?Of?Speech taggerdescribed in Dell?Orletta (2009) and dependency?parsed by the DeSR parser (Attardi et al, 2009).PAISA` is a freely distributed corpus of texts withCreative Commons license automatically harvestedfrom the web.
This corpus includes approximately388,000 documents for a total of 250 millions oftokens and it is a large existing corpus of authen-tic contemporary texts in Italian which is free ofcopyright restrictions.
ItWaC is the largest exist-ing corpus of authentic contemporary texts in Ital-ian.
It is a 2 billion word corpus constructed fromthe Web limiting the crawl to the .it domain and us-ing medium-frequency words from La Repubblicajournalistic corpus and Basic Italian Vocabulary listsas seeds.2.1 Unsupervised StepThe first step is aimed at clustering all sentencescontained in a large corpus.
To be included in thesame cluster, the sentences have to share all lem-mas tagged with the Part?Of?Speech (POS) ?noun?,?verb?, ?numeral?, ?personal pronoun?
and ?nega-tive adverb?.
Nouns and verbs were selected be-cause they capture the informational content of asentence.
The other functional categories have alsoto be shared, otherwise the meaning of the sentencewould be altered.
For example, the deletion of thenegative adverb non (not) in one of the two follow-ing sentences would convey the opposite meaning:Non farei mai una cosa del genere!
(I would neverdo something like that) Non potevo fare una cosadel genere.
(I could not do something like that).
In1http://www.corpusitaliano.it/352the overlapping process we did not take into accountthe linear order of the considered lemma POS.
Thiswas meant to capture lexically?equivalent sentencesundergoing potential structural transformations (e.g.passivization, topicalization).All sentences within the same cluster were pairedand the pairs were ranked for similarity by calcu-lating the cosine distance between the sentence vec-tors.
Each vector is constituted by the frequenciesin the cluster of all lemma of the sentence.
The co-sine similarity served to discard different and equalor quasi?equal sentences.The whole unsupervised step was used to selectthe set of candidate pairs reducing the number ofpairs on which the following supervised step hadbeen applied.2.2 Supervised StepThe supervised step is meant to classify whethercandidate pairs were correctly or incorrectly aligned.To this end, we built a classifier based on SupportVector Machines with a quadratic kernel using LIB-SVM (Chang and Lin, 2001) that was trained on acorpus of paired sentences correctly aligned.
Theclassifier used different types of linguistic features,i.e.
lexical, morpho?syntactic and syntactic, meantto mainly capture structural transformations occur-ring in the paired sentences.These features were extracted both calculatingtheir distribution in each sentence and consider-ing their overlap between the two paired sentences.They can be classified into the following types:cosine similarity feature: it refers to the cosinevalue calculated for each pair of sentences;raw text feature: it refers to the sentence length cal-culated in terms of i) tokens of each of the two pairedsentences and ii) the different number of tokens be-tween the two sentences;lexical features: they refer to i) the lemma uni-grams contained in the two sentences excluding thePoS already considered in the pairing process (i.e.nouns, verbs, numerals, personal pronouns, negativeadverbs); ii) the distribution of word unigrams over-lapping between the two paired sentences consider-ing all PoS.morpho?syntactic feature: it refers to the distribu-tion of up to 4?grams of coarse grained Parts?Of?Speech;syntactic features: they refer to i) the distribution ofup to 4?grams of dependency types calculated withrespect to the hierarchical parse tree structure andthe surface linear ordering of words; ii) the distribu-tion of up to 4?grams of coarse grained Parts?Of?Speech of a dependent (d) involved in a dependencyrelation and the dependency relation type (t) with re-spect to the hierarchical parse tree structure.2.3 Readability Assessment StepIn the third step, the individual sentences of eachclassified pair were ordered with respect to linguisticcomplexity computed by using an automatic read-ability assessment tool.
In text simplification re-search it is widely accepted the use of readability as-sessment metrics for evaluating the transformationsthat reduce sentence complexity (Zhu et al, 2010;Woodsend and Lapata, 2011; Vajjala and Meurers,2016).
Since our approach is devoted to building re-sources for developing ATS systems, we relied onreadability assessment techniques to rank the indi-vidual sentences of the pair.
To this aim, we usedREAD?IT (Dell?Orletta et al, 2011), the only exist-ing NLP?based readability assessment tool devisedfor Italian.
It operates on syntactically parsed textsand assigns to each sentence a score quantifying itsreadability.
The assigned readability score rangesbetween 0 (easy?to?read) and 1 (difficult?to?read)referring to the percentage probability for the docu-ments or sentences to belong to the class of difficult?to?read documents.
The two poles were defined ontwo typologies of texts belonging to the same tex-tual genre (i.e.
newswire texts) but intended for dif-ferent users: adults with a rudimentary literacy levelor with mild intellectual disabilities for the easy?to?read pole and readers of a national daily newspaperconsidered of medium difficulty for?70% of Italianlaymen for the difficult?to?read pole.3 Tuning Process and EvaluationIn order to tune and evaluate each step of the pro-posed approach, we tested it on PAISA`.
We firstpruned from the corpus the sentences with a num-ber of tokens <5 and >40.
The resulting sentenceswere then grouped with respect to their shared POS(i.e.
nouns, verbs, numerals, personal pronouns andnegative adverbs) and paired using cosine similarity.353Cosine no correct pairs % correct pairs0.92 54 12.030.91 151 29.490.90 91 26.760.89 157 23.360.88 331 48.040.87 336 68.150.86 674 57.360.85 107 57.220.84 176 61.750.83 1096 40.350.71 1092 38.970.70 62 27.80Total: 4,327Table 1: Absolute number and % distribution of correct ex-tracted pairs for each manually reviewed cosine threshold inPAISA?.We obtained 256,383 clusters containing at least twosentences.
In order to discard different and equal orquasi?equal sentences we empirically set two cosinepruning thresholds: we discarded pairs with cosinebelow 0.4 since they were too lexically different andabove 0.93 since they were too identical.To build the training set for the supervised stepwe selected a subset of pairs resulting from the un-supervised step at different cosine similarity scores.This subset was manually reviewed by two native?speaker linguists with a background in text sim-plification.
Specifically, they reviewed a subset of10,543 pairs at different cosine similarity scores, i.e.those comprised between 0.92 and 0.83.
In order toevaluate sentence similarity at lower values we alsoselected cosine scores 0.71 and 0.70.
In the end, weobtained 4,327 correct pairs (i.e.
about 41% of thewhole set of candidate sentence pairs) distributed asin Table 1.This manually revised set of pairs was then usedto test the classifier in two different experimentalscenarios.
In the first one, named Known Cosine,KC, we tested the classifier in a five?fold cross val-idation process where pairs of sentences belongingto all the cosine scores were contained in each train-ing and test set.
In the second experiment, namedUnknown Cosine, UC, the manually?revised corpuswas differently split.
In this case, the test set wascomposed by pairs of sentences with a cosine simi-larity score not contained in the training set and con-Figure 1: Accuracy of the KC and UC experiments comparedwith the distribution of correctly paired sentences at differentcosine similarity scores.sequently twelve classification runs were performed.In order to assess the discriminating power of thelinguistic features used in the classification, we car-ried out an Information Gain analysis.
This analy-sis showed the effectiveness of all the selected fea-tures in both experiments (i.e.
KC, UC).
In particu-lar, we observed that the best ranked features are themorpho?syntactic and syntactic ones.
This mightsuggest that our classification approach is intercept-ing pairs of sentences undergoing different typolo-gies of structural transformations involving e.g.
theuse of verbal features or the order of phrases.
Sen-tence length and lexical features play a lower dis-criminative role with respect to the grammatical fea-tures; this follows from the constraints we put on theunsupervised sentence pairing process.
As it can beexpected, the best ranked features are those provid-ing information about the overlapping characteris-tics of the paired sentences.Figure 1 and 2 report the results for each cosinethreshold considered in the manual revision of thetwo experiments respectively in terms of i) Accu-racy in the classification of the correct and incorrectalignments, and of ii) Precision, Recall of the classi-fication of the correct alignments.
As it can be notedin Figure 1, in both experiments the classifier is ableto outperform the process of sentence pairing basedonly on the cosine (i.e.
line Cosine, that representsthe unsupervised step of the pairing process).
As wecan expect, Precision, Recall and Accuracy of theKC experiment are higher than the classification re-sults obtained in the UC.
The latter represents a more354Figure 2: Precision and Recall of the two experiments (KC andUC) in the classification of the correct alignments.challenging experimental scenario where the classi-fier is tested on a cosine threshold unseen in training.The overall results for the KC and the UC experi-ments are respectively 73.95% and 58.71% in termsof Precision, 70.3% and 68.1% in terms of Recall;and respectively 77.64% and 67.2% in terms of Ac-curacy.
These results are significantly higher whencompared with the accuracy of 41% reported for theunsupervised alignment (i.e.
line Cosine).
Interest-ingly, in the KC experiment, Precision and Recalllines are close and they remain stable with respectto all cosines even if the distribution of correct pairsvaries in the different cosine values.Figure 3 shows the accuracy of our classifier atdifferent confidence thresholds (i.e.
the probabilityassigned by the classifier for the correct alignments)for both the KC and UC experiments.
Note that foreach confidence intervals we have a different num-ber of total pairs, and of gold-correct alignments andgold-incorrect alignments.
As expected, the perfor-mance grows as the confidence grows.
Interestingly,in the KC scenario, the classifier reached up to 90%of accuracy in discriminating the correct from theincorrect alignments when the classifier has a confi-dence score ?0.90.
These results look very promis-ing if we consider that 30% of the pairs of the wholetest set classified as correct alignments is comprisedin the subset for which the classifier is more con-fident.
This is also the case of the UC experiment,where, even if with lower accuracies, more than 56%of the correct alignments occurs when the classifierhas a confidence score ?0.90.We carried out a last evaluation to estimate theclassifier performance in the UC scenario for lowFigure 3: Classifier performance in the KC and UC experi-ments with probability intervals reported along the x axis.cosine ranges not comprised in the manually revisedportion of the corpus (from 0.45 to 0.75, exclud-ing cosines 0.70 and 0.71).
We considered only thepairs classified as correct with a confidence score of?85%.
As expected, the system performance growsas the cosine grows: only few correct pairs occur atcosine <0.60, at cosine 0.60?0.65 the classifier as-signs the correct class 237 times with an accuracyof 62.97%, at 0.65?0.69 330 times with 71.82% andat 0.72?0.75 256 times with an accuracy of 87.89%.According to these evaluations, we extracted fromPAISA?
those pairs with a confidence score ?
85%and cosine similarity between 0.6 and 0.93, resultingin a collection of about 20,000 pairs.In the last step, the sentences in each pair wereranked according to the readability score automat-ically assigned by READ?IT making a collectionof complex?simple aligned sentences.
However, theaverage difference of the readability score betweenthe complex and simple sentences is only 0.13, mak-ing this collection not so useful for ATS.
For thisreason, we selected only pairs with a difference ofreadability score higher than a significant thresholdset at 0.2.
We defined this threshold on the basisof previous empirical experiments carried out usingREAD-IT on different typologies of texts.
Lowervariations of READ-IT score are scarcely perceivedby human subjects.
Since the construction of thisresource has been specifically designed to developATS systems for human target, this READ-IT varia-tion is a fundamental parameter of PaCCSS-IT.
Wethus obtained about 4,450 pairs.3554 PaCCSS?ITThe unsupervised step applied to ItWaC resulted in?28 million of clusters with overlapping lexicon fora total of ?35 million of single sentences.
Fromthis initial set we pruned sentences with a numberof tokens <5 and >40 and clusters containing lessthan two sentences.
We obtained 419,252 clustersfor a total of ?8,5 million of single sentences andan average number of pairs in each cluster of 1,613.Filtering the pairs according to the cosine similarityrange defined in the development step, we obtaineda subset of 73,142 clusters with an average of ?112pairs for each.
The classifier with the same modeltested on PAISA?
recognised about 1 million of cor-rect aligned pairs.
Excluding pairs below the confi-dence score ?
85% we obtained ?284,000 pairs.This collection was further pruned selecting onlythose pairs with at least 0.2 points in terms of vari-ation in readability score.
PaCCSS?IT is the result-ing resource.
It is a freely available resource 2 com-posed of ?63,000 pairs of sentences (?126k sen-tences) ranked with respect to the readability scoreof the two sentences.
For each pair the cosine sim-ilarity, the probability score of the classifier and thereadability level of the sentences are provided.The following sections report the evaluation andthe qualitative analysis we carried out on PaCCSS?IT.
The evaluation was performed to assess the re-liability of sentence alignment and of the sentenceranking with respect to readability level.
The qual-itative analysis was focused on studying which lin-guistic phenomena typically related to text simplifi-cation are successfully intercepted by our approachin order to show the applicability of the resource ina ATS scenario.4.1 EvaluationThe evaluation process was intended to calculate theaccuracy of i) the automatic classification processin predicting correct sentence alignments and ii) theautomatic readability ranking of each pair.The alignment evaluation was carried out by twotrained linguists who manually revised 40 pairs ofrandomly selected sentences for each cosine score(1,088 paired sentences).
It resulted that 85% ofpairs were correctly classified (i.e.
921 pairs) and2http://www.italianlp.it/software-data/precision increases as cosine grows (from 73.2% atcosine 0.65-0.69 to 90.8% at cosine 0.90-0.92).The subset of 921 pairs correctly classified wasfurther investigated with respect to the readabilitylevel automatically assigned.
To this aim we elicitedhuman judgements through the crowdsourcing plat-form CrowdFlower3.
We collected judgements from7 workers that were asked to rate for each pair whichof the two individual sentences was simpler.
Weconsidered the majority label to be true label foreach pair.
Comparing the score obtained by our sys-tem with the human judgements we obtained an ac-curacy of 74%.
Restricting the evaluation only topairs with the same label assigned by at least fiveout seven annotators (i.e.
79% of the whole pairs),the system achieved an accuracy of 78%.4.2 Qualitative AnalysisTwo qualitative analyses were carried out onPaCCSS?IT.
The first analysis took into account thesubset of 921 revised pairs with the aim of manu-ally investigating what kinds of sentence transfor-mations previously observed in the literature on textsimplification were intercepted by our approach.
Inthe second one, the whole resource was automati-cally investigated to study how the alignment pro-cess impacts on the distribution of multi?level lin-guistic features correlated to sentence complexity.4.2.1 Analysis of Simplification OperationsFollowing the classification of simplification op-erations proposed in the literature (Brunato et al,2015; Bott and Saggion, 2014; Coster and Kauchak,2011; Caseli et al, 2009), we identified the majortypes of operations occurring in the subset of revisedpairs 4, namely:Deletion: the second sentence (S) does not con-tain one or more than two words occurring in thefirst one (C):?
C: Ma c?e` un altro problema, ancora piu` grave.
[Lit: But there is another problem, even moreserious.
]3www.crowdflower.com4In each of the following examples the first sentence (C) isthe complex sentence and the second (S) the simple one.
Weunderlined the text span affected by the operation.356?
S: Poi c?e` un altro problema.
[Lit: Then thereis another problem.
]Verbal Features: the two sentences differ withrespect to verbal mood and tense:?
C: I suoi libri sono stati tradotti in molte lingue.
[Lit: His books have been translated in manylanguages.]?
S: I suoi libri sono tradotti in diverse lingue.
[Lit: His books have been translated in differ-ent languages.
]Lexical Substitution: the two sentences containsynonyms of words tagged with POS which were notconsidered in the clustering step based on POS over-lapping, e.g.
adjectives, adverbs:?
C: Il colore e` un rosso rubino fittissimo, quasiimpenetrabile, limpido.
[Lit: The color isa rubyred very dense, almost impenetrable,clear.]?
S: Il colore e` un rosso rubino vivo quasi impen-etrabile.
[Lit: The color is a bright red rubyalmost impenetrable.
]Reordering: the two sentences contain a differ-ent word order both at single word (e.g.
subject inpre- vs. post-verbal position) and phrase level (e.ga subordinate clause proceeds vs. follows the mainclause):?
C: Ringraziandola per la sua cortese atten-zione, resto in attesa di risposta.
[Lit: Thank-ing you for your kind attention, I look forwardto your answer.]?
S: Resto in attesa di una risposta e ringraziovivamente per l?attenzione.
[Lit: I look forwardto your answer and I thank you greatly for yourattention.
]Insertion: the second sentence contains one or n-words more than the first one:?
C: In attesa di un sollecito riscontro, distintisaluti.
[Lit: Waiting for an early reply, yoursfaithfully.]?
S: In attesa di un riscontro porgiamo distintisaluti.
[Lit: Waiting for a reply, we offer ourregards.
]Sentence Type: the two sentences differ with re-spect to their form (i.e.
affirmative vs. interroga-tive):?
C: Quale consiglio darebbe ai genitori?
[Lit:Which advice would you give to parents?]?
S: Diamo un consiglio ai genitori.
[Lit: Let?sgive an advice to parents.
]For each operation there can be different degreesof sentence transformation.
For example, focusingon Verbal Feature, the example reported above rep-resents a ?light?
transformation while a ?stronger?transformation can occur when the verb changesfrom the conditional to the indicative mood (or viceversa), as in the following pair:?
C: Sarebbe un grave un errore.
[Lit: It wouldbe a serious error.]?
S: Ma e` un grave errore.
[Lit: But it is a seriouserror.
]Figure 4 reports the distribution of these sentenceoperations in the manually revised portion of thecorpus.
The distribution in All cosines shows that thetwo most frequent operations are deletion (30.74%)and changes affecting verbal features (26.30%).
Ac-cording to the literature, the deletion of redundantinformation (e.g.
adjectives, adverbs) is one ofthe main phenomena typically related to reductionof complexity.
Also transformations of verbal fea-tures are likely to intercept simplification operationsin a language like Italian with a rich inflectionalparadigm.
The third most frequent operation is lexi-cal substitution (15.52%).
According to the POS fil-ter used in the unsupervised step of sentence align-ment, this operation affects morpho?syntactic cate-gories such as e.g.
adverbs, adjectives, conjunctionsor prepositions which are substituted with a sim-pler synonym.
Reordering and insertion of wordsor phrases are respectively the fourth and the fifthtypes of transformation.
Reordering can be ex-pected as a simplification strategy especially whenit yields a more canonical word order.
The dis-tribution of reordering here reported, i.e.
14.24%,357Figure 4: Distribution of sentence operations at different cosineranges.is quite high if compared to the distribution of thesame operation found in hand-crafted simplified cor-pora where it represents about 8% of sentence oper-ations (Brunato et al, 2015).
This result gives ev-idence that our approach succeeds in automaticallyintercepting this kind of syntactic transformation.
Inthe manually revised portion of PaCCSS?IT inser-tion represents 12.72% of the whole operations.
De-spite inserting words or phrases could make morecomplex a sentence, this operation is used in thesimplification process e.g.
when it makes explicitmissing arguments in elliptical clauses more fre-quently used in non?standard language varieties orsublanguages such as legal language.
This is thecase of the heterogeneous nature of the corpus fromwhich PaCCSS?IT derives, where documents char-acterized by non?canonical languages (e.g.
blogs,e?mails) or domain?specific documents (e.g.
ad-ministrative acts) are mixed to texts representativeof more standard varieties, e.g.
newspapers, novels.Let us consider the relation between simplifica-tion operations, cosine values and readability levels.For what concerns the distribution of the operationsat different cosines (Figure 4), we observe that dele-tion is the most frequent operation at all cosines,in particular at lower cosines i.e.
<.70.
At highcosines, i.e.
>.90, operations affecting word orderand verbal features increase.
The relation betweenreadability score and sentence operations is shownin Figure 5.
Specifically, we calculated how the dis-tribution of operations changes with increasing dif-ferences between the readability score assigned tothe complex and the simple sentence of each pair.Although it is difficult to study the effect of each sin-Figure 5: Distribution of sentence operations at different read-ability scores.gle operation on the readability score variation sincethese operations are usually applied in combination,we observe some clear tendencies.
In particular,operations concerning deletion and verbal featuresare the most frequent ones both at lower and higherreadability scores differences.
However, they havean opposite distribution: transformations of verbalfeatures increase at higher readability differences(>0.6) while deletions decrease.
For what concernsthe other operations, the trend is quite homogeneousalong with the different readability scores.
In par-ticular, this is the case of reordering thus showingthe proposed approach is able to intercept syntactictransformations which impact at different readabil-ity variations.4.2.2 Analysis of Linguistic PhenomenaThe second qualitative analysis focused on thewhole resource which was searched for linguisticphenomena correlating with the process of sentencealignment.
To this end, we compared the distribu-tion of a set of different linguistic features, i.e.
rawtext, lexical, morpho?syntactic and syntactic, auto-matically extracted from the set of complex and sim-ple sentences of PaCCSS?IT, which was previouslytagged and dependency?parsed.
In Table 2 we reporta selection of the features with a statistically signifi-cant variation5 between the complex and the simplesentences.
As expected, the average sentence length(feature [1]) of the Simple sentence is lower thanthe Complex one.
The higher distribution of adjec-tives [2], adverbs [3] and determiners [4] might be5Wilcoxon?s signed rank test was used to evaluate statisticalsignificance.358related to the insertion of simple lexicon belongingto the Basic Italian Vocabulary (De Mauro, 2000).The distribution of verbal moods is also significantlycorrelated to a higher readability level: simple sen-tences have a higher percentage of indicatives [6] (asimple mood indicating a state of being or reality)and less participles [7] and gerundives [8] which arenon finite moods and thus can be more ambiguouswith respect to the reference.
In addition, sentencesclassified as complex have higher parse trees [13],longer dependency links [14] and longer embeddedcomplement chains modifying a noun [15], all fea-tures correlated with syntactic complexity (Gibson,1998; Lin, 1986; Frazier, 1985).
On the contrary,sentences classified as simple are characterised by amore canonical word order (Subject?Verb?Object inItalian) i.e.
a lower distribution of post-verbal sub-jects [16] and of pre-verbal objects [17].
These sen-tences also contain a higher distribution of subordi-nate clauses following the main clause [18], an ordereasier to process.Since syntactic features intercepting the structureof the sentence (e.g.
parse tree depth and depen-dency length) heavily depend on the overall sentencelength, we carried out an analysis only on pairs ofsentences where the complex and the simple sen-tence have the same number of tokens (i.e.
15,958pairs in PaCCSS?IT) and we compared how linguis-tic features vary between the complex and the sim-ple sentences of these pairs.
We observed that sim-ple sentences have a more canonical position of thesubject (i.e.
a lower percentage distribution of post-verbal subjects: C: 18.14%, S: 15.72%) and of theobject (i.e.
a lower percentage distribution of pre-verbal objects: C: 1.52%, S: 1.18%).
Simple sen-tences have also lower parsed trees (C: 2.42, S: 2.37)and shorter embedded complement chains modify-ing a noun (C: 0.27, S: 0.26).
Since these variationscannot be due to sentence shortening, they rather fol-low from reordering phenomena e.g.
changing fromactive to passive voice.The distribution of linguistic features here re-ported has already been observed in hand?craftedcorpora of complex and simple sentences for Italian(Brunato et al, 2015).
This is a further evidence ofthe reliability of our method for automatically creat-ing corpora of complex?simple sentences.Feature Complex Simple Variation[1] 8.98 7.80 0.97[2] 4.10 7.90 -3.80[3] 9.10 10.0 -0.85[4] 0.34 1.43 -1.10[5] 10.70 20.30 -9.61[6] 5.20 2.72 2.49[7] 0.47 0.04 0.42[8] 2.89 4.29 -1.40[9] 79.18 80.91 -1.73[10] 1.33 1.57 -0.24[11] 2.03 2.14 -0.10[12] 8.35 7.33 0.5[13] 2.88 2.70 0.18[14] 1.76 1.63 0.12[15] 0.44 0.41 0.02[16] 15.37 14.37 1.00[17] 2.03 1.38 0.65[18] 3.29 4.17 -0.90Table 2: Distribution of a subset of linguistic features with sta-tistically significant variation between the complex and simplesentences.
Features [1],[13],[14],[15] are absolute values, theothers are percentage distributions.
All differences are signifi-cant at p <0.001.5 ConclusionIn this paper we have presented PaCCSS?IT, a cor-pus of complex?simple aligned sentences for Italiancontaining?63,000 paired sentences.
To our knowl-edge, PaCCSS?IT is the biggest corpus of complex?simple aligned sentences, with the exception of En-glish.
It resulted from a new method for automat-ically acquiring corpora of parallel sentences ableto capture structural transformations and particularlysuitable for text simplification systems.
A compara-tive analysis of the multi?level linguistic features inthe complex and simple sentences showed that thismethod intercepts linguistic phenomena character-ising simplification operations previously observedin manually?created complex?simple corpora.
Amain novelty of the proposed approach is that it doesnot rely on a large pre-existing corpus of alignedcomplex?simple documents like e.g.
the English andSimple English Wikipedia.
This makes it very ap-propriate for less?resourced languages.
In addition,since the method does not need parallel corpora, thedimension of the web is the only limitation to thesize of the corpus that could be created.359ReferencesGiuseppe Attardi, Felice Dell?Orletta, Maria Simi, andJoseph Turian.
2009.
Accurate dependency parsingwith a stacked multilayer perceptron.
Proceedings ofthe 2nd Workshop of Evalita 2009 - Evaluation of NLPand Speech Tools for Italian, Reggio Emilia, Italy.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta.
2009.
The WaCky wide web: Acollection of very large linguistically processed web-crawled corpora.
Language Resources and Evalua-tion, 43(3):209?226.Regina Barzilay and Noemi Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing.Regina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: an unsupervised approach using multiple-sequence alignment.
Proceedings of the Conferenceof the North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies.Wauter Bosma and Chris Callison-Burch.
2007.
Para-phrase substitution for recognizing textual entailment.Proceedings of the 7th International Conference onCross-Language Evaluation Forum (CLEF).Stefan Bott and Horacio Saggion.
2011.
An unsuper-vised alignment algorithm for text simplification cor-pus construction.
Proceedings of the Workshop onMonolingual Text-To-Text Generation, co-located withACL 2011, Porland, Oregon.Stefan Bott and Horacio Saggion.
2014.
Text simplifica-tion resources for Spanish.
Language Resources andEvaluation, 48(1):93?120.Laetitia Brouwers, Delphine Bernhard, Anne-LaureLigozat, and Thomas Franc?ois.
2014.
Syntactic sen-tence simplification for French.
Proceedings of the 3rdWorkshop on Predicting and Improving Text Readabil-ity for Target Reader Populations (PITR).Dominique Brunato, Felice Dell?Orletta, Giulia Venturi,and Simonetta Montemagni.
2015.
Design and anno-tation of the first Italian corpus for text simplification.Proceedings of the 9th Linguistic Annotation Work-shop (LAW?15), Denver, Colorado, USA.Helena M. Caseli, Tiago F. P. Pereira, Lucia Specia,Thiago A. S. Pardo, Caroline Gasperin, and SandraAlu??sio.
2009.
Building a Brazilian Portuguese paral-lel corpus of original and simplified texts.
Proceedingsof the 10th Conference on Intelligent Text Processingand Computational Linguistics.Chih-Chung Chang and Chih-Jen Lin.
2001.
LIBSVM:a library for support vector machines.
Software avail-able at http://www.csie.ntu.edu.tw/?cjlin/libsvm.David L. Chen and William B. Dolan.
2011.
Collectinghighly parallel data for paraphrase evaluation.
Pro-ceedings of the Annual Meetings of the Association forComputational Linguistics (ACL).Do Kook Choe and David McClosky.
2015.
Parsingparaphrases with joint inference.
Proceedings of the53rd Annual Meeting of the Association for Computa-tional Linguistics and the 7th International Joint Con-ference on Natural Language Processing.William Coster and David Kauchak.
2011.
Simple en-glish wikipedia: a new text simplification task.
Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Linguis-tics: Human Language Technologies.Tullio De Mauro.
2000.
Il dizionario della lingua ital-iana.Felice Dell?Orletta, Simonetta Montemagni, and GiuliaVenturi.
2011.
READ?IT: assessing readability ofitalian texts with a view to text simplification.
Pro-ceedings of the Second Workshop on Speech and Lan-guage Processing for Assistive Technologies (SLPAT),Edinburgh, UK.Felice Dell?Orletta.
2009.
Ensemble system for Part-of-Speech tagging.
Proceedings of Evalita?09, Eval-uation of NLP and Speech Tools for Italian, ReggioEmilia, December.William Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.Proceedings of the 20th International Conference onComputational Linguistics, Geneva, Switzerland.Anthony Fader, Luke Zettlemoyer, and Oren Etzioni.2013.
Paraphrase-driven learning for open questionanswering.
Proceedings of the Annual Meetings of theAssociation for Computational Linguistics (ACL).Lyn Frazier.
1985.
Syntactic complexity.
Natural Lan-guage Parsing.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
PPDB: The paraphrasedatabase.
Proceedings of the Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies.Edward Gibson.
1998.
Linguistic complexity: Localityof syntactic dependencies.
Cognition, 68(1):1?76.Sigrid Klerke and Anders S?gaard.
2012.
DSim, a Dan-ish parallel corpus for text simplification.
Proceed-ings of Language Resources and Evaluation Confer-ence (LREC).Nikolina Koleva, Andrea Horbach, Alexis Palmer, SimonOstermann, and Manfred Pinkal.
2014.
Paraphrasedetection for short answer scoring.
Proceedings ofthe third workshop on NLP for computer-assisted lan-guage learning.360Dekan Lin.
1986.
On the structural complexity of naturallanguage sentences.
Proceedings of COLING 1996.Verena Lyding, Egon Stemle, Claudia Borghetti,Marco Brunello, Sara Castagnoli, Felice Dell?Orletta,Dittmann Henrik, Alessandro Lenci, and Vito Pirrelli.2014.
The PAISA corpus of Italian web texts.
Pro-ceedings of the 9th Web as Corpus Workshop (WAC-9)EACL.Yuval Marton, Chris Callison-Burch, and Philip Resnik.2009.
Improved statistical machine translation usingmonolingually-derived paraphrases.
Proceedings ofthe 2009 Conference on Empirical Methods in Natu-ral Language Processing.Rani Nelken and Stuart M. Shieber.
2006.
Towards ro-bust context-sensitive sentence alignment for monolin-gual corpora.
Proceedings of the 11th Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL-06), 3?7 April.Advaith Siddharthan and Mandya Angrosh.
2014.
Hy-brid text simplification using synchronous dependencygrammars with hand-written and automatically har-vested rules.
Proceedings of the 14th Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL 2014).Sowmya Vajjala and Detmar Meurers.
2016.Readability-based sentence ranking for evaluat-ing text simplification.
arXiv.Kristian Woodsend and Mirella Lapata.
2011.
Learningto simplify sentences with quasi-synchronous gram-mar and integer programming.
Proceedings of the2011 Conference on Empirical Methods in NaturalLanguage Processing.Sander Wubben, Antal van den Bosch, and Emiel Krah-mer.
2012.
Sentence simplification by monolingualmachine translation.
Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics.Wei Xu, Chris Callison-Burch, and Courtney Napoles.2015.
Problems in current text simplification research:New data can help.
Transactions of the Association forComputational Linguistics, 3.Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation model forsentence simplification.
Proceedings of the 23rd inter-national conference on computational linguistics.361
