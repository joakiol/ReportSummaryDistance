Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 193?201,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsExploiting multiple hypotheses for Multilingual Spoken LanguageUnderstandingMarcos Calvo, Fernando Garc?
?a, Llu??s-F.
Hurtado, Santiago Jime?nez, Emilio SanchisDepartament de Sistemes Informa`tics i Computacio?Universitat Polite`cnica de Vale`ncia, Vale`ncia, Spain{mcalvo,fgarcia,lhurtado,sjimenez,esanchis}@dsic.upv.esAbstractIn this work, we present an approach formultilingual portability of Spoken Lan-guage Understanding systems.
The goalof this approach is to avoid the effort of ac-quiring and labeling new corpora to learnmodels when changing the language.
Thework presented in this paper is focused onthe learning of a specific translator for thetask and the mechanism of transmitting theinformation among the modules by meansof graphs.
These graphs represent a set ofhypotheses (a language) that is the inputto the statistical semantic decoder that pro-vides the meaning of the sentence.
Someexperiments in a Spanish task evaluatedwith input French utterances and text arepresented.
They show the good behaviorof the system, mainly when speech inputis considered.1 IntroductionSpoken Language Understanding (SLU) is one ofthe key modules in many voice-driven human-computer interaction systems.
Many successfulSLU systems that have been developed in the lastfew years are based on statistical models automat-ically learned from semantically labeled corpora(Maynard and Lefe`vre, 2001; Segarra et al 2002;He and Young, 2006; Lefe`vre, 2007; De Mori etal., 2008).
One of the advantages of statisticalmodels is the capability of representing the vari-ability of lexical realizations of concepts (mean-ings).
On the other hand, they are usually plainmodels, that is, they can not represent a hierarchi-cal semantic dependency, although there are someworks in this area (He and Young, 2003).
How-ever, this is not a problem in most Spoken DialogSystems since the semantic information to be ex-tracted is not very hierarchically structured.Another important aspect of these models is thatthey can be learned from corpora.
The corporaused for training must be large enough to allowan accurate estimation of the probabilities, and itmust represent the lexical and syntactic variabil-ity that is used in the language to express the se-mantics as much as possible.
Although there aresome approaches based on semi-supervised or un-supervised learning (Tu?r et al 2005; Riccardi andHakkani-Tu?r, 2005; Ortega et al 2010), the mostcommon approaches need to have a segmentedand labeled training corpus.
This is the case ofdiscriminative models (like Conditional RandomFields (Hahn et al 2010)), and generative models(such as Hidden Markov Models and StochasticFinite State Automata (Segarra et al 2002; Hahnet al 2010)).
In the case of supervised learn-ing, it is necessary to define a set of concepts thatrepresent the semantic domain of the task and toassociate these concepts to the corresponding se-quences of words in the sentences.
This is the caseof the French MEDIA corpus (Bonneau-Maynardet al 2005), and the Spanish DIHANA corpus(Bened??
et al 2006).
Since the corpus acquisi-tion and labeling require a great manual effort, be-ing able to reuse the corpus generated for a taskto easily develop SLU systems for other tasks, orlanguages, is an important issue.This work focuses on the problem of SLU porta-bility between languages (Garc?
?a et al 2012; Heet al 2013; Jabaian et al 2013).
We propose asemi-supervised approach for adapting the systemto tackle sentences that are uttered in a new lan-guage.
In order to learn a domain-specific transla-tion model, a parallel corpus is automatically gen-erated from the training set by using web transla-tors.
Due to the fact that the speech recognitionand the translation phases can generate many er-rors, a mechanism to obtain the correct meaningdespite these errors is needed.
This can be per-formed by supplying many hypotheses between193the different stages, either as a set of n sentencesor as a graph that represents not only the originalsentences but also an adequate generalization ofthem.
This graph can be obtained from a Gram-matical Inference process.
We have also devel-oped a specific algorithm to perform the semanticdecoding by taking graphs of words as the inputand considering statistical semantic models.
Wehave applied these techniques for the DIHANAcorpus, which is a task to access the informationof train timetables and fares in Spanish by phone.This corpus was originally generated in Spanish,and we have evaluated our system by using inputsentences in French.2 Description of the systemOne way of solving the SLU problem is to find thesequence of concepts C?
that best fits the seman-tics contained in an utterance A.
Considering astochastic modelization, it can be stated as:C?
= argmaxCp(C|A) (1)In the case of Multilingual SLU, the user uttersa sentence in a source language s, which is dif-ferent to the language t of the original data of theSLU task.
Thus, either the uttered sentence or thetraining data (or maybe both) should be translatedinto a common language in order to be able to ap-ply the semantic decoding process to the input ut-terance.
In our case, we recognize the input ut-terance by using an Automatic Speech Recognizer(ASR) in the source language, and we then trans-late the hypotheses provided by the ASR into thetarget language t by means of a statistical MachineTranslation system (see Figure 1).
Consequently,by considering both the input sentence Ws utteredby the user and its translation into the target lan-guage Wt, Equation (1) can be rewritten as:C?
= argmaxCmaxWs,Wtp(C,Ws,Wt|A) (2)Equation (2) can be decomposed into severalfactors, as shown in Equation (3).
This is achievedby applying the Bayes?
Rule and making somereasonable assumptions about the independence ofthe variables.C?
= argmaxCmaxWs,Wtp(A|Ws) ?
p(Ws|Wt) ?
p(Wt|C) ?
p(C)p(A)(3)To perform this maximization, we propose a de-coupled architecture, which sequentially appliesall the knowledge sources.
One of the most impor-tant drawbacks of decoupled architectures is thatthe errors generated in one stage can not be recov-ered in following phases.
To overcome this prob-lem, we propose an architecture in which the com-munication between the modules is done by meansof structures that provide more than one hypothe-sis, like n-best and graphs of words.
A scheme ofthis architecture is shown in Figure 1.
Its modulesare the following:1.
First, the input utterance is processed by anASR in the source language, providing as itsoutput either the 1-best or a set of n-best tran-scriptions.
We have used a general purpose,freely available web ASR, which means thatthe ASR has no specific information aboutthe task.2.
These transcriptions are translated into thetarget language by means of a state-of-the-art Machine Translation system: MOSES(Koehn et al 2007).
The translation mod-els have been trained without using any man-ually generated data.
Instead, a set of freelyavailable web translators was used to trans-late the training sentences of the corpus fromthe target language (the original language ofthe corpus sentences) into the source lan-guage (the language of the speaker), therebybuilding a parallel training corpus.
MOSESprovides as its output a set of candidate trans-lations (n-best) of the transcriptions suppliedby the ASR.3.
A graph of words is built from the n-bestprovided by the translator.
This graph isbuilt through a Grammatical Inference pro-cess.
This way the graph not only representsthe translations, but also a reasonable gener-alization of them.
This makes it possible forthe semantic decoder to consider some sen-tences that were not in the initial set but thatare made of pieces of those sentences.4.
This graph of words is processed by a SLUmodule that is able to tackle graphs.
The se-mantic model for this stage has been learnedusing only the training data in the target lan-guage.
As an intermediate result, this processbuilds a graph of concepts, which is a com-pact representation of all the possible seman-tics contained in the language represented by194Speech TranslationTESTTRAININGSLUSLUStage 1SLUStage 2Graph of Conceptsw1  ...wi:Concept1wi+1...wj:Concept2...wm+1...wn:ConceptkGraph of WordsGraph ofWordsBuilderFrameConverterFRAME_NAMEslot1:value1slot2:value2...slotm:valuemASR StatisticalTranslator1-best/n-best1-best/n-bestSpanishDIHANACorpus(TrainingSet)TranslationModelTranslationModel Learning(MOSES)SemanticModelLearningWebTranslatorsSemanticModelFigure 1: Scheme of the decoupled architecture.the graph of words.
The output of this mod-ule is the best sequence of concepts C?
andalso its underlying sequence of words W?t inthe target language and a segmentation of W?taccording to C?.5.
Finally, the segmentation obtained in the pre-vious step is processed in order to convertit into a frame representation.
This involvesextracting the relevant information from thesegmentation and representing it in a canoni-cal way.Assuming that all the translations Wt that be-long to the language represented by the graph ofwords are a priori equiprobable in the target lan-guage, we can rewrite Equation (3) as follows:C?
= argmaxCmaxWs,Wtp(A|Ws) ?
p(Ws) ?
p(Wt|Ws) ?
p(Wt|C) ?
p(C)p(A)(4)The first three modules of the architecture canbe viewed as a speech translation process, wherethe input is an utterance and the output is a set ofpossible translations of this utterance, representedas a graph of words.
Each one of these translationsis weighted with the probability p(Wt|A).
Consid-ering thatp(Wt|A) ?
maxWsp(A|Ws) ?
p(Ws) ?
p(Wt|Ws)p(A)it stands that Equation (4) can be rewritten as:C?
= argmaxCmaxWtp(Wt|A) ?p(Wt|C) ?p(C) (5)The fact that the communication between thedifferent modules is a set of hypotheses makes itpossible to apply the different constraints (acous-tic, lexical, syntactic, and semantic) in a globalway, while the modular architecture allows localpruning taking into account only a subset of theknowledge sources.
This way each of the modulescontributes to the computation of the global max-imization, but it is not completely performed untilthe end of the process.3 Learning of the translation modelIt has been shown that statistical models achievegood performance in speech translation tasks(Mathias and Byrne, 2006).
Also, they have theadvantage that they can be adapted to a specifictask, as long as a large enough amount of paral-lel training data is available in order to adequatelytrain the parameters of the Machine Translationsystem.
However, obtaining this task-specifictraining data by translating the original data byhand is very expensive and time-consuming.
Asolution to this problem is to use several general-purpose web translators (which are available on195the Internet) to automatically translate the task-specific training sentences into another language.Although these translators can generate many er-rors, they are an interesting way to obtain severalhypotheses for a translation without much effort.However, the use of these translators at testingtime is not very convenient due to the fact that thesystem would depend on the Internet connectionand the reaction time of the corresponding webpages.
Another drawback is that it is impossibleto adapt them to a specific task, which could gen-erate many errors that are important to the task.The approach that we propose attempts to takeadvantage of these resources, but for training pur-poses.
In other words, given the training sentencesin Spanish, they are translated into a new language(French in this case) by using several web transla-tors.
This way we build a parallel corpus whereeach sentence has different translations associatedto it.
From this parallel corpus, we train a statisti-cal translator that is specific for the task.
It shouldbe noted that by means of this process, the learnedtranslator can represent and modelize the variabil-ity generated by the different translators.
How-ever, due to the difficulty of the problem, this mod-elization may not be enough.
Therefore we can notguarantee that the best translation obtained by themodel is consistent with the meaning of the origi-nal sentence.
This is why it is convenient to supplymore than one hypothesis to the semantic decod-ing module in order to have the possibility of find-ing the correct semantic meaning even when someerrors were generated in the recognition and trans-lation processes.
We think that separately process-ing the n-best translated sentences (for each inputsentence) generated by the translator is not the bestsolution.
In contrast, it would be better to ade-quately combine segments of different sentences.Thus, we have developed a Grammatical Inferencemechanism to build a graph of words from a set ofhypotheses as described in the following section.4 Generating the graphs of wordsIn this section, the process of obtaining the graphsof words in the target language from multipletranslation hypotheses is explained.
This processis divided into two steps:1.
The translation hypotheses are aligned usinga Multiple Sequence Alignment (MSA) algo-rithm.
The result of the MSA process is analignment matrix.2.
The aligned sentences, represented by thealignment matrix, are used to obtain aweighted graph of words that will be the in-put to the graph-based SLU module.A Multiple Sequence Alignment is a process ofsequence alignment that involves more than twosequences.
It takes a set of sequences of symbols(in our case, sequences of words) and provides thealignment of the elements of the set that minimizesthe number of edit operations (substitutions, in-sertions, and deletions) among all the symbols ofthe sequences.
In this work, a modification of theClustalW (Larkin et al 2007) Multiple SequenceAlignment software has been used.The result of the MSA process is an alignmentmatrix.
Each row in this matrix represents a differ-ent aligned sentence, and each column representsthe alignment of each symbol.
The total numberof columns is usually greater than the length ofthe longest sequence, since not all the symbols canbe aligned.
The special symbol ?-?
is used to rep-resent the positions of non-alignment points in asentence.A weighted directed acyclic graph of wordsis created from the MSA alignment matrix, Thegraph construction consists of creating as manynodes as columns in the alignment matrix plus onefor the final state and as many arcs as cells in thematrix that contain a symbol different to ?-?.
Thearcs with the same source, destination, and symbolare joined, and the weights are obtained by nor-malizing these counters (Calvo et al 2012).Figure 2 shows a real example (extracted fromthe test set) of the full process of obtaining thegraph of words.
As the figure shows, the obtainedgraph of words (where the arcs are labeled withwords and weighted with the normalized coun-ters) represents a language which is a generaliza-tion of the individual translations of the originalutterance.
That is, this process is a Grammati-cal Inference mechanism that represents sentenceswith characteristics that are similar to those usedto build the graph.
A full path from the initialnode to the final node in the graph may be seenas an alternative translation of the original utter-ance.
For example, the correct translation of theutterance ?el precio del billete del tren de las seistreinta y cinco?
was not among the candidates pro-vided, but it can be recovered using this algorithm.This graph builder module completes the se-quence of modules that perform the speech trans-196source le prix du billet de train de six heures trente-cinqutterance (the price of the train ticket for six thirty-five)(el precio del billete del tren de las seis treinta y cinco)le prix du billet train de sezer trente-cinqmultiple ASR le prix du billet train de six vers trente-cinqoutputs le prix du billet train de six onze trente-cinqle prix du billet train des six heures trente cinqel precio del billete de tren de sezer treinta y cincomultiple el precio del billete de tren alrededor de las seis treinta y cincotranslations el precio del billete del tren de las seis once y treinta y cincoel precio del billete de tren de las seis treinta de las cinco de la tardeel precio del billete de tren - de sezer treinta - - - y cinco - - -alignment el precio del billete de tren alrededor de las seis treinta - - y cinco - - -matrix el precio del billete del tren - de las seis once y treinta y cinco - - -el precio del billete de tren - de las seis treinta - de las cinco de la tarde0 1el(1.00) 2precio(1.00) 3del(1.00) 4billete(1.00) 5de(0.75)del(0.25) 6tren(1.00) 7alrededor(0.25) 8de(0.75) de(1.00) 9las(0.75)sezer(0.25) 10seis(0.75)treinta(0.25) 11once(0.25)treinta(0.50) 14y(0.25)12y(0.33) 13de(0.33) y(0.33)treinta(1.00) las(0.50)y(0.50) 15cinco(0.25) 18cinco(0.75)16de(1.00) 17la(1.00) tarde(1.00)Figure 2: Steps for obtaining the graph of words from the original utterance le prix du billet de train desix heures trente-cinq, (the price of the train ticket for six thirty-five).lation process.
This process takes as its inputan utterance and outputs a weighted graph ofwords, which represents the probability distribu-tion p(Wt|A).
In other words, each full path inthe graph of words (from the initial to the endingnode) is a candidate translation of the input utter-ance, and is weighted with the probability of thetranslation given the utterance.5 Performing the semantic decodingOur semantic decoding process is based on theidea of finding segments of words contained inthe graph of words that are relevant to each of theconcepts of the task.
In order to compactly repre-sent this set of segments and the concepts they arerelevant to, a second graph is created, which wehave called a graph of concepts.
This graph hasthe same set of nodes as the graph of words, buteach arc represents that there is a path in the graphof words between the initial and ending node ofthe arc, which induces a sequence of words that isrelevant to some of the concepts of the task.
Thus,each of these arcs is labeled with the correspond-ing sequence of words and the concept they repre-sent.
To assign a proper weight to the arcs, boththe weights represented in the graph of words andthe semantic model are considered.
As the set ofnodes is the same as in the graph of words, wewill say that for every two nodes i, j, it stands thati < j if i comes before j in the topological or-der of the nodes in the graph of words (there isa topological order because the graph of words isdirected and acyclic).As stated in Equation (5), one of the importantfactors in this approach is the probability of thesequence of words in the target language giventhe sequence of concepts p(Wt|C).
This proba-bility can be decomposed as the product of theprobabilities assigned by each concept of the se-quence of concepts C to the segment of words thatis attached to it; that is,?
?ck?C p(Wtk |ck), whereWtk is the sequence of words corresponding tothe concept ck in the segmentation.
To computethese probabilities, our semantic model includesa set of bigram Language Models (LMs), one foreach concept in the task, which provide the prob-ability of any sequence of words given the con-cept.
To train these LMs, the training sentencesof the corpus in the target language must be seg-mented and labeled in terms of the concepts ofthe task.
The consequence of defining the seman-tic model this way is that every arc from node ito node j in the graph of concepts represents theprobability p(W i,jt |A)?p(W i,jt |c), where W i,jt andc are the sequence of words and the concept at-tached to the arc, respectively.
Furthermore, eachfull path (from the initial to the ending node) inthe graph of concepts represents the probability197p(Wt|A) ?
p(Wt|C), for the sequence of conceptsC and the sentence Wt induced by the path.The set of arcs of the graph of concepts can bebuilt by means of a Dynamic Programming (DP)algorithm that finds the sequence of words thatmaximizes the combined probability stated above,for each pair of nodes i, j and each concept c.Only the arc that represents the sequence of wordsof maximum probability is needed because this in-formation will afterwards be combined with theprobability of the sequence of concepts to find thepath of maximum probability (see Equation (5)),and if there are many arcs between nodes i and jcorresponding to the concept c only the one withmaximum probability will be considered.
This al-lows us to prune the arcs of the graph of conceptswithout any loss of information.
For the DP al-gorithm, we will consider a representation of theLM corresponding to each concept as a StochasticFinite State Automaton (SFSA).
Then, in the DPprocess, for each concept c we will obtain the bestpath from node i to node j in the graph of wordssuch that its underlying sequence of words arrivesto the state qc in the SFSA LMc (the LM of theconcept c).
This can be achieved by means of thefollowing algorithm:M(i, j, qc) =??????????
?1 if i = j ?
qc is the initial state of LMc0 if i = j ?
qc is not the initial state of LMc0 if j < imax?a?EGW :dest(a)=j?
(q?c,wd(a),qc)?LMcM(i, src(a), q?c) ?
p(q?c,wd(a), qc) ?
wt(a)otherwise(6)where dest(a) stands for the destination node ofthe arc a in the graph of words, src(a) refers to itssource node, and wd(a) and wt(a) refer to the wordand the weight attached to the arc, respectively.Also, (q?c,wd(a), qc) represents a transition fromthe state q?c to the state qc labeled with wd(a) inthe SFSA that represents LMc.It is worth noting that this process must be per-formed for each concept in the task.
Also, it is im-portant for the algorithm to keep track of the wordsthat constitute the paths that maximize the expres-sion for each cell.
When this matrix has beenfilled for a specific concept c, the cell that max-imizes M(i, j, qc) for each pair i and j becomesan arc in the graph of concepts between nodes iand j.
This arc is labeled with the sequence un-derlying the winning path and the concept c and isweighted with the score (probability) contained inM(i, j, qc).This process shapes the first stage of the SLUprocess, which provides the graph of concepts asa result.
Then, this graph of concepts is processedby a second stage.
This second stage finds the pathin the graph that maximizes the combination of itsprobability and the probability that a LM of bi-grams of concepts gives to the sequence of con-cepts underlying the path.
The LM of bigrams ofconcepts is also part of the semantic model, andto train it we take advantage of the segmentationand labeling in term of concepts provided by thetraining corpus.
Finding the best path this waycompletely fulfills what is stated in Equation (5).Also, this best path in the graph of concepts pro-vides the best sequence of concepts C?, the under-lying sequence of words W?t, and a segmentationof W?t according to C?.6 The DIHANA task and the semanticrepresentationThe DIHANA task consists of a telephone-basedinformation service for trains in Spanish.
A setof 900 dialogs was acquired by using the Wizardof Oz technique.
The number of user turns was6,280 and the vocabulary was 823.
As in manyother dialog systems (Minker, 1999), the semanticrepresentation chosen for the task is based on aframe representation.
Therefore, the final outputof the understanding process is one or more frameswith their corresponding attributes.Even though the frame representation is the out-put of the system, we propose an intermediate se-mantic labeling that consists of assigning conceptsto segments of the sentence in a sequential way.This is the output provided by the graph-basedSLU module.In order to represent the meaning of the utter-ances in terms of this intermediate semantic lan-guage, a set of 31 concepts was defined.
Someof them are: query, affirmation, origin city, andcourtesy.Each concept represents the meaning of words(or sequences of words) in the sentences.
For ex-ample, the semantic unit query can be associatedto ?can you tell me?, ?please tell me?, ?what is?,etc.
This way, each sentence (sequence of words)has a semantic sentence (sequence of concepts) as-sociated to it, and there is an inherent segmenta-tion.
The advantage of this kind of representationis that statistical models of the lexical realizationof concepts and the n-gram probabilities of the se-198Sentence hola buenos d?
?as quer?
?a saber los horarios de trenes para ir a Madrid(hello good morning I?d like to know the train timetables to go to Madrid)Semantic hola buenos d?
?as : courtesysegments quer?
?a saber : querylos horarios de trenes para ir : <time>a Madrid : destination cityFrame (TIME?
)DEST CITY : MadridTable 1: Example of the outputs of the SLU and Frame Converter modules.quences of semantic units can be learned.Finally, a set of rules are used to transduce thisintermediate representation into a frame.
Since theintermediate language is close to the frame repre-sentation, only a small set of rules are required tobuild the frame.
This phase consists of the fol-lowing: the deletion of irrelevant segments (suchas courtesies), the reordering of the relevant con-cepts and attributes that appeared in the segmenta-tion following an order which has been defined apriori, the automatic instantiation of certain task-dependent values, etc.Table 1 shows an example of the semantic rep-resentation in terms of the intermediate semanticsegmentation provided by the SLU module and thefinal frame representation.7 Experiments and resultsTo evaluate this architecture, we performed a setof experiments with the DIHANA corpus.
Theuser turns of the corpus were split into a set of4889 turns for training and 1227 turns for test.
Totrain the translation models, the training set wasautomatically translated from Spanish into Frenchby four freely available web translators (Apertium,Bing, Google, Lucy), which provided us a paralleltraining corpus.
The semantic model was learnedfrom the segmentation and labeling provided inthe DIHANA corpus for the training sentences inSpanish.
All the Language Models in the semanticmodel were bigram models trained using Witten-Bell smoothing.For evaluation purposes, all the test set wasmanually translated into French, and 500 turnswere uttered by four native French speakers.
Thus,we have carried out experiments both consideringas the input to our system the correct sentences inFrench (which is the same than assuming a perfectASR) and the utterances.
To recognize the utter-ances the Google ASR was used, which for thistest set provides a Word Error Rate of 21.9% con-sidering only the 1-best recognized sentence.For this experimentation we have consideredthree kinds of ASR outputs, namely, a Perfect ASR(text input), the 1-best output, and finally the n-best hypotheses (with n ranging from 1 to 20).Also, we have configured the system in two dif-ferent ways:?
Configuration 1: The output of the statisticaltranslation system are the n-best translationsfor the input.
Note that these n-best couldcontain repeated translations, which may leadto the reinforcement of some paths in thegraphs of words.?
Configuration 2: The output of the statisticaltranslation system is the set formed by thebest n different (unique) translations that itcan provide for the given input.When the output of the ASR are n-best, we haveonly considered the Configuration 1.We have evaluated each experiment using twomeasures: the Concept Error Rate (CER), whichcorresponds to errors in the output of the SLUmodule, and the Frame-Slot Error Rate (FSER),which corresponds to errors in the slots of theframes in the final output of the system.Figures 3, 4, and 5 show the results obtained foreach of the ASR outputs and configurations con-sidered.
The horizontal axis represents the numberof hypotheses provided by the statistical translator.As expected, in all the cases the FSER is lowerthan the CER, as some errors at level of the con-cept sequence are not relevant for the frame con-version (for example, courtesies).
In the case oftext input (Fig.
3), the best results are achievedwhen just one or two hypotheses are providedby the translator.
This is because the translationmodel has also been learned using correct sen-tences, which makes the translation system morerobust for this kind of input.
However, when con-sidering speech as input (Figs.
4 and 5), the gen-eralization provided by the graphs obtained usinga relatively large set of n-best translations leads to199a better behavior.
This is due to the fact that theerrors introduced by the recognition of the speechinput increases the errors in the translation stage.Thus, working with different alternatives makes itpossible to recover some of the errors.
Table 2shows the results obtained when optimizing theFSER, and the number of hypotheses n used tobuild the graphs that provide the best results.Figures 3 and 4 also show that the parametersthat optimize FSER and CER may not be the same.This behavior is due to the different nature of bothmeasures.
While CER is defined in terms of thesequence of concepts extracted by the SLU mod-ule, FSER only takes into account those segmentsthat have relevant information.It can be seen in Figures 3 and 4 that, for Con-figuration 2, when n takes the value 18, both errormeasures descend.
However, after this, the errorscontinue with their ascending tendency.
The rea-son for this is that with these parameters, the trans-lations provided by the translator generate a graphof words that allows the semantic model to betterrecover the semantics of the sentence.
However,this effect is spurious, as for higher values of n theerror measures present higher values.1520251  5  10  15  20errorn-bestCER-Text Config.
1FSER-Text Config.
1CER-Text Config.
2FSER-Text Config.
2Figure 3: Results obtained with the text input.ASR output Config.
CER FSER nText input Config.
1 21.50 14.03 2Config.
2 21.37 14.08 11-best Config.
1 24.27 19.11 3Config.
2 24.13 19.28 3n-best Config.
1 22.40 19.63 7Table 2: Results obtained optimizing the FSER.8 ConclusionsWe have presented an approach for developingmultilingual SLU systems without any manual ef-1520251  5  10  15  20errorn-bestCER-Voice (1-best) Config.
1FSER-Voice (1-best) Config.
1CER-Voice (1-best) Config.
2FSER-Voice (1-best) Config.
2Figure 4: Results obtained with the voice input,taking the 1-best from the ASR and the n-bestfrom MOSES.1520251  5  10  15  20errorn-bestCER-Voice (N-best) Config.
1FSER-Voice (N-best) Config.
1Figure 5: Results obtained with the voice input,taking the n-best from the ASR and the corre-sponding 1-best from MOSES.fort in the adaptation of the models.
It has beenshown that the use of graphs of words, as a mech-anism of generalization and transmission of hy-potheses, is a good approach to recover from er-rors generated in the different phases of the sys-tem.
As future work it may be interesting to ex-plore other Grammatical Inference techniques tocombine the n-best hypotheses generated by boththe ASR and the translator.
It would also be inter-esting to study the behavior of this approach withother languages that have greater differences thanSpanish and French, for example non-Latin lan-guages like English and German.AcknowledgementsThis work is partially supported by the SpanishMICINN under contract TIN2011-28169-C05-01,and under FPU Grant AP2010-4193.200ReferencesJose?-Miguel Bened?
?, Eduardo Lleida, Amparo Varona,Mar??a-Jose?
Castro, Isabel Galiano, Raquel Justo,In?igo Lo?pez de Letona, and Antonio Miguel.
2006.Design and acquisition of a telephone spontaneousspeech dialogue corpus in Spanish: DIHANA.In Proceedings of LREC 2006, pages 1636?1639,Genoa (Italy).H.
Bonneau-Maynard, Sophie Rosset, C. Ayache,A.
Kuhn, and Djamel Mostefa.
2005.
Semantic an-notation of the French MEDIA dialog corpus.
InProc.
of InterSpeech 2005, pages 3457?3460, Portu-gal.Marcos Calvo, Llu?
?s-F Hurtado, Fernando Garc?
?a, andEmilio Sanchis.
2012.
A Multilingual SLU SystemBased on Semantic Decoding of Graphs of Words.In Advances in Speech and Language Technologiesfor Iberian Languages, pages 158?167.
Springer.R.
De Mori, F. Bechet, D. Hakkani-Tu?r, M. McTear,G.
Riccardi, and G. Tu?r.
2008.
Spoken languageunderstanding: A survey.
IEEE Signal Processingmagazine, 25(3):50?58.F.
Garc?
?a, L.-F. Hurtado, E. Segarra, E. Sanchis, andG.
Riccardi.
2012.
Combining multiple translationsystems for spoken language understanding porta-bility.
In Spoken Language Technology Workshop(SLT), 2012 IEEE, pages 194?198.
IEEE.S.
Hahn, M. Dinarelli, C. Raymond, F. Lefe`vre,P.
Lehnen, R. De Mori, A. Moschitti, H. Ney, andG.
Riccardi.
2010.
Comparing stochastic ap-proaches to spoken language understanding in multi-ple languages.
IEEE Transactions on Audio, Speech,and Language Processing, 6(99):1569?1583.Yulan He and S. Young.
2003.
Hidden vectorstate model for hierarchical semantic parsing.
InProceedings of IEEE International Conference onAcoustics, Speech, and Signal Processing (ICASSP?03), volume 1, pages 268?271.Yulan He and Steve Young.
2006.
Spoken languageunderstanding using the hidden vector state model.Speech Communication, 48:262?275.Xiaodong He, Li Deng, Dilek Hakkani-Tur, andGokhan Tur.
2013.
Multi-style adaptive training forrobust cross-lingual spoken language understanding.In Proc.
ICASSP.B.
Jabaian, L. Besacier, and F. Lefe`vre.
2013.Comparison and combination of lightly supervisedapproaches for language portability of a spokenlanguage understanding system.
Audio, Speech,and Language Processing, IEEE Transactions on,21(3):636?648.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,Moran C., R. Zens, C. Dyer, Bojar O., A. Con-stantin, and E. Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Pro-ceedings of Association for Computational Linguis-tics (ACL?07), pages 177?180.M.
A. Larkin, G. Blackshields, N. P. Brown,R.
Chenna, P. A. McGettigan, H. McWilliam,F.
Valentin, I. M. Wallace, A. Wilm, R. Lopez, J. D.Thompson, T. J. Gibson, and D. G. Higgins.
2007.ClustalW and ClustalX version 2.0.
Bioinformatics,23(21):2947?2948.F.
Lefe`vre.
2007.
Dynamic bayesian networks and dis-criminative classifiers for multi-stage semantic in-terpretation.
In Proceedings of IEEE InternationalConference on Acoustics, Speech and Signal Pro-cessing (ICASSP?07), volume 4, pages 13?16.
IEEE.Lambert Mathias and William Byrne.
2006.
Statis-tical phrase-based speech translation.
In Proceed-ings of IEEE International Conference on Acoustics,Speech, and Signal Processing (ICASSP?06), vol-ume 1, pages 561?564.
IEEE.H.
Bonneau Maynard and F. Lefe`vre.
2001.
Investi-gating Stochastic Speech Understanding.
In Proc.of IEEE Automatic Speech Recognition and Under-standing Workshop (ASRU?01).W.
Minker.
1999.
Stocastically-based semantic analy-sis.
In Kluwer Academic Publishers, Boston, USA.Luc?
?a Ortega, Isabel Galiano, Llu??s-F.
Hurtado, EmilioSanchis, and Encarna Segarra.
2010.
A statisticalsegment-based approach for spoken language under-standing.
In Proc.
of InterSpeech 2010, pages 1836?1839, Makuhari, Chiba, Japan.G.
Riccardi and D. Hakkani-Tu?r.
2005.
Active learn-ing: theory and applications to automatic speechrecognition.
IEEE Transactions on Speech and Au-dio Processing, 13(4):504 ?
511.E.
Segarra, E. Sanchis, M. Galiano, F.
Garc?
?a, andL.
Hurtado.
2002.
Extracting Semantic InformationThrough Automatic Learning Techniques.
IJPRAI,16(3):301?307.Gokhan Tu?r, Dilek Hakkani-Tu?r, and Robert E.Schapire.
2005.
Combining active and semi-supervised learning for spoken language under-standing.
In Speech Communication, volume 45,pages 171?186.201
