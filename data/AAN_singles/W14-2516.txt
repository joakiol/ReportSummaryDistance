Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 56?60,Baltimore, Maryland, USA, June 26, 2014.c?2014 Association for Computational LinguisticsPredicting Party Affiliations from European Parliament DebatesBj?rn H?ylandDepartment of Political ScienceUniversity of Oslobjorn.hoyland@stv.uio.noJean-Franc?ois GodboutDepartment of Political ScienceUniversity of Montrealgodboutj@umontreal.caEmanuele LapponiDepartment of InformaticsUniversity of Osloemanuel@ifi.uio.noErik VelldalDepartment of InformaticsUniversity of Osloerikve@ifi.uio.noAbstractThis paper documents an ongoing effortto assess whether party group affiliationof participants in European Parliament de-bates can be automatically predicted onthe basis of the content of their speeches,using a support vector machine multi-classmodel.
The work represents a joint effortbetween researchers within Political Sci-ence and Language Technology.1 IntroductionThe European Parliament (EP) is the directlyelected parliamentary institution of the EuropeanUnion (EU), elected once every five years by vot-ers from across all 28 member states.
An im-portant arena for the political activity in the EPis the plenary sittings, the forum where all (cur-rently 766) elected members of the European Par-liament (MEPs) from all member states participatein plenary debates (in all represented languages,simultaneously translated).
Our current work in-vestigates to what extent the party affiliation ofthe legislators in the plenary debates can be pre-dicted on the basis of their speeches.
More specif-ically, the goal is to predict the party affiliation ofplenary speakers in the 6thEuropean Parliament(July 2004 ?
July 2009) on the basis of the partyaffiliations of plenary speakers in the 5thEuro-pean Parliament (July 1999 ?
July 2004).1One1The data have been collected from the official website ofthe European Parliament, where verbatim reports from eachplenary sitting are published:www.europarl.europa.eu/plenary/en/debates.htmlpremise for the success of such an approach is thatdifferences in ideology and belief systems are re-flected in differences in choice of words in ple-nary debates.
Another premise is that a shared be-lief system translates to the same choice of partygroup.
As discussed below, systematic differencesin prediction performance in the data can be usedto reveal interesting differences in the extent towhich these premises hold for various subgroupsof MEPs.
While this is further discussed in Sec-tion 4, we first describe the data sets in some moredetail in Section 2 and present some preliminaryresults in Section 3.2 Data sets and experimental set-upThe debates from the 5thEP are used for train-ing an SVM(Cortes and Vapnik, 1995) multi-class classifier2which we then apply for predict-ing party affiliations in the 6thEP.
We do 5-foldcross validation experiments on the 5thterm formodel tuning.
Data points in the model cor-respond to speakers; participants in the debatesin the EP labeled with their political party.
Allrecorded speeches for a given speaker are con-flated in a single vector.
Although we can so faronly report results for models using fairly basicfeature types ?
various bag-of-words configura-tions based on lemmas, stems or full word-forms ?combined with more linguistically informed ones,2We use the freely available SVMmulticlasstoolkit, im-plementing the multi-class formulation of support vector ma-chines described by Crammer and Singer (2001) with veryfast optimization for linear kernels based on the algorithmfor estimating Structural SVMs described by Tsochantaridiset al.
(2004).
For more information see; www.cs.cornell.edu/people/tj/svm_light/svm_multiclass.html56Party MEPsPSE 211EPP-ED 272ELDR 65GUE/NGL 48V/ALE 55UEN 38Total 689Table 1: Distribution of members across the var-ious political parties in the training data from the5thEuropean Parliament plenary debates.like part-of-speech (PoS) tags and dependency re-lations; work is already in progress with respectto assessing the usefulness of e.g.
class-based fea-tures drawn from unsupervised word clusteringand modeling semantic phenomena such as nega-tion, speculation and sentiment.
Large-scale ex-perimentation with different features sets and hy-perparameters is made possible by running ex-periments on a large high-performance computing(HPC) cluster.The main political groups in the European Par-liament during these terms were the ChristianDemocratic / Conservative (EPP-ED), the Social-Democratic (PES), the Liberal (ELDR), the Green(V/ALE), the Socialists (GUE/NGL), and Right(UEN).
Note that experiments only focus on thesix largest political parties, excluding the smallerand more marginal ones which are often more un-stable or ad-hoc configurations, including inde-pendent MEPs with various forms of Anti-EU ide-ologies.
To give an idea of class distribution, thenumber of MEPs for all parties in our training setis listed in Table 1.
Our 5thEP term training setcomprises a total of 689 MEPs while our 6thtermtest set comprises 818.
It is worth pointing out thatin the 6thEP, roughly 75% of the data correspondsto MEPs from the old member states while 25%test are MEPs from the new member states.
Ofthe members from the old member states, roughly53% of the MEPs are incumbents while the re-mainders are freshmen (we return to this propertyin Section 4 below).In order to facilitate reproducibility of reportedresults and foster further research, all data sets areavailable for download, including party labels andBaseline stem dep/stemAcc 0.394 0.476 0.492Prec 0.065 0.439 0.458Rec 0.166 0.399 0.393F10.094 0.418 0.423Table 3: Results of the 5-fold cross-validation ex-periments on the training data for the majority-class baseline, a model trained on stems and oneenriched with dependency-disambiguated stems.all (automatic) linguistic annotations.33 Preliminary resultsIn addition to reporting results for the SVM classi-fier, we also include figures for a simple majority-class baseline approach, i.e., simply assigning allMEPs in the test set to the largest political party,EPP-ED.
For evaluating the various approacheswe will be reporting precision (Prec), recall (Rec)and F1for each individual class/party, in addi-tion to the corresponding macro-averaged scoresacross all parties.
Note that for one-of classifi-cation problems like the one we are dealing withhere, micro-averaging would simply correspond toaccuracy (with Prec = Rec = F1, since the numberof false positives and false negatives would be thesame).
While we also report accuracy, it is worthbearing in mind that accuracy will overemphasizeperformance on the large classes when workingwith skewed class distributions like we do here.In order to study the effects of different surfacefeatures and classifier-tuning, we conduct a num-ber of 5-fold cross-validation experiments on thetraining data using different feature combinations,for each empirically determining the best valuefor the C-parameter (i.e., the regularization param-eter of the SVM classifier, governing the trade-off between training error and margin size).
Inthis initial experiments we trained different mod-els with various configurations of non-normalizedtokens (i.e., observed word forms), stems, lemmasand PoS- and dependency-disambiguated tokensand stems.
The best performing configuration sofar turns out to be the dependency disambiguatedstems with the observed optimal C-value of 0.8,with F1over two percentage points higher thanthe model trained on stems alone at the same C-3Downloadable at http://emanuel.at.ifi.uio.no/debates_data.tar.gz57PSE EPP-ED ELDR GUE/NGL V/ALE UEN totalPSE 111 36 15 9 6 1 178EPP-ED 123 286 77 13 12 31 542ELDR 3 3 7 0 1 0 14GUE/NGL 2 0 1 18 1 0 22V/ALE 3 2 2 5 25 1 38UEN 7 9 3 1 8 4 32total 249 336 105 46 53 37 826Acc 0.445 0.851 0.066 0.391 0.471 0.108 0.551Prec 0.623 0.527 0.500 0.818 0.657 0.166 0.549Rec 0.445 0.851 0.066 0.391 0.555 0.108 0.403F10.519 0.651 0.117 0.529 0.602 0.131 0.464Table 2: Confusion matrix showing predicted (horizontal) and true (vertical) party affiliations, togetherwith accuracy, precision, recall and F1scores for system predictions.
Overall accuracy and macro-averaged precision, recall and F1(presented in bold text) can be compared to majority-class baselineresults of Acc=0.410, Prec=0.068, Rec=0.166 and F1=0.097.value point (see Table 3 for details).
This indicatesthat linguistically informed features do provide themodel with relevant information.Results obtained by applying the best-performing configuration from our developmentexperiments to the test data are presented inTable 2, together with a confusion matrix forthe classifier assignments.
Party-wise F1andaccuracy scores in addition to overall accuracyand macro-averaged precision, recall and F1are shown in the bottom four rows; comparevalues in bold text to majority-class baselineresults of Acc=0.407, Prec=0.069, Rec=0.166 andF1=0.097.
There are two groups with compara-tively poor prediction scores, the Liberal (ELDR)and the Right (UEN).
In the case of the former,there are two key factors that may account forthis: (1) Ideological compositions of the groupand, (2) coalition-formation in the EP.
Firstly,ELDR consists of delegations from nationalparties that tend to locate themselves betweenthe Social-Democratic (PES) and the Christian-Democratic / Conservative parties (EPP-ED) atthe national arena.
Due to differences in theideological landscape across EU member states,some members of the ELDR may find themselvesholding views that are closer to those held byPES or EPP-ED than ELDR representatives fromsome countries.
Secondly, in the period underinvestigation, ELDR tended to form coalitionswith the EPP-ED on some policy areas and withthe PES on others.
As MEPs mainly speak onpolicies related to the Committees they serveon, misclassifications as PES or EPP-ED maybe a reflection of the coaltion-formation on thecommittees they served on (Hix and H?yland,2013).
When it comes to UEN, misclassificationas EPP-ED may be explained in terms of sharedideology.
In some cases, the membership of UENrather than EPP-ED is due to historical eventsrather than ideological considerations (McElroyand Benoit, 2012).4 Research questionsThis section briefly outlines some of the questionswe will be focusing on in the ongoing work of an-alyzing the predictions of the SVM classifier inmore detail.
In most cases this analysis will con-sist of comparing prediction performance acrossvarious relevant subsets of MEPs while lookingfor systematic differences.Contribution of linguistic features Much ofthe work done to date in ?text-as-data?
approachesin social sciences has been based on relatively sim-ple and surface oriented features, typically bag-of-words models, perhaps combined with termweighting and stemming for word normalization(for an overview of what is currently consideredbest practice, see Grimmer and Stewart (2013)).Much of the methodology can be seen as importsfrom the fields of information retrieval and datamining rather than natural language processing.58A relevant question for the current work is theextent to which more linguistically informed fea-tures can contribute to the task of predicting po-litical affiliation, compared to ?surface features?based solely on directly observable lexical infor-mation.
One of our goals is to asses whether moreaccurate models can be built by including richerfeature sets with more linguistically informed fea-tures, like part-of-speech (PoS) tags, dependencyrelations, class-based features drawn from unsu-pervised word clustering, negation scope analysis,and more.
The preliminary results already demon-strates that linguistically motivated features canbe useful for the current task, but there are stillmany more feature types and combinations to beexplored.Differences between new and old memberstates Ten countries joined the European Unionin 2004.
This offered a rare opportunity for the ex-isting party groups to substantively increase theirshare of the seats in the European Parliament byrecruiting national party delegations from the newmember states.
As most of the new member stateshave a relative short history of competitive mul-tiparty system, there were weaker ties betweenparties in new and old member states when com-pared to previous rounds of enlargement.
Sincethe allocation of office spoils in the EP is fairlyproportional among party groups it was assumedthat national parties from the new member states?
less ideologically committed to any of the be-lief systems held by the traditional Western Euro-pean party families ?
would shift the allocation ofsome offices in the EP by opting to join certainparty group who controlled a larger share of min-isterial portfolios.
If there are large differencesin classifier performance between members fromnew and old members states, this can provide sup-port for the hypothesis that national party delega-tions from new member states joined the existingparty groups for other reasons than simply sharedideological beliefs and goals.
H?yland and God-bout (2008) presented similar preliminary resultsthat already hint at this tendency.
The ongoingcollaboration will further explore this question bytargeting it in new ways.Differences between incumbents and freshmenMEPs This point is tightly connected to the pre-vious.
Given that our training and testing data arecorrespond to distinct consecutive terms of parlia-ment, one should determine whether any differ-ences in prediction performance for MEPs fromnew and old member states can be explained sim-ply by the fact that the latter will include manyMEPs that appear both in the training and the testdata (i.e., speakers participating in the debates inboth the 5thand 6thterm).
In order to factor outany such ?incumbency effect?, we will also in-vestigate whether any differences can be found inprediction performance between incumbents and?freshmen?
(members who joined the EP afterthe 2004 elections) originating from old memberstates only.Differences between political domains An-other effect we would like to measure is whetherthere are any systematic differences in predictionperformance across different political topics or do-mains.
Among other things this could indicate thatthe language use is more politicized or ideologi-cally charged in debates concerning certain politi-cal issues.
Much of the work in the European Par-liament is carried out in specialized committeesthat prepare reports that will later be debated andvoted on in the plenary.
By coupling the debateswith information about which legislative standingcommittee has handled each particular case, wewould be able to automatically break down ourresults according to political domain.
This couldbe achieved using a resource like that describedby H?yland et al.
(2009).
Examples of commit-tee domains include Foreign Affairs, InternationalTrade, Legal Affairs, Regional Development, Eco-nomic and Monetary Affairs, and Internal Marketand Consumer Protection, to name a few.
Anotherpossibility here would be to train separate special-ized classifiers for debates falling within the do-main of each specialized committee directly.5 SummaryThis paper has outlined an interdisciplinary effortto explore whether the recorded speeches from theplenary debates of the European Parliament can beutilized by an SVM classifier to correctly predictthe party affiliations of the participants.
Prelim-inary experimental results already demonstratesthat such predictions can indeed be made ?
alsodemonstrating the contribution of linguistically in-formed features ?
and the paper has outlined anumber of related research questions currently be-ing pursued in ongoing work.59References[Cortes and Vapnik1995] Corinna Cortes and VladimirVapnik.
1995.
Support-vector networks.
MachineLearning, 20(3):273?297, September.
[Crammer and Singer2001] Koby Crammer and YoramSinger.
2001.
On the algorithmic implementation ofmulticlass kernel-based vector machines.
Journal ofMachine Learning Research, 2:265?292, December.
[Grimmer and Stewart2013] Justin Grimmer and Bran-don M. Stewart.
2013.
Text as data: The promiseand pitfalls of automatic content analysis methodsfor political texts.
Political Analysis, 21(3):267?297.
[Hix and H?yland2013] Simon Hix and Bj?rn H?yland.2013.
The empowerment of the european parlia-ment.
Annual Review of Political Science, 16:171?189.
[H?yland and Godbout2008] Bj?rn H?yland and Jean-Franc?ois Godbout.
2008.
Lost in translation?
pre-dicting party group affiliation from european parlia-ment debates.
In On-line Proceedings of the FourthPan-European Conference on EU Politics.
[H?yland et al.2009] Bj?rn H?yland, Indraneel Sircar,and Simon Hix.
2009.
Forum section: an auto-mated database of the european parliament.
Euro-pean Union Politics, 10(1):143?152.
[McElroy and Benoit2012] Gail McElroy and KennethBenoit.
2012.
Policy positioning in the europeanparliament.
European Union Politics, 13(1):150?167.
[Tsochantaridis et al.2004] Ioannis Tsochantaridis,Thomas Hofmann, Thorsten Joachims, and YaseminAltun.
2004.
Support vector machine learning forinterdependent and structured output spaces.
InProceedings of the 21st International Conferenceon Machine Learning.60
