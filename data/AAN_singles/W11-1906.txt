Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 51?55,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsRule and Tree Ensembles for Unrestricted Coreference Resolution?Cicero Nogueira dos SantosUniversidade de Fortaleza ?
UNIFORInforma?tica Aplicada ?
PPGIAFortaleza, Brazilcnogueira@unifor.brDavi Lopes CarvalhoUniversidade de Fortaleza ?
UNIFORInforma?tica Aplicada ?
PPGIAFortaleza, Brazildavi.carvalho@gmail.comAbstractIn this paper, we describe a machine learn-ing system based on rule and tree ensemblesfor unrestricted coreference resolution.
Weuse Entropy Guided Transformation Learning(ETL) and Decision Trees as the base learners,and, respectively, ETL Committee and Ran-dom Forest as ensemble algorithms.
Our sys-tem is evaluated on the closed track of theCoNLL 2011 shared task: Modeling Unre-stricted Coreference in OntoNotes.
A prelim-inary version of our system achieves the 6thbest score out of 21 competitors in the CoNLL2011 shared task.
Here, we depict the systemarchitecture and our experimental results andfindings.1 IntroductionUnrestricted coreference resolution consists in iden-tifying coreferring entities and events in texts.
Forinstance, in the sentence?She had a good suggestion andit was unanimously accepted.
?there is a coreference between the pronoun ?it?
andthe noun phrase ?a good suggestion?.
In the follow-ing sentence?Sales of passenger cars grew 22%.
The stronggrowth followed year-to-year increases.
?there is a coreference between the noun phrase ?thestrong growth?
and the event ?grew?.
Throughout?This work is partially funded by the FUNCAP grant 0011-00147.01.00/09.this paper, we use the term mention to mean a refer-ence to an entity or event.The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coref-erence in OntoNotes.
The participants are providedwith a large corpus that contains various annotationlayers such as part-of-speech (POS) tagging, pars-ing, named entities and semantic role labeling.
Thetask consists in the automatic identification of core-ferring entities and events given predicted informa-tion on other OntoNotes layers.
A previous work onmodeling unrestricted coreference using an earlierversion of this corpus is presented in (Pradhan et al,2007).In this paper, we describe the machine learningapproach that we used to the closed track of theCoNLL 2011 Shared Task.
Our system followsthe common strategy of recasting the problem as aclassification task.
First, in a preprocessing step,a set of candidate mentions is constructed.
Next,also in the preprocessing step, pairs of candidate co-referring mentions are generated.
Then, each candi-date pair of mentions is classified as co-referring ornot using a classifier learned from the annotated cor-pus.
Finally, a postprocessing step (clustering) re-moves inconsistencies that would result of the pair-wise classifications and constructs a partition on theset of mentions.
In our system, the learning mod-ule is based on ensemble learning.
We use EntropyGuided Transformation Learning (ETL) (Milidiu?
etal., 2008) and Decision Trees (DT) (Quinlan, 1993)as base learners, and, respectively, ETL Commit-tee (dos Santos et al, 2010) and Random Forest(Breiman, 2001) as ensemble algorithms.51The remainder of this paper is organized as fol-lows.
In Section 2, we present the corpus pre-processing and postprocessing steps.
Our machinelearning modeling for the unrestricted coreferenceresolution task is presented in Section 3.
The exper-imental findings are depicted in Section 4.
Finally,in Section 5, we present our final remarks.2 Corpus ProcessingIn this section we describe some preprocessing andpostprocessing steps used in the proposed system.2.1 Candidate Mention ExtractionFor each text document, we generate a list of candi-date mentions in the following way:?
all the noun phrases (NP) identified in the pro-vided parsing tree are considered as candidatementions;?
each pronoun is isolatedly considered as a can-didate mention even if it is inside a larger NP;?
named entities in the categories Person (PER-SON), Organization (ORG) and Geo-PoliticalEntity (GPE) are isolatedly considered as can-didate mentions even if they are inside largerNPs.
Additionally, in order to better align withthe OntoNotes mention annotation, a process-ing is performed to include possessive marks??s?
and premodifiers such as ?Mr.
?.In the current version, our system does notconsider verbs when creating candidate mentions.Therefore, the system does not resolve coreferencesinvolving events.2.2 Candidate Co-referring Pairs GenerationIn the training phase, we generate positive and neg-ative examples of co-referring pairs using a strategysimilar to the one of Soon et al (2001).
In theirmethod, the text is examined in a left-to-right man-ner.
For each anaphoric mention mj , is generated apositive example pair that includes mj and its clos-est preceding antecedent, mi.
A negative exampleis created for mj paired with each of the interven-ing mentions, mi+1, mi+2, ..., mj?1.
We extend theSoon et al (2001) approach by also including allpositive and negative pairs that can be formed withthe mentions in the sentence of the closest precedingantecedent, mi.In the classification phase, the text is also exam-ined in a left-to-right manner.
For each mention mj ,candidate co-referring pairs are generated by pair-ing it with a limited number of preceding mentions.When using predicted mentions, we set this limit to60 (sixty).
For the gold-mentions track, the limit isset to 40 (forty).2.3 Feature EngineeringWe use a set of 80 features to describe each pair ofmentions (mi, mj).
The feature set includes lex-ical, morphological, syntactic, semantic and posi-tional information.
Most of them are borrowed fromthe works of Ng and Cardie (2002) and Sapena et al(2010).
However, we also propose some new fea-tures.
In the following, due to space constraints, webriefly describe some of them.
The features markedwith * are the new proposed ones.Lexical: head word of mi/j ; String matchingof (head word of) mi and mj (y/n); Both are pro-nouns and their strings match (y/n); Previous/Nexttwo words of mi/j ; Length of mi/j ; Edit distance ofhead words; mi/j is a definitive NP (y/n); mi/j is ademonstrative NP (y/n).Morphological: Both are proper names andtheir strings match (y/n); Basic gender agreement*,which use a list of proper names extracted from thetraining corpus (y/n); Gender/Number of mi/j ; Gen-der/Number agreement(y/n), this and the previousfeature are generated using the number and genderdata provided by Bergsma and Lin (2006).Syntactic: POS tag of the mi/j head word; Previ-ous/Next two POS tags of mi/j ; mi and mj are bothpronouns / proper names (y/n); Previous/Next pred-icate of mi/j*; Compatible pronouns, which checkswhether two pronouns agree in number, gender andperson (y/n)*; NP embedding level; Number of em-bedded NPs in mi/j*.Semantic: the result of a baseline system; senseof the mi/j head word; Named entity type of mi/j ;mi and mj have the same named entity; Semanticrole of mi/j for the prev/next predicate*; Concate-nation of semantic roles of mi and mj for the samepredicate (if they are in the same sentence)*; Samespeaker* (y/n); Alias (y/n); mi and mj have a hy-pernym/hyponym relation (y/n); mi and mj have the52same semantic class (y/n); sum of distances betweenmi and mj to their class.
The last three features aregenerated using WordNet 3.0 (Miller, 1995).Distance and Position: Distance between mi andmj in sentences; Distance in number of mentions;Distance in number of person names (applies onlyfor the cases where mi and mj are both pronouns orone of them is a person name)*; One mention is inapposition to the other (y/n).2.4 Clustering StrategyIn order to generate the coreference chains, it isneeded a strategy to create a partition in the men-tions using the predictions for the candidate co-referent pairs.
This part of the coreference resolutionsystem is frequently called clustering strategy (Ngand Cardie, 2002).
Our system uses an aggressive-merge clustering approach similar to the one pro-posed by Mccarthy and Lehnert (1995).
In this strat-egy, each mention is merged with all of its precedingmentions that are classified as coreferent with it.Additionally, a postprocessing step is employed toremove inconsistencies that would result of the clus-tering processing, such as an NP being coreferent toits embedded NP.3 Machine Learning ModelingIn this section we briefly describes the machinelearning approaches used in our experiments.
Wealso describe a baseline system (BLS) that is usedby ETL for the learning of correction rules.
Theclassification produced by the BLS is also used asa feature for the other experimented learning strate-gies.ETL: Entropy Guided Transformation Learning(ETL) is a correction rule learning algorithm.
Itextends Transformation Based Learning (TBL) byautomatically generating rule templates using Deci-sion Trees (DT) (Milidiu?
et al, 2008).
We use anin-house implementation of ETL.ETL Committee: is an ensemble method thatuses ETL as the base learner (dos Santos et al,2010).
This approach combines the main ideas ofBagging and Random Subspaces, as well as rule re-dundancy and template sampling to generate diverseETL classifiers.
We use an in-house implementationof ETL Committee.Decision Trees: the C4.5 (Quinlan, 1993) systemis one of the most popular DT induction implemen-tation.
It induces a tree based classifier using thetraining data information gain.
In our experiments,we use the J48 tool, which is a DT induction sys-tem similar to C4.5.
J48 is part of the WEKA datamining toolkit (Hall et al, 2009).Random Forest: is an ensemble method that usesDT as the base learner.
In the Random Forest learn-ing process (Breiman, 2001), first, bootstrap sam-pling is employed to generate multiple replicates ofthe training set.
Then, a decision tree is grown foreach training set replicate.
When growing a tree,a subset of the available features is randomly se-lected at each node, the best split available withinthose features is selected for that node.
In our ex-periments, the WEKA?s Random Forest implemen-tation is used.Baseline System: the BLS classifies a candidateco-referring pair (mi, mj) as co-referring when oneof the following conditions occur:?
mj is an alias of mi;?
mj and mi are 3rd person pronouns and there isno person name between them;?
the pair is composed of a person name and a 3rdperson pronoun and there is no person name be-tween them;?
removing determiners, mi matches mj ;?
the feature basic gender agreement is true.The parameters of each algorithm are tuned usingthe development set.
For both, ETL Committee andRandom Forest the ensemble size is set to 50.4 Experiments and ResultsWe train models for two different CoNLL 2011shared task closed tracks: (a) using candidate men-tions whose boundaries are automatically extracted(see Section 2.1); and (b) using candidate men-tions whose boundaries are provided.
In the trainingphase, the gold standard OntoNotes annotation lay-ers are used.
For the development and test sets theautomatically generated OntoNotes annotation lay-ers are used.53For all experiments, results are reported usingthree metrics: MUC, B3 and CEAF(E).
We also re-port the average F1 score for these three metrics,which is the official CoNLL 2011 shared task met-ric.
Additionally, results for the test set are also re-ported using the CEAF(M) and BLANC metrics.4.1 Automatic Mention BoundariesIn Table 1, we show machine learning system resultsfor unrestricted coreference resolution using the de-velopment set.
As we can see in Table 1, the resultsof ensemble methods are better than ones of the baselearners, which is the expected result.
ETL Com-mittee is the classifier that achieve the best results,closely followed by Random Forest.All the experimented ML systems achieve resultsbetter than the baseline.
However, the improvementprovided by ML is more expressive only for theMUC metric.
For instance, ETL Committee pro-vides an improvement over the baseline of about 6.5points in the MUC F1-score, while the improvementfor the other two metrics is only about 2 points.We run an additional experiment by constructinga heterogeneous committee composed by the threebest classifiers: (1) ETL Committee, (2) RandomForest and (3) ETL.
The results for this system isshown in table line with ML Model name ?
(1) + (2)+ (3)?.
This heterogeneous committee provides ourbest experimental results for the development set,which is slightly better than ETL Committee results.Due to deadline constraints, the system outputthat we have submitted to the CoNLL 2011 sharedtask is a majority voting committee of three differentETL classifiers.
These three ETL classifiers slightlydiffers in the used feature sets.
In Table 1, the resultsof the Submitted System is presented for the devel-opment set.
Table 2 presents the Submitted Systemresults for the test set.
Our system achieves the 6thbest score out of 21 competitors in the closed trackof the CoNLL 2011 shared task.4.2 Gold Mention BoundariesFor the gold mention boundaries task, we were notable to assess system performances on the develop-ment set.
This is due to the fact that not all goldmentions are annotated in the development set.We have submitted two outputs for the CoNLL2011 shared task gold mentions closed track.
TheseMetric R P F1MUC 59.21 54.30 56.65BCUBED 68.79 62.81 65.66CEAF (M) 49.54 49.54 49.54CEAF (E) 35.86 40.21 37.91BLANC 73.37 66.91 69.46(MUC + B3 + CEAF(E))/3 53.41Table 2: Submitted System results for the test set usingautomatically extracted mention boundaries.outputs were generated by two systems described inthe previous subsection: (a) the Submitted System;and (b) the heterogeneous committee (ETL Commit-tee + Random Forest + ETL).
In Table 3, we showthe system results for the test set with gold standardmentions.
Again, the heterogeneous committee pro-vides our best results.At the moment of writing this paper, the score-board for this task has not yet been released by theCoNLL 2011 shared task committee.5 ConclusionIn this paper, we describe a machine learning sys-tem based on rule and tree ensembles for unre-stricted coreference resolution.
The system uses En-tropy Guided Transformation Learning and DecisionTrees as the base learners.
ETL Committee and Ran-dom Forest are the used ensemble algorithms.
Wedepict the system architecture and present experi-mental results and findings of our participation inthe CoNLL 2011 shared task.We present results for two closed tasks: (a) usingautomatically extracted mention boundaries; and (b)using gold mention boundaries.
For both tasks, en-semble classifiers have better results than the baseclassifiers.
This is the expected outcome, since en-semble classifiers tend to be more accurate than thebase classifiers.
We also experiment heterogeneouscommittees that combines the three best classifierfor the first task.
Heterogeneous committees provideour best scoring results for both tasks.
Using a pre-liminary version of our system, we achieve the 6thbest score out of 21 competitors in the closed trackof the CoNLL 2011 shared task.One of the possible future works, is to investigatethe impact of the new features that we propose.54MUC B3 CEAF(E) (MUC + B3 + CEAF(E))/3ML Model R P F1 R P F1 R P F1 F1(1) ETL Committee 52.31 57.51 54.78 63.62 70.42 66.84 42.64 37.99 40.18 53.93(2) Random Forest 53.31 54.91 54.10 65.23 67.31 66.25 40.47 39.05 39.75 53.37(3) ETL 54.80 52.24 53.49 67.56 62.19 64.77 37.22 39.55 38.35 52.20(4) Decision Trees 57.51 49.12 52.98 71.23 58.94 64.50 34.84 42.25 38.19 51.89(5) Baseline System 43.04 55.13 48.34 57.82 74.21 64.99 43.63 33.62 37.98 50.43(1) + (2) + (3) 52.77 57.44 55.00 64.09 70.58 67.18 42.67 38.48 40.47 54.21Submitted System 54.65 53.25 53.94 67.15 63.86 65.46 38.3 39.56 38.92 52.45Table 1: System results for the development set using automatically extracted mention boundaries.Submitted System (1) + (2) + (3)Metric R P F1 R P F1MUC 58.77 56.54 57.64 57.76 61.39 59.52BCUBED 67.05 64.84 65.92 64.49 70.27 67.26CEAF (M) 50.05 50.05 50.05 51.87 51.87 51.87CEAF (E) 37.61 39.62 38.59 41.42 38.16 39.72BLANC 72.59 67.76 69.80 72.72 71.97 72.34(MUC + B3 + CEAF(E))/3 54.05 55.50Table 3: System results for the test set using gold mention boundaries.ReferencesShane Bergsma and Dekang Lin.
2006.
Bootstrap-ping path-based pronoun resolution.
In Proceedingsof ACL2006, ACL?44, pages 33?40, Stroudsburg, PA,USA.
Association for Computational Linguistics.Leo Breiman.
2001.
Random forests.
Machine Learn-ing, 45(1):5?32.C?
?cero Nogueira dos Santos, Ruy Luiz Milidiu?, CarlosE.
M. Crestana, and Eraldo R. Fernandes.
2010.
ETLensembles for chunking, NER and SRL.
In 11th In-ternational Conference on Computational Linguisticsand Intelligent Text Processing, CICLing, pages 100?112.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The weka data mining software: an update.Sigkdd Explorations, 11:10?18.Joseph F Mccarthy and Wendy G Lehnert.
1995.
Usingdecision trees for coreference resolution.
In In Pro-ceedings of the Fourteenth International Joint Confer-ence on Artificial Intelligence, pages 1050?1055.Ruy L.
Milidiu?, C?
?cero N. dos Santos, and Julio C.Duarte.
2008.
Phrase chunking using entropy guidedtransformation learning.
In Proceedings of ACL2008,Columbus, Ohio.George A. Miller.
1995.
Wordnet: A lexical database forenglish.
Communications of the ACM, 38:39?41.Vincent Ng and Claire Cardie.
2002.
Improving machinelearning approaches to coreference resolution.
In Pro-ceedings of the 40th Annual Meeting on Associationfor Computational Linguistics, ACL ?02, pages 104?111, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Sameer Pradhan, Lance Ramshaw, Ralph Weischedel,Jessica MacBride, and Linnea Micciulla.
2007.
Unre-stricted Coreference: Identifying Entities and Eventsin OntoNotes.
In in Proceedings of the IEEE Inter-national Conference on Semantic Computing (ICSC),September 17?19.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and Nianwen Xue.2011.
CoNLL-2011 shared task: Modeling unre-stricted coreference in ontonotes.
In Proceedings ofthe Fifteenth Conference on Computational NaturalLanguage Learning (CoNLL 2011), Portland, Oregon,June.J.
Ross Quinlan.
1993.
C4.5: programs for machinelearning.
Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA.Emili Sapena, Llu?
?s Padro?, and Jordi Turmo.
2010.
Re-laxcor: A global relaxation labeling approach to coref-erence resolution.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, SemEval?10, pages 88?91, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to corefer-ence resolution of noun phrases.
Computational Lin-guistics, 27:521?544, December.55
