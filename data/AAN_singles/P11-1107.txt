Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1066?1076,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsMetagrammar Engineering:Towards systematic exploration of implemented grammarsAntske FokkensDepartment of Computational Linguistics, Saarland University &German Research Center for Artificial Intelligence (DFKI) Project Office BerlinAlt-Moabit 91c, 10559 Berlin, Germanyafokkens@coli.uni-saarland.deAbstractWhen designing grammars of natural lan-guage, typically, more than one formal anal-ysis can account for a given phenomenon.Moreover, because analyses interact, thechoices made by the engineer influence thepossibilities available in further grammar de-velopment.
The order in which phenomenaare treated may therefore have a major impacton the resulting grammar.
This paper proposesto tackle this problem by using metagrammardevelopment as a methodology for grammarengineering.
I argue that metagrammar engi-neering as an approach facilitates the system-atic exploration of grammars through compar-ison of competing analyses.
The idea is illus-trated through a comparative study of auxil-iary structures in HPSG-based grammars forGerman and Dutch.
Auxiliaries form a cen-tral phenomenon of German and Dutch andare likely to influence many components ofthe grammar.
This study shows that a spe-cial auxiliary+verb construction significantlyimproves efficiency compared to the standardargument-composition analysis for both pars-ing and generation.1 IntroductionOne of the challenges in designing grammars of nat-ural language is that, typically, more than one for-mal analysis can account for a given phenomenon.The criteria for choosing between competing analy-ses are fairly clear (observational adequacy, analyti-cal clarity, efficiency), but given that analyses of dif-ferent phenomena interact, actually evaluating anal-yses on those criteria in a systematic manner is farfrom straightforward.
The standard methodology in-volves either picking one analysis, and seeing howit goes, then backing out if it does not work out,or laboriously adapting a grammar to two versionssupporting different analyses (Bender, 2010).
Theformer approach is not in any way systematic, in-creasing the risk that the grammar is far from opti-mal in terms of efficiency.
The latter approach po-tentially causes the grammar engineer an amount ofwork that will not scale for considering many differ-ent phenomena.This paper proposes a more systematic andtractable alternative to grammar development: meta-grammar engineering.
I use ?metagrammar?
as ageneric term to refer to a system that can generateimplemented grammars.
The key idea is that thegrammar engineer adds alternative plausable anal-yses for linguistic phenomena to a metagrammar.This metagrammar can generate all possible com-binations of these analyses automatically, creatingdifferent versions of a grammar that cover the samephenomena.
The engineer can test directly howcompeting analyses for different phenomena inter-act, and determine which combinations are possible(after minor adaptations) and which analyses are in-compatible.The idea of metagrammar engineering is illus-trated here through a case study of word order andauxiliaries in Germanic languages, which forms thesecond goal of this paper.
Auxiliaries form a centralphenomenon of German and Dutch and are likely toinfluence many components of the grammar.
The re-sults show that the analysis of auxiliary+verb struc-tures presented in Bender (2010) significantly im-1066proves efficiency of the grammar compared to thestandard argument-composition analysis within therange of phenomena studied.
Because future re-search is needed to determine whether the auxil-iary+verb alternative can interact properly with ad-ditional phenomena and still lead to more efficientresults than argument-composition, it is particularlyuseful to have a grammar generator that can auto-matically create grammars with either of the twoanalyses.The remainder of this paper starts with the casestudy.
Section 2 provides a description of the con-text of the study.
The relevant linguistic propertiesand alternative analyses are described in Sections3 and 4.
After evaluating and discussing the casestudy?s results, I return to the general approach ofmetagrammar engineering.
Section 6 presents re-lated work on metagrammars.
It is followed by aconclusion and discussion on using metagrammarsas a methodology for grammar engineering.2 A metagrammar for GermanicLanguages2.1 The LinGO Grammar MatrixThe LinGO Grammar Matrix (Bender et al, 2002;Bender et al, 2010) provides the main context forthe experiments described in this paper.
To beginwith, its further development plays a significant rolefor the motivation of the present study.
More impor-tantly, the Germanic metagrammar is implementedas a special branch of the LinGO Grammar Matrixand uses a significant amount of its code.The Grammar Matrix customization system al-lows users to derive a starter grammar for a particu-lar language from a common multi-lingual resourceby specifying linguistic properties through a web-based questionnaire.
The grammars are intended forparsing and generation with the LKB (Copestake,2002) using Minimal Recursion Semantics (Copes-take et al, 2005, MRS) as parsing output and gener-ation input.
After the starter grammar has been cre-ated, its development continues independently: en-gineers can thus make modifications to their gram-mar without affecting the multi-lingual resource.Internally, the customization system works as fol-lows: The web-based questionnaire registers lin-guistic properties in a file called ?choices?
(hence-forth choices file).
The customization system takesthis choices file as input to create grammar frag-ments, using so-called ?libraries?
that contain imple-mentations of cross-linguistically variable phenom-ena.
Depending on the definitions provided in thechoices file, different analyses are retrieved from thecustomization system?s libraries.
The language spe-cific implementations inherit from a core grammarwhich handles basic phrase types, semantic compo-sitionality and general infrastructure, such as featuregeometry (Bender et al, 2002).The present study is part of a larger effort to im-prove the customization library for auxiliary struc-tures in free word order and verb second languages.It examines whether Bender?s observations concern-ing an improved analysis for auxiliaries in Wambaya(Bender, 2010) also hold for Germanic languages.
Amore elaborate study of German and Dutch (includ-ing both Flemish and (Northern) Dutch, which haveslightly different word order constraints) is informa-tive, because these languages are well-described andknown to have distinctly challenging word order be-havior.2.2 Germanic branchIn order to create grammars for Germanic lan-guages, a specialized branch of the Grammar Ma-trix customization system was developed.
This Ger-manic grammars generator uses the Grammar Ma-trix?s facilities to generate types in type descriptionlanguage (tdl).
At present, the generator uses theGrammar Matrix analyses for agreement and casemarking as well as basics from its morphotactics,coordination and lexicon implementations.In the first stage, the word order library and aux-iliary implementation were extended to cover twoalternative analyses for Germanic word order (seeSection 4).
The coordination library was adapted toensure correct interactions with the new word orderanalyses and agreement.
The morphotactics librarywas extended to cover Dutch and Flemish interac-tions between word order and morphology.
Finally,the lexicon and verbal case pattern implementationswere extended to cover ditransitive verbs.Both versions of word order analyses can betweaked to include or exclude a rarely occurringvariant of partial VP fronting (see Section 4.3) re-sulting in four distinct grammars for each of the1067Vorfeld LB Mittelfeld RB NachfeldDer Mann hat den Jungen gesehen nach der PartyThe man.nom has the boy.acc seen after the partyDer Mann hat den Jungen nach der Party gesehenDen Jungen hat der Mann gesehen nach der PartyNach der Party hat der Mann den Jungen gesehenDen Jungen gesehen hat der Mann nach der PartyGesehen hat der Mann den Jungen nach der PartyThe man saw the boy after the partyTable 1: Basic structure of German word order (not exhaustive)languages under investigation.
These 12 grammarscover Dutch, Flemish and German main clauses withup to three core arguments.13 Germanic word order3.1 German word orderTopological fields (Erdmann, 1886; Drach, 1937)form the easiest way to describe German word or-der.
The sentence structure for declarative mainclauses, consists of five topological fields: Vorfeld(?pre-field?
), Left Bracket (LB), Mittelfeld (?middlefield?
), Right Bracket (RB) and the Nachfeld (?afterfield?).
A subset of permissible alternations in Ger-man are provided in Table 1.
The last two sentencespresent an example of partial VP fronting.The fields are defined with regard to verbal forms,which are placed in the Left and Right Brackets.Each topological field has word order restrictionsof its own.
The Vorfeld must contain exactly oneconstituent in an affirmative main clause.
The LeftBracket contains the finite verb and no other ele-ments.
Other verbal forms (if not fronted to the Vor-feld) must be placed in the Right Bracket.
Most non-verbal elements are placed in the Mittelfeld.
Whenmain verbs are placed in the Vorfeld, their object(s)may stay in the Mittelfeld.
This kind of partial VPfronting is illustrated by the last example in Table 1.The Nachfeld typically contains subordinate clausesand sometimes adverbial phrases.In German, the respective order between the verbsin the Right Bracket is head-final, i.e.
auxiliaries fol-low their complements.
The only exception is the1The grammar generation system also creates Danish gram-mars.
Danish results are not presented, because the languagedoes not pose the challenges explained in Section 4.auxiliary flip: under certain conditions in subordi-nate clauses, the finite verb precedes all other verbalforms.3.2 Dutch word orderDutch word order reveals the same topological fieldsas German.
There are two main differences betweenthe languages where word order is concerned.
First,whereas the order of arguments in the German Mit-telfeld allows some flexibility depending on infor-mation structure, Dutch argument order is fixed, ex-cept for the possibility of placing any argument inthe Vorfeld.
A related aspect is that Dutch is lessflexible as to what partial VPs can be placed in theVorfeld.The second difference is the word order in theRight Bracket.
The order of auxiliaries and theircomplements is less rigid in Dutch and typicallyauxiliary-complement, the inverse of German order.Most Dutch auxiliaries can occur in both orders, butthis may be restricted according to their verb form.Four groups of auxiliary verbs can be distinguishedthat have different syntactic restrictions.1.
Verbs selecting for participles which may ap-pear on either side of their complement (e.g.hebben (?have?
), zijn (?be?)).2.
Verbs selecting for participles which prefer tofollow their complement and must do so if theyare in participle form themselves (e.g.
blijven(?remain?
), krijgen (?get?)).3.
Modals selecting for infinitives which prefer toprecede their complement and must do so ifthey appear in infinitive form themselves.1068VF LB MF RBDe man zou haar kunnen hebben gezienthe man would her.acc can have seenDe man zou haar gezien kunnen hebben%De man zou haar kunnen gezien hebbenThe man should have been able to see herTable 2: Variations of Dutch auxiliary order4.
Verbs selecting for ?to infinitives?
which mustprecede their complement.While there is some variation among speakers,the generalizations above are robust.
The permittedvariations assuming a verb of the 3rd and 1st cate-gory in the right bracket are presented in Table 2.2The variant %De man zou haar kunnen gezienhebben is typical of speakers from Belgium (Hae-seryn, 1997); speakers from the Netherlands tend toregard such structures as ungrammatical.
Our sys-tem can both generate a Flemish grammar acceptingall of the above and a (Northern) Dutch grammar,rejecting the third variant.4 Alternative auxiliary approachesThis section presents the alternative analyses forauxiliary-verb structures in Germanic languagescompared in this study.
For reasons of space, I limitmy description to an explanation of the differencesand relevance of the compared analyses.34.1 Argument-compositionThe standard analysis for German and Dutchauxiliaries in HPSG is a so-called ?argument-composition?
analysis (Hinrichs and Nakazawa,1994), which I will explain through the followingDutch example:4(1) IkIzouwouldhettheboekbookwillenwantlezen.read.
?I would like to read the book.
?In the sentence above, the auxiliary willen ?want?separates the verb lezen ?read?
from its object het2Note that the same orders as in the Right Brackets may alsooccur in the Vorfeld (with or without the object).3Details of the implementations can be found by using themetagrammar, which can be found on my homepage.4Hinrichs and Nakazawa (1994) present an analysis for theGerman auxiliary flip.
The relevant observations are the same.266664VAL266664SUBJ 1COMPS*264HEAD verbVAL"SUBJ 1COMPS 2#375, 2+377775377775Figure 1: Standard Auxiliary Subcategorizationboek ?the book?.
A parser respecting surface ordercan thus not combine lezen and het boek before com-bining willen and lezen.The argument-composition analysis was intro-duced to make sure that het boek can be picked upas the object of the embedded verb lezen.
The sub-categorization of an auxiliary under this analysis ispresented in Figure 1.
The subject of the auxiliaryis identical to the subject of the auxiliary?s com-plement.
Its complement list consists of the con-catenation of the verbal complement and any com-plement this verbal complement may select for.
Inthe sentence above, willen will add the subject andthe object of lezen to its own subcatorization lists.5This standard solution for auxiliary-verb structuresis (with minor differences) also what is provided bythe Matrix customization system.Argument-composition can capture the grammat-ical behavior of auxiliaries in German and Dutch.However, grammaticality and coverage is not allthat matters for grammars of natural language.
Ef-ficiency remains an important factor, and argument-composition has some undesirable properties on thislevel.
The problem lies in the fact that lexical en-tries of auxiliaries have underspecified elements ontheir subcategorization lists.
With the current chartparsing and chart generation algorithms (Carroll andOepen, 2005), an auxiliary in a language with flex-ible word order will speculatively add edges to thechart for potential analyses with the adjacent con-stituent as subject or complement.
Because thelength of the lists are underspecified as well, it cancontinue wrongly combining with all elements in thestring.
In the worse case scenario, the number ofedges created by an auxiliary grows exponentially inthe number of words and constituents in the string.The efficiency problem is even worse for generation:while the parser is restricted by the surface order of5In the semantic representation, both arguments will be di-rectly related to the main verb exclusively.1069`i?24VAL"SUBJ ?
?COMPSD?HEAD verb?E#35`ii?26666664VAL"SUBJ 1COMPS 2#HEAD-DTR|VAL| COMPS 3NON-HEAD-DTR 3"VAL"SUBJ 1COMPS 2##37777775Figure 2: Auxiliary lexical type (i) and Auxiliary+verbconstruction (ii) under alternative analysisthe string, the generator will attempt to combine alllexical items suggested by the input semantics, aswell as lexical items with empty semantics, in ran-dom order.4.2 Aux+verb constructionBender (Bender, 2010)6 presents an alternative ap-proach to auxiliary-verb structures for the Australianlanguage Wambaya.
The analysis introduces auxil-iaries that only subcategorize for one verbal com-plement, not raising any of the complement?s ar-guments or its subject.
Auxiliaries combine withtheir complement using a special auxiliary+verbrule.
Figure 2 presents this alternative solution.
Inprinciple, the new analysis uses the same techniqueas argument composition.
The difference is that theauxiliary now starts out with only one element in itssubcategorization lists and can only combine withpotential verbal complements that are appropriatelyconstrained.
The structure that combines the auxil-iary with its complement places the remaining ele-ments on the complement?s SUBJ and COMPS listson the respective lists of the newly formed phrase,as can be seen in Figure 2 (ii).
The constraints onraised arguments are known when the constructionapplies.
The efficiency problem sketched above isthus avoided.4.3 A small wrinkle: partial VP frontingIn its basic form, the auxiliary+verb structure cannothandle partial VP fronting where the main verb isplaced in first position leaving one or more verbal6Bender credits the key idea behind this analysis to DanFlickinger (Bender, 2010).forms in the verbal cluster, as illustrated in (2) forDutch:(2) GezienSeenzoushoulddethemanmanhaarherkunnencanhebben.have?The man should have been able to see her.
?The problem is that hebben ?have?
cannot com-bine with gezien ?seen?, because they are sepa-rated by the head of the clause.
Because the verbhebben cannot combine with its complement, it can-not raise its complement?s arguments either: theauxiliary+verb analysis only permits raising whenauxiliary and complement combine.This shortcoming is no reason to immediately dis-miss the proposal.
Structures such as (2) are ex-tremely rare.
The difference in coverage of a parserthat can and a parser that cannot handle such struc-tures is likely to be tiny, if present at all, nor is itvital for a sentence generator to be able to producethem.
However, a correct grammar should be able toanalyze and produce all grammatical structures.I implemented an additional version of the aux-iliary+verb construction using two rather complexrules that capture examples such as (2).
Becausethe structure in (2) also presented difficulties forthe argument-composition analysis in Dutch, I testedboth of the analyses with and without the inclusionof these structures.
In the ideal case, the full cov-erage version will remain efficient enough as thegrammar grows.
But if this turns out not to be thecase, the decision can be made to exclude the ad-ditional rule from the grammar or to use it as a ro-bustness rule that is only called when regular rulesfail.
Given the metagrammar engineering approach,it will be straightforward to decide at a later point toexclude the special rule, if corpus studies reveal thisis favourable.5 Grammars and evaluation5.1 Experimental set-upAs described above, the Germanic metagrammar isa branch of the customization system.
As such, ittakes a choices file as input to create a grammar.
Thebasic choices files for Dutch and German were cre-ated through the LinGO Grammar Matrix web inter-1070Complete Set Reduced SetPositive Total Positive Total Av.s s s s w/sDu 177 14654 138 14591 6.61Fl 195 14654 156 14606 6.61Ge 116 6926 84 6914 6.65Table 3: Number of test examples (s) used in evaluationand average words per sentence (w/s)face.7 The choices files defined artificial grammarswith a dummy vocabulary.
The system can producereal fragments of the languages, but strings repre-senting syntactic properties through dummy vocab-ulary were used to give better control over ambiguityfacilitating the evaluation of coverage and overgen-eration of the grammars.
The grammars have a lexi-con of 9-10 unambiguous dummy words.The created choices files were extended offline todefine those properties that the Germanic metagram-mar captures, but are not incorporated in the Matrixcustomization system.
This included word order ofthe auxiliary and complement, fixed or free argu-ment order, influence of inflection on word order,a more elaborate case hierarchy, ditransitive verbs,and the choice of auxiliary/verb analysis.
Fourchoices files with different combinations of analy-ses were created for each language, resulting in 12choices files in total.A basic test suite was developed that covers in-transitive, transitive and ditransitive main clauseswith up to three auxiliaries.
The German set wasbased on a description provided by Kathol (2000),Dutch and Flemish were based on Haeseryn (1997).For each verb and auxiliary combination, all permis-sible word orders were defined based on descriptiveresources.
In order to make sure the grammars donot reveal unexpected forms of overgeneration, allpossible ungrammatical orders were automaticallygenerated.
Table 3 provides the sizes of the testsuites.
Each language has both a complete set forthe 6 grammars that provide full coverage, and a re-duced set for the 6 grammars that can not handlesplit verbal clusters (see Section 4.3 for the motiva-tion to test grammars that do not have full coverage).7http://www.delph-in.net/matrix/customize/Each grammar was created using the metagram-mar, ensuring that all components except the com-peting analyses were held constant among comparedgrammars.
The [incr tsdb()] competence and per-formance profiling environment (Oepen, 2001) wasused in combination with the LKB to evaluate pars-ing performance of the individual grammars on thetest suites.
For each grammar, the number of re-quired parsing tasks, memory (space) and CPU timeper sentence, as well as the number of passive edgescreated during an average parse were compared.Performance on language generation was evaluatedusing the LKB.5.2 Parsing resultsTable 4 presents the results from the parsing ex-periment.
Note that all directly compared gram-mars have the same empirical coverage (100% cov-erage and 0% overgeneration on the phenomena in-cluded in the test suites).
The comparison there-fore addresses the effect on efficiency of the al-ternative analyses.
Three tests per grammar werecarried out: one on positive data, one on nega-tive data and one on the complete dataset.
Re-sults were similar for all three sets, with slightlylarger differences in efficiency for negative exam-ples.
For reasons of space, only the results on pos-itive examples are presented, which are more rele-vant for most applications involving parsing.
Theresults show that the auxiliary+verb (aux+v) leads toa more efficient grammar according to all measuresused.
There is an average reduction of 73.2% in per-formed tasks, 56.3% in produced passive edges and32.9% in memory when parsing grammatical exam-ples using the auxiliary+verb structure compared toargument-composition.
CPU-time per sentence alsoimproved significantly, but, due to the short averagesentence length (5-10 words) the value is too smallfor exact comparison with [incr tsdb()].5.3 Sentence generation evaluationThe complete coverage versions of Dutch and Ger-man were used to create the exhaustive set of sen-tences with an intransitive, transitive and ditransitiveverb combined with none, one or two auxiliaries butrapidly loses ground when one or more auxiliaries88All auxiliaries in the grammars contribute an ep.1071Average Performed TasksCompl.
Cov.
Gram.
No Split Cl.
Gram.arg-comp aux+v arg-comp aux+vDu 524 149 480 134Fl 529 150 483 137Ge 684 148 486 136Average Created EdgesCompl.
Cov.
Gram.
No Split Cl.
Gram.arg-comp aux+v arg-comp aux+vDu 58 25 52 25Fl 58 26 52 25Ge 67 23 52 24Average Memory Use (kb)Compl.
Cov.
Gram.
No Split Cl.
Gram.arg-comp aux+v arg-comp aux+vDu 9691 6692 8944 6455Fl 9716 6717 8989 6504Ge 10289 5675 8315 5468Average CPU Time (s)Compl.
Cov.
Gram.
No Split Cl.
Gram.arg-comp aux+v arg-comp aux+vDu 0.04 0.02 0.03 0.01Fl 0.04 0.02 0.03 0.01Ge 0.06 0.01 0.04 0.01Table 4: Parsing results positive examplesfrom a total of 18 MRSs.
The input MRSs were ob-tained by parsing a sentence with canonical word or-der.
Both versions provide the same set of sentencesas output, confirming their identical empirical cover-age.
Table 5 presents the number of edges requiredby the generator to produce the full set of generatedsentences from a given MRS.
The cells with no num-ber represent conditions under which the LKB gen-erator reaches the maximum limit of edges, set at40,000, without completing its exhaustive search.The grammar using argument-composition isslightly more efficient when there are no aux-iliaries, are added, in particular when sentencelength increases: For ditransitive verbs (dv), theDutch argument-composition grammar maxes outthe 40,000 edge limit with two auxiliaries, whereasthe auxiliary+verb grammar creates 910 edges, amanageable number.
Due to the more liberal orderof arguments, results are even worse for German:the argument-composition grammar reaches its limitwith the first auxiliary for ditransitive verbs.
Theseresults indicate that the auxiliary+verb analysis isRequired edgesDu No Aux 1 Aux 2 Auxarg-c aux+v arg-c aux+v arg-c aux+viv 54 57 221 99 792 248tv 124 141 1311 211 7455 500dv 212 230 14968 378 ?
910Ge No Aux 1 Aux 2 Auxarg-c aux+v arg-c aux+v arg-c aux+viv 54 57 295 84 1082 165tv 130 142 4001 212 18473 422dv 306 351 ?
608 ?
1379Table 5: Performance on Sentence Generationstrongly preferable where natural language genera-tion is concerned.5.4 In summaryThe results of the experiment presented above showthat avoiding underspecified subcategorization lists,as found in the standard argument-composition anal-ysis, significantly increases the efficiency of thegrammar for both parsing and generation.
On av-erage, they show a reduction of 73.2% in performedtasks, 56.3% in produced passive edges and 32.9%in memory for parsing.
In generation experiments,results are even more impressive: the reduction ofedges for German sentences with one auxiliary anda ditransitve verb is at least 98.5%.
These resultsshow that the auxiliary+verb alternative should beconsidered seriously as an alternative to the HPSGstandard analysis of argument-composition, thoughfurther investigation in a larger context is needed be-fore final conclusions can be drawn.Future work will focus on increasing the cover-age of the grammars, as well as the number of al-ternative options explored.
In particular, both ap-proaches for auxiliaries should be compared us-ing alternative analyses for verb-second word orderfound in other HPSG-based grammars, such as theGG (Mu?ller and Kasper, 2000; Crysmann, 2005),Grammix (Mu?ller, 2009; Mu?ller, 2008) and Cheetah(Cramer and Zhang, 2009) for German, and Alpino(Bouma et al, 2001) for Dutch.
These grammarsmay use approaches that somewhat reduce the prob-lem of argument-composition, leading to less sig-nificant differences between the auxiliary+verb andargument-composition analyses.
On the other hand,planned extensions that cover modification and sub-1072ordinate clauses will increase local ambiguities.
Theadvantage of the auxiliary+verb analysis is likely tobecome more important as a result.In addition to providing a clearer picture of aux-iliary structures, these extensions will also lead toa better insight into efforts involved in using gram-mar generation to explore alternative versions of agrammar over time.
In particular, it should pro-vide an indication of the feasibility of maintaininga higher number of competing analyses as the gram-mar grows.
After providing background on relatedmetagrammar projects and their goals, I will elabo-rate on the importance of systematic exploration ofgrammars in the discussion.6 Related workMetagrammars (or grammar generators) have beenestablished in the field for over a decade.
This sec-tion provides an overview of the goals and set-up ofsome of the most notable projects.The MetaGrammar project (Candito, 1998; de laClergerie, 2005; Kinyon et al, 2006) started asan effort to encode syntactic knowledge in an ab-stract class hierarchy.
The hierarchy can containcross-linguistically invariable properties and syntac-tic properties that hold across frameworks (Kinyonet al, 2006).
The factorized descriptions of Meta-Grammar support Tree-Adjoining Grammars (Joshiet al, 1975, TAG) as well as Lexical FunctionalGrammars (Bresnan, 2001, LFG).
The eXtensibleMetaGrammar (Crabbe?, 2005, XMG) defines itsMetaGrammar as classes that are part of a multipleinheritance hierarchy.
Kinyon et al (Kinyon et al,2006) use XMG to perform a cross-linguistic com-parison of verb-second structures.
Their study fo-cuses on code-sharing between the languages, butdoes not address the problem of competing analysesinvestigated in this paper.The GF Resource Grammar Library (Ranta, 2009)is a multi-lingual linguistic resource that contains aset of syntactic analyses implemented in GF (Gram-matical Framework).
The purpose of the library isto allow engineers working on NLP applications towrite simple grammar rules that can call more com-plex syntactic implementations from the grammar li-brary.
The grammar library is written by researcherswith linguistic expertise.
It makes extensive use ofcode sharing: general categories and constructionsthat are used by all languages are implemented ina core syntax grammar.
Each language9 has its ownlexicon and morphology, as well as a set of languagespecific syntactic structures.
Code sharing also takesplace between the subset of languages explored, inparticular by means of common modules for Ro-mance languages and for Scandanavian languages.PAWS creates PC-PATR (McConnel, 1995) gram-mars based on field linguists?
input.
The mainpurpose of PAWS lies in descriptive grammar writ-ing and ?computer-assisted related language adap-tation?, where the grammar is used to map wordsfrom a text in a source language to a target language.PAWS differs from the other projects discussed here,because grammar engineering or syntactic researchare not the main focus of the project.The LinGO Grammar Matrix, described in Sec-tion 2.1, is most closely related to the work pre-sented in this paper.
Like the other projects reviewedhere, the Grammar Matrix does not offer alterna-tive analyses for the same phenomenon.
Moreover,starter grammars created by the Grammar Matrix aredeveloped manually and individually after their cre-ation.
The approach taken in this paper differs fromthe original goal of the Grammar Matrix in that itcontinues the development of new grammars withinthe system, introducing a novel application for meta-grammars.
By using a metagrammar to store alter-native analyses, grammars can be explored system-atically over time.
As such, the paper introduces anovel methodology for grammar engineering.
Thediscussion and conclusion will elaborate on the ad-vantages of the approach.7 Discussion and conclusion7.1 The challenge of choosing the right analysisAs mentioned in the introduction, most phenomenain natural languages can be accounted for by morethan one formal analysis.
An engineer may imple-ment alternative solutions and test the impact on thegrammar concerning interaction with other phenom-ena (Bierwisch, 1963; Mu?ller, 1999; Bender, 2008;Bender et al, 2011) and efficiency to decide betweenanalyses.9Ranta (Ranta, 2009) reports that GF is developed for four-teen languages, and more are under development.1073However, it is not feasible to carry out compara-tive tests by manually creating different versions of agrammar every time a decision about an implemen-tation is made.
Moreover, even if such a study werecarried out at each stage, only the interaction withthe current state of the grammar would be tested.This has two undesirable consequences.
First, op-tions may be rejected that would have worked per-fectly well if different decisions had been made inthe past.
Second, because each decision is onlybased on the current state of the grammar, the result-ing grammar is partially (or even largely) a productof the order in which phenomena are treated.10For grammar engineers with practical applica-tions in mind, this is undesirable because the re-sulting grammar may end up far from optimal.
Forgrammar writers that use engineering to find validlinguistic analyses, the problem is even more seri-ous: if there is a truth in a declarative grammar,surely, this should not depend on the order in whichphenomena are treated.7.2 Metagrammar engineeringThis paper proposes to systematically explore anal-yses throughout the development of a grammar bywriting a metagrammar (or grammar generator),rather than directly implementing the grammar.
Ametagrammar can contain several different analysesfor the same phenomenon.
After adding a new phe-nomenon to the metagrammar, the engineer can au-tomatically generate versions of the grammar con-taining different combinations of previous analyses.As a result, the engineer can not only systematicallyexplore how alternative analyses interact with thecurrent grammar, but also continue to explore inter-actions with phenomena added in the future.
Espe-cially for alternative approaches to basic propertiesof the language, such as the auxiliary-verb structuresexamined in this study, parallel analyses may pre-vent the cumbersome scenario of changing a deeplyembedded property of a large grammar.An additional advantage is that the engineer canuse the methodology to make different versions ofthe grammar depending on its intended application.10It is, of course, possible to go back and change old anal-yses based on new evidence.
In practice, the large effort in-volved will only be undertaken if the advantages are apparentbeforehand.For instance, it is possible to develop a highly re-stricted version for grammar checking that providesdetailed feedback on detected errors (Bender et al,2004), next to a version with fewer constraints toparse open text.As far as finding optimal solutions is concerned,it must be noted that this approach does not guar-antee a perfect result, partially because there is noguarantee the grammar engineer will think of theperfect solution for each phenomenon, but mainlybecause it is not maintainable to implement all pos-sible alternatives for each phenomenon and makethem interact correctly with all other variations inthe grammar.
The grammar engineer still needs todecide which alternatives are the most promisingand therefore the most important to implement andmaintain.
The resulting grammar therefore partiallyremains a result of the order in which phenomenaare implemented.
Nevertheless, the grammar engi-neer can keep and try out solutions in parallel fora longer time, increasing the possibility of explor-ing more alternative versions of the grammar.
Theseadditional investigations allow for better informeddecisions to stop exploring certain analyses.
In ad-dition, by breaking up analyses into possible alter-natives, chances are that the resulting metagrammarwill be more modular than a directly written gram-mar would have been, which facilitates exploring al-ternatives further.In sum, even though metagrammar engineeringdoes not completely solve the challenge of completeexplorations of a grammar?s possibilities, it does fa-cilitate this process so that finding optimal solutionsbecomes more likely, leading to better supportedchoices among alternatives and a more scientific ap-proach to grammar development.Acknowledgments.The work described in this paper has been sup-ported by the project TAKE (Technologies for Ad-vanced Knowledge Extraction), funded under con-tract 01IW08003 by the German Federal Ministryof Education and Research.
Emily M. Bender, Lau-rie Poulson, Christoph Zwirello, Bart Cramer, KimGerdes and three anonymous reviewers providedvaluable feedback that resulted in significant im-provement of the paper.
Naturally, all remaining er-rors are my own.1074ReferencesEmily M. Bender, Dan Flickinger, and Stephan Oepen.2002.
The grammar matrix: An open-source starter-kit for the rapid development of cross-linguisticallyconsistent broad-coverage precision grammars.
InJohn Carroll, Nelleke Oostdijk, and Richard Sutcliffe,editors, Proceedings of the Workshop on GrammarEngineering and Evaluation at the 19th InternationalConference on Computational Linguistics, pages 8?14, Taipei, Taiwan.Emily M. Bender, Dan Flickinger, Stephan Oepen, An-nemarie Walsh, and Tim Baldwin.
2004.
Arboretum:Using a precision grammar for grammar checking incall.
In Proceedings of the InSTIL/ICAL Symposium:NLP and Speech Technologies in Advance LanguageLearning Systems, Venice, Italy.Emily M. Bender, Scott Drellishak, Antske Fokkens,Laurie Poulson, and Safiyyah Saleem.
2010.
Gram-mar customization.
Research on Language & Compu-tation, 8(1):23?72.Emily M. Bender, Dan Flickinger, and Stephan Oepen.2011.
Grammar engineering and linguistic hypoth-esis testing.
In Emily M. Bender and Jennifer E.Arnold, editors, Language from a Cognitive Perspec-tive: Grammar, Usage and Processing, pages 5?29.Stanford: CSLI Publications, Palo Alto, USA.Emily M. Bender.
2008.
Grammar engineering forlinguistic hypothesis testing.
In Nicholas Gaylord,Alexis Palmer, and Elias Ponvert, editors, Proceedingsof the Texas Linguistics Society X Conference: Compu-tational Linguistics for Less-Studied Languages, pages16?36, Stanford.
CSLI Publications.Emily M. Bender.
2010.
Reweaving a grammar forWambaya: A case study in grammar engineering forlinguistic hypothesis testing.
Linguistic Issues in Lan-guage Technology, 3(3):1?34.Manfred Bierwisch.
1963.
Grammatik des deutschenVerbs, volume II of Studia Grammatica.
AkademieVerlag.Gosse Bouma, Gertjan van Noord, and Robert Malouf.2001.
Alpino: Wide coverage computational analysisof Dutch.
In Computational Linguistics in the Nether-lands CLIN 2000.Joan Bresnan.
2001.
Lexical Functional Syntax.
Black-well Publishers, Oxford.Marie-Helene Candito.
1998.
Building parallel LTAGfor French and Italian.
In Proceedings of the 36thAnnual Meeting of the Association for Computa-tional Linguistics and 17th International Conferenceon Computational Linguistics, Volume 1, pages 211?217, Montreal, Quebec, Canada.
Association for Com-putational Linguistics.John Carroll and Stephan Oepen.
2005.
High efficiencyrealization for a wide-coverage unification grammar.In IJCNLP, Jeju Island.
Springer-Verlag LNCS.Ann Copestake, Dan Flickinger, Carl Pollard, and IvanSag.
2005.
Minimal recursion semantics.
an introduc-tion.
Journal of Research on Language and Computa-tion, 3(2?3):281 ?
332.Ann Copestake.
2002.
Implementing Typed FeatureStructure Grammars.
CSLI Publications, Stanford,CA.Beno?
?t Crabbe?.
2005.
Repre?sentation modulaireet parame?trable de grammaires e?lectroniques lexi-calise?es.
Ph.D. thesis, Universite?
de Paris 7.Bart Cramer and Yi Zhang.
2009.
Constructon of aGerman HPSG grammar from a detailed treebank.
InProceedings of the ACL 2009 Grammar Engineeringacross Frameworks workshop, pages 37?45, Singa-pore, Singapore.Berthold Crysmann.
2005.
Relative clause extrapositionin German: An efficient and portable implementation.Research on Language and Computation, 3(1):61?82.
?Eric Villemonte de la Clergerie.
2005.
From metagram-mars to factorized TAG/TIG parsers.
In Proceedingsof IWPT?05, pages 190?191.Erich Drach.
1937.
Grundgedanken der Deutschen Sat-zlehre.
Diesterweg, Frankfurt am Main, Germany.Oskar Erdmann.
1886.
Grundzu?ge der deutschen Syntaxnach ihrer geschichtlichen Entwicklung dargestellt.Erste Abteilung.
Verlag der Cotta?schen Buchhand-lung, Stuttgart, Germany.Walter Haeseryn.
1997.
De gebruikswaarde van deans voor tekstschrijvers, taaltrainers en taaladviseurs.Tekst[blad], 3.Erhard Hinrichs and Tsuneko Nakazawa.
1994.
Lin-earizing auxs in German verbal complexes.
In JohnNerbonne, Klaus Netter, and Carl Pollard, editors,German in HPSG.
CSLI, Stanford, USA.Aravind K. Joshi, Leon S. Levy, and Masako Takahashi.1975.
Tree adjunct grammars.
Journal of Computerand System Sciences, 10(1):136?163.Andreas Kathol.
2000.
Linear Syntax.
Oxford Press.Alexandra Kinyon, Owen Rambow, Tatjana Scheffler,SinWon Yoon, and Aravind K. Joshi.
2006.
The meta-grammar goes multilingual: A cross-linguistic look atthe V2-phenomenon.
In Proceedings of the Eighth In-ternational Workshop on Tree Adjoining Grammar andRelated Formalisms, pages 17?24, Sydney, Australia.Association for Computational Linguistics.Stephen McConnel.
1995.
PC-PATR reference manual.Stefan Mu?ller and Walter Kasper.
2000.
HPSG analy-sis for German.
In Wolfgang Wahlster, editor, Verb-mobil: Foundations of Speech-to-Speech translation,pages 238 ?
253, Berlin, Germany.
Springer.1075Stefan Mu?ller.
1999.
Deutsche Syntax deklarativ.
Head-Driven Phrase Structure Grammar fu?r das Deutsche.Max Niemeyer Verlag, Tu?bingen.Stefan Mu?ller.
2008.
Depictive secondary predicates ingerman and english.
In Christoph Schroeder, GerdHentschel, and Winfried Boeder, editors, SecondaryPredicates in Eastern European Languages and Be-yond, number 16 in Studia Slavica Oldenburgensia,pages 255?273, Oldenburg, Germany.
BIS-Verlag.Stefan Mu?ller.
2009.
On predication.
In Stefan Mu?ller,editor, Proceedings of the 16th International Con-ference on Head-Driven Phrase Structure Grammar,Stanford, USA.
CSLI Publications.Stephan Oepen.
2001.
[incr tsdb()] ?
competenceand performance laboratory.
Technical report, DFKI,Saarbru?cken, Germany.Aarne Ranta.
2009.
The GF resource grammar library.Linguistic Issues in Language Technology, 2(2).1076
