Mapping Multilingual Hierarchies Using Relaxation LabelingJ.
Daud6, L. Padr6 &: G. RigauTALP Research CenterDepartament de Llenguatges i Sistemes Inform?ticsUniversitat Politbcnica de Catalunya.
Barcelona(daude,  padro ,  g. r igau}?ls i ,  upc.
esAbstractThis paper explores the automatic onstructionof a multilingual Lexical Knowledge Base frompre-existing lexical resources.
We present a newand robust approach for linking already existinglexical/semantic hierarchies.
We used a con-straint satisfaction algorithm (relaxation label-ing) to select -among all the candidate trans-lations proposed by a bilingual dictionary- theright English WordNet synset for each sense ina taxonomy automatically derived from a Span-ish monolingua\] dictionary.
Although on aver-age, there are 15 possible WordNet connectionsfor each sense in the taxonomy, the methodachieves an accuracy over 80~.
Finally, we alsopropose several ways in which this techniquecould be applied to enrich and improve exist-ing lexical databases.1 IntroductionThere is an increasing need of having availablegeneral, accurate and broad coverage multilin-gual lexical/semantic resources for developingNL applications.
Thus, a very active field in-side NL during the last years has been the fastdevelopment of generictanguage resources.Several attempts have been performed to pro-duce multilingual ontologies.
In (Ageno et al,1994), a Spanish/English bilingual dictionary isused to (semi)automatically ink Spanish andEnglish taxonomies extracted from DGILE (A1-var, 1987) and LDOCE (Procter, 1987).
Sim-ilarly, a simple automatic approach for link-ing Spanish taxonomies extracted from DGILEto WordNet (Miller et al, 1991) synsets isproposed in (Rigau et al, 1995).
The workreported in (Knight and Luk, 1994) focuseson the construction of Sensus, a large knowl-edge base for supporting the Pangloss machinetranslation system.
In (Okumura and Hovy,1994) (semi)automatic methods for associatinga Japanese lexicon to an English ontology us-ing a bilingual dictionary are described.
Sev-eral experiments aligning EDR and WordNet on-tologies are described in (Utiyama and Hasida,1997).
Several exical resources and techniquesare combined in (Atserias et al, 1997) to mapSpanish words from a bilingual dictionary toWordNet, and in (Farreres et al, 1998) theuse of the taxonomic structure derived from amonolingual MaD is proposed as an aid to thismapping process.This paper presents a novel approach formerging already existing hierarchies.
Themethod has been applied to attach substan-tial fragments of the Spanish taxonomy derivedfrom DGILE (Rigau et al, 1998) to the EnglishWordNet using a bilingual dictionary for con-necting both hierarchies.This paper is organized as follows: In section2 we describe the used technique (the relaxationlabeling algorithm) and its application to hier-archy mapping.
In section 3 we describe theconstraints used in the relaxation process, andfinally, after presenting some experiments andpreliminary results, we offer some conclusionsand outline further lines of research.2 Application of RelaxationLabeling to NLPRelaxation labeling (RL) is a generic name fora family of iterative algorithms which performfunction optimization, based on local informa-tion.
See (Torras, 1989) for a summary.
Itsmost remarkable feature is that it can deal withany kind of constraints, thus, the model can beimproved by adding any constraints available,and the algorithm is independent of the com-plexity of the model.
That is, we can use moresophisticated constraints without changing the12algorithm.The algorithm has been applied to POS tag-ging (Mkrquez and Padrd, 1997), shallow pars-ing (Voutilainen and Padrd, 1997) and to wordsense disambiguation (Padrd, 1998).Although ocher function optimization algo-rithms could have been used (e.g.
genetic algo-rithms, simmulated annealing, etc.
), we foundRL to be suitable to our purposes, given its abil-ity to use models based on context constraints,and the existence of previous work on applyingit to NLP tasks.Detailed explanation of the algorithm can befound in (Torras, 1989), while its applicationto NLP tasks, advantages and drawbacks areaddressed in (padrS, 1998).2.1 A lgor i thm Descr ip t ionThe Relaxation Labeling algorithm deals witha set of variables (which may represent words,synsets, etc.
), each of which may take oneamong several different labels (POS tags, senses,MaD entries, etc.).
There is also a set of con-straints which state compatibility or incompat-ibility of a combination of pairs variable-label.The aim of the algorithm is to find a weightassignment for each possible label for each vari-able, such that (a) the weights for the labels ofthe same variable add up to one, and (b) theweight assignation satisfies -to the maximumpossible extent- the set of constraints.Summarizing, the algorithm performs con-straint satisfaction to solve a consistent labelingproblem.
The followed steps are:1.2.Start with a random weight assignment.Compute the support value for each labelof each variable.
Support is computed ac-cording to the constraint set and to the cur-rent weights for labels belonging to contextvariables...Increase the weights of the labels morecompatible with the context (larger sup-port) and decrease those of the less com-patible labels (smaller support).
Weightsare changed proportionally to the supportreceived from the context.If a stopping/convergence criterion is sat-isfied, stop, otherwise go to step 2.
Weuse the criterion of stopping when there areno more changes, although more sophisti-cated heuristic procedures may also be usedto stop relaxation processes (Eklundh andRosenfeld, 1978; Richards et al, 1981).The cost of the algorithm is proportional tothe product of the number of variables by thenumber of constraints.2.2 Appl icat ion  to taxonomy mapp ingAs described in previous sections, the problemwe are dealing with is to map two taxonomies.That is:?
The starting point is a sense disam-biguated Spanish taxonomy-automatical lyextracted from a monolingual dictionary(Rigau et al, 1998)-.?
We have a conceptual taxonomy (e.g.WordNet (Miller et al, 1991)), in whichthe nodes represent concepts, organized assynsets.?
We want to relate both taxonomies in orderto have an assignation of each sense of theSpanish taxonomy to a WN synset.The modeling of the problem is the following:?
Each sense in the Spanish taxonomy is avariable for the relaxation algorithm.?
The possible labels for that variable, areall the WN synsets which contain a wordthat is a possible translation of the Span-ish sense.
Thus, we will need a bilingualdictionary to know all the possible trans-lations for a given Spanish word.
This hasthe effect of losing the sense information wehad in the Spanish taxonomy.?
The algorithm will need constraints statingwhether a synset is a suitable assignmentfor a sense.
These constraints will rely onthe taxonomy structure.
Details are givenin section 3.3 The  Const ra in tsConstraints are used by relaxation labeling al-gorithm to increase or decrease the weight for avariable label.
In our case, constraints increasethe weights for the connections between a sensein the Spanish taxonomy and a WordNet synset.Increasing the weight for a connection implies13decreasing the weights for all the other possi-ble connections for the same node.
To increasethe weight for a connection, constraints look fora.lready connected nodes that have the same re-lationships in both taxonomies.Although there is a wide range of relation-ships between WordNet synsets which can beused to build constraints, we have focused onthe hyper/hyponym relationships.
That is, weincrease the weight for a connection when theinvolved nodes have hypernyms/hyponyms al oconnected.
We consider hyper/hyponym rela-tionships either directly or indirectly (i.e.
an-cestors or descendants), depending on the kindof constraint used.Figure 1 shows an example of possible con-nections between two taxonomies.
ConnectionCh will have its weight increased ue to C5, C6and C1, while connections C2 and Ca will havetheir weights decreased.o/ \ /  V \--:: .
.
.
.
.
.
.
.
.
.
._o/2\o?
I""-.
..... :.-;.L-;L-L--:.. o / ; \oFigure 1: Example of connections between tax-onolnies.Constraints are coded with three charactersxYz, which are read as follows: The last char-acter, z, indicates whether the constraints re-quires the existence of a connected hypernym(~), hyponym (o), or both (S).
The two firstcharacters indicate how the hyper/hyponym re-lationship is considered in the Spanish taxon-omy (character x) and in WordNet (charac-ter ?
): (I) indicates that only immediate hy-per/hyponym atch, and (A) indicates that anyancestor/descendant matches.Thus, we have constraints IIE/nO which in-crease the weight for a connection between aSpanish sense and a WordNet synset when thereis a connection between their respective hyper-nyms/hyponyms.
Constraint Im requires the si-multaneous satisfaction of IIE and II0.Similarly, we have constraints IAE/IAO, whichincrease the weight for a connection between aSpanish sense and a WordNet synset when thereis a connection between the immediate hyper-nym/hyponym of the Spanish sense and any an-cestor/descendant of he WN synset.
ConstraintIAB requires the simultaneous satisfaction of IAEand IAO.
Symmetrically, constraints AtE, A10and AIB, admit recursion on the Spanish taxon-omy, but not in WordNet.Finally, constraints AAE, AAO and AAB, admitrecursion on both sides.For instance, the following example shows ataxonomy in which the IIE constraint wouldbe enough to connect the Spanish node ra-paz to the <bird_of_prey> synset, given thatthere is a connection between ave (hypernymof rapaz) and animal <bird> (hypernym of< bird_of_prey>).animal --4-(Tops < animM, animate_being,...> )- -4.
(person <beast, brute,...>)-.---4.
(person <dunce, blockhead .... >)ave ==>(animal <bird>):.
(animal <fowl,poultry,...>). '
.
(a r t i fact  <bird,shuttle ....>).. >(food <fowl,poultry,...>): >(person <dame, doll,...>)faisan :.
(animal <pheasant>)===~ (food <pheasant>)rapaz ==~(emimal <bird_of_prey,...>)==->(person <cub,lewd,...>)==-~ (person <chap,fellow,...>)==~ (pers on < lass,young_girl,... >)Constraint lIE would -wrongly-  connect theSpanish sense faisgn to the food <pheasant>synset, since there is a connection between itsimmediate hypernym (ave) and the immedi-ate hypernym food <pheasant> (which is food<fowl,poultry,...>), but the animal synsets forave are non-immediate ancestors of the animalsynsets for <pheasant>.
This would be rightlysolved when using IAE or AAE constraints.More information on constraints and their ap-plication can be found in (Daud~ et al, 1999).4 Exper iments  and Resul tsIn this section we will describe a set of experi-ments and the results obtained.
A brief descrip-tion of the used resources is included to set thereader in the test environment.144.1 Spanish TaxonomiesWe tested the relaxation labeling algorithmwith the described constraints on a set ofdisambiguated Spanish taxonomies automat-ically acquired from monolingual dictionar-ies.
These taxonomies were automatically as-signed to a WordNet semantic file (Rigau etal., 1997; Rigau et al, 1998).
We testedthe performance of the method on two dif-ferent kinds of taxonomies: those assignedto a well defined and concrete semantic files(noun.
animal, noun.
food), and those assignedto more abstract and less structured ones(noun.
cogn i t ion  and noun.
communication).We performed experiments directly on thetaxonomies extracted by (Rigau et al, 1997),as well as on slight variations of them.
Namely,we tested on the following modified taxonomies:+top  Add a new virtual top as an hypernymof all the top nodes of taxonomies belong-ing to the same semantic file.
The virtualtop is connected to the top synset of theWordNet semantic file.
In this way, all thetaxonomies assigned to a semantic file, are?
converted to a single one.no-senses The original taxonomies were builttaking into account dictionary entries.Thus, the nodes are not words, but dictio-nary senses.
This test consists of collaps-ing together all the sibling nodes that havethe same word, regardless of the dictionarysense they came from.
This is done as anattempt to minimize the noise introducedat the sense level by the taxonomy buildingprocedure.4.2 Bil ingual dictionariesThe possible connections between a node in theSpanish taxonomy and WN synsets were ex-tracted from bilingual dictionaries.
Each nodehas as candidate connections all the synsets forall the words that are possible translations forthe Spanish word, according to the bilingualdictionary.
Although the Spanish taxonomynodes are dictionary senses, bilingual dictionar-ies translate words.
Thus, this step introducesnoise in the form of irrelevant connections, incenot all translations necessarily hold for a singledictionary sense.We used an integration of several bilingualsources availabl'e.
This multi-source dictionarycontains 124,949 translations (between 53,830English and 41,273 Spanish nouns).Since not all words in the taxonomy appear inour bilingual dictionaries, coverage will be par-tial.
Table 1 shows the percentage of nodes ineach taxonomy that appear in the dictionaries(and thus, that may be connected to WN).Among the words that appear in the bilingualdictionary, some have only one candidate con-nection -i.e.
are monosemous-.
Since selectinga connection for these cases is trivial, we will fo-cus on the polysemic nodes.
Table 2 shows thepercentage of polysemic nodes (over the num-ber of words with bilingual connection) in eachtest taxonomy.
The average polysemy ratio(number of candidate connections per Spanishsense) is 15.8, ranging from 9.7 for taxonomiesin noun.
animal, to 20.1 for less structured o-mains such as noun.
communication.4.3 ResultsIn the performed tests we used simultaneouslyall constraints with the same recursion pattern.This yields the packs: II*, AI*, IA* and AA*,which were applied to all the taxonomies for thefour test semantic files.Table 3 presents coverage figures for the dif-ferent test sets, computed as the amount ofnodes for which some constraint is applied andthus their weight assignment is changed.
Per-centage is given over the total amount of nodeswith bilingual connections.To evaluate the precision of the algorithm, wehand checked the results for the original tax-onomies, using AA* constraints.
Precision re-sults can be divided in several cases, dependingon the correctness of the Spanish taxonomiesused as a starting point.ToK, Foh" The Spanish taxonomy was wellbuilt and correctly assigned to the semanticfile.ToK,FNoI~" The Spanish taxonomy was wellbuilt, but wrongly assigned to the semanticfile.TNOI( The Spanish taxonomy was wronglybuilt.In each case, the algorithm selects a conne('-tion for each sense, we will count how manyconnections are right/wrong in the first and s~,c-ond cases.
In the third case the taxonomy wa.~15noun.animalnoun.foodnoun.cognitionnoun.communicationoriginal +top no-senses45% 45% 43%55% 56% 52%54% 55% 52%66% 66% 64%Table 1: Percentage of nodes with bilingual connection in each test taxonomy.noun.animalnoun.foodnoun.cognitionnoun.communicationoriginal +top no-senses77% 77% 75%81% 81% 79%74% 74% 72%87% 87% 86%Table 2: Percentage of nodes with more than one candidate connection.wrongly extracted and is nonsense, so the assig-nations cannot be evaluated.Note that we can distinguish right/wrongassignations in the second case because the con-nections are taken into account over the wholeWN, not only on the semantic file being pro-cessed.
So, the algorithm may end up correctlyassigning the words of a hierarchy, even whenit was assigned to the wrong semantic file.
Forinstance, in the hierarchypiel (skin, Fur, peel, pelt)==~marta (sable, marten, coal_back)==~.vison (mink, mink_coat)all words may belong either to the semantic filenoun.
substance  (senses related to fur, pelt) orto noun.animal  (animal, animal_part senses),among others.
The right noun.substancesynsets for each word are selected, since therewas no synset for piel that was ancestor of theanimal senses of marta and visdn.In this case, the hierarchy was well built, andwell solved by the algorithm.
The only mistakewas having assigned it to the noun.animal se-mantic file, so we will count it as a right choiceof the relaxation labeling algorithm, but writeit in a separate column.Tables 4 and 5 show the precision rates foreach original taxonomy.
In the former, fig-ures are given over polysemic words (nodes withmore than one candidate connection).
In thelater, figures are computed overall (nodes withat least one candidate connection).Accuracy is computed at the semantic filelevel, i.e., if a word is assigned a synset of theright semantic file, it is computed as right, oth-erwise, as wrong.To give an idea of the task complexity and thequality of the reported results, even with thissimplified evaluation, consider the following:?
Those nodes with only one possible synsetfor the right semantic file (30% in average,ranging from 22% in noun.
communicationto 45% in noun.animal)  are not affectedby the evaluation at the semantic file level.?
The remaining nodes have more thanone possible synset in the right se-mantic file: 6.3 in average (rangingfrom 3.0 for noun.animal  to 8.7 fornoun.
communication).?
Thus ,  we  can consider that we  are eval-uat ing a task easier than the actual one(the actual evaluation wou ld  be per fo rmedat the synset level).
Th is  simplified taskhas an average po lysemy of 6.7 possiblechoices per sense, while the actual task atthe synset level would have 15.8.
Althoughthis situates the baseline of a random as-signment about 15% instead of 6%, it isstill a hard task.5 Conc lus ionsWe have applied the relaxation labeling algo-rithm to assign an appropriate WN synset toeach node of an automatically extracted tax-onomy.
Results for two different kinds of con-ceptual structures have been reported, and theypoint that this may be an accurate and robustmethod (not based on ad-hoc heuristics) to con-nect hierarchies (even in different languages).
'16WN filenoun.animalnoun.foodnoun.cognit ionnoun.communicat iontaxonomyoriginal+topno-sensesoriginal+topno-sensesoriginal+topno-sensesoriginal+topno-sensesII* AI* IA* AA*134 (23%) 135 (23%) 357 (62%) 365 (63%)138 (24%) 143 (25%) 375 (65%) 454 (78%)118 (23%) 119 (20%) 311 (61%) 319 (62%)119 (36%) 130 (39%) 164 (49%) 180 (63%)134 (40%) 158 (47%) 194 (58%) 259 (77%)102 (36%) 111 (39%) 153 (51%) 156 (55%)225 (37%) 230 (38%) 360 (60%) 373 (62%)230 (38%) 240 (40%) 395 (65%) 509 (84%)192 (37%) 197 (38%) 306 (59%) 318 (61%)552 (43%) 577 (45%) 737 (57%)589 (46%) 697 (54%) 802 (62%)485 (43%) 509 (45%) 645 (57%)760 (59%)1136 (88%)668 (59%)Table 3: Coverage of each constraint set for different est sets.animalfoodcognitioncommunicationprecision over precision over total precisionTOK, FOK TOK, FNOK over ToK279 (90%) 30 (91%) 309 (90%)166 (94%) 3 (100%) 169 (94%)198 (67%) 27 (90%) 225 (69%)533 (77%) 40 (97%) 573 (78%)numberof TNOK2324916Table 4: Precision results over polysemic words for the test taxonomies.The experiments performed up to now seemto indicate that:?
The relaxation labeling algorithm is a goodtechnique to link two different hierarchies.For each node with several possible connec-tions, the candidate that best matches thesurrounding structure is selected.?
The only information used by the algorithmare the hyper/hyponymy relationships inboth taxonomies.
These local constraintsare propagated throughout the hierarchiesto produce a global solution.?
There is a certain amount of noise in thedifferent phases of the process.
First, thetaxonomies were automatically acquiredand assigned to semantic files.
Second, thebilingual dictionary translates words, notsenses, which introduces irrelevant candi-date connections.?
The size and coverage of the bilingual dic-tionaries used to establish the candidateconnections i an important issue.
A dic-tionary with larger coverage increases theamount of nodes with candidate connec-tions and thus the algorithm coverage6 P roposa ls  for Fur ther  WorkSome issues to be addressed to improve the al-gorithm performance are the following:?
Further test and evaluate the precision ofthe algorithm.
In this direction we plan-apart from performing wider hand check-ing of the results, both to file and synsetlevel- to use the presented technique to linkWN1.5 with WN1.6.
Since there is alreadya mapping between both versions, the ex-periment would provide an idea of the ac-curacy of the technique and of its applica-bility to different hierarchies of the samelanguage.
In addition, it would constitutean easy way to update existing lexical re-sources.?
Use other relationships apart from hy-per/hyponymy to build constraints to se-lect the best connection (e.g.
sibling.cousin, synonymy, meronymy, etc.).?
To palliate the low coverage of the bilingualdictionaries, candidate translations couldbe inferred from connections of surround-ing senses.
For instance, if a sense has nocandidate connections, but its hypernym17animalfoodcognitioncommunicationprecision over precision over total precisionTOI,;, FOIL TOK, FNOK over Toil424 (93%) 62 (95%) 486 (93%)166 (94%) 83 (100%) 149 (96%)200 (67%) 245 (99%) 445 (82%)536 (77%) 234 (99%) 760 (81%)Table 5: Precision results over all words for the test taxonomies.does, we could consider as candidate con-nections for that node all the hyponyms ofthe synset connected to its hypernym.?
Use the algorithm to enrich the Spanishpart of EuroWordNet axonomy.
It couldalso be applied to include taxonomies forother languages not currently in the SWNproject.In addition, some ideas to further exploit thepossibilities of these techniques are:?
Use EWN instead of WN as the target tax-onomy.
This would largely increase thecoverage, since the candidate connectionsmissing in the bilingual dictionaries couldbe obtained from the Spanish part of EWN,and viceversa.
In addition, it would be use-tiff to detect gaps in the Spanish part ofEWN, since a EWN synset with no Spanishwords in EWN, could be assigned one viathe connections obtained from the bilingualdictionaries.?
Since we are connecting dictionary senses(the entries in the MRD used to build thetaxonomies) to EWN synsets: First of all,we could use this to disambiguate he rightsense for the genus of an entry.
For in-stance, in the Spanish taxonomies, thegenus for the entry queso_l (cheese) is masa(mass) but this word has several dictio-nary entries.
Connecting the taxonomyto EWN, we would be able to find outwhich is the appropriate sense for m~sa,and thusl which is the right genus sense forqueso_l.
Secondly, once we had each dic-tionary sense connected to a EWN synset,we could enrich EWN with the definitionsin the MaD, using them as Spanish glosses.?
Map the Spanish part of EWN to WN1.6.This could be done either directly, or viamapping WN 1.5-WN 1.6.7 AcknowledgmentsThis research as been partially funded by theSpanish Research Department (ITEM ProjectTIC96-1243-C03-03), the Catalan Research De-partment (CREL project), and the UE Com-mission (EuroWordNet LE4003).ReferencesA.
Ageno, I. Castelldn, F. Ribas, G. Rigau,H.
Rodr/guez, and A. Samiotou.
1994.
TGE:Tlink Generation Environment.
In Proceed-ings of the 15th International Conferenceon Computational Linguistics (COLING'9~),Kyoto, Japan.M.
Alvar, editor.
1987.
Diccionario GeneralIlustrado de la Lengua Espafiola VOX.
Biblo-graf S.A, Barcelona, Spain.J.
Atserias, S. Climent, X. Farreres, G. Rigau,and H. Rodrlguez.
1997.
Combining Mul-tiple Methods for the Automatic Construc-tion of Multilingual WordNets.
In proceed-ings of International Conference on RecentAdvances in Natural Language Processing(RANLP'97), Tzigov Chark, Bulgaria.J.
Daud@, L. Padr6, and G. Rigau.
1999.
Exper-iments on Applying Relaxation Labeling toMap Multilingual Hierarchies.
Technical Re-port LSI-99-5-R, Departament de LSI.
Uni-versitat Polit~cnica de Catalunya.J.
O. Eklundh and A. Rosenfeld.
1978.
Con-vergence Properties of Relaxation Labelling.Technical Report 701, Computer ScienceCenter.
University of Maryland.X.
Farreres, G. Rigau, and H. Rodrlguez.
1998.Using WordNet for Building WordNets.
InProceedings of COLING-ACL Workshop onUsage of WordNet in Natural Language Pro-cessing Systems, Montr6al, Canada.K.
Knight and S. Luk.
1994.
Building a Large-Scale Knowledge Base for Machine Transla-tion.
In Proceedings of the American Associ-ation for Artificial Inteligence (AAAI'9~).18L.
Mkrquez and L. Padr6.
1997.
A Flex-ible POS Tagger Using an AutomaticallyAcquired Language Model.
In Proceedingsof the 35th Annual Meeting of the Associ-ation for Computational Linguistics.
JointACL/EACL, pages 238-245, Madrid, Spain,July.G.
A. Miller, R. Beckwith, C. Fellbaum,D.
Gross, and K. Miller.
1991.
Five Paperson WordNet.
International Journal of Lexi-cography.A.
Okumura and E. Hovy.
1994.
Buildingjapanese-english dictionary based on ontol-ogy for machine translation.
In proceedings ofARPA Workshop on Human Language Tech-nology, pages 236-241.L.
Padr6.
1998.
A Hybrid Environment forSyntax-Semantic Tagging.
Phd.
Thesis, Dep.Llenguatges i Sistemes Informktics.
Univer-sitat Polit~cnica de Catalunya, February.http://www.lsi.upc.es/'padro.P.
Procter, editor.
1987.
Longman Dictionaryof Common English.
Longman Group, Hat-low, Essex, England.J.
Richards, D. Landgrebe, and P. Swain.
1981.On the accuracy of pixel relaxation labelling.IEEE Transactions on Systems, Man and Cy-bernetics, 11(4) :303-309.G.
Rigau, H. Rodrlguez, and J. Turmo.
1995.Automatically extracting Translation Linksusing a wide coverage semantic taxonomy.In proceedings 15th International ConferenceAI'95, Montpellier , France.G.
Rigau, J. Atserias, and E. Agirre.
1997.Combining Unsupervised Lexical KnowledgeMethods for Word Sense Disambiguation.
InP.~vceedings of the 35th Annual Meeting ofthe Association for Computational Linguis-tics.
Joint A CL/EA CL, pages 48-55, Madrid,Spain, July.G.
Rigau, H. Rodr/guez, and E. Agirre.1998.
Building Accurate Semantic Tax-onomies fl'om MRDs.
In Proceedings ofCOLING-A CL '98, Montreal, Canada.C.
Torras.
1989.
Relaxation and Neural Learn-ins: Points of Convergence and Divergence.,lournal of Parallel and Distributed Comput-ing, 6:217-244.M.
Utiyama and K. Hasida.
1997.
Bottom-upAlignment of Ontologies.
In Proceedings ofIJCAI workshop on Ontologies and Multilin-gual NLP, Nagoya, Japan.A.
Voutilainen and L. PadrS.
1997.
Developinga Hybrid NP Parser.
In Proceedings of the5th Conference on Applied Natural LanguageProcessing, ANLP, pages 80-87, WashingtonDC.
ACL.19
