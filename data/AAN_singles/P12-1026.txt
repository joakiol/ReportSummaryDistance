Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 242?252,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsCapturing Paradigmatic and Syntagmatic Lexical Relations:Towards Accurate Chinese Part-of-Speech TaggingWeiwei Sun??
and Hans Uszkoreit?
?Institute of Computer Science and Technology, Peking University?Saarbru?cken Graduate School of Computer Science?
?Department of Computational Linguistics, Saarland University?
?Language Technology Lab, DFKI GmbHws@pku.edu.cn, uszkoreit@dfki.deAbstractFrom the perspective of structural linguistics,we explore paradigmatic and syntagmatic lex-ical relations for Chinese POS tagging, an im-portant and challenging task for Chinese lan-guage processing.
Paradigmatic lexical rela-tions are explicitly captured by word cluster-ing on large-scale unlabeled data and are usedto design new features to enhance a discrim-inative tagger.
Syntagmatic lexical relationsare implicitly captured by constituent pars-ing and are utilized via system combination.Experiments on the Penn Chinese Treebankdemonstrate the importance of both paradig-matic and syntagmatic relations.
Our linguis-tically motivated approaches yield a relativeerror reduction of 18% in total over a state-of-the-art baseline.1 IntroductionIn grammar, a part-of-speech (POS) is a linguis-tic category of words, which is generally definedby the syntactic or morphological behavior of theword in question.
Automatically assigning POS tagsto words plays an important role in parsing, wordsense disambiguation, as well as many other NLPapplications.
Many successful tagging algorithmsdeveloped for English have been applied to manyother languages as well.
In some cases, the meth-ods work well without large modifications, suchas for German.
But a number of augmentationsand changes become necessary when dealing withhighly inflected or agglutinative languages, as wellas analytic languages, of which Chinese is the focus?This work is mainly finished when this author (correspond-ing author) was in Saarland University and DFKI.of this paper.
The Chinese language is characterizedby the lack of formal devices such as morphologicaltense and number that often provide important cluesfor syntactic processing tasks.
While state-of-the-art tagging systems have achieved accuracies above97% on English, Chinese POS tagging has proven tobe more challenging and obtained accuracies about93-94% (Tseng et al, 2005b; Huang et al, 2007,2009; Li et al, 2011).It is generally accepted that Chinese POS tag-ging often requires more sophisticated language pro-cessing techniques that are capable of drawing in-ferences from more subtle linguistic knowledge.From a linguistic point of view, meaning arises fromthe differences between linguistic units, includingwords, phrases and so on, and these differences areof two kinds: paradigmatic (concerning substitu-tion) and syntagmatic (concerning positioning).
Thedistinction is a key one in structuralist semiotic anal-ysis.
Both paradigmatic and syntagmatic lexical re-lations have a great impact on POS tagging, becausethe value of a word is determined by the two rela-tions.
Our error analysis of a state-of-the-art ChinesePOS tagger shows that the lack of both paradigmaticand syntagmatic lexical knowledge accounts for alarge part of tagging errors.This paper is concerned with capturing paradig-matic and syntagmatic lexical relations to advancethe state-of-the-art of Chinese POS tagging.
First,we employ unsupervised word clustering to exploreparadigmatic relations that are encoded in large-scale unlabeled data.
The word clusters are then ex-plicitly utilized to design new features for POS tag-ging.
Second, we study the possible impact of syn-tagmatic relations on POS tagging by comparativelyanalyzing a (syntax-free) sequential tagging model242and a (syntax-based) chart parsing model.
Inspiredby the analysis, we employ a full parser to implicitlycapture syntagmatic relations and propose a Boot-strap Aggregating (Bagging) model to combine thecomplementary strengths of a sequential tagger anda parser.We conduct experiments on the Penn ChineseTreebank and Chinese Gigaword.
We implementa discriminative sequential classification model forPOS tagging which achieves the state-of-the-art ac-curacy.
Experiments show that this model are sig-nificantly improved by word cluster features in ac-curacy across a wide range of conditions.
This con-firms the importance of the paradigmatic relations.We then present a comparative study of our taggerand the Berkeley parser, and show that the combi-nation of the two models can significantly improvetagging accuracy.
This demonstrates the importanceof the syntagmatic relations.
Cluster-based featuresand the Bagging model result in a relative error re-duction of 18% in terms of the word classificationaccuracy.2 State-of-the-Art2.1 Previous WorkMany algorithms have been applied to computation-ally assigning POS labels to English words, includ-ing hand-written rules, generative HMM taggingand discriminative sequence labeling.
Such meth-ods have been applied to many other languages aswell.
In some cases, the methods work well withoutlarge modifications, such as German POS tagging.But a number of augmentations and changes becamenecessary when dealing with Chinese that has little,if any, inflectional morphology.
While state-of-the-art tagging systems have achieved accuracies above97% on English, Chinese POS tagging has provento be more challenging and obtains accuracies about93-94% (Tseng et al, 2005b; Huang et al, 2007,2009; Li et al, 2011).Both discriminative and generative models havebeen explored for Chinese POS tagging (Tsenget al, 2005b; Huang et al, 2007, 2009).
Tsenget al (2005a) introduced a maximum entropy basedmodel, which includes morphological features forunknown word recognition.
Huang et al (2007) andHuang et al (2009) mainly focused on the gener-ative HMM models.
To enhance a HMM model,Huang et al (2007) proposed a re-ranking proce-dure to include extra morphological and syntacticfeatures, while Huang et al (2009) proposed a la-tent variable inducing model.
Their evaluations onthe Chinese Treebank show that Chinese POS tag-ging obtains an accuracy of about 93-94%.2.2 Our Discriminative Sequential ModelAccording to the ACL Wiki, all state-of-the-art En-glish POS taggers are based on discriminative se-quence labeling models, including structure percep-tron (Collins, 2002; Shen et al, 2007), maximumentropy (Toutanova et al, 2003) and SVM (Gimnezand Mrquez, 2004).
A discriminative learner is easyto be extended with arbitrary features and thereforesuitable to recognize more new words.
Moreover, amajority of the POS tags are locally dependent oneach other, so the Markov assumption can well cap-tures the syntactic relations among words.
Discrim-inative learning is also an appropriate solution forChinese POS tagging, due to its flexibility to includeknowledge from multiple linguistic sources.To deeply analyze the POS tagging problem forChinese, we implement a discriminative sequentialmodel.
A first order linear-chain CRF modelis used to resolve the sequential classificationproblem.
We choose the CRF learning toolkitwapiti1 (Lavergne et al, 2010) to train models.In our experiments, we employ a feature setwhich draws upon information sources such asword forms and characters that constitute words.To conveniently illustrate, we denote a word infocus with a fixed window w?2w?1ww+1w+2,where w is the current token.
Our features includes:Word unigrams: w?2, w?1, w, w+1, w+2;Word bigrams: w?2 w?1, w?1 w, w w+1, w+1 w+2;In order to better handle unknown words, we extractmorphological features: character n-gram prefixes andsuffixes for n up to 3.2.3 Evaluation2.3.1 SettingPenn Chinese Treebank (CTB) (Xue et al, 2005)is a popular data set to evaluate a number of ChineseNLP tasks, including word segmentation (Sun and1http://wapiti.limsi.fr/243Xu, 2011), POS tagging (Huang et al, 2007, 2009),constituency parsing (Zhang and Clark, 2009; Wanget al, 2006) and dependency parsing (Zhang andClark, 2008; Huang and Sagae, 2010; Li et al,2011).
In this paper, we use CTB 6.0 as the labeleddata for the study.
The corpus was collected duringdifferent time periods from different sources with adiversity of topics.
In order to obtain a representa-tive split of data sets, we define the training, devel-opment and test sets following two settings.
To com-pare our tagger with the state-of-the-art, we conductan experiment using the data setting of (Huang et al,2009).
For detailed analysis and evaluation, we con-duct further experiments following the setting of theCoNLL 2009 shared task.
The setting is provided bythe principal organizer of the CTB project, and con-siders many annotation details.
This setting is morerobust for evaluating Chinese language processingalgorithms.2.3.2 Overall PerformanceTable 1 summarizes the per token classificationaccuracy (Acc.)
of our tagger and results reported in(Huang et al, 2009).
Huang et al (2009) introduceda bigram HMM model with latent variables (BigramHMM-LA in the table) for Chinese tagging.
Com-pared to earlier work (Tseng et al, 2005a; Huanget al, 2007), this model achieves the state-of-the-artaccuracy.
Despite of simplicity, our discriminativePOS tagging model achieves a state-of-the-art per-formance, even better.System Acc.Trigram HMM (Huang et al, 2009) 93.99%Bigram HMM-LA (Huang et al, 2009) 94.53%Our tagger 94.69%Table 1: Tagging accuracies on the test data (setting 1).2.4 Motivating AnalysisFor the following experiments, we only report re-sults on the development data of the CoNLL setting.2.4.1 Correlating Tagging Accuracy with WordFrequencyTable 2 summarizes the prediction accuracy onthe development data with respect to the word fre-quency on the training data.
To avoid overestimat-ing the tagging accuracy, these statistics exclude allpunctuations.
From this table, we can see that wordswith low frequency, especially the out-of-vocabulary(OOV) words, are hard to label.
However, when aword is very frequently used, its behavior is verycomplicated and therefore hard to predict.
A typi-cal example of such words is the language-specificfunction word ??.?
This analysis suggests that amain topic to enhance Chinese POS tagging is tobridge the gap between the infrequent words and fre-quent words.Freq.
Acc.0 83.55%1-5 89.31%6-10 90.20%11-100 94.88%101-1000 96.26%1001- 93.65%Table 2: Tagging accuracies relative to word frequency.2.4.2 Correlating Tagging Accuracy with SpanLengthA word projects its grammatical property to itsmaximal projection and it syntactically governs allwords under the span of its maximal projection.
Thewords under the span of current token thus reflectits syntactic behavior and good clues for POS tag-ging.
Table 3 shows the tagging accuracies relativeto the length of the spans.
We can see that with theincrease of the number of words governed by thetoken, the difficulty of its POS prediction increase.This analysis suggests that syntagmatic lexical re-lations plays a significant role in POS tagging, andsometimes words located far from the current tokenaffect its tagging much.Len.
Acc.1-2 93.79%3-4 93.39%5-6 92.19%7- 94.18%Table 3: Tagging accuracies relative to span length.3 Capturing Paradigmatic Relations viaWord ClusteringTo bridge the gap between high and low fre-quency words, we employ word clustering to acquire244the knowledge about paradigmatic lexical relationsfrom large-scale texts.
Our work is also inspiredby the successful application of word clustering tonamed entity recognition (Miller et al, 2004) anddependency parsing (Koo et al, 2008).3.1 Word ClusteringWord clustering is a technique for partitioning setsof words into subsets of syntactically or semanti-cally similar words.
It is a very useful techniqueto capture paradigmatic or substitutional similarityamong words.3.1.1 Clustering AlgorithmsVarious clustering techniques have been pro-posed, some of which, for example, perform au-tomatic word clustering optimizing a maximum-likelihood criterion with iterative clustering algo-rithms.
In this paper, we focus on distributionalword clustering that is based on the assumption thatwords that appear in similar contexts (especiallysurrounding words) tend to have similar meanings.They have been successfully applied to many NLPproblems, such as language modeling.Brown Clustering Our first choice is the bottom-up agglomerative word clustering algorithm of(Brown et al, 1992) which derives a hierarchicalclustering of words from unlabeled data.
This al-gorithm generates a hard clustering ?
each word be-longs to exactly one cluster.
The input to the algo-rithm is sequences of words w1, ..., wn.
Initially, thealgorithm starts with each word in its own cluster.As long as there are at least two clusters left, the al-gorithm merges the two clusters that maximizes thequality of the resulting clustering.
The quality is de-fined based on a class-based bigram language modelas follows.P (wi|w1, ...wi?1) ?
p(C(wi)|C(wi?1))p(wi|C(wi))where the function C maps a word w to its classC(w).
We use a publicly available package2 (Lianget al, 2005) to train this model.MKCLS Clustering We also do experiments byusing another popular clustering method based on2http://cs.stanford.edu/?pliang/software/brown-cluster-1.2.zipthe exchange algorithm (Kneser and Ney, 1993).The objective function is maximizing the likelihood?ni=1 P (wi|w1, ..., wi?1) of the training data givena partially class-based bigram model of the formP (wi|w1, ...wi?1) ?
p(C(wi)|wi?1)p(wi|C(wi))We use the publicly available implementation MK-CLS3 (Och, 1999) to train this model.We choose to work with these two algorithmsconsidering their prior success in other NLP appli-cations.
However, we expect that our approach canfunction with other clustering algorithms.3.1.2 DataChinese Gigaword is a comprehensive archiveof newswire text data that has been acquired overseveral years by the Linguistic Data Consortium(LDC).
The large-scale unlabeled data we use inour experiments comes from the Chinese Gigaword(LDC2005T14).
We choose the Mandarin news text,i.e.
Xinhua newswire.
This data covers all newspublished by Xinhua News Agency (the largest newsagency in China) from 1991 to 2004, which containsover 473 million characters.3.1.3 Pre-processing: Word SegmentationDifferent from English and other Western lan-guages, Chinese is written without explicit word de-limiters such as space characters.
To find the basiclanguage units, i.e.
words, segmentation is a neces-sary pre-processing step for word clustering.
Previ-ous research shows that character-based segmenta-tion models trained on labeled data are reasonablyaccurate (Sun, 2010).
Furthermore, as shown in(Sun and Xu, 2011), appropriate string knowledgeacquired from large-scale unlabeled data can signif-icantly enhance a supervised model, especially forthe prediction of out-of-vocabulary (OOV) words.In this paper, we employ such supervised and semi-supervised segmenters4 to process raw texts.3.2 Improving Tagging with Cluster FeaturesOur discriminative sequential tagger is easy to be ex-tended with arbitrary features and therefore suitableto explore additional features derived from other3http://code.google.com/p/giza-pp/4http://www.coli.uni-saarland.de/?wsun/ccws.tgz245sources.
We propose to use of word clusters as sub-stitutes for word forms to assist the POS tagger.
Weare relying on the ability of the discriminative learn-ing method to explore informative features, whichplay a central role in boosting the tagging perfor-mance.
5 clustering-based uni/bi-gram features areadded: w?1, w, w+1, w?1 w, w w+1.3.3 EvaluationFeatures Data Brown MKCLSBaseline CoNLL 94.48%+c100 +1991-1995(S) 94.77% 94.83%+c500 +1991-1995(S) 94.84% 94.93%+c1000 +1991-1995(S) - - 94.95%+c100 +1991-1995(SS) 94.90% 94.97%+c500 +1991-1995(SS) 94.94% 94.88%+c1000 +1991-1995(SS) 94.89% 94.94%+c100 +1991-2000(SS) 94.82% 94.93%+c500 +1991-2000(SS) 94.92% 94.99%+c1000 +1991-2000(SS) 94.90% 95.00%+c100 +1991-2004(SS) - - 94.87%+c500 +1991-2004(SS) - - 95.02%+c1000 +1991-2004(SS) - - 94.97%Table 4: Tagging accuracies with different features.
S:supervised segmentation; SS: semi-supervised segmenta-tion.Table 4 summarizes the tagging results on the de-velopment data with different feature configurations.In this table, the symbol ?+?
in the Features col-umn means current configuration contains both thebaseline features and new cluster-based features; thenumber is the total number of the clusters; the sym-bol ?+?
in the Data column means which portion ofthe Gigaword data is used to cluster words; the sym-bol ?S?
and ?SS?
in parentheses denote (s)upervisedand (s)emi-(s)upervised word segmentation.
For ex-ample, ?+1991-2000(S)?
means the data from 1991to 2000 are processed by a supervised segmenterand used for clustering.
From this table, we canclearly see the impact of word clustering features onPOS tagging.
The new features lead to substantialimprovements over the strong supervised baseline.Moreover, these increases are consistent regardlessof the clustering algorithms.
Both clustering algo-rithms contributes to the overall performance equiv-alently.
A natural strategy for extending current ex-periments is to include both clustering results to-gether, or to include more than one cluster granular-ity.
However, we find no further improvement.
Foreach clustering algorithm, there are not much dif-ferences among different sizes of the total clusteringnumbers.
When a comparable amount of unlabeleddata (five years?
data) is used, the further increaseof the unlabeled data for clustering does not lead tomuch changes of the tagging performance.3.4 Learning CurvesSize Baseline +Cluster4.5K 90.10% 91.93%9K 92.91% 93.94%13.5K 93.88% 94.60%18K 94.24% 94.77%Table 5: Tagging accuracies relative to sizes of trainingdata.
Size=#sentences in the training corpus.We do additional experiments to evaluate the ef-fect of the derived features as the amount of la-beled training data is varied.
We also use the?+c500(MKCLS)+1991-2004(SS)?
setting for theseexperiments.
Table 5 summarizes the accuracies ofthe systems when trained on smaller portions of thelabeled data.
We can see that the new features obtainconsistent gains regardless of the size of the trainingset.
The error is reduced significantly on all datasets.
In other words, the word cluster features cansignificantly reduce the amount of labeled data re-quired by the learning algorithm.
The relative reduc-tion is greatest when smaller amounts of the labeleddata are used, and the effect lessens as more labeleddata is added.3.5 AnalysisWord clustering derives paradigmatic relational in-formation from unlabeled data by grouping wordsinto different sets.
As a result, the contribution ofword clustering to POS tagging is two-fold.
Onthe one hand, word clustering captures and abstractscontext information.
This new linguistic knowledgeis thus helpful to better correlate a word in a cer-tain context to its POS tag.
On the other hand, theclustering of the OOV words to some extent fightsthe sparse data problem by correlating an OOV wordwith in-vocabulary (IV) words through their classes.To evaluate the two contributions of the word clus-tering, we limit entries of the clustering lexicon toonly contain IV words, i.e.
words appearing inthe training corpus.
Using this constrained lexicon,246we train a new ?+c500(MKCLS)+1991-2004(SS)?model and report its prediction power in Table 6.The gap between the baseline and +IV clusteringmodels can be viewed as the contribution of the firsteffect, while the gap between the +IV clustering and+All clustering models can be viewed as the secondcontribution.
This result indicates that the improvedpredictive power partially comes from the new in-terpretation of a POS tag through a clustering, andpartially comes from its memory of OOV words thatappears in the unlabeled data.Baseline +IV Clustering +All clusteringAcc.
94.48% 94.70%(?0.22) 95.02%(?0.32)Table 6: Tagging accuracies with IV clustering.Table 7 shows the recall of OOV words on thedevelopment data set.
Only the word types appear-ing more than 10 times are reported.
The recall ofall OOV words are improved, especially of propernouns (NR) and common verbs (VV).
Another in-teresting fact is that almost all of them are contentwords.
This table is also helpful to understand theimpact of the clustering information on the predic-tion of OOV words.4 Capturing Syntagmatic Relations viaConstituency ParsingSyntactic analysis, especially the full and deep one,reflects syntagmatic relations of words and phrasesof sentences.
We present a series of empirical stud-ies of the tagging results of our syntax-free sequen-tial tagger and a syntax-based chart parser5, aimingat illuminating more precisely the impact of infor-mation about phrase-structures on POS tagging.
Theanalysis is helpful to understand the role of syntag-matic lexical relations in POS prediction.4.1 Comparing Tagging and PCFG-LA ParsingThe majority of the state-of-the-art constituentparsers are based on generative PCFG learning, withlexicalized (Collins, 2003; Charniak, 2000) or la-tent annotation (PCFG-LA) (Matsuzaki et al, 2005;Petrov et al, 2006; Petrov and Klein, 2007) refine-ments.
Compared to lexicalized parsers, the PCFG-LA parsers leverages on an automatic procedure to5Both the tagger and the parser are trained on the same por-tion from CTB.#Words Baseline +Clustering ?AD 21 33.33% 42.86% <CD 249 97.99% 98.39% <JJ 86 3.49% 26.74% <NN 1028 91.05% 91.34% <NR 863 81.69% 88.76% <NT 25 60.00% 68.00% <VA 15 33.33% 53.33% <VV 402 67.66% 72.39% <Table 7: The tagging recall of OOV words.learn refined grammars and are therefore more ro-bust to parse non-English languages that are not wellstudied.
For Chinese, a PCFG-LA parser achievesthe state-of-the-art performance and defeat manyother types of parsers (Zhang and Clark, 2009).
Forfull parsing, the Berkeley parser6, an open sourceimplementation of the PCFG-LA model, is used forexperiments.
Table 8 shows their overall and de-tailed performance.4.1.1 Content Words vs. Function WordsTable 8 gives a detailed comparison regarding dif-ferent word types.
For each type of word, we re-port the accuracy of both solvers and compare thedifference.
The majority of the words that are bet-ter labeled by the tagger are content words, includ-ing nouns(NN, NR, NT), numbers (CD, OD), pred-icates (VA, VC, VE), adverbs (AD), nominal modi-fiers (JJ), and so on.
In contrast, most of the wordsthat are better predicted by the parser are functionwords, including most particles (DEC, DEG, DER,DEV, AS, MSP), prepositions (P, BA) and coordi-nating conjunction (CC).4.1.2 Open Classes vs. Close ClassesPOS can be divided into two broad supercate-gories: closed class types and open class types.Open classes accept the addition of new morphemes(words), through such processes as compounding,derivation, inflection, coining, and borrowing.
Onthe other hand closed classes are those that have rel-atively fixed membership.
For example, nouns andverbs are open classes because new nouns and verbsare continually coined or borrowed from other lan-guages, while DEC/DEG are two closed classes be-cause only the function word ???
is assigned to6http://code.google.com/p/berkeleyparser/247Parser<Tagger Parser>Tagger?
AD 94.15<94.71 ?
AS 98.54>98.44?
CD 94.66<97.52 ?
BA 96.15>92.52CS 91.12<92.12 ?
CC 93.80>90.58ETC 99.65<100.0 ?
DEC 85.78>81.22?
JJ 81.35<84.65 ?
DEG 88.94>85.96LB 91.30<93.18 ?
DER 80.95>77.42LC 96.29<97.08 ?
DEV 84.89>74.78M 95.62<96.94 DT 98.28>98.05?
NN 93.56<94.95 ?MSP 91.30>90.14?
NR 89.84<95.07 ?
P 96.26>94.56?
NT 96.70<97.26 VV 91.99>91.87?
OD 81.06<86.36PN 98.10<98.15SB 95.36<96.77SP 61.70<68.89?
VA 81.27<84.25 Overall?
VC 95.91<97.67 Tagger: 94.48%?
VE 97.12<98.48 Parser: 93.69%Table 8: Tagging accuracies of relative to word classes.them.
The discriminative model can convenientlyinclude many features, especially features related tothe word formation, which are important to predictwords of open classes.
Table 9 summarizes the tag-ging accuracies relative to IV and OOV words.
Onthe whole, the Berkeley parser processes IV wordsslightly better than our tagger, but processes OOVwords significantly worse.
The numbers in this ta-ble clearly shows the main weakness of the Berkeleyparser is the the predictive power of the OOV words.IV OOVTagger 95.22% 81.59%Parser 95.38% 64.77%Table 9: Tagging accuracies of the IV and OOV words.4.1.3 Local Disambiguation vs. GlobalDisambiguationClosed class words are generally function wordsthat tend to occur frequently and often have struc-turing uses in grammar.
These words have littlelexical meaning or have ambiguous meaning, butinstead serve to express grammatical relationshipswith other words within a sentence.
They signalthe structural relationships that words have to oneanother and are the glue that holds sentences to-gether.
Thus, they serve as important elements to thestructures of sentences.
The disambiguation of thesewords normally require more syntactic clues, whichis very hard and inappropriate for a sequential taggerto capture.
Based on global grammatical inferenceof the whole sentence, the full parser is relativelygood at dealing with structure related ambiguities.We conclude that discriminative sequential tag-ging model can better capture local syntactic andmorphological information, while the full parser canbetter capture global syntactic structural informa-tion.
The discriminative tagging model are limitedby the Markov assumption and inadequate to cor-rectly label structure related words.4.2 Enhancing POS Tagging via BaggingThe diversity analysis suggests that we may im-prove parsing by simply combining the tagger andthe parser.
Bootstrap aggregating (Bagging) is a ma-chine learning ensemble meta-algorithm to improveclassification and regression models in terms of sta-bility and classification accuracy (Breiman, 1996).
Italso reduces variance and helps to avoid overfitting.We introduce a Bagging model to integrate differentPOS tagging models.
In the training phase, givena training set D of size n, our model generates mnew training sets Di of size 63.2%?
n by samplingexamples from D without replacement.
Namely noexample will be repeated in each Di.
Each Di isseparately used to train a tagger and a parser.
Us-ing this strategy, we can get 2m weak solvers.
In thetagging phase, the 2m models outputs 2m taggingresults, each word is assigned one POS label.
Thefinal tagging is the voting result of these 2m labels.There may be equal number of different tags.
In thiscase, our system prefer the first label they met.4.3 EvaluationWe evaluate our combination model on the samedata set used above.
Figure 1 shows the influenceof m in the Bagging algorithm.
Because each newdata set Di in bagging algorithm is generated by arandom procedure, the performance of all Baggingexperiments are not the same.
To give a more sta-ble evaluation, we repeat 5 experiments for each mand show the averaged accuracy.
We can see thatthe Bagging model taking both sequential taggingand chart parsing models as basic systems outper-form the baseline systems and the Bagging modeltaking either model in isolation as basic systems.
An2489393.59494.59595.51  2  3  4  5  6  7  8  9  10Accuracy(%)Number of sampling data sets mTaggerParserTagger(WC)Tagger-BaggingParser-BaggingTagger+Parser-BaggingTagger(WC)-BaggingTagger(WC)+Parser-BaggingFigure 1: Tagging accuracies of Bagging models.Tagger-Bagging and Tagger(WC)-Bagging means that theBagging system built on the tagger with and withoutword clusters.
Parser-Bagging is named in the same way.Tagger+Paser-Bagging and Tagger(WC)+Paser-Baggingmeans that the Bagging systems are built on both taggerand parser.interesting phenomenon is that the Bagging methodcan also improve the parsing model, but there is adecrease while only combining taggers.5 Combining BothWe have introduced two separate improvements forChinese POS tagging, which capture different typesof lexical relations.
We therefore expect further im-provement by combining both enhancements, sincetheir contributions to the task is different.
We stilluse a Bagging model to integrate the discriminativetagger and the Berkeley parser.
The only differ-ence between current experiment and previous ex-periment is that the sub-tagging models are trainedwith help of word clustering features.
Figure 1 alsoshows the performance of the new Bagging modelon the development data set.
We can see that the im-provements that come from two ways, namely cap-turing syntagmatic and paradigmatic relations, arenot much overlapping and the combination of themgives more.Table 10 shows the performance of different sys-tems evaluated on the test data.
The final result isremarkable.
The word clustering features and theBagging model result in a relative error reduction of18% in terms of the classification accuracy.
The sig-nificant improvement of the POS tagging also helpsuccessive language processing.
Results in TableSystems Acc.Baseline 94.33%Tagger(WC) 94.85%Tagger+Parser(m = 15) 94.96%Tagger(WC)+Parser(m = 15) 95.34%Table 10: Tagging accuracies on the test data (CoNLL).11 indicate that the parsing accuracy of the Berke-ley parser can be simply improved by inputting theBerkeley parser with the POS Bagging results.
Al-though the combination with a syntax-based taggeris very effective, there are two weaknesses: (1) asyntax-based model relies on linguistically rich syn-tactic annotations that are not easy to acquire; (2)a syntax-based model is computationally expensivewhich causes efficiency difficulties.Tagger LP LR FBerkeley 82.71% 80.57% 81.63Bagging(m = 15) 82.96% 81.44% 82.19Table 11: Parsing accuracies on the test data.
(CoNLL)6 ConclusionWe hold a view of structuralist linguistics and studythe impact of paradigmatic and syntagmatic lexicalrelations on Chinese POS tagging.
First, we har-vest word partition information from large-scale rawtexts to capture paradigmatic relations and use suchknowledge to enhance a supervised tagger via fea-ture engineering.
Second, we comparatively analyzesyntax-free and syntax-based models and employ aBagging model to integrate a sequential tagger anda chart parser to capture syntagmatic relations thathave a great impact on non-local disambiguation.Both enhancements significantly improve the state-of-the-art of Chinese POS tagging.
The final modelresults in an error reduction of 18% over a state-of-the-art baseline.AcknowledgementThis work is mainly finished when the first authorwas in Saarland University and DFKI.
At that time,this author was funded by DFKI and German Aca-demic Exchange Service (DAAD).
While workingin Peking University, the first author is supportedby NSFC (61170166) and National High-Tech R&DProgram (2012AA011101).249ReferencesLeo Breiman.
1996.
Bagging predictors.
MachineLearning, 24(2):123?140.Peter F. Brown, Peter V. deSouza, Robert L. Mer-cer, Vincent J. Della Pietra, and Jenifer C. Lai.1992.
Class-based n-gram models of naturallanguage.
Computational Linguistics, 18:467?479.
URL http://portal.acm.org/citation.cfm?id=176313.176316.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.
In Proceedings of the first con-ference on North American chapter of the Associ-ation for Computational Linguistics.Michael Collins.
2002.
Discriminative trainingmethods for hidden markov models: Theoryand experiments with perceptron algorithms.
InProceedings of the 2002 Conference on Empir-ical Methods in Natural Language Processing,pages 1?8.
Association for Computational Lin-guistics.
URL http://www.aclweb.org/anthology/W02-1001.Michael Collins.
2003.
Head-driven statistical mod-els for natural language parsing.
ComputationalLinguistics, 29(4):589?637.Jes?s Gim?nez and Llu?s M?rquez.
2004.Svmtool: A general pos tagger generator basedon support vector machines.
In In Proceedingsof the 4th International Conference on LanguageResources and Evaluation, pages 43?46.Liang Huang and Kenji Sagae.
2010.
Dynamic pro-gramming for linear-time incremental parsing.
InProceedings of the 48th Annual Meeting of theAssociation for Computational Linguistics, pages1077?1086.
Association for Computational Lin-guistics, Uppsala, Sweden.
URL http://www.aclweb.org/anthology/P10-1110.Zhongqiang Huang, Vladimir Eidelman, and MaryHarper.
2009.
Improving a simple bigram hmmpart-of-speech tagger by latent annotation andself-training.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Confer-ence of the North American Chapter of the Asso-ciation for Computational Linguistics, Compan-ion Volume: Short Papers, pages 213?216.
As-sociation for Computational Linguistics, Boulder,Colorado.
URL http://www.aclweb.org/anthology/N/N09/N09-2054.Zhongqiang Huang, Mary Harper, and Wen Wang.2007.
Mandarin part-of-speech tagging and dis-criminative reranking.
In Proceedings of the2007 Joint Conference on Empirical Methodsin Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL), pages 1093?1102.
Association forComputational Linguistics, Prague, Czech Re-public.
URL http://www.aclweb.org/anthology/D/D07/D07-1117.Reinhard Kneser and Hermann Ney.
1993.
Im-proved clustering techniques for class-based sta-tistical language modeling.
In In Proceedings ofthe European Conference on Speech Communica-tion and Technology (Eurospeech).Terry Koo, Xavier Carreras, and Michael Collins.2008.
Simple semi-supervised dependencyparsing.
In Proceedings of ACL-08: HLT,pages 595?603.
Association for Computa-tional Linguistics, Columbus, Ohio.
URLhttp://www.aclweb.org/anthology/P/P08/P08-1068.Thomas Lavergne, Olivier Cappe?, and Franc?oisYvon.
2010.
Practical very large scale CRFs.pages 504?513.
URL http://www.aclweb.org/anthology/P10-1052.Zhenghua Li, Min Zhang, Wanxiang Che, TingLiu, Wenliang Chen, and Haizhou Li.
2011.Joint models for Chinese pos tagging and depen-dency parsing.
In Proceedings of the 2011 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 1180?1191.
Associationfor Computational Linguistics, Edinburgh, Scot-land, UK.
URL http://www.aclweb.org/anthology/D11-1109.Percy Liang, Michael Collins, and Percy Liang.2005.
Semi-supervised learning for natural lan-guage.
In Master?s thesis, MIT.Takuya Matsuzaki, Yusuke Miyao, and Jun?ichiTsujii.
2005.
Probabilistic cfg with latent an-notations.
In Proceedings of the 43rd An-nual Meeting on Association for ComputationalLinguistics, ACL ?05, pages 75?82.
Associa-tion for Computational Linguistics, Stroudsburg,250PA, USA.
URL http://dx.doi.org/10.3115/1219840.1219850.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and dis-criminative training.
In Daniel Marcu Susan Du-mais and Salim Roukos, editors, HLT-NAACL2004: Main Proceedings, pages 337?342.
As-sociation for Computational Linguistics, Boston,Massachusetts, USA.Franz Josef Och.
1999.
An efficient method fordetermining bilingual word classes.
In Pro-ceedings of the ninth conference on Europeanchapter of the Association for ComputationalLinguistics, EACL ?99, pages 71?76.
Associa-tion for Computational Linguistics, Stroudsburg,PA, USA.
URL http://dx.doi.org/10.3115/977035.977046.Slav Petrov, Leon Barrett, Romain Thibaux, andDan Klein.
2006.
Learning accurate, compact,and interpretable tree annotation.
In Proceedingsof the 21st International Conference on Computa-tional Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics, pages433?440.
Association for Computational Linguis-tics, Sydney, Australia.Slav Petrov and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Human Lan-guage Technologies 2007: The Conference of theNorth American Chapter of the Association forComputational Linguistics; Proceedings of theMain Conference, pages 404?411.
Associationfor Computational Linguistics, Rochester, NewYork.Libin Shen, Giorgio Satta, and Aravind Joshi.2007.
Guided learning for bidirectional sequenceclassification.
In Proceedings of the 45th An-nual Meeting of the Association of Computa-tional Linguistics, pages 760?767.
Associationfor Computational Linguistics, Prague, Czech Re-public.
URL http://www.aclweb.org/anthology/P07-1096.Weiwei Sun.
2010.
Word-based and character-based word segmentation models: Compari-son and combination.
In Proceedings of the23rd International Conference on ComputationalLinguistics (Coling 2010), pages 1211?1219.Coling 2010 Organizing Committee, Beijing,China.
URL http://www.aclweb.org/anthology/C10-2139.Weiwei Sun and Jia Xu.
2011.
EnhancingChinese word segmentation using unlabeleddata.
In Proceedings of the 2011 Confer-ence on Empirical Methods in Natural Lan-guage Processing, pages 970?979.
Associationfor Computational Linguistics, Edinburgh, Scot-land, UK.
URL http://www.aclweb.org/anthology/D11-1090.Kristina Toutanova, Dan Klein, Christopher D.Manning, and Yoram Singer.
2003.
Feature-richpart-of-speech tagging with a cyclic dependencynetwork.
In Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human Lan-guage Technology - Volume 1, NAACL ?03, pages173?180.
Association for Computational Linguis-tics, Stroudsburg, PA, USA.
URL http://dx.doi.org/10.3115/1073445.1073478.Huihsin Tseng, Pichuan Chang, Galen Andrew,Daniel Jurafsky, and Christopher Manning.2005a.
A conditional random field word seg-menter.
In In Fourth SIGHAN Workshop on Chi-nese Language Processing.Huihsin Tseng, Daniel Jurafsky, and ChristopherManning.
2005b.
Morphological features helppos tagging of unknown words across languagevarieties.
In The Fourth SIGHAN Workshop onChinese Language Processing.Mengqiu Wang, Kenji Sagae, and Teruko Mitamura.2006.
A fast, accurate deterministic parser forChinese.
In Proceedings of the 21st Interna-tional Conference on Computational Linguisticsand 44th Annual Meeting of the Association forComputational Linguistics, pages 425?432.
As-sociation for Computational Linguistics, Sydney,Australia.
URL http://www.aclweb.org/anthology/P06-1054.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The penn Chinese treebank: Phrasestructure annotation of a large corpus.
NaturalLanguage Engineering, 11(2):207?238.Yue Zhang and Stephen Clark.
2008.
A tale of twoparsers: Investigating and combining graph-based251and transition-based dependency parsing.
In Pro-ceedings of the 2008 Conference on EmpiricalMethods in Natural Language Processing, pages562?571.
Association for Computational Linguis-tics, Honolulu, Hawaii.
URL http://www.aclweb.org/anthology/D08-1059.Yue Zhang and Stephen Clark.
2009.
Transition-based parsing of the Chinese treebank using aglobal discriminative model.
In Proceedingsof the 11th International Conference on Pars-ing Technologies (IWPT?09), pages 162?171.
As-sociation for Computational Linguistics, Paris,France.
URL http://www.aclweb.org/anthology/W09-3825.252
