Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics, pages 42?50Manchester, August 2008Eliciting Subjectivity and Polarity Judgements on Word SensesFangzhong SuSchool of ComputingUniversity of Leedsfzsu@comp.leeds.ac.ukKatja MarkertSchool of ComputingUniversity of Leedsmarkert@comp.leeds.ac.ukAbstractThere has been extensive work on elicit-ing human judgements on the sentimentof words and the resulting annotated wordlists have frequently been used for opin-ion mining applications in Natural Lan-guage Processing (NLP).
However, thisword-based approach does not take differ-ent senses of a word into account, whichmight differ in whether and what kindof sentiment they evoke.
In this paper,we therefore introduce a human annotationscheme for judging both the subjectivityand polarity of word senses.
We show thatthe scheme is overall reliable, making thisa well-defined task for automatic process-ing.
We also discuss three issues that sur-faced during annotation: the role of anno-tation bias, hierarchical annotation (or un-derspecification) and bias in the sense in-ventory used.1 IntroductionWork in psychology, linguistics and computationallinguistics has explored the affective connotationsof words via eliciting human judgements (seeSection 2 for an in-depth review).
Two impor-tant parameters in determining affective meaningthat have emerged are subjectivity and polarity.Subjectivity identification focuses on determiningwhether a language unit (such as a word, sentenceor document) is subjective, i.e.
whether it ex-presses a private state, opinion or attitude, or isfactual.
Polarity identification focuses on whetherc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.a language unit has a positive or negative connota-tion.Word lists that result from such studies would,for example tag good or positive as a positiveword, bad as negative and table as neither.
Suchword lists have frequently been used in natural lan-guage processing applications, such as the auto-matic identification of a review as favourable orunfavourable (Das and Chen, 2001).
However,the word-based annotation conducted so far is atleast partially unreliable.
Thus Andreevskaia andBergler (2006) find only a 78.7% agreement onsubjectivity/polarity tags between two widely usedword lists.
One problem they identify is that word-based annotation does not take different sensesof a word into account.
Thus, many words aresubjectivity-ambiguous or polarity-ambiguous, i.e.have both subjective and objective or both posi-tive and negative senses, such as the words posi-tive and catch with corresponding example sensesgiven below.1(1) positive, electropositive?having a positive electriccharge;?protons are positive?
(objective)(2) plus, positive?involving advantage or good; ?a plus (orpositive) factor?
(subjective)(3) catch?a hidden drawback; ?it sounds good but what?sthe catch??
(negative)(4) catch, match?a person regarded as a good matrimonialprospect (positive)Inspired by Andreeivskaia and Bergler (2006)and Wiebe and Mihalcea (2006), we therefore ex-plore the subjectivity and polarity annotation ofword senses instead of words.
We hypothesizethat annotation at the sense level might eliminateone possible source of disagreement for subjectiv-ity/polarity annotation and will therefore hopefullylead to higher agreement than at the word level.1All examples in this paper are from WordNet 2.0.42An additional advantage for practical purposes isthat subjectivity labels for senses add an additionallayer of annotation to electronic lexica and cantherefore increase their usability.
As an example,Wiebe and Mihalcea (2006) prove that subjectiv-ity information for WordNet senses can improveword sense disambiguation tasks for subjectivity-ambiguous words (such as positive).
In addition,Andreevskaia and Bergler (2006) show that theperformance of automatic annotation of subjectiv-ity at the word level can be hurt by the presence ofsubjectivity-ambiguous words in the training setsthey use.
A potential disadvantage for annotationat the sense level is that it is dependent on a lexicalresource for sense distinctions and that an annota-tion scheme might have to take idiosyncracies ofspecific resources into account or, ideally, abstractaway from them.In this paper, we investigate the reliabilityof manual subjectivity labeling of word senses.Specifically, we mark up subjectivity/attitude (sub-jective, objective, and both) of word senses as wellas polarity/connotation (positive, negative and nopolarity).
To the best of our knowledge, this isthe first annotation scheme for judging both sub-jectivity and polarity of word senses.
We test itsreliability on the WordNet sense inventory.
Over-all, the experimental results show high agreement,confirming our hypothesis that agreement at senselevel might be higher than at the word level.
Theannotated sense inventory will be made publicallyavailable to other researchers at http://www.comp.leeds.ac.uk/markert/data.The remainder of this paper is organized as fol-lows.
Section 2 discusses previous related work.Section 3 describes our human annotation schemefor word sense subjectivity and polarity in detail.Section 4 presents the experimental results andevaluation.
We also discuss the problems of bias inthe annotation scheme, the impact of hierarchicalorganization or underspecification on agreement aswell as problems with bias in WordNet sense de-scriptions.
Section 5 compares our annotation tothe annotation of a different scheme, followed byconclusions and future work in Section 6.2 Related WorkOsgood et al (1957) proposed semantic differ-ential to measure the connotative meaning ofconcepts.
They conducted a factor analysis oflarge collections of semantic differential scales andpointed out three referring attitudes that people useto evaluate words and phrases?evaluation (good-bad), potency (strong-weak), and activity (active-passive).
Also, they showed that these three di-mensions of affective meaning are cross-culturaluniversals from a study on dozens of cultures (Os-good et al, 1975).
This work has spawned a con-siderable amount of linguistic and psychologicalwork in affect analysis on the word level.
In psy-chology both the Affective Norms for EnglishWords (ANEW) project as well as the Magel-lan project focus on collecting human judgementson affective meanings of words, roughly follow-ing Osgood?s scheme.
In the ANEW project theycollected numerical ratings of pleasure (equivalentto our term polarity), arousal, and dominance for1000 English terms (Bradley and Lang, 2006) andin Magellan they collected cross-cultural affectivemeanings (including polarity) in a wide variety ofcountries such as the USA, China, Japan, and Ger-many (Heise, 2001).
Both projects concentrate oncollecting a large number of ratings on a large va-riety of words: there is no principled evaluation ofagreement.The more linguistically oriented projects of theGeneral Inquirer (GI) lexicon2and the Ap-praisal framework3also provide word lists anno-tated for affective meanings but judgements seemto be currently provided by one researcher only.Especially the General Enquirer which contains11788 words marked for polarity (1915 positive,2291 negative and 7582 no-polarity words) seemsto use a relatively ad hoc definition of polarity.Thus, for example amelioration is marked as no-polarity whereas improvement is marked as posi-tive.The projects mentioned above center on subjec-tivity analysis on words and therefore are not goodat dealing with subjectivity or polarity-ambiguouswords as explained in the Introduction.
Work thatlike us concentrates on word senses includes ap-proaches where the subjectivity labels are automat-ically assigned such as WordNet-Affect (Strap-parava and Valitutti, 2004), which is a subset ofWordNet senses with semi-automatically assignedaffective labels (such as emotion, mood or be-haviour).
In a first step, they manually collectan affective word list and a list of synsets whichcontain at least one word in this word list.
Fine-2Available at http://www.wjh.harvard.edu/ inquirer/3Available at http://www.grammatics.com/appraisal/43grained affect labels are assigned to these synsetsby the resource developers.
Then they automati-cally expand the lists by employing WordNet re-lations which they consider to reliably preservethe involved labels (such as similar-to, antonym,derived-from, pertains-to, and attribute).
Our workdiffers from theirs in three respects.
First, theyfocus on their semi-automatic procedure, whereaswe are interested in human judgements.
Second,they use a finer-grained set of affect labels.
Third,they do not provide agreement results for their an-notation.
Similarly, SentiWordNet4is a resourcewith automatically determined polarity of wordsenses in WordNet (Esuli and Sebastiani, 2006),produced via bootstrapping from a small manuallydetermined seed set.
Each synset has three scoresassigned, representing the positive, negative andneutral score respectively.
No human annotationstudy is conducted.There are only two human annotation studieson subjectivity of word senses as far as we areaware.
Firstly, theMicro-WNOp corpus is a list ofabout 1000 WordNet synsets annotated by Ceriniet al (2007) for polarity.
The raters manually as-signed a triplet of numerical scores to each sensewhich represent the strength of positivity, negativ-ity, and neutrality respectively.
Their work dif-fers from us in two main aspects.
First, they fo-cus on polarity instead of subjectivity annotation(see Section 3 for a discussion of the two con-cepts).
Second, they do not use absolute categoriesbut give a rating between 0 and 1 to each synset?thus a synset could have a non-zero rating on bothnegativity and positivity.
They also do not reporton agreement results.
Secondly, Wiebe and Mi-halcea (2006) mark up WordNet senses as subjec-tive, objective or both with good agreement.
How-ever, we expand their annotation scheme with po-larity annotation.
In addition, we hope to annotatea larger set of word senses.3 Human Judgements on Word SenseSubjectivity and PolarityWe follow Wiebe and Mihalcea (2006) in thatwe see subjective expressions as private states?that are not open to objective observation or ver-ification?
and in that annotators distinguish be-tween subjective (S), objective (O) and both sub-jective/objective (B) senses.4Available at http://sentiwordnet.isti.cnr.it/Polarity refers to positive or negative connota-tions associated with a word or sense.
In contrastto other researchers (Hatzivassiloglou and McKe-own, 1997; Takamura et al, 2005), we do not seepolarity as a category that is dependent on priorsubjectivity assignment and therefore applicable tosubjective senses only.
Whereas there is a depen-dency in that most subjective senses have a rel-atively clear polarity, polarity can be attached toobjective words/senses as well.
For example, tu-berculosis is not subjective ?
it does not describea private state, is objectively verifiable and wouldnot cause a sentence containing it to carry an opin-ion, but it does carry negative associations for thevast majority of people.
We allow for the polaritycategories positive (P), negative (N), varying (V)or no-polarity (NoPol).Overall we combine these annotations into 7categories?S:N, S:P, S:V, B, O:N, O:P, andO:NoPol, which are explained in detail in the sub-sequent sections.
Figure 1 gives an overview of thehierarchies over all categories.As can be seen in Figure 1, our annotationscheme allows for hierarchical annotation, i.e.
it ispossible to only annotate for subjectivity or polar-ity.
This can be necessary to achieve higher agree-ment by merging categories or to concentrate inspecific applications on only one aspect.3.1 Subjectivity3.1.1 Subjective SensesSubjective senses include several categories,which can be expressed by nouns, verbs, adjec-tives or adverbs.
Firstly, we include emotions.Secondly, we include judgements, assessments andevaluations of behaviour as well as aesthetic as-sessments of individuals, natural objects and arte-facts.
Thirdly, mental states such as doubts, beliefsand speculations are also covered by our definition.This grouping follows relatively closely the def-inition of attitudinal positioning in the Appraisalscheme (which has, however, only been used onwords, not on word senses before).These types of subjectivity can be expressed viadirect references to an emotion or mental state (seeExample 5 or 8 below) as well as by expressivesubjective elements (Wiebe and Mihalcea, 2006).Expressive subjective elements contain judgemen-tal references to objects or events.
Thus, pontifi-cate in Example 6 below is a reference to a speechevent that always judges it negatively; beautiful as44word sensesubjective(S) both(B) objective(O)negative positive varying/context-depedent(S:V) strong negativeconnotation(O:N) no strongconnotation(O:NoPol) strong positiveconnotation(O:P)(S:N) (S:P)Figure 1: Overview of the hierarchies over all categoriesin Example 7 below is a positive judgement.
(5) angry?feeling or showing anger; ?angry at theweather; ?angry customers; an angry silence?
(emotion)(6) pontificate?talk in a dogmatic and pompous manner;?The new professor always pontificates?
(assessment ofbehaviour)(7) beautiful?aesthetically pleasing (aesthetic assess-ment)(8) doubt, uncertainty, incertitude, dubiety, doubtfulness,dubiousness?the state of being unsure of something(mental state)3.1.2 Objective SensesObjective senses refer to persons, objects, ac-tions, events or states without an inherent emotionor judgement or an expression of a mental state.Examples are references to individuals via namedentities (see Example 9) or non-judgemental refer-ences to artefacts, persons, animals, plants, statesor events (see Example 10 and 11).
If a sentencecontains an opinion, it is not normally due to thepresence of this word sense and the sense oftenexpresses objectively verifiable states or events.Thus, Example 12 is objective as we can verifywhether there is a war going on.
In addition, a sen-tence containing this sense of war does not neces-sarily express an opinion.
(9) Einstein, Albert Einstein ?
physicist born in Germanywho formulated the special theory of relativity and thegeneral theory of relativity; Einstein also proposed thatlight consists of discrete quantized bundles of energy(later called photons) (1879-1955) (named entity)(10) lawyer, attorney ?
a professional person authorized topractice law; conducts lawsuits or gives legal advice(non-judgemental reference to person)(11) alarm clock, alarm ?
a clock that wakes sleeper at presettime (non-judgemental reference to object)(12) war, warfare ?
the waging of armed conflict against anenemy; ?thousands of people were killed in the war?
(non-judgemental reference to event)3.1.3 BothIn rare cases, a sense can be both subjective andobjective (denoted by B).
The following are thetwo most frequent cases.
First, a WordNet sensemight conflate a private state meaning and an ob-jective meaning of a word in the gloss description.Thus, in Example 13 we have the objective literaluse of the word tarnish mentioned such as tarnishthe silver, which does not express a private state.However, it also includes a metaphorical use oftarnish as in tarnish a reputation, which implicitlyexpresses a negative attitude.
(13) tarnish, stain, maculate, sully, defile?make dirty orspotty, as by exposure to air; also used metaphorically;?The silver was tarnished by the long exposure to theair?
; ?Her reputation was sullied after the affair with amarried man?The second case includes the inclusion of near-synonyms (Edmonds, 1999) which differs on sen-timent in the same synset list.
Thus in Example14, the term alcoholic is objective as it is not nec-essarily judgemental, whereas the other words inthe synset such as soaker or souse are normally in-sults and therefore subjective.
(14) alcoholic, alky, dipsomaniac, boozer, lush, soaker,souse?a person who drinks alcohol to excess habitu-ally3.2 Polarity3.2.1 Polarity of Subjective SensesThe polarity of a subjective sense can be positive(Category S:P), negative (S:N), or varying, depen-dent on context or individual preference (S:V).
Thedefinitions of these three categories are as follows.?
S:P is assigned to private states that expressa positive attitude, emotion or judgement (seeExample 7).?
S:N is assigned to private states that express anegative attitude, emotion or judgement (seeExample 5, 6 and 8).?
S:V is used for senses where the polarity isvarying by context or user.
For example, it is45likely that you give an opinion about some-body if you call him aloof; however, onlycontext can determine whether this is positiveor negative (see Example 15).
(15) aloof, distant, upstage?remote in manner; ?stood apartwith aloof dignity?
; ?a distant smile?
; ?he was upstagewith strangers?
(S:V)3.2.2 Polarity of Objective SensesThere are many senses that are objective buthave strong negative or positive connotations.
Forexample, war describes in many texts an objec-tive state (?He fought in the last war?)
but stillhas strong negative connotations.
In many (but notall) cases the negative or positive associations arementioned in the WordNet gloss.
Therefore, wecan determine three polarity categories for objec-tive senses:?
O:NoPol Objective with no strong, generallyshared connotations (see Example 9, 10, 11and 16).?
O:P Objective senses with strong positiveconnotations.
These refer to senses that donot describe or express a mental state, emo-tion or judgement but whose presence in atext would give it a strong feel-good flavour(see Example 17).?
O:N Objective senses with strong negativeconnotations.
These are senses that do notdescribe or express an emotion or judgementbut whose presence in a text would give it anegative flavour (see Example 12).
Anotherexample is (18): you can verify objectivelywhether a liquor was diluted, but it is nor-mally associated negatively.
(16) above?appearing earlier in the same text; ?flaws in theabove interpretation?
(O:NoPol)(17) remedy, curative, cure ?
a medicine or therapy thatcures disease or relieve pain (O:P)(18) adulterate, stretch, dilute, debase?corrupt, debase, ormake impure by adding a foreign or inferior substance;often by replacing valuable ingredients with inferiorones; ?adulterate liquor?
(O:N)We only allow positive and negative annotationsfor objective senses if we expect strong connota-tions that are shared among most people (in West-ern culture).
Thus, for example war, diseases andcrimes can relatively safely be predicted to haveshared negative connotations.
In contrast, a senselike the one of alarm clock in Example 11 mighthave negative connotations for late risers but itwould be annotated as O:NoPol in our scheme.
Weare interested in strong shared connotations as thepresence of such ?loaded?
terms can partially in-dicate bias in a text.
In addition, such objectivesenses are likely to give rise to figurative subjec-tive senses (see Example 18).4 Experiments and EvaluationThis section describes the experimental setup forour annotation experiments, presents reliability re-sults and discusses the benefits of the use of a hier-archical annotation scheme as well as the problemsof bias in the annotation scheme, annotator prefer-ences and bias in the sense inventory.4.1 Dataset and Annotation ProcedureThe dataset used in our annotation scheme is theMicro-WNOp corpus5, which contains all sensesof 298 words in WordNet 2.0.
We used it as it isrepresentative of WordNet with respect to its part-of-speech distribution and includes synsets of rel-atively frequent words, including a wide variety ofsubjective senses.
It contains 1105 synsets in total,divided into three groups common (110 synset),group1 (496 synsets) and group2 (499 synsets).We used common as the training set for the anno-tators and tested annotation reliability on group1.Annotation was performed by two annotators.Both are fluent English speakers; one is a compu-tational linguist whereas the other is not in linguis-tics.
All annotation was carried out independentlyand without discussion during the annotation pro-cess.
The annotators were furnished with guide-line annotations with examples for each category.Annotators saw the full synset, including all syn-onyms, glosses and examples.4.2 Agreement StudyTraining.
The two annotators first annotated thecommon group for training.
Observed agreementon the training data is 83.6%, with a kappa (Co-hen, 1960) of 0.76.
Although this looks overallquite good, several categories are hard to identify,for example B and S:V, as can be seen in the con-fusion matrix below (Table 1) with Annotator 1 incolumns and Annotator 2 in the rows.Testing.
Problem cases were discussed betweenthe annotators and a larger study on group 1 as test5Available at http://www.unipv.it/wnop/micrownop.tgz46Table 1: Confusion matrix for the training dataB S:N S:P S:V O:NoPol O:N O:P totalB 1 0 0 0 2 0 0 3S:N 0 13 0 0 0 2 0 15S:P 0 0 8 1 1 0 0 10S:V 1 1 0 13 6 0 0 21O:NoPol 1 0 0 0 50 0 0 51O:N 0 0 0 0 2 4 0 6O:P 0 0 1 0 0 0 3 4total 3 14 9 14 61 6 3 110data was carried out.
Table 2 shows the confusionmatrix for all 7 categories.Table 2: Confusion matrix on the test setB S:N S:P S:V O:NoPol O:N O:P totalB 7 2 0 2 0 0 0 11S:N 0 41 1 0 0 0 0 42S:P 0 0 65 4 0 0 2 71S:V 0 0 7 17 3 0 0 27O:NoPol 9 1 2 6 253 5 8 284O:N 0 14 0 2 0 25 0 41O:P 1 0 5 0 1 0 13 20total 17 58 80 31 257 30 23 496The observed agreement is 84.9% and the kappais 0.77.
This is good agreement for a relativelysubjective task.
However, there is no improve-ment over agreement in training although an ad-ditional clarification phase of the training materialtook place between training and testing.We also computed single category kappa in or-der to estimate which categories proved the mostdifficult.
Single category-kappa concentrates onone target category and conflates all other cate-gories into one non-target category and measuresagreement between the two resulting categories.The results showed that S:N (0.80), S:P (0.84)and O:NoPol (0.86) were highly reliable with lessconvincing results for B (0.49), S:V (0.56), O:N(0.68), and O:P (0.59).
B is easily missed dur-ing annotation (see Example 19), S:V is easily con-fused with several other categories (Example 20),whereas O:N is easily confused with O:NoPol andS:N (Example 21); andO:P is easily confused withO:NoPol and S:P (Example 22).
(19) antic, joke, prank, trick, caper, put-on?a ludicrousor grotesque act done for fun and amusement (B vsO:NoPol)(20) humble?marked by meekness or modesty; not arro-gant or prideful; ?a humble apology?
(S:V vs S:P)(21) hot?recently stolen or smuggled; ?hot merchandise?
;?a hot car?
(O:N vs O:NoPol)(22) profit, gain?the advantageous quality of being benefi-cial (S:P vs O:P)Our annotation scheme also needs testing on aneven larger data set as a few categories such as Band O:P occur relatively rarely.4.3 The Effect of Hierarchical AnnotationAs mentioned above, our annotation scheme al-lows us to consider the subjectivity or polarity dis-tinction individually, leaving the full categoriza-tion underspecified.Subjectivity Distinction Only.
For subjectivitydistinctions we collapse S:V, S:P and S:N into asingle label S (subjective) and O:NoPol, O:N andO:P into a single label O (objective).
B remainsunchanged.
The resulting confusion matrix on thetest set is in Table 3.Table 3: Confusion matrix for SubjectivityB S O totalB 7 4 0 11S 0 135 5 140O 10 30 305 345total 17 169 310 496Observed agreement is 90.1% and kappa is 0.79.Single category kappa is 0.49 for B, 0.82 for S and0.80 for O.
As B is a very rare category (less than5% of items), this is overall an acceptable levelof distinction with excellent reliability for the twomain categories.Polarity Distinction Only.
We collapse O:Nand S:N into a single category N (negative) andO:P and S:P into P (positive), leaving the othercategories intact.
This results in 5 categories B,S:V/V, NoPol, N and P. The resulting confusionmatrix is in Table 4.Table 4: Confusion matrix for PolarityB N P V NoPol totalB 7 2 0 2 0 11N 0 80 1 2 0 83P 1 0 85 4 1 91V 0 0 7 17 3 27NoPol 9 6 10 6 253 284total 17 88 103 31 257 496Observed agreement is 89.1% and kappa is 0.83.Single category kappa is as follows: B (0.49), N(0.92), P (0.85), V (0.56), and NoPol (0.86).
Thismeans all categories but B and V (together about10% of items) are reliably identifiable.Overall we show that both polarity and sub-jectivity identification of word senses can be re-liably annotated and are well-defined tasks forautomatic classification.
Specifically the per-47centage agreement of about 90% for word sensepolarity/subjectivity identification is substantiallyhigher than the one of 78% reported in An-dreeivskaia and Bergler (2006).
Agreement forpolarity-only is significantly higher than for thefull annotation scheme, showing the value of hi-erarchical annotation.
We believe hierarchical an-notation is also appropriate for this task, as sub-jectivity and polarity are linked but still separateconcepts.
Thus, a researcher might want to mainlyfocus on explicitly expressed opinions as exempli-fied by subjectivity, whereas another can also focuson opinion bias in a text as expressed by loadedwords of positive or negative polarity.4.4 Bias in Annotation Performance, SenseInventory and Annotation GuidelinesWhy do annotators assign different labels to somesenses?
Three main aspects are responsible fornon-spurious disagreement.Firstly, individual perspective or bias played arole.
For example, Annotator 2 was more inclinedto give positive or negative polarity labels than An-notator 1 as can be seen in Table 4, where Anno-tator 2 assigned 103 positive and 88 negative la-bels,whereas Annotator 1 assigned only 91 posi-tive and 83 negative labels.Secondly, the WordNet sense inventory con-flates near-synonyms which just differ in sentimentproperties (see Section 3.1.3 and Example 14).
Al-though the labels B and S:V were specifically cre-ated in the annotation scheme to address this prob-lem, these cases still proved confusing to annota-tors and do not readily lead to consistent annota-tion.Thirdly, WordNet sometimes includes a conno-tation bias either in its glosses or in its hierarchicalorganization.
Here we use the word connotationbias for the inclusion of connotations that seemhighly controversial.
Thus, in Example 23, theWordNet gloss for Iran evokes negative connota-tions by mentioning allegations of terrorism.6InExample 24 skinhead is a hyponym of bully, giv-ing strong negative connotations for all skinheads.Although the annotation scheme explicitly encour-ages annotators to disregard especially such con-troversial connotations as in Example 23 such ex-amples can still confuse annotators and show thatword sense annotation is to a certain degree depen-6Note that this was part of WordNet 2.0 and has been re-moved in WordNet 2.1.dent on the sense inventory used.
(23) Iran, Islamic Republic of Iran, Persia?a theocratic is-lamic republic in the Middle East in western Asia; Iranwas the core of the ancient empire that was knownas Persia until 1935; rich in oil; involved in state-sponsored terrorism(24) skinhead ??
bully, tough, hooligan, ruffian, rough-neck, rowdy, yob, yobo, yobboSome of our good reliability performance mightbe due to one particular instance of bias in the an-notation guidelines.
We strongly advised annota-tors to only annotate positive or negative polarityfor objective senses when strong, shared connota-tions are expected,7thereby ?de-individualising?the task of polarity annotation.
This introducesa bias towards the category NoPol for objectivesenses.
We also did not allow varying polarity forobjective senses, instructing annotators that suchpolarity would be unclear and should be annotatedas NoPol as not being a strong shared connotation.It can of course be questioned whether the intro-duction of such a bias is good or not.
It helpsagreement but might reduce the usefulness of theannotation as individual connotations are not an-notated for objective senses.
However, to considermore individual connotations needs an annotationeffort with a much larger number of annotators toarrive at a profile of polarity connotations over alarger population.
We leave this for future work.Our current framework is comprehensive for sub-jectivity as well as polarity for subjective senses.4.5 Gold StandardAfter discussion between the two annotators, agold standard annotation was agreed upon.
Ourdata set consists of this agreed set as well as the re-mainder of the Micro-WNOp corpus (group2) an-notated by one of the annotators alone after agree-ment was established.How many words are subjectivity-ambiguous orpolarity-ambiguous, i.e.
how much informationdo we gain by annotating senses over annotatingwords?
As the number of senses increases withword frequency, we expect rare words to be lesslikely to be subjectivity-ambiguous than frequentwords.
The Micro-WNOp corpus contains rela-tively frequent words so we will get an overesti-mation of subjectivity-ambiguous word types fromthis corpus, though not necessarily of word tokens.Of all 298 words, 97 (32.5%) are subjectivity-ambiguous, a substantial number.
Fewer words are7See Section 3.2.2 for justification.48polarity-ambiguous: only 10 words have at leastone positive and one negatively annotated sensewith a further 44 words having at least one sub-jective sense with varying polarity (S:V).
This sug-gests that subjective and objective uses of the sameword are more frequent than reverses in emotionalorientation.5 Comparison to Original PolarityAnnotation (Cerini et al)We can compare the reliability of our own annota-tion scheme with the original (polarity) annotationin the Micro-WNOp corpus.
Cerini et al (2007)do not present agreement figures but as their cor-pus is publically available we can easily computereliability.
Recall that each synset has a triplet ofnumerical scores between 0 and 1 each: positiv-ity, negativity and neutrality, which is not explic-itly annotated but derived as 1 ?
(positivity +negativity).
Subjectivity in our sense (existenceof a private state) is not annotated.The ratings of three annotators are available forGroup 1 and of two annotators for Group 2.
Wemeasured the Pearson correlation coefficient be-tween each annotator pair for both groups for bothnegativity and positivity scoring.
As correlationcan be high without necessarily high agreementon absolute values, we also computed a variant ofkappa useful for numerical ratings, namely alpha(Artstein and Poesio, 2005), which gives weightto degrees of disagreement.
Thus, a disagreementbetween two scores would be weighted as the ab-solute value of score1 ?
score2.
The results arelisted in Table 5.Table 5: Reliability of original annotation onMicro-WNOpdataset raters score type correlation alphaGroup 1 1 and 2 negative 83.7 64.9Group 1 1 and 3 negative 86.4 71.8Group 1 2 and 3 negative 82.5 56.9Group 1 1 and 2 positive 80.5 60.9Group 1 1 and 3 positive 87.8 74.9Group 1 2 and 3 positive 78.2 57.5Group 2 1 and 2 negative 95.9 90.7Group 2 1 and 2 positive 92.2 84.9Correlation between the annotators is high.However, Rater 2 (in Group1) still behaves differ-ently from the other two raters, giving consistentlyhigher or lower scores overall, leading to low al-pha.
Thus, we can conclude that Group 2 is muchmore reliably annotated than Group 1 and that es-pecially Rater 2 in Group 1 is an outlier in this(small) set of raters.
This also shows that workwith several annotators is valuable and should beconducted for our scheme as well.6 Conclusion and Future WorkWe elicit human judgements on the subjectivityand polarity of word senses.
To the best of ourknowledge, this is the first such annotation schemefor both categories.
We detail the definitions foreach category and measure the reliability of the an-notation.
The experimental results show that whenusing all 7 categories, only 3 categories (S:N, S:P,and O:NoPol) are reliable while the reliability ofthe other 4 categories is not high.
We also showthat this is improved by the virtue of hierarchicalannotation and that the general tasks of subjectivityand polarity annotation on word senses are there-fore well-defined.
Moreover, we also discuss theeffect of different kinds of bias on our approach.In future we will refine the guidelines for themore difficult categories, including more detailedadvice on how to deal with sense inventory bias.We will also perform larger-scale annotation exer-cises with more annotators as the latter is necessaryto deal with more individualised polarity connota-tions.
In addition, we will use the data to test learn-ing methods for the automatic detection of subjec-tivity and polarity properties of word senses.ReferencesAndreevskaia, Alina and Sabine Bergler.
2006.
Min-ing WordNet for Fuzzy Sentiment: Sentiment TagExtraction from WordNet Glosses.
Proceedings ofEACL?06.Artstein, Ron and Massimo Poesio.
2005.Kappa3=alpha(or beta).
Technical Report CSM-437, University of Essex.Bradley, Margaret and Peter Lang.
1999.
AffectiveNorms for EnglishWords (ANEW): Stimuli, Instruc-tion Manual and Affective Ratings Technical reportC-1, the Center for Research in Psychophysiology,University of Florida.
.Cerini, Sabrina, Valentina Compagnoni, Alice Demon-tis, Maicol Formentelli, and Caterina Gandini.
2007.Micro-WNOp: A Gold Standard for the Evaluationof Automatically Compiled Lexical Resources forOpinion Mining.
Language resources and linguis-tic theory: Typology, second language acquisition,English linguistics.49Cohen, Jacob.
1960.
A Coefficient of Agreementfor Nominal Scales.
Educational and PsychologicalMeasurement, Vol.20, No.1.Das, Sanjiv and Mike Chen.
2001.
Yahoo!
for Ama-zon: Extracting Market Sentiment from Stock Mes-sage Boards.
Proceedings of APFA?01.Edmonds, Philip.
1999.
Semantic RepresentationsOf Near-Synonyms For Automatic Lexical Choice.PhD thesis, University of Toronto.Esuli, Andrea and Fabrizio Sebastiani.
2006.
Senti-WordNet: A Publicly Available Lexical Resource forOpinion Mining.
Proceedings of LREC?06.Hatzivassiloglou, Vasileios and Kathleen McKeown.1997.
Predicting the Semantic Orientation of Ad-jectives.
Proceedings of ACL?97.Heise, David.
2001.
Project Magellan: CollectingCross-culture Affective Meanings via the Internet.Electronic Journal of Sociology.Osgood, Charles, William May, and Murray Miron.1975.
Cross-cultural Universals of Affective Mean-ing.
University of Illinois Press.Osgood, Charles, George Suci, and Percy Tannenbaum.1957.
The Measurment of Meaning.
University ofIllinois Press.Strapparava, Carlo and Alessandro Valitutti.
2004.WordNet-Affect: an Affective Extension of Word-Net.
Proceedings of LREC?04.Takamura, Hiroya, Takashi Inui, and Manabu Oku-mura.
2005.
Extracting Semantic Orientations ofWords using Spin Model.
Proceedings of ACL?05.Wiebe, Janyce and Rada Micalcea.
2006.
Word Senseand Subjectivity.
Proceedings of ACL?06.Wiebe, Janyce, Theresa Wilson, and Claire Cardie.2005.
Annotating Expressions of Opinions andEmotions in Language.
Language Resources andEvaluation.50
