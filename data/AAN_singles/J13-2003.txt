Statistical Metaphor ProcessingEkaterina Shutova?University of CambridgeSimone Teufel?University of CambridgeAnna Korhonen?University of CambridgeMetaphor is highly frequent in language, which makes its computational processing indis-pensable for real-world NLP applications addressing semantic tasks.
Previous approaches tometaphor modeling rely on task-specific hand-coded knowledge and operate on a limited domainor a subset of phenomena.
We present the first integrated open-domain statistical model ofmetaphor processing in unrestricted text.
Our method first identifies metaphorical expressionsin running text and then paraphrases them with their literal paraphrases.
Such a text-to-textmodel of metaphor interpretation is compatible with other NLP applications that can benefitfrom metaphor resolution.
Our approach is minimally supervised, relies on the state-of-the-artparsing and lexical acquisition technologies (distributional clustering and selectional preferenceinduction), and operates with a high accuracy.1.
IntroductionOur production and comprehension of language is a multi-layered computationalprocess.
Humans carry out high-level semantic tasks effortlessly by subconsciouslyusing a vast inventory of complex linguistic devices, while simultaneously integratingtheir background knowledge, to reason about reality.
An ideal computational modelof language understanding would also be capable of performing such high-level se-mantic tasks.
With the rapid advances in statistical natural language processing (NLP)and computational lexical semantics, increasingly complex semantic tasks can nowbe addressed.
Tasks that have received much attention so far include, for example,word sense disambiguation (WSD), supervised and unsupervised lexical classification,selectional preference induction, and semantic role labeling.
In this article, we take astep further and show that state-of-the-art statistical NLP and computational lexicalsemantic techniques can be used to successfully model complexmeaning transfers, suchas metaphor.?
Computer Laboratory, William Gates Building, 15 JJ Thomson Avenue, Cambridge CB3 0FD, UK.E-mail: {Ekaterina.Shutova, Simone.Teufel, Anna.Korhonen}@cl.cam.ac.uk.Submission received: 28 July 2011; revised submission received: 21 April 2012; accepted for publication:31 May 2012.doi:10.1162/COLI a 00124?
2013 Association for Computational LinguisticsComputational Linguistics Volume 39, Number 2Metaphors arise when one concept is viewed in terms of the properties of another.Humans often use metaphor to describe abstract concepts through reference to moreconcrete or physical experiences.
Some examples of metaphor include the following.
(1) How can I kill a process?
(Martin 1988)(2) Hillary brushed aside the accusations.
(3) I investedmyself fully in this research.
(4) And then my heart with pleasure fills,And danceswith the daffodils.
(?I wandered lonely as a cloud,?
William Wordsworth, 1804)Metaphorical expressions may take a great variety of forms, ranging from conventionalmetaphors, which we produce and comprehend every day, for example, those in Exam-ples (1)?
(3), to poetic and novel ones, such as Example (4).
In metaphorical expressions,seemingly unrelated features of one concept are attributed to another concept.
In Ex-ample (1), a computational process is viewed as something alive and, therefore, its forcedtermination is associated with the act of killing.
In Example (2) Hillary is not literallycleaning the space by sweeping accusations.
Instead, the accusations lose their validityin that situation, in other words Hillary rejects them.
The verbs brush aside and reject bothentail the resulting disappearance of their object, which is the shared salient propertythat makes it possible for this analogy to be lexically expressed as a metaphor.Characteristic of all areas of human activity (from poetic to ordinary to scientific)and thus of all types of discourse, metaphor becomes an important problem for NLP.As Shutova and Teufel (2010) have shown in an empirical study, the use of conventionalmetaphor is ubiquitous in natural language text (according to their data, on averageevery third sentence in general-domain text contains a metaphorical expression).
Thismakes metaphor processing essential for automatic text understanding.
For example,an NLP application which is unaware that a ?leaked report?
is a ?disclosed report?and not, for example, a ?wet report,?
would fail further semantic processing of thepiece of discourse in which this phrase appears.
A system capable of recognizing andinterpreting metaphorical expressions in unrestricted text would become an invaluablecomponent of any real-world NLP application that needs to access semantics (e.g., infor-mation retrieval [IR], machine translation [MT], question answering [QA], informationextraction [IE], and opinion mining).So far, these applications have not used any metaphor processing techniques andthus often fail to interpret metaphorical data correctly.
Consider an example from MT.Figure 1 shows metaphor translation from English into Russian by a state-of-the-artstatistical MT system (Google Translate1).
For both sentences the MT system producesliteral translations of metaphorical terms in English, rather than their literal interpreta-tions.
This results in otherwise grammatical sentences being semantically infelicitous,poorly formed, and barely understandable to a native speaker of Russian.
The meaningof stir in Figure 1 (1) and spill in Figure 1 (2) would normally be realized in Russian onlyvia their literal interpretation in the given context (provoke and tell), as shown underCORRECT TRANSLATION in Figure 1.
A metaphor processing component could help to1 http://translate.google.com/.302Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingFigure 1Examples of metaphor translation.avoid such errors.
We conducted a pilot study of the importance of metaphor for MT,by running an English-to-Russian MT system (Google Translate) on the sentences fromthe data set of Shutova (2010) containing single-word verb metaphors.
We found that27 out of 62 sentences (44%) were translated incorrectly due to metaphoricity.
Due tothe high frequency of metaphor in text according to corpus studies, such a high level oferror becomes important for MT.Examples where metaphor understanding is crucial can also be found in opinionmining, that is, detection of the speaker?s attitude to what is said and to the topic.Consider the following sentences.
(5) a.
Government loosened its strangle-hold on business.
(Narayanan 1999)b.
Government deregulated business.
(Narayanan 1999)Both sentences describe the same fact.
The use of the metaphor loosened strangle-hold inExample (5a) suggests that the speaker opposes government control of economy, how-ever, whereas Example (5b) does not imply this.
One can infer the speaker?s negativeattitude via the presence of a negativeword strangle-hold.
Ametaphor processing systemwould establish the correct meaning of Example (5a) and thus discover the actual facttowards which the speaker has a negative attitude.Because metaphor understanding requires resolving non-literal meanings via ana-logical comparisons, the development of a complete and computationally practicalaccount of this phenomenon is a challenging and complex task.
Despite the impor-tance of metaphor for NLP systems dealing with semantic interpretation, its automaticprocessing has received little attention in contemporary NLP, and is far from being asolved problem.
The majority of computational approaches to metaphor still exploitideas articulated two or three decades ago (Wilks 1978; Lakoff and Johnson 1980).
Theyoften rely on task-specific hand-coded knowledge (Martin 1990; Fass 1991; Narayanan1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004; Agerri et al2007)and reduce the task to reasoning about a limited domain or a subset of phenomena(Gedigian et al2006; Krishnakumaran and Zhu 2007).
So far there has been no robuststatistical system operating on unrestricted text.
State-of-the-art accurate parsing (KleinandManning 2003; Briscoe, Carroll, andWatson 2006; Clark and Curran 2007), however,as well as recent work on computational lexical semantics (Schulte im Walde 2006;303Computational Linguistics Volume 39, Number 2Mitchell and Lapata 2008; Davidov, Reichart, and Rappoport 2009; Erk and McCarthy2009; Sun and Korhonen 2009; Abend and Rappoport 2010; O?
Se?aghdha 2010) open upmany avenues for the creation of such a system.
This is the niche the presented work isintending to fill.1.1 What Is Metaphor?Metaphor has traditionally been viewed as an artistic device that lends vividness anddistinction to an author?s style.
This view was first challenged by Lakoff and Johnson(1980), who claimed that it is a productive phenomenon that operates at the level ofmental processes.
According to Lakoff and Johnson, metaphor is thus not merely aproperty of language (i.e., a linguistic phenomenon), but rather a property of thought(i.e., a cognitive phenomenon).
This view was subsequently adopted and extendedby a multitude of approaches (Grady 1997; Narayanan 1997; Fauconnier and Turner2002; Feldman 2006; Pinker 2007) and the term conceptual metaphor was coined todescribe it.The view postulates that metaphor is not limited to similarity-based meaning ex-tensions of individual words, but rather involves reconceptualization of a whole areaof experience in terms of another.
Thus metaphor always involves two concepts orconceptual domains: the target (also called the topic or tenor in the linguistics literature)and the source (also called the vehicle).
Consider Examples (6) and (7).
(6) He shot down all of my arguments.
(Lakoff and Johnson 1980)(7) He attacked every weak point in my argument.
(Lakoff and Johnson 1980)According to Lakoff and Johnson, a mapping of the concept of argument to that of war isused in both Examples (6) and (7).
The argument, which is the target concept, is viewedin terms of a battle (or awar), the source concept.
The existence of such a link allows us totalk about arguments using war terminology, thus giving rise to a number of metaphors.Conceptual metaphor, or source?target domain mapping, is thus a generalization overa set of individual metaphorical expressions that covers multiple cases in which waysof reasoning about the source domain systematically correspond to ways of reasoningabout the target.Conceptual metaphor manifests itself in natural language in the form of linguisticmetaphor (or metaphorical expressions) in a variety of ways.
The most common typesof linguistic metaphor are lexical metaphor (i.e., metaphor at the level of a singleword sense, as in the Examples (1)?
(4)), multi-word metaphorical expressions (e.g.,?whether we go on pilgrimagewith Raleigh or put out to seawith Tennyson?
), or extendedmetaphor, that spans over longer discourse fragments.Lexical metaphor is by far the most frequent type.
In the presence of a certainconceptual metaphor individual words can be used in entirely novel contexts, whichresults in the formation of new meanings.
Consider the following example.
(8) How can we build a ?Knowledge economy?
if research is handcuffed?
(Barqueand Chaumartin 2009)In this sentence the physical verb handcuff is used with an abstract object researchand its meaning adapts accordingly.
Metaphor is a productive phenomenon (i.e., its304Shutova, Teufel, and Korhonen Statistical Metaphor Processingnovel examples continue to emerge in language).
A large number of metaphoricalexpressions, however, become conventionalized (e.g., ?I cannot grasp his way of think-ing?).
Although metaphorical in nature, their meanings are deeply entrenched in every-day use, and are thus cognitively treated as literal terms.
Both novel and conventionalmetaphors are important for text processing, hence our work is concerned with bothtypes.
Fixed non-compositional idiomatic expressions (e.g., kick the bucket, rock the boat,put a damper on), however, are left aside, because the mechanisms of their formation areno longer productive in modern language and, as such, they are of little interest for thedesign of a generalizable computational model of metaphor.Extended metaphor refers to the use of metaphor at the discourse level.
A famousexample of extended metaphor can be found in William Shakespeare?s play As You LikeIt, where he first compares the world to a stage and then in the following discoursedescribes its inhabitants as players.
Extended metaphor often appears in literaturein the form of an allegory or a parable, whereby a whole story from one domain ismetaphorically transferred onto another in order to highlight certain attributes of thesubject or teach a moral lesson.1.2 Computational Modeling of MetaphorIn this article we focus on lexical metaphor and the computational modeling thereof.From an NLP viewpoint, not all metaphorical expressions are equally important.
Ametaphorical expression is interesting for computational modeling if its metaphoricalsense is significantly distinct from its original literal sense and cannot be interpreteddirectly (e.g., by existing word sense disambiguation techniques using a predefinedsense inventory).
The identification of highly conventionalized metaphors (e.g., theverb impress, whose meaning originally stems from printing) are not of interest for NLPtasks, because their metaphorical senses have long been dominant in language and theiroriginal literal senses may no longer be used.
A number of conventionalizedmetaphors,however, require explicit interpretation in order to be understood by computer (e.g.,?cast doubt,?
?polish the thesis,?
?catch a disease?
), as do all novel metaphors.
Thuswe are concerned with both novel and conventional metaphors, but only consider thecases whereby the literal and metaphorical senses of the word are in clear opposition incommon use in contemporary language.Automatic processing of metaphor can be divided into two subtasks: metaphoridentification, or recognition (distinguishing between literal and metaphorical languagein text); and metaphor interpretation (identifying the intended literal meaning of ametaphorical expression).
An ideal metaphor processing system should address bothof these tasks and provide useful information to support semantic interpretation inreal-world NLP applications.
In order to be directly applicable to other NLP systems,it should satisfy the following criteria: Provide a representation of metaphor interpretation that can be easilyintegrated with other NLP systems: This criterion places constraintson how the metaphor processing task should be defined.
The mostuniversally applicable metaphor interpretation would be in the text-to-textform.
This means that a metaphor processing system would take raw textas input and provide a more literal text as output, in which metaphorsare interpreted.305Computational Linguistics Volume 39, Number 2 Operate on unrestricted running text: In order to be useful for real-worldNLP the system needs to be capable of processing real-world data.
Ratherthan only dealing with individual carefully selected clear-cut examples,the system should be fully implemented and tested on free naturallyoccurring text. Be open-domain: The system needs to cover all domains, genres, andtopics.
Thus it should not rely on any domain-specific information or focuson individual types of instances (e.g., a hand-chosen limited set ofsource-target domain mappings). Be unsupervised or minimally supervised: To be easily adaptable to newdomains, the system needs to be unsupervised or minimally supervised.This means it should not use any task-specific (i.e., metaphor-specific)hand-coded knowledge.
The only acceptable exception might be amulti-purpose general-domain lexicon that is already in existence anddoes not need to be created in a costly manner, although it would be anadvantage if no such resource is required. Cover all syntactic constructions: To be robust, the system needs to beable to deal with metaphors represented by all word classes and syntacticconstructions.In this article, we address both the metaphor identification and interpretationtasks, resulting in the first integrated domain-independent corpus-based computationalmodel of metaphor.
The method is designed with the listed criteria in mind.
It takesunrestricted text as input and produces textual output.
Metaphor identification andinterpretation modules, based on the algorithms of Shutova, Sun, and Korhonen (2010)and Shutova (2010), are first evaluated independently, and then combined and evalu-ated together as an integrated system.
All components of the method are in principleapplicable to all part-of-speech classes and syntactic constructions.
In the current ex-periments, however, we tested the system only on single-word metaphors expressed bya verb.
Verbs are frequent in language and central to conceptual metaphor.
Cameron(2003) conducted a corpus study of the use of metaphor in educational discourse for allparts of speech.
She found that verbs account for around 50% of the data, the rest beingshared by nouns, adjectives, adverbs, copula constructions, and multi-word metaphors.This suggests that verb metaphors provide a reliable testbed for both linguistic andcomputational experiments.
Restricting the scope to verbs is a methodological stepaimed at testing the main principles of the proposed approach in a well-defined setting.We would, however, expect the presented methods to scale to other parts of speechand to a wide range of syntactic constructions, because they rely on techniques fromcomputational lexical semantics that have been shown to be effective in modeling notonly verb meanings, but also those of nouns and adjectives.As opposed to previous approaches that modeled metaphorical reasoning startingfrom a hand-crafted description and applying it to explain the data, we aim to designa statistical model that captures regular patterns of metaphoricity in a large corpus andthus generalizes to unseen examples.
Compared to labor-intensive manual efforts, thisapproach is more robust and, being nearly unsupervised, cost-effective.
In contrast toprevious statistical approaches, which addressed metaphors of a specific topic or didnot consider linguistic metaphor at all (e.g., Mason 2004), the proposed method coversall metaphors in principle, can be applied to unrestricted text, and can be adapted todifferent domains and genres.306Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingOur first experiment is concerned with the identification of metaphorical expres-sions in unrestricted text.
Starting from a small set of metaphorical expressions, thesystem learns the analogies involved in their production in aminimally supervised way.It generalizes over the exemplified analogies by means of verb and noun clustering(i.e., the identification of groups of similar concepts).
This generalization allows it torecognize previously unseen metaphorical expressions in text.
Consider the followingexamples:(9) All of this stirred an uncontrollable excitement in her.
(10) Time and time again he would stare at the ground, hand on hip, and thenswallow his anger and play tennis.Having once seen the metaphor ?stir excitement?
in Example (9) the metaphor identifi-cation system successfully concludes that ?swallow anger?
in Example (10) is also usedmetaphorically.The identified metaphors then need to be interpreted.
Ideally, a metaphor interpre-tation task should be aimed at producing a representation of metaphor understandingthat can be directly embedded into other NLP applications that could benefit frommeta-phor resolution.
We define metaphor interpretation as a paraphrasing task and builda system that discovers literal meanings of metaphorical expressions in text and pro-duces their literal paraphrases.
For example, for metaphors in Examples (11a) and (12a)the system produces the paraphrases in Examples (11b) and (12b), respectively.
(11) a.
All of this stirred an uncontrollable excitement in her.b.
All of this provoked an uncontrollable excitement in her.
(12) a. a carelessly leaked reportb.
a carelessly disclosed reportThe paraphrases for metaphorical expressions are acquired in a data-driven mannerfrom a large corpus.
Literal paraphrases are then identified using a selectional prefer-ence model.This article first surveys the relevant theoretical and computational work on meta-phor, then describes the design of the identification and paraphrasingmodules and theirindependent evaluation, and concludes with the evaluation of the integrated text-to-textmetaphor processing system.
The evaluations were carried out with the aid of humansubjects.
In the case of identification, the subjects were asked to judge whether a system-annotated phrase is a metaphor.
In case of paraphrasing, they had to decide whetherthe system-produced paraphrase for the metaphorical expression is correct and literalin the given context.
In addition, we created a metaphor paraphrasing gold standardby asking human subjects (not previously exposed to system output) to produce theirown literal paraphrases for metaphorical verbs.
The system paraphrasing was then alsoevaluated against this gold standard.2.
Theoretical and Computational Background2.1 Metaphor and PolysemyTheorists of metaphor distinguish between two kinds of metaphorical language: novel(or poetic) metaphors (i.e., those that are imaginative), and conventionalized metaphors307Computational Linguistics Volume 39, Number 2(i.e., those that are used as a part of an ordinary discourse).
According to Nunberg(1987), all metaphors emerge as novel, but over time they become part of general usageand their rhetorical effect vanishes, resulting in conventionalized metaphors.
FollowingOrwell (1946), Nunberg calls such metaphors ?dead?
and claims that they are notpsychologically distinct from literally used terms.
The scheme described by Nunbergdemonstrates how metaphorical associations capture patterns governing polysemy,namely, the capacity of aword to havemultiplemeanings.
Over time some of the aspectsof the target domain are added to the meaning of a term in the source domain, resultingin a (metaphorical) sense extension of this term.
Copestake and Briscoe (1995) discusssense extension mainly based on metonymic examples and model the phenomenonusing lexical rules encoding metonymic patterns.
They also suggest that similar mecha-nisms can be used to account for metaphorical processes.
According to Copestake andBriscoe, the conceptual mappings encoded in the sense extension rules would definethe limits to the possible shifts in meaning.General-domain lexical resources often include information about metaphoricalword senses, although unsystematically and without any accompanying semantic an-notation.
For example, WordNet2 (Fellbaum 1998) contains the comprehension senseof grasp, defined as ?get the meaning of something,?
and the reading sense of skim,defined as ?read superficially.?
A great deal of metaphorical senses are absent fromthe current version of WordNet, however.
A number of researchers have advocated thenecessity of systematic inclusion and mark-up of metaphorical senses in such general-domain lexical resources (Alonge and Castelli 2003; Lo?nneker and Eilts 2004) and claimthat this would be beneficial for the computational modeling of metaphor.
Metaphorprocessing systems could then either use this knowledge or be evaluated against it.Lo?nneker (2004) mapped the senses from EuroWordNet3 to the Hamburg MetaphorDatabase (Lo?nneker 2004; Reining and Lo?nneker-Rodman 2007) containing examplesof metaphorical expressions in German and French.
Currently no explicit informationabout metaphor is integrated into WordNet for English, however.Although consistent inclusion in WordNet is in principle possible for conventionalmetaphorical senses, it is not viable for novel contextual sense alternations.
Becausemetaphor is a productive phenomenon, all possible cases of contextual meaning alter-nations it results in cannot be described via simple sense enumeration (Pustejovsky1995).
Computational metaphor processing therefore cannot be approached using thestandard word sense disambiguation paradigm, whereby the contextual use of a wordis classified according to an existing sense inventory.
The metaphor interpretation taskis inherently more complex and requires generation of new and often uncommonmeanings of the metaphorical term based on the context.2.2 Theoretical Views on MetaphorThe following views on metaphor are prominent in linguistics and philosophy: thecomparison view (e.g., the Structure-Mapping Theory of Gentner [1983]), the interactionview (Black 1962; Hesse 1966), the selectional restrictions violation view (Wilks 1975,1978), and conceptual metaphor theory (CMT) (Lakoff and Johnson 1980).
All of these2 http://wordnet.princeton.edu/.3 EuroWordNet is a multilingual database containing WordNets for several European languages (Dutch,Italian, Spanish, German, French, Czech, and Estonian).
The WordNets are structured in the same wayas the Princeton WordNet for English.
URL: http://www.illc.uva.nl/EuroWordNet/.308Shutova, Teufel, and Korhonen Statistical Metaphor Processingapproaches share the idea of an interconceptual mapping that underlies the productionof metaphorical expressions.
Gentner?s Structure-Mapping Theory postulates that theground for metaphor lies in similar properties and relations shared by the two con-cepts (the target and the source).
Tourangeau and Sternberg (1982), however, criticizethis view by noting that ?everything has some feature or category that it shares witheverything else, but we cannot combine just any two things in metaphor?
(Tourangeauand Sternberg 1982, page 226).
The interaction view focuses on the surprise and noveltythat metaphor introduces.
Its proponents claim that the source concept (or domain) rep-resents a template for seeing the target concept in an entirely new way.
The conceptualmetaphor theory of Lakoff and Johnson (1980) takes this idea much further by statingthat metaphor operates at the level of thought rather than at the level of language, andthat it is based on a set of cognitive mappings between source and target domains.
ThusLakoff and Johnson put the emphasis on the structural aspect of metaphor, rather thanits decorative function in language that dominated the preceding theories.
The selec-tional restrictions violation view of Wilks (1978) concerns manifestation of metaphor inlanguage.
Wilks suggests that metaphor represents a violation of combinatory normsin the linguistic context and that metaphorical expressions can be detected via suchviolation.2.2.1 Conceptual Metaphor Theory.
Examples (6) and (7) provided a good illustration ofCMT.
Lakoff and Johnson explain them via the conceptual metaphor ARGUMENT ISWAR, which is systematically reflected in language in a variety of expressions.
(13) Your claims are indefensible.
(Lakoff and Johnson 1980)(14) I demolished his argument.
(Lakoff and Johnson 1980)(15) I?ve never won an argument with him.
(Lakoff and Johnson 1980)(16) You disagree?
Okay, shoot!
(Lakoff and Johnson 1980)According to CMT, we conceptualize and structure arguments in terms of battle, whichsystematically influences the way we talk about arguments within our culture.
Inother words, the conceptual structure behind battle (i.e., that one can shoot, demolish,devise a strategy, win, and so on), is metaphorically transferred onto the domain ofargument.Manifestations of conceptual metaphor are ubiquitous in language and communi-cation.
Here are a few other examples of common metaphorical mappings. TIME IS MONEY (e.g., ?That flat tire costme an hour?
) IDEAS ARE PHYSICAL OBJECTS (e.g., ?I cannot grasp his way ofthinking?
) LINGUISTIC EXPRESSIONS ARE CONTAINERS (e.g., ?I would notbe able to put all my feelings intowords?
) EMOTIONS ARE VEHICLES (e.g., ?[...]
she was transportedwithpleasure?
) FEELINGS ARE LIQUIDS (e.g., ?[...]
all of this stirred an unfathomableexcitement in her?
)309Computational Linguistics Volume 39, Number 2 LIFE IS A JOURNEY (e.g., ?He arrived at the end of his life with very littleemotional baggage?
)CMT produced a significant resonance in the fields of philosophy, linguistics, cogni-tive science, and artificial intelligence, including NLP.
It inspired novel research (Martin1990, 1994; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman andNarayanan 2004;Mason 2004; Martin 2006; Agerri et al2007), but was also criticized for the lack ofconsistency and empirical verification (Murphy 1996; Shalizi 2003; Pinker 2007).
Thesole evidence with which Lakoff and Johnson (1980) supported their theory was a set ofcarefully selected examples.
Such examples, albeit clearly illustrating the main tenets ofthe theory, are not representative.
They cannot possibly capture the whole spectrumof metaphorical expressions, and thus do not provide evidence that the theory canadequately explain the majority of metaphors in real-world texts.
Aiming to verify thelatter, Shutova and Teufel (2010) conducted a corpus-based analysis of conceptual meta-phor in the data from the British National Corpus (BNC) (Burnard 2007).
In their studythree independent participants annotated both linguistic metaphors and the underlyingsource?target domain mappings.
Their results show that although the annotators reachsome overall agreement on the annotation of interconceptual mappings, they experi-enced a number of difficulties, one of which was the problem of finding the right levelof abstraction for the source and target domain categories.
The difficulties in categoryassignment for conceptual metaphor suggest that it is hard to consistently assign explicitlabels to source and target domains, even though the interconceptual associations existin some sense and are intuitive to humans.2.2.2 Selectional Restrictions Violation View.
Lakoff and Johnson do not discuss howmeta-phors can be recognized in linguistic data.
To date, the most influential account of thisissue is that ofWilks (1975, 1978).
According toWilks, metaphors represent a violation ofselectional restrictions (or preferences) in a given context.
Selectional restrictions are thesemantic constraints that a predicate places onto its arguments.
Consider the followingexample.
(17) a.
My aunt always drinks her tea on the terrace.b.
My car drinks gasoline.
(Wilks 1978)The verb drink normally requires a grammatical subject of type ANIMATE and a gram-matical object of type LIQUID, as in Example (17a).
Therefore, drink taking a car as asubject in (17b) is an anomaly, which, according to Wilks, indicates a metaphorical useof drink.Although Wilks?s idea inspired a number of computational experiments on meta-phor recognition (Fass and Wilks 1983; Fass 1991; Krishnakumaran and Zhu 2007), itis important to note that in practice this approach has a number of limitations.
Firstly,there are other kinds of non-literalness or anomaly in language that cause a violation ofsemantic norm, such as metonymies.
Thus the method would overgenerate.
Secondly,there are kinds of metaphor that do not represent a violation of selectional restrictions(i.e., the approach may also undergenerate).
This would happen, for example, whenhighly conventionalized metaphorical word senses are more frequent than the originalliteral senses.
Due to their frequency, selectional preference distributions of such wordsin real-world data would be skewed towards the metaphorical senses (e.g., capturemayselect for ideas rather than captives according to the data).
As a result, no selectionalpreferences violation can be detected in the use of such verbs.
Another case where the310Shutova, Teufel, and Korhonen Statistical Metaphor Processingmethod does not apply is copula constructions, such as ?All the world?s a stage.?
Andfinally, the method does not take into account the fact that interpretation (of metaphoras well as other linguistic phenomena) is always context-dependent.
For example,the phrase ?All men are animals?
uttered by a biology professor or a feminist wouldhave entirely different interpretations, the latter clearly metaphorical, but without anyviolation of selectional restrictions.2.3 Computational Approaches to Metaphor2.3.1 Automatic Metaphor Recognition.
One of the first attempts to automatically identifyand interpret metaphorical expressions in text is the approach of Fass (1991).
It origi-nates in the idea of Wilks (1978) and utilizes hand-coded knowledge.
Fass developed asystem called met*, which is capable of discriminating between literalness, metonymy,metaphor, and anomaly.
It does this in three stages.
First, literalness is distinguishedfrom non-literalness using selectional preference violation as an indicator.
In the casethat non-literalness is detected, the respective phrase is tested for being metonymicusing hand-coded patterns (such as CONTAINER-FOR-CONTENT).
If the system failsto recognize metonymy, it proceeds to search the knowledge base for a relevant analogyin order to discriminate metaphorical relations from anomalous ones.
For example, thesentence in Example (17b) would be represented in this framework as (car,drink,gasoline),which does not satisfy the preference (animal,drink,liquid), as car is not a hyponym ofanimal.
met* then searches its knowledge base for a triple containing a hypernym ofboth the actual argument and the desired argument and finds (thing,use,energy source),which represents the metaphorical interpretation.Goatly (1997) identifies a set of linguistic cues, namely, lexical patterns indicatingthe presence of a metaphorical expression in running text, such as metaphorically speak-ing, utterly, completely, so to speak, and literally.
This approach, however, is likely to findonly a small proportion ofmetaphorical expressions, as the vast majority of them appearwithout any signaling context.
We conducted a corpus study in order to investigate theeffectiveness of linguistic cues asmetaphor indicators.
For each cue suggested by Goatly(1997), we randomly sampled 50 sentences from the BNC containing it and manuallyannotated them for metaphoricity.
The results are presented in Table 1.
The averageprecision (i.e., the proportion of identified expressions that were metaphorical) of thelinguistic cue method according to these data is 0.40, which suggests that the set ofmetaphors that this method generates contains a great deal of noise.
Thus the cues areunlikely to be sufficient for metaphor extraction on their own, but together with someadditional filters, they could contribute to a more complex system.The work of Peters and Peters (2000) concentrates on detecting figurative languagein lexical resources.
They mine WordNet (Fellbaum 1998) for examples of systematicTable 1Corpus statistics for linguistic cues.Cue BNC frequency Sample size Metaphors Precision?metaphorically speaking?
7 7 5 0.71?literally?
1,936 50 13 0.26?figurative?
125 50 9 0.18?utterly?
1,251 50 16 0.32?completely?
8,339 50 13 0.26?so to speak?
353 49 35 0.71311Computational Linguistics Volume 39, Number 2polysemy, which allows them to capture metonymic and metaphorical relations.
Theirsystem searches for nodes that are relatively high in the WordNet hierarchy (i.e., arerelatively general) and that share a set of commonword forms among their descendants.Peters and Peters found that such nodes often happen to be in a metonymic (e.g.,publisher ?
publication) or a metaphorical (e.g., theory ?
supporting structure) relation.The CorMet system (Mason 2004) is the first attempt at discovering source?target domain mappings automatically.
It does this by finding systematic variations indomain-specific selectional preferences, which are inferred from texts on the Web.
Forexample, Mason collects texts from the LAB domain and the FINANCE domain, in bothof which pourwould be a characteristic verb.
In the LAB domain pour has a strong selec-tional preference for objects of type liquid, whereas in the FINANCE domain it selects formoney.
From this Mason?s system infers the domain mapping FINANCE ?
LAB and theconcept mappingMONEY IS LIQUID.
He compares the output of his system against theMaster Metaphor List (MML; Lakoff, Espenson, and Schwartz 1991) and reports a per-formance of 77% in terms of accuracy (i.e., proportion of correctly induced mappings).Birke and Sarkar (2006) present a sentence clustering approach for non-literal lan-guage recognition, implemented in the TroFi system (Trope Finder).
The idea behindtheir system originates from a similarity-based word sense disambiguation methoddeveloped by Karov and Edelman (1998).
The latter uses a set of seed sentences anno-tated with respect to word sense.
The system computes similarity between the sentencecontaining the word to be disambiguated and all of the seed sentences and selects thesense corresponding to the annotation in the most similar seed sentences.
Birke andSarkar adapt this algorithm to perform a two-way classification (literal vs. non-literal),not aiming to distinguish between specific kinds of tropes.
An example for the verbpour in their database is shown in Figure 2.
They attain a performance of 0.54 in termsof F-measure (van Rijsbergen 1979).Themethod of Gedigian et al(2006) discriminates between literal andmetaphoricaluse.
The authors trained a maximum entropy classifier for this purpose.
They col-lected their data using FrameNet (Fillmore, Johnson, and Petruck 2003) and PropBank(Kingsbury and Palmer 2002) annotations.
FrameNet is a lexical resource for Englishcontaining information on words?
semantic and syntactic combinatory possibilities, orvalencies, in each of their senses.
PropBank is a corpus annotated with verbal propo-sitions and their arguments.
Gedigian et al(2006) extracted the lexical items whoseframes are related to MOTION and CURE from FrameNet, then searched the PropBankWall Street Journal corpus (Kingsbury and Palmer 2002) for sentences containing suchlexical items and annotated them with respect to metaphoricity.
For example, the verbrun in the sentence ?Texas Air has run into difficulty?
was annotated as metaphorical,and in ?I was doing the laundry and nearly broke my neck running upstairs to see?as literal.
Gedigian et alused PropBank annotation (arguments and their semanticpour*nonliteral cluster*wsj04:7878 N As manufacturers get bigger, they are likely to pour more money into the battle for shelfspace, raising the ante for new players.wsj25:3283 N Salsa and rap music pour out of the windows.wsj06:300 U Investors hungering for safety and high yields are pouring record sums into single-premium, interest-earning annuities.
*literal cluster*wsj59:3286 L Custom demands that cognac be poured from a freshly opened bottle.Figure 2An example of the data of Birke and Sarkar (2006).312Shutova, Teufel, and Korhonen Statistical Metaphor Processingtypes) as features to train the classifier, and report an accuracy of 95.12%.
This result is,however, only 2.22 percentage points higher than the performance of the naive baselineassigning majority class to all instances (92.90%).
Such high performance of their systemcan be explained by the fact that 92.90% of the verbs ofMOTION and CURE in their dataare used metaphorically, thus making the data set unbalanced with respect to targetcategories and making the task easier.Both Birke and Sarkar (2006) and Gedigian et al(2006) focus only on metaphorsexpressed by a verb.
The approach of Krishnakumaran and Zhu (2007) additionallycovers metaphors expressed by nouns and adjectives.
Krishnakumaran and Zhu usehyponymy relation in WordNet and word bigram counts to predict metaphors at asentence level.
Given a metaphor in copula constructions, or an IS-A metaphor (e.g., thefamous quote by William Shakespeare ?All the world?s a stage?)
they verify if the twonouns involved are in hyponymy relation inWordNet, otherwise this sentence is taggedas containing a metaphor.
They also treat expressions containing a verb or an adjectiveused metaphorically (e.g., ?He planted good ideas in their minds?
or ?He has a fertileimagination?).
For those cases, they calculate bigram probabilities of verb?noun andadjective?noun pairs (including the hyponyms/hypernyms of the noun in question).
Ifthe combination is not observed in the data with sufficient frequency, the system tagsthe sentence as metaphorical.
This idea is a modification of the selectional preferenceview of Wilks, although applied at the bigram level.
Alternatively, one could extractverb?object relations from parsed text.
Compared to the latter, Krishnakumaran andZhu (2007) lose a great deal of information.
The authors evaluated their system on aset of example sentences compiled from the Master Metaphor List, whereby highly con-ventionalized metaphors are taken to be negative examples.
Thus they do not deal withliteral examples as such.
Essentially, the distinction Krishnakumaran and Zhu are mak-ing is between the senses included inWordNet, even if they are conventional metaphors(e.g., ?capture an idea?
), and those not included in WordNet (e.g., ?planted good ideas?
).2.3.2 Automatic Metaphor Interpretation.
One of the first computational accounts of meta-phor interpretation is that of Martin (1990).
In his metaphor interpretation, denotationand acquisition system (MIDAS), Martin models the hierarchical organization of con-ventional metaphors.
The main assumption underlying this approach is that more spe-cific conventional metaphors (e.g., COMPUTATIONAL PROCESS viewed as a LIVINGBEING in ?How can I kill a process??)
descend from more general ones (e.g., PROCESS[general, as a sequence of events] is a LIVINGBEING).
Given an example of ametaphor-ical expression, MIDAS searches its database for a corresponding conceptual metaphorthat would explain the anomaly.
If it does not find any, it abstracts from the example tomore general concepts and repeats the search.
If a suitable general metaphor is found,it creates a new mapping for its descendant, a more specific metaphor, based on thisexample.
This is also how novel conceptual metaphors are acquired by the system.The metaphors are then organized into a resource called MetaBank (Martin 1994).
Theknowledge is represented in MetaBank in the form of metaphor maps (Martin 1988)containing detailed information about source-target concept mappings and empiricallyderived examples.
MIDAS has been integrated with Unix Consultant, a system thatanswers users?
questions about Unix.
The system first tries to find a literal answer to thequestion.
If it is not able to, it calls MIDAS, which detects metaphorical expressions viaselectional preference violation and searches its database for a metaphor explaining theanomaly in the question.Another cohort of approaches aims to perform inference about entities and eventsin the source and target domains for the purpose of metaphor interpretation.
These313Computational Linguistics Volume 39, Number 2include the KARMA system (Narayanan 1997, 1999; Feldman and Narayanan 2004)and the ATT-Meta project (Barnden and Lee 2002; Agerri et al2007).
Within bothsystems the authors developed a metaphor-based reasoning framework in accordancewith CMT.
The reasoning process relies on manually coded knowledge about the worldand operates mainly in the source domain.
The results are then projected onto the targetdomain using the conceptual mapping representation.
The ATT-Meta project concernsmetaphorical and metonymic description of mental states; and reasoning about mentalstates is performed using first order logic.
Their system, however, does not take naturallanguage sentences as input, but hand-coded logical expressions that are representa-tions of small discourse fragments.
KARMA in turn deals with a broad range of abstractactions and events and takes parsed text as input.Veale and Hao (2008) derive a ?fluid knowledge representation for metaphor inter-pretation and generation?
called Talking Points.
Talking Points is a set of characteristicsof concepts belonging to source and target domains and related facts about the worldwhich are acquired automatically from WordNet and from the Web.
Talking Points arethen organized in Slipnet, a framework that allows for a number of insertions, deletions,and substitutions in definitions of such characteristics in order to establish a connectionbetween the target and the source concepts.
This work builds on the idea of slippage inknowledge representation for understanding analogies in abstract domains (Hofstadterand Mitchell 1994; Hofstadter 1995).
The following is an example demonstrating howslippage operates to explain the metaphorMake-up is a Western burqa.Make-up =>?
typically worn by women?
expected to be worn by women?must be worn by women?must be worn by Muslim womenBurqa <=By doing insertions and substitutions, the system arrives from the definition ?typi-cally worn by women?
to that of ?must be worn byMuslimwomen.?
Thus it establishesa link between the concepts of make-up and burqa.
Veale and Hao, however, did notevaluate to what extent their system is able to interpret metaphorical expressions inreal-world text.The next sections of the paper are devoted to our own experiments on metaphoridentification and interpretation.3.
Metaphor Identification Method and ExperimentsThe first task for metaphor processing within NLP is its identification in text.
As dis-cussed earlier, previous approaches to this problem either utilize hand-coded knowl-edge (Fass 1991; Krishnakumaran and Zhu 2007) or reduce the task to searching formetaphors of a specific domain defined a priori (e.g., MOTIONmetaphors) in a specifictype of discourse (e.g., the Wall Street Journal [Gedigian et al2006]).
In contrast, thesearch space in our experiments is the entire BNC and the domain of the expressionsidentified is unrestricted.
In addition, the developed technique does not rely on anyhand-crafted lexical or world knowledge, but rather captures metaphoricity by meansof verb and noun clustering in a data-driven manner.Themotivation behind the use of clusteringmethods for themetaphor identificationtask lies in CMT.
The patterns of conceptual metaphor (e.g., FEELINGS ARE LIQUIDS)314Shutova, Teufel, and Korhonen Statistical Metaphor Processingalways operate on semantic classes, that is, groups of related concepts, defined byLakoff and Johnson as conceptual domains (FEELINGS include love, anger, hatred, etc.
;LIQUIDS include water, tea, petrol, beer, etc.).
Thus modeling metaphorical mechanismsin accordance with CMT would involve capturing such semantic classes automatically.Previous research on corpus-based lexical semantics has shown that it is possible toautomatically induce semantic word classes from corpus data via clustering of contex-tual cues (Pereira, Tishby, and Lee 1993; Lin 1998; Schulte im Walde 2006).
The currentconsensus is that the lexical items showing similar behavior in a large body of text mostlikely have related meanings.The second reason for the use of unsupervised and weakly supervised methodsis suggested by the results of corpus-based studies of conceptual metaphor.
The anal-ysis of conceptual mappings in unrestricted text, conducted by Shutova and Teufel(2010), although confirming some aspects of CMT, uncovered a number of fundamentaldifficulties.
One of these is the choice of the level of abstraction and granularity ofcategories (i.e., labels for source and target domains).
This suggests that it is hardto define a comprehensive inventory of labels for source and target domains.
Thus acomputational model of metaphorical associations should not rely on explicit domainlabels.
Unsupervised methods allow us to recover patterns in data without assigningany explicit labels to concepts, and thus to model interconceptual mappings implicitly.The method behind our metaphor identification system relies on distributionalclustering.
Noun clustering, specifically, is central to the approach.
It is traditionallyassumed that noun clusters produced using distributional clustering contain conceptsthat are similar to each other.
This is true only in part, however.
There exist two typesof concepts: concrete, those concepts denoting physical entities or physical experiences(e.g., chair, apple, house, rain) and abstract, those concepts that do not physically existat any particular time or place, but rather exist as a type of thing or as an idea (e.g.,justice, love, democracy).
It is the abstract concepts that tend to be described metaphori-cally, rather than concrete concepts.
Humans use metaphor attempting to gain a betterunderstanding of an abstract concept by comparing it to their physical experiences.
Asa result, abstract concepts expose different distributional behavior in a corpus.
Thisin turn affects the application of clustering techniques and the obtained clusters forconcrete and abstract concepts would be structured differently.
Consider the example inFigure 3.
The figure shows a cluster containing concrete concepts (on the right) that arevarious kinds of mechanisms; a cluster containing verbs co-occurring with mechanismsin the corpus (at the bottom); and a cluster containing abstract concepts (on the left)that tend to co-occur with these verbs.
Such abstract concepts, albeit having quitedistinct meanings (e.g., marriage and democracy), are observed in similar lexico-syntacticenvironments.
This is due to the fact that they are systematically used metaphoricallywith the verbs from the domain of MECHANISM.
Hence, they are automaticallyassigned to the same cluster.
The following examples illustrate this phenomenon intextual data.
(18) Our relationship is not really working.
(19) Diana and Charles did not succeed in mending their marriage.
(20) The wheels of Stalin?s regime were well oiled and already turning.Such a structure of the abstract clusters can be explained by the fact that relationships,marriages, collaborations, and political systems are all cognitively mapped to the same315Computational Linguistics Volume 39, Number 2Figure 3Cluster of target concepts associated with MECHANISM.source domain of MECHANISM.
In contrast to concrete concepts, such as tea, water,coffee, beer, drink, liquid, that are clustered together when they have similar meanings,abstract concepts tend to be clustered together if they are associated with the samesource domain.We define this phenomenon as clustering by association and it becomescentral to the system design.
The expectation is that clustering by association wouldallow the harvesting of new target domains that are associated with the same sourcedomain, and thus identify new metaphors.The metaphor identification system starts from a small set of seed metaphoricalexpressions, that is, annotatedmetaphors (such as those in Examples (18) or (19)), whichserve as training data.
Note that seed annotation only concerns linguistic metaphors;metaphorical mappings are not annotated.
The system then (1) creates source domainsdescribing these examples by means of verb clustering (such as the verb cluster inFigure 3); (2) identifies new target domains associated with the same source domain bymeans of noun clustering (see, e.g., ABSTRACT cluster in Figure 3), and (3) establishes alink between the source and the target clusters based on the seed examples.Thus the system captures metaphorical associations implicitly.
It generalizes overthe associated domains by means of verb and noun clustering.
The obtained clustersthen represent source and target concepts between which metaphorical associationshold.
The knowledge of such associations is then used to identify new metaphoricalexpressions in a large corpus.In addition to this, we build a selectional preference?based metaphor filter.
Thisidea stems from the view of Wilks (1978), but is, however, a modification of it.
Thefilter assumes that the verbs exhibiting weak selectional preferences, namely, verbs co-occurring with any argument class in linguistic data (remember, influence, etc.)
generallyhave no or only weak potential for being a metaphor.
It has been previously shownthat it is possible to quantify verb selectional preferences on the basis of corpus data,using, for example, a measure defined by Resnik (1993).
Once the candidate metaphorsare identified in the corpus using clustering methods, those displaying weak selectionalpreferences can be filtered out.Figures 4 and 5 depict the metaphor identification pipeline: first, the identifica-tion of metaphorical associations and then that of metaphorical expressions in text.
In316Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingFigure 4Learning metaphorical associations by means of verb and noun clustering and using the seed set.summary, the system (1) starts from a seed set of metaphorical expressions exemplifyinga range of source?target domain mappings; (2) performs noun clustering in order toharvest various target concepts associated with the same source domain; (3) creates asource domain verb lexicon by means of verb clustering; (4) searches the corpus formetaphorical expressions describing the target domain concepts using the verbs fromthe source domain lexicon; and (5) filters out the candidates exposing weak selectionalpreference strength as non-metaphorical.Figure 5Identification of new metaphorical expressions in text.317Computational Linguistics Volume 39, Number 23.1 Experimental DataThe identification system takes a list of seed phrases as input.
Seed phrases containmanually annotated linguistic metaphors.
The system generalizes from these linguisticmetaphors to the respective conceptual metaphors by means of clustering.
This gen-eralization is then used to harvest a large number of new metaphorical expressions inunseen text.
Thus the data needed for the identification experiment consist of a seed set,data sets of verbs and nouns that are subsequently clustered, and an evaluation corpus.3.1.1 Metaphor Corpus and Seed Phrases.
The data to test the identification module wereextracted from the metaphor corpus created by Shutova and Teufel (2010).
Their corpusis a subset of the BNC (Burnard 2007) and, as such, it provides a suitable platformfor testing the metaphor processing system on real-world general-domain expressionsin contemporary English.
Our data set consists of verb?subject and verb?direct objectmetaphorical expressions.
In order to avoid extra noise, we enforced some additionalselection criteria.
All phrases were included unless they fell in one of the followingcategories: Phrases where the subject or object referent is unknown (e.g., containingpronouns such as in ?in which they [changes] operated?)
or representedby a named entity (e.g., ?Then Hillary leapt into the conversation?
).These cases were excluded from the data set because their processingwould involve the use of additional modules for coreference resolutionand named entity recognition, which in turn may introduce additionalerrors into the system. Phrases whose metaphorical meaning is realized solely in passiveconstructions (e.g., ?sociologists have been inclined to [..]?).
These caseswere excluded because for many such examples it was hard for humansto produce a literal paraphrase realized in the form of the same syntacticconstruction.
Thus their paraphrasing was deemed to be an unfairlyhard task for the system. Multiword metaphors (e.g., ?whether we go on pilgrimage with Raleigh orput out to seawith Tennyson?).
The current system is designed to identifyand paraphrase single-word, lexical metaphors.
In the future the systemneeds to be modified to process multiword metaphorical expressions;this is, however, outside the scope of the current experiments.The resulting data set consists of 62 phrases that are different single-word metaphorsrepresenting verb?subject and verb?direct object relations, where a verb is used meta-phorically.
The phrases include, for instance, ?stir excitement,?
?reflect enthusiasm,?
?grasp theory,?
?cast doubt,?
?suppressmemory,?
?throw remark?
(verb?direct object con-structions); and ?campaign surged,?
?factor shaped [...],?
?tension mounted,?
?ideologyembraces,?
?example illustrates?
(subject?verb constructions).
This data set was used asa seed set in the identification experiments.
The phrases in the data set were manuallyannotated for grammatical relations.3.1.2 Verb and Noun Data Sets.
The noun data set used for clustering consists of the2,000 most frequent nouns in the BNC.
The 2,000 most frequent nouns cover mostcommon target categories and their linguistic realizations.
BNC represents a suitable318Shutova, Teufel, and Korhonen Statistical Metaphor Processingsource for such nouns because the corpus is balanced with respect to genre, style,and theme.The verb data set is a subset of VerbNet (Kipper et al2006).
VerbNet is the largestresource for general-domain verbs organized into semantic classes as proposed by Levin(1993).
The data set includes all the verbs in VerbNet with the exception of highlyinfrequent ones.
The frequency of the verbs was estimated from the data collected byKorhonen, Krymolowski, and Briscoe (2006) for the construction of the VALEX lexicon,which to date is one of the largest automatically created verb resources.
The verbs fromVerbNet that appear less than 150 times in this data were excluded.
The resulting dataset consists of 1,610 general-domain verbs.3.1.3 Evaluation Corpus.
The evaluation data for metaphor identification was the BNCparsed by the RASP parser (Briscoe, Carroll, and Watson 2006).
We used the gram-matical relation (GR) output of RASP for the BNC created by Andersen et al(2008).The system searched the corpus for the source and target domain vocabulary within aparticular grammatical relation (verb?direct object or verb?subject).3.2 MethodThe main components of the method include (1) distributional clustering of verbsand nouns, (2) search through the parsed corpus, and (3) selectional preference-basedfiltering.3.2.1 Verb and Noun Clustering Method.
The metaphor identification system relies onthe clustering method of Sun and Korhonen (2009).
They use a rich set of syntacticand semantic features (GRs, verb subcategorization frames [SCFs], and selectionalpreferences) and spectral clustering, a method particularly suitable for the resultinghigh dimensional feature space.
This algorithm has proved to be effective in previousverb clustering experiments (Brew and Schulte im Walde 2002) and in other NLP tasksinvolving high dimensional data (Chen et al2006).Spectral clustering partitions objects relying on their similarity matrix.
Given a setof data points, the similarity matrix records similarities between all pairs of points.
Thesystem of Sun and Korhonen (2009) constructs similarity matrices using the Jensen-Shannon divergence as a measure.
Jensen-Shannon divergence between two featurevectors wi and wj is defined as follows:JSD(wi,wj) =12D(wi||m)+ 12D(wj||m) (1)where D is the Kullback-Leibler divergence, and m is the average of the wi and wj.Spectral clustering can be viewed in abstract terms as the partitioning of a graphG over a set of words W. The weights on the edges of G are the similarities Sij.
Thesimilarity matrix S thus represents the adjacency matrix for G. The clustering problemis then defined as identifying the optimal partition, or cut, of the graph into clusters,such that the intra-cluster weights are high and the inter-cluster weights are low.
Thesystem of Sun and Korhonen (2009) uses the MNCut algorithm of Meila and Shi (2001)for this purpose.Sun and Korhonen (2009) evaluated their clustering approach on 204 verbs from17 Levin classes and obtained an F-measure of 80.4, which is the state-of-the-art319Computational Linguistics Volume 39, Number 2performance level.
The metaphor identification system uses the method of Sun andKorhonen to cluster both verbs and nouns (separately), however, significantly extendingits coverage to unrestricted general-domain data and applying the method to a con-siderably larger data set of 1,610 verbs.3.2.2 Feature Extraction and Clustering Experiments.
For verb clustering, the best perform-ing features from Sun and Korhonen (2009) were adopted.
These include automaticallyacquired verb SCFs parameterized by their selectional preferences.
These features wereobtained using the SCF acquisition system of Preiss, Briscoe, and Korhonen (2007).
Thesystem tags and parses corpus data using the RASP parser (Briscoe, Carroll, andWatson2006) and extracts SCFs from the produced grammatical relations using a rule-basedclassifier which identifies 168 SCF types for English verbs.
It produces a lexical entryfor each verb and SCF combination occurring in corpus data.
The selectional preferenceclasses were obtained by clustering nominal arguments appearing in the subject andobject slots of verbs in the resulting lexicon.Following previous works on semantic noun classification (Pantel and Lin 2002;Bergsma, Lin, and Goebel 2008), grammatical relations were used as features for nounclustering.
More specifically, the frequencies of nouns and verb lemmas appearing inthe subject, direct object, and indirect object relations in the RASP-parsed BNC wereincluded in the feature vectors.
For example, the feature vector for bananawould containthe following entries: {eat-dobj n1, fry-dobj n2, sell-dobj n3,..., eat with-iobj ni,look at-iobj ni+1,..., rot-subj nk, grow-subj nk+1,...}.We experimented with different clustering granularities, subjectively examined theobtained clusters, and determined that the number of clusters set to 200 is the mostsuitable setting for both nouns and verbs in our task.
This was done by means of qual-itative analysis of the clusters as representations of source and target domains?that is,by judging how complete and homogeneous the verb clusters were as lists of potentialsource domain vocabulary and howmany new target domains associated with the samesource domain were found correctly in the noun clusters.
This analysis was performedon a randomly selected set of 10 clusters taken from different granularity settings andnone of the seed expressions were used for it.
Examples of such clusters are shown inFigures 6 (nouns) and 7 (verbs), respectively.
The noun clusters represent target conceptsassociated with the same source concept (some suggested source concepts are given inFigure 6, although the system only captures those implicitly).
The verb clusters containlists of source domain vocabulary.3.2.3 Corpus Search.Once the clusters have been obtained, the system proceeds to searchthe corpus for source and target domain terms within verb?object (both direct andindirect) and verb?subject relations.
For each seed expression, a cluster is retrieved forthe verb to form the source concept, and a cluster is retrieved for the noun to form a listof target concepts.
The retrieved verb and noun clusters are then linked, and such linksrepresent metaphorical associations.
The system then classifies grammatical relations inthe corpus as metaphorical if the lexical items in the grammatical relation appear in thelinked source (verb) and target (noun) clusters.
This search is performed on the BNCparsed by RASP.
Consider the following example sentence extracted from the BNC (theBNC text ID is given in brackets, followed by the hypothetical conceptual metaphor):(21) Few would deny that in the nineteenth century change was greatly accelerated.
(ACA) ?
CHANGE IS MOTION320Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingSource: MECHANISMTarget Cluster: consensus relation tradition partnership resistance foundation alliance friendship con-tact reserve unity link peace bond myth identity hierarchy relationship connection balance marriagedemocracy defense faith empire distinction coalition regime divisionSource: PHYSICAL OBJECT; LIVING BEING; STRUCTURETarget Cluster: view conception theory concept ideal belief doctrine logic hypothesis interpretationproposition thesis assumption idea argument ideology conclusion principle notion philosophySource: STORY; JOURNEYTarget Cluster: politics practice trading reading occupation profession sport pursuit affair career think-ing lifeSource: LIQUIDTarget Cluster: disappointment rage concern desire hostility excitement anxiety passion doubt panicdelight anger fear curiosity shock terror surprise pride happiness pain enthusiasm alarm hope memorylove satisfaction sympathy spirit frustration impulse instinct warmth beauty ambition thought guiltemotion sensation horror feeling laughter suspicion pleasureSource: LIVING BEING; ENDTarget Cluster: defeat fall death tragedy loss collapse decline disaster destruction fateFigure 6Clustered nouns (the associated source domain labels are suggested by the authors for clarity;the system does not assign any labels, but models source and target domains implicitly).Source Cluster: sparkle glow widen flash flare gleam darken narrow flicker shine blaze bulgeSource Cluster: gulp drain stir empty pour sip spill swallow drink pollute seep flow drip purify oozepump bubble splash ripple simmer boil treadSource Cluster: polish clean scrape scrub soakSource Cluster: kick hurl push fling throw pull drag haulSource Cluster: rise fall shrink drop double fluctuate dwindle decline plunge decrease soar tumblesurge spiral boomSource Cluster: initiate inhibit aid halt trace track speed obstruct impede accelerate slow stimulatehinder blockSource Cluster: work escape fight head ride fly arrive travel come run go slip moveFigure 7Clustered verbs.The relevant GRs identified by the parser are presented in Figure 8.
The relation betweenthe verb accelerate and its semantic object change in Example (21) is expressed in thepassive voice and is, therefore, tagged by RASP as an ncsubj GR.
Because this GR con-tains terminology from associated source (MOTION) and target (CHANGE) domains,it is marked as metaphorical and so is the term accelerate, which belongs to the sourcedomain of MOTION.3.2.4 Selectional Preference Strength Filter.
In the previous step a set of candidate verbmetaphors and the associated grammatical relations were extracted from the BNC.These now need to be filtered based on selectional preference strength.
To do this, weFigure 8Grammatical relations output for metaphorical expressions.321Computational Linguistics Volume 39, Number 2automatically acquire selectional preference distributions for verb?subject and verb?direct object relations from the RASP-parsed BNC.
The noun clusters obtained usingSun and Korhonen?s method as described earlier form the selectional preference classes.To quantify selectional preferences, we adopt the selectional preference strength (SPS)measure of Resnik (1993).
Resnik models selectional preferences of a verb in proba-bilistic terms as the difference between the posterior distribution of noun classes in aparticular relation with the verb and their prior distribution in that syntactic positionirrespective of the identity of the verb.
He quantifies this difference using the Kullback-Leibler divergence and defines selectional preference strength as follows:SR(v) = D(P(c|v)||P(c)) =?cP(c|v) logP(c|v)P(c) (2)where P(c) is the prior probability of the noun class, P(c|v) is the posterior probabilityof the noun class given the verb, and R is the grammatical relation in question.
In orderto quantify how well a particular argument class fits the verb, Resnik defines anothermeasure called selectional association:AR(v, c) =1SR(v)P(c|v) logP(c|v)P(c)(3)which stands for the contribution of a particular argument class to the overall selectionalpreference strength of a verb.The probabilities P(c|v) and P(c) were estimated from the corpus data as follows:P(c|v) =f (v, c)?k f (v, ck)(4)P(c) =f (c)?k f (ck)(5)where f (v, c) is the number of times the predicate v co-occurs with the argument class cin the relation R, and f (c) is the number of times the argument class occurs in the relationR regardless of the identity of the predicate.Thus for each verb, its SPS can be calculated for specific grammatical relations.This measure was used to filter out the verbs with weak selectional preferences.
Theexpectation is that such verbs are unlikely to be used metaphorically.
The optimalselectional preference strength threshold was set experimentally for both verb?subjectand verb?object relations on a small held-out data set (via qualitative analysis of thedata).
It approximates to 1.32.
The system excludes expressions containing the verbswith preference strength below this threshold from the set of candidate metaphors.Examples of verbs with weak and strong direct object SPs are shown in Tables 2 and3, respectively.
Given the SPS threshold of 1.32, the filter discards 31% of candidateexpressions initially identified in the corpus.3.3 EvaluationIn order to show that the described metaphor identification method generalizes wellover the seed set and that it operates beyond synonymy, its output was compared to322Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingTable 2Verbs with weak direct object SPs.SPS Verb1.3175 undo1.3160 bud1.3143 deplore1.3138 seal1.3131 slide1.3126 omit1.3118 reject1.3097 augment1.3094 frustrate1.3087 restrict1.3082 employ1.3081 highlight1.3081 correspond1.3056 dab1.3053 assist1.3043 neglect...Table 3Verbs with strong direct object SPs.SPS Verb SPS Verb...3.0810 aggravate 2.9434 coop3.0692 dispose 2.9326 hobble3.0536 rim 2.9285 paper3.0504 deteriorate 2.9212 sip3.0372 mourn ...3.0365 tread 1.7889 schedule3.0348 cadge 1.7867 cheat3.0254 intersperse 1.7860 update3.0225 activate 1.7840 belt3.0085 predominate 1.7835 roar3.0033 lope 1.7824 intensify2.9957 bone 1.7811 read2.9955 pummel 1.7805 unnerve2.9868 disapprove 1.7776 arrive2.9838 hoover 1.7775 publish2.9824 beam 1.7775 reason2.9807 amble 1.7774 bond2.9760 diversify 1.7770 issue2.9759 mantle 1.7760 verify2.9730 pulverize 1.7734 vomit2.9604 skim 1.7728 impose2.9539 slam 1.7726 phone2.9523 archive 1.7723 purify2.9504 grease ...323Computational Linguistics Volume 39, Number 2that of a baseline using WordNet.
In the baseline system, WordNet synsets representsource and target domains.
The quality of metaphor identification for both the systemand the baseline was evaluated in terms of precision with the aid of human judges.To compare the coverage of the system to that of the baseline in quantitative terms weassessed how broadly they expand on the seed set.
To do this, we estimated the numberof word senses captured by the two systems and the proportion of identified metaphorsthat are not synonymous with any of those seen in the seed set, according to WordNet.This type of evaluation assesses how well clustering methods are suited to identify newmetaphors not directly related to those in the seed set.3.3.1 Comparison with WordNet Baseline.
The baseline system was implemented usingsynonymy information from WordNet to expand on the seed set.
Source and targetdomain vocabularies were thus represented as sets of synonyms of verbs and nouns inseed expressions.
The baseline system then searched the corpus for phrases composedof lexical items belonging to those vocabularies.
For example, given a seed expression?stir excitement,?
the baseline finds phrases such as ?arouse fervour, stimulate agitation,stir turmoil,?
and so forth.
It is not able to generalize over the concepts to broadsemantic classes, however?for example, it does not find other FEELINGS such asrage, fear, anger, pleasure.
This, however, is necessary to fully characterize the targetdomain.
Similarly, in the source domain, the system only has access to direct synonymsof stir, rather than to other verbs characteristic of the domain of LIQUIDS (pour, flow,boil, etc.
).To compare the coverage achieved by the system using clustering to that of thebaseline in quantitative terms, we estimated the number of WordNet synsets, thatis, different word senses, in the metaphorical expressions captured by the two sys-tems.
We found that the baseline system covers only 13% of the data identified usingclustering.
This is due to the fact that it does not reach beyond the concepts presentin the seed set.
In contrast, most metaphors tagged by the clustering method (87%)are non-synonymous to those in the seed set and some of them are novel.
Together,these metaphors represent a considerably wider range of meanings.
Given the seedmetaphors ?stir excitement, throw remark, cast doubt,?
the system identifies previouslyunseen expressions ?swallow anger, hurl comment, spark enthusiasm,?
and so on, asmetaphorical.
Tables 4 and 5 show examples of how the system and the baseline expandon the seed set, respectively.
Full sentences containing metaphors annotated by thesystem are shown in Figure 9.
Twenty-one percent of the expressions identified by thesystem do not have their correspondingmetaphorical senses included inWordNet, suchas ?spark enthusiasm?
; the remaining 79% are, however, more common conventionalmetaphors.
Starting with a seed set of only 62 examples, the system expands signif-icantly on the seed set and identifies a total of 4,456 metaphorical expressions in theBNC.
This suggests that the method has the potential to attain a broad coverage of thecorpus given a large and representative seed set.3.3.2 Evaluation Against Human Judgments.
In order to assess the quality of metaphoridentification by both systems, their output was assessed by human judgments.
Forthis purpose, we randomly sampled sentences containing metaphorical expressions asannotated by the system and by the baseline and asked human annotators to decidewhether these were metaphorical or not.Participants Five volunteers participated in the experiment.
They were all nativespeakers of English and had no formal training in linguistics.324Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingTable 4Examples of seed set expansion by the system.Seed phrase Harvested metaphors BNC frequencyreflect concern (V-O): reflect concern 78reflect interest 74reflect commitment 26reflect preference 22reflect wish 17reflect determination 12reflect intention 8reflect willingness 4reflect sympathy 3reflect loyalty 2disclose interest 10disclose intention 3disclose concern 2disclose sympathy 1disclose commitment 1disguise interest 6disguise intention 3disguise determination 2obscure interest 1obscure determination 1cast doubt (V-O): cast doubt 197cast fear 3cast suspicion 2catch feeling 3catch suspicion 2catch enthusiasm 1catch emotion 1spark fear 10spark enthusiasm 3spark passion 1spark feeling 1campaign surged (S-V): campaign surged 1charity boomed 1effort decreased 1expedition doubled 1effort doubled 1campaign shrank 1campaign soared 1drive spiraled 1Materials The subjects were presented with a set of 78 randomly sampled sentencesannotated by the two systems.
Fifty percent of the data set were the sentences annotatedby the identification system and the remaining 50%were annotated by the baseline; andthe sentences were randomized.
The annotation was done electronically in MicrosoftWord.
An example of annotated sentences is given in Figure 10.Task and guidelines The subjects were asked to mark which of the expressions weremetaphorical in their judgment.
The participants were encouraged to rely on theirown intuition of what a metaphor is in the annotation process.
Additional guidance,325Computational Linguistics Volume 39, Number 2Table 5Examples of seed set expansion by the baseline.Seed phrase Harvested metaphors BNC frequencyreflect concern (V-O): reflect concern 78ponder business 1ponder headache 1reflect business 4reflect care 2reflect fear 19reflect worry 3cast doubt (V-O): cast doubt 197cast question 11couch question 1drop question 2frame question 21purge doubt 2put doubt 12put question 151range question 1roll question 1shed doubt 2stray question 1throw doubt 35throw question 17throw uncertainty 1campaign surged (S-V): campaign surged 1campaign soared 1however, in the form of the following definition of metaphor (Pragglejaz Group 2007)was also provided:1.
For each verb establish its meaning in context and try to imagine a morebasic meaning of this verb in other contexts.
Basic meanings normally are:(1) more concrete; (2) related to bodily action; (3) more precise (as opposedto vague); (4) historically older.2.
If you can establish a basic meaning that is distinct from the meaning ofthe verb in this context, the verb is likely to be used metaphorically.CKM 391 Time and time again he would stare at the ground, hand on hip, if he thought he had receiveda bad call, and then swallow his anger and play tennis.AD9 3205 He tried to disguise the anxiety he felt when he found the comms system down, but Tammuzwas nearly hysterical by this stage.AMA 349Wewill halt the reduction in NHS services for long-term care and community health serviceswhich support elderly and disabled patients at home.ADK 634 Catch their interest and spark their enthusiasm so that they begin to see the product?spotential.K2W 1771 The committee heard today that gangs regularly hurled abusive comments at local people,making an unacceptable level of noise and leaving litter behind them.Figure 9Sentences tagged by the system (metaphors in bold).326Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingFigure 10Evaluation of metaphor identification.Interannotator agreement Reliability was measured at ?
= 0.63 (n = 2,N = 78, k = 5).The data suggest that the main source of disagreement between the annotators was thepresence of conventional metaphors (e.g., verbs such as adopt, convey, decline).Results The system performance was then evaluated against the elicited judgments interms of precision.
The system output was compared to the gold standard constructedby merging the judgments, whereby the expressions tagged as metaphorical by at leastthree annotators were considered to be correct.
This resulted in P = 0.79, with thebaseline attaining P = 0.44.
In addition, the system tagging was compared to that ofeach annotator pairwise, yielding an average P = 0.74 for the system and P = 0.41 forthe baseline.In order to compare system performance to the human ceiling, pairwise agreementwas additionally calculated in terms of precision between the majority gold standardand each judge.
This corresponds to an average of P = 0.94.To show that the system performance is significantly different from that of the base-line, we annotated additional 150 instances identified by both systems for correctnessand conducted a one-tailed t-test for independent samples.
The difference is statisticallysignificant with t = 4.11 (df = 148, p < 0.0005).3.4 DiscussionWe have shown that the method leads to a considerable expansion on the seed set andoperates with high precision?namely, it produces high quality annotations, and iden-tifies fully novel metaphorical expressions relying only on the knowledge of source?target domain mappings that it learns automatically.
By comparing its coverage to thatof a WordNet baseline, we showed that the method reaches beyond synonymy andgeneralizes well over the source and target domains.The observed discrepancy in precision between the clustering approach and thebaseline can be explained by the fact that a large number of metaphorical senses areincluded in WordNet.
This means that in WordNet synsets source domain verbs appeartogether with more abstract terms.
For instance, the metaphorical sense of shape inthe phrase ?shape opinion?
is part of the synset ?
(determine, shape, mold, influence,regulate).?
This results in the low precision of the baseline system, because it tags literalexpressions (e.g., influence opinion) as metaphorical, assuming that all verbs from thesynset belong to the source domain.327Computational Linguistics Volume 39, Number 2To perform a more comprehensive error analysis, we examined a larger subset ofthe metaphorical expressions identified by the system (200 sentences, equally coveringverb?subject and verb?object constructions).
System precision against the additionaljudgments by one of the authors was measured at 76% (48 instances were taggedincorrectly according to the judgments).
The classification of system errors by type ispresented in Table 6.
Precision errors in the output of the system were also concentratedaround the problem of conventionality of some metaphorical verbs, such as those in?hold views, adopt traditions, tackle a problem.?
This conventionality is reflected in thedata in that such verbs are frequently used in their ?metaphorical?
contexts.
As a result,they are clustered together with literally used terms.
For instance, the verb tackle isfound in a cluster with solve, resolve, handle, confront, face, and so forth.
This results inthe system tagging ?resolve a problem?
as metaphorical if it has previously seen ?tacklea problem.
?A number of system errors affecting its precision are also due to cases of generalpolysemy and homonymy of both verbs and nouns.
For example, the noun passagecan mean both ?the act of passing from one state or place to the next?
and ?a sectionof text; particularly a section of medium length,?
as defined in WordNet.
Sun andKorhonen?s (2009) method performs hard clustering, that is, it does not distinguishbetween different word senses.
Hence the noun passage occurred in only one cluster,containing concepts like thought, word, sentence, expression, reference, address, description,and so on.
This cluster models the ?textual?
meaning of passage.
As a result of senseambiguity within the cluster, given the seed phrase ?she blocked the thought,?
the systemtags such expressions as ?block passage,?
?impede passage,?
?obstruct passage,?
and?speed passage?
as metaphorical.The errors that may cause low recall of the system are of a different nature.
Whereasnoun clustering considerably expands the seed set by identifying new associated tar-get concepts (e.g., given the seed metaphor ?sell soul?
it identifies ?sell skin?
and?launch pulse?
as metaphorical), the verb clusters sometimes miss a certain proportionof source domain vocabulary.
For instance, given the seed metaphor ?example illus-trates,?
the system identifies the following expressions: ?history illustrates,?
?episodeillustrates,?
?tale illustrates,?
?combination illustrates,?
?event illustrates,?
and so forth.
Itdoes not, however, capture obvious verb-based expansions, such as ?episode portrays,?present in the BNC.
This is one of the problems that could lead to a lower recallof the system.Nevertheless, in many cases the system benefits not only from dissimilar conceptswithin the noun clusters used to detect new target domains, but also from dissim-ilar concepts in the verb clusters.
Verb clusters produced automatically relying onTable 6Common system errors by type.Source of error Subject?Verb Verb?Object TotalsMetaphor conventionality 7 14 21General polysemy 9 6 15Verb clustering 4 5 9Noun clustering 2 1 3SP filter 0 0 0Totals 22 26 48328Shutova, Teufel, and Korhonen Statistical Metaphor Processingcontextual features may contain lexical items with distinct, or even opposite meanings(e.g., throw and catch, take off and land).
They tend to belong to the same semanticdomain, however (e.g., verbs of dealing with LIQUIDS, verbs describing a FIGHT) It isthe diversity of verb meanings within the domain cluster that allows the generalizationfrom a limited number of seed expressions to a broader spectrum of previously unseenand novel metaphors, non-synonymous with those in the seed set.The fact that the approach is seed-dependent is one of its possible limitations,affecting the coverage of the system.
Wide coverage is essential for the practical useof the system.
At this stage, however, it was impossible for us to reliably measure therecall of the system, because there is no large corpus annotated for metaphor available.In addition, because the current system was only tested with very few seeds (again,due to the lack of metaphor-annotated data), we expect the current overall recall of thesystem to be relatively low.
In order to obtain a full coverage of the corpus, a large andrepresentative seed set is necessary.
Although it is hard to capture the whole variety ofmetaphorical language in a limited set of examples, it is possible to compile a seed setrepresentative of all common source?target domain mappings.
The learning capabilitiesof the system can then be used to expand on those to the whole range of conventionaland novel metaphorical mappings and expressions.
In addition, because the precisionof the system was measured on the data set produced by expanding individual seedexpressions, we would expect the expansion of other, new seed expressions to yield acomparable quality of annotations.
Incorporating new seed expressions is thus likely toresult in increasing recall without a significant loss in precision.The current system harvests a large and relatively clean set of metaphoricalexpressions from the corpus.
These annotations could provide a new platform for thedevelopment and testing of other metaphor systems.4.
Metaphor Interpretation Method and ExperimentsAs is the case in metaphor identification, the majority of existing approaches to meta-phor interpretation also rely on task-specific hand-coded knowledge (Martin 1990; Fass1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004;Agerri et al2007) and produce interpretations in a non-textual format (Veale and Hao2008).
The ultimate objective of automatic metaphor processing, however, is a typeof interpretation that can be directly embedded into other systems to enhance theirperformance.
We thus define metaphor interpretation as a paraphrasing task and builda system that automatically derives literal paraphrases for metaphorical expressions inunrestricted text.
Our method is also distinguished from previous work in that it doesnot rely on any hand-crafted knowledge aboutmetaphor, but in contrast is corpus-basedand uses automatically induced selectional preferences.The metaphor paraphrasing task can be divided into two subtasks: (1) generatingparaphrases, that is, other ways of expressing the same meaning in a given context,and (2) discriminating between literal and metaphorical paraphrases.
Consequently,the proposed approach is theoretically grounded in two ideas underlying each of thesesubtasks: The meaning of a word in context emerges through interaction with themeaning of the words surrounding it.
This assumption is widely acceptedin lexical semantics theory (Pustejovsky 1995; Hanks and Pustejovsky2005) and has been exploited for lexical acquisition (Schulte im Walde2006; Sun and Korhonen 2009).
It suggests that the context itself imposes329Computational Linguistics Volume 39, Number 2certain semantic restrictions on the words which can occur within it.Given a large amount of linguistic data, it is possible to model thesesemantic restrictions in probabilistic terms (Lapata 2001).
This can bedone by deriving a ranking scheme for possible paraphrases that fit ordo not fit in a specific context based on word co-occurrence evidence.This is how initial paraphrases are generated within the metaphorparaphrasing module. Literalness can be detected via strong selectional preference.
This ideais a mirror-image of the selectional preference violation view of Wilks(1978), who suggested that a violation of selectional preferences indicatesa metaphor.
The key information that selectional preferences provide iswhether there is an association between the predicate and its potentialargument and how strong that association is.
A literal paraphrasewould normally come from the target domain (e.g., ?understand theexplanation?)
and be strongly associated with the target concept, whereasa metaphorical paraphrase would belong to the source domain (e.g.,?grasp the explanation?)
and be associated with the concepts from thissource domain more strongly than with the target concept.
Hence weuse a selectional preference model to measure the semantic fit of thegenerated paraphrases into the given context as opposed to all othercontexts.
The highest semantic fit then indicates the most literalparaphrase.Thus the context-based probabilistic model is used for paraphrase generation andthe selectional preference model for literalness detection.
The key difference betweenthe two models is that the former favors the paraphrases that co-occur with the wordsin the context more frequently than other paraphrases do, and the latter favors theparaphrases that co-occur with the words from the context more frequently than withany other lexical items in the corpus.
This is the main intuition behind our approach.The system thus incorporates the following components: a context-based probabilistic model that acquires paraphrases formetaphorical expressions from a large corpus; a WordNet similarity component that filters out the irrelevantparaphrases based on their similarity to the metaphorical term (similarityis defined as sharing a common hypernym within three levels in theWordNet hierarchy); a selectional preference model that discriminates literal paraphrases fromthe metaphorical ones.
It re-ranks the paraphrases, de-emphasizing themetaphorical ones and emphasizing the literal ones.In addition, the system disambiguates the sense of the paraphrases using theWordNet inventory of senses.
The context-based model together with the WordNetfilter constitute a metaphor paraphrasing baseline.
By comparing the final system tothis baseline, we demonstrate that simple context-based substitution, even supplied byextensive knowledge contained in lexical resources, is not sufficient for metaphor inter-pretation and that a selectional preference model is needed to establish the literalness ofthe paraphrases.330Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingThis section first provides an overview of paraphrasing and lexical substitutionand relates these tasks to the problem of metaphor interpretation.
It then describesthe experimental data used to develop and test the paraphrasing system and themethod itself, and finally, concludes with the system evaluation and the presentationof results.4.1 Paraphrasing and Lexical SubstitutionParaphrasing can be viewed as a text-to-text generation problem, whereby a new pieceof text is produced conveying the same meaning as the original text.
Paraphrasing canbe carried out at multiple levels (sentence-, phrase-, and word-levels), and may involveboth syntactic and lexical transformations.
Paraphrasing by replacing individual wordsin a sentence is known as lexical substitution (McCarthy 2002).
Because, in this article,we address the phenomenon of metaphor at a single-word level, our task is close innature to lexical substitution.
The task of lexical substitution originates from wordsense disambiguation (WSD).
The key difference between the two is that whereas WSDmakes use of a predefined sense-inventory to characterize the meaning of a word incontext, lexical substitution is aimed at automatic induction of meanings.
Thus the goalof lexical substitution is to generate the set of semantically valid substitutes for theword.
Consider the following sentences from Preiss, Coonce, and Baker (2009).
(22) His parents felt that he was a bright boy.
(23) Our sun is a bright star.Bright in Example (22) can be replaced by the word intelligent.
The same replacementin the context of Example (23) will not produce an appropriate sentence.
A lexicalsubstitution system needs to (1) find a set of candidate synonyms for the word and(2) select the candidate that matches the context of the word best.Both sentence- or phrase-level paraphrasing and lexical substitution find a widerange of applications in NLP.
These include summarization (Knight and Marcu 2000;Zhou et al2006), information extraction (Shinyama and Sekine 2003), machine trans-lation (Kurohashi 2001; Callison-Burch, Koehn, and Osborne 2006), text simplification(Carroll et al1999), question answering (McKeown 1979; Lin and Pantel 2001) andtextual entailment (Sekine et al2007).
Consequently, there has been a plethora ofNLP approaches to paraphrasing (McKeown 1979; Meteer and Shaked 1988; Dras 1999;Barzilay and McKeown 2001; Lin and Pantel 2001; Barzilay and Lee 2003; Bolshakovand Gelbukh 2004; Quirk, Brockett, and Dolan 2004; Kauchak and Barzilay 2006; Zhaoet al2009; Kok and Brockett 2010) and lexical substitution (McCarthy and Navigli 2007,2009; Erk and Pado?
2009; Preiss, Coonce, and Baker 2009; Toral 2009; McCarthy, Keller,and Navigli 2010).Among paraphrasing methods one can distinguish (1) rule-based approaches,which rely on a set of hand-crafted (McKeown 1979; Zong, Zhang, and Yamamoto 2001)or automatically learned (Lin and Pantel 2001; Barzilay and Lee 2003; Zhao et al2008)paraphrasing patterns; (2) thesaurus-based approaches, which generate paraphrasesby substituting words in the sentence by their synonyms (Bolshakov and Gelbukh2004; Kauchak and Barzilay 2006); (3) natural language generation?based approaches(Kozlowski, McCoy, and Vijay-Shanker 2003; Power and Scott 2005), which transforma sentence into its semantic representation and generate a new sentence from it; and(4) SMT-based methods (Quirk, Brockett, and Dolan 2004), operating as monolingual331Computational Linguistics Volume 39, Number 2MT.
A number of approaches to lexical substitution rely on manually constructedthesauri to find sets of candidate synonyms (McCarthy and Navigli 2007), whereasothers address the task in a fully unsupervised fashion.
In order to derive and rankcandidate substitutes, the latter systems make use of distributional similarity measures(Pucci et al2009; McCarthy, Keller, and Navigli 2010), vector space models of wordmeaning (De Cao and Basili 2009; Erk and Pado?
2009) or statistical learning techniques,such as hidden Markov models and n-grams (Preiss, Coonce, and Baker 2009).The metaphor interpretation task is different from the WSD task, because it isimpossible to predefine a set of senses of metaphorical words, in particular for novelmetaphors.
Instead, the correct substitute for the metaphorical term needs to be gen-erated in a data-driven manner, as for lexical substitution.
The metaphor paraphrasingtask, however, also differs from lexical substitution in the following two ways.
Firstly,a suitable substitute needs to be used literally in the target context, or at least moreconventionally than the original word.
Secondly, by definition, the substitution is notrequired to be a synonym of the metaphorical word.
Moreover, for our task this is noteven desired, because there is the danger that synonymous paraphrasing may resultin another metaphorical expression, rather than the literal interpretation of the originalone.
Metaphor paraphrasing therefore presents an additional challenge in comparisonto lexical substitution, namely, that of discriminating between literal and metaphoricalsubstitutes.
This second, harder, and not previously addressed task is the main focusof the work presented in this section.
The remainder of the section is devoted to thedescription of the metaphor paraphrasing experiment.4.2 Experimental DataThe paraphrasing system is first tested individually on a set of metaphorical expres-sions extracted from a manually annotated metaphor corpus of Shutova and Teufel(2010).
This is the same data set as the one used for seeding the identification module(see Section 3.1.1 for description).
Because the paraphrasing evaluation described inthis section is conducted independently from the identification experiment, and nopart of the paraphrasing system relies on the output of the identification system andvice versa, the use of the same data set does not give any unfair advantage to thesystems.
In the later experiment (Section 5) when the identification and paraphrasingsystem are evaluated jointly, again the same seed set will be used for identification;paraphrasing, however, will be performed on the output of the identification system(i.e., the new identified metaphors) and both the identified metaphors and their para-phrases will be evaluated by human judges not used in the previous and the currentexperiments.4.3 MethodThe system takes phrases containing annotated single-word metaphors as input; wherea verb is used metaphorically, its context is used literally.
It generates a list of possibleparaphrases of the verb that can occur in the same context and ranks them accordingto their likelihood, as derived from the corpus.
It then identifies shared features of theparaphrases and themetaphorical verb using theWordNet hierarchy and removes unre-lated concepts.
It then identifies the literal paraphrases among the remaining candidatesbased on the verb?s automatically induced selectional preferences and the properties ofthe context.332Shutova, Teufel, and Korhonen Statistical Metaphor Processing4.3.1 Context-based Paraphrase Ranking Model.
Terms replacing the metaphorical verb vwill be called its interpretations i.
We model the likelihood L of a particular paraphraseas a joint probability of the following events: the interpretation i co-occurring with theother lexical items from its context w1, ...,wN in syntactic relations r1, ..., rN, respectively.Li = P(i, (w1, r1), (w2, r2), ..., (wN, rN )) (6)where w1, ...,wN and r1, ..., rN represent the fixed context of the term used metaphori-cally in the sentence.
In the system output, the context w1, ...,wN will be preserved, andthe verb v will be replaced by the interpretation i.We assume statistical independence between the relations of the terms in a phrase.For instance, for a verb that stands in a relation with both a subject and an object, theverb?subject and verb?direct object relations are considered to be independent eventswithin the model.
The likelihood of an interpretation is then calculated as follows:P(i, (w1, r1), (w2, r2), ..., (wN, rN )) = P(i) ?
P((w1, r1)|i) ?
... ?
P((wN, rN )|i) (7)The probabilities can be calculated using maximum likelihood estimationP(i) =f (i)?k f (ik)(8)P(wn, rn|i) =f (wn, rn, i)f (i)(9)where f (i) is the frequency of the interpretation irrespective of its arguments,?k f (ik) isthe number of times its part of speech class is attested in the corpus, and f (wn, rn, i) isthe number of times the interpretation co-occurs with context word wn in relation rn.
Byperforming appropriate substitutions into Equation (7) one obtainsP(i, (w1, r1), (w2, r2), ..., (wN, rN )) =f (i)?k f (ik)?f (w1, r1, i)f (i)?
... ?f (wN, rN, i)f (i)=?Nn=1 f (wn, rn, i)( f (i))N?1 ?
?k f (ik)(10)This model is then used to rank the possible replacements of the term used meta-phorically in the fixed context according to the data.
The parameters of the model wereestimated from the RASP-parsed BNC using the grammatical relations output createdby Andersen et al(2008).4.3.2 WordNet Filter.
The context-based model described in Section 4.3.1 overgeneratesand hence there is a need to further narrow down the results.
It is acknowledged in thelinguistics community that metaphor is, to a great extent, based on similarity betweenthe concepts involved (Gentner et al2001).
We exploit this fact to refine paraphrasing.After obtaining the initial list of possible substitutes for the metaphorical term, thesystem filters out the terms whose meanings do not share any common propertieswith that of the metaphorical term.
Consider the computer science metaphor ?kill aprocess,?
which stands for ?terminate a process.?
The basic sense of kill implies an end333Computational Linguistics Volume 39, Number 2Table 7The list of paraphrases with the initial ranking (correct paraphrases are underlined).Log-likelihood ReplacementVerb?DirectObjecthold back truth:?13.09 contain?14.15 conceal?14.62 suppress?15.13 hold?16.23 keep?16.24 defendstir excitement:?14.28 create?14.84 provoke?15.53 make?15.53 elicit?15.53 arouse?16.23 stimulate?16.23 raise?16.23 excite?16.23 conjureleak report:?11.78 reveal?12.59 issue?13.18 disclose?13.28 emerge?14.84 expose?16.23 discoverSubject?Verbcampaign surge:?13.01 run?15.53 improve?16.23 soar?16.23 liftor termination of life.
Thus termination is the shared element of the metaphorical verband its literal interpretation.Such an overlap of properties can be identified using the hyponymy relations in theWordNet taxonomy.
Within the initial list of paraphrases, the system selects the termsthat are hypernyms of the metaphorical term, or share a common hypernym with it.
Tomaximize the accuracy, we restrict the hypernym search to a depth of three levels in thetaxomomy.
Table 7 shows the filtered lists of paraphrases for some of the test phrases,together with their log-likelihood.
Selecting the highest ranked paraphrase from this listas a literal interpretation will serve as a baseline.4.3.3 Re-ranking Based on Selectional Preferences.
The lists which were generated containsome irrelevant paraphrases (e.g., ?contain the truth?
for ?hold back the truth?)
andsome paraphrases where the substitute itself is metaphorically used (e.g., ?suppress the334Shutova, Teufel, and Korhonen Statistical Metaphor Processingtruth?).
As the task is to identify the literal interpretation, however, the system shouldremove these.One way of dealing with both problems simultaneously is to use selectional prefer-ences of the verbs.
Verbs used metaphorically are likely to demonstrate semantic pref-erence for the source domain, e.g., suppress would select for MOVEMENTS (political)rather than IDEAS, or TRUTH (the target domain), whereas the ones used literally forthe target domain (e.g., conceal) would select for TRUTH.
Selecting the verbs whosepreferences the noun in the metaphorical expression matches best should allow filteringout non-literalness, as well as unrelated terms.We automatically acquired selectional preference distributions of the verbs in theparaphrase lists (for verb?subject and verb?direct object relations) from the RASP-parsed BNC.
As in the identification experiment, we derived selectional preferenceclasses by clustering the 2,000 most frequent nouns in the BNC into 200 clusters us-ing Sun and Korhonen?s (2009) algorithm.
In order to quantify how well a particularargument class fits the verb, we adopted the selectional association measure proposedby Resnik (1993), identical to the one we used within the selectional preference-basedfilter for metaphor identification, as described in Section 3.2.4.
To remind the reader,selectional association is defined as follows:AR(v, c) =1SR(v)P(c|v) logP(c|v)P(c)(11)where P(c) is the prior probability of the noun class, P(c|v) is the posterior probabilityof the noun class given the verb, and SR is the overall selectional preference strength ofthe verb in the grammatical relation R.We use selectional association as a measure of semantic fitness (i.e., literalness) ofthe paraphrases.
The paraphrases are re-ranked based on their selectional associationwith the noun in the context.
Those paraphrases that are not well suited or used meta-phorically are dispreferred within this ranking.
The new ranking is shown in Table 8.The expectation is that the paraphrase in the first rank (i.e., the verb with which thenoun in the context has the highest association) represents a literal interpretation.4.4 Evaluation and DiscussionAs in the case of identification, the paraphrasing system was tested on verb?subject andverb?direct object metaphorical expressions.
These were extracted from the manuallyannotated metaphor corpus of Shutova and Teufel (2010), as described in Section 3.1.1.We compared the output of the final selectional-preference based system to that of theWordNet filter acting as a baseline.
We evaluated the quality of paraphrasing with thehelp of human judges in two different experimental settings.
The first setting involveddirect judgments of system output by humans.
In the second setting, the subjects didnot have access to system output and had to provide their own literal paraphrases forthe metaphorical expressions in the data set.
The system was then evaluated againsthuman judgments in Setting 1 and a paraphrasing gold standard created by mergingannotations in Setting 2.4.4.1 Setting 1: Direct Judgment of System Output.
The subjects were presented with aset of sentences containing metaphorical expressions and the top-ranked paraphrasesproduced by the system and by the baseline, randomized.
They were asked to mark as335Computational Linguistics Volume 39, Number 2Table 8Paraphrases re-ranked by SP model (correct paraphrases are underlined).Association ReplacementVerb?DirectObjecthold back truth:0.1161 conceal0.0214 keep0.0070 suppress0.0022 contain0.0018 defend0.0006 holdstir excitement:0.0696 provoke0.0245 elicit0.0194 arouse0.0061 conjure0.0028 create0.0001 stimulate?
0 raise?
0 make?
0 exciteleak report:0.1492 disclose0.1463 discover0.0674 reveal0.0597 issue?
0 emerge?
0 exposeSubject?Verbcampaign surge:0.0086 improve0.0009 run?
0 soar?
0 liftcorrect the paraphrases that have the same meaning as the term used metaphorically ifthey are used literally in the given context.Subjects Seven volunteers participated in the experiment.
They were all nativespeakers of English (one bilingual) and had little or no linguistics expertise.Interannotator agreement The reliability was measured at ?
= 0.62 (n = 2,N = 95, k = 7).System evaluation against judgments We then evaluated the system performanceagainst the subjects?
judgments in terms of Precision at Rank 1, P(1).
Precision at Rank(1) measures the proportion of correct literal interpretations among the paraphrasesin rank 1.
The results are shown in Table 9.
The system identifies literal paraphraseswith a P(1) = 0.81 and the baseline with a P(1) = 0.55.
We then conducted a one-tailedSign test (Siegel and Castellan 1988) that showed that this difference in performance isstatistically significant (N = 15, x = 1, p < 0.001).336Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingTable 9System and baseline P(1) and MAP.Relation System P(1) Baseline P(1) System MAP Baseline MAPVerb?DirectObject 0.79 0.52 0.60 0.54Verb?Subject 0.83 0.57 0.66 0.57Average 0.81 0.55 0.62 0.564.4.2 Setting 2: Creation of a Paraphrasing Gold Standard.
The subjects were presented witha set of sentences containing metaphorical expressions and asked to write down all suit-able literal paraphrases for the highlighted metaphorical verbs that they could think of.Subjects Five volunteer subjects who were different from the ones used in the pre-vious setting participated in this experiment.
They were all native speakers of Englishand some of them had a linguistics background (postgraduate-level degree in English).Gold Standard The elicited paraphrases combined together can be interpretedas a gold standard.
For instance, the gold standard for the phrase ?brushed aside theaccusations?
consists of the verbs rejected, ignored, disregarded, dismissed, overlooked, anddiscarded.System evaluation by gold standard comparison The system output was com-pared against the gold standard using mean average precision (MAP) as a measure.MAP is defined as follows:MAP = 1MM?j=11NjNj?i=1Pji (12)where M is the number of metaphorical expressions, Nj is the number of correct para-phrases for the metaphorical expression j, Pji is the precision at each correct paraphrase(the number of correct paraphrases among the top i ranks).
First, average precisionis estimated for individual metaphorical expressions, and then the mean is computedacross the data set.
This measure allows one to assess ranking quality beyond rank 1,as well as the recall of the system.
As compared with the gold standard, MAP of theparaphrasing system is 0.62 and that of the baseline is 0.56, as shown in Table 9.4.4.3 Discussion.
Given that the metaphor paraphrasing task is open-ended, any goldstandard elicited on the basis of it cannot be exhaustive.
Some of the correct paraphrasesmay not occur to subjects during the experiment.
As an example, for the phrase ?stirexcitement?
most subjects suggested only one paraphrase ?create excitement,?
which isfound in rank 3, suggesting an average precision of 0.33 for this phrase.
The top ranks ofthe system output are occupied by provoke and stimulate, however, which are intuitivelycorrect, more precise paraphrases, despite none of the subjects having thought of them.Such examples contribute to the fact that the system?s MAP is significantly lower thanits precision at rank 1, because a number of correct paraphrases proposed by the systemare not included in the gold standard.The selectional preference-based re-ranking yields a considerable improvement inprecision at rank 1 (26%) over the baseline.
This component is also responsible for someerrors of the system, however.
One of the potential limitations of selectional preference-based approaches to metaphor paraphrasing is the presence of verbs exhibiting weak337Computational Linguistics Volume 39, Number 2selectional preferences.
This means that these verbs are not strongly associated withany of their argument classes.
As noted in Section 3, such verbs tend to be usedliterally, and are therefore suitable paraphrases.
Our selectional preference model de-emphasizes them, however, and, as a result, they are not selected as literal paraphrasesdespite matching the context.
This type of error is exemplified by the phrase ?mendmarriage.?
For this phrase, the system ranking overruns the correct top suggestionof the baseline, ?improve marriage,?
and outputs ?repair marriage?
as the most likelyliteral interpretation, although it is in fact a metaphorical use.
This is likely to be due tothe fact that improve exposes a moderate selectional preference strength.Table 10 provides frequencies of the common errors of the system by type.
Themost common type of error is triggered by the conventionality of certain metaphoricalverbs.
Because they frequently co-occur with the target noun class in the corpus, theyreceive a high association score with that noun class.
This results in a high rankingof conventional metaphorical paraphrases.
Examples of top-ranked metaphorical para-phrases include ?confront a question?
for ?tackle a question,?
?repairmarriage?
for ?mendmarriage,?
?example pictures?
for ?example illustrates.
?These errors concern non-literalness of the produced paraphrases.
A less frequentlyoccurring error was paraphrasing with a verb that has a different meaning.
One suchexample was the metaphorical expression ?tensionmounted,?
for which the system pro-duced a paraphrase ?tension lifted,?
which has the opposite meaning.
This error is likelyto have been triggered by the WordNet filter, whereby one of the senses of lift wouldhave a common hypernym with the metaphorical verb mount.
This results in lift notbeing discarded by the filter, and subsequently ranked top due to the conventionality ofthe expression ?tension lifted.
?Another important issue that the paraphrase analysis brought to the foregroundis the influence of wider context on metaphorical interpretation.
The current systemprocesses only the information contained within the GR of interest, discarding therest of the context.
For some cases, however, this is not sufficient and the analysisof a wider context is necessary.
For instance, given the phrase ?scientists focus?
thesystem produces a paraphrase ?scientists think,?
rather than the more likely paraphrase?scientists study.?
Such ambiguity of focus could potentially be resolved by taking itswider context into account.
The context-based paraphrase ranking model described inSection 4.3.1 allows for the incorporation of multiple relations of the metaphorical verbin the sentence.Although the paraphrasing system uses hand-coded lexical knowledge fromWordNet, it is important to note that metaphor paraphrasing is not restricted tometaphorical senses included in WordNet.
Even if a metaphorical sense is absent fromWordNet, the system can still identify its correct literal paraphrase relying on theTable 10Common system errors by type.Source of error Subject?Verb Verb?Object TotalsMetaphor conventionality 0 5 5General polysemy/WordNet filter 1 1 2SP re-ranking 0 1 1Lack of context 1 1 2Totals 2 8 10338Shutova, Teufel, and Korhonen Statistical Metaphor Processinghyponymy relation and similarity between concepts, as described in Section 4.3.2.
Forexample, the metaphorical sense of handcuff in ?research is handcuffed?
is not includedin Wordnet, although the system correctly identifies its paraphrase confine (?research isconfined?).5.
Evaluation of Integrated SystemUp to now, the identification and the paraphrasing systemswere evaluated individuallyas modules.
To determine to which extent the presented systems are applicable withinNLP, we then ran the two systems together in a pipeline and evaluated the accuracy ofthe resulting text-to-text metaphor processing.
First, the metaphor identification systemwas applied to naturally occurring text taken from the BNC and then the metaphoricalexpressions identified in those texts were paraphrased by the paraphrasing system.Some of the expressions identified and paraphrased by the integrated system are shownin Figure 11.
The system output was compared against human judgments in twophases.
In phase 1, a small sample of sentences containing metaphors identified andparaphrased by the system was judged by multiple judges.
In phase 2, a larger sampleof phrases was judged by only one judge (one of the authors of this article).
Agreementof the judgments of the latter with the other judges was measured on the data fromphase 1.Because our goal was to evaluate both the accuracy of the integrated system andits usability by other NLP tasks, we assessed its performance in a two-fold fashion.Instances where metaphors were both correctly identified and paraphrased by thesystem were considered strictly correct, as they show that the system fully achievedCKM 391 Time and time again he would stare at the ground, hand on hip, if he thought he had receiveda bad call, and then swallow his anger and play tennis.CKM 391 Time and time again he would stare at the ground, hand on hip, if he thought he had receiveda bad call, and then suppress his anger and play tennis.AD9 3205 He tried to disguise the anxiety he felt when he found the comms system down, but Tammuzwas nearly hysterical by this stage.AD9 3205 He tried to hide the anxiety he felt when he found the comms system down, but Tammuzwas nearly hysterical by this stage.AMA 349Wewill halt the reduction in NHS services for long-term care and community health serviceswhich support elderly and disabled patients at home.AMA 349 We will prevent the reduction in NHS services for long-term care and community healthservices which support elderly and disabled patients at home.J7F 77 An economist would frame this question in terms of a cost-benefit analysis: the maximization ofreturns for the minimum amount of effort injected.J7F 77 An economist would phrase this question in terms of a cost-benefit analysis: the maximizationof returns for the minimum amount of effort injected.EEC 1362 In it, Younger stressed the need for additional alternatives to custodial sentences, which hadbeen implicit in the decision to ask the Council to undertake the enquiry.EEC 1362 In it, Younger stressed the need for additional alternatives to custodial sentences, which hadbeen implicit in the decision to ask the Council to initiate the enquiry.A1F 24 Moreover, Mr Kinnock brushed aside the suggestion that he needed a big idea or unique sellingpoint to challenge the appeal of Thatcherism.A1F 24 Moreover, Mr Kinnock dismissed the suggestion that he needed a big idea or unique sellingpoint to challenge the appeal of Thatcherism.Figure 11Metaphors identified (first sentences) and paraphrased (second sentences) by the system.339Computational Linguistics Volume 39, Number 2its goals.
Instances where the paraphrasing retained the meaning and resulted in aliteral paraphrase (including the cases where the identification module tagged a literalexpression as a metaphor) were considered correct lenient.
The intuition behind thisevaluation setting is that correct paraphrasing of literal expressions by other literalexpressions, albeit not demonstrating the positive contribution of metaphor processing,does not lead to any errors in system output and thus does not hamper the overallusability of the integrated system.5.1 Phase 1: Small Sample, Multiple JudgesThree volunteer subjects participated in the experiment.
They were all native speakersof English and had no formal training in linguistics.Materials and task Subjects were presented with a set of sentences containingmetaphorical expressions identified by the system and their paraphrases, as shownin Figure 12.
There were 35 such sentences in the sample.
They were asked to do thefollowing:1.
Compare the sentences, decide whether the highlighted expressions havethe same meaning, and record this in the box provided;2.
Decide whether the verbs in both sentences are used metaphorically orliterally and tick the respective boxes.For the second task, the same definition of metaphor as in the identification evaluation(cf.
Section 3.3.2) was provided for guidance.Interannotator agreement The reliability of annotations was evaluated indepen-dently for judgments on similarity of paraphrases and their literalness.
The inter-annotator agreement on the task of distinguishing metaphoricity from literalness wasmeasured at ?
= 0.53 (n = 2,N = 70, k = 3).
On the paraphrase (i.e., meaning retention)task, reliability was measured at ?
= 0.63 (n = 2,N = 35, k = 3).System performance We then evaluated the integrated system performanceagainst the subjects?
judgments in terms of accuracy (both strictly correct and correctFigure 12Evaluation of metaphor identification and paraphrasing.340Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingTable 11Integrated system performance.Tagging case Acceptability PercentageCorrect paraphrase: metaphorical?
literal ?
53.8Correct paraphrase: literal?
literal ?
13.5Correct paraphrase: literal?metaphorical ?
0.5Correct paraphrase: metaphorical?metaphorical ?
10.7Incorrect paraphrase ?
21.5lenient).
Strictly correct accuracy in this task measures the proportion of metaphorsboth identified and paraphrased correctly in the given set of sentences.
Correct lenientaccuracy, which demonstrates applicability of the system, is represented by the overallproportion of paraphrases that retained their meaning and resulted in a literal para-phrase (i.e., including literal paraphrasing of literal expressions in original sentences).Human judgments were merged into a majority gold standard, which consists of thoseinstances that were considered correct (i.e., identified metaphor correctly paraphrasedby the system) by at least two judges.
Compared to this majority gold standard, theintegrated system operates with a strictly correct accuracy of 0.66 and correct lenientaccuracy of 0.71.
The average human agreement with the majority gold standard interms of accuracy is 0.80 on the literalness judgments and 0.89 on the meaning retentionjudgments.5.2 Phase 2: Larger Sample, One JudgeThe systemwas also evaluated on a larger sample of automatically annotatedmetaphor-ical expressions (600 sentences) using one person?s judgments produced followingthe procedure from phase 1.
We measured how far these judgments agree with thejudges used in phase 1.
The agreement on meaning retention was measured at ?
= 0.59(n = 2,N = 35, k = 4) and that on the literalness of paraphrases at ?
= 0.54 (n = 2,N =70, k = 4).On this larger data set, the system achieved an accuracy of 0.54 (strictly correct) and0.67 (correct lenient).
The proportions of different tagging cases are shown in Table 11.The table also shows the acceptability of tagging cases.
Acceptability indicates whetheror not this type of system paraphrasing would cause an error when hypotheticallyintegrated with an external NLP application.
Cases where the system produces correctliteral paraphrases for metaphorical expressions identified in the text would benefitanother NLP application, whereas cases where literal expressions are correctly para-phrased by other literal expressions are considered neutral.
Both such cases are deemedacceptable, because they increase or preserve literalness of the text.
All other taggingcases introduce errors, thus they are marked as unacceptable.
Examples of differenttagging cases are shown in Table 12.The accuracy of metaphor-to-literal paraphrasing (0.54) indicates the level of in-formative contribution of the system, and the overall accuracy of correct paraphrasingresulting in a literal expression (0.67) represents the level of its acceptability within NLP.5.3 Discussion and Error AnalysisThe results of integrated system evaluation suggest that the system is capable of pro-viding useful information about metaphor for an external text processing application341Computational Linguistics Volume 39, Number 2Table 12Examples of different tagging cases.Tagging case ExamplesCorrect paraphrase: met?
lit throw an idea?
express an ideaCorrect paraphrase: lit?
lit adopt a recommendation?
accept a recommendationCorrect paraphrase: lit?met arouse memory?
awakenmemoryCorrect paraphrase: met?met work killed him?work exhausted himwith a reasonable accuracy (0.67).
It may, however, also introduce errors in the text byincorrect paraphrasing, as well as by producing metaphorical paraphrases.
If the lattererrors are rare (0.5%), the errors of the former type are sufficiently frequent (21.5%) tomake the metaphor system less desirable for use in NLP.
It is therefore important toaddress such errors.Table 13 shows the contribution of the individual system components to the overallerror.
The identification system tags 28% of all instances incorrectly (170).
This yields acomponent performance of 72%.
This result is slightly lower than that obtained in itsindividual evaluation in a setting with multiple judges (79%).
This can be explainedby the fact that the integrated system was evaluated by one judge only, rather thanusing a majority gold standard.
When compared with the judgments of each annotatorpairwise the system precision was measured at 74% (cf.
Section 3.3.2).
Some of theliteral instances tagged as ametaphor by the identification component are then correctlyparaphrased with a literal expression by the paraphrasing component.
Such cases donot change the meaning of the text, and hence are considered acceptable.
The resultingcontribution of the identification component to the overall error of the integrated systemis thus 15%.As Table 13 shows, the paraphrasing component failed in 32% of all cases(196 instances out of 600 were paraphrased incorrectly).
As mentioned previously, thiserror can be further split into paraphrasing without meaning retention (21.5%) andmetaphorical paraphrasing (11%).
Both of these error types are unacceptable and leadto lower performance of the integrated system.
This error rate is also higher than thatof the paraphrasing system when evaluated individually on a manually created dataset (19%).
The reasons for incorrect paraphrasing by the integrated system are manifoldTable 13System errors by component.
Three categories are cases where the identification modelincorrectly tagged a literal expression as metaphoric (false negatives from this modulewere not measured).
The remaining two categories are for paraphrase errors on correctlyidentified metaphors.Type of error Identification ParaphrasingCorrect paraphrase: lit?
lit 81 0Correct paraphrase: lit?met 3 3Correct paraphrase: met?met ?
64Incorrect paraphrase for literal 86 86Incorrect paraphrase for metaphor ?
43Totals 170 196342Shutova, Teufel, and Korhonen Statistical Metaphor Processingand concern both themetaphor identification and paraphrasing components.
One of thecentral problems stems from the initial tagging of literal expressions as metaphorical bythe identification system.
The paraphrasing system is not designed with literal-to-literalparaphrasing in mind.
When it receives literal expressions which have been incorrectlyidentified as input, it searches for a more literal paraphrase for them.
Not all literallyused words have suitable substitutes in the given context, however.
For instance,the literal expression ?approve conclusion?
is incorrectly paraphrased as ?evaluateconclusion.
?Similar errors occur when metaphorical expressions do not have any single-wordliteral paraphrases, for example, ?country functions according to...?.
This is, however,a more fundamental problem for metaphor paraphrasing as a task.
In such cases, thesystem, nonetheless, attempts to produce a substitute with approximately the samemeaning, which often leads to either metaphorical or incorrect paraphrasing.
For in-stance, ?country functions?
is paraphrased by ?country runs,?
with suggestions withlower rank being ?country works?
and ?country operates.
?Some errors that occur at the paraphrasing level are also due to the generalword sense ambiguity of certain verbs or nouns.
Consider the following paraphras-ing example, where Example (24a) shows an automatically identified metaphor andExample (24b) its system-derived paraphrase:(24) a. B71 852 Craig Packer and Anne Pusey of the University of Chicago havecontinued to follow the life and loves of these Tanzanian lions.b.
B71 852 Craig Packer and Anne Pusey of the University of Chicago havecontinued to succeed the life and loves of these Tanzanian lions.This error results from the fact that the verb succeed has a high selectional preference forlife in one of its senses (?attain success or reach a desired goal?)
and is similar to followin WordNet in another of its senses (?be the successor [of]?).
The system merges thesetwo senses in one, resulting in an incorrect paraphrase.One automatically identified example exhibited interaction of metaphor withmetonymy at the interpretation level.
In the phrase ?break word,?
the verb break is usedmetaphorically (although conventionally) and the noun word is a metonym standingfor promise.
This affected paraphrasing in that the system searched for verbs denotingactions that could be done with words, rather than promises, and suggested the para-phrase ?interrupt word(s).?
This paraphrase is interpretable in the context of a persongiving a speech, but not in the context of a person giving a promise.
This was the onlycase of metonymy in the analyzed data, however.Another issue that the evaluation on a larger data set revealed is the limitations ofthe WordNet filter used in the paraphrasing system.
Despite being a wide-coveragegeneral-domain database, WordNet does not include information about all possiblerelations that exist between particular word senses.
This means that some of the correctparaphrases suggested by the context-based model get discarded by the WordNet filterdue to missing information in WordNet.
For instance, the system produces no para-phrase for the metaphors ?hurl comment,?
?spark enthusiasm,?
and ?magnify thought?that it correctly identified.
This problemmotivates the exploration of possibleWordNet-free solutions for similarity detection in the metaphor paraphrasing task.
The systemcould either rely entirely on such a solution, or back off to it in cases when theWordNet-based system fails.Table 14 provides a summary of system errors by type.
The most common errorsare caused by metaphor conventionality resulting in metaphorical paraphrasing (e.g.,343Computational Linguistics Volume 39, Number 2Table 14Errors of the paraphrasing component by type.Source of error Met?Met Lit?Met Incorr.
for Lit Incorr.
for Met TotalNo literal paraphrase exists 11 0 5 2 18Metaphor conventionality 53 3 0 0 56General polysemy 0 0 13 10 23WordNet filter 0 0 21 21 42SP re-ranking 0 0 41 7 48Lack of context 0 0 6 2 8Interaction with metonymy 0 0 0 1 1Totals 64 3 86 43 196?swallow anger?
suppress anger,?
?work killed him?
work exhausted him?
), followedby the WordNet filter?
and general polysemy?related errors (e.g.
?follow lives ?succeed lives?
), resulting in incorrect paraphrasing or the system not producing anyparaphrase at all.
Metaphor paraphrasing by another conventional metaphor insteadof a literal expression is undesirable, although it may still be useful if the paraphrasesare more lexicalized than the original expression.
The word sense ambiguity?
andWordNet-based errors are more problematic, however, and need to be addressed in thefuture.
SP re-ranking is responsible for the majority of incorrect paraphrasing of literalexpressions.
This may be due to the fact that the model is ignorant of the meaningretention aspect, but rather favors the paraphrases that are used literally (albeitincorrectly) in the given context.
This shows that when building an integrated system,it is necessary to adapt the metaphor paraphrasing module to be able to also handleliteral expressions, because the identification module is likely to produce at least someof them.5.4 Comparison to the CorMet SystemIt is hard to directly compare the performance of the presented system to the otherrecent approaches to metaphor, because all of these approaches assume different taskdefinitions, and hence use data sets and evaluation techniques of their own.
Among thedata-driven methods, however, the closest in nature to ours is Mason?s (2004) CorMetsystem.
Mason?s system does not perform metaphor interpretation or identification ofmetaphorical expressions in text, but rather focuses on the detection of metaphoricallinks between distant domains.
Our system also involves such detection.
WhereasMason relies on domain-specific selectional preferences for this purpose, however, oursystem uses information about verb subcategorization, as well as general selectionalpreferences, to perform distributional clustering of verbs and nouns and then link theclusters based on metaphorical seeds.
Another fundamental difference is that whereasCorMet assigns explicit domain labels, our system models source and target domainsimplicitly.
In the evaluation of the CorMet system, the acquired metaphorical mappingsare compared to those in the manually created Master Metaphor List demonstrating theaccuracy of 77%.
In our system, on the contrary, metaphor acquisition is evaluated viaextraction of naturally occurring metaphorical expressions, achieving a performance of79% in terms of precision.
In order to compare the new mapping acquisition ability344Shutova, Teufel, and Korhonen Statistical Metaphor Processingof our system to that of CorMet, however, we performed an additional analysis of themappings hypothesized by our noun clusters in relation to those in the MML.
It was notpossible to compare the new mappings discovered by our system to the MML directlyas was done in Mason?s experiments, because in our approach source domains arerepresented by clusters of their characteristic verbs.
The analysis of the noun clusterswith respect to expansion of the the seed mappings taken from the MML, however,allowed us to evaluate the mapping acquisition by our system in terms of both precisionand recall.
The goal was to confirm our hypothesis that abstract concepts get clusteredtogether if they are associated with the same source domain and to evaluate the qualityof the newly acquired mappings.To do this, we randomly selected 10 target domain categories described in theMML and manually extracted all corresponding mappings (42 mappings in total).The categories included SOCIETY, IDEA, LIFE, OPPORTUNITY, CHANGE, LOVE,DIFFICULTY, CREATION, RELATIONSHIP, and COMPETITION.
For the concept ofOPPORTUNITY, for example, three mappings were present in the MML: OPPORTU-NITIES ARE PHYSICAL OBJECTS, OPPORTUNITIES ARE MOVING ENTITIES, andOPPORTUNITIES ARE OPEN PATHS, whereas for the concept of COMPETITION thelist describes only two mappings: COMPETITION IS A RACE, COMPETITION IS AWAR.We then extracted the system-produced clusters containing the selected 10 targetconcepts.
Examples of the mappings and the corresponding clusters are shown inFigure 13.
Our goal was to verify whether other concepts in the cluster containing thetarget concept are associated with the source domains given in the mappings.
Eachmember of these clusters was analyzed for possible association with the respectivesource domains.
For each concept in a cluster, we verified that it is associated withthe respective source domain by finding a corresponding metaphorical expression andannotating the concepts accordingly.
The degree of association of the members of theclusters with a given source domain was evaluated in terms of precision on the setof hypothesized mappings.
The precision of the cluster?s association with the sourceConceptual mapping: RELATIONSHIP IS A MECHANISM (VEHICLE)Cluster: consensus relation tradition partnership resistance foundation alliance friendship con-tact reserve unity link peace bond myth identity hierarchy relationship connection balancemarriage democracy defense faith empire distinction coalition regime divisionConceptual mapping: LIFE IS A JOURNEYCluster: politics practice trading reading occupation profession sport pursuit affair careerthinking lifeConceptual mapping: SOCIETY is a (HUMAN) BODYCluster: class population nation state country family generation trade profession householdkingdom business industry economy market enterprise world community institution societysectorConceptual mapping: DIFFICULTY is DIFFICULTY IN MOVING (OBSTACLE); PHYSICALHARDNESSCluster: threat crisis risk problem poverty obstacle dilemma challenge prospect danger dis-crimination barrier difficulty shortageConceptual mapping: OPPORTUNITY is a PHYSICAL OBJECT; MOVING ENTITY; OPENPATHCluster: incentive attraction scope remedy chance choice solution option perspective rangepossibility contrast opportunity selection alternative focusFigure 13Noun clusters.345Computational Linguistics Volume 39, Number 2concept was calculated as a proportion of the associated concepts in it.
Based on theseresults we computed the average precision (AP) as follows:AP = 1MM?j=1#associated concepts in cluster cj|cj|(13)whereM is the number of hypothesizedmappings and cj is the cluster of target conceptscorresponding to mapping j.The annotation was carried out by one of the authors and its average precisionis 0.82.
This confirms the hypothesis of clustering by association and shows that ourmethod favorably compares to Mason?s system.
This is only an approximate compari-son, however.
Direct comparison of metaphor acquisition by the two systems was notpossible, as they produce the output in different formats and, as mentioned earlier, oursystem models conceptual mappings implicitly, both within the noun clusters, as wellas by linking them to the verb clusters.We then additionally evaluated the recall of mapping acquisition by our systemagainst the MML.
For each selected MML mapping, we manually extracted all alter-native target concepts associated with the source domain in the mapping from theMML.
For example, in case of LIFE IS A JOURNEY we identified all target conceptsassociated with JOURNEY according to the MML and extracted them.
These includedLIFE, CAREER, LOVE, and CHANGE.
We then verified whether the relevant system-produced noun clusters contained these concepts.
The recall was then calculated as aproportion of the concepts in this list within one cluster.
For example, the concepts LIFEand CAREER are found in the same cluster, but not LOVE and CHANGE.
The overallrecall of mapping acquisition was measured at 0.50.These results show that the system is able to discover a large number of metaphor-ical connections in the data with high precision.
Although the evaluation against theMaster Metaphor List is subjective, it suggests that the use of statistical data-drivenmethods in general, and distributional clustering in particular, is a promising directionfor computational modeling of metaphor.6.
Conclusion and Future DirectionsThe 1980s and 1990s provided us with a wealth of ideas on the structure and mecha-nisms of metaphor.
The computational approaches formulated back then are still highlyinfluential, although their use of task-specific hand-coded knowledge is becoming in-creasingly less popular.
The last decade witnessed a significant technological leap innatural language computation, whereby manually crafted rules gradually gave wayto more robust corpus-based statistical methods.
This is also the case for metaphorresearch.
In this article, we presented the first integrated statistical system for metaphorprocessing in unrestricted text.
Our method is distinguished from previous work in thatit does not rely on anymetaphor-specific hand-coded knowledge (besides the seed set inthe identification experiments), operates on open-domain text, and produces interpreta-tions in textual format.
The system, consisting of independent metaphor identificationand paraphrasing modules, operates with a high precision (0.79 for identification, 0.81for paraphrasing, and 0.67 as an integrated system).
Although the system has beentested only on verb?subject and verb?object metaphors at this stage, the described iden-tification and paraphrasing methods should be similarly applicable to a wider rangeof syntactic constructions.
This expectation rests on the fact that both distributional346Shutova, Teufel, and Korhonen Statistical Metaphor Processingclustering and selectional preference induction techniques have been shown to modelthe meanings of a range of word classes (Hatzivassiloglou and McKeown 1993; BoledaTorrent and Alonso i Alemany 2003; Brockmann and Lapata 2003; Zapirain, Agirre,and Ma`rquez 2009).
Extending the system to deal with metaphors represented by otherword classes and constructions as well as multi-word metaphors is part of future work.Such an extension of the identification system would require the creation of aseed set exemplifying more syntactic constructions and the corpus search over fur-ther grammatical relations (e.g., verb?prepositional phrase [PP] complement relations:?Hillary leapt in the conversation;?
adjectival modifier?noun relations ?slippery mind,deep unease, heavy loss;?
noun?PP complement relations: ?a fraction of self-control, afoot of a mountain;?
verb?VP complement relations: ?aching to begin the day;?
andcopula constructions: ?Death is the sorry end of the human story, not a mysteriousprelude to a new one?).
Besides noun and verb clustering, it would also be necessaryto perform clustering of adjectives and adverbs.
Clusters of verbs, adjectives, adverbs,and concrete nouns would then represent source domains within the model.
The datastudy of Shutova and Teufel (2010) suggested that it is sometimes difficult to choose theoptimal level of abstraction of domain categories that would generalize well over thedata.
Although the system does not explicitly assign any domain labels, its domainrepresentation is still restricted by the fixed level of generality of source concepts,defined by the chosen cluster granularity.
To relax this constraint, one could attemptto automatically optimize cluster granularity to fit the data more accurately and toensure that the generated clusters explain themetaphorical expressions in the data morecomprehensively.
A hierarchical clustering algorithm, such as that of Yu, Yu, and Tresp(2006) or Sun andKorhonen (2011), could be used for this purpose.
Besides this, it wouldbe desirable to be able to generalize metaphorical associations learned from one typeof syntactic construction across all syntactic constructions, without providing explicitseed examples for the latter.
For instance, given the seed phrase ?stir excitement,?representing the conceptual mapping FEELINGS ARE LIQUIDS, the system should beable to discover not only that phrases such as ?swallow anger?
are metaphorical, butthat phrases such as ?ocean of happiness?
are as well.The extension of the paraphrasing system to other syntactic constructions wouldinvolve the extraction of further grammatical relations from the corpus, such as thoselisted herein, and their incorporation into the context-based paraphrase selectionmodel.Extending both the identification system and the paraphrasing system would requirethe application of the selectional preference model to other word classes.
AlthoughResnik?s selectional association measure has been used to model selectional preferencesof verbs for their nominal arguments, it is in principle a generalizable measure of wordassociation.
Information-theoretic word association measures (e.g., mutual information[Church and Hanks 1990]) have been continuously successfully applied to a range ofsyntactic constructions in a number of NLP tasks (Hoang, Kim, and Kan 2009; Baldwinand Kim 2010).
This suggests that applying a distributional association measure, suchas the one proposed by Resnik, to other part-of-speech classes should still result in arealistic model of semantic fitness, which in our terms corresponds to a measure of?literalness?
of the paraphrases.In addition, the selectional preference model can be improved by using an SPacquisition algorithm that can handle word sense ambiguity (e.g., Rooth et al1999;O?
Se?aghdha 2010; Reisinger and Mooney 2010).
The current approach relies on SPclasses produced by hard clustering and fails to accurately model word senses of gener-ally polysemous words.
This resulted in a number of errors in metaphor paraphrasingand it therefore needs to be addressed in the future.347Computational Linguistics Volume 39, Number 2The current version of the metaphor paraphrasing system still relies on some hand-coded knowledge in the form of WordNet.
WordNet has been criticized for a lack ofconsistency, high granularity of senses, and negligence with respect to some importantsemantic relations (Lenat, Miller, and Yokoi 1995).
In addition, WordNet is a general-domain resource, which is less suitable if one wanted to apply the system to domain-specific data.
For all of these reasons it would be preferable to develop a WordNet-freefully automated approach to metaphor resolution.
Vector space models of word mean-ing (Erk 2009; Rudolph and Giesbrecht 2010; Van de Cruys, Poibeau, and Korhonen2011) might provide a solution, as they have proved efficient in general paraphrasingand lexical substitution settings (Erk and Pado?
2009).
The feature similarity componentof the paraphrasing system that is currently based on WordNet could be replaced bysuch a model.Another crucial problem that needs to be addressed is the coverage of the iden-tification system.
To enable high usability of the system it is necessary to performhigh-recall processing.
One way to improve the coverage is the creation of a larger,more diverse seed set.
Although it is hardly possible to describe the whole variety ofmetaphorical language, it is possible to compile a set representative of (1) all most com-mon source?target domain mappings and (2) all types of syntactic constructions thatexhibit metaphoricity.
The existing metaphor resources, primarily the Master MetaphorList (Lakoff, Espenson, and Schwartz 1991), and examples from the linguistic literatureabout metaphor, could be a sensible starting point on a route to such a data set.
Havinga diverse seed set should enable the identification system to attain a broad coverage ofthe corpus.The proposed text-to-text representation of metaphor processing is directly trans-ferable to other NLP tasks and applications that could benefit from the inclusion ofa metaphor processing component.
Overall, our results suggest that the system canprovide useful and accurate information about metaphor to other NLP tasks relyingon lexical semantics.
In order to prove its usefulness for external applications, however,an extrinsic task-based evaluation is outstanding.
In the future, we intend to integratemetaphor processing with NLP applications, exemplified by MT and opinion mining,in order to demonstrate the contribution of this pervasive yet rarely addressed phe-nomenon to natural language semantics.AcknowledgmentsWe would like to thank the volunteerannotators for their help in the evaluations,as well as the Cambridge Overseas Trust(UK), EU FP-7 PANACEA project, and theRoyal Society (UK), who funded our work.ReferencesAbend, Omri and Ari Rappoport.
2010.Fully unsupervised core-adjunct argumentclassification.
In Proceedings of the 48thAnnual Meeting of the Association forComputational Linguistics, pages 226?236,Uppsala.Agerri, Rodrigo, John Barnden, Mark Lee,and Alan Wallington.
2007.
Metaphor,inference and domain-independentmappings.
In Proceedings of RANLP-2007,pages 17?23, Borovets.Alonge, Antonietta and Margherita Castelli.2003.
Encoding information on metaphoricexpressions in WordNet-like resources.In Proceedings of the ACL 2003 Workshopon Lexicon and Figurative Language,pages 10?17, Sapporo.Andersen, Oistein, Julien Nioche, TedBriscoe, and John Carroll.
2008.
TheBNC parsed with RASP4UIMA.
InProceedings of LREC 2008, pages 865?869,Marrakech.Baldwin, Timothy and Su Nam Kim.
2010.Multiword expressions.
In N. Indurkhyaand F. J. Damerau, editors, Handbook ofNatural Language Processing, Second Edition.CRC Press, Taylor and Francis Group,Boca Raton, FL, pages 267?292.348Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingBarnden, John and Mark Lee.
2002.
Anartificial intelligence approach tometaphor understanding.
Theoria etHistoria Scientiarum, 6(1):399?412.Barque, Lucie and Franc?ois-Re?gisChaumartin.
2009.
LDV Forum, 24(2):5?18.Barzilay, Regina and Lillian Lee.
2003.Learning to paraphrase: an unsupervisedapproach using multiple-sequencealignment.
In Proceedings of the 2003Conference of the North American Chapter ofthe Association for Computational Linguisticson Human Language Technology - Volume 1,NAACL ?03, pages 16?23, Edmonton.Barzilay, Regina and Kathryn McKeown.2001.
Extracting paraphrases from aparallel corpus.
In Proceedings of the39th Annual Meeting on Association forComputational Linguistics, ACL ?01,pages 50?57, Toulouse.Bergsma, Shane, Dekang Lin, and RandyGoebel.
2008.
Discriminative learning ofselectional preference from unlabeled text.In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing,EMNLP ?08, pages 59?68, Honolulu, HI.Birke, Julia and Anoop Sarkar.
2006.A clustering approach for the nearlyunsupervised recognition of nonliterallanguage.
In Proceedings of EACL-06,pages 329?336, Trento.Black, Max.
1962.Models and Metaphors.Cornell University Press, Ithaca, NY.Boleda Torrent, Gemma and Laura Alonso iAlemany.
2003.
Clustering adjectives forclass acquisition.
In Proceedings of the TenthConference of the European Chapter of theAssociation for Computational Linguistics -Volume 2, EACL ?03, pages 9?16, Budapest.Bolshakov, Igor and Alexander Gelbukh.2004.
Synonymous paraphrasing usingWordnet and Internet.
In Proceedings of the9th International Conference on Applicationsof Natural Language to Information Systems,NLDB 2004, pages 312?323, Alicante.Brew, Chris and Sabine Schulte im Walde.2002.
Spectral clustering for German verbs.In Proceedings of EMNLP, pages 117?124,Philadelphia, PA.Briscoe, Ted, John Carroll, and RebeccaWatson.
2006.
The second release ofthe RASP system.
In Proceedings of theCOLING/ACL on Interactive PresentationSessions, pages 77?80, Sydney.Brockmann, Carsten and Mirella Lapata.2003.
Evaluating and combiningapproaches to selectional preferenceacquisition.
In Proceedings of the TenthConference of the European Chapter of theAssociation for Computational Linguistics -Volume 1, EACL ?03, pages 27?34,Budapest.Burnard, Lou.
2007.
Reference Guide for theBritish National Corpus (XML Edition).Available at http://www.natcorp.ox.ac.uk/docs/URG.Callison-Burch, Chris, Philipp Koehn, andMiles Osborne.
2006.
Improved statisticalmachine translation using paraphrases.
InProceedings of NAACL, HLT-NAACL ?06,pages 17?24, New York, NY.Cameron, Lynne.
2003.Metaphor inEducational Discourse.
Continuum, London.Carroll, John, Guido Minnen, Darren Pearce,Yvonne Canning, Siobhan Devlin, andJohn Tait.
1999.
Simplifying text forlanguage-impaired readers.
In Proceedingsof the 9th Conference of the European Chapterof the Association for ComputationalLinguistics (EACL), pages 269?270, Bergen.Chen, Jinxiu, Donghong Ji, Chew Lim Tan,and Zhengyu Niu.
2006.
Unsupervisedrelation disambiguation using spectralclustering.
In Proceedings of theCOLING/ACL, pages 89?96, Sydney.Church, Kenneth and Patrick Hanks.1990.
Word association norms, mutualinformation, and lexicography.Computational Linguistics, 16(1):22?29.Clark, Stephen and James Curran.
2007.Wide-coverage efficient statisticalparsing with CCG and log-linear models.Computational Linguistics, 33(4):493?552.Copestake, Ann and Ted Briscoe.
1995.Semi-productive polysemy and senseextension.
Journal of Semantics, 12:15?67.Davidov, Dmitry, Roi Reichart, and AriRappoport.
2009.
Superior and efficientfully unsupervised pattern-based conceptacquisition using an unsupervised parser.In Proceedings of the Thirteenth Conference onComputational Natural Language Learning,CoNLL ?09, pages 48?56, Boulder, CO.De Cao, Diego and Roberto Basili.2009.
Combining distributional andparadigmatic information in a lexicalsubstitution task.
In Proceedings ofEVALITA Workshop, 11th Congress ofItalian Association for Artificial Intelligence,Reggie Emilia.Dras, Mark.
1999.
Tree Adjoining Grammarand the Reluctant Paraphrasing of Text.
Ph.D.thesis, Macquarie University, Australia.Erk, Katrin.
2009.
Representing words asregions in vector space.
In Proceedings ofthe Thirteenth Conference on ComputationalNatural Language Learning, pages 57?65,Boulder, CO.349Computational Linguistics Volume 39, Number 2Erk, Katrin and Diana McCarthy.
2009.Graded word sense assignment.
InProceedings of the 2009 Conference onEmpirical Methods in Natural LanguageProcessing, pages 440?449, Edinburgh.Erk, Katrin and Sebastian Pado?.
2009.Paraphrase assessment in structuredvector space: exploring parameters anddatasets.
In Proceedings of the Workshop onGeometrical Models of Natural LanguageSemantics, pages 57?65, Athens.Fass, Dan.
1991. met*: A method fordiscriminating metonymy and metaphorby computer.
Computational Linguistics,17(1):49?90.Fass, Dan and Yorick Wilks.
1983.
Preferencesemantics, ill-formedness, and metaphor.Computational Linguistics, 9(3-4):178?187.Fauconnier, Gilles and Mark Turner.
2002.The Way We Think: Conceptual Blending andthe Mind?s Hidden Complexities.
Basic Books,New York, NY.Feldman, Jerome.
2006.
From Molecule toMetaphor: A Neural Theory of Language.The MIT Press, Cambridge, MA.Feldman, Jerome and Srini Narayanan.2004.
Embodied meaning in a neuraltheory of language.
Brain and Language,89(2):385?392.Fellbaum, Christiane, editor.
1998.WordNet: An Electronic Lexical Database(ISBN: 0-262-06197-X).
MIT Press,Cambridge, MA.Fillmore, Charles, Christopher Johnson,and Miriam Petruck.
2003.
Backgroundto FrameNet.
International Journal ofLexicography, 16(3):235?250.Gedigian, Matt, John Bryant, SriniNarayanan, and Branimir Ciric.
2006.Catching metaphors.
In Proceedingsof the 3rd Workshop on Scalable NaturalLanguage Understanding, pages 41?48,New York, NY.Gentner, Dedre.
1983.
Structure mapping:A theoretical framework for analogy.Cognitive Science, 7:155?170.Gentner, Dedre, Brian Bowdle, Phillip Wolff,and Consuelo Boronat.
2001.
Metaphor islike analogy.
In D. Gentner, K. J. Holyoak,and B. N. Kokinov, editors, The AnalogicalMind: Perspectives from Cognitive Science.MIT Press, Cambridge, MA,pages 199?253.Goatly, Andrew.
1997.
The Language ofMetaphors.
Routledge, London.Grady, Joe.
1997.
Foundations of Meaning:Primary Metaphors and Primary Scenes.Ph.D.
thesis, University of Californiaat Berkeley.Hanks, Patrick and James Pustejovsky.
2005.A pattern dictionary for natural languageprocessing.
Revue Franc?aise de linguistiqueapplique?e, 10(2):63?82.Hatzivassiloglou, Vasileios and Kathleen R.McKeown.
1993.
Towards the automaticidentification of adjectival scales:Clustering adjectives according tomeaning.
In Proceedings of the 31st AnnualMeeting of the Association for ComputationalLinguistics, ACL ?93, pages 172?182,Columbus, OH.Hesse, Mary.
1966.Models and Analogies inScience.
Notre Dame University Press,Notre Dame, IN.Hoang, Hung Huu, Su Nam Kim, andMin-Yen Kan. 2009.
A re-examination oflexical association measures.
In Proceedingsof the Workshop on Multiword Expressions,pages 31?39, Singapore.Hofstadter, Douglas.
1995.
Fluid Concepts andCreative Analogies: Computer Models of theFundamental Mechanisms of Thought.HarperCollins Publishers, London.Hofstadter, Douglas and Melanie Mitchell.1994.
The Copycat Project: A model ofmental fluidity and analogy-making.
InK.
J. Holyoak and J.
A. Barnden, editors,Advances in Connectionist and NeuralComputation Theory.
Ablex, New York, NY.Karov, Yael and Shimon Edelman.1998.
Similarity-based word sensedisambiguation.
ComputationalLinguistics, 24(1):41?59.Kauchak, David and Regina Barzilay.
2006.Paraphrasing for automatic evaluation.
InProceedings of the Main Conference on HumanLanguage Technology, Conference of the NorthAmerican Chapter of the Association ofComputational Linguistics, HLT-NAACL?06, pages 455?462, New York, NY.Kingsbury, Paul and Martha Palmer.
2002.From TreeBank to PropBank.
In Proceedingsof LREC-2002, pages 1989?1993,Gran Canaria, Canary Islands.Kipper, Karin, Anna Korhonen, NevilleRyant, and Martha Palmer.
2006.Extensive classifications of English verbs.In Proceedings of the 12th EURALEXInternational Congress, pages 1?15, Torino.Klein, Dan and Christopher Manning.2003.
Accurate unlexicalized parsing.In Proceedings of the 41st Annual Meetingof the Association for ComputationalLinguistics, pages 423?430, Sapporo.Knight, Kevin and Daniel Marcu.
2000.Statistics-based summarization?step one:Sentence compression.
In Proceedings of theSeventeenth National Conference on Artificial350Shutova, Teufel, and Korhonen Statistical Metaphor ProcessingIntelligence and Twelfth Conference onInnovative Applications of ArtificialIntelligence, pages 703?710, Austin, TX.Kok, Stanley and Chris Brockett.
2010.Hitting the right paraphrases in good time.In Human Language Technologies: The 2010Annual Conference of the North AmericanChapter of the Association for ComputationalLinguistics, HLT ?10, pages 145?153,Los Angeles, CA.Korhonen, Anna, Yuval Krymolowski,and Ted Briscoe.
2006.
A largesubcategorization lexicon for naturallanguage processing applications.In Proceedings of LREC 2006,pages 1015?1020, Genoa.Kozlowski, Raymond, Kathleen F.McCoy, and K. Vijay-Shanker.
2003.Generation of single-sentenceparaphrases from predicate/argumentstructure using lexico-grammaticalresources.
In Proceedings of the SecondInternational Workshop on Paraphrasing -Volume 16, PARAPHRASE ?03,pages 1?8, Sapporo.Krishnakumaran, Saisuresh and Xiaojin Zhu.2007.
Hunting elusive metaphors usinglexical resources.
In Proceedings of theWorkshop on Computational Approaches toFigurative Language, pages 13?20,Rochester, NY.Kurohashi, Sadao.
2001.
SENSEVAL-2Japanese translation task.
In Proceedings ofthe SENSEVAL-2 Workshop, pages 37?44,Toulouse.Lakoff, George, Jane Espenson, and AlanSchwartz.
1991.
The master metaphor list.Technical report, University of Californiaat Berkeley.Lakoff, George and Mark Johnson.
1980.Metaphors We Live By.
University ofChicago Press, Chicago, IL.Lapata, Mirella.
2001.
The Acquisitionand Modeling of Lexical Knowledge: ACorpus-Based Investigation of SystematicPolysemy.
Ph.D. thesis, University ofEdinburgh.Lenat, Doug, George Miller, and ToshioYokoi.
1995.
CYC, WordNet, and EDR:Critiques and responses.
Commun.ACM, 38(11):45?48.Levin, Beth.
1993.
English Verb Classes andAlternations.
University of Chicago Press,Chicago, IL.Lin, Dekang.
1998.
Automatic retrieval andclustering of similar words.
In Proceedingsof the 17th International Conference onComputational Linguistics, pages 768?774,Montreal.Lin, Dekang and Patrick Pantel.
2001.Discovery of inference rules for questionanswering.
Natural Language Engineering,7:343?360.Lo?nneker, Birte.
2004.
Lexical databases asresources for linguistic creativity: Focus onmetaphor.
In Proceedings of the LREC 2004Workshop on Language Resources forLinguistic Creativity, pages 9?16, Lisbon.Lo?nneker, Birte and Carina Eilts.
2004.
Acurrent resource and future perspectivesfor enriching Wordnets with metaphorinformation.
In Proceedings of the SecondInternational WordNet Conference?GWC2004, pages 157?162, Brno.Martin, James.
1988.
Representingregularities in the metaphoric lexicon.In Proceedings of the 12th Conference onComputational Linguistics, pages 396?401,Budapest.Martin, James.
1990.
A Computational Model ofMetaphor Interpretation.
Academic PressProfessional, Inc., San Diego, CA.Martin, James.
1994.
Metabank: Aknowledge-base of metaphoric languageconventions.
Computational Intelligence,10:134?149.Martin, James.
2006.
A corpus-basedanalysis of context effects on metaphorcomprehension.
In A. Stefanowitsch andS.
T. Gries, editors, Corpus-Based Approachesto Metaphor and Metonymy.
Mouton deGruyter, Berlin, pages 214?236.Mason, Zachary.
2004.
Cormet: Acomputational, corpus-based conventionalmetaphor extraction system.
ComputationalLinguistics, 30(1):23?44.McCarthy, Diana.
2002.
Lexicalsubstitution as a task for WSD evaluation.In Proceedings of the ACL-02 Workshop onWord Sense Disambiguation: Recent Successesand Future Directions - Volume 8, WSD ?02,pages 109?115, Philadelphia, PA.McCarthy, Diana, Bill Keller, andRoberto Navigli.
2010.
Getting synonymcandidates from raw data in the Englishlexical substitution task.
In Proceedings ofthe 14th EURALEX International Congress,Leeuwarden.McCarthy, Diana and Roberto Navigli.2007.
Semeval-2007 task 10: Englishlexical substitution task.
In Proceedingsof the 4th Workshop on SemanticEvaluations (SemEval-2007), pages 48?53,Prague.McCarthy, Diana and Roberto Navigli.
2009.The English lexical substitution task.Language Resources and Evaluation,43(2):139?159.351Computational Linguistics Volume 39, Number 2McKeown, Kathleen.
1979.
Paraphrasingusing given and new information in aquestion-answer system.
In Proceedingsof the 17th Annual Meeting of the Associationfor Computational Linguistics, ACL ?79,pages 67?72, La Jolla, CA.Meila, Marina and Jianbo Shi.
2001.A random walks view of spectralsegmentation.
In AISTATS, Key West, FL.Meteer, Marie and Varda Shaked.
1988.Strategies for effective paraphrasing.In Proceedings of the 12th Conference onComputational Linguistics - Volume 2,COLING ?88, pages 431?436, Budapest.Mitchell, Jeff and Mirella Lapata.
2008.Vector-based models of semanticcomposition.
In Proceedings of ACL,pages 236?244, Columbus, OH.Murphy, Gregory.
1996.
On metaphoricrepresentation.
Cognition, 60:173?204.Narayanan, Srini.
1997.
Knowledge-basedAction Representations for Metaphor andAspect (KARMA).
Ph.D. thesis, Universityof California at Berkeley.Narayanan, Srini.
1999.
Moving right along:A computational model of metaphoricreasoning about events.
In Proceedings ofAAAI 99, pages 121?128, Orlando, FL.Nunberg, Geoffrey.
1987.
Poetic and prosaicmetaphors.
In Proceedings of the 1987Workshop on Theoretical Issues in NaturalLanguage Processing, pages 198?201,Stroudsburg, PA.O?
Se?aghdha, Diarmuid.
2010.
Latentvariable models of selectional preference.In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics,pages 435?444, Uppsala.Orwell, George.
1946.
Politics and theEnglish Language.
Horizon, 13(76):252?265.Pantel, Patrick and Dekang Lin.
2002.Discovering word senses from text.
InProceedings of the Eighth ACM SIGKDDInternational Conference on KnowledgeDiscovery and Data Mining, pages 613?619,Edmonton.Pereira, Fernando, Naftali Tishby, andLillian Lee.
1993.
Distributional clusteringof English words.
In Proceedings of ACL-93,pages 183?190, Morristown, NJ.Peters, Wim and Ivonne Peters.
2000.Lexicalised systematic polysemy inWordnet.
In Proceedings of LREC 2000,Athens.Pinker, Stephen.
2007.
The Stuff of Thought:Language as a Window into Human Nature.Viking Adult, New York, NY.Power, Richard and Donia Scott.
2005.Automatic generation of large-scaleparaphrases.
In Proceedings of IWP,pages 73?79.Pragglejaz Group.
2007.
MIP: A methodfor identifying metaphorically usedwords in discourse.Metaphor and Symbol,22:1?39.Preiss, Judita, Ted Briscoe, and AnnaKorhonen.
2007.
A system for large-scaleacquisition of verbal, nominal andadjectival subcategorization frames fromcorpora.
In Proceedings of ACL-2007,volume 45, page 912, Prague.Preiss, Judita, Andrew Coonce, andBrittany Baker.
2009.
HMMs, GRs, andn-grams as lexical substitution techniques:are they portable to other languages?In Proceedings of the Workshop on NaturalLanguage Processing Methods and Corporain Translation, Lexicography, and LanguageLearning, MCTLLL ?09, pages 21?27,Borovets.Pucci, Dario, Marco Baroni, Franco Cutugno,and Alessandro Lenci.
2009.
Unsupervisedlexical substitution with a word spacemodel.
In Proceedings of the EVALITAWorkshop, 11th Congress of ItalianAssociation for Artificial Intelligence,Reggie Emilia.Pustejovsky, James.
1995.
The GenerativeLexicon.MIT Press, Cambridge, MA.Quirk, Chris, Chris Brockett, and WilliamDolan.
2004.
Monolingual machinetranslation for paraphrase generation.In Proceedings of the 2004 Conference onEmpirical Methods in Natural LanguageProcessing, pages 142?149, Barcelona.Reining, Astrid and Birte Lo?nneker-Rodman.2007.
Corpus-driven metaphor harvesting.In Proceedings of the HLT/NAACL-07Workshop on Computational Approachesto Figurative Language, pages 5?12,Rochester, NY.Reisinger, Joseph and Raymond Mooney.2010.
A mixture model with sharing forlexical semantics.
In Proceedings of the2010 Conference on Empirical Methods inNatural Language Processing, EMNLP ?10,pages 1173?1182, Cambridge, MA.Resnik, Philip.
1993.
Selection andInformation: A Class-based Approach toLexical Relationships.
Ph.D. thesis,University of Pennsylvania.Rooth, Mats, Stefan Riezler, Detlef Prescher,Glenn Carroll, and Franz Beil.
1999.Inducing a semantically annotated lexiconvia EM-based clustering.
In Proceedingsof ACL 99, pages 104?111, Maryland.Rudolph, Sebastian and Eugenie Giesbrecht.2010.
Compositional matrix-space352Shutova, Teufel, and Korhonen Statistical Metaphor Processingmodels of language.
In Proceedings ofthe 48th Annual Meeting of the Association forComputational Linguistics, pages 907?916,Uppsala.Schulte im Walde, Sabine.
2006.
Experimentson the automatic induction of Germansemantic verb classes.
ComputationalLinguistics, 32(2):159?194.Sekine, Satoshi, Kentaro Inui, Ido Dagan,Bill Dolan, Danilo Giampiccolo, andBernardo Magnini, editors.
2007.Proceedings of the ACL-PASCAL Workshopon Textual Entailment and Paraphrasing.Prague.Shalizi, Cosma.
2003.
Analogy and metaphor.Available at http://masi.cscs.lsa.umich.edu/?crshalizi/notabene.Shinyama, Yusuke and Satoshi Sekine.
2003.Paraphrase acquisition for informationextraction.
In Proceedings of the SecondInternational Workshop on Paraphrasing -Volume 16, PARAPHRASE ?03,pages 65?71, Sapporo.Shutova, Ekaterina.
2010.
Automaticmetaphor interpretation as a paraphrasingtask.
In Proceedings of NAACL 2010,pages 1029?1037, Los Angeles, CA.Shutova, Ekaterina, Lin Sun, and AnnaKorhonen.
2010.
Metaphor identificationusing verb and noun clustering.In Proceedings of COLING 2010,pages 1,002?1,010, Beijing.Shutova, Ekaterina and Simone Teufel.2010.
Metaphor corpus annotated forsource?target domain mappings.In Proceedings of LREC 2010,pages 3,255?3,261, Malta.Siegel, Sidney and N. John Castellan.
1988.Nonparametric Statistics for the BehavioralSciences.
McGraw-Hill Book Company,New York, NY.Sun, Lin and Anna Korhonen.
2009.Improving verb clustering withautomatically acquired selectionalpreferences.
In Proceedings ofEMNLP 2009, pages 638?647, Singapore.Sun, Lin and Anna Korhonen.
2011.Hierarchical verb clustering using graphfactorization.
In Proceedings of EMNLP,pages 1,023?1,033, Edinburgh.Toral, Antonio.
2009.
The lexical substitutiontask at EVALITA 2009.
In Proceedings ofEVALITA Workshop, 11th Congress of ItalianAssociation for Artificial Intelligence,Regio Emilia.Tourangeau, Roger and Robert Sternberg.1982.
Understanding and appreciatingmetaphors.
Cognition, 11:203?244.Van de Cruys, Tim, Thierry Poibeau, andAnna Korhonen.
2011.
Latent vectorweighting for word meaning incontext.
In Proceedings of EMNLP,pages 1,012?1,022, Edinburgh.van Rijsbergen, Keith.
1979.
InformationRetrieval, 2nd edition.
Butterworths,London.Veale, Tony and Yanfen Hao.
2008.A fluid knowledge representation forunderstanding and generating creativemetaphors.
In Proceedings of COLING 2008,pages 945?952, Manchester.Wilks, Yorick.
1975.
A preferentialpattern-seeking semantics for naturallanguage inference.
Artificial Intelligence,6:53?74.Wilks, Yorick.
1978.
Making preferences moreactive.
Artificial Intelligence, 11(3):197?223.Yu, K., S. Yu, and V. Tresp.
2006.
Softclustering on graphs.
NIPS,pages 1553?1561, Vancouver.Zapirain, Ben?at, Eneko Agirre, and Llu??sMa`rquez.
2009.
Generalizing over lexicalfeatures: selectional preferences forsemantic role classification.
In Proceedingsof the ACL-IJCNLP 2009 Conference ShortPapers, pages 73?76, Singapore.Zhao, S., H. Wang, T. Liu, and S. Li.
2008.Pivot approach for extracting paraphrasepatterns from bilingual corpora.In Proceedings of ACL-08:HLT,pages 780?788, Columbus, OH.Zhao, Shiqi, Xiang Lan, Ting Liu, andSheng Li.
2009.
Application-drivenstatistical paraphrase generation.
InProceedings of the Joint Conference of the47th Annual Meeting of the ACL and the4th International Joint Conference onNatural Language Processing of the AFNLP:Volume 2, ACL ?09, pages 834?842, Suntec.Zhou, Liang, Chin-Yew Lin, Dragos StefanMunteanu, and Eduard H. Hovy.
2006.PARAEVAL: Using paraphrases toevaluate summaries automatically.In Proceedings of HLT-NAACL,pages 447?454, New York, NY.Zong, Chengqing, Yujie Zhang, andKazuhide Yamamoto.
2001.
Approach tospoken Chinese paraphrasing based onfeature extraction.
In Proceedings of NLPRS,pages 551?556, Tokyo.353
