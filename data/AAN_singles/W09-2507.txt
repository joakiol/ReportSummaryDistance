Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 48?51,Suntec, Singapore, 6 August 2009.c?2009 ACL and AFNLPBuilding an Annotated Textual Inference Corpus for Motion and SpaceKirk RobertsHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson TX 75080kirk@hlt.utdallas.eduAbstractThis paper presents an approach for build-ing a corpus for the domain of motion andspatial inference using a specific class ofverbs.
The approach creates a distributionof inference features that maximize thediscriminatory power of a system trainedon the corpus.
The paper addresses the is-sue of using an existing textual inferencesystem for generating the examples.
Thisenables the corpus annotation method toassert whether more data is necessary.1 IntroductionOpen-domain textual inference provides a vast ar-ray of challenges to a textual entailment system.In order to ensure a wide distribution of these chal-lenges in building the PASCAL 2005 corpus (Da-gan et al, 2005), seven different application set-tings were used for inspiration: Information Re-trieval, Comparable Documents, Reading Com-prehension, Question Answering, Information Ex-traction, Machine Translation, and Paraphrase Ac-quisition.
While PASCAL 2005 and its subse-quent challenges have released numerous corporafor open-domain textual inference, many types oftextual inference are sparsely represented.
Thisspeaks not to a weakness in the mentioned cor-pora, but rather the depth and complexity of chal-lenges that textual inference presents.Furthermore, the open-domain inference taskoften forces systems to face more than one ofthese challenges on a single inference pair (suchas requiring both an understanding of paraphrasesand part-whole relationships).
In many cases, itis desirable to isolate out most of these ?sub-tasks?
within textual inference and concentrateon a single aspect.
Partly for this reason, theBoeing-Princeton-ISI (BPI) Textual EntailmentTest Suite1was developed.
Its focus is real-worldknowledge and not syntactic constructions, so itprovides 250 syntactically simple but semanticallyrich inference pairs.This paper explores the creation of such aspecific textual inference corpus based on verbclasses, specifically focusing on the class of mo-tion verbs and their nominalizations.
The goal isto develop a publicly available corpus for spatialinference involving motion.
Section 2 analyzes theproperties of such a corpus.
Section 3 outlines theeffort to build a motion corpus.
Finally, Section 4discusses considerations for the size of the corpus.2 Properties of an Inference Corpus2.1 General PropertiesAnnotated corpora are designed for training andevaluation for specific classification tasks, andthus an optimal corpus is one that maximizes asystem?s ability to form a discriminative featurespace.
However, knowing ahead of time what thefeature space will look like may be difficult.
But,at the same time the corpus should be also reflec-tive of the real world.One method for developing a useful corpus un-der these conditions, especially for a specific do-main, is to use an existed textual entailment sys-tem that can aid in the example generation pro-cess.
By using such a system to suggest examples,one is able to both reduce the time (and cost) ofannotation as well as producing a corpus with adesirable distribution of features.1Available at http://www.cs.utexas.edu/?pclark/bpi-test-suite/48Text: John flew to New York from LA.Hypothesis: John left LA for New York.Text: John will fly over the Atlantic duringhis trip to London from New York on Tuesday.Hypothesis: On Tuesday, John flew over waterwhen going from North America to Europe.Table 1: Examples of textual inference for motion.2.2 Properties of a Motion CorpusTextual inference about motion requires an exter-nal representation apart from the text.
While manyinference pairs can be solved with strategies suchas lexical alignment or paraphrasing, many textsassume the reader has knowledge of the proper-ties of motion.
Table 1 shows two such inferencepairs.
The first can be solved through a paraphrasestrategy, while the second requires explicit knowl-edge of the properties of motion that are difficultto acquire through a paraphrasing method.
Unfor-tunately, most open-domain inference corpora aresparsely populated with such types of inferencepairs, so a new corpus is required.For the purpose of the corpus, the concept ofmotion is strictly limited to the set of words in the(Levin, 1993) verb-class MOTION.
This greatlybenefits the annotation process: passages or sen-tences without a verb or nominalization that fitsinto the MOTION class can immediately be dis-carded.
Levin?s verb classes are easily accessiblevia VERBNET (Kipper et al, 1998), which pro-vides additional syntactic and semantic informa-tion as well as mappings into WORDNET (Fell-baum, 1998).
(Muller, 1998) proposes a qualitative theory ofmotion based on spatio-temporal primitives, while(Pustejovsky and Moszkowicz, 2008) shows anannotation structure for motion.
Furthermore, rep-resenting motion requires the complete representa-tion of spatial information, as motion is simply acontinuous function that transforms space.
(Hobbsand Narayanan, 2002) discuss many of the prop-erties for spatial representation, including dimen-sionality, frame of reference, regions, relative lo-cation, orientation, shape, and motion.
It is there-fore desirable for a motion corpus to require infer-ence over many different aspects of space as wellas motion.
Table 2 shows the properties of motionincorporated in the inference system.In practice, these properties are far from uni-formly distributed.
Properties such as dest(Mx)are far more common than shape(Mx).
Clearly,Property Descriptionmotion(Mx) Instance of motion in texttheme(Mx) Object under motionarea(Mx) Area of motionsrc(Mx) Source locationdest(Mx) Destination locationpath(Mx) Path of motioncurrent(Mx) Current positionorientation(Mx) Direction/Orientationshape(Mx) Shape of objectt start(Mx) Start of motiont end(Mx) End of motionTable 2: Extracted properties of motion.having a system that performs well on destinationsis more important than one that can draw infer-ences from motion?s effects on an object?s shape(?the car hit the barricade and was crushed?
), butit is still desirable to have a corpus that providessystems with examples of such properties.The corpus annotation process shall disregardmany discourse-related phenomena, including co-reference.
Further, the text and hypothesis for eachinference pair will be limited to one sentence.
Inthis way, knowledge of motion is emphasized overother linguistic tasks.3 Building a Corpus Focusing onKnowledge about MotionTo build the motion inference corpus, we choseto start with an existing, large document corpus,AQUAINT-2.2This corpus is composed of 2.4GBof raw files and contains over 900,000 documents.Having a large corpus is important for findingsparse verbs like escort and swing and sparseproperties like area(Mx) and orientation(Mx).3.1 Text AnnotationIn order to get a more diverse distribution of mo-tion verbs and properties (hereafter, just referredto as properties) than the given distribution fromthe corpus, the following procedure is considered:Let Vsbe the (static) distribution of motionproperties from the document corpus.
Let Vdbethe (dynamic) distribution of motion propertiesfrom an (initially empty) set of annotated exam-ples.
Next, define a ?feedback?
distribution Vf,such that for each property y:Pf(y) =max(0, 2Ps(y)?
Pd(y))Z(1)Where Ps(y), Pd(y), and Pf(y) are the proba-bilities of property y in distributions Vs, Vd, and2Available through the Linguistic Data Consortium, idLDC2008T2549Vf, respectively, and Z is a normalization factor(needed when the numerator is zero).Let the parameter ?
determine the likeli-hood of sampling from this distribution Vforfrom the uniform distribution U .
The functionNextExampleType(Vf, ?)
then specifies which mo-tion property should be in the next example.
Anunannotated example is then drawn from an index,annotated by the user, and placed in the set of an-notated examples.
Vdis then updated to reflect thenew distribution of verbs and properties in the an-notated example set.There are several items to note.
First, the exam-ple might contain multiple properties not chosenby the NextExampleType method.
When a motionevent with a path(Mx) is chosen, it is not uncom-mon for a dest(Mx) property to be a part of thesame event.
This is why the Vdand Vfdistribu-tions are necessary: they are a feedback mecha-nism to try to keep the actual distribution, Vd, asclose to the desired distribution as possible.Second, the value for ?
is the sole pre-specifiedparameter.
It dictates the likelihood of choosingan example despite its a priori probability.
Setting?
to 1.0 will result in only sampling based on theVfdistribution, and setting it to 0.0 will generatea uniform sampling.
In practice, this is set to 0.8to allow many of the sparse features through.Third, Vdand Vfaccount even for proper-ties generated from the uniform distribution.
Inpractice this means that low-probability eventswill be generated from U and not Vf, especiallylater in the sampling process.
Due to the non-independence of the properties as discussed above,this discrepancy is difficult to account for and isconsidered acceptable: U will still dictate a muchhigher distribution of low-probability propertiesthan would otherwise be the case.3.2 Hypothesis AnnotationWhile the hypothesis itself must be written by theannotator, one can apply some of the same prin-ciples to ensure a coverage of motion concepts.Since not every motion term in the text need betested by the hypothesis, it is beneficial to keeptrack of which properties are tested within each.For this reason, the annotator is responsible for in-dicating which motion properties are used in thehypothesis.
This way, the annotator can be alertedto any properties under-represented in the set ofhypotheses relative to the set of annotated texts.Feature # Seq Ex Gendest(Mx) 749 48 60go 382 90 129leave 105 376 454. .
.
.
.
.
.
.
.
.
.
.orientation(Mx) 94 420 282flee 4 9,991 5,508steer 2 20,000 7,065parachute 1 40,000 8,227Table 3: Motion features with instance countsfrom 2000 sample sentences.
The Seq (Sequen-tial) and Ex Gen (see Section 3.1) columns arethe expected number of annotated sentences for20 instances of the feature to be found using thatmethod, assuming i.i.d.3.3 EvaluationThe purpose of the algorithm from Section 3.1 isnot only to build a more balanced corpus, but todo so more quickly.
By looking through exam-ples that are more likely to maintain a balancedcorpus, annotators are saved from looking throughhundreds (or thousands!)
of examples that containoverly redundant properties.To illustrate this point, consider a random sam-ple of 2000 sentences.
Table 3 shows the extractedcounts for some of the least and most commonverbs and properties alongside projections of howmany motion sentences would need to be anno-tated with and without the algorithm to attain arather modest 20 examples of each.
The resultsprove that, for many features, the example genera-tion approach allows many more instances of thatfeature to be placed in the corpus.3.4 Comparison with Active LearningThe process presented in Section 3.1 bears a closeresemblence with active learning, so the differ-ences between the two merit some discussion.
Ac-tive learning seeks to improve a specific classifierby selecting training data based on some confi-dence/score metric for the purpose of improvingan overall metric (usually the score across all an-notated data).
Often, examples on which the clas-sifier is the least confident are presented to an an-notator for manual classification.
Then the systemis re-trained to include the new data, and the pro-cess repeats.The annotation process presented above, how-ever, is not ?active?
in this same sense.
Insteadit seeks a certain distribution of properties regard-less of a classifier?s ability to accurately performinferences.
The primary advantage, then, is a cor-pus that is not designed for a specific classification50Corpus # Dev # TestRTE-1 567 800RTE-2 800 800RTE-3 800 800BPI 250Table 4: Number of annotated inferences for eachinference corpus.technique or set of features.
A secondary advan-tage is that it avoids the risk of choosing poor ex-amples but rather seeks a breadth of data.4 Corpus Size ConsiderationsAn important consideration?and an active area ofresearch?is the ideal size of an annotated corpus.As one can see from Table 4, the RTE tasks make800 examples available for an open-domain tex-tual inference corpus.But when the scope of the corpus is more lim-ited, perhaps 800 examples is too few or too many.If the intent is to provide a set on which systemscan be blindly evaluated for motion inference, thena much smaller number is required than a corpusintended for training machine-learned models.
Inthis case, we seek to do the latter.It should be mentioned that if the corpus gen-eration process follows the algorithm presented inSection 3.1, then any reasonable number of infer-ence pairs should follow the same distribution asa much larger set.
For this reason, it is possibleto adopt the active learning approach and build thecorpus incrementally by iteratively annotating un-til satisfactory results are reached or gains are min-imal.5 DiscussionIn addition to building a motion-specific corpus,this paper argues for the creation of domain-specific corpora for textual inference.
Beyondsimply measuring a system?s ability to reason forspecific tasks, they enable the aquisition of worldknowledge through training data.
They can thenbe used by statistical learning techniques appliedto natural language processing.
This is differentthan generating axioms and using them in abduc-tive reasoning, which is another approach to ap-proximate world knowledge.Levin?s verb classes (of which there are lessthan fifty) are a useful way to organize corpora.Levin?s classes are structured under the assump-tion that syntactic and semantic frames are directlylinked within each class.
Since all verbs within theclass have similar semantic arguments, knowledgeaquisition becomes manageable.
A system thathas a wide coverage of knowledge trained on suchcorpora could claim a wide coverage of knowledgeof all verb-based events within text.6 ConclusionThis paper has presented an argument for the cre-ation of domain-specific textual inference corporaand, in general terms, what that corpus should looklike.
In particular, it has described the ongoingprocess of building an inference corpus for spa-tial inference about motion.
It has shown how anexisting system can be used to aid in the examplegeneration and annotation process with analysis asto the effects of the algorithm on presenting morebalanced data.
Finally, the paper discussed someconsiderations for the size of such a corpus.Upon completion, the corpus will be made pub-lically available.ReferencesIdo Dagan, Oren Glickman, and Bernardo Magnini.2005.
The pascal recognizing textual entailmentchallenge.
In Proceedings of the First PASCALChallenges Workshop on Recognising Textual En-tailment, pages 1?8.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Jerry R. Hobbs and Srini Narayanan.
2002.
Spatialrepresentation and reasoning.
In Intelligent Systems:Concepts and Applications, pages 67?76.
MacMil-lan.Karin Kipper, Hoa Trang Dang, and Martha Palmer.1998.
Class-based construction of a verb lexicon.In In Proceedings of AAAI/IAAI.Beth Levin.
1993.
English Verb Classes and Alterna-tions: A Preliminary Investigation.
The Universityof Chicago Press.Philippe Muller.
1998.
A Qualitative Theory of Mo-tion Based on Spatio-Temporal Primitives.
In KR?98: Principles of Knowledge Representation andReasoning, pages 131?141.James Pustejovsky and Jessica L. Moszkowicz.
2008.Integrating Motion Predicate Classes with Spatialand Temporal Annotations.
In Proceedings of COL-ING 2008, pages 95?98.51
