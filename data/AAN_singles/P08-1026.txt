Proceedings of ACL-08: HLT, pages 218?226,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsRegular tree grammars as a formalism for scope underspecificationAlexander Koller?a.koller@ed.ac.uk?
University of EdinburghMichaela Regneri?
?regneri@coli.uni-sb.de?
University of GroningenStefan Thater?stth@coli.uni-sb.de?
Saarland UniversityAbstractWe propose the use of regular tree grammars(RTGs) as a formalism for the underspecifiedprocessing of scope ambiguities.
By applyingstandard results on RTGs, we obtain a novelalgorithm for eliminating equivalent readingsand the first efficient algorithm for computingthe best reading of a scope ambiguity.
We alsoshow how to derive RTGs from more tradi-tional underspecified descriptions.1 IntroductionUnderspecification (Reyle, 1993; Copestake et al,2005; Bos, 1996; Egg et al, 2001) has become thestandard approach to dealing with scope ambiguityin large-scale hand-written grammars (see e.g.
Cope-stake and Flickinger (2000)).
The key idea behindunderspecification is that the parser avoids comput-ing all scope readings.
Instead, it computes a singlecompact underspecified description for each parse.One can then strengthen the underspecified descrip-tion to efficiently eliminate subsets of readings thatwere not intended in the given context (Koller andNiehren, 2000; Koller and Thater, 2006); so whenthe individual readings are eventually computed, thenumber of remaining readings is much smaller andmuch closer to the actual perceived ambiguity of thesentence.In the past few years, a ?standard model?
of scopeunderspecification has emerged: A range of for-malisms from Underspecified DRT (Reyle, 1993)to dominance graphs (Althaus et al, 2003) haveoffered mechanisms to specify the ?semantic mate-rial?
of which the semantic representations are builtup, plus dominance or outscoping relations betweenthese building blocks.
This has been a very suc-cessful approach, but recent algorithms for elimi-nating subsets of readings have pushed the expres-sive power of these formalisms to their limits; forinstance, Koller and Thater (2006) speculate thatfurther improvements over their (incomplete) redun-dancy elimination algorithm require a more expres-sive formalism than dominance graphs.
On the theo-retical side, Ebert (2005) has shown that none ofthe major underspecification formalisms are expres-sively complete, i.e.
supports the description of anarbitrary subset of readings.
Furthermore, the some-what implicit nature of dominance-based descrip-tions makes it difficult to systematically associatereadings with probabilities or costs and then com-pute a best reading.In this paper, we address both of these shortcom-ings by proposing regular tree grammars (RTGs)as a novel underspecification formalism.
Regulartree grammars (Comon et al, 2007) are a standardapproach for specifying sets of trees in theoreticalcomputer science, and are closely related to regu-lar tree transducers as used e.g.
in recent work onstatistical MT (Knight and Graehl, 2005) and gram-mar formalisms (Shieber, 2006).
We show that the?dominance charts?
proposed by Koller and Thater(2005b) can be naturally seen as regular tree gram-mars; using their algorithm, classical underspecifieddescriptions (dominance graphs) can be translatedinto RTGs that describe the same sets of readings.However, RTGs are trivially expressively completebecause every finite tree language is also regular.
Weexploit this increase in expressive power in present-ing a novel redundancy elimination algorithm that issimpler and more powerful than the one by Kollerand Thater (2006); in our algorithm, redundancyelimination amounts to intersection of regular treelanguages.
Furthermore, we show how to define aPCFG-style cost model on RTGs and compute bestreadings of deterministic RTGs efficiently, and illus-trate this model on a machine learning based model218of scope preferences (Higgins and Sadock, 2003).To our knowledge, this is the first efficient algorithmfor computing best readings of a scope ambiguity inthe literature.The paper is structured as follows.
In Section 2,we will first sketch the existing standard approachto underspecification.
We will then define regulartree grammars and show how to see them as an un-derspecification formalism in Section 3.
We willpresent the new redundancy elimination algorithm,based on language intersection, in Section 4, andshow how to equip RTGs with weights and computebest readings in Section 5.
We conclude in Section 6.2 UnderspecificationThe key idea behind scope underspecification is todescribe all readings of an ambiguous expressionwith a single, compact underspecified representation(USR).
This simplifies semantics construction, andcurrent algorithms (Koller and Thater, 2005a) sup-port the efficient enumeration of readings from anUSR when it is necessary.
Furthermore, it is possibleto perform certain semantic processing tasks suchas eliminating redundant readings (see Section 4) di-rectly on the level of underspecified representationswithout explicitly enumerating individual readings.Under the ?standard model?
of scope underspeci-fication, readings are considered as formulas or trees.USRs specify the ?semantic material?
common toall readings, plus dominance or outscopes relationsbetween these building blocks.
In this paper, we con-sider dominance graphs (Egg et al, 2001; Althauset al, 2003) as one representative of this class.
Anexample dominance graph is shown on the left ofFig.
1.
It represents the five readings of the sentence?a representative of a company saw every sample.
?The (directed, labelled) graph consists of seven sub-trees, or fragments, plus dominance edges relatingnodes of these fragments.
Each reading is encodedas one configuration of the dominance graph, whichcan be obtained by ?plugging?
the tree fragmentsinto each other, in a way that respects the dominanceedges: The source node of each dominance edgemust dominate (i.e., be an ancestor of) the targetnode in each configuration.
The trees in Fig.
1a?eare the five configurations of the example graph.An important class of dominance graphs are hy-pernormally connected dominance graphs, or dom-inance nets (Niehren and Thater, 2003).
The pre-cise definition of dominance nets is not importanthere, but note that virtually all underspecified de-scriptions that are produced by current grammars arenets (Flickinger et al, 2005).
For the rest of the pa-per, we restrict ourselves to dominance graphs thatare hypernormally connected.3 Regular tree grammarsWe will now recall the definition of regular treegrammars and show how they can be used as an un-derspecification formalism.3.1 DefinitionLet ?
be an alphabet, or signature, of tree construc-tors { f ,g,a, .
.
.
}, each of which is equipped with anarity ar( f )?
0.
A finite constructor tree t is a finitetree in which each node is labelled with a symbol of?, and the number of children of the node is exactlythe arity of this symbol.
For instance, the configura-tions in Fig.
1a-e are finite constructor trees over thesignature {ax|2,ay|2,compz|0, .
.
.}.
Finite construc-tor trees can be seen as ground terms over ?
thatrespect the arities.
We write T (?)
for the finite con-structor trees over ?.A regular tree grammar (RTG) is a 4-tuple G =(S,N,?,R) consisting of a nonterminal alphabet N,a terminal alphabet ?, a start symbol S ?
N, and afinite set of production rules R of the form A?
?
,where A ?
N and ?
?
T (?
?N); the nonterminalscount as zero-place constructors.
Two finite con-structor trees t, t ?
?
T (?
?
N) stand in the deriva-tion relation, t ?G t ?, if t ?
can be built from t byreplacing an occurrence of some nonterminal A bythe tree on the right-hand side of some productionfor A.
The language generated by G, L(G), is the set{t ?
T (?)
| S?
?G t}, i.e.
all terms of terminal sym-bols that can be derived from the start symbol by asequence of rule applications.
Note that L(G) is apossibly infinite language of finite trees.
As usual,we write A?
t1 | .
.
.
| tn as shorthand for the n pro-duction rules A?
ti (1 ?
i ?
n).
See Comon et al(2007) for more details.The languages that can be accepted by regular treegrammars are called regular tree languages (RTLs),and regular tree grammars are equivalent to regular219everyysampleyseex,yaxrepr-ofx,zazcompz12 34 5 67everyyaxsampleyseex,yrepr-ofx,zazcompz(a)everyyazaxsampleyseex,ycompzrepr-ofx,z(c)everyyazaxsampleyseex,ycompzrepr-ofx,z(d)(b)everyysampleyseex,yaxrepr-ofx,zazcompz(e)everyysampleyaxrepr-ofx,zseex,yazcompzFigure 1: A dominance graph (left) and its five configurations.tree automata, which are defined essentially like thewell-known regular string automata, except that theyassign states to the nodes in a tree rather than the po-sitions in a string.
Tree automata are related to treetransducers as used e.g.
in statistical machine trans-lation (Knight and Graehl, 2005) exactly like finite-state string automata are related to finite-state stringtransducers, i.e.
they use identical mechanisms to ac-cept rather than transduce languages.
Many theoreti-cal results carry over from regular string languagesto regular tree languages; for instance, membershipof a tree in a RTL can be decided in linear time,RTLs are closed under intersection, union, and com-plement, and so forth.3.2 Regular tree grammars inunderspecificationWe can now use regular tree grammars in underspeci-fication by representing the semantic representationsas trees and taking an RTG G as an underspecifieddescription of the trees in L(G).
For example, thefive configurations in Fig.
1 can be represented asthe tree language accepted by the following gram-mar with start symbol S.S ?
ax(A1,A2) | az(B1,A3) | everyy(B3,A4)A1 ?
az(B1,B2)A2 ?
everyy(B3,B4)A3 ?
ax(B2,A2) | everyy(B3,A5)A4 ?
ax(A1,B4) | az(B1,A5)A5 ?
ax(B2,B4)B1 ?
compz B2 ?
repr-ofx,zB3 ?
sampley B4 ?
seex,yMore generally, every finite set of trees can bewritten as the tree language accepted by a non-recursive regular tree grammar such as this.
Thisgrammar can be much smaller than the set of trees,because nonterminal symbols (which stand for setsof possibly many subtrees) can be used on the right-hand sides of multiple rules.
Thus an RTG is a com-pact representation of a set of trees in the same waythat a parse chart is a compact representation of theset of parse trees of a context-free string grammar.Note that each tree can be enumerated from the RTGin linear time.3.3 From dominance graphs to tree grammarsFurthermore, regular tree grammars can be system-atically computed from more traditional underspeci-fied descriptions.
Koller and Thater (2005b) demon-strate how to compute a dominance chart from adominance graph D by tabulating how a subgraphcan be decomposed into smaller subgraphs by re-moving what they call a ?free fragment?.
If D ishypernormally connected, this chart can be read asa regular tree grammar whose nonterminal symbolsare subgraphs of the dominance graph, and whoseterminal symbols are names of fragments.
For theexample graph in Fig.
1, it looks as follows.
{1,2,3,4,5,6,7} ?
1({2,4,5},{3,6,7}){1,2,3,4,5,6,7} ?
2({4},{1,3,5,6,7}){1,2,3,4,5,6,7} ?
3({6},{1,2,4,5,7}){1,3,5,6,7} ?
1({5},{3,6,7}) | 3({6},{1,5,7}){1,2,4,5,7} ?
1({2,4,5},{7}) | 2({4},{1,5,7}){1,5,7} ?
1({5},{7}){2,4,5} ?
2({4},{5}) {4} ?
4 {6}?
6{3,6,7} ?
3({6},{7}) {5} ?
5 {7}?
7This grammar accepts, again, five different trees,whose labels are the node names of the dominancegraph, for instance 1(2(4,5),3(6,7)).
If f : ??
?
?is a relabelling function from one terminal alpha-bet to another, we can write f (G) for the grammar(S,N,??,R?
), where R?
= {A ?
f (a)(B1, .
.
.
,Bn) |A?
a(B1, .
.
.
,Bn) ?
R}.
Now if we choose f to bethe labelling function of D (which maps node namesto node labels) and G is the chart of D, then L( f (G))will be the set of configurations of D. The grammarin Section 3.2 is simply f (G) for the chart above (upto consistent renaming of nonterminals).In the worst case, the dominance chart of a dom-inance graph with n fragments has O(2n) produc-tion rules (Koller and Thater, 2005b), i.e.
charts maybe exponential in size; but note that this is still an2201,0E+001,0E+041,0E+081,0E+121,0E+161 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33#fragments#configurations/rules01020304050607080#sentences#sentences#production rules in chart#configurationsFigure 2: Chart sizes in the Rondane corpus.improvement over the n!
configurations that theseworst-case examples have.
In practice, RTGs thatare computed by converting the USR computed by agrammar remain compact: Fig.
2 compares the aver-age number of configurations and the average num-ber of RTG production rules for USRs of increasingsizes in the Rondane treebank (see Sect.
4.3); thebars represent the number of sentences for USRs of acertain size.
Even for the most ambiguous sentence,which has about 4.5?1012 scope readings, the domi-nance chart has only about 75 000 rules, and it takesonly 15 seconds on a modern consumer PC (IntelCore 2 Duo at 2 GHz) to compute the grammar fromthe graph.
Computing the charts for all 999 MRS-nets in the treebank takes about 45 seconds.4 Expressive completeness andredundancy eliminationBecause every finite tree language is regular, RTGsconstitute an expressively complete underspecifica-tion formalism in the sense of Ebert (2005): Theycan represent arbitrary subsets of the original set ofreadings.
Ebert shows that the classical dominance-based underspecification formalisms, such as MRS,Hole Semantics, and dominance graphs, are allexpressively incomplete, which Koller and Thater(2006) speculate might be a practical problem for al-gorithms that strengthen USRs to remove unwantedreadings.
We will now show how both the expres-sive completeness and the availability of standardconstructions for RTGs can be exploited to get animproved redundancy elimination algorithm.4.1 Redundancy eliminationRedundancy elimination (Vestre, 1991; Chaves,2003; Koller and Thater, 2006) is the problem of de-riving from an USR U another USR U ?, such thatthe readings of U ?
are a proper subset of the read-ings of U , but every reading in U is semanticallyequivalent to some reading in U ?.
For instance, thefollowing sentence from the Rondane treebank is an-alyzed as having six quantifiers and 480 readings bythe ERG grammar; these readings fall into just twosemantic equivalence classes, characterized by therelative scope of ?the lee of?
and ?a small hillside?.A redundancy elimination would therefore ideally re-duce the underspecified description to one that hasonly two readings (one for each class).
(1) We quickly put up the tents in the lee of asmall hillside and cook for the first time in theopen.
(Rondane 892)Koller and Thater (2006) define semantic equiva-lence in terms of a rewrite system that specifies un-der what conditions two quantifiers may exchangetheir positions without changing the meaning of thesemantic representation.
For example, if we assumethe following rewrite system (with just a single rule),the five configurations in Fig.
1a-e fall into threeequivalence classes ?
indicated by the dotted boxesaround the names a-e ?
because two pairs of read-ings can be rewritten into each other.
(2) ax(az(P,Q),R)?
az(P,ax(Q,R))Based on this definition, Koller and Thater (2006)present an algorithm (henceforth, KT06) that deletesrules from a dominance chart and thus removes sub-sets of readings from the USR.
The KT06 algorithmis fast and quite effective in practice.
However, it es-sentially predicts for each production rule of a dom-inance chart whether each configuration that can bebuilt with this rule is equivalent to a configurationthat can be built with some other production for thesame subgraph, and is therefore rather complex.4.2 Redundancy elimination as languageintersectionWe now define a new algorithm for redundancy elim-ination.
It is based on the intersection of regular treelanguages, and will be much simpler and more pow-erful than KT06.Let G = (S,N,?,R) be an RTG with a linear or-der on the terminals ?
; for ease of presentation, weassume ?
?
N. Furthermore, let f : ??
??
be a re-labelling function into the signature ??
of the rewrite221system.
For example, G could be the dominancechart of some dominance graph D, and f could bethe labelling function of D.We can then define a tree language LF as follows:LF contains all trees over ?
that do not contain a sub-tree of the form q1(x1, .
.
.
,xi?1,q2(.
.
.
),xi+1, .
.
.
,xk)where q1 > q2 and the rewrite system contains a rulethat has f (q1)(X1, .
.
.
,Xi?1, f (q2)(.
.
.
),Xi+1, .
.
.
,Xk)on the left or right hand side.
LF is a regular tree lan-guage, and can be accepted by a regular tree gram-mar GF with O(n) nonterminals and O(n2) rules,where n = |??|.
A filter grammar for Fig.
1 looksas follows:S ?
1(S,S) | 2(S,Q1) | 3(S,S) | 4 | .
.
.
| 7Q1 ?
2(S,Q1) | 3(S,S) | 4 | .
.
.
| 7This grammar accepts all trees over ?
except onesin which a node with label 2 is the parent of a nodewith label 1, because such trees correspond to config-urations in which a node with label az is the parent ofa node with label ax, az and ax are permutable, and2 > 1.
In particular, it will accept the configurations(b), (c), and (e) in Fig.
1, but not (a) or (d).Since regular tree languages are closed under in-tersection, we can compute a grammar G?
such thatL(G?)
= L(G)?LF .
This grammar has O(nk) nonter-minals and O(n2k) productions, where k is the num-ber of production rules in G, and can be computedin time O(n2k).
The relabelled grammar f (G?)
ac-cepts all trees in which adjacent occurrences of per-mutable quantifiers are in a canonical order (sortedfrom lowest to highest node name).
For example, thegrammar G?
for the example looks as follows; notethat the nonterminal alphabet of G?
is the product ofthe nonterminal alphabets of G and GF .
{1,2,3,4,5,6,7}S ?
1({2,4,5}S,{3,6,7}S){1,2,3,4,5,6,7}S ?
2({4}S,{1,3,5,6,7}Q1){1,2,3,4,5,6,7}S ?
3({6}S,{1,2,4,5,7}S){1,3,5,6,7}Q1 ?
3({6}S,{1,5,7}S){1,2,4,5,7}S ?
1({2,4,5}S,{7}S){1,2,4,5,7}S ?
2({4}S,{1,5,7}Q1){2,4,5}S ?
2({4}S,{5}Q1) {4}S ?
4{3,6,7}S ?
3({6}S,{7}S) {5}S ?
5{1,5,7}S ?
1({5}S,{7}S) {5}Q1 ?
5{6}S ?
6 {7}S ?
7Significantly, the grammar contains no produc-tions for {1,3,5,6,7}Q1 with terminal symbol 1, andno production for {1,5,7}Q1 .
This reduces the treelanguage accepted by f (G?)
to just the configura-tions (b), (c), and (e) in Fig.
1, i.e.
exactly onerepresentative of every equivalence class.
Noticethat there are two different nonterminals, {5}Q1 and{5}S, corresponding to the subgraph {5}, so the in-tersected RTG is not a dominance chart any more.As we will see below, this increased expressivity in-creases the power of the redundancy elimination al-gorithm.4.3 EvaluationThe algorithm presented here is not only more trans-parent than KT06, but also more powerful; for exam-ple, it will reduce the graph in Fig.
4 of Koller andThater (2006) completely, whereas KT06 won?t.To measure the extent to which the new algo-rithm improves upon KT06, we compare both algo-rithms on the USRs in the Rondane treebank (ver-sion of January 2006).
The Rondane treebank is a?Redwoods style?
treebank (Oepen et al, 2002) con-taining MRS-based underspecified representationsfor sentences from the tourism domain, and is dis-tributed together with the English Resource Gram-mar (ERG) (Copestake and Flickinger, 2000).The treebank contains 999 MRS-nets, which wetranslate automatically into dominance graphs andfurther into RTGs; the median number of scope read-ings per sentence is 56.
For our experiment, we con-sider all 950 MRS-nets with less than 650 000 con-figurations.
We use a slightly weaker version of therewrite system that Koller and Thater (2006) used intheir evaluation.It turns out that the median number of equivalenceclasses, computed by pairwise comparison of all con-figurations, is 8.
The median number of configu-rations that remain after running our algorithm isalso 8.
By contrast, the median number after run-ning KT06 is 11.
For a more fine-grained compari-son, Fig.
3 shows the percentage of USRs for whichthe two algorithms achieve complete reduction, i.e.retain only one reading per equivalence class.
In thediagram, we have grouped USRs according to thenatural logarithm of their numbers of configurations,and report the percentage of USRs in this group onwhich the algorithms were complete.
The new algo-rithm dramatically outperforms KT06: In total, it re-duces 96% of all USRs completely, whereas KT06was complete only for 40%.
This increase in com-pleteness is partially due to the new algorithm?s abil-ity to use non-chart RTGs: For 28% of the sentences,2220%20%40%60%80%100%1 3 5 7 9 11 13KT06 RTGFigure 3: Percentage of USRs in Rondane for which thealgorithms achieve complete reduction.it computes RTGs that are not dominance charts.KT06 was only able to reduce 5 of these 263 graphscompletely.The algorithm needs 25 seconds to run for theentire corpus (old algorithm: 17 seconds), and itwould take 50 (38) more seconds to run on the 49large USRs that we exclude from the experiment.By contrast, it takes about 7 hours to compute theequivalence classes by pairwise comparison, and itwould take an estimated several billion years to com-pute the equivalence classes of the excluded USRs.In short, the redundancy elimination algorithm pre-sented here achieves nearly complete reduction at atiny fraction of the runtime, and makes a useful taskthat was completely infeasible before possible.4.4 CompactnessFinally, let us briefly consider the ramifications ofexpressive completeness on efficiency.
Ebert (2005)proves that no expressively complete underspecifi-cation formalism can be compact, i.e.
in the worstcase, the USR of a set of readings become exponen-tially large in the number of scope-bearing operators.In the case of RTGs, this worst case is achieved bygrammars of the form S?
t1 | .
.
.
| tn, where t1, .
.
.
, tnare the trees we want to describe.
This grammar is asbig as the number of readings, i.e.
worst-case expo-nential in the number n of scope-bearing operators,and essentially amounts to a meta-level disjunctionover the readings.Ebert takes the incompatibility between compact-ness and expressive completeness as a fundamentalproblem for underspecification.
We don?t see thingsquite as bleakly.
Expressions of natural language it-self are (extremely underspecified) descriptions ofsets of semantic representations, and so Ebert?s ar-gument applies to NL expressions as well.
Thismeans that describing a given set of readings mayrequire an exponentially long discourse.
Ebert?s def-inition of compactness may be too harsh: An USR,although exponential-size in the number of quanti-fiers, may still be polynomial-size in the length ofthe discourse in the worst case.Nevertheless, the tradeoff between compactnessand expressive power is important for the designof underspecification formalisms, and RTGs offer aunique answer.
They are expressively complete; butas we have seen in Fig.
2, the RTGs that are derivedby semantic construction are compact, and even in-tersecting them with filter grammars for redundancyelimination only blows up their sizes by a factor ofO(n2).
As we add more and more information toan RTG to reduce the set of readings, ultimately tothose readings that were meant in the actual contextof the utterance, the grammar will become less andless compact; but this trend is counterbalanced bythe overall reduction in the number of readings.
Forthe USRs in Rondane, the intersected RTGs are, onaverage, 6% smaller than the original charts.
Only30% are larger than the charts, by a maximal factorof 3.66.
Therefore we believe that the theoreticalnon-compactness should not be a major problem ina well-designed practical system.5 Computing best configurationsA second advantage of using RTGs as an under-specification formalism is that we can apply exist-ing algorithms for computing the best derivationsof weighted regular tree grammars to compute best(that is, cheapest or most probable) configurations.This gives us the first efficient algorithm for comput-ing the preferred reading of a scope ambiguity.We define weighted dominance graphs andweighted tree grammars, show how to translate theformer into the latter and discuss an example.5.1 Weighted dominance graphsA weighted dominance graph D = (V,ET unionmulti ED unionmultiWDunionmultiWI) is a dominance graph with two new typesof edges ?
soft dominance edges, WD, and soft dis-jointness edges, WI ?, each of which is equippedwith a numeric weight.
Soft dominance and dis-jointness edges provide a mechanism for assigningweights to configurations; a soft dominance edge ex-223everyysampleyseex,yaxrepr-ofx,zazcompz1234 5 6798Figure 4: The graph of Fig.
1 with soft constraintspresses a preference that two nodes dominate eachother in a configuration, whereas a soft disjointnessedge expresses a preference that two nodes are dis-joint, i.e.
neither dominates the other.We take the hard backbone of D to be the ordinarydominance graph B(D) = (V,ET unionmultiED) obtained byremoving all soft edges.
The set of configurationsof a weighted graph D is the set of configurationsof its hard backbone.
For each configuration t ofD, we define the weight c(t) to be the product ofthe weights of all soft dominance and disjointnessedges that are satisfied in t. We can then ask forconfigurations of maximal weight.Weighted dominance graphs can be used to en-code the standard models of scope preferences(Pafel, 1997; Higgins and Sadock, 2003).
For exam-ple, Higgins and Sadock (2003) present a machinelearning approach for determining pairwise prefer-ences as to whether a quantifier Q1 dominates an-other quantifier Q2, Q2 dominates Q1, or neither (i.e.they are disjoint).
We can represent these numbersas the weights of soft dominance and disjointnessedges.
An example (with artificial weights) is shownin Fig.
4; we draw the soft dominance edges ascurved dotted arrows and the soft disjointness edgesas as angled double-headed arrows.
Each soft edgeis annotated with its weight.
The hard backboneof this dominance graph is our example graph fromFig.
1, so it has the same five configurations.
Theweighted graph assigns a weight of 8 to configura-tion (a), a weight of 1 to (d), and a weight of 9 to (e);this is also the configuration of maximum weight.5.2 Weighted tree grammarsIn order to compute the maximal-weight configura-tion of a weighted dominance graph, we will firsttranslate it into a weighted regular tree grammar.
Aweighted regular tree grammar (wRTG) (Graehl andKnight, 2004) is a 5-tuple G = (S,N,?,R,c) suchthat G?
= (S,N,?,R) is a regular tree grammar andc : R?
R is a function that assigns each productionrule a weight.
G accepts the same language of treesas G?.
It assigns each derivation a cost equal to theproduct of the costs of the production rules used inthis derivation, and it assigns each tree in the lan-guage a cost equal to the sum of the costs of itsderivations.
Thus wRTGs define weights in a waythat is extremely similar to PCFGs, except that wedon?t require any weights to sum to one.Given a weighted, hypernormally connected dom-inance graph D, we can extend the chart of B(D) toa wRTG by assigning rule weights as follows: Theweight of a rule D0 ?
i(D1, .
.
.
,Dn) is the productover the weights of all soft dominance and disjoint-ness edges that are established by this rule.
We saythat a rule establishes a soft dominance edge fromu to v if u = i and v is in one of the subgraphsD1, .
.
.
,Dn; we say that it establishes a soft disjoint-ness edge between u and v if u and v are in differentsubgraphs D j and Dk ( j 6= k).
It can be shown thatthe weight this grammar assigns to each derivationis equal to the weight that the original dominancegraph assigns to the corresponding configuration.If we apply this construction to the example graphin Fig.
4, we obtain the following wRTG:{1, ...,7} ?
ax({2,4,5},{3,6,7}) [9]{1, ...,7} ?
az({4},{1,3,5,6,7}) [1]{1, ...,7} ?
everyy({6},{1,2,4,5,7}) [8]{2,4,5} ?
az({4},{5}) [1]{3,6,7} ?
everyy({6},{7}) [1]{1,3,5,6,7} ?
ax({5},{3,6,7}) [1]{1,3,5,6,7} ?
everyy({6},{1,5,7}) [8]{1,2,4,5,7} ?
ax({2,4,5},{7}) [1]{1,2,4,5,7} ?
az({4},{1,5,7}) [1]{1,5,7} ?
ax({5},{7}) [1]{4} ?
compz [1] {5} ?
repr?o f x,z [1]{6} ?
sampley [1] {7} ?
seex,y [1]For example, picking ?az?
as the root of a con-figuration (Fig.
1 (c), (d)) of the entire graph hasa weight of 1, because this rule establishes no softedges.
On the other hand, choosing ?ax?
as the roothas a weight of 9, because this establishes the softdisjointness edge (and in fact, leads to the derivationof the maximum-weight configuration in Fig.
1 (e)).5.3 Computing the best configurationThe problem of computing the best configuration ofa weighted dominance graph ?
or equivalently, the224best derivation of a weighted tree grammar ?
cannow be solved by standard algorithms for wRTGs.For example, Knight and Graehl (2005) present analgorithm to extract the best derivation of a wRTG intime O(t + n logn) where n is the number of nonter-minals and t is the number of rules.
In practice, wecan extract the best reading of the most ambiguoussentence in the Rondane treebank (4.5?
1012 read-ings, 75 000 grammar rules) with random soft edgesin about a second.However, notice that this is not the same problemas computing the best tree in the language acceptedby a wRTG, as trees may have multiple deriva-tions.
The problem of computing the best tree is NP-complete (Sima?an, 1996).
However, if the weightedregular tree automaton corresponding to the wRTGis deterministic, every tree has only one derivation,and thus computing best trees becomes easy again.The tree automata for dominance charts are alwaysdeterministic, and the automata for RTGs as in Sec-tion 3.2 (whose terminals correspond to the graph?snode labels) are also typically deterministic if thevariable names are part of the quantifier node labels.Furthermore, there are algorithms for determinizingweighted tree automata (Borchardt and Vogler, 2003;May and Knight, 2006), which could be applied aspreprocessing steps for wRTGs.6 ConclusionIn this paper, we have shown how regular tree gram-mars can be used as a formalism for scope under-specification, and have exploited the power of thisview in a novel, simpler, and more complete algo-rithm for redundancy elimination and the first effi-cient algorithm for computing the best reading of ascope ambiguity.
In both cases, we have adaptedstandard algorithms for RTGs, which illustrates theusefulness of using such a well-understood formal-ism.
In the worst case, the RTG for a scope ambigu-ity is exponential in the number of scope bearers inthe sentence; this is a necessary consequence of theirexpressive completeness.
However, those RTGs thatare computed by semantic construction and redun-dancy elimination remain compact.Rather than showing how to do semantic construc-tion for RTGs, we have presented an algorithm thatcomputes RTGs from more standard underspecifica-tion formalisms.
We see RTGs as an ?underspecifi-cation assembly language?
?
they support efficientand useful algorithms, but direct semantic construc-tion may be inconvenient, and RTGs will rather beobtained by ?compiling?
higher-level underspecifiedrepresentations such as dominance graphs or MRS.This perspective also allows us to establish aconnection to approaches to semantic construc-tion which use chart-based packing methods ratherthan dominance-based underspecification to managescope ambiguities.
For instance, both CombinatoryCategorial Grammars (Steedman, 2000) and syn-chronous grammars (Nesson and Shieber, 2006) rep-resent syntactic and semantic ambiguity as part ofthe same parse chart.
These parse charts can beseen as regular tree grammars that accept the lan-guage of parse trees, and conceivably an RTG thatdescribes only the semantic and not the syntacticambiguity could be automatically extracted.
Wecould thus reconcile these completely separate ap-proaches to semantic construction within the sameformal framework, and RTG-based algorithms (e.g.,for redundancy elimination) would apply equally todominance-based and chart-based approaches.
In-deed, for one particular grammar formalism it haseven been shown that the parse chart contains anisomorphic image of a dominance chart (Koller andRambow, 2007).Finally, we have only scratched the surface ofwhat can be be done with the computation of bestconfigurations in Section 5.
The algorithms gen-eralize easily to weights that are taken from an ar-bitrary ordered semiring (Golan, 1999; Borchardtand Vogler, 2003) and to computing minimal-weightrather than maximal-weight configurations.
It is alsouseful in applications beyond semantic construction,e.g.
in discourse parsing (Regneri et al, 2008).Acknowledgments.
We have benefited greatlyfrom fruitful discussions on weighted tree grammarswith Kevin Knight and Jonathan Graehl, and on dis-course underspecification with Markus Egg.
Wealso thank Christian Ebert, Marco Kuhlmann, AlexLascarides, and the reviewers for their comments onthe paper.
Finally, we are deeply grateful to our for-mer colleague Joachim Niehren, who was a great fanof tree automata before we even knew what they are.225ReferencesE.
Althaus, D. Duchier, A. Koller, K. Mehlhorn,J.
Niehren, and S. Thiel.
2003.
An efficient graphalgorithm for dominance constraints.
J. Algorithms,48:194?219.B.
Borchardt and H. Vogler.
2003.
Determinization offinite state weighted tree automata.
Journal of Au-tomata, Languages and Combinatorics, 8(3):417?463.J.
Bos.
1996.
Predicate logic unplugged.
In Proceedingsof the Tenth Amsterdam Colloquium, pages 133?143.R.
P. Chaves.
2003.
Non-redundant scope disambigua-tion in underspecified semantics.
In Proceedings ofthe 8th ESSLLI Student Session, pages 47?58, Vienna.H.
Comon, M. Dauchet, R. Gilleron, C. Lo?ding,F.
Jacquemard, D. Lugiez, S. Tison, and M. Tommasi.2007.
Tree automata techniques and applications.Available on: http://www.grappa.univ-lille3.fr/tata.A.
Copestake and D. Flickinger.
2000.
An open-source grammar development environment and broad-coverage English grammar using HPSG.
In Confer-ence on Language Resources and Evaluation.A.
Copestake, D. Flickinger, C. Pollard, and I.
Sag.
2005.Minimal recursion semantics: An introduction.
Re-search on Language and Computation, 3:281?332.C.
Ebert.
2005.
Formal investigations of underspecifiedrepresentations.
Ph.D. thesis, King?s College, Lon-don.M.
Egg, A. Koller, and J. Niehren.
2001.
The ConstraintLanguage for Lambda Structures.
Logic, Language,and Information, 10:457?485.D.
Flickinger, A. Koller, and S. Thater.
2005.
A newwell-formedness criterion for semantics debugging.
InProceedings of the 12th HPSG Conference, Lisbon.J.
S. Golan.
1999.
Semirings and their applications.Kluwer, Dordrecht.J.
Graehl and K. Knight.
2004.
Training tree transducers.In HLT-NAACL 2004, Boston.D.
Higgins and J. Sadock.
2003.
A machine learning ap-proach to modeling scope preferences.
ComputationalLinguistics, 29(1).K.
Knight and J. Graehl.
2005.
An overview of proba-bilistic tree transducers for natural language process-ing.
In Computational linguistics and intelligent textprocessing, pages 1?24.
Springer.A.
Koller and J. Niehren.
2000.
On underspecifiedprocessing of dynamic semantics.
In Proceedings ofCOLING-2000, Saarbru?cken.A.
Koller and O. Rambow.
2007.
Relating dominanceformalisms.
In Proceedings of the 12th Conference onFormal Grammar, Dublin.A.
Koller and S. Thater.
2005a.
Efficient solving andexploration of scope ambiguities.
Proceedings of theACL-05 Demo Session.A.
Koller and S. Thater.
2005b.
The evolution of dom-inance constraint solvers.
In Proceedings of the ACL-05 Workshop on Software.A.
Koller and S. Thater.
2006.
An improved redundancyelimination algorithm for underspecified descriptions.In Proceedings of COLING/ACL-2006, Sydney.J.
May and K. Knight.
2006.
A better n-best list: Prac-tical determinization of weighted finite tree automata.In Proceedings of HLT-NAACL.R.
Nesson and S. Shieber.
2006.
Simpler TAG semanticsthrough synchronization.
In Proceedings of the 11thConference on Formal Grammar.J.
Niehren and S. Thater.
2003.
Bridging the gap be-tween underspecification formalisms: Minimal recur-sion semantics as dominance constraints.
In Proceed-ings of ACL 2003.S.
Oepen, K. Toutanova, S. Shieber, C. Manning,D.
Flickinger, and T. Brants.
2002.
The LinGO Red-woods treebank: Motivation and preliminary applica-tions.
In Proceedings of the 19th International Con-ference on Computational Linguistics (COLING?02),pages 1253?1257.J.
Pafel.
1997.
Skopus und logische Struktur: Studienzum Quantorenskopus im Deutschen.
Habilitationss-chrift, Eberhard-Karls-Universita?t Tu?bingen.M.
Regneri, M. Egg, and A. Koller.
2008.
Efficient pro-cessing of underspecified discourse representations.
InProceedings of the 46th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (ACL-08: HLT) ?
Short Papers,Columbus, Ohio.U.
Reyle.
1993.
Dealing with ambiguities by underspec-ification: Construction, representation and deduction.Journal of Semantics, 10(1).S.
Shieber.
2006.
Unifying synchronous tree-adjoininggrammars and tree transducers via bimorphisms.
InProceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Linguis-tics (EACL-06), Trento, Italy.K.
Sima?an.
1996.
Computational complexity of proba-bilistic disambiguation by means of tree-grammars.
InProceedings of the 16th conference on Computationallinguistics, pages 1175?1180, Morristown, NJ, USA.Association for Computational Linguistics.M.
Steedman.
2000.
The syntactic process.
MIT Press.E.
Vestre.
1991.
An algorithm for generating non-redundant quantifier scopings.
In Proc.
of EACL,pages 251?256, Berlin.226
