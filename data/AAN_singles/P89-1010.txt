Word Association Norms, Mutual Information, and LexicographyKenneth Ward ChurchBell LaboratoriesMurray Hill, N.J.Patrick HanksCoLlins PublishersGlasgow, ScotlandAbstractThe term word assaciation is used in a veryparticular sense in the psycholinguistic literature.
(Generally speaking, subjects respond quicker thannormal to the word "nurse" if it follows a highlyassociated word such as "doctor.")
We wilt extendthe term to provide the basis for a statisticaldescription of a variety of interesting linguisticphenomena, ranging from semantic relations of thedoctor/nurse type (content word/content word) tolexico-syntactic o-occurrence constraints betweenverbs and prepositions (content word/functionword).
This paper will propose a new objectivemeasure based on the information theoretic notionof mutual information, for estimating wordassociation orms from computer eadable corpora.
(The standard method of obtaining word associationnorms, testing a few thousand subjects on a fewhundred words, is both costly and unreliable.)
The, proposed measure, the association ratio, estimatesword association norms directly from computerreadable corpora, waki,~g it possible to estimatenorms for tens of thousands of words.I.
Meaning and AssociationIt is common practice in linguistics to classify wordsnot only on the basis of their meanings but also onthe basis of their co-occurrence with other words.Running through the whole Firthian tradition, forexample, is the theme that "You shall know a wordby the company it keeps" (Firth, 1957).
"On the one hand, bank ?o.occors with words and expressionsuch u money, nmu.
loan, account, ~ m .
c~z~c.o~.ctal, manager, obbery, vaults, wortln# in a, lu action,Fb~Nadonal.
of F.ngland, and so forth.
On the other hand,we find bank m-occorring with r~r.
~bn, boa:.
am (endof course West and Sou~, which have tcqu/red specialmeanings of their own), on top of the, and of the Rhine.
"\[Hanks (1987), p. 127\]The search for increasingly delicate word classes isnot new.
In lexicography, for example, it goes backat least to the "verb patterns" described in Hornby'sAdvanced Learner's Dictionary (first edition 1948).What is new is that facilities for the computationalstorage and analysis of large bodies of naturallanguage have developed significantly in recentyears, so that it is now becoming possible to test andapply informal assertions of this kind in a more76rigorous way, and to see what company our wordsdo keep.2.
Practical ApplicationsThe proposed statistical description has a largenumber of potentially important applications,including: (a) constraining the language model bothfor speech recognition and optical characterrecognition (OCR), (b) providing disambiguationcues for parsing highly ambiguous syntacticstructures uch as noun compounds, conjunctions,and prepositional phrases, (c) retrieving texts fromlarge databases (e.g., newspapers, patents), (d)enhancing the productivity of computational linguistsin compiling lexicons of lexico-syntactic facts, and(e) enhancing the productivity of lexicographers inidentifying normal and conventional usage.Consider the optical character recognizer (OCR)application.
Suppose that we have an OCR devicesuch as \[Kahan, Pavlidis, Baird (1987)\], and it hasassigned about equal probability to havingrecognized "farm" and "form," where the context iseither: (1) "federal t credit" or (2) "someof."
The proposed association measure can makeuse of the fact that "farm" is much more likely inthe first context and "form" is much more likely inthe second to resolve the ambiguity.
Note thatalternative disambiguation methods based onsyntactic constraints uch as part of speech areunlikely to help in this case since both "form" and"farm" are commonly used as nouns.3.
Word Association and Psycholingui~ticsWord association orms are well known to be animportant factor in psycholinguistic research,especially in the area of lexical retrieval.
Generallyspeaking, subjects respond quicker than normal tothe word "nurse" if it follows a highly associatedword such as "doctor.
""Some resuhs and impl~tfions ere summarized fromrexcfion-fime .experiments in which subjects either (a)~as~f'mi successive strings of lenen as words and nonwords,c~ (b) pronounced the sUnriSe.
Both types of response towords (e.g., BUTTER) were consistently fester whenpreceded by associated words (e.g., BREAD) rather thanunassociated words (e.g, NURSE)."
\[Meyer, Schvaneveldtand Ruddy (1975), p. 98\]Much of this psycholinguistic research is based onempirical estimates of word association orms suchas \[Palermo and Jenkins (1964)\], perhaps the mostinfluential study of its kind, though extremely smalland somewhat dated.
This study measured 200words by asking a few thousand subjects to writedown a word after each of the 200 words to bemeasured.
Results are reported in tabular form,indicating which words were written down, and byhow many subjects, factored by grade level and sex.The word "doctor," for example, is reported on pp.98-100, to be most often associated with "nurse,"followed by "sick," "health," "medicine,""hospital," "man," "sickness," "lawyer," and about70 more words.4.
An Information Theoretic MeasureWe propose an alternative measure, the associationratio, for measuring word association orms, basedon the information theoretic concept of mutualinformation.
The proposed measure is moreobjective and less costly than the subjective methodemployed in \[Palermo and Jenkins (1964)\].
Theassociation ratio can be scaled up to provide robustestimates of word association norms for a largeportion of the language.
Using the association ratiomeasure, the five most associated words are (inorder): "dentists," "nurses," "treating," "treat,"and "hospitals.
"What is "mutual information"?
According to \[Fano(1961), p. 28\], if two points (words), x and y, haveprobabilities P(x) and P(y),  then their mutualinformation, l(x,y), is defined to bel(x,y) - Io- P(x,y) s2 P(x) P(y)Informally, mutual information compares the prob-ability of observing x and y together (the jointprobability) with the probabilities of observing x andy independently (chance).
If there is a genuineassociation between x and y, then the jointprobability P(x,y) will be much larger than chanceP(x) P(y), and consequently l(x,y) >> 0.
Ifthere is no interesting relationship between x and y,then P(x,y) ~ P(x) P(y), and thus, I(x,y) ~- 0.If x and y are in complementary distribution, thenP(x,y) will be much less than P(x) P(y), forcingl(x,y) << O.In our application, word probabilities, P(x) andP(y), are estimated by counting the number ofobservations of x and y in a corpus, f(x) and f(y),and normalizing by N, the size of the corpus.
(Ourexamples use a number of different corpora withdifferent sizes: 15 million words for the 1987 AP77corpus, 36 million words for the 1988 AP  corpus,and 8.6 million tokens for the tagged corpus.)
Jointprobabilities, P(x,y), are estimated by counting thenumber of times that x is followed by y in a windowof w words,f,,(x,y), and normalizing by N.The window size parameter allows us to look atdifferent scales.
Smaller window sizes will identifyfixed expressions (idioms) and other relations thathold over short ranges; larger window sizes willhighlight semantic concepts and other relationshipsthat hold over larger scales.
For the remainder ofthis paper, the window size, w, will be set to 5words as a compromise; this setting is large enoughto show some of the constraints between verbs andarguments, but not so large that it would wash outconstraints that make use of strict adjacency.1Since the association ratio becomes unstable whenthe counts are very small, we will not discuss wordpairs with f(x,y) $ 5.
An improvement would makeuse of t-scores, and throw out pairs that were notsignificant.
Unfortunately, this requffes an estimateof the variance of f(x,y), which goes beyond thescope of this paper.
For the remainder of thispaper, we will adopt the simple but arbitrarythreshold, and ignore pairs with small counts.Technically, the association ratio is different frommutual information in two respects.
First, jointprobabilities are supposed to be symmetric:P(x,y) = P(y,x), and thus, mutual information isalso symmetric: l(x,y)=l(y,x).
However, theassociation ratio is not symmetric, since f(x,y)encodes linear precedence.
(Recall that f(x,y)denotes the number of times that word x appearsbefore y in the window of w words, not the numberof times the two words appear in either order.
)Although we could fix this problem by redefiningf(x,y) to be symmetric (by averaging the matrixwith its transpose), we have decided not to do so,since order information appears to be veryinteresting.
Notice the asymmetry in the pairsbelow (computed from 36 million words of 1988 APtext), illustrating a wide variety of biases ranging1.
This definition fw(x,y) uses ?
rectangular window.
It mightbc interesting to consider alternatives (e.g., ?
triangularwindow or ?
decaying exponential) that would weight wordsless and less as they are separated by more and more words.f rom sexism to syntax.Asymmetry  in 1988 AP Corpus  ('N ffi 36 million)x y fix,y) fly, x)doctors nurses 81 10man woman 209 42doctors lawyers 25 16bread butter 14 0save life 106 8save money 155 8save from 144 16supposed to 982 21Secondly, one might expect f(x,y)<-f(x) andf(x,y) ~f(y), but the way we have been counting,this needn't be the case if x and y happen to appearseveral times in the window.
For example, giventhe sentence, "L ibrary workers were prohibitedfrom saving books from this heap of ruins,"  whichappeared in an AP story on Apri l  l ,  1988,f (prohibited) ffi 1 and f(prohibited,  f rom)  ffi 2.This problem can he fixed by dividing f (x ,y )  byw-  I (which has the consequence of subtractingIog2(w-  l) -- 2 from our association ratioscores).
This adjustment has the additional benefitof assuring that ~ f(x,y) ffi ~ f(x)ffi ~ f (y ) f f i  N.When l (x ,y )  is large, the association ratio producesvery credible results not unlike those reported in~a lermo and Jenkins (1964)\], as il lustrated in thetabl~ below.
In contrast,  when l (x ,y )  ~ 0, the pairsless interesting.
(As a very rough rule of thumb, wehave observed that pairs with l ( x ,y )  > 3 tend to beinteresting, and pairs with smaller l (x ,y )  aregenerally not.
One can make this statement preciseby calibrating the measure with subjective measures.Alternatively, one could make estimates of thevariance and then make statements about confidencelevels, e.g., with 95% confidence, P(x ,y )  >P(x) P(y ) .
)Some Interest ing Associat ions with "Doctor"in the 1987 AP  Corpus  (N = 15 minion)I(x, y) fix, y) fix) x fly) y11.3 12 111 honorary 621 doctor11.3 8 1105 doctors 44 dentists10.7 30 1105 doctors 241 nurses9.4 8 1105 do~ors 154 treating9.0 6 275 examined 621 doctor8.9 11 1105 doctors 317 treat8.7 25 621 doctor 1407 bills8.7 6 621 doctor 350 visits8.6 19 1105 doctors 676 hospitals8.4 6 241 nurses 1105 doctors78Some Un- interesttng Associat ions with "Doctor"0.96 6 621 doctor 73785 with0.95 41 284690 a 1105 doctors0.93 12 84716 is 1105 doctorsI f  l (x ,y )  < < 0, we would predict that x and y are incomplementary distribution.
However,  we arerarely able to Observe l ( x ,y )<<O because ourcorpora are too small (and our measurementtechniques are too crude).
Suppose, for example,that both x and y appear about i0 times per millionwords of text.
Then, P(x)=P(y)=iO -s andchance is P(x)P(x)ffi tO -l?.
Thus, to say thatl(x,y) is much less than 0, we need to say thatP(x,y) is much less than 10-~?
a statement that ishard to make with much confidence given the size ofpresently available corpora.
In fact, we cannot(easily) observe a probabil ity less than1/N = 10 -7 ,  and therefore,  it is hard to know ffl(x,y) is much less than chance or not, unlesschance is very large.
(In fact, the pair (a, doctors)above, appears significantly less often than chance.But to justify this statement, we need to compensatefor the window size (which shifts the scoredownward by 2.0, e.g.
from 0.96 down to - 1.04)and we need to estimate the standard deviation,using a method such as \[Good (1953)\].)5.
Lexico-$yntactic RegularitiesAlthough the psycholinguistic l iterature documentsthe significance of noun/noun word associations suchas doctor/nurse in considerable detail, relatively littleis said about associations among verbs, functionwords,  adjectives, and other non-nouns.
In additionto identifying semantic relations of the doctor/nursevariety, we believe the association ratio can also beused to search for interesting lexico-syntacticrelationships between verbs and typicalarguments/adjuncts.
The proposed association ratiocan be viewed as a formalization of Sinciair'sargument:"How common are the phrasal verbs with set7 Set isparticularly rich in making combinations with words likeabout, in, up, out, on, off, and these words are themselvesvery common.
How likely is set off to occur?
Both arefrequent words; \[set occurs approximately 250 times in amillion words and\] off occurs approximately 556 times in amillion words... IT\]he question we are asking can beroughly rephrased as follows: how Likely is off to occurimmediately after set?
...
This is 0.00025x0.00055\[P(x) P(y)\], which gives us the tiny figure of 0.0000001375...
The assumption behind this calculation is that the wordsare distributed at random in a text \[at chance, in ourterminology\].
It is obvious to a linguist that this is not so,and a cough measure of how much set and off attract eachother is to cumpare the probability with what actuallyhappens... $~ off o~urs nearly 70 times in the 7.3 millionword corpus \[P(x,y)-70/(7.3 106) >> P(x) P(y)\].That is enough to show its main patterning and it suggeststhat in currently-held corpora there will be found sufficientevidence for the desc~'iption of a substantial collection ofphrases... \[Sinclair (1987)?.
pp.
151-152\]It happens that set ... offwas found 177 times in the1987 AP Corpus of approximately 15 million words,about the same number of occurrences per million asSinclair found in his (mainly British) corpus.Quantitatively, l ( se t ,o f f )  = 5.9982, indicating thatthe probability of set ... of f  is almost 64 timesgreater than chance.
This association is relativelystrong; the other particles that Sincliir mentionshave association ratios of: about (1.4), in (2.9), up(6.9), out (4.5), on (3.3) in the 1987 AP Corpus.As Sinclair suggests, the approach is well suited foridentifying phrasal verbs.
However, phrasal verbsinvolving the preposition to raise an interestingproblem because of the possible confusion with theinfinitive marker to.
We have found that if we firsttag every word in the corpus with a part of speechusing a method such as \[Church (1988)\], and thenmeasure associations between tagged words, we canidentify interesting contrasts between verbsassociated with a following preposition to~in andverbs associated with a following infinitive markerto~to.
(Part of speech notation is borrowed from\[Francis and Kucera (1982)\]; in = preposition; to =infinitive marker; vb = bare verb; vbg = verb +ins; vbd = verb + ed; vbz = verb + s; vbn = verb+ en.)
The association ratio identifies quite anumber of verbs associated in an interesting waywith to; restricting our attention to pairs with ascore of 3.0 or more, there are 768 verbs associatedwith the preposition to~in and 551 verbs with theinfinitive marker to~to.
The ten verbs found to bemost associated before to~in are:?
to~in: alluding/vbg, adhere/vb, amounted/vbn, re-lating/vbg, amounting/vbg, revert/vb, re-verted/vbn, resorting/vbg, relegated/vbn?
to~to: obligated/vbn, trying/vbg, compened/vbn,enables/vbz, supposed/vbn, intends/vbz, vow-ing/vbg, tried/vbd, enabling/vbg, tends/vbz,tend/vb, intend/vb, tries/vbzThus, we see there is considerable leverage to begained by preprocessing the corpus and manipulatingthe inventory of tokens.
For measuring syntacticconstraints, it may be useful to include some part ofspeech information and to exclude much of theinternal structure of noun phrases.
For otherpurposes, it may be helpful to tag items and/orphrases with semantic libels such as *person*,*place*, *time*, *body-part*, *bad*, etc.
Hindle(personal communication) has found it helpful topreprocess the input with the Fidditch parser ~I-.Iindle(1983a,b)\] in order to identify associations betweenverbs and arguments, and postulate semantic lassesfor nouns on this basis.6.
Applications in LexicographyLarge machine-readable corpora are only just nowbecoming available to lexicographers.
Up to now,lexicographers have been reliant either on citationscollected by human readers, which introduced anelement of selectivity and so inevitably distortion(rare words and uses were collected but commonuses of common words were not), or on smallcorpora of only a million words or so, which arereliably informative for only the most common usesof the few most frequent words of English.
(Amillion-word corpus such as the Brown Corpus isreliable, roughly, for only some uses of only some ofthe forms of around 4000 dictionary entries.
Butstandard dictionaries typically contain twenty timesthis number of entries.
)The computational tools available for studyingmachine-readable corpora are at present still ratherprimitive.
There are concordancing programs (seeFigure 1 at the end of this paper), which arebasically KWIC (key word in context \[Aho,Kernighan, and Weinberger (1988), p. 122\]) indexeswith additional features uch as the ability to extendthe context, sort leftwards as well as rightwards,and so on.
There is very little interactive software.In a typical skuation in the lexicography of the1980s, a lexicographer is given the concordances fora word, marks up the printout with colored pens inorder to identify the salient senses, and then writessyntactic descriptions and definitions.Although this technology is a great improvement onusing human readers to collect boxes of citationindex cards (the method Murray used inconstructing the Oxford English Dictionary acentury ago), it works well if there are no morethan a few dozen concordance lines for a word, andonly two or three main sense divisions.
Inanalyzing a complex word such as "take", "save",or "from", the lexicographer is trying to pick outsignificant patterns and subtle distinctions that areburied in literally thousands of concordance lines:pages and pages of computer printout.
The unaidedhuman mind simply cannot discover all thesignificant patterns, let alne group them and rankin order of importance.The AP 1987 concordance to "save" is many pages79long; there are 666 lines for the base form alone,and many more for the inflected forms "saved,""saves," saving," and "savings."
In the discussionthat follows, we shall, for the sake of simplicity, notanalyze the inflected forms and we shall only look atthe patterns to the right of "save".Words Often Co.Occurring to the right of "save"l(x, y) fix, y) fix) x f(y) y9.5 6 724 save ' 170 forests9.4 6 724 save 180 $1.28.8 37 724 save 1697 lives8.7 6 724 save 301 enormous8.3 7 724 save 447 annually7.7 20 724 save 2001 jobs7.6 64 724 save 6776 money7.2 36 724 save 4875 life6.6 g 724 save 1668 dollars6.4 7 724 save 1719 costs6.4 6 724 save 1481 thousands6.2 9 724 save 2590 face5.7 6 724 save 2311 son5.7 6 724 save 2387 estimated5.5 7 724 save 3141 your5.5 24 724 save 10880 billion5.3 39 724 save 20846 million5.2 8 724 save 4398 us5.1 6 724 save 3513 less5.0 7 724 save 4590 own4.6 7 724 save 5798 world4.6 7 724 save 6028 my4.6 15 724 save 13010 them4.5 8 724 save 7434 country4.4 15 724 save 14296 time4.4 64 724 save 61262 from4.3 23 724 save 23258 more4.2 25 724 save 27367 their4.
I 8 724 save 9249 company4.1 6 724 save 7114 monthIt is hard to know what is important in such aconcordance and what is not.
For example,although it is easy to see from the concordanceselection in Figure 1 that the word "to" often comesbefore "save" and the word "the" often comes after"save," it is hard to say from examination of aconcordance alone whether either or both of theseco-occurrences have any significance.Two examples will be illustrate how the associationratio measure helps make the analysis both quickerand more accurate.806.1 F.xamp/e 1: "save ... from"The association ratios (above) show that associationnorms apply to function words as well as contentwords.
For example, one of the words significantlyassociated with "save" is "from".
Manydictionaries, for example Merriam-Webster's Ninth,make no explicit mention of "from" in the entry for"save", although British learners' dictionaries domake specific mention of "from" in connection with"save".
These learners' dictionaries pay moreattention to language structure and collocation thando American collegiate dictionaries, andlexicographers trained in the British tradition areoften fairly skilled at spotting these generalizations.However, teasing out such facts, and distinguishingtrue intuitions from false intuitions takes a lot oftime and hard work, and there is a high probabilityof inconsistencies and omissions.Which other verbs typically associate with "from,"and where does "save" rank in such a list?
Theassociation ratio identified 1530 words that areassociated with "from"; 911 of them were tagged asverbs.
The first I00 verbs are:refi'aJn/vb, gleaned/vii, stems/vbz, stemmed/vbd, stem-mins/vbg, renging/vbg, stemmed/vii, ranged/vii,derived/vii, reng~/vbd, extort/vb, gradu|ted/vbd, bar-red/vii, benefltiag/vbg, benefmect/vii, benefited/vii, ex-?used/vbd, m'hing/vbg, range/vb, exempts/vbz, suffers/vbz,exemptingtvbg, benefited/vbd, In.evented/vbd (7.0), seep-ins/vbs, btrted/vbd, tnevents/vbz, suffering/vbs, ex-e.laded/vii, mtrks/vbz, pmfitin~vbs, recoverins/vbg, dis-charged/vii, reboundins/vbg, vary/vb, exempted/vbn,~te /vb ,  blmished/vii, withdrawing/vbg, ferry/vb, pre-vented/vii, pmfit/vb, bar/vb, excused/vii, bars/vbz, bene-fit/vb, emerget/vbz, em~se/vb, vm'tes/vbz, differ/vb, re-moved/vim, exemln/vb, expened/vbn, withdraw/vb, stem/vb,separated/vii, judging/vbg, adapted/vbn, escapins/vbs, in-herited/vii, differed/vbd, emerged/vbd, withheld/vbd,kaked/vbn, strip/vb, i~mlting/vbs, discouruge/vb, I~'e-vent/vb, withdrew/vbd, pmhibits/vbz, borrowing/vbg , pre-venting/vbg, prohibit/vb, resulted/vbd (6.0), predude/vb, di-vert/vb, distin~hh/vb, pulled/vbn, fell/vbn, varied/vbn,emerging/vbs, suHe~r/vb, prohibiting/vbg, extract/vb, sub-U'act/vb, remverA, b paralyzed/vii, stole/vbd, departing/vbs,escaped/vii, l~ohibited/vbn, forbid/vb, evacuated/vii,reap/vb, barring/vbg, removing/vbg, stolen/vii, receives/vbz.
"Save ... from" is a good example for illustratingthe advantages of the association ratio.
Save isranked 319th in this list, indicating that theassociation is modest, strong enough to be important(21 times more likely than chance), but not sostrong that it would pop out at us in a concordance,or that it would be one of the first things to come tomind.If the dictionary is going to list "save ... from,"then, for consistency's sake, it ought to considerlisting all of the more important associations as well.Of the 27 bare verbs (tagged 'vb3 in the list above,all but 7 are listed in the Cobuild dictionary asoccurring with "from".
However, this dictionarydoes not note that vary, ferry, strip, divert, forbid,and reap occur with "from."
If the Cobuildlexicographers had had access to the proposedmeasure, they could possibly have obtained bettercoverage at less cost.6.2 Example 2: Identifying Semantic ClassesHaving established the relative importance of "save... from", and having noted that the two words arerarely adjacent, we would now like to speed up thelabor-intensive task of categorizing the concordancelines.
Ideally, we would like to develop a set ofsemi-automatic tools that would help a lexicographerproduce something like Figure 2, which provides anannotated summary of the 65 concordance lines for"save ... from.
''a The "save ... from" pattern occursin about 10% of the 666 concordance lines for"save.
"Traditionally, semantic categories have been onlyvaguely recognized, and to date little effort has beendevoted to a systematic classification of a largecorpus.
Lexicographers have tended to useconcordances impressionistically; semantic theorist,AI-ers, and others have concentrated on a fewinteresting examples, e.g., '*bachelor," and have notgiven much thought to how the results might bescaled up.With this concern in mind, it seems reasonable toask how well these 65 lines for "save ... from" fitin with all other uses of "save"?.
A laboriousconcordance analysis was undertaken to answer thisquestion.
When it was nearing completion, wenoticed that the tags that we were inventing tocapture the generalizations could in most cases havebeen suggested by looking at the lexical items listedin the association ratio table for "save".
Forexample, we had failed to notice the significance oftime adverbials in our analysis of "save," and no2.
The last unclassifaat line, "...save shoppers anywhere from$S0..." raises imeres~g problems.
Syntactic "chunking"shows that, in spite of its ~o-coearreaoe of "from" with"save", this line does ant belong hm'e.
An intriguing exerciw,given the lookup table we  are trying to construct, is how toguard against false inferences such u that since "shoppm's" itagged \[PERSON\], "$$0 to 5500" must here count u eitherBAD m" a LOCATION.
Accidental coincidmlces of this kinddo not have a significant effect on the measure, however,although they do secve as a reminder of the probabilisticnature of the findings.dictionary records this.
Yet it should be clear fromthe association ratio table above that "annually" and"month ''3 are commonly found with "save".
Moredetailed inspection shows that the time adverbialscorrelate interestingly with just one group of "save"objects, namely those tagged \[MONEY\].
The APwire is fuU of discussions of "saving $1.2 billion permonth"; computational lexicography should measureand record such patterns ff they are general, evenwhen traditional dictionaries do not.As another example illustrating how the associationratio tables would have helped us analyze the "save"concordance lines, we found ourselves contemplatingthe semantic tag ENV(IRONMENT) in order toanalyze lines such as:the trend toit's our turn tojoined a fight tocan we get busy tosave the forests\[ENV\]save the lake\[ENV\],save their forests\[ENV\],save the planet\[ENV\]?If we had looked at the association ratio tablesbefore labeling the 65 lines for "save ... from," wemight have noticed the very large value for "save ...forests," suggesting that there may be an importantpattern here.
In fact, this pattern probablysubsumes most of the occurrences of the "save\[ANIMAL\]" pattern noticed in Figure 2.
Thus,tables do not provide semantic tags, but theyprovide a powerful set of suggestions to thelexicographer for what needs to be accounted for inchoosing a set of semantic tags.It may be that everything said here about "save"and other words is true only of 1987 Americanjournalese.
Intuitively, however, many of thepatterns discovered seem to be good candidates forconventions of general English.
A future stepwould be to examine other more balanced corporaand test how well the patterns hold up.7.
ConcluMomWe began this paper with the psycholinguistic notion?
of word association orm, and extended that concepttoward the information theoretic def'mition ofmutual information.
This provided a precisestatistical calculation that could be applied to a very3.
The word "time" itself also occurs significantly in the table,but on clco~ examination it is clear that this use of "time"(e.g., "to save time") counts as something like a commodity orresource, not as part of a time adjunct.
Such are the pitfalls oflexicography (obvious when they are pointed out).81large corpus of text in order to produce a table ofassociations for tens of thousands of words, Wewere then able to show that the table encoded anumber of very interesting patterns ranging fromdoctor ... nurse to save ... f rom.
We finallyconcluded by showing how the patterns in theassociation ratio table might help a lexicographerorganize a concordance.In point of fact, we actually developed these resuksin basically the reverse order.
Concordance analysisis stilt extremely labor-intensive, and prone to errorsof omission.
The ways that concordances are sorteddon't adequately support current lexicographicpractice.
Despite the fact that a concordance isindexed by a single word, often lexicographersactually use a second word such as "from" or anequally common semantic concept such as a timeadverbial to decide how to categorize concordancelines.
In other words, they use two words totriangulate in on a word sense.
This triangulationapproach clusters concordance Lines together intoword senses based primarily on usage (distributionalevidence), as opposed to intuitive notions ofmeaning.
Thus, the question of what is a wordsense can be addressed with syntactic methods(symbol pushing), and need not address semantics(interpretation), even though the inventory of tagsmay appear to have semantic values.The triangulation approach requires "art ."
Howdoes the lexicographer decide which potential cutpoints are "interesting" and which are merely due tochance?
The proposed association ratio scoreprovides a practical and objective measure which isoften a fairly good approximation to the "art .
"Since the proposed measure is objective, it can beapplied in a systematic way over a large body ofmaterial, steadily improving consistency andproductivity.But on the other hand, the objective score can bemisleading.
The score takes only distributionalevidence into account.
For example, the measurefavors "set ... for" over "set ... down"; it doesn'tknow that the former is less interesting because itssemantics are compositional.
In addition, themeasure is extremely superficial; it cannot clusterwords into appropriate syntactic classes without anexplicit preprocess uch as Church's parts program"or Hindle's parser.
Neither of these preprocesses,though, can help highlight the "natural" similaritybetween ouns such as "picture" and "photograph.
"Although one might imagine a preprocess that wouldhelp in this particular case, there will probablyalways be a class of generalizations that are obvious82to an intelligent lexicographer, but lie hopelesslybeyond the objectivity of a computer.Despite these problems, the association ratio couldbe an important ool to aid the lexicographer, atherlike an index to the concordances, It can help usdecide what to look for; it provides a quicksummary of what company our words do keep.ReferencesChurch, K., (1988), "A Stochastic Pans Program and NounPhrase Parser for Unrestricted Text," Second Conference onAppU~ Natural Language Processing, Austin, Texas.Fano, R., (1961), Tranamlx~n of Information, MIT Press,Cambridge, Massechusens.Firth, J., (1957), "A Synopsis of Linguistic Theory 1930-1955" inSmdiea in l.AnguLvd?
Analysis, Philological Society, Oxford;reprinted in Palmer, F., (ed.
1968), Selected Papers Of J.R. Firth,Longman, Httlow.Pranch, W., and Kucera, H., (1982), Frequency AnalysiJ ofEnglhOt U,~&e, Houghton Mifflin Company, Boston.Good, I. J., (1953), The Population Frequemctea of Species and theF..tttnmrlan of Population Parametera, Biomelxika, Vol.
40, pp,237-264.Hanks, P. (198"0, "Definitions and Explanations," in Sinclair(1987b).Hindle, D., (1983a), "Deterministic Parsing of Syntactic Non-fluancks," ACL Proceedings.Hindle, D., (1983b), "User manual for Fidditch, a deterministicparser," Naval Research Laboratory Technical Memorandum?7590-142Hornby, A., (1948), The Advanced Learner's D/cn'onary, OxfordUnivenity Press.Kahaa, $., Pavlidis, T., and Baird, H., (1987) "On theRecognition of Printed Characters of any Font or She," IEEETransections PAMI, pp.
274-287.Meyer, D., Schvaneveldt, R.. and Ruddy, M., (1975), "Loci ofContextual Effects on Visual Word-Reoognition," i  Rabbin, P.,and Domic, S., (ads.
), Attention and Performance V, AcademicPress, London, New York, San PrantAwo.Pakn-mo, D,, and Jenkins, J., (1964) "Word Asr,~:iation Norms,"University of Minnesota Press, Minn~po~.Sine.lair, J., Hanks, P., Fox, G., Moon, R., Stock, P. (ads),(1997a), CoUtma Cobulld Engllah Language DlcrlanaW, Collins,London and Glasgow.Sinclair, J., (lgSTo), "The Nature of the Evidence," in Sinclair, J.(ed.
), Looking Up: an account of the COBUILD Project in lexicalco.orang, Collins, London and Glasgow.Figure I: Short Sample of the Concordance to "Save" from the AP 1987 Corpusrs Sunday, ~aIlins for greater economic reforms tommts.qion af~efted that " the Postai Servi~ COUldThen, she said.
the family hopes to?
out-of*work steelworker. "
because that doesn't" We suspend reality when we say we'\]\]scientists has won the first round in an effort toabout hree children in a mining town who plot toGM executives say the shutdowns willrtmant as receiver, instructed officials to try toThe package, which is tonewly elshanced image as the moderate who moved tomillion offer from chairman Victor Posner to helpafter telling a delivery-room do~or not to try toh birthday Tuesday.
cheered by those who fought toat he had formed an ellianco with Moslem rebels to" Basically we couldWe worked for a year totheir expensive rob'mrs, just like in wartime, toard of many who risked their own lives in order toWe must inct~tse the amount Americanssave China from poverty.save enormous ums of money in contracting out individual csave enough for a down payment on 8 home.save jobs, that costs jobs.
"save money by spending $10,000 in wages for a public workssave one of Egypt's great reasures, the decaying tomb of Rsave the "p i t  ponies "doomed to be slaughtered.save the automak~r $$00 milfion a year in operating costs asave the company rather than liquidate it and then declaredsave the counU3, nearly $2 billion, also includes a programsave the country.save the fmanclaliy troubled company, but said Posner sailsave the infant by inserting a tube in its throat o help isave the majestic Beaux Arts architectural masterpie~,e.save the nation from communism.save the operating costs of the Pershings and ground-launchsave the site at enormous expense to us. "
said Leveiilee.save them from drunken Yankee brawlers, "Tass  said.save those who were passengers.
"save.
"Figure 2: Some AP 1987 Concordance lines to 'save ... f rom, '  roughly sorted into categoriessave X from Y (6S concordance lines)1 save PERSON from Y (23 concordance lanes)1.1 save PERSON from BAD (19 concordance lines)( Robert DeNiro ) to save Indian Iribes\[PERSON\] from se~ocide\[DESTRUCT\[BAD\]\] at the hands of'~ We wanted to save him\[PERSON\] from undue uouble\[BAD\] and loti\[BAD\] of money,  "Murphy WLV sacriflcod to save more powerful Democrats\[PERsoN\] from harm\[BAD\] .
"God sent this man to save my five children\[PERsoN\] from being burned to death\[DESTRUCT\[BAD\]\] andPope John Paul H to " save us\[PERSON\] from sin\[BAD\] .
"1.2 save PERSON &ore (BAD) LOC(ATION) (4 concordance lines)rescoers who helped save the toddler\[pERSON\] from an abandoned weli\['LOC\] will be feted with a paradewhile attempting to save two drowning boys\[PERSON\] from a turbulent\[BAD\] creek\[LOC\] in Ohio\[LOCI2.
save INSTtTFUTION) &ore (ECON) BAD (27 concordance lines)membe~ states to help save the BEC\[INST\] from possible bankrnptcy\[BCONJ\[BAD\] this year .should be sought " to  save the company\[CORP\[lNST\]\] from bankruptey(ECON\]\[BAD\] .law was necessary to save the cuuntry\[NATION\[INST\]\] from disast~\[BAD\] .operation " to save the nafion\[NATION\[INST\]\] from Communism\[BAD\]~q3LITICAL\] ,were not needed to save the system from bankrnptcy\[ECON\]\[BAD\] .his efforts to save the world\[IN'ST\] from the likes of Lothar and the Spider Woman3.
save ANIMAL ~'om DESTRUCT(ION) (5 concordance lines)sire them the money topmgrem intended toUNCLASSIFIED (10wainut and ash trees toafter the attack to ,~.n'~t~ttes that wouldrove the dogs\[ANIMAL\] from being des~'oyed\[DESTRUCT\] ,save the slant birds(ANIMAL\] from extinction\[DESTRUCT\] ,concordance lines)save them from the axes and saws of a logging company.save the ship from a terrible\[BAD\] f ire, Navy reports concluded Thursday.save shoppers\[PERSON\] anywhese from $~O\[MONEY\] [NUMBER\] to $500\[MONEY\] \[NUMBER\]83
