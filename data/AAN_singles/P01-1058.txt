Evaluating CETEMP?blico, a free resource for PortugueseSINTEF Tele og DataPostboks 124, BlindernN-0314 Oslo, NorwayDiana.Santos@informatics.sintef.noDepartamento de Inform?ticaUniversidade do MinhoPT-4710-057 Braga, PortugalPaulo.Rocha@alfa.di.uminho.ptAbstractIn this paper we present a thoroughevaluation of a corpus resource forPortuguese, CETEMP?blico, a 180-million word newspaper corpus freefor R&D in Portuguese processing.We provide information that shouldbe useful to those using the resource,and to considerable improvement forlater versions.
In addition, we thinkthat the procedures presented can beof interest for the larger NLPcommunity, since corpus evaluationand description is unfortunately not acommon exercise. CETEMP?blico is a large corpus of EuropeanPortuguese newspaper language, available at nocost to the community dealing with theprocessing of Portuguese.1 It was created in theframework of the Computational Processing ofPortuguese project, a government fundedinitiative to foster language engineering of thePortuguese language.2Evaluating this resource, we have two maingoals in mind: To contribute to improve itsusefulness; and to suggest ways of going aboutas far as corpus evaluation is concerned ingeneral (noting that most corpora projects aresimply described and not evaluated).1CETEMP?blico stands for ?Corpus de Extractos deTextos Electr?nicos MCT / P?blico?, and its full referenceis http://cgi.portugues.mct.pt/cetempublico/2See http://www.portugues.mct.pt/In fact, and despite the amount of researchdevoted to corpus processing nowadays, there isnot much information about the actual corporabeing processed, which may lead na?ve usersand/or readers to conclude that this is not aninteresting issue.
In our opinion, that is thewrong conclusion.There is, in fact, a lot to be said about anyparticular corpus.
We believe, in addition, thatsuch information should be available when oneis buying, or even just browsing, a corpus, and itshould be taken into consideration when, in turn,systems or hypotheses are evaluated with thehelp of that corpus.In this paper, we will solely be concernedwith CETEMP?blico, but it is our belief thatsimilar kinds of information could be publishedabout different corpora.
Our intention is to givea positive contribution both to the wholecommunity involved in the processing ofPortuguese and to the particular users of thiscorpus.
At the moment of writing, 160 peoplehave ordered (and, we assume, consequentlyreceived) it3.
There have also been more thanfour thousand queries via the Web site whichgives access to the corpus.We want to provide evaluation data anddescribe how one can improve the corpus.
Weare genuinely interested in increasing its value,and have, since corpus release,4 made availablefour patches (e-mailing this information to all3Although we also made available a CQP (Christ et al,1999) encoded version in March 2001, the vast majority ofthe users received the text-only version.4The corpus was ready in July 2000; the first copies weresent out in October, with the information that version 1.0creation date was 25 July 2000.who ordered the corpus).
We have also tried toconsiderably improve the Web page.We decided to concentrate on the evaluationof version 1.0, given that massive distributionwas done of that particular version5.
Webaccess to the corpus (Santos and Bick, 2000)will not be dealt with here.
Note that all trivialimprovements described here have already beenaddressed in some patch. 	As described in detail in Rocha and Santos(2000) and also in the FAQ at the corpus Webpage, CETEMP?blico was built from the rawmaterial provided by the Portuguese dailynewspaper P?blico: text files in Macintoshformat, covering approximately the years 1991to 1998, and including both published newsarticles and those created but not necessarilybrought to print.
These files were automaticallytagged with a classification based on, but notidentical to, the one used by the newspaper toidentify sections, and with the semester thearticle was associated to.
In addition, sentenceseparation, and title and author identificationwere automatically created.
The texts were thendivided in extracts with an average length oftwo paragraphs.
These extracts were randomlyshuffled (for copyright reasons) and numbered,and the final corpus was the ordered sequenceof the extract numbers.To illustrate the corpus in text format, wepresent in Appendix A an extract that includesall possible tags with the exception of <marca>. We start by commenting on the distributionprocess, and then go on to analyse the corpuscontents and the specific options chosen in itscreation.Let us first comment on the distributionoptions.
While this resource is entirely free(one has just to register in a Web page in orderto receive the corpus at the address of one?schoice), several critical remarks are not out ofplace:5We have no estimate of how many users have actuallysucceeded, or even tried, to apply the patches madeavailable later on.
We have just launched a Webquestionnaire in order to have a better idea of our usercommunity.First of all, when publicizing the resource, itwas not clear for whom the CD distribution wasactually meant: Later on, we discovered thatmany traditional linguists ordered it just to findout that they were much better off with the on-line version.Second, more accompanying information inthe CD would not hurt, instead of pointing to aWeb page as the only source: In fact, theassumption that everyone has access to the Webwhile working with CETEMP?blico is notnecessarily true in Portugal or Brazil.Finally, we did not produce a medium-sizetechnical description; in addition to the FAQ onthe Web page, we provided only a full paper(Rocha and Santos, 2000) describing the wholeproject, arguably an overkill.About the corpus contents, severalfundamental decisions can ?
and actually have,in previous conferences or by e-mail ?
becriticized, in particular the use of a single textsource and the inclusion of sentence tags (bycriteria so far not yet documented).
Still, wethink that both are easy to defend, since 1) thetime taken in copyright handling and contractwriting with every copyright owner stronglysuggests minimizing their number.
And 2)although sentence separation is a controversialissue, it is straightforward to dispose ofsentence separation tags.
So, this option cannotreally be considered an obstacle to users.6We will concentrate instead on eachannotation, after discussing the choice of textsand extracts. Looking at the final corpus, it is evident thatmany extracts should be discarded or, at least,rewritten.
We tried to remove specific kinds of"text", namely soccer classifications, citationsfrom other newspapers, etc., but it is stillpossible to detect several other objects ofdubious interest in the resulting corpus.In fact, using regular expression patterns ofthe kind ?existence of multiple tabs in a lineending in numbers?, we identified 5270 extractshaving some form of classification, as well as662 extracts with no valid content.6Since extract definition is based on paragraph and notsentence boundary, the option of marking <s> boundarieshas no other consequences.Now, it is arguable that classifications ofother sports (e.g., athletics and motor races),solutions to crossword puzzles, film and bookreviews, and TV programming tables, just toname a few, should have been extracted on thesame grounds presented for removing soccer.Our decision was obviously based on a questionof extent.
(Soccer results are much morefrequent.)
However, we now regret thismethodological flaw and would like to clean upa little more (as done in the patches), or addback soccer results.Another problem detected, concerning theextract structure, was our unfortunate algorithmof appending titles to the previous extract, justlike authors, instead of joining them to the nextextract.
This means that 4.8% of the extractsend with a title in CETEMP?blico.
(9.6% endwith an author.
) 	The worst problem presented by theCETEMP?blico corpus is the question ofrepeated material.
(Incidentally, it is interestingto note that this is also a serious problem insearching the Web, as mentioned by Kobayashiand Takeda (1999).)
Repeated articles7 can bedue to two independent factors:- parallel editions of the local section ofthe newspaper in the two main cities ofPortugal (Lisboa and Porto)- later publication of previously ?rejected?articlesIn addition to manually inspecting rare itemsthat one would not expect to appear more than afew times in the corpus (but which had higherfrequency than expected), we used thefollowing strategies to detect repeated extracts:1.
Record the first and last 40 characters ofeach extract, in a hash table, as well as theirsize in characters.
Then fully compare onlythe repeated extracts under this criterion.2.
Using the Perl module MD5 (useful forcryptographical purposes), we attributed toeach extract a checksum of 32 bytes, andrecorded it in a hash table.
Repeatedextracts have the same checksum, but it isextremely unlikely that two different oneswill.7Repeated sentences can also occur in the lead and in thebody of an article, and (in the opinion section) to highlightparts of an article.The results obtained for exactly equalextracts are displayed in Table 1 for bothmethods.Another related (and obviously morecomplicated) problem is what to do with quasi-duplicates, i.e.
sentences or texts that arealmost, but not, identical.
An estimate of thenumber of approximately equal extracts,obtained with the 40 character-method but withrelaxed size constraints (10%) yields somefurther 15,665 possibly repeated extracts.
It isnot obvious whether one can automaticallyidentify which one is the revised version, oreven whether it is desirable to choose that one.We have, anyway, compiled a list of thesecases, thinking that they might serve as rawmaterial for studying the revision process (andto obtain a list of errors and their correction).Kind DifferentextractsExtracts toremove40chr MD5 40chr MD5twice 45,046 44,188 45,046 44,1883 times 1,493 1,401 2,986 2,8024 times 301 271 903 8135 times 68 63 272 2526-10 83 81 552 548> 11 31 31 643 880Total 47,022 46,035 50,402 49,483Table 1.
Overview of exact duplication In the CETEMP?blico corpus, newspaper titlesand subtitles, as well as author identifications,have been marked up as result of heuristicprocessing.
In Rocha and Santos (2000), apreliminary evaluation of precision and recallfor these tasks was published, but here we wantto evaluate this in a different way, withoutmaking reference to the original text files.Given the corpus, we want to addressprecision and error rate (i.e., of all chunkstagged as titles, how many have been rightlytagged?, and how many are wrong?).
Wereviewed manually the first 500 instances of<t>8, of which 427 were undoubtedly titles, afurther 4 wrongly tagged authors, and at least15 belonged to book or film reviews, indicating8In the 15th chunk of the corpus.
This aparently na?vechoice of test data does not bias evaluation, since theextracts are randomly placed in the corpus and do notreflect any order of time period or kind of text.title, author and publisher, or director andbroadcasting date, etc.We then looked into the following error-prone situation: After having noted that severalparagraphs in a row including title and authortags were usually wrong (and should have beenmarked as list items instead), we looked forextracts containing sequences of four titles /authors and manually checked 200.
Theprecision in this case was very low: Only 38%were correctly tagged.
Of the incorrect ones, asmuch as 34% were part of book reviews asdescribed above.
This indicates clearly that weshould have processed special text formats priorto applying our general heuristic rules.Regarding recall, we did the followingpartial inspection: We noted several shortsentences ending in ?
or !
(a criterion to parse atext chunk as a full sentence) that shouldactually be tagged as titles.
We therefore lookedat 200 paragraphs with one single sentenceending in question or exclamation markcontaining less than 8 words, and concludedthat 41 cases (20%) could definitively bemarked as titles, while no less than 85 of thesecases where questions taken from interviews.Most other cases were questions inside ordinaryarticles.As far as authors are concerned, the phraseLeitor devidamente identificado (?dulyidentified reader?, used to sign reader's letterswhere the writer does not wish to disclose his orher identity) was correctly identified only in78% of the cases (135 in 172).
In 17% of theoccurrences, it was wrongly tagged as title.From a list of 500 authors randomlyextracted for evaluation purposes, only 395(79%) were unambiguously so, while 8 (1.5%)could still be considered correct by somehowmore relaxed criteria.
We thus conclude that upto 21% of the author tags in the corpus may bewrongly attributed, a figure much higher thanthe originally estimated 4%.Among those cases, foreign names(generally in the context of film or musicreviews, or book presentations) were frequentlymistagged as authors of articles in P?blico, asituation highly unlikely and amenable toautomatic correction.
Figure 1 is an example.a> Contos Assombrosos </a><a> Amazing Stories </a><a> De Steven Spielberg </a><t> Com Kevin Costner, Patrick Swayze e SidCaesar  </t>Figure 1.
Wrong attribution of <a> and <t> 	In addition to paragraph separation comingfrom the original newspaper files,CETEMP?blico comes with sentenceseparation as an added-value feature.Now, sentence separation is obviously not atrivial question, and there are no foolproof rulesfor complicated cases (Nunberg, 1990;Grefenstette and Tapainanen, 1994; Santos,1998).
So, instead of trying to produce othersubjective criteria for evaluating a particularlydelicate area, we decided to look at the amountof work needed to revise the sentenceseparation for a given purpose, as reported insection 4.2.But we did some complementary searchesfor cases we would expect to be wrongwhatever the sentence separation philosophy.We thus found 6,358 sentences initiated by apunctuation mark (comma, closing quotes,period, question mark and exclamation mark,respectively amounting to 4053, 410, 1607, 227and 61 occurrences), as well as a plethora ofsuspiciously small sentences, cf.
Table 2.SentencesizeNumber ofsentencesErrorestimationone 14,783 100%two 55,121 53%three 70,909 20%Table 2.
Too small sentencesSentence separation marks some sentencesas fragments (<s frag>); in addition, the <li>attribute was used to render list elements.
Weare not sure now whether it was worthwhile tohave two different markup elements.<s frag> 63,122<li> 113,540<t> 687,720<a> 263,269Table 3.
Number of cases of non-standard <s>Finally, the sentence separation module alsointroduces the <marca> tag to identify meta-characters that are used for later coreference(eg.
in footnotes).
The asterisk "*" was markedas such in CETEMP?blico, but not insideauthor or title descriptions, an undesirableinconsistency.  	An annoying detail is the amount of strangecharacters that have remained in the corpusafter font conversion, such as non-Portuguesecharacters, hyphens, bullet list marking, and thecharacters < > instead of quotes.It is straightforward to replace these withother ISO-8859-1 characters or combinations ofcharacters, as was done with dashes andquotes.9 Only the last line of Table 4 requiressome care, since ?
is a otherwise validPortuguese character that should only bereplaced a few times.Character Action Number?
non-breaking hyphen 856?
use oe 246tab stop remove/replace by " " 50,312control character eliminate extract 53,631character 0x95 (?)
40,665< use &lt; 1,283> use &gt; 1,232?
replace by ... 3,167Table 4.
Occurrence of extraneous chars! 		CETEMP?blico extracts come with a subjectclassification derived from (but not equal to)the original newspaper section.
Due to formatdifferences of the original files, only 86% of theextracts have some classification associated.The others carry the label ND (not determined).We evaluate here this classification, sincefor half of the corpus article separation had tobe carried out automatically and thus chancesexist that errors may have crept in.The first thing we did was to check whetherrepeated extracts had been attributed the sameclassification.
Astonishingly, there were manydifferences: of the 47,002 cases of multipleextracts, 10,872 (23%) had different categories,even though only in 2% of the cases none of theconflicting categories was ND.Another experiment was to look at well-known polysemic or ambiguous items and seewhether their meaning correlated with the kindof text it was purported to be in.
We thusinspected manually several thousandconcordances dealing with the following middlefrequency words10: 201 occurrences of vassoura9Note that it is not always possible to have a one-to-onemapping from MacRoman into ISO-8859-1.10Glosses provided are not exhaustive.
(broom; last vehicle in a bicycle race); 124 ofpassador (sieve; drug seller; emigrant dealer);314 of cunha (wooden object; corruptiondevice); 599 of coxa (noun thigh; adjectivelame); 205 of prego (nail; meat sandwich;pawnshop); 145 of garfo (fork; biking); 5505 ofestrela (star; filmstar; success); 375 ofdobragem (folding; dubbing; parachuting andF1 term); 573 of escravatura (slavery).We could only find two cases of firmdisagreement with source classification (in thetwo last mentioned queries).
This is not such agood result as it seems, though, since it can beargued that subject classification is too highlevel (society, politics, culture) to allow fordefinite results. "		The best way to evaluate a corpus resource is tosee how well it fares regarding the tasks it is putto.
We will not evaluate concordancing forhuman inspection, because we assume that thisis a rather straightforward task for whichCETEMP?blico is useful, especially because itrequires direct scrutiny.
Obviously, humaninspection and judgement make the resultsmore robust.#One of the authors developed proper nameidentification tools (Santos, 1999) prior to theexistence of CETEMP?blico.
We ran them onthis corpus to see how they worked.We proceeded in the following way: Weinspected manually the first 1,000 proper namesobtained from CETEMP?blico and got less then4% wrong, i.e., over 96% precision.Size NumberOne word 26,518Two words 15,512Two words and de 4,623Three words 2,132Three words and de 2,354Four words 201Four words and de 583>= five words 359problems 11 383Table 5.
Size distribution of proper nouns11This category encompasses ?deviant?
proper names,mainly including foreign accents and numbers,irrespective of proper name length.Then, we computed the distribution of the52,665 proper nouns identified by the program(23,401 types) on the first million words of thecorpus as shown in Table 5, and inspectedmanually those 1,017 having a length larger orequal than four words.
Of these 88% werecorrect and 6.5% were plainly wrong.
Cases ofmerging two proper names and cases where itwas easy to guess one missing (preceding orfollowing) word accounted each forapproximately 5% of the remaining instances.While use of CETEMP?blico allowed us touncover cases not catered for by the program, italso illuminated some potential12 tokenizationproblems in the corpus, namely a large quantityof tokens ending in a dash (21,455 tokens,6,458 types) or in a slash (7313 tokens, 4530types), as well as up to 132,455 tokensincluding one single parenthesis (28,466 types). $%$&The first million words of CETEMP?blico wasselected for the creation of a treebank forPortuguese (Floresta Sint?
(c)tica13), given thatits use is copyright cleared and the corpus isfree.The treebank team engaged in a manualrevision of the text prior to treebank coding,refining sentence separation with the help ofsyntactically-based criteria (Afonso andMarchi, 2001).
We have tried to compute theamount of change produced by humanintervention, which turned out to be asurprisingly complex task (Santos, 2001).This one million words subcorpus contained8,043 extracts.14 Assuming that the first millionis not different from the rest of the corpus, theresults indicate an estimate of 17% of thecorpus extracts in need of improvement.Looking at sentences, 2,977 sentences of the42,026 original ones had to be re-separated into4,304 of the resulting 43,271.
Table 6 displaysan estimate of what was actually involved in therevision of sentence tags (percentages arerelative to the original number of sentences).12Different tokenizers may have different strategies, butwe assume that these will be hard cases for most.13See http://cgi.portugues.mct.pt/treebank/.14Numbered from 1 to 8067, since version 1.2 was used,and therefore 24 invalid extracts had been alreadyremoved.
In addition, the treebank reviewers consideredthat further 129 should be taken out.The "Other" category includes changes amongthe tags <t>, <a>, <li> and <s>.<s>-addition 1,481-1,872 3.52-4.24%<s>-removal 612-115 1.46-2.65%Other 550 1.3%Table 6.
Revision of <s> tags &%One of the first and most direct uses of a largecorpus is to study the coverage, evaluate, andespecially improve a spelling checker andmorphological analyser.Our preliminary results of evaluating Jspell(Almeida and Pinto, 1994) as far as type andtoken spelling is concerned are as follows:Among the 942,980 types of CETEMP?blico,574,199 were not recognized by the currentversion of Jspell (60.4%), amounting to 3.07%of the size of the corpus.
A superficialcomparison showed that CETEMP?blicocontains a higher percentage of unrecognizedwords, both types and tokens, than otherPortuguese newspaper corpora.
Numbers for a1.5-million word corpus of Di?rio do Minho (aregional newspaper) and for a 4-million wordcorpus of a political party newspaper arerespectively 26.5% and 25.41% unrecognizedtypes and 2.26% and 1.67% unrecognizedtokens.
These numbers may be partiallyexplained by P?blico?s higher coverage ofinternational affairs, together with its cinemaand music sections, both bringing an increase inforeign proper names15.Description Tokens TypesForeign first names 130 125Portuguese first names 19 16Foreign surnames 216 208Portuguese surnames 35 34Foreign organizations 50 45Portuguese organizations 26 23Foreign geographical16 48 48Portuguese geographic 28 28acronyms 81 77foreign words 171 161Portuguese foreign words17 26 2515The percentage of unrecognized tokens varies from4.8% for culture to 2.0% for society extracts.16We classify as Portuguese or foreign the word, not thelocation: thus, Tanz?nia is a Portuguese word.17That is, words routinely used in Portuguese but whichup to now have kept a distinctly foreign spelling, such aspullover.words missing in dict.
101 98incorrectly spelled18 36 36others 33 32total 1,000 956Table 7.
Distribution of ?errors?We investigated the ?errors?
found by thesystem, to see how many were real and howmany were due to a defficient lexical (or rule)coverage.
Table 7 shows the distribution of1,000 ?errors?
randomly obtained from the 12thcorpus chunk.The absolute frequencies of the mostcommon spelling errors in CETEMP?blico isanother interesting evaluation parameter.Applying Jspell to types with frequency > 100(excluding capitalized and hyphenated words),we identified manually the ?real?
errors.Strikingly, all involved lack or excess ofaccents.
The most frequent appeared 840 times(ju?z), the second one (sa?u) 659, and the third(imp?r) had 637 occurrences.
Their correctlyspelled variants (juiz, saiu, impor) appearedrespectively 11896, 9892 and 5125 times. "#	'One can find excellent reports on thedifficulties encountered in creating corpora (seee.g.
Armstrong et al (1998) and referencestherein), but it is significantly rarer to get anevaluation of the resulting objects.
It is thus noteasy to compare CETEMP?blico with othercorpora on the issues discussed here.For example, it was not easy to find athorough documentation of BNC19 problems(although there is a mailing list and a specific e-mail address to report bugs), nor is similarinformation to be found in distributionagencies?
(such as LDC or ELRA) Web sites.It is obviously outside the scope of thepresent paper to do a thorough analysis of othercorpora as well, but our previous experienceshows that it is not at all uncommon toexperience problems with characters and fonts,repeated texts or sentences, rubbish-likesections, wrong markup and/or lack of it.
Allthis independently of corpora being paid and/ordistributed by agencies supposed to have18Including one case of lack of space between two words,suacontribui?
?o.19British National Corpus.
http://info.ox.ac.uk/bnc/performed validation checks.
The same happensfor corpora that have been manually revised.As regards sentence separation, Johansson etal.
(1996) mention that proofreading of theautomatic insertion of <s>-units was necessaryfor the ENPC corpus, but they do not reportproblems of human editors in deciding what an<s> should be.
Let us, however, note that ENPCcompilers were free to use an <omit> tag forcomplicated cases and, last but not least, werenot dealing with newspaper text.
! "&#%This paper can be read from a user?s angle as acomplement to the documentation of theCETEMP?blico corpus.
In addition, byshowing several simple forms of evaluating acorpus resource, we hope to have inspiredothers to do the same for other corpora.While the work described in this paperalready allowed us to publish several patches,improve our corpus processing library andcontribute to new versions of other people?sprograms, namely Jspell, our future plans are todo more extensive testing using more powerfultechniques (e.g.
statistical) to investigate otherproblems or features of the corpus.
In any case,we believe that the work reported in this papercomes logically first.AcknowledgementsWe are first of all grateful to the P?bliconewspaper (especially Jos?
V?tor Malheiros, theresponsible for the online edition) for makingthis resource possible.
We thank Jos?
Jo?o Diasde Almeida for several suggestions, the team ofFloresta Sint?
(c)tica for their thorough revisionof the first million words, Stefan Evert forinvaluable CQP support, and Jan Engh forhelpful comments.ReferencesSusana Cavadas Afonso and Ana Raquel Marchi.2001.
Crit?rios de separa?
?o de senten?as/frases,cgi.portugues.mct.pt/treebank/CriteriosSeparacao.htmlJ.J.
Almeida and Ulisses Pinto.
1994.
Jspell ?
umm?dulo para an?lise l?xica gen?rica de linguagemnatural.
  	     (?vora, 1994),www.di.uminho.pt/~jj/pln/jspell1.ps.gz.Susan Armstrong, Masja Kempen, David McKelvie,Dominique Petitpierre, Reinhard Rapp, andHenry S. Thompson.
1998.
Multilingual Corporafor Cooperation.
In Antonio Rubio et al (eds.
),        (Granada, 28-30 May 1998), Vol.
2,pp.975-80.Oliver Christ, Bruno M. Schulze, Anja Hofmann andEsther Koenig.
1999.
The IMS CorpusWorkbench: Corpus Query Processor (CQP):User?s Manual, Institute for Natural LanguageProcessing, University of Stuttgarthttp://www.ims.uni-stuttgart.de/projekte/CorpusWorkbench/CQPUserManualGregory Grefenstette and Pasi Tapanainen.
1994.What is a word, What is a sentence?
Problems ofTokenization.
    	  	 ! "#	$%&'()*, pp.
79-87Stig Johansson, Jarle Ebeling and Knut Hofland.1996.
Coding and aligning the English-Norwegian Parallel Corpus.
In Karin Aijmer,Bengt Altenberg & Mats Johansson (eds.
),  	+   ,"   !-. 	-,#/)-0%1(()*, Lund UniversityPress, pp.87-112.Mei Kobayashi and Koichi Takeda.
1999.Information retrieval on the web: Selected topics.IBM Research, Tokyo Research Laboratory, IBMJapan, Dec. 16, 1999.Geoffrey Nunberg.
1990.
  .
CSLI Lecture Notes, Number 18.Paulo Alexandre Rocha and Diana Santos.
2000.CETEMP?blico: Um corpus de grandesdimens?es de linguagem jornal?stica portuguesa.In Gra?a Nunes (ed.
),2       #$$34555*,(S?o Paulo, 19-22 November 2000), pp.131-140.Diana Santos.
1998.
Punctuation and multilinguality:Reflections from a language engineeringperspective.
In Jo Terje Ydstie and Anne C.Wolleb?k (eds.
), 67      4/98.
Oslo: Department of Linguistics,Faculty of Arts, University of Oslo, pp.138-60.Diana Santos.
1999.
Compara?
?o de corpora emportugu?s: algumas experi?ncias.www.portugues.mct.pt/Diana/download/CCP.psDiana Santos.
2001.
Resultado da revis?o doprimeiro milh?o de palavras do CETEMP?blico cgi.portugues.mct.pt/treebank/RevisaoMilhao.htmlDiana Santos and Eckhard Bick.
2000.
ProvidingInternet access to Portuguese corpora: the AC/DCproject.
In Maria Gavriladou et al (eds.
),   ,     / 	4555 (Athens, 31 May-2 June2000), pp.205-210.Appendix A.
Example of an extract<ext n=1914 sec=nd sem=93b><p> <s>Produ?
?o da Hammer.</s><s>Um epis?dio da II GuerraMundial, um caso de hero?smo,quando toda uma companhia ?destru?da no Norte de ?frica.</s></p><li>THE STEEL BAYONET de MichaelCarreras com Leo Glenn e KieronMoore</li><li>Gr?-Bretanha, 1957, 82 min</li><li>Canal 1, ?s 15h15</li><p><s>Um ex-presidi?rioesfor?adamente em busca deregenera?
?o (Nicolas Cage) e amulher, uma honesta e voluntariosapol?cia (Holly Hunter), queremformar fam?lia mas descobrem quen?o podem ter filhos e decidemraptar um beb?.</s><s>O cinema dos irm?os Coen sempreatraiu cr?ticas de ?exibicionismo?e ?fogo-de-artif?cio?.</s><s>Esta com?dia desbragada, que deuma s?
vez faz um curto-circuitocom as refer?ncias ?
bandadesenhada, ao burlesco ou ?
s?rie?Mad Max?, ?
o tipo de objecto quemais evidencia o que os detractoresdos Coen considerar?o um ?exerc?ciode estilo?.</s><s>?Arizona Junior?, concorde-se, ?uma obra que exibe um gozo evidentepelas proezas do trabalho de c?marae Nicolas Cage, Holly Hunter ouJohn Goodman t?m a consist?ncia defiguras de cart?o.</s><s>Mas nem por isso se deve ignorarestarmos perante um dos universosmais paran?icos do cinemaactual.</s> </p><t>RAISING ARIZONA de Joel Coen comNicolas Cage, Holly Hunter e JohnGoodman</t><t>EUA, 1987, 97 min</t><a>Quatro, ?s 21h35</a> </ext>
