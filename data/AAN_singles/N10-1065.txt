Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 420?428,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEverybody loves a rich cousin: An empirical study of transliteration throughbridge languagesMitesh M. KhapraIndian Institute of TechnologyBombay,Powai, Mumbai 400076,Indiamiteshk@cse.iitb.ac.inA KumaranMicrosoft Research India,Bangalore,Indiaa.kumaran@microsoft.comPushpak BhattacharyyaIndian Institute of TechnologyBombay,Powai, Mumbai 400076,Indiapb@cse.iitb.ac.inAbstractMost state of the art approaches for machinetransliteration are data driven and require sig-nificant parallel names corpora between lan-guages.
As a result, developing translitera-tion functionality among n languages couldbe a resource intensive task requiring paral-lel names corpora in the order of nC2.
In thispaper, we explore ways of reducing this highresource requirement by leveraging the avail-able parallel data between subsets of the n lan-guages, transitively.
We propose, and showempirically, that reasonable quality transliter-ation engines may be developed between twolanguages, X and Y , even when no direct par-allel names data exists between them, but onlytransitively through language Z .
Such sys-tems alleviate the need for O(nC2) corpora,significantly.
In addition we show that the per-formance of such transitive transliteration sys-tems is in par with direct transliteration sys-tems, in practical applications, such as CLIRsystems.1 IntroductionNames and Out Of Vocabulary (OOV) terms appearvery frequently in written and spoken text and henceplay a very important role in several Natural Lan-guage Processing applications.
Several studies haveshown that handling names correctly across lan-guages can significantly improve the performance ofCLIR Systems (Mandl and Womser-Hacker, 2004)and the utility of machine translation systems.
Thefact that translation lexicons or even statistical dic-tionaries derived from parallel data do not provide agood coverage of name and OOV translations, un-derscores the need for good transliteration enginesto transform them between the language.The importance of machine transliteration, in theabove context, is well realized by the research com-munity and several approaches have been proposedto solve the problem.
However, most state of the artapproaches are data driven and require significantparallel names corpora between languages.
Suchdata may not always be available between every pairof languages, thereby limiting our ability to supporttransliteration functionality between many languagepairs, and subsequently information access betweenlanguages.
For example, let us consider a practi-cal scenario where we have six languages from fourdifferent language families as shown in Figure 1.The nodes in the graph represent languages and theedges indicate the availability of data between thatlanguage pair and thus the availability of a MachineTransliteration system for that pair.
It is easy to seethe underlying characteristics of the graph.
Data isavailable between a language pair due to one of thefollowing three reasons:Politically related languages: Due to the politicaldominance of English it is easy to obtain parallelnames data between English and most languages.Genealogically related languages: Arabic and He-brew share a common origin and there is a signifi-cant overlap between their phoneme and graphemeinventory.
It is easy to obtain parallel names databetween these two languages.Demographically related languages: Hindi andKannada are languages spoken in the Indian sub-continent, though they are from different languagefamilies.
However, due to the shared culture and de-mographics, it is easy to create parallel names databetween these two languages.420Figure 1: A connected graph of languagesOn the other hand, for politically, demographi-cally and genealogically unrelated languages suchas, say, Hindi and Hebrew, parallel data is not readilyavailable, either due to the unavailability of skilledbilingual speakers.
Even the argument of usingWikipedia resources for such creation of such par-allel data does not hold good, as the amount of inter-linking may be very small to yield data.
For exam-ple, only 800 name pairs between Hindi and Hebrewwere mined using a state of the art mining algorithm(Udupa et al, 2009), from Wikipedia interwiki links.We propose a methodology to develop a practi-cal Machine Transliteration system between any twonodes of the above graph, provided a two-step pathexists between them.
That is, even when no paralleldata exists between X & Y but sufficient data existsbetween X & Z and Z & Y it is still possible to de-velop transliteration functionality between X & Yby combining a X ?
Z system with a Z ?
Ysystem.
For example, given the graph of Figure 1,we explore the possibility of developing translitera-tion functionality between Hindi and Russian eventhough no direct data is available between these twolanguages.
Further, we show that in many cases thebridge language can be suitably selected to ensureoptimal MT accuracy.To establish the practicality and utility of our ap-proach we integrated such a bridge transliterationsystem with a standard CLIR system and comparedits performance with that of a direct transliterationsystem.
We observed that such a bridge systemperforms well in practice and in specific instancesresults in improvement in CLIR performance overa baseline system further strengthening our claimsthat such bridge systems are good practical solutionsfor alleviating the resource scarcity problem.To summarize, our main contributions in this pa-per are:1.
Constructing bridge transliteration systems andestablishing empirically their quality.2.
Demonstrating their utility in providing prac-tical transliteration functionality between twolanguages X & Y with no direct parallel databetween them.3.
Demonstrating that in specific cases it is pos-sible to select the bridge language so that op-timal Machine Transliteration accuracy is en-sured while stepping through the bridge lan-guage.1.1 Organization of the PaperThis paper is organized in the following manner.
Insection 2 we present the related work and highlightthe lack of work on transliteration in resource scarcescenarios.
In section 3 we discuss the methodologyof bridge transliteration.
Section 4 discusses the ex-periments and datasets used.
Section 4.3 discussesthe results and error analysis.
Section 5 discusses or-thographic characteristics to be considered while se-lecting the bridge language.
Section 6 demonstratesthe effectiveness of such bridge systems in a practi-cal scenario, viz., Cross Language Information Re-trieval.
Section 7 concludes the paper, highlightingfuture research issues.2 Related WorkCurrent models for transliteration can be classi-fied as grapheme-based, phoneme-based and hy-brid models.
Grapheme-based models, such as,Source Channel Model (Lee and Choi, 1998), Max-imum Entropy Model (Goto et al, 2003), Condi-tional Random Fields (Veeravalli et al, 2008) andDecision Trees (Kang and Choi, 2000) treat translit-eration as an orthographic process and try to mapthe source language graphemes directly to the tar-get language graphemes.
Phoneme based models,such as, the ones based on Weighted Finite State421Transducers (WFST) (Knight and Graehl, 1997)and extended Markov window (Jung et al, 2000)treat transliteration as a phonetic process rather thanan orthographic process.
Under such frameworks,transliteration is treated as a conversion from sourcegrapheme to source phoneme followed by a conver-sion from source phoneme to target grapheme.
Hy-brid models either use a combination of a graphemebased model and a phoneme based model (Stallsand Knight, 1998) or capture the correspondence be-tween source graphemes and source phonemes toproduce target language graphemes (Oh and Choi,2002).A significant shortcoming of all the previousworks was that none of them addressed the issue ofperforming transliteration in a resource scarce sce-nario, as there was always an implicit assumptionof availability of data between a pair of languages.In particular, none of the above approaches addressthe problem of developing transliteration functional-ity between a pair of languages when no direct dataexists between them but sufficient data is availablebetween each of these languages and an intermedi-ate language.
Some work on similar lines has beendone in Machine Translation (Wu and Wang, 2007)wherein an intermediate bridge language (say, Z) isused to fill the data void that exists between a givenlanguage pair (say, X and Y ).
In fact, recently it hasbeen shown that the accuracy of a X ?
Z MachineTranslation system can be improved by using addi-tional X ?
Y data provided Z and Y share somecommon vocabulary and cognates (Nakov and Ng,2009).
However, no such effort has been made in thearea of Machine Transliteration.
To the best of ourknowledge, this work is the first attempt at providinga practical solution to the problem of transliterationin the face of resource scarcity.3 Bridge Transliteration SystemsIn this section, we explore the salient question ?Isit possible to develop a practical machine transliter-ation system between X and Y , by composing twointermediate X ?
Z and Z ?
Y transliterationsystems??
We use a standard transliteration method-ology based on orthography for all experiments (asoutlined in section 3.1), to ensure the applicabilityof the methodology to a variety of languages.3.1 CRF based transliteration engineConditional Random Fields ((Lafferty et al, 2001))are undirected graphical models used for labelingsequential data.
Under this model, the conditionalprobability distribution of the target word given thesource word is given by,P (Y |X;?)
= 1N(X)?
ePTt=1PKk=1 ?kfk(Yt?1,Yt,X,t)(1)where,X = source wordY = target wordT = length of source wordK = number of features?k = feature weightN(X) = normalization constantCRF++ 1, an open source implementation of CRFwas used for training and decoding (i.e.
transliter-ating the names).
GIZA++ (Och and Ney, 2003),a freely available implementation of the IBM align-ment models (Brown et al, 1993) was used to getcharacter level alignments for the name pairs in theparallel names training corpora.
Under this align-ment, each character in the source word is aligned tozero or more characters in the corresponding targetword.
The following features are then generated us-ing this character-aligned data (here ei and hi formthe i-th pair of aligned characters in the source wordand target word respectively):?
hi and ej such that i?
2 ?
j ?
i + 2?
hi and source character bigrams ( {ei?1, ei} or{ei, ei+1})?
hi and source character trigrams ( {ei?2, ei?1,ei} or {ei?1, ei, ei+1} or {ei, ei+1, ei+2})?
hi, hi?1 and ej such that i?
2 ?
j ?
i + 2?
hi, hi?1 and source character bigrams?
hi, hi?1 and source character trigrams1http://crfpp.sourceforge.net/4223.2 Bridge Transliteration MethodologyIn this section, we outline our methodology for com-posing transitive transliteration systems between Xand Y , using a bridge language Z , by chaining indi-vidual direct transliteration systems.
Our approachof using bridge transliteration for finding the besttarget string (Y ?
), given the input string X can berepresented by the following probabilistic expres-sion:Y ?
= arg maxYP (Y |X)=?ZP (Y,Z|X)=?ZP (Y |Z,X) ?
P (Z|X) (2)We simplify the above expression, by assuming thatY is independent of X given Z; the linguistic intu-ition behind this assumption is that the top-k outputsof the X ?
Z system corresponding to a string inX, capture all the transliteration information neces-sary for transliterating to Y .
Subsequently, in sec-tion 5 we discuss the characteristics of the effectivebridge languages to maximize the capture of neces-sary information for the second stage of the translit-eration, namely for generating correct strings of Z .Thus,Y ?
=?ZP (Y |Z) ?
P (Z|X) (3)The probabilities P (Y |Z) and P (Z|X) in Equation(3) are derived from the two stages of the bridge sys-tem.
Specifically, we assume that the parallel namescorpora are available between the language pair, Xand Z , and the language pair, Z and Y .
We train twobaseline CRF based transliteration systems (as out-lined in Section 3.1), between the language X andZ , and Z and Y .
Each name in language X wasprovided as an input into X ?
Z transliteration sys-tem, and the top-10 candidate strings in language Zproduced by this first stage system were given as aninput into the second stage system Z ?
Y .
The re-sults were merged using Equation (2).
Finally, thetop-10 outputs of this system were selected as theoutput of the bridge system.4 ExperimentsIt is a well known fact that transliteration is lossy,and hence the transitive systems may be expected tosuffer from the accumulation of errors in each stage,resulting in a system that is of much poorer qualitythan a direct transliteration system.
In this section,we set out to quantify this expected loss in accuracy,by a series of experiments in a set of languages us-ing bridge transliteration systems and a baseline di-rect systems.
We conducted a comprehensive set ofexperiments in a diverse set of languages, as shownin Figure 1, that include English, Indic (Hindi andKannada), Slavic (Russian) and Semitic (Arabic andHebrew) languages.
The datasets and results are de-scribed in the following subsections.4.1 DatasetsTo be consistent, for training each of these systems,we used approximately 15K name pairs corpora (asthis was the maximum data available for some lan-guage pairs).
While we used the NEWS 2009 train-ing corpus (Li et al, 2009) as a part of our train-ing data, we enhanced the data set to about 15K byadding more data of similar characteristics (such as,name origin, domain, length of the name strings,etc.
), taken from the same source as the originalNEWS 2009 data.
For languages such as Arabicand Hebrew which were not part of the NEWS 2009shared task, the data was created along the samelines.
All results are reported on the standard NEWS2009 test set, wherever applicable.
The test set con-sists of about 1,000 name pairs in languages X andY ; to avoid any bias, it was made sure that there isno overlap between the test set with the training setsof both the X ?
Z and Z ?
Y systems.
To estab-lish a baseline, the same CRF based transliterationsystem (outlined in Section 3.1) was trained with a15K name pairs corpora between the languages X?
Y .
The same test set used for testing the transi-tive systems was used for testing the direct systemas well.
As before, to avoid any bias, we made surethat there is no overlap between the test set and thetraining set for the direct system as well.4.2 ResultsWe produce top-10 outputs from the bridge systemas well from the direct system and compare theirperformance.
The performance is measured usingthe following standard measures, viz., top-1 accu-racy (ACC-1) and Mean F-score.
These measuresare described in detail in (Li et al, 2009).
Table 1423LanguagePairACC-1 Relative change inACC-1 Mean F-scoreRelative change inMean F-scoreHin-Rus 0.507 0.903Hin-Eng-Rus 0.466 -8.08% 0.886 -1.88%Hin-Ara 0.458 0.897Hin-Eng-Ara 0.420 -8.29% 0.876 -2.34%Eng-Heb 0.544 0.917Eng-Ara-Heb 0.544 0% 0.917 0%Hin-Eng 0.422 0.884Hin-Kan-Eng 0.382 -9.51% 0.871 -1.47%Table 1: Stepping through an intermediate languagepresents the performance measures, both for a di-rect system (say, Hin-Rus), and a transitional sys-tem (say, Hin-Eng-Rus), in 4 different transitionalsystems, between English, Indic, Semitic and Slaviclanguages.
In each case, we observe that the transi-tional systems have a slightly lower quality, with anabsolute drop in accuracy (ACC-1) of less than 0.05(relative drop under 10%), and an absolute drop inMean F-Score of 0.02 (relative drop under 3%).4.3 Analysis of ResultsIntuitively, one would expect that the errors of thetwo stages of the transitive transliteration system(i.e., X ?
Z , and Z ?
Y ) to compound, leadingto a considerable loss in the overall performance ofthe system.
Given that the accuracies of the directtransliteration systems are as given in Table 2, thetransitive systems are expected to have accuraciesclose to the product of the accuracies of the individ-ual stages, for independent systems.Language Pair ACC-1 Mean F-ScoreHin-Eng 0.422 0.884Eng-Rus 0.672 0.935Eng-Ara 0.514 0.905Ara-Heb 1.000 1.000Hin-Kan 0.433 0.879Kan-Eng 0.434 0.886Table 2: Performance of Direct Transliteration SystemsHowever, as we observe in Table 1, the relativedrop in the accuracy (ACC-1) is less than 10% fromthat of the direct system, which goes against our in-tuition.
To identify the reasons for the better thanexpected performance, we performed a detailed er-ror analysis of each stage of the bridge translitera-tion systems, and the results are reported in Tables 3?
5.
We draw attention to two interesting facts whichaccount for the better than expected performance ofthe bridge system:Improved 2nd stage performance on correctinputs: In each one of the cases, as expected, theACC-1 of the first stage is same as the ACC-1 of theX ?
Z system.
However, we notice that the ACC-1of the second stage on the correct strings outputin the first stage, is significantly better than the theACC-1 of the Z ?
Y system!
For example, theACC-1 of the Eng-Rus system is 67.2% (see Table2), but, that of the 2nd stage Eng-Rus system is77.8%, namely, on the strings that are transliteratedcorrectly by the first stage.
Our analysis indicatethat there are two reasons for such improvement:First, the strings that get transliterated correctly inthe first stage are typically shorter or less ambigu-ous and hence have a better probability of correcttransliterations in the both stages.
This phenomenoncould be verified empirically: Names like gopAl{Gopal}, rm?
{Ramesh}, rAm {Ram} areshorter and in general have less ambiguity on targetorthography.
Second, also significantly, the use oftop-10 outputs from the first stage as input to thesecond stage provides a better opportunity for thesecond stage to produce correct string in Z .
Again,this phenomenon is verified by providing increasingnumber of top-n results to the 2nd stage.424Hi?En?Ru En ?
Ru(Stage-2)Stage-2Acc.Correct ErrorHi?En Correct 263 75 77.81%(Stage-1) Error 119 362 24.74%Table 3: Error Analysis for Hi?En?RuHi?En?Ar En ?
Ar(Stage-2)Stage-2Acc.Correct ErrorHi?En Correct 221 127 63.50%(Stage-1) Error 119 340 25.70%Table 4: Error Analysis for Hi?En?Ar2nd stage error correction on incorrect inputs:The last rows in each of the above tables 3 ?
5 re-port the performance of the second stage system onstrings that were transliterated incorrectly by the firststage.
While we expected the second row to pro-duce incorrect transliterations nearly for all inputs(as the input themselves were incorrect in Z), wefind to our surprise that upto 25% of the erroneousstrings in Z were getting transliterated correctly inY !
This provides credence to our hypothesis thatsufficient transliteration information is captured inthe 1st stage output (even when incorrect) that maybe exploited in the 2nd stage.
Empirically, we veri-fied that in most cases (nearly 60%) the errors weredue to the incorrectly transliterated vowels, and inmany cases, they get corrected in the second stage,and re-ranked higher in the output.
Figure 2 shows afew examples of such error corrections in the secondstage.Figure 2: Examples of error correctionsHi?Ka?En Ka ?
En(Stage-2)Stage-2Acc.Correct ErrorHi?Ka Correct 225 196 53.44%(Stage-1) Error 151 400 27.40%Table 5: Error Analysis for Hi?Ka?En5 Characteristics of the bridge languageAn interesting question that we explore in this sec-tion is ?how the choice of bridge language influencethe performance of the bridge system??.
The under-lying assumption in transitive transliteration systems(as expressed in Equation 3), is that ?Y is indepen-dent of X given Z?.
In other words, we assume thatthe representations in the language will Z ?capturesufficient transliteration information from X to pro-duce correct strings in Y ?.
We hypothesize that twoparameters of the bridge language, namely, the or-thography inventory and the phoneme-to-graphemeentropy, that has most influence on the quality of thetransitional systems, and provide empirical evidencefor this hypothesis.5.1 Richer Orthographic InventoryIn each of the successful bridge systems (that is,those with a relative performance drop of less than10%), presented in Table 1, namely, Hin-Eng-Ara,Eng-Ara-Heb and Hin-Kan-Eng, the bridge lan-guage has, in general, richer orthographic inven-tory than the target language.
Arabic has a reducedset of vowels, and hence poorer orthographic inven-tory compared with English.
Similarly, between theclosely related Semitic languages Arabic-Hebrew,there is a many-to-one mapping from Arabic to He-brew, and between Kannada-English, Kannada hasnearly a superset of vowels and consonants as com-pared to English or Hindi.As an example for a poor choice of Z , we presenta transitional system, Hindi ?
Arabic ?
English, inTable 6, in which the transitional language z (Ara-bic) has smaller orthographic inventory than Y (En-glish).Arabic has a reduced set of vowels and, unlike En-glish, in most contexts short vowels are optional.
Asa result, when Arabic is used as the bridge languagethe loss of information (in terms of vowels) is large425LanguagePairACC-1 Relative change inACC-1Hin-Eng 0.422Hin-Ara-Eng 0.155 -64.28%Table 6: Incorrect choice of bridge languageand the second stage system has no possibility of re-covering from such a loss.
The performance of thebridge system confirms such a drastic drop in ACC-1 of nearly 64% compared with the direct system.5.2 Higher Phoneme-Grapheme EntropyWe also find that the entropy in phoneme - graphememapping of a language indicate a good correlationwith a good choice for a transition language.
Ina good transitional system (say, Hin-Eng-Rus), En-glish has a more ambiguous phoneme-to-graphememapping than Russian; for example, in English thephoneme ?s?
as in Sam or Cecilia can be repre-sented by the graphemes ?c?
and ?s?, whereas Rus-sian uses only a single character to represent thisphoneme.
In such cases, the ambiguity introducedby the bridge language helps in recovering from er-rors in the X ?
Z system.
The relative loss ofACC-1 for this transitional system is only about 8%.The Table 7 shows another transitional system, inwhich a poor choice was for the transitional lan-guage was made.LanguagePairACC-1 Relative change inACC-1Hin-Eng 0.422Hin-Tam-Eng 0.231 -45.26%Table 7: Incorrect choice of bridge languageTamil has a reduced set of consonants comparedwith Hindi or English.
For example, the Hindi con-sonants (k, kh, g, gh) are represented by a sin-gle character in Tamil.
As a result, when Tamil isused as the bridge language it looses information (interms of consonants) and results in a significant dropin performance (nearly a 45% drop in ACC-1) forthe bridge system.6 Effectiveness of Bridge Transliterationon CLIR SystemIn this section, we demonstrate the effectiveness ofour bridge transliteration system on a downstreamapplication, namely, a Crosslingual Information Re-trieval system.
We used the standard document col-lections from CLEF 2006 (Nardi and Peters, 2006),CLEF 2007 (Nardi and Peters, 2007) and FIRE 2008(FIRE, 2008).
We used Hindi as the query language.All the three fields (title, description and narration)of the topics were used for the retrieval.
Since thecollection and topics are from the previous years,their relevance judgments were also available as areference for automatic evaluation.6.1 Experimental SetupWe used primarily the statistical dictionaries gen-erated by training statistical word alignment mod-els on an existing Hindi-English parallel corpora.As with any CLIR system that uses translation lex-icon, we faced the problem of out-of-vocabulary(OOV) query terms that need to be transliterated,as they are typically proper names in the target lan-guage.
First, for comparison, we used the abovementioned CLIR system with no transliteration en-gine (Basic), and measured the crosslingual retrievalperformance.
Clearly, the OOV terms would not beconverted into target language, and hence contributenothing to the retrieval performance.
Second, we in-tegrated a direct machine transliteration system be-tween Hindi and English (D-HiEn), and calibratedthe improvement in performance.
Third, we inte-grate, instead of a direct system, a bridge transliter-ation system between Hindi and English, transition-ing through Kannada (B-HiKaEn).
For both, directas well as bridge transliteration, we retained the top-5 transliterations generated by the appropriate sys-tem, for retrieval.6.2 Results and DiscussionThe results of the above experiments are given inTable 7.
The current focus of these experiments isto answer the question of whether the bridge ma-chine transliteration systems used to transliteratethe OOV words in Hindi queries to English (by step-ping through Kannada) performs at par with a di-rect transliteration system.
As expected, enhancingthe CLIR system with a machine transliteration sys-426Collection CLIR System MAP Relative MAP changefrom BasicRecall Relative Recall changefrom BasicBasic 0.1463 - 0.4952 -CLEF 2006 D-HiEn 0.1536 +4.98% 0.5151 +4.01%B-HiKaEn 0.1529 +4.51% 0.5302 +7.06%Basic 0.2521 - 0.7156 -CLEF 2007 D-HiEn 0.2556 +1.38% 0.7170 + 0.19%B-HiKaEn 0.2748 +9.00% 0.7174 + 0.25%Basic 0.4361 - 0.8457 -FIRE 2008 D-HiEn 0.4505 +3.30% 0.8506 +0.57%B-HiKaEn 0.4573 +4.86% 0.8621 +1.93%Table 8: CLIR Experiments with bridge transliteration systemstem (D-HiEn) gives better results over a CLIR sys-tem with no transliteration functionality (Basic).
Onthe standard test collections, the bridge translitera-tion system performs in par or better than the di-rect transliteration system in terms of MAP as wellas recall.
Even though, the bridged system is ofslightly lesser quality in ACC-1 in Hi-Ka-En, com-pared to Hi-En (see Table 1), the top-5 results hadcaptured the correct transliteration, as shown in ouranalysis.
A detailed analysis of the query transla-tions produced by the above systems showed that insome cases the bridge systems does produce a bet-ter transliteration thereby leading to a better MAP.As an illustration, consider the OOV terms vEV?n{Vatican} and n-l {Nestle} and the corre-sponding transliterations generated by the differentsystems.
The Direct-HiEn system was unable toOOV term D-HiEn B-HiKaEnvetican veticanveticon vetticanvEV?n vettican vatican(vatican) vetticon waticanwetican weticannesle nestlenesly neslen-l nesley nesley(nestle) nessle nestleynesey neslyTable 9: Sample output in direct and bridge systemsgenerate the correct transliteration in the top-5 re-sults whereas the B-HiKaEn was able to produce thecorrect transliteration in the top-5 results thereby re-sulting in an improvement in MAP for these queries.7 ConclusionsIn this paper, we introduced the idea of bridgetransliteration systems that were developed employ-ing well-studied orthographic approaches betweenconstituent languages.
We empirically establishedthe quality of such bridge transliteration systemsand showed that quite contrary to our expectations,the quality of such systems does not degrade dras-tically as compared to the direct systems.
Our er-ror analysis showed that these better-than-expectedresults can be attributed to (i) Better performance(?10-12%) of the second stage system on the stringstransliterated correctly by the first stage system and(ii) Significant (?25%) error correction in the sec-ond stage.
Next, we highlighted that the perfor-mance of such bridge systems will be satisfactory aslong as the orthographic inventory of the bridge lan-guage is either richer or more ambiguous as com-pared to the target language.
We showed that ourresults are consistent with this hypothesis and pro-vided two examples where there is a significant dropin the accuracy when the bridge language violatesthe above constraints.
Finally, we showed that astate of the art CLIR system integrated with a bridgetransliteration system performs in par with the sameCLIR system integrated with a direct translitera-tion system, vindicating our claim that such bridgetransliteration systems can be use in real-world ap-plications to alleviate the resource requirement ofnC2 parallel names corpora.427ReferencesPeter E Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19:263?311.FIRE.
2008.
Forum for information retrieval evaluation.Isao Goto, Naoto Kato, Noriyoshi Uratani, and TerumasaEhara.
2003.
Transliteration considering context in-formation based on the maximum entropy method.
InProceedings of MT-Summit IX, pages 125?132.Sung Young Jung, SungLim Hong, and Eunok Paek.2000.
An english to korean transliteration model ofextended markov window.
In Proceedings of the 18thconference on Computational linguistics, pages 383?389.Byung-Ju Kang and Key-Sun Choi.
2000.
Automatictransliteration and back-transliteration by decision treelearning.
In Proceedings of the 2nd International Con-ference on Language Resources and Evaluation, pages1135?1411.Kevin Knight and Jonathan Graehl.
1997.
Machinetransliteration.
In Computational Linguistics, pages128?135.John D. Lafferty, Andrew Mccallum, and Fernando C. N.Pereira.
2001.
Conditional random fields: Probabilis-tic models for segmenting and labeling sequence data.In ICML ?01: Proceedings of the Eighteenth Interna-tional Conference on Machine Learning, pages 282?289, San Francisco, CA, USA.Jae Sung Lee and Key-Sun Choi.
1998.
English to ko-rean statistical transliteration for information retrieval.In Computer Processing of Oriental Languages, pages17?37.Haizhou Li, A Kumaran, , Min Zhang, and Vladimir Per-vouvhine.
2009.
Whitepaper of news 2009 machinetransliteration shared task.
In Proceedings of the 2009Named Entities Workshop: Shared Task on Transliter-ation (NEWS 2009), pages 19?26, Suntec, Singapore,August.
Association for Computational Linguistics.Thomas Mandl and Christa Womser-Hacker.
2004.
Howdo named entities contribute to retrieval effectiveness?In CLEF, pages 833?842.Preslav Nakov and Hwee Tou Ng.
2009.
Improved statis-tical machine translation for resource-poor languagesusing related resource-rich languages.
In Proceedingsof the 2009 Conference on Empirical Methods in Nat-ural Language Processing, pages 1358?1367, Singa-pore, August.
Association for Computational Linguis-tics.A Nardi and C Peters.
2006.
Working notes for the clef2006 workshop.A Nardi and C Peters.
2007.
Working notes for the clef2007 workshop.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Jong-hoon Oh and Key-Sun Choi.
2002.
An english-korean transliteration model using pronunciation andcontextual rules.
In Proceedings of the 19th In-ternational Conference on Computational Linguistics(COLING), pages 758?764.Bonnie Glover Stalls and Kevin Knight.
1998.
Trans-lating names and technical terms in arabic text.
InProceedings of COLING/ACL Workshop on Computa-tional Approaches to Semitic Languages, pages 34?41.Raghavendra Udupa, K Saravanan, Anton Bakalov, andAbhijit Bhole.
2009.
?they are out there, if you knowwhere to look: Mining transliterations of oov queryterms for cross language information retrieval?.
InECIR?09: Proceedings of the 31st European Confer-ence on IR research on Advances in Information Re-trieval, pages 437?448, Toulouse, France.Suryaganesh Veeravalli, Sreeharsha Yella, Prasad Pin-gali, and Vasudeva Varma.
2008.
Statistical translit-eration for cross language information retrieval usinghmm alignment model and crf.
In Proceedings of the2nd workshop on Cross Lingual Information Access(CLIA) Addressing the Information Need of Multilin-gual Societies.Hua Wu and Haifeng Wang.
2007.
Pivot languageapproach for phrase-based statistical machine transla-tion.
Machine Translation, 21(3):165?181.428
