Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 714?724,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsA Unified Framework for Scope Learning via Simplified Shallow Seman-tic ParsingQiaoming Zhu    Junhui Li    Hongling Wang    Guodong Zhou?School of Computer Science and TechnologySoochow University, Suzhou, China 215006{qmzhu, lijunhui, hlwang, gdzhou}@suda.edu.cn?
Corresponding authorAbstractThis paper approaches the scope learningproblem via simplified shallow semantic pars-ing.
This is done by regarding the cue as thepredicate and mapping its scope into severalconstituents as the arguments of the cue.Evaluation on the BioScope corpus shows thatthe structural information plays a critical rolein capturing the relationship between a cueand its dominated arguments.
It also showsthat our parsing approach significantly outper-forms the state-of-the-art chunking ones.
Al-though our parsing approach is only evaluatedon negation and speculation scope learninghere, it is portable to other kinds of scopelearning.1 IntroductionRecent years have witnessed an increasing interestin the analysis of linguistic scope in natural lan-guage.
The task of scope learning deals with thesyntactic analysis of what part of a given sentenceis under user?s special interest.
For example, ofnegation assertion concerned, a negation cue (e.g.,not, no) usually dominates a fragment of the givensentence, rather than the whole sentence, especiallywhen the sentence is long.
Generally, scope learn-ing involves two subtasks: cue recognition and itsscope identification.
The former decides whether aword or phrase in a sentence is a cue of a specialinterest, where the semantic information of theword or phrase, rather than the syntactic informa-tion, plays a critical role.
The latter determines thesequences of words in the sentence which aredominated by the given cue.Recognizing the scope of a special interest (e.g.,negative assertion and speculative assertion) is es-sential in information extraction (IE), whose aim isto derive factual knowledge from free text.
Forexample, Vincze et al (2008) pointed out that theextracted information within the scope of a nega-tion or speculation cue should either be discardedor presented separately from factual information.This is especially important in the biomedical andscientific domains, where various linguistic formsare used extensively to express impressions, hy-pothesized explanations of experimental results ornegative findings.
Besides, Vincez et al (2008)reported that 13.45% and 17.70% of the sentencesin the abstracts subcorpus of the BioScope corpuscontain negative and speculative assertions, respec-tively, while 12.70% and 19.44% of the sentencesin the full papers subcorpus contain negative andspeculative assertions, respectively.
In addition tothe IE tasks in the biomedical domain, negationscope learning has attracted increasing attention insome natural language processing (NLP) tasks,such as sentiment classification (Turney, 2002).For example, in the sentence ?The chair is notcomfortable but cheap?, although both the polari-ties of the words ?comfortable?
and ?cheap?
arepositive, the polarity of ?the chair?
regarding theattribute ?cheap?
keeps positive while the polarityof ?the chair?
regarding the attribute ?comfortable?is reversed due to the negation cue ?not?.
Similarly,seeing the increasing interest in speculation scopelearning, the CoNLL?2010 shared task (Farkas etal., 2010) aims to detect uncertain information inresolving the scopes of speculation cues.Most of the initial research in this literature fo-cused on either recognizing negated terms or iden-tifying speculative sentences, using some heuristic714rules (Chapman et al, 2001; Light et al, 2004),and machine learning methods (Goldin and Chap-man, 2003; Medlock and Briscoe, 2007).
However,scope learning has been largely ignored until therecent release of the BioScope corpus (Szarvas etal., 2008), where negation/speculation cues andtheir scopes are annotated explicitly.
Morante et al(2008) and Morante and Daelemans (2009a &2009b) pioneered the research on scope learningby formulating it as a chunking problem, whichclassifies the words of a sentence as being inside oroutside the scope of a cue.
Alternatively, ?zg?rand Radev (2009) and ?vrelid et al (2010) definedheuristic rules for speculation scope learning fromconstituency and dependency parse tree perspec-tives, respectively.Although the chunking approach has beenevaluated on negation and speculation scope learn-ing and can be easily ported to other scope learningtasks, it ignores syntactic information and suffersfrom low performance.
Alternatively, even if therule-based methods may be effective for a specialscope learning task (e.g., speculation scope learn-ing), it is not readily adoptable to other scopelearning tasks (e.g., negation scope learning).
In-stead, this paper explores scope learning fromparse tree perspective and formulates it as a simpli-fied shallow semantic parsing problem, which hasbeen extensively studied in the past few years(Carreras and M?rquez, 2005).
In particular, thecue is recast as the predicate and the scope is recastas the arguments of the cue.
The motivation behindis that the structured syntactic information plays acritical role in scope learning and should be paidmuch more attention, as indicated by previousstudies in shallow semantic parsing (Gildea andPalmer, 2002; Punyakanok et al, 2005).
Althoughour approach is evaluated only on negation andspeculation scope learning here, it is portable toother kinds of scope learning.The rest of this paper is organized as follows.Section 2 reviews related work.
Section 3 intro-duces the Bioscope corpus on which our approachis evaluated.
Section 4 describes our parsing ap-proach by formulating scope learning as a simpli-fied shallow semantic parsing problem.
Section 5presents the experimental results.
Finally, Section6 concludes the work.2 Related WorkMost of the previous research on scope learningfalls into negation scope learning and speculationscope learning.Negation Scope LearningMorante et al (2008) pioneered the research onnegation scope learning, largely due to the avail-ability of a large-scale annotated corpus, the Bio-scope corpus.
They approached negation cuerecognition as a classification problem and formu-lated negation scope identification as a chunkingproblem which predicts whether a word in the sen-tence is inside or outside of the negation scope,with proper post-processing to ensure consecutive-ness of the negation scope.
Morante and Daele-mans (2009a) further improved the performance bycombing several classifiers and achieved the accu-racy of ~98% for negation cue recognition and thePCS (Percentage of Correct Scope) of ~74% fornegation scope identification on the abstracts sub-corpus.
However, this chunking approach suffersfrom low performance, in particular on long sen-tences.
For example, given golden negation cueson the Bioscope corpus, Morante and Daelemans(2009a) only got the performance of 50.26% inPCS on the full papers subcorpus (22.8 words persentence on average), compared to 87.27% in PCSon the clinical reports subcorpus (6.6 words persentence on average).Speculation Scope LearningSimilar to Morante and Daelemans (2009a),Morante and Daelemans (2009b) formulatedspeculation scope identification as a chunkingproblem which predicts whether a word in the sen-tence is inside or outside of the speculation scope,with proper post-processing to ensure consecutive-ness of the speculation scope.
They concluded thattheir method for negation scope identification isportable to speculation scope identification.
How-ever, of speculation scope identification concerned,it also suffers from low performance, with only60.59% in PCS for the clinical reports subcorpusof short sentences.Alternatively, ?zg?r and Radev (2009) em-ployed some heuristic rules from constituencyparse tree perspective on speculation scope identi-fication.
Given golden speculation cues, their rule-based method achieves the accuracies of 79.89%715and 61.13% on the abstracts and the full paperssubcorpora, respectively.
The more recentCoNLL?2010 shared task was dedicated to the de-tection of speculation cues and their linguisticscope in natural language processing (Farkas et al,2010).
As a representative, ?vrelid et al (2010)adopted some heuristic rules from dependencyparse tree perspective to identify their speculationscopes.3 Cues and Scopes in the BioScope Cor-pusThis paper employs the BioScope corpus (Szarvaset al, 2008; Vincze et al, 2008) 1 , a freelydownloadable resource from the biomedical do-main, as the benchmark corpus.
In this corpus,every sentence is annotated with negation cues andspeculation cues (if it has), as well as their linguis-tic scopes.
Figure 1 shows a self-explainable ex-ample.
It is possible that a negation/speculation cueconsists of multiple words, i.e., ?can not?/?indicatethat?
in Figure 1.The Bioscope corpus consists of three sub-corpora: biological full papers from FlyBase andfrom BMC Bioinformatics, biological paper ab-stracts from the GENIA corpus (Collier et al,1999), and clinical (radiology) reports.
Amongthem, the full papers subcorpus and the abstractssubcorpus come from the same genre, and thusshare some common characteristics in statistics,such as the number of words in the nega-tion/speculation scope to the right (or left) of thenegation/speculation cue and the average scopelength.
In comparison, the clinical reports subcor-pus consists of clinical radiology reports with shortsentences.
For detailed statistics and annotation1 http://www.inf.u-szeged.hu/rgai/bioscopeguidelines about the three subcorpora, please seeMorante and Daelemans (2009a & 2009b).For preprocessing, all the sentences in the Bio-scope corpus are tokenized and then parsed usingthe Berkeley parser (Petrov and Klein, 2007) 2trained on the GENIA TreeBank (GTB) 1.0(Tateisi et al, 2005)3, which is a bracketed corpusin (almost) PTB style.
10-fold cross-validation onGTB1.0 shows that the parser achieves the per-formance of 86.57 in F1-measure.
It is worth not-ing that the GTB1.0 corpus includes all thesentences in the abstracts subcorpus of the Bio-scope corpus.4 Scope Learning via Simplified ShallowSemantic ParsingIn this section, we first formulate the scope learn-ing task as a simplified shallow semantic parsingproblem.
Then, we deal with it using a simplifiedshallow semantic parsing framework.4.1 Formulating Scope Learning as a Simpli-fied Shallow Semantic Parsing Problem<sentence id="S26.8">These findings <xcopeid="X26.8.2"><cue type="speculation"ref="X26.8.2">indicate that</cue> <xcopeid="X26.8.1">corticosteroid resistance in bron-chial asthma <cue type="negation"ref="X26.8.1">can not</cue> be explained byabnormalities in corticosteroid receptor charac-teristics</xcope></xcope>.</sentence>Figure 1: An annotated sentence in the BioScopecorpusGiven a parse tree and a predicate in it, shallowsemantic parsing recognizes and maps all the con-stituents in the sentence into their correspondingsemantic arguments (roles) of the predicate or not.As far as scope learning considered, the cue can beregarded as the predicate4, while its scope can bemapped into several constituents dominated by thecue and thus can be regarded as the arguments ofthe cue.
In particular, given a cue and its scopewhich covers wordm, ?, wordn, we adopt the fol-lowing two heuristic rules to map the scope of thecue into several constituents which can be deemedas its arguments in the given parse tree.1) The cue itself and all of its ancestral constituentsare non-arguments.2) If constituent X is an argument of the given cue,then X should be the highest constituent domi-nated by the scope of wordm, ?, wordn.
That isto say, X?s parent constituent must cross-bracketor include the scope of wordm, ?, wordn.2 http://code.google.com/p/berkeleyparser/3 http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA4 If a speculation cue consists of multiply words (e.g., whetheror not), the first word (e.g., whether) is chosen to represent thespeculation signal.
However, the last word (e.g., not) is chosento represent the negation cue if it consists of multiple words(e.g., can not).716Figure 2: Examples of a negation/speculation cue and its arguments in a parse treeThese findingsindicatethatcorticosteroid resistanceNP0,1VBP2,2 SBAR3,11can notIN3,3beexplained by abnormalitiesNP4,5MD6,6 RB7,7VB8,8 VP9,11VP8,11VP6,11S4,11VP2,11S0,11neg-predicateneg-argumentsspec-predicatespec-argumentThe first rule ensures that no argument coversthe cue while the second rule ensures no overlapbetween any two arguments.
These two constraintsbetween a cue and its arguments are consistentwith shallow semantic parsing (Carreras andM?rquez, 2005).
For example, in the sentence?These findings indicate that corticosteroid resis-tance can not be explained by abnormalities?, thenegation cue ?can not?
has the negation scope?corticosteroid resistance can not be explained byabnormalities?
while the speculation cue ?indicatethat?
has the speculation scope ?indicate that cor-ticosteroid resistance can not be explained by ab-normalities?.
As shown in Figure 2, the node?RB7,7?
(i.e., not) represents the negation cue ?cannot?
while its arguments include three constituents{NP4,5, MD6,6, and VP8,11}.
Similarly, the node?VBP2,2?
(i.e., indicate) represents the  speculationcue ?indicate that?
while its arguments include oneconstituent SBAR3,11.
It is worth noting that ac-cording to the above rules, scope learning via shal-low semantic parsing, i.e.
determining thearguments of a given cue, is robust to some varia-tions in the parse trees.
This is also empiricallyjustified by our later experiments.
For example, ifthe VP6,11 in Figure 2 is incorrectly expanded bythe rule VP6,11?MD6,6+RB7,7+VB8,8+VP9,11, thenegation scope of the negation cue ?can not?
canstill be correctly detected as long as {NP4,5, MD6,6,VB8,8, and VP9,11} are predicated as the argumentsof the negation cue ?can not?.Compared with common shallow semantic pars-ing which needs to assign an argument with a se-mantic label, scope identification does not involvesemantic label classification and thus could be di-vided into three consequent phases: argumentpruning, argument identification and post-processing.4.2 Argument PruningSimilar to the predicate-argument structures incommon shallow semantic parsing, the cue-scopestructures in scope learning can be also classifiedinto several certain types and argument pruningcan be done by employing several heuristic rulesaccordingly to filter out constituents, which aremost likely non-arguments of a given cue.
Similarto the heuristic algorithm proposed in Xue andPalmer (2004) for argument pruning in commonshallow semantic parsing, the argument pruningalgorithm adopted here starts from designating thecue node as the current node and collects its sib-lings.
It then iteratively moves one level up to theparent of the current node and collects its siblings.The algorithm ends when it reaches the root of theparse tree.
To sum up, except the cue node itselfand its ancestral constituents, any constituent in theparse tree whose parent covers the given cue willbe collected as argument candidates.
Taking thenegation cue node ?RB7,7?
in Figure 2 as an exam-ple, constituents {MD6,6, VP8,11, NP4,5, IN3,3,717Feature RemarksB1 Cue itself: the word of the cue, e.g., not,rather_than.
(can_not)B2 Phrase Type: the syntactic category of theargument candidate.
(NP)B3 Path: the syntactic path from the argumentcandidate to the cue.
(NP<S>VP>RB)B4 Position: the positional relationship of theargument candidate with the cue.
?left?
or?right?.
(left)Table 1: Basic features and their instantiations for ar-gument identification in scope learning, with NP4,5 asthe focus constituent (i.e., the argument candidate) and?can not?
as the given cue, regarding Figure 2.Feature RemarksArgument Candidate (AC) relatedAC1 The headword (AC1H) and its POS(AC1P).
(resistance, NN)AC2 The left word (AC2W) and its POS(AC2P).
(that, IN)AC3 The right word (AC3W) and its POS(AC3P).
(can, MD)AC4 The phrase type of its left sibling (AC4L)and its right sibling (AC4R).
(NULL, VP)AC5 The phrase type of its parent node.
(S)AC6 The subcategory.
(S:NP+VP)Cue/Predicate (CP) relatedCP1 Its POS.
(RB)CP2 Its left word (CP2L) and right word(CP2R).
(can, be)CP3 The subcategory.
(VP:MD+RB+VP)CP4 The phrase type of its parent node.
(VP)Combined Features related with the Argument Candi-date  (CFAC1-CFAC2)b2&AC1H, b2&AC1PCombined Features related with the givenCue/Predicate  (CFCP1-CFCP2)B1&CP2L, B1&CP2RCombined Features related with both the ArgumentCandidate and the given Cue/Predicate (CFACCP1-CFACCP7)B1&B2, B1&B3, B1&CP1, B3&CFCP1, B3&CFCP2,B4&CFCP1, B4&CFCP2Table 2: Additional features and their instantiations forargument identification in scope identification, withNP4,5 as the focus constituent (i.e., the argument candi-date) and ?can not?
as the given cue, regarding Figure 2.VBP2,2, and NP0,1} are collected as its argumentcandidates consequently.4.3 Argument IdentificationHere, a binary classifier is applied to determine theargument candidates as either valid arguments ornon-arguments.
Similar to argument identificationin common shallow semantic parsing, the struc-tured syntactic information plays a critical role inscope learning.Basic FeaturesTable 1 lists the basic features for argument identi-fication.
These features are also widely used incommon shallow semantic parsing for both verbaland nominal predicates (Xue, 2008; Li et al, 2009).Additional FeaturesTo capture more useful information in the cue-scope structures, we also explore various kinds ofadditional features.
Table 2 shows the features inbetter capturing the details regarding the argumentcandidate and the cue.
In particular, we categorizethe additional features into three groups accordingto their relationship with the argument candidate(AC, in short) and the given cue/predicate (CP, inshort).Some features proposed above may not be effec-tive in argument identification.
Therefore, weadopt the greedy feature selection algorithm as de-scribed in Jiang and Ng (2006) to pick up positivefeatures incrementally according to their contribu-tions on the development data.
The algorithm re-peatedly selects one feature each time, which con-tributes most, and stops when adding any of theremaining features fails to improve the perform-ance.4.4 Post-ProcessingAlthough a cue in the BioScope corpus always hasonly one continuous block as its scope (includingthe cue itself), the scope identifier may result indiscontinuous scope due to independent predica-tion in the argument identification phase.
Given thegolden negation/speculation cues, we observe that6.2%/9.1% of the negation/speculation scopes pre-dicted by our scope identifier are discontinuous.718Figure 3 demonstrates the projection of all theargument candidates into the word level.
Accord-ing to our argument pruning algorithm in Section4.2, except the words presented by the cue, the pro-jection covers the whole sentence and each con-stituent (LACi or RACj in Figure 3) receives aprobability distribution of being an argument of thegiven cue in the argument identification phase.Since a cue is deemed inside its scope in theBioScope corpus, our post-processing algorithmfirst includes the cue in its scope and then starts toidentify the left and the right scope boundaries,respectively.As shown in Figure 3, the left boundary hasm+1 possibilities, namely the cue itself, the left-most word of constituent LACi (1<=i<=m).
Sup-posing LACi receives probability of Pi being anargument, we use the following formula to deter-mine LACk* whose leftmost word represents theboundary of the left scope.
If k*=0, then the cueitself represents its left boundary.
( )*1 1arg max 1k mi ik i i kk P= = += ??
?
P?Similarly, the right boundary of the given cuecan be decided.4.5 Cue RecognitionAutomatic recognition of cues of a special interestis the prerequisite for a scope learning system.
Theapproaches to recognizing cues of a special interestusually fall into two categories: 1) substringmatching approaches, which require a set of cuewords or phrases in advance (e.g., Light et al,2004); 2) machine learning approaches, whichtrain a classifier with either supervised or semi-supervised learning methods (e.g., ?zg?r andRadev, 2009; Szarvas, 2008).
Without loss of gen-erality, we adopt a machine learning approach andtrain a classifier with supervised learning.
In par-ticular, we make an independent classification foreach word with a BIO label to indicate whether itis the first word of a cue, inside a cue, or outside ofit, respectively.LACm    ?.
LAC1 RAC1      ?.
RACnm nFigure 3: Projecting the left and the right argumentcandidates into the word level.Inspired by previous studies on similar taskssuch as WSD and nominal predicate recognition inshallow semantic parsing (Lee and Ng, 2002; Li etal., 2009), where various features on the word it-self, surrounding words and syntactic informationhave been successfully used, we believe that suchinformation is also valuable to automatic recogni-tion of cues.
Table 3 shows the features employedfor cue recognition.
In particular, we categorizethese features into three groups: 1) features aboutthe cue candidate itself (CC in short); 2) featuresabout surrounding words (SW in short); and 3)structural features derived from the syntactic parsetree (SF in short).Feature RemarksCue Candidate (CC) relatedCC1 The cue candidate itself.
(indicate)CC2 The stem of the cue candidate.
(indicate)CC3 The POS tag of the cue candidate.
(VBP)Surrounding Words (SW) relatedSW1 The left surrounding words with the win-dow size of 3.
(these, findings)SW2 The right surrounding words with thewindow size of 3.
(that, corticosteroid,resistance)Structural Features (SF)SF1 The subcategory of the candidate node.
(VP-->VBP+SBAR)SF2 The subcategory of the candidate node?sparent.
(S-->NP+VP)SF3 POS tag of the candidate node + Phrasetype of its parent node + Phrase type of itsgrandpa node.
(VBP + VP + S)Table 3: Features and their instantiations for cue recog-nition, with VBP2,2 as the cue candidate, regarding Fig-ure 2.5 ExperimentationWe have evaluated our simplified shallow seman-tic parsing approach to negation and speculationscope learning on the BioScope corpus.5.1 Experimental SettingsFollowing the experimental setting in Morante et al(2008) and Morante and Daelemans (2009a &2009b), the abstracts subcorpus is randomly di-vided into 10 folds so as to perform 10-fold cross-validation, while the performance on both the pa-719pers and clinical reports subcorpora is evaluatedusing the system trained on the whole abstractssubcorpus.
In addition, SVMLight  is selected asour classifier.5For cue recognition, we report its performanceusing precision/recall/F1-measure.
For scope iden-tification, we report the accuracy in PCS (Percent-age of Correct Scopes) when the golden cues aregiven, and report precision/recall/F1-measurewhen the cues are automatically recognized.5.2 Experimental Results on Golden ParseTrees and Golden CuesIn order to select beneficial features from the addi-tional features proposed in Section 4.3, we ran-domly split the abstracts subcorpus into thetraining data and the development data with pro-portion of 4:1.
After performing the greedy featureselection algorithm on the development data, 7features {CFACCP5, CP2R, CFCP1, AC1P, CP3,CFACCP7, AC4R} are selected consecutively fornegation scope identification while 11 features{CFACCP5, AC2W, CFACCP2, CFACCP4, AC5,CFCP1, CFACCP7, CFACCP1, CP4, AC3P,CFAC2} are selected for speculation scope identi-fication.
Table 4 gives the contribution of addi-tional features on the development data.
It showsthat the additional features significantly improvethe performance by 11.66% in accuracy from74.93% to 86.59% ( ) for negation scopeidentification and improve the performance by11.07% in accuracy from 77.29% to 88.36%( ) for speculation scope identification.The feature selection experiments suggest that thefeatures (e.g., CFACCP5, AC2W, CFCP1) relatedto neighboring words of the cue play a critical rolefor both negation and speculation scope identifica-tion.
This may be due to the fact that neighboringwords usually imply important sentential informa-tion.
For example, ?can not be?
indicates a passiveclause while ?did not?
indicates an active clause.2; 0.0p?
< 112; 0.0p?
<Since the additional selected features signifi-cantly improve the performance for both negationand speculation scope identification, we will in-clude those additional selected features in all theremaining experiments.5 http://svmlight.joachims.org/Task Features Acc (%)Baseline 74.93 Negation scopeidentification +selected features 86.59Baseline 77.29 Speculation scopeidentification +selected features 88.36Table 4: Contribution of additional selected features onthe development dataset of the abstracts subcorpusSince all the sentences in the abstracts subcorpusare included in the GTB1.0 corpus while we do nothave golden parse trees for the sentences in the fullpapers and the clinical reports subcorpora, we onlyevaluate the performance of scope identification onthe abstracts subcorpus with golden parse trees.Table 5 presents the performance on the abstractssubcorpus by performing 10-fold cross-validation.It shows that given golden parse trees and goldencues, speculation scope identification achieveshigher performance (e.g., ~3.3% higher in accu-racy) than negation scope identification.
This ismainly due to the observation on the BioScopecorpus that the scope of a speculation cue can beusually characterized by its POS and the syntacticstructures of the sentence where it occurs.
For ex-ample, the scope of a verb in active voice usuallystarts at the cue itself and ends at its object (e.g.,the speculation cue ?indicate that?
in Figure 2scopes the fragment of ?indicate that corticoster-oid resistance can not be explained by abnormali-ties?).
Moreover, the statistics on the abstractssubcorpus shows that the number of arguments perspeculation cue is smaller than that of argumentsper negation cue (e.g., 1.5 vs. 1.8).Task Acc (%)Negation scope identification 83.10Speculation scope identification 86.41Table 5: Accuracy (%) of scope identification withgolden parse trees and golden cues on the abstracts sub-corpus using 10-fold cross-validationIt is worth nothing that we adopted the post-processing algorithm proposed in Section 4.4 toensure the continuousness of identified scope.
Asto examine the effectiveness of the algorithm, weabandon the proposed algorithm by simply takingthe left and right-most boundaries of any nodes inthe tree which are classified as in scope.
Experi-ments on the abstracts subcorpus using 10-foldcross-validation shows that the simple post-processing rule gets the performance of 80.59 and86.08 in accuracy for negation and speculation720scope identification, respectively, which is lowerthan the performance in Table 5 achieved by ourpost-processing algorithm.5.3 Experimental Results on AutomaticParse Trees and Golden CuesThe GTB1.0 corpus contains 18,541 sentences inwhich 11,850 of them (63.91%) overlap with thesentences in the abstracts subcorpus6.
In order toget automatic parse trees, we train the Berkeleyparser with the remaining 6,691 sentences inGTB1.0, which achieves the performance of 85.22in F1-measure on the remaining 11,850 sentencesin GTB1.0.
Table 6 shows the performance ofscope identification on automatic parse trees andgolden cues.
In addition, we also report an oracleperformance to explore the best possible perform-ance of our system by assuming that our scopefinder can always correctly determine whether acandidate is an argument or not.
That is, if an ar-gument candidate falls within the golden scope,then it is a argument.
This is to measure the impactof automatic syntactic parsing itself.
Table 6 showsthat:1) For both negation and speculaiton scopeidentification, automatic syntactic parsinglowers the performance on the abstractssubcorpus (e.g., from 83.10% to 81.84% inaccuracy for negation scope identification andfrom 86.41% to 83.74% in accuracy forspeculaiton scope identification).
However, theperformance drop shows that both negation andspeculation scope identification are not assenstive to automatic syntactic parsing ascommon shallow semantic parsing, whoseperformance might decrease by about ~10 in F1-measure (Toutanova et al, 2005).
This indicatesthat scope identification via simplified shallowsemantic parsing is robust to some variations inthe parse trees.2) Although speculation scope identificationconsistently achieves higher performance thannegaiton scope identification when golden parsetrees are availabe, speculation scopeidentification achieves comparable performancewith negation scope identification on theabstracts subcorpus and the full papers6 There are a few cases where two sentences in the abstractssubcorpus map into one sentence in GTB1.0.subcorpus while speculation scope identificationeven performs ~20% lower in accuracy thannegation scope identification on the clinicalreport subcorpus.
This is largely due to thatspecuaiton scope identification is more sensitiveto syntactic parsing errors than negation scopeidentification due to the wider scope of aspeculation cue while the sentences of theclinical reports come from a different genre,which indicates low performance in syntacticparsing.3) Given the performance gap between theperformance of our scope finder and the oracleperformance, there is still much room for furtherperformance improvement.Task Method Abstracts Papers Clinicalauto 81.84 62.70 85.21 Negation scopeidentification oracle 94.37 83.33 98.39auto 83.74 61.29 67.90 Speculation scopeidentification oracle 95.69 83.72 83.29Table 6: Accuracy (%) of scope identification on thethree subcorpora using automatic parser trained on6,691 sentences in GTB1.0Task Method Abstracts Papers ClinicalM et al (2008) 57.33 n/a n/aM & D (2009a) 73.36 50.26 87.27Our baseline 73.42 53.70 88.42NegationscopeidentificationOur final  81.84 64.02 89.79M & D (2009b) 77.13 47.94 60.59?
& R (2009) 79.89 61.13 n/aOur baseline 77.39 54.55 61.92SpeculationscopeidentificationOur final  83.74 63.49 68.78Table 7: Performance comparison of our system withthe state-of-the-art ones in accuracy (%).
Note that allthe performances achieved on the full papers subcorpusand the clinical subcorpus are achieved using the wholeGTB1.0 corpus of 18,541 sentences while all the per-formances achieved on the abstract subcorpus areachieved using 6,691 sentences from GTB1.0 due tooverlap of the abstract subcorpus with GTB1.0.Table 7 compares our performance with relatedones.
It shows that even our baseline system withthe four basic features presented in Table 1achieves comparable performance with Morante etal.
(2008) and Morante and Daelemans (2009a &2009b).
This further indicates the appropriatenessof our simplified shallow semantic parsing ap-proach and the effectiveness of structured syntacticinformation on scope identification.
It also showsthat our final system significantly outperforms the721state-of-the-art ones using a chunking approach,especially on the abstracts and full papers subcor-pora.
However, the improvement on the clinicalreports subcorpora for negation scope identifica-tion is much less apparent, partly due to the factthat the sentences in this subcorpus are much sim-pler (with average length of 6.6 words per sentence)and thus a chunking approach can achieve highperformance.
Table 7 also shows that our parsingapproach to speculation scope identification out-performs the rule-based method in ?zg?r andRadev (2009), where 10-fold cross-validation isperformed on both the abstracts and the full paperssubcorpora.5.4 Experimental Results with AutomaticParse Trees and Automatic CuesSo far negation/speculation cues are assumed to bemanually annotated and available.
Here we turn toa more realistic scenario in which cues are auto-matically recognized.
In the following, we firstreport the results of cue recognition and then theresults of scope identification with automatic cues.Cue RecognitionTask Features R (%) P (%) F1CC + SW 93.80 94.39 94.09Negation cuerecognition CC+SW+SF 95.50 95.72 95.61CC + SW 83.77 92.04 87.71Speculation cuerecognition CC+SW+SF 84.33 93.07 88.49Table 8: Performance of automatic cue recognition withgold parse trees on the abstracts subcorpus using 10-foldcross-validationTable 8 lists the performance of cue recognition onthe abstracts subcorpus, assuming all words in thesentences as candidates.
It shows that as a com-plement to features derived from word/pos infor-mation (CC+SW features), structural features (SFfeatures) derived from the syntactic parse tree sig-nificantly improve the performance of cue recogni-tion by about 1.52 and 0.78 in F1-measure fornegation and speculation cue recognition, respec-tively, and thus included thereafter.
In addition, wehave also experimented on only these words,which happen to be a cue or inside a cue in thetraining data as cue candidates.
However, this ex-perimental setting achieves a lower performancethan that when all words are considered.Task Corpus R (%) P (%) F1Abstracts 94.99 94.35 94.67Papers 90.48 87.47 88.95Negation cuerecognitionClinical 86.81 88.54 87.67Abstracts 83.74 93.14 88.19Papers 73.02 82.31 77.39Speculation cuerecognitionClinical 33.33 91.77 48.90Table 9: Performance of automatic cue recognition withautomatic parse trees on the three subcorporaTable 9 presents the performance of cue recog-nition achieved with automatic parse trees on thethree subcorpora.
It shows that:1) The performance gap of cue recognitionbetween golden parse trees and automatic parsetrees on the abstracts subcorpus is not salient(e.g., 95.61 vs. 94.67 in F1-measure for negationcues and 88.49 vs. 88.19 for speculation cues),largely due to the features defined for cuerecognition are local and insenstive to syntacticvariations.2) The performance of negation cue recognition ishigher than that of speculation cue recognitionon all the three subcorpora.
This is prabably dueto the fact that the collection of negation cuewords or phrases is limitted while speculationcue words or phrases are more open.
This isillustrated by our statistics that about only 1%and 1% of negation cues in the full papers andthe clinical reports subcorpora are absent fromthe abstracts subcorpus, compared to about 6%and 20% for speculation cues.3) Unexpected, the recall of speculation cuerecognition on the clinical reports subcorpus isvery low (i.e., 33.33% in recall measure).
This isprobably due to the absence of about 20%speculation cues from the training data of theabstracts subcorpus.
Moreover, the speculationcue ?or?, which accounts for about 24% ofspecuaiton cues in the clinical reports subcorpus,only acheives about 2% in recall largely due tothe errors caused by the classifier trained on theabstracts subcorpus, where only about 11% ofwords ?or?
are annotated as speculation cues.Scope Identification with Automatic Cue Rec-ognitionTable 10 lists the performance of both negationand speculation scope identification with automaticcues and automatic parse trees.
It shows that auto-matic cue recognition lowers the performance by7223.34, 6.80, and 8.38 in F1-measure for negationscope identification on the abstracts, the full papersand the clinical reports subcorpora, respectively,while it lowers the performance by 6.50, 13.14 and31.23 in F1-measures for speculation scope identi-fication on the three subcorpora, respectively, sug-gesting the big challenge of cue recognition in thetwo scope learning tasks.Task Corpus R (%) P (%) F1Abstracts 78.77 78.24 78.50Papers 58.20 56.27 57.22Negation scopeidentificationClinical 80.62 82.22 81.41Abstracts 73.34 81.58 77.24Papers 47.51 53.55 50.35Speculation scopeidentificationClinical 25.59 70.46 37.55Table 10: Performance of both negation and speculationscope identification with automatic cues and automaticparse trees6 ConclusionIn this paper we have presented a new approach toscope learning by formulating it as a simplifiedshallow semantic parsing problem, which has beenextensively studied in the past few years.
In par-ticular, we regard the cue as the predicate and mapits scope into several constituents which aredeemed as arguments of the cue.
Evaluation on theBioscope corpus shows the appropriateness of ourparsing approach and that structured syntactic in-formation plays a critical role in capturing thedomination relationship between a cue and itsdominated arguments.
It also shows that our pars-ing approach outperforms the state-of-the-artchunking ones.
Although our approach is onlyevaluated on negation and speculation scope learn-ing here, it is portable to other kinds of scopelearning.For the future work, we will explore tree kernel-based methods to further improve the performanceof scope learning in better capturing the structuralinformation, and apply our parsing approach toother kinds of scope learning.AcknowledgmentsThis research was supported by Projects 60873150,60970056, and 90920004 under the National Natu-ral Science Foundation of China, Project20093201110006 under the Specialized ResearchFund for the Doctoral Program of Higher Educa-tion of China.ReferencesXavier Carreras and Llu?s M?rquez.
2005.
Introductionto the CoNLL-2005 Shared Task: Semantic Role La-beling.
CoNLL?
2005.Wendy W. Chapman, Will Bridewell, Paul Hanbury,Gregory F. Cooper, and Bruce G. Buchanan.
2001.
ASimple Algorithm for Identifying Negated Findingsand Diseases in Discharge Summaries.
Journal ofBiomedical Informatics, 34: 301-310.Nigel Collier, Hyun Seok Park, Norihiro Ogata, et al1999.
The GENIA Project: Corpus-Based Knowl-edge Acquisition and Information Extraction fromGenome Research Papers.
EACL?1999.Rich?rd Farkas, Veronika Vincze, Gy?rgy M?ra, J?nosCsirik, and Gy?rgy Szarvas.
2010.
The CoNLL-2010Shared Task: Learning to Detect Hedges and theirScope in Natural Language Text.
CoNLL?2010:Shared Task.Daniel Gildea and Martha Palmer.
2002.
The Necessityof Parsing for Predicate Argument Recognition.ACL?2002.Ilya M. Goldin and Wendy W. Chapman.
2003.
Learn-ing to Detect Negation with ?Not?
in Medical Texts.SIGIR?2003.Zheng Ping Jiang and Hwee Tou Ng.
2006.
SemanticRole Labeling of NomBank: A Maximum EntropyApproach.
EMNLP?
2006.Yoong Keok Lee and Hwee Tou Ng.
2002.
An Empiri-cal Evaluation of Knowledge Sources and LearningAlgorithms for Word Sense Disambiguation.EMNLP?2002.Junhui Li, Guodong Zhou, Hai Zhao, Qiaoming Zhu,and Peide Qian.
2009.
Improving Nominal SRL inChinese Language with Verbal SRL Information andAutomatic Predicate Recognition.
EMNLP?
2009.Marc Light, Xin Ying Qiu, and Padmini Srinivasan.2004.
The Language of Bioscience: Facts, Specula-tions, and Statements in Between.
BioLink?2004.Ben Medlock and Ted Briscoe.
2007.
Weakly Super-vised Learning for Hedge Classification in ScientificLiterature.
ACL?2007.Roser Morante, Anthony Liekens, and Walter Daele-mans.
2008.
Learning the Scope of Negation in Bio-medical Texts.
EMNLP?2008.723Roser Morante and Walter Daelemans.
2009a.
AMetalearning Approach to Processing the Scope ofNegation.
CoNLL?2009.Roser Morante and Walter Daelemans.
2009b.
Learningthe Scope of Hedge Cues in Biomedical Texts.BioNLP?2009.Lilja ?vrelid, Erik Velldal, and Stephan Oepen.
2010.Syntactic Scope Resolution in Uncertainty Analysis.COLING?2010.Arzucan ?zg?r, Dragomir R. Radev.
2009.
DetectingSpeculations and their Scopes in Scientific Text.EMNLP?2009.Slav Petrov and Dan Klein.
2007.
Improved Inferencefor Unlexicalized Parsing.
NAACL?2007.Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2005.The Necessity of Syntactic Parsing for Semantic RoleLabeling.
IJCAI?
2005.Gy?rgy Szarvas.
2008.
Hedge Classification in Bio-medical Texts with a Weakly Supervised Selection ofKeywords.
ACL?2008.Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas, andJ?nos Csirik.
2008.
The BioScope corpus: Annota-tion for Negation, Uncertainty and their Scope inBiomedical Texts.
BioNLP?2008.Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, andJun?ichi Tsujii.
2005.
Syntax Annotation for theGENIA Corpus.
IJCNLP?2005 (Companion volume).Peter D. Turney.
2002.
Thumbs Up or Thumbs Down?Semantic Orientation Applied to Unsupervised Clas-sification of Reviews.
ACL?2002.Veronika Vincze, Gy?rgy Szarvas, Rich?rd Farkas,Gy?rgy M?ra, and J?nos Csirik.
2008.
The BioScopecorpus: biomedical texts annotated for uncertainty,negation and their scopes.
BMC Bioinformatics,9(Suppl 11):S9.Nianwen Xue and Martha Palmer.
2004.
CalibratingFeatures for Semantic Role Labeling.
EMNLP?2004.Nianwen Xue.
2008.
Labeling Chinese Predicates withSemantic Roles.
Computational Linguistics,34(2):225-255.724
