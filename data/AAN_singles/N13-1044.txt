Proceedings of NAACL-HLT 2013, pages 426?432,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsMorphological Analysis and Disambiguation for Dialectal ArabicNizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi TomehCenter for Computational Learning SystemsColumbia University{habash,ryanr,rambow,reskander,nadi}@ccls.columbia.eduAbstractThe many differences between Dialectal Ara-bic and Modern Standard Arabic (MSA) posea challenge to the majority of Arabic naturallanguage processing tools, which are designedfor MSA.
In this paper, we retarget an exist-ing state-of-the-art MSA morphological tag-ger to Egyptian Arabic (ARZ).
Our evalua-tion demonstrates that our ARZ morphologytagger outperforms its MSA variant on ARZinput in terms of accuracy in part-of-speechtagging, diacritization, lemmatization and to-kenization; and in terms of utility for ARZ-to-English statistical machine translation.1 IntroductionDialectal Arabic (DA) refers to the day-to-day na-tive vernaculars spoken in the Arab World.
DAis used side by side with Modern Standard Arabic(MSA), the official language of the media and edu-cation (Holes, 2004).
Although DAs are historicallyrelated to MSA, there are many phonological, mor-phological and lexical differences between them.Unlike MSA, DAs have no standard orthographiesor language academies.
Furthermore, different DAs,such as Egyptian Arabic (henceforth, ARZ), Levan-tine Arabic or Moroccan Arabic have important dif-ferences among them, similar to those seen amongRomance languages (Holes, 2004; Abdel-Massih etal., 1979).
Most tools and resources developed fornatural language processing (NLP) of Arabic are de-signed for MSA.
Such resources are quite limitedwhen it comes to processing DA, e.g., a state-of-the-art MSA morphological analyzer only has 60%coverage of Levantine Arabic verb forms (Habashand Rambow, 2006).In this paper, we describe the process of retar-geting an existing state-of-the-art tool for model-ing MSA morphology disambiguation to ARZ, themost commonly spoken DA.
The MSA tool weextend is MADA ?
Morphological Analysis andDisambiguation of Arabic (Habash and Rambow,2005).
The approach used in MADA, which wasinspired by earlier work by Hajic?
(2000), disam-biguates in context for every aspect of Arabic mor-phology, thus solving all tasks in ?one fell swoop?.The disadvantage of the MADA approach is its de-pendence on two complex resources: a morpholog-ical analyzer for the language and a large collectionof manually annotated words for all morphologicalfeatures in the same representation used by the an-alyzer.
For ARZ, such resources have recently be-come available, with the development of the CAL-IMA ARZ morphological analyzer (Habash et al2012b) and the release by the Linguistic Data Con-sortium (LDC) of a large ARZ corpus annotatedmorphologically in a manner compatible with CAL-IMA (Maamouri et al 2012a).
In the work pre-sented here, we utilize these new resources withinthe paradigm of MADA, transforming MADA intoMADA-ARZ.
The elegance of the MADA solutionmakes this conceptually a simple extension.Our evaluation demonstrates that our EgyptianDA version of MADA, henceforth MADA-ARZ,outperforms MADA for MSA on ARZ morpholog-ical tagging and improves the quality of ARZ to En-glish statistical machine translation (MT).The rest of this paper is structured as follows:Section 2 discusses related work.
Section 3 presentsthe challenges of processing Arabic dialects.
Sec-tion 4 outlines our approach.
And Section 5 presentsand discusses our evaluation results.4262 Related WorkThere has been a considerable amount of work onMSA morphological analysis, disambiguation, part-of-speech (POS) tagging, tokenization, lemmatiza-tion and diacritization; for an overview, see (Habash,2010).
Most solutions target specific problems, suchas diacritization (Zitouni et al 2006), tokenizationor POS tagging (Diab et al 2007).
In contrast,MADA provides a solution to all of these problemstogether (Habash and Rambow, 2005).Previous work on DA morphological tagging fo-cused on creating resources, using noisy or in-complete annotations, and using unsupervised/semi-supervised methods.
Duh and Kirchhoff (2005)adopt a minimally supervised approach that only re-quires raw text data from several DAs, as well as aMSA morphological analyzer.
They report a POSaccuracy of 70.9% on a rather coarse-grained POStagset (17 tags).Al-Sabbagh and Girju (2012) describe a super-vised tagger for Egyptian Arabic social networkingcorpora trained using transformation-based learning(Brill, 1995).
They report 94.5% F-measure on to-kenization and 87.6% on POS tagging.
Their tok-enization and POS tagsets are comparable to the setused by the Arabic Treebank (ATB).
We do not com-pare to them since their data sets are not public.Stallard et al(2012) show that unsupervisedmethods for learning DA tokenization can outper-form MSA tokenizers on MT from Levantine Ara-bic to English.
We do not compare to them directlysince our work is on ARZ.
However, we carry a sim-ilar MT experiment in Section 5.Mohamed et al(2012) annotated a small corpusof Egyptian Arabic for morphological segmentationand learned segmentation models using memory-based learning (Daelemans and van den Bosch,2005).
Their best system achieves a 91.90% accu-racy on the task of morpheme-segmentation.
Wecompare to their work and report on their test setin Section 5.There are some other morphological analyzers forDA.
Kilany et al(2002) worked on ARZ, but theanalyzer has very limited coverage.
Their lexiconwas used as part of the development of CALIMA(Habash et al 2012b).
Other efforts are not aboutARZ (Habash and Rambow, 2006; Salloum andHabash, 2011).Given the similarity between MSA and DA, therehas been some work on mapping DA to MSA toexploit rich MSA resources (Chiang et al 2006;Abo Bakr et al 2008; Salloum and Habash, 2011;Salloum and Habash, 2013).
Other researchers havestudied the value of simply combining DA andMSA data, such as Zbib et al(2012) for DA to En-glish MT.
In our approach, we target DA directly,and we evaluate the use of additional MSA anno-tated resources to our training in Section 5.3 Arabic Dialect ChallengesGeneral Arabic Challenges Arabic, as MSA orDA, poses many challenges for NLP.
Arabic is amorphologically complex language which includesrich inflectional morphology and a number of cli-tics.
For example, the MSA word A?
E?J.J?J??
wsyk-tbwnhA (wa+sa+ya-ktub-uwna+hA)1 ?and they willwrite it [lit.
and+will+they-write-they+it]?
has twoproclitics, one circumfix and one pronominal en-clitic.
Additionally, Arabic has a high degree ofambiguity resulting from its diacritic-optional writ-ing system and common deviation from spellingstandards (e.g., Alif and Ya variants) (Buckwalter,2007).
The Standard Arabic Morphological Ana-lyzer for (SAMA) (Graff et al 2009) produces 12analyses per MSA word on average.Differences between ARZ and MSA As men-tioned above, most tools developed for MSA cannotbe expected to perform well on ARZ.
This is dueto the numerous differences between the two vari-ants.
Lexically, the number of differences is quitesignificant.
For example, ARZ?QK.
Q?
Trbyzh?
?table?corresponds to MSA???A?
TAwlh?.
Phonologically,there are many important differences which relateto orthography in DA, e.g., the MSA consonant H/?/ is pronounced as /t/ in ARZ (or /s/ in more re-cent borrowings from MSA); for a fuller discussion,see (Habash, 2010; Habash et al 2012a).
Examplesof morphological differences include changes in the1Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al 2007): (in alphabetical or-der) Abt?jHxd?rzs?SDTD??
?fqklmnhwy and the additional sym-bols: ?
Z, ?
@, A?
@, A?@, w??
', y?
Z?
', h??, ?
?.427morpheme form, e.g., the MSA future proclitic +?sa+ appears in ARZ as +?
ha+.
There are somemorphemes in ARZ that do not exist in MSA suchas the negation circum-clitic ?+ .
.
.
+ A?
mA+ .
.
.
+?.And there are MSA features that are absent fromARZ, most notably case and mood.Since there are no orthographic standards, ARZwords may be written in a variety of ways reflect-ing different writing rules, e.g., phonologically oretymologically.
A conventional orthography for Di-alectal Arabic (CODA) has been proposed and usedfor writing ARZ in the context of NLP applications(Habash et al 2012a; Al-Sabbagh and Girju, 2012;Eskander et al 2013).
Finally, MSA and ARZ co-exist and are often used interchangeably, especiallyin more formal settings.
The CALIMA morpholog-ical analyzer we use addresses several of these issuesby modeling both ARZ and MSA together, includ-ing a limited set of inter-dialect morphology phe-nomena, and by mapping ARZ words into CODAorthography internally while accepting a wide rangeof spelling variants.4 Approach4.1 The MADA ApproachMADA is a method for Arabic morphological anal-ysis and disambiguation (Habash and Rambow,2005; Roth et al 2008).
MADA uses a morpholog-ical analyzer to produce, for each input word, a listof analyses specifying every possible morphologicalinterpretation of that word, covering all morphologi-cal features of the word (diacritization, POS, lemma,and 13 inflectional and clitic features).
MADA thenapplies a set of models (support vector machinesand N-gram language models) to produce a predic-tion, per word in-context, for different morpholog-ical features, such as POS, lemma, gender, numberor person.
A ranking component scores the analy-ses produced by the morphological analyzer using atuned weighted sum of matches with the predictedfeatures.
The top-scoring analysis is chosen as thepredicted interpretation for that word in context.4.2 Extending MADA into MADA-ARZAdjusting MADA to handle DA requires a numberof modifications.
The most significant change is re-placing the MSA analyzer SAMA with the ARZanalyzer CALIMA to address the differences out-lined in Section 3.
In addition, new feature predic-tion models are needed; these are trained using ARZdata sets annotated by the LDC (Maamouri et al2006; Maamouri et al 2012b).
The data sets werenot usable as released due to numerous annotationinconsistencies and differences from CALIMA, aswell due to gaps in CALIMA.
We synchronized theannotations with the latest version of CALIMA fol-lowing a technique described by Habash and Ram-bow (2005).
The result of this synchronization stepis the data we use in this study (for training, de-velopment and testing).
Our synchronized annota-tions fully match the LDC annotations in 90% of thewords (in full morphological tag).
We performed amanual analysis on randomly chosen 100 words thatdid not fully match.
The choice we made is cor-rect or acceptable in 55% of the cases of mismatchwith the LDC annotation, which means that the ourchoice is accurate in over 95% of all cases.Some of the original MADA features (whichwere needed for MSA) are not used in ARZ andso are dropped in MADA-ARZ; these features arecase, mood, the question-marking proclitic, stateand voice.
Additional ARZ feature values have beenadded, e.g., to handle the progressive particle andfuture marker, among others.
These are providedby CALIMA and are classified and selected byMADA-ARZ.
In our current implementation, ARZfeatures that are not present in MSA, such as thenegation and indirect-object enclitics, are not classi-fied by MADA-ARZ classifiers, but since they areprovided by CALIMA they can be selected by thewhole MADA-ARZ system.5 EvaluationWe evaluate MADA-ARZ intrinsically ?
in termsof performance on morphological disambiguation?
and extrinsically in the context of MT.5.1 POS Tagging, Diacritization,Lemmatization and SegmentationExperimental Settings We use two sets of anno-tated data from the LDC: ATB-123, which includesparts 1, 2 and 3 of the MSA Penn Arabic Treebank428Development TestMADA MADA-ARZ MADA MADA-ARZTrain Data MSA ARZ ALL MSA ARZ ALLMorph Tag 35.8 84.0 77.3 35.7 84.5 75.5Penn POS 77.5 89.6 90.2 79.0 90.0 90.1MADA POS 80.7 90.8 91.3 82.1 91.1 91.4Diacritic 31.3 82.6 72.9 32.2 83.2 72.2Lemma 64.0 85.2 81.6 67.1 86.3 82.8Full 26.2 74.3 65.4 27.0 75.4 64.7ATB Segmentation 90.6 97.4 97.6 90.5 97.4 97.5Table 1: Evaluation metrics on the ATB-ARZ development and test sets.
The best results are bolded.
We compareMADA and MADA-ARZ with different training data conditions.
Definitions of metrics are in Section 5.1.
MSAtraining data is ATB-123.
ARZ training data is ATB-ARZ.
ALL training data is ATB-123 plus ATB-ARZ.
(Maamouri et al 2004); and ATB-ARZ, the Egyp-tian Arabic Treebank (parts 1-5) (Maamouri et al2012a).
For ATB-123 training, we use all of parts 1and 2 plus the training portion of ATB-3 (as definedby Zitouni et al(2006)); for development and test,we split Zitouni et al(2006)?s devtest set into two.We sub-divide ATB-ARZ into development, train-ing, and test sets (roughly a 10/80/10 split).
TheATB-ARZ training data has 134K words, and theATB-123 training data has 711K words.We evaluate two systems.
We used the latest re-lease of MADA for MSA (v3.2), trained on ATB-123 (MSA), as our baseline.
For MADA-ARZ,we compare two training settings: using ATB-ARZ(ARZ) and combining ATB-ARZ with ATB-123(ALL).
We present our results on the ATB-ARZdevelopment and blind test sets (21.1K words and20.4K words).
Tuning for MADA-ARZ was doneusing a random 10% of the ATB-ARZ training data,which was later integrated back into the training set.Metrics We use several evaluation metrics to mea-sure the effectiveness of MADA-ARZ.
Morph Tagrefers to the accuracy of correctly predicting the fullCALIMA morphological tag (i.e., not the diacriticsor the lemma).
Penn POS and MADA POS are alsotag accuracy metrics.
Penn POS, also known as theReduced Tag Set, is a tag set reduction of the fullArabic morphological tag set, which was proposedfor MSA (Kulick et al 2006; Diab, 2007; Habash,2010); since it retains no MSA-specific morpholog-ical features, it also makes sense for ARZ.
MADAPOS is the small POS tag set (36 tags) MADA usesinternally.
Diacritic and Lemma are the accura-cies of the choice of diacritized form and Lemma,respectively.
Full is the harshest metric, requiringthat every morphological feature of the chosen anal-ysis be correct.
Finally, ATB Segmentation is thepercentage of words with correct ATB segmentation(splitting off all clitics except for the determiner +?
@Al+).Results The results are shown in Table 1.MADA-ARZ performs much better than theMADA baselines in all evaluation metrics.
Compar-ing the two MADA-ARZ systems, it is evident thatadding MSA data (ATB123) results in slightly betterperformance only for the Penn POS, MADA POS,and ATB Segmentation metrics.
Including the MSAdata results in accuracy reductions for the other met-rics, but the resulting system still outperforms theMADA MSA baseline in all cases.
The results areconsistent for development and blind test.The CMUQ-ECA Test Set Mohamed et al(2012) reported on the task of ARZ raw orthogra-phy morph segmentation (determining the morphsin the raw word).
The CMUQ-ECA test datacomprised 36 ARZ political comments and jokesfrom the Egyptian web site www.masrawy.com.The set contains 2,445 words including punctua-tion.
Their best system gets a 91.9% word-level ac-curacy.
Since MADA-ARZ modifies the spelling429Tokenization OOV BLEU METEOR TERPunct 9.2 22.1 27.2 63.2MADA ATB 5.8 24.4 29.6 60.5MADA-ARZ ATB 4.9 25.2 29.9 59.4Table 2: Machine translation results on the test set.
?Punct?
refers to the baseline which only tokenizes at punctuation.of the word when it maps into CODA, we neededa manual analysis where no exact match with thegold occurs (11.8% of the time).
We determinedMADA-ARZ?s accuracy on their test set for morph-segmentation to be 93.2%.5.2 Egyptian Arabic to English MTMT Experimental Settings We use the open-source Moses toolkit (Koehn et al 2007) to builda phrase-based SMT system.
We use MGIZA++for word alignment (Gao and Vogel, 2008).
Phrasetranslations of up to 8 words are extracted in thephrase table.
We use SRILM (Stolcke, 2002) withmodified Kneser-Ney smoothing to build two 4-gram language models.
The first model is trainedon the English side of the bitext, while the otheris trained on the English Gigaword data.
Featureweights are tuned to maximize BLEU (Papineni etal., 2002) on a development set using Minimum Er-ror Rate Training (Och, 2003).
We perform case-insensitive evaluation in terms of BLEU , METEOR(Banerjee and Lavie, 2005) and TER (Snover et al2006) metrics.Data We trained on DA-English parallel data(Egyptian and Levantine) obtained from severalLDC corpora.
The training data amounts to 3.8Muntokenized words on the Arabic side.
The dev set,used for tuning the parameters of the MT system,has 15,585 untokenized Arabic words.
The test sethas 12,116 untokenized Arabic words.
Both dev andtest data contain two sets of reference translations.The English data is lower-cased and tokenized usingsimple punctuation-based rules.Systems We build three translation systems whichvary in tokenization of the Arabic text.
The firstsystem applies only simple punctuation-based rules.The second and third systems use MADA andMADA-ARZ, respectively, to tokenize the Arabictext in the ATB tokenization scheme (Habash andSadat, 2006).
The Arabic text is also Alif/Ya nor-malized.Results The MT results are in Table 2, which alsoshows the percentage of out-of-vocabulary (OOV)words ?
test words not in the training data.
MADA-ARZ delivers the best translation performance ac-cording to all metrics.
All MADA-ARZ improve-ments over MADA are statistically significant atthe .01 level (except in the case of METEOR).
Allimprovements over Punct by MADA and MADA-ARZ are also statistically significant.
For BLEUscores, we observe 3.1% absolute improvement toPunct (14% relative), and 0.8% absolute improve-ment to MADA (3.3% relative).
In addition to bet-ter morphological disambiguation, MADA-ARZreduces the OOV ratio (16% relative to MADA),which we suspect contributes to the observed im-provements in MT quality.6 Conclusion and Future WorkWe have presented MADA-ARZ, a system formorphological tagging of ARZ.
We have shownthat it outperforms an state-of-the-art MSA tagger(MADA) on ARZ text, and that it helps ARZ-to-English machine translation more than MADA.In the future, we intend to perform further featureengineering to improve the results of MADA-ARZ,and extend the system to handle other DAs.AcknowledgmentsThis paper is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-12-C-0014.Any opinions, findings and conclusions or recom-mendations expressed in this paper are those of theauthors and do not necessarily reflect the views ofDARPA.430ReferencesErnest T. Abdel-Massih, Zaki N. Abdel-Malek, and El-Said M. Badawi.
1979.
A Reference Grammar ofEgyptian Arabic.
Georgetown University Press.Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.2008.
A Hybrid Approach for Converting WrittenEgyptian Colloquial Dialect into Diacritized Arabic.In The 6th International Conference on Informaticsand Systems, INFOS2008.
Cairo University.Rania Al-Sabbagh and Roxana Girju.
2012.
A super-vised POS tagger for written Arabic social network-ing corpora.
In Jeremy Jancsary, editor, Proceedingsof KONVENS 2012, pages 39?52.
?GAI, September.Main track: oral presentations.Satanjeev Banerjee and Alon Lavie.
2005.
METEOR:An Automatic Metric for MT Evaluation with Im-proved Correlation with Human Judgments.
In Pro-ceedings of the ACL Workshop on Intrinsic and Ex-trinsic Evaluation Measures for Machine Transla-tion and/or Summarization, pages 65?72, Ann Arbor,Michigan.Eric Brill.
1995.
Transformation-Based Error-DrivenLearning and Natural Language Processing: A CaseStudy in Part-of-Speech Tagging.
Computational Lin-guistics, 21(4):543?565.Tim Buckwalter.
2007.
Issues in Arabic Morphologi-cal Analysis.
In A. van den Bosch and A. Soudi, edi-tors, Arabic Computational Morphology: Knowledge-based and Empirical Methods.
Springer.David Chiang, Mona Diab, Nizar Habash, Owen Ram-bow, and Safiullah Shareef.
2006.
Parsing ArabicDialects.
In Proceedings of the European Chapter ofACL (EACL).Walter Daelemans and Antal van den Bosch.
2005.Memory-Based Language Processing.
Studies inNatural Language Processing.
Cambridge UniversityPress, Cambridge, UK.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2007.Automated methods for processing arabic text: Fromtokenization to base phrase chunking.
In Antalvan den Bosch and Abdelhadi Soudi, editors, ArabicComputational Morphology: Knowledge-based andEmpirical Methods.
Kluwer/Springer.Mona Diab.
2007.
Improved Arabic Base Phrase Chunk-ing with a New Enriched POS Tag Set.
In Proceedingsof the 2007 Workshop on Computational Approachesto Semitic Languages: Common Issues and Resources,pages 89?96, Prague, Czech Republic, June.Kevin Duh and Katrin Kirchhoff.
2005.
POS tagging ofdialectal Arabic: a minimally supervised approach.
InProceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, Semitic ?05, pages55?62, Ann Arbor, Michigan.Ramy Eskander, Nizar Habash, Owen Rambow, and NadiTomeh.
2013.
Processing Spontaneous Orthogra-phy.
In Proceedings of the 2013 Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies (NAACL-HLT), Atlanta, GA.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, SETQA-NLP ?08, pages 49?57,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.David Graff, Mohamed Maamouri, Basma Bouziri,Sondos Krouna, Seth Kulick, and Tim Buckwal-ter.
2009.
Standard Arabic Morphological Analyzer(SAMA) Version 3.1.
Linguistic Data ConsortiumLDC2009E73.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and MorphologicalDisambiguation in One Fell Swoop.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL?05), pages 573?580, AnnArbor, Michigan.Nizar Habash and Owen Rambow.
2006.
MAGEAD:A Morphological Analyzer and Generator for the Ara-bic Dialects.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 681?688, Sydney, Australia.Nizar Habash and Fatiha Sadat.
2006.
Arabic Prepro-cessing Schemes for Statistical Machine Translation.In Proceedings of the 7th Meeting of the North Ameri-can Chapter of the Association for Computational Lin-guistics/Human Language Technologies Conference(HLT-NAACL06), pages 49?52, New York, NY.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van den Boschand A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash, Mona Diab, and Owen Rabmow.
2012a.Conventional Orthography for Dialectal Arabic.
InProceedings of the Language Resources and Evalua-tion Conference (LREC), Istanbul.Nizar Habash, Ramy Eskander, and Abdelati Hawwari.2012b.
A Morphological Analyzer for EgyptianArabic.
In NAACL-HLT 2012 Workshop on Com-putational Morphology and Phonology (SIGMOR-PHON2012), pages 1?9.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Publish-ers.Jan Hajic?.
2000.
Morphological tagging: Data vs. dic-tionaries.
In Proceedings of the 1st Meeting of the431North American Chapter of the Association for Com-putational Linguistics (NAACL?00), Seattle, WA.Clive Holes.
2004.
Modern Arabic: Structures, Func-tions, and Varieties.
Georgetown Classics in Ara-bic Language and Linguistics.
Georgetown UniversityPress.H.
Kilany, H. Gadalla, H. Arram, A. Yacoub, A. El-Habashi, and C. McLemore.
2002.
EgyptianColloquial Arabic Lexicon.
LDC catalog numberLDC99L22.Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-pher Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Christopher Dyer, Ondrej Bo-jar, Alexandra Constantin, and Evan Herbst.
2007.Moses: open source toolkit for statistical machinetranslation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public.Seth Kulick, Ryan Gabbard, and Mitch Marcus.
2006.Parsing the Arabic Treebank: Analysis and Improve-ments.
In Proceedings of the Treebanks and Linguis-tic Theories Conference, pages 31?42, Prague, CzechRepublic.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank :Building a Large-Scale Annotated Arabic Corpus.
InNEMLAR Conference on Arabic Language Resourcesand Tools, pages 102?109, Cairo, Egypt.Mohamed Maamouri, Ann Bies, Tim Buckwalter, MonaDiab, Nizar Habash, Owen Rambow, and DalilaTabessi.
2006.
Developing and Using a Pilot Dialec-tal Arabic Treebank.
In The fifth international confer-ence on Language Resources and Evaluation (LREC),pages 443?448, Genoa, Italy.Mohamed Maamouri, Ann Bies, Seth Kulick, DalilaTabessi, and Sondos Krouna.
2012a.
Egyptian Ara-bic Treebank Pilot.Mohamed Maamouri, Sondos Krouna, Dalila Tabessi,Nadia Hamrouni, and Nizar Habash.
2012b.
EgyptianArabic Morphological Annotation Guidelines.Emad Mohamed, Behrang Mohit, and Kemal Oflazer.2012.
Annotating and Learning Morphological Seg-mentation of Egyptian Colloquial Arabic.
In Proceed-ings of the Language Resources and Evaluation Con-ference (LREC), Istanbul.Franz Josef Och.
2003.
Minimum Error Rate Trainingfor Statistical Machine Translation.
In Proceedingsof the 41st Annual Conference of the Association forComputational Linguistics, pages 160?167, Sapporo,Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA.Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,and Cynthia Rudin.
2008.
Arabic morphological tag-ging, diacritization, and lemmatization using lexememodels and feature ranking.
In ACL 2008: The Con-ference of the Association for Computational Linguis-tics; Companion Volume, Short Papers, Columbus,Ohio.Wael Salloum and Nizar Habash.
2011.
Dialectalto Standard Arabic Paraphrasing to Improve Arabic-English Statistical Machine Translation.
In Proceed-ings of the First Workshop on Algorithms and Re-sources for Modelling of Dialects and Language Va-rieties, pages 10?21, Edinburgh, Scotland.Wael Salloum and Nizar Habash.
2013.
Dialectal Ara-bic to English Machine Translation: Pivoting throughModern Standard Arabic.
In Proceedings of the 2013Conference of the North American Chapter of the As-sociation for Computational Linguistics: Human Lan-guage Technologies (NAACL-HLT), Atlanta, GA.Matt Snover, Bonnie J. Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Studyof Translation Error Rate with Targeted Human An-notation.
In Proceedings of the Association for Ma-chine Transaltion in the Americas (AMTA 2006), Cam-bridge, Massachusetts.David Stallard, Jacob Devlin, Michael Kayser,Yoong Keok Lee, and Regina Barzilay.
2012.Unsupervised Morphology Rivals Supervised Mor-phology for Arabic MT.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics, pages 322?327, Jeju Island, Korea.Andreas Stolcke.
2002.
SRILM - an Extensible Lan-guage Modeling Toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Processing(ICSLP), volume 2, pages 901?904, Denver, CO.Rabih Zbib, Erika Malchiodi, Jacob Devlin, DavidStallard, Spyros Matsoukas, Richard Schwartz, JohnMakhoul, Omar F. Zaidan, and Chris Callison-Burch.2012.
Machine translation of arabic dialects.
In Pro-ceedings of the 2012 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 49?59, Montr?al, Canada.Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya.2006.
Maximum entropy based restoration of ara-bic diacritics.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics and44th Annual Meeting of the Association for Computa-tional Linguistics, pages 577?584, Sydney, Australia.432
