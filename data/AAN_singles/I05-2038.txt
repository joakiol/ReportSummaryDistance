Syntax annotation for the GENIA corpusYuka Tateisi1 Akane Yakushiji2 Tomoko Ohta1 Jun?ichi Tsujii2,3,11 CREST, Japan Science and Technology Agency4-1-8, Honcho, Kawaguchi-shi, Saitama 332-0012 Japan2 Department of Computer Science, University of Tokyo7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan3 School of Informatics, University of ManchesterPOBox 88, Sackville St, MANCHESTER M60 1QD, UK{yucca,akane,okap,tsujii}@is.s.u-tokyo.ac.jpAbstractLinguistically annotated corpus basedon texts in biomedical domain has beenconstructed to tune natural languageprocessing (NLP) tools for bio-textmining.
As the focus of informationextraction is shifting from "nominal"information such as named entity to"verbal" information such as functionand interaction of substances, applica-tion of parsers has become one of thekey technologies and thus the corpusannotated for syntactic structure of sen-tences is in demand.
A subset of theGENIA corpus consisting of 500MEDLINE abstracts has been anno-tated for syntactic structure in an XML-based format based on Penn TreebankII (PTB) scheme.
Inter-annotatoragreement test indicated that the writ-ing style rather than the contents of theresearch abstracts is the source of thedifficulty in tree annotation, and thatannotation can be stably done by lin-guists without much knowledge of bi-ology with appropriate guidelinesregarding to linguistic phenomena par-ticular to scientific texts.1 IntroductionResearch and development for information ex-traction from biomedical literature (bio-textmining) has been rapidly advancing due todemands caused by information overload in thegenome-related field.
Natural language process-ing (NLP) techniques have been regarded asuseful for this purpose.
Now that focus of in-formation extraction is shifting from extractionof ?nominal?
information such as named entityto ?verbal?
information such as relations of enti-ties including events and functions, syntacticanalysis is an important issue of NLP applica-tion in biomedical domain.
In extraction of rela-tion, the roles of entities participating in therelation must be identified along with the verbthat represents the relation itself.
In text analysis,this corresponds to identifying the subjects, ob-jects, and other arguments of the verb.Though rule-based relation information ex-traction systems using surface pattern matchingand/or shallow parsing can achieve high-precision (e.g.
Koike et al, 2004) in a particulartarget domain, they tend to suffer from low re-call due to the wide variation of the surface ex-pression that describe a relation between a verband its arguments.
In addition,  the portability ofsuch systems is low because the system has tobe re-equipped with different set of rules whendifferent kind of relation is to be extracted.
Onesolution to this problem is using deep parserswhich can abstract the syntactic variation of arelation between a verb and its arguments repre-sented in the text, and constructing extractionrule on the abstract predicate-argument structure.To do so, wide-coverage and high-precisionparsers are required.While basic NLP techniques are relativelygeneral and portable from domain to domain,customization and tuning are inevitable, espe-cially in order to apply the techniques effec-tively to highly specialized literatures such asresearch papers and abstracts.
As recent ad-vances in NLP technology depend on machine-learning techniques, annotated corpora fromwhich system can acquire rules (includinggrammar rules, lexicon, etc.)
are indispensable220resources for customizing general-purpose NLPtools.
In bio-textmining, for example, trainingon part-of-speech (POS)-annotated GENIA cor-pus was reported to improve the accuracy ofJunK tagger (English POS tagger) (Kazama etal., 2001) from  83.5% to 98.1% on MEDLINEabstracts (Tateisi and Tsujii, 2004), and theFraMed corpus (Wermter and Hahn, 2004) wasused to train TnT tagger on German (Brants,2000) to improve its accuracy from 95.7% to98% on clinical reports and other biomedicaltexts.
Corpus annotated for syntactic structuresis expected to play a similar role in tuning pars-ers to biomedical domain, i.e., similar improve-ment on the performance of parsers is expectedby using domain-specific treebank as a resourcefor learning.
For this purpose, we constructGENA Treebank (GTB), a treebank on researchabstracts in biomedical domain.2 Outline of the CorpusThe base text of GTB is that of the GENIA cor-pus constructed at University of Tokyo (Kim etal., 2003), which is a collection of research ab-stracts selected from the search results ofMEDLINE database with keywords (MeSHterms) human, blood cells and transcription fac-tors.
In the GENIA corpus, the abstracts are en-coded in an XML scheme where each abstract isnumbered with MEDLINE UID and containstitle and abstract.
The text  of title and abstract issegmented into sentences in which biologicalterms are annotated with their semantic classes.The GENIA corpus is also annotated for part-of-speech (POS) (Tateisi and Tsujii, 2004), andcoreference is also annotated in a part of theGENIA corpus by MedCo project at Institute forInfocomm Research, Singapore (Yang et al2004).GTB is the addition of syntactic informationto the GENIA corpus.
By annotating variouslinguistic information on a same set of text, theGENIA corpus will be a resource not only forindividual purpose such as named entity extrac-tion or training parsers but also for integratedsystems such as information extraction usingdeep linguistic analysis.
Similar attempt of con-structing integrated corpora is being done inUniversity of Pennsylvania, where a corpus ofMEDLINE abstracts in CYP450 and oncologydomains where annotated for named entities,POS, and tree structure of sentences (Kulick etal, 2004).2.1 Annotation SchemeThe annotation scheme basically follows thePenn Treebank II (PTB) scheme (Beis et al1995), encoded in XML.
A non-null constituentis marked as an element, with its syntactic cate-gory (which may be combined with its functiontags indicating grammatical roles such as  -SBJ,-PRD, and -ADV) used as tags.
A null constitu-ent is marked as a childless element whose tagcorresponds to its categories.
Other function tagsare encoded as attributes.
Figure 1 shows an ex-ample of annotated sentence in XML, and thecorresponding PTB notation.
The label ?S?means ?sentence?, ?NP?
noun phrase, ?PP?prepositional phrase, and ?VP?
verb phrase.The label ?NP-SBJ?
means that the element isan NP that serves as the subject of the sentence.A null element, the trace of the object of ?stud-ied?
moved by passivization, is denoted by?
<NP NULL="NONE" ref="i55"/>?
in XMLand ?*-55?
in PTB notation.
The number ?55?which refers to the identifier of the moved ele-ment, is denoted by ?id?
and ?ref?
attributes inXML, and is denoted as a part of a label in PTB.In addition to changing the encoding, wemade some modifications to the scheme.
First,analysis within the noun phrase is simplified.Second, semantic division of adverbial phrasessuch as ??TMP?
(time) and ??MNR?
(manner)are not used: adverbial constituents other than?ADVP?
(adverbial phrases) or ?PP?
used ad-verbially are marked with ?ADV tags but notwith semantic tags.
Third, a coordination struc-ture is explicitly marked with the attributeSYN=?COOD?
whereas in the original PTBscheme it is not marked as such.In our GTB scheme, ?NX?
(head of a com-plex noun phrase) and ?NAC?
(a certain kind ofnominal modifier within a noun phrase) of thePTB scheme are not used.
A noun phrase is gen-erally left unstructured.
This is mainly in orderto simplify the process of annotation.
In case ofbiomedical abstracts, long noun phrases ofteninvolve multi-word technical terms whose syn-tactic structure is difficult to determine withoutdeep domain knowledge.
However, the structureof noun phrases are usually independent of thestructure outside the phrase, so that it would be221easier to analyze the phrases involving suchterms independently (e.g.
by biologists) andlater merge the two analysis together.
Thus wehave decided that we leave noun phrases un-structured in GTB annotation unless their analy-sis is necessary for determining the structureoutside the phrase.
One of the exception is thecases that involves coordination where it is nec-essary to explicitly mark up the coordinatedconstituents.In addition, we have added special attributes?TXTERR?, ?UNSURE?,  and ?COMMENT?for later inspection.
The ?TXTERR?
is usedwhen the annotator suspects that there is agrammatical error in the original text; the?UNSURE?
attribute is used when the annotatoris not confident; and the ?COMMENT?
is usedfor free comments (e.g.
reason of using?UNSURE?)
by the annotator.2.2   Annotation ProcessThe sentences in the titles and abstracts of thebase text of GENIA corpus are annotated manu-ally using an XML editor used for the GlobalDocument Annotation project (Hasida 2000).Although the sentence boundaries were adoptedfrom the corpus, the tree structure annotationwas done independently of POS- and term- an-notation already done on the GENIA corpus.The annotator was a Japanese non-biologist whohas previously involved in the POS annotationof the GENIA corpus and accustomed to thestyle of research abstracts in English.
Manuallyannotated abstracts are automatically convertedto the PTB format, merged with the POS annota-tion of the GENIA corpus (version 3.02).3 Annotation ResultsSo far, 500 abstracts are annotated and con-verted to the merged PTB format.
In the merg-ing process, we found several annotation errors.The 500 abstracts with correction of these errorsare made publicly available as ?The GENIATreebank Beta Version?
(GTB-beta).For further clean-up, we also tried to parsethe corpus by the Enju parser (Miyao and Tsujii2004), and identify the error of the corpus byinvestigating into the parse errors.
Enju is anHPSG parser that can be trained with PTB-typecorpora which is reported to have 87% accuracyon Wall Street Journal portion of Penn Treebankcorpus.
Currently the accuracy of the parserdrops down to 82% on GTB-beta, and althoughproper quantitative analysis is yet to be done, itwas found that the mismatches between labels ofthe treebank and the GENIA POS corpus (e.g.an ?ing form labeled as noun in the POS corpusand as the head of a verb phrase in the tree cor-pus) are a major source of parse error.
The cor-rection is complicated because several errors inthe GENIA POS corpus were found in thiscleaning-up process.
When the cleaning-upprocess is done, we will make the corpus pub-licly available as the proper release.<S><PP>In <NP>the present paper </NP></PP>,<NP-SBJ id="i55"><NP>the binding</NP><PP>of <NP>a [125I]-labeled aldosteronederivative </NP></PP><PP>to <NP><NP>plasmamembrane rich fractions </NP><PP>of HML</PP></NP></PP></NP-SBJ><VP>was<VP>studied <NP NULL="NONE"ref="i55"/></VP></VP>.</S>4 Inter-Annotator AgreementWe have also checked inter-annotator agreement.Although the PTB scheme is popular amongnatural language processing society, applicabil-ity of the scheme to highly specialized text suchas research abstract is yet to be discussed.
Espe-cially, when the annotation is done by linguists,lack of domain knowledge might decrease thestability and accuracy of annotation.A small part of the base text set (10 ab-stracts) was annotated by another annotator.
The10 abstracts were chosen randomly, had 6 to 17sentences per abstract (total 108 sentences).
Thenew annotator had a similar background as thefirst annotator that she is a Japanese non-biologist who has experiences in translation of(S (PP In (NP the present paper)), (NP-SBJ-55 (NPthe binding) (PP of (NP a [125I]-labeled aldosteronederivative)) (PP to (NP (NP plasma membrane richfractions) (PP of HML)))) (VP was (VP studied *-55)).
)Figure 1.
The sentence ?In the present paper, the binding ofa [125I]-labeled aldosterone derivative to plasma mem-brane rich fractions of HML was studied?
annotated inXML and PTB formats.222technical documents in English and in corpusannotation of  English texts.The two results were examined manually,and there were 131 disagreements.
Almost everysentence had at least one disagreement.
We havemade the ?gold standard?
from the two sets ofabstracts by resolving the disagreements, and theaccuracy of the annotators against this goldstandard were 96.7% for the first annotator and97.4% for the second annotator.Of the disagreement, the most prominentwere the cases involving coordination, espe-cially the ones with ellipsis.
For example, oneannotator annotated the phrase ?IL-1- and IL-18-mediated function?
as in Figure 2a, the otherannotated as Figure 2b.Such problem is addressed in the PTBguideline and both formats are allowed as alter-natives.
As coordination with ellipsis occursrather frequently in research abstracts, this kindof phenomena has higher effect on decrease ofthe agreement rate than in Penn Treebank.
Ofthe 131 disagreements, 25 were on this type ofcoordination.Another source of disagreement is the at-tachment of modifiers such as prepositionalphrases and pronominal adjectives.
However,most are ?benign ambiguity?
where the differ-ence of the structure does not affect on interpre-tation, such as ?high expression of STAT inmonocytes?
where the prepositional phrase ?inmonocytes?
can attach to ?expression?
or?STAT?
without much difference in meaning,and ?is augmented when the sensitizing tumor isa genetically modified variant?
where the wh-clause can attach to ?is augmented?
or ?aug-mented?
without changing the meaning.
ThePTB guideline states that the modifier should beattached at the higher level in the former caseand at the lower case in the latter.
In the annota-tion results, one annotator consistently attachedthe modifiers in both cases at the higher level,and the other consistently at the lower level, in-dicating that the problem is in understanding thescheme rather than understanding the sentence.Only 15 cases were true ambiguities that neededknowledge of biology to solve, in which 5 in-volved coordination (e.g., the scope of ?various?in ?various T cell lines and peripheral bloodcells?)
.Although the number was small, there weredisagreements on how to annotate a mathemati-cal formula such as ?n=2?
embedded in the sen-tence, since mathematical formulae were outsidethe scope of the original PTB scheme.
One an-notator annotated this kind of phrase consis-tently as a phrase with ?=?
as an adjective, theother annotated as phrase with ?=?
as a verb.There were 6 such cases.
Another disagreementparticular to abstracts is a treatment of labeledsentences.
There were 8 sentences in two ab-stracts where there is a label like ?Background:?.One annotator included the colon (?:?)
in the la-bel, while the other did not.
Yet another is thatone regarded the phrase ?Author et al as coor-dination, and the other regarded ?et al as amodifier.<NP SYN="COOD"><NP><ADJP>IL-1- <ADJP NULL="QSTN"/></ADJP><NP NULL="RNR" ref="i20"/></NP>and<NP>IL-18-mediated <NP NULL="RNR" ref="i20"/></NP><NP id="i20">function </NP>Other disagreements are more general typesuch as regarding ?-ed?
form of a verb as an ad-jective or a participle, miscellaneous errors suchas omission of a subtype of label (such as ?-PRD?
or ?-SBJ) or the position of <PRN> tags<NP><ADJP SYN="COOD"><ADJP>IL-1- <ADJP NULL="QSTN"/></ADJP>and<ADJP>IL-18-mediated </ADJP></ADJP>function</NP>NPADJP   FunctionADJP     and ADJPIL-1  *   IL-18 mediatedFigure 2a.
Annotation of a coordinated phrase by the firstannotator.
A* denotes a null constituent.</NP>NPNP And NPADJP  *20 IL-18 meidiated NPIL-1 *      function20Figure 2b.
Annotation of the same phrase as in Figure 2aby the second annotator.
A * denotes a null constituentand ?20?
denotes coindexing.223with regards to ?,?
for the inserted phrase, or theerrors which look like just ?careless?.
Such dis-agreements and mistakes are at least partiallyeliminated when reliable taggers and parsers areavailable for preprocessing5 DiscussionThe result of the inter-annotator agreementtest indicates that the writing style rather thanthe contents of the research abstracts is thesource of the difficulty in tree annotation.
Con-trary to the expectation that the lack of domainknowledge causes a problem in annotation onattachments of modifiers, the number of caseswhere annotation of modifier attachment needsdomain knowledge is small.
This indicates thatlinguists can annotate most of syntactic structurewithout an expert level of domain knowledge.A major source of difficulty is coordination,especially the ones involving ellipsis.
Coordina-tion is reported to be difficult phenomena in an-notation of different levels in the GENIA corpus(Tateisi and Tsujii, 2004), (Kim et al, 2003).
Inaddition to the fact that this is the major sourceof inter-annotator agreement, the annotator oftencommented the coordinated structure as ?unsure?.The problem of coordination can be divided intotwo with different nature: one is that the annota-tion policy is still not well-established for thecoordination involving ellipsis, and the other isan ambiguity when the coordinated phrase hasmodifiers.Syntax annotation of coordination with ellip-sis is difficult in general but the more so in an-notation of abstracts than in the case of generaltexts, because in abstracts authors tend to packinformation in limited number of words.
ThePTB guideline dedicates a long section for thisphenomena and allows alternatives in annotation,but there are still cases which are not well-covered by the scheme.
For example, in additionto the disagreement, the phrase illustrated inFigure 2a and Figure 2b shows another problemof the annotation scheme.
Both annotators fail toindicate that it is ?mediated?
that was to be after?IL-1?
because there is no mechanism ofcoindexing a null element with a part of a token.This problem of ellipsis can frequently occurin research abstracts, and it can be argued thatthe tokenization criteria must be changed fortexts in biomedical domain (Yamamoto and Sa-tou, 2004) so that such fragment as ?IL-18?
and?mediated?
in ?IL-18-ediated?
should be regaredeas separate tokens.
The Pennsylvania biologycorpus (Kulick et al, 2004) partially solves thisproblem by separating a token where two ormore subtokens are connected with hyphens, butin the cases where a shared part of the word isnot separated by a hyphen (e.g.
?metric?
of ?ste-reo- and isometric alleles?)
the word includingthe part is left uncut.
The current GTB followsthe GENIA corpus that it retains the tokeniza-tion criteria of the original Penn Treebank, butthis must be reconsidered in future.For analysis of coordination with ellipsis, ifthe information on full forms is available, onestrategy would be to leave the inside structure ofcoordination unannotated in the treebank corpus(and in the phase of text analysis the structure isnot established in the phase of parsing but with adifferent mechanism) and later merge it with thecoordination structure annotation.
The GENIAterm corpus annotates the full form of a techni-cal term whose part is omitted in the surface asan attribute of the ?<cons>?
element indicating atechnical term (Kim et al, 2003).
In the above-mentioned Pennsylvania corpus, a similarmechanism (?chaining?)
is used for recoveringthe full form of named entities.
However, inboth corpora, no such information is availableoutside the terms/entities.The cases where scope of modification incoordinated phrases is problematic are few butthey are more difficult in abstracts than in gen-eral texts because the resolution of ambiguityneeds domain knowledge.
If term/entity annota-tion is already done, that information can helpresolve this type of ambiguity, but again theproblem is that outside the terms/entities suchinformation is not available.
It would be practi-cal to have the structure flat but speciallymarked when the tree annotators are unsure andhave a domain expert resolve the ambiguity, asthe sentences that needs such intervention seemsfew.
Some cases of ambiguity in modifier at-tachment (which do not involve coordination)can be solved with similar process.We believe that other type of disagreementscan be solved with supplementing criteria forlinguistic phenomena not well-covered by thescheme, and annotator training.
Automatic pre-processing by POS taggers and parsers can alsohelp increase the consistent annotation.2246 ConclusionA subset of the GENIA corpus is annotatedfor syntactic (tree) structure.
Inter-annotatoragreement test indicated that the annotation canbe done stably by linguists without muchknowledge in biology, provided that properguideline is established for linguistic phenomenaparticular to scientific research abstracts.
Wehave made the 500-abstract corpus in both XMLand PTB formats and made it publicly availableas ?the GENIA Treebank beta version?
(GTB-beta).
We are in further cleaning up process ofthe 500-abstract set, and at the same time, initialannotation of the remaining abstracts is beingdone, so that the full GENIA set of 2000 ab-stracts will be annotated with tree structure.For parsers to be useful for information ex-traction, they have to establish a map betweensyntactic structure and more semantic predicate-argument structure, and between the linguisticpredicate-argument structures to the factual rela-tion to be extracted.
Annotation of various in-formation on a same set of text can helpestablish these maps.
For the factual relations,we are annotating relations between proteins andgenes in cooperation with a group of biologists.For predicate-argument annotation, we are in-vestigating the use of the parse results of theEnju parser.AcknowledgmentsThe authors are grateful to annotators and col-leagues that helped the construction of the cor-pus.
This work is partially supported by Grant-in-Aid for Scientific Research on Priority AreaC ?Genome Information Science?
from the Min-istry of Education, Culture, Sports, Science andTechnology of Japan.ReferencesBrants,T.(2000).
TnT: a statistical part-of-speechtagger, Proceedings of the sixth conference on Ap-plied natural language processing, pp.224-231,Morgan Kaufmann Publishers Inc.Beis.A., Ferguson,M., Katz,K., and Mac-Intire,R.(1995).
Bracketing Guidelines for Tree-bank II Style: Penn Treebank Project, Universityof PennsylvaniaHasida, K. (2000).
GDA: Annotated Document asIntelligent Content.
Proceedings ofCOLING?2000 Workshop on Semantic Annotationand Intelligent Content.Kazama,J., Miyao,Y., and Tsujii,J.
(2001) A Maxi-mum Entropy Tagger with Unsupervised HiddenMarkov Models, Proceedings of the Sixth NaturalLanguage Processing Pacific Rim Symposium, pp.333-340.Kim,J-D, Ohta,T., Tateisi,Y.
and Tsujii,J.
(2003).GENIA corpus - a semantically annotated corpusfor bio-textmining.
Bioinformatics.
19(suppl.
1).pp.
i180-i182.
Oxford University Press.Koike,A., Niwa,Y., and Takagi,T.
(2004) Automaticextraction of gene/protein biological functionsfrom biomedical text.
Bioinformatics, AdvancedAccess published on October 27, 2004;doi:10.1093/bioinformatics/bti084.Oxford Univer-sity Press.Kulick,S., Bies,A., Liberman,M., Mandel,M.,McDonald,R., Palmer,M., Schein,A., Ungar,L.,Winters,S.
and White,P.
(2004)  Integrated Anno-tation for Biomedical Information Extraction.BioLINK 2004: Linking Biological Literature, On-tologies, and Databases, pp.
61-68.Association forComputational Linguistics.Miyao,Y.
and Tsujii,J.
(2004a).
Deep LinguisticAnalysis for the Accurate Identification of Predi-cate-Argument Relations.
Proceedings ofCOLING 2004. pp.
1392-1397.Tateisi,Y.
and Tsujii,J.
(2004).
Part-of-Speech Anno-tation of Biology Research Abstracts.
Proceedingsof the 4th International Conference on LanguageResource and Evaluation (LREC2004).
IV.
pp.1267-1270, European Language Resources Asso-ciation.Wermter, J. and Hahn, U.
(2004).
An annotated Ger-man-language medical text corpus.
GMDS 2004meeting,http://www.egms.de/en/meetings/gmds2004/04gmds168.shtml.Yamamoto,K., and Satou,K (2004).
Low-level TextProcessing for Life Science, Proceedings of theSIG meeting on Natural Language Processing, In-formation Processing Society of Japan, IPSJ-SIGNL-159 (In Japanese).Yang,XF., Zhou,GD., Su,J., and Tan.,CL (2004).Improving Noun Phrase Coreference Resolutionby Matching Strings.
Proceedings of 1st Interna-tional Joint Conference on Natural LanguageProcessing (IJCNLP'2004), pp226-233.225
