HMM Based Chunker for HindiAkshay SinghIIITHyderabad, Indiaakshay@students.iiit.ac.inSushma BendreDept.
of Mathematics and StatisticsUniversity of HyderabadHyderabad, Indiasmbsm@uohyd.ernet.inRajeev SangalIIITHyderabad, Indiasangal@iiit.ac.inAbstractThis paper presents an HMM-basedchunk tagger for Hindi.
Various taggingschemes for marking chunk boundariesare discussed along with their results.Contextual information is incorporatedinto the chunk tags in the form of part-of-speech (POS) information.
This in-formation is also added to the tokensthemselves to achieve better precision.Error analysis is carried out to reducethe number of common errors.
It isfound that for certain classes of words,using the POS information is more ef-fective than using a combination ofword and POS tag as the token.
Fi-nally, chunk labels are also marked onthe chunks.1 Introduction1.1 Motivation and Problem StatementA robust chunker or shallow parser has emergedas an important component in a variety of NLPapplications.
It is employed in information ex-traction, named entity identification, search, andeven in machine translation.
While chunkers maybe built using handcrafted linguistic rules, thesetend to be fragile, need a relatively long time todevelop because of many special cases, and sat-urate quickly.
The task of chunking is ideallysuited for machine learning because of robustnessand relatively easy training.A chunker or shallow parser identifies simpleor non-recursive noun phrases, verb groups andsimple adjectival and adverbial phrases in runningtext.
In this work, the shallow parsing task hasbeen broken up into two subtasks: first, identi-fying the chunk boundaries and second, labellingthe chunks with their syntactic categories.The first sub-problem is to build a chunker thattakes a text in which words are tagged with partof speech (POS) tags as its input, and marks thechunk boundaries in its output.
Moreover, thechunker is to be built by using machine learn-ing techniques requiring only modest amount oftraining data.
The second sub-problem is to labelthe chunks with their syntactic categories.The presented work aims at building a chun-ker for Hindi.
Hindi is spoken by approximatelyhalf a billion people in India.
It is a relatively freeword order language with simple morphology (al-beit a little more complex than that of English).At present, no POS taggers or chunkers are avail-able for Hindi.1.2 Survey of Related WorkChunking has been studied for English and otherlanguages, though not very extensively.
The earli-est work on chunking based on machine learninggoes to (Church K, 1988) for English.
(Ramshawand Marcus, 1995) used transformation basedlearning using a large annotated corpus for En-glish.
(Skut and Brants, 1998) modified Church?sapproach, and used standard HMM based taggingmethods to model the chunking process.
(Zhou,etal., 2000) continued using the same methods, andachieved an accuracy of 91.99% precision and92.25% recall using a contextual lexicon.
(Kudo and Matsumoto, 2001) use support vec-126tor machines for chunking with 93.48% accuracyfor English.
(Veenstra and Bosch, 2000) usememory based phrase chunking with accuracy of91.05% precision and 92.03% recall for English.
(Osborne, 2000) experimented with various setsof features for the purpose of shallow parsing.In this work, we have used HMM based chunk-ing.
We report on a number of experiments show-ing the effect of different encoding methods onaccuracy.
Different encodings of the input showthe effect of including either words only, POS tagsonly, or a combination thereof, in training.
Theireffect on transition probabilities is also studied.We do not use any externally supplied lexicon.Analogous to (Zhou,et al, 2000), we found thatfor certain POS categories, a combination of wordand the POS category must be used in order toobtain good results.
We report on detailed ex-periments which show the effect of each of thesecombinations on the accuracy.
This experiencecan also be used to build chunkers for other lan-guages.
The overall accuracy reached for Hindiis 92.63% precision with 100% recall for chunkboundaries.The rest of the paper is structured as follows.Section 2 discusses the problem formulation andreports the results of some initial experiments.
InSection 3, we present a different representation ofchunks which significantly increased the accuracyof chunking.
In Section 4, we present a detailederror analysis, based on which changes in chunktags are carried out.
These changes increased theaccuracy.
Section 5 describes experiments on la-belling of chunks using rule-based and statisticalmethods.2 Initial ExperimentsGiven a sequence of words W n =(w1, w2, ?
?
?
, wn), wi ?
W , where W is the wordset and the sequence of corresponding part ofspeech (POS) tags T n = (t1, t2, ?
?
?
, tn), ti ?
Twhere T is the POS tag set, the aim is to createmost probable chunks of the sequence W n. Thechunks are marked with chunk tag sequenceCn = (c1, c2, ?
?
?
, cn) where ci stands for thechunk tag corresponding to each word wi, ci ?
C.C here is the chunk tag set which may consistof symbols such as STRT and CNT for eachword marking it as the start or continuation ofa chunk.
In our experiment, we combine thecorresponding words and POS tags to get asequence of new tokens V n = (v1, v2, ?
?
?
, vn)where vi = (wi, ti) ?
V .
Thus the problem isto find the sequence Cn given the sequence oftokens V nwhich maximizes the probabilityP (Cn|V n) = P (c1, c2, ?
?
?
, cn|v1, v2, ?
?
?
, vn),(1)which is equivalent to maximizingP (V n|Cn)P (Cn).We assume that given the chunk tags, the to-kens are statistically independent of each otherand that each chunk tag is probabilistically depen-dent on the previous k chunk tags ((k + 1)-grammodel).
Using chain-rule, the problem reduces tothat of Hidden Markov Model (HMM) given bymaxci?Cn?i=1P (vi|ci)P (ci+k|ci, ?
?
?
, ci+k?1)(2)where the probabilities in the first term are emis-sion probabilities and in the second term are tran-sition probabilities.
The optimal sequence ofchunk tags can be found using the Viterbi algo-rithm.
For training and testing of HMM we haveused the TnT system (Brants, 2000).
Since TnTis implemented up to a tri-gram model, we use asecond order HMM (k = 2) in our study.Before discussing the possible chunk sets andthe token sets, we consider an example below.
(( sher )) (( hiraN ke pIche ))lion deer of behindNN NN PREP PREPSTRT STRT CNT CNT(( jangal meM )) (( bhAgA .
))forest in ran .NN PREP VB SYMSTRT CNT STRT CNTIn this example, the chunk tags considered areSTRT and CNT where STRT indicates that thenew chunk starts at the token which is assignedthis tag and CNT indicated that the token whichis assigned this tag is inside the chunk.
We re-fer to this as 2-tag scheme.
Under second-orderHMM, the prediction of chunk tag at ith token isconditional on the only two previous chunk tags.Thus in the example, the fact that the chunk termi-nates at the word pIche (behind) with the POStag PREP is not captured in tagging the tokenjangal (forest).
Thus, the assumptions that the127tokens given the chunk tags are independent re-stricts the prediction of subsequent chunk tags.
Toovercome this limitation in using TnT, we experi-mented with additional chunk tags.We first considered a 3-tag scheme by includ-ing an additional chunk tag STP which indicatesend of chunk.
It was further extended to a 4-tag scheme by including one more chunk tagSTRT STP to mark the chunks which consist ofa single word.
A summary of the different tagschemes and the tag description is given below.1.
2-tag Scheme: {STRT, CNT}2.
3-tag Scheme: {STRT, CNT, STP}3.
4-tag Scheme: {STRT, CNT, STP,STRT STP}where tags stand for:?
STRT: A chunk starts at this token?
CNT: This token lies in the middle of achunk?
STP: This token lies at the end of a chunk?
STRT STP: This token lies in a chunk of itsownWe illustrate the three tag schemes using part ofthe earlier example sentence.
(( sher )) (( hiraN ke pIche))...lion deer of behind ...NN NN PREP PREP ...2-tag: STRT STRT CNT CNT ...3-tag: STRT STRT CNT STP ...4-tag: STRT_ST STRT CNT STP ...We further discuss the different types of inputtokens used in the experiment.
Since the tokensare obtained by combining the words and POStags we considered 4 types of tokens given by1.
Word only2.
POS tag only: Only the part of speech tag ofthe word was used3.
Word POStag: A combination of the wordfollowed by POS tag4.
POStag Word: A combination of POS tagfollowed by word.Note that the order of Word and POS tag in thetoken might be important as the TnT module usessuffix information while carrying out smoothingof transition and emission probabilities for sparsedata.
An example of the Word POStag type oftokens is given below.
((sher ))((hiraN ke pIche))...lion deer of behind...NN NN PREP PREP...Token:sher_NN hiran_NN ke_PREP pIche_PREP2-tag:STRT STRT CNT CNT ...The annotated data set contains Hindi texts of200,000 words.
These are annotated with POStags, and chunks are marked and labelled (NP,VG, JJP, RBP, etc).
This annotated corpus wasprepared at IIIT Hyderabad from funds providedby HP Labs.
The POS tags used in the corpusare based on the Penn tag set.
Hewever, thereare a few additional tags for compound nouns andverbs etc.Out of the total annotated data, 50,000 tokenswere kept aside as unseen data.
A set of 150,000tokens was used for training the different HMMrepresentations.
This set converted into the ap-propriate format based on the representation be-ing used.
20,000 tokens of the unseen data wereused for development testing.Table 1: Initial Results of Chunking (% Precision)Word POS POS WordWord POS2 Tags 79.21 80.32 81.42 81.853 Tags 75.30 71.99 77.05 77.804 Tags 70.41 68.25 72.59 73.643 Tags 75.30 71.99 77.05 77.804?3 Tags 76.95 74.65 78.78 79.562 Tags 79.21 80.32 81.42 81.853?2 Tags 81.14 79.66 82.58 83.304?2 Tags 83.37 82.41 84.89 85.60The initial results using various tag sets andtoken sets are presented in Table 1.
The firstthree rows show the raw scores of different tag-ging schemes.
To compare across the differentschemes, the output were converted to the re-duced chunk tag sets which are denoted by 4?3,4?2 and 3?2 in the table.
This ensures that themeasurement metric is the same no matter whichtagging scheme is used, thus allowing us to com-pare across the tagging schemes.
The last threerows show the result of usingIt should be noted that converting from the 4tag set to 3 or 2 tags results in no loss in infor-mation.
This is because it is trivial to convert128fromt the 2-tag set to the corresponding 4-tag setand vice-versa.
Even though the information con-tent in the 3 different chunk tag representationsis the same, using higher tag scheme for trainingand then later converting back to 2-tags results ina significant improvement in the precision of thetagger.
For example, in the case where we took?Word POSTag?
as the token, using 4-tag set theoriginal precision was 73.64%.
When precisionwas measured by reducing the tag set to 3 tags,we obtained a precision of 79.56%.
Four tags re-duced to two gave the highest precision of 85.6%.However, these differences may be interpreted asthe result of changing the measurement metric.This figure of 85.6% may be compared with a pre-cision of 81.85% obtained when the 2-tag set wasused.
Recall in all the cases was 100%.3 Incorporating POS Context in OutputTagsWe attempted modification of chunk tags us-ing contextual information.
The new outputtags considered were a combination of POS tagsand chunk tags using any one of the chunktag schemes discussed in the earlier section.The new format of chunk tags considered wasPOS:ChunkTag, which is illustrated for 2-tagscheme in the example below.
(( sher )) (( hiraN ke ...lion deer of ...NN NN PREP ...Token: sher_NN hiran_NN ke_PREP...2-tag: NN:STRT NN:STRT PREP:CNT...The tokens (V) were left unchanged.
Our in-tention in doing this was to bring in a finer degreeof learning.
By having part of speech informa-tion in the chunk tag, the information about thePOS-tag of the previous word gets incorporatedin the transition probabilities.
In the earlier chunkschemes, this information was lost due to the as-sumption of independence of tokens given chunktags.
In other words, part of speech informationwould now influence both the transition and emis-sion probabilities of the model instead of just theemission probabilities.We carried out the experiment with these mod-ified tags.
Based on the results in Table 1 for var-ious tokens, we restricted our choice of tokens toWord POStags only.
Also, while combining POStags with chunk tags, the 4-tag scheme was used.The accuracy with 4-tag scheme was 78.80% andfor 4 ?
2 scheme, it turned out to be 88.63%.This was a significant improvement.4 Error Analysis and FurtherEnhancementsWe next carried out the error analysis on the re-sults of the last experiment.
We looked at whichtype of words were resulting in the maximum er-rors, that is, we looked at the frequencies of er-rors corresponding to the various part of speech.These figures are given in Table 2.
On doing thisanalysis we found that a large number of errorswere associated with NN (nouns), VFM (finiteverbs) and JJ (adjectives).
Most of these errorswere coming in possibly because of sparsity ofthe data.
Hence we removed the word informationfrom these types of input tokens and left only thePOS tag.
This gave us an improved precision of91.04%.
Further experiments were carried out onTable 2: Error Analysis I - With Word POSTag asthe Token and POSTag:ChunkTag as Output TagPOS Tag Total Total % ErrorErrors TokensNN 1207 4063 29.71 %VFM 459 2108 21.77 %SYM 420 2483 16.92 %PRP 402 1528 26.31 %JJ 260 911 28.54 %PREP 237 2526 9.38 %NNP 142 389 36.50 %RP 129 589 21.90 %the other POS tags.
Experiments were done to seewhat performed better - a combination of wordand POS tag or the POS tag alone.
It was foundthat seven groups of words - PRP, QF (quanti-fiers), QW, RB (adverbs), VRB, VAUX (auxillaryverbs) and RP (particles) performed better with acombination of word and POS tag as the token.All the other words were replaced with their POStags.An analysis of the errors associated with punc-tuations was also done.
It was found that the setof punctuations { !
: ?
, ? }
was better at mark-ing chunks than other symbols.
Therefore, thesepunctuations were kept in the tokens while the129other symbols were reduced to a common marker(SYM).After performing these steps, the chunker wastested on the same testing corpus of 20,000 to-kens.
The precision achieved was 92.03% with arecall of 100% for the development testing data.Table 3 gives the stepwise summary of results ofthis experiment.
The first coloumn of the tablegives different token sets described above.
ErrorTable 3: Stepwise Summary of Results for Iden-tifying Chunk BoundariesMethod Precision Precision(4 Tags) (4 ?
2)Adding POS Contextinfo78.80 88.63Reducing NN, JJ, RPto POS only83.14 91.04Limiting word info.
to7 POS groups84.02 91.79Limiting punctuationmarks to {!
, : ?
?
}84.03 92.03analysis of this experiment is given in Table 4.On comparing with Table 2, it may be seen thatthe number of errors associated with almost allthe POS types has reduced significantly, therebyresulting in the improved precision.Table 4: Error Analysis IIPOS Tag Total Total % ErrorErrors TokensNN 557 4063 13.71%VFM 200 2108 9.49%JJ 99 911 10.87%PRP 84 1528 5.50%SYM 79 2483 3.18%RP 64 589 10.87%CC 61 748 8.16%QFN 59 310 19.03%5 Chunk LabelsOnce the chunk boundaries are marked, the nexttask is to classify the chunk.
In our scheme thereare 5 types of chunks - NP (noun phrase), VG(verb group), JJP (adjectival phrase) RBP (ad-verbial phrase) and BLK (others).
We tried twomethods for deciding chunk labels.
One wasbased on machine learning while the other wasbased on rules.5.1 HMM Based Chunk LabellingIn this method, the chunk boundary tags are aug-mented with the chunk labels while learning.
Forexample, the tags for the last token in a chunkcould have additional information in the form ofthe chunk label.
(( sher )) (( hiraN kelion deer ofNN NN PREPToken: sher_NN hiran_NN ke_PREP2-tag: NN:STRT#NP NN:STRT PREP:CNTpIche )) (( jangal meM )) ...behind forest inPREP NN PREPToken: pIche_PREP jangal_NN meM_PREP2-tag: PREP:CNT#NP NN:STRT PREP:CNT#NPThree schemes for putting chunk labels in thetags were tried.?
Scheme 1: The token at the start of the chunkwas marked with the chunk label.?
Scheme 2: All the tokens were marked withthe chunk labels.?
Scheme 3: The token at the end of the chunkwas marked with the chunk label.
(See ex-ample above.
)The best results were obtained with scheme 3,which when reduced to the common metric of 2-tags only gave a precision of 92.15% (for chunkboundaries only) which exceeded the result forchunk boundaries alone (92.03%).
The accu-racy for scheme 3 with the chunk boundaries andchunk labels together was 90.16%.
The corre-sponding figures for scheme 1 were 91.70% and90.00%, while for scheme 2 they were 92.02%and 88.05%.5.2 Rules Based Chunk LabelsSince there are only five types of chunks, it turnsout that the application of rules to find out thechunk-type is very effective and gives good re-sults.
An outline of the algorithm used for thepurpose is given below.?
For each chunk, find the last token ti whosePOS does not belong to the set {SYM, RP,CC, PREP, QF}.
(Such tags do not help inclassifying the chunks.)130?
If ti is a noun/pronoun, verb, adjective or ad-verb, then label the chunk as NP, VG, JJP orRBP respectively.?
Otherwise, label the chunk as BLK.In our experiments, we found that over 99% ofthe chunks identified were given the correct chunklabels.
Thus, the best method for doing chunkboundary identification is to train the HMM withboth boundary and syntactic label information to-gether (as given in Section 6.1).
Now given a testsample, the trained HMM can identify both thechunk boundaries and labels.
The chunk labelsare then dropped to obain data marked with chunkboundaries only.
Now rule based labelling is ap-plied ( with an accuracy of over 99%) yielding aprecision of 91.70% (test set) for the compositetask.Table 5: Summary of Chunk LabellingMethod Prec-1 Prec-2HMM with label at thestart of the chunk91.70 90.00HMM with chunk la-bels for all the tokens92.02 88.05HMM with label at theend of the chunk92.15 90.16HMM with label at theend of the chunk (testset)92.63 91.70Prec-1 - Precision for Chunk BoundariesPrec-2 - Precision for Chunk Boundaries andChunk Labels6 ConclusionsIn this paper, we have studied HMM based chunk-ing for Hindi.
We tried out several schemes forchunk labels and input tokens.
We found that fora certain type of words (function words), word in-formation along with POS information gave bet-ter precision.
A similar differentiation was donefor punctuations.
We tried several methods toclassify the chunks and found that a simple rule-based approach gave the best results.
The finalprecision we got was 92.63% for chunk boundaryidentification task and 91.70% for the compositetask of chunk labelling with a recall of 100%.This paper raises the issue that if there are twotag sets T1 and a more finely differentiated set T2,then T2 might give better accuracy than T1, pro-vided the errors are measured using the same met-ric (say, using the T1 set).
This, we believe, islikely to happen, when T2 is more finely and ap-propriately differentiated.
The most striking ex-ample was where T1 consisted of chunk bound-aries and T2 consisted of boundaries and labels.Training with T2 outperformed T1 for the bound-ary task, even though it did not perform very wellin the labelling task.ReferencesSteven Abney.
1996.
Tagging and Partial Parsing.Corpus-Based Methods in Language and Speech.Kluwer Academic Publishers, Dordrecht (1996)Thorsten Brants.
2000.
TnT - A Statistical Part-of-Speech Tagger Proceedings of the sixth conferenceon Applied Natural Language Processing (2000)224?231K.
Church.
1988.
A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text.
Proceed-ings of Second Conference on Applied Natural Lan-guage Processing (1988) 136?143Taku Kudo and Yuji Matsumoto.
2001.
Chunkingwith Support Vector Machines.
Proceedings ofNAACL 2001 (2001) 1013?1015Miles Osborne 2000.
Shallow Parsing as Part-of-Speech Tagging.
Proceedings of CoNLL-2000.
(2000)Lance A. Ramshaw, and Mitchell P. Marcus.
1995.Text Chunking Using Transformation-Based Learn-ing.
Proceedings of the 3rd Workshop on VeryLarge Corpora (1995) 88?94W.
Skut and T. Brants 1998.
Chunk Tagger, StatisticalRecognition of Noun Phrases.
ESSLLI-1998 (1998)Zhou, GuoDong, Jian Su and TongGuan Tey 2000.Hybrid Text Chunking.
Proceedings of CoNLL-2000 and LLL-2000 (2000) 163?165.Jorn Veenstra and Antal van den Bosch 2000.
Single-Classifier Memory-Based Phrase Chunking.
Pro-ceedings of CoNLL-2000 and LLL-2000 (2000)157?159.131
