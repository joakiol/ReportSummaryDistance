Proceedings of the ACL 2011 Workshop on Relational Models of Semantics (RELMS 2011), pages 19?27,Portland, Oregon, USA, June 23, 2011. c?2011 Association for Computational LinguisticsIdentifying Event ?
Sentiment Association using Lexical Equivalence andCo-reference ApproachesAnup Kumar Kolya1       Dipankar Das1      Asif Ekbal2      Sivaji Bandyopadhyay11 Computer Science and Engineering Department, Jadavpur University, India2 Indian Institute of Technology, Patna (IITP), Indiaanup.kolya@gmail.com, dipankar.dipnil2005@gmail.comasif.ekbal@gmail.com, sivaji_cse_ju@yahoo.comAbstractIn this paper, we have identified event and sen-timent expressions at word level from the sen-tences of TempEval-2010 corpus and evaluatedtheir association in terms of lexical equivalenceand co-reference.
A hybrid approach that con-sists of Conditional Random Field (CRF) basedmachine learning framework in conjunctionwith several rule based strategies has beenadopted for event identification within theTimeML framework.
The strategies are basedon semantic role labeling, WordNet relationsand some handcrafted rules.
The sentiment ex-pressions are identified simply based on thecues that are available in the sentiment lexiconssuch as Subjectivity Wordlist, SentiWordNetand WordNet Affect.
The identification of lexi-cal equivalence between event and sentimentexpressions based on the part-of-speech (POS)categories is straightforward.
The emotionalverbs from VerbNet have also been employedto improve the coverage of lexical equivalence.On the other hand, the association of sentimentand event has been analyzed using the notion ofco-reference.
The parsed dependency relationsalong with basic rhetoric knowledge help toidentify the co-reference between event andsentiment expressions.
Manual evaluation onthe 171 sentences of TempEval-2010 datasetyields the precision, recall and F-Score valuesof 61.25%, 70.29% and 65.23% respectively.1 IntroductionEvent and Sentiment are two abstract entitiesclosely coupled with each other from social, psy-chological and commercial perspectives.
Somekind of action that is going on or something that isbeing happened are addressed as events in generalby the Natural Language (NL) researchers.
Theevents are described in texts where the time, tem-poral location and ordering of the events are speci-fied.
Event entities are represented by finiteclauses, nonfinite clauses, nominalizations, event-referring nouns, adjectives and even some kinds ofadverbial clauses.On the other hand, text not only contains the in-formative contents, but also some attitudinal pri-vate information that includes sentiments.Nowadays, in the NLP communities, research ac-tivities on sentiment analysis are in full swing.
But,the identification of sentiment from texts is not aneasy task as it is not open to any objective observa-tion or verification (Quirk et al, 1985).Sometimes, similar or different types of senti-ments are expressed on a single or multiple events.Sentiment of people over different events is impor-tant as it has great influence on our society.
Track-ing users?
sentiments about products or events orabout political candidates as expressed in onlineforums, customer relationship management, stockmarket prediction, social networking etc., temporalquestion answering, document summarization, in-formation retrieval systems are some of the impor-tant applications of sentiment analysis.The identification of the association betweenevent and sentiment is becoming more popular andinteresting research challenge in the area of Natu-ral Language Processing (NLP).
Our present task isto identify the event and sentiment expressionsfrom the text, analyze their associative relationship19and investigate the insides of event-sentiment rela-tions.For example, in the following sentence, the an-notated events are, talked, sent and hijacked .But,it also shows the presence of underlying sentiments(as shown in underlined script) inscribed in thesentence.
Here, sentiment helps to evoke the eventproperty at lexical entity level (e.g.
negative (-ve)sentiment for only the event word hijacked) as wellas at context level (e.g.
positive (+ve) sentimentassociated with the event hijacked as the eventword appears with the evaluative expression, re-cover that gives the +ve polarity).
?The prime minister of India told Friday that hehas talked with top commander of Indian militaryforce and sent a team to recover the host of TajHotel hijacked.
?Hence, we have organized the entire task intothree different steps i) event identification, ii) sen-timent expression identification and iii) identifica-tion of event sentiment relationships at contextlevel using lexical equivalence and co-referenceapproaches.In the first step, we propose a hybrid approachfor event extraction from the text under the Tem-pEval-2010 framework.
Initially, we have used aConditional Random Field (CRF) (Lafferty et al,2001) machine learning framework but we observethat it often makes the errors in extracting theevents denoted by deverbial entities.
This observa-tion prompts us to employ several strategies inconjunction with machine learning.
These strate-gies are implemented based on semantic role labe-ling, WordNet (Miller, 1990) and somehandcrafted rules.
We have experimented with theTempEval-2010 evaluation challenge setup (Kolyaet al, 2010).
Evaluation results yield the preci-sion, recall and F-measure values of approximate-ly 93.00%, 96.00% and 94.47% respectively.
Thisis approximately 12% higher F-measure in com-parison to the best system (Llorens et al, 2010) ofTempEval-2010.On the other hand, the identification of the sen-timent expressions is carried out based on the sen-timent word.
The words are searched in threedifferent sentiment lexicons, the Subjectivity Wordlists (Banea et al, 2008), SentiWordNet (Baccia-nella et al, 2010) and WordNet Affect (Strapparavaand Valitutti, 2004).
The coarse-grained (positiveand negative) as well as Ekman?s (1993) six fine-grained sentiment or emotion expressions (happy,sadness, anger, disgust, fear and surprise) aretagged in the corpus.
As there is no annotation inthe TemEval-2010 corpus for sentiment expres-sions, the evaluation has been carried out by theauthors and it achieves the precision, recall and F-measure values of approximately 73.54%, 86.04%and 79.30% respectivelyDetermining the lexical equivalence of eventand sentiment expressions based on the POS prop-erty at the lexical entity level is straightforward.
Ifan event word also expresses the sentiment word,we have associated the corresponding sentimenttype with the event word directly.
In addition to thesentiment lexicons, the emotional verbs extractedfrom the VerbNet (Kipper-Schuler, 2005) are usedin this phase.
It improves the coverage of lexicalequivalence by 12.76%.But, if the event and sentiment expressions oc-cupy separate text spans in a sentence, we haveadopted a co-reference approach for identifyingtheir association.
The parsed dependency relationsalong with some basic rhetoric components, suchas nucleus, satellite and locus help in identifyingthe co-reference between the event and sentimentexpressions.
The text span containing sentimentword is hypothesized as the locus, the main effec-tive part of the nucleus or satellite.
The text spanthat reflects the primary goal of the writer istermed as nucleus (marked as ?
{ }?)
whereas thespan that provides supplementary material istermed as satellite (marked as ?
[ ]?).
The distin-guished identification of nucleus and satellite aswell as their separation from each other is carriedout based on the direct and transitive dependencyrelations, causal verbs, relaters or discourse mark-ers.
If both the locus and event are identified to-gether in either nucleus or satellite, we term theirassociation as co-referenced.
If they occur sepa-rately in nucleus and satellite and share at least onedirect dependency relation, we consider their asso-ciation as co-referenced.The evaluation of the lexical equivalence aswell as co-reference systems has been performedby the authors.
Primarily, the evaluation of bothsystems has been conducted on the random sam-ples of 200 sentences of the TempEval-2010 train-ing dataset.
Finally, the co-reference systemachieves the precision, recall and F-Scores of2061.25%, 70.29% and 65.23% respectively on 171sentences of the TempEval-2010 test corpus.The rest of the paper is organized as follows.Section 2 describes the related work.
The eventidentification is discussed in Section 3.
The identi-fication of sentiment expressions is described inSection 4.
Determination of lexical equivalencebetween event and sentiment expressions is speci-fied in Section 5.
The co-reference approach foridentifying the association between event and sen-timent is described in Section 6.
Finally Section 7concludes the paper.2 Related WorkThe existing works on event extraction are basedeither on pattern-matching rules (Mani and Wilson2000), or on the machine learning approach (Bo-guraev and Ando, 2005).
But, still the problemspersist with the high complexities involved in theproper extractions of events.
The events expres-sions were annotated in the TempEval 2007source in accordance with the TimeML standard(Pustejovsky et al, 2003).
On the other hand, theTask B of TempEval-2010 evaluation challengesetup (Verhagen et al, 2010) was aimed at identi-fying events from text.
The best achieved resultwas obtained by (Llorens et al, 2010).The majority of subjective analysis methodsthat are related to emotion is based on textual key-words spotting that use specific lexical resources.A lexicon that provides appraisal attributes forterms was constructed and the features were usedfor emotion classification (Whitelaw et al, 2005).The features along with the bag-of-words modelgive 90.2% accuracy.
UPAR7 (Chaumartin, 2007),a rule-based system uses a combination of Word-Net Affect and SentiWordNet.
The system wassemi-automatically enriched with the original trialdata provided during the SemEval task (Strappara-va and Mihalcea, 2007).
SWAT (Katz et al, 2007)is another supervised system that uses a unigrammodel trained to annotate emotional content.Our motivation is that though events and senti-ments are closely coupled with each other fromsocial, psychological and commercial perspectives,very little attention has been given about their de-tection and analysis.
To the best of our knowledge,only a few tasks have been attempted (Fukuhara etal., 2007) (Das et al, 2010).Sometimes, the opinion topics are not neces-sarily spatially coherent as there may be two opi-nions in the same sentence on different topics, aswell as opinions that are on the same topic sepa-rated by opinions that do not share that topic(Stoyanov and Cardie 2008).
The authors have es-tablished their hypothesis by applying the co-reference technique.
Similarly, we have adoptedthe co-reference technique based on basic rhetoriccomponents for identifying the association be-tween event and sentiment expressions.
In addi-tion to that, we have also employed the lexicalequivalence approach for identifying their associa-tion.3 Event IdentificationIn this work, we propose a hybrid approach forevent identification from the text under the Tem-pEval-2010 framework.
We use Conditional Ran-dom Field (CRF) as the underlying machinelearning algorithm.
We observe that this machinelearning based system often makes the errors inidentifying the events denoted by deverbial enti-ties.
This observation prompts us to employ severalstrategies in conjunction with machine learningtechniques.
These strategies have been imple-mented based on semantic role labeling, WordNetsenses and some handcrafted rules.We have experiment with the TempEval-2010evaluation challenge setup (Kolya et al, 2010).Evaluation results yield the precision, recall and F-measure values of approximately 93.00%, 96.00%and 94.47% respectively.
This is approximately12% higher F-measure in comparison to the bestsystem (Llorens et al, 2010) of TempEval-2010.3.1 CRF based Approach for Event Identifi-cationWe extract the gold-standard TimeBank featuresfor events in order to train/test the CRF model.
Inthe present work, we mainly use the various com-binations of the following features:Part of Speech (POS) of event terms (e.g.
Ad-jective, Noun and Verb), Tense (Present, Past, Fu-ture, Infinitive, Present part, Past part, or NONE),Aspect (Progressive, Perfective and PerfectiveProgressive or NONE), Class (Reporting, Percep-tion, Aspectual, I_action, I_state, State, Occur-rence), Stem (e.g., discount /s/).213.2 Use of Semantic Roles for Event Identifi-cationWe use an open source Semantic Role Labeler1(SRL) (Gildea et al, 2002) (Pradhan et al, 2004)to identify different features of the sentences.
Foreach predicate in a sentence acting as event word,semantic roles extract all constituents, determiningtheir arguments (agent, patient etc.)
and adjuncts(locative, temporal etc.).
Semantic roles can beused to detect the events that are the nominaliza-tions of verbs such as agreement for agree or con-struction for construct.
Nominalizations (or,deverbal nouns) are commonly defined as nounsthat are morphologically derived from verbs,usually by suffixation (Quirk et al, 1985).
Eventnominalizations often afford the same semanticroles as verbs and often replace them in writtenlanguage (Gurevich et al, 2006).
Event nominali-zations constitute the bulk of deverbal nouns.
Thefollowing example sentence shows how semanticroles can be used for event identification.
[ARG1 All sites] were [TARGET inspected] to the satis-faction of the inspection team and with full coope-ration of Iraqi authorities, [ARG0 Dacey] [TARGETsaid].The extracted target words are treated as theevent words.
It has been observed that many ofthese target words are identified as the event ex-pressions by the CRF model.
But, there exists ma-ny nominalised event expressions (i.e., deverbalnouns) that are not identified as events by the su-pervised CRF.
These nominalised expressions arecorrectly identified as events by SRL.3.3 Use of WordNet for Event IdentificationWordNet is mainly used to identify non-deverbalevent nouns.
We observed that the event entitieslike ?war?, ?attempt?, ?tour?
are not properly identi-fied.
These words have noun (NN) POS informa-tion as the previous approaches, i.e., CRF and SRLcan only identify those event words that have verb(VB) POS information.
We know from the lexicalinformation of WordNet that the words like ?war?and ?tour?
are generally used as both noun andverb forms in the sentence.
Therefore, we have1 http://cemantix.org/assert.htmldesigned the following two rules based on theWordNet:Rule 1: The word tokens having Noun (NN) POScategories are looked into the WordNet.
If it ap-pears in the WordNet with noun and verb senses,then that word token is considered as an event.
Forexample, war has both noun and verb senses in theWordNet, and hence war is considered as an event.Rule 2: The stems of the noun word tokens arelooked into the WordNet.
If one of the WordNetsenses is verb then the token is considered as verb.For example, the stem of proposal, i.e., proposehas two different senses, noun and verb in theWordNet, and thus it is considered as an event.3.4    Use of Rules for Event IdentificationHere, we mainly concentrate on the identificationof specific lexical classes like ?inspection?
and?resignation?.
These can be identified by the suf-fixes such as (?-ci?n?
), (?-tion?)
or (?-ion?
), i.e., themorphological markers of deverbal derivations.Initially, we have employed the CRF based Stan-ford Named Entity (NE) tagger2 on the TempEval-2 test dataset.
The output of the system is taggedwith Person, Location, Organization and Otherclasses.
The words starting with the capital lettersare also considered as NEs.
Thereafter, we cameup with the following rules for event identification:Cue-1: The deverbal nouns are usually identifiedby the suffixes like ?-tion?, ?-ion?, ?-ing?
and ?-ed?etc.
The nouns that are not NEs, but end with thesesuffixes are considered as the event words.Cue 2: The verb-noun combinations are searchedin the sentences of the test set.
The non-NE nounword tokens are considered as the events.Cue 3: Nominals and non-deverbal event nounscan be identified by the complements of aspectualPPs headed by prepositions like during, after andbefore, and complex prepositions such as at theend of and at the beginning of etc.
The next wordtoken(s) appearing after these clue word(s) orphrase(s) are considered as events.2 http://nlp.stanford.edu/software/CRF-NER.shtml22Cue 4: The non-NE nouns occurring after the ex-pressions such as frequency of, occurrence of andperiod of are most probably the event nouns.Cue 5: Event nouns can also appear as objects ofaspectual and time-related verbs, such as have be-gun a campaign or have carried out a campaignetc.
The non-NEs that appear after the expressionslike ?have begun a?, ?have carried out a?
etc.
arealso denoted as the events.4 Sentiment Expression IdentificationSentiment is an important cue that effectively de-scribes the events associated with it.
The binaryclassification of the sentiments (positive and nega-tive) as well as the fine-grained categorization intoEkman?s (1993) six emotions is therefore em-ployed for identifying the sentiment expressions.200 sentences are randomly selected from thetraining dataset of the TempEval-2010 corpus.These sentences have been considered as our de-velopment set.
On the other hand, 171 sentenceswere already provided as the test sentences in theTempEval-2010 evaluation challenge.The events are already annotated in the Tem-pEval-2010 corpus.
But, no sentiment or emotionrelated annotation is available in the corpus.Hence, we have annotated the sentiment expres-sions at word level in a semi-supervised way.
Theword level entities are tagged by their coarse andfine grained sentiment tags using the available sen-timent related lexical resources.
Then the automat-ic annotation has been evaluated manually by theauthors.
The semi-supervised sentiment annotationagreements were 90.23% for the development setand 92.45% for the test sets respectively.4.1 Lexicon based ApproachThe tagging of the evaluative expressions or morespecifically the sentiment expressions on the Tem-pEval-2010 corpus has been carried out using theavailable sentiment lexicons.
We passed the sen-tences through three sentiment lexicons, Subjectivi-ty Wordlists (Banea et al, 2008), SentiWordNet(Baccianella et al, 2010) and WordNet Affect(Strapparava and Valitutti, 2004).
SubjectivityWordlist assigns words with the strong or weaksubjectivity and prior polarities of types positive,negative and neutral.
SentiWordNet, used in opi-nion mining and sentiment analysis, assigns threesentiment scores such as positive, negative andobjective to each synset of WordNet.
WordNet Af-fect, a small well-used lexical resource but valua-ble for its affective annotation contains the wordsthat convey emotion.The algorithm is that, if a word in a sentence ispresent in any of these resources; the word istagged as the sentiment expression.
But, if anyword is not found in any of them, each word of thesentence is passed through the WordNet Morpho-logical analyzer (Miller, 1990) to identify its rootform and the root form is searched through the re-sources again.
If the root form is found, the corres-ponding word is tagged as sentiment expressionaccordingly.The identified sentiment expressions have beenevaluated by the authors and it achieves the preci-sion, recall and F-Score of 73.54%, 86.04% and79.30%, respectively on a total of 171 test sen-tences of the TempEval-2010 corpus.The identification of event words that also ex-press sentiment is straightforward.
But, the prob-lem arises when the event and sentimentexpressions are present separately in a sentenceand the sentiment is either closely associated withthe event or affects it.
In case of the former, wehave adopted the approach of lexical equivalencebetween the event and sentiment entities whereasthe co-reference technique has been introduced forresolving the latter case.5 Lexical Equivalence between Event andSentiment ExpressionsIt is observed that in general the verbs, nouns andadjectives represent events.
The sentences arepassed through an open source Stanford MaximumEntropy based POS tagger (Manning and Toutano-va, 2000).
The best reported accuracy for the POStagger on the Penn Treebank is 96.86% overall and86.91% on previously unseen words.
Our objectivewas to identify the event words that also expresssentiments.
Hence, we have identified the eventwords that have also been tagged as the sentimentexpressions.
The coverage of these lexical re-sources in identifying the event sentiment associa-tion is shown in Table 1.On the other hand, not only the adjectives ornouns, the sentiment or emotional verbs play animportant role in identifying the sentiment expres-23sions.
Hence, in addition to the above mentionedsentiment resources, we have also incorporatedEnglish VerbNet (Kipper-Schuler, 2005) for theautomatic annotation process.
VerbNet associatesthe semantics of a verb with its syntactic framesand combines traditional lexical semantic informa-tion such as thematic roles and semantic predi-cates, with syntactic frames and selectionalrestrictions.
Verb entries in the same VerbNet classshare common syntactic frames and thus they arebelieved to have the same syntactic behavior.
Forexample, the emotional verbs ?love?
and ?enjoy?are members of the admire-31.2-1 class and ?en-joy?
also belongs to the class want-32.1-1.The XML files of VerbNet are preprocessed tobuild up a general list that contains all memberverbs and their available syntax information re-trieved from VerbNet.
The main criterion for se-lecting the member verbs as sentiment expressionsis the presence of ?emotional_state?
type predicatein their frame semantics.
The frequencies of theevent words matched against the above said fourresources are shown in Table 1.
It has been ob-served that the adjective events are not identifiedby the lexical resources as their frequency in thetest corpus was very low.
But, the lexical coveragehas been improved by 12.76% by incorporatingVerbNet.Resources Noun   Adjective  Verb#114    #4              #380Subjectivity WordlistsSentiWordNetWordNet Affect ListVerbNet (emotionalverbs)24            --             3532            --             5912            --             25--            --             79Accuracy (in %) 59.64                    52.57Table 1: Results of Lexical Equivalence betweenEvent and Sentiment based on different resources6 Co-reference between Event and Senti-ment ExpressionsThe opinion and/or sentiment topics are not neces-sarily spatially coherent as there may be two opi-nions in the same sentence on different topics.Sometimes, the opinions that are on the same topicare separated by opinions that do not share thattopic (Stoyanov and Cardie, 2008).
We observe thesimilar situation in case of associating sentimentswith events.
Hence, the hypothesis for opinion top-ic is established for sentiment events by applyingthe co-reference technique along with the rhetori-cal structure.
We have proposed two different sys-tems for identifying the association of sentimentswith the events at context level.6.1 Baseline Co-reference SystemThe baseline system has been developed based onthe object information present in the dependencyrelations of the parsed sentences.
Stanford Parser(Marneffe et al, 2006), a probabilistic lexicalizedparser containing 45 different part of speech (POS)tags of Pen Treebank tagset  has been used to getthe parsed sentences and dependency relations.The dependency relations are checked for the pre-dicates ?dobj?
so that the related componentspresent in the predicate are considered as the prob-able candidates for the events.If a dependency relation contains both the eventand sentiment words, we have considered the pres-ence of co-reference between them.
But, it hasbeen observed that the event and sentiment expres-sions are also present in two different relations thatshare a common word element.
Hence, if the eventand sentiment words appear in two different rela-tions but both of the relations contain at least onecommon element, the event and sentiment wordsare termed as co-referenced.Overall, the baseline co-reference systemachieves the precision, recall and F-Scores of40.03%, 46.10% and 42.33% for event-sentimentco-reference identification.
For example in the fol-lowing sentence, the writer?s direct as well as indi-rect emotional intentions are reflected bymentioning one or more topics or events (spent,thought) and their associated sentiments (great).
?When Wong Kwan spent seventy million dol-lars for this house, he thought it was a great deal.
?The baseline co-reference system fails to asso-ciate the sentiment expressions with their corres-ponding event expressions.
Hence, we aimed forthe rhetoric structure based co-reference system toidentify their association.6.2  Rhetoric Co-reference SystemThe distribution of events and sentiment expres-sions in different text spans of a sentence needs the24analysis of sentential structure.
We have incorpo-rated the knowledge of Rhetorical StructureTheory (RST) (Mann and Thompson 1987) foridentifying the events that are co-referred by theircorresponding sentiment expressions.The theory maintains that consecutive discourseelements, termed text spans, are related by a rela-tively small set (20?25) of rhetorical relations.But, instead of identifying the rhetorical relations,the present task acquires the basic and coarse rhe-torical components such as locus, nucleus and sa-tellite from a sentence.
These rhetoric clues helpin identifying the individual event span associatedwith the span denoting the corresponding senti-ment expression in a sentence.
The text span thatreflects the primary goal of the writer is termed asnucleus (marked as ?
{ }?)
whereas the span thatprovides supplementary material is termed as satel-lite (marked as ?
[ ]?).
For example, the nucleus andsatellite textual spans are shown in the followingsentence as,{Traders said the market remains extremelynervous} because [the wild swings seen on theNew York Stock Exchange last week].The event or topic of an opinion or sentimentdepends on the context in which the associatedopinion or sentiment expression occurs (Stoyanovand Cardie 2008).
Considering the similar hypo-thesis in case of events instead of topics, the co-reference between an event and a sentiment ex-pression is identified from the nucleus and/or satel-lite by positioning the sentiment expression aslocus.
We have also incorporated the WordNet?s(Miller 1990) morphological analyzer to identifythe stemmed forms of the sentiment words.The preliminary separation of nucleus from sa-tellite was carried out based on the list of frequent-ly used causal keywords (e.g., as, because, that,while, whether etc) and punctuation markers (,) (!)(?
).The discourse markers and causal verbs arealso the useful clues if they are explicitly specifiedin the text.
The identification of discourse markersfrom written text itself is a research area (Azar1999).
Hence, our task was restricted to identifyonly the explicit discourse markers that are taggedby conjunctive_() or mark_() type dependency re-lations of the parsed constituents.
The dependencyrelations containing conjunctive markers (e.g.,conj_and(), conj_or(), conj_but()) were consideredfor separating nucleus from satellite if the markersare present in between two successive clauses.Otherwise, the word token contained in themark_() type dependency relation was consideredas a discourse marker.The list of causal verbs is prepared byprocessing the XML files of VerbNet.
If any Verb-Net class file contains any frame with semantictype as Cause, we collect the member verbs of thatXML class file and term the member verbs ascausal verbs.
We used a list that contains a totalnumber of 253 causal verbs.If any clause tagged as S or SBAR in the parsetree contains any causal verb, that clause is consi-dered as the nucleus and the rest of the clauses de-note the satellites.
Considering the basic theory ofrhetorical structure (Mann and Thompson 1987),the clauses were separated into nucleus and satel-lite to identify the event and sentiment expressions.The direct dependency is identified based on thesimultaneous presence of locus and the event wordin the same dependency relation whereas the tran-sitive dependency is verified if the word is con-nected to locus and event via one or moreintermediate dependency relations.If the event and sentiment words are togetherpresent in either nucleus or satellite, the associa-tion between the two expressions is considered asco-referenced.
If they occur in nucleus and satelliteseparately, but the event and sentiment words arepresent in at least one direct dependency relation,the expressions are termed as co-referenced.In the previous example, the event expressions,?said?
and ?remains?
are associated with the sen-timent expression ?nervous?
as both the event ex-pressions share the direct dependency relations?cop(nervous-7, remains-5)?
and ?ccomp(said-2,nervous-7)?
in the nucleus segment.
Similarly, theevent word, ?seen?
and sentiment word ?wild?
arepresent in the satellite part and they share a directdependency relation ?partmod(swings-12, seen-13)?.
But, no direct dependency relation is presentbetween the ?nervous?
and ?seen?
or ?said?
and?wild?
or ?remains?
and ?wild?.6.3 ResultsThough the event annotation is specified in theTempEval-2010 corpus, the association betweenthe event and sentiment expressions was not speci-fied in the corpus.
Hence, we have carried out the25evaluation manually.
The 200 random samples ofthe training set that were used in sentiment expres-sion identification task have been considered asour development set.
The Evaluation Vectors(EvalV) are prepared manually from each sentenceof the development and test sets.
The vectors<EvExp, SentiExp> are filled with the annotatedevents and sentiment expressions by consideringtheir association.
The annotation of sentiment ex-pressions using the semi-supervised process hasbeen described in Section 4.The rule based baseline and rhetoric based co-reference systems identify the event and sentimentexpressions from each sentence and stores them ina Co-reference Vector (CorefV).
The evaluation iscarried out by comparing the system generated Co-reference Vectors (CorefV) with their correspond-ing Evaluation Vectors (EvalV).
The evaluationresults on 171 test sentences are shown in Table 2.Co-referenceApproachesPrec.
Rec.
F-Score(in %)Baseline System 40.03    46.10       42.33Rhetoric System 61.25    70.29       65.23Table 2: Precision (Prec.
), Recall (Rec.)
and F-Scores (in %) of the event-sentiment co-referencesystemsOverall, the precision, recall and F-Scores are61.25%, 70.29% and 65.23% for event-sentimentco-reference identification using rhetoric clues.Though the co-reference technique performs satis-factorily for identifying the event-sentiment co-reference, the problem arises in distinguishing thecorresponding spans of events from an overlappedtext span of multi-word tokens.7 ConclusionIn this present work, we have identified event andsentiment expressions at word level from the sen-tences of TempEval-2010 corpus and evaluatedtheir association in terms of lexical equivalenceand co-reference.
It has been observed that the lex-ical equivalence based on lexicons performs satis-factorily but overall, the co-reference entails thatthe presence of indirect affective clues can also betraced with the help of rhetoric knowledge and de-pendency relations.
The association of the senti-ments with their corresponding events can be usedin future concerning the time based sentimentchange over events.AcknowledgmentsThe work is supported by a grant from the India-Japan Cooperative Programme (DST-JST) 2009Research project entitled ?Sentiment Analysiswhere AI meets Psychology?
funded by Depart-ment of Science and Technology (DST), Govern-ment of India.ReferencesBaccianella Stefano, Esuli Andrea and Sebas-tiani Fa-brizio.
2010.
SentiWordNet 3.0: An Enhanced Lexi-cal Re-source for Sentiment Analysis and OpinionMining.
In Proceedings of the 7th Conference onLanguage Resources and Evaluation, pp.
2200-2204.Banea, Carmen, Mihalcea Rada, Wiebe Janyce.
2008.A Bootstrapping Method for Building SubjectivityLexicons for Languages with Scarce Resources.
TheSixth International Conference on Language Re-sources and Evaluation.Boguraev, B., Ando, R. K. 2005.
TimeBank-DrivenTimeML Analysis.
Annotating, Extracting andReasoning about Time and Events 2005.Chaumartin, F. 2007.
Upar7: A knowledge-based sys-tem for headline sentiment tagging.
SemEval-200,Czech Republic.Ekman Paul.
1993.
An argument for basic emotions,Cognition and Emotion, 6(3-4):169-200.Fukuhara T., Nakagawa, H. and Nishida, T. 2007.
Un-derstanding Sentiment of People from News Articles:Temporal Sentiment Analysis of Social Events.ICWSM?2007, Boulder, Colorado.Gildea, D. and Jurafsky, D. 2002.
Automatic Labelingof Semantic Roles.
Computational Linguistics,28(3):245?288.Gurevich, O., R. Crouch, T. King, and V. de Paiva.2006.
Deverbal Nouns in Knowledge Representation.Proceedings of FLAIRS, pages 670?675, MelbourneBeach, FL.Katz, P., Singleton, M. and Wicentowski, R. 2007.Swat-mp: the semeval-2007 systems for task 5 andtask SemEval-2007.Kipper-Schuler, K. 2005.
VerbNet: A broad-coverage,comprehensive verb lexicon.
Ph.D. thesis, Computerand Information Science Dept., University of Penn-sylvania, Philadelphia, PA.26Kolya, A., Ekbal, A. and Bandyopadhyay, S. 2010.JU_CSE_TEMP: A First Step towards EvaluatingEvents, Time Expressions and Temporal Relations.In Proceedings of the 5th International Workshop onSemantic Evaluation, ACL 2010, July 15-16, Swe-den, pp.
345?350.Lafferty, J., McCallum, A.K., Pereira, F. 2001.
Condi-tional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
InternationalConference on Machine Learning.Llorens Hector, Estela Saquete, Borja Navarro.
2010.TIPSem (English and Spanish): Evaluating CRFs andSemantic Roles.
Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, ACL 2010, pages284?291, Uppsala, Sweden, 15-16 July 2010.Mani, I., and Wilson G. 2000.
Processing of News.
InProceedings of the 38th Annual Meeting of the Asso-ciation for Computational Linguistics, pp.
69-76.Mann, W. and S. Thompson.
1987.
Rhetorical StructureTheory: Description and Construction of Text Struc-ture.
In G. Kempen (ed.
), Natural Language Genera-tion, Martinus Nijhoff, The Hague, pp.
85?96.Manning Christopher and Toutanova, Kristina.
2000.Enriching the Knowledge Sources Used in a Maxi-mum Entropy Part-of-Speech Tagger.
Proceedings ofthe Joint SIGDAT Conference on Empirical Methodsin Natural Language Processing and Very LargeCorpora (EMNLP/VLC)Marneffe, Marie-Catherine de, Bill MacCartney, andChristopher D.Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
5thInternational Conference on Language Resourcesand Evaluation.Miller George A.
1990.
WordNet: An on-line lexicaldatabase.
International Journal of Lexicography,3(4): 235?312Pradhan S., Wayne W., Hacioglu, K., Martin, J.H.
andJurafsky, D. 2004.
Shallow Semantic Parsing usingSupport Vector Machines.
Proceedings of the HumanLanguage Technology Conference/North Americanchapter of the Association for Computational Lin-guistics annual meeting Boston, MA, May 2-7.Pustejovsky, J., Castano, J., Ingria, R., Sauri, R., Gai-zauskas, R., Setzer, A., Katz, G. and Radev, D.TimeML: Robust specification of event and temporalexpressions in text.
In AAAI Spring Symposium onNew Directions in Question-Answering, pp.
28-34,CA, 2003.Quirk, R., Greenbaum, S. Leech, G. and Svartvik, J.1985.
A Comprehensive Grammar of the EnglishLanguage.
Longman.Strapparava C. and Valitutti, A.
2004.
Wordnet-affect:an affective extension of wordnet.
In 4th Internation-al Conference on Language Resources and Evalua-tion, pp.
1083-1086.Strapparava Carlo and Mihalcea Rada.
2007.
SemEval-2007 Task 14: Affective Text.
45th Aunual Meetingof Association for Computational linguistics.Stoyanov, V., and Cardie, C. 2008.
Annotating topics ofopinions.
In Proceedings of LREC.27
