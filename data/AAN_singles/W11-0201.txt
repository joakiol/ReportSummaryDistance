Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 1?9,Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational LinguisticsNot all links are equal: Exploiting Dependency Types for the Extraction ofProtein-Protein Interactions from TextPhilippe Thomas 1, Stefan Pietschmann 1, Ille?s Solt 2, Domonkos Tikk1,2 and Ulf Leser 11Knowledge Management in Bioinformatics, Institute for Computer Science,Humboldt-University of Berlin,Unter den Linden 6, 10099 Berlin, Germany2Department of Telecommunications and Media Informatics,Budapest University of Technology and Economics,Magyar tudo?sok ko?ru?tja 2, 1117 Budapest, Hungary{thomas,pietschm,solt,tikk,leser}@informatik.hu-berlin.deAbstractThe extraction of protein-protein interactions(PPIs) reported in scientific publications is oneof the most studied topics in Text Mining inthe Life Sciences, as such algorithms can sub-stantially decrease the effort for databases cu-rators.
The currently best methods for thistask are based on analyzing the dependencytree (DT) representation of sentences.
Manyapproaches exploit only topological featuresand thus do not yet fully exploit the informa-tion contained in DTs.
We show that incor-porating the grammatical information encodedin the types of the dependencies in DTs no-ticeably improves extraction performance byusing a pattern matching approach.
We au-tomatically infer a large set of linguistic pat-terns using only information about interact-ing proteins.
Patterns are then refined basedon shallow linguistic features and the seman-tics of dependency types.
Together, these leadto a total improvement of 17.2 percent pointsin F1, as evaluated on five publicly availablePPI corpora.
More than half of that improve-ment is gained by properly handling depen-dency types.
Our method provides a generalframework for building task-specific relation-ship extraction methods that do not require an-notated training data.
Furthermore, our obser-vations offer methods to improve upon rela-tion extraction approaches.1 IntroductionInsights about protein-protein interactions (PPIs) arevital to understand the biological processes withinorganisms.
Accordingly, several databases, such asIntAct, DIP, or MINT, contain detailed informationabout PPIs.
This information is often manually har-vested from peer reviewed publications (Ceol et al,2010).
However, it is assumed that a high amountof PPIs is still hidden in publications.
Therefore, theautomated extraction of PPIs from text has attractedconsiderable attention from biology research.A number of different techniques have been pro-posed to solve the problem of extracting PPIs fromnatural language text.
These can be roughly or-ganized into one of three classes: co-occurrence,machine learning, and pattern matching (for a re-cent survey, see (Zhou and He, 2008)).
The co-occurrence based approaches use only informationon the co-existence of protein mentions in a givenscope.
They are easy to implement and allow forefficient processing of huge amounts of texts, butthey are also prone to generate many false positivesbecause they cannot distinguish positive from neg-ative pairs.
The second class is based on machinelearning.
Here, a statistical model is learned from aset of positive and negative examples and then ap-plied to unseen texts.
In general, machine learning-based methods to relation extraction perform verywell for any task where sufficient, representative andhigh quality training data is available (Kazama etal., 2002).
This need for training data is their ma-jor drawback, as annotated texts are, especially inthe Life Sciences, rather costly to produce.
Fur-thermore, they are prone to over-fit to the trainingcorpus, which renders evaluation results less infer-able to real applications.
A third class of methodsis based on pattern matching.
Such methods workwith patterns constructed from linguistically anno-1tated text, which are matched against unseen textto detect relationships.
Patterns can either be in-ferred from examples (Hakenberg et al, 2010; Liuet al, 2010) or can be defined manually (Fundel etal., 2007).
Systems based on manually defined pat-terns typically use few patterns, leading to high pre-cision but low recall (Blaschke et al, 2002).
In con-trast, systems that learn patterns automatically oftenproduce more patterns and exhibit a better recall, atthe cost of a decrease in precision.
To circumventthis penalty, several works have tried to improvepatterns.
E.g., SPIES (Hao et al, 2005) filters pat-terns using the minimum description length (MDL)method which improves its F1 by 6.72%.Another classification of PPI extraction methodsis based on the sentence representation that is ap-plied.
The simplest such representation is the bag ofwords (BoW) that occur in the sentence; more com-plex representations are constituent trees, capturingthe syntactic structure of the sentence, and depen-dency trees (DTs), which represent the main gram-matical entities and their relationships to each other.PPI extraction methods use various sentence repre-sentation, e.g., are based only on BoW (Bunescuand Mooney, 2006; Giuliano et al, 2006), use onlyDTs (Erkan et al, 2007), or combine representa-tions (Airola et al, 2008; Miwa et al, 2008).In the last years, dependency trees have becomethe most popular representation for relation extrac-tion.
DTs characterize, via their dependency links,grammatical relationships among words.
They areparticularly favored by kernel-based learning ap-proaches, see e.g.
(Culotta and Sorensen, 2004;Erkan et al, 2007; Airola et al, 2008; Miwa et al,2008; Kim et al, 2010) but also graph matching ap-proaches using DTs have been proposed (Liu et al,2010).
However, these methods do not further utilizethe grammatical information encoded in the depen-dency types (edge labels).
Recently proposed meth-ods like (Buyko et al, 2009; Rinaldi et al, 2010)modify the DTs by e.g.
trimming irrelevant depen-dencies.
In contrast to these approaches, our methodexploits the dependency types of DTs and performsbasic transformations on DTs; we use Stanford de-pendencies, which are presumably the most oftenused DT representation in PPI extraction.The rest of this paper is organized as follows.
Wedescribe our novel method for extracting PPIs fromtext that is based on pattern matching in dependencygraphs.
We evaluate our method against benchmarkPPI corpora, and discuss results with a focus on de-pendency type information based methods.2 MethodsOur approach consists of a series of steps: First, weextract sentences from Medline and PMC open ac-cess that contain pairs of genes/proteins known tointeract.
Second, we convert each of those sentencesinto DTs and derive putative tree patterns for eachpair.
Having a set of such patterns, we apply a num-ber of generalization methods to improve recall andfiltering methods to improve precision.
We discernbetween methods that are purely heuristic (termedshallow) and steps that incorporate dependency typeinformation (termed grammatical).
To predict PPIsin unseen text, the resulting patterns are matchedagainst the corresponding DTs.2.1 Extraction of PPI sentencesWe apply the method described in (Hakenberg et al,2006) to extract a set of sentences from Medline andPMC potentially describing protein interactions.
Es-sentially, this method takes a database of PPIs (hereIntAct; (Aranda et al, 2010)) and searches all sen-tences in Medline and PMC containing any of thosepairs.
Proteins were tagged and normalized usingGNAT (Hakenberg et al, 2008).
To avoid a possiblebias, articles contained in any of the five evaluationcorpora are excluded.
This resulted in 763,027 in-teracting protein pairs.2.2 Pattern generation and matchingFor each protein pair we generate a new sentenceand apply entity blinding, meaning that named enti-ties are replaced by placeholders to avoid systemicbias.
Specifically, the mentions of the two proteinsknown to interact are replaced by the placeholderENTITY A and any additional proteins in the samesentence are replaced by ENTITY B. Tokens aretagged with their part-of-speech (POS) using Med-Post (Smith et al, 2004), which is specifically op-timized for biomedical articles.
Constituent parsetrees are generated using the Bikel parser (Bikel,2002) and converted to DTs by the Stanford con-verter (De Marneffe et al, 2006).
In a DT, the short-est path between two tokens is often assumed to con-2tain the most valuable information about their mu-tual relationship.
Therefore, we generate a patternfrom each DT by extracting the shortest, undirectedpath between the two occurrences of ENTITY A.The set of initial patterns is denoted by SIP.We employ several methods to improve the qual-ity of this initial set of patterns.
We systemati-cally evaluated possible constellations and identifiedthose that help in improving performance of PPI ex-traction.
The modifications are of two kinds.
Patterngeneralizers are intended to elevate recall, whereaspattern filters should raise precision.
We presenttwo types of methods: Shallow methods are simpleheuristics whereas grammatical methods are rulesthat exploit the information in dependency types.We use a strict graph matching approach for pat-tern matching.
We consider a pattern to match a sub-graph of a DT iff all their nodes and edges matchexactly, including edge labels and edge directions.2.3 Pattern generalizationIt is a common practice in NLP to apply some pre-processing on patterns to reduce corpus-specificity.In particular, we perform stemming (GST), re-moval of common protein name prefixes and suf-fixes (GPN), and replacement of interaction phrasesby single words (GIW).
We summarize these steps asshallow generalization steps.
We only describe thelatter two (GPN, GIW) in more detail.Protein names are often modified by suffixes like-kinase, -receptor or -HeLa or by prefixes likephospho- or anti-.
These affixes are usually notcovered by entity blinding as the entity recognitionmethod does not consider them as part of the pro-tein name.
As such affixes are not relevant for rela-tion extraction but do interfere with our exact graphmatching approach, we apply the GPN heuristic toremove them.Interactions between proteins can be expressedvery diversely in natural language.
In almost allcases there is at least one word that specifies the in-teraction semantically, called the interaction word;this is often a verb, such as ?binds?
or ?phospho-rylates?, but can as well be a noun, such as ?
[in-duced] phosphorylation?, or an adjective, such as?binding?.
The GIW heuristic generalizes patternsby substituting all contained interaction words withgeneric placeholders.
We assembled a list of 851 in-teraction words (including inflection variants) basedon (Temkin and Gilder, 2003; Hakenberg et al,2006) that was further enriched manually.
Basedon their POS-tags, interaction words are assigned toone of the three placeholders IVERB, INOUN, IAD-JECTIVE.
We also experimented with a single inter-action word placeholder, IWORD, handling the caseof incorrect POS-tags.Unifying dependency types (GUD): The Stan-ford typed dependency format contains 55 grammat-ical relations organized in a generalization hierar-chy.
Therefore, it is a natural idea to treat simi-lar (e.g., sibling) dependency types equally by re-placing them with their common parent type.
Wemanually evaluated all dependency types to assesswhether such replacements are viable.
The final listof replacements is listed in Table 1.
Note that weused the so-called collapsed representation of de-pendency types of the Stanford scheme.
This meansthat prepositional and conjunctive dependencies arecollapsed to form a single direct dependency be-tween content words, and the type of this depen-dency is suffixed with the removed word.
In the GUDgeneralizer, these dependency subtypes are substi-tuted by their ancestors (e.g., prep, conj).Dependency types Common typesubj, nsubj*, csubj* subjobj, dobj, iobj, pobj objprep *, agent, prepc prepnn, appos nnTable 1: Unification of specific dependency types toa single common type by the generalizer GUD.
Notethat agent is merged with dependency type prepas it is inferred for the preposition ?by?.Collapsing dependency links (GCD): In addi-tion to the collapsing performed by Stanford con-verter, we remove edges that likely are irrelevantfor PPIs.
We focused on removing the dependen-cies nn (noun compound modifier) and appos (ap-positional modifier).
These grammatical construc-tions have the same syntactic role but they carrysomewhat different meaning.
They function as nounphrase modifiers and often specify the subtype ofan entity, which is irrelevant for our task.
As thesetwo dependency types convey no information about3the interaction itself, the dependency itself and thecorresponding noun can be removed, as long as thenoun is not an entity itself.
As an example, thisgeneralizer is applied on the dependency parse treeof the sentence ?ENTITY A protein recognized anti-body (ENTITY A)?
shown on Figure 1a.
The modi-fied parse tree is depicted on Figure 1b.ENTITY-Aprote inn nrecognizednsubjant ibodydobjENTITY-Aappos(a) Original patternENTITY_ArecognizednsubjENTITY_Adobj(b) Generalized patternFigure 1: Dependency pattern before and after col-lapsing nn and appos dependency links using thegeneralizer GCD.2.4 Pattern constraintsDue to the automatic construction method, our setof patterns also contains samples derived from sen-tences that do not actually describe an interactionbetween proteins, although it does contain a pair ofinteracting proteins.
Such patterns lead to wrongmatches.
As a countermeasure, we define con-straints an extracted pattern has to fulfill.
Patternsnot adhering to these constraints are removed fromthe pattern set, thus increasing precision.
Standard(shallow) heuristics for doing so are the exclusion ofnegation words (CNW) and the restriction to patternscontaining interaction-related words from a prede-fined set (CIW).
Patterns containing negations po-tentially match two negative protein pairs.
Such pat-tern can be removed to prevent wrong extractions.For negation words, the list described in (Fundelet al, 2007) was used.
Additionally, patterns con-taining the dependency type conj no*, conj or, orprep without are also removed.
On top of those pre-viously known approaches, we developed two newfilter to leverage the semantic richness of the DTs.Dependency combination (CDC): Interactionwords are organized into the following categories:verb, adjective and noun.
Based on linguistic con-siderations we define ?dependency patterns?
for thedifferent word types.
For example we assume thatinteraction verbs describe an action that originates inone protein and affects the other protein.
Obviously,the dependency combination subj with obj fulfillsthis consideration (for an example see Figure 1b).We manually evaluated a few DTs containing PPIfor each interaction word category (verb, noun, ad-jective) and determined all combinations of depen-dency types that are valid for the given category.
Theresulting combinations are listed in Table 2.Part of speech Dependency type combinationNounprep prepprep nnprep amodnn nnnn amodVerbprep subjprep infmodprep partmodobj subjobj infmodobj partmodAdjective amodTable 2: Allowed dependency type combinationsbased on classes of POS classes (constraint CDC).subj = {nsubj, nsubjpass, xsubj, csubj,csubjpass}, obj = {dobj, pobj, iobj} andprep = {prep *, agent}Syntax Filter (CSF): A particular case in PPI ex-traction are sentences with enumerations, as shownin Figure 2.
Such (possibly quite long; the longestenumeration we found contains not less than 9 pro-teins) enumerations greatly increase the number ofprotein pairs.We observed that sentences in which the commondependency type is prep between or nn often dodescribe an association between the connected pro-teins.
Accordingly, such patterns are retained.The remaining pairs inside enumerations oftendo not describe an interaction between each other.Therefore, we developed a special handling of enu-merations, based on dependency types.
If two pro-teins have a common ancestor node connected by thesame dependency type, we assume that those pro-teins do not interact with each other.
Accordingly,we remove all such patterns.4ENTITY_Bact ivatesnsubjENTITY_BdobjENTITY_AapposENTITY_AapposFigure 2: Dependency tree (DT) for the entityblinded sentence ?ENTITY B activates ENTITY B,ENTITY A, ENTITY A.?
with the initial patternhighlighted in bold red.
Application of CSF removesthis pattern.3 ResultsFor evaluation we use five manually annotatedbenchmark corpora: AIMed, BioInfer, HPRD50,IEPA, and LLL.
Those have been unified to the?greatest common factors?
by Pyysalo et al (2008).This means that protein names in the corpora aretagged and that interactions are undirected and bi-nary.
A basic overview of the corpora can be foundin Table 1 of (Airola et al, 2008).A sentence with n entities contains(n2)differentundirected entity pairs.
For each entity pair in asentence, we generate a separate evaluation exam-ple, apply entity blinding and generate the DT inthe same manner as previously described for gen-erating the pattern set.
All patterns are then matchedagainst the DTs of the sentences from the evalua-tion corpora.
If at least one pattern matches, the pairis counted as positive otherwise as negative.
Fromthis information we calculate precision, recall, andF1 scores.Table 3 shows results using the initial pattern setand the different configurations of generalized / fil-tered pattern sets.
We evaluate the impact of shallowand grammar-based methods separately.
Recall thatSshallow encompasses stemming (GST), substitutionof interaction words (GIW), suffix/prefix removal atentity names (GPN), and interaction (CIW) and nega-tion word filtering (CNW), while Sgrammar-based en-compasses unification of dependency types (GUD),collapsing dependency links (GCD), the dependencycombination constraint (CDC) and the syntax fil-ter (CSF).
In addition, results after application ofall generalizers Sgeneralizers, all constraints Sconstraints0.00.20.40.60.81.0AIMedBioInferHPRD50IEPALLLPrecisionRecallF1Figure 3: Results for the five corpora using the set-ting achieving highest overall F1 (Sall).and the combination of both Sall are also included.Corpus-specific results for the best setting in termsof F1 (Sall) are shown in Figure 3.Setting P R F1 #Baseline Sinitial 23.2 34.8 27.8 478 kGeneralizersGPN 23.4 37.0 28.7 423 kGIW 26.2 45.3 33.2 453 kGST 24.1 37.4 29.3 471 kGUD 24.0 38.3 29.5 467 kGCD 26.3 48.9 34.2 418 kConstraintsCNW 23.4 34.8 28.0 455 kCIW 42.5 17.2 24.5 322 kCDC 39.5 15.9 22.7 318 kCSF 28.2 32.6 30.3 419 kCombinationsSgeneralizers 28.2 69.0 39.9 290 kSconstraints 68.3 12.7 21.4 224 kSshallow 40.9 31.4 35.5 253 kSgrammar-based 33.2 42.1 37.2 264 kSall 38.2 54.8 45.0 152 kTable 3: Performance of pattern sets on the ensem-ble of all five corpora.
# denotes the pattern set size.4 DiscussionWe presented a pattern-based approach to extractprotein-protein interactions from text.
Our maincontribution in this paper was a systematic study onthe usage of dependency types within this approach.We showed that using such knowledge, F1 on aver-age improves by 9.4 percentage points (pp) (27.8 %to 37.2 %) as measured on the five benchmark PPIcorpora.Apart from this result, we note that our method5also has a number advantageous features: First, pat-terns are learned from co-mentions of pairs of pro-teins known to interact, and hence no annotated cor-pus is necessary.
This does not only make an ap-plication of the method for new tasks easier andcheaper, but also prevents over-fitting to a trainingcorpus.
Note, that as shown recently by (Airola etal., 2008; Tikk et al, 2010), essentially all state-of-the-art machine learning methods show large per-formance differences depending on whether or notthe evaluation and training examples are drawn fromthe same corpus.
In particular, cross-validation re-sults of those are consistently more optimistic thanthe more realistic cross-learning results.
In contrast,a pattern-based approach like ours is not prone toover-fitting.
Furthermore, debugging our method israther simple.
Unlike when using a black-box ma-chine learning method, whenever a false positivematch is found, one can pinpoint the specific patternproducing it and take action.The work most closely related to ours isRelEx (Fundel et al, 2007).
RelEx uses a smallset of fixed rules to extract directed PPIs from de-pendency trees.
Some of these rules also take ad-vantage of dependency types, for instance, to prop-erly treat enumerations.
A reimplementation ofRelEx (Pyysalo et al, 2008) was recently evalu-ated on the same corpora we used (see Table 7) andwas found to be on par with other systems, thoughsome of its measures were considerably worse thanthose reported in the original publication.
Com-pared to our approach, RelEx is similar in that itperforms pattern matching on DTs using informa-tion encoded in dependency types, however, thereare some notable differences: First, RelEx ruleswere defined manually and are highly specific toprotein-protein interactions.
It is not clear how thesecould be adapted to other applications; in contrast,we described a general method that performs pat-tern learning from automatically generated exam-ples.
Second, it is not clear how RelEx resultscould be further improved except by trial-and-errorwith more rules.
In contrast, our pattern learningmethod offers a natural way of improvement by sim-ply increasing the number of examples and hence thenumber of patterns.
We compared the results of ourapproach using an increasingly larger pattern set andobserved a continuous increase in F1, due to a con-tinuous improvement in recall.
Consequently, usingmore PPI databases would likely produce better re-sults.
Third, our generalization methods can be seenas graph rewriting rules.
The result of applying themto a DT is, again, a DT; thus, they can easily be usedas pre-processing coupled with other PPI extractionmethods (a direction we are currently exploring).
Incontrast, RelEx matches patterns against DTs, butcannot be used to transform DTs.In the following, we discuss the impact of the re-finement methods individually and provide a brieferror analysis based on a random sample of falsenegative pairs and a random sample of low preci-sion patterns.
We also compare our best results withthose of several state-of-the-art methods.4.1 Generalizers and constraintsAs can be seen in Table 3, all of the generalizers in-creased recall and even provide minor improvementin precision.
For the combination of all five general-izers (Sgeneralizers), an overall increase of 34.2 pp inrecall and 5 pp in precision was observed.
From theshallow generalizers, merging interaction phrases(GIW) was proven to be the most effective, account-ing for an increase of 10.5 pp in recall and 3 pp inprecision.
As shown in Table 4, the general variant,which merges all interaction phrases to a commonword, is slightly superior to the variant in which in-teraction words are merged class-wise.GIW variant P R F1Specific 26.1 44.7 33.0General 26.2 45.4 33.2Table 4: Results for collapsing interaction wordvariants (GIW).For the grammar-based generalizer unifying de-pendency types (GUD), each of the different variantswas evaluated separately (see Table 5).
The com-bination of the all different variants leads to an in-crease of 3.5 pp in recall.
As shown in Table 6, col-lapsing the dependency types nn and appos (GCD)also provides the highest improvement when appliedin combination.In contrast to generalizers that alter patterns, con-straints remove patterns from the pattern set.
Asshown in Table 3, application of all constraints6GUD variant P R F1subj 23.4 35.1 28.1obj 23.3 34.9 27.9prep 24.0 37.0 29.1nn 23.1 35.6 28.1sopn 24.0 38.3 29.5Table 5: Dependency type aggregations used in gen-eralizer GUD.
sopn combines the dependency ag-gregations for subj, obj, prep, and nn.GCD variant P R F1appos 23.6 38.1 29.2nn 25.8 45.3 32.9appos+nn 26.3 48.9 34.2Table 6: Impact of collapsing the dependency typesappos and nn using generalizer GCD.
(Sconstraints) leads to an increase in precision of45.1 pp at the cost of 22.1 pp reduced recall.The shallow constraint that disallows patternswith negation words (CNW) has comparably littleimpact and removes only 5 % of the patterns.
In con-trast, the interaction word constraint (CIW) is lessconservative and removes more than 32.6 % of thepatterns, trading off an increase of 19.3 pp in preci-sion to a decrease of 17.6 pp in recall.Among the grammar-based constraints, the de-pendency combination constraint CDC is supersededby the syntax filter constraint (CSF) that removes12 % of the patterns and increases precision about5 pp while recall drops by only 2.2 pp.
Note that CSFis the only constraint substantially increasing F1.As seen in Table 3, combinations of generalizersand constraints yield almost fully additive improve-ments.
The combination of all shallow refinementsonly (Sshallow) leads to an increase of 7.7 pp in F1,whereas with the addition of our grammar-based re-finements (Sall) a total increase of 17.2 pp in F1 isachieved.
We justify that the inclusion of depen-dency type information adds a source of knowledgethat further improves on conventional methods suchas stemming or negation filtering.4.2 Comparison with other methodsWe compare the results of our best setting (Sall) withthe results of the recently published analysis of ninestate-of-the-art machine learning methods for PPIextraction (Tikk et al, 2010).
For these methods, across-learning evaluation by training each kernel onthe ensemble of four corpora and evaluating it on thefifth has been performed.
Detailed results are givenin Table 7.
In terms of F1 we achieve on BioInfer,the corpus with most protein pairs, the second-bestresult.
On IEPA and LLL we achieve mid-range re-sults and on AIMed and HPRD50 we yield resultsbelow average.
Overfitting remains a severe prob-lem in ML based methods as these results are infe-rior to those measured in cross-validation (Tikk etal., 2010), though there are suggestions to overcomethis issue even in a ML setting (Miwa et al, 2009).4.3 Error analysisWe randomly picked 30 gold standard sentences (allcorpora) containing false negatives pairs and investi-gated all 72 false negative pairs included therein.
For29 positive pairs, possibly matching pattern were re-moved by CDC, as the corresponding dependencycombination was not covered in our rule set.
Fur-ther 16 graphs passed the filtering, but our set ofsentences contained no adequate pattern.
The thirdlargest fraction of errors (13 cases) are pairs which,by our understanding, hardly describe an interaction.In 11 cases, the dependency parse trees are incorrectand therefore they do not provide the correct syntac-tic information.
For 7 pairs, the shortest path coversinsufficient syntactic information to decide whethertwo proteins interact.
For instance Figure 4 pro-vides not enough information on the shortest path,whereas the second shortest path would provide suf-ficient information.
Finally, three pairs were filteredby the CIW filter, as their interaction words weremissing from our list.We conclude that some constraints (especiallyCDC and CIW) are too aggressive.
Relaxation ofthese syntactic rules should lead to higher recall.We also analyzed the 30 patterns producing themost false positives matches.
20 of them containedan interaction verb, the remaining 10 an interactionnoun.
The 10 noun patterns produced more thantwice as many false positives as the 20 verb patternswhile matching about 50 % less true positives.
Thesingle noun pattern producing the most false posi-tives (356) can be seen on Figure 5a.
Among the 10,four additional patterns can be seen as an extension7MethodAIMed BioInfer HPRD50 IEPA LLLP R F1 P R F1 P R F1 P R F1 P R F1Shallow linguistic (Giuliano et al, 2006) 28.3 86.6 42.6 62.8 36.5 46.2 56.9 68.7 62.2 71.0 52.5 60.4 79.0 57.3 66.4Spectrum tree (Kuboyama et al, 2007) 20.3 48.4 28.6 38.9 48.0 43.0 44.7 77.3 56.6 41.6 9.6 15.5 48.2 83.5 61.2k-band shortest path (Tikk et al, 2010) 28.6 68.0 40.3 62.2 38.5 47.6 61.7 74.2 67.4 72.8 68.7 70.7 83.7 75.0 79.1Cosine distance (Erkan et al, 2007) 27.5 59.1 37.6 42.1 32.2 36.5 63.0 56.4 59.6 46.3 31.6 37.6 80.3 37.2 50.8Edit distance (Erkan et al, 2007) 26.8 59.7 37.0 53.0 22.7 31.7 58.1 55.2 56.6 58.1 45.1 50.8 68.1 48.2 56.4All-paths graph (Airola et al, 2008) 30.5 77.5 43.8 58.1 29.4 39.1 64.2 76.1 69.7 78.5 48.1 59.6 86.4 62.2 72.3RelEx reimpl.
(Pyysalo et al, 2008) 40.0 50.0 44.0 39.0 45.0 41.0 76.0 64.0 69.0 74.0 61.0 67.0 82.0 72.0 77.0Our method (Sall) 25.8 62.9 36.6 43.4 50.3 46.6 48.3 51.5 49.9 67.5 58.2 62.5 70.3 70.7 70.5Table 7: Cross-learning results.
Classifiers are trained on the ensemble of four corpora and tested on thefifth one (except for the rule-based RelEx).
Best results are typeset in bold.of this pattern leading to a total amount of 732 falsepositives while only 172 true positives.
This phe-nomenon is caused by the way in which generaliz-ers and constraints are currently applied.
The unifi-cation of different prep * dependency types to thegeneral prep (GUD) makes some dependency typecombinations indistinguishable, e.g.
(prep to,prep to) and (prep to, prep of).
The depen-dency type combination constraint (CDC) would dis-allow a pattern containing the first combination, butas it is not applied in the matching phase, its benefitscannot be realized.
A lesson learned from this exam-ple is that constraints should also be applied in thematching step as follows.
After a successful match,the constraints should be applied to the original un-generalized counterparts of the matching subgraphs.Similar conclusions can be drawn from examiningthe verb pattern producing the most false positivesshown in Figure 5b.5 ConclusionWe presented a pattern-based approach to extractPPIs from literature.
Its unique features are the ca-pability of learning patterns from ?cheap?
trainingdata, i.e., co-mentions of proteins known to inter-act, and the use of linguistically motivated refine-ments on the dependency structures of the DT it op-erates on.
We utilized the fact that not all depen-dency types are of equal importance for relation ex-traction; for instance, collapsing dependency links(GCD) or unifying dependencies (GUD) considerablyimproved extraction performance.
However, as ourerror analysis shows, especially our filtering meth-ods deserve further study.
Even without manuallyannotated training data, our approach performs onENTITY_A ENTITY_Aconj_andinterac tnsubj nsubjFigure 4: Example dependency parse where the in-formation extracted by the shortest path (highlightedin bold red) is insufficient.ENTITY_AinounprepENTITY_Aprep(a) Noun patternENTITY_AiverbsubjENTITY_Aprep(b) Verb patternFigure 5: Patterns producing the most false posi-tives.
Depicted dependency types are generalizedaccording to GUD and GIW.par with state-of-the-art machine learning methodswhen evaluated in a cross-learning setting.
In par-ticular, it reaches the second best performance (interms of F-measure) of all approaches on the largestPPI corpus.Apart from presenting a volatile and elegant newmethod for relationship extraction, we believe thatour study on using dependency type informationalso will be helpful for advancing the performanceof other methods.
For instance, we are currentlyexperimenting with using our DT-rewrite rules as apreprocessor for a kernel-based extraction method.AcknowledgmentsPT was supported by BMBF, grant No 0315417B;IS was supported by DAAD; DT was supported byAlexander von Humboldt-Foundation.8ReferencesA.
Airola, S. Pyysalo, F Ginter J. Bjo?rne, andT.
Pahikkala.
2008.
All-paths graph kernel forprotein-protein interaction extraction with evaluationof cross-corpus learning.
BMC Bioinformatics, 9:S2.B.
Aranda, P. Achuthan, Y. Alam-Faruque, I. Armean,A.
Bridge, C. Derow, M. Feuermann, et al 2010.
TheIntAct molecular interaction database in 2010.
Nu-cleic Acids Res, 38:D525?D531, Jan.DM.
Bikel.
2002.
Design of a Multi-lingual, Parallel-processing Statistical Parsing Engine.
In In HumanLanguage Technology Conference, pages 24?27.C.
Blaschke, L. Hirschman, and A. Valencia.
2002.
In-formation extraction in molecular biology.
Briefingsin Bioinformatics, 3(2):154?165.R.
Bunescu and R. Mooney.
2006.
Subsequence Kernelsfor Relation Extraction.
In Y. Weiss, B. Scho?lkopf,and J. Platt, editors, Advances in Neural InformationProcessing Systems 18, pages 171?178.
MIT Press,Cambridge, MA.E.
Buyko, E. Faessler, J. Wermter, and U. Hahn.
2009.Event extraction from trimmed dependency graphs.
InBioNLP?09, pages 19?27.A.
Ceol, Chatr AA., L. Licata, D. Peluso, L. Briganti,L.
Perfetto, L. Castagnoli, and G. Cesareni.
2010.MINT, the molecular interaction database: 2009 up-date.
Nucl.
Acids Res., 38(suppl1):D532?539.A.
Culotta and JS.
Sorensen.
2004.
Dependency TreeKernels for Relation Extraction.
In ACL?04, pages423?429.MC.
De Marneffe, B.Maccartney, and CD.
Manning.2006.
Generating typed dependency parses fromphrase structure parses.
In In LREC 2006.G.
Erkan, A. O?zgu?r, and DR. Radev.
2007.
Semi-Supervised Classification for Extracting Protein Inter-action Sentences using Dependency Parsing.
In Proc.of EMNLP?CoNLL?07, pages 228?237.K.
Fundel, R. Ku?ffner, and R. Zimmer.
2007.
RelEx ?
re-lation extraction using dependency parse trees.
Bioin-formatics, 23(3):365?371, February.A.
Giuliano, A. Lavelli, and L. Romano.
2006.
Ex-ploiting Shallow Linguistic Information for RelationExtraction from Biomedical Literature.
In Proc.
ofEACL?06, pages 401?408, Trento, Italy.
The Associ-ation for Computer Linguistics.J.
Hakenberg, U. Leser, H. Kirsch, and D. Rebholz-Schuhmann.
2006.
Collecting a large corpus from allof Medline.
In SMBM?06, pages 89?92, April.J.
Hakenberg, C. Plake, R. Leaman, M. Schroeder,and G. Gonzalez.
2008.
Inter-species normaliza-tion of gene mentions with GNAT.
Bioinformatics,24(16):i126?132.J.
Hakenberg, R. Leaman, NH.
Vo, S.Jonnalagadda,R.
Sullivan, C. Miller, L. Tari, C. Baral, and G. Gon-zalez.
2010.
Efficient extraction of protein-proteininteractions from full-text articles.
IEEE/ACM TransComput Biol Bioinform, 7(3):481?494.Y.
Hao, X. Zhu, M. Huang, and M. Li.
2005.
Discov-ering patterns to extract protein-protein interactionsfrom the literature: Part II.
Bioinformatics, 21:3294?3300.J.
Kazama, T. Makino, Y. Ohta, and J. Tsujii.
2002.Tuning support vector machines for biomedical namedentity recognition.
In Proc.
of BioNLP at ACL?02,page 8.S.
Kim, J. Yoon, J Yang, and S. Park.
2010.
Walk-weighted subsequence kernels for protein-protein in-teraction extraction.
BMC Bioinformatics, 11(1):107.R.
Kuboyama, K. Hirata, H. Kashima, KF.
Aoki-Kinoshita, and H. Yasuda.
2007.
A spectrum tree ker-nel.
Information and Media Technologies, 2(1):292?299.H.
Liu, V. Keselj, and C. Blouin.
2010.
Biological EventExtraction using Subgraph Matching.
In SMBM?10,October.M.
Miwa, R. S?tre, Y. Miyao, T. Ohta, and J. Tsujii.2008.
Combining multiple layers of syntactic infor-mation for protein-protein interaction extraction.
InSMBM?08, pages 101?108.M.
Miwa, R. S?tre, Y. Miyao, and J. Tsujii.
2009.A Rich Feature Vector for Protein-Protein InteractionExtraction from Multiple Corpora.
In EMNLP?09,pages 121?130.S.
Pyysalo, A. Airola, J. Heimonen, J. Bjrne, F. Gin-ter, and T. Salakoski.
2008.
Comparative analysis offive protein-protein interaction corpora.
BMC Bioin-formatics, 9 Suppl 3:S6.F.
Rinaldi, G. Schneider, K. Kaljurand, S. Clematide,T.
Vachon, and M. Romacker.
2010.
Ontogene inbiocreative ii.5.
IEEE/ACM Trans Comput Biol Bioin-form, 7(3):472?480.L.
Smith, T. Rindflesch, and W. J. Wilbur.
2004.
Med-Post: a part-of-speech tagger for bioMedical text.Bioinformatics, 20(14):2320?2321, Sep.JM.
Temkin and MR. Gilder.
2003.
Extraction of proteininteraction information from unstructured text using acontext-free grammar.
Bioinformatics, 19(16):2046?2053, Nov.D.
Tikk, P. Thomas, P. Palaga, J. Hakenberg, andU.
Leser.
2010.
A comprehensive benchmark ofkernel methods to extract protein-protein interactionsfrom literature.
PLoS Comput Biol, 6:e1000837.D.
Zhou and Y.
He.
2008.
Extracting interactions be-tween proteins from the literature.
J Biomed Inform,41(2):393?407, April.9
