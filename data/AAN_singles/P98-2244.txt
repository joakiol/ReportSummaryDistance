Optimal Multi-Paragraph Text Segmentation byDynamic ProgrammingOskari HeinonenUniversity of  Helsinki, Department of  Computer ScienceP.O.
Box 26 (Teollisuuskatu 23), F IN-00014 University of  Helsinki, FinlandOskari.Heinonen @ cs.Helsinki.FIAbstractThere exist several methods of calculating a similar-ity curve, or a sequence of similarity values, repre-senting the lexical cohesion of successive text con-stituents, e.g., paragraphs.
Methods for decidingthe locations of fragment boundaries are, however,scarce.
We propose a fragmentation method basedon dynamic programming.
The method is theoret-ically sound and guaranteed to provide an optimalsplitting on the basis of a similarity curve, a pre-ferred fragment length, and a cost function defined.The method is especially useful when control onfragment size is of importance.1 IntroductionElectronic full-text documents and digital librariesmake the utilization of texts much more effectivethan before; yet, they pose new problems and re-quirements.
For example, document retrieval basedon string searches typically returns either the wholedocument or just the occurrences of the searchedwords.
What the user often is after, however, is mi-crodocument: a part of the document that containsthe occurrences and is reasonably self-contained.Microdocuments can be created by utilizing lex-ical cohesion (term repetition and semantic rela-tions) present in the text.
There exist several meth-ods of calculating a similarity curve, or a sequenceof similarity values, representing the lexical cohe-sion of successive constituents ( uch as paragraphs)of text (see, e.g., (Hearst, 1994; Hearst, 1997; Koz-ima, 1993; Morris and Hirst, 1991; Yaari, 1997;Youmans, 1991)).
Methods for deciding the loca-tions of fragment boundaries are, however, not thatcommon, and those that exist are often rather heuris-tic in nature.To evaluate our fragmentation method, to be ex-plained in Section 2, we calculate the paragraphsimilarities as follows.
We employ stemming, re-move stopwords, and count the frequencies of theremaining words, i.e., terms.
Then we take a pre-defined number, e.g., 50, of the most frequent termsto represent the paragraph, and count the similar-ity using the cosine coefficient (see, e.g., (Salton,1989)).
Furthermore, we have applied a sliding win-dow method: instead of just one paragraph, sev-eral paragraphs on both sides of each paragraphboundary are considered.
The paragraph vectors areweighted based on their distance from the boundaryin question with immediate paragraphs having thehighest weight.
The benefit of using a larger win-dow is that we can smooth the effect of short para-graphs and such, perhaps example-type, paragraphsthat interrupt achain of coherent paragraphs.2 Fragmentation by DynamicProgrammingFragmentation is a problem of choosing the para-graph boundaries that make the best fragmentboundaries.
The local minima of the similaritycurve are the points of low lexical cohesion and thusthe natural candidates.
To get reasonably-sized mi-crodocuments, the similarity information alone isnot enough; also the lengths of the created frag-ments have to be considered.
In this section, we de-scribe an approach that performs the fragmentationby using both the similarities and the length infor-mation in a robust manner.
The method is based ona programming paradigm called dynamic program-ming (see, e.g., (Cormen et al, 1990)).
Dynamicprogramming as a method guarantees the optimal-ity of the result with respect o the input and theparameters.The idea of the fragmentation algorithm is as fol-lows (see also Fig.
1).
We start from the first bound-ary and calculate acost for it as if the first paragraphwas a single fragment.
Then we take the secondboundary and attach to it the minimum of the twoavailable possibilities: the cost of the first two para-graphs as if they were a single fragment and the cost1484fragmentation(n, p, h, len\[1..n\], sim\[1..n - 1\])/* n no.
of pars, p preferred frag length, h scaling */I* len\[1..n\] par lengths, sim\[1..n - 1\] similarities */{sire\[O\] := 0.0; cost\[O\] := 0.0; B := 0;for par := 1 to n {lensum := 0;/* cumulative fragment length */emin  := MAXREAL;for i := par to I {lensum := lensurn + len\[i\];c := Cle,(lensum, p, h);i f  e ~> emin  { / *  optimization */exit the innermost for loop;}e := c + cost\[i - 1\] + sim\[i - 1\];i f  C < Cmin  {Cmin  := C ;  IOC-Cmin  := i - -  1 ;}}cost~ar\] := Cmin; linkp,ev\[par\] := lot-train;}j := n;while linkprev\[j\] > 0 {B := B t_J linkprev\[j\]; j := linkprev\[j\];)return(B);/* set of chosen fragment boundaries */Figure 1: The dynamic programming algorithm forfragment boundary detection.of the second paragraph as a separate fragment.
Inthe following steps, the evaluation moves on by oneparagraph at each time, and all the possible loca-tions of the previous breakpoint are considered.
Wecontinue this procedure till the end of the text, andfinally we can generate a list of breakpoints that in-dicate the fragmentation.The cost at each boundary is a combination ofthree components: the cost of fragment length Clen,and the cost cost\[.\] and similarity sim\[.\] of someprevious boundary.
The cost function Clen gives thelowest cost for the preferred fragment length givenby the user, say, e.g., 500 words.
A fragment whichis either shorter or longer gets a higher cost, i.e., ispunished for its length.
We have experimented withtwo families of cost functions, a family of seconddegree functions (parabolas),~z + 1),and V-shape linear functions,Clen(X,p,h) = Ih(~ - 1)1,1485Mats.
Chaplet II.
Section I.i 0.S0.4 .,~0.3 t ?0.20.10 IT1000i Ill2OOOI 'i ,i .
.
.
.3000 4000 5000wocdcounl(a)"W6ClinHO.25L""W6ClinH0.SL""W6ClinH0.75L""W6ClinH 1.0L""W6ClinH 1.25L""W6ClinH 1 .SL"?
W6L ?
.
.
.
.II1~11 -7 .
.
.
.6000 7000Mars.
Chapter IL Section I.i 0.6"~ 0.50.40.30.20.10t i!
,IH I1000 2000 3000 4000"W6CparH0.25L" ?
"W6C~rH0.SL" ?
"W6CparH0.75L" ?
"W6CparH1.0L" ?T "W6CI~d-11.2$L" *'WSCparHI.SL" ??
"W61."
- - -If 111 -ii-- 7 .
.
.
.5000 6000 7000wotdt~mnt(b)Figure 2: Similarity curve and detected fragmentboundaries with different cost functions.
(a) Lin-ear.
(b) Parabola.
p is 600 words in both (a) & (b).
"H0.25", etc., indicates the value of h. Vertical barsindicate fragment boundaries while short bars belowhorizontal axis indicate paragraph boundaries.where x is the actual fragment length, p is the pre-ferred fragment length given by the user, and h is ascaling parameter that allows us to adjust he weightgiven to fragment length.
The smaller the value ofh, the less weight is given to the preferred fragmentlength in comparison with the similarity measure.3 ExperimentsAs test data we used Mars by Percival Lowell, 1895.As an illustrative xample, we present he analysisof Section I.
Evidence of  it of Chapter II.
Atmo-sphere.
The length of the section is approximately6600 words and it contains 55 paragraphs.
The frag-ments found with different parameter settings canbe seen in Figure 2.
One of the most interesting isthe one with parabola cost function and h = .5.
Inthis case the fragment length adjusts nicely accord-ing to the similarity curve.
Looking at the text, mostfragments have an easily identifiable topic, like at-mospberic hemistry in fragment 7.
Fragments 2and 3 seem to have roughly the same topic: measur-ing the diameter of the planet Mars.
The fact thatthey do not form a single fragment can be explainedcost functionlinearparabolah.25.50.751.001.251.50.25.50.751.001.251.50lavg /min /max davg1096.1 501 3101 476.5706.4 501 1328 110.5635.7 515 835 60.1635.7 515 835 59.5635.7 515 835 59.5635.7 515 835 57.6908.2 501 1236 269.4691.0 319 1020 126.0676.3 371 922 105.8662.2 371 866 94.2648.7 466 835 82.4635.7 473 835 69.9Table 1: Variation of fragment length.
Columns:lavg, lmin, Imax average, minimum, and maximumfragment length; and davg average deviation.by the preferred fragment length requirement.Table 1 summarizes the effect of the scaling fac-tor h in relation to the fragment length variationwith the two cost functions over those 8 sectionsof Mars that have a length of at least 20 para-graphs.
The average deviation davg with respectto the preferred fragment length p is defined asdavg = (~-'~n= 1 \[P -- lil)/m where li is the length offragment i, and m is the number of fragments.
Theparametric cost function chosen affects the result alot.
As expected, the second degree cost functionallows more variation than the linear one but roleschange with a small h. Although the experiment isinsufficient, we can see that in this example a factorh > 1.0 is unsuitable with the linear cost function(and h = 1.5 with the parabola) since in these casesso much weight is given to the fragment length thatfragment boundaries can appear very close to quitestrong local maxima of the similarity curve.4 ConclusionsIn this article, we presented a method for detect-ing fragment boundaries in text.
The fragmentationmethod is based on dynamic programming and isguaranteed togive an optimal solution with respectto a similarity curve, a preferred fragment length,and a parametric fragment-length cost function de-fined.
The method is independent of the similaritycalculation.
This means that any method, not nec-essarily based on lexical cohesion, producing asuit-able sequence of similarities can be used prior toour fragmentation method.
For example, the lexicalcohesion profile (Kozima, 1993) should be perfectlyusable with our fragmentation method.1486The method is especially useful when controlover fragment size is required.
This is the casein passage retrieval since windows of 1000 bytes(Wilkinson and Zobel, 1995) or some hundredwords (Callan, 1994) have been proposed as bestpassage sizes.
Furthermore, we believe that frag-ments of reasonably similar size are beneficial inour intended purpose of document assembly.AcknowledgementsThis work has been supported by the FinnishTechnology Development Centre (TEKES) togetherwith industrial partners, and by a grant from the350th Anniversary Foundation of the Universityof Helsinki.
The author thanks Helena Ahonen,Barbara Heikkinen, Mika Klemettinen, and JuhaK~kk~iinen for their contributions to the work de-scribed.ReferencesJ.
P. Callan.
1994.
Passage-level vidence in doc-ument retrieval.
In Proc.
SIGIR'94, Dublin, Ire-land.T.
H. Cormen, C. E. Leiserson, and R. L. Rivest.1990.
Introduction to Algorithms.
MIT Press,Cambridge, MA, USA.M.
A. Hearst.
1994.
Multi-paragraph segmentationof expository text.
In Proc.
ACL-gg, Las Cruces,NM, USA.M.
A. Hearst.
1997.
TextTiling: Segmenting textinto multi-paragraph subtopic passages.
Compu-tational Linguistics, 23(1):33-64, March.H.
Kozima.
1993.
Text segmentation based on sim-ilarity between words.
In Proc.
ACL-93, Colum-bus, OH, USA.J.
Morris and G. Hirst.
1991.
Lexical cohesioncomputed by thesaural relation as an indicator ofthe structure of text.
Computational Linguistics,17(1):21-48.G.
Salton.
1989.
Automatic Text Processing: TheTransformation, Analysis, and Retrieval of lnfor-mation by Computer.
Addison-Wesley, Reading,MA, USA.R.
Wilkinson and J. Zobel.
1995.
Comparison offragmentation schemes for document retrieval.
InOverview of TREC-3, Gaithersburg, MD, USA.Y.
Yaari.
1997.
Segmentation f expository texts byhierarchical agglomerative clustering.
In Proc.RANLP'97, Tzigov Chark, Bulgaria.G.
Youmans.
1991.
A new tool for discourse anal-ysis.
Language, 67(4):763-789.
