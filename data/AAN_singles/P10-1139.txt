Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1367?1375,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsA Unified Graph Model for Sentence-based Opinion RetrievalBinyang Li, Lanjun Zhou, Shi Feng, Kam-Fai WongDepartment of Systems Engineering and Engineering ManagementThe Chinese University of Hong Kong{byli, ljzhou, sfeng, kfwong}@se.cuhk.edu.hkAbstractThere is a growing research interest in opinionretrieval as on-line users?
opinions are becom-ing more and more popular in business, socialnetworks, etc.
Practically speaking, the goal ofopinion retrieval is to retrieve documents,which entail opinions or comments, relevant toa target subject specified by the user?s query.
Afundamental challenge in opinion retrieval isinformation representation.
Existing researchfocuses on document-based approaches anddocuments are represented by bag-of-word.However, due to loss of contextual information,this representation fails to capture the associa-tive information between an opinion and itscorresponding target.
It cannot distinguish dif-ferent degrees of a sentiment word when asso-ciated with different targets.
This in turn se-riously affects opinion retrieval performance.In this paper, we propose a sentence-based ap-proach based on a new information representa-tion, namely topic-sentiment word pair, to cap-ture intra-sentence contextual information be-tween an opinion and its target.
Additionally,we consider inter-sentence information to cap-ture the relationships among the opinions onthe same topic.
Finally, the two types of infor-mation are combined in a unified graph-basedmodel, which can effectively rank the docu-ments.
Compared with existing approaches,experimental results on the COAE08 datasetshowed that our graph-based model achievedsignificant improvement.1 IntroductionIn recent years, there is a growing interest insharing personal opinions on the Web, such asproduct reviews, economic analysis, politicalpolls, etc.
These opinions cannot only help inde-pendent users make decisions, but also obtainvaluable feedbacks (Pang et al, 2008).
Opinionoriented research, including sentiment classifica-tion, opinion extraction, opinion question ans-wering, and opinion summarization, etc.
are re-ceiving growing attention (Wilson, et al, 2005;Liu et al, 2005; Oard et al, 2006).
However,most existing works concentrate on analyzingopinions expressed in the documents, and noneon how to represent the information needs re-quired to retrieve opinionated documents.
In thispaper, we focus on opinion retrieval, whose goalis to find a set of documents containing not onlythe query keyword(s) but also the relevant opi-nions.
This requirement brings about the chal-lenge on how to represent information needs foreffective opinion retrieval.In order to solve the above problem, previouswork adopts a 2-stage approach.
In the first stage,relevant documents are determined and rankedby a score, i.e.
tf-idf value.
In the second stage,an opinion score is generated for each relevantdocument (Macdonald and Ounis, 2007; Oard etal., 2006).
The opinion score can be acquired byeither machine learning-based sentiment classifi-ers, such as SVM (Zhang and Yu, 2007), or asentiment lexicons with weighted scores fromtraining documents (Amati et al, 2007; Hannahet al, 2007; Na et al, 2009).
Finally, an overallscore combining the two is computed by using ascore function, e.g.
linear combination, to re-rankthe retrieved documents.Retrieval in the 2-stage approach is based ondocument and document is represented bybag-of-word.
This representation, however, canonly ensure that there is at least one opinion ineach relevant document, but it cannot determinethe relevance pairing of individual opinion to itstarget.
In general, by simply representing adocument in bag-of-word, contextual informa-tion i.e.
the corresponding target of an opinion, isneglected.
This may result in possible mismatchbetween an opinion and a target and in turn af-fects opinion retrieval performance.
By the sametoken, the effect to documents consisting of mul-1367tiple topics, which is common in blogs andon-line reviews, is also significant.
In this setting,even if a document is regarded opinionated, itcannot ensure that all opinions in the documentare indeed relevant to the target concerned.Therefore, we argue that existing informationrepresentation i.e.
bag-of-word, cannot satisfythe information needs for opinion retrieval.In this paper, we propose to handle opinion re-trieval in the granularity of sentence.
It is ob-served that a complete opinion is always ex-pressed in one sentence, and the relevant targetof the opinion is mostly the one found in it.Therefore, it is crucial to maintain the associativeinformation between an opinion and its targetwithin a sentence.
We define the notion of a top-ic-sentiment word pair, which is composed of atopic term (i.e.
the target) and a sentiment word(i.e.
opinion) of a sentence.
Word pairs canmaintain intra-sentence contextual information toexpress the potential relevant opinions.
In addi-tion, inter-sentence contextual information is alsocaptured by word pairs to represent the relation-ship among opinions on the same topic.
In prac-tice, the inter-sentence information reflects thedegree of a word pair.
Finally, we combine bothintra-sentence and inter-sentence contextual in-formation to construct a unified undirected graphto achieve effective opinion retrieval.The rest of the paper is organized as follows.In Section 2, we describe the motivation of ourapproach.
Section 3 presents a novel unifiedgraph-based model for opinion retrieval.
Weevaluated our model and the results are presentedin Section 4.
We review related works on opi-nion retrieval in Section 5.
Finally, in Section 6,the paper is concluded and future work is sug-gested.2 MotivationIn this section, we start from briefly describingthe objective of opinion retrieval.
We then illu-strate the limitations of current opinion retrievalapproaches, and analyze the motivation of ourmethod.2.1 Formal Description of ProblemOpinion retrieval was first presented in theTREC 2006 Blog track, and the objective is toretrieve documents that express an opinion abouta given target.
The opinion target can be a ?tradi-tional?
named entity (e.g.
a name of person, lo-cation, or organization, etc.
), a concept (e.g.
atype of technology), or an event (e.g.
presidentialelection).
The topic of the document is not re-quired to be the same as the target, but an opi-nion about the target has to be presented in thedocument or one of the comments to the docu-ment (Macdonald and Ounis, 2006).
Therefore,in this paper we regard the information needs foropinion retrieval as relevant opinion.2.2 Motivation of Our ApproachIn traditional information retrieval (IR)bag-of-word representation is the most commonway to express information needs.
However, inopinion retrieval, information need target at re-levant opinion, and this renders bag-of-word re-presentation ineffective.Consider the example in Figure 1.
There arethree sentences A, B, and C in a document di.Now given an opinion-oriented query Q relatedto ?Avatar?.
According to the conventional2-stage opinion retrieval approach, di isrepresented by a bag-of-word.
Among the words,there is a topic term Avatar (t1) occurring twice,i.e.
Avatar in A and Avatar in C, and two senti-ment words comfortable (o1) and favorite (o2)(refer to Figure 2 (a)).
In order to rank this doc-ument, an overall score of the document di iscomputed by a simple combination of the rele-vant score ( ???????? )
and the opinion score(???????
), e.g.
equal weighted linear combination,as follows.????????
?
????????
?
??????
?For simplicity, we let ????????
?
?
??
?
??
??
, and???????
be computed by using lexicon-basedmethod: ???????
?
?????????????????
?
?????????????
?.Figure 1: A retrieved document di on the target?Avatar?.Although bag-of-word representation achievesgood performance in retrieving relevant docu-ments, our study shows that it cannot satisfy theinformation needs for retrieval of relevant opi-nion.
It suffers from the following limitations:(1) It cannot maintain contextual information;thus, an opinion may not be related to the targetof the retrieved document is neglected.
In thisexample, only the opinion favorite (o2) on Avatarin C is the relevant opinion.
But due to loss ofcontextual information between the opinion andits corresponding target, Avatar in A and com-A.
???????????
?Tomorrow, Avatar will be shown in China.B.
?????
IMAX?????????
?I?ve reserved a comfortable seat in IMAX.C.
???????????
3D??
?Avatar is my favorite 3D movie.1368fortable (o1) are also regarded as relevant opi-nion mistakenly, creating a false positive.
In re-ality comfortable (o1) describes ?the seats inIMAX?, which is an irrelevant opinion, and sen-tence A is a factual statement rather than an opi-nion statement.
(a)                (b)Figure 2: Two kinds of information representa-tion of opinion retrieval.
(t1=?Avatar?
o1= ?com-fortable?, o2=?favorite?
)(1) Current approaches cannot capture the re-lationship among opinions about the same topic.Suppose there is another document includingsentence C which expresses the same opinion onAvatar.
Existing information representationsimply does not cater for the two identical opi-nions from different documents.
In addition, ifmany documents contain opinions on Avatar, therelationship among them is not clearlyrepresented by existing approaches.In this paper, we process opinion retrieval inthe granularity of sentence as we observe that acomplete opinion always exists within a sentence(refer to Figure 2 (b)).
To represent a relevantopinion, we define the notion of topic-sentimentword pair, which consists of a topic term and asentiment word.
A word pair maintains the asso-ciative information between the two words, andenables systems to draw up the relationshipamong all the sentences with the same opinionon an identical target.
This relationship informa-tion can identify all documents with sentencesincluding the sentiment words and to determinethe contributions of such words to the target(topic term).
Furthermore, based on word pairs,we designed a unified graph-based method foropinion retrieval (see later in Section 3).3 Graph-based model3.1 Basic IdeaDifferent from existing approaches which simplymake use of document relevance to reflect therelevance of opinions embedded in them, ourapproach concerns more on identifying the re-levance of individual opinions.
Intuitively, webelieved that the more relevant opinions appearin a document, the more relevant is that docu-ment for subsequent opinion analysis operations.Further, since the lexical scope of an opiniondoes not usually go beyond a sentence, we pro-pose to handle opinion retrieval in the granularityof sentence.Without loss of generality, we assume thatthere is a document set ?
?
??
?, ?
?, ??,?
, ??
?, anda specific query  ?
?
??
?, ?
?, ??,?
, ???
, where?
?, ?
?, ??,?
, ??
are query keywords.
Opinion re-trieval aims at retrieving documents from ?with relevant opinion about the query ?.
In ad-dition, we construct a sentiment word lexicon ?
?and a topic term lexicon ??
(see Section 4).
Tomaintain the associative information between thetarget and the opinion, we consider the documentset as a bag of sentences, and define a sentenceset as ?
?
??
?, ?
?, ??,?
, ???.
For each sentence, wecapture the intra-sentence information throughthe topic-sentiment word pair.Definition 1. topic-sentiment word pair ???
con-sists of two elements, one is from ?
?, and theother one is from ??.???
?
??
?
?, ??
?
|??
?
??
, ??
?
???
?.The topic term from ??
determines relevanceby the query term matching, and the sentimentword from ??
is used to express an opinion.
Weuse the word pair to maintain the associative in-formation between the topic term and the opinionword (also referred to as sentiment word).
Theword pair is used to identify a relevant opinion ina sentence.
In Figure 2 (b), t1, i.e.
Avatar in C, isa topic term relevant to the query, and o2 (?favo-rite?)
is supposed to be an opinion; and the wordpair < t1, o2> indicates sentence C contains a re-levant opinion.
Similarly, we map each sentencein word pairs by the following rule, and expressthe intra-sentence information using word pairs.For each sentiment word of a sentence, wechoose the topic term with minimum distance asthe other element of the word pair:??
?
??
?
?, ??
?
|??
?
min??????
?, ???
for each ??
?According to the mapping rule, although asentence may give rise to a number of word pairs,only the pair with the minimum word distance isselected.
We do not take into consideration of theother words in a sentence as relevant opinionsare generally formed in close proximity.
A sen-tence is regarded non-opinionated unless it con-tains at least one word pair.In practice, not all word pairs carry equalweights to express a relevant opinion as the con-tribution of an opinion word differs from differ-ent target topics, and vice versa.
For example,the word pair < t1, o2> should be more probableas a relevant opinion than < t1, o1>.
To consider1369that, inter-sentence contextual information is ex-plored.
This is achieved by assigning a weight toeach word pair to measure their associative de-grees to different queries.
We believe that themore a word pair appears the higher should bethe weight between the opinion and the target inthe context.We will describe how to utilize intra-sentencecontextual information to express relevant opi-nion, and inter-sentence information to measurethe degree of each word pair through agraph-based model in the following section.3.2 HITS ModelWe propose an opinion retrieval model based onHITS, a popular graph ranking algorithm(Kleinberg, 1999).
By considering both in-tra-sentence information and inter-sentence in-formation, we can determine the weight of aword pair and rank the documents.HITS algorithm distinguishes hubs and au-thorities in objects.
A hub object has links tomany authorities.
An authority object, which hashigh-quality content, would have many hubslinking to it.
The hub scores and authority scoresare computed in an iterative way.
Our proposedopinion retrieval model contains two layers.
Theupper level contains all the topic-sentiment wordpairs ???
?
??
?
?, ??
?
|??
?
?
?, ??
?
????
.
The lowerlevel contains all the documents to be retrieved.Figure 3 gives the bipartite graph representationof the HITS model.Figure 3: Bipartite link graph.For our purpose, the word pairs layer is consi-dered as hubs and the documents layer authori-ties.
If a word pair occurs in one sentence of adocument, there will be an edge between them.In Figure 3, we can see that the word pair thathas links to many documents can be assigned ahigh weight to denote a strong associative degreebetween the topic term and a sentiment word,and it likely expresses a relevant opinion.
On theother hand, if a document has links to many wordpairs, the document is with many relevant opi-nions, and it will result in high ranking.Formally, the representation for the bipartitegraph is denoted as ?
??
?
?, ?
?, ???
?
, where??
?
?????
is the set of all pairs of topic wordsand sentiment words, which appear in one sen-tence.
??
?
???
?
is the set of documents.???
?
?????
|???
?
?
?, ??
?
???
corresponds to theconnection between documents and top-ic-sentiment word pairs.
Each edge ????
is asso-ciated with a weight ????
?
?0,1?
denoting thecontribution of ???
to the document ??
.
Theweight ????
is computed by the contribution ofword pair ???
in all sentences of ??
as follows:????
?
?|??|?
??
?
?????
?, ???
?
?1 ?
???????
?, ?????????????
?1??
|?
?| is the number of sentences in ??;?
?
is introduced as the trade-off parameter tobalance the ?????
?, ???
and ?????
?, ???;?
?????
?, ???
is computed to judge the relevanceof ??
in ??
which belongs to ??;?????
?, ???
?
?
???,??
?
??
???
(2)where ?
???,??
is the number of ??
appears in ??
,and??
????log?????.???????
(3)where ?
???
is the number of sentences that theword ??
appears in.?
?????
?, ???
is the contribution of ??
in ?
?which belongs to ??.?????
?, ???
???,??????,?????0.5??1.5???????????
?
(4)where ???
is the average number of sentences in??
; ?
???,??
is the number of ??
appears in ??
(Al-lan et al, 2003; Otterbacher et al, 2005).It is found that the contribution of a sentimentword ??
will not decrease even if it appears inall the sentences.
Therefore in Equation 4, wejust use the length of a sentence instead of ??
??
?to normalize long sentences which would likelycontain more sentiment words.The authority score ??????????????????
ofdocument ??
and a hub score ?????????????????
?of ???
at the ??
?
1???
iteration are computedbased on the hub scores and authority scores inthe ???
iteration as follows.??????????????????
?
?
????
?
????????????????????
(5)??????????????????
?
?
????
?
???????????????????
(6)We let ?
?
???,??|??|?|?
?| denote the adjacencymatrix.????????
???????
(7)?????????
??
?????
(8)where ?????
?
????????????????|??|??
is the vectorof authority scores for documents at the ???
ite-ration and ??????
?
????????????????|??|??
is thevector of hub scores for the word pairs at ???iteration.
In order to ensure convergence of theiterative form, ??
and ???
are normalized in eachiteration cycle.1370For computation of the final scores, the initialscores of all documents are set to??
?, and top-ic-sentiment word pairs are set to?????
.
Theabove iterative steps are then used to computethe new scores until convergence.
Usually theconvergence of the iteration algorithm isachieved when the difference between the scorescomputed at two successive iterations for anynodes falls below a given threshold (Wan et al,2008; Li et al, 2009; Erkan and Radev, 2004).
Inour model, we use the hub scores to denote theassociative degree of each word pair and the au-thority scores as the total scores.
The documentsare then ranked based on the total scores.4 ExperimentWe performed the experiments on the Chinesebenchmark dataset to verify our proposed ap-proach for opinion retrieval.
We first tested theeffect of the parameter ?
of our model.
Todemonstrate the effectiveness of our opinion re-trieval model, we compared its performance withthe same of other approaches.
In addition, westudied each individual query to investigate theinfluence of query to our model.
Furthermore,we showed the top-5 highest weight word pairsof 5 queries to further demonstrate the effect ofword pair.4.1 Experiment Setup4.1.1 Benchmark DatasetsOur experiments are based on the Chinesebenchmark dataset, COAE08 (Zhao et al, 2008).COAE dataset is the benchmark data set for theopinion retrieval track in the Chinese OpinionAnalysis Evaluation (COAE) workshop, consist-ing of blogs and reviews.
20 queries are providedin COAE08.
In our experiment, we created re-levance judgments through pooling method,where documents are ranked at different levels:irrelevant, relevant but without opinion, and re-levant with opinion.
Since polarity is not consi-dered, all relevant documents with opinion areclassified into the same level.4.1.2 Sentiment LexiconIn our experiment, the sentiment lexicon iscomposed by the following resources (Xu et al,2007):(1) The Lexicon of Chinese Positive Words,which consists of 5,054 positive words andthe Lexicon of Chinese Negative Words,which consists of 3,493 negative words;(2) The opinion word lexicon provided by Na-tional Taiwan University which consists of2,812 positive words and 8,276 negativewords;(3) Sentiment word lexicon and comment wordlexicon from Hownet.
It contains 1836 posi-tive sentiment words, 3,730 positive com-ments, 1,254 negative sentiment words and3,116 negative comment words.The different graphemes corresponding toTraditional Chinese and Simplified Chinese areboth considered so that the sentiment lexiconsfrom different sources are applicable to processSimplified Chinese text.
The lexicon was ma-nually verified.4.1.3 Topic Term CollectionIn order to acquire the collection of topic terms,we adopt two expansion methods, dictio-nary-based method and pseudo relevance feed-back method.The dictionary-based method utilizes Wikipe-dia (Popescu and Etzioni, 2005) to find an entrypage for a phrase or a single term in a query.
Ifsuch an entry exists, all titles of the entry pageare extracted as synonyms of the query concept.For example, if we search ????
(Green Tsu-nami, a firewall) in Wikipedia, it is re-directed toan entry page titled ??????
(Youth Escort).This term is then added as a synonym of ????
(Green Tsunami) in the query.
Synonyms aretreated the same as the original query terms in aretrieval process.
The content words in the entrypage are ranked by their frequencies in the page.The top-k terms are returned as potential ex-panded topic terms.The second query expansion method is aweb-based method.
It is similar to the pseudorelevance feedback expansion but using webdocuments as the document collection.
Thequery is submitted to a web search engine, suchas Google, which returns a ranked list of docu-ments.
In the top-n documents, the top-m topicterms which are highly correlated to the queryterms are returned.4.2 Performance Evaluation4.2.1 Parameter TuningWe first studied how the parameter ?
(see Equ-ation 1) influenced the mean average precision(MAP) in our model.
The result is given in Fig-ure 4.1371Figure 4: Performance of MAP with varying ?.Best MAP performance was achieved inCOAE08 evaluation, when ?
was set between0.4 and 0.6.
Therefore, in the following experi-ments, we set ?
?
0.4.4.2.2 Opinion Retrieval Model ComparisonTo demonstrate the effectiveness of our proposedmodel, we compared it with the following mod-els using different evaluation metrics:(1) IR: We adopted a classical information re-trieval model, and further assumed that all re-trieved documents contained relevant opinions.
(2) Doc: The 2-stage document-based opinionretrieval model was adopted.
The model usedsentiment lexicon-based method for opinionidentification and a conventional informationretrieval method for relevance detection.
(3) ROSC: This was the model which achievedthe best run in TREC Blog 07.
It employed ma-chine learning method to identify opinions foreach sentence, and to determine the target topicby a NEAR operator.
(4) ROCC: This model was similar to ROSC,but it considered the factor of sentence and re-garded the count of relevant opinionated sen-tence to be the opinion score (Zhang and Yu,2007).
In our experiment, we treated this modelas the evaluation baseline.
(5) GORM: our proposed graph-based opinionretrieval model.Approach COAE08 Evaluation metricsRun id MAP R-pre bPref P@10IR 0.2797 0.3545 0.2474 0.4868Doc 0.3316 0.3690 0.3030 0.6696ROSC 0.3762 0.4321 0.4162 0.7089Baseline 0.3774 0.4411 0.4198 0.6931GORM 0.3978 0.4835 0.4265 0.7309Table 1: Comparison of different approaches onCOAE08 dataset, and the best is highlighted.Most of the above models were originally de-signed for opinion retrieval in English, andre-designed them to handle Chinese opinionateddocuments.
We incorporated our own Chinesesentiment lexicon for this purpose.
In our expe-riments, in addition to MAP, other metrics suchas R-precision (R-prec), binary Preference (bPref)and Precision at 10 documents (P@10) were alsoused.
The evaluation results based on these me-trics are shown in Table 1.Table 1 summarized the results obtained.
Wefound that GORM achieved the best performancein all the evaluation metrics.
Our baseline, ROSCand GORM which were sentence-based ap-proaches achieved better performance than thedocument-based approaches by 20% in average.Moreover, our GORM approach did not use ma-chine learning techniques, but it could stillachieve outstanding performance.To study GORM influenced by different que-ries, the MAP from median average precision onindividual topic was shown in Figure 5.Figure 5: Difference of MAP from Median onCOAE08 dataset.
(MAP of Median is 0.3724)As shown in Figure 5, the MAP performancewas very low on topic 8 and topic 11.
Topic 8, i.e.????
(Jackie Chan), it was influenced by topic7, i.e.
?????
(Jet Lee) as there were a numberof similar relevant targets for the two topics, andtherefore many word pairs ended up the same.As a result, documents belonging to topic 7 andtopic 8 could not be differentiated, and they bothperformed badly.
In order to solve this problem,we extracted the topic term with highest relevantweight in the sentence to form word pairs so thatit reduce the impact on the topic terms in com-mon.
24% and 30% improvement were achieved,respectively.As to topic 11, i.e.
?????
(Lord of King),there were only 8 relevant documents withoutany opinion and 14 documents with relevantopinions.
As a result, the graph constructed byinsufficient documents worked ineffectively.Except for the above queries, GORM per-formed well in most of the others.
To further in-vestigate the effect of word pair, we summarizedthe top-5 word pairs with highest weight of 5queries in Table 2.0.20.250.30.350.40 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1MAP?COAE08?0.4?0.3?0.2?0.100.10.20.30.40.50.61 2 3 4 5 6 7 8 9 1011121314151617181920DifferenceTopicDifference from Median Average Precision perTopic1372Table 2: Top-5 highest weight word pairs for 5 queries in COAE08 dataset.Table 2 showed that most word pairs couldrepresent the relevant opinions about the corres-ponding queries.
This showed that inter-sentenceinformation was very helpful to identify the as-sociative degree of a word pair.
Furthermore,since word pairs can indicate relevant opinionseffectively, it is worth further study on how theycould be applied to other opinion oriented appli-cations, e.g.
opinion summarization, opinionprediction, etc.5 Related WorkOur research focuses on relevant opinion ratherthan on relevant document retrieval.
We, there-fore, review related works in opinion identifica-tion research.
Furthermore, we do not support theconventional 2-stage opinion retrieval approach.We conducted literature review on unified opi-nion retrieval models and related work in thisarea is presented in the section.5.1 Lexicon-based Opinion IdentificationDifferent from traditional IR, opinion retrievalfocuses on the opinion nature of documents.During the last three years, NTICR and TRECevaluations have shown that sentiment lex-icon-based methods led to good performance inopinion identification.A lightweight lexicon-based statistical ap-proach was proposed by Hannah et al (2007).
Inthis method, the distribution of terms in relevantopinionated documents was compared to theirdistribution in relevant fact-based documents tocalculate an opinion weight.
These weights wereused to compute opinion scores for each re-trieved document.
A weighted dictionary wasgenerated from previous TREC relevance data(Amati et al, 2007).
This dictionary was submit-ted as a query to a search engine to get an initialquery-independent opinion score of all retrieveddocuments.
Similarly, a pseudo opinionatedword composed of all opinion words was firstcreated, and then used to estimate the opinionscore of a document (Na et al, 2009).
This me-thod was shown to be very effective in TRECevaluations (Lee et al, 2008).
More recently,Huang and Croft (2009) proposed an effectiverelevance model, which integrated bothquery-independent and query-dependent senti-ment words into a mixture model.In our approach, we also adopt sentiment lex-icon-based method for opinion identification.Unlike the above methods, we generate a weightto a sentiment word for each target (associatedtopic term) rather than assign a unified weight oran equal weight to the sentiment word for thewhole topics.
Besides, in our model no trainingdata is required.
We just utilize the structure ofour graph to generate a weight to reflect the as-sociative degree between the two elements of aword pair in different context.5.2 Unified Opinion Retrieval ModelIn addition to conventional 2-stage approach,there has been some research on unified opinionretrieval models.Eguchi and Lavrenko proposed an opinion re-trieval model in the framework of generativelanguage modeling (Eguchi and Lavrenko, 2006).They modeled a collection of natural languagedocuments or statements, each of which con-sisted of some topic-bearing and some senti-ment-bearing words.
The sentiment was eitherrepresented by a group of predefined seed words,or extracted from a training sentiment corpus.This model was shown to be effective on theMPQA corpus.Mei et al tried to build a fine-grained opinionretrieval system for consumer products (Mei etal., 2007).
The opinion score for a product was amixture of several facets.
Due to the difficulty inTop-5 MAP??
?Chen Kaige??
?Six States????Macro-regulation??
?Stephen ChowVistaVista<???
?
?>Chen Kaige Support<???
?
?>Chen Kaige Best<????
?>Limitless Revile<??
?
?>Movie Excellent<??
??
?>Cast Strong<??
?
?>Room rate Rise<??
?
?>Regulate Strengthen<??
?
?>CCP Strengthen<??
?
?>Room rate Steady<??
?
?>Housing Security<??
?
?>Economics Steady<??
?
?>Price Rise<??
?
?>Development Steady<??
?
?>Consume Rise<??
?
?>Social Security<??
?
?>Movie Like<???
?
?>Stephen Chow Like<??
?
?>Protagonist Best<??
?>Comedy Good<??
?
?>Works Splendid<??
?>Price Expensive<??
?
?>Microsoft Like<Vista ?
?>Vista Recommend<??
?
?>Problem Vital<??
?>Performance No1373associating sentiment with products and facets,the system was only tested using small scale textcollections.Zhang and Ye proposed a generative model tounify topic relevance and opinion generation(Zhang and Ye, 2008).
This model led to satis-factory performance, but an intensive computa-tion load was inevitable during retrieval, sincefor each possible candidate document, an opinionscore was summed up from the generative prob-ability of thousands of sentiment words.Huang and Croft proposed a unified opinionretrieval model according to the Kullback-Leib-ler divergence between the two probability dis-tributions of opinion relevance model and docu-ment model (Huang and Croft, 2009).
They di-vided the sentiment words into query-dependentand query-independent by utilizing several sen-timent expansion techniques, and integrated theminto a mixed model.
However, in this model, thecontribution of a sentiment word was its corres-ponding incremental mean average precisionvalue.
This method required that large amount oftraining data and manual labeling.Different from the above opinion retrieval ap-proaches, our proposed graph-based modelprocesses opinion retrieval in the granularity ofsentence.
Instead of bag-of-word, the sentence issplit into word pairs which can maintain thecontextual information.
On the one hand, wordpair can identify the relevant opinion accordingto intra-sentence contextual information.
On theother hand, it can measure the degree of a rele-vant opinion by considering the inter-sentencecontextual information.6 Conclusion and Future WorkIn this work we focus on the problem of opinionretrieval.
Different from existing approaches,which regard document relevance as the key in-dicator of opinion relevance, we propose to ex-plore the relevance of individual opinion.
To dothat, opinion retrieval is performed in the granu-larity of sentence.
We define the notion of wordpair, which can not only maintain the associationbetween the opinion and the corresponding targetin the sentence, but it can also build up the rela-tionship among sentences through the same wordpair.
Furthermore, we convert the relationshipsbetween word pairs and sentences into a unifiedgraph, and use the HITS algorithm to achievedocument ranking for opinion retrieval.
Finally,we compare our approach with existing methods.Experimental results show that our proposedmodel performs well on COAE08 dataset.The novelty of our work lies in using wordpairs to represent the information needs for opi-nion retrieval.
On the one hand, word pairs canidentify the relevant opinion according to in-tra-sentence contextual information.
On the otherhand, word pairs can measure the degree of arelevant opinion by taking inter-sentence con-textual information into consideration.
With thehelp of word pairs, the information needs foropinion retrieval can be represented appropriate-ly.In the future, more research is required in thefollowing directions:(1) Since word pairs can indicate relevant opi-nions effectively, it is worth further study onhow they could be applied to other opinionoriented applications, e.g.
opinion summa-rization, opinion prediction, etc.
(2) The characteristics of blogs will be takeninto consideration, i.e., the post time, whichcould be helpful to create a more time sensi-tivity graph to filter out fake opinions.
(3) Opinion holder is another important role ofan opinion, and the identification of opinionholder is a main task in NTCIR.
It would beinteresting to study opinion holders, e.g.
itsseniority, for opinion retrieval.Acknowledgements: This work is partiallysupported by the Innovation and TechnologyFund of Hong Kong SAR (No.
ITS/182/08) andNational 863 program (No.
2009AA01Z150).Special thanks to Xu Hongbo for providing theChinese sentiment resources.
We also thank BoChen, Wei Gao, Xu Han and anonymous re-viewers for their helpful comments.ReferencesJames Allan, Courtney Wade, and Alvaro Bolivar.2003.
Retrieval and novelty detection at the sen-tence level.
In SIGIR ?03: Proceedings of the 26thannual international ACM SIGIR conference onResearch and development in information retrieval,pages 314-321.
ACM.Giambattista Amati, Edgardo Ambrosi, Marco Bianc-hi, Carlo Gaibisso, and Giorgio Gambosi.
2007.FUB, IASI-CNR and University of Tor Vergata atTREC 2007 Blog Track.
In Proceedings of the 15thText Retrieval Conference.Koji Eguchi and Victor Lavrenko.
Sentiment retrievalusing generative models.
2006.
In EMNLP ?06,Proceedings of 2006 Conference on Empirical Me-thods in Natural Language Processing, page345-354.1374Gunes Erkan and Dragomir R. Radev.
2004.
Lexpa-gerank: Prestige in multi-document text summariza-tion.
In EMNLP ?04, Proceedings of 2004 Confe-rence on Empirical Methods in Natural LanguageProcessing.David Hannah, Craig Macdonald, Jie Peng, Ben He,and Iadh Ounis.
2007.
University of Glasgow atTREC 2007: Experiments in Blog and EnterpriseTracks with Terrier.
In Proceedings of the 15th TextRetrieval Conference.Xuanjing Huang, William Bruce Croft.
2009.
A Uni-fied Relevance Model for Opinion Retrieval.
InProceedings of CIKM.Jon M. Kleinberg.
1999.
Authoritative sources in ahyperlinked environment.
J. ACM, 46(5): 604-632.Yeha Lee, Seung-Hoon Na, Jungi Kim, Sang-HyobNam, Hun-young Jung, Jong-Hyeok Lee.
2008.KLE at TREC 2008 Blog Track: Blog Post and FeedRetrieval.
In Proceedings of the 15th Text RetrievalConference.Fangtao Li, Yang Tang, Minlie Huang, and XiaoyanZhu.
2009.
Answering Opinion Questions withRandom Walks on Graphs.
In ACL ?09, Proceedingsof the 48th Annual Meeting of the Association forComputational Linguistics.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: Analyzing and comparing opi-nion s on the web.
In WWW ?05: Proceedings of the14th International Conference on World Wide Web.Craig Macdonald and Iadh Ounis.
2007.
Overview ofthe TREC-2007 Blog Track.
In Proceedings of the15th Text Retrieval Conference.Craig Macdonald and Iadh Ounis.
2006.
Overview ofthe TREC-2006 Blog Track.
In Proceedings of the14th Text Retrieval Conference.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and Chengxiang Zhai.
2007.
Topic sentiment mix-ture: Modeling facets and opinions in weblogs.
InWWW ?07: Proceedings of the 16 InternationalConference on World Wide Web.Seung-Hoon Na, Yeha Lee, Sang-Hyob Nam, andJong-Hyeok Lee.
2009.
Improving opinion retrievalbased on query-specific sentiment lexicon.
InECIR ?09: Proceedings of the 31st annual EuropeanConference on Information Retrieval, pages734-738.Douglas Oard, Tamer Elsayed, Jianqiang Wang, Ye-jun Wu, Pengyi Zhang, Eileen Abels, Jimmy Lin,and Dagbert Soergel.
2006.
TREC-2006 at Mary-land: Blog, Enterprise, Legal and QA Tracks.
InProceedings of the 15th Text Retrieval Conference.Jahna Otterbacher, Gunes Erkan, and Dragomir R.Radev.
2005.
Using random walks for ques-tion-focused sentence retrieval.
In EMNLP ?05,Proceedings of 2005 Conference on Empirical Me-thods in Natural Language Processing.Larry Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1998.
The pagerank citation ranking:Bringing order to the web.
Technical report, Stan-ford University.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in In-formation Retrieval, 2(1-2): 1-135.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinion s from reviews.
InEMNLP ?05, Proceedings of 2005 Conference onEmpirical Methods in Natural LanguageProcessing.Xiaojun Wan and Jianwu Yang.
2008.
Mul-ti-document summarization using cluster-based linkanalysis.
In SIGIR ?08: Proceedings of the 31th an-nual international ACM SIGIR conference on Re-search and development in information retrieval,pages 299-306.
ACM.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity inphrase-level sentiment analysis.
In EMNLP ?05,Proceedings of 2005 Conference on Empirical Me-thods in Natural Language Processing.Ruifeng Xu, Kam-Fai Wong and Yunqing Xia.
2007.Opinmine - Opinion Analysis System by CUHK forNTCIR-6 Pilot Task.
In Proceedings of NTCIR-6.Min Zhang and Xingyao Ye.
2008.
A generationmodel to unify topic relevance and lexicon-basedsentiment for opinion retrieval.
In SIGIR ?08: Pro-ceedings of the 31st Annual International ACM SI-GIR conference on Research and Development inInformation Retrieval, pages 411-418.
ACM.Wei Zhang and Clement Yu.
2007.
UIC at TREC2007 Blog Track.
In Proceedings of the 15th TextRetrieval Conference.Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan,Kang Liu, and Qi Zhang.
2008.
Overview of Chi-nese Opinion Analysis Evaluation 2008.
In Pro-ceedings of the First Chinese Opinion AnalysisEvaluation.1375
