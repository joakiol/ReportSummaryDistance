Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 433?444, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsUnsupervised PCFG Induction for Grounded Language Learningwith Highly Ambiguous SupervisionJoohyun Kim Raymond J. MooneyDepartment of Computer ScienceThe University of Texas at Austin1616 Guadalupe, Suite 2.408Austin, TX 78701, USA{scimitar,mooney}@cs.utexas.eduAbstract?Grounded?
language learning employs train-ing data in the form of sentences paired withrelevant but ambiguous perceptual contexts.Bo?rschinger et al2011) introduced an ap-proach to grounded language learning basedon unsupervised PCFG induction.
Their ap-proach works well when each sentence po-tentially refers to one of a small set of pos-sible meanings, such as in the sportscastingtask.
However, it does not scale to prob-lems with a large set of potential meaningsfor each sentence, such as the navigation in-struction following task studied by Chen andMooney (2011).
This paper presents an en-hancement of the PCFG approach that scalesto such problems with highly-ambiguous su-pervision.
Experimental results on the naviga-tion task demonstrates the effectiveness of ourapproach.1 IntroductionThe ultimate goal of ?grounded?
language learningis to develop computational systems that can acquirelanguage more like a human child.
Given only su-pervision in the form of sentences paired with rel-evant but ambiguous perceptual contexts, a systemshould learn to interpret and/or generate languagedescribing situations and events in the world.
Forexample, systems have learned to commentate sim-ulated robot soccer games by learning from samplesportscasts (Chen and Mooney, 2008; Liang et al2009; Bo?rschinger et al2011), or understand nav-igation instructions by learning from action tracesproduced when following the directions (Chen andMooney, 2011; Tellex et al2011).Bo?rschinger et al2011) recently introduced anapproach to grounded language learning using un-supervised induction of probabilistic context freegrammars (PCFGs) to learn from ambiguous con-textual supervision.
Their approach first constructsa large set of production rules from sentences pairedwith descriptions of their ambiguous context, andthen trains the parameters of this grammar usingEM.
Parsing a novel sentence with this grammargives a parse tree which contains the formal mean-ing representation (MR) for this sentence.
This ap-proach works quite well on the sportscasting taskoriginally introduced by Chen and Mooney (2008).In this task, each sentence in a natural-languagecommentary describing activity in a simulated robotsoccer game is paired with the small set of actionsobserved within the past 5 seconds, one of whichis usually described by the sentence.
Even with thislow level of ambiguity in a constrained domain, theirmethod constructs a PCFG with about 33,000 pro-ductions.
More fundamentally, their approach is re-stricted to a finite set of potential meaning represen-tations, and the grammar size grows at least linearlywith the number of possible MRs, which in turn isinevitably exponential in the number of objects andactions in the domain.The navigation task studied by Chen and Mooney(2011) provides much more ambiguous supervision.In this task, each instructional sentence is pairedwith a formal landmarks plan (represented as alarge graph) that includes a full description of theobserved actions and world-states that result when433someone follows this instruction.
An instructiongenerally refers to a subgraph of this large graph.Therefore, there are a combinatorial number of pos-sible meanings to which a given sentence can refer.Chen and Mooney (2011) circumvent this combi-natorial problem by never explicitly enumerating theexponential number of potential meanings for eachsentence.
Their system first induces a semantic lex-icon that maps words and short phrases to formalrepresentations of actions and objects in the world.This lexicon is learned by finding words and phraseswhose occurrence highly correlates with specific ob-served actions and objects in the simulated environ-ment when executing the corresponding instruction.This learned lexicon is then used to directly infera formal MR for observed instructional sentencesusing a greedy covering algorithm.
These inferredMRs are then used to train a supervised semanticparser capable of mapping novel sentences to theirformal meanings.We present a novel enhancement of Bo?rschingeret al PCFG approach that uses Chen and Mooney?slexicon learner to avoid a combinatorial explosion inthe number of productions.
The learned lexicon isfirst used to build a hierarchy of semantic lexemes(i.e.
lexicon entries) called the Lexeme HierarchyGraph (LHG) for each ambiguous landmarks planin the training data.
The intuition behind utilizingan LHG is that the MR for each lexeme constitutes asemantic concept that corresponds to some natural-language (NL) word or phrase.
Therefore, the LHGrepresents how complex semantic concepts are com-posed of simpler semantic concepts and ultimatelyconnected to NL words and phrases.
Bo?rschingeret al approach instead produces NL groundings atthe level of atomic MR constituents, which causesan explosion in the number of PCFG productionsfor complex MR languages.
We estimated thatBo?rschinger et al approach would require morethan 20!
(> 1018) productions for our navigationproblem.1 On the other hand, our method, whichuses correspondences from the LHG at the seman-tic concept level, constructs a more focused PCFGof tractable size.
It then extracts the MR for a novel1The corpus contains quite a few examples with landmarksplans containing more than 20 actions.
This results in at least20!
permutations representing possible alignments between ac-tions and NL words.sentence from the most-probable parse tree for theresulting PCFG.
Our approach can produce a large,combinatorial number of different MRs for a widerange of novel sentences by composing relevant MRcomponents from the resulting parse tree, whereasBo?rschinger et al approach is only able to outputMRs that are explicitly included as a nonterminalsin the original learned PCFG.The remainder of the paper is organized as fol-lows.
Section 2 reviews Bo?rschinger et al PCFGapproach as well as the navigation task and data.Section 3 describes our enhanced PCFG approachand Section 4 presents an experimental evaluationof it.
Then, Section 5 discusses the unique aspectsof our approach and Section 6 describes additionalrelated work.
Finally, Section 7 presents future re-search directions and Section 8 gives our conclu-sions.2 Background2.1 Existing PCFG ApproachOur approach extends that of Bo?rschinger et al(2011), which in turn was inspired by a series ofprevious techniques (Lu et al2008; Liang et al2009; Kim and Mooney, 2010) following the ideaof constructing correspondences between NL andMR in a single probabilistic generative framework.Particularly, their approach automatically constructsa PCFG that generates NL sentences from MRs,which indicates how atomic MR constituents areprobabilistically related to NL words.
The nonter-minals in the grammar correspond to complete MRs,MR constituents, and NL phrases.
The nontermi-nal for a composite MR generates each of its MRconstituents, and each atomic MR, x, generates anNL phrase, Phrasex.
Each Phrasex then gener-ates a sequence of Wordx?s for describing x, andeach Wordx can generate each possible word in thenatural language.
This allows the system to learnthe words and phrases used to describe each atomicMR by properly weighting these rules.
Figure 1shows one possible derivation tree for a sample NL-MR pair and the PCFG rules that are constructed forit.
Once a set of productions are assembled, theirprobabilities are learned using the Inside-Outside al-gorithm.
Computing the most probable parse for anovel sentence with the trained PCFG provides its434Figure 1: Derivation tree for the NL/MR pair: THEPINK GOALIE PASSES THE BALL TO PINK11 /pass(pink1, pink11).
Left side shows PCFG rulesthat are added for each stage (full MR to atomicMRs, and atomic MRs to NL words ).preferred MR interpretation in the topmost nonter-minal.Unfortunately, as discussed earlier, this approachonly works for finite MR languages, and the gram-mar becomes intractably large even for finite butcomplex MRs.
It effectively assumes that MRs arefairly small and includes every possible MR con-stituent as a nonterminal in the PCFG.
This is nottractable for more complex MRs.
Therefore, our ex-tension incorporates a learned lexicon to constrainthe space of productions, thereby making the sizeof the PCFG tractable for complex MRs, and evengiving it the ability to handle infinite MR languages.Moreover, when processing novel sentences, our ap-proach can produce a large space of novel MRs thatwere not anticipated during training, which is not thecase for Bo?rschinger et al approach.2.2 Navigation Task and DatasetWe employ the task and data introduced by Chen andMooney (2011) whose goal is to interpret and followNL navigation instructions in a virtual world.
Fig-ure 2 shows a sample execution path in a particularvirtual world.
The challenge is learning to performthis task by simply observing humans following in-structions.
Formally, given training data of the form{(e1, a1, w1), .
.
.
, (en, an, wn)}, where ei is an NLinstruction, ai is an observed action sequence, andwi is the current world state (patterns of floors andwalls, positions of any objects, etc.
), we want to pro-duce the correct actions aj for a novel (ej , wj).Figure 2: Sample virtual world from Chen andMooney (2011) of interconnecting hallways withdifferent floor and wall patterns and objects indi-cated by letters (e.g.
?H?
for hatrack).Figure 3: Sample instruction with its constructedlandmarks plan, components in bold compose thecorrect plan.In order to learn, their system infers the intendedformal plan pi (the MR for a sentence) which pro-duced the action sequence ai from the instruction ei.However, there is a large space of possible plans forany given action sequence.
Chen and Mooney firstconstruct a formal landmarks plan, ci, for each ai,which is a graph representing the context of everyaction and the world-state encountered during theexecution of the sequence.
The correct plan MR,pi, is assumed to be a subgraph of ci, and this causesa combinatorial matching problem between ei andci in order to learn the correct meaning of ei amongall the possible subgraphs of ci.
The landmarks andcorrect plans for a sample instruction are shown inFigure 3, illustrating the complexity of the MRs.Instead of directly solving the combinatorial cor-respondence problem, they first learn a semantic lex-435Figure 4: An overview of Chen and Mooney(2011)?s system.
Our method replaces the plan re-finement and semantic parser parts.icon that maps words and short phrases to small sub-graphs representing their inferred meanings from the(ei, ci) pairs.
The lexicon is learned by evaluatingpairs of n-grams, wj , and MR graphs, mj , and scor-ing them based on how much more likely mj is asubgraph of the context ci when w occurs in thecorresponding instruction ei.
This process is simi-lar to other ?cross-situational?
approaches to learn-ing word meanings (Siskind, 1996; Thompson andMooney, 2003).
Then, a plan refinement step esti-mates pi from ci by greedily selecting high-scoringlexemes of the form (wj ,mj) whose words andphrases (wj) cover the instruction ei and introducecomponents (mj) from the landmarks plan ci.
Therefined plans are used to construct supervised train-ing data (ei, pi) for a supervised semantic-parserlearner.
The trained semantic parser can parse anovel instruction into a formal plan, which is finallyexecuted for end-to-end evaluation.
Figure 4 illus-trates the overall system.As this figure indicates, our new PCFG methodreplaces the plan refinement and semantic parsercomponents in their system with a unified modelthat both disambiguates the training data and learnsa semantic parser.
We use the landmarks plans andthe learned lexicon produced by Chen and Mooney(2011) as inputs to our system.22In our experiments, we used the top 1,000 lexemes learnedby Chen and Mooney (2011).3 Our PCFG ApproachLike Bo?rschinger et al2011), our approach learnsa semantic parser directly from ambiguous su-pervision, specifically NL instructions paired withtheir complete landmarks plans as context.
Ourmethod incorporates the semantic lexemes as build-ing blocks to find correspondences between NLwords and semantic concepts represented by the lex-eme MRs, instead of building connections betweenNL words and every possible MR constituent as inBo?rschinger et al approach.
Particularly, we uti-lize the hierarchical subgraph relationships betweenthe MRs in the learned semantic lexicon to producea smaller, more focused set of PCFG rules.3 Theintuition behind our approach is analogous to the hi-erarchical relations between nonterminals in syntac-tic parsing, where higher-level categories such as S,VP, or NP are further divided into smaller categoriessuch as V, N, or Det, thereby forming a hierarchi-cal structure.
Inspired by this idea, we introduce adirected acyclic graph called the Lexeme HierarchyGraph (LHG) which represents the hierarchical rela-tionships between lexeme MRs.
Since complex lex-eme MRs represent complicated semantic conceptswhile simple MRs represent simple concepts, it isnatural to construct a hierarchy amongst them.
TheLHGs for all of the training examples are used toconstruct production rules for the PCFG, which arethen parametrized using EM.
Finally, a novel sen-tence is semantically parsed by computing its most-probable parse using the trained PCFG, and then itsMR is extracted from the resulting parse tree.3.1 Constructing a Lexeme Hierarchy GraphAn LHG represents the hierarchy of lexical mean-ings relevant to a particular training instance by en-coding the subgraph relations between the MRs ofrelevant lexemes.
Algorithm 1 describes how anLHG is constructed for an ambiguous training pairof a sentence and its corresponding context, (ei, ci).First, we obtain all relevant lexemes (wij ,mij) in thelexicon L, where the MR mij is a subgraph of thecontext ci (denoted as mij ?
ci).
These lexemes are3The total number of PCFG rules constructed for our navi-gation training sets is about 18,000, while Bo?rschinger et almethod produces 33,000 rules for the much simpler sportscast-ing domain.436Algorithm 1 LEXEME HIERARCHY GRAPH (LHG)Input: Training instance (ei, ci), Lexicon LOutput: Lexeme hierarchy graph for (ei, ci)Find relevant lexemes (wi1,mi1), .
.
.
, (win,min)s.t.
mij ?
ciCreate a starting node T ; MR(T )?
cifor all mij in the descending order of size doCreate a node T ij ; MR(Tij )?
mijPLACELEXEME(T ij ,T )end forprocedure PLACELEXEME(T ?,T )for all children Tj of T doif MR(T ?)
?
MR(Tj) thenPLACELEXEME(T ?,Tj)end ifend forif T ?
was not placed under any child Tj thenAdd T ?
as child of Tend ifend proceduresorted in descending order based on the number ofnodes in their MRs mij .
Then, after setting the con-text ci as the MR of the root node (MR(T ) ?
ci),lexemes are inserted, in order, into the graph to cre-ate a hierarchy of MRs, where each child?s MR is asubgraph of the MR of each of its parents.
Figure 5illustrates a sample construction of an LHG for thefollowing landmarks plan (ci):Turn(RIGHT),Verify(side:HATRACK, front:SOFA),Travel(steps:3),Verify(at:EASEL)The initial LHG may contain nodes with too manychildren.
This is a problem, because when we sub-sequently extract PCFG rules, we need to add a pro-duction for every k-permutation of the children ofeach node (see Section 3.2).
To reduce the branch-ing factor in the LHG, we introduce pseudo-lexemenodes by repeatedly combining the two most similarchildren of each node.
Pseudocode for the process isshown in Algorithm 2.
The MR for a pseudo-lexemeis the minimal graph, m?, that is a supergraph of bothof the lexeme MRs that it combines.
The pair of(a) All relevant lexemes are obtained for the training exam-ple and ordered by the number of nodes in their MR.(b) Lexeme MR [1] is added as a child of the top node.
MR[2] is a subgraph of [1], so it is added as its child.
(c) MR [3] is not a subgraph of [1] or [2], so it is added as achild of the root.
MR [4] is added under [3], and MR [5] isrecursively filtered down and added under [2].Figure 5: Sample LHG construction.437Algorithm 2 ADDING PSEUDO LEXEMES TO LHGInput: LHG with root TOutput: LHG with pseudo lexemes addedprocedure RECONSTRUCTLHG(T )repeat((Ti, Tj),m?)
?
pick the most similarpair (Ti, Tj) of children of T and the minimal ex-tension m?
s.t.
MR(Ti) ?
m?, MR(Tj) ?
m?,m?
?
MR(T )Add child T ?
of T ; MR(T ?)?
m?Move Ti and Tj to be children of T ?until There are no more pairs to combinefor all non-leaf children Tk of T doRECONSTRUCTLHG(Tk)end forend proceduremost similar children, (mi,mj), is determined bymeasuring the fraction of the nodes in mi and mjthat overlap with their minimum extension m?
andis calculated as follows:Sim(mi,mj ,m?)
=|mi|+ |mj |2 |m?|where |m| is the number of nodes in the MR m.Adding pseudo-lexemes also has another advan-tage.
They can be considered to be higher-levelsemantic concepts composed of two or more sub-concepts.
These higher-level concepts will likelyoccur in other training examples as well, which al-lows for more flexible interpretations.
For example,assuming the rule A ?
BCD is constructed froman LHG, we will introduce a pseudo lexeme E andbuild two rules A?
BE and E ?
CD.
It is likelythat E also occurs in another rule constructed fromother training examples such as E ?
FG.
Thisincreases the model?s expressive power by support-ing additional derivations such as A??
BFG, pro-viding more flexibility when parsing novel NL sen-tences.3.2 Composing PCFG RulesThe next step composes PCFG rules from the LHGsand is summarized in Figure 6.
We basically fol-low the scheme of Bo?rschinger et al2011), butinstead of generating NL words from each atomicMR, words are generated from each lexeme MR,Figure 6: Summary of the rule generation process.NLs refer to the set of NL words in the corpus.
Lex-eme rules come from the schemata of Bo?rschingeret al2011), and allow every lexeme MR to gener-ate one or more NL words.
Note that pseudo-lexemenodes do not produce NL words.and smaller lexeme MRs are generated from morecomplex ones as given by the LHGs.
A nonterminalSm is generated for the MR, m, of each LHG node.Then, for every LHG node, T , with MR, m, we addrules of the form Sm ?
Smi ...Smj , where the RHSis some k-permutation of the nonterminals for theMRs of the children of node T .
Bo?rschinger et alassume that every atomic MR generates at least oneNL word.
However, since we do not know whichsubgraph of the overall context (i.e.
ci, the MR of theroot node) conveys the intended plan and is thereforeexpressed in the NL instruction, we must allow eachordered subset of the children of a node (i.e.
eachk-permutation) to be a possible generation.The rest of the process more closely followsBo?rschinger et al.
Every MR, m, of a lexemenode4 generates a rule Sm ?
Phrasem, and ev-ery Phrasem generates a sequence of NL words, in-cluding one or more ?content words?
(Wordm) forexpressing m and zero or more ?extraneous?
words(Word?).
While Bo?rschinger et alave Wordmgenerate all possible NL words (each of which are4We exclude pseudo-lexeme nodes in this process, becausethey should only generate words through generating lexemes.438subsequently weighted by EM training), in our ap-proach, each Wordm only produces the NL phraseassociated with m in the lexicon, or individual wordsthat appear in this phrase.
The words not coveredby Wordm also can be generated by Word?
whichhas rules for every word.
Phm and PhXm ensurethat Phrasem produces at least one Wordm, wherePhXm indicates that one or more Wordm?s havealready been generated, and Phm indicates that noWordm has yet been generated.3.3 Parsing Novel NL SentencesTo learn the parameters of the resulting PCFG, weuse the Inside-Outside algorithm.5 Then, the stan-dard probabilistic CKY algorithm is used to producethe most probable parse for novel NL sentences (Ju-rafsky and Martin, 2000).Bo?rschinger et al2011) simply read the MR, m,for a sentence off the top Sm nonterminal of themost probable parse tree.
However, in our approach,the correct MR is constructed by properly compos-ing the appropriate subset of lexeme MRs from themost-probable parse tree.
This allows the system toproduce a wide variety of novel MRs for novel sen-tences, as long as the correct MR is a subgraph of thecomplete context (ci) for at least one of the trainingsentences.First, the parse tree is pruned to remove all sub-trees starting with Phrasex nodes.
This leaves atree consisting of the Root and a set of Sm nodes.The pruned subtrees only concern generating NLwords and phrases from the selected MRs.
The re-maining tree shows which MR constituents were se-lected from the available context, from which thesentence is then generated.
Each leaf in the prunedtree represents an MR constituent that was used togenerate a phrase in the sentence.
These are the con-stituents we want to assemble and compose into afinal MR for the sentence.Algorithm 3 describes the procedure for extract-ing the final MR from the pruned parse tree.
Fig-ure 7 graphically depicts a sample trace of this algo-rithm.
The algorithm recursively traverses the parsetree.
When a leaf-node is reached, it marks all of thenodes in its MR. After traversing all of its children,5We used the implementation available at http://web.science.mq.edu.au/?mjohnson/Software.htmwhich was also used by Bo?rschinger et al2011).Algorithm 3 CONSTRUCT PARSED MR RESULTInput: Parse tree T for input NL, e, with allPhrasex subtrees removed.Output: Semantic parse MR, m, for eprocedure OBTAINPARSEDOUTPUT(T )if T is a leaf thenreturn MR(T ) with all its nodes markedend iffor all children Ti of T domi ?
OBTAINPARSEDOUTPUT(Ti)Mark the nodes in MR(T ) correspondingto the marked nodes in miend forif T is not the root thenreturn MR(T )end ifreturn MR(T ) with unmarked nodes removedend procedurea node in the MR for the current parse-tree node ismarked iff its corresponding node in any of the chil-dren?s MRs were marked.
The final output is the MRconstructed by removing all of the unmarked nodesfrom the MR for the root node.4 Experimental EvaluationFor evaluation, we used the same data and method-ology as Chen and Mooney (2011).
Please see theirpaper for more details.4.1 DataWe used the English instructions and follower datacollected by MacMahon et al2006).6 This datacontains 706 route instructions for three virtualworlds.
The instructions were produced by six in-structors for 126 unique starting and ending loca-tion pairs spread evenly across the three worlds, andthere were 1 to 15 human followers for each instruc-tion who executed an average of 10.4 actions per in-struction.
Each instruction is a paragraph consist-ing of an average of 5.0 sentences, each contain-ing an average of 7.8 words.
Chen and Mooneyconstructed the additional single-sentence corpus bymatching each sentence with the majority of human6Available at http://www.cs.utexas.edu/users/ml/clamp/navigation/439(a) Pruned parse tree showing only MRs for Smnodes(b) Leaf nodes have all their elements marked(c) Upper level nodes are marked according to leaf-node markings(d) Removing all unmarked elements for the rootnode leads to the final MR outputFigure 7: Sample construction of MR output from pruned parse tree.followers?
actions.
We use this single-sentence ver-sion for training, but use both the single-sentenceand the original paragraph version for testing.
Eachsentence was manually annotated with a ?gold stan-dard?
execution plan, which is used for evaluationbut not for training.4.2 Methodology and ResultsExperiments were conducted using ?leave one envi-ronment out?
cross-validation, training on two envi-ronments and testing on the third, averaging over allthree test environments.
We perform direct compar-ison to the best results of Chen and Mooney (2011)(referred to as CM).
A Wilcoxon signed-rank testis performed for statistical significance, and ???
de-notes significant differences (p < .01) in the tables.Semantic Parsing ResultsWe first evaluated how well our system learns tomap novel NL sentences for new test environmentsinto their correct MRs.
Partial semantic-parsing ac-curacy (Chen and Mooney, 2011) is calculated byPrecision Recall F1Our system 87.58 ?65.41 ?74.81CM ?90.22 55.10 68.37Table 1: Test accuracy for semantic parsing.???
denotes difference is statistically significant.comparing the system?s MR output to the hand-annotated gold standard.
Accuracy is measured interms of precision, recall, and F1 for individual MRconstituents (thereby awarding partial credit for ap-proximately correct MRs).Table 1 demonstrates that our method outper-forms CM by 6 points in F1.
Our PCFG-based ap-proach is able to probabilistically disambiguate thetraining data as well as simultaneously learn a sta-tistical semantic parser within a single framework.This results in better overall performance comparedto CM, since they lose potentially useful informa-tion, particularly during the refinement stage, due tothe separate disjoint components of the system.440Single-sentence ParagraphOur system ?57.22% ?20.17%CM 54.40% 16.18%Table 2: Successful plan execution rates for noveltest data.
???
means statistical significance.Navigation Plan Execution ResultsNext, we test the end-to-end system by execut-ing the parsed navigation plans for test instructionsin novel environments to see if they reach the ex-act desired destinations in the environment.
Table2 shows the successful end-to-end navigation-taskcompletion rate for both single-sentences and com-plete paragraph instructions.Again, our system outperforms CM?s best resultssince more accurate semantic parsing produces moresuccessful plans.
However, the difference in per-formance is smaller than that observed for semanticparsing.
This is because the redundancy in the hu-man generated instructions allows an incorrect se-mantic parse to be successful, as long as the errorsdo not affect its ability to guide the system to thecorrect destination.5 DiscussionOur approach improves on Bo?rschinger et al(2011)?s method in the following ways:?
The building blocks for associating NL and MRare semantic lexemes instead of atomic MR con-stituents.
This prevents the number of constructedPCFG rules from becoming intractably large as hap-pens with Bo?rschinger et al approach.
As previ-ously mentioned, lexeme MRs are intuitively anal-ogous to syntactic categories in that complex lex-eme MRs represent complicated semantic conceptswhereas higher-level syntactic categories such as S,VP, or NP represent complex syntactic structures.?
Our approach has the ability to produce previ-ously unseen MRs, whereas Bo?rschinger et alanonly generate an MR if it is explicitly included inthe PCFG rules constructed from the training data.Even though our MR parse is restricted to be a sub-graph of some training context, ci, our model allowsfor exponentially many combinations.In addition, our approach can produce a widerrange of MR outputs than Chen and Mooney(2011)?s even though we use their semantic lexi-con as input.
Their system deterministically builds asupervised training set by greedily selecting high-scoring lexemes, thus implicitly including onlyhigh-scoring lexemes during training.
On the otherhand, our probabilistic approach also considers rela-tively low-scoring but useful lexemes, thereby utiliz-ing more semantic concepts in the lexicon.
In partic-ular, this explains why our approach obtains higherrecall in the evaluation of semantic parsing.Even though we have demonstrated our approachon the specific task of following navigation in-structions, it is straightforward to apply it to otherlanguage-grounding tasks where NL sentences po-tentially refer to some subset of states, events, or ac-tions in the world, as long as this overall context canbe represented as a semantic graph or logical form.Since the semantic lexicon is an input to our system,other approaches to lexicon learning are also easilyincorporated.6 Related WorkMost work on learning semantic parsers that mapnatural-language sentences to formal representa-tions of their meaning have relied upon totally su-pervised training data consisting of NL/MR pairs(Zelle and Mooney, 1996; Zettlemoyer and Collins,2005; Kate and Mooney, 2006; Wong and Mooney,2007; Zettlemoyer and Collins, 2007; Lu et al2008; Zettlemoyer and Collins, 2009).
Several re-cent approaches have investigated grounded learn-ing from ambiguous supervision extracted from per-ceptual context.
A number of approaches (Kate andMooney, 2007; Chen and Mooney, 2008; Chen et al2010; Kim and Mooney, 2010; Bo?rschinger et al2011) assume training data consisting of a set of sen-tences each associated with a small set of MRs, oneof which is usually the correct meaning of the sen-tence.
Many of these approaches (Kate and Mooney,2007; Chen and Mooney, 2008; Chen et al2010)disambiguate the data and match NL sentences totheir correct MR by iteratively retraining a super-vised semantic parser.
Kim and Mooney (2010)proposed a generative semantic parsing model thatfirst chooses which MRs to describe and then gen-erates a hybrid tree structure (Lu et al2008) con-taining both the MR and NL sentence.
They train441this model on ambiguous data using EM.
As pre-viously discussed, Bo?rschinger et al2011) use aPCFG generative model and also train it on ambigu-ous data using EM.
Liang et al2009) assume eachsentence maps to one or more semantic records (i.e.MRs) and trains a hierarchical semi-Markov genera-tive model using EM, and then finds a Viterbi align-ment between NL words and records and their con-stituents.
Several recent projects (Branavan et al2009; Vogel and Jurafsky, 2010) use NL instructionsto guide reinforcement learning from independentexploration with delayed rewards.
These systems donot even need the ambiguous supervision obtainedfrom observing humans follow instructions; how-ever, they do not learn semantic parsers that mapsentences to complex, structural representations oftheir meaning.Interpreting and executing NL navigation instruc-tions is our primary task, and several other recentprojects have studied related problems.
Shimizu andHaas (2009) present a system that parses natural lan-guage instructions into actions.
However, they limitthe number of possible actions to only 15 and treatthe problem as a sequence labeling problem that issolved using a CRF with supervised training.
Ma-tuszek et al2010) developed a system that learns tomap NL instructions to executable commands for arobot navigating in an environment constructed by alaser range finder.
However, their approach has limi-tations of ignoring any objects or other landmarks inthe environment to which the instructions can refer.There are several recent projects (Vogel and Juraf-sky, 2010; Kollar et al2010; Tellex et al2011)which learn to follow instructions in more linguisti-cally complex environments.
However, they assumepredefined spatial words, direct matching betweenNL words and the names of objects and other land-marks in the MR, and/or an existing syntactic parser.By contrast, our work does not assume any prior lin-guistic knowledge, syntactic, lexical, or semantic,and must learn the mapping between NL words andphrases and the MR terms describing landmarks.7 Future WorkIn the future, we would like to develop a better lex-icon learner since our PCFG approach critically re-lies on the quality of the learned lexicon.
Particu-larly, we would like to investigate how syntactic in-formation (such as part-of-speech tags induced us-ing unsupervised learning) could be used to improvesemantic-lexicon learning.
For example, some of thecurrent lexicon entries violate the general constraintthat nouns usually refer to objects and verbs to ac-tions.
Ideally, the lexicon learner would be able toinduce and then utilize this sort of relationship be-tween syntax and semantics.In addition, we want to investigate the use of dis-criminative reranking (Collins, 2000), which hasproven effective in various other NLP tasks.
Wewould expect the final MR output to improve if adiscriminative model, which uses additional globalfeatures, is used to rerank the top-k parses producedby our generative PCFG model.8 ConclusionsWe have presented a novel method for learning asemantic parser given only highly ambiguous su-pervision.
Our model enhances Bo?rschinger etal.
(2011)?s approach to reducing the problem ofgrounded learning of semantic parsers to PCFG in-duction.
We use a learned semantic lexicon to aidthe construction of a smaller and more focused setof PCFG productions.
This allows the approachto scale to complex MR languages that define alarge (potentially infinite) space of representationsfor capturing the meaning of sentences.
By contrast,the previous PCFG approach requires a finite MRlanguage and its grammar grows intractably largefor even moderately complex MR languages.
In ad-dition, our algorithm for composing MRs from thefinal parse tree provides the flexibility to produce awide range of novel MRs that were not seen duringtraining.
Evaluations on a previous corpus of nav-igational instructions for virtual environments hasdemonstrated the effectiveness of our method com-pared to a recent competing system.AcknowledgmentsWe thank the anonymous reviewers and David Chenfor useful comments that helped improve this paper.This work was funded by NSF grants IIS-0712907and IIS-1016312.
Experiments were performed onthe Mastodon Cluster, provided by NSF grant EIA-0303609.442ReferencesBenjamin Bo?rschinger, Bevan K. Jones, and Mark John-son.
2011.
Reducing grounded learning tasks to gram-matical inference.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP-11), pages 1416?1425, Stroudsburg, PA,USA.
Association for Computational Linguistics.S.R.K.
Branavan, Harr Chen, Luke S. Zettlemoyer, andRegina Barzilay.
2009.
Reinforcement learning formapping instructions to actions.
In Joint Conferenceof the 47th Annual Meeting of the Association forComputational Linguistics and the 4th InternationalJoint Conference on Natural Language Processing ofthe Asian Federation of Natural Language Processing(ACL-IJCNLP), Singapore.David L. Chen and Raymond J. Mooney.
2008.
Learn-ing to sportscast: A test of grounded language ac-quisition.
In Proceedings of 25th International Con-ference on Machine Learning (ICML-2008), Helsinki,Finland, July.David L. Chen and Raymond J. Mooney.
2011.
Learn-ing to interpret natural language navigation instruc-tions from observations.
In Proceedings of the 25thAAAI Conference on Artificial Intelligence (AAAI-11),San Francisco, CA, USA, August.David L. Chen, Joohyun Kim, and Raymond J. Mooney.2010.
Training a multilingual sportscaster: Using per-ceptual context to learn language.
Journal of ArtificialIntelligence Research, 37:397?435.Michael Collins.
2000.
Discriminative reranking for nat-ural language parsing.
In Proceedings of the Seven-teenth International Conference on Machine Learning(ICML-2000), pages 175?182, Stanford, CA, June.Daniel Jurafsky and James H. Martin.
2000.
Speechand Language Processing: An Introduction to Natu-ral Language Processing, Computational Linguistics,and Speech Recognition.
Prentice Hall, Upper SaddleRiver, NJ.R.
J. Kate and R. J. Mooney.
2006.
Using string-kernels for learning semantic parsers.
In Proceedingsof the 21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Associ-ation for Computational Linguistics (COLING/ACL-06), pages 913?920, Sydney, Australia, July.Rohit J. Kate and Raymond J. Mooney.
2007.
Learn-ing language semantics from ambiguous supervision.In Proceedings of the Twenty-Second Conference onArtificial Intelligence (AAAI-07), pages 895?900, Van-couver, Canada, July.Joohyun Kim and Raymond.
J. Mooney.
2010.
Genera-tive alignment and semantic parsing for learning fromambiguous supervision.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(COLING-10), pages 543?551.
Association for Com-putational Linguistics.Thomas Kollar, Stefanie Tellex, Deb Roy, and NicholasRoy.
2010.
Toward understanding natural languagedirections.
In Proceedings of Human Robot Interac-tion Conference (HRI-2010).P.
Liang, M. I. Jordan, and D. Klein.
2009.
Learning se-mantic correspondences with less supervision.
In JointConference of the 47th Annual Meeting of the Associ-ation for Computational Linguistics and the 4th Inter-national Joint Conference on Natural Language Pro-cessing of the Asian Federation of Natural LanguageProcessing (ACL-IJCNLP), Singapore.Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-moyer.
2008.
A generative model for parsing naturallanguage to meaning representations.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP-08), pages 783?792,Morristown, NJ, USA.
Association for ComputationalLinguistics.M.
MacMahon, B. Stankiewicz, and B. Kuipers.
2006.Walk the talk: Connecting language, knowledge, andaction in route instructions.
In Proceedings of theTwenty-First National Conference on Artificial Intel-ligence (AAAI-06), Boston, MA, July.Cynthia Matuszek, Dieter Fox, and Karl Koscher.
2010.Following directions using statistical machine transla-tion.
In Proceedings of the 5th ACM/IEEE interna-tional conference on Human-robot interaction (HRI-10), pages 251?258, New York, NY, USA.
ACM.Nobuyuki Shimizu and Andrew Haas.
2009.
Learning tofollow navigational route instructions.
In Proceedingsof the Twenty First International Joint Conference onArtificial Intelligence (IJCAI-2009).Jeffrey M. Siskind.
1996.
A computational studyof cross-situational techniques for learning word-to-meaning mappings.
Cognition, 61(1):39?91, October.Stefanie Tellex, Thomas Kolla, Steven Dickerson,Matthew R. Walter, Ashis G. Banerjee, Seth Teller, andNicholas Roy.
2011.
Understanding natural languagecommands for robotic navigation and mobile manipu-lation.
In Proceedings of the National Conference onArtificial Intelligence (AAAI-11), August.Cynthia A. Thompson and Raymond J. Mooney.
2003.Acquiring word-meaning mappings for natural lan-guage interfaces.
Journal of Artificial Intelligence Re-search, 18:1?44.Adam Vogel and Dan Jurafsky.
2010.
Learning to fol-low navigational directions.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics (ACL-10).Yuk Wah Wong and Raymond J. Mooney.
2007.
Learn-ing synchronous grammars for semantic parsing with443lambda calculus.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Linguis-tics (ACL-07), pages 960?967, Prague, Czech Repub-lic, June.John M. Zelle and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logic pro-gramming.
In Proceedings of the Thirteenth NationalConference on Artificial Intelligence (AAAI-96), pages1050?1055, Portland, OR, August.Luke S. Zettlemoyer and Michael Collins.
2005.
Learn-ing to map sentences to logical form: Structured clas-sification with probabilistic categorial grammars.
InProceedings of 21st Conference on Uncertainty in Ar-tificial Intelligence (UAI-2005), Edinburgh, Scotland,July.Luke S. Zettlemoyer and Michael Collins.
2007.
Onlinelearning of relaxed CCG grammars for parsing to logi-cal form.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL-07), pages 678?687, Prague, CzechRepublic, June.Luke .S.
Zettlemoyer and Micheal Collins.
2009.
Learn-ing context-dependent mappings from sentences tological form.
In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP (ACL-IJCNLP-09), pages976?984.
Association for Computational Linguistics.444
