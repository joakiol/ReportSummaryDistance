Software for Annotating Argument StructureWojc iech  Skut ,  Br ig i t teKrenn,  Thors ten  Brants ,  HansUszkore i tUn ivers i t?
t  des Saar landes66041Saarbr f i cken ,  Germany{skut,krenn,brants,uszkoreit}@coli.uni-sb.deAbst ractWe present a tool developed for annota-ting corpora with argument structure re-presentations.
The presentation focuses onthe architecture of the annotation schemeand a number of techniques for increa-sing the efficiency and accuracy of annota-tion.
Among others, we show how the as-signment of grammatical functions can beautomatised using standard part-of-speechtagging methods.1 The  Annotat ion  SchemeSeveral features of the tool have been introduced tosuite the requirements imposed by the architectureof the annotation scheme (cf.
(Skut et al, 1997)),which can itself be characterised as follows:?
Direct representation of the underlying argu-ment structure in terms of unordered trees;?
Rudimentary, flat representations; uniformtreatment of local and non-local dependencies;?
Extensive ncoding of linguistic information ingrammatical function labels.Thus the format of the annotations is somewhatdifferent from treebanks relying on a context-freebackbone augmented with trace-filter annotations ofnon-local dependencies.
(cf.
(Marcus et al, 1994),(Sampson, 1995), (Black et al, 1996)) Nevertheless,such treebanks can also be developed using our tool.To back this claim, the representation f structuresfrom the SUZANNE corpus (cf.
(Sampson, 1995))will be shown in the presentation.2 User  In ter faceA screen dump of the tool is shown in fig.
1.
The lar-gest part of the window contains the graphical repre-sentation of the structure being annotated.
The no-des and edges are assigned category and grammati-cal function labels, respectively.
The words are num-bered and labelled with part-of-speech tags.
Anychange into the structure of the sentence being an-notated is immediately displayed.Extra effort has been put into the developmentof a convenient keyboard interface.
Menus are sup-ported as a useful way of getting help on commandsand labels.
Automatic completion and error checkon user input are supported.Three tagsets have to be defined by the user: part-of-speech tags, phrasal categories and grammaticalfunctions.
They are stored together with the corpus,which permits easy modification when needed.The user interface is implemented in Tcl /Tk Ver-sion 4.1.
The corpus is stored in an SQL database.3 Automat ionTo increase the efficiency of annotation and avoidcertain types of errors made by the human annota-tor, manual and automatic annotation are combinedin an interactive way.
The automatic omponent ofthe tool employs a stochastic tagging model indu-ced from previously annotated sentences.
Thus thedegree of automation increases with the amount ofdata available.At the current stage of automation, the annotatordetermines the substructures to be grouped into anew phrase and assigns it a syntactic ategory.
Theassignment of grammatical functions is performedautomatically.
To do this, we adapted a standardpart-of-speech tagging algorithm (the best sequenceof grammatical functions is to be determined for asequence of syntactic categories, cf.
(Skut et al,1997))The annotator supervises the automatic assi-gnment of function tags.
In order to keep him frommissing tagging errors, the grammatical functiontagger is equipped with a function measuring thereliability of its output.
On the basis of the diffe-rence between the best and second-best assignment,the prediction is classified as belonging to one of thefollowing certainty intervals:Rel iable:  the most probable tag is assigned,Less rel iable: the tagger suggests a function tag;the annotator is asked to confirm the choice,27- Gen eral:corp. , :  iR~!co,pus tes~op~.
..
I FIEditor: IThorsten IFI\[\] _.ar.r I-~---II _.?.o.d II ~_*,t I-Sentence:No.
: 4 / 1269Comment: IOrigin: refcorp.ttLast edited: Thorsten, 07102/97, 17:39:29isog~Es ?
spielt 1 eben 's keine 3 Rolle511ob die Mus% gef"allig 9I505+14 Neues, s 16 mu",, /iStlo -i1 nur2 etwas13PPER VVFIN ADV PlAT NN $, KOUS ART NN ADJD VAFIN, - -Move:I " ' '  II " " '  I ~-?
to: I II :~0 11 ; ,o I\[\] ~_,,to.I :~??
II ;'??
I Mato"es:?-Dependency:Selection: |Command: II Ex-ecute I$( ADV PlATI , ,i F Parentlabel:IN?de  no.
: I I/ Parent\[abel: I IRI Swi.!
?hing to sentence .no.
4....Done.Figure 1: Screen dump of the annotation toolUnre l iab le:  the annotator has to determine the.function himself.The annotator always has the option of alteringalready assigned tags.The tagger rates 90% of all assignments as relia-ble.
Accuracy for these cases is 97%.
Most errorsare due to wrong identification of the subject anddifferent kinds of objects in S's and VP's.
Accuracyof the unreliable 10% of assignments i  75%, i.e., theannotator has to alter the choice in 1 of 4 cases whenasked for confirmation.
Overall accuracy of the tag-ger is 95%.In several cases, the tagger has been able to ab-stract from annotation errors in training material,which has proved very helpful in detecting inconsi-stencies and wrong structures.This first automation step has considerably in-creased the efficiency of annotation.
The averageannotation time per sentence improved by 25%.ReferencesEzra Black et al 1996.
Beyond Skeleton Par-sing: Producing a Comprehensive Large-ScaleGeneral-English Treebank With Full Grammati-cal Analysis.
In The 16th International Confe-rence on Computational Linguistics, pages 107-113, Copenhagen, Denmark.Mitchell Marcus et al 1994.
The Penn Treebank:Annotating Predicate Argument Structure.
InProceedings of the Human Language TechnologyWorkshop, San Francisco.
Morgan Kaufmann.Geoffrey Sampson.
1995.
English for the Computer.The SUSANNE Corpus and Analytic Scheme.Wojciech Skut et al 1997.
An Annotation SchemeFor Free Word Order Languages.
In The 7th Con-ference on Applied Natural Language Processing,Washington, DC.28
