Proceedings of NAACL-HLT 2013, pages 649?654,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsPhrase Training Based Adaptation for Statistical Machine TranslationSaab Mansour and Hermann NeyHuman Language Technology and Pattern RecognitionComputer Science DepartmentRWTH Aachen University, Aachen, Germany{mansour,ney}@cs.rwth-aachen.deAbstractWe present a novel approach for translationmodel (TM) adaptation using phrase train-ing.
The proposed adaptation procedure is ini-tialized with a standard general-domain TM,which is then used to perform phrase trainingon a smaller in-domain set.
This way, we biasthe probabilities of the general TM towardsthe in-domain distribution.
Experimental re-sults on two different lectures translation tasksshow significant improvements of the adaptedsystems over the general ones.
Additionally,we compare our results to mixture modeling,where we report gains when using the sug-gested phrase training adaptation method.1 IntroductionThe task of domain-adaptation attempts to exploitdata mainly drawn from one domain (e.g.
news,parliamentary discussion) to maximize the perfor-mance on the test domain (e.g.
lectures, web fo-rums).
In this work, we focus on translation model(TM) adaptation.
A prominent approach in recentwork is weighting at different levels of granularity.Foster and Kuhn (2007) perform weighting at thecorpus level, where different corpora receive differ-ent weights and are then combined using mixturemodeling.
A finer grained weighting is that of Mat-soukas et al(2009), who weight each sentence in thebitexts using features of meta-information and opti-mize a mapping from the feature vectors to weightsusing a translation quality measure.In this work, we propose to perform TM adapta-tion using phrase training.
We start from a general-domain phrase table and adapt the probabilities bytraining on an in-domain data.
Thus, we achievedirect phrase probabilities adaptation as opposed toweighting.
Foster et al(2010) perform weightingat the phrase level, assigning each phrase pair aweight according to its relevance to the test domain.They compare phrase weighting to a ?flat?
model,where the weight directly approximates the phraseprobability.
In their experiments, the weightingmethod performs better than the flat model, there-fore, they conclude that retaining the original rela-tive frequency probabilities of the TM is importantfor good performance.
The ?flat?
model of Fosteret al(2010) is similar to our work.
We differ inthe following points: (i) we use the same procedureto perform the phrase training based adaptation andthe search thus avoiding inconsistencies between thetwo; (ii) we do not directly interpolate the originalstatistics with the new ones, but use a training pro-cedure to manipulate the original statistics.
We per-form experiments on the publicly available IWSLTTED task, on both Arabic-to-English and German-to-English lectures translation tracks.
We compareour suggested phrase training adaptation method toa variety of baselines and show its effectiveness.
Fi-nally, we experiment with mixture modeling basedadaptation.
We compare mixture modeling to ouradaptation method, and apply our method within amixture modeling framework.In Section 2, we present the phrase trainingmethod and explain how it is utilized for adaptation.Experimental setup including corpora statistics andthe SMT system are described in Section 3.
Sec-tion 4 summarizes the phrase training adaptation re-sults ending with a comparison to mixture modeling.6492 Phrase TrainingThe standard phrase extraction procedure in SMTconsists of two phases: (i) word-alignment training(e.g., IBM alignment models), (ii) heuristic phraseextraction and relative frequency based phrase trans-lation probability estimation.
In this work, we utilizephrase training for the task of adaptation.
We usethe forced alignment (FA) method (Wuebker et al2010) to perform the phrase alignment training andprobability estimation.
We perform phrase trainingby running a normal SMT decoder on the trainingdata and constrain the translation to the given targetinstance.
Using n-best possible phrase segmentationfor each training instance, the phrase probabilitiesare re-estimated over the output.
Leaving-one-out isused during the forced alignment procedure phase toavoid over-fitting (Wuebker et al 2010).In the standard phrase training procedure, weare given a training set y, from which an initialheuristics-based phrase table p0y is generated.
FAtraining is then done over the training set y using thephrases and probabilities in p0y (possibly updated bythe leaving-one-out method).
Finally, re-estimationof the phrase probabilities is done over the decoderoutput, generating the FA phrase table p1.
We ex-plain next how to utilize FA training for adaptation.2.1 AdaptationIn this work, we utilize phrase training for the taskof adaptation.
The main idea is to generate the initialphrase table required for FA using a general-domaintraining data y?, thus resulting in p0y?
, and performthe FA training over yIN , the in-domain trainingdata (instead of y?
in the standard procedure).
Thisway, we bias the probabilities of p0y?
towards the in-domain distribution.
We denote this new procedureby Y?-FA-IN.
This differs from the standard IN-FA-IN by that we have more phrase pairs to use for FA.Thus, we obtain phrase pairs relevant to IN in ad-dition to ?general?
phrase pairs which were not ex-tracted from IN, perhaps due to faulty word align-ments.
The probabilities of the general phrase tablewill be tailored towards IN.
In practice, we usuallyhave in-domain IN and other-domain OD data.
Wedenote by ALL the concatenation of IN and OD.
Toadapt the ALL phrase table, we perform the FA pro-cedure ALL-FA-IN.
We also utilize leaving-one-outto avoid over-fitting.Another procedure we experimented with isadapting the OD phrase table using FA over IN,without leaving-one-out.
We denote it by OD-FA0-IN.
In this FA scenario, we do not use leaving-one-out as IN is not contained in OD, therefore, over-fitting will not occur.
By this procedure, we trainphrases from OD that are relevant for both OD andIN, while the probabilities will be tailored to IN.
Inthis case, we do not expect improvements over theIN based phrase table, but, improvements over ODand reduction in the phrase table size.We compare our suggested FA based adaptationto the standard FA procedure.3 Experimental Setup3.1 Training CorporaTo evaluate the introduced methods experimentally,we use the IWSLT 2011 TED Arabic-to-English andGerman-to-English translation tasks.
The IWSLT2011 evaluation campaign focuses on the transla-tion of TED talks, a collection of lectures on avariety of topics ranging from science to culture.For Arabic-to-English, the bilingual data consistsof roughly 100K sentences of in-domain TED talksdata and 8M sentences of ?other?-domain UnitedNations (UN) data.
For the German-to-English task,the data consists of 130K TED sentences and 2.1Msentences of ?other?-domain data assembled fromthe news-commentary and the europarl corpora.
Forlanguage model training purposes, we use an addi-tional 1.4 billion words (supplied as part of the cam-paign monolingual training data).The bilingual training and test data for the Arabic-to-English and German-to-English tasks are sum-marized in Table 11.
The English data was tok-enized and lowercased while the Arabic data wastokenized and segmented using MADA v3.1 (Rothet al 2008) with the ATB scheme.
The Germansource is decompounded (Koehn and Knight, 2003)and part-of-speech-based long-range verb reorder-ing rules (Popovic?
and Ney, 2006) are applied.From Table 1, we note that using the generaldata considerably reduces the number of out-of-1For a list of the IWSLT TED 2011 training cor-pora, see http://www.iwslt2011.org/doku.php?id=06_evaluation650Set Sen Tok OOV/IN OOV/ALLGerman-to-EnglishIN 130K 2.5MOD 2.1M 55Mdev 883 20K 398 (2.0%) 215 (1.1%)test 1565 32K 483 (1.5%) 227 (0.7%)eval 1436 27K 490 (1.8%) 271 (1.0%)Arabic-to-EnglishIN 90K 1.6MOD 7.9M 228Mdev 934 19K 408 (2.2%) 184 (1.0%)test 1664 31K 495 (1.6%) 228 (0.8%)eval 1450 27K 513 (1.9%) 163 (0.6%)Table 1: IWSLT 2011 TED bilingual corpora statistics:the number of tokens is given for the source side.
OOV/Xdenotes the number of OOV words in relation to corpusX (the percentage is given in parentheses).
IN is the TEDin-domain data, OD denotes other-domain data, ALL de-notes the concatenation of IN and OD.vocabulary (OOV) words.
This comes with the priceof increasing the size of the training data by a factorof more than 20.
A simple concatenation of the cor-pora might mask the phrase probabilities obtainedfrom the in-domain corpus, causing a deteriorationin performance.
One way to avoid this contamina-tion is by filtering the general corpus, but this dis-cards phrase translations completely from the phrasemodel.
A more principled way is by adapting thephrase probabilities of the full system to the domainbeing tackled.
We perform this by phrase trainingthe full phrase table over the in-domain training set.3.2 Translation SystemThe baseline system is built using the open-sourceSMT toolkit Jane 2.0, which provides a state-of-the-art phrase-based SMT system (Wuebker et al2012a).
In addition to the phrase based decoder,Jane 2.0 implements the forced alignment procedureused in this work for the purpose of adaptation.
Weuse the standard set of models with phrase transla-tion probabilities for source-to-target and target-to-source directions, smoothing with lexical weights,a word and phrase penalty, distance-based reorder-ing and an n-gram target language model.
The SMTsystems are tuned on the dev (dev2010) developmentset with minimum error rate training (Och, 2003) us-ing BLEU (Papineni et al 2002) accuracy measureas the optimization criterion.
We test the perfor-mance of our system on the test (tst2010) and eval(tst2011) sets using the BLEU and translation editrate (TER) (Snover et al 2006) measures.
We useTER as an additional measure to verify the consis-tency of our improvements and avoid over-tuning.The Arabic-English results are case sensitive whilethe German-English results are case insensitive.4 ResultsFor TM training, we define three different sets: in-domain (IN) which is the TED corpus, other-domain(OD) which consists of the UN corpus for Arabic-English and a concatenation of news-commentaryand europarl for German-English, and ALL whichconsists of the concatenation of IN and OD.
We ex-periment with the following extraction methods:?
Heuristics: standard phrase extraction usingword-alignment training and heuristic phraseextraction over the word alignment.
The ex-traction is performed for the three differenttraining data, IN, OD and ALL.?
FA standard: standard FA phrase trainingwhere the same training set is used for initialphrase table generation as well as the FA pro-cedure.
We perform the training on the threedifferent training sets and denote the resultingsystems by IN-FA, OD-FA and ALL-FA.?
FA adaptation: FA based adaptation phrasetraining, where the initial table is generatedfrom some general data and the FA training isperformed on the IN data to achieve adapta-tion.
We perform two experiments, OD-FA0-IN without leaving-one-out and ALL-FA-INwith leaving-one-out.The results of the various experiments over bothArabic-English and German-English tasks are sum-marized in Table 2.
The usefulness of the ODdata differs between the Arabic-to-English and theGerman-to-English translation tasks.
For Arabic-to-English, the OD system is 2.5%-4.3% BLEU worsethan the IN system, whereas for the German-to-English task the differences between IN and OD aresmaller and range from 0.9% to 1.6% BLEU.
The651Phrase training System Rules dev test evalmethod number BLEU TER BLEU TER BLEU TERArabic-to-EnglishHeuristicsIN 1.1M 27.2 54.1 25.3 57.1 24.3 59.9OD 36.3M 24.7 57.7 21.2 62.6 21.0 64.7ALL 36.9M 27.1 54.8 24.4 58.6 23.8 61.1FA standardIN-FA 1.0M 27.0 54.4 25.0 57.5 23.8 60.3OD-FA 1.8M 24.5 57.7 21.0 62.4 21.2 64.3ALL-FA 2.0M 27.2 54.2 24.5 58.1 23.8 60.6FA adaptationOD-FA0-IN 0.3M 25.8 55.8 23.6 59.4 22.7 61.7ALL-FA-IN 0.5M 27.7 53.7 25.3 56.9 24.7 59.3German-to-EnglishHeuristicsIN 1.3M 31.0 48.9 29.3 51.0 32.7 46.8OD 7.3M 29.8 49.2 27.7 51.5 31.8 47.5ALL 7.8M 31.2 48.3 29.5 50.5 33.6 46.1FA standardIN-FA 0.5M 31.6 48.2 29.7 50.5 33.3 46.4OD-FA 3.0M 29.1 51.0 27.6 53.0 30.7 49.6ALL-FA 3.2M 31.4 48.3 29.4 50.8 33.6 46.2FA adaptationOD-FA0-IN 0.9M 31.2 48.7 29.1 50.9 32.7 46.9ALL-FA-IN 0.9M 31.8 47.4 29.7 49.7 33.6 45.5Table 2: TED 2011 translation results.
BLEU and TER are given in percentages.
IN denotes the TED lectures in-domain corpus, OD denotes the other-domain corpus, ALL is the concatenation of IN and OD.
FA0 denotes forcedalignment training without leaving-one-out (otherwise, leaving-one-out is used).inferior performance of the OD system can be re-lated to noisy data or bigger discrepancy betweenthe OD data domain distribution and the IN distri-bution.
The ALL system performs according to theusefulness of the OD training set, where for Arabic-to-English we observe deterioration in performancefor all test sets and up-to -0.9% BLEU on the testset.
On the other hand, for German-to-English, theALL system is improving over IN where the biggestimprovement is observed on the eval set with +0.9%BLEU improvement.The standard FA procedure achieves mixed re-sults, where IN-FA deteriorates the results over theIN counterpart for Arabic-English, while improvingfor German-English.
ALL-FA performs comparablyto the ALL system on both tasks, while reducing thephrase table size considerably.
The OD-FA systemdeteriorates the results in comparison to the OD sys-tem in most cases, which is expected as training overthe OD set fits the phrase model on the OD domain,making it perform worse on IN.
(Wuebker et al2012b) also report mixed results with FA training.The FA adaptation results are summarized in thelast block of the experiments.
The OD-FA0-IN im-proves over the OD system, which means that thetraining procedure was able to modify the OD prob-abilities to perform well on the IN data.
On theGerman-to-English task, the OD-FA0-IN performscomparably to the IN system, whereas for Arabic-to-English OD-FA0-IN was able to close around halfof the gap between OD and IN.The FA adapted ALL system (ALL-FA-IN) per-forms best in our experiments, improving on bothBLEU and TER measures.
In comparison to thebest heuristics system (IN for Arabic-English andALL for German-English), +0.4% BLEU and -0.6%TER improvements are observed on the eval set forArabic-English.
For German-English, the biggestimprovements are observed on TER with -0.8% ontest and -0.5% on eval.
The results suggest that ALL-FA-IN is able to learn more useful phrases than theIN system and adjust the ALL phrase probabilitiestowards the in-domain distribution.652System dev testBLEU TER BLEU TERArabic-to-EnglishHeuristicsbest 27.2 54.1 25.3 57.1IN,OD 28.2 53.1 25.5 56.8IN,OD-FA0-IN 28.4 52.9 25.7 56.5German-to-EnglishHeuristicsbest 31.2 48.3 29.5 50.5IN,OD 31.6 48.2 29.9 50.5IN,OD-FA0-IN 31.8 47.8 30.0 50.0Table 3: TED 2011 mixture modeling results.Heuristicsbest is the best heuristics based system, IN forArabic-English and ALL for German-English.
X,Y de-notes linear interpolation between X and Y phrase tables.4.1 Mixture ModelingIn this section, we compare our method to mixturemodeling based adaptation, in addition to applyingmixture modeling on top of our method.
We focuson linear interpolation (Foster and Kuhn, 2007) ofthe in-domain (IN) and other-domain phrase tables,where we vary the latter between the heuristicallyextracted phrase table (OD) and the FA adapted one(OD-FA0-IN).
The interpolation weight is uniformfor the interpolated phrase tables (0.5).
The resultsof mixture modeling are summarized in Table 3.
Inthis table, we include the best heuristics based sys-tem (Heuristicsbest) from Table 2 as a reference sys-tem.
The results on the eval set are omitted as theyshow similar tendencies to the test set results.Linear interpolation of IN and OD (IN,OD) is per-forming well in our experiments, with big improve-ments over the dev set, +1.0% BLEU for Arabic-to-English and +0.4% BLEU for German-to-English.On the test set, we observe smaller improvements.Interpolating IN with the phrase training adaptedsystem OD-FA0-IN (IN,OD-FA0-IN) achieves ad-ditional gains over the IN,OD system, the biggestare observed on TER for German-to-English, with-0.4% and -0.5% improvements on the dev and testsets correspondingly.Comparing heuristics based interpolation(IN,OD) to our best phrase training adapted system(ALL-FA-IN) shows mixed results.
For Arabic-to-English, the systems are comparable, while for theGerman-to-English test set, IN,OD is +0.2% BLEUbetter and +0.8% TER worse than ALL-FA-IN.
Wehypothesize that for Arabic-to-English interpolationis important due to the larger size of the OD data,where it could reduce the masking of the IN trainingdata by the much larger OD data.
Nevertheless,as mentioned previously, using phrase trainingadapted phrase table in a mixture setup consistentlyimproves over using heuristically extracted tables.5 ConclusionsIn this work, we propose a phrase training procedurefor adaptation.
The phrase training is implementedusing the FA method.
First, we extract a standardphrase table using the whole available training data.Using this table, we initialize the FA procedure andperform training on the in-domain set.Experiments are done on the Arabic-to-Englishand German-to-English TED lectures translationtasks.
We show that the suggested procedure is im-proving over unadapted baselines.
On the Arabic-to-English task, the FA adapted system is +0.9%BLEU better than the full unadapted counterpart onboth test sets.
Unlike the Arabic-to-English setup,the German-to-English OD data is helpful and pro-duces a strong unadapted baseline in concatenationwith IN.
In this case, the FA adapted system achievesBLEU improvements mainly on the development setwith +0.6% BLEU, on the test and eval sets, im-provements of -0.8% and -0.6% TER are observedcorrespondingly.
As a side effect of the FA trainingprocess, the size of the adapted phrase table is lessthan 10% of the size of the full table.Finally, we experimented with mixture model-ing where improvements are observed over the un-adapted baselines.
The results show that using ourphrase training adapted OD table yields better per-formance than using the heuristically extracted ODin a mixture framework.AcknowledgmentsThis material is based upon work supported by theDARPA BOLT project under Contract No.
HR0011-12-C-0015.
Any opinions, findings and conclusionsor recommendations expressed in this material arethose of the authors and do not necessarily reflectthe views of DARPA.653ReferencesGeorge Foster and Roland Kuhn.
2007.
Mixture-modeladaptation for SMT.
In Proceedings of the SecondWorkshop on Statistical Machine Translation, pages128?135, Prague, Czech Republic, June.
Associationfor Computational Linguistics.George Foster, Cyril Goutte, and Roland Kuhn.
2010.Discriminative instance weighting for domain adapta-tion in statistical machine translation.
In Proceedingsof the 2010 Conference on Empirical Methods in Natu-ral Language Processing, pages 451?459, Cambridge,MA, October.
Association for Computational Linguis-tics.Philipp Koehn and Kevin Knight.
2003.
Empirical Meth-ods for Compound Splitting.
In Proc.
10th Conf.
of theEurop.
Chapter of the Assoc.
for Computational Lin-guistics (EACL), pages 347?354, Budapest, Hungary,April.Spyros Matsoukas, Antti-Veikko I. Rosti, and BingZhang.
2009.
Discriminative corpus weight estima-tion for machine translation.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 708?717, Singapore, Au-gust.
Association for Computational Linguistics.Franz J. Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proceedings of the41th Annual Meeting of the Association for Compu-tational Linguistics, pages 160?167, Sapporo, Japan,July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, Penn-sylvania, USA, July.M.
Popovic?
and H. Ney.
2006.
POS-based Word Re-orderings for Statistical Machine Translation.
In In-ternational Conference on Language Resources andEvaluation, pages 1278?1283.Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,and Cynthia Rudin.
2008.
Arabic morphological tag-ging, diacritization, and lemmatization using lexememodels and feature ranking.
In Proceedings of ACL-08: HLT, Short Papers, pages 117?120, Columbus,Ohio, June.
Association for Computational Linguis-tics.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Studyof Translation Edit Rate with Targeted Human Anno-tation.
In Proceedings of the 7th Conference of theAssociation for Machine Translation in the Americas,pages 223?231, Cambridge, Massachusetts, USA, Au-gust.Joern Wuebker, Arne Mauser, and Hermann Ney.
2010.Training phrase translation models with leaving-one-out.
In Proceedings of the 48th Annual Meeting of theAssoc.
for Computational Linguistics, pages 475?484,Uppsala, Sweden, July.Joern Wuebker, Matthias Huck, Stephan Peitz, MalteNuhn, Markus Freitag, Jan-Thorsten Peter, Saab Man-sour, and Hermann Ney.
2012a.
Jane 2: Opensource phrase-based and hierarchical statistical ma-chine translation.
In International Conference onComputational Linguistics, Mumbai, India, Decem-ber.Joern Wuebker, Mei-Yuh Hwang, and Chris Quirk.2012b.
Leave-one-out phrase model training for large-scale deployment.
In NAACL 2012 Seventh Work-shop on Statistical Machine Translation, pages 460?467, Montreal, Canada, June.
Association for Compu-tational Linguistics.654
