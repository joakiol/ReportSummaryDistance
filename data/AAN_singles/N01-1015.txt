Re-Engineering Letter-to-Sound RulesMartin JanscheThe Ohio State UniversityColumbus, OH 43210, U.S.A.jansche.1@osu.eduAbstractUsing finite-state automata for the text analysiscomponent in a text-to-speech system is problem-atic in several respects: the rewrite rules from whichthe automata are compiled are difficult to write andmaintain, and the resulting automata can becomevery large and therefore inefficient.
Converting theknowledge represented explicitly in rewrite rulesinto a more efficient format is difficult.
We take anindirect route, learning an efficient decision tree rep-resentation from data and tapping information con-tained in existing rewrite rules, which increases per-formance compared to learning exclusively from apronunciation lexicon.1 IntroductionText-to-speech (TTS) systems, like any other pieceof sophisticated software, suffer from the shortcom-ings of the traditional software development pro-cess.
Highly skilled developers are a costly re-source, the complexity and sheer size of the codeinvolved are difficult to manage.
A paradigmaticexample of this is the letter-to-sound componentwithin the text analysis module of a mature large-scale text-to-speech system.
In the system describedin (Sproat, 1998) text analysis is performed usingfinite-state transducers compiled from rewrite rules(Kaplan and Kay, 1994; Mohri and Sproat, 1996)and other high-level descriptions.
While the exclu-sive use of finite-state technology has advantages, itis not without its shortcomings, both technical andstemming from the use of hand-crafted rule sets andhow they are represented:1.
Extensive rule sets need to be constructed byhuman experts, which is labor-intensive andexpensive (Sproat et al, 1998).2.
Realistic rule sets are difficult to maintain be-cause of complex interactions between seriallycomposed rules.3.
Although rewrite rules can, in principle, becompiled into a huge monolithic transducerthat is then very time-efficient, in practice thisis not feasible because of the enormous sizes ofthe resulting machines (cf.
the numbers givenin (Mohri and Sproat, 1996) and (Sproat et al,1998, 74)).4.
For reasons of space efficiency, certain com-putations are deferred until run-time (Mohri etal., 1996; Mohri et al, 2000), with a significantimpact on time efficiency.While there is a clear need for human expertknowledge (Sproat et al, 1998, 75ff.
), those expertsshould not have to deal with the performance as-pects of the knowledge representation.
Ideally wewould like to use a knowledge representation thatis both time and space efficient and can be con-structed automatically from individually meaning-ful features supplied by human experts.
For practi-cal reasons we have to be content with methods thataddress the efficiency issues and can make use ofexplicitly represented knowledge from legacy sys-tems, so that moving to a new way of building TTSsystems does not entail starting over from scratch.As a case study of how this transition might beachieved we took the letter-to-phoneme rules forFrench in the TTS system described in (Sproat,1998) and proceeded to1.
Construct a lexicon using the existing system.2.
Produce an alignment for that lexicon.3.
Convert the aligned lexicon into training in-stances for an automatically induced classifier.4.
Train and evaluate decision trees.By running the existing system on a small news-paper corpus (ca.
1M words of newspaper text fromLe Monde) and eliminating abbreviations we ob-tained a lexicon of about 18k words.
This meansthat the performance of the automatically trainedsystem built from this lexicon is relative to the ex-isting system.The key steps, aligning the lexicon and buildinga training set, are described in detail in Sections 2and 3 below.Our choice of decision trees was motivated bytheir following desirable properties:1.
Space and time efficiency, provided the featurefunctions can be represented and computed ef-ficiently, which they can be in our case.2.
Generality.3.
Symbolic representation that can easily be in-spected and converted.The first property addresses the efficiency re-quirements stated above: if every feature functioncan be computed in time O(f), where the functionf does not involve the height of the decision tree h,then the classification function represented by thedecision tree can be computed in time O(?n.
h ?f(n)) = O(f) if feature values can be mapped tochild nodes in constant time, e. g. through hashing;and similarly for space.The other properties justify the use of decisiontrees as a knowledge representation format.
In par-ticular, decision trees can be converted into im-plicational rules that an expert could inspect andcan in principle be compiled back into finite-statemachines (Sproat and Riley, 1996), although thatwould re-introduce the original efficiency problems.On the other hand, finite-state transducers have theadvantage of being invertible, which can be ex-ploited e. g. for testing hand-crafted rule sets.We use a standard decision tree learner (Quin-lan, 1993), since we believe that it would be pre-mature to investigate the implications of differentchoices of machine learning algorithms while thefundamental question of what any such algorithmshould use as training data is still open.
This topicis explored further in Section 5.
Related work isdiscussed in Section 6.2 Aligning the LexiconLearning a mapping between sets of strings is dif-ficult unless the task is suitably restricted or addi-tional supervision is provided.
Aligning the lexiconallows us to transform the learning task into a clas-sification task to which standard machine learningtechniques can be applied.Given a lexical entry we ideally would want toalign each letter with zero or more phonemes ina way that minimizes the descriptions of the func-tion performing the mapping and of the exceptions.Since we do not know how to do this efficiently,we chose to be content with an alignment producedby the first phase of the algorithm described in(Luk and Damper, 1996): we treat the strings to bealigned as bags of symbols, count all possible com-binations, and use this to estimate the parameters fora zeroth-order Markov model.
(a) t e x .
t et E k s t .
(b) t e x t e .
.
.
.
.. .
.
.
.
t E k s tFigure 1: Two possible alignmentsFigure 1 shows two examples of an alignment,where the dot represents the empty string (for rea-sons of visual clarity), also referred to as ?.
Align-ment (b), while not as intuitively plausible as align-ment (a), is possible as an extreme case.
In gen-eral, when counting the combinations of ` letterswith p phonemes, we want to include p empty let-ters and ` empty phonemes.
For example, given theletters ?texte?
and corresponding phonemes /tEkst/,we count CL(t, ?)
= 10, CL(t, t) = 4, CL(t, k) = 2,etc.
By normalizing the counts we arrive at an em-pirical joint probability distribution P?L for the lexi-con.The existing rewrite rules were another source ofinformation.
A rewrite rule is of the form??
?
/ ?
?where ?
is usually a string of letters and ?
a stringof phonemes.
The contextual restrictions expressedby ?
and ?
will be ignored.
Typically ?
and ?are very short, rarely consisting of more than foursymbols.
We created a second lexicon consistingof around 200 pairs ?
?, ??
mentioned in the rewriterules, and applied the same procedure as before toobtain counts CR and from those a joint probabilitydistribution P?R.The two empirical distributions were combinedand smoothed by linear interpolation with a uniformdistribution PU :P (x, y) = ?1P?R(x, y) + ?2P?L(x, y) + ?3PU (x, y)where each ?i ?
0 and ?1 + ?2 + ?3 = 1.
Theeffects of using different coefficient vectors ~?
willbe discussed in Section 4.Since we had available a library for manipulatingweighted automata (Mohri et al, 2000), the align-ments were computed by using negative log proba-bilities as weights for a transducer with a single state(hence equivalent to a zeroth-order Markov model),composing on the left with the letter string and onthe right with the phoneme string, and finding thebest path (Searls and Murphy, 1995; Mohri et al,2000).
This amounts to inserting ?-symbols intoboth the string of letters and the string of phonemesin a way that minimizes the overall weight of thetransduction, i. e. maximizes the probability of thealignment with respect to the model.3 Building Training InstancesNow we bring in additional restrictions that allowus to express the task of finding a function that mapsletter sequences to phoneme sequences as the sim-pler task of inducing a mapping from a single letterto a single phoneme.
This is a standard classifica-tion task, and once we have a set of feature func-tions and training instances we can choose from amultitude of learning algorithms and target repre-sentations.
However, investigating the implicationsof different choices is not our goal.The first simplifying assumption is to pretend thattranslating an entire text amounts to translating eachword in isolation (but see the discussion of liaisonin Section 5 below).
Secondly we make use of thefact that the pronunciation of a letter is in most casesfully determined by its local context, much more soin French (Laporte, 1997) than in English.Each letter is to be mapped to a phoneme, or theempty string ?, in the case of ?silent?
letters (dele-tions).
An additional mechanism is needed for thosecases where a letter corresponds to more than onephoneme (insertions), e. g. the letter ?x?
correspond-ing to the phonemes /ks/ in Figure 2a.
The problemis the non-uniform appearance of an explicit emptystring symbol that allows for insertions.
We avoidedhaving to build a separate classifier to predict theseinsertion points (see (Riley, 1991) in the context ofpronunciation modeling) by simply pretending thatan explicit empty string is present before each letterand after the last letter.
This is illustrated in Fig-ure 2b.
Visual inspection of several aligned lexicarevealed that at most one empty string symbol isneeded between any two letters.From these aligned and padded strings we derivedtraining instances by considering local windows ofa fixed size.
A context of size one requires a win-(a) t e x .
t et E k s t .
(b) .
t .
e .
x .
t .
e .. t .
E .
k s t .
.
.Figure 2: Padding aligned stringsdow of size three, which is centered on the letteraligned with the target phoneme.
Figure 3 showsthe first few training instances derived from the ex-ample in Figure 2b above.
The beginning and endof the string are marked with a special symbol.
Notethat the empty string symbol only appears in thecenter of the window, never in the contextual part,where it would not convey any information.$ .
t 7?
.$ t e 7?
tt .
e 7?
.t e x 7?
Ee .
x 7?
.e x t 7?
kx .
t 7?
sx t e 7?
tFigure 3: A few training instances (context size: 1)4 EvaluationWe delineated a 90%/10% split of the lexicon andperformed the alignment using a probability distri-bution with coefficients ?1 = 0, ?2 = 0.9, and?3 = 0.1, i. e., no information from the rewriterules was used and the empirical probabilities de-rived from the lexicon were smoothed slightly.
Thevalue for ?3 was determined empirically after sev-eral trial runs on a held-out portion.
We then gener-ated training instances as described in the previoussection, and set aside the 10% we had earmarkedearlier for testing purposes.
We ran C4.5 on the re-maining portion of the data, using the held out 10%for testing.
Table 1 summarizes the following as-pects of the performance of the induced decisiontree classifiers on the test data relative to the size ofcontext used for classification: classification accu-racy per symbol; micro-averaged precision (P) andrecall (R) per symbol; size of the tree in number ofnodes; and size of the saved tree data in kilobytes.All trees were pruned and the subsetting option ofC4.5 was used to further reduce the size of the trees.Further increasing the context size did not resultin better performance.
We did see a performance in-context acc.
P R size of treeletters % % % nodes kB0 84.0 51.9 86.6 44 71 96.6 90.0 91.3 917 1492 98.6 97.0 97.1 2664 4353 98.7 97.5 97.4 3585 586Table 1: Performance relative to context size, align-ment based on lexiconcrease, however, when we repeated the above proce-dure with different coefficients ~?.
This time we set?1 = 0.9, ?2 = 0.09, and ?3 = 0.01.
These partic-ular values were again determined empirically.
Theimportant thing to note is that the information fromthe rewrite rules is now dominant, as compared tobefore when it was completely absent.
The effectthis had on performance is summarized in Table 2for three letters of context.
As before, classificationaccuracy is given on a per-symbol basis; average ac-curacy per word is around 85%.
Notice that the sizeof the tree decreases as a result of a better alignment.alignment acc.
P R size of tree% % % nodes kBlexicon 98.7 97.5 97.4 3585 586lex.
+ rules 98.9 97.8 97.9 3394 555Table 2: Performance relative to alignment quality(context size: 3)These figures are all relative to our existing sys-tem.
What is most important to us are the vast im-provements in efficiency: the decision trees take upless than 10% of the space of the original letter-to-phoneme component, which weighs in at 6.7 MBtotal with composition deferred until runtime, sinceoff-line composition would have resulted in an im-practically large machine.
The size of the origi-nal component could be reduced through the useof compression techniques (Kiraz, 1999), whichwould lead to an additional run-time overhead.Classification speed of the decision trees is onthe order of several thousand letters per second (de-pending on platform details), which is many timesfaster than the existing system.
The exact details ofa speed comparison depend heavily on platform is-sues and what one considers to be the average case,but a conservative estimate places the speedup at afactor of 20 or more.5 Directions for Further ResearchThe tremendous gains in efficiency will enable usto investigate the use of additional processing mod-ules that are not included in the existing system be-cause they would have pushed performance belowan acceptable bound.
For example no sophisticatedpart-of-speech (POS) disambiguation is done at themoment, but would be needed to distinguish, e. g.,between different pronunciations of French wordsending in -ent, which could be verbs, nouns, ad-verbs, etc.
The need for POS disambiguation iseven clearer for languages with ?deep?
orthogra-phies, such as English.
In conjunction with shallowparsing, POS disambiguation would give us enoughinformation to deal with most cases of liaison, aninter-word phenomenon that required special atten-tion in the existing system and that we have so farignored in the new approach because of the exclu-sive focus on regularities at the level of isolatedwords.We have been using the existing automaton-basedsystem as our baseline, which is unfair becausethat system makes mistakes which could very wellobscure some regularities the inductive approachmight otherwise have discovered.
Future compar-isons should use an independent gold standard, suchas a large dictionary, to evaluate and compare bothapproaches.
The advantage of using the existingsystem instead of a dictionary is that we could gen-erate large amounts of training data from corpora.But even with plenty of training data available,the paradigms of verbal inflections, for example,are quite extensive in French, inflected verb formsare typically not listed in a dictionary, and we can-not guarantee that sufficiently many forms appearin a corpus to guarantee full coverage.
In this caseit would make sense to use a hybrid approach thatreuses the explicit representations of verbal inflec-tions from the existing system.More importantly, having more training dataavailable for use with our new approach wouldonly help to a small extent.
Though more and/orcleaner data would possibly result in better align-ments, we do not expect to find vast improvementsunless the restriction imposed by the zeroth-orderMarkov assumption used for alignment is dropped,which could easily be done.
However, it is not clearthat using a bigram or trigram model for alignmentwould optimize the alignment in such a way that thedecision tree classifier learned from the aligned datais as small and accurate as possible.This points to a fundamental shortcoming of theusual two-step procedure, which we followed here:the goodness of an alignment performed in the firststep should be determined by the impact it has onproducing an optimal classifier that is induced inthe second step.
However, there is no provision forfeedback from the second step to the first step.
Forthis a different setup would be needed that woulddiscover an optimal alignment and classifier at thesame time.
This, to us, is one of the key researchquestions yet to be addressed in learning letter-to-sound rules, since the quality of an alignment andhence the training data for a classifier learner is es-sential for ensuring satisfactory performance of theinduced classifier.
The question of which classifier(learner) to use is secondary and not necessarily spe-cific to the task of learning letter?sound correspon-dences.6 Relation to Existing ResearchThe problem of letter-to-sound conversion is verysimilar to the problem of modeling pronuncia-tion variation, or phonetic/phonological model-ing (Miller, 1998).
For pronunciation modelingwhere alternative pronunciations are generated fromknown forms one can use standard similarity met-rics for strings (Hamming distance, Levenshteindistance, etc.
), which are not meaningful for map-pings between sequences over dissimilar alphabets,such as letter-to-phoneme mappings.General techniques for letter-to-phoneme con-version need to go beyond dictionary lookups andshould be able to handle all possible written wordforms.
Since the general problem of learning reg-ular mappings between regular languages is in-tractable because of the vast hypothesis space, allexisting research on automatic methods has im-posed restrictions on the class of target functions.
Inalmost all cases, this paper included, one only con-siders functions that are local in the sense that onlya fixed amount of context is relevant for mapping aletter to a phoneme.One exception to this is (Gildea and Jurafsky,1995), where the target function space are the subse-quential transducers, for which a limit-identificationalgorithm exists (Oncina et al, 1993).
However,without additional guidance, that algorithm cannotbe directly applied to the phonetic modeling taskdue to data sparseness and/or lack of sufficient bias(Gildea and Jurafsky, 1995).
We would argue thatthe lack of locality restrictions is at the root of theconvergence problems for that approach.Our approach effectively restricts the hypothe-sis space even further to include only the k-local(or strictly k-testable) sequential transducers, wherea classification decision is made deterministicallyand based on a fixed amount of context.
We con-sider this to be a good target since we would likethe letter-to-sound mapping to be a function (everypiece of text has exactly one contextually appropri-ate phonetic realization) and to be deterministicallycomputable without involving any kind of search.Locality gives us enough bias for efficiently learn-ing classifiers with good performance.
Since weare dealing with a restricted subclass of finite-statetransducers, our approach is, at a theoretical level,fully consistent with the claim in (Sproat, 2000) thatletter?phoneme correspondences can be expressedas regular relations.
However, it must be stressedthat just because something is finite-state does notmean it should be implemented directly as a finite-state automaton.Other machine learning approaches employ es-sentially the same locality restrictions.
Differentlearning algorithms can be used, including Artificialneural networks (Sejnowski and Rosenberg, 1987;Miller, 1998), decision tree learners (Black et al,1998), memory-based learners and hybrid symbolicapproaches (Van den Bosch and Daelemans, 1993;Daelemans and van den Bosch, 1997), or Markovmodels.
Out of these the approach in (Black et al,1998) is most similar to ours, but it presupposesthat phoneme strings are never longer than the cor-responding letter strings, which is mostly true, buthas systematic exceptions, e. g. ?exact?
in Englishor French.
English has many more exceptions thatdo not involve the letter ?x?, such as ?cubism?
(/kju-bIz@m/ according to cmudict.0.6) or ?mutual-sim?.The problem of finding a good alignment has notreceived its due attention in the literature.
Workon multiple alignments in computational biologycannot be adapted directly because the letter-to-sound mapping is between dissimilar alphabets.The alignment problem in statistical machine trans-lation (Brown et al, 1990) is too general: long-distance displacement of large chunks of materialmay occur frequently when translating whole sen-tences, but are unlikely to play any role for theletter-to-sound mapping, though local reorderingsdo occur (Sproat, 2000).
Ad hoc figures of merit foralignments (Daelemans and van den Bosch, 1997)or hand-corrected alignments (Black et al, 1998)might give good results in practice, but do not getus any closer to a principled solution.
The presentwork is another step towards obtaining better align-ments by exploiting easily available knowledge in asystematic fashion.7 ConclusionWe presented a method for building efficient letter-to-sound rules from information extractable from,or with the help of, existing hand-crafted rewriterules.
Using decision trees as the new target rep-resentation, significant improvements in time andspace efficiency could be achieved at the cost ofa reduction in accuracy.
Our approach relies onfinding an alignment between strings of letters andphonemes.
We identified a way to improve align-ments and argued that finding a good alignment iscrucial for success and should receive more atten-tion.AcknowledgmentsThe work reported on here was carried out withinLucent Technologies?
Summer Research Program.I would like to thank the people at Bell Labs fortheir help and support, especially Gerald Penn, whowas my mentor for the summer, and Evelyne Tzouk-ermann.
Thanks also to Chris Brew, Gerald Penn,Richard Sproat, and three anonymous reviewers forvaluable feedback on this paper.
The usual dis-claimers apply.ReferencesAlan W. Black, Kevin Lenzo, and Vincent Pagel.1998.
Issues in building general letter to soundrules.
In Proc.
of the 3rd ESCA Workshop onSpeech Synthesis, pages 77?80.Antal van den Bosch and Walter Daelemans.1993.
Data-oriented methods for grapheme-to-phoneme conversion.
In Proc.
of the 6th Euro-pean Conference of the Association for Compu-tational Linguistics, pages 45?53.Peter F. Brown, John Cocke, Stephen A.Della Pietra, Vincent J. Della Pietra, FredrickJelinek, John D. Lafferty, Robert L. Mercer, andPaul S. Rossin.
1990.
A statistical approach tomachine translation.
Computational Linguistics,16(2):79?85.Walter M. P. Daelemans and Antal P. J. van denBosch.
1997.
Language-independent data-oriented grapheme-to-phoneme conversion.
InJan P. H. van Santen, Richard W. Sproat,Joseph P. Olive, and Julia Hirschberg, edi-tors, Progress in Speech Synthesis, pages 77?89.Springer, New York.Dan Gildea and Dan Jurafsky.
1995.
Automaticinduction of finite state transducers for simplephonological rules.
In Proc.
of the 33rd AnnualMeeting of the Association for ComputationalLinguistics, pages 9?15.Ronald M. Kaplan and Martin Kay.
1994.
Regularmodels of phonological rule systems.
Computa-tional Linguistics, 20(3):331?378.George Anton Kiraz.
1999.
Compressed storageof sparse finite-state transducers.
In Proc.
of the1999 Workshop on Implementing Automata, Pots-dam, Germany.
?ric Laporte.
1997.
Rational transductions for pho-netic conversion and phonology.
In EmmanuelRoche and Yves Schabes, editors, Finite-StateLanguage Processing, chapter 14, pages 407?430.
MIT Press, Cambridge.Robert Luk and Robert Damper.
1996.
Stochas-tic phonographic transduction for English.
Com-puter Speech and Language, 10:133?153.Corey Andrew Miller.
1998.
Pronunciation Model-ing in Speech Synthesis.
Ph.D. thesis, Universityof Pennsylvania.Mehryar Mohri and Richard Sproat.
1996.
An ef-ficient compiler for weighted rewrite rules.
InProc.
of the 34th Annual Meeting of the Associ-ation for Computational Linguistics, pages 231?238.Mehryar Mohri, Fernando Pereira, and Michael Ri-ley.
1996.
Weighted automata in text and speechprocessing.
In Extended Finite State Models ofLanguage: Proc.
of the ECAI ?96 Workshop,pages 46?50.Mehryar Mohri, Fernando Pereira, and Michael Ri-ley.
2000.
The design principles of a weightedfinite-state transducer library.
Theoretical Com-puter Science, 231(1):17?32.Jos?
Oncina, Pedro Garc?a, and Enrique Vi-dal.
1993.
Learning subsequential transducersfor pattern recognition and interpretation tasks.IEEE Transactions on Pattern Analysis and Ma-chine Intelligence, 15(5):448?458.J.
R. Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann, San Mateo, CA.Michael D. Riley.
1991.
A statistical model forgenerating pronunciation networks.
In Proc.of the International Conference on Acoustics,Speech, and Signal Processing, pages 737?740.David B. Searls and Kevin P. Murphy.
1995.Automata-theoretic models of mutation andalignment.
In International Conference on Intel-ligent Systems in Molecular Biology, pages 341?349.T.
J. Sejnowski and C. R. Rosenberg.
1987.
Paral-lel networks that learn to pronounce English text.Complex Systems, 1:145?168.Richard Sproat and Michael Riley.
1996.
Compila-tion of weighted finite-state transducers from de-cision trees.
In Proc.
of the 34th Annual Meetingof the Association for Computational Linguistics,pages 215?222.Richard Sproat, Bernd M?bius, Kazuaki Maeda,and Evelyne Tzoukermann.
1998.
Multilingualtext analysis.
In (Sproat, 1998), chapter 3, pages31?87.Richard Sproat, editor.
1998.
Multilingual Text-to-Speech Synthesis: The Bell Labs Approach.Kluwer, Dordrecht.Richard Sproat.
2000.
A Computational Theoryof Writing Systems.
Cambridge University Press,Cambridge.
