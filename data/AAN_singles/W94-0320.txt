The Role of Cognit ive Model ing in AchievingCommunicat ive IntentionsMar i lyn  A .
Wa lker*M i tsub ish i  E lec t r i c  Research  Laborator ies201 i B roadwayCambr idge ,  MA 02139USAwalk~r~merl, comAbst rac tA discourse planner for (task-oriented) ialogue mustbe able to make choices about whether elevant, butoptional information (for example, the "satellites" inan RST-based planner) Should be communicated.
Weclaim that effective text planners must explicitly modelaspects of the Hearer's cognitive state, such as what thehearer is attending to and what inferences the hearercan draw, in ord@r to make these choices.
We arguethat a mere representation f the Hearer's knowledge isinadequate.
We support his claim by (1) an analysisof naturally occurring dialogue, and (2) by simulatingthe generation of discourses in a situation in which wecan vary the cognitive parameters of the hearer.
Ourresults how that modeling cognitive state can lead tomore effective discourses (measured with respect o asimple task).1 In t roduct ionText planning is the task for a speaker (S) of decid-ing what information to :communicate o a hearer (H)and how and when to communicate it.
Over the lastfew years a consensus has emerged that the text plan-ning task should be formulated in terms of commu-nicative goals or intentions \[19, 25, 23, 16\].
Consider,for example, the RST-based planners developed at ISI\[13, 21, 14\].
These planners use the discourse relationsproposed by Rhetorical S'tructure Theory (RST) \[18\] asplan operators, by interpreting the requirements ontherelated segments as preconditions, and the resultant ef-fect of the discourse relation as a postcondition i atraditional AI planning architecture.Two types (at least) of discourse relations have beenidentified in the literature.
A SUBJECT-MATTER rela-tion \[18\] or SEMANTIC relation \[14\] simply reflects arelation that exists independently in the world, such ascausation.
Each subject-matter relation can be seen asa rhetorical strategy for the linguistic realization of a*Walker was partially funded by ARO grant DAAL03-89-C0031PRI and DARPA grant N00014-90-J-1863 at theUniversity of Pennsylvania and by Hewlett Packard, U.K.t Rambow was supported by NATO on a NATO/NSFpostdoctoral fellowship in France.Owen Rambow tUn ivers i t4  Par i s  7 and  CoGenTex ,  Inc .TALANA,  UFR L ingu is t ique ,  Case  70032, P lace  Juss ieu75251 Par i s  Cedex  05, F rancerainbow?linguist, j ussieu, frrange of communicative intentions \[22\].
A PRESENTA-TIONAL RELATION \[18\] or INTERPERSONAL relation \[14\]holds between two discourse segments such that the jux-taposition increases H's STRENGTH of belief, desire, orintention.
Each presentational relation maps directlyto a communicative intention.
Examples of presenta-tional relations include the MOTIVATION relation, whichincreases H's desire to perform an action, hopefully per-suading H to form an intention to do the action.Both subject-matter and presentational relations re-late two clauses: (1) the NUCLEUS which realizes themain point; and (2) the SATELLITE which is auxiliaryoptional information.
For example in the MOTIVATIONrelation shown in figure 1, the SATELLITE is the beliefwhich provides motivation to do the action realized bythe proposal or suggestion i  the NI;CLEUS.
Since theSATELLITE information may or may not be realized, pre-vious text planners have run in either verbose or tersemode, in which either all or no satellite information isrealized \[22\].If an approach to text planning based on the notionof communicative intention is to succeed, it requiresan appropriate representation f communicative goals,and of all mental states required for reasoning aboutthese goals.
This is especially true in the case of pre-sentational relations.
We can immediately observe thatsince such relations affect he degree of strength of H'sbelief, desire of intention, we need a gradual representa-tion of mental attitudes.
To our knowledge, no currenttext planner uses such a gradual representation.
Sec-ond, it has been widely assumed that a model of whatthe hearer knows determines exactly when to includeoptional information i verbose mode: include optionalinformation unless the hearer knows it.
However, in ouranalysis of a corpus of 55 naturally-occurring dialogues,information that the hearer knew was frequently real-ized \[35\].
Consider the following short natural dialogue,part of a discussion about which Indian restaurant togo to for lunch:(1) a.
Listen to Ramesh.b.
He's Indian.Clearly, S wants to MOTIVATE H to accept his pro-posal with (lb).
However, in this situation all of the dis-1717th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994course participants already knew that Ramesh was In-dian.
We hypothesize that example (1) shows that thereare cognitive processing motivations for S's choice to in-clude information that is already known to the hearer,such as (lb), and that a model of H's cognitive pro-cesses are required for a text planner to appropriatelydecide when to include optional information.The remainder of this paper is structured as follow.We start out by describing in more detail the prob-lem facing text planners based on communicative goals(Section 2).
In Section 3 we briefly review cognitivetheories of deliberation and inference and relate theseto an account of working memory.
Next, in Section 4 wepresent he Design-World experimental environment, inwhich we embed our cognitive model.
In Section 5, wepresent some examples of modeling experiments thatsuggest what sort of information S must access in orderto generate fficient discourse.
Finally, in Section 6 webriefly discuss possible implications for text planningarchitectures.2 Ach iev ing  Communicat ive  Goa lsIn this paper, we focus on presentational relations, andwe use the MOTIVATION relation as a prototypical pre-sentational discourse relation to illustrate our points.The MOTIVATION relation, whose effect is to increaseH's desire to perform an action, is shown in Figure 1.We will call the nucleus of MOTIVATION the PROPOSAL,and any information that can serve as the satellite ofMOTIVATION we will call a WAR.RANT.What sort of representation is needed in order to useMOTIVATION for discourse planning?
The effect of pre-sentational relations is always to increase H's belief, de-sire, or intention.
Thus we will need (in the case ofMOTIVATION) some sort of representation of degree ofdesire.
In a first attempt at using MOTIVATION, we willuse utility theory \[6\] and simply associate utilities withproposed actions.
Under this view, an agent's trengthof desire to perform an action is the utility he or she be-lieves performing the action will yield, where "utility"is a quantifiable variable.
In section 6 we will discussthe limitations of this approach.However, even though utility theory can be used asthe theoretical underpinning of the MOTIVATION rela-tion, it will not in general be sufficient because it doesnot take into account he way in which H's beliefs in-teract with his attentional state, and the way that H'scognitive limitations interact with the demands of thetask.Consider the following scenario.
An agent S wants anagent H to accept a proposal P. In the situation where Halways deliberates and H knows of options which com-pete with proposal P, H cannot decide whether to ac-cept P without a warrant.
1 Previous work has assumed1Elsewhere we consider scenarios in which H always ac-cepts S's proposal without a warrant and in which H neverknows of competing options to P \[36\].that the warrant can be omitted if it is already believedby H. Presumably the speaker in (2) will not say It'sshorter if she believes that the hearer knows that theWalnut St. route was shorter.
(2) a.
Let's walk along Walnut St.b.
It's shorter.However, consider again (1), repeated here as (3):(3) a.
Listen to l:tamesh.b.
He's Indian.The warrant in (3b) was included despite the factthat it was common knowledge among the conversants.
2Our hypothesis i that 3 shows that speakers distinguishbetween information that H knows and information thatis salient for H \[28\].
Thus even if H knows a warrantfor adopting S's proposal, if the warrant is not SALIENTfor H, then S may choose to include it with a proposal.We define SALIENT as available in current WorkingMemory, referred to below as Attention/Working Mem-ory or AWM.
A model of the hearer H's attentionalstate will distinguish between those discourse entitiesand beliefs which are currently available in workingmemory, and thus salient, and those that are not.
Insection 3, we introduce an operationalization f AWMand discuss how S can model what is salient for H.When a warrant is not SALIENT, H must either inferthe warrant information, or retrieve it from long termmemory, or obtain it from an external source in order toevaluate S's proposal.
Thus S's communicative choiceas to whether to include the warrant satellite may de-pend on S's model of H's attentional state.
Further-more, it is possible that, even though the warrant isnot salient, merely a trivial processing effort is requiredto retrieve it, so that it is not worth saying.
Anotherpossibility is that processing the warrant utterance re-quires effort that can be traded off against other pro-cesses such as retrieval and inference.
In other words,S may decide that it is easier just to say the warrantrather than require H to infer or retrieve it.
We willcall a text planning strategy that always includes thewarrant satellite the Explicit-Warrant strategy.We see that in addition to S modeling H's knowledge,H's attentional state and expectations about other as-pects of H's cognitive processes may also influence S'stext planning decisions, and S cannot simply representH's beliefs as a set of pairs of propositions and associ-ated utility.
3 In sum, the choice is hypothesized to de-pend on cognitive properties of H, e.g.
what H knows,H's attentional state, and H's processing capabilities, aswell as properties of the task and the communicationchannel.2After inferring the intended relation the hearer stillmust decide whether s/he believes that Indians know of goodIndian restaurants \[38\].3How S would have access to the necessary informationis a separate issue, briefly discussed in section 6.1727th International Generation Workshop ?
Kennebunkport, Maine - June 21-24, 1994relation name:constraints on Nucleus:constraints on Satellite:constraints on theNucleus + Satellite combination:the effect:MOTIVATIONpresents an action in which H is the actorunrealized with respect o the context of N(a proposal in our terminology)noneH's comprehending the Satellite increases H's desire toperform action presented in the NucleusH's desire to perform action presented in the Nucleus is increasedFigure 1: RST definition of Motivation RelationIn this paper, we explore some cognitive issues in-volved in planning to include satellite information foundin RST presentational' relations and the representa-tional demands that arise for text planning tasks.
Wewill argue that S must :model H's cognitive state in amuch more detailed manner than previously assumedand put forth a proposal about how S might access theinformation required in order to do so.
In order toprovide evidence for our claim, we will use the cogni-tive modeling methodology developed in \[35\], in whichcommunicative strategies on the part of S can be repre-sented and their effects can be empirically tested.
Thisarchitecture allows us to identify parameters in H's cog-nitive state that affect S's communicative d cisions andtherefore must be mod@led.
The simulation/modelingenvironment is called Design-World.3 Modeling Cognitive LimitsIn Section 2 we proposed some cognitive factors, mo-tivated by proposals in naturally occurring dialogue,that may provide limits on whether agents can opti-mally deliberate proposed actions or make inferences.We hypothesized that these factors will determine whenExplicit-Warrant is an effective strategy.
Here webriefly present a way of cognitively modeling agents'limited attention and the relationship of limited atten-tion to deliberation and inference.It is well known that human agents have limited at-tentional capacity \[20\] and it has been argued that lim-ited attention plays a major role in theoretical and sci-entific reasoning \[29, 15,!
32\], ie.
in deduction, and be-lief and intention deliberation.
We hypothesized thatexample 2 shows that a warrant must be SALIENT forboth agents in order to be used in deliberation, i.e.
for itto motivate H effectivelyl This fits with the psycholog-ical theories mentioned above, that only salient beliefsare used in deliberation and inference.In Design-World, salience is modeled by the AWMmodel, adapted from \[17\].
While the AWM model is ex-tremely simple, Landauer shows that it can be parame-terized to fit many empirical results on human memoryand learning \[2\].
AWM consists of a three dimensionalspace in which propositions acquired from perceivingthe world are stored in chronological sequence accord-ing to the location of a moving memory pointer.
Thesequence of memory loci used for storage constitutes arandom walk through memory with each locus a fixeddistance from the previous one.
If items are encoun-tered multiple times, they are stored multiple times \[12\].When an agent retrieves items from memory, searchstarts from the current pointer location and spreads outin a spherical fashion.
Search is restricted to a partic-ular search radius: radius is defined in Hamming dis-tance.
For example if the current memory pointer locusis (0 0 0), the loci distance 1 away would be (0 1 0) (0-10) (0 0 1) (0 0-1)  (-1 0 0) (10  0).
The actual lo-cations are calculated modulo the memory size.
Thelimit on the search radius defines the capacity of atten-tion/working memory and hence defines which storedbeliefs and intentions are SALIENT.The radius of the search sphere in the AWM modelis used as the parameter for Design-World agents'resource-bound on attentional capacity.
In the exper-iments below, memory is 16x16x16 and the radius pa-rameter varies between 1 and 16.
Agents with an AWMof 1 have access to 7 loci, and since propositions arestored sparsely, they only remember the last few propo-sitions that they acquired from perception.
Agents withan AWM of 16 can access everything they know.
4The AWM model also gives us a way to measure (1)the number of retrievals from memory in terms of thenumber of locations earched to find a proposition; (2)the number of inferences that the agents make as theymeans-end reason and draw content-based inferences;and (3) the number of messages that the agents end toone another as they carry out the dialogue.
The amountof effort required for each of these cognitive processesare parameters of the model.
These cost parameterssupport modeling various cognitive or text planning ar-chitectures, e.g.
varying the cost of retrieval models4The size of memory was determined as adequate forproducing the desired level of variation in the current askacross all the experimental variables, while still making itpossible to run a large number of simulations involvingagents with access to all of their memory in a reasonableamount of time.
In order to use the AWM model in a differ-ent task," the experimenter might want to explore differentsizes for memory.1737th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994different assumptions about memory.
Since these cog-nitive processes are the primitives involved in text plan-ning, this framework can be used to model many differ-ent architectures rather than the results being specificto a particular text-planning architecture.The retrieval parameter alone allows us to modelmany different assumptions about memory.
For exam-ple, if retrieval is free then all items in working memoryare instantly accessible, as they would be if they werestored in registers with fast parallel access.
If AWMis set to 16, but retrieval isn't free, the model approxi-mates slow spreading activation that is quite effortful,yet the agent still has the ability to access all of mem-ory, given enough time.
If AWM is set lower than 16and retrieval isn't free, then we model slow spreadingactivation with a timeout when effort exceeds a certainamount, so that an agent does not have the ability toaccess all of memory.
Thus the AWM parameter sup-ports a distinction between an agent's ability to accessall the information stored in its memory, and the effortinvolved in doing so.It does not make sense to fix absolute values for theretrieval, inference and communication cost parame-ters in relation to human processing.
However, Design-World supports exploring issues about the relative costsof various processes.
These relative costs might vary de-pending on the language that the agents are communi-cating with, properties of the communication channel,how smart the agents are, how much time they have,and what the demands of the task are \[24\].
Below wevary the relative cost of communication and retrieval.The advantages of the AWM model is that it hasbeen shown to reproduce, in simulation, many resultson human memory and learning.
Because search startsfrom the current pointer location, items that have beenstored most recently are more likely to be retrieved,predicting recency effects \[2\].
Because items that arestored in multiple locations are more likely to be re-trieved, the model predicts frequency effects \[17\].
Be-cause items are stored in chronological sequence, themodel produces natural associativity effects \[1\].The overall agent architecture is modeled on theIRMA agent architecture \[3\] with the addition of AWM.See figure 2.
As figure 2 shows, AWM interacts withother processing because deliberation and means:endreasoning only operate on salient beliefs.
This meansthat limits in AWM produces a concomitant inferen-tial limitation, i.e.
if a belief is not salient it cannot beused in deliberation or means-end-reasoning.
Thus mis-takes that agents make in their planning process have aplausible cognitive basis.
Agents can both fail to accessa belief that would allow them to produce an optimalplan, as well as make a mistake in planning if a beliefabout how the world has changed as a result of planningis not salient.
Depending on the preceding discourse,and the agent's attentional capacity, the propositionsthat an agent knows may or may not be salient when aproposal is made \[28\].WI rrE oN/woRxING IIo= - - - J - - -  , \ /?
/optionsFigure 2: Design-World version of the IRMA Agent Ar-chitecture for Resource-Bounded Agents with LimitedAttention (AWM)4 Experimental Environment:Design-WorldDesign-World is an experimental environment for test-ing the relationship between ways of realizing com-municative intentions and agents' cognitive capabili-ties, similar to the single-agent TileWorld simulationenvironment \[26, 11\].
Design-World agents can beparametrized as to discourse strategy, e.g.
whether touse the Explicit-Warrant strategy, and the effects ofthis strategy can be measured against a range of cog-nitive and task parameters.
In section 4.1, we describethe Design-World omain and task.
In section 4.2, wedescribe two alternate discourse strategies.
In section4.3, we discuss how performance is evaluated and com-pared.
Finally, in section 5 we present he experimentalresults.4.1 Des ign  Wor ld  Domain  and  TaskThe Design-World task requires two agents to carry outa dialogue in order to negotiate an agreement on the de-sign of the floor plan of a two room house \[30, 39\].
TheDESIGN-IIOUSE plan requires the agents to agree on howto DESIGN-R.OOM-1 and DESIGN-R.OOM-2.
At the begin-ning of the simulation, both agents know the structureof the DESIGN-IIOUSE plan.
Each agent has 12 itemsof furniture that can be used in the plan, with utilityscores ranging from 10 to 56.
A potential final designplan negotiated via a (simulated) dialogue is shown infigure 3.1747th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994KEY:F=FUCHSIAG = GREENP= PURPLE56IN 155( )III)11)FJI54DI52 53ROOM#1 ROOM#2DESIGN WORLD COLLABORATIVE PLAN: 4M p0intsFigure 3: One Final State for Design-World StandardTask: Represents the Collaborative Plan Achieved bythe Dialogue, 434-pointsNegotiating an agreement consists of a cycle in which:(1) individual agents perform means-end reasoningabout OPTIONS to use various furniture pieces that theyhave in the floor plan; (2) individual agents deliberateabout which options are preferable; (3) then agents usethe OPTIONS identified as the content of PROPOSALS toother agents to PUT a piece of furniture into one of therooms; (4) then these proposals are ACCEPTED or RE-JECTED by the other agent, or acceptance/rejection ispostponed by a CLARIFICATION.Dialogue (4) illustrates agents' communication forpart of designing room-!
: Both the artificial languagethat the agents communicate with and a gloss generatedfrom that language in ifalics are shown: ~(4) 1: BILL: Let's put the green rug in the study.
(propose agent-bill agent-kim option-10: put-act(agent-bill green rug room-l))2: KIM: Then, let's put the green lamp there.
(propose agent-kim, agent-bill option-33: put-act(agent-ldm green lamp room-l))3: BILL: Next, let's put the green couch in the study.
(propose agent-bill agent-kim option-45: put-act(agent-bill green couch room-l))4: KIM: No, instead let's put the purple couch in thestudy.
(reject agent-kim agent-bill option-56: put-act (agent-kim purple couch room-l))On receiving a proposal, an agent deliberates whetherto ACCEPT or r~EJECT the proposal \[6\].
Each furniture5The generation of the gloss was not a focus of this studyand was done via adhoc methods.item has a value that contributes to an evaluation ofthe final plan.
The values on the furniture items rangefrom 10 to 56, and both agents' furniture items rangeover these values.
Agents know the values of all thefurniture items at the beginning of the dialogue.
Thevalues of the furniture items are used to MOTIVATE theagents to ACCEPT a proposal, as well as providing away of objectively evaluating agents' performance.
Inother words, we define each potential action to have anassociated SCORE; agents can evaluate whether theirdesire to do an action is increased by comparing thescore of the proposed action with other actions thatthey know about.For example, at the beginning of the dialogue, Agent-Kim has stored in memory the proposition that (scoregreen-rug 56).
When she receives Bill's proposal asshown in (4-1), she evaluates that proposal in order todecide whether to accept or reject it.
As part of evalu-ating the proposal she will attempt o retrieve the scoreproposition stored earlier in memory.
Thus the proposi-tions about the scores of furniture items are VCARJ1.ANTSfor supporting deliberation.Agents REJECT a proposal if deliberation leads themto believe that they know of a better option.
For exam-ple, in (4-4) Kim rejects the proposal in (4-3), for pur-suing option-45, and proposes option-56 instead.
Theform of the rejection as a counter-proposal is based onobservations about how rejection is communicated innaturally-occurring dialogue as codified in the GOLLAB-OR.ATIVE PLANNING PRINCIPLES \[37\].Proposals i and 2 are inferred to be implicitly AC-CEPTED because they are not rejected \[37\].
If a pro-posal is ACCEPTED, either implicitly or explicitly, thenthe option that was the content of the proposal becomesa mutual intention that contributes to the final designplan \[27, 34, 30\].The model of AWM discussed above plays a criticalrole in determining agents' performance.
Rememberthat only salient beliefs can be used in means-end rea-soning and deliberation, so that if the warrant for aproposal isnot salient, the agent cannot properly eval-uate a proposal.4.2 Vary ing  D iscourse  S t ra teg iesAgents are parametrized for different discourse strate-gies by placing different expansions of discourse plans intheir plan libraries.
In Design-World the only discourseplans required are plans for PROPOSAL, REJECTION,ACCEPTANCE, CLAR.IFICATION, OPENING and CLOSING.The only variations discussed here are variations intheexpansions of PROPOSALS.The All-Implicit strategy is an expansion of a dis-course plan to make a PROPOSAL, in which a PROPOSALdecomposes trivially to the communicative act of Pn.o-POSE.
In dialogue (4), both Design-World agents com-municate using the All-lmplicit strategy, and propos-als are expanded to the PROPOSE communicative actsshown in 1, 2, and 3 in dialogue (4).
The All-Implicit1757th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994strategy never includes warrants in proposals, leavingit up to the other agent to retrieve them from memory.The Explicit-Warrant strategy expands the PRo-POSAL discourse act to be a WAR.R.ANT followed by aPROPOSE utterance \[33\].
6 Since agents already knowthe point values for pieces of furniture, warrants are al-ways optional in the experiments here.
In RST terms,an agent with the Explicit-Warrant strategy alwayschooses to MOTIVATE every proposal.
For example (5-1)is a W'AR.R.ANT for the proposal in (5-2):(5) 1: TED: Putt ing in the green rug is worth 56.
(say agent-ted agent-ben bel-10: score (option-10:put-act (agent-ted green rug room-l) 56))2: TED: So, let's put the green rug in the study.
(propose agent-ted agent-ben option-10: put-act(agent-ted green rug room-l))3: BEN: Putt ing in the green lamp is worth 55.
(say agent-ben agent-ted bel-34: score (option-33:put-act (agent-ben green lamp room-l) 55))4: BEN: So, let's put the green lamp in the study.
(propose agent-ben agent-ted option-33: put-act(agent-ben green lamp room-l))The fact that the green rug is worth 56 points is mo-tivation for adopting the intention of putting the greenrug in the study.
Whether it is good motivation de-pends on what other options the agent knows about andwhat their utilities are.
The Explicit-Warrant strategymodels naturally occurring examples uch as those in2 because the score information used by the hearer todeliberate whether to accept or reject the proposal isalready mutually believed.4.3 Eva luat ing  Per fo rmanceRemember that we incorporate cognitive modeling intoDesign-World so that attentional capacity and the costof various cognitive processes are parameters.
To eval-uate PERFORMANCE,  we compare the Explicit-Warrantstrategy with the All-Implicit strategy while we varyagents' attentional capacity, and the cost of retrieval,inference and communication.
Evaluation of the result-ing DESIGN-IIOUSE plan is parametrized by (1) COMM-COST: cost of sending a message; (2) INFCOST: costof inference; and (3) I~.ETCOST: cost of retrieval frommemory:PERFOllMANCE = Task Defined I~AW SCOaE- (COMMCOST ?
total messages)- (INFCOST ?
total inferences)- (I~.ETCOST ?
total retrievals)I~.AW SCOaE is task specific: in the Standard taskwe simply summarize the point values of the furniturepieces in each PUT-ACT in the final design.6The ordering of these two acts as given lets us have asimple control regime for processing utterances.
The reverseordering would require the agent to check whether it hasmore messages before processing the current message.We simulate 100 dialogues at each parameter set-ting for each strategy.
Because the AWM model isprobabilistic, the agents do not perform identically oneach trial, and their performance over the 100 dialoguesdefines a performance distribution.
In order to com-pare two strategies, we test whether the differences inthe performance distributions are significant, using theKolmogorov-Srnirnov (KS) two sample test \[31\].A strategy A is BENEFICIAL aS compared to a strat-egy B, for a set of fixed parameter settings, if thedifference in distributions using the Kolmogorov-Smirnov two sample test is significant at p < .05,in the positive direction, for two or more AWMsettings.A strategy is DETRIMENTAL if the differences go inthe negative direction.
Strategies may be neither BEN-EFICIAL or DETRIMENTAL,  there may be no differencebetween two strategies.5 Exper imenta l  Resu l ts  on  Prov id ingMot ivat ionThis section discusses a few experimental results on the"Explicit-Warrant discourse strategy, which we comparewith the All-Implicit strategy.
Here we simply test theeffect of whether the warrant is salient or not, whetherthere is any processing effort associated with retrievingthe warrant from long term memory, and whether thecost of processing an utterance is high.Differences in performance between the Explicit-Warrant strategy and the All-Implicit strategy areshown via a DIFFERENCE PLOT such as figure 4.
In fig-ure 4 performance differences are plotted on the Y-axisand AWM settings are shown on the X-axis.
If the plotis above the dotted line for 2 or more AWM settings,then the Explicit-Warrant s rategy may be BENEFICIAL.Each point represents the difference in the means of 100runs of each strategy at a particular AWM setting.5.1 Exp l i c i t  Warrant  reduces  Ret r ieva lsDialogues in which one or both agents use the Explicit-Warrant strategy are more efficient when retrieval hasa cost.Figure 4 shows that the Explicit-Warrant strategy isdetrimental at AWM of 3,4,5 for the Standard task, incomparison with the All-Implicit strategy, if retrievalfrom memory is free (KS 3,4,5 > .19, p < .05).
Thisis because making the warrant salient displaces infor-mation about other pieces when agents are attention-limited.However, Figure 5 shows that Explicit-Warrant isbeneficial when retrieval has an associated processingcost.
By AWM values of 3, performance with Explicit-Warrant is better than All-Implicit because the war-rants intended to motivate the hearer and used by thehearer in deliberation are made salient with each pro-posal (KS for AWM of 3 and above > .23, p < .01).
AtAWM parameter settings of 16, where agents have the1767th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994cost - ted-benb i l l - k imC:= 1 , I=  1 , F I=Ooo o. .
.
.
.
, ,, ,~0 2 .4, 8 10  1 1 1A f fent lon /Work lng  MemoryFigure 4: If Retrieval is Free, Explicit-Warrant is detri-mental at AWM of 3,4,5: Strategy 1 of two Explicit-Warrant agents and strategy 2 of two All-Implicitagents: Task = Standard, commcost = 1, infcost =1, retcost -- 0ability to search a huge belief space for beliefs to be usedas warrants, the saving in processing time is substan-tial.
Again at the lowest AWM settings, the strategyis not beneficial because it displaces information aboutother pieces from AWM, However in Figure 5, in con-trast with Figure 4, retrieval has an associated cost.Thus the savings in retrieval balance out with the lossof raw score so that the strategy is not DETRIMENTAL.5.2 Explicit Warrant is detrimental ifCommunication is ExpensiveFinally we can amplify the results shown in Figure 4 bypositing that in addition to there being no processingeffort for retrieving from memory, processing the ad-ditional warrant utterance requires a lot of processingeffort.
Figure 6 shows that if communication cost is 10,and inference and retrieval are free, then the Explicit-Warrant strategy is DETR.IMENTAL (KS for AWM 1 to5 > .23, p< .01).
This isl because the Explicit-Warrantstrategy increases the number of utterances required toperform the task; it doubles the number of messagesin every proposal.
If communication is expensive com-pared to retrieval, processing additional warrant utter-ances is highly detrimental if there would be no effortinvolved in reirieving them, i.e., if they are essentiallyalready salient.cost  - ted -ben  b i l l - k im C= 1 , I = 1 , R = 0 .01$?Yo ~~_~._  o_o /?
.
~ .
.
.
.
.
.
.
.
.
.
.I I I I I I t 1162 4 6 8 10  12  1.4,Attention/WorkinG MemoryFigure 5: Retrieval costs: Strategy 1 is two Explicit-Warrant agents and strategy 2 is two All-Implicitagents: Task = Standard, commcost = 1, infcost =1, retcost = .016 Imp l i ca t ions  for  Text  P lann ingThe experiments reported in the previous ection showthat there is a direct relation between H's attentionalstate and the advisability of including warrants in a textplan.
There are two ways in which we have modeleddifferent aspects of H's attentional state in the experi-ments reported in the previous sections: we have var-ied the cost of retrieval, and we have varied the size ofAWM.
We can think of H's attentional state as compris-ing a (small) active working memory, and a larger long-term memory.
We vary whether an agent has the abilityto retrieve an item by varying the radius of AWM.
Wevary the amount of effor~ involved in retrieving an itemby varying the cost of retrieval \[17, 24, 2\].
If a war-rant for the proposal is in short-term memory and canbe accessed virtually cost-free, then figure 4 shows thatgenerating the warrant explicitly can actually be detri-mental, since it can displace other information.
The ef-fect is further magnified if communication is very costly,as shown in figure 6.
(Cost of communication may byincreased by a large number of factors, such as the lin-guistic complexity of the generated message, the factthat H is not fully competent in the language of com-munication, or noise in the channel of communication.
)Thus, if S knows that information that can serve as awarrant is salient to H, then no warrant should be gen-erated.
On the other hand, if a cost is in fact associatedwith retrieval, as in the experiment reported in figure 5,1777th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994cost  - ted -ben  b i l l - k i rn  C= 10 ,  I = 0 ,  R = 0m0 2 4 6 8 10 1 14  1Art  ent ion /VVork ing  MemoryFigure 6: If Communication is Expensive: Communica-tion costs can dominate other costs in dialogues.
Strat-egy 1 is two Explicit-Warrant agents and strategy 2 istwo All-Implicit agents: Task = Standard, commcost =10, infcost = 0, retcost = 0then we can see that generating a warrant is beneficial,especially as the size of AWM increases and agents havethe ability to access all of long term memory.We conclude that for a text planner to decide whetheror not to communicate certain non-essential informa-tion, such as a warrant as part of a MOTIVATE relation,depends not just on the effect of the relation (whichmust of course match the discourse goal), but also onthe attentional state of H, and on the other factors suchas the cost of communication.
A maximally efficienttext planner will need to have access to:?
a model of H's attentional state;?
an algorithm that, given the attentional state modeland additional parameters uch as the costs ofcommunication and retrieval determines whether Hknows accessible information which can serve as awarrant.Here "accessible information" means either that theinformation is already salient or that it can be retrievedat a reasonable cost, given the costs of communicationand retrieval.
If we assume that the algorithm definesa binary predicate NOT-ACCESSIBLE ,  we can for-malize the RST relation MOTIVATE as a plan operatorMot ivat ion  as given in Figure 7.
The format followsthe format of the plan operators given in \[22\], exceptthat, for simplicity, we conflate the intentional and therhetorical evels/  This plan operator is of course onlymeant to be suggestive, and we are not committed toany details.Of course, procedure NOT-ACCESSIBLE  cru-cially relies on a proper model of H's attentional stateand on an algorithm that accesses it.
We intend to in-vestigate these issues in future work, but sketch somepossible solutions here.
An obvious candidate for themodel is the AWM model used in the simulations it-self.
(In fact, it is quite plausible that speakers use theirown attentional state as a model for thai  of the hearer.
)The algorithm could then be defined very straightfor-wardly in terms of a three-dimensional boolean matrix,indexed on distance in memory, communication cost,and retrieval cost.
The value for a given triple indicateswhether or not information stored at this distance is ac-cessible.
The values in the table are determined usingthe simulation environment.
Presumably, this processweakly corresponds to the acquisition of proper textplanning strategies by human agents.While an obvious candidate for the model of H's at-tentional state is the AWM model itself, certain aspectsof this model do not exactly match some widely believedand intuitively motivated observations aboUt hierarchi-cal discourse structure \[10, 18\].
However, hierarchicalstructure interacts with attentional state in ways thathave not been fully explored in the literature to date.
Inparticular, if a discourse segment consisting of a nucleuswith a hierarchically complex satellite that is extremelylong, then a further satellite to the same nucleus maywell require repetition of the nucleus \[35\].
Neither RSTnor the model of \[10\] accounts for such effects.
We con-clude that it is not a priori obvious that hierarchicalstructure contradicts our model.
We will investigatethis issue further.Throughout his paper, we have used the MOTIVATErelation in order to motivate our claims.
However, simi-lar observations apply to other presentational relations,such as BACKGROUND, or I~VIDENCE as shown in 5: s(6) a. Clinton has to take a stand on abortion rightsfor poor women.b.
He's the president.Here 6b is already known to the discourse partici-pants, but saying it makes it salient.
The fact thatit is already known makes S's attempt to convince Hof 6a more likely to succeed.
A discussion of the EVI-DENCE relation, however, is complicated by the need tofind a proper representation f the degree of strength ofZMoore and Paris argue that for presentational relations(such as MOTIVATE), there is a one-to-one mapping betweenintentional and rhetorical structure.
Therefore, conflatingthem is theoretically justified.SWe also believe that whether a known proposition issalient is an issue for supporting content-based inferences,and thus cognitive modeling may be required for text plan-ning of subject-matter relations as well.1787th International Generation Workshop.. Kennebunkport, Maine ?
June 21-24, 1994NAME:EFFECT;CONSTRAINTS:SATELLITENUCLEUS:MOTIVATION)(DESIRE ?hearer (DO ?hearer ?act) ?utility-act)(AND (AGENT ?act ?hearer))(UNREALIZED ?act)(NOT-ACCESSIBLE ?hearer (UTILITY ?act ?utility-act))(BEL ?hearer (UTILITY ?act ?utility-act))(BEL ?hearer (WANT ?speaker (DO ?hearer ?act)))Figure 7: The MOTIVATION plan operatorbelief, since utility theory is not appropriate as a repre-sentation of degree of belief \[9\].
In other work, we havedeveloped a version of Gallier's theory of belief revisionwhich takes into account he effect of limited workingmemory on agent's belief revision processes \[7, 8, 5, 35\].This theory could be used for the RST EVIDENCE rela-tion.However, the use of a simple evaluation function forthe representation f gradual strengths (of desire, belief,etc.)
is in itself problematic.
In this paper, we used thetheoretical construct of utility as the basis for degreeof desire for the MOTIVATION relation.
However, obser-vations of human dialogue show that there are manyevaluation functions in the real world that can be thebasis for the MOTIVATION relation.
Furthermore, theseevaluation functions are incomparable and competing,as shown by (7), asserted by a speaker while walking towork:(7) I don't like going down that way.It may be shorter, but I don't like it.The speaker's desire for an aesthetic environment onher walk has in this case overridden her desire for thefastest route to work.
However if she were late, theefficiency evaluation function might dominate.
In thereal world or in real text planning domains, the issueof multiple competing evaluation functions on poten-tial intended actions must be addressed.
Observe thatthis issue is crucially related to the proper theoreticaldiscussion of presentational relations.Finally, we would like to observe that there is ev-idence that the results presented here are domain-independent.
The task that the agents are performingin Design-World is a simple task without any complexconstraints, which we would expect to be a subcom-ponent of many other tasks.
The model of limited re-sources we used was cogtjitively based, but the cost pa-rameters allow us to model different agent architectures,and we explored the effects of different cost parameters.The Explicit-Warrant strategy is based on simple rela-tionships between different facts which we would expectto occur in any domain, i.e.
the fact that some beliefcan be used as a 'WAIl.RANT for accepting a proposalshould occur in almost tiny task.
Furthermore, our re-sults are confirmed by naturally occurring discourses ina wide variety of domains \[38, 4, 35\].7 ConclusionIn this paper, we have argued that a text planner thatis based on the notion of communicative intention andon plan operators that explictly represent such inten-tions must also incorporate a sophisticated model ofthe heater's attentional state, and the ability to usethis model in order to make decisions about whetheror not to include optional information (satellites of pre-sentational relations).
We have motivated this claimusing naturally occurring dialogues, and by experimen-tal results from a simulation environment which imple-ments a simple, but psychologically plausible model ofattentional state.
Future work includes extending theanalysis to the whole range of presentational relations,defining precisely a hearer model that can be used intext planning and an associated algorithm that can beused by the plan operators, and a theoretical investi-gation of the interaction between textual hierarchy andattentional state.References\[1\] J. R. Anderson and G. H. Bower.
Human Associa-tive Memory.
V.H.
Winston and Sons, 1973.\[2\] A. Baddeley.
Working Memory.
Oxford UniversityPress, 1986.\[3\] M. Bratman, D. Israel, and M. Pollack.
Plans andresource bounded practical reasoning.
Computa-tional Intelligence, 4:349-355, 1988.\[4\] A. Cawsey.
Planning interactive xplanations.
In-ternational Journal of Man.Machine Studies, 1992.\[5\] A. Cawsey, J. Galliers, S. Reece, and K. S. Jones.Automating the librarian: A fundamental ap-proach using belief revision.
TR-243, CambridgeComputer Laboratory, 1992.\[6\] J. Doyle.
Rationality and its roles in reasoning.Computational Intelligence, November 1992.\[7\] J. R. Galliers.
Belief revision and a theory of com-munication.
TR 193, University of Cambridge,Computer Laboratory, 1990.\[8\] J. R. Galliers.
Autonomous belief revision andcommunication.
In P. Gardenfors, editor, BeliefRevision, pages 220 - 246.
CUP, 1991.1797th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994\[9\] P. Gardenfors.
Knowledge in flux : modeling thedynamics of epistemic states.
MIT Press, 1988.\[10\] B.J.
Grosz and C. L. Sidner.
Attentions, intentionsand the structure of discourse.
Computational Lin-guistics, 12:175-204, 1986.\[11\] S. Hanks, M. E. Pollack, and P. R. Cohen.
Bench-marks, testbeds, controlled experimentation andthe design of agent architectures.
AI Magazine,December 1993.\[12\] D. L. Hintzmann and R. A.
Block.
Repetition andmemory: evidence for a multiple trace hypothesis.Journal of Experimental Psychology, 88:297-306,1971.\[13\] E. H. Hovy.
Planning coherent multisententialtext.
In Proc.
26th Annual Meeting of the ACL,Association of Computational Linguistics, pages.163-169, Buffalo, 1988.
ACL.\[14\] E. H. Hovy.
Automated iscourse generation usingdiscourse structure relations.
Artificial IntelligenceJournal, 63:341-385, 1993.\[15\] D. Kahnemem, P. Slovic, and A. Tversky.
Judg-ment under uncertainty : heuristics and biases.Cambridge University Press, 1982.\[16\] R. Kittredge, T. Korelsky, and O. Rambow.
On theneed for domain communication knowledge.
Com-putational Intelligence, 7(4):305-314, 1991.\[17\] T. K. Landauer.
Memory without organization:Properties of a model with random storage andundirected retrieval.
Cognitive Psychology, pages495-531, 1975.\[18\] W. Mann and S. Thompson.
Rhetorical structuretheory: Description and construction of text struc-tures.
In G. Kempen, editor, Natural LanguageGeneration, pages 83-96.
Martinus Nijhoff, 1987.\[19\] K. R. McKeown.
Discourse strategies for generat-ing natural language text.
Artificial Intelligence,27(1):1-42, September 1985.\[20\] G. A. Miller.
The magical number seven, plus orminus two: Some limits on our capacity for pro-cessing information.
Psychological Review, pages81-97, 1956.\[21\] J. D. Moore and C. L. Paris.
Planning text foradvisory dialogues.
In Proc.
27th Annual Meetingof the Association of Computational Linguistics,Vancouver, 1989.
ACL.\[22\] J. D. Moore and C. L. Paris.
Planning textfor advisory dialogues: Capturing intentional andrhetorical information.
Computational Linguistics,19(4), 1993.\[23\] J. D. Moore and M. E. Pollack.
A problem forrst: The need for multi-level discourse analysis.Computational Linguistics, 18(4), 1992.\[24\] D. A. Norman and D. G. Bobrow.
On data-limitedand resource-limited processes.
Cognitive Psychol-ogy, 7(1):44-6, 1975.\[25\] C. L. Paris.
Tailoring object descriptions to auser's level of expertise.
Computational Linguis-tics, 14(3):64-78, 1988.\[26\] M. E. Pollack and M. Ringuette.
Introducing theTileworld: Experimentally Evaluating Agent Ar-chitectures.
In AAAIgO, pages 183-189, 1990.\[27\] R. Power.
Mutual intention.
Journal for the The-ory of Social Behaviour, 14, 1984.\[28\] E. F. Prince.
Toward a taxonomy of given-newinformation.
In Radical Pragmatics, pages 223-255.
Academic Press, 1981.\[29\] L. Ross and C. A. Anderson.
Shortcomings in theattribution process: On the origins and mainte-nance of erroneous social assessments.
In Judgmentunder uncertainty : heuristics and biases.
Cam-bridge University Press, 1982.\[30\] C. Sidner.
Using discourse to negotiate in col-laborative activity: An artificial language.
AAAIWorkshop on Cooperation among HeterogeneousAgents, 1992.\[31\] S. Siegel.
Nonparametric Statistics for the Behav-ioral Sciences.
McGraw Hill, 1956.\[32\] M. Solomon.
Scientific rationality and human rea-soning.
Philosophy of Science, September 1992.\[33\] D. D. Suthers.
Sequencing explanations to enhancecommunicative functionality.
In Proceedings of the15th Annual Meeting of the Cognitive Science So-ciety, 1993.\[34\] M. A. Walker.
Redundancy in collaborative dia-logue.
In Fourteenth International Conference onComputational Linguistics, pages 345-351, 1992.\[35\] M. A. Walker.
Informational Redundancy and Re-source Bounds in Dialogue.
PhD thesis, Universityof Pennsylvania, 1993.\[36\] M. A. Walker.
Discourse and deliberation:testinga collaborative strategy.
In Coling 94, 1994.\[37\] M. A. Walker and S. Whittaker.
Mixed initiativein dialogue: An investigation into discourse seg-mentation.
In Proc.
28th Annual Meeting of theACL, page s 70-79, 1990.\[38\] B. Webber and A. Joshi.
Taking the initiative innatural language database interaction: Justifyingwhy.
In COLING84, pages 413-419, 1982.\[39\] S. Whittaker, E. Geelhoed, and E. Robinson.Shared workspaces: How do they work and whenare they useful?
IJMMS, 39:813-842, 1993.180
