Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 37?40,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsSafe In-vehicle Dialogue Using Learned Predictions of User UtterancesStaffan LarssonTalkamatic ABF?orsta L?anggatan 18413 28 G?oteborgSwedenstaffan@talkamatic.seFredrik KronlidTalkamatic ABF?orsta L?anggatan 18413 28 G?oteborgSwedenfredrik@talkamatic.sePontus W?arnest?alHalmstad UniversityBox 823301 18 HalmstadSwedenpontus.warnestal@hh.seAbstractWe present a multimodal in-vehicle dia-logue system which uses learned predic-tions of user answers to enable shorter,more efficient, and thus safer natural lan-guage dialogues.1 Background1.1 Driver DistractionDriver distraction is a common cause of accidents,and is often caused by the driver interacting withtechnologies such as mobile phones, media play-ers or navigation systems.
A study, commonlyreferred to as the ?100 car study?
(Neale et al.,2005) revealed that secondary task distraction isthe largest cause of driver inattention, and that thehandling of wireless devices is the most commonsecondary task.As interaction complexity in the car increasesdue to more advanced infotainment systems andsmartphones, drivers are often executing severaltasks in parallel to the primary task of driving.The increased functionality of these systems hasresulted in large hierarchical information architec-tures that prolong interaction time, thereby nega-tively affecting safety as well as user experience(Kern and Schmidt, 2009).1.2 Relation to state of the artState-of-the-art infotainment systems typically donot include user models at all.
Siri, available onthe Apple iPhone 4S and later models, has a staticuser model containing personal information ex-plicitly provided by the user (home address, etc.
).This information is used in voice interactions; forexample, given that the user has entered their fam-ily relations, phrases like ?Call my wife?
can beused.
A different approach is taken in GoogleNow, which dynamically learns user patterns fromobservations and presents unrequested informa-tion as ?cards?
on the screen.
However, GoogleNow does not attempt to integrate predictions intodialogue interaction.The work reported here explores the use ofadaptive user modeling in multimodal dialoguesystems.
User preferences and behaviour patternsare learnt from observations of user interactionswith the infotainment system and the context inwhich these interactions take place, and are usedproactively to predict user answers and thereby en-able shorter and more efficient interaction.
Theunderlying motivating assumption is that usingapps and services in an in-vehicle context inher-ently leads to distraction, and that reducing inter-action time will reduce driver distraction.1.3 TDMBased on Larsson (2002) and later work, Talka-matic AB has developed the Talkamatic DialogueManager (TDM).TDM provides a general interaction modelbased on interaction which are basic to human-human linguistic interaction, resulting in a highdegree of naturalness and flexibility which in-creases usability.
The model is domain-independent which means that dialogue behaviourcan be altered without touching application prop-erties and vice versa.
TDM also offers integratedmulti-modality which allows user to freely switchbetween modalities (Larsson et al., 2011).1.4 Grounding in TDMGrounding (Clark and Brennan, 1990) is, roughly,the process of making sure that dialogue partici-pants agree on what has been said so far and whatit meant.
TDM has an extensive model of ground-ing (Larsson, 2002).
It operates on different levels:?
Perception?
Semantic Understanding37?
Pragmatic Understanding?
AcceptanceSystem feedback (positive, negative and insome cases interrogative) can be generated on eachlevel:?
Examples: ?I didn?t hear?
?
negative percep-tion?
?To work, is that right??
?
interrogative se-mantic understanding?
?OK?
?
positive acceptance.2 Learning and ClassificationMany dialogue applications require the user to an-swer a number of questions.
To make dialogueshorter, we have extended TDM so that it tries topredict user answers on the basis of a user modellearned from observations of user behaviour.
Asan illustration, we use a road information appli-cation which tries to predict the user?s destina-tion and thereby eliminate the need to ask the userabout this.2.1 Learning MethodInitially, a range of learning methods requir-ing (N-gram, MDP, POMDP) were explored andevaluated, but the KNN (K-Nearest Neighbours)(Mitchell, 1997) was considered the best method.An important advantage is that KNN can learnfrom a relatively small set of observations.
Thisis in contrast to the MDP and POMDP (and toa lesser extent, N-gram) methods, which requirelarge amounts of data to generate useful behaviour.A potential drawback of KNN is that this modelcannot model sequences of user behaviours.2.2 Parameter SelectionOn the basis of user studies provided from theuser partner of the project, it was decided that themost important user model parameters was posi-tion, day of the week and hour of the day.
Thetraining data were simulated and correspond to thebehaviour of an archetypal persona provided bythe user partner in the project.2.3 Learning and ClassificationThe learning part of the system listens for a num-ber of events, such as ?start-car?, ?stop-car?
etc..From these events and information about cur-rent position, the time of the day and the day ofthe week, the system creates new data instances.The system thus learns how the user?s destinationvaries depending on these parameters.
A sampledataset is shown in Figure 1, where data pointsshow destinations of trips initiated at various timesof the week.When the dialogue manager requests a predic-tion of the destination, the KNN algorithm tries tofind the K data points closest to the present datapoint, and the top alternatives are returned to thedialogue manager together with confidence scoresindicating the reliability of the predictions.3 Integration of Classifications into TDM3.1 Grounding uncertain informationWe treat the information emanating from the usermodel as uncertain information about a (predicted)user utterance.
Hence, the same mechanisms usedfor grounding utterances have been adapted for in-tegrating user model data.3.2 Integrating Classifier OutputTDM is based on the Information State Update(ISU) approach to dialogue management.
The in-formation state in TDM is based on that of thesystem described in Larsson (2002) and includesQuestions Under Discussion, a dialogue plan, andshared commitments.The rule for integrating the user model data isa standard ISU rule, consisting of preconditionsand effects on the information state.
We describethese informally below:PRECONDITIONS?
If there is a propositional answer from theuser model resolving a question in the currentplan...?
and if the confidence score reported from theuser model is sufficient, then...EFFECTS?
accept the propositional answer (include itinto the shared commitments), and...?
give appropriate feedback to the user depend-ing on the confidence score:?
High confidence?
embedded feedback?
?Which route do you want to take towork?
?.38Figure 1: A sample dataset.
The horizontal axis shows days of the week (0=Monday, ..., 6=Sunday)and the vertical axis shows hour of the day.
Data points show destinations of trips initiated at the timeindicated by their position.
(?Now?
is the current time, in this case Thursday at lunchtime.)?
The user can always reject the predictionby requesting another destination.?
Medium confidence?
positive feedback?
?I assume you?re going to work?.?
If the user says ?no?, the answer is re-jected?
Silence is interpreted as acceptance.?
Low confidence?
interrogative feedback?
?To work, is that correct???
In this case, the user needs to explicitlyaccept the proposed answer.?
Otherwise, the user is prompted for ananswer.3.3 GUI outputIf the ISU rule above does not apply because oftoo low confidence scores, user model informa-tion is still used in the GUI.
When a Wh-questionis raised by the system, the GUI always presents alist of possible alternatives.
High-confidence alter-natives are highlighted and sorted before the otheralternatives in the list.4 Resulting behaviourThe demonstrator enables interaction with a learn-ing dialogue system which uses predictions to sim-plify interactions.
Here is an sample interaction:User: Traffic informationCar: Ok. What road?User: E6.Car: Showing traffic on the E6If this is repeated on a number of occasions,eventually the system will use a prediction:User: Traffic informationCar: Showing traffic on the E6The system thus reduces the need for repetitiveand information-scarce utterances from the user.As soon as the system has started identifying a pat-tern, it will start to suggest the most probable al-ternatives.
Initially, the most probable answers arepresented to the user as the top items in a list.
Thealternatives are also marked in a different color tomake them more visible to the user (not shownhere).User: Traffic informationCar: Ok. What road?Car GUI: [E6] [E45] [E20] [155]User: E6.Car: Showing traffic on the E639After some further use, the system has identi-fied a pattern which is prominent enough for thesystem to make a suggestion:User: Traffic informationCar: E6, is that right?User: Yes.Car: Showing traffic on the E6After getting further support for its hypothesis,the system will merely inform the user that an as-sumption has been made.
If the user is satisfiedwith the assumption, she does not need to do any-thing, but can correct or confirm it if desired.User: Traffic informationCar: I assume E6.User: [silence]Car: Showing traffic on the E6User: Traffic informationCar: I assume E6.User: No, E45.Car: Showing traffic on the E45If the user rejects the system suggestion with-out giving another answer, the system will showa menu where the most probable choices are thetopmost ones, and marked in a distinct colour (notshown here).User: Traffic informationCar: I assume E6.User: No.Car: What road?Car GUI: [E6] [E45] [E20] [155]When the system is certain about its hypothe-sis, the system will simply provide the user withthe desired information without asking the user forparameters.User: Traffic informationCar: Showing traffic on the E65 Conclusions and further workWe have designed and implemented a mechanismwhich learns user patterns and uses them proac-tively to simplify and shorten dialogue interac-tions.
The idea of learning user patterns from ob-servations is similar to Google Now.
However,while Google Now uses ?cards?
to provide un-requested information to the user, we show howpredictions can be integrated into spoken or multi-modal dialogue.It remains for future work to evaluate the sys-tem to establish that this actually reduces the dis-traction rate of drivers.
We also want to test theperformance of the learning mechanism by train-ing it on real observations of user behaviours (asopposed to simulated data).The current mechanism only predicts answersto individual system questions, which may resultin suboptimal behaviour in cases where there aredependencies between the questions pertaining tosome task.
An interesting area for future work isto instead predict sequences of answers; however,this would require a more powerful learning andclassification mechanisms.AcknowledgementsThis work was carried out within the FFI project?Safe Speech by Knowledge?
(2012-00941),funded by VINNOVA, Volvo Car Corporation andTalkamatic.ReferencesH.
H. Clark and S. E. Brennan.
1990.
Groundingin communication.
In L. B. Resnick, J. Levine,and S. D. Behrend, editors, Perspectives on SociallyShared Cognition, pages 127 ?
149.
APA.Dagmar Kern and Albrecht Schmidt.
2009.
Designspace for driver-based automotive user interfaces.
InProceedings of the 1st International Conference onAutomotive User Interfaces and Interactive Vehic-ular Applications, AutomotiveUI ?09, pages 3?10,New York, NY, USA.
ACM.Staffan Larsson, Alexander Berman, and JessicaVilling.
2011.
Adding a speech cursor to a mul-timodal dialogue system.
In INTERSPEECH 2011,12th Annual Conference of the International SpeechCommunication Association, Florence, Italy, 2011,pages 3319?3320.Staffan Larsson.
2002.
Issue-based Dialogue Manage-ment.
Ph.D. thesis, G?oteborg University.Tom M. Mitchell.
1997.
Machine Learning.
McGraw-Hill, New York.Vicki L. Neale, Thomas A. Dingus, Sheila G. Klauer,Jeremy Sudweeks, and Michael Goodman.
2005.An overview of the 100-car naturalistic study andfindings.
Technical report.40
