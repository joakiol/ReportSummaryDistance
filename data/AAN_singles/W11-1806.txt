Proceedings of BioNLP Shared Task 2011 Workshop, pages 41?45,Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational LinguisticsEvent Extraction as Dependency Parsing for BioNLP 2011David McClosky, Mihai Surdeanu, and Christopher D. ManningDepartment of Computer ScienceStanford UniversityStanford, CA 94305{mcclosky,mihais,manning}@stanford.eduAbstractWe describe the Stanford entry to the BioNLP2011 shared task on biomolecular event ex-traction (Kim et al, 2011a).
Our framework isbased on the observation that event structuresbear a close relation to dependency graphs.We show that if biomolecular events are castas these pseudosyntactic structures, standardparsing tools (maximum-spanning tree parsersand parse rerankers) can be applied to per-form event extraction with minimum domain-specific tuning.
The vast majority of ourdomain-specific knowledge comes from theconversion to and from dependency graphs.Our system performed competitively, obtain-ing 3rd place in the Infectious Diseases track(50.6% f-score), 5th place in Epigenetics andPost-translational Modifications (31.2%), and7th place in Genia (50.0%).
Additionally, thissystem was part of the combined system inRiedel et al (2011) to produce the highestscoring system in three out of the four eventextraction tasks.1 IntroductionThe distinguishing aspect of our approach is that bycasting event extraction as a dependency parsing, wetake advantage of standard parsing tools and tech-niques rather than creating special purpose frame-works.
In this paper, we show that with minimaldomain-specific tuning, we are able to achieve com-petitive performance across the three event extrac-tion domains in the BioNLP 2011 shared task.At the heart of our system1 is an off-the-shelf1nlp.stanford.edu/software/eventparser.shtmldependency parser, MSTParser2 (McDonald et al,2005; McDonald and Pereira, 2006), extended withevent extraction-specific features and bookended byconversions to and from dependency trees.
Whilefeatures in MSTParser must be edge-factored andthus fairly local (e.g., only able to examine a portionof each event at once), decoding is performed glob-ally allowing the parser to consider trade-offs.
Fur-thermore, as MSTParser can use n-best decoders,we are able to leverage a reranker to capture globalfeatures to improve accuracy.In ?2, we provide a brief overview of our frame-work.
We describe specific improvements for theBioNLP 2011 shared task in ?3.
In ?4, we presentdetailed results of our system.
Finally, in ?5 we givesome directions for future work.2 Event ParsingOur system includes three components: (1) anchordetection to identify and label event anchors, (2)event parsing to form candidate event structures bylinking entities and event anchors, and (3) eventreranking to select the best candidate event structure.As the full details on our approach are described inMcClosky et al (2011), we will only provide an out-line of our methods here along with additional im-plementation notes.Before running our system, we perform basicpreprocessing on the corpora.
Sentences needto be segmented, tokenized, and parsed syntacti-cally.
We use custom versions of these (exceptfor Infectious Diseases where we use those fromStenetorp et al (2011)).
To ease event parsing, our2http://sourceforge.net/projects/mstparser/41tokenizations are designed to split off suffixes whichare often event anchors.
For example, we split thetoken RelA-induced into the two tokens RelA and in-duced3 since RelA is a protein and induced an eventanchor.
If this was a single token, our event parserwould be unable to link them since it cannot pre-dict self-loops in the dependency graph.
For syntac-tic parsing, we use the self-trained biomedical pars-ing model from McClosky (2010) with the Charniakand Johnson (2005) reranking parser.
We use its ac-tual constituency tree, the dependency graph createdby applying head percolation rules, and the StanfordDependencies (de Marneffe and Manning, 2008) ex-tracted from the tree (collapsed and uncollapsed).Anchor detection uses techniques inspired fromnamed entity recognition to label each token withan event type or none.
The features for this stageare primarily drawn from Bjo?rne et al (2009).
Wereduce multiword event anchors to their syntactichead.4 We classify each token independently using alogistic regression classifier with L2 regularization.By adjusting a threshold parameter, we can adjustthe balance between precision and recall.
We chooseto heavily favor recall (i.e., overgenerate event an-chors) as the event parser can drop extraneous an-chors by not attaching any arguments to them.The event anchors from anchor detection andthe included entities (.t1 files) form a ?reduced?sentence, which becomes the input to event pars-ing.
Thus, the only words in the reduced sentenceare tokens believed to directly take part in events.Note, though, that we use the original ?full?
sen-tence (including the various representations of itssyntactic parse) for feature generation.
For full de-tails on this process, see McClosky et al (2011).As stated before, this stage consists of MSTParserwith additional event parsing features.
There arefour decoding options for MSTParser, dependingon (a) whether features are first- or second-orderand (b) whether graphs produced are projective ornon-projective.
The projective decoders have com-plete n-best implementations whereas their non-projective counterparts are approximate.
Neverthe-3The dash is removed since a lone dash would further con-fuse the syntactic parser.4This does not affect performance if the approximate scoreris used, but it does impact scores if exact matching of anchorboundaries is imposed.less, these four decoders constitute slightly differentviews of the same data and can be combined insidethe reranking framework.
After decoding, we con-vert parses back to event structures.
Details on thiscritical step are given in McClosky et al (2011).Event reranking, the final stage of our system, re-ceives an n-best list of event structures from eachdecoder in the event parsing step.
The rerankercan use any global features of an event structure torescore it and outputs the highest scoring structure.This is based on parse reranking (Ratnaparkhi, 1999;Collins, 2000) but uses features on event structuresinstead of syntactic constituency structures.
Weused Mark Johnson?s cvlm estimator5 (Charniakand Johnson, 2005) when learning weights for thereranking model.
Since the reranker can incorporatethe outputs from multiple decoders, we use it as anensemble technique as in Johnson and Ural (2010).3 Extensions for BioNLP 2011This section outlines the changes between ourBioNLP 2011 shared task submission and the sys-tem described in McClosky et al (2011).
The maindifferences are that all dataset-specific portions ofthe model have been factored out to handle the ex-panded Genia (GE) dataset (Kim et al, 2011b) andthe new Epigenetics and Post-translational Modifi-cations (EPI) and Infectious Diseases (ID) datasets(Ohta et al, 2011; Pyysalo et al, 2011, respec-tively).
Other changes are relatively minor but doc-umented here as implementation notes.Several improvements were made to anchor de-tection, improving its accuracy on all three do-mains.
The first is the use of distributional sim-ilarity features.
Using a large corpus of abstractsfrom PubMed (30,963,886 word tokens of 335,811word types), we cluster words by their syntactic con-texts and morphological contents (Clark, 2003).
Weused the Ney-Essen clustering model with morphol-ogy to produce 45 clusters.
Using these clusters, weextended the feature set for anchor detection fromMcClosky et al (2011) as follows: for each lexical-ized feature we create an equivalent feature wherethe corresponding word is replaced by its cluster ID.This yielded consistent improvements of at least 1percentage point in both anchor detection and event5http://github.com/BLLIP/bllip-parser42extraction in the development partition of the GEdataset.Additionally, we improved the head percolationrules for selecting the head of each multiword eventanchor.
The new rules prohibit determiners andprepositions from being heads, instead preferringverbs, then nouns, then adjectives.
There is alsoa small stop list to prohibit the selection of certainverbs (?has?, ?have?, ?is?, ?be?, and ?was?
).In event parsing, we used the morpha lemma-tizer (Minnen et al, 2001) to stem words insteadof simply lowercasing them.
This generally led toa small but significant improvement in event extrac-tion across the three domains.
Additionally, we donot use the feature selection mechanism describedin McClosky et al (2011) due to time restrictions.It requires running all parsers twice which is espe-cially cumbersome when operating in a round-robinframe (as is required to train the reranker).Also, note that our systems were only trained todo Task 1 (or ?core?)
roles for each dataset.
This wasdue to time restrictions and not system limitations.3.1 Adapting to the Epigenetics trackFor the EPI dataset, we adjusted our postprocessingrules to handle the CATALYSIS event type.
Similarto REGULATION events in GE, CATALYSIS events donot accept multiple CAUSE arguments.
We handlethis by replicating such CATALYSIS events and as-signing each new event a different CAUSE argument.To adapt the ontology features in the parser (Mc-Closky et al, 2011, ?3.3), we created a supertype forall non-CATALYSIS events since they behave simi-larly in many respects.There are several possible areas for improvementin handling this dataset.
First, our internal imple-mentation of the evaluation criteria differed fromthe online scorer, sometimes by up to 6% f-score.As a result, the reranker optimized a noisy versionof the evaluation criteria and potentially could haveperformed better.
It is unclear why our evaluatorscored EPI structures differently (it replicated thescores for GE) but it is worthy of investigation.
Sec-ond, due to time constraints, we did not transfer theparser or reranker consistency features (e.g., non-REGULATION events should not take events as argu-ments) or the type ontology in the reranker to the EPIdataset.
As a result, our results describe our systemwith incomplete domain-specific knowledge.3.2 Adapting to the Infectious Diseases trackLooking only at event types and their arguments, IDis similar to GE.
As a result, much of our domain-specific processing code for this dataset is based oncode for GE.
The key difference is that the GE post-processing code removes event anchors with zero ar-guments.
Since ID allows PROCESS events to havezero or one anchors, we added this as an exception.Additionally, the ID dataset includes many nestedentities, e.g., two-component system entities containtwo other entities within their span.
In almost all ofthese cases, only the outermost entity takes part inan event.
To simplify processing, we removed allnested entities.
Any events attaching to a nested en-tity were reattached to its outermost entity.Given the similarities with GE, we explored sim-ple domain adaptation by including the gold datafrom GE along with our ID training data.
To en-sure that the GE data did not overwhelm the ID data,we tried adding multiple copies of the ID data (seeTable 1 and the next section).As in EPI, we adjusted the type ontology in theparser for this dataset.
This included ?core enti-ties?
(as defined by the task) and a ?PROTEIN-or-REGULON-OPERON?
type (the type of arguments forGENE EXPRESSION and TRANSCRIPTION events).Also as in EPI, the reranker did not use the updatedtype ontology.4 ResultsFor ID, we present experiments on merging GE withID data (Table 1).
Since GE is much larger thanID, we experimented with replicating the ID trainingpartition.
Our best performance came from train-ing on three copies of the ID data and the trainingand development sections of GE.
However, as the ta-ble shows, performance is stable for more than twocopies of the ID data.
Note that for this shared taskwe simply merged the two domains.
We did notimplement any domain adaptation techniques (e.g.,labeling features based on the domain they comefrom (Daume?
III, 2007)).Table 2 shows the performance of the variousparser decoders and their corresponding rerankers.The last line in each domain block lists the score ofthe reranker that uses candidates produced by all de-43coders.
This reranking model always outperformsthe best individual parser.
Furthermore, the rerank-ing models on top of individual decoders help in allbut one situation (ID ?
2N decoder).
To our knowl-edge, our approach is the first to show that rerankingwith features generated from global event structurehelps event extraction.
Note that due to approximate2N decoding in MSTParser, this decoder does notproduce true n-best candidates and generally out-puts only a handful of unique parses.
Because ofthis, the corresponding rerankers suffer from insuf-ficient training data and hurt performance in ID.Finally, in Table 3, we give our results and rank-ing on the official test sets.
Our results are 6 fpoints lower than the best submission in GE and EPIand 5 points lower in ID.
Considering that the weused generic parsing tools with minimal customiza-tion (e.g., our parsing models cannot extract directedacyclic graph structures, which are common in thisdata), we believe these results are respectable.5 ConclusionOur participation in the BioNLP shared task provesthat standard parsing tools (i.e., maximum-spanningtree parsers, parse rerankers) can be successfullyused for event extraction.
We achieved this by con-verting the original event structures to a pseudo-syntactic representation, where event arguments ap-pear as modifiers to event anchors.
Our analysis in-dicates that reranking always helps, which provesthat there is merit in modeling non-local informationin biomolecular events.
To our knowledge, our ap-proach is the first to use parsing models for biomed-ical event extraction.During the shared task, we adapted our systempreviously developed for the 2009 version of theGenia dataset.
This process required minimal ef-fort: we did not add any new features to the pars-ing model; we added only two domain-specific post-processing steps (i.e., we allowed events without ar-guments in ID and we replicated CATALYSIS eventswith multiple CAUSE arguments in EPI).
Our sys-tem?s robust performance in all domains proves thatour approach is portable.A desired side effect of our effort is that wecan easily incorporate any improvements to parsingmodels (e.g., parsing of directed acyclic graphs, dualdecomposition, etc.)
in our event extractor.Model Prec Rec f-scoreID 59.3 38.0 46.3(ID?1) + GE 52.0 40.2 45.3(ID?2) + GE 52.4 41.7 46.4(ID?3) + GE 54.8 45.0 49.4(ID?4) + GE 55.2 43.8 48.9(ID?5) + GE 55.1 44.7 49.4Table 1: Impact of merging several copies of IDtraining with GE training and development.
Scoreson ID development data (2N parser only).Decoder(s) Parser Reranker1P 49.0 49.42P 49.5 50.51N 49.9 50.22N 46.5 47.9All ?
50.7 ?
(a) Genia results (task 1)Decoder(s) Parser Reranker1P 62.3 63.32P 62.2 63.31N 62.9 64.6 ?2N 60.8 63.8All ?
64.1(b) Epigenetics results (core task)Decoder(s) Parser Reranker1P 46.0 48.52P 47.8 49.81N 48.5 49.42N 49.4 48.8All ?
50.2 ?
(c) Infectious Diseases results (core task)Table 2: Results on development sections inBioNLP f-scores.
???
indicates the submissionmodel for each domain.Domain (task) Prec Rec f-score RankingGE (task 1) 61.1 42.4 50.0 7thEPI (core) 70.2 56.9 62.8 5thID (core) 55.9 46.3 50.6 3rdTable 3: BioNLP f-scores on the final test set.44AcknowledgmentsWe would like to thank the BioNLP shared task or-ganizers for an enjoyable and interesting task andtheir quick responses to questions.
We would alsolike to thank Sebastian Riedel for many interestingdiscussions.
We gratefully acknowledge the sup-port of the Defense Advanced Research ProjectsAgency (DARPA) Machine Reading Program underAir Force Research Laboratory (AFRL) prime con-tract no.
FA8750-09-C-0181.ReferencesJari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Extract-ing complex biological events with rich graph-basedfeature sets.
In Proceedings of the BioNLP 2009Work-shop Companion Volume for Shared Task, pages 10?18, Boulder, Colorado, June.
Association for Compu-tational Linguistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
In ACL.
The Association for ComputerLinguistics.Alexander Clark.
2003.
Combining distributional andmorphological information for part of speech induc-tion.
In Proceedings of the tenth Annual Meeting ofthe European Association for Computational Linguis-tics (EACL), pages 59?66.Michael Collins.
2000.
Discriminative reranking for nat-ural language parsing.
In Machine Learning: Pro-ceedings of the Seventeenth International Conference(ICML 2000), pages 175?182, Stanford, California.Hal Daume?
III.
2007.
Frustratingly easy domain adap-tation.
In Conference of the Association for Computa-tional Linguistics (ACL), Prague, Czech Republic.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
Stanford typed hierarchies representation.In Proceedings of the COLING Workshop on Cross-Framework and Cross-Domain Parser Evaluation.Mark Johnson and Ahmet Engin Ural.
2010.
Rerank-ing the berkeley and brown parsers.
In Proceedings ofthe HLT: North American Chapter of the ACL (HLT-NAACL), pages 665?668.
Association for Computa-tional Linguistics, June.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011a.
Overviewof BioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011b.
Overview of the Genia Eventtask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.David McClosky, Mihai Surdeanu, and Chris Manning.2011.
Event extraction as dependency parsing.
InProceedings of the Association for Computational Lin-guistics: Human Language Technologies 2011 Confer-ence (ACL-HLT?11), Main Conference, Portland, Ore-gon, June.David McClosky.
2010.
Any Domain Parsing: Auto-matic Domain Adaptation for Parsing.
Ph.D. thesis,Computer Science Department, Brown University.Ryan T. McDonald and Fernando C. N. Pereira.
2006.Online learning of approximate dependency parsingalgorithms.
In Proceedings of EACL.
The Associationfor Computer Linguistics.Ryan T. McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof HLT/EMNLP.
The Association for ComputationalLinguistics.Guido Minnen, John Carroll, and Darren Pearce.
2001.Applied morphological processing of English.
Natu-ral Language Engineering, 7(03):207?223.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, Portland, Oregon,June.
Association for Computational Linguistics.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Adwait Ratnaparkhi.
1999.
Learning to parse naturallanguage with maximum entropy models.
MachineLearning, 34(1-3):151?175.Sebastian Riedel, David McClosky, Mihai Surdeanu, An-drew McCallum, and Christopher D. Manning.
2011.Model Combination for Event Extraction in BioNLP2011.
In BioNLP 2011 Shared Task.Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, TomokoOhta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011.BioNLP Shared Task 2011: Supporting Resources.
InProceedings of the BioNLP 2011 Workshop Compan-ion Volume for Shared Task, Portland, Oregon, June.Association for Computational Linguistics.45
