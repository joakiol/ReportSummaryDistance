Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 79?82,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsReference reversibility with Reference Domain TheoryAlexandre DenisTALARIS team / UMR 7503 LORIA/INRIALorraine.
Campus scientifique, BP 239F-54506 Vandoeuvre-le`s-Nancy cedexalexandre.denis@loria.frAbstractIn this paper we present a reference modelbased on Reference Domain Theory thatcan work both in interpretation and gener-ation.
We introduce a formalization of keyconcepts of RDT, the interpretation andgeneration algorithms and show an exam-ple of behavior in the dynamic, asymmetricand multimodal GIVE environment.1 IntroductionThe reference task in a dialogue system is two-fold.On the one hand the system has to interpret thereferring expressions (RE) produced by the user inhis utterances.
On the other hand the system hasto generate the REs for the objects it aims to referto.
We present in this paper a framework that con-siders that reference interpretation and generationare two sides of the same coin, hence avoiding anypotential misunderstanding arising from the twomodules discrepancies.
Reference Domain Theory(RDT) (Salmon-Alt and Romary, 2000; Salmon-Alt and Romary, 2001) proposes to represent thediversity of referring acts by the diversity of con-straints they impose on their context of use.
Thereversibility then lies in the possibility to expressthese constraints independently of the consideredtask.In (Denis, 2010) we described the generation sideof RDT in the context of the GIVE-2 challenge(Koller et al, 2010) which is an evaluation of in-struction generation systems in a 3D maze.
In thispaper we propose the interpretation counterpartand show the required modeling to consider thedynamic, asymmetric and multimodal context ofGIVE.
We first present the reference model in sec-tion 2 and 3, discuss the interpretation problemsin GIVE in section 4, detail an example in section5 and present evaluation results in section 6.2 Reference DomainsA rich contextual structure is required to give anaccount for the different kinds of discriminationwe observe in REs such as semantic discrimina-tion (e.g.
?the blue button?
), focus discrimination(e.g.
?this button?)
and salience discrimination(e.g.
?this one?).
We introduce here the struc-ture of reference domain which is a local contextsupporting these different discriminations.We assume that Props is the set of unary predi-cate names e.g.
{blue, left, ...}, Types is the set oftypes of predicates e.g.
{color, position, ...}, andval is the function val : Types?
2Props which mapsa type on the predicates names.
Finally, E is theset of all objects and V the set of ground predicatese.g.
{blue(b1), ...}.A reference domain D is then a tuple?GD, SD, ?D, (c, P, F )?where GD ?
E is the set of objects of the do-main, called the ground of the domain; SD ?
Propsis the semantic description of the domain, satis-fied by all elements of the ground; ?D ?
N is thesalience of the domain.
And (c, P, F ) is a parti-tion structure where c ?
Types is a differentiationcriterion; P is the partition generated by c; andF ?
P is the focus of P .For instance, a domain composed of a blue but-ton b1 and a red button b2, with a salience equalto 3, where b1 and b2 are differentiated using thecolor, and where b1 is in focus, would be noted as:D =?
{b1, b2}, {button}, 3,(color, {{b1}, {b2}}, {{b1}})?Finally we define a referential space (RS) as aset of reference domains (RD) ordered by salience.3 ReferringA RE impose some constraints on the context inwhich it can be uttered, that is in which RD theinterpretation has to be made.
The constraints arerepresented as underspecified domains (UD), spec-ifying the structure of the suitable RD in terms ofground, salience or partition.
The explicit defini-tions of the UDs makes possible to share these def-initions between the interpretation and the gener-ation modules, hence allowing the implementationof a type B reversible reference module (Klarner,2005), that is a module in which both directionsshare the same resources.79Expression U(N, t) matches D iff ?
(c, P, F ) ?
D;this one F = {{t}} ?
msd(D)this N F = {{t}} ?
t ?
NIthe N t ?
NI ?
{t} ?
P ?
?X?P,X 6={t}?X?NI =?the other one F 6= ?
?
P \ F = {{t}} ?
msd(D)the other N F 6= ?
?
P \ F = {{t}} ?GD ?
NIanother one F 6= ?
?
{t} ?
P \ F ?
msd(D)another N F 6= ?
?
{t} ?
P \ F ?GD ?
NIa N t ?
NI ?
t ?
GDTable 1: Underspecified domains for each type ofreferring expression3.1 Underspecified domainsThe different types of UDs are presented in table 1.Each UD is a parametric conjunction of constraintson a RD, noted U(N, t), where t is the intendedreferent and N ?
Props is a semantic description.NI stands for the extension of N , and msd(D)stands for most salient description, that is, thereis no more or equally salient domain than D in thecurrent RS with a different description.
Each UDis associated to a wording combining a determinerand a wording of the semantic description, for in-stance ?the N?
is a shortcut for a definite expres-sion whose head noun and modifiers are providedby the wording of N .
Finally we say that an UDmatches a RD if all the constraints of the UD aresatisfied by the RD.3.2 Referring processesInterpretation and generation can now be definedin terms of UD.
The two processes are illustratedin figure 1 and the algorithms are presented in fig-ure 2.The interpretation algorithm consists in findingor creating a RD from the input UD, U(N, .)
cre-ated from the input RE type and description N .The algorithm then iterates through the RS insalience order, and through all the individuals t ofthe tested domain to retrieve the first one match-ing U(N, t).
If a matching domain D is found, arestructuring operation is applied and the referentt is focused in the partition of D. On the otherhand, if no domain is found, the UD is accommo-dated, that is a new domain and a new referent sat-isfying the constraints of U(N, t) are created.
Ac-cording to the task, this accommodation may notbe possible for all REs, but for sake of simplicitywe assume here this operation is always possible.The generation side is the opposite, that is itfinds an UD from an input RD.
It first selects aRD containing the target referent to generate t,assuming here that the most salient domain has tobe preferred.
The description N used to instan-tiate the UDs is composed of the description ofthe domain and the description of the referent inthe partition (line 2).
It then iterates through theUnderspecifiedDomainsExistingDomainsinterpretationgenerationreferentreferringexpressionFigure 1: Reference processesdifferent UDs by Givenness order (Gundel et al,1993) and selects the first one that matches.
A re-structuring operation is applied and the found UDis returned, eventually providing the RE.The restructuring operation, detailed in (Denis,2010), aims to restrict the current context by cre-ating a new domain around the referent in the ref-erential space or by increasing the salience of thedomain containg the referent.
This operation helpsto perform focalization in restricted domains.4 The complex context of GIVEThe dynamic, asymmetric and multimodal contextof GIVE requires additional mechanisms for inter-pretation.
Asymmetry causes the late visual con-text integration, when the direction giver producesa RE to objects not yet known by the directionfollower, that are only visually discovered later on.Space prevents us to describe in details the late in-tegration algorithm, but the idea is, given a newphysical object t, to scan existing domains of theactual RS to check if t can be merged semanticallywith any previous object t?.
If this could be thecase, the integration leads to create two parallelRS, one in which t = t?
(the fusion hypothesis)and one in which t 6= t?
(the separation hypoth-esis).
If this cannot be the case, t is added as anew object.
Following (DeVault and Stone, 2007),these alternative contexts can persist across timeand further referring expressions may reject one orthe other hypothesis as illustrated in section 5.The second required mechanism is the properhandling of the multimodal dynamic focus, thatis the combination of the linguistic focus result-ing from RE, and the visual focus.
It is possibleto have two referential spaces for the linguistic orvisual context as in (Kelleher et al, 2005; Byronet al, 2005), or to have two foci in a partition.We can also model interleaved focus, that is, onlyone focus per domain but that dynamically corre-sponds to the linguistic focus or the visual focus.The idea is that after each RE, the referent receivesthe focus as described in algorithm 1, but wheneverthe visual context changes, the focus is updated tothe visible objects.
Although interleaved focus pre-vents anaphora while the visual context changes,its complexity is enough for our setup.80Algorithm 1 interpret(U(N, .
), RS)1: for all domain D in RS by salience order do2: for all t ?
GD do3: if U(N, t) matches D then4: restructure(D, N , RS)5: focus t in D6: return t7: end if8: end for9: end for10: return accommodate(U(N, .
), RS)Algorithm 2 generate(t, RS)1: D ?
most salient domain containing t2: N ?
SD ?
{p|p ?
val(c), p(t) ?
V }3: for all U(N, t) sorted by Givenness do4: if U(N, t) matches D then5: restructure(D, N , RS)6: return U(N, t)7: end if8: end for9: return failureFigure 2: Reference algorithms, relying on the same underspecified domains5 ExampleIn this section we present the interpretation sideof some expressions we generated in the GIVE set-ting (table 2).
The detailed generation side of thisexample can be found in (Denis, 2010).
S is thesystem that interprets the RE of U the user.
Thesituation is: S enters a room with two blue but-tons b1 and b2, none of them being visible when heenters and U wants to refer to b1.state of S utterance of UPush a blue button (b1)see(b2) Not this one!
Look for the other one!see(b1) Yeah!
This one!Table 2: Utterances produced by UWhen S enters the room, U generates an indef-inite RE ?Push a blue button?.
S first constructsan indefinite UD ?a N?
with N = {blue, button}.However, because there exists no RD at first, hehas to accommodate the UD, hence creating a newdomain D1 containing a new linguistically focusedindividual t:D1 =?
{t}, {button, blue}, 1,(id, {{t}}, {{t}})?We assume that S moves and now sees the bluebutton b2 without knowing yet if this is the in-tended one.
The integration of this new physicalobject then leads to two hypothesis.
In the fu-sion hypothesis, b2 = t, and in the separation hy-pothesis, b2 6= t. In both cases, the visible buttonis focused in the two versions of D1, D1FUS andD1SEP :D1FUS =?
{t}, {button, blue}, 2,(id, {{t}}, {{t}})?D1SEP =?
{t, b2}, {button, blue}, 2,(id, {{t}, {b2}}, {{b2}})?However, U utters ?Not this one!?
rejecting thenthe fusion hypothesis.
To be able to consider the ef-fects of this utterance, we have to take into accountthe ellipsis.
This can be done by assuming that Uis asserting properties of the target of his first RE,that is, he is actually stating that ?
[t is] not thisone!?.
The RE ?this one?
leads to the constructionof a demonstrative one-anaphora UD that matchest in D1FUS but b2 in D1SEP .
The following schemashows the contradiction in the fusion hypothesis:t is not this onefusion t 6= tseparation t 6= b2Being contradictory, the fusion hypothesis is re-jected and only D1SEP is maintained.
For thereadability of the presentation, D1SEP is rewrit-ten as D1.The interpretation of ?Look for the other one!
?is straightforward.
A definite alternative one-anaphora UD is built, and both t and b2 are testedin D1 but only t is matched because it is unfocused(see the definition of the alternative one-anaphorain table 1).Now S moves again and sees b1.
As for b2, theintegration of b1 in the referential space leads totwo alternative RS.
The buttons b2 and b1 cannotbe merged (we assume here that S can clearly seethey are two different buttons), thus the two alter-native RS are whether b1 = t or b1 6= t:D1FUS =?
{t, b2}, {button, blue}, 3,(id, {{t}, {b2}}, {{t}})?D1SEP =?
{t, b1, b2}, {button, blue}, 3,(id, {{t}, {b1}, {b2}}, {{b1}})?Eventually S has to interpret ?this one?.
Likepreviously, in order to take into account the effectsof this utterance, S has to resolve the ellipsis andmust consider ?
[t is] this one?.
The RE ?this one?is resolved on t in D1FUS but on b1 in D1SEP .81t is this onefusion t = tseparation t = b1This is now the separation hypothesis which isinconsistent because we assumed that b1 6= t. ThisRS is then ruled out, and only the fusion RS re-mains.6 EvaluationOnly the generation direction has been evaluatedin the GIVE challenge.
The results (Koller et al,2010) show that the system embedding ReferenceDomain Theory proves to rely on less instructionsthan other systems (224) and proves to be the mostsuccessful (47% of task success) while being thefastest (344 seconds).
We conjecture that the goodresults of RDT can be explained by the low cogni-tive load resulting from the use of demonstrativeNPs and one-anaphoras, but the role of the over-all generation strategy has also to be taken intoaccount in these good results (Denis et al, 2010).Although it would be very interesting, the in-terpretation side has not yet been evaluated inthe GIVE setting, but only in the MEDIA cam-paign (Bonneau Maynard et al, 2009) which is anunimodal setting.
The results show that the in-terpretation side of RDT achieves a fair precisionin identification (75.2%) but a low recall (44.7%).We assume that the low recall of the module iscaused by the cascade of errors, one error at thestart of a reference chain leading to several othererrors.
Nonetheless, we estimate that error cascad-ing would be less problematic in the GIVE settingbecause of its dynamicity.7 ConclusionsWe presented a reference framework extending(Salmon-Alt and Romary, 2001) in which interpre-tation and generation can be defined in terms of theconstraints imposed by the referring expressions ontheir context of use.
The two modules sharing thesame library of constraints, the model is then saidreversible.
However, because of the asymmetry anddynamicity of our setup, the GIVE challenge, ad-ditional mechanisms such as uncertainty have tobe modeled.
In particular, we have to maintaindifferent interpretation contexts like (DeVault andStone, 2007) to take into account the ambiguityarising from the late integration of the visual con-text.
It would be interesting now to explore deeperour reversibility claim by evaluating the interactionbetween the two reference algorithms in the GIVEsetting.ReferencesHe?le`ne Bonneau Maynard, Matthieu Quignard,and Alexandre Denis.
2009.
MEDIA: a seman-tically annotated corpus of task oriented dialogsin French.
Language Resources and Evaluation,43(4):329?354.Donna K. Byron, Thomas Mampilly, VinaySharma, and Tianfang Xu.
2005.
Utilizing vi-sual attention for cross-modal coreference inter-pretation.
In Proceedings of Context-05, pages83?96.Alexandre Denis, Marilisa Amoia, LucianaBenotti, Laura Perez-Beltrachini, Claire Gar-dent, and Tarik Osswald.
2010.
The GIVE-2Nancy Generation Systems NA and NM.Technical report.Alexandre Denis.
2010.
Generating referring ex-pressions with Reference Domain Theory.
InProceedings of the 6th International NaturalLanguage Generation Conference - INLG 2010,Dublin, Ireland.David DeVault and Matthew Stone.
2007.
Man-aging ambiguities across utterances in dialogue.In Proceedings of the 2007 Workshop on the Se-mantics and Pragmatics of Dialogue (DECA-LOG 2007), Trento, Italy.Jeanette K. Gundel, Nancy Hedberg, and RonZacharski.
1993.
Cognitive status and the formof referring expressions in discourse.
Language,69(2):274?307.John Kelleher, Fintan Costello, and Josef van Gen-abith.
2005.
Dynamically structuring, updatingand interrelating representations of visual andlinguistic discourse context.
Artificial Intelli-gence, 167(1-2):62?102.Martin Klarner.
2005.
Reversibility and re-usability of resources in NLG and natural lan-guage dialog systems.
In Proceedings of the 10thEuropean Workshop on Natural Language Gen-eration (ENLG-05), Aberdeen, Scotland.Alexander Koller, Kristina Striegnitz, AndrewGargett, Donna Byron, Justine Cassell, RobertDale, Johanna Moore, and Jon Oberlander.2010.
Report on the second NLG challenge ongenerating instructions in virtual environments(GIVE-2).
In Proceedings of the 6th Interna-tional Natural Language Generation Conference- INLG 2010, Dublin, Ireland.Susanne Salmon-Alt and Laurent Romary.
2000.Generating referring expressions in multimodalcontexts.
In Workshop on Coherence in Gener-ated Multimedia - INLG 2000, Israel.Susanne Salmon-Alt and Laurent Romary.
2001.Reference resolution within the framework ofcognitive grammar.
In Proceeding of the Inter-national Colloquium on Cognitive Science, SanSebastian, Spain.82
