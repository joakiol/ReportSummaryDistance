HITIQA:  An Interactive Question Answering SystemA Preliminary ReportSharon Small, Ting Liu, Nobuyuki Shimizu, and Tomek StrzalkowskiILS InstituteThe State University of New York at Albany1400 Washington AvenueAlbany, NY 12222{small,tl7612,ns3203,tomek}@albany.eduAbstractHITIQA is an interactive question answeringtechnology designed to allow intelligence analystsand other users of information systems to posequestions in natural language and obtain relevantanswers, or the assistance they require in order toperform their tasks.
Our objective in HITIQA is toallow the user to submit exploratory, analytical,non-factual questions, such as ?What has beenRussia?s reaction to U.S. bombing of Kosovo?
?The distinguishing property of such questions isthat one cannot generally anticipate what mightconstitute the answer.
While certain types of thingsmay be expected (e.g., diplomatic statements), theanswer is heavily conditioned by what informationis in fact available on the topic.
From a practicalviewpoint, analytical questions are often under-specified, thus casting a broad net on a space ofpossible answers.
Therefore, clarification dialogueis often needed to negotiate with the user the exactscope and intent of the question.1   IntroductionHITIQA project is part of the ARDA AQUAINTprogram that aims to make significant advances inthe state of the art of automated question answer-ing.
In this paper we focus on two aspects of ourwork:1.
Question Semantics: how the system ?un-derstands?
user requests.2.
Human-Computer Dialogue: how the userand the system negotiate this understand-ing.We will also discuss very preliminary evalua-tion results from a series of pilot tests of the systemconducted by intelligence analysts via a remoteinternet link.2   Factual vs. AnalyticalThe objective in HITIQA is to allow the user tosubmit and obtain answers to exploratory, analyti-cal, non-factual questions.
There are very signifi-cant differences between factual, or fact-finding,and analytical question answering.
A factual ques-tion seeks pieces of information that would make acorresponding statement true (i.e., they becomefacts): ?How many states are in the U.S.??
/ ?Thereare X states in the U.S.?
In this sense, a factualquestion usually has just one correct answer thatcan generally, be judged for its truthfulness.
Bycontrast, an analytical question is when the ?truth?of the answer is more a matter of opinion and maydepend upon the context in which the question isasked.
Answers to analytical questions are rarelyunilateral, indeed, a mere ?correct?
answer mayhave limited value, and in some cases may noteven be determinate (?Which college is the best?
?,?How do I stop my baby?s crying??).
Instead, an-swers to analytical questions are often judged ashelpful, or useful, or satisfactory, etc.
?Technicallycorrect?
answers (e.g., ?feed the baby milk?)
maybe considered as irrelevant or at best unresponsive.The distinction between factual and analyticalquestions depends primarily on the intention of theperson who is asking, however, the form of a ques-tion is often indicative of which of the two classesit is more likely to belong to.
Factual questionscan be classified into a number of syntactic formats(?question typology?)
that aids in automatic proc-essing.Factual questions display a fairly distinctive?answer type?, which is the type of the informationpiece needed to fulfill the statement.
Recent auto-mated systems for answering factual questionsdeduct  this expected answer type from the form ofthe question and a finite list of possible answertypes.
For example, ?Who was the first man inspace?
expects a ?person?
as the answer, while?How long was the Titanic??
expects some lengthmeasure as an answer, probably in yards and feet,or meters.
This is generally a very good strategy,that has been exploited successfully in a number ofautomated QA systems that appeared in recentyears, especially in the context of TREC QA1evaluations (Harabagiu et al, 2000; Hovy et al,2000; Prager at al., 2001).This process is not easily applied to analyticalquestions.
This is because the type of an answer foranalytical questions cannot always be anticipateddue to their inherently exploratory character.
Incontrast to a factual question, an analytical ques-tion has an unlimited variety of syntactic formswith only a loose connection between their syntaxand the expected answer.
Given the unlimited po-tential of the formation of analytical questions, itwould be counter-productive to restrict them to alimited number of question/answer types.
Evenfinding a non-strictly factual answer to an other-wise simple question about Titanic length (e.g.,?two football fields?)
would push the limits of theanswer-typing approach.
Therefore, the formationof an answer should instead be guided by the top-ics the user is interested in, as recognized in thequery and/or through the interactive dialogue,rather than by a single type as inferred from thequery in a factual system.This paper argues that the semantics of an ana-lytical question is more likely to be deduced fromthe information that is considered relevant to thequestion than through a detailed analysis of theirparticular form.
While this may sound circular, itneeds not be.
Determining ?relevant?
informationis not the same as finding an answer; indeed wecan use relatively simple information retrievalmethods (keyword matching, etc.)
to obtain per-haps 50 or 100 ?relevant?
documents from a data-base.
This gives us an initial answer space to workon in order to determine the scope and complexityof the answer.
In our project, we use structuredtemplates, which we call frames to map out thecontent of pre-retrieved documents, and subse-quently to delineate the possible meaning of thequestion (Section 6).1 TREC QA is the annual Question Answering evalua-tion sponsored by the U.S. National Institute of Stan-dards and Technology www.trec.nist.gov.3   Document RetrievalWhen the user poses a question to a system sittingatop a huge database of unstructured data (textfiles), the first order of business is to reduce thatpile to perhaps a handful of documents where theanswer is likely to be found.
This means, most of-ten, document retrieval, using fast but non-exactselection methods.
Questions are tokenized andsent to a document retrieval engine, such as Smart(Buckley, 1985) or InQuery (Callan et al, 1992).Noun phrases and verb phrases are extracted fromthe question to give us a list of potential topics thatthe user may be interested in.In the experiments with the HITIQA prototype,see Figure 1, we are retrieving the top fifty docu-ments from three gigabytes of newswire(AQUAINT corpus plus web-harvested docu-ments).DocumentRetrievalDocumentRetrievalBuildFramesBuildFramesProcessFramesProcessFramesDialogueManagerDialogueanagerSegment/FilterSegment/FilterClusterParagraphsClusterParagraphsAnswerGeneratorAnswerGeneratoranswerTokenizedquestiontop 50documentsdistinctparagraphsclustersframed textsegmentscandidateanswer topicsrelevant textsegmentssystemclarificationquestion/user responseDBGateWordnetFigure 1: HITIQA preliminary architecture4   Data Driven Semantics of QuestionsThe set of documents and text passages returnedfrom the initial search is not just a random subsetof the database.
Depending upon the quality (recalland precision) of the text retrieval system avail-able, this set can be considered as a first stab atunderstanding the user?s question by the machine.Again, given the available resources, this is thebest the system can do under the circumstances.Therefore, we may as well consider this collectionof retrieved texts (the Retrieved Set) as the mean-ing of the question as understood by the system.This is a fair assessment: the better our search ca-pabilities, the closer this set would be to what theuser may accept as an answer to the question.We can do better, however.
We can performautomatic analysis of the retrieved set, attemptingto uncover if it is a fairly homogenous bunch (i.e.,all texts have very similar content), or whetherthere are a number of diverse topics representedthere, somehow tied together by a common thread.In the former case, we may be reasonably confi-dent that we have the answer, modulo the retriev-able information.
In the latter case, we know thatthe question is more complex than the user mayhave intended, and a negotiation process is needed.We can do better still.
We can measure howwell each of the topical groups within the retrievedset is ?matching up?
against the question.
This isaccomplished through a framing process describedlater in this paper.
The outcome of the framingprocess is twofold: firstly, the alternative interpre-tations of the question are ranked within 3 broadcategories: on-target, near-misses and outliers.Secondly, salient concepts and attributes for eachtopical group are extracted into topic frames.
Thisenables the system to conduct a meaningful dia-logue with the user, a dialogue which is whollycontent oriented, and thus entirely data driven.ON-TARGETOUTLIERSNEAR-MISSESFigure 2: Answer Space Topology.
The goal of interac-tive QA it to optimize the ON-TARGET middle zone.5   ClusteringWe use n-gram-based clustering of text passagesand concept extraction  to uncover the main topics,themes and entities in this set.Retrieved documents are first broken into natu-rally occurring paragraphs.
Duplicate paragraphsare filtered out and the remaining passages areclustered using a combination of hierarchical clus-tering and n-bin classification (details of the clus-tering algorithm can be found in Hardy et al,2002a).
Typically three to six clusters are gener-ated out of the top 50 documents, which may yieldas many as 1000 passages.
Each cluster representsa topic theme within the retrieved set: usually analternative or complimentary interpretation of theuser?s question.A list of topic labels is assigned to each cluster.A topic label may come from one of two places:First, the texts in the cluster are compared againstthe list of key phrases extracted from the user?squery.
For each match found, the matching phraseis used as a topic label for the cluster.
If a matchwith the key phrases from the question cannot beobtained, Wordnet is consulted to see if a commonancestor can be found.
For example, ?rifle?
and?machine gun?
are kinds of ?weaponry?
in Word-net, which allows an indirect match between aquestion about weapon inspectors and a text re-porting a discovery by the authorities of a cache of?rifles?
and ?machine guns?.6   FramingIn HITIQA we use a text framing technique to de-lineate the gap between the meaning of the user?squestion and the system ?understanding?
of thisquestion.
The framing is an attempt to impose apartial structure on the text that would allow thesystem to systematically compare different textpieces against each other and against the question,and also to communicate with the user about this.In particular, the framing process may uncovertopics and themes within the retrieved set whichthe user has not explicitly asked for, and thus maybe unaware of their existence.
Nonetheless thesemay carry important information ?
the NEAR-MISSES in Figure 2.In the current version of the system, frames arefairly generic templates, consisting of a smallnumber of attributes, such as LOCATION, PERSON,COUNTRY, ORGANIZATION, etc.
Future versions ofHITIQA will add domain specialized frames, forexample, we are currently constructing frames forthe Weapons Non-proliferation Domain.
Most ofthe frame attributes are defined in advance, how-ever, dynamic frame expansion is also possible.Each of the attributes in a frame is equipped withan extractor function which specializes in locatingand extracting instances of this attribute in the run-ning text.
The extractors are implemented usinginformation extraction utilities which form the ker-nel of Sheffield?s GATE2 system.
We have modi-fied GATE to separate organizations into compa-nies and other organizations, and we have also ex-panded by adding new concepts such as industries.Therefore, the framing process resembles stronglythe template filling task in information extraction(cf.
MUC3 evaluations), with one significant ex-ception: while the MUC task was to fill in a tem-plate using potentially any amount of source text(Humphreys et al, 1998), the framing is essentiallyan inverse process.
In framing, potentially multipleframes can be associated with a small chunk of text(a passage or a short paragraph).
Furthermore, thischunk of text is part of a cluster of very similar textchunks that further reinforce some of the most sali-ent features of these texts.
This makes the framefilling a significantly less error-prone task ?
ourexperience has been far more positive than theMUC evaluation results may indicate.
This is be-cause, rather than trying to find the most appropri-ate values for attributes from among many poten-tial candidates, we in essence fit the frames oversmall passages4.Therefore, data frames are built from the re-trieved data, after clustering it into several topicalgroups.
Since clusters are built out of small textpassages, we associate a frame with each passagethat serves as a seed of a cluster.
We subsequentlymerge passages, and their associated frames when-ever anaphoric and other cohesive links are de-tected.A very similar process is applied to the user?squestion, resulting in a Goal Frame which can besubsequently compared to the data frames obtainedfrom retrieved data.
For example, the Goal Framegenerated from the question, ?How has pollution inthe Black Sea affected the fishing industry, and2 GATE is Generalized Architecture for Text Engineering, aninformation extraction system developed at the University ofSheffield (Cunningham, 2000).3 MUC, the Message Understanding Conference, funded byARPA, involved the evaluation of information extraction sys-tems applied to a common task.4 We should note that selecting the right frame type for a pas-sage is an important pre-condition to ?understanding?.what are the sources of this pollution??
is shownin Figure 3 below.TOPIC:[pollution, industry, sources]LOCATION: [Black Sea]INDUSTRY:[fishing]Figure 3: HITIQA generated Goal FrameTOPIC: pollutionSUB-TOPIC: [sources]LOCATION: [Black Sea]INDUSTRY :[fisheries, tourism]TEXT: [In a period of only three decades (1960's-1980's),the Black Sea has suffered the catastrophic degradationof a major part of its natural resources.
Particularly acuteproblems have arisen as a result of pollution (notablyfrom nutrients, fecal material, solid waste and oil), acatastrophic decline in commercial fish stocks, a severedecrease in tourism and an uncoordinated approach to-wards coastal zone management.
Increased loads of nutri-ents from rivers and coastal sources caused an overpro-duction of phytoplankton leading to extensive eutrophica-tion and often extremely low dissolved oxygen concentra-tions.
The entire ecosystem began to collapse.
This prob-lem, coupled with pollution and irrational exploitation offish stocks, started a sharp decline in fisheries resources.
]RELEVANCE: Matches on all elements found in goalframeFigure 4: A HITIQA generated data frame.
Words inbold were used to fill the Frame.The data frames are then compared to the GoalFrame.
We pay particular attention to matching thetopic attributes, before any other attributes are con-sidered.
If there is an exact match between a GoalFrame topic and the text being used to build thedata frame, then this becomes the data frame?stopic as well.
If more than one match is found, thesubsequent matches become the sub-topics of thedata frame.
On the other hand, if no match is pos-sible against the Goal Frame topic, we choose thetopic from the list of the Wordnet generated hy-pernyms.
An example data frame generated fromthe text retrieved in response to the query about theBlack Sea is shown in Figure 4.
After the initialframing is done, frames judged to be related to thesame concept or event, are merged together andvalues of their attributes are combined.7   Judging Frame RelevanceWe judge a particular data frame as relevant, andsubsequently the corresponding segment of text asrelevant, by comparison to the Goal Frame.
Thedata frames are scored based on the number ofconflicts found between them and the Goal Frame.The conflicts are mismatches on values of corre-sponding attributes.
If a data frame is found tohave no conflicts, it is given the highest relevancerank, and a conflict score of zero.
All other dataframes are scored with an incrementing conflictvalue, one for frames with one conflict with theGoal Frame, two for two conflicts etc.
Frames thatconflict with all information found in the query aregiven a score of 99 indicating the lowest relevancyrank.
Currently, frames with a conflict score of 99are excluded from further processing.
The frame inFigure 4 is scored as fully relevant to the question(0 conflicts).8   Enabling Dialogue with the UserFramed information allows HITIQA to automati-cally judge some text as relevant and to conduct ameaningful dialogue with the user as needed onother text.
The purpose of the dialogue is to helpthe user to navigate the answer space and to solicitfrom the user more details as to what informationhe or she is seeking.
The main principle here is thatthe dialogue is at the information semantic level,not at the information organization level.
Thus, it isokay to ask the user whether information about theAIDS conference in Cape Town should be in-cluded in the answer to a question about combatingAIDS in Africa.
However, the user should never beasked if a particular keyword is useful or not, or ifa document is relevant or not.
We have developeda 3-pronged strategy:1.
Narrowing dialogue: ask questions thatwould allow the system to reduce the sizeof the answer set.2.
Expanding dialogue: ask questions thatwould allow the system to decide if the an-swer set needs to be expanded by informa-tion just outside of it (near-misses).3.
Fact seeking dialogue: allow the user toask questions seeking additional facts andspecific examples, or similar situations.Of the above, we have thus far implemented thefirst two options as part of the preliminary clarifi-cation dialogue.
The clarification dialogue is whenthe user and the system negotiate the task thatneeds to be performed.
We can call this a ?triagingstage?, as opposed to the actual problem solvingstage (point 3 above).
In practice, these two stagesare not necessarily separated and may be overlap-ping throughout the entire interaction.
Nonetheless,these two have decidedly distinct character andrequire different dialogue strategies on the part ofthe system.Our approach to dialogue in HITIQA is mod-eled to some degree upon the mixed-initiative dia-logue management adopted in the AMITIES pro-ject (Hardy et al, 2002b).
The main advantage ofthe AMITIES model is its reliance on data-drivensemantics which allows for spontaneous and mixedinitiative dialogue to occur.By contrast, the major approaches to implemen-tation of dialogue systems to date rely on systemsof functional transitions that make the resultingsystem much less flexible.
In the grammar-basedapproach, which is prevalent in commercial sys-tems, such as in various telephony products, aswell as in practically oriented research prototypes5,(e.g., DARPA, 2002; Seneff and Polifoni, 2000;Ferguson and Allen, 1998) a complete dialoguetransition graph is designed to guide the conversa-tion and predict user responses, which is suitablefor closed domains only.
In the statistical variationof this approach, a transition graph is derived froma large body of annotated conversations (e.g.,Walker, 2000; Litman and Pan, 2002).
This latterapproach is facilitated through a dialogue annota-tion process, e.g., using Dialogue Act Markup inSeveral Layers (DAMSL) (Allen and Core, 1997),which is a system of functional dialogue acts.Nonetheless, an efficient, spontaneous dialoguecannot be designed on a purely functional layer.Therefore, here we are primarily interested in thesemantic layer, that is, the information exchangeand information building effects of a conversation.In order to properly understand a dialogue, bothsemantic and functional layers need to be consid-ered.
In this paper we are concentrating exclusivelyon the semantic layer.9   Clarification DialogueData frames with a conflict score of zero form theinitial kernel answer space.
Depending upon thesize of this set and the presence of other framesoutside of it, the system either proceeds to generatethe answer or initiates a dialogue with the user.
For5 A notable exception is CU Communicator developedat University of Colorado (Ward and Pellom, 1999)example, if the answer space appears too large orvaried, e.g.
consists of many different topics, thesystem may ask the user how to narrow it.
Alterna-tively, the presence of large groups of texts frameswith near-miss frames assigned to them (i.e.,frames with 1 or 2 conflicts with the Goal Frame)may indicate that the answer space is actually lar-ger, and the user will be consulted about a  possi-ble broadening of the question.
Currently, we onlyinitiate a clarification dialogue for 1-conflictframes.A 1-conflict frame has only a single attributemismatch with the Goal Frame.
This could be amismatch on any attribute, for example, LOCA-TION, or ORGANIZATION, or TIME, etc.
A specialcase arises when the conflict occurs on the TOPICattribute.
Since all other attributes match, we maybe looking at potentially different events or situa-tions involving the same entities, or occurring atthe same location or time.
The purpose of the clari-fication dialogue in this case is to probe which ofthese topics may be of interest to the user.
This isillustrated in the exchange below recorded duringan evaluation session with an intelligence analyst:User: ?Who is Elizardo Sanchez?
?HITIQA: ?Are you interested in seeing informationabout civil rights as it is related to Elizardo Sanchez?ONE-CONFLICT FRAMETOPIC: civil_rightsSUB-TOPIC: []LOCATION: [Cuba, Cuba, Cuba]COMPANIES: []PEOPLE: [Sanchez, Sanchez]DOCUMENT DATE: [2000, 1, 11]SOURCE: HAVANA (AP) ?TEXT: [``I consider that the situation for civil and politicalrights in Cuba has worsened over the past year... owing tothat Cuba continues to be the only closed society in this hemi-sphere,'' Sanchez said.
``There have been no significant re-lease of prisoners, the number of people sanctioned or proc-essed for political motives increased.
Sanchez, who himselfspent many years in Cuban prisons, is among the communistisland's best known opposition activists.
The commission heheads issues a report on civil rights every six months, alongwith a list of people it considers to be imprisoned for politicalmotives.
]Figure 5: One of the Frames that were used in generat-ing Sanchez  dialogue.
Words in bold were used to fillthe Frame.In order to understand what happened here, weneed to note first that the Goal Frame for the userquestion does not have any specific value assignedto its TOPIC attribute.
This of course is as we wouldexpect it: the question does not give us a hint as towhat information we need to look for or may behoping to find about Sanchez.
This also means thatall the text frames obtained from the retrieved setfor this question will have at least one conflict,near-misses.
One such text frame is shown in Fig-ure 5: its topic is ?civil rights?
and it about San-chez.
HITIQA thus asks if ?civil rights?
is a topicof interest to the user.
If the user responds posi-tively, this topic will be added to the answer space.The above dialogue strategy is applicable toother attribute mismatch cases, and produces intel-ligent-sounding responses from the system.
Duringthe dialogue, as new information is obtained fromthe user, the Goal Frame is updated and the scoresof all the data frames are reevaluated.
The systemmay interpret the new information as a positive ornegative.
Positives are added to the Goal Frame.Negatives are stored in a Negative-Goal Frame andwill also be used in the re-scoring of the dataframes, possibly causing conflict scores to in-crease.
The Negative-Goal Frame is created whenHITIQA receives a negative response from theuser.
The Negative-Goal Frame includes informa-tion that HITIQA has identified as being of no in-terest to the user.
If the user responds the equiva-lent of ?yes?
to the system clarification question  inthe Sanchez dialogue, civil_rights will be added tothe topic list in the Goal Frame and all one-conflictframes with a civil_rights topic will be re-scored toZero conflicts, two-conflict frames withcivil_rights as a topic will be rescored to one, etc.If the user responds ?no?, the Negative-GoalFrame will be generated and all frames withcivil_rights as a topic will be rescored to 99 in or-der to remove them from further processing.The clarification dialogue will continue on thetopic level until all the significant sets of NEAR-MISS frames are either included in the answerspace (through user broadening the scope of thequestion that removes the initial conflicts) or dis-missed as not relevant.
When HITIQA reaches thispoint it will re-evaluate the data frames in its an-swer space.
If there are too many answer framesnow (more than a pre-determined upper threshold),the dialogue manager will offer to the user to nar-row the question using another frame attribute.
Ifthe size of the new answer space is still too small(i.e., there are many unresolved near-miss  frames),the dialogue manager will suggest to the user waysof further broadening the question, thus makingmore data frames relevant, or possibly retrievingnew documents by adding terms acquired throughthe clarification dialogue.
When the number offrames is within the acceptable range, HITIQA willgenerate the answer using the text from the framesin the current answer space.
The user may end thedialogue at any point and have an answer gener-ated given the current state of the frames.9.1   Narrowing DialogueHITIQA attempts to reduce the number of framesjudged to be relevant through a Narrowing Dia-logue.
This is done when the answer space con-tains too many elements to form a succinct answer.This typically happens when the initial questionturns out to be too vague or unspecific, with re-spect to the available data.9.2   Broadening DialogueAs explained before, the system may attempt toincrease the number of frames judged relevantthrough a Broadening Dialogue (BD), wheneverthe answer space appears too narrow, i.e., containstoo few zero-conflict frames.
We are conductingfurther experiments to define this situation moreprecisely.
Currently, the BD will only occur ifthere are one-conflict frames, or near misses.Broadening questions can be asked about any ofthe attributes which have values in the Goal Frame.10   Answer GenerationCurrently, the answer is simply composed of textpassages from the zero conflict frames.
The text ofthese frames are ordered by date and outputted tothe user.
Typically the answer to these analyticaltype questions will require many pages of informa-tion.
Example 1 below shows the first portion ofthe answer generated by HITIQA for the Black Seaquery.
Current work is focusing on answer genera-tion.2002:The Black Sea is widely recognized as one of the re-gional seas most damaged by human activity.
Almostone third of the entire land area of continental Europedrains into this sea?
major European rivers, the Da-nube, Dnieper and Don, discharge into this sea while itsonly connection to the world's oceans is the narrowBosphorus Strait.
The Bosphorus is as little as 70 me-ters deep and 700 meters wide but the depth of theBlack Sea itself exceeds two kilometers in places.
Con-taminants and nutrients enter the Black Sea via riverrun-off mainly and by direct discharge from land-basedsources.
The management of the Black Sea itself is theshared responsibility of the six coastal countries: Bul-garia, Georgia, Romania, Russian Federation, Turkey,and Ukraine?Example 1: Partial answer generated by HITIQA to theBlack Sea query.11   EvaluationsWe have just completed the first round of a pilotevaluation for testing the interactive dialogue com-ponent of HITIQA.
The purpose of this first stageof evaluation is to determine what kind of dialogueis acceptable/tolerable to the user and whether anefficient navigation though the answer space ispossible.
HITIQA was blindly tested by two dif-ferent analysts on eleven different topics.
Fivedifferent groups participated, but no analyst testedmore than one system, as system comparison wasnot a goal.
The analysts were given complete free-dom in forming their queries and responses toHITIQA?s questions.
They were only providedwith descriptions of the eleven topics the systemswould be tested on.
The analysts were given 15minutes for each topic to arrive at what they be-lieved to be an acceptable answer.
During testing aWizard (human) was allowed to intervene ifHITIQA generated a dialogue question/responsethat was felt inappropriate.
The Wizard was able tooverride the system and send a Wizard generatedquestion/response to the analyst.
The HITIQAWizard intervened an average of 13% of the time.These results are for information purposes onlyas it was not a formal evaluation.
HITIQA earnedan average score of 5.8 from both Analysts for dia-logue, where 1 was ?extremely dissatisfied?
and 7was ?completely satisfied?.
The highest score pos-sible was a 7 for each dialogue.
The Analysts wereasked to grade each scenario for success or failure.We divide the failures from both analysts into threecategories:1) the user gives up on the system for thegiven scenario(9%)2) the 15 minute time limit was up(13%)3) the data was not in the database(9%)HITIQA had a 63% success rate for Analyst 1 anda 73% success rate for Analyst 2.
It is unclear howthese results should be interpreted, if at all, as theevaluation was a mere pilot, mostly to test the me-chanics of the setup.
We know only that a humanWizard equipped with all necessary informationcan easily achieve 100% success in this test.
Whatis still needed is a baseline performance, perhapsbased on using an ordinary keyword-based searchengine.12   Future WorkThis paper describes a work in progress.
We ex-pect that the initial specification of content framewill evolve as we subject the initial system to moredemanding evaluations.
Currently, the frames arenot topically specialized, and this appears the mostlogical next refinement, i.e., develop several (10-30) types of frames covering different classes ofevents, from politics to medicine to science to in-ternational economics, etc.
This is expected to in-crease the accuracy of the dialogue as is the inter-active visualization which is also under develop-ment.
Answer generation will involve fusion ofinformation on the frame level, and is currently inan initial phase of implementation.AcknowledgementsThis paper is based on work supported by the AdvancedResearch and Development Activity (ARDA)?s Ad-vanced Question Answering for Intelligence(AQUAINT) Program under contract number 2002-H790400-000.ReferencesJ.
Allen.
and Core.
1997.
Draft of DAMSL:  Dialog ActMarkup in Several Layers.http://www.cs.rochester.edu/research/cisd/ resources/damsl/Bagga, A., T. Strzalkowski, and G.B.
Wise.
2000.
PartsID: ADialog-Based System for Identifying Parts for MedicalSystems.
Proc.
of the ANLP-NAACL-2.Chris Buckley.
May 1985.
Implementation of the Smart in-formation retrieval system.
Technical Report TR85-686,Department of Computer Science, Cornell University,Ithaca, NY.James P. Callan, W. Bruce Croft, Stephen M. Harding 1992.The INQUERY Retrieval System.
Proc.
of DEXA-92, 3rdInternational Conference on Database and Expert SystemsApplications.
78-83.Cunningham, H., D. Maynard, K. Bontcheva, V. Tablan andY.
Wilks.
2000 Experience of using GATE for NLP R&D.In Coling 2000 Workshop on Using Toolsets and Architec-tures To Build NLP Systems.DARPA Communicator Program.
2002.http://www.darpa.mil/iao/communicatorGrinstein, G.G., Levkowitz, H., Pickett, R.M., Smith, S.
1993.?Visualization alternatives: non-pixel based images,?Proc.
of IS&T 46th Annual Conf.
132-133.George Ferguson and James Allen.
1998.
"TRIPS: An Intelli-gent Integrated Problem-Solving Assistant," in Proc.
ofthe Fifteenth National Conference on Artificial Intelli-gence (AAAI-98), Madison, WI.
567-573.H.
Hardy, N. Shimizu, T. Strzalkowski, L. Ting, B.
Wise andX.
Zhang 2002a.
Cross-Document Summarization byConcept Classification.
Proceedings of SIGIR-2002, Tam-pere, Finland.H.
Hardy, K. Baker, L. Devillers, L. Lamel, S. Rosset, T.Strzalkowski, C. Ursu and N. Webb.
2002b.
Multi-layerDialogue Annotation for Automated Multilingual Cus-tomer Service.
ISLE Workshop, Edinburgh, Scotland.Harabagiu, S., M. Pasca and S. Maiorano.
2000.
Experimentswith Open-Domain Textual Question Answering.
In Proc.of COLING-2000.
292-298.Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell,H.
Cunningham, Y. Wilks.
1998.
Description of theLaSIE-II System as Used for MUC-7.
In Proceedings ofthe Seventh Message Understanding Conference (MUC-7.
)Judith Hochberg, Nanda Kambhatla and Salim Roukos.
2002.A Flexible Framework for Developing Mixed-InitiativeDialog Systems.
Proc.
of 3rd SIGDIAL Workshop on Dis-course and Dialogue, Philadelphia.Hovy, E., L. Gerber, U. Hermjakob, M. Junk, C-Y.
Lin.
2000.Question Answering in Webclopedia.
Notebook Proceed-ings of Text Retrieval Conference (TREC-9).Johnston, M., Ehlen, P., Bangalore, S., Walker., M., Stent, A.,Maloor, P., and Whittaker, S. 2002.
MATCH: An Archi-tecture for Multimodal Dialogue Systems.
In Meeting ofthe Association for Computational Linguistics , 2002.Diane J. Litman and Shimei Pan.
Designing and Evaluating anAdaptive Spoken Dialogue System.
2002.
User Modelingand User-Adapted Interaction.
12(2/3):111-137.Miller, G.A.
1995.
WordNet: A Lexical Database.
Comm.
ofthe ACM, 38(11):39-41.John Prager, Dragomir R. Radev, and Krzysztof Czuba.
An-swering what-is questions by virtual annotation.
In HumanLanguage Technology Conference, Demonstrations Sec-tion, San Diego, CA, 2001.S.
Seneff and J. Polifroni, ``Dialogue Management in theMERCURY Flight Reservation System,'' Proc.
ANLP-NAACL 2000, Satellite Workshop, 1-6, Seattle, WA, 2000.Marilyn A. Walker.
An Application of Reinforcement Learn-ing to Dialogue Strategy Selection in a Spoken DialogueSystem for Email .
Journal of Artificial Intelligence Re-search.12:387-416.W.
Ward and B. Pellom.
1999.
The CU Communicator Sys-tem.
IEEE ASRU.
341-344.
