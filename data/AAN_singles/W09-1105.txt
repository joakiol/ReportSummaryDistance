Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 21?29,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA metalearning approach to processing the scope of negationRoser Morante, Walter DaelemansCNTS - Language Technology GroupUniversity of AntwerpPrinsstraat 13, B-2000 Antwerpen, Belgium{Roser.Morante,Walter.Daelemans}@ua.ac.beAbstractFinding negation signals and their scope intext is an important subtask in information ex-traction.
In this paper we present a machinelearning system that finds the scope of nega-tion in biomedical texts.
The system combinesseveral classifiers and works in two phases.To investigate the robustness of the approach,the system is tested on the three subcorporaof the BioScope corpus representing differenttext types.
It achieves the best results to datefor this task, with an error reduction of 32.07%compared to current state of the art results.1 IntroductionIn this paper we present a machine learning systemthat finds the scope of negation in biomedical texts.The system works in two phases: in the first phase,negation signals are identified (i.e., words indicatingnegation), and in the second phase the full scope ofthese negation signals is determined.
Although thesystem was developed and tested on biomedical text,the same approach can also be used for text fromother domains.Finding the scope of a negation signal means de-termining at sentence level the sequence of words inthe sentence that is affected by the negation.
Thistask is different from determining whether a word isnegated or not.
For a sentence like the one in Exam-ple (1) taken from the BioScope corpus (Szarvas etal., 2008), the system detects that lack, neither, andnor are negation signals; that lack has as its scopelack of CD5 expression, and that the discontinuousnegation signal neither ... nor has as its scope nei-ther to segregation of human autosome 11, on whichthe CD5 gene has been mapped, nor to deletion ofthe CD5 structural gene.
(1) <sentence id=?S334.5?>Analysis at the phenotype andgenetic level showed that <xcope id?X334.5.3?><cuetype=?negation?
ref=?X334.5.3?>lack</cue> of CD5expression</xcope> was due <xcope id=?X334.5.1?><cue type=?negation?
ref=?X334.5.1?>neither</cue>to segregation of human autosome 11, on which the CD5gene has been mapped, <cue type=?negation?ref=?X334.5.1?>nor</cue> to deletion of the CD5structural gene</xcope>.</sentence>Predicting the scope of negation is relevant fortext mining and information extraction purposes.
AsVincze et al (2008) put it, extracted information thatfalls in the scope of negation signals cannot be pre-sented as factual information.
It should be discardedor presented separately.
Szarvas et al (2008) reportthat 13.45% of the sentences in the abstracts sectionof the BioScope corpus and 12.70% of the sentencesin the full papers section contain negations.
A sys-tem that does not deal with negation would treat thefacts in these cases incorrectly as positives.
Addi-tionally, information about the scope of negation isuseful for entailment recognition purposes.The approach to the treatment of negation in NLPpresented in this paper was introduced in Morante etal.
(2008).
This system achieved a 50.05 percent-age of correct scopes but had a number of impor-tant shortcomings.
The system presented here usesa different architecture and different classificationtask definitions, it can deal with multiword negationsignals, and it is tested on three subcorpora of theBioScope corpus.
It achieves an error reduction of2132.07% compared to the previous system.The paper is organised as follows.
In Section 2,we summarise related work.
In Section 3, we de-scribe the corpus on which the system has been de-veloped.
In Section 4, we introduce the task to beperformed by the system, which is described in Sec-tion 5.
Results are presented and discussed in Sec-tion 6.
Finally, Section 7 puts forward some conclu-sions.2 Related workNegation has been a neglected area in open-domainnatural language processing.
Most research hasbeen performed in the biomedical domain and hasfocused on detecting whether a medical term isnegated or not, whereas in our approach we focuson detecting the full scope of negation signals.Chapman et al (2001) developed NegEx, a reg-ular expression based algorithm for determiningwhether a finding or disease mentioned within nar-rative medical reports is present or absent.
The re-ported results are 94.51% precision and 77.84% re-call.
Mutalik et al (2001) developed Negfinder, arule-based system that recognises negated patternsin medical documents.
It consists of two tools: a lex-ical scanner that uses regular expressions to generatea finite state machine, and a parser.
The reported re-sults are 95.70% recall and 91.80% precision.Sanchez-Graillet and Poesio (2007) present ananalysis of negated interactions in 50 biomedicalarticles and a heuristics-based system that extractssuch information.
The preliminary results reportedrange from 54.32% F-score to 76.68%, dependingon the method applied.
Elkin et al (2005) describe arule-based system that assigns to concepts a level ofcertainty as part of the generation of a dyadic parsetree in two phases: First a preprocessor breaks eachsentence into text and operators.
Then, a rule basedsystem is used to decide if a concept has been pos-itively, negatively, or uncertainly asserted.
The sys-tem achieves 97.20% recall and 98.80% precision.The systems mentioned above are essentiallybased on lexical information.
Huang andLowe (2007) propose a classification scheme ofnegations based on syntactic categories and patternsin order to locate negated concepts, regardless oftheir distance from the negation signal.
Their hy-brid system that combines regular expression match-ing with grammatical parsing achieves 92.60% re-call and 99.80% precision.
Additionally, Boytchevaet al (2005) incorporate the treatment of negationin a system, MEHR, that extracts from electronichealth records all the information required to gen-erate automatically patient chronicles.
They report57% of negations correctly recognised.The above-mentioned research applies rule-basedalgorithms to negation finding.
Machine learningtechniques have been used in some cases.
Averbuchet al (2004) developed an algorithm that uses infor-mation gain to learn negative context patterns.
Gold-ing and Chapman (2003) experiment with NaiveBayes and Decision Trees to distinguish whether amedical observation is negated by the word not in acorpus of hospital reports.
They report a maximumof 90% F-score.Goryachev et al (2006) compare the perfor-mance of four different methods of negation de-tection, two regular expression-based methods andtwo classification-based methods trained on 1745discharge reports.
They show that the regularexpression-based methods show better agreementwith humans and better accuracy than the classifica-tion methods.
Like in most of the work mentioned,the task consists in determining whether a medi-cal term is negated.
Rokach et al (2008) present anew pattern-based algorithm for identifying contextin free-text medical narratives.The originality of thealgorithm lies in that it automatically learns patternssimilar to the manually written patterns for negationdetection.We are not aware of any research that has focusedon learning the full scope of negation signals outsidebiomedical natural language processing.3 Negation in the BioScope CorpusThe system has been developed using the BioScopecorpus (Szarvas et al, 2008; Vincze et al, 2008)1,a freely available resource that consists of medicaland biological texts.
In the corpus, every sentenceis annotated with information about negation andspeculation.
The annotation indicates the bound-aries of the scope and the keywords, as shown in (1)above.
In the annotation, scopes are extended to the1Web page: www.inf.u-szeged.hu/rgai/bioscope.22biggest syntactic unit possible, so that scopes havethe maximal length, and the negation signal is al-ways included in the scope.
The annotation guide-lines and the inter-annotator agreement informationcan be found on the web page.Clinical Papers Abstracts#Documents 1954 9 1273#Sentences 6383 2670 11871#Words 41985 60935 282243#Lemmas 2320 5566 14506Av.
length sentences 7.73 26.24 26.43% Sent.
1-10 tokens 75.85 11.27 3.17% Sent.
11-20 tokens 20.99 27.67 30.49% Sent.
21-30 tokens 2.94 29.55 35.93% Sent.
31-40 tokens 0.15 17.00 19.76% Sent.
> 40 tokens 0.01 0.03 10.63%Negation sentences 13.55 12.70 13.45#Negation signals 877 389 1848Av.
length scopes 4.98 8.81 9.43Av.
length scopes 4.84 7.61 8.06to the rightAv.
length scopes 6.33 5.69 8.55to the left% Scopes to the right 97.64 81.77 85.70% Scopes to the left 2.35 18.22 14.29Table 1: Statistics about the subcorpora in the BioScopecorpus and the negation scopes (?Av?.
stands for aver-age).The BioScope corpus consists of three parts: clin-ical free-texts (radiology reports), biological full pa-pers and biological paper abstracts from the GENIAcorpus (Collier et al, 1999).
Table 1 shows statisticsabout the corpora.
Negation signals are representedby one or more tokens.Only one negation signal (exclude) that occurs inthe papers subcorpus does not occur in the abstractssubcorpus, and six negation signals (absence of, ex-clude, favor, favor over, may, rule out that appear inthe clinical subcorpus do not appear in the abstractssubcorpus.
The negation signal no (determiner) ac-counts for 11.74 % of the negation signals in the ab-stracts subcorpus, 12.88 % in the papers subcorpus,and 76.65 % in the clinical subcorpus.
The nega-tion signal not (adverb) accounts for 58.89 % of thenegation signals in the abstracts subcorpus, 53.22 %in the papers subcorpus, and 6.72 % in the clinicalsubcorpus.The texts have been processed with the GENIAtagger (Tsuruoka and Tsujii, 2005; Tsuruoka et al,2005), a bidirectional inference based tagger that an-alyzes English sentences and outputs the base forms,part-of-speech tags, chunk tags, and named entitytags in a tab-separated format.
Additionally, we con-verted the annotation about scope of negation into atoken-per-token representation, following the stan-dard format of the 2006 CoNLL Shared Task (Buch-holz and Marsi, 2006), where sentences are sepa-rated by a blank line and fields are separated by asingle tab character.
A sentence consists of a se-quence of tokens, each one starting on a new line.4 Finding the scope of negationWe model the scope finding task as two consecutiveclassification tasks: a first one that consists of classi-fying the tokens of a sentence as being at the begin-ning of a negation signal, inside or outside.
This al-lows the system to find multiword negation signals.The second classification task consists of classi-fying the tokens of a sentence as being the first ele-ment of the scope, the last, or neither.
This happensas many times as there are negation signals in thesentence.
We have chosen this classification modelafter experimenting with two additional models thatproduced worse results: in one case we classifed to-kens as being inside or outside of the scope.
In an-other case we classified chunks, instead of tokens, asbeing inside or outside of the scope.5 System descriptionThe two classification tasks (identifying negationsignals and finding the scope) are implemented us-ing supervised machine learning methods trained onpart of the annotated corpus.5.1 Identifying negation signalsIn this phase, a classifier predicts whether a token isthe first token of a negation signal, inside a nega-tion signal, or outside of it.
We use IGTREE asimplemented in TiMBL (version 6.1.2) (Daelemanset al, 2007).
TiMBL2 is a software package thatcontains implementations of memory-based learn-ing algorithms like IB1 and IGTREE.
We also ex-perimented with IB1, but it produced lower results.2TiMBL can be downloaded from the web pagehttp://ilk.uvt.nl/timbl/.23The classifier was parameterised by using gain ra-tio for feature weighting.
The instances represent alltokens in the corpus and they have features of thetoken (lemma) and of the token context: word form,POS, and chunk IOB tag3 of one token to the leftand to the right; word form of the second token tothe left and to the right.
According to the gain ratioscores, the most informative feature is the lemma ofthe token, followed by the chunk IOB tag of the to-ken to the right, and the features relative to the tokento the left.The test file is preprocessed using a list of nega-tion signals extracted from the training corpus, thatare unambiguous in the training corpus.
The listcomprises the following negation signals: absence,absent, fail, failure, impossible, lack, loss, miss, neg-ative, neither, never, no, none, nor, not, unable, with-out.
Instances with this negation signals are directlyassigned their class.
The classifier predicts the classof the rest of tokens.5.2 Scope findingIn this phase three classifiers predict whether a tokenis the first token in the scope sequence, the last, orneither.
A fourth classifier is a metalearner that usesthe predictions of the three classifiers to predict thescope classes.
The three object classifiers that pro-vide input to the metalearner were trained using thefollowing machine learning methods:?
Memory-based learning as implemented in TiMBL(version 6.1.2) (Daelemans et al, 2007), a super-vised inductive algorithm for learning classificationtasks based on the k-nearest neighbor classificationrule (Cover and Hart, 1967).
In this lazy learningapproach, all training data is kept in memory andclassification of a new item is achieved by extrap-olation from the most similar remembered trainingitems.?
Support vector machines (SVM) as implemented inSVMlightV6.01 (Joachims, 1999).
SVMs are de-fined on a vector space and try to find a decisionsurface that best separates the data points into twoclasses.
This is achieved by using quadratic pro-gramming techniques.
Kernel functions can be usedto map the original vectors to a higher-dimensionalspace that is linearly separable.3Tags produced by the GENIA tagger that indicate if a tokenis inside a certain chunk, outside, or at the beginning.?
Conditional random fields (CRFs) as implementedin CRF++-0.51 (Lafferty et al, 2001).
CRFs de-fine a conditional probability distribution over labelsequences given a particular observation sequencerather than a joint distribution over label and ob-servation sequences, and are reported to avoid thelabel bias problem of HMMs and other learning ap-proaches.The memory-based learning algorithm was pa-rameterised by using overlap as the similarity met-ric, gain ratio for feature weighting, using 7 k-nearest neighbors, and weighting the class vote ofneighbors as a function of their inverse linear dis-tance.
The SVM was parameterised in the learningphase for classification, cost factor of 1 and biasedhyperplane, and it used a linear kernel function.
TheCRFs classifier used regularization algorithm L2 fortraining, the hyper-parameter and the cut-off thresh-old of features were set to 1.An instance represents a pair of a negation signaland a token from the sentence.
This means that alltokens in a sentence are paired with all negation sig-nals that occur in the sentence.
Negation signals arethose that have been classified as such in the previ-ous phase.
Only sentences that have negation signalsare selected for this phase.We started with a larger, extensive pool of 131features which encoded information about the nega-tion signal, the paired token, their contexts, and thetokens in between.
Feature selection experimentswere carried out with the memory-based learningclassifier.
Features were selected based on theirgain ratio, starting with all the features and elimi-nating the least informative features.
We also per-formed experiments applying the feature selectionprocess reported in Tjong Kim Sang et al (2005),a bi-directional hill climbing process.
However, ex-periments with this method did not produce a betterselection of features.The features of the first three classifers are:?
Of the negation signal: Chain of words.?
Of the paired token: Lemma, POS, chunk IOB tag,type of chunk; lemma of the second and third tokensto the left; lemma, POS, chunk IOB tag, and type ofchunk of the first token to the left and three tokensto the right; first word, last word, chain of words,and chain of POSs of the chunk of the paired tokenand of two chunks to the left and two chunks to the24right.?
Of the tokens between the negation signal and thetoken in focus: Chain of POS types, distance innumber of tokens, and chain of chunk IOB tags.?
Others: A feature indicating the location of the to-ken relative to the negation signal (pre, post, same).The fourth classifier, a metalearner, is also a CRFas implemented in CRF++.
The features of this clas-sifier are:?
Of the negation signal: Chain of words, chain ofPOS, word of the two tokens to the right and twotokens to the left, token number divided by the totalnumber of tokens in the sentence.?
Of the paired token: Lemma, POS, word of two to-kens to the right and two tokens to the left, tokennumber divided by the total number of tokens in thesentence.?
Of the tokens between the negation signal and thetoken in focus: Binary features indicating if thereare commas, colons, semicolons, verbal phrases orone of the following words between the negationsignal and the token in focus:Whereas, but, although, nevertheless, notwith-standing, however, consequently, hence, therefore,thus, instead, otherwise, alternatively, furthermore,moreover.?
About the predictions of the three classifiers: pre-diction, previous and next predictions of each ofthe classifiers, full sequence of previous and full se-quence of next predictions of each of the classifiers.?
Others: A feature indicating the location of the to-ken relative to the negation signal (pre, post, same).Negation signals in the BioScope corpus alwayshave one consecutive block of scope tokens, includ-ing the signal token itself.
However, the classifiersonly predict the first and last element of the scope.We need to process the output of the classifers inorder to build the complete sequence of tokens thatconstitute the scope.
We apply the following post-processing:(2) - If one token has been predicted as FIRST and oneas LAST, the sequence is formed by the tokensbetween first and last.- If one token has been predicted as FIRST andnone has been predicted as LAST, the sequence isformed by the token predicted as FIRST.- If one token has been predicted as LAST andnone as FIRST, the sequence will start at thenegation signal and it will finish at the tokenpredicted as LAST.- If one token has been predicted as FIRST andmore than one as LAST, the sequence will end withthe first token predicted as LAST after the tokenpredicted as FIRST, if there is one.- If one token has been predicted as LAST andmore than one as FIRST, the sequence will start atthe negation signal.- If no token has been predicted as FIRST andmore than one as LAST, the sequence will start atthe negation signal and will end at the first tokenpredicted as LAST after the negation signal.6 ResultsThe results provided for the abstracts part of the cor-pus have been obtained by performing 10-fold crossvalidation experiments, whereas the results providedfor papers and clinical reports have been obtained bytraining on the full abstracts subcorpus and testingon the papers and clinical reports subcorpus.
Thelatter experiment is therefore a test of the robustnessof the system when applied to different text typeswithin the same domain.The evaluation is made using the precision andrecall measures (Van Rijsbergen, 1979), and theirharmonic mean, F-score.
In the negation findingtask, a negation token is correctly classified if it hasbeen classified as being at the beginning or inside thenegation signal.
We also evaluate the percentage ofnegation signals that have been correctly identified.In the scope finding task, a token is correctly classi-fied if it has been correctly classified as being insideor outside of the scope of all the negation signals thatthere are in the sentence.
This means that when thereis more than one negation signal in the sentence, thetoken has to be correctly assigned a class for as manynegation signals as there are.
Additionally, we eval-uate the percentage of correct scopes (PCS).
A scopeis correct if all the tokens in the sentence have beenassigned the correct scope class for a specific nega-tion signal.
The evaluation in terms of precision andrecall measures takes as unit a token, whereas theevaluation in terms of PCS takes as unit a scope.256.1 Negation signal findingAn informed baseline system has been created bytagging as negation signals the tokens with thewords: absence, absent, fail, failure, impossible, in-stead of, lack, loss, miss, negative, neither, never, no,none, nor, not, rather than, unable, with the excep-tion of, without.
The list has been extracted from thetraining corpus.
Baseline results and inter-annotatoragreement scores are shown in Table 2.Corpus Prec.
Recall F1 Correct IAAAbstracts 100.00 95.17 97.52 95.09 91.46Papers 100.00 92.46 96.08 92.15 79.42Clinical 100.00 97.53 98.75 97.72 90.70Table 2: Baseline results of the negation finding systemand inter-annotator agreement (IAA) in %.Table 3 shows the results of the system, which aresignificantly higher than the results of the baselinesystem.
With a more comprehensive list of negationsignals it would be possible to identify all of them ina text.Corpus Prec.
Recall F1 CorrectAbstracts 100.00 98.75 99.37 98.68Papers 100.00 95.72 97.81 95.80Clinical 100.00 98.09 99.03 98.29Table 3: Results of the negation finding system in %.The lower result of the papers subcorpus is causedby the high frequency of the negation signal not inthis corpus (53.22 %), that is correct in 93.68 % ofthe cases.
The same negation signal is also frequentin the abstracts subcorpus (58.89 %), but in this caseit is correct in 98.25 % of the cases.
In the clinicalsubcorpus not has low frequency (6.72 %), whichmeans that the performance of the classifer for thisnegation signal (91.22 % correct) does not affect somuch the global results of the classifier.
Most errorsin the classification of not are caused by the systempredicting it as a negation signal in cases not markedas such in the corpus.
The following sentences aresome examples:(3) However, programs for tRNA identification [...] do notnecessarily perform well on unknown ones.The evaluation of this ratio is difficult because not alltrue interactions are known.However, the Disorder module does not contributesignificantly to the prediction.6.2 Scope findingAn informed baseline system has been created bycalculating the average length of the scope to theright of the negation signal in each corpus and tag-ging that number of tokens as scope tokens.
We takethe scope to the right for the baseline because it ismuch more frequent than the scope to the left, as isshown by the statistics contained in Table 1 of Sec-tion 3.Corpus Prec.
Recall F1 PCS PCS-2 IAAAbstracts 76.68 78.26 77.46 7.11 37.45 92.46Papers 69.34 66.92 68.11 4.76 24.86 70.86Clinical 86.85 74.96 80.47 12.95 62.27 76.29Table 4: Baseline results of the scope finding system andinter-annotator agreement (IAA) in %.Baseline results and inter-annotator agreementscores are presented in Table 4.
The percentageof correct scopes has been measured in two ways:PCS measures the proportion of correctly classifiedtokens in the scope sequence, whereas PCS-2 mea-sures the proportion of nouns and verbs that are cor-rectly classifed in the scope sequence.
This lessstrict way of computing correctness is motivated bythe fact that being able to determine the conceptsand relations that are negated (indicated by contentwords) is the most important use of the negationscope finder.
The low PCS for the three subcorporaindicates that finding the scope of negations is not atrivial task.
The higher PCS for the clinical subcor-pus follows a trend that applies also to the results ofthe system.
The fact that, despite a very low PCS,precision, recall and F1 are relatively high indicatesthat these measures are in themselves not reliable toevaluate the performance of the system.The upper-bound results of the metalearner sys-tem assuming gold standard identification of nega-tion signals are shown in Table 5.Corpus Prec.
Recall F1 PCS PCS-2Abstracts 90.68 90.68 90.67 73,36 74.10Papers 84.47 84.95 84.71 50.26 54.23Clinical 91.65 92.50 92.07 87.27 87.95Table 5: Results of the scope finding system with gold-standard negation signals.The results of the metalearner system are pre-sented in Table 6.
Results with gold-standard nega-26tion signals are especially better for the clinical sub-corpus because except for lack, negative and not,all negation signals score a PCS higher than 90 %.Thus, in the clinical subcorpus, if the negation sig-nals are identified, their scope will be correctlyfound.
This does not apply to the abstracts and pa-pers subcorpus.Corpus Prec.
Recall F1 PCS PCS-2Abstracts 81.76 83.45 82.60 66.07 66.93Papers 72.21 69.72 70.94 41.00 44.44Clinical 86.38 82.14 84.20 70.75 71.21Table 6: Results of the scope finding system with pre-dicted negation signals.In terms of PCS, results are considerably higherthan baseline results, whereas in terms of precision,recall and F1, results are slightly higher.
Com-pared to state of the art results (50.05 % PCS in(anonymous reference) for the abstracts subcorpus),the system achieves an error reduction of 32.07 %,which shows that the system architecture presentedin this paper leads to more accurate results.Evaluating the system in terms of a more relaxedmeasure (PCS-2) does not reflect a significant in-crease in its performance.
This suggests that whena scope is incorrectly predicted, main content to-kens are also incorrectly left out of the scope oradded.
An alternative to the PCS-2 measure wouldbe to mark in the corpus the relevant negated contentwords and evaluate if they are under the scope.Results also show that the system is portable todifferent types of documents, although performancevaries depending on the characteristics of the corpus.Clinical reports are easier to process than papers andabstracts, which can be explained by several factors.One factor is the length of sentences: 75.85 % ofthe sentences in the clinical reports have 10 or lesswords, whereas this rate is 3.17 % for abstracts and11.27 % for papers.
The average length of a sen-tence for clinical reports is 7.73 tokens, whereas forabstracts it is 26.43 and for papers 26.24.
Shortersentences imply shorter scopes.
In the scope findingphase, when we process the output of the classifiersto build the complete sequence of tokens that con-stitute the scope, we give preference to short scopesby choosing as LAST the token classified as LASTthat is the closest to the negation signal.
A way tomake the system better portable to texts with longersentences would be to optimise the choice of the lasttoken in the scope.Abstracts Papers Clinical# PCS # PCS # PCSabsence 57 56.14 - - - -absent 13 15.38 - - - -can not 28 42.85 16 50.00 - -could not 14 57.14 - - - -fail 57 63.15 13 38.46 - -lack 85 57.64 20 45.00 - -negative - - - - 17 0.00neither 33 51.51 - - - -no 207 73.42 44 50.00 673 73.10nor 43 44.18 - - - -none 7 57.14 10 0.00 - -not 1036 69.40 200 39.50 57 50.87rather than 20 65.00 12 41.66 - -unable 30 40.00 - - - -without 82 89.02 24 58.33 - -Table 7: PCS per negation signal for negation signals thatoccur more than 10 times in one of the subcorpus.Another factor that causes a higher performanceon the clinical subcorpus is the frequency of thenegation signal no (76.65 %), which has also a highPCS in abstracts, as shown in Table 7.
Typical ex-ample sentences with this negation signal are shownin (4).
Its main characteristics are that the scope isvery short (5 tokens average in clinical reports) andthat it scopes to the right over a noun phrase.
(4) No findings to account for symptoms.No signs of tuberculosis.The lower performance of the system on the pa-pers subcorpus compared to the abstracts subcorpusis due to the high proportion of the negation signalnot (53.22 %), which scores a low PCS (39.50), asshown in Table 7.
Table 7 also shows that, exceptfor can not, all negation signals score a lower PCSon the papers subcorpus.
This difference can notbe caused by the sentence length, since the averagesentence length in the abstracts subcorpus (26.43 to-kens) is similar to the average sentence length in thepapers subcorpus (26.24).
The difference may berelated to the difference in the length of the scopesand their direction.
For example, the average lengthof the scope of not is 8.85 in the abstracts subcorpusand 6.45 in the papers subcorpus.
The scopes to the27left for not amount to 23.28 % in the papers subcor-pus and to 16.41 % in the abstracts subcorpus, andthe average scope to the left is 5.6 tokens in the pa-pers subcorpus and 8.82 in the abstracts subcorpus.As for the results per negation signal on the ab-stracts corpus, the negation signals that score higherPCS have a low (none) or null (absence, fail, lack,neither, no, rather than, without) percentage ofscopes to the left.
An exception is not with a highscore and 16.41% of scopes to the left.
The negationsignals with lower PCS have a higher percentage ofscopes to the left (absent, can not, nor, unable).
Atypical error for the negation signal unable is exem-plified by the sentence VDR DNA-binding mutantswere unable to either bind to this element in vitroor repress in vivo, in which the gold scope starts atthe beginning of the sentence, where the predictedscopes starts at the negation signal.6.2.1 Results of the metalearner versus resultsof the first three classifiersThe choice of a metalearner approach has beenmotivated by the significantly higher results that themetalearner produces compared to the results of thefirst three classifiers.
The results of each of the clas-sifiers independently are presented in Table 8.Algor.
Ev.
Abstracts Papers ClinicalTiMBL Prec.
78.85 68.66 82.25Rec.
80.54 66.29 78.56F1 79.69 67.46 80.36PCS 56.80 33.59 70.87PCS-2 57.99 37.30 71.21CRF Prec.
78.49 68.94 93.42Rec.
80.16 66.57 80.24F1 79.31 67.73 86.33PCS 59.90 36.50 59.51PCS-2 60.04 38.88 59.74SVM Prec.
77.74 68.01 93.80Rec.
79.35 65.66 85.16F1 78.54 66.82 89.27PCS 56.80 33.33 82.45PCS-2 57.59 35.18 82.68Table 8: Results for the first three classifiers of the scopefinding system.PCS results show that the metalearner system per-forms significantly better than the three classifiersfor the abstracts and papers subcorpora, but not forthe clinical subcorpus, in which case TiMBL andSVM produce higher scores, although only the SVMresults are significantly better with a difference of11.7 PCS.
An analysis in detail of the SVM scoresper negation signal shows that the main differencebetween the scores of the metalearner and SVM isthat the SVM is good at predicting the scopes of thenegation signal no when it occurs as the first tokenin the sentence, like in (4) above.
When no occursin other positions, SVM scores 1.17 PCS better.We plan to perform experiments with the threeclassifiers using the features of the metalearner thatare not related to the predictions, in order to check ifthe three classifiers would perform better.7 ConclusionsIn this paper we have presented a metalearning ap-proach to processing the scope of negation signals.Its performance is evaluated in terms of percent-age of correct scopes on three test sets.
With 66.07% PCS on the abstracts corpus the system achieves32.07 % of error reduction over current state of theart results.
The architecture of the system is new forthis problem, with three classifiers and a metalearnerthat takes as input the output of the first classifiers.The classification task definition is also original.We have shown that the system is portable to dif-ferent corpora, although performance fluctuates de-pending on the characteristics of the corpora.
Theresults per corpus are determined to a certain extentby the scores of the negation signals no and not, thatare very frequent and difficult to process in some texttypes.
Shorter scopes are easier to learn as reflectedin the results of the clinical corpus, where no is themost frequent negation signal.
We have also shownthat the metalearner performs better than the threefirst classifiers, except for the negation signal no inclinical reports, for which the SVM classifier pro-duces the highest scores.Future research will deal with a more detailedanalysis of the errors by each of the three initial clas-sifiers compared to the errors of the metalearner inorder to better understand why the results of the met-alearner are higher.
We also would like to performfeature analysis, and test the system on general do-main corpora.28AcknowledgmentsOur work was made possible through financial sup-port from the University of Antwerp (GOA projectBIOGRAPH).
We are grateful to four anonymousreviewers for their valuable comments and sugges-tions.ReferencesM.
Averbuch, T. Karson, B. Ben-Ami, O. Maimon, andL.
Rokach.
2004.
Context-sensitive medical informa-tion retrieval.
In Proc.
of the 11th World Congresson Medical Informatics (MEDINFO-2004), pages 1?8, San Francisco, CA.
IOS Press.S.
Boytcheva, A. Strupchanska, E. Paskaleva, andD.
Tcharaktchiev.
2005.
Some aspects of negationprocessing in electronic health records.
In Proc.
ofInternational Workshop Language and Speech Infras-tructure for Information Access in the Balkan Coun-tries, pages 1?8, Borovets, Bulgaria.S.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In Proc.
of the XCoNLL Shared Task, New York.
SIGNLL.W.
W. Chapman, W. Bridewell, P. Hanbury, G. F. Cooper,and B.G.
Buchanan.
2001.
A simple algorithm foridentifying negated findings and diseases in dischargesummaries.
J Biomed Inform, 34:301?310.N.
Collier, H.S.
Park, N. Ogata, Y. Tateisi, C. Nobata,T.
Sekimizu, H. Imai, and J. Tsujii.
1999.
The GE-NIA project: corpus-based knowledge acquisition andinformation extraction from genome research papers.In Proceedings of EACL-99.T.
M. Cover and P. E. Hart.
1967.
Nearest neighborpattern classification.
Institute of Electrical and Elec-tronics Engineers Transactions on Information The-ory, 13:21?27.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A. Vanden Bosch.
2007.
TiMBL: Tilburg memory basedlearner, version 6.1, reference guide.
Technical ReportSeries 07-07, ILK, Tilburg, The Netherlands.P.
L. Elkin, S. H. Brown, B.
A. Bauer, C.S.
Husser,W.
Carruth, L.R.
Bergstrom, and D. L. Wahner-Roedler.
2005.
A controlled trial of automated classi-fication of negation from clinical notes.
BMC MedicalInformatics and Decision Making, 5(13).l.
M. Goldin and W.W. Chapman.
2003.
Learning todetect negation with ?Not?
in medical texts.
In Pro-ceedings of ACM-SIGIR 2003.S.
Goryachev, M. Sordo, Q.T.
Zeng, and L. Ngo.
2006.Implementation and evaluation of four different meth-ods of negation detection.
Technical report, DSG.Y.
Huang and H.J.
Lowe.
2007.
A novel hybrid approachto automated negation detection in clinical radiologyreports.
J Am Med Inform Assoc, 14(3):304?311.T.
Joachims, 1999.
Advances in Kernel Methods -Support Vector Learning, chapter Making large-ScaleSVM Learning Practical, pages 169?184.
MIT-Press,Cambridge, MA.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of ICML2001, pages 282?289.R.
Morante, A. Liekens, and W. Daelemans.
2008.
Acombined memory-based semantic role labeler of en-glish.
In Proc.
of the EMNLP 2008, pages 715?724,Honolulu, Hawaii.A.G.
Mutalik, A. Deshpande, and P.M. Nadkarni.
2001.Use of general-purpose negation detection to augmentconcept indexing of medical documents.
a quantita-tive study using the UMLS.
J Am Med Inform Assoc,8(6):598?609.L.
Rokach, R.Romano, and O. Maimon.
2008.
Negationrecognition in medical narrative reports.
InformationRetrieval Online.O.
Sanchez-Graillet and M. Poesio.
2007.
Negation ofprotein-protein interactions: analysis and extraction.Bioinformatics, 23(13):424?432.G.
Szarvas, V. Vincze, R. Farkas, and J. Csirik.
2008.The BioScope corpus: annotation for negation, uncer-tainty and their scopein biomedical texts.
In Proc.
ofBioNLP 2008, pages 38?45, Columbus, Ohio, USA.ACL.E.
Tjong Kim Sang, S. Canisius, A.van den Bosch, andT.
Bogers.
2005.
Applying spelling error correctiontechniques for improving semantic role labelling.
InProc.
of CoNLL 2005, pages 229?232.Y.
Tsuruoka and J. Tsujii.
2005.
Bidirectional in-ference with the easiest-first strategy for tagging se-quence data.
In Proc.
of HLT/EMNLP 2005, pages467?474.Y.
Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught,S.
Ananiadou, and J. Tsujii, 2005.
Advances in Infor-matics - 10th Panhellenic Conference on Informatics,volume 3746 of Lecture Notes in Computer Science,chapter Part-of-Speech Tagger for Biomedical Text,Advances in Informatics, pages 382?392.
Springer,Berlin/Heidelberg.C.J.
Van Rijsbergen.
1979.
Information Retrieval.
But-terworths, London.V.
Vincze, G. Szarvas, R. Farkas, G. Mo?ra, and J. Csirik.2008.
The BioScope corpus: biomedical texts anno-tated for uncertainty, negation and their scopes.
BMCBioinformatics, 9((Suppl 11)):S9.29
