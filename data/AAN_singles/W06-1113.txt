Proceedings of the Workshop on Linguistic Distances, pages 100?108,Sydney, July 2006. c?2006 Association for Computational LinguisticsVariants of tree similarity in a Question Answering taskMartin EmmsDept of Computer ScienceTrinity CollegeIrelandAbstractThe results of experiments on the appli-cation of a variety of distance measuresto a question-answering task are reported.Variants of tree-distance are considered,including whole-vs-sub tree, node weight-ing, wild cards and lexical emphasis.
Wederive string-distance as a special caseof tree-distance and show that a particu-lar parameterisation of tree-distance out-performs the string-distance measure.1 IntroductionThis paper studies the deployment in a ques-tion answering task of methods which assess thesimilarity of question and answer representations.Given questions such asQ1 what does malloc return ?Q2 What year did poet Emily Dickinson die?and a collection of sentences (eg.
a computer man-ual, a corpus of newspaper articles), the task is toretrieve the sentences that answer the question, eg.A1 the malloc function returns a null pointerA2 In 1886 , poet Emily Dickinson died in Amherst , MassOne philosophy for finding answers to ques-tions would be to convert questions and candidateanswers into logical forms and to compute answer-hood by apply theorem-proving methods.
Anotherphilosophy is to assume that the answers are simi-lar to the questions, where similarity might be de-fined in many different ways.
While not all an-swers to all questions will be similar, there?s anintuition that most questions can be answered ina way which shares quite a bit with the question,and that accordingly with a large enough corpus, asimilarity-based approach could be fruitful.2 Distance MeasuresIn pursuing such a similarity-based approach toquestion-answering, the key decisions to be madeare the representations of the questions and an-swers, and relatedly, distance measures betweenthem.We will primarily be concerned with measureswhich refer to a linguistic structure assigned to aword sequence ?
variants of tree-distance, but wewill also consider string-distance.2.1 Tree MeasuresFollowing (Zhang and Shasha, 1989), one can ar-rive at tree-distance in the following way.
Givensource and target ordered, labelled trees, S andT , consider the set H(S, T ) of all 1-to-1 par-tial maps, ?, from S into T , which are homo-morphisms preserving left-to-right order and an-cestry1.
Let the alignment, ?
?, be the enlarg-ment of the map ?
with pairs (Si, ?)
for nodesSi 6?
dom(?)
and (?, Tj) for nodes Tj 6?
ran(?
).Let D define deletion costs for the (Si, ?
), I inser-tion costs for the (?, Tj), and R replacement costsfor the (Si, Tj) which represent nodes with non-identical labels.
Then a total cost for the align-ment, C(??)
can be defined as the sum of thesecomponents costs, and the tree distance can thenbe defined as the cost of the least-cost map:?
(S, T ) = min({C(??)
| ?
?
H(S, T )})For any 3 trees, T 1, T 2, T 3, the triangle inequal-ity holds ?
(T 1, T 3) ?
?
(T 1, T 2) + ?
(T 2, T 3).1If Tj1 = ?
(Si1) and Tj2 = ?
(Si2) then (i) Si1 is to theleft of Si2 iff Tj1 is to the left of Tj2 and (ii) Si1 is a descen-dant of Si2 iff Tj1 is a descendant of Tj2 , with descendencyunderstood as the transitive closure of the daugher-mother re-lation.100Briefly the argument is as follows.
Given map-pings ?
?
H(T 1, T 2), and ?
?
H(T 2, T 3), ???
?H(T 1, T 3)2, so (?
?
?)?
is an alignment betweenT 1 and T 3, and ?
(T 1, T 3) ?
C((?
?
?)?).
Thecost of the composition is less than the sum of thecosts of the composed maps: ?
?s insertions and re-placements contribute only if they fall in dom(?),?
?s deletions and replacements contribute only ifthey act on ran(?
).From this basic definition, one can depart ina number of directions.
First of all, there is apart-vs-whole dimension of variation.
Where?
(S, T ) gives the cost of aligning the wholesource tree S with the target T , one can considervariants where one minimises over a set of sub-parts of S. This is equivalent to letting all but thenodes belonging to the chosen sub-part to deleteat zero cost3.
Let ?
(S, T ) be the sub-tree dis-tance.
Let ~?
(S, T ), be the sub-traversal distance,in which sub-traversals of the left-to-right, post-order traversal of S are considered.
As for ?, thetriangle inequality holds for ?
and ~?
?
one needsto extend the notion of alignment with a set of freedeletions.
Unlike ?, ?
and ~?
are not symmetric.All of ?, ?
and ~?
are implicitly parametrised bythe cost functions, D, I and R. In the work below4 other parameters are exploredNode weighting W: this is a function whichassigns a real-number weight to each eachnode.
The cost function then refers to theweights.
In experiments reported below,Dw((Si, w), ?)
= w, Iw(?, (Tj , w)) = w,Rw((Si, ws), (Tj , wt)) = max(ws, wt), ifSi and Tj have unequal labels.
The experi-ments reported below use 2 weighting func-tion ST R, and LEX .
ST R assign weightsaccording to the syntactic structure, via aclassification of nodes as heads vs. comple-ments vs. adjuncts vs. the rest, with es-sentially adjuncts given 1/5th the weights ofheads and complements, and other daughters1/2, via essentially the following top-downalgorithm:Str(node, rank) :assign weight 1/rank to nodefor each daughter d2?x ?
T1?z ?
T3((x, z) ?
?
?
?
iff ?y ?
T2((x, y) ?
?, (y, z) ?
?
)3Note that if one minimises also over sub-parts of the tar-get, you do not get an interesting notion, as the minimum willinevitably involve at most one node of source and target.if (d is head or complement){assign weight = 1/rank,Str(rank, d) }else if (d is adjunct) {assign weight = 1/(5 ?
rank),Str(5 ?
rank, d)}else {assign weight = 1/(2 ?
rank)Str(2 ?
rank, d) }LEX is a function which can be composedwith ST R, and scales up the weights of leafnodes by a factor of 3.Target wild cards T (?
): this is a function whichclassifies certain target sub-trees as wild-card.
If source Si is mapped to target Tj , andTj is the root of a wild-card tree, all nodeswithin the Si sub-tree can be deleted for 0cost, and all those within the Tj sub-tree canbe inserted for 0 cost.
A wild card np treemight can be put in the position of the gap inwh-questions, allowing for example what ismemory allocation, to closely match any sen-tences with memory allocation as their ob-ject, no matter what their subject ?
see Fig-ure 3.Source self-effacers S/?
: this is a functionwhich classifies source sub-trees as self-effacers.
Such trees can be deleted intheir entirety for zero cost.
If S/?
clas-sifies all source sub-trees as self-effacing,then ?(S/?)
will coincide with notion of?tree-distance with Cut?
given in (Zhang andShasha, 1989).Target self-inserters ?/T : this is a functionwhich classifies certain target sub-trees asself-inserters.
Such trees can be inserted intheir entirety for zero cost.
A candidate mightbe optional adjuncts.42.2 Sequence MeasuresThe tree-distance measures work with an elabora-tion of the original questions and answers.
(Lev-enshtein, 1966) defined the 1 dimensional precur-sor of tree distance, which works directly on the2 word sequences for the answer and question.For two sequences, s, t, and vertical (or hori-zontal) tree encodings l tree(s) and l tree(t), if4Thus a target wild-card is somewhat like a target self-effacer, but one which also licenses the classification of amatched source sub-tree as a being self-effacer.101processnnpsvprhslhs be rhslhsvpcall bememorynnnallocationnp somethingpronpsvplhs rhsmemorynnnallocationnpsub tree matching dist=5.0Figure 1: Sub tree examplewe define ?
(s, t), as ?
(l tree(s), l tree(t)), and?
(s, t), as ~?
(l tree(s), l tree(t)), then ?
and ?coincide with the standard sequence edit distanceand sub-sequence edit distance.
As special casesof ?
and ?, ?
and ?
inherit the triangle inequalityproperty.To illustrate some of the tree-distance defini-tions, in the following example, a ?
distance of3 between 2 trees is obtained, assuming unit costsfor deletions (shown in red and double outline), in-sertions (shown in green and double outline), andsubstitutions (shown in blue and linked with an ar-row):abbaacbab b aawhole tree matching dist=3.0Note also in this picture that nodes that are mappedwithout a relabelling are shown at the same hori-zontal level, with no linking arrow.Figure 1 shows a sub-tree example ?
?.
Thesource tree nodes which do not belong to the cho-sen sub-tree are shown in grey.
The lowest vp sub-tree in the source is selected, and mapped to thevp in the target.
The remaining target nodes mustbe inserted, but this costs less than a match whichstarts higher and necessitates some deletions andsubstitutions.Figure 2 shows a sub-tree example where thestructural weighting ST R has been used: size ofa node reflects the weight.
4 of the nodes in thesource represent the use of an auxiliary verb, andreceive low weight, changing the optimum matchto one covering the whole source tree.
There issome price paid in matching the dissimilar subjectnps.process somethingn pronpsvprhslhs be rhslhsvpcall bememorynnnallocationnpnpsvplhs rhsmemorynnnallocationnpsub tree matching dist=3.6Figure 2: Structurally weighted exampleFigure 3 continues the example, but this timein the subject position there is a sub-tree which isclassified as a wild-card np tree, and it matches at0 cost with the subject np in the source tree.processnnp np_wildsvprhslhs be rhslhsvpcall bememorynnnallocationnpsomethingprosvplhsrhsmemorynnnallocationnpsub tree matching dist=1.6Figure 3: Wild-card exampleThe basis of the algorithm used to calculate ?is the ZhangShasha algorithm (Zhang and Shasha,1989): the Appendix summarises it.
The im-102plementation is based on code implementing ?
(Fontana et al, 2004), adapting it to allowing forthe ?
and ~?
variants and T (?
), S/?, and ?/T pa-rameters, and to generate the human-readable dis-plays of the alignments (such as seen in figures 1,2and 3).2.3 Order invariant measuresAssessing answer/question similarity by variantsof tree distance or sequence edit-distance, meansthat distance will not be word-order invariant.There are also measures which are word-order in-variant, sometimes called token-based measures.These measures are usually couched in a vectorrepresentation of questions and answers, wherevector dimensions are words from (some cho-sen enumeration) of words (see (Salton and Lesk,1968)).
In the simplest case the values on eachdimensions are in {0, 1}, denoting presence or ab-sence of a word.
If ?
is vector product and awis the set of words in a sequence a, then ~a ?~b =|aw ?
bw|, for the binary vectors representing aw,bw.
Three well known measures based on this aregiven below, both in terms vectors, and for binaryvectors, the equivalent formulation with sets:Dice 2(~a ?~b)/(~a ?
~a) + (~b ?~b))= 2(|aw ?
bw|)/(|aw |+ |bw|)Jaccard (~a ?~b)/(~a ?
~a) +~b ?~b?
~a ?~b)= (|aw ?
bw|)/(|aw ?
bw)Cosine (~a ?~b)/(~a ?
~a).5(~b ?~b).5= (|aw ?
bw|)/((|aw |)0.5(|bw|)0.5)These measure similarity, not difference, rangingfor 1 for identical aw,bw, to 0 for disjoint.
Inthe binary case, Dice/Jaccard similarity can berelated to the alignment-based, difference count-ing perspective of the edit-distances.
If we de-fine ?w(a, b) as |aw ?
bw| ?
|aw ?
bw| ?
the sizeof the symmetric difference between aw and bw ?this can be seen as a set-based version of edit dis-tance5, which (i) considers mappings on the sets ofwords, aw, bw, not the sequences a, b, and (ii) setsreplacement cost to infinity.
A difference measure(ranging from 0 for identical aw,bw to 1 for dis-joint) results if ?w(a, b) is divided by |aw| + |bw|(resp.
|aw ?
bw|) and this difference measures willgive the reverse of a ranking by Dice (resp.
Jac-card) similarity.The Cosine is a measure of the angle be-tween the vectors ~a,~b, and is not relatable in the5?w(a, b) could be equivalently defined as |(~a ?~b)|2binary-case to the alignment-based, difference-counting perspective of the edit-distances: di-viding ?w(a, b), the symmetric difference, by|aw|.5|bw|.5 does not give a measure with maxi-mum value 1 for the disjoint case, and does notgive the reverse of a ranking by Cosine similarity.6Below we shall use ?
to denote the Cosine dis-tance.3 The Question Answering TasksFor a given representation r (parse trees, word se-quences etc.
), and distance measure d, we shallgenerically take a Question Answering by Dis-tance (QAD) task to be given by a set of queries,Q, and for each query q, a corpus of potential an-swer sentences, CORq.
For each a ?
CORq, thesystem determines d(r(a), r(q)), the distance be-tween the representations of a and q, then uses thisto sort CORq into Aq.
This sorting is then evalu-ated in the following way.
If ac ?
Aq is the correctanswer, then the correct-answer-rank is the rankof ac in Aq:| {a ?
Aq : d(r(a), r(q)) ?
d(r(ac), r(q))} |whilst the correct-answer-cutoff is the proportionof Aq cut off by the correct answer ac:| {a ?
Aq : d(r(a), r(q)) ?
d(r(ac), r(q))} | / | Aq |Lower values for this connote better performance.Another figure of merit is the reciprocal correct-answer-rank.
Higher values of this connote betterperformance.Note the notion of answerhood is not one requir-ing answers to be the sub-sentential phrases asso-ciated with wh-phrases in the question.
Also notall the questions are wh-questions.Note also that the set of candidate answersCORq is sorted by the answer-to-query distance,d(r(a), r(q)), not the query-to-answer distance,d(r(q), r(a)).
The intuition is that the queries areshort and the answers longer, with sub-part that re-ally contains the answer.The performance of some of the above men-tioned distance measures on 2 examples of QADtasks has been measured:GNU Library Manual QAD Task: inthis case Q is a set of 88 hand-created6if the vectors are normalised by their length, then youcan show |(~a/|~a| ?~b/|~b|)|2 reverses the Cosine ranking103queries, and CORq, shared by all thequeries, is the sentences of the manualof the GNU C Library7 (| CORq |?31, 000).The TREC 11 QAD task: In thiscase Q was the 500 questions of theTREC11 QA track (Voorhees and Buck-land, 2002), whose answers are drawnfrom a large corpus of newspaper arti-cles.
CORq was taken to be the sen-tences of the top 50 from the top-1000ranking of articles provided by TREC11for each question (| CORq |?
1000).Answer correctness was determined us-ing the TREC11 answer regular expres-sions.For the tree-distance measures, 2 parsing sys-tems have been used.
For convenience of refer-ence, we will call the first parser, the trinity parser.This is a home-grown parser combining a disam-biguating part-of-speech tagger with a bottom-upchartparser, refering to CFG-like syntax rules anda subcategorisation system somewhat in a catego-rial grammar style.
Right-branching analyses areprefered and a final selection of edges from allavailable is made using a leftmost/longest selec-tion strategy ?
there is always an output regardlessof whether there is a single input-encompassingedge.
Preterminal node labels are a combinationof a main functor with other feature terms, but thereplacement cost function R is set to ignore thefeature terms.
Terminal node labels are base formsof words, not inflected forms.
For the structuralweighting algorithm, ST R, the necessary nodedistinctions are furnished directly by the parser forvp, and by a small set of structure matching rulesfor other structures (nps, pps etc).
The structuresoutput for wh-questions are essentially deep struc-tures, re-ordering an auxiliary inversion, and plac-ing a tree in the position of a gap.The Collins parser (Collins, 1999) (Model 3variant) is a probabilistic parser, using a model oftrees as built top-down with a repertoire of moves,learnt from the Penn Treebank.
The preterminalnode labels are a combination of a Penn Tree-bank label with other information pertaining to thehead/complement/adjunct distinction, but the re-placement cost function R is set to ignore all butthe Penn Treebank part of the label.
The termi-7http://www.gnu.orgnal node labels are inflected forms of words, notbase forms.
For the structural weighting algo-rithm, ST R, the necessary node distinctions arefurnished directly by the parser.
For the questionparses, a set of transformations is applied to theparses directly given by the parser, which compa-rable to the trinity parser, re-order auxiliary inver-sion, and place a tree in the position of a gap.4 Relating Parse Quality to RetrievalPerformanceAs a kind of sanity-check on the idea of the us-ing syntactic structures in retrieving answers, weperformed some experiments in which we var-ied the sophistication of the parse trees that theparsers could produce, the expectation being thatthe less sophisticated the parse, the less successfulwould be question-answering performance.
Theleft-hand data in Table 1 refers to various reduc-tions of the linguistic knowledge bases of the trin-ity parser(thin50 = random removal of 50% subset,manual = manual removal of a subset, flat = en-tirely flat parses, gold = hand-correction of queryparses and their correct answers).
The right-handdata in Table 1 refers to experiments in which therepertoire of moves available to the Collins parser,as defined by its grammar file, was reduced to dif-ferent sized random subsets of itself.Figure 4 shows the empirical cumulative den-sity function (ecdf) of the correct-answer-cutoffobtained with the weighted sub-tree with wildcards measure.
For each possible value c ofcorrect-answer-cutoff, it plots the percentage ofqueries with a correct-answer-cutoff ?
c.0.0 0.1 0.2 0.3 0.4 0.50.00.40.8goldfullthin50manualflatFigure 4: Success vs Cut-off for different parse settings:x = correct-answer-cutoff, y = proportion of queries whosecorrect-answer-cutoff ?
x (ranking by weighted sub-treewith wild cards) (Library task)What these experiments show is that the ques-104Table 1: Distribution of Correct Cutoff across query set Q in different parse settings.
Left-hand data =GNU task, trinity parser, right-hand data = TREC11 task, Collins parserParsing 1st Qu.
Median Mean 3rd Qu.flat 0.1559 0.2459 0.2612 0.3920manual 0.0215 0.2103 0.2203 0.3926thin50 0.01418 0.02627 0.157 0.2930full 0.00389 0.04216 0.1308 0.2198gold 0.00067 0.0278 0.1087 0.1669Parsing 1st Qu.
Median Mean 3rd Qu.55 0.3157 0.6123 0.5345 0.76640075 0.02946 0.1634 0.2701 0.449585 0.0266 0.1227 0.2501 0.4380100 0.01256 0.08306 0.2097 0.2901tion answering performance is a function of the so-phistication of the parses that the parsers are ableto produce.5 Comparing Distance MeasuresTable 2 gives results on the Library task, using thetrinity parser, for some variations of the distancemeasure.Considering the results in 2, the best perform-ing measure (mrr = 0.27) was the sub-traversaldistance, ~?, assigning weights structurally usingST R, with lexical emphasis LEX , and treating agap position as an np wild card.
This slightly outperforms the sub-tree measure, ?
(mrr = 0.25).An alternative approach to discounting parts ofthe answer tree, allowing any sub-tree of the an-swer the option to delete for free (?
(W = Str ?Lex, T (?)
= np gap, S/?
= ?))
performs con-siderably worse (mrr = 0.16).
Presumably this isbecause it is too enthusiastic to assemble the querytree from disparate parts of the answer tree.
Bycomparison, ~?
and ?
can only assembly the querytree from parts of the answer tree that are moreclosely connected.The tree-distance measures (~?, ?)
using struc-tural weights, lexical emphasis and wild cards(mrr = 0.27) out-perform the sub-sequence mea-sure, ?
(mrr = 0.197).
It also out-performs thecosine measure, ?
(mrr = 0.190).
But ?
and ?either out-perform or perform at about the samelevel as the tree-distance measure if the lexicalemphasis is removed (see ?
(W = Str, T (?)
=np gap), mrr = 0.160).The tree-distance measure ?
works better ifstructural weighting is used (mrr = 0.09) thanif it is not (mrr = 0.04).The tree-distance measure ?
works better withwild-cards (see ?
(W = Str, T (?)
= np gap),mrr = 0.160, than without (see ?
(W = Str),mrr = 0.090).Table 3 gives some results on the TREC11 task,using the Collins parser.
Fewer comparisons havebeen made here.The sub-traversal measure, using structuralweighting, lexical emphasis, and wild-cards per-forms better (mrr = 0.150) than the sub-sequencemeasure (mrr = 0.09), which in turn performsbetter than the basic sub-traversal measure, with-outh structural weighting, lexical emphasis orwild-cards (mrr = 0.076).
The cosine distance,?, performed best.6 DiscussionFor the parsers used, you could easily have 2sentences with completely different words, andvery different meanings, but which would have thesame pre-terminal syntactic structure: the preter-minal syntactic structure is not a function of themeaning.
Given this, it is perhaps not surpris-ing that there will be cases that the sequence dis-tance easily spots as dissimilar, but which the treedistance measure, without any lexical emphasis,will regard as quite similar, and this perhaps ex-plains why, without any lexical emphasis, the tree-distance measure performs at similar level to, orworse than, the sub-sequence distance measure.With some kind of lexical emphasis in place,the tree-distance measures out-perform the sub-sequence measures.
We can speculate as to thereason for this.
There are two kinds of casewhere the tree-distance measures could be ex-pected to spot a similarity which the sequence-distance measures will fail to spot.
One is whenthe question and answer are more or less simi-lar on their head words, but differ in determiners,auxiliaries and adjuncts.
The sequence distancemeasure will pay more of a price for these differ-ences than the structurally weighted tree-distance.Another kind of case is when the answer supplieswords which match a wild-card in the middle ofthe query tree, as might happen for example in:Q: what do child processes inherit from their par-ent processesA: a child process inherits the owner and permis-sions from the ancestor process105Table 2: For different distance measures (Library task, trinity parser), distrution of correct-answer-cutoff, mean reciprocal rank mrrcutoffdistance type 1st Qu.
Median Mean mrr~?
(W = Str ?
Lex, T (?)
= np gap) 8.630-05 8.944-04 2.460-02 0.270?
(W = Str ?
Lex, T (?)
= np gap) 9.414e-05 1.428e-03 7.133e-02 0.255?
bases 1.569e-04 2.087e-03 5.181e-02 0.197?
bases 1.569e-04 8.630e-04 1.123e-02 0.190?
(W = Str ?
Lex, T (?)
= np gap, S/?
= ?)
4.080e-04 9.352-03 5.853-02 0.160?
(W = Str, T (?)
= np gap) 3.923e-04 1.964e-02 1.162e-01 0.160?
(W = Str) 5.060e-03 3.865e-02 1.303e-01 0.090?
1.324e-03 1.046e-01 1.852e-01 0.040?
8.398e-02 2.633e-01 3.531e-01 0.003Table 3: For different distance measures (TREC task, collins parser) the distribution of correct-answer-cutoff and mean reciprocal rank (mrr)cutoffdistance type 1st Qu.
Median Mean mrr?
forms 7.847e-03 2.631e-02 1.068e-01 0.167~?
(W = Str ?
Lex, T (?)
= np gap) 8.452e-03 4.898e-02 1.558e-01 0.150?
forms 2.113e-02 7.309-02 2.051e-01 0.092~?
1.815e-02 1.030e-01 3.269e-01 0.076The tree-distance measures will see these assimilar, but the sub-sequence measure will pay alarge price for words in the answer that match thegap position in the query.
Thus one can argue thatthe use of structural weighting, and wild-card treesin the query analysis will tend to equate thingswhich the sequence distance sees as dissimilar.Another possible reason that the tree-distancemeasure out-performs the sub-sequence measureis that it may be able to distinguish things whichthe sequence distance will tend to treat as equiva-lent.
A question might make the thematic role ofsome entity very clear, but use very few significantwords as in:what does malloc do ?Using tree distance will favour answer sen-tences with malloc as the subject, such as mal-loc returns a null pointer.
The basic problem forthe sequence distance here is that it does not havemuch to work with and will only be able to parti-tion the answer set into a small set of equivalenceclasses.These are speculations as to why tree-distancewould out-perform sequence distance.
Whetherthese equating and discriminating advantageswhich theoretically should accrue to ?, ~?
actuallywill do so, will depend on the accuracy of the pars-ing: if there is too much bad parsing, then we willbe equating that which we should keep apart, anddiscriminating that which we should equate.In the two tasks, the relationship between thetree-distance measures and the order-invariant co-sine measure worked out differently.
The reasonsfor this are not clear at the moment.
One pos-sibility is that our use of the Collins parser hasnot yet resulted in good enough parses, especiallyquestion parses ?
recall that the indication from4 was that improved parse quality will give betterretrieval performance.
Also it is possible that rel-ative to the queries in the Library task, the amountof word-order permutation between question andanswer is greater in the TREC task.
This is alsoindicated by the fact that on the TREC task, thesub-sequence measure, ?, falls considerably be-hind the cosine measure, ?, whereas for the Li-brary task they perform at similar levels.Some other researchers have also looked atthe use of tree-distance measures in semantically-oriented tasks.
Punyakonok(2004) report work106using tree-distance to do question-answering onthe TREC11 data.
Their work differs from thatpresented here in several ways.
They take theparse trees which are output by Collins parser andconvert them into dependency trees between theleaves.
They compute the distance from query tothe answer, rather than from answer to query, us-ing essentially the variant of tree-distance that al-lows arbitrary sub-trees of the target to insert forzero-cost.
Presumably this directionality differ-ence is not a significant one, and with distancescalculated from answers to queries, this would cor-respond to the variant that allows arbitrary sourcesub-trees to delete with zero cost.
The cost func-tions are parameterised to refer in the case of wild-card replacements to (i) information derived fromNamed Entity recognisers so different kinds of whwild-cards can be given low-cost replacment withvocabulary categorised as belong to the right kindby NE recognition and (ii) base-form information.There is no way to make a numerical compar-ison because they took a different answer corpusCORq ?
the articles containing the answers sug-gested by TREC11 participants ?
and a differentcriterion of correctness ?
an answer was correct ifit belonged to an article which the TREC11 adju-dicators judges to contain a correct answer.Their adaptation of cost functions to refer to es-sentially semantic annotations of tree nodes is anavenue we intend to explore in future work.
Whatthis paper has sought to do is to investigate intrin-sic syntactic parameters that might influence per-formance.
The hope is that these parameters stillplay a role in an enriched system.7 Conclusion and Future WorkFor two different parsers, and two differentquestion-answering tasks, we have shown that im-proved parse quality leads to better performance,and that a tree-distance measure out-performs asequence distance measure.
We have focussed onintrinsic, syntactic properties of parse-trees.
It isnot realistic to expect that exclusively using tree-distance measures in this rather pure way will givestate-of-the-art question-answering performance,but the contribution of this paper is the (start ofan) exporation of the syntactic parameters whicheffect the use of tree-distance in question answer-ing.
More work needs to be done in systematicallyvarying the parsers, question-answering tasks, andparametrisations of tree-distance over all the pos-sibilities.There are many possibilities to be explored in-volving adapting cost functions to enriched nodedescriptions.
Already mentioned above, is the pos-sibility to involve semantic information in the costfunctions.
Another avenue is introducing weight-ings based on corpus-derived statistics, essentiallymaking the distance comparision refer to extrin-sic factors.
One open question is whether anal-ogously to idf , cost functions for (non-lexical)nodes should depend on tree-bank frequencies.Another question needing further exploration isthe dependency-vs-constituency contrast.
Interest-ingly Punyakonok(2004) themselves speculate:each node in a tree represents only aword in the sentence; we believe that ap-propriately combining nodes into mean-ingful phrases may allow our approachto perform better.We found working with constituency trees thatit was the sub-traversal distance measure that per-formed best, and it needs to be seen whether thisholds also for dependency trees.
Also to be ex-plored is the role of structural weighting in a sys-tem using dependency trees.A final speculation that it would be interestingto explore is whether one can use feed-back fromperformance on a QATD task as a driver in themachine-learning of probabilities for a parser, inan approach analogous to the use of the language-model in parser training.ReferencesMichael Collins.
1999.
Head-driven statistical modelsfor natural language parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.Walter Fontana, Ivo L. Hofacker, and Pe-ter F. Stadler.
2004.
Vienna rna package.www.tbi.univie.ac.at/?ivo/RNA.V.
I. Levenshtein.
1966.
Binary codes capable of cor-recting insertions and reversals.
Sov.
Phys.
Dokl,10:707?710.Vasin Punyakanok, Dan Roth, and Wen tau Yih.
2004.Natural language inference via dependency treemapping: An application to question answering.Computational Linguistics.G.
Salton and M. E. Lesk.
1968.
Computer evala-tion of indexing and text processing.
Journal of theACM, 15:8?36, January.107Ellen Voorhees and Lori Buckland, editors.
2002.
TheEleventh Text REtrieval Conference (TREC 2002).Department of Commerce, National Institute ofStandards and Technology.K.
Zhang and D. Shasha.
1989.
Simple fast algorithmsfor the editing distance between trees and relatedproblems.
SIAM Journal of Computing, 18:1245?1262.AppendixThis appendix briefly summarises the algorithmto compute the tree-distance, based on (Zhangand Shasha, 1989) (see Section 2.1 for definitionof tree-distance).
The algorithm operates on theleft-to-right post-order traversals of trees.
Givensource and target trees S and T , the output is atable T , indexed vertically by the traversal of Sand horizontally by the traversal of T , and posi-tion T [i][j] is the tree-distance from the S subtreerooted at i, to the T subtree rooted at j.
Thus thebottom righthand corner of the table represents thetree distance between S and T .If k is the index of a node of the tree, the left-most leaf, l(k), is the index of the leaf reachedby following the left-branch down.
For a givenleaf there is a highest node of which it is theleft-most leaf.
Let such a node be called a key-root.
Let KR(T ) be the sequence of key-rootsin T .
The algorithm is a doubly nested loop as-cending throught the key-roots of S and T , inwhich for each pair of key-roots (i, j), a routinetree dist(i, j) updates the T table.Suppose i is any node of S. Then for any iswith l(i) ?
is ?
i, the subsequence of S froml(i) to is can be seen as a forest of subtrees of S,denoted F (l(i), is).
tree dist(i, j) creates a ta-ble F , indexed vertically from l(i) to i and hori-zontally from l(j) to j, such that F [is][jt] repre-sents the distance between the forests F (l(i), is)and F (l(j), jt).
Also the F table should be seenas having an extra left-most column, representingfor each is, l(i) ?
is ?
i, the F (l(i), is) to ?
map-ping (pure deletion), and an extra uppermost rowrepresenting for each for each jt, l(j) ?
jt ?
j,the ?
to F (l(j), jt) mapping (pure insertion).tree dist(i, j){initialize:F [l(i)][?
], .
.
.
,F [i][?]
= 1, .
.
.
, i ?
l(i) + 1F [?
][l(j)], .
.
.
,F [?
][j] = 1, .
.
.
, j ?
l(j) + 1loop: ?is, l(i) ?
is ?
i,?jt, l(j) ?
jt ?
j{case 1: l(is) = l(i) and l(jt) = l(j)T [is][jt] = F [is][jt] = min of swap, delete,insert, whereswap = F [is ?
1][jt ?
1] + swap(is, jt)delete = F [is ?
1][jt] + delete(is)insert = F [is][jt ?
1] + insert(jt)case 2: either l(is) 6= l(i) or l(jt) 6= l(j)F [is][jt] = min of delete, insert, for + tree,whereswap, delete, insert as before andfor + tree = F [l(is) ?
1][l(jt) ?
1] + T [is][jt]}}In case 1, the ?forests?
F (l(i), is) andF (l(j), jt) are both single trees and the computedforest distance is transferred to the tree-distancetable T .
In case 2, at least one of F (l(i), is) orF (l(j), jt) represents a forest of more than onetree.
This means there is the possibility that thefinal trees in the two forests are mapped to eachother.
This quantity is found from the T table.This formulation gives the whole-tree distancebetween S and T .
For the sub-tree distance, youtake the minimum of the final column of T .
Forthe sub-traversal case, you do the same but on thefinal iteration, you set the pure deletion columnof F to all 0s, and take the minimum of the finalcolumn of F .To accommodate wild-card target trees, case1 in the above is extended to allow T [is][jt] =F [is][jt] = 0 in case jt is the root of a wild-cardtree.
To accommodate self-effacing source trees,case 2 in the above is extended to also considerfor + tree del = F [l(is)?
1, jt].108
