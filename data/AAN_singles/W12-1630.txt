Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 217?226,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsAdapting to Multiple Affective States in Spoken DialogueKate Forbes-RileyLearning R&D Ctr (LRDC)University of PittsburghPittsburgh, PA 15260, USAforbesk@cs.pitt.eduDiane LitmanLRDC and Dept.
Computer ScienceUniversity of PittsburghPittsburgh, PA 15260, USAlitman@cs.pitt.eduAbstractWe evaluate a wizard-of-oz spoken dialoguesystem that adapts to multiple user affectivestates in real-time: user disengagement anduncertainty.
We compare this version with theprior version of our system, which only adaptsto user uncertainty.
Our analysis investigateshow iteratively adding new affect adaptationto an existing affect-adaptive system impactsglobal and local performance.
We find a sig-nificant increase in motivation for users whomost frequently received the disengagementadaptation.
Moreover, responding to disen-gagement breaks its negative correlations withtask success and user satisfaction, reduces un-certainty levels, and reduces the likelihood ofcontinued disengagement.1 IntroductionState of the art spoken dialogue system research fo-cuses on responding not only to the literal contentof users?
speech but also to their affective state1,such that the same literal content may receive onesystem response when the user is frustrated, andanother when the user is confused, etc.
The po-tential benefits are clear: affect-adaptive systemscan increase task success (Forbes-Riley and Litman,2011a; Wang et al, 2008) and other global perfor-mance metrics such as user satisfaction (Liu and Pi-card, 2005; Klein et al, 2002) and motivation (Aist1We use affect for emotions and attitudes that affect howusers communicate.
Other speech researchers also combineconcepts of emotion, arousal, and attitudes where emotion isnot full-blown (Cowie and Cornelius, 2003).et al, 2002).
However, to date most researchers havefocused on adapting to a single affective state.
Thenext step is thus to develop and evaluate spoken dia-logue systems that respond to multiple user affectivestates.
The problem of how to develop effective af-fect adaptations is a complex one even as appliedto a single affective state, and it multiples with ev-ery new state added.
For example, it is not cleara priori how responding to one affective state mayimpact another?s frequency and relationship to per-formance.
In this paper we examine this problemin the context of the computer tutoring domain.
Wepreviously showed that adapting to user uncertaintyduring spoken dialogue computer tutoring improvestask success, both in a wizard-of oz version wherea hidden human performed the affect detection andnatural language understanding (Forbes-Riley andLitman, 2011b), as well as in a fully automated sys-tem version (Forbes-Riley and Litman, 2011a).We are now taking the next step by incorporatingadaptation to a second user affective state: user dis-engagement.
We target user disengagement for tworeasons: first, our prior manual annotation showeddisengagement and uncertainty to be the most fre-quent user affective states that occur in our system,and second, our prior analyses show that the occur-rence of disengagement is negatively correlated withtask success and user satisfaction (Forbes-Riley andLitman, 2012).2 Thus, we hypothesized that provid-ing appropriate system responses to both affectivestates could have multiple benefits: 1) reduce thefrequency of one or both states, 2) ?break?
the nega-2Redesigning a system in light of correlational analyses canimprove performance (Rotaru and Litman, 2009).217tive correlations with performance, and 3) yield fur-ther improvements in global and local performance.In this paper, we test these hypotheses, present-ing the results of a controlled experiment evaluatinga wizard-of-oz version of our spoken dialogue com-puter tutor that adapts to both user uncertainty anduser disengagement (Section 3).
Although we ad-dress these states within the tutoring domain, speechresearchers from other domains and applications arealso focusing on detecting and adapting to user dis-engagement (e.g., (Schuller et al, 2010; Wang andHirschberg, 2011)) and uncertainty (e.g.
(Pon-Barryand Shieber, 2011; Paek and Ju, 2008)) to improvesystem performance.
Our results should be of in-terest not only to these researchers but also moregenerally to any researchers working towards com-prehensive affect-adaptive spoken dialogue systems.In particular, our results show that iteratively addingnew affect adaptations to an existing affect-adaptivesystem can yield performance improvements.
Wefind no increase (but also no decrease) in task suc-cess or user satisfaction, but we do find an increasein motivation for users who most frequently receivedthe disengagement adaptation (Section 4).
Further-more, we find that responding to disengagement?breaks?
negative correlations with task success anduser satisfaction (Section 5), and also yields a reduc-tion both in uncertainty levels (Section 4) and in thelikelihood of continued disengagement (Section 6).2 Related WorkUser disengagement is highly undesirable becauseof its potential to increase dissatisfaction and taskfailure, and there is a growing awareness of itspotential to negatively impact commercial applica-tions; thus there has been substantial prior workfocused on detecting disengagement (along withthe closely related states of boredom and lack ofinterest) (e.g., (Schuller et al, 2010; Wang andHirschberg, 2011; Bohus and Horvitz, 2009)).
Todate, however, only a few disengagement-adaptivesystems have been evaluated, and within the tutoringdomain these have focused on only one disengage-ment behavior: gaming.
For example, responding togaming with supplementary material reduced gam-ing and improved task success for users who mostfrequently gamed (Baker et al, 2006), while addingprogress reports and productive learning tips at theend of problems (i.e., without specifically targetinggaming instances) increased task success, engage-ment, and user satisfaction (Arroyo et al, 2007).Our research builds on this work but is novel in thatwe focus on speech and dialogue-based disengage-ment and on adapting to multiple affective states.More generally, while substantial spoken dia-logue and affective systems research has shownthat users display a range of affective states wheninteracting with a system (e.g.
(Schuller et al,2009; Conati and Maclaren, 2009)), to date onlya few systems adapt to multiple affective states(e.g., (D?Mello et al, 2010; Aist et al, 2002; Tsuka-hara and Ward, 2001)).
Most have been deployedwith wizard-of-oz components, and none have yetshown significant improvements in task success,though other benefits have been shown, includingincreased user satisfaction (Tsukahara and Ward,2001), rapport (Acosta and Ward, 2011) and mo-tivation (Aist et al, 2002).
Recently, D?Mello etal.
(2010) showed that performance can depend onwhen and to whom the adaptations are provided;higher expertise users never benefited from systemresponses to their frustration, boredom and confu-sion, while lower expertise users only benefited aftermultiple system interactions.
While this prior workshowed the benefits of adapting to multiple affec-tive states as compared to not adapting to affect atall, it did not test whether these benefits were dueto having multiple adaptations, or if any one wouldhave sufficed.
Our work is novel in explicitly mea-suring the value of having multiple adaptations ascompared to one.3 The ExperimentOur prior work showed that our uncertainty-adaptivespoken dialogue system improves performance overnot adapting to affect (Forbes-Riley and Litman,2011b; Forbes-Riley and Litman, 2011a); this sys-tem serves as our baseline in the current work.3.1 Baseline System: UNC ADAPT ITSPOKEUNC ADAPT ITSPOKE (Intelligent TutoringSPOKEn dialog system)3 tutors 5 Newtonian3ITSPOKE is a speech-enhanced and modified version ofthe Why2-Atlas text-based tutor (VanLehn et al, 2002).218physics problems (one per dialogue), using a TutorQuestion - User Answer - Tutor Response format.In the fully automated system, the speech fromthe user?s answer is digitized from head-mountedmicrophone input and sent to a speech recognizer.The answer?s (in)correctness is then automaticallyclassified based on the recognizer?s transcription us-ing a semantic analysis component, and the answer?s(un)certainty is automatically classified by inputtingfeatures of the speech signal (e.g.
prosody), the au-tomatic transcript, and the dialogue context into alogistic regression model.
The (in)correctness and(un)certainty detection components comprising oursystem?s user model are described in detail else-where (Forbes-Riley and Litman, 2011a).For the present experiment, the affect and(in)correctness labeling are performed by a hiddenhuman wizard.
As in our prior work, this allows usto first analyze the impact of an affect adaptationseparately from the noise introduced by automat-ing affect and semantic analysis (see Section 7).Figures 1-3 illustrate the binary (dis)engagement(ENG, DISE), (in)correctness (COR, INC), and(un)certainty (CER, UNC) labels.Finally, the system automatically determines theappropriate response based on the answer?s labeled(in)correctness and (un)certainty and this responseis sent to the Cepstral text-to-speech system4, whoseaudio output is played through the headphones anddisplayed on a web-based interface (see Figure 4).The uncertainty label and system adaptation aredescribed in detail elsewhere (Forbes-Riley and Lit-man, 2011b; Forbes-Riley and Litman, 2011a).Briefly, the uncertain (UNC) label is used for turnsexpressing uncertainty or confusion about the topicbeing discussed, and the non-uncertain (CER) labelis used otherwise.
The wizard in this experimentdisplayed interannotator agreement of 0.85 and 0.62Kappa on correctness and uncertainty, respectively,in prior ITSPOKE corpora.
Our uncertainty adapta-tion is based on the hypothesis that uncertainty andincorrectness are both points of impasse in a dia-logue, and that providing additional knowledge canhelp resolve them.
In UNC ADAPT ITSPOKE, in-correct answers and uncertain answers both receive(in)correctness feedback (e.g., ?Right?
or ?I don?t4an outgrowth of Festival (Black and Taylor, 1997).think so?
), followed by a (re)statement of the cor-rect answer.
Depending on topic difficulty, the sys-tem then either provides a brief explanation of rea-soning (?Bottom Out?)
or a more lengthy dialogueexchange that walks the user through the steps ofthe reasoning (?Remediation Subdialogue?).
An ex-ample is shown in Figure 1.3.2 UNC-DISE ADAPT ITSPOKEUNC-DISE ADAPT ITSPOKE adds disengage-ment detection and adaptation to UNC ADAPT IT-SPOKE.
Our disengagement annotation scheme isdescribed in detail elsewhere (Forbes-Riley and Lit-man, 2011c).
It was derived from empirical obser-vation of our data and from prior work, includingthat mentioned in Section 2 and appraisal theory-based emotion models, which distinguish emotionalbehaviors from their underlying causes (e.g., (Conatiand Maclaren, 2009)).
Briefly, the Disengaged(DISE) label is used for turns expressing moderateto strong disengagement towards the interaction, i.e.,responses given without much effort or caring aboutappropriateness, and might include signs of bore-dom or irritation.
Clear examples include turns spo-ken in leaden monotone, with sarcasm, or off-tasksounds such as electronics usage.
The wizard inthis experiment displayed interannotator agreementof 0.55 Kappa on the DISE label in prior ITSPOKEcorpora, which is on par with prior affect research,where moderate agreement is common given the dif-ficulty of the task (Forbes-Riley and Litman, 2011c).Based on the results of the prior research dis-cussed in Section 2 and our own prior research,we have developed one class of system responsesfor correct+disengaged (COR-DISE) answers andanother for incorrect+disengaged (INC-DISE) an-swers (Forbes-Riley and Litman, 2011c)5.Our INC-DISE adaptation builds on the priorfinding that supplementary information can help re-duce some types of disengagement for highly dis-engaged users (Baker et al, 2006).
We hypothe-sized that our UNC ADAPT response to incorrect-ness (a Bottom Out or Remediation Subdialogue)was insufficient for an INC-DISE turn because the5Originally we distinguished six DISE types, but found thistoo many to be reliably detected automatically and thus reducedthe distinction to two using correctness.
Our automatic disen-gagement detector is discussed further in Section 7.219user had already disengaged.
To benefit from thissupplementary knowledge, the user first had to reen-gage.
Thus, the UNC-DISE ADAPT system re-sponds to INC-DISE answers with ?productive in-teraction feedback?6 followed by an easier ?fill inthe blank?
version of the original question.
The pur-pose of this two-pronged response is to regain theuser?s attention with the feedback and then providea path through the impasse with the easier ques-tion, thereby keeping the user engaged.
An ex-ample is shown in Figure 2, where USER-1 is la-beled INC-DISE because the user gives an irrelevant(and obviously incorrect) answer.
Note that whilemost knowledge asymmetry spoken dialogue sys-tems (e.g., problem-solving and troubleshooting (Ja-narthanam and Lemon, 2008)) use the concept ofresponse (in)correctness, a more general version isresponse (in)appropriateness, which can be realizeddifferently across applications, including as the userturn?s speech recognition score (Kamm et al, 1998).Since misrecognitions are also a type of dialogueimpasse, a similar version of our INC-DISE adap-tation could be provided by other spoken dialoguesystems for turns where users disengage and theirresponse isn?t recognized by the system.Our COR-DISE adaptation builds on the priorfindings that progress reports and productive learn-ing tips can positively impact multiple performancemetrics when used without specifically targeting dis-engagement (Arroyo et al, 2007), but not whenused after every user turn (Walonoski and Heffer-nan, 2006).
We hypothesized that these responsesmight be most beneficial if they targeted COR-DISEturns.
Thus, the UNC-DISE ADAPT system re-sponds to COR-DISE answers with ?productive in-teraction feedback?
followed by a progress reportgraphing the user?s correctness both in the currentdialogue and over all prior dialogues.
Examplesare shown in Figures 3-4, where USER-1 is labeledCOR-DISE because the user unnecessarily repeatshimself, signaling his lack of interest.
As shown,we distinguish two classes of productive interactionfeedback.
That in ?2a?
shows the feedback givenwhen the progress report indicates improvement onthe current dialogue relative to the prior ones, while6This is our generalization of the concept of ?productivelearning tip?
used in prior work (Arroyo et al, 2007).?2b?
shows the feedback given when there is a de-cline.
Note that a similar combination of productiveinteraction feedback and progress reports tailored tothe domain (e.g., graphs showing subtasks accom-plished so far) could be provided by most spoken di-alogue systems on turns where users disengage andtheir response is recognized by the system.73.3 Experimental ProcedureCollege students with no college-level physics wererecruited and randomly assigned to either theUNC ADAPT or UNC-DISE ADAPT condition af-ter balancing for user expertise (pretest score) andgender.
Users: (1) read a short physics text, (2) tooka pretest and a pre-motivation survey, (3) worked 5?training?
problem dialogues with the system fromtheir condition, (4) took a post-motivation surveyand a user satisfaction survey, (5) took a posttest iso-morphic to the pretest, and (6) worked a ?test?
prob-lem dialogue with UNC ADAPT.The pre/post tests are the same as those used inmultiple prior ITSPOKE experiments (c.f., (Forbes-Riley and Litman, 2011a)).
The tests are isomor-phic, each containing 26 multiple choice questionsquerying knowledge of the topics covered in the di-alogues.
Average pretest and posttest scores were53% and 81% (out of 100%), respectively.The pre/post motivation surveys are a reducedversion of a widely used motivation survey in thetutoring domain (Pintrich and DeGroot, 1990); ourselected questions were relevant to our system andalso selected in other recent research (Ward, 2010;Roll, 2009).
The two surveys are isomorphic, eachcontaining 19 statements rated on a 7-point Likertscale.
Average pre and post scores were 68% and70% (out of 100%), respectively.The user satisfaction survey was recently devel-oped and validated for use with spoken dialoguecomputer tutors (Dzikovska et al, 2011).
It con-tains 40 statements rated on a 5-point Likert scale.Average score was 68% (out of 100%).The ?test?
dialogue is isomorphic to the fifthtraining dialogue, such that all questions are identi-cal except for the identities of the objects discussed.In this way, we can measure how the disengagement7Note that our DISE and UNC adaptations are combined ifthe two states occur simultaneously.220adaptations from the fifth dialogue impact user turnswhen the questions are repeated in the test dialogue(where no disengagement adaptation is given).
Wehave also used this test dialogue in our prior work(c.f., (Forbes-Riley and Litman, 2011a)).3.4 CorpusThe resulting corpus contains 228 dialogues (6 peruser) and 3518 turns from 38 users, 22 female and 16male, with 19 subjects per condition.8 Table 1 showsthe distribution of the labeled turns in the corpus.Table 1: Corpus Description (N=3518)Turn Label Total PercentDisengaged 622 17.7%Correct 2825 80.3%Disengaged+Correct 247 7.0%Uncertain 537 15.3%4 Global Performance EvaluationWe use the test and survey instruments described inSection 3.3 to evaluate global performance in UNC-DISE ADAPT.
We measure task success via learn-ing gain; as is typical in the tutoring community,we compute normalized learning gain as (posttest-pretest)/(1-pretest).
We compute percent user satis-faction from the survey as (user score)/(maximumpossible score).
We compute raw motivation gainfrom the surveys as (post score-pre score).9 For eachmetric, we ran a one-way ANOVA with condition asthe between-subjects factor.
The first two rows ofTable 2 show the number of users (N), means (Mn)and standard deviations (sd) for these metrics acrosscondition.
Although UNC-DISE ADAPT shows asmall decrease in means for learning gain and usersatisfaction, there were no significant differences(p?.05) or trends (p?.10) for differences betweenconditions for any global metric.As a further comparison, we compared the perfor-mance of UNC-DISE ADAPT to our non-adaptivewizard-of-oz version of ITSPOKE (NO ADAPT),using the corpus collected from our prior user8One outlier with negative learning was removed from eachcondition, because our goal is to investigate the role of affectadaptation when learning is successful.9Total, average or percent satisfaction yielded comparableresults, as did raw or normalized motivation and learning gains.study comparing UNC ADAPT and NO ADAPT;that study showed UNC ADAPT had signifi-cantly higher learning gain than NO ADAPT(p=.001) (Forbes-Riley and Litman, 2011b).10 Thegoal here was to ascertain in a post-hoc way whetheradapting to multiple affective states yielded highertask success than not adapting to affect at all.As shown last in Table 2, UNC-DISE ADAPTand UNC ADAPT both significantly outperformNO ADAPT (p?.003), suggesting that while itera-tively adding new affect adaptations to an existingaffect-adaptive system does not necessarily yield ad-ditive improvements to global performance, it alsodoes not decrease performance.Table 2: Global Performance Metrics Across Conditions(All UNC vs. UNC-DISE Differences Yield p>=.274;All NO-ADAPT Differences Yield p?.003)Cond N LearnGain UserSat MotGainMn sd Mn sd Mn sdUnc 19 .65 .20 .69 .11 .01 .07Unc-Dise 19 .58 .19 .66 .09 .01 .07NoAdapt 21 .38 .20 - - - -The frequency of disengagement and other af-fective states can vary widely across system users.In our case, some users showed disengagement onthe majority of turns in later dialogues while oth-ers showed almost none at all; the average and stan-dard deviation of per user %DISE over conditionsare 17.7% and 10.1%, respectively (Table 5 breaksthis down by condition).
Thus we hypothesizedthat the global performance improvements of UNC-DISE ADAPT might have been weakened by in-cluding users with low or no disengagement whorarely received the adaptation and thus could not beexpected to show improvement.
To test this hypoth-esis, we split users into high and low DISE basedon the median %DISE in the corpus.
We ran atwo-way ANOVA for each global metric with DISEsplit and condition as factors.
We found a signifi-cant interaction effect between condition and DISE10Because this prior corpus was collected in a different exper-iment, the conclusions here are tenuous.
However, both exper-iments had similar subject populations (local college students)and mean pretest scores (p=.84).
The prior experiment used asmaller satisfaction survey and no motivational surveys, so wecan only compare learning.221split (F(1,38) = 4.84, p=0.035) for motivation gain.Means for these groups are shown in Table 3.
Asshown, low DISE users had higher motivation gainin UNC ADAPT, while high DISE users had highermotivation gain in UNC-DISE ADAPT.Table 3: Motivation Gain Differences Across Conditionfor High and Low DISE Users (p=.035)Condition Split N MotGainMn sdUNC high DISE 9 -.01 .04UNC-DISE high DISE 7 .04 .07UNC low DISE 10 .03 .08UNC-DISE low DISE 12 -.01 .06In contrast to the tests and surveys, which donot necessarily reflect user performance during thedialogues, the ?test?
dialogue enables us to mea-sure global performance using dialogue-based met-rics.
The test dialogue was isomorphic with the fi-nal training dialogue, except that the disengagementadaptation was not given; moreover, different sys-tem questions could appear in the test dialogue if theuser answered a question differently.11 We hypoth-esized that responding to the user?s disengagementduring the training dialogue (UNC-DISE ADAPT)would yield increased correctness as well as reduceduncertainty and disengagement in the test dialogue.We tested this hypothesis by computing per-cent correctness, disengagement, and uncertaintyfor each user, both alone and in combination, overuser answers to tutor questions that were repeatedbetween the training and test dialogues.
We ranANOVAs comparing these metrics across the twoconditions.
Table 4 presents our results.
Interest-ingly, no differences between conditions were foundfor transitions from DISE turns.
However, the dis-engagement adaptation did impact other turns in thedialogues apart from the (DISE) ones that triggeredit.
The first row shows that uncertain answers aremore likely to remain uncertain in UNC ADAPTthan in UNC-DISE ADAPT.
The second row showsthat incorrect+uncertain+engaged answers are morelikely to become correct and certain in UNC-11For example, if a user answered a question incorrectly dur-ing training and then answered its isomorph correctly duringtesting, s/he would not receive the remediation during the testdialogue that s/he received during training.DISE ADAPT.
By more fully engaging users, thedisengagement adaptation may thereby enable themto benefit more from the uncertainty adaptation.However, the third row suggests that the adaptationcan have a negative impact when users are origi-nally certain about their incorrect answers: incor-rect+certain+engaged users turns are more likelyto become disengaged in UNC-DISE ADAPT.
Thissuggests that the disengagement adaptation does notmore fully engage certain users (particularly thosewhose certainty does not reflect correctness).Table 4: Differences Across Condition for Test DialogueMetric Condition Mn sd pUNC?
UNC UNC .06 .09 .05UNC-DISE .01 .04INC+UNC+ENG?
UNC .01 .03 .10COR+CER+ENG UNC-DISE .03 .05INC+CER+ENG?
UNC .00 .00 .04INC+CER+DISE UNC-DISE .02 .035 Breaking Negative CorrelationsAs noted in Section 1, in our prior ITSPOKEcorpora we found that user disengagement wasnegatively correlated with task success (measuredas learning gain) (p=.01) and user satisfaction(p=.03) (Forbes-Riley and Litman, 2011c; Forbes-Riley and Litman, 2012).
Thus, one important stan-dard of evaluation for our disengagement adapta-tion is to determine whether or not it ?breaks?
thesenegative correlations when it is employed with realusers (Rotaru and Litman, 2009).
A broken corre-lation would mean that even though disengagementmay still occur, it no longer relates to decreased per-formance.UNC-DISE ADAPT responds differently to cor-rect and incorrect DISE turns (Section 3.2).
Tocompare the impacts of these responses both com-bined and individually, we computed %DISE, %cor-rectDISE (CDISE) and %incorrectDISE (IDISE) foreach user (over all five training problems).
We thencomputed bivariate Pearson?s correlations withineach condition between each DISE metric and bothlearning and user satisfaction.Table 5 shows the mean (Mn) and standard de-viations (sd) for the DISE metrics within each con-222dition, the coefficient (R) for each correlation, andits significance (p).
Consider first task success.The first pair of rows shows that the negative cor-relation between DISE and learning is still presentwhether or not the disengagement adaptation is re-ceived.
However, the second pair of rows shows thatthe negative correlation between %correctDISE andlearning is broken when the disengagement adap-tation is received (UNC-DISE), but is still presentwhen not received (UNC).
The third pair of rowsshows that the disengagement adaptation does notbreak the negative correlation between %incorrect-DISE and learning.
Consider next user satisfaction.The first pair of rows shows that the negative cor-relation between DISE and user satisfaction is bro-ken when the disengagement adaptation is received(UNC-DISE), but is still present when not received(UNC).
The third pair of rows shows that the thenegative correlation between %incorrectDISE anduser satisfaction is also broken when the disengage-ment adaptation is received (UNC-DISE), but is stillpresent when not received (UNC).
These results sug-gest that for improving task success, adapting to dis-engagement is more effective for correct turns thanincorrect turns12, while for improving user satisfac-tion, adapting to disengagement is effective for in-correct turns and for the dialogue as a whole with-out considering correctness.
Finally, Table 5 showsthat while %correctDISE is reduced in UNC-DISEas compared to UNC, %incorrectDISE actually in-creases in UNC-DISE.
This suggests that while a re-duction in disengagement due to the adaptation par-tially explains the broken correlations, the adapta-tion may also ameliorate the negative performanceimpact of user disengagement.6 Local Affect Transition AnalysesIn addition to global performance analyses, the im-pact of affect adaptation can also be evaluated lo-cally, i.e., in terms of its immediate impact in the di-alogue.
We investigate this local effect by comput-ing the likelihoods of transitioning from each user12Users who are more often correct may also be predisposedto learn more.
This may explain why %correctDISE has a lessernegative impact on learning than %DISE and %incorrectDISEin UNC and UNC-DISE.
However, only the disengagementadaptation can explain why %correctDISE has a lesser negativeimpact on learning in UNC-DISE than in UNC.Table 5: Disengagement-Performance CorrelationsAcross Conditions (Bold Indicates ?Broken?
Correlation)Mn sd LGain UserSatR p R p%DISE in:UNC 17.2 12.1 -.77 .01 -.48 .04UNC-DISE 16.9 7.9 -.65 .01 -.16 .51%CDISE in:UNC 7.7 7.6 -.45 .05 -.14 .56UNC-DISE 6.1 3.3 .25 .31 -.27 .27%IDISE in:UNC 9.5 7.7 -.76 .01 -.61 .01UNC-DISE 10.8 7.7 -.78 .01 -.05 .83disengagement state in turn n (DISE or ENG) toeach user disengagement state in turn n+1 (DISEor ENG).
We use the transition likelihood L met-ric (D?Mello et al, 2007), which has also previouslybeen used by ourselves and others to compute thelikelihood of transitioning from one affective stateto another in a dialogue corpus and to compare theselikelihoods across different system versions (Forbes-Riley and Litman, 2011a; McQuiggan et al, 2008;D?Mello et al, 2007).
As in this prior work, we com-pute the transition likelihoods for each user (over all5 training dialogues), then use ANOVAs to deter-mine if there were differences in the likelihoods ofall possible transitions from the user state in turn n.Transition likelihood L is computed as shown be-low, where n refers to the disengagement state inturn n and n+1 refers to the state in turn n+1.
Asshown, L computes the likelihood that the n?n+1transition will occur.
L=1 indicates that n+1 alwaysfollows n, while L=0 and L<0 indicate that the like-lihood of transitioning from n to n+1 is equal tochance, and less than chance, respectively.L(n?n+1) = P (n+1|n)?P (n+1)1?P (n+1)We hypothesized that users in the UNC-DISE ADAPT condition would be less likely totransition into disengagement in turn n+1.
Mean Lvalues across users for each transition are shown inTable 6 for the two conditions, where the rows repre-sent each turn n state and the columns represent eachturn n+1 state.
The p-value from the ANOVA foreach transition likelihood comparison is also shown.The table shows that in both conditions, an engaged223user in turn n is significantly more likely to remainengaged in turn n+1 than s/he is to become disen-gaged.
However, in UNC ADAPT, a disengageduser is more likely (as a trend, p=.06) to remain dis-engaged than to become engaged in turn n+1.
Incontrast, in UNC-DISE ADAPT, a disengaged useris equally likely (p=.14) to become disengaged orremain engaged in turn n+1.
This analysis thus in-dicates that the disengagement adaptation also has abenefit at the local performance level, in that it re-duces the likelihood of continued disengagement.Table 6: Mean L Values for Disengagement State Transi-tionsCondition Turn n Turn n+1ENG DISE pUNC-DISE ENG .06 -.01 .04DISE -.35 .06 .14UNC ENG .09 -.03 .01DISE -.41 .09 .067 Summary and Current DirectionsWe investigated how iteratively adding new affectadaptation to an affect-adaptive spoken dialoguesystem impacts global and local performance.
Wepresented a disengagement adaptation that can gen-eralize across domains, and discussed its incorpo-ration into our uncertainty-adaptive computer tutor.We then presented a controlled evaluation compar-ing these multiply and singly adaptive systems.
Ourresults showed that while the disengagement adap-tation did not increase (or decrease) task success oruser satisfaction, it demonstrated a slight but sig-nificant increase in motivation gain for users withhigh disengagement.
Future analyses will shed fur-ther light on how disengagement mediates the ef-fect of condition on motivation.
The adaptation alsoreduced user uncertainty and increased correctnessfor uncertain answers when repeated in the test dia-logue, but increased disengagement for repeated an-swers that were originally certain and incorrect.
Italso broke negative correlations between disengagedturns and performance, when measured both as tasksuccess and user satisfaction, and showed a trend toreduce disengagement at the local dialogue level.Our next step is to repeat the experiment withfully automated versions of our affect-adaptive spo-ken dialogue systems, to determine the impact ofadding new affect adaptation when the system per-forms the affect detection and natural language un-derstanding tasks.
We are currently in the laststages of building an automatic disengagement de-tector that will then be implemented in UNC-DISE ITSPOKE.
Interestingly, our prior work sug-gests that the fully automated UNC-DISE ADAPTsystem may yield greater global performance im-provements relative to UNC ADAPT (Forbes-Rileyand Litman, 2012) than the wizard-of-oz version ofthe system; it may be that users are more responsiveto the disengagement adaptation when the affect de-tection and natural language understanding outputsare ?noisier?.
Future work will also consider otherexperimental designs to help determine the separateand joint effects of the two affect adaptations.AcknowledgmentsThis work is funded by NSF award 0914615.
Wethank Scott Silliman for experimental support.ReferencesJ.
C. Acosta and N. G. Ward.
2011.
Achieving rapportwith turn-by-turn, user-responsive emotional coloring.Speech Communication, 53(9-10):1137?1148.G.
Aist, B. Kort, R. Reilly, J. Mostow, and R. Pi-card.
2002.
Experimentally augmenting an intel-ligent tutoring system with human-supplied capabil-ities: Adding human-provided emotional scaffoldingto an automated reading tutor that listens.
In Proc.IEEE International Conference on Multimodal Inter-faces (ICMI), pages 483?492, Washington, DC.I.
Arroyo, K. Ferguson, J. Johns, T. Dragon, H. Merhera-nian, D. Fisher, A. Barto, S. Mahadevan, and B.Woolf.2007.
Repairing disengagement with non-invasive in-terventions.
In Proc.
Artificial Intelligence in Educa-tion (AIED), pages 195?202.R.
S. Baker, A. Corbett, K. Koedinger, S. Evenson,I.
Roll, A. Wagner, M. Naim, J. Raspat, D. Baker, andJ.
Beck.
2006.
Adapting to when students game anintelligent tutoring system.
In Proceedings IntelligentTutoring Systems, pages 392?401.A.
Black and P. Taylor.
1997.
Festival speech synthe-sis system: system documentation (1.1.1).
The Centrefor Speech Technology Research, University of Edin-burgh, http://www.cstr.ed.ac.uk/projects/festival/.D.
Bohus and E. Horvitz.
2009.
Models for multipartyengagement in open-world dialog.
In Proceedings ofSIGdial, pages 225?234, London, UK.224C.
Conati and H. Maclaren.
2009.
Empirically build-ing and evaluating a probabilistic model of user af-fect.
User Modeling and User-Adapted Interaction,19(3):267?303.R.
Cowie and R. R. Cornelius.
2003.
Describing theemotional states that are expressed in speech.
SpeechCommunication, 40(1-2):5?32.S.
D?Mello, R. S. Taylor, and A. Graesser.
2007.
Mon-itoring affective trajectories during complex learning.In Proc.
Cognitive Science Society, pages 203?208.S.
D?Mello, B. Lehman, J. Sullins, R. Daigle, R. Combs,K.
Vogt, L. Perkins, and A. Graesser.
2010.
A timefor emoting: When affect-sensitivity is and isn?t effec-tive at promoting deep learning.
In Proc.
IntelligentTutoring Systems Conference, pages 245?254, June.M.
Dzikovska, J. Moore, N. Steinhauser, and G. Camp-bell.
2011.
Exploring user satisfaction in a tutorialdialogue system.
In Proc.
SIGDIAL, pages 162?172,Portland, Oregon, June.K.
Forbes-Riley and D. Litman.
2011a.
Benefits andchallenges of real-time uncertainty detection and adap-tation in a spoken dialogue computer tutor.
SpeechCommunication, 53(9?10):1115?1136.K.
Forbes-Riley and D. Litman.
2011b.
Designing andevaluating a wizarded uncertainty-adaptive spoken di-alogue tutoring system.
Computer Speech and Lan-guage (CSL), 25(1):105?126.K.
Forbes-Riley and D. Litman.
2011c.
When does dis-engagement correlate with learning in spoken dialogcomputer tutoring?
In Proceedings of AIED, Auck-land, NZ, June.K.
Forbes-Riley and D. Litman.
2012.
Intrinsic and ex-trinsic evaluation of an automatic user disengagementdetector for an uncertainty-adaptive spoken dialoguesystem.
In Proc.
NAACL-HLT, Montreal, June.S.
Janarthanam and O.
Lemon.
2008.
User simula-tions for online adaptation and knowledge-alignmentin troubleshooting dialogue systems.
In Proc.
SEM-dial.C.
Kamm, D. Litman, and M. Walker.
1998.
Fromnovice to expert: The effect of tutorials on user exper-tise with spoken dialogue systems.
In Proceedings ofthe 5th International Conference on Spoken LanguageProcessing, pages 1211?1214.J.
Klein, Y.
Moon, and R. Picard.
2002.
This computerresponds to user frustration: Theory, design, and re-sults.
Interacting with Computers, 14:119?140.K.
Liu and R. W. Picard.
2005.
Embedded empathyin continuous, interactive health assessment.
In CHIWorkshop on HCI Challenges in Health Assessment.S.
W. McQuiggan, J. L Robison, and J. C. Lester.
2008.Affective transitions in narrative-centered learning en-vironments.
In Proc.
Intelligent Tutoring SystemsConference, pages 490?499.T.
Paek and Y.-C. Ju.
2008.
Accommodating ex-plicit user expressions of uncertainty in voice searchor something like that.
In Proceedings Interspeech),pages 1165?1168, Brisbane, Australia, September.P.
Pintrich and E. DeGroot.
1990.
Motivational andself-regulated learning components of classroom aca-demic performance.
Journal of Educational Psychol-ogy, 82(1):33?40.H.
Pon-Barry and S. Shieber.
2011.
Recognizing uncer-tainty in speech.
EURASIP Journal on Advances inSignal Processing.I.
Roll.
2009.
Structured Invention Tasks to Prepare Stu-dents for Future Learning: Means, Mechanisms, andCognitive Processes.
Ph.D. thesis, Carnegie MellonUniversity.M.
Rotaru and D. Litman.
2009.
Discourse structureand performance analysis: Beyond the correlation.
InProc.
SIGDIAL, pages 178?187, London, UK.B.
Schuller, S. Steidl, and A. Batliner.
2009.
The Inter-speech 2009 emotion challenge.
In Proc.
Interspeech,pages 312?315, ISCA, Brighton, UK, September.B.
Schuller, S. Steidl, A. Batliner, F. Burkhardt, L. Dev-illers, C. Muller, and S. Narayanan.
2010.
The Inter-speech 2010 paralinguistic challenge.
In Proc.
Inter-speech, pages 2794?2797, Chiba, Japan, September.W.
Tsukahara and N. Ward.
2001.
Responding to subtle,fleeting changes in the user?s internal state.
In Pro-ceedings of the SIG-CHI on Human factors in comput-ing systems, pages 77?84, Seattle, WA.
ACM.K.
VanLehn, P. Jordan, C.
Rose?, D. Bhembe, M. Bo?ttner,A.
Gaydos, M. Makatchev, U. Pappuswamy, M. Rin-genberg, A. Roque, S. Siler, R. Srivastava, and R. Wil-son.
2002.
The architecture of Why2-Atlas: A coachfor qualitative physics essay writing.
In Proc.
Intelli-gent Tutoring Systems Conference, pages 158?167.J.
Walonoski and N. Heffernan.
2006.
Prevention ofoff-task gaming behavior in intelligent tutoring sys-tems.
In Proc.
Intelligent Tutoring Systems Confer-ence (ITS), pages 722?724.W.
Wang and J. Hirschberg.
2011.
Detecting levels ofinterest from spoken dialog with multistream predic-tion feedback and similarity based hierarchical fusionlearning.
In Proc.
SIGDIAL, pages 152?161, Portland,Oregon, June.N.
Wang, W.L.
Johnson, R. E. Mayer, P. Rizzo, E. Shaw,and H. Collins.
2008.
The politeness effect: Peda-gogical agents and learning outcomes.
InternationalJournal of Human-Computer Studies, 66(2):98?112.A.
Ward.
2010.
Reflection and Learning Robustness ina Natural Language Conceptual Physics Tutoring Sys-tem.
Ph.D. thesis, University of Pittsburgh.APPENDIX225UNC ADAPT ITSPOKE: What are the forces exerted on the man after he releases his keys?USER: gravity???
(COR, UNC, ENG)UNC ADAPT ITSPOKE: Right.
[Correctness Feedback] Gravity is the only force acting on the man.
This force isalso called the weight of the man.
It?s always present when an object is in earth?s gravitational field.
[Bottom Out].
Sowhat?s the direction of the force of gravity on the man (e.g., vertically up)?
[Next Topic Question]Figure 1: Annotated Dialogue Example Showing Uncertainty AdaptationUNC-DISE ADAPT ITSPOKE-1: Let?s begin by looking at the motion of the man and his keys while he?s holdingthem.
How does his velocity compare to that of his keys?USER-1: vertical (INC, UNC, DISE)UNC-DISE ADAPT ITSPOKE-2: That doesn?t sound right.
Let?s think about this a little more.
[ ProductiveInteraction Feedback] Since the man is holding his keys, they aren?t moving relative to each other.
So their velocitiesmust be WHAT?
[Supplementary Question].Figure 2: Dialogue Example Showing Adaptation for Disengaged+Incorrect TurnsUNC-DISE ADAPT ITSPOKE-1: Let?s begin by looking at the motion of the man and his keys while he?s holdingthem.
How does his velocity compare to that of his keys?USER-1: same same same (COR, CER, DISE).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.UNC-DISE ADAPT ITSPOKE-2a: Well done.
Here?s a quick progress update.
Good effort so far!!
[ProductiveInteraction Feedback When Progress Report Shows Improvement] Now let?s see what happens after the man releaseshis keys.
[...] [Next Topic Question].
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.UNC-DISE ADAPT ITSPOKE-2b: Right.
Here?s a quick progress update.
It might help to remember we will buildon the topics we?re discussing now.
[Productive Interaction Feedback When Progress Report Shows Decline] Now let?ssee what happens after the man releases his keys.
[...] [Next Topic Question]Figure 3: Dialogue Example Showing Adaptation for Disengaged+Correct UsersFigure 4: Example Progress Report after Disengaged+Correct Turn226
