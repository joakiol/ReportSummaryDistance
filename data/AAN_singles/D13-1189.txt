Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1840?1850,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsCollective Opinion Target Extraction in Chinese MicroblogsXinjie Zhou, Xiaojun Wan* and Jianguo XiaoInstitute of Computer Science and TechnologyThe MOE Key Laboratory of Computational LinguisticsPeking UniversityNo.
5, Yiheyuan Road, Beijing, China{zhouxinjie,wanxiaojun,xiaojianguo}@pku.edu.cnAbstractMicroblog messages pose severe challengesfor current sentiment analysis techniques dueto some inherent characteristics such as thelength limit and informal writing style.
In thispaper, we study the problem of extractingopinion targets of Chinese microblog messag-es.
Such fine-grained word-level task has notbeen well investigated in microblogs yet.
Wepropose an unsupervised label propagation al-gorithm to address the problem.
The opiniontargets of all messages in a topic are collec-tively extracted based on the assumption thatsimilar messages may focus on similar opiniontargets.
Topics in microblogs are identified byhashtags or using clustering algorithms.
Ex-perimental results on Chinese microblogsshow the effectiveness of our framework andalgorithms.1 IntroductionMicroblogging services such as Twitter 1 , SinaWeibo2 and Tencent Weibo3 have swept across theglobe in recent years.
Users of microblogs rangefrom celebrities to ordinary people, who usuallyexpress their emotions or attitudes towards a broadrange of topics.
It is reported that there are morethan 340 million tweets per day on Twitter andmore than 200 million on Sina Weibo.
A tweetmeans a post on Twitter.
Since we mainly focuson Chinese microblogs instead of Twitter in thispaper, we will refer to a post as a message.
Eachmessage is limited to 140 Chinese characters andusually contains several sentences.
* Xiaojun Wan is the corresponding author.1 https://twitter.com2 http://weibo.com/3 http://t.qq.com/Currently, researches on microblog sentimentanalysis have been conducted on polarity classifi-cation (Barbosa and Feng, 2010; Jiang el al., 2011;Speriosu et al 2011) and have been proved to beuseful in many applications, such as opinion poll-ing (Tang et al 2012), election prediction(Tumasjan et al 2010) and even stock marketprediction (Bollen et al 2011).
However, classify-ing microblog texts at the sentence level is ofteninsufficient for applications because it does notidentify the opinion targets.
In this paper, we willstudy the task of opinion target extraction for Chi-nese microblog messages.Opinion target extraction aims to find the objectto which the opinion is expressed.
For example, inthe sentence ?The sound quality is good!
?, ?soundquality?
is the opinion target.
This task is mostlystudied in customer review texts in which opiniontargets are often referred as features or aspects(Liu, 2012).
Most of the opinion target extractionapproaches rely on dependency parsing (Zhuang etal., 2006; Jakob and Gurevych, 2010; Qiu et al2011) and are regarded as a domain-dependenttask (Li et al 2012a).
However, such approachesare not suitable for microblogs because the naturallanguage processing tools perform poorly on mi-croblog texts due to their inherent characteristics.Studies show that one of the state-of-the-art part-of-speech taggers - OpenNLP only achieves theaccuracy of 74% on tweets (Liu et al2011).
Thesyntactic analysis tool that generates dependencyrelation may perform even worse.
Besides, mi-croblog messages may express opinion in differentways and do not always contain opinion words,which lowers the performance of methods utiliz-ing opinion words to find opinion targets.In this study, we propose an unsupervisedmethod to collectively extract the opinion targetsfrom opinionated sentences in the same topic.1840Topics are directly identified by hashtags.
We firstpresent a dynamic programming based segmenta-tion algorithm for Chinese hashtag segmentation.By leveraging the contents in a topic, our segmen-tation algorithm can successfully identify out-of-vocabulary words and achieve promising results.Afterwards, all the noun phrases in each sentenceand the hashtag segments are extracted as opiniontarget candidates.
We propose an unsupervisedlabel propagation algorithm to collectively rankthe candidates of all sentences based on the as-sumption that similar sentences in a topic mayshare the same opinion targets.
Finally, for eachsentence, the candidate which gets the highestscore after unsupervised label propagation is se-lected as the opinion target.Our contributions in this study are summarizedas follows: 1) our method considers not only theexplicit opinion targets within the sentence butalso the implicit opinion targets in the hashtag ormentioned in the previous sentence.
2) We devel-op an efficient algorithm to segment Chinesehashtags.
It can successfully identify out-of-vocabulary words by leveraging contextual infor-mation and help to improve the segmentation per-formance of the messages in the topic.
3) Wedevelop an unsupervised label propagation algo-rithm for collective opinion target extraction.
La-bel propagation (Zhu and Ghahramani, 2002) aimsto spread label distributions from a small trainingset throughout the graph.
However, our unsuper-vised algorithm leverages the connection betweentwo adjacent unlabeled nodes to find the correctlabels for both of them.
The proposed unsuper-vised method does not need any training corpuswhich will cost much human labor especially forfine-grained annotation.
4) To the best of ourknowledge, the task of opinion target extraction inmicroblogs has not been well studied yet.
It ismore challenging than microblog sentiment classi-fication and opinion target extraction in reviewtexts.2 Characteristics of Chinese MicroblogsMost of previous microblog sentiment analysisresearches focus on Twitter and especially in Eng-lish.
However, the analysis of Chinese microblogshas some differences with that of Twitter: 1) Chi-nese word segmentation is a necessary step forChinese sentiment analysis, but the existing seg-mentation tool performs poorly on microblogsbecause the microblog texts are much differentfrom regular texts.
2) Wang et al(2011) find thathashtags in English tweets are used to highlightthe sentiment information such as ?
#love?,?#sucks?
or serve as user-annotated coarse topicssuch as ?#news?, ?#sports?.
But in Chinese mi-croblogs, most of the hashtags are used to indicatefine-grained topics such as #NBA??????#(#NBAFinalG7#).
Besides, hashtags in Twitteralways appear within a sentence such as ?I love#BarackObama!?
while hashtags in Chinese mi-croblogs are always isolated and are surroundedby two # symbols such as ?#?????
?# ???!?
(?#BarackObama# I love him??
).It is noteworthy that topics aggregated by thesame hashtag play an important role in Chinesemicroblog websites.
These websites often providean individual webpage4 to list hot topics and invitepeople to participate in the discussion, where eachtopic consists of tens of thousands of messageswith the same hashtag.
The hot topics have a widecoverage of timely events and entities.
Analyzingthe opinion targets of these topics can help to get adeeper overview of the public attitudes towardsthe entities involved in the hot topics.3 MotivationAs described above, #hashtags# in Chinese mi-croblogs often indicate fine-grained topics.
In thisstudy, we aim to collectively extract the opiniontargets of messages with the same hashtag, i.e.
inthe same topic.
Opinion target of a sentence can bedivided into two types, one of which called explic-it target appears in the sentence such as ?I loveObama?, and the other one called implicit target4 http://huati.weibo.com/Topic Sentence#?????
?##Property publicityof government offic-ials#1.
?????
(Just for show?)2.
????????????
(Property publicity is just a showin China.)#??????
?##Philippine navyvessel hits Chinesefishing boat#1.
?????????
(The government is not toughenough.)2.
???????????
(Why cannot the government takea tougher line?
)Table 1.
Motivation Examples1841may appear out of the sentence, for example, thesentence ?Just for show!?
in Table 1 directlycomments on the target in the hashtag ?#Propertypublicity of government officials#?
.
Such implicitopinion targets are not considered in previousworks and are more difficult to extract than explic-it targets.
However, we believe that the contextualinformation will help to locate both of the twokinds of opinion targets because similar sentencesin a topic may share the same opinion target,which provides the possibility for collective ex-traction.Table 1 shows the motivation examples of twotopics and four sentences.
The two sentences ineach topic are considered to be similar becausethey share several Chinese words.
In the topic #?????
?# (#Property publicity of governmentofficials#), the first sentence omits the opiniontarget.
However, the second one contains an ex-plicit target ??????
(?property publicity?)
inthe sentence.
If we find the correct opinion targetfor sentence 2, we can infer that sentence 1 mayhave an implicit opinion target similar to the opin-ion target in sentence 2.
In the second topic, bothsentences contain a noun word ????
(?govern-ment?).
The similarity between these two sentenc-es may indicate that both of the two sentences areexpressing opinion on ???
?.Based on the above observation, we can assumethat similar sentences in a topic may have thesame opinion targets.
Such assumption can help tolocate both explicit and implicit opinion targets.Following this idea, we firstly extract all the nounphrases in each sentence as opinion target candi-dates after applying Chinese word segmentationand part-of-speech tagging.
Afterwards, an unsu-pervised label propagation algorithm is proposedto rank these candidates for all sentences in thetopic.In our methods, hashtags are used to find gold-standard topics.
For messages without hashtags, analternative way is to generate pseudo topics byclustering microblogs messages and then apply theproposed algorithm to each pseudo topic.
The de-tailed discussion of such general circumstance isshown in Section 5.7.4 Methodology4.1 Context-Aware Hashtag SegmentationIn our approach, the Chinese word segmentationsof hashtags and topic contents are treated separate-ly.
Existing Chinese word segmentation toolswork poorly on microblog texts.
The segmentationerrors especially on opinion target words will di-rectly influence the results of part-of-speech tag-ging and candidate extraction.
However, some ofthe opinion target words in a topic are often in-cluded in the hashtag.
By finding the correct seg-ments of a hashtag and adding them to the userdictionary of the Chinese word segmentation tool,we can remarkably improve the overall segmenta-tion performance.The following example can help to understandthe idea better.
In the topic #90???
?# (means?A young man hits an old man?
), ?90??
(literally?90 later?
and means a young man born in the 90s)is an important word because it is the opinion tar-get of many sentences.
However, existing Chineseword segmentation tools will regard it as two sep-arate words ?90?
and ???
(?later?).
Then in thepart-of-speech tagging stage, ?90?
will be taggedas number and ???
will be tagged as localizer.
Aswe only extract noun phrases as opinion targetcandidates, the wrong segmentation on ?90 ?
?makes it impossible to find the right opinion target.Such error may occur many times in sentences thatmention the word ?90??
and express opinion onit.
In our method, the message texts of the topicare utilized to identify such out-of-vocabularywords based on its frequency in the topic.
For ex-ample, the high frequency of ?90??
is a strongindication that it should be regard as a single word.After segmenting the hashtag correctly into ?90?/?/??
?, we can add the hashtag segments to theuser dictionary of the segmentation tool to furthersegment the message texts of the topic.The basic idea for our hashtag segmentation al-gorithm is to regard strings that appear frequentlyin a topic as words.
Formally, given a hashtag hthat contains n Chinese characters c1c2...cn.
Wewant to segment into several words w1w2...wm,where each word is formed by one of more charac-ters.Firstly, we define the stickiness score for a Chi-nese string c1c2...cn based on the SymmetricalConditional Probability (SCP) (Silva and Lopes,1999):184221 21 21 11Pr( ... )( ... ) 1 Pr( ... )Pr( ... )1nn ni i nic c cSCP c c cc c c cn ????
?
(1)and SCP(c1) = Pr(c1)2 for string with only onecharacter.
Pr(c1c2...cn) is the occurrence frequencyof the string in the topic.Following (Li et al 2012b), we smooth theSCP value by taking logarithm calculation.
Be-sides, the length of the string is taken into consid-eration,1 2 1 2( ... ) log ( ... )n nSCP c c c n SCP c c c?
?
?
(2)where n is the number of characters in the string.Then the stickiness score is defined by the sig-moid function as follows:1 21 2 ( ... )2( ... ) 1 nn SCP c c cStickiness c c c e ???
?
(3)For the hashtag h = c1c2...cn, we want to seg-ment it into m words w1w2...wm which maximizethe following equation,1max ( )m iiStickness w??
(4)The optimization of Equation (4) can be solvedefficiently by dynamic programming which itera-tively segments a string into two substrings.
Dif-ferent from (Li et al 2012b) which calculates theSCP value of each string based on Microsoft WebN-Gram, our hashtag segmentation algorithm onlyuses the topic content and do not need any addi-tional corpus.4.2 Candidate ExtractionAfter segmenting the hashtag, all the hashtag seg-ments with length greater than one are added tothe user dictionary of the Chinese word segmenta-tion tool ICTCLAS5 to further segment the mes-sage texts of the topic.
It also assigns the part-of-speech tag for each word after segmentation.
Thenoun phrases in each sentence is extracted by thefollowing regular expression:( | )( ) .noun adj noun adj noun?
?That means anoun phrase can only include nouns, adjectivesand the Chinese word ???
(?of?).
It should beginwith a noun or adjective and end with a noun.
For5 http://www.ictclas.org/example, in the following sentence, ??
?/n ?/u?
?/n ?
?/n ?/v ?
?/n ?/w?
(?Chinese edu-cation system has problems.?
), ?????????
(?Chinese education system?)
and ????
(?prob-lem?)
are extracted as noun phrases.The character number of a noun phrase is lim-ited between two and seven Chinese characters.For each sentence, all phrases that match the regu-lar expression and meet the length restriction areextracted as explicit opinion target candidates.
Thehashtag segments are regarded as implicit candi-dates for all sentences.
Besides, some opinionatedsentences in microblogs do not contain any nounphase, such as ??????
?
(?So boring!?
).These sentences may express opinion on objectthat has been mentioned before.
Therefore, theexplicit candidates of the previous sentence in thesame message are also taken as the implicit candi-dates for such sentences.We do not use any syntactic parsing tool to ex-tract noun phrases because the parsing results onmicroblogs are not reliable.
A performance com-parison of our rule based method and the state-of-the-art syntactic parser will be shown in Section 5.4.3 Unsupervised Label Propagation forCandidate RankingWe simply assume that each opinionated sentencehas one opinion target, which is consistent withAlgorithm 1 Unsupervised Label PropagationInput:Graph:                              , ,G V E W??
?Candidate Similarity:     M MS R ??
?Prior labeling:                 1 MvY R ???
for v?VFiltering Matrix:             M MvF R ???
for v?VProbability:                       pinj and pcontOutput:Label vector:                   1?
MvY R ??
?1: for all v?V do2:v?
vY Y?3: end for4: repeat5:       for all v?V do6:?
?,?v uv u vu V u vD W Y S F?
??
?
?
?7:        ?
inj contv v vY p Y p D?
?8:       end for9: until convergence1843the statistical result of our dataset that over 93%sentences have only one opinion target and eachsentence has an average of 1.09 targets.
Therefore,the most confident candidate of each sentence willbe selected as the opinion target.
In this section,we introduce an unsupervised graph-based labelpropagation algorithm to collectively rank thecandidates of all sentences in a topic.Label propagation (Zhu and Ghahramani, 2002;Talukdar and Crammer, 2009) is a semi-supervised algorithm which spreads label distribu-tions from a small set of nodes seeded with someinitial label information throughout the graph.
Thebasic idea is to use information from the labelednodes to label the adjacent nodes in the graph.However, our idea is to use the connection be-tween different nodes to find the correct labels forall of them.
Our unsupervised label propagationalgorithm is summarized in Algorithm 1.
Sentenc-es are regarded as nodes and candidates of eachsentence are regarded as labels.
The label vectorfor each node is initialized based on the results ofthe candidate extraction step, which means nomanually-labeled instances are needed in ourmodel.
In each iteration, the label vector of onenode is propagated to the adjacent nodes.
Both thesentence (node) similarity and the candidate (label)similarity are considered during propagation.
Fi-nally, we select the candidate with the highestscore in the label vector as the opinion target foreach sentence.
The details of Algorithm 1 are pre-sented as follows.Formally, an undirected graph , ,G V E W??
?is built for each topic.
A node v?V represents asentence in the topic and an edge e = (a, b) ?Eindicates that the labels of the two vertices shouldbe similar.
W  is the normalized weight matrix toreflect the strength of this similarity.
The similari-ty between two nodes Wab is simply calculated byusing the cosine measure (Salton et al 1975) ofthe two sentences.
( , ) a bab a ba bT TW cos T T T T??
?
?
(5)where Ta and Tb are the term vectors of sentences aand b represented by the standard vector spacemodel and weighted by term frequency.
After cal-culating the similarity matrix W, we get the weightmatrix W  by normalizing each row of W such that1abb W ?
?.For each sentence (node) v, a candidate set Cv isextracted in the previous step.
The candidate setCT for the whole topic is the union of all Cv,vCT C?
(6)The total number of candidates in the topic isdenoted by M = |CT|.
We calculate the candidatesimilarity matrix M MS R ???
based on Jaccard In-dex:( ) ( ) 1( ) ( )i jiji jA CT A CTS i j MA CT A CT?
?
?
?
(7)where A(CTi) and A(CTj) are the Chinese charactersets of the i-th and j-th candidates in CT respec-tively.Candidates are regarded as labels in our modeland without loss of generality we assume that thepossible labels for the whole topic are L = {1?M}and each label in L corresponds to a unique can-didate in CT. For each node v?V, a label vector1 MvY R ???
is initialized as?
?
10 k vv k k vw L CY k ML C???
?
??
??
(8)where w is the initial weight of the candidate.
Weset w = we if Lk is an explicit candidate (extractednoun phrase) of v and w = wi if Lk is an implicitcandidate (hashtag segment or inherited from pre-vious sentence) of v. If Lk is not a candidate of thecurrent sentence, then the corresponding value inthe label vector is 0.
These values which are ini-tialized as zero should always remain zero duringthe propagation algorithm because the correspond-ing label does not belong to the candidate set Cv ofnode v. To reset the values on these positions, adiagonal matrix M MvF R ???
is created for all nodesv,?
?
?
??
?1 0 10 0v kv kkv kYF k MY?
???
?
??
???
(9)where the subscript kk denotes the k-th position inthe diagonal of matrix Fv.
We can right-multiplyYv by Fv to clear the values of the invalid candi-1844dates.
Figure 1 shows an example of creating thefiltering matrix for a label vector.The propagation process is formalized via twopossible actions: inject and continue, with pre-defined probabilities pinj and pcont.
Their sum isunit: pinj + pcont = 1.
In each iteration, every node isinfluenced by its adjacent nodes.
The propagationinfluence for each node v is?
?,?v uv u vu V u vD W Y S F?
??
?
??
(10)whereu?Y  is the label vector of node u at the previ-ous iteration.
By multiplying the candidate simi-larity matrix S, we aim to propagate the score ofthe i-th candidate of node u not only to the i-thcandidate of node v, but also to all the other can-didates.
Wuv measures the strength of such propa-gation.
The filtering matrix Fv is used to clear thevalues of the invalid candidates as describedabove.Then the label vector of node v is updated asfollow,?
inj contv v vY p Y p D?
?
(11)When the positions of the largest values in alllabel vectors keep unchanged in ten iterations, it isregarded that the algorithm has already converged.5 Experiments5.1 DatasetWe use the dataset from the 2012 Chinese Mi-croblog Sentiment Analysis Evaluation (CMSAE)6held by China Computer Federation (CCF).
Thereare three tasks in the evaluation: subjectivity clas-sification, polarity classification and opinion targetextraction.
The dataset contains 20 topics collect-ed from Tencent Weibo, a popular Chinese mi-croblogging website.
All the messages in a topiccontain the same hashtag.
The dataset has a total6 http://tcci.ccf.org.cn/conference/2012/pages/page04_eva.html.
The dataset can also be publicly accessed on the website.of 17518 messages and 31675 sentences.
In eachtopic, 100 messages are manually annotated withsubjectivity, polarity and opinion targets.
A totalof 2361opinion targets are annotated for 2152opinionated sentences.5.2 Evaluation MetricPrecision, recall and F-measure are used in theevaluation.
Since expression boundaries are hardto define exactly in annotation guidelines (Wiebeet al 2005), both the strict evaluation metric andthe soft evaluation metric are used in CMSAE.Strict Evaluation: For a proposed opinion tar-get, it is regarded as correct only if it covers thesame span with the annotation result.
Note that, inCMSAE, an opinion target should be proposedalong with its polarity.
The correctness of the po-larity is also necessary.Soft Evaluation: The soft evaluation metricpresented in (Johansson and Moschitti, 2010) isadopted by CMSAE.
The span coverage c be-tween each pair of the proposed target span s andthe gold standard span s?
is calculated as follows,?
?, s sc s s s???
?
?
(12)In Equation 12, the operator |?| counts Chinesecharacters, and the intersection ?
gives the set ofcharacters that two spans have in common.Using the span coverage, the span set coverageC of a set of spans S with respect to another set S?is?
?, ( , )s S s SC S S c s s?
??
???
???
(13)The soft precision P and recall R of a proposedset of spans S?
with respect to a gold standard setS is defined as follows:?
?
( , ) ( , )Precision Recall?
| || |C S S C S SSS?
?
(14)Note that the operator |?| counts spans in Equation14.
The soft F-measure is the harmonic mean ofsoft precision and recall.5.3 Comparison MethodsOur proposed approach is first compared with theCMSAE teams.CMSAE Teams: Sixteen teams participated inthe opinion target extraction task of CMSAE.
Themethods of the top 3 teams are used as baselines?
?1 0 0 00 1 0 01 1 0.5 00 0 1 00 0 0 0v vY F?
??
??
??
?
??
??
??
?Figure 1.
Example of filtering matrix1845here.
They are denoted as Team-1, Team-2 andTeam-3 respectively.
The average result of all thesixteen teams is also included and is denoted asTeam-Avg.
We will briefly introduce the bestteam?s method.
The most important component oftheir model is a topic-dependent opinion targetlexicon which is called object sheet.
If a word orphrase in the object sheet appears in a sentence ora hashtag, it is extracted as opinion target.
Theobject sheet is manually built for each topic,which means their method cannot be applied tonew topics.The following models are also used for compar-ison.AssocMi: We implement the unsupervisedmethod for opinion target extraction based on (Huand Liu, 2004), which relies on association miningand a sentiment lexicon to extract frequent andinfrequent product features.CRF: The CRF-based method used in (Jakoband Gurevych, 2010) is also used for comparison.We implement both the single-domain and cross-domain models.
Both models are evaluated using5-fold cross-validation.
More specifically, the sin-gle-domain model, denoted as CRF-S, trains dif-ferent models for different topics.
In each cross-validation round, 80 percent of each topic is usedfor training and the other 20 percent is used fortest.
The cross-domain model, denoted as CRF-C,uses 16 topics for training and the rest 4 topics fortest in each round.5.4 Comparison ResultsCMSAE requires all the teams to perform the sub-jectivity and polarity classification task in advance.The opinion targets are extracted only for opinion-ated sentences and should be proposed along withtheir polarity.
To make a fair comparison, we di-rectly use the subjectivity and polarity classifica-tion results of Team-1.
Then our unsupervisedlabel propagation (ULP) method is used to extractthe opinion targets for the proposed opinionatedsentences.
The parameters of our method aresimply set as pinj = pcont = 0.5, we = 1 and wi = 0.5.Table 2 lists the comparison results withCMSAE teams.
The average F-measure of allteams is 0.12 and 0.20 in strict and soft evaluation,respectively.
It shows that opinion target extrac-tion is a quite hard problem in Chinese microblogs.Our method performs better than all the teams.
Itincreases by 10% and 13% in the two kinds of F-measure compared to the best team.
Besides, wedo not need any prior information of the topicswhile Team-1 has to manually build an opiniontarget lexicon for each topic.To compare with the other opinion target ex-traction methods, we only use gold-standard opin-ionated sentences for evaluation and do notclassify the polarity of the opinion targets.
Table 3shows the experimental results of the four models.Our approach achieves the best result among them.AssocMi performs worst in strict evaluation butgets better results than the two CRF-based modelsin soft evaluation.
The two CRF-based modelsachieve high precision but low recall.
We can alsoobserve that CRF-S is much more effective thanCRF-C.
It achieves high results because it has al-ready seen the opinion targets in the training set.However, it is impossible to build such single-domain model in practical applications becauseMethodStrict SoftPrecision Recall F-Measure Precision Recall F-MeasureAssocMi 0.22 0.20 0.21 0.47 0.43 0.45CRF-C 0.59 0.15 0.24 0.70 0.18 0.28CRF-S 0.61 0.27 0.35 0.73 0.31 0.41ULP 0.43 0.39 0.41 0.61 0.55 0.58Table 3.
Comparison results with baseline methods (only gold-standard opinionated sentences are used)Method.Strict SoftPrecision Recall F-measure Precision Recall F-measureTeam-Avg 0.17 0.09 0.12 0.29 0.15 0.20Team-3 0.26 0.16 0.20 0.40 0.25 0.31Team-2 0.31 0.18 0.23 0.40 0.22 0.29Team-1 0.30 0.27 0.29 0.39  0.36 0.37ULP 0.37 0.27 0.32 0.48 0.37 0.42Table 2.
Comparison results with CMSAE teams (with subjectivity and polarity classification in advance)1846labeled instances are not available for new topics.Our proposed method does not require any train-ing data and gets an increase of 17% over CRF-Sand 70% over CRF-C in strict evaluation.
In termsof soft evaluation, we achieve an increase of 41%and 107% over the two CRF models.5.5 Parameter Sensitivity StudyIn this section, we study the parameter sensitivity.There are two major parameters in our algorithm:the initial weight w for both explicit and implicitcandidates in Equation 8 and the injection proba-bility pinj in Equation 11.The initial weights of explicit and implicit can-didates are set differently because the explicit can-didates are more likely to be the opinion targets.These two kinds of initial weights are denoted aswe and wi for explicit and implicit candidate, re-spectively.
To study the impact of the initialweights, we fix we at 1 and tune wi because weonly care about the relative contribution of them.The injection probability is fixed at 0.5.
Figure 2(a)displays the opinion target extraction performancewhen wi varies from 0 to 1.5.
Due to limited space,we only list the strict F-measure of opinion targetextraction evaluated on opinioned sentences (sameexperimental setup as Table 3).In particular, when wi is equal to 0, only explicitcandidates are considered.
When wi becomes larg-er than 1, the implicit candidates become moreimportant than explicit candidates.
From the curvein Figure 2(a), we can observe that the implicitcandidates help to improve the performance sig-nificantly when wi varies from 0 to 0.1.
The per-formance reaches the peak when wi = 0.7 anddeclines rapidly when wi gets larger than 1.To study the impact of injection probability pinj,we fix the initial weights for explicit and implicitcandidates as 1 and 0.5, respectively.
Figure 2(b)shows the results of opinion target extraction withrespect to different values of the injection proba-bility.
We can observe that the performance keepssteady except for the two extreme values 0 and 1.From the above two figures, we can conclude thatour proposed method performs well and robustlywith a wide range of parameter values.5.6 Analysis of Candidate ExtractionCandidate extraction is an important step in ourproposed method.
If the correct opinion target isnot extracted as a candidate, the ranking step willbe in vain.
As described in Section 3, we developa hashtag segmentation algorithm and use a rulebased method to extract noun phrases from eachsentence.
We do not use any parsing tool becausewe believe the performance of these tools is notgood enough when applied on microblogs.
Aquantitative comparison is shown in this section.We use one of the state-of-the-art syntacticanalysis tools - Berkeley Parser (Petrov et al2006) for comparison here.
Noun phrases are di-rectly extracted from the parsing results.
Ourmethod HS+Rule leverages the hashtag segmentsto enhance the segmentation result and extractsexplicit candidate using a regular expression.
Todemonstrate the effectiveness of our hashtag seg-mentation algorithm, the second comparison base-line Rule directly uses ICTCLAS to segment thewhole topic content and labels each word with itspart-of-speech tag.
The explicit candidates are ex-tracted by using the same regular expression.The performance on candidate extraction iscompared in Table 4.
The second column showsthe number of all extracted candidates for all theopinionated sentences by different methods.
Thethird column shows the number of correct opiniontargets among them.
We can find that the two rule-based models both outperform Berkeley Parserand our HS+Rule method finds 14% more correctopinion targets than Rule.
It proves the effective-ness of our hashtag segmentation algorithm.
TheMethod Total CorrectF-Measure of OpinionTarget ExtractionStrict SoftBerkleyParser4554 877 0.36 0.56Rule 4105 918 0.37 0.56HS + Rule 4094 1042 0.41 0.58Table 4.
Performance of candidate extraction andopinion target extraction0.30.320.340.360.380.40.420.440 0.2 0.4 0.6 0.8 1PrecisionRecallF-Measurepinj0.30.320.340.360.380.40.420.440 0.2 0.4 0.6 0.8 1 1.2 1.4PrecisionRecallF-Measurewi(a) Initial Candidate Weight        (b) Injection ProbabilityFigure 2.
Influence of the parameters1847total number of candidates extracted by HS+Ruleis also less than the other two methods.
Therefore,the performance of label propagation will be im-proved when there are fewer candidates to rank.
Itcan be demonstrated by the F-measure of opiniontarget extraction in the fourth and fifth columns.The experiments are conducted on opinionatedsentence only as above.
By using HS+Rule to ex-tract candidates, our label propagation algorithmgets the highest F-measure in both evaluation met-rics.5.7 Performance on Pseudo Topics by Mes-sage ClusteringIn our collective extraction algorithm, topics aredirectly identified by hashtags.
For messageswithout hashtags, we can first employ clusteringalgorithms to obtain pseudo topics (clusters) andthen exploiting the topic-oriented algorithm forcollective opinion target extraction.
To test theperformance of the proposed method in such cir-cumstance, we use the popular clustering algo-rithm - Affinity Propagation (Frey and Dueck,2007) to generate topics.
The experimental resultsare shown in Table 5.
APCluster means that themessages are clustered after removing all thehashtags.
APCluster+HS means that all thehashtags are retained as normal texts for calculat-ing message similarity.
Therefore, the clusteringperformance can be largely improved.
The stand-ard cosine similarity is used to measure the dis-tance between microblog messages for AffinityPropagation in the above two methods.
The lastmethod denoted as GoldCluster directly useshashtags to identify the gold-standard topics whichshows the upper bound of the performance.
Afterclustering microblogs, the opinion targets of mes-sages in each cluster are collectively extracted bythe proposed unsupervised label propagation algo-rithm.
The experiments are conducted on opinion-ated sentences only.From the results, we can see that clustering mi-croblogs without hashtags is a quite difficult jobwhich only gets an F-Measure of 0.27.
However,the corresponding opinion target extraction per-formance is still promising, which outperforms theAssocMi and CRF-C methods in Table 3.
With thehelp of hashtags, the clustering performance ofAPCluster+HS is largely improved and the opin-ion target extraction performance is also increased.It outperforms all the baseline methods in Table 3.The above results reveal that our proposed unsu-pervised label propagation algorithm works wellin pseudo topics and the performance can be in-creased with better clustering results.
Therefore,we can try to incorporate other social network in-formation to improve the message clustering per-formance, which will be studied in our futurework.6 Related WorkSentiment analysis, a.k.a.
opinion mining, is thefield of studying and analyzing people?s opinions,sentiments, evaluations, appraisals, attitudes, andemotions (Liu, 2012).
Most of the previous senti-ment analysis researches focus on customer re-views (Pang et al 2002; Hu and Liu, 2004) andsome of them focus on news (Kim and Hovy,2006) and blogs (Draya et al 2009).
However,sentiment analysis on microblogs has recently at-tracted much attention and has been proved to bevery useful in many applications.Classification of opinion polarity is the mostcommon task studied in microblogs.
Go et.al(2009) follow the supervised machine learningapproach of Pang et al(2002) to classify the po-larity of each tweet by distant supervision.
Thetraining dataset of their method is not manuallylabeled but automatically collected using theemoticons.
Barbosa and Feng (2010) use the simi-lar pseudo training data collected from threeonline websites which provide Twitter sentimentanalysis services.
Speriosu et al(2009) explorethe possibility of exploiting the Twitter followergraph to improve polarity classification.Opinion target extraction is a fine-grainedword-level task of sentiment analysis.
Currently,this task has not been well studied in microblogsyet.
It is mostly performed on product reviewswhere opinion targets are always described asproduct features or aspects.
The pioneering re-search on this task is conducted by Hu and LiuClustering MethodF-Measureof ClusteringF-Measure of OpinionTarget ExtractionStrict SoftAPCluster 0.27 0.35 0.50APCluster+HS 0.71 0.37 0.55GoldCluster 1.00 0.41 0.58Table 5.
Performance of clustering and opiniontarget extraction1848(2004) who propose a method which extracts fre-quent nouns and noun phrases as the opinion tar-gets.
Jakob and Gurevych (2010) model theproblem as a sequence labeling task based onConditional Random Fields (CRF).
Qiu et al(2011) propose a double propagation method toextract opinion word and opinion target simulta-neously.
Liu et al(2012) use the word translationmodel in a monolingual scenario to mine the asso-ciations between opinion targets and opinionwords.7 Conclusion and Future WorkIn this paper, we study the problem of opiniontarget extraction in Chinese microblogs which hasnot been well investigated yet.
We propose an un-supervised label propagation algorithm to collec-tively rank the opinion target candidates of allsentences in a topic.
We also propose a dynamicprogramming based algorithm for segmentingChinese hashtags.
Experimental results show theeffectiveness of our method.In future work, we will try to collect and anno-tate data for microblogs in other languages to testthe robustness of our method.
The repost and replymessages can also be integrated into our graphmodel to help improve the results.AcknowledgmentsThe work was supported by NSFC (61170166),Beijing Nova Program (2008B03) and NationalHigh-Tech R&D Program (2012AA011101).ReferencesBarbosa Luciano and Junlan Feng.
2010.
Robust senti-ment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters.
Associationfor Computational Linguistics, 2010.Johan Bollen, Huina Mao and Xiaojun Zeng.
2011.Twitter mood predicts the stock market.
Journal ofComputational Science 2.1 (2011): 1-8.G?rard Dray, Michel Planti?, Ali Harb, Pascal Poncelet,Mathieu Roche and Fran?ois Trousset.
2009.
Opin-ion Mining from Blogs.
In International Journal ofComputer Informa-tion Systems and Industrial Man-agement Applications.Brendan J. Frey and Delbert Dueck.
2007.
"Clusteringby passing messages between data points."
Science315.5814 (2007): 972-976.Alec Go, Richa Bhayani and Lei Huang.
2009.
Twittersentiment classification using distant supervision.CS224N Project Report, Stanford (2009): 1-12.Minqing Hu and Bing Liu.
Mining and summarizingcustomer reviews.
2004.
In Proceedings of the tenthACM SIGKDD international conference onKnowledge discovery and data mining, pp.
168-177.ACM.Long Jiang , Mo Yu, Ming Zhou, Xiaohua Liu andTiejun Zhao.
2011.
Target-dependent twitter senti-ment classification.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, vol.
1,pp.
151-160.Niklas Jakob and Iryna Gurevych.
Extracting opiniontargets in a single-and cross-domain setting withconditional random fields.
2010.
In Proceedings ofthe 2010 Conference on Empirical Methods in Natu-ral Language Processing.
Association for Computa-tional Linguistics.Richard Johansson and Alessandro Moschitti.
2010.Syntactic and semantic structure for opinion expres-sion detection.
Proceedings of the Fourteenth Con-ference on Computational Natural LanguageLearning.
Association for Computational Linguistics.Soo-Min Kim and Eduard Hovy.
2006.
ExtractingOpinions, Opinion Holders and Topics Expressed inOnline News Media Text.
In Proceedings of theACL Workshop on Sentiment and Subjectivity inText, 2006, pp.
1?8.Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang andXiaoyan Zhu.
2012a.
Cross-Domain Co-Extractionof Sentiment and Topic Lexicons.
In Proceedings ofthe 50th Annual Meeting of the Association forComputational Linguistics, pages 410?419, Jeju,Republic of Korea, 8-14 July 2012.Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao,Anwitaman Datta, Aixin Sun and Bu-Sung Lee.2012b.
Twiner: Named entity recognition in targetedtwitter stream.
In Proceedings of the 35th interna-tional ACM SIGIR conference on Research and de-velopment in information retrieval, pp.
721-730.ACM.Xiaohua Liu, Kuan Li, Ming Zhou and ZhongyangXiong.
2011.
Collective semantic role labeling fortweets with clustering.
In Proceedings of the Twen-ty-Second international joint conference on Artificial1849Intelligence-Volume Volume Three, pp.
1832-1837.AAAI Press.Bing Liu.
2012.
Sentiment analysis and opinion mining.Synthesis Lectures on Human Language Technolo-gies 5.1 (2012): 1-167.Kang Liu, Liheng Xu and Jun Zhao.
2012.
OpinionTarget Extraction Using Word-Based TranslationModel.
In Proceedings of the 2012 Joint Conferenceon Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing.Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification usingmachine learning techniques.
In Proceedings of theACL-02 conference on Empirical methods in naturallanguage processing-Volume 10, pp.
79-86.
Associa-tion for Computational Linguistics.Slav Petrov, Leon Barrett, Romain Thibaux and DanKlein.
Learning accurate, compact, and interpretabletree annotation.
2006.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand the 44th annual meeting of the Association forComputational Linguistics, pp.
433-440.Guang Qiu, Bing Liu, Jiajun Bu and Chun Chen.
2011.Opinion word expansion and target extractionthrough double propagation.
Computational linguis-tics 37, no.
1 (2011): 9-27.G.
Salton, A. Wong and C. S. Yang.
1975.
A VectorSpace Model for Automatic Indexing, Communica-tions of the ACM, vol.
18, nr.
11, pages 613?620.J.
F. da Silva and G. P. Lopes.
1999.
A local maximamethod and a fair dispersion normalization for ex-tracting multi-word units from corpora.
In Proc.
ofthe 6th Meeting on Mathematics of Language .Michael Speriosu, Nikita Sudan, Sid Upadhyay andJason Baldridge.
2011.
Twitter polarity classificationwith label propagation over lexical links and the fol-lower graph.
In Proceedings of the First Workshopon Unsupervised Learning in NLP, pp.
53-63.
Asso-ciation for Computational Linguistics, 2011.Partha Talukdar and Koby Crammer.
New regularizedalgorithms for transductive learning.
2009.
MachineLearning and Knowledge Discovery in Databases(2009): 442-457.Jie Tang, Yuan Zhang, Jimeng Sun, Jinhai Rao, Wen-jing Yu, Yiran Chen and A. C. M. Fong.
2012.Quantitative study of individual emotional states insocial networks.
Affective Computing, IEEE Trans-actions on 3, no.
2 (2012): 132-144.Andranik Tumasjan, Timm O. Sprenger, Philipp G.Sandner and Isabell M. Welpe.
2010.
Predictingelections with twitter: What 140 characters revealabout political sentiment.
In Proceedings of thefourth international aaai conference on weblogs andsocial media, pp.
178-185.X.
Zhu and Z. Ghahramani.
2002.
Learning from la-beled and unlabeled data with label propagation.Technical report, CMU CALD tech report.Li Zhuang, Feng Jing and Xiaoyan Zhu.
2006.
Moviereview mining and summarization.
In Proceedings ofthe ACM 15th Conference on Information andKnowledge Management, pages 43?50, Arlington,Virginia, USA, November.1850
