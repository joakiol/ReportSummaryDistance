Proceedings of the Workshop on BioNLP, pages 63?70,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsInvestigation of Unsupervised Pattern Learning Techniques for BootstrapConstruction of a Medical Treatment LexiconRong Xu, Alex Morgan, Amar K DasBiomedical Informatics ProgramStanford UniversityStanford, CA 94305, USAxurong@stanford.eduAlan GarberPrimary Care and Outcomes ResearchStanford UniversityStanford, CA94305, USAAbstractDictionaries of biomedical concepts (e.g.
dis-eases, medical treatments) are critical sourceof background knowledge for systems doingbiomedical information retrieval, extraction,and automated discovery.
However, the rapidpace of biomedical research and the lack ofconstraints on usage ensure that such dictio-naries are incomplete.
Focusing on medicaltreatment concepts (e.g.
drugs, medical pro-cedures and medical devices), we have devel-oped an unsupervised, iterative pattern learn-ing approach for constructing a comprehen-sive dictionary of medical treatment termsfrom randomized clinical trial (RCT) ab-stracts.
We have investigated different meth-ods of seeding, either with a seed pattern orseed instances (terms), and have compareddifferent ranking methods for ranking ex-tracted context patterns and instances.
Whenused to identify treatment concepts from 100randomly chosen, manually annotated RCTabstracts, our medical treatment dictionaryshows better performance (precision:0.40, re-call: 0.92 and F-measure: 0.54) over themost widely used manually created medicaltreatment terminology (precision: 0.41, recall:0.52 and F-measure: 0.42).1 IntroductionDictionary based natural language processing sys-tems have been widely used in recognizing medicalconcepts from free text.
For example, the MetaMapprogram is used to map medical text to conceptsfrom the most widely used biomedical terminol-ogy, the Unified Medical Language System (UMLS)Metathesaurus (Aronson, 2000).
It identifies variousforms of UMLS concepts in text and returns themas a ranked list using a five-step process: identify-ing simple noun phrases (NP?s), generating variantsof each phrase, finding matched phrases, assign-ing scores to matched phrases and composing map-pings.
However, its performance largely depends onthe quality of the underlying UMLS Metathesaurusand its manually created rules and variants.
Onestudy has shown that, of the medical concepts iden-tified by human subjects, more than 40% were notin UMLS (Pratt, 2003).
Other examples of map-ping text to controlled biomedical terminologies in-clude (Cohen, 2005) and (Fang, 2006).
Many othersystems make heavy use of biomedical terminolo-gies directly such as the work of Blaschke, et al(Blaschke, 2002) and Friedman et al (Friedman,2001).Biomedical terminology is highly dynamic, bothbecause biomedical research is itself highly dy-namic, but also because there are essentially no con-straints on the use of new terminological variants,making the terms used in free text quite differentfrom the canonical forms listed in controlled ter-minologies.
To contrast UMLS with actual textmentions, there are 150 different chemotherapy con-cepts in UMLS.
The majority of these terms de-rive from the diseases they are used to treat.
Forexample cancer chemotherapy, AIDS chemother-apy, brain disorder chemotherapy, and alcoholismchemotherapy.
On the other hand, we have identi-fied more than 1,000 different chemotherapy typesmentioned in RCT (Randomized Clinical Trial) re-port abstracts, with most of the names derived63from the chemicals contained in the chemother-apy regimen, such as platinum-based chemother-apy or fluorouracil-based chemotherapy.
There islittle overlap between the chemotherapy terms inUMLS and the ones used in RCT abstracts.
Evenfor simple drug names as 5-fluorouracil and tamox-ifen, there are many clinically distinct and importantvariants of these drugs which are absent in UMLSas distinct terms/concepts, such as intralesional 5-fluorouracil, topical 5-fluorouracil, intrahepatic ar-terial 5-Fluorouracil, adjuvant sequential tamox-ifen, and neoadjuvant tamoxifen.There has been considerable work on expand-ing the coverage of biomedical dictionaries throughmorphological variants, but these approaches re-quire an initial term dictionary with reasonableextensive coverage.
Examples include the ap-proaches developed by Krauthammer and Nenadic(Krauthammer, 2004), Tsuruoka and Tsujii (Tsu-ruoka, 2004) & (Tsuruoka, 2003), Bodenreider, etal.
(Bodenreider, 2002), and Mukherjea and col-leagues (Mukherjea, 2004).
An important short-coming with static, human derived terminologiesthat cannot easily be addressed by looking for vari-ants of existing terms is the fact that continual devel-opments in medical therapies constantly gives riseto new terms.
Examples include, Apomab, Bap-ineuzumab, Bavituximab, Etaracizumab, and Figi-tumumab.
These all represent a new generation oftargeted biological agents currently in clinical trialsnone of which appear in UMLS.
Clearly we need todevelop techniques to deal with this dynamic termi-nology landscape.MEDLINE is the most extensive and authoritativesource of biomedical information.
Large quantitiesof biomedical text are available in MEDLINE?s col-lection of RCT reports with over 500,000 abstractsavailable.
RCT reports are a critical resource for in-formation about diseases, their treatments, and treat-ment efficacy.
These reports have the advantage ofbeing highly redundant (a disease or treatment nameis often reported in multiple RCT abstracts), medi-cally related, coherent in writing style, trustworthyand freely available.In our recent study (Xu, 2008), we have devel-oped and evaluated an automated, unsupervised, it-erative pattern learning approach for constructinga comprehensive disease dictionary from RCT ab-stracts.
When used to identify disease concepts from100 manually annotated clinical abstracts, the dis-ease dictionary shows significant performance im-provement (F1 increased by 35-88%) over UMLSand other disease terminologies.
It remained tobe demonstrated that these bootstrapping techniquesare indeed rapidly retargetable and can be extendedto other situations, and so we have extended ourscope to investigate medical treatment names in ad-dition to disease terms in this work.Our approach is inspired by the frameworkadopted in several bootstrapping systems for learn-ing term dictionaries, including (Brin, 1998), (?
),and (Agichtein, 2000).
These approaches are basedon a set of surface patterns (Hearst , 1992), whichare matched to the text collection and used to findinstance-concept relations.
Similar systems includethat of Snow and colleagues (Snow, 2005), whichintegrates syntactic dependency structure into pat-tern representation and has been applied to the taskof learning instance-of relations, and the approachdeveloped of Caprosaso, et al (Caprosaso, 2007)which focussed on learning text context patterns toidentify mentions of point mutations.All iterative learning systems suffer from the in-evitable problem of spurious patterns and instancesintroduced in the iterative process.
To analyze dif-ferent approaches to addressing this issue, we havecompared three different approaches to ranking ex-tracted patterns and three different approaches toranking extracted instances.
Because such systemsalso depend on an initial seeding with either a seedpattern or term instance, an important question iswhether these different starting points lead to dif-ferent results.
We investigated this issue by startingfrom each point separately and compared the finalresults.2 Data and Methods2.1 Data509,308 RCT abstracts published in MEDLINEfrom 1965 to 2008 were parsed into 8,252,797 sen-tences.
Each sentence was lexically parsed to gen-erate a parse tree using the Stanford Parser.
TheStanford Parser (Klein, 2003) is an unlexicalizednatural language parser, trained on a non-medicaldocument collection (Wall Street Journal).
We used64the publicly available information retrieval library,Lucene, to create an index on sentences and theircorresponding parse trees.
For evaluation and com-parison, 241,793 treatment terms with treatment re-lated semantics types from UMLS were used.2.2 Unsupervised Instance Extraction andPattern DiscoveryFigure 1 describes the bootstrapping algorithm usedin learning instances of treatment and their associ-ated text patterns.
The algorithm can operate in twomodes, either starting with a seed pattern p0, whichrepresents a typical way of writing about treatments,or a set of seed instances, (di).
For example, theseed pattern we used was ?treated with NP?
(NP:noun phrase).
The program loops over a procedureconsisting of two steps: instance extraction and pat-tern discovery.
In the instance extraction step, pat-terns are used as search queries to the local searchengine.
The parse trees with given patterns are re-trieved and noun phrases (instances of treatments)following the pattern are matched from the parsetrees.
In the pattern discovery step, instances ex-tracted from the previous iteration are used as searchqueries to the local search engine.
Correspondingsentences containing instance mentions are retrievedand the bigrams (two words) in front of instances areextracted as patterns.
When seeding with an initialpattern, only two iterations are typically needed, asexperience shows that most of reliable patterns andinstances have been discovered at this stage.
The al-gorithm stops after a single iteration when seedingwith a list of instances.2.3 Selecting Seed InstancesOf the 241,793 treatment related terms in theUMLS, only about 22,000 (9%) of these have ap-peared in MEDLINE RCT reports.
We randomlyselected 500 drug terms and 500 medical procedureterms from the 22,000 terms as seed instances andused them in the pattern discovery system describedabove.2.4 Pattern RankingA newly discovered pattern is scored on how simi-lar its output (instances associated with the pattern)is to the output of the initial seed pattern.
Intu-itively, a reliable pattern is one that is both highlyInstanceExtractionPatternDiscoveryInstance& patternrankingSeed patternRCTDBSeed InstanceFigure 1: General scheme of the iterative method.precise (high precision) and general (high recall).Using the output instances from the seed pattern p0as a comparison, we developed Precision Based, Re-call Based, and F1 Based algorithms to rank pat-terns.
We define instances(p) to be the set ofinstances matched by pattern p, and the intersec-tion instances(p)?
instances(p0) as the set of in-stances matched by both pattern p and p0.1.
Precision Based rank:score1(p) = instances(p)?
instances(p0)instances(p)(1)The precision based ranking method favorsspecific patterns.2.
Recall Based rank:score2(p) = instances(p)?
instances(p0)instances(p0) (2)The recall based ranking method favors gen-eral patterns.3.
F1 based rank:score3(p) = 2?
score1(p)?
score2(p)score1(p) + score2(p)(3)A combination of the Precision Based and theRecall Based evaluation methods is the F165Based ranking method, which takes into ac-count both pattern specificity and pattern gener-ality.
This method favors general patterns whilepenalizing overly specific patterns.2.5 Instance RankingA reliable instance is one that is associated with areliable pattern many times.
We experimented withthree ranking algorithms:1.
Abundance Based rank: A treatmentinstance(d) that is obtained multiple timesis more likely to be a real treatment conceptwhen compared with one that has only asingle mention in the whole corpus.
We definescoreA(d) as the number of times where dappears in the corpus.2.
Pattern Based rank: A treatment instance ob-tained from multiple patterns is more likelyto be a real treatment concept when comparedwith the one that was obtained by a single pat-tern (p).
Pattern Based rank takes into accountthe number of patterns that generated the in-stance, score of those patterns, and the num-ber of times that the instance is associated witheach pattern (count(p, d)).scoreB(d) =n?i=0log score3(pi)?count(pi, d)(4)3.
Best Pattern Based rank: A treatment instanceobtained from a highly ranked pattern is morelikely to be a real treatment concept when com-pared with the one that was obtained from apoorly ranked pattern.
First the instances areranked by the best pattern (pb) that generatedthe instances and then further ties are brokenby the number of times the instance is associ-ated with that pattern (count(p, d)) to providescoreC(d).2.6 Comparison of Patterns Derived fromDifferent Seed TypesThe patterns extracted when starting with either seedinstances or a seed pattern are ranked by the recallbased method and F1-based method, then the over-laps at different cutoffs are measured to assess thesimilarity of the patterns discovered by starting withthe different starting seed types.2.7 Evaluation of Stanford Parser inIdentifying Treatment Noun PhraseAn important question is how accurate the Stan-ford Parser is at identifying the relevant term bound-aries.
We used manually curated treatment namesfrom UMLS to measure the accuracy of the Stan-ford Parser in identifying treatment noun phrases.With NPcount(treatment) defined as number oftimes that the Stanford Parser identifies a treatmentas noun phrase or part of a noun phrase in the dataand count(treatment) as number of times the treat-ment appears in the data.accuracy = 1nn?i=0(NPcount(di)count(di))(5)2.8 Evaluation of the extracted treatmentlexiconWe assessed the quality (precision and recall) of ourlexicon by using it to identify treatment concepts in100 randomly selected RCT abstracts where treat-ment names were manually identified.
In addition,we also compared the performance of our lexiconwith that of UMLS.3 Results3.1 Evaluation of Stanford Parser inIdentifying Treatment Noun PhrasesEven though the Stanford Parser is trained on non-medical data, it is highly accurate in identifyingtreatments as noun phrases or parts of a noun phrasewith accuracy of 0.95.
The reason may be that medi-cal treatments are indeed often noun phrases or partsof a noun phrase in RCT reports, and there are strongsyntactical signals for their phrasal roles in the sen-tences.
For example, treatments are often either theobject of a preposition (e.g.
efficacy of fluorouraciland treated with fluorouracil) or the subject of a sen-tence (e.g.
fluorouracil is effective in treating coloncancer).3.2 Comparison between Seed TypesThere is considerable overlap in discovered patternsbetween starting with a single seed pattern and start-66ing with the 1,000 seed instances and little differ-ence in overall performance.
12,241 patterns arefound to be associated with the 1,000 seed treatmentinstances.
However, only the most highly rankedpatterns are relevant (see Evaluation of The Ex-tracted Treatment Lexicon, below).
Table 1 showsthe intersection of the top ranked patterns betweenboth seeding methods at different rank cut-offs.
Wefind a very high level of intersection between the topranked patterns from both initial seed types, for ex-ample eighteen of the top twenty patterns are iden-tical.
These results indicate that starting from eitherseed type leads to very similar results.Rank Recall Based F1 Based10 0.90 0.8020 0.90 0.9030 0.87 0.8040 0.83 0.8550 0.84 0.8260 0.82 0.8570 0.82 0.7980 0.83 0.8490 0.84 0.83100 0.82 0.83Table 1: : The ratio of overlap in the top ranking patternsdiscovered by different seed types3.3 Pattern RankingSimilar to the results observed in our previous study(Xu, 2008), the Precision Based metric assigns highscores to very specific but not generalizable patternssuch as ?lornoxicam versus?
(Table 2), which ap-pears only once in the data collection, while thetop 10 patterns based on the Recall Based and F1Based rankings are typical treatment related pat-terns.
When a different seed pattern ?efficacy of ?was used, the top 10 patterns were the same with adifferent rank ordering.3.4 Instance rankingTable 3 shows the top 10 suggested treatment nameswhen using ?treated with?
as the initial seed pattern.The rank of a proposed treatment instance is deter-mined by the different ranking methods: AbundanceBased, Pattern Based, or Best Pattern Based ranking# Precision based Recall based F1 based1 beta-blockers nor treated with treated with2 lornoxicam versus treatmentwithtreatment with3 piroxantrone and effects of efficacy of4 heparin called efficacy of effects of5 anesthetics con-tainingdose of dose of6 antioestrogens and doses of doses of7 markedly adsorb suggest that suggest that8 recover following study of safety of9 Phisoderm and response to response to10 MitoExtra and effect of effect ofTable 2: Top 10 patterns with ?treated with?
as seed pat-ternalgorithms.
None of the top 10 extracted phrases onthe basis of Abundance Based or Pattern Based areactual treatment names.
These two ranking methodsassign high ranks to common, non-specific phrases.The Best Pattern Based ranking method correctlyidentifies specific treatment mentions, mainly be-cause it reduces the likelihood of selecting irrelevantpatterns.# Abundance Pattern Best patternbased based based1 patients patients placebo2 treatments the treatment chemotherapy3 the treatments treatments radiotherapy4 children the use tamoxifen5 the effect children antibiotics6 no significantdifferencessurgery insulin7 placebo the patients interferon8 surgery changes surgery9 the effects women corticosteroids10 the study use cisplatinTable 3: Top 10 treatments when using ?treated with?
asthe seed pattern3.5 Evaluation of the Extracted TreatmentLexiconOur dictionary derived from using ?treated with?as the seed pattern with two bootstrapping itera-67Count Cutoff Precision Recall F117,683 1.0% 0.404 0.921 0.54088,415 5% 0.127 1.0 0.22132,623 7.5% 0.105 1.0 0.187176,832 10% 0.088 1.0 0.160Table 4: Precision, recall and F1 at 4 cutoff valuestions consists of 1,768,320 candidate instances and78,037 patterns, each with an accompanying confi-dence score.
The top 20 patterns are associated withmore than 90% of the instances.
We evaluated thequality of the dictionary by using it to identify treat-ment concepts in 100 randomly selected abstractswhere treatment names were manually annotated.There were an average of three treatment names pertest abstract.
Table 4 shows the precision, recall andF1 values when instances are ranked by the best pat-tern based ranking method (ScoreC).
The precision,recall and F1 values at each cut-off (percentage of allinstances) were averaged across the 100 abstracts.The precision, recall and F1 of the UMLSMetathesaurus in identifying treatment names fromthe test dataset are 0.41, 0.52 and 0.42 respectively.The performance using UMLS on this task is con-sistent with a previous study (Pratt, 2003).
The lowprecision may due to the fact that UMLS often tagsirrelevant names as treatment related names.
For ex-ample, common, non-specific terms such as drug,agent, treatment and procedure appear in the dictio-nary derived from UMLS.
However, we chose not toedit the lexicon derived from UMLS as it is unclearhow to do so in a systematic matter without essen-tially creating a new version of UMLS, and we areinterested in studying methods that do not rely onany human involvement (our Discussion describesthe possible inclusion of human judgments).
Also,the low recall of UMLS is not surprising given thefact that the names specified in UMLS are often notthe terms authors use in writing.
The performanceof our dictionary (precision: 0.40, recall: 0.92, F1:0.54) is a dramatic improvement over using UMLS.Our recall is high since all the terms are learned fromthe literature directly and exemplify the manner inwhich authors write RCT reports.
However, the pre-cision of our dictionary is still low (see Discussion).4 DiscussionWe have demonstrated an automated, unsupervised,iterative pattern learning approach for bootstrappingconstruction of a comprehensive treatment lexicon.We also compared different pattern and instanceranking methods and different initial seed types (in-stances or patterns).
On the task of term identifica-tion, use of our boostrapped lexicon increased per-formance over using the most widely used manuallycurated terminology (UMLS).We have extended ourprevious work to the identification of new termi-nology types, demonstrating the versatility of thisapproach.
Our approach may also be used withother data sources such as general health related webpages.
However, there is still significant space inwhich to seek improvement in increasing the cover-age of our lexicon and the quality of our patterns.Although useful in demonstrating the proof ofconcept and allowing us to examine different rank-ing methods, focusing on bigrams that precedenoun-phrases limited the space of patterns that wecould potentially examine.
More complex patternsmight be involved.
For example, in the sentence?Pravastatin is an effective and safe drug?
(PMID08339527), there is a distinctive treatment relatedpattern ?NP is an effective and safe drug?
that ourtechnique does not capture.
However, most keyterms are mentioned in multiple contexts.
For ex-ample, Pravastatin appears with the seed patterntreatment with more than 200 times.
As our corpusof literature increases, redundancy will increase thelikelihood of a treatment term being matched by thetype of patterns we recognize.
The rapid growth ofbiomedical knowledge and literature, which makesour automatically generated medical treatment vo-cabulary necessary, can also act to increase its cov-erage over time.In order to keep our algorithm simple, we did notperform deep grammatical analysis.
For example, inthe sentence ?Treatment of the subjects with atorvas-tatin decreased the abundance of IL-12p35 mRNA inmononuclear cells?
(PMID 12492458), atorvastatinis associated with treatment of, not subjects with.Since our algorithms simply extracts the two wordsin front of treatment names, subjects with will be ex-tracted as treatment related pattern.
In fact, subjectswith is a disease related pattern in RCT reports, for68example ?34 subjects with asthma?.
But our patternranking algorithm will assign a low score to subjectswith since the terms associated with this pattern aremore disease related and have little overlap with theoutput of the seed pattern treatment with.Our instance ranking assigns high confidencescores to common and non specific terms like thisdrug, the treatment or this procedure since they areoften associated with highly ranked patterns manytimes.
These anaphoric terms often refer to treat-ment names previously specified.
There are at leasttwo ways to address this problem.
The first is to as-sign low scores to terms starting with a determinersuch as the or this.
Another way to improve the in-stance ranking algorithm is to take into account ofthe overall context of the term.
For example, theseanaphora often appear in specific sections of RCTreports such as the result section, and refer to termsfrom previous sections.
Specific examples include?Treatment with this drug should be attempted inintractable cases?
(PMID 09038009) and ?The effi-cacy of the treatment was 88 and 95% in group 1 and2, respectively?
(PMID 14520944).
The terms fromtitle, background or conclusion sections could be as-signed higher scores than the ones from result sec-tion.
Beyond these simple heuristics, more sophisti-cated approaches might take advantage of the workin anaphora resolution, such as (Baldwin, 2001).The lexicon consists of terms with mixed hi-erarchies, including general terms as chemother-apy, surgery, corticosteroids, antibiotics, and spe-cific terms as fluorouracil, oral or intravenous 5-Fluorouracil, cisplatin, nephrectomy.
In order tomake this dictionary more useful, additional workis needed to organize the terms and build ontologiesbased on the lexicon.Previous work has shown that learning multiplesemantic types simultaneously can improve preci-sion (Thelen, 2002) & (Curran, 2007), and it re-mains to be seen if that approach can be combinedwith the prioritization of pattern and extracted in-stance rankings here to give better overall perfor-mance.
Other possible extensions and improve-ments include various approaches to slow the learn-ing process and discover new patterns and instancesmore conservatively, at the expense of more itera-tions.
Further improvements can be expected fromintegrating active learning approaches to includethe involvement of a human judge in the process,analogous to the tag-a-little, learn-a-little methodproposed as part of the Alembic Workbench (Day,1997).
Because our approach ranks both extractedpatterns and instances, it is amenable to such tech-niques.
Indeed, active learning has been foundto provide considerable gains in corpus annotation(Tomanek, 2007) & (Buyko, 2007), and can be amodel for semi-automated terminology compilation.All the data and code are available on requestfrom the author.AcknowledgmentsRX is supported by NLM training grant LM007033and Stanford Medical School.ReferencesE.
Agichtein, L Gravano.
2000.
Snowball: extractingrelations from large plaintext collections, In Proc ofthe 5th ACM conference on Digital libraries .A.R.
Aronson 2001.
Effective mapping of biomedicaltext to the UMLS Metathesaurus: the MetaMap pro-gram.
Proc AMIA Symp:17-21.B.
Baldwin 2001.
Text and knowledge mining for coref-erence resolution.
Second meeting of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Language technologies:1-8.C.
Blaschke, A. Valencia.
2002.
The frame-based mod-ule of the SUISEKI information extraction system, In-telligent Systems, IEEE, 17; 2:14 - 20.O.
Bodenreider, T.C.
Rindflesch, A. Burgun, 2002.Unsupervised, corpus-based method for extending abiomedical terminology.
Proc of the ACL-02 work-shop on Natural language processing in the biomedi-cal domain: 53?60.S.
Brin 1998.
Extracting patterns and relations fromthe world wide web.
WebDB Workshop at 6th Interna-tional Conference on Extending Database TechnologyE.
Buyko, S. Piao, Y. Tsuruoka, K. Tomanek , J.D.
Kim,J.
McNaught, U. Hahn, J. Su, and S. Ananiadou.
2007,Bootstrep annotation scheme: Encoding informationfor text mining, Proc of the 4th Corpus LinguisticsConference, Birmingham, July 27-30.J.
G. Caprosaso, W.A.
Baumgartner, D.A.
Randolph,K.B.
Cohen, L. Hunter 2007.
Rapid pattern develop-ment for concept recognition systems: application topoint mutations., Journal of Bioinformatics and Com-putational Biology, Vol.
5, No.
6, 12331259.69A.
Cohen 2005.
Unsupervised gene/protein named en-tity normalization using automatically extracted dic-tionaries.
Proc of the ACL-ISMB Workshop on Link-ing Biological Literature, Ontologies and Databases:17-24.M.
Collins, Y.
Singer 1999.
Unsupervised Models forNamed Entity Classification.
EMNLPJ.R.
Curran, T Murphy, B Scholz 2007.
MinimizingSemantic Drift With Mutual Exclusion Bootstrapping,Proc of the 10th Conference of PACL:172-180.D.
Day, J. Aberdeen, L. Hirschman, R. Kozierok, P.Robinson, M. Vilain 1997, Mixed-initiative develop-ment of language processing systems.
Proc of the 5thACL Conference on Applied Natural Language Pro-cessingH.
Fang, K. Murphy, Y. Jin, J.S.
Kim, P.S.
White 2006.Human Gene Name Normalization using Text Match-ing with Automatically Extracted Synonym Dictionar-ies.
Proc of the BioNLP Workshop on Linking NaturalLanguage Processing and Biology at HLT-NAACL 06:4148.C.
Friedman, P. Kra, H. Yu, M. Krauthammer, A. Rzhet-sky.
2001.
GENIES: a natural-language processingsystem for the extraction of molecular pathways fromjournal articles.
Bioinformatics, ;17 Suppl 1:S74-82.M.A.
Hearst 1992.
Automatic acquisition of hyponymsfrom large text corpora, Proc of the 14th conferenceon computational linguistics.D.
Klein D, CD.
Manning 2003.
Accurate UnlexicalizedParsing, Proc of the 41st Meeting of the Associationfor Computational Linguistics, 2003; 423-30.M.
Krauthammer G. Nenadic 2004.
Term identifica-tion in the biomedical literature., J Biomed Inform,Dec;37(6):512-26.S.
Mukherjea, L.V.
Subramaniam, G. Chanda, S.Sankararaman, R. Kothari, V.S.
Batra, D.N.
Bhardwaj,B.Srivastava 2004.
Enhancing a biomedical infor-mation extraction system with dictionary mining andcontext disambiguation, IBM Journal of Research andDevelopment, 48(5-6): 693-702W.
Pratt, M. Yetisgen-Yildiz 2003 A Study of Biomedi-cal Concept Identification: MetaMap vs. People, ProcAMIA Symp, 529-533.R.
Snow, D. Jurafsky, A. Ng 2005.
Learning syntacticpatterns for automatic hypernym discovery, Proc ofthe 17th Conference on Advances in Neural Informa-tion Processing Systems MIT Press.M.
Thelen, E. Riloff 2002.
A Bootstrapping Method forLearning Semantic Lexicons Using Extraction PatternContexts, Proc of EMNLP.K.
Tomanek, J Wermter, U Hahn.
2007.
An Approachto Text Corpus Construction which Cuts AnnotationCosts and Maintains Reusability of Annotated Data,Proc of the 2007 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning:486-495.Y.
Tsuruoka, J. Tsujii 2003, Boosting Precision andRecall of Dictionary-Based Protein Name Recogni-tion, Proc of the ACL 2003 Workshop on NLP inBiomedicine:41-8.Y.
Tsuruoka, J. Tsujii 2004, Improving the performanceof dictionary-based approaches in protein name recog-nition, J of Biomed Inf 37, 6; December: 461-470.R.
Xu, K. Supekar, A. Morgan, A.Das, A. Garber 2008.Unsupervised Method for Automatic Construction of aDisease Dictionary from a Large Free Text Collection,Proc AMIA Symp.70
