Talking About  TreesPatrick BlackburnDepartment of Philosophy, Rijksuniversiteit UtrechtHeidelberglaan 8, 3584 CS Utrecht.
Email: patrick@phil.ruu.nlClaire GardentGRIL, Universit4 de Clermont Ferrand, France, andDepartment of Computational Linguistics, Universiteit van AmsterdamSpuistraat 134, 1012 VB Amsterdam.
Email: claire@mars.let.uva.nlWilfried Meyer-ViolCentrum voor Wiskunde n InformaticaKruislaan 413, 1098 SJ Amsterdam.
Email: W.Meyer.Viol@cwi.nlAbstractIn this paper we introduce a modal lan-guage L T for imposing constraints on trees,and an extension LT(L r) for imposing con-straints on trees decorated with featurestructures.
The motivation for introducingthese languages is to provide tools for for-malising grammatical frameworks perspic-uously, and the paper illustrates this byshowing how the leading ideas of GPS6 canbe captured in LT(LF).In addition, the role of modal languages(and in particular, what we have calledlayered modal anguages) as constraint for-malisms for linguistic theorising is discussedin some detail.1 IntroductionIn this paper we introduce a modal language L 7for talking about trees, and an extension L'r(L F)for talking about trees decorated with feature struc-tures.
From a logical point of view this is a nat-ural thing to do.
After all, the trees and featurestructures used in linguistics are simple graphicalobjects.
To put it another way, they are merelyrather simple Kripke models, and modal languagesare probably the simplest languages in which non-trivial constraints can be imposed on such structures.Moreover the approach is also linguistically natural:many of the things linguists need to say about trees(and feature structures) give rise to modal operatorsrather naturally, and indeed our choice of modalitieshas been guided by linguistic practice, not logicalconvenience.There are several reasons why we think this pathis an interesting one to explore, however two are ofparticular elevance to the present paper.
1 First,we believe that it can lead to relatively simple andnatural formalisations of various grammatical frame-works.
In our view, neither simplicity nor natural-ness are luxuries: unless a formalisation possesses ahigh degree of clarity, it is unrealistic to hope thatit can offer either precise analyses of particular sys-tems or informative comparisons of different frame-works.
We believe our approach has the requisiteclarity (largely because it arose by abstracting fromlinguistic practice in a rather direct manner) andmuch of this paj?er is an attempt o substantiatethis.
Second, L r can be combined in a very nat-ural way with feature logics to yield simple systemswhich deal with configurational concepts, complexcategories and their interaction.
The key idea is toperform this combination of logics in a highly con-strained way which we have called layering.
Layer-ing is a relatively new idea in modal ogic (in fact theonly paper devoted exclusively to this topic seems tobe \[Finger and Gabbay 1992\]), and it seems to pro-vide the right level of expressive power needed tomodel many contemporary grammar formalisms.The paper is structured as follows.
In section 2 wedefine the syntax and semantics of L T, our modallanguage for imposing constraints on tree structure.~Lurking in the background are two additional, rathermore technical, reasons for our interest.
First, we believethat being ezplicit about tree structure in our logical ob-ject languages (instead of, say, coding tree structure up asjust another complex feature) may make it easier to findcomputationally tractable logics for linguistic processing.Second, we believe that logical methods may interactfruitfully with the mathematical literature on tree ad-missibility (see \[Peters and Ritchie 1969\], \[Rounds 1970\]and \[Joshi and Levy 1977\]).
However we won't explorethese ideas here.21In section 3 we put L T to work, showing how it canbe used to characterise the parse trees of context freephrase structure grammars.
In section 4 we considerhow the structured categories prevalent in modernlinguistic formalisms are dealt with.
Our solutionis to introduce a simple feature logic L F for talk-ing about complex categories, and then to layer L Tacross L F. The resulting system LT(L F) is capableof formulating constraints involving the interactionof con~igurational nd categorial information.
Sec-tion 5 illustrates how one might use this expressivepower by formulating some of the leading ideas of(~PS(~ in LT(LF).
We conclude the paper with somegeneral remarks on the use of modal languages asconstraint formalisms in linguistics.2 The language L TThe primitive alphabet of the language LT(Prop)contains the following items: two constant symbolss and t, some truth functionally adequate collectionof Boolean operators, 2 two unary modalities ~ andT, a binary modality ::~, a modality of arbitrary pos-itive arity ?, the left bracket ( and the right bracket).
In addition we have a set of propositional symbolsProp.
We think of the symbols in Prop as given to usby the linguistic theory under consideration; differ-ent applications may well result in different choicesof Prop.
To give a very simple example, Prop mightbe {S, NP, VP, N, V, DET, CONJ ).The wits of LT(Prop) are defined as follows.
First,all elements of Prop are LT(Prop) wits, and so arethe constant symbols s and t. Second, if ?, ?
and?1, .
- .
,  Cn (n > 1) are LT(Prop) wffs, then so are -,?,(?
A ?
), T?, ~ ?, (?
=~ ?)
and ?
(?1,..., Ca).
Third,nothing else is an LT(Prop) wff.
In what follows, wewill assume that some choice of Prop has been fixedand drop all subsequent mention of it.
That is, we'llusually speak simply of the language LT.The semantics of L T is given in terms of finiteordered trees.
We regard finite trees T as quadruplesof the form (F, >, O, root ), where r is a finite set ofnodes, > is the 'Mother of' relation between nodes('u > v' means 'u is the mother of v'), O (C_ r )  isthe set of terminal nodes and root is the root node ofthe tree.
As for the precedence ordering, we define:Def in i t ion  2.1 (F in i te  o rdered  t rees)A finite ordered tree is a pair O = IT, A) where Tis a tree (I', >, (9, root ) and A is a function assign-ing to each node u in F a finite sequence of nodesof F. For all nodes u ?
I', 2(u) must satisfy twoconstraints.
First, )~(u) must contain no repetitions.Second, ~(u) = (ut , .
.
.
,u~)  iff u > u l , .
.
.
,u  > uk2In what follows we treat -, and ^  as primitive, andthe other Boolean symbols such as V (disjunction), --*(material implication), *-* (material equivalence), T (con-stant true) and / (constant false) as abbreviations de-fined in the familiar manner.and there is no node u I in I" such that u > u I and Cdoes not occur in the sequence ~(u).
o(In short, the repetition-free s quence assigned to anode u by ~ consists of all and only the nodes im-mediately dominated by u; the sequence gives us aprecedence ordering on these nodes.
Note that itfollows from this definition that ~(u) is the null-sequence iff u is a terminal node.)
Next, we definea model M to be a pair (O, V) where O is a finiteordered tree (T,)~) and V is a function from Prop tothe powerset of r .
That is, V assigns to each proposi-tional symbol a set of nodes.
Given any model M andany node u of M, the satisfaction relation M, u ~ ?,(that is, the model M satisfies ?
at node u) is definedas follows:M,u~p iff ueV(p) ,for all p E PropM, u ~ s iff u = rootM,u~t  iff uEOM,u~-~?
iff not M,u~?M,u  ~?A?
iff M,u~?and M, u ~ ?M,u~?
iff BC ?
r (u>Cand M, u' ~ ?)M,u~T?
iff 3u' ?
F (u '  > uand M, u' ~ ?
)M,u  ~?=~?
iff Vu' ?
r (M,  ul ~ ?implies M, u' ~ ?
)M,u  ~ *(?1, .
.
.
,?k)  iff length(A(u)) = kand M,)t(u)(i) ~ ?i,for all 1 < i < k(In the satisfaction clause for e, ~(u)(i) denotes theith element of the sequence assigned to u by ~.)
If~b is satisfied at all nodes of a model M, then we saythat ?
is valid on M and write M ~ ?.
The notion ofvalidity has an important role to play for us.
As weshall see in the next section, we think of a grammarG as being represented by an L T wff CG.
The treesadmitted by the grammar are precisely those modelson which ?u is valid.Note that L T is just a simple formalisation of lin-guistic discourse concerning tree structure.
First,and T enable us to say that a daughter node, or amother node, do (or do not) bear certain pieces oflinguistic information.
For example, ~ ?
insists thatthe information ?
is instantiated on some daughternode.
Second, :?.
enables general constraints abouttree structure to be made: to insist that ?
=~ ?
is tosay that any node in the tree that bears the informa-tion ?
must also bear the information ?.
Finally ?enables admissibility conditions on local trees to bestated.
That is, ?
is a modal operator that embod-ies the idea of local tree admissibility introduced by\[McCawley 1968\].3 It enables us to insist that a node3As well as McCawley's article, see also \[Gazdar 1979\].Our treatment of node admissibility conditions has beenheavily influenced by Gazdat's paper and later work inthe GPSG tradition (for example, \[Gazdar et al 1985\]).22must immediately and exhaustively dominate nodesbearing the listed information, and in the followingsection we'll see how to put it to work.
4Although the design of L T was guided by linguisticconsiderations, with the exception of ?
it turns outto be a rather conventional language.
5 In particular,=~ is what modal ogicians call strict implication, andand 1" together form a particularly simple exampleof what modal logicians like to call a 'tense logic'.In what follows we will occasionally make useof the following (standard) modal abbreviations:O?
=&!
T ==> ?
(that is, ?
is satisfied at all nodes)and ~?
=d~!
"~ T-'?
(that is, ?
is true at the motherof the node we are evaluating at, if in fact this nodehas a mother).3 Ta lk ing  about  t reesIn this section we show by example how to use L T toformulate node admissibility conditions that will pickout precisely the parse trees of context free gram-mars.
Consider the context free phrase structuregrammar G = (S, N, T, P) where S is the start sym-bol of G; where N, the set of non-terminal symbols,is {S, NP, VP, N, V, DET, CONJ }; where T, theset of terminal symbols, is {the, a, man, woman, don-key, beat, stroke, and, but}; and where P, the set ofproductions, is:S , NP VP\[ S CONJSNP  ) DET NVP  ~ V NPN , man JwomauJ donkeyV ~ beat \[ strokeD ET  ) the \[ aCONJ  , and I butLet's consider how to capture the parse trees of thisgrammar by means of constraints formulated in L T.The first step is to fix our choice of Prop.
We chooseit to be N U T, that is, all the terminal and non-terminal symbols of G. The second step is to capturethe effect of the productions P. We do so as follows.Let ?
*" be the conjunction of the following wffs:4The reader will doubtless be able to think of otherinteresting operators to add.
For example, adding opera-tors J.
* and \]'* which explore the transitive closures of thedaughter-of and mother-of relations respectively enablesGB discourse concerning command relations to be mod-eled; while weakening the definition of * to ignore theprecedence ordering on sisters, and adding a new unarymodality to take over the task of regulating linear prece-dence, permits the ID/LP format used in GPSG to be nat-urally incorporated.
Such extensions will be discussed in\[Blackburn et al forthcoming\], however for the purposesof the present paper we will be content o work with thesimpler set of operators we have defined here.5Indeed, on closer inspection, even ?
can be regardedas an old friend in disguise; such logical issues will bediscussed in \[Blackburn et al forthcoming\].S =V .
(NP, VP) V .
(S, CON J, 5)NP => ,(DET, N)VP =~ .
(11, NP).
(man) v .
(woman) v .
(donkey)V .
(beaO v.(stroke)DET ::~ .
(the) V *(a)co w -(and)v.(buONote that each conjunct licences a certain informa-tion distribution on local trees.
Now, any parse treefor G can be regarded as an L T model, and becauseeach conjunct in eP mimics in very obvious fashiona production in G, each node of an L G parse tree islicenced by one of the conjuncts.
To put it anotherway, eP is valid on all the G parse trees.However we want to capture all and only the parsetrees for G.This is easily done: we need merely expressin our language certain general facts about parsetrees.
First, we insist that each node is labeledby at least one propositional symbol: \[3(Vp~teuT p)achieves this.
Second, we insist that each node islabeled by at most one propositional symbol: (p =~Aq~((NuT)\{p}) "~q) achieves this.
Third, we insistthat the root of the tree be decorated by the startsymbol S of the grammar: s =:, S achieves this.Fourth, we insist that non-terminal symbols labelonly nonterminal nodes: ApeN(P =~ -,t) achievesthis.
Finally, we insist that terminal symbols labelterminal nodes: Apew(p => t) achieves this.
Call theconjunction of these five wits ev; note that, mod-ulo our choice of the particular sets N and T, evexpresses universal facts about parse trees.Now, for the final step: let eG be eP A dr .
Thatis, eG expresses both the productions P of G andthe universal facts about parse tree structure.
It iseasy to see that for any model M, M ~ eG iff M is(isomorphic to) a parse tree for G. Indeed, it is nothard to see that the method we used to express Gas a formula generalises to any context free phrasestructure grammar.4 T rees  decorated  w i th  features t ructuresThe previous section showed that L T is powerfulenough to get to grip with interesting 'languages' inthe sense of formal language theory; but althoughnatural language syntacticians may use tools bor-rowed from formal language theory, they usuallyhave a rather different conception of language thando computer scientists.
One important difference isthat linguists typically do not consider either non-terminal or terminal symbols to be indivisible atoms,rather they consider them to be conglomerationsof 'lower level' information called feature structures.For example, to say that a node bears the informa-tion NP is to say that the node actually bears a lot23of lower level information: for example, the features+N,  -V ,  and BAR 2.
Moreover (as we shall seein section 5) the constraints that a tree must sat-isfy in order to be accepted as well formed will typi-cally involve this lower level information.
The featureco-occurrence r strictions and feature instantiationprinciples of ?PSa are good examples of this.Is it possible to extend our framework to deal withsuch ideas?
More to the point, is there a simple ex-tension of our framework that can deal with com-plex categories?
Layered modal languages providewhat is needed.
Semantically, instead of associatingeach tree node with an atomic value, we are going toassociate it with a feature structure.
Syntactically,we are going to replace the propositional symbols ofL T with wits capable of talking about this additionalstructure.
To be more precise, instead of defining thewits of L T over a base Prop consisting of primitivepropositional symbols, we are going to define themover a base of modal formulas.
That is, we will usea language with two 'layers'.
The top layer L T willtalk about tree structure just as before, whereas thebase layer (or feature layer) L v will talk about the'internal structure' associated with each node.
6Clearly the first thing we have to do is to define ourfeature language LF and its semantics.
We will as-sume that the linguistic theory we are working withtells us what features and atoms may be used.
Thatis, we assume we have been given a signature (~',,4)where both jr  and ,4 are non-empty finite or denu-merably infinite sets, the set of features and the set ofatomic information respectively.
Typical elements of~r might be CASE, NUM, PERSON and AGR; while typ-ical elements of ,4 might be genitive, singular, plural,1st, 2nd, and 3rd.The language L F (of signature (~',,4)) containsthe following items: all the elements of ,4 (which wewill regard as propositional symbols), a truth func-tionally adequate collection of Boolean connectives,and all the elements of jr  (which we will regard asone place modal operators).
The set of wits of L Fis the smallest set containing all the propositionalsymbols (that is, all the elements of ,4) closed underthe application of the Boolean and modal operators(that is, the elements of jr).
Thus a typical wff ofL F might be the following:(AGR)(PERSON)3rd A (CASE)genitive.Note that this wff is actually something very familiar,namely the following Attribute Value Matrix:\[ AGR \[PERSON 3rd\] \]CASE genitive6As was mentioned earlier, at present there is rela-tively little published literature on layered modal lan-guages.
The most detailed investigation is that of\[Finger and Gabbay 1992\], while \[de Rijke 1992\] gives abrief account in the course of a general discussion on thenature of modal ogic.Indeed the wits of L F are nothing but straightfor-ward 'linearisations' of the traditional two dimen-sional AVM format.
Thus it is unsurprising that thesemantics of L F is given in terms of feature struc-tures:Def in i t ion  4.1 (Feature  s t ruc tures )A feature structure of signature (~,,4) is a tripleF of the form (W, {RI}/el:, V), where W is a non-empty set, called the set of points; for all f 6 ~', R!is a binary relation on W that is a partial function;and V is a function that assigns to each propositionalsymbol (that is, each ~ 6 ,4), a subset of W. 7 \[\]Our satisfaction definition for L F wffs is as follows.For any F = (W, {Rl}yey, V) and any point w 6 W:F, w ~ a iff w 6 V(~), for all a fi ,4F, w ~ -~?
iff not F, w ~ ?F ,w~?A?
iff F ,w~?
and F ,w~?F, w ~ (f)?
iff 3w'(wRlw' and F, w' ~ ?
)With L F and its semantics defined, we are readyto define a language for talking about trees decoratedwith feature structures: the language LT(LF), thatis, the language L T layered over the language L F.That is, we choose Prop to be L F and then make theL T wffs on top of this base in the usual way.
s As aresult, we've given an 'internal structure' (namely, amodal structure, or AVM structure) to the proposi-tional symbols of L T. This is the syntactical heartof layering.Def in i t ion  4.2 (Feature  decorated  t rees )By a (finite ordered) feature structure decorated tree(of signature (Yr, A)) is meant a triple (O, D, d)where O is a finite ordered tree, D is a functionthat assigns to each node u of O a feature struc-ture (of signature (, A)), and d is a function thatassigns to each node u of O a point of D(u).
Thatis, d(u) 6 D(u).
9 \[\]It is straightforward to interpret LT(L F) wits onfeature structure decorated trees: indeed all we have7For detailed discussion of this definition see \[Black-burn 1991, 1992\] or \[Blackburn and Spaan 1991, 1992\].For present purposes it suffices to note that it includes asspecial cases most of the well known definitions of featurestructures, uch as that of \[Kasper and Rounds 1986\].SThis is worth spelling out in detail.
The wffs of thelanguage LT(L F) (of signature (~, ~4)) axe defined as fol-lows.
First, all L F wits (of signature (.%',.4)) axe LT(L F)wtfs, and so axe the constant symbols s and t. Second,if ~b, ~b and ~b, .
.
.
.
.
~b, axe LT(L F) wtfs then so are --~b,~b A~b, T~b, ~?, ~b=~ b and .(~b,,...,~b,).
Third, nothingelse is an LT(L F) wtf.9In a number of recent tallcs Dov Gsbbay has ad-vocated the idea of 'fibering' one set of semantic en-tities over another.
This is precisely what's going onhere: we're fibering trees over feature structures.
Fiberedstructures axe the natural semantic dommns for layeredlanguages.24to do is alter the base clause of the L T definition.
So,let M = (O, D, d) be a feature structure decoratedtree, and u be any node in O.
Then for all wffs?
ELF:M, u ~ ?
iff D(u), d(u) ~ ?.In short, when in the course of evaluating an LT(L ~)wff at a node u we encounter an L F wff (that is,when we reach 'atomic' level) we go to the featurestructure associated with u (that is, D(u)), and startevaluating the L F wff at the point d(u).
This changeat the atomic level is the only change we need tomake: all the other clauses (that is, the clauses for sand t, the Boolean operators, for =~, 1, T, and e) areunchanged from the L T satisfaction definition givenin section 2.To close this section, a general comment.
LT(L F)is merely one, rather minimalist, example of a lay-ered modal language.
The layering concept offersconsiderable flexibility.
By enriching either the L Tcomponent, he L F component, or both, one can tai-lor constraint languages for specific applications.
In-deed, it's worth pointing out that one is not forcedto layer L T over a modal language at all.
One couldperfectly well layer L T across a first order featurelogic or over a fragment of such a first order logic(such as the SchSnfinkel Bernays fragment exploredin \[Johnson 1991\]), 1?
and doubtless the reader canimagine other possibilities.
That said, we're struckby the simplicity of purely modal layered languagessuch as LT(LF), and we believe that there are goodtheoretical reasons for being interested in modal ap-proaches (these are discussed at the end of the pa-per).
Moreover, as we shall now see, even the rathersimple collection of operators offered by LT(L F) arecapable of imposing interesting constraints on syn-tactic structures.5 LT(L F) and linguistic theoryAt this stage, it should be intuitively clear why T F L (L )  is well suited for modeling contemporary lin-guistic theories.
On  the one hand, the L T part ofthe language lets us talk directly about tree struc-ture, thus clearly it is a suitable tool for imposingconstraints on constituent structure.
On  the otherhand, the L F part of the language permits the de-scription of complex (rather than atomic) categories;and nowadays the use of such categories i standard.The aim of this section is to give a concrete illustra-tion of how LT(L F) can be used to model modernlinguistic theories.
The theory we have chosen forthis purpose is GPSG.
In what follows we sketch howsome of the leading ideas of GPSG can be capturedusing LT(L F) wits.1?Layering over first order languages is treated in\[Finger and Gabbay 1992\].5.1 Complex  categor iesOne of the fundamental ideas underlying GPSG (andindeed many other contemporary s ntactic theories)is that a linguistic category is a complex object con-sisting of feature specifications, where feature speci-fications are feature/value pairs, and a value is eitheran atom or is itself a category.
In LT(L F) , this ideais easily modeled since L'I"(L F) contains L F, a lan-guage specifically designed for talking about featurestructures.
To give a simple example, consider thefollowing complex category:NOUN - \]VERB -l-BAR twoThis is naturally represented by the followingL F wff:".noun A verb A (BAR)twowhere the attribute BAR is represented by a modalityand the atomic symbols and Boolean features arerepresented by propositional symbols.
This wff issatisfied at any point w in a feature structure suchthat noun is false at w, verb is true at w, and thepropositional information two is reachable by makinga BAR transition from w.5.2 Admiss ib i l i ty  const ra in ts  on local t reesThe heart of GPS?
is a collection of interactingprinciples governing the proper distribution of fea-tures within syntactic trees.
Central to this the-ory is the concept of admissibility constraints onlocal trees.
Very roughly, 11 the idea is that a lo-cal tree is admissible if it is a projection of an im-mediate dominance rule (that is, each node in thetree corresponds in some precisely defined way toexactly one category in the rule) and it satisfies allof the grammar principles; these include feature co-occurrence restrictions (FCRs), feature specificationdefaults (FSDs), linear precedence (LP) statements,and universal feature instantiation principles (UIPs).In what follows, we show how LT(L F) can be usedto model some of these admissibility conditions onlocal trees: section 5.2.1 shows how to model phrasestructure restrictions and section 5.2.2 concentrateson FCRs.
Finally, in section 5.2.3 we sketch anLT(L F) treatment of the GPSG UIPs.5.2.1 Phrase  s t ructure  res t r i c t ionsIn  GPSG, restrictions on constituent structure areexpressed by a set of ID/LP statements.
As the nameindicates, I(mmediate) D(ominance) statements en-code immediate dominance restrictions on local trees(for instance, the ID rule A --* B, C licenses any localtree consisting of a mother node labeled with cate-gory A and exactly two daughter nodes labeled with11For a more precise formulation of the constraints ontree admissibility, see \[Gazdar et al 1985, page 100\].25categories B and C respectively), whereas LP state-ments define a linear precedence r lation between sis-ter nodes (for example, the LP statement C -4 Bstates that in any local tree with sisters labeled Band C, the C node must precede the B node).Strictl Z speaking, such restrictions cannot be mod-eled in LT(L F) .
The reason for this is trivial.
As hasalready been pointed out, the satisfaction definitionfor * makes use of both the immediate dominanceand linear precedence r lations.
In a full-blooded at-tempt to model GPSG, we would probably define avariant modal operator o of ?
that did not make useof the precedence relation, and introduce an addi-tional modal operator (say ~,) to control precedence.However, having made this point, we shall not pur-sue the issue further.
Instead, we will show how thepresent version of LT(L F) allows for the encoding ofphrase structure rules involving complex categories.As was shown in section 3, rules involving atomiccategories can be modeled in a fairly transparent wayusing =~, ?
and V. For instance,S ::~ .
(NP, VP) V .
(S, CON J, 5")captures the import of the following two phrasestructure rules:S , NP VPS , S CONJ SIn these rules the information associated with eachnode of the tree is propositional in nature, thatis, non-structured.
However because LT(L F) allowsone to peer into the internal structure of nodes,this way of modeling phrase structure rules extendsstraightforwardly to rules involving complex cute-gories: it sufficesbols by L F wffs.rule: \[NOUNVERBBAR.SUBCATcan be formulatedto replace the propositional sym-For example, the phrase structureNOUN -- \]VERB +BAR twoNOUN ++ VERB -- zerot rans  BAR tWOas the following LT(L ~') wff:(-moun A verb A (BAR)two)*((-,noun A verb A (BAR)zero A (SUBCAT)trans),(noun ^  ^ (BAR)twO))That is, the L F wffs give the required 'internalstructure' in the obvious way.5.2.2 Feature  co -occur rence  res t r i c t ionsFCRs encode restrictions on the distribution offeatures within categories.
More specifically, theyexpress conditional or bi-conditional dependenciesbetween feature specifications occurring within thesame category.
For instance, the FCR:\[INV +\] ~ \[AUX +, VFORM fin\] (FCR1)states that any category with feature specificationINV -t- must also contain the feature specificationsAUX + and VFORM fin.
In other words, any invertedconstituent must be a finite auxiliary.FCRs are naturally expressed in LT(L F) by usingthe ::~ connective.
Thus, FCR1 can be captured bymeans of the following schema:inv ::~ (a~x A (VFORM) fin)This says that for any ordered tree and any nodeu in this tree, if the feature structure associated withu starts with the point w and inv is true at w, thenauz is also true at w and furthermore, the proposi-tional information fin is reachable from w by makinga (VFORM) transition to some other node w'.5.2.3 Un iversa l  pr inc ip lesIn this section, we show that LT(L F) allows usto axiomatize the main content of GFSG three fea-ture instantiation principles namely, the foot featureprinciple, the head feature convention and the con-trol agreement principle.Consider first the foot feature principle (FFP).This says that:Any foot feature specification which is in-stantiated on a daughter in a local tree mustalso be instantiated on the mother cate-gory in that tree.
\[Gazdar et aL 1985, page81\] 12So, assume that our GPSG theorising has resultedin signature (jc, .A) which includes the feature FOOT.We capture the FFP by means of the followingschema:(FOOT)~b =~I~(FOOT)~b.This says that for any node u, if the information ~bis reachable by making a FOOT transition in the fea-ture structure associated with u, then it must alsobe possible to obtain the information ~b by makinga FOOT transition in the feature structure associ-ated with the mother of u.
That is, FOOT infor-mation percolates up the tree.
So for instance, ifthree sister nodes ul, u2 and u3 of a tree bear theinformation (FOOTI?I , (FOOT)?2 and (FOOTIC3respectively, then the feature structure associatedwith the mother node must bear the information(FOOT)C1 A (FOOT)C2 A (FOOT)C3.
Incidentally, itthen follows from the semantics of L F that this nodebears the information (FOOW)(~b 1 ^  ?2 ^  ~b3)- Thatis, the three pieces of foot information are unified.a2This axiom is actually a simplified version of the FFPin that it ignores the distinction between inherited andinstantiated features.
See section 5.3 for discussion ofthis point.26Consider now the head feature convention (HFC).A simplified version of the HFC can be stated asfollows; isAny head features carried by the headdaughter is carried by the mother and vice-versa.Assuming a signature (~',,4) which includes thefeature HEAD-FEATURE and the atomic informationhead, we capture the HFC by means of the followingschema:(head A (HEAD-FEATURE)~) ::~(HEAD-FEATURE)~A(head A T(HEAD-FEATURE)~) :=~ (HEAD-FEATURE)~The first conjunct says that whenever the featurestructure associated with a node u marks it as a headnode, and the information ff is reachable by makinga HEAD-FEATURE transition, then one can also reachthe same information ~by making a HEAD-FEATUREtransition in the feature structure associated withthe mother of u.
The second conjunct works analo-gously to bring HEAD-FEATURE information down tothe head daughter.Finally, we sketch how the effect of the more elab-orate control agreement principle (CAP) can be cap-tured.
~PSG formulates CAP by making use ofthe Montagovian semantic type assignments.
As wehaven't discussed semantics, we're going to assumethat the relevant type information is available insideour feature structures.
With this assumed, our for-mulation of CAP  falls into three steps: first, definingthe notions of controller and controllee (or target inGPSQ terminology); second, defining the notion of acontrol feature; and third, defining the instantiationprinciple.
We consider each in turn.
Controller andcontrollee are defined as follows: 14A category C is controlled by another cate-gory C ~ in a constituent Co if one of thefollowing situations obtains at a seman-tic level: either C is a functor that ap-plies to C ~ to yield a Co, or else thereis a control mediator C"  which combineswith C and C ~ in that order to yield a Co.\[Gazdar et al 1985, page 87\]Further, a control mediator is a head categorywhose semantic type is (VP, (NP, VP)) where VPdenotes the type of an intransitive verb phase andNP that of a generalised quantifier.
The first step isto formulate the notions of controller and controllee.ISThe exact formulation of the i/FC implies that onlyflee feature specifications are taken into account.
Seesection 5.3 for discussion of this point.14Again this is somewhat simplified in that the finalGPSG definition of control only takes into account so-called x-features so as to ignore perturbations of se-mantic types introduced by the presence of instantiatedfeatures.We do this with the following three wits (a and b aremetavariables over semantic types, and np and vpcorrespond to the NP and VP  above):?
( (TYPE)a/b, (TYPE)a)=?, e(controllee, controller)?
( (TYPE)a, (TYPE)a/b)=~ ?
(controller, eontrollee)?
( T, (TYPE)vp/(np/vp),T)::~ ?
(controller, T, controllee)Control features are SLASH and AOR and are notmutually exclusive.
The problem is to decide whichshould actually function as control feature when bothof them are present on the controllee category.
In ef-fect, in case of conflict (cf.
\[Gazdar et al 1985, 89\]),SLASH is the control feature if it is inherited, elseACR is.
As we have no way to distinguish ere be-tween inherited and instantiated feature values, wewill (again) give a simplified axiomatisation of con-trol features, namely:(SLASH)~b ::?"
(CONTROL_FEAT)~b(~ (SLASH)'\]- A (AGR)~) ::~ (CONTROL_FEAT)~Finally, we turn to the CAP itself.
This saysthat the value of the control feature of the controlleeis identical with the category of the controller.
InLT(L F) :(~ (eontroller)A ~ (controllee)) ::~I ((controller A ~)(controllee A (CONTROL_FEAT)C))5.3 Discuss ionIn the preceding sections, we showed how LT(L F)could be used to capture some of the leading conceptsof GPSG.
Although the account involves many sim-plifications and shortcomings, the examples houldillustrate how to use LT(Le'): one expresses linguis-T F - tic principles as L (L )  wffs, and only those (deco-rated) trees validatings all these wffs are consideredwell-formed.
What we hope to have shown is thatLT(L F) is a very natural anguage for expressing thevarious types of theoretical constructs developed inGPSG and, more generally, in most modern theories ofgrammar.
Complex categories can be described us-ing the L F part of the language while general infor-mation concerning the geometry of trees and the dis-tribution of feature specifications within those treescan be stated using the full language.
More specifi-cally, the bullet operator ?
provides an easy way to27express phrase structure constraints while the strictimplication operator :=~ allows one to express varioustypes of constraints on the distribution of features intrees.
When used to connect wo L F wffs, ==~ ex-presses generalisations over the internal structure ofcategories (as illustrated in section 5.2.2 on FCRs),whereas when used together with T, ~ and ?
it allowsinformation sharing between feature structures asso-ciated with different nodes in the tree (cf.
section5.2.3).As already repeatedly mentioned, there remainmany shortcomings in our approach to modelingGPSG.
To close this discussion let's consider them alittle more closely; this will lead to some interestingquestions about the nature of linguistic theorising.The first type of shortcoming involves lack of ex-pressivity in L T (L F) and is illustrated by the impos-sibility of expressing ID/LP statements (cf.
section5.2.1).
As already indicated, we don't regard suchshortcomings as a failure of the general modal ap-proach being developed here.
With a slightly differ-ent choice of modal language, an adequate modelingof ID/LP statements could be attained.
More gener-ally, we think it is important to explore a wide rangeof modal languages for linguistic theorising, for webelieve that it may be possible to usefully classifydiffering linguistic theories in terms of the differentmodal operators required to formalise them.
A theo-retical justification for our confidence will be given inthe following section; here we'll simply say that wethink this is a feasible way of addressing the ques-tions raised in \[Shieber 1988\] concerning the com-parative xpressivity and computational complexityof grammatical formalisms.The second type of shortcoming is more seriousand potentially far more interesting.
Two casesin point are (i) the distinction made in 6PS6 be-tween instantia~ed and inherited features and (ii) theGPSG notion of a free feature.
Briefly, inherited fea-tures are features whose presence on categories intrees is directly determined by an ID rule whereasinstantiated features are non-inherited features (eft\[Gazdar et al 1985, page 76\]).
Furthermore, givena category C occurring in a tree r such that r is aprojection of some ID rule that satisfies the FFP andthe CAP, a feature specification is said to be free inC iff is is compatible with the information containedin C (cf.
\[Gazdar et al 1985, page 95\] for a moreprecise definition of free features).
The problem inboth cases is that derivational information eeds tobe taken into account.
In the first case, the sourceof the feature specification must be known (does itstem from an ID rule or from some other source?).
Inthe second case, we must know that both CAP andFFP are already being satisfied by the category un-der consideration.
There is an essentially dynamicflavour to these ideas, something that goes againstthe grain of the essentially static tree descriptionsoffered by LT(LF).
Whether this dynamic aspect isin fact required, and how it could best be modeled,we leave here as open research questions.6 But  why  moda l  languages?To close this paper we wish to discuss an issue thatmay be bothering some readers: why were modallanguages chosen as the medium for expressing con-straints on trees and feature structures?
A readerunfamiliar with the developments hat have takenplace in modal logic since the early 19T0's, and inparticular, unfamiliar with the emergence of modalcorrespondence theory, may find the decision to workwith modal languages rather odd; surely it wouldbe more straightforward to work in (say) some ap-propriate first order language?
However we believethat there are general reasons for regarding modallanguages as a particularly natural medium for lin-guistic theorising, and what follows is an attempt tomake these clear.The first point that needs to be made about modallanguages is that they are nothing but extremelysimple languages for talking about graphs.
Unfortu-nately, the more philosophical presentations of modallogic tend to obscure this rather obvious point.
Insuch presentations the emphasis i on discussing suchideas as 'possible worlds' and 'intensions'.
Such dis-cussions have their charms, but they make it veryeasy to overlook the fact that the mathematicalstructures on which these ideas rest are extremelysimple: just sets of nodes decorated with atomic in-formation on which a transition relation is defined.Kripke models are nothing but graphs.The second point is even more important.
Modallanguages are not some strange alternative to classi-cal languages; rather, they are relatively constrainedfragments of such languages.
If a problem has beenmodelled in a modal anguage then it has, ipso facto,been modeled in a classical language; and moreover,it has been modeled in a very resource conscious way.The point deserves a little elaboration.
Ever sincethe early 1970's, one of the most important branchesof research in technical modal logic has been modalcorrespondence theory (see \[van Benthem 1984\] andreferences therein), the systematic study of the in-terrelationships between modal anguages on the onehand, and various classical logics (first order, infini-tary, and second order) on the other.
Modal corre-spondence theory rests on the following simple ob-servation.
It is usually possible to view modal oper-ators as logical 'macros'; essentially modal operatorsare a prepackaging of certain forms of quantificationthat are available in classical anguages.
To give asimple example, we might view a statement of theform T ~b as a shorthand for the first order expres-sion 3y(y > z A ~0(y)), where ~o(y) is a certain firstorder wff called the standard translation of ~b.
15 Forl~This is somewhat impressionistic; for the full storyconsult \[van Benthem 1984\].
For a discussion of the fun-28present purposes the details aren't particularly im-portant; the key point to note is that the T operator isessentially a neat notation which embodies a limitedform of first order quantificational power: namelythe ability to quantify over mother nodes.
More gen-erally, modal languages eschew the quantificationalpower that classical anguages achieve through theuse of variables and binding, in favour of a variablefree syntax in which quantification is performed us-ing operators.
Expressive power is traded for syntac-tic simplicity.The relevance of these points for linguistics houldbe clear.
Linguistic theorizing makes heavy use ofgraph structures; trees and feature structures are ob-vious examples.
Thus modal anguages can be usedas constraint formalisms; what correspondence the-ory tells us is that they are particularly interestingones, namely formalisms that mesh neatly with thelinguists' quest for revealing descriptions using theweakest tools possible.Acknowledgements: We would like to thank Jo-han van Benthem, Gerald Gazdar, Maarten de Ri-jke, Albert Visser and the anonymous referees fortheir comments on the earlier draft of this paper.Patrick Blackburn would like to acknowledge the fi-nancial support of the Netherlands Organization forthe Advancement of Research (project NF 102\[62-356 'Structural and Semantic Parallels in NaturalLanguages and Programming Languages').Re ferences\[Blackburn 1991\] Blackburn, P.: 1991, Modal Logicand Attribute Value Structures.
To appear inDiamonds and Defaults, edited by M. de Ri-jke, Studies in Logic, Language and Informa-tion, Kluwer.\[Blackburn and Spaan 1991\] Blackburn, P. andSpaan, E.: 1991, On the Complexity of At-tribute Value Logics.
Proceedings of the EighthAmsterdam Colloquium, edited by P. Dekkerand M. Stokhof, Philosophy Department, Ams-terdam University, The Netherlands.\[Blackburn and Spaan 1992\] Blackburn, P. andSpaan, E.: 1992, A Modal Perspective on theComputational Complexity of Attribute ValueGrammar.
To appear in Journal of Logic, Lan-guage and Information.\[Blackburn 1992\] Blackburn, P.: 1992, Structures,Languages and Translations: the Structural Ap-proach to Feature Logic.
To appear in Con-straints, Language and Computation, edited byC.
Rupp, M. Rosner and It.
Johnson, AcademicPress.\[Blackburn et al forthcoming\] Blackburn, P., Gar-dent, C., and Meyer-Viol, W.: Modal PhraseStructure Grammars.
In preparation.damental correspondences involved in feature logic see\[Blackburn 1992\].\[de RJjke 1992\] de Rijke, M.: 1992, What is ModalLogic?
In Logic at Work, proceedings of theApplied Logic Conference, CCSOM, Universityof Amsterdam, 1992.\[Finger and Gabbay 1992\] Finger, M. and Gabbay,D.
: 1992, Adding a Temporal Dimension to aLogic System.
Journal of Logic, Language andInformation, 1, pp.
203-233.\[Gazdar 1979\] Gazdar, G.: 1979, Constituent Struc-tures.
Manuscript, Sussex University.\[Gazdar et al 1985\] Gazdar, G.: Klein, E., Pullum,G., and Sag, S.: 1985, Generalised Phrase Struc-ture Grammar.
Basil Blackwell.\[Johnson 1991\] Johnson, M.: 1991, Features andFormulas, Computational Linguistics, 17, pp.131-151.\[Joshi and Levy 1977\] Joshi, A. and Levy, S.: 1977,Constraints on Structural Descriptions: LocalTransformations.
SIAM Journal of Computing,6, pp.
272-284.\[Kasper and Rounds 1986\] Kasper, R. and Rounds,W.
: 1986, A logical semantics for feature struc-tures.
Proceedings of the 24th Annual Meeting ofthe Association for Computational Linguistics,Columbia University, New York, pp.
257-266.\[McCawley 1908\] MeCawley, J.: 1968, Concerningthe Base Component of a TransformationalGrammar.
Foundations of Language, 4, pp.
55-81.\[Peters and Ritchie 1969\] Peters, S. and Ritehie, R.:1969, Context-Sensitive Immediate ConstituentAnalysis - Context-Free Languages Revisited.Proceedings ACM Symposium on Theory ofComputing, Association for Computing Machin-ery, pp.
1- 10.\[Rounds 1970\] Rounds, W.: 1970, Tree-OrientedProofs of Some Theorems in Context-Free andIndexed Languages.
Proceedings ACM Sympo-sium on Theory of Computing, Association forComputing Machinery, pp.
210 - 216.\[Shieber 1988\] Shieber, S.: 1988, Separating Lin-guistic Analyses from Linguistic Theories.
InNatural Language Parsing and Linguistic Theo-ries, edited by U. Reyle and C. Rohrer, Reidel.\[van Benthem 1984\] van Benthem, J.: 1984, Corre-spondence Theory, in Handbook of PhilosophicalLogic, 2, edited by D. Gabbay and F. Guenth-ner, Reidel.29
