Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2048?2053,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsBeyond Canonical Texts: A Computational Analysis of FanfictionSmitha MilliComputer Science DivisionUniversity of California, Berkeleysmilli@berkeley.eduDavid BammanSchool of InformationUniversity of California, Berkeleydbamman@berkeley.eduAbstractWhile much computational work on fictionhas focused on works in the literary canon,user-created fanfiction presents a unique op-portunity to study an ecosystem of liter-ary production and consumption, embodyingqualities both of large-scale literary data (55billion tokens) and also a social network (withover 2 million users).
We present several em-pirical analyses of this data in order to illus-trate the range of affordances it presents to re-search in NLP, computational social scienceand the digital humanities.
We find that fan-fiction deprioritizes main protagonists in com-parison to canonical texts, has a statisticallysignificant difference in attention allocated tofemale characters, and offers a framework fordeveloping models of reader reactions to sto-ries.1 IntroductionThe development of large-scale book collections?such as Project Gutenberg, Google Books, and theHathiTrust?has given rise to serious effort in theanalysis and computational modeling of fiction (Mo-hammad, 2011; Elsner, 2012; Bamman et al, 2014;Jockers, 2015; Chaturvedi et al, 2015; Vala et al,2015; Iyyer et al, 2016).
Of necessity, this workoften reasons over historical texts that have been inprint for decades, and where the only relationshipbetween the author and the readers is mediated bythe text itself.
In this work, we present a computa-tional analysis of a genre that defines an alternativerelationship, blending aspects of literary production,consumption, and communication in a single, vi-brant ecosystem: fanfiction.Fanfiction is fan-created fiction based on a previ-ously existing, original work of literature.
For claritywe will use the term CANON to refer to the originalwork on which a fanfiction story is based (e.g.
HarryPotter) and the term STORY to refer to a single fan-authored story for some canon.Although stories are based on an original canoni-cal work and feature characters from the canon, fansfrequently alter and reinterpret the canon?changingits setting, playing out an alternative ending, addingan original character, exploring a minor charactermore deeply, or modifying the relationships betweencharacters (Barnes, 2015; Van Steenhuyse, 2011;Thomas, 2011).In this work, we present an empirical analysis ofthis genre, and highlight several unique affordancesthis data presents for contemporary research in NLP,computational social science, and the digital human-ities.
Our work is the first to apply computationalmethods to fanfiction; in presenting this analysis, wehope to excite other work in this area.2 Fanfiction dataOur data, collected between March?April 2016,originates from fanfiction.net.1 In this data,AUTHORS publish stories serially (one chapter at atime); REVIEWERS comment on those chapters.A summary of data is presented in table 1.
Thescale of this data is large for text; at 55 billion to-1While terms of service prohibit our release of this data,tools to collect and process it can be found here: http://github.com/smilli/fanfiction.2048Figure 1: Difference in percent character mentions between fanfiction and canon for Pride and Prejudice(left) and Sherlock Holmes (right).kens, it is over 50 times larger than the BookCorpus(Zhu et al, 2015) and over 10% the size of GoogleBooks (at 468B tokens).The dataset is predominantly written in English(88%), but also includes 317,011 stories in Span-ish, 148,475 in French, 102,439 in Indonesian, and73,575 in Portuguese.
In total, 44 different lan-guages are represented.Type Num of TypeCanons 9,246Stories 5,983,038Tokens 55,264,185,653Reviews 159,914,877Users 2,093,601?Authors 1,364,729?Reviewers 1,438,721Languages 44Table 1: Summary of the fanfiction.net corpus3 Analysis of fanfiction3.1 Differences between canons and fanfictionThe systematic ways in which fanfiction stories dif-fer from their canonical works can give insight intothe characteristics of a story that are desired by fansbut may be missing from the mainstream canon.We investigate two questions: 1.)
Is there a differ-ence between the characters emphasized in fanfic-tion compared to the original canon?
And 2.)
Isgender presented differently in these two sources?Character differences.
In order to explore thediffering attention to character, we consider fanfic-tion from ten canons whose original texts appear inProject Gutenberg; we selected the ten canons fromunique authors with the most fanfiction stories as-sociated with them.2 To extract and compare char-acters, we run BookNLP (Bamman et al, 2014) onboth the canonical work and the top 100 stories (bynumber of reviews) from each canon, and pair char-acters across canon/fanfiction with the same name.To measure how the importance of individualcharacters varies between canon and fanfiction, wecalculate the change in the percent of all charactermentions a character has in the canon to the aver-age percent of character mentions that same charac-ter has in fanfiction.Across all canons we find that the most prominentcharacter in the canon had at most a small increasein percent character mentions, while less prominentcharacters received large increases.
The results fortwo illustrative examples, Pride and Prejudice andSherlock Holmes, are shown in Figure 1.
The per-cent of character mentions for the main protagonists(Elizabeth and Holmes) decreases in fanfiction, butthe secondary characters of Mr. Darcy and Watson2Les Miserables (3996 fanfiction stories), Sherlock Holmes(3283), Pride and Prejudice (3084), Peter Pan (2431), Alicein Wonderland (1446), Anne of Green Gables (620), Jane Eyre(331), Little Women (286), The Scarlet Pimpernel (255), and theSecret Garden (222).2049Labels TermsAuthor encouragementread story one reading chapters time best ever review longupdate please love soon story amazing really hope continue writingchapter great good keep really work story job forward awesomeca wait next chapter see na happens gon great readlike well really story love chapter way one see interestingRequests for story would like know get think going could something really evenEmotional reactionswow better beautiful getting fight adorable keeps team birthday tearsoh god yes man yay damn hell dear yeah gotpoor lol cute howl evil bad hate baby feel lordxd loved funny love haha sweet lol ah cute awwTable 2: Top 10 terms in the 10 manually grouped LDA topics.show a large increase.
These findings confirm theresults of Xu et al (2011), who find a greater in-crease in mentions of Mr. Darcy relative to Elizabethin a different corpus of Pride and Prejudice fanfic-tion, and supports claims that fanfiction authors maydelve deeper into characters that receive less atten-tion in the canon (Jwa, 2012; Thomas, 2011).Gender differences.
Fanfiction has a predom-inantly female authorship and readership base(Barnes, 2015); these stories often oppose tradi-tional gender norms present in the canon and show-case stronger female characters (Handley, 2012;Scodari and Felder, 2000; Leow, 2011; Busse,2009).In order to test whether fanfiction allocates moreattention to female characters than canonical stories,we compare the percent of mentions of male and fe-male characters using the same collection of storiesfrom Gutenberg canons as above.
40.1% of charac-ter mentions in the canons are to women; in fanfic-tion, this ratio increases to 42.4%.
This effect size issmall (2.3% absolute difference), but in a bootstraphypothesis test of the difference (using 106 boot-strapped samples), the difference is highly signifi-cant (p < 0.001), suggesting that fanfiction does in-deed devote more attention to female characters.3.2 Interaction between usersA unique characteristic of this data is the chapter-by-chapter reader reviews; any user can leave a reviewfor a chapter of a story.
Authors are also frequentlyreviewers of other stories (Thomas, 2011), formingan ecosystem with qualities of a social network.709,849 authors in this data (52%) are also re-viewers; if we define a network node to be a userand edge to be a reviewing relationship (a directededge exists from A !
B if A reviews one of B?sworks), this network contains 9.3M such directededges, with an average outdegree of 13.2 and inde-gree of 15.6 (each author on average reviews for 13other authors, and is reviewed by 16).To explore the content of these reviews computa-tionally, we sampled one story with more than 500reviews from 500 different canons and ran LatentDirichlet Allocation (Blei et al, 2003) with 10 topicson the text of the reviews (excluding names as stop-words).
This is an exploratory analysis, but can giveinsight into the broad functions of reader responsesin this domain.Table 2 presents the results, grouping the topicsinto three exploratory categories: positive encour-agement and pleas for updates, requests to the authorabout the progression of the story, and emotional re-actions to the story.
Prior studies that have examinedthe role of reviews as a form of interaction betweenthe reader and the author have documented the firsttwo categories extensively (Campbell et al, 2016;Magnifico et al, 2015; Lammers and Marsh, 2015;Black, 2006).
However, despite a significant portionof the reviews consisting of the reader?s emotionalresponses to the story, the way in which readers usereviews as a means of emotional engagement withthe story itself has yet to be examined in such detail.3.3 Predicting reader responses to characterThe presence of reader reviews accompanying eachfanfiction chapter presents a unique opportunity todevelop a predictive model of how readers respondto text?given the text of a chapter, can we predict2050I hate Mr.
Darcy!?
Mr. Darcy walked off; and Elizabethremained with no very cordial feelings towardhim ?Fiction textReader response  Response labelnegativeFigure 2: Illustration of data for predicting readerresponses.
Here we are using features derived onlyfrom FICTION TEXT to predict the RESPONSE LA-BEL.how readers will react?To test the feasibility of this task, we focus onreader responses to character.
A RESPONSE to acharacter is operationalized as a sentence from areader reviewmentioning that character and no othercharacters.
We create an annotated dataset by ran-domly sampling a single character with at least 10reader responses from each of the 500 stories de-scribed in ?3.2.
From this set, we randomly selectexactly 10 responses for each character, to yield atotal of 5,000 reader responses.We then present these 5,000 responses to annota-tors on Amazon Mechanical Turk, and ask them tojudge the sentiment toward the character expressedin the response as either positive, negative, neutral,or not applicable (in the case of character recog-nition errors).
The overall agreement rate amongannotators for this classification task is moderate(Fleiss?
?
= 0.438), in part due to the difficulty ofassessing the responders?
attitudes from short text;while some responses wear their sentiment on theirsleeve (I knew I hated Brandon!
), others requiremore contextual knowledge to judge (Ah Link orAkira appears!
).In order to create a higher-precision subset we se-lect responses with only unanimous positive or neg-ative votes from 3 different annotators, yielding atotal dataset of 1,069 response labels.
We divide thedataset into 80% training/development and 20% fora held-out test (with no overlap in stories betweentraining and test).We also bootstrap additional semi-supervised databy training a sentiment classifier on the unigrams ofthe reader responses in the training data (with a 3-class accuracy of 75%; compared to majority base-line of 49.7%), predicting the sentiment label for allresponses in the dataset, and selecting examples thata.)
have 95% prediction confidence and b.)
whosestories do not appear in the training or test data.
Wesample selected examples to respect the label dis-tribution in the training data, yielding an additional25,000 data points to supplement learning.Our core task is to use only the text of the story(and not the reader response) to predict the corre-sponding response sentiment label in order to un-derstand what aspects of the story (and a character?srole within it) readers are reacting to.
We experimentwith several features to represent the characters:?
AGENT, PATIENT, PREDICATIVE, POSSESSIVErelations for each character (as output byBookNLP), both in the specific chapter and inthe book overall (under the rationale that read-ers are responding to the actions that characterstake).?
Unigrams spoken by the character, both in thechapter and in the book overall.?
Character gender.?
Character?s frequency in the book (binary indi-cators of the decile of their frequency of men-tion).?
Skip-gram representations trained on 4.1Bwords of fanfiction text (200-dimensional,grouped into 1000 clusters using k-means clus-tering); these cluster identities form additionalbinary features by replacing the lexical indica-tors for the text features above.We perform model selection using tenfold cross-validation on the training data alone, training `2-regularized logistic regression on one partition ofthe data, tuning the `2 regularization parameter onanother, and assessing performance on a third (notenone of the test data described above is seen duringthis stage).A majority class (all-positive) baseline on thetraining data results in an accuracy rate of 75.6%;2051only syntactic features yield a significant improve-ment, achieving an accuracy rate of 80.5%.Table 3 lists the most informative features for pre-dicting negatively-assessed characters.
While thesecharacteristic features have face validity and offerpromise for understanding character in more depth,we do not see similar improvements in accuracy onthe truly held-out test data (run once before sub-mission); this same feature set achieves an accuracyrate of 70.4% (compared to a majority baseline onthe test data of 71.4%).
Part of this may be due tothe sample size of the test data (n = 199); a boot-strap 95% confidence interval (Berg-Kirkpatrick etal., 2012) places the accuracy in the range [0.648,0.754].
However, this more likely constitutes a neg-ative result that reflects the inherent difficulty of thetask; while syntactic features point to a real sig-nal that readers are reacting to when writing theirresponses, literary character is of course far morecomplex, and more sophisticated representations ofcharacter?and of the readers who react to them?are likely warranted for real predictive performanceon this task.agent patient predicative possessivehissed hate pregnant phonesneered done human stateshoved see afraid toneglared hated stubborn facepaused asked person spotrespond face boy plancaught pissed angry wandscowled blame stupid painwalked shocked free emotionshad used mother chakraTable 3: Syntactic features most predictive of anegatively-assessed character.4 ConclusionIn blending aspects of large-scale literary data andsocial network structure, fanfiction publication con-stitutes a vibrant ecosystem with ample textual ev-idence for the production and consumption of liter-ary texts.
In this work, we have briefly illustratedthree aspects of this data that have the potential toyield interesting insight?the relationship betweenfanfiction stories and their original source material,the social network structure of authors and their re-spondents, and the possibility of predicting readerresponses from serially published text.
Many ques-tions remain; in providing a quantitative descriptionof this dataset, we hope to highlight its potential foranalysis, and encourage other work in this domain.AcknowledgmentsWe thank Cecilia Aragon and our anonymous re-viewers for their helpful comments.
This work ismade possible by the use of computing resourcesfrom Berkeley Research Computing.ReferencesDavid Bamman, Ted Underwood, and Noah A. Smith.2014.
A Bayesian mixed effects model of literarycharacter.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 370?379, Baltimore,Maryland, June.
Association for Computational Lin-guistics.Jennifer L Barnes.
2015.
Fanfiction as imaginary play:What fan-written stories can tell us about the cognitivescience of fiction.
Poetics, 48:69?82.Taylor Berg-Kirkpatrick, David Burkett, and Dan Klein.2012.
An empirical investigation of statistical sig-nificance in NLP.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, EMNLP-CoNLL ?12, pages 995?1005, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.RW Black.
2006.
Not just the OMG standard: readerfeedback and language, literacy, and culture in onlinefanfiction.
In Annual Meeting of The American Ed-ucational Research Association, San Francisco, vol-ume 10.David M. Blei, Andrew Ng, and Michael Jordan.
2003.Latent dirichlet alocation.
JMLR, 3:993?1022.Kristina Busse.
2009.
In focus: Fandom and feminism:gender and the politics of fan production.
CinemaJournal, 48(4):104?108.Julie Campbell, Cecilia Aragon, Katie Davis, SarahEvans, Abigail Evans, and David Randall.
2016.Thousands of positive reviews: Distributed mentor-ing in online fan communities.
In Proceedings of the19th ACM Conference on Computer-Supported Coop-erative Work & Social Computing, CSCW ?16, pages691?704, New York, NY, USA.
ACM.2052Snigdha Chaturvedi, Shashank Srivastava, Hal Daume,and Chris Dyer.
2015.
Modeling dynamic relation-ships between characters in literary novels.Micha Elsner.
2012.
Character-based kernels for novel-istic plot structure.
In EACL.Christine Handley.
2012.
Distressing damsels: narra-tive critique and reinterpretation in star wars fanfiction.Fan Culture: Theory/Practice, Newcastle upon Tyne:Cambridge Scholars Publishing, pages 97?118.Mohit Iyyer, Anupam Guha, Snigdha Chaturvedi, JordanBoyd-Graber, and Hal Daume?
III.
2016.
Feuding fam-ilies and former friends: Unsupervised learning for dy-namic fictional relationships.
In North American As-sociation for Computational Linguistics.Matthew Jockers.
2015.
Revealing senti-ment and plot arcs with the syuzhet package.http://www.matthewjockers.net/2015/02/02/syuzhet/.Soomin Jwa.
2012.
Modeling L2 writer voice: Discour-sal positioning in fanfiction writing.
Computers andComposition, 29(4):323?340.Jayne C Lammers and Valerie L Marsh.
2015.
Go-ing public: An adolescent?s networked writing on fan-fiction.net.
Journal of Adolescent & Adult Literacy,59(3):277?285.Hui Min Annabeth Leow.
2011.
Subverting the canonin feminist fan fiction.
Transformative Works and Cul-tures, 7.Alecia Marie Magnifico, Jen Scott Curwood, and Jayne CLammers.
2015.
Words on the screen: broadeninganalyses of interactions among fanfiction writers andreviewers.
Literacy, 49(3):158?166.Saif Mohammad.
2011.
From once upon a time to hap-pily ever after: Tracking emotions in novels and fairytales.
CoRR, abs/1309.5909.Christine Scodari and Jenna L Felder.
2000.
Creating apocket universe: Shippers, fan fiction, and the X-Filesonline.
Communication Studies, 51(3):238?257.Bronwen Thomas.
2011.
What is fanfiction and why arepeople saying such nice things about it?
Storyworlds:A Journal of Narrative Studies, 3(1):1?24.Hardik Vala, David Jurgens, Andrew Piper, and DerekRuths.
2015.
Mr. Bennet, his coachman, and theArchbishop walk into a bar but only one of them getsrecognized: On the difficulty of detecting charactersin literary texts.
In Proceedings of the 2015 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 769?774, Lisbon, Portugal, September.Association for Computational Linguistics.Veerle Van Steenhuyse.
2011.
The writing and read-ing of fan fiction and transformation theory.
CLCWeb:Comparative Literature and Culture, 13(4):4.Jun Xu.
2011.
Austen?s fans and fans?
Austen.
Journalof Literary Semantics, 40(1):81?97.Yukun Zhu, Ryan Kiros, Richard S. Zemel, RuslanSalakhutdinov, Raquel Urtasun, Antonio Torralba, andSanja Fidler.
2015.
Aligning books and movies:Towards story-like visual explanations by watchingmovies and reading books.
CoRR, abs/1506.06724.2053
