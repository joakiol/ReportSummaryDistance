Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1576?1585,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsMixKMeans: Clustering Question-Answer ArchivesDeepak PCentre for Data Sciences and Scalable ComputingQueen?s University Belfast, UKdeepaksp@acm.orgAbstractCommunity-driven Question Answering(CQA) systems that crowdsource experientialinformation in the form of questions andanswers and have accumulated valuablereusable knowledge.
Clustering of QAdatasets from CQA systems provides a meansof organizing the content to ease tasks suchas manual curation and tagging.
In this paper,we present a clustering method that exploitsthe two-part question-answer structure in QAdatasets to improve clustering quality.
Ourmethod, MixKMeans, composes question andanswer space similarities in a way that thespace on which the match is higher is allowedto dominate.
This construction is motivatedby our observation that semantic similaritybetween question-answer data (QAs) couldget localized in either space.
We empiricallyevaluate our method on a variety of real-worldlabeled datasets.
Our results indicate thatour method significantly outperforms state-of-the-art clustering methods for the task ofclustering question-answer archives.1 IntroductionCommunity-based Question Answering (CQA) sys-tems such as Yahoo!
Answers1, StackOverflow2 andBaidu Zhidao3 have become dependable sources ofknowledge to solve common user problems.
Unlikefactoid question answering4, CQA systems focus on1http://answers.yahoo.com2http://www.stackoverflow.com3http://en.wikipedia.org/en/Baidu Knows4e.g., http://trec.nist.gov/data/qa.htmlcrowdsourcing how and why questions and their an-swers.
As is the case with any system where con-tent is generated by web users, the generated con-tent would be of varying quality, reliability, readabil-ity and abstraction.
Thus, manual curation of suchdatasets is inevitable to weed out low quality andduplicate content to ensure user satisfaction.
A nat-ural way to aid manual curation of such broad-basedCQA archives is to employ clustering so that seman-tically related QAs are grouped together; this wouldhelp organize the corpus in a way that experts en-gaged in manual curation be assigned specific clus-ters relating to areas of their expertise.
Cluster-ing also provides a platform to enable tagging theQA dataset; cluster topics could be used as tags, orother QAs in the same cluster could be tagged asbeing related to a QA.
The fundamental differencebetween CQA archives and general text documentcollections is the existence of a two-part structurein QAs and the difference in lexical ?character?
be-tween the question and answer parts.
This lexicalchasm (i.e., gap) (Berger et al, 2000) between ques-tion and answer parts has been a subject of muchstudy, especially, in the context of improving QA re-trieval.
In this paper, we consider using the two-partstructure in QAs for clustering CQA datasets.Motivating Example: Table 1 lists four exampleQAs from the context of a CQA system focused onaddressing myriad technical issues.
These QAs havebeen tagged in the table with a manually identifiedroot-cause to aid understanding; the root-cause isnot part of the CQA data per se.
QA1 and QA2 areseen to address related issues pertaining to routers,whereasQA3 andQA4 are focused on the same nar-1576row issue dealing with java libraries.
Since QA1and QA2 address different problems, they may notbe expected to be part of the same cluster in fine-grained clusterings.
On the other hand, the solu-tions suggested in QA3 and QA4 are distinct anddifferent legitimate solutions to the same problemcause.
Thus, from a semantics perspective, it is intu-itive that QA3 and QA4 should be part of the samecluster in any clustering of the CQA dataset to aidactioning on them together; a human expert mightdecide to merge the question parts and tag one ofthe answers as an alternative answer.
Let us nowexamine the lexical relatedness between the pairs asillustrated in Table 2.
State-of-the-art text similar-ity measures that quantify word overlaps are likelyto judge QA1 and QA2 to be having a medium sim-ilarity when either the question-part or the answer-part are considered.
For the pair (QA3, QA4), thequestion-part similarity would be judged to be highand the answer-part similarity as low.
Thus, the highsimilarity between the root-causes ofQA3 andQA4manifest primarily in their question-parts.
Analo-gously, we observed that some QAs involving thesame root-cause lead to high answer-part similaritydespite poor question-part similarity.
This is espe-cially true in cases involving suggestion of the samesequence of solution steps despite the question-partbeing divergent due to focusing on different symp-toms of the same complex problem.
From these ob-servations, we posit that high similarities on eitherthe question-space or answer-space is indicative ofsemantic relatedness.
Any clustering method thatuses a sum, average or weighted sum aggregationfunction to arrive at pair-wise similarities, such asa K-Means clustering that treats the collated QA asa single document, would intuitively be unable toheed to such differential manifestation of semanticsimilarities across the two parts.Our Contributions: We address the problem ofharnessing the two-part structure in QA pairs to im-prove clustering of CQA data.
Based on our obser-vations on CQA data such as those illustrated in theexample, we propose a clustering approach, MixK-Means, that composes similarities (dissimilarities)in the question and answer spaces using a max (min)operator style aggregation.
Through abundant em-pirical analysis on real-world CQA data, we illus-trate that our method outperforms the state-of-the-art approaches for the task of CQA clustering.2 Related WorkTo enable position our work in the context of exist-ing literature, we now summarize prior work alongthree related directions, viz., (1) processing of CQAdatasets, (2) multi-modal data clustering, and (3) K-Means extensions.Processing CQA Datasets: Most work on pro-cessing CQA data has been in the realm of re-trieval, where the task addressed is to leverage CQAdatasets to aid answering new questions.
These startwith a new question and find one of (i) related ques-tions (Zhou et al, 2015), (ii) potentially usable an-swers (Shtok et al, 2012), or (iii) related QAs (Xueet al, 2008).
Different methods differ in the tech-nique employed to overcome the lexical chasm, withstatistical translation models (Brown et al, 1993)that model word-level correlations between ques-tions and answers being the most popular tool for thesame.
Usage of topic models (e.g., (Cai et al, 2011))and combining evidence from topic and translationmodels (Zhou et al, 2015) have also met with suc-cess.
The usage of deep-learning methods such asdeep belief networks (Wang et al, 2011) and auto-encoders (Zhou et al, 2016) have also been exploredfor QA retrieval.
While the problem of estimat-ing the relevance of a QA to address a new ques-tion is related to the problem of estimating sim-ilarities between QAs to aid clustering, the latterproblem is different in that both question and an-swer parts are available at either side.
In fact, ourproblem, CQA clustering, has been largely unex-plored among literature in CQA data processing.
Inthe interest of benchmarking our work against tech-niques from the CQA processing community, weconsider the correlated latent representation learntby the recent auto-encoder based neural network(AENN) method (Zhou et al, 2016) as input toK-Means, and empirically validate our techniqueagainst the AENN+K-Means combination (referredto as AENN, for short) in our experimental study.Outside the task of retrieval, there has been work ongetting QAs from experience reports (Deepak et al,2012) and discussion forums (P and Visweswariah,2014).
Conversational transcripts from contact cen-tres, as outlined in (Kummamuru et al, 2009), form1577# QA CauseQA1Q: My internet connection is not working, my router shows the ?Internet?
led blinking in red.
RouterA: Please go to the router login page and re-login with broadband credentials; click ?connect?
Authenticationand you should be on the internet.
IssueQA2Q: My internet connection is not working, only the power led is lit in the router.
RouterA: Check whether the router login page is loading.
Else, the broadband cable Loosemay not be connected properly.
ConnectionQA3Q: My Java app is picking up the old dojo 0.4.4 libraries though I have a newer version.
MultipleA: Search for dojo 0.4.4 in Windows, and delete off the folder, and it should Libraries inautomatically start using the newer version.
ClasspathQA4Q: My java application is not picking up the new dojo 1.11.1 libraries that I just installed.
MultipleA: Update the java classpath variable to exclude the Libraries inpath to the earlier version, and add the path to the new version.
ClasspathTable 1: Example CQA DataQA LexicalPair Part SimilarityQA1 QA2 Question MediumQA1 QA2 Answer MediumQA3 QA4 Question HighQA3 QA4 Answer LowTable 2: Similarity Analysis of QAs from Table 1another rich source of QA data, but need careful seg-mentation due to interleaving of question and an-swer parts.Multi-modal Data Clustering: The problem ofclustering CQA data is an instance of the gen-eral problem of clustering multi-modal (aka multi-relational, multi-view or heterogeneous) data whenthe question and answer parts are seen as instanti-ations of the same root cause, but in question andanswer ?modalities?.
Clustering multi-modal datahas been explored well in the context of multi-mediadata clustering where each data element comes inmulti-modal form such as [image, caption] pairs or[audio, text] pairs.
The pioneering work in thisfield adapted markov random fields (Bekkerman andJeon, 2007) to generate separate clusterings for eachmodality.
Later approaches are closer to our taskof generating a unified clustering across modalities;they work by learning a unified latent space embed-ding of the dataset, followed by usage of K-Meansclustering (MacQueen and others, 1967).
Eigen-decomposition (Petkos et al, 2012), spectral meth-ods (Blaschko and Lampert, 2008) and canonicalcorrelation analysis (Jin et al, 2015) have been ex-ploited for learning the latent space prior to the clus-tering step.
A recent work (Meng et al, 2014)proposes a single-pass leader-clustering5 style for-mulation called GHF-ART to progressively assigndata objects to clusters.
Unlike most other methodsthat assume that vector representations are obtainedfrom general multimedia data, the authors of GHF-ART lay out how text data be pre-processed for us-age in GHF-ART, making it an appropriate methodfor usage in our setting.
Accordingly, we will useGHF-ART as a baseline method for our experimen-tal study.K-Means Extensions: The method that we proposein this paper, MixKMeans, draws generous inspira-tion from the classical K-Means clustering formula-tion (MacQueen and others, 1967).
There have beennumerous extensions to the basic K-Means formula-tion over the last many decades; many such exten-sions have been covered in focused surveys (Stein-ley, 2006; Jain, 2010).
Of particular interest inour scenario are those relating to usage of varying(dis)similarity measures.
(Patel and Mehta, 2012)discuss the usage of various popular distance mea-sures within the K-Means framework.
The point-symmetry distance, where the distance between anobject and the cluster prototype is determined usingother objects?
information, has been explored (Suand Chou, 2001) for usage within K-Means for facerecognition applications.
Another work (Visalak-shi and Suguna, 2009) suggests the computation ofthe aggregate distance as a fraction of the distance5https://cran.r-project.org/web/packages/leaderCluster/index.html1578along the closest attribute to that along the farthestattribute.
Despite the plethora of work around ex-tending K-Means to work with a variety of methodsto aggregate distances across attributes, we have notcome across previous work composing distances atthe level of attribute sets (or modalities) like we willdo in this work.3 Problem DefinitionLet D = {(q1, a1), .
.
.
, (qn, an)} be a dataset ofQAs from a CQA archive where each answer ai wasposted in response to the corresponding question qi.The CQA clustering problem is the task of parti-tioning D into k clusters C = {C1, .
.
.
, Ck} where?i Ci = D and ?
(i, j), i 6= j ?
Ci ?
Cj = ?
(dis-jointedness) hold such that similar QAs are groupedinto the same cluster and dissimilar QAs are as-signed to different clusters.
The key aspect that dif-ferentiates the CQA clustering problem from gen-eral clustering of relational data is the opportunity toleverage the specifics of the CQA data, such as thetwo-part structure, to model the similarity measurethat would drive the clustering.Evaluation: The quality of a clustering method maybe quantified by assessing how well the clusteringit produces, i.e., C, reflects the semantic similari-ties between QAs in D. Given a QA (qi, ai) ?
D,the other QAs that share the same cluster may bethought of as the result set, i.e., the set of relatedQAs according to C. In a labeled dataset such asCQADupStack (Hoogeveen et al, 2015) where re-lated QA pairs have been manually identified foreach (qi, ai), the quality of the results set may be as-sessed by contrasting against the labeled set using astandard metric such as F-score6.
These QA-specificF-scores are then aggregated across the QAs in D toarrive at a single quality measure for the clustering.We will use such aggregated dataset-level F-scoresas our primary evaluation measure.
It may be notedthat the related labellings may not be ?clustering-friendly?
; for example, there may not exist any k-clustering with no related labels going across clus-ters.
Additionally, we observed that not all relatedQAs were labeled to be related in the CQADupStackdataset.
The dataset owners confirm the problem ofmissing labelings in a very recent study (Hoogeveen6https://en.wikipedia.org/wiki/F1 scoreet al, 2016).
It is conceivable that only a few po-tential results were manually inspected to inject la-bellings.
Thus, while the relative trends on F-scoreoffer insights, the absolute F-scores may only betreated as a loose lower bounds.4 MixKMeans: Our MethodWe now describe the key details of our proposedtechnique, MixKMeans.
The name is motivated bythe flexibility that is built into the method to mix(dis)similarities across question and answer spacesin a formulation that derives inspiration from theclassical K-Means algorithm (MacQueen and oth-ers, 1967).
Throughout this formulation, we repre-sent question and answer parts of QAs by their re-spective tf-idf vectors.
We start with our objectivefunction and move on to the iterative optimization.4.1 Objective FunctionGuided by our observation from Section 1 that thespace in which a pair of QAs are more similar shouldhold sway in determining their overall match, weoutline a penalty function for a clustering C:O?
=?C?C?
(q,a)?C min{wq d(q, C.?.q), wa d(a,C.
?.a)}(1)where C.?
= (C.?, q, C.?.a) is a prototypi-cal QA vector for cluster C and the parameterpair [wq, wa] control the relative weighting betweenquestion and answer parts.
d(., .)
is a dissimilar-ity function modeled as a simple sum of squaresof element-wise differences between vector entries,i.e., d(x, y) =?i(x[i]?
y[i])2.Intuitively,O?
sums up the distance between eachQA in D and the prototypical QA vector of the clus-ter to which it is assigned to, making it a penaltyfunction.
Since we use dissimilarities that are in-versely related to similarities, the min function cap-tures the idea that the aggregate (dis)similarity be es-timated according to the measure in the best match-ing space.
For optimization convenience, we replacethe min construction by a differentiable approxima-tion to get a modified objective function:1579O =?C?C?
(q,a)?C((wqd(q, C.?.q))x+(wad(a,C.
?.a))x) 1x(2)where x is a reasonably high negative value orx ?
??.
This is used since (ax + bx)1/x approxi-mates min{a, b} for high negative values of x.
It isworth noting that the opposite effect (i.e., max ap-proximation) is achieved when x ?
?
for usagein scenarios where a max combination is desirable.The remainder of the steps are applicable for posi-tive values of x too.4.2 Optimization ApproachThere are two sets of variables in Equation 2, viz.,cluster assignments of QAs inD and the cluster pro-totypes (C.?s).
We optimize for each set of variablesalternatively, much like in the EM-steps used in theclassical K-Means algorithm.4.2.1 Estimating Cluster MembershipsThe cluster membership estimation directly fallsout from the objective function and the current es-timates of cluster prototypes since O (Equation 2)involves an instance-specific term for each QA.
Wewill simply assign each QA to the cluster such thatthe respective instance-specific term is minimized:Cluster((q, a)) = argminC?C(dxQ+A((q, a), C.?))
1x(3)dxQ+A(., .)
is a short-hand for composite distance,composed of two terms (which we will denote asdxQ(., .)
and dxA(., .)
respectively):dxQ+A((q, a), C.??)
=(wq ?
d(q, C.?
?.q))x+(wa ?
d(a,C.?
?.a))x (4)4.2.2 Estimating Cluster PrototypesWe now estimate the cluster prototype in element-wise fashion.
Consider a particular element in theC.
?.q vector, C.?.q[i]; computing the partial deriva-tive and simplifying:?O?C.
?.q[i] =?(q,a)?C[?
2(dxQ+A((q, a), C.?))
1?xxdx?1Q ((q, a), C.?)
wq (q[i]?
C.?.q[i])](5)Equating the first derivative to zero and solvingfor C.?.q[i] gets us to the following form:C.?.q[i] =?(q,a)?Cq[i][(dxQ+A((q,a),C.??))
1?xxdx?1Q ((q,a),C.??)]?(q,a)?C[(dxQ+A((q,a),C.??))
1?xxdx?1Q ((q,a),C.??)](6)whereC.??
is used to indicate the estimate ofC.
?from the previous iteration.
The corresponding esti-mation for C.?.a[i] is:C.?.a[i] =?(q,a)?Ca[i][(dxQ+A((q,a),C.??))
1?xxdx?1A ((q,a),C.??)]?(q,a)?C[(dxQ+A((q,a),C.??))
1?xxdx?1A ((q,a),C.??
)](7)Equations 6 and 7 form the cluster prototype esti-mation steps of our method.
It may be noted that forthe choice of parameters (x = 1, wq = wa), eitherequations reduce it to the usual centroid estimationprocess for K-Means (since the terms within [.
.
.]
re-duce to 1.0), as intuitively expected.
Thus, the mod-ified formulation generalizes K-Means by allowingto weigh each element differently, the weight beingmodeled as a product two components:?
First component involves dxQ+A(., .)
and is afunction of the composite distance of (q, a) tothe cluster prototype.?
Second component involves one of dx?1Q (., .
)or dx?1A (., .)
and is a function of the respectivespace (Q or A) to which the specific vector ele-ment belongs.1580Alg.
1 MixKMeansInput.
Dataset D, number of clusters kHyper-parameters: x, wq, waOutput.
Clustering C1: Initialize C.?s using data points from D2: while not yet converged do3: ?
(q, a) ?
D, assign cluster using Eq.
34: ?C ?
C, estimate C.?
using Eq.
6 & 75: end while6: Return current clustering assignments as C4.3 MixKMeans: The AlgorithmHaving outlined the various steps, we are now readyto present the overall MixKMeans algorithm inAlgorithm 1.
As the pseudo-code indicates, the clus-ter assignment and prototype estimation steps arerun in a loop until the clustering converges.
Addi-tionally, we terminate after a threshold number of it-erations even if the clustering does not converge bythen; we set the threshold to 10.Initialization: In the initialization step, we ini-tialize the first cluster prototype using a random QAfrom D. Each of the next cluster prototypes are ini-tialized using the QA that has the highest sum ofdistances to all pre-chosen cluster prototypes, dis-tance computed using (dxQ+A(., .))1/x.
This is in-spired by previous work on spreading out the clus-ter centroids (Arthur and Vassilvitskii, 2007) in K-Means initialization.Hyperparameters: The algorithm has threehyper-parameters, viz., the exponentiation parame-ter x and the weight parameters wq and wa.
Asoutlined in Sec.
4.1, x should be a negative value;we observed that any value beyond ?3.0 does notmake any significant differences to the final cluster-ing (while higher absolute values for the exponentpose an underflow risk) and thus use x = ?3.0 con-sistently.
For the weights, we set wq = 0.2 andwa = 0.8.
Due to the min-formulation in the ob-jective function, a lower weight increases the in-fluence of the respective space.
Thus, we let ourcomposed similarities be influenced more by thequestion-space similarities as in previous work (Xueet al, 2008).4.4 Generalizing MixKMeansSince the question and answer spaces are neatly seg-regated into different terms in the parameter up-date equations, MixKMeans is easily generalizableto work with more than two spaces.
Consider theset of spaces to beM = {.
.
.
,M, .
.
.}
and that eachobject,X ?
D be represented by an |M| tuple; now,the modified update equations are as follows:Cluster(X) = argminC?C(d ?M?MM (X,C.?))
1x(8)C.?.M [i] =?X?CX.M [i][(dx ?M?MM (X,C.??))
1?xxdx?1M (X,C.??
)]?X?C[(dx ?M?MM (X,C.??))
1?xxdx?1M (X,C.??
)](9)where the somewhat awkward notationdx?M?MM (., .)
denotes the direct generalizationof dxQ+A(., .)
to cover all spaces inM.A simple modeling extension to use the general-ized MixKMeans in the CQA setting is to considerthe question title and question description as twoseparate spaces instead of using a single questionspace, increasing the total number of spaces to three;such a split of the question-part was used in (Qiu etal., 2013).
In certain cases, one might want to usespaces that are of questionable quality due to rea-sons such as sparsity (e.g., set of tags associated witha question) and reliability (e.g., comments attachedto a QA that could be noisy).
The best way to lever-age such spaces would be to include it inM for themodeling, but use a high weight for wM ; due to themin-style construction in the objective function, thatsetting will ensure that that space is called into playonly when (a) signals from other spaces are not verystrong, and (b) the signal from the space in questionis very strong.5 Experimental Evaluation5.1 Datasets, Baselines and SetupDatasets: We use the recently released data col-1581lection, CQADupStack (Hoogeveen et al, 2015),for our experimental evaluation.
Unlike most otherdatasets, this has each QA labeled with a set ofrelated QAs, as alluded to in Section 3; this makesautomated evaluation feasible in lieu of a laborioususer study.
We use the android, gis, stats andphysics datasets from the CQADupStack collection,with our choice of datasets motivated by datasetsize.
These datasets comprise 2193, 3726, 4004 and5044 QAs respectively.Baselines: We use two baselines from literaturein our study, (i) AENN (Zhou et al, 2016), (ii)GHF-ART (Meng et al, 2014).
AENN, as alludedto in Section 2, refers to the K-Means clustering inthe latent space learnt by correlated auto-encodersacross the Q-A subspaces.
AENN requires tripletsof the form [question, answer, other answer] inthe training phase; we populate the other answerpart by the answer to a related question from thedataset (it may be noted that this is advantageous toAENN since it gets to ?see?
some related labelingsin the training, whereas other methods can?t).
GHF-ART is the state-of-the-art multi-modal clusteringapproach that is targeted towards scenarios thatinvolve a text modality.
Unlike typical clusteringalgorithms that can generate a pre-specified (k)number of clusters, the number of clusters in theGHF-ART output is controlled by a vigilanceparameter, ?.
Lower values of ?
result in smallernumber of clusters and vice versa.
A third intuitivebaseline is the degenerate x = 1 instantiation ofMixKMeans, which we will denote as X1.
We areinterested in evaluating the improvement achievedby MixKMeans over the best possible instantiationof X1; towards that, for every setting denoted bythe combination [dataset, k], we do a search overpossible positive values of wq and wa within thelocus of the line wq + wa = 1.
It may be noted thatthis search space includes simple QA clustering us-ing K-Means, being the case where wq = wa = 0.5.We collect the best result of X1 from across thegrid-search for each setting.
This approach, whichwe will denote as X1?, while impractical in realscenarios due to usage of labeled data, gives anempirical upper bound of the accuracy of X1.Experimental Setup: We use a latent space di-Figure 1: Android: F-Score (Y-Axis) vs. kFigure 2: GIS: F-Score (Y-Axis) vs. kFigure 3: Stats: F-Score (Y-Axis) vs. kFigure 4: Physics: F-Score (Y-Axis) vs. kmensionality of 2000 for AENN since we observedan accuracy peak around that value, and set GHF-ART parameters to their recommended values fromthe paper.
For MixKMeans, we use tf-idf represen-tation and set (x = ?3.0, wq = 0.2, wa = 0.8)as discussed earlier (Section 4.3).
We use the F-score7 measure to experimentally compare the ap-proaches.
The F-score is computed using the related7https://en.wikipedia.org/wiki/F1 score1582Figure 5: MixKMeans: F-Score (Y-Axis) vs. wq at k = 600labellings in the CQADupStack data, in a manner asdescribed in Section 3.
As pointed out therein, dueto the sparse labellings, the F-score may only be re-garded as a loose lower bound of their real values ona fully-labeled dataset.5.2 Comparative AnalysisThe results of the comparative analysis benchmark-ing our approach MixKMeans (MKM) against base-lines X1?, AENN and GHF-ART for the variousdatasets appear in Fig 1 (Android), Fig 2 (GIS),Fig 3 (Stats) and Fig 4 (Physics).
Each of the trend-lines plot the F-Score against varying number ofclusters in the output (k) in the range {100, 1000}.Since the number of clusters cannot be pre-specifiedfor GHF-ART directly, we varied its ?
parameter togenerate varying number of clusters to generate atrend-line that can be compared against MixKMeans,AENN and X1?
directly.
It may be noted that F-score is generally seen to increase when the cluster-ing is more fine-grained (i.e., high k); this is an arti-fact of the sparse labeling that causes large clustersto have very low precision, causing precision and re-call to diverge at low k, thus reducing the F-score.In most cases, MixKMeans is seen to outperform theother methods by scoring significantly higher in theF-Score, illustrating the superiority of our method.A notable exception appears in the higher values ofk in the android dataset where GHF-ART quicklycatches up and surpasses the others; however, it maybe noted that k ?
1000 is an extremely fine-grainedclustering for the android dataset with 2193 QAs,and is thus not a very useful setting in practice.
Onthe average, MixKMeans achieves an F-score im-provement of between 30 ?
100% over the othermethods.5.3 MixKMeans Parameter AnalysisWe now analyze the F-score trends of MixKMeansagainst varying values of the weight parameters.Since the relative weighting between wq and wa iswhat matters (simply scaling them both up by thesame multiplier does not make any difference dueto the construction of the objective), we set wa =(1.0 ?
wq) and do the analysis for varying valuesof wq keeping k = 600.
As may be observed fromthe results in Figure 5, MixKMeans was seen to peakaround wq = 0.2-0.5 while degrading gracefully to-wards higher values of wq.
The android dataset, per-haps due to its relatively small size, records a dif-ferent behavior as compared to the other trend-lines.Similar trends were observed for other values of k,indicating MixKMeans is not highly sensitive to theparameter and degrades gracefully outside the peak.6 Conclusions and Future WorkWe considered the problem of clustering question-answer archives from CQA systems.
Clustering, weobserved, helps in organizing CQA archival data forpurposes such as manual curation and tagging.
Wemotivated, by way of examples, as to why simi-larities along question and answer spaces be bettercomposed using methods other than simple sum oraverage type aggregation.
In particular, we notedthat there are potentially different ways to answerquestions pertaining to the same root-cause, miti-gating the manifestation of the inherent root-causesimilarity in the answer-space.
Analogously, a so-phisticated root-cause could be narrated differentlyby different people in the question part, while elicit-ing very similar answers.
In short, we observe thatlegitimate reasons cause manifestation of semanticsimilarity between QAs to be localized on to oneof the spaces.
Accordingly, we propose a cluster-ing method for QA archives, MixKMeans, that canheed to high similarities in either spaces to drive theclustering.
MixKMeans works by iteratively opti-mizing the two sets of parameters, cluster assign-ments and cluster prototype learning, in an approachinspired by the classical K-Means algorithm.
Weempirically benchmark our method against currentmethods on multiple real-world datasets.
Our exper-imental study illustrates that our method is able tosignificantly outperform other methods, establishing1583MixKMeans as the preferred method for the task ofclustering CQA datasets.Future Work: As discussed in Section 4.4,MixKMeans is eminently generalizable to beyondtwo spaces.
Considering the usage of other kinds ofdata (e.g., tags, comments) as additional ?spaces?
toextend the CQA clustering problem is an interestingdirection for future work.
The applicability of MixK-Means and it?s max variant (i.e., with x > 0) forother kinds of multi-modal clustering problems fromdomains such as multimedia processing is worth ex-ploring.
The extension of the formulation to includea weight learning step may be appropriate for sce-narios where prior information on the relative im-portance of the different spaces is not available.
It iseasy to observe that MixKMeans is prone to local op-tima issues; this makes devising better initializationstrategies another potential direction.
Yet another di-rection of interest is to make MixKMeans clustersinterpretable, potentially by augmenting each clus-ter with word-level rules as used in earlier work onpartitional document clustering (Balachandran et al,2012).ReferencesDavid Arthur and Sergei Vassilvitskii.
2007. k-means++:The advantages of careful seeding.
In Proceedings ofthe eighteenth annual ACM-SIAM symposium on Dis-crete algorithms, pages 1027?1035.
Society for Indus-trial and Applied Mathematics.Vipin Balachandran, Deepak P, and Deepak Khemani.2012.
Interpretable and reconfigurable clusteringof document datasets by deriving word-based rules.Knowl.
Inf.
Syst., 32(3):475?503.Ron Bekkerman and Jiwoon Jeon.
2007.
Multi-modalclustering for multimedia collections.
In Computer Vi-sion and Pattern Recognition, 2007.
CVPR?07.
IEEEConference on, pages 1?8.
IEEE.Adam Berger, Rich Caruana, David Cohn, Dayne Freitag,and Vibhu Mittal.
2000.
Bridging the lexical chasm:statistical approaches to answer-finding.
In Proceed-ings of the 23rd annual international ACM SIGIR con-ference on Research and development in informationretrieval, pages 192?199.
ACM.Matthew B Blaschko and Christoph H Lampert.
2008.Correlational spectral clustering.
In Computer Visionand Pattern Recognition, 2008.
CVPR 2008.
IEEEConference on, pages 1?8.
IEEE.Peter F Brown, Vincent J Della Pietra, Stephen A DellaPietra, and Robert L Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational linguistics, 19(2):263?311.Li Cai, Guangyou Zhou, Kang Liu, and Jun Zhao.
2011.Learning the latent topics for question retrieval in com-munity qa.
In IJCNLP, volume 11, pages 273?281.P.
Deepak, Karthik Visweswariah, Nirmalie Wiratunga,and Sadiq Sani.
2012.
Two-part segmentation of textdocuments.
In 21st ACM International Conference onInformation and Knowledge Management, CIKM?12,Maui, HI, USA, October 29 - November 02, 2012,pages 793?802.Doris Hoogeveen, Karin M Verspoor, and Timothy Bald-win.
2015.
Cqadupstack: A benchmark data set forcommunity question-answering research.
In Proceed-ings of the 20th Australasian Document ComputingSymposium, page 3.
ACM.Doris Hoogeveen, Karin M Verspoor, and Timothy Bald-win.
2016.
Cqadupstack: Gold or silver?Anil K Jain.
2010.
Data clustering: 50 years beyondk-means.
Pattern recognition letters, 31(8):651?666.Cheng Jin, Wenhui Mao, Ruiqi Zhang, Yuejie Zhang, andXiangyang Xue.
2015.
Cross-modal image cluster-ing via canonical correlation analysis.
In Twenty-NinthAAAI Conference on Artificial Intelligence.Krishna Kummamuru, Deepak Padmanabhan, ShouryaRoy, and L Venkata Subramaniam.
2009.
Unsuper-vised segmentation of conversational transcripts.
Sta-tistical Analysis and Data Mining, 2(4):231?245.James MacQueen et al 1967.
Some methods for classi-fication and analysis of multivariate observations.
InProceedings of the fifth Berkeley symposium on math-ematical statistics and probability, volume 1, pages281?297.
Oakland, CA, USA.Lei Meng, Ah-Hwee Tan, and Dong Xu.
2014.
Semi-supervised heterogeneous fusion for multimedia dataco-clustering.
Knowledge and Data Engineering,IEEE Transactions on, 26(9):2293?2306.Deepak P and Karthik Visweswariah.
2014.
Unsuper-vised solution post identification from discussion fo-rums.
In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguistics, ACL2014, June 22-27, 2014, Baltimore, MD, USA, Volume1: Long Papers, pages 155?164.Vaishali R. Patel and Rupa G. Mehta, 2012.
Proceed-ings of the International Conference on Soft Comput-ing for Problem Solving (SocProS 2011) December20-22, 2011: Volume 2, chapter Data Clustering: In-tegrating Different Distance Measures with Modifiedk-Means Algorithm, pages 691?700.
Springer India,India.Georgios Petkos, Symeon Papadopoulos, and YiannisKompatsiaris.
2012.
Social event detection using mul-timodal clustering and integrating supervisory signals.1584In Proceedings of the 2nd ACM International Confer-ence on Multimedia Retrieval, page 23.
ACM.Xipeng Qiu, Le Tian, and Xuanjing Huang.
2013.
Latentsemantic tensor indexing for community-based ques-tion answering.
In ACL (2), pages 434?439.Anna Shtok, Gideon Dror, Yoelle Maarek, and IdanSzpektor.
2012.
Learning from the past: answeringnew questions with past answers.
In Proceedings ofthe 21st international conference on World Wide Web,pages 759?768.
ACM.Douglas.
Steinley.
2006.
K-means clustering: A half-century synthesis.
British Journal of Mathematicaland Statistical Psychology, 59(1):1?34.Mu-Chun Su and Chien-Hsing Chou.
2001.
A modifiedversion of the k-means algorithm with a distance basedon cluster symmetry.
IEEE Transactions on PatternAnalysis & Machine Intelligence, (6):674?680.N Karthikeyani Visalakshi and J Suguna.
2009.
K-meansclustering using max-min distance measure.
In FuzzyInformation Processing Society, 2009.
NAFIPS 2009.Annual Meeting of the North American, pages 1?6.IEEE.Baoxun Wang, Bingquan Liu, Xiaolong Wang, ChengjieSun, and Deyuan Zhang.
2011.
Deep learning ap-proaches to semantic relevance modeling for chinesequestion-answer pairs.
ACM Transactions on AsianLanguage Information Processing (TALIP), 10(4):21.Xiaobing Xue, Jiwoon Jeon, and W Bruce Croft.
2008.Retrieval models for question and answer archives.
InProceedings of the 31st annual international ACM SI-GIR conference on Research and development in in-formation retrieval, pages 475?482.
ACM.Tom Chao Zhou, Michael Rung-Tsong Lyu, Irwin King,and Jie Lou.
2015.
Learning to suggest questions insocial media.
Knowledge and Information Systems,43(2):389?416.Guangyou Zhou, Yin Zhou, Tingting He, and WenshengWu.
2016.
Learning semantic representation withneural networks for community question answering re-trieval.
Knowledge-Based Systems, 93:75?83.1585
