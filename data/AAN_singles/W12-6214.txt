Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 75?79,Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational LinguisticsA methodology for obtaining concept graphs from word graphsMarcos Calvo, Jon Ander Go?mez, Llu??s-F.
Hurtado, Emilio SanchisDepartament de Sistemes Informa`tics i Computacio?Universitat Polite`cnica de Vale`nciaCam??
de Vera s/n, 46022, Vale`ncia, Spain{mcalvo,jon,lhurtado,esanchis}@dsic.upv.esAbstractIn this work, we describe a methodologybased on the Stochastic Finite State Trans-ducers paradigm for Spoken Language Under-standing (SLU) for obtaining concept graphsfrom word graphs.
In the edges of these con-cept graphs, both semantic and lexical infor-mation are represented.
This makes thesegraphs a very useful representation of the in-formation for SLU.
The best path in these con-cept graphs provides the best sequence of con-cepts.1 IntroductionThe task of SLU can be seen as the process that,given an utterance, computes a semantic interpreta-tion of the information contained in it.
This semanticinterpretation will be based on a task-dependent setof concepts.An area where SLU systems are typically appliedis the construction of spoken dialog systems.
Thegoal of the SLU subsystem in the context of a dia-log system is to process the information given by theAutomatic Speech Recognition (ASR) module, andprovide the semantic interpretation of it to the Dia-log Manager, which will determine the next actionof the dialog.
Thus, the work of the SLU modulecan be split into two subtasks, the first of them isthe identification of the sequence of concepts and thesegments of the original sentence according to them,and the other is the extraction of the relevant infor-mation underlying to these labeled segments.
In thiswork we will focus on concept labeling, but we willalso consider the other subtask in our evaluation.We can distinguish between the SLU systems thatwork with the 1-best transcription and those that takea representation of the n-best (Hakkani-Tu?r et al,2006; Tur et al, 2002).
The use of a word graph asthe input of the SLU module makes this task moredifficult, as the search space becomes larger.
On theother hand, the advantage of using them is that thereis more information that could help to find the cor-rect semantic interpretation, rather than just takingthe best sentence given by the ASR.In the recent literature, a variety of approaches forautomatic SLU have been proposed, like those ex-plained in (Hahn et al, 2010; Raymond and Ric-cardi, 2007; McCallum et al, 2000; Macherey etal., 2001; Le?fe`vre, 2007; Lafferty et al, 2001).
Themethodology that we propose in this paper is basedon Stochastic Finite State Transducers (SFST).
Thisis a generative approach that composes several trans-ducers containing acoustic, lexical and semanticknowledge.
Our method performs this compositionon-the-fly, obtaining as a result a concept graph,where semantic information is associated with seg-ments of words.
To carry out this step, we use adifferent language model for each concept and alsostudy the use of lexical categorization and lemmas.The best sequence of concepts can be determined byfinding the best path in the concept graph, with thehelp of a language model of sequences of the con-cepts.The rest of this paper is structured as follows.
InSection 2, the theoretical model for SLU based onSFST is briefly presented.
Then, in Section 3 themethodology for converting word graphs into con-cept graphs is described.
A experimentation to eval-75uate this methodology for the SLU task is shown inSection 4.
Finally, we draw some conclusions andfuture work.2 The SFST approach for SLUThe Bayes classifier for the SLU problem can be ex-pressed as stated in equation 1, where C representsa sequence of concepts or semantic labels and A isthe utterance that constitutes the input to the system.C?
= argmaxCp(C|A) (1)Taking into account the underlying sequence ofwords W , and assuming that the acoustics may de-pend onW but not onC, this equation can be rewrit-ten as follows.C?
= argmaxCmaxWp(A|W ) ?
p(W,C) (2)To compute the best sequence of concepts C?
ex-pressed as in equation 2, the proposal made by theparadigm based on SFST is to search the best path ina transducer ?SLU result of composing four SFST:?SLU = ?G ?
?gen ?
?W2C ?
?SLM (3)In this equation ?G is a SFST provided bythe ASR module where the acoustic probabilitiesp(A|W ) are represented, ?gen introduces prior in-formation of the task by means of a lexical cate-gorization, ?W2C provides the probability of a se-quence of words and labels it with a semantic labeland ?SLM modelizes a language model of sequencesof concepts.3 From word graphs to concept graphsThe output of an ASR can be represented as a wordgraph.
This word graph can be enriched with se-mantic information, obtaining a concept graph.
Thisconcept graph constitutes a useful representation ofthe possible semantics, considering the uncertaintyexpressed in the original word graph.
Finally, find-ing the best path in the concept graph using a lan-guage model of sequences of concepts provides asa result the best sequence of concepts C?, the recog-nized sentence W?
, and its segmentation accordingto C?.3.1 Topology and semantics of the word graphTo perform the transformations for obtaining theconcept graph, the input graph given by the ASRshould represent the information in the followingway.
First, its nodes will be labeled with times-tamps.
Also, for every two nodes i, j such thati < j ?
1, there will be an edge from i to j labeledwith w and weight s if the ASR detected w betweenthe instants i and j ?
1 with an acoustic score s.Finally, there may exist a ?-transition between anypair of adjacent nodes.
The score of this edge shouldbe computed by means of a smoothing method.Defining the word graph in this way allows us tomodel on it the distribution p(A|w), where A is thesequence of acoustic frames between the initial andfinal nodes of any edge, and w the word attached toit.
This probability distribution is represented in thetheoretical model by ?G.3.2 Building the concept graphThe concept graph that is obtained has the followingfeatures.
First, its set of nodes is the same of theword graph, and its meaning is kept.
There is at mostone edge between every two nodes i and j (i < j)labeled with the concept c. Every edge is labeledwith a pair (W, c), where W is a sequence of wordsand c the concept that they represent.
The weightof the edge is maxW (p(Aji |W ) ?p(W |c)), where Ajiare the acoustic frames in the interval [i, j[ and Wthe argument that maximizes the former expression.In this specification appears the probability distri-bution p(W |c), which can be estimated by using alanguage model for each available concept.This concept graph can be built using a DynamicProgramming algorithm that finds for each conceptc and each pair of nodes i, j, with i < j, thepath from i to j on the word graph that maximizesp(Aji |W )?p(W |c).
In this case,W is the sequence ofwords obtained by concatenating the words attachedto the edges of the path.
Each of the ?best paths?computed in this way will become an edge in theresulting concept graph.Thus, in the concept graph it is represented infor-mation about possible sequences of words that mighthave been uttered by the speaker, along with the con-cepts each of these sequences expresses.
This pair isweighted with a score that is the result of combining76the acoustic score expressed in the word graph, andthe lexical and syntactic score given by the languagemodel, which is dependent on the current concept.Furthermore, this information is enriched with tem-poral information, since the initial and final nodesof every edge represent the beginning and endingtimestamps of the sequence of words.
Consequently,this way of building the concept graph correspondsto the transducer ?W2C of equation 3, since we findsequences of words and attach them to a concept.However, we also take advantage of and keep otherinformation, such as the temporal one.4 Experiments and resultsTo evaluate this methodology, we have performedSLU experiments using the concept graphs obtainedas explained in Section 3 and then finding the bestpath in each of them.
For this experimentation wehave used the DIHANA corpus (Bened??
et al, 2006).This is a corpus of telephone spontaneous speech inSpanish composed by 900 dialogs acquired by 225speakers using the Wizard of Oz technique, with atotal of 6,229 user turns.
All these dialogs simulatereal conversations in an automatic train informationphone service.
The experiments reported here wereperformed using the user turns of the dialogs, split-ting them into a set of 1,340 utterances (turns) fortest and all the remaining 4,889 for training.
Someinteresting statistics about the DIHANA corpus aregiven in table 1.Number of words 47,222Vocabulary size 811Average number of words per user turn 7.6Number of concepts 30Table 1: Characteristics of the DIHANA corpus.In the DIHANA corpus, the orthographic tran-scriptions of the utterances are semi-automaticallysegmented and labeled in terms of semantic units.This segmentation is used by our methodology as alanguage model of sequences of words for each con-cept.
All the language models involved in this exper-imentation are bigram models trained using Witten-Bell smoothing and linear interpolation.In our experimentation, we have considered threedifferent ways for building the ?gen transducer ex-plained in Section 2.
The first way consists of con-sidering a transducer that given a word as its input,outputs that word with probability 1.
This meansthat no generalization is being done.The second ?gen transducer performs a lexicalcategorization of some of the nouns of the vocab-ulary.
Some extra words have been added to somelexical categories, in order to make the task morerealistic, as the lexical coverage is increased.
Never-theless, it also makes the task harder, as the size ofthe vocabulary increases.
We have used a total of 11lexical categories.Finally, the third ?gen, transducer we have gen-erated performs the same lexical categorization butit also includes a lemmatization of the verbs.
Thisprocess is normally needed for real-world systemsthat work with spontaneous (and maybe telephonic)speech.We have generated three sets of word graphs totake them as the input for the method.
The first ofthese sets, G1, is made up by the whole graphs ob-tained from a word graph builder module that workswithout using any language model.
The OracleWER of these graphs is 4.10.
With Oracle WER wemean the WER obtained considering the sequence ofwords S(G) corresponding to the path in the graphG that is the nearest to the reference sentence.The second set, G2, is composed by word graphsthat only contain the path corresponding to S(G) foreach graph G ?
G1.
These graphs give an idea ofthe best results we could achieve if we could mini-mize the confusion due to misrecognized words.The third set, G3 is formed by a synthetic wordgraph for each reference sentence, in which only thatsentence is contained.
This set of graphs allows usto simulate an experimentation on plain text.For our evaluation, we have taken two measures.First, we have evaluated the Concept Error Rate(CER) over the best sequence of concepts.
The def-inition of the CER is analogous to that of the WERbut taking concepts instead of words.
Second, wehave also evaluated the slot-level error (SLE).
TheSLE is similar to the CER but deleting the non-relevant segments (such as courtesies) and substitut-ing the relevant concepts by a canonic value for thesequence of words associated to them.Tables 2, 3, and 4 show the results obtained usingthe different ?gen transducers explained before.77Input word graphs CER SLEG1 31.794 35.392G2 11.230 9.104G3 9.933 5.321Table 2: CER and SLE without any categorization.Input word graphs CER SLEG1 34.565 38.760G2 11.755 8.714G3 9.633 4.516Table 3: CER and SLE with lexical categorization.From the results of Tables 2, 3, and 4 several factscome to light.
First, we can see that, in all the exper-iments performed with the G1 set, the CER is lowerthan the SLE, while with the other sets the CER islarger than the SLE.
It is due to the fact that thewhole graphs obtained from the word graph builderhave more lexical confusion than those from G2 andG3, which are based on the reference sentence.
Thislexical confusion may cause that a well-recognizedconcept is associated to a misrecognized sequenceof words.
This would imply that a hit would be con-sidered for the CER calculation, while the value forthis slot is missed.Other interesting fact is that, for the G1 set, themore complex ?gen transducers give the worse re-sults.
This is because in these graphs there is asignificant confusion between phonetically similarwords, as the graphs were generated without anylanguage model.
This phonetic confusion, combinedwith the generalizations expressed by the lexical cat-egorization and the lemmas, makes the task harder,which leads to worse results.
Nevertheless, in a real-world application of this system these generaliza-tions would be needed in order to have a larger cov-erage of the lexicon of the language.
The experi-ments on G2 and G3 show that when the confusionintroduced in the graphs due to misrecognized wordsis minimized, the use of lexical categorization andlemmatization helps to improve the results.5 Conclusions and future workIn this paper we have described a methodology,based on the SFST paradigm for SLU, for obtainingInput word graphs CER SLEG1 36.536 40.640G2 11.605 8.445G3 9.458 4.064Table 4: CER and SLE with lemmatization and lexicalcategorization.concept graphs from word graphs.
The edges of theconcept graphs represent information about possiblesequences of words that might have been uttered bythe speaker, along with the concept each of these se-quences expresses.
Each of these edges is weightedwith a score that combines acoustic, lexical, syntac-tic and semantic information.
Furthermore, this in-formation is enriched with temporal information, asthe nodes represent the beginning and ending of thesequence of words.
These concepts graphs consti-tute a very useful representation of the informationfor SLU.To evaluate this methodology we have performedan experimental evaluation in which different typesof lexical generalization have been considered.
Theresults show that a trade-off between the lexical con-fusion expressed in the word graphs and the general-izations encoded in the other transducers should beachieved, in order to obtain the best results.It would be interesting to apply this methodologyto word graphs generated with a language model,although this way of generating the graphs wouldnot fit exactly the theoretical model.
If a languagemodel is used to generate the graphs, then their lex-ical confusion could be reduced, so better resultscould be achieved.
Other interesting task in whichthis methodology could help is in performing SLUexperiments on a combination of the output of somedifferent ASR engines.
All these interesting appli-cations constitute a line of our future work.AcknowledgmentsThis work has been supported by the Spanish Mi-nisterio de Econom?
?a y Competitividad, under theproject TIN2011-28169-C05-01, by the Vicerrec-torat d?Investigacio?, Desenvolupament i Innovacio?de la Universitat Polite`cnica de Vale`ncia, under theproject PAID-06-10, and by the Spanish Ministeriode Educacio?n under FPU Grant AP2010-4193.78ReferencesJose?-Miguel Bened?
?, Eduardo Lleida, Amparo Varona,Mar??a-Jose?
Castro, Isabel Galiano, Raquel Justo, In?igoLo?pez de Letona, and Antonio Miguel.
2006.
Designand acquisition of a telephone spontaneous speech di-alogue corpus in Spanish: DIHANA.
In Proceedingsof LREC 2006, pages 1636?1639, Genoa (Italy).S.
Hahn, M. Dinarelli, C. Raymond, F. Le?fe`vre,P.
Lehnen, R. De Mori, A. Moschitti, H. Ney, andG.
Riccardi.
2010.
Comparing stochastic approachesto spoken language understanding in multiple lan-guages.
Audio, Speech, and Language Processing,IEEE Transactions on, 6(99):1569?1583.D.
Hakkani-Tu?r, F. Be?chet, G. Riccardi, and G. Tur.2006.
Beyond ASR 1-best: Using word confusion net-works in spoken language understanding.
ComputerSpeech & Language, 20(4):495?514.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In InternationalConference on Machine Learning, pages 282?289.Citeseer.F.
Le?fe`vre.
2007.
Dynamic bayesian networks and dis-criminative classifiers for multi-stage semantic inter-pretation.
In Acoustics, Speech and Signal Processing,2007.
ICASSP 2007.
IEEE International Conferenceon, volume 4, pages 13?16.
IEEE.K.
Macherey, F.J. Och, and H. Ney.
2001.
Natural lan-guage understanding using statistical machine transla-tion.
In European Conf.
on Speech Communicationand Technology, pages 2205?2208.
Citeseer.A.
McCallum, D. Freitag, and F. Pereira.
2000.
Maxi-mum entropy markov models for information extrac-tion and segmentation.
In Proceedings of the Seven-teenth International Conference onMachine Learning,pages 591?598.
Citeseer.C.
Raymond and G. Riccardi.
2007.
Generative anddiscriminative algorithms for spoken language under-standing.
Proceedings of Interspeech2007, Antwerp,Belgium, pages 1605?1608.G.
Tur, J. Wright, A. Gorin, G. Riccardi, and D. Hakkani-Tu?r.
2002.
Improving spoken language understandingusing word confusion networks.
In Proceedings of theICSLP.
Citeseer.79
