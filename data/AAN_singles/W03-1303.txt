Using Domain-Specific Verbs for Term ClassificationIrena Spasi?Computer ScienceUniversity of Salford, UKI.Spasic@salford.ac.ukGoran Nenadi?Department of ComputingUMIST, UKG.Nenadic@umist.ac.ukSophia AnaniadouComputer ScienceUniversity of Salford, UKS.Ananiadou@salford.ac.ukAbstractIn this paper we present an approach toterm classification based on verb com-plementation patterns.
The complementa-tion patterns have been automaticallylearnt by combining information found ina corpus and an ontology, both belongingto the biomedical domain.
The learningprocess is unsupervised and has been im-plemented as an iterative reasoning pro-cedure based on a partial order relationinduced by the domain-specific ontology.First, term recognition was performed byboth looking up the dictionary of termslisted in the ontology and applying theC/NC-value method.
Subsequently, do-main-specific verbs were automaticallyidentified in the corpus.
Finally, theclasses of terms typically selected as ar-guments for the considered verbs were in-duced from the corpus and the ontology.This information was used to classifynewly recognised terms.
The precision ofthe classification method reached 64%.1 IntroductionBasic notions used when describing a specificproblem domain are concepts, classes and attrib-utes (or features).
The identification of concepts,linguistically represented by domain-specific terms(Maynard and Ananiadou, 2000), is a basic step inthe automated acquisition of knowledge from tex-tual documents.
Textual documents describing newknowledge in an intensively expanding domain areswamped by new terms representing newly identi-fied or created concepts.
Dynamic domains, suchas biomedicine, cannot be represented by staticmodels, since new discoveries give rise to the ap-pearance of new terms.
This makes the automaticterm recognition (ATR) tools essential assets forefficient knowledge acquisition.However, ATR itself is not sufficient when itcomes to organizing newly acquired knowledge.Concepts are natively assorted into groups and awell-formed model of a domain, representedthrough terms and their relations, needs to reflectthis property consistently.
Dynamic domain mod-els should be able to adapt to the advent of newterms representing newly discovered or identifiedconcepts.
In other words, newly extracted termsneed to be incorporated into an existing model byassociating them with one another and with alreadyestablished terms preferably in an automated man-ner.
This goal may be achieved by relying on termclustering (the process of linking semanticallysimilar terms together) and term classification (theprocess of assigning terms to classes from a pre-defined classification scheme).
In particular, classi-fication results can be used for efficient and consis-tent term management through populating andupdating existing ontologies in expanding domainssuch as biomedicine.
In this paper, we comparesome of the term classification approaches and in-troduce another approach to this problem.The paper is organised as follows.
In Section 2we provide a brief overview of the existing termclassification approaches and suggest the main ideaof our approach to this problem.
Section 3 de-scribes the learning phase of our classificationmethod.
Further, Section 4 provides details on theclassification algorithm.
Finally, in Section 5 wedescribe the evaluation strategy and provide theresults, after which we conclude the paper.2 Term Classification ApproachesSimilarly to general classification algorithms, theexisting term classification approaches typicallyrely on learning techniques.
These techniques aremost often statistically based (e.g.
hidden Markovmodels, naive Bayesian learning, etc.).
Other tech-niques include decision trees, inductive rule learn-ing, support-vector machines (SVMs), etc.
We, onthe other hand, suggest the use of a genetic algo-rithm as a learning engine for the classificationtask.
Let us now discuss some approaches to theautomatic classification of biomedical terms.Nobata et al (2000) implemented a statisticalmethod for term classification.
In their approach,each class was represented by a list of (single)words.
The first step was to estimate the condi-tional probability P(c | w) of each word w beingassigned to a specific class c, based on the assump-tion that each word occurrence is independent ofits context and position in the text.
Further, yet an-other strong restriction was made by assuming thatthere was one-to-one correspondence betweenterms and their classes.
In addition, this approachis not applicable to ?unknown?
terms, i.e.
termscontaining words for which no classification prob-abilities had been determined.
A special class, re-ferring to ?other?, was introduced to cover suchwords.
Bearing in mind the increasing number ofnew terms, such an approach is bound to produceskewed results, where many of the terms wouldsimply be classified as ?other?.While Nobata et al (2000) statistically proc-essed the information found inside the terms, Col-lier et al (2001) applied statistical techniques tothe information found outside the terms.
A hiddenMarkov model based on n-grams (assuming that aterm?s class may be induced from the previous n-1lexical items and their classes) was used as a theo-retical basis for their classification method.
Themethod relied on the orthographic features includ-ing numerals, capital and Greek letters, specialcharacters (such as `-`, `/`, `+`, etc.
), parenthesis,etc.
In the biomedical domain, such features oftenprovide hints regarding the class of a specific term.Each unclassified term was assigned a class of themost similar (with respect to the orthographic fea-tures) term from the training set.
This approachencountered the minority class prediction problem.Namely, the best classification results in terms ofrecall and precision were achieved for the mostfrequent class of terms in their training corpus,while the worst results were those achieved for theleast frequent class.Hatzivassiloglou et al (2001) proposed amethod for unsupervised learning of weights forcontext elements (including words as context con-stituents and the corresponding positional andmorphological information) of known terms andusing these weights for term classification.
Threewell-known learning techniques were used: naiveBayesian learning, decision trees, and inductiverule learning.
Simplified classification experimentsin which a classification algorithm was choosingbetween two or three options respectively wereconducted.
The precision of binary classificationwas around 76% for all three learning algorithms,and the precision dropped to approximately 67%when choosing between three options.
If the pro-posed techniques were to be applied for generalclassification where the number of options is arbi-trary, the precision is expected to decrease evenfurther.Nenadic et al (2003b) conducted a series oflarge-scale experiments with different types of fea-tures for a multi-class SVM.
These features in-cluded document identifiers, single words, theirlemmas and stems, and automatically recognisedterms.
The results indicated that the performancewas approximately the same (around 60% in thebest case) when using single words, lemmas orstems.
On the other side, terms proved to be better(more than 90% precision) than single words atlower recall points (less than 10%), which meansthat terms as features can improve the precision forminority classes.
The best results were achievedwith document identifiers, but such features cannotbe used on the fly in new documents.Spasic et al (2002) used a genetic algorithm(GA) based on a specific crossover operator to ex-plore the relationships between verbs and the termscomplementing them.
The GA performed reason-ing about term classes allowed to be combinedwith specific verbs by using an existing ontologyas a seed for learning.
In this paper, we use the re-sults of the proposed methodology as a platformfor term classification.
In the following section webriefly overview the method for the acquisition ofverb complementation patterns.3 Verb Complementation PatternsBy looking at the context of an isolated verb occur-rence it is difficult to predict all term classes thatcan be combined with the given verb.
On the otherhand, the whole ?population?
of terms comple-menting a specific verb is likely to provide a cer-tain conclusion about that verb with respect to itscomplementation patterns.
This was a primary mo-tivation for Spasic et al (2002) to use a GA as itoperates on a population of individuals as opposedto a single individual.
This fact also makes the ap-proach robust, since it does not rely on every spe-cific instance of verb-term combination to becorrectly recognised.As not all verbs are equally important for theterm classification task, we are primarily interestedin domain-specific verb complementation patterns.In our approach, a complementation pattern of adomain-specific verb is defined as a disjunction ofterms and/or their classes that are used in combina-tion with the given verb.
The automatic acquisitionof these patterns is performed in the followingsteps: term recognition, domain-specific verb ex-traction, and the learning of complementation pat-terns.
Let us describe each of these steps in moredetail.3.1   Term RecognitionFirst, a corpus is terminologically processed: bothterms present in the ontology and the terms recog-nised automatically are tagged.
Terms alreadyclassified in the ontology are used to learn theclasses allowed by the domain-specific verbs,while the new terms are yet to be classified basedon the learnt classes.
New terms are recognized bythe C/NC-value method (Frantzi et al, 2000),which extracts multi-word terms.
This method rec-ognises terms by combining linguistic knowledgeand statistical analysis.
Linguistic knowledge isused to propose term candidates through generalterm formation patterns.
Each term candidate t isthen quantified by its termhood C-value(t) calcu-lated as a combination of its numerical characteris-tics: length |t| as the number of words, absolutefrequency f(t) and two types of frequency relativeto the set S(t) of candidate terms containing anested candidate term t (frequency of occurrencenested inside other candidate terms and the numberof different term candidates containing a nestedcandidate term):??????????=?=?
??
)( if  ,))(|)(|1)((||ln)( if  ),(||ln)()(tSsftStfttStfttvalueCtSsObviously, the higher the frequency of a candi-date term the greater its termhood.
The same holdsfor its length.
On the other side, the more fre-quently the candidate term is nested in other termcandidates, the more its termhood is reduced.However, this reduction decreases with the in-crease in the number of different host candidateterms as it is hypothesised that the candidate termis more independent if the set of its host terms ismore versatile.Term distribution in top-ranked candidate termsis further improved by taking into account theircontext.
The relevant context words, includingnouns, verbs and adjectives, are extracted and as-signed weights based on how frequently they co-occur with top-ranked term candidates.
Subse-quently, context factors are assigned to candidateterms according to their co-occurrence with top-ranked context words.
Finally, new termhood esti-mations (NC-values) are calculated as a linearcombination of the C-values and context factors.Nenadic et al (2003a) modified the C/NC-valueto recognise acronyms as a special type of single-word terms, and, thus, enhanced the recall of themethod.
On the other hand, the modified versionincorporates the unification of term variants intothe linguistic part of the method, which also im-proved the precision, since the statistical analysis ismore reliable when performed over classes ofequivalent term variants instead of separate terms.3.2   Domain-Specific Verb RecognitionVerbs are extracted from the corpus and rankedbased on the frequency of occurrence and the fre-quency of their co-occurrence with terms.
A stoplist of general verbs frequently mentioned in scien-tific papers independently of the domain (e.g.
ob-serve, explain, etc.)
was used to filter out suchverbs.
The top ranked verbs are selected andconsidered to be domain-specific.
Moreover, theseverbs are also corpus-specific (e.g.
activate,bind, etc.).
Table 3 provides a list of such verbs,which were used in the experiments.3.3   Complementation Pattern LearningIn order to learn a verb complementation patternfor each of the selected verbs separately, terms arecollected from the corpus by using these verbs asanchors.
A GA has been implemented as an itera-tive reasoning procedure based on a partial orderrelation induced by the domain-specific ontology.1In each iteration pairs of verb complementationpatterns represented as sets of terms and termclasses are merged.
This operation involves thesubstitution of less general terms/classes by theirmore general counterparts, if there is a path in theontology connecting them.
Otherwise, the disjunc-tion of the terms is formed and passed to the nextiteration.
Figure 1 depicts the process of learning averb complementation pattern.Since the partial order relation induced by theontology is transitive, the order in which terms areprocessed is of no importance.
The final verb com-plementation patterns are minimal in the sense thatthe number of terms in a verb complementationpattern and the depth of each individual term in theontology are minimised.Figure 1.
Learning the complementation patternfor the verb bind4 Term Classification MethodThe verb complementation patterns have been ob-tained by running the GA on a set of terms some ofwhich were present in an ontology, which is used1 The partial order relation is based on the hierarchy ofterms/classes: term/class t1 is in relation with t2, if there is apath in the ontology from t2 to t1.
In that case, we say that t2  ismore general than t1.during the learning process.
The newly recognisedterms (i.e.
the ones not found in the ontology) willremain included in the final verb complementationpatterns as non-classified terms, since at this pointit is not known which classes could replace them.All elements of the final verb complementationpatterns can be thus divided into two groups basedon the criterion of their (non)existence in the on-tology.
The elements already present in the ontol-ogy are candidate classes for the newly recognisedterms.
Let us now describe the classificationmethod in more detail.Let V = {v1, v2, ... , vn} be a set of automaticallyidentified domain-specific verbs.
During the phaseof learning verb complementation patterns, each ofthese verbs is associated with a set of classes andterms it co-occurs with.
Let Ci = {ci,1, ci,2, ... , ci,mi}denote a set of classes assigned automatically tothe verb vi (1 ?
i ?
n) by a learning algorithm basedon the information found in the corpus and thetraining ontology.
As indicated earlier, we definesuch set to be a verb complementation pattern forthe given verb.4.1   Statistical AnalysisAs we planned to use verb complementation pat-terns for term classification, we modified the origi-nal learning algorithm (Spasic et al, 2002) byattaching the frequency information to terms andtheir classes.
When substituting a less general classby its more general counterpart, 2  the frequencyinformation is updated by summing the tworespective frequencies of occurrence.
In the finalverb complementation pattern, each class ci,j hasthe frequency feature fi,j, which aggregates the fre-quency of co-occurrence with vi (1 ?
i ?
n; 1 ?
j ?mi) for the given class and its subclasses.
The fre-quency information is used to estimate the classprobabilities given a verb, P(ci,j | vi):?==lmllijijiffp1,,,2 The ontology used for learning allowed multiple inheritanceonly at the leaf level, that way incurring no ambiguities whensubstituting subclass by its superclass.
The multiple inheri-tance at the leaf level was resolved by mapping each term toall its classes, which were then processed by a GA.Unclassified terms remain present in the finalverb complementation patterns, and, like classes,they are also assigned the information on the fre-quency of co-occurrence with the given verb.When classifying a specific term, this informationis used to select the verb based on whose patternthe term will be classified.
Precisely, the verb thegiven term most frequently co-occurs with is cho-sen, as it is believed to be the most indicative onefor the classification purpose.4.2   Term Similarity MeasureA complementation pattern associated with thechosen verb typically contain several classes.
Inorder to link the newly recognised terms to specificcandidate classes, we used a hybrid term similaritymeasure, called the CLS similarity measure.
Itcombines contextual, lexical and syntactic proper-ties of terms in order to estimate their similarity(Nenadic et al, 2002).Lexical properties used in the CLS measure re-fer to constituents shared by the compared terms.The rationale behind the lexical term similarityinvolves the following hypotheses: (1) Terms shar-ing a head are likely to be hyponyms of the sameterm (e.g.
progesterone receptor and oes-trogen receptor).
(2) A term derived by modi-fying another term is likely to be its hyponym (e.g.nuclear receptor and orphan nuclear re-ceptor).
Counting the number of common con-stituents is a simple and straightforward approachto measuring term similarity, but it falls short whenit comes to single-word terms and those introducedin an ad-hoc manner.
Thus, properties other thanlexical need to be included.We use syntactic properties in the form of spe-cific lexico-syntactical patterns indicating parallelusage of terms (e.g.
both Term and Term).
Allterms used within a parallel structure have identi-cal syntactic features and are used in combinationwith the same verb, preposition, etc., and, hence,can be regarded as similar with high precision.However, patterns used as syntactic properties ofterms have relatively low frequency of occurrencecompared to the total number of terms, and in or-der to have a good recall, a large-size corpus isneeded.
In order to remedy for small-size corpora,other contextual features are exploited.Context patterns (CPs) in which terms appearare used as additional features for term compari-son.
CPs consist of the syntactic categories andother grammatical and lexical information (e.g.PREP NP V:stimulate).
They are ranked ac-cording to a measure called CP-value  (analogue toC-value for ATR).
The ones whose CP-value isabove a chosen threshold are deemed significantand are used to compare terms.
Each term is asso-ciated with a set of its CPs, and contextual similar-ity between terms is then measured by comparingthe corresponding sets.
Automatically collectedCPs are indeed domain-specific, but the method fortheir extraction is domain independent.4.3   Term-Class SimilarityThe CLS similarity measure applies to pairs ofterms.
However, in case of multiple choices pro-vided by the verb complementation patterns, weneed to compare terms to classes.
In order to do so,we use the similarity between the given term andthe terms belonging to the classes.
The selection ofterms to be compared is another issue.
One possi-bility is to use the full or random set of terms (be-longing to the given class) that occur in the corpus.Alternatively, some ontologies provide a set ofprototypical instances for each class, which can beused for comparison of terms and classes.3 Moreformally, if c is a class, e1, e2,..., ek are terms repre-senting the class, and t is a term, then the similaritybetween the term t and the class c is calculated inthe following way:?=?=kjjikietCLSetCLSctEx12},...,1{),(),(max),(This example-based similarity measure maxi-mises the value of the CLS measure between theterm and the instances representing the class.
Inaddition, the values of the CLS measure aremapped into the interval (0,1) by performing vec-tor normalisation in order to make them compara-ble to the class probability estimations.4.4   Term ClassificationFinally, given the term t and the verb vi it mostfrequently co-occurs with, a score is calculated for3 For example, in the UMLS ontology each class is assigned anumber of its prototypical examples represented by terms.each class ci,j from the set Ci according to the fol-lowing formula:),()1(),( ,,, jijiji ctExapactC ?
?+?=    (1)where a (0 ?
a ?
1) is a parameter, which balancesthe impact of the class probabilities and the simi-larity measure.4 A class with the highest C(t, ci,j)score is used to classify the term t. Alternatively,multiple classes may be suggested by setting athreshold for C(t, ci,j).At this point, let us reiterate that the final verbcomplementation patterns are minimal in the sensethat the number of terms in a verb complementa-tion pattern and the depth of each individual termin the ontology are minimised.
The latter conditionmay cause the classification to be crude, that is ?new terms will be assigned to classes close to theroot of the ontology.
For more fine-grained classi-fication results, the classes placed close to the rootof the ontology should be either removed from theinitial verb complementation patterns, thus beingunable to override the classes found lower in thehierarchy or in other way prevented from substitut-ing less general terms.
The depth up to which theterms are to be blocked may be empirically deter-mined.5 Experiments and Evaluation5.1   ResourcesThe resources used for the experiments include anontology and a corpus, both belonging to the do-main of biomedicine.
We used an ontology, whichis a part of the UMLS (Unified Medical LanguageSystem) knowledge sources (UMLS, 2002).UMLS integrates biomedical information from avariety of sources and is regularly updated.Knowledge sources maintained under the UMLSproject include: METATHESAURUS linking termvariants referring to the same concepts;SPECIALIST LEXICON providing syntactic informa-tion for terms, their component words, and general4 Note that when a = 0, the classification method resemblesthe nearest neighbour classification method, where the exam-ples are used as a training set.
On the other hand, when a = 1,the method is similar to naive Bayesian learning.
However, inboth cases the method represents a modification of the men-tioned approaches, as the classes used in formula (1) are notall classes, but the ones learned by the GA.English words; and SEMANTIC NETWORK contain-ing information about the classes to which allMETATHESAURUS concepts have been assigned.The knowledge sources used in our term classi-fication experiments include METATHESAURUSand SEMANTIC NETWORK.
As the number of termsin  METATHESAURUS was too large (2.10 millionterms) and the classification scheme too broad(135 classes) for the preliminary experiments, wemade a decision to focus only on terms belongingto a subtree of the global hierarchy of theSEMANTIC NETWORK.
The root of this subtree re-fers to substances, and it contains 28 classes.The corpus used in conjunction with the aboveontology consisted of 2082 abstracts on nuclearreceptors retrieved from the MEDLINE database(MEDLINE, 2003).
The majority of terms found inthe corpus were related to nuclear receptors andother types of biological substances, as well as thedomain-specific verbs extracted automaticallyfrom the corpus in the way described in Section 3.5.2   Evaluation FrameworkWhen retrieving terms found in the context of do-main-specific verbs (see Section 3 for details) bothterms found in the ontology and terms recognisedon the fly by the C/NC-value method should beextracted.
However, for the purpose of evaluation,only terms classified in the ontology were used.
Inthat case, it was possible to automatically verifywhether such terms were correctly classified bycomparing the classes suggested by the classifica-tion method to the original classification informa-tion found in the ontology.During the phase of retrieving the verb-termcombinations, some of the terms were singled outfor testing.
Namely, for each verb, 10% of the re-trieved terms were randomly selected for testing,and the union of all such terms formed a testing set(138 terms) for the classification task.
The remain-ing terms constituted a training set (1618 terms)and were used for the learning of complementationpatterns.5.3   ResultsBased on the training set, domain-specific verbswere associated with the complementation patternsgiven (see Table 1 for examples).
Then, each termfrom the training set was associated with the verbit most frequently co-occurred with.
The comple-mentation pattern learnt for that verb was used toclassify the term in question.Verb Complementation patternactivatebindImmunologic FactorReceptorEnzymeHormoneOrganic ChemicalHazardous or Poisonous SubstancePharmacologic SubstanceTable 1.
Learnt verb complementation patternsSince the UMLS ontology contains a number ofprototypical examples for each class, we have usedthese class representatives to compare unclassifiedterms to their potential classes as indicated in Sec-tion 4.
Table 2 shows the results for some of theterms from the testing set and compares them tothe correct classifications obtained from the ontol-ogy.Term SuggestedclassCorrect classes4 hydroxy-tamoxifenOrganicchemical Organic chemicalbenzoicacidOrganicchemicalOrganic chemicalPharmacologicsubstancetestoster-onePharmacologicsubstanceSteroidPharmacologicsubstanceHormoneTable 2.
Examples of the classification resultsNote that in UMLS one term can be assigned tomultiple classes.
We regarded a testing term to becorrectly classified if the automatically suggestedclass was among these classes.
Table 3 providesinformation on the performance of the classifica-tion method for each of the considered verbs sepa-rately and for the combined approach in which theverb most frequently co-occurring with a giventerm was used for its classification.
The combinedapproach provided considerably higher recall(around 50%) and a slight improvement in preci-sion (around 64%) compared to average valuesobtained with the same method for each of theverbs separately.
The classification precision didnot tend to very considerably, and was not affectedby the recall values.
The recall could be improvedby taking into account more domain-specific verbs,while the improvement of precision depends onproper tuning of: (1) the module for learning theverb complementation patterns, and (2) the similar-ity measure used for the classification.
Anotherpossibility is to generalize the classificationmethod by relying on domain-specific lexico-syntactic patterns instead of verbs.
Such patternswould have higher discriminative power than verbsalone.
Moreover, they could be acquired automati-cally.
For instance, the CP-value method can beused for their extraction from a corpus (Nenadic etal., 2003a).Verb Recall Precision F-measureactivate 19.28 66.59 29.90bind 29.30 66.53 40.68compete   3.58 63.16   6.78conserve   2.41 61.82   4.64inhibit 16.62 62.81 26.28interact 13.16 64.31 21.85mediate 11.68 62.75 19.69modulate 10.44 64.13 17.96repress   6.18 62.91 11.25stimulate   9.39 63.25 16.35Average: 12.20 63.83 20.48Combined: 49.88 64.18 56.13Table 3.
The performance of the classificationmethodThe values for precision and recall provided inTable 3 refer to the classification method itself.
Ifit were to be used for the automatic ontology up-date, then the success rate of such update wouldalso depend on the performance of the term recog-nition method, as the classification module wouldoperate on its output.
We used the C/NC-valuemethod for ATR; still any other method may beused for this purpose.
We have chosen the C/NC-value method because it is constantly improvingand is currently performing around 72% recall and98% precision (Nenadic et al, 2002).6 ConclusionEfficient update of the existing knowledge re-positories in many rapidly expanding domains is aburning issue.
Due to an enormous number ofterms and the complex structure of the terminol-ogy, manual update approaches are prone to beboth inefficient and inconsistent.
Thus, it has be-come absolutely essential to implement efficientand reliable term recognition and term classifica-tion methods as means of maintaining the knowl-edge repositories.
In this paper, we have suggesteda domain independent classification method as away of incorporating automatically recognisedterms into an existing ontology.
For the prelimi-nary experiments, we used the UMLS ontology inthe domain of biomedicine, but the method can beeasily adapted to use other ontologies in any otherdomain.The classification method makes use of thecontextual information.
Not all word types foundin the context are of equal importance in theprocess of reasoning about the terms: the most in-formative are verbs, noun phrases (especiallyterms) and adjectives.
The presented termclassification approach revolves around domain-specific verbs.
These verbs are used to collectunclassified terms and to suggest their potentialclasses based on the automatically learnt verbcomplementation patterns.Note that not every term appearing in a corpusis guaranteed to be classified by the proposed clas-sification method due to the fact that a term neednot occur as a complement of a domain-specificverb.
Still, for a large number of terms the classifi-cation method is expected to obtain the classifica-tion information, as it is highly probable (thoughnot certain) for a term to occur in a context of adomain-specific verb.
The main goal of the methodis to provide aid for the automatic ontology updateby populating newly recognised terms into an ex-isting ontology, rather than classifying arbitraryterm occurrences in the corpus.The presented classification method can be eas-ily modified to use lexical classes other than verbsas a criterion for classification.
Even more, it canbe further generalised to use a combination of lexi-cal classes, which can be specified as a set oflexico-syntactic patterns.
Further experiments withthe generalisation of the classification method bybasing it on a set of domain-specific lexico-syntactic patterns instead of domain-specific verbsare expected to demonstrate better performance interms of recall and precision.
These facts suggestthat our classification approach, in combinationwith the C/NC-value method, could be reliablyused as a (semi)automatic ontology maintenanceprocedure.ReferencesNigel Collier, Chikashi Nobata and Junichi Tsujii.
2001.Automatic Acquisition and Classification of Termi-nology Using a Tagged Corpus in the Molecular Bi-ology Domain.
Journal of Terminology, JohnBenjamins.Katerina Frantzi, Sophia Ananiadou and Hideki Mima.2000.
Automatic Recognition of Multi-Word Terms:the C-value/NC-value Method.
International Journalon Digital Libraries 3(2):115-130.Vasileios Hatzivassiloglou, Pablo Duboue and AndreyRzhetsky.
2001.
Disambiguating Proteins, Genes,and RNA in Text: A Machine Learning Approach.Bioinformatics, 1(1):1-10.Diana Maynard and Sophia Ananiadou.
2000.
Identify-ing Terms by their Family and Friends.
Proceedingsof COLING 2000, Saarbrucken, Germany, 530-536.MEDLINE.
2003.
National Library of Medicine.
Avail-able at: http://www.ncbi.nlm.nih.gov/PubMed/Goran Nenadic, Irena Spasic and Sophia Ananiadou.2002.
Automatic Acronym Acquisition and TermVariation Management within Domain-SpecificTexts.
Proceedings of LREC-3, Las Palmas, Spain,2155-2162.Goran Nenadic, Irena Spasic and Sophia Ananiadou.2003a.
Automatic Discovery of Term Similarities Us-ing Pattern Mining.
To appear in Terminology.Goran Nenadic, Simon Rice, Irena Spasic, SophiaAnaniadou and Benjamin Stapley.
2003b.
SelectingFeatures for Text-Based Classification: from Docu-ments to Terms.
Proceedings of ACL Workshop onNatural Language Processing in Biomedicine,Sapporo, Japan.Chikashi Nobata, Nigel Collier and Junichi Tsujii.
2000.Automatic Term Identification and Classification inBiology Texts.
Proceedings of the Natural LanguagePacific Rim Symposium (NLPRS?2000), 369-375.Irena Spasic, Goran Nenadic and Sophia Ananiadou.2002.
Tuning Context Features with Genetic Algo-rithms.
Proceedings of 3rd International Conferenceon Language,  Resources and Evaluation, Las Pal-mas, Spain, 2048-2054.UMLS.
2002.
UMLS Knowledge Sources.
NationalLibrary of Medicine, 13th edition.
