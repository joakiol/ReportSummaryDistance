Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 18?22,Baltimore, Maryland, USA, June 26, 2014.c?2014 Association for Computational LinguisticsFact Checking: Task definition and dataset constructionAndreas VlachosDept.
of Computer ScienceUniversity College LondonLondon, United Kingdoma.vlachos@cs.ucl.ac.ukSebastian RiedelDept.
of Computer ScienceUniversity College LondonLondon, United Kingdoms.riedel@ucl.ac.ukAbstractIn this paper we introduce the task of factchecking, i.e.
the assessment of the truth-fulness of a claim.
The task is commonlyperformed manually by journalists verify-ing the claims made by public figures.
Fur-thermore, ordinary citizens need to assessthe truthfulness of the increasing volumeof statements they consume.
Thus, de-veloping fact checking systems is likelyto be of use to various members of soci-ety.
We first define the task and detail theconstruction of a publicly available datasetusing statements fact-checked by journal-ists available online.
Then, we discussbaseline approaches for the task and thechallenges that need to be addressed.
Fi-nally, we discuss how fact checking relatesto mainstream natural language processingtasks and can stimulate further research.1 MotivationFact checking is the task of assessing the truth-fulness of claims made by public figures suchas politicians, pundits, etc.
It is commonly per-formed by journalists employed by news organisa-tions in the process of news article creation.
Morerecently, institutes and websites dedicated to thiscause have emerged such as Full Fact1and Politi-Fact2respectively.
Figure 1 shows two examplesof fact checked statements, together with the ver-dicts offered by the journalists.Fact-checking is a time-consuming process.
Inassessing the first claim in Figure 1 a journalistwould need to consult a variety of sources to find1http://fullfact.org2http://politifact.comthe average ?full-time earnings?
for criminal bar-risters.
Fact checking websites commonly providethe detailed analysis (not shown in the figure) per-formed to support the verdict.Automating the process of fact checking has re-cently been discussed in the context of computa-tional journalism (Cohen et al., 2011; Flew et al.,2012).
Inspired by the recent progress in naturallanguage processing, databases and informationretrieval, the vision is to provide journalists withtools that would allow them to perform this taskautomatically, or even render the articles ?live?
byupdating them with most current data.
This au-tomation is further enabled by the increasing on-line availability of datasets, survey results, and re-ports in machine readable formats by various insti-tutions, e.g.
EUROSTAT releases detailed statis-tics for all European economies.3Furthermore, ordinary citizens need to factcheck the information provided to them.
This needis intensified with the proliferation of social mediasuch as Twitter, since the dissemination of newsand information commonly circumvents the tra-ditional news channels (Petrovic, 2013).
In addi-tion, the rise of citizen journalism (Goode, 2009)suggests that often citizens become the sourcesof information.
Since the information providedby them is not edited or curated, automated factchecking would assist in avoiding the spreadingfalse information.In this paper we define the task of fact-checking.We then detail the construction of a dataset usingfact-checked statements available online.
Finally,we describe the challenges it poses and its relationto current research in natural language processing.3http://epp.eurostat.ec.europa.eu/portal/page/portal/eurostat/home182 Task definitionWe define fact-checking to be the assignment of atruth value to a claim made in a particular con-text.
Thus it is natural to consider it as a bi-nary classification task.
However, it is often thecase that the statements are not completely trueor false.
For example, the verdict for the thirdclaim in Figure 1 is MOSTLYTRUE because someof the sources dispute it, while in the fourth exam-ple the statistics can be manipulated to support ordisprove the claim as desired.
Therefore it is bet-ter to consider fact-checking as an ordinal classifi-cation task (Frank and Hall, 2001), thus allowingsystems to capture the nuances of the task.The verdict by itself, even if graded, needs to besupported by an analysis (e.g., what is the systemsinterpretation of the statement).
However, giventhe difficulty of carving out exactly what the cor-rect analysis for a statement might be, we restrictthe task to be a prediction problem so that we canevaluate performance automatically.Context can be crucial in fact-checking.
For ex-ample, knowing that the fourth claim of Figure 1is made by a UK politician is necessary in orderto assess it using data about this country.
Fur-thermore, time is also important since the vari-ous comparisons usually refer to time-frames an-chored at the time a claim is made.The task is rather challenging.
While someclaims such as the one about Crimea can be fact-checked by extracting relations from WikiPedia,the verdict often hinges on interpreting relativelyfine points, e.g.
the last claim refers to a partic-ular definition of income.
Journalists also checkmultiple sources in producing their verdicts, as inthe case of the third claim.
Interestingly, they alsoconsider multiple interpretations of the data; e.g.in the last claim is assessed as HALFTRUE sincedifferent but reasonable interpretations of the samedata lead to different conclusions.We consider all of the aspects mentioned (time,speaker, multiple sources and interpretations) aspart of the task of fact checking.
However, wewant to restrict the task to statements that can befact-checked objectively, which is not always truefor the statements assessed by journalists.
There-fore, we do not consider statements such as ?NewLabour promised social improvement but deliv-ered a collapse in social mobility?
to be part tothe task since there are no universal definitions of?social improvement?
and ?social mobility?.44http://blogs.channel4.com/factcheck/factcheck-social-mobility-collapsed/Claim (by Minister Shailesh Vara)?The average criminal bar barrister working full-time is earning some ?84,000.
?Verdict: FALSE (by Channel 4 Fact Check)The figures the Ministry of Justice have stressedthis week seem decidedly dodgy.
Even if you dowant to use the figures, once you take away themany overheads self-employed advocates have topay you are left with a middling sum of money.Claim (by U.S. Rep. Mike Rogers)?Crimea was part of Russia until 1954, when itwas given to the Soviet Republic of the Ukraine.
?Verdict: TRUE (by Politifact)Rogers said Crimea belonged to Russia until1954, when Khrushchev gave the land toUkraine, then a Soviet republic.Claim (by President Barack Obama)?For the first time in over a decade, businessleaders around the world have declared thatChina is no longer the world?s No.
1 place toinvest; America is.
?Verdict: MOSTLYTRUE (by Politifact)The president is accurate by citing one particularstudy, and that study did ask business leaderswhat they thought about investing in the UnitedStates.
A broader look at other rankings doesn?tmake the United States seem like such a power-house, even if it does still best China in some lists.Claim (by Chancellor George Osborne)?Real household disposable income is rising.
?Verdict: HALFTRUE (by Channel 4 Fact Check)RHDI did grow in latest period we know about(the second quarter of 2013), making Mr Osbornearguably right to say that it is rising as we speak.But over the last two quarters we know about,income was down 0.1 per cent.
If you want tocompare the latest four quarters of data with theprevious four, there was a fall in householdincome, making the chancellor wrong.
But ifyou compare the latest full year of results, 2012,with 2011, income is up and he?s right again.Figure 1: Fact-checked statements.193 Dataset constructionIn order to construct a dataset to develop and eval-uate approaches to fact checking, we first surveyedpopular fact checking websites.
We decided toconsider statements from two of them, the factchecking blog of Channel 45and the Truth-O-Meter from PolitiFact.6Both websites have largearchives of fact-checked statements (more than1,000 statements each), they cover a wide range ofprevalent issues of U.K. and U.S. public life, andthey provide detailed verdicts with fine-grained la-bels such as MOSTLYFALSE and HALFTRUE.We examined recent fact-checks from eachwebsite at the time of writing.
For each state-ment, apart from the statement itself, we recordedthe date it was made, the speaker, the label ofthe verdict and the URL.
As the two websitesuse different labelling schemes, we aligned the la-bels of the verdicts to a five-point scale: TRUE,MOSTLYTRUE, HALFTRUE, MOSTLYFALSE andFALSE.
The speakers included, apart from pub-lic figures, associations such as the American Bev-erage Association, activists, even viral FaceBookposts submitted by the public.We then decided which of the statements shouldbe considered for the task proposed.
As discussedin the previous section we want to avoid state-ments that cannot be assessed objectively.
Follow-ing this, we deemed unsuitable statements:?
assessing causal relations, e.g.
whether astatistic should be attributed to a particular law?
concerning the future, e.g.
speculations involv-ing oil prices?
not concerning facts, e.g.
whether a politicianis supporting certain policiesFor the statements that were considered suit-able, we also collected the sources used by thejournalists in the analysis provided for the verdict.Common sources include tables with statistics andreports from governments, think tanks and otherorganisations, available online.
Automatic identi-fication of the sources needed to fact check a state-ment is an important stage in the process, which ispotentially useful in its own right in the contextof assisting journalists in a semi-automated fact-checking approach Cohen et al.
(2011).
Some-164445http://blogs.channel4.com/factcheck/6http://www.politifact.com/truth-o-meter/statements/times the verdicts relied on data that were notavailable online such personal communications;statements whose verdict relied on such data werealso deemed unsuitable for the task.As mentioned earlier, the verdicts on the web-sites are accompanied by lengthy analyses.
Whilesuch analyses could be useful annotation for in-termediate stages of the task ?
e.g.
we could useit as supervision to learn how to combine the in-formation extracted from the various sources intoa verdict ?
we noticed that the language used inthem is indicative of the verdict.7Thus we decidednot to include them in the dataset, as it would en-able tackling part of the task as sentiment analy-sis.
Out of the 221 fact-checked statements exam-ined, we judged 106 as suitable.
The dataset col-lected including our suitability judgements is pub-licly available8and we are working on extendingit so that it can support the development and theautomatic evaluation of fact checking approaches.4 Baseline approachesAs discussed in Section 2, we consider fact check-ing as an ordinal classification task.
Thus, in the-ory it would be possible to tackle it as a supervisedclassification task using algorithms that learn fromstatements annotated with the verdict labels.
How-ever this is unlikely to be successful, since state-ments such as the ones verified by journalists donot contain the world knowledge and the temporaland spatial context needed for this purpose.A different approach would be to match state-ments to ones already fact-checked by journalistsand return the label in a K-nearest neighbour fash-ion.9Thus the task is reduced to assessing the se-mantic similarity between statements, which wasexplored in a recent shared task (Agirre et al.,2013).
An obvious shortcoming of this approachis that it cannot be applied to new claims that havenot been fact-checked, thus it can only be used todetect repetitions and paraphrases of false claims.A possible mechanism to extend the coverage ofsuch an approach to novel statements is to assumethat some large text collection is the source of alltrue statements.
For example, Wikipedia is likely7E.g.
part of the analysis of the first claim in Figure 1reads: ?the full-time figure has the handy effect of strippingout the very lowest earners and bumping up the average?.8https://sites.google.com/site/andreasvlachos/resources9The Truth-Teller by Washington Post (http://truthteller.washingtonpost.com/) follows thisapproach.20to contain a statement that would match the sec-ond claim in Figure 1.
However, it would still beunable to tackle the other claims mentioned, sincethey require calculations based on the data.5 DiscussionThe main drawback of the baseline approachesmentioned (aside from their potential coverage) isthe lack of interpretability of their verdicts, also re-ferred to as algorithmic accountability (Diakopou-los, 2014).
While it is possible for a natural lan-guage processing expert to inspect aspects of theprediction such as feature weights, this tends tobecome harder as the approaches become more so-phisticated.
Ultimately, the user of a fact checkingsystem would trust a verdict only if it is accom-panied by an analysis similar to the one providedby the journalists.
This desideratum is present inother tasks such as the recently proposed sciencetest question answering (Clark et al., 2013).Cohen et al.
(2011) propose that fact checkingis about asking the right questions.
These ques-tions might be database queries, requests for in-formation to be extracted from textual resources,etc.
For example, in checking the last claim in Fig-ure 1 a critical reader would like to know what arethe possible interpretations of ?real household dis-posable income?
and what the calculations mightbe for other reasonable time spans.The manual fact checking process suggests anapproach that is more likely to give an inter-pretable analysis and would decompose the taskinto the following stages:1. extract statements to be fact-checked2.
construct appropriate questions3.
obtain the answers from relevant sources4.
reach a verdict using these answersThe stages of this architecture can be mappedto tasks well-explored in the natural language pro-cessing community.
Statement extraction couldbe tackled as a sentence classification problem,following approaches similar to those proposedfor speculation detection (Farkas et al., 2010) andveridicality assessment (de Marneffe et al., 2012).Furthermore, obtaining answers to questions fromdatabases is a task typically addressed in the con-text of semantic parsing research, while obtainingsuch answers from textual sources is usually con-sidered in the context of information extraction.Finally, the compilation of the answers into a ver-dict could be considered as a form of logic-basedtextual entailment (Bos and Markert, 2005).However, the fact-checking stages described in-clude a novel task, namely question construc-tion for a given statement.
This task is likelyto rely on semantic parsing of the statement fol-lowed by restructuring of the logical form gener-ated.
Since question construction is a rather un-common task, it is likely to require human supervi-sion, which could possibly be obtained via crowd-sourcing.
Furthermore, the open-domain nature offact checking places greater demands on the estab-lished tasks of information extraction and seman-tic parsing.
Thus, fact-checking is likely to stim-ulate research in these tasks on methods that donot require domain-specific supervision (Riedel etal., 2013) and are able to adapt to new informationrequests (Kwiatkowski et al., 2013).Fact-checking is related to the tasks of textualentailment (Dagan et al., 2006) and machine com-prehension (Richardson et al., 2013), with the dif-ference that the text which should be used to pre-dict the entailment of the hypothesis or the correctanswer respectively is not provided in the input.Instead, systems need to locate the sources neededto predict the verdict label as part of the task.
Fur-thermore, by defining the task in the context ofreal-world journalism we are able to obtain labeledstatements at no annotation cost, apart from the as-sessment of their suitability for the task.6 ConclusionsIn this paper we introduced the task of fact check-ing and detailed the construction of a dataset us-ing statements fact-checked by journalists avail-able online.
In addition, we discussed baseline ap-proaches that could be applied to perform the taskand the challenges that need to be addressed.Apart from being a challenging testbed to stim-ulate progress in natural language processing, re-search in fact checking is likely to inhibit the in-tentional or unintentional dissemination of falseinformation.
Even an approach that would returnthe sources related to a statement could be veryhelpful to journalists as well as other critical read-ers in a semi-automated fact checking approach.AcknowledgmentsThe authors would like to thank the members ofthe Machine Reading lab for useful discussions21and their help in compiling the dataset.ReferencesEneko Agirre, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, and Weiwei Guo.
2013.
*sem 2013 sharedtask: Semantic textual similarity.
In Proceedings ofthe Second Joint Conference on Lexical and Compu-tational Semantics and the Shared Task: SemanticTextual Similarity, pages 32?43, Atlanta, GA.Johan Bos and Katja Markert.
2005.
Recognising tex-tual entailment with logical inference.
In Proceed-ings of the 2005 Conference on Empirical Methodsin Natural Language Processing (EMNLP 2005),pages 628?635.Peter Clark, Philip Harrison, and Niranjan Balasubra-manian.
2013.
A study of the knowledge base re-quirements for passing an elementary science test.In Proceedings of the 2013 Workshop on AutomatedKnowledge Base Construction, pages 37?42.Sarah Cohen, Chengkai Li, Jun Yang, and Cong Yu.2011.
Computational journalism: A call to arms todatabase researchers.
In Proceedings of the Confer-ence on Innovative Data Systems Research, volume2011, pages 148?151.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The pascal recognising textual entailmentchallenge.
In Proceedings of the First InternationalConference on Machine Learning Challenges: Eval-uating Predictive Uncertainty Visual Object Classi-fication, and Recognizing Textual Entailment, pages177?190.Marie-Catherine de Marneffe, Christopher D. Man-ning, and Christopher Potts.
2012.
Did it happen?the pragmatic complexity of veridicality assessment.Computational Linguistics, 38(2):301?333, June.Nick Diakopoulos.
2014.
Algorithmic accountabil-ity reporting: On the investigation of black boxes.Technical report, Tow Center for Digital Journalism.Richard Farkas, Veronika Vincze, Gyorgy Mora, JanosCsirik, and Gyorgy Szarvas.
2010.
The CoNLL2010 Shared Task: Learning to Detect Hedges andtheir Scope in Natural Language Text.
In Proceed-ings of the CoNLL 2010 Shared Task.Terry Flew, Anna Daniel, and Christina L. Spurgeon.2012.
The promise of computational journalism.In Proceedings of the Australian and New ZealandCommunication Association Conference, pages 1?19.Eibe Frank and Mark Hall.
2001.
A simple approachto ordinal classification.
In Proceedings of the 12thEuropean Conference on Machine Learning, pages145?156.Luke Goode.
2009.
Social news, citizen journalismand democracy.
New Media & Society, 11(8):1287?1305.Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and LukeZettlemoyer.
2013.
Scaling semantic parsers withon-the-fly ontology matching.
In Proceedings ofthe 2013 Conference on Empirical Methods in Natu-ral Language Processing, pages 1545?1556, Seattle,WA.Sasa Petrovic.
2013.
Real-time event detection in mas-sive streams.
Ph.D. thesis, School of Informatics,University of Edinburgh.Matthew Richardson, Christopher J.C. Burges, andErin Renshaw.
2013.
MCTest: A challenge datasetfor the open-domain machine comprehension oftext.
In Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing,pages 193?203, Seattle, WA.Sebastian Riedel, Limin Yao, Benjamin M. Marlin,and Andrew McCallum.
2013.
Relation extractionwith matrix factorization and universal schemas.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Atlanta, GA.22
