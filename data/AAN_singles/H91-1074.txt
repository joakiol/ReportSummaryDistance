Predicting Intonational Boundaries Automatically from Text: TheATIS DomainMichelle Q. WangChurchill CollegeCambridge UniversityCambridge UKJulia HirschbergAT&T Bell Laboratories600 Mountain AvenueMurray Hill NJ 07974February 11, 1991AbstractRelating the intonational characteristics of an utter-ance to other features inferable from its text is impor-tant both for speech recognition and for speech syn-thesis.
This work investigates techniques for predictingthe location of intonational phrase boundaries in naturalspeech, through analyzing a utterances from the DARPAAir Travel Information Service database.
For statisticalmodeling, we employ Classification and Regression Tree(CART)  techniques.
We achieve success rates of  justover 90%.1 IntroductionIntuitively, intonational phrasing divides an utterance intomeaningful 'chunks' of information \[3\].
Variation in phrasingcan change the meaning hearers assign to tokens of a givensentence.
For example, 'Bi l l  doesn't drink because he% un-happy'  is likely to be interpreted one way when uttered asa single phrase (i.e., Bill drinks, but not because he's un-happy) and another when uttered with a boundary betweendrink and because (the cause of Bill's failure to drink is hisunhappiness).While phrase boundaries are perceptual categories, theyare associated with certain acoustic features.
Generally,phrases may be identified by one of more of the followingfeatures: pauses (which may be filled or not), changes in am-plitude and in the pitch contour, and lengthening of the finalsyllable in the phrase (sometimes accompanied by glottaliza-tion of that syUable and perhaps preceding syllables).
Majorphrase boundaries tend to be associated with longer pauses,more pronounced contour excursions, and greater amounts offinal lengthening than minor boundaries.2 Inferring Phrasing from TextHow the intonational phrasing of an utterance is related to as-pects of the text uttered is potentially an important source ofinformation for speech recognition, to constrain the set of al-lowable hypotheses by identifying boundary locations in boththe recognized text and the acoustic signal or to moderatedurational information at likely boundary locations.
How-ever, to date, syntactically-based prediction of intonationalboundaries has met with limited success.
While considerablework has been done on the relationship between some par-ticular syntactic onfigurations and intonational boundaries\[12, 2, 6, 9\], the prediction of boundaries in unrestricted andspontaneous speech rarely been attempted \[1\].
1 Predictingboundaries olely from information available automaticaLlyfrom text analysis presents a further challenge, which mustalso be addressed if predictions are to be useful in real spokenlanguage systems.To address these issues, we experimented with the pre-diction of intonational boundaries from text analysis, using298 utterances from 26 speakers in the Air Travel Informa-tion Service (ATIS) database for training and testing.
~ Toprepare data for analysis, we labeled the speech prosodicallyby hand, noting location and type of intonational boundariesand presence or absence of pitch accents, using both the wave-form and pitchtracks of each utterance.
Although major andminor boundaries were distinguished in the labeling process,in the analysis presented below these axe collapsed.
Eachdata point in our analysis consists of a potential boundarylocation in an utterance, defined by a pair of adjacent words< wi ,w  i >.
There are 3677 potential boundary locations< wi,wj > in the ATIS sample analyzed here.For each potential boundary site, we examine the predic-tive power of a number of textual features whose values canbe determined from orthographic transcriptions of the ATISsentences, as well as a number of phonological categories fea-tures available from our hand-labeling, to see, first, how wellboundary locations can be predicted automatically from text,l Bachenko and Fitzpatrick classify 83.5-86.2% of boundariescorrectly for a test set of 35 sentences; Ostendorf et alreport 80-8.3% correct prediction of boundaries only on a different 35 sentencetest set.
Altenberg models only major boundaries for a portion ofhis training data, 48 minutes of partly-read, partly spontaneousspeech from a single speaker,2These sentences were selected from the 772-odd utterances inthe original TI collection.378and, second, whether prediction using fuller information, cur-rently available only via hand-labeling, can improve perfor-mance significantly.Temporal variables used in the analysis include utteranceand phrase duration, and distance of the potential bound-ary from various strategic points in the utterance.
Althoughit is tempting to assume that phrase boundaries represent apurely intonational phenomenon, it is possible that process-ing constraints help govern their occurrence.
So, for example,longer utterances may tend to include more boundaries.
Ac-cordingly, we measure the length of each utterance both inseconds and in words.
The distance of the boundary site fromthe beginning and end of the utterance also appears likely tobe correlated with boundary location.
The tendency to enda phrase may also be affected by the position of the poten-tial boundary site in the utterance.
For example, positionsvery close to the beginning or end of an utterance may wellbe unlikely positions for intonational boundaries.
We mea-sure this variable too, both in seconds and in words.
Theimportance of phrase length has also been proposed \[6, 2\] asa factor in boundary location.
Simply put, it may be thatconsecutive phrases have roughly equal length.
To test this,we calculate the elapsed distance from the last boundary tothe potential boundary site, divided by the length of the lastphrase encountered, both in time and words.
To obtain thisinformation from text analysis alone would require us to fac-tor prior boundary predictions into subsequent predictions.While this would be feasible, it is not straightforward in ourcurrent analysis trategy.
To see whether this information isuseful, therefore, we currently use observed boundary loca-tion.Syntactic onstituency information is widely considered amajor factor in phrasing \[6, 14, 11, 15\].
That is, some types ofconstituents may be more or less likely to be broken up intophrases, and some constituent boundaries may be more or lesslikely to coincide with intonational boundaries.
To test theformer, we examine the class of the lowest node in the parsetree to dominate both wi  and wj, as determined by Hindle'sparser, Fidditch \[7\].
To test the latter we determine the classof the highest node in the parse tree to dominate wi ,  but notwj, and similarly for w i but not wi .
Word class is often usedto predict boundary location, particularly in text-to-speech,where simple parsing into function/content word groupingsgenerally controls the generation of phrase boundaries.
Totest the importance of word class, we examine part-of-speechin a window of four words surrounding each potential phrasebreak, using Church's part-of-speech tagger \[5\].Informal observation suggests that phrase boundaries aremore likely to occur in some PITCH ACCENT contexts thanin others.
For example, phrase boundaries between wordsthat are DEACCENTED seem to occur much less frequentlythan boundaries between two accented words.
To test this,we look at the pitch accent values of wi  and  w i for each< wl, wj >, comparing observed values with predicted pitchaccent information obtained from \[8\].Finally, in a multi-speaker database, an obvious vari-able to test is speaker identity.
While for applications tospeaker-independent recognition this variable would be unin-stantiable, we nonetheless need to determine how importantspeaker idiosyncracy may be in boundary location.
Since wehave found no significant increase in predictive power whenthis variable is used, results presented below are speaker-independent.3 Analysis and ResultsFor statistical modeling, we employ Classification and Re-gression Tree (CART) analysis \[4\] to generate decision treesfrom sets of continuous and discrete variables.
At each stagein growing the tree, CART determines which factor shouldgovern the forking of two paths from that node.
Further-more, CART must decide which values of the factor to as-sociate with each path.
Ideally, splitting rules should choosethe factor and value split which minimizes the prediction er-ror rate.
The rules in the implementation employed for thisstudy \[13\] approximate optimality by choosing at each nodethe split which minimizes the prediction error rate on thetraining data.
In this implementation, all these decisions arebinary, based upon consideration ofeach possible binary par-tition of values of categorical variables and consideration ofdifferent cut-points for values of continuous variables.Stopping rules terminate the splitting process at each in-ternal node.
To determine the best tree, this implementationuses two sets of stopping rules.
The first set is extremelyconservative, resulting in an overly large tree, which usuallylacks the generality necessary to account for data outside ofthe training set.
To compensate, the second rule set forms asequence of subtrees.
Each tree is grown on a sizable fraction(80%) of the training data and tested on the remaining por-tion.
This step is repeated until the tree has been grown andtested on all of the data.
The stopping rules thus have accessto cross-validated error rates for each subtree.
The subtreewith the lowest rates then defines the stopping points for eachpath in the full tree.
Results presented below all representcross-validated data.Prediction rules label label the terminal nodes.
For contin-uous variables, the rules calculate the mean of the data pointsclassified together at that node.
For categorical variables,the rules choose the class that occurs most frequently amongthe data points.
The success of these rules can be measuredthrough estimates of deviation.
In this implementation, thedeviation for continuous variables is the sum of the squarederror for the observations.
The deviation for categorical vari-ables is simply the number of misdassified observations.In analyzing our data, we employ four different sets of vari-ables.
The first includes observed phonological informationabout pitch accent and prior boundary location, as well asautomatically obtainable information.
The success rate ofboundary prediction from this set is quite high, with cor-rect cross-validated classification of 3330 out of 3677 poten-tial boundary sites - -  an overall success rate of 90% (Fig-ure 1).
Furthermore, there are only five decision points inthe tree.
Thus, the tree represents a dean, simple model ofphrase boundary prediction, assuming accurate phonologicalinformation.379Turning to the tree itself, we that the ratio of currentphrase length to prior phrase length is very important inboundary location.
This variable alone (assuming that theboundary site occurs before the end of the utterance) permitscorrect classification of 2403 out of 2556 potential bound-ary sites.
Occurrence of a phrase boundary thus appears ex-tremely unlikely in cases where its presence would result in aphrase less than half the length of the preceding phrase.
Thefirst and last decision points in the tree axe the most trivial.The first split indicates that utterances virtually always endwith a boundary - -  rather unsurprising news.
The last splitshows the importance of distance from the beginning of theutterance in boundaxy location; boundaries are more likelyto occur when more than 2 } seconds have elapsed from thestart of the utterance.
3 The third node in the tree indicatesthat noun phrases form a tightly bound intonational unit.The fourth split in 1 shows the role of accent context in de-termining phrase boundary location.
If wi is not accented,then it is unlikdy that a phrase boundary will occur after it.The importance of accent information in Figure 1 raisesthe question of whether or not automatically inferred accentinformation (via \[8\]) can substitute ffectively for observeddata.
In fact, when predicted accent information is substi-tuted, the success rate of the classification remains approx-imately the same, at 90%.
However, the number of splitsin the resultant tree increases - -  and fails to include the ac-centing of wi as a factor in the classification!
A look at theerrors in accent prediction in this domain reveals that the ma-jority occur when function words preceding a boundary areincorrectly predicted to be deaccented.
This appears to bean idiosyncracy of the corpus; such words generally occurredbefore relatively long pauses.
Nevertheless, classification suc-ceeds well in the absence of accent information, perhaps re-flecting a high correlation between predictors of accent andpredictors of phrase boundaries.
For example, both pitch ac-cent and boundary location are sensitive to location of priorintonational boundaries and part-of-speech ontext.In a third analysis, we eliminate the dynamic boundarypercentage measure.
The result remains nearly as good as be-fore, with a success rate of 89%.
This analysis reconfirms theusefulness of observed accent status of wi  in boundary pre-diction.
By itself (again assuming that the potential bound-ary site occurs before the end of the utterance), this factoraccounts for 1590 out of 1638 potential boundary site clas-sifications.
This analysis also confirms the strength of theintonational ties among the components of noun phrases.
Inthis tree, 536 out of 606 potential boundary sites receive finalclassification from this feature.We conclude our analysis by producing a classification treethat uses text-based information alone.
For this analysis weuse predicted accent values and omit information about priorboundary location.
Figure 2 shows results of this analysis,with a successful c assification of90% of the data.
In Figure 2,more variables are used to obtain a classification percentagesimilar to the previous classifications.
Here, accent predic-tions are used trivially, to indicate sentence-final boundaries3This fact may be idiosyncratic toour data, given the fact thatwe observed a trend towards initial hesitations.
(ra='NA'), a function performed in Figure 1 by distance ofpotential boundary site from end of utterance (et).
The sec-ond split in 2 does rely upon temporal distance - -  this time,distance of boundary site from the beginning of the utter-ance.
Together these measurements correctly predict 38.2eAof the data.
The classifier next uses a variable which has notappeared in earlier cla:.,sifications - -  the part-of-speech of tcj.In 2, in the majority of cases (88%) where w i is a functionword other than 'to,' "in,' or a conjunction (true for abouthalf of potential boundary sites), a boundary does not oc-cur.
Part-of-speech of u,i and type of constituent dominatingwi  but not tu~ are further used to classify these items.
Thisportion of the classification is reminiscent of the notion of'function word group" used commonly in assigning prosodyin text-to-speech, in which phrases are defined, roughly, fromone function word to the next.
Overall rate of the utter-ance and type of utterance appear in the tree, in additionto part-of-speech and constituency information, and distanceof potential boundary site from beginning and end of utter-ance.
In general, results of this first stage of analysis uggest- -  encouragingly - -  that there is considerable r dundancy inthe features predicting boundary location: when some fea-tures are unavailable, others can be used with similar ratesof success.4 DiscussionThe experiments described above indicate that it is indeedpossible to relate intonational boundaries to the text of anutterance with fair success, 4 using information available auto-matically using current NLP technology.
This application ofCART techniques to the problem of predicting phrase bound-aries increases our understanding of the importance ofseveralamong the numerous variables which might plausibly be re-lated to boundary location.
Future word wiLl extend the setof variables for analysis to include distance metrics definedin terms of stressed syllables, automatic NP-detection \[5\],MUTUAL INFORMATION, GENERALIZED MUTUAL LNFORMATIONscores can serve as indicators of intonational phrase bound-aries \[10\].
We will alto examine possible interactions amongthe statistically important variables which have emerged fromour initial study.
CART's step-wise treatment of variables,optimization heuristics, and dependence on binary splits ob-scure the possible relationships that exist among the variousfactors.
Now that we have discovered a set of variables whichdo well at predicting intonational boundary location, we needto understand just how these variables interact.While we have not yet attempted the parallel classifica-tion of boundary sites from acoustic information for the ATISsample, previous research \[12\] and our own preliminary anal-ysis of a a smaller set of training data collected for the VEST(Voice English-Spanish Translation) project, suggest hat in-4For purposes of comparison with classification efforts thatmeasure only success of boundary prediction (not success of non-boundary prediction as well), the best cross-validated predictionfrom the analyses done for this study has a 79.5% success rate andthe best prediction from a full tree classifies 89.7% correctly.380tonational boundaries can be identified with some successfrom simple measures of final lengthening (inferred from rel-ative word or syllable duration) and of pausal duration.
Forthe VEST data, for example, boundary location can be in-ferred correctly from such metrics in 92% of cases.
In futurework, these features, as well as amplitude and other potentialboundary indicators will be examined in the ATIS database.References\[1\] B. Altenberg.
Prosodic Patterns in Spoken English:Studies in the Correlation between Prosody and Gram-mar \]or Text-to-Speech Conversion, volume 76 of LundStudies in English.
Lund University Press, Lund, 1987.\[2\] J. Bachenko and E. Fitzpatrick.
A computational gram-mat of di..~course-neutral prosodic phrasing in English.Computational Linguistics, 1990.
To appear.\[3\] D. Bolinger.
Intonation and Its Uses: Melody in Gram-mar and Discourse.
Edward Arnold, London, 1989.\[4\] L. Brieman, J. H. Friedman, R. A. Olshen, and C. J.Stone.
Classification and Regression Trees.
Wadsworth& Brooks, Monterrey CA, 1984.\[5\] K. W. Church.
A stochastic parts program and nounphrase parser for unrestricted text.
In Proceedings of theSecond Conference on Applied Natural Language Pro-cessing, pages 136-143, Austin, 1988.
Association forComputational Linguistics.\[6\] J. P. Gee and F. Grosjean.
Performance structures: Apsychofinguistic and linguistic appraisal.
C~nitive Pslt-chology, 15:411-.458, 1983.\[7\] D. M. Hindle.
Acquiring disambiguation rules from text.In Proceedings ol the ?7th Annual Meeting, pages 118-125, Vancouver, 1989.
Association for ComputationalLinguistics.\[8\] J. Hirschberg.
Assigning pitch accent in syntheticspeech: The given/new distinction and deaccentability.In Proceedings of the Seventh National Conference, pages952-957, Boston, 1990.
American Assodation for Artifi-cial Intelligence.\[9\] I. Lehiste, J. Olive, and L. Streeter.
Role of durationin disambiguating syntactically ambiguous entences.Journal of the Acoustical Society of America, 60:1199-1202, 1976.\[10\] D. M. Magerman and M. P. Marcus.
Parsing a naturallanguage using mutual information statistics.
In Proceed.ings of AAAI.90, pages 984-989.
American Associationfor Artifical Intelligence, 1990.\[11\] M. P. Marcus and D. Hindle.
A computational ccountof extra categorial elements in japanese.
In Papers pre.seated at the First SDF Workshop in Japanese Syntax.System Development Foundation, 1985.\[12\] M. Ostendod, P. Price, J.
Bear, and C. W. Wightman.The use of relative duration in syntactic disambiguation.In Proceedings ol the DARPA Speech and Natural Lan-guage Workshop.
Morgan Kaufmann, June 1990.\[13\] M. D. Riley.
Some applications of tree-based modellingto speech and language.
In Proceedings.
DARPA Speechand Natural Language Workshop, October 1989.\[14\] E. Selkirk.
Phonology and Syntax.
MIT Press, Cam-bridge MA, 1984.\[15\] M. Steedman.
Structure and intonation in spoken lan-guage understanding.
In Proceedings o\] the 28th AnnualMeeting oi the Association .for Computational Linguis.tics, 1990.tttwstetSWewlarapertperutterance length in secondsutterance length in wordsseconds from start to w~seconds from wj to endwords from start to w,words from w~ to endis w, accented or not/cliticized, deaccented, accented, NAis w~ accented or not/cliticized, deaccented, accented, NA\[# words from last boundary\] /\[ # words in of last phrase\]\[ seconds from last boundary\] /\[seconds from last phrase\]jl-4 part-of-speech for wi-l, wi, wj, wj+ , :v:verb b:copula m:modifier f:function wordn:noun p:preposition w:wh-wordfs,l,r category of:s:smallest constituent dominating wi and wjl:largest constituent dominating w, not w ir:largest constituent dominating wj not tvim:modifier d:determiner v:verbp:preposition w:wh-word n:noun s:sentencef:function wordTable 1: Key to Node Labels in Figures381St:<11C 18NAet:<0.
: 151/198tr:<l tr.> I.~1265 ~<15/15nd/wh24/353D,VBN,VBZ, NAtr:<l8/8j~727/46 \ 82./12018 tr~,1.~71811/14 ~.
.
_ f l~S~ ~ .
;D,IN,NAFigure 2: Phrase Boundary Predictions from Text Analysis Alone, 90%382noet:<O.~4954e5~:>(I95455yes j297/298tper:<O ;01564 1564\[ no I2403/2556fsn:N,noP,Fno318/367nolano111/137st:<79455st:>2.~455nol61/81 157/238Figure 1: Phrase Boundary Predictions from Text and Observed Accents, 90%383
