Generated Narratives for Computer-aided Language TeachingMichael LEVISONSchool of ComputingQueen?s UniversityKingston, OntarioCanada K7L 3N6levison@cs.queensu.caGreg LESSARDFrench StudiesQueen?s UniversityKingston, OntarioCanada K7L 3N6lessardg@post.queensu.caAbstractVINCI is a Natural Language Generation envi-ronment designed for use in computer-aided sec-ond language instruction.
It dynamically gener-ates multiple parallel trees representing an ini-tial text, questions on this text, and expectedanswers, and either orthographic or phoneticoutput.
Analyses of a learner?s answers to ques-tions are used to diagnose comprehension andlanguage skills and to adaptively control sub-sequent generation.
The paper traces stagesin the generation of short texts in English andFrench, and discusses issues of architecture, tex-tual enrichment, and planning.1 VINCI: Architecture,Implementation and OutputIdeally, a language teaching system should both?encourage the creative use of language in com-municatively relevant settings?
(Menzel andSchroeder, 1998) and also provide detailed andadaptive feedback (cf.
(Michaud, 2002)).
Manysystems resolve the issue by means of complexparsing.
In what follows, we describe VINCI, amultilingual generation environment which rep-resents a complementary approach in that it as-sumes conversational control, dynamically pro-ducing more or less complex texts and askinginformation of users.
VINCI is based on a col-lection of metalanguages which define the se-mantics, syntax, lexicon and morphology of alanguage.
Text files defining the language areread by an interpreter (written in C) and out-put is presented either orthographically or pho-netically.When used in a teaching context, VINCI cre-ates an utterance and presents it to a learner.It also creates a series of questions based oneach utterance, together with some hidden an-swers.
The learner is prompted to respond toeach question, and his or her response is com-pared with the hidden one (or ones) and a de-tailed report is produced on the relation be-tween the two.
This report provides informa-tion on a learner?s comprehension and languageskills, as well as guidance for subsequent gener-ation.VINCI is capable of generation in many lan-guages, and has been tested on such diverse lan-guages as Spanish, Italian, Russian and Chi-nese.
Our work to date has been carried outin both English and French, predominantly thelatter.For the generation of simple utterances,VINCI constructs a syntax tree using context-free rules and syntactic transformations.
Thenodes of the tree may be decorated with at-tributes, whose role is to maintain grammaticaland perhaps semantic agreement by restrictingthe choice of lexical items and controlling mor-phology.
Once a tree is formed, its leaves areassigned suitable lexical choices which are in-flected by morphology rules.
In the most basicsituation, choices among syntactic alternativesand among possible lexical entries are made atrandom.
In such a model, the semantic con-trol exercised by attributes is minimal.
Theycan, for example, ensure that the subject of averb such as eat is animate and its object edible,but they cannot influence the overall meaning ofthe utterance produced.
To achieve this, VINCImakes use of preselections.1.1 PreselectionsPreselections may be thought of as forming ametaphoric blackboard on which the person re-quiring an utterance writes some choices aboutits features.
Lexical entries corresponding tothese features are selected before the syntax treeis formed, and syntax rules have access both tothe words themselves and to information aboutthem obtained from the lexicon.
We will illus-trate this by showing the steps in the generationof a short fairy tale, although other sorts of textsare also possible.In a typical fairy tale we have a collectionof characters, including a pompous twit (aking or a rich merchant), a victim or heroine(the twit?s daughter), a villain (a sorcerer orwitch), a hero (a prince or a brave woodcutter),a goodfairy (the victim?s fairy godmother), amagicobj (a sword or a silver goblet).
Theseform the basis for a set of preselections such as:twit :PN/"Midas";victim:PN/ pre twit/@14: daughter;hero :PN[male, brave, handsome];magicobj :N[physobj, magic]These preselections presuppose a database ofcharacters/objects which are simply entries in alexicon:"Midas"|PN|male, rich, weak, vain|...daughter: "Marie";...type: "king"; ...home: "castle"; ..."Marie"|PN|female, beautiful, kind|...type: "princess"; ...Preselections can be specified with more orless precision.
In this example, only Midas canbe chosen for the role of twit, but any mem-ber of the class PN (proper names) having theattributes male, brave and handsome can beselected as hero.
We might well have writ-ten twit: PN[rich]/@14: daughter mak-ing the twit any PN who is rich and has apointer to a daughter in lexical field 14.These preselections are global, in that theypersist across several utterances.
If the hero is aprince in one sentence, he cannot be a woodcut-ter in the next.
In contrast, the local preselec-tions described below associate these characterswith a semantic role in a particular sentence,for example, the agent or the patient.
We canenvisage a user typing/editing a global preselec-tions file to select favorite characters for a story.Alternatively, there may be an interface whichallows a user to choose characters from a set ofmenus.
In the following tale, we assume thatWanda has been preselected as the goodfairyand magic sword as magicobj.1.2 Semantic ExpressionsA semantic expression is a representation of thecontent of an utterance in a form in which thegrammatical constraints of any particular natu-ral language have been abstracted away, leav-ing only some expression of meaning behind.A simple functional notation is used, describedmore fully in (Levison et al, 2001b).
Theseexpressions are transformed into VINCI pres-elections, triggering syntax rules which, in theirturn, yield sentences in some language.
Thesame sequence of expressions can transformedinto paragraphs in different languages or differ-ent paragraphs in the same language.The plot for the fairy tale can be specified asa sequence of these expressions:exists(twit)Once upon a time there was a twit.describe(twit)He was rich and vain.exists(victim)The twit had a daughter, the victim.describe(victim)She was beautiful and kind.admonish(twit, victim, action)The twit warned the victim aboutwalking in the forest.disobey(victim)However, the victim disobeyed.action(victim)She went for a walk in the forest.exists(villain)In the forest there lived a villain.describe(villain)He was strong and evil.kidnap(villain, victim)The villain kidnapped the victim.exists(hero)In the same area, there lived a hero.seekhelp(twit, hero)The twit sought his help.seek(hero, goodfairy)The hero went to find the goodfairy...give(goodfairy, hero, magicobj)who gave him a magicobj.seek(hero, villain)The hero sought the villain...kill(hero, villain, magicobj)and killed him with the magicobj.rescue(hero, victim)The hero rescued the victim, ...marry(hero, victim)married her, ...livehappily(hero, victim)and lived happily ever after.Obviously, the plot can be modified simplyby varying the expressions.
Indeed there mightbe alternative plots or sections, perhaps cho-sen by a user or produced by a text plan-ner.
Let us repeat that these expressions arelanguage-independent.
The names of the func-tions and parameters are, in fact, VINCI at-tributes, and although English words have beenused here, any string of letters or digits couldhave been substituted.
If a French grammar andlexicon is built using the same attributes, asin: "donner"|V|vtdi, give, ...|... thenVINCI can construct French sentences from thesame semantic expressions.1.3 Local PreselectionsEach of the expressions in the previous section isequivalent to and is transformed by VINCI intoa set of local preselections which apply to thegeneration of a single sentence.
For example,give(goodfairy, hero, magicobj) becomes:vtdi; {this attribute selects asegment of syntax basedon a verb with direct andindirect objects}act : V[give];{e.g.
: "give","offer"}agent : PN/ pre goodfairy;beneficiary : PN/ pre hero;theme : N/ pre magicobjSome of these local preselections refer backto the global ones, associating the charactersselected in the earlier preselections with thesemantic roles they will play in the currentsentence: agent, beneficiary and theme.
Sogoodfairy (and hence Wanda) becomes theagent of the act of giving, magicobj (the magicsword) becomes its theme, and hero its benefi-ciary.In effect, semantic expressions provide a moreuser-friendly form for the set of preselections.Conversion from the former to the latter is ef-fected by semantic transformations; for exam-ple:give : vtdi;act : V[give];agent : PN/ pre #1;beneficiary : PN/ pre #2;theme : N/ pre #3whose left-hand side matches give(goodfairy,hero, magicobj), #1 being associated withgoodfairy, #2 with hero and #3 withmagicobj.
In practice it shorter, if less ele-gant, to replace this semantic expression byvtdi(give, goodfairy, hero, magicobj),since this single expression can be used for anyverb taking both direct and indirect objects.1.4 Syntax RulesSyntax rules in Vinci take the abstract semanticrepresentations produced by semantic expres-sions and preselections and clothe them in thesyntax of the language chosen.
Among otherthings, this allows the system to capture con-straints on word order, argument structure, andagreement.
This is accomplished by means ofinheritance of attributes down the nodes of asyntax tree, and guarded syntax rules, in whichattributes present on a parent node are used todetermine the nature of child nodes.
For ex-ample, given a parent node such as NP (nounphrase) containing the attribute ?p1?
(first per-son), a guarded syntax rule (these are headedby the symbol <) will determine that the onlypossible child node is a pronoun.
However, inthe default case (these are headed by the sym-bol >), the child may take either the form of apronoun or a full noun phrase.Let us now return to the example of prese-lections developed above and resume with theaction of syntax rules on the output of prese-lections and semantic expressions.
The sectionof the context-free rules corresponding to vtdidescribe the structure of a sentence with a vtdiverb in terms of the its agent, theme and ben-eficiary.
Thus, assuming the local preselectionsgiven above:ROOT =< _pre_ vtdi:NPP[sing, agent, def]V[p3, sing, past]/_pre_ actNPP[sing, beneficiary, def]NP[sing, theme, indef] %NPP = inherit Fn: Function, Nu: Number,De: Detkind;DET[De] N[Nu]/_pre_ Fn/@13:type %NP = inherit Fn: Function, Nu: Number,De: Detkind;DET[De] N[Nu]/_pre_ Fn %The root of the utterance (the top of its syn-tax tree) has four child nodes, two of themproper noun phrases (NPP), a third a com-mon noun phrase (NP).
To the first it passesa Number-value, sing, a Function-value, agent,and a Detkind-value.
When this NPP is devel-oped into its two children, it assigns these at-tribute values to Nu, Fn and De, passing De toDET (hence a or the) and Nu to the child noun,which will therefore be singular.
This noun isalso directed to obtain its lexical entry from thepreselection labelled Fn (i.e.
agent, which inturn refers to goodfairy, and hence to Wanda).Furthermore, rather than using Wanda itself,the chosen noun must be replaced the lexicalentry indicated by tag type in field 13 (fairygodmother).The other noun phrases obtain their nounssimilarly from beneficiary and theme, thoughthe last (NP) uses the preselected magicobj di-rectly.
The root?s verb-child, which will be thirdperson singular past tense, will obtain its lexi-cal entry from the preselection labelled act.
So,we get: the fairy godmother gave the prince amagic sword.1.5 Two Generated StoriesUsing a simple English lexicon and the grammardescribed above, VINCI generates fairy tales, ofwhich the following is an intentionally short andsimple example.Once upon a time there was a kingcalled Midas who lived in a castle.He was rich and vain.
The king hada daughter, a princess named Marie,who was beautiful.
The king warnedMarie not to go out of the castle.
Theprincess disobeyed the king.
She leftthe castle.A sorcerer called Merlin lived in thewoods.
He was evil.
The sorcerer kid-napped the princess.Nearby there lived a woodcutterwho was named Axel.
The king soughtthe help of the woodcutter.
The wood-cutter went to look for the fairy god-mother.
The fairy godmother passedAxel a magic sword.
Axel searched forthe sorcerer.
The woodcutter killed thesorcerer with the magic sword.
Thewoodcutter rescued the princess.
Thewoodcutter and the princess got mar-ried and lived happily ever after.When linked to a French lexicon, morphologyand syntax, VINCI generates comparable textsin French, as the following example shows:Il e?tait une fois un roi qui s?appelaitMidas et qui vivait dans un beaucha?teau.
Il e?tait riche et vain.
Leroi avait une fille: une princesse quis?appelait Marie et qui e?tait belle.Le roi interdit a` Marie de quitter lecha?teau.
La princesse de?sobe?it au roi.Elle quitta le cha?teau.Dans la fo?ret il y avait un sorcierqui s?appelait Merloc.
Il e?tait me?chant.Le sorcier enleva la princesse.Aux alentours vivait un prince quis?appelait Coeur de Lion et qui e?taitbeau.
Le roi demanda l?aide du prince.Le prince chercha la bonne fe?e.
Labonne fe?e donna une e?pe?e magiqueau prince.
Le prince chercha le sor-cier.
Coeur de Lion utilisa l?e?pe?e mag-ique pour tuer le sorcier.
Le princelibe?ra la princesse.
Le prince e?pousala princesse et ils eurent beaucoupd?enfants.Along with orthographic output, (Thomas,2002) describes the generation of good qualityprosodically controlled French oral output bylinking VINCI with the MBROLA speech syn-thesizer (Dutoit, 2004).
At this time, learnerresponses must still be entered orthographically.1.6 Analysis of User InputAs well as constructing the story, VINCI mayproduce a series of questions to put before alearner; for example:Question: What was the name ofthe good fairy?Expected (hidden) answer: Thegood fairy was called Wanda.Question: Describe Maria.Expected (hidden) answer:Maria was beautiful andkind.In French, whose complex morphology givesscope for more varied errors, a typical questionsuch as:Question: Ou` vivait le roi?and a reponse from a particularly incompetentlearner (one of the authors), gives rise to thefollowing error report:EXPECTED : le roi vivait dansun beau cha^teauRESPONSE : la roi vivrait enune chapeau belleC4 DELETE dansS4 INSERT enC6 ORDER C7 C6C1 S1 la/le MORPH fe?m/mascC2 S2 EXACTC3 S3 vivrait/vivait MORPHcond/imparfC5 S5 une/un MORPH fe?m/mascC6 S7 belle/beau MORPH fe?m/mascC7 S6 APPROX chapeau/cha^teauIf the learner had typed habitait, VINCIwould have reported the change as LEX syn,habiter being tagged in the lexicon as a syn-onym for vivre.
If he had omitted the circumflexaccent on cha?teau, the error would have beenmarked as PHON, since the two forms wouldhave been similar in sound.
This is made pos-sible by the fact that in VINCI, lexical entriesmay carry both orthographic and phonologicalinformation.Output of the error analysis routines as shownabove is not designed to be presented directlyto a learner.
However, since it is machine-generated, it is relatively easy to parse by aroutine which uses it to present error analysesin a more user-friendly format.
At the sametime, results of each analysis may be storedand then used by a driver program to builda user model, and to adaptively control sub-sequent generation (Levison et al, 2001a).
Inthis way, VINCI?s architecture ?closes the loop?in the traditional pipeline approach to genera-tion, in that the output of analysis and diagnosisdrives the input of textual planning.2 Enhancements and Future WorkVINCI?s use of semantic input by means offunctional expressions is designed to allow itto function either as an autonomous narrativegeneration system (cf.
(Callaway and Lester,2001a), (Bringsjord and Ferrucci, 2000) for ex-amples) or as a story authoring environment(cf.
(Umaschi and Cassell, 1997)) in which alanguage teacher may select or construct high-level utterance specifications, or alternatively,a learner may play with the order of a set ofsemantic specifications, or even add new char-acters with their own traits, examining in eachcase the texts produced.
Two kinds of enhance-ments can be used to improve output.2.1 Encyclopedic EnrichmentIn examples shown above, descriptions arebased on simple static attributes (beauty,morality, etc.).
In fact, VINCI?s compound at-tribute mechanism also allows for the expres-sion of actions by characters.
Thus, the at-tribute kill.monsters in the lexical entry forPrince Braveheart might cause exists(hero)to lead to: Nearby there lived a prince calledBraveheart, who was renowned for killing mon-sters.
This mechanism is also applicable to theexpression of a character?s thoughts and atti-tudes, and past background information, bothnarrative desiderata (Bringsjord and Ferrucci,2000), (Robin, 1993) as well as the generationmore or less complex versions of the same text(cf.
(Chali, 1998)).
Work is underway on mech-anisms for the dynamic temporal tagging of at-tributes, as a story develops.
For example, alearner given $50 and instructed to purchasegroceries in a textual supermarket would havehis or her remaining money reduced by eachpurchase he or she describes.It should also be noted that the micro-worlddefined by means of Vinci may be fictional, asin the cases above, or based on real people andevents.
For example, we have performed exper-iments based on a database of French authors,their works, and their biographical details suchas date of birth, death, etc.2.2 Narrative EnrichmentAppropriate use of anaphoric pronous and ag-gregation of sentences both have a significanteffect on perceptions of text quality (Callawayand Lester, 2001b).
In a number of systems,both processes occur after sentences have beenrealized, at the level of revision, which oftenrequires that utterances be reformulated.
Wepropose to perform comparable operations atthe level of semantic expressions.
Suppose twofunctions: exists(X), which generates Therewas an X, and describe(X) which generates Xwas brave and handsome.
The fact that both ex-pressions share a common argument allows fortheir replacement by another, say exdesc(X),which aggregates the two functions to produceThere was a brave and handsome X. Similarly,in the case of anaphoric relations, shared argu-ments allow for replacement of full names bypronouns.
We are currently researching this.Finally, taking account of work by (Karamanisand Manurung, 2002) which shows that sharingof at least one argument characterizes a highpercentage of successive sentences in a text, itis possible to use the sequence of arguments toorder a sequence of semantic expressions.
Per-haps more interestingly, it may be that one ofthe criteria of a new paragraph is a break in thechain of shared arguments from one semanticexpression to the next.
The paragraph breaksin the English and French texts above, whilehuman-constructed, respect this constraint.ReferencesS.
Bringsjord and D.A.
Ferrucci.
2000.
Artifi-cial Intelligence and Literary Creativity: In-side the Mind of BRUTUS, a Storytelling Ma-chine.
London, Lawrence Erlbaum.C.B.
Callaway and J.C. Lester.
2001a.
Eval-uating the effects of natural language gen-eration techniques on reader satisfaction.
InProceedings of the 23rd Annual Conference ofthe Cognitive Science Society, pages 164?169.Edinburgh, UK.C.B.
Callaway and J.C. Lester.
2001b.
Narra-tive prose generation.
In Proceedings of theSeventeenth International Joint Conferenceon Artificial Intelligence (IJCAI 2001), pages1241?1248.
Seattle, WA.Y.
Chali.
1998.
Text expansion using causaland temporal relations.
In Proceedings of theThird International Conference on NaturalLanguage Processing and Industrial Applica-tions.
Moncton, New Brunswick.T.
Dutoit.
2004.
The MBROLA Project.http://tcts.fpms.ac.be/synthesis/mbrola.html.N.
Karamanis and H.M. Manurung.
2002.Stochastic text structuring using the princi-ple of continuity.
In Proceedings of INLG-02,pages 81?88.
Columbia University.M.
Levison, G. Lessard, A-M. Danielson, andD.
Merven.
2001a.
From symptoms to diag-nosis.
In (K. Cameron, editor, CALL ?
TheChallenge of Change, pages 53?59.
Elm Bank,Exeter.M.
Levison, G. Lessard, B. Gottesman, andM.
Stringer.
2001b.
Semantic expressions:An experiment.
Working paper, foundat: http://www.cs.queensu.ca/CompLing/semanticexpressions.html.W.
Menzel and I. Schroeder.
1998.
Constraint-based diagnosis for intelligent language tu-toring systems.
In Proc.
IT&KNOWS, XV.IFIP World Computer Congress, pages 484?497.
Vienna/Budapest.L.N.
Michaud.
2002.
Modeling User Interlan-guage in a Second Language Tutoring Sys-tem for Deaf Users of American Sign Lan-guage.
PhD Dissertation, Department ofComputer and Information Sciences, Univer-sity of Delaware.J.
Robin.
1993.
A revision-based generation ar-chitecture for reporting facts in their histor-ical context.
In M. Zock H. Horecek, editor,New Concepts in Natural Language Genera-tion, pages 238?268.
Pinter, London.C.
Thomas.
2002.
A Prosodic TranscriptionMethod for Natural Language Generation.MSc Thesis, Queen?s University, Kingston.M.
Umaschi and J. Cassell.
1997.
Storytellingsystems: Constructing the innerface of theinterface.
In Cognitive Technologies Proceed-ings ?97, pages 98?108.
IEEE.
