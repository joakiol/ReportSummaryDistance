Multi-Component TAG and Notions of Formal PowerWilliam Schuler, David ChiangComputer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104fschuler,dchiangg@linc.cis.upenn.eduMark DrasInst.
for Research in Cognitive ScienceUniversity of PennsylvaniaSuite 400A, 3401 Walnut StreetPhiladelphia, PA 19104-6228madras@linc.cis.upenn.eduAbstractThis paper presents a restricted versionof Set-Local Multi-Component TAGs(Weir, 1988) which retains the stronggenerative capacity of Tree-Local Multi-Component TAG (i.e.
produces thesame derived structures) but has agreater derivational generative capacity(i.e.
can derive those structures in moreways).
This formalism is then applied asa framework for integrating dependencyand constituency based linguistic repre-sentations.1 IntroductionAn aim of one strand of research in gener-ative grammar is to nd a formalism thathas a restricted descriptive capacity sucientto describe natural language, but no morepowerful than necessary, so that the reasonssome constructions are not legal in any nat-ural language is explained by the formalismrather than stipulations in the linguistic the-ory.
Several mildly context-sensitive grammarformalisms, all characterizing the same stringlanguages, are currently possible candidatesfor adequately describing natural language;however, they dier in their capacities to as-sign appropriate linguistic structural descrip-tions to these string languages.
The work inthis paper is in the vein of other work (Joshi,2000) in extracting as much structural de-scriptive power given a xed ability to de-scribe strings, and uses this to model depen-dency as well as constituency correctly.One way to characterize a formalism's de-scriptive power is by the the set of string lan-guages it can generate, called its weak gener-ative capacity.
For example, Tree AdjoiningGrammars (TAGs) (Joshi et al, 1975) cangenerate the language anbncndnand Context-Free Grammars (CFGs) cannot (Joshi, 1985).Sa  bSa Sa  bbSa Sa Sa  bbb: : :Figure 1: CFG-generable tree set for anbn.Sa Sb Sa Sa Sb Sb Sa Sa Sa Sb Sb Sb : : :Figure 2: TAG-generable tree set for anbn.However, weak generative capacity ignoresthe capacity of a grammar formalism to gener-ate derived trees.
This is known as its stronggenerative capacity.
For example, CFGs andTAGs can both generate the language anbn,but CFGs can only associate the a's and b'sby making them siblings in the derived tree,as shown in Figure 1, whereas a TAG can gen-erate the innite set of trees for the languageanbnthat have a's and b's as siblings, as wellas the innite set of trees where the a's dom-inate the b's in each tree, shown in Figure 2(Joshi, 1985); thus TAGs have more stronggenerative capacity than CFGs.In addition to the tree sets and string lan-guages a formalism can generate, there mayalso be linguistic reasons to care about howthese structures are derived.
For this reason,multi-component TAGs (MCTAGs) (Weir,1988) have been adopted to model somelinguistic phenomena.
In multi-componentTAG, elementary trees are grouped into treesets, and at each step of the derivation all thetrees of a set adjoin simultaneously.
In tree-local MCTAG (TL-MCTAG) all the trees ofa set are required to adjoin into the sameelementary tree; in set-local MCTAG (SL-MCTAG) all the trees of a set are requiredto adjoin into the same elementary tree set.TL-MCTAGs can generate the same stringlanguages and derived tree sets as ordinaryTAGs, so they have the same weak and stronggenerative capacities, but TL-MCTAGs canderive these same strings and trees in morethan TAGs can.
One motivation for TL-MCTAG as a linguistic formalism (Frank,1992) is that it can generate a functional head(such as does) in the same derivational stepas the lexical head with which it is associated(see Figure 3) without violating any assump-tions about the derived phrase structure tree{ something TAGs cannot do in every case.seem:SdoesS...VPseem VPsleep:SJohnVPto sleepsleepseemSdoes SJohn VPseem VPto sleepFigure 3: TL-MCTAG generable derivationThis notion of the derivations of a gram-mar formalism as they relate to the struc-tures they derive has been called the deriva-tional generative capacity (1992).
Somewhatmore formally (for a precise denition, seeBecker et al (1992)): we annotate each ele-ment of a derived structure with a code indi-cating which step of the derivation producedthat element.
This code is simply the addressof the corresponding node in the derivationtree.1Then a formalism's derivational gener-ative capacity is the sets of derived structures,thus annotated, that it can generate.1In Becker et al (1992) the derived structures werealways strings, and the codes were not addresses butunordered identiers.
We trust that our denition isin the spirit of theirs.The derivational generative capacity of aformalism also describes what parts of a de-rived structure combine with each other.
Thusif we consider each derivation step to corre-spond to a semantic dependency, then deriva-tional generative capacity describes whatother elements a semantic element may de-pend on.
That is, if we interpret the derivationtrees of TAG as dependency structures andthe derived trees as phrase structures, thenthe derivational generative capacity of TAGlimits the possible dependency structures thatcan be assigned to a given phrase structure.1.1 Dependency and ConstituencyWe have seen that TL-MCTAGs can gener-ate some derivations for \Does John seemto sleep" that TAG cannot, but even TL-MCTAG cannot generate the string, \DoesJohn seem likely to sleep" with a derived treethat matches some linguistic notion of correctconstituency and a derivation that matchessome notion of correct dependency.
This isbecause the components for `does' and `seem'would have to adjoin into dierent compo-nents of the elementary tree set for `likely'(see Figure 4), which would require a set-localmulti-component TAG instead of tree-local.seem:SdoesS...VPseem VPlikely:S...VPlikely VPsleep:SJohn VPto sleepsleeplikelyseemFigure 4: SL-MCTAG generable derivationUnfortunately, unrestricted set-local multi-component TAGs not only have more deriva-tional generative capacity than TAGs, butthey also have more weak generative capac-ity: SL-MCTAGs can generate the quadru-ple copy language wwww, for example, whichdoes not correspond to any known linguis-tic phenomenon.
Other formalisms aiming tomodel dependency correctly similarly expandweak generative capacity, notably D-tree Sub-stitution Grammar (Rambow et al, 1995),and consequently end up with much greaterparsing complexity.The work in this paper follows anotherFigure 5: Set-local adjunction.line of research which has focused on squeez-ing as much strong generative capacity aspossible out of weakly TAG-equivalent for-malisms.
Tree-local multicomponent TAG(Weir, 1988), nondirectional composition(Joshi and Vijay-Shanker, 1999), and seg-mented adjunction (Kulick, 2000) are exam-ples of this approach, wherein the constrainton weak generative capacity naturally limitsthe expressivity of these systems.
We discussthe relation of the formalism of this paper,Restricted MCTAG (R-MCTAG) with someof these in Section 5.2 Formalism2.1 Restricting set-local MCTAGThe way we propose to deal with multi-component adjunction is rst to limit thenumber of components to two, and then,roughly speaking, to treat two-componentadjunction as one-component adjunction bytemporarily removing the material betweenthe two adjunction sites.
The reasons behindthis scheme will be explained in subsequentsections, but we mention it now because itmotivates the somewhat complicated restric-tions on possible adjunction sites: One adjunction site must dominate theother.
If the two sites are hand l, callthe set of nodes dominated by one nodebut not strictly dominated by the otherthe site-segment hh; li. Removing a site-segment must not de-prive a tree of its foot node.
That is, nosite-segment hh; li may contain a footnode unless lis itself the foot node. If two tree sets adjoin into the same tree,the two site-segments must be simulta-neously removable.
That is, the two site-segments must be disjoint, or one mustcontain the other.Because of the rst restriction, we depicttree sets with the components connected bya dominance link (dotted line), in the man-ner of (Becker et al, 1991).
As written, theabove rules only allow tree-local adjunction;we can generalize them to allow set-local ad-junction by treating this dominance link likean ordinary arc.
But this would increase theweak generative capacity of the system.
Forpresent purposes it is sucient just to allowone type of set-local adjunction: adjoin theupper tree to the upper foot, and the lowertree to the lower root (see Figure 5).This does not increase the weak generativecapacity, as will be shown in Section 2.3.
Ob-serve that the set-local TAG given in Figure 5obeys the above restrictions.2.2 2LTAGFor the following section, it is useful to thinkof TAG in a manner other than the usual.Instead of it being a tree-rewriting systemwhose derivation history is recorded in aderivation tree, it can be thought of as a setof trees (the `derivation' trees) with a yieldfunction (here, reading o the node labels ofderivation trees, and composing correspond-ing elementary trees by adjunction or sub-stitution as appropriate) applied to get theTAG trees.
Weir (1988) observed that severalTAGs could be daisy-chained into a multi-level TAG whose yield function is the com-position of the individual yield functions.More precisely: a 2LTAG is a pair ofTAGs hG;G0i = hh;NT ; I; A; Si; hI [ A; I [A; I0; A0; S0ii.We call G the object-level grammar, andG0the meta-level grammar.
The object-levelgrammar is a standard TAG:  and NT areits terminal and nonterminal alphabets, I andA are its initial and auxiliary trees, and S 2 Icontains the trees which derivations may startwith.The meta-level grammar G0is dened sothat it derives trees that look like derivationtrees of G: Nodes are labeled with (the names of)elementary trees of G. Foot nodes have no labels. Arcs are labeled with Gorn addresses.22The Gorn address of a root node is ; if a node hasGorn address , then its ith child has Gorn addressFigure 6: Adjoining into  by removing. An auxiliary tree may adjoin anywhere. When a tree  is adjoined at a node ,  isrewritten as , and the foot of  inheritsthe label of .The tree set of hG;G0i, T (hG;G0i), isfG[T (G0)], where fGis the yield function ofG and T (G0) is the tree set of G0.
Thus, theelementary trees of G0are combined to forma derived tree, which is then interpreted as aderivation tree for G, which gives instructionsfor combining elementary trees of G into thenal derived tree.It was shown in Dras (1999) that when themeta-level grammar is in the regular form ofRogers (1994) the formalism is weakly equiv-alent to TAG.2.3 Reducing restricted R-MCTAGto RF-2LTAGConsider the case of a multicomponent treeset f1;2g adjoining into an initial tree(Figure 6).
Recall that we dened a site-segment of a pair of adjunction sites to be allthe nodes which are dominated by the uppersite but not the lower site.
Imagine that thesite-segmentis excised from , and that1and2are fused into a single elementary tree.Now we can simulate the multi-componentadjunction by ordinary adjunction: adjoin thefused1and2into what is left of ; thenreplaceby adjoining it between1and2.The replacement ofcan be postponedindenitely: some other (fused) tree setf10;20g can adjoin between1and2, andso on, and thenadjoins between the lastpair of trees.
This will produce the same re-sult as a series of set-local adjunctions.More formally:1.
Fuse all the elementary tree sets of thegrammar by identifying the upper foot  i.with the lower root.
Designate this fusednode the meta-foot.2.
For each tree, and for every possible com-bination of site-segments, excise all thesite-segments and add all the trees thusproduced (the excised auxiliary trees andthe remainders) to the grammar.Now that our grammar has been smashedto pieces, we must make sure that the rightpieces go back in the right places.
We could dothis using features, but the resulting grammarwould only be strongly equivalent, not deriva-tionally equivalent, to the original.
Thereforewe use a meta-level grammar instead:1.
For each initial tree, and for every pos-sible combination of site-segments, con-struct the derivation tree that will re-assemble the pieces created in step (2)above and add it to the meta-level gram-mar.2.
For each auxiliary tree, and for every pos-sible combination of site-segments, con-struct a derivation tree as above, and forthe node which corresponds to the piececontaining the meta-foot, add a child, la-bel its arc with the meta-foot's address(within the piece), and mark it a footnode.
Add the resulting (meta-level) aux-iliary tree to the meta-level grammar.Observe that set-local adjunction corre-sponds to meta-level adjunction along the(meta-level) spine.
Recall that we restrictedset-local adjunction so that a tree set canonly adjoin at the foot of the upper tree andthe root of the lower tree.
Since this pair ofnodes corresponds to the meta-foot, we canrestate our restriction in terms of the con-verted grammar: no meta-level adjunction isallowed along the spine of a (meta-level) aux-iliary tree except at the (meta-level) foot.Then all meta-level adjunction is regularadjunction in the sense of (Rogers, 1994).Therefore this converted 2LTAG producesderivation tree sets which are recognizable,and therefore our formalism is strongly equiv-alent to TAG.Note that this restriction is much strongerthan Rogers' regular form restriction.
Thiswas done for two reasons.
First, the deni-tion of our restriction would have been morecomplicated otherwise; second, this restric-tion overcomes some computational dicul-ties with RF-TAG which we discuss below.3 Linguistic ApplicationsIn cases where TAG models dependencies cor-rectly, the use of R-MCTAG is straightfor-ward: when an auxiliary tree adjoins at asite pair which is just a single node, it looksjust like conventional adjunction.
However, inproblematic cases we can use the extra expres-sive power of R-MCTAG to model dependen-cies correctly.
Two such cases are discussedbelow.3.1 Bridge and Raising VerbsSNPJohnVPVthinksS...SSCthatS...VPVseemsVPSNPMaryVPVto sleepFigure 7: Trees for (1)Consider the case of sentences which con-tain both bridge and raising verbs, notedby Rambow et al (1995).
In most TAG-basedanalyses, bridge verbs adjoin at S (or C0), andraising verbs adjoin at VP (or I0).
Thus thederivation for a sentence like(1) John thinks that Mary seems tosleep.will have the trees for thinks and seems si-multaneously adjoining into the tree for like,which, when interpreted, gives an incorrectdependency structure.But under the present view we can ana-lyze sentences like (1) with derivations mir-roring dependencies.
The desired trees for (1)are shown in Figure 7.
Since the tree for thatseems can meta-adjoin around the subject,the tree for thinks correctly adjoins into thetree for seems rather than eat.Also, although the above analysis producesthe correct dependency links, the directionsare inverted in some cases.
This is a disad-vantage compared to, for example, DSG; butsince the directions are consistently inverted,for applications like translation or statisticalmodeling, the particular choice of direction isusually immaterial.3.2 More on Raising VerbsTree-local MCTAG is able to derive (2a), butunable to derive (2b) except by adjoining theauxiliary tree for to be likely at the foot of theauxiliary tree for seem (Frank et al, 1999).
(2) a.
Does John seem to sleep?b.
Does John seem to be likely tosleep?The derivation structure of this analysis doesnot match the dependencies, however|seemadjoins into to sleep.DSG can derive this sentence with a deriva-tion matching the dependencies, but it losessome of the advantage of TAG in that, forexample, cases of super-raising (where theverb is raised out of two clauses) must be ex-plicitly ruled out by subsertion-insertion con-straints.
Frank et al (1999) and Kulick (2000)give analyses of raising which assign the de-sired derivation structures without runninginto this problem.
It turns out that the anal-ysis of raising from the previous section, de-signed for a translation problem, has bothof these properties as well.
The grammar isshown back in Figure 4.4 A ParserFigure 8 shows a CKY-style parser for ourrestriction of MCTAG as a system of inferencerules.
It is limited to grammars whose treesare at most binary-branching.The parser consists of rules over items ofone of the following forms, where w1  wnisthe input; , h, and lspecify nodes of thegrammar; i, j, k, and l are integers between 0and n inclusive; and code is either + or  : [; code ; i; ; ; l; ; ] and[; code ; i; j; k; l; ; ] function as ina CKY-style parser for standard TAG(Vijay-Shanker, 1987): the subtreerooted by  2 T derives a tree whosefringe is wi  wlif T is initial, orwi  wjFwk  wlif T is the lowerauxiliary tree of a set and F is the labelof its foot node.
In all four item forms,code = + i adjunction has taken placeat . [; code ; i; j; k; l; ; l] species that thesegment h; li derives a tree whosefringe is wi  wjLwk  wl, where L isthe label of l.
Intuitively, it means thata potential site-segment has been recog-nized. [; code ; i; j; k; l; h; l] species, if  be-longs to the upper tree of a set, thatthe subtree rooted by , the segmenthh; li, and the lower tree concatenatedtogether derive a tree whose fringe iswi  wjFwk  wl, where F is the la-bel of the lower foot node.
Intuitively, itmeans that a tree set has been partiallyrecognized, with a site-segment insertedbetween the two components.The rules which require dier from a TAGparser and hence explanation are Pseudopod,Push, Pop, and Pop-push.
Pseudopod appliesto any potential lower adjunction site and isso called because the parser essentially viewsevery potential site-segment as an auxiliarytree (see Section 2.3), and the Pseudopod ax-iom recognizes the feet of these false auxiliarytrees.The Push rule performs the adjunction ofone of these false auxiliary trees|that is, itplaces a site-segment between the two trees ofan elementary tree set.
It is so called becausethe site-segment is saved in a \stack" so thatthe rest of its elementary tree can be recog-nized later.
Of course, in our case the \stack"has at most one element.The Pop rule does the reverse: every com-pleted elementary tree set must contain asite-segment, and the Pop rule places it backwhere the site-segment came from, emptyingthe \stack."
The Pop-push rule performs set-local adjunction: a completed elementary treeset is placed between the two trees of yet an-other elementary tree set, and the \stack" isunchanged.Pop-push is computationally the most ex-pensive rule; since it involves six indices andthree dierent elementary trees, its runningtime is O(n6G3).It was noted in (Chiang et al, 2000) thatfor synchronous RF-2LTAG, parse forestscould not be transferred in time O(n6).
Thisfact turns out to be connected to several prop-erties of RF-TAG (Rogers, 1994).33Thanks to Anoop Sarkar for pointing out the rstThe CKY-style parser for regular formTAG described in (Rogers, 1994) essentiallykeeps track of adjunctions using stacks, andthe regular form constraint ensures that thestack depth is bounded.
The only kinds of ad-junction that can occur to arbitrary depth areroot and foot adjunction, which are treatedsimilarly to substitution and do not aect thestacks.
The reader will note that our parserworks in exactly the same way.A problem arises if we allow both rootand foot adjunction, however.
It is well-knownthat allowing both types of adjunction createsderivational ambiguity (Vijay-Shanker, 1987):adjoining1at the foot of2produces thesame derived tree that adjoining1at theroot of2would.
The problem is not the am-biguity per se, but that the regular form TAGparser, unlike a standard TAG parser, doesnot always distinguish these multiple deriva-tions, because root and foot adjunction areboth performed by the same rule (analogousto our Pop-push).
Thus for a given applicationof this rule, it is not possible to say which treeis adjoining into which without examining therest of the derivation.But this knowledge is necessary to per-form certain tasks online: for example, enforc-ing adjoining constraints, computing proba-bilities (and pruning based on them), or per-forming synchronous mappings.
Therefore wearbitrarily forbid one of the two possibilities.4The parser given in Section 4 already takesthis into account.5 DiscussionOur version of MCTAG follows otherwork in incorporating dependency into aconstituency-based approach to modelingnatural language.
One such early integra-tion involved work by Gaifman (1965), whichshowed that projective dependency grammarscould be represented by CFGs.
However, itis known that there are common phenom-ena which require non-projective dependencygrammars, so looking only at projective de-such connection.4Against tradition, we forbid root adjunction, be-cause adjunction at the foot ensures that a bottom-uptraversal of the derived tree will encounter elementarytrees in the same order as they appear in a bottom-uptraversal of the derivation tree, simplifying the calcu-lation of derivations.Goal: [r; ; 0; ; ; n; ; ] ran initial root(Leaf) [;+; i; ; ; j; ; ]  a leaf(Foot) [;+; i; i; j; j; ; ]  a lower foot(Pseudopod) [;+; i; i; j; j; ; ](Unary)[1;+; i; p; q; j; h; l][; ; i; p; q; j; h; l]1(Binary 1)[1;+; i; p; q; j; h; l] [2;+; j; ; ; k; ; ][; ; i; p; q; k; h; l]12(Binary 2)[1;+; i; ; ; j; ; ] [2;+; j; p; q; k; h; l][; ; i; p; q; k; h; l]12(No adjunction)[; ; i; p; q; j; h; l][;+; i; p; q; j; h; l](Push)[1;+; j; p; q; k; ; ] [h; ; i; j; k; l; ; l][;+; i; p; q; l; h; l]...1(i.e.
 is an upper footand 1is a lower root)(Pop)[l; ; j; p; q; k; h0; l0] [r;+; i; j; k; l; h; l][h;+; i; p; q; l; h0; l0]ra root of an upper treeadjoinable at hh; li(Pop-push)[1;+; j; p; q; k; ; ] [r;+; i; j; k; l; h; l][;+; i; p; q; l; h; l]...1, ra root of an uppertree adjoinable ath; 1iFigure 8: Parserpendency grammars is inadequate.
Follow-ing the observation of TAG derivations' sim-ilarity to dependency relations, other for-malisms have also looked at relating depen-dency and constituency approaches to gram-mar formalisms.A more recent instance is D-Tree Substi-tution Grammars (DSG) (Rambow et al,1995), where the derivations are also inter-preted as dependency relations.
Thought ofin the terms of this paper, there is a clearparallel with R-MCTAG, with a local setultimately representing dependencies havingsome yield function applied to it; the ideaof non-immediate dominance also appears inboth formalisms.
The dierence between thetwo is in the kinds of languages that they areable to describe: DSG is both less and morerestrictive than R-MCTAG.
DSG can gener-ate the language count-k for some arbitraryk (that is, fa1na2n: : : akng), which makesit extremely powerful, whereas R-MCTAGcan only generate count-4.
However, DSGcannot generate the copy language (that is,fww j w 2 g with  some terminal al-phabet), whereas R-MCTAG can; this maybe problematic for a formalism modeling nat-ural language, given the key role of the copylanguage in demonstrating that natural lan-guage is not context-free (Shieber, 1985).
R-MCTAG is thus a more constrained relaxationof the notion of immediate dominance in fa-vor of non-immediate dominance than is thecase for DSG.Another formalism of particular interesthere is the Segmented Adjoining Grammar of(Kulick, 2000).
This generalization of TAG ischaracterized by an extension of the adjoiningoperation, motivated by evidence in scram-bling, clitic climbing and subject-to-subjectraising.
Most interestingly, this extension toTAG, proposed on empirical grounds, is de-ned by a composition operation with con-strained non-immediate dominance links thatlooks quite similar to the formalism describedin this paper, which began from formal con-siderations and was then applied to data.
Thisconuence suggests that the ideas describedhere concerning combining dependency andconstituency might be reaching towards somedeeper connection.6 ConclusionFrom a theoretical perspective, extractingmore derivational generative capacity andthereby integrating dependency and con-stituency into a common framework is an in-teresting exercise.
It also, however, proves tobe useful in modeling otherwise problematicconstructions, such as subject-auxiliary inver-sion and bridge and raising verb interleaving.Moreover, the formalism developed from the-oretical considerations, presented in this pa-per, has similar properties to work developedon empirical grounds, suggesting that this isworth further exploration.ReferencesTilman Becker, Aravind Joshi, and Owen Ram-bow.
1991.
Long distance scrambling and treeadjoining grammars.
In Fifth Conference of theEuropean Chapter of the Association for Com-putational Linguistics (EACL'91), pages 21{26.Tilman Becker, Owen Rambow, and Michael Niv.1992.
The derivational generative power of for-mal systems, or, Scrambling is beyond LCFRS.Technical Report IRCS-92-38, Institute for Re-search in Cognitive Science, University of Penn-sylvania.David Chiang, William Schuler, and Mark Dras.2000.
Some Remarks on an Extension of Syn-chronous TAG.
In Proceedings of TAG+5,Paris, France.Mark Dras.
1999.
A meta-level grammar: re-dening synchronous TAG for translation andparaphrase.
In Proceedings of the 37th AnnualMeeting of the Association for ComputationalLinguistics (ACL '99).Robert Frank, Seth Kulick, and K. Vijay-Shanker.1999.
C-command and extraction in tree-adjoining grammar.
Proceedings of the SixthMeeting on the Mathematics of Language(MOL6).Robert Frank.
1992.
Syntactic locality andtree adjoining grammar: grammatical acquisi-tion and processing perspectives.
Ph.D. the-sis, Computer Science Department, Universityof Pennsylvania.Haim Gaifman.
1965.
Dependency Systems andPhrase-Structure Systems.
Information andControl, 8:304{337.Gerald Gazdar.
1988.
Applicability of indexedgrammars to natural languages.
In Uwe Reyleand Christian Rohrer, editors, Natural Lan-guage Parsin and Linguistic Theories.
D. ReidelPublishing Company, Dordrecht, Holland.Aravind Joshi and K. Vijay-Shanker.
1999.
Com-positional Semantics with Lexicalized Tree-Adjoining Grammar (LTAG): How Much Un-derspecication is Necessary?
In Proceedings ofthe 2nd International Workshop on Computa-tional Semantics.Aravind K. Joshi, Leon S. Levy, and M. Taka-hashi.
1975.
Tree adjunct grammars.
Journalof computer and system sciences, 10:136{163.Aravind K. Joshi.
1985.
How much context sen-sitivity is necessary for characterizing struc-tural descriptions: Tree adjoining grammars.
InL.
Karttunen D. Dowty and A. Zwicky, editors,Natural language parsing: Psychological, com-putational and theoretical perspectives, pages206{250.
Cambridge University Press, Cam-bridge, U.K.Aravind Joshi.
2000.
Relationship between strongand weak generative power of formal systems.In Proceedings of TAG+5, pages 107{114, Paris,France.Seth Kulick.
2000.
A uniform account of localityconstraints for clitic climbing and long scram-bling.
In Proceedings of the Penn LinguisticsColloquium.Owen Rambow, David Weir, and K. Vijay-Shanker.
1995.
D-tree grammars.
In Proceed-ings of the 33rd Annual Meeting of the Associa-tion for Computational Linguistics (ACL '95).James Rogers.
1994.
Capturing CFLs with treeadjoining grammars.
In Proceedings of the 32ndAnnual Meeting of the Association for Compu-tational Linguistics (ACL '94).Stuart Shieber.
1985.
Evidence against thecontext-freeness of natural language.
Linguis-tics and Philosophy, 8:333{343.K.
Vijay-Shanker.
1987.
A study of tree adjoininggrammars.
Ph.D. thesis, Department of Com-puter and Information Science, University ofPennsylvania.David Weir.
1988.
Characterizing MildlyContext-Sensitive Grammar Formalisms.Ph.D.
thesis, Department of Computer and In-formation Science, University of Pennsylvania.
