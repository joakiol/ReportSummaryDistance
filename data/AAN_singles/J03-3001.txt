c?
2003 Association for Computational LinguisticsIntroduction to the Special Issue on theWeb as CorpusAdam Kilgarriff?
Gregory Grefenstette?Lexicography MasterClass Ltd. and ITRI Clairvoyance CorporationUniversity of BrightonThe Web, teeming as it is with language data, of all manner of varieties and languages, invast quantity and freely available, is a fabulous linguists?
playground.
This special issue ofComputational Linguistics explores ways in which this dream is being explored.1.
IntroductionThe Web is immense, free, and available by mouse click.
It contains hundreds ofbillions of words of text and can be used for all manner of language research.The simplest language use is spell checking.
Is it speculater or speculator?
Googlegives 67 for the former (usefully suggesting the latter might have been intended) and82,000 for the latter.
Question answered.Language scientists and technologists are increasingly turning to the Web as asource of language data, because it is so big, because it is the only available sourcefor the type of language in which they are interested, or simply because it is freeand instantly available.
The mode of work has increased dramatically from a standingstart seven years ago with the Web being used as a data source in a wide range ofresearch activities: The papers in this special issue form a sample of the best of it.
Thisintroduction to the issue aims to survey the activities and explore recurring themes.We first consider whether the Web is indeed a corpus, then present a history ofthe theme in which we view the Web as a development of the empiricist turn that hasbrought corpora center stage in the course of the 1990s.
We briefly survey the rangeof Web-based NLP research, then present estimates of the size of the Web, for Englishand for other languages, and a simple method for translating phrases.
Next we openthe Pandora?s box of representativeness (concluding that the Web is not representativeof anything other than itself, but then neither are other corpora, and that more workneeds to be done on text types).
We then introduce the articles in the special issue andconclude with some thoughts on how the Web could be put at the linguist?s disposalrather more usefully than current search engines allow.1.1 Is the Web a Corpus?To establish whether the Web is a corpus we need to find out, discover, or decide whata corpus is.
McEnery and Wilson (1996, page 21) sayIn principle, any collection of more than one text can be called acorpus.
.
.
.
But the term ?corpus?
when used in the context of modernlinguistics tends most frequently to have more specific connotationsthan this simple definition provides for.
These may be considered un-?
Lewes Rd, Brighton, BN2 4JG, UK.
E-mail: Adam.Kilgarriff@itri.brighton.ac.uk?
Suite 700, 5001 Baum Blvd, Pittsburgh, PA 15213-1854.
E-mail: grefen@clairvoyancecorp.com334Computational Linguistics Volume 29, Number 3der four main headings: sampling and representativeness, finite size,machine-readable form, a standard reference.We would like to reclaim the term from the connotations.
Many of the collectionsof texts that people use and refer to as their corpus, in a given linguistic, literary, orlanguage-technology study, do not fit.
A corpus comprising the complete publishedworks of Jane Austen is not a sample, nor is it representative of anything else.
Closerto home, Manning and Schu?tze (1999, page 120) observe:In Statistical NLP, one commonly receives as a corpus a certain amountof data from a certain domain of interest, without having any say inhow it is constructed.
In such cases, having more training data isnormally more useful than any concerns of balance, and one shouldsimply use all the text that is available.We wish to avoid a smuggling of values into the criterion for corpus-hood.
McEneryand Wilson (following others before them) mix the question ?What is a corpus??
with?What is a good corpus (for certain kinds of linguistic study)??
muddying the simplequestion ?Is corpus x good for task y??
with the semantic question ?Is x a corpus atall??
The semantic question then becomes a distraction, all too likely to absorb energiesthat would otherwise be addressed to the practical one.
So that the semantic questionmay be set aside, the definition of corpus should be broad.
We define a corpus simplyas ?a collection of texts.?
If that seems too broad, the one qualification we allow relatesto the domains and contexts in which the word is used rather than its denotation: Acorpus is a collection of texts when considered as an object of language or literary study.The answer to the question ?Is the web a corpus??
is yes.2.
HistoryFor chemistry or biology, the computer is merely a place to store and process infor-mation gleaned about the object of study.
For linguistics, the object of study itself (inone of its two primary forms, the other being acoustic) is found on computers.
Textis an information object, and a computer?s hard disk is as valid a place to go for itsrealization as the printed page or anywhere else.The one-million-word Brown corpus opened the chapter on computer-based lan-guage study in the early 1960s.
Noting the singular needs of lexicography for big data,in the 1970s Sinclair and Atkins inaugurated the COBUILD project, which raised thethreshold of viable corpus size from one million to, by the early 1980s, eight millionwords (Sinclair 1987).
Ten years on, Atkins again took the lead with the develop-ment (from 1988) of the British National Corpus (BNC) (Burnard 1995), which raisedhorizons tenfold once again, with its 100 million words and was in addition widelyavailable at low cost and covered a wide spectrum of varieties of contemporary BritishEnglish.1 As in all matters Zipfian, logarithmic graph paper is required.
Where corpussize is concerned, the steps of interest are 1, 10, 100, .
.
.
, not 1, 2, 3, .
.
.Corpora crashed into computational linguistics at the 1989 ACL meeting in Van-couver, but they were large, messy, ugly objects clearly lacking in theoretical integrityin all sorts of ways, and many people were skeptical regarding their role in the disci-pline.
Arguments raged, and it was not clear whether corpus work was an acceptable1 Across the Atlantic, a resurgence in empiricism was led by the success of the noisy-channel model inspeech recognition (see Church and Mercer [1993] for references).335Kilgarriff and Grefenstette Web as Corpus: Introductionpart of the field.
It was only with the highly successful 1993 special issue of thisjournal, ?Using Large Corpora?
(Church and Mercer 1993), that the relation betweencomputational linguistics and corpora was consummated.There are parallels with Web corpus work.
The Web is anarchic, and its use isnot in the familiar territory of computational linguistics.
However, as students withno budget or contacts realize, it is the obvious place to obtain a corpus meeting theirspecifications, as companies want the research they sanction to be directly relatedto the language types they need to handle (almost always available on the Web), ascopyright continues to constrain ?traditional?
corpus development,2 as people wantto explore using more data and different text types, so Web-based work will grow.The Web walked in on ACL meetings starting in 1999.
Rada Mihalcea and DanMoldovan (1999) used hit counts for carefully constructed search engine queries toidentify rank orders for word sense frequencies, as an input to a word sense dis-ambiguation engine.
Philip Resnik (1999) showed that parallel corpora?until then apromising research avenue but largely constrained to the English-French CanadianHansard?could be found on the Web: We can grow our own parallel corpus usingthe many Web pages that exist in parallel in local and in major languages.
We areglad to have the further development of this work (co-authored by Noah Smith) pre-sented in this special issue.
In the student session of ACL 2000, Rosie Jones and RayidGhani (2001) showed how, using the Web, one can build a language-specific corpusfrom a single document in that language.
In the main session Atsushi Fujii and Tet-suya Ishikawa (2000) demonstrated that descriptive, definition-like collections can beacquired from the Web.2.1 Some Current ThemesSince then there have been many papers, at ACL and elsewhere, and we can mentiononly a few.
The EU MEANING project (Rigau et al 2002) takes forward the explorationof the Web as a data source for word sense disambiguation, working from the premisethat within a domain, words often have just one meaning, and that domains can beidentified on the Web.
Mihalcea and Tchklovski complement this use of Web as corpuswith Web technology to gather manual word sense annotations on the Word ExpertWeb site.3 Santamari?a et al, in this issue, discuss how to link word senses to Webdirectory nodes, and thence to Web pages.The Web is being used to address data sparseness for language modeling.
Inaddition to Keller and Lapata (this issue) and references therein, Volk (2001) gatherslexical statistics for resolving prepositional phrase attachments, and Villasenor-Pinedaet al (2003) ?balance?
their corpus using Web documents.The information retrieval community now has a Web track as a component of itsTREC evaluation initiative.
The corpus for this exercise is a substantial (around 100GB)sample of the Web, largely using documents in the .gov top level domain, as frozenat a given date (Hawking et al 1999).The Web has recently been used by groups at Sheffield and Microsoft, amongothers, as a source of answers for question-answering applications, in a merge of searchengine and language-processing technologies (Greenwood, Roberts, and Gaizauskas2 Lawyers may argue that the legal issues for Web corpora are no different from those around non-Webcorpora.
However, first, language researchers can develop Web corpora just by saving Web pages ontheir own computer without any copying, thereby avoiding copyright issues, and second, a Webcorpus is a very minor subspecies of the caches and indexes held by search engines and assorted othercomponents of the infrastructure of the Web: If a Web corpus is infringing copyright, then it is merelydoing on a small scale what search engines such as Google are doing on a colossal scale.3 ?http://teach-computers.org/word-expert.html?.336Computational Linguistics Volume 29, Number 32002; Dumais et al 2002).
AnswerBus (Zheng 2002) will answer questions posed inEnglish, German, French, Spanish, Italian, and Portuguese.Naturally, the Web is also coming into play in other areas of linguistics.
Agirreet al 2000) are exploring the automatic population of existing ontologies using theWeb as a source for new instances.
Varantola (2000) shows how translators can use?just-in-time?
sublanguage corpora to choose correct target language terms for areasin which they are not expert.
Fletcher (2002) demonstrates methods for gathering andusing Web corpora in a language-teaching context.2.2 The 100M Words of the BNCOne hundred million words is a large enough corpus for many empirical strategiesfor learning about language, either for linguists and lexicographers (Baker, Fillmore,and Lowe 1998; Kilgarriff and Rundell 2002) or for technologies that need quantitativeinformation about the behavior of words as input (most notably parsers [Briscoe andCarroll 1997; Korhonen 2000]).
However, for some purposes, it is not large enough.This is an outcome of the Zipfian nature of word frequencies.
Although 100 million isa huge number, and the BNC contains ample information on the dominant meaningsand usage patterns for the 10,000 words that make up the core of English, the bulkof the lexical stock occurs less than 50 times in the BNC, which is not enough todraw statistically stable conclusions about the word.
For rarer words, rare meaningsof common words, and combinations of words, we frequently find no evidence at all.Researchers are obliged to look to larger data sources (Keller and Lapata, this issue;also Section 3.3).
They find that probabilistic models of language based on very largequantities of data, even if those data are noisy, are better than ones based on estimates(using sophisticated smoothing techniques) from smaller, cleaner data sets.Another argument is made vividly by Banko and Brill (2001).
They explore theperformance of a number of machine learning algorithms (on a representative dis-ambiguation task) as the size of the training corpus grows from a million to a bil-lion words.
All the algorithms steadily improve in performance, though the question?Which is best??
gets different answers for different data sizes.
The moral: Perfor-mance improves with data size, and getting more data will make more difference thanfine-tuning algorithms.2.3 Giving and TakingDragomir Radev has made a useful distinction between NLP ?giving?
and ?taking.
?4NLP can give to the Web technologies such as summarization (for Web pages orWeb search results); machine translation; multilingual document retrieval; question-answering and other strategies for finding not only the right document, but the rightpart of a document; and tagging, parsing, and other core technologies (to improveindexing for search engines, the viability of this being a central information retrievalresearch question for the last 20 years).
?Taking?
is, simply, using the Web as a sourceof data for any CL or NLP goal and is the theme of this special issue.
If we focus tooclosely on the giving side of the equation, we look only at short to medium-term goals.For the longer term, for ?giving?
as well as for other purposes, a deeper understandingof the linguistic nature of the Web and its potential for CL/NLP is required.
For that,we must take the Web itself, in whatever limited way, as an object of study.Much Web search engine technology has been developed with reference to lan-guage technology.
The prototype for AltaVista was developed in a joint project be-4 In remarks made in a panel discussion at the Empirical NLP Conference, Hong Kong, October 2002.337Kilgarriff and Grefenstette Web as Corpus: Introductiontween Oxford University Press (exploring methods for corpus lexicography [Atkins1993]) and DEC (interested in fast access to very large databases).
Language identifi-cation algorithms (Beesley 1988; Grefenstette 1995), now widely used in Web searchengines, were developed as NLP technology.
The special issue explores a ?homecom-ing?
of Web technologies, with the Web now feeding one of the hands that fosteredit.3.
Web Size and the Multilingual WebThere were 56 million registered network addresses in July 1999, 125 million in January2001, and 172 million in January 2003.
A plot of this growth of the Web in terms ofcomputer hosts can easily be generated.
Linguistic aspects take a little more workand can be estimated only by sampling and extrapolation.
Lawrence and Giles (1999)compared the overlap between page lists returned by different Web browsers over thesame set of queries and estimated that, in 1999, there were 800 million indexable Webpages available.
By sampling pages, and estimating an average page length of sevento eight kilobytes of nonmarkup text, they concluded that there might be six terabytesof text available then.
In 2003, Google claims to search four times this number of Webpages, which raises the number of bytes of text available just through this one Webserver to over 20 terabytes from directly accessible Web pages.
At an average of 10bytes per word, a generous estimate for Latin-alphabet languages, that suggests twothousand billion words.The Web is clearly a multilingual corpus.
How much of it is English?
Xu (2000) es-timated that 71% of the pages (453 million out of 634 million Web pages indexed by theExcite engine at that time) were written in English, followed by Japanese (6.8%), Ger-man (5.1%), French (1.8%), Chinese (1.5%), Spanish (1.1%), Italian (0.9%), and Swedish(0.7%).We have measured the counts of some English phrases according to various searchengines over time and compared them with counts in the BNC, which we know has100 million words.
Table 1 shows these counts in the BNC, on AltaVista in 1998 andin 2001, and then on Alltheweb in 2003.
For example, the phrase deep breath appears732 times in the BNC.
It was indexed 54,550 times by AltaVista in 1998.
This roseTable 1Frequencies of English phrases in the BNC and on AltaVista in 1998 and 2001, and onAlltheWeb in 2003.
The counts for the BNC and AltaVista are for individual occurrences of thephrase.
The counts for AlltheWeb are page counts (the phrase may appear more than once onany page).Sample Phrase BNC WWW WWW WWW(100 M) Fall 1998 Fall 2001 Spring 2003medical treatment 414 46,064 627,522 1,539,367prostate cancer 39 40,772 518,393 1,478,366deep breath 732 54,550 170,921 868,631acrylic paint 30 7,208 43,181 151,525perfect balance 38 9,735 35,494 355,538electromagnetic radiation 39 17,297 69,286 258,186powerful force 71 17,391 52,710 249,940concrete pipe 10 3,360 21,477 43,267upholstery fabric 6 3,157 8,019 82,633vital organ 46 7,371 28,829 35,819338Computational Linguistics Volume 29, Number 3to 170,921 in 2001.
And in 2003, we could find 868,631 Web pages containing thecontiguous words deep breath according to AlltheWeb.
The numbers found through thesearch engines are more than three orders of magnitude higher than the BNC counts,giving a first indication of the size of the English corpus available on the Web.We can derive a more precise estimate of the number of words available througha search engine by using the counts of function words as predictors of corpus size.Function words, such as the, with, and in, occur with a frequency that is relativelystable over many different types of texts.
From a corpus of known size, we can cal-culate the frequency of the function words and extrapolate.
In the 90-million-wordwritten-English component of the BNC, the appears 5,776,487 times, around seventimes for every 100 words.
In the U.S.
Declaration of Independence, the occurs 84times.
We predict that the Declaration is about 84 ?
100/7 = 1,200 words long.
In fact,the text contains about 1,500 words.
Using the frequency of one word gives a firstapproximation.
A better result can be obtained by using more data points.From the first megabyte of the German text found in the European Corpus Ini-tiative Multilingual Corpus,5 we extracted frequencies for function words and othershort, common words.
We removed from the list words that were also common wordsin other languages.6 AltaVista provided, on its results pages, along with a page countfor a query, the number of times that each query word was found on the Web.7 Ta-ble 2 shows the relative frequency of the words from our known corpus, the indexfrequencies that AltaVista gave (February 2000), and the consequent estimates of thesize of the German-language Web indexed by AltaVista.We set aside words which give discrepant predictions (too high or too low) as (1)AltaVista does not record in its index the language a word comes from, so the countfor the string die includes both the German and English occurrences, and (2) a wordmight be under- or overrepresented in the training corpus or on the Web (considerhere, which occurs very often in ?click here?).
Averaging the remaining predictionsgives an estimate of three billion words of German that could be accessed throughAltaVista on the day in February 2000 that we conducted our test.Table 2Short German words in the ECI corpus and via AltaVista, giving German Web estimates.Word Known-Size-Corpus AltaVista Prediction forRelative Frequency Frequency German-Language Weboder 0.00561180 13,566,463 2,417,488,684sind 0.00477555 11,944,284 2,501,132,644auch 0.00581108 15,504,327 2,668,062,907wird 0.00400690 11,286,438 2,816,750,605nicht 0.00646585 18,294,174 2,829,353,294eine 0.00691066 19,739,540 2,856,389,983sich 0.00604594 17,547,518 2,902,363,900ist 0.00886430 26,429,327 2,981,546,991auf 0.00744444 24,852,802 3,338,438,082und 0.02892370 101,250,806 3,500,617,348Average 3,068,760,3565 ?http://www.elsnet.org/resources/eciCorpus.html?.6 These lists of short words and frequencies were initially used to create a language identifier.7 AltaVista has recently stopped providing information about how often individual words in a queryhave been indexed and now returns only a page count for the entire query.339Kilgarriff and Grefenstette Web as Corpus: IntroductionTable 3Estimates of Web size in words, as indexed by AltaVista, for various languages.Language Web SizeAlbanian 10,332,000Breton 12,705,000Welsh 14,993,000Lithuanian 35,426,000Latvian 39,679,000Icelandic 53,941,000Basque 55,340,000Latin 55,943,000Esperanto 57,154,000Roumanian 86,392,000Irish 88,283,000Estonian 98,066,000Slovenian 119,153,000Croatian 136,073,000Malay 157,241,000Turkish 187,356,000Language Web SizeCatalan 203,592,000Slovakian 216,595,000Polish 322,283,000Finnish 326,379,000Danish 346,945,000Hungarian 457,522,000Czech 520,181,000Norwegian 609,934,000Swedish 1,003,075,000Dutch 1,063,012,000Portuguese 1,333,664,000Italian 1,845,026,000Spanish 2,658,631,000French 3,836,874,000German 7,035,850,000English 76,598,718,000This technique has been tested on controlled data (Grefenstette and Nioche 2000)in which corpora of different languages were mixed in various proportions and foundto give reliable results.
Table 3 provides estimates for the number of words thatwere available in 30 different Latin-script languages through AltaVista in March 2001.English led the pack with 76 billion words, and seven additional languages alreadyhad over a billion.From the table, we see that even ?smaller?
languages such as Slovenian, Croatian,Malay, and Turkish have more than one hundred million words on the Web.
Much ofthe research that has been undertaken on the BNC simply exploits its scale and couldbe transferred directly to these languages.The numbers presented in Table 3 are lower bounds, for a number of reasons:?
AltaVista covers only a fraction of the indexable Web pages available(the fraction was estimated at just 15% by Lawrence and Giles [1999]).?
AltaVista may be biased toward North American (mainlyEnglish-language) pages by the strategy it uses to crawl the Web.?
AltaVista indexes only pages that can be directly called by a URL anddoes not index text found in databases that are accessible through dialogwindows on Web pages (the ?hidden Web?).
This hidden Web is vast(consider MedLine,8 just one such database, with more than five billionwords; see also Ipeirotis, Gravano, and Sahami [2001]), and it is notconsidered at all in the AltaVista estimates.Repeating the procedure after an interval, the second author and Nioche showedthat the proportion of non-English text to English is growing.
In October 1996 there8 ?http://www4.ncbi.nlm.nih.gov/PubMed/?.340Computational Linguistics Volume 29, Number 3Table 4AltaVista frequencies for candidate translations of groupe de travail.labor cluster 21labor grouping 28labour concern 45labor concern 77work grouping 124work cluster 279labor collective 423labour collective 428work collective 759work concern 772labor group 3,977labour group 10,389work group 148,331were 38 German words for every 1,000 words of English indexed by AltaVista.
InAugust 1999, there were 71, and in March 2001, 92.3.1 Finding the Right TranslationHow can these large numbers be used for other language-processing tasks?
Considerthe compositional French noun phrase groupe de travail.
In the MEMODATA bilingualdictionary,9 the French word groupe is translated by the English words cluster, group,grouping, concern, and collective.
The French word travail translates as work, labor, orlabour.
Many Web search engines allow the user to search for adjacent phrases.
Com-bining the possible translations of groupe de travail and submitting them to AltaVistain early 2003 yielded the counts presented in Table 4.
The phrase work group is 15times more frequent than any other and is also the best translation among the testedpossibilities.
A set of controlled experiments of this form is described in Grefenstette(1999).
In Grefenstette?s study, a good translation was found in 87% of ambiguouscases from German to English and 86% of ambiguous cases from Spanish to English.4.
RepresentativenessWe know the Web is big, but a common response to a plan to use the Web as acorpus is ?but it?s not representative.?
There are a great many things to be said aboutthis.
It opens up a pressing yet alost untouched practical and theoretical issue forcomputational linguistics and language technology.4.1 TheoryFirst, ?representativeness?
begs the question ?representative of what??
Outside verynarrow, specialized domains, we do not know with any precision what existing corporamight be representative of.
If we wish to develop a corpus of general English, wemay think it should be representative of general English, so we then need to definethe population of ?general English-language events?
of which the corpus will be asample.
Consider the following issues:?
Production and reception: Is a language event an event of speaking orwriting, or one of reading or hearing?
Standard conversations have, foreach utterance, one speaker and one hearer.
A Times newspaper articlehas (roughly) one writer and several hundred thousand readers.9 See ?http://www.elda.fr/cata/text/M0001.html?.
The basic multilingual lexicon produced byMEMODATA contains 30,000 entries for five languages: French, English, Italian, German, Spanish.341Kilgarriff and Grefenstette Web as Corpus: Introduction?
Speech and text: Do speech events and written events have the samestatus?
It seems likely that there are orders of magnitude more speechevents than writing events, yet most corpus research to date has tendedto focus on the more tractable task of gathering and working with text.?
Background language: Does muttering under one?s breath or talking inone?s sleep constitute a speech event, and does doodling with wordsconstitute a writing event?
Or, on the reception side, does passing (andpossibly subliminally reading) a roadside advertisement constitute areading event?
And what of having the radio on but not attending to it,or the conversational murmur in a restaurant??
Copying: if I?d like to teach the world to sing, and, like Michael Jackson orthe Spice Girls, am fairly successful in this goal and everyone sings mysong, then does each individual singing constitute a distinct languageproduction event?In the text domain, organizations such as Reuters produce news feedsthat are typically adapted to the style of a particular newspaper and thenrepublished: Is each republication a new writing event?
(These issues,and related themes of cut-and-paste authorship, ownership, andplagiarism, are explored in Wilks [2003].
)4.2 TechnologyApplication developers urgently need to know what to do about sublanguages.
Ithas often been argued that, within a sublanguage, few words are ambiguous, and alimited repertoire of grammatical structures is used (Kittredge and Lehrberger 1982).This points to sublanguage-specific application development?s being substantially sim-pler than general-language application development.
However, many of the resourcesthat developers may wish to use are general-language resources, such as, for English,WordNet, ANLT, XTag, COMLEX, and the BNC.
Are they relevant for building ap-plications for sublanguages?
Can they be used?
Is it better to use a language modelbased on a large general-language corpus or a relatively tiny corpus of the right kindof text?
Nobody knows.
There is currently no theory, no mathematical models, andalmost no discussion.A related issue is that of porting an application from the sublanguage for whichit was developed to another.
It should be possible to use corpora for the two sublan-guages to estimate how large a task this will be, but again, our understanding is inits infancy.4.3 Language ModelingMuch work in recent years has gone into developing language models.
Clearly, thestatistics for different types of text will be different (Biber 1993).
This imposes a lim-itation on the applicability of any language model: We can be confident only thatit predicts the behavior of language samples of the same text type as the training-data text type (and we can be entirely confident only if training and test samples arerandom samples from the same source).When a language technology application is put to use, it will be applied to newtext for which we cannot guarantee the text type characteristics.
There is little workon assessing how well one language model fares when applied to a text type that isdifferent from that of the training corpus.
Two studies in this area are Sekine (1997)and Gildea (2001), both of which show substantial variation in model performance342Computational Linguistics Volume 29, Number 3Table 5Hits for Spanish pensar que with and without possible ?dequeismos errors?
(spurious debetween the verb and the relative), from Alltheweb.com (March 2003).
Not all items are errors(e.g., ?.
.
.pienso de que manera.
.
.?
.
.
.
think how.
.
.).
The correct form is always at least 500times more common than any potentially incorrect form.pienso de que 388pienso que 356,874piensas de que 173piensas que 84,896piense de que 92piense que 67,243pensar de que 1,640pensar que 661,883when the training corpus changes.
The lack of theory of text types leaves us withouta way of assessing the usefulness of language-modeling work.4.4 Language ErrorsWeb texts are produced by a wide variety of authors.
In contrast to paper-based, copy-edited published texts, Web-based texts may be produced cheaply and rapidly withlittle concern for correctness.
On Google a search for ?I beleave?
has 3,910 hits, and?I beleive,?
70,900.
The correct ?I believe?
appears on over four million pages.
Table 5presents what is regarded as a common grammatical error in Spanish, comparing thefrequency of such forms to the accepted forms on the Web.
All the ?erroneous?
formsexist, but much less often than the ?correct?
forms.
The Web is a dirty corpus, butexpected usage is much more frequent than what might be considered noise.4.5 Sublanguages and General-Language-Corpus CompositionA language can be seen as a modest core of lexis, grammar, and constructions, plusa wide array of different sublanguages, as used in each of a myriad of human ac-tivities.
This presents a challenge to general-language resource developers: Shouldsublanguages be included?
The three possible positions are?
No, none should.?
Some, but not all, should.?
Yes, all should.The problem with the first position is that, with all sublanguages removed, theresidual core gives an impoverished view of language (quite apart from demarcationissues and the problem of determining what is left).
The problem with the second isthat it is arbitrary.
The BNC happens to include cake recipes and research papers ongastro-uterine diseases, but not car manuals or astronomy texts.
The third has not,until recently, been a viable option.4.6 LiteratureTo date, corpus developers have been obliged to make pragmatic decisions about thesorts of text to go into a corpus.
Atkins, Clear, and Ostler (1992) describe the desiderataand criteria used for the BNC, and this stands as a good model for a general-purpose,general-language corpus.
The word representative has tended to fall out of discussions,to be replaced by the meeker balanced.343Kilgarriff and Grefenstette Web as Corpus: IntroductionThe recent history of mathematically sophisticated modeling of language variationbegins with Biber (1988), who identifies and quantifies the linguistic features associatedwith different spoken and written text types.
Habert and colleagues (Folch et al 2000;Beaudouin et al 2001) have been developing a workstation for specifying subcorporaaccording to text type, using Biber-style analyses, among others.
In Kilgarriff (2001)we present a first pass at quantifying similarity between corpora, and Cavaglia (2002)continues this line of work.
As mentioned above, Sekine (1997) and Gildea (2001)directly address the relation between NLP systems and text type; one further such itemis Roland et al (2000).
Buitelaar and Sacaleanu (2001) explores the relation betweendomain and sense disambiguation.
A practical discussion of a central technical concernis Vossen (2001), which tailors a general-language resource for a domain.Baayen (2001) presents sophisticated mathematical models for word frequencydistributions, and it is likely that his mixture models have potential for modelingsublanguage mixtures.
His models have been developed with a specific, descriptivegoal in mind and using a small number of short texts: It is unclear whether they canbe usefully applied in NLP.Although the extensive literature on text classification (Manning and Schu?tze 1999,pages 575?608) is certainly relevant, it most often starts from a given set of categoriesand cannot readily be applied to the situation in which the categories are not known inadvance.
Also, the focus is usually on content words and topics or domains, with otherdifferences of genre or sublanguage remaining unexamined.
Exceptions focusing ongenre include Kessler, Nunberg, and Schu?tze (1997) and Karlgren and Cutting (1994).4.7 Representativeness: ConclusionThe Web is not representative of anything else.
But neither are other corpora, in anywell-understood sense.
Picking away at the question merely exposes how primitiveour understanding of the topic is and leads inexorably to larger and altogether moreinteresting questions about the nature of language, and how it might be modeled.
?Text type?
is an area in which our understanding is, as yet, very limited.
Althoughfurther work is required irrespective of the Web, the use of the Web forces the issue.Where researchers use established corpora, such as Brown, the BNC, or the PennTreebank, researchers and readers are willing to accept the corpus name as a label forthe type of text occurring in it without asking critical questions.
Once we move to theWeb as a source of data, and our corpora have names like ?April03-sample77,?
theissue of how the text type(s) can be characterized demands attention.5.
Introduction to Articles in This Special IssueOne use of a corpus is to extract a language model: a list of weighted words, orcombinations of words, that describe (1) how words are related, (2) how they areused with each other, and (3) how common they are in a given domain.
Languagemodels are used in speech processing to predict which word combinations are likelyinterpretations of a sound stream, in information retrieval to decide which words areuseful indicators of a topic, and in machine translation to identify good translationcandidates.In this volume, Celina Santamari?a, Julio Gonzalo, and Felisa Verdejo describe howto build sense-tagged corpora from the Web by associating word meanings with Webpage directory nodes.
The Open Directory Project (at ?dmoz.org?)
is a collaborative,volunteer project for classifying Web pages into a taxonomic hierarchy.
Santamari?a etal.
present an algorithm for attaching WordNet word senses to nodes in this sametaxonomy, thus providing automatically created links between word senses and Web344Computational Linguistics Volume 29, Number 3pages.
They also show how this method can be used for automatic acquisition ofsense-tagged corpora, from which one could, among other things, produce languagemodels tied to certain senses of words, or for a certain domain.Unseen words, or word sequences?that is, words or sequences not occurring intraining data?are a problem for language models.
If the corpus from which a particu-lar model is extracted is too small, there are many such sequences.
Taking the secondauthor?s work, as described above, as a starting point, Frank Keller and Mirella Lapataexamine how useful the Web is as a source of frequency information for rare items:specifically, for dependency relations involving two English words such as <fulfill OB-JECT obligation>.
They generate pairs of common words, constructing combinationsthat are and are not attested in the BNC.
They then compare the frequency of thesecombinations in a larger 325-million-word corpus and on the Web.
They find that Webfrequency counts are consistent with those for other large corpora.
They also reporton a series of human-subject experiments in which they establish that Web statisticsare good at predicting the intuitive plausibility of predicate-argument pairs.
Otherexperiments discussed in their article show that Web counts correlate reliably withcounts re-created using class-based smoothing and overcome some problems of datasparseness in the BNC.Other very large corpora are available for English (English is an exception), andthe other three papers in the special issue all exploit the multilinguality of the Web.Andy Way and Nano Gough show how the Web can provide data for an example-based machine translation (Nagao 1984) system.
First, they extract 200,000 phrasesfrom a parsed corpus.
These phrases are sent to three online translation systems.
Bothoriginal phrases and translations are chunked.
From these pairings a set of chunktranslations is extracted to be applied in a piecewise fashion to new input text.
Theauthors use the Web again at a final stage to rerank possible translations by verifyingwhich subsequences among the possible translations are most attested.The two remaining articles present methods for building aligned bilingual corporafrom the Web.
It seems plausible that such automatic construction of translation dic-tionaries can palliate the lack of translation resources for many language pairs.
PhilipResnik was the first to recognize that it is possible to build large parallel bilingualcorpora from the Web.
He found that one can exploit the appearance of languageflags and other clues that often lead to a version of the same page in a differentlanguage.10 In this issue, Resnik and Noah Smith present their STRAND system forbuilding bilingual corpora from the Web.An alternative method is presented by Wessel Kraaij, Jian-Yun Nie, and MichelSimard.
They use the resulting parallel corpora to induce a probabilistic translationdictionary that is then embedded into a cross-language information retrieval system.Various alternative embeddings are evaluated using the CLEF (Peters 2001) multilin-gual information retrieval test beds.6.
ProspectsThe default means of access to the Web is through a search engine such as Google.Although the Web search engines are dazzlingly efficient pieces of technology andexcellent at the task they set for themselves, for the linguist they are frustrating:10 For example, one can find Azerbaijan news feeds online at ?http://www.525ci.com?
in Azeri (writtenwith a Turkish code set), and on the same page are pointers to versions of the same stories in Englishand in Russian.345Kilgarriff and Grefenstette Web as Corpus: Introduction?
The search engine results do not present enough instances (1,000 or 5,000maximum).?
They do not present enough context for each instance (Google provides afragment of around ten words).?
They are selected according to criteria that are, from a linguisticperspective, distorting (with uses of the search term in titles andheadings going to the top of the list and often occupying all the topslots).?
They do not allow searches to be specified according to linguistic criteriasuch as the citation form for a word, or word class.?
The statistics are unreliable, with frequencies given for ?pages containingx?
varying according to search engine load and many other factors.If only these constraints were removed, a search engine would be a wonderfultool for language researchers.
Each of the constraints could straightforwardly be re-solved by search engine designers, but linguists are not a powerful lobby, and searchengine company priorities will never perfectly match our community?s.
This suggestsa better solution: Do it ourselves.
Then the kinds of processing and querying wouldbe designed explicitly to meet linguists?
desiderata, without any conflict of interest or?poor relation?
role.
Large numbers of possibilities open up.
All those processes oflinguistic enrichment that have been applied with impressive effect to smaller corporacould be applied to the Web.
We could parse the Web.
Web searches could be specifiedin terms of lemmas, constituents (e.g., noun phrase), and grammatical relations ratherthan strings.
The way would be open for further anatomizing of Web text types anddomains.
Thesauruses and lexicons could be developed directly from the Web.
Andall for a multiplicity of languages.11The Web contains enormous quantities of text, in numerous languages and lan-guage types, on a vast array of topics.
Our take on the Web is that it is a fabulouslinguists?
playground.
We hope the special issue will encourage you to come on outand play!ReferencesAgirre, Eneko, Olatz Ansa, Eduard Hovyand David Martinez.
2000.
Enriching verylarge ontologies using the WWW.
InProceedings of the Ontology LearningWorkshop of the European Conference of AI(ECAI), Berlin.Atkins, Sue.
1993.
Tools for computer-aidedcorpus lexicography: The Hector project.Acta Linguistica Hungarica, 41:5?72.Atkins, Sue, Jeremy Clear, and NicholasOstler.
1992.
Corpus design criteria.Literary and Linguistic Computing, 7(1):1?16.Baayen, Harald.
2001.
Word FrequencyDistributions.
Kluwer, Dordrecht.Baker, Collin F., Charles J. Fillmore, andJohn B. Lowe.
1998.
The BerkeleyFrameNet Project.
In Proceedings ofCOLING-ACL, pages 86?90, Montreal,August.Banko, Michele and Eric Brill.
2001.
Scalingto very very large corpora for naturallanguage disambiguation.
In Proceedings ofthe 39th Annual Meeting of the Association forComputational Linguistics and the10th Conference of the European Chapter of theAssociation for Computational Linguistics,Toulouse.Beaudouin, Vale?rie, Serge Fleury, Beno?
?tHabert, Gabriel Illouz, Christian Licoppe,and Marie Pasquier.
2001.
Typweb:de?crire la toile pour mieux comprendreles parcours.
In Colloque International surles Usages et les Services desTe?le?communications (CIUST?01), Paris,June.
Available at ?http://www.cavi.univ-11 The idea is developed further in Grefenstette (2001) and in Kilgarriff (2003).346Computational Linguistics Volume 29, Number 3paris3.fr/ilpga/ilpga/sfleury/typweb.htm?.Beesley, Kenneth R. 1988.
Languageidentifier: A computer program forautomatic natural-language identificationof on-line text.
In Language at Crossroads:Proceedings of the 29th Annual Conference ofthe American Translators Association, pages47?54, October 12?16.Biber, Douglas.
1988.
Variation across speechand writing.
Cambridge University Press,Cambridge.Biber, Douglas.
1993.
Usingregister-diversified corpora for generallanguage studies.
Computational Linguistics,19(2):219?242.Briscoe, Ted and John Carroll.
1997.Automatic extraction of subcategorizationfrom corpora.
In Proceedings of the FifthConference on Applied Natural LanguageProcessing, pages 356?363, Washington,DC, April.Buitelaar, Paul and Bogdan Sacaleanu.
2001.Ranking and selecting synsets by domainrelevance.
In Proceedings of the Workshop onWordNet and Other Lexical Resources:Applications, Extensions and Customizations,NAACL, Pittsburgh, June.Burnard, Lou.
1995.
The BNC ReferenceManual.
Oxford University ComputingService, Oxford.Cavaglia, Gabriela.
2002.
Measuring corpushomogeneity using a range of measuresfor inter-document distance.
In Proceedingsof the Third International Conference onLanguage Resources and Evaluation, pages426?431, Las Palmas de Gran Canaria,Spain, May.Church, Kenneth W. and Robert L. Mercer.1993.
Introduction to the special issue oncomputational linguistics using largecorpora.
Computational Linguistics,19(1):1?24.Dumais, Susan, Michele Banko, Eric Brill,Jimmy Lin, and Andrew Ng.
2002.
Webquestion answering: Is more alwaysbetter?
In Proceedings of the 25th ACMSIGIR, pages 291?298, Tampere, Finland.Fletcher, William.
2002.
Facilitatingcompilation and dissemination of ad-hocweb corpora.
In Teaching and LanguageCorpora 2002.
Available at ?http://miniappolis.com/KWiCFinder/KWiCFinder.html?.Folch, Helka, Serge Heiden, Beno?
?t Habert,Serge Fleury, Gabriel Illouz, Pierre Lafon,Julien Nioche, and Sophie Pre?vost.
2000.Typtex: Inductive typological textclassification by multivariate statisticalanalysis for NLP systemstuning/evaluation.
In Proceedings of theSecond Language Resources and EvaluationConference, pages 141?148, Athens,May?June.Fujii, Atsushi and Tetsuya Ishikawa.
2000.Utilizing the World Wide Web as anencyclopedia: Extracting termdescriptions from semi-structured text.
InProceedings of the 38th Meeting of the ACL,pages 488?495, Hong Kong, October.Gildea, Daniel.
2001.
Corpus variation andparser performance.
In Proceedings of theConference on Empirical Methods in NLP,Pittsburgh, PA.Greenwood, Mark, Ian Roberts, and RobertGaizauskas.
2002.
University of SheffieldTREC 2002 Q & A system.
In E. M.Voorhees and Lori P. Buckland, editors,The Eleventh Text Retrieval Conference(TREC-11), Washington.
U.S. GovernmentPrinting Office.Grefenstette, Gregory.
1995.
Comparing twolanguage identification schemes.
InProceedings of the Third InternationalConference on the Statistical Analysis ofTextual Data (JADT?95), pages 263?268,Rome, December 11?13.
Available at?www.xrce.xerox.com/competencies/content-analysis/publications/Documents/P49030/content/gg aslib.pdf?.Grefenstette, Gregory.
1999.
The WWW as aresource for example-based MT tasks.Paper presented at ASLIB ?Translatingand the Computer?
conference, London,October.Grefenstette, Gregory.
2001.
Very largelexicons.
In Walter Daelemans, KhalilSimaan, Jakub Zavrel, and Jorn Veenstra,editors, Computational Linguistics in theNetherlands 2000: Selected Papers from theEleventh CLIN Meeting, Language andComputers 37.
Rodopi, Amsterdam.Grefenstette, Gregory and Julien Nioche.2000.
Estimation of english andnon-english language use on the WWW.In Proceedings of the RIAO (Recherched?Informations Assiste?e par Ordinateur),pages 237?246, Paris.Hawking, D., E. Voorhees, N. Craswell, andP.
Bailey.
1999.
Overview of the TREC8Web track.
In Proceedings of the Eighth TextRetrieval Conference, Gaithersburg,Maryland, November.Ipeirotis, Panagiotis G., Luis Gravano, andMehran Sahami.
2001.
Probe, count, andclassify: Categorizing hidden Webdatabases.
In Proceedings of the SIGMODConference, Santa Barbara, CA.Jones, Rosie and Rayid Ghani.
2000.Automatically building a corpus for aminority language from the Web.
InProceedings of the Student Workshop of the38th Annual Meeting of the Association for347Kilgarriff and Grefenstette Web as Corpus: IntroductionComputational Linguistics, Hong Kong,pages 29?36.Karlgren, Jussi and Douglass Cutting.
1994.Recognizing text genres with simplemetrics using discriminant analysis.
InProceedings of COLING-94, pages1071?1075, Kyoto, Japan.Kessler, Brett, Geoffrey Nunberg, andHinrich Schu?tze.
1997.
Automaticdetection of text genre.
In Proceedings ofACL and EACL, pages 39?47, Madrid.Kilgarriff, Adam.
2001.
Comparing corpora.International Journal of Corpus Linguistics,6(1):1?37.Kilgarriff, Adam.
2003.
Linguistic searchengine.
In Kiril Simov, editor, ShallowProcessing of Large Corpora: Workshop Held inAssociation with Corpus Linguistics 2003,Lancaster, England, March.Kilgarriff, Adam and Michael Rundell.
2002.Lexical profiling software and itslexicographical applications?A casestudy.
In Proceedings of EURALEX ?02,Copenhagen, August.Kittredge, Richard and John Lehrberger.1982.
Sublanguage: Studies of Language inRestricted Semantic Domains.
De Gruyter,Berlin.Korhonen, Anna.
2000.
Using semanticallymotivated estimates to helpsubcategorization acquisition.
InProceedings of the Joint Conference onEmpirical Methods in NLP and Very LargeCorpora, pages 216?223, Hong Kong,October.Lawrence, Steve and C. Lee Giles.
1999.Accessibility of information on the Web.Nature, 400:107?109.Manning, Christopher and Hinrich Schu?tze.1999.
Foundations of Statistical NaturalLanguage Processing.
MIT Press, Cambridge.McEnery, Tony and Andrew Wilson.
1996.Corpus Linguistics.
Edinburgh UniversityPress, Edinburgh.Mihalcea, Rada and Dan Moldovan.
1999.
Amethod for word sense disambiguation ofunrestricted text.
In Proceedings of the 37thMeeting of ACL, pages 152?158, CollegePark, MD, June.Nagao, Makoto.
1984.
A framework of amechanical translation between Japaneseand English by analogy principle.
In AlickElithorn and Ranan Banerji, editors,Artificial and Human Intelligence.North-Holland, Edinburgh, pages 173?180.Peters, Carol, editor.
2001.
Cross-LanguageInformation Retrieval and Evaluation,Workshop of Cross-Language Evaluation Forum(CLEF 2000) Lisbon, Portugal, September21?22, 2000, Revised Papers.
Lecture Notesin Computer Science.
Springer-Verlag.Resnik, Philip.
1999.
Mining the Web forbilingual text.
In Proceedings of the 37thMeeting of ACL, pages 527?534, CollegePark, MD, June.Rigau, German, Bernardo Magnini, EnekoAgirre, and John Carroll.
2002.
Meaning:A roadmap to knowledge technologies.
InProceedings of COLING Workshop on ARoadmap for Computational Linguistics,Taipei, Taiwan.Roland, Douglas, Daniel Jurafsky, LiseMenn, Susanne Gahl, Elizabeth Elder, andChris Riddoch.
2000.
Verbsubcategorization frequency differencesbetween business-news and balancedcorpora: The role of verb sense.
InProceedings of the Workshop on ComparingCorpora, 38th ACL, Hong Kong, October.Sekine, Satshi.
1997.
The domaindependence of parsing.
In Proceedings ofthe Fifth Conference on Applied NaturalLanguage Processing, pages 96?102,Washington, DC, April.Sinclair, John M., editor.
1987.
Looking Up:An Account of the COBUILD Project inLexical Computing.
Collins, London.Varantola, Krista.
2000.
Translators anddisposable corpora.
In Proceedings of CULT(Corpus Use and Learning to Translate),Bertinoro, Italy, November.Villasenor-Pineda, L., M. Montes y Go?mez,M.
Pe?rez-Coutino, and D. Vaufreydaz.2003.
A corpus balancing method forlanguage model construction.
In FourthInternational Conference on Intelligent TextProcessing and Computational Linguistics(CICLing-2003), pages 393?401, MexicoCity, February.Volk, Martin.
2001.
Exploiting the WWW asa corpus to resolve PP attachmentambiguities.
In Proceedings of CorpusLinguistics 2001, Lancaster, England.Vossen, Piek.
2001.
Extending, trimmingand fusing WordNet for technicaldocuments.
In Proceedings of the NAACL2001 Workshop on WordNet and Other LexicalResources, Pittsburgh, June.
Available at?http://engr.smu.edu/?rada/mwnw/papers/WNW-NACL-205.pdf.gz?.Wilks, Yorick.
2003.
On the ownership oftext.
Computers and the Humanities.Forthcoming.Xu, J. L. 2000.
Multilingual search on theWorld Wide Web.
In Proceedings of theHawaii International Conference on SystemScience (HICSS-33), Maui, Hawaii, January.Zheng, Zhiping.
2002.
AnswerBus questionanswering system.
In E. M. Voorhees andLori P. Buckland, editors, Proceedings ofHLT Human Language Technology Conference(HLT 2002), San Diego, CA, March 24?27.
