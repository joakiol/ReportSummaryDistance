Corpus-Centered ComputationEiichiro SUMITAATR Spoken Language Translation Research Laboratories2-2 Hikaridai, Seika, SourakuKyoto 619-0288, JAPANhttp://www.atr.co.jp/slteiichiro.sumita@atr.co.jpAbstractTo achieve translation technology thatis adequate for speech-to-speechtranslation (S2S), this paper introducesa new attempt named Corpus-CenteredComputation, (abbreviated to C3 andpronounced c-cube).
As opposed toconventional approaches adopted bymachine translation systems forwritten language, C3 places corpora atthe center of the technology.
Forexample, translation knowledge isextracted from corpora, translationquality is gauged by referring tocorpora and the corpora themselves arenormalized by paraphrasing orfiltering.
High-quality translation hasbeen demonstrated in the domain oftravel conversation, and the prospectsof this approach are promising due tothe benefits of synergistic effects.1IntroductionText-based MT systems are not suitable forspeech-to-speech translation (S2S) partlybecause they have not been designed to cope withthe deviations from conventional grammar thatcharacterize spoken language input and partlybecause they have been designed to be as generalas possible to cover as many domains as possible.Consequently, the translation quality is not good1enough for S2S purposes.
Furthermore, sincesuch systems have been constructed by humanexperts, the development of machine translation21 For our travel domain, a famous translation systemon the WEB between Japanese and English produceda good translation for only about 10~20% of our testsentences.systems and porting them to different domainsare expensive and snail-paced processes.This paper introduces a new attemptnamed Corpus-Centered Computation,(abbreviated to C3 and pronounced c-cube).
C3places corpora at the center of the technology,where, for example, translation knowledge isextracted from corpora, translation quality isgauged by referring to corpora, and the corporathemselves are normalized by paraphrasing orfiltering.C3 has demonstrated its ability to providehigh-quality translation.
The construction is doneby machine, allowing quick and low-costdevelopment.Section 2 introduces the corpus we arecurrently dealing with, Section 3 briefly explainsour three corpus-based machine translationsystems, Section 4 demonstrates the first roundof competition between the three systems on thesame corpus, Section 5 touches on the automaticselection of the best translation, Section 6introduces a combination of corpus-basedprocesses, such as translation and paraphrasing,Section 7 discusses the implications of ourapproach, and finally Section 8 concludes thepaper.The CorpusWe are aiming at the development of a S2Ssystem to be used in place of a phrasebook byforeign tourists.
Table 1 shows the English partof some sample translation pairs from ourJapanese and English corpus.Table 2 compares our corpus with twoother spoken language corpora developed byATR (Takezawa, T. et al, 2002) and Verbmobil(Ney, H. et al, 2000).2 Our corpus has the shortest2 J, E, and G stand for Japanese, English, and German.Association for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
1-8.Proceedings of the Workshop on Speech-to-Speech Translation:average sentence length.
On the other hand, it isrich in topics and thus has the largest vocabularyand volumes.Table 1.
Sample English sentences in our corpusI want to buy a roll of film.I?d like to reserve a table for eight.Do you have some tea?I?d like to return the car.You need to cross the bridge to go there.My friend was hit by a car and badly injured.Table 2.
Comparison with other bilingual spokenlanguage corporaATR/dialogueOur corpus Verbmobil#Sent.
16,110 204,108 58,332#Word (J) 231,267 (J) 1,689,449 (G) 519,523(E) 181,263 (E) 1,235,747 (E) 549,921Voc.
(J) 4,895 (J) 19,640 (G) 7,940(E) 4,032 (E) 15,374 (E) 4,673Length (J) 14.3 (J) 8.3  (G) 8.9(E) 11.3 (E) 6.1 (E) 9.4Three Corpus-based MachineTranslation Systems33.1Research on corpus-based translation is agrowing trend and has become indispensable tothe MT industry.There are two main strategies used incorpus-based translation:1.
Example-Based Machine Translation(EBMT): EBMT uses the corpus directly.EBMT retrieves the translation examples thatare best matched to an input expression andadjusts the examples to obtain the translation(Nagao, 1984; Somers, 1999).2.
Statistical Machine Translation (SMT): SMTlearns models for translation from corporaand dictionaries and searches at run-time forthe best translation according to the models(Brown et al, 1993; Knight, 1997; Ney et al,2000).We have developed two EBMT systems and oneSMT system.An EBMT, D3Sumita (2001) proposed D3 (Dp-match DriventransDucer).
The characteristics of D3 aredifferent from previous EBMT approaches: a)Most EBMT proposals assume syntactic parsingand bilingual tree-banks, but D3 does not; b)Most EBMT proposals divide the translationprocess in two, i.e.
learning of translationpatterns in advance and application of thetranslation patterns, but D3 generates translationpatterns on the fly according to the input and theretrieved translation examples as needed.As shown in Figure 1, our languageresources are [i] a bilingual corpus, in whichsentences are aligned beforehand; [ii] a bilingualdictionary, which is used for generating targetsentences; and [iii] thesauri of both languages,which are used for incorporating the semanticdistance between words into the distancebetween word sequences.
Furthermore, [ii] and[iii] are also used for word alignment.GenerateSelectSubstituteRetrieve AlignedBilingualCorpus[i]Sentence[ii]BilingualDictionary[iii]ThesauriInputsentenceTargetsentenceFigure 1.
ConfigurationSuppose we are translating a Japanese sentenceinto English.
Let?s review the process with asimple sample below.
The Japanese input (1-j) istranslated into English (1-e) by utilizing (2-e),whose source (2-j) is similar to (1-j).
Thecommon parts are unchanged, and the differentportions are substituted by consulting a bilingualdictionary.
;;;A Japanese input(1-j) iro/ga/ki/ni/iri/masen;;; Japanese part of an example in corpus [i](2-j) dezain/ga/ki/ni/iri/masen;;; English part of an example in corpus [i](2-e) I do not like the design.
;;; the English output(1-e) I do not like the color.We retrieve the most similar source sentence ofexamples from a bilingual corpus.
For this, weuse DP-matching, which tells us the distancebetween word sequences, dist while giving us thematched portions between the input and theexample.
According to equation [1], dist, iscalculated.
The counts of the Insertion (I),Deletion (D), and substitution operations aresummed.
Then, this total is normalized by thesum of the lengths of the source and examplesequences.
According to equation [2],substitution considers the semantic distance,SEMDIST, between two substituted words.
[1]exampleinput LLSEMDISTDIdist2[2]NKSEMDIST Figure 2 illustrates the SEMDIST calculationbetween ?potato?
and ?beef.?
The most specificcommon abstraction of the two words is?ingredients,?
as shown in boldface.
TheSEMDIST is K divided by N in the figure.
K isthe level of the most specific common abstractionof two words, and N is the height of thethesaurus.fruitapple carrot potato beef chicken orangevegetable meatingredientsfoodTOPK Nmost specific common abstractionFigure 2.
SEMDIST calculated using thesaurusLet us show the latest performance of D3.The translation speed is sufficiently fast in thatthe average translation time is 0.04 seconds persentence with the 200 K corpus shown in Section2.
The translation quality is so high that themethod can achieve a TOEIC score3 of 750.
Thisis equivalent to the average score of a Japanesebusinessperson in overseas department ofJapanese corporations.3.23  The TOEIC (Test of English for InternationalCommuncation) test is an English languageproficiency test for people whose native language isnot English (http://www.chauncey.com/).
The Totalscore ranges from 10 to 990.
ATR has developed amethod to measure the TOEIC score of a machinetranslation system.
(Sugaya et al, 2000)In brief, D3 uses DP-matching, whichfeatures the semantic distance between words.
D3has demonstrated good quality and shortturnaround in travel conversations such as thosein a phrasebook.EBMT and SMT based on HierarchicalPhrase Alignment (HPA)Here we intoroduce Hierarchical PhraseAlignment (HPA) and its application to EBMTand SMT.3.2.1 Hierarchical Phrase Alignment (HPA)This subsection introduces a new phrasealignment approach (Imamura, 2001) calledHierarchical Phrase Alignment (HPA).I have arrivejus in New Yorkni desuNewYork tatsui bakariVPVP(3)(3)VPAUXVPSVPAUXVPS(4)(5)(6)(4)(5)(6)NPVMPNP(1)(2)(1)(2)VMPFigure 3.
Bilingual trees and alignmentFirst, two sentences are tagged and parsedindependently.
This operation obtains twosyntactic trees.
Next, words are linked by theword alignment program.
Then, HPA retrievesequivalent phrases that satisfy two conditions: 1)words in the pair correspond with no deficiencyand no excess; 2) the phrases are of the samesyntactic category.Let?s look at a sample pair of a Japanesetree and the corresponding English tree (Figure3).
The retrieval of equivalent phrases is done ina bottom-up fashion.
First, the syntactic node pairthat consists of only the ?New York?
and?NewYork?
link, having the same syntacticcategory, is retrieved.
Then, NP(1) and VMP(2)are found.
Next, the syntactic node pair thatconsists of only the ?arrived?
and ?tsui?
link,having the same syntactic category, is retrieved.Then, VP(3) is found.
Finally, the syntactic nodepairs that include two word links having the samesyntactic category are retrieved.
Then VP(4),AUXVP(5), and S(6) are found.
Accordingly, sixequivalent phrases are hierarchically extracted.3.2.2 EBMT based on HPAImamura (2002) proposed an application of HPAin EBMT called HPA-based translation (HPAT).HPAed bilingual trees include all informationnecessary to automatically generate transferpatterns.
Translation is done according to transferpatterns using the TDMT engine (Sumita et al,1999), our previous EBMT system.
First, thesource part of transfer patterns are utilized, andsource structure is obtained.
Second, structuralchanges are performed by mapping sourcepatterns to target patterns.
Finally, lexical itemsare inserted by referring to a bilingual dictionary,and then a conventional generation is performed.HPAT achieved about 70% accuracy.3.2.3 SMT based on HPAStatistical machine translation (SMT) representsa translation process as a noisy channel modelthat consists of a source-channel model and alanguage model of the target language.The translation model is based onword-for-word translation and limited to allowonly one channel source word to be aligned froma channel target word.
Although phrasalcorrespondence is implicitly implemented insome translation models by means of distortion,careful parameter training is required.In addition, the training procedure relieson the EM algorithm, which can converge to anoptimal solution but does not assure the globalmaximum parameter assignment.
Furthermore,the numbers of parameters represent thetranslation models, so that easily suffered fromthe over-fitting problem.
In order to overcomethese problems, simpler models, such asword-for-word translation models (Brown et al,1993) or HMM models (Och et al, 2000), havebeen introduced to determine the initialparameters and to bootstrap the training.We have proposed two methods toovercome the above problems by using HPA.
(1)The first method converts the hierarchicallyaligned phrasal texts into a pair of sequences ofchunks of words, treating the word-for-wordtranslation model as a chunk-for-chunktranslation model.
(2) The second methodcomputes the parameters for the translationmodel from the computed phrase alignments anduses the parameters as a starting point for trainingiterations.The experimental results onJapanese-to-English translation indicated that themodel trained from the parameters derived fromthe HPA could improve the quality of translation(Watanabe et al, 2002a).44.14.2Competition between the ThreeMTs on Same CorpusCompetition ConditionsWe used the corpus shown in Section 2, which isa collection of Japanese sentences and theirEnglish translations, typically found inphrasebooks for foreign tourists.
We lemmatizedand POS-tagged both the Japanese and Englishsentences.
A quality evaluation was done for thetest set consisting of 510 sentences selectedrandomly from the above corpus, and theremaining sentences were used for learning andverification.We also used a bilingual dictionarypreviously developed for TDMT.
The size of thedictionary is 24,658 words.
We used thesauriwhose hierarchies are based on the KadokawaRuigo-shin-jiten (Ohno and Hamanishi, 1984).The size of the Japanese thesaurus is 21,608 andthat of the English thesaurus is 11,359.ResultsSMT has been applied to language pairs ofsimilar European languages.
We implementedSMT for translation between Japanese andEnglish, which are dissimilar in many pointssuch as word order.
Table 3 shows the accuracyof our SMT system.
The four ranks are defined asfollows (Sumita et al, 1999): (A) Perfect: noproblems in both information and grammar; (B)Fair: easy-to-understand, with either someunimportant information missing or flawedgrammar; (C) Acceptable: broken, butunderstandable with effort; (D) Nonsense:important information has been translatedincorrectly.
It worked in both J-to-E and E-to-Jdirections 4  in spite of the negative opinionspreviously expressed.Table 3.
SMT worked for J and ERank(s) A A+B A+B+CSMT(JE) 25% 46% 64%SMT(EJ) 41% 48% 57%We implemented two EBMT systems, D3and HPAT, using the same corpus.
D3 and HPATsurpassed SMT in the travel conversation task(Tables 3 and 4).Table 4.
EBMTs on the same corpusRank(s) A A+B A+B+CD3(JE) 47% 66% 77%HPAT(EJ) 50% 61% 71%Finally, it became clear that word-basedSMT, a revival of the direct method of the ?50s, issuitable for pairs of European languages but notfor Japanese and English.
This is becauseword-based SMT cannot capture the majordifferences such as word order between Japaneseand English.Several organizations (Yamada et al,2001; Alshawi et al,  2000) are pursuingsyntax-based SMT.
We plan to join the race.Which is suitable for Japanese and English,syntax-based SMT or EBMT?55.1Combination of Evaluation andTranslationWe are researching automatic evaluation ofmachine translation outputs and multipleparadigms for machine translationsimultaneously.
Together, they have synegisticeffects as explained below.Automatic Quality Evaluation UsingCorpus5.24 For this test set, the accuarcy of SMT is at leasttwice as good as that of a famous conventionalmachine translation system on the WEB.Translation quality has conventionally beenevaluated by hand.
Likewise, we have evaluatedthe outputs of our translation systemssubjectively with four ranks from ?good?
to?bad?
: A, B, C, and D (Sumita et al, 1999).Such subjective evaluation by ranking,however, is taxing on both time and resources.
Ifautomatic evaluation methods are inexpensive,fast, and sufficiently accurate, then suchautomatic evaluation methods would provebeneficial.Conventional approaches to automaticevaluation include methods (Su, 1992; Yasuda etal., 2001) that automatically assign one of severalranks  to MT output according to a single editdistance between an MT output and a correcttranslation example.To improve performance, we proposedan automatic ranking method that, by usingmultiple edit distances, encodesmachine-translated sentences with a rankassigned by humans into multi-dimensionalvectors from which a classifier of ranks is learnedin the form of a decision tree.
The proposedmethod assigns a rank to MT output through thelearned decision tree (Akiba et al, 2001).Experimental results show that theproposed method is more accurate than thesingle-edit-distance-based ranking methods inboth closed and open tests.
The proposed methodhas the potential to accurately estimate thequality of outputs of machine translationsystems.Multiple-engine Machine TranslationSystemEvery researcher has his own way of acquiringtranslation knowledge by generalizing translationinstances in a corpus.
Our approach is noexception to this rule.
Our MTs are based ondifferent paradigms, different development styles,and different development periods.
This resultsin various behaviors for each input sentence, andthe translation rank of a given input sentencechanges system-by-system.Table 5.
Sample of transaltion variety with qualityranko-shiharai wa genkin desu ka kurejitto kaado desu ka[B] Is the payment cash?
Or is it the credit card?
[A] Would you like to pay in cash or with a credit card?
[C] Could you cash or credit card?We show a sample of different Englishtranslations obtained by three systems for aJapanese sentence (Table 5).
The brackets showthe quality rank judged by a human translator.Translation systems gain A-rankedtranslations in different subsets of inputsentences as illustrated in Figure 4.
Thus, wecould obtain a large increase in accuracy by usingan ?ideal?
MT, if it were possible to select thebest one of the three different translations foreach input sentence.MT1MT2 MT3Figure 4.
Subsets of input sentences whosetranslation is A-rankedWe are investigating methods to utilizetechniques of automatic evaluation for selector(Figure 5).MT1MT2MT3SelectorFigure 5.
Selector for multi-engine MTIn our pilot experiment, our selectors (Akiba etal., 2002; Yasuda et al, 2002) outperformed notonly the component systems but also aconventional selector using N-gram(Callison-Burch et al,  2001).Combination of Paraphrasingand Translation66.1We are automating extraction of paraphraseknowledge from a bilingual corpus.
In thissection, we introduce its application to improvethe performance of corpus-based translation byusing SMT as a touchstone.Extraction of Synonymous ExpressionsWe propose an automatic paraphrasing methodthat exploits knowledge from bilingual corpora(Shimohata et al, 2002).Synonymous expressions are defined as asequence of variant words with surroundingcommon words.
The expressions are extractedfrom bilingual corpora by the followingprocedures (Figure 6):1.
Collect sentences that share the sametranslation in another language.
Theaccumulated sentences are defined assynonymous sentences.2.
For all pairs of synonymous sentences, applyDP-matching and collect sequences of words,synonymous expressions that consist ofvariant words preceded/followed by commonwords.3.
Remove pairs of synonymous expressionswith a frequency lower than a giventhreshold.4.
Cluster the pairs of synonymous expressionsby transitive relation.<s> how would you like ?
</s><s> ?
wa dou nasai masu </s><s> how long will ?
</s>  <s> dore kurai ?
</s><s> how much ?
</s><s> ikura ?
</s><s> would you like ?
</s><s> do you like ?
</s><s> what would you like ?
</s><s> how do you like ?
</s><s> would you like ?|             |     |<s> do      you like ?<s>         would you like ?|             |       |     |<s> what would you like ?<s> would you<s> do you<s> would       <s> what would you<s> would you<s> how do you<s> would you<s> how do you<s> do youCluster of synonymous expressionsSynonymous expressionsDP-matchingSynonymous sentencesBilingual corpus<s>?wa ikaga desu ka </s>Figure 6.
Extraction of synonymous expressions6.2 Corpus NormalizationAfter the acquisition of clusters of synonymousexpressions, normalization is carried out bytransforming the expressions into major ones,selected according to their frequency in thecorpora.
For instance, the cluster obtainedconsists of the expressions ?<s> would you,?
?<s>how do you?
and ?<s> do you.?
Suppose that anexpression ?<s> do you?
occurred mostfrequently in a given corpus, an input ?how doyou like your coffee?
could be normalized into?do you like your coffee.
?6.377.17.28SMT on Normalized CorpusStatistical approach to machine translationdemands huge bilingual corpora in good qualityand broad coverage.
However, such an idealcorpus is not usually available: one may contain asufficiently large number of samples, for instance,derived from web pages with translations, butthese may not be well-aligned or have lowtranslation quality.
Others may consist ofhigh-quality translations but have a limitednumber of examples.
In addition, the variety ofpossible translations makes it even harder toestimate parameters for statistical-based machinetranslation.We propose a way to overcome theseproblems by creating a corpus that consists ofnormalized expressions, expressions with lessvariety, through automated paraphrasing(Watanabe et al, 2002b).
As described above, bythe method of transforming target sentences of agiven bilingual corpus into a normalized form isexpected to improve the parameter estimation fora statistical machine translation model.
Thenormalization method proposed above locallyreplaces word sequences, hence will not affectthe syntactical coherence.
Therefore,normalization will not affect the distortion model,which accounts for reordering of bilingual texts.In addition, reduction of the vocabulary size willgreatly help improve the parameter estimationfor lexical models.The experimental results onJapanese-to-English translation indicated that theSMT created on the target normalized sentencesreduced word-error-rate from 66% to 58%.DiscussionsForecasting from the ObtainedPerformanceAs a component of C3, D3 has achieved a highTOEIC score.
We foresee much higher scores forC3 because it features a multi-engine and selectorscheme, which is an easy, quick and low-costmethod of improving total performance, sincethere is no need to investigate the messyrelationships between resources and processes ofthe component systems by hand.Backcasting from the Future S2S System inthe Real WorldWe are aiming to develop technologies for S2Sthat are usable in real-world environments.
Noone knows what the real world will be, but thereis no doubt that an S2S system should deal withvariations in length and expressions beyond ourcorpus that explained in Section 2.
In other words,we divided our ?real-world?
goal into threesub-goals; (1) translation of short and editedsentences; (2) translation of long sentences; (3)translation of short but non-edited sentences; and(4) combining solutions for these sub-goalsseamlessly.Since we are centering our approaches oncorpora, we are developing corpora for achievingsub-goals (1), (2) and (3) as reported in(Takezawa et al, 2002; Sugaya et al, 2002) .For sub-goal (1), we are using a selectorfor multiple engines, for sub-goal (2), we have todevise methods to chunk long sentences intoappropriate translation units, and for sub-goal (3)we need a powerful automatic paraphraser.ConclusionsOur attempt called C3 places corpora at the centerof S2S technology.
All components of C3 arecorpus-based as shown in the paper.
If we havesufficient volumes of sentence-aligned bilingualcorpora, we would be able to build a high-qualityMT.
Corpus-based processes for such tasks astranslation, evaluation, and paraphrasing havesynergistic effects.
Therefore, we are optimisticabout the progress of components and theirintegration in C3.AcknowledgementsThe author?s heartfelt thanks go to Kadokawa-Shotenfor providing the Ruigo-Shin-Jiten.
The researchreported here was supported in part by a contract withthe Telecommunications Advancement Organizationof Japan entitled, "A study of speech dialoguetranslation technology based on a large corpus.
"ReferencesAkiba, Y., Imamura, K. and Sumita, E.  2001Using multiple Edit Distances to automaticallyrank machine translation output, Proc.
ofMT-SUMMIT-VIIIAkiba, Y., Watanabe, T. and Sumita, E.  2002Using Language and Translation Models to Selectthe Best among Outputs from Multiple MTsystems, Proc.
of Coling (to appear)Alshawi, H., Bangalore, S. and Douglas, S. 2000Learning Dependency Translation Models asCollections of Finite-State Head Transducers,Computational Linguistics, 26 (1), pp.
45--60.Brown, P., Cocke, J.,  Della Pietra, S. A.,  DellaPietra, V. J., Jelinek, F., Laffetry, J. D., Mercer, R.L.
and Roossin, P. S.  1993 A Statistical Approachto Machine Translation, ComputationalLinguistics 16, pp.
79--85Callison-Burch, C. and Flournoy, S.  2001 AProgram for Automatically Selecting the BestOutput from Multiple Machine TranslationEngines, Proc.
of MT-SUMMIT-VIIIImamura, K. 2001 Hierarchical phrase alignmentharmonized with parsing, Proc.
of NLPRS, pp.377--384Imamura, K. 2002 Application of TranslationKnowledge Acquired by Hierarchical PhraseAlignment, Proc.
of TMIKnight, K. 1997, Automating KnowledgeAcquisition for Machine Translation, AIMagazine, 18 (4), pp.
81--96Nagao, M. 1984 A Framework of a MechanicalTranslation between Japanese and English byAnalogy Principle, in A. Elithorn and R. Banerji(eds), Artificial and Human Intelligence,Amsterdam: North-Holland, pp.
173--180.Ney, H., Och, F. J. and Vogel, S. 2000 StatisticalTranslation of Spoken Dialogues in the VermobilSystem, Proc.
of MSC2000, pp.
69--74.Och et al 2000.
Improved statistical alignmentmodels.
In Proc.
of ACL, pp.
440--447, HongKong, China, OctoberOhno, S. and Hamanishi, M. 1984.Ruigo-Shin-Jiten, Kadokawa, Tokyo (in Japanese)Shimohata, M. and Sumita, E. 2002 Automaticparaphrasing based on parallel corpus fornormalization, Proc.
of LRECSomers, H. 1999 Review Article: Example-basedMachine Translation, Journal of MachineTranslation, pp.
113--157Su, K. -Y, Wu, M. -W. and Chang, J.
?S.
1992 Anew quantitative quality measure for machinetranslation systems, Proc.
of Coling, pp.
433--439Sugaya, F., Takezawa, T., Yokoo, A., Sagisaka, Y,and Yamamoto, S. 2000 Evaluation of theATR-MATRIX Speech Translation System with aPair Comparison Method Between the System andHumans, Proc.
of ICSLP, pp.
1105--1108Sugaya, F. et al 2002 Proposal for a verylarge-corpus acquisition method by registering intree-structure form, Proc.
of LRECSumita, E. 2001 Example-based machinetranslation using DP-matching between wordsequences, Proc.
of DDMT (ACL), pp.
1--8Sumita, E., Yamada, S., Yamamoto, K., Paul, M.,Kashioka, H., Ishikawa, K. and Shirai, S.  1999Solutions to Problems Inherent inSpoken-language Translation: TheATR-MATRIX Approach, Proc.
of MT SummitVII, pp.
229--235Takezawa, T. et al 2002 Toward aBroad-coverage Bilingual Corpus for SpeechTranslation of Travel Conversations in the RealWorld, Proc.
of  LRECYamada et al 2001 A Syntax-Based StatisticalTranslation Model.
Proc.
of ACL, FranceYasuda, K., Sugaya, F., Takezawa, T., Yamamoto,S.
and Yanagida, M. 2001 An automaticevaluation method of translation quality usingtranslation answer candidates queried from aparallel corpus, Proc.
of MT-SUMMIT-VIIIYasuda, K., Sugaya, F., Takezawa, T., Yamamoto,S.
and Yanagida, M. 2002 Automatic MachineTranslation Selection Scheme to Output the BestResult, Proc.
of LRECWatanabe, T., Imamura, K. and Sumita, E. 2002aStatistical Machine Translation Based OnHierarchical Phrase Alignment, Proc.
of TMIWatanabe, T., Shimohata, M. and Sumita, E.2002b Statistical Machine Translation Based OnParaphrased Corpora, Proc.
of LREC
