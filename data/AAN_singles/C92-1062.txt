A Chart-based Method of ID /LP  Parsingwith Generalized Discrimination NetworksSurapant  Meknav in  Manabu Okumura  Hozumi  Ta~mkaDepar tment  of  Computer  Science,Tokyo  Ins t i tu te  of Techno logy2-12-1, O-oknyama,  Meguro -ku ,  Tokyo  152, Japane -mai l  surapan@cs .
t i tech .ac .
jp1 In t roduct ionVariations of word order are among themost well-known phenomena of natural lan-guages.
From st well represented sample ofworld languages, Steele\[13\] shows that about76% of languages exhibit significant wordorder variation.
In addition to the well-known Walpiri(Australian language), severallanguages uch as Japanese, Thai, German,Hindi, and Finnish also allow considerableword order variations.
It is widely admit-ted that such variations are" governed bygeneralizations that should be expressed bythe grammars.
Generalized Phrase StructureGrammar (GPSG)\[7\] provides a method toaccount for these generalizations by decom-posing the grammar rules to Immediate Dom-inance(ID) rules and Linear Preeedence(LP)rules.
Using ID/LP formalism, the flexibleword order languages can be concisely andmore easily described.
However, designingan efficient algorithm to pnt the seperatedcomponents back in real parsing is a difficultproblem.Given a set of ID/LP rules, one alter-native method for parsing is to compile itinto another grammar description language,e.g.
Context-Free Grammar(CFG), for whichthere exist some parsing algorithms.
How-ever, the received object grammar tends tobe so huge and can slow down the parsingtime dramatically.
Also, the method losts themodularity of ID/LP formalism.Another set of approaches\[ll, 4  11 triesto keep ID and LP rules as they are, with-out expanding them out to other formalisms.Shieber\[ll\] has proposed an interesting al-gorithm for direct ID/LP parsing by gener-alizing Earley's algorithm\[6\] to use tile con-straints of ID/LP rules directly.
Despite ofits possibility of blowing up in the worstease, Barton\[3\] has shown that Shieber's di-rect parsing algorithm usually does have atime advantage over the use of Earley's algoorithm oll the expanded CFG.
Thus the directparsing strategy is likely to be an appealingcandidate for parsing with ID/LP rules fromthe computational point of view.In this paper, we present a new approachto direct ID/LP rules parsing that outper-forms the prcvious methods.
Besides of thedirect parsing property, three features con-tribute to its efficiency.
First, ID rulesare precompiled to generalized iscrimina-tion networks\[9\] to yield compact represen-tation of parsing states, hence less compu-tation time.
Second, LP rules are also pre-compiled into a Hasse diagram to minimizethe time used for order legality cheek at runtime.
And, third, its bottom-up depth-firstparsing strategy minimizes the work of edgecheck and therefore saves a lot of processingtime.We will first describe briefly each featureof our parser.
Then, we will show the parsingalgorithm and an example of parsing.
Thecomparisons of our approach with other re-lated works are also described.
Finally, wegive a conclusion and our future works.ACIES DE COLING-92, NANTES, 23-28 AO~' 1992 4 0 1 I)ROC.
OF COI.,ING-92, NANTES, AUG. 23-28, 1992s --*ID a,b,c,d (1)s -~x.
a,b,e,f  (2)a,b,c < d (3)b < c (4)a,e < f (5)Figure 1: An example ID/LP grammar : Gl2 The Pr inc ip les  o f  theParserIdentifier Bit  Vector111111ollo1 Iln2lolxoldl If10111~011101 \[0112110111012.1  Bot tom-up Depth- f i r s tS t ra tegyChart parsing is one of the most well-knownand efficient techniques for parsing generalcontext-free grammars.
The chart serves asa book-keeping storage for all parses gener-ated while parsing.
In general, to avoid re-doing the same tasks, the chart has to bechecked every time a new edge is proposedto see whether the identical edge was alreadygenerated.
Also, when an edge is entered intothe chart, it must be checked with other edgesto see if it can be merged together to createnew edges.
In practice, these checks can oc-cupy the majority of parsing time.In order to build an efficient parser, it is ap-parent to minimize the checks above.
Manydifferent strategies of chart parsers has beendeveloped.
Most of them try to mininfize thenumber of useless edges to reduce the check-ing time.Our parsing strategy is based on the WordIncorporation (VVI) algorithm\[12\] with somemodifications to accommodate ID/LP for-realism.
We follow WI algorithm by restrict-ing the parsing strategy to be solely bottom-up and depth-first.
This makes the parsingproceed along the input in an orderly fashion(left to right or right to left) and keep pro-cessing at a vertex until no more new edgesending at the vertex can be generated.
Oncethe parsing go beyond a vertex, the process-ing will never be redone at that vertex again.As a consequence, the duplicated edge checkcan be completely omitted.
Moreover, onceFigure 2: Generalized iscrimination networkrepresentation f ID rulesa complete dge is used (for creating new ac-tive edges), we can delete it out of tile storagesince it cannot affect other edges anymore.This reduces the number of edges and hencethe checking time.2 .2  Genera l i zed  D isc r imina-t ion  Networks  as  ID  ru lescompi la t ionIn conventional chart parsing for context-freegrammars, a method for reducing the numberof edges is precompiling the grammars intodiscrimination trees.
Assume two CFG rules,S ~ ABCD and S ~ ABEF.
The RHS of thetwo rules have the common left part AB andtherefore can be merged together into a singlecombined rule: S ~ AB(CD,EF).
In parsing,the common part can then be represented bya single active edge.However, to apply the method to ID/LPformalism, the case is different.
Supposewe have a ID/LP grammar (-;1 as shown inFig.
1.
If we view parsing as discriminationtree traversal, the parsing has to proceed inthe fixed order from the root to leaf nodes.Because of the order-free characteristic of IDrules, we can no longer just simply combinethe ID rules (1) and (2) together as for thetwo CFG rules above.To achieve the same merit of discriminationnetwork in the case of CFG rules, we use gen-ACTES DE COLING-92.
NxrcrEs, 23-28 AO~,'r 1992 4 0 2 Paoc.
OF COLING-92.
NANTES.
Aua.
23-28.
1992erMized discrimination etwork (GDN) forrepresenting ID rules.
GDN is a generaliza-tion of a discrimination tree that can be tra-versed according to the order in which con-stralnts are obtained incrementally during theanalytical process, independently of the orderof the network's arcs.
The technique has beenfirst proposed in \[9\] to be used in incremen-tal semantic disambiguation nmdel but itscharacteristic also matches our purpose.
Thetechnique of GI)N is to assign each node inthe network a unique identifier and a bit vec-tor.
For example, the ID rules of Ga, shownin Fig.
1 ,can be represented asthe discrimi-nation network in Fig.
2, of which each nodeis assigned a unique identifier.
The leftmostdigit of an identifier of a node v indicateswhether the node is a leaf or not, '0' for beinga leaf and '1' for being a non-leaf.
This digitis followed by the sequence S(v), which is theconcatenation f the sequence S(u) and theinteger k, where u is the immediate predeces-sor of v and k is the numerical number of thearcs issuing from u.
1 Note that the identifierof the root node r has only the first leftmostdigit(S(r) is null).As shown in Fig.
2, to each node identifier,we attached a bit vector that has the samelength as the identifier and consists of l 's ex-cept the leftmost and rightmost bits.
Theseidentifiers together with their correspondingbit vectors play an important role in the pars-ing process with GDN, as will be describedlater.Note that representing ID rules by GDNcan combine the common parts of differentID rules into the same arcs in the network.Shieber's representation, i  contrast, consid-ers each single ID rule seperately and thuscannot achieve this kind of compactness.2 .3  Represent ing  LP  ru les  as  aHasse diagramHasse diagram is a representation f partiallyordered set used in graph theory\[8\].
Sincea set of LP rules also defines a partially orodered set on a grammar's categories, we can1The encoding used here is a little ditfercnt fromthe original ()tie in \[9\].d fFigure 3: Hasse diagram with the precedencevector assigned to each nodeconstrnct its corresponding Hasse diagram.Fig.
3 shows a Hasse diagram for LP rulesof G1.
qb each node we assign a unique flagand construct a bit vector by setting the flagto '1' and the others to '0'.
As for this Hassediagram, we assign 1lag(a) the first bit, flag(b)the second bit, .
.
.
,  and flag(f) the sixth bit.The bit vectors of nodes a, b, c, d, e and f arethen 000001, 000010, 000100, 001000, 010000and 100000, respectively.
The precedencevector of each node is the bitwise disjunctionbetween its bit vector and all bit vectors of itssubordinate nodes.
For example, the prece-dence vector of f is the disjunction betweenbit vectors of f,  a and e; 100000 V 000001 V010000 = 110001.
The resultant precedencevectors are shown in Fig.
3 with O's in theirleft parts omitted.Using the above technique, the order legal-ity check with respect o a given set of LPrules can be efficiently done by the algorithmbelow:A lgor i thm:  CheckOrderInput : Two symbols, A and B with thet)recedence vector Prea and Pre~ respec-tively, where A precedes B in the input.1.
'Fake the bitwise disjunction betweenPre a and Pren.2.
Ctieck equality: if the result is equal to\['rea, fail.
Otherwise, return the resultas the precedence vector of the stringAB.ACTES DE COLING-92, NANTES, 23-28 AOtn' 1992 4 0 3 I)ROC.
OV COLING-92, NAN'I'ES, AUG. 23~28, 1992Note that, by the encoding algorithm de-scribed in the previous ubsection, the prece-dence vector of a symbol A that must precedea symbol B always be included in B's prece-dence vector.
As a result, if A comes behindB the disjunction of their precedence vectorswill be equal to B's precedence vector.
Theabove algorithm thus employs this fact to de-tect the order violation easily.
Moreover, notethat all LP constraints concerning the sym-bols concatenated are propagated with theresultant string's precedence vector by the re-sult of disjunction.
We can then use the al-gorithm to check the legality of next inputsymbol with respect o all preceded symbolseasily by checking with the resultant string'sprecedence vector only.
In real implementa-tion, we can represent a precedence vector byan integer and the order legality can thus bechecked efficiently by using Boolean bitwiseoperations between integers provided in mostmachines.reduce(a , (s , l l , l ,00) ) .reduce(b , (s , l l l ,10 ,010) ) .reduce(c , ( s , l l l l , l l 0 ,0110) ) .reduce(d, (s ,01111,1111,01110)) .reduce(e , (s , l l l 2 ,10000,0110) ) .reduce( f , (s ,O1121,110001,Ol l lO) ) .Figure 4: Category-state table generatedfrom ID/LP rules : G:Next, the constraint-identifier table is re-placed by the category-state able, notatedas reduce(category, state), viewing each cat-egory as a constraint.
This table will be usedto reduce a constituent to higher level con-stituent state when it is complete.
A con-stituent is complete if its current state is ata leaf node and all bits of BitV are set to 0.Fig.
4 shows the table derived from G1.2.4 Table for ID/LP ParsingGDN can cope with any order of input con-straints by referring to the table of constraint-identifier which is extracted from the networkby collecting pairs of a branch and its im-mediate subordinate node.
However, GDNhas been proposed to handle the completelyorder-free constraint system.
In order to ap-ply the model to parse natural language ofwhich word order is restricted by some lin-ear precedence constraints, some modifica-tions have to be done to take those constraintsinto account.First, the definition of a state is changedfrom a 2-tuple < Id, B i tV  > to a 4-tuple< Cat, Id, Pre, B i tV  > where each elementis defined as the following:Cat : the mother category of the state;Id : the identifier of the state;Pre : the precedence vector of the state;BitV : the bit vector of the state.Because we have several networks for allnonterminal categories in grammar, Cat isadded to indicate which networks the statebelongs to.
Moreover, in addition to the ele-ments used to check ID rules, the precedencevector Pre is added for the check of LP rules.3 The Parsing AlgorithmUsing the table generated from the ID/LPgrammar, we can parse by the following al-gorithm.A lgor i thm:  ParseGiven a category~state table T generatedfrom ID/LP grammar G, a dictionary D ,a goal category S and an input string w =wlw2..  ?
w,, where wi is a terminal in G, weconstruct he chart as follows:k +-- 0;whi le  k < n do beg in1.
Look up D for the entry of Wk+ 1, Spanthe inactive(complete) edges correspond-ing to every possible category of w~+: be-tween vertices k and k + 1.Now perform steps (2) and (3) until nonew edges can be added.2.
For each inactive edge of category flspanned between vertices j and k+l (j <k + 1), if reduce(~3, ?)
is an entry in T,span the edge of state ?
between verticesj and k + 1.AC'T~ DE COLING-92, N^h'TES, 23-28 Aotrr 1992 4 0 4 PROC.
OF COLING-92, NANTES, AUG. 23-28, 19923.
For each active(incomplete) edge of cat-egory/3 spanned between vertices j andk + 1, search for active edge spanned be-tween vertices i and j (i < j).
For eachone found, perform the check operationbetween the two edges.
If this succeeds,add the resultant new edge between ver-tices i and k + 1.4+ k~k+l .end;The input string w is accepted if and onlyif there exists ome complete dge of categoryS from vertex 0 to vertex n in the chart.Here, the cheek operation between twoedges(states) includes all of the following op-erations:operat ion  between Cats : If Catl = Cabethen return Cab.
Otherwise, fail;operat ion  between Ids : Ignoring the left-most bit, if Id~ is a prefix-numericalstring of/+/2, return Id2.
Otherwise, fail;operat ion  between Pres : As described inCheckOrder algorithm;operat ion  between BitVs : After adjust-ing the length of BitVs by attaching l 'sto the end of the shorter vector, returnthe bit vector of which each bit is a coat-junction of the bits of two bit vectors.The operation between Cats first checkswhether the two states are in the same net-work.
The operation between Ids then checkswhether one node can be reached front theother in the network.
The operation betweenPres tests whether the catenation ofthe edgesviolates LP constraints and return the prece-dence vector of the successful combined edgeas described in section 4.
The operation be-tween BitVs allows us to cope with the freeorder of constraints.
The bit vector repre:sents all the constraints that must be saris-fled between the root node and the reachednode.
A bit of 0 and 1 means that the corre-sponding constraint is satisfied and unsatis=fled, respectively.
For example, the bit vector'0110' in reduce(e, <s,ll12,10000,0110>) ofthe table in Fig.
4 means that by receiving/ :  (s,o1121,11oo11,0oooo)i b ~ e ~ a ~ fFigure 5: Chart of parsing beaf.e as the input, the constraint e is satisfiedand its corresponding rightnrost bit in the bitvector will become '0'.
In addition, the twol 's mean that we can traverse to the nodewith the identitier 1112 but another two con-straints, a and b, has to be satisfied before.The leftmost bit just makes the vector lengththe same as that of the identifier and has nocorresponding constraint.
By taking the con-jltnction of bits of these vectors, bits of tileresultant vector are incrementally changed to0.
Because the bit conjunction operation isexecutable in any order, it is possible to copewith an arbitrary order of constraints.Note that one may adopt other mechanismsused in conventional chart parsing to improvethe efficiency of the above algorithm.Example.
Suppose we are given the stringof categories b,e,a,f to parse, using grammarin Fig.
1.
First, the edge <s,ll l ,10,010>is spanned between vertices 0 and 1, sincethe first element of the string is a b. Nomore iterations of step 2 and 3 are possi-ble, so we move on to the next word.
Af-ter category e is obtained, its correspondingstate <s,1112,10000,0110> is then operatedwith the state <s,111,10,010>.
Operation be-tween categories succeeds because both stateshave the same category .~.
Operation betweenidentifiers I l l  and 1112 succeeds because 111is a prefix of l l l2 ,  thus 1.112 is returned.Operation between precedence values 10 and10000 also succeeds because the bitwise dis-junction of them yields 10010 which is notequal to 10.
Last, the operation between bitAcrEs DE COLING-92.
NAbrFES.
23-28 AOUT 1992 4 0 5 l)l~oe, o1: COLING-92.
N^N'rES.
AUG. 23-28.
1992vectors 010 and 0110 returns the result of con-junction between 0100 and 0110 which is thus0100.
So the above operations yield the resul-tant state <s,ll12,10010,0100> as the edgespanned between vertices 0 and 2.Continuing in this manner, we will get<s,ll12,10011,0000> between vertices 0 and3, and <s, ll121,110011,00000> between ver-tices 0 and 4.
Because the latter is a completeedge of goal category ~s', the input string isthus accepted.
The chart is shown in Fig.
5.4 Comparison wi th  Re-lated WorksOther than Shieber's work, there are manyworks in the past concerning ID/LP pars-ing.
Popowich's FIGG\[10\] treats ID/LP rulesby compiling them into Discontinuos Gram-mar rules.
The different approach of top-down ID/LP parsing using logic grammars ipresented by Abramson\[1\].
This approach isbased on using metarules and is attractive inthat it can be simply added on top of logicgrammars that are directly available in Pro-log.
However, the main drawback in using topdown recursive descent parsing methods isthat it might result in an infinite loop for leftrecursive grammars.
The recent version us-ing Static Discontinuity Grammars(SDG)\[5\]augmented with Abramson's metarules cansolve this problem by adding loop controlas a constraint on parsing.
According tothe comparison tests reported in \[2\], the ap-proach appears to be considerably faster thanPopowich's FIGG.Another approach of Bottom-up filter-ing strategy\[4\] attempts to reduce the non-determinism in parsing.
Different ID rulesare constrained to have at most one categoryin common and the knowledge of the leftmostconstituent is used for phrase level initializa-tion.As an investigation of our approach, wehave implemented a small parser, calledGHW, using SlCStus prolog on a Sun 3-60workstation.
To reduce spurious parses, theparser adopts the technique of the left-cornerparsing method to detect the edges that can-ACTES DE COLlNG-92.
NAN'I~.
23-28 hofrr 1992 4 0 6not start a constituent in the bottom-up rulesinvoking stage.
The technique is similar tothe one used in \[4\].
GHW is compared withthe SDG+metarules and Shieber's parsersrunning on the same environments.
In exper-imentation, we use a toy grammar taken from\[2\] that was used to compare SDG+metarulesapproach with FIGG.
The grammar contains11 ID rules and 4 LP rules.
A set of artificialsentences whose lengths are ranged from 2 to6 is tested on.
The timings are averaged over100 runs using compiled fastcode and reflectthe average amount of CPU time in millisec-onds required to parse the sentences of sev-erai lengths.
The result is shown in Fig.
6.Because Shieber's and our parser develop allparses in parallel and thus the time used tofind the 1st and M1 parses are about the same,only the all parses time is shown.Comparing GHW with Shieber's parser, asexpected, GHW outperforms the other for alllengths of the input.
When comparing withSDG+metarules parser, for short sentencesSDG+metarules wins over our approach infinding the 1st parse, but for longer sentencesour approach surpasses it in all cases.
Thiscan be explained that because our methodneeds to do more works of initialization atthe beginning of parsing and thus for shortsentences this cost will affect parse time sig-nificantly.
However, in the case of longer sen-tences the cost will be small compared toover all costs and can be neglected.
Thusour method may be more suited for using inreM applications that concern rather long andcomplicated sentences.
However, this exper-iment is just a first step of investigating thebehaviour of our approach.
It remains to beseen how the performance will be for a real-istic grammar.5 Conclus ionA new method for ID/LP rules parsing isdescribed.
The method improves the per-formance of parsing by keeping the parsingstates set as small as possible, reducing thetime used by the LP rules checking operationand cutting away the overhead of duplicatededge checking.
These are accomplished by in-PRoc.
OF COLING-92, NAN'rE.s, AUG. 23-28, 1992total ~8_.~63._1 104:_ ~ 97.
\[ al0./Figure 6: The result of contp*trison testtegrating the.
merits of GDN, l lasse diagramand WI algorithm in parsing.The method isshown to be superior to the previous methodson the tested grammar.
However, more ex-plorations have to be done with diverse gram-mars and sentences to confirm the effective-ness of our method.
This is left as one of ourfurther works.
Also, extending the parser tohandle ill-formed input is under investigation.AcknowledgementsThe authors would like to thank Prof. Har:vey Abramson for providing his system andSuresh Katare Gopalrao for checking Englishin this paper.
This work w~Ls partly sup-ported by the Telecommunications Advance-ment Foundation(TAF).References\]ll\[2\]Is\[\[4\]Abramson, H. Metarules for Eflficient Top-down ID-LP Parsing in Logic Grammars,Technical Report TR-89-11, University ofBristol, I)epartment of Computer Science,1989.Abr,~mson, H. and l)alll, V. On Top-downID-LP Parsing With Logic Grammars, sub-mitted for publication.Barton, E. On the Complexity of II)/LPParsing.
In Computational Liuguzstics,(October-December 1985), 205-218.Blache, P. and Morin J. Bottom-Up Filter-ing: a Parsing Strategy for GPSG.
In pro.ceedings of the 131h Internat*onal Confer-ence on Computational Linguistics, vol.
2,pp.
19-23, 1990\[5\] 1)Md, V. and Popowich, F. Parsingand Generation with Static Discontinu-ity Gr~nnlars.
New Generation Computing,vol.
8, no.
3, pp.
245-274, 1990.\[6\] l"mrley, J.
An Efficient Context-l~ree ParsingAlgorithm, Comm.
ACM 13.2:94-102.
1970.\[7\] Gazdar, G., E. Klein, G.K. Pullum and 1.A.Sag.
Generalized Phrase Structure Gram-mar.
1985.\[8\] I,iu, C.L.
Elements of Discrete Mathemat-ics.
MeGrawqlill International Editions.1986.\[9\] Okumura M. and Tanaka H. ~lbwm'ds In-cremental Disambiguation with a General-ized Discrimination Network.
In PTvceed-lugs Eighth National Confe~ence on Artifi-cial Intelligence, pp.
990-995, 1990.\[10\] popowieh, F.P.
Unrestricted gypping gram-mars.
Computational intelligence, vol.
2,pp.
28-53, 1986.\[11\] Shieber, Stuart M. Direct Parsing ofII)/LP Grammars.
Linguistics and Philos-ophy 7(1984), pp.
135-154.
1984.\[l 2\] Simpkins, N.K.
and ttancox, P. Chart Pars-ing in Prolog.
New Gene~Yttion Computing,vol.
8, no.
2, pp.
113-138.
1990.\[13\] Steel, S. Word ()rder Variation: A typolog-ical Study.
In J.
G*eenbeTy(ed.)
Universalsof Language, vo\[.
4.
Stanford, CA: StanfordUniversity Press.
1981.\[14\] Winograd T. Language as a Cognitive P,v-sees, vol.
l, Syntax, Addison-Wesley.
1983.Acn'Es DE COLING-92, NANTES, 23-28 AO(n" 1992 4 0 7 PV.OC.
OF COI.ING 92, NANTES, AUG. 23-28, 1992
