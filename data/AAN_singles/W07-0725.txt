Proceedings of the Second Workshop on Statistical Machine Translation, pages 189?192,Prague, June 2007. c?2007 Association for Computational LinguisticsBuilding a Statistical Machine Translation Systemfor French using the Europarl CorpusHolger SchwenkLIMSI-CNRS, bat 508, BP 13391403 Orsay cedex, FRANCEschwenk@limsi.frAbstractThis paper describes the development of astatistical machine translation system basedon the Moses decoder for the 2007 WMTshared tasks.
Several different translationstrategies were explored.
We also use a sta-tistical language model that is based on acontinuous representation of the words inthe vocabulary.
By these means we expect totake better advantage of the limited amountof training data.
Finally, we have investi-gated the usefulness of a second referencetranslation of the development data.1 IntroductionThis paper describes the development of a statisticalmachine translation system based on the Moses de-coder (Koehn et al, 2007) for the 2007 WMT sharedtasks.
Due to time constraints, we only consideredthe translation between French and English.
A sys-tem with a similar architecture was successfully ap-plied to the translation between Spanish and En-glish in the framework of the 2007 TC-STAR eval-uation.1 For the 2007 WMT shared task a recipe isprovided to build a baseline translation system usingthe Moses decoder.
Our system differs in several as-pects from this base-line: 1) the training data is notlower-cased; 2) Giza alignments are calculated onsentences of up to 90 words; 3) a two pass-decodingwas used; and 4) a so called continuous space lan-guage model is used in order to take better advantageof the limited amount of training data.1A paper on this work is submitted to MT Sumit 2007.This architecture is motivated and detailed in thefollowing sections.2 Architecture of the systemThe goal of statistical machine translation (SMT) isto produce a target sentence e from a source sen-tence f .
It is today common practice to use phrasesas translation units (Koehn et al, 2003; Och andNey, 2003) and a log linear framework in order tointroduce several models explaining the translationprocess:e?
= arg max p(e|f)= arg maxe{exp(?i?ihi(e, f))} (1)The feature functions hi are the system models andthe ?i weights are typically optimized to maximizea scoring function on a development set (Och andNey, 2002).
In our system fourteen features func-tions were used, namely phrase and lexical transla-tion probabilities in both directions, seven featuresfor the lexicalized distortion model, a word and aphrase penalty and a target language model (LM).The system is constructed as follows.
First,Giza++ is used to perform word alignments in bothdirections.
Second, phrases and lexical reorderingsare extracted using the default settings of the MosesSMT toolkit.
A target LM is then constructed asdetailed in section 2.1.
The translation itself is per-formed in two passes: first, Moses in run and a 1000-best list is generated for each sentence.
When gen-erating n-best lists it may happen that the same tar-get sentence is generated multiple times, for instanceusing different segmentations of the source sentence189or a different set of phrases.
We enforced all thehypothesis in an n-best list to be lexically differentsince our purpose was to rescore them with a LM.The parameters of Moses are tuned on devtest2006for the Europarl task and nc-dev2007 for the newscommentary task, using the cmert tool.These 1000-best lists are then rescored with dif-ferent language models, either using a longer con-text or performing the probability estimation in thecontinuous space.
After rescoring, the weights of thefeature functions are optimized again using the nu-merical optimization toolkit Condor (Berghen andBersini, 2005).
Note that this step operates only onthe 1000-best lists, no re-decoding is performed.
Ingeneral, this results in an increased weight for theLM.
Comparative results are provided in the resultsection whether it seems to be better to use higherorder language models already during decoding, orto generate first rich n-best lists and to use the im-proved LMs during rescoring.2.1 Language modelingThe monolingual part of the Europarl (38.3M En-glish and 43.1 French words) and the news commen-tary corpus (1.8M/1.2M words) were used.
SeparateLMs were build on each data source and then lin-early interpolated, optimizing the coefficients withan EM procedure.
This usually gives better re-sults than building an LM on the pooled data.
Notethat we build two sets of LMs: a first set tuned ondevtest2006, and a second one on nc-dev2007.
Itis not surprising to see that the interpolation coeffi-cients differ significantly: 0.97/0.03 for devtest2006and 0.42/0.58 for nc-dev2007.
The perplexities ofthe interpolated LMs are given in Table 1.2.2 Continuous space language modelOverall, there are roughly 40 million words of textsavailable to train the target language models.
Thisis a quite limited amount in comparison to tasks likethe NIST machine translation evaluations for whichseveral billion words of newspaper texts are avail-able.
Therefore, new techniques must be deployedto take the best advantage of the limited resources.Here, we propose to use the so-called continu-ous space LM.
The basic idea of this approach is toproject the word indices onto a continuous space andto use a probability estimator operating on this spaceFrench EnglishEparl News Eparl NewsBack-off LM:3-gram 47.0 91.6 57.2 160.14-gram 41.5 85.2 51.6 152.4Continuous space LM:4-gram 35.8 73.9 44.5 133.45-gram 33.9 71.2 - -6-gram 33.1 70.1 41.2 127.0Table 1: Perplexities on devtest2006 (Europarl) andnc-dev2007 (news commentary) for various LMs.
(Bengio et al, 2003).
Since the resulting probabilityfunctions are smooth functions of the word repre-sentation, better generalization to unknown n-gramscan be expected.
A neural network can be used to si-multaneously learn the projection of the words ontothe continuous space and to estimate the n-gramprobabilities.
This is still a n-gram approach, butthe LM probabilities are ?interpolated?
for any pos-sible context of length n-1 instead of backing-off toshorter contexts.This approach was successfully used in large vo-cabulary continuous speech recognition (Schwenk,2007) and in a phrase-based system for a small task(Schwenk et al, 2006).
Here, it is the first timeapplied in conjunction with a lexicalized reorderingmodel.
A 4-gram continuous space LM achieves aperplexity reduction of about 13% relative with re-spect to a 4-gram back-off LM (see Table 1).
Ad-ditional improvements can be obtained by using alonger context.
Note that this is difficult for back-off LMs due to insufficient training data.3 Experimental EvaluationThe system was trained on the Europarl parallel textsonly (approx.
1.3M words).
The news commentaryparallel texts were not used.
We applied the tok-enization proposed by the Moses SMT toolkit andthe case was preserved.
While case sensitivity mayhurt the alignment process, we believe that true caseis beneficial for language modeling, in particular infuture versions of our system in which we plan touse POS information.
Experiences with alternativetokenizations are undergoing.The parameters of the system were tuned on190DevTest2006 Test2006Decode: 3-gram 4-gram 3-gram 4-gramBack-off LM:decode 30.88 - 30.82 -4-gram 31.65 31.43 31.35 30.86Continuous space LM:4-gram 31.96 31.75 32.03 31.595-gram 31.97 31.86 31.90 31.506-gram 32.00 31.93 31.89 31.64Lex.
diff.
904.2 797.6 900.6 795.8Oracle 37.82 37.64 - -Table 2: Comparison of different translation strate-gies (BLEU scores for English to French): 3- or 4-gram decoding (columns) and n-best list rescoringwith various language models (lines).devtest2006 and nc-dev2007 respectively.
Thegeneralization performance was estimated on thetest2006 and nc-devtest2007 corpora respectively.3.1 Comparison of decoding strategiesTwo different decoding strategies were compared inorder to find out whether it is necessary to alreadyuse higher-order LMs during decoding or whetherthe incorporation of this knowledge can be post-poned to the n-best list rescoring.
Tri- or 4-gramback-off language models were used during decod-ing.
In both cases the generated n-best lists wererescored with higher order back-off or the continu-ous space language model.
A beam of 0.6 was usedin all our experiments.The oracle BLEU scores of the generated n-bestlists were estimated by rescoring the n-best lists witha cheating LM trained on the development data.
Wealso provide the average number of lexically differ-ent hypothesis in the n-best lists.
The results aresummarized in Table 2 and 3.
The numbers in boldindicate the systems that were used in the evaluation.These results are somehow contradictory : whilerunning Moses with a trigram LM seems to be betterwhen translating from English to French, a 4-gramLM achieves better results when translating to En-glish.
An analysis after the evaluation seems to indi-cate that the pruning was too aggressive for a 4-gramLM, at least for a morphologically rich language likeFrench.
Using a beam of 0.4 and a faster implemen-DevTest2006 Test2006Decode: 3-gram 4-gram 3-gram 4-gramBack-off LM:decode 32.21 - 31.50 -4-gram 32.46 32.34 32.07 32.12Continuous space LM:4-gram 32.87 32.90 30.51 32.476-gram 32.85 32.98 32.46 32.50Lex.
diff.
791.3 822.7 802.5 827.8Oracle 38.80 39.69 - -Table 3: Comparison of different translation strate-gies (BLEU scores for French to English).tation of lexical reordering in the Moses decoder, itis apparently better to use a 4-gram LM during de-coding.
The oracle scores of the n-best lists andthe average number of lexically different hypothe-sis seem to correlate well with the BLEU scores: inall cases it is better to use the system that producedn-best lists with more variety and a higher oracleBLEU score.The continuous space language model achievedimprovements in the BLEU by about 0.4 on the de-velopment data.
It is interesting to note that this ap-proach showed a very good generalization behavior:the improvements obtained on the test data are asgood or even exceed those observed on the Dev data.3.2 Multiple reference translationsOnly one reference translation is provided for alltasks in the WMT?07 evaluation.
This may be prob-lematic since systems that do not use the official jar-gon or different word order may get ?incorrectly?
alow BLEU score.
We have also noticed that the ref-erence translations are not always real translationsof the input, but they rely on document wide contextinformation.
Therefore, we have produced a secondset of sentence based reference translations.2The improvements brought by the continuousspace LM are much higher using the new referencetranslations.
Using both reference translations to-gether leads to an important increase of the BLEUscore and confirms the improvements obtained bythe continuous space LM.
These results are in line2The second reference translations can be downloaded fromhttp://instar.limsi.fr/en/data.html191Ref.
transl.
: official addtl.
both retunedBack-off 31.64 32.91 47.62 47.95CSLM 32.00 33.81 48.66 49.02Table 4: Impact of additional human reference trans-lations (devtest2006, English to French)with our experiences when translating from Englishto Spanish in the framework of the TC-STAR project(gain of about 1 point BLEU).
The BLEU scores canbe further improved by rerunning the whole tuningprocess using two reference translations (last col-umn of Table 4).Second reference translations for the test data arenot yet available.
Therefore the devtest data wassplit into two parts: the back-off and the CSLMachieve BLEU scores of 47.98 and 48.66 respec-tively on the first half used for tuning, and of 47.95and 49.02 on the second half used for testing.3.3 Adaptation to the news commentary taskWe only performed a limited domain adaptation: theLMs and the coefficients of the log-linear combi-nation of the feature functions were optimized onnc-dev2007.
We had no time to add the news com-mentary parallel texts which may result in miss-ing translations for some news specific words.
TheBLEU scores on the development and developmenttest data are summarized in Table 5.
A trigramwas used to generate 1000-best lists that were thenrescored with various language models.Language modeling seems to be difficult whentranslating from English to French: the use of a 4-gram has only a minor impact.
The continuous spaceLM achieves an improvement of 0.3 on nc-dev and0.5 BLEU on nc-devtest.
There is no benefit for us-English/French French/Englishdev devtest dev devtestBack-off LM:decode 27.11 25.31 27.57 26.214-gram 27.35 25.53 27.56 26.55Continuous space LM:4-gram 27.63 26.01 28.25 26.876-gram 27.60 25.64 28.38 27.26Table 5: BLEU scores for news commentary task.ing longer span LMs.
The BLEU score is even 0.5worse on nc-devtest due to a brevity penalty of 0.95.The continuous space LM also achieves interestingimprovements in the BLEU score when translatingfrom French to English.4 AcknowledgmentsThis work has been partially funded by the EuropeanUnion under the integrated project TC-STAR and bythe French Government under the project INSTAR(ANR JCJC06 143038).
The author would like torecognize the contributions of A. Allauzen for hishelp with the creation of the second reference trans-lations.ReferencesYoshua Bengio, Rejean Ducharme, Pascal Vincent, andChristian Jauvin.
2003.
A neural probabilistic lan-guage model.
Journal of Machine Learning Research,3(2):1137?1155.Frank Vanden Berghen and Hugues Bersini.
2005.
CON-DOR, a new parallel, constrained extension of powell?sUOBYQA algorithm: Experimental results and com-parison with the DFO algorithm.
Journal of Computa-tional and Applied Mathematics, 181:157?175.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL, demonstation session.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statis-tical machine translation.
In ACL, pages 295?302.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignement models.Computational Linguistics, 29(1):19?51.Holger Schwenk, Marta R. Costa-jussa`, and Jose?
A. R.Fonollosa.
2006.
Continuous space language modelsfor the IWSLT 2006 task.
In IWSLT, pages 166?173,November.Holger Schwenk.
2007.
Continuous space languagemodels.
Computer Speech and Language, 21:492?518.192
