Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 384?389,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsLanguage Identification and Modeling in Specialized HardwareKenneth Heafield?,?Rohan Kshirsagar?Santiago Barona?
?Bloomberg L.P.731 Lexington Ave.New York, NY 10022 USA?University of Edinburgh10 Crichton StreetEdinburgh EH8 9AB, UK{kheafield,rkshirsagar2,sbarona}@bloomberg.netAbstractWe repurpose network security hardwareto perform language identification and lan-guage modeling tasks.
The hardware isa deterministic pushdown transducer sinceit executes regular expressions and has astack.
One core is 2.4 times as fast at lan-guage identification and 1.8 to 6 times asfast at part-of-speech language modeling.1 IntroductionLarger data sizes and more detailed models haveled to adoption of specialized hardware for naturallanguage processing.
Graphics processing units(GPUs) are the most common, with applicationsto neural networks (Oh and Jung, 2004) and pars-ing (Johnson, 2011).
Field-programmable gate ar-rays (FPGAs) are faster and more customizable,so grammars can be encoded in gates (Ciressanet al, 2000).
In this work, we go further downthe hardware hierarchy by performing languageidentification and language modeling tasks on anapplication-specific integrated circuit designed fornetwork monitoring.The hardware is programmable with regular ex-pressions and access to a stack.
It is therefore a de-terministic pushdown transducer.
Prior work usedthe hardware mostly as intended, by scanning harddrive contents against a small set of patterns fordigital forensics purposes (Lee et al, 2008).
Thepurposes of this paper are to introduce the naturallanguage processing community to the hardwareand evaluate performance.We chose the related tasks of language identi-fication and language modeling because they donot easily map to regular expressions.
Fast lan-guage classification is essential to using the webas a corpus (Smith et al, 2013) and packages com-pete on speed (Lui and Baldwin, 2012).
Exten-sive literature on fast language models comprisesa strong baseline (Stolcke, 2002; Federico et al,2008; Heafield, 2011; Yasuhara et al, 2013).
Inboth cases, matches are frequent, which differsfrom network security and forensics applicationswhere matches are rare.2 Related WorkAutomata have been emulated on CPUs withAT&T FSM (Mohri et al, 2000) and OpenFST(Allauzen et al, 2007), on GPUs (Rudom?
?n et al,2005; He et al, 2015), and on FPGAs (Sidhu andPrasanna, 2001; Lin et al, 2006; Korenek, 2010).These are candidates for the ASIC we use.
In par-ticular, gappy pattern matching (He et al, 2015)maps directly to regular expressions.GPUs have recently been applied to the re-lated problem of parsing (Johnson, 2011; Yi et al,2011).
These operate largely by turning a sparseparsing problem into a highly-parallel dense prob-lem (Canny et al, 2013) and by clustering similarworkloads (Hall et al, 2014).
Since the hardwareused in this paper is a deterministic pushdown au-tomaton, parsing ambiguous natural language istheoretically impossible without using the CPU asan oracle.
Hall et al (2014) rely on communi-cation between the CPU and GPU, albeit for ef-ficiency reasons rather than out of necessity.Work on efficiently querying backoff languagemodels (Katz, 1987) has diverged from a finitestate representation.
DALM (Yasuhara et al,2013) is an efficient trie-based representation us-ing double arrays while KenLM (Heafield, 2011)has traditional tries and a linear probing hash ta-ble.
We use the fastest baselines from both.3 Programming ModelThe fundamental programming unit is a POSIXregular expression including repetition, lineboundaries, and trailing context.
For example,a[bc] matches ?ab?
and ?ac?.384When an expression matches, the hardware canoutput a constant to the CPU, output the spanmatched, push a symbol onto the stack, pop fromthe stack, or halt.
There is little meaning tothe order in which the expressions appear in theprogram.
All expressions are able to match atany time, but can condition on the top of thestack.
This is similar to the flex tool (Lesk andSchmidt, 1975), which refers to stack symbols asstart conditions.4 Language IdentificationWe exactly replicate the model of langid.py(Lui and Baldwin, 2012) to identify 97 languages.Their Na?
?ve Bayes model has 7,480 features fi,each of which is a string of up to four bytes (Luiand Baldwin, 2011).
Inference amounts to collect-ing the count ciof each feature and computing themost likely language l given model p.l?= argmaxlp(l)?ip(fi|l)ciWe use the hardware to find all instances of fea-tures in the input.
Feature strings are convertedto literal regular expressions.
When the hardwarematches the expression for feature fi, it outputsthe unique feature index i.
Since the hardwarehas no user-accessible arithmetic, the CPU accu-mulates feature counts ciin an array and performssubsequent modeling steps.
The baseline emulatesautomata on the CPU (Aho and Corasick, 1975).Often the input is a collection of documents,each of which should be classified independently.To separate documents, we have the hardwarematch document boundaries, such as newlines,and output a special value.
Since the hardwarenatively reports matches in order by start position(then by end position), the special value acts asa delimiter between documents that the CPU candetect.
This removes the need to reconcile docu-ment offsets on the CPU and saves bus bandwidthsince the hardware can be configured to not reportoffsets.5 Language Model ProbabilityThe task is to compute the language model prob-ability p of some text w. Backoff models (Katz,1987) memorize probability for seen n?grams andcharge a backoff penalty b for unseen n?grams.p(wn| wn?11) ={p(wn| wn?11) if wn1is seenp(wn| wn?12)b(wn?11) o.w.5.1 Optimizing the TaskThe backoff algorithm normally requires stor-ing probability p and backoff b with each seenn?gram.
However, Heafield et al (2012) usedtelescoping series to prove that probability andbackoff can be collapsed into a single function qq(wn|wn?11) = p(wn|wn?11)?ni=1b(wni)?n?1i=1b(wn?1i)This preserves sentence-level probabilities.1Because the hardware lacks user-accessiblearithmetic, terms are sent to the CPU.
Sending justq for each token instead of p and various backoffsb reduces communication and CPU workload.
Wealso benefit from a simplified query procedure: foreach word, match as much context as possible thenreturn the corresponding value q.5.2 Greedy MatchingLanguage models are greedy in the sense that, forevery word, they match as much leading contextas possible.
We map this onto greedy regular ex-pressions, which match as much trailing context aspossible, by reversing the input and n?grams.2Unlike language identification, we run the hard-ware in a greedy mode that scans until a matchis found, reports the longest such match, and re-sumes scanning afterwards.
The trailing contextoperator / allows fine-grained control over the off-set where scanning resumes.
Given two regularexpressions r and s, the trailing context expres-sion r/s matches rs as if they were concatenated,but scanning resumes after r. For example, if thelanguage model contains n?gram ?This is a?, thenwe create regular expression" a"/" is This "where the quotes ensure that spaces are interpretedliterally.
Scanning resumes at the space before thenext word: ?
is?.
Because greedy mode suppressesshorter matches, only the longest n?gram will bereported.
The CPU can then sum log q values asso-ciated with each expression without regard to po-sition.Unknown words are detected by matching aspace: " ".
Vocabulary words will greedily1Technically, q is off by the constant b(<s>) due to con-ditioning on <s>.
We account for this at the end of sentence,re-defining q(</s> | wn?11) ?
q(</s> | wn?11)b(<s>).Doing so saves one output per sentence.2For exposition, we show words in reverse order.
Theimplementation reverses bytes.385Rule Value Purpose" a"/" in " q(a | in) Normal query" " q(<unk>) Unknown word" in"/" \n" q(in | <s>) Sentence begin" \n"/" " q(</s>) Sentence end" \n"/" in " q(</s> | in) Sentence endTable 1: Example regular expressions, includingthe special rules for the unknown word and sen-tence boundaries.
We rely on the newline \n inlieu of sentence boundary tokens <s> and </s>.Model Platform 1 core 5 coreslangidHardware 160.34 608.41C 64.57 279.18Java 25.53 102.72Python 2.90 12.63CLD2 C++ 12.39 30.15Table 2: Language identification speed in MB/s.match their own regular expression, which beginswith a space.
This space also prevents matchinginside an unknown word (e.g.
?Ugrasena?
shouldnot match ?a?).
The tokenizer is expected to re-move duplicate spaces and add them at line bound-aries.
Table 1 shows key expressions.Instead of strings, we can match vocabulary in-dices.
Spaces are unnecessary since indices havefixed length and the unknown word has an index.6 ExperimentsWe benchmarked a Tarari T2540 PCI express de-vice from 2011 against several CPU baselines.
Ithas 2 GB of DDR2 RAM and 5 cores.
A single-threaded CPU program controls the device andperforms arithmetic.
The program scaled linearlyto control four devices, so it is not a bottleneck.Wall clock time, except loading, is the minimumfrom three runs on an otherwise-idle machine.Models and input were in RAM before each run.6.1 Language IdentificationThe langid.py model is 88.6?99.2% accurate(Lui and Baldwin, 2012).
We tested the origi-nal Python, a Java implementation that ?should befaster than anything else out there?
(Weiss, 2013),a C implementation (Lui, 2014), and our replica inhardware.
We also tested CLD2 (Sites, 2013) writ-ten in C++, which has a different model that wasless accurate on 4 of 6 languages selected fromEuroparl (Koehn, 2005).
Time includes the costsLines Tokens Ken DA 1 core 5 cores100 2.6 ?
10337.8 40.3 6.6 2.11000 2.2 ?
10442.4 43.6 16.2 10.710000 2.6 ?
10553.9 55.7 46.2 42.0100000 2.8 ?
10678.6 85.3 91.3 93.6305263 8.6 ?
10692.9 105.6 97.0 91.8Table 3: Seconds to compute perplexity on strings.The hardware was tested with 1 core and 5 cores.of feature extraction and modeling.Table 2 reports speed measured on a 9.6 GB textfile created by concatenating the 2013 News Crawlcorpora for English, French, German, Hindi,Spanish, and Russian (Bojar et al, 2014).
Onehardware core is 2.48 times as fast as the fastestCPU program.
Using five cores instead of oneyielded speed improvements of 3.8x on hardwareand 4.3x on a 16-core CPU.
The hardware per-forms decently on this task, likely because the 1MB binary transition table mostly fits in cache.6.2 Language ModelingWe benchmarked against the fastest reported lan-guage models, DALM?s reverse trie (Yasuhara etal., 2013) and KenLM?s linear probing (Heafield,2011).
Both use stateful queries.
For sur-face strings, time includes the cost of vocabularylookup.
For vocabulary identifiers, we convertedwords to bytes then timed custom query programs.Unpruned models were trained on the En-glish side of the French?English MultiUN corpus(Eisele and Chen, 2010).
Perplexity was computedon 2.6 GB of tokenized text from the 2013 EnglishNews Crawl (Bojar et al, 2014).6.2.1 Surface StringsWe tested trigram language models trained on var-ious amounts of data before reaching a software-imposed limit of 4.2 million regular expressions.3Figure 1 and Table 3 show total query time as afunction of training data size while Figure 2 showsmodel size.
DALM model size includes the entiredirectory.Cache effects are evident: the hardware binaryformat is much larger because it stores a generictable.
Queries are fast for tiny models but becomeslower than the CPU.
Multiple cores do not helpfor larger models because they share the cache andmemory bus.
Since the hardware operates at thebyte level and there is an average of 5.34 bytes3Intel is working to remove this restriction.386020406080100120104105106107RealsecondsexcludingloadingTokens of training dataDALMKenLM5 cores1 coreFigure 1: Time to compute perplexity on strings.01002003004005006007008000 1 2 3 4 5 6 7 8 9Binaryfilesize(MB)Millions of tokens of training dataHardDALMKenLMFigure 2: Size of the models on strings.per word, random memory accesses happen moreoften than in CPU-based models that operate onwords.
We then set out to determine if the hard-ware runs faster when each word is a byte.6.2.2 Vocabulary IndicesClass-based language models are often usedalongside lexical language models to form gener-alizations.
We tested a 5?gram language modelover CoNLL part-of-speech tags from MITIE(King, 2014).
There are fewer than 256 uniquetags, fitting into a byte per word.
We also cre-ated special KenLM and DALM query programsthat read byte-encoded input.
Figure 3 and Ta-ble 4 show total time while model sizes are shownin Figure 4.
Performance plateaus for very smallmodels, which is more clearly shown by plottingspeed in Figure 5.01020304050607080102103104105106107108109RealsecondsexcludingloadingTokens of training dataKenLMDALM1 core5 coresFigure 3: Time to compute perplexity on bytes.0204060801001201400 50 100 150 200 250 300 350 400Binaryfilesize(MB)Millions of tokens of training dataHardKenLMDALMFigure 4: Size of the models on bytes.0100200300400500600700800102103104105106107108109WordspermicrosecondexcludingloadingTokens of training data5 cores1 coreDALMKenLMFigure 5: Speed, in words per microsecond, tocompute perplexity on bytes.387Lines Tokens Ken DA 1 core 5 cores100 2.6 ?
10338.0 24.1 3.4 0.91000 2.3 ?
10446.1 27.5 7.5 5.010000 2.7 ?
10553.9 33.4 15.7 10.7100000 2.9 ?
10657.5 34.2 21.1 19.31000000 2.9 ?
10765.2 35.4 22.1 20.713000000 3.7 ?
10873.0 42.9 23.3 22.0Table 4: Seconds to compute perplexity on bytes.The hardware was tested with 1 core and 5 cores.The hardware is faster for all training data sizeswe tested.
For tiny models, one core is initially 6times as fast one CPU core while larger models are1.8 times as fast as the CPU.
For small models, thehardware appears to hitting another limit, perhapsthe speed at which a core can output matches.
Thisis not a CPU or PCI bus limitation because fivecores are faster than one core, by a factor of 4.67.Model growth is sublinear because novel POSn?grams are limited.
The hardware binary imageis 3.4 times as large as DALM, compared with7.2 times as large for the lexical model.
We at-tribute this to denser transition tables that resultfrom model saturation.AcknowledgementsWe thank Intel and Xanadata for numerous con-sultations and for providing access to a machinewith four devices.
Intel markets the hardware asa regular expression processor, not a deterministicpushdown automaton.7 ConclusionLanguage identification and language modelingentail scanning that can be offloaded to regular ex-pression hardware.
The hardware works best forsmall models, such as those used in language iden-tification.
Like CPUs, random memory accessesare slow.
We believe it will be useful for web-scale extraction problems, where language identi-fication and coarse language modeling are used tofilter large amounts of data.
We plan to investigatea new hardware version that Intel is preparing.ReferencesAlfred V. Aho and Margaret J. Corasick.
1975.
Ef-ficient string matching: An aid to bibliographicsearch.
Commun.
ACM, 18(6):333?340, June.Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-jciech Skut, and Mehryar Mohri.
2007.
Openfst: Ageneral and efficient weighted finite-state transducerlibrary.
In Implementation and Application of Au-tomata, pages 11?23.
Springer.Ondrej Bojar, Christian Buck, Christian Federmann,Barry Haddow, Philipp Koehn, Johannes Leveling,Christof Monz, Pavel Pecina, Matt Post, HerveSaint-Amand, Radu Soricut, Lucia Specia, and Ale?sTamchyna.
2014.
Findings of the 2014 workshopon statistical machine translation.
In Proceedings ofthe Ninth Workshop on Statistical Machine Transla-tion, pages 12?58, Baltimore, Maryland, USA, June.Association for Computational Linguistics.John Canny, David Hall, and Dan Klein.
2013.
Amulti-teraflop constituency parser using GPUs.
InProceedings of EMNLP, pages 1898?1907.Cristian Ciressan, Eduardo Sanchez, Martin Rajman,and Jean-Cedric Chappelier.
2000.
An fpga-basedcoprocessor for the parsing of context-free gram-mars.
In Field-Programmable Custom ComputingMachines, Annual IEEE Symposium on, pages 236?236.
IEEE Computer Society.Andreas Eisele and Yu Chen.
2010.
MultiUN: Amultilingual corpus from United Nation documents.In Daniel Tapias, Mike Rosner, Stelios Piperidis,Jan Odjik, Joseph Mariani, Bente Maegaard, KhalidChoukri, and Nicoletta Calzolari, editors, Proceed-ings of the Seventh conference on InternationalLanguage Resources and Evaluation, pages 2868?2872.
European Language Resources Association(ELRA), 5.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
IRSTLM: an open source toolkit forhandling large scale language models.
In Proceed-ings of Interspeech, Brisbane, Australia.David Hall, Taylor Berg-Kirkpatrick, John Canny, andDan Klein.
2014.
Sparser, better, faster GPU pars-ing.
In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguistics,pages 208?217, June.Hua He, Jimmy Lin, and Adam Lopez.
2015.
Gappypattern matching on GPUs for on-demand extrac-tion of hierarchical translation grammars.
Transac-tions of the Association for Computational Linguis-tics, 3:87?100.Kenneth Heafield, Philipp Koehn, and Alon Lavie.2012.
Language model rest costs and space-efficientstorage.
In Proceedings of the 2012 Joint Confer-ence on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, Jeju Island, Korea.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, Edin-burgh, UK, July.
Association for Computational Lin-guistics.388Mark Johnson.
2011.
Parsing in parallel on multiplecores and GPUs.
In Proceedings of the AustralasianLanguage Technology Association Workshop 2011,pages 29?37, December.Slava Katz.
1987.
Estimation of probabilities fromsparse data for the language model component of aspeech recognizer.
IEEE Transactions on Acoustics,Speech, and Signal Processing, ASSP-35(3):400?401, March.Davis E. King.
2014.
MITIE: MIT informationextraction, January.
https://github.com/mit-nlp/MITIE.Philipp Koehn.
2005.
Europarl: A parallel corpusfor statistical machine translation.
In Proceedingsof MT Summit.Jan Korenek.
2010.
Fast regular expression matchingusing FPGA.
Information Sciences and Technolo-gies Bulletin of the ACM Slovakia, 2(2):103?111.Jooyoung Lee, Sungkyong Un, and Dowon Hong.2008.
High-speed search using Tarari content pro-cessor in digital forensics.
Digital Investigation,5:S91?S95.Michael E Lesk and Eric Schmidt.
1975.
Lex: A lexi-cal analyzer generator, July.Cheng-Hung Lin, Chih-Tsun Huang, Chang-PingJiang, and Shih-Chieh Chang.
2006.
Optimizationof regular expression pattern matching circuits onFPGA.
In Design, Automation and Test in Europe,2006.
DATE?06.
Proceedings, volume 2, pages 1?6.IEEE.Marco Lui and Timothy Baldwin.
2011.
Cross-domainfeature selection for language identification.
In Pro-ceedings of the 5th International Joint Conferenceon Natural Language Processing, pages 553?561,Chiang Mai, Thailand, November.Marco Lui and Timothy Baldwin.
2012.langid.py: An off-the-shelf language iden-tification tool.
In Proceedings of the 50th AnnualMeeting of the Association for ComputationalLinguistics, pages 25?30, Jeju, Republic of Korea,July.Marco Lui.
2014.
Pure C natural language iden-tifier with support for 97 languages.
https://github.com/saffsd/langid.c.Mehryar Mohri, Fernando Pereira, and Michael Riley.2000.
The design principles of a weighted finite-state transducer library.
Theoretical Computer Sci-ence, 231(1):17?32.Kyoung-Su Oh and Keechul Jung.
2004.
GPU imple-mentation of neural networks.
Pattern Recognition,37(6):1311?1314.Isaac Rudom?
?n, Erik Mill?an, and Benjam?
?n Hern?andez.2005.
Fragment shaders for agent animation usingfinite state machines.
Simulation Modelling Prac-tice and Theory, 13(8):741?751.Reetinder Sidhu and Viktor K Prasanna.
2001.
Fastregular expression matching using FPGAs.
In Field-Programmable Custom Computing Machines, 2001.FCCM?01.
The 9th Annual IEEE Symposium on,pages 227?238.
IEEE.Dick Sites.
2013.
Compact language detection 2.https://code.google.com/p/cld2/.Jason R. Smith, Herve Saint-Amand, Magdalena Pla-mada, Philipp Koehn, Chris Callison-Burch, andAdam Lopez.
2013.
Dirt cheap web-scale paral-lel text from the common crawl.
In Proceedings ofthe 51st Annual Meeting of the Association for Com-putational Linguistics, Sofia, Bulgaria, August.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In Proceedings of the Sev-enth International Conference on Spoken LanguageProcessing, pages 901?904.Dawid Weiss.
2013.
Java port of langid.py(language identifier).
https://github.com/carrotsearch/langid-java.Makoto Yasuhara, Toru Tanaka, Jun-ya Norimatsu, andMikio Yamamoto.
2013.
An efficient languagemodel using double-array structures.
In Proceed-ings of EMNLP, pages 222?232, October.Youngmin Yi, Chao-Yue Lai, Slav Petrov, and KurtKeutzer.
2011.
Efficient parallel CKY parsing onGPUs.
In Proceedings of the 12th InternationalConference on Parsing Technologies, pages 175?185.
Association for Computational Linguistics.389
