Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 272?276,Prague, June 2007. c?2007 Association for Computational LinguisticsPU-BCD: Exponential Family Models for the Coarse- and Fine-GrainedAll-Words TasksJonathan ChangPrinceton UniversityDepartment of Electrical Engineeringjcone@princeton.eduMiroslav Dud?
?k, David M. BleiPrinceton UniversityDepartment of Computer Science{mdudik,blei}@cs.princeton.eduAbstractThis paper describes an exponential familymodel of word sense which captures bothoccurrences and co-occurrences of wordsand senses in a joint probability distribution.This statistical framework lends itself to thetask of word sense disambiguation.
We eval-uate the performance of the model in its par-ticipation on the SemEval-2007 coarse- andfine-grained all-words tasks under a varietyof parameters.1 IntroductionThis paper describes an exponential family modelsuited to performing word sense disambiguation.Exponential family models are a mainstay of mod-ern statistical modeling (Brown, 1986) and they arewidely and successfully used for example in textclassification (Berger et al, 1996).
In statisticalmachine learning research, a general methodologyand many algorithms were developed for undirectedgraphical model representation of exponential fam-ilies (Jordan, 2004), providing a solid basis for effi-cient inference.Our model differs from other probabilistic mod-els used for word sense disambiguation in that itcaptures not only word-sense co-occurrences butalso contextual sense-sense co-occurrences, therebybreaking the na?
?ve Bayes assumption.
Althoughspare in the types of features, the model is extremelyexpressive.
Our model has parameters that controlfor word-sense interaction and sense-sense similar-ity, allowing us to capture many of the salient fea-tures of word and sense use.
After fitting the param-eters of our model from a labeled corpus, the taskof word sense disambiguation immediately followsby considering the posterior distribution of sensesgiven words.We used this model to participate in SemEval-2007 on the coarse- and fine-grained all-words tasks.In both of these tasks, a series of sentences aregiven with certain words tagged.
Each competingsystem must assign a sense from a sense inventoryto the tagged words.
In both tasks, performancewas gauged by comparing the output of each systemto human-tagged senses.
In the fine-grained task,precision and recall were simply and directly com-puted against the golden annotations.
However, inthe coarse-grained task, the sense inventory was firstclustered semi-automatically with each cluster rep-resenting an equivalence class over senses (Navigli,2006).
Precision and recall were computed againstequivalence classes.This paper briefly derives the model and thenexplores its properties for WSD.
We show howcommon algorithms, such as ?dominant sense?
and?most frequent sense,?
can be expressed in the ex-ponential family framework.
We then proceed topresent an evaluation of the developed techniques onthe SemEval-2007 tasks in which we participated.2 The modelWe describe an exponential family model for wordsense disambiguation.
We posit a joint distributionover words w and senses s.2.1 NotationWe define a document d to be a sequence of wordsfrom some lexicon W; for the participation in thiscontest, a document consists of a sentence.
Associ-ated with each word is a sense from a lexicon S. In272this work, our sense lexicon is the synsets of Word-Net (Fellbaum and Miller, 2003), but our methodseasily generalize to other sense lexicons, such asVerbNet (Kipper et al, 2000).Formally, we denote the sequence of words in adocument d by wd = (wd,1, .
.
.
, wd,nd) and the se-quence of synsets by sd = (sd,1, sd,2, .
.
.
, sd,nd),where nd denotes the number of words in the docu-ment.
A corpus D is defined as a collection of doc-uments.
We also write w ?
s if w can be used torepresent sense s.2.2 An exponential family of words and sensesWe turn our attention to an exponential familyof words and senses.
The vector of parameters?
= (?,?)
consists of two blocks capturing depen-dence on word-synset co-occurrences, and synsetco-occurrences.p?,n(s,w)= exp{?i?wi,si +?i,j ?si,sj}/Z?,n .
(1)The summations are first over all positions in thedocument, 1 ?
i ?
n, and then over all pairs ofpositions in the document, 1 ?
i, j ?
n. We discussparameters of our exponential model in turn.Word-sense parameters ?
Using parameters ?alone, it is possible to describe an arbitrary contextindependent distribution between a word and its as-signed synset.Sense co-occurrence parameters?
Parameters?are the only parameters that establish the depen-dence of sense on its context.
More specifically,they capture co-occurrences of synset pairs within acontext.
Larger values favor, whereas smaller valuesdisfavor each pair of synsets.3 Parameter estimationWith the model in hand, we need to address twoproblems in order to use it for problems such asWSD.
First, in parameter estimation, we find valuesof the parameters that explain a labeled corpus, suchas SemCor (Miller et al, 1993).
Once the parame-ters are fit, we use posterior inference to compute theposterior probability distribution of a set of sensesgiven a set of unlabeled words in a context, p(s |w).This distribution is used to predict the senses of thewords.In this section, it will be useful to introduce thenotation p?
(s, w) to denote the empirical probabili-ties of observing the word-sense pair s, w in the en-tire corpus:p?
(s, w) =?d,i ?
(sd,i, s)?
(wd,i, w)/?d nd ,where ?
(x, y) = 1 if x = y and 0 otherwise.Similarly, we will define p?
(s) to denote the empiri-cal probability of observing a sense s over the entirecorpus:p?
(s) =?d,i ?
(sd,i, s)/?d nd .3.1 Word-sense parameters ?Fallback Let ?WNw,s = 0 if w ?
s and ?WNw,s = ??otherwise.
This simply sets to zero the probability ofassigning a word w to a synset s when w 6?
s whilemaking all w ?
s equally likely as an assignmentto s. This forces the model to rely entirely on ?for inference.
If ?
is also set to 0, this then forcesthe system to fall back onto its arbitrary tie-breakingmechanism such as choosing randomly or choosingthe first sense.Most-frequent synset One approach to disam-biguation is the technique of choosing the most fre-quently occurring synset which the word may ex-press.
This can be implemented within the model bysetting ?w,s = ?MFSw,s ?
ln p?
(s) if w ?
s and ?
?otherwise.MLE Given a labeled corpus, we would like tofind the corresponding parameters that maximizelikelihood of the data.
Equivalently, we would liketo maximize the log likelihoodL(?)
=?d[?i?wd,i,sd,i +?i,j ?sd,i,sd,j ?
lnZ?,nd].
(2)In this section, we consider a simple case when itis possible to estimate parameters maximizing thelikelihood exactly, i.e., the case where our modeldepends only on word-synset co-occurrences and isparametrized solely by ?
(setting ?
= 0).Using Eq.
(1), with ?
= 0, we obtainp?
(sD,wD) =exp{?d,i?wd,i,sd,i}?d Z?,nd.273Thus, p?
(sD,wD) can be viewed as a multino-mial model with?d nd trials and |S| outcomes,parametrized by ?w,s.
The maximum likelihood es-timates in this model are ?
?w,s ?
ln p?
(s, w).This setting of the parameters corresponds pre-cisely to the dominant-sensemodel (McCarthy et al,2004).
The resulting model is thusp?,n(s,w) =?i p?
(si, wi) .
(3)3.2 Sense co-occurrence parameters ?Unlike ?, it is impossible to find a closed-form so-lution for the maximum-likelihood settings of ?.Therefore, we turn to intuitive methods.Observed synset co-occurrence One natural adhoc statistic to use to compute the parameters ?
arethe empirical sense co-occurrences.
In particular, wemay set?si,sj = ?SFsi,sj ?
ln p?
(si, sj) .
(4)We will observe in section 5 that the performanceof ?
= ?SF actually degrades the performance ofthe system, especially when combined with ?
= ?
?.This can be understood as a by-product of an un-sympathetic interaction between ?
and ?.
In otherwords, ?
and ?
overlap; by favoring a sense pair themodel will also implicitly favor each of the senses inthe pair.Discounted observed synset co-occurrence Aswe noted earlier, the combination ?
= ??,?
= ?SFactually performs worse than ?
= ??,?
= 0.In order to cancel out the aforementioned over-lap effect, we attempt to compute the number ofco-occurrences beyond what the occurrences them-selves would imply.
To do so, we set?
= ?DSF ?
lnp?
(si, sj)p?(si)p?
(sj), (5)a quantity which finds an analogue in the notion ofmutual information.
We will see shortly that sucha setting of ?
will allow sense co-occurrence to im-prove disambiguation performance.4 Word Sense DisambiguationFinally, we describe how to perform WSD using theexponential family model.
Our goal is to assign asynset si to every word wi in an unlabeled documentd of length n. In this setting, the synsets are hiddenvariables.
Thus, we assign synsets according to theirposterior probability given the observed words:s?
= argmaxs?Snp?,n(s,w)?s?
p?,n(s?,w),where the sum is over all possible sequences ofsynsets.
This combinatorial sum renders exact infer-ence computationally intractable.
We discuss how toobtain the sense assignment using approximate in-ference.4.1 Variational InferenceTo approximate the posterior over senses, we usevariational inference (Jordan et al, 1999).
In vari-ational inference, one first chooses a family ofdistributions for which inference is computationllytractable.
Then the distribution in that family whichbest approximates the posterior distribution of inter-est is found.For our purposes, it is convenient to select q fromthe family of factorized multinomial distributions:q(s) =?iqi(si) ,where each qi(si) is a multinomial distributionover all possible senses.
Observe that finding s?
ismuch simpler using q(s): one can find the argmaxof each individual qi independently.It can be shown that the multinomial which mini-mizes the KL-divergence must satisfy:qi(si) ?
exp???
?wi,si +?j 6=i?sjqj(sj)?si,sj???
(6)a system of transcendental equations which canbe solved iteratively to find q.
This q is then used toefficiently perform inference and hence disambigua-tion.5 EvaluationThis section evaluates the performance of the modeland the techniques described in the previous sec-tions with respect to the coarse- and fine-grained all-words tasks at SemEval-2007.In order to train the parameters, we trained ourmodel in a supervised fashion on SemCor (Miller et274?
= ?WN ?
= ?MFS ?
= ???
= 0 52.0% 45.8% 51.2%?
= ?SF 48.8% 45.3% 52.5%?
= ?DSF 47.0% 44.6% 54.2%Table 1: Precision for the fine-grained all-words task.
The results corresponding to the bolded value wassubmitted to the competition.al., 1993) with Laplace smoothing for parameter es-timates.
We utilized the POS tagging and lemma-tization given in the coarse-grained all-words testset.
Wherever a headword was tagged differentlybetween the two test sets, we produced an answeronly for the coarse-grained test and not for the fine-grained one.
This led to responses on only 93.9% ofthe fine-grained test words.
Of the 6.1% over whichno response was given, 5.3% were tagged as ?U?
inthe answer key.In order to break ties between equally likelysenses, for the fine-grained test, the system returnedthe first one returned in WordNet?s sense inventoryfor that lemma.
For the coarse-grained test, an arbi-trary sense was returned in case of ties.The precision results given in this section are overpolysemous words (of all parts of speech) for whichour system gave an answer and for which the answerkey was not tagged with ?U.
?5.1 Fine-grained results (Task 17)The fine-grained results over all permutations of theparameters mentioned in Section 3 are given in Ta-ble 1.
Note here that the baseline number of ?
=0,?
= ?WN given in the upper-left is equivalent tosimply choosing the first WordNet sense.
Notably,such a simple configuration of the model outper-forms all but two other of the other parameter set-tings.When any sort of nonzero sense co-occurrenceparameter is used with ?
= ?WN, the performancedegrades dramatically, to 48.8% and 47.0% for ?SFand ?DSF respectively.
Since the discounting schemewas devised to positively interact with ?
= ?
?, it isno surprise that it does poorly when ?
is not set insuch a way.
And as mentioned previously, na?
?velysetting ?
to ?SF improperly conflates ?
and ?, yield-ing a poor result.When ?
= ?MFS is used, the precision iseven lower, dropping to 45.8% when no sense co-occurrence information is used.
And similarly to?
= ?WN, any nonzero ?
significantly degrades per-formance.
This seems to indicate the most-frequentsynset, as predicted by our earlier analysis, is an in-ferior technique.Finally, when?
= ??
is used (i.e.
dominant sense),the precision is 51.2%, slightly lower than but nearlyon par with that of the baseline.
When sense co-occurrence parameters are added, the performanceincreases.
For ?SF, a precision of 52.5% is achieved;a precision above the baseline.
But again, because ofthe interaction between ?
and ?, here we expect itto be possible to improve upon this performance.And indeed, when ?
= ?DSF, the highest valueof the entire table, 54.2% is achieved.
This is a sig-nificant improvement over the baseline and demon-strates that our intuitively appealing mutual informa-tion discounting mechanism allows for ?
and ?
towork cooperatively.5.2 Coarse-grained results (Task 7)In order to perform the coarse-grained task, our sys-tem first determined the set of sense equivalenceclasses.
We denote a sense equivalence class by k,where k is some sense key member of the class.
Theequivalence classes were created according to thefollowing constraints:?
Each sense key k may only belong to oneequivalence class k.?
All sense keys referring to the same sense smust belong in the same class.?
All sense keys clustered together must belongin the same class.Once the clustering is complete, we can proceedexactly as we did in the previous sections, while re-placing all instances of s with k. Thus, trainingin this case was performed on a SemCor where all275the senses were mapped back to their correspondingsense equivalence classes.The model fared considerably worse on thecoarse-grained all-words task.
The precision of thesystem as given by the scorer was 69.7% and therecall 62.8%.
These results, while naturally muchhigher than those for the fine-grained test, are low bycoarse-grained standards.
While the gold standardwas not available for comparison for these results,there are two likely causes of the lower performanceon this task.The first is that ties were not adjudicated bychoosing the first WordNet sense.
Instead, an ar-bitrary sense was chosen thereby pushing cases inwhich the model is unsure from the baseline to themuch lower random precision rate.
The second is thesame number of documents are mapped to a smallernumber of ?senses?
(i.e.
sense equivalence classes),the number of parameters is greatly reduced.
There-fore, the expressive power of each parameter is di-luted because it must be spread out across all senseswithin the equivalence class.We believe that both of these issues can be eas-ily overcome and we hope to do so in future work.Furthermore, while the model currently captures themost salient features for word sense disambiguation,namely word-sense occurrence and sense-sense co-occurrence, it would be simple to extend the modelto include a larger number of features (e.g.
syntacticfeatures).6 ConclusionIn summary, this paper described our participation inthe the SemEval-2007 coarse- and fine-grained all-words tasks.
In particular, we described an exponen-tial family model of word sense amenable to the taskof word sense disambiguation.
The performance ofthe model under a variety of parameter settings wasevaluated on both tasks and the model was shown tobe particularly effective on the fine-grained task.7 AcknowledgmentsThe authors would like to thank Christiane Fell-baum, Daniel Osherson, and the members of theCIMPL group for their helpful contributions.
Thisresearch was supported by a grant from Google Inc.and by NSF grant CCR-0325463.ReferencesAdam L. Berger, Vincent J. Della Pietra, and Stephen A.Della Pietra.
1996.
A maximum entropy approach to naturallanguage processing.
Computational Linguistics, 22(1):39?71.Lawrence D. Brown.
1986.
Fundamentals of Statistical Expo-nential Families.
Institute of Mathematical Statistics, Hay-ward, CA.Christiane Fellbaum and George A. Miller.
2003.
Mor-phosemantic links in WordNet.
Traitement automatique delangue.Michael I. Jordan, Zoubin Ghahramani, Tommi Jaakkola, andLawrence K. Saul.
1999.
An introduction to varia-tional methods for graphical models.
Machine Learning,37(2):183?233.Michael I. Jordan.
2004.
Graphical models.
Statistical Science,19(1):140?155.Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000.Class-Based Construction of a Verb Lexicon.
Proceedingsof the Seventeenth National Conference on Artificial Intelli-gence and Twelfth Conference on Innovative Applications ofArtificial Intelligence table of contents, pages 691?696.Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll.2004.
Finding predominant senses in untagged text.
InProceedings of the 42nd Annual Meeting of the Associationfor Computational Linguistics, pages 280?287, Barcelona,Spain.George A. Miller, Claudia Leacock, Randee Tengi, and Ross T.Bunker.
1993.
A semantic concordance.
In 3rd DARPAWorkshop on Human Language Technology.Roberto Navigli.
2006.
Meaningful clustering of senses helpsboost word sense disambiguation performance.
In COLING-ACL 2006, pages 105?112, July.276
