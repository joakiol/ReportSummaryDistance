Annotating emotion in dialogueRichard CraggsDepartment of Computer ScienceManchester Universitycraggs@cs.man.ac.ukMary McGee WoodDepartment of Computer ScienceManchester Universitymary@cs.man.ac.ukAbstractCommunication behaviour is affected byemotion.
Here we discuss how dialogue isaffected by participants?
emotion and howexpressions of emotion are manifested inits content.Keywords: Dialogue, Emotions, Annotation1 IntroductionDialogue annotation is a fundamental stage of muchof the research conducted on both Human-Humanand Human-Machine dialogue.We are fortunate to have access to a valuablecorpus of 37 dialogues between nurses and pa-tients, each comprising 200-1200 utterances (Wood,2001).
These consultations contain genuine emo-tional speech and form the ideal basis for studies ofrealistic conversational dialogue.The emotional state of participants affects theway in which the dialogue is conducted.
I proposethat annotating emotion in dialogue alongside cur-rently annotated phenomena will reveal interestingand useful correlations that will improve our under-standing of dialogue and benefit natural languageapplications.
The overall aim of this research isto develop a scheme for annotating expressions ofemotion, to create an annotated corpus of dialoguecontaining emotion and to study the effects that aparticipant?s emotional state has on their commu-nicative behaviour.2 Effects of emotion in dialogueThis research is motivated by observations made onthe consultation dialogues described above.
Theseare naturally occurring conversational dialoguesconducted under unusual circumstances, in whichthe consultant?s goal is to elicit concerns fromthe patient.
They therefore contain an unusuallyhigh level of emotional speech.
When read witha dialogue analyst?s eye it is apparent that certainphenomena, interesting to the dialogue analysiscommunity, are affected by the changing level ofemotion.
For example, grounding behaviour is moreprotracted when a participant is discussing a subjectabout which they feel emotional.
This is manifestedin an increase in the number of clarification requestsand repetitions.
E.g.
-N. How do you feel when you look at yourscar?P.
Erm, it doesn?t bother me that muchN OkayP.
But I still, When I?m washing and ev-erything I still get a funny feelingN.
You get a funny feeling, in which way?P.
It just feels strange, hollow,N.
Physically?P.
Physically yes,yesN.
YesP.
It feels really weirdTurn taking behaviour changes under these cir-cumstances too.
An emotional speaker will hold thefloor for an increased length of time when discussinga topic about which they feel, for example, anxietyor joy.Although these are casual observations of a smallamount of dialogue, other studies have benefitedfrom investigation into a speaker?s behaviour whenemotional.
For the Verbmobil project (Bub andSchwinn, 1996) it was recognised that anger inspeakers changed the way in which they commu-nicated (Fischer, 1999).
Also applications such asautomated call centres would benefit from recogni-tion of human emotion so that humans could inter-vene when a customer becomes angry and frustrated(Petrushin, 1999).
However, these insights are lim-ited to the vocal expression of the speaker.
An anno-tated corpus of emotional dialogue would allow usto study all aspects of a speaker?s behaviour.3 Annotating emotion in dialogueI envisage that a scheme to annotate dialogue wouldconstitute one or more layers augmenting an exist-ing annotation scheme.
There are plenty of otherschemes developed for previous dialogue research,many of which are designed to investigate a particu-lar phenomenon of communicative behaviour.In this section we will look at some existing an-notation schemes.
We shall investigate if any of thelayers may accommodate emotion and which maypresent interesting correlations with emotional tag-ging.Of course when looking for possible indicators ofemotional speech it is important to remember thatpeople exhibit different behaviours from each otherwhen they speak.
For example some people aremore expressive than others and so a large number ofexpletives from one person may be natural, and notindicative of their emotional state.
Prosodic studiesof emotion also suffer from this complexity and itwould be interesting to see if language use, and dia-logue behaviour are more robust indicators of emo-tion than prosody.3.1 Task and conversational dialogueMost dialogue research concentrates either on taskbased dialogue, where the participants converse inorder to achieve some set goal (e.g.
Maptask (An-derson et al, 1991) Coconut (Di Eugenio et al,1998)), or on conversational dialogue, which is of-ten less structured and contains a richer use of lan-guage (e.g.
DAMSL (Core and Allen, 1997) andChat (MacWhinney, 1998)).
It seems likely that wewould see more expressions of emotion in conver-sational dialogue where people are discussing topicsof personal interest rather than the more mechanicalprocess of achieving a goal through communication.These differences are reflected in the types ofphenomena that the schemes are designed to iden-tify.
Task based research may be more interestedin the structure of the dialogue and the way that itrepresents the division of the task into sub-goals.Schemes to annotate conversational dialogue aremore likely to require a greater breadth of dialogueacts to describe the wider range of illocutionary actsthat may be performed in this type of speech.3.2 Current dialogue annotation schemesIn order to learn how current annotation schemesaccommodate emotion, we aligned the layers in anumber of schemes.
(Core and Allen, 1997; Di Eu-genio et al, 1998; Traum, 1996; Walker et al, 1996;MacWhinney, 1996; Jekat et al, 1995; Anderson etal., 1991; Condon and Cech, 1996; van Vark et al,1996; Walker and Passonneau, 2001).
Layers fromdifferent schemes are grouped according to the sim-ilar phenomena that they label.
Table 1 shows thisalignment.In this section we will look at these layers anddiscuss how they may relate to annotating emotionin dialogue.Information level When analysing task dialogue,we may be interested in knowing whether an utter-ance pertains to the management of the communi-cations channel, advancement of a task, discussingof a task etc.
In the previous section we suggestedthat we are more likely to find emotional speech inconversational rather than task dialogue because thelatter is more of a mechanical process than conver-sation.
Perhaps we may consider this layer as an ex-tension of that distinction where sub-dialogues arelabelled according to how closely related to the taskthey are.This may reveal a correlation where the more re-lated to the task a sub-dialogue is, the less emotionalspeech becomes.
There is evidence in our corpusthat when one participant is attempting to achievea goal, often the elicitation of information, then theparticipants?
behaviour becomes more business likeand the language becomes more formal and lessexpressive ?N.
Was that Dr Smith who you saw there?P.
Yes but it wasn?t Dr Smith it was an-other doctor.N.
Right.P.
But I was under Dr Smith.N.
Right.
So when did you actually havethose radiotherapy treatments?P.
I had the radiotherapy October 13th.N.
Right, thank you.Communications statusCommunications status indicates whether an ut-terance was successfully completed.
It is used totag utterances that are abandoned or unintelligiblerather than whether the intention of a speech act wasachieved.Although failure to perform a successful utter-ance may be partly due to the emotional state ofthe speaker, annotating such utterances for theiremotional content may be difficult, especially fromthe textual content alone.
This and the multiplicityof reasons for unsuccessful communication meansthat using communications status as an indicationof emotion in the speaker will produce unreliableresults.In Human-Machine dialogue failure on behalf ofthe machine to communicate can lead to frustrationand anger in the user.
In these cases communicationstatus may signal behaviour that can result inemotion in the listener which is also applicable toHuman-Human dialogue.Speech actsAll of the schemes that we examined annotatedthe utterances for their illocutionary force.
Sincethis is the layer that contains most information re-garding the semantic content of an utterance, this islikely to be where we shall find the most interestingcorrelations.
We have already seen that high levelsof emotion in dialogue alters the frequencies ofdialogue acts compared with the more impassiveconversations conducted in the Switchboard corpus(Wood and Craggs, 2002).Forward communicative functions describe utter-ances that intend to evoke some response from thelistener (such as believing a statement or answeringa question), perform an action (such as committingto something) or similar dialogue advancing func-tions.
These types of utterance are likely to be mo-tivated by some intention or belief on behalf of thespeaker, providing clues as to their cognitive state.Forward communicative functions can play animportant role in eliciting emotional responses fromthe listener.
Open ended questions are more likely toproduce an emotional response than a yes/no ques-tion (Maguire et al, 1996b).
This is partly becauseopen questions hand the initiative to the listener al-lowing them to express themselves.
The relation-ship between questions, initiative and emotion is dis-cussed further in (Wood and Craggs, 2003).The following extract from our corpus show howan open question elicits an emotional response fromthe listener.N.
How were you coping with that yourself?P.
Oh mentally I?ve never been down men-tallyBackward communicative functions are used to la-bel utterances that respond to something that hasbeen said to them.
Some responses are requiredby the previous utterance, for example an answerfollowing a question.
In these cases the utterancewasn?t motivated by a desire on behalf of the speakerbut rather an obligation to adhere to the rules ofengagement for communication.
This of coursedoesn?t mean that a response can not be emotional.When faced with a proposal, question or offer thelistener is free to react as they wish and this includesemotional responses.Here a backward communicative act responds toappreciation with sympathy.N.
Good okay.
Well thank you as I say forfilling me in and...P. poor girl you?ve got to listen to allthatHowever, from observations of our emotionaldialogues it appears that short Question-Answer,Offer-Acceptance exchanges tend to be formal.Emotion tends to build though a sub-dialogue on atopic that speakers find funny, feel anxious about etc.Dialogue grammars are used to exploit the ex-pected sequences of speech acts.
These can be usedin dialogue act classification to predict the next actin a series of utterances (Stolcke et al, 2000).
It maybe possible that a complementary approach may beused to automatically identify emotional utterances.One way would be to develop grammars basedon patterns discovered in emotional sections ofdialogue where a particular sequence of acts mayindicate the proceedings have become emotional.Another may be to apply established grammars todialogue so that deviations from the grammar mayhighlight interesting or emotional passages.TopicSeveral annotation schemes contain a layer thatlabels the topic discussed in an utterance.
This isusually in task domains where there is a finite num-ber of subjects that will be discussed.
For exam-ple in the Alparon scheme for transport dialogues(van Vark et al, 1996), the topic layer (called ?cod-ing of information?
), labels utterances according towhether they relate to topics such as timetable, price,time and locations.For our corpus of cancer consultations it is ap-parent that certain topics are more likely to invokeemotion in people.
However topic annotation is onlyusually performed in the restricted domains of taskdialogues, where the range of topics that may be dis-cussed is limited.
However it is in these types ofdialogue that we expect the levels of emotion to below, and topics are chosen because of their necessityfor the task.
Because of this we may not get to seethe correlation between topic and emotion that weexpect.Topics may play a further role in identificationof emotion in dialogue since in our corpus, patientstend to remain on the same topic for longer whenthey emotional about it.
Length of a topic, or return-ing to a previously discussed topic are indicationsof emotion.PhasesSome schemes distinguish between dialoguephases such as opening, negotiation and query.Emotion in dialogue also goes through phases andit is possible that there are boundaries between thephases of emotion that correspond to those taggedusing the phase layer.An interesting area of research would be to iden-tify how boundaries between the phases of differentlevels and types of emotion are manifested in theuse of language.
For instance psycho-oncologyresearch states that open ended questions are morelikely to elicit emotional responses than yes-noquestions (Maguire et al, 1996a).
This may cause acorrelation between forward-looking functions andthe onset of phases.Surface formSurface form tagging is used in David Traum?sadaptation of the TRAINS annotation scheme(Traum, 1996) and the Coconut scheme to tag utter-ances for certain special features such as cue wordsor negation.It has been shown that certain syntactic featuresof an utterance may be indicators of emotion.
Forexample in German use of modal particles suchas ?eben?
and ?denn?
colour the utterance with aparticular emotional attitude.Although the surface form of utterances is depen-dent on the style of the speaker, it does sometimescontain indications of emotion.P.
Oh no, no no no no, I?m not in any dis-comfortRelatedness and Information relationsThe relatedness layer is used to show how utter-ances relate to one another, usually by tagging an ut-terance with the distance to the antecedent to whichit refers.Information relation describes the relationship be-tween utterances, for instance that one utterancepresents information in support of its antecedent.These layers are more concerned with the struc-ture of the dialogue than the semantic content andare therefore less likely to correlate well with emo-tional tags.It would be interesting to see if the emotionallevel of the dialogue or its participants has an affecton the dialogue?s structure.
In our corpus it appearsthat discussion of emotional topics is often moreprotracted, with speakers answering questions withsuccessive statements, each adding more detail totheir answer.
This type of behaviour may show upin the relatedness and information relations layers.GroundingGrounding describes the process by which com-mon ground between the participants is established.As with relatedness and information relations,emotion in the dialogue may be manifested in thislayer by protracted grounding behaviour as peoplereiterate points about which they feel emotional.
Inour highly emotional corpus this resulted in fourtimes as many summaries and five times as manyrepetitions than in the Switchboard corpus.Besides the layers listed here there are other lay-ers included in schemes that do not fit into anyof these categories.
For instance Verbmobil (Jekatet al, 1995) includes a layer for annotating thepropositional content of an utterance, and contentrelevance in the Penn multi-party coding scheme(Walker et al, 1996).
Investigation on dialogue an-notated for emotion will show whether there are anyinteresting correlations with these layers.4 Emotional speech corporaOne of the difficulties in analysing emotion in com-munication is in obtaining the material to study.
Forstudies into task dialogues, researchers can simplyrecord speakers performing the tasks.
However cap-turing conversational dialogue in general and espe-cially emotional dialogue is a much more difficulttask.Studies into emotional speech based on acousticfeatures use three approaches to attain their data.Ideally it is preferable to use genuine speech takenwithout the speaker?s knowledge since you can beconfident that the resulting data will faithfully repre-sent human behaviour.
An example of research us-ing this type of data is (Scherer and Ceschi, 2000).This approach isn?t commonly adopted, partly be-cause of the ethical issues concerned with recordingpeople without their consent and also because of thedifficulty in controlling variables such as recordingquality or establishing age, sex, etc.
of the speaker.For dialogue studies this would also be the desiredtype of data.
If we are interested communicative be-haviour such as turn-taking and language use ratherthan the acoustic features of the speech then we neednot be so concerned with the acoustic quality.
If itwere possible to obtain recordings of police inter-views, legal trails or calls to emergency services thenthese would provide suitable material to study.
Ourcorpus of oncology consultations is a good exampleof this type of dialogue.A more common type of data used in speech stud-ies is that of acted emotions.
Actors deliver linesexpressed with different emotions (e.g.
(Dellaert etal., 1996)).
The quality of this data is reliant onthe accuracy with which the emotion is acted.
Thisis suitable for establishing the prosodic features as-sociated with various emotions but not for dialoguestudies.
It would be much more difficult to recreatethe communicative behaviour of an emotional per-son through acting than to simply sound emotional.Finally, induced emotion, where participants areprovoked into an emotional state so that their speechcan be recorded (e.g.
(Huber et al, 2000)) .
Thisprovides natural emotion within a laboratory setting.It is conceivable that this process could be adapted toobtain induced emotional dialogue.
One participantmay try to conduct a conversation during which theother may behave emotionally.
However it is likelythat the data derived from this would be unlike realconversations.It is apparent that when studying emotion in dia-logue it would be desirable to obtain genuine con-versations that contained some degree of emotion.Attempting to induce emotion is likely to cause thecommunicative behaviour to become unnatural.
Thepreferable option would be to use natural conversa-tion in unusually emotional circumstances such asthose described above.5 Toward an emotion annotation schemeIn developing an annotation scheme our first stepwill be to decide on the facets of emotion which wewould like to identify.
Emotion is a very vague wordand so it is important that we polarise it into clearand understandable aspects of human cognition.
InLayer DAMSL Coconut Traum Penn MaptaskInfo level Info Level Info Level Info TypeComm status Comms StatusTopic Topic TopicSpeech act Dialogue acts Comm function Illocutionary func Speech acts MovesInfo relations Info relations Info relations ArgumentationRelatedness Antecedent Link Relatedness InitiativeGrounding Grounding Info statusSurface form Surface features Surface formPhasesLayer Verbmobil Chat Condon & Cech Alparon DateInfo level Interchange type Metalanguage DomainComm statusTopic Info coding SubtasksSpeech act Dialogue acts Illocutionary force Move function Moves Speech actsInfo relationsRelatednessGroundingSurface formPhases Phases PhasesTable 1: Annotation schemes and their layersorder for the annotation to be useful these aspectsmust have some influence on their communicativebehaviour.
They must also be identifiable from thelanguage of the dialogue.
This will mean that thescheme may consist of several layers each describ-ing a different aspect of human emotion.One of the differences between these types of lay-ers and those current schemes is that rather than dis-crete categories such as those used to label speechacts we can observe varying levels of emotion.
Aprecedent for this type of annotation exists in thelabelling of expressions of concern in the oncol-ogy consultation coding scheme of PsychologicalMedicine Group at Manchester University (Heavenand Green, 2001).
where these cues are rated 0?3.If this approach was adopted then we would have todecide on the number of levels to chose from basedon a trade-off between ease of performing annota-tion with getting a fine enough distinction betweendifferent levels.This would allow us to draw conclusions aboutcommunicative behaviour under different levels ofemotion (e.g.
?The length of utterances becomeslonger under increasing levels of anxiety?)
and cor-relations with other layers (e.g.
?People ask openquestions when relaxed but closed questions whenagitated?).
It would also allow us to plot the quanti-tative level of emotions throughout the dialogue, in-vestigate the way in which this changes and identifythe language phenomena that signal these changes.If only for pragmatic reasons, it would be wise tochoose utterances as the basic unit for annotation.By utterances here we refer to the common under-standing described as ?a sequence of communicativebehaviour bounded by lack of activity?
(Allwood,1996).
This would not only allow us to apply otherschemes to emotionally annotated dialogue, but alsoto use tools that have been developed to work on ut-terances.
It would therefore be necessary to chosedimensions of emotion that can be applied to utter-ances.There is an interesting question of whether emo-tion is a property of the participants or the dialogue.Obviously two or more people participating in a di-alogue will react differently to the proceedings andwill therefore exhibit different emotions.
Howeverit is apparent from our corpus that the dialogue it-self has its own levels of emotion.
For instance, theconversation may go through a phase of solemnityduring which the participants may exchange a joke.The mood of the dialogue outlives this perturbationand remains serious.
It would appear that it may beuseful to track the emotional state of the dialogueas well as the speakers since one will clearly havean effect on the other.
Quantitative annotation andanalysis of the flow of these levels would thereforebe useful here too.6 Future workOur next step will be to design an annotation schemebased on the observations and principles statedthroughout this paper.
We could then start annotat-ing our corpus for the emotional dimensions that wehad chosen.In order to assess the correlations that we pro-posed might exist in section 3, we would have toannotate these dialogues with the layers of otherschemes.
Since none of schemes contain all of thelayers, we would have to combine individual layersbased on our beliefs about which could be most use-ful and the ease with which we would annotate thedialogue.
It would make sense to select layers fromschemes which have comprehensive coding manu-als, which have been shown to be reliable and whichwould be accommodated by annotation tools.Before any claims about the effects of emotion indialogue can be made, the reliability of the schememust be established.
Once this has been achievedthan analysis of the results can begin.An annotated corpus would present us with theopportunity to investigate correlations and attemptto identify the effects the various types of emotionon the behaviour of the participants.
It is likely thatalong with the possible effects that we have prof-fered in this paper there will be other interesting pat-terns that become apparent from the results of ourannotation.
This will improve our understanding ofbehaviour in dialogue and benefit dialogue applica-tions.ReferencesJ Allwood.
1996.
On dialogue cohesion.
In Papers fromThirteenth Scandinavian Conference of Linguistics.A Anderson, M Bader, E Bard, Boyle E, G Doherty,S Garrod, S Isard, J Kowtko, J McAllister, J Miller,C Sotillo, H Thompson, and R Weinert.
1991.
TheHCRC Map Task corpus.
Language and Speech,34:351?66.T Bub and J Schwinn.
1996.
VERBMOBIL: The evo-lution of a complex large speech-to-speech translationsystem.
In Proc.
ICSLP ?96, volume 4, pages 2371?2374, Philadelphia, PA.S Condon and C Cech, 1996.
Manual for CodingDecision-Making Interactions.Mark G Core and James F Allen.
1997.
Coding dialogswith the damsl annatation scheme.
In AAAI Fall Sym-posium on Communicative Action in Humans and Ma-chines.F.
Dellaert, T. Polzin, and A. Waibel.
1996.
Recognizingemotions in speech.
In Proc.
ICSLP ?96, volume 3,pages 1970?1973, Philadelphia, PA.B Di Eugenio, P.W Jordan, and L Pylkkanen, 1998.
TheCOCONUT project: Dialogue Annotation Manual.ISP Technical Report 98-1.K Fischer.
1999.
Annotating emotional langauge data.Technical report, Verbmobil - report 236.C Heaven and C Green, 2001.
Medical Interview AuralRating Scale, CRC psychological medical group, Oc-tober.R.
Huber, A. Batliner, J. Buckow, E. No?th, V. Warnke,and H. Niemann.
2000.
Recognition of Emotion ina Realistic Dialogue Scenario.
In Proc.
Int.
Conf.
onSpoken Language Processing, volume 1, pages 665?668, Beijing, China, Oktober.S Jekat, A Klein, E Maier, I Maleck, M Mast, andJ Quantz.
1995.
Dialogue acts in Verbmobil.Technical Report 65, DFKI Saarbrucken, UniversitatStuttgart, Technische Universitat Berlin, Universitatdes Saarlandes.B MacWhinney, 1996.
The CHILDES System.
CarnegieMellon University.B MacWhinney, 1998.
The CHILDES Project: Tools forAnalysing Talk.
Carnegie Mellon University.P Maguire, K Booth, C Elliott, and B Jones.
1996a.Helping health professionals involved in cancer carework shops acquire key interviewing skills ?
the im-pact of workshops.
European journal of cancer,32A(9):1486?1489.P Maguire, K Faulkner, K Booth, C Elliot, and V Hillier.1996b.
Helping cancer patients disclose their con-cerns.
European Journal of Cancer, 32(9):1486?1489.V.
Petrushin.
1999.
Emotion in speech: Recognition andapplication to call centers.K.R Scherer and G Ceschi.
2000.
Criteria for emo-tion recognition from verbal and nonverbal expression:studying baggage loss in the airport.
Personality & So-cial Psychology Bulletin, 26(3):327, March.A.
Stolcke, K. Ries, N. Coccaro, E. Shriberg, R. Bates,D.
Jurafsky, P. Taylor, R. Martin, C. Van Ess-Dykema,and M. Meteer.
2000.
Dialogue act modeling forautomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26:339?373.D Traum, 1996.
Coding Schemes for Spoken DialogueStructure.R.J van Vark, J.P.M de Vreught, and L.J.M Rothkrantz,1996.
Analysing OVR dialogue coding scheme 1.0.Delft University of Technology.M Walker and R Passonneau.
2001.
DATE: a dialogueact tagging scheme for evaluation of spoken dialoguesystems.
In Proceedings: Human Language Technol-ogy Conference, San Diego, March.
AT&T ShannonLabs.M Walker, E Maier, J Allen, J Carletta, S Condon,G Flammia, J Hirschberg, S Isard, M Ishizaki, L Levin,S Luperfoy, D Traum, and S Whittaker, 1996.
Pennmultiparty standard coding scheme, Draft annotationmanual.M.M Wood and R Craggs.
2002.
Rare dialogue acts inoncology consultations.
In Submitted to SIGdial3.M.M Wood and R Craggs.
2003.
Initiative in health caredialogues.
In Submitted to DiaBruck 7th workshop onthe semantics and pragmatics of dialogue.M.M Wood.
2001.
Dialogue tagsets in oncology.
InProceedings of Sigdial2.
