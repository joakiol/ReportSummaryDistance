llIII////////lProper  Name Class i f icat ion in an In format ion  Ext ract ion  ToolsetPeter Wallis, Edmund Yuen, and Greg ChaseInformation Technology Division, DSTO, Box 1500 Salisbury, Sth Aust.
5108{Peter.Wallis,Edmund.Yuen,Greg.Chase}@dsto.defence.gov.auAbstractApplied discourse analysis is a hot topic in In-formation Retrieval (IR) and the related fieldof Information Extraction (IE).
Although in-teresting observations about discourse can bemade "by hand," applications require largequantities of data about language - -  datawhich is rather uninteresting.
This paper in-vestigates u ing statistical analysis over a bodyof text to suggest new rules for recognizingnamed entities.1 IntroductionUnderstanding human languages on any sort ofscale is a knowledge intensive task.
This paper de-scribes a corpus based approach to gathering lan-guage data in the shallow parts of the NLP pond.Information retrieval is a popular application for re-searchers interested in applied NLP, but the problemof improving retrieval effectiveness appears to be in-tractable (Smeaton, 1992; Wallis, 1995).
One helpfultechnique is tagging the proper names in text.
Tag-ging and classifying (e.g.
Is "Washington" a placeor a person?)
the named entities and co-referencesto them (she, he, the company) in text is also a pri-mary concern in systems for information extraction(DARPA, 1995).Information extraction (IE) is a well defined task;the aim being to extract data from free text, andput it in a more structured format.
The IE task isnot only well defined, it has application and is henceoften seen as a prime example of language ngineer-ing, where the aim is to explicitly solve a problemrather than to understand the nature of language.IE systems have typically only been successful innarrow domains with significant effort required tomove and existing information extraction system toa new problem domain.
One approach is to use toolsin a development environment that assists the lan-guage engineer to create a new information extrac-tion system from pre-exisiting components.The DSTO Fact Ext rac tor  Workbench pro-vides the tools to create re-usable text skimmingcomponents, called fact extractors, that perform IEon a (very) limited domain.
These components canbe used directly to find things like dates and thenames of companies including co-references, or theycan be assembled to create larger fact extractors thatskim text for more abstract entities uch as companymergers.The workbench provides different views of the do-main text to assist in the development process.
Asan example, the language ngineer might be inter-ested in seeing how the word "bought" is used inthe domain o.f interest.
A "grep"-like tool allowshim or her to view all and only those sentences con-taining "bought".
Naturally more complex patternsare possible incorporating previously developed factextractors in the pattern.This paper discusses an extension to the corpusviewing tool set that assists the language ngineerto find words, called selector terms, that may aid inthe classification of proper nouns and determinationof possible co-references for those nouns.
First, wedescribe the domain in which we are applying ourfact extractors.
Next, we introduce our method ofmeasuring the suitability of words as selector terms.Lastly we discuss how this data is collected and pre-sented in the fact extractor workbench.2 Problem DomainThe Named Entity Test is one component ofthe message understanding conference (MUC 5-7 (DARPA, 1995)) evaluations.
The goal of the NEtest is to add SGML tags to the evaluation textsthat mark up all the proper names.
The body oftext used in these trials is a selection of articlesfrom the Wall Street Journal.
McDonald (McDon-ald, 1996) characterizes the problem as having threesub-components:Wallis, Yuen and Chase 161 Proper Name ClassificationPeter Wallis, Edmund Yuen and Greg Chase (1998) Proper Name Classification in an Information Extraction Toolset.
InD.M.W.
Powers (ed.)
NeMLaP3/CoNLL98: New Methods in Language Processing and Computational Natural LanguageLearning, ACL, pp 161-162.?
delimit he sequence of words that make up thename, i.e.
identify its boundaries;?
classify the resulting constituent based on thekind of individual it names (e.g.
Person, Orga-nization, Location); and?
record the name and the individual it denotesin the discourse modelThe emphasis in this paper is on a method forclassifying the name using external evidence.2.1 Classif icat ionDuring this process, internal  evidence (McDon-ald, 1996) may be gleaned as to the type of thenamed entity.
Titles such as Mr, Ms, Dr, Sir, and Jrprovide evidence of the named entity being a person.The presence of Ltd. or G.m.b.H.
signify a company.Externa l  evidence (McDonald, 1996) about anamed entity's type can also be used.
If it is unclearwhether a name refers to a person or a company, itcan help to look at the verb it participates in, orat any modifiers it may have.
People do things like"head" organizations, "speak" and "walk".
Com-panies "merge" and "take measures".
People haveemployment roles, gender, and age; companies havelocations and managing directors.
Ideally a sys-tem would have rules that say if a subject-of-a-verb( < NE >, (head, say, explain ...) ) thenthe named entity is of type person.
Similarly afunction modified-by( < NE >, (chairman, head,< number > years old, ...) ) could be used in arule to determine if the < NE > is a person.
Writ-ing such rules require a list of terms which are goodselector  te rms for the entity of interest.
The pro-posal is to add a tool to the fact extractor work-bench that helps the language ngineer find goodselector terms using probabilistic measures.3 Finding Class SelectorsTo measure how good a selector term is for an ex-isting fact extractor, we need to compare the proba-blity that the word is present in a sentence and theprobability that the word is in a sentence given thata "fact" is in that sentence.w = wordS = sentenceSf = sentence with fact fProb(w in S \[ f in S) =number of S I with wnumber of S f(1)number of S with wProb(w in S) = number of S (2)If w and f are independent then 1 will approx-imate 2 however if they are dependent 1 will bedifferent from 2.A measure of w's selective power can be calculatedas a ratio.Sell(w ) ~ Prob(w in S t f in S)Prob( w in S) (3)An Sel of close to 1 indicates little correlation be-tween the term, w, and the fact, \].
An Sel sig-nificantly greater than 1 indicates a high degree ofcorrelation between w and f and hence w is a goodselector term.
Interestingly, a Sel of significantly lessthan 1 (close to zero) indicates that the presence ofw is a good indication of f being absent.4 Incorporating Selective PowerA tool has been incorporated into the Fact ExtractorWorkbench that allows the user to run one or morefact extractors over the text corpus and produce andordered set of candidate selector terms.
This list ofselector terms can then be considered for inclusioninto a more refined fact extractor.For example, by measuring the selective power ofcorpus words for the "City" fact extractor pattern,we can find which words are used in the context ofWashington, the city and which are used in the con-text of Washington, the person.
By ranking corpuswords based on selective power, we single out can-didates as good selector terms to refine the "City"fact extractor.ReferencesDefense Advanced Research Projects Agency(DARPA).
Proceedings Sixth Message Un-derstanding Conference (MUC-6), November1995.David D. McDonald.
Internal and external evi-dence in the identification and semantic atego-rization of proper names.
In Branirn~ir Bogu-raev and James Pustejovsky, editors, Corpus Pro-cessing for Lexical Acquisition, pages 21-39.
MITPress, Cambridge, Mass, 1996.
A Bradford Book.Alan F. Smeaton.
Progress in the application ofnatural language processing to information re-trieval tasks.
The Computer Journal, 35(3):268-278, 1992.Peter Wallis.
Semantic Signatures for InformationRetrieval.
PhD thesis, Faculty of Applied Science,R.M.I.T., 1995.Wallis, Yuen and Chase 162 Proper Name ClassificationIIIIIIIIIIIIIIIIIIIiIIIIIIII
