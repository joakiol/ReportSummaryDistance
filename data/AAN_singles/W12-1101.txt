JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 1?13,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPIndexation libre et contr?l?e d?articles scientifiquesPr?sentation et r?sultats du d?fi fouille de textes DEFT2012Patrick Paroubek1 Pierre Zweigenbaum1 Dominic Forest2 Cyril Grouin1(1) LIMSI?CNRS, Rue John von Neumann, 91403 Orsay, France(2) EBSI, Universit?
de Montr?al, C.P.
6128, succursale Centre-ville, Montr?al H3C 3J7, Canada{pap,pz,grouin}@limsi.fr, dominic.forest@umontreal.caR?SUM?Dans cet article, nous pr?sentons la campagne 2012 du d?fi fouille de texte (DEFT).
Cette ?ditiontraite de l?indexation automatique par des mots-cl?s d?articles scientifiques au travers de deuxpistes.
La premi?re fournit aux participants la terminologie des mots-cl?s employ?s dans lesdocuments ?
indexer tandis que la seconde ne fournit pas cette terminologie, rendant la t?cheplus complexe.
Le corpus se compose d?articles scientifiques parus dans des revues de scienceshumaines, index?s par leurs auteurs.
Cette indexation sert de r?f?rence pour l??valuation.
Lesr?sultats ont ?t?
?valu?s en termes de micro-mesures sur les rappel, pr?cision et F-mesure calcul?sapr?s lemmatisation de chaque mot-cl?.
Dans la piste fournissant la terminologie des mots-cl?semploy?s, la F-mesure moyenne est de 0,3575, la m?diane de 0,3321 et l?
?cart-type de 0,2985 ;sur la seconde piste, en l?absence de terminologie, la F-mesure moyenne est de 0,2055, la m?dianede 0,1901 et l?
?cart-type de 0,1516.ABSTRACTControlled and free indexing of scientific papersPresentation and results of the DEFT2012 text-mining challengeIn this paper, we present the 2012 edition of the DEFT text-mining challenge.
This editionaddresses the automatic, keyword-based indexing of scientific papers through two tracks.
Thefirst gives to the participants the terminology of keywords used to index the documents, while thesecond does not provide this terminology.
The corpus is composed of scientific papers publishedin humanities journals, indexed by their authors.
This indexing is used as a reference for theevaluation.
The results have been evaluated in terms of micro-measures on the recall, precisionand F-measure computed after keyword lemmatization.
In the track giving the terminology ofused keywords, the mean F-measure is 0.3575, the median is 0.3321 and the standard deviationis 0.2985 ; in the second track, the mean F-measure is 0.2055, the median is 0.1901 and thestandard deviation is 0.1516.MOTS-CL?S : Campagne d?
?valuation, fouille de textes, indexation libre, indexation contr?l?e,mots-cl?s, th?saurus.KEYWORDS: Evaluation campaign, Text-Mining, Free Indexing, Controlled Indexing, Keywords,Thesaurus.11 IntroductionLa r?daction d?un article scientifique s?accompagne g?n?ralement de m?ta-donn?es que l?auteurde l?article doit tr?s souvent renseigner : titre, auteurs, affiliation des auteurs, et g?n?ralementun r?sum?
pr?sentant bri?vement le contenu de l?article et un ensemble de mots-cl?s d?crivantles th?mes de l?article.
Ces mots-cl?s visent ?
aider la recherche des articles dans les bases dedonn?es bibliographiques.La campagne DEFT 2012 s?int?resse ?
la d?termination des mots-cl?s appropri?s pour un article.Cela demande d?une part de d?terminer les th?mes principaux de l?article et d?autre part dechoisir des termes pour les nommer.Certaines disciplines ont constitu?
un th?saurus qui prescrit les termes ?
employer pour cela.
C?estle cas par exemple des sciences de la vie avec le th?saurus MeSH (Medical Subject Headings)1avec ses 26 142 descripteurs (version 2011), ou encore de l?informatique avec la classificationhi?rarchique de l?ACM2 et ses 368 classes.
Des th?saurus ?
vocation plus large ont aussi ?t?
cr?
?s,telle que la classification de la Biblioth?que du Congr?s des ?tats-Unis3.
Ces r?f?rentiels visent ?contr?ler l?indexation des documents et ?
aider ainsi leur recherche.?
l?inverse, dans certaines revues ou conf?rences, aucun r?f?rentiel n?est impos?
pour le choix desmots-cl?s indexant un article.
Dans cette indexation libre, g?n?ralement r?alis?e par les auteurseux-m?mes, le choix des mots-cl?s devient plus subjectif, chacun ayant une vision diff?rente destermes ?
utiliser pour caract?riser l?article.C?est donc dans le cadre de cette probl?matique d?indexation libre ou contr?l?e des articlesscientifiques que nous avons inscrit cette nouvelle ?dition du d?fi fouille de texte (DEFT).1.1 ?tat de l?artLes travaux dans le domaine de l?indexation des documents, qu?elle soit automatique (Saltonet al, 1975) ou non (Lancaster, 2003), ne sont pas r?cents.
Parmi les m?thodes g?n?ralementappliqu?es pour la cr?ation de classes de termes, celles-ci comprennent traditionnellement deux?tapes : l?identification de termes dans un premier temps, puis la s?lection des meilleurs candidats.L?
?tude des cooccurrences de termes (avec pr?-traitements tels que ?tiquetage des parties dudiscours et lemmatisation) et l?utilisation de connaissances du domaine permet d?obtenir desr?sultats exploitables (Toussaint et al, 1998).
Ces techniques reprennent celles en vigueuren recherche d?information.
Appliqu?es aux syntagmes nominaux, elles fournissent une basequi ne peut cependant suffire pour l?indexation (Sidhom, 2002).
Des exp?riences d?indexationcontr?l?e automatique (au moyen de l?algorithme Okapi) et manuelle sur un corpus en fran?aisont d?montr?
l?int?r?t de combiner ces deux approches pour am?liorer les r?sultats (Savoy,2005).
Des approches plus r?centes en mati?re d?indexation automatiques prennent en compte lacoccurrence des termes associ?es ?
la structure des documents (Pompidor et al, 2008).
D?autresm?thodes ont aussi ?t?
exploit?es pour assister l?indexion automatique des documents, parmilesquelles on retrouve la s?mantique latente (Deerwester et al, 1990).1MeSH (National Library of Medicine) : http://www.nlm.nih.gov/mesh/MBrowser.html.2Association for Computing Machinery, Computing Classification System : http://dl.acm.org/ccs.cfm?part=author&coll=portal&dl=GUIDE.3Library of Congress Classification : http://www.loc.gov/catdir/cpso/lcc.html.21.2 D?roulementUn appel ?
participation a ?t?
lanc?
le 5 f?vrier 2012 sur les principales listes de diffusion dans lesdomaines des sciences de l?information (ASIS-L), de la fouille de textes (TextAnalytics, KDnuggets),des humanit?s num?riques (DH, Humanist), du Traitement Automatique des Langues et de lalinguistique de corpus (Corpora, LN, etc.).
Dix-huit ?quipes se sont inscrites, pour certaines alorsm?me que la phase de test avait d?j?
commenc?, tandis que dix ?quipes ont poursuivi leurs effortsjusqu??
la p?riode de tests.
Ces ?quipes sont les suivantes, des inscriptions les plus anciennes (6f?vrier) aux plus r?centes (11 avril) :?
FBK, Fondazione Bruno Kessler, Trento, Italie : Sara Tonelli, Elena Cabrio, Emanuele Pianta.?
LIM&BIO, Laboratoire d?Informatique M?dicale & bioinformatique, Universit?
Paris 13 Nord,Bobigny (93) : Thierry Hamon.?
URPAH, Unit?
de Recherche en Programmation Algorithmique et Heuristique, Facult?
des Sciencesde Tunis, Tunisie : Amine Amri, Mbarek Maroua, Chedi Bechikh, Chiraz Latiri, Hatem Haddad.?
GREYC, Groupe de Recherche en Informatique, Image, Automatique et Instrumentalisation deCaen, Universit?
de Caen Basse-Normandie, Caen (14) : Ga?lle Doualan, Mathieu Boucher,Romain Brixtel, Ga?l Lejeune et Ga?l Dias.?
IRISA, Institut de Recherche en Informatique et Syst?mes Al?atoires, Universit?
Rennes 1, Rennes(35) : Vincent Claveau et Christian Raymond.?
LINA, Laboratoire d?Informatique de Nantes Atlantique, Universit?
de Nantes/?cole des Minesde Nantes, Nantes (44) : Florian Boudin, Amir Hazem, Nicolas Hernandez et Prajol Shrestha.?
LIMSI, Laboratoire d?Informatique pour la M?canique et les Sciences de l?Ing?nieur, Orsay (91) :Alexander Pak.?
LUTIN, Laboratoire des Usages en Technologies d?Information Num?rique, Universit?
Paris8/UPMC/UTC/Universcience, Paris (75) : Adil El Ghali, Daniel Hromada et Kaoutar El Ghali.?
LORIA, Laboratoire Lorrain de Recherche en Informatique et ses Applications, Nancy (54) : AlainLelu et Martine Cadot.?
PRISM, laboratoire Parall?lisme, R?seaux, Syst?mes et Mod?lisation, Universit?
Versailles?Saint-Quentin-en-Yvelines (78) et LaISC Laboratoire d?Informatique et des Syst?mes Complexes, EPHE,Paris (75) : Murat Ahat, Coralie Petermann, Yann Vigile Hoareau, Soufian Ben Amor et MarcBui.Les corpus d?entra?nement ont ?t?
diffus?s aux participants inscrits ayant retourn?s l?accord derestriction d?usage des corpus sign?s ?
partir du 6 f?vrier 2012.
Chaque ?quipe a choisi unefen?tre de trois jours durant la semaine du 9 au 15 avril 2012 pour appliquer ses m?thodes sur lecorpus de test.
Les r?sultats ont ?t?
communiqu?s aux participants le 17 avril.
La version finaledes articles pr?sentant les m?thodes utilis?es ?tait attendue pour le 1er mai, pour un atelier decl?ture le 8 juin 2012 pendant la conf?rence jointe JEP/TALN ?
Grenoble.Pour la premi?re fois dans l?histoire de DEFT, nous avons voulu mettre en place une interfacede soumission des fichiers de r?sultats qui permettent de lancer une ?valuation.
Cette interface,d?riv?e d?une version utilis?e dans un projet d?annotation de corpus, a n?cessit?
de nombreusesadaptations et n?a pu ?tre utilis?e par les participants que trop tardivement (?
partir du 6 avril, soitune semaine avant le d?marrage de la phase de test) avec une fonction d?
?valuation r?ellementop?rationnelle qu?en fin de p?riode de test.
En cons?quence, les participants au d?fi n?ont pas puacc?der ?
l?outil d?
?valuation de leurs r?sultats pendant la p?riode d?entra?nement, ce qui, nousen convenons, ne facilite pas le d?veloppement de m?thodes ni l?appr?ciation des ?volutionsoffertes par les tentatives de modifications de ces m?thodes durant cette p?riode.32 Pr?sentationDans la continuit?
de l?
?dition 2011 du d?fi (voir DEFT2011), nous proposons de travailler denouveau sur un corpus d?articles scientifiques parus dans le domaine des Sciences Humaineset Sociales.
Alors que l?
?dition 2011 visait l?appariement de r?sum?
avec l?article scientifiquecorrespondant, nous proposons cette ann?e d?identifier les mots-cl?s, tels qu?ils ont ?t?
choisispar les auteurs, pour indexer ces m?mes types d?articles.
Les m?thodes qui seront utilis?es pouridentifier les mots-cl?s devraient permettre de mettre en ?vidence les ?l?ments saillants quipermettent d?indexer le contenu d?un article au moyen de mots-cl?s.2.1 PistesDeux pistes sont propos?es autour de l?identification de mots-cl?s (chaque piste dispose de sespropres corpus d?apprentissage et de test) :?
la premi?re piste renvoie ?
l?indexation contr?l?e des articles scientifiques et fournit la termi-nologie des mots-cl?s utilis?s dans le corpus de cette piste (avec cependant une terminologiedistincte pour chaque sous-corpus : une premi?re pour l?apprentissage, une seconde pour letest), cette terminologie constituant une aide ?
la d?couverte des mots-cl?s ;?
la seconde piste renvoie ?
une indexation libre et ne fournit donc pas cette terminologie der?f?rence ; les participants doivent identifier par eux-m?mes, dans le contenu du r?sum?
et ducorps de l?article, quels sont les mots-cl?s qui ont pu ?tre choisis par l?auteur de l?article.Sur chacune des deux pistes, le nombre de mots-cl?s indexant chaque document dans la r?f?renceest renseign?, tant dans le corpus d?apprentissage que dans le corpus de test.
Les participantspeuvent ainsi fournir exactement le nombre de mots-cl?s attendus.Le travail d?indexation, qu?il s?effectue dans un cadre contr?l?
ou non, reste complexe (Moens,2000).
Dans le cadre d?une indexation contr?l?e, le choix de mots-cl?s parmi ceux propos?s dansune terminologie reste difficile, l?indexeur, qu?il soit humain ou automatique, doit choisir parmiles termes propos?s et uniquement parmi ceux-ci, les meilleurs candidats.
Le travail consiste donc?
identifier, parmi les termes propos?s, quels sont ceux qui se rapprochent le plus de ceux quel?on aurait naturellement eu tendance ?
choisir.
Dans le cadre d?une indexation libre, la premi?redifficult?
consiste ?
d?terminer quels sont les meilleurs candidats ?
l?indexation, g?n?ralementen usant de m?thodes statistiques ?ventuellement compl?t?es par d?autres approches.
Dans lecadre de ce d?fi, l?
?valuation des termes qui auront ?t?
automatiquement choisis constitue unedeuxi?me difficult?
puisque la r?f?rence est constitu?e des mots-cl?s choisis par les auteurs desarticles, ce choix ?tant purement subjectif mais consid?r?
comme le meilleur pour cette campagned??valuation.
Les r?sultats des participants sont donc ?valu?s en comparaison d?une r?f?rence quireste hautement perfectible.Les participants peuvent participer, ?
leur convenance, aux pistes qu?ils souhaitent (seulementl?une ou les deux).
Chaque participant est autoris?
?
soumettre jusqu??
trois fichiers de r?sultatspar piste (soit un maximum de six ex?cutions pour une ?quipe participant aux deux t?ches),permettant de tester officiellement trois syst?mes ou trois configurations diff?rentes d?un m?mesyst?me.Les participants peuvent utiliser n?importe quelle ressource externe sauf celles provenant du siteErudit.org d?o?
proviennent les corpus.42.2 CorpusLe corpus se compose d?articles scientifiques provenant du portail Erudit.org parus entre 2003 et2008 dans quatre revues de Sciences Humaines et Sociales : Anthropologie et Soci?t?, M?ta, Revuedes Sciences de l?
?ducation et Traduction, terminologie, r?daction.
Ces revues ont ?t?
s?lectionn?escar une majorit?
d?articles qui y ont paru sont accompagn?s de mots-cl?s, choisis par les auteurs,indexant le contenu des articles.
Ces mots-cl?s constituent la r?f?rence de cette ?dition, utilis?epar les participants lors de la phase d?apprentissage et par les organisateurs pour ?valuer lesr?sultats lors de la phase de tests.Du corpus initial de quatre revues, nous avons donc extrait 468 articles index?s par des mots-cl?s.Ces articles ont ?t?
r?partis ?quitablement entre corpus des deux pistes, soit 234 articles parpiste.
Pour chaque piste, nous avons ensuite op?r?
une r?partition entre corpus d?apprentissageet corpus de test selon le ratio 60/40% habituel, en nous assurant que ce ratio s?applique surchaque revue (soit 60% des articles de chaque revue dans l?apprentissage et les 40% restants dechaque revue dans le test).
Nous donnons ci-apr?s (Figure 1) un exemple de document tel qu?ilapparait dans le corpus d?apprentissage.<doc id=" 0360 "><motsc les><nombre>5</nombre><mots>dimension ; concept ; c a r a c t ?
r e ; s p a t i o l o g i e ; o rgan i s a t i on des connaissances</mots></motsc les><a r t i c l e><resume><p>?
p a r t i r de l ?
ana lyse de p l u s i e u r s termes se rappor tant au domaine de l a s p a t i o l o g i e , dansdes langues a u s s i d i f f ?
r e n t e s que l ?
a n g l a i s e t l e f r a n ?
a i s d ?
une par t e t l ?
arabe d ?
autrepart , nous nous proposons de d?montrer l ?
importance de l a not ion de p l u r i d i m e n s i o n n a l i t ?du concept d a n s l ?
o rgan i sa t i on des connaissances e t l a c l a s s i f i c a t i o n des o b j e t s du monde .Ce f a i s a n t , nous about i rons a u s s i ?
l a conc lus ion que l a s t r u c t u r a t i o n d ?
un domaine des p ?
c i a l i t ?
, l ?
?
l abo ra t i on de son arborescence e t su r tou t l a formulat ion d ?
une d ?
f i n i t i o nd?pendent pr inc ipa lement des c a r a c t ?
r e s p r i s en compte dans l ?
appr?hension des concepts ,donc n?cessa i rement de l a ?
d imens ion ?
du concept .</p></resume><corps><p>Nous savons que l e concept e s t l ?
un i t?
de base de toute analyse terminolog ique .
Que c e l l e?c is o i t synchronique ou diachronique , por tant sur l e terme ou sur l a d ?
f i n i t i o n , i l f au ttou jour s r even i r au concept , ?
sa d e s c r i p t i o n au se in du syst?me de concepts qu ?
i lc o n s t i t u e avec l e s au t re s concepts appartenant au m?me domaine.</p><p>Le concept e s t une ?
u n i t ?
de connaissance cr?
?e par une combinaison unique de c a r a c t ?
r e s ?
( ISO 1087?1 2000 : 2) .
Cet te d ?
f i n i t i o n que donne l a norme ISO 1087?1 2000 du concept metsu r tou t l ?
accent sur l a d?composit ion du concept en ca rac t ?
re s , une d?composit ion quipermet une mei l l eure compr?hension du concept e t donc une mei l l eure o rgan i sa t i on dusyst?me de concepts auquel i l appa r t i en t .</p>.
.
.</ corps></ a r t i c l e></doc>FIG.
1 ?
Extrait du corpus d?apprentissage avec m?ta-donn?es associ?esChaque document int?gre les ?l?ments suivants :?
Des m?ta-donn?es : la liste des mots-cl?s indexant le contenu de l?article (chaque mot cl?est s?par?
du suivant par un point-virgule, information uniquement fournie dans les corpusd?apprentissage), mots-cl?s qu?il faudra identifier pour la phase de test (ligne 4) et le nombre demots-cl?s indexant le contenu de l?article (information fournie dans les corpus d?apprentissage5et de test, ligne 3) ;?
L?article scientifique : le r?sum?
de l?article (ligne 8) et le corps de l?article au complet (?
partirde la ligne 11).2.3 TerminologieSur la premi?re piste, la terminologie des mots-cl?s employ?s dans le corpus est fournie (Figure 2).La terminologie du corpus d?apprentissage a ?t?
constitu?e en relevant tous les mots-cl?s desdocuments de ce corpus, class?s par ordre alphab?tique.
La m?me proc?dure a ?t?
suivie pourconstuire la terminologie du corpus de test.
Puisque les mots-cl?s ont ?t?
choisis par les auteurseux-m?mes, on constate que les mots-cl?s sont de diff?rents types : des mots simples (ethnologie),des mots compos?s (Am?rique latine), des expressions complexes (Am?rindien du Nord-Est) et descombinaisons d?informations pr?sentes dans l?article rassembl?es sous un m?me ?
mot-cl?
?
(1982,droit constitutionnel canadien).
Si la question de la difficult?
de rattacher chaque mot-cl?
de cetteterminologie aux documents du corpus se pose pour la premi?re piste, les exemples pr?sent?sici t?moignent ?galement de la difficult?
?
venir pour identifier les mots-cl?s sur la secondepiste, en l?absence de toute terminologie, compte-tenu de la grande variabilit?
des modalit?s deconstitution des mots-cl?s.1867 , C o n s t i t u t i o n Act1982 , d r o i t c o n s t i t u t i o n n e l canadienAb?l?sAf r iqueAf r ique de l ?
Es tAgrawalA lg?
r i ensAmazonieAmbedkarAm?rindien du Nord?EstAm?rique l a t i n eAncien R?gimeAubr?e.
.
.e t h n i c i t ?ethno?f i c t i o nethnographieethnographie m u l t i s i t e se t h n o l i n g u i s t i q u ee thno log ieexogamie.
.
.FIG.
2 ?
Extrait de la terminologie du corpus d?apprentissage63 ?valuationLes mesures qui ont ?t?
retenues pour l?
?valuation 2012 sont les mesures de pr?cision, rappel, etF-mesure (Manning et Sch?tze, 1999), calcul?es avec une micro-moyenne (Nakache et M?tais,2005).
Ce sont ces mesures qui ont ?t?
utilis?es pour la piste 5 de la campagne SemEval-2010 :Automatic Keyphrase Extraction from Scientific Articles (Kim et al, 2010).Notons D l?ensemble des idenfiants de documents, K l?ensemble de tous les mots-cl?s utilis?spar le syst?me, W l?ensemble des mots-cl?s utilis?s dans la base documentaire, les donn?eshypoth?se H (formule 1), c?est-?-dire l?ensemble des paires associant un identifiant de document?
un mot cl?
fourni par le syst?me participant et R les donn?es r?f?rence (formule 2), c?est-?-dire l?ensemble des paires associant un identifiant de document ?
un mot cl?
issu de la basedocumentaire.
Naturellement, pour un m?me identifiant de document, il peut exister plusieurspaires, aussi bien dans H que dans R, mais nous n?aurons pas de paire doublon au sein de l?un deces ensembles, car les mots-cl?s seront alors diff?rents.
En effet, il n?y a aucun int?r?t ?
annoterun document plusieurs fois avec le m?me mot-cl?H = (d, Lem(Norm(w))d ?
D, w ?W, ((d, w1) ?
H)?
((d, w2) ?
H) ?
w1 6= w2 (1)R = (a, Lem(Norm(k))a ?
D, k ?
K , ((a, k1) ?
R)?
((a, k2) ?
R) ?
k1 6= k2 (2)Norm() est une fonction de normalisation de la typographie des mots-cl?
(normalisation de lacasse) et Lem() est une fonction de lemmatisation des mots-cl?.L?ensemble des mots-cl?
correctement associ?s ?
un document par le syst?me correspond au tauxde vrais positifs (TP, formule 3), l?ensemble des mots-cl?
incorrectement associ?s ?
un documentpar le syst?me correspond au taux de faux positifs (FP, formule 4) et l?ensemble des mots-cl?
nontrouv?s par le syst?me correspond au taux de faux n?gatifs (FN, formule 5).TP = H ?
R (3) FP = H(H ?
R) (4) FN =R(H ?
R) (5)La pr?cision, le rappel et la F-mesure calcul?s en micro-moyenne correspondent aux formules 6 :Pr?cision = |H ?
R||H| Rappel =|H ?
R||R| F-mesure =(2?
p?
r)(p + r) (6)Notons que nous utilisons l??galit?
stricte sur les mots-cl?s sans avoir recourt ?
une distances?mantique qui permettrait par exemple, de s?apercevoir que recherche d?information est plusproche de fouille de donn?es que d?algorithmique afin de ne pas biaiser l?
?valuation par rapport?
une ontologie particuli?re.
Nous avons ?galement d?cid?
de ne pas prendre en compte lesrecouvrements partiels de termes comme ayant une certaine validit?
pour ?viter de recompenserun syst?me qui retournerait fouilles arch?logiques alors que la bonne r?ponse est fouille de donn?es.Bien entendu, ce choix a pour r?sultat que la fourniture de l?hyponyme d?un terme au lieu du7terme sera consid?r?e comme tout aussi fausse que la fourniture de n?importe quel autre terme.La production de mesures de performance compl?mentaires peut ?tre envisag?e ?
titre indicatif.Pour les r?sultats officiels de la campagne, seule la performance en F-mesure en micro-moyennesera prise en compte.4 Tests humainsNous avons effectu?
des tests humains sur les deux pistes aupr?s des ?tudiants du parcours?
Ing?nierie Multilingue ?
du M2 Professionnel de l?INaLCO (formation sciences du langage avecune dominante traitement automatique des langues, ?tudiants d?origine ?trang?re avec pourcertains une ma?trise moyenne de la langue fran?aise).
Pour chaque piste, un sous-corpus compos?de quatre fichiers chacun a ?t?
produit (un fichier issu de chacune des quatre revues utilis?esdans le corpus global).
Nous remercions chacun des ?tudiants pour le travail accompli.4.1 Premi?re piste, avec terminologieSur la premi?re piste, puisque la terminologie des mots-cl?s employ?s dans les quatre articlescomposant le sous-corpus est disponible, une simple projection des mots-cl?s sur ce corpus aumoyen d?une commande informatique4 permet d?identifier dans quel fichier appara?t 14 des mots-cl?s de la terminologie.
Sur ces 14 mots-cl?s, un seul est attribu?
?
deux fichiers ; l?attribution dece mot-cl?
au fichier qui compte le plus d?occurrences de ce terme permet une indexation correcte.Pour les 4 mots-cl?s restants qui n?ont pu faire l?objet d?une projection (g?n?ralement des mots-cl?scompos?s : traduction fran?aise et alemande, ?ducation multiculturelle, ?ducation intellectuelle),une recherche d?un des termes composant le mot-cl?
permet d?identifier correctement l?articleauquel il doit ?tre associ?.
Cette technique, sur un sous-corpus limit?, permet d?identifier 100%des indexations (F-mesure de 1,000).4.2 Seconde piste, sans terminologieSur la seconde piste, aucune terminologie des mots-cl?s n?ayant ?t?
fournie, la t?che a ?t?
jug?eplus complexe par les ?tudiants comme en t?moignent les r?sultats obtenus (voir Tableau 1,F-mesure moyenne de 0,216 et m?diane de 0,208).
Afin de dresser grossi?rement le contenuAM BM IP LM LT NS SKPr?cision 0.250 0.200 0.167 0.118 0.292 0.292 0.208Rappel 0.250 0.208 0.167 0.083 0.292 0.292 0.208F-mesure 0.250 0.204 0.167 0.098 0.292 0.292 0.208TAB.
1 ?
?valuation des tests humains sur la seconde pistede chaque article, un script qui extrait les tokens et les trigrammes de tokens utilis?s dans le4grep -of termino_appr.txt piste1/testSans/* | sort | uniq8document class?s par fr?quence d?utilisation d?croissante a ?t?
mis ?
contribution.
?
charge pourles ?tudiants de s?inspirer de ces listes et de les confronter au contenu r?el de l?article pour cr?erdes mots-cl?s potentiels.En conclusion, la seconde piste (sans terminologie) a ?t?
jug?e difficile.
Les mots-cl?s employ?sne se retrouvent pas forc?ment ?
l?identique (traduction fran?aise et alemande) mais peuventcorrespondre ?
une concat?nation de plusieurs expressions (traduction allemande et traductionfran?aise).
Il apparait par ailleurs que les mots-cl?s employ?s peuvent ne pas apparaitre dans letexte mais r?sulter d?une inf?rence (Colombie Britannique alors que le texte ne mentionne pasle nom de cette province mais celui d?une ville de cette province).
Enfin, la redondance d?uneth?matique d?un m?me champ s?mantique exprim?e au moyen de deux mots-cl?s (interpr?teet interpr?tation) a ?t?
jug?e complexe parce que contre-intuitif (un annotateur humain ayanttendance ?
choisir soit l?un, soit l?autre).5 M?thodes des participantsLa plupart des participants a consid?r?
la premi?re piste (avec terminologie) comme une t?chede recherche d?information dans laquelle les mots-cl?s constituent la requ?te ?
traiter.Pour la seconde piste (absence de terminologie), les participants ont utilis?s des outils d?extractionde mots-cl?s apr?s avoir supprim?
les mots non significatifs puis des m?thodes de r?ordonnan-cement des mots-cl?s candidats.
Concernant le niveau de granularit?
sur lequel travailler, une?quipe (n?
04) a tent?
le niveau caract?re et le niveau mot (Doualan et al, 2012) tandis qu?uneautre ?quipe (n?
03) a fait le pari de travailler uniquement ?
l?
?chelle du syntagme nominal,consid?rant qu?un terme complexe est moins ambig?
qu?un terme simple isol?
(Amri et al, 2012).Plusieurs outils d?extraction de termes ont ainsi ?t?
mobilis?s : l?outil KX accorde ainsi un poidsaux termes extraits selon des annotations linguistiques et des relev?s statistiques (Tonelli et al,2012) (n?
01), l?outil TermoStat qui repose sur des m?thodes symboliques puis effectue untri statistique (Claveau et Raymond, 2012) (n?
05), l?algorithme KEA (Keyphrase ExtractionAlgorithm) utilis?
par l?
?quipe 06 (Boudin et al, 2012).
Une ?quipe (n?
02) a utilis?
des outilsde constitution de terminologies structur?es pour reconna?tre les termes (librairie TermTaggeren Perl) extraire les termes (outil YaTeA) (Hamon, 2012).
Les participants ont g?n?ralementutilis?
des m?thodes de pond?ration des mots-cl?s extraits reposant principalement sur le tf*idf,parfois en compl?tant avec la position du mot dans le document (Boudin et al, 2012; Claveauet Raymond, 2012; Doualan et al, 2012; Hamon, 2012; Tonelli et al, 2012), la fr?quence dansl?article, dans le r?sum?, la longueur de la cha?ne, la pr?sence du terme dans l?introduction et laconclusion (Doualan et al, 2012).
Certaines ?quipes ont ?galement travaill?
sur la reconnaissancedes variantes morpho-syntaxiques des termes candidats (Hamon, 2012; Claveau et Raymond,2012) en utilisant notamment l?outil Fastr.
Mais l?approche qui a permis d?obtenir les meilleursr?sultats (El Ghali et al, 2012) repose sur une combinaison de plusieurs modules linguistiquesd?ordre morphologique, s?mantique et pragmatique.En ce qui concerne le choix des meilleurs candidats, le cosinus a g?n?ralement ?t?
employ?
(Ahatet al, 2012; Hamon, 2012), parfois en combinaison avec d?autres techniques telles que lesgraphes par l?
?quipe 18 (Ahat et al, 2012) ou les r?seaux bay?siens (El Ghali et al, 2012).D?autres techniques fond?es sur l?apprentissage ont ?galement ?t?
mobilis?es.96 R?sultats des participants?
l?image des tests humains, les participants ont obtenu de meilleurs r?sultats sur la premi?repiste (o?
la terminologie des mots-cl?s employ?s ?tait fournie) que sur la seconde (absence determinologie).
Nous renseignons dans le tableau 2 des r?sultats obtenus par les participantspour chacun des fichiers soumis dans chacune des deux pistes.
Nous int?grons ?galement une?valuation dite ?
hors comp?tition ?
pour les fichiers re?us apr?s la fin de la p?riode de test ; cesr?sultats ne sont pris en compte, ni dans le classement final, ni dans les statistiques globales(moyenne, m?diane, ?cart-type).
?quipe Run T?CHE 1 T?CHE 2Pr?cision Rappel F-mesure Pr?cision Rappel F-mesure01 ?
FBK1 0,2682 0,2682 0,2682 0,1880 0,1880 0,18802 0,2737 0,2737 0,2737 0,1452 0,1446 0,14493 0,1978 0,1974 0,1976 0,1901 0,1901 0,190102 ?
LIM&BIO1 0,3985 0,3985 0,3985 0,1798 0,1798 0,17982 0,3333 0,3333 0,3333 0,1612 0,1612 0,16123 0,2253 0,2253 0,2253 0,1921 0,1921 0,192103 ?
URPAH 1 0,0857 0,0857 0,0857 0,0785 0,0785 0,07852 ?
?
?
0,0785 0,0785 0,078504 ?
GREYC1 0,0507 0,1769 0,0788 0,0469 0,1777 0,07422 0,1082 0,1322 0,1190 0,1108 0,1488 0,12703 0,4144 0,4730 0,4417 ?
?
?05 ?
IRISA1 0,8017 0,7002 0,7475 0,2087 0,2087 0,20872 0,7114 0,7114 0,7114 0,1704 0,1694 0,16993 0,6760 0,6760 0,6760 ?
?
?06 ?
LINA1 0,3812 0,4004 0,3906 0,1788 0,2128 0,19432 0,3759 0,3948 0,3851 0,1949 0,2355 0,21333 0,3343 0,4097 0,3682 0,1643 0,1880 0,175313 ?
LIMSI 1 0,1378 0,1378 0,1378 0,1632 0,1632 0,163216 ?
LUTIN1 0,4618 0,4618 0,4618 0,2438 0,2438 0,24382 0,9480 0,9497 0,9488 0,3471 0,3471 0,34713 0,7486 0,7486 0,7486 0,5880 0,5868 0,587417 ?
LORIA1 0,0522 0,2737 0,0877 0,0446 0,2562 0,07592 0,0745 0,1955 0,1079 0,0603 0,1736 0,08953 0,0401 0,3147 0,0711 0,0350 0,3017 0,062718 ?
PRISM 1 0,0428 0,0428 0,0428 ?
?
?2 0,0242 0,0242 0,0242 ?
?
?
?valuations hors comp?titionHC 03 ?
URPAH 1 0,1695 0,1695 0,1695 0,1203 0,1198 0,1201HC 15 ?
NOOPSIS 1 0,4587 0,2067 0,2850 0,0969 0,0909 0,0938TAB.
2 ?
R?sultats des participants pour chaque soumission sur les deux pistes10La correspondance entre num?ro d?
?quipe et article pr?sentant les m?thodes s?
?tablit comme suit :01 ?
FBK (Tonelli et al, 2012), 02 ?
LIM&Bio (Hamon, 2012), 03 ?
URPAH (Amri et al, 2012),04 ?
GREYC (Doualan et al, 2012), 05 ?
IRISA (Claveau et Raymond, 2012), 06 ?
LINA (Boudinet al, 2012), 16 ?
LUTIN (El Ghali et al, 2012), et 18 ?
PRISM (Ahat et al, 2012).Sur la premi?re piste, nous constatons des ?carts extr?mement importants entre participants,avec des F-mesures qui varient de 0,0242 ?
0,9488 !
On observe ?galement des ?carts ?lev?sentre les diff?rentes soumissions d?un m?me participant variant du simple au quadruple.
Surcette piste, si l?on se fonde sur les meilleures soumissions de chaque ?quipe, la F-mesure moyenneest de 0,3575, la m?diane de 0,3321 et l?
?cart-type de 0,2985.Sur la seconde piste, les ?carts entre participants sont moindres, les F-mesures variant de 0,0627?
0,5874.
On observe ?galement qu?un grand nombre de participants obtient, sur la meilleuresoumission de son syst?me, une F-mesure qui varie autour de 0,2.
En se focalisant sur la meilleuresoumission de chaque participant, la F-mesure moyenne est de 0,2055, la m?diane de 0,1901 etl?
?cart-type de 0,1516.Nous renseignons dans le tableau 3 du nombre de mots-cl?s int?gr?s dans chaque fichier desoumission.
Sur la premi?re piste, 443 mots-cl?s ?taient attendus tandis que la seconde enattendait 391.
Nombreux sont les participants qui ont fournis autant de mots-cl?s que le nombreattendu (ce nombre ?tant renseign?
dans les m?ta-donn?es de chaque document ?
traiter).
Deux?quipes ont fait le choix de retourner davantage de mots-cl?s que le nombre attendu.
?quipe 01 ?
FBK 02 ?
LIM&BIO 03 ?
URPAH 04 ?
GREYC 05 ?
IRISARun 1 2 3 1 2 3 1 2 1 2 3 1 2 3T?che 1 443 443 442 443 443 443 443 ?
1786 657 519 375 443 443T?che 2 391 390 391 391 391 391 391 391 1748 650 ?
391 388 ?
?quipe 06 ?
LINA 13 ?
LIMSI 16 ?
LUTIN 17 ?
LORIA 18 ?
PRISMRun 1 2 3 1 1 2 3 1 2 3 1 2T?che 1 470 470 564 443 443 444 443 2725 1315 4134 443 443T?che 2 483 492 461 391 391 391 391 2697 1302 4092 ?
?TAB.
3 ?
Nombre de mots-cl?s renseign?s par fichier et par ex?cution sur chaque pisteLe GREYC (?quipe 04) d?abord, avec environ quatre fois plus de mots-cl?s sur la premi?reex?cution, environ une fois et demie de plus sur la seconde soumission et ?
peine 1,17 fois deplus sur la troisi?me.
Rapport?
aux r?sultats obtenus, la troisi?me soumission ?
parce qu?ellecorrespond globalement au nombre attendu de mots-cl?s ?
obtient les meilleurs r?sultats.
LeLORIA (?quipe 17) enfin, avec environ six fois plus de mots-cl?s sur la premi?re ex?cution,environ 3 fois plus sur la seconde et 9,33 fois plus sur la troisi?me soumission.
?
l?image duGREYC, la soumission dont le nombre de mots-cl?s se rapproche de celui attendu obtient lesmeilleurs r?sultats.
Pour ces deux ?quipes, ces strat?gies permettent d?obtenir un rappel meilleurque la pr?cision mais les valeurs calcul?es restent faibles.117 ConclusionLes t?ches d?indexation, bien que r?alis?es depuis de nombreuses ann?es, ne constituent plusdes pistes exploratoires.
?
ce titre, les r?sultats obtenus par les participants sur cette cam-pagne t?moignent des ?carts importants entre ?quipes, selon que l?
?quipe dispose d?un syst?med?indexation ou bien part uniquement d?un syst?me de base.Les participants ont mieux r?ussi la premi?re piste que la seconde, parce qu?elle fournissaitla terminologie des mots-cl?s employ?s dans les documents du corpus ?
traiter.
La F-mesuremoyenne passe de 0,3575 sur la premi?re piste ?
0,2045 sur la seconde avec des ?cart-typesvariant de 0,2985 ?
0,1522 de l?une ?
l?autre.
On constate ?galement des ?carts ?lev?s (jusqu?
?0,5388 d?
?cart de F-mesure), pour une m?me ?quipe, entre la meilleure soumission sur chaquepiste.Compte-tenu des modalit?s d?
?valuation, les strat?gies visant ?
fournir davantage de mots-cl?sque le nombre attendu (cette information ayant ?t?
fournie dans les corpus d?apprentissage et detest) ont permis d?accro?tre le rappel au d?triment d?une pr?cision tr?s faible.RemerciementsL?interface de soumission et d?
?valuation des r?sultats a ?t?
d?velopp?e par Pierre Albert dansle cadre du projet DoXa (financement CapDigital, convention DGE no 08 2 93 0888).
Nousremercions les organisateurs des conf?rences JEP/TALN pour l?organisation logistique de l?atelieret l?ATALA pour la mise ?
disposition d?une salle.Nous remercions les ?tudiants du M2 Professionnel ?
Ing?nierie Multilingue ?
2011/2012 del?INaLCO pour les tests humains qu?ils ont effectu?s, leur permettant ainsi de d?couvrir l?unedes ?tapes essentielles lors de l?organisation d?une campagne d?
?valuation : Alexandra Moraru,Benjamin Marie, Irina Poltavchenko, Leidiana Martins, L?vana Thammavongsa, Nazim Saadi,Sofiane Kerroua.R?f?rencesAHAT, M., PETERMANN, C., HOAREAU, Y. V., BEN AMOR, S. et BUI, M. (2012).
Algorithme automa-tique non supervis?
pour le deft 2012.
In Actes de l?atelier de cl?ture du huiti?me d?fi fouille detexte (DEFT), pages 73?79.AMRI, A., MBAREK, M., BECHIKH, C., LATIRI, C. et HADDAD, H. (2012).
Indexation ?
base dessyntagmes nominaux.
In Actes de l?atelier de cl?ture du huiti?me d?fi fouille de texte (DEFT), pages37?43.BOUDIN, F., HAZEM, A., HERNANDEZ, N. et SHRESTHA, P. (2012).
Participation du lina ?
deft 2012.In Actes de l?atelier de cl?ture du huiti?me d?fi fouille de texte (DEFT), pages 65?72.CLAVEAU, V. et RAYMOND, C. (2012).
Participation de l?irisa ?
deft2012 : recherche d?informationet apprentissage pour la g?n?ration de mots-cl?s.
In Actes de l?atelier de cl?ture du huiti?me d?fifouille de texte (DEFT), pages 53?64.12DEERWESTER, S., DUMAIS, S. T., FURNAS, G. W., LANDAUER, T. K. et HARSHMAN, R. (1990).
Indexingby latent semantic analysis.
In Journal of the American Society for Information Science, volume 41,pages 391?407.DOUALAN, G., BOUCHER, M., BRIXTEL, R., LEJEUNE, G. et DIAS, G. (2012).
D?tection de mots-cl?spar approches au grain caract?re et au grain mot.
In Actes de l?atelier de cl?ture du huiti?me d?fifouille de texte (DEFT), pages 45?52.EL GHALI, A., HROMADA, D. et EL GHALI, K. (2012).
Enrichir et raisonner sur des espacess?mantiques pour l?attribution de mots-cl?s.
In Actes de l?atelier de cl?ture du huiti?me d?fi fouillede texte (DEFT), pages 81?94.HAMON, T. (2012).
Acquisition terminologique pour identifier les mots-cl?s d?articles scientifiques.In Actes de l?atelier de cl?ture du huiti?me d?fi fouille de texte (DEFT), pages 29?35.KIM, S. N., MEDELYAN, O., KAN, M.-Y.
et BALDWIN, T. (2010).
Semeval-2010 task 5 : Automatickeyphrase extraction from scientific articles.
In Proc.
of SemEval, pages 21?26, Stroudsburg, PA.Association for Computational Linguistics.LANCASTER, F. W. (2003).
Indexing and abstracting in theory and practice.
Facet, London.MANNING, C. D. et SCH?TZE, H. (1999).
Foundations of Statistical Natural Language Processing.MIT Press, Cambridge, Massashusetts.MOENS, M. F. (2000).
Indexing and abstracting of Document Texts.
Kluwer Academic Publishers.NAKACHE, D. et M?TAIS, E. (2005).
Evaluation : nouvelle approche avec juges.
In INFORSID,pages 555?570, Grenoble.POMPIDOR, P., CARBONNEILL, B. et SALA, M. (2008).
Indexation de co-occurrences guid?e parla structure des documents et contr?l?e par une ontologie et l?exploitation du corpus.
InINFORSID?08, Fontainebleau, France.
Lavoisier-Herm?s.SALTON, G., WONG, A. et YANG, C. S. (1975).
A vector space model for automatic indexing.
InCommunications of the ACM, volume 18, pages 613?620.SAVOY, J.
(2005).
Indexation manuelle et automatique : une ?valuation comparative bas?e surun corpus en langue fran?aise.
In Actes de Coria, pages 9?23, Grenoble.SIDHOM, S. (2002).
Plate-forme d?analyse morpho-syntaxique pour l?indexation automatique et larecherche d?information : de l?
?crit vers la gestion des connaissances.
Th?se de doctorat, Universit?Claude Bernard ?
Lyon I.TONELLI, S., CABRIO, E. et PIANTA, E. (2012).
Key-concept extraction from french articles with kx.In Actes de l?atelier de cl?ture du huiti?me d?fi fouille de texte (DEFT), pages 19?28.TOUSSAINT, Y., NAMER, F., DAILLE, B., JACQUEMIN, C., ROYAUT?, J. et HATHOUT, N. (1998).
Uneapproche linguistique et statistique pour l?analyse de l?information en corpus.
In ZWEIGENBAUM,P., ?diteur : Actes de TALN 1998 (Traitement automatique des langues naturelles), pages 1?10,Paris.
ATALA.13
