Backtracking-Free Dict ionary Access Method  forJapanese Morphological  AnalysisHi rosh i  MaruyamaIBM Research, Tokyo Research Laboratorymaruyarna@trl.
ibm.co.jp1 Introduction Input sentence: ~-\[-Ill:~f?
:,~ e) I-3f- ~: j~.
--~/:.
oJMA output:Since the Japanese language does not haveexplicit word boundaries, dictionary lookupshould be done, in principle, for all possible sub-strings in an input sentence.
Thus, Japanesemorphological analysis involves a large numberof dictionary accesses.The standard technique for handling thisproblem is to use the TRIE structure to find allthe words that begin at a given position in a sen-tence (Morimoto and Aoe 1993).
This process isexecuted for every character position in the sen-tence; that is, after looking up all the words be-ginning at position n, the program looks up allthe words beginning at position n + 1, and soon.
Therefore, some characters may be scannedmore than once for different starting positions.This paper describes an attempt o minimizethis 'backtracking' by using an idea similar to oneproposed by Aho and Corasick (Aho 1990) formultiple-keyword string matching.
When usedwith a 70,491-word ictionary that we developedfor Japanese morphological nalysis, our methodreduced the number of dictionary accesses by25%.The next section briefly describes the prob-lem and our basic idea for handling it.
The de-tailed algorithm is given in Section 3 and Sec-tion 4, followed by the results of an experimentin Section 5.22.-I-ft1:*i1:19 I~ :19  ?
:76-I-~I-: 19 ~:.
:78ix:9 0 :29  \]'2:63 o :100Fig.
1: Sample input/output of JMA2 JapaneseAnalysisMorphological2.1 GrammarA Japanese morphological analyzer (here-after called the JMA) takes an input sentenceand segments it into words and phrases, attach-ing a part-of-speech code to each word at thesame time.
Figure 1 shows a sample input andthe output of our JMA.Tile grammaticality of a sequence ofJapanese words is mainly determined by look-ing at two consecutive words at a time (thatis, hy looking at two-word windows).
There-fore, Japanese morphological analysis is nor-really done by using a Regular Grammar (e.g.,Maruyama and Ogino 1994).
Our JMA gram-mar rules have the following general form:state1 ~ "word" \[linguistic-features\]state2 cost=cost.Each grammar ule has a heuristic cost, andtile parse with the minimum cost will be selectedas the most plausible morphological reading ofthe input sentence.
A part of our actual gram-208mar is shown in Figure 2.
Currently our gram-mar has about 4,300 rules and 400 nonterminalsymbols.2.2  D ic t ionary  LookupWhile the flmction words (particles, auxiliaryverbs, and so on, totaling several hundred) areencoded in the grammar ules, the content words(nouns, verbs, and so on) are stored in st sepa-rate dictionary.
Since content words may appearat any position in tile input sentence, dictionaryaccess is tried from all the positions n.For example, in the sentence fragment: ill Fig-ure 3,"7..~ {'/.
(large)" and "J~ ~I'J.
~i\[ ~i ~(mainframe)"are the results of dictionary access at, posit.ion1.
For simplicity, we assume that the dictionarycontains only the following words:"i~ ~ (large),"";k2 ~lJ.
~\['.~ : (mainframe),""a \ ] '~  (computer)","~ Ig  ~ f~ (eomput.ing facility),"and",~R~ (facility).
"2.3  Us ing  TR IEThe most common method for dictionarylookup is to use an index structure called TRIE(see Figure 4).
The dictionary lookup beginswith the root node.
The hatched nodes represent.the terminal no(tes that correspond to dictionaryentries.
At position 1 in tile sentence ab(we, I, wowords, "Jq~.eJ.
(large)" and " )k:)l'-I.
}i\].~:~.~ (main-frame)," are found.Then, the starting position is advanced 1;o thesecond character in the text; and the dictionarylookup is tried again.
In this case, no word isfound, because there are no words thai, begins~Actual' dictionaries' '?1so co,train i')'C (big)," " ,b~,!
(type)," "~'1" (measure)," "i{l'~: (compute)," "~'~: (cwdm.
),""~ (m,.:hi.~.
)," ~b~ ( .~t,,bU.~h)," ,.,,i "~;;i (p,.,,~ ......
).
"with "~{'.1."
in the dictionary.
The start, lug posi-tion is l, hen set I,o 3 and t.rled again, and this,.i,,~ th,.
words "al~:~ (,:,lnlp,,Ce,.y and "i}t~';k)~;{'~{i\[i (comput.ing facilit,y)" are obtained.
'eThe problem here ix (,hal;, even though weknow that, 1,here is "TQ){l!
}i\[.~\])~ (ma.in\[rarne)"al, posit;ion I, we look up "}}\[~{:t~ (computer)"again.
Since "iil~:~.~: (computer)" is a snhstringof "9'4~{~iI'~;)1~ (n-lainframe)," we know that, t;heword "~,i\]~,i~ (compul:er)" exists at, posit;ion 3 assoon as we lind "X~{~}~\[~3,,i~ (lnainframe)" at i)o-.sit;ion I.
Therefore, going back l;o 1;he root nodeat position 3 and trying mat;citing all over againmeans duplicatAng our efforts unnecessarily.2.4 E l iminat ing  Backt rack ingOur idea is to use t, he b)dex stsuct,m'e dew~loped by Abe and Corasick to find muli;iplesl,rings in a text.
Figure 5 shows l;he TRII!
;with a point.er called t;he fail pointer associatedwith the node corresponding to l;he word "7)k/~I T/~'\[~2~: (mail fxa.nm) ' (the rightmost, word in Lhefirst row).
When a match st;re'Ling al, positionn reaches I, his node, it is gnaranl,eetl hat tilesl.ring "~,ilJ)i~,~" exists starting at position n -t-2.Therefore, if the next character in the input sen-tence does not mat,oh any of the child nodes, wedo not go b~ck to the root but go back to thenode corresponding 1,o this substring by follow-ing t, he fail pointer, and resume matching fromthis node.
For the input sentence in l,'igure 3,l.he dict, ionary access proceeds as indica.ted bythe dot, t;ed line in I.he Figure 5, 13n(ling the words")<~{t!
(la.rge)," "g<~{t\[}\]\[#:~.~ (mair,\[','ame)," "\]i\[~'~:'~  (COlIIplll;cT)," and so on.
Thus, the nmnt)er ofdictionary node ac(:esses i greatly reduced.Ill many Japanese tnorphok)gical analysissystems, the dictionary ix held in the secondarystorage, a.nd t, herefore the number of dictionary~Wh,, r,,:~, ch,~t "X~{'~iil~A:~.~ (,,**i,,~'~,-,,,0" w,~.~ re,,.,1heft)re does no(.
neees;sarily mean f,\[ud, there is no needto l~mk up "~{I'~:)~%.
(computr.r ...)," because at this pointtwa interpretat.ions, "mainframe facilit.y" and "large com-puting facilit.y," are possible.209J\[~i~/~ -> EAGYOU-SDAN \[pos=l,kow=doushi\] ~f  5 f~;YJ~ 5 \[~ -> ?
'~'" \[pos=26,kow=v_infl\] ~,\[iJ 5 ~k ,~ 4 ~x,~ cost=300;~\ ]  5 ~-~,~)- 4~(ff6 -> "J'" \[pos=64,kow=jodoushi,fe={negative}\]"~" \[pos=78, kow=set suzoku_j oshi\]~It J j~  ~'f cost=500;~l~J~J~,~Y/ -> J\[~)~ cost=999;~1 -> "" \[pos=48,kow=jodoushi\] J~J~-~Y~,#~ cost=S00;.... ~ ~)~J~ cost=300;~) j~y~t~ _> "fZ o"  \[pos=45,kow=aux_infl\] '"~J\[J~ cost=a00;Fig.
2: Some of the grammar ulest ~ 3 fl" g- 6 ' ?4 large  -~ = computer -  " fac i l i ty4 main f rame* comput ing  laiSi l i ty 4~Pig.
3: Dictionary lookup for Japanese morphological analysis~F,j ~m ,11" D :  ~ ~_m -~ ~-F--1 - t__.lFig.
4: TRIE index210- I  I~?"
G% t.-:Fig.
5: 'I'I{IE structure with \]hil pointersnode accesses dominates the performance of theoverall system.3 Constructing TRIE with failpointersA TI{IF, index with fail pointers is created inthe following two steps:1.
Create a TI{IE iudex, and2.5  Other  Cos iderat ions  2.
Calculate a fail pointer of each node in theTRIE.Theoretically there is a I)ossiMlity of 1)rm,ingdictionary lookup by using the state set at.
posi-tion n. For example, if no noun can follow relyof the states in the current state set, there is noneed to look up nouns.
One way to do this prun-ing is to associate with each node a bit vectorrepresenting the set of all parts of speech of someword beyond this node.
\[f the intersection of theexpected set of parts of speeche an(t the possi.bilities beyond this node is empty, the expansionof this no(te can be pruned.
In general, however,almost every character position t)redicts most ofthe parts of speech.
Thus, it is common practicein Japanese morphok)gical analysis to h)ok upevery possible prefix at every character position.Hidaka et al (1984) used a modified l{-treeinstead of a simple TRIE.
Altough a B-tree hasmuch less nodes than a TRIE and thus the num-ber of secondary storage accesses can be signif-icantly reduced, it still backtracks to the nextcharacter position and duplicate matching is in-evitable.Since Step 1 is well known, we will describe onlyStep 2 here.\]"or each node n, Step 9 given thevalue fai l (n).
In the following algorittlm,for'ward('n, c) denotes the chikl node of the node'n whose associated character is c. If there is nosuch node, we define forward(n,  e) = hi\].
Rootis the root no(le of the T1HF,.
"2-1 j'ail(l~oot) ~- leooe2-2 for each node ft. of depth 1, fai l (n) ~ lSmt2-a re,.
e~,:l~ depth d - -  1,2, ...,2-3-1 for each node.
n with depLh d,2-3- I-I for each child node rn of n (wherem = forward(n,  c:)),fa i l (m) +-- f ( fa i l (n) ,  c).l\[ere, \]'(n, c) is defined as follows:fail(',,.)
if forward(n,  c) 5L nilf('n, c) = f ( fa i l (n) ,c )  if forward(n,  c:) = nil& n ~ Roott~oot otherwise211If tile node corresponds to the end of someword, we record the length l of the word in thenode.
For example, at the node that correspondsto the end of the word "~:~t '~:~ (mainframe)",I = 5 and l = 3 are recorded because it is the endof both of the words "~\ ] .~:~ (mainframe,l = 5)" and "~l'-~-~ (computer, l = 3)."
3Figure 6 shows the complete TRIE with tilefail pointers.traditional TRIE and was 27% faster in CPUtime.
The CPU time was measured with all thenodes in the main memory.For the computer manuals, the reduction ratewas a little larger.
This is attributable to the factthat computer manuals tend to contain longer,more technical terms than newspaper artMes.Our method is more effective if there are a largenumber of long words in a text.4 Dict ionary accessThe algorithm for consulting the dictionaryis quite simple:1 n +-- Root2 for each character position i = 11,2, ...k,2-1 while n 7~ Root and forward(n,  ci) =nil do n ~-- fai l(n)2-2 n = forward(n,cl)2-3 ifn is the end of some word(s), outputthemwhere ci is the character at position i.5 Exper imenta l  resultsWe applied the TRIE with fail pointers toour 70,491-word ictionary for Japanese mor-phological analysis (in which the average wordlength is 2.8 characters) and compared it witha conventional TRIE-based system, using twosets of data: newspapers articles (44,113 char-acters) and computer manuals (235,104 charac-ters).
The results are shown in Table 1.The tables show both the number of node ac-cesses and the actual CPU time.
For the news-paper articles, our method (marked as TRIE w/FP) had 25% fewer node accesses than than theSThis information is redundant, because one can lookup every possible word by following the fail pointer, llow-ever, if the nodes are in secondary storage, it is wort, h hav-ing the length information within the node to minimizethe disk access.6 ConclusionWe have proposed a new method of dictio-nary lookup for Japanese morphological anal-ysis.
The idea is quite simple and easy toimplement with a very small amount of over-head (a fail pointer and an array of length lto each node).
For large l, ermiriology dictionar-ies (medical, chemical, and so on), this methodwill greatly reduce tile overhead related to dic-tionary access, which dominates the efllciencyof practical Japanese morphological analyzers.Fast Japanese morphological analyzers will becrucial to the success of statistically-based lan-guage analysis in the near fllture (Maruyama etal.
1993).References1.
Atlo, A. V., 1990: "Algorithms for FindingPatterns in Strings," in Leeuwen, J.V.
ed.,Handbook of Theoretical Computer Sci-ence, Volume A - Algorithms and Com-plexity, pp.
273-278, Elsevier.2.
llidaka, T., Yoshida, S., and Inanaga, II.,1984: "Extended B-Tree and Its Applica-tions to Japanese Word Dictionaries," (InJapanese) Trans.
of IE\[CE, Vol.
367-D,No.
4:.3.
IIisamitsu, T. and Nitro, Y., \]991: "AUniform 'h'eatment of Ileuristic Meth-ods for Morphological Analysis of Written272l,'ig.
6: TI{II,~ index with fail pointers'I~RI\],; TRII!'
w/ 1,'1 ) l{educt~ion rat;eNode accesses 104,118 78,706 25%CPU time (set.)
64.77 40.92 27%(a) 44,11t3 chara(%ers in newsi)aper articlesTRIE 'l~Rllg w/ F1 ) Reduction rateNode accesses 542,542 883,176 30%CPU time (see).
372.47 228.63 28%(b) 235,104 (;haract~ers in computx~r mamlalsTable 1: lgxi)erimengal resultsJapanese," Prec.
of 2nd Japan-AustraliaJoint Workshop on NLP.4.
Maruyama, II., Ogino, S., and I\[idano, M.,1993: "The Mega-Word Tagged-CorpusProject," Prec.
of 5lh International Con-ference on Theoretical and MethodologicalIssues in Machine Translation (TM1-93),Kyoto, Japan.5.
Maruyama, H. and Ogino, S., 1994:"Japanese Morphological Analysis Basedon Regular Grammar," (In Japanese),Transactions of IPSJ, to appear.6.
Morimoto, K. and Aoe, J., 1993: "TwoTrie Structures far Natural Language \[)ic-tionaries," Prec.
of Natural Language Pro-cessing Pacific Rim Symposium (NLPR,9'93), Fukuoka, Japan.213
