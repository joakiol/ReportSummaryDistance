Automatically ExtractingAbst rac tThis paper describes how to automaticallyextract grounding features and segment adialogue into discourse units, once thedialogue has been annotated with the DR/backward- and forward-looking tags.
Suchan approach eliminates the need forseparate annotation of grounding, makingdialogue annotation quicker and removinga possible source of error.
A preliminarytest of the mapping against a humanannotator is presented.1 In t roduct ionThe annotation scheme (AC97) developed by theDiscourse Research Initiative's Backward- andForward-Looking Group (henceforth referred to asthe BF scheme) provides a set of tags that can beapplied to individual utterances in a dialogue,describing the utterance's illocutionary force.
TheBF scheme provides a standard top-level tag setthat allows researchers to reuse corpora that havebeen annotated for other projects, and also allowstags to be refined by individual projects to providedetail on particular phenomena being studied.There are a number of dialogue features that are ofinterest to researchers, and for which taggingschemes have been developed.
One feature that weare concerned with is grounding, the mechanismby which dialogue participants augment theirmutual beliefs.
In his dissertation work (Tra94),Traum establishes a set of tags to describegrounding behavior, and then uses this taxonomyof grounding acts to describe a computationalmodel of how dialogue participants achieve a stateof mutual understanding.
Traum's model describeshow grounding acts can be combined to formdiscourse units, segments of a dialogue thatcorrespond to individual contributions to thecommon ground.
Clark and Schaefer define aGrounding Tagsfrom BF TagsTeresa  Zol lo  and  Mark  CoreDepartment of Computer ScienceUniversity of RochesterRochester, New York 14627-0226zollo@cs.rochester.edumcore@cs.rochester.educontribution as the presentation f a proposition byone dialogue participant, as well as all subsequentrelated utterances until there is adequate evidencethat the initial utterance was understood orabandoned (CS89).
Discourse units are the level ofgranularity at which other dialogue tags, such asthe problem-solving acts described in (SA97), areapp!ied.Annotating dialogues can be a time-consuming anderror-prone undertaking.
To make the annotationprocess easier and more reliable, care should betaken to avoid manually tagging information thatcan be derived from other tags or that can beautomatically extracted.
This paper explores howwe can automatically annotate dialogues withgrounding tags, given a corpus that has beenannotated with the BF tags.
Once grounding hasbeen marked, we can automatically segment thedialogue into discourse units, using Traum's model.In order to tag with BF tags or grounding tags, adialog must be segmented into utterances, aproblem that is discussed briefly in section 2.Section 3 gives an overview of the BF tags andgrounding tags, section 4 discusses the mappingfrom BF tags to grounding tags, and section 5presents a comparison of the automatic mapping toa human annotator.2 Segment ing  d ia logues  in tou t terances  .
.Dialogues need to be segmented into utterancesbefore annotation with the BF tags.
Unfortunately,there is no widely accepted criteria for identifyingutterances.
Traum's approach to utterancesegmentation is to segment utterances based on thepresence of prosodic evidence such as pauses andboundary tones, and on changes of speaker.
Thebenefit of this approach is that it can be doneautomatically given prosodic annotation.
However,109we have found this approach to be somewhatproblematic since very often the resulting utteranceunits need to be combined or split when assigningthe BF tags.
Traum uses a special grounding tag,CONTINUE, when a prosodically-segraentedutterance is not an independent grounding act, butrather part of the same grounding act as a previousutterance by the same speaker.Another possible approach to utterancesegmentation for BF tagging is to allow theannotator to segment the dialogue and label it forBF tags at the same time.
The problem with thisapproach is that different annotators may segmentthe same dialogue differently, making it difficult tocompare annotations.
One way of dealing with thisproblem is to have subsequent annotators use thefirst annotator's segmentation.
A drawback of thissolution is that the first annotator's segmentationmay influence subsequent BF labeling.
Despite thisdrawback, we are assuming the second approach inorder to avoid the need to split or join utterances,and therefore do not need Traum's CONTINUE tag.3 Overview of Tag SetsTable 1 shows the illocutionary act featuresincluded in the BF tagging scheme, along with thetags for each feature.
Actions performed uring thegrounding process are shown in Table 2.1 InTraum's annotation scheme for grounding, the tagsare not mutually exclusive.The BF scheme has four main layers:communicative status, information level, forwardcommunicative function, and backwardcommunicative function.
Communicative status isused to label utterances that cannot be understood,are broken off, or are not directed at otherconversational participants.
Information level isused to differentiate between utterances discussingthe topic at hand (TASK and TASK-MGMT) andutterances whose sole purpose is to manage theconversation (COMMUNICATION-MANAGEMENT).COMMUNICATION-MANAGEMENT utterances can besimple acknowledgments (okay) or explicitcomments on the communication process (I didn'thear that).
Forward communicative functions areaspects of an utterance that directly address futureactions.
Requests and suggestions axe included inINFLUENCE-ON-LISTENER and INFO-REQUEST;Commitments and offers are included inINFLUENCE-ON-SPEAKER; and statements about1The CONTINUE act is merely an artifact Traum's ap-proach to utterance segmentation, and we omit it fromfurther discussion.Feature \[ TagsCommunicative StatusSelf-Ttdk YES\] NO I MAYBEUnintelligible YES I NO \[ MAYBE"'Abandoned YES \[ NO \ ]MAYBEInformation LevelInfo-level COMMUNICATION-MGMTI TASK I TASK-MGMTForward Communicative FunctionsStatement NONE I ASSERT I'"Influence-on-list enerInfluence-on-speakerInfo-requestConventional0ther-forward-functionREASSERTNONE \[ OPEN-OPTION IACTION-DIRECTIVENONE I OFFER I COMMITNONE I INFO-REQUESTI CHECKYES I NOBackward Communicat ive FunctionsAgreement NONE I ACCEPT \]ACCEPT-PART I MAYBE\]HOLD \[ REJECT-PART I 'REJECT \[ WH-ANSWERUnderstanding NONE I ACKNOWLEDGE ISIGNAL-NON-UNDERSTANDING ICORRECT-MISSPEAKING ISU-REPEAT-REPHRASE ISU-COMPLETIONResponse-to (any prior utt number)\[ NONETable 1: BF Features and Tagsthe world are included in STATEMENT.OTHER-FORWARD-FUNCTION identifies utterancesthat have a turn-taking function but no otherforward communicative function.
The secondutterance below is an example ofOTHER-FORWARD-FUNCTION:u t t l  u: and that  would be the  fas tes tutt2 okay okay tunutt3 we're doneBackward communicative functions includecomments on the content of previous utterances(AGREEMENT) as well as utterances that signalwhether previous material was understood or not(UNDERSTANDING).
Examples of UNDERSTANDINGinclude SIGNAL-NON-UNDERSTANDING as well asvarious types of showing understanding: simpleACKNOWLEDGMENTS, acknowledgment throughrepetit ion/paraphrase ( u- REPEAT- REPHRASE),acknowledgment through correction(CORRECT-MISSPEAKING), and acknowledgmentthrough elaboration/completion (su-cOMPLETION).The grounding acts of Traum are INITIATE,110- Grounding Act DescriptionINITIATEREPAIRREQUEST-REPAIRACKNOWLEDGEREQUEST-ACKNOWLEDGECANCELthe initial presentation of apropositiona modification to the contentor presentation of the currentproposition under considerationa request that the otherparticipant perform a REPAIRevidence that a previousutterance has been understooda request that the otherparticipant perform anACKNOWLEDGEan abandonment of theproposition under considerationTable 2: Traum's Grounding ActsREPAIR, REQUEST-REPAIR, ACKNOWLEDGE,REQUEST-ACKNOWLEDGE, and CANCEL.
Dialogueparticipants use these actions to form discourseunits as they converse.
INITIATES start discourseunits.
A discourse unit is terminated eitherthrough an ACKNOWLEDGE, in which case thediscourse unit is considered grounded, or through aCANCEL, in which case the discourse unit is notgrounded.
Acknowledgments may be either explicitor implicit.
Explicit acknowledgments can berequested by performing aREQUEST-ACKNOWLEDGE, such as Did you getthat?.
Once an initial presentation is made, eitherparticipant may make a REPAIR, or enter into arepair subdialogue by performing aREQUEST-REPAIR.4 Mapp ing  f rom BF  tags  toground ing  tagsIn general, any utterance tagged as having aforward communicative function in the BF  schemeinitiates a new discourse unit and should be givenan INITIATE grounding tag.
Exceptions areutterances that only perform a turn-taking act.These are tagged as OTHER-FORWARD-FUNCTIONin the BF  scheme, but have no content thatrequires acknowledgment.
Utterances that haveboth a turn-taking function and some otherforward communicative function, such as Give mea second.
(tagged as an ACTION-DIRECTIVE andOTHER-FORWARD-FUNCTION at  theCOMMUNICAT ION-MANAGEMENT level) do havecontent that can be acknowledged and should betagged as INITIATE.
Another exception foundfrequently in dialogues from collaborativetask-oriented domains are utterances that aretagged as COMMIT  because they ACCEPT anACTION-DIRECTIVE.
Utterances 2 and 4 in thefollowing dialogue excerpt are examples ofCOMMITS that are not INITIATES.uttl u: pick up two tankers in Corningut t2  s: okayutt3 u: then on the way back to Elmirapick up another tankerut t4  s: okayThe BF  tag SU-COMPLETION is interesting since anutterance having this tag should be INITIATE andACKNOWLEDGE in Tranm's scheme, despite the factthat completions are not labeled with forwardcommunicative functions.
The completion has animplicit forward communicative function which istaken as the same as the utterance (by anotherspeaker) that it is completing.Repairs are attempts to fix an utterance throughcorrection or clarification.
Corrections reject anutterance and offer a replacement.
Clarificationsprovide additional information about an utterance.Because of the level of granularity at which the BFtags are applied, self-repairs made mid-utteranceare not included.An  utterance B, should be given a REPAIRgrounding tag with respect to utterance A, if B is aresponse to A and any of the following patterns ofBF  tags are seen:1.
Utterance B is tagged asSU-CORRECT-MISSPEAKING.2.
Utterance B is tagged withCOMMUNICAT ION-MANAGEMENT and eitherREJECT or REJECT-PART, and a forwardcommunicative function.
In this case, thedialogue participant is making an unsolicitedrepair of their previous utterances.3.
Utterance A has the tagSIGNAL-NON-UNDERSTANDING and utteranceB has a forward communicative function anddoes not have REJECT or REJECT-PART tags.In this case, the dialogue participant is makingan solicited repair.All utterances having aSIGNAL-NON-UNDERSTANDING BF tag receive aREQUEST-REPAIR grounding tag.111An utterance is given a REQUEST-ACKNOWLEDGEgrounding tag when it has either of the followingpatterns of BF tags:1.
The utterance is tagged as CHECK.
These arecheck-questions, also known as tag-questions,and include examples uch as we will take thetop route right?.2.
The utterance is tagged as bothCOMMUNICATION-MANAGEMENT andINFO-REQUEST, and is not tagged asSIGNAL-NON-UNDERSTANDING.
Examples ofutterances of this type are Did you get that?and Are you listening?Utterances that are tagged as ABANDONED in theBF scheme will be tagged as CANCEL in Tranm'sgrounding scheme.
Sometimes a dialogueparticipant CANCELS an open discourse unit bysaying something like Forget it or Never mind inresponse to a repair initiationi such as What didyou say?
In the BF scheme, these CANCELs appearas REJECTs at the COMMUNICATION-MANAGEMENTlevel, responding toSIGNAL-NON-UNDERSTANDINGs.In the BF scheme, acknowledgments are utterancesthat explicitly indicate that a previous utterancewas understood.
In Traum's scheme,acknowledgments can either explicitly or implicitlysignal understanding.
Explicit acknowledgmentsoccur when a dialogue participant repeats,paraphrases, or completes what was said or whenthey use an acknowledgment term such as okay.Implicit acknowledgments occur when a dialogueparticipant continues the dialogue in a way that isconsistent with what has been said previously inthe dialogue.An utterance B, should be tagged as anACKNOWLEDGE to utterance A in Traum's schemeunder any of the following conditions:1.
Utterance B is tagged as SU-ACKNOWLEDGE inthe BF scheme, with the Response-to field setto A.
These utterances are examples ofacknowledgment terms such as okay.2.
Utterance B is tagged asSU-REPEAT-REPHRASE or SU-COMPLETION inthe BF scheme, with the Response-to field setto A.
These utterances are examples ofexplicit acknowledgments by paraphrase,repetition, or completion.3.
Utterance B is tagged with an agreement tagwith the Response-to field set to A, and thecombination of BF tags has not already beendetermined to indicate CANCEL or REPAIR.These utterances implicitly acknowledge A byindicating agreement with the propositionalcontent of A.. Utterance B is tagged as either WH-ANS,ASSERT or REASSERT, with the Response-tofield set to A, and A was tagged asINFO-REQUEST.
Such utterances implicitlyshow acknowledgment of a previous utteranceby answering a question posed in the previousutterance.Problems arise when an interlocutor implicitlyacknowledges an initiator's presentation either bycontinued attention or by initiating a newcontribution that is consistent with and relevant othe previous presentation.
The following dialoguesegment is an example of such an exchange:uttl u: our task is to get two tankersof orange juice to Corning by7amutt2 s: the orange warehouse is inComingThe reason that this case is somewhat problematicto our scheme is that it is not clear that utterance2 should be tagged as an ACCEPT of utterance 1 inthe BF scheme, and if the BF annotators fail to tagutterance 2 as an ACCEPT, it will not be identifiedas an ACKNOWLEDGE.
(In the BF scheme, theUnderstanding feature is only tagged when anexplicit acknowledgement or signal ofnon-understanding is made.
)5 Evaluat ionIn order to determine whether the mapping wepropose here results in accurate groundingannotation, we wrote a Perl script to perform themapping on SGML-format files containingdialogues annotated with the BF tags.
We used thescript on a set of four TRAINS-93 dialoguescontaining a total of 325 utterances, that had beenpreviously tagged with BF tags (HA95; CA97).The procedure for tagging the dialogues with BFtags was to have an annotator segment andannotate the dialogue, pass the segmented (butuntagged) dialogue to a second annotator to tagindependently, and finally for the two annotators tomeet and produce a reconciled version of thetagged dialogue.To evaluate the quality of the tags that were outputby the script, we had a human annotator tag the!1ilniEiEninni112CategoryINITACKNO-TAGREQACKREPAIRCANCELREQREPNumber ofOccurrences367Number of24Disagreements33332 4441 21169 580Table 3: "Partial Credit" AnalysisCategory  PA PE  kappa Sig LevelINIT 0.8985' 0.5084 0.7935 0.000005ACK 0.8646 0.5002 0.7291 0.000005N()-TAG 0.9354 0.8818 0.4533 0.005REQACK 0.9508 0.9289 0.3078 0.1REPAIR 0.9846 0.9727 0.4366 0.1CANCEL 0.9939 0.9757 0.7469 0.025R~QREP 1 0.9939 1 0.1Table 4: "Partial Credit" Scoressame four TRAINS-93 dialogues with groundingacts.
Our grounding annotator is a computationallinguist familiar with the concept of grounding butwith no prior knowledge of Tranm's coding scheme,the BF coding scheme, or the mapping scheme wewere using.
Before performing the annotation task,the annotator read Traum's descriptions of thegrounding tags, tagged a preliminary dialogue(found in Traum's dissertation), and compared thetags he assigned to those assigned by Traum.Tables 3 through 6 show the similarity of thehuman annotator's grounding tags to thoseautomatically derived.
The analysis is split intotwo parts to deal with the ability of annotators togive an utterance multiple labels.
Tables 3 and 4show a per tag analysis.
If both the annotators(the human and the Perl script) gave a tag such asINIT to an utterance (in addition to possibly othertags) then it is counted as agreement with respectto the INIT tag.
Table 3 shows the number of timesa tag appeared and the number of times there wasdisagreement.Table 4 shows PA (percent agreement), PE(percent expected agreement), and kappa for eachtag.
PA is simply the total agreement (either onthe presence or absence of a tag in an utterance)divided by the total number of utterances.
IfCategory Number of DisagreeOccurrences onINIT 242 40ACK 225 35INIT+ACK I01 39NO-TAG 41 21iNIT+REQACK 18 12CANCEL 8 2REPAIR 4 4INIT+REPAIRd-REQACK 2 2"mIT+REQACK+ACK 2 2REPAIR~ACKINIT+REPAIR&ACKINIT+REQREP 1REQACK 1 1REQACK+ACK 1 1REQREP211Table 5: "All-or-nothing" AnalysisN=number of utterances, TotalInit = number ofutterances tagged as INIT and TotalNone = numberof utterances not tagged as INIT, thenPE ~ ( Totallnit/ 2N) ~ + ( TotalNone/ 2N) ~.
In thiscase, there are 2N data points, the two sets ofdialogs by the two annotators.
Kappa is defined asK = ~ .
See (Car96; SC88) for more detailson these measures and the significance l vels listed.Table 5 presents the various combinations ofgrounding tags seen in the corpus.
Disagreement iscounted whenever two utterances do not have thesame exact set of tags.
Since the groups of tags aremutually exclusive, we can calculate PA, PE, andkappa over all the tag groups.
If agree =utterances where annotators assigned the same setof tags, then PA = agree/N.
If Cj is the number oftimes a set of tags such as CANCEL or INIT+ACKwas assigned, then PE = ~'~j15___ 1 ( Cj / 2N) e. Thedefinition of kappa remains the same.
Given thesedefinitions, PA = 0.7477, PE = 0.2876, and kappa= 0.6458.
To help determine where thedisagreements occurred, a simple measure of PAwas applied to the tag sets, if agreeonTag = caseswhere annotators agreed on a certain tag and NTag= occurences of tag, then in table 6,PA = agreeon Tag/ Ntag.The kappa of the "All-or-nothing" analysis issomewhat low compared with the 0.67 standard fortentative conclusions and the 0.8 standard forreliable results as reported in (Car96).
The "partialcredit" analysis is more favorable as the kappas for113CategoryINITACKINIT+ACKNO-TAGINIT-{-REQACKCANCELREPAIRINIT-b REPAIR-}- REQ AC KINIT-bREQACK-}-ACKREPAIR-bACKINIT+REPAIR+ACKINIT-bREQREPREQACKREQACK-bACKREQREP0.83470.84440.61390.48780.33330.75000000000Table 6: "All-or-nothing" ScoresINIT and ACK are close to the 0.8 standard.
Thegrounding tags are somewhat independent; an initalways starts a new discourse unit whether or notit also acknowledges a previous discourse unit.Thus, the partial credit analysis is likely to becloser to the actual reliability we want to measure.The remaining "partial credit" kappas have lowsignificance l vels indicating that more examplesare needed to calculate these measures.Another limitation of this study was that technicalpapers were used for annotator training ratherthan an annotation manual designed to explainhow tags apply in different situations.
This wasespecially problematic when several tags seemed toapply at once.
The BF tags themselves were notperfect as explained in (CA97).
Kappas for theseannotations varied from the lowest at 0.15 to 0.77for the highest.Given these limitations, the results of thisexperiment are promising.
An annotation manualneeds to be developed for labeling grounding andmore dialogs need to be labeled.
When thesesources of confusion are addressed, analysis ofremaining differences will reveal any minor changesnecessary to the mapping.6 Conc lus ionWe have presented an automatic mapping fromDRI backward- and forward-looking tags togrounding features and discourse units.
Ourapproach assumes imultaneous segmentation i toutterance units and annotation of BF tags, whicheliminates the need to split or join utterances.
Themapping is still being tested but preliminarycomparison with a human annotator was?
promising.
Automatic derivation of grounding tagswill eliminate the need for separate annotation ofgrounding, making dialogue annotation quicker andremoving a possible source of error.7 AcknowledgmentsThis work was supported in part by DARPA grant5-28838 and by National Science Foundation grantsiRL9503312 and 5-28789.ReferencesJames Allen and Mark Core.
DAMSL: Dialog ActMarkup In Several Layers, 1997.
Draft version,available athttp: / / www.cs.rochester.edu /research/ trains/ annotation /.Mark Core and James Allen.
Annotating dialogswith the damsl annotation scheme.
In WorkingNotes of the AAAI Fall Symposium onCommunicative Action in Humans and Machines,1997.Jean Carletta.
Assessing agreement onclassification tasks: The kappa statistic.Computational Linguistics, 22(2), 1996.Herbert Clark and Edward Schaefer.
Contributingto discourse.
Cognitive Science, 13, 1989.Peter Heeman and James Allen.
The trains 93dialogues.
Technical report, University ofRochester, 1995.Teresa Sikorski and James Allen.
A scheme forannotating problem solving actions in dialogue.
InWorking Notes of the AAAI  Fall Symposium onCommunicative Action in Humans and Machines,1997.S.
Siegel and N. J. Castellan.
NonparametricStatistics for the Behavioral Sciences.McGraw-Hill, second edition, 1988.David Traum.
A Computational Theory ofGrounding in Natural Language Conversation.PhD thesis, University of Rochester, 1994.114
