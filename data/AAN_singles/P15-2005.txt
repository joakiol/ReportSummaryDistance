Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 27?31,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsSemi-Stacking for Semi-supervised Sentiment ClassificationShoushan Li?
?,   Lei Huang?,    Jingjing Wang?,   Guodong Zhou?
*?Natural Language Processing Lab, Soochow University, China?
Collaborative Innovation Center of Novel Software Technology and Industrialization{shoushan.li, lei.huang2013, djingwang}@gmail.com,gdzhou@suda.edu.cnAbstractIn this paper, we address semi-supervisedsentiment learning via semi-stacking, whichintegrates two or more semi-supervisedlearning algorithms from an ensemble learn-ing perspective.
Specifically, we apply meta-learning to predict the unlabeled data giventhe outputs from the member algorithms andpropose N-fold cross validation to guaranteea suitable size of the data for training themeta-classifier.
Evaluation on four domainsshows that such a semi-stacking strategy per-forms consistently better than its member al-gorithms.1 IntroductionThe past decade has witnessed a huge explodinginterest in sentiment analysis from the natural lan-guage processing and data mining communitiesdue to its inherent challenges and wide applica-tions (Pang et al, 2008; Liu, 2012).
One funda-mental task in sentiment analysis is sentimentclassification, which aims to determine the senti-mental orientation a piece of text expresses (Panget al, 2002).
For instance, the sentence "I abso-lutely love this product."
is supposed to be deter-mined as a positive expression in sentimental ori-entation.
?While early studies focus on supervised learn-ing, where only labeled data are required to trainthe classification model (Pang et al, 2002), recentstudies devote more and more to reduce the heavydependence on the large amount of labeled databy exploiting semi-supervised learning ap-proaches, such as co-training (Wan, 2009; Li et al,2011), label propagation (Sindhwani and Melville,2008), and deep learning (Zhou et al, 2013), tosentiment classification.
Empirical evaluation onvarious domains demonstrates the effectiveness ofthe unlabeled data in enhancing the performance?
* Corresponding authorof sentiment classification.
However, semi-super-vised sentiment classification remains challeng-ing due to the following reason.Although various semi-supervised learning al-gorithms are now available and have been shownto be successful in exploiting unlabeled data toimprove the performance in sentiment classifica-tion, each algorithm has its own characteristicwith different pros and cons.
It is rather difficultto tell which performs best in general.
Therefore,it remains difficult to pick a suitable algorithm fora specific domain.
For example, as shown in Li etal.
(2013), the co-training algorithm with personaland impersonal views yields better performancesin two product domains: Book and Kitchen, whilethe label propagation algorithm yields better per-formances in other two product domains: DVDand Electronic.In this paper, we overcome the above challengeabove by combining two or more algorithms in-stead of picking one of them to perform semi-su-pervised learning.
The basic idea of our algorithmensemble approach is to apply meta-learning tore-predict the labels of the unlabeled data after ob-taining their results from the member algorithms.First, a small portion of labeled samples in the in-itial labeled data, namely meta-samples, arepicked as unlabeled samples and added into theinitial unlabeled data to form a new unlabeled data.Second, we use the remaining labeled data as thenew labeled data to perform semi-supervisedlearning with each member algorithm.
Third, wecollect the meta-samples?
probability results fromall member algorithms to train a meta-learningclassifier (called meta-classifier).
Forth and fi-nally, we utilize the meta-classifier to re-predictthe unlabeled samples as new automatically-la-beled samples.
Due to the limited number of la-beled data in semi-supervised learning, we use N-fold cross validation to obtain more meta-samplesfor better learning the meta-classifier.
In principle,the above ensemble learning approach could be27seen as an extension of the famous stacking ap-proach (D?eroski and ?enko, 2004) to semi-su-pervised learning.
For convenience, we call itsemi-stacking.The remainder of this paper is organized as fol-lows.
Section 2 overviews the related work onsemi-supervised sentiment classification.
Section3 proposes our semi-stacking strategy to semi-su-pervised sentiment classification.
Section 4 pro-poses the data filtering approach to filter low-con-fident unlabeled samples.
Section 5 evaluates ourapproach with a benchmark dataset.
Finally, Sec-tion 6 gives the conclusion and future work.2 Related WorkEarly studies on sentiment classification mainlyfocus on supervised learning methods with algo-rithm designing and feature engineering (Pang etal., 2002; Cui et al, 2006; Riloff et al, 2006; Li etal., 2009).
Recently, most studies on sentimentclassification aim to improve the performance byexploiting unlabeled data in two main aspects:semi-supervised learning (Dasgupta and Ng, 2009;Wan, 2009; Li et al, 2010) and cross-domainlearning (Blitzer et al 2007; He et al 2011; Li etal., 2013).
Specifically, existing approaches tosemi-supervised sentiment classification could becategorized into two main groups: bootstrapping-style and graph-based.As for bootstrapping-style approaches, Wan(2009) considers two different languages as twoviews and applies co-training to conduct semi-su-pervised sentiment classification.
Similarly, Li etal.
(2010) propose two views, named personal andimpersonal views, and apply co-training to use un-labeled data in a monolingual corpus.
More re-cently, Gao et al (2014) propose a feature sub-space-based self-training to semi-supervised sen-timent classification.
Empirical evaluationdemonstrates that subspace-based self-trainingoutperforms co-training with personal and imper-sonal views.As for graph-based approaches, Sindhwani andMelville (2008) first construct a document-wordbipartite graph to describe the relationship amongthe labeled and unlabeled samples and then applylabel propagation to get the labels of the unlabeledsamples.Unlike above studies, our research on semi-su-pervised sentiment classification does not merelyfocus on one single semi-supervised learning al-gorithm but on two or more semi-supervisedlearning algorithms with ensemble learning.
Tothe best of our knowledge, this is the first attemptto combine two or more semi-supervised learningalgorithms in semi-supervised sentiment classifi-cation.3 Semi-Stacking for Semi-supervisedSentiment ClassificationIn semi-supervised sentiment classification, thelearning algorithm aims to learn a classifier froma small scale of labeled samples, named initial la-beled data, with a large number of unlabeled sam-ples.
In the sequel, we refer the labeled data as1{( , )} Lni i iL x y ??
where dix ?R  is the d dimen-sional input vector, andiy is its output label.
Theunlabeled data in the target domain is denoted as1{( )} Unk kU x ??
.
Suppose semil  is a semi-supervisedlearning algorithm.
The inputs of semil  are L  andU , and the output is 1' {( , )} Unk k kU x y ??
which de-notes the unlabeled data with automatically as-signed labels.
Besides the labeled results, it is al-ways possible to obtain the probability results, de-noted as UP ?
, which contains the posterior proba-bilities belonging to the positive and negative cat-egories of each unlabeled sample, i.e., <( | ), ( | )k kp pos x p neg x>.
For clarity, some im-portant symbols are listed in Table 1.Table 1: Symbol definitionSymbol DefinitionL  Labeled dataU  Unlabeled dataU ?
Unlabeled data with automaticallyassigned labelsUP ?
The probability result of unlabeleddatasuperl  A supervised learning algorithmsemil  A semi-supervised learning algo-rithmmetacThe meta-classifier obtained frommeta-learningtestcThe test classifier for classifying thetest data3.1 Framework OverviewIn our approach, two member semi-supervisedlearning algorithm are involved, namely,1semil and2semil  respectively, and the objective is to leverageboth of them to get a better-performed semi-su-pervised learning algorithm.
Our basic idea is toapply meta-learning to re-predict the labels of theunlabeled data given the outputs from the memberalgorithms.
Figure 1 shows the framework of our28implementation of the basic idea.
The core com-ponent in semi-stacking is the meta-classifierlearned from the meta-learning process, i.e.,metac .This classifier aims to make a better prediction onthe unlabeled samples by combining two differentprobability results from the two member algo-rithms.Figure 1: The framework of semi-stacking3.2 Meta-learningAs shown above, meta-classifier is the core com-ponent in semi-stacking, trained through the meta-learning process.
Here, meta- means the learningsamples are not represented by traditional descrip-tive features, e.g., bag-of-words features, but bythe result features generated from member algo-rithms.
In our approach, the learning samples inmeta-learning are represented by the posteriorprobabilities of the unlabeled samples belongingto the positive and negative categories from mem-ber algorithms, i.e.,(1)Where1( | )kp pos x  and 1( | )kp neg x  are the pos-terior probabilities from the first semi-supervisedlearning algorithm while2 ( | )kp pos x  and2 ( | )kp neg x  are the posterior probabilities fromthe second semi-supervised learning algorithm.The framework of the meta-learning process isshown in Figure 2.
In detail, we first split the ini-tial labeled data into two partitions,newL  and unLwherenewL  is used as the new initial labeled datawhileunL  is merged into the unlabeled data U  toform a new set of unlabeled dataunL U?
.
Then,two semi-supervised algorithms are performedwith the labeled datanewL  and the unlabeled dataunL U?
.
Third and finally, the probability resultsofunL , together with their real labels are used asmeta-learning samples to train the meta-classifier.The feature representation of each meta-sample isdefined in Formula (1).Figure 2: The framework of meta-learning3.3 Meta-learning with N-fold Cross Valida-tionInput:   Labeled data L ,  Unlabeled data UOutput:  The meta-classifiermetacProcedure:(a) Initialize the meta-sample setmetaS ??
(b) Split L into N  folds, i.e.,1 2 NL L L L?
?
??
(c) For i  in 1: N :c1)new iL L L?
?
, un iL L?c2) Perform1semil  on newL  and unL U?c3) Perform2semil  on newL  and unL U?c4) Generate the meta-samples, imetaS ,from the probability results ofunL  in the abovetwo steps.c5) imeta meta metaS S S?
?
(d) Train the meta-classifiermetac with metaSand superlFigure 3: The algorithm description of meta-learningwith N-fold cross validationOne problem of meta-learning is that the data sizeofunL  might be too small to learn a good meta-classifier.
To better use the labeled samples in theinitial labeled data, we employ N-fold cross vali-dation to generate more meta- samples.
Specifi-cally, we first split L  into N  folds.
Then, we se-lect one of them asunL  and consider the others asnewL  and generate the meta-learning samples asdescribed in Section 3.2; Third and finally, we re-peat the above step 1N ?
times by selecting a dif-ferent fold asunL  in each time.
In this way, we canobtain the meta-learning samples with the samesize as the initial labeled data.
Figure 3 presentsthe algorithm description of meta-learning withN-fold cross validation.
In our implementation,we set N to be 10.1 1 2 2( | ), ( | ), ( | ), ( | )meta k k k kx p pos x p neg x p pos x p neg x??
?LU1semil2semil1UP ?2UP ?metacnew U ?unL U?1 unLP1semil2semil2 unLPmetacsuperlnewL29Figure 4: Performance comparison of baseline and three semi-supervised learning approaches4 ExperimentationDataset: The dataset contains product reviewsfrom four different domains: Book, DVD, Elec-tronics and Kitchen appliances (Blitzer et al,2007), each of which contains 1000 positive and1000 negative labeled reviews.
We randomly se-lect 100 instances as labeled data, 400 instancesare used as test data and remaining 1500 instancesas unlabeled data.Features: Each review text is treated as a bag-of-words and transformed into binary vectors encod-ing the presence or absence of word unigrams andbigrams.Supervised learning algorithm: The maximumentropy (ME) classifier implemented with thepublic tool, Mallet Toolkits (http://mal-let.cs.umass.edu/), where probability outputs areprovided.Semi-supervised learning algorithms: (1) Thefirst member algorithm is called self-trainingFS,proposed by Gao et al (2014).
This approach canbe seen as a special case of self-training.
Differentfrom the traditional self-training, self-trainingFSuse the feature-subspace classifier to make theprediction on the unlabeled samples instead of us-ing the whole-space classifier.
In our implementa-tion, we use four random feature subspaces.
(2)The second member algorithm is called labelpropagation, a graph-based semi-supervisedlearning approach, proposed by Zhu and Ghah-ramani (2002).
In our implementation, the docu-ment-word bipartite graph is adopted to build thedocument-document graph (Sindhwani and Mel-ville, 2008).Significance testing: We perform t-test to evalu-ate the significance of the performance differencebetween two systems with different approaches(Yang and Liu, 1999)Figure 4 compares the performances of thebaseline approach and three semi-supervisedlearning approaches.
Here, the baseline approachis the supervised learning approach by using onlythe initial labeled data (i.e.
no unlabeled data isused).
From the figure, we can see that both Self-trainingFS and label propagation are successful inexploiting unlabeled data to improve the perfor-mances.
Self-trainingFS outperforms label propa-gation in three domains including Book, DVD,and Kitchen but it performs worse in Electronic.Our approach (semi-stacking) performs much bet-ter than baseline with an impressive improvementof 4.95% on average.
Compared to the two mem-ber algorithms, semi-stacking always yield a bet-ter performance, although the improvement overthe better-performed member algorithm is slight,only around 1%-2%.
Significance test shows thatour approach performs significantly better thanworse-performed member algorithm (p-value<0.01) in all domains and it also performssignificantly better than better-performed memberalgorithm (p-value<0.05) in three domains, i.e.,Book, DVD, and Kitchen.5 ConclusionIn this paper, we present a novel ensemble learn-ing approach named semi-stacking to semi-super-vised sentiment classification.
Semi-stacking isimplemented by re-predicting the labels of the un-labeled samples with meta-learning after two ormore member semi-supervised learning ap-proaches have been performed.
Experimentalevaluation in four domains demonstrates thatsemi-stacking outperforms both member algo-rithms.0.680.6550.710.6730.7050.6830.7180.750.6730.6630.73 0.7350.7150.7030.7380.760.640.660.680.70.720.740.760.78Book DVD Electronic KitchenAccuracyUsing 100 labeled samplesBaseline Self-trainingFS Label Propagation Semi-Stacking30AcknowledgmentsThis research work has been partially supportedby three NSFC grants, No.61273320,No.61375073, No.61331011, and CollaborativeInnovation Center of Novel Software Technologyand Industrialization.ReferencesBlitzer J., M. Dredze and F. Pereira.
2007.
Biographies,Bollywood, Boom-boxes and Blenders: DomainAdaptation for Sentiment Classification.
In Pro-ceedings of ACL-07, pp.440-447.Blum A. and T. Mitchell.
1998.
Combining Labeledand Unlabeled Data with Co-training.
In Proceed-ings of COLT-98,pp.
92-100.Cui H., V. Mittal and M. Datar.
2006.
Comparative Ex-periments on Sentiment Classification for OnlineProduct Reviews.
In Proceedings of AAAI-06,pp.1265-1270.Dasgupta S. and V. Ng.
2009.
Mine the Easy, Classifythe Hard: A Semi-Supervised Approach to Auto-matic Sentiment Classification.
In Proceedings ofACL-IJCNLP-09, pp.701-709, 2009.D?eroski S. and B.
?enko.
2004.
Is Combining Classi-fiers with Stacking Better than Selecting the BestOne?
Machine Learning, vol.54(3), pp.255-273,2004.Gao W., S. Li, Y. Xue, M. Wang, and G. Zhou.
2014.Semi-supervised Sentiment Classification withSelf-training on Feature Subspaces.
In Proceedingsof CLSW-14, pp.231-239.He Y., C. Lin and H. Alani.
2011.
Automatically Ex-tracting Polarity-Bearing Topics for Cross-DomainSentiment Classification.
In Proceedings of ACL-11,pp.123-131.Li S., C. Huang, G. Zhou and S. Lee.
2010.
EmployingPersonal/Impersonal Views in Supervised andSemi-supervised Sentiment Classification.
In Pro-ceedings of ACL-10, pp.414-423.Li S., R. Xia, C. Zong, and C. Huang.
2009.
A Frame-work of Feature Selection Methods for Text Catego-rization.
In Proceedings of ACL-IJCNLP-09,pp.692-700.Li S., Y. Xue, Z. Wang, and G. Zhou.
2013.
ActiveLearning for Cross-Domain Sentiment Classifica-tion.
In Proceedings of IJCAI-13, pp.2127-2133.Li S., Z. Wang, G. Zhou and S. Lee.
2011.
Semi-super-vised Learning for Imbalanced Sentiment Classifi-cation.
In Proceedings of IJCAI-11, pp.1826-1831.Liu B.
2012.
Sentiment Analysis and Opinion Mining(Introduction and Survey).
Morgan & ClaypoolPublishers, May 2012.Pang B. and L. Lee.
2008.
Opinion Mining and Senti-ment Analysis: Foundations and Trends.
Infor-mation Retrieval, vol.2(12), pp.1-135.Pang B., L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment Classification using Machine Learn-ing Techniques.
In Proceedings of EMNLP-02,pp.79-86.Riloff E., S. Patwardhan and J. Wiebe.
2006.
FeatureSubsumption for Opinion Analysis.
In Proceedingsof EMNLP-06, pp.440-448.Sindhwani V. and P. Melville.
2008.
Document-WordCo-Regularization for Semi-supervised SentimentAnalysis.
In Proceedings of ICDM-08, pp.1025-1030.Wan X.
2009.
Co-Training for Cross-Lingual Senti-ment Classification.
In Proceedings of ACL-IJCNLP-09, pp.235-243.Yang Y. and X. Liu.
1999.
A Re-Examination of TextCategorization Methods.
In Proceedings of SIGIR-99.Zhu X. and Z. Ghahramani.
2002.
Learning from La-beled and Unlabeled Data with Label Propagation.CMU CALD Technical Report.
CMU-CALD-02-107.31
