Using Semantic Preferences to Identify Verbal Participation inRole Switching Alternations.Diana McCar thyCognit ive & Comput ing  Sciences,University of SussexBrighton BN1 9QH, UKd ianam @cogs.susx.
ac.
ukAbst rac tWe propose a method for identifying diathesis alter-nations where a particular argument type is seen inslots which have different grammatical roles in thealternating forms.
The method uses selectional pref-erences acquired as probability distributions overWordNet.
Preferences for the target slots are com-pared using a measure of distributional similarity.The method is evaluated on the causative and cona-tive alternations, but is generally applicable anddoes not require a priori knowledge specific to thealternation.1 In t roduct ionDiathesis alternations are alternate ways in whichthe arguments of a verb are expressed syntactically.The syntactic hanges are sometimes accompaniedby slight changes in the meaning of the verb.
An ex-ample of the causative alternation is given in (1) be-low.
In this alternation, the object of the transitivevariant can also appear as the subject of the intransi-tive variant.
In the conative alternation, the transi-tive form alternates with a prepositional phrase con-struction involving either at or on.
An example ofthe conative alternation is given in (2).1.
The boy broke the window ~-* The windowbroke.2.
The boy pulled at the rope *-* The boy pulledthe rope.We refer to alternations where a particular seman-tic role appears in different grammatical roles in al-ternate realisations as "role switching alternations"(RSAS).
It is these alternations that our method ap-plies to.Recently, there has been interest in corpus-basedmethods to identify alternations (McCarthy and Ko-rhonen, 1998; Lapata, 1999), and associated verbclassifications (Stevenson and Merlo, 1999).
Thesehave either elied on a priori knowledge specified forthe alternations in advance, or are not suitable fora wide range of alternations.
The fully automaticmethod outlined here is applied to the causativeand conative alternations, but is applicable to otherRSAS.2 MotivationDiathesis alternations have been proposed for anumber of NLP tasks.
Several researchers have sug-gested using them for improving lexical acquisition.Korhonen (1997) uses them in subcategorizationframe (SCF) acquisition to improve the performanceof a statistical filter which determines whether aSCF observed for a particular verb is genuine or not.They have also been suggested for the recovery ofpredicate argument structure, necessary for SCF ac-quisition (Briscoe and Carroll, 1997; Boguraev andBriscoe, 1987).
And Ribas (1995) showed that selec-tional preferences acquired using alternations per-formed better on a word sense disambiguation taskcompared to preferences acquired without alterna-tions.
He used alternations to indicate where theargument head data from different slots can be com-bined since it occupies the same semantic relation-ship with the predicate.Different diathesis alternations give different em-phasis and nuances of meaning to the same basiccontent.
These subtle changes of meaning are impor-tant in natural language generation (Stede, 1998).Alternations provide a means of reducing redun-dancy in the lexicon since the alternating scFs neednot be enumerated for each individual verb if amarker is used to specify which verbs the alterna-tion applies to.
Alternations also provide a meansof generalizing patterns of behaviour over groups ofverbs, typically the group members are semanticallyrelated.
Levin (1993) provides aclassification ofover3000 verbs according to their participation i alter-nations involving NP and PP constituents.
Levin'sclassification is not intended to be exhaustive.
Au-tomatic identification ofalternations would be a use-ful tool for extending the classification with newparticipants.
Levin's taxonomy might also be usedalongside observed behaviour, to predict unseen be-haviour.Levin's classification has been extended by otherNLP researchers (Doff and Jones, 1996; Dang et al,256<Root>I  bs,r  t,on  i uoao activ,t e..ti /  ~ .
.
.
.
.
.
.
~ construction timecar  war  l measure \] /"( time \] ( relation \] migration meal ceremonial,, drum---0a- t .
.
.
.
.
/\[time_period\]weekmonthafternoonAtime Tfo .v,=t,4speechyellingmigrationFigure 1: TCM for the object slot of the transitive frame of start.1998).
Dang et al (1998) modify it by adding newclasses which remove the overlap between classesfrom the original scheme.
Dorr and Jones (1996)extend the classification by using grammatical in-formation in LDOCE alongside semantic informationin WordNet.
What is missing is a way of classifyingverbs when the relevant information is not availablein a manmade resource.
Using corpora by-passesreliance on the availability and adequacy of MRDs.Additionally, the frequency information in corpora ishelpful for estimating alternation productivity (La-pata, 1999).
Estimations of productivity have beensuggested for controlling the application of alterna-tions (Briscoe and Copestake, 1996).
We propose amethod to acquire knowledge of alternation partic-ipation directly from corpora, with frequency infor-mation available as a by-product.3 MethodWe use both syntactic and semantic information foridentifying participants in RSAs.
Firstly, syntacticprocessing is used to find candidates taking the alter-nating SeEs.
Secondly, selectional preference modelsare acquired for the argument heads associated witha specific slot in a specific SCF of a verb.We use the SCF acquisition system of Briscoe andCarroll (1997), with a probabilistic LR parser (Inui etal., 1997) for syntactic processing.
The corpus datais POS tagged and lemmatised before the LR parseris applied.
Subcategorization patterns are extractedfrom the parses, these include both the syntactic at-egories and the argument heads of the constituents.These subcategorization patterns are then classifiedaccording to a set of 161 SeE classes.
The SeE en-tries for each verb are then subjected to a statisticalfilter which removes SCFs that have occurred witha frequency less than would be expected by chance.The resulting SCF lexicon lists each verb with theSCFs it takes.
Each SCF entry includes a frequencycount and lists the argument heads at all slots.Selectional preferences are automatically acquiredfor the slots involved in the role switching.
We referto these as the target slots.
For the causative al-ternation, the slots are the direct object slot of thetransitive SCF and the subject slot of the intransi-tive.
For the conative, the slots are the direct objectof the transitive and the PP of the np v pp SCF.Selectional preferences are acquired using themethod devised by Li and Abe (1995).
The pref-erences for a slot are represented as a tree cut model(TCM).
This is a set of disjoint classes that partitionthe leaves of the WordNet noun hypernym hierar-chy.
A conditional probability is attached to each ofthe classes in the set.
To ensure the TCM covers allthe word senses in WordNet, we modify Li and Abe'soriginal scheme by creating hyponym leaf classes be-low all WordNet's hypernym (internal) classes.
Eachleaf holds the word senses previously held at the in-ternal class.
The nominal argument heads from atarget slot are collected and used to populate theWordNet hierarchy with frequency information.
Thehead lemmas are matched to the classes which con-tain them as synonyms.
Where a lemma appears as asynonym in more than one class, its frequency countis divided between all classes for which it has directmembership.
The frequency counts from hyponymclasses are added to the count for each hypernymclass.
A root node, created above all the WordNetroots, contains the total frequency count for all theargument head lemmas found within WordNet.
Theminimum description length principle (MDL) (Rissa-nen, 1978) is used to find the best TCM by consid-257ering the cost (in bits) of describing both the modeland the argument head data encoded in the model.The cost (or description length) for a TCM is cal-culated according to equation 1.
The number ofparameters of the model is given by k, this is thenumber of classes in the TCM minus one.
S is thesample size of the argument head data.
The cost ofdescribing each argument head (n) is calculated us-ing the log of the probability estimate for the classeson the TCM that n belongs to (Cn).kdescription length = ~ x log IS I -  E logp(cn) (1)nESA small portion of the TCM for the object slot ofstart in the transitive frame is displayed in figure 1.WordNet classes are displayed in boxes with a labelwhich best reflects the sense of the class.
The prob-ability estimates are shown for the classes along theTCM.
Examples of the argument head data are dis-played below the WordNet classes with dotted linesindicating membership at a hyponym class beneaththese classes.We assume that verbs which participate will showa higher degree of similarity between the preferencesat the target slots compared with non-participatingverbs.
To compare the preferences we compare theprobability distributions across WordNet using ameasure of distributional similarity.
Since the prob-ability distributions may be at different levels ofWordNet, we map the TCMs at the target slots to acommon tree cut, a "base cut".
We experiment withtwo different ypes of base cut.
The first is simply abase cut at the eleven root classes of WordNet.
Werefer to this as the "root base cut" (I~BC).
The sec-ond is termed the "union base cut" (tJBC).
This isobtained by taking all classes from the union of thetWO TCMs which are not subsumed by another classin this union.
Duplicates are removed.
Probabilitiesare assigned to the classes of a base cut using theestimates on the original TCM.
The probability esti-mate for a hypernym class is obtained by combiningthe probability estimates for all its hyponyms on theoriginal cut.
Figure 2 exemplifies this process for twoTOMs (TCM1 and TCM2) in an imaginary hierarchy.The UBC is at the classes B, c and D.To quantify the similarity between the probabilitydistributions for the target slots we use the a-skewdivergence (aSD) proposed by Lee (1999).
1 Thismeasure, defined in equation 2, is a smoothed versionof the Kulback-Liebler divergence, pl(x)  and p2(x)are the two probability distributions which are beingcompared.
The ~ constant is a value between 0 and1 We also experimented with euclidian distance, the L1norm, and cosine measures.
The differences in performanceof these measures were not statistically significant.1 which smooths pl(x) with p2(z) so that ~SD isalways defined.
We use the same value (0.99) foras Lee.
If a is set to 1 then this measure is equivalentto the Kulback-Liebler divergence.asd(p l (x ) ,p2(x ) )  = x p l ( z ) )  +((1 - . )
?
(2)4 Exper imenta l  Eva luat ionWe experiment with a SCF lexicon produced from19.3 million words of parsed text from the BNC(Leech, 1992).
We used the causative and conativealternations, ince these have enough candidates inour lexicon for experimentation.
Evaluation is per-formed on verbs already filtered by the syntacticprocessing.
The SCF acquisition system has beenevaluated elsewhere (Briscoe and Carroll, 1997).We selected candidate verbs which occurred with10 or more nominal argument heads at the targetslots.
The argument heads were restricted to thosewhich can be classified in the WordNet hypernym hi-erarchy.
Candidates were selected by hand so as toobtain an even split between candidates which didparticipate in the alternation (positive candidates)and those which did not (negative candidates).
Fourhuman judges were used to determine the "gold stan-dard".
The judges were asked to specify a yes orno decision on participation for each verb.
Theywere Mso permitted a don't know verdict.
The kappastatistic (Siegel and Castellan, 1988) was calculatedto ensure that there was significant agreement be-tween judges for the initial set of candidates.
Fromthese, verbs were selected which had 75% or moreagreement, i.e.
three or more judges giving the sameyes or no decision for the verb.For the causative alternation we were left with 46positives and 53 negatives.
For the conative alter-nation we had 6 of each.
In both cases, we used theMann Whitney U test to see if there was a signifi-cant relationship between the similarity measure andparticipation.
We then used a threshold on the sim-ilarity scores as the decision point for participationto determine a level of accuracy.
We experimentedwith both the mean and median of the scores as athreshold.
Seven of the negative causative candi-dates were randomly chosen and removed to ensurean even split between positive and negative candi-dates for determining accuracy using the mean andmedian as thresholds.The following subsection describes the results ofthe experiments using the method described in sec-tion 3 above.
Subsection 4.2 describes an experimenton the same data to determine participation using asimilarity measure based on the intersection of thelemmas at the target slots.258- _ _ 0 .4  ~ g ~  New TCM1E F G H I JNew TCM2 - , ,E F G H I JFigure 2: New TCMs at the union base cut4.1 Using Syntax and SelectionalPre ferencesThe results for the causative alternation are dis-played in table 1 for both the rt~c and the uBc.
Therelationship between participation and ~SD is highlysignificant in both cases, with values of p well below0.01.
Accuracy for the mean and median thresholdsare displayed in the fourth and fifth columns.
Boththresholds outperform the random baseline of 50%.The results for the vl3c are slightly improved, com-pared to those for the rtBc, however the improve-ment is not significant.The numbers of false negative (FN) and false posi-tive (FP) errors for the mean and median thresholdsare displayed in table 2, along with the threshold andaccuracy.
The outcomes for each individual verb forthe experiment using the RBC and the mean thresh-old are as follows:?
True negatives:add admit answer believe borrow cost declare de-mand expect feel imagine know notice pay per-form practise proclaim read remember sing sur-vive understand win write?
True positives:accelerate bang bend boil break burn changeclose cook cool crack decrease drop dry end ex-pand fly improve increase match melt open ringrip rock roll shatter shut slam smash snap spillsplit spread start stop stretch swing lilt turnwake?
False negatives:flood land march repeat terminate?
False positives:ask attack catch choose climb drink eat help kickknit miss outline pack paint plan prescribe pullremain steal suck warn washThe results for the uBc experiment are very similar.I f  the median is used, the number of FPs and FNsare evenly balanced.
This is because the medianthreshold is, by definition, taken midway betweenthe test items arranged in order of their similarityscores.
There are an even number of items on eitherside of the decision point, and an even number ofpositive and negative candidates in our test sample.Thus, the errors on either side of the decision pointare equal in number.For both base cuts, there are a larger number offalse positives than false negatives when the meanis used.
The mean produces a higher accuracy thanthe median, but gives an increase in false positives.Many false positives arise where the preferences atboth target slots are near neighbours in WordNet.For example, this occurred for eat and drink.
Thereverbs have a high probability mass (around 0.7) un-der the ent i ty  class in both target slots, since bothpeople and types of food occur under this class.
Incases like these, the probability distributions at theasc ,  and frequently the UBC, are not sufficiently dis-tinctive.The polysemy of the verbs may provide anotherexplanation for the large quantity of false positives.The SCFS and data of different senses should notideally be combined, at least not for coarse grainedsense distinctions.
We tested the false positive andtrue negative candidates to see if there was a re-lationship between the polysemy of a verb and itsmisclassification.
The number of senses (accordingto WordNet) was used to indicate the polysemy of averb.
The Mann Whitney U test was performed on259RBCUBCMann Whitney z-4.03-4.3significance (p) mean median0.0003 71 630.00003 73 70Table 1: Causative resultsbase cutUBCUBCRBCRBCthreshold typemeanmedianmeanmedianthreshold0.380.200.32 "0.15accuracy o~ num FPs73 2170 1471 2263 '17num FNs1417Table 2: Error analysis for the causative xperimentsthe verbs found to be true negative and false positiveusing the Rat .
A significant relationship was notfound between participation and misclassification.Both groups had an average of 5 senses per verb.This is not to say that distinguishing verb senseswould not improve performance, provided that therewas sufficient data.
However, verb polysemy doesnot appear to be a major source of error, from ourpreliminary analysis.
In many eases, such as readwhich was classified both by the judges, and the sys-tem as a negative candidate, the predominant senseof the verb provides the majority of the data.
Alter-nate senses, for example, the book reads well, oftendo not contribute nough data so as to give rise toa large proportion of errors.
Finding an appropriateinventory of senses would be difficult, since we wouldnot wish to separate related senses which occur asalternate variants of one another.
The inventorywould therefore require knowledge of the phenomenathat we are endeavouring to acquire automatically.To show that our method will work for other RSAS,we use the conative.
Our sample size is rather smallsince we are limited by the number of positive can-didates in the corpus having sufficient frequency forboth sets.
The sparse data problem is acute whenwe look at alternations with specific prepositions.
Asample of 12 verbs (6 positive and 6 negative) re-mained after the selection process outlined above.For this small sample we obtained a significant re-sult (p = 0.02) with a mean accuracy of 67% anda median accuracy of 83%.
On this occasion, themedian performed better than the mean.
More datais required to see if this difference is significant.4.2 Us ing  Syntax  and  LemmasThis experiment was conducted using the same dataas that used in the previous subsection.
In this ex-periment, we used a similarity score on the argumentheads directly, instead of generalizing the argumentheads to WordNet classes.
The venn diagram in fig-ure 3 shows a subset of the lemmas at the transitiveand intransitive SCFs for the verb break.The lemma based similarity measure is termedlemmaoverlap (LO) and is given in equation 3, whereA and B represent the target slots.
LO is the size ofthe intersection of the multisets of argument headsat the target slots, divided by the size of the smallerof the two multisets.
The intersection of two mul-tisets includes duplicate items only as many timesas the item is in both sets.
For example, if oneslot contained the argument heads {person, person,person, child, man, spokeswoman}, and the otherslot contained {person, person, child, chair, collec-tion}, then the intersection would be {person, per-3 son, child}, and LO would be g. This measure rangesbetween zero (no overlap) and I (where one set is aproper subset of that at the other slot).Lo(A, B) = Imuttiset inlerseetion(A B)I (3)Ismallest set(A, B)IUsing the Mann Whitney U test on the LO scores,we obtained a z score of 2.00.
This is significant othe 95% level, a lower level than that for the class-based experiments.
The results using the mean andmedian of the LO scores are shown in table 3.
Perfor-mance is lower than that for the class-based experi-ments.
The outcome for the individual verbs usingthe mean as a threshold was:-?
True negatives:add admit answer borrow choose climb cost de-clare demand drink eat feel imagine notice out-line pack paint perform plan practise prescribeproclaim read remain sing steal suck survive un-derstand wash win write?
True positives:bend boil burn change close cool dry end fly im-prove increase match melt open ring roll shutslam smash Mart stop tilt wake?
False negatives:accelerate bang break cook crack decrease dropexpand flood land march repeat rip rock shatter260_ ~ ~ ~Objects  of Subjects _~ / ~ "~ntransitiveIntra/~i:e /silence ~/ / \\ war.
\ back /ground /y weather X dead,oc k /diet /Figure 3: Lemmas at the causative target slots of breaksnap spill split spread stretch swing terminateturn?
False positives:ask attack believe catch expect help kick knitknow miss pay pull remember warnInterestingly, the errors for the LO measure tendto be false negatives, rather than false positives.
TheLO measure is much more conservative than the ap-proach using the TCMS.
In this case the medianthreshold produces better results.For the conative alternation, the lemma basedmethod does not show a significant relationship be-tween participation and the LO scores.
Moreover,there is no difference between the sums of the ranksof the two groups for the Mann Whitney U test.The mean produces an accuracy of 58% whilst themedian produces an accuracy of 50%.5 Re la ted  WorkThere has been some recent interest in observingalternations in corpora (McCarthy and Korhonen,1998; Lapata, 1999) and predicting related verbclassifications (Stevenson and Merlo, 1999).
Ear-lier work by Resnik (1993) demonstrated a link be-tween selectional preference strength and participa-tion in alternations where the direct object is omit-ted.
Resnik used syntactic information from thebracketing within the Penn Treebank corpus.
Re-search into the identification of other diathesis al-ternations has been advanced by the availabilityof automatic syntactic processing.
Most work us-ing corpus evidence for verb classification has re-lied on a priori knowledge in the form of linguisticcues specific to the phenomena being observed (La-pata, 1999; Stevenson and Merlo, 1999).
Our ap-proach, whilst being applicable only to RSAs, doesnot require human input specific to the alternationat hand.Lapata (1999) identifies participation i the dativeand benefactive alternations.
Lapata's trategy is toidentify participants using a shallow parser and vari-ous linguistic and semantic ues, which are specifiedmanually for these two alternations.
PP attachmentsare resolved using Hindle and Rooth's (1993) lexicalassociation score.
Compound nouns, which could bemistaken for the double object construction, werefiltered using the log-likelihood ratio test.
The se-mantic cues were obtained by manual analysis.
Therelative frequency of a SCF for a verb, compared tothe total frequency of the verb, was used for filteringout erroneous SCFs.Lapata does not report recall and precision fig-ures against a gold standard.
The emphasis is onthe phenomena actually evident in the corpus data.Many of the verbs listed in Levin as taking the al-ternation were not observed with this alternationin the corpus data.
This amounted to 44% of theverbs for the benefactive, and 52% for the dative.These figures only take into account the verbs forwhich at least one of the SCFS were observed.
54%of the verbs listed for the dative and benefactive byLevin were not acquired with either of the targetSCFs.
Conversely, many verbs not listed in Levinwere identified as taking the benefactive or dativealternation using Lapata's criteria.
Manual analysisof these verbs revealed 18 false positives out of 52candidates.Stevenson and Merlo (1999) use syntactic and lex-ical cues for classifying 60 verbs in three verb classes:unergative, unaccusative and verbs with an optionaldirect object.
These three classes were chosen be-261threshold type thresholdmeanmedianaccuracy % num FPS num FNs0.26 60 14 230.23 63 17 17Table 3: Accuracy and error analysis for lemma based experimentscause a few well defined features, specified a pri-ori, can distinguish the three groups.
Twenty verbsfrom Levin's classification were used in each class.They were selected by virtue of having sufficient fre-quency in a combined corpus (from the Brown andthe wsJ) of 65 million words.
The verbs were alsochosen for having one predominant intended sense inthe corpus.
Stevenson and Merlo used four linguisti-cally motivated features to distinguish these groups.Counts from the corpus data for each of the four fea-tures were normalised to give a score on a scale of 1to I00.
One feature was the causative non-causativedistinction.
For this feature, a measure similar toour LO measure was used.
The four features wereidentified in the corpus using automatic POS taggingand parsing of the data.
The data for half of theverbs in each class was subject to manual scrutiny,after initial automatic processing.
The rest of thedata was produced fully automatically.
The verbswere classified automatically using the four features.The accuracy of automatic lassification was 52% us-ing all four features, compared to a baseline of 33%.The best result was obtained using a combination ofthree features.
This gave an accuracy of 66%.McCarthy and Korhonen (1998) proposed amethod for identifying rtSAS using MDL.
Thismethod relied on an estimation of the cost of us-ing TCMS to encode the argument head data at atarget slot.
The sum of the costs for the two targetslots was compared to the cost of a TCM for encodingthe union of the argument head data over the twoslots.
Results are reported for the causative alterna-tion with 15 verbs.
This method depends on therebeing similar quantities of data at the alternatingslots, otherwise the data at the more frequent slotoverwhelms the data at the less frequent slot.
How-ever, many alternations involve SCFs with substan-tially different relative frequencies, especially whenone SCF is specific to a particular preposition.
Wecarried out some experiments using the MDL methodand our TCMs.
For the causative, we used a sampleof 110 verbs and obtained 63% accuracy.
For theconative, a sample of 16 verbs was used and this timeaccuracy was only 56%.
Notably, only one negativedecision was made because of the disparate framefrequencies, which reduces the cost of combining theargument head data.6 ConclusionWe have discovered a significant relationship be-tween the similarity of selectional preferences at thetarget slots, and participation in the causative andconative alternations.
A threshold, such as the meanor median can be used to obtain a level of accuracywell above the baseline.
A lemma based similarityscore does not always indicate a significant relation-ship and generally produces a lower accuracy.There are patterns of diathesis behaviour amongverb groups (Levin, 1993).
Accuracy may be im-proved by considering severM alternations collec-tively, rather than in isolation.
Complementarytechniques to identify alternations, for example(Resnik, 1993), might be combined with ours.Although we have reported results on only twoRSAS, our method is applicable to other such alter-nations.
Furthermore, such application requires nohuman endeavour, apart from that required for eval-uation.
However, a considerably larger corpus wouldbe required to overcome the sparse data problem forother RSA alternations.7 AcknowledgementsSome funding for this work was provided by UK EP-SRC project GR/L53175 'PSET: Practical Simplifi-cation of English Text'.
We also acknowledge GeraldGazdar for his helpful comments on this paper.ReferencesBran Boguraev and Ted Briscoe.
1987.
Large lex-icons for natural language processing: Utilisingthe grammar coding system of LDOCE.
Compu-tational Linguistics, 13(3-4):203-218.Ted Briscoe and John Carroll.
1997.
Automaticextraction of subcategorization from corpora.
InFifth Applied Natural Language Processing Con-ference, pages 356-363.Ted Briscoe and Ann Copestake.
1996.
Controllingthe application of lexical rules.
In E Viegas, ed-itor, SIGLEX Workshop on Lezieal Semantics -ACL 96 Workshop.Hoa Trang Dang, Karin Kipper, Martha Palmer,and Joseph Rosensweig.
1998.
Investigating reg-ular sense extensions based on intersective Levinclasses.
In Proceedings of the 171h InternationalConference on Computational Linguistics and the36th Annual Meeting of the Association for Com-putational Linguistics, volume 1, pages 293-299.262Bonnie J. Dorr and Doug Jones.
1996.
Role of wordsense disambiguation i lexieal acquisition: Pre-dicting semantics from syntactic ues.
In Proceed-ings of the 16lh International Conference on Com-putational Linguistics, COLING-96, pages 322-327.Donald Hindle and Mats Rooth.
1993.
Structuralambiguity and lexieal relations.
ComputationalLinguistics, 19(1):103-120.Kentaro Inui, Viraeh Sornlertlamvanich, HozumiTanaka, and Takenobu Tokunaga.
1997.
A newformalization of probabilistic glr parsing.
In5th ACL/SIGPARSE International Workshop onParsing Technologies, pages 123-134, Cambridge,MA.Anna Korhonen.
1997.
Acquiring Subcategorisationfrom Textual Corpora.
Master's thesis, Universityof Cambridge.Maria Lapata.
1999.
Acquiring lexieal generaliza-tions from corpora: A case study for diathe-sis alternations.
In Proceedings of the 37th An-nual Meeting of the Association for Computa-tional Linguistics, pages 397-404.Lillian Lee.
1999.
Measures of distributional simi-larity.
In Proceedings of the 37th Annual Meetingof the Association for Computational Linguistics,pages 25-32.Geoffrey Leech.
1992.
100 million words of English:the British National Corpus.
Language Research,28(1):1-13.Beth Levin.
1993.
English Verb Classes and Alter-nations: a Preliminary Investigation.
Universityof Chicago Press, Chicago and London.Hang Li and Naoki Abe.
1995.
Generalizing caseframes using a thesaurus and the MDL principle.In Proceedings of the International Conference onRecent Advances in Natural Language Processing,pages 239-248, Bulgaria.Diana McCarthy and Anna Korhonen.
1998.
De-tecting verbal participation in diathesis alterna-tions.
In Proceedings of the 17th InternationalConference on Computational Linguistics and the36th Annual Meeting of the Association for Com-putational Linguists., volume 2, pages 1493-1495.Philip Resnik.
1993.
Selection and Information:A Class-Based Approach to Lexical Relationships.Ph.D.
thesis, University of Pennsylvania.Francesc Ribas.
1995.
On Acquiring AppropriateSelectional Restrictions from Corpora Using a Se-mantic Taxonomy.
Ph.D. thesis, University ofCatalonia.Jorma.
Rissanen.
1978.
Modeling by shortest datadescription.
Automatiea, 14:465-471.Sidney Siegel and N. John Castellan, editors.
1988.Non-Parametric Statistics for the BehaviouralSciences.
McGraw-Hill, New York.Manfred Stede.
1998.
A generative perspectiveon verb alternations.
Computational Linguistics,24(3):401-430.Suzanne Stevenson and Paola Merlo.
1999.
Au-tomatic verb classification using distributions ofgrammatical features.
In Proceedings of the NinthConference of the European Chapter of the Associ-ation for Computational Linguistics, pages 45-52.263
