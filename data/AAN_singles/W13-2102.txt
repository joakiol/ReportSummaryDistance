Proceedings of the 14th European Workshop on Natural Language Generation, pages 10?19,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsExploiting ontology lexica forgenerating natural language texts from RDF dataPhilipp Cimiano, Janna Lu?ker, David Nagel, Christina UngerSemantic Computing GroupCognitive Interaction Technology ?
Center of Excellence (CITEC),Bielefeld University, GermanyAbstractThe increasing amount of machine-readable data available in the contextof the Semantic Web creates a needfor methods that transform such datainto human-comprehensible text.
Inthis paper we develop and evaluate aNatural Language Generation (NLG)system that converts RDF data intonatural language text based on an on-tology and an associated ontology lex-icon.
While it follows a classical NLGpipeline, it diverges from most cur-rent NLG systems in that it exploitsan ontology lexicon in order to capturecontext-specific lexicalisations of ontol-ogy concepts, and combines the use ofsuch a lexicon with the choice of lexicalitems and syntactic structures based onstatistical information extracted from adomain-specific corpus.
We apply thedeveloped approach to the cooking do-main, providing both an ontology andan ontology lexicon in lemon format.Finally, we evaluate fluency and ade-quacy of the generated recipes with re-spect to two target audiences: cookingnovices and advanced cooks.1 IntroductionThe goal of the Semantic Web is to en-rich the current web by a layer of machine-readable and machine-understandable con-tent (Berners-Lee et al 2001).
In recent years,the growth of data published on the web ac-cording to Semantic Web formalisms and datamodels (e.g.
RDF(S) and OWL) has beenexponential, leading to more than 30 billionRDF triples1 available as part of the Linked1http://www4.wiwiss.fu-berlin.de/lodcloud/state/Open Data cloud, which contains a wide rangeof factual knowledge that is very interestingto many applications and for many purposes.However, due to the fact that it is available asRDF, it is not directly accessible to humans.Thus, natural language generation from RDFdata has recently become an important topicfor research, leading to the development of var-ious systems generating natural language textfrom knowledge bases (Bouayad-Agha et al2012a; Mellish and Sun, 2006; Sun and Mel-lish, 2007; Wilcock and Jokinen, 2003) as wellas corresponding shared tasks (Banik et al2012; Bouayad-Agha et al 2012b).Natural language generation (NLG) fromknowledge bases requires knowledge abouthow the concepts in the underlying ontology?individuals, classes and relations?are realisedlinguistically.
For this purpose, lemon, a lex-icon model for ontologies, has been devel-oped (McCrae et al 2011).
One of the usecases of lemon is to support natural languagegeneration systems that take as input a knowl-edge base structured with respect to a givenontology.
In this paper, we present a systemthat relies on lemon lexica for selecting suit-able lexicalisations of a given concept, showinghow ontology lexica can be exploited in a stan-dard generation architecture.We apply our system to the domain ofcooking, generating natural language texts forrecipes modeled as RDF data based on a cook-ing ontology.
Our system relies on a large textcorpus of cooking recipes that is used to ex-tract frequency information for single termsand n-grams as well as syntactic trees, whichare then used in the selection process for lex-icalisation and surface realisation.
Addition-ally, we provide a manually created lemon lex-icon for the underlying ontology that was en-riched with inflectional variants derived from10Wiktionary.
The lexicon also includes con-textual information regarding which lexicalisa-tions to prefer depending on the target group,and thereby allows our system to personalizethe output to different groups of users.
Wedemonstrate the flexibility of our system byshowing that it can be easily tuned to gen-erate recipe descriptions both for novices andfor advanced cooks and that this adaptation isclearly recognized by users.The remainder of this paper is structuredas follows.
In Section 2 we describe the re-sources we created and employed, in particulara domain ontology, a corresponding ontologylexicon enriching ontology concepts with lexi-cal information, and a parsed domain corpus.In Section 3 we describe the architecture ofthe system, in particular the use of a corpusfor selecting appropriate syntactic structuresand surface realisations of concepts.
Then wepresent the results of an extensive user studyin Section 4, compare our approach to relatedwork in Section 5 and finally give an outlookon future work in Section 6.2 Resources2.1 Domain ontology and lexiconIn order to be able to model cooking recipesas RDF data, we created a domain ontologyin which recipes are modeled comprising thefollowing information (for a similar modelingsee (Ribeiro et al 2006)):?
An indication of the number of peoplethat it serves.?
A set of ingredients used in the recipe.?
An ordered list of steps involving a certainaction (e.g.
cutting) on a set of ingredi-ents.
Each action in turn allows one ormany modifiers (e.g.
to indicate cuttinggranularity).?
Interim ingredients that are produced asthe result of some step and can be reusedlater in another step.An excerpt from the RDF recipe for mar-ble cake is given in Figure 1.
It shows twosteps, one for mixing the ingredients butter,flour and egg, using a bowl, thereby creating1 :Marmorkuchen a :Nachspeise;23 :hasStep [ a :Step ;4 :hasStepNumber 7?
?xsd:integer ;5 :hasAction action:mischen ;6 :hasMixType prop:vermengen ;7 :hasIngredient8 [ a ingredient:Butter ;9 :hasAmount amount:Gramm ;10 :hasValue "300" ],11 [ a ingredient:Mehl ;12 :hasAmount amount:Gramm ;13 :hasValue "375" ],14 [ a ingredient:Ei ;15 :hasAmount amount:Stueck16 :hasValue "5" ] ;17 :hasIndirectIngredient18 tool:Schuessel ;19 :creates tool:Marmorkuchen_Interim_120 ] ;2122 :hasStep [ a :Step ;23 :hasStepNumber 8?
?xsd:integer ;24 :hasAction action:backen ;25 :isPassive "true "?
?xsd:boolean ;26 :hasTimeUnit prop:Minute ;27 :hasTimeValue 45.0??
xsd:double ;28 :hasIngredient29 tool:Marmorkuchen_Interim_1 ;30 :hasIndirectIngredient31 tool:Backofen32 ] .Figure 1: An excerpt from the RDF recipe formarble cake.the dough as an interim object, and a subse-quent one in which this interim object is beingbaked in the oven for 45 minutes.In general, each step comprises:?
A step number indicating the order in alist of steps.?
An associated action indicating the typeof action performed in the step, e.g.
tofold in.?
One or more ingredients used in the ac-tion.
This is either an ingredient from theingredient list of the recipe, or an objectthat was created as a result of some otherstep.?
A passivity flag indicating whether a stepdoes not require an active action by thecook, e.g.
Let the cake cool for 1 hour.?
Further modifiers such as mixType indi-cating the way in which the ingredients11are mixed (e.g.
beating or folding), tem-poral modifiers specifying a time unit andtime value (e.g.
45 minutes).
These mod-ifiers later affect the grouping of steps andtheir lexicalisation.?
A flag indicating whether this is a key stepwithin the recipe, for example a step thatrequires particular care and thus shouldget emphasis in the verbalization, likeQuickly fry the meat!Overall, the ontology comprises 54 differentaction types that we used to manually model37 recipes.
Further, we created a lemon lexi-con specifying how the different actions and in-gredients specified in the ontology are verbal-ized in German.
In total the lexicon contains1,530 lexical entries, on average 1.13 lexicalvariants for each ingredient and 1.96 variantsfor each action.Figure 2 gives an example entry for theverb schneiden (to cut), specifying its partof speech, two form variants, the infinitiveand the past participle, and a semantic ref-erence to the ontology action of cutting.
Fig-ure 3 gives an excerpt from the lexical entryfor tranchieren (to carve), which refers to thesame cutting action but is restricted to caseswhere the ingredient is of type meat, modelledusing a logical condition that can be issuedas a query to the knowledge base.
This verbwould therefore only be used in the context oftechnical registers, i.e.
with advanced cooksas target group.After having manually created lexical en-tries with their base forms, we automaticallyenrich them with inflectional forms extractedfrom Wiktionary, as already indicated in Fig-ure 2.The ontology, the RDF recipes as wellas the ontology lexicon can be accessedat http://www.sc.cit-ec.uni-bielefeld.de/natural-language-generation.Although the manual creation of lemon lex-ica is feasible for small domains (and sup-ported by tools such as lemon source (McCraeet al 2012)), it does not scale to larger do-mains without a significant amount of effort.Therefore corpus-based methods for the semi-automatic creation of ontology lexica are cur-rently developed, see (Walter et al 2013).1 :schneiden a lemon:LexicalEntry ;2 lexinfo:partOfSpeech lexinfo:verb ;34 lemon:canonicalForm [5 lemon:writtenRep "schneiden"@de ;6 lexinfo:tense lexinfo:present ;7 lexinfo:mood lexinfo:infinitive8 ];9 lemon:otherForm [10 lemon:writtenRep "geschnitten"@de ;11 lexinfo:verbFormMood12 lexinfo:participle ;13 lexinfo:aspect lexinfo:perfective14 ];1516 lemon:sense17 [ lemon:reference action:schneiden ].Figure 2: Lexical entry for the verb schneiden,denoting a cutting action.1 :tranchieren a lemon:LexicalEntry ;2 lexinfo:partOfSpeech lexinfo:verb ;34 lemon:canonicalForm [5 lemon:writtenRep "tranchieren"@de ];67 lemon:sense8 [ lemon:reference action:schneiden;9 lemon:condition [ lemon:value10 "exists ?x :11 :hasIngredient (?x,?y),12 :Step(?x),13 ingredient:Fleisch (?y)" ];14 lemon:context15 isocat:technicalRegister ] .Figure 3: Lexical entry for the verbtranchieren, denoting a cutting action re-stricted to meat and marked as a technicalterm.2.2 Domain corpusIn order to build a domain corpus, we crawledthe recipe collection website http://www.chefkoch.de, which at that point containedmore than 215 000 recipes with a total amountof 1.9 million sentences.
We extracted therecipe text as well as the list of ingredients andthe specified level of difficulty ?
easy, normaland complicated.The extracted text was tokenized using theunsupervised method described by Schmid(Schmid, 2000), and for each recipe an n-gramindex (considering 2, 3 and 4-grams) for boththe recipe text and the ingredient list was con-structed.
Furthermore, 65 000 sentences wereparsed using the Stanford parser, trained on12the German TIGER corpus, also enriching thetraining data of the parser with fragments de-rived from the ontology lexicon in order to en-sure that the lexical entries in the ontologylexicon are actually covered.
This resulted in20 000 different phrase structure trees wherethe leafs were replaced by lists of all terms oc-curring at that position in the parse tree.
Bothtrees and leaf terms were stored together withthe number of their occurrences.
Leaf termswere additionally annotated with lexical sensesby comparing them to the already created lex-ical entries and thus connecting them to on-tology concepts.3 System architectureOur system implements a classical NLGpipeline comprising the following threesteps (Reiter and Dale, 2000):?
Document planning?
Microplanning?
Surface realisationDocument planning in our case is quitestraightforward as the recipes already com-prise exactly the information that needs to beverbalized.
In the following we present the tworemaining steps in more detail, followed by abrief description of how the text generation isparametrized with respect to the target group(novices or experts).3.1 MicroplanningFollowing Reiter & Dale (Reiter and Dale,2000), microplanning comprises three steps:aggregation, referring expression generation,and lexicalisation.Aggregation Aggregation serves to collapseinformation using grouping rules in order toavoid redundancies and repetitions.
In ourcase, the main goal of aggregation is to groupsteps of recipes, deciding which steps shouldbe verbalized within the same sentences andwhich ones should be separated, based on thefollowing hand-crafted rules:?
Steps are grouped if?
they have the same step number, or?
the actions associated with the stepsare the same, or?
the same ingredient is processed insubsequent actions, e.g.
peeling andchopping onions.?
Steps that are marked as important in theontology can only be grouped with otherimportant steps.?
If the grouping of steps would result in toomany ingredients to still form a readablesentence, the steps are not grouped.
Cur-rently we consider more than six ingredi-ents to be too many, as there are hardlyany trees in the corpus that could gener-ate corresponding sentences.?
If there is a big enough time differencebetween two steps, as e.g.
between bakinga cake for 60 minutes and then decoratingit, the steps are not grouped.Each of these rules contributes to a numeri-cal value indicating the probability with whichsteps will be grouped.
The use of the rules isalso controlled by a system parameter ?lengththat can be set to a value between 0 and 1,where 0 gives a strong preference to short sen-tences, while 1 always favors longer sentences.Referring expression generation Thegeneration of referring expressions is also rule-based and mainly concerns ingredients, as ac-tions are commonly verbalized as verbs andtools (such as bowls and the oven) usuallydo not re-occur often enough.
In decidingwhether to generate a pronoun, the followingrule is used: A re-occurring ingredient is re-placed by a pronoun if there is no other ingre-dient mentioned in the previous sentence thathas the same number and gender.
A systemparameter ?pronoun can be set to determine therelative frequency of pronouns to be generated.If an ingredient is not replaced by a pro-noun, then one of the following expressions isgenerated:?
A full noun phrase based on the verbal-ization given in the ontology lexicon, e.g.two eggs.?
A definite expression describing a super-category of the given ingredient.
Thesuper-category is extracted from the on-tology and its verbalization from the on-13tology lexicon.
For instance, if the ingre-dient in question is pork, the expressionmeat would be generated.?
A zero anaphora, i.e.
an empty referringexpression, as in Bake for 60 minutes orSimmer until done.The use of those variants is regulated by a sys-tem parameter ?pronoun, where a high valueforces the use of abstract expressions and zeroanaphora, while a low value prefers the useof exact ingredient names.
In future workthe decision of which referring expression touse should be decided on the basis of gen-eral principles, such as uniqueness of the refer-ent, avoidance of unnecessary and inappropri-ate modifiers, brevity, and preference for sim-ple lexical items, see, e.g., (Reiter and Dale,1992).An exception to the above rules are interimingredients, whose realisation is determined asfollows.
If there is a lexical entry for the in-terim, it is used for verbalization.
If there isno lexical entry, then the name of the mainingredient used in the creation of the interimis used.
Furthermore, we define and exploitmanually specified meaning postulates to cre-ate names for specific, common interims.
Forexample dough is used if the interim is gener-ated from flour and at least one of the ingre-dients butter, sugar, egg or backing powder.Lexicalisation In order to lexicalise actionsand ingredients, the ontology lexicon is con-sulted.
Especially for actions, the lexicon con-tains several lexical variants, usually accompa-nied by a restriction that specifies the contextin which the lexicalisation is appropriate.
Forexample the action to cut can be lexicalisedin German as hacken (to chop) if the specifiedgranularity is rough, as bla?ttrig schneiden (tothinly slice) if the specified granularity is fine,or tranchieren (to carve) in case the ingredientis of type meat.The conditions under which a lexicalisa-tion can be used felicitously are given in thelexicon as logical expressions, as exemplifiedin Figure 3 above, which are translated intoSPARQL queries that can be used to checkwhether the condition is satisfied with respectto the recipe database.In addition, we rely on statistics derivedfrom our domain corpus in order to choose alexicalisation in case the conditions of morethan one lexical variant are fulfilled, by pre-ferring terms and term combinations with ahigher frequency in the domain corpus.
Again,the system implements a parameter, ?variance,that regulates how much overall lexical vari-ability is desired.
This, however, should beused with care, as choosing variants that areless frequent in the corpus could easily lead tostrange or inappropriate verbalizations.3.2 Surface realisationThe input to the surface realisation compo-nent is a list of concepts (spanning one or morerecipe steps) together with appropriate lexical-isations as selected by the lexicalisation com-ponent.
The task of the surface realiser thenis to find an appropriate syntactic tree fromthe parsed corpus that can be used to realisethe involved concepts.
An example of such aparse tree with annotated leaf probabilities isshown in Figure 4.All trees retrieved from the index areweighted to identify the best fitting tree com-bining the following measures: i) the normal-ized probability of the syntax tree in the do-main corpus, ii) a comparison of the part-of-speech tag, synonyms and the lexical sense of agiven lexicalisation with those of the terms inthe retrieved tree, iii) the node distances of re-lated words inside each tree, and iv) an n-gramscore for each resulting sentence.
These scoresare added up and weighted w.r.t.
the size ofn, such that, for example, 4-grams have moreinfluence on the score than 3-grams.
Also,sentences with unbalanced measure, i.e.
thatscore very well w.r.t.
one measure but verypoorly w.r.t.
another one, are penalized.3.3 PersonalizationOn the basis of conditions on the context of useprovided in the ontology lexicon, it is possibleto distinguish lexicalisations that are suitablefor experts from lexical variants that are suit-able for novices.
Thus, texts can be generatedeither containing a high amount of technicalterms, in case the user has a high proficiencylevel, or avoiding technical terms at all, in casethe user is a novice.
Furthermore, the com-plexity of texts can be varied by adjusting the14S (0.005)VPVVINFschlagen (0.33)wu?rfeln (0.22)stellen (0.13).
.
.ADJDsteif (0.32)fein (0.18)kalt (0.08).
.
.NPNNSahne (0.20)Eiwei?
(0.09)Zwiebel (0.07).
.
.ARTDie (0.60)Das (0.18)Den (0.21).
.
.Figure 4: Example of a parse tree extractedfrom the corpus, annotated with leaf proba-bilitiessentence length and the number of adjectivesused.
We used this as an additional parameter?context for tailoring texts to their target group,preferring complex structures in expert textsand simple structures in texts for novices.
Theinfluence of this parameter is tested as part ofthe user study described in the next section.Personalization thus has been implementedat the level of microplanning.
In addition,personalization is possible on the level of textplanning.
For example, experts often requireless detailed descriptions of actions, such thatthey can be summarized in one step, whilethey need to be broken down into several stepsfor beginners.
This will be subject of futurework.4 EvaluationThe system was evaluated in an online studywith 93 participants?mainly students re-cruited via email or Facebook.
The major-ity of the participants (70%) were between 18and 34 years old; the native tongue of almostall participants (95%) was German.
Abouthalf of the participants regarded themselves asnovices, while the other half regarded them-selves as advanced cooks.For each participant, 20 recipes were ran-domly selected and split into two groups.
Forten recipes, test subjects were asked to ratethe fluency and adequacy of the automaticallygenerated text along the categories very good,good, sufficient and insufficient.
The other tenrecipes were used to compare the effect of pa-rameters of the generation system and thuswere presented in two different versions, vary-ing the sentence length and complexity as wellas the level of proficiency.
Participants wereasked to rate texts as being appropriate fornovices or for advanced cooks.The parameters that were varied in our ex-perimental setting are the following:?
?context: The context of the used terms, inparticular novice or advanced.?
?pronoun: Amount of proper nouns, wherea high value prefers pronouns over propernouns, while a low value generates onlyproper nouns.?
?variance: Amount of repetitions, wherelow values lead to always using the sameterm, whereas high values lead to fewerrepetitions.?
?length: Length of the created sentences,where a low value creates short sentences,and high values merge short sentencesinto longer ones.The values of these parameters that wereused in the different configurations are sum-marized in Table 1.
The parameter ?pronoun isnot varied but set to a fixed value that yieldsa satisfactory generation of referring expres-sions, as texts with smaller or higher valuestend to sound artificial or incomprehensible.
?context ?pronoun ?variance ?lengthStandard novice 0.5 0.5 0.5Novice vs novice 0.5 0.5 0.3Advanced advanced 0.5 0.5 0.7Simple vs novice 0.5 0.0 0.3Complex novice 0.5 1.0 0.7Table 1: The used parameter setsFluency and adequacy of the generatedtexts Each participant was asked to rate flu-ency and adequacy of ten automatically gen-erated texts.
The results are given in Figures5 and 6.
The fluency of the majority of gen-erated texts (85.8%) were perceived as verygood or good, whereas only 1% of the generatedtexts were rated as insufficient.
Similarly, theadequacy of 92.5% of the generated texts wererated as very good or good, and again only 1%of the generated texts were rated as insuffi-cient.
There was no significant difference be-tween judgments of novices and experts; nei-ther did the category of the recipe (main or15side dish, dessert, etc.)
have any influence.Overall, these results clearly show that thequality of the texts generated by our systemis high.Figure 5: Results for text fluencyFigure 6: Results for text adequacyError analysis The most frequent errorsfound in the generated texts can be groupedinto the following categories:?
Content (39.4%): Errors in documentplanning (e.g.
due to the ontology miss-ing details about tools, such as for cut-ting cookies, or the recipe missing infor-mation about the amount of ingredients)or aggregation (e.g.
sentences with highlyrelated content were not aggregated), aswell as sentence repetitions.?
Language (29.4%): Errors in the re-ferring expression generation or lexicali-sation steps (e.g.
wrong use of functionwords like as well) and grammar errors(e.g.
wrong use of definite or indefinitedeterminers).?
Other (31.3%): Some users specifiedthat they would prefer another orderingof the involved steps, or that they lackknowledge of particular terms.
Also shortsentences with exclamation marks are of-ten perceived as impolite.Influence of parameter settings We setup the following hypotheses, validating themby means of a ?2-test by comparing answersacross two conditions corresponding to differ-ent parameter settings.
We regarded a p-valueof 0.05 as sufficient to reject the correspondingnull hypothesis.H1 Users prefer longer sentences: Re-jecting the null hypothesis that users ratetexts with longer sentences and texts withshorter sentences in the same way (p-value: 3 ?
10?5).H2 Texts for professionals are regardedas not suitable for novices: Reject-ing the null hypothesis that texts gen-erated for professionals are regarded asmany times as suitable for novices as forprofessionals (p-value: 2 ?
10?7).H3 Beginners prefer texts generatedfor novices: The null hypothesis thatnovices equally prefer texts targeted tonovices and texts targeted to expertscould not be rejected.H4 Advanced cooks prefer texts gener-ated for advanced cooks: Rejectingthe null hypothesis that advanced cooksequally prefer texts targeted to novicesand texts targeted to experts (p-value:0.0005).The confirmation of H1 shows that users per-ceive a difference in sentence length and pre-fer texts with longer sentences, probably dueto perceived higher fluency.
The confirmationof H2 and H4, on the other hand, corrobo-rates the successful adaptation of the gener-ated texts to specific target groups, showing16that texts generated for professionals are in-deed perceived as being generated for profes-sionals, and that such texts are preferred byadvanced cooks.
The rejection of H3 mightbe caused by the fact that recipes for ad-vanced cooks include some but actually notmany technical terms and are therefore alsocomprehensible for novices.5 Related workThere have been different approaches tonatural language generation, ranging fromtemplate-based to statistical architectures.While early NLG systems were mainly basedon manually created rules (Bourbeau et al1990; Reiter et al 1992), later approachesstarted applying statistical methods to thesubtasks involved in generation (Belz, 2005),focusing on scalability and easy portabilityand often relying on overgeneration and sub-sequent ranking of generation possibilities.Personalization has been a concern in bothstrands of research.
PEBA-II (Milosavljevicet al 1996), for example, generates target-group-specific texts for novice and expertsusers from taxonomical information, relyingon a phrasal lexicon that is similar in spirit toour ontology lexicon.
Statistical approachessuch as (Isard et al 2006), on the otherhand, use text corpora to generate personal-ized texts.Our approach is hybrid in the sense that itenriches a classical rule-based approach withstatistical data in the microplanning and reali-sation steps, thus being comparable to systemslike HALogen (Langkilde and Knight, 1998)and pCRU (Belz, 2008).
The main differenceis that it uses Semantic Web data as base.Since the emergence of the Semantic Webthere has been a strong interest in NLGfrom Semantic Web data, especially for pro-viding users with natural language access tostructured data.
Work in this area com-prises verbalization of ontologies as well asRDF knowledge bases; for an overview see(Bouayad-Agha et al to appear).
Of par-ticular interest in the context of our work isNaturalOWL (Galanis and Androutsopoulos,2007), a system that produces descriptions ofentities and classes relying on linguistic anno-tations of domain data in RDF format, similarto our exploitation of ontology lexica.
We thusshare with NaturalOWL the use of linguis-tic resources encoded using standard SemanticWeb formats.
The main difference is that theannotations used by NaturalOWL comprisenot only lexical information but also micro-plans for sentence planning, which in our caseare derived statistically and represented out-side the lexicon.
Separating lexical informa-tion and sentence plans makes it easier to usethe same lexicon for generating different formsof texts, either with respect to specific targetgroups or stylistic variants.6 Conclusion and future workWe have presented a principled natural lan-guage generation architecture that follows aclassical NLG architecture but exploits an on-tology lexicon as well as statistical informationderived from a domain corpus in the lexicali-sation and surface realisation steps.
The sys-tem has been implemented and adapted to thetask of generating cooking recipe texts on thebasis of RDF representations of recipes.
In anevaluation with 93 participants we have shownthat the system is indeed effective and gener-ates natural language texts that are perceivedas fluent and adequate.
A particular featureof the system is that it can personalize thegeneration to particular target groups, in ourcase cooking novices and advanced cooks.
Theinformation about which lexicalisation to pre-fer depending on the target group is includedin the ontology lexicon.
In fact, the ontologylexicon is the main driver of the generationprocess, as it also guides the search for ap-propriate parse trees.
It thus is a central andcrucial component of the architecture.While the system has been adapted to theparticulars of the cooking domain, especiallyconcerning the generation of referring expres-sions, the architecture of the system is fairlygeneral and in principle the system could beadapted to any domain by replacing the on-tology, the corresponding ontology lexicon andby providing a suitable domain corpus.
Thisflexibility is in our view a clear strength of oursystem architecture.A further characteristic of our system is theconsistent use of standards, i.e.
OWL forthe ontology, RDF for the actual data to be17verbalized, SPARQL for modelling contextualconditions under which a certain lexicalisa-tion is to be used, and the lemon format forthe representation of the lexicon-ontology in-terface.
One important goal for future workwill be to clearly understand which knowledgean ontology lexicon has to include in orderto optimally support NLG.
To this end, weintend to test the system on other domains,and at the same time invite other researchersto test their systems on our data, availableat http://www.sc.cit-ec.uni-bielefeld.de/natural-language-generation.AcknowledgmentThis work was partially funded within the EUproject PortDial (FP7-296170).ReferencesE.
Banik, C. Gardent, D. Scott, N. Dinesh, andF.
Liang.
2012.
KBGen: text generation fromknowledge bases as a new shared task.
In Proc.Seventh International Natural Language Gener-ation Conference (INLG 2012), pages 141?145.A.
Belz.
2005.
Statistical generation: Three meth-ods compared and evaluated.
In Proc.
10th Eu-ropean Workshop on Natural Language Genera-tion (ENLG ?05), pages 15?23.A.
Belz.
2008.
Automatic generation of weatherforecast texts using comprehensive probabilisticgeneration-space models.
Natural Language En-gineering, 14(4):431?455.T.
Berners-Lee, J. Hendler, and O. Lassila.
2001.The Semantic Web.
Scientific American Maga-zine.N.
Bouayad-Agha, G. Casamayor, S. Mille,M.
Rospocher, H. Saggion, L. Serafini, andL.
Wanner.
2012a.
From ontology to NL: Gener-ation of multilingual user-oriented environmen-tal reports.
In Proc.
17th International Confer-ence on Applications of Natural Language Pro-cessing to Information Systems (NLDB 2012),pages 216?221.N.
Bouayad-Agha, G. Casamayor, L. Wanner, andC.
Mellish.
2012b.
Content selection from Se-mantic Web data.
In Proc.
Seventh Interna-tional Natural Language Generation Conference(INLG 2012), pages 146?149.N.
Bouayad-Agha, G. Casamayor, and L. Wanner.to appear.
Natural Language Generation in thecontext of the Semantic Web.
Semantic WebJournal.L.
Bourbeau, D. Carcagno, E. Goldberg, R. Kit-tredge, and A. Polgue`re.
1990.
Bilingual gener-ation of weather forecasts in an operations en-vironment.
In Proc.
13th International Con-ference on Computational Linguistics (COLING1990), pages 318?320.D.
Galanis and I. Androutsopoulos.
2007.
Gen-erating multilingual descriptions from linguis-tically annotated OWL ontologies: the Nat-uralOWL system.
In Proc.
11th EuropeanWorkshop on Natural Language Generation(ENLG ?07), pages 143?146.A.
Isard, C. Brockmann, and J. Oberlander.
2006.Individuality and alignment in generated dia-logues.
In Proc.
Fourth International NaturalLanguage Generation Conference (INLG 2006),pages 25?32.I.
Langkilde and K. Knight.
1998.
Generation thatexploits corpus-based statistical knowledge.
InProc.
17th International Conference on Compu-tational Linguistics (COLING ?98), pages 704?710.J.
McCrae, D. Spohr, and P. Cimiano.
2011.Linking lexical resources and ontologies on thesemantic web with lemon.
In Proc.
8th Ex-tended Semantic Web Conference on The Se-mantic Web: Research and Applications (ESWC2011), pages 245?259.J.
McCrae, E. Montiel-Ponsoda, and P. Cimiano.2012.
Collaborative semantic editing of linkeddata lexica.
In Proceedings of the 2012 Inter-national Conference on Language Resource andEvaluation.C.
Mellish and X.
Sun.
2006.
The Semantic Webas a linguistic resource: Opportunities for nat-ural language generation.
Knowl.-Based Syst.,19(5):298?303.M.
Milosavljevic, A. Tulloch, and R. Dale.
1996.Text generation in a dynamic hypertext environ-ment.
In Proc.
19th Australian Computer Sci-ence Conference, pages 417?426.E.
Reiter and R. Dale.
1992.
A fast algorithm forthe generation of referring expressions.E.
Reiter and R. Dale.
2000.
Building naturallanguage generation systems.
Cambridge Uni-versity Press.E.
Reiter, C. Mellish, and J. Levine.
1992.
Au-tomatic generation of on-line documentation inthe IDAS project.
In Proc.
Third Conference onApplied Natural Language Processing (ANLP),pages 64?71.R.
Ribeiro, F. Batista, J.P. Pardal, N.J. Mamede,and H.S.
Pinto.
2006.
Cooking an ontology.
InProceedings of the 12th international conferenceon Artificial Intelligence: methodology, Systems,18and Applications, AIMSA?06, pages 213?221.Springer.Helmut Schmid.
2000.
Unsupervised learning ofperiod disambiguation for tokenisation.
Techni-cal report, IMS-CL, University of Stuttgart.X.
Sun and C. Mellish.
2007.
An experiment on?free generation?
from single RDF triples.
InProc.
11th European Workshop on Natural Lan-guage Generation (ENLG ?07), pages 105?108.S.
Walter, C. Unger, and P. Cimiano.
2013.
Acorpus-based approach for the induction of on-tology lexica.
In Proceedings of the 18th Inter-national Conference on the Application of Nat-ural Language to Information Systems (NLDB2013).G.
Wilcock and K. Jokinen.
2003.
Generating re-sponses and explanations from RDF/XML andDAML+OIL.
In Knowledge and Reasoning inPractical Dialogue Systems, IJCAI 2003 Work-shop, pages 58?63.19
