SESS ION 5: NATURAL LANGUAGE,  D ISCOURSEPaul S. Jacobs, ChairIn format ion Technology LaboratoryGE Research and Deve lopment  CenterSchenectady,  NY 12301OVERVIEW AND BACKGROUNDThe papers in this group cover a broad range of topicsfrom different perspectives.
They have in common anemphasis on the handling of frequently-occurring phe-nomena in real data sets of spoken and written language,phenomena which are in some sense outside of the scopeof some of the core problems in human language tech-nologies.
We can view problems uch as acoustic process-ing, word recognition, sentence parsing, and word sensedisambiguation as core problems because they have awealth of published literature and a set of broadly ap-plied techniques.
By contrast, the natural anguage pa-pers in this session hit upon issues like recognizing speechrepairs and designing "templates" to capture informa-tion and test text understanding.
These issues are alsocentral to HLT work, but have certainly not evolved intomature practices.Within this general framework, three of the papers ad-dress written language work, including template designand processing methods, while the remaining two pa-pers are on spoken language work, including repairs andintonation.The two speech papers represent innovative work doneindependently in universities, while the three writtenlanguage papers are part of a community effort to de-velop and evaluate systems for extracting data fromfree text, and are all thus all directly related to theARPA-funded TIPSTER program.
The two speech pa-pers, therefore, are quite self-standing.
However, to ap-preciate the three written language papers, it helps tohave a general understanding of TIPSTER data extrac-tion and why, for example, some of the themes of thesepapers, such as template design and linguistic motiva-tion, are important.
Therefore, we will first consider thethree written language papers here, then turn to the twospeech papers.T IPSTER DATA EXTRACTIONThe TIPSTER (Phase 1) data extraction project, span-ning roughly a two-year period from 1991-1993, aimedto expand the state of the art in coverage and accu-racy in data extractior\[ techniques--systems that derivestructured information from free text, to support "down-stream" text applications such as database retrieval,trend analysis, question answering, and so on.
TIPSTERPhase 2, which focuses on a common, sharable architec-ture for such systems along with continuing algorithmdevelopment, is just beginning.In TIPSTER Phase 1, data extraction systems howedthe ability to cover broad ranges of text in two domains(joint ventures and microelectronics) and two languages(English and Japanese), with accuracy comparable tohow similar programs had done a year earlier on mucheasier tasks in a single language and domain.
The pro-gram thus made considerable progress in scale-up andportability, which were its key goals.
In addition, theTIPSTER-sponsored evaluations, including the recentMUC-5 message understanding conference, provided atestbed in which many other sites were able to partici-pate and compare approaches.The papers by Boyan Onyshkevych, "Issues and Method-ology for Template Design for Information Extraction",and by Jerry Hobbs and David Israel, "Principles ofTemplate Design", discuss the infrastructure withinwhich work in data extraction is conducted.
The dataextraction task generally uses a corpus of texts, a tem-plate design reflecting both the domain of knowledge andthe information to be extracted, and some examples ofcorrectly-filled templates for training.
Two particularlyimportant criteria of template design help to make suchwork successful: (1) the design must be expressive andgeneral enough so that a system that can do a good jobat filling a particular template can be used successfullyin new, real applications, and (2) the design must beboth rich and intuitive, so that the task reveals interest-ing characteristics of different methods without makinga lot of extra work for researchers.
The infrastructureissues presented in these papers, therefore, are essentialfor progress in the field.The paper by Damaris Aynso and the BBN PLUM Re-search Group, "Pattern-Matching in a Linguistically Mo-tivated Text-Understanding System" summarizes some169of BBN's efforts in TIPSTER, but also gives a good per-spective on some of the results of ARPA-sponsored re-search in data extraction.
As the paper points out, someof the most successful efforts in data extraction havegradually dispensed with traditional inguistic knowl-edge (such as the largest and most powerful gram-mars) and relied more heavily on pattern matching andlexically-organized knowledge.
This trend has been go-ing oll for several years and has been reported, partic-ularly by GE and SRI, in previous ARPA workshops.Lexically-oriented pattern matching is particularly goodat quickly capturing the domain and corpus knowledgethat is required for data extraction.
The BBN papersuggests that pattern matching and linguistic knowledgework best together, a claim that would seem to be sup-ported by the fact that systems like SRI's and GE's bothuse pattern matching as an approximation to more pow-erful analysis.
BBN's system, by contrast, still includesa more traditional grammatical component.SPEECH REPAIRS  ANDINTONATION"Tagging Speech Repairs" by Peter Heeman and JamesAllen, addresses a critical issue in processing real spo-ken dialogues--that recognizing and correcting repairs,which are frequent in real speech, is necessary to pro-cess and understand many spoken inputs.
The noveltyof this work is that it relies heavily on a part-of-speechtagger, combining a variety of cues to spot and correctthe repairs.
The results reported, for both recogniti?nand correction, are quite good.
However, the discus-sion of the paper at the HLT meeting did raise someof the problems with comparing results of different sys-tems and approaches on different data sets; for example,related work by Nakatani and Hirschberg used acousticinformation only and tested only on examples that in-cluded repairs, and did only recognition, not correction.This raises the question of how these different approachescould be effectively compared and even combined.
"Information Based Intonation Synthesis" by ScottPrevost and Mark Steedman uses a rich linguisticmodel to account for problems with contrastive stressin dialogues--cases where the simple traditional rule,that previously-mentioned word are de-accented, breaksdown.
Although the results of this work so far are morelimited and anecdotal than the other papers in this ses-sion, the approach shows promise for covering a broaderrange of examples of stress and intonation.170
