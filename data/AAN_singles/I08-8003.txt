AbstractThis paper presents a technique fortransliteration based directly on techniquesdeveloped for phrase-based statisticalmachine translation.
The focus of our workis in providing a transliteration system thatcould be used to translate unknown wordsin a speech-to-speech machine translationsystem.
Therefore the system must  be ableto generate arbitrary sequence of charactersin the target language, rather than wordschosen from a pre-determined vocabulary.We evalauted our method automaticallyrelative to a set of human-annotatedreference transliterations as well as byassessing it  for correctness using humanevaluators.
Our experimental resultsdemonstrate that for both transliterationand back-transliteration the system is ableto produce correct, or phoneticallye q u i v a l e n t t o c o r r e c t o u t p u t  i napproximately 80% of cases.1 IntroductionDictionaries and corpora are only able to cover acertain proportion of language.
Those words andphrases that are unknown to a translator/machinetranslation system present  a problem.
Examples ofsuch words include people?s names, place names,and technical terms.
One solution to the problem isto transcribe the source language and use thetranscription directly in the target language.Usually these transcrptions will be phoneticallysimilar.
This process of transcription is known astransliteration and in this paper we will present  atechnique for automatically transliterating betweenEnglish and Japanese, although the technique isgeneral and is able to be appied directly to otherlanguage pairs.
Of particular interest  to us is theappl icat ion of such a sys tem within aspeech-to-speech machine translation (MT)system.
Typically words not seen by the MTsystem, known as out of vocabulary words(OOVs), are either left  untranslated or simplyremoved from the output.
Common examples ofOOVs are named entities such as personal names,place names and technical terms, unknownoccurences of which could benefit from beingtransliterated into the MT  system?s output duringtranslation between Japanese and English.Moreover, in the case of a transation system thattranslates directly to speech, the transliterationsystem does not  necessarily need to produce thecorrect transliteration as any one of a set ofphonetically equivalent alternatives would beequally acceptable.1.1 English-Japanese TransliterationIn Japanese there are three separate alphabets,kanji (the Chinese character set), hiragana  (used asan alternative to the kanji, and to expressfunctional elements such as particles etc.)
andkatakana (used to express foreign loan words, andrelatively new words in the language, for example?karaoke?).
Figure 1 shows some examples, thefirst  line is the English source, the second line isthe Japanense and the last line is a directtranscription of the Japanese katakana into theroman alphabet with spaces delimiting thecharacter boundaries.
As can be seen from theexamples, transliteration is not a straghtforwardprocess.
Example 1 of Figure 1 shows an exampleof a transliteration which is a reasonably directphonetic transfer.
The word ?manga?
in English isa loan word from Japanese and has more-or-lessthe same pronunciation in both languages.
InExample 2 we have an ambiguity, the ?aa?
at theend of the word kompyutaa, corresponds to thePhrase-based Machine TransliterationAndrew FinchNiCT-ATR?Keihanna Science City?Kyoto, JAPANandrew.finch@atr.jpEiichiro SumitaNiCT-ATR?Keihanna Science City?Kyoto, JAPANeiichiro.sumita@atr.jp?er?
of ?computer?.
However, although incorrectthe sequences kompyuta or kompyuuta are alsoplausible transliterations for the word.
Example 4shows a contraction.
The English word has beentransfered over into Japanese, and then shortened.In this case ?personal?
has been shortened to pasoand ?computer?
has been contracted into con.
InExample 4 the Japanese loan word has come froma language other than English, in this case French,and these words are usually transliteratedaccording to the pronunciation in their nativelanguage.
In Example 5, the etymology is quitecomplex.
The word has entered the language fromthe Portugese for ?English?
: inglese, but has cometo mean ?Great Britain?.
Example 6 is a creativemodern mixture of an imported loan word ero  acontraction of the transliteration erochikku of theEnglish word ?erotic?, concatenated with acontraction of the Japanese word kawaii (usuallywritten in kanji/kana) meaning ?cute?.
Not  only isthe English phrase phonetically unrelated in thiscase, but  the expression is difficult  to translatewithout  using a number of English words since itrepresents quite a lot of information.2 Related Work2.1 Machine TransliterationThis paper is directly related to an important paperby Knight  and Graehl (1996).
Their transliterationsystem was also evaluated by English-Japanese(back-)transliteration performance.
Our systemdiffers from theirs in a number of aspects.
Themost important  of which is that their systemoutputs word sequences whereas our systemoutputs character sequences in the target language.The difference reflects the intended application ofthe transliteration system.
Their system wasintended to transliterate from the output  of an OCRsystem, and must  therefore be robust  to errors inthe input, whereas our system has been developedwith machine translation in mind, and the input  toour system is likely to consist of out-of-vocabularywords.
This flexibility is a double-edged sword inthat: on the one hand our system is able to handleOOVs; whereas on the other hand our system isfree to generate non-words.
A second differencebetween the approaches is that, Knight andGraehl?s model models the pronunciation of thesource word sequences using a pronunciationdictionary in an intermediate model.
Our systemtransforms the character sequence from onelanguage into another in a subword-level charactersequence-based manner.
Our systems relies on thethe system being able to implicitly learn the correctcharacter-sequence mappings through the processof character alignment.
Our system is also able tore-order the translated character sequences in theoutput.
The system can be easily constrained togenerate the target  in the same order as the sourceif necessary, however, often in Japanese names(including foreign names) are written with thefamily name first, therefore for the purposes of ourexperiments we allow the system to performreordering.2.2 Phrase-based Stat ist ical  MachineTranslation (SMT)Our approach couches the problem of machinetransliteraion in terms of a character-leveltranslation process.
Character-based machinetranslation has been proposed as a method toovercome segmention issues in natural languagecomputer?????
?ko n pi yu taa2personal computer???
?pa so ko n3bread?
?pa n4Figure 1: Example English-Japanese Transliterationsmanga??
?ma n ga1Great Britain???
?i gi ri su5cute but still sexy???
?e ro ka wa6processing (Denoual and Lepage, 2006) andcharacter-based machine translation systems havealready been developed on these principles(Lepage and Denoual, 2006).
Our system alsotakes a character-based approach but  restricts itselfto the translation of short phrases.
This is to ouradvantage because machine translation systemsstruggle in the translation of longer sequences.Moreover, the process of transliteration tends to bea monotone process, and this assists us further.
Wewill give only a brief overview of the process ofphrase-based machine translation, for a fulleraccount of statistical machine translation we referthe reader to (Brown et  al., 1991) and (Koehn,Och, and Marcu, 2003).During the process of phrase-based SMT thesource sequence is segmented into sub-sequences ,each sub-sequence being translated using bilingualsequence pairs (called phrase pairs when thetranslation proceeds at the word-level).
The targetgeneration process (for English-to-Japanese) at  thecharacter level is illustrated in Figure 3.
Theexample is a real system output  from an unseenphrase.
The source sequence is segmented by thesystem into three segments.
The translations ofeach of these segments have been gleaned fromalignments of these segments where they occur inthe training corpus.
For example ?machine?????
may have come from the pair ?Turingmachine??????????
(chi yuu ri n guma chi n)?
that is present in the Wikipediacomponent  of the training corpus.
The  ?slation?
inthis example certainly came from the film title?Lost in Translation?
since the Japanese translationof the English word ?translation?
is usually writtenin kanji.3 Experimental Methodology3.1 Experimental DataThe data for these experiments was taken from thepublicly available EDICT  dictionary (Breen, 1995)together with a set  of katakana-English phrasepairs extracted from inter-language links in theWikipedia1.
These phrase pairs were extracted in asimilar fashion to (Erdmann, et  al., 2007) who usedthem in the construction of a bilingual dictionary.An inter-language link is a direct link from anarticle in one language to an article in another.Phrase-pairs are extracted from these links bypairing the titles of the two articles.
We collectedonly phrase pairs in which the Japanese sideconsisted of only katakana and the English sideconsisted of only ASCII characters (thusdeliberately eliminating some foreign language?English?
names that  would be hard to transliteratecorrectly).
Data from both sources was combinedto make a single corpus.
Thus corpus was thenrandomly sub-divided into training (33479 phrasepairs), development  (2000 phrase pairs) andevaluation (2000 phrase pairs) sub-corpora.
For thehuman evaluation a sample of 200 phrase-pairswas chosen randomly from the test corpus.
Inaddition a small corpus of 73 US politicians?names was collected from a list of US presidentsand vice presidents in the Wikipedia.
Duplictateentries were removed from this list and the trainingset was also filtered to exclude these entries.3.2 Back-transliteration AccuracyFollowing Knight and Graeh (1996), we evaluatedour system with respect to back-transliterationperformance.
That is, word sequences in katakanawere used to generate English sequences.
As apoint  of reference to the results in this paper, weback-transliterated a list  of American polititians?names.
The results are shown in Table 1.
Thenumber of exacty correct  results is lower than thesystem of Knight and Graehl, but the total numberof correct  + phonetically equivalent  results is aboutthe same.
This can be explained by the fact that oursystem is able to generate character sequencesmore freely in order to be able to handle unknownwords .
A l toge the r a round 78% o f t heback-transliterations were judged either correct orphonetically equivalent to a correct  result.
Weincluded a class to respesent those results that werenot equivalent in terms of English phonology but1http://www.wikipedia.orgFigure 3: The phrase-translation processmachine??
?ma shi ntran??
?to ra nslation?????
?su ree shi yo nmachine translationwere ?reasonable errors?
in terms of Japanesephonology, for example ?James Polk?
wasback-transliterated as ?James Pork?, the ?r?
and ?l?sound being hard to discrimitate in Japanesebecasue the two sounds are combined into a singlesound.
The reason for making this distinction wasto identify the proportion (around 10%) of morepathological errors caused by errors such asincorrect phrase pairs extracted due to erroneaousword alignments.3.3 Human AssessmentFigure 2 shows the results of the humanevaluation.
Transliterated text  from English toJapanese was graded by a professional translatorwho was fluent  in both languages but native inJapanese.
Conversely the back-transliteratedphrases were judged by a native English-speakingtranslator who was also fluent in Japanese.
Theevaluation data was graded into 4 categories:(1) The transliteration or back-transliterationwas correct.
(2) The transliteraton was not correct  howeverthe result  was phonetically equivalent to acorrect result.
(3) The transliteration or back-transliterationwas incorrect.
(4) The annnotator was unsure of the correctgrade for that example.Transliteration examples:Grade 1:  worm gear ?
u oo mu gi yaGrade 2:  worm gear ?
waa mu gi aGrade 3: marcel desailly ?
ma ru se ru de sa iriGrade 4: agnieszka holland ?
?Figure 2: Human Judgement of Quality Transliteration Performance and Wikipedia Data0255075100EN?JA JA?EN EN?JA JA?ENMachineWikipediaProportionofData(%)Incorrect Don?t knowPhonetically correct Correct582218.5875.567715.55.5571710.515.5Correct 57.53%Phonetically equivalent (EN) 20.54%Phonetically equivalent (JA) 10.96%Incorrect 10.96%Table 1: Back-transliteration performance onpoliticians?
namesThe example of Grade 1 is the Wikipedia entry andis the normal way of expressing this phrase inJapanese.
The Grade 2 example is output from oursystem, the pronunciation of the string is almostthe same as the Grade 1 version, however the formof expression is unusual.
The Grade 3 example isalso a system output.
Here the system has made areasonable attempt  at  generating the katakana, buthas transliterated it in terms of the Englishpronunciation rather than the French from whichthe name dervies.
The correct  transliteration fromthis name would be: ma ru se ru de sa ii.
Thisproblem has been caused by the nature of thetraining data which contains mainly Englishexpressions.
The word ?desailly?
had not  occurredin the training data.The results reveal several things about the data, thetask and the system performance.
Looking at  thescoring of the Wikipedia data, there is a reasonablelevel of disagreement  between the two annotators,but the overall number of pairs judged as correct(back-)transliterations is nonetheless reasonablyhigh; in the 80-90% range.
Secondly, theannotators judged the quality of the transliterationand back- t rans l i t e ra t ion sys tems to beapproximately the same.
We found this resultsurprising since the English generation, intuitivelyat  least, appears to be harder than Japanesegeneration because there are fewer constraints ongraphemic structure.
The most significant result  isthat the number of cases labelled ?correct?
or?phonetcially equivalent to a correct  result?
wasaround 80% for both systems, which should behigh enough to allow the system to be used in aspeech translation system, especially since byvisual inspection of the data, many of the the?incorrect?
results were near misses that  would beeasy for a user of the system to understand.
Forexample the transliteraton ko-roo-ra for ?Corolla?was judged correct, however ko-ro-ra was judgedincorrect and not phonetically equivalent.3.4 Assement using automatic machinetranslation evaluation methodsTable 2 shows the results from evaluating theoutput of our t ransl i terat ion and back-transliteration systems according to a range ofcommonly-used automatic machine translationscoring schemes.
We believe these techniques arean effective way to evaluate transliteration quality,and are therefore provided here as a reference.
Thedifference between the WER and PER scores isinteresting here as the WER score takes sequenceorder into account when comparing to a referencewhereas  PER does not.
There is a larger differencewhen the target  is English indicating that thisprocess has more issues related to character order.4 Conclusion and Future DirectionsThis paper has demonstrated that transliterationcan be done effectively by a machine translationsystem, and has quantified this empirically.
It isclear that by leaving the system ?open?
and free togenerate any sequence of characters in the targetlanguage there is a price to pay since the system isable to generate non-words.
On the other hand,restricting the system so that  it is only able to gen-erate words is for many applications unrealistic,and in particular it  is necessary for the speechtranslation application this system has been devel-oped for.
Our results show that  our system gener-ates correct  or phonetically correct transliterationsaround 80% of the time.
This figure serves as alower bound estimate for the proportion of practi-cally useful transliterations it will produce.
Perhapsa compromise between these two approaches canbe achieved by introducing a lexically-based lan-guage model into the system in addition to the ex-isting high-order character-based language model.Furthermore, we are also interested in investigatingthe use of the models generated by training oursystem in the process of word alignment for statis-tical machine translation, and as a precursor to thisthe models might be used in filtering the trainingdata in a pre-processing stage.
Lastly it  is impor-BLEU NIST WER PER GTM METEOR TEREN?JAJA?EN0.627 9.17 0.31 0.29 0.8 0.81 30.670.682 10.023 0.277 0.237 0.83 0.81 27.14Table 2: System performance according to automatic machine translation scoring schemestant to mention that Wikipedia (which provided uswith most  of our corpus), is growing very rapidly,and considerably more training data for statisticaltransliteration systems should be available in thenear future.ReferencesJ.W.
Breen.
1995.
Building an electronic Japanese-English dictionary.
Japanese Studies Association ofAustralia Conference.
Queensland, Australia.Peter Brown, S. Della Pietra, V. Della Pietra, and R.Mercer (1991).
The mathematics of statistical ma-chine translation: parameter estimation.
Computa-tional Linguistics, 19(2), 263-311.Etienne Denoual and  Yves Lepage.
2006.
The characteras an appropriate unit of processing for non-segmenting languages, Proceedings of the 12th An-nual Meeting of The Association of NLP, pp.
731-734.Maike Erdmann, Kotaro Nakayama, Takahiro Hara,andShojiro Nishio.
2007.
Wikipedia Link StructureAnalysis for Extracting Bilingual Terminology.IEICE Technical Committee on Data Engineering.Miyagi, Japan.Kevin Knight and Jonathan Graehl.
1997.
MachineTransliteration.
Proceedings of the Thirty-Fifth An-nual Meeting of the Association for ComputationalLinguistics and Eighth Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pp.
128-135, Somerset, New Jersey.Yves Lepage and Etienne Denoual.
2006.
Objectiveevaluation of the analogy-based machine translationsystem ALEPH.
Proceedings of the 12th AnnualMeeting of The Association of NLP, pp.
873-876.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical Phrase-Based Translation.
In Pro-ceedings of the Human Language Technology Con-ference 2003 (HLT-NAACL 2003), Edmonton, Can-ada.
