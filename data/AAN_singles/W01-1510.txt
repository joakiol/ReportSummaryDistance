Resource sharing among HPSG and LTAG communitiesby a method of grammar conversion from FB-LTAG to HPSGNaoki Yoshinaga Yusuke MiyaoDepartment of Information Science, Graduate school of Science, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo, 113-0033, Japanfyoshinag, yusukeg@is.s.u-tokyo.ac.jpKentaro TorisawaSchool of Information Science, Japan Advanced Institute of Science and TechnologyAsahidai 1-1, Tatsunokuchi-cho, Noumi-gun, Ishikawa, 923-1292, JapanInformation and Human Behavior, PRESTO, Japan Science and Technology CorporationKawaguchi Hon-cho 4-1-8, Kawaguchi-shi, Saitama, 332-0012, Japantorisawa@jaist.ac.jpJun?ichi TsujiiDepartment of Computer Science, Graduate school of Information Science and Technology, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo, 113-0033, JapanCREST, JST (Japan Science and Technology Corporation)Kawaguchi Hon-cho 4-1-8, Kawaguchi-shi, Saitama, 332-0012, Japantsujii@is.s.u-tokyo.ac.jpAbstractThis paper describes the RenTAL sys-tem, which enables sharing resourcesin LTAG and HPSG formalisms by amethod of grammar conversion froman FB-LTAG grammar to a stronglyequivalent HPSG-style grammar.
Thesystem is applied to the latest versionof the XTAG English grammar.
Ex-perimental results show that the ob-tained HPSG-style grammar success-fully worked with an HPSG parser, andachieved a drastic speed-up against anLTAG parser.
This system enables toshare not only grammars and lexiconsbut also parsing techniques.1 IntroductionThis paper describes an approach for shar-ing resources in various grammar formalismssuch as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG1) (Vijay-Shanker, 1987;Vijay-Shanker and Joshi, 1988) and Head-DrivenPhrase Structure Grammar (HPSG) (Pollard andSag, 1994) by a method of grammar conver-sion.
The RenTAL system automatically convertsan FB-LTAG grammar into a strongly equiva-lent HPSG-style grammar (Yoshinaga and Miyao,2001).
Strong equivalence means that both gram-mars generate exactly equivalent parse results,and that we can share the LTAG grammars andlexicons in HPSG applications.
Our system canreduce considerable workload to develop a hugeresource (grammars and lexicons) from scratch.Our concern is, however, not limited to thesharing of grammars and lexicons.
Stronglyequivalent grammars enable the sharing ofideas developed in each formalism.
Therehave been many studies on parsing tech-niques (Poller and Becker, 1998; Flickinger etal., 2000), ones on disambiguation models (Chi-ang, 2000; Kanayama et al, 2000), and oneson programming/grammar-development environ-1In this paper, we use the term LTAG to refer to FB-LTAG, if not confusing.LTAG ResourcesGrammar:Elementary treetemplatesLexiconType hierarchyextractorTreeconverterLexiconconverterRenTAL SystemHPSG ResourcesGrammar:Lexical entrytemplatesLexiconLTAG parsers HPSG parsersDerivation trees Parse treesDerivationtranslatorLTAG-based applicationHPSG-based applicationFigure 1: The RenTAL System: Overviewment (Sarkar and Wintner, 1999; Doran et al,2000; Makino et al, 1998).
These works are re-stricted to each closed community, and the rela-tion between them is not well discussed.
Investi-gating the relation will be apparently valuable forboth communities.In this paper, we show that the strongly equiv-alent grammars enable the sharing of ?parsingtechniques?, which are dependent on each com-putational framework and have never been sharedamong HPSG and LTAG communities.
We ap-ply our system to the latest version of the XTAGEnglish grammar (The XTAG Research Group,2001), which is a large-scale FB-LTAG gram-mar.
A parsing experiment shows that an efficientHPSG parser with the obtained grammar achieveda significant speed-up against an existing LTAGparser (Yoshinaga et al, 2001).
This result im-plies that parsing techniques for HPSG are alsobeneficial for LTAG parsing.
We can say that thegrammar conversion enables us to share HPSGparsing techniques in LTAG parsing.Figure 1 depicts a brief sketch of the RenTALsystem.
The system consists of the following fourmodules: Tree converter, Type hierarchy extrac-tor, Lexicon converter and Derivation translator.The tree converter module is a core module of thesystem, which is an implementation of the gram-mar conversion algorithm given in Section 3.
Thetype hierarchy extractor module extracts the sym-bols of the node, features, and feature values fromthe LTAG elementary tree templates and lexicon,and construct the type hierarchy from them.
Thelexicon converter module converts LTAG elemen-tary tree templates into HPSG lexical entries.
Thederivation translator module takes HPSG parseSNP VPVrunVPVPVcan*NPNWe?1?2?1anchorfoot node*substitution nodeInitial treeAuxiliary treeFigure 2: Elementary treestrees, and map them to LTAG derivation trees.
Allmodules other than the last one are related to theconversion process from LTAG into HPSG, andthe last one enables to obtain LTAG analysis fromthe obtained HPSG analysis.Tateisi et al also translated LTAG intoHPSG (Tateisi et al, 1998).
However, theirmethod depended on translator?s intuitive analy-sis of the original grammar.
Thus the transla-tion was manual and grammar dependent.
Themanual translation demanded considerable effortsfrom the translator, and obscures the equiva-lence between the original and obtained gram-mars.
Other works (Kasper et al, 1995; Beckerand Lopez, 2000) convert HPSG grammars intoLTAG grammars.
However, given the greater ex-pressive power of HPSG, it is impossible to con-vert an arbitrary HPSG grammar into an LTAGgrammar.
Therefore, a conversion from HPSGinto LTAG often requires some restrictions on theHPSG grammar to suppress its generative capac-ity.
Thus, the conversion loses the equivalence ofthe grammars, and we cannot gain the above ad-vantages.Section 2 reviews the source and the tar-get grammar formalisms of the conversion algo-rithm.
Section 3 describes the conversion algo-rithm which the core module in the RenTAL sys-tem uses.
Section 4 presents the evaluation ofthe RenTAL system through experiments with theXTAG English grammar.
Section 5 concludes thisstudy and addresses future works.2 Background2.1 Feature-Based Lexicalized TreeAdjoining Grammar (FB-LTAG)LTAG (Schabes et al, 1988) is a grammar formal-ism that provides syntactic analyses for a sentenceby composing elementary trees with two opera-Arg :wecan runID grammar ruleunifySym : NPArg :Sym : VPArg :   VPSym : VPArg :   NPArg :Sym :Arg :232unify3unifyID grammar rulewecan runSym : NPArg :Sym : VPArg :   VPSym : VPArg :   NPArg :   NPSym :Arg :Arg :11|2Arg :2unifywe can runSym : NPArg :Sym : VPArg :   VPSym : VPArg :   NPArg :   NPArg :Figure 6: Parsing with an HPSG grammarSNPVPVrunNPNWesubstitution?1?2SNP VPVrunNWeFigure 3: SubstitutionVPVPVcan*adjunction?1SNP VPVrunNWeSNPVPVPVcanNWeVrunFigure 4: Adjunctiontions called substitution and adjunction.
Elemen-tary trees are classified into two types, initial treesand auxiliary trees (Figure 2).
An elementary treehas at least one leaf node labeled with a terminalsymbol called an anchor (marked with ).
In anauxiliary tree, one leaf node is labeled with thesame symbol as the root node and is speciallymarked as a foot node (marked with ).
In an el-ementary tree, leaf nodes with the exception ofanchors and the foot node are called substitutionnodes (marked with #).Substitution replaces a substitution node withanother initial tree (Figure 3).
Adjunction graftsan auxiliary tree with the root node and footnode labeled x onto an internal node of anothertree with the same symbol x (Figure 4).
FB-LTAG (Vijay-Shanker, 1987; Vijay-Shanker andJoshi, 1988) is an extension of the LTAG formal-ism.
In FB-LTAG, each node in the elementarytrees has a feature structure, containing grammat-ical constraints on the node.
Figure 5 shows aresult of LTAG analysis, which is described notderived tree?2?1?1derivation treeSNP VPVPVcanNWeVrunFigure 5: Derived trees and derivation treesonly by derived trees (i.e., parse trees) but also byderivation trees.
A derivation tree is a structuraldescription in LTAG and represents the history ofcombinations of elementary trees.There are several grammars developed in theFB-LTAG formalism, including the XTAG En-glish grammar, a large-scale grammar for En-glish (The XTAG Research Group, 2001).
TheXTAG group (Doran et al, 2000) at the Univer-sity of Pennsylvania is also developing Korean,Chinese, and Hindi grammars.
Development ofa large-scale French grammar (Abeille?
and Can-dito, 2000) has also started at the University ofPennsylvania and is expanded at University ofParis 7.2.2 Head-Driven Phrase StructureGrammar (HPSG)An HPSG grammar consists of lexical entries andID grammar rules, each of which is describedwith typed feature structures (Carpenter, 1992).
Alexical entry for each word expresses the charac-teristics of the word, such as the subcategorizationframe and the grammatical category.
An ID gram-mar rule represents a relation between a motherand its daughters, and is independent of lexicalcharacteristics.
Figure 6 illustrates an example ofbottom-up parsing with an HPSG grammar.
First,lexical entries for ?can?
and ?run?
are unified re-spectively with the daughter feature structures ofCanonical elementary trees Non-canonical elementary treesthinkSNP VPV S*itSNP VPNVVPV?isNon-anchored subtreeSNP VPV PPP NPforlookPP SP NPa) Exception for Condition 1b) Exception for Condition 2Figure 7: A canonical elementary tree and exceptionsan ID grammar rule.
The feature structure of themother node is determined as a result of these uni-fications.
The center of Figure 6 shows a rule ap-plication to ?can run?
and ?we?.There are a variety of works on efficient pars-ing with HPSG, which allow the use of HPSG-based processing in practical application con-texts (Flickinger et al, 2000).
Stanford Univer-sity is developing the English Resource Gram-mar, an HPSG grammar for English, as a partof the Linguistic Grammars Online (LinGO)project (Flickinger, 2000).
In practical con-text, German, English, and Japanese HPSG-basedgrammars are developed and used in the Verb-mobil project (Kay et al, 1994).
Our grouphas developed a wide-coverage HPSG grammarfor Japanese (Mitsuishi et al, 1998), which isused in a high-accuracy Japanese dependency an-alyzer (Kanayama et al, 2000).3 Grammar conversionThe grammar conversion from LTAG toHPSG (Yoshinaga and Miyao, 2001) is thecore portion of the RenTAL system.
Theconversion algorithm consists of:1.
Conversion of canonical elementary trees toHPSG lexical entries.2.
Definition of ID grammar rules to emulatesubstitution and adjunction.3.
Conversion of non-canonical elementarytrees to canonical ones.The left-hand side of Figure 7 shows a canoni-cal elementary tree, which satisfies the followingconditions:Condition 1 A tree must have only one anchor.Sym:Arg:Sym  :Leaf :Dir    :right left,Foot?
:+_*thinkV SVPSNPVthink:SVP SNPfoot nodeanchortrunk*substitution nodeSym  :Leaf :Dir    :Foot?
:Figure 8: A conversion from a canonical elemen-tary tree into an HPSG lexical entrymotherSym : 1Arg : 2hSym : 3Arg : h iisubstitution nodeXXXXX24Arg :*24Sym : 1Leaf : 3Dir : leftFoot?
:  35j 2+35trunk nodeFigure 9: Left substitution ruleCondition 2 All branchings in a tree must con-tain trunk nodes.Trunk nodes are nodes on a trunk, which is a pathfrom an anchor to the root node (the thick lines inFigure 7) (Kasper et al, 1995).
Condition 1 guar-antees that a canonical elementary tree has onlyone trunk, and Condition 2 guarantees that eachbranching consists of a trunk node, a leaf node,and their mother (also a trunk node).
The right-hand side of Figure 7 shows elementary trees vi-olating the conditions.Canonical elementary trees can be directly con-verted to HPSG lexical entries by regarding eachleaf node as a subcategorization element of theanchor, and by encoding them into a list.
Fig-ure 8 shows an example of the conversion.
Byfollowing the trunk from the anchor ?think?
to themotherSym : 1Arg : 2  3Sym : 4Arg : 3foot nodePPPPP24Arg :*24Sym : 1Leaf : 4Dir : leftFoot?
: +35j 2+35trunk node appendFigure 10: Left adjunction ruleroot node labeled S, we store each branching ina list.
As shown in Figure 8, each branching isspecified by a leaf node and the mother node.
Afeature Sym represents the non-terminal symbolof the mother node.
Features Leaf, Dir, Foot?represent the leaf node; the non-terminal symbol,the direction (on which side of the trunk node theleaf node is), and the type (whether a foot node ora substitution node), respectively.Figures 9 and 10 show ID grammar rules to em-ulate substitution and adjunction.
These grammarrules are independent of the original grammar be-cause they don?t specify any characteristics spe-cific to the original grammar.In the substitution rule, the Sym feature of thesubstitution node must have the value of the Leaffeature 3 of the trunk node.
The Arg feature ofthe substitution node must be a null list, becausethe substitution node must be unified only withthe node corresponding to the root node of the ini-tial tree.
The substitution rule percolates the tailelements 2 of the Arg feature of a trunk node tothe mother in order to continue constructing thetree.In the adjunction rule, the Sym feature of afoot node must have the same value as the Leaffeature 4 .
The value of the Arg feature of themother node is a concatenation list of both Argfeatures 2 and 3 of its daughters because wefirst construct the tree corresponding to the ad-joining tree and next continue constructing thetree corresponding to the adjoined tree.
The value?+?
or ? ?
of the Foot?
feature explicitly de-termines whether the next rule application is theadjunction rule or the substitution rule.Figure 11 shows an instance of rule applica-tions.
The thick line indicates the adjoined tree(1) and the dashed line indicates the adjoiningSym : NPArg :Sym : SArg :Sym : S?12153Sym :        SLeaf :        NPDir :  leftFoot?
:  21Sym :        VPLeaf :        SDir :  rightFoot?
:  +Sym : NPArg :Sym : NPArg :Sym : VSym : SSym : VPSym : Vthink:loves:you?
A*?
B447786Sym :        SLeaf :        NPDir :  leftFoot?
:  5Sym :        SLeaf :        NPDir :  leftFoot?
:  215Sym :        SLeaf :        NPDir :  leftFoot?
:  21368Sym :        SLeaf :        NPDir :  leftFoot?
:  36Sym :        SLeaf :        NPDir :  leftFoot?
: ,5Sym :        SLeaf :        NPDir :  leftFoot?
:  21,499?1he?2?4?3Arg :Arg :Arg : Arg :Arg :what?
CFigure 11: An example of rule applicationsSNPVPV PPP NPforSNP VPVP NPforlook lookcut offPPlook_forPPlook_foridentifierFigure 12: Division of a multi-anchored elemen-tary tree into single-anchored treestree (2).
The adjunction rule is applied to con-struct the branching marked with ?, where ?think?takes as an argument a node whose Sym feature?svalue is S. By applying the adjunction rule, theArg feature of the mother node (B) becomes aconcatenation list of both Arg features of 1 ( 8 )and 1 ( 5 ).
Note that when the construction of1 is completed, the Arg feature of the trunk node(C) will be its former state (A).
We can continueconstructing 1 as if nothing had happened.Multi-anchored elementary trees, which violateCondition 1, are divided into multiple canonicalelementary trees.
We call the cutting nodes in thedivided trees cut-off nodes (Figure 12).
Note thata cut-off node is marked by an identifier to pre-serve a co-occurrence relation among the multipleanchors.
Figure 12 shows an example of the con-version of a multi-anchored elementary tree for acompound expression ?look for?.
We first selectan anchor ?look?
as the syntactic head, and tra-verse the tree along the trunk from the root nodeS to the anchor ?look?.
We then cut off the multi-PAdPPsubstitutionall candidate initial treesfor substitution, ?non-anchored subtreemulti-anchored trees without non-anchored subtreesitSNP VPNVisVPV?PP SP NPbreaking pointsontonextitSNP VPNVisVPV?PP SP NPitSNP VPNVisVPV?PP SP NP, ?AdPontonextFigure 13: Combination of a non-anchored subtree into anchored treesanchored elementary tree at the node PP, and cut-off nodes PP in resulting single-anchored trees aremarked by an identifier look for.Non-canonical elementary trees violating Con-dition 2 have a non-anchored subtree which isa subtree of depth 1 or above with no anchor.A non-anchored subtree is converted into multi-anchored trees by substituting the deepest node(Figure 13).
Substituted nodes are marked asbreaking points to remember that the nodes orig-inate from the substitution nodes.
In the resultingtrees, all subtrees are anchored so that we can ap-ply the above conversion algorithms.
Figure 13shows a conversion of a non-canonical elemen-tary tree for it-cleft.
A substitution node P in thenon-anchored subtree is selected, and is substi-tuted by each initial tree.
The substituted nodeP in resulting multi-anchored trees are marked asbreaking points.The above algorithm gives the conversion ofLTAG, and it can be easily extended to handle anFB-LTAG grammar by merely storing a featurestructure of each node into the Sym feature andLeaf feature together with the non-terminal sym-bol.
Feature structure unification is executed byID grammar rules.The strong equivalence is assured because onlysubstitution/adjunction operations performed inLTAG are performed with the obtained HPSG-style grammar.
This is because each elementin the Arg feature selects only feature structurescorresponding to trees which can substitute/beadjoined by each leaf node of an elementarytree.
By following a history of rule applications,each combination of elementary trees in LTAGderivation trees can be readily recovered.
Thestrong equivalence holds also for conversion ofnon-canonical elementary trees.
For trees violat-ing Condition 1, we can distinguish the cut-offTable 1: The classification of elementary treetemplates in the XTAG English grammar (LTAG)and converted lexical entry templates correspond-ing to them (HPSG): A: canonical elementarytrees, B: elementary trees violating only Condi-tion 1, C: elementary trees violating only Condi-tion 2, D: elementary trees violating both condi-tionsGrammar A B C D TotalLTAG 326 764 54 50 1,194HPSG 326 1,992 1,083 2,474 5,875nodes from the substitution nodes owing to iden-tifiers, which recover the co-occurrence relationin the original elementary trees between the di-vided trees.
For trees violating Condition 2, wecan identify substitution nodes in a combined treebecause they are marked as breaking points, andwe can consider the combined tree as two trees inthe LTAG derivation.4 ExperimentsThe RenTAL system is implemented in LiL-FeS (Makino et al, 1998)2.
LiLFeS is one ofthe fastest inference engines for processing fea-ture structure logic, and efficient HPSG parsershave already been built on this system (Nishidaet al, 1999; Torisawa et al, 2000).
We ap-plied our system to the XTAG English gram-mar (The XTAG Research Group, 2001)3, whichis a large-scale FB-LTAG grammar for English.2The RenTAL system is available at:http://www-tsujii.is.s.u-tokyo.ac.jp/rental/3We used the grammar attached to the latest distributionof an LTAG parser which we used for the parsing experi-ment.
The parser is available at:ftp://ftp.cis.upenn.edu/pub/xtag/lem/lem-0.13.0.i686.tgzTable 2: Parsing performance with the XTAG En-glish grammar for the ATIS corpus.Parser Parse Time (sec.
)lem 19.64TNT 0.77The XTAG English grammar consists of 1,194 4elementary tree templates and around 45,000 lex-ical items5.
We successfully converted all theelementary tree templates in the XTAG Englishgrammar to HPSG lexical entry templates.
Ta-ble 1 shows the classifications of elementary treetemplates of the XTAG English grammar, ac-cording to the conditions we introduced in Sec-tion 3, and also shows the number of correspond-ing HPSG lexical entry templates.
Conversiontook about 25 minutes CPU time on a 700 MhzPentium III Xeon with four gigabytes main mem-ory.The original and the obtained grammar gener-ated exactly the same number of derivation treesin the parsing experiment with 457 sentencesfrom the ATIS corpus (Marcus et al, 1994)6 (theaverage length is 6.32 words).
This result empir-ically attested the strong equivalence of our algo-rithm.Table 2 shows the average parsing time withthe LTAG and HPSG parsers.
In Table 2, lemrefers to the LTAG parser (Sarkar et al, 2000),ANSI C implementation of the two-phase pars-ing algorithm that performs the head corner pars-ing (van Noord, 1994) without features (phase1), and then executes feature unification (phase2).
TNT refers to the HPSG parser (Torisawa etal., 2000), C++ implementation of the two-phaseparsing algorithm that performs filtering with acompiled CFG (phase 1) and then executes fea-ture unification (phase 2).
Table 2 clearly showsthat the HPSG parser is significantly faster thanthe LTAG parser.
This result implies that parsingtechniques for HPSG are also beneficial for LTAG4We eliminated 32 elementary trees because the LTAGparser cannot produce correct derivation trees with them.5These lexical items are a subset of the original XTAGEnglish grammar distribution.6We eliminated 59 sentences because of a time-out ofthe parsers, and 61 sentences because the LTAG parser doesnot produce correct derivation trees because of bugs in itspreprocessor.parsing.
We can say that the grammar conversionenables us to share HPSG parsing techniques inLTAG parsing.
Another paper (Yoshinaga et al,2001) describes the detailed analysis on the factorof the difference of parsing performance.5 ConclusionWe described the RenTAL system, a grammarconverter from FB-LTAG to HPSG.
The grammarconversion guarantees the strong equivalence, andhence we can obtain an HPSG-style grammarequivalent to existing LTAG grammars.
Experi-mental result showed that the system enabled toshare not only LTAG grammars, but also HPSGparsing techniques.
This system will enable avariety of resource sharing such as the sharingof the programming/grammar-development envi-ronment (Makino et al, 1998; Sarkar and Wint-ner, 1999) and grammar extraction methods frombracketed corpora (Xia, 1999; Chen and Vijay-Shanker, 2000; Neumann, 1998).
Although oursystem connects only FB-LTAG and HPSG, webelieve that our approach can be extended to otherformalisms such as Lexical-Functional Gram-mar (Kaplan and Bresnan, 1982).Acknowledgment The authors are indebtedto Mr. Anoop Sarkar for his help in using hisparser in our experiment.
The authors would liketo thank anonymous reviewers for their valuablecomments and criticisms on this paper.ReferencesAnne Abeille?
and Marie-He?le`ne Candito.
2000.FTAG: A Lexicalized Tree Adjoining Grammar forFrench.
In Anne Abeille?
and Owen Rambow, edi-tors, Tree Adjoining Grammars: Formal, Computa-tional and Linguistic Aspects, pages 305?329.
CSLIpublications.Tilman Becker and Patrice Lopez.
2000.
AdaptingHPSG-to-TAG compilation to wide-coverage gram-mars.
In Proc.
of TAG+5, pages 47?54.Bob Carpenter.
1992.
The Logic of Typed FeatureStructures.
Cambridge University Press.John Chen and K. Vijay-Shanker.
2000.
Automatedextraction of TAGs from the Penn Treebank.
InProc.
of IWPT 2000.David Chiang.
2000.
Statistical parsing with anautomatically-extracted Tree Adjoining Grammar.In Proc.
of ACL 2000, pages 456?463.Christy Doran, Beth Ann Hockey, Anoop Sarkar,B.
Srinivas, and Fei Xia.
2000.
Evolution of theXTAG system.
In Anne Abeille?
and Owen Ram-bow, editors, Tree Adjoining Grammars: Formal,Computational and Linguistic Aspects, pages 371?403.
CSLI publications.Dan Flickinger, Stephen Oepen, Jun?ichi Tsujii, andHans Uszkoreit, editors.
2000.
Natural LanguageEngineering ?
Special Issue on Efficient Processingwith HPSG: Methods, Systems, Evaluation.
Cam-bridge University Press.Dan Flickinger.
2000.
On building a more effi-cient grammar by exploiting types.
Natural Lan-guage Engineering ?
Special Issue on Efficient Pro-cessing with HPSG: Methods, Systems, Evaluation,6(1):15?28.Hiroshi Kanayama, Kentaro Torisawa, Yutaka Mitsu-isi, and Jun?ichi Tsujii.
2000.
Hybrid Japaneseparser with hand-crafted grammar and statistics.
InProc.
of COLING 2000, pages 411?417.Ronald Kaplan and Joan Bresnan.
1982.
Lexical-Functional Grammar: A formal system for gram-matical representation.
In Joan Bresnan, editor, TheMental Representation of Grammatical Relations,pages 173?281.
The MIT Press.Robert Kasper, Bernd Kiefer, Klaus Netter, andK.
Vijay-Shanker.
1995.
Compilation of HPSG toTAG.
In Proc.
of ACL ?94, pages 92?99.M.
Kay, J. Gawron, and P. Norvig.
1994.
Verbmo-bil: A Translation System for Face-to-Face Dialog.CSLI Publications.Takaki Makino, Minoru Yoshida, Kentaro Torisawa,and Jun?ichi Tsujii.
1998.
LiLFeS ?
towards apractical HPSG parsers.
In Proc.
of COLING?ACL?98, pages 807?811.Mitchell Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a large annotatedcorpus of English: the Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Yutaka Mitsuishi, Kentaro Torisawa, and Jun?ichi Tsu-jii.
1998.
HPSG-style underspecified Japanesegrammar with wide coverage.
In Proc.
ofCOLING?ACL ?98, pages 876?880.Gu?ter Neumann.
1998.
Automatic extraction ofstochastic lexcalized tree grammars from treebanks.In Proc.
of TAG+4, pages 120?123.Kenji Nishida, Kentaro Torisawa, and Jun?ichi Tsujii.1999.
An efficient HPSG parsing algorithm with ar-ray unification.
In Proc.
of NLPRS ?99, pages 144?149.Carl Pollard and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
University of ChicagoPress and CSLI Publications.Peter Poller and Tilman Becker.
1998.
Two-step TAGparsing revisited.
In Proc.
of TAG+4, pages 143?146.Anoop Sarkar and Shuly Wintner.
1999.
Typing as ameans for validating feature structures.
In Proc.ofCLIN ?99, pages 159?167.Anoop Sarkar, Fei Xia, and Aravind Joshi.
2000.Some experiments on indicators of parsing com-plexity for lexicalized grammars.
In Proc.
of COL-ING 2000, pages 37?42.Yves Schabes, Anne Abeille, and Aravind K. Joshi.1988.
Parsing strategies with ?lexicalized?
gram-mars: Application to Tree Adjoining Grammars.
InProc.
of 12th COLING ?92, pages 578?583.Yuka Tateisi, Kentaro Torisawa, Yusuke Miyao, andJun?ichi Tsujii.
1998.
Translating the XTAG En-glish grammar to HPSG.
In Proc.
of TAG+4, pages172?175.The XTAG Research Group.
2001.
A Lex-icalized Tree Adjoining Grammar for English.http://www.cis.upenn.edu/?xtag/.Kentaro Torisawa, Kenji Nishida, Yusuke Miyao, andJun?ichi Tsujii.
2000.
An HPSG parser with CFGfiltering.
Natural Language Engineering ?
SpecialIssue on Efficient Processing with HPSG: Methods,Systems, Evaluation, 6(1):63?80.Gertjan van Noord.
1994.
Head corner parsing forTAG.
Computational Intelligence, 10(4):525?534.K.
Vijay-Shanker and Aravind K. Joshi.
1988.
Fea-ture structures based Tree Adjoining Grammars.
InProc.
of 12th COLING ?92, pages 714?719.K.
Vijay-Shanker.
1987.
A Study of Tree AdjoiningGrammars.
Ph.D. thesis, Department of Computer& Information Science, University of Pennsylvania.Fei Xia.
1999.
Extracting Tree Adjoining Grammarsfrom bracketed corpora.
In Proc.
of NLPRS ?99,pages 398?403.Naoki Yoshinaga and Yusuke Miyao.
2001.
Grammarconversion from FB-LTAG to HPSG.
In Proc.
ofESSLLI 2001 Student Session.
To appear.Naoki Yoshinaga, Yusuke Miyao, Kentaro Torisawa,and Jun?ichi Tsujii.
2001.
Efficient LTAG parsingusing HPSG parsers.
In Proc.
of PACLING 2001.To appear.
