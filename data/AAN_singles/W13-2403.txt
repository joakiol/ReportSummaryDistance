Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 12?17,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsEvaluating Sentiment Analysis Systems in RussianIlia ChetviorkinFaculty of ComputationalMathematics and CyberneticsLomonosov Moscow State UniversityMoscow, Leninskiye Gory 1, Building 52ilia2010@yandex.ruNatalia LoukachevitchResearch Computing CenterLomonosov Moscow State UniversityMoscow, Leninskiye Gory 1, Building 4louk nat@mail.ruAbstractIn this paper we describe our experience inconducting the first open sentiment anal-ysis evaluations in Russian in 2011-2012.These initiatives took part within RussianInformation Retrieval Seminar (ROMIP),which is an annual TREC-like competitionin Russian.
Several test and train collec-tions were created for such tasks as senti-ment classification in blogs and newswire,opinion retrieval.
The paper describes thestate of the art in sentiment analysis inRussian, collection characteristics, tracktasks and evaluation metrics.1 IntroductionSentiment analysis of natural language texts is oneof the fast-developing technologies of natural lan-guage processing.
Many lexical resources andtools were created for sentiment analysis in En-glish.
But lately a lot of research work was initi-ated for sentiment analysis in other languages (Mi-halcea et al 2007; Abdul-Mageed et al 2011;Pe?rez-Rosas et al 2012).The development of sentiment analysis in Rus-sian previously did not attract a lot of attentionat international conferences.
Besides, until re-cently, the interest to sentiment analysis withinRussia was connected only with election cam-paigns.
But now there is a considerable interestto sentiment analysis within Russia both from theresearch community and from the industry.Therefore during the last years, two workshopson the evaluation of sentiment analysis systemswere organized within the framework of RussianInformation Retrieval Seminar ROMIP1 .
In manyrespects ROMIP seminars are similar to other in-ternational information retrieval events such asTREC and NTCIR, which have already conducted1http://romip.ru/en/index.htmldifferent sentiment analysis tracks.
Besides, thereare various shared tasks connected to the senti-ment analysis like (Morante and Blanco, 2012;Pestian et al 2012; Wu and Jin, 2010; Amigo?
etal., 2012).In this paper we partly overview the sentimentanalysis tasks proposed at ROMIP-2011 (Chetv-iorkin et al 2012) and ROMIP-2012 (Chetviorkinand Loukachevich, 2013), the data prepared forevaluation (and therefore available for other in-terested researchers), and the results obtained byparticipants.
In addition we summarize the resultsof two initiatives, compare them with the state ofthe art in English and describe some interesting is-sues connected to news-based sentiment analysis.We justify all our decisions about the conductedtracks based on the experience of the other re-searchers, who made the similar initiatives in En-glish.
ROMIP-2011 and ROMIP-2012 are uniqueevents for Slavic languages and other Europeanlanguages different from English.The paper is structured as follows.
In section 2we review papers on Russian sentiment analysis,not related to the ROMIP evaluations.
In section3 we consider sentiment analysis evaluation tasksproposed during ROMIP-2011, 2012 and considerthe main results obtained by participants.2 Sentiment Analysis in RussianIn Russia studies devoted to sentiment analysis inRussian before 2011 are not very numerous.In (Ermakov, 2009) a sentiment analysis sys-tem extracting opinions about cars from a Russianblog community (http://avto-ru.livejournal.com/)is presented.
The approach is based on the detaileddescription of knowledge about car trade marks,their details and characteristics, semantic patternsof sentiment expressions.
This paper is the first, toour knowledge, paper in Russia that reports eval-uation results of the proposed approach: precision84%, recall 20% (self-evaluation).12In international research Russian sentimentanalysis appears mainly in multilingual experi-ments.In (Zagibalov et al 2010) comparable corporaof reviews related to the same books in Englishand in Russian are described.
These corpora al-lowed authors to study specific ways of sentimentexpression in Russian and English.In (Steinberger et al 2011) construction of gen-eral sentiment vocabularies for several languagesis described.
They create two source sentimentvocabularies: English (2400 entries) and Spanish(1737 entries).
Both lists are translated by Googletranslator to the target language.
Only the overlap-ping entries from each translation are taken intofurther consideration.
The set of target languagescomprises six languages including Russian.
Theextracted Russian list of sentiment words con-tained 966 entries with accuracy of 94.9%.In one of the recent papers not relatedto the ROMIP evaluations (Chetviorkin andLoukachevitch, 2012), the generation of the Rus-sian sentiment vocabulary for the generalized do-main of products and services is described.
Au-thors constructed a new model based on multiplefeatures for domain-specific sentiment vocabularyextraction, then applied this model to several do-mains, and at last combined these domain-specificvocabularies to generate Russian sentiment vocab-ulary for products and services ?
ProductSentiRus.Now the extracted list is publicly available2.3 Sentiment analysis tasksThe tasks of two Russian sentiment analysis eval-uations ROMIP-2011 and ROMIP-2012 included:?
Sentiment classification of user reviews inthree domains (movies, books, digital cam-eras) using several different sentiment scales,?
Sentiment classification of news-based opin-ions, which are fragments of direct or indirectspeech extracted from news articles,?
Query-based retrieval of opinionated blogposts in three domains (movies, books, dig-ital cameras).In ROMIP-2011 sentiment evaluation therewere 12 participants with more than 200 runs.
InROMIP-2012 17 teams sent more than 150 runs.2http://www.cir.ru/SentiLexicon/ProductSentiRus.txtThe presentations describing approaches were or-ganized as a section of International Conferenceon Computational Linguistics and InformationTechnologies ?Dialog?
(www.dialog-21.ru/en/).3.1 Sentiment classification of reviewsThe only task of ROMIP-2011 and one of the tasksof ROMIP-2012 was sentiment classification ofusers reviews in three domains: movies, books anddigital cameras.The training data for this task includedmovie and book collections with 15,718 and24,159 reviews respectively from Imhonet service(imhonet.ru) and the digital camera review collec-tion with 10,370 reviews from Yandex Market ser-vice (http://market.yandex.ru/).
All reviews havethe authors score on the ten-point scale or the five-point scale.For testing, another collection of reviews with-out any authors?
scores was created.
The testingcollection contained blog posts about the above-mentioned entities found with Yandex?s BlogSearch Engine (http://blog.yandex.ru).
So in thistrack we tried to model a real-word task, whena classifier should be trained on available data,which can be quite different from the task data.The participants stressed that our track is more dif-ficult than training and testing on the similar data,but agreed that this task setting is more realistic.For each domain a list of search queries wasmanually compiled and for each query a set ofblog posts was extracted.
Finally, results obtainedfor all queries were merged and sent to the partic-ipants.For the evaluation, annotators selected subjec-tive posts related to three target domains, as-sessed the polarity of these posts and labeled themwith three scores corresponding to different senti-ment scales (two-class, three-class and five-classscales).The participants systems had to classify thereviews to two, three or five classes accordingto sentiment.
The primary measures for evalua-tion of two and three class tasks were accuracyand macro-F1 measure.
Macro-measures (Man-ning et al 2008) were used because the majorityof user reviews in blogs are positive (more than80%).
Macro-averaging means a simple averageover classes.
The five-class task was additionallyevaluated with Euclidean distance measure, whichis the quadratic mean between the scores of the al-13Domains2-class 3-class 5-classF1 Acc.
F1 Acc.
F1 Acc.Movies 0.786 0.881 0.592 0.754 0.286 0.602Books 0.747 0.938 0.577 0.771 0.291 0.622Cameras 0.929 0.959 0.663 0.841 0.342 0.626Table 1: Best results of blog review classification in ROMIP-2011Domains2-class 3-class 5-classF1 Acc.
F1 Acc.
F1 Acc.Movies 0.707 0.831 0.520 0.694 0.377 0.407Books 0.715 0.884 0.560 0.752 0.402 0.480Cameras 0.669 0.961 0.480 0.742 0.336 0.480Table 2: Best results of blog review classification in ROMIP-2012gorithm and the assessor scores.Practically all the best approaches in the reviewclassification tasks used SVM machine learningmethod (Kotelnikov and Klekovkina, 2012; Pakand Paroubek, 2012; Polyakov et al 2012).
Be-sides, the best methods usually combined SVMwith other approaches including manual or auto-matic dictionaries or rule-based systems.
The bestachieved results according to macro-F1 measureand Accuracy within ROMIP 2011 are presentedin Table 1 and within ROMIP 2012 in Table 2.Observing the results of the open evaluation ofsentiment analysis systems in Russian during twoyears we can make some conclusions about thestate of the art performance and specific charac-teristics of the track.The average level in 2-class classification taskaccording to Accuracy is near 90%, near 75% for3-class classification task and near 50% for 5-classtask.
Such results are consistent with the state ofthe art performance in English.
However these fig-ures are slightly overestimated due to the skewnessof the testing collections.
This fact is the conse-quence of using blogs as a test set.
The majorityof blog opinions about various objects is positive,but such a collection is a priori unlabeled, whichleads to fair evaluation results.3.2 Sentiment classification of opinionatedquotationsThe next task of ROMIP-2012 concerned senti-ment classification of short (1-2 sentences on av-erage) fragments of direct or indirect speech au-tomatically extracted from news articles (furtherquotations).
The somewhat similar task was con-ducted within the NTCIR-6, where one of the maintasks was extraction of opinion sentences from thenews articles in three languages: English, Chineseand Japanese (Seki et al 2007).The topics of quotations could be quite differ-ent: from politics and economy to sports and arts.Therefore this task should be difficult enough forboth knowledge-based and machine-learning ap-proaches.Assessors annotated quotations as positive, neu-tral, negative, or mixed.
After the annotation thequotations with mixed sentiment were removedfrom the evaluation.
So the participating systemsshould classify quotations to three classes.
Thistask is similar to sentiment classification of po-litical quotations (Awadallah et al 2012; Bala-subramanyan et al 2012) to pro and contra po-sitions.
In (Awadallah et al 2012) authors statethat short quotations are difficult for classificationbecause useful linguistic features tend to be sparseand the same quotation can have different polari-ties for different topics.
In our case the task waseven more difficult because of unlimited topicsand three-class classification.In ROMIP-2012 evaluation 4,260 quotationswere prepared for training.
For testing more than120 thousand quotes were sent to participants, butreal evaluation was made on the basis of 5,500quotations randomly sampled and annotated fromthe testing set.
An example of the quotation is asfollows: Patriarch Kirill, says feminism is a ?verydangerous?
phenomenon offering an illusion offreedom to women, who he says should focus ontheir families and children.In this task class distribution was rather bal-anced in comparison with the review classifica-tion task: 41% of quotes were negative, 32% of14RunID Macro P Macro R Macro F1 Accuracyxxx-4 0.626 0.616 0.621 0.616xxx-11 0.606 0.579 0.592 0.571xxx-15 0.563 0.560 0.562 0.582Baseline 0.138 0.333 0.195 0.413Table 3: Best results for the news quotation classification task in ROMIP 2012RunID Domain P@1 P@5 P@10 NDCG@10xxx-0 book 0.3 0.32 0.286 0.305xxx-8 book 0.25 0.31 0.332 0.298yyy-9 camera 0.402 0.313 0.302 0.305yyy-1 camera 0.402 0.328 0.325 0.226zzz-3 film 0.494 0.449 0.438 0.338zzz-8 film 0.
494 0.448 0.444 0.332Table 4: Best results in the task of retrieval of opinionated blog postsquotes were positive and 27% of quotes were neu-tral.
For evaluation again macro-measures and ac-curacy were applied.The results of the participants are presented inTable 3.
The baseline results correspond to clas-sification of quotations according to the majorclass.
In opposite to the review classification task,the leaders in the news-based classification wereknowledge-based approaches.
It is due to the ab-sence of a large training collection appropriate forthis task because of the broad scope of quotationtopics.The authors of the best approach in this task re-port that their knowledge-based system has a con-siderable vocabulary including 15 thousand nega-tive expressions, 7 thousand positive expressions,around 120 so-called operators (intensifiers andinvertors) and around 200 neutral stop expressionsincluding sentiment words as their components.The system has a small number of rules for ag-gregating scores of sentiment word and operatorsequences (Kuznetsova et al 2013).
The secondand third results in this task were obtained by arule-based system with comparably small senti-ment dictionaries but a rich rule set based on syn-tactic analysis (Panicheva, 2013).An interesting conclusion is that the size of sen-timent dictionaries can be compensated with vari-ous syntactic rules, which allows handling the va-riety of situations in expressing sentiment.The results of this task can be compared withone of the recent studies on lexicon-based meth-ods for sentiment analysis in English (Taboada etal., 2011).
The text fragments in the paper andin ROMIP evaluation are rather equal by style(news quotes versus opinionated news sentences).We cannot directly compare the results of analo-gous systems in Russian and English, because weworked with 3 class classification problem (pos-itive, negative, neutral) versus 2 class task in thepaper, but available figures are the following: theaccuracy of sentiment analysis systems in Russianis near 61.6% in the three-class task versus 71.57%for the two-class task in English.3.3 Query-based retrieval of opinionatedblog postsFor several years TREC Blog tracks were con-nected with opinion finding and processing of blogdata (Ounis et al 2007; Macdonald et al 2008;Ounis et al 2008; Macdonald et al 2010; Ou-nis et al 2011).
During the research cycles withinthese initiatives, the following sentiment analysistasks were considered:?
Opinion finding (blog post) retrieval task,?
Polarised opinion finding (blog post) retrievaltask.The query-based retrieval of opinions fromblogs was one of the basic tasks for the TRECBlog Track.
Thus, we also decided to start with thesimilar task for Russian language.
Here the par-ticipants had to find all relevant opinionated postsfrom the blog collection according to a specificquery.
Examples of queries include (translationfrom Russian):15?
movie domain: The Girl with the Dragon Tat-too; film ?The dictator?;?
book domain: Agatha Cristie ?Ten little nig-gers?
; Dan Brown ?The Code da Vinci?;?
digital camera domain: Canon EOS 1100DKit; Canon PowerShot G12.Only one group participated in this task andtherefore organizers implemented a simple ap-proach to conduct the track.
The approach to thesentiment post retrieval was based on computa-tion of weighted sum of three components: TFIDFsimilarity of a query to the title of a blog post,TFIDF of a query to the text of the post and theshare of sentiment words in the post.
For com-putation of the latter component, aforementionedRussian sentiment list ProductSentiRus (see sec-tion 2) was used:Weight = ?
?
(?w?qtfidf +?w?qtfidfheader)++(1?
?)
?
(SentiWeight)The organizers experimented with different val-ues of ?
= 0.2, 0.4, 0.5, 0.6, 0.8.
The best per-formance was obtained with ?
= 0.6 for all sub-domains of this task.
To avoid underestimation ofparticipant results, the evaluation was made onlyon the basis of labeled documents.
For this taskwe used two measures: P@n and NDGN@n.Precision@n indicates the number of correct(relevant) objects in the first n objects in the re-sult set and NDCG@n measures the usefulness,or gain, of a document based on its position inthe result list (Manning et al 2008).
The mainmeasures of the performance in this task wereNDCG@10 and Precision@10 (Table 4).4 ConclusionIn this paper we reported the state of the art ofRussian sentiment analysis.
Our report is based onthe results of two evaluations of sentiment analysissystems organized in 2011?2012 within the frame-work of Russian seminar on information retrievalROMIP.
We proposed user review classificationtasks in a practical setting, when available datashould be used for training a classifier intended forsimilar, but another data.
Besides, one of the inter-esting and complicated tasks of ROMIP-2012 wassentiment classification of opinions extracted fromnews articles.AcknowledgmentsThis work is partially supported by grant N11-07-00588-a.ReferencesMuhammad Abdul-Mageed, Mona Diab, and Mo-hammed Korayem.
2011.
Subjectivity and senti-ment analysis of modern standard arabic.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies, volume 2, pages 587?591.Enrique Amigo?, Adolfo Corujo, Julio Gonzalo, EdgarMeij, and Md Rijke.
2012.
Overview of re-plab 2012: Evaluating online reputation manage-ment systems.
In CLEF 2012 Labs and WorkshopNotebook Papers, pages 1?24.Rawia Awadallah, Maya Ramanath, and GerhardWeikum.
2012.
Polaricq: polarity classification ofpolitical quotations.
In Proceedings of the 21st ACMinternational conference on Information and knowl-edge management, pages 1945?1949.Ramnath Balasubramanyan, William W Cohen, DougPierce, and David P Redlawsk.
2012.
Modeling po-larizing topics: When do different political commu-nities respond differently to the same news?
In theInternational AAAI Conference on Weblogs and So-cial Media (ICWSM).Ilia Chetviorkin and Natalia Loukachevich.
2013.Sentiment analysis track at romip 2012.
In Proceed-ings of International Conference Dialog, volume 2,pages 40?50.Ilia Chetviorkin and Natalia Loukachevitch.
2012.Extraction of russian sentiment lexicon for productmeta-domain.
In Proceedings of COLING 2012,pages 593?610.Ilia Chetviorkin, P Braslavskiy, and NataliaLoukachevich.
2012.
Sentiment analysis trackat romip 2011.
In Proceedings of InternationalConference Dialog, volume 2, pages 1?14.Alexander Ermakov.
2009.
Knowledge extractionfrom text and its processing: Current state andprospects.
Information technologies, (7):50?55.Evgeniy Kotelnikov and Marina Klekovkina.
2012.Sentiment analysis of texts based on machine learn-ing methods.
In Proceedings of International Con-ference Dialog, volume 2, pages 27?36.Ekaterina Kuznetsova, Natalia Loukachevitch, and IliaChetviorkin.
2013.
Testing rules for sentiment anal-ysis system.
In Proceedings of International Con-ference Dialog, volume 2, pages 71?80.Craig Macdonald, Iadh Ounis, and Ian Soboroff.
2008.Overview of the trec 2007 blog track.
In Proceed-ings of TREC, volume 7.16Craig Macdonald, Iadh Ounis, and Ian Soboroff.
2010.Overview of the trec 2009 blog track.
In Proceed-ings of TREC, volume 9.Christopher D Manning, Prabhakar Raghavan, andHinrich Schu?tze.
2008.
Introduction to informationretrieval, volume 1.
Cambridge University PressCambridge.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective language viacross-lingual projections.
In Proceedings of the An-nual Meeting of the Association of ComputationalLinguistics, volume 45, pages 976?983.Roser Morante and Eduardo Blanco.
2012.
* sem 2012shared task: Resolving the scope and focus of nega-tion.
In Proceedings of the First Joint Conference onLexical and Computational Semantics, pages 265?274.Iadh Ounis, Maarten de Rijke, Craig Macdonald, Gi-lad Mishne, and Ian Soboroff.
2007.
Overview ofthe trec 2006 blog track.
In Proceedings of TREC,volume 6.Iadh Ounis, Craig Macdonald, and Ian Soboroff.
2008.Overview of the trec-2008 blog track.
Technical re-port, DTIC Document.Iadh Ounis, Craig Macdonald, and Ian Soboroff.
2011.Overview of the trec 2010 blog track.
In Proceed-ings of TREC, volume 10.Alexander Pak and Patrick Paroubek.
2012.
Languageindependent approach to sentiment analysis (limsiparticipation in romip11.
In Proceedings of Interna-tional Conference Dialog, volume 2, pages 37?50.Polina Panicheva.
2013.
Atex.
a rule-based sentimentanalysis system.
processing texts in various topics.In Proceedings of International Conference Dialog,volume 2, pages 101?113.Vero?nica Pe?rez-Rosas, Carmen Banea, and Rada Mi-halcea.
2012.
Learning sentiment lexicons inspanish.
In Proceedings of the Eight InternationalConference on Language Resources and Evaluation(LREC?12).John P Pestian, Pawel Matykiewicz, Michelle Linn-Gust, Brett South, Ozlem Uzuner, Jan Wiebe, K Bre-tonnel Cohen, John Hurdle, and Christopher Brew.2012.
Sentiment analysis of suicide notes: A sharedtask.
Biomedical Informatics Insights, 5(Suppl1):3?16.Pavel Polyakov, Maria Kalinina, and Vladimir Pleshko.2012.
Research on applicability of thematic classifi-cation methods to the problem of book review classi-fication.
In Proceedings of International ConferenceDialog, volume 2, pages 51?59.Yohei Seki, David Kirk Evans, Lun-Wei Ku, Hsin-HsiChen, Noriko Kando, and Chin-Yew Lin.
2007.Overview of opinion analysis pilot task at ntcir-6.
InProceedings of NTCIR-6 Workshop Meeting, pages265?278.Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova,Ralf Steinberger, Hristo Tanev, Silvia Va?zquez, andVanni Zavarella.
2011.
Creating sentiment dictio-naries via triangulation.
Decision Support Systems,pages 28?36.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-based methods for sentiment analysis.
Computa-tional linguistics, 37(2):267?307.Yunfang Wu and Peng Jin.
2010.
Semeval-2010task 18: Disambiguating sentiment ambiguous ad-jectives.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 81?85.Taras Zagibalov, Katerina Belyatskaya, and John Car-roll.
2010.
Comparable english-russian book reviewcorpora for sentiment analysis.
In ComputationalApproaches to Subjectivity and Sentiment Analysis,pages 67?72.17
