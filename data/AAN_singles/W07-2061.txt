Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 282?287,Prague, June 2007. c?2007 Association for Computational LinguisticsRACAI: Meaning Affinity ModelsRadu IonInstitute for Artificial Intelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniaradu@racai.roDan Tufis?Institute for Artificial Intelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniatufis@racai.roAbstractThis article introduces an unsupervised wordsense disambiguation algorithm that is in-spired by the lexical attraction models ofYuret (1998).
It is based on the assump-tion that the meanings of the words thatform a sentence can be best assigned by con-structing an interpretation of the whole sen-tence.
This interpretation is facilitated bya dependency-like context specification ofa content word within the sentence.
Thus,finding the context words of a target wordis a matter of finding a pseudo-syntactic de-pendency analysis of the sentence, called alinkage.1 IntroductionWord Sense Disambiguation (WSD) is a difficultNatural Language Processing task which requiresthat for every content word (noun, adjective, verbor adverb) the appropriate meaning is automaticallyselected from the available sense inventory1.
Tradi-tionally, the WSD algorithms are divided into tworough classes: supervised and unsupervised.
Thesupervised paradigm relies on sense annotated cor-pora, with the assumption that neighbouring disam-biguate words provide a strongly discriminating andgeneralizable context representation for the meaningof a target word.
Obviously, this approach suffersfrom the knowledge acquisition bottleneck in that1In principle, one can select meanings for any part of speechthat is represented into the semantic lexicon (prepositions forinstance) but the content words disambiguation is the de factostandard.there will never be enough training data to ensurea scalable result of such algorithms.
The unsuper-vised alternative to WSD tries to alleviate the burdenof manually sense tagging the corpora, by employ-ing algorithms that use different knowledge sourcesto determine the correct meaning in context.
In fact,the ?knowledge source usage?
is another way to dis-tinguish among the WSD methods.
Such methodscall upon further processing of the text to be dis-ambiguated such as parsing and/or use handcrafted,semantically rich sense inventories such as Word-Net (Fellbaum, 1998).
WSD methods in this cate-gory range from the very simple ranking based oncounting the number of words occurring in both thetarget word?s context and its sense definitions in areference dictionary (Lesk, 1986) to the more elabo-rated approaches using the semantic lexicon?s tax-onomies, (shallow) parsing, collocation discoveryetc.
(Stevenson and Wilks, 2001).One of the central issues of any WSD implemen-tation is given by the context representation.
Thestandard principle that is applied when trying to dis-ambiguate the meaning of a word is that the sameword in similar contexts should have the same mean-ing.
By and large, the context of a target word is ma-terialized by a collection of features among whichare: the collocates of the target word, the part-of-speech (POS) of the target word, ?k words sur-rounding the target word and/or their POSes and soon.
More often than not, the contexts similarity is es-timated by the distance in the feature vector space.Lin (1997) defines the local context of a target wordby the collection of syntactic dependencies in whichthe word takes part.
According to this notion of con-282text, Lin assumes that two different words are likelyto have similar meanings if they occur in identicallocal contexts.What we will attempt here is to combine the twoviews of context similarity/identity versus meaningsimilarity/identity by using a dependency-like repre-sentation of the context as a lexical attraction model.More specifically, we will not consider any featureof the context and will try to maximize a meaning at-traction function over all linked words of a sentence.In section 2 we will describe SynWSD, an unsuper-vised, knowledge-based WSD algorithm and in sec-tions 3 and 4 we will present the application of Syn-WSD to two of SEMEVAL-2007 ?all words?
tasks:English Coarse-Grained and English Fine-Grained.Finally, with section 5 we will conclude the article.2 SynWSDThe syntactic context representation is not new inthe realm of WSD algorithms.
For instance, Lin(1997) used the dependency relations of the targetword to specify its context and Stetina (1998) ex-tracted head-modifier relations to obtain the contextpairs for each word of interest from a constituentstree.
The syntactic representation of the context of atarget word has one main advantage over the collec-tion of features method: the target word is relatedonly with the relevant word(s) in its window andnot with all the words and thus, many noisy cooc-currences are eliminated.
Mel?c?uk (1988) furtherstrengthens the intuition of a syntactic context rep-resentation with his Meaning Text Model in whichthere is a deterministic translation from the surfacesyntactic dependency realization of the sentence toits deep syntactic one and therefore to the semanticrepresentation.To use a syntactic analysis as a context representa-tion, one needs a parser which will supply the WSDalgorithm with the required analysis.
Because wehave intended to develop a language independentWSD algorithm and because there is no available,reliable dependency parser for Romanian, we havebacked off to a simpler, easier to obtain dependency-like representation of a sentence: a slightly modifiedversion of the lexical attraction models of (Yuret,1998).2.1 LexParLexical attraction is viewed as the likelihood of asyntactic dependency relation between two words ofa sentence and is measured by the pointwise mutualinformation between them.
Yuret (1998) shows thatthe search for the lowest entropy lexical attractionmodel leads to the unsupervised discovery of undi-rected dependency relations or links.LexPar (Ion and Barbu Mititelu, 2006) is a linkanalyzer (a linker) which generates a connected,undirected, acyclic and planar graph of an input sen-tence in which the nodes are the words of the sen-tence and the edges are the highest lexical attracteddependency-like relations.
This program is simi-lar to the suboptimal one presented in (Yuret, 1998)with the following main differences:?
the policy of checking pairs of words to be re-lated is based on the assumption that most ofthe syntactic relations2 are formed between ad-jacent words and then between adjacent groupsof linked words;?
it operates on POS-tagged and lemmatized cor-pora and attempts to improve parameter estima-tion by using both lemmas and POS tags.
Thescore of a link is defined as the weighted sumof the pointwise mutual information of the lem-mas and of the POS tags, thus coping even withthe unknown lemmas;?
it uses a rule filter that will deny the formationof certain links based on the POSes of the can-didate words.
For instance, neither the relationbetween a determiner and an adverb nor the re-lation between a singular determiner and a plu-ral noun should be permitted;In Figure 1 we have an example of a XML en-coded, LexPar processed sentence.
The head at-tribute of the w tag specifies the position of the headword of the tagged word.
Because LexPar considersnon-directed dependency relations, for the purposesof XML encoding3, the first word of every sentence2At least for our languages of interest, namely English andRomanian.3The encoding of the morpho-syntactic descriptors (MSD) isMULTEXT-East compliant (http://nl.ijs.si/ME/V3/msd/00README.txt).283Figure 1: The XML representation of a LexPar pro-cessed sentence.
(position 0) is always the root of the syntactic de-pendency tree, its dependents are its children nodes,and so on while we recursively build the tree fromthe LexPar result.We have chosen not to give a detailed presentationof LexPar here (the reader is directed towards (Yuret,1998; Ion and Barbu Mititelu, 2006)) and instead,to briefly explain how the linkage in Figure 1 wasobtained.
The processor begins by inspecting a listG of groups of linked words which initially containsthe positions of each of the words in the sentence:G0 = {(0), (1), (2), (3), (4), (5)}The linking policy is trying to link words in thegroups (0) and (1) or (1) and (2).
The syntacticrule filter says that auxiliary verbs (Va) can onlybe linked with main verbs (Vm) and so one link isformed and the list of groups becomes:G1 = {(0), (?1, 2?
), (3), (4), (5)}Next, the processor must decide linking the groups(?1, 2?)
and (3) or (3) and (4) but the syntactic rulefilter is denying any link from positions 1 or 2 to 3(no links from any kind of verb V to any kind of adeterminer D) or from 3 to 4 (no link from a nega-tive determiner Dz3 to a qualificative adjective Af).Continuing this way, the progress of G list is as fol-lows:G1 = {(0), (?1, 2?
), (3), (?4, 5?
)}G2 = {(?0, 2?, ?1, 2?
), (?3, 5?, ?4, 5?
)}G3 = {(?0, 2?, ?1, 2?, ?2, 5?, ?3, 5?, ?4, 5?
)}So in 3 steps G3 contains a single group of linkedwords namely the linkage of the sentence.2.2 Meaning Affinity ModelsIf the lexical attraction models are geared towardsthe discovery of the most probable syntactic rela-tions of a sentence, we can naturally generalize thisidea to construct a class of models that will find acombination of meanings that maximizes a certainmeaning attraction function over a linkage of a sen-tence.
We call this class of models the meaningaffinity models.Optimizing meaning affinity over a syntactic rep-resentation of a sentence has been tried in (Stetina etal., 1998; Horbovanu, 2002).
SynWSD (Ion, 2007)is an implementation with two phases of the mean-ing affinity concept: training which takes as inputa corpus with LexPar linked sentences (of the typeshown in Figure 1) and outputs a table M of mean-ing co-occurrence frequencies and disambiguationof a LexPar linked sentence S, based on the countsin table M from the previous phase.Before continuing with the descriptions of thesephases, we will introduce the notations that we willuse throughout this section:?
A n-word sentence is represented by a vec-tor S of n elements, each of them contain-ing a triple ?wordform, lemma,POS?.
For in-stance, the first element from S in Figure 1 isS[0] = ?We,we, Pp1?pn?;?
L is the LexPar linkage of S, and is also a vec-tor containing pairs of positions ?i, j?
in S thatare related, where 0 ?
i < j < n;?
lem(S, i) and pos(S, i) are two functions thatgive the lemma and the POS of the position i inS, 0 ?
i < n.The training phase is responsible for collectingmeaning co-occurrence counts.
It simply iteratesover each sentence S of the training corpus and forevery link L[k] of the form ?a, b?
from its linkage,does the following (K stores the total number ofrecorded meaning pairs):1. extracts the sets of meanings Ia and Ib corre-sponding to the lemma lem(S, a) with the POSpos(S, a) and to the lemma lem(S, b) with thePOS pos(S, b) from the sense inventory4;4If the lemma does not appear in the sense inventory or its2842.
increases by 1 the M table frequencies for ev-ery pair of the cartesian product Ia ?
Ib.
Forevery meaning m ?
Ia, the frequency of thespecial pair ?m, ??
is increased with |Ib|.
Simi-larly, the pair ??,m?
frequency is also increasedwith |Ia| for m ?
Ib);3.
K ?
K + |Ia ?
Ib|.We have used the Princeton WordNet (Fellbaum,1998), version 2.0 (PWN20) as our sense inventoryand the mappings from its synsets to the SUMOontology concepts (Niles and Pease, 2003) and tothe IRST domains (Magnini and Cavaglia, 2000).Thus we have tree different sense inventories eachwith a different granularity.
For instance, the nounhomeless has 2 senses in PWN20, its first sense(?someone with no housing?)
being mapped onto themore general Human SUMO concept and onto theperson IRST domain.
The second sense of thesame noun is ?people who are homeless?
which cor-responds to the same SUMO concept and to a differ-ent IRST domain (factotum).In order to reduce the number of recorded pairsin the case of PWN20 meanings (the finest granular-ity available) and to obtain reliable counts, we havemodified the step 1 of the training phase in the fol-lowing manner:?
if we are dealing with nouns or verbs, for everymeaning mi of the lemma, extract the upper-most hypernym meaning which does not sub-sume any other meaning of the same lemma;?
if we are dealing with adjectives, for everymeaning mi of the lemma, extract the meaningof the head adjective if mi is part of a cluster;?
if we are dealing with adverbs, for every mean-ing mi of the lemma, return mi (no generaliza-tion is made available by the sense inventory inthis case).This generalization procedure will be reversed at thetime of disambiguation as will be explained shortly.POS does not give a noun, verb, adjective or adverb, the lemmaitself is returned as the sole meaning because in the disambigua-tion phase we need a meaning for every word of the sentence,be it content word or otherwise.Figure 2: The tree representation of the sentence inFigure 1.The disambiguation phase takes care of findingthe best interpretation of a linked sentence based onthe frequency table M .
For a test sentence S, withthe linkage L, the procedure goes as follows:1. produce a proper tree T of positions from L bytaking position 0 as the root of the tree.
Then,for every link that contains 0 make the other po-sition in the link a child of 0 and then, in a re-cursive manner, apply the same process for allchildren of 0.
For instance, the tree for Figure1 if depicted in Figure 2;2. construct a vector P of sentence positions vis-ited during a depth-first traversal of the T tree.The vector of sentence positions for Figure 2 isP = (0, 2, 5, 3, 5, 4, 5, 2, 1, 2, 0)3. construct a meaning vector V of the samelength as P .
V [i] contains the list of mean-ings of the lemma lem(S, P [i]) with the POSpos(S, P [i]).
If the sense inventory is PWN20,every meaning from the list is generalized asdescribed above;4. finally, apply the Viterbi algorithm ((Viterbi,1967)) on the V vector and extract the path (se-quence of meanings) which maximizes mean-ing affinity.Each state transition is scored according to ameaning affinity function.
In our experiments wehave considered three meaning affinity functions.
IfK is the total number of meaning pairs and if m1285and m2 are two meanings from adjacent V positionsfor which f(m1,m2) is the pair frequency extractedfrom M , the functions are:1.
DICE:dice(m1,m2) =2f(m1,m2)+2f(m2,m1)f(m1,?)+f(?,m1)+f(m2,?)+f(?,m2)2.
Pointwise mutual information:mi(m1,m2) =log Kf(m1,m2)+Kf(m2,m1)(f(m1,?)+f(?,m1))(f(m2,?)+f(?,m2))3.
Log-Likelihood, ll(m1,m2) which is com-puted as in (Moore, 2004).After the Viterbi path (best path) has been calcu-lated, every state (meaning) from V [i] (0 ?
i < |V |)along this path is added to a finalD vector.
When thePWN20 sense inventory is used, the reverse of thegeneralization procedure is applied to each meaningrecorded in D, thus coming back to the meaningsof the words of S. Please note that an entry in Dmay contain more than one meaning especially inthe case of PWN20 meanings for which there wasnot enough training data.3 SEMEVAL-2007 Task #7:Coarse-grained English All-WordsLexPar and SynWSD were trained on an 1 millionwords corpus comprising the George Orwell?s 1984novel and the SemCor corpus (Miller et al, 1993).Both texts have been POS-tagged (with MULTEXT-East compliant POS tags) and lemmatized and theresult was carefully checked by human judges to en-sure a correct annotation.SynWSD was run with all the meaning attractionfunctions (dice, mi and ll) for all the sense in-ventories (PWN20, SUMO categories and IRST do-mains) and a combined result was submitted to thetask organizers.
The combined result was preparedin the following way:1. for each sense inventory and for each tokenidentifier, get the union of the meanings foreach run (dice, mi and ll);2. for each token identifier with its three unionsets of PWN20 meanings, SUMO categoriesand IRST domains:(a) for each PWN20 meaningmi in the union,if there is a SUMO category that mapsonto it, increase mi?s weight by 1;(b) for each PWN20 meaningmi in the union,if there is a IRST domain that maps ontoit, increase mi?s weight by 1;(c) from the set of weighted PWN20 mean-ings, select the subset C that best over-laps with a cluster.
That is, the intersec-tion between the subset and the cluster hasa maximal number of meanings for whichthe sum of weights is also the greatest;(d) output the lowest numbered meaning inC.With this combination, the official F-measure ofSynWSD is 0.65712 which places it into the 11thposition out of 16 competing systems5.Another possible combination is that of the inter-section which is obtained with the exact same stepsas above, replacing the union operation with the in-tersection.
When the PWN20 meanings set is void,we can make use of the most frequent sense (MFS)backoff strategy thus selecting the MFS of the cur-rent test word from PWN20.
Working with the of-ficial key file and scoring software, the intersectioncombination with MFS backoff gives an F-measureof 0.78713 corresponding to the 6th best result.
Thesame combination method but without MFS backoffachieves a precision of 0.80559 but at the cost of avery low F-measure (0.41492).4 SEMEVAL-2007 Task #17: EnglishAll-WordsFor this task, LexPar and SynWSD were furthertrained on a 12 million POS tagged and lemmatizedbalanced corpus6.
The run that was submitted wasthe intersection combination with the MFS backoffstrategy which obtained an F-measure of 0.527.
Thisscore puts our algorithm on the 8th position out of14 competing systems.
For the union combinator5Precision = Recall = F-measure.
In what follows, mention-ing only the F-measure means that this equality holds.6A random subset of the BNC (http://www.natcorp.ox.ac.uk/).286(the MFS backoff strategy is not applicable), the F-measure decreases to 0.445 (10th place).
Finally, ifwe train SynWSD only on corpora from task#7, theunion combinator leads to an F-measure of 0.344.5 ConclusionsSynWSD is a knowledge-based, unsupervised WSDalgorithm that uses a dependency-like analysis of asentence as a uniform context representation.
It is alanguage independent algorithm that doesn?t requireany feature selection.Our system can be improved in several ways.First, one can modify the generalization procedurein the case of PWN20 meanings in the sense of se-lecting a fixed set of top level hypernyms.
The sizeof this set will directly affect the quality of meaningco-occurrence frequencies.
Second, one may studythe effect of a proper dependency parsing on the re-sults of the disambiguation process including heremaking use of the syntactic relations names and ori-entation.Even if SynWSD rankings are not the best avail-able, we believe that the unsupervised approach tothe WSD problem combined with different knowl-edge sources represents the future of these systemseven if, at least during the last semantic evalua-tion exercise SENSEVAL-3, the supervised systemsachieved top rankings.ReferencesChristiane Fellbaum, editor.
1998.
WordNet.
An Elec-tronic Lexical Database.
MIT Press, May.Vladimir Horbovanu.
2002.
Word Sense Disambigua-tion using WordNet.
?Alexandru Ioan Cuza?
Univer-sity, Faculty of Computer Science, Ias?i, Romania.
InRomanian.Radu Ion and Verginica Barbu Mititelu.
2006.
Con-strained lexical attraction models.
In Proceedings ofthe Nineteenth International Florida Artificial Intelli-gence Research Society Conference, pages 297?302,Menlo Park, Calif., USA.
AAAI Press.Radu Ion.
2007.
Word Sense Disambiguation meth-ods applied to English and Romanian.
Ph.D. thesis,Research Institute for Artificial Intelligence (RACAI),Romanian Academy, January.
In Romanian, to be de-fended.Michael Lesk.
1986.
Automatic sense disambiguation :How to tell a pine cone from an ice cream cone.
InProceedings of the 1986 SIGDOC Conference, Asso-ciation for Computing Machinery, pages 24?26, NewYork.Dekang Lin.
1997.
Using syntactic dependency as lo-cal context to resolve word sense ambiguity.
In Pro-ceedings of the 35th Annual Meeting of the Associationfor Computational Linguistics, pages 64?71, Madrid,Spain, July.Bernardo Magnini and Gabriela Cavaglia.
2000.
Inte-grating Subject Field Codes into WordNet.
In Gavrili-dou M., Crayannis G., Markantonatu S., Piperidis S.,and Stainhaouer G., editors, Proceedings of LREC-2000, Second International Conference on LanguageResources and Evaluation, pages 1413?1418, Athens,Greece, June.Igor Mel?c?uk.
1988.
Dependency Syntax: theory andpractice.
State University of New York Press, Albany,NY.George A. Miller, Claudia Leacock, Randee Tengi, andRoss T. Bunker.
1993.
A semantic concordance.In Proceedings of the 3rd DARPA Workshop on Hu-man Language Technology, pages 303?308, Plains-boro, New Jersey.Robert C. Moore.
2004.
On Log-Likelihood Ratios andthe Significance of Rare Events.
In Proceedings ofthe 2004 Conference on Empirical Methods in Natu-ral Language Processing, pages 333?340, Barcelona,Spain.Ian Niles and Adam Pease.
2003.
Linking Lexiconsand Ontologies: Mapping WordNet to the SuggestedUpper Merged Ontology.
In Proceedings of the 2003International Conference on Information and Knowl-edge Engineering (IKE 03), Las Vegas, Nevada, June.Jiri Stetina, Sadao Kurohashi, and Makoto Nagao.
1998.General word sense disambiguation method based ona full sentential context.
In Proceedings of the Coling-ACL?98 Workshop ?Usage of WordNet in Natural Lan-guage Processing Systems?, pages 1?8, Montreal.Mark Stevenson and YorickWilks.
2001.
The interactionof knowledge sources in word sense disambiguation.Computational Linguistics, 27(3):321?349.Andrew J. Viterbi.
1967.
Error bounds for convolu-tional codes and an asymptotically optimum decodingalgorithm.
IEEE Transactions on Information Theory,IT(13):260?269, April.Deniz Yuret.
1998.
Discovery of linguistic relationsusing lexical attraction.
Ph.D. thesis, Department ofComputer Science and Electrical Engineering, MIT,May.287
