Learning Domain-Specific Transfer Rules:An Experiment with Korean to English TranslationBenoit Lavoie, Michael White, and Tanya KorelskyCoGenTex, Inc.840 Hanshaw RoadIthaca, NY 14850, USAbenoit,mike,tanya@cogentex.comAbstractWe describe the design of an MT system that em-ploys transfer rules induced from parsed bitextsand present evaluation results.
The system learnslexico-structural transfer rules using syntactic pat-tern matching, statistical co-occurrence and error-driven filtering.
In an experiment with domain-specific Korean to English translation, the approachyielded substantial improvements over three base-line systems.1 IntroductionIn this paper, we describe the design of an MTsystem that employs transfer rules induced fromparsed bitexts and present evaluation results for Ko-rean to English translation.
Our approach is basedon lexico-structural transfer (Nasr et.
al., 1997),and extends recent work reported in (Han et al,2000) about Korean to English transfer in particular.Whereas Han et al focus on high quality domain-specific translation using handcrafted transfer rules,in this work we instead focus on automating the ac-quisition of such rules.The proposed approach is inspired by example-based machine translation (EBMT; Nagao, 1984;Sato and Nagao, 1990; Maruyama and Watanabe,1992) and is similar to the recent works of (Mey-ers et al, 1998) and (Richardson et al, 2001) wheretransfer rules are also derived after aligning thesource and target nodes of corresponding parses.However, while (Meyers et al, 1998) and (Richard-son et al, 2001) only consider parses and ruleswith lexical labels and syntactic roles, our approachuses parses containing any syntactic informationprovided by parsers (lexical labels, syntactic roles,tense, number, person, etc.
), and derives rules con-sisting of any source and target tree sub-patternsmatching a subset of the parse features.
A more de-tailed description of the differences can be found in(Lavoie et.
al., 2001).2 Overall Runtime System DesignOur Korean to English MT runtime system relies onthe following off-the-shelf software components:Korean parser For parsing, we used the wide cov-erage syntactic dependency parser for Koreandeveloped by (Yoon et al, 1997).
The parserwas not trained on our corpus.Transfer component For transfer of the Koreanparses to English structures, we used the samelexico-structural transfer framework as (Lavoieet al, 2000).Realizer For surface realization of the transferredEnglish syntactic structures, we used the Re-alPro English realizer (Lavoie and Rambow,1997).The training of the system is described in the nexttwo sections.3 Data Preparation3.1 Parses for the BitextsIn our experiments, we used a parallel corpus de-rived from bilingual training manuals provided bythe U.S. Defense Language Institute.
The corpusconsists of a Korean dialog of 4,183 sentences aboutbattle scenario message traffic and their English hu-man translations.The parses for the Korean sentences were ob-tained using Yoon?s parser, as in the runtime sys-tem.
The parses for the English human transla-(S1) {i} {Ci-To-Reul} {Ta-Si} {Po-Ra}.this + map-accusative + again + look-imp(D1) {po} [class=vbma ente={ra}] (s1 {ci-to} [class=nnin2 ppca={reul}] (s1 {i} [class=ande] )s1 {ta-si} [class=adco2] )(S2) Look at the map again.
(D2) look [class=verb mood=imp] (attr at [class=preposition] (ii map [class=common_noun article=def] )attr again [class=adverb] )Figure 1: Syntactic dependency representations forcorresponding Korean and English sentencesKorean EnglishAvg.
sentence size 9.08 13.26Avg.
parse size 8.96 10.77Table 1: Average sizes for sentences and parses incorpustions were derived from an English Tree Bank de-veloped in (Han et al, 2000).
To enable the sur-face realization of the English parses via RealPro,we automatically converted the phrase structuresof the English Tree Bank into deep-syntactic de-pendency structures (DSyntSs) of the Meaning-TextTheory (MTT) (Mel?c?uk, 1988) using Xia?s con-verter (Xia and Palmer, 2001) and our own conver-sion grammars.
The realization results of the re-sulting DSyntSs for our training corpus yielded aunigram and bigram accuracy (f-score) of approxi-mately 95% and 90%, respectively.A DSyntS is an unordered tree where all nodesare meaning-bearing and lexicalized.
Since the out-put of the Yoon parser is quite similar, we have usedits output as is.
The syntactic dependency represen-tations for two corresponding Korean1 and Englishsentences are shown in Figure 1.3.2 Training and Test Sets of Parse PairsThe average sentence lengths (in words) and parsesizes (in nodes) for the 4,183 Korean and Englishsentences in our corpus are given in Table 1.In examining the Korean parses, we found thatmany of the larger parses, especially those contain-ing intra-sentential punctuation, had incorrect de-pendency assignments, incomplete lemmatizationor were incomplete parses.
In examining the En-glish converted parses, we found that many of1Korean is represented in romanized format in this paper.Korean EnglishAvg.
sentence size 6.43 9.36Avg.
parse size 6.43 7.34Table 2: Average sizes for sentences and parses intraining setKorean EnglishAvg.
sentence size 7.04 10.58Avg.
parse size 7.02 8.56Table 3: Average sizes for sentences and parses intest setthe parses containing intra-sentential punctuationmarks other than commas had incorrect dependencyassignments, due to the limitations of our conver-sion grammars.
Consequently, in our experimentswe have primarily focused on a higher quality sub-set of 1,483 sentence pairs, automatically selectedby eliminating from the corpus all parse pairs whereone of the parses contained more than 11 contentnodes or involved problematic intra-sentential punc-tuation.We divided this higher quality subset into trainingand test sets.
For the test set, we randomly selected50 parse pairs containing at least 5 nodes each.
Forthe training set, we used the remaining 1,433 parsepairs.
The average sentence lengths and parse sizesfor the training and test sets are represented in Ta-bles 2 and 3.3.3 Creating the Baseline Transfer DictionaryIn our system, transfer dictionaries contain Ko-rean to English lexico-structural transfer rules de-fined using the formalism described in (Nasr et.al., 1997), extended to include log likelihood ra-tios (Manning and Schutze, 1999: 172-175).
Sam-ple transfer rules are illustrated in Section 4.
Thesimplest transfer rules consist of direct lexical map-pings, while the most complex may contain sourceand target syntactic patterns composed of multiplenodes defined with lexical and/or syntactic features.Each transfer rule is assigned a log likelihood ratiocalculated using the training parse set.To create the baseline transfer dictionary for ourexperiments, we had three bilingual dictionary re-sources at our disposal:A corpus-based handcrafted dictionary: Thisdictionary was manually assembled by (Han etal., 2000) for the same corpus used here.
Note,Korean EnglishLexical coverage 92.18% 90.17%Table 4: Concurrent lexical coverage of training setby baseline dictionaryhowever, that it was developed for differentparse representations, and with an emphasisprimarily on the lexical coverage of the sourceparses, rather than the source and target parsepairs.A corpus-based extracted dictionary: This dic-tionary was automatically created from ourcorpus by the RALI group from the Universityof Montreal.
Since the extraction heuristicsdid not handle the rich morphological suffixesof Korean, the extraction results containedinflected words rather than lexemes.A wide coverage dictionary: This dictionary of70,300 entries was created by Systran, withoutregard to our corpus.We processed and combined these resources asfollows: First, we replaced the inflected words with un-inflected lexemes using Yoon?s morphologicalanalyzer and a wide coverage English morpho-logical database (Karp and Schabes, 1992). Second, we merged all morphologically an-alyzed entries after removing all non-lexicalfeatures, since these features generally did notmatch those found in the parses. Third, we matched the resulting transfer dictio-nary entries with the training parse set, in orderto determine for each entry all possible part-of-speech instantiations and dependency relation-ships.
For each distinct instantiation, we cal-culated a log likelihood ratio. Finally, we created a baseline dictionary us-ing the instantiated rules whose source patternshad the best log likelihood ratios.Table 4 illustrates the concurrent lexical coverageof the training set using the resulting baseline dictio-nary, i.e.
the percentage of nodes covered by ruleswhose source and target patterns both match.
Notethat since the baseline dictionary contained somenoise, we allowed induced rules to override ones inthe baseline dictionary where applicable.
@KOREAN:{po} [class=vbma] (s1 $X [ppca={reul}] )@ENGLISH:look [class=verb] (attr at [class=preposition] (ii $X ))@-2xLOG_LIKELIHOOD: 12.77Figure 2: Transfer rule for English lexicalizationand preposition insertion4 Transfer Rule InductionThe transfer rule induction process has the follow-ing steps described below (additional details canalso be found in (Lavoie et.
al., 2001)): Nodes of the corresponding source and targetparses are aligned using the baseline transferdictionary and some heuristics based on thesimilarity of part-of-speech and syntactic con-text. Transfer rule candidates are generated basedon the sub-patterns that contain the corre-sponding aligned nodes in the source and targetparses. The transfer rule candidates are ordered basedon their likelihood ratios. The transfer rule candidates are filtered, one ata time, in the order of the likelihood ratios, byremoving those rule candidates that do not pro-duce an overall improvement in the accuracy ofthe transferred parses.Figures 2 and 3 show two sample induced rules.The rule formalism uses notation similar to thesyntactic dependency notation shown in Figure 1,augmented with variable arguments prefixed with$ characters.
These two lexico-structural rules canbe used to transfer a Korean syntactic representationfor ci-to-reul po-ra to an English syntactic represen-tation for look at the map.
The first rule lexicalizesthe English predicate and inserts the correspondingpreposition while the second rule inserts the Englishimperative attribute.4.1 Aligning the Parse NodesTo align the nodes in the source and target parsetrees, we devised a new dynamic programming@KOREAN:$X [class=vbma ente={ra}]@ENGLISH:$X [class=verb mood=imp]@-2xLOG_LIKELIHOOD: 33.37Figure 3: Transfer rule for imperative formsalignment algorithm that performs a top-down, bidi-rectional beam search for the least cost mapping be-tween these nodes.
The algorithm is parameterizedby the costs of (1) aligning two nodes whose lex-emes are not found in the baseline transfer dictio-nary; (2) aligning two nodes with differing parts ofspeech; (3) deleting or inserting a node in the sourceor target tree; and (4) aligning two nodes whose rel-ative locations differ.To determine an appropriate part of speech costmeasure, we first extracted a small set of parse pairsthat could be reliably aligned using lexical matchingalone, and then based the cost measure on the co-occurrence counts of the observed parts of speechpairings.
The remaining costs were set by hand.As a result of the alignment process, alignment idattributes (aid) are added to the nodes of the parsepairs.
Some nodes may be in alignment with noother node, such as English prepositions not foundin the Korean DSyntS.4.2 Generating Rule CandidatesCandidate transfer rules are generated by extractingsource and target tree sub-patterns from the alignedparse pairs using the two set of constraints describedbelow.4.2.1 Alignment constraintsFigure 4 shows an example alignment constraint.This constraint, which matches the structural pat-terns of the transfer rule illustrated in Figure 2, usesthe aid alignment attribute to indicate that in a Ko-rean and English parse pair, any source and targetsub-trees matching this alignment constraint (where$X1 and $Y1 are aligned, i.e.
have the same aid at-tribute values, and where $X2 and $Y3 are aligned)can be used as a point of departure for generat-ing transfer rule candidates.
We suggest that align-ment constraints such as this one can be used to de-fine most of the possible syntactic divergences be-tween languages (Dorr, 1994), and that only a hand-ful of them are necessary for two given languages(we have identified 11 general alignment constraints@KOREAN:$X1 [aid=$1] ($R1 $X2 [aid=$2] )@ENGLISH:$Y1 [aid=$1] ($R2 $Y2 ($R3 $Y3 [aid=$2] ) )Figure 4: Alignment constraintEach node of a candidate transfer rule must haveits relation attribute (relationship with its governor)specified if it is an internal node, otherwise this relationmust not be specified:e.g. $X1 ( $R $X2 )Figure 5: Independent attribute constraintnecessary for Korean to English transfer so far).4.2.2 Attribute constraintsAttribute constraints are used to limit the space ofpossible transfer rule candidates that can be gen-erated from the sub-trees satisfying the alignmentconstraints.
Candidate transfer rules must satisfy allof the attribute constraints.
Attribute constraints canbe divided into two types: independent attribute constraints, whose scopecovers only one part of a candidate transfer ruleand which are the same for the source and tar-get parts; concurrent attribute constraints, whose scopeextends to both the source and target parts of acandidate transfer rule.Figures 5 and 6 give examples of an indepen-dent attribute constraint and of a concurrent attributeconstraint.
As with the alignment constraints, wesuggest that a relatively small number of attributeconstraints is necessary to generate most of the de-sired rules for a given language pair.4.3 Ordering Rule CandidatesIn the next step, transfer rule candidates are orderedas follows.
First, they are sorted by their decreasinglog likelihood ratios.
Second, if two or more can-didate transfer rules have the same log likelihoodratio, ties are broken by a specificity heuristic, withthe result that more general rules are ordered aheadIn a candidate transfer rule, inclusion of the lexemes oftwo aligned nodes must be done concurrently:e.g.$X [aid=$1]and$Y [aid=$1]e.g. [aid=$1]and [aid=$1]Figure 6: Concurrent attribute constraintof more specific ones.
The specificity of a rule isdefined to be the following sum: the number of at-tributes found in the source and target patterns, plus1 for each for each lexeme attribute and for each de-pendency relationship.
In our initial experiments,this simple heuristic has been satisfactory.4.4 Filtering Rule CandidatesOnce the candidate transfer rules have been ordered,error-driven filtering is used to select those that yieldimprovements over the baseline transfer dictionary.The algorithm works as follows.
First, in the initial-ization step, the set of accepted transfer rules is setto just those appearing in the baseline transfer dic-tionary.
The current error rate is also established, byapplying these transfer rules to all the source struc-tures and calculating the overall difference betweenthe resulting transferred structures and the targetparses, using a tree accuracy recall and precisionmeasure (determined by comparing the features anddependency relationships in the transferred parsesand corresponding target parses).
Then, in a sin-gle pass through the ordered list of candidates, eachtransfer rule candidate is tested to see if it reducesthe error rate.
During each iteration, the candidatetransfer rule is provisionally added to the current setof accepted rules and the updated set is applied toall the source structures.
If the overall difference be-tween the transferred structures and the target parsesis lower than the current error rate, then the can-didate is accepted and the current error rate is up-dated; otherwise, the candidate is rejected and re-moved from the current set.4.5 Discussion of Induced RulesIn our experiments, the alignment constraintsyielded 22,881 source and target sub-tree pairs fromthe training set of 1,433 parse pairs.
Using the at-@KOREAN:{po} [class=vbma ente={ra}] (s1 $X [ppca={reul}] )@ENGLISH:look [class=verb mood=imp] (attr at [class=preposition] (ii $X ) )@-2xLOG_LIKELIHOOD: 11.40Figure 7: Transfer rule for English imperative withlexicalization and preposition insertiontribute constraints, an initial list of 801,674 trans-fer rule candidates was then generated from thesesub-tree pairs.
The initial list was subsequently re-duced to 32,877 unique transfer rule candidates byremoving duplicates and by eliminating candidatesthat had the same source pattern as another candi-date with a better log likelihood ratio.
After filter-ing, 2,133 of these transfer rule candidates were ac-cepted.
We expect that the number of accepted rulesper parse pair will decrease with larger training sets,though this remains to be verified.The rule illustrated in Figure 3 was accepted asthe 65th best transfer rule with a log likelihood ra-tio of 33.37, and the rule illustrated in Figure 2 wasaccepted as the 189th best transfer rule candidatewith a log likelihood ratio of 12.77.
An exampleof a candidate transfer rule that was not accepted isthe one that combines the features of the two rulesmentioned above, illustrated in Figure 7.
This trans-fer rule candidate had a lower log likelihood ratio of11.40; consequently, it is only considered after thetwo rules mentioned above, and since it provides nofurther improvement upon these two rules, it is fil-tered out.In an informal inspection of the top 100 acceptedtransfer rules, we found that most of them appearto be fairly general rules that would normally befound in a general syntactic-based transfer dictio-nary.
In looking at the remaining rules, we foundthat the rules tended to become increasingly corpus-specific.The induction results were obtained using a Javaimplementation of the induction component.
Mi-crosoft SQL Server was used to count and dedupli-cate the rule candidates.
The data preparation andinduction processes took about 12 hours on a 300MHz PC with 256 MB RAM.5 Evaluation5.1 Systems ComparedBabelfish As a first baseline, we used Babelfishfrom Systran, a commercial large coverage MTsystem supporting Korean to English transla-tion.
This system was not trained on our cor-pus.GIZA++/RW As a second baseline, we used anoff-the-shelf statistical MT system, consistingof the ISI ReWrite Decoder (Germann et al,2001) together with a translation model pro-duced by GIZA++ (Och and Ney, 2000) anda language model produced by the CMU Sta-tistical Language Modeling Toolkit (Clarksonand Rosenfeld, 1997).
This system was trainedon our corpus only.Lex Only As a third baseline, we used our systemwith the baseline transfer dictionary as the soletransfer resource.Lex+Induced We compared the three baseline sys-tems against our complete system, using thebaseline transfer dictionary augmented withthe induced transfer rules.We ran each of the four systems on the test setof 50 Korean sentences described in Section 3.2and compared the resulting translations using theautomatic evaluation and the human evaluation de-scribed below.5.2 Automatic Evaluation ResultsFor the automatic evaluation, we used the Bleu met-ric from IBM (Papineni et al, 2001).
The Bleumetric combines several modified N-gram precisionmeasures (N = 1 to 4), and uses brevity penalties topenalize translations that are shorter than the refer-ence sentences.Table 5 shows the Bleu N-gram precision scoresfor each of the four systems.
Our system(Lex+Induced) had better precision scores than eachof the baseline systems, except in the case of 4-grams, where it slightly trailed Babelfish.
The sta-tistical baseline system (GIZA++/RW) performedpoorly, as might have been expected given the smallamount of training data.Table 6 shows the Bleu overall precision scores.Our system (Lex+Induced) improved substantiallyover both the Lex Only and Babelfish baseline sys-tems.
The score for the statistical baseline system(GIZA++/RW) is not meaningful, due to the ab-sence of 3-gram and 4-gram matches.System 1-g Prec 2-g Prec 3-g Prec 4-g PrecBabelfish 0.3814 0.1207 0.0467 0.0193GIZA++/RW 0.1894 0.0173 0.0 0.0Lex Only 0.4234 0.1252 0.0450 0.0145Lex+Induced 0.4725 0.1618 0.0577 0.0185Table 5: Bleu N-gram precision scoresSystem Bleu ScoreBabelfish 0.0802GIZA++/RW NALex Only 0.0767Lex+Induced 0.0950Table 6: Bleu overall precision scores5.3 Human Evaluation ResultsFor the human evaluation, we asked two Englishnative speakers to rank the quality of the transla-tion results produced by the Babelfish, Lex Onlyand Lex+Induced, with preference given to fidelityover fluency.
(The translation results of the statisti-cal system were not yet available when the evalua-tion was performed.)
A rank of 1 was assigned tothe best translation, a rank of two to the second bestand a rank of 3 to the third, with ties allowed.Table 7 shows the pairwise comparisons of thethree systems.
The top section indicates that theBabelfish and Lex Only baseline systems are es-sentially tied, with neither system preferred morefrequently than the other.
In contrast, the middleand bottom sections show that our system improvessubstantially over both baseline systems; most strik-ingly, our system (Lex+Induced) was preferred al-most 20% more frequently than the Babelfish base-line (46% to 27%, with ties 27% of the time).System Pair Comparison ResultBabelfish better than Lex Only 37%Lex Only better than Babelfish 36%Babelfish same as Lex Only 27%Babelfish better than Lex+Induced 27%Lex+Induced better than Babelfish 46%Babelfish same as Lex+Induced 27%Lex Only better than Lex+Induced 18%Lex+Induced better than Lex Only 41%Lex Only same as Lex+Induced 41%Table 7: Human evaluation results6 Conclusion and Future WorkIn this paper we have described the design of an MTsystem based on lexico-structural transfer rules in-duced from parsed bitexts.
In a small scale exper-iment with Korean to English translation, we havedemonstrated a substantial improvement over threebaseline systems, including a nearly 20% improve-ment in the preference rate for our system over Ba-belfish (which was not trained on our corpus).
Al-though our experimentation was aimed at Koreanto English translation, we believe that our approachcan be readily applied to other language pairs.It remains for future work to explore how wellthe approach would fare with a much larger train-ing corpus.
One foreseeable problem concerns thetreatment of lengthy training sentences: since thenumber of transfer rule candidates generated growsexponentially with the size of the parse tree pairs,refinements will be necessary in order to make useof complex sentences; one option might be to auto-matically chunk longer sentences into smaller units.AcknowledgementsWe thank Richard Kittredge for helpful discussion, Daryl Mc-Cullough and Ted Caldwell for their help with evaluation andFei Xia for her assistance with the automatic conversion ofthe phrase structure parses to syntactic dependency represen-tations.
We also thank Chung-hye Han, Chulwoo Park, MarthaPalmer, and Joseph Rosenzweig for the handcrafted Korean-English transfer dictionary, and Graham Russell for the corpus-based extracted transfer dictionary.
This work has been par-tially supported by DARPA TIDES contract no.
N66001-00-C-8009.ReferencesPhilip Clarkson and Ronald Rosenfeld.
1997.
Statistical Lan-guage Modeling Using the CMU-Cambridge Toolkit.
InProceedings of Eurospeech?97.Bonnie Dorr.
1994.
Machine translation divergences: A for-mal description and proposed solution.
Computational Lin-guistics, 20(4):597?635.Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcuand Kenji Yamada.
2001.
Fast Decoding and Optimal De-coding for Machine Translation.
In Proceedings of ACL?01,Toulouse, France.Chung hye Han, Benoit Lavoie, Martha Palmer, OwenRambow, Richard Kittredge, Tanya Korelsky, Nari Kim,and Myunghee Kim.
2000.
Handling Structural Diver-gences and Recovering Dropped Arguments in a Korean-English Machine Translation System.
In Proceedings of theFourth Conference on Machine Translation in the Americas(AMTA?00), Mision Del Sol, Mexico.Daniel Karp and Yves Schabes.
1992.
A Wide CoveragePublic Domain Morphological Analyzer for English.
InProceedings of the Fifteenth International Conference onComputational Linguistics (COLING?92), pages 950?955,Nantes, France.Benoit Lavoie and Owen Rambow.
1997.
RealPro ?
A Fast,Portable Sentence Realizer.
In Proceedings of the Confer-ence on Applied Natural Language Processing (ANLP?97),Washington, DC.Benoit Lavoie, Richard Kittredge, Tanya Korelsky, and OwenRambow.
2000.
A framework for MT and multilingualNLG systems based on uniform lexico-structural process-ing.
In Proceedings of ANLP/NAACL 2000, Seattle, Wash-ington.Benoit Lavoie, Michael White, and Tanya Korelsky.
2001.
In-ducing Lexico-Structural Transfer Rules from Parsed Bi-texts.
In Proceedings of the ACL 2001 Workshop onData-driven Machine Translation, pages 17?24, Toulouse,France.Christopher D. Manning and Hinrich Schutze.
1999.
Foun-dations of Statistical Natural Language Processing.
MITPress.H.
Maruyama and H. Watanabe.
1992.
Tree cover SearchAlgorithm for Example-Based Translation.
In Proceedingsof the Fourth International Conference on Theoretical andMethodological Issues in Machine Translation (TMI?92),pages 173?184.Yuji Matsumoto, Hiroyuki Hishimoto, and Takehito Utsuro.1993.
Structural Matching of Parallel Texts.
In Proceedingsof the 31st Annual Meetings of the Association for Compu-tational Linguistics (ACL?93), pages 23?30.Igor Mel?c?uk.
1988.
Dependency Syntax.
State University ofNew York Press, Albany, NY.Adam Meyers, Roman Yangarber, Ralph Grishman, CatherineMacleod, and Antonio Moreno-Sandoval.
1998.
DerivingTransfer Rules from Dominance-Preserving Alignments.
InProceedings of COLING-ACL?98, pages 843?847.Makoto Nagao.
1984.
A framework of a mechanical transla-tion between Japenese and English by analogy principle.
InA.
Elithorn and R. Banerji, editors, Artificial and HumanIntelligence.
NATO Publications.Alexis Nasr, Owen Rambow, Martha Palmer, and JosephRosenzweig.
1997.
Enriching lexical transfer with cross-linguistic semantic features.
In Proceedings of the Interlin-gua Workshop at the MT Summit, San Diego, California.Franz Josef Och and Hermann Ney.
2000.
Improved StatisticalAlignment Models.
In Proceedings of ACL?00, pages 440?447, Hongkong, China.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2001.
Bleu: a Method for Automatic Evaluation ofMachine Translation.
In IBM technical report, RC22176.Stephen D. Richardson, William B. Dolan, Arul Menezes, andMonica Corston-Oliver.
2001.
Overcoming the Customiza-tion Bottleneck using Example-based MT.
In Proceedingsof the ACL 2001 Workshop on Data-driven Machine Trans-lation, pages 9?16, Toulouse, France.Satoshi Sato and Makoto Nagao.
1990.
Toward Memory-based Translation.
In Proceedings of the 13th InternationalConference on Computational Linguistics (COLING?90),pages 247?252.Fei Xia and Martha Palmer.
2001.
Converting DependencyStructures to Phrase Structures.
In Notes of the First HumanLanguage Technology Conference, San Diego, California.Juntae Yoon, Seonho Kim, and Mansuk Song.
1997.
Newparsing method using global association table.
In Proceed-ings of the 5th International Workshop on Parsing Technol-ogy.
