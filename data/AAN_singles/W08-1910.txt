Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 73?76Manchester, August 2008The "Close-Distant" Relation of Adjectival ConceptsBased on Self-Organizing MapKyoko Kanzaki, Hitoshi IsaharaNational Institute of Information andCommunications Technology3-5, Hikaridai, Seikacho,Sorakugun, Kyoto, 619-0289,Japan{kanzaki,isahara}@nict.go.jpNoriko TomuroSchool of Computer Science, Telecom-munications and Information SystemsDePaul UniversityChicago, IL 60604U.S.Atomuro@cs.depaul.eduAbstractIn this paper we aim to detect some as-pects of adjectival meanings.
Concepts ofadjectives are distributed by SOM (Self-Organizing map) whose feature vectorsare calculated by MI (Mutual Informa-tion).
For the SOM obtained, we maketight clusters from map nodes, calculatedby cosine.
In addition, the number oftight clusters obtained by cosine was in-creased using map nodes and Japanesethesaurus.
As a result, the number of ex-tended clusters of concepts was 149 clus-ters.
From the map, we found 8 adjectivalclusters in super-ordinate level and sometendencies of similar and dissimilar clus-ters.1 IntroductionThis paper aims to find a diversity range of ad-jectival meanings from a coordinate map inwhich  "close-distant" relationships between ad-jectival classes is reflected.
In related researchover adjectives, Alonge et.al (2000), Solar (2003),Marrafa and Mendes (2006) suggested thatWordNet and EuroWordNet lack sufficient ad-jectival classes and semantic relations, and  ex-tended the resources over such relations.For the sake of identifying the diversity of ad-jectival meanings, it is necessary to analyze ad-jectival semantics via "close-distant" relation-ships extracted from texts.
In our work on ex-tracting adjective semantics, we consider abstractnouns as semantic proxies of adjectives.
For theclustering method, we utilized a self-organizing?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.map (SOM) based on a neural network model(Kohonen, 1997).
One of the features of SOM isthat it assigns words coordinates, allowing forthe possibility of visualizing word similarity.SOM has two advantages for our task.
One isthat we can utilize the map nodes of words tolocate members of clusters that clustering meth-ods have failed to classify.
The other is that themap shows the relative relations of whole clus-ters of adjectival concepts.
By observing such amap in which the relations of clusters are re-flected, we can analyze the diversity of adjectivalmeaning.2 Abstract Nouns that Categorize Ad-jectivesCollocations between adjectives and nouns in?concrete value and its concept?
relations can beused to represent adjectival semantics.
Nemoto(1969) indicated that expressions such as ?iro gaakai (the color is red)?
and ?hayasa ga hayai(literally, the speed is fast)?
are a kind oftautology.
Some studies have suggested thatsome abstract nouns collocating with adjectivesare hypernymic concepts (or concepts) of thoseadjectives, and that some semantic relationsbetween abstract nouns and adjectives representa kind of repetition of meaning.This paper defines such abstract nouns as thesemantic categorization of an adjective (or anadjectival concept).The data for this study was obtained by ex-tracting adjectives co-occurring with abstractnouns in 100 novels, 100 essays, and 42 years ofnewspaper articles.We extracted the abstract nouns according tothe procedure described by Kanzaki et.al (2006).Here, they evaluated the category labels of adjec-tives obtained by the proposed procedure andfound that for 63% of the adjectives, the ex-73tracted categories were found to be appropriate.We constructed a list as follows:Abstract Nouns:Adjectives modifying abstract nounsKIMOCHI (feeling):ureshii (glad), kanashii (sad),shiawasena (happy) ?In this list,  ?KIMOCHI (feeling)?
is defined by?ureshii (glad), kanashii (sad), and shiawasena(happy)?, for example.
Here, each abstract nounconveys the concept or hypernym of the givenadjectives.Next we classify these abstract nouns based ontheir co-occurring adjectives using SOM.3.
A Map of Adjective Semantics3.1 Input DataIn our SOM, we use adjectives which occur morethan four times in our corpus.
The number ofsuch adjectives was 2374.
Then we identified361 abstract nouns that co-occurred with four ormore of the adjectives.
The maximum number ofco-occurring adjectives for a given abstract nounin the corpus was 1,594.In the data, each abstract noun was defined bya feature vector, in the form of noun co-occurrences represented by pointwise mutualinformation (Manning and Schutze, 1999).
Mu-tual information (MI) is an information theoricmeasure and has been used in many NLP tasks,including clustering words (e.g.
Lin and Pantel,2002).3.2 SOMKohonen?s self-organizing map (SOM) is an un-supervised learning method, where input in-stances are projected onto a grid/map of nodesarranged in an n-dimensional space.
Input in-stances are usually high-dimensional data, whilethe map is usually two-dimensional (i.e., n = 2).Thus, SOM essentially reduces the dimensional-ity of the data, and can be used as an effectivetool for data visualization ?
projecting complex,high-dimensional data onto a low-dimensionalmap.
SOM can also be utilized for clustering.Each node in a map represents a cluster and isassociated with a reference vector of m-dimensions, where m is the dimension of the in-put instances.
During learning, input instancesare mapped to a map node whose (current) refer-ence vector is the closest to the instance vector(where SOM uses Euclidean distance as themeasure of similarity by default), and the refer-ence vectors are gradually smoothed so that thedifferences between the reference vector and theinstance vectors mapped to the node are mini-mized.
This way, instances mapped to the samenode form a cluster, and the reference vector es-sentially corresponds to the centroid of the clus-ter.SOM maps are self-organizing in the sensethat input instances that are similar are graduallypulled closer during learning and assigned tonodes that are topographically close to one an-other on the map.
The mapping from input in-stances to map nodes is one-to-one (i.e., one in-stance is assigned to exactly one node), but frommap nodes to instances, the mapping is one-to-many (i.e., one map node is assigned to zero, one,or more instances).The input data was the set of 361 abstractnouns defined by the 2,374 co-occurring adjec-tives, as described in the previous section.
Theseabstract nouns were distributed visually on the 2-dimensional map based on co-occurring adjec-tives.
This map is a ?map of adjective semantics?because the abstract nouns are identified as prox-ies for adjective semantics.As mentioned before, similar words are lo-cated in neighboring nodes on the 2-dimensionalmap.
The next step is to identify similar clusterson the map.4.
Clusters of Adjective Semantics4.1 Tight Clusters from the Map NodesIn SOMs, each node represents a cluster, i.e.
a setof nouns assigned to the same node.
These nounsare very similar and can be considered to besynonyms.
However, nouns that are similarmight map to different nodes because the algo-rithm?s self-organization is sensitive to the pa-rameter settings.
To account for this, and also toobtain a more (coarse-grained) qualitative de-scription of the map, tight clusters?clusters ofmap nodes whose reference vectors are signifi-cantly close?were extracted.
All groupings ofmap nodes whose average cosine coefficient be-tween the reference vectors in the group wasgreater than 0.96 were extracted (Salton andMcGill, 1983).4.2 ResultThe total number of clusters was 213.
Excludingsingleton clusters, the number of clustes was 81.229 concepts were classified into 81 clusters,with 132 concepts not classified into any cluster.74In order to evaluate the quality of the concep-tual classification, we utilized the ?Bunruigoi-hyou?
Japanese thesaurus (National Institute ofJapanese Language, 1964).
In ?Bunruigoihyou,?each category is assigned a 5-digit categorynumber, with close numbers indicating similarcategories.Among the 81 with two or more concepts, thenumber of clusters containing words with thesame class was 36.
That is, for 44% of the clus-ters, the constituent nouns had the same ?Bun-ruigoihyou?
class label.
The ratio of conceptagreement between "Bunruigiohyou?
and ourobtained clusters was found to be  20.87/81=0.25.We also compared tight clusters by performinghierarchical clustering with the k-means algo-rithm.The results of the hierarchical clustering were asfollows:1) The rate of clusters agreeing with ?Bunruigoi-hyou?
: 30/96 = 0.312) The average rate of agreement for each tightcluster: 21.07/96 = 0.21In the case of k-means:3)The rate of clusters agreeing with ?Bunruigoi-hyou?
: 33/143 = 0.234) The average rate of agreement for each tightcluster: 28.37/143 = 0.198From these results, we can observe that clus-ters obtained with cosine similarity agree morewith the Japanese thesaurus than the other twomethods.
Therefore, in terms of quality, clustersobtained by cosine similarity seem to be superiorto the others.4.3 Using the Position of Map NodesHowever, even for the result obtained with co-sine similarity, 132 concepts were not classifiedinto any clusters.
Additionally, the clusters ap-pear to be overly fine grained: most tight clustersinclude 1, 2 or 3 concepts.
In order to find simi-lar concepts that cosine similarity failed to clus-ter together, we used the position information ofthe map nodes.After we plotted clusters obtained by cosinesimilarity on the map, we checked for singletonconcepts located near a cluster which are mem-bers of the same ?Bunruigoihyou?
class.
Also,we checked to see if concepts in clusters locatedat neighboring nodes could be clustered togetherusing the category numbers of ?Bunruigoihyou.
?By extending the clusters, we generated a totalof 149 clusters, including 68 with two or moreelements and 81 singleton clusters.5.
Interpreting the Adjectival ClustersIn our final map, 361 concepts were distributedbased on 2374 adjectives into 149 clusters.Among the 149 clusters, 68 contained two ormore concepts.5.1 ?Close-Distant?
Relations of Clusters andAdjectivesIn the final map, clusters at the superordinatelevel are located around the center of the map.Upper level concepts tend to agree with clustersin ?Bunruigoihyou.?
For examples, ?image andimpression,?
?situation and state?, ?feeling andmood?
are located around the center of the map.Cluster1 (Center of the map): koto (matter),in?shou (impression), men (side of some-thing or someone), and kankaku(sense/feeling)Cluster2: seishitsu (characteristics of some-one/something), yousou (aspect)Cluster3: kanten (viewpoint), tachiba (stand-point), bun?ya (domain)Cluster4: taido (attitude), yarikata (way of do-ing)Cluster5: gaikan, gaiken, sugata (outlook andappearance of someone/something)Cluster6:  fun?iki, kuuki, kehai (atmosphere)Cluster7:  kimochi, kanji (feeling)Cluster8:  joutai (state), joukyou (situation)In our experiment, at the top level, adjectivalconcepts seem to be divided into 8 basic clusters.From the distribution of the map, we find ?close-distant?
relationships between clusters, that isclusters located far from each other tend to besemantically disparate.
In terms of adjective se-mantics, the semantic relationship between ?ki-mochi, kanji (feeling)?
(Cluster7) and ?seishitsu(characteristics of someone/something), yousou(aspect)?
are distant.However, ?kimochi, kanji (feeling)?
(Cluster7)has a close relation to ?fun?iki, kuuki, kehai(atmosphere) ?
(Cluster6) and also  ?joutai (state),joukyou (situation)?
(Cluster8).Fig7.
Cluster 7 on the map124 35Center of a map 678751.
In our experiment, 77 adjectives belongedto one or two clusters.
Though there is thepossibility of data sparseness, there is alsothe possibility that the meanings of theseadjectives are specific.
Examples of adjec-tives belonging to specific clusters are asfollows:Adjectives in distant relationships;- Clusters 2: keisandakai (seeing everything interms of money), ken?meina(wise), ?- Cluster 7: akkenai (disappointing/easily), kiya-sui (feel at home),?Adjectives in close relationships;- Cluster 6: ayashigena (fishy)- Cluster7: akkenai (disappointing /easily), kiya-sui (feel at home)- Cluster8: meihakuna (obvious), omoshiroi (in-teresting), makkurana (dark)Japanese adjectives are often said to represent?kanjou (mental state)?, ?joutai (state),?
?seisitsu(characteristics)?
and ?teido (degree)?, in addi-tion to ?positive/negative image.?
In our experi-ment, the SOM unearthed not only these adjecti-val meanings, but also ?inshou (impression)?,?taido (attitude)?, ?kanten (viewpoint)?
and?sugata (outlook)?, which seem to be discrimina-tive meanings of adjectives.6.
Future workWe classified 361 concepts based on 2374 adjec-tives using a self-organizing map.
Since theSOM shows the distribution visually, it providesnot only clusters of adjectives but also ?close-distant?
relationships between clusters.
As a re-sult, adjectival concepts at the superordinatelevel are divided into 8 main clusters.
The resultsnot only verify previous work but also suggestnew discriminative adjective classes.
One of theadvantages of SOM is that it presents its outputsvisually.
As a result, we can explore ?close- dis-tant?
relationships between clusters, and  analyzethe meaning of each.
In addition to increasing therange of adjectival classes and improving ourmethod, our method provides the means to ana-lyze concepts which did not agree with those inexisting thesauri such as ?Bunruigoihyou?, theEDR dictionary or Japanese Word Net.ReferencesAlonge, Antonietta., Francesca Bertagna, NicolettaCalzolari, Andriana Roventini and Antonio Zam-polli.
2000.
Encoding Information on Adjectives ina Lexical-semantic Net for Computational Applica-tions, Proceedings of the 1st Conference of theNorth American Chapter of the Association forComputational Linguistics(NAACL-00) :42-49Kyoko Kanzaki,Qing Ma, Eiko Yamamoto andHitoshi Isahara, 2006, Semantic Analysis ofAbstract Nouns to Compile a Thesaurus ofAdjectives, In Proceedings of The Interna-tional Conference on Language Resourcesand Evaluation (LREC-06)Kohonen, Teuvo.
1997.
Self-Organizing Maps, Sec-ond Edition, Springer.Lin, Dekang., and Patrick Pantel.
2002.
Concept Dis-covery from Text, Proceedings of the 19th Interna-tional Conference on Computational Linguis-tics(COLING-02): 768-774Manning, Christopher D., and Hinrich Sh?tze.
1999.Foundations of Statistical Natural language Proc-essing, The MIT Press.Marrafa, Palmira., and Sara Mendes.
2006.
ModelingAdjectives in Computational Relational Lexica,Proceedings of the COLING/ACL2006:555-562National Institute for Japanese Language.
1964.
Bun-ruigoihyou (Word List by Semantic Principles).Nemoto, Kesao.
1969.
The combination of the nounwith ?ga-Case?
and the adjective, Language re-search 2 for the computer, National Language Re-search Institute: 63-73 (in Japanese)Salton, Gerard., and Michael J. McGill.
1983.
Intro-duction to Modern Information Retrieval.
McGrawHill.Solar, Clara.
2003.
Extension of Spanish WordNet,Proceedings of the third International WordNetConference(GWC-06):213-21976
