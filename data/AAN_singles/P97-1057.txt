String Transformation LearningGiorgio SattaDipar t imento  di E le t t ron ica  e In fo rmat icaUn ivers i th  di Padovav ia  Graden igo ,  6 /A1-35131 Padova ,  I ta lysatt a@dei, unipd, itJ ohn  C .
HendersonDepar tment  of  Computer  Sc ienceJohns  Hopk ins  Un ivers i tyBa l t imore ,  MD 21218-2694j hndrsn~cs, j hu.
eduAbst rac tString transformation systems have beenintroduced in (Brill, 1995) and have sev-eral applications in natural language pro-cessing.
In this work we consider the com-putational problem of automatically learn-ing from a given corpus the set of transfor-mations presenting the best evidence.
Weintroduce an original data structure andefficient algorithms that learn some fam-ilies of transformations that are relevantfor part-of-speech tagging and phonologi-cal rule systems.
We also show that thesame learning problem becomes NP-hardin cases of an unbounded use of don't caresymbols in a transformation.1 In t roduct ionOrdered sequences of rewriting rules are used inseveral applications in natural language process-ing, including phonological and morphological sys-tems (Kaplan and Kay, 1994), morphological disam-biguation, part-of-speech tagging and shallow syn-tactic parsing (Brill, 1995), (Karlsson et ah, 1995).In (Brill, 1995) a learning paradigm, called error-driven learning, has been introduced for automaticinduction of a specific kind of rewriting rules calledtransformations, and it has been shown that theachieved accuracy of the resulting transformationsystems is competitive with that of existing systems.In this work we further elaborate on the error-driven learning paradigm.
Our main contributionis summarized in what follows.
We consider somefamilies of transformations and design efficient al-gorithms for the associated learning problem thatimprove existing methods.
Our results are achievedby exploiting a data structure originally introducedin this work.
This allows us to simultaneously repre-sent and test the search space of all possible transfor-mations.
The transformations we investigate makeuse of classes of symbols, in order to generalize regu-larities in rule applications.
We also show that whenan unbounded number of these symbol classes are al-lowed within a transformation, then the associatedlearning problem becomes NP-hard.The notation we use in the remainder of the paperis briefly introduced here.
~3 denotes a fixed, finitealphabet and e the null string.
E* and E+ are theset of all strings and all non-null strings over E, re-spectively.
Let w 6 E*.
We denote by Iwl the lengtho fw.
Let w = uxv; u i s  apre f ix  and v is a suf-fix of w; when x is non-null, it is called a fac tor  ofw.
The suffix of w of length i is denoted suffi(w),for O < i _< Iwl.
Assume that x is non-null, andw = uixsuff i (w ) for ~ > 0 different values of i butnot for ~ + 1, or x is not a factor of w and ~ = 0.Then we say that ~ is the statistic of factor z in w.2 The  learn ing  parad igmThe learning paradigm we adopt is called error-driven learning and has been originally proposedin (Brill, 1995) for part of speech tagging applica-tions.
We briefly introduce here the basic assump-tions of the approach.A string t rans format ion  is a rewriting rule de-noted as u -* v, where u and v are strings such that\[u\[ = Ivt.
This means that i fu appears as a factor ofsome string w, then u should be replaced by v in w.The application of the transformation might be con-ditioned by the requirement that some additionallyspecified pattern matches ome part of the string wto be rewritten.We now describe how transformations can be au-tomatically learned.
A pair of strings (w, w') is ana l igned pa i r  if IT\[ = \]w'\[.
When w = uzsuff i (w) ,w' = u'x 'suff i (w'  ) and Ixl = Ix'l, we say that fac-tors x and x' occur at aligned positions within(w, w').
A multi-set of aligned pairs is called ana l igned  corpus .
Let (w, w ') be an aligned pair andlet 7- be some transformation of the form u --~ v.The pos i t ive  ev idence  of v (w.r.t.
(w, w')) is thenumber of different positions at which factors u andv are aligned within (w, w').
The negat ive  evi-dence  of r (w.r.t.
w, w ~) is the number of differentpositions at which factors u and u are aligned within444?a ~(C$'$-a.,a l(p$ c lq~$,\ [ 1 , 2 ~Figure 1: Trie and suffix tree for string w = accbacac$.
Pair \[i, j\] denotes the factor of w starting at positioni and ending at position j (hence \[1, 2\] denotes ac).
(w, w').
Intuitively speaking, positive (negative) ev-idence is a count of how many times we will do well(badly, respectively) when using v on w in trying toget w'.
The score associated with v is the differ-ence between the positive evidence and the negativeevidence of r. This extends to an aligned corpusin the obvious way.
We are interested in the set oftransformations that are associated with the high-est score in a given aligned corpus, and will developalgorithms to find such a set in the next sections.3 Data  S t ruc turesThis section introduces two data structures that arebasic to the development of the algorithms presentedin this paper.3.1 Suffix treesWe briefly present here a data structure that iswell known in the text processing literature; thereader is referred to (Crochemore and Rytter, 1994)and (Apostolico, 1985) for definitions and furtherreferences.Let w be some non-null string.
Throughout thepaper we assume that the rightmost symbol of w isan end-marker not found at any other position inthe string.
The suffix tree associated with w is a"compressed" trie of all strings suffi(w), 1 < i< Iwl.Edges are labeled by factors of w which are encodedby means of two natural numbers denoting endpointsin the string.
An example is reported in Figure 1.An implicit  node is a node not explicitly repre-sented in the suffix tree, that splits the label of someedge at a given position.
(Each implicit node cor-responds to some node in the original trie havingonly one child.)
We denote by parent(p) the parentnode of (implicit) node p and by label(p, q) the la-bel of the edge spanning (implicit) nodes p and q.Throughout the paper, we take the dominance rela-tion between odes to be reflexive, unless we writep roper  dominance.
We also say that implicit nodeq immediate ly  dominates node p if q splits the arcbetween parent(p) and p. Of main interest here arethe following properties of suffix trees:?
if node p has children Pl .
.
.
.
, Pd, then d _> 2 andstrings label(p, pi) differ one from the other atthe leftmost symbol;.
all and only the factors of w are represented bypaths from the root to some (implicit) node;?
the statistic of factor u of w is the number ofleaves dominated by the (implicit) node endingthe path representing u.In the remainder of the paper, we sometimes identifyan (implicit) node of a suffix tree with the factorrepresented by the path from the root to that node.The suffix tree and the statistics of all factors ofw can be constructed/computed in time O(\[w\[), asreported in (Weiner, 1973) and (McCreight, 1976).McCreight algorithm uses two basic functions toscan paths in the suffix tree under construction.These functions are briefly introduced here and willbe exploited in the next subsection.
Below, p is anode in a tree and u is a non-null string.funct ion Slow_scan(p, u): Starting at p, scan u sym-bol by symbol.
Return the {implicit) node corre-sponding to the last matching symbol.The next function runs faster than Slow_scan, andcan be used whenever we already know that u is an(implicit) node in the tree (u completely matchessome path ill the tree).funct ion Fast_scan(p, u): Starting at p, scan u byiteratively (i) finding the edge between the currentnode and one of its children, that has the same firstsymbol as the suffix of u yet to be scanned, and(ii) skipping a prefix of u equal to the length of theselected edge label.
Return the (implicit) node u.445\ [ 1 , 2 ~  / \"-M9,91d/\[8,9\] t : : 7 ~ ~  N a \ [ ~/ \ [8 .9 \ ] / \ [6 .9 \ ]9,9\]7(13)~(2) .\[3~\] N"~ "91Figure 2: Suffix tree aligmnent for strings w = accbacac$, w' = acabacba$ and the identity homomorphismh(a) = a, h(b) = b, h(c) = c. Each a-link is denoted by indexing the incident nodes with the same integernumber; if the incident node is an implicit node, then we add between parentheses the relative position w.r.t.the arc label.From each node au in the suffix tree, au some factor,McCreight's algorithm creates a pointer, called an s-l ink, to node u which necessarily exists in the suffixtree.
We write q = s-link(p) if there is an s-link fromptoq .3.2 Suffix t ree  a l ignmentIn the next section each transformation will be as-sociated with several strings.
Given an input text,we will compute transformation scores by comput-ing statistics of these strings.
This can easily bedone using suffix trees, and by pairing statistics cor-responding to the same transformation.
The lattertask can be done using the data structure originallyintroduced here.A total function h : E ~ E ~, ~ and E' two alpha-bets, is called a (restricted) homomorph ism.
Weextend h to a string function in the usual way byposing h(?)
= s and h(au) = h(a)h(u), a E E andu E E*.
Given w,w' E E +, we need to pair eachfactor u of w with factor h(u) possibly occurring inw ~.
To solve this problem, we construct he suffixtrees T,T '  for w,w',  respectively.
Then we estab-lish an a- l ink (a pointer) from each node u of T,u some factor, to the (implicit) node h(u) of T ~, ifh(u) exists.
Furthermore, if factor ua with a E E isan (implicit) node of T such that h(u) but not h(ua)are (implicit) nodes of T', we create node u in T (ifu was an implicit node) and establish an a-link fromu to (implicit) node h(u) of T'.
Note that the to-tal number of a-links is O(Iwl).
The resulting datastructure is called here suffix t ree  a l igmnent .
Anexample is reported in Figure 2.We now specify a method to compute suffix treealignments.
In what follows p,p~ are tree nodes andu is a non-null string.
Crucially, we assume we canaccess the s-links of T and T'.
Paths u and v in Tand T',  respectively, are aligned if v = h(u).
Thenext two functions are used to move a-links up anddown two aligned paths.funct ion  Move_link_down(p,p',u): Starting at.
pand p', simultaneously scan u and h(u), respectively,using function Slow_scan.
Stop as soon as a symbolis not matched.
At each encountered node of T andat the (implicit) node of T corresponding to the lastsuccessful match, create an a-link to the paired (im-plicit) node of T'.
Return the pair of nodes in thelastly created a-link Mong with the length of the suc-cessfully matched prefix of u.In the next function, we use function Fast_scan in-troduced in Section 3.1, but we run it upward thetree (with the obvious modifications).funct ion  Move_link_up(p,p'): Starting at p and p',simultaneously scan the paths to the roots of T andT', respectively, using function Fast_scan.
Stop assoon as a node of T is encountered that already ha.san a-link.
At each encountered node of T create ana-link to the paired (implicit) node of T'.We also need a function that "shifts" a-links to a newpair of aligned paths.
This is done using s-links.
Thenext auxiliary function takes care of those (implicit)nodes for which the s-link is missing.
(This is thecase for implicit nodes of T ~ and for some nodes ofT that have been newly created.)
We rest on theproperty that the parent node of any such (implicit)node always has an s-link, when it differs from theroot.funct ion  Up_link_down(p): If s-link(p) is definedthen return s-link(p).
Else, let pl = parent(p).
IfPl is not the root node, let P2 = s-link(p1) andreturn (implicit) node FasLscan(p2,1abel(pl,p)).If Pl is the root node, return (implicit) nodeFast_scan(p1, sufflZab~l(p~,p )i_ l ( label(pl ,p) ).funct ion  Shifl_link(p,p'): P l  = Up_link_down(p),P'I = Up_linLdown(p').
Return (Pl,P~).We can now present the algorithm for the con-struction of suffix tree alignments.A lgor i thm 1 Let T and T' be the suffix trees forstrings w and w', respectively:( bl~l ' G l  ' d) ,-- Move_link_down(root of T,446I i l  ab' I bi I a-linkl9 - ac 1, 28 C C - -7 e cba 46 ba bac 55 ac aca 64 ca ca 73 a ac --2 c c 81 e $ -Figure 3: The table reports the values of 8bi, biand the established a-links at each iteration of Algo-rithm 1, when constructing the suffix tree aligmnentin Figure 2.
To denote a-links we use the same inte-ger numbers as in Figure 2.root of T',for  i f rom \]w I - 1 downto  1 do beg in(sbi, sb;) ~-- Shift_link(bi+l, b;+l)M ove_link_up( sbi , sb~ )( b, , dd) Move_link_do n( ab, , abe,s  wl-d(w))d. - -d+ddendendIn Figure 3 a sample run of Algorithm 1 is schemat-ically represented.In the next section we use the following propertiesof Algorithm 1:?
after T and T' have been processed, for everynode p o fT  representing factor u of w, (implicit)node a-link(p) of T ~ is defined if and only ifa-link(p) represents factor h(u) of w';?
the algorithm can be executed in timeO(Iwl + Iw'l).The first property above can be proved as follows.For 1 < i < Iwl, bi in Algorithm 1 is (the noderepresenting) the longest prefix of suffi(w ) such thath(bi) is an (implicit) node of T'  (is a factor of w').This can be proved by induction on \[w I - i ,  using thedefinition of Move_link_down and of s-link.
We thenobserve that, if u is a node of T, then factor u is aprefix of some suffi(w ) and either u dominates bi orbi properly dominates u in T. If u dominates bi, then?
h(u) must be an (implicit) node ofT ' .
In this case ana-link is established from u to h(u) by Move_link_upor Move_link_down, depending on whether u dom-inates or is dominated by sbi in T. If bi properlydominates u, h(u) does not occur in w'.
In thiscase, node u is never reached by the algorithm andno a-link is established for this node.The proof of the linear time result is rather long,we only give an outline here.
The interesting caseis the function Shift_link, which is executed Iwl- 1times by the algorithm.
When executed once onnodes p and if, Shift_link uses time 0(1) if s-link(p)and s-link(p ~) are both defined.
In all other cases,it uses an amount of time proportional to the num-ber of (implicit) nodes visited by function FasLscan,which is called through function Up_link_down.
Weuse an amortization technique and charge a constantamount of time to the symbols in w and w', for eachnode visited in this way.
Consider the execution ofShif l_ l ink(bi+l,  b~+l) for some i, 1 < i < Iw \ [ -  1.
As-sume that, correspondingly, Fast_scan visits nodesu l , .
.
.
,Ud  of T in this order, with d __ 1 and eachuj some factor of w. Then we have that each uj isa (proper) prefix of uj+l, and Ud = sbi.
For eachu j, 1 < j _< d -  1, we charge a constant amount oftime to the symbol in w "corresponding" to the lastsymbol of uj.
The visit to Ud, on the other hand, ischarged to the ith symbol of w. (Note that chargingthe visit to ud to the symbol in w "corresponding"to the last symbol of Ud does not work, since in thecase of sbi ---" bi the same symbol would be chargedagain at the next iteration of the for-cycle.)
It is notdifficult to see that, in this way, each symbol of w ischarged at most once.
A similar argument works forvisits to nodes of T' by Fast_scan, which are chargedto symbols of u?.
This shows that the time used byall executions of Shift_link is 0(Iwl + Iw'l).Suffix trees and suffix tree alignments can be gen-eralized to finite multi-sets of strings, each stringending with the same end-marker not found at anyother position.
In this case each leaf holds a record,called count ,  of the number of times the correspond-ing suffix appears in the entire multi-set, which willbe propagated appropriately when computing factorstatistic.
Most important here, all of the above re-sults still hold for these generalizations.
In the nextsection, we will deal with the multi-set case.4 T rans format ion  learn ingThis section deals with the computational problemof learning string transformations from an alignedcorpus.
We show that some families of transforma-tions can be efficiently learned exploiting the datastructures of Section 3.
We also consider more gen-eral kinds of transformations and show that for thisclass the learning problem is NP-hard.4.1 Data  representat ionWe introduce a representation of aligned corporathat reduces the problem of computing the pos-itive/negative vidence of transformations to theproblem of computing factor statistics.Let (w, w') be an aligned pair, w = a l .
.
"an andw'=a' l .
.
.a ,~;  witha iEE for l< i<n,  andn>_ 1.We definew?w'  = (a l ,a~) . "
(a~,a~) .
(1)447Note that w x w ~ is a string over the new al-phabet E x E. Let N > 1 and let L ={(wl, w~), .
.
.
,  (Wg, W~v)} be an aligned corpus.
Werepresent L as a string multi-set over alphabet E x E:L?
= {w x w' I (w,w') E L}, (2)where w x w ~ appears in Lx as many times as (w, w ~)appears in L.4.2 Learn ing  a lgor i thmsLet L be an aligned corpus with N aligned pairs overa fixed alphabet E, and let n be the length of thelongest string in a pair in L. We start by consideringplain transformations of the formu --* v ,  (3 )where u, v E E +, lul = Ivl, We want to find all in-stances of strings u, v E E* such that, in L, u ~ vhas score greater or equal than the score of any othertransformation.
Existing methods for this problemare data-driven.
They consider all pairs of factors(with lengths bounded by n) occurring at alignedpositions within some pair in L, and update thepositive and the negative evidence of the associatedtransformations.
They thus consider O(Nn 2) fac-tor pairs, where each pair takes time O(n) to beread/stored.
We conclude that these methods usean amount of time O(Nn3).
We can improve onthis by using suffix tree alignments.Let Lx be defined as in (2) and let hi : (E x E)(E x E) be the homomorphism specified as:h~((a,b)) = (a,a).Recall that, each suffix of a multi-set of strings isrepresented by a leaf in the associated suffix-tree,because of the use of the end-marker, and that eachleaf stores the count of the occurrences of the corre-sponding suffix in the source multi-set.
We schemat-ically specify our first learning algorithm below.A lgor i thm 2S tep  1: construct wo copies Tx and T x of the suf-fix tree associated with L?
and align them using hi;S tep  2: visit trees T?
and T~ in post-order, and an-notate each node p with the number e(p) computedas the sum of the counts at leaves that p dominates;S tep  3: annotate ach node p of T?
with the scoree(p) - e(p'), where p' = a-link(p) if a-link(p) is anactual node, p~ is the node immediately dominatedby a-link(p) if a-link(p) is an implicit node, ande(p ~) = 0 if a-link(p) is undefined; make a list ofthe nodes with the highest annotated score.Let p be a node of Tx associated with factor u x v.Integer e(p) computed at Step 2 is the number oftimes a suffix having u x v as a prefix appears instrings in Lx.
Thus e(p) is the number of differ-ent positions at which factors u and v are alignedwithin Lx and hence the positive evidence of trans-formation u --~ v w.r.t.
L, as defined in Section 2.Similarly, e(#) is the statistic of factor u >< u andhence the negative vidence of u --+ v (as well as thenegative vidence of all transformations having u asleft-hand side).
It follows that Algorithm 2 records,at Step 3, the transformations having the highestscore in L among all transformations represented bynodes of Tx.
It is not difficult to see that the re-maining transformations, denoted by implicit nodesof Tx, do not have score greater than the one above.The latter transformations with highest score, if any,can be easily recovered by visiting the implicit nodesthat immediately dominate the nodes of Tx recordedat Step 3.A complexity analysis of Algorithm 2 is straight-forward.
Step 1 can be executed in time O(Nn), asdiscussed in Section 3.
Since the size of Tx and T~<is O(Nn)~ all other steps can be easily executed inlinear time.
Hence Algorithm 2 runs in time O(Nn).We now turn to a more general kind of transfor-mations.
In several natural language processing ap-plications it is useful to generalize over some trans-formations of the form in (3), by using classes ofsymbols in E. Let t > 1 and let C1, ?
.
.
,  Ct be a par-tition of E (each Ci ~-O).
Consider F = {C1, .
.
.
,  Ct}as an alphabet.
We say that string al.. .ad E ~+matches  string Ci,...Cid E F + if ak E Cik for1 < k < d. We define transformations 1u 7 -* v-- ,  (4)u, v E E +, lut = Ivt, 7 E F +, and assume the follow-ing interpretation.
An occurrence of string u mustbe rewritten to v in a text whenever u is followedby a substring matching 7.
String 7 is called ther ight  context  of the transformation.
The positiveevidence for such transformation is the number ofpositions at which factors ux and vx ~ are alignedwithin the corpus, for all possible x, x ~ E E + withx matching 7.
(We do not require x = x', sincelater transformations can change the right context.
)The negative evidence for the transformation is thenumber of positions at which factors ux and ux ~ arealigned within the corpus, x, x ?
as above.We are not aware of any learning method fortransformations of the form in (4).
A naive methodfor this task would consider all factor pairs appear-ing at aligned positions in some pair in L. The leftcomponent of each factor must then be split intoa string in E + and a string in F +, to represent atransformation i the desired form.
Overall, thereare O(Nn 3) possible transformations, and we needtime O(n) to read/store ach transformation.
Thenthe method uses an amount of time O(Nn4).
Again,we can improve on this.
We need a representa-tion for right context strings.
Define homomorphismh2 : (E  X E)---+ F ash~((a,~)) = C, a~C.1In generative phonology (4) is usually written as u ---+v / _ 7.
Our notation can more easily be generalized, asit is needed in some transformation systems.448(h2 is well defined since r is a partition of E.) LetalsoLr  = {h2(w x w')  I w x w' e Lx},where h2(w x w') appears in Lr  as many times asw x w' appears in L x.uxv/ \ ~qFigure 4: At Step 3 of Algorithm 3, triple (q, e, e')is inserted in v(p) if the relations depicted above arerealized, where dashed arrows denote a-links, blackcircles denote nodes, and white circles denote nodesthat might be implicit.
Integer e > 0 is a count ofthe paths from node q downward, having the formy x y' with a prefix of y matching 7.
Similarly, e ~ is acount of the paths from node q~ downward satisfyingthe same matching condition with 7.
The matchingcondition is enforced by the fact that the above pathshave their ending leaf nodes a-linked to a leaf nodeof Tr dominated by node p.Below we link a suffix-tree to more than one suffix-tree.
In the notation of a-links we then use a sub-script indicating the suffix tree of the target node,in order to distinguish among different linkings.
Wenow schematically specify the learning algorithm;additional computational details will be providedlater in the discussion of the complexity.A lgor i thm 3S tep  1: construct wo copies Tx and T~ of the suffixtree associated with L?
and construct he suffix treeTr associated with Lr;S tep  2: align Tx with T" using hi and align theresulting suffix trees Tx and T~ with Tr using h~;Step  3: for each node p of Tr, store a set v(p)including all triples (q, e, e') such that (see Figure 4):?
q is a node of Tx such that a-linkTr(q) properlydominates p?
e > 0 is the sum of the counts at leaves of Txdominated by q that have an a-link to a leaf ofTr dominated by p?
if ql = a_linkT, x(q) is defined, e' is the sum ofthe counts at leaves of T x dominated by q' thathave an a-link to a leaf of Tr dominated by p;otherwise, e ~ = 0;S tep  4: find all pairs (p,q), p a node of Tr and(q, e, e') E v(p), such that e - e ~ is greater than orequal to any other el - e~, (ql, el, el) in some r(pl).We next show that if pair (p, q) is found at Step 4,then q represents a factor u x v, p represents a factorh2(u x v)7, and transformation u7 ~ v -- has thehighest score among all transformations representedby nodes of Tx and Tr.
Similarly to the case of Al-gorithm 2, this is the highest score achieved in L,and other transformations with the same score canbe obtained from some of the implicit nodes imme-diately dominating p and q.Let p a id  q be defined as in Step 3 above.
Assumethat q represents a factor u x v of some string in L?and p represents a factor 87 E F* of some string inLr,  where \[81 = lul.
Since a-linkTr(q) dominatesp, we must have h2(u x v) = 8.
Consider a suffix(u x v)(z x x')(y x y') appearing in ~ > 0 stringsin Lx, such that h2(x x x') = 7.
(This means thatx matches 7, and there are at least ~ positions atwhich u --+ v has been applied with a right-context of%) We have that string h2((u x v)(x x x')(y x y')) =&Th2(y x y') must be a suffix of some strings in Lr.It follows that (u x v)(x x z')(y x y') is a leaf ofTx with a count of ~, ~Th2(y x y') is a leaf of Tr,and there is an a-link between these two nodes.
Leaf(u x v)(x x z')(y ?
y') is dominated by q, and leaf&Th2(y x y') is dominated by p. Then, at Step 3,integer ~ is added to e. Since no condition has beenimposed above on string x' and on suffix (y x y'), weconclude that the final value ofe must be the positiveevidence of transformation u7 --+ v --.
A similarargument shows that the negative evidence of thistransformation is stored in e'.
It then follows that, atStep 4, Algorithm 3 finds the transformations withthe highest score among those represented by nodesof Tx and Tr.Algorithm 3 can be executed in time O(Nn2).
Weonly outline a proof of this property here, by fo-cusing on Step 3.
To execute this step we visit Trin post order.
At leaf node p, we consider the setF(p) of all leaves q of Tx such that p = a-linkT?
(q),and the set F~(p) of all leaves q~ of T~ such thatp = a-linkTx (q').
For each (implicit) node of T"that dominates some node in F~(p) and that isthe target of some a-link (from some source nodeof Tx), we record the sum of the counts of thedominated nodes in Fl(p).
This can be done intime O(IF'(p)l n).
For each node q of Tx dominat-ing some node in F(p), we store in v(p) the triple(q,e, e'), since a-linkTr(q) necessarily dominates p.We let e > 0 be the sum of the counts of the dom-inated nodes in F(p), and let e' be the value re-trieved from the a-link to T ' ,  if any.
This takestime O(IF(P)l n).
When p ranges over the leaves of449Tr,  we have ~-~p IF(p)I = EC, IF'(p)I = O(Nn).
Wethen conclude that sets r(p) for all leaves p of Trcan be computed in time O(Nn2).
At internal nodep with children Pi, 1 < i _< d, d > 1, we assumethat sets r(pi) 's have already been computed.
As-sume that for some i we have (q, ei, e~) E r(pl) anda-linkTr(q) does not immediately dominate Pi.
If' to e, respectively; (q, e, e') E r(p), we add ei, e i e',otherwise, we insert (q, el, e{) in r(p).
We can thencompute sets r(p) for all internal nodes p of Tr usingan amount of time }-'~p Ir(p)t = O(Nn=).4.3 Genera l  t rans format ionsWe have mentioned that the introduction of classesof alphabet symbols allows abstraction over plaintransformations that is of interest to natural lan-guage applications.
We generalize here transforma-tions in (47 by letting 7 be a string over E U F. Moreprecisely, we assume 7 has the form:"1 = uo~iu l .
.
-u~- i~ 'a~,  (5)where u0,ud E ~*, ui E ~+ and ~j E F + for 1 _i_< d -1  and l _< j_< d, and d>_ 1.
The notion ofmatching previously defined is now extended in sucha way that, for a, b E P,, a matches b if a = b. Thenthe interpretation of the resulting transformation isthe usual one.
The parameter d in (5) is called thenumber of a l te rnat ions  of the transformation.
Wehave established the following results:?
transformations with a bounded number of al-ternations can be learned in polynomial time;?
learning transformations with an unboundednumber of alternations is NP-hard.Again, we only give an outline of the proof below.The first result is easy to show, by observing thatin an aligned corpus there are polynomially manyoccurrences of transformations with a bounded num-ber of alternations.
The second result holds even ifwe restrict ourselves to IEI = 2 and Irl = 1, that isif we use a don~t care  symbol.
Here we introducea decision problem associated with the optimiza-tion problem of learning the transformations withthe highest, score, and outline an NP-completenessproof.TRANSFORMATION SCORING (TS)Instance: (L ,K) ,  with L an aligned corpus, K apositive integer.Question: Is there a transformation that has scoregreater than or equal to K w.r.t.
L?Membership in NP is easy to establish for TS.
Toshow NP-hardness, we consider the CLIQUE de-cision problem for undirected, simple, connectedgraphs and transform such a problem to the TSproblem.
(The NP-completeness for .the used restric-tion of the CLIQUE problem (Garey and Johnson,1979) is easy to establish.)
Let (G,K ' )  be an in-stance of the CLIQUE problem as above, G = (V, E)and K '  > 0.
Without loss of generality, we assumethat V = {1,2, .
.
.
,q}.
Let E = {a,b}; we constructan instance of the TS problem (L, K} over E as fol-lows.
For each {i, j} E V with i < j letwi,j = ai- lbaJ- i - lba q-j.
(6)We add to the aligned corpus L:1. one instance of pair Pi,j = (awl j ,  bwi,j) for eachi < j, { i , j}  E E;2. q2 instances of pair Pi,j = (awi,j, awi,j) for eachi , j  E Y with i < j and {i, j} ~ E;3. q2 instances of pair Pa = (aaa, ban).Also, we set K = q2 + (~').
The above instance ofTS can easily be constructed in polynomial deter-ministic time with respect o the length of (G, K'}.It is easy to show that when (G, K' )  is a positiveinstance of the source problem, then the correspond-ing instance of TS is satisfied by at least one trans-formation.
Assume now that there exists a trans-formation r having score greater equal than K > 0,w .
r .
t .
L .
Since the replacement of a with b is theonly rewriting that appears in pairs of L, r musthave the form a7 --+ b --.
If 7 includes some occur-rence of b, then r cannot match Pa and the positiveevidence of r will not exceed IEI < (3) < K, con-trary to our assumption.
We then conclude that 7has the form (?
denotes the don't  care symbol):aJl-l?aJ~-ji-1 ?
...?.aq'-Ja,where V" = { j i , .
.
.
, Jd}  C_ V, d > 0 and q' < q. Ifthere exists i, j E V" such that {-i, j} ~ E, then rwould match some pair Pi,j E L and it would havenegative evidence smaller or equal than q2.
Sincethe positive evidence of r cannot exceed q2 + IEI,r would have a score not exceeding IEI < (q) < If,contrary to our assumption.
Then r matches no pairPij E L and, for each i , j  E V", we have {i , j}  E E.= K' (K') Since K - q2 ( 2 ), at least pairs Pi,j E L arematched by r. We therefore conclude that d > K 'and that V" is a clique in G of size greater equalthan K'.
This concludes our outline of the proof.5 Conc lud ing  remarksWith some minor technical changes to functionUp_link_down, we can align a suffix tree with itself(w.r.t.
a given homomorphism).
In this way weimprove space performance of Algorithms 2 and 3,avoiding the construction of two copies of the samesuffix tree.
Algorithm 3 can trivially be adapted tolearn transformations in (4) where a left context isspecified in place of a right context.
The algorithmcan also be used to learn traditional phonologicalrules of the form a --* b / _7,  where a,b are sin-gle phonemes and "/is a sequence over {C, V}, theclasses of consonants and vowels.
In this case the450algorithm runs in time O(Nn) (for fixed alphabet).We leave it as an open problem whether ules of theform in (4) can be learned in linear time.We have been concerned with learning the besttransformations that should be applied at a givenstep.
An ordered sequence of transformations canbe learned by iteratively learning a single transfor-mation and by processing the aligned corpus withthe transformation just learned (Brill, 1995).
Dy-namic techniques for processing the aligned corpuswere first proposed in (Ramshaw and Marcus, 1996)to re-edit the corpus only where needed.
Those au-thors report that this is not space efficient if trans-formation learning is done by independently test-ing all possible transformations in the search space(as in (Brill, 1995)).
The suffix tree alignment datastructure allows simultaneous scoring for all trans-formations.
We can now take advantage of this anddesign dynamical algorithms that re-edit a suffix treealignment only where needed, on the line of a similarmethod for suffix trees in (McCreight, 1976).An alternative data structure to suffix trees forthe representations of string factors, called DAWG,has been presented in (Blumer et al, 1985).
Wepoint out here that, because a DAWG is an acyclicgraph rather than a tree, straightforward ways ofdefining alignment between two DAWGs results in aquadratic number of a-links, making DAWGs muchless attractive than suffix trees for factor alignment.We believe that suffix tree alignments are a very flex-ible data structure, and that other transformationscould be efficiently learned using these structures.We do not regard the result in Section 4.3 as a neg-ative one, since general transformations specified asin (5) seem too powerful for the proposed applica-tions in natural language processing, and learningmight result in corpus overtraining.Other than transformation based systems themethods presented in this paper can be used forlearning rules of constraint grammars (Karlsson etal., 1995), phonological rule systems as in (Kaplanand Kay, 1994), and in general those grammaticalsystems using constraints represented by means ofrewriting rules.
This is the case whenever we canencode the alphabet of the corpus in such a waythat alignment is possible.AcknowledgementsPart of the present research was done while the firstauthor was visiting the Center for Language andSpeech Processing, Johns Hopkins University, Bal-timore, MD.
The second author is a member of theCenter for Language and Speech Processing.
Thiswork was funded in part by NSF grant IRI-9502312.The authors are indebted to Eric Brill for technicaldiscussions on topics related to this paper.ReferencesApostolico, A.
1985.
The myriad virtues of suf-fix trees.
In A. Apostolico and Z. Galil, editors,Combinatorial Algorithms on Words, volume 12.Springer-Verlag, Berlin, Germany, pages 85-96.NATO Advanced Science Institutes, Seires F.Blumer, A., J. Blumer, D. Haussler, A. Ehrenfeucht,M.
Chen, and J. Seiferas.
1985.
The smallest au-tomaton recognizing the subwords of a text.
The-oretical Computer Science, 40:31-55.Brill, E. 1995.
Transformation-based error-drivenlearning and natural anguage processing: A casestudy in part of speech tagging.
ComputationalLinguistics.Crochemore, M. and W. Rytter.
1994.
Text Algo-rithms.
Oxford University Press, Oxford, UK.Garey, M. R. and D. S. Johnson.
1979.
Computersand Intractability.
Freeman and Co., New York,NY.Kaplan, R. M. and M. Kay.
1994.
Regular modelsof phonological rule sistems.
Computational Lin-guistics, 20(3):331-378.Karlsson, F., A. Voutilainen, J. Heikkil~, andA.
Anttila.
1995.
Constraint Grammar.
ALanguage Independent System for Parsing Unre-stricted Text.
Mouton de Gruyter.McCreight, E. M. 1976.
A space-economical suffixtree construction algorithm.
Journal of the Asso-ciation for Computing Machinery, 23(2):262-272.Ramshaw, L. and M. P. Marcus.
1996.
Explor-ing the nature of transformation-based l arning.In J. Klavans and P. Resnik, editors, The Bal-ancing Act--Combining Symbolic and StatisticalApproaches to Language.
The MIT Press, Cam-bridge, MA, pages 135-156.Weiner, P. 1973.
Linear pattern-matching algo-rithms.
In Proceedings of the i4th IEEE AnnualSymposium on Switching and Automata Theory,pages 1-11, New York, NY.
Institute of Electricaland Electronics Engineers.451
