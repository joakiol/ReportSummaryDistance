Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 658?664,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsUnderstanding Tables in Context Using Standard NLP ToolkitsVidhya Govindaraju Ce Zhang Christopher Re?University of Wisconsin-Madison{vidhya, czhang, chrisre}@cs.wisc.eduAbstractTabular information in text documentscontains a wealth of information, andso tables are a natural candidate for in-formation extraction.
There are manycues buried in both a table and its sur-rounding text that allow us to under-stand the meaning of the data in a ta-ble.
We study how natural-languagetools, such as part-of-speech tagging,dependency paths, and named-entityrecognition, can be used to improve thequality of relation extraction from ta-bles.
In three domains we show that (1)a model that performs joint probabilis-tic inference across tabular and naturallanguage features achieves an F1 scorethat is twice as high as either a pure-table or pure-text system, and (2) us-ing only shallower features or non-jointinference results in lower quality.1 IntroductionTabular data is ubiquitous and often containshigh-quality, structured relational data.
Re-cent studies found billions of high-quality re-lations on the web in HTML (Cafarella etal., 2008).
In financial applications, a hugeamount of data is buried in the tables of cor-porate filings and earnings reports; in science,millions of journal articles contain billions ofscientific facts in tables.
Although tables de-scribe precise, structured relations, tables arerarely written in a way that is self-describing,e.g., tables may contain abbreviations or onlyinformal schema information; in turn, the con-tents of tables are often ambiguously specified,which makes extracting the relations implicitin tabular data difficult.Tables are, however, not written in isola-tion.
The text surrounding a table in a jour-nal article explains its contents to its intendedaudience, a human reader.
For example, ina simple study, we demonstrate that humanscan achieve more than 60% higher recall byjointly reading the text and tables in a journalarticle than by only looking at the tables.
Theconclusion of this experiment is not surprising,but it raises a question: How should a systemcombine tabular and natural-language featuresto understand tables in text?The literature provides a broad spectrum ofanswers to this question.
Most previous ap-proaches use textual or tabular features sepa-rately, e.g., tabular approaches that do not usetext features (Dalvi et al, 2012; Wu and Lee,2006; Pinto et al, 2003) or textual approachesthat do not use tabular features (Mintz et al,2009; Wu and Weld, 2010; Poon and Domin-gos, 2007).
In a prescient study, Liu et al(2007) proposed to learn the target relation in-dependently from both table and surface tex-tual features, and then combine the result us-ing a linear combination of the predictions.In a similar spirit, we propose to use bothtypes of features in our approach of relationextraction.
Our proposed approach differsfrom prior approaches in two ways: (1) Weuse deeper?but standard?NLP features thanprior approaches for table extraction.
In con-trast to the shallow, lexical features that priorapproaches have used, we use standard NLPfeatures, such as dependency paths, parts ofspeech, etc.
Our hypothesis is that a deeperunderstanding of the text in which a table isembedded will lead to higher quality table ex-traction.
(2) Our probabilistic model jointlyuses both tabular and textual features.
Oneadvantage of a joint approach is that one canpredict portions of the complicated predicatethat is buried in a table.
For example, in a ge-ology journal article, we may read a measure-658Table?although some fractional crystallization must have occurred duringthe formation of these rocks, crystal fractionation alone cannotaccount for the adakitic signature of the Gangdese rocks.
Consideringthe presence of a ~1500 km long belt of adakitic rocks, a fractionationmodel would require the existence of an extremely large parentmagma body, the evidence for which is lacking.
In fact, there is acomplete absence of coeval andesitic and basaltic magmatisms in thisadakite belt.
Recent investigation on the crystallization history of ahydrous primitive andesite composition shows that garnet is stable inandesitic and basaltic bulk compositions only after large degrees ofcrystallization lead to a decrease of the Mg-number to less than 0.5,and that high Mg-number primitive melts are not garnet saturated athigh pressures (M?entener et al, 2001).
However, all of the adakiticporphyries from southern Tibet including those with lower Mg-number show high Dy/Yb ratios and La/Yb ratios (Gao et al, 2007a).The high Sr/Y, Dy/Yb and La/Yb ratios, low heavy REE and Yconcentrations of the Gangdese adakites require an adakitic signaturein the primary melt source.Overall, the adakitic rocks of different ages in the Gangdese beltdisplay same differentiation trends (Figs.
2 and 3).
In both the pre-collision and post-collision groups, the abundances of MgO (Fig.
3a),TiO2 (Fig.
3c) and CaO (Fig.
3d) decrease with increasing SiO2,whereas with few exceptions, most samples have nearly constantAl2O3 contents (Fig.
3b).
Whereas the MgO and SiO2 contents of thepre-collision adakite show a wide range, most of the post-collisionadakites have high SiO2 and low MgO contents, and plot in the highSiO2 adakite field (Fig.
2a).
In the two types of adakites, the totalalkaline contents (K2O+Na2O wt.%), K2O abundances and K2O/Na2Oratios show a positive correlation with SiO2, displaying the typicaldifferentiation trend of calc-alkaline arc magmas (Fig.
2).
However,some of the post-collision adakitic rocks have unusually high K2Ocontents, yielding abnormally high total alkaline contents and K2O/Na2O ratios.
Consequently, these samples significantly depart fromthe overall trends (Fig.
2).
This suggests that the unusual K2Oenrichment was not simply a result of magmatic differentiation.The two generations of adakitic rock in the Gangdese belt showmany similarities in terms of distribution of trace elements withtypical incompatible trace element fractionation patterns of subduc-tion-related magmas (Fig.
4).
Overall, the adakites of different agesdisplay significant positive Pb and Sr anomalies, and negative Nb, Taand Ti anomalies (Fig.
4), correlating with typical features of adakiticmagmas (Martin et al, 2005).
Despite their similar trace elementpatterns, the geochemical signatures of the rocks in different regionsshow some distinction.
Some of the post-collision adakitic rocks fromTable 1Major and trace elements of the post-collision adakitic rocks from the Gangdese belt, southern Tibet.Location Zhunuo PuridazongSample ZM-1 ZM-2 ZM-3 ZM-4 ZM-5 ZM-6 ZM-7 ZM-8 ZM-9 ZM-10 ZM-12 ZM-13 PRDZ1 PRDZ2 PRDZ3 PRDZ4 PRDZ5SiO2 66.69 65.96 65.37 67.00 69.09 65.10 63.86 71.56 69.73 69.37 67.27 65.99 65.61 65.97 65.73 65.02 65.29TiO2 0.64 0.5 0.60 0.57 0.46 0.60 0.59 0.31 0.40 0.45 0.47 0.5 0.6 0.64 0.65 0.63 0.64Al2O3 15.28 15.28 15.35 14.56 14.67 15.44 16.01 14.2 14.35 14.14 17.12 15.27 15.45 15.4 15.39 15.04 15.18Fe2O3 4.17 3.07 4.27 4.06 3.18 4.31 3.83 2.39 3.04 3.32 2.25 3.05 3.46 3.69 3.68 3.54 3.62MnO 0.02 0.06 0.08 0.08 0.04 0.09 0.08 0.03 0.04 0.04 0.03 0.06 0.06 0.06 0.06 0.06 0.06MgO 1.75 1.54 1.84 1.60 1.20 1.94 2.35 0.83 1.08 1.34 0.97 1.54 1.63 1.75 1.76 1.72 1.7CaO 2.20 2.61 3.70 2.88 2.06 3.69 3 1.81 2.38 2.52 2.43 2.59 3.27 3.22 3.33 3.16 3.24Na2O 4.16 4.19 4.02 3.92 3.81 4.00 4.27 4.32 4.34 3.98 5.03 4.13 3.93 3.83 3.78 3.82 3.77K2O 3.57 3.71 3.25 3.49 4.20 3.19 3.41 4.00 3.85 3.65 3.75 3.71 3.82 3.84 3.79 3.85 3.8P2O5 0.21 0.18 0.21 0.19 0.17 0.22 0.27 0.11 0.15 0.16 0.24 0.19 0.26 0.27 0.27 0.26 0.26LOI 0.90 2.66 0.94 1.36 0.86 1.08 1.98 0.22 0.36 0.80 0.12 2.76 1.46 1.62 1.5 1.56 1.4Sum 99.6 99.8 99.6 99.7 99.7 99.7 99.7 99.8 99.7 99.8 99.7 99.8 99.6 100.3 99.9 98.7 99.0Mg# 49.4 53.9 50.1 47.9 46.8 51.2 58.8 44.7 45.3 48.5 50.1 54.0 52.3 52.5 52.7 53.1 52.2Sc 8.31 5.2 8.55 7.36 5.72 8.65 5.79 3.6 4.52 5.62 2.54 8.96 7.27 7.57 7.28 7.43 8.03V 78.1 66 79.9 71.5 56.3 81.5 74.3 36.2 44.9 52.1 48.8 107 84.8 87.1 83.0 75.6 91.6Cr 23.1 118 22.6 22.6 21.8 24.5 82.6 13.3 18.2 22.2 112 33.4 24.1 25.5 23.1 377.8 28.7Co 11 14.4 12.2 10.9 7.27 13 11.5 5.21 6.7 5.24 5.99 13.1 10.6 10.8 10.6 13.4 11.4Ni 15 86.8 13.9 12.7 10.5 15.9 17.3 6.41 8.65 14.2 6.85 17.1 11.4 11.6 11.5 74.2 12.9Rb 232 202 141 158 218 142 153 227 207 191 193 40.3 149 143 134 149 155Sr 681 633 884 752 550 878 807 567 664 623 824 825 1025 987.5 994 950 995Y 12.2 9.21 17.5 11.0 11.0 11.2 9.57 6.02 7.64 8.98 5.06 8.69 12.0 12.1 11.2 11.6 12.9Zr 47.2 96.6 114 78.6 26.8 64.7 67.5 26.5 46 77.7 18.3 166 127 136 127 139 149Nb 9 9.3 9.72 9.14 9.83 9.23 8.98 8.6 8.41 9.77 7.3 6.45 8.83 8.77 8.07 8.65 9.28Cs 19.1 8.47 6.42 6.97 11.1 8.28 6.26 10.8 8.35 14.0 8.42 2.07 3.66 3.79 3.49 3.60 3.92Ba 880 669 985 912 848 964 741 861 857 838 652 1043 1287 1234 1129 1205 1225La 37.4 31.5 33.36 37.8 38.4 38.7 33.6 28 37.2 34.8 25.4 20.6 42.2 50.8 41.5 46.7 49.7Ce 65.7 63.8 63.6 68.3 65.9 69.6 66.9 47.4 62.7 61.5 49.7 41 83.4 94.0 81.0 88.7 95.5Pr 8.35 7.81 8.32 8.52 8.2 8.65 8.15 5.41 7.45 7.55 6.65 5.09 9.83 10.42 9.21 9.93 10.70Nd 31.3 28.3 31.68 30.8 28.4 31.9 29.2 19.2 26.5 27.8 25.1 19.8 37.5 38.4 34.7 37.2 39.8Sm 5.57 4.68 6.32 5.22 4.79 5.48 4.96 3.02 4.27 4.69 4.19 3.45 6.19 6.25 5.53 6.05 6.55Eu 1.36 1.17 1.1 1.23 1.08 1.36 1.30 0.76 1.00 1.07 1.04 1.29 1.60 1.57 1.44 1.48 1.60Gd 4.46 3.34 4.02 3.98 3.58 4.02 3.54 2.17 3.09 3.36 2.69 2.92 4.64 4.50 4.17 4.38 4.63Tb 0.54 0.43 0.520 0.47 0.47 0.5 0.45 0.25 0.35 0.38 0.32 0.41 0.390 0.397 0.359 0.374 0.414Dy 2.7 1.99 2.72 2.46 2.3 2.5 2.03 1.22 1.64 1.98 1.22 1.89 2.84 2.79 2.63 2.74 2.91Ho 0.49 0.34 0.487 0.43 0.41 0.44 0.38 0.23 0.29 0.35 0.19 0.33 0.504 0.511 0.471 0.491 0.530Er 1.29 0.92 1.26 1.13 1.13 1.19 0.97 0.61 0.77 0.92 0.48 0.96 1.40 1.40 1.30 1.34 1.50Tm 0.17 0.13 0.16 0.15 0.14 0.15 0.13 0.09 0.11 0.12 0.06 0.13 0.186 0.185 0.167 0.179 0.188Yb 0.99 0.82 1 0.96 0.94 0.91 0.83 0.6 0.67 0.74 0.38 0.87 1.032 1.004 0.957 1.004 1.096Lu 0.13 0.12 0.13 0.14 0.13 0.12 0.11 0.09 0.1 0.1 0.04 0.12 0.166 0.166 0.157 0.172 0.173Hf 1.44 4.05 3.57 2.76 0.94 2.35 2.74 1.11 1.82 2.7 1.34 4.88 3.58 3.84 3.65 3.89 4.15Ta 0.69 0.79 0.77 0.73 0.92 0.69 0.69 0.82 0.76 0.82 0.62 0.4 0.582 0.567 0.534 0.573 0.592Pb 21 60.1 34.4 43.9 42.2 34.9 42.4 28 29.7 32.1 23 10.6 32.1 30.8 29.9 31.8 31.9Th 18 27.2 24.6 24.5 30.1 21.7 24.6 22.3 26 28.4 15 2.95 16.5 17.5 16.0 17.6 17.9U 2.97 6.64 5.66 5.91 4.48 5.16 5.39 5.11 4.84 8.33 2.83 0.92 2.58 2.43 2.35 2.46 2.57Mg#=Mg/(Mg+0.85?TFe2+).654 Y. Gao et al / Lithos 119 (2010) 651?663SampleID?
Loca?on?ZM-??1?
Zhunuo???
??Loca?on?
RockType?Zhunuo?
Granodi-???orite???
??Loca?on_RockType?SampleID?
RockType?ZM-??1?
Granodi-??orite???
??Sample_RockType?Zhunuo?(ZN),?which?lithologically?corresp-??ond?to?granodiori?c?and?grani?c??Context?Text?Sample_Loca?
n?Input?Data?
Joint?Inference?Results?Fig re 1: An example of joint inference be-tween a table and its context.1?
7???
14??
15?
21??1?
7??
8?
14??
15?
21??1?
7??
8?
14??
15?
21?
?Whole doc.Table-onlyText-onlyGeoscien?st?1?
Geoscien?st?2?
Geoscien?st?3?Figure 2: Job assignments for the humanstudy.ment in a table that tells us the type of rockand its weight?but data such as the locationwhere this rock was unearthed and in what ge-ological time interval this rock appeared mayno be specifi d in the table.We consider tasks in three domains:Petrology, Finan e, and Geology.
Foreach domain, we build a system to extract re-lations from text, tables, or b t .
We foundthat a joint inference system that uses non-shallow, but standard NLP features can sig-nificantly improv the quality of he extractedrelations, and that this result holds consistentlyacross all three domains.
For example, in ourPetrology application to extract a knowledgebase, call PetDB1, by using informationextracted from both text and tables, we canachieve twice as high F1 compared to either apure-table or pure-text system.2 Motivating Human StudyWe describe a simple human study that mo-tivated our approach to jointly combine bothtabular features and natural language featuresto extract relations from tables.
The hypoth-1http://www.earthchem.org/petdb0?0.2?0.4?0.6?0.8?1?Precision?
Recall?
F-??1?Text-??only?
Table-??only?
Whole?document?Figure 3: Human quality to extract Sample-Rocktype relations in PetDB.Task?
Text Table Joint NER?
POS?tags?Stanford?NER?Regular?Expression?Dic?onary?pd?otable?NER?of?neighbor?cells?Regular?expression?Dic?onary?#?columns?Whether?a?men?on??in?table?also?appears??in?the?text.?EL?
POS?tags?Bing?query?results?Freebase?Stanford?Parser?Pd?otable?Bing?query?results?Freebase?Subjec?e?men?ns??in?the?sentence?near??a?table?RE?
Dependency?path?Term?proximity?Word?sequence?Table?headers?Table?subheaders?RE?of?neighbor?rows?Join?between?rela?ons?
(See?Figure?1?for?an?example)?Figure 4: List of features we used in Text,Table, and Joint approaches.
NER, EL,and RE refer to named-entity recognition, en-tity linking, and relation extraction, respec-tively.esis that we want to validate is that the textsurrounding a table could provide valuable in-formation even for a human reader, and there-fore, n id l achine reading system shouldalso try to capture similar information.We asked three geoscientists to manuallyread journal articles nd extract relationsfor the Petrology domain.
We reportour r sults for he target relation, Sample-RockType, which associates a rock type witha rock sample (see Figure 1 for an example).We randomly sampled 21 journal articles.
Foreach journal article, we pr duced three vari-ants: (1) the original document; (2) table-only, which is the set of tables in the docu-ment (without the text); (3) text-only, whichis the text of the document with the tablesremoved from the document.
Each geoscien-tist was asked to read and extract the relationsfrom one of the three variants.
We then judgedthe precision and recall of their extraction, asshown in Figure 2.659As shown in Figure 3, human readers notsurprisingly achieve perfect precision on eachof the variants, but lower recall on boththe table-only and text-only variants.
How-ever, summing the recall of table-only (60%)and text-only (20%) variants together wouldachieve only 80% recall; this implies that inthe best case more than 20% of the extrac-tions require that the human reader read thetable and its surrounding text jointly.
Figure 1shows one representative example.This motivates our approach, which uses ajoint inference system to model features froma table and its surrounding text.
We also pro-pose to use deep linguistic features instead ofshallower features to get as close as possible tothe ability of human readers in understandingthe surrounding text of a table.3 Empirical Study & ExperimentsWe describe our experiments to test the hy-pothesis that (1) deeper linguistic features canhelp to extract higher quality relations fromtables, and (2) joint inference across tables andtext improves extraction quality compared toapproaches that use pure-table, pure-text, andnon-joint ways of combining these two.
Webriefly describe some experiments for a datasetthat we call Geology (Zhang et al, 2013).The detailed experimental results in all threedomains are in the technical report version ofthis paper.3.1 Experimental SetupWe consider the task of constructing a geol-ogy knowledge base.
Specifically, our goal isto extract a Rock-TotalOrganicCarbonrelation that maps rock formations (e.g., ?Bar-nett Formation?)
to their total organic carbon(e.g., ?6%?).
Such data is important for es-timating stored energy and for global climateresearch.Dataset.
We selected 100 geology journalarticles.2 We asked three geoscientists to an-notate these journal articles manually to ex-tract the Rock-TotalOrganicCarbon re-lation (1.5K tuples).
We processed each doc-ument using Stanford CoreNLP (de Marneffeet al, 2006; Toutanova and Manning, 2000),2We choose a set of documents that (1) are in En-glish, and (2) contain at least one table.PDFtoHTML3, and pdf2table (Yildiz, 2004).We then extracted features following state-of-the-art practices (see Figure 4).Approaches.
To validate our hypothesis,we implement four systems, each of which hasaccess to different types of data:(1) Table.
This approach follows Pinto etal.
(2003) and Dalvi et al (2012) and only usesthe tables in a document.
(2) Text.
This approach only has access tothe text in a document and contains all the fea-tures mentioned in Wu and Weld (2010) andMintz et al (2009).The features used in (1) and (2) are shown inFigure 4.
In both Table and Text, we use aconditional random field (Lafferty et al, 2001)model for the Rock-TotalOrganicCarbonrelation.
(3) Merge.
Using Table and Text, weextract all facts and their associated probabil-ity.
Following Duin (2002), we combine thesetwo probabilities using a linear combination.Merge is a baseline approach that uses infor-mation from both tables and text.
(4) Joint.
We build a joint approach thatuses information from both tables and text.This approach is a large factor graph in whichwe embed the CRFs developed in Table andText.
Additionally, we allow Joint to pre-dict projections of each relation, as shown inFigure 4.
Recall that a key advantage of a jointapproach is that we do not need to predict allarguments of the relation (if such a predictionis unwarranted from the data).
The inferenceis done by Gibbs sampling using our inferenceengine Elementary (Zhang and Re?, 2013).We describe the Joint system in more detailin the technical report version of this paper.3.2 End-to-End QualityWe were able to validate that Joint achieveshigher quality than the other three approacheswe considered.
Figure 5 shows the P/R curveof different approaches on three domains.
Weanalyzed the domain Geology.Joint dominates all other approaches.
Ata recall of 10%, Joint achieves 3x higher pre-cision than all other approaches.
In our erroranalysis, we saw that tables in geology articlesoften contain ambiguous words; for example,3http://pdftohtml.sourceforge.net/6600?0.2?0.4?0.6?0.8?1?0?
0.2?
0.4?Recall?Table?Text?
Merge?Joint?(b)?Petrology?Domain??0?0.2?0.4?0.6?0.8?1?0?
0.1?
0.2?
0.3?Precision?Recall?Joint?Merge?Text?Table?(a)?Geology?Domain??0?0.2?0.4?0.6?0.8?1?0?
0.1?
0.2?Recall?Joint?Table?Merge?Text?(c)?Finance?Domain?
?Figure 5: End-to-end extraction quality on Petrology, Finance, and GeoDeepDive.
Therecall is limited by the quality of state-of-the-art table recognition software on PDFs.the word ?Barnett?
in a table may refer to ei-ther a location or a rock formation.
By usingfeatures extracted from text, Joint achieveshigher precision.
For recall in the range of 0?10%, Merge outperforms both Text and Ta-ble, with 3%?90% improvement in precision.In Geology, Merge has precision that issimilar to Text and Table for the higher re-call range (>10%).
In this domain, we foundthat relations that appeared in the text oftenrepeated relations described in the table.
Inother domains, such as Petrology, wherethe relations in text and tables have lower de-grees of overlap, Merge significantly improvesover Text and Table (Figure 5(b)).We conducted a statistical significance testto check whether the improvement of Jointover the three other approaches is statisticallysignificant.
For each of the three probabilitythresholds, t ?
{.99, .90, .50}, we created theset of predictions that Joint assigns probabil-ity greater than t. Figure 6 shows the resultsof the statistical significance test in which thenull hypothesis is that the F1 scores of two ap-proaches are the same.
With p = 0.01, Jointhas statistically significant improvement of F1score over all three other approaches with eachprobability threshold.3.3 Shallow vs. Linguistic FeaturesWe validate the hypothesis that usinglinguistic features, e.g., part-of-speechtags (Toutanova and Manning, 2000),named-entity tags (Finkel et al, 2005), anddependency trees (de Marneffe et al, 2006),helps improve the quality of our approach,called Joint.
There are different ways touse shallow and linguistic features; we selectApproaches \ Prob.
.99 .90 .50Text + + +Table + + +Merge + + +Figure 6: Approximate randomization testfrom Chinchor (1992) of F1 score with p =0.01 on the impact of joint inference comparedwith pure-table or pure-text approaches fordifferent probability thresholds.
A + sign in-dicates that the F1 score of joint approach in-creased significantly.Type?
Features?Shallow?
Regular?Expressions?(Dalvi?et?al.,?2012)??Term?proximity?(Matsuo?et?al.,?2003)?Dic?onary?and?Freebase?(Mintz?et?al.,?2009)?Linguis??
POS?tags?(Wu?et?al.,?2010)?Stanford?NER?tags?(Mintz?et?al.,?2009)?Dependence?trees?
(Mintz?et?al.,?2009)?Figure 7: Types of Features.state-of-the-art approaches from the literature(see Figure 7).We created the following variants of Joint.Joint(-parse) removes features generated bythe dependency parser and syntax parser.Similarly, Joint(-ner) (Joint(-pos)) removesall features related to NER (resp.
POS).Joint(-pos) also removes NER and parser fea-tures because the latter two are dependent onPOS features.Figure 8 shows the P/R curve for allthese variants on Geology, and Figure 9shows the results of statistical significancetest.
For probability threshold .90, Jointoutperforms Joint(-pos) significantly.
Thedifference between Joint, Joint(-parse),6610?0.2?0.4?0.6?0.8?1?0?
0.1?
0.2?
0.3?Precision?Recall?Joint(-??pos)?Joint?Joint(-??parse)?Joint(-?
?ner)?Figure 8: Lesion study of different features forGeology.Features \ Prob.
.90 .50Joint(-parse) ?
Joint 0 +Joint(-ner) ?
Joint 0 +Joint(-pos) ?
Joint + +Figure 9: Approximate randomization test ofF1 score with p = 0.01 on the impact of lin-guistic features.
For x ?
y, a + indicates thatthe F1 score of y is significantly higher than x.0 indicates that the F1 score does not changesignificantly.and Joint(-ner) is not significant becausethere are ?easy-to-extract?
facts in the high-probability range.
For probability threshold.50, Joint outperforms all three other vari-ants significantly.4 Related WorkThe intuition that context features might helptable-related tasks has existed for decades.
Forexample, Hurst and Nasukawa (2000) men-tioned (as future work) that context featurescould be used to further improve their relationextraction approaches from tables.
Lin et al(2010) use bag-of-words features and hyper-links to recommend new columns for web ta-bles.
Liu et al (2007) extract features, includ-ing font size and title, from PDF documents inwhich a table appears to help the table rank-ing task.
They find that these features onlycontribute less than 2% to precision.
In con-trast, in our approach linguistic features arequite useful.
The above approaches use con-text features that can be extracted withoutPOS tagging or linguistic parsing.
One aspectof our work is to demonstrate that traditionalNLP tools can enhance the quality of table ex-traction.Extracting information from tables has beendiscussed by different communities in the lastdecade, including NLP (Wu and Lee, 2006;Tengli et al, 2004; Chen et al, 2000), artifi-cial intelligence (Fang et al, 2012; Pivk, 2006),information retrieval (Wei et al, 2006; Pintoet al, 2003), database (Cafarella et al, 2008),and the web (Dalvi et al, 2012).
This body ofwork considers only features derived from ta-bles and does not examine richer NLP featuresas we do.While joint inference is popular, it is notclear when a joint inference system outper-forms a more traditional NLP pipeline.
Re-cent studies have reached a variety of conclu-sions: in some, joint inference helps extractionquality (McCallum, 2009; Poon and Domin-gos, 2007; Singh et al, 2009); and in some,joint inference hurts extraction quality (Poonand Domingos, 2007; Eisner, 2009).
Our intu-ition is that joint inference is helpful in this ap-plication because our joint inference approachcombines non-redundant signals (textual ver-sus tabular).5 ConclusionTo improve the quality of extractions of tabu-lar data, we use standard NLP techniques tomore deeply understand the text in which atable is embedded.
We validate that deeperNLP features combined with a joint proba-bilistic model has a statistically significant im-pact on quality, i.e., recall and precision.
Ourongoing work is to apply these ideas to a muchlarger corpus from each of the three domains.6 AcknowledgmentsWe gratefully acknowledge the support of theDefense Advanced Research Projects Agency(DARPA) DEFT Program under Air ForceResearch Laboratory (AFRL) prime contractNo.
FA8750-13-2-0039, the National ScienceFoundation EAGER Award under No.
EAR-1242902 and CAREER Award under No.
IIS-1054009, and the Sloan Research Fellowship.Any opinions, findings, and conclusion or rec-ommendations expressed in this material arethose of the authors and do not necessarily re-flect the view of DARPA, AFRL, NSF, or theUS government.
We are also grateful to JudeW.
Shavlik for his insightful comments.662ReferencesMichael J. Cafarella, Alon Halevy, Daisy ZheWang, Eugene Wu, and Yang Zhang.
2008.WebTables: Exploring the power of tables on theweb.
Proceedings of VLDB Endowment, 1(1).Hsin-Hsi Chen, Shih-Chung Tsai, and Jin-He Tsai.2000.
Mining tables from large scale HTMLtexts.
In Proceedings of the 18th Conference onComputational Linguistics, COLING ?00.Nancy Chinchor.
1992.
The statistical significanceof the MUC-4 results.
In Proceedings of the 4thConference on Message Understanding, MUC4?92.Bhavana Bharat Dalvi, William Cohen, and JamieCallan.
2012.
WebSets: Extracting sets of en-tities from the web using unsupervised infor-mation extraction.
In Proceedings of the 5thACM International Conference on Web Searchand Data Mining, WSDM ?12.Marie-Catherine de Marneffe, Bill MacCartney,and Christopher D. Manning.
2006.
Generatingtyped dependency parses from phrase structureparses.
In Proceedings of the 5th InternationalConference on Language Resources and Evalua-tion.Robert Duin.
2002.
The combining classifier: totrain or not to train?
In 16th InternationalConference on Pattern Recognition.Jason Eisner.
2009.
Joint models with missingdata for semi-supervised learning.
In NAACLHLT Workshop on Semi-supervised Learning forNatural Language Processing.Jing Fang, Prasenjit Mitra, Zhi Tang, and C. LeeGiles.
2012.
Table header detection and classi-fication.
In Proceedings of the 26th AAAI Con-ference on Artificial Intelligence, AAAI ?12.Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local infor-mation into information extraction systems byGibbs sampling.
In Proceedings of the 43rd An-nual Meeting on Association for ComputationalLinguistics, ACL ?05.Matthew Hurst and Tetsuya Nasukawa.
2000.Layout and language: Integrating spatial andlinguistic knowledge for layout understandingtasks.
In Proceedings of the 18th Conference onComputational Linguistics, COLING ?00.John D. Lafferty, Andrew McCallum, and Fer-nando C. N. Pereira.
2001.
Conditional ran-dom fields: Probabilistic models for segmentingand labeling sequence data.
In Proceedings ofthe Eighteenth International Conference on Ma-chine Learning, ICML ?01, pages 282?289, SanFrancisco, CA, USA.
Morgan Kaufmann Pub-lishers Inc.Cindy Xide Lin, Bo Zhao, Tim Weninger, JiaweiHan, and Bing Liu.
2010.
Entity relation dis-covery from web tables and links.
In Proceedingsof the 19th International Conference on WorldWide Web, WWW ?10.Ying Liu, Kun Bai, Prasenjit Mitra, and C. LeeGiles.
2007.
TableSeer: Automatic table meta-data extraction and searching in digital libraries.In Proceedings of the 7th ACM/IEEE-CS JointConference on Digital Libraries, JCDL ?07.Andrew McCallum.
2009.
Joint inference for nat-ural language processing.
In Proceedings of the13th Conference on Computational Natural Lan-guage Learning, CoNLL ?09.Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-rafsky.
2009.
Distant supervision for relationextraction without labeled data.
In Proceedingsof the Joint Conference of the 47th Annual Meet-ing of the ACL and the 4th International JointConference on Natural Language Processing ofthe AFNLP, ACL ?09.David Pinto, Andrew McCallum, Xing Wei, andW.
Bruce Croft.
2003.
Table extraction us-ing conditional random fields.
In Proceedingsof the 26th Annual International ACM SIGIRConference on Research and Development in In-formaion Retrieval, SIGIR ?03.Aleksander Pivk.
2006.
Automatic ontology gen-eration from web tabular structures.
AI Com-munication, 19(1).Hoifung Poon and Pedro Domingos.
2007.
Jointinference in information extraction.
In Proceed-ings of the 22nd National Conference on Artifi-cial intelligence, AAAI?07.Sameer Singh, Karl Schultz, and Andrew Mc-Callum.
2009.
Bi-directional joint inferencefor entity resolution and segmentation usingimperatively-defined factor graphs.
In Pro-ceedings of the European Conference on Ma-chine Learning and Knowledge Discovery inDatabases, ECML PKDD ?09.Ashwin Tengli, Yiming Yang, and Nian Li Ma.2004.
Learning table extraction from examples.In Proceedings of the 20th International Con-ference on Computational Linguistics, COLING?04.Kristina Toutanova and Christopher D. Manning.2000.
Enriching the knowledge sources used ina maximum entropy part-of-speech tagger.
InProceedings of the 2000 Joint SIGDAT Confer-ence on Empirical Methods in Natural LanguageProcessing, EMNLP ?00.Xing Wei, Bruce Croft, and Andrew McCallum.2006.
Table extraction for answer retrieval.
In-formation Retrieval, 9(5).663Dekai Wu and Ken Wing Kuen Lee.
2006.
A gram-matical approach to understanding textual ta-bles using two-dimensional scfgs.
In Proceedingsof the COLING/ACL, COLING-ACL ?06.Fei Wu and Daniel S. Weld.
2010.
Open informa-tion extraction using Wikipedia.
In Proceedingsof the 48th Annual Meeting of the Associationfor Computational Linguistics, ACL ?10.Burcu Yildiz.
2004.
Information extraction ?
uti-lizing table patterns.
Master?s thesis, Institutfu?rSoftwaretechnik und Interaktive Systeme.Ce Zhang and Christopher Re?.
2013.
Towardshigh-throughput Gibbs sampling at scale: Astudy across storage managers.
SIGMOD ?13.Ce Zhang, Vidhya Govindaraju, Jackson Bor-chardt, Tim Foltz, Christopher Re?, and ShananPeters.
2013.
GeoDeepDive: Statistical infer-ence using familiar data-processing languages.SIGMOD ?13.664
