Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 55?60,Columbus, June 2008. c?2008 Association for Computational LinguisticsA Subcategorization Acquisition System for French VerbsCe?dric MessiantLaboratoire d?Informatique de Paris-NordCNRS UMR 7030 and Universite?
Paris 1399, avenue Jean-Baptiste Cle?ment, F-93430 Villetaneuse Francecedric.messiant@lipn.univ-paris13.frAbstractThis paper presents a system capable of auto-matically acquiring subcategorization frames(SCFs) for French verbs from the analysis oflarge corpora.
We applied the system to a largenewspaper corpus (consisting of 10 years ofthe French newspaper ?Le Monde?)
and ac-quired subcategorization information for 3267verbs.
The system learned 286 SCF types forthese verbs.
From the analysis of 25 represen-tative verbs, we obtained 0.82 precision, 0.59recall and 0.69 F-measure.
These results arecomparable with those reported in recent re-lated work.1 IntroductionMany Natural Language Processing (NLP) tasksrequire comprehensive lexical resources.
Hand-crafting large lexicons is labour-intensive and error-prone.
A growing body of research focuses thereforeon automatic acquisition of lexical resources fromtext corpora.One useful type of lexical information for NLP isthe number and type of the arguments of predicates.These are typically expressed in simple syntac-tic frames called subcategorization frames (SCFs).SCFs can be useful for many NLP applications, suchas parsing (John Carroll and Briscoe, 1998) or in-formation extraction (Surdeanu et al, 2003).
Au-tomatic acquisition of SCFs has therfore been anactive research area since the mid-90s (Manning,1993; Brent, 1993; Briscoe and Carroll, 1997).Comprehensive subcategorization information iscurrently not available for most languages.
Frenchis one of these languages: although manually builtsyntax dictionaries do exist (Gross, 1975; van denEynde and Mertens, 2006; Sagot et al, 2006) noneof them are ideal for computational use and nonealso provide frequency information important forstatistical NLP.We developed ASSCI, a system capable of ex-tracting large subcategorization lexicons for Frenchverbs from raw corpus data.
Our system is based ona approach similar to that of the well-known Cam-bridge subcategorization acquisition system for En-glish (Briscoe and Carroll, 1997; Preiss et al, 2007).The main difference is that unlike the Cambridgesystem, our system does not employ a set of pre-defined SCF types, but learns the latter dynamicallyfrom corpus data.We have recently used ASSCI to acquireLexSchem ?
a large subcategorization lexicon forFrench verbs ?
from a raw journalistic corpus.
andhave made the resulting resource freely available tothe community on the web (Messiant et al, 2008).We describe our SCF acquisition system in sec-tion 2 and explain the acquisition of a large subcat-egorization lexicon for French and its evaluation insection 3.
We finally compare our study with workpreviously achieved for English and French in sec-tion 4.2 ASSCI: The Acquisition SystemOur SCF acquisition system takes as input corpusdata and produces a list of frames for each verb thatoccurred more than 200 times in the corpus.
It thefirst system that automatically induces a large-scaleSCF information from raw corpus data for French.55Previous experiments focussed on a limited set ofverbs (Chesley and Salmon-Alt, 2006), or werebased on treebanks or on substantial manual work(Gross, 1975; Kups?c?, 2007).The system works in three steps:1. verbs and surrounding phrases are extractedfrom parsed corpus data;2. tentative SCFs are built dynamically, based onmorpho-syntactic information and relations be-tween the verb and its arguments;3. a statistical filter is used to filter out incorrectframes.2.1 PreprocessingWhen aiming to build a large lexicon for generallanguage, the input data should be large, balancedand representative enough.
Our system tags andlemmatizes input data using TreeTagger (Schmid,1994) and then syntactically analyses it using Syn-tex (Bourigault et al, 2005).
The TreeTagger is astatistical, language independent tool for the auto-matic annotation of part-of-speech and lemma in-formation.
Syntex is a shallow parser for extract-ing lexical dependencies (such as adjective/noun orverb/noun dependencies).
Syntex obtained the bestprecision and F-measure for written French text inthe recent EASY evaluation campaign1.The dependencies extracted by the parser includeboth arguments and adjuncts (such as location ortime phrases).
The parsing strategy is based onheuristics and statistics only.
This is ideal for ussince no lexical information should be used whenthe task is to acquire it.
Syntex works on the generalassumption that the word on the left side of the verbis the subject, where as the word on the right is theobject.
Exceptions to this assumption are dealt witha set of rules.
(2) Ces proprie?taires exploitantsache`tent ferme le carburant la1http://www.limsi.fr/Recherche/CORVAL/easyThe scores and ranks of Syntex at this evaluation campaignare available at http://w3.univ-tlse2.fr/erss/textes/pagespersos/bourigault/syntex.html#easycompagnie .
(These owners buy fast the fuel tothe company.
)(3) is the preprocessed ASSCI input for sentence(2) (after the TreeTagger annotation and Syntex?sanalysis).
(3) DetMP|ce|Ces|1|DET;3|AdjMP|proprie?taire|proprie?taires|2|ADJ;3|NomMP|exploitant|exploitants|3||DET;1,ADJ;2VCONJP|acheter|ache`tent|4||ADV;5,OBJ;7,PREP;8Adv|ferme|ferme|5|ADV;11|DetMS|le|le|6|DET;7|NomMS|carburant|carburant|7|OBJ;4|DET;6Prep|a`|a`|8|PREP;4|NOMPREP;10DetFS|le|la|9|DET;10|NomFS|compagnie|compagnie|10|NOMPREP;8|DET;9Typo|.|.|11||2.2 Pattern ExtractorThe pattern extraction module takes as input thesyntactic analysis of Syntex and extracts each verbwhich is sufficiently frequent (the minimum of 200corpus occurrences) in the syntactically analysedcorpus data, along with surrounding phrases.
Insome cases, this module makes deeper use of thedependency relations in the analysis.
For example,when a preposition is part of the dependencies, thepattern extractor examines whether this prepositionis followed by a noun phrase or an infinitive clause.
(4) is the output of the pattern extractor for (3).
(4) VCONJP|acheterNomMS|carburant|OBJ Prep|a`+SN|PREPNote that +SN marks that the ?a`?
preposition isfollowed by a noun phrase.2.3 SCF BuilderThe next module examines the dependencies accord-ing to their syntactic category (e.g., noun phrase)and their relation to the verb (e.g., object), if any.It constructs frames dynamically from the followingfeatures: a nominal phrase; infinitive clause; prepo-sitional phrase followed by a noun phrase; prepo-sitional phrase followed by an infinitive clause;subordinate clause and adjectival phrase.
If theverb has no dependencies, its SCF is ?intransitive?(INTRANS).
The number of occurrences for each56SCF and the total number of occurrences with eachverb are recorded.This dynamic approach to SCF learning wasadopted because no sufficiently comprehensive listof SCFs was available for French (most previouswork on English (e.g., (Preiss et al, 2007)) employsa set of predefined SCFs because a relatively com-prehensive lists are available for English).The SCF candidate built for sentence (2) isshown in (5)2.
(5) SN SP[a`+SN]2.4 SCF FilterThe final module filters the SCF candidates.
A fil-ter is necessary since the output of the second mod-ule is noisy, mainly because of tagging and parsingerrors but also because of the inherent difficulty ofargument-adjunct distinction which ideally requiresaccess to the lexical information we aim to acquire,along with other information and criteria which cur-rent NLP systems (and even humans) find it difficultto identify.
Several previous works (e.g., (Briscoeand Carroll, 1997; Chesley and Salmon-Alt, 2006))have used binomial hypothesis testing for filtering.Korhonen et al (2000) proposes to use the maxi-mum likelihood estimate and shows that this methodgives better results than the filter based on binomialhypothesis testing.
This method employs on a sim-ple threshold over the relative frequencies of SCFscandidates.
(The maximum likehood estimate is stillan option in the current Cambridge system but animproved version calculates it specific to differentSCFs - a method which we left for future work).The relative frequency of the SCF i with the verbj is calculated as follows:rel freq(scfi, verbj) =|scfi, verbj ||verbj ||scfi, verbj | is the number of occurrences of theSCF i with the verb j and |verbj | is the total numberof occurrences of the verb j in the corpus.These estimates are compared with the thresholdvalue to filter out low probability frames for eachverb.
The effect of the choice of the threshold on theresults is discussed in section 3.2SN stands for a noun phrase and SP for a prepositionalphrase3 Experimental Evaluation3.1 CorpusIn order to evaluate our system on a large corpus,we gathered ten years of the French newspaper LeMonde (two hundred millions words).
It is one ofthe largest corpus for French and ?clean?
enough tobe easily and efficiently parsed.
Because our aimwas to acquire a large general lexicon, we requirethe minimum of 200 occurrences per each verb weanalysed using this system.3.2 LexSchem: The Acquired Lexicon3267 verbs were found with more than 200 oc-currences in the corpus.
From the data for theseverbs, we induced 286 distinct SCF types.
We havemade the extracted lexicon freely available on theweb (http://www-lipn.univ-paris13.fr/?messiant/lexschem.html) under theLGPL-LR (Lesser General Public License ForLinguistic Resources) license.
An interface whichenables viewing the SCFs acquired for each verband the verbs taking different SCFs is also availableat the same address.
For more details of the lexiconand its format, see (Messiant et al, 2008).3.3 Gold StandardDirect evaluation of subcategorization acquisitionperformance against a gold standard based on amanmade dictionary is not ideal (see e.g.
(Poibeauand Messiant, 2008)).
However, this method is stillthe easiest and fastest way to get an idea of the per-formance of the system.
We built a gold standardusing the SCFs found in the Tre?sor de la LangueFranc?aise Informatise?
(TFLI), a large French dictio-nary available on the web3.
We evaluated 25 verbslisted in Appendix to evaluate our system.
Theseverbs were chosen for their heterogeneity in termsof semantic and syntactic features, but also becauseof their varied frequency in the corpus (from 200 to100.000 occurences).3.4 Evaluation MeasuresWe calculated type precision, type recall and F-measure for these 25 verbs.
We obtain the bestresults (0.822 precision, 0.587 recall and 0.685 f-measure) with the MLE threshold of 0.032 (see fig-3http://atilf.atilf.fr/57Figure 1: The relation of the threshold on the F-MeasureFigure 2: The relation between precision and recallure 1).
Figure 2 shows that even by substantiallylowering recall we cannot raise precision over 0.85.Table 1 shows a comparison of three versions ofASSCI for our 25 verbs:?
Unfiltered: the unfiltered output of ASSCI;?
ASSCI-1: one single threshold fixed to 0.0325;?
ASSCI-2: one INTRANS-specific threshold(0.08) and the 0.0325-threshold for all othercases.These results reveal that the unfiltered version ofthe lexicon is very noisy indeed (0.01 precision).System Precision Recall F-MeasureUnfiltered 0.010 0.921 0.020ASSCI-1 0.789 0.595 0.679ASSCI-2 0.822 0.587 0.685Table 1: Comparison of different versions of ASSCIA simple threshold on the relative frequencies im-proves the results dramatically (ASSCI-1).Each step of the acquisition process generates er-rors.
For example, some nouns are tagged as a verbby TreeTagger (e.g., in the phrase ?Le programmed?armement (weapons program)?, ?programme?
istagged verb).
Syntex generates errors when identi-fying dependencies: in some cases, it fails to iden-tify relevant dependencies; in other cases incorrectdependencies are generated.
The SCF builder is an-other source of error because of the ambiguity or thelack of sufficient information to build some frames(e.g.
those involving pronouns).
Finally, the filteringmodule rejects some correct SCFs and accept someincorrect ones.
We could reduce these errors by im-proving the filtering method or refining the thresh-olds.Many of the errors involve intransitive SCFs.
Wetried to address this problem with an INTRANS-specific threshold which is higher than others (seethe results for ASSCI-2).
This improves the preci-sion of the system slightly but does not substantiallyreduce the number of false negatives.
The intran-sitive form of verbs is very frequent in corpus databut it doesn?t appear in the gold standard.
A betterevaluation (e.g., a gold standard based on manualanalysis of the corpus data and annotation for SCFs)should not yield these errors.
In other cases (e.g.interpolated clauses), the parser is incapable of find-ing the dependencies.
In subsequent work we plan touse an improved version of Syntex which deals withthis problem.Our results (ASSCI-2) are similar with those ob-tained by the only directly comparable work forFrench (Chesley and Salmon-Alt, 2006) (0.87 pre-cision and 0.54 recall).
However, the lexicons showstill room for improvement, especially with recall.In addition to the improvements in the method andevaluation suggested above, we plan to evaluatewhether lexicons resulting from our system are use-58ful for NLP tasks and applications.
For example,John Carroll & al.
shows that a parser can be signif-icantly improved by using a SCF lexicon despite ahigh error rate (John Carroll and Briscoe, 1998).4 Related Work4.1 Manual or Semi-Automatic WorkMost previous subcategorization lexicons for Frenchwere built manually.
For example, Maurice Grossbuilt a large French dictionnary called ?Les Tablesdu LADL?
(Gross, 1975).
This dictionary is not easyto employ for NLP use but work in progress is aimedat addressing this problem (Gardent et al, 2005).The Lefff is a morphological and syntactic lexiconthat contains partial subcategorization information(Sagot et al, 2006), while Dicovalence is a manuallybuilt valency dictionnary based on the pronominalapproach (van den Eynde and Blanche-Benveniste,1978; van den Eynde and Mertens, 2006).
There arealso lexicons built using semi-automatic approachese.g., the acquisition of subcategorization informa-tion from treebanks (Kups?c?, 2007).4.2 Automatic WorkExperiments have been made on the automaticacquisition of subcategorization frames since mid1990s (Brent, 1993; Briscoe and Carroll, 1997).The first experiments were performed on English butsince the beginning of 2000s the approach has beensuccessfully applied to various other languages.
Forexample, (Schulte im Walde, 2002) has induced asubcategorization lexicon for German verbs from alexicalized PCFG.
Our approach is quite similar tothe work done in Cambridge.
The Cambridge sys-tem has been regularly improved and evaluated; andit represents the state-of-the-art perfomance on thetask (Briscoe and Carroll, 1997; Korhonen et al,2000; Preiss et al, 2007).
In the latest paper, the au-thors show that the method can be successfully ap-plied to acquire SCFs not only for verbs but also fornouns and adjectives (Preiss et al, 2007).
A majordifference between these related works and ours isthe fact that we do not use a predefined set of SCFs.Of course, the number of frames depends on thelanguage, the corpus, the domain and the informa-tion taken into account (for example, (Preiss et al,2007) used a list of 168 predefined frames for En-glish which abstract over lexically-governed prepo-sitions).As far as we know, the only directly compara-ble work on subcategorization acquisition for Frenchis (Chesley and Salmon-Alt, 2006) who proposea method for acquiring SCFs from a multi-genrecorpus in French.
Their work relies on the VISLparser which have an ?unevaluated (and potentiallyhigh) error rate?
while our system relies on Syntexwhich is, according to the EASY evaluation cam-paign, the best parser for French (as evaluated ongeneral newspaper corpora).
Additionally, we ac-quired a large subcategorization lexicon (availableon the web) (286 distinct SCFs for 3267 verbs)whereas (Chesley and Salmon-Alt, 2006) producedonly 27 SCFs for 104 verbs and didn?t produce anylexicon for public release.5 ConclusionWe have introduced a system which we have devel-oped for acquiring large subcategorization lexiconsfor French verbs.
When the system was applied toa large French newspaper corpus, it produced a lex-icon of 286 SCFs corresponding to 3267 verbs.
Weevaluated this lexicon by comparing the SCFs it pro-duced for 25 test verbs to those included in a manu-ally built dictionary and obtained promising results.We made the automatically acquired lexicon freelyavailable on the web under the LGPL-LR license(and through a web interface).Future work will include improvements of the fil-tering module (using e.g.
SCF-specific thresholdsor statistical hypothesis testing) and exploration oftask-based evaluation in the context of practical NLPapplications and tasks such as the acquisition of se-mantic classes from the SCFs (Levin, 1993).AcknowledgementsCe?dric Messiant?s PhD is funded by a DGA/CNRSGrant.
The research presented in this paper was alsosupported by the ANR MDCO ?CroTal?
project andthe British Council and the French Ministry of For-eign Affairs -funded ?Alliance?
grant.ReferencesDidier Bourigault, Marie-Paule Jacques, Ce?cile Fabre,Ce?cile Fre?rot, and Sylwia Ozdowska.
2005.
Syntex,59analyseur syntaxique de corpus.
In Actes des 12e`mesjourne?es sur le Traitement Automatique des LanguesNaturelles, Dourdan.Michael R. Brent.
1993.
From Grammar to Lexicon:Unsupervised Learning of Lexical Syntax.
Computa-tional Linguistics, 19:203?222.Ted Briscoe and John Carroll.
1997.
Automatic Ex-traction of Subcategorization from Corpora.
In Pro-ceedings of the 5th ACL Conference on Applied Nat-ural Language Processing, pages 356?363, Washing-ton, DC.Paula Chesley and Susanne Salmon-Alt.
2006.
Au-tomatic extraction of subcategorization frames forFrench.
In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Genua (Italy).Claire Gardent, Bruno Guillaume, Guy Perrier, and In-grid Falk.
2005.
Maurice Gross?
Grammar Lexiconand Natural Language Processing.
In 2nd Languageand Technology Conference, Poznan.Maurice Gross.
1975.
Me?thodes en syntaxe.
Hermann,Paris.Guido Minnen John Carroll and Ted Briscoe.
1998.Can subcategorisation probabilities help a statisticalparser?
In Proceedings of the 6th ACL/SIGDAT Work-shop on Very Large Corpora, Montreal (Canada).Anna Korhonen, Genevieve Gorrell, and Diana Mc-Carthy.
2000.
Statistical filtering and subcategoriza-tion frame acquisition.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing and Very Large Corpora, Hong Kong.Anna Kups?c?.
2007.
Extraction automatique de cadresde sous-cate?gorisation verbale pour le franc?ais a` par-tir d?un corpus arbore?.
In Actes des 14e`mes journe?essur le Traitement Automatique des Langues Naturelles,Toulouse, June.Beth Levin.
1993.
English Verb Classes and Alter-nations: a preliminary investigation.
University ofChicago Press, Chicago and London.Christopher D. Manning.
1993.
Automatic Acquisitionof a Large Subcategorization Dictionary from Cor-pora.
In Proceedings of the Meeting of the Associationfor Computational Linguistics, pages 235?242.Ce?dric Messiant, Anna Korhonen, and Thierry Poibeau.2008.
LexSchem : A Large Subcategorization Lex-icon for French Verbs.
In Language Resources andEvaluation Conference (LREC), Marrakech.Thierry Poibeau and Ce?dric Messiant.
2008.
Do We StillNeed Gold Standard For Evaluation ?
In Proceedingsof the Language Resources and Evaluation Conference(LREC), Marrakech.Judita Preiss, Ted Briscoe, and Anna Korhonen.
2007.
ASystem for Large-Scale Acquisition of Verbal, Nom-inal and Adjectival Subcategorization Frames fromCorpora.
In Proceedings of the Meeting of the Associ-ation for Computational Linguistics, pages 912?918,Prague.Beno?
?t Sagot, Lionel Cle?ment, Eric de La Clergerie, andPierre Boullier.
2006.
The Lefff 2 syntactic lexiconfor French: architecture, acquisition, use.
In Proceed-ings of the Language Resources and Evaluation Con-ference (LREC), Genua (Italy).Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In International Con-ference on New Methods in Language Processing,Manchester, UK.
unknown.Sabine Schulte im Walde.
2002.
A SubcategorisationLexicon for German Verbs induced from a LexicalisedPCFG.
In Proceedings of the 3rd Conference on Lan-guage Resources and Evaluation, volume IV, pages1351?1357, Las Palmas de Gran Canaria, Spain.Mihai Surdeanu, Sanda M. Harabagiu, John Williams,and Paul Aarseth.
2003.
Using Predicate-ArgumentStructures for Information Extraction.
In Proceed-ings of the Association of Computational Linguistics(ACL), pages 8?15.Karel van den Eynde and Claire Blanche-Benveniste.1978.
Syntaxe et me?canismes descriptifs :pre?sentation de l?approche pronominale.
Cahiersde Lexicologie, 32:3?27.Karel van den Eynde and Piet Mertens.
2006.
Le dictio-nnaire de valence Dicovalence : manuel d?utilisation.Manuscript, Leuven.Appendix ?
List of test verbscompter donner apprendrechercher possder comprendreconcevoir proposer montrerrendre s?abattre joueroffrir continuer ouvriraimer croire existerobtenir refuser programmeracheter rester s?ouvrirvenir60
