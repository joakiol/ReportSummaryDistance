Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 59?63,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsApplicative structure in vector space modelsMa?rton Makrai Da?vid NemeskeyHAS Computer and Automation Research InstituteH-1111 Kende u 13-17, Budapest{makrai,ndavid,kornai}@sztaki.huAndra?s KornaiAbstractWe introduce a new 50-dimensional em-bedding obtained by spectral clustering ofa graph describing the conceptual struc-ture of the lexicon.
We use the embeddingdirectly to investigate sets of antonymicpairs, and indirectly to argue that func-tion application in CVSMs requires notjust vectors but two transformations (cor-responding to subject and object) as well.1 IntroductionCommutativity is a fundamental property of vec-tor space models.
As soon as we encode king by~k, queen by ~q, male by ~m, and female by ~f , if weexpect ~k ?
~q ?
~m ?
~f , as suggested in Mikolovet al(2013), we will, by commutativity, also ex-pect ~k ?
~m ?
~q ?
~f ?ruler, gender unspecified?.When the meaning decomposition involves func-tion application, commutativity no longer makessense: consider Victoria as ~qmEngland and Victoras ~kmItaly.
If the function application operator mis simply another vector to be added to the rep-resentation, the same logic would yield that Italyis the male counterpart of female England.
Tomake matters worse, performing the same oper-ations on Albert, ~kmEngland and Elena, ~qmItalywould yield that Italy is the female counterpart ofmale England.Section 2 offers a method to treat antonymy incontinuous vector space models (CVSMs).
Sec-tion 3 describes a new embedding, 4lang, obtainedby spectral clustering from the definitional frame-work of the Longman Dictionary of Contempo-rary English (LDOCE, see Chapter 13 of McArtur1998), and Section 4 shows how to solve the prob-lem outlined above by treating m and n not as avectors but as transformations.2 Diagnostic properties of additivedecompositionThe standard model of lexical decomposition(Katz and Fodor, 1963) divides lexical meaning ina systematic component, given by a tree of (gener-ally binary) features, and an accidental componentthey call the distinguisher.
Figure 1 gives an ex-ample.bachelornoun(Animal)(Male)[young furseal whenwithout a mateduring thebreeding time](Human)[who has thefirst or lowestacademicdegree](Male)[young knightserving underthe standard ofanother knight][whohas nevermarried]Figure 1: Decomposition of lexical items to fea-tures (Katz and Fodor, 1963)This representation has several advantages: forexample bachelor3 ?holder of a BA or BSc de-gree?
neatly escapes being male by definition.
Wetested which putative semantic features like GEN-DER are captured by CVSMs.
We assume that thedifference between two vectors, for antonyms, dis-tills the actual property which is the opposite ineach member of a pair of antonyms.
So, for ex-ample, for a set of male and female words, suchas xking, queeny, xactor, actressy, etc., the differ-ence between words in each pair should representthe idea of gender.
To test the hypothesis, we as-59GOOD VERTICALsafe out raise levelpeace war tall shortpleasure pain rise fallripe green north southdefend attack shallow deepconserve waste ascending descendingaffirmative negative superficial profound............Table 1: Word pairs associated to features GOODand VERTICALsociated antonymic word pairs from the WordNet(Miller, 1995) to 26 classes e.g.
END/BEGINNING,GOOD/BAD, .
.
.
, see Table 1 and Table 3 for ex-amples.
The intuition to be tested is that the firstmember of a pair relates to the second one in thesame way among all pairs associated to the samefeature.
For k pairs ~xi, ~yi we are looking for acommon vector ~a such that~xi ?
~yi ?
~a (1)Given the noise in the embedding, it would benaive in the extreme to assume that (1) can be astrict identity.
Rather, our interest is with the best~a which minimizes the errorErr ?
?i||~xi ?
~yi ?
~a||2 (2)As is well known, E will be minimal when ~a ischosen as the arithmetic mean of the vectors ~xi ?~yi.
The question is simply the following: is theminimal Em any better than what we could expectfrom a bunch of random ~xi and ~yi?Since the sets are of different sizes, we took 100random pairings of the words appearing on eithersides of the pairs to estimate the error distribution,computing the minima ofErrrand ?
?i||~xi1 ?
~y1i ?
~a||2 (3)For each distribution, we computed the meanand the variance ofErrrand, and checked whetherthe error of the correct pairing, Err is at least 2 or3 ?s away from the mean.Table 2 summarizes our results for three embed-dings: the original and the scaled HLBL (Mnihand Hinton, 2009) and SENNA (Collobert et al2011).
The first two columns give the number ofpairs considered for a feature and the name of thePRIMARY ANGULARleading following square roundpreparation resolution sharp flatprecede follow curved straightintermediate terminal curly straightantecedent subsequent angular roundedprecede succeed sharpen softenquestion answer angularity roundness............Table 3: Features that fail the testfeature.
For each of the three embeddings, we re-port the errorErr of the unpermuted arrangement,the mean m and variance ?
of the errors obtainedunder random permutations, and the ratior ?|m?
Err|?.Horizontal lines divide the features to threegroups: for the upper group, r ?
3 for at leasttwo of the three embeddings, and for the middlegroup r ?
2 for at least two.For the features above the first line we concludethat the antonymic relations are well captured bythe embeddings, and for the features below thesecond line we assume, conservatively, that theyare not.
(In fact, looking at the first column of Ta-ble 2 suggests that the lack of significance at thebottom rows may be due primarily to the fact thatWordNet has more antonym pairs for the featuresthat performed well on this test than for those fea-tures that performed badly, but we didn?t want tostart creating antonym pairs manually.)
For exam-ple, the putative sets in Table 3 does not meet thecriterion and gets rejected.3 Embedding based on conceptualrepresentationThe 4lang embedding is created in a manner thatis notably different from the others.
Our input is agraph whose nodes are concepts, with edges run-ning from A to B iff B is used in the definition ofA.
The base vectors are obtained by the spectralclustering method pioneered by (Ng et al 2001):the incidence matrix of the conceptual network isreplaced by an affinity matrix whose ij-th elementis formed by computing the cosine distance of theith and jth row of the original matrix, and the firstfew (in our case, 100) eigenvectors are used as abasis.Since the concept graph includes the entireLongman Defining Vocabulary (LDV), each LDV60# feature HLBL original HLBL scaled SENNApairs name Err m ?
r Err m ?
r Err m ?
r156 good 1.92 2.29 0.032 11.6 4.15 4.94 0.0635 12.5 50.2 81.1 1.35 22.942 vertical 1.77 2.62 0.0617 13.8 3.82 5.63 0.168 10.8 37.3 81.2 2.78 15.849 in 1.94 2.62 0.0805 8.56 4.17 5.64 0.191 7.68 40.6 82.9 2.46 17.232 many 1.56 2.46 0.0809 11.2 3.36 5.3 0.176 11 43.8 76.9 3.01 1165 active 1.87 2.27 0.0613 6.55 4.02 4.9 0.125 6.99 50.2 84.4 2.43 14.148 same 2.23 2.62 0.0684 5.63 4.82 5.64 0.14 5.84 49.1 80.8 2.85 11.128 end 1.68 2.49 0.124 6.52 3.62 5.34 0.321 5.36 34.7 76.7 4.53 9.2532 sophis 2.34 2.76 0.105 4.01 5.05 5.93 0.187 4.72 43.4 78.3 2.9 1236 time 1.97 2.41 0.0929 4.66 4.26 5.2 0.179 5.26 51.4 82.9 3.06 10.320 progress 1.34 1.71 0.0852 4.28 2.9 3.72 0.152 5.39 47.1 78.4 4.67 6.734 yes 2.3 2.7 0.0998 4.03 4.96 5.82 0.24 3.6 59.4 86.8 3.36 8.1723 whole 1.96 2.19 0.0718 3.2 4.23 4.71 0.179 2.66 52.8 80.3 3.18 8.6518 mental 1.86 2.14 0.0783 3.54 4.02 4.6 0.155 3.76 51.9 73.9 3.52 6.2614 gender 1.27 1.68 0.126 3.2 2.74 3.66 0.261 3.5 19.8 57.4 5.88 6.3812 color 1.2 1.59 0.104 3.7 2.59 3.47 0.236 3.69 46.1 70 5.91 4.0417 strong 1.41 1.69 0.0948 2.92 3.05 3.63 0.235 2.48 49.5 74.9 3.34 7.5916 know 1.79 2.07 0.0983 2.88 3.86 4.52 0.224 2.94 47.6 74.2 4.29 6.2112 front 1.48 1.95 0.17 2.74 3.19 4.21 0.401 2.54 37.1 63.7 5.09 5.2322 size 2.13 2.69 0.266 2.11 4.6 5.86 0.62 2.04 45.9 73.2 4.39 6.2110 distance 1.6 1.76 0.0748 2.06 3.45 3.77 0.172 1.85 47.2 73.3 4.67 5.5810 real 1.45 1.61 0.092 1.78 3.11 3.51 0.182 2.19 44.2 64.2 5.52 3.6314 primary 2.22 2.43 0.154 1.36 4.78 5.26 0.357 1.35 59.4 80.9 4.3 58 single 1.57 1.82 0.19 1.32 3.38 3.83 0.32 1.4 40.3 70.7 6.48 4.698 sound 1.65 1.8 0.109 1.36 3.57 3.88 0.228 1.37 46.2 62.7 6.17 2.677 hard 1.46 1.58 0.129 0.931 3.15 3.41 0.306 0.861 42.5 60.4 8.21 2.1810 angular 2.34 2.45 0.203 0.501 5.05 5.22 0.395 0.432 46.3 60 6.18 2.2Table 2: Error of approximating real antonymic pairs (Err), mean and standard deviation (m,?)
of errorwith 100 random pairings, and the ratio r ?
|Err?m|?
for different features and embeddingselement wi corresponds to a base vector bi.
Forthe vocabulary of the whole dictionary, we sim-ply take the Longman definition of any word w,strip out the stopwords (we use a small list of 19elements taken from the top of the frequency dis-tribution), and form V pwq as the sum of the bi forthe wis that appeared in the definition of w (withmultiplicity).We performed the same computations based onthis embedding as in Section 2: the results are pre-sented in Table 4.
Judgment columns under thefour three embeddings in the previous section and4lang are highly correlated, see table 5.Unsurprisingly, the strongest correlation is be-tween the original and the scaled HLBL results.Both the original and the scaled HLBL correlatenotably better with 4lang than with SENNA, mak-ing the latter the odd one out.4 ApplicativitySo far we have seen that a dictionary-based em-bedding, when used for a purely semantic task, theanalysis of antonyms, does about as well as themore standard embeddings based on cooccurrencedata.
Clearly, a CVSM could be obtained by thesame procedure from any machine-readable dic-# feature 4langpairs name Err m ?
r49 in 0.0553 0.0957 0.00551 7.33156 good 0.0589 0.0730 0.00218 6.4542 vertical 0.0672 0.1350 0.01360 4.9834 yes 0.0344 0.0726 0.00786 4.8623 whole 0.0996 0.2000 0.02120 4.7428 end 0.0975 0.2430 0.03410 4.2732 many 0.0516 0.0807 0.00681 4.2614 gender 0.0820 0.2830 0.05330 3.7636 time 0.0842 0.1210 0.00992 3.7465 active 0.0790 0.0993 0.00553 3.6820 progress 0.0676 0.0977 0.00847 3.5618 mental 0.0486 0.0601 0.00329 3.5148 same 0.0768 0.0976 0.00682 3.0522 size 0.0299 0.0452 0.00514 2.9816 know 0.0598 0.0794 0.00706 2.7732 sophis 0.0665 0.0879 0.00858 2.5012 front 0.0551 0.0756 0.01020 2.0110 real 0.0638 0.0920 0.01420 1.988 single 0.0450 0.0833 0.01970 1.957 hard 0.0312 0.0521 0.01960 1.0610 angular 0.0323 0.0363 0.00402 0.99912 color 0.0564 0.0681 0.01940 0.6008 sound 0.0565 0.0656 0.01830 0.49517 strong 0.0693 0.0686 0.01111 0.062514 primary 0.0890 0.0895 0.00928 0.052910 distance 0.0353 0.0351 0.00456 0.0438Table 4: The results on 4lang61HLBL HLBL SENNA 4langoriginal scaledHLBL original 1 0.925 0.422 0.856HLBL scaled 0.925 1 0.390 0.772SENNA 0.422 0.390 1 0.3614lang 0.856 0.772 0.361 1Table 5: Correlations between judgments based ondifferent embeddingstionary.
Using LDOCE is computationally advan-tageous in that the core vocabulary is guaranteedto be very small, but finding the eigenvectors foran 80k by 80k sparse matrix would also be withinCPU reach.
The main advantage of starting with aconceptual graph lies elsewhere, in the possibilityof investigating the function application issue westarted out with.The 4lang conceptual representation relies on asmall number of basic elements, most of whichcorrespond to what are called unary predicates inlogic.
We have argued elsewhere (Kornai, 2012)that meaning of linguistic expressions can be for-malized using predicates with at most two argu-ments (there are no ditransitive or higher aritypredicates on the semantic side).
The x and yslots of binary elements such as x has y or x killy, (Kornai and Makrai 2013) receive distinct la-bels called NOM and ACC in case grammar (Fill-more, 1977); 1 and 2 in relational grammar (Perl-mutter, 1983); or AGENT and PATIENT in linkingtheory (Ostler, 1979).
The label names themselvesare irrelevant, what matters is that these elementsare not part of the lexicon the same way as thewords are, but rather constitute transformations ofthe vector space.Here we will use the binary predicate x has yto reformulate the puzzle we started out with, an-alyzing queen of England, king of Italy etc.
in acompositional (additive) manner, but escaping thecommutativity problem.
For the sake of concrete-ness we use the traditional assumption that it isthe king who possesses the realm and not the otherway around, but what follows would apply just aswell if the roles were reversed.
What we are inter-ested in is the asymmetry of expressions like Al-bert has England or Elena has Italy, in contrast tolargely symmetric predicates.
Albert marries Vic-toria will be true if and only if Victoria marriesAlbert is true, but from James has a martini it doesnot follow that ?A martini has James.While the fundamental approach of CVSM isquite correct in assuming that nouns (unaries)and verbs (binaries) can be mapped on the samespace, we need two transformations T1 and T2to regulate the linking of arguments.
A formlike James kills has James as agent, so we com-pute V (James)`T1V (kill), while kills James is ob-tained as V (James)`T2V (kill).
The same twotransforms can distinguish agent and patient rel-atives as in the man that killed James versus theman that James killed.Such forms are compositional, and in languagesthat have overt case markers, even ?surface com-positional?
(Hausser, 1984).
All input and outputsare treated as vectors in the same space where theatomic lexical entries get mapped, but the applica-tive paradox we started out with goes away.
Aslong as the transforms T1 (n) and T2 (m) take dif-ferent values on kill, has, or any other binary, themeanings are kept separate.AcknowledgmentsMakrai did the work on antonym set testing,Nemeskey built the embedding, Kornai advised.We would like to thank Zso?fia Tardos (BUTE) andthe anonymous reviewers for useful comments.Work supported by OTKA grant #82333.ReferencesR.
Collobert, J. Weston, L. Bottou, M. Karlen,K.
Kavukcuoglu, and P. Kuksa.
2011.
Natural lan-guage processing (almost) from scratch.
Journal ofMachine Learning Research (JMLR).Charles Fillmore.
1977.
The case for case reopened.In P. Cole and J.M.
Sadock, editors, GrammaticalRelations, pages 59?82.
Academic Press.Roland Hausser.
1984.
Surface compositional gram-mar.
Wilhelm Fink Verlag, Mu?nchen.J.
Katz and Jerry A. Fodor.
1963.
The structure of asemantic theory.
Language, 39:170?210.Andra?s Kornai and Ma?rton Makrai.
2013.
A 4langfogalmi szo?ta?r [the 4lang concept dictionary].
InA.
Tana?cs and V. Vincze, editors, IX.
MagyarSza?mito?ge?pes Nyelve?szeti Konferencia [Ninth Con-ference on Hungarian Computational Linguistics],pages 62?70.Andra?s Kornai.
2012.
Eliminating ditransitives.
InPh.
de Groote and M-J Nederhof, editors, Revisedand Selected Papers from the 15th and 16th FormalGrammar Conferences, LNCS 7395, pages 243?261.
Springer.62Tom McArthur.
1998.
Living Words: Language, Lex-icography, and the Knowledge Revolution.
ExeterLanguage and Lexicography Series.
University ofExeter Press.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
to appear.
Efficient estimation of word repre-sentations in vector space.
In Y. Bengio, , and Y. Le-Cun, editors, Proc.
ICLR 2013.George A. Miller.
1995.
Wordnet: a lexicaldatabase for english.
Communications of the ACM,38(11):39?41.Andriy Mnih and Geoffrey E Hinton.
2009.
A scalablehierarchical distributed language model.
Advancesin neural information processing systems, 21:1081?1088.Andrew Y. Ng, Michael I. Jordan, and Yair Weiss.2001.
On spectral clustering: Analysis and an algo-rithm.
In Advances in neural information processingsystems, pages 849?856.
MIT Press.Nicholas Ostler.
1979.
Case-Linking: a Theory ofCase and Verb Diathesis Applied to Classical San-skrit.
PhD thesis, MIT.David M. Perlmutter.
1983.
Studies in RelationalGrammar.
University of Chicago Press.63
