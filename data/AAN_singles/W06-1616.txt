Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 129?137,Sydney, July 2006. c?2006 Association for Computational LinguisticsIncremental Integer Linear Programming for Non-projective DependencyParsingSebastian Riedel and James ClarkeSchool of Informatics, University of Edinburgh2 Bucclecuch Place, Edinburgh EH8 9LW, UKs.r.riedel@sms.ed.ac.uk, jclarke@ed.ac.ukAbstractInteger Linear Programming has recentlybeen used for decoding in a number ofprobabilistic models in order to enforceglobal constraints.
However, in certain ap-plications, such as non-projective depen-dency parsing and machine translation,the complete formulation of the decod-ing problem as an integer linear programrenders solving intractable.
We present anapproach which solves the problem in-crementally, thus we avoid creating in-tractable integer linear programs.
This ap-proach is applied to Dutch dependencyparsing and we show how the additionof linguistically motivated constraints canyield a significant improvement over state-of-the-art.1 IntroductionMany inference algorithms require models tomake strong assumptions of conditional indepen-dence between variables.
For example, the Viterbialgorithm used for decoding in conditional ran-dom fields requires the model to be Markovian.Strong assumptions are also made in the case ofMcDonald et al?s (2005b) non-projective depen-dency parsing model.
Here attachment decisionsare made independently of one another1.
However,often such assumptions can not be justified.
Forexample in dependency parsing, if a subject hasalready been identified for a given verb, then theprobability of attaching a second subject to theverb is zero.
Similarly, if we find that one coor-dination argument is a noun, then the other argu-1If we ignore the constraint that dependency trees must becycle-free (see sections 2 and 3 for details).ment cannot be a verb.
Thus decisions are oftenco-dependent.Integer Linear Programming (ILP) has recentlybeen applied to inference in sequential condi-tional random fields (Roth and Yih, 2004), thishas allowed the use of truly global constraintsduring inference.
However, it is not possible touse this approach directly for a complex task likenon-projective dependency parsing due to the ex-ponential number of constraints required to pre-vent cycles occurring in the dependency graph.To model all these constraints explicitly would re-sult in an ILP formulation too large to solve effi-ciently (Williams, 2002).
A similar problem alsooccurs in an ILP formulation for machine transla-tion which treats decoding as the Travelling Sales-man Problem (Germann et al, 2001).In this paper we present a method which extendsthe applicability of ILP to a more complex set ofproblems.
Instead of adding all the constraints wewish to capture to the formulation, we first solvethe program with a fraction of the constraints.
Thesolution is then examined and, if required, addi-tional constraints are added.
This procedure is re-peated until all constraints are satisfied.
We applythis dependency parsing approach to Dutch dueto the language?s non-projective nature, and takethe parser of McDonald et al (2005b) as a startingpoint for our model.In the following section we introduce depen-dency parsing and review previous work.
In Sec-tion 3 we present our model and formulate it asan ILP problem with a set of linguistically mo-tivated constraints.
We include details of an in-cremental algorithm used to solve this formula-tion.
Our experimental set-up is provided in Sec-tion 4 and is followed by results in Section 5 alongwith runtime experiments.
We finally discuss fu-129Figure 1: A Dutch dependency tree for ?I?ll comeat twelve and then you?ll get what you deserve?ture research and potential improvements to ourapproach.2 Dependency ParsingDependency parsing is the task of attaching wordsto their arguments.
Figure 1 shows a dependencygraph for the Dutch sentence ?I?ll come at twelveand then you?ll get what you deserve?
(taken fromthe Alpino Corpus (van der Beek et al, 2002)).
Inthis dependency graph the verb ?kom?
is attachedto its subject ?ik?.
?kom?
is referred to as the headof the dependency and ?ik?
as its child.
In labelleddependency parsing edges between words are la-belled with the relation captured.
In the case ofthe dependency between ?kom?
and ?ik?
the labelwould be ?subject?.In a dependency tree every token must be thechild of exactly one other node, either another to-ken or the dummy root node.
By definition, a de-pendency tree is free of cycles.
For example, itmust not contain dependency chains such as ?en??
?kom??
?ik??
?en?.
For a more formal def-inition see previous work (Nivre et al, 2004).An important distinction between dependencytrees is whether they are projective or non-projective.
Figure 1 is an example of a projec-tive dependency tree, in such trees dependenciesdo not cross.
In Dutch and other flexible word or-der languages such as German and Czech we alsoencounter non-projective trees, in these cases thetrees contain crossing dependencies.Dependency parsing is useful for applicationssuch as relation extraction (Culotta and Sorensen,2004) and machine translation (Ding and Palmer,2005).
Although less informative than lexicalisedphrase structures, dependency structures still cap-ture most of the predicate-argument informationneeded for applications.
It has the advantage of be-ing more efficient to learn and parse.McDonald et al (2005a) introduce a depen-dency parsing framework which treats the task assearching for the projective tree that maximisesthe sum of local dependency scores.
This frame-Figure 2: An incorrect partial dependency tree.The verb ?krijg?
is incorrectly coordinated withthe preposition ?om?.work is efficient and has also been extended tonon-projective trees (McDonald et al, 2005b).
Itprovides a discriminative online learning algo-rithm which when combined with a rich feature setreaches state-of-the-art performance across multi-ple languages.However, within this framework one can onlydefine features over single attachment decisions.This leads to cases where basic linguistic con-straints are not satisfied (e.g.
verbs with two sub-jects or incompatible coordination arguments).
Anexample of this for Dutch is illustrated in Figure 2which was produced by the parser of McDonaldet al (2005b).
Here the parse contains a coordi-nation of incompatible word classes (a prepositionand a verb).Our approach is able to include additional con-straints which forbid configurations such as thosein Figure 2.
While McDonald and Pereira (2006)address the issue of local attachment decisions bydefining scores over attachment pairs, our solutionis more general.
Furthermore, it is complementaryin the sense that we could formulate their modelusing ILP and then add constraints.The method we present is not the only one thatcan take global constraints into account.
Deter-ministic dependency parsing (Nivre et al, 2004;Yamada and Matsumoto, 2003) can apply globalconstraints by conditioning attachment decisionson the intermediate parse built.
However, for effi-ciency a greedy search is used which may producesub-optimal solutions.
This is not the case whenusing ILP.3 ModelOur underlying model is a modified labelled ver-sion2 of McDonald et al (2005b):s(x,y) =?
(i,j,l)?ys(i, j, l)=?
(i,j,l)?yw ?
f(i, j, l)2Note that this is not described in the McDonald papersbut implemented in his software.130where x is a sentence, y is a set of labelled de-pendencies, f(i, j, l) is a multidimensional fea-ture vector representation of the edge from tokeni to token j with label l and w the correspond-ing weight vector.
For example, a feature f101 in fcould be:f101(i, j, l) =????
?1 if t(i) = ?en?
?
p(j) = V?l = ?coordination?0 otherwisewhere t(i) is the word at token i and p(j) the part-of-speech tag at token j.Decoding in this model amounts to finding they for a given x that maximises s(x,y):y?
= arg maxys(x,y)while fulfilling the following constraints:T1 For every non-root token in x there exists ex-actly one head; the root token has no head.T2 There are no cycles.Thus far, the formulation follows McDonaldet al (2005b) and corresponds to the MaximumSpanning Tree (MST) problem.
In addition to T1and T2, we include a set of linguistically moti-vated constraints:A1 Heads are not allowed to have more than oneoutgoing edge labelled l for all l in a set oflabels U .C1 In a symmetric coordination there is exactlyone argument to the right of the conjunctionand at least one argument to the left.C2 In an asymmetric coordination there are no ar-guments to the left of the conjunction and atleast two arguments to the right.C3 There must be at least one comma betweensubsequent arguments to the left of a sym-metric coordination.C4 Arguments of a coordination must have com-patible word classes.P1 Two dependencies must not cross if one oftheir labels is in a set of labels P .A1 covers constraints such as ?there can onlybe one subject?
if U contains ?subject?
(see Sec-tion 4.4 for more details of U ).
C1 applies toconfigurations which contain conjunctions such as?en?,?of?
or ?maar?
(?and?, ?or?
and ?but?).
C2will rule-out settings where a conjunction such as?zowel?
(translates as ?both?)
having argumentsto its left.
C3 forces coordination arguments tothe left of a conjunction to have commas in be-tween.
C4 avoids parses in which incompatibleword classes are coordinated, such as nouns andverbs.
Finally, P1 allows selective projective pars-ing: we can, for instance, forbid the crossing of?Noun-Determiner?
dependencies if we add thecorresponding label type to P (see Section 4.4 formore details of P ) .
If we extend P to contain alllabels we forbid any type of crossing dependen-cies.
This corresponds to projective parsing.3.1 DecodingMcDonald et al (2005b) use the Chu-Liu-Edmonds (CLE) algorithm to solve the maxi-mum spanning tree problem.
However, global con-straints cannot be incorporated into the CLE algo-rithm (McDonald et al, 2005b).
We alleviate thisproblem by presenting an equivalent Integer Lin-ear Programming formulation which allows us toincorporate global constraints naturally.Before giving full details of our formulationwe first introduce some of the concepts of lin-ear and integer linear programming (for a morethorough introduction see Winston and Venkatara-manan (2003)).Linear Programming (LP) is a tool for solvingoptimisation problems in which the aim is to max-imise (or minimise) a given linear function withrespect to a set of linear constraints.
The func-tion to be maximised (or minimised) is referredto as the objective function.
A number of decisionvariables are under our control which exert influ-ence on the objective function.
Specifically, theyhave to be optimised in order to maximise (or min-imise) the objective function.
Finally, a set of con-straints restrict the values that the decision vari-ables can take.
Integer Linear Programming is anextension of linear programming where all deci-sion variables must take integer values.There are several explicit formulations of theMST problem as an integer linear program in theliterature (Williams, 2002).
They are based onthe concept of eliminating subtours (cycles), cuts(disconnections) or requiring intervertex flows(paths).
However, in practice these formulationscause long solve times ?
as the first two meth-131Algorithm 1 Incremental Integer Linear Program-mingC ?
Bxrepeaty?
solve(C, Ox, Vx)W ?
violated(y, Ix)C ?
C ?Wuntil V = ?return yods yield an exponential number of constraints.Although the latter scales cubically, it producesnon-fractional solutions in its relaxed version; thiscauses long runtimes for the branch and bound al-gorithm (Williams, 2002) commonly used in inte-ger linear programming.
We found out experimen-tally that dependency parsing models of this formdo not converge on a solution after multiple hoursof solving, even for small sentences.As a workaround for this problem we follow anincremental approach akin to the work of Warme(1998).
Instead of adding constraints which forbidall possible cycles in advance (this would resultin an exponential number of constraints) we firstsolve the problem without any cycle constraints.The solution is then examined for cycles, and ifcycles are found we add constraints to forbid thesecycles; the solver is then run again.
This processis repeated until no more violated constraints arefound.
The same procedure is used for other typesof constraints which are too expensive to add inadvance (e.g.
the constraints of P1).Algorithm 1 outlines our approach.
For a sen-tence x, Bx is the set of constraints that we addin advance and Ix are the constraints we add in-crementally.
Ox is the objective function and Vxis a set of variables including integer declarations.solve(C, O, V ) maximises the objective functionO with respect to the set of constraints C and vari-ables V .
violated(y, I) inspects the proposed so-lution (y) and returns all constraints in I which areviolated.The number of iterations required in this ap-proach is at most polynomial with respect to thenumber of variables (Gro?tschel et al, 1981).
Inpractice, this technique converges quickly (lessthan 20 iterations in 99% of approximately 12,000sentences), yielding average solve times of lessthan 0.5 seconds.Our approach converges quickly due to thequality of the scoring function.
Its weights havebeen trained on cycle free data, thus it is morelikely to guide the search to a cycle free solution.In the following section we present the objec-tive function Ox, variables Vx and linear con-straints Bx and Ix needed for parsing x using Al-gorithm 1.3.1.1 VariablesVx contains a set of binary variables to representlabelled edges:ei,j,l ?i ?
0..n, j ?
1..n,l ?
bestk(i, j)where n is the number of tokens and the index 0represents the root token.
bestk(i, j) is the set of klabels with highest s(i, j, l).
ei,j,l equals 1 if thereis a edge (i.e., a dependency) with the label l be-tween token i (head) and j (child), 0 otherwise.
kdepends on the type of constraints we want to add.For the plain MST problem it is sufficient to setk = 1 and only take the best scoring label for eachtoken pair.
However, if we want a constraint whichforbids duplicate subjects we need to provide ad-ditional labels to fall back on.Vx also contains a set of binary auxiliary vari-ables:di,j ?i ?
0..n, j ?
1..nwhich represent the existence of a dependency be-tween tokens i and j.
We connect these to the ei,j,lvariables by the constraint:di,j =?l?bestk(i,j)ei,j,l3.1.2 Objective FunctionGiven the above variables our objective functionOx can be represented as (using a suitable k):?i,j?l?bestk(i,j)s(i, j, l) ?
ei,j,l3.1.3 Base ConstraintsWe first introduce a set of base constraints Bxwhich we add in advance.Only One Head (T1) Every token has exactlyone head:?idi,j = 1for non-root tokens j > 0 in x.
An exception ismade for the artificial root node:?idi,0 = 0132Label Uniqueness (A1) To enforce uniquenessof children with labels in U we augment our modelwith the constraint:?jei,j,l ?
1for every token i in x and label l in U .Symmetric Coordination (C1) For each con-junction token i which forms a symmetric coor-dination we add:?j<idi,j ?
1and?j>idi,j = 1Asymmetric Coordination (C2) For each con-junction token i which forms an asymmetric coor-dination we add:?j<idi,j = 0and?j>idi,j ?
23.1.4 Incremental ConstraintsNow we present the set of constraints Ix we addincrementally.
The constraints are chosen based onthe two criteria: (1) adding them to the base con-straints (those added in advance) would result inan extremely large program, and (2) it must be ef-ficient to detect whether the constraint is violatedin y.No Cycles (T2) For every possible cycle c forthe sentence x we have a constraint which forbidsthe case where all edges in c are active simultane-ously:?
(i,j)?cdi,j ?
|c| ?
1Comma Coordination (C3) For each symmet-ric conjunction token i which forms a symmetriccoordination and each set of tokens A in x to theleft of i with no comma between each pair of suc-cessive tokens we add:?a?Adi,a ?
|A| ?
1which forbids configurations where i has the argu-ment tokens A.Compatible Coordination Arguments (C4)For each conjunction token i and each set of to-kens A in x with incompatible POS tags, we add aconstraint to forbid configurations where i has theargument tokens A.?a?Adi,a ?
|A| ?
1Selective Projective Parsing (P1) For each pairof triplets (i, j, l1) and (m, n, l2) we add the con-straint:ei,j,l1 + em,n,l2 ?
1if l1 or l2 is in P .3.2 TrainingFor training we use single-best MIRA (McDon-ald et al, 2005a).
This is an online algorithm thatlearns by parsing each sentence and comparingthe result with a gold standard.
Training is com-plete after multiple passes through the whole cor-pus.
Thus we decode using the Chu-Liu-Edmonds(CLE) algorithm due to its speed advantage overILP (see Section 5.2 for a detailed comparison ofruntimes).The fact that we decode differently during train-ing (using CLE) and testing (using ILP) may de-grade performance.
In the presence of additionalconstraints weights may be able to capture otheraspects of the data.4 Experimental Set-upOur experiments were designed to answer the fol-lowing questions:1.
How much do our additional constraints helpimprove accuracy?2.
How fast is our generic inference method incomparison with the Chu-Liu-Edmonds algo-rithm?3.
Can approximations be used to increase thespeed of our method while remaining accu-rate?Before we try to answer these questions we brieflydescribe our data, features used, settings for U andP in our parametric constraints, our working envi-ronment and our implementation.1334.1 DataWe use the Alpino treebank (van der Beek et al,2002), taken from the CoNLL shared task of mul-tilingual dependency parsing3.
The CoNLL datadiffers slightly from the original Alpino treebankas the corpus has been part-of-speech tagged usinga Memory-Based-Tagger (Daelemans et al, 1996).It consists of 13,300 sentences with an averagelength of 14.6 tokens.
The data is non-projective,more specifically 5.4% of all dependencies arecrossed by at least one other dependency.
It con-tains approximately 6000 sentences more than theAlpino corpus used by Malouf and van Noord(2004).The training set was divided into a 10% devel-opment set (dev) while the remaining 90% is usedas a training and cross-validation set (cross).
Fea-ture sets, constraints and training parameters wereselected through training on cross and optimisingagainst dev.Our final accuracy scores and runtime eval-uations were acquired using a nine-fold cross-validation on cross4.2 Environment and ImplementationAll our experiments were conducted on a IntelXeon with 3.8 Ghz and 4Gb of RAM.
We usedthe open source Mixed Integer Programming li-brary lp solve4 to solve the Integer Linear Pro-grams.
Our code ran in Java and called the JNI-wrapper around the lp solve library.4.3 Feature SetsOur feature set was determined through experi-mentation with the development set.
The featuresare based upon the data provided within the Alpinotreebank.
Along with POS tags the corpus containsseveral additional attributes such as gender, num-ber and case.Our best results on the development set wereachieved using the feature set of McDonald et al(2005a) and a set of features based on the addi-tional attributes.
These features combine the at-tributes of the head with those of the child.
Forexample, if token i has the attributes a1 and a2,and token j has the attribute a3 then we createdthe features (a1 ?
a3) and (a2 ?
a3).3For details see http://nextens.uvt.nl/?conll.4The software is available from http://www.geocities.com/lpsolve.4.4 ConstraintsAll the constraints presented in Section 3 wereused in our model.
The set U of unique labelsconstraints contained su, obj1, obj2, sup, ld, vc,predc, predm, pc, pobj1, obcomp and body.
Heresu stands for subject and obj1 for direct object (forfull details see Moortgat et al (2000)).The set of projective labels P contained cnj,for coordination dependencies; and det, for de-terminer dependencies.
One exception was addedfor the coordination constraint: dependencies cancross when coordinated arguments are verbs.One drawback of hard deterministic constraintsis the undesirable effect noisy data can cause.
Wesee this most prominently with coordination argu-ment compatibility.
Words ending in ?en?
are typ-ically wrongly tagged and cause our coordinationargument constraint to discard correct coordina-tions.
As a workaround we assigned words endingin ?en?
a wildcard POS tag which is compatiblewith all POS tags.5 ResultsIn this section we report our results.
We not onlypresent our accuracy but also provide an empiri-cal evaluation of the runtime behaviour of this ap-proach and show how parsing can be acceleratedusing a simple approximation.5.1 AccuracyAn important question to answer when usingglobal constraints is: How much of a performanceboost is gained when using global constraints?We ran the system without any linguistic con-straints as a baseline (bl) and compared it to asystem with the additional constraints (cnstr).
Toevaluate our systems we use the accuracy over la-belled attachment decisions:LAC = NlNtwhere Nl is the number of tokens with correcthead and label and Nt is the total number of to-kens.
For completeness we also report the unla-belled accuracy:UAC = NuNtwhere Nu is the number of tokens with correcthead.134LAC UAC LC UCbl 84.6% 88.9% 27.7% 42.2%cnstr 85.1% 89.4% 29.7% 43.8%Table 1: Labelled (LAC) and unlabelled (UAC) ac-curacy using nine-fold cross-validation on crossfor baseline (bl) and constraint-based (constr) sys-tem.
LC and UC are the percentages of sentenceswith 100% labelled and unlabelled accuracy, re-spectively.Table 1 shows our results using nine-fold cross-validation on the cross set.
The baseline system(no additional constraints) gives an unlabelled ac-curacy of 84.6% and labelled accuracy of 88.9%.When we add our linguistic constraints the per-formance increases by 0.5% for both labelled andunlabelled accuracy.
This increase is significant(p < 0.001) according to Dan Bikel?s parse com-parison script and using the Sign test (p < 0.001).Now we give a little insight into how our resultscompare with the rest of the community.
The re-ported state-of-the-art parser of Malouf and vanNoord (2004) achieves 84.4% labelled accuracywhich is very close numerically to our baseline.However, they use a subset of the CoNLL Alpinotreebank with a higher average number of tokensper sentences and also evaluate control relations,thus results are not directly comparable.
We havealso run our parser on the relatively small (approx-imately 400 sentences) CoNNL test data.
The bestperforming system (McDonald et al 2006; note:this system is different to our baseline) achieves79.2% labelled accuracy while our baseline sys-tem achieves 78.6% and our constrained version79.8%.
However, a significant difference is onlyobserved between our baseline and our constraint-based system.Examining the errors produced using the devset highlight two key reasons why we do not seea greater improvement using our constraint-basedsystem.
Firstly, we cannot improve on coordina-tions that include words ending with ?en?
based onthe workaround present in Section 4.4.
This prob-lem can only be solved by improving POS taggersfor Dutch or by performing POS tagging withinthe dependency parsing framework.Secondly, our system suffers from poor nextbest solutions.
That is, if the best solution violatessome constraints, then we find the next best solu-tion is typically worse than the best solution withviolated constraints.
This appears to be a conse-quence of inaccurate local score distributions (asopposed to inaccurate best local scores).
For ex-ample, suppose we attach two subjects, t1 and t2,to a verb, where t1 is the actual subject while t2is meant to be labelled as object.
If we forbid thisconfiguration (two subjects) and if the score of la-belling t1 object is higher than that for t2 beinglabelled subject, then the next best solution willlabel t1 incorrectly as object and t2 incorrectly assubject.
This is often the case, and thus results in adrop of accuracy.5.2 Runtime EvaluationWe now concentrate on the runtime of our method.While we expect a longer runtime than using theChu-Liu-Edmonds as in previous work (McDon-ald et al, 2005b), we are interested in how largethe increase is.Table 2 shows the average solve time (ST) forsentences with respect to the number of tokens ineach sentence for our system with constraints (cn-str) and the Chu-Liu-Edmonds (CLE) algorithm.All solve times do not include feature extractionas this is identical for all systems.
For cnstr wealso show the number of sentences that could notbe parsed after two minutes, the average numberof iterations and the average duration of the firstiteration.The results show that parsing using our genericapproach is still reasonably fast although signifi-cantly slower than using the Chu-Liu-Edmonds al-gorithm.
Also, only a small number of sentencestake longer than two minutes to parse.
Thus, inpractice we would not see a significant degrada-tion in performance if we were to fall back on theCLE algorithm after two minutes of solving.When we examine the average duration of thefirst iteration it appears that the majority of thesolve time is spent within this iteration.
This couldbe used to justify using the CLE algorithm to finda initial solution as starting point for the ILP solver(see Section 6).5.3 ApproximationDespite the fact that our parser can parse all sen-tences in a reasonable amount of time, it is still sig-nificantly slower than the CLE algorithm.
Whilethis is not crucial during decoding, it does makediscriminative online training difficult as trainingrequires several iterations of parsing the wholecorpus.135Tokens 1-10 11-20 21-30 31-40 41-50 >50Count 5242 4037 1835 650 191 60Avg.
ST (CLE) 0.27ms 0.98ms 3.2ms 7.5ms 14ms 23msAvg.
ST (cnstr) 5.6ms 52ms 460ms 1.5s 7.2s 33sST > 120s (cnstr) 0 0 0 0 3 3Avg.
# iter.
(cnstr) 2.08 2.87 4.48 5.82 8.40 15.17Avg.
ST 1st iter.
(cnstr) 4.2ms 37ms 180ms 540ms 1.3s 2.6sTable 2: Runtime evaluation for different sentence lengths.
Average solve time (ST) for our systemwith constraints (constr), the Chu-Liu-Edmonds algorithm (CLE), number of sentences with solve timesgreater than 120 seconds, average number of iterations and first iteration solve time.q=5 q=10 all CLELAC 84.90% 85.11% 85.14% 85.14%ST 351s 760s 3640s 20sTable 3: Labelled accuracy (LAC) and total solvetime (ST) for the cross dataset using varying q val-ues and the Chu-Liu-Edmonds algorithm (CLE)Thus we investigate if it is possible to speed upour inference using a simple approximation.
Foreach token we now only consider the q variablesin Vx with the highest scoring edges.
For exam-ple, if we set q = 2 the set of variables for a to-ken j will contain two variables, either both forthe same head i but with different labels (variablesei,j,l1 and ei,j,l2) or two distinct heads i1 and i2(variables ei1,j,l1 and ei2,j,l2) where labels l1 andl2 may be identical.Table 3 shows the effect of different q valueson solve time for the full corpus cross (roughly12,000 sentences) and overall accuracy.
We seethat solve time can be reduced by 80% while onlylosing a marginal amount of accuracy when we setq to 10.
However, we are unable to reach the 20seconds solve time of the CLE algorithm.
Despitethis, when we add the time for preprocessing andfeature extraction, the CLE system parses a cor-pus in around 15 minutes whereas our system withq = 10 takes approximately 25 minutes5.
Whenwe view the total runtime of each system we seeour system is more competitive.6 DiscussionWhile we have presented significant improve-ments using additional constraints, one may won-5Even when caching feature extraction during trainingMcDonald et al (2005a) still takes approximately 10 minutesto train.der whether the improvements are large enoughto justify further research in this direction; espe-cially since McDonald and Pereira (2006) presentan approximate algorithm which also makes moreglobal decisions.
However, we believe that our ap-proach is complementary to their model.
We canmodel higher order features by using an extendedset of variables and a modified objective function.Although this is likely to increase runtime, it maystill be fast enough for real world applications.
Inaddition, it will allow exact inference, even in thecase of non-projective parsing.
Also, we argue thatthis approach has potential for interesting exten-sions and applications.For example, during our runtime evaluations wefind that a large fraction of solve time is spent inthe first iteration of our incremental algorithm.
Af-ter the first iteration the solver uses its last state toefficiently search for solutions in the presence ofnew constraints.
Some solvers allow the specifica-tion of an initial solution as a starting point, thus itis expected that significant improvements in termsof speed can be made by using the CLE algorithmto provide an initial solution.Our approach uses a generic algorithm to solvea complex task.
Thus other applications may ben-efit from it.
For instance, Germann et al (2001)present an ILP formulation of the Machine Trans-lation (MT) decoding task in order to conduct ex-act inference.
However, their model suffers fromthe same type of exponential blow-up we observewhen we add all our cycle constraints in advance.In fact, the constraints which cause the exponentialexplosion in their graphically formulation are ofthe same nature as our cycle constraints.
We hopethat the incremental approach will allow exact MTdecoding for longer sentences.1367 ConclusionIn this paper we have presented a novel ap-proach for inference using ILP.
While previous ap-proaches which use ILP for decoding have solvedeach integer linear program in one run, we incre-mentally add constraints and solve the resultingprogram until no more constraints are violated.This allows us to efficiently use ILP for depen-dency parsing and add constraints which providea significant improvement over the current state-of-the-art parser (McDonald et al, 2005b) on theDutch Alpino corpus (see bl row in Table 1).Although slower than the baseline approach,our method can still parse large sentences (morethan 50 tokens) in a reasonable amount of time(less than a minute).
We have shown that pars-ing time can be significantly reduced using asimple approximation which only marginally de-grades performance.
Furthermore, we believe thatthe method has potential for further extensions andapplications.AcknowledgementsThanks to Ivan Meza-Ruiz, Ruken C?ak?c?, BeataKouchnir and Abhishek Arun for their contribu-tion during the CoNLL shared task and to MirellaLapata for helpful comments and suggestions.ReferencesCulotta, Aron and Jeffery Sorensen.
2004.
Dependency treekernels for relation extraction.
In 42nd Annual Meeting ofthe Association for Computational Linguistics.
Barcelona,Spain, pages 423?429.Daelemans, W., J. Zavrel, and S. Berck.
1996.
MBT: Amemory-based part of speech tagger-generator.
In Pro-ceedings of the Fourth Workshop on Very Large Corpora.pages 14?27.Ding, Yuan and Martha Palmer.
2005.
Machine transla-tion using probabilistic synchronous dependency insertiongrammars.
In The 43rd Annual Meeting of the Associationof Computational Linguistics.
Ann Arbor, MI, USA, pages541?548.Germann, Ulrich, Michael Jahr, Kevin Knight, Daniel Marcu,and Kenji Yamada.
2001.
Fast decoding and optimal de-coding for machine translation.
In Meeting of the Asso-ciation for Computational Linguistics.
Toulouse, France,pages 228?235.Gro?tschel, M., L. Lova?sz, and A. Schrijver.
1981.
The ellip-soid method and its consequences in combina- torial opti-mization.
Combinatorica I:169?
197.Malouf, Robert and Gertjan van Noord.
2004.
Wide cover-age parsing with stochastic attribute value grammars.
InProc.
of IJCNLP-04 Workshop ?Beyond Shallow Analy-ses?.
Sanya City, Hainan Island, China.McDonald, R., K. Crammer, and F. Pereira.
2005a.
Onlinelarge-margin training of dependency parsers.
In 43rd An-nual Meeting of the Association for Computational Lin-guistics.
Ann Arbor, MI, USA, pages 91?98.McDonald, R. and F. Pereira.
2006.
Online learning of ap-proximate dependency parsing algorithms.
In 11th Con-ference of the European Chapter of the Association forComputational Linguistics.
Trento, Italy, pages 81?88.McDonald, R., F. Pereira, K. Ribarov, and J. Hajic.
2005b.Non-projective dependency parsing using spanning treealgorithms.
In Proceedings of Human Language Technol-ogy Conference and Conference on Empirical Methods inNatural Language Processing.
Association for Computa-tional Linguistics, Vancouver, British Columbia, Canada,pages 523?530.McDonald, Ryan, Kevin Lerman, and Fernando Pereira.2006.
Multilingual dependency analysis with a two-stagediscriminative parser.
In Proceedings of CoNLL-2006.New York, USA.Moortgat, M., I. Schuurman, and T. van der Wouden.2000.
Cgn syntactische annotatie.
Internal report CorpusGesproken Nederlands.Nivre, J., J.
Hall, and J. Nilsson.
2004.
Memory-based depen-dency parsing.
In Proceedings of CoNLL-2004.
Boston,MA, USA, pages 49?56.Roth, D. and W. Yih.
2004.
A linear programming formu-lation for global inference in natural language tasks.
InProceedings of CoNLL-2004,.
Boston, MA, USA, pages1?8.van der Beek, L., G. Bouma, R. Malouf, G. van Noord,Leonoor van der Beek, Gosse Bouma, Robert Malouf, andGertjan van Noord.
2002.
The Alpino dependency tree-bank.
In Computational Linguistics in the Netherlands(CLIN).
Rodopi.Warme, David Michael.
1998.
Spanning Trees in Hyper-graphs with Application to Steiner Trees.
Ph.D. thesis,University of Virginia.Williams, Justin C. 2002.
A linear-size zero - one program-ming model for the minimum spanning tree problem inplanar graphs.
Networks 39:53?60.Winston, Wayne L. and Munirpallam Venkataramanan.2003.
Introduction to Mathematical Programming.Brooks/Cole.Yamada, Hiroyasu and Yuji Matsumoto.
2003.
Statistical de-pendency analysis with support vector machines.
In Pro-ceedings of IWPT .
pages 195?206.137
