Practical Experience with Grammar Sharing in Multilingual NLP ?Michael Gamon, Carmen Lozano, Jessie Pinkham, Tom ReutterMicrosoft ResearchOne Microsoft WayRedmond WA 98052USA{ mgamon,clozano,jessiep,treutter } @ microsoft.cornAbstractIn the Microsoft Natural LanguageProcessing System (MSNLP), grammarsharing between English, French, Spanish,and German has been an important meansfor speeding up the development time forthe latter grammars.Despite significant typologicaldifferences between these languages, amature English grammar was taken as thestarting point for each of the other threegrarnmars.
In each case, through acombination of adding and deleting amodest number of grammar rules, andmodifying the conditions on many others,a broad-coverage target grammar emerged.Tests indicate that this approach hasbeen successful in achieving a high degreeof coverage in a relatively short period oftime.1 Grammar SharingA broad-coverage multilingual NLP system such asthe one currently being developed at MicrosoftResearch faces the challenge of parallel grammardevelopment in multiple languages (currentlyEnglish, French, Spanish, German, Chinese,Japanese, and Korean).
This development is bynature a very complex and time-consuming task.
Inaddition, the design of the overall NLP system hasto be well suited to be readily portable to languagesother than the one the development s arted with(English in our case).
For these reasons, few groupshave succeeded at the challenge of multilingualNLP.I This work has benefited from comments and suggestions fromother members ofthe Natural Language Processing group atMicrosoft Research.
Particular thanks go to Simon Corston.
BillDolan, Ken Felder, Karen Jensen, Martine Penenaro, HisamiSuzuki, and Lucy Vanderwende.One approach to multilingual development isto rely on theoretical concepts uch as UniversalGrammar.
The goal is to create a grammar that caneasily be parameterized to handle many languages.Wu (1994) describes an effort aimed at accountingfor word order variation, but his focus is on thedemonstration f a theoretical concept.
Kameyama(1988) describes a prototype shared grammar forthe syntax of simple nominal expressions for fivelanguages, but the focus of the effort is only on thenoun phrase, which makes the approach notapplicable to a large-scale ffort.
Principle-basedparsers are also designed with universal grammar inmind (Lin 1994), but have yet to demonstrate large-scale coverage in several anguages.
Other effortshave been presented in the literature, with a focuson generation (Bateman et al 1991.)
An effort toport a grammar of English to French and Spanish isalso underway at SRI (Rayner et al 1996.
)The approach taken in the MSNLP projectfocused from the beginning on possibilities forgrammar sharing between languages to facilitategrammar development and reduce the developmenttime.
We want to stress that our use of the term"grammar sharing" is not to be confused with "codesharing."
Grammar sharing, in our use of the term,simply means that the existing grammar for onelanguage can be used totally or in part to serve asthe development basis for a second language.In this paper we Want to demonstrate hat thejumpstart hrough grammar sharing considerablyaccelerated grammar development in French,Spanish, and German.
We will present est andprogress data from all languages to support ourclaim.2 The Microsoft NLP SystemThe English grammar that we used as our startingpoint, as well as the target-language rammars thatwere spawned from it, are sketch grammars.Sketch grammars use a computational dictionary49containing part-of-speech, morphological, andsubcategofization i formation to yield an initialsyntactic analysis (the sketch).
The rules used insketch have no access to any semantic informationthat would allow the assignment of semanticstructure such as case frames or thematic roles.Further analysis proceeds through a stage ofreattachment of phrases using both semantic andsyntactic information to produce the portrait, thento a first representation f some aspects of meaning,the logical form, and to word sense-disambiguationand higher representations of meaning.
In thispaper, however, we will restrict our attention to thesketch grammars.A bottom-up parallel parsing algorithm isapplied to the sketch grammar ules, resulting inone or more analyses for each input string, anddefaulting in cases (such as PP attachment) wheresemantic information is needed at a later stage ofthe processing (portrait) to give the correct result.Context-sensitive binary rules are used becausethey have been found necessary for the successfulanalysis of natural anguages (Jensen et al 1993,pp.
33-35; Jensen 1987, pp.
65-86).
2 Figure 1 givesa template for the rule formalism for a binary rule,in this case a rule that combines a verb phrase witha prepositional phrase to its right.Each sentence parse contains syntactic andfunctional role information.
This information iscarried through the system in the form of arbitrarilycomplex attribute-value pairs.
The sketch alwaysproduces at least one constituent analysis, even forsyntactically invalid input, and displays its analysesas parse trees.
FITTED parses are obtained when aninput string cannot be parsed up to a sentence node(possibly because it is a noun phrase, a sentencefragment, or otherwise deficient).
Fr ITED parsescontain as much constituent structure as thegrammar could assign to the input string.VPwPPr:VP ( Condition 1 &Condition 2 & ....... )PP ( Condition 1 &Condition 2 & ..... )--> VP {action 1 ;action 2; .... }Figure 1.
Outline of the binary rule combining a VPwith a PP to its right (VPwPPr)Binary rules deal with the problem of free constituent order,which is significant even in a largely configurafional languagesuch as English.
A ease of frec word order in English is theposition of adverbials and prepositional phrases.Two types of trees are available (Figure 2).
Onestrictly follows the derivational history of the parse,and is therefore binary-branching.
In the binary treethe names of the rules that have produced a nodeare displayed to the fight of that node.
The second(which is used in later processing because itaccords better with our intuitive understanding ofmany structures) is n-ary branching, or "flattened,"and is computed from a small set of syntacticattributes of the analysis record.
The * indicates thehead of the phrase.DECLI SentIEGINi " "Pl Thatcomp~VP2 VPwNPrlbvp  w stovp~NP4 NOUNtoNP"NOUNI "Juan.
~OMPCLi ConjCompS  ONJPl CONJtoCONJP "~CONJi "que"P4 VPwNPl~ %  NOUNtONPOUN2 "Madrid"Vp5 VPwNPrl  P6 VERBtoVP \VERB2 "es"P 6 N PwDet QuantP2 ADJtoAJPJl "una"P7 NPwAJPr~ NOUNtoNPOUN3 "ciudad"~AJ P3 ADJt oAJ P\ADJ2 "hermosa"HAR1 ".
"Dice Juan ue Madrid es una eluded hermosa.DECLi~ VERB1* "Dice" (Subject MPi Object CCMPCLi) \ ~NPI NOUN1* "Juan"~NPZ~NOUN2* "Madrid"\~VZKB2* "es" (Subject ~2 Prednom NP3)~NP3~-'DETPi--ADJi * "una"~NOUN3'  "ciudad"~AJ~i ADJ2' "hemosa"Figure 2: A derivational tree and a "flattened" treefor the sentence "Dice Juan que Madrid es unaciudad hermosa" ("John says that Madrid is abeautiful city")The sketch grammar is written in G, aMicrosoft-internal programming language that hasbeen specially designed for NLP.
The English50grammar contains 129 rules, which vary in sizefrom two to 600 lines of code, according to thenumber of conditions that they contain.
Thecoverage of English is broad.
Processing time israpid: a typical 20-word sentence requires about aneighth of a second on a Pentium 200 MHz machine.The goal of all Natural Language Research andDevelopment a Microsoft Research is to produce abroad coverage muitilingual NLP system that is nottailored to any specific application, but has thepotential to be used by any of them.
To date, theEnglish system is the foundation of the grammarchecker in Word 97.
We expect our multilingualtechnology to be used in as wide a spectrum ofapplications as possible.3 The Development of theFrench, Spanish and GermanGrammarsIn this section we briefly explain the commonstrategy of grammatical development in theMSNLP system and we give the current status ofdevelopment for each of these three languages.For each of the three languages underconsideration, the development team consists of alexicographer/morphologist, and a grammarian.Grammar work in each language proceedsaccording to the same rationale: the grammarianprocesses entences from diverse text sources andexamines the resulting parses.
He/she thendetermines whether the resulting parse is adesirable one.
If this is the case, the sentence withthe correct parse is added to a regression file.
If theparse is incorrect, conditions on grammar rules aremodified or added to accommodate he sentence inquestion and similar constructions.
Regression testsare run frequently to ensure that new changes donot affect the performance of the system in anynegative way.
A debugging tool is available for thelinguist to immediately view differences that arisein the processing of the regression file compared toan earlier run.
Another important tool enables thegrammarian to identify conditions in grammar rulesthat have been tried during a particular parse, anddistinguish those that succeeded from those thatfailed.3.1 FrenchDevelopment of the French grammar started in1995.
French grammar work has covered mostmajor constructs including:?
clitic pronouns?
attachment of adjectival modifiers to the rightof the nominal head in NPs?
the more liberal use of infinitival complementsin French than in English?
questions and other subject inversionconstructions?
compound noun constructions?
floating quantifiers and negativesThe French dictionary currently consists of68,000 words.
Morphology is nearly complete, with98.13% word recognition on a 276,000 wordcorpus.3.2 SpanishDevelopment of the Spanish grammar began inNovember 1995.
The initial focus of grammar workin Spanish was on the following areas:?
preverbal and postverbal c itics?
sentences with no overt subjects?
varying word order of subject noun phrases?
dislocated object noun phrases?
infinitival complements introduced byprepositions?
finite complement clauses introduced byprepositions?
handling of noun phrases that function asadverbs?
homography issuesThe Spanish dictionary has 94,000 words.Morphology is almost complete with 98% wordrecognition on a 300,000 word corpus.3.3 GermanGerman grammar development s arted in October1996.
The focus of the grammar work in Germanhas been on:?
verb-final and verb-second word-order?
the relative freedom of constituent-ordercompared to English?
VP-coordination?
agreement in noun phrases (weak and stronginflection)?
separable prefixes?
homography issuesThe German dictionary has over 140,000entries.
The morphology, which includes word-breaking, is nearly complete, with 97% wordrecognition on a 400,000 word corpus.Because Spanish and German share thefundamental property of freer constituent order than51English, German grammar has benefited from someof the solutions for this challenge already workedout for Spanish.
Grammar sharing between Spanishand German focused mainly on adoption of Spanishcode from the binary rules that combine verbs andpreceding/following oun phrases.3.4 Changes from the EnglishGrammar to the TargetGrammarsIn spite of the numerous areas of divergencebetween the target grammars and English, we foundthat the fundamental organization of the grammarchanged as little as 10-19% (see specifics in Table1).
The bulk of the required modifications occurredin the conditions on the rules.
Since theseconditions are complex, it is difficult to illustratethem fully here.
To give one simpl e example, inFrench and Spanish, we found it necessary toexclude all NPs that consisted of clitic pronounsfrom rules that attach modifiers on NPs.Few rules had to be added or completelyremoved from the grammar.
For example,bootstrapping the Spanish grammar from anEnglish grammar consisting of 129 rules requiredthat only 13 of the original English rules (10.1%)be deleted, while 10 new rules (7.8%) wereintroduced.Language % Deleted % AddedSpanish 10.1 7.8German 10.7 8.6French 7.8 2.3Table 1: percentages of deleted/added rules withrespect to the English source grammar.The new rules were added to accommodateconstructions in the target language that are(virtually) non-existent in English.
Spanish, forexample, added rules to handle nominalizedprepositional phrases like el de Juan and nominaluses of infinitives: al verlo.
French needed rules tohandle present participles introduced by en: enpartant, and for sentential constructions likeHeureusement qu'il est venu!
German added rulesfor constructions such as postposed genitive NPs(das Buch Peters) and participial VPs premodifyingNPs: die dem Mann gegebenen Biicher.4 Testing and ProgressMeasurementTesting NLP systems is known to be a difficulttask, and one that is hard to standardize acrosssystems with different aims and differentgrammatical foundations (see e.g.
the discussion inBalkan et al n.d.).
One relatively simplemeasurement that we found particularly useful forthe beginning stages of grammar development isthe percentage of non-FITI'ED parses on a corpuscontaining sentences from different types of text(news, literature, technical writing etc.
).In what follows, this corpus for each languagewill be referred to as a benchmark corpus andcoverage refers to the percentage of non-FITTEDparses for the benchmark corpus.
Sentence lengthrefers to the number of words in the sentence.
Intesting, the linguist does not examine the outputparses obtained from the benchmark corpus, inorder to avoid targeting modifications of thegrammar towards the particular problems withFITTED parses in the benchmark file.
This "blind"test yields a rough measure of the real coverage ofthe grammar.
It should be noted that althoughsome non-FITTED parses may not constitute thedesired parse, many FITTED parses yield a largelyusable parse which has only failed at the sentencelevel) But more important at this point is the factthat our measurement against a benchmark allowsus to reliably track progress over time.Even though not all of the successfully parsedsentences are guaranteed to have received a desiredparse, a stable increase in the percentage of parsedsentences during language-specific grammar workhas proven to be a reliable measurement ofprogress.
This is particularly true given thatgrammar work (as described above) proceeds onthe basis of example sentences that come to a largeextent from real-life text.A factor that influences the coverageconsiderably is sentence length.
In order to assessthe relationship between sentence length and thepercentage of parsed sentences in a corpus, we usea tool that extracts information from a parsedcorpus on the ratio of successfully parsed sentencesto FITI'ED parses depending on sentence l ngth.3 Additional testing of considerable magnitude would berequired to evaluate "perfect on~ctness".
This would take usaway from development, and provide slower feedback ofprogress.525 Results5.1 FrenchThe corpus gathered for French is 500 sentenceslong, and 16.9 words average in length.
It covers anumber of  different ext types (news, letters, onlinediscussions, legal, literature, etc.)
(see Pinkham 96for details) 4.
The text is used 'as is' from the Web,with only a few spelling corrections.
Coverage onthis corpus approximately a year ago was 54%;today it is 75~o.
5Development work for French up until now hasbeen biased toward sentences under 20 words.
Onthe basis of  the data collected from the experimentbelow, we can also deduce that effort spent onsentences in the 20+ word range would produce thequickest improvement overall in the future.
Figure3 shows coverage across different sentence lengthintervals for French.
The coverage (i.e.
thepercentage of  parses that is non-FI'VI'ED) is shownfor each category on top of the columns.140120?/)0o== 1004-fO= 80?
Q 60Ec4020Figure 3: The number of non-FrrTED versus FITTED parses in relationto sentence length for French (showing percentage of coverage)l \[\] number of sentences El non-FITTED parses II FITTED parses I1-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 51-55 >56sentence length1604 This is in contrast to the Test Suites for Natural LanguageProcessing (TSNLP) test suite data (cf.
Balkan et al n.d.), wherethe grammatical sentences for French are on average 7 wordslong, and artificially simple in terms of lexical and grammaticalcomplexity.
On the TSNLP data, coverage of the French systemis 96%.5 We estimate that coverage at the very beginning of Frenchdevelopment approximately 18months ago would have been25% (on the basis of tests done with other text).535.2 SpanishThe Spanish benchmark file contains 503 sentencesfrom textbooks, magazines, news articles, achildren's book and literary writing (novel).
Tocontrol for regional variation, both Latin Americanand Castilian Spanish are represented (the sourcesare from Spain, Chile, Argentina, and Mexico).
Theaverage sentence length is 19.1 words.
Currentcoverage on the benchmark file is 75.15%.Because Spanish started grammar developmentwhile there was only a small prototype dictionaryof about 2000 words, no coverage data were takenat the earlier stages of grammar work.Figure 4 shows the current status of the Spanishgrammar with respect o coverage across differentsentence l ngth categories in intervals of 5 words in?
the benchmark corpus.Figure 4: The number of non-FITTED versus FITTED parses in relationto sentence length for Spanish (showing percentage of coverage)100I \ [ \ ]  number of sentences \ [ \ ]  non-Fl'l'l'ED parses ?
FITTED parses / L Jc/IO o 80C0E 40C120201-5 6-10 11-15 16-20 21-255.3 GermanThe German benchmark corpus currently consistsof 424 sentences with an average length of 15.3words per sentence.
The sentences are extractedfrom news articles, novels, children's books, travelguides, technical writing and interviews.Figure 5 below illustrates the progress ofcoverage over time from the first steps in grammarwork in October 1996 until February 1997.
At that26-30 31-35 36-40 41-45 46-50 51-55 >56sentence lengthpoint, the coverage had reached over 56.13%.
Notethat the increase in coverage over time resemblesthe facts reported in section 5.1 for French.
InNovember 1996, the size of the benchmark corpuswas increased from 229 to 424 sentences.
Thisaddition of new sentences from new sources hadvery little impact on the statistics.Figure 6 shows statistics on the make-up of thecorpus and coverage across different sentence-length categories in intervals of 5 words.54Figure 5: Coverage Progress in German~'number  of sentences in corpus ~percentage of non-Fl'rrED parses I450400?oE- 3500o_~ 300Q250200w150J~E 100C500/ 100% 90% c 8O% ~, C o 70% =UJ 60%50%O40% =30%20% ==10% ?0%6-Oct November December January February140Figure 6: The number of non-FITTED parses versus FITTED parses inrelation to sentence length for German (showing percentage ofcoverage)I Elnumber of \[\] non-FITTED ?
FITTED I\[sentences parses parses J120?nGo ?QWJ~Ec1008060402001-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 51-55sentence length>56556 ConclusionThe results presented here further corroborate theconclusion drawn in Pinkham 1996 that thearchitecture of the MSNLP system lends itselfparticularly well to multilingual developmentand grammar sharing for related languages.
Ofspecial importance are the binary rule formalism(Jensen et al 1993) and the linguisticdevelopment tools provided by the system.While we recognize that grammardevelopment proceeds rapidly in the early stagesand slows down with increasing coverage, wehave shown that the time frame for full-scalegrammars can be much shorter than the 4 yearsreported in Cole et al (1997), if the system isdesigned in the appropriate fashion.By keeping track of progress in a quickinformal fashion, we also gather information onthe time-frames required for all future sharedgrammar development?ReferencesLorna Balkan, Frederik Fouvry, Sylvie Regnier-Prost.
n.d.. Test Suites for Natural LanguageProcessing, User Manual, Volume 1.John A. Bateman, Christian M.I.M.
Matthiessen,Keizo Nanri, and Licheng Zeng.
1991.
There-use of linguistic resources across languagein multilingual generation components.
InProceedings of the 1991 International JointConference on Artificial Intelligence,Sydney, Australia, volume 2, pages 966 -971.
Morgan Kaufmann Publishers.Ronald A. Cole, Joseph Mariani, HansUszkoreit, Annie Zaenen and Victor Zue,eds.
1997.
Survey of the State of the Art ofHuman Language Technology.http://www.ese.ogi.edu/CSLU/HLTsurvey.Karen Jensen.
1987.
Binary rules and non-binarytrees: Breaking down the concept of phrasestructure.
In Mathematics of language, ed.Alexis Manaster-Ramer, pages 65-86.Amsterdam: John Benjarnins PublishingCompany.6 The grammars for Korean, Japanese and Chinese arestarting from the ground up, using the same binary rulestrategy, but without he benefit of bootstrapping from anexisting rammar.
This is inevitable since they aretypologically too different from the European languagesprofiled here.Karen Jensen, George Heidorn, SteveRichardson, eds.
1993.
Natural LanguageProcessing: The PLNLP Approach, KluwerAcademic Publishers.Megumi Kameyama.
1988.
Atomization inGrammar Sharing.
in Proceedings of the 26 thAnnual Meeting of the Association forComputational Linguistics, Buffalo, NewYork, June 7-10, 1988.Dekang Lin.
1994.
PRINCIPAR - An Efficient,Broad-coverage, Principle-based Parser.
InProceedings of the 15 'h InternationalConference on Computational Linguistics,Kyoto, Japan, August 5-9, 1994.Jessie Pinkham.
1996.
Grammar Sharingbetween English and French.
In Proceedingsof the NLP-IA conference, Moncton, Canada,June 4-6, 1996.Manny Rayner, Pierrette Bouillon.
1996.Adapting the Core Language Engine toFrench and Spanish.
In Proceedings of theNLP-IA conference, Moncton, Canada, June4-6, 1996.Andi Wu.
1994.
The Spell-Out Parameters: aminimalist approach to syntax.
Doctoraldissertation, University of California, LosAngeles.56
