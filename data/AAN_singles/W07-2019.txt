Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 105?108,Prague, June 2007. c?2007 Association for Computational LinguisticsAUG: A combined classification and clustering approach for web peopledisambiguationEls Lefever and Ve?ronique HosteLT3 Language and Translation TechnologyGhent University AssociationGroot-Brittannie?laan 45, 9000 Gentels.lefever@hogent.beveronique.hoste@hogent.beTimur FayruzovComputational Web IntelligenceGhent University AssociationKrijgslaan 281, 9000 GentTimur.Fayruzov@UGent.beAbstractThis paper presents a combined super-vised and unsupervised approach for multi-document person name disambiguation.Based on feature vectors reflecting pairwisecomparisons between web pages, a classifi-cation algorithm provides linking informa-tion about document pairs, which leads toinitial clusters.
In addition, two differentclustering algorithms are fed with matricesof weighted keywords.
In a final step the?seed?
clusters are combined with the resultsof the clustering algorithms.
Results on thevalidation data show that a combined classi-fication and clustering approach doesn?t al-ways compare favorably to those obtainedby the different algorithms separately.1 IntroductionFinding information about people on the WorldWide Web is one of the most popular activities ofInternet users.
Given the high ambiguity of personnames and the increasing amount of information onthe web, it becomes very important to organize thislarge amount of information into meaningful clus-ters referring each to one single individual.The problem of resolving name ambiguity onthe Internet has been approached from different an-gles.
Mann and Yarowsky (2003) have proposed aWeb based clustering technique relying on a fea-ture space combining biographic facts and associ-ated names, whereas Bagga and Baldwin (1998)have looked for coreference chains within each doc-ument, take the context of these chains for creatingsummaries about each entity and convert these sum-maries into a bag of words.
Documents get clusteredusing the standard vector space model.
Other re-searchers have taken this search for distinctive key-words one step further and tried to come up with?concepts?
describing the documents.
Fleischmanand Hovy (2004) introduce the ?maximum entropymodel?
: a binary classifier determines whether twoconcept-instance pairs refer to the same individ-ual.
Pedersen (2006) presented an unsupervised ap-proach using bigrams in the contexts to be clustered,thus aiming at a concept level semantic space insteadof a word level feature space.For the semeval contest, we approached the taskfrom a double supervised and unsupervised perspec-tive.
For the supervised classification, the task wasredefined in the form of feature vectors containingdisambiguating information on pairs of documents.In addition to this, different clustering approacheswere applied on matrices of keywords.
These resultswere then merged by taking the classification outputas basic ?seed?
clusters, which were then enhancedby the results from the clustering experiments.In the remainder of this paper, Section 2 intro-duces the data sets and describes the construction ofthe feature vectors and the keyword matrices.
Theclassification and clustering experiments, and thefinal combination of the different outputs are dis-cussed in Section 3.
Section 4 gives an overview ofthe results on the test data and Section 5 summarizesthe main findings of the paper.1052 Data sets and feature constructionThe data we have used for training our system weremade available in the framework of the SemEval(task 13: Web People Search) competition (Artileset al, 2007).
As preliminary training corpus (re-ferred to as ?trial data?
in our article), we used theWePS corpus (Web People Search corpus), availableat http://nlp.uned.es/weps.
For the real training set,this trial set was expanded in order to cover differ-ent degrees of ambiguity (very common names, un-common names and celebrity names which tend tomonopolize search results).
The training corpus iscomposed of 40 sets of 100 web pages, each setcorresponding to the first 100 results for a personname query.
The documents were manually clus-tered.
Documents that couldn?t be clustered prop-erly have been put in a ?discarded?
section.
Testdata have been constructed in a similar way (30 setsof 100 web pages).The content of the web pages has been prepro-cessed by means of a memory-based shallow parser(MBSP) (Daelemans and van den Bosch, 2005).From the MBSP, we used the regular expressionbased tokenizer, the part-of-speech tagger and textchunker using the memory-based tagger MBT.
Onthe basis of the preprocessed data we construct a richfeature space that combines biographic facts and dis-tinctive characteristics for a given person, a list ofweighted keywords and meta data information aboutthe web page.2.1 Feature vector constructionThe following biographic facts and related namedentities were extracted from the preprocessed data.Information on date and place of birth, and on dateand place of death were extracted by means of a rule-based component.
Furthermore, three named en-tity features were extracted on the basis of the shal-low syntactic information provided by the memory-based shallow parser and additional gazetteer infor-mation.
Furthermore, a ?name?
feature was aimedat the extraction of further interesting name infor-mation (E.g other surnames, family names) on theperson in focus, leading to the extraction of for ex-ample ?Ann Hill Carter Lee?
and ?Jo Ann Hill?
forthe document collection on ?Ann Hill?.
The ?loca-tion?
feature informs on the overlap between all lo-cations named in the different documents.
In a simi-lar way, the ?NE?
feature returns the inter-documentoverlap between all other named entities.Starting with the assumption that overlappingURL and email addresses usually point to the sameindividual, we have also extracted URL, email anddomain addresses from the web pages.
Therefore wehave combined pattern matching rules and markupinformation (HTML <href> tag).
The link of thedocument itself has been added to the set of URLlinks.
Some filtering on the list has been performedconcerning length (to exclude garbage) and content(to exclude non-distinctive URL addresses such asindex.html).
Pair-wise comparison of documentswith respect to overlapping URL, email and domainnames resulted in 3 binary features.Another binary feature we have extracted is thelocation, based on our simple supposition that iftwo documents are hosted in the same city, theymost probably refer to the same person (but notvice versa).
For converting IP-addresses to city lo-cations, we have used MaxMind GeoIP(tm) opensource database2, which was sufficient for our needs.2.2 A bag of weighted keywordsThe input source for extracting our distinctive key-words is double: both the entire (preprocessed) con-tent of the web pages as well as snippets and titles ofdocuments are used.
Keywords extracted from snip-pets and titles get a predefined -rather high- score,as we consider them quite important.
For determin-ing the keyword relevance of the words extractedfrom the content of the web pages, we have appliedTerm Frequency Inverse Document Frequency (TF-IDF) (Berger et al, 2000).Once all scores are calculated, all weighted key-words get stored in a matrix, which serve as inputfor the clustering experiments.
The calculated key-word weight is also used, in case of overlapping key-words, as a feature in our pairwise comparison vec-tor.
In case two keywords occurring in two differentdocuments are identical or recognized as synonyms(information we obtain by using WordNet3), we sumup the different weights of these keywords and storethis value in the feature vector.2http://www.maxmind.com/app/geolitecity3http://wordnet.princeton.edu/1063 Classification and Clustering algorithms3.1 ClassificationFor the classification experiments, we used the ea-ger RIPPER rule learner (Cohen, 1995) which in-duces a set of easily understandable if-then classi-fication rules for the minority class and a defaultrule for the remaining class.
The ruler learner wastrained and validated on the trial and training data.Given the completely different class distribution ofthe trial and training data, viz.
10.6% positive in-stances in the trial data versus 66.7% in the train-ing data, we decided to omit the trial data and opti-mize the learner on the basis of the more balancedtraining data set.
There was an optimization of theclass ordering parameter, the two-valued negativetests parameter, the hypothesis simplification param-eter, the example coverage parameter, the parameterexpressing the number of optimization passes andthe loss ratio parameter.
The predicted positive pair-wise classifications were then combined using a forcoreference resolution developed counting mecha-nism (Hoste, 2005).3.2 Clustering AlgorithmsWe experimented with several clustering algorithmsand settings on the trial and training data to de-cide on our list of parameter settings.
We validatedthe following three clustering algorithms.
First,we compared output from k-means and hierarchicalclustering algorithms.
Next to that, we have run ex-periments for agglomerative clustering4 .
with differ-ent parameter combinations (2 similarity measuresand 5 clustering functions).
All clustering experi-ments take the weighted keywords matrix as input.Based on the validation experiments, hierarchicaland agglomerative clustering were further evaluatedto find out the optimal parameter settings.
For hier-archical clustering, this led to the choice of the co-sine distance metric, single-link hierarchical cluster-ing and a 50% cluster size.
For agglomerative clus-tering, clustering accuracy was very dependent onthe structure of the document set.
This has made ususe different strategies for clustering sets containing?famous?
and ?non famous?
people.
As a distinctioncriterion we have chosen the presence/non-presence4http://glaros.dtc.umn.edu/gkhome/views/clutoof the person in Wikipedia.
We started with the as-sumption that sets containing famous people (foundin Wikipedia) most probably contain a small amountof bigger clusters than sets describing ?ordinary?persons.
According to this assumption, two differ-ent parameter sets were used for clustering.
ForWikipedia people we have used the correlation co-efficient and g1 clustering type, for ordinary peoplewe have used the cosine similarity measure and sin-gle link clustering.
For both categories the numberof target output clusters equals (number of RIPPERoutput clusters + the number of documents*0.2).Although the clustering results with the best set-tings for hierarchical and agglomerative clusteringwere very close with regard to F-score (combiningpurity and inverse purity, see (Artiles et al, 2007)for a more detailed description), manual inspectionof the content of the clusters has revealed big dif-ferences between the two approaches.
Clusters thatare output by our hierarchical algorithm look morehomogeneous (higher purity), whereas inverse pu-rity seems better for the agglomerative clustering.Therefor we have decided to take the best of twoworlds and combined resulting clusters of both al-gorithms.3.3 Merging of clustering resultsClassification and clustering with optimal settingsresulted in three sets of clusters, one based on pair-wise similarity vectors and two based on keywordmatrices.
Since the former set tends to have betterprecision, which seems logical because more evi-dent features are used for classification, we used thisset as ?seed?
clusters.
The two remaining sets wereused to improve recall.Merging was done in the following way: first wecompare the initial set with the result of the agglom-erative clustering by trying to find the biggest inter-section.
We remove the intersection from the small-est cluster and add both clusters to the final set.
Theresulting set of clusters is further improved by us-ing the result of the hierarchical clustering.
Here weapply another combining strategy: if two documentsform one cluster in the initial set, but are in separateclusters in the other set, we merge these two clusters.Table 1 lists all results of the separate clustering al-gorithms as well as the final clustering results forthe Wikipedia person names.
Second half of the ta-107Person Name Ripper agglom.
hierarch.
mergedWikipediaAlexander Macomb .69/.63 .64/.56 .57/.47 .79/.80David Lodge .69/.65 .69/.64 .43/.33 .79/.85George Clinton .65/.62 .64/.59 .54/.45 .75/.80John Kennedy .67/.62 .70/.66 .49/.39 .76/.80Michael Howard .56/.54 .63/.62 .65/.58 .62/.75Paul Collins .54/.57 .64/.62 .63/.56 .55/.62Tony Abbott .63/.59 .67/.63 .62/.54 .77/.83Average Scores .73/.76 .67/.72 .62/.60 .66/.75all Training DataTable 1: Results on Training Datable shows the average results for the separate andcombined algorithms.
The first score always refersto F?
= 0.5, the second score refers to F?
= 0.2.The average scores, that were calculated on thecomplete training set, show that RIPPER outperformsthe combined clusters.4 Results on the test data4.1 Final settingsFor our classification algorithm, we have finally notkept the best settings for the training data, as thisled to an alarming over-assignment of the positiveclass, thus linking nearly every document to eachother.
Therefore, we were forced to define a morestrict rule set.
For the clustering algorithms, we haveused the optimal parameter settings as described inSection 3.4.2 Test resultsTable 2 lists the results for the separate and mergedclustering for SET 1 in the test data (participantsin the ACL conference) and the average for all al-gorithms.
The average score, that has been calcu-lated on the complete test set, shows that the com-bined clusters outperform the separate algorithmsfor F?
= 0.2, but the hierarchical algorithm out-performs the others for F?
= 0.5.
Table 3 lists theaverage results for purity, inverse purity and the F-measures.5 ConclusionsWe proposed and validated a combined classifica-tion and clustering approach for resolving web peo-ple ambiguity.
In future work we plan to experimentwith clustering algorithms that don?t require a prede-fined number of clusters, as our tests revealed a bigimpact of the cluster size on our results.
We will alsoPerson Name Ripper agglom.
hierarch.
mergedACLChris Brockett .49/.39 .74/.69 .70/.61 .79/.80Dekang Lin .69/.58 .76/.67 .59/.47 .93/.89Frank Keller .48/.41 .68/.75 .64/.62 .56/.71James Curran .53/.50 .64/.77 .75/.78 .54/.72Jerry Hobbs .50/.39 .02/.01 .58/.47 .74/.70Leon Barrett .47/.40 .67/.74 .65/.66 .57/.73Mark Johnson .45/.42 .55/.70 .65/.77 .44/.65Robert Moore .39/.37 .60/.71 .66/.68 .46/.65Sharon Goldwater .60/.49 .72/.61 .40/.29 .91/.86Stephen Clark .41/.42 .53/.67 .68/.75 .46/.67Average Scores .49/.45 .58/.63 .69/.69 .61/.74all Test DataTable 2: Results on Test DataTest set Purity Inverse F = F =Purity ?
= 0.5 ?
= 0.2Set1 .57 .85 .64 .73Set2 .45 .91 .58 .73Set3 .48 .89 .60 .73Global .50 .88 .60 .73Table 3: Purity/Inverse Purity Results on Test Dataexperiment with meta-learning, other merging tech-niques and evaluation metrics.
Furthermore, we willinvestigate the impact of intra-document and inter-document coreference resolution on web people dis-ambiguation.6 ReferencesJ.
Artiles and J. Gonzalo and S. Sekine.
2007.
The SemEval-2007 WePS Evaluation: Establishing a benchmark for the WebPeople Search Task, Proceedings of Semeval 2007, Associationfor Computational Linguistics.A.
Bagga and B. Baldwin.
1998.
Entity-based cross-documentco-referencing using the vector space model, Proceedings ofthe 17th international conference on Computational linguistics,75?85.A.
Berger and R. Caruana and D. Cohn and D. Freitag and V.Mittal.
2000.
Bridging the Lexical Chasm: Statistical Ap-proaches to Answer Finding, Proc.
Int.
Conf.
Reasearch andDevelopment in Information Retrieval, 192?199.William W. Cohen.
1995.
Fast Effective Rule Induction,Proceedings of the 12th International Conference on MachineLearning, 115?123.
Tahoe City, CA.Walter Daelemans and Antal van den Bosch.
2005.
Memory-Based Language Processing.
Cambridge University Press.Veronique Hoste.
2005.
Optimization Issues in Machine Learn-ing of Coreference Resolution.
Phd dissertation, Antwerp Uni-versity.M.B.
Fleischman and E. Hovy.
2004.
Multi-document per-son name resolution, Proceedings of 42nd Annual Meeting ofthe Association for Computational Linguistics (ACL), ReferenceResolution Workshop.G.
Mann and D. Yarowsky.
2003.
Unsupervised personal namedisambiguation, Proceedings of CoNLL-2003, 33?40.
Edmon-ton, Canada.T.
Pedersen and A. Purandare and A. Kulkarni.
2006.
NameDiscrimination by Clustering Similar Contexts, Proceedings ofthe World Wide Web Conference (WWW).108
