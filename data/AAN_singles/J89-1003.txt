DESIGN OF LMT:  A PROLOG-BASED MACHINE TRANSLATION SYSTEMMichael C. McCordIBM Thomas J. Watson Research CenterP.O.
Box 704Yorktown Heights, NY 10598LMT (logic-based machine translation) is an experimental English-to-German MT system, beingdeveloped in the framework of logic programming.
The English analysis uses a logic grammarformalism, Modular Logic Grammar, which allows logic grammars to be more compact, and which hasa modular treatment of syntax, lexicon, and semantics.
The English grammar is written independentlyof the task of translation.
LMT uses a syntax-to-syntax transfer method for translation, although theEnglish syntactic analysis trees contain some results of semantic hoices and show deep grammaticalrelations.
Semantic type checking with Prolog inference is done during analysis and transfer.
Thetransfer algorithm uses logical variables and unification to good advantage; transfer works in a simpleleft-to-right, top-down way.
After transfer, the German syntactic generation component produces asurface structure tree by application of a system of tree transformations.
These transformations use anaugmentation of Prolog pattern matching.
LMT has a single lexicon, containing both source andtransfer information, as well as some idiosyncratic target morphological information.
There is acompact external format for this lexicon, with a lexical preprocessing system that applies defaults andcompiles it into an internal format convenient for the syntactic omponents.
During lexical preprocess-ing, English morphological analysis can be coupled with rules that synthesize new transfer entries.
11 INTRODUCTIONThe purpose of this paper is to describe an experimentalEnglish-to-German machine translation system, LMT(logic-based machine translation), 2 which has evolvedout of previous work by the author on logic grammars.The translation system is organized in a modularway.
The grammar for analysis of the source language(English) is written completely independently of thetask of translation.
In fact, this grammar produceslogical forms that can be used for other applicationssuch as database query systems and knowledge-basedsystems, and has been used in the systems described inMcCord (1982, 1987), Teeple (1985), Bernth (1988), andDahlgren (1988).
The components of LMT dealing spe-cifically with translation do not index into the grammarrules, as, for example, in the LRC system (Bennett andSlocum 1985).An interesting sort of modularity exists in the Englishgrammar itself, whereby syntax, lexicon, and semanticinterpretation closely interact, yet manage to be clearlyseparated.
The lexicon exerts control over syntacticanalysis through the use of slot frames in lexical entriesand slot filling methods in syntax, as well as throughtype checking with semantic types taken from lexicalentries.
Yet the syntax rules look completely syntactic;e.g., no specific semantic types or word senses arereferred to.
The syntactic analysis trees look like sur-face structure trees, with annotations showing gram-matical relations (including remote relations due toextraposition).
The terminal nodes of these trees arelogical terminals (explained below), which contain wordsense predications and can be used in building logicalforms as semantic representations of sentences.
Theselogical forms are built by a separate semantic interpre-tation component which deals with problems of scopingof quantifiers and other modifiers.Given that the English grammar can produce bothsyntactic structures and logical forms, an issue in de-signing LMT was what structures to use as input totransfer.
The initial idea was to use the logical forms.The main argument for this was that 1. the logical formanalyses express the complete meaning of the sourcetext, and 2. there is no doubt that for perfect ransla-tions, one must in general have a complete semanticanalysis of the source text (and employ world knowl-edge to get it).
The logical form analyses are expres-Copyright 1989 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material is granted providedthat the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, orto republish, requires a fee and/or specific permission.0362-613X/89/010033-52503.00Computational Linguistics, Volume 15, Number 1, March 1989 33Michael C. McCord \]Design of LMT: A Prolog-Based Machine Translation Systemsions in a logical form language (LFL)  (McCord 1985a,1987).
Although the formalism for LFL is intended to belanguage universal, there is actually a ,different versionof LFL for every natural anguage, because most of thepredicates are word senses in the natural anguage beinganalyzed.
The original scheme, then, :for LMT was toanalyze English text into English LFL forms, thentransfer these to German LFL form.,;, then generateGerman text.This scheme is neat, and may be investigated againlater; but for the sake of practicality, the compromisehas been to use the syntactic analyses produced by thegrammar as the point of transfer.
Useful MT systemsmust generally work with rather large domains, and thetrouble with the use of logical forms is that too manydecisions must be made and too much world knowledgeis needed to produce correct analyses for a large do-main.
For example, LFL expressions for degree adjec-tives like "good" are focalizers (McCord 1985a, 1987),where the base argument shows the base of comparisonfor the adjective.
In general, it may be difficult todetermine such arguments.
In the syntactic structure,arguments of focalizers are not yet determined; but forthe purposes of translation, such scoping problems canoften (though not always) be ignored.
They can often besidestepped because the same ambiguity exists in thetarget language.
For example, "He is good" can easilytranslate into Er ist gut without deciding "good withrespect o what?".
Another point is that in the case oflanguages as close as English and German, it is simplymore direct to transfer syntactic structure to syntacticstructure.
For more discussion of the practicality of asyntactic transfer method, see Bennett and Slocum(1985).It should be emphasized that the syntactic analysistrees produced by the grammar do contain some of theingredients of semantic interpretation.
As mentionedabove, terminal nodes contain word sense predications.Although the arguments of focalizer predications arenot yet filled in, the arguments of verb and noun senses(corresponding tocomplements), are filled in (inasmuchas they can be determined by the syntax of the sen-tence, plus a few heuristics).
Semantic type checkinginvolves Prolog inference and is used for constrainingword sense selection, complementation, and adjunctattachment.
Also certain preference heuristics, de-scribed in Section 2 below, are used for modifierattachment.Translation of a sentence by LMT proceeds in fivesteps.1.
Lexical preprocessing;2.
English syntactic analysis;3.
English-to-German transfer;4.
German syntactic generation;5.
German morphological generation.During Step 1, lexical preprocessing, the words of aninput sentence are looked up in the LMT lexicon, incombination with English morphological nalysis (bothinflectional and derivational).
Morphological deriva-tions are used to synthesize new transfer entries.
Forexample, the derivation of "reuseable" from "use" andthe existence of a transfer entry use--> verwenden allowautomatic synthesis of a new transfer entry reuseablewieder verwendbar.Step 1, and Step 5 as well, are the topics of acompanion paper (McCord and Wolff 1988).
Thepresent paper deals mainly with the syntactic ompo-nents of LMT; but enough description of the lexicon isgiven to make the discussion self-contained.Step 2, F, nglish syntactic analysis, is dealt with inSection 2.
Several aspects of the English grammar aredescribed: the Modular Logic Grammar formalism, useof metarules in the grammar, special syntactic tech-niques, and the methods used for semantic type check-ing.Section 3 provides an overview of the LMT lexiconand its relation to the English grammar.Step 3 is dealt with in Section 4, "The TransferComponent of LMT."
The transfer component con-verts an English syntax tree into the German transfertree.
This is a syntax tree that (normally) has the sameshape as the English tree, but has different node labels.Its nonterminal nodes are labeled by feature structuresappropriate for German syntax and morphology; and itsterminal nodes are (normally) citation forms of Germanwords, together with feature structures that determinethe inflections of the words during Step 5.The transfer algorithm works in a simple way, in onetop-down, left-to-right pass, yet manages to get a lotdone, making German word choices and essentiallyproducing all required German feature structures (likecase markers).
This is facilitated by use of logicalvariables and unification.
Lexical transfer informationresides in Prolog clauses (in internal representation),used by the transfer algorithm for simultaneous deter-mination of German target words and associated inflec-tional markings for complements of these target words.Step 4, German syntactic generation, is described inSection 5.
This phase takes the German transfer treeand produces a German surface structure tree by apply-ing a battery of tree transformations in a cycle, as intransformational grammar.
The pattern matching usedby these transformations i  mainly Prolog unification,but there is an augmentation for matching sublists.Transformations are expressed in a special notationinvolving this augmented pattern matching and arecompiled by the system into normal Prolog clauses.
Thenumber of transformations u ed in the system is rathersmall (currently 44), because the general idea of LMT isto get as much right as possible during the transfer step.As mentioned above, Step 5, German morphologicalgeneration, is described in detail in McCord and Wolff(1988), but some comments are given here in Section 6.Section 7 briefly describes the status of the system asof November 1988.
It is worth noting here that LMT,34 ComputaLtional Linguistics, Volume 15, Number 1, March 1989Michael C. McCord Design of LMT: A Prolog-Based Machine Translation Systemalthough fairly large by now, is written entirely inProlog (except for a few lines of trivial system code).
Noneed has been seen for other methods, even for quickaccess to large dictionary disk files.
The version ofProlog used is VM/Prolog (written by Marc Gillet),running on an IBM mainframe.
The features of Prolog(especially logical variables and unification) have beenvery useful in making LMT easy to write.
32 THE ENGLISH ANALYSIS GRAMMAR, MoDLThe term grammar is being used in this paper in thebroad sense of a system that associates semantic represen-tations with sentences (and may also associate syntacticanalyses).
A modular logic grammar (MLG) (McCord1985a, 1987) has a syntactic component (with ruleswritten in a certain formalism), and a separate semanticinterpretation component (using a certain methodology).The English MLG used in LMT is called ModL, and hasevolved since 1979.
Many of the ingredients have beendescribed previously (McCord 1981, 1982, 1985a, 1987),so the background description given here is abbreviated(but fairly self-contained), and the emphasis is on newingredients.2.1 THE MLG FORMALISMMetamorphosis grammars (MGs) (Colmerauer 1975,1978) are like type-0 phrase structure grammars, butwith logic terms for grammar symbols, and with unifi-cation of grammar symbols used in rewriting instead ofequality checks.
In an MG in normal form, the left-handside of each rule is required to start with a nonterminal,followed possibly by terminals.
Definite clause gram-mars (DCGs) (Pereira nd Warren 1980), are the specialcase of normal form MGs corresponding to context-freephrase structure grammars; i.e., the left-hand side ofeach rule consists of a nonterminal only.
In MGs (andDCGs), any of the grammar symbols can have argu-ments, and these can be used to constrain the grammaras well as to build analysis tructures.
MGs (in normalform) can be compiled irectly into Horn clauses (Col-merauer 1978) (hence run in Prolog for parsing andgeneration), by adding extra arguments ononterminalsrepresenting difference lists of word strings being ana-lyzed.
In MGs, the right-hand side of a rule can alsocontain ordinary Horn clause goals, which translate intothemselves in the compilation to Horn clauses.The MLG syntactic formalism is an extension of theDCG formalism.
The three most important extra ingre-dients (to be explained in this subsection) are thefollowing:1.
A declaration of strong nonterminals preceding thelisting of syntax rules;2.
Logical terminals;3.
Shifted nonterminals.The second and third ingredients are allowed on theright-hand sides of syntax rules.
There are several otherminor types of extra ingredients in the MLG formalism,which will be mentioned at the end of the subsection.The syntax rule compiler of an MLG compiles thesyntactic omponent directly into Prolog (as is commonwith MGs, so that parsing is top-down), but takes careof analysis structure building, so that the grammarwriter does not have to bother with the bookkeeping ofadding nonterminal rguments o accomplish this (as inMGs).
Also, since systematic structure building is in thehands of the rule compiler, it is easier to write meta-grammatical rules.The MLG rule compiler has two options for structurebuilding.
The compiled grammar can operate in a one-pass mode, in which LFL representations are builtdirectly during parsing, through interleaved calls to thesemantic interpreter, and no syntactic structures arebuilt.
Or it can operate in a two-pass mode, in whichsyntactic structures are built during parsing, and theseare given to the semantic interpreter in a second pass.The two-pass mode is used for LMT, since we wantsyntactic analysis trees.
In the following discussion, theone-pass mode will be ignored--for details, seeMcCord (1985a, 1987).Now let us look at the three distinctive ingredients ofMLGs mentioned above.
Strong nonterminals representmajor syntactic ategories, and they are declared by aclausestrongnonterminals(NT 1.
2 .
.
.
.
.
NTn.nil).
(The dot operator is used for lists.)
Each NTi is of theform A/k where A is an atom, the principal functor ofthe strong nonterminal being declared, and k is anonnegative integer, less than or equal to the number ofarguments of the nonterminal.
The first k arguments ofthe nonterminal re called its feature arguments; theirsignificance is explained below.
4 A nonterminal notdeclared strong is called weak.
A syntax rule whoseleft-hand side is a strong (weak) nonterminal is called astrong (weak) rule.The most significant way in which the strong/weakdistinction is used by the MLG rule compiler is inautomatic analysis structure building.
Nodes for theanalysis tree get built corresponding to the applicationof strong rules, but not weak rules.
Specifically, when astrong nonterminalA(X: .... ~n)is expanded in the derivation of a sentence, a tree nodeof the formsyn(A(Xl .... ,X~k),B,Mods)is built for the analysis tree.
The first argument of thesyn term is the label on the node, consisting of thenonterminal together with its feature arguments.
Thusfeature arguments are made available in the syntacticdescription of the sentence, and may be used by othermodules--such astransfer in LMT.
(The significance offeature arguments for MLG metarules i s  indicatedComputational Linguistics, Volume 15, Number 1, March 1989 35Michael C. McCord Design of LMT: A Proiog-Based Machine Translation Systembelow.)
The second argument B of syn has to do withbracketing of the phrase analyzed by A, and will beexplained below.
The last argument Mods is the list ofdaughter nodes.The second way in which MLGs differ from DCGs isthat the right-hand sides of rules can contain logicalterminals.
These are building blocks fi~r analysis truc-tures, just as ordinary terminals are building blocks forthe word strings being analyzed.
The terminal nodes ofsyntactic analysis trees are logical terminals.
In fact, theterminal node members of Mods in the syn term aboveare just the logical terminals encountered while expand-ing the strong nonterminal A, possi~bly through theapplication of subordinate weak rules, but not throughother applications of strong rules.Logical terminals are terms of the form Op-LF.
Here,LF is a logical form (an LFL expression), usually a wordsense predication, like see(X,Y).
The term Op, calledan operator, determines how the logical terminal willcombine with other logical terminals during semanticinterpretation to build larger logical forms.
For a de-scription of the way MLG semantic interpretationworks, see McCord (1985a, 1987).As indicated above, the MLG semantic interpreter isnot used in LMT.
Because of this, the operator compo-nents of logical terminals are not important here; how-ever, the logical form components are used.
The argu-ments of word sense predications show deep relationsof words to other parts of the sentence, includingremote dependencies, and play a central role in thetransfer algorithm, as we will see in Section 3.
It shouldalso be noted that the grammar Mod.L has been shapedstrongly by the need to produce logical form analyses.The last distinctive ingredient of MLGs is the shiftoperator, denoted by %.
Its purpose is to allow theproduction of left-embedded structures while usingright-recursive rules (necessary because of the top-down parsing).
Before describing the shift operatorgenerally, let us look at an example.Left-recursive constructions occur in English nounphrases like "my oldest brother's wife's father's car".A noun phrase grammar f agment with shift that handlesthis is as follows:np ~ determiner: np 1.npl ~ premodifiers: noun: np2.np2 ~ apostrophe_ s: np % npl.rip2 ~ postmodifiers.Here, np is declared a strong nonterminal nd all othersare weak.
(The colon operator on the right-hand side ofMLG rules denotes the usual sequencing.)
The occur-rence of an apostrophe-s triggers ashift back to the statenp l ,  where we are looking at the premodifiers (say,adjectives) of a noun phrase.
In making the transition,though, the provisional syntactic structure being builtfor the noun phrase is changed: A|I daughters con-structed so far are made the daughters of a new nodewith label np (the left operand of the shift operator), and36this new node is made the initial daughter in the newprovisional syntactic structure.In general, the right-hand side of an MLG syntax rulecan contain a shifted nonterminal, which is of the formLaboI%NT, where Label is a term (to be used as a nodelabel), and ~ is a weak nonterminal.
The idea, in ratherprocedural terms, is: 1.
Take the list of daughters builtso far for the active tree node (corresponding to themost recently activated strong rule), and make it thecomplete daughter list of a new node Mod with labelLabel; and then 2. proceed with NT, using Mod as theinitial daughter of the active tree node.It should be noted that the syntactic analysis truc-tures built automatically for MLGs differ from deriva-tion trees in three ways: a.
Weak rules do not contributenodes to analysis trees (but strong rules do); b. shiftednonterminals can contribute nodes in the special wayjust indicated; and c. terminal nodes are logical termi-nals, not word string terminals.It was mentioned above that there are several minortypes of extra ingredients in the MLG formalism.
Fiveof these will be described here briefly.1.
There is an "escape" to the DCG formalism: Agrammar symbol of the form -NT does analysis witha DCG nonterminal NT, defined by its own DCGrules.
(DCG rules are written with the symbol ---~,whereas MLG rules are written with ft.) This isuseful, for the sake of efficiency, when MLG struc-ture building is not necessary.2.
In order to look at right context, one can refer tothe next terminal T (without removing T from theword stream) by using the symbol +-T. (Ordinaryreferences to terminals are indicated by +T.)3.
Also, one can examine the complete right contextwith a DCG nonterminal NT by use of the symbol-~r .4.
As with DCGs, one can specify a Prolog goal Goalon the right-hand side of a rule.
Our notation for thisis $Goa2.
Such goals are executed when the compiledgrammar is executed.
But there is another type ofProlog goal, denoted by !Goal, which gets executedimmediately at compile time.
This is convenient,e.g., for specifying feature selection goals whoseimmediate compilation constrains feature structuresthrough unificationmwith more efficient executionduring parsing.
Writing such constraints directly maynot be as perspicuous, or as flexible if one wants tochange the representation f feature structures.5.
Although syntactic structures are handled auto-matically by the rule compiler, it is occasionallyconvenient to be able to refer to them.
A symbol1~ > Syn,  where NT is a strong nonterminal, bindsSyn to the syntactic structure of the phrase analyzedby ~ (and is otherwise treated like an occurrence ofNT) 5.
There is a similar method for referring directlyto bracketing symbols (dealt with in the next sec-tion).Computational Linguistics, Volume 15, Number 1, March 1989Michael C. McCord Design of LMT: A Prolog-Based Machine Translation System2.2 METAGRAMMATICAL RULESThere are two grammatical constructions that are sopervasive and cut across ordinary grammatical catego-ries to such an extent, that they invite treatment bymetagrammatical ru es: coordination and bracketing.Coordination is construction with "and",  "or" ,  "but",etc.
Bracketing consists of the enclosure of sentencesubstrings in paired symbols like parentheses, othertypes of brackets, dashes, and quotes.
Also, in textformatting languages, there are paired symbols used forfont changes and other formatting control.
LMT is beingwritten to process the source text for the IBM SCRIPT/GML formatting language (as well as ordinary text), soit is important to handle such formatting control sym-bols.
(Note that "bracketing" symbols can be nested\[as in this sentence\].)
Use of metarules allows one tomake coordination and bracketing more "invisible" tothe parser and translator.Coordination has been treated metagrammatically inseveral systems.
In the logic programming framework,treatments include those in Dahl and McCord (1983),Sedogbo (1984), and Hirschman (1986).
The first ofthese systems implemented coordination metarules inan interpreter for the logic grammar, whereas the lasttwo implement them in a syntax rule compiler.
Brack-eting with ordinary parentheses is treated in the LRCsystem (Bennett and Slocum 1985) by reliance onLISP's handling of parentheses.There is a limited treatment of coordination andbracketing through metarules inthe MLG rule compiler.Specifically, the implementation is for coordination andbracketing of complete phrases, where a phrase is aword string analyzed by a strong nonterminal.
Anyphrase (type) can be coordinated, any number of times,using the usual coordinating conjunctions, commas, andsemicolons, as well as the "both-and", "either-or"constructions.
Bracketing of a phrase (with nesting toany level) is allowed in contexts where the phrase couldoccur grammatically anyway (as in this sentence).
Inaddition, appositive parentheticals, as in "I  know thatman (the one over there)", where a phrase type isrepeated in parentheses, are treated by the metarules.The current restriction to coordination of completephrases (without identifying aps) is not quite as severeas it might seem, because 1. there are quite a few phrasetypes (including verb phrases, verb groups, and noungroups), and for these, all appropriate associations ofvariables are made; and 2. examples with real gaps oftendo at least get parsed because of optional constituents(as in "John saw and Mary heard the train", where"John saw" is parsed as a complete phrase because theobject of "saw" is optional).The second argument of the Prolog term syn(Label,B,Mods) representing a syntax tree node is used toaccommodate bracketing.
The term B is a list of sym-bols, like quote.pa~ren.nfl, each representing a pair ofbrackets enclosing the phrase represented by the node.Computational Linguistics, Volume 15, Number 1, March 1989This "factored out" representation f brackets al-lows the translation component of LMT to handlebrackets in a way that is transparent to most of therules.
The result is that if a phrase is bracketed in acertain way in the English source, then the correspond-ing phrase will automatically be bracketed in the sameway in the German translation.Coordination and bracketing are handled in an inte-grated way by the rule compiler.
For each strongnonterminal, the following is done (a simplified versionis given here).
For the sake of concreteness, let us saythat the nonterminal has name nt and that it has fivearguments:nt(F,G,H.I,J)(before compilation), where the first two arguments Fand G are declared to be the feature arguments.
Theexisting syntax rules for nt are compiled essentially asin McCord (1985a), but the name given to the headpredicate is changed to ntbase, representing the simple(noncoordinated, nonbracketed) form of the phrase.
Inaddition, the metarules create four additional Prologrules--for the original nt, not for ntbase.
The firstadditional rule is:nt(F,G,H,I~I, syn(Lab,B1,Mods), g,z) *--copylabel(nt(F,G),nt(F1,G 1)) &bbrackets(B, U,V) &preconj(PC,Mods,Modsl, V,W) &ntbase(F1,G1,H,I~, B, SynO, W.X) &ntconj(F1,G1, F G,H,I,J, PC,Syn0,syn( Lab,B 1,Mods 1 ), X,Y) &ebrackets ( B1.
Y,Z).In each of these predications besides copylabel, the lasttwo arguments represent difference lists for wordstrings.
The purpose of eopylabel is to create a newversion of the label nt(F,G) which can differ in somesubterms, to allow for differences in the feature struc-tures of the coordinated phrases.
(Feature argumentsfor constituents ofcoordinated phrases are thus allowedto differ, but the other arguments in repeated calls ofntbase must match.)
The procedure bbrackets ("be-gin-brackets") reads the list B (possibly empty) ofbrackets from the word list (represented by differencelist (U,V).)
A possible preconjunction PC (like "both")is gotten by preeonj.
Then the simple nonterminalntbase is called.
Then ntconj gets the remainder of thecoordinated phrase, and ebraekets closes off the brack-ets.There are three rules for the continuation teonj.The first of these (to be given below) gets most types ofconjunctions, makes another call to ntbase, and finallycalls nt~onj recursively.
The second allows termina-tion.
The third is like the first, but gets other types ofconjunctions.
Thus, with termination i  the middle ofthese three rules, a preference 6 is created for certaintypes of coordination at the given phrase level.
Thedetails of this preference coding will not be given here.The first rule for ntconj is:37Michael C. McCord l)esign of LMT: A Prolog-Based Machine Translation SystemntconJ(F0,G0, F,G,H,I,J, PC,syn(nt(F0,G0)xdl,Mods0),Syn, U~X) *-optionalcommma(U,T.V) &coord(T,PC,a,nt,0p,LF ) &copylabel(nt(F,G),nt(F1,G1)) &ntbase(F1,G1,H,I~, nil,syn(nt(F1,G1)~il,Modsl), V,W) &combinelabels(T,nt(F0,G0).ut(F1,G 1),nt(F2,G2)) &ntcor~(F2,G2, F G,H,I?.I, nil,syn(nt(F2,G2),*,syn(nt(F0,G0 ),nil,Mods0 ).0p-LF.syn(nt(F1,G 1) ~il,:~/Iods 1).nil),Syn, w~x).Here coord tests that the terminal T is a coordinatingconjunction, allowing preconjunction PC, being of con-junction type (a,nt), and having associated logicalterminal Op-LF.
Conjunctions used in the first nteonjrule are given conjunction type (a,nt), and those usedin the third rule are given type (b,nt).
This distinction isrelated to specific conjunctions by the rules for coord.The procedure combinelabels combines features ofconjuncts (this includes the treatment of number forcoordinated noun phrases).
Finally, nteonj is calledrecursively to get possible further coordinated phrases.The second rule for ntconj (termination) is trivial,and will not be given.
The third is essentially like thefirst, but requires the conjunction type (b,nt) in the callto coord.Note that some category-specific nformation forcoordination does have to be written, mainly in the rulesfor copylabel and oombinelabels ( ince these dependon the nonterminal nt).
However, default rules exist forthese in ModL, so that one does not have to writespecial rules for all categories.
On the whole, theamount of rule writing is greatly reduced by the meta-rules.As mentioned above, the rules produced by themetarules were given here in simplified form.
Theactual, more complex, forms deal with the followingthree things.I.
A more complete treatment of bracketing andpunctuation within coordinated phrases.
The aboverules allow bracketing only at the beginning and endof a complete, coordinated phrase; therefore xtracalls to begin-bracket and end-bracket proceduresare needed.
Also there are actually two  terminationclauses for ntcor~--a clause dealing with appositivesintroduced by commas, and a simple terminationclause.2.
Appositive parentheticals (mentioned above).These are handled by an additional clause for nteonj.3.
A partial tabular parsing facility.
The purpose ofthis facility is to allow parsing (and translation) ofinputs that are not complete sentences, while usingtop-down parsing.
The only nonterminal called bythe driver of ModL is s, for a complete sentence.
Ithappens that most types of phrases can begin asentence in the ModL grammar.
When s fails but the38input is a well-formed phrase of some type, a syntac-tic structure for the input usually gets built neverthe-less during the parse.
Thus it is worth saving resultsof phrase analyses that span the whole input.
Therule compiler takes care of this by adding at the endof the main rule for each strong nonterminal (cf.
therule for nt above) a call to a procedure savesyn,which saves the corresponding syntactic structurewhen the analyzed phrase spans the whole inputstring.
(Saving is done by assertion into the Prologworkspace.)
Therefore, when a sentence analysisfails, these saved partial results may be used.Experiments were made with general tabular parsing(see, e.g., Pereira and Shieber 1987), but it was foundthat this does not speed up parsing with the particulargrammar ModL, especially considering that only thefirst parse is normally used in LMT.2.3 SYNTACTIC AND SEMANTIC TECHNIQUES IN MODLThe syntactic component of ModL is basically anextension of that in McCord (1982), which was writtenas a DCG.
In particular, slot filling techniques are usedin ModL for handling complementation.
However,there are some improvements in the basic techniques,which will be described in this section.2.3.1 POSTMODIFIERS AND ORDERING CONSTRAINTSAs in the earlier grammar, the analysis of the comple-ments of an open class word (verb, noun, or adjective)is directly controlled by a slot frame which appears inthe lexical entry of the open-class word.
There is a weaknonterminal postmods, which takes as input the slotframe of the word, chooses lots (nondeterministically,and not necessarily in the order in which they appear inthe slot frame), and tries to fill the slots by slot fillingrules indexed to specific slot names.
The procedurepostmods also finds adjunct postmodifiers.
Slot fillers(complements) correspond to arguments of the wordsense predication for the open-class word, and adjunctscorrespond to outer modifiers of it in logical form.By itself, the free choice of slots and adjuncts forpostmodification allows for free ordering of these post-modifiers; but of course the ordering should not becompletely free, and some constraints are needed.
Animproved method of expressing such constraints hasbeen developed for ModL.The same procedure postrnods is used for all threeopen class categories, but let us illustrate its use forverbs.
The following ModL rule (simplified) for thenonterminal predicate gets a verb and its postmodi-tiers.predicate( Infl,VS ~X,C )vc(Infl,VS,Y,Slots):voice( Infl~,Y,Slots,Slots 1):$theme(X,Slots,Z):postmods(vp,nil,Slots 1,VS,Z,C ).
(Recall that the $ sign signals that its operand is a Prologgoal.)
Here Infl is the inflectional feature structure ofComputational Linguistics, Volume 15, Number 1, March 1989Michael C. McCordthe verb, VS is the verb sense, X is the marker 7 for thegrammatical subject of the verb, and C is the modifiercontext for predicate (to be explained below).The nonterminal vc (verb compound), which is theonly strong nonterminal in this rule, gets the head of thepredicate.
(The feature arguments of vc are declared tobe its first two arguments.)
A verb compound normallyconsists of a single word, but could be a compound like"time share".
And of course since vc is a strongnonterminal, coordinated forms are allowed.
Verb com-pounds do not include auxiliary verbs as premodifiers;these are treated as separate, higher verbs with theirown complementation.
The call to vc determines themarker Y for the logical subject of the verb, and the slotlist Slots of the verb.The procedure voice handles the passive transforma-tion (when the verb analyzed by vc is a passive pastparticiple) as a slot list transformation, and themecomputes the marker Z for implicit subjects in comple-ments like "John wants to leave", and "John wants Billto leave".
For these, see the discussion in McCord(1982).The first rule for postmods, which gets slot fillers (asopposed to adjuncts), is as follows, slightly simplified(we leave off the treatment of the modifier contextargument for now).postmods(Cat,State,Slots,VS,Z)Sselectslot(Slot,State,Slots,Slots 1 ):filler(Slot,Z):postmods ( Cat,Slot.State,Slots 1,VS,Z).What is of interest here (compared with McCord 1982)is the use of the State argument, whose purpose is toconstrain the free ordering of postmodifiers.
In theearlier grammar, states were a linearly ordered set ofsymbols isomorphic to the natural numbers, and theidea was that postmodification by a given slot (oradjunct ype) can advance the state to a certain level, orleave it the same, but can never go backwards.
Thetrouble with this (as implemented) was that postmodscould try filling a "late state" slot when an obligatory"early state" slot has not been filled yet.
(This does notcause any wrong parses, but it is inefficient.
)The cure involves looking not only at the postmodi-tiers that have already been found, but also at theobligatory slots that are still pending.
The state is nowjust the list of slots and adjunct ypes that have alreadybeen used.
(Building up of this list can be seen in theabove rule for postmods.
)The procedure selectslot selects a Slot from thecurrent list Slots, with Slotsl as the remainder.
In sodoing, it looks at the current state as well as theremaining slots to exercise the constraints.The specific constraints hemselves are expressed inthe most straightforward way possible--as orderingrelationships S1 << S2 , where Sl and S2 are slotsor adjunct types.
Slots are represented as termsslot(S,Ob,Re,X), where 1.
S is the slot name (like obj orComputational Linguistics, Volume 15, Number 1, March 1989Design of LMT: A Prolog-Based Machine Translation Systemlobj), 2.
Ob indicates whether the slot is obligatory oroptional, 3.
Re indicates whether the slot has a realfiller, or a virtual filler (because of left extraposition),and 4.
X, is the marker for the slot filler.
Adjunct typesare simple symbols (like avel for adverbial clause),which divide adjuncts into broad types.
Specific order-ing constraints are:slot(lobj,*~,*) << slot (obj,*x,*).slot (obJ,*~,*) << slot (S,*~r,*) *-- S =/iobJ.slot(*,*~r,*) << avcl.The idea of soleotslot is then simple.
It selects a slot Snondeterministically from the current slot list Slots,leaving remainder Slotsl; but it checks that 1. there isno member Sl of State such that S << S1, and 2. thereis no obligatory slot 82 in Slots1 such that S2 << S.The basic idea of factoring out the control of constit-uent ordering into simple ordering relationships hasbeen used in other systems, for example in the systemicgrammar system of Hudson (1971), and more recently inthe ID/LP formalism (Gazdar and Pullum 1982).2.3.2 PREFERENCE ATTACHMENTA second improvement in ModL concerns preferenceattachment of postmodifiers in the sense of Wilks,Huang and Fass (1985), and Huang (1984a, 1984b).
Theproblem is simply stated: When we have parsed part ofa sentence, as in "John saw the way to send a f i l e .
.
. "
,and we see a further phrase "to Bill", then does thisattach to "file", "send", "way",  or "saw"?
I.e.,which final phrase of the partial sentence does it mod-ify?
If the initial segment were instead "John describedthe way to create af i l e .
.
. "
,  then the answer would bedifferent.The method of handling this in ModL is basicallysimilar to that in the work of Huang, Wilks, and Fasscited above, but seems slightly simpler and more gen-eral, because of the systematic use of postraods inModL.
The implementation involves the modifier con-text argument ( he last argument) of postmods.It should be mentioned first that the modifier contextis used not only for handling preference attachment, butalso for left extraposition.
The modifier context con-tains a pair of topic terms (T,T1) used as in McCord(1982) to represent a left-extraposed item T, with T1equal to nil or T according as T is or is not used as avirtual filler (or adjunct) by postmods.A modifier context is a term of the formo(T,T1,Pend), where (T,T1) is a topic pair and Pond isa pending stack.
The latter is a list whose members arepending frames, which are terms of the form Cat.Sense.Slots, giving a phrase category (verb, noun, or adjec-tive), the sense of the head, and the current slot list ofthe head (some slots may already be used).
A pendingframe describes what is possible for further modifiers ofa given head word (adjunct modification depends on thecategory Cat and the particular head word (sense)Sense).39Michael C. McCord Design of LMT: A Prolog-Based Machine Translation SystemUsing modifier contexts, an essentially completeversion of the slot-filling rule for post~mods is:postmods (Cat,State,Slots,VS,Z,c(T,T2,Pend))$ selectslot( Slot,State ,Slots ,Slots 1 ):filler(Slot,Z,c(T,Tl,(Cat.VS.Slotsl).Pend)):postmods ( Cat,Slot.State,Slots 1,VS,Z,c(T1,T2,Pend)).Thus, in the call to filler, the current pending frame isstacked onto the pending stack.
A rule for filling, say,an object slot with a noun phrase would pass this largermodifier context argument into the noun phrase, wherethe higher context is then available.On a given level for postmods, the most pressingquestion is how to attach prepositional phrases.
Slotfilling is always preferred over adjunct modification ona given level.
Thus, if the given head word has aprepositional object slot pobj (Prep) matching the givenpreposition, then only this will be tried.To decide whether a pp can attach as an adjunctmodifier, the pp rule (as soon as it sees the preposition)looks at the pending stack to determine whether thereare pending prepositional case slots (pobj) that couldtake the given preposition, and, if so, the pp aborts.Adjunct attachment of a pp can also be blocked bysemantic type requirements made by the preposition onthe modified phrase and the object of the preposition(even the combination of these two).
A discussion ofsemantic type checking is given at the end of thissubsection.
Currently the grammar does not try tocompare semantic types for preferences; but this couldbe done since the pending stack, with all the higher headword senses, is in place.2.3.3 NOUN COMPOUNDSA third improvement in the grammar is the treatment ofnoun compounds.
Noun compounds were treated in alimited way in McCord (1982) by allowing noun premod-ifiers of the head noun to fill slots in the head noun, asin "mathematics student".
In the syntactic structure,these noun premodifiers were all shown on the samelevel, as daughters of the noun phrase, although the slotfilling attachment to the head corresponds logically to aright branching structure.
But of course noun com-pounds in English can exhibit any pattern of attach-ment, with the patterns corresponding to the ways onecan bracket n symbols.
This is important to capture.The shift operator allows one to produce all patternsof attachment--left branching, right branching, and allcombinations in between--while using right recursiverules.
The following small grammar produces all possi-ble bracketings:np --* +N.np ---* +N: np%npl.npl ---* np.npl ~ np: np%npl.Here, np is a strong nonterminal and np l  is weak.Recall that + N signals that N is a terminal.In ModL, a somewhat more complicated form of thisfragment is used in the noun compound rules.
Eachsubcompound gets a slot list and a marker associatedwith it, and there is a procedure attach (an extension ofthat in McCord 1982), which allows one subcompoundto attach to another.
Adjectives are included in the pot,but the rules for attaching them are of course different.The potential to get any pattern of attachment exists inthe rules, but again preferences are implemented.Roughly, the idea is this: As a new noun (or adjective)N is read, if 1. the structure NO already built has a headthat is a noun, and 2.
N can attach to NO, then onerequires this immediate attachment, building a leftbranching structure.
Otherwise, one continues withright branching and attaches the larger compound toNO.
This scheme prefers left branching for a sequenceof nouns, if attach allows it, but prefers a right branch-ing structure for a sequence of adjectives followed by anoun.Currently, attach does not deal with "creative"attachments, where the relationship between the twosubcompounds is not mere slot-filling or apposition, butwhere the combination i volves some extraneous rela-tionship, as in "music box" and "work clothes".
Butan extended version of attach which handles suchcombinations could still be used in the existing algo-rithm.2.3.4 SEMANTIC TYPE CHECKINGSemantic type checking is done during parsing withModL.
In earlier versions of the system, semantic typechecking was accomplished by Prolog unification oftype trees, representing types in a hierarchy allowingcross-classification.
It appears that in practice thisscheme is not flexible and convenient enough; a moregeneral type checking scheme based on Prolog infer-ence has been implemented.Let us illustrate the new scheme with type checkingfor noun phrase fillers of verb slots.
In the format for aslot mentioned aboveslot(S,Ob,Re,X)X is the marker for a possible filler of the slot.
A markeris of the formY:Sense:SynFeas & Test.Here, Y is the logical variable associated with the nounphrase filler.
During lexical preprocessing, Y is unifiedwith the argument of the verb sense predication corre-sponding to this slot, or part of this argument.S When afiller is found during parsing, Y is also unified with themain logical variable for the noun phrase (normally thefirst variable in the noun sense predication).
The com-ponent Sense of the marker is the sense name of thehead noun of the filler.
(In earlier versions of ModL,this component was a semantic type for the nounsense.)
The component SynFeas is a term representingsyntactic and morphological features of the noun40 Computational Linguistics, Volume 15, Number 1, March 1989Michael C. McCordphrase.
Finally, Test is a Prolog goal that is executedafter the head noun is found.
Normally, Test willcontain a variable unified with Sense, so that a test ismade on the noun sense.As a simple example, if a verb requires that its objectbe a~i.mat~, then the object slot can have the markerY:S:SF & isa(S,animate).If the head noun has sense man l ,  and the clausesi sa(manl  ~human).isa(S,animate) <- isa(S~human).are in the Prolog workspace, then the test in the markerwill succeed.The lexical preprocessing scheme of LMT allowsconvenient specification of type requirements on slotfillers (and on other kinds of modifiers) and type state-ments for word senses.
Such type conditions can begiven in lexical entries in a compact format hat does notexplicitly involve isa clauses.
This will be described inthe next section.Design of LMT: A Proiog-Based Machine Translation System3 TaE LMT LEXICONSome MT systems have three separate lexicons, forsource, transfer, and target; but LMT has only one,unified lexicon, indexed by source language (English)words.
The entry for a word contains monolingualEnglish information about he word, as well as all of itstransfers.
A transfer element can contain monolingualGerman information about the target word.For example, a simple entry for the word "view"might beview < v(obJ) < n(nobj)< gv(acc,be +tracht)< gn(gen,ansichtzf.n).Here, < is just an operator that connects the compo-nents of the entry.
The monolingual English informationis on the first line, showing that view is a verb taking anobject and is also a noun with a (possible) noun object(appearing in postmodifier form as an of-pp comple-ment).
The transfer information is on the second andthird lines.
This shows that the translation of the verbform is the inseparable-prefix verb betrachten, wherethe German complement corresponding to the Englishobject akes the accusative case.
And the translation ofthe noun form is Ansicht, where the noun complementtakes the genitive case, and Ansicht is a feminine noun(f) of declension class n.There are two advantages of the unified lexicondesign: 1.
Lexical look-up is more efficient since onlyone index system is involved, and 2. it is easier for theperson creating the lexicon(s) to look at only onelexicon, seeing all pertinent information about a sourcelanguage word and its transfers.It might be argued that it is inefficient o storemonolingual target language information in transferelements, because there is redundancy, e.g., when twonoun transfers are German compound nouns with thesame head.
However, the format for specifying Germannoun classes and other German morphological informa-tion in the LMT lexicon is very compact, so theredundancy does not involve much space or trouble.More will be said below about the specification ofGerman morphological information.The principle that source language analysis in LMT isindependent of the task of translation is not reallyviolated by the unified lexicon, because purely Englishelements in lexical entries can easily be distinguished(as will be seen from the description below), and theremaining elements can be discarded, if desired, toobtain a monolingual English lexicon for other applica-tions.Another feature of the LMT lexicon is that thestorage format is not the same as the format seen by thesyntactic omponents.
Both formats are Prolog clauses,but the lexical preprocessing step of LMT does lexicalcompiling of lexical entries, converting the externalstorage format into the internal format used by thesyntactic omponents.
Lexical compiling is applied notonly to entries obtained by direct look-up (for wordsthat are found directly in the lexicon), but also to"derived" entries, obtained by morphological nalysisin conjunction with look-up.
There are two reasons fordoing lexical compiling.
One is that it allows for com-pact, abbreviated forms in the external lexicon based ona system of defaults, whereas the compiled internalform is convenient for efficient syntactic processing.Another eason is that the lexical compiler can producedifferent internal forms for different applications.
Infact, the internal form produced for applications ofModL involving logical forms is different from the formproduced for LMT.Lexical preprocessing is done on a sentence-by-sentence basis.
Only the words actually occurring in aninput sentence are processed.
The internal form clausesproduced for these words are deleted from the work-space, once the sentence is translated.
Thus the parsersees only lexical clauses relevant o the words of thesentence, and in general the Prolog workspace is notoverloaded by the more space-consuming internal-format clauses.
Currently, the external lexicon is storedin the Prolog workspace (there being about 1,600entries), but Prolog procedures for look-up in a largelexicon of the same form stored on disk have beenwritten--along the lines described in McCord (1987).Now let us look briefly at the external format.
9 Alexical entry consists of an English Word and itsAnalysis, represented asa Prolog unit clauseWord < AnalYSlS.
(Here, the predicate for the unit clause is the operator<.)
A word analysis consists of subterms called analysiselements connected by operators, most commonly theoperator <.
In the example for view above, there arefour analysis elements.
In general, analysis elementsComputational Linguistics, Volume 15, Number 1, March 1989 41Michael C. McCord Design of LMT: A Prolog-Based Machine Translation Systemcan be English elements, transfer elements, or (German)word list transformations.
English elements will bediscussed (briefly) in the current section; transfer ele-ments will be described in the next section, and wordlist transformations i  Section 6.English analysis elements are of three types:1. base analysis elements,2.
(irregular) inflectional elements, and3.
multiword elements.The above example for view has two English baseanalysis elements, the v (verb) and n (:noun) elements.Currently, there are 11 parts of speech allowed in baseanalysis elements--v (verb), modal, n (noun), propn(proper noun), pron (pronoun), adj (adjective), det(determiner), prop (preposition), subconj (subordi-nating conjunction), adv (adverb), and qua,l (qualifier).Let us look in particular at the form of' verb elements.The general, complete format (without use of de-faults) for a verb element isv(VSense,VType,SubjType,Slots )Here, VSense is a name for a sense of the index word asa verb, VType is the semantic type of the verb (aninherent feature), SubJType is the semantic type re-quirement on the (logical) subject, and Slots is the slotlist.
An example to look at, before seeing more details,is the following simplified v element for the verb"give":v(give 1,action,human,obj:concrete.iobJ :animate).The semantic type VType of the verb can in general beany conjunction of simple types (represented normallyby atoms).
The type requirement SubjType on thesubject can be an arbitrary Boolean combination ofsimple types.The slot list Slots is a list (using the dot operator) ofslot names (the final nfl in the list is not necessary),where each slot name may have an associated typerequirement on its filler.
Like the SubjTy-pe, a typerequirement for a slot can be an arbitrary Booleancombination of simple types.An abbreviation convention allows one to omit anyinitial sequence of the arguments of a v element.
If thesense name is omitted, it will be taken to be the same as?
the citation form.
Omitting types is equivalent to havingno typing conditions.
For an intransitive verb with notyping and only one sense, the element could be simplyv, with no arguments.Given a (possibly inflected) verb V and a v elementfor the base form of V, the lexical compiler translatesthe v element into a one or more unit clauses for thepredicate verb, with argument structureverb (V,Pred,lnfl,VSense ~r~qubJ,SlotFrame).Before saying what the arguments of verb are in gen-eral, we give an example for the inflected verb "gives"produced from the sample v element above:42verb(gives, give 1 (X:XS:XF,Y:YS:YF,Z:ZS:ZF),fin(pers3,sg,pres,*), give 1,X:XS:XF & isa(XS,human),slot(0bj,op,*,Y:YS:YF & isa(YS,concrete)) .slot(iobj,op,*,Z:ZS:ZF &isa(ZS,animate)) .
nil) .In general the arguments ofverb are as follows: V is theactual verb (possibly a derived or inflected form), andIn?1 is an allowable inflectional feature structure.
(There are as many verb clauses as there are allowableinflectional forms forV.
For example, ifV is made, thenthe inflection could be finite past or past participle.)
Theverb sense VSense becomes the predicate of the verbsense predication Pred, described in the next para-graph.
The argument XSubj is the marker for thesubject.
The slot list in the v element is converted intoSlotFrame, consisting of slots in the fuller form slot-(S,Ob,Re,Y) described in the preceding section.
(Therecan be optional and obligatory forms of the same slot.
)The verb sense predication Pred has argumentg cor-responding to the markers for the verb's complements--its subject and its slots--in the order given, but thereis an option in the compiler: When ModL is being usedto create LFL forms, these arguments will just be thelogical variable components of the markers for thecomplements.
But when ModL is used in LMT, thearguments will be the complete markers except for theirsemantic type tests.
(Thus the arguments are of the formY:Sense:Syr~eas, as described in Section 2.3) Thisready access to features of complements, by directrepresentation in the word sense predication, is veryuseful for transfer in LMT and will be illustrated in thenext section.The lexical compiler handles semantic type condi-tions by converting them into Prolog goals involvingisa.
For example, for each component type T of thesemantic type VType of a verb (given in a v element),the unit clause isa(VSense,T) is added to the work-space.
Thus, in the case of "gives" above,isa(givel,action) is added.
Type conditions as isaclauses relating to specific word senses are handleddynamically, but relations between types such astsa(S,animate) <-isa(S~human)are stored permanently.
A type requirement for a verbcomplement (subject or slot list member), being aBoolean combination of simple types T, is convertedinto a similar Boolean combination, Test, of goalsisa(S,T), where S is the sense component of the com-plement's marker; and Test is made the test componentof this marker.The second kind of English analysis element (men-tioned above) is an inflectional element.
Eleven kinds ofthese are allowed (McCord and Wolff 1988).
An exam-ple of an inflectional element isyen(V), which indicatesthat the index word is the past participle of the verb V.This appears inbecome < v(predcmp) < ven(become).Computational Linguistics, Volume 15, Number 1, March 1989Michael C. McCord Design of LMT: A Prolog-Based Machine Translation Systemwhere become is shown as the past participle of itself.The third kind of English analysis element is themultiword element.
Multiword elements (existing intransfer also) are used for handling idiomatic phrases inLMT.
Multiword forms are allowed for all but three( moda l  propn, and qual ) of the 11 parts of speech.Their names are like the base analysis element names,but with a initial m. An example of an entry with amultiverb element is the following (simplified) entry for"take":take < v(obJ) < mv(=.care.of, bj).The mv element allows a treatment of the phrase "takecare of X".
Forms based on inflections of the indexword, such as "took care of", are handled automati-cally by the morphological system.
Multiword elementshave much the same format as single word elementsexcept hat sense names cannot be specified, and thefirst argument is always a multiword pattern (like= .care.of).
Lexical preprocessing verifies that thepattern actually matches a sublist of the sentence beforecompiling the multiword element.Some kinds of idiomatic phrases are treated throughthe use of slots in base analysis elements.
For example,there is a verb slot ptcl(P) that allows particles, spec-ified by P, for the verb.
The particle P might be anordinary particle like "up" or "back" as in "take up","take back", or it could be a phrasal particle, likeinto.consideration, for handling "take into consider-ation".
Note that "into consideration" does behavemuch like an ordinary particle, since we can say "takeX into consideration", as well as "take into consider-ation X", if X is not too light a noun phrase.
A baseanalysis element for "take" that allows both ordinaryparticles and the multiparticle "into consideration" isv(obj.ptcl(all I into.consideration)).This shows that "take" is a verb with an object slot anda particle slot.
The particle allowed could be anyordinary single-word particle (indicated by all ) or(indicated by I) the multiword particle "into consider-ation".Idiomatic phrases can also be treated by Germanword list transformations.
These are described in Sec-tion 6.In addition to the unified LMT lexicon we have beendescribing, there is an auxiliary interface of ModL tothe UDICT monolingual English lexicon Byrd (1983,1984).
This contains around 65,000 citation forms, witha morphological rule system to get derived forms ofthese words.
The ModL lexical compiler also canconvert UDICT analyses to the internal form requiredby the ModL grammar.4 THE TRANSFER COMPONENT OF LMTThe transfer component akes an English syntacticanalysis tree syn(Lab,B,Mods) and converts it to aGerman tree syn(GLab,B,GMods) which normally hasthe same shape.
Before discussing the transfer methodin general, let us look at an example.
The Englishsentence is "The woman gives a book to the man".
Thesyntactic analysis tree produced by ModL is:s(fin(pers3,sg,pres,ind),glve,*,top)np(X:woman:*&*)detp(X:woman:*&*)the(P,Q)woman(X:woman:*)vp ( fin(pers3,sg,pres,ind),give )give(X:woman:*,Y:book:*,Z:man:*)np(Y:book:*&*)detp(Y:book:**)a(P1,Q1)book(Y:book:*)ppnp(to,Z:man:*&*)np(Z:man:*&*)detp(Z:man:*&*)the(P2,Q2)man(Z:man:*)Each n0nterminal node label in the tree consists of thestrong nonterminal responsible for the node togetherwith its feature arguments (as indicated in Section 2.
I).The feature arguments for the np nodes are just themarkers for these noun phrases.
For the sake of sim-plicity in the display of this tree, the syntactic featurestructures and semantic tests of np markers are justshown as stars.
The terminals in the syntactic analysistree are actually logical terminals, but we do not displaythe operator components, ince these are not relevantfor LMT.
Also, we do not display the node labels fornoun compounds (nc) and verb compounds (vc) unlessthese compounds have more than one element.To get a good idea of the working of the transferalgorithm, let us look at the transfer of the verb "give"in this example, and the effect it has on the rest of thetransfer.
The terminal in the above tree involving ive isa verb sense predication of the form described in thepreceding section as the second argument of verb.
Themost relevant hing to notice in the syntax tree is thatthe variables X, Y, and Z in the give predication areunified with the logical variables in markers of thecorresponding complements of gi~re.
Transfer of thegive form simultaneously chooses the German targetverb and marks features on its (German) complementsby binding X, Y, and Z to the proper German cases.
Theinternal form of the transfer element in the lexical entryfor "give" might look like the following unit clause.10gverb(give(nom:*,acc:*,dat:*),geb).In transfer, the first argument of gvorb is matchedagainst he give form in the tree, and we get bindingsX = nora, Y = ace, and Z = dat, which determine thecases of the complements.
In general, logical variablesassociated with complements are used to control fea-tures on the transfers of those complements.
The trans-fer tree is as follows:Computational Linguistics, Volume 15, Number 1, March 1989 43Michael C. McCord Design of LMT: A Prolog-Based Machine Translation Systemvp(ind:slin(pers3,sg,pres,ind): Xl,nil)np(n(on),nom,sg:pers3-sg-f~2)det(nom,pers3-sg-f~2)d + det(nom,pers3-sg-f~X2)frau/1 + nc(n(cn),nom,pers3-sg-f~X2)vp(ind:vp ;fin(pers3,sg,pres,ind): Xl,nil)get) + vc(ind:vp;fln(pers3-sg-f~pres, ind):Xljail)np(n(on),aco,sg:pers3-sg-nt~X3)det(acc,pers3-sg-nt~X3)ein + det(acc,pers3-sg-nt~X3)buch/h + nc(n(cn),acc, per~33-sg-nt~X3)ppnp(vp(inchvp;fln(pers3,sg,pres, ind):Xl jall),dat)np(n(cn),dat,sg:pers3-sg-m$C4)det(dat,pers3-sg-m~4)d + det(dat,pers3-sg-rn~X4)mann/h + nc(n(cn),dat,pers3-sg-m,X4)The three noun phrases in this tree have, the correct casemarkings as a result of the above verb transfer, so thatwe will eventually get die Frau, ein Buch, and demMann.
~ A transformation (to be discussed below)moves the dative noun phrase, and the eventual trans-lation (after inflection) is Die Frau gibt dem Mann einBuch.The top-level procedure, transfer, of the transfercomponent works in a simple, recursive way, and iscalled in the formtransfer (Syn,MLab,GSyn)where MLab is the German ode label on the mother ofthe node 8yn being transferred.
(In the top-level call,MLab is equal to the symbol top.
)The definition of transfer,  somewhat simplified, is:transfer(syn(ELab,B,EMods),MLab,syn(GLab,B,GMods)) ~--tranlabel( ELab,MLab,GLab ) &tranlist(EMods,GLab,GMods).transfer(0p-EPred,MLab,GWord + GLab) ~-tranword(EPred,MLab,GWord,GLab).tranlist(EMod.EMods,MLab,GMod.GMods ) ~--transfer(EMod,MLab,GMod) &tranlist(EMods,MLab,GMods).tranlist(nil,*,nil).Thus, transfer translates a syn structure (a nontermi-nal node of a tree) by translating the node label (by a callto tranlabel) and then recursively translating thedaughter nodes.
Terminal nodes (words) are translatedby a call to tranword.Note that transfer does the transfer in a simpletop-down, left-to-right way.
The German feature struc-tures (showing case markings, for instance) that getassigned to nodes in the left-to-right processing areoften partially instantiated, and do not get fully instan-tiated until controlling words are encountered further tothe right.
For example, the German feature structureassigned to the subject noun phrase in the above exam-ple does not get the case field assigned until the verb isprocessed.
The use of logical variables and unificationmakes this easier.The clauses for tranlabel (which transfers nodelabels) are mainly unit clauses.
The basic problem is to44transfer an English feature structure to a German fea-lure structure, allowing for differences in a suitableway.
For example, the number of an English nounphrase is often the same as the number of the corre-sponding German noun phrase, but not always.
Themain tranlabel clause that transfers a noun phrase labelis:tran\]abel(np(Case:Sense:nf(NType,Num,*,*)&*),MLab,np (NType,Case,Num~dj Decl)).The first component, NType, of the German p featurestructure (and the first component of the nf  ("npfeatures") syntactic feature structure for the Englishnoun phrase) is the nominal type, which encodes cate-gorization of the head nominal.
Nominal subcategoriesinclude common nouns, pronouns, proper nouns, andadjectives.
Adjectives are further subcategorized asverbal (verb participles) and nonverbal, and the com-parison feature (positive, comparative, superlative) foradjectives i also shown in NType.The second component, Case, of the German npstructure is unified with the first component of theEnglish marker.
As indicated above, this gets unifiedwith an actual German case by application of a verbtransfer ule.The third component, Num, of the German npstructure ncodes number, person, and gender of theGerman noun phrase.
The tranlabel rule above unifiesNum with a component of the English nf  structure; but,as we will see below, Num is of such a form that 1. itsoccurrence in the English analysis is independent ofGerman, and 2. the actual number of the German ounphrase can come out different from that of the English.The last component has to do with adjective declen-sions (strong vs. weak).
This is discussed in McCordand Wolff (1988).The German feature structure for a noun compound(nc) (including a simple head noun) has a similar form toan np structure.How is the Num field used to treat differences innumber between English and German?
This is actuallya compound term of the form ANum:CStruet, whereANum is the actual number (sg or 91) of the Englishnoun phrase (which may be a coordinated noun phrase),and CStruet is a term that reflects the coordinationstructure.
For example, for the noun phrase "the manand the woman", the number structure isph(Nl&N2),where the subphrase "the man" has number structuresg:N1 and "the woman" has number structure sg:N2.Before transfer, the second components of the num-ber structures of simple noun phrases are just variables,but during transfer these get bound by t ranword tostructures of the form Pers-Num-Gen showing person,number and gender Of the German translations.
Theperson and gender of the simple German noun phrasecome directly from the lexical transfer entry for thehead noun.
The question is how the number of theComputational Linguistics, Volume 15, Number 1, March 1989Michael C. McCord Design of LMT: A Prolog-Based Machine Translation SystemGerman noun phrase (possibly coordinated) is deter-mined.
For a simple noun phrase, the default is to unifythe German number with the English number, buttransfer entries can override this, as in the case ofscissors/Schere.
Given this determination of the Ger-man numbers of the simple np components of a coor-dinated rip, the German number of the whole can bedetermined from the second component of the numberfield.
In the case of coordination with and/und, theresult will simply be plural in German (as in English).For coordination with or/oder, though, German is dif-ferent from English.
In English, the number of thedisjunction is the same as that of its last component,whereas in German the disjunction is plural if and onlyif at least one of its components i  plural.Thus, for the noun phrase "the men or the woman",the English number structure is sg:(NllN2), where thenumber of "the men" is phN1, and the number of "thewoman" is sg:N2.
After transfer, this structure for thetranslation die Maenner oder die Frau becomes sg:(pers3-pl-mlpers3-sg-f).
The second component ofthis determines a final number of pl for the translation.On the other hand, the English noun phrase "the knifeor the scissors" is plural, but the translation, dasMesser oder die Schere, has number structure ph(*-sg-*l*-sg-*) and so is singular.In the sample transfer tree above, one can see otherexamples of the transfer of feature structures, for whichtranlabel is responsible.
In the vp feature structures,the second component is of the form Infl:Inf11, whereInfl is the English inflection and Infll is to be the finalGerman inflection.
The default is for Inf11 to becomeequal to In.f1, but this does not always happen.
TheEnglish inflection might be overridden by a transforma-tion.
For example, LMT translates "The man wants thewoman to buy a car" into Der Mann will, da\[3 die Fraueinen Wagen kauft.
The infinitive v'p complement of"wants" is transferred to an infinitive German vp, butthis and its sister np subject are transformed into a finiteclause complement of "will".The transformation mentioned in the previous para-graph (needed for transforming an np + infinitive-v-pstructure to a finite clause) is triggered by the lexicaltransfer element for the controlling verb "want".
Spe-cifically, the trigger (or rule switch) is the German"case" corresponding to the last (vp) complement of"want".
Any case assigned to a v-p complement isunified by tranlabel with the last field of the German vpfeature structure (see the sample transfer tree above forexamples of such vp structures).
Transformations canrecognize such cases and be triggered by them.The proceduretranword(EWord,MLab,GWord,GLab)is the interface to the transfer portion of the lexicon.
Ittakes a terminal EWord representing an English wordsense predication dominated by a node with associatedGerman label MLab, and assigns to these the Germantranslation GWord and its associated feature structureGLab.
(Often GLab will be taken to be the same asMLab.)
The procedure tr~ia-~word, in looking at thelabel MLab, can call various more specific transferprocedures, like gverb and gnoun, associated withvarious parts of speech.
Clauses for these are producedby the lexical compiler from transfer elements in theexternal lexicon.
We have already seen a sample clausefor gverb.Lexical transfer elements can be either of single wordor muitiword form.
Each type of English analysis ele-ment (associated with a particular part of speech) has acorresponding type of transfer element, whose name isobtained by prefixing the letter g, except hat 1. propernouns just translate to themselves, 2. modals are sub-sumed under gv, and 3. qualifiers are subsumed undergary.
Multiword transfer forms exist for all the multi-word source forms, and have names of the form rag-part-of-speech (like ragadv).As in the case of English analysis elements, there isa system of abbreviations and defaults for the externalforms of lexical transfer elements.
Let us illustrate thesituation for verbs (in single word form).
The full formof a gv element (external form for gverb clauses) isgv(VSense,SubJ Case,CompCases,Target ).The first argument is the verb sense.
Its default is theindex word.
The second argument is the German casefor the German complement corresponding to the En-glish logical subject (which is usually, but not always,the German logical subject).
Its default is nora (nomi-"native).
The third argument is the list of cases for theother complements (given in order corresponding to theslots of the v element for the same sense of the indexword and having the same number of complements).
Ifthis argument is omitted, the verb should be intransi-tive.
The last argument is the German target verb.The cases appearing in the second and third argu-ments of gv can have associated semantic type require-ments (arbitrary Boolean combinations) on the corre-sponding complements.
An example illustrating this isthe following external form entry for "eat",  used totranslate "eat" into essen or fressen, according as thesubject is human or nonhuman.eat < v(obJ)< gv(nom:human,acc,ess )< gv(nom:( anlmate&-human),acc J~ess ).Normally, a gv element is compiled into a (possiblyconditional) clause for gverb, where the clause head hasthe form~e~(~ed,T~g~) .Here, Prod is an English verb sense predication of thesame form described for the second argument ofvorb inthe preceding section.
The logical variable componentsof the arguments of Prod are bound (in the gvorbclause) to the German cases appearing inthe gv elementComputational Linguistics, Volume 15, Number 1, March 1989 45Michael C. McCord Design of LMT: A Prolog-Based Machine Translation System(in the order given).
Any semantic type requirementsattached to these cases are converted into Prolog goalsthat are combinations of isa tests on the sense variableof the associated marker, and these goals are put on thecondition side of the gvorb clause.
For example, the gvelements for "eat" above are compiled into the follow-ing gverb clauses:gverb(eat(nom:S:*,acc:*),ess) *--isa(S,human).gverb(eat(nom:S:*,acc:*);fress) *--isa(S,animate) & -\]isa(S~uman).The German case symbols that can appear in transferentries include not only the standard fbur cases (nora,ace, dat, and gen), but also prepositional case symbols(for pp complements of German verbs),, which are of theform pc(Prep,Case).
This form signifies that the spe-cific preposition Prop appears, followed by a nounphrase with case Case.
The Case component of pc canbe omitted when a default case is to be used.
Forexample, an entry for "search (something) for (some-thing)" could besesa'ch < v(obj.pobJ(for))< gv( acc.pc(nach),durch + such).The gvorb clause compiled for this gv element is theunit clause:gverb(search(nom:*,acc:*,pc(nach):*),durch+ such).There are also special genitive cases that allow for thevariation in ein Stack des wei\[3en Papiers/ein Stackwei\[3es Papier (' 'a piece of the white paper"/' 'a piece ofwhite paper").
In the first phrase the complement ofStack is a real genitive, but in the second phrase thecomplement takes the same case as StaXek itself.One allowance that has to be made is that the subjectof the English verb may not correspond to the subject ofthe German verb.
This occurs with the translation of"l ike" into gefallen, where we can translate " I  like thecar" into Mir gefaellt der Wagen.
An internal-formtransfer entry for the verb "like" isgverb(like(dat:*,nom:X),ge + fall,*:X).The extra argument of gvorb is the marker (minus test)of the German subject.
In such instances, tra~wordmust make sure that the German verb (if finite) agreeswith the actual German subject.Care is taken in the trazaword rules involving gvorbto handle auxiliary verbs correctly.
One problem is toget the correct case marking on the German subject andthe correct inflection on the highest auxiliary, eventhough the English subject may not correspond to theGerman subject of the main verb.In particular, care with case marking must be takenin the translation of passives.
In a German passive, thegrammatical subject may correspond to a direct objectin the active form, but it may not correspond to anindirect object (as it may" in English).
Thus, LMTtranslates "The car was given to the man" into DerWagen wurde dem Mann gegeben, but translates "Theman was given a car" into Dem Mann wurde ein Wagengegeben (where ein Wagen is the grammatical subject).Currently, LMT translates the English passive only bythe use of werden.
The use of sein and active forms willbe tackled eventually.In the translation of the perfect "have",  the haben/sein distinction is made by feature markings on theEnglish verb complement of"have".
It could be arguedthat this is an exception to the principle that the Englishgrammar is written independently of the task of trans-lation, but the distinction made by the required featuresis largely semantic.How does LMT treat situations in which there is nota word-for-word correspondence in translations?
Ofcourse transformations can add, delete, or rearrangewords, and examples of these will be discussed in thenext section.
But, in keeping with the principle ofgetting as much right as possible during transfer, vari-ous methods are used in transfer, too.One method is that the result arguments of lexicaltransfer elements can contain compound terms thatrepresent word sequences.
The most general form isWl#W2, which represents Wl followed by W2 (with aseparating blank).
This form is used, for example, incases where the verb translation is a reflexive verb.
Theverb "refer to" translates to sich beziehen auf, and theexternal form of its transfer element is:gv(pc( auf, acc),sich#be + zieh).The lexical compiler converts this to the internal form:gverb(refer(nom:F,pc(auf,acc):*),refl(*:F)#be+zieh).The term refl(X) representing the reflexive containsthe feature structure of the German subject, so that itmay be realized as the correct form of the reflexivepronoun by the German morphological component.A special compound form shows up in the represen-tation of separable prefix verbs, which are of the formPrefix:Verb.
(As exhibited above for beziehen, insepa-rable prefix verbs are given in the form Prefix+Verb.
)A separable prefix can become a separate word througha transformation that recognizes the special form andmoves the prefix appropriately.
The separable prefixverb device P:V can often be used also to specifytransfers where the target is an adverb-verb combina-tion, when the adverb behaves transformationally like aseparable prefix.One could say that the translation of noun com-pounds involves a many-to-one correspondence, sincenoun compounds are given as a group of words inEnglish, but often as a single word in German.
Theprocedure tranlabel is responsible for marking the ncfeature structure of each noun premodifier of a noun.The case feature of such a noun premodifier is markedby a special case symbol comb (combining form), whichsignals that the noun is part of a noun compound and46 Computational Linguistics, Volume 15, Number 1, March 1989Michael C. McCordwill be given a special form by the German morpholog-ical component.The most important means for handling noncompo-sitional translation in LMT is through the use of multi-word elements in the lexicon.
As indicated in thepreceding section, all but three of the eleven parts ofspeech allow multiword forms, in transfer as well as insource analysis elements.
As an example, to translate"take care of" into sich kiimmern um, the relevantportion of the external form entry for "take" could betake < mv(=.care.of, bJ)> mgv(pc(um),sich#kfimmer).The connecting operator > tells the lexical compiler toprocess its right operand only if its left operand has"succeeded" (i.e., the mv pattern has matched).The patterns in multiword elements can containvariables.
For example, the phrase "at least N",  whereN is a number (like "5" or "five"), can be considereda multi-determiner.
This can be translated into min-destens M, where M is the German form of N, by themultiword elements in an entry for "least" (showingonly the relevant part of the entry).least < mdet(at.=.N)-enum(N)> mgdet(mindestens#M)-gnum( N,M ).Prolog goals associated with multiword elements areindicated by attaching them with the operator -.
Thelexical compiler handles such goals in source elementsdifferently from goals in transfer elements.
A goal for asource element, like chum(N)  in the example, istreated as a test that is executed at lexical preprocessingtime after the multiword pattern successfully matchespart of the sentence.
If this test does not succeed, themultiword element is not compiled.
A goal for a transferelement, like gnum(N,M) (which associates the En-glish number N to the German number M), is added bythe lexical compiler to the right-hand side of the clausecompiled for the multiword transfer element, and thus itis not executed until transfer time.
(In the above exam-ple, this postponement is not necessary; but in generalit is necessary because the transfer may depend oningredients from the rest of the sentence that are notknown until a complete parse is obtained.
)Non-compositional translation can also be handledby the German word list transformations allowed inlexical entries.
This facility will be described in Section6.
For more details on lexical aspects of transfer, seeMcCord and Wolff (1988).5 GERMAN SYNTACTIC GENERATIONAs indicated in the Introduction, the purpose of thiscomponent is to generate a German surface structuretree from the transfer tree, and this is accomplished byapplying a system of transformations.
Before the trans-formations operate, however, aminor bookkeeping stepis carried out, having to do with bracketing.
Recall thatDesign of LMT: A Prolog.Based Machine Translation Systemsyntax trees (both English and German) are representedso far as termssyn(Label,B,Modlfiers)where B is the bracket list for the node.
Transforma-tions operate on terms similar to this, but it is conve-nient if they do not have to deal with bracket listsexplicitly.
Therefore, tree terms in the above form areconverted (by the bookkeeping step in question) to treeterms in the simpler formsyn(Label,Modiflers 1)where Modlfiersl is obtained by surrounding Modl_q-ors appropriately with the terminal pairs correspondingto the bracket symbols in the list B.
The main procedurefor syntactic generation,generate(Syn,Synl),applies transformations to a syn tree Syn (in the simplerform), producing another syn tree Synl .
This worksrecursively on the tree.
At each level, generate is firstapplied recursively to the modifiers, giving a tree with anew modifier list.
Then the transformations are appliedin a loop: Each time through the loop, the first applica-ble transformation is used (hence the order of transfor-mations matters).
The loop terminates when no trans-formation is applicable.
Thus the definition can be givenas :generate(syn(Lab,Mods),syn(Lab2,Mods2)) ~--/&genlist(Mods,Mods 1) &.alltransforms(syn(Lab,Mods 1),syn( Lab2,Mods2 )).generate(Mod,Mod).genlist(Mod:Mods,Modl :Mods 1) ~--generate(Mod,Modl) @9genlist(Mods,Modsl).genlist(nil,nil).alltransforms( Syn,Syn2 ) ~--transform( Trans,Syn,Syn 1 ) &/&alltransforms(Syn 1,Syn2).alltransforms(Syn,Syn).
(The symbol / denotes the cut in VM/Prolog.
)Note that in this scheme transformations on a givenlevel are applied after the recursive generation of daugh-ter nodes.
The alternative schemes of applying them allbefore recursive generation, or applying some desig-nated transformations before and others after recursivegeneration, were tried in earlier versions of LMT.
Butthese other schemes led to problems with a workableordering of the list of transformations.
Also, experi-ments were made with an additional system of transfor-mations, applied to English trees prior to transfer, but itwas found that this complication is unnecessary.Specific transformations are given by rules for trans-form.
Its first argument is just a name for the transfor-mation, like verbfinal, which is used in tracing (in afuller definition of generate).One could write rules for t ransform directly, but inLMT transformational rules are written in a slightlyComputational Linguistics, Volume 15, Number 1, March 1989 47Michael C.  McCordmore convenient notation and then compiled into rulesfor transform.
The main purpose of the alternativeformat is to provide an augmentation of the patternmatching of Prolog in which specially marked terms canmatch sublists of lists.
Specifically, when a term of theform %X is written syntactically as a member of a list,then X matches (unifies with) any sublist in that posi-tion.
This can be used both in analyzing and construct-ing lists.
As an example, the expression a.b.%X.e.d.n.ilmatches the list a.b.u.v.w.e.d.
11il and unifies X withu.v.w.nfl.
(Similar conventions have been used in manypattern matchers dealing with lists.)
In this implemen-tation, such extended list expressions can be embeddedarbitrarily in Prolog terms.The form for a transformation given to the rulecompiler is:Nsf f I l o  - -A === > B*-- Condition.Here, A and B are arbitrary Prolog terms, containingpossible extended list expressions.
The Condition is aProlog goal, and it can be omitted if desired.
This rule iscompiled into a t ransform rule of the formtransform(Name~l,B1) ~-ASplit & Condition & BSplit.Here, the original pseudo-term A involving % elementshas been re-expressed as an ordinary term A1 and aconjunction NBplit of calls to conc, which concatenateslists.
Similarly, B is re-expressed asB1 and BSplit.As an example, a simplified version of the Germandative transformation isdative - -syn(vp, %LMods.Obj.IObj.RMods )syn(vp, %LMods.IObj.Obj.RMods )*-- case(Obj,acc) & case(IObj,dat).This is compiled into the t rans form rule:transform(dative, syn(vp,Mods), syz.
(vp,Modsl)) *--concCLMods, Obj.IObj.RMods, Mods) @*case(0bj,acc) & case(I0bJ,dat) &conc(LMods, IObj.Obj.RMods, Modsl).For efficiency, the Condi t ion  is inserted betweenASplit and BSplit, because Condition normally con-tains constraints whose arguments become known im-mediately after execution of ASplit.The transformation rolclauso is defined as follows(we give here somewhat simplified versions of theactual transformations).relclause - -syn(vp(dep (tel( Case,Type,PNG ) ),I,M ), Mods)syn(vp(dep(rel),I,M), (','+punt).
(drel +pro(Case,PNG)).%Mods.
(',' +punc).nn).\]Design of LMT: A Prolog-Based Machine Translation SystemHere, PNG is the person-number-gender structure forthe noun phrase modified by the relative clause.
(The viaarguments I and M are as described in the precedingsection.)
The relclause transformation is responsiblefor adding a relative pronoun and surrounding commasto the relative clause.
In the English analysis tree, norelatiw: pronoun is explicitly shown.
(Note that incertain cases it can be omitted in the English sentence.
)Thus, "'The man I saw is my brother" translates intoDer Mann, den ich sah, ist rnein Bruder.
There arevariants of this relative clause transformation dealingwith cases like "The book to which I referred is old",which translates to Das Buch, auf das ich mich bezog,ist alt.
LMT also gives exactly this same translation foreach of the English sentences: "The book which Ireferred to is old", "The book that I referred to is old",and "The book I referred to is old".There is a similar transformation compclause, whichadds the word da\[3 and commas to a finite complementclause.
Thus, "Hans knows Peter is my brother" trans-lates into Hans wei\[3, da\[3 Peter mein Bruder ist.The example just given illustrates the need to movethe verb to the end of a dependent clause.
This is doneby the transformation verbfinal, defined as follows:verbfinal - -syn(vp(dep(T),I,M), %Mods 1.Verb.Mod.Mods2 )syn(vp(dep(T),I,M), %Mods 1.Mod.Verb.Mods2).-- syrdabel(Verb,vc(*,*,*)) &~clausal(Mod) &--lallpunc(Mod.Mods2).The idea is simply that the verb Verb hops over themodifier Mod to its right, provided that Mod is notclausal (to be explained) and provided that the remain-ing modifiers (including Mod) do not consist solely ofpunctuation.
For example, in the translation of the nounphrase "the man that gave the woman the book", theverb gab moves all the way to the end of the relativeclause, producing: der Mann, der der Frau das Buchgab.
Note that verbfinal may apply several times, untilthe verb has moved as far as it can go.
(It is possible tobe a bit more efficient by writing an auxiliary procedureto perform the movement.
)The point in not hopping over clausal elements inverbfinal is illustrated with the translation of the nounphrase "the man that told me that Hans bought a car",which is der Mann, der mir sagte, da\[3 Hans einenWagen kaufte.
Here, sagte hops over mir, but not overthe da\[3 clause.
Roughly, clausal elements are phraseswhose heads are verbs.But an interesting situation for vorbfinal arises whenthere is a clausal element that is on the right end of thetree but is not a sister of the verb being moved.
Thisoccurs in the translation of the noun phrase "the manthat gave the woman the book I referred to".
Here gabshould not move past the final relative clause, and theresult should be: der Mann, der der Frau das Buch gab,aufdas ich reich bezog.
The final clausal element couldactually be embedded several evels.
To handle this,Computational Linguistics, Volume 15, Number 1, March 1989 48Michael C. McCord Design of LMT: A Proiog-Based Machine Translation Systemthere is a transformation clauseraise, ordered beforeverbflmal, which raises such final clauses.
Its definitionis simply:clauseralse - -syn(Lab, %Mods.syn(Lab 1,%Mods 1.Syn.nil).nil )syn(Lab, %Mods .syn(Lab 1,Mods 1 ).Syn.nil )~-- clausal(Syn).This may operate through several levels before theresult of the raising is pertinent to verbfinal.The transformation verbfinal also handles (withoutextra effort) the word ordering in auxiliary verb con-structions, because of the treatment of auxiliary verbsas higher verbs.
Thus, the sentence "Hans will havebought the car" is structured as Hans \[will \[have\[bought the car\]\]\].
Before transformations, the transla-tion will be structured as Hans \[wird \[haben \[gekauftden Wagen\]\]\].
The verb phrases headed by haben andgekauft are dependent, so verbfLual operates on themto give: Hans \[wird \[\[den Wagen gekauft\] haben\]\].
(Thephrases hopped over are not cases of clausal elements.
)Right movement of separable verb prefixes in inde-pendent clauses is similar to right movement of the verbin dependent clauses.
This is handled by two transfor-mations, one to separate the prefix, the other to move it.In this case, too, the moved item does not hop overclausal elements.
An example for the separable prefixverb aufbereiten ("edit") is in the LMT translation ofthe sentence "Hans edited the file that he had created",which is Hans bereitete die Datei auf, die er erstellthatte.
In dependent clauses, the separable prefix stayswith the verb, although inflection has to treat it speciallyfor past participles and zu infinitive forms.Ordering of transformations is important in that elau-seraise must be ordered before verbfinal and theseparable prefix transformations.
In turn, it is importantto order the dative transformation before all of these.
Ifthe dative noun phrase to be moved contains a finalclausal element, then this element should not be abarrier to rightward movement of a verb or separableprefix.
If dative operates first, the final clausal elementwill go with the whole dative noun phrase, and will nothave a chance to be raised by clauseraise, which onlysees clausal elements on the extreme right of the clausein which it operates.
Thus, for the sentence "Hansknew that Peter had given a book to the woman hesaw", the translation is Hans wu~te, da\[3 Peter derFrau, die er sah, ein Buch gegeben hatte.Another example of a transformation is verbsecond,which operates in independent clauses.verbsecond - -syn(vp( ind(s) , I ,M),  Mod.%Modsl.syn(vp(ind(vp),I1,M1),%Mods2.Verb.
Mods3).Mods4)syn(vp(ind(s),I3ql), Mod.Verb.%Mods 1.syn(vp(ind(vp),I 1 M 1),%Mods2.Mods3).Mods4)*- Modsl = /nil & synlabel(Verb,vc(*,*,*)).Computational Linguistics, Volume 15, Number 1, March 1989As the name indicates, this moves the verb so that it isthe second modifier of the independent clause.
As aresult, the sentence "Probably the file was created byHans" translates into Wahrscheinlich wurde die Dateivon Hans erstellt, where wurde is moved into secondposition by verbsecond.An interesting example of a transformation is subcl,which adds pronouns in examples like"The man wants the woman to speak with Hansbefore buying the car.
"Der Mann will, daft die Frau mit Hans spricht, bevorsie den Wagen kauftHere, the translation of the subordinate participialclause "before buying the car" is the finite clause bevorsie den Wagen kauft (before she buys the car), wherethe pronoun sie (she), referring to the subject of thematrix clause, is added.
The English analysis hows avariable in the analysis of the participial clause which isunified with one in the subject of the matrix clause.
Thisvariable serves as the link to transmit he appropriateperson-number-gender to the subordinate clause in thetransfer tree.
The transformation subcl can then easilyadd the correct pronoun.A final example of a transformation is possessive,which deals with left-branching possessive noun phraseconstructions, asin "my oldest brother's wife's father'scar".
The possessive transformation is responsible forconverting such structures into a sort of right branchingmirror image, where extra definite articles are added:der Wagen des Vaters der Frau meines iiltesten Bru-ders.
The definition of possessive, without its condi-tion, is as follows:possessive - -syn(NPLab, PossNP.NC.Mods) - - ->syn(NPLab, Det.NC.PossNP.Mods).The condition (not shown) tests that the components ofthe pattern are what their names suggest, assigns thegenitive case to the possessive noun phrase PossN'P,and creates a definite article Det that agrees with thewhole noun phrase.6 GERMAN MORPHOLOGICAL GENERATIONThe task of this component is to take the output reefrom the syntactic generation component and to pro-duce the character string representing the final Germantranslation.
There are three substeps for accomplishingthis.The first and most substantial step is the applicationof morphological procedures, mainly inflectional, to theindividual nodes of the tree, which are of the formBase+Features, producing another tree whose termi-nals are inflected German words.
The main procedurefor this step, gmorph, takes such a Base+Featuresstructure and produces the required inflected word.
Itaccomplishes this mainly by dispatching the problem tovarious procedures like gverbf (German verb form)49Michael C. McCord \]Design of LMT: A Proiog-Based Machine Translation Systemassociated with different parts of speech, as determinedappropriately from Feat-u.res.
Before calling these pro-cedures, though, graorph performs several "tidying-up" operations, such as simplifying tense and casestructures and handling compound words (through re-cursive calls).Details will not be given here for the inflectionalprocedures for the various parts of speech, but it isworth saying a bit about the noun declension system inLMT, since the most idiosyncratic part of Germaninflectional morphology is the system for nouns.
It wasmentioned in Section 3 that German noun class infor-mation is exhibited along with target nouns in gntransfer elements of the lexicon, in a compact format.The transfer component marks this irfformation in thetransfer tree (see the example tree in Section 4), whereit can be read off by the noun inflection procedures.
Ingeneral, a gn target is of the formNoun.Gender.DeclensionClass.For example, the transfer of brother is bruder.m.b.The declension class is usually specified by a singleletter.
In the case of Bruder, for example, the class bdictates that the plural base is formed by umlauting thenoun, and there is a general rule for finding where toplace the umlaut.
In general, the declension class hasimplicit within it the method of getting the plural base,the combining form (used in forming noun compounds),and the complete declension pattern.
In exampleswhere the plural base or combining form is very irreg-ularly formed, the declension class may be given as aletter together with the required morpheme, as ind~a_m.nt.x.daten.Susanne Wolff has worked out a system of 20 nounclasses under the preceding scheme, together with themorphological rules for getting declensions for eachclass.
There are also some rules that compute thegender/class for nouns with certain common endings, sothat for these nouns the gender/class can be omitted inthe transfer entry.The second substep of German morphological gener-ation is the application of German word list transforma-tions.
The tree output of the first substep (whoseterminals are inflected German words) is converted to alinear list of words by this second substep.
This is donerecursively.
On each level, all the daughter nodes areconverted to word lists and these are concatenated,producing a tentative word list Words for the node.
Butthen an attempt is made to apply a word list transfor-mation to Words, by calling a proceduregphrase(Label,Words,Words 1)where Label is the (principal functor of the) label on thecurrent node.
If this succeeds, the desired word list forthe node is Words1; otherwise it is Words.Currently, g-phrase rules are used mainly for han-dling German contractions.
For example, there is a rulegphrase(pp, an.dem.U, am.U).But these rules can also be used to handle noncompo-sitional translations.
For example, "for example" cantranslate compositionally into far Beispiel, and then ag'phrase rule can convert this to zum Beispiel.
Asmentioned in Section 3, word list transformations canbe specified in the lexicon.
There is a slightly shorterformat (like gph(pp,a~.dsm,am)) which is compiledinto gphrase clauses by the lexical compiler.It seems better on the whole, however, to treatnoncompositional translation by means of multiwordelements in the lexicon, since these involve both sourceand transfer elements.
It is useful to involve sourceelements, because in many cases the source phrase isidiomatic in itself, and the parser is helped by having anEnglish multiword analysis.The last substep, a rather simple one conceptually, isto convert he German word list for the whole sentenceinto a simple character string.
This involves mainly thetreatment of punctuation, blanks, capitalization, andtext formatting symbols.
For a more detailed escrip-tion of German morphological generation, see McCordand Wolff (1988).7 STATUS OF THE SYSTEMLMT handles all of the examples and constructionsgiven above, and many other types of constructions otillustrated for lack of space.
Testing and vocabularydevelopment have been done with the IBM CMS Editor(XED\]T) reference manual, as well as with a collectionof sentences made up by ourselves and others toillustrate key grammatical constructions and problemsof English-German translation.
Every effort has beenmade to keep the rules of the system general.
As withmost MT systems, it is assumed that there will be somepostediting of the output.In a test on a 500-sentence orpus from an initial partof the XEDIT manual, LMT was able to translate 95%of the sentences in an "understandable" 12 way, with anaverage processing time on an IBM 3081 of 364 milli-seconds per sentence (19.5 msec.
per word), usingVM/Prolog as an interpreter.The first few sentences and their LMT translation(with no postediting) are as follows:XEDIT  subcommands and macros follow the samerules and conventions.
For purposes of  this discus-sion, " subcommand" refers to both XEDIT  subcom-mands and XED1T macros.
The general format ofXEDIT subcommands i : (fig.)
At  least one blankmust separate the subcommand name and the oper-ands, unless the operand is a number or a specialcharacter.
For example, NEXT8 and NEXT 8 areequivalent.
At  least one blank must be used toseparate each operand in the command line unlessotherwise indicated.
The maximum length of  anXEDIT  subcommand issued from an EXEC proce-dure or.from an XEDIT  macro is 256 characters.50 Computational Linguistics, Volume 15, Number 1, March 1989Michael C. McCordXEDIT  Unterbefehle und Makros folgen den glei-chen Regeln und Konventionen.
Zum Zweck dieserDiskussion bezieht sich "Unterbefehl" sowohl aufXEDIT  Unterbefehle als auch auf  XEDIT  Makros.Das allgemeine Format von XEDIT  Unterbefehlenist: (fig.)
Mindestens ein Leerzeichen muf  den Un-terbefehls-Namen u d die Operanden abtrennen, essei denn der Operand ist eine Zahl oder ein speziellesZeichen.
Zum Beispiel sind NEXT8 und NEXT 8iiquivalent.
Mindestens ein Leerzeichen muff ver-wendet werden, jeden Operanden in der Befehls-Zeile abzutrennen, wenn nicht anderweitig ange-zeigt.
Die maximale Liinge eines XEDIT  Unterbe-fehls, der von einer EXEC Prozedur oder yon einemXEDIT  Makro ausgegeben wird, ist 256 Zeichen.As for the size of LMT, there are now about 3,500Prolog clauses, not including the lexicon.
This includesthe MLG and DCG grammar rules as clauses, and thereare about 270 of these.
After metarules have operated,the total number of grammar ules is about 450.
Thelexicon currently contains about 1,600 entries; thisincludes most of the vocabulary for the XEDIT Refer-ence Manual.
As mentioned earlier, ModL is interfacedto the UDICT monolingual English lexicon (Byrd 1983,1984), with around 65,000 citation forms.
Also an inter-face of LMT to a lexical data base (Neff, Byrd, Rizk1988) for the Collins English-German Dictionary hasbeen partially developed by Susanne Wolff and theauthor.
Currently, this interface, given an English word,just takes the first German translation provided, foreach part of speech.
For nouns, the required LMTGerman noun classes are obtained from a data baseworked out by Wolff from the inflectional informationon the German-English side of Collins.In recent work (McCord 1988), LMT has been ex-panded to deal with target languages besides German.This expansion has been made easier by the develop-ment of a large subsystem LMTX of LMT which isessentially target language independent and can bethought of as an "English-to-X translation shell."
De-velopment of the shell has involved improvements andgeneralizations in the modules of LMT, but most of themethods and organization are as described in the cur-rent paper.The shell LMTX includes: 1. the English grammarModL; 2. most of the source/transfer morphology sys-tem and lexical processing system; 3. the transferalgorithm and rule system, except for low level, lexicaltransfer entries; 4. the syntactic generation algorithm; 5.target independent procedures dealing with morpholog-ical generation, and 6. many utility procedures.
For agiven target language, the only target specific modulesare a. the source/transfer (unified) lexicon; b. the set oftransformations for syntactic generation, and c. thetarget morphological system.
As an example of the sizeof the shell, for the English-German version of LMT theComputational Linguistics, Volume 15, Number 1, March 1989Design of LMT: A Prolog-Based Machine Translation Systemshell contains approximately 80% of the rules (notcounting the lexicon).Using the shell, prototype versions of LMT havebeen started up for several target languages, in cooper-ation with other groups and individuals: French---incooperation with the KAL IPSOS group of the IBMParis Scientific Center (Fargues et al 1987), with workespecially by Eric Bilange; Danish---with ArendseBernth and in cooperation with IBM European Lan-guage Services; Spanish with Nelson Correa; and Por-tuguese,--with Paula Newman's  group at the IBM LosAngeles Scientific Center.REFERENCESBennett, W. S. and Slocum, J.
1985 "The LRC Machine TranslationSystem," Computational Linguistics 11: 111-121.Bernth, A.
1988 "LODUS--A Logic-oriented Discourse Understand-ing System," Research Report RC 13676, IBM Research Division,Yorktown Heights, NY.Byrd, R. J.
1983 "Word Formation in Natural Language ProcessingSystems," In Proceedings of the 8th International Joint Confer-ence on Artificial Intelligence, Karlsruhe: 704-706.Byrd, R. J.
1984 "The Ultimate Dictionary Users' Guide," IBMResearch Internal Report.Colmerauer, A.
1971 "Les syst6mes-Q: un formalisme pour analyseret synth6tiser des phrases ur ordinateur," Groupe TAUM, Uni-versit6 de Montr6al, Qu6bec, Canada.Colmerauer, A. et al 1971 "TAUM-71," Groupe TAUM, Universit6de Montr6al, Qu6bec, Canada.Colmerauer, A.
1975 "Les grammaires de m6tamorphose," InternalReport, Groupe d'Intelligence Artificielle, Universit6 d'Aix-Mar-seille, France.Colmerauer, A.
1978 "Metamorphosis Grammars," in L. Bolc (ed.
),Natural Language Communication with Computers, Springer-Verlag, Berlin, W. Germany.Dahl, V., and McCord, M. C. 1983 "Treating Coordination i LogicGrammars," American Journal of Computational Linguistics 9:69--91.Dahlgren, K. 1988 Naive Semantics for Natural Language Under-standing, Kluwer Academic Publishers, Norwell, MA.Fargues, J.; B6rard-Dugourd, A.; Landau, M. C.; Nogier, J. F.;Catach, L. 1987 "KALIPSOS Project: Conceptual Semantics andLinguistics," In Proceedings of the Conference on ArtificialIntelligence and Natural Language Technology, IBM EuropeanLanguage Services, Copenhagen, Denmark.Gazdar, G., and Pullum, G. K. 1982 "Generalized Phrase StructureGrammar: A Theoretical Synopsis," Indiana University Linguis-tics Club, Bloomington, IN.Hirschman, L. 1986 "Conjunction in Meta-restriction Grammar,"The Journal of Logic Programming 3: 299-328.Huang, X-M. 1984a "The Generation of Chinese Sentences from theSemantic Representations of English Sentences," In Proceedingsof the International Conference on Machine Translation, Cran-field, England.Huang, X-M. 1984b "Dealing with Conjunctions ina Machine Trans-lation Environment," In Proceedings ofthe Joint Association forComputational Linguistics and Conference on ComputationalLinguistics Meeting 1984: 243-246, Stanford, CA.Huang, X-M 1985 "Machine Translation in SDCG Formalism," inNirenburg (1985, these references):135-144.Hudson, R. A.
1971 English Complex Sentences, North-Holland.lsabeUe, P. and Bourbeau, L. 1985 "TAUM-AVIATION: Its Tech-nical Features and Some Experimental Results," ComputationalLinguistics 11 : 18-27.51Michael C. McCord Design of LMT: A Prolog-Based Machine Translation SystemKittredge, R.; Bourbeau, L.; and Isabelle, P. 1973 "Design andImplementation f a French Transfer Grammar," Conference onComputational Linguistics Meeting 1976, Otl:awa, Canada.McCord, M. C. 1975 "On the Form of a Systemic Grammar," Journalof Linguistics 11: 195-212.McCord, M. C. 1981 "Focalizers, the Scoping Problem, and SemanticInterpretation Rules in Logic Grammars," Technical Report,University of Kentucky, Lexington, KY.
Appeared in Logic Pro-gramming and Its Applications, M. van Caneghem and D. H. D.Warren (Eds.
), Ablex, 1986.McCord, M. C. 1982 "Using Slots and Modifiers in Logic Grammarsfor Natural Language," Artificial Intelligence 18: 327-367.McCord, M. C. 1984 "Semantic Interpretation for the EPISTLESystem," In Proceedings of the Second International LogicProgramming Conference, Uppsala, Sweden: 65-76.McCord, M. C. 1985a "Modular Logic Grammars," In Proceedingsof the 23rd Annual Meeting of the Association for ComputationalLinguistics, Chicago, IL: 104-117.McCord, M. C. 1985b "LMT: A Prolog-hased Machine TranslationSystem" (extended abstract), in Nirenburg (1985, these refer-ences): 179-182.McCord, M. C. 1986 "Design of a Prolog-based Machine TranslationSystem," In Proceedings of the Third International Logic Pro-gramming Conference, Springer-Verlag, Berlin, W. Germany:350-374.McCord, M. C. 1987 "Natural Language Processing in Prolog," inWalker et al (1987, these references).McCord, M. C. 1988 "A Multi-target Machine Translation System,"In Proceedings of the International Conference on Fifth Genera-tion Computer Systems 1988, Tokyo, Japan: 1141-1149.McCord, M. C. and Wolff, S. 1988 "The Lexicon and Morphology forLMT, a Prolog-based MT System," Research Report RC 13403,IBM Research Division, Yorktown Heights, NY.Neff, M. S.; Byrd, R. J.; and Rizk, O.
A.
1988 "Creating andQuerying Lexical Data Bases," In Proceedings of the SecondConference on Applied Natural Language Processing, Austin,TX.Nirenburg, S. 1985, (ed.)
Proceedings of the Conference on Theoret-ical and Methodological Issues in Machine Translation of NaturalLanguages, Colgate University, Hamilton, NY.Pereira, F. C. N. and Shieber, S. M. 1987 Prolog and NaturalLanguage Analysis, CSLI Lecture Notes, no.
10, Menlo Park,CA.Pereira, F. C. N. and Warren, D. H. D. 1980 "Definite ClauseGrammars for Language Analysis--A Survey of the Formalismand a Comparison with Transition Networks," Artificial Intelli-gence 13: 231-278.Sedogbo, C. 1984 "A Meta Grammar for Handling Coordination inLogic Grammars," In Proceedings of the Conference on NaturalLanguage Understanding and Logic Programming, Rennes,France: 137-149.Teeple, D. 1985 "Reasoning in Embedded Contexts," ResearchReport RC 11539, IBM Research Division, Yorktown Heights,NY.Walker, A.
(ed.
); McCord, M.; Sowa, J. F.; and Wilson, W. G. 1987Knowledge Systems and Prolog: A Logical Approach to ExpertSystems and Natural Language Processing, Addison-Wesley,Reading, M.A.Wilks, Y.; Huang, X-M.; and Fass, D. 1985 "Syntax, Preference andRight-Attachment," In Proceedings of the 9th International JointConference on Artificial Intelligence, Los Angeles, CA.Wolff, Susanne 1983 Lexical Entries and Word-Formation, (Ph.D.dissertation}, New York University.NOTES1.
This paper is a revision of a paper (invited presentation) thatappeared in the Proceedings of the Third International LogicProgramming Conference, London, July 1986, published bySpringer-Verlag, Lecture Notes in Computer Science.
The cur-rent version reflects recent improvements in LMT.2.
The description "Logic-programming-based" is slightly moreaccurate.3.
There is an interesting historical connection between machinetranslation and Prolog.
Prior to the development of Prolog, AlainColmerauer worked in the period 1967-70 on a machine transla-tion project, the TAUM project--Traduction Automatique Uni-versit6 de Montr6al (Colmerauer et al 1971, Kittredge, Bout-beau and Isabelle 1973, Isabelle and Bourbeau 1985).
Inconnection with this project, Colmerauer developed a grammarlanguage, Q-systems (Colmerauer 1971), which had some of thefeatures of logic grammars and Prolog.
In his subsequent workon the development of Prolog, natural language applicationsformed a major motivation for Colmerauer.4.
In earlier work on MLGs, only the first argument of a strongnonterminal was used as a feature argument, so that the /kspecification was not used in strong nonterminal declarations.5.
Currently, there is only one occurrence of this device in ModL,which could be probably be avoided without oo much trouble.6.
The ordering of parses is significant in ModL.
Normally trans-lation is done only for the first parse obtained.7.
Markers are logical variables together with semantic and syntac-tic feature information.
The exact format used currently inModL is described at the end of this subsection.8.
As described in the next section, the lexical preprocessor canoptionally make this verb sense argument simply Y or make itthe whole term ?
:Sense:Syr~eas, depending on the applicationof ModL.9.
For more details, see McCord and Wolff (1988).10.
External forms for transfer elements are discussed below.II.
The symbols l and h attached to the nouns are their declensionclasses.
More details are given in Section 6.12.
This means that a native German speaker can read the transla-tion (without seeing the source) and understand it in the samesense as the source.52 Computational Linguistics, Volume 15, Number 1, March 1989
