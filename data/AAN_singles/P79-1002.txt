TOWARDS A SELF-EXTENDING PARSERJaime G. CarbonellDepartment Of Computer ScienceCarnegie-Mellon UniversityPittsburgh, PA 15213Abst rac tThis paper discusses an approach to incrementallearning in natural language processing.
Thetechnique of projecting and integrating semanticconstraints to learn word definitions is analyzedas Implemented in the POLITICS system.Extensions and improvements of this techniqueare developed.
The problem of generalizingex ist ing word meanings and understandingmetaphorical uses of words Is addressed In termsof semantic constraint Integration.1.
In t roduct ionNatural language analysis, like most other subfields ofArtif icial  Intell igence and Computational Linguistics, suffersfrom the fact  that computer systems are unable toautomatical ly  better  themselves.
Automated learning iacons idered a very  difficult problem, especially when appliedto  natural language understanding.
Consequently, little effortha8 been focused on this problem.
Some pioneering work inArtif icial intell igence, such as AM \ [ I \ ]  and Winston's learningsystem 1"2\] strove to learn or discover concept descriptionsin wel l -def ined domains.
Although their efforts producedinterest ing Ideas and techniques, these techniques do notful ly extend  to ?
domain as complex as natural languageanalysis.Rather than attempting the formidable task of creating alanguage learning system, I will discuss techniques forIncremental ly Increasing the abilities of a flexible languageanalyzer.
There are many tasks that can be considered" Incremental  language learning".
Initially the learning domainIs rest r ic ted to learning the meaning of new words andgeneral iz ing exist ing word definitions.
There ere a number ofA.I.
techniques, and combinations of these techniquescapable  of exhibit ing incremental learning behavior.
I firstd iscuss FOULUP and POLITICS, two programs that exhibit al imited capabi l i ty for Incremental word learning.
Secondly, thetechnique of semantic constraint projection end Integration,as Implemented in POLITICS, Is analyzed in some detail.Finally, I discuss the application of some general learningtechniques to the problem of generalizing word definitionsend understanding metaphors.2 .
Learn ing  From Scr ipt  Expectat ionsLearning word definitions In semantically-rich contexts Isperhaps one of the simpler tasks of incremental learning.Initially I confine my discussion to situations where themeaning of a word can be learned from the Immediatelysurrounding context .
Later I relax this criterion to see howglobal context  and multiple examples can help to learn themeaning of unknown words.The FOULUP program \ [3 \ ]  learned the meaning of someunknown words in the context  of applying s script tounderstand a story.
Scripts \[4, 5\] are frame-like knowledgerepresentat ions abstracting the important features andcausal  structure of mundane events.
Scripts have generalexpectat ions  of the actions and objects that will beencountered in processing a story.
For Instance, therestaurant  script expects  to see menus, waitresses, andcustomers ordering and eating food (at differentp re -spec i f led  times In the story).FOULUP took advantage of these script expectations toconclude that Items referenced in the story, which were partof expected  actions, were Indeed names of objects that thescr ipt  expected  to see.
These expectations were used toform definit ions of new words.
For instance, FOULUP inducedthe meaning of "Rabbit" in, "A Rabbit veered off the roadand struck a tree,"  to be a self-propelled vehicle.
Thesystem used information about the automobile accident scriptto  match the unknown word with the script-role "VEHICLE",because  the script knows that the only objects that veer offroads to smash Into road-side obstructions ere self propelledvehic les .3 .
Const ra in t  P ro jec t ion  In POLITICSThe POLITICS system E6, 7\] induces the meanings ofunknown words by a one*pass syntactic and semanticconstraint  projection followed by conceptual enrichment fromplanning and world-knowledge inferences.
Consider howPOLITICS proceeds when It encounters the unknown word"MPLA" In analyzing the sentence:"Russia sent massive arms shipments to the MPLA In Angola.
"Since "MPLA" follows the article '*the N it must be a noun,ad jec t ive  or adverb.
After the word "MPLA", the preposition" in"  Is encountered, thus terminating the currentpreposit ional  phrase begun with "to".
Hence, since allwel l - formed prepositional phrases require a head noun, andthe " to"  phrase has no other noun, "MPLA" must be the headnoun.
Thus, by projecting the syntactic constraintsnecessary  for the sentence to be well formed, one learn8the syntact ic  category of an unknown word.
it Is not alwayspossible to narrow the categorization of a word to a singlesyntact i c  category  from one example.
In such cases, Ipropose Intersecting the sets of possible syntacticcategor ies  from more then one sample use of the unknownword until the Intersection has a single element.POLITICS learns the meaning of the unknown word by asimilar, but substantial ly more complex, application of thesame principle of projecting constraints from other parts ofthe sentence  and subsequently Integrating these constraintsto  oonetruot a meaning representation.
In the exampleabove,  POLITICS analyzes the verb "to send" as either inATRANS or s PTRAflS.
(Schank \ [8 \ ]  discusses the ConceptualDependency case frames.
Briefly, a PTRANS IS s physicalt ransfer  of location, and an ATRANS Is an abstract transferof  ownership, possession or control.)
The reason whyPOLITICS cannot decide on the type of TRANSfer is that itdoes not know whether the destination of the transfer (i.e.,the  MPLA) Is s location or an agent.
Physical objects, suchas weapons,  are PTRANSed to locations but ATRANSed toagents .
The conceptual analysis of the sentence, with MPLAas yet  unresolved, Is diagrammed below:*SUSSIA* <-~ \ [C IPS l  < is> LOC v i i  ~qNGOLAetlmlq.R)RTRRNS ?
d IN, iq\[CIPillI IN< ,,ffi/$SIRi,IJ~ERPONe <ls~ NWISER vii (, llOMI)What has the analyzer learned about "MPLA" as s result offormulating the CD case frame?
Clearly the MPLA can only bean actor  (I.e., s person, an Institution or s political entity inthe  POLITICS domain) or s location.
Anything else wouldv io la te  the constraints for the recipient case In both ATRANSend PTRANS.
Furthermore, the analyzer knows that thelocat ion of the MPLA Is Inside Angola.
This Item of Informationis in tegrated with the case constraints to form a partialdef init ion of "MPLA".
Unfortunately both Iocatlcms and actorscan be located inside countries; thus, the identity of theMPLA is still not uniquely resolved.
POLITICS assigns thename RECIP01 to the partial definition of "MPLA" andproceeds  to apply Its Inference rules tO understand thepol i t ical  Implications of the event.
Here I discuss only theInferences re levant  for further specifying the meaning of-MPLA m .4 .
Uncer ta in  In ference in LearningPOLITICS Is a goal-driven tnferencer.
It must explain ellact ions In terms of the goals of the actors and recipients.The emphasis on inducing the goals of actors and relatingthei r  actions to means of achieving these goals is Integral tothe  theory  of subject ive understanding embodied inPOLITICS.
(See \ [7 \ ]  for a detailed discussion.)
Thus, POLITICSt r ies  to determine how the action of sending weapons can bere la ted  to the goals of the Soviet Union or any other possibleactors  involved in the situation.
POLITICS k~s  that Angolawas  Jn a s ta te  of civto war; that Is, a state where politicalfact ions were  .
'xerclstng their goals of taking military and,therefore ,  political control of a country.
Since po6ssssingweapons  Is a precondition to military actions, POLITICS infersthat  the recipient of the weapons may have been one of thepoliUcal factions.
(Weapons ere s means to fulfUllng the goalof  ?
polit ical faction, therefore POLITICS Is able to explainwhy  the faction wants to receive weapons.)
Thus, MPLA IsInferred to be a political faction.
This Inference is Integratedwith the exist ing partial definition and found to beconsistent.
Finally, the original action Is refined to be anATRANS, as transfer of possession of the weapons (notmere ly  their k:mation) helps the political faction to achieveIts mil itary goal.Next ,  POLITICS tries to determine how sending weapons to smil itary fact ion can further the goals of the Soviet Union.Communist countries have the goal of spreading their 'Ideology.
POLITICS concludes that this goal can be fulfilledonly if the government of Angola becomes communist.
Militaryaid to s political faction has the standard goal of militarytakeover  of the government.
Putting these two factstogether ,  POLITICS concludes that the Russian goal can befulf i l led if the MPLA, which may become the new Angelesgovernment,  is Communist.
The definition formed for MPLA Isae fol lows:QI~'I i~a1"~ tntrvI(OPS flPLA (POS NOUN (TYPE PROgI\[R)))(TOK efllq.A.)
)(PARTOF.
luRN6OLR.
)(|oEOLOGY .
~?OiltlUN|STe)(GORLSt ((ACTOR (*flPLA*) iS(SCONT O?JI\[CT (dN6OLRe)Vm.
(IR)))))PThe reason why memory entries are distinct from dictionarydef init ions is that  there is no one-to-one mapping betweenthe  two.
For Instance, "Russia" and "Soviet Union" are twoseparate  dict ionary entries that refer to the same concept inmemory.
Similarly, the concept of SCONT (social or politicalcontrol )  abstracts Information useful for the goal-driveninferences,  but has no corresponding entry in the lexicon, asI found no example where such concept was explicit lyment ioned In newspaper headlines of political conflicts (i.e.,POLITICS' domain).Some of the Inferences that POLITICS made are much moreprone to error than others.
More specifically, the syntacticconstra int  projections and the CD case-frame projectionsere quite certain, but the goal-driven Inferences are onlyreasonable  guesses.
For Instance, the MPLA coWd have been?
p lateau where Russia dePosited Its weapons for laterde l ivery .5 .
A S t ra tegy  fo r  Deal ing w i th  Uncerta intyGiven such possibilities for error, two possible strategies todeei  with the problem of uncertain inference come to mind.First, the system could be restricted to making only the morecerta in constraint projection and integration inferences.
Thisdoes not usually produce s complete definition, but theprocess may be Iterated for other exemplars where theunknown word Is used in different semantic contexts.
Eacht ime the new word Is encountered, the semantic constraintsare  integrated with the previous partial definition until acomplete  definition is formulated.
The problem with thisprocess Is that it may require a substantial number ofi terat ions to converge upon s meaning representation, endwhen it eventual ly  does, this representation wtll not be asrich as the representation resulting from the less certaingoal -dr iven inferences.
For Instance, it would be impossibleto conclude that the MPLA was Communist and wanted totake  over  Angola only by projecting semantic constraints.The second method is based on the system's ability torecover  from inaccurate inferences.
This is the method iimplemented in POLITICS.
The first step requires thedeteot lon  of contradictions between the Inferred Informationend new Incoming information.
The next  step is to assignblame to the appropriate culprit, i.e., the inference rule thatasser ted  the incorrect conclusion.
Subsequently, the systemmust de lete  the inaccurate assertion and later inferencesthat  depended upon it.
(See \ [9\ ]  for a model of truthmaintenance.)
The final step is to use the new information tocor rec t  the memory entry.
The optimal system within myparadigm would use a combination of both strategies - Itwould use Its maximal Inference capability, recover whenInconsistencies arise, and iterate over many exemplars toref ine and confirm the meaning of the new word.
The firsttwo  cr iter ia are present in the POLITICS implementation, butthe system sto~s building a new definition after processing asingle exemplar unless it detects a contradiction.Let  us brief ly trace through an example where PC~.ITICS latold that the MPLA is indeed a pisteau after it inferred themeaning to be a political faction.I POLITICS Pun - -  2/06/76 !?
: INTERPRET US-CONSERVRT IVE)INPUT STORY, Russia sent massive arms ship.eatsto the flPL.A in Re,gels.PARSING... (UNKNOUN UOROI MPLA):SYNTACTIC EXPECTATION!
NOUN)(SERRNTIC EXPECTATION; (FRANC: (ATRONS PTRONS) SLOTI RECIPREQ, ILOC ROTOR))) COflPLETEO.CREATING N( u MEMORY ENTRY, *flPLRoINFERENCE, ~,MPLRo MIAY BE A POLXTICI:n. FACTION OF mARGOt.fiG|NFEfl(NCE, eflUSSIAe RTRRNS eRRMSo TO tAPLRoINFERENCE; *MPLAe IS PNOOROLY aCOflMUNXSTeINFERENCE, GOAL OF aMPLRa IS TO TAK( OVEN eANOOl.AeINSTANTIATING SCAIPTJ SRIONFINFERENCE; GOAL OF eRUSSIAa I$ toNGOLflo TO BE ?comflNl|$TeI Question-salem- dialog )441hst does the MPLA ~ent the arms foP?TNE RPLR MANTa TO TAKE OVER RNGOLR USING THE NEIMONS.I~he( might the ether factionS in An(iolll de?THE OTHER FACTIONS NAY ASK SORE OTHER COUNTRY FOR RRflS.| Reading furthcP Input \]INPUT STORY; +The Zunqabl faction oleoPatlng fPoe the I~PLAplateau received the $ovist uealNme.PARS |NO... CONPLETEO ?GREAT|NO NEW N(NORY ENTRY: aZUNGRO|aACTIVE CONTEXT RPPLJCRItLE, ~IONFC1 ISR CONFLICT, eMPLRe ISR (eFRCTIONo sPI.RTERUe)(ACTIVATE' (|NFCN(CK C|)) R(OUEST(OC2 SCRIPT ROLE CONFLICT,(&R\[O-RECXP |N SRIOMF) ?
aMPLRe RNO aZUNGABIe(ACTIVATE (INFCHECK C2)) RE~JEST\[O(INFCHECK C1 C2) INVOKEOtRTTERPT TO MERGE MEMORY ENTRIES, (*M~.Ae aZON~Ia)...FAIUJRE'INFER(lICE RULE CHECK(O (RULEJFI .
SRIOMF)...OKINFERENCE RUt.E CHECKED (flULEIGO)...CONFLICT!OELETING RESULT OF RULE/GOC2 RESOt.VEDt ~f'~'LRe \]SA *PLRTEIqJe IN eRNGOLRsC2 flESOLVEO; UlAI?-RECIP IN SRIOMF) ?
eZONGROIoREDEFINING enPLRe AS eZUNGRe|O...COMPI.IrTEO.CREATING HEM orlPLRo fl(NORY (NTNY...CORPLET(O.POLITICS realizes that there is an Inconsistency In ItsInterpretat ion when It tries to integrate "the MPLA plateau"with its previous definition of "MPLA".
Political factions andp lateaus ere different conceptual classes.
Furthermore, thenew Input states that the Zungsbl received the weapons,not the MPLA.
Assuming that the Input Its correct, POLITICSsearches for an Inference rule to assign blame for thepresent  contradiction.
This Is done simply by temporarilydelet ing the result of each inference rule that was activatedin the original interpretation until the contradiction no longerex i s ts .
The rule that concluded that the MPLA was a politicalfact ion Is found to resolve both contradictions If deleted.Since recipients of military aid must be political entitles, theMPLA being s geographical location no longer qualifies as amil itary aid recipient.Finally, POLITICS must check whether the inference rulesthat  depended upon the result of the deleted rule are nolonger applicable.
Rules, such as the one that concluded thatthe polit ical faction was communist, depended upon therebeing a political faction receiving military aid from Russia.The Zungabi now fulfll:s this role; therefore, the inferencesabout the MPLA are transfered to the Zungabl, and th~ MPLAIs redef ined to be a plateau.
(Note: the word "Zungabl" wasconst ructed  for this example.
The MPLA is the present rulingbody  of Angola.
)6 .
Ex tend ing  the P ro jec t  and Integrate MethodThe POL)TICS Implementation of the project-and-integratetechnique ts by no means complete.
POLITICS can onlyInduce the meaning of concrete or proper nouns when thereIs suff ic ient  contextual  information In a single exemplar.Furthermore, POLITICS assumes that each unknown word willhave only one meaning.
In general It is useful to realize whena word Is used to mean something other than Its definition,and subsequent ly formulate an alternative definition.I I l lustrate the case where many examples are required tonarrow down the meaning of s word with the followingexample:  "Johnny told Mary that If she didn't give him thetoy,  he would <unknown-word) her."
One can induce that theunknown word Is a verb, but its meaning can only be guessedat, In general terms, to be something unfavorable to Mary.For Instance, the unknown word could mean "take the objectfrom", or "cause injury to".
One needs more then oneexample  of the unknown word used to mean the same thingIn d i f ferent  contexts .
Then one has s much richer, combinedcontext  from which the meaning can be projected withgreater  precision.Figure 1 diagrams the general project-and-integratealgorithm.
This extended version of POLITICS' word-learningtechnique addresses the problems of iterating over manyexamples,  multiple word definitions, and does not restrict itsInput to certain classes of nouns.7 .
Genera l i z ing  Word  Def init ions.Words can have many senses, some more n"neral thanothers.
Let us look at the problem of gen lizlng thesemantic definition of a word.
Consider the case where"barr ier"  is defined to be a physical object that dlsenables at ransfer  of location.
(e.g.
"The barrier on the road Is blockingmy way . "
)  Now, let us interpret the sentence, "Import quotasform a barrier to International trade."
Clearly, an Import quotaIs not ?
physical object.
Thus, one can minimally generalize"barr ier"  to mean "anything that disc.shies s physicalt rans fer  of location.
"Let  us subst i tute "tar i f f"  for "quota" In our example.
Thissuggests  that our meaning for "barrier" is insufficientlygeneral .
A tariff  cannot disensble physical transfer; tariffsdime.able will ingness to buy or sell goods.
Thus, one canfurther general ize the meaning of barrier to be: "anythingthat  dlaenablee any type of transfer", Yet, Urea trace of theF Ight  1: The prijeat-a.d-lntsgPete Nthedfar Indu@l~ Re.
ueP4 and :oe~ept detlnitlemlcontalnl .
|  ?hiURK~O~ ?lardPROJECTthe s~ntaetie Imdsemantic ?onstrai.tl!fPoa eft Imelvslt ofthe other eowDonints\]N~qRTE?
1!
Oh?
?onttrilntltQ tM, imlite ?
wddeflflltl(mINTEGRRTE91ob?l Cento?t to(mrlch 4QtlnitiqmI COn?cut"airOlealmPseaedelpJml goil,.dPiwmInt.fqm~teNOemcm~ in t M, Imee~.u?Ing a I ?eet-q:m" ?also-!
IP?|NO \[111101Postul?te ?
mm.erd same amlbuild a I terlqltedefif l it ie~Delete culpellIn f ?
r~e  mid ~.
Jgeneral izat ion process must be remembered because theoriginal meaning is often preferred, or metaphoricallyre ferenced.
Consider: "The trade barriers were lifted.
?
and"The new legislation bulldozed existing trade barriers.
?rheas  sentences can only be understood metaphorically.rhat is, one needs to refer to the original meaning of~barrier" as a physical object, In order for ?l ifting" or'bulldozing" to make sense.
After understanding the literalleaning of a "bulldozed barrier", the next step Is to inferhe consequence of such aft action, namely, the barrier no)nger exists .
Finally, one can refer to the generalizedleaning of "barrier" to interpret the proPoaltion that ?Theew legislation caused the trade barriers to be no longer Inx ie tence .
"propose the *ollowing rules to generalize word definitionsld understand metaphorical references to their ortglnol,mmel definition:1 ) If the definition of a word violates the semanticconstraints projected from an interpretation of therest  of the sentence, create a new word-sensedefinit ion that copies the old deflnltiml minimallyrelaxing (I.e., generalizing) the violated constraint.2) In Interpreting new sentences always preferthe mast specific definition if applicable.3) If the generalized definition Is encounteredagain in Interpreting text ,  make It part of thepermanent dictionary.4) If ?
word definition requires furthergeneralization, choose the existing most generaldefinit ion and minimally relax Its violated semanticconstraints until a new, yet  more general definitionIs formed.5) If the case frame formulated in interpreting asentence  projects more specific semanticconstraints onto the word meaning than thoseconsistent  with rite entire sentence, Interpret theword usln(!
the most specific definition conslste.twith the case frame.
If the resultant meaning ofthe case frame Is inconsistent with theinterpretat ion of the whole sentence, Infer themost l ikely consequence of the pMtlally-buildConceptual Dependency case frame, and use thisconsequence In Interpreting the rest of thesentence.The process described by rule 5 enables one to Interpret themetaphorical  uses of words like "l i fted" and "bulldozed" Inour ear l ier  examples.
The literal meaning of each word i8appl ied to the ob ject  case, (i.e., "barrier?
), and the Inferredconsequence (i.e., destruction of the barrier) i8 used toInterpret  the full sentence.8 .
Cora l .
c l ing  RemarksThere are a multitude of ways to incrementally Improve thelanguage understanding capabilities of a system.
In thispaper  I discussed in some detail the process of learning neww~rde.
In lesser detail  I presented some ideas on how togeneral ize word meanings and Interpret metaphorical uses ofindividual words.
There are many more aspects to learninglanguage and understanding metaphors that I have nottouched upon, For Instance, many metaphors transcendIndividual words and phrases.
Their Interpretation mayrequire detai led cultural knowledge \ [10\] .In order  to place some perspective on project-and-integratelearning method, consider throe general learning mechanismscapable  of implementing different aspects of Incrementallanguage learning.Learn ing hy example.
This Is perhaps the mostgeneral  learning strategy.
From several exemplars,one can intersect the common concept by, Ifnecessary,  minimally generalizing the meaning ofthe known part of each example until a commonaubpart  Is found by Intersection.
This commoneubpart Is l ikely to be the meaning of the unknownsect ion of each exemplar.Learn ing by near-miss analysis.
Winston \ [2 \ ]takes  full advantage of this technique, it may beuseful ly applied to a natural language system thatcan Interact lveiy generate utterances using thewords it learned, and later be told whether It usedthose words correctly, whether It erred seriously,or whether  It came close but failed to understanda subtle nuance In meaning.Learn ing  by contextua l  expectat ion.
EasanUallyFOULUP and POLITICS use the method ofproject ing contextual  expectations to thel inguistic element whose meaning Is to be Induced.Much more mileage can be gotten from thismethod, especially If one uses strong syntacticconstraints and expectations from otherknowledge sources, such as s discourse model, snarrat ive model, knowledge about who is providingthe information, and why the information Is beingprovided.9 .
ReferencesT.2.3.4.5.6.7.8.9.TO.Lenet, 0.
AMz Discovery In Mathematics asHeuristic Search.
Ph.D.
Th., Stanford University,1977.Winston, P. Learning Structural Descriptions fromExamples.
Ph.D.
Th., MIT, 1970.Granger, R. FOUL-UPt A Program that Figures OutMeanings of Worcls from Context.
IJCAI-77, 1977.Schank, R. C. and Abelson, R.P.
Scripts, Goals,Plans and Unclerstancling.
Hillside, NJ: LawrenceErlbaum, 1977.Cullingford, R. Script Appllcationt ComputerUncleratandlng of Newspaper Stories.
Ph.D. Th.,Yale University, 1977.Carbonell, J.G.
POLITICS: Automated IdeologicalReasoning.
Cognitive Science 2, 1 (1978), 27-51.Carbonell, J .G.
Subjective Unclerstancllng:Computer Mo<lels of Belief Systems.. Ph.D.
Th., YaleUniversity, 1979.Sohsnk, R.C.
Conceptual Information Processing.Amsterdam: North-Holland, 1975.Doyle, J.
Truth Malntenanoe Systems for ProblemSolving.
Master Th., M.I.T., 1978.Lakoff, G. and Johnson, M. Towards anExperimentalist Philosopher: The Case From LiteralMetaphor.
In preparation for publication, 1979.
