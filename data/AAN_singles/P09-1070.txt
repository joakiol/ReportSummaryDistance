Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 620?628,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPLatent Variable Models of Concept-Attribute AttachmentJoseph Reisinger?Department of Computer SciencesThe University of Texas at AustinAustin, Texas 78712joeraii@cs.utexas.eduMarius Pas?caGoogle Inc.1600 Amphitheatre ParkwayMountain View, California 94043mars@google.comAbstractThis paper presents a set of Bayesianmethods for automatically extending theWORDNET ontology with new conceptsand annotating existing concepts withgeneric property fields, or attributes.
Webase our approach on Latent Dirichlet Al-location and evaluate along two dimen-sions: (1) the precision of the rankedlists of attributes, and (2) the quality ofthe attribute assignments to WORDNETconcepts.
In all cases we find that theprincipled LDA-based approaches outper-form previously proposed heuristic meth-ods, greatly improving the specificity ofattributes at each concept.1 IntroductionWe present a Bayesian approach for simultane-ously extending Is-A hierarchies such as thosefound in WORDNET (WN) (Fellbaum, 1998) withadditional concepts, and annotating the resultingconcept graph with attributes, i.e., generic prop-erty fields shared by instances of that concept.
Ex-amples of attributes include ?height?
and ?eye-color?
for the concept Person or ?gdp?
and ?pres-ident?
for Country.
Identifying and extractingsuch attributes relative to a set of flat (i.e., non-hierarchically organized) labeled classes of in-stances has been extensively studied, using a vari-ety of data, e.g., Web search query logs (Pas?ca andVan Durme, 2008), Web documents (Yoshinagaand Torisawa, 2007), and Wikipedia (Suchanek etal., 2007; Wu and Weld, 2008).Building on the current state of the art in at-tribute extraction, we propose a model-based ap-proach for mapping flat sets of attributes anno-tated with class labels into an existing ontology.This inference problem is divided into two maincomponents: (1) identifying the appropriate par-ent concept for each labeled class and (2) learning?Contributions made during an internship at Google.the correct level of abstraction for each attribute inthe extended ontology.
For example, consider thetask of annotating WN with the labeled class re-naissance painters containing the class instancesPisanello, Hieronymus Bosch, and Jan van Eyckand associated with the attributes ?famous works?and ?style.?
Since there is no WN concept forrenaissance painters, the latter would need to bemapped into WN under, e.g., Painter.
Further-more, since ?famous works?
and ?style?
are notspecific to renaissance painters (or even the WNconcept Painter), they should be placed at themost appropriate level of abstraction, e.g., Artist.In this paper, we show that both of these goalscan be realized jointly using a probabilistic topicmodel, namely hierarchical Latent Dirichlet Allo-cation (LDA) (Blei et al, 2003b).There are three main advantages to using a topicmodel as the annotation procedure: (1) Unlike hi-erarchical clustering (Duda et al, 2000), the at-tribute distribution at a concept node is not com-posed of the distributions of its children; attributesfound specific to the concept Painter would notneed to appear in the distribution of attributes forPerson, making the internal distributions at eachconcept more meaningful as attributes specific tothat concept; (2) Since LDA is fully Bayesian, itsmodel semantics allow additional prior informa-tion to be included, unlike standard models such asLatent Semantic Analysis (Hofmann, 1999), im-proving annotation precision; (3) Attributes withmultiple related meanings (i.e., polysemous at-tributes) are modeled implicitly: if an attribute(e.g., ?style?)
occurs in two separate input classes(e.g., poets and car models), then that attributemight attach at two different concepts in the ontol-ogy, which is better than attaching it at their mostspecific common ancestor (Whole) if that ancestoris too general to be useful.
However, there is alsoa pressure for these two occurrences to attach to asingle concept.We use WORDNET 3.0 as the specific test on-tology for our annotation procedure, and evalu-620anticancer drugs: mechanism of action, uses, extrava-sation, solubility, contraindications, side effects, chem-istry, molecular weight, history, mode of actionbollywood actors: biography, filmography, age, bio-data, height, profile, autobiography, new wallpapers, lat-est photos, family picturescitrus fruits: nutrition, health benefits, nutritional value,nutritional information, calories, nutrition facts, historyeuropean countries: population, flag, climate, presi-dent, economy, geography, currency, population density,topography, vegetation, religion, natural resourceslondon boroughs: population, taxis, local newspapers,mp, lb, street map, renault connexions, local historymicroorganisms: cell structure, taxonomy, life cycle,reproduction, colony morphology, scientific name, vir-ulence factors, gram stain, clipartrenaissance painters: early life, bibliography, short bi-ography, the david, bio, painting, techniques, homosexu-ality, birthplace, anatomical drawings, famous paintingsFigure 1: Examples of labeled attribute sets ex-tracted using the method from (Pas?ca and VanDurme, 2008).ate three variants: (1) a fixed structure approachwhere each flat class is attached to WN usinga simple string-matching heuristic, and conceptnodes are annotated using LDA, (2) an extensionof LDA allowing for sense selection in addition toannotation, and (3) an approach employing a non-parametric prior over tree structures capable of in-ferring arbitrary ontologies.The remainder of this paper is organized as fol-lows: ?2 describes the full ontology annotationframework, ?3 introduces the LDA-based topicmodels, ?4 gives the experimental setup, ?5 givesresults, ?6 gives related work and ?7 concludes.2 Ontology AnnotationInput to our ontology annotation procedure con-sists of sets of class instances (e.g., Pisanello,Hieronymus Bosch) associated with class labels(e.g., renaissance painters) and attributes (e.g.,?birthplace?, ?famous works?, ?style?
and ?earlylife?).
Clusters of noun phrases (instances) areconstructed using distributional similarity (Linand Pantel, 2002; Hearst, 1992) and are labeledby applying ?such-as?
surface patterns to raw Webtext (e.g., ?renaissance painters such as Hierony-mous Bosch?
), yielding 870K instances in morethan 4500 classes (Pas?ca and Van Durme, 2008).Attributes for each flat labeled class are ex-tracted from anonymized Web search querylogs using the minimally supervised procedurein (Pas?ca, 2008)1.
Candidate attributes are rankedbased on their weighted Jaccard similarity to aset of 5 manually provided seed attributes for the1Similar query data, including query strings and fre-quency counts, is available from, e.g., (Gao et al, 2007)LDA??z?DTw??
?z?DTw?cFixed Structure LDA?
?z?D?w?Tc?nCRPTwwwFigure 2: Graphical models for the LDA variants;shaded nodes indicate observed quantities.class european countries.
Figure 1 illustrates sev-eral such labeled attribute sets (the underlying in-stances are not depicted).
Naturally, the attributesextracted are not perfect, e.g., ?lb?
and ?renaultconnexions?
as attributes for london boroughs.We propose a set of Bayesian generative modelsbased on LDA that take as input labeled attributesets generated using an extraction procedure suchas the above and organize the attributes in WN ac-cording to their level of generality.
AnnotatingWN with attributes proceeds in three steps: (1)attaching labeled attribute sets to leaf concepts inWN using string distance, (2) inferring an attributemodel using one of the LDA variants discussed in?
3, and (3) generating ranked lists of attributes foreach concept using the model probabilities (?
4.3).3 Hierarchical Topic Models3.1 Latent Dirichlet AllocationThe underlying mechanism for our annotationprocedure is LDA (Blei et al, 2003b), a fullyBayesian extension of probabilistic Latent Seman-tic Analysis (Hofmann, 1999).
Given D labeledattribute sets wd, d ?
D, LDA infers an unstruc-tured set of T latent annotated concepts overwhich attribute sets decompose as mixtures.2 Thelatent annotated concepts represent semanticallycoherent groups of attributes expressed in the data,as shown in Example 1.The generative model for LDA is given by?d|?
?
Dir(?
), d ?
1 .
.
.
D?t|?
?
Dir(?
), t ?
1 .
.
.
Tzi,d|?d ?
Mult(?d), i ?
1 .
.
.
|wd|wi,d|?zi,d ?
Mult(?zi,d), i ?
1 .
.
.
|wd|(1)where ?
and ?
are hyperparameters smoothingthe per-attribute set distribution over concepts andper-concept attribute distribution respectively (seeFigure 2 for the graphical model).
We are inter-ested in the case where w is known and we want2In topic modeling literature, attributes are words and at-tribute sets are documents.621to compute the conditional posterior of the remain-ing random variables p(z,?,?|w).
This distribu-tion can be approximated efficiently using Gibbssampling.
See (Blei et al, 2003b) and (Griffithsand Steyvers, 2002) for more details.
(Example 1) Given 26 labeled attribute sets falling intothree broad semantic categories: philosophers, writersand actors (e.g., sets for contemporary philosophers,women writers, bollywood actors), LDA is able to infera meaningful set of latent annotated concepts:quotationsteachingsvirtue ethicsphilosophiesbiographysayingsnew moviesfilmographyofficial websitebiographyemail addressautobiographywriting styleinfluencesachievementsbibliographyfamily treeshort biography(philosopher) (writer) (actor)(concept labels manually added for the latent annotatedconcepts are shown in parentheses).
Note that with a flatconcept structure, attributes can only be separated intobroad clusters, so the generality/specificity of attributescannot be inferred.
Parameters were ?=1, ?=0.1, T=3.3.2 Fixed-Structure LDAIn this paper, we extend LDA to model structuraldependencies between latent annotated concepts(cf.
(Li and McCallum, 2006; Sivic et al, 2008));In particular, we fix the concept structure to cor-respond to the WN Is-A hierarchy.
Each labeledattribute set is assigned to a leaf concept in WNbased on the edit distance between the concept la-bel and the attribute set label.
Possible latent con-cepts for this set include the concepts along allpaths from its attachment point to the WN root,following Is-A relation edges.
Therefore, any twolabeled attribute sets share a number of latent con-cepts based on their similarity in WN: all labeledattribute sets share at least the root concept, andmay share more concepts depending on their mostspecific, common ancestor.
Under such a model,more general attributes naturally attach to latentconcept nodes closer to the root, and more specificattributes attach lower (Example 2).Formally, we introduce into LDA an extra set ofrandom variables cd identifying the subset of con-cepts in T available to attribute set d, as shownin the diagram at the middle of Figure 2.3 Forexample, with a tree structure, cd would be con-strained to correspond to the concept nodes in Ton the path from the root to the leaf containing d.Equation 1 can be adapted to this case if the in-dex t is taken to range over concepts applicable toattribute set d.3Abusing notation, we use T to refer to a structured set ofconcepts and to refer to the number of concepts in flat LDA(Example 2 ) Fixing the latent concept structure to cor-respond to WN (dark/purple nodes), and attaching eachlabeled attribute set (examples depicted by light/orangenodes) yields the annotated hierarchy:workspicturewritingshistorybiographyphilosophynatural rightscriticismethicslawliterary criticismbooksessaysshort storiesnovelstattoosfuneralfilmographybiographiesnet worthpersonphilosopher writer actorscholarintellectualperformerentertainerliteratecommunicatorbollywoodactorswomenwriterscontemporaryphilosophersAttribute distributions for the small nodes are not shown.Dotted lines indicate multiple paths from the root, whichcan be inferred using sense selection.
Unlike with the flatannotated concept structure, with a hierarchical conceptstructure, attributes can be separated by their generality.Parameters were set at ?=1 and ?=0.1.3.3 Sense-Selective LDAFor each labeled attribute set, determining the ap-propriate parent concept in WN is difficult since asingle class label may be found in many differentsynsets (for example, the class bollywood actorsmight attach to the ?thespian?
sense of Actor orthe ?doer?
sense).
Fixed-hierarchy LDA can beextended to perform automatic sense selection byplacing a distribution over the leaf concepts c, de-scribing the prior probability of each possible paththrough the concept tree.
For WN, this amountsto fixing the set of concepts to which a labeled at-tribute set can attach (e.g., restricting it to a seman-tically similar subset) and assigning a probabilityto each concept (e.g., using the relative WN con-cept frequencies).
The probability for each senseattachment cd becomesp(cd|w, c?d, z) ?
p(wd|c,w?d, z)p(cd|c?d),i.e., the complete conditionals for sense selection.p(cd|c?d) is the conditional probability for attach-ing attribute set d at cd (e.g., simply the priorp(cd|c?d)def= p(cd) in the WN case).
A closedform expression for p(wd|c,w?d, z) is derivedin (Blei et al, 2003a).3.4 Nested Chinese Restaurant ProcessIn the final model, shown in the diagram on theright side of Figure 2, LDA is extended hierarchi-cally to infer arbitrary fixed-depth tree structures622from data.
Unlike the fixed-structure and sense-selective approaches which use the WN hierarchydirectly, the nCRP generates its own annotated hi-erarchy whose concept nodes do not necessarilycorrespond to WN concepts (Example 3).
Eachnode in the tree instead corresponds to a latent an-notated concept with an arbitrary number of sub-concepts, distributed according to a Dirichlet Pro-cess (Ferguson, 1973).
Due to its recursive struc-ture, the underlying model is called the nested Chi-nese Restaurant Process (nCRP).
The model inEquation 1 is extended with cd|?
?
nCRP(?, L),d ?
D i.e., latent concepts for each attribute set aredrawn from an nCRP.
The hyperparameter ?
con-trols the probability of branching via the per-nodeDirichlet Process, and L is the fixed tree depth.An efficient Gibbs sampling procedure is givenin (Blei et al, 2003a).
(Example 3) Applying nCRP to the same three semanticcategories: philosophers, writers and actors, yields themodel:biographydate of birthchildhoodpicturefamilyworksbooksquotationscriticspoemsteachingsvirtue ethicsstructuralismphilosophiespolitical theorycriticismshort storiesstylepoemscomplete worksaccomplishmentsofficial websiteprofilelife storyachievementsfilmographypicturesnew moviesofficial siteworks(root)(philosopher) (writer) (actor)bollywoodactorswomenwriterscontemporaryphilosophers(manually added labels are shown in parentheses).
Un-like in WN, the inferred structure naturally placesphilosopher and writer under the same subconcept,which is also separate from actor.
Hyperparameters were?=0.1, ?=0.1, ?=1.0.4 Experimental Setup4.1 Data AnalysisWe employ two data sets derived using the pro-cedure in (Pas?ca and Van Durme, 2008): the fullset of automatic extractions generated in ?
2, and asubset consisting of all attribute sets that fall underthe hierarchies rooted at the WN concepts livingthing#1 (i.e., the first sense of living thing), sub-stance#7, location#1, person#1, organization#1and food#1, manually selected to cover a high-precision subset of labeled attribute sets.
By com-paring the results across the two datasets we canmeasure each model?s robustness to noise.In the full dataset, there are 4502 input attributesets with a total of 225K attributes (24K unique),of which 8121 occur only once.
The 10 attributesoccurring in the most sets (history, definition, pic-ture(s), images, photos, clipart, timeline, clip art,types) account for 6% of the total.
For the subset,there are 1510 attribute sets with 76K attributes(11K unique), of which 4479 occur only once.4.2 Model SettingsBaseline: Each labeled attribute set is mapped tothe most common WN concept with the closest la-bel string distance (Pas?ca, 2008).
Attributes arepropagated up the tree, attaching to node c if theyare contained in a majority of c?s children.LDA: LDA is used to infer a flat set of T = 300latent annotated concepts describing the data.
Theconcept selection smoothing parameter is set as?=100.
The smoother for the per-concept multi-nomial over words is set as ?=0.1.4 The effects ofconcept structure on attribute precision can be iso-lated by comparing the structured models to LDA.Fixed-Structure LDA (fsLDA): The latent con-cept hierarchy is fixed based on WN (?
3.2), andlabeled attribute sets are mapped into it as in base-line.
The concept graph for each labeled attributeset wd is decomposed into (possibly overlapping)chains, one for each unique path from the WN rootto wd?s attachment point.
Each path is assigned acopy wd, reducing the bias in attribute sets withmany unique ancestor concepts.5 The final mod-els contain 6566 annotated concepts on average.Sense-Selective LDA (ssLDA): For the sense se-lective approach (?
3.3), the set of possible senseattachments for each attribute set is taken to be allWN concepts with the lowest edit distance to itslabel, and the conditional probability of each senseattachment p(cd) is set proportional to its relativefrequency.
This procedure results in 2 to 3 sensesper attribute set on average, yielding models with7108 annotated concepts.Arbitrary hierarchy (nCRP): For the arbitraryhierarchy model (?
3.4), we set the maximumtree depth L=5, per-concept attribute smoother?=0.05, concept assignment smoother ?=10 andnCRP branching proportion ?=1.0.
The resulting4(Parameter setting) Across all models, the main resultsin this paper are robust to changes in ?.
For nCRP, changesin ?
and ?
affect the size of the learned model but have lesseffect on the final precision.
Larger values for L give themodel more flexibility, but take longer to train.5Reducing the directed-acyclic graph to a tree ontologydid not significantly affect precision.623models span 380 annotated concepts on average.4.3 Constructing Ranked Lists of AttributesGiven an inferred model, there are several ways toconstruct ranked lists of attributes:Per-Node Distribution: In fsLDA and ssLDA,attribute rankings can be constructed directly foreach WN concept c, by computing the likelihoodof attribute w attaching to c, L(c|w) = p(w|c) av-eraged over all Gibbs samples (discarding a fixednumber of samples for burn-in).
Since c?s attributedistribution is not dependent on the distributionsof its children, the resulting distribution is biasedtowards more specific attributes.Class-Entropy (CE): In all models, the inferredlatent annotated concepts can be used to smooththe attribute rankings for each labeled attribute set.Each sample from the posterior is composed oftwo components: (1) a multinomial distributionover a set of WN nodes, p(c|wd, ?)
for each at-tribute set wd, where the (discrete) values of c areWN concepts, and (2) a multinomial distributionover attributes p(w|c, ?)
for each WN concept c.To compute an attribute ranking for wd, we havep(w|wd) =?cp(w|c, ?
)p(c|wd, ?
).Given this new ranking for each attribute set, wecan compute new rankings for each WN conceptc by averaging again over all the wd that appearas (possible indirect) descendants of c. Thus, thismethod uses LDA to first perform reranking on theraw extractions before applying the baseline ontol-ogy induction procedure (?
4.2).6CE ranking exhibits a ?conservation of entropy?effect, whereby the proportion of general to spe-cific attributes in each attribute set wd remains thesame in the posterior.
If set A contains 10 specificattributes and 30 generic ones, then the latter willbe favored over the former in the resulting distri-bution 3 to 1.
Conservation of entropy is a strongassumption, and in particular it hinders improvingthe specificity of attribute rankings.Class-Entropy+Prior: The LDA-based modelsdo not inherently make use of any ranking infor-mation contained in the original extractions.
How-ever, such information can be incorporated in theform of a prior.
The final ranking method com-bines CE with an exponential prior over the at-tribute rank in the baseline extraction.
For eachattribute set, we compute the probability of each6One simple extension is to run LDA again on the CEranked output, yielding an iterative procedure; however, thiswas not found to significantly affect precision.attribute p(w|wd) = plda(w|wd)pbase(w|wd), as-suming a parametric form for pbase(w|wd)def=?r(w,wd).
Here, r(w,wd) is the rank of w in at-tribute set d. In all experiments reported, ?=0.9.4.4 Evaluating Attribute AttachmentFor the WN-based models, in addition to mea-suring the average precision of the reranked at-tributes, it is also useful to evaluate the assign-ment of attributes to WN concepts.
For this eval-uation, human annotators were asked to determinethe most appropriate WN synset(s) for a set of goldattributes, taking into account polysemous usage.For each model, ranked lists of possible conceptassignments C(w) are generated for each attributew, usingL(c|w) for ranking.
The accuracy of a listC(w) for an attribute w is measured by a scoringmetric that corresponds to a modification (Pas?caand Alfonseca, 2009) of the mean reciprocal rankscore (Voorhees and Tice, 2000):DRR = max1rank(c)?
(1 + PathToGold)where rank(c) is the rank (from 1 up to 10) of aconcept c in C(w), and PathToGold is the lengthof the minimum path along Is-A edges in the con-ceptual hierarchies between the concept c, on onehand, and any of the gold-standard concepts man-ually identified for the attribute w, on the otherhand.
The length PathToGold is 0, if the returnedconcept is the same as the gold-standard concept.Conversely, a gold-standard attribute receives nocredit (that is, DRR is 0) if no path is found inthe hierarchies between the top 10 concepts ofC(w) and any of the gold-standard concepts, or ifC(w) is empty.
The overalll precision of a givenmodel is the average of the DRR scores of individ-ual attributes, computed over the gold assignmentset (Pas?ca and Alfonseca, 2009).5 Results5.1 Attribute PrecisionPrecision was manually evaluated relative to 23concepts chosen for broad coverage.7 Table 1shows precision at n and the Mean Average Preci-sion (MAP); In all LDA-based models, the Bayesaverage posterior is taken over all Gibbs samples7(Precision evaluation) Attributes were hand annotatedusing the procedure in (Pas?ca and Van Durme, 2008) and nu-merical precision scores (1.0 for vital, 0.5 for okay and 0.0 forincorrect) were assigned for the top 50 attributes per concept.25 reference concepts were originally chosen, but 2 were notpopulated with attributes in any method, and hence were ex-cluded from the comparison.624Model Precision @ MAP5 10 20 50Base (unranked) 0.45 0.48 0.47 0.44 0.46Base (ranked) 0.77 0.77 0.69 0.58 0.67LDA?
-24 ?
105CE 0.64 0.53 0.52 0.56 0.55CE+Prior 0.80 0.73 0.74 0.58 0.69Fixed-structure (fsLDA) -22 ?
105Per-Node 0.43 0.41 0.42 0.41 0.42CE 0.75 0.68 0.63 0.55 0.63CE+Prior 0.78 0.77 0.71 0.59 0.69Sense-selective (ssLDA) -18 ?
105Per-Node 0.37 0.44 0.42 0.41 0.42CE 0.69 0.68 0.65 0.58 0.64CE+Prior 0.81 0.80 0.72 0.60 0.70nCRP?
-14 ?
105CE 0.74 0.76 0.73 0.65 0.72CE+Prior 0.88 0.85 0.81 0.68 0.78Subset onlyBase (unranked) 0.61 0.62 0.62 0.60 0.62Base (ranked) 0.79 0.82 0.72 0.65 0.72?WN living thing 0.73 0.80 0.71 0.65 0.69?WN substance 0.80 0.80 0.69 0.53 0.68?WN location 0.95 0.93 0.84 0.75 0.84?WN person 0.75 0.83 0.75 0.77 0.77?WN organization 0.60 0.70 0.60 0.68 0.63?WN food 0.90 0.85 0.58 0.45 0.64Fixed-structure (fsLDA) -77 ?
104Per-Node 0.64 0.58 0.52 0.56 0.55CE 0.90 0.83 0.78 0.73 0.78CE+Prior 0.88 0.86 0.80 0.66 0.78?WN living thing 0.83 0.88 0.78 0.63 0.77?WN substance 0.85 0.83 0.78 0.66 0.76?WN location 0.95 0.95 0.88 0.75 0.85?WN person 1.00 0.93 0.91 0.76 0.87?WN organization 0.80 0.70 0.80 0.76 0.75?WN food 0.80 0.70 0.63 0.40 0.59nCRP?
-45 ?
104CE 0.88 0.88 0.78 0.71 0.79CE+Prior 0.90 0.88 0.83 0.67 0.79Table 1: Precision at n and mean-average preci-sion for all models and data sets.
Inset plots showlog-likelihood of each Gibbs sample, indicatingconvergence except in the case of nCRP.
?
indi-cates models that do not generate annotated con-cepts corresponding to WN nodes and hence haveno per-node scores.after burn-in.8 The improvements in average pre-cision are important, given the amount of noise inthe raw extracted data.When prior attribute rank information (Per-Node and CE scores) from the baseline extractionsis not incorporated, all LDA-based models outper-form the unranked baseline (Table 1).
In particu-lar, LDA yields a 17% reduction in error (MAP)8(Bayes average vs. maximum a-posteriori) The fullBayesian average posterior consistently yielded higher preci-sion than the maximum a-posteriori model.
For the per-nodedistributions, the fsLDA Bayes average model exhibits a 17%reduction in relative error over the maximum a-posteriori es-timate and for ssLDA there was a 26% reduction.Model DRR Scoresall (n) found (n)Base (unranked) 0.14 (150) 0.24 (91)Base (ranked) 0.17 (150) 0.21 (123)Fixed-structure(fsLDA) 0.31 (150) 0.37 (128)Sense-selective(ssLDA) 0.31 (150) 0.37 (128)Subset onlyBase (unranked) 0.15 (97) 0.27 (54)Base (ranked) 0.18 (97) 0.24 (74)WN living thing 0.29 (27) 0.35 (22)WN substance 0.21 (12) 0.32 (8)WN location 0.12 (30) 0.17 (20)WN person 0.37 (18) 0.44 (15)WN organization 0.15 (31) 0.17 (27)WN food 0.15 (6) 0.22 (4)Fixed-structure(fsLDA) 0.37 (97) 0.47 (77)WN living thing 0.45 (27) 0.55 (22)WN substance 0.48 (12) 0.64 (9)WN location 0.34 (30) 0.44 (23)WN person 0.44 (18) 0.52 (15)WN organization 0.44 (31) 0.71 (19)WN food 0.60 (6) 0.72 (5)Table 2: All measures the DRR score relative tothe entire gold assignment set; found measuresDRR only for attributes with DRR(w)>0; n is thenumber of scores averaged.over the baseline, fsLDA yields a 31% reduction,ssLDA yields a 33% reduction and nCRP yieldsa 48% reduction (24% reduction over fsLDA).Performance also improves relative to the rankedbaseline when prior ranking information is incor-porated in the LDA-based models, as indicatedby CE+Prior scores in Table 1.
LDA and fsLDAreduce relative error by 6%, ssLDA by 9% andnCRP by 33%.
Furthermore, nCRP precisionwithout ranking information surpasses the base-line with ranking information, indicating robust-ness to extraction noise.
Precision curves for indi-vidual attribute sets are shown in Figure 3.
Over-all, learning unconstrained hierarchies (nCRP) in-creases precision, but as the inferred node distri-butions do not correspond to WN concepts theycannot be used for annotation.One benefit to using an admixture model likeLDA is that each concept node in the resultingmodel contains a distribution over attributes spe-cific only to that node (in contrast to, e.g., hierar-chical agglomerative clustering).
Although abso-lute precision is lower as more general attributeshave higher average precision (Per-Node scoresin Table 1), these distributions are semanticallymeaningful in many cases (Figure 4) and further-more can be used to calculate concept assignmentprecision for each attribute.99Per-node distributions (and hence DRR) were not evalu-625Figure 3: Precision (%) vs. rank plots (log scale) of attributes broken down across 18 labeled test attributesets.
Ranked lists of attributes are generated using the CE+Prior method.5.2 Concept Assignment PrecisionThe precision of assigning attributes to variousconcepts is summarized in Table 2.
Two scores aregiven: all measures DRR relative to the entire goldassignment set, and found measures DRR only forattributes with DRR(w)>0.
Comparing the scoresgives an estimate of whether coverage or precisionis responsible for differences in scores.
fsLDA andssLDA both yield a 20% reduction in relative er-ror (17.2% increase in absolute DRR) over the un-ranked baseline and a 17.2% reduction (14.2% ab-solute increase) over the ranked baseline.5.3 Subset Precision and DRRPrecision scores for the manually selected subsetof extractions are given in the second half of Ta-ble 1.
Relative to the unranked baseline, fsLDAand nCRP yield 42% and 44% reductions in er-ror respectively, and relative to the ranked base-line they both yield a 21.4% reduction.
In terms ofabsolute precision, there is no benefit to adding inprior ranking knowledge to fsLDA or nCRP, in-dicating diminishing returns as average baselineprecision increases (Baseline vs. fsLDA/nCRP CEscores).
Broken down across each of the subhier-archies, LDA helps in all cases except food.DRR scores for the subset are given in the lowerhalf of Table 2.
Averaged over all gold test at-tributes, DRR scores double when using fsLDA.These results can be misleading, however, dueto artificially low coverage.
Hence, Table 2 alsoshows DRR scores broken down over each sub-hierarchy, In this case fsLDA more than doublesthe DRR relative to the baseline for substance andlocation, and triples it for organization and food.ated for LDA or nCRP, because they are not mapped to WN.6 Related WorkA large body of previous work exists on extend-ing WORDNET with additional concepts and in-stances (Snow et al, 2006; Suchanek et al, 2007);these methods do not address attributes directly.Previous literature in attribute extraction takes ad-vantage of a range of data sources and extractionprocedures (Chklovski and Gil, 2005; Tokunagaet al, 2005; Pas?ca and Van Durme, 2008; Yoshi-naga and Torisawa, 2007; Probst et al, 2007; VanDurme et al, 2008; Wu and Weld, 2008).
How-ever these methods do not address the task of de-termining the level of specificity for each attribute.The closest studies to ours are (Pas?ca, 2008), im-plemented as the baseline method in this paper;and (Pas?ca and Alfonseca, 2009), which relies onheuristics rather than formal models to estimatethe specificity of each attribute.7 ConclusionThis paper introduced a set of methods based onLatent Dirichlet Allocation (LDA) for jointly ex-tending the WORDNET ontology and annotatingits concepts with attributes (see Figure 4 for theend result).
LDA significantly outperformed a pre-vious approach both in terms of the concept as-signment precision (i.e., determining the correctlevel of generality for an attribute) and the mean-average precision of attribute lists at each concept(i.e., filtering out noisy attributes from the base ex-traction set).
Also, relative precision of the attach-ment models was shown to improve significantlywhen the raw extraction quality increased, show-ing the long-term viability of the approach.626entityphysical entitybollywoodactorsactornew wallpapersupcoming moviesbaby pictureslatest wallpapersperformerfilmographynew moviesschedulenew picturesnew picsentertainerhairstylehairstylesmusic videossongsnew picturessexy picturespersonbioautobiographychildhoodbibliographyaccomplishmentstimelineorganismcausal agentliving thingphotostaxonomyscientific namereproductionlife cyclehabitatwholeobjecthistorypicturesimagespicturephotostimelinerenaissancepainterspainterinfluencedimpressionistthe life's paintingsstyle ofwatercolorartistself portraitpaintingsfamous worksself portraitspainting techniquesfamous paintingscreatorinfluencesartworkstyleworkarttechniqueeuropeancountriesEuropeancountryrecreationnational costumeprime ministerpolitical partiesroyal familynational parkscountrystate codeszipcodescountry profilecurrenciesnational anthemtelephone codesadministrativedistrictsightsweather forecastculturetourist spotsstate mapdistricttraditional dressper capita incometourist spotcuisinefolk dancesindustrial policyregionpopulationnightlifestreet maptemperaturelocationclimatetourist attractionsgeographyweathertourismeconomydrugdangerhalf lifeingredientsside effectswithdrawal symptomssexual side effectsagentpharmacokineticsmechanism of actionlong term effectspharmacologycontraindicationsmode of actionsubstancematterchemistryingredientschemical structuredangerschemical formulamsdsliquorsliquordrink mixesapparitionspitchersexistencefantasy artalcoholcarbohydratescarbscaloriesalcohol contentpronunciationglassbeveragedrug of abusesugar contentalcohol contentcaffeine contentserving temperaturealcohol percentageshelf lifeliquidfoodadvertisementssugar contentadvertsbrandnutrition informationstorage temperatureshelf lifenutritional factsnutrition informationflavorsnutritionnutritional informationfluidrecepiesgift basketsreceipesrdidaily allowancefondue recipessubstancedensityusesphysical propertiesmelting pointchemical propertieschemical structureabstractionlondonboroughsboroughregistry officeschool term dateslocal historyrenaultcitizens advice bureauleisure centresvegetablesvegetablepestsnutritional valuesmusic storeessential oilnutrition valuedna extractionproducefiberelectricitypotassiumnutritional valuesnutrition valuedna extractionfoodsolidmaterial propertiesrefractive indexthermal propertiesphase diagramthermal expansionaneurysmparasitesparasitepathogenphobiamortality ratesymptomstreatmentorchestrasorchestrarecordingsbroadcastsrecordingchristmasticketconductormusicalorganizationdvorakrecordingsconductorinstrumentbroadcastshallorganizationcareersceophone numberannual reportlondoncompanysocialgroupjobswebsitelogoaddressmission statementpresidentgroupancient citiescityportcost of livingcanadian embassycityair pollutioncheap hotelsmunicipalitysightseeingweather forecasttourist guideamerican schoolzoohospitals??
?red wineswinegrapevintage chartgrapescityfood pairingscheeseFigure 4: Example per-node attribute distribution generated by fsLDA.
Light/orange nodes representlabeled attribute sets attached to WN, and the full hypernym graph is given for each in dark/purplenodes.
White nodes depict the top attributes predicted for each WN concept.
These inferred annotationsexhibit a high degree of concept specificity, naturally becoming more general at higher levels of theontology.
Some annotations, such as for the concepts Agent, Substance, Living Thing and Person havehigh precision and specificity while others, such as Liquor and Actor need improvement.
Overall, themore general concepts yield better annotations as they are averaged over many labeled attribute sets,reducing noise.
627ReferencesD.
Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.2003a.
Hierarchical topic models and the nestedChinese restaurant process.
In Proceedings of the17th Conference on Neural Information Process-ing Systems (NIPS-2003), pages 17?24, Vancouver,British Columbia.D.
Blei, A. Ng, and M. Jordan.
2003b.
Latent dirich-let alocation.
Machine Learning Research, 3:993?1022.T.
Chklovski and Y. Gil.
2005.
An analysis of knowl-edge collected from volunteer contributors.
In Pro-ceedings of the 20th National Conference on Arti-ficial Intelligence (AAAI-05), pages 564?571, Pitts-burgh, Pennsylvania.R.
Duda, P. Hart, and D. Stork.
2000.
Pattern Classifi-cation.
John Wiley and Sons.C.
Fellbaum, editor.
1998.
WordNet: An ElectronicLexical Database and Some of its Applications.
MITPress.T.
Ferguson.
1973.
A bayesian analysis of some non-parametric problems.
Annals of Statistics, 1(2):209?230.W.
Gao, C. Niu, J. Nie, M. Zhou, J. Hu, K. Wong, andH.
Hon.
2007.
Cross-lingual query suggestion usingquery logs of different languages.
In Proceedings ofthe 30th ACM Conference on Research and Devel-opment in Information Retrieval (SIGIR-07), pages463?470, Amsterdam, The Netherlands.T.
Griffiths and M. Steyvers.
2002.
A probabilistic ap-proach to semantic representation.
In Proceedingsof the 24th Conference of the Cognitive Science So-ciety (CogSci02), pages 381?386, Fairfax, Virginia.M.
Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 14th International Conference on ComputationalLinguistics (COLING-92), pages 539?545, Nantes,France.T.
Hofmann.
1999.
Probabilistic latent semantic in-dexing.
In Proceedings of the 22nd ACM Confer-ence on Research and Development in InformationRetrieval (SIGIR-99), pages 50?57, Berkeley, Cali-fornia.W.
Li and A. McCallum.
2006.
Pachinko alloca-tion: DAG-structured mixture models of topic cor-relations.
In Proceedings of the 23rd InternationalConference on Machine Learning (ICML-06), pages577?584, Pittsburgh, Pennsylvania.D.
Lin and P. Pantel.
2002.
Concept discovery fromtext.
In Proceedings of the 19th International Con-ference on Computational linguistics (COLING-02),pages 1?7, Taipei, Taiwan.M.
Pas?ca and E. Alfonseca.
2009.
Web-derived re-sources for Web Information Retrieval: From con-ceptual hierarchies to attribute hierarchies.
In Pro-ceedings of the 32nd International Conference onResearch and Development in Information Retrieval(SIGIR-09), Boston, Massachusetts.M.
Pas?ca and B.
Van Durme.
2008.
Weakly-supervised acquisition of open-domain classes andclass attributes from web documents and query logs.In Proceedings of the 46th Annual Meeting of the As-sociation for Computational Linguistics (ACL-08),pages 19?27, Columbus, Ohio.M.
Pas?ca.
2008.
Turning Web text and searchqueries into factual knowledge: Hierarchical classattribute extraction.
In Proceedings of the 23rd Na-tional Conference on Artificial Intelligence (AAAI-08), pages 1225?1230, Chicago, Illinois.K.
Probst, R. Ghani, M. Krema, A. Fano, and Y. Liu.2007.
Semi-supervised learning of attribute-valuepairs from product descriptions.
In Proceedings ofthe 20th International Joint Conference on ArtificialIntelligence (IJCAI-07), pages 2838?2843, Hyder-abad, India.J.
Sivic, B. Russell, A. Zisserman, W. Freeman, andA.
Efros.
2008.
Unsupervised discovery of visualobject class hierarchies.
In Proceedings of the IEEEConference on Computer Vision and Pattern Recog-nition (CVPR-08), pages 1?8, Anchorage, Alaska.R.
Snow, D. Jurafsky, and A. Ng.
2006.
Semantic tax-onomy induction from heterogenous evidence.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics(COLING-ACL-06), pages 801?808, Sydney, Aus-tralia.F.
Suchanek, G. Kasneci, and G. Weikum.
2007.
Yago:a core of semantic knowledge unifying WordNet andWikipedia.
In Proceedings of the 16th World WideWeb Conference (WWW-07), pages 697?706, Banff,Canada.K.
Tokunaga, J. Kazama, and K. Torisawa.
2005.
Au-tomatic discovery of attribute words from Web doc-uments.
In Proceedings of the 2nd InternationalJoint Conference on Natural Language Processing(IJCNLP-05), pages 106?118, Jeju Island, Korea.B.
Van Durme, T. Qian, and L. Schubert.
2008.Class-driven attribute extraction.
In Proceedingsof the 22nd International Conference on Computa-tional Linguistics (COLING-2008), pages 921?928,Manchester, United Kingdom.E.M.
Voorhees and D.M.
Tice.
2000.
Building aquestion-answering test collection.
In Proceedingsof the 23rd International Conference on Researchand Development in Information Retrieval (SIGIR-00), pages 200?207, Athens, Greece.F.
Wu and D. Weld.
2008.
Automatically refining theWikipedia infobox ontology.
In Proceedings of the17th World Wide Web Conference (WWW-08), pages635?644, Beijing, China.N.
Yoshinaga and K. Torisawa.
2007.
Open-domainattribute-value acquisition from semi-structuredtexts.
In Proceedings of the 6th International Se-mantic Web Conference (ISWC-07), Workshop onText to Knowledge: The Lexicon/Ontology Interface(OntoLex-2007), pages 55?66, Busan, South Korea.628
