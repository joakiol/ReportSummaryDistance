Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 54?57,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPGraph-based Event Coreference ResolutionZheng ChenThe Graduate CenterThe City University of New Yorkzchen1@gc.cuny.eduHeng JiQueens College and The Graduate CenterThe City University of New Yorkhengji@cs.qc.cuny.eduAbstractIn this paper, we address the problem of eventcoreference resolution as specified in the Au-tomatic Content Extraction (ACE11 Introduction) program.In contrast to entity coreference resolution,event coreference resolution has not receivedgreat attention from researchers.
In this paper,we first demonstrate the diverse scenarios ofevent coreference by an example.
We thenmodel event coreference resolution as a spec-tral graph clustering problem and evaluate theclustering algorithm on ground truth eventmentions using ECM F-Measure.
We obtainthe ECM-F scores of 0.8363 and 0.8312 re-spectively by using  two methods for compu-ting coreference matrices.Typically, an ACE Event Detection and Recog-nition (VDR) system consists of two steps: first,it detects all mentions of events with certain spe-cified types occurring in the raw text (event men-tion detection) and second, it unifies the eventmentions into equivalence classes so that all thementions in a given class refer to an event (eventcoreference resolution).
ACEdefines the follow-ing terminologies related with VDR:z Event: a specific occurrence involving partic-ipants.
An ACE event has six attributes (type,subtype, modality, polarity, genericity andtense), zero or more event arguments, and acluster of event mentions.z Event trigger: the word that most clearly ex-presses an event?s occurrence.z Event argument:  an entity, or a temporal ex-pression or a value that has a certain role (e.g.,Time-Within, Place) in an event.z Event mention: a sentence (or a text spanextent) that mentions an event, including adistinguished trigger and involving arguments.1 http://www.nist.gov/speech/tests/ace/In contrast to entity coreference, the scenariosin event coreference are more complicated,mainly because entity coreference is word (orphrase)-level coreference whereas event corefe-rence is sentence-level coreference and thereforethe coreferring event mentions may have moreflexible linguistic structures than entity mentions.We provide an example to demonstrate this di-versity.EM1An {explosion} in a cafe at one of the capital'sbusiest intersections killed one woman and injuredanother TuesdayEM2Police were investigating the cause of the {ex-plosion} in, police said.the restroom of the multistory CrocodileCafe in the commercial district of Kizilay dur-ing the morning rush hour.
EM3The {blast} shatteredwalls and windows in the buildingEM4Ankara police chief Ercument Yilmaz vi-sited.the site of the morning blast but refused to sayif a bombEM5The {explosion} comes a month after EM6had caused the {explosion}.a bomb{exploded} at a McDonald's restaurant in IstanbulEM7,causing damage but no injuries.Radical leftist, Kurdish and Islamic groups areactive in the country and have carried out {bomb-ings} in the past.Table 1.
Source text and event mentionsTable 1 shows the source text of a news story.As an example, we only tag the event mentionswhich have the event type and subtype of (Con-flict:Attack).
In each event mention, the trigger issurrounded by curly brackets, and arguments areunderlined.Table 2 shows the tabular representation ofthose event mentions.Table 3 shows that the five event mentions inevent EV1 corefer with each other.
We summar-ize EV1 as follows: a bomb (E4-1) exploded inthe restroom (E2-1) of a caf?
(E1-1 or E1-2) dur-ing Tuesday morning?s rush hour (combinationof T1-1, T2-1 and T3-1).
EV2 is a different at-tack event because the target (E6-1) in EV2 dif-fers from the one (E1-3) in EV1.
EV3 tells thatthe bombing attacks have occurred generically54(thus the event attribute ?genericity?
is ?General?whereas it is ?Specific?
in EV1 and EV2).EM1 Trigger: explosionArguments (ID: ROLE):(E1-1: Place) a cafe at one of the capital'sbusiest intersections(T1-1: Time-Within) TuesdayEM2 Trigger: explosionArguments:(E2-1: Place) the restroom of the multistoryCrocodile Cafe(E3-1: Place) the commercial district ofKizilay(T2-1: Time-Within) the morning rush hourEM3 Trigger: blastArguments:(E1-2: Place) the buildingEM4 Trigger: explosionArguments:(E4-1: Instrument) a bomb(E1-3: Target) the site of the morning blast(T3-1: Time-Within) morningEM5 Trigger: explosionArguments: NoneEM6 Trigger: explodedArguments:(E5-1: Instrument) a bomb(E6-1: Target) a McDonald's restaurant(E7-1: Place) IstanbulEM7 Trigger: bombings(E8-1: Attacker) Radical leftist, Kurdishand Islamic groups(E9-1: Place) the country(T4-1: Time-Within) the pastTable 2.
Tabular representation of event mentionsEvent Included event mentionsEV1 {EM1,EM2,EM3,EM4,EM5}EV2 {EM6}EV3 {EM7}Table 3.
Event coreference results2 Event Coreference Resolution asSpectral Graph ClusteringWe view the event coreference space as an undi-rected weighted graph in which the nodesrepresent all the event mentions in a documentand the edge weights indicate the coreferenceconfidence between two event mentions.
In realimplementation,  we initially construct differentgraphs for separate event types 22 We view the 33 ACE event subtypes as event types, such that, ineach graph, all the event mentions have the sameevent type.
Similar to (Nicolae and Nicolae,2006), we formally define a framework for eventcoreference resolution.Let ??
= {???
: 1 ?
?
?
?}
be ?
event men-tions in the document and ??
= {???
: 1 ?
?
?
?
}be ?
events.
Let ?:??
?
??
be the functionmapping from an event mention ???
?
??
to anevent ???
?
??
.
Let ???:????
?
??
?
[0,1] bethe function that computes the coreference confi-dence between two event mentions ???
, ?
??
???
.
Let ?
= {??
: 1 ?
?
?
?}
be ?
event types.Thus for each event type ?
, we have a graph??(??
,??)
, where ??
= {???
|?(???
).
????
= ??
, ???
???}
and ??
= ?(???
, ???
, ?????(???
, ???
))????
, ???
?
??
?.We then model event coreference resolution asa spectral graph clustering problem that optimiz-es the normalized-cut criterion (Shi and Malik,2000).
Such optimization can be achieved bycomputing the second generalized eigenvector,thus the name ?spectral?.
In this paper, we do nottry to propose a new spectral clustering algo-rithm  or improve the existing algorithm.
Instead,we focus on how to compute the coreference ma-trix (equivalently, the affinity matrix in Shi andMalik?s algorithm) because a better estimation ofcoreference matrix can reduce the burden onclustering algorithm.3 Coreference Matrix ?3.1 Method 1: Computing a Coreference FormulaObviously, the trigger pair and the argument setsowned by two event mentions carry much infor-mation about whether one event mention coreferswith the other.
Based on a corpus, we computethe statistics about event mention pairs (with thesame event type)  listed in Table 4.Let ???
.
???????
be the trigger in ???
,????(???
.
???????)
be the stem of the trigger in???
, ???????(???
.
??????
?, ?
??
.
???????)
be thesemantic similarity between the two triggers in??
?and ?
??
as computed in (Seco et al, 2004),???
.
???
be the argument (ID and ROLE) set in???
.
Let 1?
be the conjunction operator on ar-gument pairs whose ID 3???
= ??
1????
+????
whereand ROLE match, 2?be the conjunction operator on argument pairswhose ID matches but ROLE does not match, 3?be the conjunction operator on argument pairswhose ROLE matches but ID does not match, 4?be the conjunction operator on argument pairswhose ID and ROLE do not match.
We then pro-pose the following formula to measure the core-ference value between ???
and ?
??
.3 We view two argument IDs ?E1-1?
and ?E1-2?
as a matchif they mention the same entity which is ?E1?551111 1221( ) ( )21 2231( , ) 031 324141 42.
.. .. .i ji jTiji jTif em trigger em triggerT TTelseif stem em trigger stem em triggerT TwTelseif wordnet em trigger em triggerT TTotherwiseT T???
??
????
??
?
???
??
??????
?
?and1 23 41min{ .arg , .arg }11 21[ .arg .arg .arg .arg11 12 21 2231 41.arg .arg .arg .arg ]31 32 41 42Aiji ji j i ji j i jwem emA Aem em em emA A A AA Aem em em emA A A Aq?
??
?The strength of this formula is that it allows togive credit to different cases of trigger matchingand argument pair matching between two eventmentions.T11 in those coreferring event mention pairs, howmany pairs use exactly the same triggersT12 in those non-coreferring event mention pairs, howmany pairs use exactly the same triggersT21 in those coreferring event mention pairs, howmany pairs do not have the same triggers, buthave the same stems of triggersT22 non-coreferring version of T21T31 in those coreferring event mention pairs, howmany pairs do not have the same triggers nor thesame stems, but the semantic similarity betweentwo triggers is higher than 0 in WordNet.T32 non-coreferring version of T31T41 in those non-coreferring event mention pairs, howmany pairs are not in T11 or T21 or T31T42 non- coreferring version that is not T12 or T22 orT32A11 in those coreferring event mention pairs, howmany argument pairs whose ID and ROLE matchA12 non-coreferring version of A11A21 in those coreferring event mention pairs, howmany argument pairs whose ID matches butROLE does not matchA22 non-coreferring version of A21A31 in those coreferring event mention pairs, howmany argument pairs whose ROLE matches butID does not matchA32 non-coreferring version of A31A41 in those non-coreferring event mention pairs, howmany argument pairs whose ID and ROLE do notmatchA42 non-coreferring version of A41Table 4.
Statistics of event mention pairs3.2 Method 2: Applying a Maximum En-tropy ModelWe train a maximum entropy model to producethe confidence values for ?
.
Each confidencevalue tells the probability that there exists corefe-rence ?
between event mention ???
and ?
??
.???????
, ?
??
?
=?(?
???
??(???
, ???
,?))?(???
, ?
??
)where ??(??
?,  ???,?)
is a feature and ??
is itsweight; ?????
, ?
??
?
is the normalizing factor.The feature sets applied in the model are listedin Table 5 by categories.4 Experiments and Results4.1 Data and Evaluation MetricsWe developed and tested the spectral clusteringalgorithm for event coreference resolution usingthe ACE 2005 English corpus which contains560 documents.
We used the ground truth eventmentions and evaluated our algorithm based onECM F-Measure (Luo, 2005).
We reserved 60documents for testing purpose and used the left500 documents for training/developing purposeand for computing the statistics discussed above.We applied 10-fold cross-validation in the expe-riment of comparing two methods for computingcoreference matrix.4.2 Statistics of Event Mention PairsThe results of the statistics discussed in Section3.1 are presented in Table 6.T11=1042,T12=1297, T21=240,T22=840,T31=257, T32=2637, T41=784,T42=5628A11=888, A12= 1485, A21=31, A22=146,A31=542, A32=6849, A41=323, A42=3000Table 6.
Results of statistics in 500 documentsFrom Table 6, we observe that if two eventmentions use the same trigger or if they havearguments whose ID and ROLE match, it is moreprobable for them to corefer with each other thanother cases.4.3 Comparison of the Two Methods forComputing Coreference MatrixFigure 1.
ECM-F scores for both methods56Category Features Remarks (EM1: the first event mention, EM2: the second eventmention)Lexicon type_subtype pair of event type and subtype in EM1trigger_pair trigger pair of EM1 and EM2pos_pair part-of-speech pair of triggers of EM1 and EM2nominal 1 if the trigger of EM2 is nominalexact_match 1 if the spellings of triggers in EM1 and EM2 exactly matchstem_match 1 if the stems of triggers in EM1 and EM2 matchtrigger_sim quantized semantic similarity score (0-5) using WordNet resourceDistance token_dist how many tokens between triggers of EM1 and EM2 (quantized)sentence_dist how many sentences EM1 and EM2 are apart (quantized)event_dist how many event mentions in between EM1 and EM2 (quantized)Arguments overlap_num,overlap_roles overlap number of arguments and their roles (role and id exactlymatch) between EM1 and EM2prior_num, prior_roles the number and the roles of arguments that only appear in EM1act_num, act_roles the number and the roles of arguments that only appear in EM2coref_num the number of arguments that corefer each other but have differentroles between EM1 and EM2Table 5.
EM(Event Mention)-pair features for the maximum entropy modelFigure 1 shows the ECM-F scores for both me-thods by varying the cut threshold in the cluster-ing algorithm.
Both methods obtain the highestECM-F score at threshold 0.85 and method 1performs slightly better than method 2 (0.8449 vs.0.8418, significant at 85% confidence level,p<=0.1447).
We obtained the ECM-F scores of0.8363 and 0.8312 on the test set for method 1and method 2 respectively.
We also obtainedtwo baseline ECM-F scores, one is 0.535 if weconsider all the event mentions with the sameevent type as a cluster, the other is 0.7635 if weconsider each event mention as a cluster.5 Related WorkEarlier work on event coreference (e.g.
Humph-reys et al, 1997; Bagga and Baldwin, 1999) inMUC was limited to several scenarios, e.g., ter-rorist attacks, management succession, resigna-tion.
The ACE program takes a further step to-wards processing more fine-grained events.
Tothe best of our knowledge, this paper is the firsteffort to apply graph-based algorithm to theproblem of event coreference resolution.Nicolae and Nicolae (2006) proposed a similargraph-based framework for entity coreferenceresolution.
However, in our task, the event men-tion has much richer structure than the entitymention, thus, it is possible for us to harness theuseful information from both the triggers and theattached arguments in the event mentions.6 Conclusions and Future WorkIn this paper, we addressed the problem of eventcoreference resolution in a graph-based frame-work, and presented two methods for computingthe coreference matrix.
A practical event corefe-rence resolver also depends on high-performanceevent extractor.
We will further study the impactof system generated event mentions on the per-formance of our coreference resolver.AcknowledgmentsThis material is based upon work supported bythe Defense Advanced Research Projects Agencyunder Contract No.
HR0011-06-C-0023 via 27-001022, and the CUNY Research EnhancementProgram and GRTI Program.ReferencesA.
Bagga and B. Baldwin.
1999.
Cross-documentevent coreference: Annotations, experiments, andobservations.
In Proc.
ACL-99 Workshop on Core-ference and Its Applications.C.
Nicolae and G. Nicolae.
2006.
Bestcut: A graphalgorithm for coreference resolution.
In EMNLP,pages 275?283, Sydney, Australia, July.J.
Shi and J. Malik.1997.
Normalized Cuts and ImageSegmentation.
In Proc.
of IEEE Conf.
on Comp.Vision and Pattern Recognition, Puerto RicoK.
Humphreys, R. Gaizauskas, S. Azzam.
1997.Event coreference for information extraction.
InProceedings of the ACL Workshop on OperationalFactors in Practical Robust Anaphora Resolutionfor Unrestricted Texts.N.
Seco, T. Veale, J. Hayes.
2004.
An intrinsic infor-mation content metric for semantic similarity inWordNet.
In Proc.
of ECAI-04, pp.
1089?1090.X.
Luo.
2005.
On coreference resolution performancemetrics.
Proc.
of HLT-EMNLP.57
