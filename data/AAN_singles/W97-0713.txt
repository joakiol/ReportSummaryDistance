From discourse structures to text summariesDanie l  MarcuDepartment  of  Computer  ScienceUmvers l ty  o f  TorontoToronto, Ontar ioCanada MSS 3G4marcu@cs.toronto, eduAbstractWe describe xperiments hat show thatthe concepts of rhetorical nalysts and nu-cleanty can be used effectively for deter-numng the most nnportant umts m a textWe show how these concepts can be xm-plemented and we discuss results that weobtained with a chscourse-based summa-nzatmn program1 MotivationThe evaluaUon of automatic summarizers has alwaysbeen a thorny problem most papers on summanzaUondescribe the approach that they use and give some "con-vmcmg" samples of the output In very few cases, thedtrect output of a suramanzatton program Is comparedwtth a human-made summary or evaluated wtth the helpof human subjects, usually, the results are modest Un-fortunately, evaluatmg the results of a pamcular tmple-mentaUon does not enable one to detenmne what part ofthe fmlure is due to the tmplementatton ttself and whatpart to Rs underlying assumpttons The posmon that wetake m tins paper is that, m order to bmld htgh-quahtysummarization programs, one needs to evaluate not onlya representatave set of automattcally generated outputs (ahtghly chfficult problem by Rself), but also the adequacyof the assumptaons that these programs use That way,one ts able to dtsungmsh t e problems that pertmn to aparttcular implementation from those that pertmn to theunderlying theoretical framework and explore new waysto improve achWith few excepttons, automaUc approaches tosumma-nzatmn have primarily addressed possthle ways to deter-rmne the most mportant parts of a text (see Patce (!990)for an excellent overview) Deterrmnmg the salient partsIS constdered to be achievable because one or more ofthe following assumpuons hold 0) important sentencesm a text contmn words that are used frequently (Luhn,1958, Edmundson, 1968), (n) tmportant sentences con-tam words that are used m the Utle and secuon head-mgs (Edmundson, 1968), On) important sentences arelocated at the begmmng or end of paragraphs (Baxen-dale, 1958), 0v) tmportant sentences are located at posl-Uons m a text hat are genre dependent-- these posluonscan be detenmned automatically, through trmnmg tech-tuques (Lm and Hovy, 1997), (v) important sentences usebq?us words uch as "greatest'~ and "stgmficant" ormdt-cater phrases uch as "the mmn aim of thispaper" and"the purpose of tb~s aruclo", wlule nonqmportant sen-tences use stigma words such as "hardly" and "tmpossl-ble" (Edmundson, 1968, Rush, Salvador, and Zamora,1971), (v0 important sentences and concepts are thelughest connected enttUes m elaborate semantuc struc-tures (Skorochodko, 1971, Lm, 1995, Barzday and E1-hadad, 1997), and (vn) tmportant and nonqmportant sen-tences are derivable from a &scourse representaUon fthe text (Sparck Jones, 1993, One; Surmta, and Mnke,1994)In deterrmnmg the words that occur most frequently ma text or the sentences that use words that occur m theheadings of secttons, computers are accurate tools How-ever, m determmmgthe concepts that are semanucallyrelated or the dtscourse structure of a text, computersare no longer so accurate, rather, they are highly depen-dent on the coverage of the hngmsuc resources that theyuse and the qualRy of the algorithms that they Imple-ment Although ~t ~s plausible that elaborate cohesion-and coherence-based structures can be used effecuvelym summanzauon, we beheve that before bmldmg sum-.manzzat~on programs, we should deterrmne the extent owinch these assumpUons holdIn tins paper, we describe xperiments that show that?
the concepts of rbetoncal analysts and nucleanty can beused effecUvely for deterrmmng the most important umtsm a text We show how these concepts were implementedand discuss results that we obtained with a ?hscourse-based summanzauon program2 From discourse trees to summariesan empirical view2.1 IntroductionResearchers m computauonal imgmsucs (Mann andThompson, 1988, Mattluessen and Thompson, 1988,Sparck Jones, 1993) have long speculated that the nucleithat pertain to a rhetorical structure tree (RS-tree) (Mannand Thompson, 1988) consmute an adequate summanza-82!!UmtI2.
~345789Table I101112131415161718Judges ?~y~te \[ Program1 2 3 4 5 6 7 8 9 10  11 12 13 ....0 2 2 2 0 0 0 0 0 0 0 0 0 3 3 30 0 0 0 0 0 0 0 0 0 0 0 1 1 0 20 2 0 2 0 0 0 0 0 0 0 0 " 1 3 2 32 1 2 2 2 2 2 2 2 2 2 2 2 6 5 61 1 0 1 1 1 0 1 2 1 0 2 2 4 3 40 I 0 1 1 I 0 1 1 1 0 2 2 4 ?3  40 2 1 0 0 0 1 1 1 0 0 0 0 4 3 30 1 0 0 0 0 0 0 0 0 0 0 0 4 3 30 0 2 0 0 0 0 0 0 0 1 0 1 1 0 10 2 2 2 0 0 2 0 0 0 0 0 0 3 4 30 0 0 2 0 0 0 1 0 0 0 0 1 3 4 32 2 2 2 2 2 2 2 2 0 1 2 2 5 4 51 1 0 0 0 1 0 1 0 0 0 2 0 3 3 31 0 0 0 0 1 1 0 0 0 0 2 0 3 3 30 0 0 0 0 1 0 0 0 0 0 1 0 2 3 30 1 .1 0 1 0 0 0 2 0"  0 1 0 4 3 40 I 0 0 0 0 0 0 1 0 0 I 0 2 1 32 1 1 0 1 0 1 0 2 0 I 1 2 4 3 4The scores assigned by the judges, analysts, and our program tothe textual umts m text Ition 0.fthe text for winch that RS-tree was bruit However,to otff knowledge, there was no experiment to confirmhow vahd this speculaUon really is In what follows,?
we desonbe an experiment that shows that there exists astrong correlataon between the nuclei of the RS-tree of atext and what readers perceive to be the most importantumts m a text2.2 Exper iment2.2.1 Materials and methodsWe know from the results reported m the psychologicalhterature on summanzaUon (Johnson, 1970, Chou Hareand Borchardt, 1984, Sherrarck 1989) that there exists acertmn degree of disagreement between readers with re-spect o the importance that they assign to various textualumts and that the ?hsagreement is dependent on the qual-ity of the text and the comprehension a d summarizationslalls of the readers (Wmograd, 1984) In an attempt toproduce an adequate r ference set of data, we selected forour experiment five texts from $czenttflc American thatwe considered to be weU-wntten The texts ranged insize from 161 to 725 words We used square brackets toenclose the wammal textual units (essentially the clauses)of each text Overall, the five texts were broken rote 160textual umts with the shortest text being broken into 18textual umts, and the longest into 70 The shortest text isg!ven in (1), below (here, for the purpose of reference, thermmmal umts are not only enclosed by square brackets,but also are numbered)(1) \[With its &stunt orbit I\] \ [ - -  50 percent farther from thesun than Earth _.2\] \[and shm atmospheric blanket, 3\]\[Mars experiences fngld weather conchaons 4\] \[Sur-face temperatures typically average about -60  degreesCelsius (-76 degrees FahrenheR) at the equator s\] \[andcan ?hp to -123 degrees C near the poles s\] \[Only thenndday sun at tropical latRudes I warm enough to thawIce on eccaslon, ~\] \[but any hqmd water formed ~ thisway would evaporate almost instantly s\] \[because of thelow almosphenc pressure 9\]\[Although t e atmosphere holds a small amount ofwater, i?\] \[and water-ice clouds omeumes develop, H \]\[most Maman weather revolves blowing dust or car-ben &oxide n\] \[Each wmter0 for example, a bhzzardof frozen carbon ?hoxlde rages over one pole, t3\] \[anda few meters of thts dry-wee snow acfumulate 14\] \[aspreviously frozen carbon thoxzde vaporates from theopposite polar cap is\] \[Yet even on the summer pole, Is\]\[where the sun remains m the sky all day long, 17 \] \[tem-peratures never warm enough to melt frozen water ~s\]We followed Garner's (1982) strategy and asked 13independent judges to rate each textual umt accorchngto its importance to a potentml summary The judgesused a three-point scale and assigned a score of 2 to theumts that they beheved to be very nnportant and shouldappear m a concise summary, I to those they consideredmoderately important, whlch should appear m a longsummary, and 0 to those they consldered ummportant,winch should not appear in any summary The judge swere instructed that here were no nght or wrong answersand no upper or lower bounds with respect to the numberof textual umts that they should select as being Importantor moderately important The judges were all graduatestudents m computer sclence, we assumed that they haddeveloped adequate comprehensmn a d summanzauonshl ls  on thelr own, so no trmnmg session was carriedout Table 1 presents the scores that were assigned byeach judge to the umts m text (1)The same texts were also given to two computauonal?
hngmsts with sohd knowledge of rhetoncal structure the-ory (RST) The analysts were asked to bmld one RS-tree83oText 1 2 3 4 5 AllAllumts ~ 70 71Verylmportant.unlts 88 63 65 64 67 66Lessnnportantumts 51 73 54 46 - 58Ummportantunits 75 83 73 73 71 74Table 2 Percent agreement with the majonty opinionfor each text We took then the RS-trees built by the an-alysts and used our formalizaUon of RST (Marcu, 1996,Marcu, 1997b) to assocmte with each.
node m a tree itssal,ent umts The salient umts were computed recur-s~vely, assocmnng with each leaf m an RS-tree the leafitself, and to each internal node the salient umts of thenucleus or nucle~ of the rhetoncal relauon correspon&ngto that node We then computed for each textual umt ascore, depen&ng on the depth m the tree where it oc-curred as a salient umt the textual umts that were sal,entumts of the top nodes m a tree had a Ingher score thanthose that were salient umts of the nodes found at the bot-tom of a tree Essentially, from a rhetorical structure tree,we derived an importance score for each textual umt thelmpoi-tance scores ranged from 0 to n where n was thedepth of the RS-tree i Table 1 presents the scores thatwere derived from the RS-trees that were bmlt by eachanalyst for text (1)2.2.2 ResultsOverall agreement among judges.
We measured theability of judges to agree with one another, using the no-Uon ofpercent agreement that was defined by Gale (1992)and used extensively m &scourse segmentanon stud-les (Passonnean and Lltman, 1993, Hearst, 1994) Per-cent agreement reflects the ratio of observed agreementsvath the majority opmmn to posmble agreements withthe majority opinion The percent agreements computedfor, each of the five texts and each level of ,mportanceare given m table 2 The agreements among judges forour expenment seem to follow the same pattern as thosedescribed by other esearchers msummanzatlon (John-son, 1970) That is, the judges are qmte consistent withrespect o what they perceive as being very Lmportantand unimportant, but less conststent wath respect to whatthey perceive as being less tmportant In contrast with?
the agreement observed among judges, the percentageagreements computed for 1000 ,mportance assignmentsthat were randomly generated for the same texts followeda normal distnbutlon with p = 47 31, (r = 0 04 Theseresults suggest that the agreement among judges ,s ssg-mficantAgreement among judges with respect o the impor-tance of each textual umt.
We considered a textualumt to be labeled con~stendy ifa s,mple majonty of thejudges (~ 7) assigned the same score to that umt Over-Secuon 32 gives an example of how the importance scoreswere computed84all, the judges labeled conmstently 140 of the 160 textualunits (87%) In contrast, a set of 1000 randomly gener-ated importance scores howed agreement, on average,for only 50 of the 160 textual umts (3 I%), o" = 0 05The judges consistently abeled 36 of the umts as veryimportant, 8 as less maportant, and 96 as unmaportantThey were inconsistent with respect to 20 textual unitsFor example, for text (1), thejudges consistently labeledumts 4 and 12 as very important, umts 5 and 6 as less ,m-portant, units 1,2, 3, 7, 8, 9,10,11,13,14,15,17 as umm-portant, and were inconsistent mlabehng umt 18 If wecompute percent agreement figures only for the textualumts for winch at least 7 judges agreed, we get 69%for the units considered very important, 63% for thoseconsidered less important, and 77% for those consideredummportant The overall percent agreement m tins caseis 75%Statistical significance.
It has often been emphasizedthat agreement figures of the hnds computed above couldbe mrslea&ng (Knppendorff, 1980, Passonneau nd Lit-man, 1993) Since the "true" set of lmpertant textualumts cannot be mdependentlyknown, e cannot om-pure how valid the importance ass,gaments of the judgeswere Moreover, although the agreement figures thatwould occur by chance offer a strong mdlcatlon that ourdata are reliable, they do not prowde a prec,se measure-ment ofrehabdltyTo compute a rehablhty figure, we followed the samemethodology as Passonneau and Lltrnan (1993) andHearst (1994) and apphed the Cochran's Q summarystatlsucs to our data (Cochran.
1950) Cochran's testassumes that a set of judges make binary decismns withrespect to a dataset The null hypothesis that he num-ber of judges that take the same declmon is randomly&sttabuted Since Cochran's test is appropriate only forbinary judgments and since our mam goal was to deter-mine a rehablhty figure for the agreement among judgeswith respect o what they believe to be ,mportant, weevaluated two versions of.the data that reflected only oneImportance l vel In the first Version we considered asbeing important the judgments with a score of 2 andunimportant the judgments with a score of 0 and 1 Inthe second version, we consdered as being important thejudgments with a score of 2 and 1 and ummportant thejudgments with a score of 0 EssenUally, we mapped thejudgment matrices of each of the five texts rote matnceswhose elements ranged over only two values 0 and 1After these mod,ficauons were made, we computed foreach version and each text he Cochran stausucs Q, winchapproximates the X z &stnbuuon w,th n - 1 degrees offreedom, where nrs the number of elements mthe datasetIn all cases we obtmned probabflmes that were very lowp < 10 -6 Tins means that the agreement among judgeswas extremely slgmficantAlthough the probainhty was very low for both ver-sions, it was lower for the first Vermon of the modflieddata than for the second Tins means that ,t is more re-hable to consider as important only the units that wereIII?
assigned a score of 2 by a majority of the judgesAs we have already menUoned, our ulumate goal wasto detenmne whether there exists a correlauon between ~the umts that judges find important and the umts thathave nuclear status m the rhetorical structure trees of thesame texts Since the percentage agreement for the umtsthat were consadered very important was higher than thepercentage agreement for the mats that were consaderedless amportant, and since the Cochran's slgmficance com-puted for the first versaon of the mochfied ata was Ingherthat he one computed for the second, we decaded to con-sider the set of 36 textual umts labeled by a majority ofjudges wath 2 as a rehable reference set of importanceumts for the five texts For example, umts 4 and 12 fromtext (1) belong to t/us reference setAgreement between analysts.
Once we detenmnedthe set of textual umts that the judges beheved to beamportant, we needed to detenmne the agreement be-tween the analysts who built the &scourse trees for thefive texts Because we chd not know the &stnbutton ofthe importance scores denved from the thscourse trees,we computed the correlatmn between the analysts by ap-plying Spearman's correlatzon coefficaent on the scoresassociated to each textual umt We interpreted thesescores as ranks on a scale that measures the xmportanceof the umts m a textThe Spearman rank correlauon coefficaent as an alter-naUve to the usual correlauon coefficaent It ~s based onthe ranks of the data, and not on the data itself, so asresastant to outhers The null hypothesis tested by theSpearman coefficient as that two variables are indepen-dent of each other, agmnst the alternative hypothesis thatthe rank of a variable is correlated with the rank of an-other variable The value of the staustlcs ranges from-1 ,  mchcatmg that Ingh ranks of one variable occur withlow ranks of the other variable, through 0, mchcatmg nocorrelauon between the variables, to +1, mchcalzng thatingh ranks of one vanable occur with ingh ranks of theother variableThe Spearman correlauon coefficient between the- ranks assagned for each textual umt on the bases of theRS-trees bmlt by the two analysts was very ingh 0 798,at the p < 0 0001 level of sagmficance The chfferencesbetween the two analysts came mmnly from then" anter-pretaUons of two of the texts the RS-trees 0lone analystnm'Iored the paragraph structure of the texts, while theRS-trees of the other muTored a logical orgamzaUon ofthe text, winch that analyst believed to be amportantAgreement between the analysts and the judges withrespect to the most important textual units.
In orderto detenmne whether there exists any correspondencebetween what readers beheve to be important and thenuclea of the RS-trees, we selected, from each of the fivetexts, the set of textual umts that were labeled as "veryImportant" by a majority of the judges For example,for text (1), we selected umts 4 and 12, a e, 11% of theumts Overall, the judges elected 36 mats as being veryamportant, whach as approximately 22% of the mats an atext The percentages oftmportant umts for the five textswere 11,36, 35, 17, and 22 respecuvelyWe took the maximal scores computed for each textualumt from the RS-trees bruit by each analyst and selecteda percentage of umts that matched the percentage ofIm-portant umts elected by the judges In the cases m winchthere were ues, we selected apercentage ofumts that wasclosest o the one computed for the judges For example,we selected umts 4 and 12, winch represented the mostimportant 11% of umts as reduced from the RS-tree bruitby the first analyst However, we selected only ?
umt 4,winch represented 6% of the most Important umts as re-duced from the RS-tree bmlt by the s.e~nd analyst Thereason for selecting only umt 4 for the second analystwas that umts 10,11, and 12 have the same score - -  4(see table I) If we had selected umts 10,11 and 12 aswell, we wouldhave nded up selecting 22% of the umtsm text (1), winch as farther from 11 than 6 Hence, wedetenmned for each text the set of amportant umts as la-beled byjudges and as denved from the RS-trees of thosetextsWe calculated for each text the recall and precasaon fthe important umts derived from the RS-trees, with re-spect o the umts labeled important by the judges Theoverall recall and precasaon was the same for both ana-lysts 56% recall and 66% precision In contrast, theaverage recall and precasaon for the same percentages ofumts selected randomly 1000 Umes from the same fivetexts were both 25 7%, o- = 0 059In summarizing text, at ~s often useful to consider notonly clauses, but full sentences To account for tbJs, weconsadered tobe ~mportant all the textual units that per-tinned to a sentence that was characterized by at leastone amportant textual umt For example, we labeled asimportant textual umts 1 to 4 m text (I), because theymake up a full sentence and because umt 4 was labeledas nnportant For the adjusted ata, we detenmned agmnthe percentages ofamportant umts for the five texts andwe re-calculated the recall and precasmn for both ana-lysts the recall was 69% and 66% and the preclsaon 82%and 75% respectively In contrast, he average recall andprecisaon for the same percentages ofmats elected ran-domly 1000 ttmes from the same five texts were 38 4%,?r = 0 048 These results confirm that there exasts astrong correlaUon between the nuclea of the RS-trees thatpertmn to a text and what readers perceave asbeing ampor-tant m that text Gaven the values of recall and precasaonthat we obtained, at as plausible that an adequate com-putatmnal treatment of dxscourse theories would providemost of what is needed for selecting accurately the xm-portant umts m a text However, the results also suggestthat RST by atself as not enough if one wants to strive forpeffecUonThe above results not only provade strong evadence thatchscourse theories can be used effecUvely for text sum-manzaUon, but also enable one to derive strategies thatan automaUc summarizer naght follow For example, theSpearman correlauon coofficlent between the judges andthe first analyst, the one who chd not follow the paragraph85structure, was lower than the one between the judges andthe second analyst It follows that most humanjudges aremchned to use the paragraph breaks as valuable sourcesof mformaUon when they mterpret discourse If the mmofa summanzaUon program ss to mmuc human behaxaor,~t seems adequate for the program to take advantage ofthe paragraph structure of the texts that It analyzesCurrently, the rank asstgnment for each textual umt man RS-tree ts done enurely on the basts of the mammaldepth m the tree where that umt as sahent (Marcu, 1996)Our data seem to support the fact that there exists a cor-relatmn also between the types of relatmus that are usedto connect various textual umts and the tmportance ofthose umts m a text We plan to desagn other experimentsthat can provade clearcut evtdence on the nature of thiscorrelauon3 An  RST-based  summar izat ion  program3.1 ImplementationOur summanzauon program rehes on a rhetorical parserthat braids RS-trees for unrestricted texts The mathe-maUcal foundaUons of the rhetorical parsing algorithmrely on a first'order formahzaUon of vahd textl struc-tures (Marcu, 1997h) The assumpUons of the formal-azaUon are the following 1 The elementary umts ofcomplex text structures are non-overlappmg spans of text2 Rhetorical, coherence, and cohessve relauons hold be-tween textual umts of various izes 3 Rel~ons canbe paruuoned into two classes paratacuc and hypotac-uc Paratacuc relauons are those that hold between spansof equal ~mportanee HypotacUc relations are those thathold between a span that s essenual for the writer's pur-pose, I e, a nucleus, and a span that increases the under-standing of the nucleus but is not essenUal for the writer'spurpose, ~ e, a satelhte 4 The abstract structure of mosttexts ts a binary, tree-lake structure 5 If a relaUonholds between two textual spans of the tree structure of atext, that relatton also holds between the most Importantumts of the consUtuent subspans The most ~mportantumts of a textual span are determined recursavely theycorrespond tothe most important umts of the tmmechatesubspans when the relauon that holds between these sub-spans ts paratacUc, and to the most amportant umts of thenucleus ubspan when the relauon that holds between thetmmedtate subspans as hypotaclacThe rhetorical parsmg algorithm, which is outhned mfigure l, is based on a comprehens|ve corpus analysisofmore than 450 discourse markers and 7900 text fragments(see (Marcu, 199To) for detmls) When gwen a text, therhetorical parser detenmnes first the &scourse markersand the elementary umts that make UP that text Theparser uses then the mformatton derived from the cor-pus analysts m order to hypothesize rhetorical relaUonsamong the elementary umts In the end, the parser apphesa constrmnt-saUsfactmn procedure to deterrmne the textstr~tures that are vahd If more than one val|d structureis found, the parser chooses one that s the "best" accord-mg to a gwen metric The detmls of the algorithms thatINPUT a text T1 Deternune the set D of all dtscourse markers m Tand the set Ur of elementary textual nmts m T2 Hypothes|ze a set ofrelataons R between the elementsof Ur3 Deternune the set ValTrees of all vahd RS-trees ofT that can be built using relauons from R4 Deterrmne the "best" RS-tree m VaITrees on thebasts of a metric that assagns Ingher wetghts to the treesthat are more skewed to the rightFigure 1 An outline of the rhetorical parsing algorithm?
~ 78c/~.aa12 P.T.cmphf~caaon '1011~- 1618 Anmhem17Figure 2 The RS-tree of mammal weight built by therhetoncal parser for text (I)are used by the rethoncal parser are &scussed at lengthm (Mareu, 1997a, Marco, I997b)When the rhetoncal parser takes text (1) as mpuL Rproduces the RS-tree m figure 2 The conventaon thatwe use IS that nuclei are surrounded by sohd boxes andsatelhtes by dotted boxes, the hnks between anode anda subordinate nucleus or nuclei are represented bysohdarrows, and the hnks between anode and a subordinatesatelhte by dotted hnes The nodes with only one satel-hte denote occurrences ofparenthetical mformaUon forexample, textual tnnt 2 ss labeled as parenthetacal to thetextual umt that results from juxtaposing 1and 3 Thenumbers assoctated voth each leaf correspond to the nu-.mencal labels m text (1) The numbers assocxated votheach internal node correspond tothe sahent umts of thatnode and are exphcatly represented m the RS-treeBy respecting the RS-tree m figure 2, one can horacethat he trees that are bmlt by the program do not have thesame granulartty as the trees constructed by the analystsFor example, the program treats umts 13,14, and 15 asone elementary umt However, as we argue m (Marcu,1997b), the corpus analysis on winch our parser as bmltsupports the observatton that, m most cases, the globalstructure of the RS-tree as not affected by the mabahty ofthe rbetoncal parser to uncover all clauses m a text86most of  the clauses that are not uncovered are nuclet ofJOn~ relaUonsThe summanzatton program takes the RS-tree pro-duced by the rbetoncal parser and selects the textual umtsthat are most salient m that text If the nim of the programIs to produce just a very short summary, only the salientumts associated with the internal nodes found closer tothe root are selected The longer the summary one wantsto generate, the farther the selected salient umts rol l  befrom the root In fact, one can see that the RS-treesbmlt by the rhetoncal parser educe apamal order on the~mportance of the textual umts For text (1), the mostimportant umt ~s 4 The textual umts that are sahent mthe nodes found one level below represent the next levelof importance (m this case, umt 12 - -  umt 4 was alreadyaccounted for) The next level contains umts 5, 6,16, and18, and so on3.2 Eva luat ionTo evaluate our program, we associated with each textualumt m the RS-trees bmlt by the rhetoncal parser a scorem the same way we did for the RS-trees bmlt by theanalysts For example, the RS-tree m figure 2 has a depthof 6 Because umt 4 is salient for the root, ~t gets ascore of 6 Units 5, 6 are salient for an internal nodefound two levels below the root therefore, thmr score Is4 Umt 9 Is salient for a leaf found five levels below theroot therefore, ~ts core ~s 1 Table I presents the scoresassociated by our summanzauon program to each umt mtext (1)We used the importance scores assigned by our pro-gram to compute staUst~cs s~rmlar to those discussed mthe prevmus ecUon When the program selected onlythe textual umts w~th the highest scores, m percentagesthat were equal to those of the judges, the recall was 53%and the preclslon was 50% When the program selectedthe full sentences that were asseclated w~th the most im-portant umts, m percentages that were equal to those ofthe judges, the recall was 66% and the precls~on 68%The lower recall and precision scores associated w~thclauses eem to be caused primarily by the difference mgranularity w~th respect to the way the texts were brokeninto subumts the program does not recover all rmmmaltextual umts, and as a consequence, ~ts assignment ofimportance scores ~s coarser When full sentences areconsidered, the judges and the program work at the Samelevel of granularity, and as a consequence, the summa-nzauon results tmprove s~gmficantly4 Comparison with other workWe are not aware of any RST-based summanzatlon pro-gram for Enghsh However, Ono et al(1994) discussa summanzaUon program for Japanese whose m~mmaltextual umts are sentences Due to the differences be-tween Enghsh and Japanese, R was impossible for us tocompare Ono's summarizer wtth ours Fundamental dif-ferences concerning the assumpttons that underhe Ono'sworkand ours are discussed at length m (Mareu, 1997b)87, Umt typeClauses~ SentencesTable 3Recall PrecisionRandom 25 7 25 7Microsoft 28  26Summarizer "Our  snmmanzer  53 50Analysts 56 66"Random 38 4 38 4MierosoR 41 39SummarizerOur  summarizer  66 68Analysts .
67 5 78 5An evaluauon of our summarization programWe were able to obtmn only one other program thatsummarizes Enghsh text m the one included m the Ma-crosoft Office97 package We run the Microsoft summa-nzaUon program on the five texts from Sczent~fic Amer-scan and selected the same percentages of textual umtsas those considered Important by the judges When weselected percentages of text that corresponded only to theclauses considered important by the judges, the lVherosoftprogram recalled 28% of the umts, with a prec~slon of26% When we selected percentages of text that corre-sponded to Sentences considered lmportsnt by thejudgus,the Microsoft program recalled 41% of the units, wxth aprecision of 39% All Microsoft figures are only shghtlyabove those that correspond to the basehne algorithmsthat select Hnportant umts randomly It follows that ourprogram outperforms slgmficantly the one found m theOffice97 packageWe are not aware of any other summanzatton programthat can bmld summaries with granularity as fine as aclause (as our program can)5 ConclusionsWe deserthed the first experiment that shows that he con-cepts of rhetorical analysts and nucleanty can be used ef-fecUvely for suramannng text The expemnent suggeststhat discourse-based methods can account for determin-ing the most zmportant umts m a text w~th a recall andprecision as high as 70% We Showed how the concepts ofrbetoncal analysts and nucleanty can be treated algonth-mtcally and we compared recall and preclsmn figures of asummanzauon program that implements hese conceptswith recall and prects~on figures that pertmn to a basehnealgonthm and to a c6mmerclal system, the MlcrosoR Of.rice97 summarizer The discourse-based summanzauonprogram that we propose outperforms both the basehneand the commercial summarizer (see table 3) However,since ~ts results do not match yet the recall and precisionfigures that pertmn to the manual discourse analyses, ztzs likely that improvements of the rhetorical parser al-gorithm wall result m better performance of subsequentLmplemetat~onsAcknowledgements.
I am grateful to Graeme Htrst forthe .invaluable help he gave me dunng every stage oftins work and to Marllyn Mantel, David Mitchell, KevmSchlueter, and Melame Baljko for their advice on ex-perimental design and stanstlcs I am also grateful toMarzena Makuta for her help with the RST analyses andto my colleagues and friends who volunteered toact asjudges m the experiments described hereTins reasearch was supported by the Natural Sciencesand Engineering Research Council of CanadaReferencesBarzalay, Regina and Mtchael Elhadad 1997 UsingLexlcal Chmns for Text Summanzauon In Proceed-mgs of the ACL'97/EACL'97 Workshop on lntelhgentScalable Text SummanzattonBaxendale, PB ' 1958 Macinne-mademdexfortechmcalhterature m an experiment IBM Journal of Researchand Development, 2 354-361Chou Hare, Vlctona and Kathleen M Borchardt 1984Direct instruction of summanzaUon skzIls ReadmgResearch Quarterly, 20(1) 62-78, FallCochran, WG 1950 The comparison of percentages mmatched samples Btometrtka, 37256-266Edmundson, H P 1968 New methods m automatic ex:tractmg Journal of the Assoclatton for CompuungMachinery, 16(2) 264-285, AprilGale, Wfiham, Kenneth W Church, and Dawd Yarowsky1992 Esumatzng upper and lower bounds on the per-formance of word-sense disamblguataon programs InProceedings ofthe 30th Annual Meetmg of the Assoct-atwn for Computatwnal Lmgmstws (ACL-92), pages249--256Garner, Rutli 1982 Efficient text summanzauoncosts and benefits Journal of FEducanonal Research,75 275-279Hearst, Marta 1994 Multa-paragraph segmecntauon ofexpository text In Proceedmgs ofthe 32nd AnnualMeenng of the Assoczanon for ComputanonaI Lmgms-tws, pages 9-16, Las Cruces, New Mexico, June 27-30Johnson, RonaldE 1970 Recall of prose as a funcuonof structural importance of hngmsUc umts Journal ofVerbal Learning and Verbal Behavwur, 9 12-20Knppendorff, Klaus 1980 Content analys~s An Intro-ductton to tts Methodology Sage Pubhcatmns, Bev-erly Hills, CALan, Chin-Yew 1995 Knowledge-based automauc topmldenUficutton In Proceedings of the 33rd AnnualMeenng of.the AssoclaUon for Computanonal Lm-gmsttcs (ACL-95), pages 308-310, Cambridge, Mas-sachusetts, June 26-~30Lm, Chin-Yew and Eduard Hovy 1997 Idenufymg top-lcs by posmon In Proceedings ofthe Fifth Conferenceon Apphed Natural Language Processing (ANLP-97),pages 283-290, Washington, DC, March 31 - April 388Luhn, H P 1958 The automatac creation of hteratureabstracts IBM Journal of Research and Development,2(2) 159-165, AprilMann, Wllham C and Sandra A Thompson 1988Rhetorical structure theory Toward a funclaonal the-ory of text orgamzaUon Text, 8(3) 243-281Marcu, Darnel 1996 Btalchng up rhetorical structuretrees In Pwceedmgs ofthe Thwteenth Natzonal Con-ference on Arufictal lntelhgence (AAAI-96), volume 2,pages 1069-1074, Portland, Oregon, August 4-8,Marcu, Darnel 1997a The rhetorical parsing of natu-ral language texts In Pwceedmgs of the 35th AnnualMeenng of the Assoctatwn for Computatlonal Lmgms-tws (ACIIEACL-97), Madrid, Spmn, July.
7-I0Marcu, Darnel 1997b The rhetorical parsing, sum-manzanon, and generatwn ofnatural language t xtsPh D thesis, Department ofComputer Science, Um-verslty of Toronto, ForthconungMattinessen, Chnsuan and Sandra A Thompson 1988The structure of dtscourse and 'subordmauon' InJ Hmman and S A Thompson, editors, Clause com-bining m grammar nd dzscourse, volume 18 of Typo-logwal Studtes m Language John Benjanuns Pubhsh-mg Company, pages 275-329On0, Kenjl, Kazuo Sunuta, and Seljl Mnke 1994 Ab-stract generation based on rhetorical structure xtrac-Uon In Proceedings ofthe lnternatwnal Conferenceon Computanonal Lmgmstws ( Cohng-94),pages 3A A.348, JapanPmce, Chris D 1990 Construcung hterature abstractsby computer techmques and prospects InformatwnProcessmg and Management, 26(1) 171-186Passonneau, Rebecca J and Diane J Lltman 1993Intenuon-based segmentation human rehabfllty andcorrelatton wtth hngmsUc ues In Proceedings ofthe31st Annual Meeting of the Assocmnon for Computa-nonalLmgmsttcs, pages 148-155, Oino, June 22-26Rush, JE ,  R Salvador, and A Zamora 1971 Auto-matac abstracting and indexing PtoducUon of mdlca-Uve abstracts by apphcauon of contextual referenceand syntacuc coherence criteria Journal of AmerwanSociety for lnformanon Sctences, 22(4) 260-274Sherrard, Carol 1989 Teaching students to summarizeApplying texthngulstlcs System, 17(1) ?.
Skorochodko, E F 1971 Adaptive method of automaticabstracung and indexing In lnformatwn Processing,volume 2, pages 1179-1182 North-Holland Pubhsh-mg CompanySparck Jones, Karen 1993 What nught be m asummary') In Informatwn Retrieval 93 VonderModelherung zur Anwendung, pages 9-26, Umver-sltatsverlag KonstanzWmograd, Peter N 1984 Strategic hfiicultaes msummanzang texts Reading Research Quaterly,19(4) 40~ ~25, Summer
