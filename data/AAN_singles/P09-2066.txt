Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 261?264,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPFrom Extractive to Abstractive Meeting Summaries: Can It Be Done bySentence Compression?Fei Liu and Yang LiuComputer Science DepartmentThe University of Texas at DallasRichardson, TX 75080, USA{feiliu, yangl}@hlt.utdallas.eduAbstractMost previous studies on meeting summariza-tion have focused on extractive summariza-tion.
In this paper, we investigate if we canapply sentence compression to extractive sum-maries to generate abstractive summaries.
Weuse different compression algorithms, includ-ing integer linear programming with an addi-tional step of filler phrase detection, a noisy-channel approach using Markovization for-mulation of grammar rules, as well as hu-man compressed sentences.
Our experimentson the ICSI meeting corpus show that whencompared to the abstractive summaries, usingsentence compression on the extractive sum-maries improves their ROUGE scores; how-ever, the best performance is still quite low,suggesting the need of language generation forabstractive summarization.1 IntroductionMeeting summaries provide an efficient way for peopleto browse through the lengthy recordings.
Most cur-rent research on meeting summarization has focused onextractive summarization, that is, it extracts importantsentences (or dialogue acts) from speech transcripts, ei-ther manual transcripts or automatic speech recogni-tion (ASR) output.
Various approaches to extractivesummarization have been evaluated recently.
Popularunsupervised approaches are maximum marginal rele-vance (MMR), latent semantic analysis (LSA) (Mur-ray et al, 2005a), and integer programming (Gillick etal., 2009).
Supervised methods include hidden Markovmodel (HMM), maximum entropy, conditional ran-dom fields (CRF), and support vector machines (SVM)(Galley, 2006; Buist et al, 2005; Xie et al, 2008;Maskey and Hirschberg, 2006).
(Hori et al, 2003) useda word based speech summarization approach that uti-lized dynamic programming to obtain a set of words tomaximize a summarization score.Most of these summarization approaches aim forselecting the most informative sentences, while lessattempt has been made to generate abstractive sum-maries, or compress the extracted sentences and mergethem into a concise summary.
Simply concatenatingextracted sentences may not comprise a good sum-mary, especially for spoken documents, since speechtranscripts often contain many disfluencies and are re-dundant.
The following example shows two extractivesummary sentences (they are from the same speaker),and part of the abstractive summary that is related tothese two extractive summary sentences.
This is an ex-ample from the ICSI meeting corpus (see Section 2.1for more information on the data).Extractive summary sentences:Sent1: um we have to refine the tasks more and more whichof course we haven?t done at all so far in order to avoid thisrephrasingSent2: and uh my suggestion is of course we we keep thewizard because i think she did a wonderful jobCorresponding abstractive summary:the group decided to hire the wizard and continue with therefinement...In this paper, our goal is to answer the question ifwe can perform sentence compression on an extrac-tive summary to improve its readability and make itmore like an abstractive summary.
Compressing sen-tences could be a first step toward our ultimate goalof creating an abstract for spoken documents.
Sen-tence compression has been widely studied in languageprocessing.
(Knight and Marcu, 2002; Cohn and Lap-ata, 2009) learned rewriting rules that indicate whichwords should be dropped in a given context.
(Knightand Marcu, 2002; Turner and Charniak, 2005) appliedthe noisy-channel framework to predict the possibil-ities of translating a sentence to a shorter word se-quence.
(Galley and McKeown, 2007) extended thenoisy-channel approach and proposed a head-drivenMarkovization formulation of synchronous context-free grammar (SCFG) deletion rules.
Unlike these ap-proaches that need a training corpus, (Clarke and La-pata, 2008) encoded the language model and a varietyof linguistic constraints as linear inequalities, and em-ployed the integer programming approach to find a sub-set of words that maximize an objective function.Our focus in this paper is not on new compression al-gorithms, but rather on using compression to bridge thegap of extractive and abstractive summarization.
Weuse different automatic compression algorithms.
Thefirst one is the integer programming (IP) framework,where we also introduce a filler phrase (FP) detection261module based on the Web resources.
The second oneuses the SCFG that considers the grammaticality of thecompressed sentences.
Finally, as a comparison, wealso use human compression.
All of these compressedsentences are compared to abstractive summaries.
Ourexperiments using the ICSI meeting corpus show thatcompressing extractive summaries can improve humanreadability and the ROUGE scores against the refer-ence abstractive summaries.2 Sentence Compression of ExtractiveSummaries2.1 CorpusWe used the ICSI meeting corpus (Janin et al, 2003),which contains naturally occurring meetings, eachabout an hour long.
All the meetings have been tran-scribed and annotated with dialogue acts (DAs), top-ics, abstractive and extractive summaries (Shriberg etal., 2004; Murray et al, 2005b).
In this study, we usethe extractive and abstractive summaries of 6 meetingsfrom this corpus.
These 6 meetings were chosen be-cause they have been used previously in other relatedstudies, such as summarization and keyword extraction(Murray et al, 2005a).
On average, an extractive sum-mary contains 76 sentences1(1252 words), and an ab-stractive summary contains 5 sentences (111 words).2.2 Compression Approaches2.2.1 Human CompressionThe data annotation was conducted via Amazon Me-chanical Turk2.
Human annotators were asked to gen-erate condensed version for each of the DAs in the ex-tractive summaries.
The compression guideline is sim-ilar to (Clarke and Lapata, 2008).
The annotators wereasked to only remove words from the original sentencewhile preserving most of the important meanings, andmake the compressed sentence as grammatical as pos-sible.
The annotators can leave the sentence uncom-pressed if they think no words need to be deleted; how-ever, they were not allowed to delete the entire sen-tence.
Since the meeting transcripts are not as readableas other text genres, we may need a better compressionguideline for human annotators.
Currently we let theannotators make their own judgment what is an appro-priate compression for a spoken sentence.We split each extractive meeting summary sequen-tially into groups of 10 sentences, and asked 6 to 10online workers to compress each group.
Then fromthese results, another human subject selected the bestannotation for each sentence.
We also asked this hu-man judge to select the 4-best compressions.
However,in this study, we only use the 1-best annotation result.We would like to do more analysis on the 4-best resultsin the future.1The extractive units are DAs.
We use DAs and sentencesinterchangeably in this paper when there is no ambiguity.2http://www.mturk.com/mturk/welcome2.2.2 Filler Phrase DetectionWe define filler phrases (FPs) as the combination oftwo or more words, which could be discourse markers(e.g., I mean, you know), editing terms, as well as someterms that are commonly used by human but withoutcritical meaning, such as, ?for example?, ?of course?,and ?sort of?.
Removing these fillers barely causes anyinformation loss.
We propose to use web informationto automatically generate a list of filler phrases and fil-ter them out in compression.For each extracted summary sentence of the 6 meet-ings, we use it as a query to Google and examine the topN returned snippets (N is 400 in our experiments).
Thesnippets may not contain all the words in a sentencequery, but often contain frequently occurring phrases.For example, ?of course?
can be found with high fre-quency in the snippets.
We collect all the phrases thatappear in both the extracted summary sentences and thesnippets with a frequency higher than three.
Then wecalculate the inverse sentence frequency (ISF) for thesephrases using the entire ICSI meeting corpus.
The ISFscore of a phrase i is:isfi=NNiwhere N is the total number of sentences and Niis thenumber of sentences containing this phrase.
Phraseswith low ISF scores mean that they appear in many oc-casions and are not domain- or topic-indicative.
Theseare the filler phrases we want to remove to compressa sentence.
The three phrases we found with the low-est ISF scores are ?you know?, ?i mean?
and ?i think?,consistent with our intuition.We also noticed that not all the phrases with lowISF scores can be taken as FPs (?we are?
would be acounter example).
We therefore gave the ranked list ofFPs (based on ISF values) to a human subject to selectthe proper ones.
The human annotator crossed out thephrases that may not be removable for sentence com-pression, and also generated simple rules to shortensome phrases (such as turning ?a little bit?
into ?a bit?
).This resulted in 50 final FPs and about a hundred sim-plification rules.
Examples of the final FPs are: ?youknow?, ?and I think?, ?some of?, ?I mean?, ?so far?, ?itseems like?, ?more or less?, ?of course?, ?sort of?, ?soforth?, ?I guess?, ?for example?.
When using this listof FPs and rules for sentence compression, we also re-quire that an FP candidate in the sentence is consideredas a phrase in the returned snippets by the search en-gine, and its frequency in the snippets is higher than apre-defined threshold.2.2.3 Compression Using Integer ProgrammingWe employ the integer programming (IP) approach inthe same way as (Clarke and Lapata, 2008).
Given anutterance S = w1, w2, ..., wn, the IP approach forms acompression of this utterance only by dropping wordsand preserving the word sequence that maximizes anobjective function, defined as the sum of the signifi-262cance scores of the consisting words and n-gram prob-abilities from a language model:max ?
?n?i=1yi?
Sig(wi)+ (1 ?
?)
?n?2?i=0n?1?j=i+1n?k=j+1xijk?
P (wk|wi, wj)where yiand xijkare two binary variables: yi= 1represents that word wiis in the compressed sentence;xijk= 1 represents that the sequence wi, wj, wkis in the compressed sentence.
A trade-off parameter?
is used to balance the contribution from the signif-icance scores for individual words and the languagemodel scores.
Because of space limitation, we omit-ted the special sentence beginning and ending symbolsin the formula above.
More details can be found in(Clarke and Lapata, 2008).
We only used linear con-straints defined on the variables, without any linguisticconstraints.We use the lp solve toolkit.3The significance scorefor each word is its TF-IDF value (term frequency ?inverse document frequency).
We trained a languagemodel using SRILM4on broadcast news data to gen-erate the trigram probabilities.
We empirically set ?
as0.7, which gives more weight to the word significancescores.
This IP compression method is applied to thesentences after filler phrases (FPs) are filtered out.
Werefer to the output from this approach as ?FP + IP?.2.2.4 Compression Using Lexicalized MarkovGrammarsThe last sentence compression method we use is thelexicalized Markov grammar-based approach (Galleyand McKeown, 2007) with edit word detection (Char-niak and Johnson, 2001).
Two outputs were generatedusing this method with different compression rates (de-fined as the number of words preserved in the com-pression divided by the total number of words in theoriginal sentence).5We name them ?Markov (S1)?
and?Markov (S2)?
respectively.3 ExperimentsFirst we perform human evaluation for the compressedsentences.
Again we use the Amazon Mechanical Turkfor the subjective evaluation process.
For each extrac-tive summary sentence, we asked 10 human subjects torate the compressed sentences from the three systems,as well as the human compression.
This evaluation wasconducted on three meetings, containing 244 sentencesin total.
Participants were asked to read the originalsentence and assign scores to each of the compressedsentences for its informativeness and grammaticalityrespectively using a 1 to 5 scale.
An overall score iscalculated as the average of the informativeness andgrammaticality scores.
Results are shown in Table 1.3http://www.geocities.com/lpsolve4http://www.speech.sri.com/projects/srilm/5Thanks to Michel Galley to help generate these output.For a comparison, we also include the ROUGE-1 F-scores (Lin, 2004) of each system output against thehuman compressed sentences.Approach Info.
Gram.
Overall R-1 F (%)Human 4.35 4.38 4.37 -Markov (S1) 3.64 3.79 3.72 88.76Markov (S2) 2.89 2.76 2.83 62.99FP + IP 3.70 3.95 3.82 85.83Table 1: Human evaluation results.
Also shown is theROUGE-1 (unigram match) F-score of different sys-tems compared to human compression.We can see from the table that as expected, the hu-man compression yields the best performance on bothinformativeness and grammaticality.
?FP + IP?
and?Markov (S1)?
approaches also achieve satisfying per-formance under both evaluation metrics.
The relativelylow scores for ?Markov (S2)?
output are partly due toits low compression rate (see Table 2 for the length in-formation).
As an example, we show below the com-pressed sentences from human and systems for the firstsentence in the example in Sec 1.Human: we have to refine the tasks in order to avoidrephrasingMarkov (S1): we have to refine the tasks more and morewhich we haven?t done in order to avoid this rephrasingMarkov (S2): we have to refine the tasks which we haven?tdone order to avoid this rephrasingFP + IP: we have to refine the tasks more and more whichwe haven?t done to avoid this rephrasingSince our goal is to answer the question if we canuse sentence compression to generate abstractive sum-maries, we compare the compressed summaries, aswell as the original extractive summaries, against thereference abstractive summaries.
The ROUGE-1 re-sults along with the word compression ratio for eachcompression approach are shown in Table 2.
We cansee that all of the compression algorithms yield bet-ter ROUGE score than the original extractive sum-maries.
Take Markov (S2) as an example.
The recallrate dropped only 8% (from the original 66% to 58%)when only 53% words in the extractive summaries arepreserved.
This demonstrates that it is possible for thecurrent sentence compression systems to greatly con-dense the extractive summaries while preserving thedesirable information, and thus yield summaries thatare more like abstractive summaries.
However, sincethe abstractive summaries are much shorter than the ex-tractive summaries (even after compression), it is notsurprising to see the low precision results as shown inTable 2.
We also observe some different patterns be-tween the ROUGE scores and the human evaluationresults in Table 1.
For example, Markov (S2) has thehighest ROUGE result, but worse human evaluationscore than other methods.To evaluate the length impact and to further make263All Sent.
Top Sent.Approach Word ratio (%) P(%) R(%) F(%) P(%) R(%) F(%)Original extractive summary 100 7.58 66.06 12.99 29.98 34.29 31.83Human compression 65.58 10.43 63.00 16.95 34.35 37.39 35.79Markov (S1) 67.67 10.15 61.98 16.41 34.24 36.88 35.46Markov (S2) 53.28 11.90 58.14 18.37 32.23 34.96 33.49FP + IP 76.38 9.11 59.85 14.78 31.82 35.62 33.57Table 2: Compression ratio of different systems and ROUGE-1 scores compared to human abstractive summaries.the extractive summaries more like abstractive sum-maries, we conduct an oracle experiment: we computethe ROUGE score for each of the extractive summarysentences (the original sentence or the compressed sen-tence) against the abstract, and select the sentenceswith the highest scores until the number of selectedwords is about the same as that in the abstract.6TheROUGE results using these selected top sentences areshown in the right part of Table 2.
There is some dif-ference using all the sentences vs. the top sentencesregarding the ranking of different compression algo-rithms (comparing the two blocks in Table 2).From Table 2, we notice significant performance im-provement when using the selected sentences to form asummary.
These results indicate that, it may be possi-ble to convert extractive summaries to abstractive sum-maries.
On the other hand, this is an oracle result sincewe compare the extractive summaries to the abstract forsentence selection.
In the real scenario, we will needother methods to rank sentences.
Moreover, the currentROUGE score is not very high.
This suggests that thereis a limit using extractive summarization and sentencecompression to form abstractive summaries, and thatsophisticated language generation is still needed.4 ConclusionIn this paper, we attempt to bridge the gap between ex-tractive and abstractive summaries by performing sen-tence compression.
Several compression approachesare employed, including an integer programming basedframework, where we also introduced a filler phrase de-tection module, the lexicalized Markov grammar-basedapproach, as well as human compression.
Results showthat, while sentence compression provides a promisingway of moving from extractive summaries toward ab-stracts, there is also a potential limit along this direc-tion.
This study uses human annotated extractive sum-maries.
In our future work, we will evaluate using auto-matic extractive summaries.
Furthermore, we will ex-plore the possibility of merging compressed extractivesentences to generate more unified summaries.ReferencesA.
Buist, W. Kraaij, and S. Raaijmakers.
2005.
Automaticsummarization of meeting data: A feasibility study.
InProc.
of CLIN.6Thanks to Shasha Xie for generating these results.E.
Charniak and M. Johnson.
2001.
Edit detection and pars-ing for transcribed speech.
In Proc.
of NAACL.J.
Clarke and M. Lapata.
2008.
Global inference for sentencecompression: An integer linear programming approach.Journal of Artificial Intelligence Research, 31:399?429.T.
Cohn and M. Lapata.
2009.
Sentence compression as treetransduction.
Journal of Artificial Intelligence Research.M.
Galley and K. McKeown.
2007.
Lexicalized markovgrammars for sentence compression.
In Proc.
ofNAACL/HLT.M.
Galley.
2006.
A skip-chain conditional random fieldfor ranking meeting utterances by importance.
In Proc.of EMNLP.D.
Gillick, K. Riedhammer, B. Favre, and D. Hakkani-Tur.2009.
A global optimization framework for meeting sum-marization.
In Proc.
of ICASSP.C.
Hori, S. Furui, R. Malkin, H. Yu, and A. Waibel.
2003.A statistical approach to automatic speech summarization.Journal on Applied Signal Processing, 2003:128?139.A.
Janin, D. Baron, J. Edwards, D. Ellis, G. Gelbart, N. Mor-gan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke, andC.
Wooters.
2003.
The ICSI meeting corpus.
In Proc.of ICASSP.K.
Knight and D. Marcu.
2002.
Summarization beyondsentence extraction: A probabilistic approach to sentencecompression.
Artificial Intelligence, 139:91?107.C.
Lin.
2004.
Rouge: A package for automatic evaluationof summaries.
In Proc.
of ACL Workshop on Text Summa-rization Branches Out.S.
Maskey and J. Hirschberg.
2006.
Summarizing speechwithout text using hidden markov models.
In Proc.
ofHLT/NAACL.G.
Murray, S. Renals, and J. Carletta.
2005a.
Extractivesummarization of meeting recordings.
In Proc.
of INTER-SPEECH.G.
Murray, S. Renals, J. Carletta, and J. Moore.
2005b.
Eval-uating automatic summaries of meeting recordings.
InProc.
of ACL 2005 MTSE Workshop.E.
Shriberg, R. Dhillon, S. Bhagat, J. Ang, and H. Carvey.2004.
The ICSI meeting recorder dialog act (MRDA)corpus.
In Proc.
of SIGdial Workshop on Discourse andDialogue.J.
Turner and E. Charniak.
2005.
Supervised and unsuper-vised learning for sentence compression.
In Proc.
of ACL.S.
Xie, Y. Liu, and H. Lin.
2008.
Evaluating the effective-ness of features and sampling in extractive meeting sum-marization.
In Proc.
of IEEE Workshop on Spoken Lan-guage Technology.264
