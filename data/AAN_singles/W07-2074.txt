Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 342?345,Prague, June 2007. c?2007 Association for Computational LinguisticsUBC-ALM: Combining k-NN with SVD for WSDEneko Agirre and Oier Lopez de LacalleIXA NLP GroupUniversity of the Basque CountryDonostia, Basque Country{e.agirre,jibloleo}@ehu.esAbstractThis work describes the University of theBasque Country system (UBC-ALM) forlexical sample and all-words WSD subtasksof SemEval-2007 task 17, where it per-formed in the second and fifth positions re-spectively.
The system is based on a com-bination of k-Nearest Neighbor classifiers,with each classifier learning from a distinctset of features: local features (syntactic, col-locations features), topical features (bag-of-words, domain information) and latent fea-tures learned from a reduced space usingSingular Value Decomposition.1 IntroductionOur group (UBC-ALM) participated in the lexicalsample and all-words WSD subtasks of SemEval-2007 task 17.
We applied a combination of differentk-Nearest Neighbor (k-NN) classifiers.
Each clas-sifier manages different information sources (fea-tures), making the combination a powerful solution.This algorithm was previously tested on the datasetsfrom previous editions of Senseval (Agirre et al,2005; Agirre et al, 2006).
Before submission, theperformance of the system was tested on the Se-mEval lexical sample training data.
For learning weuse a rich set of features, including latent featuresobtained from a reduced space using Singular ValueDecomposition (SVD).This paper is organized as follows.
The learningfeatures are presented in section 2, and the learningalgorithm and the combinations of single k-NNs aregiven in section 3.
Section 4 focuses on the tuningexperiments.
Finally, section 5 summarizes the offi-cial results and some conclusions.2 Feature setWe relied on an extensive set of features of differ-ent types, obtained by means of different tools andresources.
We defined two main groups: the origi-nal features extracted directly from the text, and theSVD features obtained after applying SVD decom-position and projecting the original features into thenew semantic space (Agirre et al, 2005).2.1 Original featuresLocal collocations: bigrams and trigrams formedwith the words around the target.
These features areconstituted by lemmas, word-forms, or PoS tags1.Other local features are those formed with the previ-ous/posterior lemma/word-form in the context.Syntactic dependencies: syntactic dependencieswere extracted using heuristic patterns, and regularexpressions defined with the PoS tags around the tar-get2.
The following relations were used: object, sub-ject, noun-modifier, preposition, and sibling.Bag-of-words features: we extract the lemmasof the content words in the whole context, and in a?4-word window around the target.
We also obtainsalient bigrams in the context, with the methods andthe software described in (Pedersen, 2001).Domain features: The WordNet Domains re-source was used to identify the most relevant do-mains in the context.
Following the relevance for-mula presented in (Magnini and Cavaglia?, 2000), wedefined 2 feature types: (1) the most relevant do-main, and (2) a list of domains above a predefinedthreshold3 .1The PoS tagging was performed with the fnTBL toolkit(Ngai and Florian, 2001).2This software was kindly provided by David Yarowsky?sgroup, from Johns Hopkins University.3The software to obtain the relevant domains was kindlyprovided by Gerard Escudero?s group, from Universitat Politec-3422.2 SVD featuresSingular Value Decomposition (SVD) is an interest-ing solution to the sparse data problem.
This tech-nique reduces the dimensions of the vectorial spacefinding correlations and collapsing features.
It alsogives the chance to use unlabeled data as an addi-tional source of correlations.M ?
Rm?n, a matrix of features-by-document isbuilt from the training corpus and decomposed intothree matrices, as shown in Eq.
(1).
U and V , rowand column matrix, respectively, have orthonormalcolumns and ?
is a diagonal matrix which containsk eigenvalues in descending order.M = U?V T =k=min{m,n}?i=1?iuiviT (1)We used the singular value matrix (?)
and thecolumn matrix (U ) to create a projection matrix,which is used to project the data (represented in fea-tures vectors) from the original space to a reducedspace.
Prior to that we selected the first p columnsfrom the ?
and U matrices (p < k): ~tp = ~tTUp?
?1pWe have explored two different variants in orderto build a matrix, and obtain the SVD features:SVD One Matrix per Target word (SVD-OMT).
For each word (i) we extracted all the fea-tures from the given training (test) corpus, (ii) builtthe feature-by-document matrix from training cor-pus, (iii) decomposed it with SVD, and (iv) projectall the training (test) data.
Note that this variant hasbeen only used in the lexical sample task due to itscostly computational requirements.SVD Single Matrix for All target words (SVD-SMA): (i) we extracted bag-of-words features fromthe British National Corpus (BNC) (Leech, 1992),(ii) built the feature-by-document matrix, (iii) de-compose it with SVD, and (iv) project all the data(train/test).3 Learning AlgorithmThe machine learning (ML) algorithm presented inthis section rely on the previously described fea-tures.
Each occurrence or instance is represented bythe features found in the context (fi).
Given an oc-currence of a word, the ML method below returns anica de Catalunyaweight for each sense (weight(sk)).
The sense withmaximum weight will be selected.We use a set of combination of the k-NearestNeighbor (k-NN) to tag the target words in both thelexical sample and all-words tasks.3.1 k-Nearest Neighbork-NN is a memory-based learning method, wherethe neighbors are the k most similar contexts, repre-sented by feature vectors (~ci), of the test vector (~f ).The similarity among instances is measured by thecosine of their vectors.
The test instance is labeledwith the sense obtaining the maximum sum of theweighted votes of the k most similar contexts.
Thevote is weighted depending on its (neighbor) posi-tion in the ordered rank, with the closest being first.Eq.
(2) formalizes k-NN, where Ci corresponds tothe sense label of the i-th closest neighbor.arg maxSj=k?i=1{1i if Ci = Sj0 otherwise (2)3.2 k-NN combinations and feature splitsAs seen in section 2 we use a variety of heteroge-neous sets of features.
Our previous experience hasshown that splitting the problem up into more co-herent spaces, training different classifiers in eachfeature space, and then combining them into a sin-gle classifier is a good way to improve the results(Agirre et al, 2005; Agirre et al, 2006).
Depend-ing on the feature type (original features or featuresextracted from SVD projection) we split differentsets of feature spaces.
In total we tried 10 featuresspaces.For the original features:?
all feats: Extracted all original features.?
all notdom: All original features except do-main features.?
local: All the original features except domainand bag-of-words features.?
topic: The sum of bag-of-words and domainfeatures.?
bow: Bag-of-word features.?
dom: Domain features.343Combination accuracyall feats+topic+local+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.8all feats+all notdom+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.7all feats+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.5all notdom+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.5all feats+all notdom+topic+local 88.4all notdom+local+SVD-SMA 88.3all feats+all notdom+local+SVD-SMA 88.2all notdom+topic+local 88.1all feats+topic+local 88.1word-by-word optimization 89.5Table 1: Result for the best k-NN combinations in 3 fold cross-validation SemEval lexical sample.For the SVD features:?
SVD-OMT[all feats]: OMT matrix applied toall original features.?
SVD-OMT[local]: OMT matrix to the localoriginal features.?
SVD-OMT[topic]: OMT matrix to the topicoriginal features.?
SVD-SMA: Features obtained from the projec-tion of bow features with the SMA matrix.Depending on the ML method one can try differ-ent approaches to combine classifiers.
In this work,we exploited the fact that a k-NN classifier can beseen as k points casting each one vote.
The votesare weigthed by the inverse ratio of its position inthe rank (k ?
ri + 1)/k, where ri is the rank.
Eachof the k-NN classifiers is trained on a different fea-ture space and then combined.4 Experiments on training dataWe optimized and tuned the system differently foreach kind of tasks.
We will examine each in turn.4.1 Optimization for the lexical sample taskFor the lexical sample task we only use the train-ing data provided.
We tuned the classifiers using 3fold cross-validation on the SemEval lexical sampletraining data.
We tried to optimize several param-eters: number of neighbors, SVD dimensions andbest combination of the single k-NNs.
We set k asone of 1, 3, 5 and 7, and the SVD dimension (d) asone of 50, 100, 200 and 300.
We also fixed the bestcombination.
This is the optimization procedure wefollowed:1.
For each single classifier and feature set (seesection 2), check each parameter combination.2.
Fix the parameters for each single classifier.
Inour case, k = 5 and k = 7 had similar results,so we postponed the decision.
d = 200 was thebest dimension for all classifiers, except SVD-OMT[topic] which was d = 50.3.
For the best parameter settings (k = 5; k = 7and d = 200; d = 50 when SVD-OMT[topic])make a priori meaningful combinations (dueto CPU requirements, not all combination werefeasible).4.
Choose the x best combination overall, and op-timize word by word among these combination.We set x = 8 for this work, k was fixed in 5,and d = 200 (except with SVD-OMT[topic]which was d = 50).Table 1 shows the best results for 3 fold cross-validation in SemEval lexical sample training cor-pus.
The figures show that optimizing each word theperformance increases 0.7 percentage points overthe best combination.4.2 Optimization for the all-words taskTo train the classifiers for the all-words task we justused Semcor (Miller et al, 1993).
In (Agirre etal., 2006) we already tested our approach on theSenseval-3 all-words task.
The best performancefor the Senseval-3 all-words task was obtained withk = 5 and d = 200, but we decided to to performfurther experiments to search for the best combina-tion.
We tested the performance of the combinationof single k-NN training on Semcor and testing bothon the Senseval-3 all-words data (cf.
Table 2) and onthe training data from SemEval-2007 lexical sample(cf.
Table 3).Note that tables 2 and 3 show contradictory re-sults.
Given that in SemEval-2007 lexical sample344Combination rec.
prec.all feats+local+notbow 0.685 0.685all feats+local+SVD-SMA 0.679 0.679all feats+topic+local+SVD-SMA 0.689 0.689Table 2: Results for the best k-NN combinations inSenseval-3 all-words, using Semcor as training cor-pus.Combination rec.
prec.all feats+SVD-SMA 0.666 0.666all feats+local+SVD-SMA 0.661 0.661all feats+topic+local+SVD-SMA 0.664 0.664Table 3: Results for the best k-NN combinations intraining part of SemEval lexical sample, using Sem-cor as training corpus.Task Method Rank rec.
prec.LS Best 1 0.887 0.887LS UBC-ALM 2 0.869 0.869LS Baseline - 0.780 0.780AW Best 1 0.591 0.591AW k-NN combination 5 0.544 0.544AW Baseline - 0.514 0.514Table 4: Official results for SemEval-2007 task 17lexical sample and all-words subtasks.the senses are more coarse grained, we decided totake the best combination on Senseval-3 all-wordsfor the final submission.5 Results and conclusionsTable 4 shows the performance obtained by our sys-tem and the winning systems in the SemEval lexi-cal sample and all-words evaluation.
On the lexicalsample evaluation our system is 2.6 lower than thecross-validation evaluation.
This can be a sign of aslight overfitting on the training data.
All in all weranked second over 13 systems.Our all-words system did not perform so well.Our system is around 4.7 points below the winningsystem, ranking 5th from a total of 14, and 3 pointsabove the baseline given by the organizers.
This isa disappointing result when compared to our previ-ous work on Senseval-3 all-words where we wereable to beat the best official results (Agirre et al,2006).
Note that the test set was rather small, with465 occurrences only, which might indicate that theperformance differences are not statistically signifi-cant.
We plan to further investigate the reasons forour results.AcknowledgmentsWe wish to thank to David Mart?
?nez for helping usextracting learning features.
This work has beenpartially funded by the Spanish education ministry(project KNOW).
Oier Lopez de Lacalle is sup-ported by a PhD grant from the Basque Government.ReferencesE.
Agirre, O.Lopez de Lacalle, and David Mart??nez.2005.
Exploring feature spaces with svd and unlabeleddata for Word Sense Disambiguation.
In Proceedingsof the Conference on Recent Advances on Natural Lan-guage Processing (RANLP?05), Borovets, Bulgaria.E.
Agirre, O. Lopez de Lacalle, and D.
Mart??nez.
2006.Exploring feature spaces with svd and unlabeled datafor Word Sense Disambiguation.
In Proceedingsof the XXII Conference of Sociedad Espaola parael Procesamiento del Lenguaje Natural (SEPLN?06),Zaragoza, Spain.G.
Leech.
1992.
100 million words of English:the British National Corpus.
Language Research,28(1):1?13.B.
Magnini and G. Cavaglia?.
2000.
Integrating subjectfield codes into WordNet.
In Proceedings of the Sec-ond International LREC Conference, Athens, Greece.G.A.
Miller, C. Leacock, R. Tengi, and R.Bunker.
1993.A Semantic Concordance.
In Proceedings of theARPA Human Language Technology Workshop.
Dis-tributed as Human Language Technology by San Ma-teo, CA: Morgan Kaufmann Publishers., pages 303?308, Princeton, NJ.G.
Ngai and R. Florian.
2001.
Transformation-BasedLearning in the Fast Lane.
Proceedings of the SecondConference of the North American Chapter of the As-sociation for Computational Linguistics, pages 40-47,Pittsburgh, PA, USA.T.
Pedersen.
2001.
A Decision Tree of Bigrams is anAccurate Predictor of Word Sense.
In Proceedingsof the Second Meeting of the North American Chap-ter of the Association for Computational Linguistics(NAACL-01), Pittsburgh, PA.345
