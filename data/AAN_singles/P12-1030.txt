Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 283?291,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsEfficient Search for Transformation-based InferenceAsher Stern?, Roni Stern?, Ido Dagan?, Ariel Felner??
Computer Science Department, Bar-Ilan University?
Information Systems Engineering, Ben Gurion Universityastern7@gmail.comroni.stern@gmail.comdagan@cs.biu.ac.ilfelner@bgu.ac.ilAbstractThis paper addresses the search problem intextual inference, where systems need to inferone piece of text from another.
A prominentapproach to this task is attempts to transformone text into the other through a sequenceof inference-preserving transformations, a.k.a.a proof, while estimating the proof?s valid-ity.
This raises a search challenge of find-ing the best possible proof.
We explore thischallenge through a comprehensive investi-gation of prominent search algorithms andpropose two novel algorithmic componentsspecifically designed for textual inference: agradient-style evaluation function, and a local-lookahead node expansion method.
Evalua-tions, using the open-source system, BIUTEE,show the contribution of these ideas to searchefficiency and proof quality.1 IntroductionIn many NLP settings it is necessary to identifythat a certain semantic inference relation holds be-tween two pieces of text.
For example, in para-phrase recognition it is necessary to identify that themeanings of two text fragments are roughly equiva-lent.
In passage retrieval for question answering, itis needed to detect text passages from which a sat-isfying answer can be inferred.
A generic formula-tion for the inference relation between two texts isgiven by the Recognizing Textual Entailment (RTE)paradigm (Dagan et al, 2005), which is adapted herefor our investigation.
In this setting, a system isgiven two text fragments, termed ?text?
(T) and ?hy-pothesis?
(H), and has to recognize whether the hy-pothesis is entailed by (inferred from) the text.An appealing approach to such textual inferencesis to explicitly transform T into H, using a sequenceof transformations (Bar-Haim et al, 2007; Harmel-ing, 2009; Mehdad, 2009; Wang and Manning,2010; Heilman and Smith, 2010; Stern and Dagan,2011).
Examples of such possible transformationsare lexical substitutions (e.g.
?letter??
?message?
)and predicate-template substitutions (e.g.
?X [verb-active] Y?
?
?Y [verb-passive] by X?
), which arebased on available knowledge resources.
Anotherexample is coreference substitutions, such as replac-ing ?he?
with ?the employee?
if a coreference re-solver has detected that these two expressions core-fer.
Table 1 exemplifies this approach for a particu-lar T-H pair.
The rationale behind this approach isthat each transformation step should preserve infer-ence validity, such that each text generated along thisprocess is indeed inferred from the preceding one.An inherent aspect in transformation-based infer-ence is modeling the certainty that each inferencestep is valid.
This is usually achieved by a cost-based or probabilistic model, which quantifies con-fidence in the validity of each individual transfor-mation and consequently of the complete chain ofinference.Given a set of possible transformations, there maybe many transformation sequences that would trans-form T to H. This creates a very large search space,where systems have to find the ?best?
transformationsequence ?
the one of lowest cost, or of highest prob-ability.
To the best of our knowledge, this searchchallenge has not been investigated yet in a substan-283# Operation Generated text0 - He received the letter from the secretary.1 Coreference substitution The employee received the letter from the secretary.2 X received Y from Z?
Y was sent to X by Z The letter was sent to the employee by the secretary.3 Y [verb-passive] by X?
X [verb-active] Y The secretary sent the letter to the employee.4 X send Y?
X deliver Y The secretary delivered the letter to the employee.5 letter?
message The secretary delivered the message to the employee.Table 1: A sequence of transformations that transform the text ?He received the letter from the secretary.?
into thehypothesis ?The secretary delivered the message to the employee.?.
The knowledge required for such transformationsis often obtained from available knowledge resources and NLP tools.tial manner: each of the above-cited works describedthe search method they used, but none of them triedalternative methods while evaluating search perfor-mance.
Furthermore, while experimenting with ourown open-source inference system, BIUTEE1, weobserved that search efficiency is a major issue, of-ten yielding practically unsatisfactory run-times.This paper investigates the search problem intransformation-based textual inference, naturallyfalling within the framework of heuristic AI (Ar-tificial Intelligence) search.
To facilitate such in-vestigation, we formulate a generic search schemewhich incorporates many search variants as specialcases and enable a meaningful comparison betweenthe algorithms.
Under this framework, we identifyspecial characteristics of the textual inference searchspace, that lead to the development of two novel al-gorithmic components: a special lookahead methodfor node expansion, named local lookahead, and agradient-based evaluation function.
Together, theyyield a new search algorithm, which achieved sub-stantially superior search performance in our evalu-ations.The remainder of this paper is organized asfollows.
Section 2 provides an overview oftransformation-based inference systems, AI searchalgorithms, and search methods realized in prior in-ference systems.
Section 3 formulates the genericsearch scheme that we have investigated, which cov-ers a broad range of known algorithms, and presentsour own algorithmic contributions.
These new algo-rithmic contributions were implemented in our sys-tem, BIUTEE.
In Section 4 we evaluate them empir-ically, and show that they improve search efficiencyas well as solution?s quality.
Search performance isevaluated on two recent RTE benchmarks, in terms1www.cs.biu.ac.il/?nlp/downloads/biuteeof runtime, ability to find lower-cost transformationchains and impact on overall inference.2 BackgroundApplying sequences of transformations to recognizetextual inference was suggested by several works.Such a sequence may be referred to as a proof, inthe sense that it is used to ?prove?
the hypothesisfrom the text.
Although various works along thisline differ from each other in several respects, manyof them share the common challenge of finding anoptimal proof.
The following paragraphs review themajor research approaches in this direction.
We fo-cus on methods that perform transformations overparse trees, and highlight the search challenge withwhich they are faced.2.1 Transformation-based textual inferenceSeveral researchers suggested using various typesof transformations in order to derive H from T .Some suggested a set of predefined transforma-tions, for example, insertion, deletion and substitu-tion of parse-tree nodes, by which any tree can betransformed to any other tree.
These transforma-tions were used by the open-source system EDITS(Mehdad, 2009), and by (Wang and Manning, 2010).Since the above mentioned transformations are lim-ited in capturing certain interesting and prevalentsemantic phenomena, an extended set of tree editoperations (e.g., relabel-edge, move-sibling, etc.
)was proposed by Heilman and Smith (2010).
Simi-larly, Harmeling (2009) suggested a heuristic set of28 transformations, which include various types ofnode-substitutions as well as restructuring of the en-tire parse-tree.In contrast to such predefined sets of transfor-mations, knowledge oriented approaches were sug-284gested by Bar-Haim et al (2007) and de Salvo Brazet al (2005).
Their transformations are defined byknowledge resources that contain a large amount ofentailment rules, or rewrite rules, which are pairs ofparse-tree fragments that entail one another.
Typicalexamples for knowledge resources of such rules areDIRT (Lin and Pantel, 2001), and TEASE (Szpek-tor et al, 2004), as well as syntactic transforma-tions constructed manually.
In addition, they usedknowledge-based lexical substitutions.However, when only knowledge-based transfor-mations are allowed, transforming the text into thehypothesis is impossible in many cases.
This limi-tation is dealt by our open-source integrated frame-work, BIUTEE (Stern and Dagan, 2011), whichincorporates knowledge-based transformations (en-tailment rules) with a set of predefined tree-edits.Motivated by the richer structure and search spaceprovided by BIUTEE, we adopted it for our empiri-cal investigations.The semantic validity of transformation-based in-ference is usually modeled by defining a cost ora probability estimation for each transformation.Costs may be defined manually (Kouylekov andMagnini, 2005), but are usually learned automati-cally (Harmeling, 2009; Mehdad, 2009; Wang andManning, 2010; Heilman and Smith, 2010; Sternand Dagan, 2011).
A global cost (or probability esti-mation) for a complete sequence of transformationsis typically defined as the sum of the costs of theinvolved transformations.Finding the lowest cost proof, as needed for de-termining inference validity, is the focus of our re-search.
Textual inference systems limited to thestandard tree-edit operations (insertion, deletion,substitution) can use an exact algorithm that findsthe optimal solution in polynomial time under cer-tain constraints (Bille, 2005).
Nevertheless, for theextended set of transformations it is unlikely that ef-ficient exact algorithms for finding lowest-cost se-quences are available (Heilman and Smith, 2010).In this harder case, the problem can be viewedas an AI search problem.
Each state in the searchspace is a parse-tree, where the initial state is the textparse-tree, the goal state is the hypothesis parse-tree,and we search for the shortest (in terms of costs)path of transformations from the initial state to thegoal state.
Next we briefly review major conceptsfrom the field of AI search and summarize some rel-evant proposed solutions.2.2 Search AlgorithmsSearch algorithms find a path from an initial state toa goal state by expanding and generating states ina search space.
The term generating a state refersto creating a data structure that represents it, whileexpanding a state means generating all its immedi-ate derivations.
In our domain, each state is a parsetree, which is expanded by performing all applicabletransformations.Best-first search is a common search framework.It maintains an open list (denoted hereafter asOPEN) containing all the generated states that havenot been expanded yet.
States in OPEN are prior-itized by an evaluation function, f(s).
A best-firstsearch algorithm iteratively removes the best state(according to f(s)) from OPEN, and inserts newstates being generated by expanding this best state.The evaluation function is usually a linear combina-tion of the shortest path found from the start state tostate s, denoted by g(s), and a heuristic function, de-noted by h(s), which estimates the cost of reachinga goal state from s.Many search algorithms can be viewed as spe-cial cases or variations of best-first search.
Thewell-known A* (Hart et al, 1968).
algorithm isa best-first search that uses an evaluation functionf(s) = g(s) + h(s).
Weighted A* (Pohl, 1970)uses an evaluation function f(s) = w ?
g(s) + h(s),where w is a parameter, while pure heuristic searchuses f(s) = h(s).
K-BFS (Felner et al, 2003) ex-pands k states in each iteration.
Beam search (Furcyand Koenig, 2005; Zhou and Hansen, 2005) limitsthe number of states stored in OPEN, while Greedysearch limits OPEN to contain only the single beststate generated in the current iteration.The search algorithm has crucial impact on thequality of proof found by a textual inference system,as well as on its efficiency.
Next, we describe searchstrategies used in prior works for textual inference.2.3 Search in prior inference modelsIn spite of being a fundamental problem, prior so-lutions to the search challenge in textual inferencewere mostly ad-hoc.
Furthermore, there was no in-vestigation of alternative search methods, and no285evaluation of search efficiency and quality was re-ported.
For example, in (Harmeling, 2009) the orderby which the transformations are performed is pre-determined, and in addition many possible deriva-tions are discarded, to prevent exponential explo-sion.
Handling the search problem in (Heilman andSmith, 2010) was by a variant of greedy search,driven by a similarity measure between the currentparse-tree and the hypothesis, while ignoring thecost already paid.
In addition, several constraints onthe search space were implemented.
In the earlierversion of BIUTEE (Stern and Dagan, 2011)2, a ver-sion of beam search was incorporated, named here-after BIUTEE-orig.
This algorithm uses the evalua-tion function f(s) = g(s) +wi ?h(s), where in eachiteration (i) the value of w is increased, to ensuresuccessful termination of the search.
Nevertheless,its efficiency and quality were not investigated.In this paper we consider several prominentsearch algorithms and evaluate their quality.
Theevaluation concentrates on two measures: the run-time required to find a proof, and proof quality (mea-sured by its cost).
In addition to evaluating standardsearch algorithms we propose two novel compo-nents specifically designed for proof-based textual-inference and evaluate their contribution.3 Search for Textual InferenceIn this section we formalize our search problem andspecify a unifying search scheme by which we testseveral search algorithms in a systematic manner.Then we propose two novel algorithmic componentsspecifically designed for our problem.
We concludeby presenting our new search algorithm which com-bines these two ideas.3.1 Inference and search space formalizationLet t be a parse tree, and let o be a transforma-tion.
Applying o on t, yielding t?, is denoted byt `o t?.
If the underlying meaning of t?
can in-deed be inferred from the underlying meaning of t,then we refer to the application of o as valid.
LetO = (o1, o2, .
.
.
on) be a sequence of transforma-tions, such that t0 `o1 t1 `o2 t2 .
.
.
`on tn.
Wewrite t0 `O tn, and say that tn can be proven from2More details in www.cs.biu.ac.il/?nlp/downloads/biutee/search_ranlp_2011.pdft0 by applying the sequence O.
The proof might bevalid, if all the transformations involved are valid, orinvalid otherwise.An inference system specifies a cost, C(o), foreach transformation o.
In most systems the costsare automatically learned.
The interpretation of ahigh cost is that it is unlikely that applying o will bevalid.
The cost of a sequence O = (o1, o2, .
.
.
on)is defined as?ni=1C(o) (or ,in some systems,?ni=1C(o)).
Denoting by tT and tH the text parsetree and the hypothesis parse tree, a proof systemhas to find a sequenceO with minimal cost such thattT `O tH.
This forms a search problem of findingthe lowest-cost proof among all possible proofs.The search space is defined as follows.
A states is a parse-tree.
The start state is tT and the goalstate is tH.
In some systems any state s in which tHis embedded is considered as goal as well.Given a state s, let {o(1), o(2) .
.
.
o(m)} be mtransformations that can be applied on it.
Expand-ing s means generating m new states, s(j), j =1 .
.
.m, such that s `o(j) s(j).
The number m iscalled branching factor.
Our empirical observationson BIUTEE showed that its branching factor rangesfrom 2-3 for some states to about 30 for other states.3.2 Search SchemeOur empirical investigation compares a rangeprominent search algorithms, described in Section 2.To facilitate such investigation, we formulate themin the following unifying scheme (Algorithm 1).Algorithm 1 Unified Search SchemeParameters: f(?
): state evaluation functionexpand(?
): state generation functionInput: kexpand: # states expanded in each iterationkmaintain: # states in OPEN in each iterationsinit: initial state1: OPEN?
{sinit}2: repeat3: BEST?
kexpand best (according to f ) states in OPEN4: GENERATED?
?s?BEST expand(s)5: OPEN?
(OPEN \ Best) ?
GENERATED6: OPEN?
kmaintain best (according to f ) states in OPEN7: until BEST contains the goal stateInitially, the open list, OPEN contains the initialstate.
Then, the best kexpand states from OPEN arechosen, according to the evaluation function f(s)286Algorithm f() expand() kmaintain kexpandA* g + h regular ?
1Weighted A* g+w ?h regular ?
1K-Weighted A* g+w ?h regular ?
k > 1Pure Heuristic h regular ?
1Greedy g+w ?h regular 1 1Beam g + h regular k > 1 k > 1BIUTEE-orig g+wi?h regular k > 1 k > 1LLGS ?g?hlocal-lookahead1 1Table 2: Search algorithm mapped to the unified searchscheme.
?Regular?
means generating all the states whichcan be generated by applying a single transformation.
Al-ternative greedy implementations use f = h.(line 3), and expanded using the expansion func-tion expand(s).
In classical search algorithms,expand(s) means generating a set of states by ap-plying all the possible state transition operators to s.Next, we remove from OPEN the states which wereexpanded, and add the newly generated states.
Fi-nally, we keep in OPEN only the best kmaintain states,according to the evaluation function f(s) (line 6).This process repeats until the goal state is found inBEST (line 7).
Table 2 specifies how known searchalgorithms, described in Section 2, fit into the uni-fied search scheme.Since runtime efficiency is crucial in our domain,we focused on improving one of the simple but fastalgorithms, namely, greedy search.
To improve thequality of the proof found by greedy search, we in-troduce new algorithmic components for the expan-sion and evaluation functions, as described in thenext two subsections, while maintaining efficiencyby keeping kmaintain=kexpand= 13.3 Evaluation functionIn most domains, the heuristic function h(s) esti-mates the cost of the minimal-cost path from a cur-rent state, s, to a goal state.
Having such a function,the value g(s) + h(s) estimates the expected totalcost of a search path containing s. In our domain, itis yet unclear how to calculate such a heuristic func-tion.
Given a state s, systems typically estimate thedifference (the gap) between s and the hypothesistH (the goal state).
In BIUTEE this is quantified bythe number of parse-tree nodes and edges of tH thatdo not exist in s. However, this does not give anestimation for the expected cost of the path (the se-quence of transformations) from s to the goal state.This is because the number of nodes and edges thatcan be changed by a single transformation can varyfrom a single node to several nodes (e.g., by a lexi-cal syntactic entailment rule).
Moreover, even if twotransformations change the same number of nodesand edges, their costs might be significantly differ-ent.
Consequently, the measurement of the cost ac-cumulated so far (g(s)) and the remaining gap to tH(h(s)) are unrelated.
We note that a more sophisti-cated heuristic function was suggested by Heilmanand Smith (2010), based on tree-kernels.
Neverthe-less, this heuristic function, serving as h(s), is stillunrelated to the transformation costs (g(s)).We therefore propose a novel gradient-style func-tion to overcome this difficulty.
Our function isdesigned for a greedy search in which OPEN al-ways contains a single state, s. Let sj be a stategenerated from s, the cost of deriving sj from sis ?g(sj) ?
g(sj) ?
g(s).
Similarly, the reduc-tion in the value of the heuristic function is de-fined ?h(sj) ?
h(s) ?
h(sj).
Now, we definef?
(sj) ??g(sj)?h(sj).
Informally, this function mea-sures how costly it is to derive sj relative to theobtained decrease in the remaining gap to the goalstate.
For the edge case in which h(s)?
h(sj) ?
0,we define f?
(sj) =?.
Empirically, we show in ourexperiments that the function f?
(s) performs betterthan the traditional functions f(s) = g(s) + h(s)and fw(s) = g(s) + w ?
h(s) in our domain.3.4 Node expansion methodWhen examining the proofs produced by the abovementioned algorithms, we observed that in manycases a human could construct proofs that exhibitsome internal structure, but were not revealed by thealgorithms.
Observe, for example, the proof in Ta-ble 1.
It can be seen that transformations 2,3 and4 strongly depend on each other.
Applying trans-formation 3 requires first applying transformation 2,and similarly 4 could not be applied unless 2 and 3are first applied.
Moreover, there is no gain in apply-ing transformations 2 and 3, unless transformation 4is applied as well.
On the other hand, transformation1 does not depend on any other transformation.
Itmay be performed at any point along the proof, and287moreover, changing all other transformations wouldnot affect it.Carefully examining many examples, we general-ized this phenomenon as follows.
Often, a sequenceof transformations can be decomposed into a set ofcoherent subsequences of transformations, where ineach subsequence the transformations strongly de-pend on each other, while different subsequences areindependent.
This phenomenon can be utilized inthe following way: instead of searching for a com-plete sequence of transformations that transform tTinto tH, we can iteratively search for independent co-herent subsequences of transformations, such that acombination of these subsequences will transformtT into tH.
This is somewhat similar to the tech-nique of applying macro operators, which is used inautomated planning (Botea et al, 2005) and puzzlesolving (Korf, 1985).One technique for finding such subsequences isto perform, for each state being expanded, a brute-force depth-limited search, also known as looka-head (Russell and Norvig, 2010; Bulitko and Lus-trek, 2006; Korf, 1990; Stern et al, 2010).
How-ever, performing such lookahead might be slow ifthe branching factor is large.
Fortunately, in ourdomain, coherent subsequences have the followingcharacteristic which can be leveraged: typically, atransformation depends on a previous one only ifit is performed over some nodes which were af-fected by the previous transformation.
Accordingly,our proposed algorithm searches for coherent subse-quences, in which each subsequent transformationmust be applied to nodes that were affected by theprevious transformation.Formally, let o be a transformation that has beenapplied on a tree t, yielding t?.
?affected(o, t?)
denotesthe subset of nodes in t?
which were affected (modi-fied or created) by the application of o.Next, for a transformation o, applied on a parsetree t, we define ?required(t, o) as the subset of t?snodes required for applying o (i.e., in the absence ofthese nodes, o could not be applied).Finally, let t be a parse-tree and ?
be a subset ofits nodes.
enabled ops(t, ?)
is a function that re-turns the set of the transformations that can be ap-plied on t, which require at least one of the nodesin ?.
Formally, enabled ops(t, ?)
?
{o ?
O :?
?
?required(t, o) 6= ?
}, where O is the set of trans-formations that can be applied on t. In our algo-rithm, ?
is the set of nodes that were affected by thepreceding transformation of the constructed subse-quence.The recursive procedure described in Algorithm 2generates all coherent subsequences of lengths up tod.
It should be initially invoked with t - the currentstate (parse tree) being expanded, ?
- the set of all itsnodes, d - the maximal required length, and ?
as anempty initial sequence.
We useO?o as concatenationof an operation o to a subsequence O.Algorithm 2 local-lookahead (t,?,d,O)1: if d = 0 then2: return ?
(empty-set)3: end if4: SUBSEQUENCES?
?5: for all o ?
enabled ops(t, ?)
do6: Let t `o t?7: Add {O?o}?local-lookahead(t?, ?affected(o, t?
), d?1, O?o) to SUBSEQUENCES8: end for9: return SUBSEQUENCESThe loop in lines 5 - 8 iterates over transforma-tions that can be applied on the input tree, t, requir-ing the same nodes that were affected by the pre-vious transformation of the subsequence being con-structed.
Note that in the first call enabled ops(t, ?
)contain all operations that can be applied on t, withno restriction.
Applying an operation o results in anew subsequence O ?
o.
This subsequence will bepart of the set of subsequences found by the proce-dure.
In addition, it will be used in the next recur-sive call as the prefix of additional (longer) subse-quences.3.5 Local-lookahead gradient searchWe are now ready to define our new algorithmLOCAL-LOOKAHEAD GRADIENT SEARCH(LLGS).
In LLGS, like in greedy search,kmaintain=kexpand= 1. expand(s) is defined toreturn all states generated by subsequences foundby the local-lookahead procedure, while the evalua-tion function is defined as f = f?
(see last row ofTable 2).4 EvaluationIn this section we first evaluate the search perfor-mance in terms of efficiency (run time), the quality288of the found proofs (as measured by proof cost), andoverall inference performance achieved through var-ious search algorithms.
Finally we analyze the con-tribution of our two novel components.4.1 Evaluation settingsWe performed our experiments on the last twopublished RTE datasets: RTE-5 (2009) and RTE-6 (2010).
The RTE-5 dataset is composed of atraining and test corpora, each containing 600 text-hypothesis pairs, where in half of them the text en-tails the hypothesis and in the other half it doesnot.
In RTE-6, each of the training and test cor-pora consists of 10 topics, where each topic con-tains 10 documents.
Each corpus contains a set ofhypotheses (211 in the training dataset, and 243 inthe test dataset), along with a set of candidate en-tailing sentences for each hypothesis.
The systemhas to find for each hypothesis which candidate sen-tences entail it.
To improve speed and results, weused the filtering mechanism suggested by (Mirkinet al, 2009), which filters the candidate sentencesby the Lucene IR engine3.
Thus, only top 20 candi-dates per hypothesis were testedEvaluation of each of the algorithms wasperformed by running BIUTEE while replacingBIUTEE-orig with this algorithm.
We employed acomprehensive set of knowledge resources (avail-able in BIUTEE?s web site): WordNet (Fellbaum,1998), Directional similarity (Kotlerman et al,2010), DIRT (Lin and Pantel, 2001) and generic syn-tactic rules.
In addition, we used coreference substi-tutions, detected by ArkRef4.We evaluated several known algorithms, de-scribed in Table 2 above, as well as BIUTEE-orig.The latter is a strong baseline, which outperformsknown search algorithms in generating low costproofs.
We compared all the above mentioned al-gorithms to our novel one, LLGS.We used the training dataset for parameter tun-ing, which controls the trade-off between speed andquality.
For weighted A*, as well as for greedysearch, we used w = 6.0, since, for a few instances,lower values of w resulted in prohibitive runtime.For beam search we used k = 150, since higher val-3http://lucene.apache.org4www.ark.cs.cmu.edu/ARKref/ See (Haghighi andKlein, 2009)ues of k did not improve the proof cost on the train-ing dataset.
The value of d in LLGS was set to 3.d = 4 yielded the same proof costs, but was about 3times slower.Since lower values of w could be used byweighted A* for most instances, we also ran ex-periments where we varied the value of w accord-ing to the dovetailing method suggested in (Valen-zano et al, 2010) (denoted dovetailing WA*) as fol-lows.
When weighted A* has found a solution, wereran it with a new value of w, set to half of theprevious value.
The idea is to guide the search forlower cost solutions.
This process was halted whenthe total number of states generated by all weightedA* instances exceeded a predefined constant (set to10, 000).4.2 Search performanceThis experiment evaluates the search algorithms inboth efficiency (run-time) and proof quality.
Effi-ciency is measured by the average CPU (Intel Xeon2.5 GHz) run-time (in seconds) for finding a com-plete proof for a text-hypothesis instance, and by theaverage number of generated states along the search.Proof quality is measured by its cost.The comparison of costs requires that all experi-ments are performed on the same model which waslearned during training.
Thus, in the training phasewe used the original search of BIUTEE, and then ranthe test phase with each algorithm separately.
Theresults, presented in Table 3, show that our novelalgorithm, LLGS, outperforms all other algorithmsin finding lower cost proofs.
The second best isBIUTEE-orig which is much slower by a factor of3 (on RTE-5) to 8 (on RTE-6)5.
While inherentlyfast algorithms, particularly greedy and pure heuris-tic, achieve faster running times, they achieve lowerproof quality, as well as lower overall inference per-formance (see next subsection).4.3 Overall inference performanceIn this experiment we test whether, and how much,finding better proofs, by a better search algorithm,improves overall success rate of the RTE system.Table 4 summarizes the results (accuracy in RTE-55Calculating T-test, we found that runtime improvement isstatistically significant with p < 0.01, and p < 0.052 for costimprovement over BIUTEE-orig.289Algorithm Avg.
timeAvg.generatedAvg.
costWeighted A* 0.22 / 0.09 301 / 143 1.11 / 10.52DovetailingWA*7.85 / 8.53 9797 / 9979 1.05 / 10.28Greedy 0.20 / 0.10 468 / 158 1.10 / 10.55Pure heuristic 0.09 / 0.10 123 / 167 1.35 / 12.51Beam search 20.53 / 9.48 43925 / 18992 1.08 / 10.52BIUTEE-orig 7.86 / 14.61 14749 / 22795 1.03 / 10.28LLGS 2.76 / 1.72 1722 / 842 0.95 / 10.14Table 3: Comparison of algorithms on RTE-5 / RTE-6and F1 in RTE-6).
We see that in RTE-5 LLGS out-performs all other algorithms, and BIUTEE-orig isthe second best.
This result is statistically significantwith p < 0.02 according to McNemar test.
In RTE-6 we see that although LLGS tends to finds lowercost proofs, as shown in Table 3, BIUTEE obtainsslightly lower results when utilizing this algorithm.Algorithm RTE-5 accuracy % RTE-6 F1 %Weighted A* 59.50 48.20Dovetailing WA* 60.83 49.01Greedy 60.50 48.56Pure heuristic 60.83 45.70Beam search 61.33 48.58BIUTEE-orig 60.67 49.25LLGS 64.00 49.09Table 4: Impact of algorithms on system success rate4.4 Component evaluationIn this experiment we examine separately our twonovel components.
We examined f?
by runningLLGS with alternative evaluation functions.
The re-sults, displayed in Table 5, show that using f?
yieldsbetter proofs and also improves run time.f Avg.
time Avg.
cost Accuracy %f = g + h 3.28 1.06 61.50f = g + w ?
h 3.30 1.07 61.33f = f?
2.76 0.95 64.0Table 5: Impact of f?
on RTE-5.
w = 6.0.
Accuracyobtained by retraining with corresponding f .Our local-lookahead (Subsection 3.4) was exam-ined by running LLGS with alternative node expan-sion methods.
One alternative to local-lookaheadis standard expansion by generating all immediatederivations.
Another alternative is to use the stan-dard lookahead, in which a brute-force depth-limitedsearch is performed in each iteration, termed here?exhaustive lookahead?.
The results, presented inTable 6, show that by avoiding any type of looka-head one can achieve fast runtime, while compro-mising proof quality.
On the other hand, both ex-haustive and local lookahead yield better proofs andaccuracy, while local lookahead is more than 4 timesfaster than exhaustive lookahead.lookahead Avg.
time Avg.
cost Accuracy (%)exhaustive 13.22 0.95 64.0local 2.76 0.95 64.0none 0.24 0.97 62.0Table 6: Impact of local and global lookahead on RTE-5.Accuracy obtained by retraining with the correspondinglookahead method.5 ConclusionIn this paper we investigated the efficiency and proofquality obtained by various search algorithms.
Con-sequently, we observed special phenomena of thesearch space in textual inference and proposed twonovel components yielding a new search algorithm,targeted for our domain.
We have shown empiricallythat (1) this algorithm improves run time by factorsof 3-8 relative to BIUTEE-orig, and by similar fac-tors relative to standard AI-search algorithms thatachieve similar proof quality; and (2) outperformsall other algorithms in finding low cost proofs.In future work we plan to investigate other searchparadigms, e.g., Monte-Carlo style approaches(Kocsis and Szepesva?ri, 2006), which do not fallunder the AI search scheme covered in this paper.In addition, while our novel components were moti-vated by the search space of textual inference, weforesee their potential utility in other applicationareas for search, such as automated planning andscheduling.AcknowledgmentsThis work was partially supported by the IsraelScience Foundation grant 1112/08, the PASCAL-2 Network of Excellence of the European Com-munity FP7-ICT-2007-1-216886, and the Euro-pean Community?s Seventh Framework Programme(FP7/2007-2013) under grant agreement no.
287923(EXCITEMENT).290ReferencesRoy Bar-Haim, Ido Dagan, Iddo Greental, and EyalShnarch.
2007.
Semantic inference at the lexical-syntactic level.
In Proceedings of AAAI.Philip Bille.
2005.
A survey on tree edit distance andrelated problems.
Theoretical Computer Science.Adi Botea, Markus Enzenberger, Martin Mu?ller, andJonathan Schaeffer.
2005.
Macro-FF: Improving aiplanning with automatically learned macro-operators.J.
Artif.
Intell.
Res.
(JAIR), 24:581?621.Vadim Bulitko and Mitja Lustrek.
2006.
Lookaheadpathology in real-time path-finding.
In proceedings ofAAAI.Ido Dagan, Oren Glickman, and Bernardo Magnini.2005.
The pascal recognising textual entailment chal-lenge.
In Proceedings of MLCW.Rodrigo de Salvo Braz, Roxana Girju, Vasin Pun-yakanok, Dan Roth, and Mark Sammons.
2005.
Aninference model for semantic entailment in natural lan-guage.
In Proceedings of AAAI.Christiane Fellbaum, editor.
1998.
WordNet An Elec-tronic Lexical Database.
The MIT Press, May.Ariel Felner, Sarit Kraus, and Richard E. Korf.
2003.KBFS: K-best-first search.
Ann.
Math.
Artif.
Intell.,39(1-2):19?39.David Furcy and Sven Koenig.
2005.
Limited discrep-ancy beam search.
In proceedings of IJCAI.Aria Haghighi and Dan Klein.
2009.
Simple coreferenceresolution with rich syntactic and semantic features.
InProceedings of EMNLP.Stefan Harmeling.
2009.
Inferring textual entailmentwith a probabilistically sound calculus.
Natural Lan-guage Engineering.Peter E. Hart, Nils J. Nilsson, and Bertram Raphael.1968.
A formal basis for the heuristic determinationof minimum cost paths.
IEEE Transactions on Sys-tems Science and Cybernetics, SSC-4(2):100?107.Michael Heilman and Noah A. Smith.
2010.
Treeedit models for recognizing textual entailments, para-phrases, and answers to questions.
In Proceedings ofNAACL.Levente Kocsis and Csaba Szepesva?ri.
2006.
Banditbased monte-carlo planning.
In proceedings of ECML.Richard E. Korf.
1985.
Macro-operators: A weakmethod for learning.
Artif.
Intell., 26(1):35?77.Richard E. Korf.
1990.
Real-time heuristic search.
Artif.Intell., 42(2-3):189?211.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-geffet.
2010.
Directional distributionalsimilarity for lexical inference.
Natural Language En-gineering.Milen Kouylekov and Bernardo Magnini.
2005.
Rec-ognizing textual entailment with tree edit distance al-gorithms.
In Proceedings of Pascal Challenges Work-shop on Recognising Textual Entailment.Dekang Lin and Patrick Pantel.
2001.
DIRT - discov-ery of inference rules from text.
In Proceedings ofACM SIGKDD Conference on Knowledge Discoveryand Data Mining.Yashar Mehdad.
2009.
Automatic cost estimation fortree edit distance using particle swarm optimization.In Proceedings of the ACL-IJCNLP.Shachar Mirkin, Roy Bar-Haim, Jonathan Berant, IdoDagan, Eyal Shnarch, Asher Stern, and Idan Szpektor.2009.
Addressing discourse and document structure inthe rte search task.
In Proceedings of TAC.Ira Pohl.
1970.
Heuristic search viewed as path findingin a graph.
Artificial Intelligence, 1(3-4):193 ?
204.Stuart Russell and Peter Norvig.
2010.
Artificial Intel-ligence: A Modern Approach.
Prentice-Hall, Engle-wood Cliffs, NJ, 3rd edition edition.Asher Stern and Ido Dagan.
2011.
A confidence modelfor syntactically-motivated entailment proofs.
In Pro-ceedings of RANLP.Roni Stern, Tamar Kulberis, Ariel Felner, and RobertHolte.
2010.
Using lookaheads with optimal best-firstsearch.
In proceedings of AAAI.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisition ofentailment relations.
In Proceedings of EMNLP.Richard Anthony Valenzano, Nathan R. Sturtevant,Jonathan Schaeffer, Karen Buro, and Akihiro Kishi-moto.
2010.
Simultaneously searching with multiplesettings: An alternative to parameter tuning for subop-timal single-agent search algorithms.
In proceedingsof ICAPS.Mengqiu Wang and Christopher D. Manning.
2010.Probabilistic tree-edit models with structured latentvariables for textual entailment and question answer-ing.
In Proceedings of COLING.Rong Zhou and Eric A. Hansen.
2005.
Beam-stacksearch: Integrating backtracking with beam search.
Inproceedings of ICAPS.291
