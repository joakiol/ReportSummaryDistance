Modeling English Past Tense Intuitions with Minimal GeneralizationAdam Albrightaalbrigh@ucla.eduBruce Hayesbhayes@ucla.eduDepartment of LinguisticsUniversity of California, Los AngelesLos Angeles, CA  90025-1543AbstractWe describe here a supervised learningmodel that, given paradigms of relatedwords, learns the morphological andphonological rules needed to derive theparadigm.
The model can use its rules tomake guesses about how novel formswould be inflected, and has been testedexperimentally against the intuitions ofhuman speakers.1 IntroductionIn recent years, linguists have explored theoreticalmodels of how speakers discover the rules of theirlanguage.
Automated learning systems can be ofgreat use in developing such models.
The predic-tions of a theoretical model can be fully tested onlywhen it is formalized explicitly enough to be im-plemented.In our research, we have developed and imple-mented a model for discovering rules of morphol-ogy and phonology.
The model is trained on pairsof morphologically related words, and learns therules by which one form of a pair can be derivedfrom the other.
We have tested our model by com-paring its predictions against intuitions gatheredexperimentally from human speakers.2 Criteria for Evaluating ModelsA number of properties are desirable in a learningmodel whose goal is to mimic human intuition.
Wehave been motivated to develop our own model inpart because these criteria have rarely been met byprevious models.
Such models include, for exam-ple, connectionist models (Rumelhart andMcClelland 1986, Daugherty and Seidenberg1994, MacWhinney and Leinbach 1991), neigh-borhood similarity models (Nakisa, Plunkett andHahn 2001), decision tree/ILP models (Ling andMarinov 1993, Mooney and Califf 1996, Dzeroskiand Erjavec 1997), and other rule-based models(Neuvel, to appear).1Our first criterion is that a model should be ableto generate complete output forms, rather than justgrouping the outputs into (possibly arbitrary) cate-gories such as ?regular,?
?irregular,?
?vowelchange,?
etc.
The reason is that people likewisegenerate fully specified forms, and a model?s pre-dictions can be fully tested only at this level of de-tail.Second, a model should be able to make multi-ple guesses for each word and assign numericalwell-formedness scores to each guess.
People, too,often favor multiple outcomes, and they also havegradient preferences among the various possibili-ties (Prasada and Pinker 1993).2Third, a model should be able to locate detailedgeneralizations.
Here is an example: English pasttenses are often formed by changing [?]
to [?]
whenthe final consonant of the word is [?]
(fling-flung,cling-clung, sting-stung).
As experiments show,such generalizations are learned by speakers ofEnglish (that is, speakers do more than just memo-1 The Analogical Model of Language (Skousen 1989, Ed-dington 2002) satisfies all of our criteria.
However, in our useof this model so far, we have been unable to find any settingof its parameters that can achieve good correlations to ourexperimental data, reported below in section 4.2 On a practical level, an ability to consider multiple outputswould also improve the performance of a recognition system.For example, a system not told that spelt is a dialectal pasttense for spell should be able to interpret it as such, even ifspelled were its first choice.July 2002, pp.
58-69.
Association for Computational Linguistics.ACL Special Interest Group in Computational Phonology (SIGPHON), Philadelphia,Morphological and Phonological Learning: Proceedings of the 6th Workshop of therize each irregular verb).
For example, experimen-tal participants often volunteer splung as the pasttense of spling, extending the generalization to anovel verb.The importance of detailed generalizations isnot limited to irregular forms.
We have found thatspeakers are often sensitive to detailed generaliza-tions even among regulars.
For example, verbs inEnglish ending in voiceless fricatives ([f, T, s, S])are always regular.
Our experiments indicate thatEnglish speakers are tacitly aware of this pattern.Thus, an accurate model of their linguistic intui-tions must be able to detect and learn the pattern inthe training data.Although detailed generalizations are impor-tant, it is also crucial for a learning model to beable to form very broad generalizations.
The rea-son is that general morphological patterns cannotbe learned simply as the aggregation of detailedpatterns.
Speakers can generate novel inflectedforms even for words that don?t fit any of the de-tailed patterns (Pinker and Prince 1988, Prasadaand Pinker 1993).
Thus, a general rule is needed toderive an output where no close analogues occur inthe training set.
A special case of this sort is wherethe base form ends in a segment that is not phonol-ogically legal in the language (Halle 1978).
Thus,the German name Bach can be pronounced bysome English speakers with a final voiceless velarfricative [x].
Speakers who can pronounce thissound agree firmly that the past tense of to out-Bach must be [aUtbaxt] (Pinker 1999), following ageneralization which is apparently learned on thebasis of ordinary English words.In summary, we believe it is important that alearning model for morphology and phonologyshould produce complete output forms, generatemultiple outputs, assign each output a well-formedness score, and discover both specific andbroad generalizations.3 Description of the Model3.1 Rule induction by minimal generalizationOur model employs a bottom-up approach tolearning, iteratively comparing pairs of surfaceforms to yield ever more general rules.
It takes asits input ordered pairs of forms which stand in aparticular morphological relation ?
e.g., (present,past) ?
and compares the members of each pair toconstruct rules that derive one from the other.
Asan example, consider the pairs of forms in (1).
(1) ([m?s]pres., [m?st]past) ?miss(ed)?
([pr?s]pres., [pr?st]past) ?press(ed)?
([l?f]pres., [l?ft]past) ?laugh(ed)?
([h?g]pres., [h?gd]past) ?hug(ged)?
([r?b]pres., [r?bd]past) ?rub(bed)?
([nid]pres., [nid?d]past) ?need(ed)?
([dZ?mp]pres., [dZ?mpt]past) ?jump(ed)?
([pl?n]pres., [pl?nd]past) ?plan(ned)?When we compare the present and past formsof each word, we see that the relation betweenthem can be expressed as a structural change (inthis case, adding [-t], [-d], or [-?d]) in a particularcontext (after [m?s], after [h?g], etc.).
Formally, thestructural change can be represented in the formatA ?
B, and the context in the format / C__D, toyield word-specific rules like those in (2).
(Thesymbol ?#?
stands for a word boundary.
)(2) ?
?
t / # m?s __ #?
?
t / # pr?s __ #?
?
t / # l?f __ #?
?
d / # h?g __ #?
?
d / # r?b __ #?
?
?d / # nid __ #?
?
t / # dZ?mp __ #?
?
d / # pl?n __ #The exact procedure for finding a word-specificrule is as follows: given an input pair (X, Y), themodel first finds the maximal left-side substringshared by the two forms (e.g., #m?s), to create theC term (left side context).
The model then exam-ines the remaining material and finds the maximalsubstring shared on the right side, to create the Dterm (right side context).
The remaining material isthe change; the non-shared string from the firstform is the A term, and from the second form is theB term.
(3) A B# m?s ?
# # m?s t #C DNote that either A or B can be zero.
When A iszero and edge-adjacent, we are dealing with anaffixational mapping.
When B is zero and edge-adjacent, we are dealing with some sort of trunca-tion; e.g.
the mapping from English plurals to sin-gulars.
When neither A nor B is zero, we aredealing either with two paradigm members thateach have their own affix, or cases of ablaut orsimilar nonconcatenative morphology.As such word-specific rules accumulate, themodel attempts to generalize.
As soon as two ruleswith the same structural change have been discov-ered, their contexts are compared to yield a moregeneral rule, retaining all shared context material,and replacing all non-shared material with a vari-able.
Here is the generalization process as appliedto miss and press:(4) ?
?
t / m ?
s __ #+ ?
?
t / pr ?
s __ #= ?
?
t / X???????
?+syllabic?low?back?tense?rounds __ #The procedure for comparing contexts of tworules is much like the procedure for creating aword-specific rule.
The general scheme is asshown in (5):(5) A?
B / C1 __ D1+ A?
B / C2 __ D2= A?
B / X C?feat C?
__ D?
D?feat YGiven two rules that share the same structuralchange (Rule 1: A ?
B / C1 __ D1, Rule 2: A ?
B/ C2 __ D2), the model compares C1 with C2, andD1 with D2.
Working outwards from the structuralchange, it first locates the maximal right-side sub-string shared by C1 and C2; this shared substringforms part of the context for the new rule (C?)
?
inthis case, [s].
If C1 and C2 both contain additionalunmatched material, then the segments immedi-ately to the left of C?
(here, [?]
and [?])
are com-pared to see what features they have in common.
Ifthey share any feature specifications, these are re-tained as a left-side featural term (C?feat), in thiscase, [+syllabic, ?low, ?back, ?tense, ?round].
Fi-nally, if either C1 or C2 contains any additionalmaterial that has not been included in C?
or C?feat,this is converted into a free variable (X).
The sameprocedure is carried out in mirror image on theright, yielding shared D?
and D?feat terms, and aright-side variable Y.
Any of these terms may benull.This generalization procedure retains as muchshared material as possible, yielding the most spe-cific rule that will cover both input forms.
For thisreason, we call it minimal generalization.Minimal generalization is iterated over the dataset.
Iteration consists of comparing word-specificrules against other word-specific rules, and alsoagainst generalized rules.3 The procedure for com-paring a word-specific rule with a generalized ruleis much the same as in (5), but with the complica-tion that it is often necessary to compare a segmentin the word-specific rule with a featural term (C?feat,D?feat) in the generalized rule.The result of this procedure is a large list ofrules, describing all of the phonological contexts inwhich each change applies.
The fact that the modelretains rules for each change means that it has thepotential to generate multiple outputs for a novelinput, satisfying one of the criteria we proposed insection 2.In some learning models, the goal of rule in-duction is to find the most general possible rule foreach change.
However, as noted above, we alsorequire our model to assign gradient well-formedness scores to each output.
To do this, weevaluate the reliability of rules, then evaluate out-puts on the basis of the rules that derive them.3.2 Calculating reliability and confidenceThe reliability of rules is calculated as follows.First, we determine the number of forms in thetraining data that meet the structural description ofthe rule (for A ?
B / C__D, these are the formsthat contain CAD).
This number is the scope of therule.
The hits of the rule is the number of formsthat it actually derives correctly.
The reliability ofa rule is simply the ratio of its hits to its scope.Intuitively, reliability is what makes a ruletrustable.
However, reliability based on high scope(for example, 990 correct predictions out of 1000)is better than reliability based on low scope (forexample, 5 out of 5).
Following Mikheev (1997),we therefore adjust reliability using lower confi-3 We believe, but have not proven, that no additional rules arediscovered by comparing generalized rules against generalizedrules.dence limit statistics.4 The amount of the adjust-ment is a parameter (?
), which ranges from .5 < ?< 1; the higher the value of ?, the more drastic theadjustment.
The result of this adjustment value,which ranges from 0 to 1, we call confidence.
Con-fidence values are calculated for each generalizedrule, as soon as it is discovered.
As each new inputpair is processed, it is compared against previouslydiscovered generalized rules to see whether it addsto their hits or scope.
If so, their confidence valuesare updated.The list of rules, annotated for confidence, canbe used to derive outputs for novel (unknown) in-puts.
In some systems, rules are applied in order ofdecreasing specificity; the particular rule that isused to derive an output is the most specific oneavailable.
In our system, rules are applied in orderof decreasing confidence.
The novel form is com-pared against each known change Ai ?
Bi to see ifit contains the input to the change (Ai).
If so, therules for that change are examined, in order of de-creasing confidence, checking each rule to see if itis applicable.
Once an applicable rule has beenfound, it is applied to create a novel output, and thenext change (Ai+1 ?
Bi+1) is considered.
Each out-put is assigned a well-formedness score, which isthe confidence value of the rule that derives it; thatis, the confidence value of the best available rule.These well-formedness scores allow the model tosatisfy the second criterion laid out in section 2.Minimal generalization and confidence valuesprovide an effective method of discovering thephonological context in which a particular mor-phological change applies.
Rules that describe pro-ductive processes in the correct context will have a4 Following Mikheev, we use the following formula to calcu-late lower confidence limits: first, a particular reliability value(p?)
is smoothed to avoid zeros in the numerator or denomina-tor, yielding an adjusted value p?
*:p?i* =xi + 0.5ni + 1.0This adjusted reliability value is then used to estimate the truevariance of the sample:estimate of true variance =p?
*(1 ?
p?
*)nFinally, this variance is used to calculate the lower confidencelimit (?L), at the confidence level ?
:?L = p?i* ?
z(1-?
)/2 ?p?
*(1 ?
p?
*)n(The value z for confidence level ?
is found by look-up table.
)very high confidence, whereas rules that describeexceptional processes or the wrong contexts willhave lower confidence.Moreover, when a change applies with espe-cially high reliability in some particular context,the rule that the model discovers for this contextwill have especially high confidence.
Thus, forexample, the rule that suffixes [-t] in the context offinal voiceless fricatives (?2), which is exception-less and abundantly attested, is assigned an ex-tremely high confidence value by our model.3.3 Improving confidence with phonologyIn many cases, it is possible to improve the con-fidence of morphological rules, and even expandtheir context, by discovering phonological rules.To continue with the example from (1) above, con-sider the rule that the model will generalize fromthe items [h?g] and [r?b].
In the feature system weuse, the minimal natural class that covers both [g]and [b] is the set of voiced stops [b,d,g], so themodel constructs a generalized rule that attaches[-d] after any member of this class.Suppose that the model is presented next withthe input pair ([nid], [nid?d]).
It first attempts toupdate the confidence of the previously discoveredgeneralized rules, including the rule adding [d]after voiced stops.
Specifically, it tries to applyeach rule to [nid], checking to see if the rule canderive the correct output [nid?d].
When it doesthis, it discovers that the [-d] affixation rule fails,producing instead the incorrect output *[nidd].What we want the model to do in this situation isto recognize that [nid?d] is in fact an instance of[-d] affixation, but that there is an additionalphonological process of [?]
insertion that obscuresthis generalization.We allow the model to recognize this in thefollowing way: first, we provide it ahead of timewith a list of sequences that are illegal in English:*dd#, *td#, *fd#, *pd#, *bt#, and so on.
(We be-lieve that it is not unrealistic to do this, becauseexperimental work (Jusczyk et al, 1993; Friedericiand Wessels, 1993) suggests that children have agood notion of what sound sequences are legal intheir language well before they begin to learn al-ternations.)
When the learning model assesses thereliability of a rule and finds that it yields an incor-rect output, it compares the incorrect output againstthe actual form, and hypothesizes a phonologicalrule of the form A ?
B / C __ D that wouldchange the incorrect form into the correct one.
Inthis case, applying the [-d] suffixation rule to [nid]yields incorrect *[nidd], which is compared againstcorrect [nid?d], and the phonological rule that ishypothesized is ?
?
?
/ d__d.5 Finally, the modelexamines the target of the phonological rule (CAD,in this case [dd]) to see if it contains a member ofthe list of known illegal sequences.
If so, then themodel has discovered a phonological rule that canhelp the morphological rule to produce the correctoutput, by fixing a phonologically illegal sequence.In the present case, the phonological rule allows[nid] to be counted as a hit for the morphologicalrule of [-d] suffixation, thus increasing the latterrule?s reliability.3.4 Overcoming complementary distributionUnfortunately, not all phonological rules can bediscovered by waiting for morphological rules toproduce incorrect outputs.
Consider how ourmodel would analyze the pair ([m?s], [m?st])?miss(ed)?.
Using the mechanisms describedabove, this would initially be treated as a case of[-t] suffixation.
However, a more general analysiscan be found if we realize that [-t] can be the resultof /-d/ suffixation, with a phonological rule of de-voicing that converts /-d/ to [-t] after a voicelessconsonant.
This could be achieved by having themodel try attaching [-d] to [m?s], yielding incorrect*[m?sd], from which the devoicing rule could bediscovered using the procedure described in theprevious section.
However, under the assumptionof strictly minimal generalization, the opportunityto try [-d] after [m?s] would never arise.
The reasonis that [-d] suffixation was learned solely on thebasis of voiced stems, so it would never apply to avoiceless stem like [m?s].
More generally, the [-d]and [-t] allomorphs of the English past tense suffixoccur in complementary distribution, so a systemthat uses minimal generalization would never con-struct rules that attempt to use one allomorph in theenvironment of the other.Our solution to this problem involves a slightrelaxation of minimal generalization.
The intuitionis that when a new change is discovered (A ?
B,5 The set of possible phonological rules is restricted to insert-ing a segment, deleting a segment, altering a segment, con-verting one segment into two (diphthongization), convertingtwo segments into one (simple coalescence), or converting twosegments into two others (length-preserving coalescence (/XZ/?
[YY]) and metathesis).in this case ?
?
d), we should check to see ifthere are any potentially related changes that havealready been discovered (A ?
B?, here ?
?
t) thattake the same input (A), but yield a different out-put.
The idea is that B and B?
might be the result ofthe same morphological rule, obscured by aphonological change.To do this, we take every context that appearsin a rule with change A ?
B and pair it with thechange A ?
B?, creating a new set of rules, whichwe will call cross-context rules.
For example,when the model encounters the first pair employ-ing the ?
?
d change, it takes all of the existing?
?
t rules and creates cross-context ?
?
d vari-ants of them.
The result is, among other things, arule affixing [-d] after voiceless fricatives, mirror-ing the previously generalized rule affixing [-t] inthe same environment.The model then assesses the reliability of thiscross-context rule, applying it to (among others)[m?s] and deriving incorrect *[m?sd].
By compar-ing this with the actual output [m?st], the modelposits a phonological rule for devoicing, in thesame manner as described in the previous section.It then checks to see if the proposed phonologicalrule will enable the cross-context rule to producethe same output as the rule from which it wascloned in all cases.
If so, the cross-context rule iskept, and can serve as the input for further gener-alization.
Thus, the phonological rule is able toextend the set of contexts in which [-d] affixationsuccessfully applies.With these procedures in place, our model isable to discover a single rule that covers all Eng-lish regular past tenses, namely ?
?
d / ___ #.The various regular past tense allomorphs are de-rived from /-d/ by phonological rules of voicingassimilation (deriving [-t]) and [?]
insertion (de-riving [-?d]).
We would guess that these are therules that are assumed by most linguists; see Pinkerand Prince (1988) for a detailed presentation.However, we discuss evidence below suggestingthat simple [-d] affixation is not the only rule thatderives regulars.3.5 The grammar so farWe summarize here the grammar that is learned byour model (as described up until this point) whenexposed to a representative corpus of English pres-ent-past pairs.
The most general rule of the gram-mar is the noncontextual suffixation rule ?
?
d /___ #; with the help of phonology this rule canderive all regulars.
In addition, the model also dis-covers a large number of rules with lower general-ity.
Many of these rules describesubgeneralizations about the regular process, forexample, the highly reliable rule suffixing [-t] (orits underlying counterpart /-d/) after voicelessfricatives.
Other rules describe exceptional proc-esses, such as ?
?
?
before [?]
(fling-flung, wring-wrung, etc.
), i ?
?
between a liquid and [d] (bleed-bled, read-read, etc.
), and no change after [t] (hit-hit, cut-cut, etc.).
In general, such exceptional pro-cesses will have much lower confidence than theregular rules, partly because they are based onfewer forms, and partly because there are regularforms that fail to obey them (need-needed, not*ned).Lastly, the model learns a large number of rulesthat could fairly be described as detritus, becausethey are never used in deriving any form (other,more reliable rules take precedence over them).
Inprinciple, we could prune these rules from the fin-ished grammar, though we have not taken this stepin our current implementation.3.6 The distributional encroachment problemExceptional forms are easy to identify as suchwhen they involve a change that occurs in only afew words, such as ?
?
?.
Not all exceptions havethis property, however; sometimes exceptions aredisguised by the fact that they involve a changethat is regular, but in a different environment.An example of this type of exception is seen inthe past tense forms in (6), which occur in somedialects of English:(6) ([b?
?n]pres., [b?
?nt]past) ?burn(t)?([l?
?n]pres., [l?
?nt]past) ?learn(t)?
([dw?l]pres., [dw?lt]past) ?dwell(t)?
([sp?l]pres., [sp?lt]past) ?spell(t)?
([sm?l]pres., [sm?lt]past) ?smell(t)?These words form their past tense using one of theregular changes (?
?
t), but in the wrong envi-ronment (after sonorant consonants, rather thanafter voiceless ones).
We call this type of excep-tion distributional encroachment, because onemorphological change is encroaching on thephonological context in which another changeregularly occurs.Distributional encroachment appears to be amajor problem for all morphological learning sys-tems that attempt to find large-scale generaliza-tions.
In what follows, we will explain why theexample in (6) is problematic, then propose amethod for coping with distributional encroach-ment in general.Assume that prior to hearing any of the forms in(6), the model has already processed a fair numberof regular stems ending in voiceless obstruents.6Comparing forms like [m?s]-[m?st] ?miss(ed)?,[l?f]-[l?ft] ?laugh(ed)?, and [dZ?mp]-[dZ?mpt]?jumped?, the model would learn a number of rulesof [t]-suffixation.
Since [t] suffixation after voice-less obstruents is the regular outcome in English,these rules will achieve quite high confidencescores.
Moreover, if we are willing to have aphonological rule that voices /-t/ to [-d] after avoiced obstruent, the context of /-t/ suffixationcould be expanded to all obstruents.
Under thisanalysis, past tense forms like hugged can now bederived as /h?g/ ?
h?gt ?
[h?gd], so the confi-dence for this generalized rule would be evenhigher.The distributional encroachment problem is en-countered when the model, having reached thisstate, is confronted with one of the exceptionalforms in (6).
The result will be a serious overgen-eralization.
Suppose that the first such form en-countered is [b??n]-[b?
?nt] ?burn(t)?.
The modelwould first posit a single-form rule adding [-t] afterthe stem [b??n].
Then, the generalization procedurewould compare it with the other known [-t] affixa-tion rules, all of which apply after obstruents.
Thiscomparison would lead to a generalized rule add-ing [-t] after any consonant at all: ?
?
t /[?syllabic]__#.Let us now estimate the reliability of this gen-eralized rule.
Corpus counts show that the finalsegments of verb stems occur in roughly the fol-lowing proportion in English:(7) Obstruents 60%Sonorant consonants 25%Vowels 15%Suppose that prior to learning the form burnt, themodel has learned 600 input pairs, of which 500are regular and 100 are irregular exceptions, none6 The voiceless obstruents of English are [p, t, tS, k, f, T, s,S, h], and the voiced obstruents are [b, d, dZ, g, v, ?, z, Z].of them of the burnt type.
Assume for simplicitythat the distribution of final segments in bothregulars and irregulars follows the proportions of(7).
Thus, there will be 300 regular obstruent-finalstems, and 60 obstruent-final exceptions, givingthe rule attaching [-t] after obstruents a reliabilityof 300/360 = .83.
Since 500 of the verbs are regu-lar and 100 are irregular, the confidence of the ruleattaching [-d] after any segment will be 500/600,which is also .83.When the model encounters the pair ([b??n],[b?
?nt]), this adds a sonorant-final stem employingthe ?
?
t change.
The first step the model takes isto update reliability scores.
Rules attaching [-t]after obstruents will be unaffected, since [n] is notan obstruent.
The reliability of the rule attaching[-d] everywhere drops a minuscule amount, from500/600 to 500/601.
The second step is the fatalone: generalization with [b?
?nt] gives rise to thenew rule ?
?
t / [?syllabic]__#.
This rule workscorrectly for 301 verbs (the 300 regular obstruent-final stems plus burnt), and fails for 210 verbs (the60 obstruent-final exceptions, plus 150 verbs otherthan burnt that end in a sonorant consonant).
Thus,its reliability would be 301/511, or .59.
The pre-diction therefore is that for novel verbs that end insonorant consonants, such as pran [pr?n], pastswith [-t] (prant [pr?nt]) should be at least moder-ately acceptable as a second choice, after theregular pranned [pr?nd].
We believe that this pre-diction is wrong; prant strikes us as absurd.3.7 Impugnment as a solution to the distribu-tional encroachment problemThe problem we are faced with is to let the modelidentify cases of distributional encroachment assuch, and not be fooled into grouping burnt andlaughed together under the same [-t] generaliza-tion.
Intuitively, the problem with the rule attach-ing [-t] after any consonant is that it is internallyheterogeneous; it consists of one very consistentsubset of cases (the obstruent-final stems) and onefundamentally different case (burnt).
We can char-acterize internal heterogeneity more precisely if wecompare the scope and hits of the ?correct?
rule(after obstruents) and the ?spurious?
rule (after anyconsonant):(8) Rule Hits Scope?
?
t / [?sonorant]__# 300 / 360?
?
t / [?syllabic]__# 301 / 511We see that the rule adding [-t] after any consonantgains just one hit, but adds a significant number ofexceptions (150).Formalizing this intuition, we propose a re-finement of the way that confidence is calculated,in order to diagnose when a subpart of a generali-zation is doing most of the work of the larger gen-eralization.
When we consider the confidence of acontext ?
associated with a change A ?
B, wemust consider every other context ??
associatedwith A ?
B, checking to see whether ??
covers asubset of the cases that ?
covers.
In the presentcase, when we assess the confidence of adding [-t]after any consonant, we would check all of theother rules adding [-t], including the one that adds[-t] after obstruents.
For each ??
that covers a sub-set of ?, we must ask whether the rule A ?
B / ?
?is actually ?doing most of the work?
of the largerrule A ?
B / ?.To find out if the smaller rule is doing most ofthe work, we calculate how well the larger rule (?
)performs outside the area covered by the smallerrule (??).
The reliability of the residue area (?
???)
is calculated as follows:(9) Reliability(?
?
??)
= hits(?)
?
hits(??)scope(?)
?
scope(??
)From the reliability of this residue area (?
???
), we can then calculate its confidence, usingconfidence limit statistics in a way similar to thatdescribed above in section 3.2.
However, there is acrucial difference: when we are assessing whethera rule explains enough cases to be trustable, we areinterested in the denseness of cases within the gen-eralization.
But when we are assessing whether arule offers an improvement over a subpart, we areinterested in the sparseness of cases in the residueoutside of the subpart.
Therefore, when calculatingthe confidence of the residue, we must use the up-per confidence limit rather than the lower confi-dence limit.If the upper confidence limit of the reliability ofthe residue (?
?
??)
is lower than the lower confi-dence limit of the reliability of the larger context(?
), then we can infer that the smaller rule(A ?
B / ??)
is doing most of the work of thelarger rule (A ?
B / ?).
Therefore, we penalize thelarger rule by replacing its confidence value(Lower confidence(?))
with the confidence valueof the residue (Upper confidence(?
?
??)).
We callthis penalty impugnment, because the validity ofthe larger rule is being called into question by thesmaller rule.
Impugnment is carried out for allcontexts of all rules.This impugnment algorithm is similar to thepruning algorithm proposed by Anthony and Frisch(1997).
However, their algorithm requires that thesmaller rule cover at least as many positive cases(hits) as the larger rule.
In this case, the larger ruledoes cover one more case than the smaller rule (theform burnt), so it would not be eligible for pruningunder their system.
Impugnment is also similar tothe pruning strategies based on ?minimum im-provement?
or ?lift?
(e.g., Bayardo, Agrawal andGunopulos 1999), but in this case, we are consid-ering the improvement of a more general (lessspecified) context, rather than a more specific one,and the criterion of improvement is built in ratherthan user-specified.3.8 The status of impugnmentWe find that in general, impugnment suffices torelegate forms of the burnt class to the status ofminor irregular classes, and thus saves the modelfrom serious overgeneralization.
Since distribu-tional encroachment appears to be common in lan-guages (Albright and Hayes 1999), we feel thatimpugnment or some other algorithm of equivalenteffect is crucial for accurate morphological learn-ing.This said, we must add a somewhat puzzlingpostscript.
In the experiment described below, wefound that speakers gave forms like prant surpris-ingly high ratings.
As a result, we found that wecould achieve the closest match in modeling theexperimental data by turning impugnment off.
Wefeel that the high ratings for prant forms mostlikely were an artifact, reflecting the sociolinguis-tic status of burnt pasts (they are most often en-countered by Americans as literary forms and maybe felt to be prestigious).
The upshot is that at pre-sent the empirical necessity of impugnment re-mains to be demonstrated.4 Testing the Model4.1 TrainingBefore a model can be tested, it must be trainedon a representative learning set.
For our studies ofEnglish past tenses, we used a corpus of 4253verbs, consisting of all the verbs that had a fre-quency of 10 or greater in the English portion ofthe CELEX database (Burnage 1991).
We trainedour model to predict the past tense form from thepresent stem.The model, implemented in Java,7 accom-plished its task fairly rapidly, learning the Englishpast tense pattern in about 20 minutes on a 450MHz PC.
Most of this learning time was spent ex-panding and refining the more detailed rules; thebroad generalizations governing the system were inplace after only a few dozen words had been ex-amined.4.2 Corpus testingAs a first test of our model?s performance, wedivided the training data randomly into ten parts,and used the model to predict past tenses for eachpart based on the remaining nine tenths.
For virtu-ally every verb, the first choice of our model wasthe regular past tense, in its phonologically correctform: [-t], [-d], or [-?d], depending on the lastsegment of the stem.
We consider this preferenceto be appropriate, given that English past tenses areon the whole a highly regular system; humanspeakers output irregulars only because they havememorized them.4.3 Testing on novel formsIn our opinion, the most important criterion fora model like ours is the ability to deal with novel,made-up stems in the same way that people do.Novel stems access the native speaker?s generativeability, abstracting away from whatever behaviorresults from memorization of existing verbs.To begin, we have found that the model cor-rectly inflects unusual words like Prasada andPinker?s (1993) ploamph and smairg; i.e.
as[plomft] and [smergd].
The model can do this be-cause it learns highly general rules that encompassthese unusual items.
Moreover, when confrontedwith the non-English sound [x] in to out-Bach[aUtbax], our model correctly predicts [aUtbaxt].The model is able to do this because it can gener-alize using features, and thus can learn a rule thatcovers [x] based on phonetically similar segmentslike [f] and [k].On a more systematic level, we have exploredthe behavior of the model with a carefully chosen7 Source code available at http://www.linguistics.ucla.edu/people/hayes/rulesvsanalogy/set of made-up verbs, which were rated both by ourmodel and by groups of native speakers.
We car-ried out two experiments, which are described indetail in Albright and Hayes (2001).In our first experiment, we asked participants tocomplete a sentence by using the past tense of amade-up verb that had been modeled in previoussentences.
For example, participants filled in theblank in the frame ?The chance to rife would bevery exciting.
My friend Sam ___ once, and heloved it.?
Typically, they would volunteer rifed, oroccasionally rofe or some other irregular form.
Inthe second experiment, participants were given anumber of choices, and rated each on a scale from1 (worst) to 7 (best).In selecting verbs to use in the experiments, wetried to find a set of verbs for which our learningmodel would make a wide range of different pre-dictions.
We began with a constructed corpus ofphonologically-ordinary monosyllables (i.e.
com-binations of common onsets and rhymes), and usedthe model to predict past tenses for each.
Based onthese predictions, we selected four kinds of verbs,which according to the model:I. should sound especially good as regular,but not as irregularII.
should sound especially good as (somekind of) irregular, but not as regularIII.
should sound good both as regular and assome kind of irregularIV.
should not sound especially good either asregular or as any kind of irregularHere are examples of all four categories.I.
Blafe is expected to sound particularly good as aregular (because it falls within the scope of thehigh confidence voiceless-fricative rule), but not asan irregular.
II.
Spling is expected to sound espe-cially good as an irregular (splung), because it fitsa high-reliability [I] ?
[?]
rule, but it is not pre-dicted to be especially good as a regular.
III.
Bizeis predicted to sound good as both a regular and anirregular, since it falls into a highly reliable contextfor regulars (final fricatives) and also falls into ahighly reliable context for the [a?]
?
[o] change(before a coronal obstruent).
IV.
Gude is not cov-ered by any especially reliable rules for eitherregulars or irregulars.
The full set of verbs is givenin the Appendix.When we tested these four categories of made-up verbs, we found that our participants gave themratings that corresponded fairly closely to the pre-dictions of our model.
Not only did participantsstrongly prefer regulars, as we would expect, butthere was also a good match of model to datawithin the categories I-IV defined above.
The fol-lowing graphs show this for both regulars and ir-regulars (all responses are rescaled to the samevertical axis):Figure 1.
Mean ratings for regulars3.03.54.04.55.05.56.06.57.0I.
II.
III.
IV.MeanratingParticipantsModelFigure 2.
Mean ratings for irregulars3.03.54.04.55.05.56.06.57.0I.
II.
III.
IV.MeanratingParticipantsModelThe graphs show data for participant ratings;similar results were obtained when we countedhow frequently the various past tenses were vol-unteered when the participants were asked to fill inthe blanks themselves.As a more stringent test, we can examine notjust mean values, but word-by-word predictions.
Ameasure of this is the correlation between themodel?s predictions and the experimental results.The correlations are carried out separately forregulars and irregulars, since an overall correlationonly establishes that the model knows that itshould rate regulars highly.
(10) Ratings Data (n = 41)regulars r = .745, p < .0001irregulars r = .570, p < .0001(11) Volunteered Data (% volunteered, n = 41)regulars r = .695, p < .0001irregulars r = .333, p < .05In summary, our experiments validate a numberof the model?s predictions.
First, participants preferregulars over irregulars.
Second, their intuitions aregradient, ranging continuously over the scale.Third, participants favor only those irregular formsthat fall within a context characteristic of existingirregular verbs, like -ing ~ -ung.
Finally, and mostsurprisingly, the participants followed the predic-tions of our model in favoring regular forms thatcan be derived by rules with high reliability.8We conclude that our model captures a numberof subtle but important patterns in the preferencesof human speakers for past tense formation ofnovel verbs.
Some of these preferences (e.g., thespecial preference for voiceless-fricative regulars)are not predicted by traditional linguistic analyses.We have obtained similar results in other lan-guages (Albright 1999; to appear) We suspect thatthere may be many generalizations in morphologythat are apprehended by native speakers but havebeen missed by traditional analysis.
The use ofmachine learning may be useful in detecting suchgeneralizations.5 How the model could be improved5.1 Phonological representationsOur model uses a very simple kind of phonologicalrepresentation, from Chomsky and Halle (1968),and a very simple schema for rules ((5)).
Whilethis works well in systems that involve only localphonological generalizations, more complex sys-tems are likely to require better representations ifthe correct generalizations are to be discovered.For example, the notion ?closest vowel?
is neededto characterize vowel harmony (e.g.
Hungariank?nyv-nAk ?
k?nyv-nek ?book-dative?).
Our modelcannot ignore the consonants that intervene be-tween vowels, so it would not do well in learningthis kind of rule.
Our model also lacks any notion8 Statistical testing reported in Albright and Hayes (2001)indicates that the effect on regulars cannot be attributed (en-tirely) to a ?trade-off?
effect with irregulars; i.e.
splinged doesnot sound bad just because splung sounds good.
In fact, theobservable tradeoff effects are equally strong in both direc-tions: some irregular forms sound worse because they also fallinto a strong context for regulars.of syllables or syllable weight.
Thus it could notlearn the generalization that all polysyllabic Eng-lish verb stems are regular (Pinker and Prince1988); nor could it learn the distribution of theLatin abstract noun suffixes [-ia] and [-ie?s], whichdepends on the weight of the stem-final syllable([gra?.ti.a] ?favor?, [kle.men.tia] ?mercy?
vs.[ma?.te.ri.e?s] ?matter?
; Mester 1994).
Lastly, themodel lacks any notion of foot structure.
Thus, itcould not learn the distribution of the Yidiny loca-tive suffixes [-la] and [-?]
(prelengthening), whichis arranged so that the output will have an evennumber of syllables, that is, an integral number ofdisyllabic stress feet ([?gabu][?dyula] ?clay-loc.?
vs.[?u?na?][ga?ra?]
?whale-loc?
; Dixon 1977).Phonological theory provides some of the means tosolve these problems: theories of long-distancerules (e.g.
Archangeli and Pulleyblank 1987), ofsyllable weight (McCarthy 1979), and of footstructure (Hayes 1982).
We anticipate that incorpo-rating such mechanisms would permit these phe-nomena to be learned by our system.At the same time, however, we must considerthe possibility that introducing new structures mayexpand the hypothesis space so much that it cannotbe searched effectively by minimal generalization.Thus, where there are alternative phonologicaltheories available, they should be assessed forwhether they permit the right generalizations to befound without excessively expanding search time.It may also be possible to cut back on search timeby using better algorithms for searching the hy-pothesis space.5.2 Multiple changesA number of morphological processes involvemultiple changes, as in the German past participlegeschleppt ?dragged?, derived from schlepp- usingboth prefixation and suffixation.
Our model (spe-cifically, our method for detecting affixes) cannotcharacterize such cases as involving two simplechanges, and would treat the relation as arbitrary.Two methods that might help here would be (a) touse some form of string-edit distance (Kruskal1983), weighted by phonetic similarity, to deter-mine that -schlepp- is the string shared by the twoforms; (b) to adopt some method of morphemediscovery (e.g.
Baroni 2000; Goldsmith 2001;Neuvel, to appear; Schone and Jurafsky 2001;Baroni et al 2002) and use its results to favor rulesthat prefix ge- and suffix -t.Summarizing, we anticipate that improvementsin the model could result from better phonologicalrepresentations, better methods of search, and moresophisticated forms of string matching.Appendix: Made-Up Verbs Used in theExperimentsI.
Expected to be especially good as regularblafe [blef], bredge [br?dZ], chool [tSul], dape[dep], gezz [g?z], nace [nes], spack [sp?k],stire [sta?r], tesh [t?S], wiss [w?s]II.
Expected to be especially good as irregularblig [bl?g], chake [tSek], drit [dr?t], fleep[flip], gleed [glid], glit [gl?t], plim [pl?m],queed [kwid], scride [skra?d], spling [spl??
],teep [tip]III.
Expected to be good both as regular and asirregularbize [ba?z], dize [da?z], drice [dra?s], flidge[fl?dZ], fro [fro], gare [ger], glip [gl?p], rife[ra?f], stin [st?n], stip [st?p]IV.
Not expected to be especially good either asregular or as irregulargude [gud], nold [nold], nung [n??
], pank[p?
?k], preak [prik], rask [r?sk], shilk [S?lk],tark [tark], trisk [tr?sk], tunk [t?
?k],ReferencesAlbright, Adam.
1999.
Phonological subregularities ininflectional classes: Evidence from Italian.
In Mat-thew Gordon, ed., UCLA Working Papers in Lin-guistics, Vol.
1 (Papers in Phonology 2), pp.
1-47.Albright, Adam.
To appear.
The productivity of infixa-tion in Lakhota.
To appear in Pamela Munro, ed.,UCLA Working Papers in Linguistics (Studies inLakhota).Albright, Adam and Bruce Hayes 1999.
Distributionalencroachment and its consequences for phonologicallearning.
UCLA Working Papers in Linguistics 4(Papers in Phonology 4), 179-190.Albright, Adam and Bruce Hayes.
2001.
Rules vs. anal-ogy in English past tenses: A computa-tional/experimental study.
Ms., Department ofLinguistics, UCLA.
http://www.linguistics.ucla.edu/people/hayes/rulesvsanalogy/Archangeli, Diana and Douglas Pulleyblank.
1987.Maximal and minimal rules: effects of tier scansion.In Joyce McDonough and Bernadette Plunkett, eds.,Proceedings of the North Eastern Linguistic Society17, Graduate Linguistics Student Association, Uni-versity of Massachusetts, Amherst, pp.
16-35.Baroni, Marco.
2000.
Distributional cues in morphemediscovery: A computational model and empiricalevidence.
Ph.D. dissertation, UCLA.
http://www.ai.univie.ac.at/~marco/Baroni Marco, Johannes Matiasek, and Trost Harald.2002.
Unsupervised discovery of morphologicallyrelated words based on orthographic and semanticsimilarity.
To appear in Proceedings of the Workshopon Morphological and Phonological Learning ofACL-2002.
http://www.ai.
univie.ac.at/~marco/Bayardo, R., R. Agrawal and D. Gunopulos.
1999.
Con-straint-based rule mining in large, dense databases.
InICDE-99.
http://citeseer.nj.nec.com/ ba-yardo99constraintbased.htmlBurnage, G. 1991.
CELEX - A Guide for Users.
Nijme-gen: Centre for Lexical Information, University ofNijmegen.Chomsky, Noam and Morris Halle.
1968.
The SoundPattern of English.
New York: Harper and Row.Daugherty, Kim G. and Mark S. Seidenberg.
1994.
Be-yond rules and exceptions: a connectionist approachto inflectional morphology.
In S. D. Lima, R. L. Cor-rigan and G. K. Iverson, eds., The Reality of Linguis-tic Rules.
Amsterdam: J. Benjamins.Dixon, Robert M. W. 1977.
A Grammar of Yidiny.
Cam-bridge: Cambridge University Press.Dzeroski, Saso and Tomaz Erjavec.
1997.
LearningSlovene declensions with FOIDL.
In W. Daelemans,A.
Van den Bosch, and A. Weijters, eds., WorkshopNotes of the ECML/Mlnet Workshop on EmpiricalLearning of Natural Language Processing Tasks,Prague, pp.
49-60.Eddington, David.
2000.
Analogy and the dual-routemodel of morphology.
Lingua 110:281?298.Friederici, A. D. and Wessels, J. E. 1993.
Phonotacticknowledge of word boundaries and its use in infantspeech perception.
Perception and Psychophysics54:287?295.Goldsmith, John.
2001.
Unsupervised learning of themorphology of a natural language.
ComputationalLinguistics 27:153-198.Halle, Morris.
1978.
Knowledge unlearned and un-taught: what speakers know about the sounds of theirlanguage.
In Morris Halle, Joan Bresnan, and GeorgeMiller, eds., Linguistic Theory and PsychologicalReality.
Cambridge, MA: MIT Press, pp.
294-303.Hayes, Bruce.
1982.
Metrical structure as the organizingprinciple of Yidiny phonology.
In H. van der Hulstand N. Smith, eds., The Structure of PhonologicalRepresentations, Part I. Dordrecht: Foris Publica-tions, pp.
97-110.Jusczyk, P. W., Friederici, A. D., Wessels, J. M.,Svenkerud, V. Y. and Jusczyk, A. M. (1993).
Infants?sensitivity to the sound patterns of native languagewords.
Journal of Memory and Language 32:402?420.Jusczyk, P. W., Luce, P. A. and Charles-Luce, J.
1994.Infants?
sensitivity to phonotactic patterns in the na-tive language.
Journal of Memory and Language33:630?645.Kruskal, J.
B.
1983.
An overview of sequence compari-son.
In D. Sankoff and J.
B. Kruskal, eds., TimeWarps, String Edits, and Macromolecules: The The-ory and Practice of Sequence Comparison.
Reading,MA: Addison-Wesley Publishing Company.Ling, Charles X. and Marin Marinov.
1993.
Answeringthe connectionist challenge: A symbolic model oflearning the past tenses of English verbs.
Cognition49:235?290.McCarthy, John.
1979.
On stress and syllabification.Linguistic Inquiry 10:443-465.MacWhinney, Brian and Jared Leinbach.
1991.
Imple-mentations are not conceptualizations: Revising theverb learning model.
Cognition 40:121-157.Mester, Armin.
1994.
The quantitative trochee in Latin.Natural Language and Linguistic Theory 12: 1-61.Mikheev, Andrei.
1997.
Automatic rule induction forunknown-word guessing.
Computational Linguistics23:405?423.Mooney, Raymond J. and Mary Elaine Califf.
1995.Learning the past tense of English verbs using induc-tive logic programming.
In Stefan Wermter, EllenRiloff, and Gabriele Scheler, eds., Connectionist,Statistical, and Symbolic Approaches to Learning forNatural Language Processing.
Springer Verlag, pp.370-384Nakisa, Ramin.
C., Kim Plunkett, and Ulrike Hahn.2001.
A cross-linguistic comparison of single anddual-route models of inflectional morphology.
In P.Broeder and J. Murre, eds., Models of Language Ac-quisition: Inductive and Deductive Approaches.Cambridge, MA: MIT Press.Neuvel, Sylvain.
To appear.
Whole word morpholo-gizer.
To appear in Brain and Language.Pinker, Steven.
1999.
Words and Rules: The Ingredientsof Language.
New York: Basic Books.Pinker, Steven and Alan S. Prince.
1988.
On languageand connectionism: Analysis of a parallel distributedprocessing model of language acquisition.
Cognition28:73?193.Prasada, Sandeep and Pinker, Steven.
1993.
Generaliza-tion of regular and irregular morphological patterns.Language and Cognitive Processes 8:1?56.Rumelhart, David.
E. and McClelland, Jay L. 1986.
Onlearning the past tenses of English verbs.
In D. E.Rumelhart, J. L. McClelland, and The PDP ResearchGroup, eds., Parallel Distributed Processing: Explo-rations in the Microstructure of Cognition: Vol.
2.Cambridge, MA: MIT Press, pp.
216-271.Schone, Patrick and Daniel Jurafsky.
2001.
Knowledge-free induction of inflectional morphologies.
Pro-ceedings of the North American chapter of the Asso-ciation for Computational Linguistics (NAACL-2001).http://www.colorado.edu/linguistics/jurafsky/pubs.html.Simon, Anthony and Alan Frisch.
2001.
Cautious in-duction in inductive logic programming.
In ILP97,The Seventh International Workshop on InductiveLogic Programming, pp.
45-60.
