Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 160?170,Dublin, Ireland, August 23-24 2014.Contrasting Syntagmatic and Paradigmatic Relations:Insights from Distributional Semantic ModelsGabriella Lapesa3,11Universit?at Osnabr?uckInstitut f?urKognitionswissenschaftglapesa@uos.deStefan Evert22FAU Erlangen-N?urnbergProfessur f?urKorpuslinguistikstefan.evert@fau.deSabine Schulte im Walde33Universit?at StuttgartInstitut f?ur MaschinelleSprachverarbeitungschulte@ims.uni-stuttgart.deAbstractThis paper presents a large-scale evalua-tion of bag-of-words distributional modelson two datasets from priming experimentsinvolving syntagmatic and paradigmaticrelations.
We interpret the variation inperformance achieved by different settingsof the model parameters as an indicationof which aspects of distributional patternscharacterize these types of relations.
Con-trary to what has been argued in the litera-ture (Rapp, 2002; Sahlgren, 2006) ?
thatbag-of-words models based on second-order statistics mainly capture paradig-matic relations and that syntagmatic rela-tions need to be gathered from first-ordermodels ?
we show that second-order mod-els perform well on both paradigmatic andsyntagmatic relations if their parametersare properly tuned.
In particular, our re-sults show that size of the context windowand dimensionality reduction play a keyrole in differentiating DSM performanceon paradigmatic vs. syntagmatic relations.1 IntroductionDistributional takes on the representation and ac-quisition of word meaning rely on the assump-tion that words with similar meaning tend to oc-cur in similar contexts: this assumption, known asdistributional hypothesis, has been first proposedby Harris (1954).
Distributional Semantic Mod-els (henceforth, DSMs) are computational mod-els that operationalize the distributional hypoth-esis; they produce semantic representations forwords in the form of distributional vectors record-ing patterns of co-occurrence in large samples oflanguage data (Sahlgren, 2006; Baroni and Lenci,2010; Turney and Pantel, 2010).
Comparison be-tween distributional vectors allows the identifica-tion of shared contexts as an empirical correlate ofthe semantic similarity between the target words.As noted in Sahlgren (2008), the notion of seman-tic similarity applied in distributional approachesto meaning is an easy target of criticism, as it isemployed to capture a wide range of semantic re-lations, such as synonymy, antonymy, hypernymy,up to topical relatedness.The study presented in this paper contributesto the debate concerning the nature of the seman-tic representations built by DSMs, and it does soby comparing the performance of several DSMsin a classification task conducted on priming dataand involving paradigmatic and syntagmatic rela-tions.
Paradigmatic relations hold between wordsthat occur in similar contexts; they are also calledrelations in absentia (Sahlgren, 2006) becauseparadigmatically related words do not co-occur.Examples of paradigmatic relations are synonyms(e.g., frigid?cold) and antonyms (e.g., cold?hot).Syntagmatic relations hold between words that co-occur (relations in praesentia) and therefore ex-hibit a similar distribution across contexts.
Typi-cal examples of syntagmatic relations are phrasalassociates (e.g., help?wanted) and syntactic collo-cations (e.g., dog?bark).Distributional modeling has already tackled theissue of paradigmatic and syntagmatic relations(Sahlgren, 2006; Rapp, 2002).
Key contributionsof the present work are the scope of its evaluation(in terms of semantic relations and model parame-ters) and the new perspective on paradigmatic vs.syntagmatic models provided by our results.Concerning the scope of the evaluation, this isthe first study in which the comparison involvessuch a wide range of semantic relations (paradig-matic: synonyms, antonyms and co-hyponyms;syntagmatic: syntactic collocations, backward andforward phrasal associates).
Moreover, our eval-uation covers a large number of DSM parame-ters: source corpus, size and direction of the con-text window, criteria for feature selection, feature160weighting, dimensionality reduction and index ofdistributional relatedness.
We consider the varia-tion in performance achieved by different parame-ter settings as a cue towards characteristic aspectsof specific relations (or groups of relations).Our work also differs from previous studies(Sahlgren, 2006; Rapp, 2002) in its focus onsecond-order models.
We aim to show that theyare able to capture both paradigmatic and syn-tagmatic relations with appropriate parameter set-tings.
In addition, this focus provides a uniformexperimental design for the evaluation.
For ex-ample, parameters like window size and direction-ality apply to bag-of-words DSMs and colloca-tion lists but not to term-context models; dimen-sionality reduction, whose effect has not yet beenexplored systematically in the context of syntag-matic and paradigmatic relations, is not applicableto collocation lists.This paper is structured as follows.
Section 2summarizes previous work.
Section 3 describesthe experimental setup, in terms of task, datasetsand evaluated parameters.
Section 4 introducesour model selection methodology.
Section 5presents the results of our evaluation study.
Sec-tion 6 summarizes main findings and sketches on-going and future work.2 Previous WorkIn this section we discuss previous work relevantto the distributional modeling of paradigmatic andsyntagmatic relations.
For space constraints, wefocus only on two studies (Rapp, 2002; Sahlgren,2006) in which the two classes of relations arecompared at a global level, and not on studiesthat are concerned with specific semantic rela-tions, e.g., synonymy (Edmonds and Hirst, 2002;Curran, 2003), hypernymy (Weeds et al., 2004;Lenci and Benotto, 2012) or syntagmatic predicatepreferences (McCarthy and Carroll, 2003; Erk etal., 2010), etc.In previous studies, the comparison of syntag-matic and paradigmatic relations has been imple-mented in terms of an opposition between differ-ent classes of corpus-based models: term-contextmodels (words as targets, documents or context re-gions as features) vs. bag-of-words models (wordsas targets and features) in Sahlgren (2006); col-location lists vs. bag-of-words models in Rapp(2002).
Given the high terminological variationin the literature, in this paper we will adopt thelabels syntagmatic and paradigmatic to character-ize different types of semantic relations, and wewill use the labels first-order and second-orderto characterize corpus-based models with respectto the kind of co-occurrence information they en-code.
We will refer to collocation lists and term-document DSMs as first-order models, and to bag-of-words DSMs as second-order models1.Rapp (2002) integrates first-order (co-occurrence lists) and second-order (bag-of-wordsDSMs) information to distinguish syntagmaticand paradigmatic relations.
Under the assumptionthat paradigmatically related words will be foundamong the closest neighbors of a target word inthe DSM space and that paradigmatically and syn-tagmatically related words will be intermingledin the list of collocates of the target word, Rappproposes to exploit a comparison of the mostsalient collocates and the nearest DSM neighborsto distinguish between the two types of relations.Sahlgren (2006) compares term-context andbag-of-words DSMs in a number of tasks involv-ing syntagmatic and paradigmatic relations.
First,a comparison between the thesaurus entries for tar-get words (containing both paradigmatically andsyntagmatically related words) and neighbors inthe distributional spaces is conducted.
It showsthat, while term-context DSMs produce both syn-tagmatically and paradigmatically related words,the nearest neighbors in a bag-of-words DSMmainly provide paradigmatic information.
Bag-of-words models also performed better than term-context models in predicting association norms,in the TOEFL multiple-choice synonymy task andin the prediction of antonyms (although the dif-ference in performance was less significant here).Last, word neighborhoods are analysed in terms oftheir part-of-speech distribution.
Sahlgren (2006)observes that bag-of-words spaces contain moreneighbors with the same part of speech as the tar-get than term-context spaces.
He concludes thatbag-of-words spaces privilege paradigmatic rela-tions, based on the assumption that paradigmati-cally related word pairs belong to the same part ofspeech, while this is not necessarily the case forsyntagmatically related word pairs.1Term-document models encode first-order informationbecause dot products between row vectors are related to co-occurrence counts of the corresponding words (within docu-ments).
More precisely, for a binary term-document matrix,cosine similarity is identical to the square root of the MI2as-sociation measure.
Please note that our terminology differsfrom that of Sch?utze (1998) and Peirsman et al.
(2008).161Summing up, in both Rapp (2002) and Sahlgren(2006) it is claimed that second-order models per-form poorly in predicting syntagmatic relations.However, neither of those studies involves datasetscontaining exclusively syntagmatic relations, asthe evaluation focuses either on paradigmatic rela-tions (TOEFL multiple choice test, antonymy test)or on resources containing both types of relations(thesauri, association norms).3 Experimental Setting3.1 Evaluation Task and DataIn this study, bag-of-words DSMs are evaluated ontwo datasets containing experimental items fromtwo priming studies.
Each item is a word triple(target, consistent prime, inconsistent prime) witha particular semantic relation between target andconsistent prime.
Following previous work onmodeling priming effects as a comparison betweenprime-target pairs (McDonald and Brew, 2004;Pad?o and Lapata, 2007; Herda?gdelen et al., 2009),we evaluate our models in a classification task.The goal is to identify the consistent prime on thebasis of its distributional relatedness to the tar-get: if a particular DSM (i.e., a certain parame-ter combination) is sensitive to a specific relation(or group of relations), we expect the consistentprimes to be closer to the target in semantic spacethan the inconsistent ones.The first dataset is derived from the SemanticPriming Project (SPP) (Hutchison et al., 2013).To the best of our knowledge, our study repre-sents the first evaluation of bag-of-words DSMson items from this dataset.
The original data con-sist of 1661 word triples (target, consistent prime,inconsistent prime) collected within a large-scaleproject aiming at characterizing English words interms of a set of lexical and associative/semanticcharacteristics, along with behavioral data fromvisual lexical decision and naming studies2.
Wemanually discarded all triples containing propernouns, adverbs or inflected words.
We thenselected five subsets involving different seman-tic relations, namely: synonyms (SYN), 436triples (example of a consistent prime and tar-get: frigid?cold); antonyms (ANT): 135 triples(e.g., hot?cold); cohyponyms (COH): 159 triples(e.g., table?chair); forward phrasal associates(FPA): 144 triples (e.g., help?wanted); back-2The dataset is available at http://spp.montana.edu/ward phrasal associates (BPA): 89 triples (e.g.,wanted?help).The second priming dataset is the GeneralizedEvent Knowledge dataset (henceforth GEK), al-ready evaluated in Lapesa and Evert (2013): acollection of 402 triples (target, consistent prime,inconsistent prime) from three priming studiesconducted to demonstrate that event knowledgeis responsible for facilitation of the processingof words that denote events and their partici-pants.
The first study was conducted by Fer-retti et al.
(2001), who found that verbs facili-tate the processing of nouns denoting prototypi-cal participants in the depicted event and of ad-jectives denoting features of prototypical partic-ipants.
The study covered five thematic rela-tions: agent (e.g., pay?customer), patient, fea-ture of the patient, instrument, location.
The sec-ond study (McRae et al., 2005) focussed on prim-ing from nouns to verbs.
It involved four re-lations: agent (e.g., reporter?interview), patient,instrument, location.
The third study (Hare etal., 2009) investigated priming from nouns tonouns, referring to participants of the same eventor the event itself.
The dataset involves sevenrelations: event-people (e.g., trial?judge), event-thing, location-living, location-thing, people-instrument, instrument-people, instrument-thing.In the presentation of our results we group syn-onyms with antonyms and cohyponyms from SPPas paradigmatic relations, and the entire GEKdataset with backward and forward phrasal asso-ciates from SPP as syntagmatic relations.3.2 Evaluated ParametersDSMs evaluated in this paper belong to the class ofbag-of-words models.
We defined a large vocab-ulary of target words (27522 lemma types) con-taining all the items from the evaluated datasetsas well as items from other state-of-the-art evalu-ation studies (Baroni and Lenci, 2010; Baroni andLenci, 2011).
Context words were filtered by part-of-speech (nouns, verbs, adjectives, and adverbs).Distributional models were built using the UCStoolkit3and the wordspace package for R4.
Thefollowing parameters have been evaluated:?
Source corpus (abbreviated as corpus in plots1-4): We compiled DSMs from three corporaoften used in DSM evaluation studies and that3http://www.collocations.de/software.html4http://r-forge.r-project.org/projects/wordspace/162differ in both size and quality: British NationalCorpus5, ukWaC, and WaCkypedia EN6.?
Size of the context window (win.size): Asthis parameter quantifies the amount of sharedcontext involved in the computation of similar-ity, we expect it to be crucial in determiningwhether syntagmatic or paradigmatic relationsare captured.
We therefore use a finer granu-larity for window size than Lapesa and Evert(2013): 1, 2, 4, 8 and 16 words.?
Directionality of the context window(win.direction): When collecting co-occurrenceinformation from the source corpora, we use ei-ther a directed window (i.e., separate frequencycounts for co-occurrences of a context termto the left and to the right of the target term)or an undirected window (i.e., no distinctionbetween left and right context when collectingco-occurrence counts).?
Context selection: From the full co-occurrencematrix collected as described above, we selectdimensions (columns) according to the follow-ing parameters:?
Criterion for context selection (criterion):We select the top-ranked dimensions eitheraccording to marginal frequency (i.e., we usethe most frequent words as context terms)or number of nonzero co-occurrence counts(i.e., we use the context terms that co-occurwith the highest number of targets).?
Number of context dimensions (con-text.dim): We select the top-ranked 5000,10000, 20000, 50000 or 100000 dimensions,according to the criterion above.?
Feature scoring (score): Co-occurrence countsare weighted using one of the following associa-tion measures: frequency, Dice coefficient, sim-ple log-likelihood, Mutual Information, t-score,z-score or tf.idf.7?
Feature transformation (transformation): Atransformation function may be applied to re-duce the skewness of feature scores.
Possibletransformations are: none, square root, logarith-mic and sigmoid.5http://www.natcorp.ox.ac.uk/6Both ukWaC and WaCkypedia EN are available at:wacky.sslmit.unibo.it/doku.php?id=corpora7See Evert (2008) for a description of these measures anddetails on the calculation of association scores.
Note thatwe compute ?sparse?
versions of the association measures(where negative values are clamped to zero) in order to pre-serve the sparseness of the co-occurrence matrix.?
Distance metric (metric): We apply cosine dis-tance (i.e., angle between vectors) or Manhattandistance.?
Dimensionality reduction: We apply singularvalue decomposition in order to project distri-butional vectors to a relatively small number oflatent dimensions and compare the results to theunreduced runs8.
For the SVD-based models,there are two additional parameters:?
Number of latent dimensions (red.dim):Whether to use the first 100, 300, 500, 700or 900 latent dimensions from the SVD anal-ysis.?
Number of skipped dimensions (dim.skip):When selecting latent dimensions, we option-ally skip the first 50 or 100 SVD compo-nents.
This parameter was inspired by Bul-linaria and Levy (2012), who found that dis-carding the initial components of the reducedmatrix, i.e.
the SVD components with highestvariance, improves evaluation results.?
Index of distributional relatedness (rel.index):We propose two alternative ways of quantify-ing the degree of relatedness between two wordsa and b represented in a DSM.
The first op-tion (and standard in distributional modeling)is to compute the distance (cosine or Manhat-tan) between the vectors of a and b.
The sec-ond option, proposed in this work, is based onneighbor rank, i.e.
we determine the rank ofthe target among the nearest neighbors of eachprime.
We expect that the target will occur in ahigher position among the neighbors of the con-sistent prime than among those of the inconsis-tent prime.
Since this corresponds to a lowernumeric rank value for the consistent prime, wecan treat neighbor rank as a measure of dissim-ilarity.
Neighbor rank is particularly interestingas an index of relatedness because, unlike a dis-tance metric, it can capture asymmetry effects9.4 MethodologyIn our evaluation study, we tested all the possiblecombinations of the parameters listed in section8For efficiency reasons, we use randomized SVD (Halkoet al., 2009) with a sufficiently high oversampling factor toensure a good approximation.9Note that our use of neighbor rank is fully consistent withthe experimental design (primes are shown before targets).See Lapesa and Evert (2013) for an analysis of the perfor-mance of neighbor rank as a predictor of priming and discus-sion of the implications of using rank in cognitive modeling.1633.2, resulting in a total of 537600 different modelruns (33600 in the setting without dimensionalityreduction, 504000 in the dimensionality-reducedsetting).
The models were generated and evaluatedon a large HPC cluster within approx.
4 weeks.Our methodology for model selection followsthe proposal of Lapesa and Evert (2013), who con-sider DSM parameters as predictors of model per-formance.
We analyze the influence of individualparameters and their interactions using general lin-ear models with performance (percent accuracy)as a dependent variable and the model parame-ters as independent variables, including all two-way interactions.
Analysis of variance ?
whichis straightforward for our full factorial design ?
isused to quantify the importance of each parameteror interaction.
Robust optimal parameter settingsare identified with the help of effect displays (Fox,2003), which marginalize over all the parametersnot shown in a plot and thus allow an intuitive in-terpretation of the effect sizes of categorical vari-ables irrespective of the dummy coding scheme.For each dataset, a separate linear model wasfitted.
The results are reported and compared insection 5.
Table 1 lists the global goodness-of-fit(R2) on each dataset, for the reduced and unre-duced runs.
Despite some variability across re-lations and between unreduced and reduced runs,the R2values are always high (?
75%), showingthat the linear model explains a large part of theobserved performance differences.
It is thereforejustified to base our analysis on the linear models.Relation Dataset Unreduced ReducedSyntagmatic GEK 93% 87%Syntagmatic FPA 90% 79%Syntagmatic BPA 88% 77%Paradigmatic SYN 92% 85%Paradigmatic COH 89% 75%Paradigmatic ANT 89% 76%Table 1: Evaluation, Global R25 ResultsIn this section, we present the results of our study.We begin by looking at the distribution of accu-racy for different datasets, and by comparing re-duced and unreduced experimental runs in termsof minimum, maximum and mean performance.The results displayed in table 2 show that di-mensionality reduction with SVD improves theperformance of the models for all datasets butGEK.
We conclude that the information lost by ap-plying SVD reduction (namely, meaningful distri-butional features, which are replaced by the gener-Relation DatasetUnreduced ReducedMin Max Mean Min Max MeanSyntagmatic GEK 54.8 98.4 86.6 48.0 97.0 80.8Syntagmatic FPA 41.0 98.0 82.3 43.0 98.6 82.1Syntagmatic BPA 49.4 97.7 83.8 41.6 98.9 83.9Paradigmatic SYN 54.8 98.4 86.6 57.3 99.0 88.2Paradigmatic COH 49.0 100.0 92.6 54.3 100.0 94.0Paradigmatic ANT 69.6 100.0 94.2 57.8 100.0 94.3Table 2: Distribution of Accuracyalization encoded in the reduced dimensions) is ir-relevant to other tasks, but crucial for modeling therelations in the GEK dataset.
This interpretation isconsistent with the detrimental effect of SVD intasks involving vector composition reported in theliterature (Baroni and Zamparelli, 2010).5.1 Importance of ParametersTo obtain further insights into DSM performancewe explore the effect of specific model parameters,comparing syntagmatic vs. paradigmatic relationsand reduced vs. unreduced runs.In order to establish a ranking of the parametersaccording to their importance wrt.
model perfor-mance, we use a feature ablation approach.
Theablation value for a given parameter is the propor-tion of variance (R2) explained by this parametertogether with all its interactions, corresponding tothe reduction in adjusted R2of the linear model fitif the parameter were left out.
In other words, itallows us to find out whether a certain parameterhas a substantial effect on model performance (ontop of all other parameters).
Figures 1 to 4 displaythe feature ablation values of all the evaluated pa-rameters in the unreduced and reduced setting, forparadigmatic and syntagmatic relations.
Parame-ters are ranked according to their average featureablation values in each setting.Two parameters, namely feature score and fea-ture transformation, are consistently crucial indetermining DSM performance, both in reducedand unreduced runs, and for both paradigmaticand syntagmatic relations.
In the next section wewill show that it is possible to identify optimal (ornearly optimal) values for those parameters thatare constant across relations.A comparison of figures 1 and 2 with figures 3and 4 allows us to identify parameters that loseor gain explanatory power when SVD comes intoplay.
Feature ablation shows that the effect of theindex of distributional relatedness is substan-tially smaller in the SVD-reduced runs, but this pa-rameter still plays an important role.
On the otherhand, two parameters gain explanatory power in a164lllllllllcriterionwin.directioncontext.dimwin.sizecorpusmetrictransformationrel.indexscore0 20 40 60Feature Ablationl SYNANTCOHFigure 1: Paradigmatic, unreducedlllllllllcriterionwin.directioncontext.dimwin.sizecorpusmetrictransformationrel.indexscore0 20 40 60Feature Ablationl GEKFPABPAFigure 2: Syntagmatic, unreducedlllllllllllcriterionwin.directioncontext.dimdim.skiprel.indexwin.sizered.dimmetriccorpustransformationscore0 10 20 30Feature Ablationl SYNANTCOHFigure 3: Paradigmatic, reducedlllllllllllcriterionwin.directioncontext.dimrel.indexdim.skipred.dimmetriccorpuswin.sizetransformationscore0 10 20 30Feature Ablationl GEKFPABPAFigure 4: Syntagmatic, reducedSVD-reduced setting: the size of the context win-dow and the source corpus.
Optimal values arediscussed in section 5.2.Three parameters consistently have little or noexplanatory power: directionality of the con-text window, criterion for context selection andnumber of context dimensions.We conclude this section by comparing rela-tions within groups.
Within paradigmatic rela-tions, we note a significant drop in explanatorypower for the relatedness index when it comes toantonyms.
Within syntagmatic relations, the sizeof the context window appears to be more crucialon the GEK dataset than it is for FPA and BPA:in the next section, the analysis of the best choicesfor this parameter will provide a clue for the inter-pretation of this opposition.5.2 Best Parameter ValuesIn this section, we identify the best parameter val-ues for syntagmatic and paradigmatic relations byinspecting partial effects plots10.
Our discussionstarts from the parameters that contribute to theleading topic of this paper, namely the comparisonbetween syntagmatic and paradigmatic relations:10The partial effect plots in figures 5 to 12 display param-eter values on the x-axis and their effect size in terms of pre-dicted accuracy on the y-axis (see section 4 for more detailsconcerning the calculation of effect size).window size, parameters related to dimensionalityreduction, and relatedness index.As already anticipated in the feature ablationanalysis, the size of the context window playsa crucial role in contrasting syntagmatic andparadigmatic relations, as well as different rela-tions within those general groups.
The plots in fig-ures 5 and 6 display its partial effect for paradig-matic relations in the unreduced and reduced set-tings, respectively.
The plots in figures 7 and 8display its partial effect for syntagmatic relations.When no dimensionality reduction is involved, avery small context window (i.e., one word) is suffi-cient for all paradigmatic relations, and DSM per-formance decreases as soon as we enlarge the con-text window.
The picture changes when apply-ing dimensionality reduction: a 4-word windowis a robust choice for all paradigmatic relations(although ANT show a further increase in perfor-mance with an 8-word window), even in the SYNtask that is traditionally associated with very smallwindows of 1 or 2 words (cf.
Sahlgren (2006)).A significant interaction between window sizeand number of skipped dimensions (not shown forreasons of space) sheds further light on this matter.Without skipping SVD dimensions, the reducedmodels achieve optimal performance for a 2-wordwindow and degrade more (COH) or less (ANT)165l llllll l lll llll84879093961 2 4 8 16datasetlllSYNANTCOHFigure 5: Window, paradigmatic, unreducedll l l llll l llll l l84879093961 2 4 8 16datasetlllSYNANTCOHFigure 6: Window, paradigmatic, reducedlll l lll l lllllll747678808284861 2 4 8 16datasetlllGEKFPABPAFigure 7: Window, syntagmatic, unreducedlllllllll llll l l747678808284861 2 4 8 16datasetlllGEKFPABPAFigure 8: Window, syntagmatic, reducedquickly for larger windows.
With 50 or 100 di-mensions skipped, performance improves up to a4- or 8-word window.
Our interpretation is that thefirst SVD dimensions capture general domain andtopic information dominating the co-occurrencedata; removing these dimensions reveals paradig-matic semantic relations even for larger windows.For syntagmatic relations without dimensionalityreduction, a larger context window of 4 words isneeded for FPA and BPA; a further increase of thewindow is detrimental.
For the GEK dataset, per-formance peaks at 8 words, and decreases onlyminimally for even larger windows.
Again, di-mensionality reduction improves performance forlarge co-occurrence windows.
For FPA and BPA,the optimum seems to be achieved with a win-dow of 4?8 words; performance on GEK contin-ues to increase up to 16 words, the largest win-dow size considered in our experiments.
Such pat-terns reflect differences in the nature of the se-mantic relations involved: smaller windows pro-vide better contextual representations for paradig-matic relations while larger windows are needed tocapture syntagmatic relations with bag-of-wordsDSMs (because co-occurring words then share alarge portion of their context windows).
Interme-diate window sizes are sufficient for phrasal col-locates (which are usually adjacent), while event-based relatedness (GEK) requires larger windows.Returning briefly to the slight preference shownby ANT for a larger window, we notice that ANTseems to be more similar to the syntagmatic rela-tions than SYN and COH.
This is in line with theobservations of Justeson and Katz (1992) concern-ing the tendency of antonyms to co-occur (e.g., incoordinations such as short and long).
Like syn-onyms, antonyms are interchangeable in absentia;but they also enter into syntagmatic patterns thatare uncommon for synonyms.We now focus on the parameters related to di-mensionality reduction, namely the number of la-tent dimensions (figures 9 and 10) and the num-ber of skipped dimensions (figures 11 and 12).These parameters represent an extension of theexperiments conducted on the GEK dataset byLapesa and Evert (2013).
They have already beenapplied by Bullinaria and Levy (2012) to a differ-ent set of tasks, including the TOEFL multiple-choice synonymy task.
In particular, Bullinariaand Levy found that discarding the initial SVD di-mensions (with highest variance) leads to substan-tial improvements, especially in the TOEFL task.In our experiments, we found no difference be-tween syntagmatic and paradigmatic relations wrt.the number of latent dimensions: the more, thebetter in both cases (900 dimensions).
The numberof skipped dimensions, however, shows some vari-ability across the different relations.
The resultsfor SYN are in agreement with the findings of Bul-linaria and Levy (2012) on TOEFL: skipping 50or 100 initial dimensions improves performance.Skipping dimensions makes minimal difference166llll llll lllll l l87909396100 300 500 700 900datasetlllSYNANTCOHFigure 9: Latent dimensions, paradigmaticllll lllll llllll767880828486100 300 500 700 900datasetlllGEKFPABPAFigure 10: Latent dimensions, syntagmaticlllllllll87899193950 50 100datasetlllSYNANTCOHFigure 11: Skipped dimensions, paradigmaticllll lllll80818283840 50 100datasetlllGEKFPABPAFigure 12: Skipped dimensions, syntagmaticfor COH (best choice is 50 dimensions), while thefull range of reduced dimensions is necessary forANT.
Within syntagmatic relations, the full rangeof latent dimensions ensures good performance onphrasal associates (even if skipping 50 dimensionsis not detrimental for BPA).
GEK shows a patternsimilar to SYN, with 50 skipped dimensions lead-ing to a considerable improvement.We now inspect the best values for the related-ness index.
As shown in figure 13 for the unre-duced runs and in figure 14 for the reduced runs,neighbor rank is consistently better than distanceon all datasets.
This is not surprising because, asdiscussed in section 3.2, our use of neighbor rankcaptures asymmetry and mirrors the experimentalsetting, in which targets are shown after primes.A further observation may be made relating to thedegree of asymmetry of different relations.
Theunreduced setting in particular shows that syntag-matic relations are subject to stronger asymme-try effects than the paradigmatic ones, presumablydue to the directional nature of the relations in-volved (phrasal associates and syntactic colloca-tions).
Among paradigmatic relations, antonymsappear to be the least asymmetric ones (becauseusing neighbor rank instead of distance makes acomparatively small difference).We conclude by briefly summarizing the opti-mal choices for the remaining parameters.
Thecorresponding partial effects plots are not shownbecause of space constraints.A very strong interaction between score andtransformation characterizes all four settings(paradigmatic or syntagmatic datasets, reduced orunreduced experimental runs).
Association mea-sures outperform raw co-occurrence frequency.Measures based on significance tests (simple-ll,t-score, z-score) are better than Dice, and to alesser extent, MI.
Simple-ll is the best choice incombination with a logarithmic transformation forparadigmatic relations, z-score appears to be thebest measure for syntagmatic relations in combi-nation with a square root transformation.
The dif-ference is small, however, and simple-ll with logtransformation works well across all datasets.
On-going experiments with standard tasks show a sim-ilar pattern, suggesting that this combination ofscore and transformation parameters is appropri-ate for DSMs, regardless of the task involved.The optimal distance metric is the cosinedistance, consistently outperforming Manhattan.Concerning source corpus, BNC consistentlyyields the worst results, while WaCkypedia andukWaC appear to be almost equivalent in the unre-duced runs.
The trade-off between quality andquantity appears to be strongly biased towardssheer corpus size in the case of distributional mod-els.
For syntagmatic relations and SVD-reducedmodels, ukWaC is clearly the best choice.
Thissuggests that syntagmatic relations are better cap-tured by features from a larger lexical inventory,combined with the abstraction performed by SVD.167llllllllllll7580859095SYN ANT COH GEK FPA BPArel.indexlldistrankFigure 13: Relatedness index, unreducedll llllllllll7580859095SYN ANT COH GEK FPA BPArel.indexlldistrankFigure 14: Relatedness index, reducedConcerning minimally explanatory parameters,inspection of partial effect plots supported thechoice of ?unmarked?
default values for direc-tionality of the context window (i.e., undirected)and criterion for context selection (i.e., fre-quency), as well as an intermediate number ofcontext dimensions (i.e., 50000 dimensions).5.3 Best SettingsWe conclude by comparing the performanceachieved by our robust choice of optimal param-eter values (?best setting?)
from section 5.2 withthe performance of the best model for each dataset.For space constraints, the analysis of best settingsfocuses on the reduced experimental runs.
Ourbest settings, shown in table 3, perform fairly wellon the respective datasets11.dataset corpus win score transf r.dim d.sk acc bestGEK ukwac 16 s-ll log 900 50 96.0 97.0FPA ukwac 8 z-sc root 900 0 93.0 98.6BPA ukwac 8 z-sc root 900 0 95.5 98.9SYN ukwac 4 s-ll log 900 50 96.3 99.0COH ukwac 4 s-ll log 900 50 98.7 100ANT wacky 8 s-ll log 900 0 100 100Table 3: Best settings: datasets, parameter values,accuracy (acc), accuracy of the best model (best)best setting corpus win score transf r.dim d.skSyntagmatic ukwac 8 z-sc root 900 0Paradigmatic ukwac 4 s-ll log 900 50General ukwac 4 s-ll log 900 0Table 4: General best settings: parameter valuesDataset Best Synt.
Best Para.
GeneralGEK 92.5 94.8 91.3FPA 93.0 90.2 91.7BPA 95.5 97.7 95.5SYN 94.4 96.3 96.3COH 99.3 98.7 98.7ANT 99.2 99.2 99.2Table 5: General best settings: accuracy11Abbreviations in tables 3 and 4: win = window size;transf = transformation; z-sc = z-score; s-ll = simple-ll; r.dim= number of latent dimensions; d.sk = number of skipped di-mensions.
Parameters with fixed values for all datasets: num-ber of context dimensions = 50k; direction = undirected; cri-terion = frequency; metric = cosine; relatedness index = rank.As a next step, we identified parameter combi-nations that work well for all types of syntagmaticand paradigmatic relations, as well as an evenmore general setting that is suitable for paradig-matic and syntagmatic relations alike.
Best set-tings are shown in table 4, their performance oneach dataset is reported in table 5.
General modelsachieve fairly good performance on all relations.6 ConclusionWe presented a large-scale evaluation study ofbag-of-words DSMs on a classification task de-rived from priming experiments.
The leadingtheme of our study is a comparison between syn-tagmatic and paradigmatic relations in terms ofthe aspects of distributional similarity that char-acterize them.
Our results show that second-orderDSMs are capable of capturing both syntagmaticand paradigmatic relations, if parameters are prop-erly tuned.
Size of the co-occurrence window aswell as parameters connected to dimensionality re-duction play a key role in adapting DSMs to par-ticular relations.
Even if we do not address themore specific task of distinguishing between rela-tions (e.g., synonyms vs. antonyms; see Scheibleet al.
(2013) and references therein), we believethat such applications may benefit from our de-tailed analyses on the effects of DSM parameters.Ongoing and future work is concerned with theexpansion of the evaluation setting to other classesof models (first-order models, dependency-basedsecond-order models) and parameters (e.g., di-mensionality reduction with Random Indexing).AcknowledgmentsWe are grateful to Ken MacRae for providing usthe GEK priming data and to the three review-ers.
This research was funded by the DFG Col-laborative Research Centre SFB 732 (GabriellaLapesa) and the DFG Heisenberg FellowshipSCHU-2580/1-1 (Sabine Schulte im Walde).168ReferencesMarco Baroni and Alessandro Lenci.
2010.
Dis-tributional memory: A general framework forcorpus-based semantics.
Computational Linguis-tics, 36(4):1?49.Marco Baroni and Alessandro Lenci.
2011.
Howwe BLESSed distributional semantic evaluation.
InProceedings of the GEMS 2011 Workshop on GE-ometrical Models of Natural Language Semantics,pages 1?10.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, pages1183?1193.John A. Bullinaria and Joseph P. Levy.
2012.
Ex-tracting semantic representations from word co-occurrence statistics: stop-lists, stemming and svd.Behavior Research Methods, 44:890?907.James Curran.
2003.
From distributional to semanticsimilarity.
Ph.D. thesis, Institute for Communicat-ing and Collaborative Systems, School of Informat-ics, University of Edinburgh.Philip Edmonds and Graeme Hirst.
2002.
Near-synonymy and lexical choice.
Computational Lin-guistics, 28(2):105?144.Katrin Erk, Sebastian Pad?o, and Ulrike Pad?o.
2010.
Aflexible, corpus-driven model of regular and inverseselectional preferences.
Computational Linguistics,36(4):723?763.Stefan Evert.
2008.
Corpora and collocations.
In AnkeL?udeling and Merja Kyt?o, editors, Corpus Linguis-tics.
An International Handbook, chapter 58.
Mou-ton de Gruyter, Berlin, New York.Todd Ferretti, Ken McRae, and Ann Hatherell.
2001.Integrating verbs, situation schemas, and thematicrole concepts.
Journal of Memory and Language,44(4):516?547.John Fox.
2003.
Effect displays in R for gener-alised linear models.
Journal of Statistical Software,8(15):1?27.Nathan Halko, Per-Gunnar Martinsson, and Joel A.Tropp.
2009.
Finding structure with randomness:Stochastic algorithms for constructing approximatematrix decompositions.
Technical Report 2009-05,ACM, California Institute of Technology.Mary Hare, Michael Jones, Caroline Thomson, SarahKelly, and Ken McRae.
2009.
Activating eventknowledge.
Cognition, 111(2):151?167.Zelig Harris.
1954.
Distributional structure.
Word,10(23):146?162.Amac Herda?gdelen, Marco Baroni, and Katrin Erk.2009.
Measuring semantic relatedness with vectorspace models and random walks.
In Proceedingsof the 2009 Workshop on Graph-based Methods forNatural Language Processing, pages 50?53.Keith A. Hutchison, David A. Balota, James H. Neely,Michael J. Cortese, Emily R. Cohen-Shikora, Chi-Shing Tse, Melvin J. Yap, Jesse J. Bengson, DaleNiemeyer, and Erin Buchanan.
2013.
The seman-tic priming project.
Behavior Research Methods,45(4):1099?1114.John.
S. Justeson and Slava M. Katz.
1992.
Redefiningantonymy: The textual structure of a semantic rela-tion.
Literary and Linguistic Computing, 7(3):176?184.Gabriella Lapesa and Stefan Evert.
2013.
Evaluat-ing neighbor rank and distance measures as predic-tors of semantic priming.
In Proceedings of theACL Workshop on Cognitive Modeling and Compu-tational Linguistics (CMCL 2013), pages 66?74.Alessandro Lenci and Giulia Benotto.
2012.
Identi-fying hypernyms in distributional semantic spaces.In Proceedings of *SEM 2012: The First Joint Con-ference on Lexical and Computational Semantics ?Volume 1, pages 75?79.Diana McCarthy and John Carroll.
2003.
Disam-biguating nouns, verbs and adjectives using auto-matically acquired selectional preferences.
Compu-tational Linguistics, 29(4):639?654.Scott McDonald and Chris Brew.
2004.
A distri-butional model of semantic context effects in lexi-cal processing.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Lin-guistics, pages 17?24.Ken McRae, Mary Hare, Jeffrey L. Elman, and ToddFerretti.
2005.
A basis for generating expectan-cies for verbs from nouns.
Memory & Cognition,33(7):1174?1184.Sebastian Pad?o and Mirella Lapata.
2007.Dependency-based construction of semantic spacemodels.
Computational Linguistics, 33(2):161?199.Yves Peirsman, Kris Heylen, and Dirk Speelman.2008.
Putting things in order.
First and second ordercontext models for the calculation of semantic sim-ilarity.
In JADT 2008: 9es Journ?ees internationalesd?Analyse statistique des Donn?ees Textuelles.Reinhard Rapp.
2002.
The computation of word asso-ciations: Comparing syntagmatic and paradigmaticapproaches.
In Proceedings of the 19th Interna-tional Conference on Computational Linguistics -Volume 1, pages 1?7.Magnus Sahlgren.
2006.
The word-space model: Us-ing distributional analysis to represent syntagmaticand paradigmatic relations between words in high-dimensional vector spaces.
Ph.D. thesis, Universityof Stockolm.169Magnus Sahlgren.
2008.
The distributional hypothe-sis.
Rivista di Linguistica (Italian Journal of Lin-guistics), 20(1):33?53.Silke Scheible, Sabine Schulte im Walde, and SylviaSpringorum.
2013.
Uncovering Distributional Dif-ferences between Synonyms and Antonyms in aWord Space Model.
In Proceedings of the 6th In-ternational Joint Conference on Natural LanguageProcessing, pages 489?497.Hinrich Sch?utze.
1998.
Automatic word sense dis-crimination.
Computational Linguistics, 27(1):97?123.Peter D. Turney and Patrick Pantel.
2010.
Fromfrequency to meaning: Vector space models of se-mantics.
Journal of Artificial Intelligence Research,37:141?188.Julie Weeds, David Weir, and Diana McCarthy.
2004.Characterising measures of lexical distributionalsimilarity.
In Proceedings of the 20th InternationalConference of Computational Linguistics, pages1015?1021, Geneva, Switzerland.170
