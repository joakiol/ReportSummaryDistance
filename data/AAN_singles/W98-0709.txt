Using WordNet for Building WordNetsXavier Farreres, German Rigau, Horacio RodffguezDepartament de Llenguatges i Sistemes Inform~tics.Universitat PolitEcrdca de Catalunya.
Barcelona.
Spain.
{farrere s, horacio, g.rigau}@lsi.upc.esIIIIIIIIIIIIIIIAbstractThis paper summarises a set ofmethodologies and techniques for the fastconstruction of multilingual WordNets.The English WordNet is used in thisapproach as a backbone for Catalan andSpanish WordNets and as a lexicalknowledge resource for several subtasks.1 Motivation and IntroductionOne of the main issues in last years as regardsNLP activities is the increas ingly  fastdevelopment of generic language resources.
A lot ofsuch resources, including both software andl ingware items (lexicons, lexical databases,grammars, corpora marked in several ways) havebeen made available for research and  industrialapplications.Special interest presents, for knowledge-basedNLP tasks, the availability of wide coverageontologies.
Most known ontologies (as GUM, CYC,ONTOS, MICROKOSMOS, EDR or WORDNET,see \[Gomez 98\] for an extensive survey) defer ingreat extent on several characteristics (e.g.
broadcoverage vs. domain specific, lexicaUy orientedvs.
conceptually oriented, granularity, kind ofinformation placed in nodes, kind of relations,way of building, etc.).
It is clear, however, thatfor a wide range of applications, WordNet (WN)\[Miller 90\] as become a de-facto standard.The success of WordNet has determined theemergence of several projects that aim theconstruction ofWordNets for other languages thanEnglish (e.g., \[Hamp & Feldweg 97\], \[Artale t al.97\]) or to develop multilingual WordNets (themost important project in this line isEuroWordNet (EWN)I).lhttp://www.let.uva.rd/~ewn/The aim of EWN vrojectis to braid a multi.lingual database with WordN'ets forseveral european languages (in the first phase, Dutch,Italian and Spanish in addltion to English).The construction of a WN for a language Lg(LgWN) can be tackled in di f ferent waysaccording to the lexical sources available.
Ofcourse the manual construction can be undertakenquite straightforwardly and leads to the bestresults in terms of accuracy, but has the importantdrawback of its cost.
So, other approaches havebeen carried out taking profit of availableresources in fully automatic or semi-automaticways.Which are these lexical resources?
Basicallyfour kinds of resources have been used: 1) EnglishWN (EnWN0, as an initial skeleton for trying toattach the words of Lg to it, 2) already existingtaxonomies ofLg (both at word and at sense level),3) bilingual (English and Lg) and 4) monolingual(Lg) dictionaries.
All the approaches using EnWNas skeleton are based on the assumption of a closeconceptual similarity between English and Lg, insuch a way that most of the structure (relations) inEnWN could be maintained for LgWN.In the case of bilingual dictionaries the usualapproach is to try to link the English counterpartof entries to synsets in EnWN and to assume thatthe entry can be \]inked to the same synset.Monolingual dictionaries have been usedbasically as a source for extracting taxonomic(hypemym) links between words (or senses \[Bruce& Guthrie 92\], \[Rigau et al 97\]) and in lowerextent for extracting other kinds of semanticrelations \[Richardson 97\] (e.g.
meronymic links).Once a taxonomy of Lg (already existing orbuilt from a monolingual MILD) is available, thetask can consist of 1) enriching the taxonomicstructure with other semantic links (manually orautomatically), as is the case of bui ld ingindividual WNs, or 2) merging this structure withother already existing ontologies (as EnWN orEWN).This paper presents our approach to theconstruction of WNs for two languages, Spanishand Catalan, and linking the first one to EWN.We have developed a methodology that uses ascore source EnWN 2.
The methodology implies 1)2We have used WordNet 1.5.65IIIIIII!IIIIIIIIIIThe use of EnWN for guiding the selection of thebasic concepts of our WNs, 2) the use of EnWN asskeleton for linking Spanish and Catalan words toEnglish synsets using bilingual dictionaries, 3) theuse of EnWN, together with bilingual andmonol ingual  dictionaries for allowing theconstruction of taxonomies (at sense level) of ourlanguages and 4) the use of EnWN together withalready built fragments of SpWN and CtWN formerging and incorporating these taxonomies toourWNs.In section 2 an overall description of ourapproach is given.
Sections 3, 4 and 5 focus on theprocedures for extracting connections betweenwords/senses/synsets.
Section 3 is devoted toprocedures based on the use of bilinguals, section 4on the construction of taxonomies and section 5deals with the merging method.
In all thesesections we will enphasize the role played byEnWN as Knowledge Source.
Section 6, finally,presents some conclusions of our work.2 Our way of bui ld ing WordNetsAs we have pointed out in the introduction, ouraim has been to design a methodology (and asoftware environment support ing it) forfacilitating the task of building WNs from oursources.
As we are involved in EWN project(covering the Spanish part), the methodology hasbeen defined to be compatible which the generalapproach, guidelines and landmarks of the wholeproject but also to allow a parallel development ofthe CtWN.The general approach for building EWN isdescribed in \[Vossen et al 97\].
Roughly speaking,the approach follows a top-down strategy tryingto assure a high level of overlapping betweenlanguages, at least in the highest levels of thehierarchy, but reflecting the language-specificlexicalizations and providing the maximum off reedom and flexibility for bui lding theindividual WordNets.
Basically it consists ofthree major steps: l) Construction of core-WordNets for a set of common base concepts(around 800 nouns and 200 verbs), 2) enrichment ofthese sets providing relational links andincorporating their direct semantic ontexts and 3)top-down extension of these core-WordNets.In our case two different approaches have beenfollowed for dealing with nouns and verbs 3.3Although other categories can be included in EWN (andcross-category elations an be established) only nounsand verbs have been introduced until now in ourWordNets except for demostration purposes.In the case of verbs most of the work has beenperformed manually.
The main source ofinformation has been the Pirapides database\[Castell6n et al 97\] that consists of 3,600 Englishverbs forms organized around Levin's SemanticClasses connected to WN1.5 senses.
The databasecontains the theta-Grids pecifications for eachverb (its semantic structure in terms of cases orthematic roles), translation to Spanish andCatalan forms 4 and diathesis information.
Theconnections extracted from this database werecross-validated with the information provided bybilingual dictionaries in order to improve theiraccuracy.In the case of nouns we have followed EWNstrategy in the next way:1) The two highest levels of EnWN (topconcepts and direct hyponyms) were manuallytranslated into Spanish (including variants).
Theresults were fi ltered dropping out wordsappearing less than five times as genus terms inour monolingual dictionary \[DGILE 87\] or occurringless than 50 times in DGILE definition corpus 5andless than 100 times in LEXESP corpus 6.This initial set (Spanish core concepts, 361synsets) was then compared with base concept setsof other sites of EWN (roughly the union ofintersection pairs between languages wasconsidered as the common base concepts et).
Themissing concepts in Spanish were manually addedand vertically bottom up extended leading to thecommon Base Concept set (around 800 synsets).Catalan Base Concepts et was then built to coverthe Spanish Base Concepts et.2) The enrichment of the BC set has beenperformed in two steps.
First, using bilinguals asmain lexical source, and then using other sources(mainly taxonomies).
These processes aredescribed below.3 Using Eng l i sh  WordNet  withbil ingualsWhen trying to build a lexical taxonomy fromscratch, we can take profit of a preexisting lexicaltaxonomy, EnWN in our case, assuming it is weUformed, as a skeleton of a taxonomy where we willfill in the lexical data.
This ensures severaladvantages: it speeds up the construction of alarge lexicon, as the only problem left is the4Spanish and Catalan are languages close enough forallowing a simultaneous development of lexical sources.5i.e.
set of all definitions included in DGILE (1 millionwords)6balanced corpus of Spanish (5 Million words).66IIiIiIIIIIIIIIIIIIdecision where to attach the lexical data.
Thereare also some problems: nobody ensures that thewellformedness of a lexical taxonomy for alanguage keeps true for another language, theremust be semantic closeness between bothlanguages.
We have therefore assumed that thestructure of the WN taxonomy would suffice in theearlier stages of the construction of the our WNs.So, we need to choose synonyms in Spanish 7 forthe English words present in the original synsetsof WN.
One way to fulfil our requirements is usingbilingual dictionaries (see \[Knight & Luk 94\],\[Okumura & Hovy 94\]).
But we have to perform asense disambiguation task in order to know whichsense of both words (the Spanish and the Englishone) is being referred.
In other words, we have todecide, for which sense of the Spanish word andfor which synset in WordNet a relation ofsynonymy isbeing defined.There is also another minor problem toovercome, the unification of the two directions ofthe bilingual dictionary, which in few cases aresymmetrical, to collect all translations together.It is true that unifying both directions of thebilingual dictionary implies loss of informationpotentially important (e.g.
the order in whichtranslations are written is relevant).
But the lackof systematic work in the construction of thebilinguals makes this information of very doubtfulutil ity.Thus, we have processed the bilingualscreating what we have called the homogeneousbilingual, which is a bil ingual with bothdirections mixed.
Then, for each Spanish word, wehave collected all the words given as correcttranslations.
And this has been the source for ourwork of attachment of Spanish words to WordNetsynsets.Having collected all the translations of aSpanish word together, we  have then classifiedthe words in classes depending on their behaviour.They can be classified in three dimensions:polysemy, structural and conceptual.In the polysemy dimension, we  classify thewords in classes depending on the number and kindof translations.
For example, all entries that haveonly one translation fall in the same class whenthis translation is monosemous in WN terms; allentries that have several translations fall inanother class when these translations arepolysemous.7Although we ilustrate the methodology considering onlySpanish, we performed the whole process for bothCatalan and Spanish (and we provide results for both).In the structural  dimension, we classify thewords in classes depending on the relation thatthe translations owns in WN.
For example, allentries which have several translations, sharingsome of them a common synset in WN, fall in thesame category; all entries in which onetranslation is a direct hyponym of othertranslation fall in the same category, etc.In the conceptua l  dimension, we apply theconceptual distance formula (which is explainedin section 4.2.1.)
on elements of the entries.
Forexample, all entries with a low conceptualdistance between synsets of their translations fallin the same class.Each of these classes defines a set of entrieswith the same behaviour.
A confidence score hasbeen assigned to each class by means of a manualvalidation of a significant sample extracted fromthem.
We decided to accept the classes with aprecission of 85% or more as classes of words toinclude in the first version of SpWN.Bilinguals can be used a step further stating asupposition: when several methods give the sameresult for the same Spanish word, the confidencefor this attachment increases.
We have carriedout an experiment checking the classes in pairs,evaluat ing the preciss ion of the set ofintersections, and in all cases the precissionincreased.
We have removed the cases where theprecision was over 85%, the threshold applied inthe previous experiment.
This caused an incrementof 40% of the original set of attachments.Furthermore, it is clear that if we merge morebilinguals, the homogeneous resulting will belarger, and will then generate larger classes.
But,what is even more important, the classes are moreprecise because some bilinguals lack the inclusionof some translations for some words.
Table I showsthe current figures of both CtWN and SpWNfollowing this approach (see \[Atserias et al 97\]and \[Benitez et al 98\] for further details of thewhole process and tools used).NounsSpanishCatalanWords S~msets Connections23,217 18,578 41,2935,231 4,723 7,193VerbsSpanish 3,087 3,219 7,960Catalan 3,337 3,219 9,078Table 1: current volumes of CtWN and SpWN.The last point to address is the extension of theintersection method to larger number of classes.
Ifwith two classes the intersection increased theconf idence an equiva lent  increase when67IIIIIlIIIII!Iintersecting larger numbers of classes can beexpected.As a matter of fact, the extension of theintersection method would be nothing more thanperforming a multivariant statistical analysis,where each of the classes would be a factor.
Theinteresting result of this multivariant analysiswould be a formula which could be used tocalculate the value of the confidence of anattachment, depending on the number of classes inwhich it occurs.4 Building Taxonomies using WordNet4.1 Exploiting taxonomies f~m MRDsA straightforward way of obtaining a LgWNcan be performed acquiring taxonomic relationsfrom conventional dictionaries following a purelybottom up strategy.
That is, 1) parsing each?
definition for obtaining the genus, 2) performing agenus disambiguation procedure, and 3) building anatural classification of the concepts as a concepttaxonomy with several tops.
Following thispurely descriptive methodology, the semanticprimitives of the LgWN could be obtained bycollecting those dictionary senses appearing atthe top of the complete taxonomies derived fromthe dictionary.
By characterizing each of thesetops, the complete LgWN could be produced.
ForDGILE, the complete noun taxonomy was derivedusing the automatic method escribed by \[Rigau etal.
97\]8.However, several problems arise due to a) thesource (i.e., circularity, errors, inconsistencies,omitted genus, etc.)
and b) the limitation of thegenus sense disambiguation techniques applied(i.e., \[Bruce t al.
92\] report 80% accuracy usingautomatic techniques, while \[Rigau et al 97\]report 83%).
Furthermore, the top dictionarysenses do not usually represent he semanticsubsets that the LgWN needs to characterize inorder to represent useful knowledge for NLPsystems.
In other words, there is a mismatchbetween the knowledge directly derived from anMRD and the knowledge needed by a LgWN.To illustrate the problem we are facing, let ussuppose we plan to place the FOOD concepts inthe LgWN.
Neither collecting the taxonomiesderived from a top dictionary sense (or selecting a8This taxonomy contains 111,624 dictionary senses andhas only 832 dictionary senses which are tops of thetaxonomy (these top dictionary senses have nohypernyms), and 89,458 leaves (which have nohyponyms).
That is, 21,334 definitions are placedbetween the top nodes and the leaves.subset of the top dictionary senses of DGILE)closest tO FOOD concepts (e.g., substancia-substance-), nor collecting those subtaxonomiesstarting from closely related senses (e.g., bebida-drinkable liquids- and alimento -food-) we areable to collect exactly the FOOD concepts presentin the MRD.
The first are too general (they wouldcover non-FOOD concepts) and the second are toospecific (they would not cover all FOODdictionary senses because FOODs are described inmany ways).All these problems can be solved using a mixedmethodology.
That is, by attaching selected topconcepts (and its der ived taxonomies) toprescribed semantic primitives represented in theLgWN.
Thus, first, we prescribe a minimalontology (represented by the semantic primitivesof the LgWN) able to represent the whole lexiconderived from the MRD, and second, following adescriptive approach, we collect, for everysemantic primitive placed in the LgWN, itssubtaxonomies.
Finally, those subtaxonomiesselected for a semantic primitive are attached tothe corresponding L WN semantic ategory.We used as semantic primit ives the 24lexicographer's files (or semantic files) intowhich the 60,557 noun synsets (87,641 nouns) ofWN are classified 9.
Thus, we considered the 24semantic tags of WN as the main LgWN semanticprimitives to which all dictionary senses must beattached.
In order to overcome the language gapwe also used a bil ingual Span ish /Eng l i shdictionary.4.2 Attaching DGILE dictionary senses to semanticprimitivesIn order to classify all nominal DGILE senseswith respect to WordNet semantic files, we used asimilar approach to that suggested by \[Yarowsky92\].
This task is div ided into three fullyautomatic onsecutive subtasks.
First, we tag asubset (due to the difference in size between themonolingual and the bilingual dictionaries) ofDGILE dictionary senses by means of a processthat uses the conceptual distance formula (see4.2.1); second, we collect salient words for eachsemantic file; and third, we enrich each DGILE9One could use other semantic lassifications, uch asRoget's Thesaurus \[Yarowsky 92\], the LDOCE semanticor pracmatic odes \[Slator 91\] or even better, a Spanishsemantic classification such as the "DiccionarioIdeolOgico de la Lengua Espafiola J. Casares'" (DILEC).Really; when using this methodology a minimal set ofinformed seeds are needed.
These seeds can be collectedfrom MRDs, thesauri or even by introspection.
(see\[Yarowsky 95\]).68IIIIIiIIIIIi..JjIIIIIdictionary sense with a semantic tag collectingevidence from the salient words previouslycomputed.4.2.1 Attaching WordNet synsets to DGILEheadwords.For each DGILE definition, the conceptualdistance between headword and genus has beencomputed using WN1.5 as a semantic net.
Weobtained results only for those definitions havingEnglish translations (using a bilingual dictionary)for both headword and genus.
By computing theconceptual distance between two words (wl,w2)we are also selecting those concepts (Cli,C2j) whichrepresent them and seem to be closer with respectto the semantic net used.
Conceptual distance iscomputed using formula (1).1I i wl c lGpat l (c l  i "cll )ell E W lThat is, the conceptual distance between twoconcepts depends on the length of the shortestpath 10 that connects them and the specificity ofthe concepts in the path.In this way, we obtained a preliminary versionof 29,20511 dictionary definitions semanticallylabelled (that is, with WN lexicographer's files)with an accuracy of 64% (61% at a sense level).That is, a corpus (collection of dictionary senses)classified in 24 partitions (each one correspondingto a semantic ategory).4.2.2 Collecting the salient words for everysemantic primitive.Thus, we can collect the salient words (that is,those representative words for a particularcategory) using a Mutual Information-like formula(2), where w means word and SC semantic lass.
(21 AR(w, SC) = Pr(wlSC)log 2Pr(wlSC)Pr(w)Intuitively, a salient word  12 appearssignificantly more often in the context of aI OWe only consider hypo / hypermy mrelations.llDue to the different sizes of the dictionaries used weonly compute the conceptual distance for 31% of the noundictionary senses.12Instead ofword lemmas, this study has been carried outusing word forms because word forms rather than lemmassemantic ategory than at other points in thewhole corpus, and hence is a better than averageindicator for that semantic ategory.
The wordsselected are those most relevant o the semanticcategory, where relevance is def ined as theproduct of salience and local frequency.
That is tosay, important words should be distinctive andfrequent.We performed the training process consideringonly the content word forms from dictionarydefinit ions 13 and we discarded those salientwords with a negative score.
Thus, we derived alexicon of 23,418 salient words (one word can be asalient word for many semantic ategories).4.2.3 Enriching DGILE definitions with WordNetsemantic primitives.Using the salient words per category (orsemantic lass) gathered in the previous step welabelled the DGILE dictionary definitions again.When any of the salient words appears in adefinition, there is evidence that the wordbelongs to the category indicated.
If several ofthese words appear, the evidence grows.
We addtogether their weights, over all words in thedefinition, and determine the category for whichthe sum is greatest, using formula (3).
(3) W(SCO = ~ AR(w, SCOw E defmitionThus, we obtained a second semanticallylabelled version of DGILE.
This version has 86,759labelled definitions (covering more than 93% ofall noun definitions) with an accuracy rate of 80%(we have gained, since the previous labelledversion, 62% coverage and 16% accuracy).Although we used the 24 lexicographer's filesof WordNet as semantic primitives, a more fine-grained classification could be made.
For example,all FOOD synsets are classified under <food,nutrient> synset in file 13.
However, FOODconcepts are themselves classified into 11subclasses (i.e., <yo lk>,  <gast ronomy>,<comestible, dible, eatable, ...>, etc.).
Thus, ifthe LgWN we are planning to build needs torepresent <beverage, drink, potable> separatelyfrom the concepts <comestible, dible, eatable,...> a finer set of semantic primitives should bechosen, for instance, considering each directhyponym of a synset belonging to a semantic filealso as a new semantic primitive or even selectingusedare representatiVein dictionari s.?f .typical usages of the sublanguage 6S3After discarding functional words.for each semantic file the level of abstraction weneed.4.3 Selecting the main top beginners for a semanticprimitiveThis section is devoted to the location of themain top dictionary senses for a given semanticprimitive in order to correctly attach all itssubtaxonomies to the correct semantic primitive inthe LgWN.In order to illustrate this process we will locatethe main top beginners for the FOOD dictionarysenses.
However, we must consider that many ofthese top beginners are structured.
That is, some ofthem belong to taxonomies derived from otherones, and then cannot be directly placed withinthe FOOD type.
This is the case of vino (wine),which is a zumo (juice).
Both are top beginners forFOOD and one is a hyponym of the other.First, we collect all genus terms from the wholeset of DGILE dictionary senses labelled in theprevious section with the FOOD tag (2,614senses), producing a lexicon of 958 different genusterms (only 309, 32%, appear more than once in theFOOD subset of dictionary senses).As the automatic dictionary sense labelling isnot free of errors (around 80% accuracy) 14 we candiscard some senses by using filtering criteria.?
Filter I (F1) removes all FOOD genus termsnot assigned to the FOOD semantic file during themapping process between the bilingual dictionaryand WN.?
Filter 2 (F2) selects only those genus termswhich appear more times as genus terms in theFOOD category.
That is, those genus terms whichappear more frequently in dictionary definitionsbelonging to other semantic tags are discarded.?
Filter 3 (F3) discards those genus termswhich appear with a low frequency as genus termsin the FOOD semantic category.
That is,infrequent genus terms (given a certain threshold)are removed.
Thus, F3>1 means that the filteringcriteria have discarded those genus termsappearing in the FOOD subset of dictionarydefinitions less than twice.At the same level of genus frequency, filter 2(removing enus terms which are more frequent inother semantic ategories) is more accurate thanfilter 1 (removing all genus terms the translation14Most of them are not really errors.
For instance, allfishes must be ANIMALs, but some of them are edible(that is, FOODs).
Nevertheless.
all fishes labelled asFOOD have been considered mistakes.of which cannot be FOOD).
For instance, no errorappears when selecting those genus terms whichappear 10 or more limes (F3) and are more frequentin that category than in any other (F2), discardingonly 3% of correct genus terms (see \[Rigau et aL 98\]for complete figures).4.4 Automatically building large scaletaxonomies from DGILEThe automatic Genus Sense Disambiguationtask in DGILE has been performed following\[Rigau et al 97\].
This method reports 83%accuracy when selecting the correct hypemym bycombining eight different heuristics using severalmethods and types of knowledge (two of theheuristics use WN).Once the main top beginners (relevant genusterms) of a semantic category are selected andevery  d ic t ionary  def in i t ion has beendisambiguated, we collect all those pairs labelledwith the semantic category we are working onhaving one of the genus terms selected.
Usingthese pairs we finally build up the completetaxonomy for a given semantic primitive.
That is,in order to build the complete taxonomy for asemantic primitive we fit the lower senses usingthe second labelled lexicon and the genus selectedfrom this labelled lexicon.Although, both final taxonomic structuresproduce more fiat taxonomies than if the task isdone manually, a few arrangements could be doneat the top level of the automatic taxonomies.Studying the main top beginners we can easilydiscover an internal structure between them (forFOOD, 18 or 48 depending on the criteriaselected).Performing the process for the who ledictionary we obtained for F2+(F3>9) a taxonomicstructure of 35,099 definitions and for F2+(F3>4)the size grows to 40,754.
Testing the results onFOOD taxonomies we achived 99% accuracy withthe first criterion and 96% with the second.5 Extend ing  and  F i l l ing Gaps .Up to now we have described a methodology toconnect words from a language to a WN skeleton,and another methodology tobuild taxonomies.The words finally connected in the firstprocess, apart from the precission thresholdcriterion, do not follow any other criterion: theyare not the most important, neither the topmostnor the lowermost concepts in the hierarchy; theconnections are scattered all over the skeleton.The final set of words connected to the skeleton israndom, and we don't have any control over it.7OIIiiIiIIIiIiiiIiIFurthermore, we also find relevant words notconnected to the hierarchy.We are currently developing a methodologywhich tries to fill the gaps by merging thetaxonomy automatically extracted, and the sparseskeleton.
By now we have studied very simple andshort structures.We have then two hierarchies to compare, andtwo ways of connecting them: the alreadyextracted connections (A) between Spanish wordsand synsets, and the translations (B) given by thebilinguals (not disambiguated).
We have thenlooked for the next simple configurations:(4) sp-enI Isp-enwhere Spanish words are connected betweenthem via the automatically extracted taxonomy,and the English words via WN.
The Englishwords can be connected to the Spanish via A or viaB, or they can be unconnected.
Then we obtaineight configurations.
We have evaluated up tonow three of these classes:?
class 1: connections via A above and below 15?
class 2: connections via A above and B below?
class 4: connections via B above and A belowBelow there is a table showing volumes.
Theexperiment was carried out on four file senseswhich in our opinion would differ in theirbehaviour, food and artifact, which are classifiedvery similarly in Spanish and in English, andmental process and communication, which are notso dear:.semf i lea r t i fac tmental processcommuniccationfoodclass 1 c lass  2 c lass  4222 560 22454 182 105119 270 19830 66 56Table 2: class volumes.Of these volumes, some were already extractedwith the previous methods, but some are newlyproduced connections.
Some of the already existingconnections were incorrect, and led to incorrectdeductions.
Of the newly added connections, asample has been evaluated, giving the resultsbelow:15This class imply provides additional evidence overthe confidence score.semfilear t i fac tmental processcommunicationfoodc lass  I99%99%99%99%c lass  277%77%class 489%79%78%68%Table 3: overall resultssemf i lea r t i fac tmental processcommunicationfoodc lass  2 c lass  450% 85%50% 65%50%- 74%Table 4: results for new connectionsWe can then decide, after studying all thecases, to accept he connections above a threshold,or we can also try to combine them to extract moreprecise ones.
For example, some promisingcombinations could be:(5) sp - en -  AI !sp-en-B\[ Isp -en - A(6) sp - en - AI Isp -en -no connectionI Isp - en - Awhich are the combinations of classes 2 and 4 -in (5), and combinations of two new classes in (6).Furthermore, we are planning to apply aniterative bootstrapping method taking profit ofthose links with higher confidence scoresgathered in previous steps (acting as anchors) tospread evidence where no connections have beenfound.We are also considering the possibility oL notonly filling gaps in the middle levels of thehierarchy, but also to extend the LgWN addingsubtaxonomies tobottom synsets of WN, trying tocover semantic fields specific of Lg not covered bythe original WN.6.
ConclusionsAn approach for bui lding in a fast andautomatic  way substant ia l  f ragments ofWordNets have been presented.
The method usesas skeleton English WordNet and extracts itsknowledge from a variety of lexical sources( taxonomies,  mono l ingua l  and b i l ingua ldictionaries).
Our approach makes extensive uses71of English WordNet in several steps of thebuilding process.
The system has been applied tobuild Spanish WordNet (within the frameworkof EuroWordNet) and Catalan WordNet.
First,following \[Atserias et al 97\], we applied a set ofcomplementary techniques for linking Spanishand Catalan words collected from a bilingualMRDs (for nouns) and lexicons (for verbs) toEnglish WordNet.
Second, by applying themethodology described in section 4 we are able tobuild up accurate taxonomies from monolingualMRDs (see \[Rigau et al 97\] and \[Rigau et al 98\]).Third, taking profit of both lexical resources (thesparse connections produced by the firstmethodology and the taxonomies produced by thesecond) we have presented a novel bootstrappingmethodology for covering substantial parts of thenew WordNets not covered previously.AcknowledgementsThis research as been partially funded by theSpanish Research Department (ITEM ProjectTIC96-1243-C03-03), the Catalan ResearchDepartment (CREL project), and the UE Comision(EuroWordNet LE4003).ReferencesArtale A., Magnini B. and Strapparava C. (1997)Lexical Discrimination with the ItalianVersion of WordNet, in proceedings of ACLWorkshop Automatic Information Extractionand Building of Lexical Semantic Resources.Madrid.
Spain.Atserias J., Climent S., Farreres X., Rigau G. andRodriguez H., (1997)Combining MultipleMethods for the Automatic Construction ofMultilingual WordNets, in proceedings of ofInternational Conference "Recent Advances inNatural Language Processing" (RANLP'97).Tzigov Chark, Bulgaria.Benitez L., Cervell S., Escudero G., L6pez M.,Rigau G., and Tauld M. (1998) Methods andTools for Building the Catalan WordNet, inproceedings of ELRA Workshop on LanguageResources for European Minority Languages.Granada, Spain.Bruce R. and Guthrie L. (1992) Genusdisambiguation: A study in weigthedpreference, in proceedings of the 14thInternational Conference on ComputationalLinguistics (COLING'92).
Nantes, France.CasteU6n I., Fernandez A., Marti M.A., MoranteR.
and Vazquez G. (1997) Propuesta dealternancia de diatesis para el Espafiol yCatalan, in proceedings of the annual mettingof SEPLN.
Madrid, Spain.
1997.DGILE (1987) Diccionario General Ilustrado de laLengua Esvafiola VOX.
Alvar M.
(ed.
).Biblograf S.A. Barcelona, Spain.Gomez Perez A.
(1998) "Knowledge Sharing andReuse" in J. Liebowitz (edt) '"rhe Handbook ofApplied Expert Systems" CRC Press.Hamp B. and Feldweg H. (1997) GermaNet - aLexical-Semantic Net for German, inproceedings of ACL Workshop AutomaticInformation Extraction and Building of LexicalSemantic Resources.
Madrid.
Spain.Knight K. and Luk S. (1994)Building a Large-Scale Knowledge Base for MachineTranslation, in proceedings of the AmericanAssociation for Artificial Inteligence.
1994.Miller G. (1990) Five papers on WordNet,International Journal of Lexicogrphy 3(4).Okumura A. and Hovy E. (1994) BuildingJapanese-English Dictionary based onOntology for Machine Translation, inproceedings of ARPA Workshop on HumanLanguage Technology, pages 236-241.Richardson S. (1997) Determining Similarity 0LndInferrin~ Relations in a Lexical KnowledgevBase.
Ph.D. Thesis, The City University ofNew York, New York.Rigau G., Atserias J. and Agirre E. (1997)Combining Unsupervised Lexical KnowledgeMethods for Word Sense Disambiguation iproceedings of the 35th Annual Meeting of theACL (ACL'97).
Madrid, Spain.Rigau G., Rodriguez H. and Agirre E. (1998)Building Accurate Semantic Taxonomies fromMRDs, in proceedings of COLING-ACL'98.Montrdal, Canada.Slator B.
(1991) Using Context for SensePreference, in Zernik U.
(ed.
), Lex ica lAcouisition: ExDloitin~ On-line Resources t0v\]~\[.
.~X.L~2~ Lawrence Erlbaum Associates,publishers.
Hillsdale, New Jersey.Vossen P., Bloksma L., Rodriguez H., Climent S.,Roventini A., Bertagna F., Alonge A.
(1997)"The EuroWordNet Base Concepts and Top-Ontology" Deliverable D017D034D036EuroWordNet LE2-4003Yarowsky D. (1992) Word-Sense DisambiguationUsing Statistical Models of Rogetis CategoriesTraiend on Large Corpora, in proceedings ofCOLING'92, Nantes, France.Yarowsky D. (1995) Unsupervised Word SenseDisambiguation Rivaling Supervised Methods,in proceedings of the 33th Annual Meeting ofthe ACL (ACL'95).72
