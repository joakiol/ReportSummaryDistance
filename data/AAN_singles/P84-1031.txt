A CONNECTIONIST MODEL OF SOME ASPECTS OF ANAPHOR RESOLUTIONRonan G. ReillyEducational Research CentreSt  Patrick's College, DrumcondraDublin 9, IrelandABSTRACTTh is  paper  descr ibes  some recent  deve lopments  inlanguage process ing  invo lv ing  computat iona lmode ls  which more c lose ly  resemble  the  bra in  inboth  s t ruc ture  and funct ion .
These  mode ls  employa la rge  number  o f  in te rconnected  para l le lcomputat iona l  units which  communicate  viaweighted levels of excitation and inhibition.
Aspecific model is described which uses thisapproach to process some fragments of connecteddiscourse.I CONNECTIONIST MODELSThe human brain consists of about i00,000mill ion neuronal units with between a lO00 andI0,000 connections each.
The two main classes ofcells in the cortex are the striate and pyramidalcells.
The pyramidal cells are generally larseand heavily arborized.
They are the main outputcells of a region of cortex, and they mediateconnections between one region and the next.
Thestrlate cells are smaller, and act more locally.The neural circuitry of the cortex is, apart fromsome minor variations, remarkably consistent.
Itsdominant characteristics are Its parallelism, itslarge number processing units, and the extensivein terconnect ion  of these units.
This is afundamenta l ly  d i f ferent  s t ructure from thetraditional von Neumann model.
Those in favor ofadopting a connectionist approach to modellinghuman cognition argue that the structure of thehuman nervous system is so different from thestructure impl ic i t  in current in format ion-processing models that the standard approachcannot ultimately be successful.
They argue thateven at an abstract level, removed from immediateneural considerations, the fundamental structureof the human nervous system has a pervasiveeffect.Counect lou ls t  models form a class ofspreading activation or active semantic networkmodel.
Each primitive computing unit in thenetwork can be thought of as a stylized neuron.Its output is a function of a vector of inputsfrom neighbourlng units and a current level ofexcitation.
The inputs can be both excitatoryand inhibtory.
The output  of each unit has arest r ic ted range (in the case of the modeldescribed here, it can have a value between i andlO).
Associated with each unit are a number ofcomputational functions.
At each input sitethere are /unctions which determine how thei nputs  a re  to  be  summar ized .
A potent ia lfunct ion  determines  the  re la t ionsh ip  between thesummar ized  s i te  inputs  and the  un i t ' s  overa l lpotent ia l .
F ina l ly ,  au  output  funct iondetermines  the  re la t ionsh ip  between a un i t ' spotent ia l  and the  va lue  that  i t  t ransmi ts  to i t snelghhours.There  are  a number of  const ra in ts  inhererentin  a neura l ly  based  mode l .
One o f  the  mostsignificant is that the coinage of the brain isfrequency of firing.
This means that the inputsand outputs cannot carry more than a few bits ofinformation.
There are not enough bits in firingf requency to a l low symbol  pass ing betweenindividual units.
This is perhaps the singlebiggest difference between thls approach and andthat of standard informatlon-processing models.Another important constraint is that decisions inthe network are completely distributed, each unitcomputes its output solely on the basis of itsinputs; it cannot "look around" to see whatothers are doing, and no central controller givesit instructions.A number of l anguage  re la ted  app l i ca t ionshave  been deve loped  us ing  th i s  type  o f  approach .The most  notab le  o f  these  i s  the  mode l  o fMcC le l land  and  Rumelhar t  (1981) .
Theydemonst ra ted  that  a model  based  on connect ion is tp r inc ip les  cou ld  reproduce  many of thecharacter i s tcs  of  the  so -ca l led  word -super io r i tye f fec t .
Th is  i s  an  e f fec t  in  wh ich  le t te rs  inb r ie f ly  p resented  words and pseudo-words  a re  moreeas i l y  ident i f i ab le  than  le t te rs  in  non-words .At a h igher  leve l  in  the  process ing  h ie rarchy ,connect ion is t  schemes  have  been proposed  fo rmode l l ing  wOr~.sense  d i sambiguat ion  (Cot t re l l  &Smal l ,  1983) ,  and fo r  sentence  pars ing  in  genera l(Small, Cottrell, & Shastrl, 1982).144The model described in this paper isbasically an extension of the work of Cottrelland Small (1983), and of Small (1982).
Itextends their sentence-centred model to deal withconnected text, or discourse, and specificallywith anaphorlc resolution in discourse.
Themodel is not proposed as definitive in any way.It merely sets out to illustrate the propertiesof connectlonlst models, and to show how suchmodels might be extended beyond simple wordrecognition applications.IT ANAPHORAThe term anaphor  der ives  from the Greek fo r"po in t ing  back" .
What i s  po in ted  to  i s  o f tenre fer red  to as the antecedent  of  the anaphor .However, the precise definition of an antecedentis problematic.
Superflclally, it might bethought of as a preceding text element.
However,as Sidner (1983) pointed out words do not referto other words; people use words to refer toobjects, and anaphora are used to refer toobjects which have already been mentioned in adiscourse.
Sidner also maintains that theconcept of co-reference is inadequate to explainthe relationship between anaphor and antecedent.Co-reference means that anaphor and antecedentboth refer to the same object.
This explanationsuffices for a sentence llke:( i )  I th ink  green  app les  a re  best  and theymake the best  cook ing app les  too .where both the~ and green app les  re fer  to thesame ob jec t .
However, i t  i s  inadequate  whendea l ing  w i th  the fo l low ing  d iscourse :(2) My neighbour has an Irish Wolfhound.The~ are really huge, but friendly dogs.In this case they refers to the class of IrishWolfhounds, but the antecedent phrase refers to amember of that set.
Therefore, the anaphor andantecedent cannot be said to co-refer.
Sidnerintroduces the concept of specification andco-speclflcetlon to get around this problem.Tnstead of referring to objects in the realworld, the anaphor and its antecedent specify acognitive element in the hearerls mind.
Eventhough the same element is not co-speclfled onespecification may be used generate the other.This is not possible with co-reference because,as Sidner puts it:Co-speclflcatlon, unlike co-reference,a l lows one to  const ruc t  abst ractrepresentations and define relationshipsbetween them which can be studied in acomputational framework.
With coreference,no such use is posslble, since the objectreferred to exists in the world and is notava i lab le  for examinat ion  by thecomputational process.
(Sidner, 1983; p.269).S idner  proposes  two major  sources  of  const ra in ton what can become the co-speclflcatlon of ananaphorlc reference.
One is the shared knowledgeof speaker and hearer, and the other is theconcept of focus.
At any given time the focus ofa discourse is that discourse element which iscurrently being elaborated upon, and on which thespeakers have centered their attention.
Thisconcept of focus will be Implemented in the modelto be described, though differently from the waySidner (1983) has envisaged it.
In her modelpossible focuses are examined serlally, and adecision is not made until a sentence has beencompletely analyzed.
In the model proposed here,the focus is arrived at on-llne, and the processused is a parallel one.Ill THE SIMULATORThe model descr ibed  here  was const ructedus ing  an in teract ive  eonnect ion is t  s imu la torwr i t ten  in  Sa l fo rd  LISP and based on the des ignfo r  the Un ivers i ty  of  Rochester ' s  ISCON s imulator(Smal l ,  Shast r i ,  Brucks ,  Kaufman, Cot t re l l ,  &Addanki,  1983).
The s imulator  a l lows  the user  todes ign  d i f fe rent  types  of  un i t s .
These can haveany number  of  input  s i tes ,  each  w i th  anassociated site function.
Units also have anassociated potential and output function.
Aswell as unit types, ISCON allows the user todesign different types of weighted llnk.
Anetwork is constructed by generating units ofvarious types and connecting them up.
Processln Eis initiated by activating designated inputunits.
The simulator is implemented on a Prime550.
A network of about 50 units and 300 linkstakes  approx imate ly  30 CPU seconds per  i te ra t ion .As the number of  un i t s  inc reases  the s imula tortakes  exponent ia l l y  longer ,  mak ing  i t  veryunwie ldy  fo r  networks  of  more than  100 un i ts .
Oneso lu t ion  to the speed problem i s  to compi le  thenetworks  so that  they can be executed  fas ter .
Amore rad ica l  so lu t ion ,  and one which we arecur rent ly  work ing on, i s  to deve lop a progra - - , inglanguage which has as i t s  bas ic  un i t  a network .Th is  language would invo lve  a batch  sys tem ratherthan  an in teract ive  one.
There would,  there fore ,be a t rade-o f f  between the  ease  of  use of  anin teract ive  system and the  speed and power of abatch  approach .
A l though ISCON i s  an exce l lentmedium for  the const ruct ion  of  networks ,  i t  i sinadequate  fo r  any  fo rm o f  soph is t i ca tedexecut ion  of networks .
The proposed NetworkProgramming Language (NPL) would permi t  thede f in i t ion  and const ruct ion  of  networks  in  muchthe same way as ISCON.
However, w i th  N-PL i t  w i l la l so  be poss ib le  to se lec t ive ly  ac t ivate  sect ionsof  a par t i cu la r  network ,  to c reate  new networksby combining separate  sub-networks ,  to ca lcu la tesummary ind ices  of  any network ,  and to  use  theseind ices  in  gu id ing  the f low of  cont ro l  in  the145program.
NPL will have a number of modern flowof control facilities (for example, FOR and WHILEloops).
Unfortunately, thls language is still atthe design stage and is not available for use.IV THE MODELThe model consists of five main componentswhich interact in the manner illustrated inFigure i.
The llnes ending in filled circlesindicate inhibitory connections, the ordinarylines, excitatory ones.
Each component consistsof sets of neuron-llke units which can eitherexcite or inhibit neighbouring nodes, and nodesin connected components.
A successful parsing ofa sentence is deemed to have taken place if~during the processing of the discourse, the focusis accurately followed, and if at its end thereis a stable coalition of only those units centralto the discourse.
A set of units is deemed astable coalition if their level of activity isabove threshold and non-decreasing.CASE SCHEMAi /SENSElFigure I.
The main components of the model.A.
Lexical LevelThere is one unit at the lexical level forevery word in the model's lexicon.
Most of theunits are connected to the word sense level byunidirectional links, and after activation theydecay rapidly.
Units which do not have a wordsense representation, such as function words andpronouns, are connected by unidirectional llnk tothe case and schema levels.
A lexical unit isconnected to all the possible senses of the word.These connections are weighted according to thefrequency of occurence of the senses.
Tos imulate hear ing or reading a sentence thelexlcal units are activated one after anotherfrom left to right, in the order they occur inthe  sentence.B.
Word Sense LevelThe units at this level represent the"meaning" of the morphemes in the sentence.Ambiguous words are connected to all theirposslble meaning units, which are connected toeach other by inhibitory links.
As Cottrell andSmall  (1983) have shown, this ar rangementprovides an accuraate model of the processesinvo lved  in word  sense  d l samblguat lon .Grammat ica l  morphemes,  funct ion words, andpronouns do not have explicit representations atthis level, rather they connect directly to thecase and schema levels.C.
Focus LevelThe units at this level represent possiblefocuses of the discourse in the sense that Sidner(1983) intends.
The focus with the strongestactivation inhibits competelng focuses.
At anyone time there is a single dominant focus, thoughit may shift as the discourse progresses.
Ashift in focus occurs when evidence for the newfocus pushes its level of activation above thatof the old one.
In keeping with Sidner's (1983)position there are two types of focus used inthis model, an actor focus and a discourse focus.The actor focus represents the animate object inthe agent case in the most recent sentence.
Thediscourse focus is, as its name suggests, thecentral theme of the discourse.
The actor focusand discourse focus can be one and the same.D.
Case Leve lThis modal employs what Cottrell and Small(1982) call an "exploded case" representation.Instead of general cases such as Agent, Object,Patient, and so on, more specific case categoriesare used.
For instance, the sentence John kickedthe ball would activate the specific cases ofKick-agent and Kick-object.
The units at thislevel only fire when there is evidence from thepredicate and at least one filler.
Their outputthen goes to the appropriate units at the focuslevel.
In the example above, the predicate forKick-~gent is kick, and its filler is John.
Theunit Kick-agent then activates the actor focusunit for John.E.
Schema LevelTh is  model employs a partial implementationof Small's (1982) proposal for an exploded systemof schemas.
The schema level consists of ahierarchy of ever more abstract schemas.
At thebottom of the hierarchy there are schemas whichare so specl fc  that the number of poss ib leopt ions for f i l l lng their slots is h ighly146constrained, and the activation of each schemaserves, in turn, to activate all its slotfillers.
Levels further up in the hierarchycontain more general schema details, and theconnections between slots and their potentialfillers are less strong.V THE MODEL'S PERFORMANCEAt its current stage of development themodel can handle discourse involving pronounanaphora in which the discourse focus is made toshift.
It can resolve the type of referenceinvolved in the following two discourse examples(based on examples by Sidner, 1983; p. 276):DI-I: I've arranged a meeting with Mick andPeter.2: It should be in the afternoon.3: We can meet in my office.4: Invite Pat to come too.D2-1: I've arranged a meeting with Mick, Peter,and Pat.2: It should be in the afternoon.3: We can meet in my office.4: It's kind of small,5: but we'll only need it for an hour.In discourse DI, the focus throughout is themeeting mentioned in DI-I.
The it in DI-2 can beseen to co-speclfy the focus.
In order todetermine this a human llstner must use theirknowledge that meetings have times, among otherthings.
Although no mention is made of themeeting in DI-3 to DI-4 human l lstners caninterpret the sentences as being consistent witha meetlng focus.
In the discourse D2 the initialfocus is the meeting, but at D2-4 the focus hasclearly shifted to my office~ and remains thereuntil the end of the discourse.The network which handles this discoursedoes not parse it in its entirety.
The aim is notfor completeness, but to illustrate the operationof the schema level of the model, and to show howit aids in determining the focus of thediscourse.
Initlally, in analyzlng D1 the wordmeetin~ activates the schema WORK PLACE MEETING.This schema gets activated, rather--than~ny othermeeting schema, because the overall context ofthe discourse is that of an office memo.
Below,is a representation of the schema.
On the leftare its component slots, and on the right are allthe possible fillers for these slots.WORK PLACE MEETING schemaWPM location: librarytom officemy~f f l ceWPM time: morningafternoonWPM_partlclpants: tomvincentpatriclamickpetermeWhen th i s  schema i s  ac t ivated  the  s lo tsbecome active, and generate a low level ofsubthreshold activity in their potential fillers.When one or more fillers become active, as theydo when the words Hick and Peter are encounteredat the end of DI-I, the slot forms a feedbackloop with the fillers which lasts until theactivity of the sense representation of meetln~declines below a threshold.
A slot can only beactive if the word activating the schema isactive, which in this case is meetin$.
When anumber of fillers can fill a slot, as is the casewith the WPM part ic ipant  slot, a form ofregulated sub-~etwork is used.
On the otherhand, when there can only be one filler for aslot, as with the WPM location slot, a winner-take-all network is u~ed (both these types ofsub-network are described in Feldman and Ballard,1982).Associated with each unit at the sense levelis a focus unit.
A focus unit is connected toits corresponding sense unit by a bidirectionalexcitatory link, and to other focus units byinhibitory links.
As mentioned above, there aretwo separate  networks  of focus  un i ts ,corresponding to actor focuses and discoursefocuses, respectively.
Actors are animate objectswhich can serve as agents for verbs.
An actorfocus unit can only become active if itsassociated sense level unit is a filler for anagent case slot.
The discourse focus and actorfocus can be, but need not be, one and the same.The distinction between the two types of focus isin llne with a similar distinction made by Sidner(1983).
The structure of the focus level networkensures that there can only be one discoursefocus and one actor focus at a given time.
Indiscourses D1 and D2 the actor focus throughoutis the speaker.At  the  end  o f  the  sentence  D I -1  theWORK PLACE MEETING schema is in a stablecoa l~ ion  w~th the sense units representing Hickand Peter.
The focus units active at  this stageare those represent ing the speaker of thediscourse (the actor focus), and the meeting (thediscourse focus).
When the sentence D1-2 is147encountered the system must determine theco-speclflcatlon of it.
The lexlcal unit tt  isconnected to all focus units of inanimateobjects.
It serves to boost the potential of allthe focus units active at the time.
At thisstage, if there are a number of competitors forco-speclficatlon, a number of focus units will beactivated.
However, by the end of the sentence,if the discourse is coherent, one or other of thefocuses should have received suff ic ientactivation to suppress the activation of itscompetitors.
In the case of DI there is nocompetitor for the focus, so the it serves tofurther activate the meeting focus, and does soright from the beginning of the sentence.The sentence DI-3 serves to fill theWPM location slot.
The stable coalition is thenenl~rged to include the sense unit my office.The activation of my office activates a schema,which might look llke this:MY OFFICE schemaMO location: Prefab 1MO size: smallMO windows: twoIt is not strictly correct to call the abovestructure a schema.
Being so specific, there areonly single fillers for any of its slots.
It isreally a representation of the properties of aspecif ic office, rather than predict ionsconcerning offices in general.
However, in thecontext of this type of model, with the emphasison highly specif ic rather than generalstructures, the differences between the twoschemas presented above is not a clearcut one.When my office is activated, its focus unitalso receives some activation.
This is notenough to switch the focus away from meeting.However, it is enough to make itcandidate, which would permit a switch in focusin the very next sentence.
If a switch does nottake place, the candidate's level of activityrapidly decays.
This is what happens in DI-4,where the sentence specifies another participant,and the focus stays with meeting.
The finalresult of the analysis of discourse DI is astable coal i t ion of the elements of theWORK PLACE MEETING frame, and the variouspart~clpan~, times, and locations mentioned inthe discourse.
The final actor focus is thespeaker, and the final discourse focus is themeeting.The analysis of discourse D2 proceedsidentically up to D2-4, where the focus shiftsfrom meeting to my office.
At the beginning ofD2-4 there are two candidates for the discoursefocus, meeting and my office.
The occurence ofthe ~ord it then causes both these focuses tobecome equally active.
This situation reflectsour intuitions that at this stage in the sentencethe co-specifler of i~t is ambiguous.
However,the occurence of the word small causes a stablecoalition to form with the MY OFFICE schema, andgives the my office focus the ~xtra activation itneeds to overcome the competing meeting focus.Thus, by the end of the sentence, the focus hasshifted from meeting to my office.
By the timethe it in the final sentence is encountered,there is no competing focus, and the anaphor isresolved immediately.There are a number of fairly obviousdrawbacks with the above model.
The mostimportant of these being the specificity of thethe schema representations.
There is no obviousway of implementing a system of variable binding,where a general schema can be used, and variousfillers can be bound to, and unbound from, theslots.
It is not possible to have such symbolpassing in a connectionist network.
Instead, allpossible slot fillers must be already bound totheir slots, and selectively activated whenneeded.
To make this selective activation lessunwieldy, a logical step is to use a largenumber of very specific schemas, rather than afew general ones.Another drawback of the model proposed hereis that there is no obvious way of showing hownew schemas might be developed, or how existingones might be modified.
One of the basic rulesin building connectlonist models is that theconnect ions themselves cannot be modif ied,although their associated weights can be.
Thismeans that any new knowledge must be incorporatedin an old structure by changing the weights onthe connections between the old structure and thenew knowledge.
This also implies that the newand old elements must already be connected up.
Inspite of the apparent oversupply of neuronalelements in the human cortex, to have everythingconnected to virtually everything else seems tobe profligate.Another problem with  connectlonist models istheir potential "brittleness".
When trying toprogram a network to behave in a particular way,it is difficult to resist the urge to patch inarbitrary fixes here and there.
There are, asyet, nO equivalents of structured programmingtechniques for networks.
However, there are somehopeful signs that researchers are identifyingbasic network types whose behavior is robust overa range of conditions.
In particular, there arethe wlnner-take-all and regulated networks.
Thelatter type, permits the specification of upperand lower bounds on the activity of a sub-network, which allows the designer to avoid thetwin perils of total saturation of the network onthe one hand, and total silence on the other.
Areliable taxonomy of sub-networks would greatlyaid the designer in building robust networks.148VI CONCLUSIONTh is  paper  b r ie f ly  descr ibed  theconnectlonist approach to cognitive modelling,and showed how it might be applied to langaugeprocessing.
A connectionist model of languageprocessing was outlined, which employed schemasand focusing techniques to analyse fragments ofdiscourse.
The paper described how the model wassuccessfully able to resolve simple i__ttanaphora.A tape of the simulator used in this paper,?
along with a specification of the network used toanalyze the sample discourses, is available fromthe author at the above address, upon receipt ofa blank tape.VII REFERENCESCottrell, G.W., & Small, S.L.
(1983).
Aconnectionist scheme for modelling word sensedisambiguatlon.
Cognition and Brain Theory,~, 89-120.Feldman, J.A., & Ballard, D.N.
(1982).Connectlonlst models and their properties.Cognitive Science, 6, 205-254.McClelland, J.L., & Rumelhart, D.E.
(1981).
Aninteractive activation model of contexteffects in letter perception: Part i. Anaccount of basic findings.
PsychologicalReview, 88, 375-407.Sidner, C.L.
(1983).
Focussing in thecomprehension of definite anaphora.
In M.Brady & R.C.
Berwick (Eds.
), Computationalmodels of discourse, Cambridge,Massachusetts: MIT Press.Small, S.L.
(1982).
Exploded connections:Unchunklng schematic knowledge.In Proceedings of the Fourth AnnualConference of the Cognitive ScienceSociety, Ann Arbor, Michigan.Small, S.L., Cottrell, G.W., & ShastrI, L.(1982).
Toward connectionlst parsing.In Proceedings of the NationalConference on ArtificialIntelligence, Pittsburgh, Pennsylvania.Small, S.L., Shastrl, L., Brucks, M.L., Kaufman,S.G., Cottrell, G.W., & Addanki, S. (1983).ISCON: a network construction aid andsimulator for connectlonlst models.
TRIO9.Department of Computer Science, University ofRochester.149
