Spontaneous  Speech  Col lect ion for the ATIS Domain  w i than Aura l  User  Feedback  Parad igmChristine Pao and Jay WilponAT&T Bel l  Laborator ies600 Mounta in  Ave. Office: 2D-464Murray  Hil l ,  N J  07974ABSTRACTThis paper describes the AT&T ATIS data collection system,with emphasis on the development of the speech-in, speech-out interaction paradigm.
The ATIS task involves providingair travel information to a user in the context of a interactivedialogue.
Under the AT&T interaction paradigm, informa-tion retrieved from a travel information database in tabularform is automatically transformed into sentences, which arespoken to a user by a speech synthesizer.
To date, we havecollected over 1800 sentences from subjects who used the sys-tem to solve travel planning scenarios.
We present acompar-ison of the ATIS data collected at AT&T with the ATIS datacollected at other sites (BBN, CMU, MIT, and SRI), anddiscuss what we have learned in this prehminary effort.1.
INTRODUCTIONIn support of our research toward developing telephone-based spoken language systems, we have joined BBN,CMU, MIT, and SRI in collecting speech and languagedata for the ATIS (Air Travel Information Service) do-main.
The task of a spoken language system can bebroken into three parts.
First, the system must under-stand and interpret what the user says in the contextof the human-machine dialogue.
If the user's request isunderstood, the system must retrieve the requested in-formation.
The information source for the ATIS domainis a relational database that represents a 10-city subsetof the OAG, or Official Airline Guide.
Finally, the sys-tem must convey the retrieved information to the userin an appropriate format, or provide some other coop-erative response, such as a request for more informationor an error message.
In the AT&T ATIS data collec-tion system, the first and second portions of the taskare handled by components of the MIT ATIS system \[1\].Our efforts have been directed toward dealing with thethird part of the task: information presentation and sys-tem feedback under a speech-in, speech-out interactionparadigm.
Our goal is to begin to address the problemsof dialogue and information control which will affect theperformance of interactive spoken language systems.In this paper, we will first describe our data collectionsystem and data collection procedure.
Then, we willpresent analyses of AT&T ATIS data and of ATIS datacollected at other sites.
Finally, we will discuss what wehave learned in this preliminary effort.2.
DATA COLLECT IONAs at most of the other sites collecting ATIS data, datawere collected from subjects' interactions with a partiallysimulated spoken language system.
As in the MIT datacollection setup, a human experimenter is substitutedfor the speech recognition component of the system toprovide a transcription of the subject's speech for thenatural language (NL) component.
In this section, wediscuss the system's development, describe the systemhardware, and describe the collection procedure.2 .1 .
Sys tem Deve lopmentThe AT&T data collection system was designed toclosely simulate a real, telephone-based, human-machineinteraction.
Building on the framework of the MIT ATIScollection system, we directed our development efforttowards controlling the presentation of information re-trieved from the database, providing feedback to the useron the state of the system and the discourse, and ex-ploring areas where system initiative would help usersachieve their goals efficiently.
We also modified the sys-tem control oop to transfer ecording control away fromthe subject.In fo rmat ion  Presentat ion .
The collection systemsat all other sites make use of a visual display to presentinformation retrieved from the database in a tabularformat.
Because of our choice of an audio interactionparadigm, the AT&T system does not present informa-tion in a tabular format, but instead translates the re-trieved information into sentences.
In some cases, in-formation is converted into sentences using an entry-to-phrase, template-based approach (Figure 1).
When moreinformation is retrieved from the database than can bereasonably presented by the template-based approach,summarization functions are used to present some sub-set of the information (Figure 2).
In other cases, spe-cialized functions are used to avoid excessive repetition(Figure 3) or to select information based on the discoursehistory.43Sentence: I 'LL TAKE DELTA FLIGHT NINE SEVENTY FIVEEnt,ryType Entry Sentence Fra~nentFLIGHTJD 105595AIBL INE~ODE DL deltaAIRL INE3LIGHT 975 flisht nine seventy fiveFROM~IRPORT BOS from BostonTO_AIRPORT ATL to AtlantaDEPARTURE~IME 1520 departs at three tgenty P MARRIVAL~INE 1804 and arrives at six oh four P MSTOPS 0 gith no stopsATIS: delta fl ight nine seventy five from Boston toAtlanta departs at three tgenty P N and arrives at six ohfour P M glth no stops.Figure 1: Template-based conversion of flight informa-tion to sentence format.Sentence:Table:FL IGHT~D105584105586105588I MANT TO GO FROM BOSTON TO ATLANTA ON MONDAYAIRL INE~ODE ... DEPARTURE~IME ...DL ... 630 ...EA ... 700 ...DL ... 815 ...Summary: There are f l ights departing between six thirtyA M and eight tgenty four P M.ATIS: There are seventeen f l ights from boston to atlantaon Monday August nineteenth.There are f l ights departing betgeen six thirty A N andeight tgenty four P M.What time gould you l ike to go7Figure 2: Output of the table summarizer.
The sum-mary is one part of a three sentence response to theuser.Sentence: WHAT AIRLINES FLY FROM BOSTON TO ATLANTATable:AIRLINE NAME AIRLINE CODE FROM TODELTA AIR LINES, INC. DL BOS ATLEASTERN AIR LINES, INC. EA BOS ATLUSAIR US BOS ATLATIS: The airl ines gith service between Boston andAtlanta are Delta, Eastern, and U S Air.Figure 3: In this example, a table with three rows iscompressed into a single sentence.The information presentation component of the systemwas developed with two goals in mind.
The first wasto present information so it could be easily understood.Toward this end, the presentation component was de-veloped to format information into coherent sentences,to expand or hide all codes and abbreviations, and tomaximize the intelligibility of the speech synthesizer out-put.
The second goal was to minimize the amount ofirrelevant information presented to the user.
Towardsthis goal, the presentation component includes the abovementioned facilities for summarizing, compressing andfiltering information retrieved from the database.Sentence :  I WANT TO 60 ABOUT 3 P MATIS: There are  no f l ights  leav ing  beteeen teo  fo r ty  f i veP N and three  f i f teen  P N.The next earliest fl ight is eastern fl ight six forty f ivedepar t ing  at tgo  tgenty  one P M.The next la tes t  f l ight  i s  de l ta  f l ight  n ine seventy  f i vedepar t ing  at  th ree  tgenty  P M.P lease  re fer  to these  f l ights  by f l ight  number ordepar ture  t ime.Figure 4: AT&T system initiative.Sys tem Feedback.
The MIT ATIS system providesfeedback to the user on the state of the discourse in theform of text and synthesized speech.
However, the sup-porting text produced by the MIT system is intendedto complement and to direct the user's attention to atabular display.
This capability was modified to com-plement he summarization facility mentioned above.
Inthe example shown in Figure 2, the MIT system wouldgenerate the text "Here are the flights from Boston toAtlanta" to accompany the table listing seventeen flights,while the AT~T sysiem would generate "There are sev-enteen flights from Boston to Atlanta" to accompanythe following summary sentence.
The system error re-sponses (NL failure, database access failure, etc.)
werealso modified to fit the audio feedback paradigm.System In i t iat ive.
The MIT system takes initiativein two contexts: when the system does not have enoughinformation to access the database, and when guiding auser through the flight booking process \[3\].
The AT&Tsystem takes initiative in an additional context, whenthe subject is selecting a flight on the basis of departureor arrival time.
First, the system prompts the user fora departure time if the departure time is summarized,as in Figure 2.
Second, the system volunteers the nextearliest and next latest flight when the subject requestsa flight at a certain time, and there isn't one.
An ex-ample is shown in Figure 4.
This second capability wasdeveloped to address a problem that was causing a greatdeal of user frustration.
Because the system would notprovide complete flight information for more than threeflights, subjects were forced to play a guessing ame tofind out flight departure times.
The need for this type ofsystem initiative is a result of the limits imposed by theinteraction paradigm.
The more a system restricts theflow of information, the more assistance it must provideto help the user access the information.Record ing  Contro l .
At all the other ATIS datacollection sites, the subject controls the recording pro-cess using a push-to-talk or push-and-hold to talk mech-anism.
We chose not to use such a subject-controlledrecording mechanism in order to more closely simu-late an actual telephone dialogue.
Instead, the exper-44imenter who transcribed the subject's peech also con-trolled the start and end of recording from the key-board.
The control oop was designed to keep the in-teraction flowing as smoothly and efficiently as possiblein the hope of eliciting more natural speech from oursubjects.
Many subjects were initially uncertain aboutwhen to start and stop talking, but most of them ad-justed to the interaction after the first scenario.
Someeffects of experimenter-controlled recording on subjects'speech are discussed in section 3.4.2.2.
Record ing  Env i ronment  and  Sys-tem HardwareData were collected in a walled-off corner of a computerlaboratory.
The subjects were seated at a desk with atelephone, and provided with paper and writing imple-ments.
All system feedback to the subject was providedover the telephone by the AT&T TTS speech synthesizer.Speech data were captured simultaneously using (1) aSennheiser HMD-410 close-talking microphone amplifiedby a Shure FP l l  microphone-to-line amplifier, and (2)a standard carbon button microphone (in the telephonehandset) over local telephone lines.
Digitization was per-formed by an Ariel Pro-Port A/D system.2.3.
Data  Co l lec t ion  P rocedureBefore a recording session began, the experimenter p o-vided the subject with a brief verbal explanation of thetask and a page of written instructions.
The subjectalso received a summary of the task domain and twosets of travel planning scenarios.
The first set of sce-narios included a number of simple tasks (referred tobelow as "short scenarios") and the ATIS common sce-nario (used at all five ATIS data collection sites).
Thesecond set contained more complicated tasks (referred tobelow as "long scenarios"), and subjects were permittedto attempt to book flights while working on these scenar-ios.
Initially, the subjects elected which scenarios theywanted to try; because of problems with uneven scenariodistribution, the experimenter began selecting an initialset of scenarios (two short, one long) for each subject.Subjects were asked to speak as they would to a humanbeing, and to speak in single sentences.
They were nottold that someone was listening to them and typing inwhat they said until after the entire recording sessionwas over.
A complete session lasted about an hour, in-cluding initial instruction, a two part recording sessionwith a five minute break, and a debriefing questionnaire.During the recording session, the experimenter listenedto the subject's peech and the system's response.
Thesystem initiated the dialogue with the prompt, "I'mready to begin a scenario," and responded after everyutterance with information or an error message.
An ex-ample of a typical series of interactions i  given in Fig-ure 5.
The experimenter controlled recording from thekeyboard, starting recording as soon as the system re-sponse nded, and stopping recording when the subjectappeared to have completed a sentence.
The experi-menter was asked to transcribe xactly what the sub-ject said, excluding false starts.
However, because of(perceived) pressure on the experimenters to get answersto the subjects, especially after repeated system failure,the session transcriptions sent to the interaction log fileswere not always accurate.
Most of the time, the ex-perimenter interacted with the subject only through thesystem.
However in cases of complete system failure andsevere subject confusion, the experimenter could com-municate directly with the subject, either by sending amessage through the speech synthesizer, or by speakingdirectly to the subject.Subjects for data collection were recruited from localcivic organizations, and collection took place duringworking hours.
As a result, 82% of the subjects werefemale, and subjects ranged in age from 29 to 77, witha median age of 55.
Approximately 60% of the subjectscame from the New York City dialect region; all werenative speakers of English.
In return for each subject'sparticipation, a donation was made to the civic organi-zation through which he or she was recruited.Four summer students erved as experimenters for al-most all of the data collection sessions.
They weretrained for two weeks during pre-collection system de-bugging.
The system was debugged and intermittentlyupgraded uring and after the 2 1/2 week collection.
Allof the data was then transcribed and submitted to NISTfor distribution.3.
COMPARATIVE  ANALYSESIn the following section, we present analyses of data col-lected at AT&T and the four other data collection sites.We will pay particular attention to comparing the AT&Tdata with the MIT data, since the two collection systemshad identical natural language and database access com-ponents, and the two sites used the same travel planningscenarios.3.1.
Genera l  Character i s t i csTable 1 presents ome statistics which can be used tocharacterize each site's collection system and procedure.The statistics were computed for each speaker, and thespeaker values averaged for each site.
AT~zT is in themiddle of the pack in utterances per scenario, collectionrate (number of utterances collected ivided by recordingsession duration), and human-machine interaction time/45Scenar~\[o: "Determine the type of aircraft used on aflight from one city to another that leaves before (orafter) a certain time of the day.
"ATIS: l'm ready to begin a scenario.Subject: BEGIN SCENARIO THREEATIS: Okay, go ahead.Subject: <truncated utterance>ATIS: Could you repeat that please?
I didnJt catcheveryth ing  you sa id .Subject: YES I WOULD LIKE TO FIND WHAT FLIGHTS AREAVAILABLE FRON ATLANTA TO BOSTON ON THEMORNING OF JULY SEVENTHATIS: I'm confused.
Could you try to rephrase yourquestion?Subject: I WANT TO FLY FROM BOSTON TO ATLANTAATIS: There are seventeen flights from boston toatlanta.There are flights departing between six thirty A Hand eight twenty four P M.What t ime .
ou ld  you l i ke  to go?Subject: SIX THIRTY A MATIS: There is one flight from boston to atlanta leavings ix  th i r ty  A N.de l ta  f l ight  two twenty f i ve  from Boston to At lantadepar ts  at s ix  th i r ty  A M and ar r ives  at ninethirteen A N with no stops.Subject: WHAT TYPE OF AIRCRAFT WILL BE USEDATIS: There is aircraft for one flight.delta flight two twenty five from Boston to Atlantadeparts at six thirty A M and arrives at ninethirteen A M with no stops.
The plane for thisflight is a Mcdonnell Douglas H D eighty.Subject: I WOULD LIKE TO BOOK THAT FLIGHTATIS: There is one flight.delta flight two twenty five from Boston to Atlantadeparts at six thirty A M and arrives at ninethirteen A M with no stops.I~m sorry, I can help you with travel information,but I can ' t  book f l ights .Subject: END SCENARIOFigure 5: A typical interaction between a subject andthe AT&T data collection system.
(interval from the beginning of one utterance to the be-ginning of the next).
The average AT&T speaker usedsignificantly more words per utterance than the averagespeaker at any other site.
This may be due to our sub-jects' response to NL system failure, which is discussedin section 3.2.
AT&T subjects also had a lower aver-age speaking rate than speakers from other sites.
Thismay be related to the higher disfluency rate (discussed insection 3.4) and increases in the frequency of occurrenceand durations of silent pauses.3.2 .
NL System Fa i lu reOne of the effects of the audio interaction paridigm wasa higher NL system failure rate (MIT 33.4%, AT&T42.9%), where NL system failure is defined as the fail-Variables# UtterancesAvg utterances/scenarioAvg utterances/hourAv interaction timeAv 6 words/utteranceAv words minute~ t ~ m  mW~.2 i !
!m m B ~ i m /r a m / r a m  m m m m m/ m m m Bm m R u m mm m m m Ei F~ i i~| i l l~nn~ |Table 1: Summary of general characteristics of data fromeach site.ure to completely process an utterance because it con-tains unknown words or fails to parse.
The change inthe interaction paradigm changed the NL task; since theNL system was designed based on a visual display, theNL system failure rate was expected to increase.
Theresponse of subjects to NL system failure was also af-fected by the change to the audio interaction paradigm.Table 2 shows the subjects' responses to NL failure atAT&T and MIT.
Subjects at both AT&T and MIT spokelonger sentences and slowed their speaking rates.
How-ever, the effects of NL failure on subjects' speech aremore dramatic in the AT&T data: the number of wordsper utterance increased by over 50% (MIT 20%), thespeaking rate dropped by 15% (MIT 5%), and the utter-ance duration increased by over 75% (MIT 25%) whencompared with utterances which did not follow an NLsystem error.Variables AT&T MITAverage words/minute:Post NL failure 106.8 153.3Non-post NL failure 123.8 160.8Average words/utterance:Post NL failure 14.8 10.,2Non-post NL failure 9.8 8.6Average seconds/utterance:Post NL failure 8.3 4.0Non-post NL failure 4.7 3.2Table 2: These statistics reflect he subjects' response tosystem failure.The large increase in utterance length after NL failure,combined with the high NL failure rate, is the main rea-son the average AT&T sentence is so much longer thanthe average MIT sentence, both in number of words andin duration.
However, the reason behind the post-NL-failure increase in sentence l ngth is not entirely clear.
Aqualitative xamination seems to indicate that the sys-tem is not effectively communicating the reason for itsfailure.
The NL system usuMly fails as a result of an un-familiar, unusual, or u~agrammatical syntactic onstruc-tion.
During the initial task familiarization, the subjects46were told that the system failure was triggered by prob-lems with a sentence's grammatical construction, andnot by any type of recognition problem.
Subjects werealso informed of the system's discourse capabilities.
Yetwhen a sentence failed to parse and the subject was askedto rephrase his or her request, he or she frequently re-sponded by simply tacking on a summary of the previ-ous discourse without modifying the syntactic structureof the original sentence.
In these cases, the subjects ap-peared to respond to the NL failure as a discourse failureinstead of a syntactic failure.
Subjects did appear to ad-just their speech to the constraints imposed by the NLsystem, as the NL system failure rate decreased "from51% in the first scenario to 39% in subsequent scenarios.3.3 .
Vocabulary ComparisonsTable 3 contains tatistics on the increase in lexicon sizeas a function of the number of sentences collected.
Thebreakpoint of 600 sentences collected was chosen becauseit was the point at which the vocabulary growth rate re-mained less than 30 words/100 sentences for all sites.MIT has reached a terminal vocabulary growth rate of8.7 new words/100 sentences collected; the vocabularygrowth rates at the other four sites continue to decreaseas the number of collected sentences increases.
Figure 6is a graph of lexicon size vs. number of sentences col-lected for each site.Figure 7 shows the overlap of the different sites' lexicons.Excluding the AT&T data, the percentage of words inlexicon X that are found in lexicon Y appears to beproportional to the size of lexicon X.
However, the per-centages of words in the AT&T lexicon that appear inthe BBN, CMU, and SRI lexicons are lower (by about5 percentage points) than predicted, though the over-lap with the MIT lexicon matches the prediction fairlywell.
One explanation is that, although the change inthe interaction paradigm does affect he vocabulary, theeffect of the change in paradigm is similar to the ef-fects of other inter-site system variations.
The AT&Tsystem differs from the MIT system only in the inter-action paradigm, but differs from the BBN, CMU, andSRI systems in other ways, in addition to the differentinteraction paradigm.Variables AT&T MIT BBN CMU SRITotal utterances 1885 4247 1616 1543 1055Above 600 sentences* 13.75 12.64 19.70 14.78 15.75*For MIT, between 600 and 2000 sentences.MIT above 1000:8.72 new words/100 sensTable 3: Vocabulary growth: New words per 100 sen-tences collected.700t i ?
00 i500 _ .~  ~~z ~.4.
.'"'"
!
AT&T: ooo200-  .-,,+o;, .
.'"
i BBN: rams?
"~ ~.*..""
i CMU:  *~lOO ~.
":" i ~ "'L , , , _ , , , _0 200 4GO (6{~0 8~0 1000 1200 1400 1600 1800 2~0Calls rzlFigure 6: Number of sentences vs. vocabulary size.J858O757O6555454~3OOi I I !
ii i i i350 400 450 fRO 550 600 650 700 750 800VocJbulmy S~Figure 7: Percentage of inter-site vocabulary overlap.3.4 .
Dis f luenc iesTable 4 contains tatistics on the occurence of disflu-encies as transcribed by each site.
Partial words andword fragments are counted as lexical false starts, andverbally deleted complete words are counted as linguis-tic false starts, as in \[2\].
The high percentage of utter-ances containing linguistic false starts and filled pausesin the AT&T data reflect the subjects' response toexperimenter-controlled recording and their uncertaintyabout how to interact with the system.
Since the sub-jects did not take any initiative in starting and stoppingrecording, they were less likely to compose their thoughtsbefore they began speaking.
The rate of filled pauses andfalse starts did decrease somewhat as the subject becamemore comfortable talking to the system: comparing dis-fluency rates for first scenario and last scenario utter-ances, the percentage ofutterances containing linguisticfalse starts decreased from 13% to 11%, the percentagecontaining lexical false starts from 8% to 7%, and the47percentage containing filled pauses from 15% to 12%.NL system failure strongly affected the rate of linguis-tic false starts.
The percentage of utterances containinglinguistic false starts increased from 9.4% after a success-fully processed utterance to 14.4% after an NL systemerror.
The absence of similar increases in the rates oflexical false starts and filled pauses indicates that thesubjects' speech was disrupted primarily at the syntac-tic level.% of sentences with AT&T MIT CMU BBN SRIlinguistic false starts 11.4 3.9 1.2 2.4 4.5lexical false starts 7.6 2.8 9.3 2.2 2.8filled pauses 13.7 3.1 3.0 1.9 1.5Table 4: Percentage of sentences containing various dis-fluencies.4.
D ISCUSSIONOur initial effort in collecting ATIS domain data under aspeech-in, speech-out interaction paradigm has producedsome interesting results.
A number of issues have comeup during system development, data collection, and dataanalysis which need to be considered in the developmentof telephone-based spoken language systems and spokenlanguage systems in general.The system with which we collected ata was not ideal.Many of the subjects were able to get around the sys-tem's limitations, but others had a great deal of trouble.As a result, some of the speech we collected sounds per-fectly normal, and some sounds exceptionally unnaturaland unusual, and not like normal conversational speechat all.
Because of the system's inefficiency, some peo-ple found it difficult to keep track of the dialogue.
Othersubjects had problems because of the high system failurerate (NL and otherwise), ineffective communication ofthe discourse history, and confusion about system limita-tions.
Although most subjects aid they had no problemsunderstanding the output of the speech synthesizer, itappeared that many subjects had trouble absorbing andremembering the information presented.
Many poten-tially useful system components were only partially de-veloped, and sometimes caused new problems.
Becausethe bounds of the task domain as defined by the databasedid not match the bounds inferred by the users based onthe travel planning scenarios, subjects frequently wan-dered out of the domain.Developing an interactive system like ATIS under anaudio-only paradigm is more difficult than develop-ing a similar system under a less restrictive feedbackparadigm.
The audio interaction paradigm demandsmore effort on the system's part in compressing and fil-tering information before it is presented to the user, andin making sure all the information the user needs is eas-ily accessible.
It is more difficult to communicate systemlimitations and system status to the user, since informa-tion cannot be provided continuously or from more thanone source at a time, and the quantity of information islimited to what a user can be expected to absorb andremember.
Because the perceived waiting time is longerwith no visual distractions, a system operating under anaudio feedback paradigm must be efficient, so that theflow of the dialogue is maintained and the user remainsattentive.
There must be logical closure in the system'scapabilities, and the limits of the task domain must beobvious to the user.
These issues are critical in develop-ing telephone-based systems, and many are important inthe development of any interactive system.We intend to continue the development of the ATIS sys-tem, particularly in the areas of dialogue and informa-tion control.
We will also continue to collect data tosupport our research in telephone-based spoken languagesystems, and in support of the speech and language re-search community in general.5.
ACKNOWLEDGEMENTSWe would like to acknowledge the members of the MITLaboratory for Computer Science Spoken Language Sys-tems Group who provided us with the MIT ATIS sys-tem and other software assistance.
We would also like tothank all the people in AT&T Bell Laboratories Center1122 who provided technical support and who served asexperimenters and transcribers.REFERENCES1.
Polifroni, J., S. Seneff, V. W. Zue, and L. Hirschman,"ATIS Data Collection at MIT," DARPA SLS Note 8,Spoken Language Systems Group, MIT Laboratory forComputer Science, Cambridge, MA, November, 1990.2.
Pohfroni, J., S. Seneff, and V. W. Zue, "Collection ofSpontaneous Speech for the ATIS Domain and Com-paxative Analyses of Data Collected at MIT and TI,"Proc.
Fourth DARPA Speech and Language Workshop,P.
Price (ed.
), Morgan Kaufmann, February 1991.3.
Seneff, S., L. Hirschman, and V. Zue, "InteractiveProblem Solving and Dialogue in the ATIS Domain,"Proc.
Fourth DARPA Speech and Language Workshop,P.
Price (ed.
), Morgan Kaufmann, February 1991.48
