SOLVING ANALOGIES  ON WORDS:  AN ALGORITHMYves  LepageATR Interpreting Telecommunications Research Labs,Hikaridai 2-2, Seika-tyS, SSraku-gun, KySto 619-0288, Japanlepage@itl, atr.
co. jpI n t roduct ionTo introduce the algorithm presented in this pa-per, we take a path that is inverse to the his-torical development of the idea of analogy (se e(Hoffman 95)).
This is necessary, because acertain incomprehension is faced when speak-ing about linguistic analogy, i.e., it is generallygiven a broader and more psychological defini-tion.
Also, with our proposal being computa-tional, it is impossible to ignore works aboutanalogy in computer science, which has cometo mean artificial intelligence.1 A Survey  of Works  on Ana logyThis paper is not intended to be an exhaustivestudy.
For a more comprehensive study on thesubject, see (Hoffman 95).1.1 Metaphors ,  or Impl ic it  AnalogiesBeginning with works in psychology and arti-ficial intelligence, (Gentner 83) is a milestonestudy of a possible modeling of analogies uchas, "an atom is like the solar system" adequatefor artificial intelligence.
In these analogies, twodomains are mapped, one onto the other, thusmodeling of the domain becomes necessary.Y sun-,nucleusplanet-~YelectronIn addition, properties (expressed by clauses,formulae, etc.)
are transferred from one domainonto the other, and their number somehow de-termines the quality of the analogy.aZZracts(sun, J~aZZracZs(nucleus,planeZ) elecZron)moremassive(sun, -~fmoremassive(nucleus,planet) elecZron)However, Gentner's explicit description ofsentences as "an A is like a B" as analo-gies is subject to criticism.
Others (e.g.
(Steinhart 94)) prefer to call these sentencesmetaphors 1, the validity of which rests on sen-tences of the kind, "A is to B as C is to D", forwhich the name analogy 2 is reserved.
In otherwords, some metaphors are supported by analo-gies.
For instance, the metaphor, "an atom islike the solar system", relies on the analogy, "anelectron is to the nucleus, as a planet is to thesun"  .3The answer of the AI community is com-plex because they have headed irectly to morecomplex problems.
For them, in analogies ormetaphors (Hall 89):two different domains appearfor both domains, modeling of a knowledge-base is necessarymapping of objects and transfer of proper-ties are different operationsthe quality of analogies has to be evalu-ated as a function of the strength (number,truth, etc.)
of properties transferred.We must drastically simplify all this andenunciate a simpler problem (whose resolutionmay not necessarily be simple).
This can beaclfieved by simphfying data types, and conse-quently the characteristics of the problem.alf the fact that properties are carried over char-acterises uch sentences, then etymologically they aremetaphors: In Greek, pherein: to carry; meta-: between,among, with, after.
"Metaphor" means to transfer, tocarry over.2In Greek, logos, -logio: ratio, proportion, reason, dis-course; ann-: top-down, again, anew.
"Analog3," meansthe same proportions, similar ratios.3This complies with Aristotle's definitions in thePoetics.7281.2 Mul t ip l ic i ty  vs Unic i ty  of DomainsIn the field of natural anguage processing, therehave been plenty of works on pronunciation ofEnglish by analogy, some being very much con-cerned with reproducing human behavior (see(Damper & Eastmond 96)).
Here is an illustra-tion of the task from (Pirelli & Federici 94):vane A /vejn/,~ g .L hsane 1-~ x = /sejn/Similarly to AI approaches, two domains ap-pear (graphemic and phonemic).
Consequently,the functions f,  g and h are of different ypesbecause their domains and ranges are of differ-ent data types.Similarly to AI again, a common feature insuch pronouncing systems is the use of databases of written and phonetic forms.
Regard-ing his own model, (Yvon 94) comments that:The \[...\] model crucially relies upon theexistence of numerous paradigmatic rela-fionsh.ips in lexical data bases.Paradigmatic relationships being relation-ships in which four words intervene, they arein fact morphological nalogies: "reaction is toreactor, as faction is to factor".reactor/-~ reactio.n?
Lg  l gfactor  ~ fact ionContrasting sharply with AI approaches,morphological nalogies apply in only one do-main, that of words.
As a consequence,the number of relationships between analogicalterms decreases from three (f, g and h) to two(f  and g).
Moreover, because all four termsintervening in the analogy are from the samedomain, the domains and ranges of f and gare identical.
Finally, morphological nalogiescan be regarded as simple equations indepen-dent of any knowledge about the language inwhich they are written.
This standpoint elim-inates the need for any knowledge base or dic-tionary.\]reactor --, reaction~g ~gfactor ~ x?1.3 Unic i ty  vs Mult ip l ic i ty  of ChangesSolving morphological analogies remains diffi-cult because several simultaneous changes maybe required to transform one word into a sec-ond (for instance, doer ---, undo requires thedeletion of the suffix -er and the insertion ofthe prefix un-).
This problem has yet to besolved satisfactorily.
For example, in (Yvon 94),only one change at a time is allowed, andmultiple changes are captured by successiveapplications of morphological analogies (cas-cade model).
However, there are cases in themorphology of some languages where multiplechanges at the same time are mandatory, forinstance in semitic languages.
"One change at a time", is also found in (Na-gao 84) for a translation method, called trans-lation by analogy, where the translation of aninput sentence is an adaptation of translationsof similar sentences retrieved from a data base.The difficulty of handling multiple changes isremedied by feeding the system with new exam-ples differing by only one word commutation ata time.
(Sadler and Vendelmans 90) proposed adifferent solution with an algebra ontrees: dif-ferences on strings are reflected by adding orsubtracting trees.
Although this seems a moreconvincing answer, the use of data bases wouldresume, as would the multiplicity of domains.Our goal is a true analogy-solver, i.e., an algo-rithm which, on receiving three words as input,outputs a word, analogical to the input.
Forthat, we thus have to answer the hard problemof: (1) performing multiple changes (2) usinga unique data-type (words) (3) without dictio-nary nor any external knowledge.1.4 Analogies on WordsWe have finished our review of the problem andended up with what was the starting point ofour work.
In linguistic works, analogy is de-fined by Saussure, after Humboldt and Baudoinde Courtenay, as the operation by which, giventwo forms of a given word, and only one formof a second word, the missing form is coined 4,"honor is to hon6rem as 6r6tor is to 6rSt6rem"noted 6r~t6rem : 6rdtor = hon6rem : honor.This is the same definition as the one given byAristotle himself, "A is to B as C is to D", pos-tulating identity of types for A, B, C, and D.4Latin: 6rdtor (orator, speaker) and honor (honour)nominative singular, 5rat6rern and honfrem accusativesingular.729However, while analogy has been mentionedand used, algorithmic ways to solve analogiesseem to have never been proposed, maybe be-cause the operation, is so "intuitive".
We (Lep-age & Ando 96) recently gave a tentative com-putational explanation which was not alwaysvalid because false analogies were captured.
Itdid not constitute an algorithm either.The only work on solving analogies on wordsseems to be Copycat ((Hofstadter et al 94)and (Hoffman 95)), which solves such puzzlesas: abc : abbccc = ijk : x.
Unfortunately itdoes not seem to use a truly dedicated algo-rithm, rather, following the AI approach, it usesa forlnalisation of the domain with such func-tions as, "previous in aZphabe'c", "rank inaZphabel:", etc.2 Foundat ions  of  the  A lgor i thm2.1 The  First Term as an Axis(Itkonen and Haukioja 97) give a program inProlog to solve analogies in sentences, asa refu-tation of Chomsky, according to whom analogywould not be operational in syntax, because itdehvers non-gralnmatical sentences.
That anal-ogy would apply also to syntax, was advocateddecades ago by Hermann Paul and Bloomfield.Chomsky's claim is unfair, because it supposesthat analogy applies only on the symbol evel.Itkonen and Haukioja show that analogy, whencontrolled by some structural level, does deliverperfectly grammatical sentences.
What is ofinterest o us, is the essence of their method,which is the seed for our algorithm:Sentence D is formed by going throughsentences B and C one element at a timeand inspecting the relations of each ele-ment to the structure of sentence A (plusthe part of sentence D that is ready).Hence, sentence A is the axis against which sen-tences B and C are compared, and by oppositionto which output sentence D is built.rextder : u_~nreadoble = d"-oer : x ~ x = un~ab leThe method will thus be: (a) look for thoseparts which are not common to A and B on onehand, and not common to A and C on the otherand (b) put them together in the right order.2.2 Common SubsequeneesLooking for common subsequences of A and B(resp.
A and C) solves problem (a) by comple-mentation.
(Wagner & Fischer 74) is a methodto find longest common subsequences by com-puting edit distance matrices, yielding the min-imal number of edit operations (insertion, dele-tion, substitution) necessary to transform onestring into another.For instance, the following matrices give thedistance between like and unlike on one hand,and between like and known on the other hand,in their right bottom cells: dist(l ike, unlike) = 2and dist( Iike, known) = 5u n l i k e k n o w n!
1 2 2 3 4 5 l 1 2 3 4 5i 2 2 3 2 3 4 i 2 2 3 4 5k 3 3 3 3 2 3 k 2 3 3 4 5e 4 4 4 4 3 2 e 3 3 4 4 52.3 Simi l i tude between WordsWe call simi l i tude between A and B the lengthof their longest common subsequence.
It is alsoequal to the length of A, minus the number ofits characters deleted or replaced to produce B.This number we caU pdist(A,B), because it isa pseudo-distance, which can be computed ex-actly as the edit distances, except that inser-tions cost 0.sire(A, B) = I A \[ - pdist(A, B)For instance, pdist(unl ike,  like) = 2, whilepdist (  like, unlike) = O.l i k eu 1 1 1 1 u n l i k en 2 2 2 2l 2 2 2 2 I 1 1 0 0 0 0i 3 2 2 2 i 2 2 1 0 0 0k 4 3 2 2 k 3 3 2 1 0 0e 5 4 3 2 e 4 4 3 2 1 0Characters inserted into B or C may be leftaside, precisely because they are those charac-ters of B and C, absent from A, that we wantto assemble into the solution, D.As A is the axis in the resolution of analogy,graphically we make it the vertical axis aroundwhich the computation of pseudo-distancestakes place.
For instance, for l i ke :un l i ke  =k,'r~OW~ : X,n w o n k u n 1 i k e1 I I I i I 1 I 0 0 0 02 2 2 2 2 i 2 2 1 0 0 02 2 2 2 2 k 3 3 2 1 0 03 3 3 3 3 e 4 4 3 2 i 07302.4 The  Coverage  Const ra in tIt is easy to verify that there is no solution to ananalogy if some characters of A appear neitherin B nor in C. The contrapositive says that,for an analogy to hold, any character of A hasto appear in either B or C. Hence, the sumof the similitudes of A with B and C must begreater than or equal to its length: sim(A, B) +sire(A, C) >_ I A I, or, equivalently,I d I ~ pdist(d, B) + pdist(d, C)When the length of A is greater than the sumof the pseudo-distances, some subsequences ofA are common to all strings in the same order.Such subsequences have to be copied into thesolution D. We call com(A, B, C, D) the sumof the length of such subsequences.
The del-icate point is that this sum depends preciselyon the solution D being currently built by thealgorithnLTo summarise, for analogy A : B = C : D tohold, the following constraint must be verified:I A I = pdist(A, B)+pdist(A, C)+com(A, B, C, D)3 The  A lgor i thm3.1 Computat ion  of  Mat r i cesOur method relies on the computation of twopseudo-distance matrices between the three firstterms of the analogy.
A result by (Ukkonen 85)says that it is sufficient o compute a diagonalband plus two extra bands on each of its sides inthe edit distance matrix, in order to get the ex-act distance, if the value of the overall distanceis known to be less than some given thresh-old.
This result applies to pseudo-distances,and is used to reduce the computation of thetwo pseudo-distance matrices.
The width of theextra bands is obtained by trying to satisfy thecoverage constraint with the value of the currentpseudo-distance in the other matrix.proc compute_matrices(A, B, C, pdAB,pdAc)compute pseudo-distances matrices withextra bands of pdAB/2 and pdAc/2i f  \ [d l>_  pd is t (d ,B)+ pdist(A,C)main componentelsecompute.anatrices(A, B, C,max(\[ A I - pdist(d, C),pdAB + 1),xnax(I A I - pdist(A, B),pdac + x))end ifend proc COlnpute_matrices3.2 Ma in  ComponentOnce enough in the matrices has been com-puted, the principle of the algorithm is to followthe paths along which longest common subse-quences are found, simultaneously in both ma-trices, copying characters into the solution ac-cordingly.
At each time, the positions in bothmatrices must be on the same horizontal line,i.e.
at a same position in A, in order to ensurea right order while building the solution, D.Determining the paths is done by compar-ing the current cell in the matrix with its threeprevious ones (horizontal, vertical or diagonal),according to the technique in (Wagner & Fis-cher 74).
As a consequence, paths are followedfrom the end of words down to their begin-ning.
The nine possible combinations (three di-rections in two matrices) can be divided intotwo groups: either the directions are the samein both matrices, or they are different.The following sketches the al-gorithm, corn(A, B,C, D) has been initialisedto: I AI - (pdist(d,B)  + pdist(d,C)) ,  iA, isand ic are the current positions in A, B andC.
dirAB (resp.
dirAc) is the direction of thepath in matrix A x B (resp.
A ?
C) from thecurrent position.
"copy" means to copy a char-acter from a word at the beginning of D and tomove to the previous character in that word.i f  constraint(iA, iB, ic, corn(A, B, C, D))case:  dirAB = dirAc = diagonali f  A\[iA\] = B\[iB\] = C\[ic\]decrement corn(A, B, C, D)end ifcopy B\[iB\] + C\[ic\] - A\[iA\] ~case:  dirAB = dirAC = horizontalcopy charb/min(pdist(A\[1..iA\], B\[1..iB\]),pdist( A\[1..iA\], C\[1..ic\]) )case:  dirAB = dirAc = verticalmove only in A (change horizontal line)case: dirAB # dirAci f  dirAB = horizontalcopy B\[iB\]aIn this case, we move in tile three words at thesame time.
Also, the character arithmetics factors,in view of generalisations, different operations: if thethree current characters inA, B and C are equal, copythis character, otherwise copy that character f om Bor C that is different from the one in A.
If all currentcharacters are different, his is a failure.bThe word with less similitude with A is chosen, soas to make up for its delay.731e\].se ?f  d i rAB = verticalmove in A and Ce1$?
same thing by exchanging B and Cend ?fend if3.3 Ear ly  Terminat ion  in Case o fFailureComplete computation of both matrices is notnecessary to detect a failure.
It is obvious whena letter in A does not appear in B or C. Thismay already be detected before any matrix com-putation.Also, checking the coverage constraint allowsthe algorithm to stop as soon as non-satisfyingmoves have been performed.3.4 An  ExampleWe will show how the analogy l ike : unl ike =known : x is solved by the algorithm.The algorithm first verifies that all lettersof l ike are present either in unl ike or known.Then, the minimum computation is done for thepseudo-distances matrices, i.e.
only the mini-mal diagonal band is computed.e k i l n u k n o w n0 1 1 1 1 10 1 2 i 2 20 1 2 k 3 30 1 2 e 4 4As the coverage constraint is verified, themain component is called.
It follows the pathsnoted by values in circles in the matrices.e k i 1 n u k n o w n?
?
i ?
?1 2 i 2 ~)The succession of moves triggers the followingcopies into the solution:dirABdiagonaldiagonaldiagonaldiagonalhorizontalhorizontalhorizontald i rAc  copydiagonal ndiagonal wdiagonal odiagonal nhorizontal kdiagonal ndiagonal uAt each step, the coverage constraint being veri-fied, finally, the solution x = unknown is ouptut.4 P roper t ies  and  Coverage4.1 Trivial Cases, Mir ror ingTrivial cases of analogies are, of course, solvedby the algorithm, like: A :A=A:x  =~ x=A or A:A  = C :x  ~ x = C. Also, byconstruction, A :B= C:x  and A: C=B:xdeliver the same solution.With this construction, mirroring poses noproblem.
If we note A the mirror of word A,then A:B=C:D ?~ A :B=C:D.4.2 Pref ix ing,  Suffixing, Paral lelInf ix ingAppendix A lists a number of examples, actu-ally solved by the algorithm, from simple tocomplex, which illustrate the algorithm's per-formance.4.3 Redup l i ca t ion  and Permutat ionThe previous form of the algorithm does notproduce redupl ication.
This would be neces-sary if we wanted to obtain, for example, plu-rals in IndonesianS: orang:  orang-orang =burung : x =v x = burung-burung .
In thiscase, our algorithm delivers, x = orang-burung,because preference is given to leave prefixes un-changed.
However, the algorithm may be easilymodified so that it applies repeatedly so as toobtain the desired solution 6.Permutation is not captured by the algo-rithm.
An example (q with a and u) in Proto-semitic is: yaqti lu : yuqtiIu = qatal : qutaI.4.4 Language- independence/Code-dependenceBecause the present algorithm performs compu-ration only on a symbol evel, it may be appliedto any language.
It is thus language indepen-dent.
This is fortunate, as analogy in linguisticscertainly derives from a more general psycho-logical operation ((Gentner 83), (Itkonen 94)),which seems to be universal among human be-ings.
Examples in Section A illustrate the lan-guage independence of the algorithm.Conversely, the symbols determine the granu-larity of the analogies computed.
Consequently,a commutation not reflected in the coding sys-tem will not be captured.
This may be illus-trated by a Japanese xample in three differentSorang (human being) singular, orang-orang plural,burung (bird).SSi,nilarly, it is easy to apply the algorithm in atransducer-like way so that it modifies, by analogy, partsof an input string.732codings: the native writing system, the Hep-burn transcription and the official, strict rec-omlnendation (kunrei).Kanji/Kana: ~-9 : ~#~ ~-9- = ~ < : xHepburn: matsu  : maeh imasu  = hataraku  : xKunrei: matu : mat imasu  = hataraku  : xx = hatarak imasuThe algorithm does not solve the first two analo-gies (solutions: ~-~ $ #,  hatarok imasu)  be-cause it does not solve the elementary analogies,-9 :~ = < : ~ and t su :ch i=ku:k i ,  whichare beyond the symbol evel r.More generally speaking, the interaction ofanalogy with coding seems the basis of a fre-quent reasoning principle:f (A )  : f (B )  = f (C)  : x ~ A : B==_ C : f - t  (x )Only the first analogy holds on the symbol eveland, as is, is solved by our algorithm, f is anencoding function for which an inverse exists.A striking application of this principle is theresolution of some Copycat puzzles, like:abc : abd = i jk  : x => x= ij IUsing a binary ASCII representation, which re-flects sequence in the alphabet, our algorithmproduces:011000010110001001100011 : 011000010110001001100100---~ 011010010110101001101011 : X=:~ X ~ 011010010110101001101100 ~ ijlSet in this way, even analogies of geometricaltype can be solved under a convenient represen-tation.An adequate description (or coding), with noreduplication, is:ob j (b ia )& .
ob j (~maU)C ob j (b ig )_  ob j (b ig )~ :xob j=c i rc le"  ~:ob j=c i rc le  - ob j=squareThis is actually solved by our algorithm:obj( , .U)c obj(bia)x = &ob j=square~One could imagine extending the algorithm byparametrising it with such predefined analogicalrelations.In other words, coding is the key to manyanalogies.
More generally we follow (Itkonenand Haukioja 97) when they claim that analogyis an operation against which formal represen-tations should also be assessed.
But for that, ofcourse, we needed an automatic analogy-solver.Conc lus ionWe have proposed an algorithm which solvesanalogies on words, i .e.
when possible it coinsa fourth word when given three words.
It re-lies on the computation of pseudo-distances be-tween strings.
The verification of a constraint,relevant for analogy, limits the computation ofmatrix cells, and permits early termination incase of failure.This algorithm has been proved to handlemany different cases in many different lan-guages.
In particular, it handles parallel infix-ing, a property necessary for the morphologicaldescription of semitic languages.
Reduplicationis an easy extension.This algorithm is independent of any lan-guage, but not coding-independent: it consti-tutes a trial at inspecting how much can beachieved using only pure computation on sym-bols, without any external knowledge.
We areinclined to advocate that much in the matter ofusual analogies, is a question of symbolic rep-resentation, i .e.
a question of encoding into aform solvable by a purely symbolic algorithmlike the one we proposed.A ExamplesThe following examples how actual resolutionof analogies by the algorithm.
They illustratewhat the algorithm achieves on real linguisticexamples.A.1 Inser t ion  or de let ion of  pref ixes orsuffixesLatin: oratorem : o ra tor  = honorem : xx = honorFrench: rdpress ion  : rdp .
ress ionna i re  = rdact ion  : xx = rdact ionna i reMalay: t ingga l  : ke t ingga lan  = d~tduk : xx = kedudukanChinese: ~:4~ : ~$~ = ~ :xx = ~733A.2 Exchange o f  prefixes or suffixesEnglish: wolf: wolves = leaf: xx = leavesMalay: kawan : mengawani = keliting : xx = mengelil ingiMalay: keras : mengeraskan = kena : xX ---- 17zengef la \ ]za l~Polish: wyszedteg : wyszIa.4 = poszedted : xx = posztadA.3 Infixing and umlautJapanese: ~ :~@Y~ =~7o :xx= ,~@~German: lang : Idngste = scharf : xx = schdrfsteGerman: f l iehen : er floh = schlie~en : xx - er sehloflPolish: zgubiony : zgubieni = zmartwiony : xx = zmartwieniAkkadian: uka~.~ad : uktanaggad = ugak.~ad : xx = u.?tanakgadA.4 Parallel infixingProto-semitic: yasriqu : sariq = yanqinm : xx = naqimArabic: huziht : huzdI= sudi'a : xx = sud(~'Arabic: arsaIa : mursitun = asIama : xx = m.usIimunReferencesRobert I. Damper & John E.G.
EastmanPronouncing Text by AnalogyProceedings of COLING-96, Copenhagen,August 1996, pp.
268-269.Dedre GentnerStructure Mapping: A Theoretical Model forAnalogyCognitive Science, 1983, vol.
7, no 2, pp.
155-170.Rogers P. HallComputational Approaches to AnalogicalReasoning: A Comparative AnalysisArtif icial Intelligence, Vol.
39, No.
1, May1989, pp.
39-120.Douglas Hofstadter and the Fluid Analogies Re-search GroupFluid Cbncepts and Crexttive AnalogiesBasic Books, New-York, 1994.Robert R. HoffmanMonster AnalogiesAI  Magazinc, Fall 1995, vol.
11, pp 11-35.Esa ItkonenIconicity, analogy, and universal grammarJournal of Pragmatics, 1994, vol.
22, pp.
37-53.Esa Itkonen and Jussi HaukiojaA rehabilitation of analogy in syntax (andelsewhere)in AndrOs Kert~sz (ed.)
Metalinguistik imWandeh die kognitive Wende in Wis-senschaflstheorie und Linguistik Frankfurta/M, Peter Lang, 1997, pp.
131-177.Yves Lepage & Ando Shin-IchiSaussurian analogy: a theoretical accountand its applicationPrecedings of COLING-96, Copenhagen,August 1996, pp.
717-722.Nagao MakotoA Framework of a Mechanical Translation be-tween Japanese and English by Analogy Prin-ciplein Artificial ~ Human Intelligence, AlickElithorn and Ranan Banerji eds., ElsevierScience Publishers, NATO 1984.Vito Pirelli & Stefano Federici"Derivational" paradigms in morphonologyProceedings of COLING-94, Kyoto, August1994, Vol.
I, pp 234-240.Victor Sadler and Ronald VendelmansPilot implementation of a bilingual knowl-edge bankProceedings of COLING-90, Helsinki, 1990,vol 3, pp.
449-451.Eric SteinhartAnalogical Truth Conditions for MetaphorsMetaphor and Symbolic Activity, 1994, 9(3),pp 161-178.Esko UkkonenAlgorithms for Approximate String Matchingh~formation and Control, 64, 1985, pp.
100-118.Robert A. Wagner and Michael J. FischerThe String-to-String Correction ProblemJournal for the Association of ComputingMachinery, Vol.
21, No.
1, January 1974, pp.168-173.Frangois YvonParadigmatic Cascades: a LinguisticallySound Model of Pronunciation by AnalogyProceedings of A CL-EACL-97, Madrid, 1994,pp 428-435.734
