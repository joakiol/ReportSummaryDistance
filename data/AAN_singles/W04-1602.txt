Developing an Arabic Treebank: Methods, Guidelines, Procedures, and ToolsMohamed MAAMOURILDC, University of Pennsylvania3600 Market Street, Suite 810Philadelphia, PA 19104, USAmaamouri@ldc.upenn.eduAnn BIESLDC, University of Pennsylvania3600 Market Street, Suite 810Philadelphia, PA 19104, USAbies@ldc.upenn.eduAbstractIn this paper we address the followingquestions from our experience of the last twoand a half years in developing a large-scalecorpus of Arabic text annotated formorphological information, part-of-speech,English gloss, and syntactic structure:  (a)How did we ?leapfrog?
through the stumblingblocks of both methodology and training insetting up the Penn Arabic Treebank (ATB)annotation?
(b) How did we reconcile thePenn Treebank annotation principles andpractices with the Modern Standard Arabic(MSA) traditional and more recentgrammatical concepts?
(c) What are thecurrent issues and nagging problems?
(d)What has been achieved and what are ourfuture expectations?1 IntroductionTreebanks are language resources that provideannotations of natural languages at various levelsof structure: at the word level, the phrase level, andthe sentence level.
Treebanks have becomecrucially important for the development of data-driven approaches to natural language processing(NLP), human language technologies, automaticcontent extraction (topic extraction and/orgrammar extraction), cross-lingual informationretrieval, information detection, and other forms oflinguistic research in general.The Penn Arabic Treebank began in the fall of2001 and has now completed two full releases ofdata: (1) Arabic Treebank: Part 1 v 2.0, LDCCatalog No.
LDC2003T06, roughly 166K words ofwritten Modern Standard Arabic newswire fromthe Agence France Presse corpus; and (2) ArabicTreebank: Part 2 v 2.0, LDC Catalog No.LDC2004T02, roughly 144K words from Al-Hayatdistributed by Ummah Arabic News Text.
Newfeatures of annotation in the UMAAH (UMmahArabic Al-Hayat) corpus include completevocalization (including case endings), lemma IDs,and more specific part-of-speech tags for verbs andparticles.
Arabic Treebank: Part 3 is currentlyunderway, and consists of text from An-Nahar.
(Maamouri and Cieri, 2002)The ATB corpora are annotated formorphological information, part-of-speech,English gloss (all in the ?part-of-speech?
phase ofannotation), and for syntactic structure (TreebankII style).
(Marcus, et al, 1993), (Marcus, et al,1994)In addition to the usual issues involved with thecomplex annotation of data, we have come toterms with a number of issues that are specific to ahighly inflected language with a rich history oftraditional grammar.2 Issues of methodology and training withModern Standard Arabic2.1 Defining the specificities of ?ModernStandard Arabic?Modern Standard Arabic (MSA), the naturallanguage under investigation, is not nativelyspoken by Arabs, who acquire it only throughformal schooling.
MSA is the only form of writtencommunication in the whole of the Arab world.Thus, there exists a living writing and readingcommunity of MSA.
However, the level of MSAacquisition by its members is far from beinghomogeneous, and their linguistic knowledge, evenat the highest levels of education, very unequal.This problem is going to have its impact on ourcorpus annotation training, routine, and results.
Asin other Semitic languages, inflection in MSA ismostly carried by case endings, which arerepresented by vocalic diacritics appended inword-final position.
One must specify here thatthe MSA material form used in the corpus data weuse consists of a graphic representation in whichshort vowel markers and other pertinent signs likethe ?shaddah?
(consonantal germination) are leftout, as is typical in most written Arabic, especiallynews writing.
However, this deficient graphicrepresentation does not indicate a deficientlanguage system.
The reader reads the text andinterprets its meaning by ?virtually providing?
themissing grammatical information that leads to itsacceptable interpretation.2.2 How important is the missinginformation?Our description and analysis of MSA linguisticstructures is first done in terms of individual wordsand then expanded to syntactic functions.
Eachcorpus token is labeled in terms of its category andalso in terms of its functions.
It is markedmorphologically and syntactically, and otherrelevant relationship features also intervene such asconcord, agreement and adjacency.
Thisredundancy decreases the importance of theabsence of most vocalic features.2.3 The issue of vocalizationThe corpus for our annotation in the ATBrequires that annotators complement the data bymentally supplying morphological informationbefore choosing the automatic analysis, whichamounts to a pre-requisite ?manual/human?intervention and which takes effect even before theannotation process begins.
Since no automaticvocalization of unvocalized MSA newswire data isprovided prior to annotation, vocalization becomesthe responsibility of annotators at both layers ofannotation.
The part-of-speech (POS) annotatorsprovide a first interpretation of the text/data and avocalized output is created for the syntactictreebank (TB) annotators, who then engage in theresponsibility of either validating the interpretationunder their scrutiny or challenging it and providinganother interpretation.
This can have drasticconsequences as in the case of the so-called?Arabic deverbals?
where the same bare graphemicstructure can be two nouns in an ?idhafa(annexation or construct state) situation?
with agenitive case ending on the second noun or a?virtual?
verb or verbal function with a nouncomplement in the accusative to indicate a directobject.
In Example 1, genitive case is assignedunder the noun interpretation, while accusativecase is assigned by the same graphemic form of theword in its more verbal function (Badawi, et al,2004, cf.
Section 2.10, pp.
237-246).Example 11Neutral form:  <xbArh Al+nb>        ??????
????
?Idhafa:  <ixbAruhu Al+naba>i         ??????????
??????
?his receipt (of) the news [news genitive]Verbal:  <ixbAruhu Al+naba>a         ??????????
??????
?his telling the news [news accusative]These are sometimes difficult decisions to make,and annotators?
agreement in this case is always at1  For the transliteration system of all our Arabiccorpora, we use Tim Buckwalter?s code, athttp://www.ldc.upenn.edu/myl/morph/buckwalter.htmlits lowest.
Vocalization decisions have a non-trivial impact on the overall annotation routine interms of both accuracy and speed.Vocalization is a difficult problem, and we didnot have the tools to address it when the projectbegan.
We originally decided to treat our firstcorpus, AFP, by having annotators supply word-internal lexical identity vocalization only, becausethat is how people normally read Arabic ?
takingthe normal risks taken by all readers, with theassumption that any interpretation of the case ormood chosen would be acceptable as theinterpretation of an educated native speakerannotator.
In our second corpus, UMAAH, wedecided that it would improve annotation and theoverall usefulness of the corpus to vocalize thetexts, by putting the necessary rules of syntax andvocalization at the POS level of annotation ?
ourannotators added case endings to nouns and voiceto verbs, in addition to the word-internal lexicalidentity vocalization.
For our third corpus,ANNAHAR (currently in production), we havedecided to fully vocalize the text, adding the finalmissing piece, mood endings for verbs.
Inconclusion, vocalization is a nagging but necessary?nuisance?
because while its presence justenhances the linguistic analysis of the targetedcorpus, its absence could be turned into an issue ofquality of annotation and of grammaticalcredibility among Arab and non-Arab users.3 Reconciling Treebank annotation withtraditional grammar concepts in ArabicThe question we had to face in the early stagesof ATB was how to develop a Treebankmethodology ?
an analysis of all the targetedsyntactic structures ?
for MSA represented byunvocalized written text data.
Since all Arabicreaders ?
Arabs and foreigners ?
go through theprocess of virtually providing/inserting therequired grammatical rules which allow them toreach an interpretation of the text and consequentunderstanding, and since all our recruitedannotators are highly educated native Arabicspeakers, we accepted going through our firstcorpus annotation with that premise.
Ourconclusion was that the two-level annotation waspossible, but we noticed that because of the extratime taken hesitating about case markings at theTB level, TB annotation was more difficult andmore time-consuming.
This led to including allpossible/potential case endings in the POSalternatives provided by the morphologicalanalyzer.
Our choice was to make the twoannotation passes equal in difficulty by transferringthe vocalization difficulty to the POS level.
Wealso thought that it is better to localize thatdifficulty at the initial level of annotation and to tryto find the best solution to it.
So far, we are happywith that choice.
We are aware of the need to havea full and correct vocalization for our ATB, and weare also aware that there will never be an existingextensive vocalized corpus ?
except for theKoranic text ?
that we could totally trust.
Thechallenge was and still is to find annotators with avery high level of grammatical knowledge inMSA, and that is a tall order here and even in theArab region.So, having made the change from unvocalizedtext in the ?AFP Corpus?
to fully vocalized textnow for the ?ANNAHAR Corpus,?
we still need toask ourselves the question of what is better: (a) anannotated corpus in which the ATB end users areleft with the task of providing case endings toread/understand or (b) an annotated ATB corpusdisplaying case endings with a higher percentageof errors due to a significantly more complexannotation task?3.1 Training annotators, ATB annotationcharacteristics and speedThe two main factors which affect annotationspeed in our ATB experience are both related tothe specific ?stumbling blocks?
of the Arabiclanguage.1.
The first factor which affects annotationaccuracy and consistency pertains to theannotators?
educational background (theirlinguistic ?mindset?)
and more specifically to theirknowledge ?
often confused and not clear ?
oftraditional MSA grammar.
Some of the importantobstacles to POS training come from the confusingoverlap, which exists between the morphologicalcategories as defined for Western languagedescription and the MSA traditional grammaticalframework.
The traditional Arabic frameworkrecognizes three major morphological categoriesonly, namely NOUN, VERB, and PARTICLE.This creates an important overlap which leads tomistakes/errors and consequent mismatchesbetween the POS and syntactic categories.
Wehave noticed the following problems in our POStraining: (a) the difficulty that annotators have inidentifying ADJECTIVES as against NOUNS in aconsistent way; (b) problems with defining theboundaries of the NOUN category presentingadditional difficulties coming from the fact that theNOUN includes adjectives, adverbials, andprepositions, which could be formally nouns inparticular functions (e.g., from fawq ???
NOUN tofawqa ?????
PREP ?above?
and fawqu ?????
ADVetc.).
In this case, the NOUN category thenoverlaps with the adverbs and prepositions ofWestern languages, and this is a problem for ourannotators who are linguistically savvy and havean advanced  knowledge of English and, mosttimes, a third Western language.
(c) Particles arevery often indeterminate, and their category alsooverlaps with prepositions, conjunctions,negatives, etc.2.
The second factor which affects annotationaccuracy and speed is the behemoth ofgrammatical tests.
Because of the frequency ofobvious weaknesses among very literate andeducated native speakers in their knowledge of therules of ?<iErAb?
(i.e., case ending marking), itbecame necessary to test the grammaticalknowledge of each new potential annotator, and tocontinue occasional annotation testing at intervalsin order to maintain consistency.While we have been able to take care of the firstfactor so far, the second one seems to be a verypersistent problem because of the difficulty levelencountered by Arab and foreign annotators alikein reaching a consistent and agreed upon use ofcase-ending annotation.4 Tools and procedures4.1 Lexicon and morphological analyzerThe Penn Arabic Treebank uses a level ofannotation more accurately described asmorphological analysis than as part-of-speechtagging.
The automatic Arabic morphologicalanalysis and part-of-speech tagging was performedwith the Buckwalter Arabic MorphologicalAnalyzer, an open-source software packagedistributed by the Linguistic Data Consortium(LDC catalog number LDC2002L49).The analyzer consists primarily of three Arabic-English lexicon files: prefixes (299 entries),suffixes (618 entries), and stems (82158 entriesrepresenting 38600 lemmas).
The lexicons aresupplemented by three morphologicalcompatibility tables used for controlling prefix-stem combinations (1648 entries), stem-suffixcombinations (1285 entries), and prefix-suffixcombinations (598 entries).The Arabic Treebank: Part 2 corpus contains125,698 Arabic-only word tokens (prior to theseparation of clitics), of which 124,740 (99.24%)were provided with an acceptable morphologicalanalysis and POS tag by the morphological parser,and 958 (0.76%) were items that the morphologicalparser failed to analyze correctly.Items with solution      124740   99.24%Items with no solution           958     0.76%Total                    125698 100.00%Table 1.
Buckwalter lexicon coverage, UMAAHThe ANNAHAR coverage statistics after POS 1(dated January 2004) are as follows:The ANNAHAR Corpus contains 340,281tokens, of which 47,246 are punctuation, numbers,and Latin strings, and 293,035 are Arabic wordtokens.Punctuation, Numbers, Latin strings 47,246Arabic Word Tokens 293,035TOTAL 340,281Table 2.
Token distribution, ANNAHAROf the 293,035 Arabic word tokens, 289,722(98.87%) were provided with an accuratemorphological analysis and POS tag by theBuckwalter Arabic Morphological Analyzer.3,313 (1.13%) Arabic word tokens were judged tobe incorrectly analyzed, and were flagged with acomment describing the nature of the inaccuracy.
(Note that 204 of the 3,313 tokens for which nocorrect analysis was found were typos in theoriginal text).Accurately analyzedArabic Word Tokens289,722 98.87%Commented Arabic WordTokens/ items with nosolution3,313 1.13%TOTAL 293,035 100.00%Table 3.
Lexicon coverage, ANNAHARCOMMENTS ON ITEMS WITH NO SOLUTION(no comment)  1741 52.55%MISC comment  566 17.08%ADJ    250 7.55%NOUN   233 7.03%TYPO   204 6.16%PASSIVE_FORM  110 3.32%DIALECTAL_FORM 68 2.05%VERB   37 1.12%FOREIGN WORD  34 1.03%IMPERATIVE  24 0.73%ADV    9 0.27%GRAMMAR_PROBLEM 9 0.27%NOUN_SHOULD_BE_ADJ 7 0.21%A_NAME   6 0.18%NUMERICAL  6 0.18%ABBREV   5 0.15%INTERR_PARTICLE 4 0.12%TOTAL   3313 100.00%Table 4.
Distribution of items with no solution,ANNAHAR4.2 Parsing engineIn order to improve the speed and accuracy ofthe hand annotation, we automatically pre-parsethe data after POS annotation and before TBannotation using Dan Bikel's parsing engine(Bikel, 2002).
Automatically pre-parsing the dataallows the TB annotators to concentrate on the taskof correcting a given parse and providinginformation about syntactic function (subject,direct object, adverbial, etc.
).The parsing engine is capable of implementing avariety of generative, PCFG-style models(probabilistic context free grammar), including thatof Mike Collins.
As such, in English, it getsresults that are as good if not slightly better thanthe Collins parser.
Currently, this means that, forSection 00 of the WSJ of the English PennTreebank (the development test set), the parsingengine gets a recall of 89.90 and a precision of90.15 on sentences of length <= 40 words.
TheArabic version of this parsing engine currentlybrackets AFP data with recall of 75.6 and precisionof 77.4 on sentences of 40 words or less, and weare in the process of analyzing and improving theparser results.4.3 Annotation procedureOur annotation procedure is to use the automatictools we have available to provide an initial passthrough the data.
Annotators then correct theautomatic output.First, Tim Buckwalter?s lexicon andmorphological analyzer is used to generate acandidate list of ?POS tags?
for each word (in thecase of Arabic, these are compound tags assignedto each morphological segment for the word).
ThePOS annotation task is to select the correct POStag from the list of alternatives provided.
OncePOS is done, clitics are automatically separatedbased on the POS selection in order to create thesegmentation necessary for treebanking.
Then, thedata is automatically parsed using Dan Bikel?sparsing engine for Arabic.
Treebank annotatorscorrect the automatic parse and add semantic roleinformation, empty categories and theircoreference, and complete the parse.
After that isdone, we check for inconsistencies between thetreebank and POS annotation.
Many of theinconsistencies are corrected manually byannotators or automatically by script if reliablysafe and possible to do so.4.4 POS annotation quality controlFive files with a total of 853 words (and avarying number of POS choices per word) wereeach tagged independently by five annotators for aquality control comparison of POS annotators.
Outof the total of 853 words, 128 show somedisagreement.
All five annotators agreed on 85%of the words; the pairwise agreement is at least92.2%.For 82 out of the 128 words with somedisagreement, four annotators agreed and only onedisagreed.
Of those, 55 are items with ?no match?having been chosen from among the POS choices,due to one annotator?s definition of good-enoughmatch differing from all of the others?.
Theannotators have since reached agreement on whichcases are truly ?no match,?
and thus the rate of thisdisagreement should fall markedly in future POSfiles, raising the rate of overall agreement.5 Specifications for the Penn ArabicTreebank annotation guidelines5.1 Morphological analysis/Part-of-SpeechThe guidelines for the POS annotators arerelatively straightforward, since the task essentiallyinvolves choosing the correct analysis from the listof alternatives provided by the morphologicalanalyzer and adding the correct case ending.
Thedifficulties encountered by annotators in assigningPOS and case endings are somewhat discussedabove and will be reviewed by Tim Buckwalter ina separate presentation at COLING 2004.5.2 Syntactic analysisFor the most part, our syntactic/predicate-argument annotation of newswire Arabic followsthe bracketing guidelines for the Penn EnglishTreebank where possible.
(Bies, et al 1995)  Ourupdated Arabic Treebank Guidelines is availableon-line from the Linguistic Data Consortium at:http://www.ldc.upenn.edu/Catalog/docs/LDC2004T02/Some points where the Penn Arabic Treebankdiffers from the Penn English Treebank:?
Arabic subjects are analyzed as VPinternal, following the verb.?
Matrix clause (S) coordination ispossible and frequent.?
The function of NP objects of transitiveverbs is directly shown as NP-OBJ.We are also informed by on-going efforts toshare data and reconcile annotations with thePrague Arabic Dependency Treebank (two Prague-Penn Arabic Treebanking Workshops took place in2002 and 2003).
Some points where the PennArabic Treebank differs from the Prague ArabicDependency Treebank:?
Specific adverbial functions (LOC,TMP, etc.)
are shown on the adverbial(PP, ADVP, clausal) modification ofpredicates.?
The argument/adjunct distinction withinNP is shown for noun phrases andclauses.?
Empty categories (pro-drop subjects andtraces of syntactic movement) areinserted.?
Apposition is distinguished from othermodification of nouns only for propernames.In spite of the considerable differences in wordorder between Modern Standard Arabic andEnglish, we found that for the most part, it wasrelatively straightforward to adapt the guidelinesfor the Penn English Treebank to our ArabicTreebank.
In the interest of speed in startingannotation and of using existing tools to thegreatest extent possible, we chose to adapt as muchas possible from the English Treebank guidelines.There exists a long-standing, extensive, andhighly valued paradigm of traditional grammar inClassical Arabic.
We chose to adapt theconstituency approach from the Penn EnglishTreebank rather than keeping to a strict anddifficult adherence to a traditional Arabic grammarapproach for several reasons:?
Compatibility with existing treebanks,processing software and tools,?
We thought it would be easier and moreefficient to teach annotators, who cometrained in Arabic grammar, to use ourconstituency approach than to teachcomputational linguists an old andcomplex Arabic-specific syntacticterminology.Nonetheless, it was important to adhere to anapproach that did not strongly conflict with thetraditional approach, in order to ease the cognitiveload on our annotators, and also in order to betaken seriously by modern Arabic grammarians.Since there has been little work done on large datacorpora in Arabic under any of the currentsyntactic theories in spite of the theoreticalsyntactic work being done (Mohamed, 2000), wehave been working out solutions to Arabic syntaxby combining the Penn Treebank constituencyapproach with pertinent insights from traditionalgrammar as well as modern theoretical syntax.For example, we analyze the underlying basicsentence structure as verb-initial, following thetraditional grammar approach.
However, since theverb is actually not the first element in manysentences in the data, we adopt a topicalizationstructure for arguments that are fronted before theverb (as in Example 2, where the subject isfronted) and allow adverbials and conjunctions toappear freely before the verb (as in Example 3,where a prepositional phrase is pre-verbal).Example 2(S (NP-TPC-1 Huquwq+u  ???????
(NP Al+<inosAn+i  ???????????
))(VP ta+qaE+u     ??????
(NP-SBJ-1 *T*)(PP Dimona   ??????
(NP <ihotimAm+i+nA   ???????????
))))???????
???????????
??????
??????
??????????
?human rights exist within our concernExample 3(S (PP min  ???
(NP jih+ap+K   ?????
?>uxoraY  ??????
))(VP ka$af+at     ???????
(NP-SBJ maSAdir+u    ???????
?miSoriy~+ap+N    ??????????
?muT~aliE+ap+N  ???????????
))(NP-OBJ Haqiyqata  ?????????
(NP Al->amri  ???????
)))????????
????????
???????????
???????????
????????
??????
???
??????
?????
?from another side, well-informed Egyptiansources revealed the truth of the matterFor many structures, the traditional approach andthe treebank approach come together very easily.The traditional ?equational sentence,?
for example,is a sentence that consists of a subject and apredicate without an overt verb (kAna or ?to be?does not appear overtly in the present tense).
Thisis quite satisfactorily represented in the same waythat small clauses are shown in the Penn EnglishTreebank, as in Example 4, since traditionalgrammar does not have a verb here, and we do notwant to commit to the location of any potentialverb phrase in these sentences.Example 4(S (NP-SBJ Al-mas>alatu ???????????
)(ADJP-PRD basiyTatuN  ?????????))????????????
???????
?the question is simple5.3 Current issues and nagging problemsIn a number of structures, however, thetraditional grammar view does not line upimmediately with the structural view that isnecessary for annotation.
Often these arestructures that are known to be problematic in amore general sense for either traditional grammaror theoretical syntax, or both.
We take both viewsinto account and reconcile them in the best waythat we can.5.3.1 CliticsThe prevalence of cliticization in Arabicsentences of determiners, prepositions,conjunctions, and pronouns led to a necessarydifference in tokenization between the POS filesand the TB files.
Such cliticized constituents arewritten together with their host constituents in thetext (e.g., Al+<inosAn+i  ???????????
?the person?
and??????????
bi+qirA?ati ?with reading?).
Clitics thatplay a role in the syntactic structure are split offinto separate tokens (e.g., object pronounscliticized to verbs, subject pronouns cliticized tocomplementizers, cliticized prepositions, etc.
), sothat their syntactic roles can be annotated in thetree.
Clitics that do not affect the structure are notseparated (e.g., determiners).
Since the wordboundaries necessary to separate the clitics aretaken from the POS tags, and since it is notpossible to show the syntactic structure unless theclitics are separated, correct POS tagging isextremely important in order to be able to properlyseparate clitics prior to the syntactic annotation.In the example below, both the conjunction wa?and?
and the direct object hA ?it/them/her?
arecliticized to the verb and also serve syntacticfunctions independent of the verb (sententialcoordination and direct object).Example 5??????????
?wasatu$AhiduwnahAwa/CONJ+sa/FUT+tu/IV2MP+$Ahid/VERB_IMPERFECT+uwna/IVSUFF_SUBJ:MP_MOOD:I+hA/IVSUFF_DO:3FSand + will + you [masc.pl.]
+watch/observe/witness + it/them/herThe rest of the verbal inflections are alsoregarded as clitics in traditional grammar terms.However, for our purposes they do not requireindependent segmentation as they do not serveindependent syntactic functions.
The subjectinflection, for example, appears readily with fullnoun phrase subject in the sentence as well(although in this example, the subject is pro-dropped).
The direct object pronoun clitic, incontrast, is in complementary distribution with fullnoun phrase direct objects.
Topicalized directobjects can appear with resumptive pronouns in thepost-verbal direct object position.
However,resumptive pronouns in this structure should not beseen as problematic full noun phrases, as they areparasitic on the trace of movement ?
and in factthey are taken to be evidence of the topicalizationmovement, since resumptive pronouns arecommon in relative clauses and with othertopicalizations.Thus, we regard the cliticized object pronoun ascarrying the full syntactic function of direct object.As such, we segment it as a separate token andrepresent it as a noun phrase constituent that is asister to the verb (as shown in Example 6 below).Example 6(S wa-    -?
(VP sa+tu+$Ahid+uwna-   ????????????
(NP-SBJ *)(NP-OBJ ?hA      ??
)))??????????
?and you will observe her5.3.2 Gerunds (Masdar) and participialsThe question of the dual noun/verb nature ofgerunds and participles in Arabic is certainly noless complex than for English or other languages.We have chosen to follow the Penn EnglishTreebank practice to represent the more purelynominal masdar as noun phrases (NP) and themasdar that function more verbally as clauses (asS-NOM when in nominal positions).
In Example7, the masdar behaves like a noun in assigninggenitive case.Example 7(PP bi-  -??
(NP qirA?ati        ????????
(NP kitAbi       ??????
(NP Al-naHwi ???????
))))???????????
??????
?????
?with the reading of the book of syntax[book genitive]In Example 8, in contrast, the masdar functionsmore verbally, in assigning accusative case.Example 8(PP bi-     -??
(S-NOM (VP qirA?ati ????????
)(NP-SBJ fATimata ????????
-)(NP-OBJ Al-kitAba  ????????))))???????????
????????
??????
?with Fatma?s reading the book[book accusative]This annotation scheme to allow for both thenominal and verbal functions of masdar is easilyaccepted and applied by annotators for the mostpart.
However, there are situations where thefunctions and behaviors of the masdar are indisagreement.
For example, a masdar can take adeterminer ?Al-?
(the behavior of a noun) and atthe same time assign accusative case (the behaviorof a verb).Example 9(PP bi     -??
(S-NOM(VP Al+mukal~afi    ??????????
(NP-SBJ *)(NP-OBJ <injAza   ???????
(NP Al+qarAri ?????????Al+mawEuwdi??????????
)))))??????????????
???????
?????????
????????
?with the (person in) charge of completion (of)the promised report [completion accusative]In this type of construction, the annotators mustchoose which behaviors to give precedence(accusative case assignment trumps determiners,for example).
However, it also brings up the issuesand problems of assigning case ending and theannotators?
knowledge of Arabic grammar and therules of ?<iErAb.?
These examples are complexgrammatically, and finding the right answer (evenin strictly traditional grammar terms) is oftendifficult.This kind of ambiguity and decision-makingnecessarily slows annotation speed and reducesaccuracy.
We are continuing our discussions andinvestigations into the best solutions for suchissues.6 Future workAnnotation for the Arabic Treebank is on-going,currently on a corpus of An-Nahar newswire(350K words).
We continue efforts to improveannotation accuracy, consistency and speed, bothfor POS and TB annotation.ConclusionIn designing our annotation system for Arabic,we relied on traditional Arabic grammar, previousgrammatical theories of Modern Standard Arabicand modern approaches, and especially the PennTreebank approach to syntactic annotation, whichwe believe is generalizable to the development ofother languages.
We also benefited from theexistence at LDC of a rich experience in linguisticannotation.
We were innovative with respect totraditional grammar when necessary and when wewere sure that other syntactic approachesaccounted for the data.
Our goal is for the ArabicTreebank to be of high quality and to havecredibility with regards to the attitudes and respectfor correctness known to be present in the Arabicworld as well as with respect to the NLP and widerlinguistic communities.
The creation and use ofefficient tools such as an automated morphologicalanalyzer and an automated parsing engine ease andspeed the annotation process.
These tools helpedsignificantly in the successful creation of a processto analyze Arabic text grammatically and allowedthe ATB team to publish the first significantdatabase of morphologically and syntacticallyannotated Arabic news text in the world within oneyear.
Not only is this an important achievementfor Arabic for which we are proud, but it alsorepresents significant methodological progress intreebank annotation as our first data release wasrealized in significantly less time.
Half a millionMSA words will be treebanked by end of 2004,and our choice of MSA corpora will be diversifiedto be representative of the current MSA writingpractices in the Arab region and the world.
In spiteof the above, we are fully aware of the humblingnature of the task and we fully understand andrecognize that failures and errors may certainly befound in our work.
The devil is in the details, andwe remain committed to ironing out all mistakes.We count on the feedback of our users and readersto complete our work.8 AcknowledgementsWe gratefully acknowledge the tools and supportprovided to this project by Tim Buckwalter, DanBikel and Hubert Jin.
Our sincere thanks go to allof the annotators who have contributed theirinvaluable time and effort to Arabic part-of-speechand treebank annotation, and more especially toour dedicated treebank annotators, Wigdan ElMekki and Tasneem Ghandour.ReferencesElsaid Badawi, M. G. Carter and Adrian Gully,2004.
Modern Written Arabic: A ComprehensiveGrammar.
Routledge: New York.Daniel M. Bikel, 2002.
Design of a multi-lingual,parallel-processing statistical parsing engine.Proceedings of the Human LanguageTechnology Workshop.Bracketing Guidelines for Treebank II Style, 1995.Eds: Ann Bies, Mark Ferguson, Karen Katz,Robert MacIntyre, Penn Treebank Project,University of Pennsylvania, CIS TechnicalReport MS-CIS-95-06.Mohamed Maamouri and Christopher Cieri, 2002.Resources for Arabic Natural LanguageProcessing at the Linguistic Data Consortium.Proceedings of the International Symposium onProcessing of Arabic.
Facult?
des Lettres,University of Manouba, Tunisia.M.
Marcus, G. Kim, M. Marcinkiewicz, R.MacIntyre, A. Bies, M. Ferguson, K. Katz & B.Schasberger, 1994.
The Penn Treebank:Annotating predicate argument structure.Proceedings of the Human LanguageTechnology Workshop, San Francisco.M.
Marcus, B. Santorini and M.A.
Marcinkiewicz,1993.
Building a large annotated corpus ofEnglish: the Penn Treebank.
ComputationalLinguistics.Mohamed A. Mohamed, 2000.
Word Order,Agreement and Pronominalization in Standardand Palestinian Arabic.
CILT 181.
JohnBenjamins: Philadelphia.Zdenek ?abokrtsk?
and Otakar Smr?, 2003.
ArabicSyntactic Trees: from Constituency toDependency.
EACL 2003 Conferenceompanion.Association for Computational Linguistics,Hungary.
