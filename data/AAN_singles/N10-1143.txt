Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 993?1001,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEvaluating Hierarchical Discourse SegmentationLucien CarrollLinguistics Dept.UC San DiegoSan Diego, CA 92093lucien@ling.ucsd.eduAbstractHierarchical discourse segmentation is a use-ful technology, but it is difficult to eval-uate.
I propose an error measure basedon the word error rate of Beeferman et al(1999).
I then show that this new measurenot only reliably distinguishes baseline seg-mentations from lexically-informed hierarchi-cal segmentations and more informed segmen-tations from less informed segmentations, butit also offers an improvement over previouslinear error measures.1 IntroductionDiscourse segmentation is the task of identifying co-herent clusters of sentences and the points of transi-tion between those groupings.
Discourse segmenta-tion can be viewed as shallow parsing of discoursestructure.
The segments and the relations betweenthem are left unlabeled, focusing instead on theboundaries between the segments (i.e., the bracket-ing).Discourse segmentation is thought to facilitateautomatic summarization (Angheluta et al, 2002;Boguraev and Neff, 2000), information retrieval(Kaszkiel and Zobel, 1997), anaphora resolution(Walker, 1997) and question answering (Chai andJin, 2004).
Automatic discourse segmentation, asshallow annotation of discourse structure, also pro-vides a testing grounds for linguistic theories of dis-course (Passonneau and Litman, 1997) and providesa natural unit of measure in linguistic corpora (Biberet al, 2004).1.1 The structure of discourseResearch in discourse structure theory (Hobbs,1985; Grosz and Sidner, 1986; Mann and Thomp-son, 1988; Kehler, 2002; Asher and Lascarides,2003; Webber, 2004) and discourse parsing (Marcu,2000; Forbes et al, 2003; Polanyi et al, 2004;Baldridge et al, 2007) has variously defined dis-course structure in terms of communicative inten-tion, attention, topic/subtopic structure, coherencerelations, and cohesive devices.
There is much dis-agreement about the units and elementary relationsof discourse structure, but they agree that the struc-tures are hierarchical, most commonly trees (Marcu,2000), while others have argued for directed acyclicgraphs (Danlos, 2004), or general graphs (Wolf andGibson, 2004).
In contrast, most of the segmentationresearch to date has focused on linear segmentation,in which segments are non-overlapping and sequen-tial, and it has been argued that this sequence modelis sufficient for many purposes (Hearst, 1994).
I fo-cus here on tree discourse segmentation, in whichlarger segments are composed of sequences of sub-segments.
This is potentially more informative andmore faithful to linguistic theory than linear dis-course segmentation is, but it poses a more challeng-ing evaluation problem.1.2 Hierarchical segmentationFour studies have described hierarchical discoursesegmentation algorithms, but none of them rigor-ously evaluated the segmentation in its hierarchi-cal form.
Yaari (1997) used a hierarchical cluster-ing algorithm for hierarchical discourse segmenta-tion, and to evaluate it, he linearized the tree (tak-ing all boundaries equally) and compared the result-993ing precision and recall to contemporary linear seg-mentation algorithms.
Slaney and Ponceleon (2001)used scale-space segmentation (an image segmen-tation algorithm) on the discourse?s trajectory in aLatent Semantic Indexing (LSI) space (Landauer etal., 1998).
They evaluated the algorithm by visualcomparison with the heading-subheading structureof the text.
Angheluta et al (2002) applied a lineardiscourse segmentation algorithm recursively, seg-menting each major segment into a sequence of sub-segments.
They used the result in a summariza-tion system, and they evaluated the summarizationsystem but not the segmentation itself.
Eisenstein(2009) used a Bayesian latent topic model to finda hierarchical segmentation, and he comes the clos-est to quantitative evaluation of the whole segmen-tation.
He evaluated it against three recursive seg-mentation algorithms on a corpus that had just twolevels of segment depth and considers these two lev-els as separate and equally important.
While each ofthese studies offers some insight into the validity ofthe hierarchical segmentation, none of these evalua-tion methods directly and quantitatively assesses thehierarchical segmentation as a whole.Many state-of-the-art linear discourse segmenta-tion algorithms also use hierarchical frameworks,making them applicable to hierarchical discoursesegmentation with only trivial modification.
For ex-ample, the C99 algorithm (Choi, 2000) applies con-trast enhancement and divisive clustering to a ma-trix of lexical vector cosine similarities.
The CWMalgorithm (Choi et al, 2001) applies the same pro-cedure to a similarity matrix of LSI vectors.
Usingthese algorithms for hierarchical discourse segmen-tation simply requires keeping record of the bound-ary ranking, but until now they have only been usedfor linear segmentation.1.3 The Beeferman error measureStudies of linear discourse segmentation have re-vealed that discourse boundaries are inherentlyfuzzy.
Human annotators demonstrate frequent dis-agreement about the number of segments and ex-actly where the transitions between segments oc-cur, while still demonstrating statistically significantagreement (Passonneau and Litman, 1997).
Becauseof this, conventional precision and recall measurespenalize ?near misses?
when they should be treatedmuch the same as complete matches.
The crossing-bracket measure (Carbone et al, 2004) is more for-giving, but still over-penalizes near misses and fa-vors sparse bracketings.
An error measure Pk pro-posed by Beeferman et al (1999) compensates forthe variation in boundary locations.
It considers amoving window of width k equal to half the aver-age segment length in the reference segmentation,where distances are measured in words or sentences,depending on whether word boundaries or sentenceboundaries are considered possible discourse seg-ment boundaries.
The error is the average disagree-ment, between the reference segmentation and theevaluated segmentation, about whether the two endsof the window are in the same segment.
Formally,Pk =1N?
kN?k?i=1?
(?
(ri,ri+k),?
(hi,hi+k))where N is the total number of atoms (words or sen-tences) in the document, and k is the window width.The arguments ri and hi are the indices of the seg-ments that contain atom i in the reference and hy-pothesized segmentations, respectively, and ?
is thediscrete delta function, evaluating to 1 if its argu-ments are equal and to 0 otherwise.
Pevzner andHearst (2001) proposed WindowDiff, a modificationof Pk that indicates the average disagreement abouthow many boundaries lie within the window, replac-ing the inner ?
functions with the count of segmentboundaries between the two atoms.
It is as sensitiveto false positives as it is to false negatives, whereasPk is more sensitive to false negatives.There are still a few problems with these er-ror measures.
In penalizing false negatives andfalse positives equally, WindowDiff actually favorssparse segmentations.
Whereas Pk scores the base-line strategies of no boundaries and all possibleboundaries as within a few percent of 50% error,WindowDiff scores the all-boundaries baseline at100% error for typical reference segmentations.
Fur-thermore, in running the summation from i = 1 toi=N?k, both error measures count boundaries nearthe edges of the text less than boundaries near themiddle of the text.
A boundary that is j < k atomsfrom the beginning or end of the text has weight jkrelative to boundaries in the middle of the text.
Fi-nally, because of the hierarchical structure of many994texts, it is quite possible that a reference segmen-tation might not include legitimate but fairly unim-portant boundaries that a hypothesized segmentationdoes include.
These unimportant boundaries shouldnot count against the hypothesized segmentation,but in the linear segmentation paradigm, they nec-essarily do.
The ideal error measure should distin-guish more-informed algorithms from less-informedalgorithms, treating equally uninformed baselinesthe same, and it should treat boundary placement er-rors according to the prominence of the boundaries,and not according to their positions within the text.Building on work in evaluating linear segmenta-tion, this study considers the evaluation of tree seg-mentations.
I propose an error measure, derivedfrom Beeferman et al?s Pk (1999), for evaluating thealignment of a tree segmentation to a reference seg-mentation.
I first show that this error measure is ad-vantageous even for evaluating linear segmentations,and then I evaluate four hierarchical segmentationalgorithms against a gold standard derived from en-cyclopedia articles.2 A hierarchical measureThe proposed error measure is based on the intu-ition that prominent boundaries count more than lessprominent boundaries.
The hierarchical atom errorrate EPk is the mean of Beeferman errors calculatedover all linearizations of the segmentation tree (seeFig.
1).
Assume a set R of reference boundaries anda set H of hypothesized boundaries each in rank or-der (prominent boundaries precede less prominentFigure 1: Sequential linearizations in computing hierar-chical word error rate.
The heights of the vertical linesrepresent the prominences of boundaries, and each hori-zontal line is one linearization.
In the first step, only thehighest boundary is used, producing just two segments.Each following step includes one more boundary.ones).
The error is calculated asEPk =1|R|?iciPk(Ri,Hi)whereRi = {b j : b j ?
R?
j ?
i}The elements of Hi are chosen such that |Hi| = |Ri|and no bn ?
H \ Hi is more prominent than anyb j ?
Hi.
If the reference boundaries are completelyordered, then ci = 1 for all ranks i, but if some ref-erence boundaries share ranks, one Pk term is calcu-lated for each rank level in the reference segmenta-tion, and weighted (ci) by the number of boundariesthat were at that level.
In the degenerate case of lin-ear segmentation, all segments have the same rank,and EPk reduces to the original Pk.When hypothesized boundaries share ranks, eachaffected term in the summation is theoretically theaverage over all combinations (n boundaries at thenext rank Choose r boundaries to complete Hi).
Butwhen the number of combinations is large, the com-putational complexity of the calculation can be re-duced without sacrificing much accuracy by using arepresentative sampling of the combinations, as thisclosely approximates the average.When the set of hypothesized boundaries issmaller than the set of reference boundaries, wecould simply permit Hi to be smaller than Ri forlarge values of i, but that unnecessarily penalizesthe hypothesized segmentation.
The set of possi-ble boundaries (word or sentence boundaries) whichwere not marked as segment boundaries can be un-derstood to be segment boundaries of a baseline lowranking.
Adding these unmarked boundaries to H,all at a single low rank, prevents incurring an unde-served penalty for false negatives.In order to avoid undercounting boundaries nearthe beginning and end of the text, I consider the pos-sibility of wrapping the window around from the be-ginning to the end of the text.
In calculating Pk, thesum is understood to run from i = 1 to i = N, ratherthan stopping at N ?
k, and the atom index of theleading edge of the window (i+ k) generalizes to((i+ k) mod N).3 Hierarchical replication of Choi et alAs a preliminary test of the error measure, I eval-uated two algorithms from Choi et al (2001) on995the standard segmentation data set that Choi (2000)compiled.
Each file in that data is composed of10 random portions of texts from the Brown Cor-pus (Francis and Kucera, 1979).
The following re-sults are based on the T3?11 subset, in which textsegment lengths are uniformly distributed between3 and 11 sentences.
Since each file is composed ofa sequence of text portions, the reference segmenta-tion is linear, not hierarchical.
Nevertheless, I evalu-ate hierarchical segmentation algorithms with the hi-erarchical measure, to show that treating linear seg-mentation as a special case of hierarchical segmen-tation solves the issue of unequal treatment of falsepositives and false negatives, and running the Win-dowDiff sum to N (wrapping the window around tothe beginning) solves the problem of undercountingthe boundaries near the text edges.3.1 Segmentation algorithmsThe C99 (Choi, 2000) and CWM (Choi et al, 2001)algorithms were evaluated.
While these were de-signed and originally evaluated as linear segmenta-tion algorithms, the hierarchical clustering they usemakes hierarchical segmentation a trivial matter ofretaining the order of the cluster splits.
I refer to thehierarchical versions of these algorithms as HC99and HCWM.
The HC99 implementation used here isbuilt directly from the C99 code which Choi releasedfor educational use, and the HCWM implementa-tion is based off that.
The implementation usesa document-based LSI space built with Infomap-NLP1 from the British National Corpus (Aston andBurnard, 1998), whereas the original CWM usedsentence-based and paragraph-based LSI spaces de-rived from the Brown Corpus.
Because of thesedifferences, the implementation of HCWM reportedhere differs somewhat from the implementation ofCWM reported by Choi et al (2001).The C99 and CWM algorithms include a criterionfor optional automatic determination of the numberof segments, but the hierarchical error measure doesnot penalize a segmentation for having more seg-ments (defined by lower ranking boundaries) thanthe reference segmentation, so I used a constantnumber of segments, greater than in the referencesegmentation, for the results reported here.1Software available at http://infomap-nlp.sourceforge.netOne baseline (BIN) was constructed by a recur-sive bisection of segments, and another baseline(NONE) consisted of only the implicit boundariesat the beginning and end of the discourse, and all thepossible intermediate boundaries (sentence breaks)are implicitly at one unmarked lower rank.3.2 Results and DiscussionThe calculated EPk error rates are displayed inFig.
2.2 The error for HC99 in Fig.
2a (12.5%)matches what Choi et al (2001) reported (12%),while the error for HCWM (12.1%) is higher thanthat reported for the version with a paragraph-based500-dimension LSI space (9%) but appears com-parable to their sentence-based 400-dimension LSIspace.
(They do not report results for the sentence-based spaces on this T3?11 data set, but based on theresults they report for a larger data set, it would ap-pear to be about 12% for the T3?11 set.)
The resultfor BIN (43.9%) is slightly lower than what Choi etal.
(2001) reported for their equal-size segment base-line (45%).
Since BIN would be an equal-segmentbaseline if there were only 8 segments per text, BINshould be similar to Choi et als equal-size baseline.And the result for NONE (46.1%) agrees with Choiet al (2001)?s results for their NONE (46%) base-line.Comparison of graphs (a) and (b) in Fig.
2 showsthat continuing the sum to wrap the window aroundto the beginning of the text generally lowers themeasured error, to the greatest extent for BIN andleast for HCWM.
The average segment length in thereference segmentation is 7 sentences, so the win-dow size k is usually 3 or 4 sentences, comparableto the minimum segment length (3).
As a result,a boundary very rarely falls within k sentences ofthe text ends, and fully including these sentences inthe sum leads to a lower error for segmentations likeBIN that don?t hypothesize boundaries near the textends.The EWD hierarchical error rates (calculated ac-cording to WindowDiff) are consistently higher(Fig.
2c, d) than the corresponding EPk .
WindowDiff2The error rates in this section are calculated using the word-error rate for comparison with Choi?s results, but since the can-didate boundaries are actually the line breaks, the line-error ratewould be more appropriate.
Line error rates are 1% to 2%higher.996(a)ll ll lHC99HCWM BIN NONE0.00.20.40.60.8?=12.5?0.9%?=12.1?0.9%?=43.9?0.9%?=46.1?0.2%(b)ll lll lHC99HCWM BIN NONE0.00.20.40.60.8?=12.1?0.8%?=12.1?0.9%?=42.1?0.9%?=45.5?0.2%(c)l ll lHC99HCWM BIN NONE0.00.20.40.60.8?=13.8?0.9%?=14.1?1.0%?=45.0?0.9%?=49.9?0.1%(d)ll lllHC99HCWM BIN NONE0.00.20.40.60.8?=13.3?0.9%?=13.9?1.0%?=43.1?0.8%?=49.1?0.1%Figure 2: Distributions of EPk (a, b) and EWD (c, d) for each of the hypothesized and baseline segmentation algorithms.The data in graphs (a) and (c) are calculated with sums that stop at N?
k (when the window reaches the end of thetext), whereas (b) and (d) are calculated with sums that run to N (wrapping the window back to the beginning).
Theboxes indicate the quartiles, and the means with 95% confidence intervals are written above.scores are never lower than Pk scores, because in or-der to count as in agreement, the two segmentationsmust agree about the number of boundaries withinthe window rather than just about whether there areboundaries within the window.
But these scores arenot much higher than EPk either, even though theoriginal linear WindowDiff measure sometimes as-signs much higher scores.
Under the original Win-dowDiff measure, with reference and hypothesizedboundary sets of unequal size, the NONE baselinescores 43.8% (cf.
Pk=43.5% for sum to N), whilean ALL baseline scores 99.2% (cf.
Pk=51.1% forsum to N).
WindowDiff was designed to penalizefalse positives even when two boundaries are closetogether, a condition that Pk underpenalizes.
When ahypothesized segmentation has more segments thanthe reference segmentation, the extra boundaries in-cur false positive penalties without correspondingfalse negative penalties, and WindowDiff assigns anerror rate that is higher than the Pk error rate andsometimes even higher than the NONE baseline.But with the hierarchical EWD error, extra bound-aries are sampled or ignored, and so every false pos-itive has a corresponding false negative, which limitsthe divergence between EWD and EPk and keeps theEWD error of informed segmentations below base-line errors.
As with EPk , continuing the sum to N(Fig.
2d), has only a slight effect on the error, butthe effect is most pronounced on BIN, reflecting thefact that BIN, like the reference segmentation sys-tematically does not place boundaries near the textends.3.3 ConclusionWe have seen here that treating linear segmentationsas a special case of hierarchical segmentations, hav-ing just one rank of marked boundaries but havingimplicit higher ranking boundaries at the text endsand implicit lower ranking boundaries at all ?non-boundaries?, resolves the outstanding issues of un-equal sensitivity that Pk and WindowDiff have.
Fur-thermore, in sampling hypothesized boundaries tomatch the number of reference boundaries, the hi-erarchical conception of the error metric smoothlyadapts to segmentations that overestimate or under-estimate the number of segments.
A segmentation997can not do much worse than 50% (at chance) justby hypothesizing fewer or more segments than thereference segmentation ?knows?
about.
The majorremaining strength of WindowDiff over the Pk met-ric is that Pk still undercounts errors when there aresegments much smaller than the average size.For these reasons, I adopt a version of EWD thatcontinues the sum to wrap the window around theend of the text.
In addition, when I refer to the lin-ear error measure in the following sections, I meanthe special case of EWD in which the information inthe reference segmentation about the ranking of themarked boundaries is ignored, but boundary rankinginformation in the hypothesized segmentation (bothmarked and unmarked boundaries) is still used to se-lect as many segment boundaries as are in the refer-ence segmentation.4 Wikipedia EvaluationIn this section, I compare the same two algorithmsand baselines with two additional hierarchical seg-mentation algorithms, using a hierarchical referencesegmentation.
The reference segmentation corpus isderived from encyclopedia articles, and I use the hi-erarchical error measure developed in the previoussections.
I also constrast the hierarchical error rateswith measurements that ignore the boundary rankinginformation in the hypothesized or reference seg-mentations in order to highlight the difference be-tween the performance on boundary position and theperformance on boundary ranking.4.1 Corpus and AlgorithmsThe evaluation corpus is derived from the 2006Wikipedia CD release.3 The html pages were con-verted to flat text, removing boilerplate, naviga-tion, info-boxes, and image captions.
Heading textwas replaced with a boundary marker, indicating theheading depth.
The subcorpus used for this evalua-tion consists of articles with a heading depth of four(i.e.
having html elements h2 through h5), a total of66 articles.
The texts were reformatted with an au-tomatic sentence detector4 to have one sentence per3Available from http://schools-wikipedia.org/2006/.4From Ratnaparkhi?s ?jmx?
(ftp://ftp.cis.upenn.edu/pub/adwait/jmx/jmx.tar.gz).line, and then tokenized.5In addition to the HC99 and HCWM algorithmsused in the previous section, I use two algorithmsdescribed by Eisenstein (2009).
The HIERBAYESalgorithm (here, HBT) uses a multi-level latent topicmodel to perform joint inference over the locationsand prominences of topic change boundaries.
TheGREEDY-BAYES algorithm (here, GBEM) uses asingle-level latent topic model to find a linear seg-mentation, and recursively divides each of the seg-ments.6 Both algorithms internally decide the num-ber of hypothesized boundaries, sometimes underes-timating it and sometimes overestimating.74.2 Results and DiscussionThe EWD error rates for each of the hypothesizedsegmentations are presented in Fig.
3.
As with theChoi data, the NONE baseline has an error rateat chance (50%), while the lexical algorithms per-form better than that (highly statistically signifi-cantly (p < .0001) less than 50%, according to indi-vidual two-sided one-sample t-tests).
However, theyperform much worse than they did on the Choi data.In spite of the relatively high error rates, the dis-criminating power of the evaluation measure is re-vealed by comparison of the fully hierarchical er-ror rates (Fig.
3a) with the error rates that ignorethe ranking information in the reference (Fig.
3b) orhypothesized (Fig.
3c) segmentations.
For each ofthe lexical algorithms that were originally designedas linear segmentation algorithms (HC99, HCWM,and GBEM), the mean error is less in Fig.
3bagainst the linear standard (when reference segmen-tation boundary prominences are ignored) than inFig.
3a under the fully hierarchical measure (two-tailed paired t-tests, each p < .0001).
In contrast,HBT, designed as a hierarchical segmentation algo-rithm, obtains a lower error rate under the fully hier-archical EWD measure (though the difference does5The evaluation code and corpus can be downloaded fromhttp://idiom.ucsd.edu/?lucien/segmentation6Both algorithms are part of the HBayesSeg pack-age, available at http://people.csail.mit.edu/jacobe/naacl09.html7Options for HBT were set to produce 3 levels of text-internal boundary prominence.
Attempts to obtain more bound-aries and more depth levels lead to deteriorated performance,because the search space grows geometrically with the numberof levels (Eisenstein, p.c.
)998(a)llllllHC99HCWM HBT GBEM BIN NONE0.00.20.40.60.8?=45.1?1.4%?=43.9?1.5%?=41.0?1.5%?=40.6?1.1%?=51.4?0.9%?=49.8?0.3%(b)lllllHC99HCWM HBT GBEM BIN NONE0.00.20.40.60.8?=42.5?1.7%?=42.1?1.8%?=41.9?1.5%?=38.4?1.5%?=50.0?1.0%?=50.0?0.5%(c)lllHC99HCWM HBT GBEM BIN NONE0.00.20.40.60.8?=49.0?0.4%?=49.0?0.5%?=42.3?1.3%?=41.2?1.0%?=50.0?0.3%?=49.9?0.3%Figure 3: EWD error rates for each of the segmentation algorithms.
(a) Hierarchical error (b) Linear error (ignoringreference segmentation prominences) (c) Hierarchical error ignoring hypothesized segmentation prominences.
Boxesshow quantiles and means are written above, with 95% confidence intervals.not reach significance: p = 0.1, two-tailed pairedt-test).
When instead the hypothesized boundaryprominences are ignored (Fig.
3c), reducing themto linear segmentations but still evaluating againstthe hierarchical standard, the error rates of all thelexical algorithms are raised (in two-tailed paired t-tests, each p < .0001), but HBT and GBEM are onlyslightly affected, whereas HC99 and HCWM are al-most raised to chance.
While HBT and GBEM hy-pothesize about the same number of boundaries asthe reference segmentation (13 and 22 text-internalboundaries on average, compared to 22 text-internalboundaries in the reference corpus), the HC99 andHCWM algorithms were made to hypothesize 54boundaries for each text.
The difference betweentheir error rates in (Fig.
3a) and (Fig.
3c) shows thatthe HC99 and HCWM boundaries given the highestprominences corresponded much more closely to thereference boundaries than the hypothesized bound-aries given the lowest prominences.The mean scores for the BIN baseline are over50% on the encyclopedia data.
In contrast, the meanscore for BIN on the Choi standard data (Fig.
2)was 45% for the linear measure and 43% for thehierarchical measure.
Why did BIN do so poorlyhere when it performed well above chance on theChoi data?
The difference is in the distributions ofsegment lengths.
As seen in Fig.
4, the Choi datasegment lengths are well-defined by their mean, be-cause they were constructed with uniform distribu-tions of segment length.
On the other hand, the dis-tribution of segment lengths in the encyclopedia datais more skewed, with many quite short segments anda few quite long segments.The error rates for both HC99 and HCWM aremuch higher on the encyclopedia data than theyare on the Choi data, and the error rates for HBTand GBEM are not much better.
Choi?s evalua-tion corpus was specifically designed to have obvi-ous boundaries, whereas the boundaries in these dis-course samples are much less obvious.
As discussedby Kauchak and Chen (2005), even algorithms thatobtain low error rates on newsfeed do not performwell on more fluid discourse, and while Ji and Zha(2003) reported quite low error on an expository textsample (Pk = 12%), Kauchak and Chen (2005) re-port a best error rate of Pk = 38.5% on the encyclo-pedia corpus they used, and Malioutov and Barzi-999(a)Ratio of Segment Lengths to MeanFrequency0 1 2 3 4 5 6 70200400(b)Ratio of Segment Lengths to MeanFrequency0 1 2 3 4 5 6 7050150Figure 4: Distribution of sentences per segment for (a) Choi standard data (b) Wikipedia datalay (2006) obtained Pk error rates between 30% and40% on the lecture data they used, comparable tohuman annotator pairwise Pk ranging from 24% to42%.
C99 and CWM?like the other algorithmsthat make use of hierarchical representations of thetext, such as Ji and Zha (2003) and Fragkou et al(2004)?depend completely on lexical information.Another strand of research, including Galley et al(2003) and Kauchak and Chen (2005), make use ofa wide variety of linguistic and orthographic cues.And the discourse parsing systems take advantageof even more linguistic cues.
The ideal segmenta-tion algorithm needs to combine the advantages ofeach of these approaches, but the frameworks are notstraightforwardly compatible.
The Bayesian frame-work explored by Eisenstein and Barzilay (2008) isa potential route to a richer model, and they foundtheir richer model beneficial for a meetings corpusbut not for a textbook.
The HBT and GBEM al-gorithms, which were based on that work, do notattempt to go beyond lexical cohesion, but it doesprovide a framework for hierarchical segmentationalgorithms that take advantage of other cues.5 ConclusionsIn Section 2, I introduced a modification of the er-ror measure developed by Beeferman et al (1999)and Pevzner and Hearst (2001).
I then showed thatthis modification, directed at evaluating hierarchicalsegmentations, also produces a more robust evalu-ation of linear segmentations as well.
And appliedto hierarchical segmentations, it successfully dis-tinguishes lexically-informed segmentations frombaseline segmentations, and it distinguishes hierar-chical segmentations from segmentations composedof the same boundaries but without the boundaryranking information.
As a more reliable evaluationof both linear and hierarchical segmentation algo-rithms, this error measure will facilitate the devel-opment of more richly informed segmentation algo-rithms.AcknowledgmentsIn this research, I have benefited from resources atboth San Diego State University and UC San Diego.This work has been enriched by the questions andadvice of many people, including Eniko Csomay,Rob Malouf, Lara Taylor, Rebecca Colavin, AndyKehler, and the NAACL anonymous reviewers.
Iam also grateful to Freddy Choi and Jacob Eisen-stein for making their code and data available, andto Jacob for additional help running his code.
Allerrors are my own.ReferencesRoxana Angheluta, Rik De Busser, and Marie-FrancineMoens.
2002.
The use of topic segmentation for auto-matic summarization.
In DUC 2002.Nicholas Asher and Alex Lascarides.
2003.
Logics ofConversation.
Cambridge University Press.Guy Aston and Lou Burnard.
1998.
The BNC Hand-book: Exploring the British National Corpus withSARA.
Edinburgh University Press.Jason Baldridge, Nicholas Asher, and Julie Hunter.
2007.Annotation for and robust parsing of discourse struc-ture of unrestricted texts.
Zeitschrift fu?r Sprachwis-senschaft, 26(213):239.1000Doug Beeferman, Adam Berger, and John D. Lafferty.1999.
Statistical models for text segmentation.
Ma-chine Learning, 34(1-3):177?210.Douglas Biber, Eniko Csomay, James K. Jones, andCasey Keck.
2004.
A corpus linguistic investigationof vocabulary-based discourse units in university reg-isters.
Language and Computers, 20:53?72.Branimir Boguraev and Mary S. Neff.
2000.
Discoursesegmentation in aid of document summarization.
In33rd HICSS.Marco Carbone, Ya?akov Gal, Stuart Shieber, and Bar-bara Grosz.
2004.
Unifying annotated discourse hi-erarchies to create a gold standard.
In Proceedings of4th SIGDIAL Workshop on Discourse and Dialogue.Joyce Y. Chai and Rong Jin.
2004.
Discourse struc-ture for context question answering.
In HLT-NAACL2004 Workshop on Pragmatics of Question Answering,pages 23?30.Freddy Choi, Peter Wiemer-Hastings, and JohannaMoore.
2001.
Latent semantic analysis for text seg-mentation.
In Proceedings of 6th EMNLP, pages 109?117.Freddy Choi.
2000.
Advances in domain independentlinear text segmentation.
In Proceedings of NAACL-00, pages 26?33.Laurence Danlos.
2004.
Discourse dependency struc-tures as constrained DAGs.
In Proceedings of 5th SIG-DIAL Workshop on Discourse and Dialogue, pages127?135.Jacob Eisenstein and Regina Barzilay.
2008.
Bayesianunsupervised topic segmentation.
In Proceedings ofEMNLP 2008.Jacob Eisenstein.
2009.
Hierarchical text segmentationfrom multi-scale lexical cohesion.
In Proceedings ofNAACL09.Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad,Anoop Sarkar, Aravind Joshi, and Bonnie Webber.2003.
D-LTAG system: Discourse parsing with a lex-icalized tree-adjoining grammar.
Journal of Logic,Language and Information, 12(3):261?279, June.P.
Fragkou, V. Petridis, and Ath.
Kehagias.
2004.
A dy-namic programming algorithm for linear text segmen-tation.
Journal of Int Info Systems, 23:179?197.W.
Nelson Francis and Henry Kucera.
1979.
BROWNCorpus Manual.
Brown University, third edition.Michael Galley, Kathleen McKeown, Eric Fossler-Lussier, and Hongyan Jing.
2003.
Discourse segmen-tation of multi-party conversation.
In 41st ACL.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Com-putational Linguistics, 12(3):175?204.Marti Hearst.
1994.
Multi-paragraph segmentation ofexpository text.
In 32nd ACL, pages 9 ?
16, New Mex-ico State University, Las Cruces, New Mexico.Jerry R Hobbs.
1985.
On the coherence and structure ofdiscourse.
In CSLI 85-37.Xiang Ji and Hongyuan Zha.
2003.
Domain-independenttext segmentation using anisotropic diffusion and dy-namic programming.
In SIGIR?03.Marcin Kaszkiel and Justin Zobel.
1997.
Passage re-trieval revisited.
In Proceedings of 20th ACM SIGIR,pages 178?185.David Kauchak and Francine Chen.
2005.
Feature-basedsegmentation of narrative documents.
In Proceedingsof the ACL Workshop on Feature Engineering for Ma-chine Learning in NLP.Andrew Kehler.
2002.
Coherence, reference and the the-ory of grammar.
CSLI Publications.Thomas K. Landauer, Peter W. Foltz, and Darrell La-ham.
1998.
An introduction to latent semantic analy-sis.
Discourse Processes, 25:259?284.Igor Malioutov and Regina Barzilay.
2006.
Minimumcut model for spoken lecture segmentation.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and 44th Annual Meeting of theACL, pages 25?32.William Mann and Sandra Thompson.
1988.
Rhetoricalstructure theory: Towards a functional theory of textorganization.
Text, 8(3):243?281.Daniel Marcu.
2000.
The theory and practice of dis-course parsing and summarization.
MIT Press.Rebecca J. Passonneau and Diane J. Litman.
1997.
Dis-course segmentation by human and automated means.Computational Linguistics, 23(1):103?139.Lev Pevzner and Marti Hearst.
2001.
A critique andimprovement of an evaluation metric for text segmen-tation.
Computational Linguistics, 16(1).Livia Polanyi, Chris Culy, Martin van den Berg,Gian Lorenzo Thione, and David Ahn.
2004.
A rulebased approach to discourse parsing.
In Proceedingsof SIGDIAL.Malcolm Slaney and Dulce Ponceleon.
2001.
Hierar-chical segmentation: Finding changes in a text sig-nal.
Proceedings of SIAM 2001 Text Mining Work-shop, pages 6?13.Marilyn A. Walker.
1997.
Centering, anaphora resolu-tion, and discourse structure.
In Aravind K. Joshi Mar-ilyn A. Walker and Ellen F. Prince, editors, Centeringin Discourse.
Oxford University Press.Bonnie Webber.
2004.
D-LTAG: extending lexicalizedTAG to discourse.
Cognitive Science, 28:751?779.Florian Wolf and Edward Gibson.
2004.
Representingdiscourse coherence: A corpus-based analysis.
In 20thCOLING.Yaakov Yaari.
1997.
Segmentation of expository texts byhierarchical agglomerative clustering.
In Proceedingsof RANLP?97.1001
