Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1478?1488, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsUser Demographics and Language in an Implicit Social NetworkKatja FilippovaGoogle Inc.Brandschenkestr.
110Zu?rich, 8004 Switzerlandkatjaf@google.comAbstractWe consider the task of predicting the genderof the YouTube1 users and contrast two infor-mation sources: the comments they leave andthe social environment induced from the af-filiation graph of users and videos.
We prop-agate gender information through the videosand show that a user?s gender can be predictedfrom her social environment with the accuracyabove 90%.
We also show that the gender canbe predicted from language alone (89%).
Asurprising result of our study is that the latterpredictions correlate more strongly with thegender predominant in the user?s environmentthan with the sex of the person as reported inthe profile.
We also investigate how the twoviews (linguistic and social) can be combinedand analyse how prediction accuracy changesover different age groups.1 IntroductionOver the past decade the web has become more andmore social.
The number of people having an iden-tity on one of the Internet social networks (Face-book2, Google+3, Twitter4, etc.)
has been steadilygrowing, many users communicate online on a dailybasis.
Their interactions open new possibilities forsocial sciences, and linguistics is no exception.
Forexample, with the development and growth of Web2.0, it has become possible to get access to massesof text data labeled with respect to different social1www.youtube.com2www.facebook.com3www.plus.google.com4www.twitter.comparameters such as country, age, gender, professionor religion.
The study of language varieties betweengroups separated by a certain social variable belongsto the field of sociolinguistics which more generallyinvestigates the effect of society on how language isused (Coulmas, 1998).
Historically, sociolinguisticsis connected to dialectology whose focus has beenprimarily on the phonetic aspect of the regional di-alects but was later extended to sociolects (Cham-bers & Trudgill, 1998).
A usual study would involvesampling speakers from a population, interviewingthem and analyzing the linguistic items with respectto social variables (Hudson, 1980).The last decade has seen several studies inves-tigating the relationship between the language andthe demographics of the users of blogs or Twitter(see Sec.
2 for references).
Most of those studiesused social network sites to collect labeled data?samples of text together with the demographics vari-able.
However, they did not analyse how social en-vironment affects language, although very similarquestions have been recently posed (but not yet an-swered) by Ellist (2009).
In our work we attempt toaddress precisely this issue.
In particular, we con-sider the task of user gender prediction on YouTubeand contrast two information sources: (1) the com-ments written by the user and (2) her social neigh-borhood as defined by the bipartite user-video graph.We use the comments to train a gender classifier ona variety of linguistic features.
We also introduce asimple gender propagation procedure to predict per-son?s gender from the user-video graph.In what follows we will argue that although lan-guage does provide us with signals indicative of the1478user?s gender5 (as reported in the user?s profile), itis in fact more indicative of a socially defined gen-der.
Leaving aside the debate on the intricate rela-tionship between language and gender (see Eckert &McConnell-Ginet (2003) for a thorough discussionof the subject), we simply demonstrate that a classi-fier trained to predict the predominant gender in theuser?s social environment, as approximated by theYouTube graph of users and videos, achieves higheraccuracy for both genders than the one trained topredict the user?s inborn gender.
We also investi-gate ways of how the language-based and the so-cial views can be combined to improve predictionaccuracy.
Finally, we look at three age groups ?teenagers, people in their twenties and people overthirty ?
and show that gender identity is more evi-dent in the language of younger people but also thatthere is a higher correlation between their inborngender and the predominant gender in their socialenvironment.The paper is organized as follows: we first re-view related work on the language of social mediaand user demographics (Sec.
2) and elaborate on thegoals of our research (Sec.
3).
Then we describeour data (Sec.
4), introduce the demographics prop-agation experiments (Sec.
5) and the experiments onsupervised learning gender from language (Sec.
6).2 Related workPrevious studies on language and demographicswhich looked at online data can be distinguishedwith respect to their aims.
(1) Studies coming fromthe sociolinguistic community aim at empiricallyconfirming hypotheses, such as that female speakersuse more pronouns, or that males tend to use longerwords.
(2) A standard goal of an NLP study is tobuild an automatic system which accurately solvesa given task which in the case of demographics ispredicting user age, gender or country of origin.
Inthis section we start by reviewing the first kind ofstudies, which are about data analysis and hypothe-ses checking.
These are relevant for our choice offeatures.
Then we briefly summarize a selection of5Although it might be more correct to talk about the user?ssex in place of gender (Eckert & McConnell-Ginet, 2003), westick to the terminology adopted in previous NLP research ongender prediction.studies on demographics prediction to better situateand motivate our approach.2.1 Language and demographics analysisPrevious sociolinguistic studies mostly checked hy-potheses formulated before the widespread use ofthe Internet, such as that women use hedges moreoften (Lakoff, 1973) or that men use more negations(Mulac et al 2000), or looked at specific words orword classes.
Newman et al(2008) provide a com-prehensive review of such work and a description ofthe non-web corpora used therein.
Some of thosehypotheses were confirmed by empirical evidence,some not.For example, Herring & Paolillo (2006) analysegender- and genre-specific use of language in on-line communication on a sample of about 130 blogentries.
Looking at a number of stylistic featureswhich had previously been claimed to be predic-tive of gender (Argamon et al 2003; Koppel et al2004), such as personal pronouns, determiners andother function words, they find no gender effect.
Un-like them, Kapidzic & Herring (2011) analyse re-cent chat communications and find that they are gen-dered.
Similarly, Huffaker & Calvert (2005) inves-tigate the question of identity of teenager bloggers(e.g., age, gender, sexuality) and find language fea-tures indicative of gender (e.g., use of emoticons bymales).
Burger & Henderson (2006) consider therelationship between different linguistic (e.g., textlength, use of capital and punctuation letters) andnon-linguistic (e.g., interests, mood) features andblogger?s age and location.
They find that many fea-tures correlate with the age and run an experimentwith the goal of predicting whether the blog authoris over 18.2.2 Demographics prediction from languageThe studies we review here used supervised ma-chine learning to obtain models for predicting gen-der or age.
Other demographic attributes, like lo-cation, ethnicity, or educational level, have alsobeen predicted automatically (Gillick, 2010; Rao &Yarowsky, 2011, inter alia).
Also, generative ap-proaches have been applied to discover associationsbetween language and demographics of social mediausers (Eisenstein et al 2011, inter alia) but these areof less direct relevance for the present work.
For su-1479pervised approaches, major feature sources are thetext the user has written and also her profile whichmay list the name, interests, friends, etc.
There havealso been studies which did not look at the languageat all but considered the social environment only.For example, MacKinnon & Warren (2006) aim atpredicting the age and the location of the LiveJour-nal6 users.
What they found is that there is a remark-able correlation between the age and the location ofthe user and those of her friends, although there areinteresting exceptions.Burger et al(2011) train a gender classifier ontweets with word and character-based ngram fea-tures achieving accuracy of 75.5%.
Adding the fullname feature alone gives a boost to 89.1%, fur-ther features like self-written description and screenname further help to get 92%.
Also, a self-trainingmethod exploring unlabeled data is described but itsperformance is worse.
Other kinds of sociolinguisticfeatures and a different classifier have been appliedto gender prediction on tweets by Rao & Yarowsky(2010).Nowson & Oberlander (2006) achieve 92% accu-racy on the gender prediction task using ngram fea-tures only.
Their corpus consist of 1,400/450 postswritten by 47 females and 24 males, respectively.However, the ngram features were preselected basedon whether they occurred with significant relativefrequency in the language of one gender over theother.
Since the complete dataset was used to pre-select features, the results are inconclusive.Yan & Yan (2006) train a Naive Bayes classifierto predict the gender of a blog entry author.
In to-tal they looked at 75,000 individual blog entries au-thored by 3,000 bloggers, all of them posted theirgenders on the profile page.
They measure precisionand recall w.r.t.
the minority class (males) and getthe best f-measure of 0.64 (precision and recall are65% and 71%, respectively).Rosenthal & McKeown (2011) predict the age ofa blogger, most features they use are extracted fromthe blog posts, other features include blogger?s inter-ests, the number of friends, the usual time of post-ing, etc.
Similarly to Schler et al(2006), they runa classification experiment with three age classes re-moving intermediate ages and use the majority-class6www.livejournal.combaseline for comparison.
In their other experimentthey experiment with a binary classifier for age dis-tinguishing between the pre- and post-social mediagenerations and using the years from 1975-1988 as aboundary.
The prediction accuracy increases as lateryears are taken.Interestingly, it has been shown that demograph-ics can be predicted in more restricted genres thanthe personal blog or tweets and from text frag-ments even shorter than tweets (Otterbacher, 2010;Popescu & Grefenstette, 2010).3 Motivation for the present studySimilarly to previous NLP studies, our starting goalis to predict the self-reported user gender.
The firstnovelty of our research is that in doing so we con-trast two sources of information: the user?s socialenvironment and the text she has written.
Indeed,a topic which has not yet been investigated muchin the reviewed studies on language and user demo-graphics is the relationship between the language ofthe user and her social environment.
The data analy-sis studies (Sec.
2.1) verified hypotheses concerningthe dependency between a language trait (e.g., aver-age sentence length) and a demographic parameter(e.g., gender).
The demographics prediction studies(Sec.
2.2) mostly relied on language and user pro-file features and considered users in isolation.
Anexception to this is Garera & Yarowsky (2009) whoshowed that, for gender prediction in a dialogue, ithelps to know the interlocutor?s gender.
However,we aim at investigating the impact of the social en-vironment in a much broader sense than the immedi-ate interlocutors and in a much broader context thana conversation.Language is a social phenomenon, and it is thisfact that motivates all the sociolinguistic research.Many if not most language traits are not hard-wiredor inborn but can be explained by looking at whothe person interacts most with.
Since every lan-guage speaker can be seen as a member of multipleoverlapping communities (e.g., computer scientists,French, males, runners), the language of the personmay reflect her membership in different communi-ties to various degrees.
Repeated interactions withother language speakers influence the way the per-son speaks (Baxter et al 2006; Bybee, 2010), and1480the influence is observable on all the levels of thelanguage representation (Croft, 2000).
For exam-ple, it has been shown that the more a person is in-tegrated in a certain community and the tighter theties of the social network are, the more prominentare the representative traits of that community inthe language of the person (Milroy & Milroy, 1992;Labov, 1994).
In our study we adopt a similar viewand analyse the implications it has for gender pre-diction.
Given its social nature, does the languagereflect the norms of a community the user belongsto or the actual value of a demographic variable?In our study we address this issue with a particularmodeling technique: we assume that the observedonline behavior adequately reflects the offline life ofa user (more on this in Sec.
4 and 5) and based onthis assumption make inferences about the user?s so-cial environment.
We use language-based featuresand a supervised approach to gender prediction toanalyse the relationship between the language andthe variable to be predicted.
To our knowledge, weare the first to question whether it is really the in-born gender that language-based classifiers learn topredict.
More concrete questions we are going tosuggest answers to are as follows:1.
Previous studies which looked at online data re-lied on self-reported demographics.
The pro-file data are known to be noisy, although it ishard to estimate the proportion of false profiles(Burger et al 2011).
Concerning the predic-tion task, how can we make use of what weknow about the user?s social environment to re-duce the effect of noise?
How can we bene-fit from the language samples from the userswhose gender we do not know at all?2.
When analyzing the language of a user, howmuch are its gender-specific traits due to theuser?s inborn gender and to which extent canthey be explained by her social environment?Using our modeling technique and a language-based gender classifier, how is its performanceaffected by what we know about the online so-cial environment of the user?3.
Concerning gender predictions across differentage groups, how does classifier performancechange?
Judging from the online communica-tion, do teenagers signal their gender identitymore than older people?
In terms of classifieraccuracy, is it easier to predict a teenager?s gen-der than the gender of an adult?The final novelty of our study is that we are thefirst to demonstrate how YouTube can be used asa valuable resource for sociolinguistic research.
Inthe following section we highlight the points whichmake YouTube interesting and unique.4 DataMost social networks strive to protect user privacyand by default do not expose profile information orreveal user activity (e.g., posts, comments, votes,etc.).
To obtain data for our experiments we useYouTube, a video sharing site.
Most of the YouTuberegistered users list their gender, age and location ontheir profile pages which, like their comments, arepublicly available.
YouTube is an interesting domainfor sociolinguistic research for several reasons:High diversity: it is not restricted to any particulartopic (e.g., like political blogs) but covers a vast va-riety of topics attracting a very broad audience, fromchildren interested in cartoons to academics watch-ing lectures on philosophy7.Spontaneous speech: the user comments are ar-guably more spontaneous than blogs which are morelikely to conform to the norms of written language.At the same time they are less restricted than tweetswritten under the length constraint which encour-ages highly compressed utterances.Data availability: all the comments are publiclyavailable, so we have do not get a biased subset ofwhat a user has written for the public.
Moreover,we observe users?
interactions in different environ-ments because every video targets particular groupsof people who may share origin (e.g., elections inGreece) or possession (e.g., how to unlock iPhone)or any other property.
Some videos attract a well-defined group of people (e.g., the family of a new-born child), whereas some videos appeal to a verybroad audience (e.g., a kitten video).7For more information and statistics see the officialYouTube demographics on http://www.youtube.com/yt/advertise/affinities.html.1481female male nn26% 62% 12%Table 1: Gender distribution for the extracted 6.9M users.From the users, videos and the comment relation-ship we build an affiliation graph (Easley & Klein-berg, 2010): a user and a video are connected if theuser commented on the video (Fig.
1(a)).
Our graphis unweighted although the number of commentscould be used to weight edges.
The co-commentgraph is a stricter version of a more popular co-viewgraph used in, e.g., video recommendation studies(Baluja et al 2008, inter alia).We obtained a random sample of videos by con-sidering all the videos whose YouTube ID has a spe-cific prefix8.
From those, we collected the profiles ofthe users whose commented on the videos.
In total,we extracted about 6.9M profiles of users who havewritten at least 20 comments, not more than 30 com-ments were collected for every user.
The thresholdon the minimum number of comments is set in or-der to reduce the proportion of users who have usedYouTube only a few times and possibly followedthe suggestions of the site in their video choice.The users?
gender distributions is presented in Table1.
Although females, in particular teenagers, havebeen reported to be more likely to blog than males(Herring et al 2004), males are predominant in ourdataset.
A random sample from a pool of users with-out the 20-comments threshold showed that there aremore male commenters overall, although the differ-ence is less remarkable for teenagers: 58% of theteenagers with known gender are male as opposedto 74% and 79% for the age groups 20-29 and 30+.Teenagers are also more numerous accounting forabout 35% in our data.Although we did not filter users based on their lo-cation or mother tongue as many users comment inmultiple languages, the comment set is overwhelm-ingly English.8The YouTube API (http://code.google.com/apis/youtube/getting_started.html) can be usedto retrieve user profiles and video metadata as well as the com-ments.5 Gender propagationWe first consider the user?s social environment to seewhether there is any correlation between the genderof a user and the gender distribution in her vicinity,independent of the language.
We use a simple prop-agation procedure to reach the closest neighbors ofa user, that is, other users ?affiliated?
with the samevideos.
Specifically, we perform the following twosteps:1.
We send the gender information (female, maleor unknown) to all the videos the user has com-mented on.
This way for every video we obtaina multinomial distribution over three classes(see Fig.
1(b)).2.
We send the gender distributions from everyvideo back to all the users who commented onit and average over all the videos the user isconnected with (see Fig.
1(c)).
However, in do-ing so we adjust the distribution for every userso that her own demographics is excluded.
Thisway we have a fair setting where the originalgender of the user is never included in whatshe gets back from the connected videos.
Thus,the gender of a user contributes to the vicinitydistributions of all the neighbors but not to herown final gender distribution.In line with our motivation and modeling tech-nique, we chose such a simple method (and not,say, classification) in order to approximate the of-fline encounters of the user: does she more oftenmeet women or men?
The way we think of thevideos is that they correspond to places (e.g., a cin-ema, a cosmetic shop, a pub) visited by the userwhere she is unintentionally or deliberately exposedto how other speakers use the language.
Similar toBaxter et al(2006), we assume that these encoun-ters influence the way the person speaks.
Note thatif the user?s gender has no influence on her choiceof videos, then, on average, we would expect everyvideo to have the same distribution as in our dataoverall: 62% male, 26% female and 12% unknown(Table 1).To obtain a single gender prediction from thepropagated distribution, for a given user we selectthe gender class (female or male) which got more1482(a) Color represents gender information:blue=male, red=female, grey=unknown.
(b) Propagating gender from users tovideos.
(c) Propagating gender distribution fromvideos to users.Figure 1: Affiliation graph of users (circles) and videos (rectangles).of the distribution mass.
The exact procedure is asfollows: given user u connected with videos Vu ={v1, ..., vm}, there are m gender distributions sentto u: PV (u) = {p(g|vi) : 1 ?
i ?
m, g ?
{f,m, n}}.
A single distribution is obtained fromPV (u): p?
(g|u) =?i p(g|vi)/m.To address the skewness in the data, i.e., the factthat 70% of our users (62/(26 + 62)) with knowngender are male, we select the female gender if (a) itgot more than zero mass and at least as much massas male: p?
(f) > 0 ?
p?
(f) ?
p?
(m), or (b) it got atleast ?
of the mass: p?
(f) ?
?
.
We set ?
= 0.26 ini-tially because it corresponds to the expected propor-tion of females (26%) but further experimented withdifferent ?
values in the range of 0.25-0.4.
We ob-tained best accuracy and f-measures with the thresh-old of 0.33, the difference in accuracy from the ini-tial threshold of 0.26 being less than 2%.
The factthat the optimal ?
value is different from the overallproportion of females (26%) is not surprising giventhat we aggregate per video distributions and not rawuser counts.The predictions obtained with the described prop-agation method are remarkably accurate, reaching90% accuracy (Table 2).
The baseline of assigningall the users the majority class (all male) provides uswith the accuracy of 70% ?
the proportion of malesamong the users with known gender.Although the purpose of this section is not topresent a gender prediction method, we find it worthemphasizing that 90% accuracy is remarkable giventhat we only look at the immediate user vicinity.In the following section we are going to investigatehow this social view on demographics can help us inAcc% P% R% F1Baseline 70 - - -all 90 - - -fem - 84.3 80.8 83male - 92.2 93.8 93Table 2: Precision and recall for propagated gender.predicting gender from language.6 Supervised learning of genderIn this section we start by describing our first gen-der prediction experiment and several extensions toit and then turn to the results.6.1 ExperimentsSimilar to previous studies on demographics predic-tion, we start with a supervised approach and onlylook at the text (comments) written by the user.
Wedo not rely on any information from the social en-vironment of the user and do not use any featuresextracted from the user profile, like name, whichwould make the gender prediction task consider-ably easier (Burger et al 2011).
Finally, we donot extract any features from the videos the user hascommented on because our goal here is to explorethe language as a sole source of information.
Herewe simply want to investigate the extent to whichthe language of the user is indicative of her genderwhich is found in the profile and which, ignoring thenoise, corresponds to the inborn gender.In our experiments we use a distributed imple-mentation of the maximum entropy learner (Bergeret al 1996; McDonald et al 2010) which outputs1483a distribution over the classes, the final prediction isthe class with the greater probability.
We take 80%of the users for training and generate a training in-stance for every user who made her gender visible onthe profile page (4.9M).
The remaining 20% of thedata are used for testing (1.2M).
We use the follow-ing three groups of features: (1) character-based:average comment length, ratio of capital letters tothe total number of letters, ratio of punctuation to thetotal number of characters; (2) token-based: averagecomment length in words, ratio of unique words tothe total tokens, lowercase unigrams with total countover all the comments (10K most frequent unigramswere used, the frequencies were computed on a sep-arate comment set), use of pronouns, determiners,function words; (3) sentence-based: average com-ment length in sentences, average sentence length inwords.Enhancing the training set.
The first question weconsider is how the affiliation graph and propagatedgender can be used to enhance our data for the super-vised experiments.
One possibility would be to traina classifier on a refined set of users by eliminatingall those whose reported gender did not match thegender predicted by the neighborhood.
This wouldpresumably reduce the amount of noise by discard-ing the users who intentionally provided false infor-mation on their profiles.
Another possibility wouldbe to extend the training set with the users who didnot make their gender visible to the public but whosegender we can predict from their vicinity.
The ideahere is similar to co-training where one has two in-dependent views on the data.
In this case a socialgraph view would be combined with the language-based view.Profile vs. vicinity gender prediction.
The nextquestion posed in the motivation section is as fol-lows: Does the fact that language is a social phe-nomenon and that it is being shaped by the socialenvironment of the speaker impact our gender clas-sifier?
If there are truly gender-specific languagetraits and they are reflected in our features, thenwe should not observe any significant difference be-tween the prediction results on the users whose gen-der matches the gender propagated from the vicinityand those whose gender does not match.
A contraryhypothesis would be that what the classifier actuallylearns to predict is not as much the inborn but a so-cial gender.
In this case, the classifier trained on thepropagated gender labels should be more accuratethan the one trained on the labels extracted from theprofiles.To address these questions we contrast two classi-fiers: (1) the one described in the beginning of thesection which is trained on the gender labels col-lected from the user profiles; (2) a classifier trainedon the vicinity gender, that is the dominating genderof the environment of a speaker as obtained with theprocedure described in Section 5.Age groups and gender prediction.
Finally, welook at how gender predictions change with age andtrain three age-specific models to predict gender forteenagers (13-19), people in their twenties (20-29)and people over thirty (30+), the age is also ex-tracted from the profiles.
These groups are identifiedin order to check whether teenagers tend to signal-ize their gender identity more than older people, ahypothesis investigated earlier on a sample of blogposts (Huffaker & Calvert, 2005).6.2 ResultsWe report the results of the supervised experimentsfor all the settings described above.
As an estimateof the lowest bound we also give the results of themajority class baseline (all male) which guarantees70% accuracy.
For the supervised classifiers we re-port accuracy and per-gender precision, recall and f-measure.
Table 3 presents the results for the startingclassifier trained to predict profile gender.Acc% P% R% F1 TotalBaseline 70 - - - 619Kall 89 - - - 619Kfem - 83 78 80 182Kmale - 91 94 93 437KTable 3: Results on the test set.In order to investigate the relationship between thesocial environment of a person, her gender and thelanguage, we split the users from the test set intotwo groups: those whose profile gender matched thegender propagated from the vicinity and those forwhom there was a mismatch.
Thus Table 4 presentsthe same results as Table 3 but separated for these1484two groups of users.
It also gives user counts w.r.t.the profile gender.Acc% P% R% F1 Totalall (same) 94 - - - 557Kfem (same) - 89 87 88 147Kmale (same) - 95 96 96 410Kall (diff) 47 - - - 62Kfem (diff) - 54 39 45 35Kmale (diff) - 42 56 48 27KTable 4: Results for users whose profile gendermatches/differs from the vicinity gender.Enhanced training set.
In the next experiment werefined the training set by removing all the userswhose vicinity gender did not match the gender re-ported in the profile.
The evaluation was done onthe unmodified set (Table 5).
The predictions madeby the model trained on a refined set of users turnedout to be slightly less accurate than those made bythe model trained on the full training set (Table 3).The refined model performed slightly (< 1%) bet-ter than the starting one on the users whose vicinityand the profile genders matched but got very poorresults on the users with a gender mismatch, the ac-curacy being as low as 37%.
The accuracy of thestarting model on those users is 47% (Table 4).Acc% P% R% F1all 88 - - -fem - 83 76 79male - 90 94 92Table 5: Results of the models trained on the refinedtraining set.In another experiment we extended the trainingdata with the users whose gender was unknown butwas predicted with the propagation method.
How-ever, a larger training set makes a difference only ifthere is a substantial performance gain over the in-creasing size of the training set.
We observed only aminor gain in performance (< 1%) when the train-ing data size was increased by an order of magni-tude.
Given that, it is not surprising that adding 12%did not affect the results.Language, the vicinity and the profile genders.The gap in accuracies of predictions for the two usergroups in Table 4 is remarkable: 47% vs. 94%.
Ifwe extrapolate what we observe in the affiliationgraph to other online and offline life, then this re-sult may suggest that gender traits are more promi-nent in the language of people spending more timewith the people of their gender than in that of thepeople who spend more time with the people of theopposite gender.
Given the remarkable difference,a further question arises whether the classifier actu-ally learns to predict a kind of socially rather than theprofile gender.
To investigate this, we looked at theresults of the model which knew nothing about theprofile gender but was trained to predict the vicinitygender instead (Table 6).
This model relied on theexact same set of features but both for training andtesting it used the gender labels obtained from thepropagation procedure described in Section 5.Acc% P% R% F1all 91 - - -fem - 86 80 83male - 92 95 94Table 6: Results of the models trained and tested on thepropagated gender.According to all the evaluation metrics, for both gen-ders the performance of the classifier trained andtested on the propagated gender is higher (cf.
Ta-ble 3): the differences in f-measure for female andmale are four and two points respectively, both sta-tistically significant.
This indicates that it is the pre-dominant environment gender that a language-basedclassifier is better at learning rather than the inborngender.Predictions across age groups.
Finally, to ad-dress the question of whether gender differences aremore prominent and thus easer to identify in the lan-guage of younger people, we looked at the accu-racy of gender predictions across three age groups.Table 7 summarizes the results and gives the accu-racy of the all male baseline as well as of the prop-agation procedure (Prop-acc).
Although the over-all accuracy over the three groups does not degrademuch, from 89% to 87%, both precision and recalldo decrease significantly for females.
This is not1485directly reflected in the accuracy because the num-ber of females drops dramatically from 42% amongteenagers to 26% and then 21% in the latter groups.For a comparison, the accuracy of the propagatedgender (Prop-acc) also decreases from younger toolder age groups although it is slightly higher thanthat of language-based predictions.
One conclusionwe can make at this point is that a teenager?s gen-der is easier to predict from the language which isin line with the hypothesis that younger people sig-nalize their gender identities more than older people.Another observation is that, as the person gets older,we can be less sure about her gender by looking ather social environment.
This in turn might be anexplanation of why there are less gender signals inthe language of a person: the environment becomesmore mixed, and the influence of both genders be-comes more balanced.13-19 20-29 30+ OverallBase-acc% 58 74 79 70Prop-acc% 91 90 88 90Accuracy% 89 89 87 89Fem-P% 87 81 74 83Fem-R% 87 76 62 78Fem-F1 87 78 68 80Male-P% 90 92 90 91Male-R% 90 94 94 94Male-F1 90 93 92 93Table 7: Results across the age groups.7 ConclusionsIn our study we addressed the gender prediction taskfrom two perspectives: (1) the social one where welooked at an affiliation graph of users and videos andpropagated gender information between users, and(2) the language one where we trained a classifieron features which have been claimed to be indica-tive of gender.
We demonstrated that both perspec-tives provide us with comparably accurate predic-tions (around 90%) but that they are far from be-ing independent.
We also investigated a few ways ofhow the performance of a language-based classifiercan be enhanced by the social aspect, compared theaccuracy of predictions across different age groupsand found support for hypotheses made in earlier so-ciolinguistic studies.We are not the first to predict gender from lan-guage features with online data.
However, to ourknowledge, we are the first to contrast the two views,social and language-based, using online data and toquestion whether there is a clear understanding ofwhat gender classifiers actually learn to predict fromlanguage.
Our results indicate that from the standardlanguage cues we are better at predicting a socialgender, that is the gender defined by the environmentof a person, rather than the inborn gender.The theoretical significance of this result is thatit provides support for the usage-based view on lan-guage (Bybee, 2010), namely that the person?s lan-guage is largely shaped by the interactions with hersocial environment.
On the practical side, it mayhave implications for targeted advertisement as it en-riches the understanding of what gender classifierspredict.Acknowledgements: I am thankful to Enrique Al-fonseca, Keith Hall and the EMNLP reviewers fortheir feedback.ReferencesArgamon, S., M. Koppel, J.
Fine & A. R. Shimoni(2003).
Gender, genre, and writing style in formalwritten texts.
Text, 23(3).Baluja, S., R. Seth, D. Sivakumar, Y. Jing, J. Yag-nik, S. Kumar, D. Ravichandran & M. Aly (2008).Video suggestion and discovery for YouTube:Taking random walks through the view graph.
InProc.
of WWW-08, pp.
895?904.Baxter, G. J., R. A. Blythe, W. Croft & A. J. McKane(2006).
Utterance selection model of languagechange.
Physical Review, E73.046118.Berger, A., S. A. Della Pietra & V. J. Della Pietra(1996).
A maximum entropy approach to naturallanguage processing.
Computational Linguistics,22(1):39?71.Burger, J. D., J. Henderson, G. Kim & G. Zarrella(2011).
Discriminating gender on Twitter.
InProc.
of EMNLP-11, pp.
1301?1309.1486Burger, J. D. & J. C. Henderson (2006).
An ex-ploration of observable features related to bloggerage.
In Proceedings of the AAAI Spring Sympo-sium on Computational Approaches for AnalyzingWeblogs, Stanford, CA, 27-29 March 2006, pp.15?20.Bybee, J.
(2010).
Language, Usage and Cognition.Cambridge University Press.Chambers, J.
& P. Trudgill (1998).
Dialectology.Cambridge University Press.Coulmas, F.
(Ed.)
(1998).
The Handbook of Soci-olinguistics.
Blackwell.Croft, W. (2000).
Explaining Language Change: AnEvolutionary Approach.
London: Longman.Easley, D. & J. Kleinberg (2010).
Network, crowds,and markets: Reasoning about a highly connectedworld.
Cambridge University Press.Eckert, P. & S. McConnell-Ginet (2003).
Languageand Gender.
Cambridge University Press.Eisenstein, J., N. A. Smith & E. P. Xing (2011).
Dis-covering sociolinguistic associations with struc-tured sparsity.
In Proc.
of ACL-11, pp.
1365?1374.Ellist, D. (2009).
Social (distributed) language mod-eling, clustering and dialectometry.
In Proc.
ofTextGraphs at ACL-IJCNLP-09, pp.
1?4.Garera, N. & D. Yarowsky (2009).
Modeling latentbiographic attributes in conversational genres.
InProc.
of ACL-IJCNLP-09, pp.
710?718.Gillick, D. (2010).
Can conversational word usagebe used to predict speaker demographics?
In Pro-ceedings of Interspeech, Makuhari, Japan, 26-30September 2010.Herring, S. C. & J. C. Paolillo (2006).
Gender andgenre variation in weblogs.
Journal of Sociolin-guistics, 10(4):439?459.Herring, S. C., L. A. Scheidt, S. Bonus & E. Wright(2004).
Bridging the gap: A genre analysis ofweblogs.
In HICSS-04.Hudson, R. A.
(1980).
Sociolinguistics.
CambridgeUniversity Press.Huffaker, D. A.
& S. L. Calvert (2005).
Gen-der, identity and language use in teenager blogs.Journal of Computer-Mediated Communication,10(2).Kapidzic, S. & S. C. Herring (2011).
Gen-der, communication, and self-presentation in teenchatrooms revisited: Have patterns changed?Journal of Computer-Mediated Communication,17(1):39?59.Koppel, M., S. Argamon & A. R. Shimoni (2004).Automatically categorizing written text by au-thor gender.
Literary and Linguistic Computing,17(4):401?412.Labov, W. (1994).
Principles of Linguistic Change:Internal Factors.
Blackwell.Lakoff, R. (1973).
Language and woman?s place.Language in Society, 2(1):45?80.MacKinnon, I.
& R. Warren (2006).
Age and geo-graphic inferences of the LiveJournal social net-work.
In Statistical Network Analysis: Models,Issues, and New Directions Workshop at ICML-2006, Pittsburgh, PA, 29 June, 2006.McDonald, R., K. Hall & G. Mann (2010).
Dis-tributed training strategies for the structured per-ceptron.
In Proc.
of NAACL-HLT-10, pp.
456?464.Milroy, L. & J. Milroy (1992).
Social network andsocial class: Toward an integrated sociolinguisticmodel.
Language in Society, 21:1?26.Mulac, A., D. R. Seibold & J. R. Farris (2000).
Fe-male and male managers?
and professionals?
crit-icism giving: Differences in language use and ef-fects.
Journal of Language and Social Psychol-ogy, 19(4):389?415.Newman, M. L., C. J. Groom, L. D. Handelman &J. W. Pennebaker (2008).
Gender differences inlanguage use: An analysis of 14,000 text samples.Discourse Processes, 45:211?236.1487Nowson, S. & J. Oberlander (2006).
The identity ofbloggers: Openness and gender in personal we-blogs.
In Proceedings of the AAAI Spring Sympo-sium on Computational Approaches for AnalyzingWeblogs, Stanford, CA, 27-29 March 2006, pp.163?167.Otterbacher, J.
(2010).
Inferring gender of moviereviewers: Exploiting writing style, content andmetadata.
In Proc.
of CIKM-10.Popescu, A.
& G. Grefenstette (2010).
Mining userhome location and gender from Flickr tags.
InProc.
of ICWSM-10, pp.
1873?1876.Rao, D. & D. Yarowsky (2010).
Detecting latentuser properties in social media.
In Proc.
of theNIPS MLSN Workshop.Rao, D. & D. Yarowsky (2011).
Typed graph modelsfor semi-supervised learning of name ethnicity.
InProc.
of ACL-11, pp.
514?518.Rosenthal, S. & K. McKeown (2011).
Age predic-tion in blogs: A study of style, content, and on-line behavior in pre- and post-social media gener-ations.
In Proc.
of ACL-11, pp.
763?772.Schler, J., M. Koppel, S. Argamon & J. Pennebaker(2006).
Effects of age and gender on blogging.In Proceedings of the AAAI Spring Symposiumon Computational Approaches for Analyzing We-blogs, Stanford, CA, 27-29 March 2006, pp.
199?205.Yan, X.
& L. Yan (2006).
Gender classifica-tion of weblogs authors.
In Proceedings of theAAAI Spring Symposium on Computational Ap-proaches for Analyzing Weblogs, Stanford, CA,27-29 March 2006, pp.
228?230.1488
