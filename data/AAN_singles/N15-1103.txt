Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1001?1005,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsContinuous Adaptation to User Feedbackfor Statistical Machine TranslationFr?ed?eric Blain, Fethi Bougares, Amir Hazem, Lo?
?c Barrault and Holger SchwenkLIUM - University of Le Mans (France)firstname.surname@lium.univ-lemans.frAbstractThis paper gives a detailed experiment feed-back of different approaches to adapt a sta-tistical machine translation system towards atargeted translation project, using only smallamounts of parallel in-domain data.
Theexperiments were performed by professionaltranslators under realistic conditions of workusing a computer assisted translation tool.
Weanalyze the influence of these adaptations onthe translator productivity and on the overallpost-editing effort.
We show that significantimprovements can be obtained by using thepresented adaptation techniques.1 IntroductionLanguage service providers (LSP) and human pro-fessional translators currently use machine transla-tion (MT) technology as a tool to increase their pro-ductivity.
For this, MT is closely integrated intocomputer-assisted translation (CAT) tool.
The MTsystem suggests an automatic translation of the in-put sentence which is then post-edited by the hu-man professional translators.
They generally workon a project-based pace, i.e.
a set of documents (theproject) have to be translated in a certain period oftime.
It is well know that an MT system has tobe adapted to the target task and domain in orderto achieve the best performances.
This process ofadaptation can be separated into two different steps.First, an adaptation is performed before the begin-ning of the translation process,.
This aims to spe-cialize the system to the targeted domain: we will tothis adaptation as domain adaptation.Then, another adaptation is performed during thetranslation process with the aim of iteratively inte-grating users?
feedback into the MT system.
Theadaptation can be performed at two different fre-quencies: (i) the system can continuously learn frompost-edited segments, the models being immediatelyupdated, or (ii) all the available project-specific datais used after each day of work to adapt the MT en-gine.
This scheme is more related to document leveladaptation; we will refer to it as project adaptation.The experimental work described in this paper fitsinto the latter adaptation scheme.As part of the MATECAT project1, we analyzeproject adaptation performed over several days.
Allexperiments were performed with professional hu-man translators under realistic conditions of work.The motivations of this work are detailed in section 2and related work is discussed.
In sections 3 and 4 wepresent both the experimental protocol and frame-work before presenting the corresponding results insection 5.2 MotivationsThis work is a continuation of earlier research onadaptation of a statistical MT (SMT) system Cet-tolo et al, 2014).
More precisely, it was motivatedby remaining opened questions.
First, what doesthe learning curve look like for an iterative usageof the daily adaptation procedure?
Even if the ef-ficiency of the project adaptation scheme has beenestablished, it has not been tested yet over multipledays.
Does it reaches a plateau or do the translation1www.matecat.com1001quality continue to improve?
What are the causesfor the observed gains?
Are they due to the famil-iarization of the users with both the system and thetask, or are they due to real efficiency of the adap-tation scheme?
In previous work, the protocol didnot allow to clearly measure the adaptation perfor-mance.
In order to avoid this issue, a specific ex-perimental protocol has been defined as described insection 3.
Moreover, in addition to answer these newquestions, we assessed a project adaptation schemewhich take advantage of continuous space languagemodeling (CSLM) as explained in section 4.
As faras we know, this is the first time that a neural net-work LM is integrated into a professional environ-ment workflow, and that adaptation in such an ap-proach is considered.3 Evaluation ProtocolWe defined an adaptation protocol with the goalto assess the same task with and without adapta-tion procedure.
Like in (Guerberof, 2009; Plittand Masselot, 2010), three professional translatorswere involved in a two parts experiment: during thefirst part, translators receive MT suggestions froma state-of-the-art domain-adapted engine built withthe Moses toolkit (Koehn et al, 2007), without be-ing adapted with the data generated during the trans-lation of the project.For the second part, the MT sug-gestions are provided by a MT system which waspreviously adapted to the current project using thehuman translations of prior working days.
Since weasked the same translators to post-edit the same doc-ument twice (i.e.
with and without MT adaptation),the second run was launched after a sufficient delay:the human memory impact is reduced since transla-tors worked on other projects in between.To measure the user productivity, we consideredtwo performance indicators: (i) the post-editing ef-fort measured with TER (Snover et al, 2006) whichcorresponds to the number of edits made individu-ally by each translator, (ii) the time-to-edit rate ex-pressed in number of translated words per hour.
Inaddition to these two key indicators, we evaluatedthe translation quality using an automatic measure,namely BLEU score (Papineni et al, 2002).
Thismeasure is used to make sure that no regression inthe translation quality is observed after several daysof work due to overfitting of the project adaptation(since previous working days are used to adapt themodels).Moreover, in order to respect realistic workingconditions, we decided to set up a unique user-specific Moses engine per translator.
By thesemeans, any inter-user side-effects due to personalchoices or stylistic edits are avoided.
In addition, weobtain multiple references for assessing the resultsof the test.
Consequently, it was required for the as-sessment that human translators work in a synchro-nized manner, i.e.
the same amount of data is trans-lated every day by each translator.
The systems arethen adapted, individually for each translator, usingprevious days of work, and used by the translatorsduring the next day, and so on.4 Experimental frameworkWe ran contrastive experiments by asking the trans-lators to post-edit translations of a Legal documentfrom English into French (about 15k words) overfive days (i.e.
about 3k words/day).
An in-domainadapted (DA) system was used as baseline systemfor the first day, before project adapted (PA) systemshave taken over.4.1 Domain adapted systemBefore the human translator starts working, our DAsystem is trained using an extracted subset of bilin-gual training data that is mostly relevant to our spe-cific domain.
The extraction process, widely knownas data selection, is applied using cross-entropydifference algorithm proposed by (Axelrod et al,2011)2.
In order to augment the amount of train-ing data3(about 22M words) we also select a bilin-gual subset from Europarl, JRC-Acquis, news com-mentary, software manuals of the OPUS corpus,translation memories and the United Nations cor-pus.
About 700M additional newspaper monolin-gual data selected from WMT evaluation campaignare also used for language modeling.4.2 Project adapted systemOur project-adaptation scenario, which is repeatediteratively during the lifetime of the translation2We used the XenC tool for data selection3DGT+ECB corpora (see http://opus.lingfil.uu.se)1002project, is achieved as follows: the new daily amountof specific data is added to the development set, andnew monolingual and bilingual data selections areperformed with it.
The new SMT system built onthese selected data is then optimized on the new de-velopment set.When performing project adaptation of an SMTsystem, we assume that the documents of a projectare quite close and then, adapting the SMT systemusing the n-th days could be helpful to translate then + 1 day.
However, we need to be careful to notoverfit to a particular day of the project.
This is par-ticularly risky since the daily amount of specific datais relatively small (about 3k words).
Therefore, wechose to add three times the daily data to our existingin-domain development set.
This factor of three wasempirically determined during prior lab tests.
Also,all the previous days are used, i.e.
when we adapt af-ter three days of work, we used all the data from thefirst three days.4.3 Continuous Space Language ModelOver the last years, there has been significantly in-creasing interest in using neural networks in SMT.As mentioned above, we used this technology intoour project adaptation scheme.
Fully integrated tothe MT systems, it was used by our three SMT sys-tems dedicated to the translators.A continuous space LM (CSLM) (Schwenk,2010; Schwenk, 2013) is trained on the same datathan a classical n-gram back-off LM and is used torescore the n-best list.
In our case, and after eachday of work, the daily generated data (3k words) isused to perform the adaptation of the CSLM by con-tinuing its training (see (Ter-Sarkisov et al, 2014)for details).
An important advantage of this ap-proach is that the adaptation can be performed in acouple of minutes.5 Experimental results and discussionAll the results presented in this section have been ex-tracted from the edit logs provided by the MATECATCAT tool.5.1 Post-editing effortIn terms of post-editing effort, the results for eachtranslator according to several SMT systems areshown in Table 1.
Several TER scores are computedbetween the SMT system output and various sets ofreferences.
This score reveals the number of editsperformed by the translator in order to obtain a suit-able translation.
The first column indicates the dayof the experiment.
The second column representsthree SMT systems, namely: the baseline systemadapted to the domain (DA), the same system witha CSLM (DA+CSLM) and the project adapted sys-tem (all models were updated, including the CSLM)noted ?PA+CSLM-adapt?.
The third, fourth andfifth columns represent respectively the TER scoresfor the three translators.
The first score is calcu-lated using the reference produced by the translatorhimself.
It could be considered as HTER (Snoveret al, 2009).
The second score (in parenthesis) iscalculated using the three references produced bythe translators.
The third score (in brackets) is cal-culated according to an official ?generic?
referenceprovided by the European Commission.
By theseadditional results, we aim to assess whether their isa tendency of the systems to adapt strongly to theparticular style of one translator, or whether they stillperform well with respect to independent references.On day 1, only the DA and DA+CSLM systems arepresented since the project adaptation can only startafter the first working day.First of all, we can notice that the use of CSLMsignificantly decrease the TER scores for all trans-lators.
We can also remark that the third translatorhas a much higher TER than the two other trans-lators during the first two days.
Then, the sys-tem seems to learn his style and the TER reachesa comparable level at day 3.
We can observe thatproject adaptation always lowers the TER with re-spect to the individual reference.
The only excep-tion can be observed for the first translator for days2, 4 and 5.
However, the project-adapted systemis better or identical in most cases when multiplereferences are used.
It is also interesting to notethat our adaptation procedure improves the post-editing effort with respect to the independent refer-ence translation in nine out of twelve cases.
Overall,it can be clearly seen that the adaptation scheme isvery effective.
The difference between the baselinesystem (DA+CSLM) and the fully adapted system(PA+CSLM-adapt) reaches 9 TER points in someconditions.A quite similar tendency can be observed when1003day method translator 1 translator 2 translator 31 DA 33.34 (28.10) [54.59] 32.99 (28.10) [54.59] 48.62 (28.10) [54.59]DA+CSLM 31.13 (25.73) [54.94] 31.43 (25.73) [54.94] 48.50 (25.73) [54.94]2 DA 35.33 (30.73) [56.63] 37.44 (30.73) [56.63] 49.03 (30.73) [56.63]DA+CSLM 33.06 (28.86) [56.30] 36.24 (28.86) [56.30] 49.12 (28.86) [56.30]PA+CSLM-adapt 34.31 (29.07) [56.18] 30.48 (27.21) [56.30] 47.29 (29.62) [56.53]3 DA 30.76 (26.68) [55.49] 35.09 (26.68) [55.49] 38.05 (26.68) [55.49]DA+CSLM 27.87 (24.70) [55.09] 33.86 (24.70) [55.09] 36.72 (24.70) [55.09]PA+CSLM-adapt 25.24 (20.04) [54.13] 27.48 (20.40) [54.16] 27.42 (20.99) [53.77]4 DA 33.01 (29.07) [55.90] 38.31 (29.07) [55.90] 41.96 (29.07) [55.90]DA+CSLM 29.79 (27.12) [56.78] 37.92 (27.12) [56.78] 41.03 (27.12) [56.78]PA+CSLM-adapt 30.47 (25.87) [55.21] 30.15 (25.53) [56.12] 32.70 (24.03) [55.86]5 DA 31.34 (26.31) [54.78] 34.38 (26.31) [54.78] 39.41 (26.31) [54.78]DA+CSLM 29.52 (24.88) [52.59] 33.94 (24.88) [54.74] 38.85 (24.88) [54.74]PA+CSLM-adapt 31.52 (24.43) [53.08] 26.19 (22.34) [53.16] 30.46 (23.71) [54.31]Table 1: TER scores for English-French data of the Legal domain for the three translators over 5 days.
Parenthesizedscores are calculated using the references of all three translators, while scores in brackets are calculated using a genericreference provided by the European Commission.analyzing translation quality in terms of BLEU score(results not presented here).
Like for the prior TERresults, the BLEU scores for translator 3 are muchworse than the scores of the two other ones.
Afterthe third day, the scores reach the same level.
Again,this could indicate that the adaptation process haslearned his particular style.5.2 Translation speedTable 2 reports, for each translator, the translationspeed, expressed in number of post-edited words perhour.
The results are given for the two conditions ofour experiment, along with the percentage of relativeimprovement.
We can observe a very high produc-tivity gain for all translators between the two ses-sions of our test, from 18.5% to 38.3%.
The hugeUser Translation speed (words/hour)ID DA+CSLM PA+CSLM-adapt ?T1 928 1283 38.3%T2 1533 1816 18.5 %T3 308 704 128.5%Table 2: Overall translation speed for all translators.Measurements are taken on post-edits performed withthe domain-adapted MT system (DA+CSLM) and theproject-adapted MT system (PA+CSLM-adapt).gain for translator T3 could be biased by the lowworking speed of the translator, even if we had con-firmed that all the translators are experts with thepost-editing process.
We assume that either T3 hadsome difficulties with the legal domain or he hadjust taken his time to perform the test, or both.
Thiscould partially explain the huge improvement in pro-ductivity which is doubled.6 ConclusionSeveral studies have also shown that the close in-tegration of MT into a CAT tool can increase theproductivity of human translators.
In this work, weextended these works in several aspects.
We haveobserved systematic improvements of the translationquality and speed when adapting the systems withdata generated during the translation project (span-ning several days).
The MT system does not onlyadapt to the style of the human translator who post-edit the automatic translations.
In all cases, we ob-served improved translation quality with respect toan independent reference translation.
Finally, wehave shown that neural network LMs can be usedin an operational SMT system and that they can beadapted very quickly to small amount of data.
Al-though the use of neural networks in SMT is draw-ing a lot of attention, we are not aware at any other1004deployment in real applications.AcknowledgmentsWe thank the post-editors who took part to this ex-periment, as well as our anonymous reviewers fortheir feedback and suggestions.
This work has beenpartially supported by the EC-funded project MATE-CAT (ICT-2011.4.2-287688).ReferencesAxelrod, A., He, X., and Gao, J.
(2011).
Domain adapta-tion via pseudo in-domain data selection.
In Proceed-ings of the 2011 Conference on Empirical Methods inNatural Language Processing (EMNLP), pages 355?362.Cettolo, M., Bertoldi, N., Federico, M., Schwenk, H.,Barrault, L., and Servan, C. (2014).
Translationproject adaptation for mt-enhanced computer assistedtranslation.
Machine Translation, 28(2):127?150.Guerberof, A.
(2009).
Productivity and quality in mtpost-editing.
MT Summit XII-Workshop: BeyondTranslation Memories: New Tools for Translators MT.Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran,C., Zens, R., et al (2007).
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the ACL on InteractivePoster and Demonstration Sessions, pages 177?180.Association for Computational Linguistics.Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.(2002).
BLEU: a method for automatic evaluation ofmachine translation.
In Proceedings of the 40th An-nual Meeting on Association for Computational Lin-guistics, pages 311?318.Plitt, M. and Masselot, F. (2010).
A productivity test ofstatistical machine translation post-editing in a typicallocalisation context.
The Prague Bulletin of Mathe-matical Linguistics, 93(-1):7?16.Schwenk, H. (2010).
Continuous space language modelsfor statistical machine translation.
In The Prague Bul-letin of Mathematical Linguistics, number 93, pages137?146.Schwenk, H. (2013).
Cslm - a modular open-source con-tinuous space language modeling toolkit.
Interspeech.Snover, M., Dorr, B., Schwartz, R., Micciulla, L., andMakhoul, J.
(2006).
A study of translation edit ratewith targeted human annotation.
In Proceedings of the7th Conference of the Association for Machine Trans-lation in the Americas (AMTA), pages 223?231.Snover, M., Madnani, N., Dorr, B., and Schwartz, R.(2009).
Fluency, adequacy, or HTER?
exploring dif-ferent human judgments with a tunable MT metric.
InProceedings of the Fourth Workshop on Statistical Ma-chine Translation, pages 259?268.Ter-Sarkisov, A., Schwenk, H., Bougares, F., and Bar-rault, L. (2014).
Incremental adaptation strategiesfor neural network language models.
Available athttp://arxiv.org/abs/1412.6650.1005
