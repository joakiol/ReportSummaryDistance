Proceedings of the Workshop on Embodied Language Processing, pages 25?32,Prague, Czech Republic, June 28, 2007. c?2007 Association for Computational LinguisticsWhich way to turn?
Guide orientation in virtual way findingMark EversTechnical & ProfessionalCommunicationUniversity of TwenteThe NetherlandsM.Evers@alumnus.utwente.nlMarie?t TheuneHuman Media InteractionUniversity of TwenteThe NetherlandsM.Theune@utwente.nlJoyce KarremanTechnical & ProfessionalCommunicationUniversity of TwenteThe NetherlandsJ.Karreman@utwente.nlAbstractIn this paper we describe an experimentaimed at determining the most effective andnatural orientation of a virtual guide thatgives route directions in a 3D virtual envi-ronment.
We hypothesized that, due to thepresence of mirrored gestures, having theroute provider directly face the route seekerwould result in a less effective and less nat-ural route description than having the routeprovider adapt his orientation to that of theroute seeker.
To compare the effectivenessof the different orientations, after having re-ceived a route description the participants inour experiment had to ?virtually?
traverse theroute using prerecorded route segments.
Theresults showed no difference in effectivenessbetween the two orientations, but suggestedthat the orientation where the speaker di-rectly faces the route seeker is more natural.1 IntroductionWhen someone approaches us and asks which wayto go, we naturally turn ?
if necessary ?
so we facethe direction to take (which makes it also easier forourselves to imagine traversing the route).
Gener-ally, the route seeker then also turns to adapt hisor her orientation to match ours, and we end upsharing the same perspective on the route to take.1Presumably, this matching of physical orientation is1This observation is based on personal experience.
We alsoobserved this behaviour in a small corpus of route descriptionvideo?s.meant to reduce the mental effort that is involvedin matching another person?s perspective on a spa-tial scene for both speaker and hearer (Shelton andMcNamara, 2004).
However, someone who facesan embodied virtual agent presenting a route de-scription in a virtual environment (projected on acomputer screen) cannot turn to match his or herperspective with that of the agent, as turning awayfrom the screen would result in losing sight of boththe agent and the virtual environment.
In this sit-uation, the only way to bring the perspectives ofroute provider (agent) and route seeker (user) closertogether is for the agent to adapt its orientation tomatch that of the user.
In this paper, we describe anexperiment carried out to determine if such a changein orientation by the route provider helps the routeseeker with virtual way finding.
Although the ex-periment was aimed at determining the most effec-tive and natural orientation of a Virtual Guide, weused prerecorded route descriptions presented by ahuman route provider.
The Virtual Guide that wehave developed (see next section) was still being im-plemented at the time.2 The Virtual GuideWe have developed an embodied Virtual Guide2 thatcan give route directions in a 3D environment, whichis a virtual reality replica of a public building in ourhome town.
When navigating through this virtualenvironment, shown on the computer screen from afirst person perspective, the user can approach theVirtual Guide to ask for directions.
Currently the2See http://wwwhome.cs.utwente.nl/?hofs/dialogue for anonline demo.25Guide is behind the reception desk (see Figure 1),but she can be situated anywhere in the building.The first part of the interaction between the Vir-tual Guide and the user consists of a natural lan-guage dialogue in which the Guide tries to find outthe user?s intended destination.
This may involvesubdialogues, in which either the Guide or the userasks the other for clarification, and the resolution ofanaphoric expressions (e.g., How do I get there?
).Input and output modalities include text, speech andpointing.
For an in-depth description of the dialoguemodule of the Virtual Guide, see Hofs et al (2003).When the user?s destination has been established,the Virtual Guide gives a natural language route de-scription, in the form of a monologue that cannotbe interrupted.
This is somewhat unnatural sincein real direction giving, the route seeker tends togive feedback and, if necessary, ask for clarificationwhile the route is being described.
However, sincein our system dialogue management and the gener-ation of route descriptions are handled by separate,specialised modules this is currently not possible.The route is presented as a sequence of segments,which are mostly expressed as ?point+direction?combinations (Dale et al, 2005).
That is, they con-sist of a turn direction combined with the locationwhere this turn is to be made, specified in termsof a landmark.
For example, You go left at the in-formation sign.
The route description is generatedas follows.
First, the shortest path between startingpoint and destination is computed based on prede-fined paths in the virtual environment.
Turn direc-tions are derived from the relative angles of sub-sequent path segments, and landmarks are selectedbased on their relative salience (e.g., in terms of sizeor colour) and proximity to a turning point.
The se-quence of turn directions and associated landmarksis then given as input to the natural language gen-eration component, which is based on Exemplars(White and Caldwell, 1998).
After a first versionof the route description has been generated using acollection of standard sentence structures, this ini-tial description is revised by randomly aggregatingsome sentences and adding cue phrases such as andthen, after that etc.
to achieve some variation in thegenerated text.To generate appropriate gestures to accompanythe verbal route description, the generated text isFigure 1: The Virtual Guide.extended with tags associating the words in theroute description with different types of gestures.Currently this is done using a simple keyword ap-proach.
Direction words (left, right) are associatedwith pointing gestures in the corresponding direc-tions, and references to landmarks are associatedwith deictic gestures pointing to either the absoluteor the relative location of these objects (see Sec-tion 3).
Some iconic gestures (i.e., gestures that havea resemblance in shape to what they depict) are alsoavailable, for example a horizontal tube-like gesturethat can be used in references to corridors and tun-nels.
Unlike the pointing gestures, which are gener-ated ?on the fly?, the iconic gestures of the VirtualGuide are generated by using canned animations.For a more sophisticated approach to the generationof iconic gestures, see the work by Kopp et al (inpress) who describe the dynamic planning of noveliconic gestures by NUMACK, an embodied conver-sational agent that functions as a virtual guide for theNorthwestern University campus.The last stage of the route description process inour Virtual Guide is to send the marked-up text tothe animation planner, which actually generates therequired animations in synchronization with text-to-speech output.
The animation planner is based onthe work by Welbergen et al (2006).3 The Guide?s gestures and orientationDuring the route description, the Virtual Guide canmake pointing gestures from either an ?objective?viewpoint, i.e., pointing at the absolute locations ofobjects, or from a ?character?
viewpoint, i.e., point-26ing at locations relative to the position of a personwho is walking the route.
An objective viewpointmakes most sense when pointing at objects that are(in principle) visible to both the agent and the user,which is only the case for objects that are located atthe start of the route.
So, most of the time the Guidewill be using the character viewpoint, pointing leftand right relative to its own body to indicate land-marks and directions from the perspective of some-one who is walking along the route being described.The typical orientation of information presentingagents is facing the user.
However, it is not a prioriclear that this would be the best option for the Vir-tual Guide.
When facing the user, all pointing ges-tures made by the guide from a character viewpointwould mirrored in the eyes of the user, so the latterwould have to perform a mental 180?
re-orientationof the gestures.
This would demand extra cognitiveeffort on top of processing and storing the verballypresented route information, and might negativelyinfluence the user?s ability to reproduce the route di-rections during actual traversal of the route.In actual direction giving situations, people of-ten tend to minimize the difference in orientationbetween them.
Therefore we wondered if reducingthe difference in orientation between the agent andthe user would help the user to find his way dur-ing traversal.
If the agent would turn to face almostthe same direction as the user, its gestures could beexpressed as close to the route seeker?s perspectiveas possible, thus reducing the cognitive load for theuser in processing them.
Also, we wondered if thisconfiguration would yield a more natural effect thanhaving the agent directly face the user during theroute description.
We investigated these questionsin an experiment where participants had to virtu-ally follow a route, presented to them in one of twoversions that differed in the orientation of the routeprovider.
Because the Virtual Guide was still be-ing implemented at the time, we used route descrip-tions by a human route provider.
The experimentalsetup and its results are presented below, followedby some conclusions and future research directions.4 The orientation experimentThe goal of the experiment was to investigate the ef-fect of speaker orientation on the effectiveness andFigure 2: Angle between route provider and routeseeker (camera)naturalness of a route description.
For our exper-iment, we opted to use prerecorded route descrip-tions, as this matched the capabilities of our Vir-tual Guide (which can only present the route as amonologue with no interaction) and also ensuredan unlimited number of reproductions of constantquality and content.
We recorded two separateroute descriptions that differed in speaker orienta-tion with respect to the route seeker, but were other-wise (largely) the same:180?
version The route provider is oriented at a180?
angle with respect to the route seeker, i.e.,he directly faces the camera lens, creating mir-rored gestures (his left is seen as right by theviewer and vice versa).
See Figures 2(a) and3(a).120?
version The route provider is oriented at a120?
angle toward the route seeker, as if toadapt his orientation to that of the route seeker.See Figures 2(b) and 3(b).We chose an orientation of 120?
for the routeseeker-oriented version, so as to maintain visibilityof non-verbal signals.
If the route provider were toassume an orientation of 90?
or less, as illustratedin Figure 2(c), not all gestures would be visible andmaintaining eye contact could make his posture un-natural.The 120?
and the 180?
condition only differedin bodily orientation while eye contact remainedunchanged and facial expressions remained visi-ble.
Also, although wording slightly varied, thepresented information was the same in both condi-tions.
The route descriptions were recorded on lo-cation in a small town with short streets and plenty27a) b)Figure 3: ?Turn left at the white building?
(a: 180?, b: 120?
)of landmarks.
The route being described led fromthe recording location to the town hotel.
The verbaldescription was similar in structure to those gener-ated by the Virtual Guide.
It mentioned five decisionpoints, each connected with one or two characteris-tic landmarks.
For example, At the men?s fashionshop, you turn right.
During the route description,the route provider made beat gestures and pointinggestures from a character viewpoint, taking his ownbody orientation as a reference for left and right.Apart from a few slight variations, the gestures usedin both versions of the route description were thesame; see Figure 3.
At the start of the route de-scription, both route provider and route seeker wereexactly (180?
version) or almost (120?
version) per-pendicular to the starting direction of the route.After viewing one of the two versions of the routedescription, the participants in the experiment hadto ?virtually traverse?
the route (to measure effec-tiveness of the route description) and were askedhow natural they found the route description.
Themost realistic way to measure effectiveness of theroute description would have been to have the partic-ipants walk the route in reality after having receivedthe description, as was done by Fujii et al (2000)and Michon and Denis (2001).
However, conduct-ing such an experiment is a very time consumingactivity.
As a more practical alternative we devel-oped a reconstructive method allowing participantsto traverse the route on the computer, instead of ina real (live) environment.
In this set-up, participants?traversed?
the route by viewing prerecorded routesegments, showing a moving scene from a first per-son perspective as if they walked through the streetsthemselves, accompanied by street sounds.
Apartfrom practical considerations, an additional advan-tage of this set-up is that it yields full control withrespect to repeatability and the participation settingbecause of its playback nature.Our hypotheses were as follows:1.
The 120?
version is more effective, i.e., yieldsa more successful traversal than its 180?
coun-terpart.2.
The 120?
version yields a more natural routedescription than its 180?
counterpart.4.1 ParticipantsA total of 49 participants were involved in the ex-periment, aged 20 to 64 years (with an average of 33years).
Since no participants were younger than 12or post 70, no specific effect of age on their spatialskills was expected (Hunt and Waller, 1999).
Sincegender is an influential factor in orientation and wayfinding (Hunt and Waller, 1999; Lawton, 1994), weused a 50% male - 50% female test population.
The120?
version of the route description was shown to13 male and 12 female participants; the 180?
versionto 11 male and 13 female participants.4.2 ProcedureThe experiment consisted of the following steps.Introduction - After reading an introductory textexplaining the experiment, the participant filled in apre-questionnaire asking for age, gender, and edu-cational level.
We also asked how familiar the par-ticipant was with the route location, indicated on a285-point scale ranging from not at all familiar (1) tovery familiar (5).
If the participant indicated beingmoderately or more familiar with the location, his orher results were discarded.
The questionnaire wasfollowed by an example question to familiarize theparticipant with the controls and with the set-up ofthe traversal part of the experiment.Route description - First, the participant wasshown a video impression of the location where heor she, being lost in an unfamiliar town, supposedlyapproached someone to ask the way to the hotel.Then the participant watched one of the two pre-recorded route descriptions.
To compensate for thefact that, unlike a real-life situation, there was noopportunity to verify understanding or ask for clar-ifications, the participants were allowed to play theroute description video twice.Traversal - After having received the route de-scription, the participant had to virtually traversethe route by watching six prerecorded traversal seg-ments in succession, appearing in a pop-up window.The first segment began at the starting point of theroute and ended at the first decision point (intersec-tion).
Each following segment started where the pre-vious one ended, with the final segment ending atthe destination of the route.
At the end of each routesegment, an overview of the next intersection wasprovided by moving the camera viewpoint gradu-ally so the entire intersection was shown.
The av-erage length of each traversal segment was around1.5 minutes.After watching each segment, the participant hadto select which direction to take next from a lim-ited set of options: left, straight ahead or right (ifapplicable).
Each option was accompanied with aphoto of the corresponding view from the crossing.After answering the question, the participant was in-formed which direction was correct.
Then the par-ticipant proceeded with the route traversal from thecorrect turn, regardless whether the correct directionhad been chosen or not.33This differs from the effectiveness measure of Fujii et al(2000), who used a movement failure rate defined as Out/N,with Out being the number of times a participant lost the wayand was unable to return to the route, and N being the numberof trials.
We found this method too complicated in design andtoo confusing for the participants to be used in this experiment.In our set-up, the participant was only allowed one trial per de-cision point and always traveled along the correct route.120?
180?
TotalMale 3.46 (0.88) 3.27 (1.19) 3.38 (1.01)Female 4.00 (1.04) 3.62 (0.77) 3.80 (0.91)Total 3.72 (0.98) 3.46 (0.98) 3.59 (0.98)Table 1: Number of correct decisions as a func-tion of gender and version (results are presented asMeans with Std.
Deviations in brackets).Post-questionnaire - After route traversal, theparticipants answered several questions about theroute description.
Here we only focus on one of thequestions, i.e., ?Do you think the route provider de-scribed the route in a natural way?
?, to be answeredon a 5-point scale ranging from very natural (1) tovery artificial (5).
The participants were also offeredthe opportunity to comment on their answer.5 Results and discussionHere we present and discuss the main findings fromour experiment.5.1 Effectiveness of the route descriptionHypothesis 1 concerned the influence of speaker ori-entation on the effectiveness of the route description.We measured this by counting the number of correctturns taken by the participants during route traver-sal.
The route contained five decision points (inter-sections), so participants?
scores ranged from 0 to 5correct turns.
Gender has been proved to strongly in-fluence way finding ability (Hunt and Waller, 1999;Lawton, 1994), so gender was accounted for as afixed factor in our analysis.The results are summarized in Table 1, whichshows that participants performed slightly better inthe 120?
version than in the 180?
version, and thatwomen performed slightly better than men.
How-ever, these differences were not significant; neitherfor version nor gender.
Thus, our first hypothesis isnot supported.This lack of effect might be taken as evidencethat gestures hardly play a role in conveying in-formation, so that a difference in their orientationwould not affect the route seeker?s mental process-ing of the route description.
It has been arguedthat the main function of gestures in conversationis not to transfer information to the interlocutor,but to facilitate the cognitive process of speaking29(Rime?
and Schiaratura, 1991; Morsella and Krauss,2004).
Still, though most spontaneous gestures maynot be produced for the interlocutor?s benefit, it hasbeen shown experimentally that people do make useof the information conveyed by gestures (Kendon,1994; Cassell et al, 1999; Kelly et al, 1999).
Thecommunicative power of gestures does seem to de-pend on the task and the type of gesture, however(Bangerter and Chevalley, 2007).
In fact, in our ex-periment the gestures were not essential for under-standing the route description.
All pointing gestureswere accompanied by explicit verbal descriptions ofthe corresponding landmarks and/or directions; inother words, the gestures were redundant with re-spect to speech.
So, regarded from a purely informa-tional point of view, these gestures were superfluousand the participants may have paid only limited at-tention to them or even consciously ignored them.This explanation is supported by the comments ofvarious participants who said they tried to focus onthe verbal instructions because the description wasextensive and they found the gestures distracting.We consciously limited the number of decisionpoints in the experiment to five, well within the 7?2range of short term memory, but for each decisionpoint the route provider not only mentioned the di-rection to take, but also one or two landmarks.
Fur-thermore, he gave some auxiliary hints of what to doin-between turns (Walk straight ahead until you seea traffic sign; there you keep walking straight ahead)and some more details.
In their comments, severalparticipants mentioned being distracted by too muchdetail in the description, and said they found the di-rections hard to remember.
As a consequence, someparticipants tended to ignore the gestures or lookaway from the computer screen altogether.
Obvi-ously, doing so would clearly impair the effect ofspeaker orientation to be demonstrated by the exper-iment.
On the other hand, not all participants ig-nored the gestures (at least not initially) as in the180?
version, some participants declared that theyfound the mirrored gestures annoying.5.2 Naturalness of the route descriptionIn Table 2, test results on the naturalness of the routedescription are shown for speaker orientation andgender.
Orientation had an almost-significant effecton participants?
judgement of naturalness (two-wayANOVA; F(1,45)=3.35, p=0.07 two-tailed).4 Theeffect would have been significant if it had been theother way around.
The effect of gender was not sig-nificant, and neither was the interaction of versionand gender.Contrary to our hypothesis, the participantsjudged the 180?
version as being more natural thanthe 120?
version.
This was contrary to what was ex-pected, because ?in the real world?
route providersand seekers tend to minimize the difference in theirorientation.
In fact, as mentioned above, severalparticipants reported being annoyed by the mirroredgestures in the 180?
version.
These contradictoryfindings suggest that it was not the route provider?sgestures or their orientation that were crucial forthe judgement on naturalness, but only whether theroute provider?s body was fully turned toward his au-dience ?
directly addressing them ?
or not.
This maybe the result of many previous confrontations withpresenters (human or other) displayed on televisionor computer screens, explaining things to an audi-ence.
Perhaps the natural tendency to make orienta-tions as similar as possible when explaining a routeto someone does not transfer to a situation where theroute is presented by somebody on a screen: a formof presentation in which we expect someone to befacing us.Furthermore, the fixed position of the camera dur-ing the route description may also have interferedwith its naturalness.
If the route provider points intosome direction, we tend to turn our heads to that di-rection, maybe in the assumption he will point atsome landmark that can help us orientate or navi-gate.
The fixed position of the camera, in contrastwith the adaptive orientation of the route provider,may have yielded an unnatural combination in thecase of the 120?
version of the route description.5.3 Gender effectsFor both versions of the route description, womenperformed better than men.
Although not signifi-cant, the difference in performance is sufficiently re-markable to merit some discussion.
We believe thedifference may be explained by the fact that womenand men employ different strategies for way find-4A two-tailed test was performed in spite of our one-sidedhypothesis 2, because the effect was contrary to what was ex-pected.30120?
180?
TotalMale 2.62 (1.26) 1.73 (0.91) 2.21 (1.18)Female 2.75 (1.14) 2.46 (1.13) 2.60 (1.12)Total 2.68 (1.18) 2.13 (1.08) 2.41 (1.15)Table 2: Naturalness as a function of gender and ver-sion (results are presented as Means with Std.
Devi-ations in brackets).ing (Hunt and Waller, 1999): women?s strategies aremost suited for tracking and piloting, whereas menuse strategies appropriate for navigation.
Trackingis a point-to-point way finding strategy that relies oninformation limited to environmental characteristicsalong the route.
Piloting combines these environ-mental characteristics with self-centered orientationand direction (e.g., ?When you?re facing the mainentrance, turn to the right?).
Navigation, on the otherhand, uses configurational information: routes arederived from knowledge of the surroundings of thedestination or its global position.
Thus, men tend topay attention to bearings while women often rely ondescriptions of control points and cues to the routesuch as landmarks (Lawton, 1994).Looking at the set-up of our experiment, we seethat it seems to favour a strategy of point-to-pointdecision making instead of relying on a more gen-eral and global sense of direction, as in naviga-tion.
First, the route description consisted entirelyof landmarks to identify decision points and turnsto be made when encountering them, fitting a track-ing and piloting approach to way finding.
Second,both the route description and the traversal segmentswere shown on a screen, with a restricted and forcedfield of vision.
This may have impeded the estima-tion of global position, direction and distance, i.e.,the kind of spatial knowledge men rely on for orien-tation and way finding.
So, the way finding strategythat women already tend to employ in everyday lifemay have been most suited to this experiment andhence their higher score.6 Conclusions and future workThe goal of this study was to find out which ori-entation of the Virtual Guide would be most ef-fective and natural for providing route descriptionsin a virtual environment.
To test effectiveness, wedevised a method that allowed participants to ?vir-tually?
traverse a route by watching pre-recordedroute segments and making turn decisions at inter-sections.
We hypothesized that a speaker orientationof 120?
with respect to the route seeker would re-sult in a more effective and natural route descriptionthan a 180?
orientation, because it would take theroute seeker less effort to match the speaker?s ges-tures with his or her own perspective.
However, wefound no effect of speaker orientation on task per-formance.
A possible explanation lies in the com-plexity of our route description, which caused someparticipants to focus only on the verbal part of thedescription.
Contrary to our expectation, the 180?orientation was judged to be more natural, in spiteof the fact that some participants found the mirroredgestures annoying.
The reason for this may be thatpeople expect a speaker to be directly facing themwhen presenting information on a screen.Based on these results, we decided to stick tothe standard 180?
orientation for our Virtual Guide.However, some reservations are in order when ap-plying the results of our study to the Virtual Guide.For one thing, the route descriptions used in the ex-periment were not given by an agent but by a realhuman, albeit pre-recorded.
This is still far fromthe situation in which an embodied agent is com-municating with a user by means of an interface.A second difference with the Virtual Guide lies inthe participant?s navigational control.
In the con-text of the Virtual Guide, the user can actively nav-igate through, and look around in, the environmentto be traversed.
In our experiment, the participants?view was restricted and forced by that of the camerawhich severely restricted their possibilities for ori-entation and navigation.An obvious line of future research is therefore torepeat our experiment with the Virtual Guide, andhave participants actually traverse the route by nav-igating through the 3D virtual environment, with to-tal freedom of movement.
This will make the traver-sal part more realistic and also more suitable formale way finding strategies, thus providing a bet-ter and more neutral measure for the effectiveness ofthe route description.
In addition, we expect that theparticipants will be less inclined to see the guide asa kind of TV presenter and more as a real presence,because they will (virtually) share the same 3D en-vironment with it.
This may lead the participants to31be less biased toward a 180?
orientation of the routeprovider.
Finally, all information not strictly nec-essary for way finding will be left out of the routedescription.
This includes landmarks located alongtraversal segments rather than at intersections, andinstructions to go ?straight ahead?
(which severalparticipants found confusing in the current experi-ment).
With a less complex description, participantsmay refrain from ignoring the gestures made by theroute provider and thereby be more susceptible tomanipulation of speaker orientation.AcknowledgementsThe authors would like to thank Mark Tempelmanand Job van den Wildenberg for their help withthe experiment.
The Virtual Guide was imple-mented by Dennis Hofs, Rieks op den Akker, Marcovan Kessel, Richard Korthuis and Martin Bouman.The research reported here was carried out withinthe context of the project ANGELICA (A Natural-language Generator for Embodied, Lifelike Con-versational Agents) sponsored by the NetherlandsOrganisation for Scientific Research, NWO (grantnumber 532.001.301).ReferencesA.
Bangerter and E. Chevalley.
2007.
Pointing anddescribing in referential communication: When arepointing gestures used to communicate?
In Proceed-ings of the Workshop on Multimodal Output Genera-tion (MOG 2007), pages 17?28.J.
Cassell, D. McNeill, and K.E.
McCullough.
1999.Speech-gesture mismatches: Evidence for one under-lying representation of linguistic and non-linguistic in-formation.
Pragmatics and Cognition, 7(1):1?33.R.
Dale, S. Geldof, and J. Prost.
2005.
Using natural lan-guage generation in automatic route description.
Jour-nal of Research and Practice in Information Technol-ogy, 37(1):89?105.K.
Fujii, S. Nagai, Y. Miyazaki, and K. Sugiyama.
2000.Navigation support in a real city using city metaphors.In T. Ishida and K. Isbister, editors, Digital Cities, Lec-ture Notes in Computer Science 1765, pages 338?349.Springer-Verlag, Berlin Heidelberg.D.
Hofs, R. op den Akker, and A. Nijholt.
2003.
Ageneric architecture and dialogue model for multi-modal interaction.
In P. Paggio, K. Jokinen, andA.
Jnsson, editors, Proceedings of the 1st Nordic Sym-posium on Multimodal Communication, volume 1,pages 79?91, Copenhagen.
CST Publication, Centerfor Sprogteknologi.E.
Hunt and D. Waller.
1999.
Orientation and wayfind-ing: A review.
ONR technical report N00014-96-0380, Office of Naval Research, Arlington, VA.S.
D. Kelly, D. Barr, R.B.
Church, and K. Lynch.
1999.Offering a hand to pragmatic understanding: The roleof speech and gesture in comprehension and memory.Journal of Memory and Language, 40:577?592.A.
Kendon.
1994.
Do gestures communicate?
a re-view.
Research on Language and Social Interaction,27(3):175?200.S.
Kopp, P. Tepper, K. Striegnitz, and J. Cassell.
in press.Trading spaces: How humans and humanoids usespeech and gesture to give directions.
In T. Nishida,editor, Engineering Approaches to Conversational In-formatics.
John Wiley and Sons.C.A.
Lawton.
1994.
Gender differences in wayfindingstrategies: Relationship to spatial ability and spatialanxiety.
Sex Roles, 30(11-12):765?779.P.
Michon and M. Denis.
2001.
When and why are vi-sual landmarks used in giving directions?
In D.R.Montello, editor, Spatial Information Theory.
Foun-dations of Geographic Information Science: Inter-national Conference, COSIT 2001, Lecture Notes inComputer Science 2205, pages 292?305.
Springer-Verlag, Berlin Heidelberg.E.
Morsella and R. Krauss.
2004.
The role of gestures inspatial working memory and speech.
American Jour-nal of Psychology, 117(3):251?270.B.
Rime?
and L. Schiaratura.
1991.
Gesture and speech.In R. Feldman and B.
Rime?, editors, Fundamentals ofNonverbal Behavior, pages 239?281.
Cambridge Uni-versity Press, Cambridge.A.L.
Shelton and T.P.
McNamara.
2004.
Spatial mem-ory and perspective taking.
Memory and Cognition,32(3):416?426.H.
van Welbergen, A. Nijholt, D. Reidsma, and J. Zwiers.2006.
Presenting in virtual worlds: Towards an archi-tecture for a 3d presenter explaining 2d-presented in-formation.
IEEE Intelligent Systems, 21(5):47?53.M.
White and T. Caldwell.
1998.
EXEMPLARS: Apractical, extensible framework for dynamic text gen-eration.
In Proceedings of the Ninth InternationalWorkshop on Natural Language Generation, pages266?275.32
