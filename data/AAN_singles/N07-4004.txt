NAACL HLT Demonstration Program, pages 7?8,Rochester, New York, USA, April 2007. c?2007 Association for Computational LinguisticsPOSSLT: A Korean to English Spoken Language Translation SystemDonghyeon Lee, Jonghoon Lee, Gary Geunbae LeeDepartment of Computer Science and EngineeringPohang University of Science & Technology (POSTECH)San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea{semko, jh21983, gblee}@postech.ac.krAbstractThe POSSLT 1  is a Korean to Englishspoken language translation (SLT) system.Like most other SLT systems, automaticspeech recognition (ASR), machine trans-lation (MT), and text-to-speech (TTS) arecoupled in a cascading manner in ourPOSSLT.
However, several novel tech-niques are applied to improve overalltranslation quality and speed.
Modelsused in POSSLT are trained on a traveldomain conversational corpus.1 IntroductionSpoken language translation (SLT) has becomemore important due to globalization.
SLT systemsconsist of three major components: automaticspeech recognition (ASR), statistical machinetranslation (SMT), text-to-speech (TTS).
Currently,most of SLT systems are developed in a cascadingmethod.
Simple SLT systems translate a single bestrecognizer output, but, translation quality can beimproved using the N-best hypotheses or latticeprovided by the ASR (Zhang et.
al., 2004; Saleemet.
al., 2004).In POSSLT, we used an N-best hypothesis re-ranking based on both ASR and SMT features, anddivided the language model of the ASR accordingto the specific domain situation.
To improve theKorean-English SMT quality, several new tech-1 POSSLT stands for POSTECH Spoken Language Transla-tion systemniques can be applied (Lee et.
al., 2006-b).
ThePOSSLT applies most of these techniques using apreprocessor.2 System DescriptionThe POSSLT was developed by integrating ASR,SMT, and TTS.
The system has a pipelined archi-tecture as shown in Fig.
1.
LM loader, preproces-sor and re-ranking module are newly developed toimprove the translation quality and speed forPOSSLT.Figure 1: Overview of POSSLT2.1 ASRThe system used HTK-based continuous speechrecognition engine properly trained for Korean.The acoustic model, lexical model and languagemodel of Korean are trained for conversationalcorpus.
The phonetic set for Korean has 48 pho-neme-like-units, and we used three-state tri-phonehidden Markov models and trigram language mod-7els.
Pronunciation lexicons are automatically builtby a Korean grapheme-to-phoneme (G2P) tool(Lee et.
al., 2006-a).
We used an eojeol2 as a basicrecognition unit for lexical and language models,because an eojeol-based recognition unit has thehigher accuracy than the morpheme-based one.The ASR produces the N-best hypotheses deter-mined through the decoding process, which areused as the input of SMT.2.2 SMTWe implemented a Korean-English phrase-basedSMT decoder based on Pharaoh (Koehn, 2004).The decoder needs a phrase translation model forthe Korean-English pair and a language model forEnglish.
We used the Pharaoh training module andGIZA++ (Och and Ney, 2000) to construct thephrase translation table.
For language modeling,SRILM toolkit (Stolcke, 2002) was used to build atrigram language model.2.3 TTSWe used Microsoft SAPI 5.1 TTS engine for Eng-lish TTS.
The final best translation is pronouncedusing the engine.2.4 LM LoaderIn cascading SLT systems, SMT coverage dependson the used ASR.
In order to increase the ASRcoverage, our system loads and unloads the ASRlanguage models dynamically.
In our system whichuses a travel corpus, language models are built forten domain situation categories such as an airport,a hotel, a shopping, etc.
Besides user utterances,user selection of the situation is needed as an inputto decide which language model have to be loadedin advance.
By using the divided language models,many benefits such as fast decoding, higher accu-racy and more coverage can be obtained.2.5 PreprocessorIn the Korean-English SMT task, there have beendeveloped several techniques for improving thetranslation quality such as changing spacing unitsinto morphemes, adding POS tag information, anddeleting useless words (Lee et.
al., 2006-b).2 Eojeol is a spacing unit in Korean and typically consists ofmore than one morpheme.However, for these techniques, Part-Of-Speech(POS) tagger is needed.
If the final analyzed formof an eojeol (in the form of a sequence of mor-phemes plus POS tags) is defined as a word in theASR lexicon, the transformed sentences are direct-ly generated by the ASR only, so POS tagger er-rors can be removed from the system.
Preprocessoralso removes useless words in SMT in the trans-formed sentences produced by the ASR.2.6 Re-ranking ModuleWe implemented a re-ranking module to make arobust SLT system against the speech recognitionerrors.
The re-ranking module uses several fea-tures: ASR acoustic model scores, ASR languagemodel scores, and SMT translation scores.
Finally,the re-ranking module sorts the N-best lists bycomparing the total scores.AcknowledgementsThis research was supported by the MIC (Ministry ofInformation and Communication), Korea, under theITRC (Information Technology Research Center) sup-port program supervised by the IITA (Institute of In-formation Technology Assessment; IITA-2005-C1090-0501-0018)ReferencesA.
Stolcke.
2002.
SRILM ?
An Extensible Language ModelingToolkit.
Proc.
of ICSLP.F.
J. Och and H. Ney.
2000.
Improved statistical alignmentmodels.
Proc.
of 38th Annual Meeting of the ACL, page440-447, Hongkong, China, October 2000.Jinsik Lee, Seungwon Kim, Gary Geunbae Lee.
2006-a.
Gra-pheme-to-Phoneme Conversion Using Automatically Ex-tracted Associative Rules for Korean TTS System.
Proc.
ofInterspeech-ICSLP.Jonghoon Lee, Donghyeon Lee, Gary Geunbae Lee.
2006-b.Improving Phrase-based Korean-English Statistical Ma-chine Translation.
Proc.
of Interspeech-ICSLP.P.
Koehn.
2004.
Pharaoh: A Beam Search Decoder forPhrase-based Statistical Machine Translation Models.Proc.
of AMTA, Washington DC.R.
Zhang, G. Kikui, H. Yamamoto, T. Watanabe, F. Soong,and W. K. Lo.
2004.
A unified approach in speech-to-speech translation: Integrating features of speech recogni-tion and machine translation.
Proc.
of Coling 2004, Geve-va.S.
Saleem, S. Chen Jou, S. Vogel, and T.Schultz.
2004.
Usingword lattice information for a tighter coupling in speechtranslation systems.
Proc.
of ICSLP 2004, Jeju, Korea.8
