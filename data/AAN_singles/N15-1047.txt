Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 441?451,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsActive Learning with Rationales for Text ClassificationManali Sharma, Di Zhuang and Mustafa BilgicDepartment of Computer ScienceIllinois Institute of TechnologyChicago, IL USA{msharm11, dzhuang3}@hawk.iit.edu and mbilgic@iit.eduAbstractWe present a simple and yet effective ap-proach that can incorporate rationales elicitedfrom annotators into the training of any off-the-shelf classifier.
We show that our sim-ple approach is effective for multinomial na?
?veBayes, logistic regression, and support vectormachines.
We additionally present an activelearning method tailored specifically for thelearning with rationales framework.1 IntroductionAnnotating documents for supervised learning is atedious, laborious, and time consuming task for hu-mans.
Given huge amounts of unlabeled documents,it is impractical for annotators to go over each doc-ument and provide a label.
To reduce the anno-tation time and effort, various approaches such assemi-supervised learning (Chapelle et al, 2006) thatutilizes both labeled and unlabeled data, and activelearning (Settles, 2012) that carefully chooses in-stances for annotation have been developed.
To fur-ther minimize the human effort, recent work lookedat eliciting domain knowledge, such as rationalesand feature annotations, from the annotators insteadof just the labels of documents.One of the bottlenecks in eliciting domain knowl-edge from annotators is that the traditional super-vised learning approaches cannot readily handle theelicited rich feedback.
To address this issue, manymethods have been developed that are classifier-specific.
Examples include knowledge-based neuralnetworks (e.g., (Towell and Shavlik, 1994), (Girosiand Chan, 1995), (Towell et al, 1990)), knowledge-based support vector machines (Fung et al, 2002),pooling multinomial na?
?ve Bayes (Melville andSindhwani, 2009), incorporating constraints into thetraining of na?
?ve Bayes (Stumpf et al, 2007), andconverting rationales and feature annotations intoconstraints for support vector machines (e.g., (Smallet al, 2011) and (Zaidan et al, 2007)).
Beingclassifier-specific limits their applicability when onewants to test a different classifier for his/her domain,necessitating an approach that can be utilized by sev-eral off-the-shelf classifiers.In this paper we present a simple and yet effectiveapproach that can incorporate the elicited rationalesin the form of feature annotations into the trainingof any off-the-shelf classifier.
We empirically showthat it is effective at incorporating rationales into thelearning of na?
?ve Bayes, logistic regression, and sup-port vector machines using four text categorizationdatasets.
We further discuss a novel active learn-ing strategy specifically geared towards the learningwith rationales framework and empirically show thatit improves over traditional active learning.The rest of the paper is organized as follows.
InSection 2, we provide a brief background on elicit-ing rationales in the context of active learning.
InSection 3, we describe our approach for incorpo-rating rationales into the training of classifiers andcompare learning without rationales and learningwith rationales.
In Section 4, we present an activelearning method using the learning with rationalesframework and present relevant results.
Finally, wediscuss limitations and future work in Section 5, re-lated work in Section 6, and conclude in Section 7.4412 BackgroundIn this section, we provide a brief background ondata annotation with rationales in the context of ac-tive learning and introduce the notation to be usedthroughout the paper.Let D be a set of document-label pairs ?x, y?,where the label (value of y) is known only for a smallsubset L ?
D of the documents: L = {?x, y?
}and the rest U = D \ L consists of the unlabeleddocuments: U = {?x, ??}.
We assume that eachdocument xiis represented as a vector of features(most commonly as a bag-of-words model with adictionary of predefined set of phrases, which canbe unigrams, bigrams, etc.
): xi, {fi1, fi2, ?
?
?
, fin}.Each feature fijrepresents the binary presence (orabsence), frequency, or tf-idf representation of theword/phrase j in document xi.
Each label y ?
Y isdiscrete-valued variable Y , {y1, y2, ?
?
?
, yl}.Typical greedy active learning algorithms itera-tively select a document ?x, ??
?
U , query a labelerfor its label y, and incorporate the new document?x, y?
into its training set L. This process continuesuntil a stopping criterion is met, usually until a givenbudget, B, is exhausted.In the learning with rationales framework, in ad-dition to querying for label yiof a document xi, theactive learner asks the labeler to provide a rationale,R(xi) for the chosen label.
The rationale in its mostgeneral form consists of a subset of the terms thatare present in xi: R(xi) = {fik: j ?
xi}.
Notethat there might be cases where the labeler cannotpinpoint any phrase as a rationale, in which caseR(xi) is allowed to be ?.
Algorithm 1 formally de-scribes the active learning process that elicits ratio-nales from the labeler.The goal of eliciting rationales is to improve thelearning efficiency by incorporating domain knowl-edge.
However, it is not trivial to integrate domainknowledge into state-of-the-art classifiers, such aslogistic regression and support vector machines.Next, we describe our approach for incorporatingrationales into the learning process.3 Learning with RationalesIn this section we first provide the formulation of ourapproach to incorporate rationales into learning andthen present the results to compare learning with-Algorithm 1 Active Learning with Rationales1: Input: U - unlabeled documents, L - labeleddocuments, ?
- underlying classification model,B - budget2: repeat3: x?= argmaxx?Uutility(x|?
)4: request label and rationale for this label5: L ?
L ?
{?x?, y?, R(x?)?
}6: U ?
U \ {?x??
}7: Train ?
on L8: until Budget B is exhausted; e.g., |L| = Bout rationales (Lw/oR) and learning with rationales(LwR) on four datasets.
We evaluate our approachusing multinomial na?
?ve Bayes, logistic regression,and support vector machines classifiers.3.1 Training a Classifier Using Labels andRationalesLike most previous work, we assume that the ra-tionales, i.e.
the phrases, returned by the labeleralready exist in the dictionary of the vectorizer.Hence, rationales correspond to features in our vec-tor representation.
It is possible that the labeler re-turns a phrase that is currently not in the dictionary;for example, the labeler might return a phrase thatconsists of three words whereas the representationhas single words and bi-grams only.
In that case,the representation can be enriched by creating andadding a new feature that represents the phrase re-turned by the labeler.Our simple approach works as follows: wemodify the features of the annotated document?x?, y?, R(x?)?
to emphasize the rationale(s) andde-emphasize the remaining phrases in that docu-ment.
We simply multiply the features correspond-ing to phrase(s) that are returned as rationale(s) byweight r and we multiply the remaining features inthe document by weight o, where r > o, and r ando are hyper-parameters.
The modified document be-comes:xi?= ?r ?
fij, ?fij?
R(xi); o?
fij,?fij/?
R(xi), ?
(1)Note that the rationales are tied to their docu-ments for which they were provided as rationales.One phrase might be a rationale for the label of one442document and yet it might not be the rationale forthe label of another document.
Hence, the featureweightings are done at the document level, ratherthan globally.
To illustrate this concept, we providean example dataset below with three documents.
Inthese documents, the words that are returned as ra-tionales are underlined.Document 1: This is a great movie.Document 2: The plot was great, but the perfor-mance of the actors was terrible.
Avoid it.Document 3: I?ve seen this at an outdoor cinema;great atmosphere.
The movie was terrific.As these examples illustrate, the word ?great?
ap-pears in all three documents, but it is marked as arationale only for Document 1.
Hence, we do notweight the rationales globally; rather, we modifyonly the labeled document using its particular ratio-nale.
Table 1 illustrates both the Lw/oR and LwRrepresentations for these documents.Table 1: The Lw/oR binary representation (top) and itsLwR transformation (bottom) for Documents 1, 2, and 3.Stop words are removed.
LwR multiplies the rationaleswith r and other features with o.greatmovieplotperformanceactorterribleavoidoutdoorcinemaatmosphereterrificLw/oR Representation (binary)D1 1 1D2 1 1 1 1 1 1D3 1 1 1 1 1 1LwR Transformation of the binary Lw/oR repr.D1 r oD2 o o o o r rD3 o o o o o rThis approach is simple, intuitive, and classifier-agnostic.
As we will show later, it is quite effec-tive empirically as well.
To gain a theoretical un-derstanding of this approach, consider the work onregularization: the aim is to build a sparse/simplemodel that can capture the most important featuresof the training data and thus have large weights forimportant features and small/zero weights for irrel-evant features.
For example, consider the gradientfor wjof feature fjfor logistic regression with l2regularization (assuming y is binary with 0/1):?wj= C??xl?Lflj?
(yl?P (y = 1|xl))?wj(2)where C is the complexity parameter that balancesbetween fit to the data and the model complexity.With our rationales framework, the gradient forwjwill be:?wj=C ????
?xl?L:flj?R(xl)r ?
flj?
(yl?
P (yl= 1|xl))+?xl?L:flj/?R(xl)o?
flj?
(yl?
P (yl= 1|xl))????
wj(3)In the above equation, a feature fjcontributes moreto the gradient of its weight wjwhen a documentin which it is marked as a rationale is misclassified.When fjappears in another document xkbut is nota rationale, it?s contribution to the gradient is mutedby o.
And hence, when r > o, this framework im-plicitly provides more granular (per instance-featurecombination) regularization by placing a higher im-portance on the contribution of the rationales versusnon-rationales in each document.1Note that in our framework the rationales are tiedto their own documents; that is, we do not weightrationales and non-rationales globally.
In additionto providing more granular regularization, this ap-proach has the benefit of allowing different ratio-nales to contribute differently to the objective func-tion of the trained classifier.
For example, considerthe case where the number of documents in whichone word fj(e.g., ?excellent?)
is marked as a ratio-nale is much more than the number of documentswhere another word fk(e.g., ?good?)
is marked as1The justification for our approach is similar for support vec-tor machines.
The idea is also similar for multinomial na?
?veBayes with Dirichlet priors ?j.
For a fixed Dirichlet prior with?
?1, ?2, ?
?
?
, ?n?
setting, when o < 1 for a feature fj, itscounts are smoothed more.443a rationale.
Then, the first sum in equation 3 willrange over more documents for the gradient of wjcompared to the gradient of wk, giving more impor-tance to wjthan to wk.
In the traditional featureannotation work, this can be achieved only if thelabeler can rank the features; even then, it is oftenvery difficult, if not impossible, for the labelers todetermine how much more important one feature iscompared to another.3.2 Experiments Comparing Lw/oR to LwRIn this section we first describe the settings, datasets,and classifiers used for our experiments and howwe simulated a human labeler to provide rationales.Then, we present the results comparing the learn-ing curves achieved with learning without rationales(Lw/oR) and learning with rationales (LwR).3.2.1 MethodologyFor this study, we used four text classificationdatasets.
The IMDB dataset consists of 25K moviereviews (Maas et al, 2011).
The SRAA2datasetconsists of 48K documents that discuss either autoor aviation.
Nova is a text classification dataset usedin active learning challenge (Guyon, 2011) and con-tains 12K documents.
WvsH is a 20 Newsgroups3dataset in which we use the Windows vs. hardwarecategories, and it contains 1176 documents.To make sure our approach works across repre-sentations, we experimented with both binary and tf-idf representations for these text datasets.
We eval-uated our strategy using multinomial na?
?ve Bayes,logistic regression, and support vector machines, asthese are strong classifiers for text classification.
Weused the scikit-learn (Pedregosa et al, 2011) imple-mentation of these classifiers with their default pa-rameter settings for our experiments.To compare various strategies, we used learn-ing curves.
The initially labeled dataset was boot-strapped using 10 documents by picking 5 randomdocuments from each class.
A budget (B) of 200documents was used in our experiments, becausemost of the learning curves flatten out after about200 documents.
We evaluated all the strategies us-ing AUC (Area Under an ROC Curve) measure.
The2http://people.cs.umass.edu/ mccallum/data.html3http://qwone.com/ jason/20Newsgroups/code to repeat our experiments is available at Githubhttp://www.cs.iit.edu/?ml/code/.While incorporating the rationales into learning,we set the weights for rationales and the remainingfeatures of a document as 1 and 0.01 respectively(i.e.
r = 1 and o = 0.01).
That is, we did notoveremphasize the features corresponding to ratio-nales but rather de-emphasized the remaining fea-tures in the document.
These weights worked rea-sonably well for all four datasets, across all threeclassifiers, and for both binary and tf-idf data repre-sentations.Obviously, these are not necessarily the bestweight settings one can achieve; the optimal settingsfor r and o depend on many factors, such as the ex-tent of the knowledge of the labeler (i.e., how manywords a labeler can recognize), how noisy the la-beler is, and how much labeled data we have in ourtraining set.
Ideally, one should have r >> o whenthe labeled data is small and r should be closer to owhen the labeled data is large; a more practical ap-proach would be to tune for these parameters (e.g.,cross-validation) at each step of the learning curve.However, in our experiments, we fixed r and o andwe found that most settings where r > o workedquite well.3.2.2 Simulating the Human ExpertLike most literature on feature labeling, we con-structed an artificial labeler to simulate a human la-beler.
Every time a document is annotated, we askedthe artificial labeler to mark a word as a rationale forthat document?s label.
We allowed the labeler to re-turn any one (and not necessarily the top one) of thepositive words as a rationale for a positive documentand any one of the negative words as a rationale fora negative document.
If the labeler did not recog-nize any of the words as positive (negative) in a pos-itive (negative) document, we let the labeler returnnothing as the rationale.
To make this as practical aspossible in a real-world setting, we constructed theartificial labeler to recognize only the most apparentwords in the documents.
For generating rationales,we chose only the positive (negative) features thathad the highest ?2(chi-squared) statistic in at least5% of the positive (negative) documents.
This re-sulted in an overly-conservative labeler that recog-nized only a tiny subset of the words.
For example,444the artificial labeler knew about only 49 words (23for one class and 26 for the other class) for IMDB,67 words (32 for one class and 35 for the other class)for SRAA, 95 words (42 for one class and 53 for theother class) for WvsH, and 111 words (31 for oneclass and 80 for the other class) for the Nova dataset.To determine whether the rationales selected bythis artificial labeler are meaningful, we printed outthe actual words used as rationales, and we ourselvesverified that these words are human-recognizablewords that could be naturally provided as rationalesfor classification.
For example, the positive termsfor the IMDB dataset included ?great?, ?excellent?,and ?wonderful?
and the negative terms included?worst?, ?bad?, and ?waste.
?3.2.3 ResultsNext, we compare Lw/oR to LwR.
Figure 1presents the learning curves for random samplingon four text classification datasets with binary andtf-idf representations and using multinomial na?
?veBayes, logistic regression, and support vector ma-chines.
Figure 1 shows that even though the arti-ficial labeler knew only about a tiny subset of thevocabulary, and returned any one word, rather thanthe top word or all the words, as rationale, LwR stilldrastically outperformed Lw/oR across all datasets,classifiers, and representations.
This shows that ourmethod for incorporating rationales into the learningprocess is empirically effective.We used the default complexity parameters forlogistic regression and support vector machinesand used Laplace smoothing for multinomial na??veBayes.
In our rationale framework, most featureswere non-rationales, and hence in Equation 3, mostfeatures appeared in the second summation term,with o = 0.01.
We tested whether the improve-ments that LwR provide over Lw/oR are simplydue to implicit higher regularization for most of thefeatures with o = 0.01, and hence experimentedwith equation 2 (which is Lw/oR) using C = 0.01.We observed that setting C = 0.01 and indis-criminately regularizing all the terms did not im-prove Lw/oR, further providing experimental evi-dence that the improvements provided by LwR arenot due to just higher regularization, but they are dueto a more fine-grained regularization, as explained inSection 3.1.Even though LwR provides huge benefits, pro-viding both a label and a rationale is expected totake more time of the labeler than simply provid-ing a label.
However, the improvements of LwRover Lw/oR is so huge that it might be worth spend-ing the extra time in providing rationales.
For ex-ample, in order to achieve a target AUC of 0.95for SRAA dataset (using tf-idf representation withMNB classifier), Lw/oR required labeling 656 doc-uments, whereas LwR required annotating a mere29 documents, which is 22.6 times reduction in thenumber of documents.
As another example, in or-der to achieve a target AUC of 0.8 for WvsH dataset(using binary representation with SVM classifier),Lw/oR required labeling 113 documents, whereasLwR achieved this target with only 13 documents.
(Zaidan et al, 2007) conducted user studies andshowed that providing 5 to 11 rationales and a classlabel per document takes roughly twice the time ofproviding only the label for the document.
(Ragha-van et al, 2006) also conducted user studies andshowed that labeling instances takes five times moretime than labeling features.
We worked with simu-lated user and showed that a document that is anno-tated with a label and a single rationale can be worthas many as 22 documents that are annotated withonly a label and thus these results suggest that LwR,compared to Lw/oR, can lead to significant time sav-ings for the annotator.4 Active Learning with RationalesSo far we have seen that LwR provides drastic im-provements over Lw/oR.
Both these strategies se-lected documents randomly for labeling.
Activelearning (Settles, 2012) aims to carefully choose in-stances for labeling to improve over random sam-pling.
Many successful active learning approacheshave been developed for instance labeling (e.g.
(Lewis and Gale, 1994), (Seung et al, 1992),(Roy and McCallum, 2001)), feature labeling (e.g.
(Druck et al, 2009)), and rotating between instanceand feature labeling (e.g.
(Raghavan and Allan,2007), (Druck et al, 2009), (Attenberg et al, 2010),(Melville and Sindhwani, 2009)).
In this section, weintroduce an active learning strategy that can utilizethe learning with rationales framework.4450.570.620.670.720.770.820.870 50 100 150 200AUCNumber of documentsIMDB - Multinomial Naive BayesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(a)0.570.620.670.720.770.820.870 50 100 150 200AUCNumber of documentsIMDB - Logistic RegressionLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(b)0.570.620.670.720.770.820.870 50 100 150 200AUCNumber of documentsIMDB - Support Vector MachinesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(c)0.770.820.870.920.970 50 100 150 200AUCNumber of documentsNOVA  - Multinomial Naive BayesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(d)0.770.820.870.920.970 50 100 150 200AUCNumber of documentsNOVA - Logistic RegressionLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(e)0.770.820.870.920.970 50 100 150 200AUCNumber of documentsNOVA  - Support Vector MachinesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(f)0.650.700.750.800.850.900.951.000 50 100 150 200AUCNumber of documentsSRAA - Multinomial Naive BayesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(g)0.650.700.750.800.850.900.951.000 50 100 150 200AUCNumber of documentsSRAA - Logistic RegressionLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(h)0.650.700.750.800.850.900.951.000 50 100 150 200AUCNumber of documentsSRAA - Support Vector MachinesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(i)0.600.650.700.750.800.850.900 50 100 150 200AUCNumber of documentsWvsH  - Multinomial Naive BayesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(j)0.620.670.720.770.820.870.920 50 100 150 200AUCNumber of documentsWvsH - Logistic RegressionLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(k)0.620.670.720.770.820.870.920 50 100 150 200AUCNumber of documentsWvsH  - Support Vector MachinesLw/R-tfidfLw/R-binaryLw/oR-tfidfLw/oR-binary(l)Figure 1: Comparison of Lw/oR with LwR.
LwR provides drastic improvements over Lw/oR for all datasets withbinary and tf-idf representations and using all three classifiers.4464.1 Active Learning to Select Documents basedon RationalesArguably, one of the most successful active learn-ing strategies for text categorization is uncertaintysampling, which was first introduced by (Lewis andCatlett, 1994) for probabilistic classifiers and laterformalized for support vector machines (Tong andKoller, 2001).
The idea is to label instances forwhich the underlying classifier is uncertain, i.e., theinstances that are close to the decision boundaryof the model.
It has been successfully applied totext classification tasks in numerous publications,including (Zhu and Hovy, 2007), (Sindhwani et al,2009), and (Segal et al, 2006).We adapt uncertainty sampling for the learningwith rationales framework.
To put simply, whenthe underlying model is uncertain about an unla-beled document, we look whether the unlabeled doc-ument contains words/phrases that were returned asrationales for any of the existing labeled documents.More formally, letR+denote the union of all the ra-tionales returned for the positive documents so far.Similarly, let R?denote the union of all the ratio-nales returned for the negative documents so far.
Anunlabeled document can be of these three types:1.
Type1: has no words in common with R+andR?.2.
Type2: has word(s) in common with either R+or R?but not both.3.
Type3: has at least one word in common withR+and at least one word in common with R?.One would imagine that labeling each of thetype1, type2, and type3 documents has its own ad-vantage.
Labeling type1 documents has the potentialto elicit new domain knowledge, i.e., terms that werenot provided as a rationale for any of the existinglabeled documents.
It also carries the risk of con-taining little to no useful information for the clas-sifier (e.g., a neutral review).
For type2 documents,even though the document shares a word that was re-turned as a rationale for another document, the clas-sifier is still uncertain about the document either be-cause that word is not weighted high enough by theclassifier and/or there are other words that pull theclassification decision in the other direction, makingthe classifier uncertain.
Type3 documents containconflicting words/phrases and are potentially hardercases, however, they also have the potential to re-solve the conflicts for the classifier.Building on our previous work (Sharma and Bil-gic, 2013) we devised an active learning approach,where given uncertain documents, the active learnerprefers instances of type3 over type1 and type2.We call this strategy as uncertain-prefer-conflict(UNC-PC) because type3 documents carry conflict-ing words (with respect to rationales) whereas type1and type2 do not.
The difference between this ap-proach and our previous work (Sharma and Bil-gic, 2013) is that in (Sharma and Bilgic, 2013), weselected uncertain instances based on model?s per-ceived conflict whereas in this work, we are se-lecting documents based on conflict caused by thedomain knowledge provided by the labeler.
Next,we compare the vanilla uncertainty sampling (UNC)and UNC-PC strategies using LwR to see if usinguncertain documents of type3 could improve activelearning.4.2 Active Learning with RationalesExperimentsWe used the same four text datasets and evalu-ated our method UNC-PC using multinomial na?
?veBayes, logistic regression, and support vector ma-chines.
For the active learning strategies, we useda bootstrap of 10 random documents, and labeledfive documents at each round of active learning.We used a budget of 200 documents for all meth-ods.
UNC simply picks the top five uncertain doc-uments, whereas UNC-PC looks at top 20 uncertaindocuments and picks five uncertain documents giv-ing preference to the conflicting cases (type 3) overthe non-conflicting cases (type1 and type2).
We re-peated each experiment 10 times starting with a dif-ferent bootstrap at each trial and report the averageresults.In Figure 2 we show the learning curves com-paring UNC-PC with UNC for multinomial na??veBayes.
(Logistic regression and SVM curves areomitted due to space.)
Since the results for LwRusing tf-idf representation are better than the re-sults using the binary representation, we comparedUNC-PC to UNC for LwR using only the tf-idfrepresentation.
We see that for multinomial na?
?ve447Bayes, UNC-PC improves over traditional uncer-tainty, UNC, on two datasets, and hurts performanceon one dataset.
Next, we discuss the significance re-sults for all classifiers.Table 2 shows the paired t-test results comparingthe learning curves of UNC-PC with the learningcurves of UNC at each step of the active learning(i.e, if the average of one learning curve is signifi-cantly better or worse than the average of the learn-ing curve of the other).
If UNC-PC has a higher av-erage AUC than UNC with a t-test significance levelof 0.05 or better, it is a Win (W), if it has signifi-cantly lower performance, it is a Loss (L), and if thedifference is not statistically significant, the result isa Tie (T).Using multinomial na?
?ve Bayes, UNC-PC winsover UNC for two of the datasets (IMDB andWvsH), does not cause any significant changes forNova (ties all the time), and loses for SRAA.
Usinglogistic regression, UNC-PC wins for two datasets(Nova and SRAA), ties for WvsH and loses forIMDB.
Using support vector machines, UNC-PCwins for three datasets (Nova, SRAA, and WvsH)and loses for IMDB.
The t-test results show thatUNC-PC often improves learning over UNC.Table 2: Significant W/T/L counts for UNC-PC versusUNC.
UNC-PC improves over UNC significantly for allthree classifiers and most of the datasets.UNC baseline MNB LR SVMUNC-PC 2/1/1 2/1/1 3/0/15 Limitations and Future WorkA limitation of our work is that we simulated the la-beler in our experiments.
Even though we simulatedthe labeler in a very conservative way (that is, oursimulated labeler knows only a few most apparentwords) and asked the simulated labeler to provideany one (rather than the top) rationale, a user studyis needed to i) experiment with potentially noisy la-belers, and ii) measure how much actual time savingLwR provides over Lw/oR.Another line of future work is to allow the la-beler to provide richer feedback.
This is especiallyuseful for resolving conflicts that stem from seem-ingly conflicting words and phrases.
For example,for the movie review ?The plot was great, but theperformance of the actors was terrible.
Avoid it.
?the word ?great?
is at odds with the words ?terri-ble?
and ?avoid?.
If the labeler is allowed to providericher feedback, saying that the word ?great?
refersto the plot, ?terrible?
refers to the performance, and?avoid?
refers to the movie, then the learner mightbe able to learn to resolve similar conflicts in otherdocuments.
However, this requires a conflict reso-lution mechanism in which the labeler can providerich feedback, and a learner that can utilize such richfeedback.
This is an exciting future research direc-tion that we would like to pursue.We showed that our strategy to incorporate ratio-nales works well for text classification.
The pro-posed framework can potentially be used for non-text domains where the domain experts can providerationales for their decisions, such as medical do-main where the doctor can provide a rationale forhis/her diagnosis and treatment decisions.
Each do-main is expected to have its own unique researchchallenges and working with other domains is an-other interesting future research direction.6 Related WorkThe closest related work deals with eliciting ratio-nales from users and incorporating them into thelearning (e.g., (Zaidan et al, 2007), (Donahue andGrauman, 2011), (Zaidan et al, 2008), and (Parkashand Parikh, 2012)).
However, much of this workis specific to a particular classifier, such as sup-port vector machines.
The framework we present isclassifier-agnostic and we have shown that it worksacross classifiers and feature representations.
Addi-tionally, we provide a novel active learning approachtailored for the learning with rationales framework.Another line of related work is the recent workon active learning with instance and feature annota-tions (e.g., (Melville and Sindhwani, 2009), (Drucket al, 2009), (Small et al, 2011), (Stumpf et al,2008), (Raghavan and Allan, 2007), and (Attenberget al, 2010)).
The main difference between the fea-ture annotation work and the learning with ratio-nales framework is that the feature annotations arenot tied to particular instances, whereas in the learn-ing with rationales framework, the documents andtheir rationales are coupled together.
Even though4480.720.740.760.780.800.820.840.860 50 100 150 200AUCNumber of documentsIMDB - Multinomial Naive BayesUNC-LwR-tfidfUNC-PC-LwR-tfidf(a)0.800.820.840.860.880.900.920.940.960 50 100 150 200AUCNumber of documentsNOVA - Multinomial Naive BayesUNC-LwR-tfidfUNC-PC-LwR-tfidf(b)0.880.900.920.940.960.981.000 50 100 150 200AUCNumber of documentsSRAA - Multinomial Naive BayesUNC-LwR-tfidfUNC-PC-LwR-tfidf(c)0.790.810.830.850.870.890.910 50 100 150 200AUCNumber of documentsWvsH - Multinomial Naive BayesUNC-LwR-tfidfUNC-PC-LwR-tfidf(d)Figure 2: Comparison of LwR using UNC and UNC-PC for all datasets with tf-idf representation and using multino-mial na?
?ve Bayes classifier.feature annotation work can be utilized for the learn-ing with rationales framework by decoupling ratio-nales from their documents, this is expected to re-sult in information loss (such as weighting featuresglobally rather than locally).
The precise effect ofdecoupling rationales and documents on the classi-fier performance still needs to be tested empirically.7 ConclusionWe introduced a novel framework to incorporate ra-tionales into active learning for text classification.Our simple strategy to incorporate rationales can uti-lize any off-the-shelf classifier.
The empirical eval-uations on four text datasets with binary and tf-idfrepresentations and three classifiers showed that ourproposed method utilizes rationales effectively.
Ad-ditionally, we presented an active learning strategythat is tailored specifically for the learning with ra-tionales framework and empirically showed that itimproved active learning.AcknowledgmentThis material is based upon work supported bythe National Science Foundation CAREER awardno.
1350337.449ReferencesJosh Attenberg, Prem Melville, and Foster Provost.
2010.A unified approach to active dual supervision for la-beling features and examples.
In European confer-ence on Machine learning and knowledge discovery indatabases, pages 40?55.Olivier Chapelle, Bernhard Sch?olkopf, and AlexanderZien, editors.
2006.
Semi-Supervised Learning.
MITPress, Cambridge, MA.Jeff Donahue and Kristen Grauman.
2011.
Annota-tor rationales for visual recognition.
In Computer Vi-sion (ICCV), 2011 IEEE International Conference on,pages 1395?1402.G.
Druck, B.
Settles, and A. McCallum.
2009.
Ac-tive learning by labeling features.
In Proceedings ofthe 2009 Conference on Empirical Methods in Natu-ral Language Processing: Volume 1-Volume 1, pages81?90.Glenn M Fung, Olvi L Mangasarian, and Jude W Shavlik.2002.
Knowledge-based support vector machine clas-sifiers.
In Advances in neural information processingsystems, pages 521?528.Federico Girosi and Nicholas Tung Chan.
1995.
Priorknowledge and the creation of virtual examples for rbfnetworks.
In Neural Networks for Signal Processing[1995] V. Proceedings of the 1995 IEEE Workshop,pages 201?210.Isabell Guyon.
2011.
Results of active learning chal-lenge.D.D.
Lewis and J. Catlett.
1994.
Heterogeneous uncer-tainty sampling for supervised learning.
In Proceed-ings of the eleventh international conference on ma-chine learning, pages 148?156.David D. Lewis and William A. Gale.
1994.
A sequentialalgorithm for training text classifiers.
In ACM SIGIRConference on Research and Development in Informa-tion Retrieval, pages 3?12.Andrew L Maas, Raymond E Daly, Peter T Pham, DanHuang, Andrew Y Ng, and Christopher Potts.
2011.Learning word vectors for sentiment analysis.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies-Volume 1, pages 142?150.Prem Melville and Vikas Sindhwani.
2009.
Active dualsupervision: Reducing the cost of annotating examplesand features.
In Proceedings of the NAACL HLT 2009Workshop on Active Learning for Natural LanguageProcessing, pages 49?57.Amar Parkash and Devi Parikh.
2012.
Attributes forclassifier feedback.
In Computer Vision?ECCV 2012,pages 354?368.
Springer.F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Prettenhofer,R.
Weiss, V. Dubourg, J. Vanderplas, A. Passos,D.
Cournapeau, M. Brucher, M. Perrot, and E. Duches-nay.
2011.
Scikit-learn: Machine learning in Python.Journal of Machine Learning Research, 12:2825?2830.Hema Raghavan and James Allan.
2007.
An interactivealgorithm for asking and incorporating feature feed-back into support vector machines.
In Proceedings ofthe 30th annual international ACM SIGIR conferenceon Research and development in information retrieval,pages 79?86.Hema Raghavan, Omid Madani, and Rosie Jones.
2006.Active learning with feedback on features and in-stances.
Journal of Machine Learning Research,7:1655?1686.Nicholas Roy and Andrew McCallum.
2001.
Toward op-timal active learning through sampling estimation oferror reduction.
In International Conference on Ma-chine Learning, pages 441?448.Richard Segal, Ted Markowitz, and William Arnold.2006.
Fast uncertainty sampling for labeling large e-mail corpora.
In Conference on Email and Anti-Spam.Burr Settles.
2012.
Active Learning.
Synthesis Lectureson Artificial Intelligence and Machine Learning.
Mor-gan & Claypool Publishers.H.
S. Seung, M. Opper, and H. Sompolinsky.
1992.Query by committee.
In ACM Annual Workshop onComputational Learning Theory, pages 287?294.Manali Sharma and Mustafa Bilgic.
2013.
Most-surelyvs.
least-surely uncertain.
In IEEE 13th InternationalConference on Data Mining, pages 667?676.Vikas Sindhwani, Prem Melville, and Richard DLawrence.
2009.
Uncertainty sampling and transduc-tive experimental design for active dual supervision.In Proceedings of the International Conference on Ma-chine Learning, pages 953?960.Kevin Small, Byron Wallace, Thomas Trikalinos, andCarla E Brodley.
2011.
The constrained weight spacesvm: learning with ranked features.
In Proceedings ofthe 28th International Conference on Machine Learn-ing (ICML-11), pages 865?872.Simone Stumpf, Vidya Rajaram, Lida Li, Margaret Bur-nett, Thomas Dietterich, Erin Sullivan, Russell Drum-mond, and Jonathan Herlocker.
2007.
Toward har-nessing user feedback for machine learning.
In Pro-ceedings of the 12th international conference on Intel-ligent user interfaces, pages 82?91.S.
Stumpf, E. Sullivan, E. Fitzhenry, I. Oberst, W.K.Wong, and M. Burnett.
2008.
Integrating rich userfeedback into intelligent user interfaces.
In Proceed-ings of the 13th international conference on Intelligentuser interfaces, pages 50?59.Simon Tong and Daphne Koller.
2001.
Support vec-tor machine active learning with applications to text450classification.
Journal of Machine Learning Research,2:45?66.Geoffrey G Towell and Jude W Shavlik.
1994.Knowledge-based artificial neural networks.
Artificialintelligence, 70(1):119?165.Geofrey G Towell, Jude W Shavlik, and Michiel No-ordewier.
1990.
Refinement of approximate domaintheories by knowledge-based neural networks.
In Pro-ceedings of the eighth National conference on Artifi-cial intelligence, pages 861?866.Omar Zaidan, Jason Eisner, and Christine D Piatko.2007.
Using?
annotator rationales?
to improve ma-chine learning for text categorization.
In HLT-NAACL,pages 260?267.Omar F Zaidan, Jason Eisner, and Christine Piatko.
2008.Machine learning with annotator rationales to reduceannotation cost.
In Proceedings of the NIPS* 2008Workshop on Cost Sensitive Learning.J.
Zhu and E. Hovy.
2007.
Active learning for word sensedisambiguation with methods for addressing the classimbalance problem.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 783?790.451
