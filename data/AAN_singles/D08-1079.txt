Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 755?762,Honolulu, October 2008. c?2008 Association for Computational LinguisticsAn Exploration of Document Impact on Graph-Based Multi-DocumentSummarizationXiaojun WanInstitute of Compute Science and TechnologyPeking UniversityBeijing 100871, Chinawanxiaojun@icst.pku.edu.cnAbstractThe graph-based ranking algorithm has beenrecently exploited for multi-document sum-marization by making only use of the sen-tence-to-sentence relationships in thedocuments, under the assumption that all thesentences are indistinguishable.
However,given a document set to be summarized, dif-ferent documents are usually not equally im-portant, and moreover, different sentences in aspecific document are usually differently im-portant.
This paper aims to explore documentimpact on summarization performance.
Wepropose a document-based graph model to in-corporate the document-level information andthe sentence-to-document relationship into thegraph-based ranking process.
Various meth-ods are employed to evaluate the two factors.Experimental results on the DUC2001 andDUC2002 datasets demonstrate that the goodeffectiveness of the proposed model.
More-over, the results show the robustness of theproposed model.1 IntroductionMulti-document summarization aims to produce asummary describing the main topic in a documentset, without any prior knowledge.
Multi-documentsummary can be used to facilitate users to quicklyunderstand a document cluster.
For example, anumber of news services (e.g.
NewsInEssence1)have been developed to group news articles intonews topics, and then produce a short summary foreach news topic.
Users can easily understand thetopic they have interest in by taking a look at theshort summary, without looking into each individ-ual article within the topic cluster.1http://lada.si.umich.edu:8080/clair/nie1/nie.cgiAutomated multi-document summarization hasdrawn much attention in recent years.
In the com-munities of natural language processing and infor-mation retrieval, a series of workshops andconferences on automatic text summarization (e.g.NTCIR, DUC), special topic sessions in ACL,COLING, and SIGIR have advanced the summari-zation techniques and produced a couple of ex-perimental online systems.A particular challenge for multi-document sum-marization is that a document set might containdiverse information, which is either related or un-related to the main topic, and hence we need effec-tive summarization methods to analyze theinformation stored in different documents and ex-tract the globally important information to reflectthe main topic.
In recent years, both unsupervisedand supervised methods have been proposed toanalyze the information contained in a documentset and extract highly salient sentences into thesummary, based on syntactic or statistical features.Most recently, the graph-based models havebeen successfully applied for multi-documentsummarization by making use of the ?voting?
or?recommendations?
between sentences in thedocuments (Erkan and Radev, 2004; Mihalcea andTarau, 2005; Wan and Yang, 2006).
The modelfirst constructs a directed or undirected graph toreflect the relationships between the sentences andthen applies the graph-based ranking algorithm tocompute the rank scores for the sentences.
Thesentences with large rank scores are chosen intothe summary.
However, the model makes uniformuse of the sentences in different documents, i.e.
allthe sentences are ranked without considering thedocument-level information and the sentence-to-document relationship.
Actually, given a documentset, different documents are not equally important.For example, the documents close to the main top-ics of the document set are usually more importantthan the documents far away from the main topics755of the document set.
This document-level informa-tion is deemed to have great impact on the sen-tence ranking process.
Moreover, the sentences inthe same document cannot be treated uniformly,because some sentences in the document are moreimportant than other sentences because of theirdifferent positions in the document or differentdistances to the document?s centroid.
In brief, nei-ther the document-level information nor the sen-tence-to-document relationship has been taken intoaccount in the previous graph-based model.In order to overcome the limitations of the pre-vious graph-based model, this study proposes thedocument-based graph model to explore documentimpact on the graph-based summarization, by in-corporating both the document-level informationand the sentence-to-document relationship in thegraph-based ranking process.
We develop variousmethods to evaluate the document-level informa-tion and the sentence-to-document relationship.Experiments on the DUC2001 and DUC2002 data-sets have been performed and the results demon-strate the good effectiveness of the proposed model,i.e., the incorporation of document impact canmuch improve the performance of the graph-basedsummarization.
Moreover, the proposed model isrobust with respect to most incorporation schemes.The rest of this paper is organized as follows.We first introduce the related work in Section 2.The basic graph-based summarization model andthe proposed document-based graph model are de-scribed in detail in Sections 3 and 4, respectively.We show the experiments and results in Section 5and finally we conclude this paper in Section 6.2 Related WorkGenerally speaking, summarization methods canbe abstractive summarization or extractive summa-rization.
Extractive summarization is a simple butrobust method for text summarization and it in-volves assigning saliency scores to some units (e.g.sentences, paragraphs) of the documents and ex-tracting those with highest scores, while abstrac-tion summarization usually needs informationfusion (Barzilay et al, 1999), sentence compres-sion (Knight and  Marcu, 2002) and reformulation(McKeown et al, 1999).
In this study, we focus onextractive summarization.The centroid-based method (Radev et al, 2004)is one of the most popular extractive summariza-tion methods.
MEAD2 is an implementation of thecentroid-based method that scores sentences basedon sentence-level and inter-sentence features, in-cluding cluster centroids, position, TFIDF, etc.NeATS (Lin and Hovy, 2002) is a project on multi-document summarization at ISI based on the sin-gle-document summarizer-SUMMARIST.
Sen-tence position, term frequency, topic signature andterm clustering are used to select important content.MMR (Goldstein et al, 1999) is used to removeredundancy and stigma word filters and timestamps are used to improve cohesion and coher-ence.
To further explore user interface issues,iNeATS (Leuski et al, 2003) is developed basedon NeATS.
XDoX (Hardy et al, 1998) is a crossdocument summarizer designed specifically tosummarize large document sets.
It identifies themost salient themes within the set by passage clus-tering and then composes an extraction summary,which reflects these main themes.
Much otherwork also explores to find topic themes in thedocuments for summarization, e.g.
Harabagiu andLacatusu (2005) investigate five different topicrepresentations and introduce a novel representa-tion of topics based on topic themes.
In addition,Marcu (2001) selects important sentences based onthe discourse structure of the text.
TNO?s system(Kraaij et al, 2001) scores sentences by combininga unigram language model approach with a Bayes-ian classifier based on surface features.
Nenkovaand Louis (2008) investigate how summary lengthand the characteristics of the input influence thesummary quality in multi-document summarization.Graph-based models have been proposed to ranksentences or passages based on the PageRank algo-rithm (Page et al, 1998) or its variants.
Websumm(Mani and Bloedorn, 2000) uses a graph-connectivity model and operates under the assump-tion that nodes which are connected to many othernodes are likely to carry salient information.
Lex-PageRank (Erkan and Radev, 2004) is an approachfor computing sentence importance based on theconcept of eigenvector centrality.
It constructs asentence connectivity matrix and compute sentenceimportance based on an algorithm similar to Pag-eRank.
Mihalcea and Tarau (2005) also propose asimilar algorithm based on PageRank to computesentence importance for document summarization.Wan and Yang (2006) improve the ranking algo-2 http://www.summarization.com/mead/756rithm by differentiating intra-document links andinter-document links between sentences.
All thesemethods make use of the relationships betweensentences and select sentences according to the?votes?
or ?recommendations?
from theirneighboring sentences, which is similar to PageR-ank.Other related work includes topic-focused multi-document summarization (Daum?.
and Marcu,2006; Gupta et al, 2007; Wan et al, 2007), whichaims to produce summary biased to a given topicor query.
It is noteworthy that our proposed ap-proach is inspired by (Liu and Ma, 2005), whichproposes the Conditional Markov Random WalkModel based on two-layer web graph in the tasksof web page retrieval.3 The Basic Graph-Based Model (GM)The basic graph-based model is essentially a wayof deciding the importance of a vertex within agraph based on global information recursivelydrawn from the entire graph.
The basic idea is thatof ?voting?
or ?recommendation?
between the ver-tices.
A link between two vertices is considered asa vote cast from one vertex to the other vertex.
Thescore associated with a vertex is determined by thevotes that are cast for it, and the score of the verti-ces casting these votes.Figure 1.
One-layer link graphFormally, given a document set D, let G=(V, E) bean undirected graph to reflect the relationships be-tween sentences in the document set, as shown inFigure 1.
V is the set of vertices and each vertex viin V is a sentence in the document set.
E is the setof edges.
Each edge eij in E is associated with anaffinity weight f(vi, vj) between sentences vi and vj(i?j).
The weight is computed using the standardcosine measure between the two sentences.jijijiineji vvvvvvsimvvf rrrr?
?== ),(),( cos(1)where ivr  and jvr are the corresponding term vec-tors of vi and vj.
Here, we have f(vi, vj)=f(vj, vi).Two vertices are connected if their affinity weightis larger than 0 and we let f(vi, vi)=0 to avoid selftransition.We use an affinity matrix M to describe G witheach entry corresponding to the weight of an edgein the graph.
M = (Mi,j)|V|?|V| is defined as follows:otherwise0;  andconnected is  and if),(?????
?=,jiv v,   vvfMjijii,j(2)Then M is normalized to M~ as follows to makethe sum of each row equal to 1:??????=?
?==otherwise00if~|V|1|V|1,M ,   MMM ji,jji,ji,ji,j(3)Based on matrix M~ , the saliency score Sen-Score(vi) for sentence vi can be deduced from thoseof all other sentences linked with it and it can beformulated in a recursive form as in the PageRankalgorithm:???+?
?=iall jj,iji VMvSenScorevSenScore||)1(~)()( ??
(4)And the matrix form is:eV?M?
T rrr||)1(~ ??
?+=   (5)where 1||)]([ ?= VivSenScore?ris the vector of sen-tence saliency scores.
er  is a vector with all ele-ments equaling to 1. ?
is the damping factorusually set to 0.85, as in the PageRank algorithm.The above process can be considered as aMarkov chain by taking the sentences as the statesand the corresponding transition matrix is givenby TT ee|V|MA rr)1(~ ??
?+= .
The stationary prob-ability distribution of each state is obtained by theprincipal eigenvector of the transition matrix.For implementation, the initial scores of all sen-tences are set to 1 and the iteration algorithm inEquation (4) is adopted to compute the new scoresof the sentences.
Usually the convergence of theiteration algorithm is achieved when the differencebetween the scores computed at two successiveiterations for any sentences falls below a giventhreshold (0.0001 in this study).We can see that the basic graph-based model isbuilt on the single-layer sentence graph and thetransition probability between two sentences in theMarkov chain depends only on the sentences them-selves, not taking into account the document-levelinformation and the sentence-to-document rela-tionship.ESentences7574 The Document-Based Graph Model(DGM)4.1 OverviewAs we mentioned in previous section, there may bemany factors that can have impact on the impor-tance analysis of the sentences.
This study aims toexamine the document impact by incorporating thedocument importance and the sentence-to-document correlation into the sentence rankingprocess.
Our assumption is that the sentences, whi-ch belong to an important document and are highlycorrelated with the document, will be more likelyto be chosen into the summary.In order to incorporate the document-level in-formation and the sentence-to-document relation-ship, the document-based graph model is proposedbased on the two-layer link graph including bothsentences and documents.
The novel representationis shown in Figure 2.
As can be seen, the lowerlayer is just the traditional link graph between sen-tences that has been well studied in previous work.And the upper layer represents the documents.
Thedashed lines between these two layers indicate theconditional influence between the sentences andthe documents.Figure 2.
Two-layer link graphFormally, the new representation for the two-layer graph is denoted as G*=<Vs, Vd, Ess, Esd>,where Vs=V={vi} is the set of sentences andVd=D={dj} is the set of documents; Ess=E={eij|vi,vj?Vs} includes all possible links between sen-tences and Esd={eij|vi?Vs, dj?Vd and dj=doc(vi)}includes the correlation link between any sentenceand its belonging document.
Here, we use doc(vi)to denote the document containing sentence vi.
Forfurther discussions, we let ?
(doc(vi)) ?
[0,1] de-note the importance of document doc(vi) in thedocument set, and let ?
(vi, doc(vi)) ?
[0,1] denotethe strength of the correlation between sentence viand its document doc(vi).The two factors are incorporated into the affinityweight between sentences and the new sentence-to-sentence affinity weight is denoted as f(vi, vj|doc(vi),doc(vj)), which is conditioned on the two docu-ments containing the two sentences.
The new con-ditional affinity weight is computed by linearlycombining the affinity weight conditioned on thefirst document (i.e.
f(vi,vj|doc(vi))) and the affinityweight conditioned on the second document (i.e.f(vi,vj|doc(vj))).Formally, the conditional affinity weight iscomputed as follows to incorporate the two factors:)))(,())(()1())(,())(((),()))(,())(()1())(,())(((),())(,())((),()1())(,())((),())(|,()1())(|,())(),(|,(cosjjjiiijiinejjjiiijijjjjiiiijijjiijijijivdocvvdocvdocvvdocvvsimvdocvvdocvdocvvdocvvfvdocvvdocvvfvdocvvdocvvfvdocvvfvdocvvfvdocvdocvvf???????????????????????+???=???+???=????+???=?
?+?=(6)where ??
[0,1] is the combination weight control-ling the relative contributions from the first docu-ment and the second document.
Note that usuallyf(vi, vj|doc(vi), doc(vj)) is not equal to f(vj, vi|doc(vj),doc(vi)), but the two scores are equal when ?
is setto 0.5.
Various methods can be used to evaluate thedocument importance and the sentence-documentcorrelation, which will be described in next sec-tions.The new affinity matrix M* is then constructedbased on the above conditional sentence-to-sentence affinity weight.otherwise0andconnected is   and ifif))(),(|,(*?????
?=,jiv v ,   vdocvdocvvfMjijijii,j(7)Likewise, M* is normalized to *~M  and the itera-tive computation as in Equation (4) is then basedon *~M .
The transition matrix in the Markov chainis then denoted by TT ee|V|MA rr)1(~ ** ??
?+=  andthe sentence scores is obtained by the principleeigenvector of the new transition matrix A*.4.2 Evaluating Document Importance (?
)The function ?
(doc(vi)) aims to evaluate the impor-tance of document doc(vi) in the document set D.The following three methods are developed toevaluate the document importance.SentencesDocumentsEsdEss758?1: It uses the cosine similarity value betweenthe document and the whole document set as theimportance score of the document3:)),(())(( cos1 Dvdocsimvdoc iinei =?
(8)?2: It uses the average similarity value betweenthe document and any other document in thedocument set as the importance score of the docu-ment:1||)'),(())(( )('  and  'cos2?=??
?Ddvdocsimvdoc ivdocdDdiinei?
(9)?3: It constructs a weighted graph between docu-ments and uses the PageRank algorithm to com-pute the rank scores of the documents as theimportance scores of the documents.
The linkweight between two documents is computed usingthe cosine measure.
The equation for iterativecomputation is the same with Equation (4).4.3 Evaluating Sentence-Document Cor-relation (?
)The function ?
(vi, doc(vi)) aims to evaluate thecorrelation between sentence vi and its documentdoc(vi).
The following four methods are developedto compute the strength of the correlation.
The firstthree methods are based on sentence position in thedocument, under the assumption that the first sen-tences in a document are usually more importantthan other sentences.
The last method is based onthe content similarity between the sentence and thedocument.
?1: The correlation strength between sentence viand its document doc(vi) is based on the position ofthe sentence as follows:???
?=Otherwise  5.03)( if  1))(,(1iiivposvdocv?
(10)where pos(vi) returns the position number of sen-tence vi in its document.
For example, if vi is thefirst sentence in its document, pos(vi) is 1.?2: The correlation strength between sentence viand its document doc(vi) is based on the position ofthe sentence as follows:))((_1)(1))(,(2iiii vdoccountsenvposvdocv??=?
(11)where sen_count(doc(vi)) returns the total numberof sentences in document doc(vi).3 A document set is treated as a single text by concatenatingall the document texts in the set.
?3: The correlation strength between sentence viand its document doc(vi) is based on the position ofthe sentence as follows:1)(15.0))(,(3 ++=iii vposvdocv?
(12)?4: The correlation strength between sentence viand its document doc(vi) is based on the cosinesimilarity between the sentence and the document:))(,())(,( cos4 iiineii vdocvsimvdocv =?
(13)5 Empirical Evaluation5.1 Dataset and Evaluation MetricGeneric multi-document summarization has beenone of the fundamental tasks in DUC 20014 andDUC 20025 (i.e.
task 2 in DUC 2001 and task 2 inDUC 2002), and we used the two tasks for evalua-tion.
DUC2001 provided 30 document sets andDUC 2002 provided 59 document sets (D088 isexcluded from the original 60 document sets byNIST) and generic abstracts of each document setwith lengths of approximately 100 words or lesswere required to be created.
The documents werenews articles collected from TREC-9.
The sen-tences in each article have been separated and thesentence information has been stored into files.The summary of the two datasets are shown in Ta-ble 1.DUC 2001 DUC 2002Task Task 2 Task 2Number of documents 309 567Number of clusters 30 59Data source TREC-9 TREC-9Summary length 100 words 100 wordsTable 1.
Summary of datasetsWe used the ROUGE (Lin and Hovy, 2003)toolkit (i.e.
ROUGEeval-1.4.2 in this study) forevaluation, which has been widely adopted byDUC for automatic summarization evaluation.
Itmeasured summary quality by counting overlap-ping units such as the n-gram, word sequences andword pairs between the candidate summary and thereference summary.
ROUGE-N was an n-gramrecall measure computed as follows:?
??
??
??
??
?=?Sum} {RefSum} {Ref)(S Sn-gramS Sn-grammatchgram)Count(ngramnCountNROUGE(14)4 http://www-nlpir.nist.gov/projects/duc/guidelines/2001.html5 http://www-nlpir.nist.gov/projects/duc/guidelines/2002.html759where n stood for the length of the n-gram, andCountmatch(n-gram) was the maximum number ofn-grams co-occurring in a candidate summary anda set of reference summaries.
Count(n-gram) wasthe number of n-grams in the reference summaries.ROUGE toolkit reported separate scores for 1, 2,3 and 4-gram, and also for longest common subse-quence co-occurrences.
Among these differentscores, unigram-based ROUGE score (ROUGE-1)has been shown to agree with human judgmentmost (Lin and Hovy.
2003).
We showed three ofthe ROUGE metrics in the experimental results:ROUGE-1 (unigram-based), ROUGE-2 (bigram-based), and ROUGE-W (based on weighted long-est common subsequence, weight=1.2).
In order totruncate summaries longer than length limit, weused the ?-l?
option in ROUGE toolkit.
We alsoused the ?-m?
option for word stemming.5.2 Evaluation ResultsIn the experiments, the combination weight ?
forthe proposed summarization model is typically setto 0.5 without tuning, i.e.
the two documents fortwo sentences have equal influence on the summa-rization process.
Note that after the saliency scoresof sentences have been obtained, a greedy algo-rithm (Wan and Yang, 2006) is applied to removeredundancy and finally choose both informativeand novel sentences into the summary.
The algo-rithm is actually a variant version of the MMR al-gorithm (Goldstein et al, 1999).The proposed document-based graph model (de-noted as DGM) with different settings is comparedwith the basic graph-based Model (denoted as GM),the top three performing systems and two baselinesystems on DUC2001 and DUC2002, respectively.The top three systems are the systems with highestROUGE scores, chosen from the performing sys-tems on each task respectively.
The lead baselineand coverage baseline are two baselines employedin the generic multi-document summarization tasksof DUC2001 and DUC2002.
The lead baselinetakes the first sentences one by one in the lastdocument in the collection, where documents areassumed to be ordered chronologically.
And thecoverage baseline takes the first sentence one byone from the first document to the last document.Tables 2 and 3 show the comparison results onDUC2001 and DUC2002, respectively.
In Table 1,SystemN, SystemP and System T are the top threeperforming systems for DUC2001.
In Table 2, Sys-tem19, System26, System28 are the top three per-forming systems for DUC2002.
The document-based graph model is configured with differentsettings (i.e.
?1-?3, ?1-?4).
For example,DGM(?1+?1) refers to the DGM model with ?1 toevaluate the document importance and ?1 to evalu-ate the correlation between a sentence and its docu-ment.System ROUGE-1 ROUGE-2 ROUGE-WDGM(?1+?1) 0.35658 0.05926 0.10712DGM(?1+?2) 0.35945 0.06304* 0.10820DGM(?1+?3) 0.36349* 0.06472* 0.10952DGM(?1+?4) 0.35421 0.05934 0.10695DGM(?2+?1) 0.35555 0.06554* 0.10924DGM(?2+?2) 0.37228* 0.06787* 0.11295*DGM(?2+?3) 0.37347* 0.06612* 0.11352*DGM(?2+?4) 0.36340 0.06397* 0.11006DGM(?3+?1) 0.35333 0.06353* 0.10834DGM(?3+?2) 0.37082* 0.06708* 0.11235DGM(?3+?3) 0.37056* 0.06503* 0.11227*DGM(?3+?4) 0.36667* 0.06585* 0.11114GM 0.35527 0.05608 0.10641SystemN 0.33910 0.06853 0.10240SystemP 0.33332 0.06651 0.10068SystemT 0.33029 0.07862 0.10215Coverage 0.33130 0.06898 0.10182Lead 0.29419 0.04033 0.08880Table 2.
Comparison results on DUC2001System ROUGE-1 ROUGE-2 ROUGE-WDGM(?1+?1) 0.37891 0.08398 0.12390DGM(?1+?2) 0.39013* 0.08770* 0.12726*DGM(?1+?3) 0.38490* 0.08355 0.12570DGM(?1+?4) 0.38464 0.08371 0.12443DGM(?2+?1) 0.38296 0.08369 0.12499DGM(?2+?2) 0.38143 0.08792* 0.12506DGM(?2+?3) 0.38177 0.08624* 0.12511DGM(?2+?4) 0.38576* 0.08167 0.12611DGM(?3+?1) 0.38079 0.08391 0.12392DGM(?3+?2) 0.38103 0.08608* 0.12446DGM(?3+?3) 0.38236 0.08675* 0.12478DGM(?3+?4) 0.38719* 0.08150 0.12633*GM 0.37595 0.08304 0.12173System26 0.35151 0.07642 0.11448System19 0.34504 0.07936 0.11332System28 0.34355 0.07521 0.10956Coverage 0.32894 0.07148 0.10847Lead 0.28684 0.05283 0.09525Table 3.
Comparison results on DUC2002(* indicates that the improvement over the baseline GMmodel is statistically significant at 95% confidence level)Seen from the tables, the proposed document-based graph model with different settings can out-perform the basic graph-based model and otherbaselines over almost all three metrics on both760DUC2001 and DUC2002 datasets.
The resultsdemonstrate the good effectiveness of the proposedmodel, i.e.
the incorporation of document impactdoes benefit the graph-based summarization model.It is interesting that the three methods for comput-ing document importance and the four methods forcomputing the sentence-document correlation arealmost as effective as each other on the DUC2002dataset.
However, ?1 does not perform as well as ?2and ?3, and ?1 and ?4 does not perform as well as?2 and ?3 on the DUC2001 dataset.In order to investigate the relative contributionsfrom the two documents for two sentences to thesummarization performance, we varies the combi-nation weight ?
from 0 to 1 and Figures 3-6 showthe ROUGE-1 and ROUGE-W curves onDUC2001 and DUC2002 respectively.
The similarROUGE-2 curves are omitted here.0.350.3550.360.3650.370.3750 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-1DGM(?1+?1)DGM(?1+?2)DGM(?1+?3)DGM(?1+?4)DGM(?2+?1)DGM(?2+?2)DGM(?2+?3)DGM(?2+?4)DGM(?3+?1)DGM(?3+?2)DGM(?3+?3)DGM(?3+?4)GMFigure 3.
ROUGE-1 vs. ?
on DUC20010.1040.1060.1080.110.1120.1140 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-WDGM(?1+?1)DGM(?1+?2)DGM(?1+?3)DGM(?1+?4)DGM(?2+?1)DGM(?2+?2)DGM(?2+?3)DGM(?2+?4)DGM(?3+?1)DGM(?3+?2)DGM(?3+?3)DGM(?3+?4)GMFigure 4.
ROUGE-W vs. ?
on DUC20010.370.3750.380.3850.390.3950 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-1DGM(?1+?1)DGM(?1+?2)DGM(?1+?3)DGM(?1+?4)DGM(?2+?1)DGM(?2+?2)DGM(?2+?3)DGM(?2+?4)DGM(?3+?1)DGM(?3+?2)DGM(?3+?3)DGM(?3+?4)GMFigure 5.
ROUGE-1 vs. ?
on DUC20020.120.1210.1220.1230.1240.1250.1260.1270.1280.1290 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-WDGM(?1+?1)DGM(?1+?2)DGM(?1+?3)DGM(?1+?4)DGM(?2+?1)DGM(?2+?2)DGM(?2+?3)DGM(?2+?4)DGM(?3+?1)DGM(?3+?2)DGM(?3+?3)DGM(?3+?4)GMFigure 6.
ROUGE-W vs. ?
on DUC2002We can see from the figures that the proposeddocument-based graph model with different set-tings can almost always outperform the basicgraph-based model, with respect to different valuesof ?.
The results show the robustness of the pro-posed model.
We can also see that for most set-tings of the propose model, very large values orvery small values of ?
can deteriorate the summari-zation performance, i.e.
both the first documentand the second document in the computation of theconditional affinity weight between sentences havegreat impact on the summarization performance.6 Conclusion and Future WorkThis paper examines the document impact on thegraph-based model for multi-document summari-zation.
The document-level information and thesentence-to-document relationship are incorporatedinto the graph-based ranking algorithm.
The ex-perimental results on DUC2001 and DUC2002demonstrate the good effectiveness of the proposedmodel.761In this study, we directly make use of the coarse-grained document-level information.
Actually, adocument can be segmented into a few subtopicpassages by using the TextTiling algorithm (Hearst,1997), and we believe the subtopic passage is morefine-grained than the original document.
In futurework, we will exploit this kind of subtopic-levelinformation to further improve the summarizationperformance.AcknowledgmentsThis work was supported by the National ScienceFoundation of China (No.60703064), the ResearchFund for the Doctoral Program of Higher Educa-tion of China (No.20070001059) and the NationalHigh Technology Research and Development Pro-gram of China (No.2008AA01Z421).
We alsothank the anonymous reviewers for their usefulcomments.ReferencesR.
Barzilay,  K. R. McKeown and M. Elhadad.
1999.Information fusion in the context of multi-documentsummarization.
In Proceedings of ACL1999.H.
Daum?
and D. Marcu.
2006.
Bayesian query-focusedsummarization.
2006.
In Proceedings of COLING-ACL2006.G.
Erkan and D. Radev.
2004.
LexPageRank: prestige inmulti-document text summarization.
In Proceedingsof EMNLP?04.J.
Goldstein, M. Kantrowitz, V. Mittal and J. Carbonell.1999.
Summarizing text documents: sentence selec-tion and evaluation metrics.
In Proceedings of SIGIR-99.S.
Gupta, A. Nenkova and D. Jurafsky.
2007.
Measuringimportance and query relevance in topic-focusedmulti-document summarization.
In Proceedings ofACL-07.S.
Harabagiu and F. Lacatusu.
2005.
Topic themes formulti-document summarization.
In Proceedings ofSIGIR?05.H.
Hardy, N. Shimizu, T. Strzalkowski, L. Ting,  G. B.Wise.
and X. Zhang.
2002.
Cross-document summa-rization by concept classification.
In Proceedings ofSIGIR?02.M.
Hearst.
1997.
TextTiling: segmenting text into multi-paragraph subtopic passages.
Computational Linguis-tics, 23(1): 33-64.K.
Knight.
and  D. Marcu.
2002.
Summarization beyondsentence extraction: a probabilistic approach to sen-tence compression, Artificial Intelligence, 139(1).W.
Kraaij, M. Spitters and M. van der Heijden.
2001.Combining a mixture language model and Na?veBayes for multi-document summarization.
In SIGIR2001 Workshop on Text Summarization.A.
Leuski, C.-Y.
Lin and E. Hovy.
2003.  iNeATS: in-teractive multi-document summarization.
In Proceed-ings of ACL2003.C.-Y.
Lin and E. H. Hovy.
2002.
From single to multi-document summarization: a prototype system and itsevaluation.
In Proceedings of ACL-2002.C.-Y.
Lin and E. H. Hovy.
2003.
Automatic evaluationof summaries using n-gram co-occurrence statistics.In Proceedings of HLT-NAACL2003.T.-Y.
Liu and W.-Y.
Ma.
2005.
Webpage importanceanalysis using Conditional Markov Random Walk.
InProceedings of WI2005.I.
Mani and E. Bloedorn.
2000.
Summarizing similari-ties and differences among related documents.
Infor-mation Retrieval, 1(1).D.
Marcu.
Discourse-based summarization in DUC?2001.
2001.
In SIGIR 2001 Workshop on Text Sum-marization.K.
McKeown, J. Klavans, V. Hatzivassiloglou, R. Barzi-lay and E. Eskin.
1999.
Towards multidocumentsummarization by reformulation: progress and pros-pects, in Proceedings of AAAI1999.R.
Mihalcea and P. Tarau.
2005.
A language independ-ent algorithm for single and multiple document sum-marization.
In Proceedings of IJCNLP?2005.A.
Nenkova and A. Louis.
2008.
Can you summarizethis?
Identifying correlates of input difficulty for ge-neric multi-document summarization.
In Proceedingsof ACL-08: HLT.L.
Page, S. Brin, R. Motwani and T. Winograd.
1998.The pagerank citation ranking: Bringing order to theweb.
Technical report, Stanford Digital Libraries.D.
R. Radev, H. Y. Jing, M. Stys and D. Tam.
2004.Centroid-based summarization of multiple documents.Information Processing and Management, 40: 919-938.X.
Wan and J. Yang.
2006.
Improved affinity graphbased multi-document summarization.
In Proceedingsof HLT-NAACL2006.X.
Wan, J. Yang and J. Xiao.
2007.
Manifold-rankingbased topic-focused multi-document summarization.In Proceedings of IJCAI2007.762
