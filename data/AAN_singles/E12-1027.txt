Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 266?275,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsAspectual Type and Temporal Relation ClassificationFrancisco CostaUniversidade de Lisboafcosta@di.fc.ul.ptAnto?nio BrancoUniversidade de LisboaAntonio.Branco@di.fc.ul.ptAbstractIn this paper we investigate the relevance ofaspectual type for the problem of temporalinformation processing, i.e.
the problemsof the recent TempEval challenges.For a large list of verbs, we obtain sev-eral indicators about their lexical aspect byquerying the web for expressions wherethese verbs occur in contexts associatedwith specific aspectual types.We then proceed to extend existing solu-tions for the problem of temporal informa-tion processing with the information ex-tracted this way.
The improved perfor-mance of the resulting models shows that(i) aspectual type can be data-mined withunsupervised methods with a level of noisethat does not prevent this information frombeing useful and that (ii) temporal informa-tion processing can profit from informationabout aspectual type.1 IntroductionExtracting the temporal information present in atext is relevant to many natural language process-ing applications, including question-answering,information extraction, and even document sum-marization, as summaries may be more readableif they follow a chronological order.Recent evaluation campaigns have focused onthe extraction of temporal information from writ-ten text.
TempEval (Verhagen et al 2007), in2007, and more recently TempEval-2 (Verhagenet al 2010), in 2010, were concerned with thisproblem.
Additionally, they provided data thatcan be used to develop and evaluate systems thatcan automatically temporally tag natural languagetext.
These data are annotated according to theTimeML (Pustejovsky et al 2003) scheme.Figure 1 shows a small and slightly simpli-fied fragment of the data from TempEval, withTimeML annotations.
There, event terms, suchas the term referring to the event of releasing thetapes, are annotated using EVENT tags.
States(such as the situations denoted by verbs like wantor love) are also considered events.
Temporal ex-pressions, such as today, are enclosed in TIMEX3tags.
The attribute value of time expressionsholds a normalized representation of the date ortime they refer to (e.g.
the word today denotes thedate 1998-01-14 in this example).
The TLINKelements at the end describe temporal relationsbetween events and temporal expressions.
For in-stance, the event of the plane going down is anno-tated as temporally preceding the date denoted bythe temporal expression today.The major tasks of these two TempEval evalu-ation challenges were about guessing the type oftemporal relations, i.e.
the value of the relTypeattribute of the TLINK elements in Figure 1, allother annotations being given.
Temporal relationclassification is also the most interesting problemin temporal information processing.
The otherrelevant tasks (identifying and normalizing tem-poral expressions and events) have a longer re-search history and show better evaluation results.TempEval was organized in three tasks(TempEval-2 has four additional ones, that are notrelevant to this work): task A was concerned withclassifying temporal relations holding between anevent and a time mentioned in the same sentence(although they could be syntactically unrelated, asthe temporal relation represented by the TLINKwith the lid with the value l1 in Figure 1); task266<s>In Washington <TIMEX3 tid="t53" type="DATE"value="1998-01-14">today</TIMEX3>, the FederalAviation Administration <EVENT eid="e1"class="OCCURRENCE" stem="release"aspect="NONE" tense="PAST" polarity="POS"pos="VERB">released</EVENT> air traffic control tapes from<TIMEX3 tid="t54" type="TIME"value="1998-XX-XXTNI">the night</TIMEX3> the TWAFlight eight hundred <EVENT eid="e2"class="OCCURRENCE" stem="go" aspect="NONE"tense="PAST" polarity="POS"pos="VERB">went</EVENT> down.</s><TLINK lid="l1" relType="BEFORE" eventID="e2"relatedToTime="t53"/><TLINK lid="l2" relType="OVERLAP"eventID="e2" relatedToTime="t54"/>Figure 1: Sample of the data annotated for TempEval,corresponding to the fragment: In Washington today,the Federal Aviation Administration released air traf-fic control tapes from the night the TWA Flight eighthundred went down.TaskA B CBest system 0.62 0.80 0.55Average of all participants 0.56 0.74 0.51Majority class baseline 0.57 0.56 0.47Table 1: Results for English in TempEval (F-measure),from Verhagen et al(2009)B focused on the temporal relation between eventsand the document?s creation time, which is alsoannotated in TimeML (not shown in that Figure);and task C was about classifying the temporal re-lation between the main events of two consecu-tive sentences.
The possible values for the typeof temporal relation are BEFORE, AFTER andOVERLAP.1Table 1 shows the results of the first TempEvalevaluation.
The results of TempEval-2 are fairlysimilar (Verhagen et al 2010), but the data usedare similar but not identical.The best system in TempEval for tasks A and B(Pus?cas?u, 2007) combined statistical and knowl-edge based methods to propagate temporal con-straints along parse trees coming from a syntac-tic parser.
The best system for task C (Min et1There are the additional disjunctive valuesBEFORE-OR-OVERLAP, OVERLAP-OR-AFTER andVAGUE, employed when the annotators could not make amore specific decision, but these affect a small number ofinstances.al., 2007) also combined rule-based and machinelearning approaches.
It employed sophisticatedNLP to compute some of the features used; morespecifically it used syntactic features.Our goal with this work is to evaluate the im-pact of information about aspectual type on thesetasks.
The TimeML annotations include an at-tribute class for EVENTs that encodes some as-pectual information, distinguishing between sta-tive (annotated with the value STATE) and non-stative events (value OCCURRENCE).
This at-tribute is relevant to the classification problem athand, i.e.
it is a useful feature for machine learnedclassifiers for the TempEval tasks (although thisclass attribute encodes other kinds of informa-tion as well).
However, aspectual distinctions canbe more fine-grained than a mere binary distinc-tion, and so far no system has explored this sort ofinformation to help improve the solutions to tem-poral relation classification.In this paper we work with Portuguese, but inprinciple there is no reason to believe that ourfindings would not apply to other languages thatdisplay similar aspectual phenomena, such as En-glish.
Some of the details, such as the materialin Section 4.2, are however language specific andwould need adaptation.2 Aspectual TypeDistinctions of aspectual type (also referred to assituation type, lexical aspect or Aktionsart) of thesort of Vendler (1967) and Dowty (1979) are ex-pected to improve the existing solutions to theproblem of temporal relation classification.
Themajor aspectual distinctions are between (i) states(e.g.
to hate beer, to know the answer, to own acar, to stink), (ii) processes, also called activities(to work, to eat ice cream, to grow, to play thepiano), (iii) culminated processes, also called ac-complishments (to paint a picture, to burn down,to deliver a sermon) and (iv) culminations, alsocalled achievements (to explode, to win the game,to find the key).
States and processes are atelicsituations in that they do not make salient a spe-cific instant in time.
Culminated processes andculminations are telic situations: they have an in-trinsic, instantaneous endpoint, called the culmi-nation (e.g.
in the case of to paint a picture, it isthe moment when the picture is ready; in the caseof to explode, it is the moment of the explosion).There are several reasons to think aspectual267type is relevant to temporal information pro-cessing.
First, these distinctions are related tohow long events last: culminations are punctual,whereas states can be very prolonged in time.States are thus more likely to temporally overlapother temporal entities than culminations, for in-stance.Second, there are grammatical consequenceson how events are anchored in time.
Considerthe following examples, from Ritchie (1979) andMoens and Steedman (1988):(1) When they built the 59th Street bridge,they used the best materials.
(2) When they built that bridge, I was still ayoung lad.The situation of building the bridge is a cul-minated processed, composed by the process ofactively building a bridge followed by the culmi-nation of the bridge being finished.
In sentence(1), the event described in the main clause (that ofusing the best materials) is a process, but in sen-tence (2) it is a state (the state of being a younglad).
Even though the two clauses in each sen-tence are connected by when, the temporal rela-tions holding between the events of each clauseare different.
On the one hand, in sentence (1)the event of using the best materials (a process)overlaps with the process of actively building thebridge and precedes the culmination of finishingthe bridge.
On the other hand, in sentence (2)the event of being a young lad (which is a state)overlaps with both the process of actively build-ing the bridge and the culmination of the bridgebeing built.
This difference is arguably caused bythe different aspectual types of the main events ofeach sentence.As another example, states overlap with tem-poral location adverbials, as in (3), while culmi-nations are included in them, as in (4).
(3) He was happy last Monday.
(4) He reached the top of Mount Everest lastMonday.In other cases, differences in aspectual type candisambiguate ambiguous linguistic material.
Forinstance, the preposition in is ambiguous as it canbe used to locate events in the future but also tomeasure the duration of culminated processes; itis thus ambiguous with culminated processes, asin he will read the book in three days but not withother aspectual types, as in he will be living therein three days.A factor related to aspectual class, that is nottrivial to account for, is the phenomenon of as-pectual shift, or aspectual coercion (Moens andSteedman, 1988; de Swart, 1998; de Swart, 2000).Many linguistic contexts pose constraints on as-pectual type.
This does not mean, however, thatclashes of aspectual type cause ungrammatical-ity.
What often happens is that phrases associatedwith an incompatible aspectual type get their typechanged in order to be of the required type, caus-ing a change in meaning.For instance, the progressive construction com-bines with processes.
When it combines with e.g.a culminated process, the culmination is strippedoff from this culminated process, which is thusconverted into a process.
The result is that a sen-tence like (5) does not say that the bridge was fin-ished (the event has no culmination), whereas onesuch as (6) does say this (the event has a culmina-tion).
(5) They were building that bridge.
(6) They built that bridge.Aspectual type is not a property of just words,but phrases as well.
For example, while theprogressive construction just mentioned combineswith processes, the resulting phrase behaves as astate (cf.
the sentence When they built the 59thStreet bridge, they were using the best materi-als and what was mentioned above about whenclauses).3 StrategyAspectual type is hard to annotate.
This is partlybecause of what was just mentioned: it is not aproperty of just words, but rather phrases, anddifferent phrases with the same head word canhave different aspectual types; however anno-tation schemes like TimeML annotate the headword as denoting events, not full phrases orclauses.For this reason, our strategy is to obtain aspec-tual type information from unannotated data.
Be-cause these data are gradient?an event-denotingword can be associated with different aspectualtypes, depending on word sense?we do not aimto extract categorical information, but rather nu-268meric values for each event term that reflect as-sociations to aspectual types.
These may be seenas values that are indicative of the frequencies inwhich an event term denotes a state, or a process,etc.In order to extract these indicators, we resort toa methodology sometimes referred to as GoogleHits: large amounts of queries are sent to a websearch engine (not necessarily Google), and thenumber of search results (the number of webpages that match the query) is recorded and takenas a measure of the frequency of the queried ex-pression.This methodology is not perfect, since multipleoccurrences of the queried expression in the sameweb page are not reflected in the hit count, andin many cases the hit counts reported by searchengines are just estimates and might not be veryaccurate.
Additionally, uncarefully formulatedqueries can match expressions that are syntacti-cally and semantically very different from whatwas intended.
In any case, it has the advantagesof being based on a very large amount of data andnot requiring any manual annotation, which canintroduce errors.3.1 The Web as a Very Large CorpusHearst (1992) is one of the earliest studies wherespecific textual patterns are used to extract lexico-semantic information from very large corpora.The author?s goal was to extract hyponymy rela-tions.
With the same goal, Kozareva et al(2008)apply similar textual patterns to the web.The web has been used as a corpus by manyother authors with the purpose of extracting syn-tactic or semantic properties of words or re-lations between them, e.g.
Ravichandran andHovy (2002), Etzioni et al(2004), etc.
Someof this work is specially relevant to the problemof temporal information processing.
VerbOcean(Chklovski and Pantel, 2004) is a database ofweb mined relations between verbs.
Among otherkinds of relations, it includes typical precedencerelations, e.g.
sleeping happens before waking up.This type of information has in fact been used bysome of the participating systems of TempEval-2(Ha et al 2010), with good results.More generally, there is a large body of workfocusing on lexical acquisition from corpora.
Justas an example, Mayol et al(2005) learn subcate-gorization frames of verbs from large amounts ofdata.
Relevant to our work is that of Siegel andMcKeown (2000).
The authors guess the aspec-tual type of verbs by searching for specific pat-terns in a one million word corpus that has beensyntactically parsed.
They extract several linguis-tic indicators and combine them with machinelearning algorithms.
The indicators that they ex-tract are naturally different from ours, since theyhave access to syntactic structure and we do not,but our data are based on a much larger corpus.3.2 Textual Patterns as Indicators ofAspectual TypeBecause of aspectual shift phenomena (see Sec-tion 2), full syntactic parsing is necessary in orderto determine the aspectual type of a natural lan-guage expression.
However, this can be approxi-mated by frequencies: it is natural to expect thate.g.
stative verbs occur more frequently in stativecontexts than non-stative verbs, even if there maybe errors in determining these contexts if syntacticparsing is not a possibility.If one uses Google Hits, syntactic informationis not accessible.
In return for its impreciseness,Google Hits have the advantage of being based onvery large amounts of data.4 Scope and ApproachIn this study we focus exclusively on verbs, butevents can be denoted by words belonging toother parts-of-speech.
This limitation is linked tothe fact that the textual patterns that are used tosearch for specific aspectual contexts are sensitiveto part-of-speech (i.e.
what may work for a verbmay not work equally well for a noun).In order to assess whether aspectual type in-formation is relevant to the problem of temporalrelation classification, our approach is to checkwhether incorporating that kind of informationinto existing solutions for this problem can im-prove their performance.
TimeML annotateddata, such as those used for TempEval, can beused to train machine learned classifiers.
Thesecan then be augmented with attributes encodingaspectual type information and their performancecompared to the original classifiers.Additionally, we work with Portuguese data.This is because our work is part of an effort toimplement a temporal processing system for Por-tuguese.
We briefly describe the data next.269<s>Em Washington, <TIMEX3 tid="t53" type="DATE"value="1998-01-14">hoje</TIMEX3>, a Federal AviationAdministration <EVENT eid="e1" class="OCCURRENCE"stem="publicar" aspect="NONE" tense="PPI"polarity="POS" pos="VERB">publicou</EVENT>gravac?o?es do controlo de tra?fego ae?reo da <TIMEX3tid="t54" type="TIME"value="1998-XX-XXTNI">noite</TIMEX3> em que o vooTWA800 <EVENT eid="e2" class="OCCURRENCE"stem="cair" aspect="NONE" tense="PPI"polarity="POS" pos="VERB">caiu</EVENT>.</s><TLINK lid="l1" relType="BEFORE" eventID="e2"relatedToTime="t53"/><TLINK lid="l2" relType="OVERLAP"eventID="e2" relatedToTime="t54"/>Figure 2: Sample of the Portuguese data adapted fromthe TempEval data, corresponding to the fragment: EmWashington, hoje, a Federal Aviation Administrationpublicou gravac?o?es do controlo de tra?fego ae?reo danoite em que o voo TWA800 caiu.4.1 DataOur experiments used TimeBankPT (Costa andBranco, 2010; Costa and Branco, 2012; Costa, toappear).
This corpus is an adaptation of the orig-inal TempEval data to Portuguese, obtained bytranslating it and then adapting the annotations.Figure 2 shows the Portuguese equivalent to thesample presented above in Figure 1.
The two cor-pora are quite similar, but there is of course thelanguage difference.
TimeBankPT contains a fewcorrections to the data (mostly the temporal rela-tions), but these corrections only changed around1.2% of the total number of annotated temporalrelations (Costa and Branco, 2012).
Although wedid not test our results on English data, we specu-late that our results carry over to other languages.Just like the original English corpus forTempEval, it is divided in a training part and atesting part.
The numbers (sentences, words, an-notated events, time expressions and temporal re-lations) are fairly similar for the two corpora (theEnglish one and the Portuguese one).4.2 Extracting the Aspectual IndicatorsWe extracted the 4,000 most common verbs froma 180 million word corpus of Portuguese news-paper text, CETEMPu?blico.
Because this corpusis not annotated, we used a part-of-speech tag-ger and morphological analyzer (Barreto et al2006; Silva, 2007) to detect verbs and to obtaintheir dictionary form.
We then used an inflectiontool (Branco et al 2009) to generate the specificverb forms that are used in the queries.
They aremostly third person singular forms of several dif-ferent tenses.The indicators that we used are ratios of GoogleHits.
They compare two queries.Several indicators were tested.
We provide ex-amples with the verb fazer ?do?
for the queriesbeing compared by each indicator.
The name ofeach indicator reflects the aspectual type beingtested, i.e.
states should present high values forState Indicators 1 and 2, processes should showhigh values for Process Indicators 1?4, etc.?
State Indicator 1 (Indicator S1) is about im-perfective and perfective past forms of verbs.It compares the number of hits a for an im-perfective form fazia ?did?
to the number ofhits b for a perfective form fez ?did?
: aa+b .Assuming the imperfective past constrainsthe entire clause to be a state, and the perfec-tive past constrains it to be telic, the higherthis value the more frequently the verb ap-pears in stative clauses in a past tense.2?
State Indicator 2 (Indicator S2) is about theco-occurrence with acaba de ?has just fin-ished?.
It compares the number of hits afor acaba de fazer ?has just finished doing?to the number of hits b for fazer ?to do?
:ba+b .
In Portuguese, this construction doesnot seem to be felicitous with states.?
Process Indicator 1 (Indicator P1) is aboutpast progressive forms and simple past forms(both imperfective).
It compares the num-ber of hits a for fazia ?did?
to the number ofhits b for estava a fazer ?was doing?
: ba+b .Assuming the progressive construction is afunction from processes to states (see Sec-tion 2), the higher this value, the more likelythe verb can occur with the interpretation ofa process.2We expect this frequency to be indicative of states be-cause states can appear in the imperfective past tense withtheir interpretation unchanged, whereas non-stative eventshave their interpretation shifted to a stative one in that con-text (e.g.
they get a habitual reading).
In order to refer to anevent occurring in the past with an on-going interpretation,non-stative verbs require the progressive construction to beused in Portuguese, whereas states do not.
Therefore, statesshould occur more freely in the simple imperfective past.270?
Process Indicator 2 (Indicator P2) is aboutpast progressive forms vs. simple past forms(perfective).
It compares the number of hitsa for fez ?did?
to the number of hits b foresteve a fazer ?was doing?
: ba+b .
Similarlyto the previous indicator, this one tests thefrequency of a verb appearing in a contexttypical of processes.?
Process Indicator 3 (Indicator P3) is aboutthe occurrence of for Adverbials.
It com-pares the number of hits a for fez ?did?
tothe number of hits b for fez durante muitotempo ?did for a long time?
: ba+b .
Thisnumber is also intended to be an indica-tion of how frequent a verb can be usedwith the interpretation of a process.
Notethat Portuguese allows modifiers to occurfreely between a verb and its complements,so this test should work for transitive verbs(or any other subcategorization frame involv-ing complements), not just intransitive ones.?
Process Indicator 4 (Indicator P4) is aboutthe co-occurrence of a verb with parar de ?tostop?.
It compares the number of hits a forparou de fazer ?stopped doing?
to the num-ber of hits b for fazer ?to do?
: aa+b .
Just likethe English verbs stop and finish are sensitiveto the aspectual type of their complement, sois the Portuguese verb parar, which selectsfor processes.?
Atelicity Indicator 1 (Indicator A1) is aboutcomparing in and for adverbials.
It comparesthe number of hits a for fez num instante ?didin an instant?
to the number of hits b for fezdurante muito tempo ?did for a long time?
:ba+b .
Processes can be modified by for ad-verbials, whereas culminated processes aremodified by in adverbials.
This indicatortests the occurrence of a verb in contexts thatrequire these aspectual types.?
Atelicity Indicator 2 (Indicator A2) is aboutcomparing for Adverbials with suddenly.
Itcompares the number of hits a for fez de re-pente ?did suddenly?
to the number of hitsb for fez durante muito tempo ?did for along time?
: ba+b .
De repente ?suddenly?seems to modify culminations, so this indi-cator compares process readings with culmi-nation readings.?
Culmination Indicator1 (Indicator C1) isabout differentiating culminations and cul-minated processes.
It compares the numberof hits a for fez de repente ?did suddenly?
tothe number of hits b for fez num instante ?didin an instant?
: aa+b .For each of the 4,000 verbs, the necessaryqueries required by these indicators were gener-ated and then sent to a search engine.
The querieswere enclosed in quotes, so as to guarantee ex-act matches.
The number of hits was recorded foreach query.We had some problems with outliers for a fewrather infrequent verbs.
These could show veryextreme values for some indicators.
In orderto minimize their impact, for each indicator wehomogenized the 100 highest values that werefound.
More specifically, for each indicator, eachone of the highest 100 values was replaced by the100th highest value.
The bottom 100 values weresimilarly changed.
This way the top 99 values andthe bottom 99 values are replaced by the 100thhighest value and the 100th lowest value respec-tively.Each indicator ranges between 0 and 1 in the-ory.
In practice, we seldom find values close to theextremes, as this would imply that some querieswould have close to 0 hits, which does not occurvery often (after all, we intentionally used queriesfor which we would expect large hit counts, asthese are more likely to be representative of truelanguage use).
For this reason, each indicator isscaled so that its minimum (actual) value is 0 andits maximum (actual) value is 1.5 EvaluationAs mentioned before, in order to assess the use-fulness of these aspectual indicators for the tasksof temporal relation classification, we checkedwhether they can improve machine learned clas-sifiers trained for this problem.
We next describethe classifiers that were used as the bases for com-parison.5.1 Experimental SetupIn order to obtain bases for comparison, wetrained machine learned classifiers on the Por-tuguese corpus TimeBankPT, that is adapted fromthe TempEval data (see Section 4.1).
We tookinspiration in the work of Hepple et al(2007).271This was one of the participating systems ofTempEval.
It used machine learning algorithmsimplemented in Weka (Witten and Frank, 1999).For our experiments, we used Weka?s implemen-tation of the C4.5 algorithm, trees.J48 (Quin-lan, 1993), the RIPPER algorithm as implementedby Weka?s rules.JRip (Cohen, 1995), a near-est neighbors classifier, lazy.KStar (Clearyand Trigg, 1995), a Na?
?ve Bayes classifier, namelyWeka?s bayes.NaiveBayes (John and Lang-ley, 1995), and a support vector classifier, Weka?sfunctions.SMO (Platt, 1998) .
We chose thesealgorithms as they are representative of a widerange of machine learning approaches.Recall that the tasks of TempEval are to guessthe type of temporal relations.
Each train or testinstance thus corresponds to a temporal relation,i.e.
a TLINK element in the TimeML annota-tions (see Figures 1 and 2).
The classificationproblem is to determine the value of the attributerelType of TimeML TLINK elements.
Thesetemporal relations relate an event (referred by theeventID attribute of TLINK elements) to an-other temporal entity, that can be a time (pointedto by the relatedToTime attribute), in the caseof tasks A and B, or, in the case of task C, an-other event (given by the relatedToEvent at-tribute).As for the features that were employed, we alsotook inspiration in the approach of Hepple et al(2007).
These authors used as classifier attributestwo types of features.
The first group of featurescorresponds to TimeML attributes: for instancethe value of the aspect attribute of EVENT el-ements, for the events involved in the temporalrelation to be classified.
The second group of fea-tures corresponds to simple features that can becomputed with string manipulation and do not re-quire any kind of natural language processing.Table 2 shows the features that were tried andemployed.The event features correspond to attributesof EVENT elements, with the exception ofthe event-string feature, which takes asvalue the character data inside the correspond-ing TimeML EVENT element.
In a simi-lar spirit, the timex3 features are taken fromthe attributes of TIMEX3 elements with thesame name.
The tlink-relType featureis the class attribute and corresponds to therelType attribute of the TimeML TLINK el-TaskAttribute A B Cevent-aspect ?
X Xevent-polarity X X Xevent-POS ?
?
Xevent-stem ?
X ?event-string X ?
?event-class X ?
Xevent-tense X X Xorder-event-first X N/A N/Aorder-event-between X N/A N/Aorder-timex3-between ?
N/A N/Aorder-adjacent X N/A N/Atimex3-mod X ?
N/Atimex3-type ?
?
N/Atlink-relType X X XTable 2: Feature combinations used in the classifiersused as comparison bases.
Features inspired by theones used by Hepple et al(2007) in TempEval.ement that represents the temporal relation tobe classified.
The order features are the at-tributes computed from the document?s textualcontent.
The feature order-event-firstencodes whether the event terms precedes inthe text the time expression it is related to bythe temporal relation to classify.
The clas-sifier attribute order-event-between de-scribes whether any other event is mentionedin the text between the two expressions forthe entities that are in the temporal relation,and similarly order-timex3-between isabout whether there is an intervening tempo-ral expression.
Finally, order-adjacent istrue iff both order-timex3-between andorder-event-between are false (even ifother linguistic material occurs between the ex-pressions denoting the two entities in the temporalrelation).In order to arrive at the final set of features(marked with a check mark in Table 2), we per-formed exhaustive search on all possible combi-nations of these features for each task, using theNa?
?ve Bayes algorithm.
They were compared us-ing 10-fold cross-validation on the training data.The feature combinations shown in Table 2 arethe optimal combinations arrived at in this way.These are the classifiers that we used for the272comparison with the aspectual type indicators.We chose this straightforward approach because itforms a basis for comparison that is easily repro-ducible: the algorithm implementations that wereused are part of freely available software, and thefeatures that were employed are easily computedfrom the annotated data, with no need to run anynatural language processing tools whatsoever.As mentioned before in Section 4.1, the dataused are organized in a training set and an evalu-ation set.
The training part is around 60K wordslong, the test data containing around 9K words.When tested on held-out data, these classifierspresent the scores shown in italics in Table 3.These results are fairly similar to the scores thatthe system of Hepple et al(2007) obtained inTempEval with English data: 0.59 for task A, 0.73for task B, and 0.54 for task C. They are also notvery far from the best results of TempEval.
Assuch they represent interesting bases for compar-ison, as improving their performance is likely tobe relevant to the best systems that have been de-veloped for temporal information processing.5.2 Results and DiscussionAfter obtaining the bases for comparison de-scribed above, we proceeded to check whether theaspectual type indicators described in Section 4.2can improve these results.For each aspectual indicator, we implementeda classifier feature that encodes its value for theevent term in the temporal relation (if it is not averb, this value is missing).
In the case of task C,two features are added for each indicator, one foreach event term.We extended each of these classifiers with oneof these features at a time (two in the case of taskC), and checked whether it improved the resultson the test data.
So for instance, in order to testIndicator S1, we extended each of these classifierswith a feature that encodes the value that this indi-cator presents for the term that denotes the eventpresent in the temporal relation to be classified.In the case of task C, two classifier features areadded, one for each event term, and both for thesame Indicator S1.
For instance, for the (train-ing) instance corresponding to the TLINK in Fig-ure 2 with the lid attribute that has the value l1,the classifier feature for Indicator S1 has the valuethat was computed for the verb cair ?go down?,since this is the stem of the word that denotesTaskClassifier A B Ctrees.J48 0.57 0.77 0.53With best indicator 0.55rules.JRip 0.60 0.76 0.51With best indicator 0.61 0.54lazy.KStar 0.54 0.70 0.52With best indicator 0.73 0.53bayes.NaiveBayes 0.50 0.76 0.53With best indicator 0.53 0.54functions.SMO 0.55 0.79 0.54With best indicator 0.56 0.55Table 3: Evaluation on held-out test data of classi-fiers trained on full train data.
Values for the classi-fiers used as comparison bases are in italics.
Boldfacehighlights improvements resulting from incorporatingaspectual indicators as classifier features, and missingvalues represent no improvement.the event that is the first argument of this temporalrelation.
After adding each of these features, weretrained the classifiers on the training data andtested them on the held-out test data.
In order tokeep the evaluation manageable, we did not testcombinations of multiple indicators.Table 3 shows the overall results.
For taskA, the best indicators were P4 (with JRip), A1(NaiveBayes) and S1 (SMO).
For task B thebest one was P4 (KStar).
For task C, the bestindicators were P3 (J48), A1 and P3 (JRip),C1 (KStar), A1 (NaiveBayes) and P2 (SMO).Each of the indicators S2, P1 and A2 either doesnot improve the results or does so but not as muchas another, better indicator for the same task andalgorithm.It seems clear from Table 3 that some tasks ben-efit from these indicators more than others.
Inparticular, task C shows consistent improvementswhereas task B is hardly affected.
Since task Cis about relations involving two events, the classi-fiers may be picking up the sort of linguistic gen-eralizations mentioned in Section 2 about whenclauses.J48 and JRip produce human-readable mod-els.
We checked how these classifiers are takingadvantage of the aspectual indicators.
For task C,the induced models are generally associating high273values of the indicators A1 and P3 with overlaprelations and low values of these indicators withother types of relations.
This is expected.
On theone end, high values for these indicators are asso-ciated with atelicity (i.e.
the endpoint of the cor-responding event is not presented).
On the otherhand, both indicators are based on queries con-taining the phrase durante muito tempo ?for a longtime?, which, in addition to picking up events thatcan be modified by for adverbials, more specifi-cally pick up events that happen for a long timeand are thus likely to overlap other events.For task A, JRip also associates high values ofthe indicator P4?which constitute evidence thatthe corresponding events are processes (which areatelic)?with overlap relations.
This is a speciallyinteresting result, considering that the queries onwhich this indicator is based reflect a purely as-pectual constraint.6 Concluding RemarksIn this paper, we evaluated the relevance of infor-mation about aspectual type for temporal process-ing tasks.Temporal information processing has receivedsubstantial attention recently with the twoTempEval challenges in 2007 and 2010.
The mostinteresting problem of temporal information pro-cessing, that of temporal relation classification, isstill affected by high error rates.Even though a very substantial part of the se-mantics literature on tense and aspect focuses onaspectual type, solutions to the problem of auto-matic temporal relation classification have not in-corporated this sort of semantic information.
Inpart this is expected, as aspectual type is very in-terconnected with syntax (cf.
the discussion aboutaspectual coercion in Section 2), and the phe-nomenon of aspect shift can make it hard to com-pute even when syntactic information is available.Our contribution with this paper is to incor-porate this sort of information in existing ma-chine learned classifiers that tackle this problem.Even though these classifiers do not have access tosyntactic information, aspectual type informationseemed to be useful in improving the performanceof these models.
We hypothesize that combin-ing aspectual type information with informationabout syntactic structure can further improve theproblems of temporal information processing, butwe leave that research to future work.An interesting question that we hope will be ad-dressed by future work is how these results extendto other languages.
We cannot provide an answerto this question, as we do not have the data.
How-ever, this experiment can be replicated for any lan-guage that has (i) TimeML annotated data, (ii) areasonable size of documents on the Web and asearch engine capable of separating them from thedocuments in other languages and (iii) an aspec-tual system similar enough that the question be-ing addressed in this paper makes sense (and use-ful patterns for queries can be constructed, evenif not entirely identical to the ones that we used).The second criterion is met by many, many lan-guages.
The third one also seems to affect manylanguages, as the existing literature on aspectualphenomena indicates that these phenomena arequite widespread.
The second criterion is, at themoment, the hardest to fulfill as not many lan-guages have data with rich annotations about time(i.e.
including events and temporal relations).
Wespeculate that our results can extend to English,although a different set of query patterns mayhave to be used in order to extract the aspectualindicators that are employed.
We believe this be-cause the two languages largely overlap when itcomes to aspectual phenomena.ReferencesFlorbela Barreto, Anto?nio Branco, Eduardo Ferreira,Ama?lia Mendes, Maria Fernanda Nascimento, Fil-ipe Nunes, and Joa?o Silva.
2006.
Open resourcesand tools for the shallow processing of Portuguese:the TagShare project.
In Proceedings of LREC2006.Anto?nio Branco, Francisco Costa, Eduardo Ferreira,Pedro Martins, Filipe Nunes, Joa?o Silva, and SaraSilveira.
2009.
LX-Center: a center of online lin-guistic services.
In Proceedings of the Demo Ses-sion, ACL-IJCNLP2009, Singapore.Timothy Chklovski and Patrick Pantel.
2004.
Verb-Ocean: Mining the Web for fine-grained semanticverb relations.
In In Proceedings of EMNLP-2004,Barcelona, Spain.John G. Cleary and Leonard E. Trigg.
1995.
K*: Aninstance-based learner using an entropic distancemeasure.
In 12th International Conference on Ma-chine Learning, pages 108?114.William W. Cohen.
1995.
Fast effective rule induc-tion.
In Proceedings of the Twelfth InternationalConference on Machine Learning, pages 115?123.Francisco Costa and Anto?nio Branco.
2010.
Tempo-ral information processing of a new language: Fast274porting with minimal resources.
In Proceedings ofACL 2010.Francisco Costa and Anto?nio Branco.
2012.
Time-BankPT: A TimeML annotated corpus of Por-tuguese.
In Proceedings of LREC2012.Francisco Costa.
to appear.
Processing Temporal In-formation in Unstructured Documents.
Ph.D. the-sis, Universidade de Lisboa, Lisbon.Henrie?tte de Swart.
1998.
Aspect shift and coercion.Natural Language and Linguistic Theory, 16:347?385.Henrie?tte de Swart.
2000.
Tense, aspect and coer-cion in a cross-linguistic perspective.
In Proceed-ings of the Berkeley Formal Grammar conference,Stanford.
CSLI Publications.David R. Dowty.
1979.
Word Meaning and MontagueGrammar: the Semantics of Verbs and Times inGenerative Semantics and Montague?s PTQ.
Rei-del, Dordrecht.Oren Etzioni, Michael Cafarella, Doug Downey, Stan-ley Kok, Ana-Maria Popescu, Tal Shaked, , StephenSoderland, Daniel S. Weld, and Alexander Yates.2004.
Web-scale information extraction in Know-ItAll.
In Proceedings of the 13th International Con-ference on World Wide Web.Eun Young Ha, Alok Baikadi, Carlyle Licata, andJames C. Lester.
2010.
NCSU: Modeling temporalrelations with Markov logic and lexical ontology.
InProceedings of SemEval 2010.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 14th Conference on Computational Linguistics,volume 2, pages 539?545, Nantes, France.Mark Hepple, Andrea Setzer, and Rob Gaizauskas.2007.
USFD: Preliminary exploration of fea-tures and classifiers for the TempEval-2007 tasks.In Proceedings of SemEval-2007, pages 484?487,Prague, Czech Republic.
Association for Computa-tional Linguistics.George H. John and Pat Langley.
1995.
Estimatingcontinuous distributions in Bayesian classifiers.
InEleventh Conference on Uncertainty in Artificial In-telligence, pages 338?345, San Mateo.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.2008.
Semantic class learning from the web withhyponym pattern linkage graphs.
In Proceedings ofACL-08: HLT, pages 1048?1056, Columbus, Ohio.Association for Computational Linguistics.Laia Mayol, Gemma Boleda, and Toni Badia.
2005.Automatic acquisition of syntactic verb classes withbasic resources.
Language Resources and Evalua-tion, 39(4):295?312.Congmin Min, Munirathnam Srikanth, and AbrahamFowler.
2007.
LCC-TE: A hybrid approach totemporal relation identification in news text.
pages219?222.Marc Moens and Mark Steedman.
1988.
Temporalontology and temporal reference.
ComputationalLinguistics, 14(2):15?28.John Platt.
1998.
Fast training of support vec-tor machines using sequential minimal optimiza-tion.
In Bernhard Scho?lkopf, Chris Burges, andAlexander J. Smola, editors, Advances in KernelMethods?Support Vector Learning.Georgiana Pus?cas?u.
2007.
WVALI: Temporal rela-tion identification by syntactico-semantic analysis.In Proceedings of SemEval-2007, pages 484?487,Prague, Czech Republic.
Association for Computa-tional Linguistics.James Pustejovsky, Jose?
Castan?o, Robert Ingria, RoserSaur?
?, Robert Gaizauskas, Andrea Setzer, and Gra-ham Katz.
2003.
TimeML: Robust specification ofevent and temporal expressions in text.
In IWCS-5, Fifth International Workshop on ComputationalSemantics.John Ross Quinlan.
1993.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann, San Mateo,CA.Deepak Ravichandran and Eduard Hovy.
2002.Learning surface text patterns for a question an-swering system.
In Proceedings of ACL 2002.Graeme D. Ritchie.
1979.
Temporal clauses in En-glish.
Theoretical Linguistics, 6:87?115.Eric V. Siegel and Kathleen McKeown.
2000.Learning methods to combine linguistic indica-tors: Improving aspectual classification and reveal-ing linguistic insights.
Computational Linguistics,24(4):595?627.Joa?o Ricardo Silva.
2007.
Shallow processingof Portuguese: From sentence chunking to nomi-nal lemmatization.
Master?s thesis, Faculdade deCie?ncias da Universidade de Lisboa, Lisbon, Portu-gal.Zeno Vendler.
1967.
Verbs and times.
Linguistics inPhilosophy, pages 97?121.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, and James Pustejovsky.
2007.SemEval-2007 Task 15: TempEval temporal re-lation identification.
In Proceedings of SemEval-2007.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Jessica Moszkowicz, and JamesPustejovsky.
2009.
The TempEval challenge: iden-tifying temporal relations in text.
Language Re-sources and Evaluation.Marc Verhagen, Roser Saur?
?, Tommaso Caselli, andJames Pustejovsky.
2010.
SemEval-2010 task 13:TempEval-2.
In Proceedings of SemEval-2010.Ian H. Witten and Eibe Frank.
1999.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations.
Morgan Kaufmann,San Francisco.275
