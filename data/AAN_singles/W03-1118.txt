Text Categorization Using Automatically Acquired Domain OntologyShih-Hung Wu, Tzong-Han Tsai, Wen-Lian HsuInstitute of Information ScienceAcademia SinicaNankang, Taipei, Taiwan, R.O.C.shwu@iis.sinica.edu.tw, thtsai@iis.sinica.edu.tw, hsu@iis.sinica.edu.twAbstractIn this paper, we describe ontology-basedtext categorization in which the domainontologies are automatically acquiredthrough morphological rules and statisticalmethods.
The ontology-based approach isa promising way for general informationretrieval applications such as knowledgemanagement or knowledge discovery.
Asa way to evaluate the quality of domainontologies, we test our method throughseveral experiments.
Automaticallyacquired domain ontologies, with orwithout manual editing, have been usedfor text categorization.
The results arequite satisfactory.
Furthermore, we havedeveloped an automatic method toevaluate the quality of our domainontology.1.
IntroductionDomain ontology, consisting of importantconcepts and relationships of the concepts in thedomain, is useful in a variety of applications(Gruber, 1993).
However, evaluating the quality ofdomain ontologies is not straightforward.
Reusingan ontology for several applications can be apractical method for evaluating domain ontology.Since text categorization is a general tool forinformation retrieval, knowledge management andknowledge discovery, we test the ability ofdomain ontology to categorize news clips in thispaper.Traditional IR methods use keyworddistribution form a training corpus to assigntesting document.
However, using only keywordsin a training set cannot guarantee satisfactoryresults since authors may use different  keywords.We believe that, news clip events are categorizedby concepts, not just keywords.
Previous worksshows that the latent semantic index (LSI) methodand the n-gram method give good results forChinese news categorization (Wu et al, 1998).However, the indices of LSI and n-grams are lessmeaningful semantically.
The implicit rulesacquired by these methods can be understood bycomputers, not humans.
Thus, manual editing forexceptions and personalization are not possibleand it is difficult to further reuse these indices forknowledge management.With good domain ontology we can identifythe concept structure of sentences in a document.Our idea is to compile the concepts withindocuments in a training set and use these conceptsto understand documents in a testing set.
However,building rigorous domain ontology is laboriousand time-consuming.
Previous works suggest thatontology acquisition is an iterative process, whichincludes keyword collection and structurereorganization.
The ontology is revised, refined,and accumulated by a human editor at eachiteration (Noy and McGuinness, 2001).
Forexample, in order to find a hyponym of a keyword,the human editor must observe sentencescontaining this keyword and its related hyponyms(Hearst, 1992).
The editor then deduces rules forfinding more hyponyms of this keyword.
At eachiteration the editor refines the rules to obtain betterquality pairs of keyword-hyponyms.
To speed upthe above labor-intensive approach, semi-automatic approaches have been designed inwhich a human editor only has to verify the resultsof the acquisition (Maedche and Staab, 2000).A knowledge representation framework,Information Map (InfoMap) in our previous work(Hsu et al, 2001), has been designed to integratevarious linguistic, common-sense and domainknowledge.
InfoMap is designed to performnatural language understanding, and applied tomany application domains, such as questionanswering (QA), knowledge management andorganization memory (Wu et al, 2002), and showsgood results.
An important characteristic ofInfoMap is that it extracts events from a sentenceby capturing the topic words, usually subject-verbpairs or hypernym-hyponym pairs, which aredefined in the domain ontology.We shall review the InfoMap ontologyframework in Section 2.
The ontology acquisitionprocess and extraction rules will be introduced inSection 3.
We describe ontology-based textcategorization in Section 4.
Experimental resultsare reported in Section 5.
We conclude our workin Section 6.2.
Information MapInfoMap can serve as domain ontology as well asan inference engine.
InfoMap is designed for NLPapplications; its basic function is to identify theevent structure of a sentence.
We shall brieflydescribe InfoMap in this section.
Figure 1 givesexample ontology of the Central News Agency(CNA), the target in our experiment.2.1 InfoMap Structure FormatAs a domain ontology, InfoMap consists ofdomain concepts and their related sub-conceptssuch as categories, attributes, activities.
Therelationships of a concept and its associated sub-concepts form a tree-like taxonomy.
InfoMap alsodefines references to connect nodes from differentbranches which serves to integrate thesehierarchical concepts into a network.
InfoMap notonly classifies concepts, but also connects theconcepts by defining the relationships among them.Concept ACategoryAttributeConcept A'(Sub-concept ofconcept A)Concept B(relavant but notbelong to concept A)ActionConcept  C(An activity ofconcept A)Function nodeConcept nodeLegendFigure 2.
Skeleton of the Ontology Structure ofInfoMapFigure 1.
Ontology Structure for CNA NewsIn InfoMap, concept nodes represent conceptsand function nodes represent the relationshipsbetween concepts.
The root node of a domain isthe name of the domain.
Following the root node,important topics are stored in a hierarchical order.These topics have sub-categories that list relatedsub-topics in a recursive fashion.
Figure 1 is apartial view of the domain ontology of the CNA.Under each domain there are several topics andeach topic might have sub-concepts and associatedattributes.
In this example, note that, the domainontology is automatically acquired from a domaincorpus, hence the quality is poor.
Figure 2 showsthe skeleton order of a concept using InfoMap.2.2 Event StructureSince concepts that are semantically related areoften clustered together, one can use InfoMap todiscern the main event structure in a naturallanguage sentence.
The process of identifying theevent structure, we call a firing mechanism, whichmatches words in a sentence to both concepts andrelationships in InfoMap.Suppose keywords of concept A and its sub-concept B (or its hyponyms) appear in a sentence.It is likely that the author is describing an event ?Bof A?.
For example, when the words ?tire?
and?car?
appear in a sentence, normally this sentencewould be about the tire of a car (not tire in thesense of fatigue).
Therefore, a word-pair with asemantic relationship can give more concreteinformation than two words without a semanticrelationship.
Of course, certain syntacticconstraints also need to be satisfied.
This can beextended to a noun-verb pair or a combination ofnoun, verb and adjective.
We call such words in asentence an event structure.
This mechanismseems to be especially effective for Chinesesentences.2.3 Domain SpeculationWith the help of domain ontologies, one cancategorize a piece of text into a specific domain bycategorizing each individual sentence within thetext.
There are many different ways to use domainontology to categorize text.
It can be used as adictionary, as a keyword lists and as a structure toidentify NL events.
Take a single sentence forexample.
We first use InfoMap as a dictionary todo word segmentation (necessary for Chinesesentences) in which the ambiguity can be resolvedby checking the domain topic in the ontology.After words are segmented, we can examine thedistribution of these words in the ontology andeffectively identify the densest cluster.
Thus, wecan use InfoMap to identify the domains of thesentences and their associated keywords.
Section4.1 will further elaborate on this.3.
Automatic Ontology AcquisitionThe automatically domain ontology acquisitionfrom a domain corpus has three steps:1.
Identify the domain keywords.2.
Find the relative concepts.3.
Merge the correlated activities.3.1 Domain Keyword IdentificationThe first step of automatic domain ontologyacquisition is to identify domain keywords.Identifying Chinese unknown words is difficultsince the word boundary is not marked in Chinesecorpus.
According to an inspection of a 5 millionword Chinese corpus (Chen et al, 1996), 3.51% ofwords are not listed in the CKIP lexicon (aChinese lexicon with more than 80,000 entries).We use reoccurrence frequency and fan-outnumbers to characterize words and theirboundaries according to PAT-tree (Chien, 1999).We then adopt the TF/IDF classifier to choosedomain keywords.
The domain keywords serve asthe seed topics in the ontology.
We then applySOAT to automatically obtain related concepts.3.2 SOATTo build the domain ontology for a new domain,we need to collect domain keywords and conceptsby finding relationships among keywords.
Weadopt a semi-automatic domain ontologyacquisition tool (SOAT, Wu et al, 2002), toconstruct a new ontology from a domain corpus.With a given domain corpus, SOAT can build aprototype of the domain ontology.InfoMap uses two major relationships amongconcepts: taxonomic relationships (category andsynonym) and non-taxonomic relationships(attribute and action).
SOAT defines rules, whichconsist of patterns of keywords and variables, tocapture these relationships.
The extraction rules inSOAT are morphological rules constructed frompart-of-speech (POS) tagged phrase structure.Here we briefly introduce the SOAT process:Input: domain corpus with the POS tagOutput: domain ontology prototypeSteps:1 Select a keyword (usually the name ofthe domain) in the corpus as the seed toform a potential root set R2 Begin the following recursive process:2.1 Pick a keyword A as the root from R2.2 Find a new related keyword B of theroot A by extraction rules and add itinto the domain ontology according tothe rules2.3 If there is no more related keywords,remove A from R2.4 Put B into the potential root setRepeat step 2 until either R becomesempty or the total number of nodes reacha threshold3.3 Morphological RulesTo find the relative words of a keyword, we checkthe context in the sentence from which thekeyword appears.
We can then find attributes orhyponyms of the keyword.
For example, in asentence, we find a noun in front of a keyword(say, computer) may form a specific kind ofconcept (say, quantum computer).
A noun (say,connector) followed by ?of?
and a keyword maybe an attribute of the keyword, (say, connector ofcomputer).
See (Wu et al, 2002) for details.3.4 Ontology MergingOntologies can be created by merging differentresources.
One NLP resource that we will mergeinto our domain ontology is the noun-verb eventframe (NVEF) database (Tsai and Hsu, 2002).NVEF is a collection of permissible noun-verbsense-pairs that appear in general domain corpora.The noun will be the subject or object of the verb.This noun-verb sense-pair collection is domainindependent.
We can use nouns as domainkeywords and find their correlated verbs.
Addingthese verbs into the domain ontology makes theontology more suitable for NLP.
The correlatedverbs are added under the action function node.4.
Ontology-Based Text CategorizationTo incorporate the domain ontology into a textcategorization, we have to adjust both the trainingprocess and testing process.
Section 4.1 describeshow to make use of the ontology and the eventstructure during the training process.
Section 4.2describes how to use ontology to perform domainspeculation.
Section 4.3 describes how tocategorize news clippings.4.1 Feature and Threshold SelectionWith the event structure matched (fired) in thedomain ontology, we have more features withwhich to index a text.
To select useful features anda proper threshold, we apply Microsoft DecisionTree Algorithm to determine a path?s relevance asthis algorithm can extract human interpretablerules (Soni et al, 2000).Features of the event structure include eventstructure score, node score, fired node level, andnode type.
During the training process, we recordall features of the event structure fired by the newsclippings in the domain-categorized trainingcorpus.
The decision tree shows that a threshold of0.85 is sufficient to evaluate event structure scores.We use event structure score to determine if thepath is relevant.
According to Figure 3, if thethreshold of true probability is 85%, then the eventstructure score (Pathscore in the figure) should be65.75.
And the relevance of a path p is true if pfalls in a node on the decision tree whose ratio of trueinstance is greater than ?
.4.2 Domain SpeculationThe goal of domain speculation is to categorize asentence S into a domain Dj according to thecombined score of the keywords and the eventstructure in sentence S. We first calculate thesimilarity score of S and Dj.
The keyword scoreand the event structure score are calculatedindependently.
),(_*),(_),(SDScoretureEventStrucSDScoreKeywordSDSimScorejjj?+=We use the TF/IDF classifier (Salton, 1989) tocalculate the Keyword_Score of a sentence  asfollows.
First, we use a segmentation module tosplit a Chinese sentence into words.
The TF/IDFclassifier represents a domain as a weighted vector,Dj =( wj1, wj2,?, wjn), where n is the number ofwords in this domain and wk is the weight of wordk.
wk is defined as nfjk * idfjk, where nfjk is the termfrequency (i.e., the number of times the word wkoccurs in the domain j).
Let DFk be the number ofdomains in which word k appears and |D| the totalnumber of domains.
idfk, the inverse documentfrequency, is given by:)||log(kk DFDidf = .This weighting function assigns high values todomain-specific words, i.e.
words which appearfrequently in one domain and infrequently inothers.
Conversely, it will assign low weights towords appearing in many domains.
The similaritybetween a domain j and a sentence represented bya vector Di is measured by the following cosine:??
?=====nk iknk jknk ikjkijjwwwwDDSimSDScoreKeyword12121)()(),(),(_The event structure score is calculated byInfoMap Engine.
First, find all the nodes inontology that match the words in the sentence.Then determine if there is any concept-attributepair, or hypernym-hyponym pair.
Finally, assign ascore to each fired event structure according to thestring length of words that match the nodes in theontology.
The selected event structure is the onewith the highest score.
))((),(_max SDkeywordsthStringLengSDScoretureEventStrucjEventj?= ?4.3 News CategorizationUpon receiving a news clipping C, we split it intosentences Si.
The sentences are scored andcategorized according to domains.
Thus, everysentence has an individual score for each domainScore(D, Si).
We add up these scores of everysentence in the text according to domain, giving ustotal domain scores for the entire text.
Thedomain which has the highest score is the domaininto which the text is categorized.
)),(()( maxarg ??=CSiDSDScoreCDomain5.
Refining Ontology through the TextCategorization ApplicationThe advantage of ontology compared to otherimplicit knowledge representation mechanism isthat it can be read, interpreted and edited byhuman.
Noise and errors can be detected andrefined, especially for the automatically acquiredontology, in order to obtain a better ontology.Another advantage of allowing human editing isthat the ontology produced can be shared byvarious applications, such as from a QA system toa knowledge management system.
In contrast, theimplicit knowledge represented in LSI or otherrepresentations is difficult to port from oneapplication to another.Figure 3.
Threshold selection using decisiontreeIn this section, we show how the humanediting feature improves news categorization.
First,we can identify a common error type: ambiguity;then, depending on the degree of categorizationambiguity, the system can report to a human editorthe possible errors of certain concepts in thedomain ontology as clues.Consider the following common error type:event structure ambiguity.
Some event structuresare located in several domains due to the noise oftraining data.
We define two formulas to find suchevent structures.
The ambiguity of an eventstructure E(Si) is proportional to the number ofdomains in which it appears, and inverselyproportional to its event score, where Si are thesentences that fire event E.GlobalCategorizationAmiguityFactor(E(Si) )= number of domains fired bySi/average( EventScore(Si) )We also measure the similarity between everytwo event structures by calculating the co-occurrence multiplied by the global categorizationambiguity factor.GlobalCategorizationAmbiguityij (E i, E j)=Co-occurrence(E i, E j) *GlobalCategorizationAmbiguityFactor(E j)When the GlobalCategorizationAmbiguity of anevent structure E i exceeds a threshold, the systemwill suggest that the human editor refine theontology.6.
ExperimentsTo assess the power of domain identification ofontology, we test the text categorization ability ontwo different corpora.
The ontology of the firstexperiment is edited manually; the ontology of thesecond experiment is automatically acquired.
Andwe also conduct an experiment on the effect ofhuman editing of the automatically acquiredontology.6.1 Single Sentence TestWe test 9,143 sentences, edited manually for a QAsystem.
The accuracy is 94%.
These sentences arequestions in the financial domain.
Because thesentence topics are quite focused, the accuracy isvery high.
See Table 1.Table 1.
Sentence Categorization AccuracyDomain # Sentence # Accuracy24 9143 94.01%6.2 News Clippings CollectionThe second experiment that we conduct is newscategorization.
We collect daily news from ChinaNews Agency (CNA) ranging from 1991 to 1999.Each news clipping is short with 352 Chinesecharacters (about 150 words) on the average.There are more than thirty domains and we choose10 major categories for the experiment.6.3 10 Categories News CategorizationOur ten categories are: domestic arts and education(DD), foreign affairs (FA), finance report (FX),domestic health (HD), Taiwan local news (LD),Taiwan sports (LD), domestic military (MD),domestic politics (PD), Taiwan stock markets (SD),and weather report (WE).
From each category, wechoose the first 100 news clippings as the trainingset and the following 100 news clippings as thetesting set.
After data cleansing, the total trainingset has 979 news clippings, with 27,951 nodes andless than 10,000 distinct words.
The training setfor which domain ontologies are automaticallyacquired is shown in Table 2.
A partial view ofthis ontology is in Figure 1.The result of text categorization based on thisautomatically acquired domain ontology is shownin Table 5, which contains the recall and precisionfor each domain.
Note that, without the help of theevent structure, the macro average f-score is85.16%.
Even the total number of domain keyconcepts is less than 10,000 words (instead of100,000 words in standard dictionary), we can stillobtain a good categorization result.
With the helpof event structure, the macro average f-score is85.55%.6.4 Human EditingTo verify the refinement method, we conductan experiment to compare the result of usingautomatically acquired domain ontology and thatof limited human editing (on only one domainontology).
After the training process, we usedomain ontologies to classify the training data,and to calculate the global categorizationambiguity factor formula in order to obtainambiguous event structure pairs as candidates forhuman editing.
For simplicity, we restrict theaction of refinement to deletion.
It takes a humaneditor one half day to finish the task and delete0.62% nodes (172 out of 27,951 nodes).
In thetesting phase, we select 928 new news clippings asthe testing set.
Table 3 shows the results frombefore and after human editing.
Due to timeconstraints, we only edit the part of the ontologythat might affect domain DD.
The recall andprecision of domain DD increase as well as boththe average recall and average precision.
Inaddition, the recall of domains having highercorrelation with DD, such as PD and FA,decreases.
Apparently, the event structures thatmislead the categorization system to thesesdomain have mostly been deleted.
The experimentresult is very consistent with our intuition.Table 2.
Ten Category training set CNA newsTraining set sizeDomainDoc# Char#DD 98 41870FA 97 38143FX 100 30771HD 96 39818JD 107 35381LD 96 36957MD 89 32903PD 100 43152SD 109 33030WE 87 30457total 979 362,4827.
Discussions and ConclusionsCompared to an ordinary n-gram dictionary, ourontology dictionary is quite small (roughly 10%)but records certain important relations betweenkeywords.Our goal is to generate rules that are humanreadable via ontology.
The experiment resultshows that event structure enhances textcategorization, even when the domain ontology isautomatically acquired without human verification.To improve our ontological approach, our futurework are: 1. human editing in more domains; 2.enlarge our dictionary by merging existingontologies, e.g., the names of countries, capitalsand important persons, which are absent from thetraining corpus; 3. incorporate more sense pairssuch as N-A (noun-adjective), Adv-V (adverb-verb); 4. use machine learning model on theweighting of the ontological features.Previous research shows that some NLPtechniques can improve information retrieval.Ontology-based IR is one of them.
However, theconstruction of domain ontology is too costly.Thus, automatic acquisition of domain ontology isbecoming an interesting research topic.
Previousresearch shows that implicit rules (such as LSI, N-gram dictionaries) learned from a training corpusgive better results than explicit rules generated byhumans.
However, it is hard to use these implicitrules or to combine them with other resources forfurther refinement.
With the help of domainontology, we can automatically generate rules thathumans can understand.
Since humans andmachines can maintain ontology independently,the ontological approach can be applied moreeasily to other IR applications.
Ontologies fromdifferent sources can be merged into the domainontology.
The system should include an editinginterface that human thoughts can be incorporatedto complement statistical rules.
With semi-automatically acquired domain ontology, textcategorization can be adapted to personalpreferences.8.
ReferencesChen, K.J., C.R.
Huang, L.P. Chang & H.L.
Hsu,SINICA CORPUS: Design Methodology forBalanced Corpora, in Proceedings of PACLIC11th Conference, pp.167-176, 1996.Chien, L.F., PAT-tree-based Adaptive keyphraseextraction for Intelligent Chinese InformationRetrieval, Information Processing andManagement, Vol.
35, pp.
501-521, 1999.Gruber, T.R.
(1993), A translation approach toportable ontologies.
Knowledge Acquisition,5(2), pp.
199-220, 1993.Hearst, M.A.
(1992), Automatic acquisition ofhyponyms from large text corpora.
InCOLING-92, pp.
539-545.Hsu, W.L., Wu, S.H.
and Chen, Y.S., EventIdentification Based On The Information Map -INFOMAP, in Natural Language Processingand Knowledge Engineering Symposium of theIEEE Systems, Man, and CyberneticsConference, Tucson, Arizona, USA, 2001.Maedche, A. and Staab, S. (2000), DiscoveringConceptual Relationships from Text.
In: Horn,W.
(ed.
): ECAI 2000.
Proceedings of the 14thEuropean Conference on Artificial Intelligence,IOS Press, Amsterdam.Noy, N.F.
and McGuinness D.L.
(2001), OntologyDevelopment 101: A Guide to Creating YourFirst Ontology, SMI technical report SMI-2001-0880, Stanford Medical Informatics.Salton, G., Automatic Text Processing, Addison-Wesley, Massachusetts, 1989.Soni, S, Tang, Z. and Yang, J., ?MicrosoftPerformance Study of Microsoft Data MiningAlgorithms?, UniSys, 2000/12.Tsai, J.L.
and Hsu, W.L., ?Applying an NVEFWord-Pair Identifier to the Chinese Syllable-to-Word Conversion Problem,?
COLING-02,Taipei, ACM press, 2002.Wu, S.H.
and Hsu, W.L., SOAT: A Semi-Automatic Domain Ontology Acquisition Toolfrom Chinese Corpus, COLING-02, Taipei,ACM press, 2002.Wu, S.H., Day, M.Y., Tsai, T.H.
and Hsu, W.L.,FAQ-centered Organizational Memory, inNada Matta and Rose Dieng-Kuntz (ed.
),Knowledge Management and OrganizationalMemories, Kluwer Academic Publishers,Boston, 2002.Wu, S.H., Yang, P.C.
and Soo, V.W., AnAssessment on Character-based Chinese NewsFiltering Using Latent Semantic Indexing,Computational Linguistics & ChineseLanguage Processing, Vol.
3, no.2, August1998.Table 3.
Experiment result of CNA news categorization# of nodesautomaticallyacquired#of nodesdeleted inhuman editingTF/IDF(baseline)TF/IDF+EventStructure(firstimprovement)TF/IDF+Event Structurewith Human Editing(second improvement)The different between(second improvement) and(first improvement) DomainBefore  After   #  % P% R% F% P% R% F% P% R% F% P+% R+% F+%DD 4616 4574 42 0.91 72.9082.9877.61 74.04 81.91 77.78 74.29 82.98 78.39 0.25 1.07 0.61FA 8352 8348 4 0.05 75.8394.7984.26 71.32 95.83 81.78 76.67 95.83 85.19 5.35 0.00 3.41FX 44 44 0 0.00 100 100 100 100 100 100 100 100 100 0.00 0.00 0.00HD 3357 3348 9 0.27 78.7988.6483.42 80.21 87.50 83.70 78.79 88.64 83.42 -1.42 1.14 -0.28JD 1854 1846 8 0.43 88 71.7479.04 87.18 73.91 80 87.84 70.65 78.31 0.66 -3.26 -1.69LD 2925 2831 94 3.21 87.6480.4183.87 90.36 77.32 83.33 88.51 79.38 83.70 -1.85 2.06 0.37MD 2010 1999 11 0.55 95.5966.3378.31 95.71 68.37 79.76 97.26 72.45 83.04 1.55 4.08 3.28PD 3199 3195 4 0.13 65.8168.7567.25 70.43 72.32 71.37 66.67 69.64 68.12 -3.76 -2.68 -3.25SD 585 585 0 0.00 100 100 100 100 100 100 100 100 100 0.00 0.00 0.00WE 1009 1009 0 0.00 95.74 10097.83 95.74 100 97.83 95.74 100 97.83 0.00 0.00 0.00Total 27951 27779 172 0.62MacroAverage86.0385.3685.16 86.50 85.72 85.55 86.58 85.96 85.80 0.08 0.24 0.25
