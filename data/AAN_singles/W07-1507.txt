Proceedings of the Linguistic Annotation Workshop, pages 45?48,Prague, June 2007. c?2007 Association for Computational LinguisticsUsage of XSL Stylesheets for the annotation of the Sa?mi language corporaSaara HuhmarniemiUniversity of Troms?saara.huhmarniemi@helsinki.fiSjur N. MoshagenNorwegian Sa?mi Parliamentsjur.moshagen@samediggi.noTrond TrosterudUniversity of Troms?trond.trosterud@hum.uit.noAbstractThis paper describes an annotation systemfor Sa?mi language corpora, which consistsof structured, running texts.
The annotationof the texts is fully automatic, starting fromthe original documents in different formats.The texts are first extracted from the origi-nal documents preserving the original struc-tural markup.
The markup is enhanced by adocument-specific XSLT script which con-tains document-specific formatting instruc-tions.
The overall maintenance is achievedby system-wide XSLT scripts.1 IntroductionCorpus building for a specific language is consid-ered to require much human effort and time.
Toovercome this difficulty, there is a recent develop-ment of applications for automatic corpus buildingusing often the Web as a resource e.g.
(Baroni andBernardini eds., 2006; Sharoff, 2006).
For minoritylanguages, the resources for building a text corpusare often limited.
Automatic tools for building cor-pus database specifically for the minority languagesare developed e.g.
by (Ghani et al, 2005; Scannell,2004).The requirement to have the corpus building pro-cess automatized as much as possible was also cen-tral in the Sa?mi language corpora project.
How-ever, the collection of texts is done in a ?traditional?manner: the files are gathered and classified man-ually.
For North Sa?mi, there are texts available inelectronic form which can be exploited in a cor-pus database, mainly administrative and newspapertexts.
The small amount of those texts forced usto take into account a wide variety of sources andformats, and also to include texts that were of lowtechnical quality.
That introduced problems for theautomatic processing of the texts.
The solution tothis problem was the document-specific processinginstructions that were implemented in XSLT.2 The ProjectThe corpus described here is the first structurally an-notated text corpus for any Sa?mi language.
The cor-pus database was developed in parallel with the spellchecker and the syntactic analyzer projects for Northand Lule Sa?mi1.
The new texts became test mate-rial for these two applications as soon as they wereadded to the corpus database.
The requirements forthe markup were constantly being re-evaluated dur-ing the project.
The infrastructure was designedflexible so that it would accomodate to the differ-ent needs of the two projects in different phases ofthe application development.At the moment, the corpus database consists of al-most 6 million words for North Sa?mi and some 240000 for Lule Sa?mi.
Even though the system was pri-marily designed for the Sa?mi languages, there areno strictly language-dependent sections in the sys-tem; it has already been tested with Norwegian andFinnish, among others.One of the main applications of the text corpusdatabase is the syntactically annotated and fully dis-ambiguated corpus database for Sa?mi languages.The syntactic annotation is done automatically us-1http://www.divvun.no/, http://giellatekno.uit.no/45ing the tools developed in the syntactic analyzerproject, but the process is out of the scope of thispaper.
There is also some parallel texts with Norwe-gian, and plans for extending parallel text corpora todifferent Sa?mi languages and Finnish and Swedish.The corpus database is freely available for researchpurposes.
There will be a web-based corpus inter-face for the syntactically annotated corpus and a re-stricted access to the system for examining the cor-pus data directly.3 XSLT and corpus maintenaceFlexibility and reusability are in general the designrequirements of annotated text corpora.
XML hasbecome the standard annotation system in physicalstorage representation.
XML Transformation Lan-guage (XSLT) (Clark ed., 1999) provides an easydata transformation between different formats andapplications.
XSLT is commonly used in the con-temporary corpus development.
The power of XSLTmainly comes from its sublanguage XPath (Clarkand DeRose eds., 1999).
XPath provides an accessto the XML structure, elements, attributes and textthrough concise path expressions.In the Sa?mi language corpora, XSLT is used incorpus establishment and maintenance.
The rawstructural format is produced by text extraction toolsand coverted to a preliminary XML-format usingXSLT.
The markup is further enhanced by documentspecific information and a system-wide processinginstruction, both implemented in XSLT.4 The Sa?mi corpus database4.1 Overall architectureThe corpus database is organized so that the originaltext resources, which are the documents in variousformats (Word, PDF, HTML, text) form the sourcebase.
The text is extracted from the original docu-ments using various freely available text extractiontools, such as antiword and HTML Tidy.
They al-ready provide a preliminary structural markup: anti-word produces DocBook and HTML Tidy providesoutput in XHTML.
There are XSLT scripts for con-verting the different preliminary formats the to anintermediate document format.The intermediate format is further processed tothe desired XML-format using XSLT-scripts.
Theresult is the final XML-document with structuralmarkup, see Fig.
1.Figure 1: The overall architecture of the conversionprocess.The conversion of a document always starts fromthe original file, which makes it possible to adaptfor the latest versions of the text extraction tools andother tools used in the process as well as the changesin XML-markup.The annotation process is fully automatic andcan be rerun at will.
Some documents may con-tain errors or formatting that are not taken into ac-count by the automatic tools.
On the other hand,the automatized annotation process does not allowmanual correction of the texts, nor manual XML-markup.
Those exceptions can be taken into accountby document-specific processing instructions, whichare implemented using XSLT.
The script can be usedfor adding XML-annotation for specific parts of thedocument, fixing smaller errors in the document, oreven to rescue a corrupted file that would be other-wise unusable.
This is a useful feature when build-ing a corpus for a minority language with diverseand often limited text resources.4.2 XML-annotationIn the Sa?mi language corpora, markup of runningtext is simple, containing no more structural infor-mation than what is generally available in the orig-inal text.
The body text can contain sections andparagraphs and each section can contain sectionsand paragraphs.
There are four paragraph types: ti-46tle, text, table and list.
The paragraphs are classifiedwhenever the information is available in the origi-nal document.
Lists and especially tables contain in-complete sentences and in many cases numeric data.When conducting e.g.
syntactic analysis, it mightbe better to leave tables and even lists or titles out,whereas for e.g.
terminological work the tables arehighly relevant.
Tagging for paragraph type makes itpossible to include or exclude the relevant paragraphtypes at will.Inside a paragraph, there is a possibility toadd emphasis markup and other span information,such as quotes.
The sentence-level and word-levelmarkup is not included in the text corpus.
Themarkup is added when the text corpus is moved tothe syntactically annotated corpus database.The XML-annotation does not follow any stan-dardized XML-format, but it is, in essence, a subsetof the XCES (Ide et al, 2000) format.
Furthermore,the system is designed so that changing the XML-annotation and moving to a standardized format is astraightforward process.4.3 XSLT processingEach original document in the corpus database ispaired with an XSLT script.
The document-specificXSLT script contains processing instructions that areapplied to the document during the conversion fromthe preliminary document format to the final XML-format (see Fig.
1.).
The XPath expressions are pow-erful tools for accessing portions of text in a docu-ment and modifying the XML-markup without edit-ing the XML-file itself.
The usage of the XPath ex-pressions entails that the XML-structure of a docu-ment does not change, which poses some restrictionsto the intermediate format of the document.The XSLT script contains the document metadataand status information, among other relevant data.The document metadata is stored in variables inthe document-specific XSLT script, and the system-wide XSLT scripts access these variables and con-vert them to the required format.The system-wide XSLT script contains functionsand templates that can be called from the document-specific XSLT script.
There is for example a string-replacement function for correcting errors that areof technical origin, such as wrongly converted Sa?micharacters that were missed by the automatic detec-tion of wrongly encoded characters.Another example of a template that can be calledfrom the document-specific XSLT script is thestring-replacement, that can be used for markingspelling errors in the text.
Due to the variety of con-ventions of writing Sa?mi, the texts tend to containlot of strings that are classified as spelling errors.The errors disturb the testing of the analyzer, but areon the other hand interesting from the point of viewof the spell checker project.
When a spelling erroris discovered in the text, the erroneous strings andtheir corrections are added to the document-specificmetafile from where they are picked by the con-version process.
The errors are thus preserved inthe XML-format but with a correction which can beused instead of the erroneous string.
This is achievedby a special markup:<error correct="text">tetx</error>In this way the original documents stay intact andthe information is preserved also when the file is re-converted.
If the error is not just a single word butinvolves more context, it is possible to add the con-text to the error string.In addition, the document-specific XSLT scriptcontains variables that may be used already in thetext extraction phase.
An example would be the textalignment information of a pdf-file.4.4 Language identificationMost documents in the Sa?mi corpus database con-tain sections of text that are not in the document?smain language.
Those sections are marked at para-graph level, using the attribute xml:lang.The language identification is done using theTextCat tool (van Noord, 1997).
Since the differ-ent Sa?mi languages and the close relative Finnish re-semble each other significantly (the same is true forthe Scandinavian languages), the search space wasreduced at the document level.
The information ofthe document languages was stored to the document-specific XSLT script.Since the Sa?mi texts contain lot of quotationsfrom other languages, especially from the major-ity language (Norwegian, Swedish or Finnish), thequoted text fragments are analysed separately usingTextCat and marked with a corresponding xml:langattribute.
For example:47<span type="quote" xml:lang="nob">"Arbeidet med fylkesplanene"</span>(bargu fylkkapla?naiguin).When a sentence that contains a quotation in a for-eign language is given to the syntactic analyzer, thequotation can be considered as a syntactic unit andthat way carried through the analysis.4.5 Other processingCharacter set conversion may be a central task whena corpus is built for minority languages, due to alarge repertoire of non-standardized 8-bit charactersets, e.g.
(McEnery et al, 2000; Trosterud, 1996).In the Sa?mi corpus database, the text extraction toolsoften produced wrongly-utf8 -encoded output, dueto erroneous codepage IDs and font specifications.There is a specific module for guessing the docu-ments?
original code-page, and for fixing errouneousutf8-conversion.There are a couple of other scripts that are ap-plied to the final XML-documents.
For example,real hyphenation marks in the document are pre-served for testing of the hyphenator.
The hyphen-tags are marked automatically, taking into accountsome language specific cues and information of e.glist context.5 ConclusionThe system is flexible and reusable since the centralXSLT processing allows for changes in the XML-structure as well as the introduction of new struc-tural information.
The intermediate XML-formatswhich are produced by the text extraction tools arestraightforward to convert to a format that conformsto the project?s DTD using XSLT processing.
In-stead of trying to predict the future uses of the corpusdatabase in the beginning of the project, the infras-tructure was set up so that it evolves throughout theproject.The main problem in the heavy usage of XSLTis that the syntax of the XSLT is quite restricted al-though XSLT/XPath 2 brings some improvements.The lack of regular expressions is one of the restric-tions, so some of the string-replacement functionshad to be implemented by other means.
In the fu-ture, these could probably be replaced with XPath 2functions.Fully-automated, XSL/XML-based conversionhas made it possible to build a corpus of decentsize for small languages.
After the initial infrastruc-ture is created, adding new documents does not re-quire much resources.
The system does not involveany strictly language-dependent processing, so it isportable to other languages.
The result is a clean,classified and XML-annotated corpus which can beused in research and different language technologyapplications.ReferencesMarco Baroni and Silvia Bernardini (eds.).
2006.Wacky!
Working papers on the Web as Corpus.http://wacky.sslmit.unibo.it/.James Clark (ed.).
1999.
XSL Transforma-tions (XSLT) 1.0.
W3C Recommendation.http://www.w3.org/TR/xslt.James Clark and Steve DeRose (eds.).
1999.
XMLPath Language (XPath) 1.0.
W3C Recommendation.http://www.w3.org/TR/xpath.Rayid Ghani, Rosie Jones, and Dunja Mladenic.
2005.Building Minority Language Corpora by Learning toGenerate Web Search Queries.
Knowledge and Infor-mation Systems, 7(1):56?83.Nancy Ide, Patrice Bonhomme, and Laurent Romary.2000.
XCES: An XML-based Encoding Standard forLinguistic Corpora.
Proceedings of the Second Lan-guage Resources and Evaluation Conference (LREC)825?830.Anthony McEnery, Paul Baker, Rob Gaizauskas, HamishCunningham.
2000 EMILLE: Building a corpus ofSouth Asian languages.
Vivek, A Quarterly in.
Artifi-cial Intelligence, 13(3): 23?32.Kevin P. Scannell.
2004.
Corpus Building for MinorityLanguages.
http://borel.slu.edu/crubadan/.Serge Sharoff.
2006.
Open-source corpora: using thenet to fish for linguistic data International Journal ofCorpus Linguistics, 11(4): 435-462.Trond Trosterud.
1996 Funny characters on the net.How information technology may (or may not) do sup-port minority languages.
Arbete ma?nniska miljo?
&Nordisk Ergonomi, 3:114?125.Gertjan van Noord.
1997.
TextCat Language Guesser.http://www.let.rug.nl/?vannoord/TextCat/.48
