Cross-Language Information Retrieval Based onCategory Matching Between Language Versions of a Web DirectoryFuminori KimuraGraduate School ofInformation Science,Nara Institute ofScience and Technology8916-5 Takayama,Ikoma, Nara, JapanAkira MaedaDepartment ofComputer Science,Ritsumeikan University1-1-1 Noji-Higashi,Kusatsu, Shiga, JapanMasatoshi YoshikawaInformation TechnologyCenter, Nagoya UniversityFuro-cho, Chigusa-ku,Nagoya, Aichi, JapanShunsuke UemuraGraduate School ofInformation Science,Nara Institute ofScience and Technology8916-5 Takayama,Ikoma, Nara, JapanAbstractSince the Web consists of documents invarious domains or genres, the methodfor Cross-Language Information Retrieval(CLIR) of Web documents should be in-dependent of a particular domain.
In thispaper, we propose a CLIR method whichemploys a Web directory provided in mul-tiple language versions (such as Yahoo!
).In the proposed method, feature terms arefirst extracted from Web documents foreach category in the source and the tar-get languages.
Then, one or more corre-sponding categories in another languageare determined beforehand by comparingsimilarities between categories across lan-guages.
Using these category pairs, we in-tend to resolve ambiguities of simple dic-tionary translation by narrowing the cat-egories to be retrieved in the target lan-guage.1 IntroductionWith the popularity of the Internet, more and morelanguages are becoming to be used for Web docu-ments, and it is now much easier to access docu-ments written in foreign languages.
However, exist-ing Web search engines only support the retrieval ofdocuments which are written in the same languageas the query, so the monolingual users are not able toretrieve documents written in non-native languagesefficiently.
Also, there might be cases, dependingon the user?s demand, where information written ina language other than the user?s native language isrich.
Needs for retrieving such information mustbe large.
In order to satisfy such needs on a usualmonolingual retrieval system, the user him-/herselfhas to manually translate the query by using a dic-tionary, etc.
This process not only imposes a burdento the user but also might choose incorrect transla-tions for the query, especially for languages that areunfamiliar to the user.To fulfill such needs, researches on Cross-Language Information Retrieval (CLIR), a tech-nique to retrieve documents written in a certain lan-guage using a query written in another language,have been active in recent years.
A variety of meth-ods, including employing corpus statistics for thetranslation of terms and the disambiguation of trans-lated terms, are studied and a certain results hasbeen obtained.
However, corpus-based disambigua-tion methods are heavily affected by the domain ofthe training corpus, so the retrieval effectiveness forother domains might drop significantly.
Besides,since the Web consists of documents in various do-mains or genres, the method for CLIR of Web docu-ments should be independent of a particular domain.In this paper, we propose a CLIR method whichemploys Web directories provided in multiple lan-guage versions (such as Yahoo!).
Our system usestwo or more language versions of a Web directory.One version is the query language, and others arethe target languages.
From these language versions,category correspondences between languages are es-timated in advance.
First, feature terms are extractedfrom Web documents for each category in the sourceand the target languages.
Then, one or more cor-responding categories in another language are de-termined beforehand by comparing similarities be-tween categories across languages.
Using these cat-egory pairs, we intend to resolve ambiguities ofsimple dictionary translation by narrowing the cat-egories to be retrieved in the target language.2 Related WorkApproaches to CLIR can be classified into three cat-egories; document translation, query translation, andthe use of inter-lingual representation.
The approachbased on translation of target documents has the ad-vantage of utilizing existing machine translation sys-tems, in which more content information can be usedfor disambiguation.
Thus, in general, it achievesa better retrieval effectiveness than those based onquery translation(Sakai, 2000).
However, since it isimpractical to translate a huge document collectionbeforehand and it is difficult to extend this method tonew languages, this approach is not suitable for mul-tilingual, large-scale, and frequently-updated collec-tion of the Web.
The second approach transfers bothdocuments and queries into an inter-lingual repre-sentation, such as bilingual thesaurus classes or alanguage-independent vector space.
The latter ap-proach requires a training phase using a bilingual(parallel or comparable) corpus as a training data.The major problem in the approach based on thetranslation and disambiguation of queries is that thequeries submitted from ordinary users of Web searchengines tend to be very short (approximately twowords on average (Jansen et al, 2000)) and usuallyconsist of just an enumeration of keywords (i.e.
nocontext).
However, this approach has an advantagethat the translated queries can simply be fed into ex-isting monolingual search engines.
In this approach,a source language query is first translated into targetlanguage using a bilingual dictionary, and translatedquery is disambiguated.
Our method falls into thiscategory.It is pointed out that corpus-based disambiguationmethods are heavily affected by the difference in do-main between query and corpus.
Hull suggests thatthe difference between query and corpus may causebad influence on retrieval effectiveness in the meth-ods that use parallel or comparable corpora (Hull,1997).
Lin et al conducted comparative experi-ments among three monolingual corpora that havedifferent domains and sizes, and has concluded thatlarge-scale and domain-consistent corpus is neededfor obtaining useful co-occurrence data (Lin et al,1999).On the Web retrieval, which is the target of our re-search, the system has to cope with queries in manydifferent kinds of topics.
However, it is impracti-cal to prepare corpora that cover any possible do-mains.
In our previous paper(Kimura et al, 2003),we proposed a CLIR method which uses documentsin a Web directory that has several language versions(such as Yahoo!
), instead of using existing corpora,in order to improve the retrieval effectiveness.
Inthis paper, we propose an extension of our methodwhich takes account of the hierarchical structure ofWeb directories.
Dumais et al(Dumais and Chen,2000) suggests that the precision of Web documentclassification could be improved to a certain extentby limiting the target categories to compare by us-ing the hierarchical structure of a Web directory.
Inthis paper, we try to improve our proposed methodby incorporating the hierarchical structure of a Webdirectory for merging categories.3 Proposed System3.1 Outline of the SystemOur system uses two or more language versions ofa Web directory.
One version is the query language(language A in Figure 1), others are the target lan-guages to be retrieved (language B in Figure 1).From these language versions, category correspon-dences between languages are estimated in advance.The preprocessing consists of the following foursteps: 1) term extraction from Web documents ineach category, 2) feature term extraction, 3) transla-tion of feature terms, and 4) estimation of categorycorrespondences between different languages.
Fig-ure 1 illustrates the flow of the preprocessing.
Thisexample shows a case that category a in language Acorresponds to a category in language B.
First, thesystem extracts terms from Web documents whichbelong to category a (1).
Secondly, the system cal-culates the weights of the extracted terms.
Thenhigher-weighted terms are extracted as the featureterm set fa of category a (2).
Thirdly, the systemtranslates the feature term set fa into language B(3).
Lastly, the system compares the translated fea-ture term set of category a with feature term sets ofall categories in language B, and estimates the cor-responding category of category a from language B(4).These category pairs are used on retrieval.
First,the system estimates appropriate category for thequery in the query language.
Next, the system se-lects the corresponding category in the target lan-guage using the pre-estimated category pairs.
Fi-nally, the system retrieves Web documents in the se-lected corresponding category.language Acategory afeature termset flanguage Bcategory afeature termset f...compare among languages(1)(2)(3)(4)featureterm DBa bFigure 1: Preprocessing.3.2 Preprocessing3.2.1 Feature Term ExtractionThe feature of each category is represented byits feature term set.
Feature term set is a set ofterms that seem to distinguish the category.
Thefeature term set of each category is extracted in thefollowing steps: First, the system extracts termsfrom Web documents that belong to a given cate-gory.
In this time, system also collect term fre-quency of each word in each category and normal-ize these frequency for each category.
Second, thesystem calculates the weights of the extracted termsusing TF?ICF (term frequency ?
inverse category fre-quency).
Lastly, top n ranked terms are extracted asthe feature term set of the category.Weights of feature terms are calculated byTF?ICF.
TF?ICF is a variation of TF?IDF (term fre-quency ?
inverse document frequency).
Instead ofusing a document as the unit, TF?ICF calculatesweights by category.
TF?ICF is calculated as fol-lows:tf ?
icf(ti, c) = f(ti)Nc ?
logNni + 1where ti is the term appearing in the category c,f(ti) is the term frequency of term ti, Nc is the totalnumber of terms in the category c, ni is number ofthe categories that contain the term ti?and N is thenumber of all categories in the directory.3.2.2 Category Matching Between LanguagesFor estimating category correspondences betweenlanguages, we compare each feature term set of acategory which is extracted in section 3.2.1, and cal-culates similarities between categories across lan-guages.In order to compare two categories between lan-guages, feature term set must be translated into thetarget language.
First, for each feature term, thesystem looks up the term in a bilingual dictionaryand extracts all translation candidates for the featureterm.
Next, the system checks whether each trans-lation candidate exists in the feature term set of thetarget category.
If the translation candidate exists,the system checks the candidate?s weight in the tar-get category.
Lastly, the highest-weighted transla-tion candidate in the feature term set of the targetcategory is selected as the translation of the featureterm.
Thus, translation candidates are determinedfor each category, and translation ambiguity is re-solved.If no translation candidate for a feature term ex-ists in the feature term set of the target category, thatterm is ignored in the comparison.
However, thereare some cases that the source language term itselfis useful as a feature term in the target language.
Forexample, some English terms (mostly abbreviations)are commonly used in documents written in otherlanguages (e.g.
?WWW?, ?HTM?, etc.).
Therefore,in case that no translation candidate for a featureterm exists in the feature term set of the target cat-egory, the feature term itself is checked whether itexists in the feature term set of the target category.If it exists, the feature term itself is treated as thetranslation of the feature term in the target category.As an example, we consider that an English term?system?
is translated into Japanese for the cate-gory ???????????????>??????
>??????
(Computers and Internet >Soft-ware >Security)?
(hereafter called ???????
?for short).
The English term ?system?
has the fol-lowing translation candidates in a dictionary; ???(universe/space)?????
(method)?????
(orga-nization)?????
(organ)???????
(system)??etc.
We check each of these translation candidates inthe feature term set of the category ???????.
?Then the highest-weighted term of these translationcandidates in the category ????????
is deter-mined as the translation of the English term ?sys-tem?
in this category.
If no translation candidate ex-ists in the feature term set of the category ???????,?
the English term ?system?
itself is treated asthe translation.Once all the feature terms are translated, the sys-tem calculates the similarities between categoriesacross languages.
The similarity between the sourcecategory a and the target category b is calculated asthe total of multiplying the weights of each featureterm in the category a by the weight of its transla-tion in the category b.
The similarity of the categorya for the category b is calculated as follows:sim(a, b) =?f?faw(f, a) ?
w(t, b)where f is a feature term, fa is the feature term setof category a, t is the translation of f in the categoryfeature term setof category afeature term setof category bfeature term ftranslationcandidatest1t2t3...dictionarycomparetranslation termin category bFigure 2: Feature term translation.b, and w(f, a) is the weight of f in a.The system calculates the similarities of categorya for each category in the target language using theabove-mentioned method.
Then, a category with thehighest similarity in the target language is selectedas the correspondent of category a.As an example, we consider an example ofcalculating the similarity of an English category?Computers and Internet >Security and Encryption?
(hereafter called ?Encryption?
for short) for the cat-egory ????????
which is mentioned above.Suppose that the feature term set of the category?Encryption?
has the following feature terms; ?pri-vacy?, ?system?, etc., and the weights of these termsare 0.007110, 0.006327, ?
?
?.
Also suppose that theJapanese translations of these terms are ???????
(privacy)?, ?????
(system)?, etc., and theweights of these terms are 0.023999, 0.047117, ?
?
?.In this case, the similarity of the category ?Encryp-tion?
(s1) for the category ????????
(s2) iscalculated as follows:sim(s1, s2) = 0.007110?
0.023999+0.006327?
0.047117+ ?
?
?3.2.3 RetrievalFigure 3 illustrates the processing flow of a re-trieval.
When the user submits a query, the follow-ing steps are processed.In our system, a query consists of some keywords,not of a sentence.
We define the query vector ~q asfollows:~q = (q1, q2, .
.
.
, qn)where qk is the weight of the k-th keyword in thequery.
We define the values of all qk are 1.First, the system calculates the relevance betweenthe query and each category in the source language,and determines the relevant category of the query inthe source language (1).
The relevance between thequery and each category is calculated by multiply-ing the inner product between query terms and thefeature term set of the target category by the angleof these two vectors.
The relevance between queryq and category c is calculated as follows:rel(q, c) = ~q ?
~c ?
~q ?
~c|~q| ?
|~c|where ~c is a vector of category c defined as follows:~c = (w1, w2, .
.
.
, wn)where wk is the weight of the k-th keyword in thefeature term set of c.If there is more than one category whose rele-vance for the query exceeds a certain threshold, allof them are selected as the relevant categories of thequery.
It is because there might be some cases that,for example, documents in the same domain belongto different categories, or a query concept belongs tomultiple domains.Second, the corresponding category in the tar-get language is selected by using category corre-spondences between languages mentioned in section3.2.2 (2).
Third, the query is translated into the tar-get language by using a dictionary and the featureterm set of the corresponding category (3).
Finally,the system retrieves documents in the correspondingcategory (4).4 Category Merging4.1 Previous ExperimentsIn our previous paper(Kimura et al, 2003), we con-ducted experiments of category matching using thesubsets of English and Japanese versions of Yahoo!.language A language B(4)featureterm DBquery(language A)query(language B)(1)(2)(3)(4)Figure 3: Processing in retrieval.The English subset is 559 categories under the cat-egory ?Computers and Internet?
and the Japanesesubset is 654 categories under the correspondingcategory ???????????????
(Com-puters and Internet).?
Total size of English webpages in each category after eliminating HTML tagsare 45,905 bytes on average, ranging from 476 to1,084,676 bytes.
Total size of Japanese web pagesare 22,770 bytes on average, ranging from 467 to409,576 bytes.In our previous experiments, we could not matchcategories across languages with adequate accuracy.It may have been caused by the following reasons;one possible reason is that the size of Web docu-ments was not enough for statistics in some cate-gories, and another is that some categories are ex-cessively divided as a distinct domain.For the former observation, we eliminated the cat-egories whose total bytes of Web documents are lessthan 30KB, but the results were not improved.4.2 Method of Category MergingConsidering the result of the above experiments, weneed to solve the problem of excessive division ofcategories in order to accurately match categoriesbetween languages.The problem might be caused by the followingreasons; one possible reason is that there are somecategories which are too close in topic, and it mightcause poor accuracy.
Another possible reason is thatsome categories have insufficient amount of text inorder to obtain statistically significant values for fea-ture term extraction.
Considering the above observa-tions, we might expect that the accuracy will be im-proved by merging child categories at some level inthe category hierarchy in order to merge some cate-gories similar in topic and to increase the amount oftext in a category.Accordingly, we solve the problem by mergingchild categories into the parent category at somelevel using the directory hierarchy.
As child cate-gories are specialized ones of the parent category,we can assume that these categories have similartopic.
Besides, even if two categories have no directlink from each other, we can assume that categoriesthat have same parent category might also have sim-ilar topic.However, we still need further investigation on atwhich level categories should be merged.Figure 4: Category merging.5 ExperimentsWe are conducting experiments of the proposedmethod to detect relevance category of a query.
Inthis experiment, we used the same subsets men-tioned in section 4.1.
We merged the categories threelevels below the category ?Computers and Internet?into the parent.
The number of categories after cate-gory merging is 342 in English and 265 in Japanese.At first, we have done the experiment using thefollowing formula that uses only inner product,before using the calculation mentioned in section3.2.3.relinner(q, c) = ~q ?
~cIn this experiment, the query has threeterms: ?encryption?
(=q1), ?security?
(=q2), and?system?
(=q3).Table 1 is the list of top 10 relevant categories infirst experiment.
Almost all the categories in the Ta-ble 1 are relevant to the query.
Thus, the relevancecalculation method by only inner product is regardedas an effective method.
However, this method hasthe following problem.
The category that has fewquery terms might be given high relevance when thecategory has the only one query term whose weightin the category is extremely high.In order to reduce this effect, we propose the im-proved method mentioned in section 3.2.3.
Themethod is revised to take account of the angle be-tween ~q and ~c.
Ultimately, the most relevant cate-gory has the vector whose length is long and whosefactors are flat.
The length is considered by innerproduct, on the other hand, flatness is considered bythe angle between ~q and ~c.Table 2 is the list of top 10 relevant categories inthe second experiment using revised method.
Al-though noticeable improvement does not appear, therelevance of the categories which matches few queryterms are ranked lower than the first experiment.6 ConclusionsIn this paper, we proposed a method using a Webdirectory for CLIR.
The proposed method is inde-pendent of a particular domain because it uses docu-ments in a Web directory as the corpus.
Our methodis particularly effective for the case that the docu-ment collection covers wide range of domains suchas the Web.
Besides, our method does not requireexpensive linguistic resources except for a dictio-nary.
Therefore, our method can easily be extendedto other languages as long as the language versionsof a Web directory exist and the dictionary can beobtained.Future work includes improving the categorymatching method and the evaluation of retrieval ef-fectiveness.ReferencesSusan Dumais and Hao Chen.
2000.
Hierarchical clas-sification of Web content.
Proceedings of the 23rdACM International Conference on Research and De-velopment in Information Retrieval(SIGIR2000).David A.
Hull.
1997.
Using structured queries for dis-ambiguation in cross-language information retrieval.Electronic Working Notes of the AAAI Symposium onCross-Language Text and Speech Retrieval.Bernard J. Jansen, Amanda Spink, and Tefko Saracevic.2000.
Real life, real user queries on the Web.
Infor-mation Processing & Management, 36(2).Fuminori Kimura, Akira Maeda, Masatoshi Yoshikawa,and Shunsuke Uemura.
2003.
Cross-Language Infor-mation Retrieval using Web Directory Structure.
The14th Data Engineering Workshop, (in Japanese).Chuan-Jie Lin, Wen-Cheng Lin, Guo-Wei Bian, andHsin-Hsi Chen.
1999.
Description of the NTUJapanese-English cross-lingual information retrievalsystem used for NTCIR workshop.
First NTCIR Work-shop on Research in Japanese Text Retrieval and TermRecognition.Tetsuya Sakai.
2000.
MT-based Japanese-English cross-language IR experiments using the TREC test collec-tions.
Proceedings of The Fifth International Work-shop on Information Retrieval with Asian Languages(IRAL2000).Table 1: The list of top 10 relevant category calculated by inner product.category name relevance weight(q1/q2/q3)Computers and Internet/Security and Encryp-tion/Challenges/0.166845 0.112607/0.054238/0.000000Computers and Internet/Security and Encryp-tion/Conferences/0.126984 0.000000/0.126984/0.000000Computers and Internet/Security and Encryp-tion/Web Directories/0.106283 0.012577/0.093706/0.000000Computers and Internet/Security and Encryp-tion/Organizations/0.089169 0.006647/0.076520/0.006002Business and Economy/Business to Busi-ness/Computers/Security and Encryption/0.087314 0.006391/0.074656/0.006267Computers and Internet/Security and Encryp-tion/Encryption Policy/0.086271 0.075185/0.011086/0.000000Computers and Internet/Security and Encryp-tion/Mailing Lists/0.075399 0.017247/0.058152/0.000000Computers and Internet/Software/OperatingSystems/File Systems/0.075088 0.027648/0.024968/0.022472Computers and Internet/Internet/World WideWeb/Security and Encryption/0.073100 0.005671/0.05612/0.011309Computers and Internet/Software/OperatingSystems/Inferno/0.070922 0.000000/0.000000/0.070922Table 2: The list of the top 10 relevance category calculated by proposed method in section 3.2.3.category name relevance weight(q1/q2/q3)Computers and Internet/Security and Encryp-tion/Challenges/0.128587 0.112607/0.054238/0.000000Computers and Internet/Software/OperatingSystems/File Systems/0.074822 0.027648/0.024968/0.022472Computers and Internet/Security and Encryp-tion/Conferences/0.073314 0.00000/0.126984/0.000000Computers and Internet/Security and Encryp-tion/Web Directories/0.068980 0.012577/0.093706/0.000000Computers and Internet/Security and Encryp-tion/Organizations/0.059585 0.006647/0.07652/0.006002Business and Economy/Business to Busi-ness/Computers/Security and Encryption/0.058539 0.006391/0.074656/0.006267Computers and Internet/Security and Encryp-tion/Encryption Policy/0.056542 0.075185/0.011086/0.000000Computers and Internet/Security and Encryp-tion/Mailing Lists/0.054113 0.017247/0.058152/0.000000Computers and Internet/Internet/World WideWeb/Security and Encryption/0.053628 0.005671/0.05612/0.011309Computers and Internet/Programming and De-velopment/Languages/Java/Security/0.046474 0.000000/0.054276/0.01271
