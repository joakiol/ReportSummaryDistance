Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 271?281,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsLearning to Automatically Solve Algebra Word ProblemsNate Kushman?, Yoav Artzi?, Luke Zettlemoyer?, and Regina Barzilay?
?Computer Science and Articial Intelligence Laboratory, Massachusetts Institute of Technology{nkushman, regina}@csail.mit.edu?Computer Science & Engineering, University of Washington{yoav, lsz}@cs.washington.eduAbstractWe present an approach for automaticallylearning to solve algebra word problems.Our algorithm reasons across sentenceboundaries to construct and solve a sys-tem of linear equations, while simultane-ously recovering an alignment of the vari-ables and numbers in these equations tothe problem text.
The learning algorithmuses varied supervision, including eitherfull equations or just the final answers.
Weevaluate performance on a newly gatheredcorpus of algebra word problems, demon-strating that the system can correctly an-swer almost 70% of the questions in thedataset.
This is, to our knowledge, the firstlearning result for this task.1 IntroductionAlgebra word problems concisely describe a worldstate and pose questions about it.
The describedstate can be modeled with a system of equationswhose solution specifies the questions?
answers.For example, Figure 1 shows one such problem.The reader is asked to infer how many children andadults were admitted to an amusement park, basedon constraints provided by ticket prices and overallsales.
This paper studies the task of learning toautomatically solve such problems given only thenatural language.1Solving these problems requires reasoningacross sentence boundaries to find a system ofequations that concisely models the described se-mantic relationships.
For example, in Figure 1,the total ticket revenue computation in the secondequation summarizes facts about ticket prices andtotal sales described in the second, third, and fifth1The code and data for this work are availableat http://groups.csail.mit.edu/rbg/code/wordprobs/.Word problemAn amusement park sells 2 kinds of tickets.Tickets for children cost $1.50.
Adult ticketscost $4.
On a certain day, 278 people enteredthe park.
On that same day the admission feescollected totaled $792.
How many childrenwere admitted on that day?
How many adultswere admitted?Equationsx+ y = 2781.5x+ 4y = 792Solutionx = 128 y = 150Figure 1: An example algebra word problem.
Ourgoal is to map a given problem to a set of equationsrepresenting its algebraic meaning, which are thensolved to get the problem?s answer.sentences.
Furthermore, the first equation modelsan implicit semantic relationship, namely that thechildren and adults admitted are non-intersectingsubsets of the set of people who entered the park.Our model defines a joint log-linear distribu-tion over full systems of equations and alignmentsbetween these equations and the text.
The spaceof possible equations is defined by a set of equa-tion templates, which we induce from the train-ing examples, where each template has a set ofslots.
Number slots are filled by numbers fromthe text, and unknown slots are aligned to nouns.For example, the system in Figure 1 is gener-ated by filling one such template with four spe-cific numbers (1.5, 4, 278, and 792) and align-ing two nouns (?Tickets?
in ?Tickets for children?,and ?tickets?
in ?Adult tickets?).
These inferredcorrespondences are used to define cross-sentencefeatures that provide global cues to the model.For instance, in our running example, the string271pairs (?$1.50?, ?children?)
and (?$4?,?adults?
)both surround the word ?cost,?
suggesting an out-put equation with a sum of two constant-variableproducts.We consider learning with two different levelsof supervision.
In the first scenario, we assume ac-cess to each problem?s numeric solution (see Fig-ure 1) for most of the data, along with a smallset of seed examples labeled with full equations.During learning, a solver evaluates competing hy-potheses to drive the learning process.
In the sec-ond scenario, we are provided with a full systemof equations for each problem.
In both cases, theavailable labeled equations (either the seed set, orthe full set) are abstracted to provide the model?sequation templates, while the slot filling and align-ment decisions are latent variables whose settingsare estimated by directly optimizing the marginaldata log-likelihood.The approach is evaluated on a new corpus of514 algebra word problems and associated equa-tion systems gathered from Algebra.com.
Pro-vided with full equations during training, our al-gorithm successfully solves over 69% of the wordproblems from our test set.
Furthermore, we findthe algorithm can robustly handle weak supervi-sion, achieving more than 70% of the above per-formance when trained exclusively on answers.2 Related WorkOur work is related to three main areas of research:situated semantic interpretation, information ex-traction, and automatic word problem solvers.Situated Semantic Interpretation There is alarge body of research on learning to map nat-ural language to formal meaning representations,given varied forms of supervision.
Reinforcementlearning can be used to learn to read instructionsand perform actions in an external world (Brana-van et al, 2009; Branavan et al, 2010; Vogeland Jurafsky, 2010).
Other approaches have re-lied on access to more costly annotated logicalforms (Zelle and Mooney, 1996; Thompson andMooney, 2003; Wong and Mooney, 2006; Zettle-moyer and Collins, 2005; Kwiatkowski et al,2010).
These techniques have been generalizedmore recently to learn from sentences paired withindirect feedback from a controlled application.Examples include question answering (Clarke etal., 2010; Cai and Yates, 2013a; Cai and Yates,2013b; Berant et al, 2013; Kwiatkowski et al,2013), dialog systems (Artzi and Zettlemoyer,2011), robot instruction (Chen and Mooney, 2011;Chen, 2012; Kim and Mooney, 2012; Matuszek etal., 2012; Artzi and Zettlemoyer, 2013), and pro-gram executions (Kushman and Barzilay, 2013;Lei et al, 2013).
We focus on learning from variedsupervision, including question answers and equa-tion systems, both can be obtained reliably fromannotators with no linguistic training and only ba-sic math knowledge.Nearly all of the above work processed sin-gle sentences in isolation.
Techniques that con-sider multiple sentences typically do so in a se-rial fashion, processing each in turn with limitedcross-sentence reasoning (Branavan et al, 2009;Zettlemoyer and Collins, 2009; Chen and Mooney,2011; Artzi and Zettlemoyer, 2013).
We focus onanalyzing multiple sentences simultaneously, asis necessary to generate the global semantic rep-resentations common in domains such as algebraword problems.Information Extraction Our approach is relatedto work on template-based information extraction,where the goal is to identify instances of eventtemplates in text and extract their slot fillers.
Mostwork has focused on the supervised case, wherethe templates are manually defined and data is la-beled with alignment information, e.g.
(Grishmanet al, 2005; Maslennikov and Chua, 2007; Ji andGrishman, 2008; Reichart and Barzilay, 2012).However, some recent work has studied the au-tomatic induction of the set of possible templatesfrom data (Chambers and Jurafsky, 2011; Ritter etal., 2012).
In our approach, systems of equationsare relatively easy to specify, providing a type oftemplate structure, and the alignment of the slotsin these templates to the text is modeled primar-ily with latent variables during learning.
Addition-ally, mapping to a semantic representation that canbe executed allows us to leverage weaker supervi-sion during learning.Automatic Word Problem Solvers Finally, therehas been research on automatically solving vari-ous types of mathematical word problems.
Thedominant existing approach is to hand engineerrule-based systems to solve math problem in spe-cific domains (Mukherjee and Garain, 2008; Levet al, 2004).
Our focus is on learning a modelfor the end-to-end task of solving word problemsgiven only a training corpus of questions pairedwith equations or answers.272Derivation 1WordproblemAn amusement park sells 2 kinds of tickets.
Tickets for children cost $ 1.50 .
Adulttickets cost $ 4 .
On a certain day, 278 people entered the park.
On that same day theadmission fees collected totaled $ 792 .
How many children were admitted on thatday?
How many adults were admitted?Alignedtemplateu11+ u12?
n1= 0 n2?
u21+ n3?
u22?
n4= 0Instantiatedequationsx+ y ?
278 = 0 1.5x+ 4y ?
792 = 0Answerx = 128y = 150Derivation 2WordproblemA motorist drove 2 hours at one speed and then for 3 hours at another speed.
Hecovered a distance of 252 kilometers.
If he had traveled 4 hours at the first speed and1 hour at the second speed , he would have covered 244 kilometers.
Find two speeds?Alignedtemplaten1?
u11+ n2?
u12?
n3= 0 n4?
u21+ n5?
u22?
n6= 0Instantiatedequations2x+ 3y ?
252 = 0 4x+ 1y ?
244 = 0Answerx = 48y = 52Figure 2: Two complete derivations for two different word problems.
Derivation 1 shows an alignmentwhere two instances of the same slot are aligned to the same word (e.g., u11and u21both are aligned to?Tickets?).
Derivation 2 includes an alignment where four identical nouns are each aligned to differentslot instances in the template (e.g., the first ?speed?
in the problem is aligned to u11).3 Mapping Word Problems to EquationsWe define a two step process to map word prob-lems to equations.
First, a template is selectedto define the overall structure of the equation sys-tem.
Next, the template is instantiated with num-bers and nouns from the text.
During inference weconsider these two steps jointly.Figure 2 shows both steps for two derivations.The template dictates the form of the equations inthe system and the type of slots in each: u slotsrepresent unknowns and n slots are for numbersthat must be filled from the text.
In Derivation 1,the selected template has two unknown slots, u1and u2, and four number slots, n1to n4.
Slotscan be shared between equations, for example, theunknown slots u1and u2in the example appearin both equations.
A slot may have different in-stances, for example u11and u21are the two in-stances of u1in the example.We align each slot instance to a word in theproblem.
Each number slot n is aligned to a num-ber, and each unknown slot u is aligned to a noun.For example, Derivation 1 aligns the number 278to n1, 1.50 to n2, 4 to n3, and 792 to n4.
It alsoaligns both instances of u1(e.g., u11and u21) to?Tickets?, and both instances of u2to ?tickets?.In contrast, in Derivation 2, instances of the sameunknown slot (e.g.
u11and u21) are aligned to twodifferent words in the problem (different occur-rences of the word ?speed?).
This allows for atighter mapping between the natural language andthe system template, where the words aligned tothe first equation in the template come from thefirst two sentences, and the words aligned to thesecond equation come from the third.Given an alignment, the template can then beinstantiated: each number slot n is replaced withthe aligned number, and each unknown slot u witha variable.
This output system of equations is thenautomatically solved to generate the final answer.2733.1 DerivationsDefinitions Let X be the set of all word problems.A word problem x ?
X is a sequence of k words?w1, .
.
.
wk?.
Also, define an equation template tto be a formulaA = B, whereA andB are expres-sions.
An expression A is one of the following:?
A number constant f .?
A number slot n.?
An unknown slot u.?
An application of a mathematical relation Rto two expressions (e.g., n1?
u1).We define a system template T to be a set of lequation templates {t0, .
.
.
, tl}.
T is the set ofall system templates.
A slot may occur more thanonce in a system template, to allow variables tobe reused in different equations.
We denote a spe-cific instance i of a slot, u for example, as ui.
Forbrevity, we omit the instance index when a slot ap-pears only once.
To capture a correspondence be-tween the text of x and a template T , we define analignment p to be a set of pairs (w, s), where w isa token in x and s is a slot instance in T .Given the above definitions, an equation e canbe constructed from a template t where each num-ber slot n is replaced with a real number, each un-known slot u is replaced with a variable, and eachnumber constant f is kept as is.
We call the pro-cess of turning a template into an equation tem-plate instantiation.
Similarly, an equation systemE is a set of l equations {e0, .
.
.
, el}, which canbe constructed by instantiating each of the equa-tion templates in a system template T .
Finally, ananswer a is a tuple of real numbers.We define a derivation y from a word problemto an answer as a tuple (T, p, a), where T is the se-lected system template, p is an alignment betweenT and x, and a is the answer generated by instan-tiating T using x through p and solving the gener-ated equations.
Let Y be the set of all derivations.The Space of Possible Derivations We aim tomap each word problem x to an equation systemE.
The space of equation systems considered isdefined by the set of possible system templates Tand the words in the original problem x, that areavailable for filling slots.
In practice, we gener-ate T from the training data, as described in Sec-tion 4.1.
Given a system template T ?
T , wecreate an alignment p between T and x.
The setof possible alignment pairs is constrained as fol-An amusement park sells 2 kinds of tickets.Tickets for children cost $ 1.50 .
Adult tick-ets cost $ 4 .
On a certain day, 278 peopleentered the park.
On that same day the ad-mission fees collected totaled $ 792 .
Howmany children were admitted on that day?How many adults were admitted?u11+ u12?
n1= 0n2?
u21+ n3?
u22?
n4= 0Figure 3: The first example problem and selectedsystem template from Figure 2 with all potentialaligned words marked.
Nouns (boldfaced) may bealigned to unknown slot instances uji, and num-ber words (highlighted) may be aligned to numberslots ni.lows: each number slot n ?
T can be aligned toany number in the text, a number word can onlybe aligned to a single slot n, and must be alignedto all instances of that slot.
Additionally, an un-known slot instance u ?
T can only be aligned toa noun word.
A complete derivation?s alignmentpairs all slots in T with words in x.Figure 3 illustrates the space of possible align-ments for the first problem and system templatefrom Figure 2.
Nouns (shown in boldface) canbe aligned to any of the unknown slot instancesin the selected template (u11, u21, u12, and u22for thetemplate selected).
Numbers (highlighted) can bealigned to any of the number slots (n1, n2, n3, andn4in the template).3.2 Probabilistic ModelDue to the ambiguity in selecting the system tem-plate and alignment, there will be many possiblederivations y ?
Y for each word problem x ?
X .We discriminate between competing analyses us-ing a log-linear model, which has a feature func-tion ?
: X ?
Y ?
Rdand a parameter vector?
?
Rd.
The probability of a derivation y given aproblem x is defined as:p(y|x; ?)
=e???(x,y)?y??Ye???(x,y?
)Section 6 defines the full set of features used.The inference problem at test time requires usto find the most likely answer a given a problem274x, assuming the parameters ?
are known:f(x) = argmaxap(a|x; ?
)Here, the probability of the answer is marginalizedover template selection and alignment:p(a|x; ?)
=?y?Ys.t.
AN(y)=ap(y|x; ?)
(1)where AN(y) extracts the answer a out of deriva-tion y.
In this way, the distribution over deriva-tions y is modeled as a latent variable.
We use abeam search inference procedure to approximatelycompute Equation 1, as described in Section 5.4 LearningTo learn our model, we need to induce the struc-ture of system templates in T and estimate themodel parameters ?.4.1 Template InductionIt is possible to generate system templates T whenprovided access to a set of n training examples{(xi, Ei) : i = 1, .
.
.
, n}, where xiis a wordproblem and Eiis a set of equations.
We general-ize eachE to a system template T by (a) replacingeach variable with an unknown slot, and (b) re-placing each number mentioned in the text with anumber slot.
Numbers not mentioned in the prob-lem text remain in the template as constants.
Thisallows us to solve problems that require numbersthat are implied by the problem semantics ratherthan appearing directly in the text, such as the per-cent problem in Figure 4.4.2 Parameter EstimationFor parameter estimation, we assume access ton training examples {(xi,Vi) : i = 1, .
.
.
, n},each containing a word problem xiand a val-idation function Vi.
The validation functionV : Y ?
{0, 1} maps a derivation y ?
Y to 1 ifit is correct, or 0 otherwise.We can vary the validation function to learnfrom different types of supervision.
In Sec-tion 8, we will use validation functions that checkwhether the derivation y has either (1) the cor-rect system of equations E, or (2) the correct an-swer a.
Also, using different types of validationfunctions on different subsets of the data enablessemi-supervised learning.
This approach is relatedto Artzi and Zettlemoyer (2013).Word problemA chemist has a solution that is 18 % alco-hol and one that is 50 % alcohol.
He wantsto make 80 liters of a 30 % solution.
Howmany liters of the 18 % solution should headd?
How many liters of the 30 % solutionshould he add?Labeled equations18?
0.01?
x + 50?
0.01?
y = 30?
0.01?
80x + y = 80Induced template systemn1?
0.01?
u11+ n2?
0.01?
u12= n3?
0.01?
n4u21+ u22= n5Figure 4: During template induction, we automat-ically detect the numbers in the problem (high-lighted above) to generalize the labeled equationsto templates.
Numbers not present in the text areconsidered part of the induced template.We estimate ?
by maximizing the conditionallog-likelihood of the data, marginalizing over allvalid derivations:O =?i?y?Ys.t.
Vi(y)=1log p(y|xi; ?
)We use L-BFGS (Nocedal and Wright, 2006) tooptimize the parameters.
The gradient of the indi-vidual parameter ?jis given by:?O??j=?iEp(y|xi,Vi(y)=1;?
)[?j(xi, y)]?Ep(y|xi;?
)[?j(xi, y)](2)Section 5 describes how we approximate thetwo terms of the gradient using beam search.5 InferenceComputing the normalization constant for Equa-tion 1 requires summing over all templates and allpossible ways to instantiate them.
This results ina search space exponential in the number of slotsin the largest template in T , the set of availablesystem templates.
Therefore, we approximate thiscomputation using beam search.
We initialize thebeam with all templates in T and iteratively alignslots from the templates in the beam to words inthe problem text.
For each template, the next slot275to be considered is selected according to a pre-defined canonicalized ordering for that template.After each iteration we prune the beam to keep thetop-k partial derivations according to the modelscore.
When pruning the beam, we allow at most lpartial derivations for each template, to ensure thata small number of templates don?t monopolize thebeam.
We continue this process until all templatesin the beam are fully instantiated.During learning we compute the second term inthe gradient (Equation 2) using our beam searchapproximation.
Depending on the available vali-dation function V (as defined in Section 4.2), wecan also accurately prune the beam for the com-putation of the first half of the gradient.
Specifi-cally, when assuming access to labeled equations,we can constrain the search to consider only par-tial hypotheses that could possibly be completedto produce the labeled equations.6 Model DetailsTemplate Canonicalization There are many syn-tactically different but semantically equivalentways to express a given system of equations.
Forexample, the phrase ?John is 3 years older thanBill?
can be written as j = b+ 3 or j ?
3 = b.To avoid such ambiguity, we canonicalize tem-plates into a normal form representation.
We per-form this canonicalization by obtaining the sym-bolic solution for the unknown slots in terms ofthe number slots and constants using the mathe-matical solver Maxima (Maxima, 2014).Slot Signature In a template like s1+s2= s3, theslot s1is distinct from the slot s2, but we wouldlike them to share many of the features used in de-ciding their alignment.
To facilitate this, we gener-ate signatures for each slot and slot pair.
The sig-nature for a slot indicates the system of equationsit appears in, the specific equation it is in, and theterms of the equation it is a part of.
Pairwise slotsignatures concatenate the signatures for the twoslots as well as indicating which terms are shared.This allows, for example, n2and n3in Derivation1 in Figure 2 to have the same signature, while thepairs ?n2, u1?
and ?n3, u1?
have different ones.
Toshare features across templates, slot and slot-pairsignatures are generated for both the full template,as well as for each of the constituent equations.Features The features ?
(x, y) are computed for aderivation y and problem x and cover all deriva-Document levelUnigramsBigramsSingle slotHas the same lemma as a question objectIs a question objectIs in a question sentenceIs equal to one or two (for numbers)Word lemma X nearby constantSlot pairDep.
path contains: WordDep.
path contains: Dep.
TypeDep.
path contains: Word X Dep.
TypeAre the same word instanceHave the same lemmaIn the same sentenceIn the same phraseConnected by a prepositionNumbers are equalOne number is larger than the otherEquivalent relationshipSolution FeaturesIs solution all positiveIs solution all integerTable 1: The features divided into categories.tion decisions, including template and alignmentselection.
When required, we use standard toolsto generate part-of-speech tags, lematizations, anddependency parses to compute features.2For eachnumber word in y we also identify the closest nounin the dependency parse.
For example, the nounfor 278 in Derivation 1, Figure 2 would be ?peo-ple.?
The features are calculated based on thesenouns, rather than the number words.We use four types of features: document levelfeatures, features that look at a single slot entry,features that look at pairs of slot entries, and fea-tures that look at the numeric solutions.
Table 1lists all the features used.
Unless otherwise noted,when computing slot and slot pair features, a sep-arate feature is generated for each of the signaturetypes discussed earlier.Document level features Oftentimes the naturallanguage in x will contain words or phrases whichare indicative of a certain template, but are not as-sociated with any of the words aligned to slots inthe template.
For example, the word ?chemist?2In our experiments these are generated using the Stan-ford parser (de Marneffe et al, 2006)276might indicate a template like the one seen in Fig-ure 4.
We include features that connect each tem-plate with the unigrams and bigrams in the wordproblem.
We also include an indicator feature foreach system template, providing a bias for its use.Single Slot Features The natural language x al-ways contains one or more questions or commandsindicating the queried quantities.
For example, thefirst problem in Figure 2 asks ?How many childrenwere admitted on that day??
The queried quanti-ties, the number of children in this case, must berepresented by an unknown in the system of equa-tions.
We generate a set of features which look atboth the word overlap and the noun phrase overlapbetween slot words and the objects of a question orcommand sentence.
We also compute a feature in-dicating whether a slot is filled from a word in aquestion sentence.
Additionally, algebra problemsfrequently use phrases such as ?2 kinds of tickets?
(e.g., Figure 2).
These numbers do not typicallyappear in the equations.
To account for this, weadd a single feature indicating whether a numberis one or two.
Lastly, many templates contain con-stants which are identifiable from words used innearby slots.
For example, in Figure 4 the con-stant 0.01 is related to the use of ?%?
in the text.To capture such usage, we include a set of lexical-ized features which concatenate the word lemmawith nearby constants in the equation.
These fea-tures do not include the slot signature.Slot Pair Features The majority of features wecompute account for relationships between slotwords.
This includes features that trigger forvarious equivalence relations between the wordsthemselves, as well as features of the dependencypath between them.
We also include features thatlook at the numerical relationship of two num-bers, where the numeric values of the unknownsare generated by solving the system of equations.This helps recognize that, for example, the total ofa sum is typically larger than each of the (typicallypositive) summands.Additionally, we also have a single feature look-ing at shared relationships between pairs of slots.For example, in Figure 2 the relationship between?tickets for children?
and ?$1.50?
is ?cost?.
Sim-ilarly the relationship between ?Adult tickets?
and?$4?
is also ?cost?.
Since the actual nature of thisrelationship is not important, this feature is notlexicalized, instead it is only triggered for the pres-ence of equality.
We consider two cases: subject-# problems 514# sentences 1616# words 19357Vocabulary size 2352Mean words per problem 37Mean sentences per problem 3.1Mean nouns per problem 13.4# unique equation systems 28Mean slots per system 7Mean derivations per problem 4MTable 2: Dataset statistics.object relationships where the intervening verbis equal, and noun-to-preposition object relation-ships where the intervening preposition is equal.Solution Features By grounding our semantics inmath, we are able to include features which lookat the final answer, a, to learn which answers arereasonable for the algebra problems we typicallysee.
For example, the solution to many, but not all,of the problems involves the size of some set ofobjects which must be both positive and integer.7 Experimental SetupDataset We collected a new dataset of alge-bra word problems from Algebra.com, a crowd-sourced tutoring website.
The questions wereposted by students for members of the communityto respond with solutions.
Therefore, the problemsare highly varied, and are taken from real prob-lems given to students.
We heuristically filteredthe data to get only linear algebra questions whichdid not require any explicit background knowl-edge.
From these we randomly chose a set of1024 questions.
As the questions are posted to aweb forum, the posts often contained additionalcomments which were not part of the word prob-lems and the solutions are embedded in long free-form natural language descriptions.
To clean thedata we asked Amazon Mechanical Turk workersto extract from the text: the algebra word prob-lem itself, the solution equations, and the numericanswer.
We manually verified both the equationsand the numbers to ensure they were correct.
Toensure each problem type is seen at least a fewtimes in the training data, we removed the infre-quent problem types.
Specifically, we induced thesystem template from each equation system, as de-scribed in Section 4.1, and removed all problemsfor which the associated system template appeared277less than 6 times in the dataset.
This left us with514 problems.
Table 2 provides the data statistics.Forms of Supervision We consider both semi-supervised and supervised learning.
In the semi-supervised scenario, we assume access to the nu-merical answers of all problems in the training cor-pus and to a small number of problems paired withfull equation systems.
To select which problemsto annotate with equations, we identified the fivemost common types of questions in the data andannotated a randomly sampled question of eachtype.
5EQ+ANS uses this form of weak supervi-sion.
To show the benefit of using the weakly su-pervised data, we also provide results for a base-line scenario 5EQ, where the training data includesonly the five seed questions annotated with equa-tion systems.
In the fully supervised scenarioALLEQ, we assume access to full equation sys-tems for the entire training set.Evaluation Protocol We run all our experimentsusing 5-fold cross-validation.
Since our modelgenerates a solution for every problem, we reportonly accuracy.
We report two metrics: equationaccuracy to measure how often the system gener-ates the correct equation system, and answer accu-racy to evaluate how often the generated numericalanswer is correct.
When comparing equations, weavoid spurious differences by canonicalizing theequation system, as described in Section 6.
Tocompare answer tuples we disregard the orderingand require each number appearing in the refer-ence answer to appear in the generated answer.Parameters and Solver In our experiments we setk in our beam search algorithm (Section 5) to 200,and l to 20.
We run the L-BFGS computation for50 iterations.
We regularize our learning objec-tive using the L2-norm and a ?
value of 0.1.
Theset of mathematical relations supported by our im-plementation is {+,?,?, /}.Our implementationuses the Gaussian Elimination function in the Effi-cient Java Matrix Library (EJML) (Abeles, 2014)to generate answers given a set of equations.8 Results8.1 Impact of SupervisionTable 3 summarizes the results.
As expected, hav-ing access to the full system of equations (ALLEQ)at training time results in the best learned model,with nearly 69% accuracy.
However, trainingfrom primarily answer annotations (5EQ+ANS)Equation Answeraccuracy accuracy5EQ 20.4 20.85EQ+ANS 45.7 46.1ALLEQ 66.1 68.7Table 3: Cross-validation accuracy results for var-ious forms of supervision.Equation Answer % ofaccuracy accuracy data?
10 43.6 50.8 25.511?
15 46.6 45.1 10.516?
20 44.2 52.0 11.3> 20 85.7 86.1 52.7Table 4: Performance on different template fre-quencies for ALLEQ.results in performance which is almost 70% ofALLEQ, demonstrating the value of weakly super-vised data.
In contrast, 5EQ, which cannot use thisweak supervision, performs much worse.8.2 Performance and Template FrequencyTo better understand the results, we also measuredequation accuracy as a function of the frequencyof each equation template in the data set.
Table 4reports results for ALLEQ after grouping the prob-lems into four different frequency bins.
We cansee that the system correctly answers more than85% of the question types which occur frequentlywhile still achieving more than 50% accuracy onthose that occur relatively infrequently.
We do notinclude template frequency results for 5EQ+ANSsince in this setup our system is given only the topfive most common templates.
This limited set oftemplates covers only those questions in the > 20bin, or about 52% of the data.
However, on thissubset 5EQ+ANS performs very well, answering88% of them correctly, which is approximately thesame as the 86% achieved by ALLEQ.
Thus whilethe weak supervision is not helpful in generatingthe space of possible equations, it is very helpfulin learning to generate the correct answer whengiven an appropriate space of equations.8.3 Ablation AnalysisTable 5 shows ablation results for each group offeatures.
The results along the diagonal show theperformance when a single group of features isablated, while the off-diagonal numbers show the278w/o w/o w/o w/opair document solution singlew/o pair 42.8 25.7 19.0 39.6w/o document ?
63.8 50.4 57.6w/o solution ?
?
63.6 62.0w/o single ?
?
?
65.9Table 5: Cross-validation accuracy results withdifferent feature groups ablated for ALLEQ.
Re-sults are for answer accuracy which is 68.7% with-out any features ablated.performance when two groups of features are ab-lated together.
We can see that all of the featurescontribute to the overall performance, and that thepair features are the most important followed bythe document and solution features.
We also seethat the pair features can compensate for the ab-sence of other features.
For example, the perfor-mance drops only slightly when either the docu-ment or solution features are removed in isolation.However, the drop is much more dramatic whenthey are removed along with the pair features.8.4 Qualitative Error AnalysisWe examined our system output on one fold ofALLEQ and identified two main classes of errors.The first, accounting for approximately one-quarter of the cases, includes mistakes wheremore background or world knowledge might havehelped.
For example, Problem 1 in Figure 5 re-quires understanding the relation between the di-mensions of a painting, and how this relation ismaintained when the painting is printed, and Prob-lem 2 relies on understanding concepts of com-merce, including cost, sale price, and profit.
Whilethese relationships could be learned in our modelwith enough data, as it does for percentage prob-lems (e.g., Figure 4), various outside resources,such as knowledge bases (e.g.
Freebase) or distri-butional statistics from a large text corpus, mighthelp us learn them with less training data.The second category, which accounts for abouthalf of the errors, includes mistakes that stem fromcompositional language.
For example, the secondsentence in Problem 3 in Figure 5 could generatethe equation 2x?y = 5, with the phrase ?twice ofone of them?
generating the expression 2x.
Giventhe typical shallow nesting, it?s possible to learntemplates for these cases given enough data, and inthe future it might also be possible to develop new,cross-sentence semantic parsers to enable bettergeneralization from smaller datasets.
(1)A painting is 10 inches tall and 15 incheswide.
A print of the painting is 25 inchestall, how wide is the print in inches?
(2)A textbook costs a bookstore 44 dollars,and the store sells it for 55 dollars.
Findthe amount of profit based on the sellingprice.
(3)The sum of two numbers is 85.
The dif-ference of twice of one of them and theother one is 5.
Find both numbers.
(4)The difference between two numbers is6.
If you double both numbers, the sumis 36.
Find the two numbers.Figure 5: Examples of problems our system doesnot solve correctly.9 ConclusionWe presented an approach for automatically learn-ing to solve algebra word problems.
Our algorithmconstructs systems of equations, while aligningtheir variables and numbers to the problem text.Using a newly gathered corpus we measured theeffects of various forms of weak supervision onperformance.
To the best of our knowledge, wepresent the first learning result for this task.There are still many opportunities to improvethe reported results, and extend the approach torelated domains.
We would like to develop tech-niques to learn compositional models of mean-ing for generating new equations.
Furthermore,the general representation of mathematics lends it-self to many different domains including geome-try, physics, and chemistry.
Eventually, we hopeto extend the techniques to synthesize even morecomplex structures, such as computer programs,from natural language.AcknowledgmentsThe authors acknowledge the support of BattelleMemorial Institute (PO#300662) and NSF (grantIIS-0835652).
We thank Nicholas FitzGerald, theMIT NLP group, the UW NLP group and theACL reviewers for their suggestions and com-ments.
Any opinions, findings, conclusions, orrecommendations expressed in this paper are thoseof the authors, and do not necessarily reflect theviews of the funding organizations.279ReferencesPeter Abeles.
2014.
Efficient java matrix library.https://code.google.com/p/efficient-java-matrix-library/.Yoav Artzi and Luke Zettlemoyer.
2011.
Bootstrap-ping semantic parsers from conversations.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing.Yoav Artzi and Luke Zettlemoyer.
2013.
Weakly su-pervised learning of semantic parsers for mappinginstructions to actions.
Transactions of the Associa-tion for Computational Linguistics.Jonathan Berant, Andrew Chou, Roy Frostig, and PercyLiang.
2013.
Semantic parsing on freebase fromquestion-answer pairs.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing.S.R.K Branavan, Harr Chen, Luke Zettlemoyer, andRegina Barzilay.
2009.
Reinforcement learning formapping instructions to actions.
In Proceedings ofthe Annual Meeting of the Association for Computa-tional Linguistics.S.R.K Branavan, Luke Zettlemoyer, and Regina Barzi-lay.
2010.
Reading between the lines: Learning tomap high-level instructions to commands.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics.Qingqing Cai and Alexander Yates.
2013a.
Large-scale semantic parsing via schema matching and lex-icon extension.
In Proceedings of the Annual Meet-ing of the Association for Computational Linguis-tics.Qingqing Cai and Alexander Yates.
2013b.
Seman-tic parsing freebase: Towards open-domain seman-tic parsing.
In Proceedings of the Joint Conferenceon Lexical and Computational Semantics.Nathanael Chambers and Dan Jurafsky.
2011.Template-based information extraction without thetemplates.
In Proceedings of the Annual Meeting ofthe Association for Computational Linguistics.David Chen and Raymond Mooney.
2011.
Learningto interpret natural language navigation instructionsfrom observations.
In Proceedings of the Confer-ence on Artificial Intelligence.David Chen.
2012.
Fast online lexicon learning forgrounded language acquisition.
In Proceedings ofthe Annual Meeting of the Association for Computa-tional Linguistics.James Clarke, Dan Goldwasser, Ming-Wei Chang, andDan Roth.
2010.
Driving semantic parsing from theworld?s response.
In Proceedings of the Conferenceon Computational Natural Language Learning.
As-sociation for Computational Linguistics.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher Manning.
2006.
Generating typed de-pendency parses from phrase structure parses.
InProceedings of the Conference on Language Re-sources and Evaluation.Ralph Grishman, David Westbrook, and Adam Mey-ers.
2005.
NYUs English ACE 2005 System De-scription.
In Proceedings of the Automatic ContentExtraction Evaluation Workshop.Heng Ji and Ralph Grishman.
2008.
Refining event ex-traction through cross-document inference.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics.Joohyun Kim and Raymond Mooney.
2012.
Unsuper-vised pcfg induction for grounded language learningwith highly ambiguous supervision.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.Nate Kushman and Regina Barzilay.
2013.
Using se-mantic unification to generate regular expressionsfrom natural language.
In Proceeding of the AnnualMeeting of the North American Chapter of the Asso-ciation for Computational Linguistics.Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-ter, and Mark Steedman.
2010.
Inducing proba-bilistic ccg grammars from logical form with higher-order unification.
In Proceedings of the Conferenceon Empirical Methods on Natural Language Pro-cessing.Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and LukeZettlemoyer.
2013.
Scaling semantic parsers withon-the-fly ontology matching.
In Proceedings ofEmpirical Methods in Natural Language Process-ing.Tao Lei, Fan Long, Regina Barzilay, and Martin Ri-nard.
2013.
From natural language specifications toprogram input parsers.
In Proceeding of the Associ-ation for Computational Linguistics.Iddo Lev, Bill MacCartney, Christopher Manning, andRoger Levy.
2004.
Solving logic puzzles: Fromrobust processing to precise semantics.
In Proceed-ings of the Workshop on Text Meaning and Interpre-tation.
Association for Computational Linguistics.Mstislav Maslennikov and Tat-Seng Chua.
2007.
Amulti-resolution framework for information extrac-tion from free text.
In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics.Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-moyer, Liefeng Bo, and Dieter Fox.
2012.
A jointmodel of language and perception for grounded at-tribute learning.
In Proceedings of the InternationalConference on Machine Learning.Maxima.
2014.
Maxima, a computer algebra system.version 5.32.1.280Anirban Mukherjee and Utpal Garain.
2008.
A reviewof methods for automatic understanding of naturallanguage mathematical problems.
Artificial Intelli-gence Review, 29(2).Jorge Nocedal and Stephen Wright.
2006.
Numeri-cal optimization, series in operations research andfinancial engineering.
Springer, New York.Roi Reichart and Regina Barzilay.
2012.
Multi-eventextraction guided by global constraints.
In Proceed-ings of the Conference of the North American Chap-ter of the Association for Computational Linguistics.Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.2012.
Open domain event extraction from twitter.
InProceedings of the Conference on Knowledge Dis-covery and Data Mining.Cynthia Thompson and Raymond Mooney.
2003.Acquiring word-meaning mappings for natural lan-guage interfaces.
Journal of Artificial IntelligenceResearch, 18(1).Adam Vogel and Dan Jurafsky.
2010.
Learning tofollow navigational directions.
In Proceedings ofthe Annual Meeting of the Association for Compu-tational Linguistics.Yuk Wah Wong and Raymond Mooney.
2006.
Learn-ing for semantic parsing with statistical machinetranslation.
In Proceedings of the Annual Meetingof the North American Chapter of the Association ofComputational Linguistics.
Association for Compu-tational Linguistics.John Zelle and Raymond Mooney.
1996.
Learningto parse database queries using inductive logic pro-gramming.
In Proceedings of the Conference on Ar-tificial Intelligence.Luke Zettlemoyer and Michael Collins.
2005.
Learn-ing to map sentences to logical form: Structuredclassification with probabilistic categorial gram-mars.
In Proceedings of the Conference on Uncer-tainty in Artificial Intelligence.Luke Zettlemoyer and Michael Collins.
2009.
Learn-ing context-dependent mappings from sentences tological form.
In Proceedings of the Joint Confer-ence of the Association for Computational Linguis-tics and International Joint Conference on NaturalLanguage Processing.281
