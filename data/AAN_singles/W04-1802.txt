Metalinguistic Information Extraction for TerminologyCarlos Rodr?guez PenagosLanguage Engineering Group, Engineering InstituteUNAM, Ciudad Universitaria A.P.
70-472Coyoac?n 04510  Mexico City, M?xicoCRodriguezP@iingen.unam.mxAbstractThis paper describes and evaluates theMetalinguistic Operation Processor (MOP)system for automatic compilation ofmetalinguistic information from technical andscientific documents.
This system is designedto extract non-standard terminologicalresources that we have called MetalinguisticInformation Databases (or MIDs), in order tohelp update changing glossaries, knowledgebases and ontologies, as well as to reflect themetastable dynamics of special-domainknowledge.1 IntroductionMining terminological information from free orsemi-structured text in large-scale technicalcorpora is slowly becoming a reasonably matureNLP technology, with term extraction systemsleading the way.
Automatically obtaininginformation about terms from free text has been afield less explored, but recent experiences haveshown that compiling the extensive resources thatmodern scientific and technical disciplines need tomanage the explosive growth of their knowledgeis both feasible and practical.
A good example ofthis NLP-based processing need is the NationalLibrary of Medicine?s MedLine abstract database,which incorporates around 40,000 new LifeSciences papers each month.
In order to maintainand update UMLS knowledge resources1 theNLM staff needs to manually review 400,000highly-technical papers each year (Powell et al2002).
Most of these terminological knowledgesources have been compiled from existingglossaries and vocabularies that might become1 The MeSH and SPECIALIST vocabularies, aMetathesaurus, a Semantic Network, etc.dated fairly quickly, and elucidating thisinformation from domain experts is not an option.Neology detection, terminological informationupdate and other tasks can benefit from automaticsearch, in highly technical text, of semantic andpragmatic information, e.g.
when new informationabout sublanguage usage is being put forward.
Inthis paper we describe and evaluate theMetalinguistic Operation Processor (MOP)system, implemented to automatically createMetalinguistic Information Databases (or MIDs)from large collections of special-domain researchand reference documents.
Section 2 discussesprevious work, while Section 3 provides anoverview of metalinguistic exchanges betweenexperts, and their role in the constitution oftechnical knowledge.
Section 4 presentsexperiments to localize and disambiguate goodcandidate metalinguistic sentences, using rule-based and stochastic learning strategies.
Section 5focuses on the problem of identifying andstructuring the different linguistic constituents andsurface segments of metalinguistic predications.Finally, Section 6 offers a discussion of resultsand suggestions for possible applications andfuture lines of research.2 Previous workOne of the constraints of recent lines of research(Pearson, 1998; Klavans et al, 2001; Pascual &Pery-Woodley, 1997) is their focus on definitions,a theoretical object that, although undoubtedlyuseful and extensively described, presents by itsvery nature certain limitations when studyingexpert-domain peer-to-peer communication.2 Themeaning normalization process inherent in2 In some recent approaches, Meyer (2001) andCondamines & Rebeyrolles (2001) exploit widerlexico-conceptual relations in free-text that can bedifficult to model and locate accurately.CompuTerm 2004  -  3rd International Workshop on Computational Terminology 15compiling definitions may be desirable whencreating human-readable reference sources, butmight lead to a loss of valuable information forspecific contexts where the term appears.Pragmatic information (valid usage conditions orcontextual restriction for the terms), or purelyevaluative statements (usefulness or validity of acertain term for its intended purpose), might notbe found in classical definitional contexts.Metalinguistic information in texts can provide uswith information not only about what terms mean,but also how they are actually used by domainexperts.
A wide spectrum of sentential realizationsof these kinds of information has been reported byMeyer (2001) and Rodr?guez (2001), andorganizing it to provide useful terminologicalresources is left for manual review by humanlexicographers.
We believe that using the moregeneral concept of metalanguage can automate asmuch as possible the extraction of fine-grainedknowledge about terms, as well as better capturethe dynamical nature of the evolution of thescientific and technical knowledge createdthrough the interaction of expert-domain groups.3 Metalanguage, terminology and scientificknowledge3.1 Corpora used in our researchPreliminary empirical work to explore howresearchers modify the terminological frameworkof their highly complex conceptual systemsincluded an initial manual review of 19 sociologyarticles (138k words) in academic journals.
Welooked at how term introduction and modificationwas done, as well as how metalinguistic activitywas signalled in text, both by lexical andparalinguistic means.
Some of the indicatorsfound included verbs and verbal phrases likecalled, known as, defined as, termed, coined,dubbed, and descriptors such as term and word.Non-lexical markers included quotation marks,apposition and text layout.3 The metalinguisticpatterns thus identified were expanded (usingvariations of lexemes, verbal tenses and forms)into 116 queries to the scientific and learneddomains of the British National Corpus.
Theresulting 10,937 sentences (henceforth, the MOP3 Similar work by Pearson (1998) obtained many ofthe same patterns from the Nature corpus of exactscience documents.corpus) were manually classified as metalinguisticor otherwise, with 5,407 (49.6% of total) found tobe truly metalinguistic sentences, using thecriteria described in Section 3.2 below.4 Othercorpora from different domains (described inSection 4) was used both in this preliminaryanalysis of metalinguistic exchanges, as well as inevaluation and development of the MOP system.3.2 Explicit Metalinguistic OperationsCareful analysis of these corpora, as well ofexamples in other European languages, presentedsome interesting facts about what we have termed?Explicit Metalinguistic Operations?
(or EMOs):5A) EMOs do not usually follow the genus-differentia scheme of aristotelian definitions, norconform to the rigid and artificial structure oflexicographic entries.
More often than not,specific information about language use and termdefinition is provided by sentences such as (1), inwhich the term trachea is linked to the descriptionfine hollow tubes in the context of a globally non-metalinguistic sentence:(1) This means that they ingest oxygen from theair via fine hollow tubes, known as tracheae.In research papers partial and heterogeneousinformation is much more common than completedefinitions, although it might otherwise intextbooks geared towards learning a discipline.B) Introduction of metalinguistic information indiscourse is highly regular, regardless of thedomain.
This can be credited to the fact that thewriter needs to mark these sentences for specialprocessing by the reader, as they dissect acrosstwo different semiotic levels: a meta-language andits object language, to use the terminology oflogic where these concepts originated.6 Their4 Reliability of human subjects for this task has notbeen reported in the literature, and was not evaluated inour experiments.5 We have used the term to highlight the operationalnature of such textual instances in technical discourse.6 Natural language has to be split (at leastmethodologically) into two distinct systems that sharethe same rules and elements: a metalanguage used torefer to an object language, which in turn can refer toand describe objects in the mind or in the physicalworld.
The fact that the two are isomorphic accountsfor reflexivity, the property of referring to itself, aswhen linguistic items are mentioned instead of beingused normally in an utterance.
Rey-Debove (1978)CompuTerm 2004  -  3rd International Workshop on Computational Terminology16constitutive markedness means that most of thetimes these sentences will have at least twoindicators of metalinguistic nature.
These formaland cognitive properties of EMOs facilitate thetask of locating them accurately in text.C) EMOs can be further analyzed into 3 distinctcomponents, each with its own properties andlinguistic realizations:i) An autonym (see note 6): One or more self-referential lexical items that are the logical orgrammatical subject of a predication.ii) An informational segment: a contributionof relevant information about the meaning,status, coding or interpretation of a linguisticunit.
Informational segments constitute whatwe state about the autonymical element.iii) Markers/Operators: Elements used tomake prominent the whole discourse operationand its non-referential, metalinguistic nature.They are usually lexical, paralinguistic orpragmatic devices that articulate autonyms andinformational segments into a predication.In a sentence such as (2) we have marked theautonym with italics, the informational segmentwith bold type and the marker-operator items withsquare brackets:(2) The bit sequences representing quanta ofknowledge [ will be called ? ]
Kenes [ ?
],  aneologism intentionally similar to 'genes' .3.3 Knowledge and knowledge of languageWhenever scientists advance the state of the artof a discipline, their language has to evolve andchange, and this build-up is carried out undermetalinguistic control.
Previous knowledge istransformed into new scientific common groundand ontological commitments are introducedwhen semantic reference is established.
That iswhy when we want to structure and acquire newknowledge we have to go through a resource-costly cognitive process that integrates withincoherent conceptual structures and theories aconsiderable amount of new and very complexlexical items and terms.
Technical terms are not,by definition, part of the far larger linguisticcompetence of a first native language.
Unlikeeveryday words within a specific social group,follows Carnap in calling this condition autonymy.terms are conventional, even if they have derivedfrom a word that originally belonged to collectivecompetence.
We could even posit that alltechnical terms owe their existence to a baptismalspeech act, and that given a big enough sample(an impossibly exhaustive corpus of all expertlanguage exchanges), an initial metalinguisticsentence could be located that constitutes anoriginal, foundational source of meaning.The information provided by metalinguisticexchanges is not usually inferable from previousone available to the speaker?s community, anddoes not depend on general language competenceby itself, but nevertheless is judged important andrelevant enough to warrant the additionalprocessing effort involved.
Computing what isrelevant metalinguistic information has to be donedynamically by figuring out which terminologicalitems can be assumed to be shared by all, andwhich are new or have to be modified.
It?s anextended and more complex instance of lexicalalignment between interlocutors (Pickering &Garrod, in press).
Observing closely how thisalignment is achieved can allow us to createcomputer applications that mimic some aspects ofour impressive human competence as efficientreaders of technical subjects, as incredibly goodlexical-data processors that constantly update andconstruct our own special purpose vocabularies.4 Filtering out non-metalinguistic sentences:two NLP approachesThe first issue to tackle when miningmetalanguage is how to obtain a reliable set ofcandidate sentences for input into the nextextraction phases.
We employ a ?discourse-oriented?
approach that differs from Meyer?s(2001) ?term-oriented?
one.
We do not assume wehave initially identified a terminological unit andproceed from there, but rather we first locate ametalinguistic discourse operation where a termcan be retrieved along with information that refersto it.
Condamines & Rebeyrolles (2001) andMeyer (2001) both exploit patterns of?knowledge-rich contexts?
to obtain semantic andconceptual information about terms, either toinform terminological definitions or providestructure for a terminological system.
A keyproblem in such approaches that use lexical-based?triggers?
is how to control the amount of ?noise?,or non-relevant instances.
The experiments in thisCompuTerm 2004  -  3rd International Workshop on Computational Terminology 17section compare two different NLP techniques forthis task: symbolic and statistic techniques.From our initial analysis of various corpora weselected 44 patterns that showed the beststatistical reliability as EMO indicators.7 Westarted out by tokenizing text, which then was runthrough a cascade of finite-state devices thatextracted a set of candidate sentences beforefiltering out non-metalinguistic instances.
Ourfiltering distinguishes between useful results, e.g.using the lexical pattern called in (3) from non-metalinguistic instances in (4):(3) Since the shame that was elicited by thecoding procedure was seldom explicitlymentioned by the patient or the therapist, Lewiscalled it unacknowledged shame.
(4) It was Lewis (1971;1976) who called attentionto emotional elements in what until then hadbeen construed as a perceptual phenomenon .We experimented with two strategies fordisambiguation: first, we used collocations asadded restrictions (e.g., verbal vs. nominaloccurrences of our lexical markers) to discardnon-metalinguistic instances, for exampleattention in sentence (4) next to the marker called.The next table shows a sample of the filteringcollocations.Preceding Subsequentfor callsin, duty, personal, conference,local, next, the, their, house,anonymous, phone, telephone...out, someone, charges, before,charge, back, contact, for,upon, to, into, off, 911, by...for coinpound, small, pence, in, toss,the, this, a, that, one, gold,silver, metal, esophageal ...tossWe also implemented learning algorithmstrained on a subset from our EMO corpus, usingas vectors either Part-of Speech tags or wordstrings, at one, two, and three positions adjacentbefore and after our lexical markers.
Ourevaluations are based on 3 document sets: a) ouroriginal exploratory sociology corpus [5,581sentences, 243 EMOs]; b) an online histologytextbook [5,146 sentences, 69 EMOs]; and c) asmall sample from the MedLine abstract database[1,403 sentences, 10 EMOs].
Our system is coded7 We excluded dispositional and typographical cluesfrom our selectional patterns, involving mainly lexicaand punctuation.in Python, using the NLTK platform (nltk.sf.net)and a Brill tagger by Hugo Liu at MIT.4.1 The collocation-based approachOur first approach fared well, with goodprecision numbers but not so encouraging recall.The sociology corpus gave 0.94 Precision (P) and0.68 Recall (R), while the histology one presented0.9 P and 0.5 R. These low recall numbers reflectthe fact that we used a non-exhaustive list ofmetalinguistic patterns.
Example (5) shows onekind of metalinguistic sentence attested in corporathat the system does not extract or process:(5) ?Intercursive?
power, on the other hand, ispower in Weber's sense of constraint by an actoror group of actors over others.We also tested extraction against a goldenstandard where sentences that had patterns thatour list was not designed to retrieve wereremoved, which gave a more realistic picture ofhow the extraction system worked for the actualdataset it was designed to consider.
For thesociology corpus (and a ?
factor of 1), P was 0.97and R 0.79, with an F-measure of 0.87.
In thehistology one P was measured at 0.94, R at 0.81and F-measure at 0.87.
In order to better comparethe two filtering strategies, we decided also tozoom in on a more limited subset of verb forms(namely, calls, called, call), which presentedratios of metalinguistic relevance in our MOPcorpus ranging from 100% positives (for thepattern so called + quotation marks) to 31% (call).Restricted to these verbs, our metrics showedprecision and recall rates around 0.97.
Oneproblem with this approach is that the hand-codedrules are domain-specific, and customization forother domains is labour-intensive.
In our tests,although most of the collocations work language-wide (phrasal verbs or prepositions), some ofthem are very specific.8 Although collocation-based filtering will result in a working system,customization is error-prone and laborious.4.2 Testing learning algorithmsWe selected the co-text of marker/operators asrelevant features for classifiers based on well-known naive Bayes and Maximum Entropyalgorithms that have been reported to work well8 ?esophageal coins?
is quite unusual outside ofmedical documents.CompuTerm 2004  -  3rd International Workshop on Computational Terminology18with sparse data.9  We used either as grammaticalcontext the POS tags or the word formsimmediately adjacent in one to three positionsbefore and after our triggering markers.
Testingall possible combinations evaluates empiricallythe ideal mix of algorithm, feature type andcoverage that insures best accuracy.
The naiveBayes algorithm estimates the conditionalprobability of a set of features given a label, usingthe product of the probabilities of the individualfeatures given that label.
It assumes that thefeature distributions are independent, but it hasbeen shown to work well in cases with highdegree of feature dependencies.
The MaximumEntropy model establishes a probabilitydistribution favouring entropy or uniformitysubject to the constraints encoded in the feature-known label correlation.
To train our classifiers,Generalized and Improved Iterative Scalingalgorithms were used to estimate the optimalmaximum entropy of a feature set, given acorpus.10 1,371 training sentences from our MOPdataset were converted into YES-NO labelledvectors.
The following example from the textualsegment ?...
creates what Croft calls a descriptionconstraint ...?, uses 3 positions and POS tags:('VB WP NNP', 'calls', 'DT NN NN')/'YES'@[102].The different number of positions to the left andright of our training sentences, as well as thenature of the features selected (there are manymore word-types than POS tags) ensured that our3-part vector introduced a wide range of featuresagainst our 2 possible labels.
The best results ofeach algorithms restricted to the lexeme call, arepresented in the next table.
Figures 1 and 2present best results in the learning experiments forthe complete set of patterns used in the collocationapproach, over two of our evaluation corpora.11Type Positions Tags/Words Features Accuracy Precision RecallGIS 1 W 1254 0.97 0.96 0.98IIS 1 T 136 0.95 0.96 0.94NB 1 T 136 0.88 0.97 0.849 see Rish, 2001, Ratnaparkhi, 1997 and Berger et al1996 for a formal description of these algorithms.10 In other words, given known data statistics,construct a model that best represents them but isotherwise as uniform as possible.11 Legend: P: Precision; R: Recall; F:  F-Measure.
NB: na?veBayes; IIS: Maximum Entropy with Improved Iterative Scaling; GIS:Maximum Entropy with Generalized Iterative Scaling.
(Positions/Feature type)Figure 1.
Best metrics for Sociology corpus0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95PRFNB (3/T)IIS (1/W)GIS (1/W)Figure 2.
Best metrics for Histology corpus0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95PRFNB (3/W)IIS (3/W)GIS (1/W)Although our tests using collocations showedthat structural regularities would perform well,our intuitions about improvement using morefeatures (more positions to the right or left of thelexical markers) or a more grammaticallyrestricted environment (surrounding POS tags),turned out to be overly optimistic.
Nevertheless,stochastic approaches that used short-rangefeatures did perform in line with the hand-codedapproach.
Both Knowledge-Engineering andsupervised learning approaches were adequate forinitial filtering of metalinguistic sentences,although learning algorithms might allow easiertransport of systems into new domains.5 From EMOs to metalinguistic databasesAfter EMOs were obtained, POS tagging,shallow parsing and limited PP-attachment areperformed.
Resulting chunks were tagged asAutonyms, Agents, Markers, Anaphoric elementsor Noun Chunks, using heuristics based onsyntactic, pragmatic and argument structure oflexica in the extraction patterns, as well as onFrameNet data in Name conferral and NameCompuTerm 2004  -  3rd International Workshop on Computational Terminology 19bearing frames.
Next, a predicate processingphase selected the most likely surface realizationfor informational segments, autonyms andmakers-operators, and proceeded to fill out thetemplates of the database.
As mentioned earlier,informational segments present many realizationsfar from the completeness and conciseness oflexicographic entries.
In fact, they may show upas full-fledged clauses (6), as inter- or intra-sentential anaphoric elements (7 and 8), as sortalinformation (9), or as an unexpressed ?existentialvariable?
(logical form $x) indicating only thatcertain discourse entity is being introduced (10):(6) In 1965 the term soliton was coined todescribe waves with this remarkablebehaviour.
(7) This leap brings cultural citizenship in linewith what has been called the politics ofcitizenship .
(8) They are called ?endothermic compounds.?
(9) One of the most enduring aspects of all socialtheories are those conceptual entities known asstructures or groups.
(10) A [$x] so called cell-type-specific TF can beused by closely related cells?.We have not included an anaphora-resolutionmodule in our system, so that examples 7, 8 and10 only output either unresolved surface elementsor variable placeholders.12 Nevertheless, morecommon occurrences like example sentence (1)12 For sentence (8) the system might retrieve usefulinformation from a previous one: ?A few have positiveenthalpies of formation.
?are enough to create MIDs that constitute usefulresources for lexicographers.
The correct databaseentry for (1) is presented below.Reference Histology sample # 6Autonym tracheaeInformation fine hollow tubesMarkers/Operators  known asTo better reflect overall performance, weintroduced a threshold of similarity of 65% forcomparison between a golden standard slot entryand the one obtained by the application.13 Thefinal processing stage presented metrics shown inFigure 4.
Our best numbers for informationalsegments ranged around 0.85, while the lowestwere obtained for the histology corpus, withglobal precision and recall rates around 0.71, butwith high numbers in the autonym identificationtask (0.91) and midrange ones for theinformational segments (0.8).
We observed thateven though it is assumed that Bio-MedicalSciences have more consolidated vocabulariesthan Social Sciences, results for the MedLine andhistology corpus occupy the extremes in thespectrum, with the sociology one in the middlerange.
The total number of candidate sentenceswas not a good predictor of system performance.The DEFINDER system (Klavans et al, 2001)is to my knowledge the only one fully comparablewith MOP, both in scope and goals, but with somesignificant differences.14 Taking into account13 Thus, if the autonym or the informational segmentis at least 2/3 of the correct response, it is counted as apositive, allowing for expected errors in the PP oracronym attachment algorithms.14 DEFINDER examines user-oriented documentsFigure 4.
Metrics for 3 corpora(# of Records/Global F-Measure)0.60.70.80.91Precision Recall Precision Recall Precision RecallGlobal Informational Segments AutonymsHistology (35/0.71) Sociology (143/0.77) MedLine (10/0.78)CompuTerm 2004  -  3rd International Workshop on Computational Terminology20those differences, MOP compares well with the0.8 precision and 0.75 recall of DEFINDER.While the resulting MOP ?definitions?
generallydo not present high readability or completeness,these informational segments are not meant to beread by laymen, but used by domainlexicographers updating existing glossaries forneological change, or, in machine-readable form,by other applications.6 Discussion and future workWe have chosen to exploit metalinguisticinformation that is being put forward in textbecause it can?t be assumed to be part of thecollective expert-domain competence.
In doing so,we have exposed our system to the lesspredictable lexical environment of leading-edgeresearch literature, the cauldron where knowledgeand terminological systems are forged in realtime, and where scientific meaning andinterpretation are constantly debated, modifiedand agreed upon.
We believe that low recall ratesin our tests are in part due to the fact that we aredealing with the wider realm of metalinguisticinformation, as opposed to structured definitionalsentences that have been distilled by an expert forconsumer-oriented documents.
We have notperformed major customization of the system (likeenriching the tagging lexicon with medical terms),in order to preserve the ability to use the systemacross different domains.
Domain customizationmay improve metrics, but at a real cost forportability.Conventional resources like lexicons anddictionaries compile meaning definitions that areconsidered stable and widely-shared.
They can beseen as repositories of the default, core lexicalinformation for terms used by a researchcommunity (that is, the information available toan average, idealized speaker).
An MID, on theother hand, might contain the multi-textured real-time data embedded in research papers, and in thissense could be conceptualized as an anti-with fully-developed definitions for the layman.
MOPfocuses on leading-edge research papers that presentless predictable templates.
DEFINDER?s qualitativeevaluation criteria includes readability, usefulness andcompleteness, as judged by lay subjects, criteria whichwe have not adopted here, nor have we determinedcoverage against existing on-line dictionaries.dictionary: a listing of exceptions, specialcontexts and specific usage of instances wheremeaning, value or pragmatic conditions have beenspotlighted by discourse for cognitive reasons.Applications that rely on lookup on previouslycompiled resources would miss some of the datafrom EMOs, where the term is put forward for thefirst time, or where important, context-sensitiveinformation about the terms is provided.
MIDscannot be viewed as end-user products, but assemi-structured resources (midway between rawcorpora and structured lexical bases) that have tobe further processed to convert them into usabledata sources.
We might better characterize themas auxiliary lexical knowledge resources, morethan core lexical references.
Lexicographers andterminologist can use them as tools for their ownlabour-intensive work of reviewing and compilingspecial-domain vocabularies.MIDs could, in principle, also supply newinterpretation rules in AI applications wheninferences won?t succeed because the state of thelexico-conceptual system has changed.15 A neo-logism or a word in an unexpected technical sensecould stump a NLP system that assumes it will beable to use the default information from amachine-readable dictionary or TKB.
The kind ofsortal information implicit in many definitions canalso help improve anaphora resolution, semantictyping, acronym identification or bootstrapping ofontologies and taxonomies (Hearst, 1992;Condamines & Rebeyrolle, 2001; Pustejovsky etal., 2002; Malais?
et al 2004).
Although ourapproach might miss some of the importantconceptual relations between terms, many of theMIDs we have obtained using language-centredcontexts are rich sources of information.
Inaddition, terminological information can be morespecific than that obtainable by glossary lookup,and might be better suited for the interpretation ofcertain texts.
The locality of such information canbe seen as advantageous for specializedlexicography.
Another area where non-standardinformation could prove useful is the study of theevolution of scientific sublanguages and theknowledge embodied by them.
Changes in the15 When interpreting text, regular lexical informationis applied by default under normal conditions, but morespecific pragmatic or discursive information canoverride it if necessary, or if context demands so(Lascarides & Copestake, 1995).CompuTerm 2004  -  3rd International Workshop on Computational Terminology 21conceptual and terminological configuration of adiscipline might be traced and be betterunderstood by the dynamical updates reflected inthese databases.
The next table shows a smallsample, taken from our corpora, of thatinformation?s potential range, for some keyconcepts in the sociology domain.Terms Informational segments from EMOsFamily extend the meaning to include same-sex couples,single-parents, nannies, adoptive and step children,and so onFamily two adults of opposite sex, married to each other,and living with their common childrenIdentity There are two typical contextsIdentity an emotional attachment and a sense of belongingof a semi-sacred kindNationalism used here, deliberately, to describe both aspects ofthe phenomenonNationalism is used for both of these things - world view andactivism6.1 ConclusionsThe implementation we have described hereundoubtedly shows room for improvement:adding more patterns for better overall recall rates,deeper parsing for more accurate semantic typingof sentence arguments, etc.
Also, the question ofwhich learning algorithms can better perform theinitial filtering of EMO candidates is still verymuch an open issue.
We believe that the realchallenge facing work such as this one lies not inretrieving EMOs from text to populate a MID, butin the successful formalization of heterogeneouslinguistic information into a robust andmanageable data structure.
An effective andefficient computational representation of suchdiverse information is not trivial.Nevertheless, we believe that applicationsfocused on metalanguage, like the MOP systemdescribed here, can be very helpful forTerminology and lexicography, and that a MID?srole would not be to replace, but to enrich andcomplement, Terminological Knowledge Bases.ReferencesBerger, A., S. Della Pietra et al 1996.
A Max-imum Entropy Approach to Natural LanguageProcessing.
Computational Linguistics, v. 22, 1.Condamines, A.
& Rebeyrolle, J.
2001.
Searchingfor and identifying conceptual relationships viaa corpus-based approach to a TerminologicalKnowledge Base (CTKB).
Recent Advances inComputational Terminology.
John Benjamins.Hearst, M. 1992.
Automatic Acquisition ofHyponyms from Large Text Corpora.
Proc.
14thInt.
Conference on Computational Linguistics,Nantes, France.Klavans, J. and Muresan, S. 2001.
Evaluation ofthe DEFINDER System for Fully AutomaticGlossary Construction, Proc.
Am.
Med.
Inf.Ass.
Symp.Lascarides, A. and Copestake A.
1995.
ThePragmatics of Word Meaning, in Representationand Acquisition of Lexical Knowledge: Poly-semy, Ambiguity and Generativity.
Stanford.Malais?
V., Zweigenbaum P. & Bachimont, B.2004.
Rep?rage et exploitation d?
?nonc?sd?finitoires en corpus pour l?aide ?
laconstruction d?ontologie.
TALN 2004, F?s.Meyer, I.
2001.
Extracting knowledge-rich cont-exts for terminography.
Recent Advances inComputational Terminology.Pascual, E. & P?ry-Woodley, M-P 1997.
Mod?lesde texte pour la d?finition.
Actes de Journ?esScientifiques et Techniques du R?seauFrancophone de l?Ing?nierie de la Langue,Pearson, J.
1998.
Terms in Context.
JohnBenjaminsPickering, M. and Garrod, S. (in press) Toward amechanistic psychology of dialogue.
Behavioraland Brain Sciences.
Cambridge UniversityPress.Powell, T., Srinivasan, S., et al (2002) TrackingMeaning Over Time in the UMLSMetathesaurus.
In Biomedical Informatics: OneDiscipline.
Proc.
Am.
Med.
Inf.
Ass.
Symp.Pustejovsky J., A. Rumshisky and J. Casta?o.2002.
Rerendering Semantic Ontologies: Auto-matic Extensions to UMLS through CorpusAnalytics.
LREC 2002, Spain.Ratnaparkhi A., 1997.
A Simple Introduction toMaximum Entropy Models for NaturalLanguage Processing, TR 97-08, IRCS,University of PennsylvaniaRish, I., 2001.
An empirical study of the naiveBayes classifier, in IJCAI-01.Rey-Debove, J.
1978.
Le M?talangage.
Le Robert,Paris.Rodr?guez, C. 2001.
Parsing MetalinguisticKnowledge from Texts.
Selected papers fromCICLING-2000 (IPN), Mexico.CompuTerm 2004  -  3rd International Workshop on Computational Terminology22
