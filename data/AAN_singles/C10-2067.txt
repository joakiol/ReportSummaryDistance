Coling 2010: Poster Volume, pages 588?596,Beijing, August 2010DL Meet FL: A Bidirectional Mapping between Ontologies andLinguistic Knowledge?Hans-Ulrich Krieger and Ulrich Scha?ferLanguage Technology LabGerman Research Center for Artificial Intelligence (DFKI){krieger|ulrich.schaefer}@dfki.deAbstractWe present a transformation scheme that me-diates between description logics (DL) orRDF-encoded ontologies and type hierar-chies in feature logics (FL).
The DL-to-FLdirection is illustrated by an implementedoffline procedure that maps ontologies withlarge, dynamically maintained instance datato named entity (NE) and information ex-traction (IE) resources encoded in typed fea-ture structures.
The FL-to-DL translation isexemplified by a (currently manual) trans-lation of so-called MRS (Minimal Recur-sion Semantics) representations into OWLinstances that are based on OWL classes,generated from the the type hierarchy of adeep linguistic grammar.
The paper willidentify parts of knowledge which can betranslated from one formalism into the otherwithout loosing information and parts whichcan only be approximated.
The work de-scribed here is important for the Seman-tic Web to become a reality, since semanticannotations of natural language documents(DL) can be automatically generated by shal-low and deep natural language parsing sys-tems (FL).1 Introduction and motivationOntologies on the one hand and resources for natu-ral language processing (lingware) on the other hand,though closely related, are often maintained indepen-dently, thus constituting a duplication of work.In the first part of this paper, we describe an im-plemented offline procedure that can be used to mapconcepts and instance information from ontologies tolingware resources for named entity recognition andinformation extraction systems.
The approach (i) im-proves NE/IE precision and recall in closed domains,?The work described in this paper has been carried outin the TAKE project (Technologies for Advanced Knowl-edge Extraction), funded by the German Federal Min-istry of Education and Research under contract number01IW08003.
(ii) exploits linguistic knowledge for identifying on-tology instances in texts more robustly, (iii) gives fullaccess to ontology instances and concepts in natu-ral language processing results, and (iv) avoids du-plication of work in development and maintenance ofontologies and lingware.
The advantages of this ap-proach for Semantic Web and natural language (NL)processing-based applications come from a cross-fertilization effect.
While ontology instance data canimprove precision and recall of, e.g., named entityrecognition (NER) and information extraction (IE)in closed domains, linguistic knowledge contained inNER and IE components can help to recognize ontol-ogy instances (or concepts) occurring in text, e.g., bytaking into account inflection, anaphora, and context.Furthermore, (Haghighi and Klein, 2009) and othershave shown that incorporating finer-grained seman-tic information on entities occurring in text (e.g., forantecedent filtering) helps to improve performance ofcoreference resolution systems.If both resources would be managed jointly at asingle place (in the ontology), they could be eas-ily kept up-to-date and in sync, and their mainte-nance would be less time-consuming.
When ontol-ogy concepts and instances are recognized in text,their name or ID can be used by applications tosupport subsequent queries, navigation, or inferencein the ontology using an ontology query language(e.g., SPARQL).
The procedure we describe here,preserves hierarchical concept information and linksto ontology concepts and instances.
Applications are,e.g., hybrid deep-shallow question answering (Franket al, 2007), automatic typed hyperlinking (Buse-mann et al, 2003) of instances and concepts occur-ring in documents, or other innovative applicationsthat combine Semantic Web and NL processing tech-nologies, e.g., for semantic search (Scha?fer et al,2008).The second part of this paper outlines the inversetransformation from feature logics (FL) into descrip-tion logics (DL).
Walking along this direction hasthe big advantage of potentially applying subsequentdescription logic reasoners to the lexical semanticsof natural language input text in order to infer newknowledge, e.g., in interactive natural language ques-588tion answering.
As an example, we will carefully de-velop the (approximate) translation of so-called ro-bust minimal recursion semantic (RMRS) structures(Copestake, 2003) into OWL descriptions (McGuin-ness and van Harmelen, 2004).
RMRS structuresare the semantic output of various NL processingengines, encoded in typed feature structures (TFS).Since NL processors (e.g., taggers, chunkers, deepparsers) only build up structure, subsequent process-ing steps are either not realized or implemented in adhoc way,?
dealing with merging & normalization ofRMRS,?
infering new knowledge (e.g., w.r.t.
the forego-ing dialog),?
taking into account extralinguistic knowledgefor reasoning.Now, by moving from a specialized ?designer lan-guage?
(RMRS) to OWL, we can take advantage ofyears of solid theoretical and practical work in logic,especially in description logics.
Since OWL is aninstance of the description logics family and the de-facto language for the Semantic Web, we can utilizethe built-in reasoning capabilities of OWL and (rule-based) description logic reasoners.The structure of this paper is as follows.
In thenext section, we outline the relationship between de-scription logics and feature logics, trying to makeclear what they have in common, but at the sametime explaining their differences.
Section 3 describesthe syntactic mapping process from the ontologyto feature structure descriptions.
In Section 4, wepresent an example where recognized named entitiesenriched with ontology information are used in hy-brid NL processing and subsequent applications.
Af-ter that, Section 5 explains the mapping of RMRSstructures into OWL descriptions.
Finally, Section 6shows that a subsequent description logic reasonercan utilize these descriptions to infer new knowledge.2 The relationship between descriptionand feature logicsDescription logics (DL) (Baader et al, 2003) and fea-ture logics (FL) (Carpenter, 1992) have been pursuedindependently for quite a while.
Their close relation-ship was recognized by (Nebel and Smolka, 1990).Instances of both families of knowledge representa-tion formalisms are usually decidable two-variablefragments of first-order predicate logic.
Even thoughDL dialects usually have an intractable worst-casecomplexity, average-case reasoning is usually fast,due to the availability of highly-optimized tableauxreasoners.
When adding seemingly easy constructssuch as ?role-value maps?
(the analog to reentran-cies), the underlying logical calculus becomes unde-cidable.From an abstract viewpoint, both DL and FL em-ploy unary and binary predicates for which the twocommunities invented different names (we only listsome of them):arity description logic feature logicunary concept, class type, categorybinary role, property feature, attributeThough these names are different, both represen-tation families (usually) vary in further, not so subtledetails:description logic feature logicopen world assumption closed world assumptionfull Boolean concept logic only conjunctionsrelational properties functional propertiesrole-value maps forbidden reentrancies allowedLet us be more verbose here to see the descrip-tional consequences of both approaches in terms ofa mutual translation.
We note here that we takeOWL (McGuinness and van Harmelen, 2004) as aninstance of DL and TDL (type description language)(Krieger and Scha?fer, 1994) as an example of FL.OWL, the outcome of the DAML+OIL standard-ization, is regarded to be the de-facto language forthe Semantic Web.
OWL still makes use of con-structs from RDF and RDFS, but restricts the ex-pressive power of RDFS, thereby ensuring decidabil-ity of the standard inference problems.
Compared toRDF(S), OWL provides more fine-grained modellingconstructs, such as intersectionOf or unionOf.Within the Head-Driven Phrase Structure Gram-mar (HPSG) (Pollard and Sag, 1994) paradigm inmodern computational linguistics (CL), TDL is alanguage that has been employed in various imple-mented systems, such as PAGE, LKB, PET, orSProUT .Before going into the details of our approximatetransformation schema, let us quickly explain howto atomize a typed feature structure (TFS) in termsof description logic primitives, using OWL.
Considerthe following TFS which is a gross simplification ofthe Head-Feature Principle in HPSG.
In terms ofthe ?one-dimensional?
line-based TDL notation, wewritephrase1 := phrase &[HEAD #h1, HEAD-DTR|HEAD #h1],or as a two-dimensional AVM (attribute-value ma-trix) notation, we have589phrase1 ?
[ phraseHEAD h1HEAD-DTR|HEAD h1]Assuming that this is an individual of class phrase,we can obtain a meaning-preserving OWL represen-tation (we assume that HEAD and HEAD-DTR arefunctional OWL object properties):<owl:Thing rdf:ID="h1"/><rdf:Description rdf:about="hdtr1"><rdf:type rdf:resource="owl:Thing"/><HEAD rdf:resource="h1"/></rdf:Description><rdf:Description rdf:about="phr1"><rdf:type rdf:resource="phrase"/><HEAD rdf:resource="h1"/><HEAD-DTR rdf:resource="hdtr1"/></rdf:Description>Note that only the top-level structure is explic-itly typed (phrase); every other substructure thusis assigned the most general type, which trans-lates into the OWL class owl:Thing.
Note alsothe sharing of information under paths HEAD andHEAD-DTR|HEAD?this is realized by refering to thethe name h1 in the above RDF/OWL description forphr1 and hdtr1.Given a set of OWL descriptions, obtaining the in-verse direction from DL to FL should now be clear.
Itis important here to group statements that are relatedto a specific class, viz., inheritance information (e.g.,intersectionOf) together with property informa-tion about roles that are ?introduced?
on a given class(as given by the value of rdfs:domain ).
In Sec-tion 3, we focus on this inverse direction (DL-to-FL),whereas Section 5 exemplifies the FL-to-DL direc-tion.Let us finally elaborate fundamental differencesbetween the DL and FL families that can only be ap-proximated in terms of ?less expressive?
constructs.Open vs. closed world assumption.
Typed featurelogics usually ?live?
in a closed world, meaning thatif two types t1 and t2 do not share a common sub-type (having a greatest lower bound), the unifica-tion (conjuntion) is assumed to be the bottom type(OWL: owl:Nothing), meaning that no individualexists which is of both t1 and t2 at the same time.This is totally different to the DL point of view: whatcan not proven to be true (whether the conjunctionof t1 and t2 denotes the empty set) is not believedto be false.
Thus we either have to introduce a newtype t on the FL side, abbreviating the conjunction oft1 and t2 (TDL: t := t1 & t2.
), or to close the sub-class hierarchy on the DL side: ?
?
t1 u t2 (OWL:disjointWith).
This decision clearly depends onthe direction of the transformation.Boolean vs. conjunctive description logic.
Typedfeature logics rarely provide more than conjunc-tions of feature-value constraints.
This is due to thefact that disjunctive descriptions render almost linear(conjunctive) unification exponential.
A full Booleancalculus, such as OWL DL, even has an NEXPTIMEcomplexity.
Thus it is clear that the direction fromDL to FL can only be approximated.
The inverse di-rection is clearly trivial with the notable exception ofreentrancies (see below).To flesh out our point, consider the DL axiomhuman ?
man unionsq woman that fully determines (?
)human in terms of the union of the concepts manand woman.
Given the syntax of TDL, we can ap-proximate parts of the intended meaning of the de-scription by man :< human and woman :< human,since the above DL axiom entails that man v humanand woman v human is the case.
This is ex-actly specified by the above two TDL type defini-tions.
Further, not so trivial approximations can befound in (Flickinger, 2002).
The idea here is thatforeseeable disjunctions of DL concepts can be emu-lated by introducing additional FL types (in the worstcase, exponentially-many new types, however).
Evennegated concepts can be simulated this way, since FLlives in a closed world (see above).Relational vs. functional properties.
By default,roles in DL are relational properties, meaning thatfor a fixed individual in the domain of a given role,the number of individuals in the range needs not tobe 0 or 1.
DL further allows to impose cardinality(or number) restrictions on roles, so that we mightwrite ?
0 livingParents u ?
2 livingParents whichsays that one can have at least 0 and at most 2 liv-ing parents.
This is in sharp contrast to FL whichusually assume functional roles (so-called features),making such roles essentially partial functions.
Apartial workaround has been proposed in CL systemsby using (ordered) difference lists to collect informa-tion.
Other systems, such as SProUT (Krieger et al,2004), come up with bags (or multisets) that even vi-olate the foundational axiom (a set must not containitself) in order to achieve runtime efficiency.Summarizing, the FL-to-DL direction of translat-ing features into roles is easy, since features in FLcan be easily defined as functional roles in DL (OWLeven provides the owl:FunctionalProperty char-acteristics).
The inverse direction is only a gross ap-proximation in that cardinality constraints can not be590stated on the FL side.Role-value maps & reentrancies.
The above Head-Feature Principle example seems to indicate that role-value maps can be easily represented in DL, simplyby using the name of an individual to specify iden-tity.
In fact, this is true, but only for the ABox ofa knowledge base, i.e., only for the set of individu-als (or instances).
However, the notion of role-valuemaps in DL or reentrencies in FL refers to the TBoxand the set of concept definitions, resp.
Thus, onecan not intensionally specify identity of informationfor a potentially infinite number of individuals via aclass axiom in DL, but needs to extensionally spec-ify identity of information for each individual in theABox.3 OntoNERdIE: from OWL to TDLIn this section, we describe an instantiation of the DL-to-FL mapping.
OntoNERdIE is an offline procedurethat maps ontology concept and instance informationto lingware resources (Scha?fer, 2006).
The approachhas been implemented for the language technologyontology that backs up the LT World web portal(http://www.lt-world.org), but can be easily adaptedto other domains and ontologies, since it is fully au-tomated, except for the choice of relevant main con-cepts and properties that are going to be mappedwhich is a matter of configuration.The target named entity recognition and infor-mation extraction tool we employ here is SProUT(Droz?dz?yn?ski et al, 2004), a shallow multilingual,multi-purpose NL processor.
The advantage ofSProUT in the described approach for named en-tity recognition and information extraction is thatit comes with (1) a type system and typed featurestructures as the basic data type, (2) a powerful,declarative rule mechanism with regular expressionsover typed feature structures, and (3) a highly effi-cient gazetteer module with fine-grained, customiz-able classification of recognized entities.SProUT provides additional modules such as mor-phology or a reference resolver that can be exploitedin the rule system, e.g., to use context or morpholog-ical variation for improved NER.
Through automat-ically generated mappings, SProUT output enrichedwith ontology information can be used for robust, hy-brid deep-shallow parsing, and semantic analysis.In this section, we describe the offline process-ing steps of the OntoNERdIE approach.
The on-line part in applications is described in Section 4.The approach heavily relies on XSLT transformations(Clark, 1999) of the XML representation formats,both in the offline mapping and in the online appli-cation.3.1 RDF preprocessingInput to the mapping procedure is an OWL on-tology file, containing both concept and instancedescriptions.
The RDF file is pre-processed witha generic XSLT stylesheet sorting and mergingrdf:Descriptions that are distributed over the filebut which belong together.
We use XSLT?s key andgenerate-id functions.
Depending on the appli-cation, the next two processing stages take a list ofconcepts as filter because it will typically not be de-sirable to extract all concepts or instances availablein the ontology.
In both cases, resource files are gen-erated as output that can be used to extend existingnamed entity recognition resources.
E.g., while gen-eral rules can recognize domain-independent namedentities (e.g., any person name), the extended re-source contains specific, and potentially more de-tailed information for domain-specific entities.3.2 Extracting inheritanceThe second stylesheet converts RDFS subClassOfstatements from output step 1 (Section 3.1) into aset of TDL type definitions that can be immediatelyimported by the SProUT named entity recognitiongrammar.
Currently 1,260 type definitions for thesame number of subClassOf statements in the LTWorld ontology are generated, e.g.,NL_Parsing := Written_Language &Language_Analysis.This is of course a lossy conversion because notall relations supported in an OWL ontology (such asunionOf, disjointWith, intersectionOf) aremapped.
However, we think that for NE classifi-cations, the subClassOf taxonomy mappings willbe sufficient.
Other relations could be formulatedas direct (though slower) ontology queries using theOBJID mechanism described in the next step.
Ifthe target of OntoNERdIE is a NER system differ-ent from SProUT and without a type hierarchy, thisstep can be omitted.
The subClassOf informationcan always be gained by querying the ontology ap-propriately on the basis of the concept name.3.3 Generating gazetteer entriesThe next stylesheet selects statements about instancesof relevant concepts via the rdf:type informationand converts them to structured gazetteer source filesfor the SProUT gazetteer compiler (or into a differ-ent format in case of another NER system).
In thefollowing example, one of the approximately 20,000converted entries for LT World is shown.591Bernd Kiefer | GTYPE: lt_person |SNAME: "Kiefer" | GNAME: "Bernd" |CONCEPT: Active_Person |OBJID: "obj_62893"The attribute CONCEPT contains a TDL type gener-ated in step 2 (described in Section 3.2).
For con-venience, several ontology concepts are mapped (de-fined manually as part of the configuration of thestylesheet) to only a few named entity classes (underattribute GTYPE).
For the LT World ontology, theseclasses are person, organization, event, project, prod-uct, and technology.
The advantage of this simplifica-tion is that NER context rules from existing SProUTnamed entity grammars can be re-used for improvedrobustness and disambiguation.The rules, e.g., recognize name variants with titlelike Prof. Kiefer, Dr. Kiefer, or Mr. Kiefer with orwithout a first name.
Moreover, context (e.g., prepo-sitions with location names, verbs), morphology andreference resolution information can be exploited inthese rules.The following SProUT rule lt-event (extendedTDL syntax) simply copies the slots of a matchedgazetteer entry for events (e.g., a conference) to theoutput as a recognized named entity.lt-event :> gazetteer &[GTYPE lt_event, SURFACE #name,CONCEPT #concept, OBJID #objid,GABBID #abbrev]->ne-event & [EVENTNAME #name,CONCEPT #concept, OBJID #objid,GABBID #abbrev].OBJID contains the object identifier of the instancein the ontology.
It can be used as a link back to thefull knowledge stored in the ontology, e.g., for sub-sequent queries, like Who else participated in project[with OBJID obj 4789]?.In case multiple instances with same names but dif-ferent object IDs occur in the ontology (which actu-ally happens to be the case in LT World), multiple al-ternatives are generated as output which is probablythe expected and desired behavior (e.g., for frequentnames such as John Smith).
On the other hand, ifproduct or event names with an abbreviated variantexist in the ontology, they both point to the same ob-ject ID (provided they are stored appropriately in theontology).4 Application to hybrid deep-shallowparsingWe now describe and exemplify how the named en-tities enriched with ontology information are em-ployed in a robust, hybrid deep-shallow architec-ture, combining domain-specific shallow named en-tity recognition with deep, broad-coverage, domain-independent, unification-based parsing for generatinga semantic representation of the meaning of parsedsentences.
An application of this scenario is deepquestion analysis for question answering of struc-tured knowledge sources, encoded as an OWL ontol-ogy (Frank et al, 2007).The output of SProUT for a recognized named en-tity is a typed feature structure in XML containingthe instantiated RHS of the recognition rule as shownin step 3 (Section 3.3) with the copied structuredgazetteer data, plus some additional information likecharacter span, named entity type, etc.
The mappingof recognized named entities to generic lexicon en-tries of the deep grammar, in this case the English Re-source Grammar (Flickinger, 2002), for hybrid pro-cessing are performed through an XSLT stylesheet,automatically generated from the SProUT type hi-erarchy.
Analogous mappings are supported forother grammars available in the DELPH-IN reposi-tory (see http://www.delph-in.net).
The mapping ba-sically transports the surface string, a character span,and a generic lexicon type of the deep grammar for achart item to be generated in an XML format, read-able by the deep parser.
A sample output of the se-mantic representation generated by the deep parser isshown in Figure 1.
The semantic representation for-mat, called RMRS, is described in (Copestake, 2003)and in Section 5.3 below.In addition to the basic named entity type mappingfor default lexicon entries, the recognized conceptsare also useful for constraining the semantic sort inthe deep grammar in a more fine-grained way (e.g.,for disambiguation).
The deep parser?s XML inputchart format foresees ?injection?
of such types intodeep structures.
Here, OBJID and other structured in-formation, like given name and surname, can be pre-served in the representation.
The advantage of theRMRS format is that it can also be combined ex postwith analyses from other deep or shallow NLP com-ponents, e.g., with partial analyses when a full parsefails.5 (R)MRS2OWL: from TDL to OWLThis section is devoted to the translation of MRSswhich are encoded as TFSs into a set of OWL expres-sions.
An example of a variant of MRS, a so-calledrobust MRS (RMRS) has already been depicted inFigure 1.
RMRS will be explained in more detail inSection 5.3.592??????????????????????????
?TEXT ?Did Bernd Kiefer present a paper at IJCAI 2005?
?TOP h1RELS???????????????????????????????????????
?int m relLBL h1ARG0 e2MARG h1?????
?prpstn m relLBL h1001ARG0 e2MARG h5???????
?proper q relLBL h6ARG0 x8RSTR h7BODY h9?????????
?named relLBL h10ARG0 x8CARG BerndKiefer?????????????
?present vLBL h11ARG0 e2 tense=pastARG1 x8 num=sgpers=3ARG2 x12 num=sgpers=3ARG3 u13?????????????
?a qLBL h14ARG0 x12RSTR h15BODY h16??????
?paper nLBL h17ARG0 x12???????
?at pLBL h1002ARG0 e19 tense=uARG1 e2ARG2 x18 num=sgpers=3??????????
?proper q relLBL h20ARG0 x18RSTR h21BODY h22???????
?named relLBL h23ARG0 x18CARG IJCAI 2005???????????????????????????????????????
?HCONS {h5 qeq h11, h7 qeq h10, h15 qeq h17, h21 qeq h23}ING {h1 ing h1001, h11 ing h1002}??????????????????????????
?Figure 1: RMRS generated through hybrid parsing.5.1 Some words on MRSsThere exist good linguistic reasons for assumingthat the semantics of a sentence like Kim ate acookie is not past(eat(kim?, cookie?
), but insteadsomething like ?e .
eating(e) ?
subject(e, kim?)
?object(e, cookie?)?before(e,now).
This approach toNL semantics is often called Event or Davidsoniansemantics (named after the American philosopherDonald Davidson).
HPSG has incorporated ideasfrom event semantics by defining so-called MinimalRecursion Semantics (MRS) structures (Copestake etal., 2005) that are constructed in parallel with the syn-tactic structure.
MRS as such provides a flat com-positional semantics and maximizes splitting usingequality constraints.
Structural ambiguities, as canbe found in the famous sentence Every farmer whoowns a donkey beats it, are not spelled out, but in-stead quantifier scope is underspecified.
By impos-ing constraints on the scope, specific analysis treescan be reconstructed.
Robust MRS (RMRS) (Copes-take, 2003), derived from MRS, was designed as anabstract language that supports the integration of par-tial and total analysis results from deep and shallowprocessors and provides a good tradeoff between ro-bustness and accuracy (see (Frank et al, 2004) for anexample).5.2 Why the translation is usefulNL processors (e.g., tokenizer, POS tagger, shallowchunk parser, deep parser, etc.)
that are geared to-wards (R)MRSs (or another common language) havethe potential of combining their output on the levelof semantics.
However, these engines do not provideany form of reasoning, i.e., they only build up struc-ture.Consider, for instance, a deep unification-basedparser that might return analyses represented as typedfeature structures, where both syntax and semantics(the MRS) has been constructed with the help of uni-fication.
Now, to bring structures together and toperform deductive and abductive forms of reason-ing, subsequent computational steps are necessary,but these steps strictly go beyond the power of or-dinary parsing.In order to perform these subsequent steps, weneed a concrete implemented (and hopefully stan-dardized) representation language for which editing,displaying, and reasoning tools are available.
Ex-actly OWL accomplishes these requirements.
Hencewe think that the described below translation processfrom (R)MRSs into OWL is worthwhile, especiallywhen one is interested in interfacing linguistic knowl-edge (the (R)MRSs) with extralinguistic ontologiesfor specific domains.5.3 The translation processIn order to explain the translation process, we willanalyze the RMRS depicted in Figure 1.
The RMRSwas derived from the MRS of the deep unification-based parser.
We see that an RMRS contains four dis-tinguished attributes (the TEXT attribute is only addedfor illustration):1.
TOP: a handle (pointer) to the top-level structure.2.
RELS (relations): a set of so-called elementarypredications (EP), encoded as TFSs, each ex-pressing an atomic semantic unit that can not be593further decomposed; due to the lack of sets, TFSgrammars use a list here.3.
HCONS (handle constraints): a set of so-calledqeq constraints (equality modulo quantifiers);the left side of a qeq constraints (a handle h inan argument position) is always related to a labell of an EP, (i) either directly (h = l) or (ii) indi-rectly, in case h dominates a quantifier q, suchthat BODY(q) = l or again another quantifier,where condition (ii) is recursively applied again.4.
ING (in group): a set of relations used to expressa conjunction of EPs from the set RELS.Giving this information, it should now be clear thatthe TFS from Figure 1 must be realized as an instanceof the OWL class RMRS and that the features TOP andRELS must be implemented as roles in OWL, all de-fined on RMRS through the use of rdfs:domain:<owl:Class rdf:ID="RMRS"/><owl:ObjectProperty rdf:ID="TOP"><rdf:type rdf:resource="&owl;FunctionalProperty"/><rdfs:domain rdf:resource="#RMRS"/><rdfs:range rdf:resource="#HandleVar"/></owl:ObjectProperty><owl:ObjectProperty rdf:ID="RELS"><rdfs:domain rdf:resource="#RMRS"/><rdfs:range rdf:resource="#EP"/></owl:ObjectProperty>TOP takes exactly one argument, hence we use OWL?sFunctionalProperty characteristics mechanismhere.
Since RELS (as well as HCONS and ING, seebelow) might take more than one argument, we donot impose a property restriction here, so they are re-lational by default.
TOP maps to a special variableclass (see below), and RELS to EPs.TOP.
The TOP property always takes a handle vari-able; other variable classes, such as label vars areused for restricting properties:<owl:Class rdf:ID="Var"/><owl:Class rdf:ID="HandleVar"><rdfs:subClassOf rdf:resource="#Var"/></owl:Class><owl:Class rdf:ID="LabelVar"><rdfs:subClassOf rdf:resource="#Var"/></owl:Class>Actually, this modelling is mere window-dressingand clearly verbose, since an OWL instance ofclass RMRS is always assigned a name (<RMRSrdf:ID="...">), and in fact, this name can betaken to be the TOP handle.
This means that we canin principle forbear from the TOP property.
However,if we want to utilize morpho-syntactical informationin subsequent inference steps, we have to enrich theabove variable classes with further properties/roles,such as tense, pers, or num (see, e.g., the ?struc-tured?
variables in the structure for present v inFigure 1).RELS.
Elements of RELS, i.e., concrete EPs areessentially ?slimed?
instances of feature structuretypes.
Overall, this means that we have to representthe relevant types of the linguistic type hierarchy andtheir subsumption relationship as OWL classes.
Asshown in Section 3, this process can be automatedand only some guidance from a knowledge engineeris necessary to mark the features that should not betaken over to the DL side.HCONS and ING.
HCONS essentially specifies aternary relation, but since OWL (and DL in general)are restricted to unary and binary relations, one wayto model a qeq constraint is to define a binary prop-erty, consisting of a left-hand and a right-hand side.From what has been said above, the left-hand side is ahandle and the right-hand side a label, hence we havethe following declaration for qeq:<owl:ObjectProperty rdf:ID="qeq"><rdfs:domain rdf:resource="#HandleVar"/><rdfs:range rdf:resource="#LabelVar"/></owl:ObjectProperty>Given this way of modelling, it is now impossible todefine a property HCONS (as well as ING) on classRMRS, since properties can only take instances ofclasses, but not instances of other properties.
How-ever, since we assume that our variables (instancesof class Var) are always unique at runtime, it is inprinciple not necessary to group the qeq constraintinside an (R)MRS?note that there is still a connec-tion between EPs and qeq constraints through the useof variables.
However, if we want to talk about/wantto access the qeq constraints of a specific (R)MRSinstance directly, this kind of modelling is somewhatunhandy.To overcome this seemingly wrong representation(we are neutral about this), we have to ?reify?
or?wrap?
qeq property instances.
This would mean thatqeq would no longer be a property, but instead be-comes a class, say QEQ, consisting of a right-handand a left-hand side.
With this in mind, we can eas-ily model, e.g., the first qeq constraint qeq1 from theabove figure:<RMRS rdf:ID="rmrs1"><TOP rdf:resource="#h1"/><RELS rdf:resource="#ep1"/><HCONS rdf:resource="#qeq1"/>594...</RMRS><QEQ rdf:ID="qeq1"><LHS rdf:resource="#h5"/><RHS rdf:resource="#h11"/></QEQ><HandleVar rdf:ID="h1"/><HandleVar rdf:ID="h5"/><LabelVar rdf:ID="h11"/><int_m_rel rdf:ID="ep1"><LBL rdf:resource="#h1"/><ARG0 rdf:resource="#e2"/><MARG rdf:resource="#h1"/></int_m_rel>What we have said about qeq constraints so far dohold for in-group constraints as well.6 DL reasoning: a small exampleWe have already said that the OWL representation ofRMRS structures are a good starting point to imple-ment some useful forms of reasoning.
Consider thesentence Did Bernd Kiefer present a paper at IJCAI2005?
from Figure 1.
From the resulting EPs andwith the help of an in-group constraint, we can inferthe fact that Bernd Kiefer was (physically) at IJCAI2005, assuming he has presented a paper (which hedid).
The inference rule achieving this can be statedinformally as presenting a paper at a conference en-tails being at the conference.
A more formal rep-resentation in terms of feature structures is given inFigure 2.Clearly this rule can be rewritten to operatate onOWL expressions (as is proposed in SWRL (Hor-rocks et al, 2004)) or on the underlying RDF triplenotation (which, for instance, OWLIM (Kiryakov,2006) assumes).
Note the use of logical variablesin the above rule in order to formulate the transportof information from the LHS to the RHS.
The aboverule abstract away from concrete persons and loca-tions through the use of logic variables ?p and ?l.Note further that the resulting RHS output structureis no longer a RMRS but a domain-specific represen-tation (somewhat simplified in this example) that canbe queried for or can be employed in subsequent rea-soning tasks.In (Frank et al, 2007), an implemented approach isdescribed that utilizes an additional frame represen-tation layer (Ruppenhofer et al, 2006) in which rulesof the above kind are applied, using the term rewrit-ing system of (Crouch, 2005).7 SummaryOur paper returned to mind that there exists a closerelationship between feature logics as used in compu-tational linguistics and description logics employedin the Semantic Web community.
This relation-ship can be utilized to obtain more and better se-mantic annotations through information extractionand deep parsing of text documents.
We have in-dicated that specific language constructs in FL andDL can be mutally transformed without losing anymeaning, whereas others can only be approximated(esp., role-value maps/reentrencies and functionalfeatures/relational roles).We have described an implemented procedure thatmaps ontology instances and concepts to named en-tity recognition and information extraction resources.As argued in the paper, the benefits for minimizeddomain-specific and linguistic knowledge engineer-ing are manifold.
An application using hybrid shal-low and deep NL processing on the basis of themapped ontology data has been successfully imple-mented for question answering.
This application(Frank et al, 2007) employs an additional frame se-mantics layer (cf.
Section 6) on which light formsof reasoning take place.
In order to make this addi-tional layer superflous, we have described a transfor-mation scheme that maps (R)MRS into OWL descrip-tions.
Given these descriptions, rules of the abovekind (Section 6) can directly operate on OWL, andno additional translation is necessary to query the in-stance data, encoded in RDF/OWL.ReferencesBaader, Franz, Diego Calvanese, Deborah McGuinness,Daniele Nardi, and Peter Patel-Schneider.
2003.
TheDescription Logic Handbook.
Cambridge UniversityPress, Cambridge.Busemann, Stephan, Witold Droz?dz?yn?ski, Hans-UlrichKrieger, Jakub Piskorski, Ulrich Scha?fer, Hans Uszko-reit, and Feiyu Xu.
2003.
Integrating Information Ex-traction and Automatic Hyperlinking.
In Proceedings ofthe Interactive Posters/Demonstration at ACL-03, pages117?120.Carpenter, Bob.
1992.
The Logic of Typed Feature Struc-tures.
Tracts in Theoretical Computer Science.
Cam-bridge University Press, Cambridge.Clark, James, 1999.
XSL Transformations (XSLT).
W3C,http://w3c.org/TR/xslt.Copestake, Ann, Dan Flickinger, Ivan A.
Sag, and CarlPollard.
2005.
Minimal recursion semantics: An in-troduction.
Research on Language and Computation,3(4):281?332, 12.
DOI 10.1007/s11168-006-6327-9.Copestake, Ann.
2003.
Report on the Design of RMRS.Technical Report D1.1b, University of Cambridge, Cam-bridge, UK.595??
?present vLBL ?h1ARG1 ?sARG2 ?o???
&[paper nARG0 ?o]&[ named relARG0 ?sCARG ?p]&[ at pLBL ?h2ARG2 ?x]&[ named relARG0 ?xCARG ?l]& (?h1 ing ?h2) =?
[PERSON ?pLOCATION ?l]Figure 2: RMRS rule over EPs and in-group constraint.Crouch, Richard.
2005.
Packed rewriting for map-ping semantics to KR.
In Proceedings of the Interna-tional Workshop on Computational Semantics (IWCS) 6,Tilburg.Droz?dz?yn?ski, Witold, Hans-Ulrich Krieger, Jakub Pisko-rski, Ulrich Scha?fer, and Feiyu Xu.
2004.
Shallow Pro-cessing with Unification and Typed Feature Structures?Foundations and Applications.
KI, 04(1):17?23.Flickinger, Dan.
2002.
On building a more efficient gram-mar by exploiting types.
In Oepen, S. D. Flickinger,J.
Tsuji, and H. Uszkoreit, editors, Collaborative Lan-guage Engineering.
A Case Study in Efficient Grammar-based Processing, pages 1?17.
CSLI Publications.Frank, Anette, Kathrin Spreyer, Witold Droz?dz?yn?ski, Hans-Ulrich Krieger, and Ulrich Scha?fer.
2004.
Constraint-Based RMRS Construction from Shallow Grammars.
InMu?ller, Stefan, editor, Proceedings of the HPSG04 Con-ference Workshop on Semantics in Grammar Engineer-ing, pages 393?413.
CSLI Publications, Stanford, CA.Frank, Anette, Hans-Ulrich Krieger, Feiyu Xu, HansUszkoreit, Berthold Crysmann, and Ulrich Scha?fer.2007.
Question answering from structured knowledgesources.
Journal of Applied Logics, Special Issue onQuestions and Answers: Theoretical and Applied Per-spectives, 5(1):20?48.Haghighi, Aria and Dan Klein.
2009.
Simple coreferenceresolution with rich syntactic and semantic features.
InProceedings of the 2009 Conference on Empirical Meth-ods in Natural Language Processing, pages 1152?1161.Horrocks, Ian, Peter F. Patel-Schneider, Harold Boley, SaidTabet, Benjamin Grosof, and Mike Dean.
2004.
SWRL:A semantic web rule language combining OWL andRuleML.
W3C Member Submission.Kiryakov, Atanas.
2006.
OWLIM: balancing betweenscalable repository and light-weight reasoner.
Presen-tation of the Developer?s Track of WWW2006.Krieger, Hans-Ulrich and Ulrich Scha?fer.
1994.
TDL?AType Description Language for Constraint-Based Gram-mars.
In Proceedings of the 15th International Confer-ence on Computational Linguistics, COLING-94, pages893?899.Krieger, Hans-Ulrich, Witold Droz?dz?yn?ski, Jakub Pisko-rski, Ulrich Scha?fer, and Feiyu Xu.
2004.
A Bag of Use-ful Techniques for Unification-Based Finite-State Trans-ducers.
In Proceedings of KONVENS 2004, pages 105?112.McGuinness, Deborah L. and Frank van Harmelen.
2004.OWL Web Ontology Language Overview.
Technical re-port, W3C.
10 February.Nebel, Bernhard and Gert Smolka.
1990.
Represen-tation and reasoning with attributive descriptions.
InBla?sius, K.-H., U. Hedtstu?ck, and C.-R. Rollinger, ed-itors, Sorts and Types in Artificial Intelligence, pages112?139.
Springer, Berlin.
Also available as IWBS Re-port 81, IBM Germany, September 1989.Pollard, Carl and Ivan A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
Studies in Contemporary Linguis-tics.
University of Chicago Press, Chicago.Ruppenhofer, Josef, Michael Ellsworth, Miriam R.L.Petruck, Christopher R. Johnson, and Jan Schef-fczyk.
2006.
FrameNet II: extended theory and prac-tice.
Technical report, International Computer Sci-ence Institute (ICSI), University of California, Berkley.http://framenet.icsi.berkley.edu/book/book.pdf.Scha?fer, Ulrich, Hans Uszkoreit, Christian Federmann,Torsten Marek, and Yajing Zhang.
2008.
Extractingand querying relations in scientific papers on languagetechnology.
In Proceedings of LREC-2008.Scha?fer, Ulrich.
2006.
OntoNERdIE ?
mapping and link-ing ontologies to named entity recognition and infor-mation extraction resources.
In Proceedings of the 5thInternational Conference on Language Resources andEvaluation LREC-2006, pages 1756?1761, Genoa, Italy.596
