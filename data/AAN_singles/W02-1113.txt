Generating extraction patternsfrom a large semantic network and an untagged corpusThierry POIBEAUThales and LIPNDomaine de Corbeville91404 Orsay, FranceThierry.Poibeau@thalesgroup.comDominique DUTOITMemodata and CRISCO17, rue Dumont d?UrvilleCaen, Francememodata@wanadoo.frAbstractThis paper presents a module dedicatedto the elaboration of linguistic resourcesfor a versatile Information Extractionsystem.
In order to decrease the timespent on the elaboration of resources forthe IE system and guide the end-user ina new domain, we suggest to use amachine learning system that helpsdefining new templates and associatedresources.
This knowledge isautomatically derived from the textcollection, in interaction with a largesemantic network.1 IntroductionInformation Extraction (IE) is a technologydedicated to the extraction of structuredinformation from texts.
This technique is usedto highlight relevant sequences in the originaltext or to fill pre-defined templates (Pazienza,1997).Even if IE seems to be now a relativelymature technology, it suffers from a number ofyet unsolved problems that limit itsdissemination through industrial applications.Among these limitations, we can consider thefact that systems are not really portable fromone domain to another.
Even if the system isusing some generic components, most of itsknowledge resources are domain-dependent.Moving from one domain to another means re-developing some resources, which is a boringand time-consuming task (for example Riloff(1995) mentions a 1500 hours development).Several recent works propose to overcome theselimitations by using annotated corpora as areservoir of knowledge.
However, annotatedcorpora are rarely present in companies, and to acertain extent solutions based on corpora seemto be inappropriate.In this paper, we propose an approach basedon a rich semantic network.
We will firstlydescribe this network and a set of originalmeasures we have implemented to calculatesimilarities between words.
We will then presentthe acquisition process, in which the semanticnetwork is projected on the corpus to deriveextraction patterns.
This mechanism can be seenas a dynamic lexical tuning of informationcontained in the semantic network.
In the lastsection, we propose an evaluation and someperspectives.2 Related workThe bases of IE as defined in the introductionare exposed in (Pazienza, 1997).
IE is known tohave established a now widely acceptedlinguistic architecture based on cascadingautomata and domain-specific knowledge(Appelt et al 1993).
However, several studieshave outlined the problem of the definition ofthe resources, see E. Riloff (1995).To address this problem of portability, arecent research effort focused on using machinelearning throughout the IE process (Muslea,1999).
A first trend was to directly applymachine learning methods to replace IEcomponents.
For instance, statistical methodshave been successfully applied to the named-entity task.
Among others, (Bikel et a., 1997)learns names by using a variant of hiddenMarkov models.Another research area trying to avoid thetime-consuming task of elaborating IEresources is concerned with the generalizationof extraction patterns from examples.
(Muslea,1999) gives an extensive description of thedifferent approaches of that problem.
Autoslog(Riloff, 1993) was one of the very first systemsusing a simple form of learning to build adictionary of extraction patterns.
Successors ofAutoSlog like Crystal (Soderland et al, 1995)mainly use decision trees and relationallearning techniques to learn set of rules duringtheir extraction step.
More recently, the SrVsystem (Freitag, 1998) and the Pinocchiosystem (Ciravegna, 2001) use a combination ofrelational and basic statistical methods inspiredfrom Na?ve Bayes for IE tasks.These approaches acquire knowledge fromtexts but they must be completed with asemantic expansion module.
Several authorshave presented experiments based on Wordnet(Bagga et al, 1996).Our approach is original given that itconsists in an integrated system, using both asemantic network and a corpus to acquireknowledge and overcome the limitations ofboth knowledge sources.
On the one hand, thefact that we use a semantic network allows usto obtain a broader coverage than if we onlyused a training corpus (contrary Ciravegna?system for example).
On the other hand, thecorpus ensures that the acquired resources arequite adapted to the task (contrary Bagga?system for example).
The performance of thesystem will demonstrate this point (see belowsection 5).3 The semantic netThe semantic network used in this experimentis a multilingual net providing information forfive European languages.
We quickly describethe network and then give some detail about itsoverall structure.3.1 Overall descriptionThe semantic network we use is called TheIntegral Dictionary.
This database is basicallystructured as a merging of three semanticmodels available for five languages.
Themaximal coverage is given for the Frenchlanguage, with 185.000 word-meanings encodedin the database.
English Language appears likethe second language in term of coverage with79.000 word-meanings.
Three additionallanguages (Spanish, Italian and German) arepresent for about 39.500 senses.These smallest dictionaries, with universalidentifiers to ensure the translation, define theBasic Multilingual Dictionary available from theELRA.
Grefenstette (1998) has done a corpuscoverage evaluation for the Basic MultilingualDictionary.
The newspapers corpora defined bythe US-government-sponsored Text RetrievalConference (TREC) have been used as a testcorpus.
The result was that the chance of pullinga random noun out of the different corpora wason average 92%1.
This statistic is given for theBasic Multilingual Dictionary and, of course, theFrench Integral Dictionary reaches the highestcoverage.3.2 Semantic linksThe links in the semantic network canconnect word-senses together, but also classesand concepts.
Up to now, more than 100different kinds of links have been definded.
Allthese links are typed so that a weight can beallocated to each link, given its type.
Thismechanism allows to very precisely adapt thenetwork to the task: one does not use the sameweighting to perform lexical acquisition as toperform word-sense disambiguation.
Thischaracteristic makes the network highly adaptiveand appropriate to explore some kind of lexicaltuning.This network includes original strategies tomeasure the semantic proximity between twowords.
These measures take into account thesimilarity between words (their commonfeatures) but also their differences.
Thecomparison between two words is based on thestructure of the graph: the algorithm calculates ascore taken into account the common ancestorsbut also the different ones.1This means that for a target English text, one canassume that 92% of the tokens will be in the semanticnet.Figure 1: A table of linguistic constraintsWe will not detail here the different measuresthat have been implemented to calculatesimilarities between words.
Please refer to(Dutoit and Poibeau, 2002) for more details.4 Acquisition of semanticallyequivalent predicative structuresFor IE applications, defining an appropriate setof extraction pattern is crucial.
That is why wewant to validate the proposed measures toextend an initial set of extraction patterns.4.1 The acquisition processThe process begins when the end-user providesa predicative linguistic structure to the systemalong with a representative corpus.
The systemtries to discover relevant parts of text in thecorpus based on the presence of plain wordsclosely related to the ones of the examplepattern.
A syntactic analysis of the sentence isthen done to verify that these plain wordscorrespond to a predicative structure.
Themethod is close to the one of E. Morin et C.Jacquemin (1999), who first locate couples ofrelevant terms and then try to apply relevantpatterns to analyse the nature of theirrelationship.
The detail algorithm is describedbelow:1.
The head noun of the example pattern iscompared with the head noun of thecandidate pattern using the proximitymeasure.
This result of the measure mustbe under a threshold fixed by the end-user.2.
The same condition must be filled by the?expansion?
element (the complement ofthe noun or of the verb of the candidatepattern).3.
The structure must be predicative (either anominal or a verbal predicate, thealgorithm does not make any difference atthis level).The result of this analysis is a table thatrepresent predicative structures equivalent to theinitial example pattern.
The process uses thecorpus and the semantic net as two differentcomplementary knowledge sources:?
The semantic net provides informationabout lexical semantics and relationsbetween words?
The corpus attests possible expressionsand filter irrelevant ones.We performed some evaluation on differentFrench corpora, given that the semantic net isespecially rich for this language.
We take theexpression cession de soci?t?
(companytransfer) as an initial pattern.
The system thendiscovered the following expressions, each ofthem being semantically related to the initialpattern :reprise des activit?srachat d?activit?acqu?rir des magasinsracheter *c-company*cession de *c-company*?This result includes some phase with*c-company*: the corpus has been previouslypreprocessed so that each named entity isreplaced by its type.
This process normalizesthe corpus so that the learning process canachieve better performance.The result must be manually validated.
Somestructures are found even if they are irrelevant,due to the activation of irrelevant links.
It is thecase of the expression renoncer ?
se porteracqu?reur (to give up buying sthg), which isnot relevant.
In this case, there was a spuriouslink between to give up and company in thesemantic net.4.2 Dealing with syntactic variationsThe previous step extract semanticallyrelated predicative structures from a corpus.These structures are found in the corpus in acertain linguistic structure, but we want thesystem to be able to find this information evenif it appears in other kind of linguisticsequences.
That is the reason why we associatesome meta-graphs with these linguisticstructures, so that different transformation canbe recognized2.
This transformation concernsthe syntactic level, either on the head (H) or onthe expansions (E) of the linguistic structure.The meta-graphs encode transformationsconcerning the following structures:?
Subject ?
verb,?
Verb ?
direct object,2A meta-graph corresponds to a non-lexicalizedgraph.
A meta-graph is then a kind of abstractgrammar (see also the notion of metagrammar inthe TAG theory (Candito, 1999)?
Verb ?
direct object (especially whenintroduced by the French preposition ?
orde),?
Noun ?
noun complement.These meta-graphs encode the major part of thelinguistic structures we are concern with in theprocess of IE.The graph on Figure 2 recognizes thefollowing sequences (in brackets we underlinethe couple of words previously extracted fromthe corpus):Reprise des activit?s charter?
(H:reprise, E: activit?
)Reprendre les activit?s charter?
(H:reprendre, E: activit?
)Reprise de l?ensemble des magasinssuisse?
(H: reprise, E: magasin)Reprendre l?ensemble des magasinssuisse?
(H: reprendre, E: magasin)Racheter les diff?rentes activit?s?
(H: racheter, E: activit?
)Rachat des diff?rentes activit?s?
(H:rachat, E: activit?
)This kind of graph is not easy to read.
Itincludes at the same time some linguistic tagsand some applicability constraints.
For example,the first box contains a reference to the @Acolumn in the table of identified structures.
Thiscolumn contains a set of binary constraints,expressed by some signs + or -.
The sign +means that the identified pattern is of type verb-direct object: the graph can then be applied todeal with passive structures.
In other words, thegraph can only be applied in a sign + appears inthe @A column of the constraints table.
Theconstraints are removed from the instantiatedgraph3.
Even if the resulting graph is normallynot visible (the compilation process directly3In other words, an abstract graph is a non-lexicalized graph and an instantiated graph is alexicalized graph.Figure 2: A meta-graph encoding syntactic variationsproduced a graph in a binary format), we cangive an equivalent graph.This mechanism using constraint tables andmeta-graph has been implemented in the finite-state toolbox INTEX (Silberztein, 1993).
26meta-graphs have been defined modellinglinguistic variation for the 4 predicativestructures defined above.
The phenomenamainly concern the insertion of modifiers (withthe noun or the verb), verbal transformations(passive) and phrasal structures (relativeclauses like ?Vivendi, qui a rachet?Universal?Vivendi, that bought Universal).The compilation of the set of meta-graphsproduces a graph made of 317 states and 526relations.
These graphs are relatively abstractbut the end-user is not intended to directlymanipulate them.
They generate instantiatedgraphs, that is to say graphs in which theabstract variables have been replaced linguisticinformation as modeled in the constrainttables.This method associates a couple ofelements with a set of transformation thatcovers more examples than the one of thetraining corpus.
This generalization process isclose to the one imagined by Morin andJacquemin (1999) for terminology analysis.5 EvaluationThe evaluation concerned the extraction ofinformation from a French financial corpus,about companies buying other companies.
Thecorpus is made of 300 texts (200 texts for thetraining corpus, 100 texts for the test corpus).A system was first manually developed andevaluated.
We then tried to perform the sametask with automatically developed resources,so that a comparison is possible.
At thebeginning, the end-user must provide a set ofrelevant pattern to the acquisition system.
Wehave developed a filtering tool to help the enduser focus on relevant portion of text.
Due tolack of place, we will not describe this filteringtool, which is very close in its conception tothe EXDISCO system developed by R.Yangarber at NYU.First of all, the corpus is normalized.
Forexample, all the company names are replaced bya variable *c-company* thanks to the namedentity recognizer.
In the semantic network, *c-company*is introduced as a synonym ofcompany, so that all the sequences with a propername corresponding to a company could beextracted.For the slot corresponding to the companythat is being bought, 6 seed patterns were givento semantic expansion module.
This moduleacquired from the corpus 25 new validatedpatterns.
Each example pattern generated 4.16new patterns on average.
For example, from thepattern rachat de *c-company* we obtain thefollowing list:reprise de *c-company*achat de *c-company*acqu?rir *c-company*racheter *c-company*cession de *c-company*This set of pattern includes nominal phrases(reprise de *c-company*) and verbal phrases(racheter *c-company*).
The acquisitionprocess concerns at the same time, the head andthe expansion.
This technique is very close tothe co-training algorithm proposed for this kindof task by E. Riloff and R. Jones (Riloff etJones, 1999) (Jones et al, 1999).The proposed patterns must be filtered andvalidated by the end-user.
We estimate thatgenerally 25% of the acquired pattern should berejected.
However, this validation process isvery rapid: a few minutes only were necessary tocheck the 31 proposed patterns and retain 25 ofthem.We then compared these results with the onesobtained with the manually elaborated system.The evaluation concerned the two slots thatnecessitate a syntactic and semantic analysis: thecompany that is buying another one (slot 1) andthe company that is being bought (slot 2).
Theseslots imply nominal phrases, they can becomplex and a functional analysis is most of thetime necessary (is the nominal phrase the subjector the direct object of the sentence?).
Anoverview of the results is given below (P is forprecision, R for recall; P&R is the combinedratio of P and R):Slot 1 Slot 2P: 100R: 90P: 100R: 91.6HumanannotatorsP&R : 94.7 P&R : 95.6P: 79.6R: 62.6P: 93.4R: 73INTEX +manualresources  P&R : 70 P&R : 81.9P: 65.8R: 58.7P: 77R: 65.3INTEX +SemTexP&R: 62 P&R: 70.7The system running with automaticallydefined resources is about 10% less efficientthan the one with manually defined resources.The decrease of performance may vary infunction of the slot (the decrease is lessimportant for the slot 1 than for the slot 2).Two kind of errors are observed:Certain sequences are not found because arelation between words is missing in thesemantic net.
This is the case for someidiomatic expressions that were not registeredin the network like tomber dans l?escarcelle dewhich  means to acquire.Some sequences are extracted by thesemantic analysis but do not correspond to atransformation registered in the syntacticvariation management module.
For examplethe sequence:*c-company* renforce son activit?communication ethnique en prenantune participation dans *c-company* 4is not completely recognized.
The pattern(prendre <DET>) participation dans *c-company* correctly identifies the companythat is being bought.
But the pattern *c-company*(prendre <DET>) participationcannot apply because the subject is too farfrom the verb.Lastly, we can mention that some patternsthat were not found manually are identified bythe automatic procedure.
The gain concerningdevelopment time is very significant (50 hwere necessary to manually define the4*c-company* reinforces its activity inethnic communication by taking someinterest in *c-company*resources, only 10 h with the semi-automaticprocess).Even if the decrease of performance issignificant (10%), it can be reduced using morelinguistic knowledge.
For example, we knowthat nominalizations are not correctly handled bythe system at the moment.
Some moreinformation could be used from the semanticnetwork (that also includes morphological andsyntactic information) to enhance theperformances of the overall system.Experiments have been made on differentcorpora and on different MUC-like tasks.
Theyhave all proved the efficiency of the strategydescribed in this paper.
Moreover, it is possibleto adapt the system so that it has a betterprecision, or a better recall, given user needs(Poibeau, 2001).
For example, people workingon large genomic textual databases are facing ahuge amount of redundant information.
Theygenerally want some very precise information tobe extracted.
On the other hand, humanoperators monitoring critical situation generallywant to be able to have access to all theavailable information.
Our system is versatileand could be easily adapted to these differentcontexts.6 ConclusionIn this paper, we have shown an efficientalgorithm to semi-automatically acquireextraction patterns from a semantic network anda corpus.
Even if the performance decreasewhen the resource are automatically defined, thegain in development time is sufficientlysignificant to ensure the usability of theapproach.7 ReferencesAppelt D.E, Hobbs J., Bear J., Israel D., KameyanaM.
and Tyson M. (1993) FASTUS: a finite-stateprocessor for information extraction from real-world text.
Proceedings of IJCAI?93, Chamb?ry,France, pp.
1172?1178.Bagga A., Chai J.Y.
et Biermann A.
The Role ofWORDNET in the Creation of a Trainable MessageUnderstanding System.
In Proceedings of the 14thNational Conference on Artificial Intelligence andthe Ninth Conference on the InnovativeApplications of Artificial Intelligence(AAAI/IAAI?97), Rhode Island, 1997, pp.
941?948.Bikel D., Miller S., Schwartz R. and Weischedel R.(1997) Nymble: a high performance learningname-finder.
Proceeding of the fifth Conferenceon Applied Language Processing, Washington,USA.Candito, M.-H. Organisation modulaire etparam?trable de grammaires ?lectroniqueslexicalis?es.
PhD Thesis, University Paris 7,1999.Ciravegna F. Adaptive Information Extraction fromText by Rule Induction and Generalisation.
InProceedings of the 17th International JointConference on Artificial Intelligence(IJCAI?2001), Seattle, 2001, pp.
1251?1256.Dutoit D. and Poibeau T. (2002) Inferringknowledge from a large semantic network.
InProceedings of COLING?2002, Ta?pei.Fellbaum C. (1998) WordNet : An ElectronicLexical Database, edited by Fellbaum, M.I.T.press.Freitag D. (1998) Machine learning for InformationExtraction in Informal Domains, Thesis, CarnegieMellon University, USA.Grefenstette G. (1998) Evaluating the adequancy ofa multilingual transfer dictionary for the CrossLanguage Information Retrieval, LREC 1998.Jones R., McCallum A., Nigam K. and Riloff E.(1999) Bootstrapping for Text Learning Tasks.Proceedings of the IJCAI?99 Workshop on TextMining: Foundations, Techniques andApplications, Stockholm, 1999, pp.
52?63.Morin E. and Jacquemin C. (1999) Projectingcorpus-based semantic links on a thesaurus.Proceedings of the 37th Annual Meeting of theAssociation for Computational Linguistics(ACL?99), Maryland, 1999, pp.
389?396.Muslea I.
(1999) Extraction patterns forInformation Extraction tasks: a survey, AAAI?99(available at the following URL:http://www.isi.edu/~muslea/ RISE/ML4IE/)Pazienza M.T, ed.
(1997) Information extraction.Springer Verlag  (Lecture Notes in computerScience), Heidelberg, Germany.Poibeau T. (2001) ?
?
Deriving a multi-domaininformation extraction system from a roughontology.
Proceeding of the 17th InternationalConference on Artificial Intelligence(IJCAI?2001), Seattle, 2001, pp.
1264?1270.Riloff E. (1993) Automatically constructing adictionary for formation extraction tasks,AAAI?93, Stanford, USA, pp.
811?816.Riloff E. (1995) Little Words Can Make a BigDifference for Text Classification , Proceedings ofthe SIGIR'95, Seattle, USA, pp.
130?136.Riloff E. et Jones R.  (1999) Learning Dictionariesfor Information Extraction by Multi-LevelBootstrapping.
Proceedings of the 16th NationalConference on Artificial Intelligence (AAAI?99),Orlando, 1999, pp.
474?479.Silberztein M. (1993) Dictionnaires ?lectroniques etanalyse automatique des textes, Masson, Paris,France.Soderland S., Fisher D., Aseltine J. and Lenhert W.(1995) Crystal: inducing a conceptual dictionary,Proceedings of IJCAI?95, Montr?al, Canada,pp.
1314?1319.Yangarber R. (2000) Scenario Customization forInformation Extraction.
PhD Thesis, New YorkUniversity.
