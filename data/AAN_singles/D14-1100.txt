Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 928?937,October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsAmbiguity Resolution for Vt-N Structures in ChineseYu-Ming Hsieh1,2       Jason S. Chang2       Keh-Jiann Chen11 Institute of Information Science, Academia Sinica, Taiwan2 Department of Computer Science, National Tsing-Hua University, Taiwanmorris@iis.sinica.edu.tw, jason.jschang@gmail.comkchen@iis.sinica.edu.twAbstractThe syntactic ambiguity of a transitiveverb (Vt) followed by a noun (N) haslong been a problem in Chinese parsing.In this paper, we propose a classifier toresolve the ambiguity of Vt-N structures.The design of the classifier is based onthree important guidelines, namely,adopting linguistically motivated features,using all available resources, and easy in-tegration into a parsing model.
The lin-guistically motivated features includesemantic relations, context, and morpho-logical structures; and the available re-sources are treebank, thesaurus, affix da-tabase, and large corpora.
We also pro-pose two learning approaches that resolvethe problem of data sparseness by auto-parsing and extracting relativeknowledge from large-scale unlabeleddata.
Our experiment results show thatthe Vt-N classifier outperforms the cur-rent PCFG parser.
Furthermore, it can beeasily and effectively integrated into thePCFG parser and general statistical pars-ing models.
Evaluation of the learningapproaches indicates that worldknowledge facilitates Vt-N disambigua-tion through data selection and error cor-rection.1 IntroductionIn Chinese, the structure of a transitive verb (Vt)followed by a noun (N) may be a verb phrase(VP), a noun phrase (NP), or there may not be adependent relation, as shown in (1) below.
Ingeneral, parsers may prefer VP reading because atransitive verb followed by a noun object is nor-mally a VP structure.
However, Chinese verbscan also modify nouns without morphologicalinflection, e.g., ??
/farming ?
/pond.
Conse-quently, parsing Vt-N structures is difficult be-cause it is hard to resolve such ambiguities with-out prior knowledge.
The following are sometypical examples of various Vt-N structures:1)?
?/solve ?
?/problem ?
VP?
?/solving ?
?/method ?
NP?
?/solve ?
?/mankind (?
?/problem)?NoneTo find the most effective disambiguation fea-tures, we need more information about the Vt-N?
NP construction and the semantic relationsbetween Vt and N. Statistical data from the Sini-ca Treebank (Chen et al., 2003) indicates that58% of Vt-N structures are verb phrases, 16%are noun phrases, and 26% do not have any de-pendent relations.
It is obvious that the semanticrelations between a Vt-N structure and its con-text information are very important for differen-tiating between dependent relations.
Althoughthe verb-argument relation of VP structures iswell understood, it is not clear what kind of se-mantic relations result in NP structures.
In thenext sub-section, we consider three questions:What sets of nouns accept verbs as their modifi-ers?
Is it possible to identify the semantic typesof such pairs of verbs and nouns?
What are theirsemantic relations?1.1 Problem AnalysisAnalysis of the instances of NP(Vt-N) structuresin the Sinica Treebank reveals the following fourtypes of semantic structures, which are used inthe design of our classifier.Type 1.
Telic(Vt) + Host(N): Vt denotes thetelic function (purpose) of the head noun N, e.g.,928??
/research ??
/tool; ??
/explore ?/machine; ?/gamble ?/house; ?
?/search ??/program.
The telic function must be a salientproperty of head nouns, such as tools, buildings,artifacts, organizations and people.
To identifysuch cases, we need to know the types of nounswhich take telic function as their salient property.Furthermore, many of the nouns are monosyl-labic words, such as ?/people, ?/instruments,?/machines.Type 2.
Host-Event(Vt) + Attribute(N):Head nouns are attribute nouns that denote theattributes of the verb, e.g., ?
?/research ?
?/method (method of research); ?
?/attack ?
?/strategy (attacking strategy); ?
?/write ?
?/context (context of writing); ?/gamble ?/rule(gambling rules).
An attribute noun is a specialtype of noun.
Semantically, attribute nouns de-note the attribute types of objects or events, suchas weight, color, method, and rule.
Syntactically,attribute nouns do not play adjectival roles (Liu,2008).
By contrast, object nouns may modifynouns.
The number of attributes for events islimited.
If we could discover all event-attributerelations, then we can solve this type of construc-tion.Type 3.
Agentive + Host: There is only a lim-ited number of such constructions and the resultsof the constructions are usually ambiguous, e.g.,?
?/fried rice (NP), ?
?/shouting sound.
Thefirst example also has the VP reading.Type 4.
Apposition + Affair: Head nouns areevent nouns and modifiers are verbs of apposi-tion events, e.g.
?
?/collide ?
?/accident, ??
/destruct ??
/movement, ??
/hate ??/behavior.
There is finite number of event nouns.Furthermore, when we consider verbal modi-fiers, we find that verbs can play adjectival rolesin Chinese without inflection, but not all verbsplay adjectival roles.
According to Chang et al.
(2000) and our observations, adjectival verbs areverbs that denote event types rather than eventinstances; that is, they denote a class of eventswhich that are concepts in an upper-level ontolo-gy.
One important characteristic of adjectivalverbs is that they have conjunctive morphologi-cal structures, i.e., the words are conjunct withtwo nearly synonymous verbs, e.g., ?/study ?/search (research), ?
/explore ?
/detect (ex-plore), and ?/search ?/find (search).
Therefore,we need a morphological classifier that can de-tect the conjunctive morphological structure of averb by checking the semantic parity of twomorphemes of the verb.Based on our analysis, we designed a Vt-Nclassifier that incorporates the above features tosolve the problem.
However, there is a datasparseness problem because of the limited size ofthe current Treebank.
In other words, Treebankcannot provide enough training data to train aclassifier properly.
To resolve the problem, weshould mine useful information from all availa-ble resources.The remainder of this paper is organized asfollows.
Section 2 provides a review of relatedworks.
In Section 3, we describe the disambigua-tion model with our selected features, and intro-duce a strategy for handling unknown words.
Wealso propose a learning approach for a large-scale unlabeled corpus.
In Section 4, we reportthe results of experiments conducted to evaluatethe proposed Vt-N classifier on different featurecombinations and learning approaches.
Section 5contains our concluding remarks.2 Related WorkMost works on V-N structure identification focuson two types of relation classification: modifier-head relations and predicate-object relations (Wu,2003; Qiu, 2005; Chen, 2008; Chen et al., 2008;Yu et al., 2008).
They exclude the independentstructure and conjunctive head-head relation, butthe cross-bracket relation does exist between twoadjacent words in real language.
For example, if??
?/all over  ?
?/world ?
was included in theshort sentence ??
?/all over  ?
?/world ?
?/countries?, it would be an independent structure.A conjunctive head-head relation between a verband a noun is rare.
However, in the sentence ???
??
?
?
???
(Both service and equip-ment are very thoughtful.
), there is a conjunctivehead-head relation between the verb ?
?/service and the noun ??/equipment.
Therefore,we use four types of relations to describe the V-N structures in our experiments.
The symbol?H/X?
denotes a predicate-object relation; ?X/H?denotes a modifier-head relation; ?H/H?
denotesa conjunctive head-head relation; and ?X/X?
de-notes an independent relation.Feature selection is an important task in V-Ndisambiguation.
Hence, a number of studies havesuggested features that may help resolve the am-biguity of V-N structures (Zhao and Huang, 1999;Sun and Jurafsky, 2003; Chiu et al., 2004; Qiu,2005; Chen, 2008).
Zhao and Huang used lexi-cons, semantic knowledge, and word length in-929formation to increase the accuracy of identifica-tion.
Although they used the Chinese thesaurusCiLin (Mei et al., 1983) to derive lexical seman-tic knowledge, the word coverage of CiLin isinsufficient.
Moreover, none of the above paperstackle the problem of unknown words.
Sun andJurafsky exploit the probabilistic rhythm feature(i.e., the number of syllables in a word or thenumber of words in a phrase) in their shallowparser.
Their results show that the feature im-proves the parsing performance, which coincideswith our analysis in Section 1.1.
Chiu et al.
?sstudy shows that the morphological structure ofverbs influences their syntactic behavior.
Wefollow this finding and utilize the morphologicalstructure of verbs as a feature in the proposed Vt-N classifier.
Qiu?s approach uses an electronicsyntactic dictionary and a semantic dictionary toanalyze the relations of V-N phrases.
However,the approach suffers from two problems: (1) lowword coverage of the semantic dictionary and (2)the semantic type classifier is inadequate.
Finally,Chen proposed an automatic VN combinationmethod with features of verbs, nouns, context,and the syllables of words.
The experiment re-sults show that the method performs reasonablywell without using any other resources.Based on the above feature selection methods,we extract relevant knowledge from Treebank todesign a Vt-N classifier.
However we have toresolve the common problem of data sparseness.Learning knowledge by analyzing large-scaleunlabeled data is necessary and proved useful inprevious works (Wu, 2003; Chen et al., 2008; Yuet al., 2008).
Wu developed a machine learningmethod that acquires verb-object and modifier-head relations automatically.
The mutual infor-mation scores are then used to prune verb-nounwhose scores are below a certain threshold.
Theauthor found that accurate identification of theverb-noun relation improved the parsing perfor-mance by 4%.
Yu et al.
learned head-modifierpairs from parsed data and proposed a head-modifier classifier to filter the data.
The filteringmodel uses the following features: a PoS-tag pairof the head and the modifier; the distance be-tween the head and the modifier; and the pres-ence or absence of punctuation marks (e.g.,commas, colons, and semi-colons) between thehead and the modifier.
Although the method im-proves the parsing performance by 2%, the filter-ing model obtains limited data; the recall rate isonly 46.35%.
The authors also fail to solve theproblem of Vt-N ambiguity.Our review of previous works and the obser-vations in Section 1.1 show that lexical words,semantic information, the syllabic length ofwords, neighboring PoSs and the knowledgelearned from large-scale data are important forVt-N disambiguation.
We consider more featuresfor disambiguating Vt-N structures than previousstudies.
For example, we utilize (1) four relationclassification in a real environment, including?X/H?, ?H/X?, ?X/X?
and ?H/H?
relations; (2) un-known word processing of Vt-N words (includ-ing semantic type predication and morph-structure predication); (3) unsupervised data se-lection (a simple and effective way to extendknowledge); and (4) supervised knowledge cor-rection, which makes the extracted knowledgemore useful.3 Design of the Disambiguation ModelThe disambiguation model is a Vt-N relationclassifier that classifies Vt-N relations into ?H/X?
(predicate-object relations), ?X/H?
(modifier-head relations), ?H/H?
(conjunctive head-headrelations), or ?X/X?
(independent relations).
Weuse the Maximum Entropy toolkit (Zhang, 2004)to construct the classifier.
The advantage of us-ing the Maximum Entropy model is twofold: (1)it has the flexibility to adjust features; and (2) itprovides the probability values of the classifica-tion, which can be easily integrated into ourPCFG parsing model.In the following sections, we discuss the de-sign of our model for feature selection and ex-traction, unknown word processing, and worldknowledge learning.3.1 Feature Selection and ExtractionWe divide the selected features into five groups:PoS tags of Vt and N, PoS tags of the context,words, semantics, and additional information.Table 1 shows the feature types and symbol nota-tions.
We use symbols of t1 and t2 to denote thePoS of Vt and N respectively.
The context fea-ture is neighboring PoSs of Vt and N: the sym-bols of t-2 and t-1 represent its left PoSs, and thesymbol t3 and t4 represent its right PoSs.
The se-mantic feature is the lexicon?s semantic type ex-tracted from E-HowNet sense expressions(Huang et al., 2008).
For example, the E-HowNet expression of ?
?
?
/vehicles?
is{LandVehicle|?
:quantity={mass|?
}}, so itssemantic type is {LandVehicle|?}.
We discussthe model?s performance with different featurecombinations in Section 4.930Feature  Feature DescriptionPoS PoS of Vt and Nt1; t2Context Neighboring PoSst-2; t-1; t3; t4Word Lexical wordw1; w2Semantic Semantic type of wordst1; st2AdditionalInformationMorphological structure of verbVmorphSyllabic length of nounNlenTable 1.
The features used in the Vt-N classifierThe example in Figure 1 illustrates feature la-beling of a Vt-N structure.
First, an instance of aVt-N structure is identified from Treebank.
Then,we assign the semantic type of each word with-out considering the problem of sense ambiguityfor the moment.
This is because sense ambigui-ties are partially resolved by PoS tagging, andthe general problem of sense disambiguation isbeyond the scope of this paper.
Furthermore,Zhao and Huang (1999) demonstrated that theretained ambiguity does not have an adverse im-pact on identification.
Therefore, we keep theambiguous semantic type for future processing.zhe        zaochen     xuexi  zhongwen    DE    fongchaothis         cause        learn     Chinese                    trend?This causes the trend of learning Chinese.
?Figure 1.
An example of a tree with a Vt-N struc-tureTable 2 shows the labeled features for ??
?/learn  ??/Chinese?
in Figure 1.
The column xand y describe relevant features in ??
?/learn?and ???/Chinese?
respectively.
Some featuresare not explicitly annotated in the Treebank, e.g.,the semantic types of words and the morphologi-cal structure of verbs.
We propose labelingmethods for them in the next sub-section.Feature Type x yWord w1=??
w2=?
?PoS t1=VC t2=NaSemantic st1=study|??
st2=language|?
?Context t-2=Nep; t-1=VK; t3=DE; t4=NaAdditionalInformationVmorph=VV Nlen=2Relation Type  rt = H/XTable 2.
The feature labels of Vt-N pair in Figure13.2 Unknown Word ProcessingIn Chinese documents, 3% to 7% of the wordsare usually unknown (Sproat and Emerson,2003).
By ?unknown words?, we mean words notlisted in the dictionary.
More specifically, in thispaper, unknown words means words without se-mantic type information (i.e., E-HowNet expres-sions) and verbs without morphological structureinformation.
Therefore, we propose a method forpredicting the semantic types of unknown words,and use an affix database to train a morph-structure classifier to derive the morphologicalstructure of verbs.Morph-Structure Predication of Verbs: Weuse data analyzed by Chiu et al.
(2004) to devel-op a classifier for predicating the morphologicalstructure of verbs.
There are four types of mor-phological structures for verbs: the coordinatingstructure (VV), the modifier-head structure (AV),the verb-complement structure (VR), and theverb-object structure (VO).
To classify verbsautomatically, we incorporate three features inthe proposed classifier, namely, the lexeme itself,the prefix and the suffix, and the semantic typesof the prefix and the suffix.
Then, we use train-ing data from the affix database to train the clas-sifier.
Table 3 shows an example of the unknownverb ????
/disseminate?
and the morph-structure classifier shows that it is a ?VR?
type.Feature Feature DescriptionWord=???
LexiconPW=??
Prefix wordPWST={disseminate|??}
Semantic Type ofPrefix Word ??SW=?
Suffix WordSWST={Vachieve|??}
Semantic Type ofSuffix Word ?Table 3.
An example of an unknown verb andfeature templates for morph-structure predication931Semantic Type Provider: The system ex-ploits WORD, PoS, affix and E-HowNet infor-mation to obtain the semantic types of words (seeFigure 2).
If a word is known and its PoS is giv-en, we can usually find its semantic type bysearching the E-HowNet database.
For an un-known word, the semantic type of its head mor-pheme is its semantic type; and the semantic typeof the head morpheme is obtained from E-HowNet1.
For example, the unknown word ????
/disseminate?, its prefix word is ???/disseminate?
and we learn that its semantic typeis {disseminate|??}
from E-HowNet.
There-fore, we assign {disseminate|??}
as the se-mantic type of ????
/disseminate?.
If theword or head morpheme does not exist in theaffix database, we assign a general semantic typebased on its PoS, e.g., nouns are {thing|??
}and verbs are {act|??}.
In this matching pro-cedure, we may encounter multiple matchingdata of words and affixes.
Our strategy is to keepthe ambiguous semantic type for future pro-cessing.Input: WORD, PoSOutput: Semantic Type (ST)procedure STP(WORD, PoS)(* Initial Step *)ST := null;(* Step 1: Known word *)if WORD already in E-HowNet thenST := EHowNet(WORD, PoS);else if WORD in Affix database thenST := EHowNet(affix of WORD, PoS);(* Step 2 : Unknown word *)if ST is null and PoS is ?Vt?
thenST := EHowNet(prefix of WORD, PoS);else if ST is null and PoS is ?N?
thenST := EHowNet(suffix of WORD, PoS);(* Step 3 : default *)if ST is null and PoS is ?Vt?
thenST := ?act|???
;else if ST is null and PoS is ?N?
thenST := ?thing|???
(* Finally *)STP := ST;end;Figure 2.
The Pseudo-code of the Semantic TypePredication Algorithm.1 The E-HowNet function in Figure 2 will return a null STvalue where words do not exist in E-HowNet or Affix data-base.3.3 Learning World KnowledgeBased on the features discussed in the previoussub-section, we extract prior knowledge fromTreebank to design the Vt-N classifier.
However,the training suffers from the data sparsenessproblem.
Furthermore most ambiguous Vt-Nrelations are resolved by common senseknowledge that makes it even harder to constructa well-trained system.
An alternative way to ex-tend world knowledge is to learn from large-scale unlabeled data (Wu, 2003; Chen et al.,2008; Yu et al., 2008).
However, the unsuper-vised approach accumulates errors caused byautomatic annotation processes, such as wordsegmentation, PoS tagging, syntactic parsing,and semantic role assignment.
Therefore, how toextract useful knowledge accurately is an im-portant issue.To resolve the error accumulation problem, wepropose two methods: unsupervised NP selectionand supervised error correction.
The NP selec-tion method exploits the fact that an intransitiveverb followed by a noun can only be interpretedas an NP structure, not a VP structure.
It is easyto find such instances with high precision byparsing a large corpus.
Based on the selectionmethod, we can extend contextual knowledgeabout NP(V+N) and extract nouns that take ad-jectival verbs as modifiers.
The error correctionmethod involves a small amount of manual edit-ing in order to make the data more useful andreduce the number of errors in auto-extractedknowledge.
The rationale is that, in general, highfrequency Vt-N word-bigram is either VP or NPwithout ambiguity.
Therefore, to obtain moreaccurate training data, we simply classify eachhigh frequency Vt-N word bigram into a uniquecorrect type without checking all of its instances.We provide more detailed information about themethod in Section 4.3.4 Experiments and Results4.1 Experimental SettingWe classify Vt-N structures into four types ofsyntactic structures by using the bracketed in-formation (tree structure) and dependency rela-tion (head-modifier) to extract the Vt-N relationsfrom treebank automatically.
The resources usedin the experiments as follows.Treebank: The Sinica Treebank contains61,087 syntactic tree structures with 361,834words.
We extracted 9,017 instances of Vt-Nstructures from the corpus.
Then, we randomly932selected 1,000 of the instances as test data andused the remainder (8,017 instances) as trainingdata.
Labeled information of word segmentationand PoS-tagging were retained and utilized in theexperiments.E-HowNet: E-HowNet contains 99,525 lexi-cal semantic definitions that provide informationabout the semantic type of words.
We also im-plement the semantic type predication algorithmin Figure 2 to generate the semantic types of allVt and N words, including unknown words.Affix Data: The database includes 13,287 ex-amples of verbs and 27,267 examples of nouns,each example relates to an affix.
The detailedstatistics of the verb morph-structure categoriza-tion are shown in Table 4.
The data is used totrain a classifier to predicate the morph-structureof verbs.
We found that verbs with a conjunctivestructure (VV) are more likely to play adjectivalroles than the other three types of verbs.
Theclassifier achieved 87.88% accuracy on 10-foldcross validation of the above 13,287 verbs.VV VR AV VOPrefix 920 2,892 904 662Suffix 439 7,388 51 31Table 4.
The statistics of verb morph-structurecategorizationLarge Corpus: We used a Chinese parser toanalyze sentence structures automatically.
Theauto-parsed tree structures are used in Experi-ment 2 (described in the Sub-section 4.3).
Weobtained 1,262,420 parsed sentences and derived237,843 instances of Vt-N structure as our da-taset (called as ASBC).4.2 Experiment 1: Evaluation of the Vt-NClassifierIn this experiment, we used the Maximum En-tropy Toolkit (Zhang, 2004) to develop the Vt-Nclassifier.
Based on the features discussed in Sec-tion 3.1, we designed five models to evaluate theclassifier?s performance on different featurecombinations.The features and used in each model are de-scribed below.
The feature values shown inbrackets refer to the example in Figure 1.?
M1 is the baseline model.
It uses PoS-tagpairs as features, such as (t1=VC, t2=Na).?
M2 extends the M1 model by adding con-text features of (t-1=VK, t1=VC), (t2=Na,t3=DE), (t-2=Nep, t-1=VK, t1=VC), (t2=Na,t3=DE, t4=Na) and (t-1=VK, t3=DE).?
M3 extends the M2 model by adding lexi-con features of (w1=?
?, t1=VK, w2=?
?, t2=Na), (w1??
?, w2=??
), (w1=??)
and (w2=??).?
M4 extends the M3 model by adding se-mantic features of (st1=study|?
?, t1=VK ,st2=language|??
, t2=Na), (st1=study|??
, t1=VK) and (st2=language| ?
?
,t2=Na).?
M5 extends the M4 model by adding twofeatures: the morph-structure of verbs; andthe syllabic length of nouns(Vmorph=?VV?)
and (Nlen=2).Table 5 shows the results of using differentfeature combinations in the models.
The symbolP1(%) is the 10-fold cross validation accuracy ofthe training data, and the symbol P2(%) is theaccuracy of the test data.
By adding contextualfeatures, the accuracy rate of M2 increases from59.10% to 72.30%.
The result shows that contex-tual information is the most important featureused to disambiguate VP, NP and independentstructures.
The accuracy of M2 is approximatelythe same as the result of our PCFG parser be-cause both systems use contextual information.By adding lexical features (M3), the accuracyrate increases from 72.30% to 80.20%.
For se-mantic type features (M4), the accuracy rate in-creases from 80.20% to 81.90%.
The 1.7% in-crease in the accuracy rate indicates that seman-tic generalization is useful.
Finally, in M5, theaccuracy rate increases from 81.90% to 83.00%.The improvement demonstrates the benefits ofusing the verb morph-structure and noun lengthfeatures.Models Feature for Vt-N P1(%) P2(%)M1 (t1,t2) 61.94 59.10M2 + (t-1,t1) (t2,t3) (t-2,t-1,t1) (t2,t3,t4) (t-1,t3)76.59 72.30M3 + (w1,t1,w2,t2) (w1,w2)(w2) (w1)83.55 80.20M4 + (st1,t1,st2,t2) (st1,t1)(st2, t2)84.63 81.90M5 + (Vmorph) (Nlen) 85.01 83.00Table 5.
The results of using different featurecombinations933Next, we consider the influence of unknownwords on the Vt-N classifier.
The statistics showsthat 17% of the words in Treebank lack semantictype information, e.g., ?
?/StayIn, ?
?/fill, ?
?/posted, and ??/tied.
The accuracy of theVt-N classifier declines by 0.7% without seman-tic type information for unknown words.
In otherwords, lexical semantic information improves theaccuracy of the Vt-N classifier.
Regarding theproblem of unknown morph-structure of words,we observe that over 85% of verbs with morethan 2 characters are not found in the affix data-base.
If we exclude unknown words, the accura-cy of the Vt-N prediction decreases by 1%.Therefore, morph-structure information has apositive effect on the classifier.4.3 Experiment 2: Using Knowledge Ob-tained from Large-scale Unlabeled Databy the Selection and Correction Meth-ods.In this experiment, we evaluated the twomethods discussed in Section 3, i.e., unsuper-vised NP selection and supervised error correc-tion.
We applied the data selection method (i.e.,distance=1, with an intransitive verb (Vi) fol-lowed by an object noun (Na)) to select 46,258instances from the ASBC corpus and compile adataset called Treebank+ASBC-Vi-N. Table 6shows the performance of model 5 (M5) on thetraining data derived from Treebank and Tree-bank+ASBC-Vi-N.
The results demonstrate thatlearning more nouns that accept verbal modifiersimproves the accuracy.Treebank+ASBC-Vi-NTreebanksize of traininginstances46,258 8,017M5 - P2(%) 83.90 83.00Table 6.
Experiment results on the test data forvarious knowledge sourcesWe had also try to use the auto-parsed resultsof the Vt-N structures from the ASBC corpus assupplementary training data for train M5.
It de-grades the model?s performance by too mucherror when using the supplementary training data.To resolve the problem, we utilize the supervisederror correction method, which manually correcterrors rapidly because high frequency instances(w1, w2) rarely have ambiguous classifications indifferent contexts.
So we designed an editing toolto correct errors made by the parser in the classi-fication of high frequency Vt-N word pairs.
Afterthe manual correction operation, which takes 40man-hours, we assign the correct classifications(w1, t1, w2, t2, rt) for 2,674 Vt-N structure typeswhich contains 10,263 instances to creates theASBC+Correction dataset.
Adding the correcteddata to the original training data increases theprecision rate to 88.40% and reduces the numberof errors by approximately 31.76%, as shown inthe Treebank+ASBC+Correction column of Ta-ble 7.Treebank+ASBC+CorrectionTreebank+ASBC-Vi-NTreebanksize of train-ing instances56,521 46,258 8,017M5 - P2(%) 88.40 83.90 83.00Table 7.
Experiment results of classifiers withdifferent training dataWe also used the precision and recall rates toevaluate the performance of the models on eachtype of relation.
The results are shown in Table 8.Overall, the Treebank+ASBC+Correction meth-od achieves the best performance in terms of theprecision rate.
The results for Treebank+ASBC-Vi-N show that the unsupervised data selectionmethod can find some knowledge to help identi-fy NP structures.
In addition, the proposed mod-els achieve better precision rates than the PCFGparser.
The results demonstrate that using ourguidelines to design a disambiguation model toresolve the Vt-N problem is successful.H/X X/H X/XTreebankR(%) 91.11 67.90 74.62P(%) 84.43 78.57 81.86Treebank+ASBC-Vi-NR(%) 91.00 72.22 71.54P(%) 84.57 72.67 85.71Treebank+ASBC+CorrectionR(%) 98.62 60.49 83.08P(%) 86.63 88.29 93.51PCFGR(%) 90.54 23.63 80.21P(%) 78.24 73.58 75.00Table 8.
Performance comparison of differentclassification models.4.4 Experiment 3: Integrating the Vt-Nclassifier with the PCFG ParserIdentifying Vt-N structures correctly facilitatesstatistical parsing, machine translation, infor-934mation retrieval, and text classification.
In thisexperiment, we develop a baseline PCFG parserbased on feature-based grammar representationby Hsieh et al.
(2012) to find the best tree struc-tures (T) of a given sentence (S).
The parser thenselects the best tree according to the evaluationscore Score(T,S) of all possible trees.
If there aren PCFG rules in the tree T, the Score(T,S) is theaccumulation of the logarithmic probabilities ofthe i-th grammar rule (RPi).
Formula 1 shows thebaseline PCFG parser.
?==niiRPSTScore1)(),(  (1)The Vt-N models can be easily integrated intothe PCFG parser.
Formula 2 represents the inte-grated structural evaluation model.
We combineRPi and VtNPi with the weights w1 and w2 re-spectively, and set the value of w2 higher thanthat of w1.
VtNPi is the probability produced bythe Vt-N classifier for the type of the relationbetween Vt-N bigram determined by the PCFGparsing.
The classifier is triggered when a [Vt, N]structure is encountered; otherwise, the Vt-Nmodel is not processed.
?=?+?=niii VtNPwRPwSTScore121 )(),(  (2)The results of evaluating the parsing model in-corporated with the Vt-N classifier (see Formula2) are shown in Table 9 and Table 10.
The P2 isthe accuracy of Vt-N classification on the testdata.
The bracketed f-score (BF2) is the parsingperformance metric.
Based on these results, theintegrated model outperforms the PCFG parser interms of Vt-N classification.
Because the Vt-Nclassifier only considers sentences that containVt-N structures, it does not affect the parsingaccuracies of other sentences.PCFG +M5 (Treebank) PCFGP2(%) 80.68 77.09BF(%) 83.64 82.80Table 9.
The performance of the PCFG parserwith and without model M5 from Treebank.2 The evaluation formula is (BP*BR*2) / (BP+BR), whereBP is the precision and BR is the recall.PCFG +M5 (Treebank+ASBC+Correction) PCFGP2(%) 87.88 77.09BF(%) 84.68 82.80Table 10.
The performance of the PCFG parserwith and without model M5 from Tree-bank+ASBC+Correction data set.4.5 Experiment 4: Comparison of VariousChinese ParsersIn this experiment, we give some comparisonresults in various parser: ?PCFG Parser?
(base-line), ?CDM Parser?
(Hsieh et al., 2012), and?Berkeley Parser?
(Petrov et al., 2006).
The CDMparser achieves the best score in Traditional Chi-nese Parsing task of SIGHAN Bake-offs 2012(Tseng et al., 2012).
Petrov?s parser (as Berkeley,version is 2009 1.1) is the best PCFG parser fornon-English language and it is an open source.
Inour comparison, we use the same training datafor training models and parse the same test da-taset based on the gold standard word segmenta-tion and PoS tags.
We have already discussed thePCFG parser in Section 4.4.
As for CDM parser,we retrain relevant model in our experiments.And since Berkeley parser take different treestructure (Penn Treebank format), we transformthe experimental data to Berkeley CoNLL formatand re-train a new model with parameters ?-treebank CHINESE -SMcycles 4?
3 from trainingdata.
Moreover we use ?-useGoldPOS?
parame-ters to parse test data and further transform themto Sinica Treebank style from the Berkeley par-ser?s results.
The different tree structure formatsof Sinica Treebank and Penn Treebank are asfollow:Sinica Treebank:S(NP(Head:Nh:??)|Head:VC:??|NP(Head:Na:??
))Penn Treebank:( (S (NP (Head:Nh (Nh ??)))
(Head:VC(VC ??))
(NP (Head:Na (Na ??
)))))The evaluation results on the testing data, i.e.in P2 metric, are as follows.
The accuracy ofPCFG parser is 77.09%; CDM parser reaches78.45% of accuracy; and Berkeley parser is70.68%.
The results show that the problem of Vt-3 The ?-treebank CHINESE -SMcycles 4?
is the best train-ing parameter in Traditional Chinese Parsing task ofSIGHAN Bake-offs 2012.935N cannot be well solved by any general parserincluding CDM parser and Berkeley?s parser.
Itis necessary to have a different approach asidefrom the general model.
So we set the target for abetter model for Vt-N classification which can beeasily integrated into the existing parsing model.So far our best model achieved the P2 accuracyof 87.88%.5 Concluding RemarksWe have proposed a classifier to resolve the am-biguity of Vt-N structures.
The design of theclassifier is based on three important guidelines,namely, adopting linguistically motivated fea-tures, using all available resources, and easy in-tegration into parsing model.
After analyzing theVt-N structures, we identify linguistically moti-vated features, such as lexical words, semanticknowledge, the morphological structure of verbs,neighboring parts-of-speech, and the syllabiclength of words.
Then, we design a classifier toverify the usefulness of each feature.
We alsoresolve the technical problems that affect theprediction of the semantic types and morph-structures of unknown words.
In addition, wepropose a framework for unsupervised data se-lection and supervised error correction for learn-ing more useful knowledge.
Our experiment re-sults show that the proposed Vt-N classifier sig-nificantly outperforms the PCFG Chinese parserin terms of Vt-N structure identification.
Moreo-ver, integrating the Vt-N classifier with a parsingmodel improves the overall parsing performancewithout side effects.In our future research, we will exploit the pro-posed framework to resolve other parsing diffi-culties in Chinese, e.g., N-N combination.
Wewill also extend the Semantic Type PredicationAlgorithm (Figure 2) to deal with all Chinesewords.
Finally, for real world knowledge learn-ing, we will continue to learn more usefulknowledge by auto-parsing to improve the pars-ing performance.AcknowledgmentsWe thank the anonymous reviewers for their val-uable comments.
This work was supported byNational Science Council under Grant NSC99-2221-E-001-014-MY3.ReferenceLi-li Chang, Keh-Jiann Chen, and Chu-Ren Huang.2000.
Alternation Across Semantic Fields: A Studyon Mandarin Verbs of Emotion.
Internal Journal ofComputational Linguistics and Chinese LanguageProcessing (IJCLCLP), 5(1):61-80.Keh-Jiann Chen, Chu-Ren Huang, Chi-Ching Luo,Feng-Yi Chen, Ming-Chung Chang, Chao-JanChen, , and Zhao-Ming Gao.
2003.
Sinica Tree-bank: Design Criteria, Representational Issues andImplementation.
In (Abeille 2003) Treebanks:Building and Using Parsed Corpora, pages 231-248.
Dordrecht, the Netherlands: Kluwer.Li-jiang Chen.
2008.
Autolabeling of VN Combina-tion Based on Multi-classifier.
Journal of Comput-er Engineering, 34(5):79-81.Wenliang Chen, Daisuke Kawahara, KiyotakaUchimoto, Yujjie Zhang, and Hitoshi Isahara.
2008.Dependency Parsig with Short Dependency Rela-tions in Unlabeled Data.
In Proceedings of thethird International Joint Conference on NaturalLanguage Processing (IJCNLP).
pages 88-94..Chih-ming Chiu, Ji-Chin Lo, and Keh-Jiann Chen.2004.
Compositional Semantics of Mandarin AffixVerbs.
In Proceedings of the Research on Compu-tational Linguistics Conference (ROCLING), pages131-139.Yu-Ming Hsieh, Ming-Hong Bai, Jason S. Chang, andKeh-Jiann Chen.
2012.
Improving PCFG ChineseParsing with Context-Dependent Probability Re-estimation, In Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese LanguageProcessing, pages 216?221.Shu-Ling Huang, You-Shan Chung, Keh-Jiann Chen.2008.
E-HowNet: the Expansion of HowNet.
InProceedings of the First National HowNet work-shop, pages 10-22, Beijing, China.Chunhi Liu, Xiandai Hanyu Shuxing Fanchou Yianjiu(??????????).
Chengdu: Bashu Books,2008.Jiaju Mei, Yiming Lan, Yunqi Gao, and YongxianYing.
1983.
A Dictionary of Synonyms.
ShanghaiCishu Chubanshe.Slav Petrov, Leon Barrett, Romain Thibaux and DanKlein.
2006.
Learning Accurate, Compact, and In-terpretable Tree Annotation.
In Proceesings ofCOLING/ACL, pages 433-400.Likun Qiu.
2005.
Constitutive Relation Analysis forV-N Phrases.
Journal of Chinese Language andComputing, 15(3):173-183.Richard Sproat and Thomas Emerson, 2003.
The firstInternational Chinese Word Segmentation Bakeoff.In Proceedings of the Second SIGHAN Workshopon Chinese Language Processing, pages 133-143.Honglin Sun and Dan Jurafsky.
2003.
The Effect ofRhythm on Structural Disambiguation in Chinese.In Proceedings of the Second SIGHAN Workshopon Chinese Language Processing, pages 39-46.936Yuen-Hsieh Tseng, Lung-Hao Lee, and Liang-ChihYu.
2012.
Tranditional Chinese Parsing Evaluationat SIGHAN Bake-offs 2012.
In Proceedings of theSecond CIPS-SIGHAN Joint Conference on Chi-nese Language Processing, pages 199-205.Andi Wu.
2003.
Learning Verb-Noun Relations toImprove Parsing.
In Proceedings of the SecondSIGHAN workshop on Chinese Language Pro-cessing, pages 119-124.Kun Yu, Daisuke Kawahara, and Sadao Kurohashi.2008.
Chinese Dependency Parsing with LargeScale Automatically Constructed Case Structures,In Proceedings of the 22nd International Confer-ence on Computational Linguistics (COLING2008),pages 1049-1056.Jun Zhao and Chang-ning Huang.
1999.
The Com-plex-feature-based Model for Acquisition of VN-construction Structure Templates.
Journal of Soft-ware, 10(1):92-99.Le Zhang.
2004.
Maximum Entropy ModelingToolkit for Python and C++.
Reference Manual.937
