Proceedings of the ACL 2010 Conference Short Papers, pages 331?335,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsLast but Definitely not Least:On the Role of the Last Sentence in Automatic Polarity-ClassificationIsraela Becker and Vered AharonsonAFEKA ?
Tel-Aviv Academic College of Engineering218 Bney-Efraim Rd.Tel-Aviv 69107, Israel{IsraelaB,Vered}@afeka.ac.ilAbstractTwo psycholinguistic and psychophysical ex-periments show that in order to efficiently ex-tract polarity of written texts such as customer-reviews on the Internet, one should concentratecomputational efforts on messages in the finalposition of the text.1 IntroductionThe ever-growing field of polarity-classificationof written texts may benefit greatly from lin-guistic insights and tools that will allow to effi-ciently (and thus economically) extract the po-larity of written texts, in particular, online cus-tomer reviews.Many researchers interpret ?efficiently?
as us-ing better computational methods to resolve thepolarity of written texts.
We suggest that textunits should be handled with tools of discourselinguistics too in order to reveal where, withintexts, their polarity is best manifested.
Specifi-cally, we propose to focus on the last sentenceof the given text in order to efficiently extractthe polarity of the whole text.
This will reducecomputational costs, as well as improve thequality of polarity detection and classificationwhen large databases of text units are involved.This paper aims to provide psycholinguisticsupport to the hypothesis (which psycholinguis-tic literature lacks) that the last sentence of acustomer review is a better predictor for the po-larity of the whole review than other sentencesin the review, in order to be later used for auto-matic polarity-classification.
Therefore, we firstbriefly review the well-established structure oftext units while comparing notions of topic-extraction vs. our notion of polarity-classification.
We then report the psycholinguis-tic experiments that we ran in order to supportour prediction as to the role of the last sentencein polarity manifestation.
Finally, we discussthe experimental results.2 Topic-extractionOne of the basic features required to performautomatic topic-extraction is sentence position.The importance of sentence position for compu-tational purposes was first indicated by Baxen-dale in the late 1950s (Baxendale, 1958): Bax-endale hypothesized that the first and the lastsentence of a given text are the potential topic-containing sentences.
He tested this hypothesison a corpus of 200 paragraphs extracted out of 6technical articles.
He found that in 85% of thedocuments, the first sentence was the topic sen-tence, whereas in only 7% of the documents, itwas the last sentence.
A large scale study sup-porting Baxendale?s hypothesis was conductedby Lin and Hovy (Lin and Hovy, 1997) who ex-amined 13,000 documents of the Ziff-Davisnewswire corpus of articles reviewing computerhardware and software.
In this corpus, eachdocument was accompanied by a set of topickeywords and a small abstract of six sentences.Lin and Hovy measured the yield of each sen-tence against the topic keywords and ranked thesentences by their average yield.
They con-cluded that in ~2/3 of the documents, the topickeywords are indeed mentioned in the title andfirst five sentences of the document.Baxendale?s theory gained further psycholin-guistic support by the experimental results ofKieras (Kieras, 1978, Kieras, 1980) whoshowed that subjects re-constructed the content331of paragraphs they were asked to read by rely-ing on sentences in initial positions.
These find-ing subsequently gained extensive theoreticaland experimental support by Giora (Giora,1983, Giora, 1985) who correlated the positionof a sentence within a text with its degree of in-formativeness.Giora (Giora, 1985, Giora, 1988) defined adiscourse topic (DT) as the least informative(most uninformative) yet dominant propositionof a text.
The DT best represents the redun-dancy structure of the text.
As such, this propo-sition functions as a reference point for process-ing the rest of the propositions.
The text posi-tion which best benefits such processing is textinitial; it facilitates processing of oncomingpropositions (with respect to the DT) relative towhen the DT is placed in text final position.Furthermore, Giora and Lee showed (Gioraand Lee, 1996) that when the DT appears alsoat the end of a text it is somewhat information-ally redundant.
However, functionally, it plays arole in wrapping the text up and marking itsboundary.
Authors often make reference to theDT at the end of a text in order to summarizeand deliberately recapitulate what has beenwritten up to that point while also signaling theend of discourse topic segment.3 Polarity-classification vs. Topic-extractionWhen dealing with polarity-classification (aswith topic-extraction), one should again identifythe most uninformative yet dominant proposi-tion of the text.
However, given the cognitiveprominence of discourse final position in termsof memorability, known as ?recency effect?
(seebelow and see also (Giora, 1988)), we predictthat when it comes to polarity-classification, thelast proposition of a given text should be ofgreater importance than the first one (contraryto topic-extraction).Based on preliminary investigations, we sug-gest that the DT of any customer review is thecustomer?s evaluation, whether negative orpositive, of a product that s/he has purchased ora service s/he has used, rather than the details ofthe specific product or service.
The messagethat customer reviews try to get across is, there-fore, of evaluative nature.
To best communicatethis affect, the DT should appear at the end ofthe review (instead of the beginning of the re-view) as a means of recapitulating the point ofthe message, thereby guaranteeing that it is fullyunderstood by the readership.Indeed, the cognitive prominence of informa-tion in final position - the recency-effect - hasbeen well established in numerous psychologi-cal experiments (see, for example, (Murdock,1962)).
Thus, the most frequent evaluation ofthe product (which is the most uninformativeone) also should surface at the end of the textdue to the ease of its retrieval, which is pre-sumably what product review readers would re-fer to as ?the bottom line?.To the best of our knowledge, this psycholin-guistic prediction has not been supported by psy-cholinguistic evidence to date.
However, it hasbeen somewhat supported by the computationalresults of Yang, Lin and Chen (Yang et al,2007a, Yang et al, 2007b) who classified emo-tions of posts in blog corpora.
Yang, Lin & Chenrealized that bloggers tend to emphasize theirfeelings by using emoticons (such as: ?,?
and?)
and that these emoticons frequently appear infinal sentences.
Thus, they first focused on thelast sentence of posts as representing the polarityof the entire posts.
Then, they divided the posi-tive category into 2 sub-categories - happy andjoy, and the negative category - into angry andsad.
They showed that extracting polarity andconsequently sentiments from last sentences out-performs all other computational strategies.4 MethodWe aim to show that the last sentence of a cus-tomer review is a better predictor for the polarityof the whole review than any other sentence (as-suming that the first sentence is devoted to pre-senting the product or service).
To test our pre-diction, we ran two experiments and comparedtheir results.
In the first experiment we exam-ined the readers?
rating of the polarity of reviewsin their entirety, while in the second experimentwe examined the readers?
rating of the same re-views based on reading single sentences ex-tracted from these reviews: the last sentence orthe second one.
The second sentence could havebeen replaced by any other sentence, but the firstone, as our preliminary investigations clearlyshow that the first sentence is in many cases de-voted to presenting the product or service dis-cussed and does not contain any polarity con-tent.
For example: "I read Isaac?s storm, by ErikLarson, around 1998.
Recently I had occasion tothumb through it again which has prompted thisreview?..All in all a most interesting and re-warding book, one that I would recommendhighly.?
(Gerald T. Westbrook, ?GTW?
)3324.1     MaterialsSixteen customer-reviews were extracted fromBlitzer, Dredze, and Pereira?s sentiment data-base (Blitzer et al, 2007).
This database con-tains product-reviews taken from Amazon 1where each review is rated by its author on a 1-5 star scale.
The database covers 4 producttypes (domains): Kitchen, Books, DVDs, andElectronics.
Four reviews were selected fromeach domain.
Of the 16 extracted reviews, 8were positive (4-5 star rating) and the other 8 ?negative (1-2 star rating).Given that in this experiment we examine thepolarity of the last sentence relative to that of thewhole review or to a few other sentences, wefocused on the first reviews (as listed in theaforementioned database) of at least 5 sentencesor longer, rather than on too-short reviews.
By?too-short?
we refer to reviews in which suchcomparison would be meaningless; for example,ones that range between 1-3 sentences will notallow to compare the last sentence with any ofthe others.4.2     ParticipantsThirty-five subjects participated in the first ex-periment: 14 women and 21 men, ranging in agefrom 22 to 73.
Thirty-six subjects participated inthe second experiment: 23 women and 13 menranging in age from 20 to 59.
All participantswere native speakers of English, had an aca-demic education, and had normal or corrected-to-normal eye-vision.4.3     ProcedureIn the first experiment, subjects were asked toread 16 reviews; in the second experiment sub-jects were asked to read 32 single sentences ex-tracted from the same 16 reviews: the last sen-tence and the second sentence of each review.The last and the second sentence of each reviewwere not presented together but individually.In both experiments subjects were asked toguess the ratings of the texts which were givenby the authors on a 1-5 star scale, by clicking ona radio-button: ?In each of the following screensyou will be asked to read a customer review (or asentence extracted out of a customer review).
Allthe reviews were extracted from thewww.amazon.com customer review section.Each review (or sentence) describes a differentproduct.
At the end of each review (or sentence)1 http://www.amazon.comyou will be asked to decide whether the reviewerwho wrote the review recommended or did notrecommend the reviewed product on a 1-5 scale:Number 5 indicates that the reviewer highly rec-ommended the product, while number 1 indicatesthat the reviewer was unsatisfied with the prod-uct and did not recommend it.
?In the second experiment, in addition to thepsychological experiment, the latencies follow-ing reading of the texts up until the clicking ofthe mouse, as well as the biometric measure-ments of the mouse?s trajectories, were recorded.In both experiments each subject was run in anindividual session and had an unlimited time toreflect and decide on the polarity of each text.Five seconds after a decision was made (as towhether the reviewer was in favor of the productor not), the subject was presented with the nexttext.
The texts were presented in random order soas to prevent possible interactions between them.In the initial design phase of the experimentwe discussed the idea of adding an ?irrelevant?option in addition to the 5-star scale of polarity.This option was meant to be used for sentencesthat carry no evaluation at all.
Such an additionwould have necessitated locating the extra-choice radio button at a separated remote placefrom the 5-star scale radio buttons, since concep-tually it cannot be located on a nearby position.From the user interaction point of view, themouse movement to that location would havebeen either considerably shorter or longer (de-pending on its distance from the initial locationof the mouse curser at the beginning of eachtrial), and the mouse trajectory and click timewould have been, thus, very different and diffi-cult to analyze.Although the reviews were randomly selected,32 sentences extracted out of 16 reviews mightseem like a small sample.
However, the uppertime limit for reliable psycholinguistic experi-ments is 20-25 minute.
Although tempted to ex-tend the experiments in order to acquire moredata, longer times result in subject impatience,which shows on lower scoring rates.
Therefore,we chose to trade sample size for accuracy.
Ex-perimental times in both experiments ranged be-tween 15-35 minutes.5   ResultsResults of the distribution of differences be-tween the authors?
and the readers?
ratings ofthe texts are presented in Figure 1: The distribu-tion of differences for whole reviews is (un-surprisingly) the narrowest (Figure 1a).
The dis-333tribution of differences for last sentences (Fig-ure 1b) is somewhat wider than (but still quitesimilar to) the distribution of differences forwhole reviews.
The distribution of differencesfor second sentences is the widest of the three(Figure 1c).Pearson correlation coefficient calculations(Table 1) show that both the correlation be-tween authors?
ratings and readers?
rating forwhole reviews and the correlation between au-thors?
rating and readers?
rating upon readingthe last sentence are similar, while the correla-tion between authors?
rating and readers ?
ratingwhen presented with the second sentence ofeach review is significantly lower.
Moreover,when correlating readers?
rating of whole re-views with readers?
rating of single sentences,the correlation coefficient for last sentences issignificantly higher than for second sentences.As for the biometric measurements per-formed in the second experiment, since all sub-jects were computer-skilled, hesitation revealedthrough mouse-movements was assumed to beattributed to difficulty of decision-making ratherthan to problems in operating the mouse.
Aspreviously stated, we recorded mouse latencytimes following the reading of the texts up untilclicking the mouse.
Mouse latency times werenot normalized for each subject due to the lim-ited number of results.
However, the averagelatency time is shorter for last sentences(19.61?12.23s) than for second sentences(22.06?14.39s).
Indeed, the difference betweenlatency times is not significant, as a paired t-testcould not reject the null hypothesis that thosedistributions have equal means, but might showsome tendency.We also used the WizWhy software (Meidan,2005) to perform combined analyses of readers?rating and response times.
The analyses showedthat when the difference between authors?
andreaders?
ratings was ?
?1?and the response timemuch shorter than average (<14.1 sec), then96% of the sentences were last sentences.
Dueto the small sample size, we cautiously inferthat last sentences express polarity better thansecond sentences, bearing in mind that the sec-ond sentence in our experiment represents anyother sentence in the text except for the firstone.We also predicted that hesitation in making adecision would effect not only latency times butalso mouse trajectories.
Namely, hesitation willbe accompanied by moving the mouse here andthere, while decisiveness will show a firmmovement.
However, no such difference be-tween the responses to last sentences or to sec-ond sentences appeared in our analysis; mostsubjects laid their hand still while reading thetexts and while reflecting upon their answers.They moved the mouse only to rate the texts.6 Conclusions and Future WorkIn 2 psycholinguistic and psychophysical ex-periments, we showed that rating whole cus-tomer-reviews as compared to rating final sen-tences of these reviews showed an (expected)insignificant difference.
In contrast, rating wholecustomer-reviews as compared to rating secondsentences of these reviews, showed a consider-able difference.
Thus, instead of focusing onwhole texts, computational linguists should focuson the last sentences for efficient and accurateautomatic polarity-classification.
Indeed, last butdefinitely not least!We are currently running experiments that-5 -4 -3 -2 -1 0 1 2 3 4 5Counts050100150200250300350Rating Difference (Authors' rating - Readers' rating)-5 -4 -3 -2 -1 0 1 2 3 4 5 -5 -4 -3 -2 -1 0 1 2 3 4 5050100150200250300350a b cFigure 1.
Histograms of the rating differences between the authors of reviews and theirreaders: for whole reviews (a), for last sentence only (b), and  for second sentence only (c).334include hundreds of subjects in order to draw aprofile of polarity evolvement throughout cus-tomer reviews.
Specifically, we present our sub-jects with sentences in various locations in cus-tomer reviews asking them to rate them.
As theexpanded experiment is not psychophysical, weadded an additional remote radio button named?irrelevant?
where subjects can judge a giventext as lacking any evident polarity.
Based on therating results we will draw polarity profiles inorder to see where, within customer reviews, po-larity is best manifested and whether there areother ?candidates?
sentences that would serve asuseful polarity indicators.
The profiles will beused as a feature in our computational analysis.AcknowledgmentsWe thank Prof. Rachel Giora and Prof. Ido Da-gan for most valuable discussions, the 2 anony-mous reviewers ?
for their excellent suggestions,and Thea Pagelson and Jason S. Henry - for theirhelp with programming and running the psycho-physical experiment.ReferencesBaxendale, P. B.
1958.
Machine-Made Index forTechnical Literature - An Experiment.
IBM jour-nal of research development 2:263-311.Blitzer, John, Dredze, Mark, and Pereira, Fernando.2007.
Biographies, Bollywood, Boom-boxes andBlenders: Domain Adaptation for SentimentClassification.
Paper presented at Association ofComputational Linguistics (ACL).Giora, Rachel.
1983.
Segmentation and Segment Co-hesion: On the Thematic Organization of theText.
Text 3:155-182.Giora, Rachel.
1985.
A Text-based Analysis of Non-narrative Texts.
Theoretical Linguistics 12:115-135.Giora, Rachel.
1988.
On the Informativeness Re-quirement.
Journal of Pragmatics 12:547-565.Giora, Rachel, and Lee, Cher-Leng.
1996.
WrittenDiscourse Segmentation: The Function of Un-stressed Pronouns in Mandarin Chinese.
In Refer-ence and Reference Accessibility ed.
J. Gundeland T. Fretheim, 113-140.
Amsterdam: Benja-mins.Kieras, David E. 1978.
Good and Bad Structure inSimple Paragraphs: Effects on Apparent Theme,Reading Time, and Recall.
Journal of VerbalLearning and Verbal Behavior 17:13-28.Kieras, David E. 1980.
Initial Mention as a Cue to theMain Idea and the Main Item of a Technical Pas-sage.
Memory and Cognition 8:345-353.Lin, Chen-Yew, and Hovy, Edward.
1997.
IdentifyingTopic by Position.
Paper presented at Proceedingof the Fifth Conference on Applied Natural Lan-guage Processing, San Francisco.Meidan, Abraham.
2005.
Wizsoft's WizWhy.
In TheData Mining and Knowledge Discovery Hand-book, eds.
Oded Maimon and Lior  Rokach,1365-1369: Springer.Murdock, B.
B. Jr. 1962.
The Serial Position Effect ofFree Recall.
Journal of Experimental Psychology62:618-625.Yang, Changua, Lin, Kevin Hsin-Yih, and Chen,Hsin-Hsi.
2007a.
Emotion Classification UsingWeb Blog Corpora.
In IEEE/WIC/ACM/ Interna-tional Conference on Web Intelligence.
SiliconValley, San Francisco.Yang, Changua, Lin, Kevin Hsin-Yih, and Chen,Hsin-Hsin.
2007b.
Building Emotion Lexiconfrom Weblog Corpora.
Paper presented at Pro-ceeding of the ACL 2007 Demo and Poster Ses-sion, Prague.Readers?
star rating of: Correlated with: Pearson Correlation Coefficient (P<0.0001)Whole reviews 0.7891Last sentences 0.7616Second sentencesAuthors?
star ratingof whole reviews0.4705Last sentences 0.8463Second sentencesReaders?
star ratingof whole reviews 0.6563Table 1.
Pearson Correlation Coefficients335
