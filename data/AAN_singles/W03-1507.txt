Multilingual Resources for Entity ExtractionStephanie StrasselLinguistic Data Consortium3600 Market St., Ste 810Philadelphia, PA 19104strassel@ldc.upenn.eduAlexis MitchellLinguistic Data Consortium3600 Market St., Ste 810Philadelphia, PA 19104amitche0@ldc.upenn.eduShudong HuangLinguistic Data Consortium3600 Market St., Ste 810Philadelphia, PA 19104shudong@ldc.upenn.eduAbstractProgress in human language technologyrequires increasing amounts of data andannotation in a growing variety of lan-guages.
Research in Named Entity ex-traction is no exception.
Linguistic DataConsortium is creating annotated corporato support information extraction in Eng-lish, Chinese, Arabic, and other languagesfor a variety of US Government-sponsored programs.
This paper coversthe scope of annotation and research taskswithin these programs, describes some ofthe challenges of multilingual corpus de-velopment for entity extraction, and con-cludes with a description of the corporadeveloped to support this research.1research, technology development and educationIntroductionOngoing research in human language technol-ogy (HLT) requires vast amounts of data for sys-tem training and development, plus stablebenchmark data to measure ongoing progress.
Re-searchers require greater and greater volumes ofdata, representing a broadening inventory of hu-man languages and ever more sophisticatedannotation.
This presents a substantial challenge tothe HLT community because human annotationand corpus creation is quite costly.
Newapproaches to research require not tens buthundreds and thousands of hours of speech data,and millions of words of text.
The availability ofhigh quality language resources remains a centralissue for the many communities involved in basictechnology development and education related tolanguage.
The role of international data centerscontinues to evolve to accommodate emergingneeds in the speech and language technologycommunity (Liberman and Cieri 2002).The Linguistic Data Consortium (LDC) wasfounded in 1992 at the University of Pennsylvania,with seed money from DARPA, specifically toaddress the need for shared language resources.Since then, LDC has created and published morethan 241 linguistic databases and has accumulatedconsiderable experience and skill in managinglarge-scale, multilingual data collection and anno-tation projects.
LDC has established itself as acenter for research into standards and best prac-tices in linguistic resource development, while par-ticipating actively in ongoing HLT research.LDC has had a major role in creating annotatedcorpora and other resources to support named en-tity extraction, as well as larger information extrac-tion activities, for a number of years.
Currentwork in this area falls under a handful of researchprograms.
The DARPA Program in TranslingualInformation Detection, Extraction, and Summari-zation (TIDES 2002) combines technologies indetection, extraction, summarization and transla-tion to create systems capable of searching a widerange of streaming multilingual text and speechsources, in real time, to provide effective access forEnglish-speaking users.
TIDES core languages areEnglish, Mandarin and Arabic; second tier lan-guages are Korean, Spanish, and Japanese.
Theprimary medium is text though this includesspeech recognition output.
The TIDES researchtasks require broadcast transcripts and news textsto be annotated for entities, relations, and events;categorized by topic; translated; summarized; andprocessed in a variety of other ways.Another of the TIDES Program goals is to pro-duce technology that can be easily ported to handlenew natural languages.
To this end, the TIDESSurprise Language Exercise (LDC 2003b) chal-lenges researchers to produce working systems fora previously untargeted language within a con-strained time span (for instance, a single calendarmonth).Currently operating under the TIDES umbrella,the Automatic Content Extraction program (NIST2002) builds on the successes of previous extrac-tion research programs.
The objective of the ACEProgram is to develop extraction technology tosupport automatic processing of source languagedata (in the form of natural text, and as text derivedfrom Optical Character Recognition and AutomaticSpeech Recognition output).
This includes classi-fication, filtering, and selection based on the lan-guage content of the source data, i.e., the meaningconveyed by the data.
Thus the ACE program re-quires the development of technologies that auto-matically detect and characterize this meaning.The ACE research objectives are viewed as thedetection and characterization of Entities, Rela-tions, and Events.
LDC provides data and annota-tions to support these program goals.Another DARPA program, Evidence Extractionand Link Detection (EELD 2002), draws on lin-guistic resources created by LDC to promote itsresearch goals.
The EELD program aims for de-velopment of technologies and tools for automateddiscovery, extraction and linking of sparse evi-dence contained in large amounts of classified andunclassified data sources.
EELD is developingdetection capabilities to extract relevant data andrelationships about people, organizations, and ac-tivities from message traffic and open source data.LDC has provided domain-specific entity-taggedcorpora in support of the EELD technology evalua-tion.2nd Arabic.3 AnnotationFrom MUC to ACEWhile LDC's current resource development ef-forts support ACE and related programs in particu-lar, ACE is hardly the first program to tacklenamed entities and the larger information extrac-tion problem.
The Message Understanding Con-ference Program (MUC) (NIST 1999a) focused onnamed entity extraction, coreference relationsamong noun phrases, the identification of selectedrelations, and events.
High system performancewithin the English newswire domain motivated anexpansion of the named entity task after MUC-7.In 1999, the DARPA Hub-4 NE Project (Chinchoret.
al.
1999) expanded the domain of source data toinclude broadcast news transcripts.LDC joined the group of those developing cor-pora to support named entity research in that sameyear, providing annotations for the TIDES Infor-mation Extraction-Entity Recognition (IE-ER) task(NIST 1999b).
In the following year, LDC beganto develop corpora and other resources to supportthe ACE program.ACE is substantially similar in scope to theseearlier extraction programs, though slightly differ-ent in focus.
ACE adds new varieties of annotateddata to the information extraction domain.Annotators tag newswire, broadcast newstranscripts and newspaper data.
Additionally, re-search sites are evaluated on their performance ondegraded ASR and OCR output.
Under the TIDESumbrella, the ACE program supports the multilin-gual resource and system development, focusingcurrently on Chinese aACE also modifies the inventory of entity typestargeted by the MUC tasks (Chinchor et.
al.
1997).While MUC considered three entity types (person,organization, location), ACE further divides loca-tions into geo-political entities and facilities, whilethe newest phase also adds weapons, substances,and vehicles (similar to the MUC artifact cate-gory).
Coreference is preserved in ACE, whilegeneric entities and metonymy are tackled explic-itly.ACE brings together many of the separate tasksevaluated under different components of the MUCprogram.
All ACE tasks -- entities, relations andevents -- evaluate not only recognition but alsocharacterization of these phenomena.
While theMUC Template Relation and Scenario Templatetasks targeted relations and events plus their attrib-utes, the focus of these tasks was domain specific.ACE tasks, on the other hand, are defined to bemore general and domain-independent.Named entity annotation is a core component ofACE, but the scope of the annotation required bythe program builds substantially on this.3.1 The TaskThere are three main ACE tasks: Entity Detec-tion and Tracking, Relation Detection and Charac-terization, and Event Detection andCharacterization.Entity Detection and Tracking is the most fun-damental of the ACE tasks and was the sole focusof the ACE Pilot effort as well as ACE Phase One.The entity task provides a foundation for the re-maining annotation and research tasks.
ACE anno-tators identify five types of entities (Mitchell et.
al.2002).
The first two types, Person and Organiza-tion, remain substantially similar to their defini-tions under MUC.
Locations within ACE arelimited to geographical entities such as land-masses, bodies of water, and geological forma-tions.
Two new entity types are tagged underACE: Facilities, which include buildings and otherpermanent man-made structures and real estateimprovements; and GPEs, which are geographicalregions defined by political and/or social groups.GPEs are composite in nature, typically having agovernment, a populace, and a geographic loca-tion, as well as some more abstract notion of state-hood.A GPE subsumes and does not distinguish be-tween a nation, its region, its government and itspeople.
However, annotators also assign a role toeach textual reference (mention) of a GPE, indicat-ing which of these aspects is most prominent forthat mention.
In the example below, the two entitymentions refer to the governmental (rather thanpeople or location) aspect of the entities, so in bothcases the mentions would be tagged as GPEs withOrganization roles:{Russia} recently held discussions with {the US}regarding the ongoing crisis.ACE annotators tag all mentions of each entitywithin a document, whether named, nominal orpronominal.
For every mention, the annotatoridentifies the maximal extent of the string thatrepresents the entity.
Nested mentions are alsocaptured.
Each entity is classified according to itstype, and co-reference among mentions is re-corded.
While the ACE Pilot Annotation effort didnot explicitly deal with metonymic entities andgenerics, Phase One of ACE added these elementsto the entity annotation and research tasks.Metonymy occurs when a single string of textmakes reference to multiple entities.
Generally,these distinct entities are related to each other insome way.
For example, in this sentence,{Beijing} will not continue sales of anti-ship mis-siles to {Iran}.Beijing, though literally referring to the name ofthe capital of China, is being used as a reference tothe government of China.
The relationship be-tween "Beijing the city" and "Beijing the seat ofChina's government" triggers this metonymic ref-erence.
When metonymic references occur, ACEannotators create two separate entities, one foreach reference.An entity is generic when it does not refer to aparticular object or set of objects in the world.Generic entities include references to general typesof objects, hypothetical objects and generalizationsacross sets of objects.
Annotators apply the rulesof mention coreference to generic entities, and spe-cifically classify each entity as specific or generic.In future ACE efforts the set of targeted entitieswill expand to include vehicles, weapons, and sub-stances.
Entity subtypes will also be added.The second phase of the ACE program addedrelation detection and characterization to the suiteof annotation and research tasks.
This task targetsfive relation types (Mitchell et.
al.
2002b): Role,Part, Located, Near, and Social.
For example,Role relations link people to organizations andGPEs in employment, affiliate, and citizenshiprelationships.
The Social relation links people inpersonal, familial or professional relationships.Each relation type is further classified according toits subtype.
For instance, the Role relation in-cludes Management, General Staff, Member,Owner, Founder, and Citizen-Of subtypes.For every relation, annotators identify two pri-mary arguments (namely, the two ACE entities thatare linked) as well as the relation's temporal attrib-utes (Sundheim 2001).
Temporal information isdrawn from pre-existing TIMEX2 1  annotation(Ferro et.
al.
2001) wherever those values are ex-plicitly linked to a relation.
LDC annotators alsocreate more general, relative time attributes de-1 TIMEX2 annotation, supported by the ACE program, pro-vides a framework for the normalized representation of tempo-ral expressions.rived from the tense of the verb that heads thepredication of the relation.
Relations that are sup-ported by explicit textual evidence are distin-guished from those that depend on contextualinference on the part of the reader.The following is an example of an explicit rela-tion of type Located:{President Bush} was in {New York} Thurs-day.The textual evidence supports the relation betweenthe entities President Bush and New York, with thetemporal attributes was and Thursday.Future phases of ACE will refine the relationtask to highlight new relations that are of particularinterest to the program, and to allow finer categori-zation of some existing types.ACE Phase Three adds a new challenge: recog-nition and characterization of events.
Definition ofa set of general event types and subtypes is cur-rently underway.
Targeted types include Interac-tion, Movement, Transfer, Creation andDestruction events.
Annotators label event argu-ments (agent, patient and the like) and attributes(temporal, locative) according to a type-specifictemplate.
They further tag the textual mention oranchor for each event and categorize it by type andsubtype.
For example, the sentence below containsreference to an Interaction event.
{Colin Powell} and {Jiang Zemin} held high-leveltalks in {Beijing} last week.Annotators extract the specific text reference to theevent (held high-level talks); identify the meetingparticipants (Colin Powell, Jiang Zemin) as argu-ments of the event; tag the locative (Beijing) andtemporal (held, last week) attributes.The event task will expand in future phases ofACE to include additional event types and sub-types, as well characterization of relations betweenevents.3.2 The ProcessThe large amounts of data, multilingual focusand the number and range of annotation tasks re-quired by the ACE program lends itself to a team-based approach to annotation.
A single projectmanager provides oversight for all LDC ACE ac-tivities.
Language-specific lead annotators workdirectly with teams of part-time (typically student)annotators, providing training, monitoring progressand generally supervising the annotation staff.
Theproject manager works with lead annotators to de-velop and maintain the formal ACE annotationtask definitions and guidelines (LDC 2003a).The complexity of ACE annotation requires an-notators with a solid background in linguistics,particularly syntax and semantics.
New annotatorsfirst become familiar with the basic concepts andterminology and study the annotation guidelinesbefore annotating several sets of training files.Throughout the training process, supervisors pro-vide periodic feedback, comparing the trainee?sannotation to a gold standard, identifying discrep-ancies and refining the annotator?s approach to thedata and understanding of guidelines and rules.Not until an annotator has achieved a certain levelof accuracy and speed is he permitted to tag actualdata.The annotation work environment is designedto encourage regular discussion and "groupthink"among the annotation team.
Problems and ques-tions are logged for future reference, and teamsmeet regularly to discuss outstanding issues.
Aweb-based annotation manual contributes to theteam approach.
This reference complements theformal task definition, documenting decisionsabout how to handle problematic constructions andoutlier examples.
Because its content is developedsolely by ACE annotators, the web guidelines alsofunction as a training tool.
New annotators regu-larly add to the guidelines, focusing on the aspectsof the ACE tasks that are most difficult for them.During production annotation, separate annota-tors conduct at minimum two complete passes overthe data.
First pass annotation creates the initialmarkup, and a second pass reviews the existingannotation for consistency and accuracy.
Secondpassing is typically conducted by more experi-enced senior annotators.
A targeted third pass isperformed to further enhance annotation quality.During the third pass, lead annotators review theannotated data to catch common errors and ensureconsistent treatment of difficult constructions.In addition to multiple passes over all ACEdata, an additional 5% to 10% of the data is com-pletely re-annotated from scratch by separate anno-tators.
Results of this dual annotation are comparedand discrepancies adjudicated in order to establishinter-annotator agreement scores and identify areasof lingering confusion or inconsistency.
Whilerates of inter-annotator agreement for ACE namedentities are comparable to MUC consistency levels,the results for the more complex annotation tasksare considerably lower.
Particular challenges in-clude the coreference of generic entities and theuse of metonymy, GPE roles, and implicit vs. ex-plicit relations.The first two phases of ACE annotation utilizedMITRE's Alembic Workbench (Day 1997), whichwas customized for the ACE tasks.
With the ex-pansion into new languages and the addition ofevents, LDC began development of a locally de-signed, locally supported ACE toolkit.
Utilizingthe Annotation Graphs model (Bird and Liberman2001), the toolkit provides for customized, plat-form-independent, multilingual ACE annotation.At present the toolkit supports entity tagging only;focused relation and event tagging modules areunder development.
The toolkit will also supportcustomized functions for second passing, compari-son and adjudication of dually-annotated files, andadditional quality control features including que-ries of the annotation database.3.3Multilingual ACEIn its first two phases the ACE program has fo-cused primarily on English language data.
UnderTIDES, the program has grown to include new lan-guages.
LDC is supporting this expansion withproduction annotation in Arabic and Chinese, aswell as exploratory work in Farsi.LDC has completed development of entity an-notation guidelines in Chinese and Arabic.
Full-scale Chinese annotation is well underway, whileArabic annotation is just beginning.
To move fromthe basic English tasks into Chinese, Arabic andFarsi, LDC draws on the expertise of fluent bilin-gual linguists and language scholars.
These ex-perts first fully learn the English annotation tasksand complete some training annotation in English.They then apply the English guidelines to texts inthe target language, keeping careful note of anyconstructions that motivate changes or additions tothe guidelines.
After several rounds of test annota-tion in the target language, new guidelines arecrafted in English, but with examples drawn exclu-sively from the target language2.
The new guide-2 This means that annotators for non-English ACE tasks mustbe fluent bilinguals.
Customarily, new annotators start bylines are then extensively tested with pilot annota-tion by multiple annotators in the target language.Further modifications to the guidelines are made asnew patterns in the data are observed.Each time a new language is targeted, lan-guage-specific challenges emerge.
For Chinese,one of the most difficult problems is the lack ofagreed-upon rules for word segmentation.
WhileEnglish is written with white space around eachnew word, "word" is not a fundamental concept inChinese, and characters are written without whitespace.
Because entity annotation requires annota-tors to select both the maximal extent of a mentionas well as the mention's head, it becomes difficultfor annotators to agree on the exact series of char-acters that constitute the head of a mention.
Anno-tation guidelines for Chinese must include rules fordealing with this issue.Chinese also presents difficulties for tagginggeneric entities.
The rules for identifying genericsin English rely in part on tests surrounding the ex-istence of determiners.
However, determiners donot exist in Chinese, and this required the creationof  new annotation guidelines for generics that relysolely on context.
Similarly, Arabic often usesdeterminers in a way that is different from English.For instance, in Arabic it is common to use a con-struction with a determiner when referring to aclass of entities:The horse is a wonderful animal.rather than a bare plural, more common in English:Horses are wonderful animals.The complexity of Arabic morphology presents avery different set of problems.
Unlike Chinese andEnglish, Arabic commonly uses pronoun affixes.For ACE, this means that any annotation tool mustallow partial words to be tagged as mentions ofentities in Arabic, while disallowing this for otherlanguages.In addition to these linguistic differences, somedistinctive stylistic qualities of Chinese and Arabicnews reporting present challenges for annotatorsand are worthy of note.learning the English ACE tasks then move into their language-specific annotation.
This supports a consistent approach toannotation across the multiple languages despite the necessarylanguage-specific modifications.Many of these challenges are based in culturaldifferences.
For example, many industries inChina are government owned and operated.
Con-sequently, names of organizations are often quitedifferent than their English counterparts, andguidelines written with English naming conven-tions in mind are inadequate for handling commonChinese name constructions like "Beijing SchoolNumber 4".Further, organizations located outside of Chinaare often referred to with their country?s name pre-ceding the company name.
This presents a chal-lenge for annotator consistency, since it is oftenunclear whether to include the country as part ofthe extent of the company name.Arabic news sources regularly use very longsentences with multiple clauses.
This presents theannotator with different kinds of mention extentand coreference decisions than found in Englishnews data.
Mention extents are typically longerand contain more nested mentions, and pronominalreferences to entities are more easily confused.Another set of problems extends beyond anylanguage-specific considerations; these have to dowith the infrastructure needed to support a large-scale multilingual data creation effort.
Findingqualified native speaker annotators with adequatetraining in linguistics and eligibility to work in theUnited States is a serious challenge.
Further, ex-panding ACE into new languages is not simply amatter of addressing the linguistic questions, butalso tackling the technical ones.
Maintaining dataformats and annotation tools that can accommodatenot only multiple annotation tasks, but also multi-ple languages and multiple character sets and en-codings presents a significant problem.Despite the range of issues described above,porting the ACE annotation task into new lan-guages is relatively straightforward.
The funda-mental work of moving into a new language forACE involves identifying the syntactic and mor-phological (i.e., surface) constructions that areused to refer to the entities, relations and events ofinterest.
This is not an insubstantial task, and re-quires both the insights of trained linguists andmany rounds of pilot annotation and exploration ofthe data.
However, the fundamental concepts tar-geted by ACE, and the underlying semantic con-tent discussed in the annotated texts, remainsubstantially similar from one language to the next.4 CorporaAs part of the ACE program, and to furthersupport both the DARPA TIDES and DARPAEELD Programs, LDC has developed a number ofannotated corpora.
These corpora all draw onbroadcast news, newspaper and newswire data.Sources include data from the Topic Detection andTracking corpora, Chinese Treebank, Arabic Tree-bank and other news materials.Corpus development for the ACE program be-gan in 1999.
Initially, the Pilot Phase was de-signed to develop a basic task definition for entitydetection and tracking.
Multiple research sites in-cluding MITRE, BBN, NYU, and LDC annotatedthe same set of 15,000 words of English data toestablish a shared understanding of the annotationguidelines and resolve any inter-annotator discrep-ancies.
This data supported technology evalua-tions in May and November 2000.In ACE Phase 1, the research and annotationtasks were expanded to address metonymy andgeneric entities.
Multiple research sites joinedLDC in annotating 180,000 words of training datato support a February 2002 evaluation.
LDC wassolely responsible for annotating an additional45,000 words of evaluation data.ACE Phase 2 required research sites to addi-tionally detect and characterize relations betweenentities.
During this phase of ACE, LDC acted assole annotation site and also took on responsibilityfor developing and maintaining annotation guide-lines.
Phase 2 used the entire ACE Phase 1 corpusas training data, and added an additional 45,000words of new evaluation data.
Both training andevaluation data were annotated for entities plusrelations.
In support of the EELD Program, LDCannotators tagged another 30,000 words of do-main-specific training data plus 20,000 words oftest data for entities and relations.
A September2002 evaluation tested system performance forboth Entities and Relations.LDC is currently producing English test data toaugment the existing corpora in support of a Fall2003 TIDES extraction evaluation; in addition,LDC is creating data and annotations for multilin-gual extraction research in Chinese and Arabic.100,000 words of Chinese Treebank and 10,000words of Arabic Treebank have already been anno-tated for entities.Alongside corpus development, LDC is work-ing in parallel to expand and refine the existing setof ACE tasks.
These modifications are being madewith input from both the TIDES Extraction andACE communities.
For ACE Phase 3, LDC willannotate 300,000 words of data in each of threelanguages: English, Chinese and Arabic; pilot an-notation in Farsi is also targeted.
Ultimately, allthree annotation tasks -- entities, relations andevents -- will be represented in the data.
The cor-pora developed by LDC to support ACE, EELD,and TIDES Extraction are currently available toprogram participants only (LDC 2003c).
Generalpublication of the ACE Pilot and ACE Phase 1Corpora is slated for Summer 2003; upon publica-tion, the data will be available to LDC members aswell as non-members.
The remaining ACE andrelated corpora will be published after the conclu-sion of these programs' evaluation cycles.Outside of the ACE program, LDC has devel-oped a handful of additional resources for multi-lingual extraction research.
As part of the TIDESSurprise Language Exercise, LDC collects andcreates linguistic resources in a previously untar-geted language in an extremely compressed timespan.
During a two-week dry run in March 2003,the target was Cebuano, a language of the Philip-pines.
Within the span of a few days, LDC created250,000 words of monolingual text, built a 20,000word lexicon, created 25,000 words of paralleltext, built a morphological parser, and completednamed entity tagging of 32,000 words of text.Given the severe time constraints of the exer-cise, named entity annotators used a trimmed-down version of the MUC Named Entity Guide-lines rather than the more complex full MUC orACE guidelines.
Despite the time constraints, in-ter-annotator consistency remained high whenLDC-tagged data was compared with data taggedby annotators at BBN.
A similar set of resourcesfor a new surprise language will be developed dur-ing the Surprise Language evaluation in June 2003.All of the data developed for Surprise Language iscurrently available to TIDES participants, and willbe released as a general publication at the conclu-sion of the Exercise.A final resource created to support named enti-ties within information extraction more broadly isthe Xinhua Chinese-English Named Entity list,created from Xinhua Newswire's proper name andwho's who databases.
This corpus contains nearlyone million proper names of various kinds, includ-ing approximately 500,000 person names, 300,000place names, 30,000 organization names, and tensof thousands of other name types.
The data pro-vides both Chinese to English and English to Chi-nese name pairs.
This corpus, slated forpublication in Summer 2003, is currently availableto TIDES participants.Much of the material described above is basedupon large volumes of text and speech best col-lected from commercial providers.
Commercialsources may require the negotiation of agreementsthat permit the distribution of data to researcherswhile constraining the use of the material to lin-guistic education, research, and technology devel-opment.
LDC coordinates all necessary intellectualproperty arrangements for data developed undermultiple research programs including TIDES,ACE, and EELD to make resources gathered inthis way available to the broader research commu-nities.Sponsored common task research programs likeTIDES and ACE rely heavily upon such sharedresources.
LDC was in fact created specifically tofacilitate research sharing.
In order to allow forexpedited delivery of data to a group of researchersparticipating in a common task evaluation, LDChas developed a new data distribution methodknown as ECorpora.
ECorpora target expediteddelivery of training and devtest data to support offormal evaluations.
Upon the conclusion of theformal task evaluation, pending negotiations withresearch sponsors and program coordinators, LDCpublishes data more broadly to permit access tothese valuable resources to all communities work-ing in linguistic education, research, and technol-ogy development.ReferencesBird, Stephen and Mark Liberman, 2001, A FormalFramework for Linguistic Annotation.
[http://agtk.sourceforge.net/]Chinchor, Nancy, et al, 1999, Named Entity Recogni-tion Task Definition v1.4.
[ftp://jaguar.ncsl.nist.gov/ace/phase1/ne99_taskdef_v1_4.pdf]Chinchor, Nancy, 1997, MUC-7 Named Entity TaskDefinition Version 3.5[http://www.itl.nist.gov/iad/894.02/related_projects/muc/proceedings/ne_task.html]Day, David.
1997, Alembic Workbench User's Guide.
[http://www.mitre.org/tech/alembic-workbench/manual/]EELD, 2002, DARPA Program in Evidence Extractionand Link Detection[http://www.darpa.mil/iao/EELD.htm]Ferro, Lisa, et al, 2001, TIDES Temporal AnnotationGuidelines Version 1.0.2.LDC, 2003a, Automatic Content Extraction[http://www.ldc.upenn.edu/Projects/ACE/]LDC, 2003b, Surprise Language Project[http://www.ldc.upenn.edu/Projects/SurpriseLanguage]LDC, 2003c, TIDES Project[http://www.ldc.upenn.edu/Projects/TIDES/]Liberman, Mark and Christopher Cieri, 2002, TIDESLanguage Resources: A Resource Map for Translin-gual Information Access, Proceedings of the ThirdInternational Language Resources and EvaluationConference, Las Palmas, Spain, May-June 2002.Mitchell, A., et al 2002a.
Annotation Guidelines forEntity Detection and Tracking (EDT) Version 2.5.
[http://www.ldc.upenn.edu/Projects/ACE]Mitchell, A., et al 2002b.
Annotation Guidelines forRelation Detection and Characterization (RDC) Ver-sion 3.6.
[http://www.ldc.upenn.edu/Projects/ACE]NIST, 1999a, Message Understanding Conference[http://www.itl.nist.gov/iaui/894.02/related_projects/muc/]NIST, 1999b, TIDES Information Extraction-Entity[http://www.nist.gov/speech/tests/ie-er/er_99/er_99.htm]NIST, 2002, Automatic Content Extraction[http://www.nist.gov/speech/tests/ace]Sundheim, Beth, 2001, Preliminary RDC Guidelines forTime Attributes Version 1.0.TIDES, 2002, DARPA Program in Translingual Infor-mation Detection Extraction and Summarization[http://www.darpa.mil/iao/TIDES.htm]
