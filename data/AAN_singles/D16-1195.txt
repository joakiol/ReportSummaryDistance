Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1901?1911,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsAdapting Grammatical Error Correction Based on the Native Languageof Writers with Neural Network Joint ModelsShamil Chollampatt1 and Duc Tam Hoang2 and Hwee Tou Ng1,21NUS Graduate School for Integrative Sciences and Engineering2Department of Computer ScienceNational University of Singaporeshamil@u.nus.edu, {hoangdt,nght}@comp.nus.edu.sgAbstractAn important aspect for the task of grammat-ical error correction (GEC) that has not yetbeen adequately explored is adaptation basedon the native language (L1) of writers, despitethe marked influences of L1 on second lan-guage (L2) writing.
In this paper, we adapta neural network joint model (NNJM) usingL1-specific learner text and integrate it intoa statistical machine translation (SMT) basedGEC system.
Specifically, we train an NNJMon general learner text (not L1-specific) andsubsequently train on L1-specific data usinga Kullback-Leibler divergence regularized ob-jective function in order to preserve gener-alization of the model.
We incorporate thisadapted NNJM as a feature in an SMT-basedEnglish GEC system and show that adapta-tion achieves significant F0.5 score gains onEnglish texts written by L1 Chinese, Russian,and Spanish writers.1 IntroductionGrammatical error correction (GEC) deals with theautomatic correction of errors (spelling, grammar,and collocation errors), particularly in non-nativewritten text.
The native language (L1) backgroundof the writer has a noticeable influence on the er-rors made in second language (L2) writing, and con-sidering this factor can potentially improve the per-formance of GEC systems.
For example, considerthe following sentence written by a Finnish writer(Jarvis and Odlin, 2000): ?When they had escapedin the police car they sat under the tree.?
The prepo-sition in appears to be grammatically correct.
How-ever, in the given context, the preposition ?from?
isthe correct choice in place of the preposition ?in?.Finnish learners of English tend to overgeneralizethe use of the preposition ?in?.
Knowledge of L1makes the correction more probable whenever thepreposition in appears in texts written by Finnishwriters.
Similarly, Chinese learners of English tendto make frequent verb tense and verb form errors,since Chinese lacks verb inflection (Shaughnessy,1977).
The cross-linguistic influence of L1 on L2writing is a highly complex phenomenon, and the er-rors made by learners cannot be directly attributed tothe similarities or differences between the two lan-guages.
As Ortega (2009) points out, learners seemto operate on two complementary principles: ?whatworks in L1 may work in L2 because human lan-guages are fundamentally alike; but if it sounds tooL1-like, it will probably not work in L2?.
In thispaper, we follow a data-driven approach to modelthese influences and adapt GEC systems using L2texts written by writers of the same L1 background.The two most popular approaches for grammat-ical error correction are the classification approach(Dahlmeier et al, 2012; Rozovskaya et al, 2014)and the statistical machine translation (SMT) ap-proach (Chollampatt et al, 2016; Junczys-Dowmuntand Grundkiewicz, 2014).
The SMT approach hasemerged as a popular paradigm for GEC becauseof its ability to learn text transformations from ill-formed to well-formed text enabling it to correcta wide variety of errors including complex errorsthat are difficult to handle for the classification ap-proach (Rozovskaya and Roth, 2016).
The phrase-based SMT approach has been used in state-of-the-art GEC systems (Rozovskaya and Roth, 2016;1901Chollampatt et al, 2016; Hoang et al, 2016).
TheSMT approach does not model error types specifi-cally, nor does it require linguistic analysis like pars-ing and part-of-speech (POS) tagging.
We adopta phrase-based SMT approach to GEC in this pa-per.
Additionally, we implement and incorporate aneural network joint model (NNJM) (Devlin et al,2014) as a feature in our SMT-based GEC system.It is easy to integrate an NNJM into the SMT de-coding framework as it uses a fixed-window contextand it has shown to improve SMT-based GEC (Chol-lampatt et al, 2016).
We adapt the NNJM to L1-specific data (i.e., English text written by writers ofa particular L1) and obtain significant improvementsover the baseline which uses an unadapted NNJM.Adaptation is done by using the unadapted NNJMtrained on general domain data (i.e., not L1-specific)using a log likelihood objective function with self-normalization (Devlin et al, 2014) as the startingpoint, and training for subsequent iterations usingthe smaller L1-specific in-domain data with a mod-ified objective function which includes a Kullback-Leibler (KL) divergence regularization term.
Thismodified objective function prevents overfitting onthe smaller in-domain data and preserves the gener-alization capability of the NNJM.
We show that thismethod of adaptation works on very small and high-quality L1-specific data as well (50?100 essays).In summary, the two major contributions of thispaper are as follows.
(1) This is the first work thatperforms L1-based adaptation for GEC using theSMT approach and covering all error types.
(2)We introduce a novel method of NNJM adaptationand demonstrate that this method can work with in-domain data that are much smaller than the generaldomain data.2 Related WorkIn the past decade, there has been increasing atten-tion on GEC in English, mainly due to the growingnumber of English as second language (ESL) learn-ers around the world.
The popularity of this prob-lem grew further through Helping Our Own (HOO)(Dale and Kilgarriff, 2011; Dale et al, 2012) andCoNLL shared tasks (Ng et al, 2013; Ng et al,2014).
The majority of the published work on GECaimed at building classifiers or rule-based systemsfor specific error types and combined them to buildhybrid systems (Dahlmeier et al, 2012; Rozovskayaet al, 2014).The cross-linguistic influences between L1 andL2 have been mainly used for the task of native lan-guage identification (Massung and Zhai, 2016).
Ithas also been used in typology prediction (Berzak etal., 2014) and predicting error distributions in ESLdata (Berzak et al, 2015).
L1-based adaptation haspreviously shown to improve GEC for specific errortypes using the classification approach.
Rozovskayaand Roth (2010) used an approach to correct prepo-sition errors by restricting the candidate correctionsto those observed in L1-specific data.
They furtheradded artificial training data that mimic the error fre-quency in L1-specific text to improve accuracy.
Intheir later work, Rozovskaya and Roth (2011) fo-cused on L1-based adaptation for preposition andarticle correction, by modifying the prior probabil-ities in the na?
?ve Bayes classifier during decisiontime based on L1-specific ESL learner text.
Bothapproaches use native data for training, but rely onnon-native L1-specific text to introduce artificial er-rors or to modify the prior probabilities.
Dahlmeierand Ng (2011) implemented a system to correct col-location errors, by adding paraphrases derived fromL1 into the confusion set.
Specifically, they use abilingual L1-L2 corpus, to obtain L2 paraphrases,which are likely to be translated to the same phrasein L1.
There is no prior work on L1-based adap-tation for GEC using the machine translation ap-proach, which is a one of the most popular ap-proaches for GEC.With the availability of large-scale error correcteddata (Mizumoto et al, 2011), the statistical machinetranslation (SMT) approach to GEC became popu-lar and was employed in state-of-the-art GEC sys-tems.
Comparison of the classification approachand the machine translation approach can be foundin (Rozovskaya and Roth, 2016) and (Susanto etal., 2014).
Recently, an end-to-end neural machinetranslation framework was proposed for GEC (Yuanand Briscoe, 2016), which was shown to achievecompetitive results.
Neural network joint modelshave shown to be improve SMT-based GEC sys-tems (Chollampatt et al, 2016) due to their abilityto model words and phrases in a continuous space,access to larger contexts from source side, and abil-1902ity to learn non-linear mappings from input to out-put.
In this paper, we exploit the advantages ofthe SMT approach and neural network joint mod-els (NNJMs) by adapting an NNJM based on theL1 background of the writers and integrating it intothe SMT framework.
We perform KL divergenceregularized adaptation to prevent overfitting on thesmaller in-domain data.
KL divergence regulariza-tion was previously used by Yu et al (2013) forspeaker adaptation.
Joty et al (2015) proposed an-other NNJM adaptation method, which uses a regu-larized objective function that encourages a networktrained on general-domain data to be closer to an in-domain NNJM.
Other adaptation techniques used inSMT include mixture modeling (Foster and Kuhn,2007; Moore and Lewis, 2010; Sennrich, 2012) andalternative decoding paths (Koehn and Schroeder,2007).3 A Machine Translation Framework forGrammatical Error CorrectionWe formulate GEC as a translation task from a pos-sibly erroneous input sentence to a corrected sen-tence.
We use the popular phrase-based SMT sys-tem, Moses (Koehn et al, 2007), which employs alog linear model to find the best correction hypothe-sis T ?
given an input sentence S:T ?
= argmaxTP (T |S) = argmaxTN?i=1?ifi(T, S)where ?i and fi(T, S) are the ith feature weight andfeature function, respectively.
We use the standardfeatures in Moses, without any re-ordering mod-els.
The two main components of an SMT systemare the translation model (TM) and the languagemodel (LM).
The TM (typically, a phrase table), re-sponsible for generating hypotheses, is trained usingparallel data, i.e., learner-written sentences (sourcedata) and their corresponding corrected sentences(target data).
It also scores the hypotheses us-ing features like forward and inverse phrase trans-lation probabilities and lexical weights.
The LMis trained on well-formed text and ensures the flu-ency of the corrected output.
The feature weights?i are computed by minimum error rate training(MERT), optimizing the F0.5 measure (Junczys-Dowmunt and Grundkiewicz, 2014) using a devel-opment set.
The F0.5 measure computed usingthe MaxMatch scorer (Dahlmeier and Ng, 2012) isthe standard evaluation metric for GEC used in theCoNLL-2014 shared task (Ng et al, 2014), weight-ing precision twice as much as recall.Apart from the TM and the n-gram LM, we adda neural network joint model (NNJM) (Devlin etal., 2014) as a feature, following Chollampatt et al(2016), who reported that NNJM improves the per-formance of a state-of-the-art SMT-based GEC sys-tem.
Unlike Recurrent Neural Networks (RNNs)and Long Short Term Memory networks (LSTMs),NNJMs have a feed-forward architecture which re-lies on a fixed context.
This makes it easy to inte-grate NNJMs into a machine translation decoder asa feature.
The feature value is given by logP (T |S),which is the sum of the log probabilities of individ-ual target words in the hypothesis T given the con-text:logP (T |S) ?|T |?i=1logP (ti|hi) (1)where |T | is the number of words in the targethypothesis (corrected sentence), ti is the ith targetword, and hi is the context of ti.
The context hiconsists of n?1 previous target words andm sourcewords surrounding the source word that is aligned tothe target word ti.Each dimension in the output layer of the neuralnetwork (Chollampatt et al, 2016) gives the proba-bility of a word t in the output vocabulary given itscontext h:P (y = t|h) = exp(Ut(h))Z(h) =exp(Ut(h))?t?
?Vo exp(Ut?
(h))whereUt(h) is the unnormalized output score beforethe softmax, and Vo is the output vocabulary.The neural network parameters which include theweights, biases, and embedding matrices are trainedusing back propagation with stochastic gradient de-scent (LeCun et al, 1998).
Instead of using the noisecontrastive estimation (NCE) loss as done in (Chol-lampatt et al, 2016), we use the log likelihood ob-jective function with a self-normalization term sim-ilar to Devlin et al (2014):L = 1NN?i=1[log p(y = ti|hi)?
?
log2(Z(hi))](2)1903where N is the number of training instances, and tiis the target word in the ith training instance.
Eachtraining instance consists of a target word t and itscontext h. ?
is the self-normalization coefficientwhich we set to 0.1, following Devlin et al (2014).The training can be done efficiently on GPUs.
Weadapt this NNJM using L1-specific learner text usinga Kullback-Leibler divergence regularized objectivefunction as described in Section 4.4 KL Divergence Regularized AdaptationWe first train an NNJM with the general-domaindata (the erroneous and corrected texts, not consider-ing the L1 of the writers) as described in the previoussection.
Let pGD(y|h) be the probability distribu-tion estimated by the general-domain NNJM.
Start-ing from this NNJM, subsequent iterations of train-ing are done using the L1-specific in-domain dataalone.
The in-domain data consists of the erroneoustexts written by writers of a specific L1 and their cor-responding corrected texts.
This adaptive training isdone using a modified objective function having aregularization term K, which is used to minimizethe KL divergence between pGD(y|h) and the net-work?s output probability distribution p(y|h) (Yu etal., 2013):K = 1NN?i=1Vo?j=1pGD(y = tj |hi) log p(y = tj |hi)The term K will prevent the estimated probabilitydistribution from deviating too much from that ofthe general domain NNJM during training.
Our finalobjective function for the adaptation step is a linearcombination of the terms in L andK, with a regular-ization weight ?
and a self-normalization coefficient?:L?
=?K + (1?
?)
1NN?i=1log p(y = ti|hi)?
?
1NN?i=1log2(Z(hi))We integrate the unadapted NNJM and adaptedNNJM independently into our SMT-based GEC sys-tem in order to compare the effect of adaptation.5 Other Adaptation MethodsWe compare our method against two other adapta-tion methods previously used in SMT.Translation Model Interpolation: FollowingSennrich (2012), we linearly interpolate the fea-tures in two phrase tables, one trained on in-domain data (L1-specific learner text) and the otheron out-of-domain data.
The interpolation weightsare set by minimization of perplexity using phrasepairs extracted from our in-domain development set.The lexical weights are re-computed from the lex-ical counts and the interpolation weights are re-normalized if a phrase pair exists only in one of thephrase tables.Neural Domain Adaptation Model: Joty et al(2015) proposed an adaptation of NNJM for SMT.They first train an NNJM using in-domain data,and then perform regularized adaptation on the gen-eral domain data (concatenation of in-domain andout-of-domain data) which restricts the model fromdrifting away from the in-domain NNJM.
Specifi-cally, they add a regularization term J to the objec-tive function in their adaptive training step:J = 1NN?i=1pID(y = ti|hi) log p(y = ti|hi)where pID(y|h) id probability distribution estimatedby the in-domain NNJM.NDAM has the following drawbacks compared toour method: (1) Regularization is done using proba-bilities of the target words alone and not on the entireprobability distribution over all words, leading to aweak regularization.
(2) If the in-domain data is toosmall, the probability distribution learnt by the in-domain NNJM will be overfitted.
Therefore, encour-aging adaptation to be closer to this probability dis-tribution may not yield a good model.
Our method,on the other hand, can utilize in-domain data of verysmall sizes to fine tune a general NNJM.
(3) Theirmethod requires retraining of the model on completetraining data in order to adapt to each domain.
Onthe contrary, our method can adapt a single generalmodel to different domains using small in-domaindata, leading to a considerable reduction in trainingtime.We re-implement their method by incorporatingthis regularization term into the log likelihood objec-1904tive function with self-normalization, L (Equation2), during adaptive training.6 Data and EvaluationThe training data consist of two corpora: the NUSCorpus of Learner English (NUCLE) (Dahlmeieret al, 2013) and the Lang-8 Learner Corpora v2(Mizumoto et al, 2011).
We extract texts writtenby learners who learn only English from Lang-8.
Alanguage identification tool langid.py1 (Lui andBaldwin, 2011) is then used to obtain purely Englishsentences.
In addition, we remove noisy source-target sentence pairs in Lang8 where the ratio of thelengths of the source and target sentences is outside[0.5, 2.0], or their word overlap ratio is less than 0.2.A sentence pair where the source or target sentencehas more than 80 words is also removed from bothNUCLE and Lang-8.
The statistics of the data afterpre-processing are shown in Table 1.Corpus #sents #src tokens #tgt tokensNUCLE 57,063 1,156,460 1,151,278LANG-8 2,048,654 24,649,768 25,912,707CONCAT 2,105,717 25,806,228 27,063,985Table 1: Statistics of training dataWe obtain L1-specific in-domain data for adapta-tion based on the L1 information provided in Lang-8.
Adaptation is performed on English texts writ-ten by learners of three different L1 backgrounds:Chinese, Russian, and Spanish.
The statistics of thein-domain data from Lang-8 for each L1 are givenin Table 2.
For each L1, its out-of-domain dataare obtained by excluding the L1-specific in-domaindata (from Table 2) from the combined training data(CONCAT).L1 #sents #src tokens #tgt tokensChinese 260,872 3,521,336 3,688,098Russian 43,488 566,517 596,692Spanish 19,357 292,257 309,236Table 2: Statistics of L1-specific data in Lang-8We use the publicly available CLC-FCE (Yan-nakoudakis et al, 2011) corpus to obtain the de-1https://github.com/saffsd/langid.pyvelopment and test data.
The FCE corpus contains1,244 scripts written by 1,244 distinct candidates sit-ting the Cambridge ESOL First Certificate in En-glish (FCE) examination in 2000 and 2001.
Thecorpus identifies the L1 of each writer.
We extractthe scripts written by Chinese, Russian, and Span-ish native writers.
We split the data for each L1into two roughly equal parts based on the number ofscripts, of which one part is used as the developmentdata and other part is used as the test data.
Splittingbased on the number of scripts ensures that there isno overlap between the writers of the developmentand test data, as each script is written by a uniquelearner.
The details of the FCE dataset correspond-ing to each L1 are given in Table 3.#scripts #sents #srctokens#tgttokens #errorsL1: ChineseDEV 33 1,041 15,424 15,601 1,751TEST 33 1,078 15,640 15,816 1,487L1: RussianDEV 41 1,125 17,021 17,267 1,782TEST 42 1,263 18,738 18,920 1,934L1: SpanishDEV 100 2,281 41,375 41,681 4,133TEST 100 2,431 41,557 42,035 4,237Table 3: Statistics of the FCE dataset for each L1For evaluation, we use the F0.5 measure, com-puted by the M2scorer v3.2 (Dahlmeier and Ng,2012), as our evaluation metric.
The error annota-tions in FCE are converted to the format requiredby the M2scorer.
The statistics of error annotationsafter converting to this format are given in Table 3.To deal with the instability of parameter tuning inSMT, we perform five runs of tuning and calculatethe statistical significance by stratified approximaterandomization test, as recommended by (Clark etal., 2011).7 Experiments and Results7.1 Baseline SMT-based GEC systemWe use Moses (Version 3) to build all our SMT-based GEC systems.
The phrase table of the base-line system (SCONCAT) is trained using the complete1905L1: Chinese L1: Russian L1: SpanishP R F0.5 P R F0.5 P R F0.5SIN 50.03 16.11 35.09 38.11 16.99 30.52 43.40 12.74 29.28SOUT 49.88 17.34 36.23 54.78 21.15 41.54 57.18 16.10 37.83SCONCAT 51.72 17.56 37.23 54.17 21.70 41.62 55.45 16.93 38.09SCONCAT + NNJMBASELINE 50.47 18.75 37.63 55.22 21.73 42.15 58.30 16.42 38.60NNJM adaptation using KL divergence regularizationSCONCAT + NNJMADAPTED 56.02 17.59 38.90 55.71 22.53 43.03 59.05 16.77 39.24SCONCAT + NNJMADAPTED (FCE) 53.82 18.60 38.91 56.03 22.46 43.13 58.88 16.95 39.38Comparison to other adaptation techniquesTMINT + NNJMBASELINE 55.70 17.18 38.38 54.97 21.90 42.21 58.32 16.44 38.59SCONCAT + NDAM 56.56 16.76 38.31 54.60 22.03 42.11 58.28 16.64 38.83TMINT + NNJMADAPTED 55.89 17.62 38.81 56.30 21.75 42.70 57.04 16.97 38.73Using smaller general domain dataSCONCAT + NNJMSMALL-BASELINE 53.29 17.47 37.75 55.34 20.87 41.55 58.05 16.46 38.55SCONCAT + NDAMSMALL 53.89 17.36 37.87 55.29 21.09 41.70 56.82 16.69 38.36SCONCAT + NNJMSMALL-ADAPTED 52.41 17.40 37.37 56.03 21.17 42.09 58.34 16.79 39.01Table 4: Precision (P), recall (R), and F0.5 of L1-based adaptation of GEC systems.
All results are averaged over 5 runs of tuningand evaluation.training data.
We use two 5-gram language models(LMs) trained using KenLM (Heafield et al, 2013).One LM is trained on the English Wikipedia (about1.78 billion tokens) and another on the target side ofthe complete training data.
The system is tuned us-ing MERT, optimizing the F0.5 measure on the L1-specific development data in Table 2.For comparison, we show two other baselines SINand SOUT, where the phrase tables for each L1 aretrained on the in-domain data only (Table 2) and theout-of-domain data only, respectively.
The resultsof the above baseline GEC systems on L1 Chinese,Russian, and Spanish FCE test data are summarizedin Table 4.
We enhance the baseline SCONCAT with anNNJM feature, as described in following subsection.7.2 NNJM AdaptationWe implement NNJM in Python using the deeplearning library Theano2 (Bergstra et al, 2010) inorder to use the massively parallel processing powerof GPUs for training.
We first train an NNJM(NNJMBASELINE) with complete training data for 10epochs.
The source context window size is set to 5and the target context window size is set to 4, mak-ing it a (5+5)-gram joint model.
Training is doneusing stochastic gradient descent with a mini-batch2http://deeplearning.net/software/theanosize of 128 and learning rate of 0.1.
To speed uptraining and decoding, a single hidden layer neuralnetwork is used with an input embedding dimen-sion of 192 and 512 hidden units.
We use a self-normalization coefficient of 0.1.
We pick 16,000 and32,000 most frequent words on the source and tar-get sides as our source context vocabulary and targetcontext vocabulary, respectively.
The output vocab-ulary is set to be the same as the target vocabulary.The vocabulary is selected from the complete train-ing data, and not based on the L1-specific in-domaindata.
We add the self-normalized NNJM as a fea-ture to our baseline GEC system, SCONCAT to build astronger baseline.
This is referred to as SCONCAT +NNJMBASELINE in Table 4.We perform adaptation on NNJMBASELINE bytraining for 10 additional epochs using the in-domain training data alone.
We use the same hyper-parameters, network structure, and vocabulary, butwith the KL-divergence regularized objective func-tion (regularization weight ?
= 0.5).
We trainthe adapted NNJM (NNJMADAPTED) specific to eachL1.
We integrate these to our baseline GEC system,and the adapted systems are referred to as SCONCAT+ NNJMADAPTED in Table 4.
The results are aver-aged over five runs of tuning and evaluation.
Ourevaluation shows that each adapted system SCONCAT1906+ NNJMADAPTED outperforms every baseline system(SIN, SOUT, SCONCAT, and SCONCAT + NNJMBASELINE)significantly on all three L1s (p < 0.01).7.3 Comparison to Other AdaptationTechniquesWe compare our method to two different adapta-tion techniques described in Section 5: TranslationModel Interpolation (TMINT) (Sennrich, 2012) andNeural Domain Adaptation Model (NDAM) (Jotyet al, 2015)3.
The optimization of interpolationweights for TMINT is done using the L1-specificFCE development data.
NDAM is trained on thecomplete training data (CONCAT) for 10 epochs byregularizing using an in-domain NNJM also trainedfor 10 epochs on L1-specific in-domain data fromLang-8.
For NDAM, we use the same vocabularyand hyperparameters as our NNJMs.The results are shown in the rows TMINT +NNJMBASELINE and SCONCAT + NDAM in Table4.
Our evaluation shows that for L1 Russianand L1 Spanish, our adapted system SCONCAT+ NNJMADAPTED significantly outperforms bothTMINT + NNJMBASELINE and SCONCAT + NDAM (p <0.01), but the improvement is not statistically signif-icant for L1 Chinese.Our evaluation also shows that the combinationof TMINT and adapted NNJM is similar (for L1 Chi-nese and Russian) or worse (for Spanish) in perfor-mance compared to SCONCAT + NNJMADAPTED.
Thisis because NNJMADAPTED by itself is a translationmodel adaptation (because it considers source andtarget side contexts) and hence using TMINT alongwith it does not bring in any newer information andmay even hurt the performance when the in-domaindata is very small (in the case of Spanish).7.4 Effect of Adaptation DataWe also perform adaptation on the L1-specific FCEdevelopment set in Table 3 (which is also our de-velopment data for the GEC systems), instead of thein-domain data from Lang-8 in Table 2.
Our neu-ral network overfits easily on the FCE developmentset due to its much smaller size.
Hence, we per-form adaptive training for only 2 epochs on top ofNNJMBASELINE.
The results are shown in the row3We use the NDAMv1 (Joty et al, 2015) trained using thelog likelihood objective function with self-normalization.SCONCAT + NNJMADAPTED (FCE) in Table 4.
Althoughthe FCE development data is much smaller in sizethan the L1-specific in-domain data from Lang-8,we observe similar improvements on all three L1s.This is likely due to the similarity of the devel-opment and test sets, which are obtained from thesame FCE corpus.
These experiments show thatsmaller high-quality L1-specific error annotated data(1,000?2,000 sentences) similar to the target datacan be used for adaptation to give competitive re-sults compared to using much larger in-domain data(20,000?250,000 sentences) from other sources.We perform experiments with smaller general do-main data.
In order to do this, we select a sub-set of CONCAT composed of the in-domain dataof the three L1s along with 300,000 sentences ran-domly selected from the rest of CONCAT.
This cor-pus is referred to as SMALL-CONCAT (623,717 sen-tences and 7,990,659 source tokens).
We performboth KL-divergence regularized NNJM adaptation(NNJMSMALL-ADAPTED) as well as Neural DomainAdaptation Model (Joty et al, 2015) (NDAMSMALL)and compare them to NNJM trained with SMALL-CONCAT (NNJMSMALL-BASELINE).
We use theseNNJMs with our SCONCAT baseline.
The resultsare summarized in Table 4.
When the ratio be-tween in-domain data and general domain data ishigh, both adaptation methods do not significantlyimprove over an unadapted NNJM.
In the case ofL1 Spanish, KL-divergence regularized adaptationsignificantly outperforms the unadapted NNJM andNDAM as the size of in-domain data is smaller.7.5 Effect of RegularizationTo analyze the effect of regularization when smallerdata are used, we vary the regularization weight ?
inour objective function (Section 4).
The results areshown in Figure 1. ?
= 0 corresponds to no reg-ularization and training completely depends on thein-domain data apart from using the general NNJMas a starting point.
On the other hand, setting ?
= 1forces the distribution learnt by the network to besimilar to that of the unadapted model.
We see thathaving no regularization (?
= 0) fails on all threeL1s, due to overfitting on the smaller in-domaindata.
However, the effect of varying regularizationis more significant on L1 Russian and Spanish, asthe general NNJM has seen much smaller in-domain1907L1: Chinese L1: Russian L1: Spanish363738394041424344F 0.5?=0.00?=0.25?=0.50?=0.75?=1.00Figure 1: Effect of regularization for SCONCAT +NNJMADAPTED (FCE)data compared to L1 Chinese.7.6 Evaluation on Benchmark DatasetWe also evaluate our system on the benchmarkCoNLL-2014 shared task (Ng et al, 2014) test setfor GEC in English.
The CoNLL-2014 shared taskconsists of 1,312 sentences with two annotators.
Wealso perform evaluation on the extension of CoNLL-2014 test set (Bryant and Ng, 2015), which containseight additional sets of annotations over the two setsof annotations provided in the original test set.
Fol-lowing the settings of the CoNLL-2014 shared task,we tune our unadapted baseline system and the L1-adapted systems on the CoNLL-2013 shared tasktest set consisting of 1,381 test sentences.
The re-sults are summarized in Table 5.We find that only the systems adapted based on L1Chinese improves over the unadapted baseline sys-tem (SCONCAT + NNJMBASELINE).
When the smaller-sized, high-quality FCE data is used for adaptationthe margin of improvement is higher.
This could bedue to large proportion of Chinese learner writtentext in CoNLL-2014 test set, as the essays are writ-ten by the students of National University of Sin-gapore comprising mostly of native Chinese speak-ers.
Adaptation to L1 Russian and Spanish, does nothelp the system on CoNLL-2014 test set.
We alsocompare our baseline SMT-based system with otherstate-of-the-art GEC systems.
Our baseline systemwhich is SMT-based, achieves the best F0.5 scorecompared to other systems using the SMT approachalone, making it a competitive SMT-based GECbaseline.
Overall, (Rozovskaya and Roth, 2016)System CoNLL-2014ST 10ANNSCONCAT + NNJMBASELINE 42.80 59.14Adaptation based on L1 ChineseSCONCAT + NNJMADAPTED 43.06 59.27SCONCAT + NNJMADAPTED (FCE) 44.27 60.36Adaptation based on L1 RussianSCONCAT + NNJMADAPTED 42.73 58.90SCONCAT + NNJMADAPTED (FCE) 42.12 58.30Adaptation based on L1 SpanishSCONCAT + NNJMADAPTED 41.88 58.32SCONCAT + NNJMADAPTED (FCE) 42.36 58.54Best Published ResultsRozovskaya and Roth (2016)(classifiers + spelling + SMT) 47.40 -(SMT) 39.48 -Chollampatt et al (2016) (SMT) 41.75 57.19Shared Task TeamsCAMB (classifiers, rules, SMT) 37.33 54.26CUUI (classifiers) 36.79 51.79AMU (SMT) 35.01 50.17Table 5: ST denotes F0.5 scores on the shared task test set and10ANN denotes the F0.5 scores on the extended test set with 10sets of annotations.achieves the best F0.5 score (47.40) after adding clas-sifier components, spelling checker, punctuation andcapitalization correction components in a pipelinewith their SMT-based system.
However, their SMT-based system alone achieves an F0.5 score of 39.48only.8 Discussion and Error AnalysisOur results show that L1-based adaptation of theNNJM using L1-specific in-domain data from Lang-8 significantly improves the F0.5 score of the GECsystem on the three L1s by 1.27 (Chinese), 0.88(Russian), and 0.64 (Spanish).
We observe simi-lar gains when smaller in-domain development datafrom FCE is used for adaptation.
These results showthat adaptation based on L1 is beneficial for targetederror correction based on the native language of thewriters.
Our results also show that the proposedmethod of NNJM adaptation is scalable to differ-ent sizes of in-domain and general domain data andoutperforms other methods of adaptation like phrasetable interpolation (Sennrich, 2012) and Neural Do-main Adaptation Model (NDAM) (Joty et al, 2015).We perform error analysis on four error types1908Error type ?
F0.5Chinese Russian Spanishverb form/tense +0.394 +0.298 -0.124determiner +2.892 +2.440 +1.648preposition +0.084 +2.010 +1.806noun number +0.130 -0.706 +0.822all +0.400 +1.068 +0.586Table 6: Differences between per error type F0.5 scores of sys-tem and baseline for the three L1swhich are difficult for non-native learners of En-glish.We compare the outputs produced by our adaptedsystem: SCONCAT + NNJMADAPTED and the baseline:SCONCAT + NNJMBASELINE.
We perform per errortype quantitative analysis of our results by observ-ing the difference in the per error type F0.5 scoresaveraged over five runs of tuning and evaluation ofbaseline and system.
Computing per error type F0.5scores is difficult for SMT-based GEC systems, asthe error types for corrections proposed by the SMT-based GEC system cannot be determined trivially.To overcome this difficulty, we attempt to determinethe error type of the proposed corrections by match-ing them to the available human annotations (thesource/target phrase without the surrounding con-text) in the complete FCE dataset (1,244 scripts).We select those sentences from the test data wherethe error type of every correction proposed by thebaseline and the system can be determined.
Thisprocess selects 928, 1102, and 2179 sentences forL1 Chinese, Russian, and Spanish, respectively.
Thedifferences in per error type F0.5 scores between sys-tem and baseline are shown in Table 6.
For Chinese,the largest gain in F0.5 is observed for determiner er-rors.
Determiner errors are frequent in our L1 Chi-nese FCE test set (10.02%) .
Moreover, we see thatadaptation improves verb form errors by approxi-mately 0.4% F0.5.
Verb form errors are the most fre-quent error type in our L1 Chinese test set (14.46%).Also, the highest gain for L1 Russian comes fromdeterminer errors which is the most frequent errortype in our FCE test data for L1 Russian (13.55%).Similarly, the highest gain for L1 Spanish comesfrom preposition errors which is the most frequenterror type for L1 Spanish (12.51%).From a practical standpoint, the adapted systemcan be used as an educational aid in English classesof local students in non-English-speaking countries,where all the students share the same L1 and theirL1 is known in advance.
The adapted system cangive focused feedback to learners by correcting mis-takes frequently made by learners having the sameL1.
Also, NNJM adaptation proposed in this papercan be done using a small number of essays (50?100essays) in a relatively short time (20?30 minutes),making it easy to adapt GEC systems in practice.9 ConclusionIn this paper, we perform NNJM adaptation usingL1-specific learner text with a KL divergence reg-ularized objective function.
We integrate adapta-tion into an SMT-based GEC system.
The systemswith adapted NNJMs outperform unadapted base-lines significantly.
We also demonstrate the neces-sity for regularization when adapting on smaller in-domain data.
Our method of adaptation performsbetter compared to other adaptation methods, espe-cially when smaller in-domain data is used.
Our re-sults show that adapting GEC systems for learnersof similar L1 background gives significant improve-ment and can be adopted in practice to improve GECsystems.AcknowledgmentsWe thank Kaveh Taghipour for insightful commentsand discussions throughout this work.
We are alsograteful to the anonymous reviewers for their feed-back which helped in revising and improving the pa-per.
This research is supported by Singapore Min-istry of Education Academic Research Fund Tier 2grant MOE2013-T2-1-150.ReferencesJames Bergstra, Olivier Breuleux, Fre?de?ric Bastien, Pas-cal Lamblin, Razvan Pascanu, Guillaume Desjardins,Joseph Turian, David Warde-Farley, and Yoshua Ben-gio.
2010.
Theano: a CPU and GPU math expressioncompiler.
In Proceedings of the Python for ScientificComputing Conference.Yevgeni Berzak, Roi Reichart, and Boris Katz.
2014.Reconstructing native language typology from foreignlanguage usage.
In Proceedings of the 19th Confer-ence on Computational Natural Language Learning.Yevgeni Berzak, Roi Reichart, and Boris Katz.
2015.Contrastive analysis with predictive power: Typology1909driven estimation of grammatical error distributions inESL.
In Proceedings of the 19th Conference on Com-putational Natural Language Learning.Christopher Bryant and Hwee Tou Ng.
2015.
How farare we from fully automatic high quality grammaticalerror correction?
In Proceedings of the 53rd AnnualMeeting of the Association for Computational Linguis-tics and the 7th International Joint Conference on Nat-ural Language Processing.Shamil Chollampatt, Kaveh Taghipour, and Hwee TouNg.
2016.
Neural network translation models forgrammatical error correction.
In Proceedings of the25th International Joint Conference on Artificial Intel-ligence.Jonathan H Clark, Chris Dyer, Alon Lavie, and Noah ASmith.
2011.
Better hypothesis testing for statisti-cal machine translation: Controlling for optimizer in-stability.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Hu-man Language Technologies.Daniel Dahlmeier and Hwee Tou Ng.
2011.
Correct-ing semantic collocation errors with L1-induced para-phrases.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing.Daniel Dahlmeier and Hwee Tou Ng.
2012.
Better evalu-ation for grammatical error correction.
In Proceedingsof the 2012 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies.Daniel Dahlmeier, Hwee Tou Ng, and Eric Jun Feng Ng.2012.
NUS at the HOO 2012 shared task.
In Proceed-ings of the 7th Workshop on the Innovative Use of NLPfor Building Educational Applications.Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.2013.
Building a large annotated corpus of learnerEnglish: The NUS corpus of learner English.
In Pro-ceedings of the Eighth Workshop on Innovative Use ofNLP for Building Educational Applications.Robert Dale and Adam Kilgarriff.
2011.
Helping ourown: The HOO 2011 pilot shared task.
In Proceedingsof the 13th European Workshop on Natural LanguageGeneration.Robert Dale, Ilya Anisimoff, and George Narroway.2012.
HOO 2012: A report on the preposition anddeterminer error correction shared task.
In Proceed-ings of the Seventh Workshop on Building EducationalApplications Using NLP.Jacob Devlin, Rabih Zbib, Zhongqiang Huang, ThomasLamar, Richard Schwartz, and John Makhoul.
2014.Fast and robust neural network joint models for statis-tical machine translation.
In Proceedings of the 52ndAnnual Meeting of the Association for ComputationalLinguistics.George Foster and Roland Kuhn.
2007.
Mixture-modeladaptation for SMT.
In Proceedings of the SecondWorkshop on Statistical Machine Translation.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark,and Philipp Koehn.
2013.
Scalable modified Kneser-Ney language model estimation.
In Proceedings of the51st Annual Meeting of the Association for Computa-tional Linguistics.Duc Tam Hoang, Shamil Chollampatt, and Hwee TouNg.
2016.
Exploiting n-best hypotheses to improvean SMT approach to grammatical error correction.
InProceedings of the 25th International Joint Confer-ence on Artificial Intelligence.Scott Jarvis and Terence Odlin.
2000.
Morphologicaltype, spatial reference, and language transfer.
Studiesin Second Language Acquisition, 22:535?556.Shafiq Joty, Hassan Sajjad, Nadir Durrani, Kamla Al-Mannai, Ahmed Abdelali, and Stephan Vogel.
2015.How to avoid unwanted pregnancies: Domain adapta-tion using neural network models.
In Proceedings ofthe 2015 Conference on Empirical Methods in NaturalLanguage Processing.Marcin Junczys-Dowmunt and Roman Grundkiewicz.2014.
The AMU system in the CoNLL-2014 sharedtask: Grammatical error correction by data-intensiveand feature-rich statistical machine translation.
InProceedings of the Eighteenth Conference on Compu-tational Natural Language Learning: Shared Task.Philipp Koehn and Josh Schroeder.
2007.
Experiments indomain adaptation for statistical machine translation.In Proceedings of the Second Workshop on StatisticalMachine Translation.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the Associationfor Computational Linguistics (Interactive Poster andDemonstration Sessions).Yann LeCun, Leon Bottou, Genevieve Orr, and KlausMu?ller.
1998.
Efficient backprop.
Neural Networks:Tricks of the Trade, pages 9?50.Marco Lui and Timothy Baldwin.
2011.
Cross-domainfeature selection for language identification.
In Pro-ceedings of the 5th International Joint Conference onNatural Language Processing.Sean Massung and Chengxiang Zhai.
2016.
Non-nativetext analysis: A survey.
Natural Language Engineer-ing, 22:163?186.Tomoya Mizumoto, Mamoru Komachi, Masaaki Nagata,and Yuji Matsumoto.
2011.
Mining revision log of1910language learning SNS for automated Japanese errorcorrection of second language learners.
In Proceed-ings of the Fifth International Joint Conference onNatural Language Processing.Robert C. Moore and William Lewis.
2010.
Intelligentselection of language model training data.
In Proceed-ings of the 48th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies.Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, ChristianHadiwinoto, and Joel Tetreault.
2013.
The CoNLL-2013 shared task on grammatical error correction.
InProceedings of the Seventeenth Conference on Com-putational Natural Language Learning: Shared Task.Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, ChristianHadiwinoto, Raymond Hendy Susanto, and Christo-pher Bryant.
2014.
The CoNLL-2014 shared taskon grammatical error correction.
In Proceedings ofthe Eighteenth Conference on Computational NaturalLanguage Learning: Shared Task.Lourdes Ortega.
2009.
Understanding Second LanguageAcquisition.
Hodder Education.Alla Rozovskaya and Dan Roth.
2010.
Generatingconfusion sets for context-sensitive error correction.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing.Alla Rozovskaya and Dan Roth.
2011.
Algorithm selec-tion and model adaptation for ESL correction tasks.
InProceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics.Alla Rozovskaya and Dan Roth.
2016.
Grammatical er-ror correction: Machine translation and classifiers.
InProceedings of the 54th Annual Meeting of the Associ-ation for Computational Linguistics.Alla Rozovskaya, Kai-Wei Chang, Mark Sammons, DanRoth, and Nizar Habash.
2014.
The Illinois-Columbiasystem in the CoNLL-2014 shared task.
In Proceed-ings of the Eighteenth Conference on ComputationalNatural Language Learning: Shared Task.Rico Sennrich.
2012.
Perplexity minimization for trans-lation model domain adaptation in statistical machinetranslation.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Compu-tational Linguistics.Mina Shaughnessy.
1977.
Errors and Expectations.New York: Oxford University Press.Raymond Hendy Susanto, Peter Phandi, and Hwee TouNg.
2014.
System combination for grammatical errorcorrection.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Processing.Helen Yannakoudakis, Ted Briscoe, and Ben Medlock.2011.
A new dataset and method for automaticallygrading ESOL texts.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies.Dong Yu, Kaisheng Yao, Hang Su, Gang Li, and FrankSeide.
2013.
KL-divergence regularized deep neu-ral network adaptation for improved large vocabularyspeech recognition.
In Proceedings of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing.Zheng Yuan and Ted Briscoe.
2016.
Grammatical errorcorrection using neural machine translation.
In Pro-ceedings of the 15th Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics.1911
