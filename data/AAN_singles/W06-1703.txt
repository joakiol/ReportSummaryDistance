A Comparative Study on Compositional Translation Estimationusing a Domain/Topic-Specific Corpus collected from the WebMasatsugu Tonoike?, Mitsuhiro Kida?, Toshihiro Takagi?, Yasuhiro Sasaki?,Takehito Utsuro?
?, Satoshi Sato?
?
?
?Graduate School of Informatics, Kyoto UniversityYoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan?
?Graduate School of Systems and Information Engineering, University of Tsukuba1-1-1, Tennodai, Tsukuba, 305-8573, Japan?
?
?Graduate School of Engineering, Nagoya UniversityFuro-cho, Chikusa-ku, Nagoya 464-8603, JapanAbstractThis paper studies issues related to thecompilation of a bilingual lexicon for tech-nical terms.
In the task of estimating bilin-gual term correspondences of technicalterms, it is usually rather difficult to findan existing corpus for the domain of suchtechnical terms.
In this paper, we adoptan approach of collecting a corpus for thedomain of such technical terms from theWeb.
As a method of translation esti-mation for technical terms, we employ acompositional translation estimation tech-nique.
This paper focuses on quantita-tively comparing variations of the compo-nents in the scoring functions of composi-tional translation estimation.
Through ex-perimental evaluation, we show that thedomain/topic-specific corpus contributestoward improving the performance of thecompositional translation estimation.1 IntroductionThis paper studies issues related to the compilationof a bilingual lexicon for technical terms.
Thusfar, several techniques of estimating bilingual termcorrespondences from a parallel/comparable cor-pus have been studied (Matsumoto and Utsuro,2000).
For example, in the case of estimation fromcomparable corpora, (Fung and Yee, 1998; Rapp,1999) proposed standard techniques of estimatingbilingual term correspondences from comparablecorpora.
In their techniques, contextual similaritybetween a source language term and its translationcandidate is measured across the languages, andall the translation candidates are re-ranked accord-ing to their contextual similarities.
However, thereare limited number of parallel/comparable corporathat are available for the purpose of estimatingbilingual term correspondences.
Therefore, evenif one wants to apply those existing techniques tothe task of estimating bilingual term correspon-dences of technical terms, it is usually rather dif-ficult to find an existing corpus for the domain ofsuch technical terms.On the other hand, compositional translation es-timation techniques that use a monolingual corpus(Fujii and Ishikawa, 2001; Tanaka and Baldwin,2003) are more practical.
It is because collecting amonolingual corpus is less expensive than collect-ing a parallel/comparable corpus.
Translation can-didates of a term can be compositionally generatedby concatenating the translation of the constituentsof the term.
Here, the generated translation candi-dates are validated using the domain/topic-specificcorpus.In order to assess the applicability of the com-positional translation estimation technique, werandomly pick up 667 Japanese and English tech-nical term translation pairs of 10 domains from ex-isting technical term bilingual lexicons.
We thenmanually examine their compositionality, and findout that 88% of them are actually compositional,which is a very encouraging result.But still, it is expensive to collect adomain/topic-specific corpus.
Here, we adoptan approach of using the Web, since documentsof various domains/topics are available on theWeb.
When validating translation candidatesusing the Web, roughly speaking, there exist thefollowing two approaches.
In the first approach,translation candidates are validated throughthe search engine (Cao and Li, 2002).
In thesecond approach, a domain/topic-specific corpusis collected from the Web in advance and fixed11collecting termsof specificdomain/topic(language S )XSU (# of translationsis one)compiled bilingual lexiconprocess datacollectingcorpus(language T )domain/topicspecificcorpus(language T )sample termsof specificdomain/topic(language S )XSTU , XSTM ,YSTestimating bilingual termcorrespondenceslanguage pair (S,T )term set(language S )XTU(lang.
T )translation set(language T )web(language S )web(language S )existingbilingual lexiconXSM (# of translationsis more than one)YS (# of translationsis zero)web(language T )web(language T )looking upbilingual lexiconvalidatingtranslationcandidatesweb(language T )web(language T )Figure 1: Compilation of a Domain/Topic-Specific Bilingual Lexicon using the Webbefore translation estimation, then generatedtranslation candidates are validated against thedomain/topic-specific corpus (Tonoike et al,2005).
The first approach is preferable in terms ofcoverage, while the second is preferable in termsof computational efficiency.
This paper mainlyfocuses on quantitatively comparing the twoapproaches in terms of coverage and precision ofcompositional translation estimation.More specifically, in compositional translationestimation, we decompose the scoring functionof a translation candidate into two components:bilingual lexicon score and corpus score.
In thispaper, we examine variants for those componentsand define 9 types of scoring functions in total.Regarding the above mentioned two approachesto validating translation candidates using the Web,the experimental result shows that the secondapproach outperforms the first when the correcttranslation does exist in the corpus.
Furthermore,we examine the methods that combine two scor-ing functions based on their agreement.
The ex-perimental result shows that it is quite possible toachieve precision much higher than those of singlescoring functions.2 Overall frameworkThe overall framework of compiling a bilinguallexicon from the Web is illustrated as in Figure 1.Suppose that we have sample terms of a specificdomain/topic, then the technical terms that are tobe listed as the headwords of a bilingual lexiconare collected from the Web by the related term col-lection method of (Sato and Sasaki, 2003).
Thesecollected technical terms can be divided into threesubsets depending on the number of translationcandidates present in an existing bilingual lexicon,i.e., the subset XUS of terms for which the numberof translations in the existing bilingual lexicon isone, the subset XMS of terms for which the numberof translations is more than one, and the subset YSof terms that are not found in the existing bilinguallexicon (henceforth, the union XUS ?
XMS will bedenoted as XS).
Here, the translation estimationtask here is to estimate translations for the termsof the subsets XMS and YS .
A new bilingual lex-icon is compiled from the result of the translationestimation for the terms of the subsets XMS andYS as well as the translation pairs that consist ofthe terms of the subset XUS and their translationsfound in the existing bilingual lexicon.For the terms of the subset XMS , it is requiredthat an appropriate translation is selected fromamong the translation candidates found in the ex-isting bilingual lexicon.
For example, as a trans-lation of the Japanese technical term ????
?,?which belongs to the logic circuit domain, the term?register?
should be selected but not the term ?reg-ista?
of the football domain.
On the other hand, forthe terms of YS , it is required that the translationcandidates are generated and validated.
In this pa-per, out of the above two tasks, we focus on thelatter of translation candidate generation and val-idation using the Web.
As we introduced in theprevious section, here we experimentally comparethe two approaches to validating translation candi-dates.
The first approach directly uses the searchengine, while the second uses the domain/topic-specific corpus, which is collected in advance fromthe Web.
Here, in the second approach, we use theterm of XUS , which has only one translation in theexisting bilingual lexicon.
The set of translationsof the terms of the subset XUS is denoted as XUT .Then, in the second approach, the domain/topic-specific corpus is collected from the Web using theterms of the set XUT .3 Compositional Translation Estimationfor Technical Terms3.1 OverviewAn example of compositional translation estima-tion for the Japanese technical term ????????
is illustrated in Figure 2.
First, the Japanesetechnical term ????????
is decomposedinto its constituents by consulting an existingbilingual lexicon and retrieving Japanese head-12?
application(1)?
practical(0.3)?
applied(1.6)?
action(1)?
activity(1)?
behavior(1)?
analysis(1)?
diagnosis(1)?
assay(0.3)?
behavior analysis(10)?
?Compositional generationof translation candidate?
applied behavior analysis(17.6)?
application behavior analysis(11)?
applied behavior diagnosis(1)?
?Decompose source term into constituents?
?Translate constituents into target language      process??
??
??a??
???
?bGenerated translation candidates?(1.6?1?1)+(1.6?10)?
application(1)?
practical(0.3)?
applied(1.6)Figure 2: Compositional Translation Estimationfor the Japanese Technical Term ???????
?words.1 In this case, the result of this decompo-sition can be given as in the cases ?a?
and ?b?
(in Figure 2).
Then, each constituent is translatedinto the target language.
A confidence score is as-signed to the translation of each constituent.
Fi-nally, translation candidates are generated by con-catenating the translation of those constituents ac-cording to word ordering rules considering prepo-sitional phrase construction.3.2 Collecting a Domain/Topic-SpecificCorpusWhen collecting a domain/topic-specific corpus ofthe language T , for each technical term xUT in theset XUT , we collect the top 100 pages obtainedfrom search engine queries that include the termxUT .
Our search engine queries are designed suchthat documents that describe the technical term xUTare ranked high.
For example, an online glossaryis one such document.
When collecting a Japanesecorpus, the search engine ?goo?2 is used.
The spe-cific queries that are used in this search engineare phrases with topic-marking postpositional par-ticles such as ?xUT ??,?
?xUT ???,?
?xUT ?,?and an adnominal phrase ?xUT ?,?
and ?xUT .
?3.3 Translation Estimation3.3.1 Compiling Bilingual ConstituentsLexiconsThis section describes how to compile bilingualconstituents lexicons from the translation pairs of1Here, as an existing bilingual lexicon, we use Ei-jiro(http://www.alc.co.jp/) and bilingual constituents lexiconscompiled from the translation pairs of Eijiro (details to be de-scribed in the next section).2http://www.goo.ne.jp/ applied mathematics : ??
?
?applied science : ??
?
?applied robot : ??
????...
frequency?
?
?applied : ??
: 40 Figure 3: Example of Estimating Bilingual Con-stituents Translation Pair (Prefix)the existing bilingual lexicon Eijiro.
The under-lying idea of augmenting the existing bilinguallexicon with bilingual constituents lexicons is il-lustrated in Figure 3.
Suppose that the existingbilingual lexicon does not include the translationpair ?applied : ??,?
while it includes manycompound translation pairs with the first Englishword ?applied?
and the first Japanese word ???.
?3 In such a case, we align those translationpairs and estimate a bilingual constituent transla-tion pair which is to be collected into a bilingualconstituents lexicon.More specifically, from the existing bilinguallexicon, we first collect translation pairs whoseEnglish terms and Japanese terms consist of twoconstituents into another lexicon P2.
We com-pile the ?bilingual constituents lexicon (prefix)?from the first constituents of the translation pairsin P2and compile the ?bilingual constituents lex-icon (suffix)?
from their second constituents.
Thenumber of entries in each language and those ofthe translation pairs in these lexicons are shown inTable 1.The result of our assessment reveals that only48% of the 667 translation pairs mentioned in Sec-tion 1 can be compositionally generated by usingEijiro, while the rate increases up to 69% usingboth Eijiro and ?bilingual constituents lexicons.
?43.3.2 Score of Translation CandidatesThis section gives the definition of the scoresof a translation candidate in compositional trans-lation estimation.First, let ys be a technical term whose transla-tion is to be estimated.
We assume that ys is de-3Japanese entries are supposed to be segmented into asequence of words by the morphological analyzer JUMAN(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html).4In our rough estimation, the upper bound of this rateis approximately 80%.
An improvement from 69% to 80%could be achieved by extending the bilingual constituents lex-icons.13Table 1: Numbers of Entries and Translation Pairsin the Lexiconslexicon # of entries # of translationEnglish Japanese pairsEijiro 1,292,117 1,228,750 1,671,230P2217,861 186,823 235,979BP37,090 34,048 95,568BS20,315 19,345 62,419B 48,000 42,796 147,848Eijiro : existing bilingual lexiconP2: entries of Eijiro with two constituentsin both languagesBP: bilingual constituents lexicon (prefix)BS: bilingual constituents lexicon (suffix)B : bilingual constituents lexicon (merged)composed into their constituents as below:ys = s1, s2, ?
?
?
, sn (1)where each si is a single word or a sequence ofwords.5 For ys, we denote a generated translationcandidate as yt.yt = t1, t2, ?
?
?
, tn (2)where each ti is a translation of si.
Then the trans-lation pair ?ys, yt?
is represented as follows.
?ys, yt?
= ?s1, t1?, ?s2, t2?, ?
?
?
, ?sn, tn?
(3)The score of a generated translation candidate isdefined as the product of a bilingual lexicon scoreand a corpus score as follows.Q(ys, yt) = Qdict(ys, yt) ?
Qcoprus(yt) (4)Bilingual lexicon score measures appropriatenessof correspondence of ys and yt.
Corpus scoremeasures appropriateness of the translation candi-date yt based on the target language corpus.
If atranslation candidate is generated from more thanone sequence of translation pairs, the score of thetranslation candidate is defined as the sum of thescore of each sequence.Bilingual Lexicon ScoreIn this paper, we compare two types of bilin-gual lexicon scores.
Both scores are defined as theproduct of scores of translation pairs included inthe lexicons presented in the previous section asfollows.5Eijiro has both single word entries and compound wordentries.?
Frequency-LengthQdict(ys, yt) =n?i=1q(?si, ti?)
(5)The first type of bilingual lexicon scores is re-ferred to as ?Frequency-Length.?
This score isbased on the length of translation pairs and the fre-quencies of translation pairs in the bilingual con-stituent lexicons (prefix,suffix) BP , BS in Table 1.In this paper, we first assume that the translationpairs follow certain preference rules and that theycan be ordered as below:1.
Translation pairs ?s, t?
in the existing bilin-gual lexicon Eijiro, where the term s consistsof two or more constituents.2.
Translation pairs in the bilingual constituentslexicons whose frequencies in P2are high.3.
Translation pairs ?s, t?
in the existing bilin-gual lexicon Eijiro, where the term s consistsof exactly one constituent.4.
Translation pairs in the bilingual constituentslexicons whose frequencies in P2are nothigh.As the definition of the confidence scoreq(?s, t?)
of a translation pair ?s, t?, we use the fol-lowing:q(?s, t?)
=??
?10(compo(s)?1) (?s, t?
in Eijiro)log10fp(?s, t?)
(?s, t?
in BP )log10fs(?s, t?)
(?s, t?
in BS)(6), where compo(s) denotes the word count of s,fp(?s, t?)
represents the frequency of ?s, t?
as thefirst constituent in P2, and fs(?s, t?)
represents thefrequency of ?s, t?
as the second constituent in P2.?
ProbabilityQdict(ys, yt) =n?i=1P (si|ti) (7)The second type of bilingual lexicon scores is re-ferred to as ?Probability.?
This score is calcu-lated as the product of the conditional probabili-ties P (si|ti).
P (s|t) is calculated using bilinguallexicons in Table 1.P (s|t) =fprob(?s, t?
)?sjfprob(?sj , t?
)(8)14Table 2: 9 Scoring Functions of Translation Candidates and their Componentsbilingual lexicon score corpus score corpusscore ID freq-length probability probability frequency occurrence off-line on-line(search engine)A prune/final prune/final oB prune/final prune/final oC prune/final prune/final oD prune/final prune oE prune/finalF prune/final final prune oG prune/final prune/final oH prune/final final oI prune/final final ofprob(?s, t?)
denotes the frequency of the transla-tion pair ?s, t?
in the bilingual lexicons as follows:fprob(?s, t?)
={10 (?s, t?
in Eijiro)fB(?s, t?)
(?s, t?
in B)(9)Note that the frequency of a translation pair in Ei-jiro is regarded as 106 and fB(?s, t?)
denotes thefrequency of the translation pair ?s, t?
in the bilin-gual constituent lexicon B.Corpus ScoreWe evaluate three types of corpus scores as fol-lows.?
Probability: the occurrence probability of ytestimated by the following bi-gram modelQcorpus(yt) = P (t1) ?n?i=1P (ti+1|ti) (10)?
Frequency: the frequency of a translationcandidate in a target language corpusQcorpus(yt) = freq(yt) (11)?
Occurrence: whether a translation candidateoccurs in a target language corpus or notQcorpus(yt) =????
?1 yt occurs in a corpus0 yt does not occurin a corpus(12)6It is necessary to empirically examine whether or not thedefinition of the frequency of a translation pair in Eijiro isappropriate.Variation of the total scoring functionsAs shown in Table 2, in this paper, we examinethe 9 combinations of the bilingual lexicon scoresand the corpus scores.
In the table, ?prune?
indi-cates that the score is used for ranking and pruningsub-sequences of generated translation candidatesin the course of generating translation candidatesusing a dynamic programming algorithm.
?Final?indicates that the score is used for ranking the fi-nal outputs of generating translation candidates.In the column ?corpus?, ?off-line?
indicates thata domain/topic-specific corpus is collected fromthe Web in advance and then generated transla-tion candidates are validated against this corpus.?On-line?
indicates that translation candidates aredirectly validated through the search engine.Roughly speaking, the scoring function ?A?
cor-responds to a variant of the model proposed by(Fujii and Ishikawa, 2001).
The scoring func-tion ?D?
is a variant of the model proposed by(Tonoike et al, 2005) and ?E?
corresponds to thebilingual lexicon score of the scoring function ?D?.The scoring function ?I?
is intended to evaluate theapproach proposed in (Cao and Li, 2002).3.3.3 Combining Two Scoring Functionsbased on their AgreementIn this section, we examine the method thatcombines two scoring functions based on theiragreement.
The two scoring functions are selectedout of the 9 functions introduced in the previoussection.
In this method, first, confidence of trans-lation candidates of a technical term are measuredby the two scoring functions.
Then, if the firstranked translation candidates of both scoring func-tions agree, this method outputs the agreed trans-lation candidate.
The purpose of introducing thismethod is to prefer precision to recall.15collecting termsof specificdomain/topic(language S )XSU (# of translationsis one)compiled bilingual lexiconprocess datacollectingcorpus(language T )sample termsof specificdomain/topic(language S )XSTU , XSTM ,YSTestimating bilingual termcorrespondenceslanguage pair (S,T )term set(language S )XTU(lang.
T )translation set(language T )web(language S )web(language S )existingbilingual lexiconXSM (# of translationsis more than one)YS (# of translationsis zero)web(language T )web(language T )looking upbilingual lexicondomain/topicspecificcorpus(language T )validatingtranslationcandidatesweb(language T )web(language T )Figure 4: Experimental Evaluation of TranslationEstimation for Technical Terms with/without theDomain/Topic-Specific Corpus (taken from Fig-ure 1)4 Experiments and Evaluation4.1 Translation Pairs for EvaluationIn our experimental evaluation, within the frame-work of compiling a bilingual lexicon for techni-cal terms, we evaluate the translation estimationportion that is indicated by the bold line in Fig-ure 4.
In this paper, we simply omit the evalua-tion of the process of collecting technical terms tobe listed as the headwords of a bilingual lexicon.In order to evaluate the translation estimation por-tion, terms are randomly selected from the 10 cate-gories of existing Japanese-English technical termdictionaries listed in Table 3, for each of the sub-sets XUS and YS (here, the terms of YS that consistof only one word or morpheme are excluded).
Asdescribed in Section 1, the terms of the set XUT (theset of translations for the terms of the subset XUS )is used for collecting a domain/topic-specific cor-pus from the Web.
As shown in Table 3, size of thecollected corpora is 48MB on the average.
Trans-lation estimation evaluation is to be conducted forthe subset YS .
For each of the 10 categories, Ta-ble 3 shows the sizes of the subsets XUS and YS ,and the rate of including correct translation withinthe collected domain/topic-specific corpus for YS .In the following, we show the evaluation resultswith the source language S as English and the tar-get language T as Japanese.4.2 Evaluation of single scoring functionsThis section gives the results of evaluating singlescoring functions A ?
I listed in Table 2.Table 4 shows three types of experimental re-sults.
The column ?the whole set YS?
shows theresults against the whole set YS .
The column?generatable?
shows the results against the trans-lation pairs in YS that can be generated throughthe compositional translation estimation process.69% of the terms in ?the whole set YS?
belongsto the set ?generatable?.
The column ?gene.-exist?shows the result against the source terms whosecorrect translations do exist in the corpus and thatcan be generated through the compositional trans-lation estimation process.
50% of the terms in ?thewhole set YS?
belongs to the set ?gene.-exist?.
Thecolumn ?top 1?
shows the correct rate of the firstranked translation candidate.
The column ?top 10?shows the rate of including the correct candidatewithin top 10.First, in order to evaluate the effectiveness ofthe approach of validating translation candidatesby using a target language corpus, we compare thescoring functions ?D?
and ?E?.
The difference be-tween them is whether or not they use a corpusscore.
The results for the whole set YS show thatusing a corpus score, the precision improves from33.9% to 43.0%.
This result supports the effec-tiveness of the approach of validating translationcandidates using a target language corpus.As can be seen from these results for the wholeset YS , the correct rate of the scoring function ?I?that directly uses the web search engine in the cal-culation of its corpus score is higher than thoseof other scoring functions that use the collecteddomain/topic-specific corpus.
This is because,for the whole set YS , the rate of including cor-rect translation within the collected domain/topic-specific corpus is 72% on the average, which isnot very high.
On the other hand, the results of thecolumn ?gene.-exist?
show that if the correct trans-lation does exist in the corpus, most of the scor-ing functions other than ?I?
can achieve precisionshigher than that of the scoring function ?I?.
Thisresult supports the effectiveness of the approachof collecting a domain/topic-specific corpus fromthe Web in advance and then validating generatedtranslation candidates against this corpus.4.3 Evaluation of combining two scoringfunctions based on their agreementThe result of evaluating the method that combinestwo scoring functions based on their agreement isshown in Table 5.
This result indicates that com-binations of scoring functions with ?off-line?/?on-16Table 3: Number of Translation Pairs for Evaluation (S=English)dictionaries categories |YS| |XUS| corpus size C(S)Electromagnetics 33 36 28MB 85%McGraw-Hill Electrical engineering 45 34 21MB 71%Optics 31 42 37MB 65%Iwanami Programming language 29 37 34MB 93%Programming 29 29 33MB 97%Dictionary of (Computer) 100 91 67MB 51%ComputerAnatomical Terms 100 91 73MB 86%Dictionary of Disease 100 91 83MB 77%250,000 Chemicals and Drugs 100 94 54MB 60%medical terms Physical Science and Statistics 100 88 56MB 68%Total 667 633 482MB 72%McGraw-Hill : Dictionary of Scientific and Technical TermsIwanami : Encyclopedic Dictionary of Computer ScienceC(S) : for YS, the rate of including correct translations within the collected domain/topic-specific corpusTable 4: Result of Evaluating single Scoring Functionsthe whole set YS(667 terms?100%) generatable (458 terms?69%) gene.-exist (333 terms?50%)ID top 1 top 10 top 1 top 10 top 1 top 10A 43.8% 52.9% 63.8% 77.1% 82.0% 98.5%B 42.9% 50.7% 62.4% 73.8% 83.8% 99.4%C 43.0% 58.0% 62.7% 84.5% 75.1% 94.6%D 43.0% 47.4% 62.7% 69.0% 85.9% 94.6%E 33.9% 57.3% 49.3% 83.4% 51.1% 84.1%F 40.2% 47.4% 58.5% 69.0% 80.2% 94.6%G 39.1% 46.8% 57.0% 68.1% 78.1% 93.4%H 43.8% 57.3% 63.8% 83.4% 73.6% 84.1%I 49.8% 57.3% 72.5% 83.4% 74.8% 84.1%Table 5: Result of combining two scoring func-tions based on their agreementcorpus combination precision recall F?=1A & I 88.0% 27.6% 0.420off-line/ D & I 86.0% 29.5% 0.440on-line F & I 85.1% 29.1% 0.434H & I 58.7% 37.5% 0.457A & H 86.0% 30.4% 0.450F & H 80.6% 33.7% 0.476off-line/ D & H 80.4% 32.7% 0.465off-line A & D 79.0% 32.1% 0.456A & F 74.6% 33.0% 0.457D & F 68.2% 35.7% 0.469line?
corpus tend to achieve higher precisions thanthose with ?off-line?/?off-line?
corpus.
This resultalso shows that it is quite possible to achieve highprecisions even by combining scoring functionswith ?off-line?/?off-line?
corpus (the pair ?A?
and?H?).
Here, the two scoring functions ?A?
and ?H?are the one with frequency-based scoring func-tions and that with probability-based scoring func-tions, and hence, have quite different nature in thedesign of their scoring functions.5 Related WorksAs a related work, (Fujii and Ishikawa, 2001) pro-posed a technique for compositional estimation ofbilingual term correspondences for the purpose ofcross-language information retrieval.
One of themajor differences between the technique of (Fu-jii and Ishikawa, 2001) and the one proposed inthis paper is that in (Fujii and Ishikawa, 2001), in-stead of a domain/topic-specific corpus, they use acorpus containing the collection of technical pa-pers, each of which is published by one of the65 Japanese associations for various technical do-mains.
Another significant difference is that in(Fujii and Ishikawa, 2001), they evaluate only theperformance of the cross-language information re-trieval and not that of translation estimation.
(Cao and Li, 2002) also proposed a methodof compositional translation estimation for com-pounds.
In the method of (Cao and Li, 2002), thetranslation candidates of a term are composition-ally generated by concatenating the translation ofthe constituents of the term and are validated di-rectly through the search engine.
In this paper,we evaluate the approach proposed in (Cao andLi, 2002) by introducing a total scoring function17that is based on validating translation candidatesdirectly through the search engine.6 ConclusionThis paper studied issues related to the compila-tion a bilingual lexicon for technical terms.
Inthe task of estimating bilingual term correspon-dences of technical terms, it is usually rather dif-ficult to find an existing corpus for the domainof such technical terms.
In this paper, we adoptan approach of collecting a corpus for the do-main of such technical terms from the Web.
Asa method of translation estimation for technicalterms, we employed a compositional translationestimation technique.
This paper focused on quan-titatively comparing variations of the componentsin the scoring functions of compositional transla-tion estimation.
Through experimental evaluation,we showed that the domain/topic specific corpuscontributes to improving the performance of thecompositional translation estimation.Future work includes complementally integrat-ing the proposed framework of compositionaltranslation estimation using the Web with othertranslation estimation techniques.
One of them isthat based on collecting partially bilingual textsthrough the search engine (Nagata and others,2001; Huang et al, 2005).
Another techniquewhich seems to be useful is that of transliterationof names (Knight and Graehl, 1998; Oh and Choi,2005).ReferencesY.
Cao and H. Li.
2002.
Base noun phrase translation usingWeb data and the EM algorithm.
In Proc.
19th COLING,pages 127?133.A.
Fujii and T. Ishikawa.
2001.
Japanese/english cross-language information retrieval: Exploration of querytranslation and transliteration.
Computers and the Hu-manities, 35(4):389?420.P.
Fung and L. Y. Yee.
1998.
An IR approach for translatingnew words from nonparallel, comparable texts.
In Proc.17th COLING and 36th ACL, pages 414?420.F.
Huang, Y. Zhang, and S. Vogel.
2005.
Mining key phrasetranslations from web corpora.
In Proc.
HLT/EMNLP,pages 483?490.K.
Knight and J. Graehl.
1998.
Machine transliteration.Computational Linguistics, 24(4):599?612.Y.
Matsumoto and T. Utsuro.
2000.
Lexical knowledge ac-quisition.
In R. Dale, H. Moisl, and H. Somers, editors,Handbook of Natural Language Processing, chapter 24,pages 563?610.
Marcel Dekker Inc.M.
Nagata et al 2001.
Using the Web as a bilingual dictio-nary.
In Proc.
ACL-2001 Workshop on Data-driven Meth-ods in Machine Translation, pages 95?102.J.
Oh and K. Choi.
2005.
Automatic extraction of english-korean translations for constituents of technical terms.
InProc.
2nd IJCNLP, pages 450?461.R.
Rapp.
1999.
Automatic identification of word translationsfrom unrelated English and German corpora.
In Proc.37th ACL, pages 519?526.S.
Sato and Y. Sasaki.
2003.
Automatic collection of relatedterms from the web.
In Proc.
41st ACL, pages 121?124.T.
Tanaka and T. Baldwin.
2003.
Translation selection forjapanese-english noun-noun compounds.
In Proc.
Ma-chine Translation Summit IX, pages 378?85.M.
Tonoike, M. Kida, T. Takagi, Y. Sasaki, T. Utsuro, andS.
Sato.
2005.
Effect of domain-specific corpus in com-positional translation estimation for technical terms.
InProc.
2nd IJCNLP, Companion Volume, pages 116?121.18
