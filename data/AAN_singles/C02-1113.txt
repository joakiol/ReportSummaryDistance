Natural Language and Inference in a Computer GameMalte Gabsdil and Alexander Koller and Kristina StriegnitzDept.
of Computational LinguisticsSaarland University, Saarbru?cken, Germany{gabsdil|koller|kris}@coli.uni-sb.deAbstractWe present an engine for text adventures ?
computergames with which the player interacts using natu-ral language.
The system employs current meth-ods from computational linguistics and an efficientinference system for description logic to make theinteraction more natural.
The inference system isespecially useful in the linguistic modules dealingwith reference resolution and generation and weshow how we use it to rank different readings inthe case of referential and syntactic ambiguities.
Itturns out that the player?s utterances are naturallyrestricted in the game scenario, which simplifies thelanguage processing task.1 IntroductionText adventures are computer games with whichthe player interacts via a natural language dialogue.Texts describe the game world and how it evolves,and the player can manipulate objects in this gameworld by typing in commands; Fig.
1 shows a sam-ple interaction.
Text adventures were very popu-lar and commercially successful in the eighties, buthave gone out of fashion since then ?
mostly be-cause the parsers were rather limited and forced theuser into very restricted forms of interaction.We describe an engine for text adventures thatattempts to overcome these limitations by usingcurrent methods from computational linguistics forprocessing the natural language input and output,and a state-of-the-art inference system based on de-scription logic (DL) to represent the dynamic stateof the game world and what the player knows aboutit.
The DL prover is used in all language-processingmodules except for parsing and surface realization,and supports the inferences we need very well.This shows in particular in the modules for theresolution and generation of referring expressions.By keeping track of the true state of the worldand the player?s knowledge in separate knowledgebases, we can evaluate definite descriptions with re-spect to what the player knows.
In generation, suchinferences allow us to produce smaller while stillsufficiently informative references.Another interesting aspect which we discuss inthis paper is the treatment of syntactic and referen-tial ambiguities that come up in understanding inputsentences.
Here, too, the player knowledge restrictsthe way in which the input should be interpreted andguides the resolution process.
We use inferencesabout the player knowledge to rule out inconsistentanalyses and pragmatic heuristics to possibly selectthe preferred one.Players of a text adventure are effectively situ-ated in a game world and have to accomplish aspecific task, which severely restricts the utterancesthey will naturally produce.
For example, they willtypically only refer to objects they could ?see?
inthe simulated world.
This simplifies the languageprocessing tasks tremendously.
The scenario of thegame can be freely specified and tailored to differentapplications and levels of complexity.
Along withthe modularity of our implementation, this makesour system an interesting testbed for evaluatingmore sophisticated NLP modules, which also haveaccess to the inference infrastructure.
The same rea-son makes it useful as a teaching tool; in fact, ourimplementation was created as an advanced projectfor students.Plan of the paper.
We will start with an overviewover the architecture of our system in Section 2.Section 3 will give a brief introduction to descrip-tion logics, and then describes the knowledge baseswe use.
We will discuss how they interact with thelinguistic modules in Section 4, which focuses onthe resolution and generation of referring expres-sions.
Section 5 deals with the resolution of am-biguities in the player input.
Finally, Section 6 con-cludes and points to further research.2 ArchitectureThe general architecture of the game engine, shownin Fig.
2, consists of a number of language-processing modules (drawn as ellipses), which in-Observation LoungeThis is where the station staff and visitors come to relax.
There are a lot of tablesand chairs here, a large observation window, and a plush carpet.
In the corner you cansee an AstroCola dispenser.
A tube leads up to the station?s main corridor.> put my galakmid coin into the dispenserClick.The dispenser display now reads "Credit = 1.00".> push diet astrocola buttonYou hear a rumbling noise in the dispenser, but nothing appears in the tray.> kick dispenserA can drops into the tray.
Amazing!
The oldest trick in the book, and itactually worked.Figure 1: An example interaction with a text adventure, taken from (Ledgard, 1999).ContentDeterminationModelDiscourseReferenceResolutionReferenceGenerationRealizationParsingActionsA-Box: User KnowledgeT-BoxA-Box: World ModelFigure 2: The architecture.terface with knowledge bases and a discourse model(drawn as rectangles).
There are two separateknowledge bases, which share a set of common def-initions: One represents the true state of the worldin a world model, the other keeps track of what theplayer knows about the world.
Solid arrows indi-cate the general flow of information, dashed arrowsindicate access to the knowledge bases.The user?s input is first parsed using an efficientparser for dependency grammar (Duchier and De-busmann, 2001).
Next, referring expressions are re-solved to individuals in the game world.
The resultis a ground term or a sequence of ground terms thatindicates the action(s) the user wants to take.
TheActions module looks up these actions in a database(where they are specified in a STRIPS-like format),checks whether the action?s preconditions are met inthe world, and, if yes, updates the world state withthe effects of the action.The action can also specify effects on the user?sknowledge.
This information is further enrichedby the Content Determination module; for example,this module computes detailed descriptions of ob-jects the player wants to look at.
The ReferenceGeneration module translates the internal namesof individuals into descriptions that can be verbal-ized.
In the last step, an efficient realization mod-ule (Koller and Striegnitz, 2002) builds the outputsentences according to a TAG grammar.
The playerknowledge is updated after Reference Generationwhen the content of the game?s response, includingthe new information carried e.g.
by indefinite NPs,is fully established.If an error occurs at any stage, e.g.
because a pre-condition of the action fails, an error message spec-ifying the reasons for the failure is generated byusing the normal generation track (Content Deter-mination, Reference Generation, Realization) of thegame.The system is implemented in the programminglanguage Mozart (Mozart Consortium, 1999) andprovides an interface to the DL reasoning systemRACER (Haarslev and Mo?ller, 2001), which is usedfor mainting and accessing the knowledge bases.3 The World ModelNow we will look at the way that the state of theworld is represented in the game, which will beimportant in the language processing modules de-scribed in Sections 4 and 5.
We will first give a shortoverview of description logic (DL) and the theoremprover we use and then discuss some aspects of theworld model in more detail.3.1 Description LogicDescription logic (DL) is a family of logics in thetradition of knowledge representation formalismssuch as KL-ONE (Woods and Schmolze, 1992).
DLis a fragment of first-order logic which only allowsunary and binary predicates (concepts and roles)and only very restricted quantification.
A knowl-edge base consists of a T-Box, which contains ax-ioms relating the concepts and roles, and one ormore A-Boxes, which state that individuals belongto certain concepts, or are related by certain roles.Theorem provers for description logics supporta range of different reasoning tasks.
Among themost common are consistency checking, subsump-tion checking, and instance and relation check-ing.
Consistency checks decide whether a combina-tion of T-Box and A-Box can be satisfied by somemodel, subsumption is to decide of two conceptswhether all individuals that belong to one conceptmust necessarily belong to another, and instance andrelation checking test whether an individual belongsto a certain concept and whether a certain relationholds between a pair of individuals, respectively.
Inaddition to these basic reasoning tasks, descriptionlogic systems usually also provide some retrievalfunctionality which e.g.
allows to compute all con-cepts that a given individual belongs to or all indi-viduals that belong to a given concept.There is a wide range of different description log-ics today which add different extensions to a com-mon core.
Of course, the more expressive these ex-tensions become, the more complex the reasoningproblems are.
?Traditional?
DL systems have con-centrated on very weak logics with simple reasoningtasks.
In the last few years, however, new systemssuch as FaCT (Horrocks et al, 1999) and RACER(Haarslev and Mo?ller, 2001) have shown that it ispossible to achieve surprisingly good average-caseperformance for very expressive (but still decidable)logics.
In this paper, we employ the RACER sys-tem, mainly because it allows for A-Box inferences.3.2 The World ModelThe T-Box we use in the game specifies the con-cepts and roles in the world and defines some usefulcomplex concepts, e.g.
the concept of all objects theplayer can see.
This T-Box is shared by two differ-ent A-Boxes representing the state of the world andwhat the player knows about it respectively.The player A-Box will typically be a sub-part ofthe game A-Box because the player will not haveexplored the world completely and will thereforenot have encountered all individuals or know aboutall of their properties.
Sometimes, however, it mayalso be useful to deliberately hide effects of an ac-tion from the user, e.g.
if pushing a button has aneffect in a room that the player cannot see.
In thiscase, the player A-Box can contain information thatis inconsistent with the world A-Box.A fragment of the A-Box describing the state ofthe world is shown in Fig.
3; Fig.
4 gives a graphicalrepresentation.
The T-Box specifies that the worldis partitioned into three parts: rooms, objects, andplayers.
The individual ?myself?
is the only instancethat we ever define of the concept ?player?.
Indi-viduals are connected to their locations (i.e.
rooms,container objects, or players) via the ?has-location?role; the A-Box also specifies what kind of objectan individual is (e.g.
?apple?)
and what properties ithas (?red?).
The T-Box then contains axioms suchas ?apple  object?, ?red  colour?, etc., which es-tablish a taxonomy among concepts.These definitions allow us to add axioms to theT-Box which define more complex concepts.
Oneis the concept ?here?, which contains the room inwhich the player currently is ?
that is, every indi-vidual which can be reached over a ?has-location?role from a player object.here .= ?has-location?1.playerIn this definition, ?has-location?1?
is the inverse roleof the role ?has-location?, i.e.
it links a and b iff?has-location?
links b and a. Inverse roles are one ofthe constructions available in more expressive de-scription logics.
The quantification builds a morecomplex concept from a concept and a role: ?R.Cis the concept containing all individuals which arelinked via an R role to some individual in C .
In theexample in Fig.
3, ?here?
denotes the singleton set{kitchen}.Another useful concept is ?accessible?, whichcontains all individuals which the player can ma-nipulate.accessible .= ?has-location.here unionsq?has-location.
(accessible  open)All objects in the same room as the player areaccessible; if such an object is an open container,its contents are also accessible.
The T-Box con-tains axioms that express that some concepts (e.g.
?table?, ?bowl?, and ?player?)
contain only ?open?room(kitchen) player(myself)table(t1) apple(a1)apple(a2) worm(w1)red(a1) green(a2)bowl(b1) bowl(b2)has-location(t1, kitchen) has-location(b1, t1)has-location(b2, kitchen) has-location(a1, b2)has-location(a2, kitchen) has-detail(a2,w1)has-location(myself, kitchen) .
.
.Figure 3: A fragment of a world A-Box.objects.
This permits access to the player?s inven-tory.
In the simple scenario above, ?accessible?
de-notes the set {myself, t1, a1, a2, b1, b2}.
Finally,we can define the concept ?visible?
in a similar wayas ?accessible?.
The definition is a bit more com-plex, including more individuals, and is intended todenote all individuals that the player can ?see?
fromhis position in the game world.14 Referring ExpressionsThe interaction between the game and the player re-volves around performing actions on objects in thegame world and the effects that these actions haveon the objects.
This means that the resolution andgeneration of referring expressions, which identifythose objects to the user, are central tasks in our ap-plication.Our implementation illustrates how useful theavailability of an inference system as provided byRACER to access the world model is, once such aninfrastructure is available.
The inference engine iscomplemented by a simple discourse model, whichkeeps track of available referents.4.1 The Discourse ModelOur discourse model (DM) is based on Strube?s(1998) salience list approach, due to its simplic-ity.
The DM is a data structure that stores an or-dered list of the most salient discourse entities ac-cording to their ?information status?
and text po-sition and provides methods for retrieving and in-serting elements.
Following Strube, hearer-old dis-course entities (which include definites) are ranked1Remember that ?seeing?
in our application does not in-volve any graphical representations.
The player acquiresknowledges about the world only through the textual outputgenerated by the game engine.
This allows us to simplify theDL modeling of the world because we don?t have to specifyall (e.g.
spatial) relations that would implicitly be present in apicture.Figure 4: Example Scenariohigher in the DM (i.e.
are more available for refer-ence) than hearer-new discourse entities (includingindefinites).
Within these categories, elements aresorted according to their position in the currentlyprocessed sentence.
For example, the ranking ofdiscourse entities for the sentence take a banana,the red apple, and the green apple would look asfollows:[red apple ?
green apple]old ?
[banana]newThe DM is built incrementally and updated af-ter each input sentence.
Updating removes all dis-course entities from the DM which are not realizedin the current utterance.
That is, there is an assump-tion that referents mentioned in the previous utter-ance are much more salient than older ones.4.2 Resolving Referring ExpressionsThe task of the resolution module is to map def-inite and indefinite noun phrases and pronouns toindividuals in the world.
This task is simplified inthe adventure setting by the fact that the commu-nication is situated in a sense: Players will typi-cally only refer to objects which they can ?see?
inthe virtual environment, as modeled by the concept?visible?
above.
Furthermore, they should not re-fer to objects they haven?t seen yet.
Hence, weperform all RACER queries in this section on theplayer knowledge A-Box, avoiding unintended am-biguities when the player?s expression would e.g.not refer uniquely with respect to the true state ofthe world.The resolution of a definite description means tofind a unique entity which, according to the player?sknowledge, is visible and matches the description.To compute such an entity, we construct a DL con-cept expression corresponding to the descriptionand then send a query to RACER asking for all in-stances of this concept.
In the case of the apple,for instance, we would retrieve all instances of theconceptapple  visiblefrom the player A-Box.
The query concept for theapple with the worm would beapple  (?has-detail.worm)  visible.If this yields only one entity ({a2} for the apple withthe worm for the A-Box in Fig.
3), the referencehas been unambiguous and we are done.
It may,however, also be the case that more than one entityis returned; e.g.
the query for the apple would returnthe set {a1,a2}.
We will show in the next sectionhow we deal with this kind of ambiguity.
We rejectinput sentences with an error message indicating afailed reference if we cannot resolve an expressionat all, i.e.
when no object in the player knowledgematches the description.We resolve indefinite NPs, such as an apple, byquerying the player knowledge in the same way asdescribed above for definites.
Unlike in the definitecase, however, we do not require unique reference.Instead, we assume that the player did not have aparticular object in mind and arbitrarily choose oneof the possible referents.
The reply of the game willautomatically inform the player which one was cho-sen, as a unique definite reference will be generated(see below).Pronouns are simply resolved to the most saliententity in the DM that matches their agreement con-straints.
The restrictions our grammar imposeson the player input (no embeddings, no reflexivepronouns) allow us to analyze sentences includingintra-sentential anaphora like take the apple and eatit.
The incremental construction of the DM ensuresthat by the time we encounter the pronoun it, theapple has already been processed and can serve as apossible antecedent.4.3 Generating Referring ExpressionsThe converse task occurs when we generate thefeedback to show to the player: It is necessary toconstruct descriptions of individuals in the gameworld that enable the player to identify these.This task is quite simple for objects which arenew to the player.
In this case, we generate an indef-inite NP containing the type and (if it has one) colorof the object, as in the bowl contains a red apple.We use RACER?s retrieval functionality to extractthis information from the knowledge base.To refer to an object that the player already hasencountered, we try to construct a definite descrip-tion that, given the player knowledge, uniquelyidentifies this object.
For this purpose we use a vari-ant of Dale and Reiter?s (1995) incremental algo-rithm, extended to deal with relations between ob-jects (Dale and Haddock, 1991).
The properties ofthe target referent are looked at in some predefinedorder (e.g.
first its type, then its color, its location,parts it may have, .
.
.).
A property is added to thedescription if at least one other object (a distrac-tor) is excluded from it because it doesn?t share thisproperty.
This is done until the description uniquelyidentifies the target referent.The algorithm uses RACER?s reasoning and re-trieval functionality to access the relevant informa-tion about the context, which included e.g.
comput-ing the properties of the target referent and find-ing the distracting instances.
Assuming we want torefer to entity a1 in the A-Box in Fig.
3 e.g., wefirst have to retrieve all concepts and roles of a1from the player A-Box.
This gives us {apple(a1),red(a1), has-location(a1,b1)}.
As we have to have atleast one property specifying the type of a1, we useRACER?s subsumption checks to extract all thoseproperties that match this requirement; in this case,?apple?.
Then we retrieve all instances of the con-cept ?apple?
to determine the set of distractors whichis {a1, a2}.
Hence, ?apple?
alone is not enough touniquely identify a1.
So, we consider the apple?scolor.
Again using subsumption checks, we filterthe colors from the properties of a1 (i.e.
?red?)
andthen retrieve all instances belonging to the conceptapple red to check whether and how the set of dis-tractors gets reduced by adding this property.
Thisconcept has only one member in the example, so wegenerate the expression the red apple.5 Ambiguity ResolutionThe other aspect of the game engine which we wantto highlight here is how we deal with referentialand syntactic ambiguity.
We handle the former bya combination of inference and discourse informa-tion, and the latter by taking psycholinguisticallymotivated preferences into account.5.1 Resolving Referential AmbiguitiesWhen the techniques for reference resolution de-scribed in the previous section are not able to mapa definite description to a single entity in the playerknowledge, the resolution module returns a set ofpossible referents.
We then try to narrow this setdown in two steps.First, we filter out individuals which are com-pletely unsalient according to the discourse model.In our (simplified) model, these are all individualsthat haven?t been mentioned in the previous sen-tence.
This heuristic permits the game to deal withthe following dialogue, as the red but not the greenapple is still accessible in the final turn, and is there-fore chosen as the patient of the ?eat?
action.Game: .
.
.
red apple .
.
.
green apple.Player: Take the red apple.Game: You have the red apple.Player: Eat the apple.Game: You eat the red apple.If this narrows down the possible referents to justone, we are done.
Otherwise ?
i.e.
if several or noneof the referents were mentioned in the previous sen-tence ?, we check whether the player?s knowledgerules out some of them.
The rationale is that an in-telligent player would not try to perform an actionon an object on which she knows it cannot be per-formed.Assume, by way of example, that the playerknows about the worm in the green apple.
Thisviolates a precondition of the ?eat?
action for ap-ples.
Thus if both apples were equally salient, wewould read eat the apple as eat the red apple.
Wecan test if a combination of referents for the variousreferring expressions of a sentence violates precon-ditions by first instantiating the appropriate actionwith these referents.
Then we independently addeach instantiated precondition to fresh copies of theplayer knowledge A-Box and test them for consis-tency.
If one of the A-Boxes becomes inconsistent,we conclude that the player knows this preconditionwould fail, and conclude that this is not the intendedcombination of referents.If neither of these heuristics manages to pick outa unique entity, we consider the definite descriptionto be truly ambiguous and return an error messageto the user, indicating the ambiguity.5.2 Resolving Syntactic AmbiguitiesAnother class of ambiguities which we consider aresyntactic ambiguities, especially of PP attachment.We try to resolve them, too, by taking referentialinformation into account.In the simplest case, the referring expressions insome of the syntactic readings have no possible ref-erent in the player A-Box at all.
If this happens, wefilter these readings out and only continue with theothers (Schuler, 2001).
For example, the sentenceunlock the toolbox with the key is ambiguous.
In ascenario where there is a toolbox and a key, but thekey is not attached to the toolbox, resolution fails forone of the analyses and thereby resolves the syntac-tic ambiguity.If more than one syntactic reading survives thisfirst test, we perform the same computations asabove to filter out possible referents which are eitherunsalient or violate the player?s knowledge.
Some-times, only one syntactic reading will have a refer-ent in this narrower sense; in this case, we are done.Otherwise, i.e.
if more than one syntactic readinghas referents, we remove those readings which arereferentially ambiguous.
Consider once more theexample scenario depicted in Fig.
4.
The sentenceput the apple in the bowl on the table has two differ-ent syntactic analyses: In the first, the bowl on thetable is the target of the put action whereas in thesecond, in the bowl modifies the apple.
Now, notethat in the first reading, we will get two possible ref-erents for the apple, whereas in the second readingthe apple in the bowl is unique.
In cases like this wepick out the reading which only includes unique ref-erences (reading 2 in the present example).
This ap-proach assumes that the players are cooperative andtry to refer unambiguously.
It is furthermore similarto what people seem to do.
Psycholinguistic eye-tracking studies (Chambers et al, 2000) indicatethat people prefer interpretations with unambiguousreferences: subjects who are faced with scenariossimilar to Fig.
4 and hear the sentence put the ap-ple in the bowl on the table do not look at the bowlon the table at all but only at the apple in the bowl(which is unique) and the table.At this point, there can still be more than one syn-tactic reading left; if so, all of these will have unam-biguous, unique referents.
In such a case we cannotdecide which syntactic reading the player meant,and ask the player to give the game a less ambiguouscommand.6 Conclusion and OutlookWe have described an engine for text adventureswhich uses techniques from computational linguis-tics to make the interaction with the game more nat-ural.
The input is analyzed using a dependencyparser and a simple reference resolution module,and the output is produced by a small generationsystem.
Information about the world and aboutthe player?s knowledge is represented in descrip-tion logic knowledge bases, and accessed througha state-of-the-art inference system.
Most modulesuse the inference component; to illustrate its useful-ness, we have looked more closely at the resolutionand generation of referring expressions, and at theresolution of referential and syntactic ambiguities.Preliminary experiments indicate that the perfor-mance of our game engine is good enough for flu-ent gameplay.
The constraint based dependencyparser we use for parsing and generation achievesvery good average case runtimes on the grammarsand inputs we use.
More interestingly, the infer-ence system also performs very well.
With the cur-rent knowledge bases, reasoning on the world modeland user knowledge takes 546ms per turn on aver-age (with a mean of 39 queries per turn).
How wellthis performance scales to bigger game worlds re-mains to be seen.
One lesson we take from this isthat the recent progress in optimizing inference en-gines for expressive description logics is beginningto make them useful for applications.All the language-processing modules in our sys-tem are rather simplistic.
We can get away with thisbecause the utterances that players seem to want toproduce in this setting are restricted, e.g.
to objectsin the same simulated ?location?
as the player.
(Theprecise extent of this, of course, remains to be eval-uated.)
The result is a system which exceeds tradi-tional text adventures by far in the flexibility offeredto the user.Unlike the input, the output that our game gen-erates is far away from the quality of the com-mercial text adventures of the eighties, which pro-duced canned texts, sometimes written by profes-sional book authors.
A possible solution could be tocombine the full generation with a template basedapproach, to which the TAG-based generation ap-proach we take lends itself well.
Another problem isthe generation of error messages asking the user toresolve an ambiguous input.
The game should ide-ally generate and present the player with a choiceof possible (unambiguous) readings.
So, the gen-eration strategy would have to be augmented withsome kind of monitoring, such as the one proposedby Neumann and van Noord (1994).
Finally, wewant to come up with a way of synchronizing thegrammars for parsing and generation, in order to en-sure that expressions used by the game can alwaysbe used by the player as well.The system is designed in a way that should makeit reasonably easy to replace our simple modulesby more sophisticated ones.
We will shortly makeour adventure engine available over the web, andwant to invite colleagues and students to test theirown language processing modules within our sys-tem.
Generally, we believe that the prototype canserve as a starting point for an almost unlimitedrange of extensions.ReferencesC.G.
Chambers, M.K.
Tanenhaus, and J.S.
Magnu-son.
2000.
Does real-world knowledge modulatereferential effects on PP-attachment?
Evidencefrom eye movements in spoken language compre-hension.
In 14th CUNY Conference on HumanSentence Processing.R.
Dale and N. Haddock.
1991.
Generating re-ferring expressions involving relations.
In EACL?91.R.
Dale and E. Reiter.
1995.
Computational inter-pretations of the gricean maxims in the genera-tion of referring expressions.
Cognitive Science,18.D.
Duchier and R. Debusmann.
2001.
Topologicaldependency trees: A constraint-based account oflinear precedence.
In ACL ?01.V.
Haarslev and R. Mo?ller.
2001.
RACER SystemDescription.
In IJCAR ?01.I.
Horrocks, U. Sattler, and S. Tobies.
1999.
Practi-cal reasoning for expressive description logics.
InH.
Ganzinger, D. McAllester, and A. Voronkov,editors, LPAR?99.A.
Koller and K. Striegnitz.
2002.
Generation asdependency parsing.
In ACL ?02.D.
Ledgard.
1999.
Space Station.
Text adventure,modelled after a sample transcript of Infocom?sPlanetfall game.
http://members.tripod.com/?infoscripts/planetfa.htm.Mozart Consortium.
1999.
The Mozart Pro-gramming System web pages.
http://www.mozart-oz.org/.G.
Neumann and G.-J.
van Noord.
1994.Self-monitoring with reversible grammars.
InT.
Strzalkowski, editor, Reversible Grammar inNatural Language Processing.W.
Schuler.
2001.
Computational properties ofenvironment-based disambiguation.
In ACL ?01.M.
Strube.
1998.
Never Look Back: An Alternativeto Centering.
In COLING-ACL ?98.W.
Woods and J. Schmolze.
1992.
The KL-ONEFamily.
Computer and Mathematics with Appli-cations, 23(2?5).
