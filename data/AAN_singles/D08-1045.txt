Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 429?437,Honolulu, October 2008. c?2008 Association for Computational LinguisticsOnline Acquisition of Japanese Unknown Morphemesusing Morphological ConstraintsYugo Murawaki Sadao KurohashiGraduate School of Informatics, Kyoto UniversityYoshida-honmachi, Sakyo-ku, Kyoto, 606-8501, Japanmurawaki@nlp.kuee.kyoto-u.ac.jp kuro@i.kyoto-u.ac.jpAbstractWe propose a novel lexicon acquirer thatworks in concert with the morphological ana-lyzer and has the ability to run in online mode.Every time a sentence is analyzed, it detectsunknown morphemes, enumerates candidatesand selects the best candidates by comparingmultiple examples kept in the storage.
Whena morpheme is unambiguously selected, thelexicon acquirer updates the dictionary of theanalyzer, and it will be used in subsequentanalysis.
We use the constraints of Japanesemorphology and effectively reduce the num-ber of examples required to acquire a mor-pheme.
Experiments show that unknown mor-phemes were acquired with high accuracy andimproved the quality of morphological analy-sis.1 IntroductionMorphological analysis is the first step for most nat-ural language processing applications.
In Japanesemorphological analysis, segmentation is processedsimultaneously with the assignment of a part ofspeech (POS) tag to each morpheme.
Segmentationis a nontrivial task in Japanese because it does notdelimit words by white-space.Japanese morphological analysis has successfullyadopted dictionary-based approaches (Kurohashi etal., 1994; Asahara and Matsumoto, 2000; Kudo etal., 2004).
In these approaches, a sentence is trans-formed into a lattice of morphemes by searching apre-defined dictionary, and an optimal path in thelattice is selected.This area of research may be considered almostcompleted, as previous studies reported the F-scoreof nearly 99% (Kudo et al, 2004).
When appliedto web texts, however, more errors are made due tounknown morphemes.
In previous studies, exper-iments were performed on newspaper articles, butweb texts include slang words, informal spelling al-ternates (Nishimura, 2003) and technical terms.
Forexample, the verb ?????
(gugu-ru, to google) iserroneously segmented into ????
(gugu) and ???
(ru).One solution to this problem is to augment thelexicon of the morphological analyzer by extractingunknown morphemes from texts (Mori and Nagao,1996).
In the previous method, a morpheme extrac-tion module worked independently of the morpho-logical analyzer and ran in off-line (batch) mode.It is inefficient because almost all high-frequencymorphemes have already been registered to the pre-defined dictionary.
Moreover, it is inconvenientwhen applied to web texts because the web corpusis huge and diverse compared to newspaper corpora.It is not necessarily easy to build subcorpora beforelexicon acquisition.
Suppose that we want to ana-lyze whaling-related documents.
It is unnecessaryand probably harmful to acquire morphemes that areirrelevant to the topic.
A whaling-related subcorpusshould be extracted from the whole corpus but it isnot clear how large it must be.We propose a novel lexicon acquirer that worksin concert with the morphological analyzer and hasthe ability to run in online mode.
As shown in Fig-ure 1, every time a sentence is analyzed, the lexiconacquirer detects unknown morphemes, enumerates429textAnalyzerJUMAN(morph.analyzer)KNP(parser)analysisDetectorEnumeratorSelectoraccumulatedexampleshand-crafteddictionaryautomatically constructeddictionaryupdatelookupLexicon AcquireranalysisFigure 1: System architecturecandidates and selects the best candidates by com-paring multiple examples kept in the storage.
Whena morpheme is unambiguously selected, the lexiconacquirer updates the automatically constructed dic-tionary, and it will be used in subsequent analysis.The proposed method is flexible and gives the sys-tem more control over the process.
We do not haveto limit the target corpus beforehand and the systemcan stop whenever appropriate.We use the constraints of Japanese morphologythat have already been coded in the morphologicalanalyzer.
These constraints effectively reduce thenumber of examples required to acquire an unknownmorpheme.
Experiments show that unknown mor-phemes were acquired with high accuracy and im-proved the quality of morphological analysis.2 Japanese MorphologyIn order to understand the task of lexicon acquisi-tion, we briefly describe the Japanese morpholog-ical analyzer JUMAN.1 We explain Japanese mor-phemes in Section 2.1, morphological constraints inSection 2.2, and unknown morpheme processing inSection 2.3.2.1 MorphemeIn JUMAN, the POS tagset consists of four ele-ments: class, subclass, conjugation type and con-jugation form.
The classes are noun, verb, adjec-tive and others.
Noun has subclasses such as com-mon noun, sa-group noun, proper noun, organiza-1http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.htmltion, place, personal name.
Verb and adjective haveno subclasses.Verbs and adjectives among others change theirform according to the morphemes that occur afterthem, which is called conjugation.
Conjugable mor-phemes are grouped by conjugation types such asvowel verb, ra-row verb, i-type adjective and na-type adjective.
Each conjugable morpheme takesone of conjugation forms in texts.
It has an invari-ant stem and an ending which changes according toconjugation type and conjugation form.In this paper, the tuple of class, subclass and con-jugation type is referred to as a POS tag.
For sim-plicity, POS tags for nouns are called by their sub-classes and those for verbs and adjectives by theirconjugation types.There are two types of morphemes: abstract dic-tionary entries, and examples or actual occurrencesin texts.
An entry consists of a stem and a POS tagwhile an example consists of a stem, a POS tag anda conjugation form.
For example, the entry of thera-row verb ????
(hashi-ru, to run) can be repre-sented as(???
(hashi), ra-row verb),and their examples ????
(hashi-ra) and ????
(hashi-ri) as(???
(hashi), ra-row verb, imperfective),and(???
(hashi), ra-row verb, plain continu-ative)respectively.
As nouns do not conjugate, the entryof the sa-group noun ????
(kibou, hope) can berepresented as(????
(kibou), sa-group noun)and its sole example form is(????
(kibou), sa-group noun, NIL).2.2 Morphological ConstraintsJapanese is an agglutinative language.
Dependingon its grammatical roles, a morpheme is followed bya sequence of grammatical suffixes, auxiliary verbsand particles, and the connectivity of these elementsis bound by morphological constraints.
For exam-ple, the particle ???
(wo, accusative case) can fol-low a verb with the conjugation form of plain contin-uative, as in ?????
(hashi-ri-wo, running-ACC),430but it cannot follow an imperfective verb (?*????
(*hashi-ra-wo)).These constraints are used by JUMAN to reducethe ambiguity.
They can be also used in lexicon ac-quisition.2.3 Unknown Morpheme ProcessingGiven a sentence, JUMAN builds a lattice of mor-phemes by searching a pre-defined dictionary, andthen selects an optimal path in the lattice.
To han-dle morphemes that cannot be found in the dictio-nary, JUMAN enumerates unknown morpheme can-didates using character type-based heuristics, andadds them to the morpheme lattice.
Unknown mor-phemes are given the special POS tag ?undefined,?which is treated as noun.Character type-based heuristics are based on thefact that Japanese is written with several differentcharacter types such as kanji, hiragana and katakana,and that the choice of character types gives someclues on morpheme boundaries.
For example, a se-quence of katakana characters are considered as anunknown morpheme candidate, as in ??????
(gu?guru, Google) out of ???????
(gu?guru-ga,Google-NOM).
Kanji characters are segmented percharacter, which is sometimes wrong but preventserror propagation.These heuristics are simple and effective, but farfrom perfect.
They cannot identify mixed-charactermorphemes, verbs and adjectives correctly.
For ex-ample, the verb ?????
(gugu-ru, to google) iswrongly divided into the katakana unknown mor-pheme ????
(gugu) and the hiragana suffix ???
(ru).3 Lexicon Acquisition3.1 TaskThe task of lexicon acquisition is to generate dictio-nary entries inductively from their examples in texts.Since the morphological analyzer provides a basiclexicon, the morphemes to be acquired are limitedto those unknown to the analyzer.In order to generate an entry, its stem and POStag need to be identified.
Determining the stem ofan example is to draw the front and rear boundariesin a character sequence in texts which correspondsto the stem.
The POS tag is selected from the tagsetgiven by the morphological analyzer.3.2 System ArchitectureFigure 1 shows the system architecture.
Each sen-tence in texts is processed by the morphological an-alyzer JUMAN and the dependency parser KNP.2JUMAN consults a hand-crafted dictionary and anautomatically constructed dictionary.
KNP is usedto form a phrasal unit called bunsetsu by chunkingmorphemes.Every time a sentence is analyzed, the lexiconacquirer receives the analysis.
It detects examplesof unknown morphemes and keeps them in storage.When an entry is unambiguously selected, the lex-icon acquirer updates the automatically constructeddictionary, and it will be used in subsequent analy-sis.3.3 Algorithm OverviewThe process of lexicon acquisition has four phases:detection, candidate enumeration, aggregation andselection.
First the analysis is scanned to detect ex-amples of unknown morphemes.
For each exam-ple, one or more candidates for dictionary entries areenumerated.
It is added to the storage, and multipleexamples in the storage that share the candidates areaggregated.
They are compared and the best candi-date is selected from it.Take the ra-row verb ?????
(gugu-ru) for ex-ample.
Its example ?????????
(gugu-tte-mi-ta, to have tried to google) can be interpreted inmany ways as shown in Figure 2.
Similarly, multi-ple candidates are enumerated for another example???????
(gugu-ru-no-ha, to google-TOPIC).
Ifthese examples are compared, we can see that thera-row verb ?????
(gugu-ru) can explain them.3.4 SuffixesMorphological constraints are used for candidateenumeration.
Since they are coded in JUMAN, wefirst transform them into a set of strings called suf-fixes.
A suffix is created by concatenating the end-ing of a morpheme (if any) and subsequent ancillarymorphemes.
Each POS tag is associated with a setof suffixes, as shown in Table 1.
This means that astem can be followed by one of the suffixes specified2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html431Table 1: Examples of suffixesPOS tag base form stem ending conjugation form1 suffixesra-row verb hashi-ru hashira imperfective razu, ranaideri plain continuative riwo, riwomoru plain ru, rukawovowel verb akogare-ru akogare?
imperfective zu, naide?
plain continuative wo, womoru plain ru, rukawosa-group noun kibou kibou NIL wo wo, womoNIL suru suru, shitara1 The conjugation form of a noun is substituted with the base form of its immediateancillary morpheme because nouns do not conjugate.suffix??????
?google -CONT try-PASTstemstemstemsuffixsuffix[POS tags]?
ra-row verb?
wa-row verb?
ta-row verb?
ma-row verb?
vowel verb?
ta-row verb?
(EOB)stemFigure 2: Candidate enumerationby its POS tag and cannot be followed by any othersuffix.In preparation for lexicon acquisition, suffixes areacquired from a corpus.
We used a web corpus thatwas compiled through the procedures proposed byKawahara and Kurohashi (2006).
Suffixes were ex-tracted from examples of registered morphemes andwere aggregated per POS tag.We found that the number of suffixes did not con-verge even in this large-scale corpus.
It was becauseancillary morphemes included the wide variety ofauxiliary verbs and formal nouns.
Alternatively, weused the first five characters as a suffix.
In the exper-iments, we obtained 500 thousand unique suffixesfrom 100 million pages.
The number of POS tagsthat corresponded to a suffix was 1.33 on average.3.5 Unknown Morpheme DetectionThe first step of lexicon acquisition is unknown mor-pheme detection.
Every time the analysis of a sen-tence was given, the sequence of morphemes arescanned, and suspicious points that probably repre-sent unknown morphemes are detected.Currently, we use the POS tag ?undefined?
to de-tect unknown morphemes.
For example, the exam-ple ?????????
is detected because ???
?is given ?undefined.?
This simple method cannotdetect unknown morphemes if they are falsely seg-mented into combinations of registered morphemes.We leave the comprehensive detection of unknownmorphemes to future work.3.6 Candidate EnumerationFor each example, one or more candidates for thedictionary entry are enumerated.
Each candidate isrepresented by a combination of a front boundaryand the pair of a rear boundary and a POS tag.The search range for enumeration is based on bun-setsu phrases, which is created by chunking mor-phemes.
The range is at most the correspondingbunsetsu and the two immediately preceding andsucceeding bunsetsu, which we found wide enoughto contain correct candidates.The candidates for the rear boundary and the POStag are enumerated by string matching of suffixes asshown in Figure 2.
If a suffix matches, the start-ing position of the suffix becomes a candidate forthe rear boundary and the suffix is mapped to one ormore corresponding POS tags.In addition, the candidates for the front andrear boundaries are enumerated by scanning the se-quence of morphemes.
The boundary markers weuse are?
punctuations,?
grammatical prefixes such as ???
(go-, hon-orific prefix), for front boundaries,432?
grammatical suffixes such as ???
(-sama, hon-orific title), for rear boundaries, and?
bunsetsu boundaries given by KNP.Each rear boundary candidate whose correspond-ing POS tag is not decided is given the special tag?EOB?
(end-of-bunsetsu).
This means that no suf-fix is attached to the candidate.
Since nouns, vowelverbs and na-type adjectives can appear in isolation,it will be expanded to these POS tags when selectingthe best POS tag.3.7 Aggregation of ExamplesSelection of the best candidate is done by compar-ing multiple examples.
Each example is added tothe storage, and then examples that possibly repre-sent the same entry with it are extracted from thestorage.
Examples aggregated at this phase share thefront boundary but may be unrelated to the examplein question.
They are pruned in the next phase.In order to manage examples efficiently, we im-plement a trie.
The example is added to the trie foreach front boundary candidate.
The key is the char-acter sequence determined by the front boundaryand the leftmost rear boundary.
To retrieve examplesthat share the front boundary with it, we check everynode in the path from the root to the node where it isstored, and collect examples stored in each node.3.8 SelectionThe best candidate is selected by identifying thefront boundary, the rear boundary and the POS tagin this order.
Starting from the rightmost frontboundary candidate, multiple rear boundary candi-dates that share the front boundary are compared andsome are dropped.
Then starting from the leftmostsurviving rear boundary candidate, the best POS tagis selected from the examples that share the stem.If the selected candidate satisfies simple terminationconditions, it is added to the dictionary and the ex-amples are removed from the storage.For each front boundary candidate, some inappro-priate rear boundary candidates are dropped by ex-amining the inclusion relation between the examplesof a pair of candidates.
The assumption behind thisis that an appropriate candidate can interpret moreexamples than incorrect ones.
Let p and q be a pairof the candidates for the rear boundary, and RpandRqbe the sets of examples for which p and q areenumerated.
If p is a prefix of q and p is the correctstem, then Rqmust be contained in Rp.
In practicewe loosen this condition, considering possible errorsin candidate enumerationFor each stem candidate, the appropriate POS tagis identified.
Similarly to rear boundary identifica-tion, POS identification is done by checking inclu-sion relation.If the POS tag is successfully disambiguated, sim-ple termination conditions is checked to prevent theaccidental acquisition of erroneous candidates.
Thefirst condition is that the number of unique conjuga-tion forms that appear in the examples should be 3 ormore.
If the candidate is a noun, it is substituted withthe number of the unique base forms of their imme-diate ancillary morphemes.
The second condition isthat the front boundaries of some examples are de-cided by clear boundary markers such as punctua-tions and the beginning of sentence.
This preventsoversegmentation.
For example, the stem candidate?*???
(*sengumi) is always enumerated for exam-ples of ?????
(Shingengumi, a historical organi-zation) since ???
(shin-, new) is a prefix.
This can-didate is not acquired because ?*???
(*sengumi)does not occur alone and is always accompanied by???
(shin-).
Thresholds are chosen empirically.3.9 DecompositionalitySince a morpheme is extracted from a small num-ber of examples, it is inherently possible that the ac-quired morpheme actually consists of two or moremorphemes.
For example, the noun phrase ???????
(karyuu-taipu, granular type) may be ac-quired as a morpheme before ????
(karyuu, gran-ule) is extracted.
To handle this phenomenon, itis checked at the time of acquisition whether thenew morpheme (kairyuu) can decompose registeredmorphemes (kairyuu-taipu).
If found, a composite?morpheme?
is removed from the dictionary.Currently we leave the decompositionality checkto the morphological analyzer.
Possible compoundsare enumerated by string matching and temporar-ily removed from the dictionary.
Each candidateis analyzed by the morphological analyzer and it ischecked whether the candidate is divided into a com-bination of registered morphemes.
If not, the candi-date is restored to the dictionary.433Table 2: Statistical information per queryquerynumber of number of number of number of number ofsentences affected acquired correct examples1sentences morphs morphs(ratio) (precision)????
135,379 2,444 293 290 4(whaling issue) (1.81%) (99.0%)???????
74,572 775 107 105 4(baby hatch) (1.04%) (98.1%)??????
195,928 6,259 913 907 4(JASRAC) (3.19%) (99.3%)????
77,962 12,012 243 238 5(tsundere) (15.4%) (97.4%)?????
78,922 3,037 114 107 9(agaricus) (3.85%) (93.9%)1 The median number of examples used for acquisition.4 Experiments4.1 Experimental DesignWe used the default dictionary of the morphologicalanalyzer JUMAN as the initial lexicon.
It contained30 thousand basic morphemes.
If spelling variantswere expanded and proper nouns were counted, thetotal number of morphemes was 120 thousands.We used domain-specific corpora as target textsbecause efficient acquisition was expected.
If targettexts shared a topic, relevant unknown morphemeswere used frequently.
In the experiments, we usedsearch engine TSUBAKI (Shinzato et al, 2008) andcasted the search results as domain-specific corpora.For each query, our system sequentially read pagesfrom the top of the result and acquired morphemes.We terminated the acquisition at the 1000th pageand analyzed the same 1000 pages with the aug-mented lexicon.
The queries used were ??????
(whaling issue), ?????????
(baby hatch),????????
(JASRAC, a copyright collective),??????
(tsundere, a slang word) and ???????
(agaricus).4.2 Evaluation MeasuresThe proposed method is evaluated by measuring theaccuracy of acquired morphemes and their contri-bution to the improvement of morphological analy-sis.
A morpheme is considered accurate if both seg-mentation and the POS tag are correct.
Note thatsegmentation is a nontrivial problem for evaluation.In fact, the disagreement over segmentation criteriawas considered one of the main reasons for reportederrors by Nagata (1999) and Uchimoto et al (2001).It is difficult to judge whether a compound termshould be divided because there is no definite stan-dard for morpheme boundaries in Japanese.
For ex-ample, ??????
(minku-kujira, minke whale) canbe extracted as a single morpheme or decomposedinto ?????
and ??.?
While segmentation is anopen question in Japanese morphological analysis,?correct?
segmentation is not necessarily importantfor applications using morphological analysis.
Evenif a noun is split into two or more morphemes inmorphological analysis, they are chunked to forma phrasal unit called bunsetsu in dependency pars-ing, and to extract a keyword (Nakagawa and Mori,2002).To avoid the decompositionality problem, weadopted manual evaluation.
We analyzed the tar-get texts with both the initial lexicon and the aug-mented lexicon.
Then we checked differences be-tween the two analyses and extracted sentences thatwere affected by the augmentation.
Among thesesentences, we evaluated randomly selected 50 sen-tences per query.
We checked the accuracy of seg-mentation and POS tagging of each ?diff?
block,which is illustrated in Figure 3.
The segmentation ofa block was judged correct unless morpheme bound-aries were clearly wrong.In the evaluation of POS tagging, we did not dis-tinguish subclasses of noun3 such as common noun3In the experiments, we regarded demonstrative pronouns as434Table 3: Examples of acquired morphemesquery exampleswhaling issue ??????
(moratorium),?????
(giant beaked whale),??
(bycatch)baby hatch ???
(husband),???
(midwife),???
(to abandon),??
(to inquire)JASRAC ???
(an organization),???
Q (a pop-rock band),??
(geek)tsundere ???
(abbr.
of Akihabara),???
(fujoshi, a slang word),???
(to be popular)agaricus ???
(abbr.
of suppliment),???
(aroma),??
(enhanced nutritional function)Table 4: Evaluation of ?diff?
blockssegmentation POS taggingquery E ?
C C ?
C E ?
E C ?
E E ?
C C ?
C E ?
E C ?
E totalwhaling issue 11 45 0 2 11 45 0 2 58baby hatch 37 12 0 3 37 12 0 3 52JASRAC 16 23 1 12 16 23 1 12 52tsundere 17 39 0 1 17 39 0 1 57agaricus 22 31 0 0 22 31 0 0 53(Legend ?
C: correct; E: erroneous)???????????
)QQING KVCPFYGYKNNHKPFCNQV?
? WPFGHKPGF MCVCMCPC? UWHHKZ?
XGTDCNUWHHKZ??
? XGTD TCTQYXGTDFigure 3: A ?diff?
block in a sentenceand proper noun.
The special POS tag ?undefined?given by JUMAN was treated as noun.4.3 ResultsTable 2 summarizes statistical information perquery.
The number of sentences affected by theaugmentation varied considerably (1.04%?15.4%).The initial lexicon of the morphological analyzerlacked morphemes that appeared frequently in somecorpora because morphological analysis had beentested mainly with newspaper articles.The precision of acquired morphemes was high(97.4%?99.3%), and the number of examples usedfor acquisition was as little as 4?9.
These results areastonishing considering that Mori and Nagao (1996)ignored candidates that appeared less than 10 times(because they were unreliable).nouns because their morphological behaviors were the same asthose of nouns.
Although demonstrative nouns are closed classmorphemes, their katakana forms such as ????
(this) wereacquired as nouns.
The morphological analyzer assumed thatdemonstrative pronouns were written in hiragana, e.g., ??
?,?as they always are in a newspaper.Table 3 shows some acquired morphemes.
Asexpected, the overwhelming majority were nouns(93.0%?100%) and katakana morphemes (80.7%?91.6%).
Some were mixed-character morphemes(?????
and ????Q?
), which cannot be recog-nized by character-type based heuristics, and slangwords (????,?
???,?
etc.)
which did not ap-pear in newspaper articles.
Some morphemes werespelling variants of those in the pre-defined dictio-nary.
Uncommon kanji characters were used in ba-sic words (?????
for ?????
and ????
for????)
and katakana was used to change nuances(?????
for ?????
and ?????
for ????
).Table 4 shows the results of manual evaluation of?diff?
blocks.
The overwhelming majority of blockswere correctly analyzed with the augmented lexicon(E ?
C and C ?
C).
On the other hand, adverseeffects were observed only in a few blocks (C ?E).
In conclusion, acquired morphemes improve thequality of morphological analysis.4.4 Error AnalysisSome short katakana morphemes oversegmentedother katakana nouns.
For example, ??????
(sa?ba?, server) was wrongly segmented by newly-acquired ????
(sa?, sir) and preregistered ????
(ba?, bar).
Neither the morphological analyzer andthe lexicon acquirer could detect this semantic mis-match.
Curiously, one example of ????
(sa?)
wasactuallly part of ??????
(sa?ba?
), which was erro-435020040060080010000  100000  2000000800016000240003200040000num.
of acquiredmorphemesnum.
of examplesnum.
of sentencesacquired morphemesstored examplesacquired morphemes in re-analysisFigure 4: Process of online acquisitionneously segmented when extracting sentences fromHTML.The katakana adjective ????
(i-i, good), aspelling variant of the basic morpheme ???,?
wasfalsely identified as a noun because its ending ??
?was written in katakana.
The morphological ana-lyzer, and hence the lexicon acquirer, assume thatthe ending of a verb or adjective is written in hi-ragana.
This assumption is reasonable for stan-dard Japanese, but does not always hold when weanalyze web texts.
In order to recognize uncon-ventional spellings that are widely used in webtexts (Nishimura, 2003), more flexible analysis isneeded.4.5 DiscussionIt is too costly or impractical to calculate the re-call of acquisition, or the ratio of the number of ac-quired morphemes against the total number of un-known morphemes because it requires human judgesto find undetected unknown morphemes from a largeamount of raw texts.Alternatively, we examined the ratio against thenumber of detected unknown morphemes.
Figure 4shows the process of online acquisition for the query?JASRAC.?
The monotonic increase of the num-bers of acquired morphemes and stored examplessuggests that the vocabulary size did not converge.The number of occurrences of acquired morphemesin re-analysis was approximately the same with thenumber of examples kept in the storage during ac-quisition.
This means that, in terms of frequency ofoccurrence, about half of unknown morphemes wereacquired.
Most unknown morphemes belong to the?long tail?
and the proposed method seems to haveseized a ?head?
of the long tail.Although some previous studies emphasized cor-rect identification of low frequency terms (Nagata,1999; Asahara and Matsumoto, 2004), it is no longernecessary because very large scale web texts areavailable today.
If a small set of texts needs tobe analyzed with high accuracy, we can incorporatesimilar texts retrieved from the web, to increase thenumber of examples of unknown morphemes.
Theproposed method can be modified to check if un-known morphemes detected in the initial set are ac-quired and to terminate whenever sufficient acquisi-tion coverage is achieved.5 Related WorkSince most languages delimit words by white-space,morphological analysis in these languages is to seg-ment words into morphemes.
For example, Mor-pho Challenge 2007 (Kurimo et al, 2007) was eval-uations of unsupervised segmentation for English,Finnish, German and Turkish.While Japanese is an agglutinative language,other non-segmented languages such as Chinese andThai are analytic languages.
Among them, Chinesehas been a subject of intensive research.
Peng etal.
(2004) integrated new word detection into wordsegmentation.
They detected new words by comput-ing segment confidence and re-analyzed the inputswith detected words as features.The Japanese language is unique in that it is writ-ten with several different character types.
Heuris-tics widely used in unknown morpheme process-ing are based on character types.
They were alsoused as important clues in statistical methods.
Na-gata (1999) integrated a probabilistic unknown wordmodels into the word segmentation model.
Uchi-moto et al (2001) incorporated them as feature func-tions of a Maximum Entropy-based morphologicalanalyzer.
Asahara and Matsumoto (2004) used themas a feature of character-based chunking of unknownwords using Support Vector Machines.Mori (1996) extracted words from texts and esti-mated their POSs using distributional analysis.
Theappropriateness of a word candidate was measured436by the distance between probability distributions ofthe candidate and a model.
In this method, mor-phological constraints were indirectly representedby distributions.Nakagawa and Matsumoto (2006) presented amethod for guessing POS tags of pre-segmented un-known words that took into consideration all the oc-currences of each unknown word in a document.This setting is impractical in Japanese because POStagging is inseparable from segmentation.6 ConclusionWe propose a novel method that augments the lexi-con of a Japanese morphological analyzer by acquir-ing unknown morphemes from texts in online mode.Unknown morphemes are acquired with high accu-racy and improve the quality of morphological anal-ysis.Unknown morphemes are one of the main sourcesof error in morphological analysis when we analyzeweb texts.
The proposed method has the potentialto overcome the unknown morpheme problem, butit cannot be achieved without recognizing or beingrobust over various phenomena such as unconven-tional spellings and typos.
These phenomena are notobserved in newspaper articles but cannot be ignoredin web texts.
In the future, we will work on thesephenomena.Morphological analysis is now very mature.
Itis widely applied as preprocessing for NLP appli-cations such as parsing and information retrieval.Hence in the future, we aim to use the proposedmethod to improve the quality of these applications.ReferencesMasayuki Asahara and Yuji Matsumoto.
2000.
Extendedmodels and tools for high-performance part-of-speechtagger.
In Procs.
of COLING 2000, pages 21?27.Masayuki Asahara and Yuji Matsumoto.
2004.Japanese unknown word identification by character-based chunking.
In Procs.
of COLING 2004, pages459?465.Daisuke Kawahara and Sadao Kurohashi.
2006.Case frame compilation from the web using high-performance computing.
In Procs.
of LREC-06, pages1344?1347.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields to Japanesemorphological analysis.
In Procs.
of EMNLP 2004,pages 230?237.Mikko Kurimo, Mathias Creutz, and Ville Turunen.2007.
Overview of Morpho Challenge in CLEF 2007.In Working Notes of the CLEF 2007 Workshop, pages19?21.Sadao Kurohashi, Toshihisa Nakamura, Yuji Matsumoto,and Makoto Nagao.
1994.
Improvements of Japanesemorphological analyzer JUMAN.
In Procs.
of The In-ternational Workshop on Sharable Natural LanguageResources, pages 22?38.Shinsuke Mori and Makoto Nagao.
1996.
Word extrac-tion from corpora and its part-of-speech estimation us-ing distributional analysis.
In Procs.
of COLING 1996,pages 1119?1122.Masaaki Nagata.
1999.
A part of speech estimationmethod for Japanese unknown words using a statisticalmodel of morphology and context.
In Procs.
of ACL1999, pages 277?284.Tetsuji Nakagawa and Yuji Matsumoto.
2006.
Guessingparts-of-speech of unknown words using global infor-mation.
In Procs.
of COLING-ACL 2006, pages 705?712.Hiroshi Nakagawa and Tatsunori Mori.
2002.
A sim-ple but powerful automatic term extraction method.
InCOLING-02 on COMPUTERM 2002, pages 29?35.Yukiko Nishimura.
2003.
Linguistic innovations and in-teractional features of casual online communication inJapanese.
Journal of Computer-Mediated Communi-cation, 9(1).Fuchun Peng, Fangfang Feng, and Andrew McCallum.2004.
Chinese segmentation and new word detectionusing conditional random fields.
In Procs.
of COLING?04, pages 562?568.Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara,Chikara Hashimoto, and Sadao Kurohashi.
2008.TSUBAKI: An open search engine infrastructure fordeveloping new information access methodology.
InProcs.
of IJCNLP-08, pages 189?196.Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara.2001.
The unknown word problem: a morphologicalanalysis of Japanese using maximum entropy aided bya dictionary.
In Procs.
of EMNLP 2001, pages 91?99.437
