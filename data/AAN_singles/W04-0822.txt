Augmenting Ensemble Classification for Word Sense Disambiguation with aKernel PCA ModelMarine CARPUAT Weifeng SU Dekai WU1marine@cs.ust.hk weifeng@cs.ust.hk dekai@cs.ust.hkHuman Language Technology CenterHKUSTDepartment of Computer ScienceUniversity of Science and Technology, Clear Water Bay, Hong KongAbstractThe HKUST word sense disambiguation systemsbenefit from a new nonlinear Kernel PrincipalComponent Analysis (KPCA) based disambigua-tion technique.
We discuss and analyze resultsfrom the Senseval-3 English, Chinese, and Multi-lingual Lexical Sample data sets.
Among an en-semble of four different kinds of voted models, theKPCA-based model, along with the maximum en-tropy model, outperforms the boosting model andna?
?ve Bayes model.
Interestingly, while the KPCA-based model typically achieves close or better ac-curacy than the maximum entropy model, neverthe-less a comparison of predicted classifications showsthat it has a significantly different bias.
This char-acteristic makes it an excellent voter, as confirmedby results showing that removing the KPCA-basedmodel from the ensemble generally degrades per-formance.1 IntroductionClassifier combination has become a standard ar-chitecture for shared task evaluations in word sensedisambiguation (WSD), named entity recognition,and similar problems that can naturally be cast asclassification problems.
Voting is the most com-mon method of combination, having proven to beremarkably effective yet simple.A key problem in improving the accuracy of suchensemble classification systems is to find new vot-ing models that (1) exhibit significantly differentprediction biases from the models already voting,and yet (2) attain stand-alone classification accura-cies that are as good or better.
When either of theseconditions is not met, adding the new voting modeltypically degrades the accuracy of the ensemble in-stead of helping it.In this work, we investigate the potential of onepromising new disambiguation model with respect1The author would like to thank the Hong Kong ResearchGrants Council (RGC) for supporting this research in partthrough research grants RGC6083/99E, RGC6256/00E, andDAG03/04.EG09.to augmenting our existing ensemble combining amaximum entropy model, a boosting model, anda na?
?ve Bayes model?a combination representingsome of the best stand-alone WSD models cur-rently known.
The new WSD model, proposedby Wu et al (2004), is a method for disambiguat-ing word senses that exploits a nonlinear KernelPrincipal Component Analysis (KPCA) technique.That the KPCA-based model could potentially bea good candidate for a new voting model is sug-gested by Wu et al?s empirical results showing thatit yielded higher accuracies on Senseval-2 data setsthan other models that included maximum entropy,na?
?ve Bayes, and SVM based models.In the following sections, we begin with a de-scription of the experimental setup, which utilizesa number of individual classifiers in a voting en-semble.
We then describe the KPCA-based modelto be added to the baseline ensemble.
The accuracyresults of the three submitted models are examined,and also the individual voting models are compared.Subsequently, we analyze the degree of differencein voting bias of the KPCA-based model from theothers, and finally show that this does indeed usu-ally lead to accuracy gains in the voting ensemble.2 Experimental setup2.1 Tasks evaluatedWe performed experiments on the following lexicalsample tasks from Senseval-3:English (fine).
The English lexical sample taskincludes 57 target words (32 verbs, 20 nouns and5 adjectives).
For each word, training and test in-stances tagged with WordNet senses are provided.There are an average of 8.5 senses per target wordtype, ranging from 3 to 23.
On average, 138 traininginstances per target word are available.English (coarse).
This modified evaluation of thepreceding task employs a sense map that groupsfine-grained sense distinctions into the same coarse-grained sense.Chinese.
The Chinese lexical sample task in-cludes 21 target words.
For each word, severalAssociation for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of Systemssenses are defined using the HowNet knowledgebase.
There are an average of 3.95 senses per tar-get word type, ranging from 2 to 8.
Only about 37training instances per target word are available.Multilingual (t).
The Multilingual (t) task is de-fined similarly to the English lexical sample task,except that the word senses are the translations intoHindi, rather than WordNet senses.
The Multilin-gual (t) task requires finding the Hindi sense for 31English target word types.
There are an average of7.54 senses per target word type, ranging from 3 to16.
A relatively large training set is provided (morethan 260 training instances per word on average).Multilingual (ts).
The Multilingual (ts) task usesa different data set of 10 target words and providesthe correct English sense of the target word for bothtraining and testing.
There are an average of 6.2senses per target word type, ranging from 3 to 11.The training set for this subtask was smaller, withabout 150 training instances per target word.2.2 Ensemble classificationThe WSD models presented here consist of ensem-bles utilizing various combinations of four votingmodels, as follows.
Some of these component mod-els were also evaluated on other Senseval-3 tasks:the Basque, Catalan, Italian, and Romanian LexicalSample tasks (Wicentowski et al, 2004), as well asSemantic Role Labeling (Ngai et al, 2004).The first voting model, a na?
?ve Bayes model, wasbuilt as Yarowsky and Florian (2002) found thismodel to be the most accurate classifier in a compar-ative study on a subset of Senseval-2 English lexicalsample data.The second voting model, a maximum entropymodel (Jaynes, 1978), was built as Klein and Man-ning (2002) found that it yielded higher accuracythan na?
?ve Bayes in a subsequent comparison ofWSD performance.
However, note that a differentsubset of either Senseval-1 or Senseval-2 Englishlexical sample data was used.The third voting model, a boosting model (Fre-und and Schapire, 1997), was built as boosting hasconsistently turned in very competitive scores on re-lated tasks such as named entity classification (Car-reras et al, 2002)(Wu et al, 2002).
Specifically, weemployed an AdaBoost.MH model (Schapire andSinger, 2000), which is a multi-class generalizationof the original boosting algorithm, with boosting ontop of decision stump classifiers (decision trees ofdepth one).The fourth voting model, the KPCA-basedmodel, is described below.All classifier models were selected for their abil-ity to able to handle large numbers of sparse fea-tures, many of which may be irrelevant.
More-over, the maximum entropy and boosting models areknown to be well suited to handling features that arehighly interdependent.2.3 Controlled feature setIn order to facilitate a controlled comparison acrossthe individual voting models, the same feature setwas employed for all classifiers.
The features areas described by Yarowsky and Florian (2002) intheir ?feature-enhanced na?
?ve Bayes model?, withposition-sensitive, syntactic, and local collocationalfeatures.2.4 The KPCA-based WSD modelWe briefly summarize the KPCA-based model here;for full details including illustrative examples andgraphical interpretation, please refer to Wu et al(2004).Kernel PCA Kernel Principal Component Analy-sis is a nonlinear kernel method for extracting non-linear principal components from vector sets where,conceptually, the n-dimensional input vectors arenonlinearly mapped from their original space Rnto a high-dimensional feature space F where linearPCA is performed, yielding a transform by whichthe input vectors can be mapped nonlinearly to anew set of vectors (Scho?lkopf et al, 1998).As with other kernel methods, a major advantageof KPCA over other common analysis techniques isthat it can inherently take combinations of predic-tive features into account when optimizing dimen-sionality reduction.
For WSD and indeed many nat-ural language tasks, significant accuracy gains canoften be achieved by generalizing over relevant fea-ture combinations (see, e.g., Kudo and Matsumoto(2003)).
A further advantage of KPCA in the con-text of the WSD problem is that the dimensionalityof the input data is generally very large, a conditionwhere kernel methods excel.Nonlinear principal components (Diamantarasand Kung, 1996) are defined as follows.
Supposewe are given a training set of M pairs (xt, ct) wherethe observed vectors xt ?
Rn in an n-dimensionalinput space X represent the context of the targetword being disambiguated, and the correct class ctrepresents the sense of the word, for t = 1, ..,M .Suppose ?
is a nonlinear mapping from the inputspace Rn to the feature space F .
Without loss ofgenerality we assume the M vectors are centeredvectors in the feature space, i.e.,?Mt=1 ?
(xt) = 0;uncentered vectors can easily be converted to cen-tered vectors (Scho?lkopf et al, 1998).
We wish todiagonalize the covariance matrix in F :C = 1MM?j=1?
(xj) ?T (xj) (1)To do this requires solving the equation ?v =Cv for eigenvalues ?
?
0 and eigenvectors v ?Rn\ {0}.
BecauseCv = 1MM?j=1(?
(xj) ?
v)?
(xj) (2)we can derive the following two useful results.
First,?
(?
(xt) ?
v) = ?
(xt) ?
Cv (3)for t = 1, ..,M .
Second, there exist ?i for i =1, ...,M such thatv =M?i=1?i?
(xi) (4)Combining (1), (3), and (4), we obtainM?M?i=1?i (?
(xt) ?
?
(xi ))=M?i=1?i(?
(xt) ?M?j=1?
(xj)) (?
(xj) ?
?
(xi ))for t = 1, ..,M .
Let K?
be the M ?
M matrix suchthatK?ij = ?
(xi) ?
?
(xj) (5)and let ?
?1 ?
?
?2 ?
.
.
.
?
?
?M denote the eigenval-ues of K?
and ?
?1 ,..., ?
?M denote the correspondingcomplete set of normalized eigenvectors, such that??t(?
?t ?
?
?t) = 1 when ?
?t > 0.
Then the lth nonlinearprincipal component of any test vector xt is definedasylt =M?i=1?
?li (?
(xi) ?
?
(xt )) (6)where ?
?li is the lth element of ?
?l .See Wu et al (2004) for a possible geometric in-terpretation of the power of the nonlinearity.WSD using KPCA In order to extract nonlin-ear principal components efficiently, first note thatin both Equations (5) and (6) the explicit form of?
(xi) is required only in the form of (?
(xi) ??
(xj)), i.e., the dot product of vectors in F .
Thismeans that we can calculate the nonlinear princi-pal components by substituting a kernel functionk(xi, xj) for (?
(xi) ?
?
(xj )) in Equations (5) and(6) without knowing the mapping ?
explicitly; in-stead, the mapping ?
is implicitly defined by thekernel function.
It is always possible to constructa mapping into a space where k acts as a dot prod-uct so long as k is a continuous kernel of a positiveintegral operator (Scho?lkopf et al, 1998).Thus we train the KPCA model using the follow-ing algorithm:1.
Compute an M ?
M matrix K?
such thatK?ij = k(xi, xj) (7)2.
Compute the eigenvalues and eigenvectors ofmatrix K?
and normalize the eigenvectors.
Let?
?1 ?
?
?2 ?
.
.
.
?
?
?M denote the eigenvaluesand ?
?1,..., ?
?M denote the corresponding com-plete set of normalized eigenvectors.To obtain the sense predictions for test instances,we need only transform the corresponding vectorsusing the trained KPCA model and classify the re-sultant vectors using nearest neighbors.
For a giventest instance vector x, its lth nonlinear principalcomponent isylt =M?i=1?
?lik(xi, xt) (8)where ?
?li is the ith element of ?
?l.For our disambiguation experiments we employ apolynomial kernel function of the form k(xi, xj) =(xi ?
xj)d, although other kernel functions such asgaussians could be used as well.
Note that the de-generate case of d = 1 yields the dot product kernelk(xi, xj) = (xi?xj) which covers linear PCA as aspecial case, which may explain why KPCA alwaysoutperforms PCA.3 Results and discussion3.1 AccuracyTable 1 summarizes the results of the submitted sys-tems along with the individual voting models.
Sinceour models attempted to disambiguate all test in-stances, we report accuracy (precision and recall be-ing equal).
Earlier experiments on Senseval-2 datashowed that the KPCA-based model significantlyoutperformed both na?
?ve Bayes and maximum en-tropy models (Wu et al, 2004).
On the Senseval-3 data, the maximum entropy model fares slightlybetter: it remains significantly worse on the Multi-lingual (ts) task, but achieves statistically the sameaccuracy on the English (fine) task and is slightlyTable 1: Comparison of accuracy results for various HKUST ensemble and individual models on Senseval-3 Lexical Sample tasks, confirming the high accuracy of the KPCA-based model.
All test instances wereattempted.
(Bold model names were the systems entered.
)English(fine)English(coarse)Chinese Multilingual(t)Multilingual(ts)HKUST comb2 (me, boost, nb, kpca) 71.4 78.6 66.2 62.0 63.8HKUST comb (me, boost, kpca) 70.9 78.1 66.5 61.4 63.8HKUST me 69.3 76.4 64.4 60.6 60.8HKUST kpca 69.2 - 63.6 60.0 63.3HKUST boost 67.0 - 64.1 57.3 60.3HKUST nb 64.3 - 60.4 57.3 56.8Table 2: Confusion matrices showing that the KPCA-based model votes very differently from the othermodels on the Senseval-3 Lexical Sample tasks.
Percentages representing disagreement between KPCA andother voting models are shown in bold.kpca vs: me boost nbtask incorrect correct incorrect correct incorrect correctEnglish incorrect 24.14% 6.62% 21.60% 9.15% 21.04% 9.71%(fine) correct 6.59% 62.65% 11.38% 57.86% 14.63% 54.61%Chinese incorrect 24.01% 12.40% 22.96% 13.46% 26.65% 9.76%correct 11.61% 51.98% 12.93% 50.66% 12.93% 50.66%Multilingual incorrect 32.71% 7.33% 32.04% 8.01% 30.54% 9.51%(t) correct 6.74% 53.22% 10.63% 49.33% 12.20% 47.75%Multilingual incorrect 33.17% 3.52% 31.66% 5.03% 30.15% 6.53%(ts) correct 6.03% 57.29% 8.04% 55.28% 13.07% 50.25%more accurate on the Multilingual (t) task.
For un-known reasons?possibly the very small number oftraining instances per Chinese target word, as men-tioned earlier?there is an exception on the Chinesetask, where boosting outperforms the KPCA-basedmodel.
We are investigating the possible causes.The na?
?ve Bayes model remains significantly worseunder all conditions.3.2 Differentiated voting biasFor a new voting model to raise the accuracy of anexisting classifier ensemble, it is not only importantthat the new voting model achieve accuracy compa-rable to the other voters, as shown above, but alsothat it provides a significantly differentiated predic-tion bias than the other voters.
Otherwise, the accu-racy is typically hurt rather than helped by the newvoting model.To examine whether the KPCA-based model sat-isfies this requirement, we compared its predictionsagainst each of the other classifiers (for those taskswhere we have been given the answer key).
Table 2shows nine confusion matrices revealing the per-centage of instances where the KPCA-based modelvotes differently from one of the other voters.
Thedisagreement between KPCA and the other votingmodels ranges from 6.03% to 14.63%, as shownby the bold entries in the confusion matrices.
Notethat where there is disagreement, the KPCA-basedmodel predicts the correct sense with significantlyhigher accuracy, in nearly all cases.3.3 Voting effectivenessThe KPCA-based model exhibits the accuracy anddifferentiation characteristics requisite for an effec-tive additional voter, as shown in the foregoing sec-Table 3: Comparison of the accuracies for the voting ensembles with and without the KPCA voter, confirm-ing that adding the KPCA-based model to the voting ensemble always helps on Senseval-3 Lexical Sampletasks.English(fine)English(coarse)Chinese Multilingual(t)Multilingual(ts)HKUST comb3 (me, boost, nb) 71.2 - 67.5 60.6 60.8HKUST comb2 (me, boost, nb, kpca) 71.4 78.6 66.2 62.0 63.8tions.
To verify that adding the KPCA-based modelto the voting ensemble indeed improves accuracy,we compared our voting ensemble?s accuracies tothat obtained with KPCA removed.
The results,shown in Table 3, confirm that the KPCA-basedmodel generally helps on Senseval-3 Lexical Sam-ple tasks.
The only exception is on Chinese, dueto the aforementioned anomaly of boosting outper-forming KPCA on that task.
In the Multilingual (t)and (ts) cases, the improvement in accuracy is sig-nificant.4 ConclusionWe have described our word sense disambiguationsystem and its performance on the Senseval-3 En-glish, Chinese, and Multilingual Lexical Sampletasks.
The system consists of an ensemble clas-sifier utilizing combinations of maximum entropy,boosting, na?
?ve Bayes, and a new Kernel PCA basedmodel.We have demonstrated that our new model basedon Kernel PCA is, along with maximum entropy,one of the most accurate stand-alone models vot-ing in the ensemble, as evaluated under carefullycontrolled to ensure the same optimized feature setacross all models being compared.
Moreover, wehave shown that the KPCA model exhibits a signif-icantly different classification bias, a characteristicthat makes it a valuable voter in an ensemble.
Theresults confirm that accuracy is generally improvedby the addition of the KPCA-based model.ReferencesXavier Carreras, Llu?
?s Ma`rques, and Llu?
?s Padro?.
Named entityextraction using AdaBoost.
In Dan Roth and Antal van denBosch, editors, Proceedings of CoNLL-2002, pages 167?170, Taipei, Taiwan, 2002.Konstantinos I. Diamantaras and Sun Yuan Kung.
PrincipalComponent Neural Networks.
Wiley, New York, 1996.Yoram Freund and Robert E. Schapire.
A decision-theoreticgeneralization of on-line learning and an application toboosting.
In Journal of Computer and System Sciences,55(1), pages 119?139, 1997.E.T.
Jaynes.
Where do we Stand on Maximum Entropy?
MITPress, Cambridge MA, 1978.Dan Klein and Christopher D. Manning.
Conditional struc-ture versus conditional estimation in NLP models.
In Pro-ceedings of EMNLP-2002, Conference on Empirical Meth-ods in Natural Language Processing, pages 9?16, Philadel-phia, July 2002.
SIGDAT, Association for ComputationalLinguistics.Taku Kudo and Yuji Matsumoto.
Fast methods for kernel-basedtext analysis.
In Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics, pages 24?31,2003.Grace Ngai, Dekai Wu, Marine Carpuat, Chi-Shing Wang,and Chi-Yung Wang.
Semantic role labeling with boost-ing, SVMs, maximum entropy, SNOW, and decision lists.In Proceedings of Senseval-3, Third International Work-shop on Evaluating Word Sense Disambiguation Systems,Barcelona, July 2004.
SIGLEX, Association for Computa-tional Linguistics.Robert E. Schapire and Yoram Singer.
Boostexter: A boosting-based system for text categorization.
In Machine Learning,39(2/3), pages 135?168, 2000.Bernhard Sch o?lkopf, Alexander Smola, and Klaus-RoberM u?ller.
Nonlinear component analysis as a kernel eigen-value problem.
Neural Computation, 10(5), 1998.Richard Wicentowski, Grace Ngai, Dekai Wu, Marine Carpuat,Emily Thomforde, and Adrian Packel.
Joining forces toresolve lexical ambiguity: East meets West in Barcelona.In Proceedings of Senseval-3, Third International Work-shop on Evaluating Word Sense Disambiguation Systems,Barcelona, July 2004.
SIGLEX, Association for Computa-tional Linguistics.Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, andYongsheng Yang.
Boosting for named entity recognition.In Dan Roth and Antal van den Bosch, editors, Proceedingsof CoNLL-2002, pages 195?198.
Taipei, Taiwan, 2002.Dekai Wu, Weifeng Su, and Marine Carpuat.
A Kernel PCAmethod for superior word sense disambiguation.
In Pro-ceedings of the 42nd Annual Meeting of the Association forComputational Linguistics, Barcelona, July 2004.David Yarowsky and Radu Florian.
Evaluating sense disam-biguation across diverse parameter spaces.
Natural Lan-guage Engineering, 8(4):293?310, 2002.
