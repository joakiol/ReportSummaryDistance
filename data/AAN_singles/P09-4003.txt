Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 9?12,Suntec, Singapore, 3 August 2009.c?2009 ACL and AFNLPA Tool for Deep Semantic Encoding of Narrative TextsDavid K. ElsonColumbia UniversityNew York Citydelson@cs.columbia.eduKathleen R. McKeownColumbia UniversityNew York Citykathy@cs.columbia.eduAbstractWe have developed a novel, publicly avail-able annotation tool for the semantic en-coding of texts, especially those in thenarrative domain.
Users can create for-mal propositions to represent spans of text,as well as temporal relations and otheraspects of narrative.
A built-in natural-language generation component regener-ates text from the formal structures, whicheases the annotation process.
We haverun collection experiments with the tooland shown that non-experts can easily cre-ate semantic encodings of short fables.We present this tool as a stand-alone, re-usable resource for research in semanticsin which formal encoding of text, espe-cially in a narrative form, is required.1 IntroductionResearch in language processing has benefitedgreatly from the collection of large annotatedcorpora such as Penn PropBank (Kingsbury andPalmer, 2002) and Penn Treebank (Marcus et al,1993).
Such projects typically involve a formalmodel (such as a controlled vocabulary of thematicroles) and a corpus of text that has been anno-tated against the model.
One persistent tradeoff inbuilding such resources, however, is that a modelwith a wider scope is more challenging for anno-tators.
For example, part-of-speech tagging is aneasier task than PropBank annotation.
We believethat careful user interface design can alleviate dif-ficulties in annotating texts against deep semanticmodels.
In this demonstration, we present a toolwe have developed, SCHEHERAZADE, for deepannotation of text.1We are using the tool to collect semantic rep-resentations of narrative text.
This domain occurs1Available at http://www.cs.columbia.edu/?delson.frequently, yet is rarely studied in computationallinguistics.
Narrative occurs with every other dis-course type, including dialogue, news, blogs andmulti-party interaction.
Given the volume of nar-rative prose on the Web, a system competent at un-derstanding narrative structures would be instru-mental in a range of text processing tasks, suchas summarization or the generation of biographiesfor question answering.In the pursuit of a complete and connected rep-resentation of the underlying facts of a story, ourannotation process involves the labeling of verbframes, thematic roles, temporal structure, modal-ity, causality and other features.
This type of anno-tation allows for machine learning on the thematicdimension of narrative ?
that is, the aspects thatunite a series of related facts into an engaging andfulfilling experience for a reader.
Our methodol-ogy is novel in its synthesis of several annotationgoals and its focus on content rather than expres-sion.
We aim to separate the narrative?s fabula, thecontent dimension of the story, from the rhetori-cal presentation at the textual surface (sju?zet) (Bal,1997).
To this end, our model incorporates formalelements found in other discourse-level annotationprojects such as Penn Discourse Treebank (Prasadet al, 2008) and temporal markup languages suchas TimeML (Mani and Pustejovsky, 2004).
Wecall the representation a story graph, because theseelements are embodied by nodes and connected byarcs that represent relationships such as temporalorder and motivation.More specifically, our annotation process in-volves the construction of propositions to best ap-proximate each of the events described in the tex-tual story.
Every element of the representationis formally defined from controlled vocabularies:the verb frames, with their thematic roles, areadapted from VerbNet (Kipper et al, 2006), thelargest verb lexicon available in English.
Whenthe verb frames are filled in to construct action9Figure 1: Screenshot from our tool showing the process of creating a formal proposition.
On the left, theuser is nesting three action propositions together; on the right, the user selects a particular frame from asearchable list.
The resulting propositions are regenerated in rectangular boxes.propositions, the arguments are either themselvespropositions or noun synsets from WordNet (thelargest available noun lexicon (Fellbaum, 1998)).Annotators can also write stative propositionsand modifiers (with adjectives and adverbs culledfrom WordNet), and distinguish between goals,plans, beliefs and other ?hypothetical?
modalities.The representation supports connectives includingcausality and motivation between these elements.Finally, and crucially, each proposition is boundto a state (time slice) in the story?s main timeline(a linear sequence of states).
Additional timelinescan represent multi-state beliefs, goals or plans.
Inthe course of authoring actions and statives, an-notators create a detailed temporal framework towhich they attach their propositions.2 Description of ToolThe collection process is amenable to communityand non-expert annotation by means of a graphicalencoding tool.
We believe this resource can servea range of experiments in semantics and humantext comprehension.As seen in Figure 1, the process of creating aproposition with our tool involves selecting an ap-propriate frame and filling the arguments indicatedby the thematic roles of the frame.
Annotators areguided through the process by a natural-languagegeneration component that is able to realize textualequivalents of all possible propositions.
A searchin the interface for ?flatter,?
for example, offers alist of relevant frames such as<A character> flat-ters<a character>.
Upon selecting this frame, anannotator is able to supply arguments by choosingactors from a list of declared characters.
?The foxflatters the crow,?
for one, would be internally rep-resented with the proposition <flatters>([Fox1],[Crow1]) where flatters, Fox and Crow are notsnippets of surface text, but rather selected Word-Net and VerbNet records.
(The subscript indi-cates that the proposition is invoking a particular[Fox] instance that was previously declared.)
Inthis manner an entire story can be encoded.Figure 2 shows a screenshot from our interfacein which propositions are positioned on a timelineto indicate temporal relationships.
On the rightside of the screen are the original text (used forreference) and the entire story as regenerated from10Figure 2: The main screen of our tool features a graphical timeline, as well as boxes for the referencetext and the story as regenerated by the system from the formal model.the current state of the formal model.
It is also pos-sible from this screen to invoke modalities suchas goals, plans and beliefs, and to indicate linksbetween propositions.
Annotators are instructedto construct propositions until the resulting textualstory, as realized by the generation component, isas close to their own understanding of the story aspermitted by the formal representation.The tool includes annotation guidelines for con-structing the best propositions to approximate thecontent of the story.
Depending on the intendeduse of the data, annotators may be instructed tomodel just the stated content in the text, or includethe implied content as well.
(For example, causallinks between events are often not articulated in atext.)
The resulting story graph is a unified rep-resentation of the entire fabula, without a story?sbeginning or end.
In addition, the tool allows an-notators to select spans of text and link them tothe corresponding proposition(s).
By indicatingwhich propositions were stated in the original text,and in what order, the content and presentation di-mensions of a story are cross-indexed.3 EvaluationWe have conducted several formative evaluationsand data collection experiments with this inter-face.
In one, four annotators each modeled four ofthe fables attributed to Aesop.
In another, two an-notators each modeled twenty fables.
We chose tomodel stories from the Aesop corpus due to sev-eral key advantages: the stories are mostly builtfrom simple declaratives, which are within the ex-pressive range of our semantic model, yet are richin thematic targets for automatic learning (such asdilemmas where characters must choose from be-tween competing values).In the latter collection, both annotators were un-dergraduates in our engineering school and nativeEnglish speakers, with little background in lin-guistics.
For this experiment, we instructed themto only model stated content (as opposed to includ-ing inferences), and skip the linking to spans ofsource text.
On average, they required 35-45 min-utes to encode a fable, though this decreased withpractice.
The 40 encodings include 574 proposi-tions, excluding those in hypothetical modalities.The fables average 130 words in length (so the an-notators created, on average, one proposition forevery nine words).Both annotators became comfortable with thetool after a period of training; in surveys that theycompleted after each task, they gave Likert-scaleusability scores of 4.25 and 4.30 (averaged overall 20 tasks, with a score of 5 representing ?easiestto use?).
The most frequently cited deficiencies inthe model were abstract concepts such as fair (inthe sense of a community event), which we plan tosupport in a future release.4 Results and Future WorkThe end result from a collection experiment isa collection of story graphs which are suitablefor machine learning.
An example story graph,based on the state of the tool seen in Figure 2, isshown in Figure 3.
Nodes in the graph representstates, declared objects and propositions (actionsand statives).
Each of the predicates (e.g.,<lion>,11?????
??????????????????????????????????????????????????????????????????
????????
??????????????????????????????????????????????????????????????
?Figure 3: A portion of a story graph representation as created by SCHEHERAZADE.<watch>, <cunning>) are linked to their corre-sponding VerbNet and WordNet records.We are currently experimenting with ap-proaches for data-driven analysis of narrative con-tent along the ?thematic?
dimension as describedabove.
In particular, we are interested in the auto-matic discovery of deep similarities between sto-ries (such as analogous structures and prototypicalcharacters).
We are also interested in investigat-ing the selection and ordering of content in thestory?s telling (that is, which elements are statedand which remain implied), especially as they per-tain to the reader?s affectual responses.
We planto make the annotated corpus publicly available inaddition to the tool.Overall, while more work remains in expandingthe model as well as the graphical interface, webelieve we are providing to the community a valu-able new tool for eliciting semantic encodings ofnarrative texts for machine learning purposes.5 Script OutlineOur demonstration involves a walk-through of theSCHEHERAZADE tool.
It includes:1.
An outline of the goals of the project and theinnovative aspects of our formal representa-tion compared to other representations cur-rently in the field.2.
A tour of the timeline screen (equivalent toFigure 2) as configured for a particular Aesopfable.3.
The procedure for reading a text for impor-tant named entities, and formally declaringthese named entities for the story graph.4.
The process for constructing propositions inorder to encode actions and statives in thetext, as seen in Figure 1.5.
Other features of the software package, suchas the setting of causal links and the ability toundo/redo.6.
A review of the results of our formative eval-uations and data collection experiments, in-cluding surveys of user satisfaction.ReferencesMieke Bal.
1997.
Narratology: Introduction to theTheory of Narrative.
University of Toronto Press,Toronto, second edition.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA.Paul Kingsbury and Martha Palmer.
2002.
From tree-bank to propbank.
In Proceedings of the Third In-ternational Conference on Language Resources andEvaluation (LREC-02), Canary Islands, Spain.Karin Kipper, Anna Korhonen, Neville Ryant, andMartha Palmer.
2006.
Extensive classifications ofenglish verbs.
In Proceedings of the 12th EURALEXInternational Congress, Turin, Italy.Inderjeet Mani and James Pustejovsky.
2004.
Tem-poral discourse models for narrative structure.
InProceedings of the ACL Workshop on Discourse An-notation, Barcelona, Spain.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The penn treebank.
Compu-tational Linguistics, 19.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The penn discourse treebank 2.0.
InProceedings of the 6th International Conference onLanguage Resources and Evaluation (LREC 2008).12
