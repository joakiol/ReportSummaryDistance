Session 9: Automatic Acquisition of Linguistic StructureMitchel l  Marcus, Session OrganizerUniversity of PennsylvaniaPhiladelphia, PA 19104This special session was devoted to a rapidly expandingfocus of research in natural anguage processing.
Fiveyears ago, only two or three pioneering researchers wereattempting toautomatically extract and utilize higher levellinguistic structure from large corpora; all of this work waswithin the stochastic modeling tradition.
The seven paperspresented within this session provide evidence that a widerange of research is now underway in the automatic ac-quisition of linguistic structure utilizing both symbolic andprobabilisric techniques as well as combinations of the two.Rayner and SamuelssonThe key idea behind this work, presented by Rayner, isthat multiple steps in the derivation of the syntactic andsemantic analysis of a natural language input can be com-posed into single analysis rules which can then be appliedmuch more efficiently to succeeding inputs.
The resultingrules are modular and fairly general in that the compositionalgorithm stops whenever the syntactic ategory NP is en-countered.
Applied to a prototype NL query system, aspeedup by a factor of 30 on following inputs has beenobserved on a small test corpus of queries.
It was clarifiedduring the question session that he system uses either thesespecial compiled rules on a fragment of text input or itsoriginal grammar; it never attempts to use both simul-taneously.Hindle and RoothThis work demonstrated a method by which a conven-tional broad coverage parser could be used to bootstrap anautomatic statistical procedure for deciding prepositionalphrase attachment, a key and central problem in naturallanguage understanding.
This procedure correctly decidedPP attachment with an accuracy of 78 % in a set of testcases where a PP might either modify the immediatelypreceding NP or the previous verb.
Surprisingly, humanjudges succeeded in determining the correct attachment aan accuracy of only 85 % given just the lexical informationthat the procedure used (i.e.
the verb, the head noun of thefollowing object and the the preposition).
Limiting deci-sions to cases where the procedure's confidence is greaterthan 95 % gives the same accuracy as these human judges,as does using only information extracted from the Cobuilddictionary (for the subset of cases where it contained infor-marion).Question session: Bob Moore pointed out during the dis-cussion that many preposition choices in real discourse arenonstandard; four of the preposition choices in the 6/90ATIS corpus were nonstandard including Flights leavingfrom Boston to NY.
Hindle, who presented the paper, sug-gested that a sufficiently large corpus of materials wouldsee such examples.
In response to another question, he alsosuggested that one could build a more complex algorithmwhich used more classical semantic information if the con-fidence of the algorithm was low.Chitrao and GrishmanChitrao presented this paper, which demonstrated an im-proved technique for assigning probabilities to the produc-tions of a context free grammar and using the resultingprobabilistic ontext free grammar to select among the al-ternate parses of an input sentence.
Rather than assigningprobabilities to each context free production rule (e.g.S---~NPVP)) in isolation, the context of each production istaken into account, and the priority assigned to each rule isdependent on the context in which it is used.
On a corpusof test sentences from the MUCK H training data, the par-ser derives the correct parse first about 6 % more oftenusing statistical techniques than without.
Using the newcontext sensitive techniques gives an additional 7 % in-crease in accuracy (to 37 % correct, with another 37 % inerror only due to PP attachment errors).
In response to aquery, it was revealed that while the techniques discussedhere work much better than unconstrained parsing, that theextensions of preference semantics presented at the lastDARPA workshop work marginally better by somemeasures .Sharman, Jelinek and MercerAccurately estimating the probabilities of each contextfree production in a probabilisric grammar intended for un-restricted text may well require a prohibitive amount oftraining material, if done straightforwardly.
This paper,presented by Jelinek, suggests using the so-called ID/LP(immediate dominance/linear p ecedence) formalism tofactor a set of context free productions into a set ofdominance relations, stating which non-terminals candominate which other symbols in the grammar, and a set ofprecedence r lations, stating which symbols will precedeother symbols in a derivation.
An experiment was per-formed using the IBM-funded Lancaster treebank of onemillion words of hand-parsed text taken from the APnewswire to use a probabilistic ID/LP grammar to parseEnglish sentences.
Tests show that the parser yields eithera correct or close-to-correct parse about 60 % of the time(exactly correct 19 %).During the question session, Ken Church argued thatparameterization purely structural relations, such as249used in this and the previous paper would be strikingly lesssuccessful than parameterization words, parametefizingperhaps (as in the Hindle and Rooth paper) on pairs ofwords in certain structural relations.
Much discussionresulted from a side comment of Jelinek's: A group fromIBM informally surveyed a number of of purportedly"broad-coverage" parsers within the US on a test set ofshort sentences less than 14 words in length, and dis-covered that the best parser correctly identifies the bestparse for these short sentences with an accuracy of only60 %.
While these results struck many of those attendingas extremely atypical, those who had worked on such par-sers felt the results were a fair and accurate representationof the state of the art.
It is my belief that the developmentof techniques similar to those presented in this session willlead to a major improvement i  the accuracy of parsers inthe very near future.Brill, Magerman, Marcus and SantoriniA report on several related pieces of research, this paperwas presented by the current writer.
This work investigatesthe possibility that the grammar of a language can be in-ferred automatically b  a distributional nalysis of a largecorpus of text.This work presents a new algorithm whichuses an information theoretic measure to derive a unlabeledbracketings of novel sentences using primarily an analysisof the distribution of part-of-speech $n$-grams in an ap-propriately annotated corpus.
On sentences of length lessthan 15, this algorithm misplaces on average 2-3 bracketsper sentence.
Initial experiments indicate that deriving ap-propriate part-of-speech tags from raw texts using similardistributional might well be possible.
In the discussion, itwas suggested that asymmetrical information measuresmight yield better esults.
The presenter responded thatthis might well be the case; while mutual information hasbeen widely investigated recently, other measures mightwell perform somewhat better on this task.Gale and ChurchAfter showing that the task of spelling correction is inmany ways closely analogous to the task of speech recog-nition, Church demonstrated that many standard estimatorsfail to yield correct results when used as part of a stochasticspelling corrector.
Because of anomalies that result fromsparse data problems, both the maximum likelihood es-timator and the expected likelihood estimator fail to yieldgood results in choosing the correct word to replace amisspelled word.
The Good-Turing method makes the useof contextual information useful, even in the case of verysparse data.
An algorithm that uses the G-T estimator to dospelling correction was presented.Much of the discussion focussed on the fact that spellingcorrection can often be separated into the correction of truetypos and misspellings due to ignorance.
Church notedthat he performance of spelling correctors for the later casecould be improved by utilizing stress information and ex-pecting unstressed vowels to be incorrect far more oftenthan stressed vowels.LewisLewis's contribution marks the first paper presented at aDARPA Speech and Natural Language Workshop by a re-searcher in the area of information retrieval (IR); it com-bines work in classical IR with work in natural anguageprocessing.
The work presented here derives from the viewthat automatic lassification within classical IR systemscan usefully be viewed as machine learning.
The paperitself investigates the use of structural relations as deter-mined by a conventional parser to create indexing phrases.It presents the results of preliminary experiments which useclustering techniques to aggregate ogether related syntacticphrases into single concept classes (i.e.
single dimensionsin a real valued, multi-dimensional concept space) usedwithin the context of an experimental IR system.During the discussion, itwas clarified that he clusteringtechnique used was nearest neighbor clustering usingcosine correlation between vectors.
To a comment thatYoung and Hayes achieved 100 %recall and 90 % precisionin work done for the Carnegie Group, Lewis pointed outthat the task of categorization which they were doing is afar different (and simpler) task than that of doing retrievalwith respect to arbitrary queries.I would like to thank Julia Hirschberg for taking on theduties of chairing the session itself at the workshop.250
