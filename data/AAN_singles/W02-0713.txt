Sharing Problems and Solutions for Machine Translation ofSpoken and Written InteractionSherri Condon             Keith MillerThe MITRE Corporation7515 Colshire DriveMcLean, VA 22102-7508{scondon, keith}@mitre.orgAbstractExamples from chat interaction arepresented to demonstrate that machinetranslation of written interactionshares many problems with translationof spoken interaction.
The potentialfor common solutions to the problemsis illustrated by describing operationsthat normalize and tag input beforetranslation.
Segmenting utterancesinto small translation units andprocessing short turns separately  arealso motivated using data from chat.1 IntroductionThe informal, dialogic character of oralinteraction imposes demands on translationsystems that are not encountered in well-formed,monologic texts.
These differences make itappear that any similarities between the machinetranslation of text and speech will be limited tocore translation components, as opposed to pre-and post-processing operations that are linked tothe medium.In this paper, we demonstrate that manychallenges of translating spoken interaction arealso encountered in translating writteninteraction such as chat or instant messaging.Consequently, it is proposed that solutionsdeveloped for these common problems can beshared by researchers engaged in applyingmachine translation technologies to both typesof interaction.
Specifically, preprocessingoperations can address many of the problemsthat make dialogic interaction difficult totranslate in both spoken and written media.After surveying the challenges that areshared in machine translation of spoken andwritten interaction, we identify several areas inwhich preprocessing solutions have beenproposed that could be fruitfully adopted foreither spoken or written input.
The speechrecognition problem of discriminating out ofvocabulary words from unrecognizedvocabulary words is equivalent to the problemof discriminating novel forms that emerge inchat environments from words that areunrecognized due to nonstandard spellings.
Wesuggest that a solution based on templates likethose used in example-based translation couldbe a useful approach to the problem for bothspoken and written input.
Similarly, otherpreprocessing operations that tag input forspecial processing can be used to facilitatetranslation of problematic phenomena such asdiscourse markers and vocatives.
Finally, weexplore the possibility that the complexity oftranslating interaction can be reduced bytranslating smaller packages of input andexploiting participants?
strategies for packagingcertain discourse functions in smaller turn units.2 Challenges for translation ofspoken and written interactionIn illustrating the problems for machinetranslation that are shared by both spoken andwritten interactions, we take for granted thatreaders are aware of examples that occur inspoken interaction because these are available inthe literature and from direct observation ofpersonal experience.
Therefore, we focus onproviding examples of written interaction todemonstrate that the same kinds of challengesarise in translation of chat and instant messages.Most of the examples we present are taken fromlogs of chat interactions collected from 10 chatchannels in 8 languages during July of 2001.The examples are presented exactly as theyappeared in the logs.Association for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
93-100.Proceedings of the Workshop on Speech-to-Speech Translation:2.1 Ellipsis and fragmentsThe elliptical and fragmentary quality ofordinary spoken dialogue is well-known and ischaracteristic of chat interaction, too, as in (1).
(1) a. faut voirb.
voir koi?The French expression il faut ?it is necessary?
isused without the pleonastic pronoun il, and theverb voir ?to see?
is used without a direct objectexpressing what it is necessary to see.
Thewriter may have intended to use voirintransitively, as in the English expression we?llhave to see, but the interlocutor who respondedwith (1b) asks ?to see what??
and omits both thepronoun and the verb faut.
(Creative spellingsuch as the convention that replaces the qu inquoi with k in koi is discussed in section 3.3.
)Though it is unlikely that preprocessingoperations will be able to add information that ismissing from fragments and ellipticalexpressions, these problems interact withpreprocessing operations such as segmentationof units for translation (see 2.9).2.2 High function/low content termsSpoken interaction is replete with formulaicexpressions that serve significant interactionalfunctions, but have little or no internal structure.These include greetings, leave-takings,affirmations, negations, and other interjections,some of which are illustrated in (2).
(2) a. re esselamu aleyk?mb.
in like califoniac.
jose?lets make 1The expression re is a conventional greeting inchat interaction with the function re-greet, as inhello again.
In (2a) it is used on a Turkish chatchannel preceding a greeting borrowed fromArabic with the literal meaning ?peace to you.
?The example in (2b) demonstrates that chatinteraction includes expressions such as like thatare usually associated exclusively with speech.Like and discourse markers such as well, now, soand anyway occur frequently in chat interaction.Wiebe et al (1995) identify discourse markersas a major area of difficulty for translation ofspoken interaction.
Many discourse markers arehomophonous and/or homographic with lexicalitems that have very different meanings, and theneed to disambiguate polysemous words hasreceived much attention in the languageprocessing and machine translation literature.The use of vocative proper names illustratedin (2c) is frequent in chat interaction, whereparticipants?
nicknames are used to directmessages to specific interlocutors.
In a smallsample of 76 messages from our chat logs, 31%included vocative uses of participants?nicknames.
In speech and in chat interactionlike (2), where punctuation is unpredictable (see3.2), capitalization cannot be relied on toidentify proper names.
The complexity oftranslating proper names has also receivedconsiderable attention in the machine translationresearch community, and translation of propernames has been proposed as an evaluationmeasure for machine translation (Papineni et al,2002; Vanni and Miller, 2002).2.3 VaguenessThough vagueness is a problem in all languageuse, Wiebe et al (1995) identify it as a majorproblem for translation of spoken interaction,citing metaphorical expressions such as de alli,literally, ?from there,?
translated as after that.More pervasive are the deixis and vaguenessthat result from the shared online context thatparticipants in real time interaction can rely on,compared to communication environments inwhich relevant context must be encoded in thetext itself.
Researchers have demonstrated theincreased explicitness and structural complexityof asynchronous interaction, in which delaysbetween the transmission of messages precludeimmediate feedback, compared to synchronousinteraction, in which it is expected that messageswill be responded to immediately (Chafe, 1982;Condon and Cech, forthcoming; Sotillo, 2000).Similarly, Popowich et al (2000) report that ahigh degree of semantic vagueness is a problemfor translating closed captions because the visualcontext provided by the television screensupplies missing details.2.4 AnaphoraAnother consequence of the synchronouscommunication environments in written andspoken interaction is the high frequency ofpronouns and deictic forms.
Wiebe et al (1995)report that 64% of utterances in a corpus ofspoken Spanish contained pronominalscompared to 48% of sentences in a writtencorpus.
Similarly, numerous studies havedemonstrated the high frequency of personalpronouns, especially first person pronouns, inchat interaction compared to other types ofwritten texts (Ferrara, Brunner and Whittemore,1991; Flanagan 1996; Yates, 1996).
Pronounsare particularly problematic for translation whenthe target language makes distinctions such asgender that are not present in the sourcelanguage.
To determine the appropriateinflection, the antecedent of the pronoun mustbe identified, and resolution of pronounantecedents is another thorny problem that hasattracted much attention from researchers inmachine translation.2.5  JunctureAlong with the liberties that participants in chatinteraction take with spelling and punctuationconventions (see 3.1,2), they also deliberately(and undoubtedly sometimes accidentally) omitspaces between words, as in (3).
(3) a. selamunaleykum  (= selamun aleykum)b. aleykumselam   (= aleykum selam)The Turkish ?peace to you?
greeting in (3a) is avariant of (2a) and is usually represented as twowords, though the merged forms in (3a) and inthe conventional reply (3b) occur several timesin a sample of our corpus.
Consequently, one ofthe basic challenges for speech recognition,identification of word boundaries, is also aproblem in chat interaction.2.6 Colloquial terms, idioms and slangWiebe et al (1995) use the term conventionalconstructions to refer to idiosyncraticcollocations and tense/aspect usage.
Colloquialor idiomatic usage complicates translation ofboth spoken and chat interaction, though it isless frequent in formal writing.
(4) providessome examples from chat.
(4) a. have a ball, y?allb.
do u sleep there n stuffLike discourse markers, expressions such ashave a ball in (4a) and [and] stuff in (4b), haveboth compositional and idiomatic meanings,which causes ambiguity that must be resolved.2.7 Code-switchingCode-switching is common in multilingualspeech communities, and the participants incommunication environments like chat tend tobe multilingual.
The Turkish to English switchin (5a) illustrates.
(5) a. anlamami istedigin seyi anlamadim sorryb.
salam mon frereIn (5b) from the #paris chat channel, Arabicsalam ?peace?
is used as a greeting.
Not onlyare these switches problematic for translationengines designed to map a single sourcelanguage into a single target language, but alsotranslation into a single language eliminates thesociolinguistic and pragmatic effects of code-switching.2.8  Language playAnother consequence of the informal contexts inwhich speech and chat interaction occur is theplayful use of language for entertainment, and inonline environments like chat, where fun oftenis the primary attraction,  humor and languageplay are valued (Danet et al, 1995).
In additionto play with identity and typographic symbols,which have become conventional in chatinteraction, novel games like (6) emerge.
(6) a. wewb.
wiwc.
wow(6) is part of a sequence on a Cebuano languagechannel in which the game seems to be toproduce consonant frames with different vowels.It ocurred after another game in whichparticipants inserted a vocative use of baby (asin hey baby) into almost every message, oftenaccompanied by additional codeswitching intoEnglish, and finally prompting the protest, ?youguys have been on that baby thing for ages.
?2.9 Segmentation of translation unitsJust as spoken interaction does not include cleardelimiters for word boundaries, it also lacksconventional means of marking larger units ofdiscourse that would be analogous to sentencepunctuation in written texts.
Similarly, thoughchat interaction is written, punctuation is ofteninconsistent or absent.
For example, vocativenicknames used to address messages to specificparticipants may not be separated from theremainder of the message by any punctuation orthey may be separated by commas, colons,ellipses, parentheses, brackets, and emoticons.The same range of possibilities occurs forpunctuation between sentences, which isfrequently absent.
Consequently, it is difficultto segment input into consistent units thattranslation components can anticipate.3 Analogous Challenges in Spokenand Written InteractionAnother set of problems that arise in translationof written interaction are not found in spokeninteraction because they involve the typographicsymbols that render language in written form.However, most of the problems have analogiesin spoken interaction, just as lack of punctuationin writing causes the same juncture andsegmentation problems encountered in speech.Most of the challenges in Section 2 representproblems for translation from the sourcelanguage to the target language, whereas thechallenges in this section primarily complicatethe problem of recognizing the source message.3.1 Unintentional misspellings andtypographical errorsNonstandard spellings occur so frequently inchat interaction that it is difficult to findexamples that do not contain them, as (2b)illustrates above.
Online interaction alsocontains many deliberate misspellings that arediscussed in the next section.
In addition tomisspellings like (2b) and (7a), we classify astypographic errors the many instances like (7b)in which participants fail to punctuatecontractions (though these may be deliberate).
(7) a. hi evenybodyb.
bon jai mon vrai nick crisse?good, I have my true nickname crisse?Unlike the English contraction I?ve, the Frenchcontraction j?ai ?I have?
is not optional:  it isalways spelled j?ai and neither je ai nor jai existin the French language.
This kind ofmisspelling is analogous to mispronunciationsand speech errors like slips of the tongue inspeech, though clearly these anomalous formsare much more frequent in chat interaction thanin speech.Another type of problem is the failure to usediacritic symbols associated with letters in someorthographic systems.
For example, in Frenchthe letter ?a?
without an accent represents the 3rdperson singular present tense form of the verb?have,?
while the form ?
is the preposition ?to.
?Both of these forms are pronounced the same,but in other cases the diacritic signifies a changein both pronunciation and meaning.
Forexample, marche is the 3rd person singularpresent tense form of the French verb marcher?to work, go?
and is pronounced like Englishmarsh with one syllable, but march?
?market?
isa noun pronounced with a second syllable [e].Consequently, the failure to follow orthographicconventions, creates homographs that presentthe same identification and ambiguity problemsas homophones do in speech.3.2 Creative spelling, rebus, andabbreviationsOnline interaction is famous for the creative andplayful conventions that have emerged forfrequently used expressions, and though most ofthese originated in English, it is now possible toobserve French mdr (mort de rire ?dying oflaughter?)
with English lol (laughing out loud)or amha (?
mon humble avis ?in my humbleopinion?)
like English imho (in my humbleopinion) and even Portuguese vc (voce ?you?
).Like the nonstandard spellings that areunintentional, these deliberate departures fromconvention are so frequent that we have alreadyseen several instances of rebus forms in (2c) and(4b) and the replacement of Romance qu by k in(1).
Other examples include English pls "please"and ur ?your,?
Turkish slm (selam ?peace?)
andthe French forms in (8).
(8) a. ah wi snooppy ?
"ah yes, snooppy?"b.
et c pa toi     "and it is not you"In (8a) oui ?yes?
is spelled wi, which reflects thepronunciation, and in (8b) the rebus form crepresents c?est ?it is,?
both pronounced [se],while pas is also spelled as pronounced, withoutthe silent s.  In the creative and rebus spellings,the nonstandard forms typically reflect thepronunciation of the word and the pronunciationis often a reduced one, as in hiya ?hi you?
andcyah ?see you.?
Consequently, these forms canbe viewed as analogous to the variation inspeech that is caused by use of reduced forms.Alternatively, these representations might beviewed as analogous to the out of vocabularywords that plague current speech recognizers.3.3 Register and dialect differencesChat interaction is subject to the same kinds ofregister and dialect variation that occurs inspeech.
For example (2a) employs a form of thestandard Turkish greeting esselamu aleyk?m thatis closer to the original Arabic because it usesthe Arabic definite article es-, though the umlautis not Arabic.
In contrast the variant in (3a),selamun aleykum, employs the Turkish suffix onselam, but omits the umlaut.
(8) illustrates othervariants that occurred in a sample of chat fromthe #ankara channel.
(9) a. selamun aleyk?mb.
selam?n aleykumc.
Selammmmmmmmmd.
selamlare.
selam allAnother example is the variable use of ne inFrench constructions with negative polarity.Though formal French uses ne before the verband pas after the verb for sentence negation,most varieties omit the ne in everyday contexts,as observed in (8b), where the absence of bothne and the s on pas creates serious problems forany translation engine that expects negation toappear as ne and pas in French.
This variationcombines with a creative spelling based onreduction to produce examples like (10).
(10)  shuis pa interess?
?I am not interested?The standard form of (10) is je ne suis pasinteress?, but in casual speech, ne is dropped,the vowel in je is omitted and the two adjacentfricatives merge to produce the sound that istypically spelled sh in English (though it isusually spelled ch in French).3.4 Emotives and repeated lettersTwo challenges for speech recognition are non-lexical sounds such as laughter or grunts and thedistortions of pronunciation that are caused byemphasis, fatigue, or emotions such as angerand boredom.
These complications haveanalogies in written interaction whenparticipants attempt to render the same soundsorthographically, producing forms like those in(9c) and (10).
(10) a. merhabaaaaaaaaaaaaaaaaaaaaaab.
ewwwc.
eeeeeeeeeeeeeeeeeeeeeeeeeeed.
heheheIn (10a) the final syllable of the Turkish greetingmerhaba is lengthened in the same way that itwould be in an enthusiastic and expansivegreeting, and (10b) effectively communicates atypical expression of disgust.
Laughter isrendered in a variety of ways including ha ha,heh heh, and (10d).
The variability of spellingsin these cases resembles the variability ofnonverbal sounds in speech.3.5 EmoticonsAnother way that chat participants expressemotion is by using emoticons and messagesthat consist entirely of punctuation, as in (11).
(11) a. hey Pipes` >:) how u doing?b.
o)))*******c.
!!!!d.
???
?Like the emotives and repeated letters describedin 3.4, these can be viewed as analogous to thenon-lexical sounds that occur in speech.However, they are probably more easilyidentified because they are drawn from a verylimited set of symbols.4 Sharing solutions to sharedproblemsBecause machine translations of spoken andwritten interaction share so many challenges, itis likely that solutions to the problems mightalso be shared in ways that will allow researchon the newer phenomenon of written interactionto benefit from the years of experience withspoken interaction.
Conversely, approaches towritten interaction, not biased by previousefforts, can provide fresh perspectives onfamiliar problems.
We present some examplesin which there appears to be strong potential forthis kind of mutual benefit, drawing on ourefforts to improve the performance of TrIM,MITRE?s Translingual Instant Messengerprototype.
TrIM is an instant messagingenvironment in which participants are able tointeract by reading and typing in their ownpreferred languages.
The system translates eachuser?s messages into the language of the otherparticipants and displays both the sourcelanguage and target language versions.TrIM?s translation services are provided bythe CyberTrans system, which provides acommon interface for various commercial texttranslation systems and several types of textdocuments (e.g.
e-mail, web, FrameMaker).
Itincorporates text normalization tools that canimprove the quality of the input text and thus theresultant translation.
Specifically, preprocessingsystems provide special handling forpunctuation and normalize spelling, such asadding diacritics that have been omitted.4.1 Spelling and recognition problemsCloser consideration of the problems created bynonstandard spellings  reveals the strongsimilarities between the complexity of speechrecognition and recognition of written words in?noisy?
communication environments such aschat.
In both cases, there is a need todiscriminate between words that are notrecognized because they are not in the systemand words that are in the system, but are notrecognized for other reasons, such as variationin phonetic form or a problem in the recognitionprocess.
Two properties of chat interactionmake this problem as serious for identifyingwritten words as it is for spoken input.
First,though a much larger vocabulary can bemaintained in digital memory than in the modelsof speech recognition systems, the creativity andinnovation that is valued in chat environmentsprovides a constant source of new vocabulary:it is guaranteed that there will always be out ofvocabulary (OOV) words.
Second,  the highfrequency of intentional and unintentionaldepartures from standard spelling matches thevariability of speech and makes it essential thatthe system be able to normalize spellings so thatmessages are not obscured by large numbers ofunidentified words.A variety of methods have been proposed inthe speech recognition literature for detectingOOV words.
Fetter (1998) reviews fourapproaches to the problem and observes thatthey can be classified in two broad groups:explicit acoustic and language models of OOVwords ?compete against models of in-vocabulary words during a word-basedsearch?Implicit models use informationderived from other recognition parameters tocompute the likelihood of OOV-words?
(Fetter,1998: 104).
In the latter group, he classifiesapproaches that use confidence measures, onlinegarbage modeling in keyword spotting, and theuse of an additional phoneme recognizerrunning in parallel to a word recognizer.
Theseapproaches might be adapted to the problem ofdiscriminating misspelled and OOV words inchat interaction, just as approaches to spellingcorrection might provide alternative solutions tothe analogous problem in speech recognition.For example, models of OOV words mightcompete with models of in-vocabularyrecognition errors using Brill and Moore?s(2000) error model for noisy channel spellingcorrection that takes into account theprobabilities of errors occurring in specificpositions in the word.
By modeling recognitionerrors, the model captures the stochasticproperties of both the language and theindividual recognition system.Because our goal is not only recognizing,but also translating messages, we are especiallyinterested in solutions that will facilitate thetranslation system and process.
Consequently,solutions based on modeling the contexts ofOOV word use and the contexts of nonstandardspellings seem most promising.
For example, itwould be worth exploring whether the templatesused in example-based translation could be usedto model these contexts.4.2 Preprocessing for special casesSeligman (2000) observes that current spokenlanguage translation systems use very differentmethods for recognizing phones, words, andsyntactic structures, and he envisions systems inwhich these processes are integrated, proposingalternatives that range from architectures whichsupport a common central data structure togrammars whose terminal symbols are phones.The latter approach appears to be too narrowbecause it precludes the possibility ofemploying preprocessing operations thatstructure input to facilitate translation.The success of TrIm and CyberTranssuggests that preprocessing operations offeruseful approaches to the challenges we haveidentified.
For example, a preprocessing systemin CyberTrans identifies words which are likelyto be missing diacritic symbols and inserts thembefore the input is sent to the translationengines.
As a result, the chat message in (12a)is correctly translated as (12b) rather than (12c)or (12d), which are the results from two systemsthat did not benefit from preprocessing.
(12) a. et la ca va mieuxb.
and there that is betterc.
and Ca is betterd.
and the ca goes betterThe French form la is the feminine definitearticle, whereas the form l?
is the demonstrativedeictic ?there.?
CyberTrans recognized that theform should be l?
and that ca should be ?a.Another example concerns the problems offorms such as discourse markers, vocatives, andgreetings.
(13) shows that when the discoursemarker well is separated by a comma, as in(13a), it is correctly translated as a discoursemarker in (13b), whereas without the comma in(13c), the translation uses puits, the word thatwould be used if referring to a water well.
(13) a.
Well, I'm feeling great!b.
Bien, je me sens grand!c.
well aren't we happy today?d.
puits ne sommes-nous pas heureuxaujourd'hui?Therefore, the comma served as a signal to thesystem to translate the discourse markerdifferently, and clearly, a preprocessingoperation that identifies and tags items likediscourse markers can facilitate their translation.4.3 Segmentation of translation unitsThough clause or sentence units are not clearlymarked in speech, the grammars on whichanalysis and translation rely typically operatewith the clause or sentence as the primary unitof analysis.
Consequently, the issue ofsegmenting speech into sentence-like units hasreceived considerable attention in the speechtranslation community, especially the possibilitythat prosodic information can be used to identifyappropriate boundaries (Kompe, 1997; Shriberget al, 2000).
Other efforts identify lexical itemswith high probabilities of occurring at sentenceboundaries and incorporate probabilistic models,taking into account acoustic features (Lavie etal.
1996) or part of speech information(Zechner, 2001).In contrast, some researchers have proposedthat identifying sentence boundaries is lessimportant than finding appropriate packagingsizes for translation.
For example, Seligman(2000) reports that pause units divided a corpusinto units that were smaller than sentence units,but could be parsed and yielded understandabletranslations when translated by hand.
Popowichet al (2000) deliberately segment closed captioninput into small packages for translation,claiming that it provides a basis for handling thevocatives, false starts, tag questions, and othernon-canonical structures encountered incaptions.
They also claim that the procedurereduces the scope of translation failures andconstrains the generation problem.
Since muchinteraction is already fragmented, processingthat relies on smaller units rather than sentencesseems worth investigating.A related possibility is that much of theproblematic input is already packaged in smallunits of short turns or messages.
Yu et al(2000) report that 54% of turns with a durationof 0.7 seconds or less in their data consisted ofeither yeah or mmhmm and about 70% of theturns contained the same 40 words or phrasalexpressions.
They took advantage of these factsby building a language model tailoredspecifically for short turns.In a pilot study, we examined a smallsample of chat data in order to determinewhether short messages were more likely tocontain the problematic features described insections 2 and 3.
Of 76 chat messages, 46 or61% were 3 units or less, where units weredelineated by space and punctuation (withoutseparation of contractions) and emoticonscounted as a unit.
The frequency of items suchas greetings, vocatives and acronyms wascounted for each message size.
Of 8 greetingsin the corpus, 7 occurred in messages of 3 orfewer words, and all 9 greeting-plus-vocativestructures occurred in messages of 3 or fewerwords.
Messages with 3 or fewer words alsocontained 11 of the 14 emotives in the corpus(including emoticons), 8 of the 10 messageswith repeated letters, 3 of the 3 acronyms, 2 ofthe 3 discourse markers, and both of theinterjections in the corpus.
These resultssupport the claim that much of the problematicusage in chat interaction is limited to short turnsthat can be identified and processed separately.5 ConclusionsThis paper demonstrates that many of theproblems which complicate translation ofspoken interaction are shared by writteninteraction such as chat and instant messaging.It is proposed that solutions developed to solvesimilar problems in the two communicationenvironments can be profitably shared, andseveral examples are presented where mutuallybeneficial approaches might be developed.Specifically, we noted that the problem ofdiscriminating unrecognized OOV words  fromin-vocabularly words in spoken interaction isanalogous to the problem of discriminatingunrecognized OOV words from misspelledwords in written interaction.
We suggested thatsome of the same methods used in spellingcorrection might be adapted to speechrecognition, especially language models thatincorporate probabilities of errors in specificpositions in the word.
We also observed thepotential of preprocessing operations thatstructure input for translation systems to allowspecial treatment of problematic language,including the possibility that much complexitycan be avoided by processing and translatingsmaller units separately.
We look forward toexploring these possibilities in future work.ReferencesBrill, Eric and Moore, Robert C.  2000.
An improvederror model for noisy channel spellingcorrection.
Proceedings of the 38th AnnualMeeting of the Association for ComputationalLinguistics.Chafe, Wallace.
1982.
Integration and involvement inspeaking, writing, and oral literature.
In Spokenand Written Language:  Exploring Orality andLiteracy, Deborah Tannen (Ed.
), Norwoord, NJ:Ablex, pp.
35-53.Condon, Sherri and Cech, Claude.
(Forthcoming)Discourse management in three modalities.
InComputer-Mediated Conversation, SusanHerring (Ed.
), Hampton Press.Danet, Brenda, Ruedenberg-Wright, Lucia, andRosenbaum-Tamari, Yehudit.
1995.
Hmmm...Where's that smoke coming from?"
Writing,Play and Performance on Internet Relay.
Journalof Computer-Mediated Communication, 1 (2).Ferrara, Kathleen, Brunner, Hans, and Whittemore,Greg.
1991.
Interactive written discourse as anemergent register.
Written Communication, 8(1), 8-34.Fetter, Pablo.
1998.
Detection and transcription ofOOV words.
Verbmobil Technical Report 231.Flanagan, Mary.
1996.
Two years online:Experiences, challenges and trends.
ExpandingMT Horizons:  Proceedings of the SecondConference of the Association for Machinetranslation in the Americas, 2-5 October,  pp.192-197.Kompe, Ralf.
1997.
Prosody in SpeechUnderstanding Systems.
Berlin:  Springer.Lavie, Alon, Gates, Donna, Coccaro, Noah andLevin, Lori.
1996.
Input segmentation ofspontaneous speech in Janus: A speech-to-speech translation system.
Proceedings of theECAI 96, Budapest, Hungary.Papineni, K., Roukos, S., Ward, T., Henderson, J.,and Reeder, Florence.
2002.
Corpus-Basedcomprehensive and diagnostic MT evaluation :Initial Arabic, Chinese, French, and Spanishresults.
Proceedings of the Human LanguageTechnology Conference.
San Diego, California.Popowich, Fred, McFetridge, Paul, Turcato, Davide,and Toole, Janine.
2000.
Machine translation ofclosed captions.
Machine Translation, 15, 311-341.Shriberg, Elizabeth, Stolcke, Andreas, Hakkani-Tur,Dilek, and Tur, Gokhan.
2000.
Prosody-basedautomatic segmentation of speech into sentencesand topics.
Speech Communication 32(1-2).Seligman, Mark.
2000.
Nine issues in speechtranslation.
Machine Translation, 15, 149-185.Sotillo, Susana M. 2000.
Discourse functions andsyntactic complexity in synchronous andasynchronous communication.
LanguageLearning & Technology, 4 (1), pp.
82-119.Vanni, Michelle.
and Miller, Keith.
2002.
Scalingthe ISLE framework: Use of existing corpusresources for validation of MT evaluationmetrics across languages.
In Proceedings ofLREC 2002.
Las Plamas, Canary Islands, Spain.Wiebe, Janice, Farwell, David, Villa, Daniel, Chen,J-L, Sinclaire, R., Sandgren, Thorsten, Stein, G.,Zarazua, David, and Ohara, Tom.
1995.ARTWORK:  Discourse Processing in MachineTranslation of Dialog.
Final Report Year 1.New Mexico State University:  ComputingResearch Lab.
http://crl.NMSU.Edu/Research/Projects/artwork/index.htmlYates, Simeon.
1996.
Oral and written linguisticaspects of computer conferencing:  A corpusbased study.
In Computer-MediatedCommunication:  Linguistic, Social and Cross-Cultural Perspectives., Susan Herring (Ed.
),Philadelphia:  John Benjamins, pp.
29-46.Yu, Hua, Tomokiyo, Takashi, Wang, Zhirong, andWaibel, Alex.
2000.
New developments inautomatic meeting transcription.
InternationalConference on Speech and Language Processing,Beijing, China.Zechner, Klaus.
2001.
Automatic Generation ofConcise Summaries of Spoken Dialogues inUnrestricted Domains.
Proceedings of the 24thACM-SIGIR International Conference onResearch and Development in InformationRetrieval, New Orleans, Louisiana.
