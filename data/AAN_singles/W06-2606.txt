Reranking Translation Hypotheses Using Structural PropertiesSas?a Hasan, Oliver Bender, Hermann NeyChair of Computer Science VIRWTH Aachen UniversityD-52056 Aachen, Germany{hasan,bender,ney}@cs.rwth-aachen.deAbstractWe investigate methods that add syntac-tically motivated features to a statisticalmachine translation system in a rerankingframework.
The goal is to analyze whethershallow parsing techniques help in iden-tifying ungrammatical hypotheses.
Weshow that improvements are possible byutilizing supertagging, lightweight depen-dency analysis, a link grammar parser anda maximum-entropy based chunk parser.Adding features to n-best lists and dis-criminatively training the system on a de-velopment set increases the BLEU scoreup to 0.7% on the test set.1 IntroductionStatistically driven machine translation systemsare currently the dominant type of system in theMT community.
Though much better than tradi-tional rule-based approaches, these systems stillmake a lot of errors that seem, at least from a hu-man point of view, illogical.The main purpose of this paper is to investigatea means of identifying ungrammatical hypothesesfrom the output of a machine translation systemby using grammatical knowledge that expressessyntactic dependencies of words or word groups.We introduce several methods that try to establishthis kind of linkage between the words of a hy-pothesis and, thus, determine its well-formedness,or ?fluency?.
We perform rescoring experimentsthat rerank n-best lists according to the presentedframework.As methodologies deriving well-formedness ofa sentence we use supertagging (Bangalore andJoshi, 1999) with lightweight dependency anal-ysis (LDA)1 (Bangalore, 2000), link grammars(Sleator and Temperley, 1993) and a maximum-entropy (ME) based chunk parser (Bender et al,2003).
The former two approaches explicitlymodel the syntactic dependencies between words.Each hypothesis that contains irregularities, suchas broken linkages or non-satisfied dependencies,should be penalized or rejected accordingly.
Forthe ME chunker, the idea is to train n-gram mod-els on the chunk or POS sequences and directlyuse the log-probability as feature score.In general, these concepts and the underlyingprograms should be robust and fast in order to beable to cope with large amounts of data (as it is thecase for n-best lists).
The experiments presentedshow a small though consistent improvement interms of automatic evaluation measures chosen forevaluation.
BLEU score improvements, for in-stance, lie in the range from 0.3 to 0.7% on thetest set.In the following, Section 2 gives an overviewon related work in this domain.
In Section 3we review our general approach to statistical ma-chine translation (SMT) and introduce the mainmethodologies used for deriving syntactic depen-dencies on words or word groups, namely su-pertagging/LDA, link grammars and ME chunk-ing.
The corpora and the experiments are dis-cussed in Section 4.
The paper is concluded inSection 5.2 Related workIn (Och et al, 2004), the effects of integratingsyntactic structure into a state-of-the-art statisticalmachine translation system are investigated.
Theapproach is similar to the approach presented here:1In the context of this work, the term LDA is not to beconfused with linear discriminant analysis.41firstly, a word graph is generated using the base-line SMT system and n-best lists are extracted ac-cordingly, then additional feature functions repre-senting syntactic knowledge are added and the cor-responding scaling factors are trained discrimina-tively on a development n-best list.Och and colleagues investigated a large amountof different feature functions.
The field of appli-cation varies from simple syntactic features, suchas IBM model 1 score, over shallow parsing tech-niques to more complex methods using grammarsand intricate parsing procedures.
The results wererather disappointing.
Only one of the simplestmodels, i.e.
the implicit syntactic feature derivedfrom IBM model 1 score, yielded consistent andsignificant improvements.
All other methods hadonly a very small effect on the overall perfor-mance.3 FrameworkIn the following sections, the theoretical frame-work of statistical machine translation using a di-rect approach is reviewed.
We introduce the su-pertagging and lightweight dependency analysisapproach, link grammars and maximum-entropybased chunking technique.3.1 Direct approach to SMTIn statistical machine translation, the best trans-lation e?I?1 = e?1 .
.
.
e?i .
.
.
e?I?
of source words fJ1 =f1 .
.
.
fj .
.
.
fJ is obtained by maximizing the con-ditional probabilitye?I?1 = argmaxI,eI1{Pr(eI1|fJ1 )}= argmaxI,eI1{Pr(fJ1 |eI1) ?
Pr(eI1)}(1)using Bayes decision rule.
The first probabilityon the right-hand side of the equation denotes thetranslation model whereas the second is the targetlanguage model.An alternative to this classical source-channelapproach is the direct modeling of the posteriorprobability Pr(eI1|fJ1 ) which is utilized here.
Us-ing a log-linear model (Och and Ney, 2002), weobtainPr(eI1|fJ1 ) =exp(?Mm=1 ?mhm(eI1, fJ1 ))?e?I?1exp(?Mm=1 ?mhm(e?I?1 , fJ1 )) ,(2)where ?m are the scaling factors of the models de-noted by feature functions hm(?).
The denomina-tor represents a normalization factor that dependsonly on the source sentence fJ1 .
Therefore, we canomit it during the search process, leading to thefollowing decision rule:e?I?1 = argmaxI,eI1{ M?m=1?mhm(eI1, fJ1 )}(3)This approach is a generalization of the source-channel approach.
It has the advantage that ad-ditional models h(?)
can be easily integrated intothe overall system.
The model scaling factors?M1 are trained according to the maximum en-tropy principle, e.g., using the GIS algorithm.
Al-ternatively, one can train them with respect tothe final translation quality measured by an errorcriterion (Och, 2003).
For the results reportedin this paper, we optimized the scaling factorswith respect to a linear interpolation of word errorrate (WER), position-independent word error rate(PER), BLEU and NIST score using the DownhillSimplex algorithm (Press et al, 2002).3.2 Supertagging/LDASupertagging (Bangalore and Joshi, 1999) uses theLexicalized Tree Adjoining Grammar formalism(LTAG) (XTAG Research Group, 2001).
Tree Ad-joining Grammars incorporate a tree-rewriting for-malism using elementary trees that can be com-bined by two operations, namely substitution andadjunction, to derive more complex tree structuresof the sentence considered.
Lexicalization allowsus to associate each elementary tree with a lexicalitem called the anchor.
In LTAGs, every elemen-tary tree has such a lexical anchor, also called headword.
It is possible that there is more than one el-ementary structure associated with a lexical item,as e.g.
for the case of verbs with different subcat-egorization frames.The elementary structures, called initial andauxiliary trees, hold all dependent elements withinthe same structure, thus imposing constraints onthe lexical anchors in a local context.
Basically,supertagging is very similar to part-of-speech tag-ging.
Instead of POS tags, richer descriptions,namely the elementary structures of LTAGs, areannotated to the words of a sentence.
For this pur-pose, they are called supertags in order to distin-guish them from ordinary POS tags.
The resultis an ?almost parse?
because of the dependencies42very[?2]food[?1] delicious[?3]the[?1]was[?2]Figure 1: LDA: example of a derivation tree, ?nodes are the result of the adjunction operation onauxiliary trees, ?
nodes of substitution on initialtrees.coded within the supertags.
Usually, a lexical itemcan have many supertags, depending on the vari-ous contexts it appears in.
Therefore, the local am-biguity is larger than for the case of POS tags.
AnLTAG parser for this scenario can be very slow, i.e.its computational complexity is in O(n6), becauseof the large number of supertags, i.e.
elementarytrees, that have to be examined during a parse.
Inorder to speed up the parsing process, we can ap-ply n-gram models on a supertag basis in order tofilter out incompatible descriptions and thus im-prove the performance of the parser.
In (Banga-lore and Joshi, 1999), a trigram supertagger withsmoothing and back-off is reported that achievesan accuracy of 92.2% when trained on one millionrunning words.There is another aspect to the dependenciescoded in the elementary structures.
We can usethem to actually derive a shallow parse of the sen-tence in linear time.
The procedure is presentedin (Bangalore, 2000) and is called lightweight de-pendency analysis.
The concept is comparable tochunking.
The lightweight dependency analyzer(LDA) finds the arguments for the encoded depen-dency requirements.
There exist two types of slotsthat can be filled.
On the one hand, nodes markedfor substitution (in ?-trees) have to be filled by thecomplements of the lexical anchor.
On the otherhand, the foot nodes (i.e.
nodes marked for adjunc-tion in ?-trees) take words that are being modifiedby the supertag.
Figure 1 shows a tree derived byLDA on the sentence the food was very deliciousfrom the C-Star?03 corpus (cf.
Section 4.1).The supertagging and LDA tools are availablefrom the XTAG research group website.2As features considered for the reranking exper-iments we choose:2http://www.cis.upenn.edu/?xtag/D D EA EAP PSSthe food very deliciouswasFigure 2: Link grammar: example of a valid link-age satisfying all constraints.?
Supertagger output: directly use the log-likelihoods as feature score.
This did not im-prove performance significantly, so the modelwas discarded from the final system.?
LDA output:?
dependency coverage: determine thenumber of covered elements, i.e.
wherethe dependency slots are filled to the leftand right?
separate features for the number of mod-ifiers and complements determined bythe LDA3.3 Link grammarSimilar to the ideas presented in the previous sec-tion, link grammars also explicitly code depen-dencies between words (Sleator and Temperley,1993).
These dependencies are called links whichreflect the local requirements of each word.
Sev-eral constraints have to be satisfied within the linkgrammar formalism to derive correct linkages, i.e.sets of links, of a sequence of words:1.
Planarity: links are not allowed to cross eachother2.
Connectivity: links suffice to connect allwords of a sentence3.
Satisfaction: linking requirements of eachword are satisfiedAn example of a valid linkage is shown in Fig-ure 2.
The link grammar parser that we use isfreely available from the authors?
website.3 Sim-ilar to LTAG, the link grammar formalism is lex-icalized which allows for enhancing the methodswith probabilistic n-gram models (as is also thecase for supertagging).
In (Lafferty et al, 1992),the link grammar is used to derive a new class of3http://www.link.cs.cmu.edu/link/43[NP the food ] [VP was] [ADJP very delicious]the/DT food/NN was/VBD very/RB delicious/JJFigure 3: Chunking and POS tagging: a tag nextto the opening bracket denotes the type of chunk,whereas the corresponding POS tag is given afterthe word.language models that, in comparison to traditionaln-gram LMs, incorporate capabilities for express-ing long-range dependencies between words.The link grammar dictionary that specifies thewords and their corresponding valid links cur-rently holds approximately 60 000 entries and han-dles a wide variety of phenomena in English.
It isderived from newspaper texts.Within our reranking framework, we use linkgrammar features that express a possible well-formedness of the translation hypothesis.
The sim-plest feature is a binary one stating whether thelink grammar parser could derive a complete link-age or not, which should be a strong indicator ofa syntactically correct sentence.
Additionally, weadded a normalized cost of the matching processwhich turned out not to be very helpful for rescor-ing, so it was discarded.3.4 ME chunkingLike the methods described in the two preced-ing sections, text chunking consists of dividing atext into syntactically correlated non-overlappinggroups of words.
Figure 3 shows again our ex-ample sentence illustrating this task.
Chunks arerepresented as groups of words between squarebrackets.
We employ the 11 chunk types as de-fined for the CoNLL-2000 shared task (Tjong KimSang and Buchholz, 2000).For the experiments, we apply a maximum-entropy based tagger which has been successfullyevaluated on natural language understanding andnamed entity recognition (Bender et al, 2003).Within this tool, we directly factorize the poste-rior probability and determine the correspondingchunk tag for each word of an input sequence.
Weassume that the decisions depend only on a lim-ited window ei+2i?2 = ei?2...ei+2 around the currentword ei and on the two predecessor chunk tagsci?1i?2.
In addition, part-of-speech (POS) tags gI1are assigned and incorporated into the model (cf.Figure 3).
Thus, we obtain the following second-order model:Pr(cI1|eI1, gI1) ==I?i=1Pr(ci|ci?11 , eI1, gI1) (4)=I?i=1p(ci|ci?1i?2, ei+2i?2, gi+2i?2), (5)where the step from Eq.
4 to 5 reflects our modelassumptions.Furthermore, we have implemented a set of bi-nary valued feature functions for our system, in-cluding lexical, word and transition features, priorfeatures, and compound features, cf.
(Bender etal., 2003).
We run simple count-based featurereduction and train the model parameters usingthe Generalized Iterative Scaling (GIS) algorithm(Darroch and Ratcliff, 1972).
In practice, thetraining procedure tends to result in an overfittedmodel.
To avoid this, a smoothing method is ap-plied where a Gaussian prior on the parameters isassumed (Chen and Rosenfeld, 1999).Within our reranking framework, we firstly usethe ME based tagger to produce the POS andchunk sequences for the different n-best list hy-potheses.
Given several n-gram models trained onthe WSJ corpus for both POS and chunk models,we then rescore the n-best hypotheses and simplyuse the log-probabilities as additional features.
Inorder to adapt our system to the characteristics ofthe data used, we build POS and chunk n-grammodels on the training corpus part.
These domain-specific models are also added to the n-best lists.The ME chunking approach does not model ex-plicit syntactic linkages of words.
Instead, it in-corporates a statistical framework to exploit validand syntactically coherent groups of words by ad-ditionally looking at the word classes.4 ExperimentsFor the experiments, we use the translation sys-tem described in (Zens et al, 2005).
Our phrase-based decoder uses several models during searchthat are interpolated in a log-linear way (as ex-pressed in Eq.
3), such as phrase-based translationmodels, word-based lexicon models, a language,deletion and simple reordering model and wordand phrase penalties.
A word graph containingthe most likely translation hypotheses is generatedduring the search process.
Out of this compact44Supplied Data TrackArabic Chinese Japanese EnglishTrain Sentences 20 000Running Words 180 075 176 199 198 453 189 927Vocabulary 15 371 8 687 9 277 6 870Singletons 8 319 4 006 4 431 2 888C-Star?03 Sentences 506Running Words 3 552 3 630 4 130 3 823OOVs (Running Words) 133 114 61 65IWSLT?04 Sentences 500Running Words 3 597 3 681 4 131 3 837OOVs (Running Words) 142 83 71 58Table 1: Corpus statistics after preprocessing.representation, we extract n-best lists as describedin (Zens and Ney, 2005).
These n-best lists serveas a starting point for our experiments.
The meth-ods presented in Section 3 produce scores that areused as additional features for the n-best lists.4.1 CorporaThe experiments are carried out on a subsetof the Basic Travel Expression Corpus (BTEC)(Takezawa et al, 2002), as it is used for the sup-plied data track condition of the IWSLT evaluationcampaign.
BTEC is a multilingual speech corpuswhich contains tourism-related sentences similarto those that are found in phrase books.
For thesupplied data track, the training corpus contains20 000 sentences.
Two test sets, C-Star?03 andIWSLT?04, are available for the language pairsArabic-English, Chinese-English and Japanese-English.The corpus statistics are shown in Table 1.
Theaverage source sentence length is between sevenand eight words for all languages.
So the task israther limited and very domain-specific.
The ad-vantage is that many different reranking experi-ments with varying feature function settings canbe carried out easily and quickly in order to ana-lyze the effects of the different models.In the following, we use the C-Star?03 set fordevelopment and tuning of the system?s parame-ters.
After that, the IWSLT?04 set is used as ablind test set in order to measure the performanceof the models.4.2 Rescoring experimentsThe use of n-best lists in machine translation hasseveral advantages.
It alleviates the effects of thehuge search space which is represented in wordgraphs by using a compact excerpt of the n besthypotheses generated by the system.
Especiallyfor limited domain tasks, the size of the n-best listcan be rather small but still yield good oracle er-ror rates.
Empirically, n-best lists should have anappropriate size such that the oracle error rate, i.e.the error rate of the best hypothesis with respect toan error measure (such asWER or PER) is approx-imately half the baseline error rate of the system.N -best lists are suitable for easily applying severalrescoring techniques since the hypotheses are al-ready fully generated.
In comparison, word graphrescoring techniques need specialized tools whichcan traverse the graph accordingly.
Since a nodewithin a word graph allows for many histories, onecan only apply local rescoring techniques, whereasfor n-best lists, techniques can be used that con-sider properties of the whole sentence.For the Chinese-English and Arabic-Englishtask, we set the n-best list size to n = 1500.
ForJapanese-English, n = 1000 produces oracle er-ror rates that are deemed to be sufficiently low,namely 17.7% and 14.8% for WER and PER, re-spectively.
The single-best output for Japanese-English has a word error rate of 33.3% andposition-independent word error rate of 25.9%.For the experiments, we add additional fea-tures to the initial models of our decoder that haveshown to be particularly useful in the past, such asIBM model 1 score, a clustered language modelscore and a word penalty that prevents the hy-potheses to become too short.
A detailed defini-tion of these additional features is given in (Zenset al, 2005).
Thus, the baseline we start with is45Chinese ?
English, C-Star?03 NIST BLEU[%] mWER[%] mPER[%]Baseline 8.17 46.2 48.6 41.4with supertagging/LDA 8.29 46.5 48.4 41.0with link grammar 8.43 45.6 47.9 41.1with supertagging/LDA + link grammar 8.22 47.5 47.7 40.8with ME chunker 8.65 47.3 47.4 40.4with all models 8.42 47.0 47.4 40.5Chinese ?
English, IWSLT?04 NIST BLEU[%] mWER[%] mPER[%]Baseline 8.67 45.5 49.1 39.8with supertagging/LDA 8.68 45.4 49.8 40.3with link grammar 8.81 45.0 49.0 40.2with supertagging/LDA+link grammar 8.56 46.0 49.1 40.6with ME chunker 9.00 44.6 49.3 40.6with all models 8.89 46.2 48.1 39.6Table 2: Effect of successively adding syntactic features to the Chinese-English n-best list for C-Star?03(development set) and IWSLT?04 (test set).BASE Any messages for me?RESC Do you have any messages for me?REFE Do you have any messages for me?BASE She, not yet?RESC She has not come yet?REFE Lenny, she has not come in?BASE How much is it to the?RESC How much is it to the local call?REFE How much is it to the city centre?BASE This blot or.RESC This is not clean.REFE This still is not clean.Table 3: Translation examples for the Chinese-English test set (IWSLT?04): baseline system(BASE) vs. rescored hypotheses (RESC) and refer-ence translation (REFE).already a very strong one.
The log-linear inter-polation weights ?m from Eq.
3 are directly opti-mized using the Downhill Simplex algorithm on alinear combination of WER (word error rate), PER(position-independent word error rate), NIST andBLEU score.In Table 2, we show the effect of adding thepresented features successively to the baseline.Separate entries for experiments using supertag-ging/LDA and link grammars show that a combi-nation of these syntactic approaches always yieldssome gain in translation quality (regarding BLEUscore).
The performance of the maximum-entropybased chunking is comparable.
A combination ofall three models still yields a small improvement.Table 3 shows some examples for the Chinese-English test set.
The rescored translations are syn-tactically coherent, though semantical correctnesscannot be guaranteed.
On the test data, we achievean overall improvement of 0.7%, 0.5% and 0.3%in BLEU score for Chinese-English, Japanese-English and Arabic-English, respectively (cf.
Ta-bles 4 and 5).4.3 DiscussionFrom the tables, it can be seen that the use ofsyntactically motivated feature functions withina reranking concept helps to slightly reduce thenumber of translation errors of the overall trans-lation system.
Although the improvement on theIWSLT?04 set is only moderate, the results arenevertheless comparable or better to the ones from(Och et al, 2004), where, starting from IBMmodel 1 baseline, an additional improvement ofonly 0.4% BLEU was achieved using more com-plex methods.For the maximum-entropy based chunking ap-proach, n-grams with n = 4 work best for thechunker that is trained on WSJ data.
The domain-specific rescoring model which results from thechunker being trained on the BTEC corpora turnsout to prefer higher order n-grams, with n = 6 ormore.
This might be an indicator of the domain-specific rescoring model successfully capturingmore local context.The training of the other models, i.e.
supertag-ging/LDA and link grammar, is also performed on46Japanese ?
English, C-Star?03 NIST BLEU[%] mWER[%] mPER[%]Baseline 9.09 57.8 31.3 25.0with supertagging/LDA 9.13 57.8 31.3 24.8with link grammar 9.46 57.6 31.9 25.3with supertagging/LDA + link grammar 9.24 58.2 31.0 24.8with ME chunker 9.31 58.7 30.9 24.4with all models 9.21 58.9 30.5 24.3Japanese ?
English, IWSLT?04 NIST BLEU[%] mWER[%] mPER[%]Baseline 9.22 54.7 34.1 25.5with supertagging/LDA 9.27 54.8 34.2 25.6with link grammar 9.37 54.9 34.3 25.9with supertagging/LDA + link grammar 9.30 55.0 34.0 25.6with ME chunker 9.27 55.0 34.2 25.5with all models 9.27 55.2 33.9 25.5Table 4: Effect of successively adding syntactic features to the Japanese-English n-best list for C-Star?03(development set) and IWSLT?04 (test set).Arabic ?
English, C-Star?03 NIST BLEU[%] mWER[%] mPER[%]Baseline 10.18 64.3 23.9 20.6with supertagging/LDA 10.13 64.6 23.4 20.1with link grammar 10.06 64.7 23.4 20.3with supertagging/LDA + link grammar 10.20 65.0 23.2 20.2with ME chunker 10.11 65.1 23.0 19.9with all models 10.23 65.2 23.0 19.9Arabic ?
English, IWSLT?04 NIST BLEU[%] mWER[%] mPER[%]Baseline 9.75 59.8 26.1 21.9with supertagging/LDA 9.77 60.5 25.6 21.5with link grammar 9.74 60.5 25.9 21.7with supertagging/LDA + link grammar 9.86 60.8 26.0 21.6with ME chunker 9.71 59.9 25.9 21.8with all models 9.84 60.1 26.4 21.9Table 5: Effect of successively adding syntactic features to the Arabic-English n-best list for C-Star?03(development set) and IWSLT?04 (test set).out-of-domain data.
Thus, further improvementsshould be possible if the models were adapted tothe BTEC domain.
This would require the prepa-ration of an annotated corpus for the supertaggerand a specialized link grammar, which are bothtime-consuming tasks.The syntactically motivated methods (supertag-ging/LDA and link grammars) perform similarlyto the maximum-entropy based chunker.
It seemsthat both approaches successfully exploit struc-tural properties of language.
However, one outlieris ME chunking on the Chinese-English test data,where we observe a lower BLEU but a larger NISTscore.
For Arabic-English, the combination of allmethods does not seem to generalize well on thetest set.
In that case, supertagging/LDA and linkgrammar outperforms the ME chunker: the over-all improvement is 1% absolute in terms of BLEUscore.5 ConclusionWe added syntactically motivated features to a sta-tistical machine translation system in a rerank-ing framework.
The goal was to analyze whethershallow parsing techniques help in identifying un-grammatical hypotheses.
We showed that someimprovements are possible by utilizing supertag-ging, lightweight dependency analysis, a link47grammar parser and a maximum-entropy basedchunk parser.
Adding features to n-best lists anddiscriminatively training the system on a develop-ment set helped to gain up to 0.7% in BLEU scoreon the test set.Future work could include developing anadapted LTAG for the BTEC domain or incor-porating n-gram models into the link grammarconcept in order to derive a long-range languagemodel (Lafferty et al, 1992).
However, we feelthat the current improvements are not significantenough to justify these efforts.
Additionally, wewill apply these reranking methods to larger cor-pora in order to study the effects on longer sen-tences from more complex domains.AcknowledgmentsThis work has been partly funded by theEuropean Union under the integrated projectTC-Star (Technology and Corpora for Speechto Speech Translation, IST-2002-FP6-506738,http://www.tc-star.org), and by the R&D projectTRAMES managed by Bertin Technologies asprime contractor and operated by the french DGA(De?le?gation Ge?ne?rale pour l?Armement).ReferencesSrinivas Bangalore and Aravind K. Joshi.
1999.
Su-pertagging: An approach to almost parsing.
Com-putational Linguistics, 25(2):237?265.Srinivas Bangalore.
2000.
A lightweight dependencyanalyzer for partial parsing.
Computational Linguis-tics, 6(2):113?138.Oliver Bender, Klaus Macherey, Franz Josef Och, andHermann Ney.
2003.
Comparison of alignmenttemplates and maximum entropy models for naturallanguage understanding.
In EACL03: 10th Conf.
ofthe Europ.
Chapter of the Association for Computa-tional Linguistics, pages 11?18, Budapest, Hungary,April.Stanley F. Chen and Ronald Rosenfeld.
1999.
A gaus-sian prior for smoothing maximum entropy models.Technical Report CMUCS-99-108, Carnegie MellonUniversity, Pittsburgh, PA.J.
N. Darroch and D. Ratcliff.
1972.
Generalized iter-ative scaling for log-linear models.
Annals of Math-ematical Statistics, 43:1470?1480.John Lafferty, Daniel Sleator, and Davy Temperley.1992.
Grammatical trigrams: A probabilistic modelof link grammar.
In Proc.
of the AAAI Fall Sympo-sium on Probabilistic Approaches to Natural Lan-guage, pages 89?97, Cambridge, MA.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for sta-tistical machine translation.
In Proc.
of the 40th An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 295?302, Philadelphia, PA,July.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alex Fraser, ShankarKumar, Libin Shen, David Smith, Katherine Eng,Viren Jain, Zhen Jin, and Dragomir Radev.
2004.A smorgasbord of features for statistical machinetranslation.
In Proc.
2004 Meeting of the NorthAmerican chapter of the Association for Compu-tational Linguistics (HLT-NAACL), pages 161?168,Boston, MA.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proc.
of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 160?167, Sapporo,Japan, July.William H. Press, Saul A. Teukolsky, William T. Vet-terling, and Brian P. Flannery.
2002.
NumericalRecipes in C++.
Cambridge University Press, Cam-bridge, UK.Daniel Sleator and Davy Temperley.
1993.
ParsingEnglish with a link grammar.
In Third InternationalWorkshop on Parsing Technologies, Tilburg/Durbuy,The Netherlands/Belgium, August.Toshiyuki Takezawa, Eiichiro Sumita, F. Sugaya,H.
Yamamoto, and S. Yamamoto.
2002.
Towarda broad-coverage bilingual corpus for speech trans-lation of travel conversations in the real world.
InProc.
of the Third Int.
Conf.
on Language Resourcesand Evaluation (LREC), pages 147?152, Las Pal-mas, Spain, May.Erik F. Tjong Kim Sang and Sabine Buchholz.2000.
Introduction to the CoNLL-2000 sharedtask: Chunking.
In Proceedings of CoNLL-2000and LLL-2000, pages 127?132, Lisbon, Portugal,September.XTAG Research Group.
2001.
A Lexicalized TreeAdjoining Grammar for English.
Technical Re-port IRCS-01-03, IRCS, University of Pennsylvania,Philadelphia, PA, USA.Richard Zens and Hermann Ney.
2005.
Word graphsfor statistical machine translation.
In 43rd AnnualMeeting of the Assoc.
for Computational Linguis-tics: Proc.
Workshop on Building and Using Par-allel Texts: Data-Driven Machine Translation andBeyond, pages 191?198, Ann Arbor, MI, June.Richard Zens, Oliver Bender, Sas?a Hasan, ShahramKhadivi, Evgeny Matusov, Jia Xu, Yuqi Zhang, andHermann Ney.
2005.
The RWTH phrase-basedstatistical machine translation system.
In Proceed-ings of the International Workshop on Spoken Lan-guage Translation (IWSLT), pages 155?162, Pitts-burgh, PA, October.48
