Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1562?1572,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsPlot Induction and Evolutionary Search for Story GenerationNeil McIntyre and Mirella LapataSchool of Informatics, University of Edinburgh10 Crichton Street, Edinburgh, EH8 9AB, UKn.d.mcintyre@sms.ed.ac.uk, mlap@inf.ed.ac.ukAbstractIn this paper we develop a story genera-tor that leverages knowledge inherent incorpora without requiring extensive man-ual involvement.
A key feature in our ap-proach is the reliance on a story plannerwhich we acquire automatically by record-ing events, their participants, and theirprecedence relationships in a training cor-pus.
Contrary to previous work our systemdoes not follow a generate-and-rank archi-tecture.
Instead, we employ evolutionarysearch techniques to explore the space ofpossible stories which we argue are wellsuited to the story generation task.
Experi-ments on generating simple children?s sto-ries show that our system outperforms pre-vious data-driven approaches.1 IntroductionComputer story generation has met with fasci-nation since the early days of artificial intelli-gence.
Indeed, over the years, several genera-tors have been developed capable of creating sto-ries that resemble human output.
To name onlya few, TALE-SPIN (Meehan, 1977) generates sto-ries through problem solving, MINSTREL (Turner,1992) relies on an episodic memory scheme, es-sentially a repository of previous hand-coded sto-ries, to solve the problems in the current story,and MAKEBELIEVE (Liu and Singh, 2002) usescommonsense knowledge to generate short storiesfrom an initial seed story (supplied by the user).
Alarge body of more recent work views story gener-ation as a form of agent-based planning (Swartjesand Theune, 2008; Pizzi et al, 2007).
The agentsact as characters with a list of goals.
They formplans of action and try to fulfill them.
Interestingstories emerge as plans interact and cause failuresand possible replanning.The broader appeal of computational story gen-eration lies in its application potential.
Examplesinclude the entertainment industry and the devel-opment of tools that produce large numbers ofplots automatically that might provide inspirationto professional screen writers (Agudo et al, 2004);rendering video games more interesting by allow-ing the plot to adapt dynamically to the players?actions (Barros and Musse, 2007); and assistingteachers to create or personalize stories for theirstudents (Riedl and Young, 2004).A major stumbling block for the widespread useof computational story generators is their relianceon expensive, manually created resources.
A typi-cal story generator will make use of a knowledgebase for providing detailed domain-specific infor-mation about the characters and objects involvedin the story and their relations.
It will also have astory planner that specifies how these charactersinteract, what their goals are and how their ac-tions result in different story plots.
Finally, a sen-tence planner (coupled with a surface realizer) willrender an abstract story specification into naturallanguage text.
Traditionally, most of this knowl-edge is created by hand, and the effort must be re-peated for new domains, new characters and plotelements.Fortunately, recent work in natural languageprocessing has taken significant steps towards de-veloping algorithms that learn some of this knowl-edge automatically from natural language cor-pora.
Chambers and Jurafsky (2009, 2008) pro-pose an unsupervised method for learning narra-tive schemas, chains of events whose argumentsare filled with participant semantic roles definedover words.
An example schema is {X arrest, Xcharge, X raid, X seize, X confiscate, X detain, Xdeport}, where X stands for the argument types{police, agent, authority, government}.
Their ap-proach relies on the intuition that in a coherenttext events that are about the same participants are1562likely to be part of the same story or narrative.Their model extracts narrative chains, essentiallyevents that share argument slots and merges theminto schemas.
The latter could be used to constructor enrich the knowledge base of a story generator.In McIntyre and Lapata (2009) we presented astory generator that leverages knowledge inherentin corpora without requiring extensive manual in-volvement.
The generator operates over predicate-argument and predicate-predicate co-occurrencetuples gathered from training data.
These are usedto produce a large set of candidate stories whichare subsequently ranked based on their interest-ingness and coherence.
The approach is unusualin that it does not involve an explicit story plan-ning component.
Stories are created stochasticallyby selecting entities and the events they are mostfrequently attested with.In this work we develop a story generator thatis also data-driven but crucially relies on a storyplanner for creating meaningful stories.
Inspiredby Chambers and Jurafsky (2009) we acquire storyplots automatically by recording events, their par-ticipants, and their precedence relationships as at-tested in a training corpus.
Entities give rise todifferent potential plots which in turn generatemultiple stories.
Contrary to our previous work(McIntyre and Lapata, 2009), we do not follow agenerate-and-rank architecture.
Instead, we searchthe space of possible stories using Genetic Algo-rithms (GAs) which we argue are advantageousin the story generation setting, as they can searchlarge fitness landscapes while greatly reducing therisk of getting stuck in local optima.
By virtue ofexploring the search space more broadly, we areable to generate creative stories without an explicitinterest scoring module.In the remainder of this paper we give a briefoverview of the system described in McIntyre andLapata (2009) and discuss previous applications ofGAs in natural language generation (Section 2).Next, we detail our approach, specifically howplots are created and used in conjunction with ge-netic search (Sections 3 and 4).
Finally, we presentour experimental results (Sections 6 and 7) andconclude the paper with discussion of future work.2 Related WorkOur work builds on and extends the story genera-tor developed in McIntyre and Lapata (2009).
Thesystem creates simple children?s stories in an in-teractive context: the user supplies the topic of thestory and its desired length (number of sentences).The generator creates a story following a pipelinearchitecture typical of natural language generationsystems (Reiter and Dale, 2000) consisting of con-tent selection, sentence planning, and surface real-ization.The content of a story is determined by consult-ing a data-driven knowledge base that records theentities (i.e., nouns) appearing in a corpus and theactions they perform.
These are encoded as depen-dency relations (e.g., subj-verb, verb-obj).
In orderto promote between-sentence coherence the gen-erator also make use of an action graph that con-tains action-role pairs and the likelihood of tran-sitioning from one to another.
The sentence plan-ner aggregates together entities and their actionsinto a sentence using phrase structure rules.
Fi-nally, surface realization is performed by interfac-ing RealPro (Lavoie and Rambow, 1997) with alanguage model.
The system searches for the beststory overall as well as the best sentences that canbe generated from the knowledge base.
Unlikelystories are pruned using beam search.
In addition,stories are reranked using two scoring functionsbased on coherence and interest.
These are learntfrom training data, i.e., stories labeled with nu-meric values for interest and coherence.Evolutionary search techniques have been pre-viously employed in natural language generation,especially in the context of document planning.Structuring a set of facts into a coherent text is ef-fectively a search problem that may lead to com-binatorial explosion for large domains.
Mellishet al (1998) (and subsequently Karamanis andManurung 2002) advocate genetic algorithms asan alternative to exhaustively searching for the op-timal ordering of descriptions of museum arte-facts.
Rather than requiring a global optimum tobe found, the genetic algorithm selects an order(based on coherence) that is good enough for peo-ple to understand.
Cheng and Mellish (2000) focuson the interaction of aggregation and text planningand use genetic algorithms to search for the bestaggregated document that satisfies coherence con-straints.The application of genetic algorithms to storygeneration is novel to our knowledge.
Our workalso departs from McIntyre and Lapata (2009) intwo important ways.
Firstly, our generator doesnot rely on a knowledge base of seemingly un-related entities and relations.
Rather, we employ1563a document planner to create and structure a plotfor a story.
The planner is built automatically froma training corpus and creates plots dynamicallydepending on the protagonists of the story.
Sec-ondly, our search procedure is simpler and moreglobal; instead of searching for the best story twice(i.e., by first finding the n-best stories and thensubsequently reranking them based on coherenceand interest), our genetic algorithm explores thespace of possible stories once.3 Plot GenerationFollowing previous work (e.g., Shim and Kim2002; McIntyre and Lapata 2009) we assume thatthe user supplies a sentence (e.g., the princessloves the prince) from which the system createsa story.
Each entity in this sentence (e.g., princess,prince) is associated with its own narrativeschema, a set of key events and actors co-occurring with it in the training corpus.
Our nar-rative schemas differ slightly from Chambers andJurafsky (2009).
They acquire schematic represen-tations of situations akin to FrameNet (Fillmoreet al, 2003): schemas consists of semanticallysimilar predicates and the entities evoked by them.In our setting, every entity has its own schema, andpredicates associated with it are ordered.
Plots aregenerated by merging the entity-specific narrativeschemas which subsequently serve as the input tothe genetic algorithm.
In the following we describehow the narrative schemas are extracted and plotsmerged, and then discuss our evolutionary searchprocedure.Entity-based Schema Extraction Before wecan generate a plot for a story we must have anidea of the actions associated with the entities inthe story, the order in which these actions are per-formed and also which other entities can partici-pate.
This information is stored in a directed graphwhich we explain below.
Our algorithm processeseach document at a time, it operates over depen-dency structures and assumes that entity mentionshave been resolved.
In our experiments we usedRasp (Briscoe and Carroll, 2002), a broad cover-age dependency parser, and the OpenNLP1 coref-erence resolution engine.2 However, any depen-dency parser or coreference tool could serve our1See http://opennlp.sourceforge.net/.2The coreference resolution tool we employ is noterror-free and on occasion will fail to resolve a pronoun.
Wemap unresolved pronouns to the generic labels person or ob-ject.purpose.
We also assume that the actions associ-ated with a given entity are ordered and that lin-ear order corresponds to temporal order.
This is agross simplification as it is well known that tem-poral relationships between events are not limitedto precedence, they may overlap, occur simultane-ously, or be temporally unrelated.
We could haveobtained a more accurate ordering using a tempo-ral classifier (see Chambers and Jurafsky 2008),however we leave this to future work.For each entity e in the corpus we build a di-rected graph G = (V,E) whose nodes V denotepredicate argument relationships, and edges E rep-resent transitions from node Vi to node Vj.
Asan example of our schema construction process,consider a very small corpus consisting of thetwo documents shown in Figure 1.
The schemafor princess after processing the first document isgiven on the left hand side.
Each node in this graphcorresponds to an action attested with princess (wealso record who performs it and where or how).Nodes are themselves dependency trees (see Fig-ure 4a), but are linearized in the figure for thesake of brevity.
Edges in the graph indicate order-ing and are weighted using the mutual informa-tion metric proposed in Lin (1998) (the weightsare omitted from the example).3 The first sentencein the text gives rise to the first node in the graph,the second sentence to the second node, and so on.Note that the third sentence is not present in thegraph as it is not about the princess.When processing the second document, we sim-ply expand this graph.
Before inserting a newnode, we check if it can be merged with an al-ready existing one.
Nodes are merged only if theyhave the same verb and similar arguments, withthe focal entity (i.e., princess) appearing in thesame argument slot.
In our example, the nodes?prince marry princess in castle?
and ?princemarry princess in temple?
can be merged as theycontain the same verb and number of similar ar-guments.
The nodes ?princess have influence?and ?princess have baby?
cannot be merged asinfluence and baby are semantically unrelated.We compute argument similarity using WordNet(Fellbaum, 1998) and the measure proposed byWu and Palmer (1994) which is based on pathlength.
We merge nodes with related argumentsonly if their similarity exceeds a threshold (deter-mined empirically).3We use mutual information to identify event sequencesstrongly associated with the graph entity.1564The goblin holds the princess in a lair.The prince rescues the princess andmarries her in a castle.
The ceremonyis beautiful.
The princess has influenceas the prince rules the country.The dragon holds the princess in acave.
The prince slays the dragon.
Theprincess loves the prince.
The princeasks the king?s permission.
The princemarries the princess in the temple.
Theprincess has a baby.goblin hold princess in lairprince rescue princessprince marry princess in castleprincess have influence[goblindragon]hold princess in[laircave]prince rescue princess princess love princeprince marry princess in[castletemple]princess have influence princess have babyFigure 1: Example of schema construction for the entity princessThe schema construction algorithm terminateswhen graphs like the ones shown in Figure 1 (righthand side) have been created for all entities in thecorpus.Building a Story Plot Our generator takes an in-put sentence and uses it to instantiate several plots.We achieve this by merging the schemas associ-ated with the entities in the sentence into a plotgraph.
As an example, consider again the sentencethe princess loves the prince which requires comb-ing the schemas representing prince and princessshown in Figures 2 and 1 (right hand side), re-spectively.
Again, we look for nodes that can bemerged based on the identity of the actions in-volved and the (WordNet) similarity of their ar-guments.
However, we disallow the merging ofnodes with focal entities appearing in the same ar-gument slot (e.g., ?
[prince, princess] cries?
).Once the plot graph is created, a depth firstsearch starting from the node corresponding tothe input sentence, finds all paths with lengthmatching the desired story length (cycles are dis-allowed).
Assuming we wish to generate a storyconsisting of three sentences, the graph in Figure 3would create four plots.
These are (princess loveprince, prince marry princess in [castle, temple],princess have influence), (princess love prince,prince marry princess in [castle, temple], princesshave baby), (princess love prince, prince marryprincess in [castle, temple], prince rule country),and (princess love prince, prince ask king?s per-mission prince marry princess in [castle, temple]).Each of these plots represents two different storiesone with castle and one with temple in it.Sentence Planning The sentence planner is in-terleaved with the story planner and influencesthe final structure of each sentence in the story.To avoid generating short sentences ?
note thatnodes in the plot graph consist of a single ac-tion and would otherwise correspond to a sentencewith a single clause ?
we combine pairs of nodeswithin the same graph by looking at intrasenten-tial verb-verb co-occurrences in the training cor-pus.
For example, the nodes (prince have prob-lem, prince keep secret) could become the sen-tence the prince has a problem keeping a secret.We leave it up to the sentence planner to decidehow the two actions should be combined.4 Thesentence planner will also insert adverbs and ad-jectives, using co-occurrence likelihoods acquiredfrom the training corpus.
It is essentially a phrasestructure grammar compiled from the lexical re-sources made available by Korhonen and Briscoe(2006) and Grishman et al (1994).
The grammarrules act as templates for combining clauses andfilling argument slots.4We only turn an action into a subclause if its subject en-tity is same as that of the previous action.1565prince slay dragonprince rescue princessprincess love princeprince marry princess in[castletemple]prince ask king?s permissionprince rule countryFigure 2: Narrative schema for the entity prince.4 Genetic AlgorithmsThe example shown in Figure 3 is a simplified ver-sion of a plot graph.
The latter would normallycontain hundreds of nodes and give rise to thou-sands of stories once lexical variables have beenexpanded.
Searching the story space is a difficultoptimization problem, that must satisfy severalconstraints: the story should be of a certain length,overall coherent, creative, display some form ofevent progression, and generally make sense.
Weargue that evolutionary search is appealing here, asit can find global optimal solutions in a more effi-cient way than traditional optimization methods.In this study we employ genetic algorithms(GAs) a well-known search technique for findingapproximate (or exact) solutions to optimizationproblems.
The basic idea behind GAs is basedon ?natural selection?
and the Darwinian princi-ple of the survival of the fittest (Mitchell, 1998).An initial population is randomly created contain-ing a predefined number of individuals (or solu-tions), each represented by a genetic string (e.g., apopulation of chromosomes).
Each individual isevaluated according to an objective function (alsocalled a fitness function).
A number of individu-als are then chosen as parents from the populationaccording to their fitness, and undergo crossover(also called recombination) and mutation in orderto develop the new population.
Offspring with bet-ter fitness are then inserted into the population,replacing the inferior individuals in the previousgeneration.The algorithm thus identifies the individualswith the optimizing fitness values, and those withlower fitness will naturally get discarded from thepopulation.
This cycle is repeated for a given num-ber of generations, or stopped when the solution[goblindragon]hold princess in[laircave]prince rescue princess princess love princeprince marry princess in[castletemple]princess have influenceprincess have babyprince slay dragonprince ask king?spermissionprince rule countryFigure 3: Plot graph for the input sentence theprincess loves the prince.obtained is considered optimal.
This process leadsto the evolution of a population in which the in-dividuals are more and more suited to their envi-ronment, just as natural adaptation.
We describebelow how we developed a genetic algorithm forour story generation problem.Initial Population Rather than start with a ran-dom population, we seed the initial populationwith story plots generated from our plot graph.For an input sentence, we generate all possibleplots.
The latter are then randomly sampled until apopulation of the desired size is created.
Contraryto McIntyre and Lapata (2009), we initialize thesearch with complete stories, rather than generateone sentence at a time.
The genetic algorithm willthus avoid the pitfall of selecting early on a solu-tion that will later prove detrimental.Crossover Each plot is represented as an or-dered graph of dependency trees (correspondingto sentences).
We have decided to use crossover ofa single point between two selected parents.
Thechildren will therefore contain sentences up to thecrossover point of the first parent and sentencesafter that point of the second.
Figure 4a showstwo parents (prince rescue princess, prince marryprincess in castle, princess have baby) and (princerescue princess, prince love princess, princess kissprince) and how two new plots are created byswapping their last nodes.1566a) rescueprince princessmarryprince princess castlehaveprincess babyrescueprince princessloveprince princesskissprincess prince=?rescueprince princessmarryprince princess castlekissprince princessrescueprince princessloveprince princesshaveprincess babyin inb) marryprince princess castlehalltempleforestkingdomc) rescueprince princessmarryprince princess castlekissprince princessinrescueprince princessmarryprince princess castlekissprince princessind) rescueprince princessmarryprince princess castlekissprince princessin=?holdprince princesse) knowsprincelovesprincess child=?escapeprincess dragonFigure 4: Example of genetic algorithm operators as they are applied to plot structures: a) crossover oftwo plots on a single point, indicated by the dashed line, resulting in two children which are a recombi-nation of the parents; b) mutation of a lexical node, church can be replaced from a list of semanticallyrelated candidates; c) sentences can be switched under mutation to create a potentially more coherentstructure; d) if the matrix verb undergoes mutation then, a random sentence is generated to replace it; e)if the verb chosen for mutation is the head of a subclause, then a random subclause replaces it.Mutation Mutation can occur on any verb,noun, adverb, or adjective in the plot.
If a noun,adverb or adjective is chosen to undergo mutation,then we simply substitute it with a new lexical itemthat is sufficiently similar (see Figure 4b for anexample).
Verbs, however, have structural impor-tance in the stories and we cannot simply replacethem without taking account of their arguments.If a matrix verb is chosen to undergo mutation,then a new random sentence is generated to re-place the entire sentence (see Figure 4d).
If it isa subclause, then it is replaced with a randomlygenerated clause, headed by a verb that has beenseen in the corpus to co-occur with the matrix verb(Figure 4e).
The sentence planner selects and fillstemplate trees for generating random clauses.
Mu-tation may also change the order of any two nodesin the graph in the hope that this will increase thestory?s coherence or create some element of sur-prise (see Figure 4c).Selection To choose the plots for the next gener-ation, we used fitness proportional selection (alsoknow as roulette-wheel selection, Goldberg 1989)which chooses candidates randomly but with abias towards those with a larger proportion of thepopulation?s combined fitness.
We do not want toalways select the fittest candidates as there maybe valid partial solutions held within less fit mem-bers of the population.
However, we did employsome elitism by allowing the top 1% of solutionsto be copied straight from one generation to thenext.
Note that our candidates may also representinvalid solutions.
For instance, through crossoverit is possible to create a plot in which all or somenodes are identical.
If any such candidates areidentified, they are assigned a low fitness, withouthowever being eliminated from the population assome could be used to create fitter solutions.In a traditional GA, the fitness function dealswith one optimization objective.
It is possible tooptimize several objectives either using a vot-1567ing model or more sophisticated methods such asPareto ranking (Goldberg, 1989).
Following previ-ous work (Mellish et al, 1998) we used a single fit-ness function that scored candidates based on theircoherence.
Our function was learned from trainingdata using the Entity Grid document representa-tion proposed in Barzilay and Lapata (2007).
Anentity grid is a two-dimensional array in whichcolumns correspond to entities and rows to sen-tences.
Each cell indicates whether an entity ap-pears in a given sentence or not and whether it is asubject, object or neither.
For training, this repre-sentation is converted into a feature vector of en-tity transition sequences and a model is learnt fromexamples of coherent and incoherent stories.
Thelatter can be easily created by permuting the sen-tences of coherent stories (assuming that the orig-inal story is more coherent than its permutations).In addition to coherence, in McIntyre and La-pata (2009) we used a scoring function based oninterest which we approximated with lexical andsyntactic features such as the number of noun/verbtokens/types, the number of subjects/objects, thenumber of letters, word familiarity, imagery, andso on.
An interest-based scoring function madesense in our previous setup as a means of selectingunusual stories.
However, in the context of geneticsearch such a function seems redundant as inter-esting stories emerge naturally through the opera-tions of crossover and mutation.5 Surface RealizationOnce the final generation of the population hasbeen reached, the fittest story is selected for sur-face realization.
The realizer takes each sentencein the story and reformulates it into input com-patible with the RealPro (Lavoie and Rambow,1997) text generation engine.
Realpro creates sev-eral variants of the same story differing in thechoice of determiners, number (singular or plural),and prepositions.
A language model is then usedto select the most probable realization (Knightand Hatzivassiloglou, 1995).
Ideally, the realizershould also select an appropriate tense for the sen-tence.
However, we make the simplifying assump-tion that all sentences are in the present tense.6 Experimental SetupIn this section we present our experimental set-upfor assessing the performance of our story genera-tor.
We give details on our training corpus, system,parameters (such as the population size for the GAsearch), the baselines used for comparison, and ex-plain how our system output was evaluated.Corpus The generator was trained on the samecorpus used in McIntyre and Lapata (2009), 437stories from the Andrew Lang fairy tales collec-tion.5 The average story length is 125.18 sen-tences.
The corpus contains 15,789 word tokens.Following McIntyre and Lapata, we discarded to-kens that did not appear in the Children?s PrintedWord Database6, a database of printed word fre-quencies as read by children aged between fiveand nine.
From this corpus we extracted narrativeschemas for 667 entities in total.
We disregardedany graph that contained less than 10 nodes as toosmall.
The graphs had on average 61.04 nodes,with an average clustering rate7 of 0.027 which in-dicates that they are substantially connected.Parameter Setting Considerable latitude isavailable when selecting parameters for the GA.These involve the population size, crossover, andmutation rates.
To evaluate which setting was best,we asked two human evaluators to rate (on a 1?5scale) stories produced with a population sizeranging from 1,000 to 10,000, crossover rate of 0.1to 0.6 and mutation rate of 0.001 to 0.1.
For eachrun of the system a limit was set to 5,000 genera-tions.
The human ratings revealed that the best sto-ries were produced for a population size of 10,000,a crossover rate of 0.1% and a mutation rateof 0.1%.
Compared to previous work (e.g., Kara-manis and Manurung 2002) our crossover ratemay seem low and the mutation rate high.
How-ever, it makes intuitively sense, as high crossovermay lead to incoherence by disrupting canonicalaction sequences found in the plots.
On the otherhand, a higher mutation will raise the likelihood ofa lexical item being swapped for another and mayimprove overall coherence and interest.
The fit-ness function was trained on 200 documents fromthe fairy tales collection using Joachims?s (2002)SVMlight package and entity transition sequencesof length 2.
The realizer was interfaced with a tri-gram language model trained on the British Na-tional Corpus with the SRI toolkit.5Available from http://homepages.inf.ed.ac.uk/s0233364/McIntyreLapata09/.6http://www.essex.ac.uk/psychology/cpwd/7Clustering rate (or transitivity) is the number of trianglesin the graph ?
sets of three vertices each of which is con-nected to each of the others.1568Evaluation We compared the stories gener-ated by the GA against those produced by therank-based system described in McIntyre and La-pata (2009) and a system that creates stories fromthe plot graph, without any stochastic search.Since plot graphs are weighted, we can simply se-lect the graph with the highest weight.
After ex-panding all lexical variables, the chosen plot graphwill give rise to different stories (e.g., castle ortemple in the example above).
We select the storyranked highest according to our coherence func-tion.
In addition, we included a baseline whichrandomly selects sentences from the training cor-pus provided they contain either of the story pro-tagonists (i.e., entities in the input sentence).
Sen-tence length was limited to 12 words or less as thiswas on average the length of the sentences gener-ated by our GA system.Each system created stories for 12 input sen-tences, resulting in 48 (4?12) stories for eval-uation.
The sentences used commonly occurringentities in the fairy tales corpus (e.g., The childwatches the bird, The emperor rules the kingdom.,The wizard casts the spell.).
The stories were splitinto three sets containing four stories from eachsystem but with only one story from each inputsentence.
All stories had the same length, namelyfive sentences.
Human judges were presented withone of the three sets and asked to rate the storieson a scale of 1 to 5 for fluency (was the sentencegrammatical?
), coherence (does the story makesense overall?)
and interest (how interesting is thestory?).
The stories were presented in random or-der and participants were told that all of themwere generated by a computer program.
They wereinstructed to rate more favorably interesting sto-ries, stories that were comprehensible and overallgrammatical.
The study was conducted over theInternet using WebExp (Keller et al, 2009) andwas completed by 56 volunteers, all self reportednative English speakers.7 ResultsOur results are summarized in Table 1 which liststhe average human ratings for the four systems.We performed an Analysis of Variance (ANOVA)to examine the effect of system type on the storygeneration task.
Statistical tests were carried outon the mean of the ratings shown in Table 1 forfluency, coherence, and interest.In terms of interest, the GA-based system is sig-System Fluency Coherence InterestGA-based 3.09 2.48 2.36Plot-based 3.03 2.36 2.14?Rank-based 1.96??
1.65?
1.85?Random 3.10 2.23?
2.20?Table 1: Human evaluation results: mean storyratings for four story generators; ?
: p < 0.05,??
: p < 0.01, significantly different fromGA-based system.nificantly better than the Rank-based, Plot-basedand Random ones (using a Post-hoc Tukey test,?
< 0.05).
With regard to fluency, the Rank-based system is significantly worse than the rest(?
< 0.01).
Interestingly, the sentences generatedby the GA and Plot-based systems are as fluent asthose created by humans.
Recall that the Randomsystem, simply selects sentences from the train-ing corpus.
Finally, the GA system is significantlymore coherent than the Rank-based and Randomsystems (?
< 0.05), but not the Plot-based one.This is not surprising, the GA and Plot-based sys-tems rely on similar plots to create a coherentstory.
The performance of the Random system isalso inferior as it does not have any explicit coher-ence enforcing mechanism.
The Rank-based sys-tem is perceived overall worse.
As this system isalso the least fluent, we conjecture that partici-pants are influenced in their coherence judgmentsby the grammaticality of the stories.Overall our results indicate that an explicit storyplanner improves the quality of the generated sto-ries, especially when coupled with a search mech-anism that advantageously explores the searchspace.
It is worth noting that the Plot-based sys-tem is relatively simple, however the explicit useof a story plot, seems to make up for the lack ofsophisticated search and more elaborate linguis-tic information.
Example stories generated by thefour systems are shown in Table 2 for the inputsentences The emperor rules the kingdom and Thechild watches the bird.Possible extensions and improvements to thecurrent work are many and varied.
Firstly, wecould improve the quality of our plot graphs bytaking temporal knowledge into account and mak-ing use of knowledge bases such as WordNetand ConceptNet (Liu and Davenport, 2004), afreely available commonsense knowledge base.Secondly, our fitness function optimizes one ob-1569PlotGAThe emperor rules the kingdom.
The kingdomholds on to the emperor.
The emperor ridesout of the kingdom.
The kingdom speaks outagainst the emperor.
The emperor lies.The child watches the bird.
The bird weepsfor the child.
The child begs the bird to lis-ten.The bird dresses up the child.
The childgrows up.PlotThe emperor rules the kingdom.
The emperortakes over.
The emperor goes on to feel for thekingdom.
Possibly the emperor sleeps.
Theemperor steals.The child watches the bird.
The bird comesto eat away at the child.
The child does thor-oughly.
The bird sees the child.
The child sitsdown.RankThe emperor rules the kingdom.
The kingdomlives from the reign to the emperor.
The em-peror feels that the brothers tempt a beautyinto the game.
The kingdom saves the lifefrom crumbling the earth into the bird.
Thekingdom forces the whip into wiping the tearson the towel.The child watches the bird.
The bird livesfrom the reign to the child.
The child thanksthe victory for blessing the thought.
The childloves to hate the sun with the thought.
Thechild hopes to delay the duty from the happi-ness.RandomExclaimed the emperor when Petru had puthis question.
In the meantime, mind you takegood care of our kingdom.
At first the em-peror felt rather distressed.
The dinner of anemperor!
Thus they arrived at the court of theemperor.They cried, ?what a beautiful child!?
?No,that I cannot do, my child?
he said at last.
?What is the matter, dear child??
?You wickedchild,?
cried the Witch.
Well, I will watch tillthe bird comes.Table 2: Stories generated by a system that uses plots and genetic search (PlotGA), a system that usesonly plots (Plot), McIntyre and Lapata (2009)?s rank-based system (Rank) and a system that randomlypastes together sentences from the training corpus (Random).jective, namely coherence.
In the future we plan toexplore multiple objectives, such as whether thestory is verbose, readable (using existing readabil-ity metrics), has two many or two few protago-nists, and so on.Thirdly, our stories would benefit from some ex-plicit modeling of discourse structure.
Althoughthe plot graph captures the progression of the ac-tions in a story, we would also like to know wherein the story these actions are likely to occur?some tend to appear in the beginning and others inthe end.
Such information would allow us to struc-ture the stories better and render them more natu-ral sounding.
For example, an improvement wouldbe the inclusion of proper endings, as the storiesare currently cut off at an arbitrary point when thedesired maximum length is reached.Finally, the fluency of the stories would bene-fit from generating referring expressions, multipletense forms, indirect speech, aggregation and gen-erally more elaborate syntactic structure.ReferencesAgudo, Bele?n Dia?z, Pablo Gerva?s, and Fred-erico Peinado.
2004.
A case based reason-ing approach to story plot generation.
InProceedings of the 7th European Conferenceon Case-Based Reasoning.
Springer, Madrid,Spain, pages 142?156.Barros, Leandro Motta and Soraia Raupp Musse.2007.
Planning algorithms for interactive story-telling.
In Computers in Entertainment (CIE),Association for Computing Machinery (ACM),volume 5.Barzilay, Regina and Mirella Lapata.
2007.
Mod-eling local coherence: An entity-based ap-proach.
Computational Linguistics 34(1):1?34.Briscoe, E. and J. Carroll.
2002.
Robust accuratestatistical annotation of general text.
In Pro-ceedings of the 3rd International Conference onLanguage Resources and Evaluation.
Las Pal-mas, Gran Canaria, pages 1499?1504.Chambers, Nathanael and Dan Jurafsky.
2008.Unsupervised learning of narrative event chains.In Proceedings of 46th Annual Meeting of theAssociation for Computational Linguistics: Hu-man Language Technologies.
Columbus, Ohio,pages 789?797.Chambers, Nathanael and Dan Jurafsky.
2009.1570Unsupervised learning of narrative schemas andtheir participants.
In Proceedings of the JointConference of the 47th Annual Meeting of theACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP.Singapore, pages 602?610.Cheng, Hua and Chris Mellish.
2000.
Captur-ing the interaction between aggregation and textplanning in two generation systems.
In Pro-ceedings of the 1st International Conference onNatural Language Generation.
Mitzpe Ramon,Israel, pages 186?193.Fellbaum.
1998.
WordNet: An Electronic Lexi-cal Database (Language, Speech, and Commu-nication).
The MIT Press, Cambridge, Mas-sachusetts.Fillmore, Charles J., Christopher R. Johnson, andMiriam R. L. Petruck.
2003.
Background toFrameNet.
International Journal of Lexicogra-phy 16:235?250.Goldberg, David E. 1989.
Genetic Algorithmsin Search, Optimization and Machine Learning.Addison-Wesley Longman Publishing Co., Inc.,Boston, Massachusetts.Grishman, Ralph, Catherine Macleod, and AdamMeyers.
1994.
COMLEX syntax: Building acomputational lexicon.
In Proceedings of the15th COLING.
Kyoto, Japan, pages 268?272.Joachims, Thorsten.
2002.
Optimizing search en-gines using clickthrough data.
In Proceed-ings of the 8th Proceedings of the eighth ACMSIGKDD international conference on Knowl-edge discovery and data mining.
Edmonton, Al-berta, pages 133?142.Karamanis, Nikiforos and Hisar Maruli Manu-rung.
2002.
Stochastic text structuring usingthe principle of continuity.
In Proceedings ofthe 2nd International Natural Language Gener-ation Conference (INLG?02).
pages 81?88.Keller, Frank, Subahshini Gunasekharan, NeilMayo, and Martin Corley.
2009.
Timing accu-racy of web experiments: A case study using theWebExp software package.
Behavior ResearchMethods 41(1):1?12.Knight, Kevin and Vasileios Hatzivassiloglou.1995.
Two-level, many-paths generation.
InProceedings of the 33rd Annual Meeting ofthe Association for Computational Linguistics(ACL?95).
Cambridge, Massachusetts, pages252?260.Korhonen, Y. Krymolowski, A. and E.J.
Briscoe.2006.
A large subcategorization lexicon for nat-ural language processing applications.
In Pro-ceedings of the 5th LREC.
Genova, Italy.Lavoie, Benoit and Owen Rambow.
1997.
A fastand portable realizer for text generation sys-tems.
In Proceedings of the 5th Conference onApplied Natural Language Processing.
Wash-ington, D.C., pages 265?268.Lin, Dekang.
1998.
Automatic retrieval and clus-tering of similar words.
In Proceedings ofthe 17th International Conference on Compu-tational Linguistic.
Montreal, Quebec, pages768?774.Liu, Hugo and Glorianna Davenport.
2004.
Con-ceptNet: a practical commonsense reasoningtoolkit.
BT Technology Journal 22(4):211?226.Liu, Hugo and Push Singh.
2002.
Using com-monsense reasoning to generate stories.
In Pro-ceedings of the 18th National Conference on Ar-tificial Intelligence.
Edmonton, Alberta, pages957?958.McIntyre, Neil and Mirella Lapata.
2009.
Learn-ing to tell tales: A data-driven approach to storygeneration.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natu-ral Language Processing of the AFNLP.
Singa-pore, pages 217?225.Meehan, James.
1977.
An interactive program thatwrites stories.
In Proceedings of the 5th In-ternational Joint Conference on Artificial Intel-ligence.
Cambridge, Massachusetts, pages 91?98.Mellish, Chris, Alisdair Knott, Jon Oberlander,and Mick O?Donnell.
1998.
Experiments usingstochastic search for text planning.
In Proceed-ings of the 9th International Conference on Nat-ural Language Generation.
New Brunswick,New Jersey, pages 98?107.Mitchell, Melanie.
1998.
An Introduction to Ge-netic Algorithms.
MIT Press, Cambridge, Mas-sachusetts.Pizzi, David, Fred Charles, Jean-Luc Lugrin, andMarc Cavazza.
2007.
Interactive storytellingwith literary feelings.
In Proceedings of the 2ndInternational Conference on Affective Comput-ing and Intelligent Interaction.
Lisbon, Portu-gal, pages 630?641.1571Reiter, E and R Dale.
2000.
Building Natural-Language Generation Systems.
CambridgeUniversity Press, Cambridge, UK.Riedl, Mark O. and R. Michael Young.
2004.
Aplanning approach to story generation and his-tory education.
In Proceedings of the 3rd In-ternational Conference on Narrative and Inter-active Learning Environments.
Edinburgh, UK,pages 41?48.Shim, Yunju and Minkoo Kim.
2002.
Automaticshort story generator based on autonomousagents.
In Proceedings of the 5th Pacific Rim In-ternational Workshop on Multi Agents.
Tokyo,pages 151?162.Swartjes, I.M.T.
and M. Theune.
2008.
The vir-tual storyteller: story generation by simulation.In Proceedings of the 20th Belgian-NetherlandsConference on Artificial Intelligence, BNAIC2008.
Enschede, the Netherlands, pages 257?264.Turner, Scott R. 1992.
Ministrel: A ComputerModel of Creativity and Sotrytelling.
Universityof California, Los Angeles, California.Wu, Zhibiao and Martha Palmer.
1994.
Verb se-mantics and lexical selection.
In Proceedingsof the 32nd Annual Meeting of the Associa-tion for Computational Linguistics.
Las Cruces,New Mexico, pages 133?138.1572
