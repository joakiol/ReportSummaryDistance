The Role of Testing in Grammar EngineeringMartin VolkUniversity of Koblenz-LandauInstitute of Computational LinguisticsRheinau 3-45400 Koblenz, Germany(+49)-261-9119-469e-mail volk~brian.uni-koblenz.de1 I n t roduct ionIn the past grammars have been developed either with anart approach (building up a coherent system; prescrip-tive grammars like the Latin grammars of the MiddleAges) or with a science approach (describing the laws ofnature; descriptive and contrastive grammars).
We pro-pose to regard grammar development in ComputationalLinguistics as an engineering task analogous to softwareengineerkig: one that requires analysis, specification, im-plementation, testing, integration and maintenance.The different phases in the software development pro-cess correspond to phases in grammar development inthe following way:* The problem analysis and definition phase corre-sponds to an analysis of the linguistic data (textsof written or spoken language).?
Problem specification means setting up grammarrules that describe the observed data.
The gram-mar formalism thus provides the formal languagefor the specification.?
The implementation phase includes putting the ru-les into the specific format of the computationalgrammar system.
This is a computer program toprocess a grammar in the framework of a grammartheory.
The implementation effort decreases the clo-ser the format of the grammar approaches the for-mat of the computational system.
* The testing phase comprises checking the grammarimplementation against he linguistic data, i.e.
jud-ging grammaticality and the assigned structure.?
Integration, installation and maintenance are no dif-ferent in the context of an NLP system than in othersoftware systems.Our project focusses on the testing aspect of the pro-cess.
Testing can never be exhaustive but must be re-presentative.
We therefore propose an archive of testsentences (hence: ATS) to govern the incremental deve-lopment and the testing of grammar implementations.2 Const ruct ion  o f  an  ATSTowards the goal of a comprehensive collection of testsentences we have restricted ourselves to the construc-tion of an ATS that represents specific syntactic pheno-mena.
The archive aims to be a representative sampleof all syntactic phenomena of a natural language, in ourcase German.The ATS must contain grammatical sentences as wellas ungrammatical strings.
The grammatical sentencesare systematically collected by varying one syntacticphenomenon at a time.
E.g.
we vary first the subca-tegory of the verb and then we vary verb tense, etc.
Forevery phenomenon we have to construct ungrammaticalstrings to check against overgeneration by the grammar.These strings are found by manipulating the ph,'nome-non in question in such ways as to make it ungramma-tical.
A syntactic feature must be varied over all valuesof its domain.
E.g.
the feature case in German has thevalues nominative, genitive, dative, and accusative.
Anoun phrase (NP) that needs to appear in the nomina-tive in a given sentence will then result in three ungram-matical strings when the other cases are assigned.It must be noted that the set of ungrammatical stringsgets very large when it comes to problems such asword order where the permutation of all the words ina sentence is necessary to enumerate all possibilities.
Inthis case we need heuristics to find the most appropriatetest sentences.
E.g.
in German the order of NPs ina sentence is variable with certain restrictions whereasthe word order within the NP is relatively fixed.
The-refore we are much more likely to encounter problemsin NP order when setting up our grammar.
As a resultwe will have to focus on ungrammatical strings with NPorder problems.
In contrast to grammatical sentencesungrammatical strings are only seldom found naturally(e.g.
errors of language learners) and it will be intere-sting to study whether these occurrences (at least themost frequent ones) correspond to our constructed ex-amples.The judgement of grammatical versus ungrammaticalstrings is subjective and has little to say about the ac-ceptability of a sentence in a real-world communication.Thus our ATS will model competence rather than per-formance in the Chomskyan sense.For the practical use the ATS must be organized ina modular fashion, enabling the user to adapt and ex-tend the archive according to his needs and convictions.Furthermore it must be documented why a sentence hasbeen entered into the archive, since every sentence dis-plays a multitude of syntactic information, only some ofwhich is relevant in our domain.2573 Test ing  w i th  an  ATSThe ATS can be useful in many respects.
First, it cangovern the development process of a grammar in that itprovides the linguistic data in a concise fashion.
Gram-mar rules can be incrementally constructed to accountfor the given sentences.
Organizing the ATS around syn-tactic phenomena of increasing complexity supports in-cremental grammar development.
After each phenome-non has been formalized, the grammar can be checkedagainst the test sentences, thus facilitating the retrie-val of problematical sections in the grammar.
The goalis to set up the archive in such a way that incrementalgrammar development does not require total retestingof all the previous material but only of the recent re-levant phenomena.
But foremost he ATS is meant tosupport he testing of the grammar for completeness (allsentences that should be accepted are accepted by thegrammar) and soundness (the grammar does not acceptany sentence that should not be accepted).In testing a grammar we need to distinguish betweenusing the grammar for analysis or synthesis.
In ana-lysis the ATS can be used to provide input sentencesfor the parsing process.
In synthesis the ATS can beused for comparison with the generated sentences andthus minimize the human judgement effort to the lefto-ver sentences.
The grammatical ones of this group canbe used to complete the ATS.We see three major advantages in using an ATS.1.
Organizing the ATS in equivalence classes aroundsyntactic phenomena facilitates incremental gram-mar development and problem driven testing.2.
Compared to working with NL corpora the ATS avo-ids redundant testing of frequently occuring syntac-tic phenomena.
The ATS can thus serve as a testbedbefore the grammar is used on real ("unconstruc-ted" ) texts.3.
The ATS will help to compare the performance ofdifferent implementations within the same forma-lism as well as across linguistic theories.
Runningan LFG implementation against a GPSG implemen-tation will show the respective adequacy of the theo-ries for particular syntactic phenomena.In order to apply an ATS in practice we have built aworkbench for experimentation with grammar develop-ment that contains an archive of this nature (see Volkand Ridder, 1991).
The workbench is designed as a tuto-rial system for students of syntax analysis in Computa-tional Linguistics.
Its ATS contains 350 sentences for 15syntactic phenomena.
The workbench comes with a lexi-con, a morphology component, a special purpose editorand output procedures for linguistic type tree output.The program is written in Prolog and runs on PCs.4 S imi la r  workConcerning the ATS the approach most similar to ourown is by Nerbonne and coworkers (1991).
They assem-ble a database of constructed sentences in an attemptto exhaustively cover syntactic phenomena.
So far theyhave tackled coordination and verb government with se-veral hundred sentences for both.
They have not yet.included their "diagnostic database" in any test system.This work also reports on attempts to build up sentencecollections for English.Other comparable approaches towards grammar engi-neering are by Erbach (1991) and by Erbach and Arens(1991).
The first describes a system that allows for theparametrization of and experimentation with differentparsing strategies.
The user can specify priorities to in-crementally optimize the parsing process.
We believe,however, that lacking a broad collection of test sentencesthis system cannot be sufficiently evaluated and there-fore we see our approach as complementary to theirs.In another attempt Erbach and Arens (1991) try toevaluate grammars by generating a "representative s t ofsentences" in a systematic way.
They limit their lexiconand grammar, and starting with sentences of length 1,they generate sentences with increasing length.
It is notclear how they intend to check the resulting sentencesother than by human judgement.
An ATS that is ad-apted to their lexicon could be compared against thesesentences.5 Future  d i rec t ionsFuture work will focus on two aspects.
First, we willtry to apply testing techniques from software enginee-ring to our domain of grammar development.
In parti-cular we hope to demonstrate that building a grammarimplementation is a special case of declarative program-ming, since most recent grammar formalisms (notablythe unification-based theories) are declarative in nature.This needs to go together with test statistics and pre-cise information on how to incrementally improve thegrammar.Second, in the long run it will be necessary to addsentences that exceed pure syntactic testing and checkfor semantic regularities.
It is by no means clear howthe test sentences for semantics should be collected sincethere is no set of agreed upon semantic features thatcould be varied.Refere  ncesGregor Erbach.
An Environment for Ezperimentatwnwith Parsing Strategies.
(IWBS Report 167) Stuttgart:Wissenschaftliches Zentrum der IBM Deutschland.
April1991.Gregor Erbach and Roman Arens.
Evaluation vonGrammatiken fiir die Analyse natiirlicher Sprache dutchGenerierung einer repr~sentativen Satzmenge.
Procee-dings of GWAI-91, pages 126-129, Bonn, September1991.John Nerbonne t al.
A diagT~ostic ool for German syn-taz.
(Research Report RR-91-t8)Saarbriicken: DFKI.July 1991.Martin Volk and Hanno Ridder.
GTU (Grammalik TestUmgebung) Manual.
(Manuscript) Institute of Com-putational Linguistics.
University of Koblenz-Landau.1991.258
