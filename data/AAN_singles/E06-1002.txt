Using Encyclopedic Knowledge for Named Entity DisambiguationRazvan BunescuDepartment of Computer SciencesUniversity of Texas at AustinAustin, TX 78712-0233razvan@cs.utexas.eduMarius Pas?caGoogle Inc.1600 Amphitheatre ParkwayMountain View, CA 94043mars@google.comAbstractWe present a new method for detecting anddisambiguating named entities in open do-main text.
A disambiguation SVM kernelis trained to exploit the high coverage andrich structure of the knowledge encodedin an online encyclopedia.
The resultingmodel significantly outperforms a less in-formed baseline.1 Introduction1.1 MotivationThe de-facto web search paradigm defines the re-sult to a user?s query as roughly a set of links to thebest-matching documents selected out of billionsof items available.
Whenever the queries searchfor pinpointed, factual information, the burdenof filling the gap between the output granularity(whole documents) and the targeted information (aset of sentences or relevant phrases) stays with theusers, by browsing the returned documents in or-der to find the actually relevant bits of information.A frequent case are queries about named entities,which constitute a significant fraction of popu-lar web queries according to search engine logs.When submitting queries such as John Williamsor Python, search engine users could also be pre-sented with a compilation of facts and specific at-tributes about those named entities, rather than aset of best-matching web pages.
One of the chal-lenges in creating such an alternative search resultpage is the inherent ambiguity of the queries, asseveral instances of the same class (e.g., differentpeople) or different classes (e.g., a type of snake,a programming language, or a movie) may sharethe same name in the query.
As an example, theWork done during a summer internship at Google.contexts below are part of web documents refer-ring to different people who share the same nameJohn Williams:1.
?John Williams and the Boston Pops con-ducted a summer Star Wars concert at Tan-glewood.?2.
?John Williams lost a Taipei death matchagainst his brother, Axl Rotten.?3.
?John Williams won a Victoria Cross for hisactions at the battle of Rorke?s Drift.
?The effectiveness of the search could be greatlyimproved if the search results were groupedtogether according to the corresponding sense,rather than presented as a flat, sense-mixed listof items (whether links to full-length documents,or extracted facts).
As an added benefit, userswould have easier access to a wider variety of re-sults, whenever the top 10 or so results returned bythe largest search engines happen to refer to onlyone particular (arguably the most popular) senseof the query (e.g., the programming language inthe case of Python), thus submerging or ?hiding?documents that refer to other senses of the query.In various natural language applications, signif-icant performance gains are achieved as a func-tion of data size rather than algorithm complex-ity, as illustrated by the increasingly popular useof the web as a (very large) corpus (Dale, 2003).It seems therefore natural to try to exploit the webin order to also improve the performance of re-lation extraction, i.e.
the discovery of useful re-lationships between named entities mentioned intext documents.
However, if one wants to combineevidence from multiple web pages, then one needsagain to solve the name disambiguation problem.9Without solving it, a relation extraction system an-alyzing the sentences in the above example couldmistakenly consider the third as evidence that JohnWilliams the composer fought at Rorke?s Drift.1.2 ApproachThe main goal of the research reported in this pa-per is to develop a named entity disambiguationmethod that is intrinsically linked to a dictionarymapping proper names to their possible named en-titiy denotations.
More exactly, the method:1.
Detects whether a proper name refers to anamed entity included in the dictionary (de-tection).2.
Disambiguates between multiple named enti-ties that can be denoted by the same propername (disambiguation).As a departure from the methodology of previousapproaches, the paper exploits a non-traditionalweb-based resource.
Concretely, it takes advan-tage of some of the human knowledge availablein Wikipedia, a free online encyclopedia createdthrough decentralized, collective efforts of thou-sands of users (Remy, 2002).
We show that thestructure of Wikipedia lends itself to a set ofuseful features for the detection and disambigua-tion of named entities.
The remainder of the pa-per is organized as follows.
Section 2 describesWikipedia, with an emphasis on the features thatare most important to the entity disambiguationtask.
Section 3 describes the extraction of namedentity entries (versus other types of entries) fromWikipedia.
Section 4 introduces two disambigua-tion methods, which are evaluated experimentallyin Section 5.
We conclude with future work andconclusions.2 Wikipedia ?
A Wiki EncyclopediaWikipedia is a free online encyclopedia writtencollaboratively by volunteers, using a wiki soft-ware that allows almost anyone to add and changearticles.
It is a multilingual resource - there areabout 200 language editions with varying levelsof coverage.
Wikipedia is a very dynamic andquickly growing resource ?
articles about news-worthy events are often added within days of theiroccurrence.
As an example, the September 2005version contains 751,666 articles, around 180,000more articles than four months earlier.
The workin this paper is based on the English version fromMay 2005, which contains 577,860 articles.Each article in Wikipedia is uniquely identifiedby its title ?
a sequence of words separated byunderscores, with the first word always capital-ized.
Typically, the title is the most common namefor the entity described in the article.
When thename is ambiguous, it is further qualified with aparenthetical expression.
For instance, the arti-cle on John Williams the composer has the titleJohn Williams (composer).Because each article describes a specific en-tity or concept, the remainder of the paper some-times uses the term ?entity?
interchangeably to re-fer to both the article and the corresponding entity.Also, let E denote the entire set of entities fromWikipedia.
For any entity e2E, e:title is the titlename of the corresponding article, and e:T is thetext of the article.In general, there is a many-to-many correspon-dence between names and entities.
This relationis captured in Wikipedia through redirect and dis-ambiguation pages, as described in the next twosections.2.1 Redirect PagesA redirect page exists for each alternative namethat can be used to refer to an entity in Wikipedia.The name is transformed (using underscores forspaces) into a title whose article contains aredirect link to the actual article for that en-tity.
For example, John Towner Williams is thefull name of the composer John Williams.
Itis therefore an alternative name for the com-poser, and consequently the article with the ti-tle John Towner Williams is just a pointer to thearticle for John Williams (composer).
An exam-ple entry with a considerably higher number ofredirect pages is United States.
Its redirect pagescorrespond to acronyms (U.S.A., U.S., USA, US),Spanish translations (Los Estados Unidos, Esta-dos Unidos), misspellings (Untied States) or syn-onyms (Yankee land).For any given Wikipedia entity e2E, let e:R bethe set of all names that redirect to e.2.2 Disambiguation PagesAnother useful structure is that of disambiguationpages, which are created for ambiguous names,i.e.
names that denote two or more entities inWikipedia.
For example, the disambiguation pagefor the name John Williams lists 22 associated10TITLE REDIRECT DISAMBIG CATEGORIESStar Wars music, ...John Williams (composer) John Towner Williams John Williams Film score composers,20th century classical composersJohn Williams (wrestler) Ian Rotten John Williams Professional wrestlers,People living in BaltimoreJohn Williams (VC) none John Williams British Army soldiers,British Victoria Cross recipientsBoston Pops Orchestra Boston Pops, Pops American orchestras,The Boston Pops Orchestra Massachusetts musiciansUnited States US, USA, ...
US, USA, North American countries,United States of America United States Republics, United StatesVenus, VenusVenus (planet) Planet Venus Morning Star, Planets of the Solar System,Evening Star Planets, Solar System, ...Table 1: Examples of Wikipedia titles, aliases and categoriesentities.
Therefore, besides the non-ambiguousnames that come from redirect pages, additionalaliases can be found by looking for all disam-biguation pages that list a particular Wikipedia en-tity.
In his philosophical article ?On Sense andReference?
(Frege, 1999), Gottlob Frege gave afamous argument to show that sense and referenceare distinct.
In his example, the planet Venus maybe referred to using the phrases ?morning star?
and?evening star?.
This theoretical example is nicelycaptured in practice in Wikipedia by two disam-biguation pages, Morning Star and Evening Star,both listing Venus as a potential referent.For any given Wikipedia entity e 2 E, let e:Dbe the set of names whose disambiguation pagescontain a link to e.2.3 CategoriesEvery article in Wikipedia is required to have atleast one category.
As shown in Table 1, JohnWilliams (composer) is associated with a set ofcategories, among them Star Wars music, Filmscore composers, and 20th century classical com-posers.
Categories allow articles to be placed intoone or more topics.
These topics can be furthercategorized by associating them with one or moreparent categories.
In Table 1 Venus is shown asboth an article title and a category.
As a cate-gory, it has one direct parent Planets of the SolarSystem, which in turn belongs to two more gen-eral categories, Planets and Solar System.
Thus,categories form a directed acyclic graph, allowingmultiple categorization schemes to co-exist simul-taneously.
There are in total 59,759 categories inWikipedia.For a given Wikipedia entity e 2E, let e:C bethe set of categories to which e belongs (i.e.
e?simmediate categories and all their ancestors in theWikipedia taxonomy).2.4 HyperlinksArticles in Wikipedia often contain mentions ofentities that already have a corresponding arti-cle.
When contributing authors mention an ex-isting Wikipedia entity inside an article, they arerequired to link at least its first mention to the cor-responding article, by using links or piped links.Both types of links are exemplified in the follow-ing wiki source code of a sentence from the articleon Italy: ?The [[Vatican City|Vatican]] is now anindependent enclave surrounded by [[Rome]]?.The string from the second link (?Rome?)
denotesthe title of the referenced article.
The same stringis also used in the display version.
If the authorwants another string displayed (e.g., ?Vatican?
in-stead of ?Vatican City?
), then the alternative stringis included in a piped link, after the title string.Consequently, the display string for the aforemen-tioned example is: ?The Vatican is now an inde-pendent enclave surrounded by Rome?.
As de-scribed later in Section 4, the hyperlinks can pro-vide useful training examples for a named entitydisambiguator.3 A Dictionary of Named EntitiesWe organize all named entities from Wikipediainto a dictionary structure D, where each stringentry d 2 D is mapped to the set of entitiesd:E that can be denoted by d in Wikipedia.
Thefirst step is to identify named entities, i.e.
entitieswith a proper name title.
Because every title inWikipedia must begin with a capital letter, the de-cision whether a title is a proper name relies on thefollowing sequence of heuristic steps:111.
If e:title is a multiword title, check the cap-italization of all content words, i.e.
wordsother than prepositions, determiners, con-junctions, relative pronouns or negations.Consider e a named entity if and only if allcontent words are capitalized.2.
If e:title is a one word title that contains atleast two capital letters, then e is a named en-tity.
Otherwise, go to step 3.3.
Count how many times e:title occurs in thetext of the article, in positions other than atthe beginning of sentences.
If at least 75% ofthese occurrences are capitalized, then e is anamed entity.The combined heuristics extract close to half amillion named entities from Wikipedia.
The sec-ond step constructs the actual dictionary D as fol-lows: The set of entries in D consists of all stringsthat may denote a named entity, i.e.
if e2Eis a named entity, then its title name e:title,its redirect names e:R, and its disambigua-tion names e:D are all added as entries in D. Each entry string d2D is mapped to d:E, theset of entities that d may denote in Wikipedia.Consequently, a named entity e is included ind:E if and only if d = e:title, d 2 e:R, ord2e:D.4 Named Entity DisambiguationAs illustrated in Section 1, the same proper namemay refer to more than one named entity.
Thenamed entity dictionary from Section 3 and the hy-perlinks from Wikipedia articles provide a datasetof disambiguated occurrences of proper names,as described in the following.
As shown in Sec-tion 2.4, each link contains the title name of an en-tity, and the proper name (the display string) usedto refer to it.
We use the term query to denote theoccurrence of a proper name inside a Wikipediaarticle.
If there is a dictionary entry matching theproper name in the query q such that the set ofdenoted entities q:E contains at least two entities,one of them the true answer entity q:e, then thequery q is included in the dataset.
More exactly, ifq:E contains n named entities e1, e2, ..., en, thenthe dataset will be augmented with n pairs hq; ekirepresented as follows:hq; eki = [?
(ek; q:e) j q:T j ek:title]The field q:T contains all words occurring in alimit length window centered on the proper name.The window size is set to 55, which is the valuethat was observed to give optimum performancein the related task of cross-document coreference(Gooi and Allan, 2004).
The Kronecker deltafunction ?
(ek; q:e) is 1 when ekis the same asthe entity q:e referred in the link.
Table 2 liststhe query pairs created for the three John Williamsqueries from Section 1.1, assuming only three en-tities in Wikipedia correspond to this name.?
Query Text Entity Title1 Boston Pops conduct ... John Williams (composer)0 Boston Pops conduct ... John Williams (wrestler)0 Boston Pops conduct ... John Williams (VC)1 lost Taipei match ... John Williams (wrestler)0 lost Taipei match ... John Williams (composer)0 lost Taipei match ... John Williams (VC)1 won Victoria Cross ... John Williams (VC)0 won Victoria Cross ... John Williams (composer)0 won Victoria Cross ... John Williams (wrestler)Table 2: Disambiguation dataset.The application of this procedure on Wikipediaresults into a dataset of 1,783,868 disambiguatedqueries.4.1 Context-Article SimilarityUsing the representation from the previous sec-tion, the name entity disambiguation problem canbe cast as a ranking problem.
Assuming that anappropriate scoring function score(q; ek) is avail-able, the named entity corresponding to query q isdefined to be the one with the highest score:e^ = argmaxekscore(q; ek) (1)If e^ = q:e then e^ represents a hit, otherwise e^ isa miss.
Disambiguation methods will then differbased on the way they define the scoring function.One ranking function that is evaluated experimen-tally in this paper is based on the cosine similaritybetween the context of the query and the text ofthe article:score(q; ek) = cos(q:T; ek:T ) =q:Tkq:Tkek:Tkek:TkThe factors q:T and ek:T are represented in thestandard vector space model, where each compo-nent corresponds to a term in the vocabulary, andthe term weight is the standard tf  idf score(Baeza-Yates and Ribeiro-Neto, 1999).
The vo-cabulary V is created by reading all Wikipedia12articles and recording, for each word stem w, itsdocument frequency df(w) in Wikipedia.
Stop-words and words that are too frequent or too rareare discarded.
A generic document d is then repre-sented as a vector of length jV j, with a position foreach vocabulary word.
If f(w) is the frequency ofword w in document d, and N is the total num-ber of Wikipedia articles, then the weight of wordw2V in the tf  idf representation of d is:dw= f(w) lnNdf(w)(2)4.2 Taxonomy KernelAn error analysis of the cosine-based rankingmethod reveals that, in many cases, the pair hq; eifails to rank first, even though words from thequery context unambiguously indicate e as the ac-tual denoted entity.
In these cases, cue words fromthe context do not appear in e?s article due to twomain reasons:1.
The article may be too short or incomplete.2.
Even though the article captures most of therelevant concepts expressed in the query con-text, it does this by employing synonymouswords or phrases.The cosine similarity between q and ekcan be seenas an expression of the total degree of correlationbetween words from the context of query q and agiven named entity ek.
When the correlation is toolow because the Wikipedia article for named entityekdoes not contain all words that are relevant toek, it is worth considering the correlation betweencontext words and the categories to which ekbe-longs.
For illustration, consider the two queriesfor the name John Williams from Figure 1.To avoid clutter, Figure 1 depicts only two enti-ties with the name John Williams in Wikipedia: thecomposer and the wrestler.
On top of each entity,the figure shows one of their Wikipedia categories(Film score composers and Professional wrestlersrespectively), together with some of their ances-tor categories in the Wikipedia taxonomy.
Thetwo query contexts are shown at the bottom ofthe figure.
In the context on the left, words suchas conducted and concert denote concepts that arehighly correlated with the Musicians, Composersand Film score composers categories.
On the otherhand, their correlation with other categories inFigure 1 is considerably lower.
Consequently, aMusiciansComposersFilm score composersPeople by occupationPeoplePeople known in connectionwith sports and hobbiesWrestlersProfessional wrestlershigh correlationshigh correlations?
?conducteda summer Star WarsJohn Williams John Williamsa Taipei deathlostconcert match[...] [...]John Williams (composer) John Williams (wrestler)Figure 1: Word-Category correlations.goal of this paper is to design a disambiguationmethod that 1) learns the magnitude of these cor-relations, and 2) uses these correlations in a scor-ing function, together with the cosine similarity.Our intuition is that, given the query context on theleft, such a ranking function has a better chanceof ranking the ?composer?
entity higher than the?wrestler?
entity, when compared with the simplecosine similarity baseline.We consider using a linear ranking function asfollows:e^ = argmaxekw (q; ek) (3)The feature vector (q; ek) contains a dedicatedfeaturecosfor cosine similarity, and jV j  jCjfeaturesw;ccorresponding to combinations ofwords w from the Wikipedia vocabulary V andcategories c from the Wikipedia taxonomy C:cos(q; ek) = cos(q:T; ek:T ) (4)w;c(q; ek) =1 if w2q:T and c2ek:C;0 otherwise:The weight vector w models the magnitudeof each word-category correlation, and can belearned by training on the query dataset describedat the beginning of Section 4.
We used the kernelversion of the large-margin ranking approach from(Joachims, 2002) which solves the optimization13problem in Figure 2.
The aim of this formulation isto find a weight vector w such that 1) the numberof ranking constraints w (q; q:e)  w (q; ek)from the training data that are violated is mini-mized, and 2) the ranking function w (q; ek)generalizes well beyond the training data.minimize:V (w; ) =12w w+ CPq;ksubject to:w ((q; q:e)   (q; ek))  1  q;kq;k 08q;8ek2 q:E   fq:egFigure 2: Optimization problem.C is a parameter that allows trading-off marginsize against training error.
The number of linearranking constraints isPq(jq:Ej   1).
As an ex-ample, each of the three queries from Table 2 gen-erates two constraints.The learned w is a linear combination of thefeature vectors (q; ek), which makes it possibleto use kernels (Vapnik, 1998).
It is straightforwardto show that the dot product between two featurevectors (q; ek) and (q0; e0k) is equal with theproduct between the number of common words inthe contexts of the two queries and the number ofcategories common to the two named entities, plusthe product of the two cosine similarities.
The cor-responding ranking kernel is:K hq; eki; hq0; e0ki=q:T \ q0:Tek:C \ e0k:C+ cos(q:T; ek:T )  cos(q0:T; e0k:T )To avoid numerical problems, the first term of thekernel is normalized and the second term is multi-plied with a constant  = 108:K hq; eki; hq0; e0ki=jq:T \ q0:T jpjq:T j  jq0:T jjek:C \ e0k:Cjpjek:Cj  je0k:Cj+   cos(q:T; ek:T )  cos(q0:T; e0k:T )In (McCallum et al, 1998), a statistical techniquecalled shrinkage is used in order to improve theaccuracy of a naive Bayes text classifier.
Accord-ingly, one can take advantage of a hierarchy ofclasses by combining parameter estimates of par-ent categories into the parameter estimates of achild category.
The taxonomy kernel is very re-lated to the same technique ?
one can actually re-gard it as a distribution-free analogue of shrinkage.4.3 Detecting Out-of-Wikipedia EntitiesThe two disambiguation methods discussed above(Sections 4.1 and 4.2) implicitly assume thatWikipedia contains all entities that may be de-noted by entries from the named entity dictionary.Taking for example the name John Williams, bothmethods assume that in any context, the referredentity is among the 22 entities listed on the dis-ambiguation page in Wikipedia.
In practice, theremay be contexts where John Williams refers to anentity eoutthat is not covered in Wikipedia, es-pecially when eoutis not a popular entity.
Theseout-of-Wikipedia entities are accommodated in theranking approach to disambiguation as follows.
Aspecial entity eoutis introduced to denote any en-tity not covered by Wikipedia.
Its attributes areset to null values (e.g., the article text eout:T = ;,and the set of categories eout:C = ;).
The rank-ing in Equation 1 is then updated so that it returnsthe Wikipedia entity with the highest score, if thisscore is greater then a fix threshold  , otherwise itreturns eout:emax= argmaxekscore(q; ek)e^ =emaxif score(q; emax) > ;eoutotherwise:If the scoring function is implemented as aweighted combination of feature functions, as inEquation 3, then the modification shown above re-sults into a new featureout:out(q; ek) = ?
(ek; eout) (5)The associated weight  is learned along with theweights for the other features (as defined in Equa-tion 5).5 Experimental EvaluationThe taxonomy kernel was trained using theSVMlight package (Joachims, 1999).
As de-scribed in Section 4, through its hyperlinks,Wikipedia provides a dataset of 1,783,868 am-biguous queries that can be used for traininga named entity disambiguator.
The apparentlyhigh number of queries actually corresponds toa moderate size dataset, given that the spaceof parameters includes one parameter for eachword-category combination.
However, assumingSVMlight does not run out of memory, using theentire dataset for training and testing is extremely14TRAINING DATASET TEST DATASET# CAT.
QUERIES PAIRS hq; eki # CONSTR.
QUERIES PAIRS hq; eki # SV TK(A) Cos(A)S1110 12,288 39,880 27,592 48,661 147,165 19,693 77.2% 61.5%S2540 17,970 55,452 37,482 70,468 235,290 29,148 68.4% 55.8 %S32,847 21,185 64,560 43,375 75,190 261,723 36,383 68.0% 55.4%S4540 38,726 102,553 63,827 80,386 191,227 35,494 84.8% 82.3%Table 3: Scenario statistics and comparative evaluation.time consuming.
Therefore, we decided to evalu-ate the taxonomy kernel under the following sce-narios: [S1] The working set of Wikipedia categories C1is restricted to only the 110 top level categories un-der People by occupation.
The query dataset usedfor training and testing is reduced to contain onlyambiguous queries hq; eki for which any potentialmatching entity ekbelongs to at least one of the110 categories (i.e.
ek:C \ C16= ;).
The set ofnegative matching entities ekis also reduced tothose that differ from the true answer e in termsof their categories from C1(i.e.
ek:C \ C16=e:C \C1).
In other words, this scenario addressesthe task of disambiguating between entities withdifferent top-level categories under People by oc-cupation. [S2] In a slight generalization of [S1], the set ofcategories C2is restricted to all categories underPeople by occupation.
Each category must have atleast 200 articles to be retained,which results in atotal of 540 categories out of the 8202 categoriesunder People by occupation.
The query dataset isgenerated as in the first scenario by replacing C1with C2. [S3] This scenario is similar with [S2], exceptthat each category has to contain at least 20 arti-cles to be retained, leading to 2847 out of 8202categories. [S4] This scenario uses the same categories as[S2] (i.e.
C4=C2).
In order to make the task morerealistic, all queries from the initial Wikipediadataset are considered as follows.
For each queryq, out of all matching entities that do not havea category under People by occupation, one israndomly selected as an out-of-Wikipedia entity.Then, out of all queries for which the true an-swer is an out-of-Wikipedia entity, a subset is ran-domly selected such that, in the end, the number ofqueries with out-of-Wikipedia true answers is 10%of the total number of queries.
In other words, thescenario assumes the task is to detect if a namedenotes an entity belonging to the People by occu-pation taxonomy and, in the positive cases, to dis-ambiguate between multiple entities under Peopleby occupation that have the same name.The dataset for each scenario is split into a train-ing dataset and a testing dataset which are dis-joint in terms of the query names used in theirexamples.
For instance, if a query for the nameJohn Williams is included in the training dataset,then all other queries with this name are allocatedfor learning (and consequently excluded from test-ing).
Using a disjoint split is motivated by the factthat many Wikipedia queries that have the sametrue answer also have similar contexts, containingrare words that are highly correlated, almost exclu-sively, with the answer.
For example, query namesthat refer to singers often contain album or songnames, query names that refer to writers often con-tain book names, etc.
The taxonomy kernel caneasily ?memorize?
these associations, especiallywhen the categories are very fine-grained.
In thecurrent framework, the unsupervised method ofcontext-article similarity does not utilize the cor-relations present in the training data.
Therefore,for the sake of comparison, we decided to prohibitthe taxonomy kernel from using these correlationsby training and testing on a disjoint split.
Section 6describes how the training queries could be used inthe computation of the context-article similarity,which has the potential of boosting the accuracyfor both disambiguation methods.Table 3 shows a number of relevant statisticsfor each scenario: #CAT represents the number ofWikipedia categories, #SV is the number of sup-port vectors, TK(A) and Cos(A) are the accuracyof the Taxonomy Kernel and the Cosine similar-ity respectively.
The training and testing datasetsare characterized in terms of the number of queriesand query-answer pairs.
The number of rankingcontraints (as specified in Figure 2) is also in-cluded for the training data in column #CONSTR.The size of the training data is limited so thatlearning in each scenario takes within three dayson a Pentium 4 CPU at 2.6 GHz.
Furthermore,15in S4, the termination error criterion  is changedfrom its default value of 0:001 to 0:01.
Also, thethreshold  for detecting out-of-Wikipedia entitieswhen ranking with cosine similarity is set to thevalue that gives highest accuracy on training data.As can be seen in the last two columns, the Tax-onomy Kernel significantly outperforms the Co-sine similarity in the first three scenarios, con-firming our intuition that correlations betweenwords from the query context and categories fromWikipedia taxonomy provide useful informationfor disambiguating named entities.
In the last sce-nario, which combines detection and disambigua-tion, the gain is not that substantial.
Most queriesin the corresponding dataset have only two possi-ble answers, one of them an out-of-Wikipedia an-swer, and for these cases the cosine is already do-ing well at disambiguation.
We conjecture that amore significant impact would be observed if thedataset queries were more ambiguous.6 Future WorkThe high number of support vectors ?
half thenumber of query-answer pairs in training data ?suggests that all scenarios can benefit from moretraining data.
One method for making this feasibleis to use the weight vector w explicitely in a lin-ear SVM.
Because much of the computation timeis spent on evaluating the decision function, usingw explicitely may result in a significant speed-up.The dimensionality of w (by default jV j  jCj)can be reduced significantly by considering onlyword-category pairs whose frequency in the train-ing data is above a predefined threshold.A complementary way of using the training datais to augment the article of each named entity withthe contexts from all queries for which this entityis the true answer.
This method has the potentialof improving the accuracy of both methods whenthe training and testing datasets are not disjoint interms of the proper names used in their queries.Word-category correlations have been used in(Ciaramita et al, 2003) to improve word sense dis-ambiguation (WSD), although with less substan-tial gains.
There, a separate model was learned foreach of the 29 ambiguous nouns from the Sense-val 2 lexical sample task.
While creating a sepa-rate model for each named entity is not feasible ?there are 94,875 titles under People by occupation?
named entity disambiguation can neverthelessbenefit from correlations between Wikipedia cate-gories and features traditionally used in WSD suchas bigrams and trigrams centered on the propername occurrence, and syntactic information.7 ConclusionWe have presented a novel approach to named en-tity detection and disambiguation that exploitedthe untapped potential of an online encyclope-dia.
Experimental results show that using theWikipedia taxonomy leads to a substantial im-provement in accuracy.
The application of the newnamed entity disambiguation method holds thepromise of better results to popular web searches.8 AcknowledgmentsWe would like to thank Peter Dienes, ThorstenJoachims, and the anonymous reviewers for theirhelpful comments.ReferencesRicardo Baeza-Yates and Berthier Ribeiro-Neto.
1999.
Mod-ern Information Retrieval.
ACM Press, New York.Massimiliano Ciaramita, Thomas Hofmann, and Mark John-son.
2003.
Hierarchical semantic classification: Wordsense disambiguation with world knowledge.
In The 18thInternational Joint Conference on Artificial Intelligence,Acapulco, Mexico.Robert Dale.
2003.
Computational linguistics.
Special Issueon the Web as a Corpus, 29(3), September.Gottlob Frege.
1999.
On sense and reference.
In MariaBaghramian, editor, Modern Philosophy of Language,pages 3?25.
Counterpoint Press.Chung Heong Gooi and James Allan.
2004.
Cross-documentcoreference on a large scale corpus.
In Proceedings of Hu-man Language Technology Conference / North AmericanAssociation for Computational Linguistics Annual Meet-ing, Boston, MA.Thorsten Joachims.
1999.
Making large-scale SVM learn-ing practical.
In B. Scho?lkopf, C. J. C. Burges, and A. J.Smola, editors, Advances in Kernel Methods - SupportVector Learning, pages 169?184.
MIT Press.Thorsten Joachims.
2002.
Optimizing search engines us-ing clickthrough data.
In Proceedings of the eighth ACMSIGKDD international conference on Knowledge discov-ery and data mining, pages 133?142.Andrew McCallum, R. Rosenfeld, Tom Mitchell, and A. Y.Ng.
1998.
Improving text classification by shrinkage ina hierarchy of classes.
In Proceedings of the Fifteenth In-ternational Conference on Machine Learning (ICML-98),pages 359?367, Madison, WI.M.
Remy.
2002.
Wikipedia: The free encyclopedia.
OnlineInformation Review, 26(6):434. www.wikipedia.org.Vladimir N. Vapnik.
1998.
Statistical Learning Theory.John Wiley & Sons.16
