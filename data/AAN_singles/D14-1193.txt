Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1816?1821,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsMuli-label Text Categorization with Hidden ComponentsLi Li Longkai Zhang Houfeng WangKey Laboratory of Computational Linguistics (Peking University) Ministry of Education, Chinali.l@pku.edu.cn, zhlongk@qq.com, wanghf@pku.edu.cnAbstractMulti-label text categorization (MTC) issupervised learning, where a documen-t may be assigned with multiple categories(labels) simultaneously.
The labels in theMTC are correlated and the correlation re-sults in some hidden components, whichrepresent the ?share?
variance of correlat-ed labels.
In this paper, we propose amethod with hidden components for MTC.The proposed method employs PCA tocapture the hidden components, and incor-porates them into a joint learning frame-work to improve the performance.
Experi-ments with real-world data sets and evalu-ation metrics validate the effectiveness ofthe proposed method.1 IntroductionMany real-world text categorization applicationsare multi-label text categorization (Srivastava andZane-Ulman, 2005; Katakis et al., 2008; Rubinet al., 2012; Nam et al., 2013), where a docu-ments is usually assigned with multiple labels si-multaneously.
For example, as figure 1 shows,a newspaper article concerning global warmingcan be classified into two categories, Environmen-t, and Science simultaneously.
Let X = Rdbe the documents corpus, and Y = {0, 1}mbethe label space with m labels.
We denote by{(x1, y1), (x2, y2), ..., (xn, yn)} the training set ofn documents.
Each document is denoted by a vec-tor xi= [xi,1, xi,2, ..., xi,d] of d dimensions.
Thelabeling of the i-th document is denoted by vectoryi= [yi,1, yi,2, ..., yi,m], where yilis 1 when thei-th document has the l-th label and 0 otherwise.The goal is to learn a function f : X ?
Y .
Gener-ally, we can assume f consists of m functions, onefor a label.f = [f1, f2, ..., fm]Figure 1: A newspaper article concerning globalwarming can be classified into two categories, En-vironment, and Science.The labels in the MLC are correlated.
For ex-ample, a ?politics?
document is likely to be an ?e-conomic?
document simultaneously, but likely notto be a ?literature?
document.
According to thelatent variable model (Tabachnick et al., 2001),the labels with correlation result in some hiddencomponents, which represent the ?share?
varianceof correlated labels.
Intuitively, if we can captureand utilize these hidden components in MTC, theperformance will be improved.
To implement thisidea, we propose a multi- label text categorizationmethod with hidden components, which employPCA to capture the hidden components, and thenincorporates these hidden components into a jointlearning framework.
Experiments with various da-ta sets and evaluation metrics validate the valuesof our method.
The research close to our work isML-LOC (Multi-Label learning using LOcal Cor-relation) in (Huang and Zhou, 2012).
The differ-1816ences between ours and ML-LOC is that ML-LOCemploys the cluster method to gain the local cor-relation, but we employ the PCA to obtain the hid-den code.
Meanwhile, ML-LOC uses the linearprogramming in learning the local code, but weemploy the gradient descent method since we addnon-linear function to the hidden code.The rest of this paper is organized as follows.Section 2 presents the proposed method.
We con-duct experiments to demonstrate the effectivenessof the proposed method in section 3.
Section 4concludes this paper.2 Methodology2.1 Capturing Hidden Component viaPrinciple Component AnalysisThe first step of the proposed method is to capturehidden components of training instances.
Here weemploy Principal component analysis (PCA).
Thisis because PCA is a well-known statistical tool thatconverts a set of observations of possibly correlat-ed variables into a set of values of linearly uncorre-lated variables called principle components.
Theseprinciple components represent the inner structureof the correlated variables.In this paper, we directly employ PCA to con-vert labels of training instances into their principlecomponents, and take these principle componentsas hidden components of training instances.
Wedenote by hithe hidden components of the i-th in-stance captured by PCA.2.2 Joint Learning FrameworkWe expand the original feature representation ofthe instance xiby its hidden component code vec-tor ci.
For simplicity, we use logistic regression asthe motivating example.
Let wldenote weights inthe l-th function fl, consisting of two parts: 1)wxlis the part involving the instance features.
2) wclis the part involving the hidden component codes.Hence flis:fl(x,c) =11 + exp(?xTwxl?
cTwcl)(1)where C is the code vectors set of all training in-stances.The natural choice of the code vector c is h.However, when testing an instance, the labeling isunknown (exactly what we try to predict), conse-quently we can not capture h with PCA to replacethe code vector c in the prediction function Eq.
(1).Therefore, we assume a linear transformation Mfrom the training instances to their independentcomponents, and use Mx as the approximate in-dependent component.
For numerical stability, weadd a non-linear function (e.g., the tanh function)toMx.
This is formulated as follows.c = tanh(Mx) (2)Aiming to the discrimination fitting and the in-dependent components encoding, we optimize thefollowing optimization problem.minW ,Cn?i=1m?l=1`(xi, ci, yil, fl) + ?1?
(f )+?2Z(C) (3)The first term of Eq.
(3) is the loss function.
`is the loss function defined on the training data,and W denotes all weights in the our model, i.e.,w1, ...,wl, ...,wm.
Since we utilize the logistic re-gression in our model, the loss function is definedas follows.`(x,c, y, f)= ?ylnf(x,c)?
(1?
y)ln(1?
f(x,c)) (4)The second term of Eq.
(3) ?
is to punish themodel complexity, which we use the `2regular-ization term.?
(f ) =m?l=1||wl||2.
(5)The third term of Eq.
(3) Z is to enforce the codevector close to the independent component vector.To obtain the goal, we use the least square errorbetween the code vector and the independent com-ponent vector as the third regularized term.Z(C) =n?i=1||ci?
hi||2.
(6)By substituting the Eq.
(5) and Eq.
(6) into Eq.
(3)and changing c to tanh(Mx) (Eq.
(2)), we obtainthe following optimization problem.minW ,Mn?i=1m?l=1`(xi, tanh(Mxi), yil, f )+?1m?l=1||wl||2+ ?2n?i=1||Mxi?
hi||2(7)18172.3 Alternative Optimization methodWe solve the optimization problem in Eq.
(7) bythe alternative optimization method, which opti-mize one group of the two parameters with theother fixed.
When the M fixed, the third term ofEq.
(7) is a constant and thus can be ignored, thenEq.
(7) can be rewritten as follows.minWn?i=1m?l=1`(xi, tanh(Mxi), yil, fl)+?1m?l=1||wl||2(8)By decomposing Eq.
(8) based on the label, the e-quation Eq.
(8) can be simplified to:minwln?i=1`(xi, tanh(Mxi), yil, fl) + ?1||wl||2(9)Eq.
(9) is the standard logistic regression, whichhas many efficient optimization algorithms.When W fixed, the second term is constan-t and can be omitted, then Ep.
(7) can rewrittento Eq.(10).
We can apply the gradient descen-t method to optimize this problem.minMn?i=1m?l=1`(xi, tanh(Mxi), yil, fl)+?2n?i=1||Mxi?
hi||2(10)3 Experiments3.1 Evaluation MetricsCompared with the single-label classification, themulti-label setting introduces the additional de-grees of freedom, so that various multi-label eval-uation metrics are requisite.
We use three differen-t multi-label evaluation metrics, include the ham-ming loss evaluation metric.The hamming loss is defined as the percentageof the wrong labels to the total number of labels.Hammingloss =1m|h(x)?y| (11)where ?
denotes the symmetric difference of twosets, equivalent to XOR operator in Boolean logic.m denotes the label number.The multi-label 0/1 loss, also known as subsetaccuracy, is the exact match measure as it requiresany predicted set of labels h(x) to match the trueset of labels S exactly.
The 0/1 loss is defined asfollows:0/1loss = I(h(x) 6= y) (12)Let ajand rjdenote the precision and recall forthe j-th label.
The macro-averaged F is a harmon-ic mean between precision and recall, defined asfollows:F =1mm?i=j2 ?
aj?
rjaj+ rj(13)3.2 DatasetsWe perform experiments on three MTC data sets:1) the first data set is slashdot (Read et al., 2011).The slashdot data set is concerned about scienceand technology news categorization, which pre-dicts multiply labels given article titles and partialblurbs mined from Slashdot.org.
2) the second da-ta set is medical (Pestian et al., 2007).
This data setinvolves the assignment of ICD-9-CM codes to ra-diology reports.
3) the third data set is tmc2007 (S-rivastava and Zane-Ulman, 2005).
It is concernedabout safety report categorization, which is to la-bel aviation safety reports with respect to whattypes of problems they describe.
The characteris-tics of them are shown in Table 1, where n denotesthe size of the data set, d denotes the dimension ofthe document instance, and m denotes the numberof labels.dataset n d m Lcardslashdot 3782 1079 22 1.18medical 978 1449 45 1.245tmc2007 28596 500 22 2.16Table 1: Multi-label data sets and associated statis-ticsThe measure label cardinality Lcard, whichis one of the standard measures of ?multi-label-ness?, defined as follows, introduced in (T-soumakas and Katakis, 2007).Lcard(D) =?ni=1?mj=1yijnwhere D denotes the data set, lijdenotes the j-thlabel of the i-th instance in the data set.18183.3 Compared to BaselinesTo examine the values of the joint learning frame-work, we compare our method to two baselines.The baseline 1 eliminates the PCA, which justadds an extra set of non-linear features.
To im-plement this baseline, we only need to set ?2= 0.The baseline 2 eliminates the joint learning frame-work.
This baseline captures the hidden compo-nent codes with PCA, trains a linear regressionmodel to fit the hidden component codes, and u-tilizes the outputs of the linear regression modelas features.For the proposed method, we set ?1= 0.001and ?2= 0.1.
For the baseline 2, we employ l-ogistic regression with 0.001 `2 regularization asthe base classifier.
Evaluations are done in ten-fold cross validation.
Note that all of them pro-duce real-valued predictions.
A threshold t needsto be used to determine the final multi-label set ysuch that lj?
y where pj?
t. We select thresholdt, which makes the Lcard measure of predictionsfor the training set is closest to the Lcard mea-sure of the training set (Read et al., 2011).
Thethreshold t is determined as follows, where Dtisthe training set and a multi-label model Htpre-dicts for the training set under threshold t.t = argmint?[0,1]|Lcard(Dt)?
Lcard(Ht(Dt))|(14)Table 2 reports our method wins over the base-lines in terms of different evaluation metrics,which shows the values of PCA and our join-t learning framework.
The hidden component codeonly fits the hidden component in the baselinemethod.
The hidden component code obtains bal-ance of fitting hidden component and fitting thetraining data in the joint learning framework.3.4 Compared to Other MethodsWe compare the proposed method to BR, C-C (Read et al., 2011), RAKEL (Tsoumakas andVlahavas, 2007) and ML-KNN (Zhang and Zhou,2007).
entropy.
ML-kNN is an adaption of kNNalgorithm for multilabel classification.
methods.Binary Revelance (BR) is a simple but effectivemethod that trains binary classifiers for each labelindependently.
BR has a low time complexity butmakes an arbitrary assumption that the labels areindependent from each other.
CC organizes theclassifiers along a chain and take predictions pro-duced by the former classifiers as features of thelatter classifiers.
ML-kNN uses kNN algorithmsindependently for each label with considering pri-or probabilities.
The Label Powerset (LP) methodmodels independencies among labels by treatingeach label combination as a new class.
LP con-sumes too much time, since there are 2mlabelcombinations with m labels.
RAndom K labEL(RAKEL) is an ensemble method of LP.
RAKELlearns several LP models with random subsets ofsize k from all labels, and then uses a vote processto determine the final predictions.For our proposed method, we employ the set-up in subsection 3.3.
We utilize logistic regressionwith 0.001 `2 regularization as the base classifierfor BR, CC and RAKEL.
For RAKEL, the num-ber of ensemble is set to the number of label andthe size of the label subset is set to 3.
For MLKN-N, the number of neighbors used in the k-nearestneighbor algorithm is set to 10 and the smooth pa-rameter is set to 1.
Evaluations are done in ten-fold cross validation.
We employ the threshold-selection strategy introduced in subsection 3.3Table 2 also reports the detailed results in termsof different evaluation metrics.
The mean metricvalue and the standard deviation of each methodare listed for each data set.
We see our proposedmethod shows majorities of wining over the otherstate-of-the-art methods nearly at all data sets un-der hamming loss, 0/1 loss and macro f score.
E-specially, under the macro f score, the advantagesof our proposed method over the other methods arevery clear.4 CONCLUSIONMany real-world text categorization applicationsare multi-label text categorization (MTC), where adocuments is usually assigned with multiple labelssimultaneously.
The key challenge of MTC is thelabel correlations among labels.
In this paper, wepropose a MTC method via hidden componentsto capture the label correlations.
The proposedmethod obtains hidden components via PCA andincorporates them into a joint learning framework.Experiments with various data sets and evaluationmetrics validate the effectiveness of the proposedmethod.AcknowledgeWe thank anonymous reviewers for their help-ful comments and suggestions.
This researchwas partly supported by National High Tech-1819hamming?.
Lower is better.Dataset slashdot medical tmc2007Proposed 0.044?
0.004 0.010?
0.002 0.056?
0.002Baseline1 0.046?
0.003?
0.010?
0.002 0.056?
0.001Baseline2 0.047?
0.003?
0.011?
0.001 0.059?
0.001?BR 0.058?
0.003?
0.010?
0.001 0.060?
0.001?CC 0.049?
0.003?
0.010?
0.001 0.058?
0.001?RAKEL 0.039?
0.002?
0.011?
0.002 0.057?
0.001MLKNN 0.067?
0.003?
0.016?
0.003?
0.070?
0.002?0/1 loss?.
Lower is better.Dataset slashdot medical tmc2007Proposed 0.600?
0.042 0.316?
0.071 0.672?
0.010Baseline1 0.615?
0.034?
0.324?
0.058?
0.672?
0.008Baseline2 0.669?
0.039?
0.354?
0.062?
0.698?
0.007?BR 0.803?
0.018?
0.337?
0.063?
0.701?
0.008?CC 0.657?
0.025?
0.337?
0.064?
0.687?
0.010?RAKEL 0.686?
0.024?
0.363?
0.064?
0.682?
0.009?MLKNN 0.776?
0.020?
0.491?
0.083?
0.746?
0.003?F score?.
Larger is better.Dataset slashdot medical tmc2007Proposed 0.429?
0.026 0.575?
0.067 0.587?
0.010Baseline1 0.413?
0.032?
0.547?
0.056?
0.577?
0.011Baseline2 0.398?
0.032?
0.561?
0.052?
0.506?
0.011?BR 0.204?
0.011?
0.501?
0.058?
0.453?
0.011?CC 0.303?
0.022?
0.510?
0.052?
0.505?
0.011?RAKEL 0.349?
0.023?
0.589?
0.063?
0.555?
0.011?MLKNN 0.297?
0.031?
0.410?
0.064?
0.431?
0.014?Table 2: Performance (mean?std.)
of our method and baseline in terms of different evaluation metrics.?/?
indicates whether the proposed method is statistically superior/inferior to baseline (pairwise t-test at5% significance level).nology Research and Development Program ofChina (863 Program) (No.2012AA011101), Na-tional Natural Science Foundation of China(No.91024009), Major National Social ScienceFund of China (No.
12&ZD227).
The contac-t author of this paper, according to the meaninggiven to this role by Key Laboratory of Computa-tional Linguistics, Ministry of Education, Schoolof Electronics Engineering and Computer Science,Peking University, is Houfeng WangReferencesSheng-Jun Huang and Zhi-Hua Zhou.
2012.
Multi-label learning by exploiting label correlations local-ly.
In AAAI.Ioannis Katakis, Grigorios Tsoumakas, and IoannisVlahavas.
2008.
Multilabel text classification forautomated tag suggestion.
In Proceedings of theECML/PKDD.Jinseok Nam, Jungi Kim, Iryna Gurevych, and Jo-hannes F?urnkranz.
2013.
Large-scale multi-labeltext classification-revisiting neural networks.
arXivpreprint arXiv:1312.5419.John P Pestian, Christopher Brew, Pawe?
Matykiewicz,DJ Hovermale, Neil Johnson, K Bretonnel Cohen,and W?odzis?aw Duch.
2007.
A shared task involv-ing multi-label classification of clinical free text.
InProceedings of the Workshop on BioNLP 2007: Bio-logical, Translational, and Clinical Language Pro-cessing, pages 97?104.
Association for Computa-tional Linguistics.Jesse Read, Bernhard Pfahringer, Geoff Holmes, andEibe Frank.
2011.
Classifier chains for multi-labelclassification.
Machine learning, 85(3):333?359.Timothy N Rubin, America Chambers, Padhraic S-myth, and Mark Steyvers.
2012.
Statistical topicmodels for multi-label document classification.
Ma-chine Learning, 88(1-2):157?208.Ashok N Srivastava and Brett Zane-Ulman.
2005.
Dis-covering recurring anomalies in text reports regard-1820ing complex space systems.
In Aerospace Confer-ence, 2005 IEEE, pages 3853?3862.
IEEE.Barbara G Tabachnick, Linda S Fidell, et al.
2001.
Us-ing multivariate statistics.Grigorios Tsoumakas and Ioannis Katakis.
2007.Multi-label classification: An overview.
Interna-tional Journal of Data Warehousing and Mining (I-JDWM), 3(3):1?13.Grigorios Tsoumakas and Ioannis Vlahavas.
2007.Random k-labelsets: An ensemble method for mul-tilabel classification.
Machine Learning: ECML2007, pages 406?417.Min-Ling Zhang and Zhi-Hua Zhou.
2007.
Ml-knn: Alazy learning approach to multi-label learning.
Pat-tern Recognition, 40(7):2038?2048.1821
