Proceedings of the ACL 2007 Demo and Poster Sessions, pages 29?32,Prague, June 2007. c?2007 Association for Computational LinguisticszipfR: Word Frequency Distributions in RStefan EvertIKW (University of Osnabru?ck)Albrechtstr.
2849069 Osnabru?ck, Germanystefan.evert@uos.deMarco BaroniCIMeC (University of Trento)C.so Bettini 3138068 Rovereto, Italymarco.baroni@unitn.itAbstractWe introduce the zipfR package, a power-ful and user-friendly open-source tool forLNRE modeling of word frequency distribu-tions in the R statistical environment.
Wegive some background on LNRE models,discuss related software and the motivationfor the toolkit, describe the implementation,and conclude with a complete sample ses-sion showing a typical LNRE analysis.1 IntroductionAs has been known at least since the seminal workof Zipf (1949), words and other type-rich linguis-tic populations are characterized by the fact thateven the largest samples (corpora) do not contain in-stances of all types in the population.
Consequently,the number and distribution of types in the avail-able sample are not reliable estimators of the numberand distribution of types in the population.
Large-Number-of-Rare-Events (LNRE) models (Baayen,2001) are a class of specialized statistical modelsthat estimate the distribution of occurrence proba-bilities in such type-rich linguistic populations fromour limited samples.LNRE models have applications in manybranches of linguistics and NLP.
A typical usecase is to predict the number of different types (thevocabulary size) in a larger sample or the wholepopulation, based on the smaller sample available tothe researcher.
For example, one could use LNREmodels to infer how many words a 5-year-old childknows in total, given a sample of her writing.
LNREmodels can also be used to quantify the relativeproductivity of two morphological processes (asillustrated below) or of two rival syntactic construc-tions by looking at their vocabulary growth rate assample size increases.
Practical NLP applicationsinclude making informed guesses about type countsin very large data sets (e.g., How many typos arethere on the Internet?)
and determining the ?lexicalrichness?
of texts belonging to different genres.
Lastbut not least, LNRE models play an important roleas a population model for Bayesian inference andGood-Turing frequency smoothing (Good, 1953).However, with a few notable exceptions (such asthe work by Baayen on morphological productivity),LNRE models are rarely if ever employed in linguis-tic research and NLP applications.
We believe thatthis has to be attributed, at least in part, to the lack ofeasy-to-use but sophisticated LNRE modeling toolsthat are reliable and robust, scale up to large datasets, and can easily be integrated into the workflowof an experiment or application.
We have developedthe zipfR toolkit in order to remedy this situation.2 LNRE modelsIn the field of LNRE modeling, we are not interestedin the frequencies or probabilities of individual wordtypes (or types of other linguistic units), but ratherin the distribution of such frequencies (in a sam-ple) and probabilities (in the population).
Conse-quently, the most important observations (in mathe-matical terminology, the statistics of interest) are thetotal number V (N) of different types in a sample ofN tokens (also called the vocabulary size) and thenumber Vm(N) of types that occur exactly m times29in the sample.
The set of values Vm(N) for all fre-quency ranks m = 1, 2, 3, .
.
.
is called a frequencyspectrum and constitutes a sufficient statistic for thepurpose of LNRE modeling.A LNRE model M is a population model thatspecifies a certain distribution for the type proba-bilities in the population.
This distribution can belinked to the observable values V (N) and Vm(N)by the standard assumption that the observed dataare a random sample of size N from this popula-tion.
It is most convenient mathematically to formu-late a LNRE model in terms of a type density func-tion g(pi), defined over the range of possible typeprobabilities 0 < pi < 1, such that?
ba g(pi) dpi isthe number of types with occurrence probabilitiesin the range a ?
pi ?
b.1 From the type densityfunction, expected values E[V (N)]and E[Vm(N)]can be calculated with relative ease (Baayen, 2001),especially for the most widely-used LNRE models,which are based on Zipf?s law and stipulate a powerlaw function for g(pi).
These models are known asGIGP (Sichel, 1975), ZM and fZM (Evert, 2004).For example, the type density of the ZM and fZMmodels is given byg(pi) :={C ?
pi??
?1 A ?
pi ?
B0 otherwisewith parameters 0 < ?
< 1 and 0 ?
A < B.Baayen (2001) also presents approximate equationsfor the variances Var[V (N)]and Var[Vm(N)].
Inaddition to such predictions for random samples, thetype density g(pi) can also be used as a Bayesianprior, where it is especially useful for probability es-timation from low-frequency data.Baayen (2001) suggests a number of models thatcalculate the expected frequency spectrum directlywithout an underlying population model.
Whilethese models can sometimes be fitted very well toan observed frequency spectrum, they do not inter-pret the corpus data as a random sample from a pop-ulation and hence do not allow for generalizations.They also cannot be used as a prior distribution forBayesian inference.
For these reasons, we do not see1Since type probabilities are necessarily discrete, such atype density function can only give an approximation to the truedistribution.
However, the approximation is usually excellentfor the low-probability types that are the center of interest formost applications of LNRE models.them as proper LNRE models and do not considerthem useful for practical application.3 Requirements and related softwareAs pointed out in the previous section, most appli-cations of LNRE models rely on equations for theexpected values and variances of V (N) and Vm(N)in a sample of arbitrary size N .
The required ba-sic operations are: (i) parameter estimation, wherethe parameters of a LNRE model M are determinedfrom a training sample of size N0 by comparingthe expected frequency spectrum E[Vm(N0)]withthe observed spectrum Vm(N0); (ii) goodness-of-fitevaluation based on the covariance matrix of V andVm; (iii) interpolation and extrapolation of vocabu-lary growth, using the expectations E[V (N)]; and(iv) prediction of the expected frequency spectrumfor arbitrary sample size N .
In addition, Bayesianinference requires access to the type density g(pi)and distribution function G(a) =?
1a g(pi) dpi, whilerandom sampling from the population described bya LNRE model M is a prerequisite for Monte Carlomethods and simulation experiments.Up to now, the only publicly available implemen-tation of LNRE models has been the lexstats toolkitof Baayen (2001), which offers a wide range ofmodels including advanced partition-adjusted ver-sions and mixture models.
While the toolkit sup-ports the basic operations (i)?
(iv) above, it doesnot give access to distribution functions or randomsamples (from the model distribution).
It has notfound widespread use among (computational) lin-guists, which we attribute to a number of limitationsof the software: lexstats is a collection of command-line programs that can only be mastered with expertknowledge; an ad-hoc Tk-based graphical user in-terfaces simplifies basic operations, but is fully sup-ported on the Linux platform only; the GUI also hasonly minimal functionality for visualization and dataanalysis; it has restrictive input options (making itsuse with languages other than English very cumber-some) and works reliably only for rather small datasets, well below the sizes now routinely encounteredin linguistic research (cf.
the problems reported inEvert and Baroni 2006); the standard parameter es-timation methods are not very robust without exten-sive manual intervention, so lexstats cannot be used30as an off-the-shelf solution; and nearly all programsin the suite require interactive input, making it diffi-cult to automate LNRE analyses.4 ImplementationFirst and foremost, zipfR was conceived and de-veloped to overcome the limitations of the lexstatstoolkit.
We implemented zipfR as an add-on libraryfor the popular statistical computing environment R(R Development Core Team, 2003).
It can easilybe installed (from the CRAN archive) and used off-the-shelf for standard LNRE modeling applications.It fully supports the basic operations (i)?
(iv), cal-culation of distribution functions and random sam-pling, as discussed in the previous section.
We havetaken great care to offer robust parameter estimation,while allowing advanced users full control over theestimation procedure by selecting from a wide rangeof optimization techniques and cost functions.
Inaddition, a broad range of data manipulation tech-niques for word frequency data are provided.
Theintegration of zipfR within the R environment makesthe full power of R available for visualization andfurther statistical analyses.For the reasons outlined above, our softwarepackage only implements proper LNRE models.Currently, the GIGP, ZM and fZM models are sup-ported.
We decided not to implement another LNREmodel available in lexstats, the lognormal model, be-cause of its numerical instability and poor perfor-mance in previous evaluation studies (Evert and Ba-roni, 2006).More information about zipfR can be found on itshomepage at http://purl.org/stefan.evert/zipfR/.5 A sample sessionIn this section, we use a typical application exampleto give a brief overview of the basic functionality ofthe zipfR toolkit.
zipfR accepts a variety of input for-mats, the most common ones being type frequencylists (which, in the simplest case, can be newline-delimited lists of frequency values) and tokenized(sub-)corpora (one word per line).
Thus, as long asusers can extract frequency data or at least tokenizethe corpus of interest with other tools, they can per-form all further analysis with zipfR.Suppose that we want to compare the relative pro-ductivity of the Italian prefix ri- with that of therarer prefix ultra- (roughly equivalent to English re-and ultra-, respectively), and that we have frequencylists of the word types containing the two prefixes.2In our R session, we import the data, create fre-quency spectra for the two classes, and we plot thespectra to look at their frequency distribution (theoutput graph is shown in the left panel of Figure 1):ItaRi.tfl <- read.tfl("ri.txt")ItaUltra.tfl <- read.tfl("ultra.txt")ItaRi.spc <- tfl2spc(ItaRi.tfl)ItaUltra.spc <- tfl2spc(ItaUltra.tfl)> plot(ItaRi.spc,ItaUltra.spc,+ legend=c("ri-","ultra-"))We can then look at summary information aboutthe distributions:> summary(ItaRi.spc)zipfR object for frequency spectrumSample size: N = 1399898Vocabulary size: V = 1098Class sizes: Vm = 346 105 74 43 ...> summary(ItaUltra.spc)zipfR object for frequency spectrumSample size: N = 3467Vocabulary size: V = 523Class sizes: Vm = 333 68 37 15 ...We see that the ultra- sample is much smaller thanthe ri- sample, making a direct comparison of theirvocabulary sizes problematic.
Thus, we will use thefZM model (Evert, 2004) to estimate the parametersof the ultra- population (notice that the summary ofan estimated model includes the parameters of therelevant distribution as well as goodness-of-fit infor-mation):> ItaUltra.fzm <- lnre("fzm",ItaUltra.spc)> summary(ItaUltra.fzm)finite Zipf-Mandelbrot LNRE model.Parameters:Shape: alpha = 0.6625218Lower cutoff: A = 1.152626e-06Upper cutoff: B = 0.1368204[ Normalization: C = 0.673407 ]Population size: S = 8732.724...Goodness-of-fit (multivariate chi-squared):X2 df p19.66858 5 0.001441900Now, we can use the model to predict the fre-quency distribution of ultra- types at arbitrary sam-ple sizes, including the size of our ri- sample.
Thisallows us to compare the productivity of the two pre-fixes by using Baayen?sP , obtained by dividing the2The data used for illustration are taken from an Italiannewspaper corpus and are distributed with the toolkit.31ri?ultra?Frequency SpectrummV m0501001502002503003500 200000 600000 100000002000400060008000Vocabulary GrowthNE[[V((N))]]ri?ultra?Figure 1: Left: Comparison of the observed ri- and ultra- frequency spectra.
Right: Interpolated ri- vs. ex-trapolated ultra- vocabulary growth curves.number of hapax legomena by the overall samplesize (Baayen, 1992):> ItaUltra.ext.spc<-lnre.spc(ItaUltra.fzm,+ N(ItaRi.spc))> Vm(ItaUltra.ext.spc,1)/N(ItaRi.spc)[1] 0.0006349639> Vm(ItaRi.spc,1)/N(ItaRi.spc)[1] 0.0002471609The rarer ultra- prefix appears to be more produc-tive than the more frequent ri-.
This is confirmed bya visual comparison of vocabulary growth curves,that report changes in vocabulary size as sample sizeincreases.
For ri-, we generate the growth curveby binomial interpolation from the observed spec-trum, whereas for ultra- we extrapolate using theestimated LNRE model (Baayen 2001 discuss bothtechniques).> sample.sizes <- floor(N(ItaRi.spc)/100)+ *(1:100)> ItaRi.vgc <- vgc.interp(ItaRi.spc,+ sample.sizes)> ItaUltra.vgc <- lnre.vgc(ItaUltra.fzm,+ sample.sizes)> plot(ItaRi.vgc,ItaUltra.vgc,+ legend=c("ri-","ultra-"))The plot (right panel of Figure 1) confirms thehigher (potential) type richness of ultra-, a ?fancier?prefix that is rarely used, but, when it does get used,is employed very productively (see discussion ofsimilar prefixes in Gaeta and Ricca 2003).ReferencesBaayen, Harald.
1992.
Quantitative aspects of morpho-logical productivity.
Yearbook of Morphology 1991,109?150.Baayen, Harald.
2001.
Word frequency distributions.Dordrecht: Kluwer.Evert, Stefan.
2004.
A simple LNRE model for randomcharacter sequences.
Proceedings of JADT 2004, 411?422.Evert, Stefan and Marco Baroni.
2006.
Testing the ex-trapolation quality of word frequency models.
Pro-ceedings of Corpus Linguistics 2005.Gaeta, Livio and Davide Ricca.
2003.
Italian prefixesand productivity: a quantitative approach.
Acta Lin-guistica Hungarica, 50 89?108.Good, I. J.
(1953).
The population frequencies ofspecies and the estimation of population parameters.Biometrika, 40(3/4), 237?264.R Development Core Team (2003).
R: A lan-guage and environment for statistical computing.
RFoundation for Statistical Computing, Vienna, Aus-tria.
ISBN 3-900051-00-3.
See also http://www.r-project.org/.Sichel, H. S. (1975).
On a distribution law for word fre-quencies.
Journal of the American Statistical Associ-ation, 70, 542?547.Zipf, George K. 1949.
Human behavior and the princi-ple of least effort.
Cambridge (MA): Addison-Wesley.32
