2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 677?687,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsGraph-Based Lexicon Expansion with Sparsity-Inducing PenaltiesDipanjan Das and Noah A. SmithLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{dipanjan,nasmith}@cs.cmu.eduAbstractWe present novel methods to construct com-pact natural language lexicons within a graph-based semi-supervised learning framework,an attractive platform suited for propagatingsoft labels onto new natural language typesfrom seed data.
To achieve compactness,we induce sparse measures at graph verticesby incorporating sparsity-inducing penaltiesin Gaussian and entropic pairwise Markovnetworks constructed from labeled and unla-beled data.
Sparse measures are desirable forhigh-dimensional multi-class learning prob-lems such as the induction of labels on natu-ral language types, which typically associatewith only a few labels.
Compared to standardgraph-based learning methods, for two lexiconexpansion problems, our approach producessignificantly smaller lexicons and obtains bet-ter predictive performance.1 IntroductionSemi-supervised learning (SSL) is attractive for thelearning of complex phenomena, for example, lin-guistic structure, where data annotation is expen-sive.
Natural language processing applications havebenefited from various SSL techniques, such as dis-tributional word representations (Huang and Yates,2009; Turian et al, 2010; Dhillon et al, 2011),self-training (McClosky et al, 2006), and entropyregularization (Jiao et al, 2006; Smith and Eisner,2007).
In this paper, we focus on semi-supervisedlearning that uses a graph constructed from labeledand unlabeled data.
This framework, graph-basedSSL?see Bengio et al (2006) and Zhu (2008) forintroductory material on this topic?has been widelyused and has been shown to perform better than sev-eral other semi-supervised algorithms on benchmarkdatasets (Chapelle et al, 2006, ch.
21).
The methodconstructs a graph where a small portion of ver-tices correspond to labeled instances, and the restare unlabeled.
Pairs of vertices are connected byweighted edges denoting the similarity between thepair.
Traditionally, Markov random walks (Szum-mer and Jaakkola, 2001; Baluja et al, 2008) or op-timization of a loss function based on smoothnessproperties of the graph (Corduneanu and Jaakkola,2003; Zhu et al, 2003; Subramanya and Bilmes,2008, inter alia) are performed to propagate labelsfrom the labeled vertices to the unlabeled ones.In this work, we are interested in multi-class gen-eralizations of graph-propagation algorithms suit-able for NLP applications, where each graph ver-tex can assume one or more out of many possiblelabels (Talukdar and Crammer, 2009; Subramanyaand Bilmes, 2008, 2009).
For us, graph vertices cor-respond to natural language types (not tokens) andundirected edges between them are weighted using asimilarity metric.
Recently, this setup has been usedto learn soft labels on natural language types (say,word n-grams or syntactically disambiguated pred-icates) from seed data, resulting in large but noisylexicons, which are used to constrain structured pre-diction models.
Applications have ranged fromdomain adaptation of part-of-speech (POS) taggers(Subramanya et al, 2010), unsupervised learning ofPOS taggers by using bilingual graph-based projec-tions (Das and Petrov, 2011), and shallow seman-tic parsing for unknown predicates (Das and Smith,2011).
However, none of the above captured the em-pirical fact that only a few categories typically asso-ciate with a given type (vertex).
Take the case ofPOS tagging: Subramanya et al (2010) construct agraph over trigram types as vertices, with 45 pos-sible tags for the middle word of a trigram as the677label set for each vertex.
It is empirically observedthat contextualized word types can assume very few(most often, one) POS tags.
However, along withgraph smoothness terms, they apply a penalty thatencourages distributions to be close to uniform, thepremise being that it would maximize the entropyof the distribution for a vertex that is far away ordisconnected from a labeled vertex.
To prefer maxi-mum entropy solutions in low confidence regions ofgraphs, a similar entropic penalty is applied by Sub-ramanya and Bilmes (2008, 2009).In this paper, we make two major algorithmic con-tributions.
First, we relax the assumption made bymost previous work (Zhu and Ghahramani, 2002;Baluja et al, 2008; Subramanya and Bilmes, 2008;Subramanya and Bilmes, 2009; Subramanya et al,2010; Das and Petrov, 2011; Das and Smith, 2011)that the `1 norm of the masses assigned to the la-bels for a given vertex must be 1.
In other words,in our framework, the label distribution at each ver-tex is unnormalized?the only constraint we put onthe vertices?
vectors is that they must be nonnega-tive.1 This relaxation simplifies optimization: sinceonly a nonnegativity constraint for each label?s massat each vertex needs to be imposed, we can apply ageneric quasi-Newton method (Zhu et al, 1997).Second, we replace the penalties that prefer max-imum entropy, used in prior work, with penaltiesthat aim to identify sparse unnormalized measuresat each graph vertex.
We achieve this by penalizingthe graph propagation objective with the `1 norm orthe mixed `1,2 norm (Kowalski and Torre?sani, 2009)of the measures at each vertex, aiming for global andvertex-level sparsity, respectively.
Importantly, theproposed graph objective functions are convex, sowe avoid degenerate solutions and local minima.We present experiments on two natural languagelexicon expansion problems in a semi-supervisedsetting: (i) inducing distributions of POS tags overn-gram types in the Wall Street Journal section ofthe Penn Treebank corpus (Marcus et al, 1993)and (ii) inducing distributions of semantic frames(Fillmore, 1982) over predicates unseen in anno-1Moreover, we also assume the edge weights in a givengraph are unconstrained, consistent with prior work on graph-based SSL (Das and Petrov, 2011; Das and Smith, 2011; Subra-manya and Bilmes, 2008; Subramanya and Bilmes, 2009; Sub-ramanya et al, 2010; Zhu and Ghahramani, 2002).tated data.
Our methods produce sparse measuresat graph vertices resulting in compact lexicons, andalso result in better performance with respect to la-bel propagation using Gaussian penalties (Zhu andGhahramani, 2002) and entropic measure propaga-tion (Subramanya and Bilmes, 2009), two state-of-the-art graph propagation algorithms.2 Model2.1 Graph-Based SSL as MAP InferenceLet Dl = {(xj , rj)}lj=1 denote l annotated datatypes;2 xj?s empirical label distribution is rj .
Letthe unlabeled data types be denoted by Du ={xi}mi=l+1.
Usually, l  m. Thus, the entire datasetcan be called D , Dl ?
Du.
Traditionally, thegraph-based SSL problem has been set up as fol-lows.
Let G = (V,E) correspond to an undirectedgraph with vertices V and edges E. G is constructedby transforming each data type xi ?
D to a ver-tex; thus V = {1, 2, .
.
.
,m}, and E ?
V ?
V .Let Vl (Vu) denote the labeled (unlabeled) vertices.Moreover, we assume a symmetric weight matrixWthat defines the similarity between a pair of verticesi, k ?
V .
We first define a component of this ma-trix as wij , [W]ik = sim(xi,xk).
We also fixwii = 0 and set wik = wki = 0 if k 6?
N (i)and i 6?
N (k), where N (j) denotes the K-nearestneighbors of vertex j, to reduce the density of thegraph.
We next define an unnormalized measure qifor every vertex i ?
V .
As mentioned before, wehave rj , a probability distribution estimated fromannotated data for a labeled vertex j ?
Vl.
qi andrj are |Y |-dimensional measures, where Y is thepossible set of labels; while rj lies within the |Y |-dimensional probability simplex,3 qi are unnormal-ized with each component qi(y) ?
0.
For most NLPproblems, rj are expected to be sparse, with veryfew components active, the rest being zero.Graph-based SSL aims at finding the best q ={qi : 1 ?
i ?
m} given the empirical distribu-tions rj , and the weight matrix W, which provides2As explained in more detail in ?4, these types are entitieslike n-grams or individual predicates, not tokens in running text.3Note that our framework does not necessitate that rj be anormalized probability distribution; we could have unnormal-ized rj to allow strongly evident types appearing in more datato have larger influence than types that appear infrequently.
Weleave this extension to future work.678the geometry of all the vertices.
We visualize thisproblem using a pairwise Markov network (MN).For every vertex (including labeled ones) i ?
V , wecreate a variable Xi.
Additionally, for labeled ver-tices j ?
Vl, we create variables X?j .
All variables inthe MN are defined to be vector-valued; specifically,variables Xi, ?i ?
V , take value qi, and variablesX?j corresponding to the labeled vertices in G are ob-served with values rj .
An example factor graph forthis MN, with only four vertices, is shown in Fig-ure 1.
In the figure, the variables indexed by 1 and 4correspond to labeled vertices.
Factor ?j with scope{Xj , X?j} encourages qj to be close to rj .
For everyedge i ?
k ?
E, factor ?i?k encourages similaritybetween qi and qk, making use of the weight matrixW (i.e., when wik is larger, the two measures aremore strongly encouraged to be close).
These fac-tors are white squares with solid boundaries in thefigure.
Finally, we define unary factors on all vari-ablesXi, i ?
V , named ?i(Xi), that can incorporateprior information.
In Figure 1, these factors are rep-resented by white squares with dashed boundaries.According to the factor graph, the joint probabil-ity for all the measures qi, ?i ?
V that we want toinduce, is defined as: P (X; ?)
=1Zl?j=1?j(Xj , X?j) ?
?i?k?E?i?k(Xi, Xk) ?m?i=1?i(Xi)where ?
is the set of all factors in the factor graph,and Z is a partition function that normalizes the fac-tor products for a given configuration of q.
Since thegraph-based SSL problem aims at finding the best q,we optimize lnP (X; ?
); equivalently,arg maxq s.t.
q?0l?j=1ln?j(Xj , X?j) +?i?k?Eln?i?k(Xi, Xk)+m?i=1ln?i(Xi) (1)The above denotes an optimization problem withonly non-negativity constraints.
It equates to max-imum a posteriori (MAP) inference; hence, the par-tition function Z can be ignored.
We next discussthe nature of the three different factors in Eq.
1.2.2 Log-Factors as PenaltiesThe nature of the three types of factors in Eq.
1governs the behavior of a graph-based SSL algo-rithm.
Hence, the equation specifies a family ofX1X4 X3X2Figure 1: An example factor graph for the graph-basedSSL problem.
See text for the significance of the shadedand dotted factors, and the shaded variables.graph-based methods that generalize prior research.We desire the following properties to be satisfied inthe factors: (i) convexity of Eq.
1, (ii) amenabilityto scalable optimization algorithms, and (iii) sparsesolutions as expected in natural language lexicons.Pairwise factors: In our work, for the pairwisefactors ?j(Xj , X?j) and ?i?k(Xi, Xk), we examinetwo functions that penalize inconsistencies betweenneighboring vertices: the squared `2 norm and theJensen-Shannon (JS) divergence (Burbea and Rao,1982; Lin, 1991), which is a symmetrized gener-alization of the Kullback-Leibler (KL) divergence(Kullback and Leibler, 1951; Cover and Thomas,1991).
These two divergences are symmetric.
Bothare inspired by previous work; however, the use ofthe JS divergence is a novel extension to Subra-manya and Bilmes (2008).
Specifically, the factorsare:ln?j(Xj , X?j) = ??
(qj , rj) (2)ln?i?k(Xi, Xk) = ?2 ?
?
?
wik ?
?
(qi, qk) (3)where ?
is a hyperparameter whose choice we dis-cuss in ?4.
The function ?
(u, v) for two vectors uand v is defined in two ways:?
(u, v)Gaussian= ?u?
v?22 (4)?
(u, v)Entropic= 12?y?Y(u(y) ?
ln 2 ?
u(y)u(y) + v(y)+ v(y) ?
ln 2 ?
v(y)u(y) + v(y))(5)We call the version of ?
(u, v) that uses the squared`2 distance (Eq.
4) Gaussian, as it represents the ideaof label propagation via Gaussian fields proposed byZhu et al (2003).
A minor difference lies in thefact that we include variables Xj , j ?
Vl for labeled679vertices too, and allow them to change, but penal-ize them if they go too far away from the observedlabeled distributions rj .
The other ?
(u, v) shown inEq.
5 uses the generalized JS-divergence defined interms of the generalized KL-divergence for unnor-malized measures (O?Sullivan, 1998).4Eq.
5 improves prior work by replacing the asym-metric KL-divergence used to bring the distributionsat labeled vertices close to the corresponding ob-served distributions, as well as replacing the KL-based graph smoothness term with the symmetricJS-divergence (Subramanya and Bilmes, 2008, seefirst two terms in Eq.
1).
Empirical evidence showsthat entropic divergences help in multiclass prob-lems where a vertex can assume multiple labels, andmay perform better than objectives with quadraticpenalties (Subramanya and Bilmes, 2008, 2009).A major departure from prior work is the use ofunnormalized measures in Eq.
4-5, which simplifiesoptimization even with the complex JS-divergencein the objective function (see ?3), and, we will see,produces comparable and often better results thanbaselines using normalized distributions (see ?4).Unary factors: The unary factors in our factorgraph ?i(Xi) can incorporate prior information spe-cific to a particular vertex xi embodied by the vari-able Xi.
Herein, we examine three straightforwardpenalties, which can be thought of as penalties thatencourage either uniformity or sparsity:Uniform squared `2: ln?i(Xi) = ??
???
?qi ?
1|Y |??
?22(6)Sparse `1: ln?i(Xi) = ??
?
?qi?1 (7)Sparse `1,2: ln?i(Xi) = ??
?
?qi?21 (8)where ?
is a hyperparameter whose choice we dis-cuss in ?4.
The penalty expressed in Eq.
6 penal-izes qi if it is far away from the uniform distribu-tion.
This penalty has been used previously (Das andPetrov, 2011; Das and Smith, 2011; Subramanya etal., 2010), and is similar to the maximum entropypenalty of Subramanya and Bilmes (2008, 2009).The intuition behind its use is that for low confi-dence or disconnected regions, one would prefer tohave a uniform measure on a graph vertex.
Thepenalties in equations 7?8, on the other hand, en-courage sparsity in the measure qi; these are related4The generalized KL divergence is defined asDKL(u?v) =?y(u(y) ln u(y)v(y) ?
u(y) + v(y)).to regularizers for generalized linear models: thelasso (Tibshirani, 1996) and the elitist lasso (Kowal-ski and Torre?sani, 2009).
The former encouragesglobal sparsity, the latter sparsity per vertex.5 Foreach vertex, the `1,2 penalty takes the form:?qi?21 =???y?Y|qi(y)|?
?2(9)The `1 norm encourages its argument to be sparse,while the usual observed effect of an `2 norm is adense vector without many extreme values.
The `1,2penalty is the squared `2 norm of the `1 norms ofevery qi, hence it promotes sparsity within each ver-tex, but we observe density over the vertices that areselected.Talukdar (2010) enforced label sparsity for infor-mation extraction by discarding poorly scored la-bels during graph propagation updates, but did notuse a principled mechanism to arrive at sparse mea-sures at graph vertices.
Unlike the uniform penalty(Eq.
6), sparsity corresponds to the idea of entropyminimization (Grandvalet and Bengio, 2004).
Sincewe use unnormalized measures at each variable Xi,for low confidence graph regions or disconnectedvertices, sparse penalties will result in all zero com-ponents in qi, which conveys that the graph prop-agation algorithm is not confident on any potentiallabel, a condition that is perfectly acceptable.Model variants: We compare six objective func-tions: we combine factor representations from eachof Eqs.
4?5 with those from each of Eqs.
6?8, replac-ing them in the generic graph objective function ofEq.
1.
The nature of these six models is succinctlysummarized in Table 1.
For each model, we findthe best set of measures q that maximize the corre-sponding graph objective functions, such that q ?
0.Note that in each of the graph objectives, we havetwo hyperparameters ?
and ?
that control the influ-ence of the second and the third terms of Eq.
1 re-5One could additionally consider a non-sparse penalty basedon the squared `2 norm with zero mean: ln?i(Xi) = ??
??qi?22.
We experimented with this unary penalty (along with thepairwise Gaussian penalty for binary factors) for the semanticframe lexicon expansion problem, and found that it performsexactly on par with the squared `2 penalty with uniform mean.To limit the number of non-sparse graph objectives, we omitdetailed discussion of experiments with this unary penalty.680abbrev.factorspairwise unaryUGF-`2 Gaussian Uniform squared `2UGF-`1 Gaussian Sparse `1UGF-`1,2 Gaussian Sparse `1,2UJSF-`2 Entropic Uniform squared `2UJSF-`1 Entropic Sparse `1UJSF-`1,2 Entropic Sparse `1,2Table 1: Six variants of graph objective functions novelto this work.
These variants combine the pairwise factorrepresentations from Eqs.
4?5 with unary factor repre-sentations from each of Eqs.
6?8 (which either encour-age uniform or sparse measures), to be used in the graphobjective function expressed in Eq.
1.spectively.
We discuss how these hyperparametersare chosen in ?4.Baseline Models: We compare the performanceof the six graph objectives of Table 1 with twostrong baselines that have been used in previouswork.
These two models use the following two ob-jective functions, and find q s.t.
q ?
0 and ?i ?V,?y?Y qi(y) = 1.
The first is a normalized Gaus-sian field with a squared uniform `2 penalty as theunary factor (NGF-`2):arg minq, s.t.
q?0,?i?V,?qi?1=1l?j=1?qj ?
rj?22 +m?i=1???
?k?N (i)wik ?qi ?
qk?22 + ???
?qi ?
1|Y |???22??
(10)The second is a normalized KL field with an entropypenalty as the unary factor (NKLF-ME):arg minq, s.t.
q?0,?i?V,?qi?1=1l?j=1DKL(rj ?
qj)+m?i=1???
?k?N (i)wikDKL(qi ?
qk)?
?
?H(qi)??
(11)whereH(qi) denotes the Shannon entropy of the dis-tribution qi.
Both these objectives are constrainedby the fact that every qi must be within the |Y |-dimensional probability simplex.
The objectivefunction in 10 has been used previously (Das andSmith, 2011; Subramanya et al, 2010) and serves asa generalization of Zhu et al (2003).
The entropicobjective function in 11, originally called measurepropagation, performed better at multiclass prob-lems when compared to graph objectives using thequadratic criterion (Subramanya and Bilmes, 2008).3 OptimizationThe six variants of Eq.
1 in Table 1 are convexin q.
This is because the `1, squared `2 and the`1,2 penalties are convex.
Moreover, the general-ized JS-divergence term, which is a sum of two KL-divergence terms, is convex (Cover and Thomas,1991).
Since we choose ?, ?
and wik to be non-negative, these terms?
sums are also convex.
Thegraph objectives of the two baselines noted in ex-pressions 10?11 are also convex because negativeentropy in expression 11 is convex, and rest of thepenalties are the same as our six objectives.
In ourwork, to optimize the objectives of Table 1, we use ageneric quasi-Newton gradient-based optimizer thatcan handle bound-inequality constraints, called L-BFGS-B (Zhu et al, 1997).
Partial derivatives ofthe graph objectives are computed with respect toeach parameter ?i, y, qi(y) of q and passed on tothe optimizer which updates them such that the ob-jective function of Eq.
1 is maximized.
Note thatsince the `1 and `1,2 penalties are non-differentiableat 0, special techniques are usually used to computeupdates for unconstrained parameters (Andrew andGao, 2007).
However, since q ?
0, their absolutevalue can be assumed to be right-continuous, mak-ing the function differentiable.
Thus,?
?qi(y)?qi?1 = 1?
?qi(y)?qi?21 = 2 ?
?qi?1(We omit the form of the derivatives of the otherpenalties for space.)
There are several advantages totaking this route towards optimization.
The `2 andthe JS-divergence penalties for the pairwise termscan be replaced with more interesting convex di-vergences if required, and still optimization will bestraightforward.
Moreover, the nonnegative con-straints make optimization with sparsity inducingpenalties easy.
Finally, computing the objectivefunction and the partial derivatives is easily paral-lelizable on MPI (Gropp et al, 1994) or MapReduce(Dean and Ghemawat, 2008) architectures, by divid-ing up the computation across graph vertices.In comparison, constrained problems such as theone in Eq.
11 require a specialized alternating mini-681mization technique (Subramanya and Bilmes, 2008,2009), that performs two passes through the graphvertices during one iteration of updates, introducesan auxiliary set of probability distributions (thus, in-creasing memory requirements) and another hyper-parameter ?
that is used to transform the weightmatrix W to be suitable for the alternating mini-mization procedure.
To optimize the baseline ob-jectives, we borrow the gradient-free iterative up-dates described by Subramanya and Bilmes (2009)and Subramanya et al (2010).4 ExperimentsIn this section, we compare the six graph objectivefunctions in Table 1 with the two baseline objectiveson two lexicon expansion tasks.4.1 POS Lexicon ExpansionWe expand a POS lexicon for word types with a con-text word on each side, using distributional similar-ity in an unlabeled corpus and few labeled trigrams.Data and task: We constructed a graph over wordtrigram types as vertices, using co-occurrence statis-tics.
Following Das and Petrov (2011) and Sub-ramanya et al (2010), a similarity score betweentwo trigram types was computed by measuring thecosine similarity between their empirical senten-tial context statistics.
This similarity score resultedin the symmetric weight matrix W, defining edgeweights between pairs of graph vertices.
Detailsof the similarity computation are given in those pa-pers.
W is thresholded so that only the K near-est neighbors for each vertex have similarity greaterthan zero, giving a sparse graph.
We set K = 8 as itresulted in the sparsest graph which was fully con-nected.6 For this task, Y is the set of 45 POS tagsdefined in the Penn Treebank (Marcus et al, 1993),and the measure qi for vertex i (for trigram type xi)corresponds to the set of tags that can be associatedwith the middle word of xi.
The trigram represen-tation, as in earlier work, helps reduce the ambi-guity of POS tags for the middle word, and helpsin graph construction.
The 690,705-vertex graphwas constructed over all trigram types appearing in6Our proposed methods can deal with graphs containing dis-connected components perfectly well.
Runtime is asymptoti-cally linear in K for all objectives considered here.Sections 00?21 (union of the training and develop-ment sets used for POS tagging experiments in priorwork) of the WSJ section of the Penn Treebank, butco-occurrence statistics for graph construction weregathered from a million sentences drawn from theEnglish Gigaword corpus (Graff, 2003).Given the graph G with m vertices, we assumethat the tag distributions r for l labeled vertices arealso provided.
Our goal is to find the best set ofmeasures q over the 45 tags for all vertices in thegraph.
Prior work used a similar lexicon for POSdomain adaptation and POS induction for resource-poor languages (Das and Petrov, 2011; Subramanyaet al, 2010); such applications of a POS lexicon areout of scope here; we consider only the lexicon ex-pansion problem and do an intrinsic evaluation at atype-level to compare the different graph objectives.Experimental details: To evaluate, we randomlychose 6,000 out of the 690,705 types for devel-opment.
From the remaining types, we randomlychose 588,705 vertices for testing.
This left us with96,000 types from which we created sets of differ-ent sizes containing 3,000, 6,000, 12,000, 24,000,48,000 and 96,000 labeled types, creating 6 increas-ingly easy transduction settings.
The developmentand the test types were kept constant for direct per-formance comparison across the six settings and oureight models.
After running inference, the mea-sure qi at vertex i was normalized to 1.
Next, forall thresholds ranging from 0 to 1, with steps of0.001, we measured the average POS tag precisionand recall on the development data ?
this gave usthe area under the precision-recall curve (prAUC),which is often used to measure performance on re-trieval tasks.
Given a transduction setting and thefinal q for an objective, hyperparameters ?
and ?were tuned on the development set by performing agrid search, targeting prAUC.7 We ran 100 rounds7For the objectives using the uniform `2 and the maxi-mum entropy penalties, namely UGF-`2, UJSF-`2, NGF-`2and NKLF-ME, we chose ?
from {0, 10?6, 10?4, 0.1}.
For therest of the models using sparsity inducing penalties, we chose?
from {10?6, 10?4, 0.1}.
This suggests that for the formertype of objectives, we allowed a zero unary penalty if that set-ting resulted in the best development performance, while for thelatter type of models, we enforced a positive unary penalty.
Infact, ?
= 0 was chosen in several cases for the objectives withuniform penalties indicating that uniformity hurts performance.We chose ?
from {0.1, 0.5, 1.0}.682|Dl|: 3K 6K 12K 24K 48K 96KNGF-`2 0.208 0.219 0.272 0.335 0.430 0.544NKLF-ME 0.223 0.227 0.276 0.338 0.411 0.506UGF-`2 0.223 0.257 0.314 0.406 0.483 0.564UGF-`1 0.223 0.257 0.309 0.406 0.483 0.556UGF-`1,2 0.223 0.256 0.313 0.403 0.478 0.557UJSF-`2 0.271 0.250 0.310 0.364 0.409 0.481UJSF-`1 0.227 0.257 0.317 0.369 0.410 0.481UJSF-`1,2 0.227 0.258 0.309 0.369 0.409 0.479Table 2: Area under the precision recall curve for the twobaseline objectives and our methods for POS tag lexiconinduction.
This is a measure of how well the type lexicon(for some types unlabeled during training) is recoveredby each method.
The test set contains 588,705 types.of iterative updates for all 8 graph objectives.Type-level evaluation: To measure the quality ofthe lexicons, we perform type level evaluation us-ing area under the precision-recall curve (prAUC).The same measure (on development data) was usedto tune the two hyperparameters.
Table 2 shows theresults measured on 588,705 test vertices (the sametest set was used for all the transduction settings).The general pattern we observe is that our unnor-malized approaches almost always perform betterthan the normalized baselines.
(The exception isthe 3,000 labeled example case, where most unnor-malized models are on par with the better baseline.
)In scenarios with fewer labeled types, pairwise en-tropic penalties perform better than Gaussian ones,and the pattern reverses as more labeled types comeavailable.
This trend is the same when we compareonly the two baselines.
In four out of the six trans-duction settings, one of the sparsity-inducing graphobjectives achieves the best performance in terms ofprAUC, which is encouraging given that they gener-ally produce smaller models than the baselines.Overall, though, using sparsity-inducing unaryfactors seems to have a weak negative effect on per-formance.
Their practical advantage, however is ap-parent when we consider the size of the model.
Af-ter the induction of the set of measures q for alltransduction settings and all graph objectives, wenoticed that our numerical optimizer (LBFGS-B) of-ten assigns extremely small positive values ratherthan zero.
This problem can be attributed to sev-eral artifacts, including our limit of 100 iterations ofoptimization.
Hence, we use a global threshold of10?6, and treat any real value below this threshold0M5M11M16M21M27M32M3k 6k 12k 24k 48k 96kUGF-?1 UGF-?1,2 UJSF-?2UJSF-?1 UJSF-?1,2Figure 2: The number of non-zero components in q forfive graph objective functions proposed in this work, plot-ted against various numbers of labeled datapoints.
Notethat NGF-`2, NKLF-ME and UGF-`2 produce non-zerocomponents for virtually all q, and are therefore notshown (the dotted line marks the maximally non-sparsesolution, with 31,081,725 components).
All of these fiveobjectives result in sparsity.
On average, the objectivesemploying entropic pairwise penalties with sparse unarypenalties UJSF-`1 and UJSF-`1,2 produce very sparselexicons.
Although UGF-`2 produces no sparsity at all,its entropic counterpart UJSF-`2 produces considerablesparsity, which we attribute to JS-divergence as a pair-wise penalty.to be zero.
Figure 2 shows the number of non-zerocomponents in q (or, the lexicon size) for the graphobjectives that achieve sparsity (baselines NGF-`2and NKLF-ME, plus our UGF-`2 are not expectedto, and do not, achieve sparsity; surprisingly UJSF-`2 does and is shown).
Even though the hyperpa-rameters ?
and ?
in the graph objective functionswere not tuned towards sparsity, we see that sparsity-inducing factors are able to achieve far more com-pact lexicons.
Sparsity is desirable in settings wherelabeled development data for tuning thresholds thatselect the most probable labels for a given type isunavailable (e.g., Das and Petrov, 2011).4.2 Expansion of a Semantic Frame LexiconIn a second set of experiments, we follow Das andSmith (2011, D&S11 henceforth) in expanding alexicon that associates lexical predicates (targets)with semantic frames (abstract events or scenariosthat a predicate evokes when used in a sententialcontext) as labels.
More concretely, each vertex inthe graph corresponds to a lemmatized word typewith its coarse part of speech, and the labels areframes from the FrameNet lexicon (Fillmore et al,2003).
Graph construction leverages distributional683UNKNOWN ALLPREDICATES PREDICATES lexiconexact partial exact partial sizeSupervised 23.08 46.62 82.97 90.51 -?NGF-`2 39.86 62.35 83.51 91.02 128,960NKLF-ME 36.36 60.07 83.40 90.95 128,960UGF-`2 37.76 60.81 83.44 90.97 128,960UGF-`1 39.86 62.85 83.51 91.04 122,799UGF-`1,2 39.86 62.85 83.51 91.04 128,732UJSF-`2 40.56 62.81 83.53 91.04 128,232UJSF-`1 39.16 62.43 83.49 91.02 128,771UJSF-`1,2 42.67 65.29 83.60 91.12 45,544Table 3: Exact and partial frame identification accuracywith lexicon size (non-zero frame components).
The ?un-known predicates?
section of the test data contains 144targets, while the entire test set contains 4,458 targets.Bold indicates best results.
The UJSF-`1,2 model pro-duces statistically significant results (p < 0.001) for allmetrics with respect to the supervised baseline used inD&S11.
For both the unknown targets as well as thewhole test set.
However, it is weakly significant (p < 0.1)compared to the NGF-`2 model for the unseen portion ofthe test set, when partial frame matching is used.
For restof the settings, the two are statistically indistinguishable.?
indicates the best results in D&S11.similarity as well as linguistic annotations.Data: We borrow the graph-based SSL process ofD&S11 in its entirety.
The constructed graph con-tains 64,480 vertices, each corresponding to a tar-get, out of which 9,263 were drawn from the labeleddata.
The possible set of labels Y is the set of 877frames defined in FrameNet; the measure qi corre-sponds to the set of frames that a target can evoke.The targets drawn from FrameNet annotated data(l = 9,263) have frame distributions ri with whichthe graph objectives are seeded.8Evaluation: The evaluation metric used for thistask is frame disambiguation accuracy on a blind testset containing marked targets in free text.
A sectionof this test set contained 144 targets, previously un-seen in annotated FrameNet data; this section is ofinterest to us and we present separate accuracy re-sults on it.
Given the measure qi over frames in-duced using graph-based SSL for target i, we trun-cate it to keep at most the top M frames that getthe highest mass under qi, only retaining those withnon-zero values.
If all components of qi are zero,we remove target i from the lexicon, which is of-ten the case in the sparsity-inducing graph objec-tives.
If a target is unseen in annotated data, a sep-arate probabilistic model (which serves as a super-vised baseline like in D&S11, row 1 in Table 3) dis-ambiguates among the M filtered frames observingthe sentential context of the target instance.
Thiscan be thought of as combining type- and token-level information for inference.
If the target waspreviously seen, it is disambiguated using the su-8We refer the reader to D&S11 for the details of the graphconstruction method, the FrameNet dataset used, example se-mantic frames, and an excerpt of the graph over targets.pervised baseline.
The test set and the probabilis-tic model are identical to the ones in D&S11.
Wefixed K, the number of nearest neighbors for eachvertex, to be 10.
For each graph objective, ?, ?
andM were chosen by five-fold cross-validation.
Thecross-validation sets were the same as the ones de-scribed in ?6.3 of D&S11.9Results and discussion: Table 3 shows frame iden-tification accuracy, both using exact match as wellas partial match that assigns partial credit when a re-lated frame is predicted (Baker et al, 2007).
Thefinal column presents lexicon size in terms of the setof truncated frame distributions (filtered accordingto the top M frames in qi) for all the targets in agraph.
All the graph-based models are better thanthe supervised baseline; for our objectives usingpairwise Gaussian fields with sparse unary penal-ties, the accuracies are equal or better with respectto NGF-`2; however, the lexicon sizes are reducedby a few hundred to a few thousand entries.
Massivereduction in lexicon sizes (as in the POS problem in?4.1) is not visible for these objectives because wethrow out most of the components of the entire setof distributions q and keep only at most the top M(which is automatically chosen to be 2 for all ob-jectives) frames per target.
Although a significantnumber of components in the whole distribution qin the sparse objectives get zero mass, the M com-ponents for a target tend to be non-zero for a major-ity of the targets.
Better results are observed for theobjectives using entropic pairwise penalties; the ob-9We chose ?
from {0.01, 0.1, 0.3, 0.5, 1.0}; ?
was chosenfrom the same sets as the POS problem.
The graph constructionhyperparameter ?
described by D&S11 was fixed to 0.2.
As inD&S11, M was chosen from {2, 3, 5, 10}.684(a)t = discrepancy.N t = contribution.N t = print.V t = mislead.V?SIMILARITY ?GIVING ?TEXT CREATION EXPERIENCER OBJNATURAL FEATURES MONEY SENDING ?PREVARICATIONPREVARICATION COMMITMENT DISPERSAL MANIPULATE INTO DOINGQUARRELING ASSISTANCE READING COMPLIANCEDUPLICATION EARNINGS AND LOSSES STATEMENT EVIDENCEt = abused.A t = maker.N t = inspire.V t = failed.AOFFENSES COMMERCE SCENARIO CAUSE TO START SUCCESS OR FAILUREKILLING ?MANUFACTURING EXPERIENCER OBJ ?SUCCESSFUL ACTIONCOMPLIANCE BUSINESSES ?SUBJECTIVE INFLUENCE UNATTRIBUTED INFORMATIONDIFFERENTIATION BEHIND THE SCENES EVOKING PIRACYCOMMITTING CRIME SUPPLY ATTEMPT SUASION WANT SUSPECT(b)t = discrepancy.N t = contribution.N t = print.V t = mislead.V?SIMILARITY ?GIVING ?TEXT CREATION ?PREVARICATIONNON-COMMUTATIVE STATEMENT COMMERCE PAY STATE OF ENTITY EXPERIENCER OBJNATURAL FEATURES COMMITMENT DISPERSAL MANIPULATE INTO DOINGASSISTANCE CONTACTING REASSURINGEARNINGS AND LOSSES READING EVIDENCEt = abused.A t = maker.N t = inspire.V t = failed.A?MANUFACTURING CAUSE TO START ?SUCCESSFUL ACTIONBUSINESSES ?SUBJECTIVE INFLUENCE SUCCESSFULLY COMMUNICATE MESSAGECOMMERCE SCENARIO OBJECTIVE INFLUENCESUPPLY EXPERIENCER OBJBEING ACTIVE SETTING FIRETable 4: Top 5 frames (if there are ?
5 frames with mass greater than zero) according to the graph posterior qt(f)for (a) NGF-`2 and (b) UJSF-`1,2, given eight unseen predicates in annotated FrameNet data.
?
marks the correctframe, according to the predicate instances in test data (each of these predicates appear only once in test data).
Notethat UJSF-`1,2 ranks the correct frame higher than NGF-`2 for several predicates, and produces sparsity quite often;for the predicate abused.A, the correct frame is not listed by NGF-`2, while UJSF-`1,2 removes it altogether from theexpanded lexicon, resulting in compactness.jective UJSF-`1,2 gives us the best absolute result byoutperforming the baselines by strong margins, andalso resulting in a tiny lexicon, less than half the sizeof the baseline lexicons.
The size can be attributed tothe removal of predicates for which all frame com-ponents were zero (qi = 0).
Table 4 contrasts theinduced frames for several unseen predicates for theNGF-`2 and the UJSF-`2 objectives; the latter oftenranks the correct frame higher, and produces a smallset of frames per predicate.5 ConclusionWe have presented a family of graph-based SSL ob-jective functions that incorporate penalties encour-aging sparse measures at each graph vertex.
Ourmethods relax the oft-used assumption that the mea-sures at each vertex form a normalized probabil-ity distribution, making optimization and the use ofcomplex penalties easier than prior work.
Optimiza-tion is also easy when there are additional terms ina graph objective suited to a specific problem; ourgeneric optimizer would simply require the compu-tation of new partial derivatives, unlike prior workthat required specialized techniques for a novel ob-jective function.
Finally, experiments on two naturallanguage lexicon learning problems show that ourmethods produce better performance with respect tostate-of-the-art graph-based SSL methods, and alsoresult in much smaller lexicons.AcknowledgmentsWe thank Andre?
Martins, Amar Subramanya, and ParthaTalukdar for helpful discussion during the progress of thiswork and the three anonymous reviewers for their valu-able feedback.
This research was supported by Qatar Na-tional Research Foundation grant NPRP 08-485-1-083,Google?s support of the Worldly Knowledge Project, andTeraGrid resources provided by the Pittsburgh Supercom-puting Center under NSF grant number TG-DBS110003.685ReferencesG.
Andrew and J. Gao.
2007.
Scalable training of L1-regularized log-linear models.
In Proc.
of ICML.C.
Baker, M. Ellsworth, and K. Erk.
2007.
Task 19:frame semantic structure extraction.
In Proc.
of Se-mEval.S.
Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik,S.
Kumar, D. Ravichandran, and M. Aly.
2008.
Videosuggestion and discovery for Youtube: taking randomwalks through the view graph.
In Proc.
of WWW.Y.
Bengio, O. Delalleau, and N. Le Roux.
2006.
La-bel propagation and quadratic criterion.
In OlivierChapelle, Bernhard Scho?lkopf, and Alexander Zien,editors, Semi-Supervised Learning, pages 193?216.MIT Press.J.
Burbea and C. R. Rao.
1982.
On the convexity ofsome divergence measures based on entropy functions.IEEE Transactions on Information Theory, 28:489?495.O.
Chapelle, B. Scho?lkopf, and A. Zien, editors.
2006.Semi-Supervised Learning.
MIT Press.A.
Corduneanu and T. Jaakkola.
2003.
On informationregularization.
In Proc.
of UAI.T.
M. Cover and J.
A. Thomas.
1991.
Elements of infor-mation theory.
Wiley-Interscience.D.
Das and S. Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projections.In Proc.
of ACL.D.
Das and N. A. Smith.
2011.
Semi-supervised frame-semantic parsing for unknown predicates.
In Proc.
ofACL.J.
Dean and S. Ghemawat.
2008.
MapReduce: simplifieddata processing on large clusters.
Communications ofthe ACM, 51:107?113, January.P.
S. Dhillon, D. Foster, and L. Ungar.
2011.
Multi-view learning of word embeddings via cca.
In Proc.
ofNIPS.C.
J. Fillmore, C. R. Johnson, and M. R.L.
Petruck.
2003.Background to FrameNet.
International Journal ofLexicography, 16(3).C.
J. Fillmore.
1982.
Frame semantics.
In Linguistics inthe Morning Calm, pages 111?137.
Hanshin Publish-ing Co., Seoul, South Korea.D.
Graff.
2003.
English Gigaword.
Linguistic Data Con-sortium.Y.
Grandvalet and Y. Bengio.
2004.
Semi-supervisedlearning by entropy minimization.
In Proc.
of NIPS.W.
Gropp, E. Lusk, and A. Skjellum.
1994.
Using MPI:Portable Parallel Programming with the Message-Passing Interface.
MIT Press.F.
Huang and A. Yates.
2009.
Distributional representa-tions for handling sparsity in supervised sequence la-beling.
In Proc.
of ACL.F.
Jiao, S. Wang, C.-H. Lee, R. Greiner, and D. Schu-urmans.
2006.
Semi-supervised conditional randomfields for improved sequence segmentation and label-ing.
In Proc.
of ACL.M.
Kowalski and B. Torre?sani.
2009.
Sparsity and per-sistence: mixed norms provide simple signal modelswith dependent coefficients.
Signal, Image and VideoProcessing, 3:251?264.S.
Kullback and R. A. Leibler.
1951.
On information andsufficiency.
Annals of Mathematical Statistics, 22.J.
Lin.
1991.
Divergence measures based on the shan-non entropy.
IEEE Transactions on Information the-ory, 37:145?151.M.
P. Marcus, M. A. Marcinkiewicz, and B. Santorini.1993.
Building a large annotated corpus of English:the Penn Treebank.
Computational Linguistics, 19(2).D.
McClosky, E. Charniak, and M. Johnson.
2006.
Ef-fective self-training for parsing.
In Proc.
of HLT-NAACL.J.
A. O?Sullivan.
1998.
Alternating minimizationalgorithms: from Blahut-Arimoto to Expectation-Maximization.
In A. Vardy, editor, Codes, Curves,and Signals: Common Threads in Communications,pages 173?192.
Kluwer.D.
A. Smith and J. Eisner.
2007.
Bootstrapping feature-rich dependency parsers with entropic priors.
In Proc.of EMNLP.A.
Subramanya and J. Bilmes.
2008.
Soft-supervisedlearning for text classification.
In Proc.
of EMNLP.A.
Subramanya and J. Bilmes.
2009.
Entropic graph reg-ularization in non-parametric semi-supervised classifi-cation.
In Proc.
of NIPS.A.
Subramanya, S. Petrov, and F. Pereira.
2010.
EfficientGraph-based Semi-Supervised Learning of StructuredTagging Models.
In Proc.
of EMNLP.M.
Szummer and T. Jaakkola.
2001.
Partially labeledclassification with Markov random walks.
In Proc.
ofNIPS.
MIT Press.P.
P. Talukdar and K. Crammer.
2009.
New regularizedalgorithms for transductive learning.
In Proc.
of theECML-PKDD.P.
P. Talukdar.
2010.
Graph-Based Weakly-SupervisedMethods for Information Extraction and Integration.Ph.D.
thesis, University of Pennsylvania.R.
Tibshirani.
1996.
Regression shrinkage and selectionvia the lasso.
Journal of the Royal Statistical Society(Series B), 58:267?288.J.
Turian, L. Ratinov, and Y. Bengio.
2010.
Word rep-resentations: a simple and general method for semi-supervised learning.
In Proc.
of ACL.X.
Zhu and Z. Ghahramani.
2002.
Learning from labeledand unlabeled data with Label Propagation.
Technicalreport, Carnegie Mellon University.686C.
Zhu, R. H. Byrd, P. Lu, and J. Nocedal.
1997.
Algo-rithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization.
ACM Transac-tions on Mathematical Software, 23:550?560.X.
Zhu, Z. Ghahramani, and J. Lafferty.
2003.
Semi-supervised learning using gaussian fields and har-monic functions.
In Proc.
of ICML.X.
Zhu.
2008.
Semi-Supervised Learning Literature Sur-vey.
Online publication., July.687
