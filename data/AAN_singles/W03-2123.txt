DIPPER: Description and Formalisation of anInformation-State Update Dialogue System ArchitectureJohan Bos, Ewan Klein, Oliver Lemon, Tetsushi OkaICCS, School of InformaticsUniversity of Edinburgh2 Buccleuch Place, Edinburgh EH8 9LWScotland, United Kingdom{jbos,ewan,olemon,okat}@inf.ed.ac.ukAbstractThe DIPPER architecture is a collectionof software agents for prototyping spokendialogue systems.
Implemented on topof the Open Agent Architecture (OAA),it comprises agents for speech input andoutput, dialogue management, and fur-ther supporting agents.
We define a for-mal syntax and semantics for the DIP-PER information state update language.The language is independent of particularprogramming languages, and incorporatesprocedural attachments for access to ex-ternal resources using OAA.1 IntroductionSpoken dialogue systems are complex frameworks,involving the integration of speech recognition,speech synthesis, natural language understandingand generation, dialogue management, and interac-tion with domain-specific applications.
These com-ponents might be written in different programminglanguages or running on different platforms.
Fur-thermore, with current developments in speech tech-nology, many components for a dialogue systemcan be obtained ?off-the-shelf?, particularly thoseinvolving speech recognition and speech synthesis,and to a lesser extent those for parsing and genera-tion.
The overall behaviour of a dialogue system iscontrolled by the dialogue management component,where interaction between the different componentsis managed in a flexible way.
Allowing for plug-and-play and easy adaptation to new domains is achallenging task for dialogue system architectures.This paper presents DIPPER, an architecturetailored for prototyping spoken dialogue systems,based on the Open Agent Architecture (OAA).
Al-though DIPPER supports many off-the-shelf com-ponents useful for spoken dialogue systems, itcomes with its own dialogue management compo-nent, based on the information-state approach to di-alogue modelling (Traum et al, 1999; Larsson andTraum, 2000).The TrindiKit (Larsson et al, 1999; Larsson,2002) is regarded as the first implementation of theinformation-state approach.
However impressive itis, on many occasions the TrindiKit tends to givethe impression of a ?Rube Goldberg?
machine forwhat is a relatively straightforward task: updatingthe information state of the dialogue with the help ofdeclaratively stated update rules.
What should be atransparent operation is often obscured by the com-plexity of the TrindiKit framework.
The dialoguemanagement component of DIPPER borrows manyof the core ideas of the TrindiKit, but is strippeddown to the essentials, uses a revised update lan-guage (independent of Prolog), and is more tightlyintegrated with OAA.
We argue that the resultingformalism offers several advantages for developingflexible spoken dialogue systems.We will first introduce OAA and DIPPER agentsfor building spoken dialogue systems, and explainhow dialogue management interfaces with compo-nents in a flexible way (Section 2).
Then we reviewthe information-state approach to dialogue mod-elling, introduce the DIPPER update language (Sec-tion 3), and compare it to the TrindiKit (Section 4).Finally, we list some practical results obtained usingthe DIPPER framework (Section 5).2 The DIPPER EnvironmentThis section gives an overview of DIPPER.
Firstwe introduce the Open Agent Architecture, then wepresent the various agents that play a role in spokendialogue systems.
We focus on the dialogue moveengine in particular.2.1 The Open Agent ArchitectureThe Open Agent Architecture, OAA for short, is aframework for integrating several software agents,possibly coded in different programming languages(C/C++, Java, Prolog) and running on different plat-forms (Unix, Linux, Windows), in a distributed en-vironment (Martin et al, 1999).
Because dialoguesystems are typically built out of a set of indepen-dent components performing particular tasks (wherein many cases some of them are ?out-of-the-box?packages, such as speech recognition or speech syn-thesis), the OAA framework forms an ideal mediumto allow easy integration of software agents for di-alogue systems in a prototyping development envi-ronment.The term ?agent?
within OAA refers to a softwareprocess meeting the conventions of the OAA frame-work.
Basically, this means providing services toother agents in a particular form, using the Inter-agent Communication Language (ICL).
Within thecommunity of agents, service requests can be sub-mitted to the ?facilitator?.
This is a special agentwith knowledge of available agents and their ca-pabilities.
It mediates all interactions between theagents involved in submitting and fulfilling a re-quest.A prototypical spoken dialogue system built ontop of OAA consists of an agent for speech recog-nition, an agent for dialogue management, an agentfor speech synthesis, and several supporting agentsfor specific tasks such as parsing, semantic interpre-tation, and generation.
A distributed agent architec-ture allows the implementation of flexible and adapt-able dialogue systems, where individual agents caneasily be added (or substituted by others) to extendfunctionality of the overall system.
It also allowsthe integration of multi-modal input or output in astraightforward way.The current collection of DIPPER agents consistsof the following: (1) agents for input/output modali-ties, (2) agents for the dialogue move engine, and (3)supporting agents.
We will describe the functional-ity of the DIPPER agents in the remainder of thissection in terms of the services they provide.
We willuse the OAA term ?solvable?
to describe the servicesoffered by agents.
The solvables of an agent are reg-istered with the facilitator, and are implemented byfunction calls (in C++ and Java) or predicate defi-nitions (in Prolog) by the agents that provide them.We will use + and - in front of arguments to indicatepassing or returning values.2.2 Input/Output AgentsDIPPER supports agents for Nuance speech recog-nition software (www.nuance.com) by providingwrappers written in C++ or Java.
The speechrecognition agent can be used in two differentmodes: continuous speech recognition, callingthe solvable apply effects(+Effects) andthereby updating the information state of the dia-logue (see Section 3); and in callback mode, wherethe solvable recognize(+Grammar,+Time,-Input) starts recognition using the speech gram-mar Grammar and returns Input, within a timespecified by Time.
The value of Input is deter-mined by the grammar used as language model forspeech recognition.
Callback mode makes it easy toplug in new grammars during different stages of thedialogue so as to increase speech recognition perfor-mance.On the output side, DIPPER providesagents for the speech synthesisers Fes-tival (Taylor et al, 1998) and rVoice(www.rhetorical.com).
The solvables for theseoutput agents are text2speech(+Text) andsable2speech(+Sable).
The latter can beused to synthesise strings marked up in SABLE,an XML schema for text-to-speech (Sproat et al,1998).
A further agent is available to control Greta,a three-dimensional talking head (Pasquariello andPelachaud, 2001).2.3 Dialogue Management AgentsThe dialogue manager forms the heart of a dialoguesystem, reading the input modalities, updating thecurrent state of the dialogue, deciding what to donext, and generating output.
In terms of interac-tion with other agents, it is the most complex com-ponent.
In fact, the DIPPER dialogue manager isimplemented as two cooperating OAA agents: thedialogue move engine (DME), and a DME server.The DME does the real work by dealingwith input from other agents (normally the in-put modalities, such as speech recognition),updating its internal state, and calling otheragents (normally the output modalities, such asspeech synthesis).
The solvables of the DMEare check conds(+Conditions) and ap-ply effects(+Effects).
The former is usedfor other agents to check the current state of the di-alogue, the latter is used to change the state (for in-stance by integrating results of speech recognition).
(At this point these services might seem fairly ab-stract, but they will be made more concrete in Sec-tion 3.
)The DME server is an agent mediating betweenthe DME and other agents.
It collects requestssubmitted by the DME, waits for the results, andposts these back to the DME.
The DME serverenables the DME to manage information-state up-dates in an asynchronous way.
Because the DMEserver is implemented as a multi-threaded system, itis able to cope with multiple requests at the sametime.
The solvable that the DME server supports isdme(+Call,+Effects).
On receiving this call,the DME server posts the solvable Call to the fa-cilitator, waits for the result, and subsequently re-turns the results to the DME using its solveable ap-ply effects(+Effects).Let?s illustrate this with an example.
Supposethat the dialogue system just asked the user a yes-noquestion, and is ready to accept a yes-no answer.
Itwill need to tell the speech recognition agent to loadthe grammar for yes/no-answers and return a result(say, within 7 seconds) at the is?inputfield of thedialogue state (see Section 3 for more details).
Thisis done by posting the solvable:dme(recognize(?.YesNo?,7,X),[set(is?input,X)])To summarise the functionality of the DME,there are three ways it is able to communi-cate with other agents in a dialogue system:(1) agents can call the DME agent directly, us-ing check conds(+Conditions) and ap-ply effects(+Effects); (2) the DME agentcan call other agents directly, in particular if it isnot interested in the results of those requests; (3) theDME agent can use the DME server as a mediatingagent, normally when the results are needed for up-dating the information state of the DME.The advantage of this architecture is the flexibil-ity imposed by it, while at the same time allow-ing asynchronous interaction of the input/output andsupporting agents with the dialogue move engine.2.4 Supporting AgentsOAA itself comes with agents for parsing and gen-erating based on the Gemini system (Dowding etal., 1993).
DIPPER provides a further set of agentsto deal with natural language understanding, basedon Discourse Representation Theory (Kamp andReyle, 1993).
There is an ambiguity resolutionagent that resolves underspecified DRSs into fullyresolved DRSs, and there is an inference agent thatchecks consistency of DRSs, using standard first-order theorem proving techniques, including the the-orem prover SPASS (Weidenbach et al, 1999) andthe model builder MACE (McCune, 1998).
DIPPERalso includes a high-level dialogue planning compo-nent using O-Plan (Currie and Tate, 1991) which canbe used to build domain-specific content plans.3 The Information-state ApproachIn this section we will briefly review theinformation-state approach and then introducea revised version of the TrindiKit?s dialogue moveengine (Traum et al, 1999), including a new updatelanguage for information states.3.1 Some HistoryTraditional approaches to dialogue modelling canroughly be classified as dialogue state approachesor plan-based approaches.
In the former the dia-logue dynamics are specified by a set of dialoguestates, each state representing the results of perform-ing a dialogue move in some previous state.
The lat-ter are used for more complex tasks requiring flex-ible dialogue behaviour.
The information-state ap-proach (Traum et al, 1999) is intended to combinethe strengths of each paradigm, using aspects of dia-logue state as well as the potential to include detailedsemantic representations and notions of obligation,commitment, beliefs, and plans.The information-state approach allows a declara-tive representation of dialogue modelling.
It is char-acterised by the following components:1. a specification of the contents of the informa-tion state of the dialogue,2.
the datatypes used to structure the informationstate,3.
a set of update rules covering the dynamicchanges of the information state, and4.
a control strategy for information state updates.As mentioned earlier, the first fully fledged imple-mentation of the information-state approach was theTrindiKit (Larsson et al, 1999).
Written in Prolog,the TrindiKit implements dialogue systems by defin-ing information states, update and selection rules,and control algorithms governing the rules to be ap-plied to the information state.
The DIPPER dialoguemove engine builds on the TrindiKit by adopting itsrecord structure and datatypes to define informationstates.
However, there are some fundamental dif-ferences, the most important being that there are noupdate algorithms in the DIPPER DME, there is noseparation between update and selection rules, andthe update rules are abstracted away from Prolog.We will consider these differences in more detail inSection 4.3.2 Specifying Information StatesThe information state of a dialogue ?represents theinformation necessary to distinguish it from other di-alogues, representing the cumulative additions fromprevious actions in the dialogue, and motivating fu-ture action?
(Traum et al, 1999).
The term informa-tion state is very abstract, and concepts such as men-tal model, discourse context, state of affairs, conver-sational score, and other variations on this theme canbe seen as instances of an information state.Like TrindiKit, DIPPER defines informationstates using a rich set of datatypes, includingrecords, stacks, and queues.1 The TrindiKit allowsdevelopers to define specific information states, tai-lored to a particular theory or a special task.
Aninformation state is normally defined as a recursivestructure of the form Name:Type, where Name is anidentifier, and Type a datatype.
Here is a simple ex-ample:Example 1 Information State Definitionis:record([grammar:atomic,input:queue(atomic),sem:stack(record([int:atomic,context:drs]))]).This example defines an information state as arecord named is, consisting of the fields grammar,input, and sem.
The field input is itself definedas a queue of atomic typed structures, and the fieldsem is defined as a stack of records containing thefields int and context.As in the TrindiKit, DIPPER uses a system of ref-erences to anchor conditions and actions in the infor-mation state.
Each record consists of a set of fields.Following the convention of the TrindiKit, we usethe operator ?, where a?b refers to the value of fieldb in record a, and call these paths.
For instance, thepath is?input in the above example refers to aqueue of terms of type atomic.
Note that paths canbe arbitrarily long and may be used in conjunctionwith functions defined in the update language, whichwe will introduce in the next section.3.3 The DIPPER Update LanguageWe will present the DIPPER update language herein a rather informal way, merely by using examples.
(The reader is referred to the appendix for a precisedefinition of the update language.)
The update lan-guage defines the core of the formalism underlyingthe information state approach: the update rules.An update rule is a triple ?name, conditions, ef-fects?, with name a rule identifier, conditions a set oftests on the current information state, and effects anordered set of operations on the information state.Update rules specify the information state changepotential in a declarative way: applying an update1For the purpose of this paper, we restrict ourselves to asmall number of datatypes, although the implementation sup-ports further types including sets, ordered sets, numbers, anddiscourse representation structures.rule to an information state (assuming a shared vo-cabulary of fields) results in a new state.The conditions and effects of update rules are bothrecursively defined over terms.
The terms allow oneto refer to a specific value within the informationstate, either for testing a condition, or for applyingan effect.
There are two kinds of terms: standardterms and anchored terms.
The standard terms de-fine the data structures for the types (atomic types,queue, stack, records, and so on), whereas the an-chored terms allow us to refer to sub-structures ofthe information state (such as first and last torefer to the first respectively last item of a queue).A particularly useful anchored term is of the formT?f, referring to a field f in a record T.As we saw earlier the information state itself is astructure of type record.
We refer to the informationstate object with the unique fixed name is (whichbelongs to the anchored terms).
To illustrate refer-ence of terms with respect to a certain informationstate, consider the following example, using the def-inition as given in Example 1.Example 2 Information Stateis: grammar: ?.YesNo?input: <>sem: < int: model(...)drs: drs([X,Y],[...]) >As defined in the Appendix, we will use theinterpretation function [[.
]]sfor (standard and an-chored) terms with respect to an information states.
Now, with respect to the information state inExample 2, the value of [[is?grammar]]sdenotes?.YesNo?, whereas the value of [[grammar]]sdenotes grammar, because the term is not an-chored.
Similarly, [[top(is?sem)?drs]]syieldsdrs([X,Y],[...]).
However, note that[[top(sem)?drs]]sis undefined.
This term is notwell-formed since sem is of type atomic and not oftype record.This example (and the ones that follow) illustratesthe power and ease with which we can refer to spe-cific attributes of the information state, and therebyspecify the conditions and effects of update rules.The crucial property of conditions is that they mustnot change the content of the information state, andare only used to inspect values denoted by paths inthe record defining the information state (such aschecking identity of terms or whether a queue isempty or not), in order to trigger the effects of an up-date rule.
Effects, on the other hand are responsiblefor changing the information state.
There are twokinds of effects: operations (defined over terms),and solvables.
The former include assignments ofvalues to information state attributes and operationson datatypes such as stacks and queues.
The latterare OAA-solvables that allow us to fulfil requestsby supporting agents or input/output agents of thedialogue system, which is a useful way of incorpo-rating procedural attachment using the functionalityprovided by OAA as described in Section 2.
As a re-sult, external actions are able to update the informa-tion state, giving the properties of an asynchronousarchitecture while maintaining a central unit for dataprocessing.3.4 A simple exampleThe following (extremely simple) example illus-trates the DIPPER architecture and the informationstate update language.
The example implements a?parrot?, where the system simply repeats what theuser says.
Four OAA agents are involved: one agentfor the speech recogniser, one for the synthesiser,and an agent each for the DME and the DME server.We will use the following information structure:is:record([input:queue(basic),listening:basic,output:queue(basic)]).That is, there are three fields: a queue containingthe input of the speech recogniser (we?re assumingthat the objects returned by the speech recogniser arestrings), an auxiliary field keeping track of whetherspeech recognition is active or not, and an outputfield for the text-to-speech synthesiser.There are four update rules.
The first rule,timeout, deals with the situation where thespeech recognition returned ?timeout?
(no speechwas recognised in the given time).
In that case wesimply remove it from the queue.urule(timeout,[first(is?input)=timeout],[dequeue(is?input)]).By virtue of the second rule, process, we sim-ply move the string from the input queue to the out-put queue.
(This is just done for the sake of the ex-ample, we could have directly sent it to the synthe-siser).urule(process,[non-empty(is?input)],[enqueue(is?output,first(is?input)),dequeue(is?input)]).The third rule, synthesise, gives the string tothe synthesiser, by posting an OAA solvable.
We arenot interested in any result that could be yielded bythe solvable, so the set of effects is empty here.urule(synthesise,[non-empty(is?output)],[solve(text2speech(first(is?output)),[]),dequeue(is?output)]).A slightly more complicated rule is recog-nise.
It activates the speech recognition agent(with the grammar ?.Simple?)
when the systemis currently not listening, then sets the listening flagto yes (to prevent application of the update ruleagain).
The results of speech recognition will be in-tegrated by the effects stated as the third argumentof solve: the results will be placed in the inputfield, and the flag listening is set to no again.urule(recognise,[is?listening=no],[solve(X,recognise(?.Simple?,10),[enqueue(is?input,X),assign(is?listening,no)]),assign(is?listening,yes)]).Finally, we would like to make a remarks aboutthe dynamics of effects in update rules.
The effectsare ordered, because the information state is updatedafter each single effect, and hence the order in whichthe effects are applied to the information state mat-ters.
Conditions in update rules, however, are notordered.4 Comparison with TrindiKitNow that we have introduced the DIPPER informa-tion state update language, we are in a good positionto compare DIPPER?s approach to dialogue man-agement that of the TrindiKit.
We will consider theuse of variables, controlling update rules, and dis-tributed processing.4.1 Use of VariablesThe DIPPER update language is essentially avariable-free language (apart from the variables thatare used in solve/3 to return answers which arethen substituted for the variable?s occurrences in theeffects).
In the TrindiKit, Prolog variables are usedfor references to objects in the information state.The scope of such variables includes the conditionsand effects of the update rule.
The system of refer-ence in DIPPER is functional rather than relational,which we will illustrate with two examples.Example 3 In DIPPER, pushing the top el-ement of stack is?a on another stack is?b,and consequently pop the first stack, the effects[push(is?b,top(is?a)), pop(is?a)]will be the way to achieve this.
In the TrindiKit,one would need the effects [is::fst(a,X),is::pop(a), is::push(b,X)] to get thesame result, where X denotes a Prolog variable.Example 4 Given the information state struc-ture presented at the beginning of this section,the term assign(top(is?sem)?int,m)picks the first record out of a stack, and refersto one of its fields (here, the field int).In the TrindiKit, this needs to be coded as[is::fst(sem,X),X::set(int,m)],where again X denotes a Prolog variable.In both examples the TrindiKit relies on Prologunification to obtain the correct results.
As a con-sequence, the order of conditions in the TrindiKitis crucial.
Furthermore, in the TrindiKit it is com-mon practice to use variables in the conditions to re-fer to values in the effects of update rules.
Unifica-tion combined with Prolog?s backtracking can some-times lead to unexpected behaviour, causing errorsthat are difficult to debug (Burke et al, 2002).
TheDIPPER update language does not rely on Prolog,and therefore poses no such problems for dialoguesystem developers unfamiliar with Prolog.4.2 Control in DIPPERIn contrast to the TrindiKit, which comes with a spe-cial language to define the update control algorithm,the control strategy used in DIPPER to select up-date rules is simple and completely determined bythe update rules.
Furthermore, there is no distinc-tion between update and selection rules (used forselecting a new dialogue move to be made by thesystem) which the TrindiKit makes.
The DIPPERupdate algorithm is characterised by the followingpseudo-code:1 WHILE running2 deal with OAA-events;3 IF there is a rule whose condi-tions are satisfied by the informa-tion state4 THEN apply its effects;5 ENDWHILELine 2 deals with external OAA agents requestinga service from the DME, in this case the solvableapply effects(+Effects).
If there are anysuch requests, the information state gets updated,and the algorithm proceeds with line 3.
Here wesimply choose the first rule in the database whoseconditions are satisfied by the information state andapply its effects to the information state (line 4).If there is no such rule, no updates take place andonly an external event can change the informationstate.
Note that the effects of at most one rule willbe applied before proceeding to the end of the while-loop, ensuring that incoming OAA-events are regu-larly checked.4.3 OAA IntegrationAllowing OAA-solvables in the effects of updaterules, a facility that the TrindiKit lacks, is an intu-itive way of interfacing other components of a dia-logue system (see the example update rules in Sec-tion 3.4).
This feature allows components to be eas-ily replaced by others with the same functionality,which is defined purely in terms of the OAA solv-ables.
For instance, changing the synthesiser doesnot affect the dialogue management component.The direct handle on OAA technology further al-lows one to implement advanced functionality fordialogue systems such as dealing with barge-in andmulti-modal input.
Most spoken dialogue systemsexhibit a pipelined architecture with the followingcomponents: automatic speech recognition ?
nat-ural language understanding ?
dialogue manage-ment ?
natural language generation ?
speech syn-thesis.
Because DIPPER builds on the OAA frame-work, it allows developers to design asynchronousdialogue systems in a relatively straightforward way.5 Practical Results5.1 PrototypingAs the example in the previous section demon-strated, relatively little effort is required to build thecore of a new dialogue system.
First of all, the de-veloper needs to select the OAA agents.
A skeletonfor a spoken dialogue system could consists of theNuance speech recognition agent, the DME, and asynthesiser.
Further work involves defining the in-formation state, and the update rules.
Once a coresystem has been built, it is often easy to switch tonew domains, using a similar configuration as in pre-viously implemented systems.5.2 DebuggingA disadvantage of the information-state approach isthat it makes testing and debugging of dialogue sys-tems notoriously difficult.
The more advanced ap-plications require at least a couple of dozen updaterules, and even for a relatively small set of rules de-velopers tend to lose the overview of the intendedbehaviour of their system.Formal testing is one possibility, where intendedeffects of update rules could be verified by future in-formation states, or testing whether the conditionsof an update rule guarantee that its effects can be ap-plied to any information state defined over the samevocabulary.
Given the formal specification of con-ditions and effects, an interesting topic for futureresearch would be to apply model checking tech-niques to dialogue system development.
Most ofthe model checking tools do not work on the morecomplex datatypes required by the information-stateapproach, although these probably can be translatedinto some kind of propositional representation.Practically, the DIPPER environment offers agraphical user interface that assists during develop-ment (Figure 1).
This GUI starts and stops the DMEand keeps a history of updates.
In addition, the de-veloper is able to engage in ?time-travelling?, bybacktracking in the dialogue and restarting the di-alogue from any point in the past.Further functionality of the GUI includes the?Step?
function, which applies just one update rulebefore returning control to the GUI.
This functionis particularly helpful in verifying the intended ef-fect of an update rule.
Finally, the ?Spy?
functiondisplays all rules that are satisfied by the current in-formation state.5.3 DIPPER PrototypesThe number of successful spoken dialogue proto-types implemented using DIPPER is a convincingproof-of-concept.
Applications include conversa-Figure 1: The Graphical User Interface of the DIP-PER DME, showing the current information state,the last applied update rule, and system messages.tion with domestic appliances, as initiated by theEU project D?Homme (Bos and Oka, 2002), ex-plaining route descriptions to a mobile robot in aminiature town, an EPSRC-funded project (Lauriaet al, 2001), and meaningful conversation with amobile robot in the basement of our department(Theobalt et al, 2002).
Currently we are work-ing on a prototype dialogue system including theGreta three-dimensional talking head (Pasquarielloand Pelachaud, 2001) as part of the EU project Mag-iCster.6 ConclusionWe presented the DIPPER framework for build-ing spoken dialogue systems, based on the infor-mation state theory of dialogue management.
Incomparison to TrindiKit, we showed that DIPPERprovides a transparent and elegant way of declar-ing update rules?independent of any particular pro-gramming language, and with the ability to use ar-bitrary procedural attachment via OAA.
The sys-tem incorporates many off-the-shelf OAA agents,which we described, as well as a variety of sup-port agents.
The DIPPER resources are available athttp://www.ltg.ed.ac.uk/dipper.We also presented the formal syntax and seman-tics of our information-state update language.
Al-though it is up to the developer to ensure the va-lidity of update rules, this formalisation could formthe basis of implementing an interpreter that provesvalidity of update rules.
This is an attractive taskfor future work, and similar directions have beensuggested by (Ljunglo?f, 2000; Ferna?ndez, 2003) forproving generic properties of dialogue systems.AcknowledgementsPart of this work was supported by the EU ProjectMagiCster (IST 1999-29078).
We thank Nuance forpermission to use their software and tools.ReferencesJ.
Bos and T. Oka.
2002.
An Inference-based Ap-proach to Dialogue System Design.
In COLING 2002.Proceedings of the 19th International Conference onComputational Linguistics, pages 113?119, Taipei.C.
Burke, L. Harper, and D. Loehr.
2002.
A DialogueArchitecture for Multimodal Control of Robots.
In In-ternational CLASS Workshop on Natural, Intelligentand Effective Interaction in Multimodal Dialogue Sys-tems.K.
Currie and A. Tate.
1991.
O-Plan: the open planningarchitecture.
Artificial Intelligence, 52:49?86.J.
Dowding, M. Gawron, D. Appelt, L. Cherny, R. Moore,and D. Moran.
1993.
Gemini: A natural language sys-tem for spoken language understanding.
In Proceed-ings of the Thirty-First Annual Meeting of the Associ-ation for Computational Linguistics.R.
Ferna?ndez.
2003.
A dynamic logic formalisation ofthe dialogue gameboard.
In Proceedings of the 10thConference of the European Chapter of the ACL.
Stu-dent Research Workshop, pages 17?24, Budapest.H.
Kamp and U. Reyle.
1993.
From Discourse to Logic;An Introduction to Modeltheoretic Semantics of Natu-ral Language, Formal Logic and DRT.
Kluwer, Dor-drecht.S.
Larsson and D. Traum.
2000.
Information state and di-alogue management in the trindi dialogue move enginetoolkit.
Natural Language Engineering, 5(3?4):323?340.S.
Larsson, A. Berman, J. Bos, L. Gro?nqvist, P. Ljunglo?f,and D. Traum.
1999.
A model of dialogue movesand information state revision.
Technical Report D5.1,Trindi (Task Oriented Instructional Dialogue).S.
Larsson.
2002.
Issue-based Dialogue Management.Ph.D.
thesis, Goteborg University.S.
Lauria, G. Bugmann, T. Kyriacou, J.Bos, and E. Klein.2001.
Training Personal Robots Using NaturalLanguage Instruction.
IEEE Intelligent Systems,16(5):38?45, Sept./Oct.P.
Ljunglo?f.
2000.
Formalizing the dialogue move en-gine.
In Go?talog workshop on semantics and prag-matics of dialogue.D.
L. Martin, A. J. Cheyer, and D. B. Moran.
1999.
Theopen agent architecture: A framework for building dis-tributed software systems.
Applied Artificial Intelli-gence, 13.W.
McCune.
1998.
Automatic Proofs and Counterex-amples for Some Ortholattice Identities.
InformationProcessing Letters, 65(6):285?291.S.
Pasquariello and C. Pelachaud.
2001.
Greta: A simplefacial animation engine.
In 6th Online World Confer-ence on Soft Computing in Industrial Appications.R.
Sproat, A.
Hunt, M. Ostendorf, P. Taylor, A. Black,and K. Lenzo.
1998.
Sable: A standard for tts markup.In ICSLP98, pages 1719?1724.P.
A. Taylor, A.
Black, and R. Caley.
1998.
The archi-tecture of the festival speech synthesis system.
In TheThird ESCA Workshop in Speech Synthesis.C.
Theobalt, J. Bos, T. Chapman, A. Espinosa-Romero,M.
Fraser, G. Hayes, E. Klein, T. Oka, and R. Reeve.2002.
Talking to Godot: Dialogue with a MobileRobot.
In Proceedings of IROS 2002.D.
Traum, J. Bos, R. Cooper, S. Larsson, I. Lewin,C.
Matheson, and M. Poesio.
1999.
A model of dia-logue moves and information state revision.
TechnicalReport D2.1, Trindi.C.
Weidenbach, B. Afshordel, U. Brahm, C. Cohrs, T. En-gel, E. Keen, C. Theobalt, and D. Topic.
1999.
Systemdescription: Spass version 1.0.0.
In Harald Ganzinger,editor, 16th International Conference on AutomatedDeduction, CADE-16, volume 1632 of LNAI, pages314?318.
Springer-Verlag, Berlin.Appendix: Syntax and Semantics of theDIPPER Update LanguageThe terms of the update language refer to a specificvalue within the information state, either for testinga condition, or for applying an effect.
There are twokinds of terms: standard terms and anchored terms.Definition: Standard Terms.1.
All constants are standard terms of type atomic.2.
If T1, .
.
.
,Tnare standard terms of type ?
, then?T1, .
.
.
,Tn?
is a standard term of type stack(?
).3.
If T1, .
.
.
,Tnare standard terms of type ?
, then(T1, .
.
.Tn) is a standard term of type queue(?
).4.
If f1, .
.
.
,fnare record fields, T1, .
.
.
,Tnare terms of type ?1, .
.
.
, ?n, then[f1:T1, .
.
.
,fn:Tn] is a standard term oftype record(f1:?1,.
.
.,fn:?n).5.
Standard Terms are only defined on the basis of(1)?
(4).Definition: Anchored Terms.1.
is is an anchored term of typerecord(f1:?1,.
.
.,fn:?n).2.
If T is an anchored term of typerecord(.
.
.,f:?
,.
.
.
), then T?f is an anchoredterm of type ?
.3.
If T is an anchored term of type queue(?
), thenfirst(T) and last(T) are anchored terms oftype ?
.4.
If T is an anchored term of type stack(?
), thentop(T) is an anchored term of type ?
.5.
If T is an anchored term of type queue(? )
orstack(?
), then member(T) is an anchored termof type ?
.6.
Anchored terms are only defined on the basisof (1)?
(5).The interpretation function [[.
]]sfor (standard and an-chored) terms with respect to an information state sis defined as follows.Definition: Reference of Terms.1.
[[T]]s= T iff T is a standard term.2.
[[is]]s= s.3.
[[T?f]]s= the value of field f in [[T]]s.4.
[[top(T)]]s= the top member of [[T]]siff T is oftype stack().5.
[[first(T)]]s= the first member of [[T]]siff Tis of type queue().6.
[[last(T)]]s= the last member of [[T]]siff T isof type queue().7.
[[member(T)]]s= a member of [[T]]siff T is oftype stack() or of type queue().Now we define the syntax and semantics of updaterule conditions in DIPPER.
For the interpretationof conditions we use a truth-conditional semanticsmapping conditions to one of the values 1 (?true?)
or0 (?false?
), defined with the help of an interpretationfunction I with respect to an information state s.Definition: Syntax of Conditions.1.
If T1and T2are (standard or anchored) termsof the same type, then T1=T2and T16=T2areconditions.2.
If T is a (standard or anchored) term of typestack(?
), or queue(?
), then empty(T) andnon empty(T) are conditions.3.
Conditions are only defined on the basis of (1)and (2).Definition: Semantics of Conditions.1.
Is(T1=T2) = 1 iff [[T1]]s= [[T2]]s2.
Is(T16=T2) = 1 iff [[T1]]s6= [[T2]]s3.
Is(empty(T)) = 1 iff [[T]]sdenotes a stack orqueue containing no elements.4.
Is(non empty(T)) = 1 iff [[T]]sdenotes a stackor queue containing at least one element.Definition: Information State Satisfaction.An information state s satisfies a set of conditions Ciff ?c : c ?
C ?
[[c]]s= 1.The effects in an update rule are responsible forchanging the information state.
There are two kindsof effects: operations defined over terms, and solv-ables.Definition: Syntax of Effects.1.
If T1is an anchored term of type ?
and T2a (standard or anchored) term of type ?
, thenassign(T1,T2) is an effect.2.
If T1is an anchored term of type stack(? )
andT2a (standard or anchored) term of type ?
,then clear(T1), pop(T1), and push(T1,T2)are effects.3.
If T1is an anchored term of type queue(?
)and T2a (standard or anchored) term of type?
, then clear(T1), dequeue(T1), and en-queue(T1,T2) are effects.4.
If the term S is an n-place OAA-solvable,T1,.
.
.,Tnare (standard or anchored) terms,E(x) an ordered (possibly empty) set ofeffects with free occurrences of x, thensolve(x,S(T1,.
.
.,Tn),E) is an effect.5.
Effects are only defined on the basis of (1)?
(4).The semantics of the effects are defined with thehelp of the function U: s ?
E?s from an informa-tion state and an effect to a new information state.
(Some notational conventions: We will use the nota-tion s[T]s0 to mean that the information states s ands0 are the same except for the value of [[T]]s. We willuse E[t/u] to mean substituting t for u in E).Definition: Semantics of Effects.1.
U(s,assign(T,T0)) = s0 if s[T]s0 and [[T]]s?
=[[T0]]s.2.
U(s,clear(T)) = s0 if s[T]s0 and [[T]]s?
= ??.3.
U(s,pop(T)) = s0 if s[T]s0 and [[T]]s=?t1, t2, .
.
.
, tn?
and [[T]]s?
= ?t2, .
.
.
, tn?.4.
U(s,push(T,T0)) = s0 if s[T]s0 and [[T]]s=?t1, .
.
.
, tn?
and [[T]]s?
= ?
[[T0]]s, t1, .
.
.
, tn?.5.
U(s,dequeue(T)) = s0 if s[T]s0 and [[T]]s=(t1, t2, .
.
.
, tn) and [[T]]s?
= (t2, .
.
.
, tn).6.
U(s,enqueue(T,T0)) = s0 if s[T]s0 and [[T]]s=(t1, .
.
.
, tn) and [[T]]s?
= (t1, .
.
.
, tn, [[T0]]s).7.
U(s,solve(x,S(T1,.
.
.,Tn),E)) = s if for all an-swers a returned by solve(S([[T1]]s,.
.
.,[[Tn]]s))there is an s0 such that the effects E[a/x] are ap-plied to s0.Definition: Update.An ordered set of effects {e1, .
.
.
, en} are success-fully applied to an information state s, resulting aninformation state s0 if U(e1,s)=s1,.
.
., U(ei,si?1)=si,.
.
., U(en,sn?1)=s0.
