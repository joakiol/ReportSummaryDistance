A PROGRAM FOR ALIGNING SENTENCES IN BILINGUAL CORPORAWilliam A. GaleKenneth W. ChurchAT&T Bell Laboratories600 Mountain AvenueMurray Hill, NJ, 07974ABSTRACTResearchers in both machine Iranslation (e.g.,Brown et al, 1990) and bilingual lexicography(e.g., Klavans and Tzoukermann, 1990) haverecently become interested in studying paralleltexts, texts such as the Canadian Hansards(parliamentary proceedings) which are available inmultiple languages (French and English).
Thispaper describes a method for aligning sentences inthese parallel texts, based on a simple statisticalmodel of character lengths.
The method wasdeveloped and tested on a small trilingual sampleof Swiss economic reports.
A much larger sampleof 90 million words of Canadian Hansards hasbeen aligned and donated to the ACL/DCI.1.
IntroductionResearchers in both machine lranslation (e.g.,Brown et al 1990) and bilingual lexicography(e.g., Klavans and Tzoukermann, 1990) haverecently become interested in studying bilingualcorpora, bodies of text such as the CanadianI-lansards (parliamentary debates) which areavailable in multiple languages (such as Frenchand English).
The sentence alignment task is toidentify correspondences between sentences inone language and sentences in the other language.This task is a first step toward the more ambitioustask finding correspondances among words.
IThe input is a pair of texts uch as Table 1.1.
In statistics, tring matching problems are divided into twoclasses: alignment problems and correspondance problems.Crossing dependencies are possible in the latter, but not inthe former.Table 1:Input to Alignment ProgramEnglishAccording to our survey, 1988 sales of mineralwater and soft drinks were much higher than in1987, reflecting the growing poptdm'ity of theseproducts.
Cola drink manufacturers in particularachieved above-average growth rates.
Thehigher turnover was largely due to an increase inthe sales volume.
Employment and investmentlevels also climbed.
Following a two-yearIransitional period, the new FoodstuffsOrdinance for Mineral Water came into effect onApril 1, 1988.
Specifically, it contains morestringent requirements regarding qualityconsistency and purity guarantees.FrenchQuant aux eaux rain&ales et aux limonades, ellesrencontrent toujours plus d'adeptes.
En effet,notre sondage fait ressortir des ventes nettementSUl~rieures h celles de 1987, pour les boissonsbase de cola notamment.
La progression deschiffres d'affaires r~sulte en grande partie del'accroissement du volume des ventes.
L'emploiet les investissements ont 8galement augmentS.La nouvelle ordonnance f&16rale sur les denr6esalimentaires concernant entre autres les eauxmin6rales, entree en vigueur le ler avril 1988aprbs une p6riode transitoire de deux ans, exigesurtout une plus grande constance dans la qualit~et une garantie de la puret&The output identifies the alignment betweensentences.
Most English sentences match exactlyone French sentence, but it is possible for anEnglish sentence to match two or more Frenchsentences.
The first two English sentences(below) illustrate a particularly hard case wheretwo English sentences align to two Frenchsentences.
No smaller alignments are possiblebecause the clause "... sales ... were higher..." in177the first English sentence corresponds to (part of)the second French sentence.
The next twoalignments below illustrate the more typical casewhere one English sentence aligns with exactlyone French sentence.
The final alignment matchestwo English sentences toa single French sentence.These alignments agreed with the results producedby a human judge.Table 2:Output from Alignment ProgramEnglishFrenchAccording to our survey, 1988 sales of mineralwater and soft drinks were much higher than in1987, reflecting the growing popularity of theseproducts.
Cola drink manufacturers in particularachieved above-average growth rates.Quant aux eaux mintrales et aux limonades, ellesrenconlrent toujours plus d'adeptes.
En effet,notre sondage fait ressortir des ventes nettementSUlX~rieures A celles de 1987, pour les boissons Abase de cola notamment.The higher turnover was largely due to anincrease in the sales volume.La progression des chiffres d'affaires r#sulte ngrande partie de l'accroissement du volume desventes.Employment and investment levels also climbed.L'emploi et les investissements ont #galementaugmenUf.Following a two-year transitional period, the newFoodstuffs Ordinance for Mineral Water cameinto effect on April 1, 1988.
Specifically, itcontains more stringent requirements regardingquality consistency and purity guarantees.La nonvelle ordonnance f&l&ale sur les denrtesalimentaires concernant entre autres les eauxmindrales, entree en viguenr le ler avril 1988apr~ une lxfriode tmmitoire de deux ans, exigesurtout une plus grande constance darts la qualit~et une garantie de la purett.Aligning sentences is just a first step towardconstructing a probabilistic dictionary (Table 3)for use in aligning words in machine translation(Brown et al, 1990), or for constructing abilingual concordance (Table 4) for use inlexicography (Klavans and Tzoukermann, 1990).Table 3:An Entry in a Probabilistic Dictionary(from Brown et al, 1990)English French Prob(French \] English)the le 0.610the la 0.178the 1' 0.083the les 0.023the ce 0.013the il 0.012the de 0.009the A 0.007the clue 0.007Table 4: A Bilingual Concordancebank/banque ("money" sense)and the governor of theet le gouvemeur de la800 per cent in one week through% ca une semaine ~cause d' ut~bank/banc ("place" sense)bank of canada have fwxluanflybcaque du canada ont fr&lnemmbank action.
SENT therebanque.
SENT voil~such was the case in the georgesats-tmis et lc canada itWolx~ duhe said the nose and tail of the_,~M__~ lcs extn~tta dubank issue which was settled betwbanc de george.bank were surrendered bybanc.
SENT~ fairAlthough there has been some previous work onthe sentence alignment, e.g., (Brown, Lai, andMercer, 1991), (Kay and Rtscheisen, 1988),(Catizone et al, to appear), the alignment taskremains a significant obstacle preventing manypotential users from reaping many of the benefitsof bilingual corpora, because the proposedsolutions are often unavailable, unreliable, and/orcomputationally prohibitive.The align program is based on a very simplestatistical model of character lengths.
The modelmakes use of the fact that longer sentences in onelanguage tend to be translated into longersentences in the other language, and that shortersentences tend to be translated into shortersentences.
A probabilistic score is assigned toeach pair of proposed sentence pairs, based on theratio of lengths of the two sentences (incharacters) and the variance of this ratio.
Thisprobabilistic score is used in a dynamicprogramming framework in order to find themaximum likelihood alignment of sentences.178It is remarkable that such a simple approach canwork as well as it does.
An evaluation wasperformed based on a trilingual corpus of 15economic reports issued by the Union Bank ofSwitzerland (UBS) in English, French andGerman (N = 14,680 words, 725 sentences, and188 paragraphs in English and correspondingnumbers in the other two languages).
The methodcorrectly aligned all but 4% of the sentences.Moreover, it is possible to extract a largesubcorpus which has a much smaller error rate.By selecting the best scoring 80% of thealignments, the error rate is reduced from 4% to0.7%.
There were roughly the same number oferrors in each of the English-French and English-German alignments, suggesting that the methodmay be fairly language independent.
We believethat the error rate is considerably lower in theCanadian Hansards because the translations aremore literal.2.
A Dynamic Programming FrameworkNow, let us consider how sentences can be alignedwithin a paragraph.
The program makes use ofthe fact that longer sentences in one language tendto be translated into longer sentences in the otherlanguage, and that shorter sentences tend to betranslated into shorter sentences.
2 A probabilisticscore is assigned to each proposed pair ofsentences, based on the ratio of lengths of the twosentences (in characters) and the variance of thisWe will have little to say about how sentence boanderiesam identified.
Identifying sentence boundaries is notalways as easy as it might appear for masons described inLibennan and Church (to appear).
It would be much easierif periods were always used to mark sentence boundaries,but unfortunately, many periods have other purposes.
Inthe Brown Corpus, for example, only 90% of the periodsam used to mark seutence boundaries; the remaining 10%appear in nmnerical expressions, abbreviations and so forth.In the Wall Street Journal, there is even more discussion ofdollar amotmts and percentages, as well as more use ofabbreviated titles such as Mr.; consequently, only 53% ofthe periods in the the Wall Street Journal are used toidentify sentence boundaries.For the UBS data, a simple set of heuristics were used toidentify sentences boundaries.
The dataset was sufficientlysmall that it was possible to correct he reznaining mistakesby hand.
For a larger dataset, such as the CanadianHansards, it was not possible to check the results by hand.We used the same procedure which is used in (Church,1988).
This procedure was developed by Kathryn Baker(private communication).ratio.
This probabilistic score is used in adynamic programming framework in order to findthe maximum likelihood alignment of sentences.We were led to this approach after noting that thelengths (in characters) of English and Germanparagraphs are highly correlated (.991), asillustrated in the following figure.Paragraph Lengths are Highly Correlated0 QQb.
. '
- .
-.,?...
o* f~?o  "?Figure 1.
The hodzontal axis shows thelength of English paragraphs, while thevertical scale shows the lengths of thecorresponding German paragraphs.
Notethat the correlation is quite large (.991).Dynamic programming is often used to align twosequences of symbols in a variety of settings, suchas genetic ode sequences from different species,speech sequences from different speakers, gaschromatograph sequences from differentcompounds, and geologic sequences fromdifferent locations (Sankoff and Kruskal, 1983).We could expect hese matching techniques to beuseful, as long as the order of the sentences doesnot differ too radically between the two languages.Details of the alignment techniques differconsiderably from one application to another, butall use a distance measure to compare twoindividual elements within the sequences, and adynamic programming algorithm to minimize thetotal distances between aligned elements withintwo sequences.
We have found that the sentencealignment problem fits fairly well into thisframework.1793.
The Distance MeasureIt is convenient for the distance measure to bebased on a probabilistic model so that informationcan be combined in a consistent way.
Ourdistance measure is an estimate of-log Prob(match\[8), where 8 depends on !1 and12, the lengths of the two portions of text underconsideration.
The log is introduced here so thatadding distances will produce desirable results.This distance measure is based on the assumptionthat each character in one language, L 1, gives riseto a random number of characters in the otherlanguage, L2.
We assume these random variablesare independent and identically distributed with anormal distribution.
The model is then specifiedby the mean, c, and variance, s 2, of thisdistribution, c is the expected number ofcharacters in L2 per character in L1, and s 2 is thevariance of the number of characters in L2 percharacter in LI.
We define 8 to be(12-11 c ) l~s  2 so that it has a normaldistribution with mean zero and variance one (atleast when the two portions of text underconsideration actually do happen to be translationsof one another).The parameters c and s 2 are determinedempirically from the UBS data.
We couldestimate c by counting the number of characters inGerman paragraphs then dividing by the numberof characters in corresponding English paragraphs.We obtain 81105173481 = 1.1.
The samecalculation on French and English paragraphsyields c = 72302/68450 = 1.06 as the expectednumber of French characters per Englishcharacters.
As will be explained later,performance does not seem to very sensitive tothese precise language dependent quantities, andtherefore we simply assume c = 1, whichsimplifies the program considerably.The model assumes that s 2 is proportional tolength.
The constant of proportionality isdetermined by the slope of a robust regression.The result for English-German is s 2 = 7.3, andfor English-French is s 2 = 5.6.
Again, we havefound that the difference in the two slopes is nottoo important.
Therefore, we can combine thedata across languages, and adopt the simplerlanguage independent estimate s 2 = 6.8, which iswhat is actually used in the program.We now appeal to Bayes Theorem to estimateProb (match l 8) as a constant timesProb(81match) Prob(match).
The constant canbe ignored since it will be the same for allproposed matches.
The conditional probabilityProb(8\[match) can be estimated byProb(Slmatch) = 2 (1 - Prob(lSI))where Prob(\[SI) is the probability that a randomvariable, z, with a standardized (mean zero,variance one) normal distribution, has magnitudeat least as large as 18 \[The program computes 8 directly from the lengthsof the two portions of text, Ii and 12, and the twoparameters, c and s 2.
That is,8 = (12 - It c)l~f-~l s 2.
Then, Prob(\[81) iscomputed by integrating a standard normaldistribution (with mean zero and variance 1).Many statistics textbooks include a table forcomputing this.The prior probability of a match, Prob(match), isfit with the values in Table 5 (below), which weredetermined from the UBS data.
We have foundthat a sentence in one language normally matchesexactly one sentence in the other language (1-1),three additional possibilities are also considered:1-0 (including 0-I), 2-I (including I-2), and 2-2.Table 5 shows all four possibilities.Table 5: Prob(mateh)Category Frequency Prob(match)1-1 1167 0.891-0 or 0-1 13 0.00992-1 or 1-2 117 0.0892-2 15 0.0111312 1.00This completes the discussion of the distancemeasure.
Prob(matchlS) is computed as an(irrelevant) constant timesProb(Slmatch) Prob(match).
Prob(match) iscomputed using the values in Table 5.Prob(Slmatch) is computed by assuming thatProb(5\]match) = 2 (1 - erob(151)), whereProb (J 5 I) has a standard normal distribution.
Wefirst calculate 8 as (12 - 11 c)/~\[-~1 s 2 and thenerob(181) is computed by integrating a standardnormal distribution.The distance function two side distance isdefined in a general way to al\]-ow for insertions,180deletion, substitution, etc.
The function takes fourargnments: x l ,  Yl, x2, Y2.1.
Let two_side_distance(x1, Yl ; 0, 0) bethe cost of substituting xl with y 1,2. two side_distance(xl, 0; 0, 0) be thecost of deleting Xl,3.
two_sidedistance(O, Yl ; 0, 0) be thecost of insertion of yl ,4. two side_distance(xl, Yl ; xg., O) be thecost of contracting xl and x2 to yl ,5. two_sidedistance(xl, Yl ; 0, Y2) be thecost of expanding xl to Y 1 and yg, and6.
two sidedistance(xl, Yl ; x2, yg.)
be thecost of merging Xl and xg.
and matchingwith y i and yg..4.
The Dynamic Programming AlgorithmThe algorithm is summarized in the followingrecursion equation.
Let si, i= 1 .
.
.
I ,  be thesentences of one language, and t j ,  j=  1 .--  J, bethe translations of those sentences in the otherlanguage.
Let d be the distance function(two_side_distance) described in the previoussection, and let D(i, j) be the minimum distancebetween sentences sl.
? "
si and their translationstl, " "  tj, under the maximum likelihoodalignment.
D(i,j) is computed recursively, wherethe recurrence minimizes over six cases(substitution, deletion, insertion, contraction,expansion and merger) which, in effect, impose aset of slope constraints.
That is, DO,j) iscalculated by the following recurrence with theinitial condition D(i, j) = O.D(i, j) =min.D(i, j - l )  + d(0, ty; 0, 0)D( i - l ,  j) + d(si, O; 0,0)D( i -1 ,  j - l )  + d(si, t); 0, 0)!D( i -1,  j -2 )  + d(si, t:; O, tj-1)!D( i -2,  j - l )  + d(si, Ij; Si- l ,  O)!D( i -2,  j -2 )  + d(si, tj; si-1, tj-1)5.
EvaluationTo evaluate align, its results were compared witha human alignment.
All of the UBS sentenceswere aligned by a primary judge, a native speakerof English with a reading knowledge of Frenchand German.
Two additional judges, a nativespeaker of French and a native speaker of German,respectively, were used to check the primary judgeon 43 of the more difficult paragraphs having 230sentences (out of 118 total paragraphs with 725sentences).
Both of the additional judges werealso fluent in English, having spent the last fewyears living and working in the United States,though they were both more comfortable withtheir native language than with English.The materials were prepared in order to make thetask somewhat less tedious for the judges.
Eachparagraph was printed in three columns, one foreach of the three languages: English, French andGerman.
Blank lines were inserted betweensentences.
The judges were asked to draw linesbetween matching sentences.
The judges werealso permitted to draw a line between a sentenceand "null" if they thought hat the sentence wasnot translated.
For the purposed of thisevaluation, two sentences were defined to"match" if they shared a common clause.
(In afew cases, a pair of sentences shared only a phraseor a word, rather than a clause; these sentences didnot count as a "match" for the purposes of thisexperiment.
)After checking the primary judge with the othertwo judges, it was decided that the primaryjudge's results were sufficiently reliable that theycould be used as a standard for evaluating theprogram.
The primary judge made only twomistakes on the 43 hard paragraphs (one Frenchmistake and one German mistake), whereas theprogram made 44 errors on the same materials.Since the primary judge's error rate is so muchlower than that of the program, it was decided thatwe needn't be concerned with the primary judge'serror rate.
If the program and the judge disagree,we can assume that the program is probablywrong.The 43 "hard" paragraphs were selected bylooking for sentences that mapped to somethingother than themselves after going through bothGerman and French.
Specifically, for eachEnglish sentence, we attempted to find the181corresponding German sentences, and then foreach of them, we attempted to find thecorresponding French sentences, and then weattempted to find the corresponding Englishsentences, which should hopefully get us back towhere we started.
The 43 paragraphs included allsentences in which this process could not becompleted around the loop.
This relatively smallgroup of paragraphs (23 percent of all paragraphs)contained a relatively large fraction of theprogram's errors (82 percent).
Thus, there doesseem to be some verification that this trilingualcriterion does in fact succeed in distinguishingmore difficult paragraphs from less difficult ones.There are three pairs of languages: English-German, English-French and French-German.
Wewill report just the first two.
(The third pair isprobably dependent on the first two.)
Errors arereported with respect o the judge's responses.That is, for each of the "matches" that theprimary judge found, we report the program ascorrect ff it found the "match" and incorrect ff itdidn't This convention allows us to compareperformance across different algorithms in astraightforward fashion.The program made 36 errors out of 621 totalalignments (5.8%) for English-French, and 19errors out of 695 (2.7%) alignments for English-German.
Overall, there were 55 errors out of atotal of 1316 alignments (4.2%).handled correctly.
In addition, when thealgorithm assigns a sentence to the 1-0 category, itis also always wrong.
Clearly, more work isneeded to deal with the 1-0 category.
It may benecessary to consider language-specific methodsin order to deal adequately with this case.We observe that the score is a good predictor ofperformance, and therefore the score can be usedto extract a large subcorpus which has a muchsmaller error rate.
By selecting the best scoring80% of the alignments, the error rate can bereduced from 4% to 0.7%.
In general, we cantrade off the size of the subcorpus and theaccuracy by setting a threshold, and rejectingalignments with a score above this threshold.Figure 2 examines this trade-off in more detail.Table 6: Complex Matches are More Difficultcategory English-French English-German totalN err % N err % N err %l -0or0-11-12-1 or 1-22-23-1 or !-33-2 or 2-38 8 100542 14 2.659 8 149 3 331 1 1001 1 1005 5 100625 9 1.458 2 3.46 2 331 1 1000 0 013 13 1001167 23 2.0117 10 915 5 332 2 1001 1 100Table 6 breaks down the errors by category,illustrating that complex matches are moredifficulL I-I alignments are by far the easiest.The 2-I alignments, which come next, have fourtimes the error rate for I-I.
The 2-2 alignmentsare harder still, but a majority of the alignmentsare found.
The 3-I and 3-2 alignments arc noteven considered by the algorithm, so naturally allthree are counted as errors.
The mostembarrassing category is I-0, which was never182Extracting a Subcorpus with Lower Error Rate~re~i to .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
- -o .oi / | i i20  40  60  B0  t00p~mnt o( nmtminod aF~nrrmntsFigure 2.
The fact that the score is such agood predictor of performance can be usedto extract a large subcorpus which has amuch smaller error rate.
In general, we cantrade-off the size of the subcorpus and theaccuracy by-setting a threshold, and rejectingalignments with a score above this threshold.The horizontal axis shows the size of thesubcorpus, and the vertical axis shows thecorresponding error rate.
An error rate ofabout 2/3% can be obtained by selecting athreshold that would retain approximately80% of the corpus.Less formal tests of the error rate in the Hansardssuggest hat the overall error rate is about 2%,while the error rate for the easy 80% of thesentences i about 0.4%.
Apparently the Hansardtranslations are more literal than the UBS reports.It took 20 hours of real time on a sun 4 to align367 days of Hansards, or 3.3 minutes perHansard-day.
The 367 days of Hansards containabout 890,000 sentences or about 37 million"words" (tokens).
About half of the computertime is spent identifying tokens, sentences, andparagraphs, while the other half of the time isspent in the align program itself.6.
Measuring Length In Terms Of Words Ratherthan CharactersIt is interesting to consider what happens if wechange our definition of length to count wordsrather than characters.
It might seem that wordsare a more natural inguistic unit than characters183(Brown, Lai and Mercer, 1991).
However, wehave found that words do not perform nearly aswell as characters.
In fact, the "words" variationincreases the number of errors dramatically (from36 to 50 for English-French and from 19 to 35 forEnglish-German).
The total errors were therebyincreased from 55 to 85, or from 4.2% to 6.5%.We believe that characters are better because thereare more of them, and therefore there is lessuncertainty.
On the average, the~re are 117characters per sentence (including white space)and only 17 words per sentence.
Recall that wehave modeled variance as proportional to sentencelength, V = s 2 I.
Using the character data, wefound previously that s 2= 6.5.
The sameargument applied to words yields s 2 = 1.9.
Forcomparison sake, it is useful to consider the ratioof ~/(V(m))lm (or equivalently, sl~m), where mis the mean sentence length.
We obtain ff(m)lmratios of 0.22 for characters and 0.33 for words,indicating that characters are less noisy thanwords, and are therefore more suitable for use inalign.7.
ConclusionsThis paper has proposed a method for aligningsentences in a bilingual corpus, based on a simpleprobabilistic model, described in Section 3.
Themodel was motivated by the observation thatlonger regions of text tend to have longertranslations, and that shorter regions of text tendto have shorter translations.
In particular, wefound that the correlation between the length of aparagraph in characters and the length of itstranslation was extremely high (0.991).
This highcorrelation suggests that length might be a strongclue for sentence alignment.Although this method is extremely simple, it isalso quite accurate.
Overall, there was a 4.2%error rate on 1316 alignments, averaged over bothEnglish-French and English-German data.
Inaddition, we find that the probability score is agood predictor of accuracy, and consequently, it ispossible to select a subset of 80% of thealignments with a much smaller error rate of only0.7%.The method is also fairly language-independent-Both English-French and English-German datawere processed using the same parameters.
I fnecessary, it is possible to fit the six parameters inthe model with language-specific values, though,thus far, we have not found it necessary (or evenhelpful) to do so.We have examined a number of variations.
Inparticular, we found that it is better to usecharacters ather than words in counting sentencelength.
Apparently, the performance is better withcharacters because there is less variability in theratios of sentence lengths so measured.
Usingwords as units increases the error rate by half,from 4.2% to 6.5%.In the future, we would hope to extend the methodto make use of lexical constraints.
However, it isremarkable just how well we can do without suchconstraints.
We might advocate the simplecharacter length alignment procedure as a usefulfirst pass, even to those who advocate the use oflexical constraints.
The character lengthprocedure might complement a lexical conslraintapproach quite well, since it is quick but has someerrors while a lexical approach isprobably slower,though possibly more accurate.
One might gowith the character length procedure when thedistance scores are small, and back off to a lexicalapproach as necessary.Church, K., "A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text,"Second Conference on Applied NaturalLanguage Processing, Austin, Texas, 1988.Klavans, J., and E. Tzoukermann, (1990), "TheBICORD System," COLING-90, pp 174-179.Kay, M. and M. R6scheisen, (1988) "Text-Translation Alignment," unpublished ms.,Xerox Palo Alto Research Center.Liberman, M., and K. Church, (to appear), "'TextAnalysis and Word Pronunciation i  Text-to-Speech Synthesis," in Fund, S., andSondhi, M.
(eds.
), Advances in SpeechSignal Processing.ACKNOWLEDGEMENTSWe thank Susanne Wolff and and EvelyneTzoukermann for their pains in aligning sentences.Susan Warwick provided us with the UBStrilingual corpus and posed the Ixoblem addressedhere.REFERENCESBrown, P., J. Cocke, S. Della Pietra, V. DellaPietra, F. Jelinek, J. Lafferty, R. Mercer,and P. Roossin, (1990) "A  StatisticalApproach to Machine Translation,"Computational Linguistics, v 16, pp 79-85.Brown, P., J. Lai, and R. Mercer, (1991)"Aligning Sentences in Parallel Corpora,'"ACL Conference, Berkeley.Catizone, R., G. Russell, and S. Warwick, (toappear) "Deriving Translation Data fromBilingual Texts," in Zernik (ed), LexicalAcquisition: Using on-line Resources toBuild a Lexicon, Lawrence Erlbaum.184
