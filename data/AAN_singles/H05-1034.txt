Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 265?272, Vancouver, October 2005. c?2005 Association for Computational LinguisticsA Comparative Study on Language Model Adaptation TechniquesUsing New Evaluation MetricsHisami Suzuki Jianfeng GaoMicrosoft Research Microsoft Research AsiaOne Microsoft Way  49 Zhichun Road, Haidian DistrictRedmond WA 98052 USA Beijing 100080 Chinahisamis@microsoft.com jfgao@microsoft.comAbstractThis paper presents comparative experimen-tal results on four techniques of languagemodel adaptation, including a maximum aposteriori (MAP) method and three dis-criminative training methods, the boostingalgorithm, the average perceptron and theminimum sample risk method, on the task ofJapanese Kana-Kanji conversion.
We evalu-ate these techniques beyond simply usingthe character error rate (CER): the CER re-sults are interpreted using a metric of do-main similarity between background andadaptation domains, and are further evalu-ated by correlating them with a novel metricfor measuring the side effects of adaptedmodels.
Using these metrics, we show thatthe discriminative methods are superior to aMAP-based method not only in terms ofachieving larger CER reduction, but also ofbeing more robust against the similarity ofbackground and adaptation domains, andachieve larger CER reduction with fewerside effects.1 IntroductionLanguage model (LM) adaptation attempts to ad-just the parameters of a LM so that it performs wellon a particular (sub-)domain of data.
Currently,most LMs are based on the Markov assumptionthat the prediction of a word depends only on thepreceding n?1 words, but such n-gram statistics areknown to be extremely susceptible to the charac-teristics of training samples.
This is true even whenthe data sources are supposedly similar: for exam-ple, Rosenfeld (1996) showed that perplexity dou-bled when a LM trained on the Wall Street Journal(1987-1989) was tested on the AP newswire storiesof the same period.
This observation, coupled withthe fact that training data is available in large quan-tities only in selected domains, facilitates the needfor LM adaptation.There have been two formulations of the LMadaptation problem.
One is the within-domain ad-aptation, in which adapted LMs are created fordifferent topics in a single domain (e.g., Seymoreand Rosenfeld, 1997; Clarkson and Robinson,1997; Chen et al, 1998).
In these studies, a domainis defined as a body of text originating from a sin-gle source, and the main goal of LM adaptation isto fine-tune the model parameters so as to improvethe LM performance on a specific sub-domain (ortopic) using the training data at hand.The other formulation, which is the focus of thecurrent study, is to adapt a LM to a novel domain,for which only a very small amount of trainingdata is available.
This is referred to as cross-domain adaptation.
Following Bellegarda (2001),we call the domain used to train the original modelthe background domain, and the novel domainwith a small amount of training data as the adapta-tion domain.
Two major approaches to cross-domain adaptation have been investigated: maxi-mum a posteriori (MAP) estimation and discrimi-native training methods.
In MAP estimationmethods, adaptation data is used to adjust the pa-rameters of the background model so as to maxi-mize the likelihood of the adaptation data.
Countmerging and linear interpolation of models are thetwo MAP estimation methods investigated inspeech recognition experiments (Iyer et al, 1997;Bacchiani and Roark, 2003), with count mergingreported to slightly outperform linear interpolation.Discriminative approaches to LM adaptation, onthe other hand, aim at using the adaptation data todirectly minimize the errors on the adaptation datamade by the background model.
These techniqueshave been applied successfully to the task of lan-guage modeling in non-adaptation (Roark et al,2652004) as well as adaptation (Bacchiani et al, 2004)scenarios.In this paper, we present comparative experi-mental results on four language model adaptationtechniques and evaluate them from various angles,attempting to elucidate the characteristics of thesemodels.
The four models we compare are a maxi-mum a posteriori (MAP) method and three dis-criminative training methods, namely the boostingalgorithm (Collins, 2000), the average perceptron(Collins, 2002) and the minimum sample riskmethod (Gao et al, 2005).
Our evaluation of thesetechniques is unique in that we go beyond simplycomparing them in terms of character error rate(CER): we use a metric of distributional similarityto measure the distance between background andadaptation domains, and attempt to correlate it withthe CER of each adaptation method.
We also pro-pose a novel metric for measuring the side effectsof adapted models using the notion of backwardcompatibility, which is very important from a soft-ware deployment perspective.Our experiments are conducted in the setting ofJapanese Kana-Kanji conversion, as we believethis task is excellently suited for evaluating LMs.We begin with the description of this task in thefollowing section.2 Language Modeling in the Task of IMEThis paper studies language modeling in the con-text of Asian language (e.g., Chinese or Japanese)text input.
The standard method for doing this isthat the users first input the phonetic strings, whichare then converted into the appropriate word stringby software.
The task of automatic conversion hasbeen the subject of language modeling research inthe context of Pinyin-to-Character conversion inChinese (Gao et al, 2002a) and Kana-Kanji con-version in Japanese (Gao et al, 2002b).
In this pa-per, we call the task IME (Input Method Editor),based on the name of the commonly used Win-dows-based application.The performance of IME is typically measuredby the character error rate (CER), which is thenumber of characters wrongly converted from thephonetic string divided by the number of charac-ters in the correct transcript.
Current IME systemsexhibit about 5-15% CER on real-world data in awide variety of domains.In many ways, IME is a similar task to speechrecognition.
The most obvious similarity is thatIME can also be viewed as a Bayesian decisionproblem: let A be the input phonetic string (whichcorresponds to the acoustic signal in speech); thetask of IME is to choose the most likely wordstring W* among those candidates that could havebeen converted from A:)|()(maxarg)|(maxarg*)()(WAPWPAWPWAWAW GENGEN ?
?==(1)where GEN(A) denotes the candidate set given A.Unlike speech recognition, however, there is noacoustic ambiguity in IME, because the phoneticstring is provided directly by users.
Moreover, wecan assume a unique mapping from W to A in IME,i.e., P(A|W) = 1.
So the decision of Equation (1)depends solely on P(W), which makes IME idealfor testing language modeling techniques.
Anotheradvantage of using IME for language modelingresearch is that it is relatively easy to convert W toA, which facilitates the creation of training data fordiscriminative learning, as described later.From the perspective of LM adaptation, IMEfaces the same problem speech recognition faces:the quality of the model depends heavily on thesimilarity of the training and test data.
This poses aserious challenge to IME, as it is currently the mostwidely used method of inputting Chinese or Japa-nese characters, used by millions of users for in-putting text of any domain.
LM adaptation in IMEis therefore an imminent requirement for improv-ing user experience, not only as we build staticdomain-specific LMs, but also in making onlineuser adaptation possible in the future.3 Discriminative Algorithms for LM Ad-aptationThis section describes three discriminative trainingmethods we used in this study.
For a detailed de-scription of each algorithm, readers are referred toCollins (2000) for the boosting algorithm, Collins(2002) for perceptron learning, and Gao et al(2005) for the minimum sample risk method.3.1 DefinitionThe following set-up, adapted from Collins (2002),was used for all three discriminative training meth-ods:266?
Training data is a set of input-output pairs.
In thetask of IME, we have training samples {Ai, WiR},for i = 1?M, where each Ai is an input phoneticstring and each WiR is the reference transcript of Ai.?
We assume a set of D + 1 features fd(W), for d =0?D.
The features could be arbitrary functionsthat map W to real values.
Using vector notation,we have f(W)?
?D+1, where f(W) = {f0(W), f1(W),?, fD(W)}.
The feature f0(W) is called the basemodel feature, and is defined as the log probabilitythat the word trigram model assigns to W. The fea-tures fd(W) for d = 1?D are defined as the word n-gram counts (n = 1 and 2 in our experiments) in W.?
The parameters of the model form a vector of D+ 1 dimensions, one for each feature function, ?={?0, ?1, ?, ?D}.
The likelihood score of a wordstring W can then be written as)(),( WWScore ?f?
= ?==Dddd Wf?0)( .
(2)Given a model ?
and an input A, the decision ruleof Equation (1) can then be rewritten as).,(maxarg),(* ?
?GENWScoreAW(A)W ?=(3)We can obtain the number of conversion errors inW by comparing it with the reference transcript WRusing an error function Er(WR,W), which is an editdistance in our case.
We call the sum of errorcounts over the training set the sample risk (SR).Discriminative training methods strive to optimizethe parameters of a model by minimizing SR, as inEquation (4).
?===MiiiRi AWWSR...1* )),(,Er(minarg)(minarg ?????
(4)However, (4) cannot be optimized directly by regu-lar gradient-based procedures as it is a piecewiseconstant function of ?
and its gradient is undefined.The discriminative training methods described be-low differ in how they achieve the optimization:the boosting and perceptron algorithms approxi-mate SR by loss functions that are suitable for op-timization; the minimum sample risk method, onthe other hand, uses a simple heuristic training pro-cedure to minimize SR directly without resortingto an approximated loss function.3.2 The boosting algorithmThe boosting algorithm we used is based onCollins (2000).
Instead of measuring the number ofconversion errors directly, it uses a loss functionthat measures the number of ranking errors, i.e.,cases where an incorrect candidate W receives ahigher score than the correct conversion WR.
Themargin of the pair (WR, W) with respect to themodel ?
is given by),(),(),( ??
WScoreWScoreWWM RR ?=(5)The loss function is then defined as?
?= ?=Mi iAiWiRi WWMI...1 )()],([)RLoss(GEN?
(6)where I[?]
= 1 if ?
?
0, and 0 otherwise.
Note thatRLoss takes into account all candidates in GEN(A).Since optimizing (6) is NP-complete, the boost-ing algorithm optimizes its upper bound:?
?= ?
?=Mi AWiRiiiWWM...1 )()),(exp()ExpLoss(GEN?
(7)Figure 1 summarizes the boosting algorithm weused.
After initialization, Step 2 and 3 are repeatedN times; at each iteration, a feature is chosen andits weight is updated.
We used the following up-date for the dth feature fd:ZCZCddd ??
?++=+_log21(8)where Cd+ is a value increasing exponentially withthe sum of margins of (WR, W) pairs over the setwhere fd is seen in WR but not in W; Cd-  is the valuerelated to the sum of margins over the set where fdis seen in W but not in WR.
?
is a smoothing factor(whose value is optimized on held-out data) and Zis a normalization constant.1 Set ?0 = 1 and ?d = 0 for d=1?D2 Select a feature fd which has largest estimated im-pact on reducing ExpLoss of Equation (7)3 Update ?d by Equation (8), and return to Step 2Figure 1: The boosting algorithm3.3 The perceptron algorithmThe perceptron algorithm can be viewed as a formof incremental training procedure that optimizes aminimum square error (MSE) loss function, whichis an approximation of SR (Mitchell, 1997).
Asshown in Figure 2, it starts with an initial parame-ter setting and updates it for each training sample.We used the average perceptron algorithm ofCollins (2002) in our experiments, a variation thathas been proven to be more effective than the stan-dard algorithm shown in Figure 2.
Let ?dt,i be the267value for the dth parameter after the ith trainingsample has been processed in pass t over the train-ing data.
The average parameters are defined as)./()()(1 1, MTTtMiitdavgd ?= ?
?= =??
(9)3.4 The minimum sample risk methodThe minimum sample risk (MSR, Gao et al, 2005)training algorithm is motivated by analogy with thefeature selection procedure for the boosting algo-rithm (Freund et al, 1998).
It is a greedy procedurefor selecting a small subset of the features thathave the largest contribution in reducing SR in asequential manner.
Conceptually, MSR operateslike any multidimensional function optimizationapproach: a direction (i.e., feature) is selected andSR is minimized along that direction using a linesearch, i.e., adjusting the parameter of the selectedfeature while keeping all other parameters fixed.This is repeated until SR stops decreasing.Regular numerical line search algorithms cannotbe applied directly because, as described above,the value of a feature parameter versus SR is notsmooth and there are many local minima.
MSRthus adopts the method proposed by Och (2003).Let GEN(A) be the set of n-best candidate wordstrings that could be converted from A.
By adjust-ing ?d for a selected feature fd, we can find a set ofintervals for ?d within which a particular candidateword string is selected.
We can compute Er(.)
forthe candidate and use it as the Er(.)
value for thecorresponding interval.
As a result, we obtain anordered sequence of Er(.)
values and a correspond-ing sequence of ?
intervals for each training sample.By summing Er(.)
values over all training samples,we obtain a global sequence of SR and the corre-sponding global sequence of ?d intervals.
We canthen find the optimal ?d as well as its correspond-ing SR by traversing the sequence.Figure 3 summarizes the MSR algorithm.
SeeGao et al (2005) for a complete description of theMSR implementation and the empirical justifica-tion for its performance.4 Experimental Results4.1 DataThe data used in our experiments come from fivedistinct sources of text.
A 36-million-word Nikkeinewspaper corpus was used as the backgrounddomain.
We used four adaptation domains: Yomi-uri (newspaper corpus), TuneUp (balanced corpuscontaining newspaper and other sources of text),Encarta (encyclopedia) and Shincho (collection ofnovels).
The characteristics of these domains aremeasured using the information theoretic notion ofcross entropy, which is described in the next sub-section.For the experiment of LM adaptation, we usedthe training data consisting of 8,000 sentences andtest data of 5,000 sentences from each adaptationdomain.
Another 5,000-sentence subset was usedas held-out data for each domain, which was usedto determine the values of tunable parameters.
Allthe corpora used in our experiments are pre-segmented into words using a baseline lexiconconsisting of 167,107 entries.4.2 Computation of domain characteristicsYuan et al (2005) introduces two notions of do-main characteristics: a within-domain notion ofdiversity, and a cross-domain concept of similarity.Diversity is measured by the entropy of the corpusand indicates the inherent variability within thedomain.
Similarity, on the other hand, is intendedto capture the difficulty of a given adaptation task,and is measured by the cross entropy.For the computation of these metrics, we ex-tracted 1 million words from the training data ofeach domain respectively, and created a lexiconconsisting of the words in our baseline lexicon plusall words in the corpora used for this experiment(resulting in 216,565 entries) to avoid the effect ofout-of-vocabulary items.
Given two domains A and1 Set ?0 = 1 and ?d = 0 for d=1?D2 For t = 1?T (T = the total number of iterations)3For each training sample (Ai, WiR), i = 1?M4Choose the best candidate Wi from GEN(Ai)according to Equation (3)5For each ?d (?
= size of learning step)6?d = ?d + ?
(fd(WiR) ?
fd(Wi))Figure 2: The perceptron algorithm1 Set ?0 = 1 and ?d = 0 for d=1?D2 Rank all features by its expected impact on reduc-ing SR and select the top N features3 For each n = 1?N4    Update the parameter of f using line searchFigure 3: The MSR algorithm268B, we then trained a word trigram model for eachdomain B, and used the resulting model in comput-ing the cross entropy of domain A.
For simplicity,we denote this as H(A,B).Table 1 summarizes our corpora along this di-mension.
Note that the cross entropy is not sym-metric, i.e., H(A,B) is not necessarily the same asH(B,A), so we only present the average cross en-tropy in Table 1.
We can observe that Yomiuri andTuneUp are much more similar to the backgroundNikkei corpus than Encarta and Shincho.H(A,A) along the diagonal of Table 1 (in bold-face) is the entropy of the corpus, indicating thecorpus diversity.
This quantity indeed reflects thein-domain variability of text: newspaper and ency-clopedia articles are highly edited text, followingstyle guidelines and often with repetitious content.In contrast, Shincho is a collection of novels, onwhich no style or content restriction is imposed.We use these metrics in the interpretation of CERresults in Section 5.4.3 Results of LM adaptationThe discriminative training procedure was carriedout as follows: for each input phonetic string A inthe adaptation training set, we produced a wordlattice using the baseline trigram models describedin Gao et al (2002b).
We kept the top 20 hypothe-ses from this lattice as the candidate conversion setGEN(A).
The lowest CER hypothesis in the latticerather than the reference transcript was used as WR.We used unigram and bigram features that oc-curred more than once in the training set.We compared the performance of discriminativemethods against a MAP estimation method as thebaseline, in this case the linear interpolationmethod.
Specifically, we created a word trigrammodel using the adaptation data for each domain,which was then linearly interpolated at the wordlevel with the baseline model.
The probability ac-cording to the combined model is given by)|()1()|()|( hwPhwPhwp iAiBi ??
?+= ,where PB is the probability of the backgroundmodel, PA the probability of the adaptation model,and the history h corresponds to two precedingwords.
?
was tuned using the held-out data.In evaluating both MAP estimation and dis-criminative models, we used an N-best rescoringapproach.
That is, we created N best hypothesesusing the baseline trigram model (N=100 in ourexperiments) for each sentence in the test data, andused adapted models to rescore the N-best list.
Theoracle CERs (i.e., the minimal possible CER giventhe available hypotheses) ranged from 1.45% to5.09% depending on the adaptation domain.The results of the experiments are shown in Ta-ble 2.
We can make some observations from thetable.
First, all discriminative methods signifi-cantly outperform the linear interpolation (statisti-cally significant according to the t-test at p < 0.01).In contrast, the differences among three discrimi-native methods are very subtle and most of themare not statistically significant.
Secondly, the CERresults correlate well with the metric of domainsimilarity in Table 1 (r=0.94 using the Pearsonproduct moment correlation coefficient).
This isconsistent with our intuition that the closer the ad-aptation domain is to the background domain, theeasier the adaptation task.Regarding the similarity of the adaptation do-main to the background, we also observe that theCER reduction of the linear interpolation model isparticularly limited when the adaptation domain issimilar to the background domain: the CER reduc-tion of the linear interpolation model for Yomiuriand TuneUp over the baseline is 0% and 1.89%respectively, in contrast to ~22% and ~5.8% im-provements achieved by the discriminative models.The discriminative methods are therefore morerobust against the similarity of the adaptation andbackground data than the linear interpolation.Our results differ from Bacchiani et al (2004) inthat in our system, the perceptron algorithm aloneachieved better results than MAP estimation.However, the difference may only be apparent,given different experimental settings for the twoN Y T E SNikkei 3.94 7.46 7.65 9.81 10.10Yomiuri  4.09 7.82 8.96 9.29TuneUp   4.41 8.82 8.56Encarta    4.40 9.20Shincho     4.61Table 1: Cross entropyDomain Base LI MSR Boost PercepYomiuri 3.70 3.69 2.89 2.88 2.85TuneUp 5.81 5.70 5.48 5.47 5.47Encarta 10.24 8.64 8.39 8.54 8.34Shincho 12.18 11.47 11.05 11.09 11.20Table 2: CER results (%) (Base=baseline model;LI=linear interpolation)269studies.
We used the N-best reranking approachwith the same N-best list for both MAP estimationand discriminative training, while in Bacchiani etal.
(2004), two different lattices were used: the per-ceptron model was applied to rerank the latticecreated by the background model, while the MAPadaptation model was used to produce the latticeitself.
The fact that the combination of these mod-els (i.e., first use the MAP estimation to create hy-potheses and then use the perceptron algorithm torerank them) produced the best results indicatesthat given a candidate lattice, the perceptron algo-rithm is effective in candidate reranking, thus mak-ing our results compatible with theirs.5 DiscussionThe results in Section 4 demonstrate that discrimi-native training methods for adaptation are overallsuperior to MAP adaptation methods.
In this sec-tion, we show additional advantages of discrimina-tive methods beyond simple CER improvements.5.1 Using metrics for side effectsIn the actual deployment of LM adaptation, oneissue that bears particular importance is the num-ber of side effects that are introduced by anadapted model.
For example, consider an adaptedmodel which achieves 10% CER improvementsover the baseline.
Such a model can be obtained byimproving 10%, or by improving 20% and by in-troducing 10% of new errors.
Clearly, the formermodel is preferred, particularly if the models be-fore and after adaptation are both to be exposed tousers.
This concept is more widely acknowledgedwithin the software industry as backward compati-bility ?
a requirement that an updated version ofsoftware supports all features of its earlier versions.In IME, it means that all phonetic strings that canbe converted correctly by the earlier versions of thesystem should also be converted correctly by thenew system as much as possible.
Users are typi-cally more intolerant to seeing errors on the stringsthat used to be converted correctly than seeing er-rors that also existed in the previous version.Therefore, it is crucial that when we adapt to a newdomain, we do so by introducing the smallestnumber of side effects, particularly in the case ofan incremental adaptation to the domain of a par-ticular user, i.e., to building a model with incre-mental learning capabilities.5.2 Error ratioIn order to measure side effects, we introduce thenotion of error ratio (ER), which is defined as||||BAEEER = ,where |EA| is the number of errors found only in thenew (adaptation) model, and |EB| the number oferrors corrected by the new model.
Intuitively, thisquantity captures the cost of improvement in theadaptation model, corresponding to the number ofnewly introduced errors per each improvement.The smaller the ratio is, the better the model is atthe same CER: ER=0 if the adapted model intro-duces no new errors, ER<1 if the adapted modelmakes CER improvements, ER=1 if the CER im-provement is zero (i.e., the adapted model makesas many new mistakes as it corrects old mistakes),and ER>1 when the adapted model has worse CERperformance than the baseline model.Given the notion of CER and ER, a model canbe plotted on a graph as in Figure 4: the relativeerror reduction (RER, i.e., the CER difference be-tween the background and adapted models) is plot-ted along the x-axis, and ER along the y-axis.Figure 4 plots the models obtained after variousnumbers of iterations for MSR training and at vari-ous interpolation weights for linear interpolationfor the TuneUp domain.
The points in the upper-left quadrant, ER>1 and RER<0, are the modelsthat performed worse than the baseline model(some of the interpolated models fall into this cate-gory); the shaded areas (upper-right and lower-leftquadrants) are by definition empty.
The lower-right quadrant is the area of interest to us, as they     Figure 4: RER/ER plot for MSR and LI models forTuneUp domain270represent the models that led to CER improve-ments; we will focus only on this area now inFigure 5.In this figure, a model is considered to havefewer side effects when the ER is smaller at thesame RER (i.e., smaller value of y for a fixed valueof x), or when the RER is larger at the same ER(i.e., larger value of x at the fixed y).
That is, thecloser a model is plotted to the corner B of thegraph, the better the model is; the closer it is to thecorner A, the worse the model is.5.3 Model comparison using RER/ERFrom Figure 5, we can clearly see that MSR mod-els have better RER/ER-performance than linearinterpolation models, as they are plotted closer tothe corner B.
Figure 6 displays the same plot for allfour domains: the same trend is clear from allgraphs.
We can therefore conclude that a discrimi-native method (in this case MSR) is superior tolinear interpolation not only in terms of CER re-duction, but also of having fewer side effects.
Thisdesirable result is attributed to the nature of dis-criminative training, which works specifically toadjust feature weights so as to minimize error.Figure 7: RER/ER plot for MSR, boosting and percep-tron models (X-axis is normalized to represent relativeerror rate reduction)Figure 7 compares the three discriminativemodels with respect to RER/ER by plotting thebest models (i.e., models used to produce the re-sults in Table 1) for each algorithm.
We can seethat even though the boosting and perceptron algo-rithms have the same CER for Yomiuri andTuneUp from Table 2, the perceptron is better interms of ER; this may be due to the use of expo-nential loss function in the boosting algorithmwhich is less robust against noisy data (Hastie et al,2001).
We also observe that Yomiuri and Encartado better in terms of side effects than TuneUp andShincho for all algorithms, which can be explainedby corpus diversity, as the former set is less stylis-tically diverse and thus more consistent within thedomain.5.4 Overfitting and side effectsThe RER/ER graph also casts the problem of over-fitting in an interesting perspective.
Figure 8 is de-rived from running MSR on the TuneUp testcorpus, which depicts a typical case of overfitting:the CER drops in the beginning, but after a certainnumber of iterations, it goes up again.
The modelsindicated by ?
and ?
in the graph are of the sameCER, and as such, these models are equivalent.When plotted on the RER/ER graph in Figure 5,    Figure 5: RER/ER plot for the models with ER<1 andRER>0 for TuneUp domain.
See Figure 8 for the de-scription of ?
and ?                                 !"!# #Figure 6: RER/ER plot for all four domainsx-axes: RER (%); y-axes: ER?
: linear interpolation models; ?
:MSR models271however, it is clear that the overfit model ?
has theworse ER than the non-overfit counterpart ?.
Inother words, models ?
and ?
have the same CER,but they are not equivalent: model ?
is not onlyworse in light of containing more features, but alsoin terms of causing more side effects.6 Conclusion and Future WorkWe have presented a comparison of three discrimi-native learning approaches with a MAP estimationmethod in the task of LM adaptation for IME.
Wehave shown that all discriminative models are sig-nificantly better than the linear interpolationmethod, in that they achieve larger CER reductionwith fewer side effects across different domains.One direction of future research is to apply thistechnique to an incremental learning scenario, i.e.,to incrementally build models using incoming datafor adaptation, taking all previously available dataas background corpus.
The new metric for back-ward compatibility we proposed in the paper willplay a particularly important role in such a scenario.AcknowledgementsWe would like to thank Kevin Duh, Gary Kacmar-cik, Eric Ringger, Yoshiharu Sato and Wei Yuanfor their help at various stages of this research.ReferencesBacchiani, M. and B. Roark.
2003.
Unsupervised Lan-guage Model Adaptation.
Proceedings of ICASSP,pp.224-227.Bacchiani, M., B. Roark and M. Saraclar.
2004.
Lan-guage Model Adaptation with MAP Estimation andthe Perceptron Algorithm.
Proceedings of HLT-NAACL, pp.21-24.Bellegarda, J.R. 2001.
An Overview of Statistical Lan-guage Model Adaptation.
ITRW on Adaptation Meth-ods for Speech Recognition, pp.
165-174.Chen, S.F., K. Seymore and R. Rosenfeld.
1998.
TopicAdaptation for Language Modeling Using Unnormal-ized Exponential Models.
Proceedings of ICASSP.Clarkson, P.R., and A.J.
Robinson.
1997.
LanguageModel Adaptation Using Mixtures and an Exponen-tially Decaying Cache.
Proceedings of ICASSP.Collins, M. 2000.
Discriminative Reranking for NaturalLanguage Parsing.
ICML 2000.Collins, M. 2002.
Discriminative Training Methods forHidden Markov Models: Theory and Experiments withPerceptron Algorithm.
Proceedings of EMNLP, pp.1-8.Freund, Y., R. Iyer, R.E.
Shapire and Y.
Singer.
1998An Efficient Boosting Algorithm for Combining Pref-erences.
ICML'98.Gao, J., J. Goodman, M. Li and K.-F. Lee.
2002a.
To-ward a unified approach to statistical language model-ing for Chinese.
ACM Transactions on AsianLanguage Information Processing, 1-1: 3-33.Gao, J, H. Suzuki and Y. Wen.
2002b.
Using HeadwordDependency and Predictive Clustering for LanguageModeling.
Proceedings of EMNLP: 248-256.Gao, J., H. Yu, P. Xu and W. Yuan.
2005.
MinimumSample Risk Methods for Language Modeling.
Pro-ceedings of EMNLP 2005.Hastie, T., R. Tibshirani and J. Friedman.
2001.
TheElements of Statistical Learning.
Springer-Verlag,New York.Iyer, R., M. Ostendorf and H. Gish.
1997.
Using Out-of-Domain Data to Improve In-Domain Language Models.IEEE Signal Processing Letters, 4-8: 221-223.Mitchell, Tom M. 1997.
Machine learning.
TheMcGraw-Hill Companies, Inc.Och, F. J.
2003.
Minimum Error Rate Training in Statis-tical Machine Translation.
Proceedings of ACL: 160-167.Roark, B., M. Saraclar and M. Collins.
2004.
CorrectiveLanguage Modeling for Large Vocabulary ASR withthe Perceptron Algorithm.
Proceedings of ICASSP:749-752.Rosenfeld, R. 1996.
A Maximum Entropy Approach toAdaptive Statistical Language Modeling.
Computer,Speech and Language, 10: 187-228.Seymore, K. and R. Rosenfeld.
1997.
Using Story Top-ics For Language Model Adaptation.
Proceedings ofEurospeech '97.Yuan, W., J. Gao and H. Suzuki.
2005.
An EmpiricalStudy on Language Model Adaptation Using a Metricof Domain Similarity.
Proceedings of IJCNLP 05.          Figure 8: MSR test error curve for TuneUp272
