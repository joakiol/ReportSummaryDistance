Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 238?241,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUvT-WSD1: a Cross-Lingual Word Sense Disambiguation systemMaarten van GompelTilburg centre for Cognition and CommunicationTilburg Universityproycon@anaproy.nlAbstractThis paper describes the Cross-LingualWord Sense Disambiguation system UvT-WSD1, developed at Tilburg University,for participation in two SemEval-2 tasks:the Cross-Lingual Word Sense Disam-biguation task and the Cross-Lingual Lex-ical Substitution task.
The UvT-WSD1system makes use of k-nearest neighbourclassifiers, in the form of single-word ex-perts for each target word to be disam-biguated.
These classifiers can be con-structed using a variety of local and globalcontext features, and these are mappedonto the translations, i.e.
the senses,of the words.
The system works for agiven language-pair, either English-Dutchor English-Spanish in the current imple-mentation, and takes a word-aligned par-allel corpus as its input.1 IntroductionThe UvT-WSD1 system described in this papertook part in two similar SemEval-2 tasks: Cross-Lingual Word Sense Disambiguation (Lefever andHoste, 2010) and Cross-Lingual Lexical Substitu-tion (Mihalcea et al, 2010).
In each task, a num-ber of words is selected for which the senses are tobe determined for a number of instances of thesewords.
For each word, a number of samples incontext is provided, where each sample consists ofone sentence, with the word to be disambiguatedmarked.Because of the cross-lingual nature of the tasks,a word sense corresponds to a translation in an-other language, rather than a sense description inthe same language.
In the Cross-lingual LexicalSubstitution task, the target language is Spanish.The task is to find Spanish substitutes for the En-glish words marked in the test samples.
In theCross-Lingual Word Sense Disambiguation task,we participate for English-Dutch and English-Spanish.
The Word Sense Disambiguation taskprovides training data for all five languages, in theform of the sentence-aligned EuroParl parallel cor-pus (Koehn, 2005).
This is the source of trainingdata the UvT-WSD1 system uses for both tasks.The system may output several senses per in-stance, rather than producing just one sense pre-diction.
These are evaluated in two different ways.The scoring type ?best?
expects that the systemoutputs the best senses, in the order of its con-fidence.
The scoring type ?out of five/ten?
ex-pects five or ten guesses, and each answer weighsthe same.
These metrics are more extensivelydescribed in (Mihalcea et al, 2010).
The UvT-WSD1 system participates in both scoring types,for both tasks.
The system put forth in this paperfollows a similar approach as described in earlierresearch by (Hoste et al, 2002).2 System DescriptionThe UvT-WSD1 system uses machine learningtechniques to learn what senses/translations are as-sociated with any of the target words.
It doesso on the basis of a variety of local and globalcontext features, discussed in Section 2.2.
At thecore of the system are the classifiers, or so called?word experts?, one per target word.
These arebuilt using the Tilburg Memory Based Learner(TiMBL) (Daelemans et al, 2009), making useof the IB1 algorithm, an implementation of the k-nearest neighbour classifier.The core of the system can be subdivided intoroughly three stages.
In the first stage, the word-aligned parallel corpus is read and for each foundinstance of one of the target words, features are ex-tracted to be used in the classifier.
The class con-sists of the word aligned to the found instance ofthe target word, i.e.
the translation/sense.
In thisway a word expert is built for each of the target238words in the task, yielding a total amount of clas-sifiers equal to the total amount of target words.The test data is processed in a similar way, foreach marked occurrence of any of the target words,features are extracted and test instances are cre-ated.
Subsequently, the word experts are trainedand tested, and on the basis of the training data, aparameter search algorithm (Van den Bosch, 2004)determines the optimal set of classifier parametersfor each word expert, including for example thevalue of k and the distance weighting metric used.In the last phase, the classifier output of eachword expert is parsed.
The classifiers yield a dis-tribution of classes per test instance, and these areconverted to the appropriate formats for ?best?
and?out of five/ten?
evaluation.
For the latter scor-ing type, the five/ten highest scoring senses areselected, for the former scoring type, all classesscoring above a certain threshold are considered?best?.
The threshold is set at 90% of the score ofthe highest scoring class.2.1 Word-Alignment, Tokenisation,Lemmatisation andPart-of-Speech-taggingThe Europarl parallel corpus, English-Spanish andEnglish-Dutch, is delivered as a sentence-alignedparallel corpus.
We subsequently run GIZA++(Och and Ney, 2000) to compute a word-alignedparallel corpus.This, however, is not the sole input.
The tar-get words in both tasks are actually specified asa lemma and part-of-speech tag pair, rather thanwords.
In the Word Sense Disambiguation task, alltarget lemmas are simply nouns, but in the Cross-Lingual Lexical Substitution task, they can also beverbs, adjectives or adverbs.
Likewise, both tasksexpect the sense/translation output to also be in theform of lemmas.
Therefore the system internallyhas to be aware of the lemma and part-of-speechtag of each word in the parallel corpus and testdata, only then can it successfully find all occur-rences of the target words.
In order to get thisinformation, both sides of the word-aligned paral-lel corpus are run through tokenisers, lemmatisersand Part-of-Speech taggers, and the tokenised out-put is realigned with the untokenised input so theword alignments are retained.
The test data is alsoprocessed this way.
For English and Spanish, thesoftware suite Freeling (Atserias et al, 2006) per-formed all these tasks, and for Dutch it was doneby Tadpole (Van den Bosch et al, 2007).2.2 Feature ExtractionThe system can extract a variety of features to beused in training and testing.
A distinction can bemade between local context features and globalcontext features.
Local context features are ex-tracted from the immediate neighbours of the oc-currence of the target word.
One or more of thefollowing local context features are extractable bythe UvT-WSD1 system: word features, lemmafeatures, and part-of-speech tag features.
In eachcase, n features both to the right and left of thefocus word are selected.
Moreover, the systemalso supports the extraction of bigram features, butthese did not perform well in the experiments.The global context features are made up of abag-of-words representation of keywords that maybe indicative for a given word to sense/translationmapping.
The idea is that words are collectedwhich have a certain power of discrimination forthe specific target word with a specific sense,and all such words are then put in a bag-of-wordrepresentation, yielding as many features as theamount of keywords found.
A global count overthe full corpus is needed to find these keywords.Each keyword acts as a binary feature, indicatingwhether or not that particular keyword is found inthe context of the occurrence of the target word.The context in which these keywords are searchedfor is exactly one sentence, i.e.
the sentence inwhich the target word occurs.
This is due to thetest data simply not supplying a wider context.The method used to extract these keywords (k)is proposed by (Ng and Lee, 1996) and used alsoin the research of (Hoste et al, 2002).
Assume wehave a focus word f , more precisely, a lemma andpart-of-speech tag pair of one of the target words.We also have one of its aligned translations/sensess, which in this implementation is also a lemma.We can now estimate P (s|k), the probability ofsense s, given a keyword k, by dividing Ns,klocal.
(the number of occurrences of a possible localcontext word k with particular focus word lemma-PoS combination and with a particular sense s) byNklocal(the number of occurrences of a possiblelocal context keyword klocwith a particular focusword-PoS combination regardless of its sense).
Ifwe also take into account the frequency of a pos-sible keyword k in the complete training corpus(Nkcorpus), we get:239P (s|k) =Ns,klocalNklocal(1Nkcorpus) (1)(Hoste et al, 2002) select a keyword k for in-clusion in the bag-of-words representation if thatkeyword occurs more than T1times in that senses, and if P (s|k) ?
T2.
Both T1and T2are pre-defined thresholds, which by default were set to 3and 0.001 respectively.
In addition, UvT-WSD1contains an extra parameter which can be enabledto automatically adjust the T1threshold when ityields too many or too few keywords.
The selec-tion of bag-of-word features is computed prior tothe extraction of the training instances, as this in-formation is a prerequisite for the successful gen-eration of both training and test instances.2.3 Voting systemThe local and global context features, and the var-ious parameters that can be configured for extrac-tion, yield a lot of possible classifier combinations.Rather than merging all local context and globalcontext features together in a single classifier, theycan also be split over several classifiers and havean arbiter voting system do the final classificationstep.
UvT-WSD1 also supports this approach.
Avoter is constructed by taking as features the classoutput of up to three different classifiers, trainedand tested on the training data, and mapping thesefeatures onto the actual correct sense in the train-ing data.
For testing, the same approach is taken:up to three classifiers run on the test data; their out-put is taken as feature vector, and the voting sys-tem predicts a sense.
This approach may be usefulin boosting results and smoothing out errors.
Inour experiments we see that a voter combinationoften performs better than taking all features to-gether in one single classifier.
Finally, also in thevoter system there is a stage of automatic parame-ter optimisation for TiMBL.3 Experiments and ResultsBoth SemEval-2 tasks have provided trial dataupon which the system could be tested during thedevelopment stage.
Considering the high config-urability of the various parameters for feature ex-traction, the search space in possible configura-tions and classifier parameters is vast, also dueto fact that the TiMBL classifier used may take awealth of possible parameters.
As already men-tioned, for the latter an automatic algorithm of pa-BEST UvT-WSD1-v UvT-WSD1-gPrecision & Recall 21.09 19.59Mode Prec.
& Rec.
43.76 41.02Ranking (out of 14) 6 9OUT OF TEN UvT-WSD1-v UvT-WSD1-gPrecision & Recall 58.91 55.29Mode Prec.
& Rec.
62.96 73.94Ranking 3 4Table 1: UvT-WSD1 results in the Cross-Lingual LexicalSubstitution taskrameter optimisation was used (Van den Bosch,2004), but optimisation of the feature extractionparameters has not been automated.
Rather, a se-lection of configurations has been manually cho-sen and tested during the development stage.The following two configurations of featureswere found to perform amongst the best on thetrial data.
Therefore they have been selected andsubmitted for the contest:1.
UvT-WSD1-v (aka UvT-v) ?
An arbiter-voting system over three classifiers: 1) Wordexperts with two word features and lemmafeatures on both sides of the focus word.2)Word experts with global features1.
3)Word experts with two word features, twolemma features and two part-of-speech tagfeatures.2.
UvT-WSD1-g (aka UvT-g) ?
Word expertswith global features only.Table 1 shows a condensed view of the resultsfor the Cross-Lingual Lexical Substitution task.Table 2 shows the final results for the Word-SenseDisambiguation task.
Note that UvT-WSD1-v andUvT-WSD1-g are two different configurations ofthe UvT-WSD1 system, and to conserve spacethese are abbreviated as UvT-v and UvT-g respec-tively.
These are also the names used in both tasks(Lefever and Hoste, 2010; Mihalcea et al, 2010)to refer to our system.4 Discussion and ConclusionCross-Lingual Word Sense Disambiguation andCross-Lingual Lexical Substitution have proven tobe hard tasks, with scores that are relatively closeto baseline.
This can be attributed to a noticeabletrait in the system output to be inclined to assignthe same majority sense to all instances.1For the Cross-Lingual Lexical Substitution task only, theparameter to recompute the T1threshold automatically wasenabled.240Dutch BEST UvT-v UvT-g T3-COLEURPrecision & Recall 17.7 15.93 10.72 & 10.56Mode Prec.
& Rec.
12.06 10.54 6.18 & 6.16Dutch OUT OF FIVE UvT-v UvT-g T3-COLEURPrecision & Recall 34.95 34.92 21.54 & 21.22Mode Prec.
& Rec.
24.62 19.72 12.05 & 12.03Spanish BEST UvT-v UHD-1 UvT-g T3-COLEUR FCC-WSD1Precision & Recall 23.42 20.48 & 16.33 19.92 19.78 & 19.59 15.09Mode Prec.
& Rec.
24.98 28.48 & 22.19 24.17 24.59 14.31Spanish OUT OF FIVE UvT-g UvT-v FCC-WSD2 UHD-1 T3-COLEURPrecision & Recall 43.12 42.17 40.76 38.78 & 31.81 35.84 & 35.46Mode Prec.
& Rec.
43.94 40.62 44.84 40.68 & 32.38 39.01 & 38.78Table 2: UvT-WSD1 results in comparison to other participants in the Word-Sense Disambiguation taskIn our system, we used the same configurationof feature extraction, or a voter over a set of con-figurations, for all word experts.
The actual classi-fier parameters however, do differ per word expert,as they are the result of the automatic parameteroptimisation algorithm.
Selecting different featureextraction configurations per word expert wouldbe a logical next step to attempt to boost resultseven further, as been done in (Decadt et al, 2004).Keeping in mind the fact that different word ex-perts may perform differently, some general con-clusions can be drawn from the experiments onthe trial data.
It appears to be beneficial to in-clude lemma features, rather than just word fea-tures.
However, adding Part-of-speech featurestends to have a negative impact.
For these lo-cal context features, the optimum context size isoften two features to the left and two features tothe right of the focus word, cf.
(Hendrickx et al,2002).
The global keyword features perform well,but best results are achieved if they are not mixedwith the local context features in one classifier.An arbiter voting approach over multiple clas-sifiers helps to smooth out errors and yields thehighest scores (see Tables 1 and 2).
When com-pared to the other participants, the UvT-WSD1system, in the voting configuration, ranks first inthe Word Sense Disambiguation task, for the twolanguage pairs in which we participated.ReferencesJordi Atserias, Bernardino Casas, Elisabet Comelles, Mer-itxell Gonzlez, Llu?
?s Padr?o, and Muntsa Padr?o.
2006.FreeLing 1.3: Syntactic and semantic services in an open-source NLP library .
In Proceedings of the Fifth Interna-tional Conference on Language Resources and Evaluation(LREC 2006), Genoa, Italy.
ELRA.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A.
Van denBosch.
2009.
TiMBL: Tilburg memory based learner, ver-sion 6.2, reference guide.
Technical Report ILK 09-01,ILK Research Group, Tilburg University.B.
Decadt, V. Hoste, W. Daelemans, and A.
Van denBosch.
2004.
GAMBL, genetic algorithm optimizationof memory-based WSD.
In R. Mihalcea and P. Edmonds,editors, Proceedings of the Third International Workshopon the Evaluation of Systems for the Semantic Analysis ofText (Senseval-3), pages 108?112, New Brunswick, NJ.ACL.I.
Hendrickx, A.
Van den Bosch, V. Hoste, and W. Daele-mans.
2002.
Dutch word sense disambiguation: Optimiz-ing the localness of context.
In Proceedings of the Work-shop on word sense disambiguation: Recent successes andfuture directions, pages 61?65, Philadelphia, PA.V.
Hoste, I. Hendrickx, W. Daelemans, and A.
Van denBosch.
2002.
Parameter optimization for machine learn-ing of word sense disambiguation.
Natural Language En-gineering, 8(4):311?325.Philipp Koehn.
2005.
Europarl: A parallel corpus for statisti-cal machine translation.
In In Proceedings of the MachineTranslation Summit X ([MT]?05)., pages 79?86.Els Lefever and Veronique Hoste.
2010.
Semeval 2010 task3: Cross-lingual word sense disambiguation.
In Proceed-ings of the 5th International Workshop on Semantic Eval-uations (SemEval-2010), Uppsala, Sweden.Rada Mihalcea, Ravi Sinha, and Diana McCarthy.
2010.
Se-meval 2010 task 2: Cross-lingual lexical substitution.
InProceedings of the 5th International Workshop on Seman-tic Evaluations (SemEval-2010), Uppsala, Sweden.Hwee Tou Ng and Hian Beng Lee.
1996.
Integrating mul-tiple knowledge sources to disambiguate word sense: Anexemplar-based approach.
In ACL, pages 40?47.F.J.
Och and H. Ney.
2000.
Giza++: Training of statisti-cal translation models.
Technical report, RWTH Aachen,University of Technology.A.
Van den Bosch, G.J.
Busser, S. Canisius, and W. Daele-mans.
2007.
An efficient memory-based morpho-syntactic tagger and parser for Dutch.
In P. Dirix, I. Schu-urman, V. Vandeghinste, , and F. Van Eynde, editors, Com-putational Linguistics in the Netherlands: Selected Papersfrom the Seventeenth CLIN Meeting, pages 99?114, Leu-ven, Belgium.A.
Van den Bosch.
2004.
Wrapped progressive samplingsearch for optimizing learning algorithm parameters.
InR.
Verbrugge, N. Taatgen, and L. Schomaker, editors,Proceedings of the Sixteenth Belgian-Dutch Conferenceon Artificial Intelligence, pages 219?226, Groningen, TheNetherlands.241
