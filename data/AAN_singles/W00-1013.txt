Document  Transformations and Informat ion StatesSta f fan  LarssonDept.
of linguisticsGSteborg UniversitySwedensibling.
~L.
seAnn ie  ZaenenXerox Research Centre EuropeGrenoble LaboratoryFranceAnnie.
Zaenen~xrce.
xerox, comAbst rac tWe discuss ways to explore howinstructional material needs to bestructured to be presented with var-ious degrees of interactivity.
Weuse the TRINDI 1 information stateapproach to model three differentdegrees of interactivity and presentIMDiS, a small experimental imple-mentation based on the GoDiS dia-logue system.1 In t roduct ionDocument transformations is becoming a hottopic in industrial research on document cre-ation.
The reason is practical: with the newpresentation possibilities, the advantages ofbeing able to adapt he 'same' document con-tent to different uses - where the differencecan lie in the support devices, audiences, lan-guages or modes of interaction - becomes veryattractive.
It not only becomes attractive, italso becomes necessary: one needs to presentmaterial in various contexts (oral presenta-tious, internet portals, etc.)
and it is verycostly to develop presentations from scratchfor these various contexts.This situation raises an old question andopens a new area of research: can one sep-arate content from presentation?
The philo-sophical answer might be 'no', but in practiceone doesn't need an absolute answer.
As thisarea of research arises more out of practicalnecessity than pure intellectual curiosity, the1TRINDI (Task Oriented Instruc-tional Dialogue), EC Project LE4-8314,www.
ling.
gu.
se/research/proj ec~s/trindi/engineering is preceding the science and it willtake some time before it rest on explicit solidfoundations.Here we look only at one small aspect of theproblem: how can we model small changesin presentation that are due to various de-grees of interactivity between participants ininstructional exchanges.
We start from a tra-ditional manual and make some assumptionsabout minimal interactivity which are mod-eled through dialogue moves.
We concludethat in this way we can make the presenta-tion of the material more flexible.
An impor-tant limit on the flexibility is, however, thedetail with which the discourse structure ofthe manual encodes the task plan underlyingthe activity.2 Degrees  o f  In teract iv i ty  and  thed i f ference between mono logueand  d ia logueWe take here the position that the main differ-ence between dialogue and monologue is thatthe former implies interactivity.
With interac-tivity we mean here that the participants caninfluence ach other's moves.
With respectto the area that interests us here, giving in-structions to repair devices, a traditional writ-ten manual influences the user but not viceversa (except hrough notes to the author).The user can, however, influence the order inwhich she accesses the material: it is easy tostop, to go back or to consult an other section(traditional printed material might be arguedto be better in that respect than presentationon a screen, we ignore that difference here).We can consider this as a limit case of inter-activity.112Note that interactivity does not necessarilyimply shared initiative.
The literature makesa distinction between task and dialogue ini-tiative (e.g.
(Chu-Carroll and Brown, 1998))but one can have dialogue with both types ofinitiative staying with one side.
In the caseswe discuss below the task initiative stays com-pletely with the manual and the dialogue ini-tiative only switches to the instructee in thecase where she can indicate that informationabout some subprocedures can be skipped.There is another dimension that often inter-venes in discussions about the difference be-tween dialogue and written discourse: the for-mer is spoken, the latter is written.
Given theway things are in a natural setting, the writ-ten medium tends not to allow interactivity,whereas the spoken medium is used mainly ininteractive settings.
Technical changes, how-ever, allow us to separate the written/spokenopposition from that between interactive andnon, or minimally, interactive discourse.
In-structional material can be presented in theaural mode without becoming more interac-tive e.g.
when a recording is played.
This canbe considered as a plus for instructional ma-terial because it allows the instructee to useher hands and eyes for the task itself but it isnot an unqualified advantage given that read-ing gives much more flexibility than listeningto a tape.
To cash in on the advantages oftheaural presentation, we need to recapture theflexibility of access that the written mediumallows.3 Ins t ruc t ions  and  In teract iv i tyIt is obvious that instructional situationsprofit from an interactive setting.
Instruc-tional situations are typically situations inwhich some participants (the instructors)know a lot that the other participants (theinstructees) need to know to achieve the com-mon goals.
In these kinds of situations it isimportant hat all the required and, prefer-ably only the required, knowledge gets trans-ferred at the moment he instructees need it.To achieve this, it is not enough that theinstructor have all the necessary knowledge,she needs also to know which state the in-structee is in and how that state changes toadapt the transfer of knowledge, hence theinstructee needs to be able to inform the in-structor about his state and influence in thisway the course of the interaction.Currently we have manuals, whose con-tent can be presented aurally or in a writ-ten form but where both the content and thepresentation are uniquely determined a pri-ori (modulo, the speed and order of read-ing mentioned above).
Or we have interac-tions that can be at a distance but wherea human instructor needs to be available atthe time of the action.
Making humans withthe required competence available is expen-sive and one would want to achieve some in-teractivity without his.
But computers tendto be frustrating participants in interactivesettings when one compares them to humanbeings and the study of dialogue concentratesmainly on making them as human as possible.When one considers the possibility of trans-ferring the interactivity from humans to ma-chines, there are, however, many intermedi-ate possibilities between o interactivity andfull blown interactivity in free-wheeling di-alogue where the participants can ask eachother questions about anything and nothing(for a more thorough discussion about dia-logues between humans and computers ee(Clark, 1999)).
In this paper we consider howminimal interactions can be modeled on thebasis of information which is available in tra-ditional instructional manuals.In looking at the problem this way onehas to keep in mind that instructional man-uals, although not interactive, are coopera-tive constructs: they assume that they par-ticipate with the user in a rational cooper-ative task and they are built on an implicitreader model, specifically they make assump-tions about what the user knows and whatshe doesn't know and the granularity of thetask descriptions that they have to provide.They obey in their own way Grice's Maximof Quantity but they need to leave open arange of possibilities so they need to providemore detail than is necessary in all circum-stances.
In what follows we can only consider113cases of over-informedness a  the informationneeded to remedy under-informedness is notavailable.4 The  TR INDI  mode lThe TRINDI project has developed both aframework and a toolkit to model varioustypes of interactions in terms of informationstate updates.
The framework, whose mainingredients are information states, dialoguemoves and updates, is described in (Traumet al, 1999).
We use the term informationstate to mean, roughly, the information storedinternally by an agent, in this case a dia-logue system.
A dialogue move engine up-dates the information state on the basis ofobserved ialogue moves and selects appropri-ate moves to be performed.
In:formation stateupdates are formalised as in~brmation stateupdate rules.
The importance of the frame-work is that new interactive :hypotheses canbe modeled with minor extensions.
The infor-mation state approach is implemented in theTRINDIKIT (Larsson et al, 2000); (Larssonand Traum, To appear), a toolkit for experi-menting with the implementation f informa-tion states and dialogue move engines and forbuilding dialogue systems.
It is used in theexperimental implementation described here.Various instantiations of the frameworkarticulate further what information states,moves, and update rules contain.
In this pa-per we use one formal representation f in-formation states that has been developed inthe TRINDI, SDS 2 and INDI 3 projects, andimplemented in the GoDiS dialogue system(Bohlin et al, 1999).
The central parts of theinformation state in GoDiS are dialogue plansand Questions Under Discussion (QUD), anotion borrowed from Ginzburg (Ginzburg,1998).2SDS (Swedish Dial%me Systems),NUTEK/HSFR Language Technology ProjectF1472/1997, http://~rm~, ida.liu, se/ nlplab/sds/3INDI (Information Exchange in Dialogue), Riks-bankens Jubileumsfond 1997-0134.5 Mode l ing  var ious  degrees  ofin teract iv i ty  in  TR INDIWe envision the following cases:?
1.
Traditional manual: no overt inter-action, we will consider this as the limitcase?
2.
Manual can ask yes/no questions andunderstand two types of user responses:- yes/no- done/don't understand- how??
3.
User can indicate whether she alreadyknows certain (sub)procedures5.1 GoDiS / IMDiS  in format ion  statesTo model the types of interactions above, westarted from the GoDiS system which is de-signed to deal with information-seeking dia-logue.
The IMDiS information state type isshown in Figure 1.PRIVATESHAREDPLAN : StackSet (Action): AGENDA : Stack(Action)TMP : (sa,ID.e as SHARED)| BEL : Set(Prop)\[ QUD : StackSet(Question): | ACTIONS : Stack(Action)L LU : Ut te ranceFigure i: IMDiS information state typeThe main division in the information stateis between information which is private to theagent and that which is shared between thedialogue participants.
The private part of theinformation state contains a PLAN field hold-ing a dialogue plan, i.e.
is a list of dialogueactions that the agent wishes to carry out.The plan can be changed uring the courseof the conversation.
The AGENDA field, onthe other hand, contains the short term goalsor obligations that the agent has, i.e.
whatthe agent is going to do next.
We have in-cluded a field TMP that mirrors the sharedfields.
This field keeps track of shared infor-mation that has not yet been grounded, i.e.confirmed as having been understood by the114?
iother dialogue participant.
The SHARED fieldis divided into four subfields.
One subfield isa set of proposit ions which the agent assumesfor the sake of the conversation.
The secondsubfield is for a stack of questions under dis-cussion (QUD).
These are questions that havebeen raised and are currently under discus-sion in the dialogue.
The ACTIONS field is astack of (domain) actions which the user hasbeen instructed to perform but has not yetperformed.The LU field contains informationabout the latest utterance.To adapt GoDiS to instructional dialogue,we added a subfield of SHARED.ACTIONS to(the shared part  of) the information state.The value of this field is a stack of actionswhich the system has instructed the user toperform, but whose performance has not yetbeen confirmed by the user.In building the experimental IMDiS, wehave made several simplifications.
We haveignored all the natural  language generationproblems and all the problems related to mak-ing text or dialogue natural, e.g.
problems re-lated to the use of pronouns and other refer-ential expressions.
To handle these we wouldnot only have to discuss basic interactivitybut also the medium in which the interactiontakes place: speech or written text.The monologue mode (case 1) uses only 2moves ( Ins t ruct ,  and In fo rm) .
Since thereis no user to confirm that actions have beenperformed, all actions are automatical ly con-firmed using the update rule autoConf i rm.RULE: autoConf i rmCLASS: in tegratePRE: { fst( SHARED.ACTIONS, A )pop( SHARED.ACTIONS )EFF: add( SHARED.BEL, done(A) )The dialogue version (cases 2 and 3)uses 9 move types, basically the 7 used inGoDiS (Ask,  Answer ,  In fo rm,  Repeat ,RequestRepeat ,  Greet ,  Qu i t )p lus  in-structions ( Ins t ruc t )  and confirmations(Conf i rm) .
Confirmations are integrated byassuming that the current topmost actionin SHARED.ACTIONS has been performed, asseen in the update rule below.RULE: in tegrateUsrConf i rmCLASS: in tegrateval( SHARED.LU.SPEAKER, nsr )PRE: assoc( SHARED.LU.MOVES, confirm, false )fst( SHARED.ACTIONS, A )set_assoc( SHARED.LU.MOVES, confirm, true )EFF: pop( SHARED.ACTIONS )add( SHARED.BEL, clozte( A ) )This rule says that if the user performed aConf i rm move, which has not yet been in-tegrated, and A is the "most salient" action,then integrate the move by putt ing the propo-s i t ion done (A) in the shared beliefs, and tak-ing A off the action stack.Elliptical "how"-questions from the userare interpreted as applying to the currentlytopmost action in the SHARED.ACTIONS stack.5.2 Domain  task ,  manua ls  andd ia loguesLet's now see how a monologue and a dialogueversion of the same task are related.
Below wehave an example from the user manual for theHomeCentre, a Xerox MFD.?
Reinstalling the print head?
Caution: Make sure that the green carriage locklever is STILL moved all the way forward beforeyou reinstall the print head.?
1.
Line up the hole in the print head with thegreen post on the printer carriage.?
Lower the print head down gently into position.?
2.
Gently push the green cartridge lock lever upuntil it snaps into place.?
This secures the print head.?
3.
Close the top cover and reattach the scanner.?
4.
Press and release the yellow LED button.?
The printer will prepare the cartridge for print-ing.?
Note: If the carriage does not move from the cen-ter position after you press the cartridge changebutton, remove and reinstall the print head.From this text, one can (re)construct a taskplan for reinstalling the print head.
Such aplan may be represented as in figure 2.
Note115NAME rein.stall(prim head)PRE movcd_forward(carriage2od0DECEFF minstalled(prinL head)Figure 2: Task plan- -1  actioncomplcx action / planfinal statethat this is a conditional plan, i.e.
it containsbranching conditions.From this task plan, IMDiS generates twoplans: a monologue plan and a dialogue plan.This is done using the "translation schema"in Figure 3.The difference between the text plan andthe dialogue plan is in the way that condi-tionals in the task plan are interpreted.
Inthe monologue plan, they correspond to sim-ply informing the user of the conditional.
Indialogue mode, however, the system raises thequestion whether the condition holds.
Whenthe system finds out if the condition holds, itwill instruct he user to execute the appropri-ate guarded action.Here we can clearly see how dialogue differsfrom monologue as viewed by Carlson or VanKuppevelt ((Carlson, 1983), (~an Kuppevelt,1995)).
Under these views the writer antici-pates the questions the user might have askedbut given the user is not present he writerhas to make up for the lack of interactivity.The questions that can be reconstructed (oraccommodated) are different in that case.
Forinstance in the example given here, the ques-tion could something like "What should theuser/I make sure of?".
These questions arevaluable to help figure out the discourse struc-ture of a monologue.
They can also be valu-able tools to illustrate the differences betweendialogue and monologue but they do not givemuch insight in the effects of various degreesof interactivity.Conditionals are treated as follows by thesystem in dialogue mode: When the systemhas found out what the user's task is, it willload the appropriate dialogue plan into thePRIVATE.PLAN field of the information state.It will then execute the actions in the appro-priate order by moving them to the agendaand generating appropriate utterances.
Whena conditional statement is topmost on theplan, IMDiS will check whether it has been es-tablished that the condition holds (by check-ing the SHARED.BEL field).
Since the systemhas previously asked the user and the user hasanswered, either the condition or its negationwill be in the set of established propositions.If the condition or its negation holds, the con-ditional will be popped off the plan and re-placed by the first or second guarded action(respectively).116DOMAINl~recondition Paction Aif_then (C,A)effect EMONOLOGUEInstruct (check (P))Instruct(A)Inform(if_then (C, A) )Inform(E)DIALOGUEfindout(P);if_then ( not (P),Instruct (achieve (P)) )Instruct(A)findout (C) ;if-then(C,Instruct(A))Inform(E)Figure 3: Plan conversion table5.3 Monologue and DialogueBehav iourIn the monologue mode in IMDiS, thecontrol module does not call the input andinterpretation modules.
The text is output"move by move" as a sequence of utterancesfrom the system.S: Reinstalling the print head.S: Make sure that the green carriage locklever is STILL moved all the way forwardbefore you install the print head.S: Line up the hole in the print head withthe green post on the printer carriageCompared to the monologue mode, even avery restricted ialogue mode offers severaladvantages:User a t tent ion  and control The usercan direct her attention to the machine anddoes not have to look at the manual.
Aswe noted in when one goes from written toaural presentation, one gains the advantagethat the user has free hands and eyes but ifnothing more is done this advantage has tobe weighted against the disadvantage thatthe user looses all control over the orderand the speed with which the informationis presented.
We can avoid these draw-backs by allowing some limited groundingbehaviour.
Very simple interactions like'done' (Confirm) or 'don't understand'(RequestRepeat)  give back to the user alimited control over the speed and the orderof the presentation (at least up to allowingrepetition): the user decides when to moveon to the next action, by confirming that theprevious action is done, and by 'don't under-stand' she can indicate that she would wanta repetition of what was said immediatelybefore.
Here we see how to take advantageof the advantages of a different mode ofpresentation (written versus aural) we alsohave to change the type of interactivity.S: Has the carriage moved from the centerposition?U: I didn't understandS: Has the carriage moved from the centerposition?Avoid irrelevant informat ion When theaction to be taken depends on a condition,the system does not give irrelevant informa-tion.S: Has the carriage moved from the centerposition?U: yesS: The print head is now installedBecause there is no feedback from the user,a manual has always to give all the possibili-ties regardless of which one actually pertains.The possibility to ask yes/no questions allowsus to do away with this redundancy.5.4 More complex task plansIn the example above we illustrated how asimple task plan can give rise to a dialogueand a monologue rendering.
We can get someadded flexibility by giving more structure tothe task plan.
For instance in the exampleabove, one can argue that the reiustallationproper of the print head is described in point1 to 2 and that 3 and 4 describe termination117NAME reinstall(print head)PRE movcxLforward(cartiage lock)DEC\[ secu.
?
(prkR._h(~d~ \[cl t ?
cv-- t o e op=I press_and_release(yellow_button 1yes ?
noV'Y--~-(moved_from_cent e_____r(prin~head)__/~!
I I/ " >~? '
JEFF reinstallcxl(prim head)NAME secure(print:head)PREDECI line_up(hole, post)I push(leveO I6EFF secured(printhead)I \[ action~ \ ]  complex action / planfinal stateFigure 4: Revised Task Planconditions.
To reflect this we can revise thetask plan as follows:With this structure the user can controlthe level of detail of the instructions given.If the user does not know how to performa substep, she can ask the system for moredetailed instructions.U: done, aud now?S: Close the top coverIf the user manages to complete the wholeaction sequence without instructions, he cantell the system this and the system proceedsto the next relevant action.S: put the print head in placeU: how?S: Line up the hole in the print head withthe green post on the printer carriageU: r ight ,  okS: Lower the print head down gently intopositionU: okS: Gently push the green car t r idge  lock leverup unt i l  i t  snaps into p laceU: okS: The pr in t  head is  now secure ly  in p laceOn the other hand, if the user alreadyknows how to perform a substep, the systemmoves on to the next step.S: put the print head in placeS: put the print head in placeU: how?S: Line up the hole in the print head withthe green post on the printer carriageU: r ight ,  doneS: Lower the pr in t  head down gent ly  in topositionU: done, I remember now (pause) the printhead is put in placeS: Ok. Close the top coverHere, however, we see the importance ofthe task structure.
It is only if we have in-formation that gives the structure of the taskwith subtasks that we can model this.
Veryoften instructional manuals will give this sub-structure, e.g.
in the form of subdivisions ofinstructions, but they tend not to be corn-118pletely consistent in this.
It is only when thisinformation is given in a consistent way thatwe can exploit it in a transformation from awritten manual presentation to a more inter-active presentation.6 D iscuss ion  and  Research  I ssuesIn this experiment we have looked at a fewdifferences that occur in the rendering of thesame information under different conditionsof interactivity.
Our little experiment broughtout several differences in the 'rendering' of thesame task plan as a written text and as a min-imally interactive dialogue.?
Conditionals and preconditions are han-dled differently if limited confirmationsare possible.?
The flexibility of access that written textallows needs to be modeled more explic-itly in case of aural presentation.
Thiscan be done minimally by allowing themachine to interpret 'done' or 'don't un-derstand' as moves that lead to the pre-sentation of the next instruction or to arepetition of the latest instruction.Moreover the granularity with which thetask plan is represented corresponds to thegranularity of the control the user has overthe presentations of the instructions.
In thisexample we started from an existing manualtext.
Starting from a written manual helpedus understand the importance of the informa-tion about the task structure.
This comes ofcourse not as a surprise: when the presenta-tion mode is fixed as non-interactive, the thediscourse structure can be very 'fiat': thingsneed to be done in a certain order whetherthey are parts of subtasks or not is not rel-evant.
It can be argued that giving morestructure will help a user understand betterwhat the instructions achieve but it will notinfluence the execution directly.
Material thathelps the user understand why she is doingsomething is typically given in introductorysections and not in the procedures themselvesin this type of manual.
But to make doc-ument transformations possible in the sensedescribed in the beginning, it is important oclearly separate task plans and assumptionsabout interactions, i.e.
about how the infor-mation states get updated.
4Once the task plan is distinguished from thedialogue plan, assumptions about the type ofinteractions between participants can changethe dialogue plan even when the task planremains constant.In practice a completely automatic trans-formation of a written manual into even lim-ited dialogue is most likely not possible, al-though one can isolate several inguistic flagsfor some of the aspects we have been dis-cussing (e.g.
expressions like "make surethat..." flag preconditions).
A more realisticapproach would be to create a blueprint doc-ument that is marked up to allow the deriva-tion of several different types of discoursefrom the beginning on.
Such an enterprisewould need tools such as the TRINDIKIT tomodel the various cases 5So far, we have only explored one extremeof the monologue-dialogue opposition wherethe interactivity stays very low.
Obvious ex-tensions are to allow the user to ask informa-tion that goes beyond the current procedure,e.g.
'where can i find the piece you mention'or 'how long does this take: i have only 1/2hour here'.
Further inquiry into the possibleinteractions will help us to define which infor-mation is needed and how it needs to be struc-tured to fulfill these various needs.
And ofcourse we will never reach a system in whichevery user need can be anticipated but theneven human beings are not that type of sys-tem.4See (Grosz and Sidner, 1986) for a discussion ofthe importance oftask plans in more explanatory di-alogue.5It would also need tools that make it easy to modelthe relation between the linguistic expressions used inthe various renderings of the base document.
One cansee this task as akin to that of multilingual genera-tion or even simple document rendering.
Formal ap-proaches used for those tasks could be adapted to suchan enterprise.
XML supplemented with stylesheetsand schemata could be another possibility.119ReferencesP.
Bohlin, R. Cooper, E. Engdahl, and S. Larsson.1999.
Information states and dialogue moveengines.
In J. Alexandersson, editor, IJCAI-99 Workshop on Knowled9e and Reasonin 9 inPractical Dialogue Systems.L.
Carlson.
1983.
Dialogue Games.
D. Reidel,Dordrecht.Jennifer Chu-Carroll and Michael K. Brown.1998.
An evidential model for tracking initia-tive in collaborative dialogue interactions.
UserModeling and User-Adapted Interaction, specialissue on Computational Models of Mized Initia-tive Interaction, 8(3+4):215-253.H.
Clark.
1999.
How do real people communicatewith virtual partners?
Proceedings of AAAI-99 Fall Symposium, Pshychological Models ofCommunication i  Collaborative Systems.J.
Ginzburg.
1998.
Clarifying utterances.
InJ.
Hulstijn and A. Niholt, editors, Proc.
ofthe Twente Workshop on the .Formal Seman-tics and Pragmatics of Dialogues, pages 11-30,Enschede.
Universiteit Twente, Faculteit Infor-matica.B.
J. Grosz and C. L. Sidner.
1986.
Atten-tion, intention, and the structure of discourse.12(3):175-204.Staffan Larsson and David Traum.
To appear.Information state and dialogue management inthe trindi dialogue move engine toolkit.
NLESpecial Issue on Best Practice in Spoken Lan-guage Dialogue Systems Engineering.Staffan Larsson, Alexander Berman, Johan Bos,Leif GrSnqvist, Peter Ljunglbf, and DavidTraum.
2000.
Trindikit 2.0 manual.
Techni-cal Report Deliverable D5.3 - Manual, Trindi.D.
Traum, J. Bos, R. Cooper, S. Larsson, I.Lewin,C.
Matheson, and M. Poesio.
1999.
A model ofdialogue moves and irfformation state revision.deliverable D2.1, TRINDI.Jan van Kuppevelt.
1995.
Discourse structure,topicality and questioning.
Journal of Linguis-tics, 31:109-147.120
