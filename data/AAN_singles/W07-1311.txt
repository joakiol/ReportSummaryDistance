Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 84?92,Prague, June 2007. c?2007 Association for Computational LinguisticsVisualizing the evaluation of distance measuresThomas PilzUniversity of Duisburg-EssenFaculty of EngineeringDepartment of Computer Sciencepilz@inf.uni-due.deAxel PhilipsenburgUniversity of Duisburg-Essenaxel.philipsenburg@uni-due.deWolfram LutherUniversity of Duisburg-EssenFaculty of EngineeringDepartment of Computer Scienceluther@inf.uni-due.deAbstractThis paper describes the development anduse of an interface for visually evaluatingdistance measures.
The combination ofmultidimensional scaling plots, histogramsand tables allows for different stages ofoverview and detail.
The interdisciplinaryproject Rule-based search in text databaseswith nonstandard orthography develops afuzzy full text search engine and uses dis-tance measures for historical text documentretrieval.
This engine should provide easiertext access for experts as well as interestedamateurs.1 IntroductionIn recent years interest in historical digitizationprojects has markedly increased, bearing witness toa growing desire to preserve cultural heritagethrough new media.
All over Europe projects arearising digitizing not only monetary but also intel-lectually valuable text documents.
While more andmore documents are being digitized and often pro-vided with well designed interfaces, they are notnecessarily easy to work with, especially fornonlinguists.
Spelling variants, faulty characterrecognition (OCR) and typing errors hamper if notcircumvent sensible utilization of the data.
Onesuch example is the archive of Jewish periodicalsin German language, Compact Memory(www.compactmemory.de).
Even though of greatcultural value and very well maintained, the opera-tors of this project simply did not have the re-sources required to postprocess or annotate theirautomatically recognized text documents.
A userfor example searching for the word ?Fruchtbarkeit?
(=fertility) will not be able to find a certain peri-odical from 1904 even though it clearly containsthe word.
Worse, he will not even come to knowthat this text was missed.
Because the full textaligned with the graphical representation of thetext contains recognition errors, only the search forthe misspelled word ?Piuchtbaikeit?
instead of?Fruchtbarkeit?
finds the correct page (cf.
Figure1).
The same problem arises when dealing withhistorical spelling variation.
German texts prior to1901 often contain historical spelling variants.Numerous projects are dealing with similar prob-lems of optical character recognition or spellingvariation.To meet those problems linguistics and com-puter science are closing ranks.
Fuzzy full-textsearch functions provide access to nonstandard textdatabases.
Since the amount of data on the onehand and the divergence of users on the other in-creases day by day, search methods are continu-ously presented with new challenges.
The projectRSNSR (Rule-based search in text databases withFigure 1.
OCR errors prevent successful retrieval on digitized texts if misspelled variants are used for fulltext search.84nonstandard orthography) seeks to improve theretrieval of nonstandard texts.
Such texts mightinclude historical documents, texts with re-gional/dialectal or phonetic variation, typos orOCR errors.
The project?s funding by the DeutscheForschungsgemeinschaft (DFG [German ResearchFoundation]) was recently extended by two years.2 Comparing similarity measuresOne of the important issues in building a searchengine for nonstandard spellings is a reliable wayto allow the comparison of words, that is, to meas-ure the similarity between the search expressionand the results provided.
Given the abundance ofdistance measures and edit-distances available,methods are needed for efficiently comparing dif-ferent similarity measures.
In (Kempken et al2006) we evaluated 13 different measures with thecalculation of precision and recall to determinewhich were most qualified to deal with historicalGerman spelling variants.
We mainly used our owndatabase of historical spellings, manually collectedfrom the German text archives Bibliotheca Augus-tana, documentArchiv.de and Digitales ArchivHessen-Darmstadt.
Currently our database consistsof 12,687 modern-historical word pairs (that wecall evidences) originating between 1293 and 1919.The algorithm that proved best for calculatingthe edit costs between the modern and the histori-cal spellings is called Stochastic distance (SM) andwas originally proposed in 1975 by Bahl andJelinek.
In 1997 Ristad and Yianilos (Ristad et al1997) took it up again and extended the approachto machine learning abilities.
Due to the complex-ity of language, apparently similar scopes can ob-viously favor totally different mechanisms.
TheVariant Detector VARD developed by Rayson etal.
to detect spelling variants in historical Englishtexts uses the standard Soundex algorithm withconvincing efficiency (Rayson et al 2005).
Thesame algorithm yields an error rate 6.7 timeshigher than the stochastic distance for the compari-son of German spelling variants.
Cases like thesesuggest that finding one ?most suitable?
distancemeasure for all data might not be possible.
As soonas the inherent structures change, another measurecan prove to be more efficient.
Even though, withthe SM, we already found a suitable measure, itsdependency on the underlying training data forcesus to evaluate the training results: what is the sizeof an optimal training set?
Is the training set wellchosen?
Does 14th-century data appropriately rep-resent 13th-century spellings?
Answers to these andsimilar questions not only help to ensure betterretrieval but can also give an insight into phoneticor graphematic changes of language.
Since stan-dard calculations of retrieval quality, as we did forthe 13 measures, require not only extensive workbut are also difficult to evaluate, we propose possi-bilities for visual evaluation means to speed up andease this process.
The prototype we developed isbut one example for those possibilities and ismeant to encourage scientists to benefit from vis-ual information representation.3 Development and functions of an inter-active visual interfaceSince our project already deals with differentmethods for calculating word distance, the defini-tion of a generic interface was necessary.
Prioritywas given to the development of a slim and easilyaccessible device that allows the connection of ar-bitrary concepts of word distance.
Our SM, a rulebased measure using regular expressions, Soundex(Knuth, 1973), Jaro(-Winkler) (Jaro, 1995) and anumber of additional measures are already imple-mented in our system.
It was built in Java and isembedded in our general environment for the proc-essing of nonstandard spellings.Information Visualization is a fairly new field ofresearch that is rapidly evolving.
A well estab-lished definition of information visualization is?the use of computer-supported, interactive, visualrepresentations of abstract data to amplify cogni-tion?
(Card et al 1999).
While planning the proto-type, we also kept Shneiderman?s paradigm inmind: ?Overview first, zoom and filter details ondemand?
(Shneiderman, 1996).
In dealing withdistance measures, our main task is to representword distance.
We employed multidimensionalscaling (MDS) to display abstract distance in 2Dspace (see below).
Interactivity is gained with theability to select and remove spellings from the cal-culations, lower or raise cutoff frequencies andfilters and even change replacement costs with in-stantaneous effect (see below).
This led to a userinterface separated into three main views:?
The Histogram allows an overview ofthousands of data items.
The selection of a85certain portion of data triggers MDS and ta-ble views.?
Multidimensional Scaling (MDS) func-tions as a detail view.
Such visualization isused to display sets of several dozen to afew hundred items.?
The Table View can display different lev-els of detail.
In (Kempken et al 2007) wepresented a TreeMap approach, another wayto display details of single word derivationsas an add-on for table views.3.1 HistogramsHistograms are a widely spread tool for display ofstatistical distribution of values.
In favor of Shnei-derman?s paradigm, the histogram view representsa combination of overview and zoom functionality.This first stage allows for the reduction of the dataset from up to several thousand items down tomuch more manageable sizes.To get a first impression of how a spelling dis-tance performs on a set of evidences, we calculatethe distance between a spelling variant and the en-tries in a dictionary.
It is ensured that the collectionalso contains the standard spelling related to thevariant.
The results are sorted in ascending orderby their distance from the spelling variant.
After-wards, the rank of the corresponding spellings isdetermined.
In the best case, the correct relationwill appear as the first entry in this list, that is, atthe smallest distance from the variant.
Often, otherspellings appear ?closer?
to the variant and thushave a higher rank, pushing the spelling we soughtfor further down the list (cf.
Figure 2).By applying this procedure to a collection ofword pairs, we get a distribution of spelling ranksover the set of evidences based on the spelling col-lection.
Good distance measures produce a histo-gram with most of its largest bars close to the firstrank on the left.
A good example is the evaluationin section 5 (cf.
Figure 5).The histogram provides a good representation ofthe overall performance of a spelling distancegiven for a set of test data.
The user will quicklynotice if a large number of spellings are found inthe acceptable ranking range, if there are notice-able isolated outliers or if the values are spreadwidely over the whole interval.
In addition, histo-grams can be useful as tools for comparing differ-ent spelling distances.
Usually multiple histogramsare viewed one after another or arranged next toeach other.
While this might be enough to perceiveconsiderable differences in distributions, small-scale variations may pass unnoticed.
An easy solu-tion to this problem is to arrange the different his-tograms in a combined display area, where therelevant subinterval bars are lined up next to oneanother and made distinguishable by color or tex-ture.
Through this simple rearrangement, evensmall changes become noticeable to the user.Slight height differences between bars of the samevalue interval can be noticed as can shifts in peaksalong the value range.For more quantitative performance measurementmean value and standard deviation are calculatedand presented in numerical form.
A distance defi-nition that performs well will have a low meanvalue as more spellings are found with a goodranking.
However, a mean value that is not espe-cially high or low by itself is usually not enough tocharacterize a distribution.
For this reason, it isimportant to know the values?
spread around thedistribution?s mean value measured by the standarddeviation (SD).
A distribution with only a few,tightly packed value peaks provides a small SDwhereas a widely spread one will have a large SD.A spelling distance that performs well can be rec-ognized by a low mean value accompanied by alow SD.
Both key values can also be made visiblein a histogram by drawing markers in its back-ground.
In this way, even the key values are easyto compare when comparing spelling distances.3.2 Multidimensional scalingThe MDS view displays smaller subsets, thus al-lowing further refinement while providing addi-tional information detail.Figure 2.
The standard spelling "liebe" corre-sponding to variant "liebd" was pushed backby "lieb" because deletion of <d> is cheaperthan the replacement of <d> with <e>.86MDS is a class of statistical methods that has itsroots in psychological research.
The main applica-tion of such techniques is to assign the elements ofan item set to a spatial configuration in such a waythat it represents the elements?
relationships withas little distortion as possible.
In this context, MDScan be used to arrange spellings in a two-dimensional space according to their spelling dis-tances from one another.
Every available dimen-sion reduces the need for distortion but increasesthe difficulty to interpret.
Two or three dimensionsare a good trade-off.
This allows for an intuitivedisplay of distances and clusters of spelling vari-ants.
It also makes it possible to discover distanceanomalies.
If this representation is provided withfiltering features, it can be used to select subsets ofelements quickly and comfortably.
These subsetscan then be displayed in detailed informationviews that would be too cluttered with greaternumbers of items.The ?distortion?
is evaluated by comparing thedistances calculated by the spelling distances withthe configuration?s geometric distances (i.e.
dis-tances following geometric rules).
A common cal-culation for this distortion is the so-called ?rawstress?
factor.
Kruskal (Kruskal, 1964) defined rawstress as the sum of distance errors over a configu-ration.
To calculate this error, we use the distancematrix D, where each entry holds the calculateddistance ?ij between the spellings of the relevantrow and column.
These values can be modified byf(?ij)=a ?ij to achieve a scaling more fit for visualdistances, thus reducing stress.
Comparison withgeometric distances also requires this matrix to besymmetric.
Because spelling distances are not nec-essarily symmetric (distance A ?
B differs from B?
A), we use the mean value of both distance direc-tions to create symmetry, as Kruskal suggests.
Thesecond part of the error calculation requires thegeometric distances dij between the spellings,which is determined by i and j of the current con-figuration X.
The actual error is the difference be-tween the two distances squared.2)()( ??????
?= Xijdijfije ?Figure 3.
The user interface of the Metric Evaluation Tool showing the evaluation of six metricstrained on different historical training sets, polygon selection in the MDS view and cut-off sliders.87Kruskal?s ?raw stress?
value is then determinedby summarizing the error over the elements of theupper triangular matrix.
The sum can be restrictedto this reduced element set due to the symmetricnature of the matrix.
[ ]?<?=)(2)()()(jiijijr XdfX ?
?In our Metric Evaluation Tool (MET) we used theSMACOF algorithm (see below) to calculate astress-minimizing configuration.
Finding such aconfiguration is a numerical optimization problem.Because a direct solution of such a problem is of-ten not feasible, numerous iterative algorithmshave been developed to calculate an approximatesolution close enough to the direct solution, whereone actually exists.
The SMACOF algorithm (scal-ing by majorizing a complicated function) is suchan approach (De Leeuw, 1977).
We start by ar-ranging the items in a checkerboard grid configura-tion.
The algorithm then calculates the raw stress,modifies the current configuration so that it yieldsa lesser stress value by applying a Guttman Trans-formation (Guttman, 1968) and then compares thenew configuration?s stress with the old one.
Thisstep is repeated until the change in stress dropsbelow a set threshold or a maximum number ofiteration steps is exceeded.The resulting configuration is usually not an op-timal one.
Optimal in this case would be a distor-tionless representation with vanishing stress value.Such a configuration is rarely, if ever, achieved inMDS.
There are three main reasons for this:?
Some calculated spelling distances canconflict such that there is no spatial configu-ration that represents the distances withoutdistortion.
For example, a spelling may bedetermined to be close to several other spell-ings, which, however, are widely spread out.This is due to the fact that spelling distancesdo not always fulfill the triangle inequality.?
Although geometric distances, beingmathematical metrics, require the spellingdistances to be symmetric, the spelling dis-tances calculated will not necessarily be so.For instance, the distance between spellingsA and B could be different from that be-tween spellings B and A.?
Even if an optimal configuration were toexist, the iterative optimization processmight not actually find it.
The algorithmmight terminate due to iteration limits or be-cause of being ?trapped?
in a local mini-mum.This restriction on the MDS result, however, isnot severe enough to derogate its usage as a visu-alization tool.
Its task is not to reconstruct the cal-culated distance perfectly but to uncover character-istics of the spelling distances and spelling setsused.
These characteristics, such as clusters andoutliers, usually outweigh the distortions.
Appliedto a set of spellings and their distance measure,MDS generates a spatial configuration fit for a plotview.
The spellings?
positions in relation to oneanother represent their similarity.
Clusters ofclosely related spellings and outliers are easy torecognize and can be used as starting points fordetailed analyses of subsets.An advantage of this type of visualization is thatit considers the calculated distances among allspellings instead of only two.
An initial compari-son of the difference or similarity of multiple spell-ings is possible at a single glance and withoutswitching between different views.
Additional vis-ual hints can improve the overview even further.Certain spellings, such as the standard spelling orthe variant, can be made easily recognizablethrough color or shape indications.
The selection ofsubsets is aided by zoom and filtering features ap-plied to the plot view.
Densely packed clusters canbe made less cluttered by changing the plot?s zoomfactor or by blending irrelevant items into thebackground.
Selecting the spellings by either click-ing or encircling allows the subsets to be deter-mined easily.
The reduced item set can then beused for a detail view, for example the display ofoperations and distances like the tabular view.
Inthe MET, the components used to calculate a dis-tance for a given subset can be viewed.
In this way,it is easy to understand, for example, why a certainspelling is not as ?close?
to another spelling as ex-pected.This visualization approach is applicable to awide variety of spelling distances as long as theyprovide a quantitative measurement of two spell-ings.
There are no assumptions made about thedistance value except that small values represent ahigh degree of similarity.883.3 Tabular viewsAfter refining the selections from several thousanddown to a few items, a detailed display of relevantinformation about the spellings and their calculateddistances is needed.
At this stage the actual valuesare more important than a visually comprehensibledisplay of relations.Two different views in the MET use a tabular ar-rangement of values.
One represents the distancematrix between a set of spellings, similar to the oneused to calculate the MDS solution.
However, inthis case, the distances are not combined to a meanvalue for both directions.
At this point the differ-ence between the two directions can be of interestand should be visible.
Standard spelling and spell-ing variant are displayed in different colors so theycan be found more easily.The second tabular view displays the distancesbetween the standard spelling and the ranked vari-ants.
To obtain a better understanding, the resultsare split up into their components using a Leven-shtein-based distance mirroring the replacementcosts that occurred when transforming one spellinginto the other.
These components are displayed inthe rows according to their classification, while thedifferent spelling variants appear in the columns(cf.
Figure 4).
By reordering the columns, the usercan move the spellings next to each other in orderto compare them more closely.Another benefit of representing the values in thisway is that detailed modifications to the spellingdistance can be made interactively.
Here, the re-placement costs can be changed inside the tableitself, allowing an instant evaluation on what effectsuch a change will have on the distance measure.4 InteractionThere are several ways to interact with the applica-tion.
Selection of data triggers an update of theview(s) on the next level of detail: by selectingcolumns of the histogram, the ranking table is acti-vated; selecting spellings in the ranking table trig-gers the MDS view where spellings can be selectedto be shown in the distance matrix and metric edi-tor.
While selections in the tabular views and thehistogram can easily be performed with a rectangu-lar selection box, the MDS needed a more elabo-rate way of selecting data.
A polygonal form canbe drawn with the mouse that also allows invertedselection (cf.
Figure 3).
Using two sliders or nu-merical input, the upper and lower cut-off for se-lection can be defined.
For example, all spellingswith a distance higher than 2.5 to the search termcan be excluded (cf.
right side of Figure 3).
Zoom-ing can be performed using the mouse wheel.
Inthe metric editor, showing the highest degree ofdetail, the costs for the operations of deletion, in-sertion and replacement can be adjusted.
Thesechanges are instantly represented in the MDS view,therefore allowing for the manual calibration of thedistance measures (cf.
Figure 4).5 Exemplary application of the interfaceTo give an example of our MET, we will apply itto a situation we have encountered more than oncein the last two years of our research: a set of his-torical German text documents T from between1500 and 1600 which contains nonstandard spell-ings.
As shown in (Kempken, 2006), the number ofspelling variants in old documents is monotoni-cally nondecreasing with advancing age.
T mightalso contain errors originating from bad OCR orobsolete characters.
Nonetheless, we want to beable to perform retrieval on the document.
Tosimulate a successful full-text search, we manuallycollected all 1,165 spelling variants V in T andaligned them with their equivalent standard spell-ings S. We will call those word pairs evidences.
Sis now merged into a contemporary dictionary?the OpenOffice German dictionary, which containsapproximately 80,000 words.
For a reliable evalua-tion we need a high quality dictionary without ty-pos or historical spellings.
The OO-dictionary isthe best such wordlist available to us.
Our algo-rithm is able to process dictionaries of up to ~5Figure 4.
Table view of replacement costs mirroring deletion, insertion and replacement costs.
These costscan be manually adjusted to trigger an MDS view update.89million words.
Bigger dictionaries can be kept in adatabase instead of the computer?s main memory.We used the MET applied with six different dis-tance measures to determine the one that worksbest in finding all the standard spellings S ?hidden?in the dictionary related to the spelling variants V.A normal search task in a historical database wouldbe to find a spelling variant by querying a standardspelling.
Because a coherent wordlist of historicalspellings was not available, to ensure a more reli-able result, we performed the task the other wayaround.
This conforms to the way automatic anno-tators like VARD work (see above).Such experiments can be used not only to findthe best metric but also to answer general ques-tions:?
Will an SM specifically trained on datafrom the same time period as T work best orwill the extension of the time period loweror raise the retrieval quality??
Is there a level where a ?saturation?
oftraining data is reached and the measures?quality cannot be enhanced any further??
Does the amount of necessary training datavary with the time/location of T?For our first experiment the six measures M1,M2?M6 were trained by the same number of evi-dences from 14th- to 19th-century German texts.Prior to the training, the evidences had been dia-chronically clustered (1300-1500, 1300-1700,1300-1900, 1500-1700, 1500-1900, 1700-1900)into sets, each containing 1,500 word pairs.
In gen-eral, performance is measured in precision (propor-tion of retrieved and relevant documents to alldocuments retrieved) and recall (proportion of re-trieved and relevant documents to all relevantdocuments).
Since we ensured that for every his-torical spelling there is a standard spelling, re-trieved and relevant documents are equal and soare precision and recall.
We therefore use precisionat n (P@n).
This measure is often used in caseswhere instead of boolean retrieval a ranking ofdocuments is returned, for example in web-retrieval.
Precision at 10 is the precision that rele-vant documents are retrieved within the 10 docu-ments with the highest ranking.
In standard settingsthe MET is using n?15.The task of our prototype now was?
to determine the metric most suitable forthe retrieval task, and?
to figure out deficiencies in the metrics tofurther enhance their quality.DMV SD1300?1500 1.37 3.1741300?1700 1.384 3.2221300?1900 1.261 2.9831500?1700 1.375 3.18251500?1900 1.29 3.0521700?1900 1.43 3.342Table 1.
Distribution mean value and standard de-viation of the evaluated measuresLooking at P@1 the measures 1300-1500 (58.6%),1300-1700 (58.7%), 1500-1700 (59.1%) and 1700-1900 (59.4%) seem to be more or less equally effi-cient.
However, by looking at Table 1 we can seethat this assumption is not totally correct.
Themeasure trained on evidences from 1700 to 1900holds a slightly higher distribution mean value andstandard deviation than the other two.
Interestinglythe 1500-1700 measure is not the most efficientone.
1300-1900 and 1500-1900 show better resultsin P@1, DMV and SD.
Even though the inclusionof 1300-1500 evidences seems to be of minor sig-nificance, the 1300-1900 measure is still slightlybetter (60.5% P@1).
Those results are ?
of course ?not significant because of the small dictionary weused.
We hope to acquire a bigger freely availabledictionary for more expressive results.The ranking table is now able to show the actualwords that led to the result, therefore supportingthe expert in further interpretations.
The MDS plotand distance matrix let the user explore the wordsat each rank interactively.
Especially interestingare, of course, those words that could not be foundwithin the top 15 ranks.
The 1500-1900 and 1700-1900 measures have some difficulties with elderspellings (e.g.
sammatin [=velvety]).
It is also evi-dent that many of the 3.9% of words > P@10 sharecertain characteristics:90?
a lot of words are short in length (e.g.
vmb,nit, het, eer).
Even a single letter replace-ment changes a high percentage of theword?s recognizability?
some words consist of very frequentgraphemes, therefore increasing the space ofpotential matches in standard spelling (e.g.hendlen ?
enden, handeln, hehlen ?)?
some evidences feature high variability(e.g.
ewig ?
eehefig)Those cases complicate successful retrieval.Comparing the replacement costs in the metriceditor (cf.
Figure 4) indicates where the SM needsimprovement.
In our example we noticed that thecosts for the replacement of <s> with the Germaness-tset <?> were a little too high, and thereforespellings were not optimally retrieved.
A slightmanual correction, a control in the MDS view anda recalculation of the histogram showed improvedquality of the SM.Further experiments suggested a ?training satu-ration?
(see above) of about 4,000 variants.
Wetrained M1 on 1,500 evidences from 1300-1900,M2 on 4,000, M3 on 6,000 and M4 on 12,000.While M1 still shows a small drop in retrieval qual-ity, the differences between M2 to M4  are almostunnoticeable.
We also performed a cross-languageevaluation between historical English and Germanas we already did manually in (Archer et al 2006).Our prior results could be confirmed using theMET.For the comparison of truly different distancemeasures, as we did in (Kempken, 2006), we usedthe same data as above with our SM 1300-1900,Jaro metric (Jaro, 1995) and a standard bigrammeasure (cf.
Figure 5).
The histogram values ofp@<4 for the SM (86.6%) are already 9.2% betterthan Jaro (77.4%) and 9.9% better than the bigrammeasure (76.7%).
DMV and SD also show howmuch better the SM performed (cf.
Table 2).DMV SDSM 1300-1900 1.604 3.73Jaro 2.731 5.124Bigrams 2.533 4.754Table 2.
DMV and SD comparison of SM, Jaro-Winkler and bigram measure.6 Conclusion and outlookWhile table views will probably not become obso-lete any time soon, there are multiple ways to easeand enhance the understanding of abstract data.
Ithas already been documented that users often pre-fer visual data representations when dealing withcomplex problems (Kempken, 2007).In this paper we presented the prototype of ourMetric Evaluation Tool and showed that this soft-ware is helpful in the evaluation of distance meas-ures.
The combination of overview, details andinteractivity eases the complex task of determiningquality problem-specific distance measures.Because the MET is a prototype, there is roomfor improvement.
The graphical MDS displaycould be extended in various ways to further im-prove the configuration found.
Displaying the nu-merical distance values between spellings as atooltip or graphical overlay, group highlighting andinteractive insertion or removal of additional spell-ing variants are just a few examples.
The bar chartsof the histogram view could easily be extendedusing pixel-matrix displays as proposed by (Hao etal, 2007) to conveniently represent additional in-formation like the distribution of distance ranges.The MET is only one of the visualization toolswe are working on at the moment.
No single appli-cation will be able to satisfy all the many and vari-ous needs that arise in the field of language re-search.
It is our goal to build applications that ac-cess and reflect spelling variation in a more naturaland intuitive manner.
To narrow the field of poten-tially suitable distance measures, we are also work-ing on automatic text classification.
The Word-Figure 5.
Histogram and DMV comparison of Jaro metric, standard bigram measure and SM 1300-1900.91Explorer, for instance, is an additional approach topresenting details.
Similar to the MDS view in ap-pearance, it is used to further examine words?
pos-sible spelling variants, the graphematic space ofsolution (Neef, 2005).
Based on the renowned Pre-fuse-package for Java (prefuse.org), it providesmethods that support easy access and usability,including fisheye, zoom and context menus.7 AcknowledgementsWe would like to thank the Deutsche For-schungsgemeinschaft for supporting this researchand our anonymous reviewers whose detailed andhelpful reports have helped us to improve this pa-per.ReferencesArcher D, Ernst-Gerlach A, Pilz T, Rayson P (2006).The Identification of Spelling Variants in English andGerman Historical Texts: Manual or Automatic?.Proceedings Digital Humanities 2006, July 5-9 2006,Paris, FranceCard S K, Mackinlay J D, Shneiderman B (1999).
Read-ings in Information Visualization; Using Vision tothink.
Morgan Kaufman, Los Altos, CaliforniaDe Leeuw J (1977).
Applications of convex analysis tomultidimensional scalingGuttman L (1968).
A general nonmetric technique forfinding the smallest coordinate space for a configura-tion of points, PsychometrikaHao M C, Dayal U, Keim D, Schreck T (2007).
A visualanalysis of multi-attribute data using pixel matrixdisplays.
Proceedings Visualization and Data Analy-sis (EI 108), Jan 29-30 2007, San Jose, CaliforniaJaro M A (1995) Probabilistic linkage of large publichealth data file.
In: Statistics in Medicine 14, pp.491-498Kempken S, Luther W, Pilz T (2006).
Comparison ofdistance measures for historical spelling variants.Proceedings IFIP AI 2006, Sep 8-12 2006, Santiago,ChileKempken S, Pilz T, Luther W (2007).
Visualization ofrule productivity in deriving nonstandard spellings.Proceedings Visualization and Data Analysis (EI108), Jan 29-30 2007, San Jose, CaliforniaKnuth D (1973).
The Art Of Computer Programming.vol 3: Sorting and Searching, Addison-Wesley, pp.391-392Kruskal J B (1964).
Multidimensional scaling by good-ness-of-fit to a nonmetric hypothesis, Psychometrika,29:1-27Neef M (2005).
Die Graphematik des Deutschen.
Nie-meyer, T?bingen, GermanyRayson P, Archer D, Smith N (2005).
VARD versusWord: A comparison of the UCREL variant detectorand modern spell checkers on English historical cor-pora.
Proceedings of Corpus Linguistics 2005, July14-17 2005, Birmingham, UK.Ristad E; Yianilos P (1997).
Learning string edit dis-tance.
Proceedings of the Fourteenth InternationalConference, July 8-11 1997, San Francisco, Califor-niaShneiderman B (1996).
The eyes have it: A task by datatype taxonomy for information visualization.
Pro-ceedings Symposium of Visual Languages, Sep 3-61996, Boulder, Colorado92
