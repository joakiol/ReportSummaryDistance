Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 151?160,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsTarget-dependent Twitter Sentiment ClassificationLong Jiang1   Mo Yu2   Ming Zhou1   Xiaohua Liu1   Tiejun Zhao21 Microsoft Research Asia 2 School of Computer Science & TechnologyBeijing, China Harbin Institute of TechnologyHarbin, China{longj,mingzhou,xiaoliu}@microsoft.com {yumo,tjzhao}@mtlab.hit.edu.cnAbstractSentiment analysis on Twitter data has attract-ed much attention recently.
In this paper, wefocus on target-dependent Twitter sentimentclassification; namely, given a query, we clas-sify the sentiments of the tweets as positive,negative or neutral according to whether theycontain positive, negative or neutral senti-ments about that query.
Here the query servesas the target of the sentiments.
The state-of-the-art approaches for solving this problemalways adopt the target-independent strategy,which may assign irrelevant sentiments to thegiven target.
Moreover, the state-of-the-artapproaches only take the tweet to be classifiedinto consideration when classifying the senti-ment; they ignore its context (i.e., relatedtweets).
However, because tweets are usuallyshort and more ambiguous, sometimes it is notenough to consider only the current tweet forsentiment classification.
In this paper, we pro-pose to improve target-dependent Twitter sen-timent classification by 1) incorporatingtarget-dependent features; and 2) taking relat-ed tweets into consideration.
According to theexperimental results, our approach greatly im-proves the performance of target-dependentsentiment classification.1 IntroductionTwitter, as a micro-blogging system, allows usersto publish tweets of up to 140 characters in lengthto tell others what they are doing, what they arethinking, or what is happening around them.
Overthe past few years, Twitter has become very popu-lar.
According to the latest Twitter entry in Wik-ipedia, the number of Twitter users has climbed to190 million and the number of tweets published onTwitter every day is over 65 million1.As a result of the rapidly increasing number oftweets, mining people?s sentiments expressed intweets has attracted more and more attention.
Infact, there are already many web sites built on theInternet providing a Twitter sentiment search ser-vice, such as Tweetfeel2 , Twendz3 , and TwitterSentiment4.
In those web sites, the user can input asentiment target as a query, and search for tweetscontaining positive or negative sentiments towardsthe target.
The problem needing to be addressedcan be formally named as Target-dependent Sen-timent Classification of Tweets; namely, given aquery, classifying the sentiments of the tweets aspositive, negative or neutral according to whetherthey contain positive, negative or neutral senti-ments about that query.
Here the query serves asthe target of the sentiments.The state-of-the-art approaches for solving thisproblem, such as (Go et al, 20095; Barbosa andFeng, 2010), basically follow (Pang et al, 2002),who utilize machine learning based classifiers forthe sentiment classification of texts.
However, theirclassifiers actually work in a target-independentway: all the features used in the classifiers are in-dependent of the target, so the sentiment is decidedno matter what the target is.
Since (Pang et al,2002) (or later research on sentiment classification1 http://en.wikipedia.org/wiki/Twitter2 http://www.tweetfeel.com/3 http://twendz.waggeneredstrom.com/4 http://twittersentiment.appspot.com/5 The algorithm used in Twitter Sentiment151of product reviews) aim to classify the polarities ofmovie (or product) reviews and each movie (orproduct) review is assumed to express sentimentsonly about the target movie (or product), it is rea-sonable for them to adopt the target-independentapproach.
However, for target-dependent sentimentclassification of tweets, it is not suitable to exactlyadopt that approach.
Because people may mentionmultiple targets in one tweet or comment on a tar-get in a tweet while saying many other unrelatedthings in the same tweet, target-independent ap-proaches are likely to yield unsatisfactory results:1.
Tweets that do not express any sentimentsto the given target but express sentimentsto other things will be considered as beingopinionated about the target.
For example,the following tweet expresses no sentimentto Bill Gates but is very likely to be classi-fied as positive about Bill Gates by target-independent approaches.
"People everywhere love Windows & vista.Bill Gates"2.
The polarities of some tweets towards thegiven target are misclassified because ofthe interference from sentiments towardsother targets in the tweets.
For example,the following tweet expresses a positivesentiment to Windows 7 and a negativesentiment to Vista.
However, with target-independent sentiment classification, bothof the targets would get positive polarity.
?Windows 7 is much better than Vista!
?In fact, it is easy to find many such cases bylooking at the output of Twitter Sentiment or otherTwitter sentiment analysis web sites.
Based on ourmanual evaluation of Twitter Sentiment output,about 40% of errors are because of this (see Sec-tion 6.1 for more details).In addition, tweets are usually shorter and moreambiguous than other sentiment data commonlyused for sentiment analysis, such as reviews andblogs.
Consequently, it is more difficult to classifythe sentiment of a tweet only based on its content.For instance, for the following tweet, which con-tains only three words, it is difficult for any exist-ing approaches to classify its sentiment correctly.
?First game: Lakers!
?However, relations between individual tweetsare more common than those in other sentimentdata.
We can easily find many related tweets of agiven tweet, such as the tweets published by thesame person, the tweets replying to or replied bythe given tweet, and retweets of the given tweet.These related tweets provide rich informationabout what the given tweet expresses and shoulddefinitely be taken into consideration for classify-ing the sentiment of the given tweet.In this paper, we propose to improve target-dependent sentiment classification of tweets byusing both target-dependent and context-awareapproaches.
Specifically, the target-dependent ap-proach refers to incorporating syntactic featuresgenerated using words syntactically connectedwith the given target in the tweet to decide whetheror not the sentiment is about the given target.
Forinstance, in the second example, using syntacticparsing, we know that ?Windows 7?
is connectedto ?better?
by a copula, while ?Vista?
is connectedto ?better?
by a preposition.
By learning fromtraining data, we can probably predict that ?Win-dows 7?
should get a positive sentiment and?Vista?
should get a negative sentiment.In addition, we also propose to incorporate thecontexts of tweets into classification, which we calla context-aware approach.
By considering the sen-timent labels of the related tweets, we can furtherboost the performance of the sentiment classifica-tion, especially for very short and ambiguoustweets.
For example, in the third example we men-tioned above, if we find that the previous and fol-lowing tweets published by the same person areboth positive about the Lakers, we can confidentlyclassify this tweet as positive.The remainder of this paper is structured as fol-lows.
In Section 2, we briefly summarize relatedwork.
Section 3 gives an overview of our approach.We explain the target-dependent and context-aware approaches in detail in Sections 4 and 5 re-spectively.
Experimental results are reported inSection 6 and Section 7 concludes our work.2 Related WorkIn recent years, sentiment analysis (SA) has be-come a hot topic in the NLP research community.A lot of papers have been published on this topic.1522.1 Target-independent SASpecifically, Turney (2002) proposes an unsuper-vised method for classifying product or movie re-views as positive or negative.
In this method,sentimental phrases are first selected from the re-views according to predefined part-of-speech pat-terns.
Then the semantic orientation score of eachphrase is calculated according to the mutual infor-mation values between the phrase and two prede-fined seed words.
Finally, a review is classifiedbased on the average semantic orientation of thesentimental phrases in the review.In contrast, (Pang et al, 2002) treat the senti-ment classification of movie reviews simply as aspecial case of a topic-based text categorizationproblem and investigate three classification algo-rithms: Naive Bayes, Maximum Entropy, and Sup-port Vector Machines.
According to theexperimental results, machine learning based clas-sifiers outperform the unsupervised approach,where the best performance is achieved by theSVM classifier with unigram presences as features.2.2 Target-dependent SABesides the above mentioned work for target-independent sentiment classification, there are alsoseveral approaches proposed for target-dependentclassification, such as (Nasukawa and Yi, 2003;Hu and Liu, 2004; Ding and Liu, 2007).
(Nasuka-wa and Yi, 2003) adopt a rule based approach,where rules are created by humans for adjectives,verbs, nouns, and so on.
Given a sentiment targetand its context, part-of-speech tagging and de-pendency parsing are first performed on the con-text.
Then predefined rules are matched in thecontext to determine the sentiment about the target.In (Hu and Liu, 2004), opinions are extracted fromproduct reviews, where the features of the productare considered opinion targets.
The sentimentabout each target in each sentence of the review isdetermined based on the dominant orientation ofthe opinion words appearing in the sentence.As mentioned in Section 1, target-dependentsentiment classification of review sentences isquite different from that of tweets.
In reviews, ifany sentiment is expressed in a sentence containinga feature, it is very likely that the sentiment isabout the feature.
However, the assumption doesnot hold in tweets.2.3 SA of TweetsAs Twitter becomes more popular, sentiment anal-ysis on Twitter data becomes more attractive.
(Goet al, 2009; Parikh and Movassate, 2009; Barbosaand Feng, 2010; Davidiv et al, 2010) all follow themachine learning based approach for sentimentclassification of tweets.
Specifically, (Davidiv etal., 2010) propose to classify tweets into multiplesentiment types using hashtags and smileys as la-bels.
In their approach, a supervised KNN-likeclassifier is used.
In contrast, (Barbosa and Feng,2010) propose a two-step approach to classify thesentiments of tweets using SVM classifiers withabstract features.
The training data is collectedfrom the outputs of three existing Twitter senti-ment classification web sites.
As mentioned above,these approaches work in a target-independent way,and so need to be adapted for target-dependent sen-timent classification.3 Approach OverviewThe problem we address in this paper is target-dependent sentiment classification of tweets.
Sothe input of our task is a collection of tweets con-taining the target and the output is labels assignedto each of the tweets.
Inspired by (Barbosa andFeng, 2010; Pang and Lee, 2004), we design athree-step approach in this paper:1.
Subjectivity classification as the first stepto decide if the tweet is subjective or neu-tral about the target;2.
Polarity classification as the second step todecide if the tweet is positive or negativeabout the target if it is classified as subjec-tive in Step 1;3.
Graph-based optimization as the third stepto further boost the performance by takingthe related tweets into consideration.In each of the first two steps, a binary SVMclassifier is built to perform the classification.
Totrain the classifiers, we use SVM-Light 6  with alinear kernel; the default setting is adopted in allexperiments.6 http://svmlight.joachims.org/1533.1 PreprocessingIn our approach, rich feature representations areused to distinguish between sentiments expressedtowards different targets.
In order to generate suchfeatures, much NLP work has to be done before-hand, such as tweet normalization, POS tagging,word stemming, and syntactic parsing.In our experiments, POS tagging is performedby the OpenNLP POS tagger7.
Word stemming isperformed by using a word stem mapping tableconsisting of about 20,000 entries.
We also built asimple rule-based model for tweet normalizationwhich can correct simple spelling errors and varia-tions into normal form, such as ?gooood?
to?good?
and ?luve?
to ?love?.
For syntactic parsingwe use a Maximum Spanning Tree dependencyparser (McDonald et al, 2005).3.2 Target-independent FeaturesPrevious work (Barbosa and Feng, 2010; Davidivet al, 2010) has discovered many effective featuresfor sentiment analysis of tweets, such as emoticons,punctuation, prior subjectivity and polarity of aword.
In our classifiers, most of these features arealso used.
Since these features are all generatedwithout considering the target, we call them target-independent features.
In both the subjectivity clas-sifier and polarity classifier, the same target-independent feature set is used.
Specifically, weuse two kinds of target-independent features:1.
Content features, including words, punctu-ation, emoticons, and hashtags (hashtagsare provided by the author to indicate thetopic of the tweet).2.
Sentiment lexicon features, indicating howmany positive or negative words are in-cluded in the tweet according to a prede-fined lexicon.
In our experiments, we usethe lexicon downloaded from General In-quirer8.4 Target-dependent Sentiment Classifica-tionBesides target-independent features, we also incor-porate target-dependent features in both the subjec-7 http://opennlp.sourceforge.net/projects.html8 http://www.wjh.harvard.edu/~inquirer/tivity classifier and polarity classifier.
We will ex-plain them in detail below.4.1 Extended TargetsIt is quite common that people express their senti-ments about a target by commenting not on thetarget itself but on some related things of the target.For example, one may express a sentiment about acompany by commenting on its products or tech-nologies.
To express a sentiment about a product,one may choose to comment on the features orfunctionalities of the product.
It is assumed thatreaders or audiences can clearly infer the sentimentabout the target based on those sentiments aboutthe related things.
As shown in the tweet below,the author expresses a positive sentiment about?Microsoft?
by expressing a positive sentimentdirectly about ?Microsoft technologies?.
?I am passionate about Microsoft technologiesespecially Silverlight.
?In this paper, we define those aforementionedrelated things as Extended Targets.
Tweets ex-pressing positive or negative sentiments towardsthe extended targets are also regarded as positiveor negative about the target.
Therefore, for target-dependent sentiment classification of tweets, thefirst thing is identifying all extended targets in theinput tweet collection.In this paper, we first regard all noun phrases,including the target, as extended targets for sim-plicity.
However, it would be interesting to knowunder what circumstances the sentiment towardsthe target is truly consistent with that towards itsextended targets.
For example, a sentiment aboutsomeone?s behavior usually means a sentimentabout the person, while a sentiment about some-one?s colleague usually has nothing to do with theperson.
This could be a future work direction fortarget-dependent sentiment classification.In addition to the noun phrases including thetarget, we further expand the extended target setwith the following three methods:1.
Adding mentions co-referring to the targetas new extended targets.
It is common thatpeople use definite or demonstrative nounphrases or pronouns referring to the targetin a tweet and express sentiments directlyon them.
For instance, in ?Oh, Jon Stewart.How I love you so.
?, the author expresses154a positive sentiment to ?you?
which actual-ly refers to ?Jon Stewart?.
By using a sim-ple co-reference resolution tool adaptedfrom (Soon et al, 2001), we add all thementions referring to the target into the ex-tended target set.2.
Identifying the top K nouns and nounphrases which have the strongest associa-tion with the target.
Here, we usePointwise Mutual Information (PMI) tomeasure the association.
)()(),(log),( tpwptwptwPMI ?Where p(w,t), p(w), and p(t) are probabili-ties of w and t co-occurring, w appearing,and t appearing in a tweet respectively.
Inthe experiments, we estimate them on atweet corpus containing 20 million tweets.We set K = 20 in the experiments based onempirical observations.3.
Extracting head nouns of all extended tar-gets, whose PMI values with the target areabove some predefined threshold, as newextended targets.
For instance, suppose wehave found ?Microsoft Technologies?
asthe extended target, we will further add?technologies?
into the extended target setif the PMI value for ?technologies?
and?Microsoft?
is above the threshold.
Simi-larly, we can find ?price?
as the extendedtargets for ?iPhone?
from ?the price ofiPhone?
and ?LoveGame?
for ?Lady Ga-ga?
from ?LoveGame by Lady Gaga?.4.2 Target-dependent FeaturesTarget-dependent sentiment classification needs todistinguish the expressions describing the targetfrom other expressions.
In this paper, we rely onthe syntactic parse tree to satisfy this need.
Specif-ically, for any word stem wi in a tweet which hasone of the following relations with the given targetT or any from the extended target set, we generatecorresponding target-dependent features with thefollowing rules:?
wi is a transitive verb and T (or any of theextended target) is its object; we generate afeature wi _arg2.
?arg?
is short for ?argu-ment?.
For example, for the target iPhonein ?I love iPhone?, we generate?love_arg2?
as a feature.?
wi is a transitive verb and T (or any of theextended target) is its subject; we generatea feature wi_arg1 similar to Rule 1.?
wi is a intransitive verb and T (or any of theextended target) is its subject; we generatea feature wi_it_arg1.?
wi is an adjective or noun and T (or any ofthe extended target) is its head; we gener-ate a feature wi_arg1.?
wi is an adjective or noun and it (or itshead) is connected by a copula with T (orany of the extended target); we generate afeature wi_cp_arg1.?
wi is an adjective or intransitive verb ap-pearing alone as a sentence and T (or anyof the extended target) appears in the pre-vious sentence; we generate a featurewi_arg.
For example, in ?John did that.Great!
?, ?Great?
appears alone as a sen-tence, so we generate ?great_arg?
for thetarget ?John?.?
wi is an adverb, and the verb it modifieshas T (or any of the extended target) as itssubject; we generate a feature arg1_v_wi.For example, for the target iPhone in thetweet ?iPhone works better with the Cell-Band?, we will generate the feature?arg1_v_well?.Moreover, if any word included in the generatedtarget-dependent features is modified by a nega-tion9, then we will add a prefix ?neg-?
to it in thegenerated features.
For example, for the target iPh-one in the tweet ?iPhone does not work better withthe CellBand?, we will generate the features?arg1_v_neg-well?
and ?neg-work_it_arg1?.To overcome the sparsity of target-dependentfeatures mentioned above, we design a special bi-nary feature indicating whether or not the tweetcontains at least one of the above target-dependentfeatures.
Target-dependent features are binary fea-tures, each of which corresponds to the presence ofthe feature in the tweet.
If the feature is present, theentry will be 1; otherwise it will be 0.9 Seven negations are used in the experiments: not, no, never,n?t, neither, seldom, hardly.1555 Graph-based Sentiment OptimizationAs we mentioned in Section 1, since tweets areusually shorter and more ambiguous, it would beuseful to take their contexts into considerationwhen classifying the sentiments.
In this paper, weregard the following three kinds of related tweetsas context for a tweet.1.
Retweets.
Retweeting in Twitter is essen-tially the forwarding of a previous message.People usually do not change the contentof the original tweet when retweeting.
Soretweets usually have the same sentimentas the original tweets.2.
Tweets containing the target and publishedby the same person.
Intuitively, the tweetspublished by the same person within ashort timeframe should have a consistentsentiment about the same target.3.
Tweets replying to or replied by the tweetto be classified.Based on these three kinds of relations, we canconstruct a graph using the input tweet collectionof a given target.
As illustrated in Figure 1, eachcircle in the graph indicates a tweet.
The threekinds of edges indicate being published by thesame person (solid line), retweeting (dash line),and replying relations (round dotted line) respec-tively.Figure 1.
An example graph of tweets about a targetIf we consider that the sentiment of a tweet onlydepends on its content and immediate neighbors,we can leverage a graph-based method for senti-ment classification of tweets.
Specifically, theprobability of a tweet belonging to a specific sen-timent class can be computed with the followingformula:??
)())(())(|()|(),|(dNdNpdNcpcpGcp ?
?Where c is the sentiment label of a tweet whichbelongs to {positive, negative, neutral}, G is thetweet graph, N(d) is a specific assignment of sen-timent labels to all immediate neighbors of thetweet, and ?
is the content of the tweet.We can convert the output scores of a tweet bythe subjectivity and polarity classifiers into proba-bilistic form and use them to approximate p(c| ?
).Then a relaxation labeling algorithm described in(Angelova and Weikum, 2006) can be used on thegraph to iteratively estimate p(c|?,G) for all tweets.After the iteration ends, for any tweet in the graph,the sentiment label that has the maximum p(c| ?,G)is considered the final label.6 ExperimentsBecause there is no annotated tweet corpus public-ly available for evaluation of target-dependentTwitter sentiment classification, we have to createour own.
Since people are most interested in sen-timents towards celebrities, companies and prod-ucts, we selected 5 popular queries of these kinds:{Obama, Google, iPad, Lakers, Lady Gaga}.
Foreach of those queries, we downloaded 400 Englishtweets10 containing the query using the Twitter API.We manually classify each tweet as positive,negative or neutral towards the query with which itis downloaded.
After removing duplicate tweets,we finally obtain 459 positive, 268 negative and1,212 neutral tweets.Among the tweets, 100 are labeled by two hu-man annotators for inter-annotator study.
The re-sults show that for 86% of them, both annotatorsgave identical labels.
Among the 14 tweets whichthe two annotators disagree on, only 1 case is apositive-negative disagreement (one annotator con-siders it positive while the other negative), and theother 13 are all neutral-subjective disagreement.This probably indicates that it is harder for humansto decide if a tweet is neutral or subjective than todecide if it is positive or negative.10 In this paper, we use sentiment classification of Englishtweets as a case study; however, our approach is applicable toother languages as well.1566.1 Error Analysis of Twitter Sentiment Out-putWe first analyze the output of Twitter Sentiment(TS) using the five test queries.
For each query, werandomly select 20 tweets labeled as positive ornegative by TS.
We also manually classify eachtweet as positive, negative or neutral about the cor-responding query.
Then, we analyze those tweetsthat get different labels from TS and humans.
Fi-nally we find two major types of error: 1) Tweetswhich are totally neutral (for any target) are classi-fied as subjective by TS; 2) sentiments in sometweets are classified correctly but the sentimentsare not truly about the query.
The two types takeup about 35% and 40% of the total errors, respec-tively.The second type is actually what we want to re-solve in this paper.
After further checking thosetweets of the second type, we found that most ofthem are actually neutral for the target, whichmeans that the dominant error in Twitter Sentimentis classifying neutral tweets as subjective.
Beloware several examples of the second type where thebolded words are the targets.
?No debate needed, heat can't beat lakers orceltics?
(negative by TS but positive by human)?why am i getting spams from weird people ask-ing me if i want to chat with lady gaga?
(positiveby TS but neutral by human)?Bringing iPhone and iPad apps into cars?http://www.speakwithme.com/ will be out soon andalpha is awesome in my car.?
(positive by TS butneutral by human)?Here's a great article about Monte Veronesecheese.
It's in Italian so just put the url into Googletranslate and enjoy http://ow.ly/3oQ77?
(positiveby TS but neutral by human)6.2 Evaluation of Subjectivity ClassificationWe conduct several experiments to evaluate sub-jectivity classifiers using different features.
In theexperiments, we consider the positive and negativetweets annotated by humans as subjective tweets(i.e., positive instances in the SVM classifiers),which amount to 727 tweets.
Following (Pang etal., 2002), we balance the evaluation data set byrandomly selecting 727 tweets from all neutraltweets annotated by humans and consider them asobjective tweets (i.e., negative instances in theclassifiers).
We perform 10-fold cross-validationson the selected data.
Following (Go et al, 2009;Pang et al, 2002), we use accuracy as a metric inour experiments.
The results are listed below.Features Accuracy (%)Content features 61.1+ Sentiment lexicon features 63.8+ Target-dependent features 68.2Re-implementation of (Bar-bosa and Feng, 2010)60.3Table 1.
Evaluation of subjectivity classifiers.As shown in Table 1, the classifier using onlythe content features achieves an accuracy of 61.1%.Adding sentiment lexicon features improves theaccuracy to 63.8%.
Finally, the best performance(68.2%) is achieved by combining target-dependent features and other features (t-test: p <0.005).
This clearly shows that target-dependentfeatures do help remove many sentiments not trulyabout the target.
We also re-implemented themethod proposed in (Barbosa and Feng, 2010) forcomparison.
From Table 1, we can see that all oursystems perform better than (Barbosa and Feng,2010) on our data set.
One possible reason is that(Barbosa and Feng, 2010) use only abstract fea-tures while our systems use more lexical features.To further evaluate the contribution of target ex-tension, we compare the system using the exacttarget and all extended targets with that using onlythe exact target.
We also eliminate the extendedtargets generated by each of the three target exten-sion methods and reevaluate the performances.Target Accuracy (%)Exact target 65.6+ all extended targets 68.2- co-references 68.0- targets found by PMI 67.8- head nouns 67.3Table 2.
Evaluation of target extension methods.As shown in Table 2, without extended targets,the accuracy is 65.6%, which is still higher thanthose using only target-independent features.
Afteradding all extended targets, the accuracy is im-proved significantly to 68.2% (p < 0.005), whichsuggests that target extension does help find indi-157rectly expressed sentiments about the target.
Inaddition, all of the three methods contribute to theoverall improvement, with the head noun methodcontributing most.
However, the other two meth-ods do not contribute significantly.6.3 Evaluation of Polarity ClassificationSimilarly, we conduct several experiments on posi-tive and negative tweets to compare the polarityclassifiers with different features, where we use268 negative and 268 randomly selected positivetweets.
The results are listed below.Features Accuracy (%)Content features 78.8+ Sentiment lexicon features 84.2+ Target-dependent features 85.6Re-implementation of (Bar-bosa and Feng, 2010)83.9Table 3.
Evaluation of polarity classifiers.From Table 3, we can see that the classifier us-ing only the content features achieves the worstaccuracy (78.8%).
Sentiment lexicon features areshown to be very helpful for improving the per-formance.
Similarly, we re-implemented the meth-od proposed by (Barbosa and Feng, 2010) in thisexperiment.
The results show that our system usingboth content features and sentiment lexicon fea-tures performs slightly better than (Barbosa andFeng, 2010).
The reason may be same as that weexplained above.Again, the classifier using all features achievesthe best performance.
Both the classifiers with allfeatures and with the combination of content andsentiment lexicon features are significantly betterthan that with only the content features (p < 0.01).However, the classifier with all features does notsignificantly outperform that using the combina-tion of content and sentiment lexicon features.
Wealso note that the improvement by target-dependentfeatures here is not as large as that in subjectivityclassification.
Both of these indicate that target-dependent features are more useful for improvingsubjectivity classification than for polarity classifi-cation.
This is consistent with our observation inSubsection 6.2 that most errors caused by incorrecttarget association are made in subjectivity classifi-cation.
We also note that all numbers in Table 3are much bigger than those in Table 1, which sug-gests that subjectivity classification of tweets ismore difficult than polarity classification.Similarly, we evaluated the contribution of tar-get extension for polarity classification.
Accordingto the results, adding all extended targets improvesthe accuracy by about 1 point.
However, the con-tributions from the three individual methods arenot statistically significant.6.4 Evaluation of Graph-based OptimizationAs seen in Figure 1, there are several tweets whichare not connected with any other tweets.
For thesetweets, our graph-based optimization approach willhave no effect.
The following table shows the per-centages of the tweets in our evaluation data setwhich have at least one related tweet according tovarious relation types.Relation type PercentagePublished by the same person11 41.6Retweet 23.0Reply 21.0All 66.2Table 4.
Percentages of tweets having at least one relat-ed tweet according to various relation types.According to Table 4, for 66.2% of the tweetsconcerning the test queries, we can find at least onerelated tweet.
That means our context-aware ap-proach is potentially useful for most of the tweets.To evaluate the effectiveness of our context-aware approach, we compared the systems withand without considering the context.System AccuracyF1-score (%)pos neu negTarget-dependentsentiment classifier66.0 57.5 70.1 66.1+Graph-based op-timization68.3 63.5 71.0 68.5Table 5.
Effectiveness of the context-aware approach.As shown in Table 5, the overall accuracy of thetarget-dependent classifiers over three classes is66.0%.
The graph-based optimization improves theperformance by over 2 points (p < 0.005), whichclearly shows that the context information is very11 We limit the time frame from one week before to one weekafter the post time of the current tweet.158useful for classifying the sentiments of tweets.From the detailed improvement for each sentimentclass, we find that the context-aware approach isespecially helpful for positive and negative classes.Relation type Accuracy (%)Published by the same person 67.8Retweet 66.0Reply 67.0Table 6.
Contribution comparison between relations.We further compared the three types of relationsfor context-aware sentiment classification; the re-sults are reported in Table 6.
Clearly, being pub-lished by the same person is the most usefulrelation for sentiment classification, which is con-sistent with the percentage distribution of thetweets over relation types; using retweet only doesnot help.
One possible reason for this is that theretweets and their original tweets are nearly thesame, so it is very likely that they have already gotthe same labels in previous classifications.7 Conclusions and Future WorkTwitter sentiment analysis has attracted much at-tention recently.
In this paper, we address target-dependent sentiment classification of tweets.
Dif-ferent from previous work using target-independent classification, we propose to incorpo-rate syntactic features to distinguish texts used forexpressing sentiments towards different targets in atweet.
According to the experimental results, theclassifiers incorporating target-dependent featuressignificantly outperform the previous target-independent classifiers.In addition, different from previous work usingonly information on the current tweet for sentimentclassification, we propose to take the related tweetsof the current tweet into consideration by utilizinggraph-based optimization.
According to the exper-imental results, the graph-based optimization sig-nificantly improves the performance.As mentioned in Section 4.1, in future we wouldlike to explore the relations between a target andany of its extended targets.
We are also interestedin exploring relations between Twitter accounts forclassifying the sentiments of the tweets publishedby them.AcknowledgmentsWe would like to thank Matt Callcut for refiningthe language of this paper, and thank Yuki Araseand the anonymous reviewers for many valuablecomments and helpful suggestions.
We would alsothank Furu Wei and Xiaolong Wang for their helpwith some of the experiments and the preparationof the camera-ready version of the paper.ReferencesRalitsa Angelova, Gerhard Weikum.
2006.
Graph-basedtext classification: learn from your neighbors.
SIGIR2006: 485-492Luciano Barbosa and Junlan Feng.
2010.
Robust Senti-ment Detection on Twitter from Biased and NoisyData.
Coling 2010.Christopher Burges.
1998.
A Tutorial on Support VectorMachines for Pattern Recognition.
Data Mining andKnowledge Discovery, 2(2):121-167.Yejin Choi, Claire Cardie, Ellen Riloff, and SiddharthPatwardhan S. 2005.
Identifying sources of opinionswith conditional random fields and extraction pat-terns.
In Proc.
of the 2005 Human Language Tech-nology Conf.
and Conf.
on Empirical Methods inNatural Language Processing (HLT/EMNLP 2005).pp.
355-362Dmitry Davidiv, Oren Tsur and Ari Rappoport.
2010.Enhanced Sentiment Learning Using Twitter Hash-tags and Smileys.
Coling 2010.Xiaowen Ding and Bing Liu.
2007.
The Utility of Lin-guistic Rules in Opinion Mining.
SIGIR-2007 (posterpaper), 23-27 July 2007, Amsterdam.Alec Go, Richa Bhayani, Lei Huang.
2009.
Twitter Sen-timent Classification using Distant Supervision.Vasileios Hatzivassiloglou and Kathleen.R.
McKeown.2002.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the 35th ACL and the 8thConference of the European Chapter of the ACL.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of the ACMSIGKDD International Conference on KnowledgeDiscovery & Data Mining (KDD-2004, full paper),Seattle, Washington, USA, Aug 22-25, 2004.Thorsten Joachims.
Making Large-scale Support VectorMachine Learning Practical.
In B. Sch?olkopf, C. J.C. Burges, and A. J. Smola, editors, Advances inkernel methods: support vector learning, pages 169-184.
MIT Press, Cambridge, MA, USA, 1999.159Soo-Min Kim and Eduard Hovy 2006.
Extracting opi-nions, opinion holders, and topics expressed in onlinenews media text, In Proc.
of ACL Workshop on Sen-timent and Subjectivity in Text, pp.1-8, Sydney, Aus-tralia.Ryan McDonald, F. Pereira, K. Ribarov, and J. Haji?c.2005.
Non-projective dependency parsing usingspanning tree algorithms.
In Proc.
HLT/EMNLP.Tetsuya Nasukawa, Jeonghee Yi.
2003.
Sentiment anal-ysis: capturing favorability using natural languageprocessing.
In Proceedings of K-CAP.Bo Pang, Lillian Lee.
2004.
A Sentimental Education:Sentiment Analysis Using Subjectivity Summariza-tion Based on Minimum Cuts.
In Proceedings ofACL 2004.Bo Pang, Lillian Lee, Shivakumar Vaithyanathan.
2002.Thumbs up?
Sentiment Classification using MachineLearning Techniques.Ravi Parikh and Matin Movassate.
2009.
SentimentAnalysis of User-Generated Twitter Updates usingVarious Classification Techniques.Wee.
M. Soon, Hwee.
T. Ng, and Danial.
C. Y. Lim.2001.
A Machine Learning Approach to CoreferenceResolution of Noun Phrases.
Computational Linguis-tics, 27(4):521?544.Peter D. Turney.
2002.
Thumbs Up or Thumbs Down?Semantic Orientation Applied to Unsupervised Clas-sification of Reviews.
In proceedings of ACL 2002.Janyce Wiebe.
2000.
Learning subjective adjectivesfrom corpora.
In Proceedings of AAAI-2000.Theresa Wilson, Janyce Wiebe, Paul Hoffmann.
2005.Recognizing Contextual Polarity in Phrase-LevelSentiment Analysis.
In Proceedings of NAACL 2005.160
