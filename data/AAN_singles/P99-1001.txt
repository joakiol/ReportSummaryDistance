Untangling Text Data MiningMart i  A.  HearstSchool of Information Management & SystemsUniversity of California, Berkeley102 South HallBerkeley, CA 94720-4600h ttp ://www.
sims.
berkeley, edu/-hearstAbst ractThe possibilities for data mining from large textcollections are virtually untapped.
Text ex-presses avast, rich range of information, but en-codes this information i  a form that is difficultto decipher automatically.
Perhaps for this rea-son, there has been little work in text data min-ing to date, and most people who have talkedabout it have either conflated it with informa-tion access or have not made use of text directlyto discover heretofore unknown information.In this paper I will first define data mining,information access, and corpus-based computa-tional linguistics, and then discuss the relation-ship of these to text data mining.
The intentbehind these contrasts is to draw attention toexciting new kinds of problems for computa-tional linguists.
I describe xamples of what Iconsider to be reM text data mining efforts andbriefly outline recent ideas about how to pursueexploratory data analysis over text.1 I n t roduct ionThe nascent field of text data mining (TDM)has the peculiar distinction of having a nameand a fair amount of hype but as yet alostno practitioners.
I suspect his has happenedbecause people assume TDM is a natural ex-tension of the slightly less nascent field of datamining (DM), also known as knowledge dis-covery in databases (Fayyad and Uthurusamy,1999), and information archeology (Brachmanet al, 1993).
Additionally, there are somedisagreements about what actually constitutesdata mining.
It turns out that "mining" is not avery good metaphor for what people in the fieldactually do.
Mining implies extracting preciousnuggets of ore from otherwise worthless rock.If data mining really followed this metaphor, itwould mean that people were discovering newfactoids within their inventory databases.
How-ever, in practice this is not really the case.Instead, data mining applications tend to be(semi)automated discovery of trends and pat-terns across very large datasets, usually for thepurposes of decision making (Fayyad and Uthu-rusamy, 1999; Fayyad, 1997).
Part of what Iwish to argue here is that in the case of text,it can be interesting to take the mining-for-nuggets metaphor seriously.The various contrasts discussed below aresummarized in Table 1.2 TDM vs.
In fo rmat ion  AccessIt is important o differentiate between textdata mining and information access (or infor-mation retrieval, as it is more widely known).The goal of information access is to help usersfind documents that satisfy their informationneeds (Baeza-Yates and Ribeiro-Neto, 1999).The standard procedure is akin to looking forneedles in a needlestack - the problem isn't somuch that the desired information is not known,but rather that the desired information coex-ists with many other valid pieces of information.Just because a user is currently interested inNAFTA and not Furbies does not mean that alldescriptions ofFurbies are worthless.
The prob-lem is one of homing in on what is currently ofinterest o the user.As noted above, the goal of data mining is todiscover or derive new information from data,finding patterns across datasets, and/or sepa-rating signal from noise.
The fact that an infor-mation retrieval system can return a documentthat contains the information a user requestedimplies that no new discovery is being made:the information had to have already been knownto the author of the text; otherwise the authorcould not have written it down.3I have observed that many people, whenasked about text data mining, assume it shouldhave something to do with "making things eas-ier to find on the web".
For example, the de-scription of the KDD-97 panel on Data Miningand the Web stated:... Two challenges are predominant fordata mining on the Web.
The first goal isto help users in finding useful informationon the Web and in discovering knowledgeabout a domain that is represented by acollection of Web-documents.
The secondgoal is to analyse the transactions run ina Web-based system, be it to optimize thesystem or to find information about theclients using the system.
1This search-centric view misses the point thatwe might actually want to treat the informationin the web as a large knowledge base from whichwe can extract new, never-before ncounteredinformation (Craven et al, 1998).On the other hand, the results of certain typesof text processing can yield tools that indirectlyaid in the information access process.
Exam-ples include text clustering to create thematicoverviews of text collections (Cutting et al,1992; Chalmers and Chitson, 1992; Rennison,1994; Wise et al, 1995; Lin et al, 1991; Chenet al, 1998), automatically generating term as-sociations to aid in query expansion (Peat andWillett, 1991; Voorhees, 1994; Xu and Croft,1996), and using co-citation analysis to find gen-eral topics within a collection or identify centralweb pages (White and McCain, 1989; Larson,1996; Kleinberg, 1998).Aside from providing tools to aid in the stan-dard information access process, I think textdata mining can contribute along another di-mension.
In future I hope to see informationaccess systems upplemented with tools for ex-ploratory data analysis.
Our efforts in this di-rection are embodied in the LINDI project, de-scribed in Section 5 below.3 TDM and Computat iona lLinguisticsIf we extrapolate from data mining (as prac-ticed) on numerical data to data mining fromtext collections, we discover that there alreadyl http: / /www.aaai.org/ Conferences/ KD D /1997 /kdd97-schedule.htmlexists a field engaged in text data mining:corpus-based computational linguistics!
Empir-ical computational linguistics computes tatis-tics over large text collections in order to dis-cover useful patterns.
These patterns are usedto inform algorithms for various subproblemswithin natural language processing, such aspart-of-speech tagging, word sense disambigua-tion, and bilingual dictionary creation (Arm-strong, 1994).It is certainly of interest o a computationallinguist that the words "prices, prescription,and patent" are highly likely to co-occur withthe medical sense of "drug" while "abuse, para-phernalia, and illicit" are likely to co-occur withthe illegal drug sense of this word (Church andLiberman, 1991).
This kind of information canalso be used to improve information retrieval al-gorithms.
However, the kinds of patterns foundand used in computational linguistics are notlikely to be what the general business commu-nity hopes for when they use the term text datamining.Within the computational linguistics frame-work, efforts in automatic augmentation of ex-isting lexical structures eem to fit the data-mining-as-ore-extraction metaphor.
Examplesinclude automatic augmentation f WordNet re-lations (Fellbaum, 1998) by identifying lexico-syntactic patterns that unambiguously indicatethose relations (Hearst, 1998), and automaticacquisition of subcategorization data from largetext corpora (Manning, 1993).
However, theseserve the specific needs of computational lin-guistics and are not applicable to a broader au-dience.4 TDM and Category  MetadataSome researchers have claimed that text cate-gorization should be considered text data min-ing.
Although analogies can be found in thedata mining literature (e.g., referring to classifi-cation of astronomical phenomena as data min-ing (Fayyad and Uthurusamy, 1999)), I believewhen applied to text categorization this is a mis-nomer.
Text categorization is a boiling down ofthe specific content of a document into one (ormore) of a set of pre-defined labels.
This doesnot lead to discovery of new information; pre-sumably the person who wrote the documentknew what it was about.
Rather, it produces a4Finding PatternsNon-textual data standard ata miningTextua l  data  computational linguisticsFinding NuggetsNovel I Non-Novel?
database queriesreal TDM information retrievalTable 1: A classification of data mining and text data mining applications.compact summary of something that is alreadyknown.However, there are two recent areas of in-quiry that make use of text categorization anddo seem to fit within the conceptual frameworkof discovery of trends and patterns within tex-tual data for more general purpose usage.One body of work uses text category labels(associated with Reuters newswire) to find "un-expected patterns" among text articles (Feld-man and Dagan, 1995; Dagan et al, 1996; Feld-man et al, 1997).
The main approach is tocompare distributions of category assignmentswithin subsets of the document collection.
Forinstance, distributions of commodities in coun-try C1 are compared against those of countryC2 to see if interesting or unexpected trendscan be found.
Extending this idea, one coun-try's export trends might be compared againstthose of a set of countries that are seen as aneconomic unit (such as the G-7).Another effort is that of the DARPA TopicDetection and Tracking initiative (Allan etal., 1998).
While several of the tasks withinthis initiative are standard text analysis prob-lems (such as categorization and segmentation),there is an interesting task called On-line NewEvent Detection, whose input is a stream ofnews stories in chronological order, and whoseoutput is a yes/no decision for each story, madeat the time the story arrives, indicating whetherthe story is the first reference to a newly occur-ring event.
In other words, the system mustdetect the first instance of what will become a?
series of reports on some important opic.
Al-though this can be viewed as a standard clas-sification task (where the class is a binary as-signment o the new-event class) it is more inthe spirit of data mining, in that the focus ison discovery of the beginning of a new theme ortrend.The reason I consider this examples - usingmultiple occurrences of text categories to de-tect trends or patterns - to be "real" data min-ing is that they use text metadata to tell ussomething about the world, outside of the textcollection itself.
(However, since this applica-tion uses metadata ssociated with text docu-ments, rather than the text directly, it is un-clear if it should be considered text data min-ing or standard data mining.)
The computa-tional linguistics applications tell us about howto improve language analysis, but they do notdiscover more widely usable information.5 Text  Data Mining as Exp loratoryData Ana lys i sAnother way to view text data mining is asa process of exploratory data analysis (Tukey,1977; Hoaglin et al, 1983) that leads to the dis-covery of heretofore unknown information, orto answers for questions for which the answer isnot currently known.Of course, it can be argued that the stan-dard practice of reading textbooks, journal ar-ticles and other documents helps researchers inthe discovery of new information, since this isan integral part of the research process.
How-ever, the idea here is to use text for discoveryin a more direct manner.
Two examples are de-scribed below.5.1 Us ing  Text  to  Form Hypothesesabout  DiseaseFor more than a decade, Don Swanson has elo-quently argued why it is plausible to expectnew information to be derivable from text col-lections: experts can only read a small subsetof what is published in their fields and are of-ten unaware of developments in related fields.Thus it should be possible to find useful link-ages between information in related literatures,if the authors of those literatures rarely refer toone another's work.
Swanson has shown howchains of causal implication within the medicalliterature can lead to hypotheses for causes ofrare diseases, some of which have received sup-porting experimental evidence (Swanson, 1987;5Swanson, 1991; Swanson and Smalheiser, 1994;Swanson and Smalheiser, 1997).For example, when investigating causes of mi-graine headaches, he extracted various pieces ofevidence from titles of articles in the biomedi-cal literature.
Some of these clues can be para-phrased as follows:?
stress is associated with migraines?
stress can lead to loss of magnesium?
calcium channel blockers prevent some mi-graines?
magnesium is a natural calcium channelblocker?
spreading cortical depression (SCD) is im-plicated in some migraines?
high leveles of magnesium inhibit SCD?
migraine patients have high platelet aggre-gability?
magnesium can suppress platelet aggrega-bilityThese clues suggest that magnesium defi-ciency may play a role in some kinds of mi-graine headache; a hypothesis which did not ex-ist in the literature at the time Swanson foundthese links.
The hypothesis has to be tested vianon-textual means, but the important point isthat a new, potentially plausible medical hy-pothesis was derived from a combination oftext fragments and the explorer's medical ex-pertise.
(According to Swanson (1991), subse-quent study found support for the magnesium-migraine hypothesis (Ramadan et al, 1989).
)This approach has been only partially auto-mated.
There is, of course, a potential for com-binatorial explosion of potentially valid links.Beeferman (1998) has developed a flexible in-terface and analysis tool for exploring certainkinds of chains of links among lexical relationswithin WordNet.
2 However, sophisticated newalgorithms are needed for helping in the prun-ing process, since a good pruning algorithm willwant to take into account various kinds of se-mantic constraints.
This may be an interest-ing area of investigation for computational lin-guists.2See http://www.link.cs.cmu.edu/lexfn5.2 Us ing  Text  to  Uncover  Soc ia lImpactSwitching to an entirely different domain, con-sider a recent effort to determine the effectsof publicly financed research on industrial ad-vances (Narin et al, 1997).
After years ofpreliminary studies and building special pur-pose tools, the authors found that the tech-nology industry relies more heavily than everon government-sponsored search results.
Theauthors explored relationships among patenttext and the published research literature, us-ing a procedure which was reported as followsin Broad (1997):The CHI Research team examined thescience references on the front pages ofAmerican patents in two recent periods -1987 and 1988, as well as 1993 and 1994 -looking at all the 397,660 patents issued.It found 242,000 identifiable science ref-erences and zeroed in on those publishedin the preceding 11 years, which turnedout to be 80 percent of them.
Searches ofcomputer databases allowed the linking of109,000 of these references to known jour-nals and authors' addresses.
After elim-inating redundant citations to the samepaper, as well as articles with no knownAmerican author, the study had a core col-lection of 45,000 papers.
Armies of aidesthen fanned out to libraries to look upthe papers and examine their closing lines,which often say who financed the research.That detective work revealed an extensivereliance on publicly financed science.Further narrowing its focus, the study setaside patents given to schools and govern-ments and zeroed in on those awarded toindustry.
For 2,841 patents issued in 1993and 1994, it examined the peak year of lit-erature references, 1988, and found 5,217citations to science papers.Of these, it found that 73.3 percent hadbeen written at public institutions - uni-versities, government labs and other pub-lic agencies, both in the United States andabroad.Thus a heterogeneous mix of operations wasrequired to conduct a complex analyses overlarge text collections.
These operations in-cluded:61 Retrieval of articles from a particular col-lection (patents) within a particular daterange.2 Identification of the citation pool (articlescited by the patents).3 Bracketing of this pool by date, creating anew subset of articles.4 Computation of the percentage of articlesthat remain after bracketing.5 Joining these results with those of othercollections to identify the publishers of ar-ticles in the pool.6 Elimination of redundant articles.7 Elimination of articles based on an at-tribute type (author nationality).8 Location of full-text versions of the articles.9 Extraction of a special attribute from thefull text (the acknowledgement of funding).10 Classification of this attribute (by institu-tion type).11 Narrowing the set of articles to consider byan attribute (institution type).12 Computation of statistics over one of theattributes (peak year)13 Computation of the percentage of arti-cles for which one attribute has been as-signed another attribute type (whose cita-tion attribute has a particular institutionattribute).Because all the data was not available online,much of the work had to be done by hand, andspecial purpose tools were required to performthe operations.5.3 The  L INDI  P ro jec tThe objectives of the LINDI project 3 are to in-vestigate how researchers can use large text col-lections in the discovery of new important infor-mation, and to build software systems to helpsupport this process.
The main tools for dis-covering new information are of two types: sup-port for issuing sequences of queries and relatedoperations across text collections, and tightlycoupled statistical and visualization tools forthe examination ofassociations among conceptsthat co-occur within the retrieved ocuments.Both sets of tools make use of attributes as-sociated specifically with text collections and3LINDI: L inking In format ion for Novel Discovery andInsight.their metadata.
Thus the broadening, narrow-ing, and linking of relations een in the patentexample should be tightly integrated with anal-ysis and interpretation tools as needed in thebiomedical example.Following Amant (1996), the interactionparadigm is that of a mixed-initiative balanceof control between user and system.
The inter-action is a cycle in which the system suggestshypotheses and strategies for investigating thesehypotheses, and the user either uses or ignoresthese suggestions and decides on the next move.We are interested in an important problemin molecular biology, that of automating thediscovery of the function of newly sequencedgenes (Walker et al, 1998).
Human genomeresearchers perform experiments in which theyanalyze co-expression of tens of thousands ofnovel and known genes simultaneously.
4 Giventhis huge collection of genetic information, thegoal is to determine which of the novel genesare medically interesting, meaning that theyare co-expressed with already understood geneswhich are known to be involved in disease.
Ourstrategy is to explore the biomedical literature,trying to formulate plausible hypotheses aboutwhich genes are of interest.Most information access systems require theuser to execute and keep track of tactical moves,often distracting from the thought-intensive as-pects of the problem (Bates, 1990).
The LINDIinterface provides a facility for users to buildand so reuse sequences of query operations viaa drag-and-drop interface.
These allow the userto repeat he same sequence of actions for differ-ent queries.
In the gene example, this allows theuser to specify a sequence of operations to ap-ply to one co-expressed gene, and then iteratethis sequence over a list of other co-expressedgenes that can be dragged onto the template.
(The Visage interface (Derthick et al, 1997)implements his kind of functionality within itsinformation-centric framework.)
These includethe following operations (see Figure 1):?
Iteration of an operation over the itemswithin a set.
(This allows each item re-trieved in a previous query to be use as a4A gene g~ co-expresses wi th  gene g when both  arefound to be act ivated in the same cells at the same t imewith much more l ikelihood than  chance.search terms for a new query.)?
Transformation, i.e., applying an operationto an item and returning a transformeditem (such as extracting a feature).?
Ranking, i.e., applying an operation to aset of items and returning a (possibly) re-ordered set of items with the same cardi-nality.?
Selection, i.e., applying an operation toa set of items and returning a (possibly)reordered set of items with the same orsmaller cardinality.?
Reduction, i.e., applying an operation toone or more sets of items to yield a sin-gleton result (e.g., to compute percentagesand averages).6 SummaryFor almost a decade the computational linguis-tics community has viewed large text collectionsas a resource to be tapped in order to producebetter text analysis algorithms.
In this paper, Ihave attempted to suggest a new emphasis: theuse of large online text collections to discovernew facts and trends about the world itself.
Isuggest hat to make progress we do not needfully artificial intelligent ext analysis; rather,a mixture of computationally-driven and user-guided analysis may open the door to excitingnew results.Acknowledgements .
Hao Chen, KetanMayer-Patel, and Vijayshankar Raman helpeddesign and did all the implementation of thefirst LINDI prototype.This system will allow maintenance of sev-eral different ypes of history including historyof commands issued, history of strategies em-ployed, and hiStory of hypotheses tested.
Forthe history view, we plan to use a "spreadsheet"layout (Hendry and Harper, 1997) as well as avariation on a "slide sorter" view which Visageuses for presentation creation but not for his-tory retention (Roth et al, 1997).Since gene function discovery is a new area,there is not yet a known set of explorationstrategies.
So initially the system must helpan expert user generate and record good explo-ration strategies.
The user interface providesa mechanism for recording and modifying se-quences of actions.
These include facilities thatrefer to metadata structure, allowing, for exam-ple, query terms to be expanded by terms onelevel above or below them in a subject hierarchy.Once a successful set of strategies has been de-vised, they can be re-used by other researchersand (with luck) by an automated version of thesystem.
The intent is to build up enough strate-gies that the system will begin to be used as anassistant or advisor (Amant, 1996), ranking hy-potheses according to projected importance andplausibility.Thus the emphasis of this system is tohelp automate the tedious parts of the textmanipulation process and to integrate un-derlying computationally-driven text analysiswith human-guided decision making within ex-ploratory data analysis over text.Re ferencesJ.
Allan, J. Carbonell, G. Doddington, J. Yamron,and Y. Yang.
1998.
Topic detection and trackingpilot study: Final report.
In Proceedings of theDARPA Broadcast News Transcription and Un-derstanding Workshop, pages 194-218.Robert St. Amant.
1996.
A Mixed-InitiativePlanning Approach to Exploratory Data Analy-sis.
Ph.D. thesis, Univeristy of Massachusetts,Amherst.Susan Armstrong, editor.
1994.
Using Large Cor-pora.
MIT Press.Ricardo Baeza-Yates and Berthier Ribeiro-Neto.1999.
Modern Information Retrieval.
Addison-Wesley Longman Publishing Company.Marcia J. Bates.
1990.
The berry-picking search:User interface design.
In Harold Thimbleby, edi-tor, User Interface Design.
Addison-Wesley.Douglas Beeferman.
1998.
Lexical discovery withan enriched semantic network.
In Proceedings ofthe ACL/COLING Workshop on Applications ofWordNet in Natural Language Processing Sys-tems, pages 358-364.R.
J. Brachman, P. G. Selfridge, L. G. Terveen,B.
Altman, A Borgida, F. Halper, T. Kirk,A.
Lazar, D. L. McGuinness, and L. A. Resnick.1993.
Integrated support for data archaeology.International Journal of Intelligent and Cooper-ative Information Systems, 2(2):159-185.William J.
Broad.
1997.
Study finds public scienceis pillar of industry.
In The New York Times, May13.Matthew Chalmers and Paul Chitson.
1992.
Bead:Exploration in information visualization.
InProceedings of the 15th Annual InternationalACM/SIGIR Conference, pages 330-337, Copen-hagen, Denmark.8Figure 1: A hypothetical sequence of operations for the exploration of gene function within abiomedical text collection, where the functions of genes A, B, and C are known, and commonalitiesare sought to hypothesize the function of the unknown gene.
The mapping operation imposes arank ordering on the selected keywords.
The final operation is a selection of only those documentsthat contain at least one of the top-ranked keywords and that contain mentions of all three knowngenes.Hsinchen Chen, Andrea L. Houston, Robin R.Sewell, and Bruce R. Schatz.
1998.
Internetbrowsing and searching: User evaluations of cate-gory map and concept space techniques.
Journalof the American Society for Information Sciences(JASIS), 49(7).Kenneth W. Church and Mark Y. Liberman.
1991.A status report on the ACL/DCI.
In The Pro-ceedings of the 7th Annual Conference of the UWCentre for the New OED and Text Research: Us-ing Corpora, pages 84-91, Oxford.M.
Craven, D. DiPasquo, D. Freitag, A. McCallum,T.
Mitchell, K. Nigam, and S. Slattery.
1998.Learning to extract symbolic knowledge from theworld wide web.
In Proceedings of AAAI.Douglass R. Cutting, Jan O. Pedersen, DavidKarger, and John W. Tukey.
1992.
Scat-ter/Gather: A cluster-based approach to brows-ing large document collections.
In Proceedings ofthe 15th Annual International ACM/SIGIR Con-ference, pages 318-329, Copenhagen, Denmark.Ido Dagan, Ronen Feldman, and Haym Hirsh.
1996.Keyword-based browsing and analysis of largedocument sets.
In Proceedings ofthe Fifth AnnualSymposium on Document Analysis and Informa-tion Retrieval (SDAIR), Las Vegas, NV.Mark Derthick, John Kolojejchick, and Steven F.Roth.
1997.
An interactive visualization environ-ment for data exploration.
In Proceedings of theThird Annual Conference on Knowledge Discov-ery and Data Mining (KDD), Newport Beach.Usama Fayyad and Ramasamy Uthurusamy.1999.
Data mining and knowledge discoveryin databases: Introduction to the special issue.Communications ofthe ACM, 39(11), November.Usama Fayyad.
1997.
Editorial.
Data Mining andKnowledge Discovery, 1(1).Ronen Feldman and Ido Dagan.
1995.
KDT -knowledge discovery in texts.
In Proceedings ofthe First Annual Conference on Knowledge Dis-covery and Data Mining (KDD), Montreal.Ronen Feldman, Will Klosgen, and Amir Zilber-stein.
1997.
Visualization techniques to exploredata mining results for document collections.
InProceedings of the Third Annual Conference onKnowledge Discovery and Data Mining (KDD),Newport Beach.Christiane Fellbaum, editor.
1998.
WordNet: An9Electronic Lexical Database.
MIT Press.Marti A. Hearst.
1998.
Automated iscovery ofwordnet relations.
In Christiane Fellbaum, editor,WordNet: An Electronic Lexical Database.
MITPress, Cambridge, MA.David G. Hendry and David J. Harper.
1997.
An in-formal information-seeking environment.
Journalof the American Society for Information Science,48(11):1036-1048.David C. Hoaglin, Frederick Mosteller, and John W.Tukey.
1983.
Understanding Robust and Ex-ploratory Data Analysis.
John Wiley & Sons, Inc.Jon Kleinberg.
1998.
Authoritative sources in a hy-perlinked environment.
In Proceedings of the 9thA CM-SIAM Symposium on Discrete Algorithms.Ray R. Larson.
1996.
Bibliometrics of the worldwide web: An exploratory analysis of the intellec-tual structure of cyberspace.
In ASIS '96: Pro-ceedings of the 1996 Annual ASIS Meeting.Xia Lin, Dagobert Soergel, and Gary Marchion-ini.
1991.
A self-organizing semantic map for in-formation retrieval.
In Proceedings of the 14thAnnual International ACM//SIGIR Conference,pages 262-269, Chicago.Christopher D. Manning.
1993.
Automatic acquisi-tion of a large subcategorization dictionary fromcorpora.
In Proceedings of the 31st Annual Meet-ing of the Association for Computational Lin-gusitics, pages 235-242, Columbus, OH.Francis Narin, Kimberly S. Hamilton, and DominicOlivastro.
1997.
The increasing linkage betweenus technology and public science.
Research Pol-icy, 26(3):317-330.Helen J.
Peat and Peter Willett.
1991.
The limi-tations of term co-occurence data for query ex-pansion in document retrieval systems.
JASIS,42(5):378-383.N.
M. Ramadan, H. Halvorson, A. Vandelinde, andS.R.
Levine.
1989.
Low brain magnesium in mi-graine.
Headache, 29(7):416-419.Earl Rennison.
1994.
Galaxy of news: An approachto visualizing and understanding expansive newslandscapes.
In Proceedings of UIST 94, ACMSymposium on User Interface Software and Tech-nology, pages 3-12, New York.Steven F. Roth, Mei C. Chuah, Stephan Kerped-jiev, John A. Kolojejchick, and Peter Lucas.
1997.Towards an information visualization workspace:Combining multiple means of expression.
Human-Computer Interaction, 12(1-2):131-185.Don R. Swanson and N. R. Smalheiser.
1994.
As-sessing a gap in the biomedical literature: Mag-nesium deficiency and neurologic disease.
Neuro-science Research Communications, 15:1-9.Don R. Swanson and N. R. Smalheiser.
1997.
An in-teractive system for finding complementary litera-tures: a stimulus to scientific discovery.
ArtificialIntelligence, 91:183-203.Don R. Swanson.
1987.
Two medical iteraturesthat are logically but not bibliographically con-nected.
JASIS, 38(4):228-233.Don R. Swanson.
1991.
Complementary structuresin disjoint science literatures.
In Proceedings ofthe l~th Annual International ACM//SIGIR Con-ference, pages 280-289.John W. Tukey.
1977.
Exploratory Data Analysis.Addison-Wesley Publishing Company.Ellen M. Voorhees.
1994.
Query expansion usinglexical-semantic relations.
In Proceedings of the17th Annual International ACM//SIGIR Confer-ence, pages 61-69, Dublin, Ireland.Michael G. Walker, Walter Volkmuth, Einat Sprin-zak, David Hodgson, and Tod Klingler.
1998.Prostate cancer genes identified by genome~scaleexpression analysis.
Technical Report (unnum-bered), Incyte Pharmaceuticals, July.H.
D. White and K. W. McCain.
1989.
Bibliomet-rics.
Annual Review of Information Science andTechnology, 24:119-186.James A.
Wise, James J. Thomas, Kelly Pennock,David Lantrip, Marc Pottier, and Anne Schur.1995.
Visualizing the non-visual: Spatial analysisand interaction with information from text docu-ments.
In Proceedings of the Information Visual-ization Symposium 95, pages 51-58.
IEEE Com-puter Society Press.J.
Xu and W. B. Croft.
1996.
Query expansion us-ing local and global document analysis.
In SI-GIR '96: Proceedings of the 19th Annual Interna-tional ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 4-11, Zurich.10
