Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 90?94,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsInference of Phrase-Based Translation Modelsvia Minimum Description LengthJes?us Gonz?alez-Rubio and Francisco CasacubertaDepartamento de Sistemas Inform?aticos y Computaci?onUniversitat Polit`ecnica de Val`encia, Camino de Vera s/n, 46021 Valencia (Spain){jegonzalez, fcn}@dsic.upv.esAbstractWe present an unsupervised inference pro-cedure for phrase-based translation mod-els based on the minimum descriptionlength principle.
In comparison to cur-rent inference techniques that rely onlong pipelines of training heuristics, thisprocedure represents a theoretically well-founded approach to directly infer phraselexicons.
Empirical results show that theproposed inference procedure has the po-tential to overcome many of the prob-lems inherent to the current inference ap-proaches for phrase-based models.1 IntroductionSince their introduction at the beginning of thetwenty-first century, phrase-based (PB) transla-tion models (Koehn et al., 2003) have become thestate-of-the-art for statistical machine translation(SMT).
PB model provide a big leap in translationquality with respect to the previous word-basedtranslation models (Brown et al., 1990; Vogel etal., 1996).
However, despite their empirical suc-cess, inference procedures for PB models rely ona long pipeline of heuristics (Och and Ney, 2003)and mismatched learning models, such as the longoutperformed word-based models.
Latter stagesof the pipeline cannot recover mistakes or omis-sions made in earlier stages which forces the indi-vidual stages to massively overgenerate hypothe-ses.
This manifests as a huge redundancy in theinferred phrase lexicons, which in turn largely pe-nalizes the efficiency of PB systems at run-time.The fact that PB models usually cannot generatethe sentence pairs in which they have been trainedin, or that it is even possible to improve the perfor-mance of a PB system by discarding most of thelearned phrases are clear indicators of these defi-ciencies (Sanchis-Trilles et al., 2011).We introduce an unsupervised procedure to in-fer PB models based on the minimum descrip-tion length (MDL) principle (Solomonoff, 1964;Rissanen, 1978).
MDL, formally described inSection 2, is a general inference procedure that?learns?
by ?finding data regularities?.
MDL takesits name from the fact that regularities allow tocompress the data, i.e.
to describe it using fewersymbols than those required to describe the dataliterally.
As such, MDL embodies a form of Oc-cam?s Razor in which the best model for a givendata is the one that provides a better trade-off be-tween goodness-of-fit on the data and ?complex-ity?
or ?richness?
of the model.MDL has been previously used to infer mono-lingual grammars (Gr?unwald, 1996) and inversiontransduction grammars (Saers et al., 2013).
Here,we adapt the basic principles described in the lat-ter article to the inference of PB models.
TheMDL inference procedure, described in Section 3,learns PB models by iteratively generalizing aninitial model that perfectly overfits training data.An MDL objective is used to guide this process.MDL inference has the following desirable prop-erties:?
Training and testing are optimized upon thesame model; a basic principle of machine learn-ing largely ignored in PB models.?
It provides a joint estimation of the structure(set of bilingual phrases) and the parameters(phrase probabilities) of PB models.?
It automatically protects against overfitting byimplementing a trade-off between the expres-siveness of the model and training data fitting.The empirical evaluation described in Section 4focuses on understanding the behavior of MDL-based PB models and their specific traits.
Thatis, in contrast to a typical PB system building pa-per, we are not exclusively focused on a shortterm boost in translation quality.
Instead, we aimat studying the adequacy and future potential ofMDL as inference procedure for PB models.902 The MDL PrincipleGiven a set of data D, the MDL principle aims atobtaining the simplest possible model ?
that de-scribes D as well as possible (Solomonoff, 1964;Rissanen, 1978).
Central to MDL is the one-to-one correspondence between description lengthfunctions and probability distributions that followsfrom the Kraft-McMillan inequality (McMillan,1956).
For any probability distribution Pr(?
), itis possible to construct a coding scheme such thatthe length (in bits) of the encoded data is mini-mum and equal to?
log2(Pr(D)).
In other words,searching for a minimum description length re-duces to searching for a good probability distribu-tion, and vice versa.
Taking these considerationsinto account, MDL inference is formalized as:??
= argmin?DL(?,D) (1)= argmin?DL(?)
+ DL(D | ?)
(2)where DL(?)
denotes the description length ofthe model, and DL(D | ?)
denotes the descrip-tion length of the data given the model.
A com-plete introductory tutorial of the MDL principleand methods can be found in (Gr?unwald, 2004).3 MDL Phrase-Based Models3.1 Description Length FunctionsWe start by defining how to compute DL(?)
andDL(D | ?)
for any PB model and data set.Let Pr?
(D) be the probability of data setD according to PB model ?.
We follow theKraft-McMillan inequality and define the de-scription length of the data given the model asDL(D | ?)
= ?
log2(Pr?
(D)), which it is thelower bound for the description length of the data.Regarding the description length of the PBmodel, DL(?
), we compute it by serializing ?into a sequence of symbols and then computingthe length of the optimal encoding of such se-quence.
To do that, we need one symbol for eachword in the source and target languages, anothersymbol to separate the source and target sides ina phrase pair, and one additional symbol to dis-tinguish between the different pairs in the phraselexicon.
For example, the following toy PB modelLa|||The casa|||house azul|||blueis serialized as La|The?casa|house?azul|blue,where symbol ?
separates the phrase pairs, and |separates the two sides of each pair.
Assuming auniform distribution over the K different symbols,each symbol would require ?
log2(1K) bits to en-code.
We will thus require 3 bits to encode eachof the 8 symbols in the example, and 33 bits to en-code the whole serialized PB model (11 symbols).3.2 Inference ProcedureWe now describe how to perform the maximiza-tion in Equation (2).
In the case of PB models,this reduces to a search for the optimal phrase lex-icon.
Obviously, an exhaustive search over all pos-sible sets of phrase pairs in the data is unfeasiblein practice.
Following the ideas in (Vilar and Vi-dal, 2005), we implement a search procedure thatiteratively generalizes an initial PB model that per-fectly fits the data.
Let D = {fn, en}Nn=1be adata set with N sentence pairs, where fnare sen-tences in the source language and enare their cor-responding translation in the target language.
Ourinitial PB model will be as follows:f1||| e1?
?
?
fn||| en?
?
?
fN||| eNwhere the probability of each pair is given by thenumber of occurrences of the pair in the data di-vided by the number of occurrences of the source(or target) language sentence.To generalize this initial PB model, we needto identify parts of the existing phrase pairs thatcould be validly used in isolation.
As a result, thePB model will be able to generate new transla-tions different from the ones in the training data.From a probabilistic point of view, this processmoves some of the probability mass which is con-centrated in the training data out to other data stillunseen; the very definition of generalization.
Con-sider a PB model such as:La casa azul|||The blue houseEsta casa azul|||This blue houseEsta casa verde|||This green houseIt can be segmented to obtain a new PB model:La|||The casa azul|||blue houseEsta|||This casa verde|||green housewhich is able to generate one new sentence pair(La casa verde?The green house) and has ashorter description length (19 symbols) in compar-ison to the original model (23 symbols).
We onlyconsider segmentations that bisect the source andtarget phrases.
More sophisticated segmentationapproaches are beyond the scope of this article.Algorithm 1 describes the proposed PB infer-ence by iterative generalization.
First, we col-lect the potential segmentations of the current PB91Algorithm 1: Iterative inference procedure.input : ?
(initial PB model)output : ??
(generalized PB model)auxiliary : collect(?)
(Returns the set of possiblesegmentations of model ?)?DL(s,?)
(Returns variation in DL whensegmenting ?
according to s)sort(S) (Sorts segmentation set S byvariation in DL)commit(S,?)
(Apply segmentations in Sto ?, returns variation in DL)begin1repeat2S ?
collect(?);3candidates?
[];4for s ?
S do5???
?DL(s,?
);6if ???
0 then7candidates .append({?
?, s});8sort(candidates);9??
commit(candidates,?
);10until ?
> 0 ;11return?
;12end13model (line 3).
Then, we estimate the variation indescription length due to the application of eachsegmentation (lines 4 to 8).
Finally, we sort thesegmentations by variation in description length(line 9) and commit to the best of them (line 10).Specifically, given that different segmentationsmay modify the same phrase pair, we apply eachsegmentation only if it only affect phrase pairsunaffected by previous segmentations in S .
Thealgorithm stops when none of the segmentationslead to a reduction in description length.
Saerset al., (2013) follow a similar greedy algorithm togeneralize inversion transduction grammars.The key component of Algorithm 1 is function?DL(s,?)
that evaluates the impact of a candi-date segmentation s on the description length ofPB model ?.
That is, ?DL(s,?)
computes thedifference in description length between the cur-rent model ?
and the model ?
?that would resultfrom committing to s:?DL(s,?)
= DL(??)?DL(?
)+ DL(D | ??
)?DL(D | ?)
(3)The length difference between the phrase lexi-cons (DL(??)?DL(?))
is trivial.
We merely haveto compute the difference between the lengths ofthe phrase pairs added and removed.
The differ-ence for the data is given by ?
log2(Pr??(D)Pr?
(D)),where Pr??
(D) and Pr?
(D) are the probabilityof D according to ?
?and ?
respectively.
TheseEuTransI (Sp / En)train tune test#Sentences 10k 2k 1k#Words 97k / 99k 23k / 24k 12k / 12kVocabulary 687 / 513 510 / 382 571 / 435OOV ?
/ ?
0 / 0 0 / 0Perplexity ?
/ ?
8.4 / 3.4 8.1 / 3.3News Commentary (Sp / En)train tune test#Sentences 51k 2k 1k#Words 1.4M / 1.2M 56k / 50k 30k / 26kVocabulary 47k / 35k 5k / 5k 8k / 7kOOV ?
/ ?
390 / 325 832 / 538Perplexity ?
/ ?
136.2 / 197.9 144.2 / 206.0Table 1: Main figures of the experimental corpora.M and k stand for millions and thousands of ele-ments respectively.
Perplexity was calculated us-ing 5-gram language models.probabilities can be computed by translating thetraining data.
However, this is a very expensiveprocess that we cannot afford to perform for eachcandidate segmentation.
Instead, we estimate thedescription length of the data in closed form basedon the probabilities of the phrase pairs involved.The probability of a phrase pair {?f, e?}
is computedas the the number of occurrences of the pair di-vided by the number of occurrences of the source(or target) phrase.
We thus estimate the probabil-ities in the segmented model ?
?by counting theoccurrences of the replaced phrase pairs as occur-rences of the segmented pairs.
Let {?f0, e?0} bethe phrase pair we are splitting into {?f1, e?1} and{?f2, e?2}.
The direct phrase probabilities in ?
?willbe identical to those in ?
except that:P??
(e?0|?f0) = 0P??
(e?1|?f1) =N?
({?f1, e?1}) + N?
({?f0, e?0})N?
(?f1) + N?
({?f0, e?0})P??
(e?2|?f2) =N?
({?f2, e?2}) + N?
({?f0, e?0})N?
(?f2) + N?
({?f0, e?0})where N?(?)
are counts in ?.
Inverse probabilitiesare computed accordingly.
Finally, we computethe variation in data description length using:Pr??(D)Pr?(D)?P??
(e?1|?f1) ?
P??(e?2|?f2)P?(e?0|?f0)?P??
(?f1| e?1) ?
P??
(?f2| e?2)P?
(?f0| e?0)(4)92EUtransI News CommentaryBLEU [%]SizeBLEU [%]Size(tune/test) (tune/test)SotA 91.6 / 90.9 39.1k 31.4 / 30.7 2.2MMDL 88.7 / 88.0 2.7k 24.8 / 24.6 79.1kTable 2: Size (number of phrase pairs) of theMDL-based PB models, and quality of the gener-ated translations.
We compare against a state-of-the-art PB inference pipeline (SotA).For a segmentation set, we first estimate the newmodel ?
?to reflect all the applied segmentations,and then sum the differences in description length.4 Empirical ResultsWe evaluated the proposed inference procedureon the EuTransI (Amengual et al., 2000) and theNews Commentary (Callison-Burch et al., 2007)corpora.
Table 1 shows their main figures.We inferred PB models (set of phrase pairs andtheir corresponding probabilities) with the trainingpartitions as described in Section 3.2.
Then, weincluded these MDL-based PB models in a con-ventional log-linear model optimized with the tun-ing partitions (Och, 2003).
Finally, we generatedtranslations for the test partitions using a conven-tional PB decoder (Koehn et al., 2007).Table 2 shows size (number of phrase pairs) ofthe inferred MDL-based PB models, and BLEUscore (Papineni et al., 2002) of their translations ofthe tune and test partitions.
As a comparison, wedisplay results for a state-of-the-art (SotA) PB sys-tem (Koehn et al., 2007).
These results show thatMDL inference obtained much more concise mod-els (less than one tenth the number of phrases) thanthe standard inference pipeline.
Additionally, thetranslations of the simple EuTransI corpus were ofa similar quality as the ones obtained by the SotAsystem.
In contrast, the quality of the translationsfor News Commentary was significantly lower.To better understand these results, Figure 1 dis-plays the histogram of phrase lengths (number ofsource words plus target words) of the SotA modeland the MDL-based model for the News Commen-taries corpus.
We first observed that the length ofthe phrase pairs followed a completely differentdistribution depending on the inference procedure.Most of the phrase pairs of the MDL-based modeltranslated one source word by one target wordwith an exponential decay in frequency for longerphrase pairs; a typical distribution of events in nat-01020300  10  20  30  40  50  60  70  80Length of the phrase pair (words)Relativefrequency[%] SotAMDLFigure 1: Histogram of lengths (source plus targetwords) for the phrase pairs in the inferred models.ural language (Zipf, 1935).
Longer phrase pairs,about 45% of the total, contain sequences of wordsthat only appear once in the corpus, and thus, theycannot be segmented in any way that leads to a re-duction in description length.
Although formallycorrect, long phrase pairs generalize poorly whichexplains the comparatively poor performance ofMDL inference for the News Commentaries cor-pus.
This problem was largely attenuated for Eu-TransI due to its simplicity.5 Conclusions and Future DevelopmentsWe have described a simple, unsupervised infer-ence procedure for PB models that learns phraselexicons by iteratively splitting existing phrasesinto smaller phrase pairs using a theoreticallywell-founded minimum description length objec-tive.
Empirical results have shown that the in-ferred PB models, far from the artificial redun-dancy of the conventional PB inference pipeline,are very parsimonious and provide competitivetranslations for simple translation tasks.The proposed methodology provides a solidfoundation from where to develop new PB infer-ence approaches that overcome the problems in-herent to the long pipeline of heuristics that nowa-days constitute the state-of-the-art.
Future devel-opments in this direction will include:?
A more sophisticated segmentation procedurethat allow to divide the phrases into more thattwo segments.?
A hybrid approach where the long phrase pairsremaining after the MDL inference are furthersegmented, e.g., according to a word lexicon.?
The inclusion of lexical models in the definitionof the PB model.93AcknowledgmentsWork supported by the European Union 7thFramework Program (FP7/2007-2013) under theCasMaCat project (grans agreement no287576),by Spanish MICINN under grant TIN2012-31723,and by the Generalitat Valenciana under grantALMPR (Prometeo/2009/014).ReferencesJuan-Carlos Amengual, M. Asunci?on Casta?no, Anto-nio Castellanos, V?
?ctor M. Jim?enez, David Llorens,Andr?es Marzal, Federico Prat, Juan Miguel Vilar,Jos?e-Miguel Bened?
?, Francisco Casacuberta, Mois?esPastor, and Enrique Vidal.
2000.
The eutrans spo-ken language translation system.
Machine Transla-tion, 15(1-2):75?103.Peter F. Brown, John Cocke, Stephen A. Della Pietra,Vincent J. Della Pietra, Fredrick Jelinek, John D.Lafferty, Robert L. Mercer, and Paul S. Roossin.1990.
A statistical approach to machine translation.Computational Linguistics, 16:79?85.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2007.
(Meta-) evaluation of machine translation.
In Pro-ceedings of the Workshop on Statistical MachineTranslation, pages 136?158.Peter Gr?unwald.
1996.
A minimum description lengthapproach to grammar inference.
Connectionist, Sta-tistical, and Symbolic Approaches to Learning forNatural Language Processing, pages 203?216.Peter Gr?unwald.
2004.
A tutorial introduc-tion to the minimum description length principle.http://arxiv.org/abs/math/0406077.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the North American Chapter of the As-sociation for Computational Linguistics on HumanLanguage Technology, pages 48?54.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proceedings of the Association for ComputationalLinguistics, demonstration session, June.Brockway McMillan.
1956.
Two inequalities impliedby unique decipherability.
IRE Transactions on In-formation Theory, 2(4):115?116.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of theMeeting on Association for Computational Linguis-tics, pages 160?167.
Association for ComputationalLinguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic eval-uation of machine translation.
In Proceedings of theMeeting on Association for Computational Linguis-tics, pages 311?318.
Association for ComputationalLinguistics.Jorma Rissanen.
1978.
Modeling by shortest data de-scription.
Automatica, 14(5):465 ?
471.Markus Saers, Karteek Addanki, and Dekai Wu.
2013.Iterative rule segmentation under minimum descrip-tion length for unsupervised transduction grammarinduction.
In Statistical Language and Speech Pro-cessing, volume 7978 of Lecture Notes in ComputerScience, pages 224?235.
Springer.Germ?an Sanchis-Trilles, Daniel Ortiz-Mart?
?nez, Jes?usGonz?alez-Rubio, Jorge Gonz?alez, and FranciscoCasacuberta.
2011.
Bilingual segmentation forphrasetable pruning in statistical machine transla-tion.
In Proceedings of the 15th Conference of theEuropean Association for Machine Translation.Ray Solomonoff.
1964.
A formal theory of inductiveinference, parts 1 and 2.
Information and Control,7:1?22, 224?254.Juan Miguel Vilar and Enrique Vidal.
2005.
A recur-sive statistical translation model.
In Proceedings ofthe ACL Workshop on Building and Using ParallelTexts, pages 199?207.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statisticaltranslation.
In Proceedings of the 16th conferenceon Computational linguistics, pages 836?841.George Kingsley Zipf.
1935.
The Psychobiology ofLanguage.
Houghton-Mifflin.94
