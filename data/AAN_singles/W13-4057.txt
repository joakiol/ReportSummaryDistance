Proceedings of the SIGDIAL 2013 Conference, pages 360?362,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsOpen-Domain Information Access with Talking RobotsKristiina Jokinen and Graham WilcockUniversity of Tartu, Estonia and University of Helsinki, Finlandkjokinen@ut.ee, graham.wilcock@helsinki.fiAbstractThe demo shows Wikipedia-based open-domain information access dialogues witha talking humanoid robot.
The robot usesface-tracking, nodding and gesturing tosupport interaction management and thepresentation of information to the partner.1 IntroductionThe demo shows open-domain information accessdialogues with the WikiTalk system on a Naohumanoid robot (Jokinen and Wilcock, 2012b).An annotated video of the demo can be seenat https://docs.google.com/file/d/0B-D1kVqPMlKdOEcyS25nMWpjUG8.The WikiTalk system can be viewed from twocomplementary perspectives: as a spoken dialoguesystem or as a question-answering (QA) system.Viewed as a spoken dialogue system, WikiTalksupports constructive interaction for talking aboutinteresting topics (Jokinen and Wilcock, 2012a).However, using Wikipedia as its knowledge sourceinstead of a finite database means that WikiTalkis completely open-domain.
This is a significantbreakthrough compared with traditional closed-domain spoken dialogue systems.Viewed as a QA system, WikiTalk providesWikipedia-based open-domain knowledge access(Wilcock, 2012).
However, by using sentencesand paragraphs from Wikipedia, the system is ableto talk about the topic in a conversational manner,thus differing from a traditional QA system.The Nao robot prototype version of WikiTalkwas implemented by Csapo et al(2012) duringeNTERFACE 2012, the 8th International SummerWorkshop on Multimodal Interfaces at Supe?lec inMetz (Figure 1).
The humanoid robot uses face-tracking, nodding and gesturing to support interac-tion management and the presentation of new in-formation to the partner (Han et al 2012; Meenaet al 2012).Figure 1: Working with the Nao humanoid robot.2 Outline of the systemAt the heart of the system (Figure 2) is a conver-sation manager based on a finite state machine.However, the states are not based on the domain-specific tasks and utterences for a fixed domain.In WikiTalk, the states function at a more abstractdialogue management level dealing for examplewith topic initiation, topic continuation, and topicswitching.
Further details of this approach aregiven by Wilcock (2012).The finite state machine also has extensions thatstore various parameters of past interactions andinfluence the functionality of the state machine.The conversation manager communicates with aWikipedia manager to obtain information fromWikipedia, and a Nao manager to map its statesonto the actions of the robot.To enable the robot to react to various eventswhile getting information from Wikipedia, theNao manager registers events and alerts the appro-priate components of the system when anything ofinterest occurs either on the inside or the outsideof the system.
Figure 2 shows three examples of360Figure 2: The system architecture, from (Csapo et al 2012).event handling within the Nao Talk module whichdrives the robot?s speech functionality.
The func-tions isSaying(), startOfParagraph(),and endOfSentence() are called periodicallyby the Nao manager, and return True whenever therobot is talking, reaches the start of a paragraph, orfinishes a sentence, respectively.
Whenever suchevents occur, the Nao manager can trigger appro-priate reactions, for example, through the Gesturesmodule which drives the robot?s nodding and ges-turing functionalities.The history of the user?s interactions is stored ina statistics dictionary in the conversation manager.Using a set of simple heuristics, it is possible tocreate more interesting dialogues by ensuring thatthe robot does not give the same instructions to theuser in the same way over and over again, and byvarying the level of sophistication in terms of thefunctionalities that are introduced to the user bythe robot.
For example, at first the robot gives sim-ple instructions, allowing the user to practice andunderstand the basic functionalities of the system.For more advanced users, the system suggests newkinds of use cases which may not have previouslybeen known to the user.A corpus of videos of user trials with the system(Figure 3) was collected at the eNTERFACE 2012workshop.
The user trials and user questionnaireswere used for system evaluation, which is reportedby Anastasiou et al(2013).3 Outline of the demoThe demo is deliberately live, unscripted, and im-provised.
However, it typically starts with therobot in a sitting position.
The robot stands up andgreets the user, then asks what topic the user wantsto hear about.
The robot suggests some of its ownfavourite topics.When the user selects a topic, the system getsinformation about the topic from Wikipedia anddivides it into chunks suitable for spoken dialoguecontributions.
The system then manages the spo-ken presentation of the chunks according to theuser?s reactions.
If the user asks for more, or oth-erwise shows interest in the topic, the system con-tinues with the next chunk.Crucially, the system makes smooth topic shiftsby following the hyperlinks in Wikipedia when-ever the user repeats the name of one of thelinks.
For example, if the system is talking aboutShakespeare and says ?Shakespeare was born inStratford-upon-Avon?, the user can say ?Stratford-upon-Avon??
and the system smoothly switchestopics and starts talking about Stratford-upon-Avon using the Wikipedia information about thisnew topic.The user can ask for any chunk to be repeated,or go back to the previous chunk.
The user canalso interrupt the current chunk and ask to skip toanother chunk on the same topic.361Figure 3: Testing spoken interaction with Nao.The user can interrupt the robot at any time bytouching the top of the robot?s head.
The robotstops talking and explicitly acknowledges the in-terruption by saying ?Oh sorry!?
and waiting forthe user?s input.
The user can then tell it to con-tinue, to go back, to skip to another chunk, or toswitch to a new topic.The dialogue is open-domain and typicallywanders freely from topic to topic by smooth topicshifts following the links in Wikipedia.
However,if the user wants to jump to an entirely unrelatedtopic, an awkward topic shift can be made by say-ing the command ?Alphabet!?
and spelling thefirst few letters of the new topic using a spellingalphabet (Alpha, Bravo, Charlie, etc.
).As well as talking about topics selected by theuser, the robot can take the initiative by suggestingpotentially interesting new topics.
One way to dothis is by using the ?Did you know ...??
sectionsfrom Wikipedia that are new every day.The demo ends when the user tells the robot tostop.
The robot thanks the user and sits down.4 Previous demosThe system was first demonstrated in July 2012 atthe 8th International Summer Workshop on Multi-modal Interfaces (eNTERFACE 2012) in Metz.An annotated video of this demo can be seenat https://docs.google.com/file/d/0B-D1kVqPMlKdOEcyS25nMWpjUG8.The system was also demonstrated at the 3rdIEEE International Conference on Cognitive Info-communications (CogInfoCom 2012).AcknowledgementsWe thank Adam Csapo, Emer Gilmartin, JonathanGrizou, Frank Han, Raveesh Meena and DimitraAnastasiou for their collaboration, both on the NaoWikiTalk implementation and on the user evalua-tions conducted at eNTERFACE 2012.We also thank Supe?lec and especially ProfessorOlivier Pietquin for providing the Nao robots bothfor the eNTERFACE 2012 workshop and for theSIGDIAL-2013 demo.ReferencesDimitra Anastasiou, Kristiina Jokinen, and GrahamWilcock.
2013.
Evaluation of WikiTalk - user stud-ies of human-robot interaction.
In Proceedings of15th International Conference on Human-ComputerInteraction (HCII 2013), Las Vegas, USA.Adam Csapo, Emer Gilmartin, Jonathan Grizou, Jing-Guang Han, Raveesh Meena, Dimitra Anastasiou,Kristiina Jokinen, and Graham Wilcock.
2012.Multimodal conversational interaction with a hu-manoid robot.
In Proceedings of 3rd IEEE Interna-tional Conference on Cognitive Infocommunications(CogInfoCom 2012), pages 667?672, Kosice.JingGuang Han, Nick Campbell, Kristiina Jokinen, andGraham Wilcock.
2012.
Investigating the use ofnon-verbal cues in human-robot interaction with aNao robot.
In Proceedings of 3rd IEEE Interna-tional Conference on Cognitive Infocommunications(CogInfoCom 2012), pages 679?683, Kosice.Kristiina Jokinen and Graham Wilcock.
2012a.
Con-structive interaction for talking about interestingtopics.
In Proceedings of Eighth InternationalConference on Language Resources and Evaluation(LREC 2012), Istanbul.Kristiina Jokinen and Graham Wilcock.
2012b.
Multi-modal open-domain conversations with the Naorobot.
In Fourth International Workshop on SpokenDialogue Systems (IWSDS 2012), Paris.Raveesh Meena, Kristiina Jokinen, and GrahamWilcock.
2012.
Integration of gestures and speechin human-robot interaction.
In Proceedings of 3rdIEEE International Conference on Cognitive Info-communications (CogInfoCom 2012), pages 673?678, Kosice.Graham Wilcock.
2012.
WikiTalk: A spokenWikipedia-based open-domain knowledge accesssystem.
In Proceedings of the COLING 2012 Work-shop on Question Answering for Complex Domains,pages 57?69, Mumbai.362
