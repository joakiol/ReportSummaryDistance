Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 46?52,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsA hybrid framework for scalable Opinion Mining in Social Media:detecting polarities and attitude targetsCarlos Rodr?guez-PenagosBarcelona Media Innovaci?Av.
Diagonal 177Barcelona, Spaincarlos.rodriguez@barcelonamedia.orgJens GrivollaBarcelona Media Innovaci?Av.
Diagonal 177Barcelona, Spainjens.grivolla@barcelonamedia.orgJoan Codina Fib?Barcelona Media Innovaci?Av.
Diagonal 177Barcelona, Spainjoan.codina@barcelonamedia.orgAbstractText mining of massive Social Mediapostings presents interesting challenges forNLP applications due to sparseinterpretation contexts, grammatical andorthographical variability as well as its veryfragmentary nature.
No singlemethodological approach can be expected towork across such diverse typologies astwitter micro-blogging, customer reviews,carefully edited blogs, etc.
In this paper wepresent a modular and scalable frameworkto Social Media Opinion Mining thatcombines stochastic and symbolictechniques to structure a semantic space toexploit and interpret efficiently.
Wedescribe the use of this framework for thediscovery and clustering of opinion targetsand topics in user-generated comments forthe Telecom and Automotive domains.1 IntroductionSocial Media (SM) postings constitute a messyand highly heterogeneous media that nonethelessrepresent a highly valuable source of informationabout the attitudes, interests and expectations ofcitizens and consumers everywhere.
This fact hasdriven a trove of recent research anddevelopment efforts aimed at managing andinterpreting such information for a widespectrum of commercial applications, amongthem: reputation management, branding,marketing design, etc.
A diverse array oftechniques representing the state of the art runthe gamut from knowledge-engineered rule-andlexicon-base approaches that (when carefullycrafted) provide high precision in homogeneouscontexts, to wide-coverage machine learningapproaches that (when suitable development datais available) tackle noisy text with reasonableaccuracies in some genres.As SM channels are as different from eachother as, say, spoken text from essay writing, webelieve that no single technique, powerful as itmay be, is capable of interpreting all domains,genres and channels in the vast universe of SMconversations.
Faced with an industrial demandfor simultaneous monitoring of heterogeneousopinion sources, our approach has evolved intocombining diverse NLP technologies into arobust semantic analysis framework to create ahigh-granularity representation of user-generatedcommentaries amenable to machineinterpretation.Analysis of Telecom-related social postingshas shown how a modular and scalable analysisframework can combine a veritable arsenal ofNLP and data mining techniques into a hybridapplication that adapts well to the uniquechallenges and demands of different SocialMedia genres.Section 2 will present the UIMA-Solrframework and components used to processopinionated text, as well as discuss therepresentational choices made for analysis.Section 3 will frame our approach within theState-of-the-Art of Sentiment analysis andOpinion mining as we interpret it, while Sections4 and 5 describe data and results of theapplication of our proposed approach in thecontext of opinion topic detection and clusteringof SM postings in the Telecoms and Automobiledomains respectively, and with different textualgenres.
Finally, Section 6 will focus on theconclusions and future work that presents to us atthis point.462 A modular toolset for SM processingFor semantic processing of our data we use aUIMA 1  (Ferrucci & Lally, 2004) architectureplus Solr-based clustering and indexingcapabilities.
Our choice of UIMA is guided inpart by our wish to achieve good scalability androbustness, and that all components can beimplemented modularly and in a distributedmanner using UIMA-AS (Asynchronous Scaleout).
Also, UIMA?s data representation as CASobjects allows preserving the documents integritysince annotations are added as standoff metadata,without modifying the original information.Under the UIMA architecture, a hybrid NLPanalysis framework is possible, combiningpowerful Machine Learning modules likeMaximum Entropy (ME, OpenNLP) 2  orConditional Random Fields (CRF, JulieLab), 3with gazetteer and regular expression matchersand rule-based Noun Phrase chunkers.
The basiclinguistic processing has a sentence and tokenidentifier, a POS tagger, a lemmatizer, a NPchunker and a dependency parser.
In addition, weemploy gazetteers to match products, companies,and other entities in text, as well as a hand-crafted lexicon of polar terms created fromcorpus exploration of Telecom domain text, aswell as a regular expression module to detectemoticons when available.
Also, two models forNamed-Entity recognition were applied usingCRF: one trained on conventional ENAMEXNamed Entity Recognition and Classificationentities, and another trained using data fromcustomer reviews from various domains (Cars,Banking, and Mobile service providers), in orderto detect opinion targets and cues.
One of theobjectives of this relatively straightforwardprocessing (although by no means the only one),was to select candidates for classifiers that couldidentify both the specific subject of each opinionexpressed in text, as well as capture a moregeneral topic of the whole conversation (whichconceivably could coincide or not with one of thespecific opinion targets).
Targets and topics areusually expressed as entity names, concepts orattributes, and thus can appear in language asnoun, adjectival, adverbial or even verbalphrases.
Opinion cues (or Q-elements) are words,emoticons and phrases that convey the actualattitude of the speaker towards the topics and1 Unstructured Information Management Architecture2 http://maxent.sourceforge.net3 http://www.julielab.detargets, and a strength and polarity can beattributed to them, both a priori and in context.Our modular processing approach allowscustomizing the annotation for each domain orgenre, since, for example, regular expressions todetect emoticons will be useful for twitter micro-blogging, but less so for more conventional blogswhere such sentiment-expression devices are lessfrequent; Also pre-compiled lists of knownentities can provide good target precision whilecustomised distributional models will helpdiscover unlisted names and concepts in text.The output of the semantic and syntacticprocessing pipeline is indexed using the ApacheSolr framework,4 which is based on the Luceneengine.
This setup allows the implementation ofclustering and classification algorithms, allowingus to obtain reliable statistical correlationsbetween documents and entities.We also developed or adapted a number ofvisualization components in order to present thedata stored in Solr in an interactive page that isconducive to data exploration and discovery bythe system?s corporate users.
At the same time,Carrot2 is connected to Solr and is used to testclustering conditions and algorithms, providing anice visualization interface.
Carrot2 is an opensource search results clustering engine (Osi?ski& Weiss, 2005).
It can automatically organizecollections of documents into thematiccategories.3 Previous workTwo good overviews of general Opinion Miningand Sentiment Analysis challenges are Pang &Lee (2008) and, focused specifically on customerreviews, Bhuiyan, Xu & Josang (2009).Detecting the subject or targets of opinions is oneof the main lines of work within OpinionMining, and considerable effort has been put intoit, since it has been shown to be a highly-domainspecific task (consumer reviews will focus onspecific products and features, tweets havehashtags to identify topics, blogs can talk almostabout anything, etc.
).Outside of user-generated content, Coursey,Mihalcea, & Moen (2009) have suggested usingindirect semantic resources, such as theWikipedia, to identify document topics.
ForOpinion Mining genres, and extending on Hu &Liu (2004), Popescu & Etzioni (2005) use acombination of Pointwise Mutual Information,4 http://lucene.apache.org/solr/47relaxation labeling and dependency analysis toextract possible targets and features in productreviews.
Kim & Hovy (2006), for example, usethematic roles to establish a relation betweencandidate opinion holders and opinion topics,while exploiting clustering to improve coveragein their role-labeling.
Recent approaches haveincluded adaptation of NER techniques to noisyand irregular text, either by using learningalgorithms or by doing text normalization (Locke& Martin, 2009; Ritter, Clark & Etzioni, 2011).4 Exploring the semantic space ofTelecom-related online postingsWe collected close to 200,000 postings fromvarious SM sources in a 4 month timeframe,including fairly carefully-written product-oriented forums, blogs, etc., as well as morecasually-drafted Facebook and twitter micro-blogging, that discussed Spanish Telecom?sservices and products.
Of these, we randomlysub-selected a representative 190-documentsample that was manually marked-up (for a testinvolving machine learning of cue-polarity-targetrelationships) by two different human annotatorswith a 20-document overlap, using simplifiedannotation guidelines focused on opinion targets,topics, cues and polarities.
An interestingobservation about the interannotator agreement(but one we can?t discuss in detail here) is thatwith regard to targets one of the humanannotators tended more towards completesyntactic units (noun phrases), while the otherchose more conceptual and semantic extensionsas subjects for the opinions.
The 20-documentoverlap was meant to help us evaluate thisguideline development process, but themisalignment of guideline interpretation by thetwo human annotators made it very difficult tomeasure any kind of true interannotatoragreement.
Also, single annotation adjudicationwas made difficult due to the fact that bothinterpretations presented valid aspects, and wechose to use each set as an independentevaluation set to detect any unnoticed patternsthat could emerge from using one of the other inour training and validation, but those results areinconclusive and merit further research.
Since noadjudicator was incorporated in the process toresolve disagreements, the final annotated sets donot constitute a true Gold Standard, but eachhuman-annotated set was used in turn as abenchmark against automatic annotators.Content elicitation was combined with activityand network mining for an enriched overview ofthe social conversation ecosystems, but thesecond aspect won?t be discussed here for thesake of brevity.
For the same reason, althoughother aspects of sentiment analysis wereperformed on this data (cue and polaritydetection, for example), we will also restrict thescope of these discussions on the detection andclustering of specific targets and general topicsof the opinions expressed in such SM channels.Obviously, a deeper and more textured view ofopinionated text is needed to be of any real use,but the overall features, shortcomings andadvantages of our chosen approach areadequately discussed even if we restrict thispaper to these very specific tasks.The first series of experiments about clusteringusing semantics explored the above-mentionedcorpus of SM posting that discussed a SpanishTelecom, one of the aims being detecting andaggregating the topics and targets of onlineopinions.
Different processing modules gearedtowards topic and target detection werecompared against each human annotator?schoices, but also against each other and to thecombined output of each.
The main modulesinvolved were: (A) generic NERC,  (B) a targetand topic NERC model (StatTarg), (C) a NounPhrase Chunker, and (D) a Gazetteer matcher(Taxonomy).
Figures 1 through 4 show,respectively, recall (1) and precision (2) withregard to human annotated topics, and recall (3)and precision (4) with regard to human annotatedtargets.The results presented here are the overallperformance across genres and domains, sincethe 190 documents annotated covered the wholerange from forums to tweets.Figure 1.
Topic recall48Figure 2.
Topic precisionFigure 3.
Target recallFigure 4.
Target precisionFor this experiment, and as a guideline for thehuman annotators, targets were roughly definedas occurrences in the text of objects of opinion,whereas topics where to represent the main focusof the document or message.
The annotatorsusually marked one topic per document, whichwas almost always also one of the targets.The customized taxonomy has a good precisionwith regard to target and topic identification,while the NERC and NP Chunk approachesimprove the recall but suffer a bit on precision.Generic NER models have a moderately highprecision (63%) with regard to manuallyannotated targets but rather low recall (speciallyin genres where capitalization is irregular whichhinders NER detection), while NP Chunkspresent the opposite case: moderately (56%) highrecall with low precision.
This can be explainedin part by the ?greediness?
of each methodology,with the chunker annotating extensively whilethe NERC model being much more selective.Another noteworthy result is the strong domainbias of target annotators trained on a Ciaocustomer reviews for Banking, Automotive andMobile Service markets.
The modelsimplemented through training from multi-domainreview sites were found to have mediumprecision, but very low recall.The combination of all modules (AllTargets, acombination of NERC, Chunker, Taxonomy andStatTarget) had a very high recall of around 90%.With regard to topic detection, the combinationof all modules had a recall of 94% and 83%,depending on which gold standard it is comparedto (the one created by one expert humanannotator or the other), which is an excellentrecall level.
The precision obtained on topicdetection is very low.
This, however, is expectedas the evaluation is done using all candidatesgiven by the different annotation layers, with noselection process.
Since most of the topics arealready identified as targets, the key issue here isto identify which of the comment targets is themain topic.It is important to note that merging the Chunkeroutput with that of the rest of the modulesimproves the recall of the system but theprecision becomes low.
The main reason is thatmost targets and topics are noun phrases, but notall noun phrases are targets or topics.It is important to note that combining the outputof different annotation layers (except for the NPchunker) does not reduce overall precision, whilegreatly increasing recall.For the clustering experiments, we choseCarrot2?s Lingo, a clustering algorithm based onSingular Value Decomposition.
We envisionedthe content-based clustering as an interactiveexploratory tool, rather that providing a single?correct?
and definitive set of groupings.
Clusteranalysis as such is not an automatic task, but aniterative process of knowledge discovery thatinvolves trial and failure.
It will often benecessary to modify the preprocessing and adjustparameters until the result achieves the desiredproperties.The  query ?problem?, for example, sent tosome of the telecom forums in May producedgroupings suggestive of complaints relating torates, internet access, SIM chips, SMS, as well aswith regard to specific terminal models andcompanies.
Even this limited capability can behelpful for some of our user?s market analysispurposes.49The visualization of query-based clusteringwith detection of target, cues and topics, and thepossibility of tracking trends over time, provideda very powerful overview of how consumerattitudes, expectations and complaints aboutproducts and services are reflected in dynamicinterchanges in various SM channels.
Theseresults are available through an online demo 6(Figure 5, shown for Facebook postings).5 Visualizing the evolution of customeropinionIn addition to exploring SM data for the Telecomdomain, we performed some experiments usingclustering without directly using annotatedsemantics, but instead using the semantics onlyfor data interpretation.
We crawled more than10,000 customer reviews in the automotivedomain in Spanish, along with some metadatathat included the numerical ratings added by thereviewers themselves.
Using our modularpipeline, we did shallow document clusteringfollowed by linguistic processing that includedlemmatization, POS tagging and Named EntityRecognition, in order to allow for analyticalexploitation of the community-driven discussionon automobiles, product features and6 http://webmining.barcelonamedia.org/Orange/automakers.
The most relevant nouns, adjectives,bigrams and named entities from a given query,are projected into a polarity versus time dynamicmap.
The clustering was performed by thecombined use of vector space reductiontechniques and the K-means classificationparadigm in a completely unsupervised manner.Clusters thus obtained were represented by setsof words that best described them to obtain aview of the emerging terms, trends and featurescontained in the opinions, with the aim ofproviding a representation of their collectivecontent.
Since evaluating clustering techniquesper se was not the objective of theseexperiments, and since a gold standard was notavailable, the purpose of the system was (A) tovalidate the coherence of the groupingsaccording to the review?s content, and (B) assessif those clusters also aggregate as well alongdeclared global polarity.
Although inconclusivefrom a quantitative point of view, thoseexperiments show the feasibility of leveragingexisting Social Media resources in order todevelop applications that can visualize andexplore the semantic ecosystem of consumeropinions and attitudes, in a cost-effective andefficient manner.
A demo of the functionalitiesof the system described here is also publiclyFigure 5.
Facebook's "Iphone" semantic exploration (screenshot)50available.
7 .
One cluster, a very positive one(based on the average user rating), is representedby the terms land-terreno-todoterreno-rover-campo-4x4 (off-road, field, ground, land, Rover),while another one, aceite-garant?a-servicio-problemas-a?os (oil-warranty-service-problems-years), in the lower right side might indicateunhappy reviewers.6 Conclusion and future workThe results obtained on the Telecom corpus withdifferent automatic annotation layers suggest thata possible improvement in the system couldcome from researching which combinations ofautomatic annotators can enhance overallperformance, as one module?s strength mightcomplement another weaknesses and vice versa,so that what one is missing another one cancatch.
An additional option to increase overallrecall is to implement a weighted voting schemeamong the modules, allowing calculation ofprobabilities from the combinations of variousannotations that overlap a textual segment.The fact that combination of annotation layersthrough simple merging of all annotations hassuch a great impact on recall while not reducingprecision suggests that the different methods arevery complementary.
We expect to be able totrade off some of the gained recall for muchimproved precision by applying moresophisticated merging methods.Another possibility to be explored is using toplevel dependencies (such as SUBJECT,SENTENCE, etc.)
to rank and select the maintopic and target candidates using sentencestructure configuration.
This approach wouldalso ensure that once a polarity-laden cue isidentified, the corresponding target could beuniquely identified.
This linguistics-heavyapproach is feasible only in texts whosecharacteristics more closely resemble the dataused to train the parser.Our work has helped us focus more clearly manyof the challenges faced by any NLP system whenused in a new user-generated content: scarcedevelopment data, novel pattern and formadaptability, tool robustness, and scalability tomassive and noisy text.One of the lessons learned during theseexperiences is that keeping a modular hybridanalysis framework can improve matching byeither customizing the pipeline to each genre and7 http://webmining.barcelonamedia.org/cometa/index_datestask requirements, or by combining the results ofdifferent approaches to benefit from each one?sstrengths while minimizing each one?sweaknesses.
Extracting opinion centeredinformation from highly heterogeneous text andfrom multitudes of authors will never be asstraightforward as, say, doing IE on newswire orfinancial news, but it should be feasible anduseful by using the right toolset.
We are in theprocess of using crowdsourcing to fully annotatevast Spanish and English corpora of opinionatedtext, which will allow us to perform a better andmore fine-grained quantitative analysis of ourframework in the near future.Another lesson learned is that even if high-precision opinion classification is not available(because not enough development data isavailable, or data is noisy, or for whatever otherreason) doing even superficial semanticannotation of the text and unsupervisedclustering can help industrial consumer of thesetechnologies understand better what is being saidin the Social Media ecosystems.
Valuableobjectives for a useful opinion mining system donot need to include all possible analyses or state-of-the-art performance.Going forward, computational exploitation ofSocial Media and of community-based, data-driven discussions on diverse topics and productsis definitely an important facet of future marketand business intelligence competencies, sincemore and more of our activities as citizens,friends and consumers take place in an onlineenvironment, where everything seems possiblebut where also everything we do leaves a traceand has a meaning.
Extracting the semantics ofcollective action enables us to access thatmeaning.ReferencesRitter A, Clark S, Mausam, and Etzioni O (2011).Named Entity Recognition in Tweets: AnExperimental Study.
Proceedings of the 2011Conference on Empirical Methods in NaturalLanguage Processing (EMNLP 2011)Bhuiyan, T., Xu, Y., & Josang, A.
(2009).
State-of-the-Art Review on Opinion Mining from OnlineCustomers?
Feedback.
Proceedings of the 9th Asia-Pacific Complex Systems Conference (pp.
385?390).Coursey, K., Mihalcea, R., & Moen, W. (2009).
Usingencyclopedic knowledge for automatic topicidentification.
Proceedings of the ThirteenthConference on Computational Natural LanguageLearning, CoNLL  ?09 (pp.
210?218).
Stroudsburg,51PA, USA: Association for ComputationalLinguistics.Ferrucci, D., & Lally, A.
(2004).
UIMA: anarchitectural approach to unstructured informationprocessing in the corporate research environment.Natural Language Engineering, 10(3-4), 327?348.Hu, M., & Liu, B.
(2004).
Mining and summarizingcustomer reviews.
Proceedings of the tenth ACMSIGKDD international conference on Knowledgediscovery and data mining (pp.
168-177).
Seattle,WA, USA: ACM.
doi:10.1145/1014052.1014073Kim, S. M., & Hovy, E. (2006).
Extracting opinions,opinion holders, and topics expressed in onlinenews media text.
Proceedings of the Workshop onSentiment and Subjectivity in Text (pp.
1?8).Locke, B., & Martin, J.
(2009).
Named entityrecognition: Adapting to microblogging.
Universityof Colorado.Osi?ski and D. Weiss (2005), ?Carrot 2: Design of aflexible and efficient web information retrievalframework,?
Advances in Web Intelligence, pp.439?444, 2005.Pang, B., & Lee, L. (2008).
Opinion mining andsentiment analysis.
Foundations and Trends inInformation Retrieval, 2(1-2), 1?135.Popescu, A. M., & Etzioni, O.
(2005).
Extractingproduct features and opinions from reviews.Proceedings of HLT/EMNLP (Vol.
5, pp.
339?346).52
