Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 974?983, Dublin, Ireland, August 23-29 2014.A Framework for Translating SMS MessagesVivek Kumar Rangarajan Sridhar, John Chen, Srinivas Bangalore, Ron ShachamAT&T Labs1 AT&T Way, Bedminster, NJ 07921vkumar,jchen,srini,rshacham@research.att.comAbstractShort Messaging Service (SMS) has become a popular form of communication.
While it ispredominantly used for monolingual communication, it can be extremely useful for facilitatingcross-lingual communication through statistical machine translation.
In this work we present anapplication of statistical machine translation to SMS messages.
We decouple the SMS transla-tion task into normalization followed by translation so that one can exploit existing bitext re-sources and present a novel unsupervised normalization approach using distributed representa-tion of words learned through neural networks.
We describe several surrogate data that are goodapproximations to real SMS data feeds and use a hybrid translation approach using finite-statetransducers.
Both objective and subjective evaluation indicate that our approach is highly suitablefor translating SMS messages.1 IntroductionThe preferred form of communication has been changing over time with advances in communicationtechnology.
The majority of the world?s population now owns a mobile device and an ever increasingfraction of users are resorting to Short Message Service (SMS) as the primary form of communication.SMS offers an easy, convenient and condensed form of communication that is being embraced bythe younger demographic.
Due to the inherent limit in the length of a message that can be transmitted,SMS users have adopted several shorthand notations to compress the message; some that have becomestandardized and many that are invented constantly.
While SMS is predominantly used in a monolingualmode, it has the potential to connect people speaking different languages.
However, translating SMSmessages has several challenges ranging from the procurement of data in this domain to dealing withnoisy text (abbreviations, spelling errors, lack of punctuation, etc.)
that is typically detrimental to trans-lation quality.
In this work we address all the elements involved in building a cross-lingual SMS servicethat spans data acquisition, normalization, translation modeling, messaging infrastructure and user trial.The rest of the paper is organized as follows.
In Section 4, we present a variety of channels throughwhich we compiled SMS data followed by a description of our pipeline in Section 5 that includes nor-malization, phrase segmentation and machine translation.
Finally, we describe a SMS translation servicebuilt using our pipeline in Section 6 along with results from a user trial.
We provide some discussion inSection 7 and conclude in Section 8.2 Related WorkOne of the main challenges of building a machine translation system for SMS messages is the lack oftraining data in this domain.
Typically, there are several legal restrictions in using consumer SMS datathat precludes one from either using it completely or forces one to use it in limited capacity.
Only ahandful of such corpora are publicly available on the Web (Chen and Kan, 2013; Fairon and Paumier,2006; Treurniet et al., 2012; Sanders, 2012; Tagg, 2009); they are limited in size and restricted to a fewlanguage pairs.The NUS SMS corpus (Chen and Kan, 2013) is probably the largest English SMS corpus consisting ofaround 41000 messages.
However, these messages are characteristic of Singaporean chat lingo and notan accurate reflection of SMS style in other parts of the world.
A corpus of 30000 French SMS messagesThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/974was collected in (Fairon and Paumier, 2006) to study the idiosyncrasies of SMS language in comparisonwith standard French.
More recently, (Pennell and Liu, 2011) have used twitter data as a surrogatefor SMS messages.
Most of these previous efforts have focused on normalization, i.e., translation ofSMS text to canonical text while we are interested in translating SMS messages from one language intoanother (Eidelman et al., 2011).Several works have addressed the problem of normalizing SMS text.
A majority of these works haveused statistical machine translation (character-level) to translate SMS text into standard text (Pennell andLiu, 2011; Aw et al., 2009; Kobus et al., 2008).
(Beaufort et al., 2010) used a finite-state frameworkto learn the mapping between SMS and canonical form.
A beam search decoder for normalizing socialmedia text was presented in (Wang and Tou Ng, 2013).
All these approaches rely on supervised train-ing data to train the normalization model.
In contrast, we use an unsupervised approach to learn thenormalization lexicon of word forms in SMS to standard text.While several works have addressed the problem of normalizing SMS using machine translation, therehas been little to no work on the translation of SMS messages across languages on a large scale.
Machinetranslation of instant messages from English-to-Spanish was proposed in (Bangalore et al., 2002) wheremultiple translation hypotheses from several off-the-shelf translation engines were combined using con-sensus decoding.
However, the approach did not consider any specific strategies for normalization andthe fidelity of training bitext is questionable since it was obtained using automatic machine translation.Several products that enable multilingual communication with the aid of machine translation in con-ventional chat, email, etc., are available in the market.
However, most of these models are trained onrelatively clean bitext.3 Problem FormulationThe objective in SMS translation is to translate a foreign sentence fsms= fsms1, ?
?
?
, fsmsJinto target(English) sentence e = eI1= e1, ?
?
?
, eI.
In general it is hard to procure such SMS bitext due to lackof data and high cost of annotation.
However, we typically have access to bitext in non-SMS domain.Let f = f1, ?
?
?
, fJbe the normalized version of the SMS input sentence.
Given fsms, we choose thesentence with highest probability among all possible target sentences,?e(fsms) = argmaxe{P(e|fsms)} (1)P (e|fsms) ?
P (e)?fP (fsms, f |e) (2)= P (e)?fP (fsms|f , e)P (f |e) (3)If one applies the max-sum approximation and assumes that P (fsms|f , e) is independent of e,?e(fsms) = argmaxeP (f?|e)P (e) (4)where f?= argmaxfP (fsms|f).
Hence, the SMS translation problem can be decoupled into normal-ization followed by statistical machine translation1.4 DataTypically, one has access to a large corpus of general bitext {f , e} while data from the SMS domain{fsms, e} is sparse.
Compiling a large corpus of SMS messages is not straightforward as there areseveral restrictions on the use of consumer SMS data.
We are not aware of any large monolingual orbilingual corpus of true SMS messages besides those mentioned in Section 2.
To compile a corpus ofSMS messages, we used three sources of data: transcriptions of speech-based SMS collected through1One can also use a lattice output from the normalization to jointly optimize over e and f975smartphones, data collected through Amazon Mechanical Turk2and Twitter3as a surrogate for SMS-like messages.
We describe the composition of each of these data sources in the following subsections.Corpus Message #count Corpus Message #counti love you 988157 ily2hello 881635 n a meetinghi 607536 Amazon Mechanical Turk check facebook N/Ahow are you 470999 kewlSpeech SMS what?s up 251044 call u n a fewwhat are you doing 218289 lol 472556where are you 191912 Twitter haha 232428call 191430 lmao 102018lol 105618 omg 709504how?s it going 102977 thanks for the rt 300254Table 1: Examples of English messages collected from various sources in this work4.1 Speech-based SMSIn the absence of access to a real feed of SMS messages, we used transcription of speech-based SMSmessages collected through a smartphone application.
A majority of these messages were collectedwhile the users used the application in their cars.
We had access to a total of 41.3 million English and2.4 million Spanish automatic transcriptions.
To avoid the use of erroneous transcripts, we sorted themessages by frequency and manually translated the top 40,000 English and 10,000 Spanish messages,respectively.
Our final English-Spanish bitext corpus from this source of data consisted of 50,000 parallelsentences.
Table 1 shows the high frequency messages in this dataset.4.2 Amazon Mechanical TurkThe SMS messages from speech-based interaction does not consist of any shorthands or orthographicerrors as the decoding vocabulary of the automatic speech recognizer is fixed.
We posted a task onAmazon Mechanical Turk, where we took the speech-based SMS messages and asked the turkers to enterthree responses to each message as they would on a smartphone.
We iteratively posted the responses fromthe turkers as messages to obtain more messages.
We obtained a total of 1000 messages in English andSpanish, respectively.
Unlike the speech data, the responses contained several shorthands.4.3 TwitterTwitter is used by a large number of users for broadcasting messages, opinions, etc.
The language used inTwitter is similar to SMS and contains plenty of shorthands, spelling errors even though it is typically notdirected towards another individual.
We compiled a data set of Twitter messages that we subsequentlytranslated to obtain a bilingual corpus.
We used the Twitter4j API4to stream Twitter data for a set ofkeywords (function words) over a week.
The raw data consisted of roughly 106 million tweets.
Subse-quently, we performed some basic normalization (removal of @user, #tags, filtering advertisements, webaddresses) to obtain SMS-like tweets.
Finally, we sorted the data by frequency and picked the top 10000tweets.
Eliminating the tweets present in either of the two previous sources resulted in 6790 messagesthat we manually translated.5 FrameworkThe user input is first stripped of any accents (Spanish), segmented into short chunks using an automaticpunctuation classifier.
Subsequently, any shorthand in the message is expanded out using expansion dic-tionaries (constructed manually and automatically) and finally translated using a phrase-based translation2https://www.mturk.com3https://twitter.com4http://twitter4j.org/en/976model.
Our framework allows the use of confusion networks in case of ambiguous shorthand expansions.We describe each component of the pipeline in detail in the following sections.5.1 TokenizationOur initial analysis of SMS messages from users, especially in Spanish indicated that while some usersuse accented characters in orthography, several others omit it for the sake of faster responses and con-venience.
Hence, we decided to train all our models on unaccented characters.
Given a message, weconvert all accented characters to their corresponding unaccented forms, e.g., ba?no?
bano, followed bylowercasing of all characters.
We do not perform any other kind of tokenization.5.2 Unsupervised SMS NormalizationIn Section 5.2, we described a static lookup table for expanding abbreviations and shorthands typicallyencountered in SMS messages, e.g., 4ever?forever.
While a static lookup table provides a reasonableway of handling common SMS abbreviations, it has limited coverage.
In order to build a larger nor-malization lexicon, we used distributed representation of words to induce the lexicon in an unsupervisedmanner.
Distributed word representations (Bengio et al., 2003; Collobert and Weston, 2008; Turian et al.,2010) induced through deep neural networks have been shown to be useful in several natural languageprocessing applications.
We use the notion of distributional similarity that is automatically inducedthrough the word representations for learning automatic normalization lexicons.Canonical form Noisy formlove loveeee, loveeeee, looove, love, wuv, wove, love, laffff, love, wuvvv, luhhhh, love, luvvv, luvstarbucks starbs, sbucksonce oncee, 1cetomorrow tmrw, tomorrow, 2moro, tmrrw, tomarrow, tomoro, tomoz, 2mrw, tmr, tm, tmwr, 2mm, tmw, 2morroforever foreva, 5ever, foreverrrr, forver, foreeverrr, 4ever, 5eva, 4eva, foreevaa, forevs, forevebecause cause, cos, coz, ?cos, ?cause, bc, because, becuz, bcuz, cuz, bcus, bcoz, becausehomework hwk, hw, hmwk, hmwrk, hmw, homeworkk, homwork, hmk, honework, homeoworkigualmente igualmentee, igualment, iwalmentesiempre simpre, siempre, 100pre, siempre, ciempre, siempre, siiempre, siemore, siempr, siemre, siempeadios adi, a10, adiocontigo contigoo, cntigo, conmigo, contigoooo, kontigo, conmigoo, conmiqodemasiado demaciado, demasido, demasiademente, demasiaoTable 2: Examples from the unsupervised normalization lexicon induced through deep learningWe started with the 106 million tweets described in Section 4.3 and used a deep neural network iden-tical to that used in (Collobert and Weston, 2008), i.e., the network consisted of a lookup table, hiddenlayer with 100 nodes and a linear layer with one output.
However, we used a context of 5 words andcorrupted the centre word instead of the last word to learn the distributed representations.
We performedstochastic gradient minimization over 1000 epochs on the twitter data.
Subsequently, we took the En-glish and Spanish vocabularies in our translation model and found the 50 nearest neighbors using cosinedistance for each word.
We trained the above representations using the Torch toolkit (Collobert et al.,2011).Feature English Spanishdimension Precision Recall Precision Recall100 70.4 97.4 69.8 97.3200 72.2 97.5 79.2 100300 70.4 97.4 71.6 100Table 3: Performance of the unsupervised normalization procedure.
Only 1-best for each word wasconsidered.Once we obtained the 50 nearest neighbors for each word in the clean vocabulary, we used a com-bination of cosine metric threshold and Levenshtein distance (weighted equally) between the consonant977skeleton of the strings to construct the mapping lexicon.
Finally, we inverted the table to obtain a nor-malization lexicon.
Our procedure currently finds only one-to-one mappings.
We took 60 singletonentries from the static normalization tables reported in Section 5.2 and evaluated the performance of ourapproach.
The results are shown in Table 3 and some examples of learned normalizations are shown inTable 2.5.3 Phrase SegmentationIn many SMS messages, multiple clauses may be concatenated without explicit punctuation.
For exam-ple, the message hi babe hope you?re well sorry i missed your call needs to be interpreted as hi babe.hope you?re well.
sorry, i missed your call.
We perform phrase segmentation using an automatic punc-tuation classifier trained on SMS messages with punctuation.
The classifier learns how to detect end ofsentence markers, i.e.
periods, as well as commas in the input stream of unpunctuated words.An English punctuation classifier and a Spanish punctuation classifier was trained.
The former wastrained on two million words of smartphone data described in Section 4.1 while the latter was trainedon 223,000 words of Spanish subtitles from the OpenSubtitles5corpus.
From each of these data sets, amaximum entropy classifier was trained.
Both classifiers utilized both unigram word and part of speech(POS) features of a window size of two words around the target word to be classified.
A POS taggertrained on the English Penn Treebank provided English POS tags.
Likewise, a Spanish POS taggerprovided Spanish POS tags.
The training data for the Spanish tagger, 1.6 million words in size, wasobtained by running the Spanish Freeling parser over the Spanish version of TED talk transcripts.
Resultsare shown in Table 4.
Both phrase segmenters detect end of sentence well.
The Spanish phrase segmenterdetects commas better than the English one.
This might be due to differences in the training sets; commasappear about 20 times more often in the Spanish data than in the English data.Class Precision Recall F-measureEnglish period 89.7 90.9 90.3comma 61.1 10.9 18.5Spanish period 94.3 87.4 90.7comma 74.2 37.4 49.7Table 4: Performance of automatic phrase segmentation (numbers are in %)5.4 Machine TranslationWe used a phrase-based translation framework with the phrase table represented as a finite-state trans-ducer (Rangarajan Sridhar et al., 2013).
Our framework proceeds by using the standard procedure ofperforming word alignment using GIZA++ (Och and Ney, 2003) and obtaining phrases from the wordalignment using heuristics (Zens and Ney, 2004) and subsequently scoring them.
The phrase table isthen represented as a finite-state transducer (FST).
The FST decoder was used with minimum error ratetraining (MERT) to compute a set of weights for the log-linear model.
It is important to note that thecost of arcs of the FST is a composite score (dot product of scores and weights) and hence requires anadditional lookup during the N-best generation phase in MERT to obtain the component scores.
Themodel is equivalent to Moses (?)
phrase translation without reordering.We noticed from the data collected in Section 4 that in typical SMS scenarios, a lot of phrases are stockphrases and hence caching these phrases may result in high accuracies instead of deriving the translationusing a statistical model.
We took the data created in Section 4 and created a FST to represent thesentences.
The motivation is to increase the precision of common entries as well as reduce the latencyinvolved in retrieving a translation from a statistical model.
An example of the FST translation paradigmis shown in Figure 1We experimented with the notion of using a consensus-based word alignment by combining the align-ment obtained through different alignment tools.
We used GIZA++ (Och and Ney, 2003), Berkeley5http://www.opensubtitles.org978step1.fsm01how:how 2how^are:how^are 3how^are^you:how^are^youare:are are^you:are^you you:youWIPLM)hello how are youhellohow are youex.fst0hello:holathanks:graciashow^do^you^do:como^estasCached TableStatistical Modelbestpath(hola como estashello.fsm0hello:helloptable.fst0/0how:que/1.822how:como/0.458how^are^you:como^estas/1.106how^are^you:como^esta^usted/2.358are^you:estan/1.998are^you:estas/0.757you:que/1.460you:tu/0.757Figure 1: Illustration of the hybrid translation approach using FSTs.
WIP and LM refer to the finite stateautomata for word insertion penalty and language model, respectively.Alignment strategy en2es es2enGIZA++ 28.45 31.83Pialign 28.08 33.48Berkeley aligner 27.82 32.01Union 28.01 33.14Majority voting 27.32 32.96Table 5: BLEU scores obtained using different alignment strategies.
Only the statistical translation modelwas used in the evaluation.aligner (Liang et al., 2006) and the Phrasal ITG aligner (Pialign) (Neubig et al., 2011).
We combined thealignments in two different ways, taking the union of alignments or majority vote for each target word.For training the translation model, we used a total of 28.5 million parallel sentences obtained from thefollowing sources: Opensubtitles (Tiedemann and Lars Nygaard, 2004), Europarl (Koehn, 2005), TEDtalks (Cettolo et al., 2012) and Web.
The bitext was processed to eliminate spurious pairs by restrictingthe English and Spanish vocabularies to the top 150k frequent words as evidenced in a large collection ofmonolingual corpora.
We also eliminated bitext with ratio of English to Spanish words less than 0.5.
Theinitial model was optimized using MERT over 1000 parallel sentences from the SMS domain.
Results ofthe machine translation experiments are shown in Table 5.
The test set used was 456 messages collectedin a real SMS interaction (see Section 6.1).
The results indicate that consensus alignment procedure is notsuperior to the individual alignment outputs.
Furthermore, the BLEU scores obtained through both theconsensus procedures are not statistically significant with respect to the BLEU score obtained from theindividual alignment tools.
Hence, we used with the phrase translation table obtained using the PhrasalITG aligner in all our experiments.6 SMS Translation ServiceIn order to test the SMS translation models described in the previous sections, we created the infrastruc-ture to intercept SMS messages, translate and deliver them in the preferred language of the recipient.
Theusers were simply asked to register their numbers with a particular language through a Web portal andsubsequently, all messages received by a user would be in the registered language.
Some screenshots ofinteraction between users is shown in Figure 2.
For the messages that are translated, we show both theoriginal and translated messages.
In cases where the translated message is longer than the character limitper message, we split the message over two message boxes.9796.1 User EvaluationFigure 2: Screenshots of the SMS interface with translationIn order to test the SMS translation models described in the previous sections, we created the infras-tructure to intercept SMS messages, translate and deliver them in the preferred language of the recipient.For the messages that are translated, we show both the original and translated messages.
In cases wherethe translated message is longer than the character limit per message, we split the message over twomessage boxes.
As part of the study we enrolled 20 English and 5 Spanish participants.
The Spanishparticipants were bilingual while the English users had little to no knowledge of Spanish.
Some of theseinteractions turned out to be short while others were had a large number of turns.
We collected themessages exchanged over 2 days that amounted to 241 English and 215 Spanish messages.0!5!10!15!20!25!30!35!40!45!0!1!2!3!4!5!6!7!8!9!All!
Most!
Much!
Little!
None!Percentageof participants!Number of participants!Adequacy of Translation!Figure 3: Subjective ratings regarding the adequacy of using SMS translationWe manually translated the 456 messages to create a test data set for evaluation purposes.
In theabsence of real SMS feeds in training, this test set is the closest we have to real SMS field data.
The BLEUscores using the entire pipeline (normalization, punctuation, cached and statistical machine translation)for English-Spanish and Spanish-English was 31.25 and 37.19, respectively.
We also created a surveyfor the participants to evaluate fluency and adequacy (LDC, 2005) Figures 3 and 4 show the surveyresults for adequacy and fluency, respectively.
The results indicate that a majority of the people foundthe translation quality to be sufficiently adequate while the fluency was between good and non-native.7 DiscussionThe SMS bitext described in Section 4 consists of a total 58790 unique parallel sentences in the SMSdomain.
While the bulk of the data (speech-based) does not contain abbreviations and spelling errors, it9800!10!20!30!40!50!60!0!2!4!6!8!10!12!Flawless!
Good!
Non-native!
Disfluent!
Incomprehensible!Percentageof participants!Number of participants!Fluency of Translation!Figure 4: Subjective ratings regarding the fluency of using SMS translationis highly representative of SMS messages and in fact is perfectly suited for statistical machine translationthat typically uses normalized and tokenized data.
The iterative procedure using Amazon MechanicalTurk is a good approach to procuring surrogate SMS data.
We plan to continue harvesting data using thisapproach.The unsupervised normalization lexicon learning using deep learning performs a good job of learningSMS shorthands.
However, the induced lexicon contains only one-to-one word mappings.
If one wereto form compound words for a given dataset, the procedure can be potentially used for learning many-to-one and many-to-many mappings.
Our framework also learns spelling errors rather well.
It may alsobe possible to use distributed representations learned through log-linear models (Mikolov et al., 2013)for our task.
However, this is beyond the scope of the work presented in this paper.
Finally, we usedonly 1-best match for the unsupervised lexicon used in this work.
One can potentially use a confusionnetwork and compose it with the FST model to achieve higher accuracies.
Our scheme results in fairlyhigh precision with almost no false negatives (recall is extremely high) and can be reliably applied fornormalization.
The unsupervised normalization scheme did not yield significant improvements in BLEUscore since our test set contained only 4 instances where shorthands were used.Conventionally, sentence segmentation has been useful in improving the quality of statistical machinetranslation (Matusov et al., 2006; Matusov et al., 2005).
Such segmentation, albeit into shorter phrases,is also useful for SMS translation.
In the absence of phrase segmentation, the BLEU scores for English-Spanish and Spanish-English drop to 29.65 and 23.95, respectively.
The degradation for Spanish-Englishmessages is quite severe (drop from 37.19 to 23.95) as the lack of segmentation greatly reduces the use ofthe cached table.
In the absence of segmentation, the cached table was used for 12.8% and 14.4% of thetotal phrases for English-Spanish and Spanish-English, respectively.
However, with phrase segmentationthe cached table was used for 29.2% and 39.2% of total phrases.The subjective results obtained from the user trial augur well for the real use of translation technologyas a feature in SMS.
One of the issues in the study was balancing the English and Spanish participants.Since we had access to more English participants (20) in comparison with Spanish participants (5), therate of exchange was slow.
However, since SMS messages are not required to be real-time, participantsstill engaged in a meaningful conversation.
Subjective evaluation results using LDC criteria indicatethat most users were happy with the adequacy of translation while the fluency was rated as average.
Ingeneral, SMS messages are not very fluent due to character limit imposed on the exchanges and hencemachine translation has to use potentially disfluent source text.8 ConclusionWe presented an application of statistical machine translation for translating SMS messages.
We decou-pled SMS translation into normalization followed by translation.
Our unsupervised SMS normalizationapproach exploits the distributional similarity of words and learns SMS shorthands with good accuracy.We used a hybrid translation approach to exploit the repetitive nature of high frequency SMS messages.Both objective and subjective evaluation experiments indicate that our system generates translation withhigh quality while addressing the idiosyncrasies of SMS messages.981ReferencesA.
Aw, M. Zhang, J. Xiao, and J. Su.
2009.
A phrase-based statistical model for SMS text normalization.
InProceedings of COLING, pages 33?40.S.
Bangalore, V. Murdock, and G. Riccardi.
2002.
Bootstrapping bilingual data using consensus translation for amultilingual instant messaging system.
In Proceedings of COLING.R.
Beaufort, S. Roekhaut, L. A. Cougnon, and C. Fairon.
2010.
A hybrid rule/model-based finite-state frameworkfor normalizing sms messages.
In Proceedings of ACL, pages 770?779.Y.
Bengio, R. Ducharme, P. Vincent, and C. Jauvin.
2003.
A neural probabilistic language model.
Journal ofMachine Learning Research, 3:1137?1155.M.
Cettolo, C. Girardi, and M. Federico.
2012.
WIT3: Web Inventory of Transcribed and Translated Talks.
InProceedings of EAMT.T.
Chen and M. Y. Kan. 2013.
Creating a live, public short message service corpus: the NUS SMS corpus.Language Resources and Evaluation, 47(2):299?335.R.
Collobert and J. Weston.
2008.
A unified architecture for natural language processing: deep neural networkswith multitask learning.
In Proceedings of ICML.R.
Collobert, K. Kavukcuoglu, and C. Farabet.
2011.
Torch7: A matlab-like environment for machine learning.In BigLearn, NIPS Workshop.V.
Eidelman, K. Hollingshead, and P. Resnik.
2011.
Noisy SMS Machine Translation in Low-Density Languages.In Proceedings of 6th Workshop on Statistical Machine Translation.C.
Fairon and S. Paumier.
2006.
A translated corpus of 30,000 french SMS.
In Proceedings of LREC.C.
Kobus, F. Yvon, and G. Damnati.
2008.
Normalizing sms: Are two metaphors better than one?
In Proceedingsof COLING, pages 441?448.P.
Koehn.
2005.
Europarl: A parallel corpus for statistical machine translation.
In MT Summit.LDC.
2005.
Linguistic data annotation specification: Assessment of fluency and adequacy in translations.
Tech-nical report, Revision 1.5.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Alignment by agreement.
In Proceedings of NAACL-HLT, pages104?111.E.
Matusov, G. Leusch, O. Bender, and H. Ney.
2005.
Evaluating machine translation output with automaticsentence segmentation.
In Proceedings of IWSLT, pages 148?154.E.
Matusov, A. Mauser, and H. Ney.
2006.
Automatic sentence segmentation and punctuation prediction forspoken language translation.
In Proceedings of IWSLT, pages 158?165.T.
Mikolov, K. Chen, G. Corrado, and J.
Dean.
2013.
Efficient estimation of word representations in vector space.In Proceedings of Workshop at ICLR.Graham Neubig, Taro Watanabe, Eiichiro Sumita, Shinsuke Mori, and Tatsuya Kawahara.
2011.
An unsupervisedmodel for joint phrase alignment and extraction.
In Proceedings of the ACL.F.
J. Och and H. Ney.
2003.
A systematic comparison of various statistical alignment models.
ComputationalLinguistics, 29(1):19?51.D.
Pennell and Y. Liu.
2011.
A character-level machine translation approach for normalization of SMS abbrevia-tions.
In Proceedings of IJCNLP.V.
K. Rangarajan Sridhar, J. Chen, S. Bangalore, A. Ljolje, and R. Chengalvarayan.
2013.
Segmentation strategiesfor streaming speech translation.
In Proceedings of NAACL-HLT.E.
Sanders.
2012.
Collecting and analysing chats and tweets in SoNaR.
In Proceedings of LREC.C.
Tagg.
2009.
Across-frequency in convolutive blind source separation.
dissertation, University of Birmingham.J.
Tiedemann and L. Lars Nygaard.
2004.
The OPUS corpus - parallel & free.
In Proceedings of LREC.982M.
Treurniet, O.
De Clercq, H. van den Heuvel, and N. Oostdijk.
2012.
Collecting a corpus of Dutch SMS.
InProceedings of LREC, pages 2268?2273.J.
Turian, L. Ratinov, and Y. Bengio.
2010.
Word representations: a simple and general method for semi-supervised learning.
In Proceedings of ACL.P.
Wang and H. Tou Ng.
2013.
A beam-search decoder for normalization of social media text with application tomachine translation.
In Proceedings of NAACL-HLT.Richard Zens and Hermann Ney.
2004.
Improvements in phrase-based statistical machine translation.
In InProceedings of HLT-NAACL, pages 257?264.983
