Here is the essence of the frame theory: When oneencounters a new situation (or makes a substantial change tnone's view of a problem), one selects from memory astructure called a frame.
This is a remembered framework tobe adapted to fit reality by changing details as necessary.A frame is a data-structure for representing astereotyped situation like being in a certain kind of livingroom or going to a child's birthday party.
Attached to eachframe are several kinds of information.
Some of thisinformation is about how to use the frame.
Some is aboutwhat one can expect to happen next.
Some is about what todo if these expectations are not confirmed.We can think of a frame as a network of nodesand relations.
The "top levels" of a frame ere fixed, andrepresent things that are always true about the supposedsituation.
The lower levels have many terminals - -  "slots"that must be filled by specific instances or data.
Eachterminal can specify conditions its assignments must meet.
(The assignments themselves are usually smaller "sub-frames.")
Simple conditions are specified by markers thatmight require a terminal assignment o be a person, an objectof sufficient value, or a pointer to a sub-frame of a certaintype.
More complex conditions can specify relations amongthe things assigned to several terminals.Collections of related frames are linked togetherinto frame-systems.
The effects of important actions eremirrored by transformations between the framesof a system.These are used to make certain kinds of calculationseconomical, to represent changes of emphasis and attention,and to account for the effectiveness of "imagery.
"For visual scene analysis, the different frames of asystem describe the scene from different viewpoints, and thetransformations between one frame and another representthe effects of moving from place to place.
For non-visualkinds of frames, the differences between the frames of asystem can represent actions, cause-effect relations, orchanges in conceptual viewpoint.
Different frames of asystem share th._~e same terminals; this is the critical pointthat makes it possible to coordinate information gatheredfrom different viewpoints.Much of the phenomenological power of the theoryhinges on the inclusion of expectations and other kinds ofpresumptions.
A frame's terminals are normally already filledwith "default" assignments.
Thus '~ frame may contain agreat many details whose supposition is not specificallywarranted by the situation.
These have many uses inrepresenting general information, most likely cases,techniques for by-passing "logic," and ways to make usefulgeneralizations.The default assignments are attached loosely totheir terminals, so that they can be easily displaced by newitems that fit better the current situation.
They thus canserve also as =variables" or as special cases for "reasoningby example," or as "textbook cases," and often make the useof logical quantifiers unnecessary.The frame-systems are linked, in turn, by aninformation retrieval network.
When a proposed framecannot be made to fit reality -- when we cannot find terminalassignments that suitably match its terminal marker conditions--  this network provides a replac:ement frame.
These inter-frame structures make possible other ways to representknowledge about facts, analogies, and other information usefulin understanding.Once a frame is proposed to represent a situation,a matching process tries to assign values to each frame'sterminals, consistent with the markers at each place.
Thematching process is partly controlled by informationassociated with the frame (which includes information abouthow to deal with surprises) and partly by knowledge aboutthe system's current goals.
There are important uses for theinformation, obtained when a matching process fails; it can beused to select an alternative frame that better suits thesituation.LOCAL ~1~1~ LOS~L T1~EOK~E~ FO~ Vt~I01~When we enter a room we seem to see the entirescene at a glance.
But seeing is really an extended process.It takes time to fill in details, collect evidence, makeconjectures, test, deduce, and interpret in ways that dependon our knowledge, expectations and goals.
Wrong firstimpressions have to be revised.
Nevertheless, all thisproceeds so quickly and smoothly that it seems to demand aspecial explanation.Would parallel processing help?
This is a moretechnical question than it might seem.
At the level ofdetecting elementary visual features, texture elements,stereoscopic and motion-parallax cues, it is obvious thatparallel processing might be useful.
At the level of IFoupingfeatures into objects, it is harder to see exactly how to useparallelism, but one can at least conceive of the aggregationof connected "nuclei" (Guzman TR-228), or the application ofboundary line constraint semantics (Waltz TR-271),performed in a special parallel network.At "higher" levels of cognitive processing,however, one suspects fundamental limitations in theusefulness of parsllelism.
Many "integral" schemes wereproposed in the literature on "pattern recognition" forparallel operations on pictorial material - -perceptrons,integral transforms, skeletonizers, and so forth.
Thesemathematically and computationally interesting schemes mightquite possibly serve as ingredients of perceptual processingtheories.
But as ingredients only\] Bas!celly, "integral"methods work only on*isolated figures in two dimensions.They fail disastrously in coping with complicated, three-dimensional scenery.The new, more successful symbolic theories usehypothesis formation and confirmation methods that seem, onthe surface at least, more inherently serial.
It is hard t_oosolve any very complicated problem without L, ivinl?
essentiallyfull attention s at different times, to different sub-problems.Fortunately, however, beyond the brute idea of doing manythings in parallel, one c'an imagine a more serial process thatdeals with large, complex, symbolic structures as units!
Thiaopens a new theoretical "niche" for .performing a rapidselection of large substructures; in this niche our theoryhopes to find the secret of speed, both in vision and inordinary thinking.IIIIIIIIIIIIIIIIIIIIII~EEtl16 i~ C'JB?Inthe tradition of Guzman and Winston, we assumethat the result of looking at a cube is a structure somethinglike that in figure 1.
.The substructures "A" and "B"represent details or decorations on two faces of the cube.Whenwe move to the right, face "A" disappears from view,while the new face decorated with "C" is now seer If wehad to analyse the scene from the start, we would have toI (l) lose the knowledge about "A,"(2) recompute B, and(3) compute the description of "C.*cube~XI\I ~ , - - ~  le f t -above-~.~(~ -I I 1 I parallelogram~....~L~ ,~ ,"--- i 0 > etc.A BI But since we know we moved to the right, we can save "B"by assigning it also to the "left face" termlnII of a second I cube-frame.
To save "A (just in cased we connect it alsoto an extra, invisible face-terminal of the niw cube-schemeas in figure Zi /~invisible,.d I A E B Ci If later we,move back to the left,we can reconstruct the first scene without any perceptualcomputation at all:!
.
just restore the top-level pointers to the first cube-frame.We now need a place to store ~";  we Can eK:ld yet anotherinvisible face to the right in the first cube-framel See filNre I 3.
We could extend this to represent further excursions" M?ve-Right ~ C~transformation ~/ l~I % /__  "II P.._hl IA  p lIft~ VKE 3--"left-vertical parallelogram"ht-vertical parallelogram"square" (in space)tO5"IIaround the object.
This would lead to a more comprehensive Bframe system, in which each frame represents a different"perspective" of a cube.
In figure 4 there ere three frames~RIGH_~T ~RIGHT _~~ Spatial Frames IiB _ le f t  - C )l e f t  FIC~U~E ~.corresponding to 45-degree MOVE-RIGHT and MOVE-LEFTactions.
If we pursue this analysis, the resulting system canbecome very large; more complex objects need even moredifferent projections.
It is not obvious either that all of themare normally necessary or that just one of each variety isadequate.
It all depends.It is not proposed that this kind of complicatedstructure is recreated every time one examines an object.
Itis imagined instead that a great collection of frame systems isstored in permanent memory, and one of them is evokedwhen evidence and expectation make it plausible that thescene in view will fit It.
How are they acquired?
Wepropose that if a chosen frame does not fit well enough, endif no better one is easily found, and if the matter Is importantenough, then an adaptation of the best one so far discoveredwill be constructed and remembered for future use.Each frame has terminals for attaching pointers tosubstructures.
Different frames can share the same terminal,which can thus correspond to the same physical feature asseen in different views.
This permits us to represent~ in asingle place, view-independent information gathered stdifferent times and places.
This is important also in non-visual applications.The matching.process which decides whether aproposed frame is suitable is controlled partly by one'scurrent goals and partly by information attached to the frame!the frames carry terminal markers and other constraints,while the goals are used to decide which of these constraintsare currently relevantL Generally, the matching process couldhave these components:Pictorial FramesIRelation Markers in common-terminal structure can represent more invar- iant (e.g.
three-dimensional) properties.II( l )  A frame, once evoked on the basis of partial evidenceor expectat!on, would first direct a test to confirmits own appropriateness , using knowledge aboutrecently noticed features, loci, relations, andplausible Sub-frames.
The current goal list is usedto decide which terminals and conditions must bemade to match reality.
(2) Next it would request information needed to assignvalues to those terminals that cannot retain theirdefault assignments.
For example, it might requesta description of face "C," if this terminal iscurrently unassigned, but only if it is not marked"invisible."
Such assignments must avee with thecurrent markers at the terminal.
Thus, face "C"might already~have markers for such constraints orexpectations as:IIIII, Right-middle visual field., Must be assigned., Should be visible; if not, considermoving right.. , Should be a cube-face sub-frame.
* Share left vert ical  boundaryterminal with face "B.
"* If failure, consider box-lying-on-sideframe.
* Same backip'ound color as face "B.
"(3) Finally, if informed about a transformation (e.g., animpending motion) it would transfer control to theappropriate other frame of that systemWithin the details of the control scheme are opportunities toembed many kinds of knowledge.
When a terminol-essilpdngattempt fails, the resulting error message can be used topropose a second-guess alternative.
Later it is shown howmemory can be organized into a "Similarity Network" asproposed in Winston's thesis (TR-23|).IIIIiIlOI= IiIIIIIIIIIIIIIII@ VI@I@}l ~YIII\]3OhIC?Can one really believe that a person's appreciationo f  three-dimensional structure can be so fragmentary andatomic as to be representable in terms of the relationsbetween parts of two-dimensional views?
Let us separate,at once, the two issues: is imagery symbolic?
and is it basedon two-dimensional fragments?
The first problem is one ofdegree; sure!y everyone would agree that at some levelvision is essentially symbolic.
The quarrel would be betweencertain naive conceptions on one side --  in which one acceptsseeing either as picture-like or as evoking imaginary solids - -against the confrontation of such experimental results ofPiaget (1956) and others in which many limitations that onemight fear wou!d result from symbolicrepresentations ereshown actually to exist!As for our second question:the issue of two-vs, three-dimensions evaporates at thesymbolic evel.The very concept of dimension becomes inappropriate.
Eachtype of symbolic representation of an object serves somegoals well and others poorly.
If we attach the relation labelsleft-of~ right-o_~f and abo~'e between parts of the structure,Say, as markers on pairs of terminals, certain manipulations ?will work out smoothly; for example, some properties ofthese relations are "invariant" if we rotate the cube whilekeeping the same face on the table.
Most objects have"permanent" tops and bottoms.
But if we turn the cube onits side such predictions become harder to make; people?
have great difficulty keeping track of the faces of a six-colored cube if one makes them roll it around in their mind.If one uses instead more "intrinsic" relations likenext-to and opposite-t_o,o then turning the object on its sidedisturbs the "image" much less.
In Winston's thesis we seehow systematic replacements (e.g., of *left" for "behind," end"right" for "in-front-of") can deal with the effect of spatialrotation.Visual experience seems continuous.
One reasonis that we move continuously.
A deeper explanation is thatour "expectations".
usually interact smoothly with ourperceptions.
Suppose you were to leave a room, close thedoor, turn to reopen it, and find an entirely different room.You would be shocked, The sense of change would be hardlyless striking if the world suddenly changed before your eyes.A naive theory of phenomenological continuity is that we seeso quickly that our image changes as fast as'does the scene.There is an alternative theory: the changes in one's frame-structure representation proceed at their own pace; thesystem prefers to make small changes whenever possible;and the?illusion of continuity is due to the persistence ofassignments to terminals common to th__ee different view-frames.
Thus, continuity depends on the confirmation ofexpectations which in turn depends on rapid access toremembered knowledge about the visual world.Just before you enter a room, you usually knowenough to "expect" a room rather than, say, ?
landscape.
Youcan ?usually tell just by the character of the door.
And youcan often select in advance a frame for the new room.
Veryoften, one expects a certain particular room.
Then manyassignments are already filled in,Io'/The simplest sort of room-frame candidate is likethe inside of a box.
Following our cube-model, the room-frame might have the top-level structure shown in figure 5.~~a,  ceiling / a cIleft wall g center wall lh right wal l!? "
' ?fl oorFIGUR*" 5"One has to ?assign to the frame's terminals thethings that are seen.
If the room is familiar, some are alreadyassigned.
If no expectations are recorded already, the firstpriority might be Iocalcing the principal geometric landmarks.To fill in LEFT WALL one might first try to find edges "a" end"d" and then the associated corners "ag" and "gd."
Edge "g,"for example, is usually easy to find because it shouldintersect any eye-level horizontal scan from left to right.Eventually, "ag," "gb," and "ba" must not be too inconsistentwith one another - -  because they are the same physicalvertex.However the process is directed, there are somegenerally useful knowledge-based tactics.
It is probablyeasier to find edge "e '~ than any other edge, because if wehave just entered a normal rectangular room, then we mayexpect that* Edge "e" is a horizontal line.
* R is below eye level.
* It defines a floor-wall textureboundary.Given an expectation about the size of ?
room, we canestimate the elevation of "e,= and vice verse.
In outdoorscenes, "e" is the horizon and on flat round we can expectto see it at eye-level.
If we fail quickly to locate and essiinthis horizon, we must consider rejecting the proposed frame:either the room is not normal or there is a large obstruction.The room-analysis strategy might try next  toestablish some other landmarks.
Given "e,= we next look forits left and right corners, and then for the verticals risingfrom them.
Once such gross geometrical landmarks erelocated, we can guess the room's general shape end size.This might lead to selecting a new frame better matched tothat shape and size, with additional markers confirming thechoice and completing the structure with further details.If the new room is unfamiliar, no pre-assembledframe can supply fine details; more scene-analysis is needed.Even so, the complexity of the work can be reduced, givensuitable subframes for constructing hypotheses aboutsubstructures in the scene.
How useful these will bedepends both on their inherent adequacy and on the qualityof the expectation process that selects which one to usenext.
One can say a lot even about an unfamiliar roont Mostrooms are like boxes, and they can be categorized into types"kitchen, hall, living room, theater, and so on.
One knowsdozens of kinds of rooms and hundreds of particular rooms;one no doubt has them structured into some sort of similaritynetwork for effective access.
This will be discussed later.A typical room-frame has three or four visiblewalls, each perhaps of a different "kind."
One knows manykinds of walls: walls with windows, shelves, pictures, andfireplaces.
Each kind of room has its own kinds of walls.
Atypical wall might have a 3 x 3 array of region-terminals(left-center-right) x (top-middle-bottom) so that wall-objectsCan be assigned qualitat!ve locations.
One would furtherwant to locate objects relative to geometric inter-relations inorder to represent such facts as "Y is a little above thecenter of the line between X and Z.
"In three dimensions, the location of a visual featureof a subframe is ambiguous, given only eye direction.
Afeature in the middle of the visual field could belong either toa Center Front Wall object or to a High Middle Floor object;these attach to different subframes.
The decision coulddepend on reasoned evidence for support, on more directlyvisual distance information derived from stereo disparity ormotion-parallax, or on plausibility information derived fromother frames: a clock would be plausible only on the wall-frame while a person is almost certainly standing on the floor.Given a box-shaped room, lateral motions induceorderly changes in the quadrilateral shapes of the walls as infigure 6.
A picture-frame rectangle, lying flat against a wall,MOVE RIGHT=,,uu,u transform in the same way a,J does its wall.
If a"center-rectangle" is drawn on a left wall it will appear toproject out because one makes the default assumption thatany such quadrilateral is actually a rectangle hence must liein a plane that would so project.
In figure 7A, bothquadrilaterals could "look like" rectangh.s, but the one to theright does not match the markers for a "left rectangle"subframe (these require, e.g.,, that the left side be longerthan the right side).
That rectangle is therefore representedby a center-rectangle frame, and seems to project out asthough parallel to the center wall.Thus we must not simply assign the .label"rectangle" to a quadrilateral but to a particular frame of arectangle-system.
When we move, we expect"w--hateverspace-transformation is applied to the top-level system willbe applied also to its subsystems as suggested in figure 7B.Similarly the sequence of elliptical projections of acircle contains congruent pairs that are visually ambiguous asshown in figure 8.
But because wall objects usually lie flat,we assume that an ellipse on a left wall is a left-ellipse,expect it to .transform the same way as the left wall, and are?
not surprised if the prediction is confirmed.FIC~URE" IoII!I,,II!I* ~ .
~ .
_  I.
7A|r ight-s ide rO()O !!
!I 00  0 001I F~u~E 9DEF~ILT ~\ ]6R~I~RTIIIIIIIWhile both Seeing and Imagining result  inassignments to frame terminals, Imagination leaves us ?widerchoices of detail and variety of such assignments.
Framesare probably never stored in long-term memory withunassigned \[erminal values.
Instead, what really happens isthat frames are stored with weakly-bound defaultassignments at every terminalt These manifest themselves asoften-useful but sometimes counter-productive stereotypes.Thus in the sentence "John kicked the ball," youprobably cannot think of a purely abstract ball, but mustimagine characteristics of a vaguely particular ball; itprobably has a certain default size, default color, defaultweight.
Perhaps it is a descendant of one you first owned orwere injured by.
Perhaps it resembles your latest one.
Inany case your image lacks the sharpness of presencebecause the processes that inspect and operate upon theweakly-bound default features are very likely to change,adapt, or detach them.
?WOBI)B, BE~'ITE~CE~ ~l:ll) II~ERI:IIRfi~The concepts of frame and default assignmentseem helpful in discussing the phenomenology of "meaning.
"Chomsky (1957) points out that such a sentence asI(A) "colorless green ideas sleep furiously"is treated very differently than the non-sentence(B) "furiously sleep ideas green colorless"and suggests that because both are "equally nonsensical,"what is involved in the recognition of sentences must bequite different from what is involved in the appreciation efmeanings.There is no doubt that there are processesespecially concerned with grammar.
Since the meaning of anutterance is "encoded" as much in the positional andstructural relations between the words as in the wordchoices themselves, there must be processes concerned withanalysing those relations in the course of building thestructures that will more directly represent the meaning.What makes the words of (A) more effective and predictablethan (B)in producing such a structure --  putting aside thequestion of whether that structure should be called semanticor syntactic -- is that the word-order relations in (A) exploitthe (grammatical) convention and rules people usually use toinduce others to make assignments to terminals of structures.This is entirely consistent with grammar theories.
Agenerative grammar.would be a summary description of theexterior appearance of those frame rules - -  or theirassociated processes - -  whi le the operators  oftransformational grammars seem similar enough to some ofour frame transformations.We certainly cannot assume that " logical"meaninglessness has a precise psychological counterpart.Sentence (A) can certainly generate an image!
The dominantframe is perhaps .that of someone sleeping; the defaultsystem assigns a particular bed, and in it lies a mummy-likeshape-frame with a translucent green color property.
In thisframe there is a terminal for the character of the sleep - -restless, perhaps --  and "furiously" seems somewhatinappropriate at that terminal, perhaps because the terminaldoes not like to accept anything so "intentional" for a sleeper.
"Idea" is even more disturbing , because one expects eperson, or at least something animate.
One senses frustratedprocedures trying to resolve these tensions and conflictsmore properly, here or there, into the sleeping frameworkthat has been evoked:Io9iUtterance (B) does not get nearly so far becauseno subframeaccepts any substantial fragment.
As a result nolarger frame finds anything to match its terminals, hencefinally, no top level "meaning" or "sentence" frame canorganize the utterance as either meaningful or grammatical.By combining this "soft" theory with gradations of assignmenttolerances, one could develop systems that degrade properlyfor sentences with "poor" grammar ather than none~ if thesmaller fragments -- phrases and sub-clauses,-- satisfysubframes well enough, an image adequate for certain kindsof comprehension could be constructed anyway, even thoughsome parts of the top level structure are not entirelysatisfied, Thus, we arrive at a qualitative theory of"grammatical:"if the top levels are satisfied but some lower terminals arenot we have a meaningless entence; if the top is weak butthe bottom solid, we can have an ungrammatical butmeaningful utterance.I)t~COBI~ELinguistic activity involves larger structures thancan be described in terms of sentential ip'ammar, and theselarger structures further blur the distinctness of the wntex-semantic dichotomy.
Consider the following fable, as told byW.
Chafe ( !
972):There was once a Wolf who saw a Lambdrinking at a river and wanted anexcuse to eat it.
For that purpose,even though he himself was upstream,he accused the Lamb of stirring up thewater and keeping him from drinkln?..To understand this, one must realize that the Wolf is lyingtTo understand the key conjunctive "even though" one mustrealize that contamination ever flows upstream.
This in turnrequires us to understand (among other things) the word"upstream" itself.
Within a declarative, predicate-based"logical" system, one might try to formalize "upstream" bysome formula like:\[A upstream B\]AND\[Event T, Stream muddy at A\]= =>\ [Exists \[Event U, Stream muddy at B\]\]AND \[Later U, T\]t~OFJC--URE qE~-~ .
~ S ~next-to ~~- -__~~Butan adequate definition would need a good deal more.What about the fact that the order of things beingtransported by water currents is not ordinarily changed?.
Alogician might try to deduce this from a suitably intricate setof '"local" axioms, together with appropriate "induction"axioms.
I propose instead to represent this knowledge in astructure that automatically translocates Spatial descriptionsfrom the terminals of one frame to those of another frame ofthe same system.
While this might be considered to be aform of logic, it uses some of the same mechanisms designedfor spatial thinking.In many instances we would handle a change overtime, or a cause-effect relation, in the same way as we dealwith a change in position.
Thus, the concept r!ver-flow couldevoke a frame-system structure something like the following,where S\], $2, and S3are abstract slices of the flowing rivershown in figure 9.There are many more nuances to fill in.
What is"stirring up" and why would it keep the wolf from drinking?One might normally assign default floating objects to the S's,but here $3 interacts with "stirring up" to yield somethingthat "drink" does not find acceptable.
Was it "deduced" thatstirring river-water means that $3 in the first frame shouldhave "mud" assigned to it; or is this simply the defaultassignment for stirred water?Almost any event, action, change, flow of material,or even flow of information can be represented to a firstapproximation by a.two-frame generalized event.
Theframe-system can have slots for agents, tools, side-effects,preconditions, generalized trajectories, just as in the "trans"verbs of "case grammar" theories, but we have the additionalflexibility of representing changes explicitly.
To see if one.has understood an event or action, one can try to build anappropriate instantiated frame-Pair.IIIIIIiIlIIiiIIIIlI!
!tIIIIIItIII ,|IIIliHowever, in representing changes by simple"before-after" frame-pairs, we can expect to pay a price.Pointing to a pair is not the same as describing theirdifferences.
This makes it less convenient to do planning orabstract reasoning; there is no explicit place to attachinformation about the transformation.
As a secondapproximation, we could label pairs of nodes that point tocorresponding terminals, obtaining a structure like the"comparison-notes" in Winston (TR-23\]), or we might placeat the top of the frame-system information describing thedifferences more abstractly.
Something of this sort will beneeded eventually.~CE~510~We condense and conventionalize, in language andthought, complex situations and sequences into compactwords and symbols.
Some words can perhaps be "defined" inelegant, simple structures, but only a small part of themeaning of "trade" is captured by:f i r s t  frameA has ?
B has Ysecond frameB has X ?
A has YTrading normally occurs in a social context of law, trust andconvention.
Unless we also represent these other facts, mosttrade transactions will be almost meaningless.
It is usuallyessential to know that each party usually wants both thingsbut has to compromise.
It is a happy but unusualcircumstance in which each trader is glad to get rid of whathe has.
To represent trading strategies, one could insert thebasic maneuvers right into the above frame-pair scenario: inorder for A to make B want X more (or want Y less) weexpect him to select one of the familiar tactics:Offer more for Y.Explain why X is so good.Create favorable side-effect of B havingI~sparage'the competition.Make B think C wants X.These only scratch, the surface.
Trades usually occur within a?
scenario tied together by more than a simple chain of eventseach linked to the next.
No single such scenario will do;when a clue about trading appears it is essential to guesswhich of the different available scenarios is most tikely to beuseful.Charniak's thesis (TR-266) studies questions abouttransactions that seem easy for people to comprehend yetobviously need rich default structures.
We find inelementary school reading books such stories aS:Jane was invited to Jack's Birthday Party.She wonderedif he would like a kite.She went to her room and shook her piggybank.It made no sound.We first hear that Jane is invited to Jack'sBirthday Party.
Without the party scenario, or at least aninvitation scenario, the second line seems rather mysterious:She wondered if he would like a kite.To explain one's rapid comprehension ofthis, we make asomewhat radical proposal:to represent explicitly, in the frame for a scenario structure,pointers to a collection of the most serious problems andquestions commonly associated with it.In fact we shall consider the idea that the frame terminals areexactly those questions.Thus, for the birthday party:Y must get P for X .
.
.
.
.
.
.
.
Choose P!X must like P .
.
.
.
.
.
.
.
- .
.
.
.
Will X likeP?Buy P -:- .
.
.
.
.
.
.
.
.
.
.
.
- - -  Where to buy P?Get money to buy P .
.
.
.
Where to get money?
(Sub-questions of the "present" frame?
)Y must dress up What should Y wear?Certainly these are one's first concerns when one is invitedto a partY.Th e 'reader is free to wonder ?
whether this solutionis acceptable.
The question "Will X like P?"
certainly matches"She wondered if he would like a kite?"
and correctly assignsthe kite to P. But is:our world regular enough that suchquestion sets could be pro-compiled to make this mechanismoften work smoothly?
The answer is mixed.
We do indeed?
expect many such questions; we surely do not expect all o!them.
But surely "expertise" consists partly in not having torealize, a._bb initio, what are the outstanding problems andinteractions insituations.
Notice, for example, that there isno default assignment for the Present in our party-scenariofr-ame.
This mandates attention to that assignment problemand prepares us for a Possible thematic concern.
In any case,we probably need a more active mechanism for understanding"wondered" which can apply the information currently in theframe to produce an expectation of what Jane will thinkabout.The key words and ideas of a discourse evoke substantialthematic or scenario structures, drawn from memory with richdefault assumptions.In any event, the individual statements of a?
discourse lead to temporary representations - -  which seemto correspond to what contemporary linguists call "deepstructures" - -  which are then quickly rearranged orconsumed in elaborating the growing scenario representation.In order of "scale," among the ingredients of such a structurethere might be these kinds of levels:EXCU~E~We can think of a frame as describing an "ideal.
"If an ideal does not match reality because it is "basically"wrong, it must be replaced.But it is in the nature of'ideals.that they are really elegantsimplifications; their attractiveness derives from theirsimplicity, but their real power depends upon additionalknowledge about interactions between them!
Accordingly weneed not abandon an ideal because of a failure to instantiateit, provided one can explain the discrepancy in terms of suchan interaction.
Here are some examples in which such an"excuse" can save a failing match:OCCLUSION: A table, in a certain view, should have four legs,but a chair might occlude one of them One can lookfor things like T-joints and shadows to support such anexcuse.FUNCTIONAL VARIANT: A chair-leg is usually a stick,geometrically; but more important, it is functionally asupport.
Therefore, a strong center post, with anadequate base plate, should be an acceptablereplacement for all the legs.
Many objects are multiplepurpose and need functional rather than physicaldescriptions.BROKEN: A visually missing component could be explained asin fact physically missing, or it could be broken.Reality has a variety of ways to frustrate ideals.PARASITIC CONTEXTS: An object that is just like a chair,except in size, could be (and probably is) a toy chair.The complaint "too small" could often be so interpretedin contexts with other things too small, children playing,peculiarly large "grain," and so forth.In most of those examples, the kinds of knowledge to makethe repair --  and thus salvage the current frame - -  are"general" enough usually to be attached to the thematiccontext of a superior frame.In moving about a familiar house, we already knowa dependable structure for "information retrieval" of roomframes.
When we move through Door D, in Room X, weexpect to enter Room Y (assuming D I.s not the Exit).
Wecould represent this as an action transformation of thesimplest kind, consisting of pointers between pairs of roomframes of a particular house system.When the house is not familiar, a "!ogical" strategymight be to move up a level of classification: when youleave one room, you may not know which room you areentering, but you usually know that it is some room.
Thus,one can partially evade lack of specific information by dealingwith classes -- and one has to use some form of abstractionor generalization to escape the dilemma of Bart lett 'scommander.It?...Winston's thesis (TR-23\]) proposes a way toconstruct a retrieval system that cart represent classes buthas additional flexibility.
His retrieval pointers can be madeto represent goal requirements and action effects as well asclass memberships.What does it mean to expect a chair?
Typically,four legs, some assortment of rungs, a level seat,an upper back.
One expects also certain relationsbetween these "parts."
The legs must be belowthe seat, the back above.
The legs must besupported by the floo'r.
The seat must behorizontal, the back vertical, and so forth.Now suppose that this description does not match;the vision system finds four legs, a level plane, butno back.
The "difference" between what weexpect and what we see is "too few backs."
Thissuggests not a chair, but a table or a bench.Winston proposes pointers from each descriptionin memory to other descriptions, with each pointer labelledby a difference marker.
Complaints about mismatch arematched to the difference pointers leaving the frame and thusmay propose a better candidate frame.
Winston calls theresulting structure a Similarity Network.Is a Similarity Network practical?
At first sight,there might seem to be a danger of unconstrained growth ofmemory.
If there are N frames, and K kinds of differences,then there could be as many as K*N*N interframe pointers.One might fear that:(\]) If N is large, say 10, then N*N is very large - -of the order of 10 - -  which might beimpractical, at least for human memory.
(2) There might be so many pointers for a givendifference and a given frame that thesystem will not be selective enough to beuseful.
(3) K itself might be very large if the system issensitive to many different kinds of issues.But, according to contemporary opinions (admittedly, not veryconclusive) about the rate of storage into human long-termmemory there are probably not enough seconds in a lifetimeto cause a saturation problem.So the real problem, paradoxically, is that therewill be too few connections!
One cannot expect to haveenough time to fill out the network to saturation Given twoframes that should be linked by a difference, we cannot counton that pointer being there; the problem may not haveoccurred before.
However, in the next section we see howto partially escape this p~oblem.I!
!IittI|t||i|III|!I!ItIiIIIIIItIIIISurface Syntactic Frames ---  Mainly verb and nounstructures..Prepositional and word-order indicatorconventions.Surface Semantic Frames - - -Act ion-centered?
meanings of words.Qualif iers and relat ions concerningparticipants, instruments, trajectories andstrategies, goals, consequences and side-effects.Thematic Frames - - -  Scenarios concerned withtopics, activities, portraits, setting.Outstanding ?problems and strategiescommonly connected with topics.Narrative Frames - - -  Skeleton forms for typicalstor ies,  explanations, and arguments.Conventions about loci, protagonists, plotforms, development, etc., designed to help alistener construct.a new, inatantietedThematic Frame in his own mind.5EO~EgTg TO ~EtIIOSTWe can now imagine the memory system as drivenby two complementary needs.On one side are items demanding to be properly representedby being embedded into larger frames; on the other side areincompletely-filled frames demanding terminal assignments.The rest of the system will try to placate these lobbyists,but not so much in accord with "general principles" as inaccord with special knowledge and conditions imposed by thecurrently active goals.When a ?frame encounters trouble - -  when animportant condition cannot be satisfied --  something must bedone.
We envision the following major kinds of accomodationto trouble.MATCHING: When nothing more specific is found, we canattempt to use some "basic" associative memorymechanism.
This will succeed by itself  only inrelat ively simple situations, but should play ?supporting role in the other tactics.EXCUSE: An apparent misfit can often be excused orexplained, A "chair" that meets all other conditions butis much too small could be a "toy.
"ADVICE: The frame contains explicit knowledge about whatto do about the trouble.
Below, we describe anextensive, learned "Similarity Network" in which toembed such knowledge.SUMMARY: If a frame cannot be completed or replaced, onemust give it up..But first one must construct a well-formulated complaint or summary to help whateverprocess next becomes responsible for reassigning thesubframes left in limbo.~TCTIIR~When replacing a frame, we do not want to startall over again.
How can we remember what was already"seen?"
We consider here only the case in which the systemhas no specific knowledge about what to do and must resortto some "general" strate~.
No completely general methodcan be very good, but if we could find a new frame thatshares enough terminals with the old frame, then some of thecommon assignments can be retained, and we will probably dobetter than chance.The problem can be formulated as follows: let Ebe the cost of losing a certain already assigned terminal andlet F be the cost of being unable to assign some otherterminal.
If E is worse than F, then any new frame shouldretain the old subframe.
Thus, given any sort of priorityordering on the terminals, a typical request for a new frameshould include:(1) Find a frame with as many terminals in commonwith \[a,b,..,z\] as possible, where we listhigh priority terminals already assigned inthe old frame.But the frame being replaced is usually already a subframe ofsome other frame and must satisfy the markers of it._ssattachment terminal, lest the entire structure be lost.
Thissuggests another form of memory request, looking upwardrather than downward:?
(2) Find or build a frame that has properties\[a,b,...,z\]If we emphasize di f ferences rather than abso lutespecifications, we can merge (2) and (1):(3) Find a frame that is like the old frame exceptfor certain differences \[a,b~..,z\] betweenthem.One can imagine a parallel-search or hash-coded ?memory tohandle (1) and (2) if the terminals or properties are simpleatomic symbols.
(There must be some such mechanism, in anycase, to support a production-based program or some sort ofpattern matcher.)
Unfortunately, there are so many ways todo this that it implies no specific design requirements.Although (1) and'(2) are formally special cases of(3), they are different in ?practice because complicated casesof (3) require knowledge about differences.
In fact (3) is toogeneral to be useful as" stated, and we will later propose todepend on specific, learned, knowledge about differencesbetween pairs of frames rather than on broad, generalprinciples.It should be emphasized again that we must notexpect magic.
For difficult, novel  problems a newrepresentation structure will have to be constructed, and th|8will require application of both general and specialknowledge.!CI,~I~TES~.
CI, R~E~.
6R\]~ R 6EO61~RPI~IC~IR~IhOG?To make the Similarity Network act more "complete," considerthe following analogy.
In a city, any person should be able tovisit any other; but we do not build a special road betweeneach pair of houses; we place a group of houses on e"block."
We do not connect roads between each pair ofblocks; but have them share streets.
We do not connect ~each town to every other; but construct main routes,connecting the centers.of larger groups.
Within such anorganization, each member has direct links to some otherindividuals at his own "level," mainly to nearby, highly similarones; but each individual has also at least a few links to"distinguished" members of higher level groups.
The result isthat there is usually a rather short sequence between anytwo individuals, if one can but find it.A t  each level, .the aggregates usually havedistinguished loci or capitols.
These serve as elements forclustering at the next level of aggregation.
There is no non-stop airplane service between New Haven and Sen Josebecause it is more efficient overall to share the "trunk" routebetween New York and San Francisco, which are the capitolsat that level of aggregation.The non-random convergences and divergences ofthe similarity pointers, for each difference ~ thus tend tostructure our conceptual .world around' ( l ) .
the aggregation into d-clusters(2) the selection of d_-capitolsNote that it is perfectly all right to have several capitols in aclusterj so that there need be no one attribute common tothem all.
The "crisscross resemblances" of Wittgenstein arethen consequences of the local connections in our similaritynetwork, which are surely adequate to explain how we canfeel as though we know what is a chair or a game - -  yetcannot always define it in a "logical" way as an element insome class-hierarchy or by any other kind of compact, formal,declarative rule.
The apparent coherence of the conceptualaggregates need not reflect explicit definitions, but canemerge from the success-directed sharpening of thedifference-describing processes.The selection of capitols corresponds to selectingstereotypes or typical elements whose default assignmentsare unusually useful.
There are many forms of chairs, forexample, and one should Choose carefully the chair-description frames that are to be the major capitols of chair-land.
These are used for rapid matching and assigningpriorities to the various differences.
The lower priorityfeatures of the clustercenter then serve either as defaultproperties of the chair types or, if more realism is required,as dispatch pointers to the local chair villages end towns.Difference pointers could be "functional" as wel l  asgeometric.
Thus, after rejecting a first try at "chair" onemight try the functional idea of "something one can sit on" toexplain an unconventional form.
This requires ?
deeperanalysis in terms of forces and strengths.
Of course, thatanalysis would fail to capture toy chairs, or chairs of suchornamental delicacy that their actual use would beunthinkable.
These would be better handled by the methodof excuses, in which one would bypass the usual geometricalor functional explanations in favor of responding to contextsinvolving art or play..Suppose your car battery ruins down.
You believethat there is an electricity shortage and blame the generator.The generator can be represented as a mechanicalsystem: the rotor has a pulley wheel ,driven by a belt fromthe engine.
Is the belt tight enough?
Is it even there?
Theoutput, seen mechanically, is a cable to the bat tery  orwhatever.
Is.
it intact?
Are the bolts tight?
Are the brushespressing on the commutator?Seen electrically, the generator is describeddifferently.
The rotor is seen as a flux-linking coil, ratherthan as a rotating device.
The brushes and commutator areseen.as electrical switches.
The output is current along apairof conductors leading from the brushes through controlcircuits to the battery.The differences between the two frames aresubstantial.
The entire mechanical chassis of the car playsthe simple role, in the electrical frame, of one of the batteryconnections.
The diagnostician has to use bothrepresentations.
A failure of current to flow often meansthat an intended conductor is not acting like one.
For thiscase, the basic transformation between the frames dependson the fact that electrical continuity is in general equivalentto firm mechanical attachment.
Therefore, any conductiondisparity revealed by electrical measurements hould make uslook for a corresponding disparity in the mechanical frame.
Infact, since "repair ~ in this universe is synonymous with"mechanical repair," the diagnosis must end in the mechanicalframe.
Eventually, we might ocate a defective mechanicaljunction and discover a loose connection, corrosion, wear, orwhatever.One cannot expect to have e frame exactly rightfor any problem or expect always to be able to invent one.But we do have a good deal to work with, and it is importantto remember the contribution of one's culture in assessing'the complexity of problems people seem to solve.
Th eexperienced mechanic need not routinely invent~ he alreadyhas engine representations in terms of ignition, lubrication,cooling, timing, fuel .mixing, transmission, compression, and soforth.
Cooling, for example, is already subdivided into fluidcirculation, air flow, thermostasis, etc.
Most "ordinary"problems are presumably solved by systematic use of theanalogies provided by the transformations between pairs ofthese structures.
The huge network of knowledge, acquiredfrom school, books, apprenticeship, or whatever is interlinkedby difference and relevancy pointers.
No doubt the cultureimparts a good deal of this structure by its conventional useof the same words in explanations of different views of esubject.Over the past decade, it has become widelyrecognized how important are the deta i ls  of therepresentation of a "problem space"; but it was not so wellrecognized that descriptions can be useful to a program, aswell as to the person writing the program Perhaps progresswas actually retarded by ingenious schemes to avoid explicitmanipulation of descriptions.
Especially in "theorem-proving"and in "game-playing" the dominant paradigm of the pestmight be schematized so:IIItIIt1ItI!!!,i!!!
!IIII1Ii|tIIi!lIItIThe central goal ofa Theory  ofProblem Solving i sto find systematicways to reducethe extent of theSearch through theProblem Space.Sometimes a simple problem is indeed solved by trying asequence of "methods" until one is found to work.
Someharder problems are solved by a sequence of localimprovements, by "hill-climbing" within the problem space.But even when this solves a particular problem, it tells uslittle about the problem-space; hence yielding no improvedfuture competence.
The best-developed technology ofHeuristic Search is that of game-playing using tree-pruning,plausible-move generation, and terminal-evaluation methods.But even those systems that use hierarchies of symbolicgoals do not improve their understanding or refine theirunderstanding or refine their representations.
But there is amore mature and powerful paradigm:The primary purpose in problem solvingshould be better to understand theproblem.space, to find representationswithin which the problems are easier tosolve.
The purpose of search is to getinformation for this reformulation, not - -as is usually assumed - -  to findsolutions; orce the space is adequatelyunderstood, solutions to problems willmore easily be found.The value of an intellectual experiment should be assessedalong the dimension of success ~ partial success - failure, orin terms of "improving the situation" or "reducing adifference."
An application of a "method," or areconfiguration of a representation can be valuable if it leadsto a way to improve the strategy of subsequent trials.Earlier formulations of the role of heuristic search strategiesdid not emphasize these possibilities, although they areimplicit in discussions of "planning.
"Papert (1972; see also Minsky 1972) is correct inbelieving that the ability to diagnose and modify one's ownprocedures is a collection of specific and important "skills.
"Debugging, a fundamentally important component ofintelligence, has its own special techniques and procedures.Every normal person is pretty good at them.
or otherwise hewould not have learned to see and talk!
Goldstein (AIM-305)and Sussman (TR-297) have designed systems which buildnew procedures to satisfy multiple requirements by suchelementary but powerful techniques as:I.
Make a crude first attempt by the first ordermet~hod of simply putt ing togetherprocedures that separately achieve theindividual goals.2.
If something goes wrong, try to characterize oneof the de fects  as a speci f ic  (and?
undesirable) kind of interaction between twoprocedures.3.
Apply a "debugging technique" that, according to arecord in memory, is good at repairing thatspecific kind of interaction.4.
Summarize the experience, to add to the"debugging techniques library" in memory.These might seem simple-minded, but if the new problem isnot too radically different.from the old ones, then they have agood,chance to work, especially if one picks out the rightfirst-order approximations.
If the new problem is radicallydifferent, one should not expect any learning theory to workwell.
Without a structured cognitive map - -  without the"near misses" of Winston, or a cultural supply of good trainingsequences of problems -- we should not expect radicallynew paradigms to appear magically whenever we need them.gO~E F~EhEV~RT F~E~Dm~Abelson, R. P. "The Structure of ?Belief Systems."
ComputerModels of Thought an._dd Language.
Ed.
R. Schankand K. Colby.
San Francisco: W. H. Freeman,1973.Bartlett, F. C. Remembering.
Cambridge: CambridgeUniversity Press, | 967.Berlin, I. T.h.e Hedgehog and the Fox.American Library, 1957.New York: NewCelce-Murcia, M. Paradigms for Sentence Recognition.
LosAngeles~ Univ.
of California, Dept.
of Linguistics,197ZChafe, W. First Tech.
Report, Contrastive Semantics ProjecLBerkeley: Univ.
of California, Oept.
of Linguistics,1972.Chomsky, N. "Syntactic Structures."
(Ori~nally published as"Strukturen der Syntax") Janua Linguarum StudiaMemoriae, !
82 (!
957).Fillmore, C. J.
"The Case for Case."
Universals in LinguisticTheory.
Ed.
Bach and Harms.
Chicago: Holt,Rinehart and Winston, i 968.Freeman, P. and A. Newell.
"A Model for FunctionalReasoning in Design."
Proc.
Second.
Intl.
Conf.o_~nArtificial Intelligence.
London: Sept. 1971.Gombrich, E H. Ar_!t and Illusion, A_ Study in th.__ee ~ ofPictorial Representatio.n.
Princeton: PrincetonUniversity Press, t969.Hogarth, W: The A nalys)s of Beauty.
Oxford: OxfordUniversity Press, 1955.Huffman, D. A.
"Impossible Objects as Nonsense Sentences.
"Machine Intelligence 6.
Ed.
D. Michie and B.Meltzer.
Edinburgh: Edinburgh University Press,\] 972.Koffka, K. Principles of Gestalt Psychology.
New York:Harcourt, Brace and World, \] 963.Kuhn, T. The Structure Of Scientific Revolutions.
2nd ed.Chicago: University of Chicago Press, 1970.Lavoisier, A.
Elements of Chemistry.
Chicago: Regnery,\] 949.Levin, J.
A, Network Representation and Rotation of Letters.Publication of the Dept.
of Psychology, Universityof California, La Jolla, 1973.Minsky, M. "Form and Content in Computer Science."
1970ACM Turing Lecture.
Journal of the~ ACMp 17, No.2 (April 1970), 197-215.Minsky, M. and S. Papert.
Perceptrons.
Cambridge: M.I.T.Press, 1969.Moore, J. and A. Newell.
"How can MERLIN Understand?"?
Knowledge and Cognition.
Ed.
J. Gregg.
Potomac,Md.
: Lawrence Erlbaum Associates, 1973.Newelli A.
Productions Systems: Models .of ControlStructures, Visual Information Processing.
NewYork: Academic Press, 1973.Newell, A.
"Artificial Intelligence and the Concept of Mind.
"Computer Models of Thought and Language.
Ed.
R.Schank and K. Colby.
San Francisco: W. H;Freeman, 1973.Newell, A. and H. A. Simon.
Human Problem Solving.Englewood-Cliffs, N.J.: Prentice-Hall, 1972.Norman, D. "Memory, Knowledge and the Answering ofQuestio.ns."
Loyola Symposium on CognitivePsychology, Chicago, 1972.Papert, S. "Teaching Children to be Mathematicians vs.Teaching about Mathematics."
Int.
J. Matk Edu?.Sc.~i.
Technol., 3_ (1972), 249-262.Piaget, J. Si_~x Psychological Studies.
Ed.
D. Elklnd.
NewYork: Vintage, 1968.Piaget, J.Pylyshyn,and B. Inhelder.
The Child's Conception of Space.New York: The Humanities Press, | 956.Z.W.
"What the Mind's Eye Tells the Mind's BraiR"Psychological Bulletin.
80 (1973), 1-24.Roberts, L. G. Machine Perception of Three DimensionalSolids, Optical a..nd Optoelectric Information,Processing.
Cambridge: M.I.T.
Press, 1965.Sandewall, E. "Representing Natural Language Information inPredicate Calculus."
Machine !ntelligence 6.
Ed.
D.Michie and B~ Meltzer.
Edinburgh: EdinburghUniversity Press, 1972.Schank, R. "Conceptual Dependency: A Theory of NaturalLanguage Understanding."
Cognitive Psychology(\]972), 552-63l.
see also Schank, R. and K. Colby,Computer Models of Thought and Language.
SanFrancisco: W. I-1.
Freeman, \] 973..Simmons, R. F. "Semantic Networks: Their Computation andUse for Understanding English Sentences.
"Computer Models of Thought and Language.
Ed.
R.Schank and K. Colby.
San Francisco: W. H.Freeman,.
19'73.?
Underwood, S. A. and C. L. Gates, Visual Learning andRecognition by Computer, T R-_\]22~3 Publications ofElect.
Res.
Center, University of Texas, April,1972.Wertheimer, M. Productive Thinking.
Evanston, IlL: Harper &Row, 1959.Wilks, Y.
"Preference Semantics/' Memo AIM-206,Publications of Stanford Artificial IntelligenceLaboratory, Stanford University, July, 1973.Wilks, Y.
"An Artificial Intelligence Approach to MachineTranslation."
Computer Models of Thought andLanguage.
Ed.
R. Schank and K. Colby.
SanFrancisco: W. H. Freeman, !
973.I!t|II'Iitti,IIItIIIt1
