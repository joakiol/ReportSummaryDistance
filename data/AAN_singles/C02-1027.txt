Shallow language processing architecture for BulgarianHristo TanevITC-Irst,Centro per la Ricerca Scientifica e TecnologicaPovo,Trento, Italy 38050tanev@itc.itRuslan MitkovSchool of Humanities,Languages and Social StudiesWolverhampton WV1 1SB UKR.Mitkov@wlv.ac.ukAbstractThis paper describes LINGUA - an architec-ture for text processing in Bulgarian.
First, thepre-processing modules for tokenisation, sen-tence splitting, paragraph segmentation, part-of-speech tagging, clause chunking and nounphrase extraction are outlined.
Next, the pa-per proceeds to describe in more detail theanaphora resolution module.
Evaluation resultsare reported for each processing task.1 IntroductionThe state of the art of today?s full parsing andknowledge-based automatic analysis still fallsshort of providing a reliable processing frame-work for robust, real-world applications suchas automatic abstracting or information ex-traction.
The problem is especially acute forlanguages which do not benefit from a widerange of processing programs such as Bulgar-ian.
There have been various projects whichaddress different aspects of the automatic anal-ysis in Bulgarian such as morphological analy-sis (Krushkov, 1997), (Simov et al, 1992), mor-phological disambiguation (Simov et al, 1992)and parsing (Avgustinova et al, 1989), but noprevious work has pursued the development ofa knowledge-poor, robust processing environ-ment with a high level of component integrity.This paper reports the development and im-plementation of a robust architecture for lan-guage processing in Bulgarian referred to asLINGUA, which includes modules for POS tag-ging, sentence splitting, clause segmentation,parsing and anaphora resolution.
Our text pro-cessing framework builds on the basis of con-siderably shallower linguistic analysis of the in-put, thus trading off depth of interpretation forbreadth of coverage and workable, robust solu-tion.
LINGUA uses knowledge poor, heuristi-cally based algorithms for language analysis, inthis way getting round the lack of resources forBulgarian.2 LINGUA - an architecture forlanguage processing in BulgarianLINGUA is a text processing framework forBulgarian which automatically performs tokeni-sation, sentence splitting, part-of-speech tag-ging, parsing, clause segmentation, section-heading identification and resolution for thirdperson personal pronouns (Figure 1).
All mod-ules of LINGUA are original and purpose-built, except for the module for morphologicalanalysis which uses Krushkov?s morphologicalanalyser BULMORPH (Krushkov, 1997).
Theanaphora resolver is an adaptation for Bulgar-ian of Mitkovs knowledge-poor pronoun resolu-tion approach (Mitkov, 1998).LINGUA was used in a number of projectscovering automatic text abridging, word seman-tic extraction (Totkov and Tanev, 1999) andterm extraction.
The following sections outlinethe basic language processing functions, pro-vided by the language engine.2.1 Text segmentation: tokenisation,sentence splitting and paragraphidentificationThe first stage of every text processing task isthe segmentation of text in terms of tokens, sen-tences and paragraphs.LINGUA performs text segmentation by op-erating within an input window of 30 tokens, ap-plying rule-based algorithm for token synthesis,sentence splitting and paragraph identification.2.1.1 Tokenisation and token staplingTokens identified from the input text serve asinput to the token stapler.
The token staplerforms more complex tokens on the basis of aFigure 1: General architecture of LINGUAtoken grammar.
With a view to improving to-kenisation, a list of abbreviations has been in-corporated into LINGUA.2.1.2 Sentence splittingLINGUA?s sentence splitter operates to iden-tify sentence boundaries on the basis of 9 mainend-of-sentence rules and makes use of a list ofabbreviations.
Some of the rules consist of sev-eral finer sub-rules.
The evaluation of the per-formance of the sentence splitter on a text of190 sentences reports a precision of 92% anda recall of 99%.
Abbreviated names such asJ.S.Simpson are filtered by special constraints.The sentence splitting and tokenising rules wereadapted for English.
The resulting sentencesplitter was then employed for identifying sen-tence boundaries in the Wolverhampton Corpusof Business English project.2.1.3 Paragraph identificationParagraph identification is based on heuristicssuch as cue words, orthography and typograph-ical markers.
The precision of the paragraphsplitter is about 94% and the recall is 98% (Ta-ble 3).2.2 Morphological analysis andpart-of-speech tagging2.2.1 Morphological analysisBulgarian morphology is complex, for exam-ple the paradigm of a verb has over 50forms.
Krushkov?s morphological analyserBULMORPH (Krushkov, 1997) is integrated inthe language engine with a view to processingBulgarian texts at morphological level.2.2.2 Morphological disambiguationThe level of morphological ambiguity forBulgarian is not so high as it is in otherlanguages.
As a guide, we measured the ratio:Number of all tags/Number of all words.The results show that this ratio is compara-tively low and for a corpus of technical textsof 9000 words the ratio tags per word is 1,26,whereas for a 13000-word corpus from the genreof fiction this ratio is 1,32.
For other languagessuch as Turkish this ratio is about 1,9 and forcertain English corpora 2,0 1.We used 33 hand-crafted rules for disam-biguation.
Since large tagged corpora in Bul-garian are not widely available, the developmentof a corpus-based probabilistic tagger was anunrealistic goal for us.
However, as some stud-ies suggest (Voutilainen, 1995), the precision ofrule-based taggers may exceed that of the prob-abilistic ones.2.3 ParsingSeeking a robust flexible solution for pars-ing we implemented two alternative approachesin LINGUA: a fast-working NP extractor andmore general parser, which works more slowly,but delivers better results both in accuracy andcoverage.
As no syntactically annotated Bulgar-ian corpora were available to us, using statisticaldata to implement probabilistic algorithm wasnot an option.The NP extraction algorithm is capable ofanalysing nested NPs, NPs which contain left1Kemal Oflazer, personal communicationmodifiers, prepositional phrases and coordinat-ing phrases.
The NP extractor is based on asimple unification grammar for NPs and APs.The recall of NP extraction, measured against352 NPs from software manuals, was 77% andthe precision - 63.5%.A second, better coverage parser was im-plemented which employs a feature grammarbased on recent formal models for Bulgarian,(Penchev, 1993), (Barkalova, 1997).
All basictypes of phrases such as NP, AP, PP, VP andAdvP are described in this grammar.
Theparser is supported by a grammar compiler,working on grammar description languagefor representation of non context unificationgrammars.
For example one of the rules forsynthesis of NP phrases has the form:NP (def :Y full art :F ext :+ rex :?
nam :?
)?AP (gender :X def :Y full art:F number: L )NP (ext:?
def:?
number:L gender:X rex:?
)The features and values in the rules are notfixed sets and can be changed dynamically.
Theflexibility of this description allows the gram-mar to be extended easily.
The parser uses achart bottom-up strategy, which allows for par-tial parsing in case full syntactic tree cannot bebuilt over the sentence.There are currently about 1900 syntac-tic rules in the grammar which are encodedthrough 70 syntactic formulae.Small corpus of 600 phrases was syntacticallyannotated by hand.
We used this corpus tomeasure the precision of the parsing algorithm(Table 3).We found that the precision of NP extractionperformed by the chart parser is higher thanthe precision of the standalone NP extraction -74.8% vs. 63.5% while the recall improves byonly 0.9% - 77.9% vs. 77% .The syntactic ambiguity is resolved using syn-tactic verb frames and heuristics, similar to theones described in (Allen, 1995).The parser reaches its best performance forNPs (74.8% precision and 77.9% recall) and low-est for VPs (33% precision, 26% recall) andSs (20% precision and 5.9% recall) (Table 3).The overall (measured on all the 600 syntac-tic phrases) precision and recall, are 64.9% and60.5% respectively.
This is about 20% lower,compared with certain English parsers (Muratand Charniak, 1995), which is due to the in-sufficient grammar coverage, as well as the lackof reliable disambiguation algorithm.
Howeverthe bracket crossing accuracy is 80%, which iscomparable to some probabilistic approaches.
Itshould be noted that in our experiments we re-stricted the maximal number of arcs up to 35000per sentence to speed up the parsing.3 Anaphora resolution in Bulgarian3.1 Adaptation of Mitkovsknowledge-poor approach forBulgarianThe anaphora resolution module is imple-mented as the last stage of the language pro-cessing architecture (Figure 1).
This module re-solves third-person personal pronouns and is anadaptation of Mitkov?s robust, knowledge-poormultilingual approach (Mitkov, 1998) whose lat-est implementation by R. Evans is referred toas MARS 2 (Orasan et al, 2000).
MARS doesnot make use of parsing, syntactic or seman-tic constraints; nor does it employ any formof non-linguistic knowledge.
Instead, the ap-proach relies on the efficiency of sentence split-ting, part-of-speech tagging, noun phrase iden-tification and the high performance of the an-tecedent indicators; knowledge is limited to asmall noun phrase grammar, a list of (indicat-ing) verbs and a set of antecedent indicators.The core of the approach lies in activating theantecedent indicators after filtering candidates(from the current and two preceding sentences)on the basis of gender and number agreementand the candidate with the highest compositescore is proposed as antecedent 3.
Before that,the text is pre-processed by a sentence split-ter which determines the sentence boundaries, apart-of-speech tagger which identifies the partsof speech and a simple phrasal grammar whichdetects the noun phrases.
In the case of com-plex sentences, heuristic ?clause identification?rules track the clause boundaries.LINGUA performs the pre-processing,needed as an input to the anaphora resolutionalgorithm: sentence, paragraph and clausesplitters, NP grammar, part-of-speech tagger,2MARS stands for Mitkov?s Anaphora ResolutionSystem.3For a detailed procedure how candidates are handledin the event of a tie, see (Mitkov, 1998).Text Pronouns Weight setStandard Optimised Baselinemost recentSoftware manuals Success rate 221 75.0% 78.8% 58.0%Critical succ.
rate 70.0% 73.0% 54.0%Non trivial succ.
rate 70.0% 78.8% 58.0%Tourist guides Success rate 116 68.1% 69.8% 65.0%Critical succ.
rate 63.3% 64.4% 58.8%Non trivial succ.
rate 67.2% 69.0% 65.0%All texts Success rate 337 72.6% 75.7% 60.4%Critical succ.
rate 67.7% 70.0% 55.7%Non trivial succ.
rate 72.3% 75.4% 60.4%Table 1: Success rate of anaphora resolutionsection heading identification heuristics.
Sinceone of the indicators that Mitkov?s approachuses is term preference, we manually developed4a small term bank containing 80 terms fromthe domains of programming languages, wordprocessing, computer hardware and operatingsystems 5.
This bank additionally featured 240phrases containing these terms.The antecedent indicators employed inMARS are classified as boosting (such indica-tors when pointing to a candidate, reward itwith a bonus since there is a good probabilityof it being the antecedent) or impeding (such in-dicators penalise a candidate since it does notappear to have high chances of being the an-tecedent).
The majority of indicators are genre-independent and are related to coherence phe-nomena (such as salience and distance) or tostructural matches, whereas others are genre-specific (e.g.
term preference, immediate refer-ence, sequential instructions).
Most of the indi-cators have been adopted in LINGUA withoutmodification from the original English version(see (Mitkov, 1998) for more details).
How-ever, we have added 3 new indicators for Bul-garian: selectional restriction pattern, adjectivalNPs and name preference.The boosting indicators areFirst Noun Phrases: A score of +1 is assignedto the first NP in a sentence, since it is deemed4This was done for experimental purposes.
In futureapplications, we envisage the incorporation of automaticterm extraction techniques.5Note that MARS obtains terms automatically usingTF.IDF.to be a good candidate for the antecedent.Indicating verbs: A score of +1 is assignedto those NPs immediately following the verbwhich is a member of a previously defined setsuch as discuss, present, summarise etc.Lexical reiteration: A score of +2 is assignedthose NPs repeated twice or more in theparagraph in which the pronoun appears, ascore of +1 is assigned to those NP, repeatedonce in the paragraph.Section heading preference: A score of +1 isassigned to those NPs that also appear in theheading of the section.Collocation match: A score of +2 is assignedto those NPs that have an identical collocationpattern to the pronoun.Immediate reference: A score of +2 is as-signed to those NPs appearing in constructionsof the form ?
...V1 NP < CB > V2 it ?
, where< CB > is a clause boundary.Sequential instructions: A score of +2 isapplied to NPs in the NP1 position of con-structions of the form: ?To V1 NP1 ... To V2 it...?Term preference: a score of +1 is applied tothose NPs identified as representing domainterms.Selectional restriction pattern: a score ofText Pronouns Intrasentential: Average Average Average AverageIntersentential number of distance from distance from distance fromanaphors candidates the antecedent the antecedent the antecedentper anaphor in clauses in sentences in NPSofware 221 106 : 115 3.29 1.10 0.62 3.30manualsTourist 116 17 : 99 3.35 1.74 0.98 5.13guidesTable 2: Complexity of the evaluation data+2 is applied to noun phrases occurring incollocation with the verb preceding or followingthe anaphor.
This preference is differentfrom the collocation match preference in thatit operates on a wider range of ?selectionalrestriction patterns?
associated with a specificverb 6 and not on exact lexical matching.
Ifthe verb preceding or following the anaphoris identified to be in a legitimate collocationwith a certain candidate for antecedent, thatcandidate is boosted accordingly.
As an il-lustration, assume that ?Delete file?
has beenidentified as a legitimate collocation being afrequent expression in a domain specific corpusand consider the example ?Make sure you savethe file in the new directory.
You can nowdelete it.
?
Whereas the ?standard?
collocationmatch will not be activated here, the selectionalrestriction pattern will identify ?delete file?
asan acceptable construction and will reward thecandidate ?the file?.Adjectival NP: a score of +1 is applied toNPs which contain adjectives modifying thehead.
Empirical analysis shows that Bulgarianconstructions of that type are more salientthan NPs consisting simply of a noun.
Recentexperiments show that the success rate of theanaphora resolution is improved by 2.20%,using this indicator.
It would be interestingto establish if this indicator is applicable forEnglish.Name preference: a score +2 is applied tonames of entities (person, organisation, product6At the moment these patterns are extracted from alist of frequent expressions involving the verb and do-main terms in a purpose-built term bank but in gener-ally they are automatically collected from large domain-specific corpora.names).The impeding indicator is PrepositionalNoun Phrases: NPs appearing in prepositionalphrases are assigned a score of -1.Two indicators, Referential distance andIndefiniteness may increase or decrease acandidate?s score.Referential distance gives scores of +2 and+1 for the NPs in the same and in the previoussentence respectively, and -1 for the NPs twosentences back.
This indicator has strong influ-ence on the anaphora resolution performance,especially in the genre of technical manuals.Experiments show that its switching off candecrease the success rate by 26% .Indefiniteness assigns a score of -1 to indefi-nite NPs, 0 to the definite (not full article) and+1 to these which are definite, containing thedefinite ?full?
article in Bulgarian.4 Evaluation of the anaphoraresolution moduleThe precision of anaphora resolution measuredon corpus of software manuals containing 221anaphors, is 75.0%.
Given that the anaphoraresolution system operates in a fully automaticmode, this result could be considered verysatisfactory.
It should be noted that some ofthe errors arise from inaccuracy of the pre-processing modules such as clause segmentationand NP extraction (see Table 3).We also evaluated the anaphora resolutionsystem in the genre of tourist texts.
As ex-pected, the success rate dropped to 68.1%which, however, can still be regarded as a veryLanguage processing module Precision % Recall % Evaluation datasentence splitter 92.00 99.00 190 sentencesparagraph splitter 94.00 98.00 268 paragraphsclause chunker 93.50 93.10 232 clausesPOS tagger 95.00 95.00 303 POS tagsNP extractor 63.50 77.00 352 NPschart parsingNP 74.84 77.89 294 NPsAP 65.15 67.19 64 APsAdvP 37.14 50.00 26 AdvPsVP 33.33 26.39 72 VPsPP 70.00 60.21 93 PPsS 20.00 5.88 51 SsTotal 64.93 60.50 600 phrasesBracket crossing accuracy 80.33 - 600 phrasesAnaphora resolution 72.60 - 337 anaphorsTable 3: Summary of LINGUA performancegood result, given the fact that neither man-ual pre-editing of the input text, nor any post-editing of the output of the pre-processing toolswere undertaken.
The main reason for the de-cline of performance is that some of the origi-nal indicators such as term preference, immedi-ate reference and sequential instructions of theknowledge-poor approach, are genre specific.The software manuals corpus featured 221anaphoric third person pronouns, whereas thetourist text consisted of 116 such pronouns.
Forour evaluation we used the measures successrate, critical success rate and non-trivial suc-cess rate (Mitkov, 2001).
Success rate is theratio SR = AC/A, where AC is the number ofcorrectly resolved and A is the number of allanaphors.
Critical success rate is the successrate for the anaphors which have more than onecandidates for antecedent after the gender andnumber agreement filter is applied.
Non-trivialsuccess rate is calculated for those anaphorswhich have more than one candidates for an-tecedent before the gender and number agree-ment is applied.
We also compared our ap-proach with the typical baseline model Baselinemost recent which takes as antecedent the mostrecent NP matching the anaphor in gender andnumber.
The results are shown in the Table 1.These results show that the performance ofLINGUA in anaphora resolution is comparableto that of MARS (Orasan et al, 2000).
An opti-mised version 7 of the indicator weights scored asuccess rate of 69,8% on the tourist guide texts,thus yielding an improvement of 6,1%.Table 2 illustrates the complexity of the eval-uation data by providing simple quantifyingmeasures such as average number of candi-dates per anaphor, average distance from theanaphor to the antecedent in terms of sentences,clauses, intervening NPs, number of intrasen-tential anaphors as opposed to intersententialones etc.5 ConclusionThis paper outlines the development of thefirst robust and shallow text processing frame-work in Bulgarian LINGUA which includesmodules for tokenisation, sentence splitting,paragraph segmentation, part-of-speech tag-ging, clause chunking, noun phrases extractionand anaphora resolution (Figure 1).
Apartfrom the module on pronoun resolution whichwas adapted from Mitkov?s knowledge-poor ap-proach for English and the incorporation ofBULMORPH in the part-of-speech tagger, allmodules were specially built for LINGUA.
Theevaluation shows promising results for each ofthe modules.7The optimisation made use of genetic algorithms ina manner similar to that described in (Orasan et al,2000).ReferencesJ.
Allen.
1995.
Natural Language Understand-ing.
The Benjamin/Cummings PublishingCompany, Inc.T.
Avgustinova, K. Oliva, and E. Paskaleva.1989.
An HPSG-based parser for bulgar-ian.
In International Seminar on MachineTranslation ?Computer and Translation 89?,Moscow, Russia.P.
Barkalova.
1997.
Bulgarian syntax - knownand unknown.
Plovdiv University Press,Plovdiv.
in Bulgarian.H.
Krushkov.
1997.
Modelling and building ofmachine dictionaries and morphological pro-cessors.
Ph.D. thesis, University of Plovdiv.in Bulgarian.R.
Mitkov.
1998.
Robust pronoun reso-lution with limited knowledge.
In Pro-ceedings of the 18.th International Confer-ence on Computational Linguistics (COL-ING?98)/ACL?98 Conference, pages 869?875,Montreal,Canada.R.
Mitkov.
2001.
Towards a more consistentand comprehensive evaluation of anaphoraresolution algorithms and systems.
Towardsa more consistent and comprehensive evalu-ation of anaphora resolution algorithms andsystems, (15):253?276.E.
Murat and E. Charniak.
1995.
A statisticalsyntactic disambiguation program and whatit learns.
CS, 29-95.C.
Orasan, R. Evans, and R. Mitkov.
2000.Enhancing preference-based anaphora resolu-tion with genetic algorithms.
In Proceedingsof NLP?2000, Patras, Greece.J.
Penchev.
1993.
Bulgarian Syntax - Govern-ment and Binding.
Plovdiv University Press,Plovdiv.
in Bulgarian.K.
Simov, E. Paskaleva, M. Damova, andM.
Slavcheva.
1992.
Morpho-assistant - aknowledge based system for bulgarian mor-phology.
In Proceedings of the Third Confer-ence on Applied Natural Language Process-ing, Trento, Italy.G.
Totkov and Ch.
Tanev.
1999.
Computerizedextraction of word semantics through con-nected text analysis.
In Proc.
of the Interna-tional Workshop DIALOGUE ?99, pages 360?
365.A.
Voutilainen.
1995.
A syntax-based part-of-speech tagger.
In Proceedings of the 7th con-ference of the European Chapter of EACL,Dublin, Ireland.
