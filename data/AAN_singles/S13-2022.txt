Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 124?127, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsBUAP: N -gram based Feature Evaluation for the Cross-Lingual TextualEntailment TaskDarnes Vilarin?o, David Pinto, Sau?l Leo?n, Yuridiana Alema?n, Helena Go?mez-AdornoBeneme?rita Universidad Auto?noma de PueblaFaculty of Computer Science14 Sur y Av.
San Claudio, CUPuebla, Puebla, Me?xico{darnes, dpinto, saul.leon, candy.aleman, helena.gomez}@cs.buap.mxAbstractThis paper describes the evaluation of differ-ent kinds of textual features for the Cross-Lingual Textual Entailment Task of SemEval2013.
We have counted the number of N -grams for three types of textual entities (char-acter, word and PoS tags) that exist in thepair of sentences from which we are inter-ested in determining the judgment of textualentailment.
Difference, intersection and dis-tance (Euclidian, Manhattan and Jaccard) ofN -grams were considered for constructing afeature vector which is further introduced ina support vector machine classifier which al-lows to construct a classification model.
Fivedifferent runs were submitted, one of themconsidering voting system of the previous fourapproaches.
The results obtained show a per-formance below the median of six teams thathave participated in the competition.1 IntroductionThe cross-lingual textual entailment (CLTE), re-cently proposed by (Mehdad et al 2012) and(Mehdad et al 2011), is an extension of the tex-tual entailment task (Dagan and Glickman, 2004).Formally speaking, given a pair of topically relatedtext fragments (T1 and T2 which are assumed tobe TRUE statements) written in different languages,the CLTE task consists of automatically annotatingit with one of the following entailment judgments:?
bidirectional (T1 ?
T2 & T1 ?
T2): the twofragments entail each other (semantic equiva-lence);?
forward (T1 ?
T2 & T1 8 T2): unidirec-tional entailment from T1 to T2;?
backward (T1 9 T2 & T1 ?
T2): unidirec-tional entailment from T2 to T1;?
no entailment (T1 9 T2 & T1 8 T2): thereis no entailment between T1 and T2 in bothdirections;The Cross-lingual datasets evaluated were avail-able for the following language combinations (T1-T2):?
Spanish-English (SPA-ENG)?
German-English (DEU-ENG)?
Italian-English (ITA-ENG)?
French-English (FRA-ENG)In this paper we describe the evaluation of differ-ent features extracted from each pair of topically re-lated sentences.
N -grams of characters, words andPoS tags were counted with the aim of constructinga representative vector for each judgment entailment(FORWARD, BACKWARD, BI-DIRECTIONAL orNO-ENTAILMENT).
The resulting vectors werefed into a supervised classifier based on SupportVector Machines (SVM)1 which attempted to con-struct a classification model.
The description of thefeatures and the vectorial representation is given inSection 2.
The obtained results are shown and di-cussed in Section 3.
Finally, the findings of thiswork are given in Section 4.1We have employed the implementation of the Weka tool(Hall et al 2009).1242 Experimental SetupWe have considered the task as a classification prob-lem using the pivot approach.
Thus, we have trans-lated2 each pair to their corresponding language inorder to have two pairs of sentences written in thesame language.
Let Pair(T1, T2) be the origi-nal pair of topically related sentences.
Then, wehave obtained the English translation of T1, de-noted by T3, which will be aligned with T2.
Onthe other hand, we have translated T2 to the otherlanguage (Spanish, German, Italian or French), de-noted by T4, which will be aligned with T1.
Thetwo pairs of sentences, Pair(T2, T3) (English) andPair(T1, T4) (other language), are now written inthe same language, and we can proceed to calculatethe textual features we are interested in.The features used to represent both sentences aredescribed below:?
N -grams of characters, with N = 2, ?
?
?
, 5.?
N -grams of words, with N = 2, ?
?
?
, 4.?
N -grams of PoS tags, with N = 2, ?
?
?
, 4.?
Euclidean measure between each pair of sen-tences (Pair(T1, T4) and Pair(T2, T3)).?
Manhattan measure between each pair of sen-tences (Pair(T1, T4) and Pair(T2, T3)).?
Jaccard coefficient, expanding English terms inboth sentences, T2 and T3, with their corre-sponding synonyms (none disambiguation pro-cess was considered).The manner we have used the above mentionedfeatures is described in detail in the following sub-sections.2.1 Approach 1: Difference operatorFor each pair of sentences written in the same lan-guage, this approach counts the number of N -gramsthat occur in the first sentence (for instance T1), anddo not occur in the second sentence (for instanceT4) and viceversa.
Formally speaking, the valuesobtained are ???
?Pair(T1, T2) = {D1, D2, ?
?
?
, Dk},with D1 = |T1 ?
T4|, D2 = |T4 ?
T1|, D3 =2For this purpose we have used Google TranslateTable 1: Classes considered in the composition of binaryclassifiersClass 1 Class 2BACKWARD OTHERBI-DIRECTIONAL OTHERFORWARD OTHERNO-ENTAILMENT OTHERBACKWARD & BI-DIRECTIONAL OTHERBACKWARD & FORWARD OTHERBACKWARD & NO-ENTAILMENT OTHERBI-DIRECTIONAL & NO-ENTAILMENT OTHERFORWARD & BI-DIRECTIONAL OTHERFORWARD & NO-ENTAILMENT OTHER|T2 ?
T3|, D4 = |T3 ?
T2|, ?
?
?.
This vector iscalculated for all the possible values of N for eachtype of N -gram, i.e., character, word and PoS tag.The cardinality of ???
?Pair(T1, T2) will be 34, that is,16 values when the N -grams of characters are con-sidered, 12 values with word N -grams, and 6 valueswhen the PoS tag N -grams are used.The vectors obtained are labeled with the corre-sponding tag in order to construct a training datasetwhich will be further used to feed a multiclass clas-sifier which constructs the final classification model.In this case, the system will directly return one of thefour valid entailment judgments (i.e.
forward, back-ward, bidirectional, no entailment).2.2 Approach 2: Difference and IntersectionoperatorsThis approach enriches the previous one, by addingthe intersection between the two sentences of eachpair.
In a sense, we have considered all the featuresappearing in the pair of sentences.
In this case, thetotal number of features extracted, i.e., the cardinal-ity of the ???
?Pair(T1, T2) vector is 51.2.3 Approach 3: MetaclassifierIn this approach, we have constructed a systemwhich is a composition of different binary classifica-tion models.
The binary judgments were constructedconsidering the classes shown in Table 1.The approach 2 was also considered in this com-position generating a total of 11 models.
10 of themare based on the features used by Approach 1, andthe last one is based on the features used by Ap-proach 2.
The result obtained is a vector which tellswhether or not a pair is judged to have some kind oftextual entailment or not (the OTHER class).
This125vector is then labeled with the correct class obtainedfrom the gold standard (training corpus) for auto-matically obtaining a decision tree which allows usto determine the correct class.
Thus, the differentoutputs of multiple classifiers are then introduced toanother supervised classifier which constructs the fi-nal classification model.2.4 Approach 4: Distances measuresThis approach is constructed by adding five distancevalues to the Approach 2.
These values are calcu-lated as follows :?
The Euclidean distance between T2 and T3,and between T1 and T4.
We have used the fre-quency of each word for constructing a repre-sentative vector of each sentence.?
The Manhattan distance between T2 and T3,and between T1 and T4.
We have used the fre-quency of each word for constructing a repre-sentative vector of each sentence.?
A variant of the Jaccard?s Coefficient that con-sider synonyms (Carrillo et al 2012).
Since wehave only obtained synonyms for the Englishlanguage, this measure was only calculated be-tween T2 and T3.Therefore, the total number of features of the???
?Pair(T1, T2) vector is 56.2.5 Approach 5: Voting systemWith the results of the previous four models, we pre-pared a voting system which uses the majority crite-rion (3 of 4).3 Experimental resultsThe results obtained in the competition are presentedand discussed in this section.
First, we describe thetraining and test corpus, and thereafter, the resultsobtained with the different approaches submitted.3.1 DatasetIn order to train the different approaches already dis-cussed, we have constructed a training corpus madeup of two datasets: the training data provided by thetask organizers the task 8 of SemEval 2013 (Negriet al 2013), and the test dataset together with thegold standard of CLTE task of SemEval 2012 (Ne-gri et al 2011).
Thus, the training corpus contains4000 sentence pairs.
The test set provided in thecompetition contains 2000 sentence pairs.
The cor-pus is balanced, with 1000 pairs for each languagein the training dataset, whereas, 500 pairs are givenin the test set for each language (see Table 2).Table 2: Description of the datasetLanguages Training TestSPA-ENG 1000 500DEU-ENG 1000 500ITA-ENG 1000 500FRA-ENG 1000 500Total 4000 20003.2 ResultsIn Table 3 we can see the results obtained by eachone of the five approaches we submitted to the com-petition.
Each approach has been labeled with theprefix ?BUAP-R?
for indicating the approach usedby each submitted run.
For instance, the BUAP-R1run corresponds to the approach 1 described in theprevious section.
As can be seen, the behavior of thefive approaches is quite similar, which we considerit is expected because the underlying methodologyemployed is almost the same for all the approaches.With exception of the pair of sentences written inSPA-ENG in which the best approach was obtainedby the BUAP-R5 run, the approach 4 outperformedthe other appproaches.
We believe that this has beena result of introducing measures of similarity be-tween the two sentences and their translations.
Inthis table it is also reported the Highest, Average,Median and Lowest values of the competition.
Theresults we obtained are under the Median but outper-formed the results of two teams in the competition.With the purpose of analyzing the behavior of theapproach 4 in each one of the entailment judgments,we have provided the results obtained in Table 4.There we can see that the BACKWARD class is theeasiest one for being predicted, independently of thelanguage.
The second easiest class is FORWARD,followed by NO-ENTAILMENT.
Also we can seethat the BI-DIRECTIONAL class is the one that pro-duce more confusion, thus leading to obtain a lowerperformance than the other ones.126Table 3: Overall statistics obtained in the Task-8 of Se-mEval 2013SPA- ITA- FRA- DEU-RUN ENG ENG ENG ENGHighest 0.434 0.454 0.458 0.452Average 0.393 0.393 0.401 0.375Median 0.392 0.402 0.416 0.369Lowest 0.340 0.324 0.334 0.316BUAP-R1 0.364 0.358 0.368 0.322BUAP-R2 0.374 0.358 0.364 0.318BUAP-R3 0.380 0.358 0.362 0.316BUAP-R4 0.364 0.388 0.392 0.350BUAP-R5 0.386 0.360 0.372 0.318Table 4: Statistics of the approach 4, detailed by entail-ment judgmentENTAILMENT SPA- ITA- FRA- DEU-JUDGEMENT ENG ENG ENG ENGBACKWARD 0.495 0.462 0.431 0.389FORWARD 0.374 0.418 0.407 0.364NO-ENTAILMENT 0.359 0.379 0.379 0.352BI-DIRECTIONAL 0.277 0.327 0.352 0.3174 ConclusionsFive different approaches for the Cross-lingual Tex-tual Entailment for the Content Synchronization taskof Semeval 2013 are reported in this paper.
We usedseveral features for determining the textual entail-ment judgment between two texts T1 and T2 (writ-ten in two different languages).
The approach 4proposed, which employed lexical similarity and se-mantic similarity in English language only was theone that performed better.
As future work, we wouldlike to include more distance metrics which allow toextract additional features of the pair of sentencestopically related.ReferencesMaya Carrillo, Darnes Vilarin?o, David Pinto,Mireya Tovar, Saul Leo?n, and Esteban Castillo.Fcc: Three approaches for semantic textual sim-ilarity.
In *SEM 2012: The First Joint Confer-ence on Lexical and Computational Semantics ?Volume 1 and 2 (SemEval 2012), pages 631?634,Montre?al, Canada, 7-8 June 2012.
Association forComputational Linguistics.Ido Dagan and Oren Glickman.
Probabilistic tex-tual entailment: Generic applied modeling oflanguage variability.
In PASCAL Workshop onLearning Methods for Text Understanding andMining, 2004.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Wit-ten.
The weka data mining software: an update.SIGKDD Explor.
Newsl., 11(1):10?18, November2009.
ISSN 1931-0145.Yashar Mehdad, Matteo Negri, and Marcello Fed-erico.
Using bilingual parallel corpora for cross-lingual textual entailment.
In Proc.
of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technolo-gies - Volume 1, HLT ?11, pages 1336?1345,Stroudsburg, PA, USA, 2011.
Association forComputational Linguistics.Yashar Mehdad, Matteo Negri, and Marcello Fed-erico.
Detecting semantic equivalence and infor-mation disparity in cross-lingual documents.
InProc.
of the 50th Annual Meeting of the Associa-tion for Computational Linguistics: Short Papers- Volume 2, ACL ?12, pages 120?124, Strouds-burg, PA, USA, 2012.
Association for Computa-tional Linguistics.M.
Negri, A. Marchetti, Y. Mehdad, L. Ben-tivogli, and D. Giampiccolo.
Semeval-2013 Task8: Cross-lingual Textual Entailment for ContentSynchronization.
In Proceedings of the 7th Inter-national Workshop on Semantic Evaluation (Se-mEval 2013), 2013.Matteo Negri, Luisa Bentivogli, Yashar Mehdad,Danilo Giampiccolo, and Alessandro Marchetti.Divide and conquer: crowdsourcing the creationof cross-lingual textual entailment corpora.
InProc.
of the Conference on Empirical Methodsin Natural Language Processing, EMNLP ?11,pages 670?679, Stroudsburg, PA, USA, 2011.
As-sociation for Computational Linguistics.
ISBN978-1-937284-11-4.127
