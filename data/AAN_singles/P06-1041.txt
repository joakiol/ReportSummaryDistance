Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 321?328,Sydney, July 2006. c?2006 Association for Computational LinguisticsHybrid Parsing:Using Probabilistic Models as Predictors for a Symbolic ParserKilian A. Foth, Wolfgang MenzelDepartment of InformaticsUniversita?t Hamburg, Germany{foth|menzel}@informatik.uni-hamburg.deAbstractIn this paper we investigate the benefitof stochastic predictor components for theparsing quality which can be obtained witha rule-based dependency grammar.
By in-cluding a chunker, a supertagger, a PP at-tacher, and a fast probabilistic parser wewere able to improve upon the baseline by3.2%, bringing the overall labelled accu-racy to 91.1% on the German NEGRA cor-pus.
We attribute the successful integra-tion to the ability of the underlying gram-mar model to combine uncertain evidencein a soft manner, thus avoiding the prob-lem of error propagation.1 IntroductionThere seems to be an upper limit for the levelof quality that can be achieved by a parser if itis confined to information drawn from a singlesource.
Stochastic parsers for English trained onthe Penn Treebank have peaked their performancearound 90% (Charniak, 2000).
Parsing of Germanseems to be even harder and parsers trained on theNEGRA corpus or an enriched version of it stillperform considerably worse.
On the other hand,a great number of shallow components like tag-gers, chunkers, supertaggers, as well as general orspecialized attachment predictors have been devel-oped that might provide additional information tofurther improve the quality of a parser?s output, aslong as their contributions are in some sense com-plementory.
Despite these prospects, such possi-bilities have rarely been investigated so far.To estimate the degree to which the desired syn-ergy between heterogeneous knowledge sourcescan be achieved, we have established an exper-imental framework for syntactic analysis whichallows us to plug in a wide variety of externalpredictor components, and to integrate their con-tributions as additional evidence in the generaldecision-making on the optimal structural inter-pretation.
We refer to this approach as hybrid pars-ing because it combines different kinds of linguis-tic models, which have been acquired in totallydifferent ways, ranging from manually compiledrule sets to statistically trained components.In this paper we investigate the benefit of ex-ternal predictor components for the parsing qual-ity which can be obtained with a rule-based gram-mar.
For that purpose we trained a range of predic-tor components and integrated their output into theparser by means of soft constraints.
Accordingly,the goal of our research was not to extensively op-timize the predictor components themselves, butto quantify their contribution to the overall pars-ing quality.
The results of these experiments notonly lead to a better understanding of the utilityof the different knowledge sources, but also allowus to derive empirically based priorities for fur-ther improving them.
We are able to show thatthe potential of WCDG for information fusion isstrong enough to accomodate even rather unreli-able information from a wide range of predictorcomponents.
Using this potential we were able toreach a quality level for dependency parsing Ger-man which is unprecendented so far.2 Hybrid ParsingA hybridization seems advantageous even amongpurely stochastic models.
Depending on theirdegree of sophistication, they can and must betrained on quite different kinds of data collections,which due to the necessary annotation effort areavailable in vastly different amounts: While train-ing a probabilistic parser or a supertagger usually321requires a fully developed tree bank, in the caseof taggers or chunkers a much more shallow andless expensive annotation suffices.
Using a set ofrather simple heuristics, a PP-attacher can even betrained on huge amounts of plain text.Another reason for considering hybrid ap-proaches is the influence that contextual factorsmight exert on the process of determining the mostplausible sentence interpretation.
Since this influ-ence is dynamically changing with the environ-ment, it can hardly be captured from available cor-pus data at all.
To gain a benefit from such con-textual cues, e.g.
in a dialogue system, requires tointegrate yet another kind of external information.Unfortunately, stochastic predictor componentsare usually not perfect, at best producing prefer-ences and guiding hints instead of reliable certain-ties.
Integrating a number of them into a singlesystems poses the problem of error propagation.Whenever one component decides on the inputof another, the subsequent one will most proba-bly fail whenever the decision was wrong; if not,the erroneous information was not crucial anyhow.Dubey (2005) reported how serious this problemcan be when he coupled a tagger with a subsequentparser, and noted that tagging errors are by far themost important source of parsing errors.As soon as more than two components are in-volved, the combination of different error sourcesmigth easily lead to a substantial decrease of theoverall quality instead of achieving the desiredsynergy.
Moreover, the likelihood of conflictingcontributions will rise tremendously the more pre-dictor components are involved.
Therefore, it isfar from obvious that additional information al-ways helps.
Certainly, a processing regime isneeded which can deal with conflicting informa-tion by taking its reliability (or relative strength)into account.
Such a preference-based decisionprocedure would then allow stronger valued evi-dence to override weaker one.3 WCDGAn architecture which fulfills this requirementis Weighted Constraint Dependency Grammar,which was based on a model originally proposedby Maruyama (1990) and later extended withweights (Schro?der, 2002).
A WCDG models nat-ural language as labelled dependency trees onwords, with no intermediate constituents assumed.It is entirely declarative: it only contains rules(called constraints) that explicitly describe theproperties of well-formed trees, but no derivationrules.
For instance, a constraint can state that de-terminers must precede their regents, or that therecannot be two determiners for the same regent,or that a determiner and its regent must agree innumber, or that a countable noun must have a de-terminer.
Further details can be found in (Foth,2004).
There is only a trivial generator compo-nent which enumerates all possible combinationsof labelled word-to-word subordinations; amongthese any combination that satisfies the constraintsis considered a correct analysis.Constraints on trees can be hard or soft.
Ofthe examples above, the first two should proba-bly be considered hard, but the last two could bemade defeasible, particularly if a robust coverageof potentially faulty input is desired.
When twoalternative analyses of the same input violate dif-ferent constraints, the one that satisfies the moreimportant constraint should be preferred.
WCDGensures this by assigning every analysis a scorethat is the product of the weights of all instancesof constraint failures.
Parsing tries to retrieve theanalysis with the highest score.The weight of a constraint is usually determinedby the grammar writer as it is formulated.
Ruleswhose violation would produce nonsensical struc-tures are usually made hard, while rules that en-force preferred but not required properties receiveless weight.
Obviously this classification dependson the purpose of a parsing system; a prescrip-tive language definition would enforce grammat-ical principles such as agreement with hard con-straints, while a robust grammar must allow vio-lations but disprefer them via soft constraints.
Inpractice, the precise weight of a constraint is notparticularly important as long as the relative im-portance of two rules is clearly reflected in theirweights (for instance, a misinflected determiner isa language error, but probably a less severe onethan duplicate determiners).
There have been at-tempts to compute the weights of a WCDG au-tomatically by observing which weight vectorsperform best on a given corpus (Schro?der et al,2001), but weights computed completely automat-ically failed to improve on the original, hand-scored grammar.Weighted constraints provide an ideal interfaceto integrate arbitrary predictor components in asoft manner.
Thus, external predictions are treated322the same way as grammar-internal preferences,e.g.
on word order or distance.
In contrast to afiltering approach such a strong integration doesnot blindly rely on the available predictions but isable to question them as long as there is strongenough combined evidence from the grammar andthe other predictor components.For our investigations, we used the ref-erence implementation of WCDG availablefrom http://nats-www.informatik.uni-hamburg.de/download, which allowsconstraints to express any formalizable propertyof a dependency tree.
This great expressivenesshas the disadvantage that the parsing problembecomes NP-complete and cannot be solvedefficiently.
However, good success has beenachieved with transformation-based solutionmethods that start out with an educated guessabout the optimal tree and use constraint failuresas cues where to change labels, subordinations,or lexical readings.
As an example we showintermediate and final analyses of a sentence fromour test set (negra-s18959): ?Hier kletterte dieMarke von 420 auf 570 Mark.?
(Here the figurerose from 420 to 570 DM).SUBJPNPPPNPPOBJADETSADVhier kletterte die Marke von 420 auf 570 Mark .In the first analysis, subject and object relationsare analysed wrongly, and the noun phrase ?570Mark?
has not been recognized.
The analysis isimperfect because the common noun ?Mark?
lacksa Determiner.PNATTRPPPNPPSUBJDETSADVhier kletterte die Marke von 420 auf 570 Mark .The final analysis correctly takes ?570 Mark?
asthe kernel of the last preposition, and ?Marke?
asthe subject.
Altogether, three dependency edgeshad to be changed to arrive at this solution.Figure 1 shows the pseudocode of the best solu-tion algorithm for WCDG described so far (Foth etal., 2000).
Although it cannot guarantee to find thebest solution to the constraint satisfaction prob-lem, it requires only limited space and can be in-terrupted at any time and still returns a solution.If not interrupted, the algorithm terminates whenA := the set of levels of analysisW:= the set of all lexical readings of words in the sentenceL := the set of defined dependency labelsE := A ?
W ?
W ?
L = the base set of dependency edgesD := A ?
W = the set of domains da,w of all constraint variablesB := ?
= the best analysis foundC := ?
= the current analysis{ Create the search space.
}for e ?
Eif eval(e) > 0then da,w := da,w ?
{e}{ Build initial analysis.
}for da,w ?
De0 = arg maxe?da,wscore(C ?
{e})C := C ?
{e0}B := CT := ?
= tabu set of conflicts removed so far.U := ?
= set of unremovable conflicts.i := the penalty threshold above which conflicts are ignored.n := 0{ Remove conflicts.
}while ?
c ?
eval(C) \ U : penalty(c) > iand no interruption occurred{ Determine which conflict to resolve.
}cn := arg maxc?eval(C)\Upenalty(c)T := T ?
{c}{ Find the best resolution set.
}Rn := arg maxR ?
?domains(cn)score(replace(C, R))where replace(C, R) does not cause any c ?
Tand |R \ C| <= 2if no Rn can be found{ Consider c0 unremovable.
}n := 0, C := B, T := ?, U := U ?
{c0}else{ Take a step.
}n := n + 1, C := replace(C,Rn)if score(C) > score(B)n := 0, B := C, T := ?, U := U ?
eval(C)return BFigure 1: Basic algorithm for heuristic transfor-mational search.no constraints with a weight less than a prede-fined threshold are violated.
In contrast, a com-plete search usually requires more time and spacethan available, and often fails to return a usable re-sult at all.
All experiments described in this paperwere conducted with the transformational search.For our investigation we use a comprehensivegrammar of German expressed in about 1,000constraints (Foth et al, 2005).
It is intended tocover modern German completely and to be ro-323bust against many kinds of language error.
A largeWCDG such as this that is written entirely by handcan describe natural language with great precision,but at the price of very great effort for the grammarwriter.
Also, because many incorrect analyses areallowed, the space of possible trees becomes evenlarger than it would be for a prescriptive grammar.4 Predictor componentsMany rules of a language have the character ofgeneral preferences so weak that they are eas-ily overlooked even by a language expert; for in-stance, the ordering of elements in the Germanmittelfeld is subject to several types of preferencerules.
Other regularities depend crucially on thelexical identity of the words concerned; modellingthese fully would require the writing of a spe-cific constraint for each word, which is all but in-feasible.
Empirically obtained information aboutthe behaviour of a language would be welcomein such cases where manual constraints are notobvious or would require too much effort.
Thishas already been demonstrated for the case ofpart-of-speech tagging: because contextual cuesare very effective in determining the categories ofambiguous words, purely stochastical models canachieve a high accuracy.
(Hagenstro?m and Foth,2002) show that the TnT tagger (Brants, 2000)can be profitably integrated into WCDG parsing:A constraint that prefers analyses which conformto TnT?s category predictions can greatly reducethe number of spurious readings of lexically am-biguous words.
Due to the soft integration of thetagger, though, the parser is not forced to accept itspredictions unchallenged, but can override them ifthe wider syntactic context suggests this.
In ourexperiments (line 1 in Table 1) this happens 75times; 52 of these cases were actual errors com-mitted by the tagger.
These advantages taken to-gether made the tagger the by far most valuable in-formation source, whithout which the analysis ofarbitrary input would not be feasible at all.
There-fore, we use this component (POS) in all subse-quent experiments.Starting from this observation, we extended theidea to integrate several other external compo-nents that predict particular aspects of syntax anal-yses.
Where possible, we re-used publicly avail-able components to make the predictions ratherthan construct the best predictors possible; it islikely that better predictors could be found, butcomponents ?off the shelf?
or written in the sim-plest workable way proved enough to demonstratea positive benefit of the technique in each case.For the task of predicting the boundaries ofmajor constituents in a sentence (chunk parsing,CP), we used the decision tree model TreeTag-ger (Schmid, 1994), which was trained on arti-cles from Stuttgarter Zeitung.
The noun, verband prepositional chunk boundaries that it predictsare fed into a constraint which requires all chunkheads to be attached outside the current chunk, andall other words within it.
Obviously such informa-tion can greatly reduce the number of structural al-ternatives that have to be considered during pars-ing.
On our test set, the TreeTagger achieves aprecision of 88.0% and a recall of 89.5%.Models for category disambiguation can easilybe extended to predict not only the syntactic cate-gory, but also the local syntactic environment ofeach word (supertagging).
Supertags have beensuccessfully applied to guide parsing in symbolicframeworks such as Lexicalised Tree-Adjoninggrammar (Bangalore and Joshi, 1999).
To obtainand evaluate supertag predictions, we re-trainedthe TnT Tagger on the combined NEGRA andTIGER treebanks (1997; 2002).
Putting aside thestandard NEGRA test set, this amounts to 59,622sentences with 1,032,091 words as training data.For each word in the training set, the local contextwas extracted and encoded into a linear represen-tation.
The output of the retrained TnT then pre-dicts the label of each word, whether it follows orprecedes its regent, and what other types of rela-tions are found below it.
Each of these predictionsis fed into a constraint which weakly prefers de-pendencies that do not violate the respective pre-diction (ST).
Due to the high number of 12947 su-pertags in the maximally detailed model, the ac-curacy of the supertagger for complete supertagsis as low as 67.6%.
Considering that a detailed su-pertag corresponds to several distinct predictions(about label, direction etc.
), it might be more ap-propriate to measure the average accuracy of thesedistinct predictions; by this measure, the individ-ual predictions of the supertagger are 84.5% accu-rate; see (Foth et al, 2006) for details.As with many parsers, the attachment of prepo-sitions poses a particular problem for the baseWCDG of German, because it is depends largelyupon lexicalized information that is not widelyused in its constraints.
However, such information324Reannotated TransformedPredictors Dependencies Dependencies1: POS only 89.7%/87.9% 88.3%/85.6%2: POS+CP 90.2%/88.4% 88.7%/86.0%3: POS+PP 90.9%/89.1% 89.6%/86.8%4: POS+ST 92.1%/90.7% 90.7%/88.5%5: POS+SR 91.4%/90.0% 90.0%/87.7%6: POS+PP+SR 91.6%/90.2% 90.1%/87.8%7: POS+ST+SR 92.3%/90.9% 90.8%/88.8%8: POS+ST+PP 92.1%/90.7% 90.7%/88.5%9: all five 92.5%/91.1% 91.0%/89.0%Table 1: Structural/labelled parsing accuracy withvarious predictor components.can be automatically extracted from large corporaof trees or even raw text: prepositions that tendto occur in the vicinity of specific nouns or verbsmore often than chance would suggest can be as-sumed to modify those words preferentially (Volk,2002).A simple probabilistic model of PP attachment(PP) was used that counts only the occurrences ofprepositions and potential attachment words (ig-noring the information in the kernel noun of thePP).
It was trained on both the available tree banksand on 295,000,000 words of raw text drawn fromthe taz corpus of German newspaper text.
Whenused to predict the probability of the possibleregents of each preposition in each sentence, itachieved an accuracy of 79.4% and 78.3%, respec-tively (see (Foth and Menzel, 2006) for details).The predictions were integrated into the grammarby another constraint which disprefers all possibleregents to the corresponding degree (except for thepredicted regent, which is not penalized at all).Finally, we used a full dependency parser in or-der to obtain structural predictions for all words,and not merely for chunk heads or prepositions.We constructed a probabilistic shift-reduce parser(SR) for labelled dependency trees using themodel described by (Nivre, 2003): from all avail-able dependency trees, we reconstructed the se-ries of parse actions (shift, reduce and attach)that would have constructed the tree, and thentrained a simple maximum-likelihood model thatpredicts parse actions based on features of the cur-rent state such as the categories of the currentand following words, the environment of the topstack word constructed so far, and the distance be-tween the top word and the next word.
This oracleparser achieves a structural and labelled accuracyof 84.8%/80.5% on the test set but can only predictprojective dependency trees, which causes prob-lems with about 1% of the edges in the 125,000dependency trees used for training; in the inter-est of simplicity we did not address this issue spe-cially, instead relying on the ability of the WCDGparser to robustly integrate even predictions whichare wrong by definition.5 EvaluationSince the WCDG parser never fails on typical tree-bank sentences, and always delivers an analysisthat contains exactly one subordination for eachword, the common measures of precision, recalland f-score all coincide; all three are summarizedas accuracy here.
We measure the structural (i.e.unlabelled) accuracy as the ratio of correctly at-tached words to all words; the labelled accuracycounts only those words that have the correct re-gent and also bear the correct label.
For compar-ison with previous work, we used the next-to-last1,000 sentences of the NEGRA corpus as our testset.
Table 1 shows the accuracy obtained.1The gold standard used for evaluation was de-rived from the annotations of the NEGRA tree-bank (version 2.0) in a semi-automatic procedure.First, the NEGRA phrase structures were auto-matically transformed to dependency trees withthe DEPSY tool (Daum et al, 2004).
However,before the parsing experiments, the results weremanually corrected to (1) take care of system-atic inconsistencies between the NEGRA annota-tions and the WCDG annotations (e.g.
for non-projectivities, which in our case are used only ifnecessary for an ambiguity free attachment of ver-bal arguments, relative clauses and coordinations,but not for other types of adjuncts) and (2) to re-move inconsistencies with NEGRAs own annota-tion guidelines (e.g.
with regard to elliptical andco-ordinated structures, adverbs and subordinatedmain clauses.)
To illustrate the consequences ofthese corrections we report in Table 1 both kindsof results: those obtained on our WCDG-conformannotations (reannotated) and the others on theraw output of the automatic conversion (trans-1Note that the POS model employed by TnT was trainedon the entire NEGRA corpus, so that there is an overlap be-tween the training set of TnT and the test set of the parser.However, control experiments showed that a POS modeltrained on the NEGRA and TIGER treebanks minus the testset results in the same parsing accuracy, and in fact slightlybetter POS accuracy.
All other statistical predictors weretrained on data disjunct from the test set.325formed), although the latter ones introduce a sys-tematic mismatch between the gold standard andthe design principles of the grammar.The experiments 2?5 show the effect of addingthe POS tagger and one of the other predictor com-ponents to the parser.
The chunk parser yieldsonly a slight improvement of about 0.5% accu-racy; this is most probably because the baselineparser (line 1) does not make very many mistakesat this level anyway.
For instance, the relation typewith the highest error rate is prepositional attach-ment, about which the chunk parser makes no pre-dictions at all.
In fact, the benefit of the PP com-ponent alone (line 3) is much larger even thoughit predicts only the regents of prepositions.
Thetwo other components make predictions about alltypes of relations, and yield even bigger benefits.When more than one other predictor is added tothe grammar, the beneft is generally higher thanthat of either alone, but smaller than the sum ofboth.
An exception is seen in line 8, where thecombination of POS tagging, supertagging and PPprediction fails to better the results of just POStagging and supertagging (line 4).
Individual in-spection of the results suggests that the lexicalizedinformation of the PP attacher is often counter-acted by the less informed predictions of the su-pertagger (this was confirmed in preliminary ex-periments by a gain in accuracy when prepositionswere exempted from the supertag constraint).
Fi-nally, combining all five predictors results in thehighest accuracy of all, improving over the firstexperiment by 2.8% and 3.2% for structural andlabelled accuracy respectively.We see that the introduction of stochastical in-formation into the handwritten language model isgenerally helpful, although the different predictorscontribute different types of information.
The POStagger and PP attacher capture lexicalized regular-ities which are genuinely new to the grammar: ineffect, they refine the language model of the gram-mar in places that would be tedious to describethrough individual rules.
In contrast, the moreglobal components tend to make the same predic-tions as the WCDG itself, only explicitly.
Thisguides the parser so that it tends to check the cor-rect alternative first more often, and has a greaterchance of finding the global optimum.
This ex-plains why their addition increases parsing accu-racy even when their own accuracy is markedlylower than even the baseline (line 1).6 Related workThe idea of integrating knowledge sources of dif-ferent origin is not particularly new.
It has beensuccessfully used in areas like speech recognitionor statistical machine translation where acousticmodels or bilingual mappings have to be com-bined with (monolingual) language models.
Asimilar architecture has been adopted by (Wangand Harper, 2004) who train an n-best supertag-ger and an attachment predictor on the Penn Tree-bank and obtain an labelled F-score of 92.4%,thus slightly outperforming the results of (Collins,1999) who obtained 92.0% on the same sentences,but evaluating on transformed phrase structuretrees instead on directly computed dependency re-lations.Similar to our approach, the result of (Wangand Harper, 2004) was achieved by integratingthe evidence of two (stochastic) components intoa single decision procedure on the optimal inter-pretation.
Both, however, have been trained onthe very same data set.
Combining more thantwo different knowledge sources into a systemfor syntactic parsing to our knowledge has neverbeen attempted so far.
The possible synergy be-tween different knowledge sources is often as-sumed but viable alternatives to filtering or selec-tion in a pipelined architecture have not yet beenbeen demonstrated successfully.
Therefore, exter-nal evidence is either used to restrict the space ofpossibilities for a subsequent component (Clarkand Curran, 2004) or to choose among the alter-native results which a traditional rule-based parserusually delivers (Malouf and van Noord, 2004).
Incontrast to these approaches, our system directlyintegrates the available evidence into the decisionprocedure of the rule-based parser by modifyingthe objective function in a way that helps guidingthe parsing process towards the desired interpre-tation.
This seems to be crucial for being able toextend the approach to multiple predictors.An extensive evaluation of probabilistic de-pendency parsers has recently been carried outwithin the framework of the 2006 CoNLLshared task (see http://nextens.uvt.nl/?conll).
Most successful for many of the 13 dif-ferent languages has been the system described in(McDonald et al, 2005).
This approach is basedon a procedure for online large margin learningand considers a huge number of locally availablefeatures to predict dependency attachments with-326out being restricted to projective structures.
ForGerman it achieves 87.34% labelled and 90.38%unlabelled attachment accuracy.
These results areparticularly impressive, since due to the strictly lo-cal evaluation of attachment hypotheses the run-time complexity of the parser is only O(n2).Although a similar source of text has been usedfor this evaluation (newspaper), the numbers can-not be directly compared to our results since boththe test set and the annotation guidelines differfrom those used in our experiments.
Moreover, thedifferent methodologies adopted for system devel-opment clearly favour a manual grammar develop-ment, where more lexical resources are availableand because of human involvement a perfect iso-lation between test and training data can only beguaranteed for the probabilistic components.
Onthe other hand CoNLL restricted itself to the eas-ier attachment task and therefore provided the goldstandard POS tag as part of the input data, whereasin our case pure word form sequences are anal-ysed and POS disambiguation is part of the taskto be solved.
Finally, punctuation has been ig-nored in the CoNLL evaluation, while we includedit in the attachment scores.
To compensate for thelast two effects we re-evaluated our parser withoutconsidering punctuation but providing it with per-fect POS tags.
Thus, under similar conditions asused for the CoNLL evaluation we achieved a la-belled accuracy of 90.4% and an unlabelled one of91.9%.Less obvious, though, is a comparison with re-sults which have been obtained for phrase struc-ture trees.
Here the state of the art for German isdefined by a system which applies treebank trans-formations to the original NEGRA treebank andextends a Collins-style parser with a suffix analy-sis (Dubey, 2005).
Using the same test set as theone described above, but restricting the maximumsentence length to 40 and providing the correctPOS tag, the system achieved a labelled bracketF-score of 76.3%.7 ConclusionsWe have presented an architecture for the fusion ofinformation contributed from a variety of compo-nents which are either based on expert knowledgeor have been trained on quite different data col-lections.
The results of the experiments show thatthere is a high degree of synergy between thesedifferent contributions, even if they themselves arefairly unreliable.
Integrating all the available pre-dictors we were able to improve the overall la-belled accuracy on a standard test set for Germanto 91.1%, a level which is as least as good as theresults reported for alternative approaches to pars-ing German.The result we obtained also challenges the com-mon perception that rule-based parsers are neces-sarily inferior to stochastic ones.
Supplied withappropriate helper components, the WCDG parsernot only reached a surprisingly high level of out-put quality but in addition appears to be fairly sta-ble against changes in the text type it is applied to(Foth et al, 2005).We attribute the successful integration of dif-ferent information sources primarily to the funda-mental ability of the WCDG grammar to combineevidence in a soft manner.
If unreliable informa-tion needs to be integrated, this possibility is cer-tainly an undispensible prerequisite for prevent-ing local errors from accumulating and leading toan unacceptably low degree of reliability for thewhole system eventually.
By integrating the dif-ferent predictors into the WCDG parsers?s generalmechanism for evidence arbitration, we not onlyavoided the adverse effect of individual error ratesmultiplying out, but instead were able to even raisethe degree of output quality substantially.From the fact that the combination of all pre-dictor components achieved the best results, evenif the individual predictions are fairly unreliable,we can also conclude that diversity in the selec-tion of predictor components is more importantthan the reliability of their contributions.
Amongthe available predictor components which couldbe integrated into the parser additionally, the ap-proach of (McDonald et al, 2005) certainly looksmost promising.
Compared to the shift-reduceparser which has been used as one of the pre-dictor components for our experiments, it seemsparticularly attractive because it is able to predictnon-projective structures without any additionalprovision, thus avoiding the misfit between our(non-projective) gold standard annotations and therestriction to projective structures that our shift-reduce parser suffers from.Another interesting goal of future work mightbe to even consider dynamic predictors, whichcan change their behaviour according to text typeand perhaps even to text structure.
This, however,would also require extending and adapting the cur-327rently dominating standard scenario of parser eval-uation substantially.ReferencesSrinivas Bangalore and Aravind K. Joshi.
1999.
Su-pertagging: an approach to almost parsing.
Compu-tational Linguistics, 25(2):237?265.Thorsten Brants, Roland Hendriks, Sabine Kramp,Brigitte Krenn, Cordula Preis, Wojciech Skut,and Hans Uszkoreit.
1997.
Das NEGRA-Annotationsschema.
Negra project report, Uni-versita?t des Saarlandes, Computerlinguistik,Saarbru?cken, Germany.Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The TIGERtreebank.
In Proceedings of the Workshop on Tree-banks and Linguistic Theories, Sozopol.Thorsten Brants.
2000.
TnT ?
A Statistical Part-of-Speech Tagger.
In Proceedings of the Sixth AppliedNatural Language Processing Conference (ANLP-2000), Seattle, WA, USA.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.
In Proc.
NAACL-2000.Stephen Clark and James R. Curran.
2004.
The impor-tance of supertagging for wide-coverage CCG pars-ing.
In Proc.
20th Int.
Conf.
on Computational Lin-guistics, Coling-2004.Michael Collins.
1999.
Head-Driven Statistical Mod-els for Natural Language Parsing.
Phd thesis, Uni-versity of Pennsylvania, Philadephia, PA.Michael Daum, Kilian Foth, and Wolfgang Menzel.2004.
Automatic transformation of phrase treebanksto dependency trees.
In Proc.
4th Int.
Conf.
on Lan-guage Resources and Evaluation, LREC-2004, Lis-bon, Portugal.Amit Dubey.
2005.
What to do when lexicaliza-tion fails: parsing German with suffix analysis andsmoothing.
In Proc.
43rd Annual Meeting of theACL, Ann Arbor, MI.Kilian Foth and Wolfgang Menzel.
2006.
The benefitof stochastic PP-attachment to a rule-based parser.In Proc.
21st Int.
Conf.
on Computational Linguis-tics, Coling-ACL-2006, Sydney.Kilian A. Foth, Wolfgang Menzel, and Ingo Schro?der.2000.
A Transformation-based Parsing Techniquewith Anytime Properties.
In 4th Int.
Workshop onParsing Technologies, IWPT-2000, pages 89 ?
100.Kilian Foth, Michael Daum, and Wolfgang Menzel.2005.
Parsing unrestricted German text with defea-sible constraints.
In H. Christiansen, P. R. Skad-hauge, and J. Villadsen, editors, Constraint Solv-ing and Language Processing, volume 3438 of Lec-ture Notes in Artificial Intelligence, pages 140?157.Springer-Verlag, Berlin.Kilian Foth, Tomas By, and Wolfgang Menzel.
2006.Guiding a constraint dependency parser with su-pertags.
In Proc.
21st Int.
Conf.
on ComputationalLinguistics, Coling-ACL-2006, Sydney.Kilian Foth.
2004.
Writing Weighted Constraintsfor Large Dependency Grammars.
In Proc.
Re-cent Advances in Dependency Grammars, COLING-Workshop 2004, Geneva, Switzerland.Jochen Hagenstro?m and Kilian A. Foth.
2002.
Taggingfor robust parsers.
In Proc.
2nd.
Int.
Workshop, Ro-bust Methods in Analysis of Natural Language Data,ROMAND-2002.Robert Malouf and Gertjan van Noord.
2004.
Widecoverage parsing with stochastic attribute valuegrammars.
In Proc.
IJCNLP-04 Workshop BeyondShallow Analyses - Formalisms and statistical mod-eling for deep analyses, Sanya City, China.Hiroshi Maruyama.
1990.
Structural disambiguationwith constraint propagation.
In Proc.
28th AnnualMeeting of the ACL (ACL-90), pages 31?38, Pitts-burgh, PA.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proc.
HumanLanguage Technology Conference / Conference onEmpirical Methods in Natural Language Process-ing, HLT/EMNLP-2005, Vancouver, B.C.Joakim Nivre.
2003.
An Efficient Algorithm for Pro-jective Dependency Parsing.
In Proc.
4th Interna-tional Workshop on Parsing Technologies, IWPT-2003, pages 149?160.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Int.
Conf.
on NewMethods in Language Processing, Manchester, UK.Ingo Schro?der, Horia F. Pop, Wolfgang Menzel, andKilian Foth.
2001.
Learning grammar weights us-ing genetic algorithms.
In Proceedings Eurocon-ference Recent Advances in Natural Language Pro-cessing, pages 235?239, Tsigov Chark, Bulgaria.Ingo Schro?der.
2002.
Natural Language Parsing withGraded Constraints.
Ph.D. thesis, Dept.
of Com-puter Science, University of Hamburg, Germany.Martin Volk.
2002.
Combining unsupervised and su-pervised methods for pp attachment disambiguation.In Proc.
of COLING-2002, Taipeh.Wen Wang and Mary P. Harper.
2004.
A statisticalconstraint dependency grammar (CDG) parser.
InProc.
ACL Workshop Incremental Parsing: BringingEngineering and Cognition Together, pages 42?49,Barcelona, Spain.328
