Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 90?96,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsSentiment classification of online political discussions: a comparison of aword-based and dependency-based methodHugo Lewi HammerOslo and AkershusUniversity CollegeDepartment of Computer Sciencehugo.hammer@hioa.noPer Erik SolbergSpr?akbankenThe National Libraryof Norwayp.e.solberg@ifikk.uio.noLilja ?vrelidDepartment of InformaticsUniversity of Osloliljao@ifi.uio.noAbstractOnline political discussions have receiveda lot of attention over the past years.
Inthis paper we compare two sentiment lexi-con approaches to classify the sentiment ofsentences from political discussions.
Thefirst approach is based on applying thenumber of words between the target andthe sentiment words to weight the sen-tence sentiment score.
The second ap-proach is based on using the shortest pathsbetween target and sentiment words in adependency graph and linguistically mo-tivated syntactic patterns expressed as de-pendency paths.
The methods are testedon a corpus of sentences from online Nor-wegian political discussions.
The resultsshow that the method based on depen-dency graphs performs significantly betterthan the word-based approach.1 IntroductionOver the past years online political discussionshave received a lot of attention.
E.g.
theObama 2012 election team initiated an extensiveuse of text analytics and machine learning tech-niques towards online material to guide advertis-ing campaigns, identifying key voters, and im-prove fundraising (Issenberg, 2012).
There hasalso been a lot of concern about the alarminggrowth in hate and racism against minorities likeMuslims, Jews and Gypsies in online discussions(Goodwin et al., 2013; Bartlett et al., 2013).
Sen-timent analysis (SA) is the discipline of automat-ically determining sentiment in text material andmay be one important tool in understanding thediversity of opinions on the Internet.In this paper we focus on classifying the sen-timent towards religious/political topics, say theQuran, in Norwegian political discussion.
We usea lexicon-based approach where we classify thesentiment of a sentence based on the polarity ofsentiment words in relation to a set of target wordsin the sentence.
We expect that statistically theimportance of a sentiment word towards the tar-get word is related to the number of words be-tween the sentiment and target word as suggestedby Ding et al.
(2008).
Information about the syn-tactic environment of certain words or phrases hasin previous work also been shown to be useful forthe task of sentiment classification (Wilson et al.,2009; Jiang et al., 2011).
In this work we thereforecompare the results obtained using a token-baseddistance measure with a novel syntax-based dis-tance measure obtained using dependency graphsand further augmented with linguistically moti-vated syntactic patterns expressed as dependencypaths.
In order to evaluate the proposed methods,we furthermore present a freely available corpus ofNorwegian political discussion related to religionand immigration, which has been manually anno-tated for the sentiment expressed towards a set oftarget words, as well as a manually translated sen-timent lexicon.2 Previous workSentiment classification aims to classify a docu-ment or sentence as either positive or negative andsometimes also neutral.
There are mainly two ap-proaches, one based on machine learning and onebased on using a list of words with given senti-ment scores (lexicon-based approach).
For ma-chine learning any existing method can be used,e.g.
na?
?ve Bayes and support vector machine,(Joachims, 1999; Shawe-Taylor and Cristianini,2000).
One simple lexicon-based approach is tocount the number of words with positive and neg-ative sentiment in the document as suggested byHu and Liu (2004).
One may classify the opin-ion of larger documents like movie or product re-views or smaller documents like tweets, comments90or sentences.
See Liu (2012), chapters three to fiveand references therein for the description of sev-eral opinion classification methods.SA has mostly been used to analyze opinionsin comments and reviews about commercial prod-ucts, but there are also examples of SA towardspolitical tweets and discussions, see e.g.
Tumas-jan et al.
(2010); Chen et al.
(2010).
SA of politi-cal discussions is known to be a difficult task sincecitations, irony and sarcasm is very common (Liu,2012).3 Proposed SA methodsIn this section we present two methods to clas-sify sentences as either positive, neutral or neg-ative towards a target word.
Both methods fol-low the same general algorithm presented belowwhich is inspired by Ding et al.
(2008) and isbased on a list of sentiment words each associ-ated with a sentiment score representing the polar-ity and strength of the sentiment word (sentimentlexicon).
Both target words, sentiment words andsentiment shifters can in general appear severaltimes in a sentence.
Sentiment shifters are wordsthat potentially shift the sentiment of a sentencefrom positive to negative or negative to positive.E.g.
?not happy?
have the opposite polarity thanjust ?happy?.
Let twi, i ?
{1, 2, .
.
.
, I} representappearance number i of the target word in the sen-tence.
Note that we only consider one target wordat the time.
E.g.
if a sentence contains two targetwords, e.g.
Quran and Islam, the sentence is firstclassified with respect to Quran and then with re-spect to Islam.
Further let swj, j ?
{1, 2, .
.
.
, J}be appearance number j of a sentiment word in thesentence.
Finally let ss = (ss1, ss2, .
.
.
, ssK) rep-resent the sentiment shifters in the sentence.
Wecompute a sentiment score, S, for the sentence asfollowsS =1II?i=1J?j=1imp(twi, swj)shift(swj, ss)(1)where the function imp computes the importanceof the sentiment word swjon the target word ap-pearance twi.
This will be computed in differentways as described below.
Further, the functionshift(swj, ss) computes whether the sentiment ofswjshould be shifted based on all the sentimentshifters in the sentence.
It returns ?1 (sentimentshift) if some of the sentiment shifters are withindpwords in front or dnwords behind swj, re-spectively.
Else the function, returns 1 (no sen-timent shift).
We classify the sentiment towardsthe target word to be positive, neutral or negativeif S >= tp, tp> S > tnand S <= tn, respec-tively.
The parameters dp, dn, tpand tnis tunedusing a training set, as described in section 5 be-low.3.1 Word distance methodFor the word distance method we use the follow-ing imp functionimp(twi, swj) =sentsc(swj)worddist(twi, swj)(2)where sentsc(swj) is the sentiment scoreof swjfrom the sentiment lexicon andworddist(twi, swj) is the number of wordsbetween twiand swjin the sentence plus one.3.2 Parse tree methodWhen determining the sentiment expressed to-wards a specific target word, the syntactic environ-ment of this word and how it relates to sentiment-bearing words in the context may clearly be of im-portance.
In the following we present a modifi-cation of the scoring function described above toalso take into account the syntactic environmentof the target words.
The function is defined overdependency graphs, i.e.
connected, acyclic graphsexpressing bilexical relations.Dependency distance One way of expressingthe syntactic environment of a target word with re-spect to a sentiment word is to determine its dis-tance in the dependency graph.
We therefore de-fine a distance function depdist(twi, swj) whichreturns the number of nodes in the shortest depen-dency path from the target word to the sentimentword in the dependency graph.
The shortest pathis determined using Dijkstra?s shortest path algo-rithm (Dijkstra, 1959).Dependency paths A second way of determin-ing the importance of a sentiment word towardsa target based on syntactically parsed texts, is toestablish a list of grammatical dependency pathsbetween words, and test whether such paths existbetween the targets and sentiment words (Jianget al., 2011).
The assumption would be that twowords most likely are semantically related to eachother if there is a meaningful grammatical relation91between them.
Furthermore, it is reasonable to ex-pect than some paths are stronger indicators of theoverall sentiment of the sentence than others.
Totest this method, we have manually created a listof 42 grammatical dependency paths, divided intofour groups, and given them a score from 0 ?
1.The higher the score is, the better indicator of sen-timent the path is assumed to be.
In the followingparagraphs, we will briefly present the groups ofpaths and the maximum score we have assignedin each group.
The paths are represented in thefollowing format: postag-target:postag-sentimentword DEPREL up/dn( DEPREL up/dn etc.
).Up and dn indicate the direction of the traversedarc in the graph.A first group consists of paths from sub-ject targets to sentiment predicates.
Suchpaths can e.g.
go from a subject to averbal predicate, subst:verb SUBJ up, orfrom a subject to an adjectival or nominalpredicate in the context of a copular verb,subst:adj/subst SUBJ up SPRED dn.
Pathsin this group can get the maximum score, 1.The combination of a subject and a predicatewill result in a proposition, a statement whichis evaluated as true or false.
We expect that aproposition typically will represent the opinion ofthe speaker, although e.g.
irony and certain kindsof embedding can shift the truth evaluation insome cases.
Secondly, if the predicate representsan event brought about by an intentional agent,the subject will typically represent that agent.
Ifthe predicate has a positive or negative sentiment,we expect that this sentiment is directed towardsthis intentional agent.A second group we have considered, containspaths from subject targets to sentiment words em-bedded within the predicate, such as from thesubject to the nominal direct object of a verb,subst:subst SUBJ up DOBJ dn.
Paths fromsubjects into different kinds of adverbials are alsoa part of this group.
We consider paths from sub-jects to objects to be good indicators of sentimentand assign them the highest score, 1 .
The rea-soning is much the same as for subject predicatepaths: The statement is a proposition and the sub-ject will often be the agent of the event.
Also, theobject and the verb are presumably closely seman-tically connected, as the former is an argument ofthe latter.
Paths into adverbials get lower values,as adverbials often are less semantically connectedto the predicate than objects.The paths in our third group go from targets tosentiment words within the predicate.
These in-clude paths from nominal direct object target toverbal predicates, subst:verb DOBJ up, and fromvarious kinds of adverbials to verbal predicates,etc.
We assume that predicate-internal paths areless good indicators of sentiment than the abovegroups, as such paths do not constitute a proposi-tion.
Also, arguments within the predicate usuallydo not represent intentional agents.
Such pathswill get the score 1/3.Our fourth and final group of dependency pathscontains paths internal to the nominal phrase,such as from target nouns to attributive adjec-tives, subst:adj ATR dn, and from target comple-ments of attributive prepositions to target nouns,subst:subst PUTFYLL up ATR up.
A posi-tively or negatively qualified noun will probablyoften represent the sentiment of the speaker.
Atthe same time, a nominal phrase of this kind can beused in many different contexts where the holderof the sentiment is not the speaker.
We assign 2/3as the maximum score.
Table 1 summarizes thegroups of dependency paths.Path group Number Score rangeSubj.
to pred.
9 1Subj.
to pred.-internal 13 1/3?
1Pred.-internal 6 1/3NP-internal 14 1/3?
2/3Table 1: Grouping of dependency paths with thenumber of paths and score range for each group.Modified scoring function Let D denote theset of all salient dependency paths.
The func-tion gram(twi, swj) returns the dependency path,and if gram(twi, swj) ?
D, then the functionWdep(twi, swj) ?
[0, 1], returns the saliencescore of the path.
Further let depdist(twi, swj)return the dependency distance, as describedabove.
The imp function is computed as follows.If gram(twi, swj) ?
D we useimp(twi, swj) =?
?
sentsc(swj)Wdep(twi, swj)+(1?
?)
?sentsc(swj)depdist(twi, swj)(3)where ?
?
[0, 1] is a parameter that weights thescore from the salient dependency path and the92tree distance and can be tuned using a training set.If gram(twi, swj) 6?
D we simply useimp(twi, swj) =sentsc(swj)depdist(twi, swj)(4)Note that when ?
= 0, (3) reduces to (4).4 Linguistic resources4.1 Sentiment corpusWe did not find any suitable annotated text ma-terial related to political discussions in Norwe-gian and therefore created our own.
We manu-ally selected 46 debate articles from the Norwe-gian online newspapers NRK Ytring, Dagbladet,Aftenposten, VG and Bergens Tidene.
To each de-bate article there were attached a discussion threadwhere readers could express their opinions andfeelings towards the content of the debate arti-cle.
All the text from the debate articles and thesubsequent discussions were collected using textscraping (Hammer et al., 2013).
The debate arti-cles were related to religion and immigration andwe wanted to classify the sentiment towards allforms of the following target words: islam, mus-lim, quran, allah, muhammed, imam and mosque.These represent topics that typically create a lot ofactive discussions and disagreements.We automatically divided the material into sen-tences and all sentences containing at least one tar-get word and one sentiment word were kept forfurther analysis.
If a sentence contained more thanone target word, e.g.
both Islam and Quran, thesentence was repeated one time for each targetword in the final text material.
We could then clas-sify the sentiment towards each of the target wordsin the sentence consecutively.
To assure that we donot underestimate the uncertainty in the statisticalanalysis, we see each repetition of the sentence asthe same sentence with respect to the sentence ran-dom effect in the regression model in Section 5.1Each sentence was manually annotated as towhether the commenter was positive, negativeor neutral towards the target word in the sen-tence.
Each sentence was evaluated individually.The sentences were annotated based on real-worldknowledge, e.g.
a sentence like ?Muhammed islike Hitler?
would be annotated as a negative sen-timent towards Muhammed.
Further, if a com-menter presented a negative fact about the targetword, the sentence would be denoted as negative.Negative Neutral PositiveTraining 174 (46%) 162 (42%) 46 (12%)Test 102 (33%) 182 (59%) 24 (8%)Table 2: Manual annotation of training and testset.In order to assess inter-annotator agreement, arandom sample of 65 sentences from the originaltext material was annotated by a second annota-tor.
These sentences were not included in eitherthe training or test set.
For these sentences, thetwo annotators agreed on 58, which is an 89%agreement, with a 95% confidence interval equalto (79%, 95%) assuming that each sentence is in-dependent.
Since the sentences are drawn ran-domly from the population of all sentences this isa fair assumption.Finally the material was divided into two partswhere the first half of the debate articles with sub-sequent discussions make up the training set andthe rest constitutes a held-out test set.
In the man-ual development of the salient dependency paths,only the training set was used.
After the division,the training and test set consisted of a total of 382and 308 sentences, respectively.
Table 4.1 summa-rizes the annotation found in the corpus.4.2 Corpus postprocessingThe sentiment corpus was PoS-tagged and parsedusing the Bohnet&Nivre-parser (Bohnet andNivre, 2012).
This parser is a transition-baseddependency parser with joint tagger that imple-ments global learning and a beam search for non-projective labeled dependency parsing.
This lat-ter parser has recently outperformed pipeline sys-tems (such as the Malt and MST parsers) both interms of tagging and parsing accuracy for typolog-ically diverse languages such as Chinese, English,and German.
It has been reported to obtain a la-beled accuracy of 87.7 for Norwegian (Solberg etal., 2014).
The parser is trained on the Norwe-gian Dependency Treebank (NDT).
The NDT is atreebank created at the National Library of Nor-way in the period 2011-2013, manually annotatedwith part-of-speech tags, morphological features,syntactic functions and dependency graphs (Sol-berg et al., 2014; Solberg, 2013).
It consists ofapproximately 600 000 tokens, equally distributed93between Norwegian Bokm?al and Nynorsk, the twoNorwegian written standards.
Only the Bokm?alsubcorpus has been used here.
Detailed annota-tion guidelines in English will be made availablein April 2014 (Kinn et al., 2014).4.3 Sentiment lexicon and sentiment shiftersUnfortunately, no sentiment lexicon existed for theNorwegian language and therefore we developedour own by manually translating the AFINN list(Nielsen, 2011).
We also manually added 1590words relevant to political discussions like ?de-port?, ?expel?, ?extremist?
and ?terrorist?, endingup with a list of 4067 Norwegian sentiment words.Each word were given a score from ?5 to 5 rang-ing from words with extremely negative sentiment(e.g.
?behead?)
to highly positive sentiment words(e.g.
?breathtaking?
).Several Norwegian sentiment shifters were con-sidered but only the basic shifter ?not?
improvedthe sentiment classification and therefore only thisword was used in the method.5 ExperimentsIn this study we compare four different methodsbased on the general algorithm in (1).?
We use the imp-function presented in (2).
Wedenote this method WD (word distance).?
For this method and the two below we use theimp-function in (3).
Further we set ?
= 0which means that we do not use the salientdependency paths.
We denote this method A0(?
= 0).?
We set ?
= 1 and for all dependency pathswe set Wdep= 2/3.
We denote this methodCW (constant weights).?
We set ?
= 1 and for Wdepwe use theweights presented in Table 1.
We denotethis method OD (optimal use of dependencypaths)For each method we used the training set to man-ually tune the parameters dp, dn, tpand tnof themethod.
The parameters were tuned to optimizethe number of correct classifications.5.1 Statistical analysis of classificationperformanceWe compare the classification performance ofa set of M different methods, denoted asdpdntptnAccuracy p-valWD 2 0 0.7 0.0 47%A0 2 0 2.0 0.3 52% 0.023CW 2 0 2.0 0.3 52% 0.024OD 2 0 2.0 0.3 53% 0.016Table 3: The second to the fifth column showthe optimal values of the parameters of the modeltuned using the training set.
The sixth columnshow the number of correct classifications and thelast column shows p-values testing whether themethod performs better than WD.
?1,?2, .
.
.
,?M, using random effect logistic re-gression.
Let the stochastic variable Ytm?
{0, 1} represents whether method ?m, m ?
{1, 2, .
.
.
,M} classified the correct sentiment tosentence number t ?
{1, 2, .
.
.
, T}, where T isthe number of sentences in the test set.
We letYtmbe the dependent variable of the regressionmodel.
The different methods ?1,?2, .
.
.
,?Misincluded as a categorical independent variable inthe regression model.
We also assume that classi-fication performance of the different methods de-pends on the sentence to be classified, thus the sen-tence number is included as a random effect.
Fit-ting the model to the observed classification per-formance of the different methods we are able tosee if the probability of classifying correctly sig-nificantly vary between the methods.The statistical analysis is performed using thestatistical program R (R Core Team, 2013) and theR package lme4 (Bates et al., 2013).5.2 ResultsTable 3 shows the optimal parameter values ofdp, dn, tpand tntuned using the training set, andclassification performance for the different meth-ods on the test set using the parameter values tunedfrom the training set.
The p-values are computedusing the regression model presented in Section5.1.
We see that dn= 0, meaning that the sen-timent shifter ?not?
only has a positive effect onthe classification performance when it is in frontof the sentiment word.
We see that using depen-dency distances (method A0) the classification re-sults are significantly improved compared to us-ing word distances in the sentence (method WD)(p-value = 0.023).
Also classification based on94salient dependency paths (method OD) performssignificantly better than WD.
We also see that ODperforms better than A0 (162 correct compared to161), but this improvement is not statistically sig-nificant.6 Closing remarksClassifying sentiment in political discussions ishard because of the frequent use of irony, sar-casm and citations.
In this paper we have com-pared the use of word distance between targetword and sentiment word against metrics incor-porating syntactic information.
Our results showthat using dependency tree distances or salient de-pendency paths, improves the classification per-formance compared to using word distance.Manually selecting salient dependency paths forthe aim of sentiment analysis is a hard task.
A nat-ural further step of our analysis is to expand thetraining and test material and use machine learn-ing to see if there exists dependency paths that im-prove results compared to using dependency dis-tance.ReferencesJamie Bartlett, Jonathan Birdwell, and Mark Littler.2013.
The rise of populism in Europe can betraced through online behaviour... Demos, http://www.demos.co.uk/files/Demos_OSIPOP_Book-web_03.pdf?1320601634.
[Online; accessed 21-January-2014].Douglas Bates, Martin Maechler, and Ben Bolker,2013.
lme4: Linear mixed-effects models using S4classes.
R package version 0.999999-2.Bernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and la-beled non-projective dependency parsing.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 1455?1465.Association for Computational Linguistics.Bi Chen, Leilei Zhu, Daniel Kifer, and Dongwon Lee.2010.
What Is an Opinion About?
Exploring Polit-ical Standpoints Using Opinion Scoring Model.
InAAAI.E.
W. Dijkstra.
1959.
A note on two problems inconnexion with graphs.
Numerische Mathematik,1:269?271.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
AHolistic Lexicon-based Approach to Opinion Min-ing.
In Proceedings of the 2008 International Con-ference on Web Search and Data Mining, WSDM?08, pages 231?240, New York, NY, USA.
ACM.Matthew Goodwin, Vidhya Ramalingam, andRachel Briggs.
2013.
The New RadicalRight: Violent and Non-Violent Movementsin Europe.
Institute for Strategic Dialogue,http://www.strategicdialogue.org/ISD%20Far%20Right%20Feb2012.pdf.
[Online; accessed 21-January-2014].Hugo Hammer, Alfred Bratterud, and Siri Fagernes.2013.
Crawling Javascript websites using WebKitwith application to analysis of hate speech in onlinediscussions.
In Norwegian informatics conference.Irene Heim and Angelika Kratzer.
1998.
Semantics inGenerative Grammar.
Blackwell.Joan B. Hooper and Sandra A. Thompson.
1973.
Onthe Applicability of Root Transformations.
Linguis-tic Inquiry, 4(4):465?497.Minqing Hu and Bing Liu.
2004.
Mining and Sum-marizing Customer Reviews.
In Proceedings of theTenth ACM SIGKDD International Conference onKnowledge Discovery and Data Mining, KDD ?04,pages 168?177, New York, NY, USA.
ACM.Sasha Issenberg.
2012.
How President Obamascampaign used big data to rally individual vot-ers.
http://www.technologyreview.com/featuredstory/509026/how-obamas-team-used-big-data-to-rally-voters/.
[Online; accessed 21-March-2014].Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
2011.
Target-dependent Twitter Senti-ment Classification.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Vol-ume 1, HLT ?11, pages 151?160, Stroudsburg, PA,USA.
Association for Computational Linguistics.Thorsten Joachims.
1999.
Making large-scale SVMLearning Practical.
In Advances in Kernel Methods.Kari Kinn, Pl Kristian Eriksen, and Per Erik Solberg.2014.
NDT Guidelines for Morphological and Syn-tactic Annotation.
Technical report, National Li-brary of Norway.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Synthesis Lectures on Human Language Tech-nologies.
Morgan & Claypool Publishers.Finn?Arup Nielsen.
2011.
A new ANEW: Evaluationof a word list for sentiment analysis in microblogs.CoRR, abs/1103.2903.R Core Team, 2013.
R: A Language and Environmentfor Statistical Computing.
R Foundation for Statis-tical Computing, Vienna, Austria.John Shawe-Taylor and Nello Cristianini.
2000.
Sup-port Vector Machines.
Cambridge University Press.95Per Erik Solberg, Arne Skj?rholt, Lilja ?vrelid, KristinHagen, and Janne Bondi Johannessen.
2014.
TheNorwegian Dependency Treebank.
In Proceedingsof LREC 2014.
Accepted.Per Erik Solberg.
2013.
Building Gold-Standard Tree-banks for Norwegian.
In Proceedings of NODAL-IDA 2013, Linkping Electronic Conference Proceed-ings no.
85, pages 459?464, Linkping, Sweden.
LiUElectronic Press.Andranik Tumasjan, Timm O Sprenger, Philipp GSandner, and Isabell M Welpe.
2010.
Predictingelections with twitter: What 140 characters revealabout political sentiment.
In Proceedings of thefourth international aaai conference on weblogs andsocial media, pages 178?185.Theresa Wilson, Janyce Wiebe, and Paul Hoffman.2009.
Recognizing contextual polarity: An explo-ration of features for phrase-level sentiment analy-sis.
Computational Linguistics, 35(3):399 ?
433.96
