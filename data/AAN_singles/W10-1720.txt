Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143?148,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsMATREX: The DCU MT System for WMT 2010Sergio Penkale, Rejwanul Haque, Sandipan Dandapat, Pratyush Banerjee, Ankit K. Srivastava,Jinhua Du, Pavel Pecina, Sudip Kumar Naskar, Mikel L. Forcada, Andy WayCNGL, School of ComputingDublin City University, Dublin 9, Ireland{ spenkale, rhaque, sdandapat, pbanerjee, asrivastava, jdu, ppecina, snaskar, mforcada, away }@computing.dcu.ieAbstractThis paper describes the DCU machinetranslation system in the evaluation cam-paign of the Joint Fifth Workshop on Sta-tistical Machine Translation and Metricsin ACL-2010.
We describe the modulardesign of our multi-engine machine trans-lation (MT) system with particular focuson the components used in this partici-pation.
We participated in the English?Spanish and English?Czech translationtasks, in which we employed our multi-engine architecture to translate.
We alsoparticipated in the system combinationtask which was carried out by the MBRdecoder and confusion network decoder.1 IntroductionIn this paper, we present the DCU multi-engineMT system MATREX (Machine Translation usingExamples).
This system exploits example-basedMT, statistical MT (SMT), and system combina-tion techniques.We participated in the English?Spanish (en?es) and English?Czech (en?cs) translationtasks.
For these two tasks, we employ severalindividual MT systems: 1) Baseline: phrase-based SMT (Koehn et al, 2007); 2) EBMT:Monolingually chunking both source and targetsides of the dataset using a marker-based chunker(Gough and Way, 2004); 3) Factored translationmodel (Koehn and Hoang, 2007); 4) Source-sidecontext-informed (SSCI) systems (Stroppa et al,2007); 5) the moses-chart (a Moses imple-mentation of the hierarchical phrase-based (HPB)approach of Chiang (2007)) and 6) Apertium (For-cada et al, 2009) rule-based machine translation(RBMT).
Finally, we use a word-level combina-tion framework (Rosti et al, 2007) to combine themultiple translation hypotheses and employ a newrescoring model to generate the final translation.For the system combination task, we first usethe minimum Bayes-risk (MBR) (Kumar andByrne, 2004) decoder to select the best hypoth-esis as the alignment reference for the confusionnetwork (CN) (Mangu et al, 2000).
We then buildthe CN using the TER metric (Snover et al, 2006),and finally search for the best translation.The remainder of this paper is organised as fol-lows: Section 2 details the various components ofour system, in particular the multi-engine strate-gies used for the shared task.
In Section 3, weoutline the complete system setup for the sharedtask and provide evaluation results on the test set.Section 4 concludes the paper.2 The MATREX System2.1 System ArchitectureThe MATREX system is a combination-basedmulti-engine architecture, which exploits as-pects of both the EBMT and SMT paradigms.The architecture includes various individual sys-tems: phrase-based, example-based, hierarchicalphrase-based and tree-based MT.The combination structure uses the MBR andCN decoders, and is based on a word-level com-bination strategy (Du et al, 2009).
In the finalstage, we use a new rescoring module to processthe N -best list generated by the combination mod-ule.
Figure 1 illustrates the architecture.2.2 Example-Based Machine TranslationThe EBMT system uses a language-specific, re-duced set of closed-class marker morphemes orlexemes (Gough and Way, 2004) to define a wayto segment sentences into chunks, which are thenaligned using an edit-distance-style algorithm, inwhich edit costs depend on word-to-word transla-143Figure 1: System Framework.tion probabilities and the amount of word-to-wordcognates (Stroppa and Way, 2006).Once these phrase pairs were obtained theywere merged with the phrase pairs extracted bythe baseline system adding word alignment infor-mation.2.3 Apertium RBMTApertium1 is a free/open-source platform forRBMT.
The current version of the en?es systemin Apertium was used for the system combinationtask (section 2.7), and its morphological analysersand part-of-speech taggers were used to build afactored Moses model.2.4 Factored Translation ModelWe also used a factored model for the en?estranslation task.
Factored models (Koehn andHoang, 2007) facilitate the translation by break-ing it down into several factors which are furthercombined using a log-linear model (Och and Ney,2002).We used three factors in our factored translationmodel, which are used in two different decodingpaths: a surface form (SF) to SF translation factor,a lemma to lemma translation factor, and a part-of-speech (PoS) to PoS translation factor.Finally, we used two decoding paths based on1http://www.apertium.orgthe above three translation factors: an SF to SFdecoding path and a path which maps lemma tolemma, PoS to PoS, and an SF generated usingthe TL lemma and PoS.
The lemmas and PoS foren and es were obtained using Apertium (sec-tion 2.3).2.5 Source-Side Context-informed PB-SMTOne natural way to express a context-informedfeature (h?MBL) is to view it as the conditionalprobability of the target phrases (e?k) given thesource phrase (f?k) and its source-side context in-formation (CI):h?MBL = logP (e?k|f?k,CI(f?k)) (1)We use a memory-based machine learning(MBL) classifier (TRIBL:2 Daelemans andvan den Bosch (2005)) that is able to estimateP (e?k|f?k,CI(f?k)) by similarity-based reasoningover memorized nearest-neighbour examples ofsource?target phrase translations.
In equation (1),SSCI may include any feature (lexical, syntactic,etc.
), which can provide useful information todisambiguate a given source phrase.
In additionto using local words and PoS-tags as features,as in (Stroppa et al, 2007), we incorporategrammatical dependency relations (Haque et al,2009a) and supertags (Haque et al, 2009b) assyntactic source context features in the log-linearPB-SMT model.In addition to the above feature, we derived asimple binary feature h?best, defined in (2):h?best ={1 if e?k maximizes P (e?k|f?k,CI(f?k))0 otherwise(2)We performed experiments by integrating thesetwo features, h?MBL and h?best, directly into thelog-linear framework of Moses.2.6 Hierarchical PB-SMT modelFor the en?cs translation task, we builta weighted synchronous context-free grammarmodel (Chiang, 2007) of translation that usesthe bilingual phrase pairs of PB-SMT as a start-ing point to learn hierarchical rules.
We usedthe open-source Tree-Based translation systemmoses-chart3 to perform this experiment.2An implementation of TRIBL is freely available as partof the TiMBL software package, which can be downloadedfrom http://ilk.uvt.nl/timbl3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial1442.7 System CombinationFor multiple system combination, we used anMBR-CN framework (Du et al, 2009, 2010) asshown in Figure 1.
Due to the varying word or-der in the MT hypotheses, it is essential to definethe backbone which determines the general wordorder of the CN.
Instead of using a single systemoutput as the skeleton, we employ an MBR de-coder to select the best single system output Erfrom the merged N -best list by minimizing theBLEU (Papineni et al, 2002) loss, as in (3):r = argminiNs?j=1(1?
BLEU(Ej , Ei)) (3)where Ns indicates the number of translations inthe merged N -best list, and {Ei}Nsi=1 are the trans-lations themselves.
In our task, we only merge the1-best output of each individual system.The CN is built by aligning other hypothesesagainst the backbone, based on the TER metric.Null words are allowed in the alignment.
Ei-ther votes or different confidence measures are as-signed to each word in the network.
Each arc inthe CN represents an alternative word at that po-sition in the sentence and the number of votes foreach word is counted when constructing the net-work.
The features we used are as follows:?
word posterior probability (Fiscus, 1997);?
3, 4-gram target language model;?
word length penalty;?
Null word length penalty;We use MERT (Och, 2003) to tune the weightsof the CN.2.8 RescoringRescoring is a very important part in post-processing which can select a better hypothesisfrom the N -best list.
We augmented our previ-ous rescoring model (Du et al, 2009) with morelarge-scale data.
The features we used include:?
Direct and inverse IBM model;?
3, 4-gram target language model;?
3, 4, 5-gram PoS language model (Schmid,1994; Ratnaparkhi, 1996);?
Sentence length posterior probability (Zensand Ney, 2006);?
N -gram posterior probabilities within the N -Best list (Zens and Ney, 2006);?
Minimum Bayes Risk probability;?
Length ratio between source and target sen-tence;The weights are optimized via MERT.3 Experimental SetupThis section describes our experimental setup forthe en?cs and en?es translation tasks.3.1 DataBilingual data: In the experiments we used datasets provided by the workshop organizers.
For theen?cs translation table extraction we employedboth parallel corpora (News-Commentary10 andCzEng 0.9), and for the en?es experiments, weused the Europarl(Koehn, 2005), News Commen-tary and United Nations parallel data.
We used amaximum sentence length of 80 for en?es and40 for en?cs.
Detailed statistics are shown in Ta-ble 1.Corpus Langs.
Sent.
SourcetokensTargettokensEuroparl en?es 1.6M 43M 45MNews-comm en?es 97k 2.4M 2.7MUN en?es 5.9M 160M 190MNews-Comm en?cs 85k 1.8M 1.6MCzEng en?cs 7.8M 80M 69MTable 1: Statistics of en?cs and en?es parallel data.Monolingual data: For language modeling pur-poses, in addition to the target parts of the bilin-gual data, we used the monolingual News corpusfor cs; and the Gigaword corpus for es.
For bothlanguages, we used the SRILM toolkit (Stolcke,2002) to train a 5-gram language model using allmonolingual data provided.
However, for en?eswe used the IRSTLM toolkit (Federico and Cet-tolo, 2007) to train a 5-gram language model usingthe es Gigaword corpus.
Both language modelsuse modified Kneser-Ney smoothing (Chen andGoodman, 1996).
Statistics for the monolingualcorpora are given in Table 2.Corpus Language Sentences TokensE/N/NC/UN es 9,6M 290MGigaword es 40M 1,2GNews cs 13M 210MTable 2: Statistics of Monolingual Data.
E/N/NC/UNrefers to Europarl/News/News Commentary/United Nationscorpora.For all the systems except Apertium, we firstlowercase and tokenize all the monolingual andbilingual data using the tools provided by theWMT10 organizers.
After translation, systemcombination output is detokenised and true-cased.1453.2 English?Czech (en?cs) ExperimentsThe CzEng corpus (Bojar and Z?abokrtsky?, 2009)is a collection of parallel texts from sources of dif-ferent quality and as such it contains some noise.As the first step, we discarded those sentence pairshaving more than 10% of non-Latin characters.The CzEng corpus is quite large (8M sen-tence pairs).
Although we were able to builda vanilla SMT system on all parallel data avail-able (News-Commentary + CzEng), we also at-tempted to build additional systems using News-Commentary data (which we considered in-domain) and various in-domain subsets of CzEnghoping to achieve better results on domain-specific data.For our first system, we selected 128,218 sen-tence pairs from CzEng labeled as news.
For theother two systems, we selected subsets of 2M and4M sentence pairs identified as most similar tothe development sets (as a sample of in-domaindata) based on cosine similarity of their represen-tation in a TF-IDF weighted vector space model(cf.
Byrne et al (2003)).
We also applied thepseudo-relevavance-feedback technique for queryexpansion (Manning et al, 2008) to select anothersubset with 2M sentence pairs.We used the output of 15 systems for sys-tem combination for the en?cs translation task.Among these, 5 systems were built using Mosesand varying the size of the training data (DCU-All, DCU-Ex2M, DCU-4M, DCU-2M and DCU-News); 9 context-informed PB-SMT systems(DCU-SSCI-*) using (combinations of) variouscontext features (word, PoS, supertags and depen-dency relations) trained only on the News Com-mentary data (marked with ?
in Table 4); and onesystem using the moses-chart decoder, alsotrained on the news commentary data.3.3 English?Spanish (en?es) ExperimentsThree baseline systems using Moses were built,where we varied the amount of training data used:?
epn: This system uses all of the Europarl andNews-Commentary parallel data.?
UN-half: This system uses the data supliedto ?epn?, plus an additional 2.1M sentencespairs randomly selected from the United Na-tions corpus.?
all: This system uses all of the available par-allel data.For en?es we also obtained output from thefactored model (trained only on the news com-mentary corpus) and the Apertium RBMT sys-tem.
We also derived phrase alignments using theMaTrEx EBMT system (Stroppa and Way, 2006),and added those phrase translations in the Mosesphrase table.
The systems marked with ?
use alanguage model built using the Spanish Gigawordcorpus, in addition to the one built using the pro-vided monolingual data.
These 6 sets of systemoutputs are then used for system combination.3.4 Experimental ResultsThe evaluation results for en?es and en?cs ex-periments are shown in Table 3 and Table 4 re-spectively.
The output of the systems marked ?were submitted in the shared tasks.System BLEU NIST METEOR TERDCU-half ??
29.77% 7.68 59.86% 59.55%DCU-all ??
29.63% 7.66 59.82% 59.74%DCU-epn ??
29.45% 7.66 59.71% 59.64%DCU-ebmt ??
29.38% 7.62 59.59% 60.11%DCU-factor 22.58% 6.56 54.94% 67.65%DCU-apertium 19.22% 6.37 49.68% 67.68%DCU-system-combination ?
30.42% 7.78 60.56% 58.71%Table 3: en?es experimental results.System BLEU NIST METEOR TERDCU-All 10.91% 4.60 39.18% 81.76%DCU-Ex2M 10.63% 4.56 39.12% 81.96%DCU-4M 10.61% 4.56 39.26% 82.04%DCU-2M 10.48% 4.58 39.35% 81.56%DCU-Chart 9.34% 4.25 37.04% 83.87%DCU-News 8.64% 4.16 36.27% 84.96%DCU-SSCI-ccg?
8.26% 4.02 34.76% 85.58%DCU-SSCI-supertag-pair?
8.11% 3.95 34.93% 86.63%DCU-SSCI-ccg-ltag?
8.09% 3.96 34.90% 86.62%DCU-SSCI-PR?
8.06% 4.00 34.89% 85.99%DCU-SSCI-base?
8.05% 3.97 34.61% 86.02%DCU-SSCI-PRIR?
8.03% 3.99 34.81% 85.98%DCU-SSCI-ltag?
8.00% 3.95 34.57% 86.41%DCU-SSCI-PoS?
7.91% 3.94 34.57% 86.51%DCU-SSCI-word?
7.57% 3.88 34.16% 87.14%DCU-system-combination ?
13.22% 4.98 40.39% 78.59%Table 4: en?cs experimental results.4 ConclusionThis paper presents the Dublin City UniversityMT system in WMT2010 shared task campaign.This was DCU?s first attempt to translate from ento es and cs in any shared task.
We developed amulti-engine framework which combined the out-puts of several individual MT systems and gener-ated a new N -best list after CN decoding.
Then by146using some global features, the rescoring modelgenerated the final translation output.
The experi-mental results demonstrated that the combinationmodule and rescoring module are effective in ourframework for both language pairs, and producestatistically significant improvements as measuredby bootstrap resampling methods (Koehn, 2004)on BLEU over the single best system.Acknowledgements: This work is supportedby Science Foundation Ireland (Grant No.07/CE/I1142) and by PANACEA, a 7th Frame-work Research Programme of the EuropeanUnion, contract number 7FP-ITC-248064.
M.L.Forcada?s sabbatical stay at Dublin City Univer-sity is supported by Science Foundation Irelandthrough ETS Walton Award 07/W.1/I1802 and bythe Universitat d?Alacant (Spain).ReferencesBojar, O. and Z?abokrtsky?, Z.
(2009).
CzEng0.9:Large Parallel Treebank with Rich Annotation.Prague Bulletin of Mathematical Linguistics,92:63?83.Byrne, W., Khudanpur, S., Kim, W., Kumar, S.,Pecina, P., Virga, P., Xu, P., and Yarowsky, D.(2003).
The Johns Hopkins University 2003Chinese?English machine translation system.In Proceedings of MT Summit IX, pages 447?450, New Orleans, LA.Chen, S. F. and Goodman, J.
(1996).
An Empir-ical Study of Smoothing Techniques for Lan-guage Modeling.
In Proc.
34th Ann.
Meeting ofthe Association for Computational Linguistics,pages 310?318, San Francisco, CA.Chiang, D. (2007).
Hierarchical phrase-based translation.
Computational Linguistics,33(2):201?228.Daelemans, W. and van den Bosch, A.
(2005).Memory-Based Language Processing (Studiesin Natural Language Processing).
CambridgeUniversity Press, New York, NY.Du, J., He, Y., Penkale, S., and Way, A.
(2009).MaTrEx: The DCU MT System for WMT2009.In Proc.
3rd Workshop on Statistical MachineTranslation, EACL 2009, pages 95?99, Athens,Greece.Du, J., Pecina, P., and Way, A.
(2010).
AnAugmented Three-Pass System CombinationFramework: DCU Combination System forWMT 2010.
In Proc.
ACL 2010 Joint Workshopin Statistical Machine Translation and MetricsMatr, Uppsala, Greece.Federico, M. and Cettolo, M. (2007).
EfficientHandling of N-gram Language Models for Sta-tistical Machine Translation.
In Proceedingsof the Second Workshop on Statistical MachineTranslation, pages 88?95, Prague, Czech Re-public.Fiscus, J. G. (1997).
A post-processing sys-tem to yield reduced word error rates: Recog-nizer output voting error reduction (ROVER).In Proceedings 1997 IEEE Workshop on Auto-matic Speech Recognition and Understanding(ASRU), pages 347?352, Santa Barbara, CA.Forcada, M. L., Tyers, F. M., and Ram?
?rez-Sa?nchez, G. (2009).
The free/open-source ma-chine translation platform Apertium: Five yearson.
In Proceedings of the First InternationalWorkshop on Free/Open-Source Rule-BasedMachine Translation FreeRBMT?09, pages 3?10.Gough, N. and Way, A.
(2004).
Robust Large-Scale EBMT with Marker-Based Segmenta-tion.
In Proceedings of the 10th InternationalConference on Theoretical and MethodologicalIssues in Machine Translation (TMI-04), pages95?104, Baltimore, MD.Haque, R., Naskar, S. K., Bosch, A. v. d., andWay, A.
(2009a).
Dependency relations assource context in phrase-based smt.
In Proc.23rd Pacific Asia Conference on Language, In-formation and Computation, pages 170?179,Hong Kong, China.Haque, R., Naskar, S. K., Ma, Y., and Way, A.(2009b).
Using supertags as source languagecontext in SMT.
In EAMT-2009: Proceed-ings of the 13th Annual Conference of the Eu-ropean Association for Machine Translation,pages 234?241, Barcelona, Spain.Koehn, P. (2004).
Statistical significance tests formachine translation evaluation.
In Proceedingsof EMNLP, volume 4, pages 388?395.Koehn, P. (2005).
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In MachineTranslation Summit X, pages 79?86, Phuket,Thailand.Koehn, P. and Hoang, H. (2007).
Factored Trans-lation Models.
In Proceedings of the Joint Con-ference on Empirical Methods in Natural Lan-guage Processing and Computational Natural147Language Learning (EMNLP-CoNLL), pages868?876, Prague, Czech Republic.Koehn, P., Hoang, H., Birch, A., Callison-Burch,C., Federico, M., Bertoldi, N., Cowan, B.,Shen, W., Moran, C., Zens, R., Dyer, C., Bo-jar, O., Constantin, A., and Herbst, E. (2007).Moses: Open Source Toolkit for Statistical Ma-chine Translation.
In Annual Meeting of the As-sociation for Computational Linguistics (ACL),demonstration session, pages 177?180, Prague,Czech Republic.Kumar, S. and Byrne, W. (2004).
MinimumBayes-Risk Decoding for Statistical MachineTranslation.
In Proceedings of the Joint Meet-ing of the Human Language Technology Con-ference and the North American Chapter ofthe Association for Computational Linguistics(HLT-NAACL 2004), pages 169?176, Boston,MA.Mangu, L., Brill, E., and Stolcke, A.
(2000).
Find-ing consensus in speech recognition: Word er-ror minimization and other applications of con-fusion networks.
Computer Speech and Lan-guage, 14(4):373?400.Manning, C. D., Raghavan, P., and Schu?tze, H.(2008).
Introduction to Information Retrieval.Cambridge University Press.Och, F. (2003).
Minimum error rate trainingin statistical machine translation.
In Proceed-ings of the 41st Annual Meeting of the Asso-ciation for Computational Linguistics (ACL),pages 160?167, Sapporo, Japan.Och, F. and Ney, H. (2002).
Discriminative train-ing and maximum entropy models for statisticalmachine translation.
In Proceedings of ACL,volume 2, pages 295?302.Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.(2002).
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In Proceedingsof the 40th Annual Meeting of the Associationfor Computational Linguistics (ACL-02), pages311?318, Philadelphia, PA.Ratnaparkhi, A.
(1996).
A Maximum EntropyModel for Part-Of-Speech Tagging.
In Pro-ceedings of the Empirical Methods in NaturalLanguage Processing Conference (EMNLP),pages 133?142, Philadelphia, PA.Rosti, A.-V.
I., Xiang, B., Matsoukas, S.,Schwartz, R., Ayan, N. F., and Dorr, B.
J.(2007).
Combining outputs from multiple ma-chine translation systems.
In Proceedings of theJoint Meeting of the Human Language Technol-ogy Conference and the North American Chap-ter of the Association for Computational Lin-guistics (HLT-NAACL 2007), pages 228?235,Rochester, NY.Schmid, H. (1994).
Probabilistic Part-of-SpeechTagging Using Decision Trees.
In Proceedingsof International Conference on New Methodsin Language Processing, pages 44?49, Manch-ester, UK.Snover, M., Dorr, B., Schwartz, R., Micciula, L.,and Makhoul, J.
(2006).
A study of transla-tion edit rate with targeted human annotation.In Proceedings of the 7th Conference of the As-sociation for Machine Translation in the Amer-icas (AMTA 2006), pages 223?231, Cambridge,MA.Stolcke, A.
(2002).
SRILM - An Extensible Lan-guage Modeling Toolkit.
In Proceedings ofthe International Conference Spoken LanguageProcessing, pages 901?904, Denver, CO.Stroppa, N., van den Bosch, A., and Way, A.(2007).
Exploiting Source Similarity for SMTusing Context-Informed Features.
In Proceed-ings of the 11th International Conference onTheoretical and Methodological Issues in Ma-chine Translation (TMI-07), pages 231?240,Sko?vde, Sweden.Stroppa, N. and Way, A.
(2006).
MaTrEx: theDCU machine translation system for IWSLT2006.
In Proceedings of the International Work-shop on Spoken Language Translation, pages31?36, Kyoto, Japan.Zens, R. and Ney, H. (2006).
N-gram Poste-rior Probabilities for Statistical Machine Trans-lation.
In Proceedings of the Joint Meeting ofthe Human Language Technology Conferenceand the North American Chapter of the As-sociation for Computational Linguistics (HLT-NAACL 2006), pages 72?77, New York, NY.148
