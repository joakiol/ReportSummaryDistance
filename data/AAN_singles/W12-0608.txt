Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 61?69,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsOpinion and Suggestion Analysis for Expert RecommendationsAnna Stavrianou and Caroline BrunXerox Research Centre Europe6, chemin de Maupertuis38240 Meylan, France{anna.stavrianou,caroline.brun}@xrce.xerox.comAbstractIn this paper, we propose the use of fine-grained information such as opinions andsuggestions extracted from users?
reviewsabout products, in order to improve a rec-ommendation system.
While typical rec-ommender systems compare a user profilewith some reference characteristics to rateunseen items, they rarely make use of thecontent of reviews users have done on agiven product.
In this paper, we show howwe applied an opinion extraction system toextract opinions but also suggestions fromthe content of the reviews, use the results tocompare other products with the reviewedone, and eventually recommend a betterproduct to the user.1 IntroductionSocial media has enabled web users to inter-act through social platforms, express their opin-ions, comment and review various products/items.Such user-generated content has been analysedfrom a social as well as content-oriented pointof view.
For instance, social network analysistechniques have been used to identify user roles(Agarwal et al, 2008; Domingos and Richard-son, 2001; Fisher et al, 2006; Zhang et al,2007) and text or opinion mining techniques havebeen applied to identify positive/negative tenden-cies within user online review comments (Dingand Liu, 2007; Ghose et al, 2007; Hu and Liu,2004; Leskovec et al, 2010).
In the applicativecontext, recommender systems (Adomavicius andTuzhilin, 2005) make use of the opinion informa-tion (such as in star-rating systems) and recom-mend items (movies, products, news articles, etc.
)or social elements (i.e.
propositions to connectwith other people or communities), that are likelyto be of interest to a specific user.Typically, a recommender system compares auser profile with some reference characteristics,and seeks to predict the ?preference?
or ?rating?that a user would give to an item not yet consid-ered.
These characteristics may be part of the in-formation item (the content-based approach) orthe user?s social environment (the collaborativefiltering approach).
Comments published on so-cial networking or review web sites are sometimesused by recommender systems (Aciar et al, 2007;Jakob et al, 2009) in order to find out similaritiesbetween users that comment on the same itemsin the same way.
However, extracting explicit se-mantic information carried out in these comments(e.g.
?this printer is slow?)
is of great interest inorder to detect what a user has liked or dislikedabout a given topic (e.g.
the speed of the printer)and consequently take it into account to make rec-ommendations.In this paper, we propose the extraction of opin-ions and suggestions from user reviews or freetext and their use as input information to improverecommender systems.
This technique could beused on top of standard recommender techniquesin order to further fine-grain the recommendationaccording to the user comments.To the best of our knowledge, no existing ap-proach takes advantage of the fine-grained opin-ions or suggestions the user explicitly expressesusing natural language within a review or a freetext.
As aforementioned, some works considerthe product reviews as a means to get user opin-ions on certain products and use this informationfor recommendation purposes.
Nevertheless, theyall assign a polarity (?negative?
or ?positive?)
to61the review or they update the rating (e.g.
giv-ing a value from 1 to 5) without going furtherdown exploiting the exact phrases.
More partic-ularly they do not detect what aspects of the prod-uct have been appreciated or not.
For example, noapproach considers using the user-stated phrase ?Iwould prefer a lighter camera?
in order to recom-mend to a user a camera that satisfies all the de-sired features and on top of this being lighter thanthe reviewed one.The paper continues with a state-of-the art dis-cussion.
Section 3 is divided into two parts; adescription of the methodology followed in or-der to extract opinion information from reviewsthrough NLP techniques and a description of howthis information is used for recommending prod-uct items.
Section 4 shows an example and Sec-tion 5 presents a first attempt of an evaluation.Section 6 concludes and discusses future work.2 Related WorkAlthough there are no works that use the explicitsemantics extracted from reviews for recommen-dation purposes, our approach has some similari-ties with the analysis of reviews state-of-the-art.Identifying the opinion of customer reviews hasconcerned different research communities.
Somesignificant works infer opinion polarities based oncomparisons with a pre-defined seed-list of adjec-tives (Ding and Liu, 2007; Hu and Liu, 2004) orimplicitly through observing the changes in therespective product prices of reputation systems(Ghose et al, 2007).
An attempt of extractingsuggestions (and not just opinions) from customerreviews has also been presented in (Vishwanathand Aishwarya, 2011), in which ontologies andfeedback rules are used for this purpose.Combining knowledge of opinions extractedfrom reviews and recommender systems has alsosome applications.
For example, (Jakob et al,2009), have analysed opinions of movie reviews.They use pre-defined categories of movie features(acting, production, soundtrack, cinematographyand storyline), and they assign polarities (nega-tive or positive) to each category according to theper-feature opinion words expressed for each re-view.
For example, if a movie review contains thesentence ?the acting is flat?, they assign a neg-ative polarity to the category ?acting?
and theyjust avoid recommending the specific movie to theusers.
They do not explicitly use the opinion in-formation in order to make comparisons with sim-ilar movies and propose one ?less flat?
to the user.Similarly to (Jakob et al, 2009), most researchworks that use opinion information for recom-mendation purposes consider only the polarityand not the explicit semantics of the opinions.For instance, in (Aciar et al, 2007) or (Poirier,2011) they assign a kind of ?rating?
on each re-view regarding the product.
Comparisons are notincluded.
(Sun et al, 2009) include opinion-based andfeature-based comparisons in order to recommendproducts to users.
Their approach takes into ac-count a whole set of reviews (as opposed to indi-vidual ones) and it involves no NLP parsing.
Theopinions are aggregated into a sentiment valueand this value points out mainly whether a productfeature is better or not when it comes to compar-ing different models of the same product.NLP techniques have, in some cases, been usedfor recommendation.
As an example, in the pa-per of (Chai et al, 2002) the user can ?chat?
withthe system in order to describe what type of prod-uct she desires, receiving in return a list of recom-mended products.
Although, in this case, compar-isons between products take place in the database,opinion identification is not included.
The userneither expresses a complaint nor she suggestsan improvement, thus, no opinion detection takesplace.3 Opinion mining for expertrecommendationsIn this section we describe the approach followedin order to initially parse the user reviews regard-ing manufactured products, extract opinion infor-mation from them and, then, use this informationfor the purpose of providing expert recommenda-tions.Each product review concerns one specificproduct whose brand and model are clearly men-tioned each time.
In web sites such as ?epin-ions.com?
this information appears in the title ofthe review and it is straightforward to extract.In order to make use of the content of the re-views, we apply a system relying on a deep se-mantic analysis that detects opinions and sugges-tions within the customer reviews.
Natural lan-guage techniques allow the detection of the weak-nesses of the product (focusing on specific fea-tures) or the potential improvements, according to62the user?s point of view.The information extracted from the reviews isthen confronted to a database of products contain-ing information such as product characteristics,usage details, average price, etc.
For the purposesof this paper, we consider only product charac-teristics whose values can be boolean or numericand as such they can be compared with the tra-ditional methods.
The system selects, within thisdatabase, one or more similar products that com-pensate for the problems or improvement needsidentified within the review.
Then, pointers tothese products can be explicitly associated withthe specific review as ?expert recommendations?,and constitute an automatic enrichment of the re-view.The advantage for readers of these enriched re-views is to benefit from a contextualized recom-mendation that takes into account the semanticinformation conveyed in reviews of people whohave used a given product.
Moreover, the re-view?s reader may be helped in her product searchand may have a recommendation on a productshe did not even know it exists.
Figure 1 showsa schema of the process followed which is ex-plained in more detail in the next sections.3.1 Semantic ExtractionOur approach begins with the extraction of se-mantic information from each review and morespecifically the identification of the user?s sugges-tion(s) and/or opinion(s) together with the productfeatures and respective comparison words.For the purpose of identifying the weaknessesor the possible improvements mentioned in thetext, we need to extract the opinion of a user abouta given characteristic of a product.
Thus, we ap-ply an opinion detection system that is able to per-form feature-based opinion mining, relating themain concept (e.g.
a printer) to several features(e.g.
quality, print speed and resolution), that canbe evaluated separately.Formally, our system adopts the representationof a given opinion as proposed by (Liu, 2010),where an opinion is a five place predicate of theform (oj , fjk, sijkl, hi, tl), where:?
oj is the target object of the opinion (themain concept)?
fjk is a feature associated to the object?
sijkl is the value (positive or negative) ofthe opinion expressed by the opinion holderabout the feature?
hi is the opinion holder?
tl is the time when the opinion is expressed.The opinion extraction system is designed ontop of the XIP robust syntactic parser (A?
?t-Mokhtar et al, 2002), which is used as a funda-mental component, in order to extract deep syn-tactic dependencies, from which semantic rela-tions of opinion are calculated.
These semanticrelations are intermediary steps to instantiate thefive place predicates which are compliant withthe aforementioned model.
Having syntactic re-lations already extracted by a general dependencygrammar, we use the robust parser by combininglexical information about word polarities, subcat-egorization information and syntactic dependen-cies to extract the semantic relations that will theninstantiate this model.There exist other systems, such as the one de-scribed in (Kim and Hovy, 2006), that use syntac-tic dependencies to link the source and target ofthe opinions.
Our system (Brun, 2011) belongs tothis family, since we believe that the syntactic pro-cessing of complex phenomena (negation, com-parison and anaphora) is a necessary step in or-der to perform feature-based opinion mining.
An-other characteristic of our system is that it respectsa two-level architecture; it relies on a genericlevel, applicable to all domains and corpora, andon a domain-dependent level, adapted for eachsub-domain of application.Moreover, our system includes a semantic map-ping between polar vocabulary and the featuresit corresponds to.
For instance, the opinionword ?fast?
is mapped to the feature ?speed?, theword ?expensive?
to the feature ?price?, the word?clunk?
to ?noise?
and so on.
This mapping en-ables us to further exploit the comments of theuser by referring to specific product characteris-tics.When analyzing an example like ?The photoquality of my prints is astonishing.
This printeris really not that expensive.
?, our system extractstwo relations of opinion :?
OPINION POSITIVE(astonishing,photoquality): the dependency parser extracts an63User Review???????????????????????????????????????????????
?User Review???????????????????????????????????????????????
?User Review???????????????????????????????????????????????
?Semantic Extraction- Opinion detection- Suggestion detectionProduct identified issuesandimprovement needsProductDescriptionDatabaseMapping?better than?Selected productsReview enrichmentwith?ExpertRecommendations?Figure 1: Extracting opinion semantic information from product reviews and provide expert recommendations.attributive syntactic relation between thesubject ?photo quality?
and the positiveadjectival attribute ?astonishing?
fromwhich this relation of opinion is inferredabout the feature ?photo quality??
OPINION POSITIVE(expensive,printer):the dependency parser also extracts anattributive syntactic relation between thesubject ?printer?
and the negative adjectiveattribute ?expensive?, but it also extracts anegation on the main verb: the polarity ofthe final relation is inverted, i.e.
is finallypositive.
As we have also encoded that theadjective ?expensive?
is semantically linkedto ?price?, this opinion is linked to thefeature ?price?.In addition, the system includes a specific de-tection of suggestions of improvements, whichgoes beyond the scope of traditional opiniondetection.
Suggestions of improvements areexpressed with two discursive figures denoting?wishes?
or ?regrets?.
To detect these specificdiscurse patterns, we use again information ex-tracted by the parser, i.e.
syntactic relations suchas SUBJECT, OBJECT, MODIFIER, but also in-formation about verbal tenses, modality and ver-bal aspect, combined with terminological infor-mation about the domain, in our case, the domainof printers.Some examples follow that show what the sys-tem would output considering certain input sen-tences extracted from customer reviews aboutprinters:1.
Input: ?I think they should have put a fasterscanner on the machine, one at least as fastas the printer.
?Output:SUGGESTION IMPROVE(scanner, speed)In this example, the system identifiesfrom the input sentence that the user is notsatisfied with the speed of the scanner andwould have liked it to be quicker.2.
Input: ?I like this printer, but I think it is tooexpensive.
?Output: OPINION POSITIVE(printer, ),OPINION NEGATIVE(printer, price).In this example, the system identifiesthat the user is not happy with the priceof the printer although the rest of itscharacteristics satisfy him.3.
Input: ?The problem of this printer is thefuser.
?Output:OPINION NEGATIVE(printer, fuser).In this example, the system identifiesthat the problem lies in the fuser of theprinter.The first two examples can be further exploitedby the approach we propose.
For instance, for the64second example, the reader of this review couldbenefit from a recommendation of a similar butcheaper printer.
The third example contains infor-mation that is not measured (it has neither booleannor numeric values) and as such it is out of thescope of this paper.3.2 Review enrichmentFollowing the detection of the opinions or sug-gestions regarding specific product features, weidentify products that match the non-mentionedor positive characteristics of the reviewed productwhile at the same time satisfying the user sugges-tions.We consider a database that stores products to-gether with their features.
Same type of prod-ucts are stored similarly for evident reasons.
Thedatabase can be populated either manually or au-tomatically through the web sites that hold prod-uct information and it needs to be updated sothat new products appear and old ones are neverrecommended.
Access to the database is donethrough standard SQL queries.The system retrieves products of the same us-age (e.g.
a user that is reading a review for a PClaptop will not need a recommendation for a PCdesktop), while selecting those ones whose fea-tures are within the same or ?better?
range.
Thefeatures that should definitely be in ?better?
rangeare the ones retrieved with the help of the opiniondetection system described previously.
These fea-tures would be suggestions or negative opinionsthe user has expressed about a product.The ranges can be defined in many ways andthey can be subject to change.
For example, theprices may be considered to change ranges every50 Euro or 500 Euro depending on the averageprice of the product.
The feature requested by theuser (e.g.
?cheaper?)
should have a value in a dif-ferent range in order to really satisfy her this time(e.g.
a computer that costs 5 Euro less than the re-viewed one is not really considered as ?cheaper?
).Defining what ?better?
range refers to, dependson the feature.
For instance, the lower the price,the better it is, whereas, the higher the speed thebetter.
In order to avoid this confusion we keepthe descending (e.g.
in the case of price) or as-cending (e.g.
in the case of speed) semantics ofthe feature within the database.Once the system has identified the products thatseem to be closer to the user requirements, it high-lights these products by presenting them as ?ex-pert recommendations?.
These recommendationsmay appear on each review as enrichments assum-ing that the characteristics not mentioned as nega-tive by the user have satisfied her, so she would behappy with a similar product having basically thementioned features improved.
The recommenda-tion is mainly useful to the reader of the reviewthat is in the decision process before buying aproduct.Some special - sometimes often appearing -matching cases worth mentioning:Multiple features: If more than one featureneeds to be improved, priorities can be de-fined dependent on the order in which thefeatures are mentioned in the review.No comparable features: for this paper featuresare taken into account only if they are nu-meric or boolean (presence/absence) and canbe subjectively compared.Many matching products: more than one prod-uct can be recommended.
The limit of thenumber of products can be pre-defined andthe products may appear to the user in theorder of less-to-more expensive.No better answer: if no product is found thatmay satisfy the user then the search can goon in products of a different brand.
The sys-tem has also the choice to remain ?silent?and give no recommendation.A non-demanded feature changes: in the casethat a requested product is found but it ismore expensive than the reviewed product,the recommendation would include some in-formation regarding this feature (e.g.
?A pro-posed product is ?...?
whose price, though, ishigher?
).4 ExampleBefore evaluating our approach we present an ex-ample that shows the semantic extraction and rec-ommendation process.
We consider a small setof printers together with their characteristics andprices.
These data are taken from epinions.comat a date just before the submission of this paper.The data appear in Table 1 in descending order ofprice.65Brand Model Usage Technology Black speed Capacity Price($)X 8560 Laser Workgroup Color 30 1675 930X 6360V Laser Workgroup Color 42 1250 754X 6180 Laser Workgroup Color 26 300 750X 4118 All-in-One Laser All-in-One Monochrome 18 650 747HP Laserjet Cp2025n Workgroup Color 20 300 349HP Laserjet M1212nf All-in-One Monochrome 19 150 139Table 1: Printer information used for the purposes of the example(source: www.epinions.com).In the examples that follow, the input is a sen-tence that is assumed to be in the review of a givenproduct.1.
Review about the ?6180 Laser?
printer.Input:?I think they should have allowed fora higher capacity.
?Semantic Extraction step:SUGGESTION IMPROVE(printer, capac-ity)Identify similar products step:?
identify reviewed characteristics: work-group, laser, color, 26 ppm black speed,300 sheets capacity, $750 price?
identify similar printers where capacityis higher (next range) than 300 sheetsExpert recommendation: A proposed printerwith a higher capacity is the ?6360V LaserPrinter?.2.
Review about the ?6180 Laser?
printer.Input:?I like it but it is expensive!
?Semantic Extraction step:OPINION NEGATIVE(printer, price)Identify similar products step:?
identify reviewed characteristics: work-group, laser, color, 26 ppm black speed,300 sheets capacity, $750 price?
identify similar printers where price islower than $750.Expert recommendation: A proposedcheaper printer of the same type is ?HP,LaserJet Cp2025n?.5 EvaluationThe evaluation of the proposed system concernstwo modules; the semantic extraction and the re-view enrichment.The first module has already been evaluatedpreviously showing encouraging results.
The sys-tem has been evaluated as to whether it correctlyclassifies the reviews according to the overallopinion.
The structure of the ?epinions.com?
website has been used for the evaluation since eachauthor has tagged the respective review with a tag?recommended?
or ?not recommended?, the cor-pus can be thus considered as annotated for clas-sification.
The SVM classifier (Joachims, 1998)has been used with a training set of opinions ex-tracted by our system from 313 reviews and a testset of 2735 reviews, giving a 93% accuracy.The review enrichment module evaluation, pre-sented in this paper, focuses on whether the rec-ommended products enrich the specific reviewand may satisfy the user by improving at least oneof the negative features mentioned or following aspecified suggestion without worsen the range ofthe rest of the features.
The experiments are runagainst a database of 5,772 printers whose detailsare extracted from the ?epinions.com?
site.For the purposes of this evaluation, we have de-veloped a product comparison module that takesas input, for our case, the reviewed printer modeltogether with the opinion and suggestion relationsas extracted by the opinion mining system.
Theoutput of the comparison module is a set of rec-ommended printers which are similar to the re-viewed one while improving the negative features(based on a comparison of the feature values).The comparison module deals with featuresthat are numeric or boolean (presence/absence).Printers are queried against their type (color-laser/inkjet, personal/workgroup, etc.
), their func-tions (copier, scanner etc.)
and their features66(speed, resolution, etc.).
Ranges have been de-fined according to the average per-feature-rangesthat are in the database.
These ranges can be ex-tended according to the number of recommenda-tions we would like to have (the larger the rangethe more the recommendations).Certain assumptions have been made in order toprovide the recommendations.
One such assump-tion is that the author of the review knows howto best make use of the printer she has bought.For example, if the user is complaining about theprinter?s resolution or print quality, we assumethat she makes her printing decisions (paper size,landscape/portrait) based on her knowledge of theprinter?s resolution.
Thus, the specific review canindeed be enriched with a recommendation of aprinter with a better resolution rather than an ad-vice on how to use the specific printer (e.g.
byusing a different media size).Furthermore, certain issues had to be taken careof such as missing data and different measure-ment units that are not necessarily comparable.When the values of the features that are to be im-proved are missing, the respective products arenot taken into account.
The missing data case isalso applied when the same feature is measured indifferent units between two similar products.
Ata later stage we may include such products in therecommendations and inform the user about thedifferences.The experiments were run over 129 printerreviews from the ?epinions.com?
site contain-ing negative opinions and/or suggestions.
Thereviews concerned 6 different brands while thedatabase from which the recommended productsare extracted contains printers from 14 differentbrands.
Once the need-to-be improved featureswere extracted from the reviews, the comparisonmodule was run in order to identify the recom-mended products.The recommendation output is manually eval-uated by looking at the technical features on theone side and by looking at the reviews of the rec-ommended model on the other.
It has to be notedthat this is a first evaluation of the system hav-ing the usual problems that recommender systemsevaluations have e.g.
recall calculations, findingthe right experts etc.
Since we have used a printerdataset, the ideal experts to validate whether wepropose better or not printers would be expertsfrom the field of printers.
Not having found suchexperts at the moment, we limit our evaluations tothe following two-faceted one:Feature-based evaluation: Based on the featurevalues, our system has a 100% precision,meaning that the recommended products areindeed similar to the reviewed ones whileimproving at least one of the required fea-tures.
As a result, in all cases the recom-mended products are technically better thanthe reviewed one and they can help in the re-view enrichment.Rating-based evaluation: In order to seewhether an average user could benefit fromsuch a recommendation, we have alsoevaluated our approach by looking at thereviews of the recommended products.
Thisevaluation is quite limited, though, becausenot all recommended products have hadreviews.Thus, we took into account only the rec-ommended products that have had a review.We used the average rating values of the?epinions.com?
site which is a rating thatconsiders the number of reviews togetherwith the star-system ratings.
These averageratings range from ?disappointing?, ?ok?,?very good?
and ?excellent?.
For each prod-uct we accept the recommended productsthat have a rating other than ?disappointing?which is at least as good as the product?srating.Only 32 products out of the 129 reviewedwere used because those were the oneswhich had an average rating value on theweb site.
The accuracy we have achievedis 80.34%.
In Figure 2 the percentage ofaccepted versus rejected recommendationsis shown per brand.
The brand names arereplaced by numbers.Finally, we would like to point out that inprinter reviews people complain mostly about is-sues that do not involve comparable features (e.g.paper jams, toner problems) or that are not givenas part of the detailed characteristics (e.g.
car-tridge prices).
As such, in the future, we wouldlike to use a different product dataset/review-setto run the experiment over.67Figure 2: Rating-based evaluation results: rejected versus accepted recommendations over a number of differentbrands.6 ConclusionIn this paper, we propose using written opinionsand suggestions that are automatically extractedfrom user web reviews as input to a recommendersystem.
This kind of opinions is analysed from asyntactic and semantic point of view and is usedas a means to recommend items ?better than?
thereviewed one.The novelty of our proposal lies in the fact thatthe semantics of opinions hidden in social mediasuch as user reviews have not been explicitly usedin order to generate recommendations.
To the bestof our knowledge, using the explicit comments ofa user in order to enrich the reviews in a contex-tual manner has not yet appeared in literature.In the future, our system could also considerthe user?s role knowledge (e.g.
expert or novice)in order to consider her suggestion from a differ-ent weighted-point-of-view.
An expert may havealready looked at certain existing products beforebuying something so she may need a more origi-nal or diverse recommendation provided.
The roleof the user could potentially be identified throughthe social network he is in (if there is one).We realise that some reviews may be spam orthey may be written by non-trustworthy users.However, our approach aims at providing expertrecommendations as a response to a single reviewby considering only what is mentioned in this spe-cific review.
This means that the content of a re-view, even if it is spam, will not be used in orderto provide recommendations for another review.ReferencesSilvana Aciar, Debbie Zhang, Simeon Simoff, andJohn Debenham.
2007.
Informed recommender:Basing recommendations on consumer product re-views.
IEEE Intelligent Systems, 22(3).Gediminas Adomavicius and Alexander Tuzhilin.2005.
Towards the next generation of recommendersystems: a survey of the state-of-the-art and possi-ble extensions.
IEEE Transactions on Knowledgeand Data Engineering, 17(6):734?749.Nitin Agarwal, Huan Liu, Lei Tang, and Philip S. Yu.2008.
Identifying the influential bloggers in a com-munity.
In WSDM ?08: Proceedings of the interna-tional conference on Web search and web data min-ing, pages 207?218, New York, NY, USA.
ACM.Salah A?
?t-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2002.
Robustness beyond shallowness: in-cremental deep parsing.
Nat.
Lang.
Eng., 8:121?144, June.Caroline Brun.
2011.
Detecting opinions using deepsyntactic analysis.
In Recent Advances in NaturalLanguage Processing (RANLP).Joyce Chai, Veronika Horvath, Nicolas Nicolov, StysMargo, Nanda Kambhatla, Wlodek Zadrozny, andPrem Melville.
2002.
Natural language assistant:A dialog system for online product recommenda-tion.
AI Magazine, 23(2).Xiaowen Ding and Bing Liu.
2007.
The utility oflinguistic rules in opinion mining.
In SIGIR-07.Pedro Domingos and Matt Richardson.
2001.
Miningthe network value of customers.
In SIGKDD, pages57?66.Danyel Fisher, Marc Smith, and Howard T. Welser.2006.
You are who you talk to: Detecting rolesin usenet newsgroups.
In Proceedings of the 39thAnnual Hawaii International Conference on SystemSciences, pages 59b?59b.68Anindya Ghose, Panagiotis G. Ipeirotis, and ArunSundararajan.
2007.
Opinion mining using econo-metrics: a case study on reputation systems.
InACL.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In KDD 04, pages 168?177.
ACM.Niklas Jakob, Stefan Hagen Weber, Mark ChristophMu?ller, and Iryna Gurevych.
2009.
Beyond thestars: Exploiting free-text user reviews to improvethe accuracy of movie recommendations.
In CIKMWorkshop on Topic-Sentiment Analysis for MassOpinion.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: learning with many rele-vant features.
In 10th European Conference on Ma-chine Learning (ECML), page 137142.Soo-Min Kim and Eduard Hovy.
2006.
Identifyingand analyzing judgment opinions.
In Proceedingsof the main conference on Human Language Tech-nology Conference of the North American Chap-ter of the Association of Computational Linguis-tics, HLT-NAACL ?06, pages 200?207, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Jure Leskovec, Daniel P. Huttenlocher, and Jon M.Kleinberg.
2010.
Predicting positive and negativelinks in online social networks.
In WWW, pages641?650.Bing Liu.
2010.
Sentiment analysis and subjectivity.Handbook of Natural Language Processing, 2nd ed.Damien Poirier.
2011.
From text to recommendation(des textes communautaires a la recommandation).PhD Dissertation.Jianshu Sun, Chong Long, Xiaoyan Zhu, and MinlieHuang.
2009.
Mining reviews for product compar-ison and recommendation.
Polibits, 39:33?40.J.
Vishwanath and S. Aishwarya.
2011.
User sug-gestions extraction from customer reviews.
Inter-national Journal on Computer Science and Engi-neering, 3(3).Jun Zhang, Mark S. Ackerman, and Lada Adamic.2007.
Expertise networks in online communities:Structure and algorithms.
In Proceedings of the16th International conference on World Wide Web,pages 221?230.69
