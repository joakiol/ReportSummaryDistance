Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 198?206,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsA Bottom-Up Exploration ofthe Dimensions of Dialog State in Spoken InteractionNigel G. WardDepartment of Computer ScienceUniversity of Texas at El PasoEl Paso, Texas, 79968, USAnigelward@acm.orgAlejandro VegaDepartment of Computer ScienceUniversity of Texas at El PasoEl Paso, Texas, 79968, USAavega5@miners.utep.eduAbstractModels of dialog state are important, bothscientifically and practically, but today?s bestbuild strongly on tradition.
This paperpresents a new way to identify the impor-tant dimensions of dialog state, more bottom-up and empirical than previous approaches.Specifically, we applied Principal Compo-nent Analysis to a large number of low-levelprosodic features to find the most importantdimensions of variation.
The top 20 out of76 dimensions accounted for 81% of the vari-ance, and each of these dimensions clearly re-lated to dialog states and activities, includingturn taking, topic structure, grounding, empa-thy, cognitive processes, attitude and rhetori-cal structure.1 IntroductionWhat set of things should a dialog manager be re-sponsible for?
In other words, which aspects of thecurrent dialog state should the dialog manager track?These questions are fundamental: they define thefield of computational dialog modeling and deter-mine the basic architectures of our dialog systems.However the answers common in the field todayarise largely from tradition, rooted in the concernsof precursor fields such as linguistics and artificialintelligence (Traum and Larsson, 2003; McGlashanet al, 2010; Bunt, 2011).We wish to provide a new perspective on thesefundamental questions, baed on a bottom-up, empir-ical investigations of dialog state.
We hope therebyto discover new facets of dialog state and to obtainestimates of which aspects of dialog state are mostimportant.2 AimsThere are many ways to describe dialog state, but inthis paper we seek a model with 7 properties:Orthogonal to Content.
While the automaticdiscovery of content-related dialog states has seensignificant advances, we are interested here in themore general aspects of dialog state, those that oc-cur across many if not all domains.Scalar.
While it is descriptively convenient to re-fer to discrete states (is-talking, is-waiting-for-a-yes-no-answer, and so on), especially for human ana-lysts, in general it seems that scales are more naturalfor many or all aspects of dialog state, for example,one?s degree of confidence, the strength of desire totake the turn, or the solidity of grounding.Non-Redundant.
While various levels and an-gles are used in describing aspects of dialog state ?and many of these are interrelated, correlated, andgenerally tangled ?
we would like a set of dimen-sions which is as concise as possible and mutuallyorthogonal.Continuously Varying.
While it is common tolabel dialog states only at locally stable times, forexample when neither party is speaking, or onlyover long spans, for example, utterances, we want amodel that can support incremental dialog systems,able to describe the instantaneous state at any pointin time, even in the middle of an utterance.Short-Term.
While aspects of dialog state caninvolve quite distant context, we here focus on theaspects important in keeping the dialog flowing over198short time-scales.Non-Exhaustive.
While dialog states can be ar-bitrarily complex, highly specific, and intricately re-lated to content, a general model can only be ex-pected to describe the frequently important aspectsof state.Prioritized.
While no aspects of dialog are unin-teresting, we want to know which aspects of dialogstate are more important and commonly relevant.3 ApproachTo be as empirical as possible, we want to consideras much data as possible.
We accordingly needed touse automatic techniques.
In particular, we chose tobase our analysis on objective manifestations of di-alog state.
Among the many possible such manifes-tations ?
discourses markers, gesture, gaze, and soon ?
we chose to use only prosody.
This is becausethe importance of prosody in meta-communicationand dialog control has often been noted, because thecontinuous nature of (most) prosodic features is con-venient for our aims, and because prosodic featuresare relatively easy to compute.Given our aims and such features, it is naturalto do Principal Components Analysis (PCA).
Thiswell-known method automatically identifies the fac-tors underlying the observed variations across mul-tiple features.
We also hoped that PCA would sep-arate out, as orthogonal factors, aspects of prosodythat truly relate to dialog from aspects with lexical,phrasal, or other significance.4 Related ResearchWhile dialog states have apparently not previ-ously been tackled using PCA, other dimensionality-reduction methods have been used.
Clusteringhas previously been applied as a way to catego-rize user intention-types and goals, using lexical-semantic features and neighboring-turn features asinputs (Lefevre and de Mori, 2007; Lee et al, 2009),among other methods (Gasic and Young, 2011).Hidden Markov Models have been used to identifydialog ?modes?
that involve common sequences ofdialog-acts (Boyer et al, 2009).
There is also workthat uses PCA to reduce multi-factor subjective eval-uations of emotion, style, or expressiveness into afew underlying dimensions, for example (Barbosa,2009).
In addition, clustering over low-level patternsof turn-taking has been used to identify a continuumof styles (Grothendieck et al, 2011).
However anal-ysis of dialog states based on prosodic features hasnot previously been attempted, nor has analysis ofdialog behaviors over time frames shorter than thediscourse or the turn sequence.Reducing the multiplicity of prosodic features toa smaller underlying set has long been a goal forlinguists.
The traditional method is to start withpercepts (for example, that some syllables soundlouder) and then look for the acoustic-prosodic fea-tures that correlate with these perceptions.
More re-cently the opposite tack has also been tried, start-ing with acoustic-prosodic features, and trying to in-fer a higher or deeper level of description.
For ex-ample, if we discover that for many syllables pitchheight, higher volume, and increased duration allcorrelate, then we can infer some deeper factor un-derlying all of these, namely stress or prominence.PCA provides a systematic way of doing this formany features at once, and it has been used forvarious prosodic investigations, including an explo-ration of the prosodic and other vocal parametersrelevant to emotional dimensions (Goudbeek andScherer, 2010) or levels of vocal effort (Charfue-lan and Schro?eder, 2011), categorizing glottal-flowwaveforms (Pfitzinger, 2008), finding the factors in-volved in boundaries and accents (Batliner et al,2001), identifying the key dimensions of variation inpitch contours using Functional Data Analysis (Gu-bian et al, 2010), and for purely practical purposes(Lee and Narayanan, 2005; Jurafsky et al, 2012).
Inour own laboratory, Justin McManus applied PCAto 4 left-context, single-speaker prosodic features,and identified the first PC with a continuum fromsilence to cheerful speech, and the second PC withthe continuum from back-channeling to storytelling.However PCA has never before been applied to largeset of features, thus we hoped it might reveal im-portant underlying factors in prosody that have notpreviously been noticed: factors interactionally im-portant, even if not salient.5 MethodUsing Switchboard, a large corpus of smalltalk be-tween strangers over the telephone recorded in two199we  don?t  go  camping      a           lot   lately        mostly   because          uhuh-huhFigure 1: The 16 pitch-height feature windows, centered about a hypothetical occurrence of the word lot .channels (Godfrey et al, 1992), we collected data-points from both sides of 20 dialogs, totaling almosttwo hours, taking a sample every 10 milliseconds.This gave us 600,000 datapoints.For each datapoint we computed 76 prosodic fea-tures.
These features were taken from both the im-mediate past and the immediate future, since dialogstate, by any definition, relates to both: being depen-dent on past context and predictive of future actions.The features were taken from both the speaker of in-terest and his or her interlocutor, since dialog statesintrinsically involve the behavior of both parties.Because our interest is in short-term dialog states,features were computed over only the 3-4 secondsbefore and after each point of interest.
The sequenc-ing of the prosodic features being obviously impor-tant, this context was split up into a sequence ofwindows.
Wishing to give more precision and moreweight to close context than more distant context,the windows closest to the point of interest weresmallest, with the more distant being wider, as il-lustrated in Figure 1.
The window sizes were fixed,not aligned with utterances, words, nor syllables.The specific features we computed were chosenfor convenience, based on a basic set previouslyfound useful for language modeling (Ward et al,2011).
These were 1. a speaking-rate measure, over325 millisecond windows, 2. volume, over 50 mswindows, 3. pitch height, over 150 ms windows,and 4. pitch range, over 225 ms windows.
All werespeaker-normalized.
The values for the longer re-gions were obtained by simply averaging the valuesover two more more adjacent basic features.In total there were 76 features: 24 volume, 20pitch range, 16 pitch height, and 16 speaking rate.At times where there was no pitch, the average pitchvalue was used as substitute.
All features were nor-malized to have mean 0 and standard deviation 1.PCA was then done.
As hoped, a few dimensionsexplained most of the variance, with the top 4 ex-plaining 55%, the top 10 explaining 70%, and thetop 20 explaining 81%.We then set out to determine, for each of the di-mensions, what dialog states or situations, if any,were associated with it.Our first approach was to examine extreme data-points.
Because we thought that it would be infor-mative to see which words tended to occur at theextremes, we filtered our datapoints to select onlythose which were at word onsets.
For each dimen-sion we then computed, for all of these, the valueson that dimension.
We then sorted these to find thehighest 20 and the lowest 20.
Looking at these wordlists however was generally not informative, as noword or even word type predominated in any group,in fact, the words were invariably highly diverse.This perhaps indicates that the dimensions of dialogstate expressed by prosody do not aligne with thoseexpressed by words, and perhaps confirm that wordscan correlate with social and dialog functions in un-suspected ways (Tausczik and Pennebaker, 2010).We next listened to some of some of these dat-apoints in context.
First we listened to a few low-valued ones and came up with informal hypothesesabout what they had in common.
We then listenedto more examples, winnowing and revising hypothe-ses as we went, until we were satisfied that we hada generalization that held for at least the majority ofthe cases.
Then we did the same thing for the high-valued times.
Finally we put the two together andfound an opposition, and used this to describe thesignificance of the dimension as a whole.
Some-times this came easily, but sometimes it requiredmore listening to verify or refine.
This was in gen-eral easy for the top few dimensions, but more chal-lenging for the lower ones, where the shared proper-ties were generally weaker and more variable.This process was unavoidably subjective, andmust be considered only exploratory.
We did notstart out with any strong expectations, other than200that many of the dimensions would relate to aspectsof dialog.
Our backgrounds may have predisposedus to be extra alert to turn-taking processes, but of-ten initial hypotheses relating to turn-taking weresuperseded by others that explained the data bet-ter.
We did not limit ourselves to terminology fromany specific theoretical framework, rather we chosewhichever seemed most appropriate for the phenom-ena.Our second approach was to look at the loadingfactors, to see for each dimension which of the in-put prosodic features were highly correlated with it,both positively and negatively.
In every case theseconfirmed or were compatible with our interpreta-tions, generally revealing heavy loadings on featureswhich previous research or simple logic suggestedwould relate to the dialog activities and states wehad associated with the dimension.6 Interpretations of the Top DimensionsThe results of our analyses were as follows.
Thesemust be taken as tentative, and the summary descrip-tions in the headings and in the tables must be readas mere mnemonics for the more complex realitythat our fuller descriptions capture better, althoughstill far from perfectly.Dimension 1: Who?s speaking?At points with low values on this dimension thespeaker of interest is speaking loudly and continu-ously without pause while the other is completelysilent.
At points with high values on this dimen-sion the speaker of interest is producing only back-channels, while the other speaker is speaking con-tinuously.
(Points with complete silence on the partof the speaker of interest probably would have beeneven more extreme, but were not examined sinceour sample set only included timepoints where thespeaker of interest was starting a word.)
Unsurpris-ingly the features with the highest loadings were thevolumes for the two speakers.
Thus we identify thisdimension with ?who?s speaking.?
Interestingly, ofall the dimensions, this was the only with a bimodaldistribution.Dimension 2: How much involvement is there?At points with low values on this dimensionthe dialog appeared to be faltering or awkward,with the lone speaker producing words slowly in-terspersed with non-filled pauses.
High-value pointswere places where both speakers appeared highly in-volved, talking at once for several seconds, or onelaughing while the other talked.
Again the volumefeatures had the highest loadings.
Thus we identifythis dimension with the amount of involvement.Dimension 3: Is there a topic end?At points with low values on this dimension thereis generally a quick topic closing, in situations wherethe speaker had a new topic cued up and wanted tomove on to it.
An extreme example was when, af-ter hearing clicks indicating call waiting, the speakersaid she needed to take the other call.
At points withhigh values on this dimension the topic was constant,sometimes with the less active participant indicatingresigned boredom with a half-hearted back-channel.The features with the highest positive loadings werespeaking-rate features: fast speech by the interlocu-tor in the near future correlated with a topic close,whereas fast speech by the current speaker about 1?2 seconds ago correlated with topic continuity.
Thuswe identify this dimension with topic ending.Dimension 4: Is the referent grounded yet?At points with low values on this dimension thespeaker is often producing a content word after afiller or disfluent region, and this is soon followedby a back-channel by the other speaker.
At pointswith high values on this dimension the speaker of in-terest is adding more information to make the pointhe wanted (starting the comment part of a topic-comment pair) sometimes after the interlocutor hadresponded with oh.
Thus this dimension relates tothe continuum between trying to ground somethingand continuing on with something already grounded.Trying to ground correlated with an upcoming fastspeaking rate, while proceeding after grounding cor-related with a high volume.
Thus we identify thisdimension with the degree of grounding.Dimension 5: Does the speaker want to start orstop?At points with low values on this dimension thespeaker of interest is starting a turn strongly, some-times as a turn-grab or even cutting-off the otherspeaker.
At points with high values on this dimen-201sion the speaker is strongly yielding the turn, cou-pled with the interlocutor very swiftly taking up theturn.
Often the turn yield occurs when the speakeris soliciting a response, either explicitly or by ex-pressing an opinion that seems intended to invokea response.
As might be expected, cut-offs corre-late with high volume on the part of the interruptingspeaker, while clear turn yields correlate with pasthigh volume on the part of the speaker who is end-ing.
Thus we identify this dimension with startingversus stopping.Dimension 6: Has empathy been expressed yet?At points with low values on this dimension thespeaker is continuing shortly after a high-content,emotionally-colored word that has just been ac-knowledged by the interlocutor.
At points withhigh values on this dimension, the speaker is ac-knowledging a feeling or attitude just expressed bythe other, by expressing agreement with a shortturn such as that?s right or yeah, Arizona?s beau-tiful!.
Continuing after empathic grounding corre-lated with high volume after a couple of seconds;expressing empathy with a short comment corre-lated with the interlocutor recently having produceda word with high pitch.
Thus we identify this dimen-sion with the degree of empathy established.Dimension 7: Are the speakers synchronized?At points with low values on this dimension bothspeakers inadvertently start speaking at the sametime.
At points with high values on this dimensionthe speakers swiftly and successfully interleave theirspeaking, for example by completing each other?sturns or with back-channels.
The features with thehighest positive loadings were those of pitch rangeand speaking rate with the volume factors havingmostly negative loadings.
Thus we identify this di-mension with the degree of turn synchronization.Dimension 8: Is the turn end unambiguous?At points with low values on this dimensionthe speaker is dragging out a turn which appears,content-wise, to be already finished, producing post-completions, such as uh or or anything like that.
Atpoints with high values on this dimension, often thespeaker is definitively ending a turn.
The featurewith the highest positive loading was pitch range,unsurprisingly since clear turn ends often involve asharp pitch fall.
Thus we identify this dimensionwith the degree of ambiguity of the turn end.Dimension 9: Is the topic exhausted?At points with low values on this dimension aspeaker is closing out a topic due to running out ofthings to say.
Often at points with high values on thisdimension the speaker is staying with one topic, withcontinuing interest also from the interlocutor.
Themost positively correlated feature was the interloc-tor?s volume 400?800 ms ago, for example duringa back-channel or comment showing interest.
Thuswe identify this dimension with the degree of inter-est in the current topic.Dimension 10: Is the speaker thinking?At points with low values on this dimension thespeaker is looking for a word, choosing her wordscarefully, or recalling something, typically insidea turn but preceded by a short pause or an um.At points with high values on this dimension thespeaker seems to be giving up on the topic, declaim-ing any relevant knowledge and/or yielding the turn.The features correlating most with the memory-search/lexical-access state were those of high vol-ume by the speaker 50?1500 milliseconds later; thefeatures correlating most with the giving-up statewere speaking rate.
Thus we identify this dimen-sion with the degree to which the speaker is puttingmental effort into continuing.Dimension 11: How quick-thinking is thespeaker?Points with low values on this dimension includedtwo types: first where a speaker is ending a false startand about to start over, and second where the speakeris about to be cut off by the interlocutor while say-ing something noncommittal to end a turn, such as Iguess.
Points with high values included swift echosand confirmations, which seemed to reflect quick-ness and dominance.
Thus we identify this dimen-sion with quickness, confidence and dominance ver-sus the lack thereof.Dimension 12: Is the speaker claiming oryielding the floor?Points with low values on this dimension gener-ally seemed to be staking a claim to the floor, re-202vealing the intention to talk on for several seconds,sometimes as topic resumptions.
Points with highwere generally floor yields, and sometimes soundednegative or distancing.
Slow future speaking rate, byboth speakers, aligned with the low values, and fastrate with the high values.
We identify this dimensionwith the floor claim/yield continuum.Dimension 13: How compatible is theproposition with the context?Points with low values on this dimension occurredin the course of a self-narrative at the beginning ofsomething contradicting what the listener may haveinferred, or actually did think and say, for examplewith no, we actually don?t.
Points with high valuesof this dimension generally involved a restatementof something said before either by the speaker orthe interloctor, for example restating a question afterthe other failed to answer, or opining that a footballteam can now expect a few bad years, just a dozenseconds after the interlocutor had already expressedessentially the same thought.
The low, contradictingside had high volume and slow speaking rate for afraction of a second; the restatements were the oppo-site.
Thus we identify this dimension with the con-tinuum between a contrast-type rhetorical structureand a repetition-type one.Dimension 14: Are the words being saidimportant?Points with low values on this dimension occurwhen the speaker is rambling: speaking with fre-quent minor disfluencies while droning on aboutsomething that he seems to have little interested in,in part because the other person seems to have noth-ing better to do than listen.
Points with high valueson this dimension occur with emphasis and seemedbright in tone.
Slow speaking rate correlated highestwith the rambling, boring side of the dimension, andfuture interlocutor pitch height with the emphasiz-ing side.
Thus we identify this dimension with theimportance of the current word or words, and the de-gree of mutual engagement.Dimension 15: Are the words premature ordelayed?Points with low values on this dimension includedexamples where the speaker is strongly holding thefloor despite a momentary disfluency, for exampleuh and or well it?s it?s difficult, using creaky voiceand projecting authority.
Points with high value onthis dimension overlapped substantially with thosehigh on dimension 14, but in addition seemed tocome when the speaker starts sharing some infor-mation he had been wanting to talk about but sav-ing up, for in a drawn-out political discussion, a newpiece of evidence supporting an opinion expressedmuch earlier.
Thus we identify this dimension withthe continuum between talking as soon as you havesomething to say (or even slightly before) versustalking about something when the time is ripe.Dimension 16: How positive is the speaker?sstance?Points with low values on this dimension were onwords spoken while laughing or near such words, inthe course of self-narrative while recounting a hu-morous episode.
Points with high values on thisdimension also sometimes occurred in a self nar-ratives, but with negative affect, as in brakes werestarting to fail, or in deploring statements such assubject them to discriminatory practices.
Low val-ues correlated with a slow speaking rate; high valueswith the pitch height.
This we identify this a humor-ous/regrettable continuum.Other DimensionsSpace does not permit the discussion of furtherdimensions here, but the end of Table 1 and Table2 summarize what we have seen in some other di-mensions that we have examined for various rea-sons, some discussed elsewhere (dimensions 25, 62,and 72 in (Ward and Vega, 2012 submitted) and 17,18, 21, 24, 26, and 72 in (Ward et al, 2012 sub-mitted)).
Of course, not all dimensions are mostlyabout dialog, for example dimension 29 appears tobe described best as relating simply to the presenceor absence of a stressed word (Ward et al, 2012 sub-mitted), although that of course is not without impli-cations for what dialog activities may cooccur.7 DiscussionAlthough prosody is messy and multifunctional, thisexploration shows that PCA can derive from rawfeatures a set of dimensions which explain much ofthe data, and which are surprisingly interpretable.2031 this speaker talking vs. other speaker talking 32%2 neither speaking vs. both speaking 9%3 topic closing vs. topic continuation 8%4 grounding vs. grounded 6%5 turn grab vs. turn yield 3%6 seeking empathy vs. expressing empathy 3%7 floor conflict vs. floor sharing 3%8 dragging out a turn vs. ending confidently and crisply 3%9 topic exhaustion vs. topic interest 2%10 lexical access or memory retrieval vs. disengaging 2%11 low content and low confidence vs. quickness 1%12 claiming the floor vs. releasing the floor 1%13 starting a contrasting statement vs. starting a restatement 1%14 rambling vs. placing emphasis 1%15 speaking before ready vs. presenting held-back information 1%16 humorous vs. regrettable 1%17 new perspective vs. elaborating current feeling 1%18 seeking sympathy vs. expressing sympathy 1%19 solicitous vs. controlling 1%20 calm emphasis vs. provocativeness 1%Table 1: Interpretations of top 20 dimensions, with the variance explained by each21 mitigating a potential face threat vs. agreeing, with humor24 agreeing and preparing to move on vs. jointly focusing25 personal experience vs. second-hand opinion26 signalling interestingness vs. downplaying things62 explaining/excusing oneself vs. blaming someone/something72 speaking awkwardly vs. speaking with a nicely cadenced deliveryTable 2: Interpretations of some other dimensionsOverall, the top dimensions covered a broad sam-pling of the topics generally considered important indialog research.
This can be taken to indicate thatthe field of dialog studies is mostly already work-ing on the important things after all.
However pre-viously unremarked aspects of dialog behavior doappear to surface in some of the lower dimensions;here further examination is needed.We had hoped that PCA would separate out thedialog-relevant aspects of prosody from the aspectsof prosody serving other functions.
Generally thiswas true, although in part because the non-dialogfunctions of prosody didn?t show up strongly at all.While this was probably due in part to the spe-cific feature set used, it still suggests that dialogfactors are overwhelmingly important for prosody.Partial exceptions were emotion, attitude, rhetoricalstructure, speaking styles and interaction styles, allof which appeared as aspects of some dimensions.Some dimensions also seemed to relate to dialects,personality traits, or individuals; for example, manyof the most unambiguous turn endings (dimension8) were by the same few speakers, who seemed tous to be businesslike and dominant.2048 Potential ApplicationsThese dimensions, and similar empirically-derivedsets, are potentially useful for various applications.First, the inferred dimensions could serve as afirst-pass specification of the skills needed for acompetent dialog agent: suggesting a dialog man-ager whose core function is to monitor, predict, andguide the development of the dialog in terms of thetop 10 or so dimensions.
This technique could bevery generally useful: since it supports the discov-ery of dialog dimensions in a purely data-driven way(apart from the subjective interpretations, which arenot always needed), this may lead to methods for theautomatically generation of dialog models and dia-log managers for arbitrary new domains.Second, for generation and synthesis, given theincreased interest in going beyond intelligibilityto also give utterances dialog-appropriate wordingsand realizations, the inferred dimensions suggestwhat is needed for dialog applications: we may haveidentified the most important parameters for adapt-ing and controlling a speech synthesizer?s prosodicbehavior for dialog applications.Third, dimensional representations of dialog statecould be useful for predicting the speaker?s upcom-ing word choices, that is, useful for language mod-eling and thus speech recognition, as an improve-ment on dialog-act descriptions of state or descrip-tions in terms of raw, non-independent prosodic fea-tures (Shriberg and Stolcke, 2004; Ward et al, 2011;Stoyanchev and Stent, 2012).
Initial results of con-ditioning on 25 dimensions gave a 26.8% perplexityreduction (Ward and Vega, 2012 submitted).These dimensions could also be used for otherpurposes, including a more-like-this function foraudio search based on similarity in terms of dia-log context; better characterizing the functions ofdiscourse markers; tracking the time course of ac-tion sequences leading to impressions of dominance,friendliness and the like; finding salient or signifi-cant events in meeting recordings; and teaching sec-ond language learners the prosodic patterns of dia-log.9 Future WorkOur study was exploratory, and there are many ob-vious ways to improve on it.
It would be good to ap-ply this method using richer feature sets, includingfor example voicing fraction, pitch slope, pitch con-tour features, spectral tilt, voicing properties, andsyllable- and word-aligned features, to get a morecomplete view of what prosody contributes to di-alog.
Going further, one might also use temporalfeatures (Ward et al, 2011), features of gaze, ges-ture, and words, perhaps in a suitable vector-spacerepresentation (Bengio et al, 2003).
Better featureweighting could also be useful for refining the rank-ing of the dimensions: while our method treatedone standard deviation of variance in one featureas equal in importance to one standard deviation inany other, in human perception this is certainly notthe case.
It would also be interesting to apply thismethod to other corpora in other domains: for ex-ample in task-oriented dialogs we might expect itto find additional important dimensions relating totask structure, question type, recovery from mis-understandings, uncertainty, and so on.
Finally, itwould be interesting to explore which of these di-mensions of state actually matter most for dialogsuccess (Tetreault and Litman, 2006).In addition to the identification of specific dimen-sions of dialog in casual conversations, this papercontributes a new method: that of using PCA overlow-level, observable features to identify importantdimensions of dialog state, which could be appliedmore generally.While we see numerous advantages for quantita-tive, dimensional dialog state modeling, we do notthink that this obsoletes more classical methods.
In-deed, it would be interesting to explore how com-monly used dialog states and acts relate to these di-mensions; for example, to take the set of utteranceslabeled wh-questions in NXT Switchboard and ex-amine where they are located in the ?dialog space?defined by these dimensions (Calhoun et al, 2010;Ward et al, 2012 submitted).AcknowledgmentsThis work was supported in part by NSF Award IIS-0914868.
We thank Olac Fuentes for suggestingPCA, Justin McManus for the prototype analysis,Shreyas Karkhedkar for help with the basic features,and David Novick for discussion.205ReferencesPlinio Barbosa.
2009.
Detecting changes in speech ex-pressiveness in participants of a radio program.
In In-terspeech, pages 2155?2158.Anton Batliner, Jan Buckow, Richard Huber, VolkerWarnke, Elmar No?th, and Heinrich Niemann.
2001.Boiling down prosody for the classification of bound-aries and accents in German and English.
In Eu-rospeech, pages 2781?2784.Yoshua Bengio, Rejean Ducharme, Pascal Vincent, andChristian Jauvin.
2003.
A neural probabilistic lan-guage model.
Journal of Machine Learning Research,3:1137?1155.Kristy Elizabeth Boyer, Eun Young Ha, Robert Phillips,Michael D. Wallis, Mladen A. Vouk, and James C.Lester.
2009.
Inferring tutorial dialogue structurewith hidden Markov modeling.
In Proc.
NAACL-HLTWorkshop on Innovative Uses of NLP for Building Ed-ucational Applications, pages 19?26.Harry Bunt.
2011.
Multifunctionality in dialogue.
Com-puter Speech and Language, 25:222?245.Sasha Calhoun, Jean Carletta, Jason M. Brenier, NeilMayo, Dan Jurafsky, et al 2010.
The NXT-formatSwitchboard corpus: a rich resource for investigatingthe syntax, semantics, pragmatics and prosody of dia-logue.
Language Resources and Evaluation, 44:387?419.Marcela Charfuelan and Marc Schro?eder.
2011.
Investi-gating the prosody and voice quality of social signalsin scenario meetings.
In Proc.
Affective Computingand Intelligent Interaction.Milica Gasic and Steve Young.
2011.
Effective han-dling of dialogue state in the hidden information statePOMDP-based dialogue manager.
ACM Transactionson Speech and Language Processing, 7.J.
J. Godfrey, E. C. Holliman, and J. McDaniel.
1992.Switchboard: Telephone speech corpus for researchand development.
In Proceedings of ICASSP, pages517?520.Martijn Goudbeek and Klaus Scherer.
2010.
Beyondarousal: Valence and potency/control cues in the vo-cal expression of emotion.
Journal of the AcousticalSociety of America, 128:1322?1336.John Grothendieck, Allen L. Gorin, and Nash M. Borges.2011.
Social correlates of turn-taking style.
ComputerSpeech and Language, 25:789?801.Michelle Gubian, Francesco Cangemi, and Lou Boves.2010.
Automatic and data driven pitch contour ma-nipulation with functional data analysis.
In SpeechProsody.Dan Jurafsky, Rajesh Ranganath, and Dan McFarland.2012.
Detecting friendly, flirtatious, awkward, and as-sertive speech in speed-dates.
Computer Speech andLanguage, in press.Chul Min Lee and Shrikanth Narayanan.
2005.
Towarddetecting emotions in spoken dialogs.
IEEE Transac-tions on Speech and Audio Processing, 13:293?303.Cheongjae Lee, Sangkeun Jung, Kyungduk Kim, andGary Geunbae Lee.
2009.
Automatic agenda graphconstruction from human-human dialogs using clus-tering method.
In Proc.
NAACL-HLT 2009: Short Pa-pers, pages 89?92.Fabrice Lefevre and Renato de Mori.
2007.
Unsuper-vised state clustering for stochastic dialog manage-ment.
In ASRU, pages 550?553.Scott McGlashan, Daniel C. Burnett, et al 2010.
Voiceextensible markup language (VoiceXML) 3.0.
Techni-cal report, W3C.Hartmut R. Pfitzinger.
2008.
Segmental effects onthe prosody of voice quality.
In Acoustics?08, pages3159?3164.Elizabeth Shriberg and Andreas Stolcke.
2004.
Prosodymodeling for automatic speech recognition and un-derstanding.
In Mathematical Foundations of Speechand Language Processing, IMA Volumes in Mathe-matics and Its Applications, Vol.
138, pages 105?114.Springer-Verlag.Svetlana Stoyanchev and Amanda Stent.
2012.
Concepttype prediction and responsive adaptation in a dialoguesystem.
Dialogue and Discourse, 3.Yla R. Tausczik and James W. Pennebaker.
2010.
Thepsychological meaning of words: Liwc and computer-ized text analysis methods.
Journal of Language andSocial Psychology, 29:24?54.Joel R. Tetreault and Diane J. Litman.
2006.
Comparingthe utility of state features in spoken dialogue usingreinforcement learning.
In HLT-NAACL, pages 272?279.David Traum and S. Larsson.
2003.
The informa-tion state approach to dialogue management.
In Janvan Kuppevelt and Ronnie Smith, editors, Currentand New Directions in Discourse and Dialogue, pages325?353.
Kluwer.Nigel G.Ward and Alejandro Vega.
2012, submitted.
To-wards empirical dialog-state modeling and its use inlanguage modeling.
In Interspeech.Nigel G. Ward, Alejandro Vega, and Timo Baumann.2011.
Prosodic and temporal features for languagemodeling for dialog.
Speech Communication, 54:161?174.Nigel G. Ward, David G. Novick, and Alejandro Vega.2012, submitted.
Where in dialog space does uh-huhoccur?
In Interdisciplinary Workshop on FeedbackBehaviors in Dialog at Interspeech 2012.206
