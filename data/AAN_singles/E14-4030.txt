Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 154?158,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsImproving Dependency Parsers with SupertagsHiroki Ouchi Kevin Duh Yuji MatsumotoComputational Linguistics LaboratoryNara Institute of Science and Technology{ouchi.hiroki.nt6, kevinduh, matsu}@is.naist.jpAbstractTransition-based dependency parsing sys-tems can utilize rich feature representa-tions.
However, in practice, features aregenerally limited to combinations of lexi-cal tokens and part-of-speech tags.
In thispaper, we investigate richer features basedon supertags, which represent lexical tem-plates extracted from dependency struc-ture annotated corpus.
First, we developtwo types of supertags that encode infor-mation about head position and depen-dency relations in different levels of granu-larity.
Then, we propose a transition-baseddependency parser that incorporates thepredictions from a CRF-based supertaggeras new features.
On standard English PennTreebank corpus, we show that our su-pertag features achieve parsing improve-ments of 1.3% in unlabeled attachment,2.07% root attachment, and 3.94% in com-plete tree accuracy.1 IntroductionOne significant advantage of transition-based de-pendency parsing (Yamada and Matsumoto, 2003;Nivre et al, 2007, Goldberg and Elhadad, 2010;Huang and Sagae, 2010) is that they can utilizerich feature representations.
However, in prac-tice, current state-of-the-art parsers generally uti-lize only features that are based on lexical tokensand part-of-speech (POS) tags.
In this paper, weargue that more complex features that capture fine-grained syntactic phenomenon and long-distancedependencies represent a simple and effective wayto improve transition-based dependency parsers.We focus on defining supertags for English de-pendency parsing.
Supertags, which are lexicaltemplates extracted from dependency structure an-notated corpus, encode linguistically rich infor-mation that imposes complex constraints in a lo-cal context (Bangalore and Joshi, 1999).
Whilesupertags have been used in frameworks basedon lexicalized grammars, e.g.
Lexicalized Tree-Adjoining Grammar (LTAG), Head-driven PhraseStructure Grammar (HPSG) and CombinatoryCategorial Grammar (CCG), they have scarcelybeen utilized for dependency parsing so far.Previous work by Foth et al (2006) demon-strate that supertags improve German dependencyparsing under a Weighted Constraint DependencyGrammar (WCDG).
Recent work by Ambati et al(2013) show that supertags based on CCG lexi-con improves transition-based dependency parsingfor Hindi.
In particular, they argue that supertagscan improve long distance dependencies (e.g.
co-ordination, relative clause) in a morphologically-rich free-word-order language.
Zhang et.
al.
(2010) define supertags that incorporate that long-distance dependency information for the purposeof HPSG parsing.
All these works suggestthe promising synergy between dependency pars-ing and supertagging.
Our main contributionsare: (1) an investigation of supertags that workwell for English dependency parsing, and (2) anovel transition-based parser that effectively uti-lizes such supertag features.In the following, we first describe our supertagdesign (Section 2) and parser (Section 3).
Su-pertagging and parsing experiments on the PennTreebank (Marcus et al., 1993) are shown in Sec-tion 4.
We show that using automatically predictedsupertags, our parser can achieve improvements of1.3% in unlabeled attachment, 2.07% root attach-ment, and 3.94% in complete tree accuracy.2 Supertag DesignThe main challenge with designing supertags isfinding the right balance between granularity andpredictability.
Ideally, we would like to increasethe granularity of the supertags in order capture154Figure 1: Example sentenceWord Model 1 Model 2No VMOD/R VMOD/R, P/R P/Rit SUB/R SUB/Rwas ROOT+L R ROOT+SUB/L PRD/Rn?t VMOD/L VMOD/LBlack NMOD/R NMOD/RMonday PRD/L+L PRD/L+L.
P/L P/LTable 1: Model 1 & 2 supertags for Fig.
1.more fine-grained syntactic information, but largetagsets tend to be more difficult to predict auto-matically.
We describe two supertag designs withdifferent levels of granularity in the following, fo-cusing on incorporating syntactic features that webelieve are important for dependency parsing.For easy exposition, consider the example sen-tence in Figure 1.
Our first supertag design, Model1, represents syntactic information that shows therelative position (direction) of the head of a word,such as left (L) or right (R).
If a word has root as itshead, we consider it as no direction.
In addition,dependency relation labels of heads are added.
Forinstance, ?No?
in the example in Figure 1 has itshead in the right direction with a label ?VMOD?,so its supertag can be represented as ?VMOD/R?.This kind of information essentially provides cluesabout the role of the word in sentence.On top of this, we also add information aboutwhether a word has any left or right dependents.For instance, the word ?Monday?
has a left de-pendent ?Black?, so we encode it as ?PRD/L+L?,where the part before ?+?
specifies the head in-formation (?PRD/L?)
and the part afterwards (?L?
)specifies the position of the dependent (?L?
for left,?R?
for right).
When a word has its dependentsin both left and right directions, such as the word?was?
in Figure 1, we combine them using ?
?,as in: ?ROOT+L R?.
On our Penn Treebank data,Model 1 has 79 supertags.unigrams of supertagsfor p in pi?2, pi?1, pi, pi+1,pi+2, pi+3wpsp, tpspbigrams of supertagsfor p, q in (pi, pi+1),(pi, pi+2), (pi?1, pi), (pi?1,pi+2), (pi+1, pi+2)spsq, tpsq, sptq,wpsq, spwqhead-dependent of supertagsfor p, q in (pi, pi+1),(pi, pi+2), (pi?1, pi), (pi?1,pi+2), (pi+1, pi+2)wpshpwqsldq,tpshptqsldq,wpsrdpwqshq,tpsrdptqshqTable 2: Proposed supertag feature templates.w = word; t = POS-tag; s = supertag; sh = head partof supertag; sld = left dependent part of supertag;srd = right dependent part of supertagIn Model 2, we further add dependency relationlabels of obligatory dependents of verbs.
Here wedefine obligatory dependents of verbs as depen-dents which have the following dependency rela-tion labels, ?SUB?, ?OBJ?, ?PRD?
and ?VC?.
If alabel of a dependent is not any of the obligatorydependent labels, the supertag encodes only theinformation of direction of the dependents (sameas Model 1).
For instance, ?was?
in the exam-ple sentence has an obligatory dependent with alabel ?SUB?
in the left direction and ?PRD?
inthe right direction, so its supertag is representedas ?ROOT+SUB/L PRD/R?.
If a verb has multi-ple obligatory dependents in the same direction,its supertag encodes them in sequence; if a verbtakes a subject and two objects, we may have?X/X+SUB/L OBJ/R OBJ/R?.
The number of su-pertags of Model 2 is 312.Our Model 2 is similar to Model F of Foth etal.
(2006) except that they define objects of prepo-sitions and conjunctions as obligatory as well asverbs.
However, we define only dependents ofverbs because verbs play the most important rolefor constructing syntactic trees and we would liketo decrease the number of supertags.3 Supertags as Features in aTransition-based Dependency ParserIn this work, we adopt the Easy-First parser of(Goldberg and Elhadad, 2010), a highly-accuratetransition-based dependency parser.
We describehow we incorporate supertag features in the Easy-First framework, though it can be done similarly155for other transition-based frameworks like left-to-right arc-eager and arc-standard models (Nivre etal., 2006; Yamada and Matsumoto, 2003).In the Easy-First algorithm, a dependency treeis constructed by two kinds of actions: ATTACH-LEFT(i) and ATTACHRIGHT(i) to a list of par-tial tree structures p1,...,pkinitialized with the nwords of the sentence w1,...,wn.
ATTACHLEFT(i)attaches (pi, p+1) and removes pi+1from the par-tial tree list.
ATTACHRIGHT(i) attaches (pi+1, pi)and removes pifrom the partial tree list.
Featuresare extracted from the attachment point as well astwo neighboring structures: pi?2, pi?1, pi, pi+1,pi+2, pi+3.
Table 2 summarizes the supertag fea-tures we extract from this neighborhood; these areappended to the original baseline features basedon POS/word in Goldberg and Elhadad (2010).For a partial tree structure p, features are de-fined based on information in its head: we usewpto refer to the surface word form of the headword of p, tpto refer to the head word?s POStag, and spto refer to the head word?s supertag.Further, we not only use a supertag as is, butsplit each supertag into subparts.
For instance,the supertag ?ROOT+SUB/L PRD/R?
is split into?ROOT?, ?SUB/L?
and ?PRD/R?, a supertag rep-resenting the supertag head information shp, su-pertag left dependent information sldp, and su-pertag right dependent information srdp.For the unigram features, we use informationwithin a single partial structure, such as conjunc-tion of head word and its supertag (wpsp), con-junction of head word?s POS tag and its supertag(tpsp).
To consider more context, bigram featureslook at pairs of partial structures.
For each (p, q)pair of structures in pi?2, pi?1, pi, pi+1, pi+2, welook at e.g.
conjunctions of supertags (spsq).Finally, head information of a partial struc-ture and dependent information of another partialstructure are combined as ?head-dependent fea-tures?
in order to check for consistency in head-dependent relations.
For instance, in Table 1the supertag for the word ?Black?
has head part?NMOD/R?
wanting to attach right and the su-pertag for the word ?Monday?
has dependent part?L?
wanting something to the left; they are likelyto be attached by our parser because of the consis-tency in head-dependent direction.
These featuresare used in conjunction with word and POS-tag.Model # tags Dev TestModel1 79 87.81 88.12Model2 312 87.22 87.13Table 3: Supertag accuracy evaluated on develop-ment and test set.
Dev = development set, PTB 22;Test = test set, PTB 234 ExperimentsTo evaluate the effectiveness of supertags as fea-tures, we perform experiments on the Penn Tree-bank (PTB), converted into dependency formatwith Penn2Malt1.
Adopting standard approach,we split PTB sections 2-21 for training, section 22for development and 23 for testing.
We assignedPOS-tags to the training data by ten-fold jackknif-ing following Huang and Sagae (2010).
Develop-ment and test sets are automatically tagged by thetagger trained on the training set.4.1 Supertagging ExperimentsWe use the training data set to train a supertaggerof each model using Conditional Random Fields(CRF) and the test data set to evaluate the accu-racies.
We use version 0.12 of CRFsuite2for ourCRF implementation.
First-order transitions, andword/POS of uni, bi and trigrams in a 7-word win-dow surrounding the target word are used as fea-tures.
Table 3 shows the result of the supertaggingaccuracies.
The supertag accuracies are around87-88% for both models, suggesting that most ofthe supertags can be effectively learned by stan-dard CRFs.
The tagger takes 0.001 and 0.005 sec-ond per sentence for Model 1 and 2 respectively.In our error analysis, we find it is challeng-ing to assign correct supertags for obligatorydependents of Model 2.
In the test set, thenumber of the supertags encoding obligatory de-pendents is 5432 and its accuracy is 74.61%(The accuracy of the corresponding supertags inModel 1 is 82.18%).
Among them, it is es-pecially difficult to predict the supertags encod-ing obligatory dependents with a head informa-tion of subordination conjunction ?SBAR?, such as?SBAR/L+SUB/L PRD/R?.
The accuracy of suchsupertags is around 60% (e.g., the accuracy ofa supertag ?SBAR/L+SUB/L PRD/R?
is 57.78%),while the supertags encoding dependents with a la-1http://stp.lingfil.uu.se/ nivre/research/Penn2Malt.jar2http://www.chokkan.org/software/crfsuite/156feature Model1 Model2baseline 90.25 90.25+unigram of supertag 90.59 90.76+bigram of supertag 91.37 91.08+head-dependent 91.22 91.28Table 4: Unlabeled attachment scores (UAS) onthe development set for each feature template.Model UAS Root Completebaseline 90.05 91.10 37.41Model 1 91.35 93.17 41.35Model 2 91.23 92.72 41.35Table 5: Accuracies for English dependency pars-ing on the test set.
UAS = unlabeled attachmentscore; Root = root attachment score; Complete =the percentage of sentences in which all tokenswere assigned their correct heads.bel ?VC?
are assigned almost correctly (e.g., theaccuracy of ?VC/L+VC/R?
is 97.41%).
A verbwithin a subordinating clause usually has the sub-ordinating conjunction as its head and it tendsto be long-range dependency, which is harder topredict.
?VC?
represents verb complements.
Agerund and a past participle is often a dependentof the immediate front verb, so it is not so difficultto identify the dependency relation.4.2 Dependency Parsing ExperimentsFirst, we evaluate the effectiveness of the featuretemplates proposed in Section 3.
Following thesame procedure as our POS tagger, we first assignsupertags to the training data by ten-fold jackknif-ing, then train our Easy-First dependency parseron these predicted supertags.
For development andtest sets, we assign supertags based on a supertag-ger trained on the whole training data.Table 4 shows the effect of new supertag fea-tures on the development data.
We start with thebaseline features, and incrementally add the uni-grams, bigrams, and head-dependent feature tem-plates.
For Model 1 we observe that adding uni-gram features improve the baseline UAS slightlyby 0.34% while additionally adding bigram fea-tures give larger improvements of 0.78%.
On theother hand, for Model 2 unigram features makebigger contribution on improvements by 0.51%than bigram ones 0.32%.
One possible expla-nation is that because each supertag of Model 2encodes richer syntactic information, an individ-ual tag can make bigger contribution on improve-ments than Model 1 as a unigram feature.
How-ever, since supertags of Model 2 can be erroneousand noisy combination of multiple supertags, suchas bigram features, can propagate errors.Using all features, the accuracy of the accu-racy of Model 2 improved further by 0.20%, whileModel 1 dropped by 0.15%.
It is unclear whyModel 1 accuracy dropped, but one hypothesis isthat coarse-grained supertags may conflate somehead-dependent.
The development set UAS forcombinations of all features are 91.22% (Model 1)and 91.28% (Model 2), corresponding to 0.97%and 1.03% improvement over the baseline.Next, we show the parsing accuracies on thetest set, using all unigram, bigram, and head-dependents supertag features.
The UAS3, Rootattachment scores, and Complete accuracy areshown in Table 5.
Both Model 1 and 2 outperformthe baseline in all metrics.
UAS improvementsfor both models are statistically significant underthe McNemar test, p < 0.05 (difference betweenModel 1 and 2 is not significant).
Notably, Model1 achieves parsing improvements of 1.3% in un-labeled attachment, 2.07% root attachment, and3.94% in complete accuracy.
Comparing Model1 to baseline, attachment improvements binned bydistance to head are as follows: +0.54 F1 for dis-tance 1, +0.81 for distance 2, +2.02 for distance3 to 6, +2.95 for distance 7 or more, implying su-pertags are helpful for long distance dependencies.5 ConclusionsWe have demonstrated the effectiveness of su-pertags as features for English transition-based de-pendency parsing.
In previous work, syntactic in-formation, such as a head and dependents of aword, cannot be used as features before partial treestructures are constructed (Zhang and Nivre, 2011;Goldberg and Elhadad, 2010).
By using supertagsas features, we can utilize fine-grained syntacticinformation without waiting for partial trees to bebuilt, and they contribute to improvement of ac-curacies of English dependency parsing.
In futurework, we would like to develop parsers that di-rectly integrate supertag ambiguity in the parsingdecision, and to investigate automatic pattern min-ing approaches to supertag design.3For comparison, MaltParser and MSTParser with base-line features is 88.68% and 91.37% UAS respectively157ReferencesBharat R Ambati, Tejaswini Deoskar and Mark Steed-man.
2013.
Using CCG categories to improve Hindidependency parsing.
In Proceedings of ACL, pages604-609, Sofia, Bulgaria, August.Srinivas Bangalore and Aravind K. Joshi.
1999.
Su-pertagging: An approach to almost parsing.
Com-puational Linguistics, 25(2):237-265.Kilian Foth, Tomas By, and Wolfgang Menzel.
2006.Guiding a Constraint Dependency Parser with Su-pertags.
In Proceedings of COLING/ACL 2006,pages 289-296, Sydney, Australia, July.Yoav Goldberg and Michael Elhadad.
2010.
An Effi-cient Algorithm for Easy-First Non-Directional De-pendency Parsing.
In Proceedings of HLT/NAACL,pages 742-750, Los Angeles, California, June.Liang Huang and Kenji Sagae.
2010.
Dynamic pro-gramming for linear-time incremental parsing.
InProceedings of ACL, pages 1077-1086, Uppsala,Sweden, July.Mitchell.
P. Marcus, Beatrice Santorini and MaryMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: the Penn Treebank.
Computa-tional Linguistics, 19(2):313-330Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, G?ulsen Eryi?git, Sandra K?ubler, Svetoslav,Marinov, and Erwin Marsi.
2007.
Maltparser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13(2):95-135Joakim Nivre, Johan Hall, Jens Nilsson, G?ulsen Eryi?gitand Svetoslav, Marinov.
2006.
Labeled pseudo-projective dependency parsing with support vectormachines.
In Proceedings of CoNLL, pages 221-225, New York, USA.N Okazaki.
2007.
CRFsuite: a fast imple-mentation of Conditional Random Fields (CRFs).http://www.chokkan.org/software/crfsuite/.H Yamada and Y Matsumoto.
2003.
Statistical depen-dency analysis using support vector machines.
InProceedings of IWPT, Nancy, France.Yue Zhang and Joakim Nivre.
2011.
Transition-basedDependency Parsing with Rich Non-local Feaures.In Proceedings of ACL, pages 188-193, Porland,Oregon, June.Yao-zhong Zhang, Takuya Matsuzaki and Jun?ichi Tsu-jii.
2010.
A Simple Approach for HPSG Supertag-ging Using Dependency Information.
In Proceed-ings of HLT/NAACL, pages 645-648, Los Angeles,California, June.158
