COMPILING TRACE & UNIFICATION GRAMMAR FOR PARSING ANDGENERATIONHans Ulrich BlockSiemens AG, Corporate Research, ZFE  IS INF 23Otto Hahn-Ring 6D-8000 Miinchen 83Germanyblock@ztivax.uucpABSTRACTThis paper presents Trace & Unification Gram-mar (TUG), a declarative and reversible grammarformalism that brings together Unification Gram-mar (uG) and ideas of Government & BindingTheory (GB) in an undogmatic way.
A grammarcompiler is presented that transforms a grammarwritten in the TUG formalism into two differentforms, one being useful for parsing, the other be-ing useful for generation.1 INTRODUCTIONDuring the last years there has been a growinginterest in NL systems that can be used for bothparsing and generation.
The invention of unifica-tion grammar that allows for a declarative descrip-tion of language made it possible to use the samegrammar for both tasks.
The main goal of a gram-mar then is to describe a relation between nor-malized (semantic) representations and languagestrings.
A grammar that can be used in both di-rections is called "reversible".We can distinguish three levels of reversibility.On the first level, not only the same grammar isused for parsing and generation, but also the in-terpreter for parsing and generation is reversible.This approach is taken in Shieber (1988).
Besideselegance the approach as the advantage that thereversibility isguaranteed.
Further advantages arementioned in Neumann (1991).
As a disadvantage,it is yet unclear whether and how these systemscan be made efficient.On the second level we find systems where thesame reversible grammar is processed by two dif-ferent interpreters, one for parsing, one for gener-ation.
The advantage of these systems is that thegrammar can be changed and tested easily, whichhelps to shorten the development cycle.
The dis-advantage again is that grammar interpreters areusually too slow to be used in realistic systems.On the third level we finally find systems, wherethe linguistic description is given in a reversibledeclarative grammar.
This grammar is then com-piled into two different forms, one being usefullonly for parsing, the other only for generation.Whereas here we have to face the disadvantagethat compiling can take some time and thereforeprolongs the development cycle, the advantage liesin the efficient processing that can be achievedwith compiled grammars.
Strzalkowski (1990) andStrzalkowski/Peng (1990) describe a compiler thattransforms a grammar originally written for pars-ing into an efficient generator.In the follwing section I will present a system ofthe third type and show by means of which com-piling methods a grammar written in a perspiciousformalism, TRACE AND UNIFICATION GRAMMAR(TUG) can be transformed to fast parsers and gen-erators.
The proposed compilers and their mod-ular architecture have the further advantage thatmost of their parts can be used also for other for-malisms than the one described, e.g.
DCGS.The whole system is part of a polyfunctionallinguistic processor for German called LINGUISTICKERNEL PROCESSOR (LKP).
The LKP contains agrammar of German with broad coverage.
Thegrammar describes the relation between a subsetof German and a subset of QLF, the intermedi-ate semantic form that is used in the Care Lan-guage Engine of SRI Cambridge (Alshawi 1990).The LKP has been implemented in PROLOG.
Pars-ing and Generation of a sentence up to 15 wordsnormally takes between 1 and 10 seconds, with astrong tendency to the lower bound.i002 FORMALISMThe design of Trace and Unification Grammarhas been guided by the following goals:i?
Perspicuity.
We are convinced that the gen-erality, coverage , reliability and developmentspeed of a grammar are a direct function ofits perspicuity, just as programming in Pas-cal is less errorprone than programming in as-sembler.
In the optimal case, the grammarwriter shoul d be freed of reflections on howto code things best for processing but shouldonly be guided by linguistic criteria.
Thesegoals led for .example to the introduction ofunrestricted isjunction into the TUG formal-ism.?
Compat ib i l i ty  to GB Theory.
It was a ma-jor objective bf the LKP to base the grammaron well undo;stood and motivated grounds.As most of the newer linguistic descriptionson German ate in the framework of GB theory,TUG was designed to be somehow compatiblewith this theory though it was not our goalto "hardwire" every Gs principle.?
Efficiency.
:As the LKP is supposed to bethe basis of products for interactive usage ofnatural langu~age, fficiency is a very impor-tant goal.
Making efficiency a design goal ofthe formalism led e.g.
to the introduction offeature types 'and the separation of the move-ment rules int~ head movement and argumentmovement.The basis of TUG is formed by a context freegrammar that is augmented by PATR n-style fea-ture equations.
Besides this basis, the mainfeatures of TUG are feature typing, mixing ofattribute-value-pair nd (PROLOG-) term unifica-tion, flexible macros, unrestricted isjunction andspecial rule types !for argument and head move-ment.2.1 BAS IC  FEATURESAs a very simple example we will look at theTUG version of the example grammar in Shieber(1984).~type  def in i t ions => f.np => f(agr:agrmnt).vp => f(agr:agrmnt).v => f(agr:agrmnt).agrnmt => f(number:number,person:person).number => {slngular,plural}.person => {first,second,third}.ruless - - -> np, vp  \[np:agr = vp:agr.vp - - -> v, np Ivp:agr = v:agr.l ex iconlexicon('Uther',np) Iagr:number = singular,agr:person = third.lexicon('Arthur',np) Iagr:number = singular,agr:person = third.lexicon(knights,v) Iagr:number = singular,agr:person = third.lex icon(knight ,v)  \[( agr:number = singular0( agr:person = f i r s t; agr :person  = second)agr:number = p lura l).The two main differences to PATR II in the ba-sic framwork are that first, TUG is leas flexible inthat it has a "hard" contextfree backbone, whereasin PATR II categories of the context free part areplaceholders for feature structures, their namesboeing taken as the value of the cat feature inthe structure.
Second, TUG has a strict typing.For a feature path to be well defined, each of itsattributes has to be declared in the type definition.Besides defined attribute-value-pairs, TUO al-lows for the mixing of attribute-value-pair unifica-tion with arbitrary structures like PROLOG termsusing a back-quote notation.
This can be re-garded as the unificational variant of the BUILDQoperation known from ATNS.
As an example con-sider the following lexicon entry of each that con-structs a predicate logic notation out of dot :base,i01det :scope  and det :var .lexicon(each,det) Idet :sem ='all(de~:var,det:base ->det:scope)During our work on the German grammar wefound that this feature was very useful for the con-struction of semantic forms.TUG provides templates for a clearer organiza-tion of the grammar.
The agreement in the abovementioned grammar might have been formulatedlike this:agree(X,Y) short_forX:agr = Y:agr.s - - ->  np, vp Iagree(np ,vp) .TUG allows for arbitrary disjunction of featureequations.
Disjunctions and Conjunction may bemixed freely.
Besides well known cases as in theentry for knight above, we found many cases wheredisjunctions of path equations are useful, e.g.
forthe description of the extraposed relative clauses*.2.2  MOVEMENT RULESFurther to these more standard uG-features,TUG provides special rule formats for the de-scription of discontinuous dependencies, so called"movement rules".
Two main types of movementare distinguished: argument movement and headmovement.
The format and processing of argu-ment movement rules is greatly inspired by Chene.a.
(1988) and Chen (1990), the processing ofhead movement is based on GPSG like slash fea-tures.Head MovementA head movement rule defines a relation be-tween two positions in a parse tree, one is the land-ing site, the other the trace position.
Head move-ment is constrained by the condition that the traceis the head of a specified sister (the root node) of1Block/Sclunid (1991) describes our processing tech-nique for disjunctions.the landing site 2.
Trace and Antecedent are iden-tical with the exception that the landing site con-tains overt material, the trace does'nt.
Suppose,that v is the head of vk, vk the head of vp and vpthe head of s, then only the first of the followingstructures is a correct head movement, he secondis excluded because np is not head of vp, the thirdbecause antecedent and trace are unequal.Is, v~ Is .
.
.
\[vp .
.
.\[vk .
.
.
t race(v ) ,  .
.
.
\ ] .
.
.
\ ] .
.
.
\ ] .
.
.
\ ]Is' npt \[s .
.
.
\[vp t race(nph .
.
.\[vk " "  v .
.
.
\ ] .
.
.
\ ] , .
.
\ ]Is, np~ \[s .
.
.
\[vp .
.
.\[vk " "  t race(vh  .
.
.
\ ] .
.
.
\ ] .
, .
\ ] .
.
.
\ ]To formulate head movement in TUG the follow-ing format is used.
First, a head definition defineswhich category is the head of which other.v i s_head_of  vk.vk i s_head_of  vp.vp i s_head_of  s .Second, the landing site is defined by a rule likeS j - - ->  V+S \] .,.To include recursive rules in the head path,heads are defined by the following head definitions.In a structure \[M D, .
.
.
D,\] D~ is the head of14if either Di is_head_of 14 is defined or D~ has thesame category as 14 and either Di is_head_of X orX is_head_of Dt is defined for any category X.Head movement rules are very well suited fora concise description of the positions of the finiteverb in German (sentence initial, second and final)as inHat~ der Mann der Frau das Buch gegeben t~ ?Hast the man the woman the book given ttDer Mann hat~ der Frau das Buch gegebenThe man hast the woman the book given ti... daft der Mann der Frau das Buch gegeben hat... that the man the woman the book given hasAll that is needed are the head definitions andthe rule that introduces the landing site 3.~Here, "head of" is a transitive relation s.t.
if x is headof y and y is head of z then x is head of z.SEven though verb movement is not supposed to be atopic for English grammar, one might think of describingEnglish Subj-Aux inversion in terms of head movement.Peter hao been reading a bookHas~ Peter ti been reading a book102IA rgument  MovementArgument movement rules describe a relationbetween a landing site and a trace.
The trace isalways c-commanded by the landing site, its an-tecedent.
Two different races are distinguished,anaphoric traces and variable traces.
Anaphorictraces must find their antecedent within the samebounding node, variable trace binding is con-strained by subjacency, e.a.
the binding ofthe trace to its antecedent must not cross twobounding nodes. '
Anaphoric traces are foundfor example in English passive constructionsIs \[np The book' of this author\]/ was read ti\]whereas variable graces are usually found in wh-constructions and~ topicalization.
Similar to theproposal in Chen e.a.
(1988), argument movementis coded in TUG by a rule that describes the land-ing site, as for example ins2 - - -> np:ante<trace(var ,np: t racs) ,  s l lante: fx  = trace:fx,This rule states that np: ante 4 is the antecedentof an np-trace that is dominated by sl.
This ruledescribes a leftward movement.
Following Chen'sproposal, TUG also provides for rightward move-ment rules, though these are not needed in theGerman grammar.
A rightward movement rulemight look like this.s2 ---> sl, t raCe(var ,np: t race)>np:an~e \[ante: fx = trace:fx,The first argument in the trace-term indicateswhether the landing site is for a variable (vat)or for an anaphoric (ana) trace.
Other than headmovement, where trace and antecedent are by def-inition identical, the feature sharing of argumenttraces with their 'antecedents has to be definedin the grammar by feature equations (ante : fx  =t race :  fx .
.
.
.
).
~,Furthermore, it is not necessarythat the antecedent and the trace have the samesyntactic ategory.
A rule for pronoun fronting inGerman might e.g.
look like this:spr ---> pron<trace(ana0np) ,  s \[ ...4The notation Cat :Index is used to distinguish two ormore occurrences of the same category in the same rule inthe equation part.
:ante and :trace are arbitrary namesused as index to refer to the two different nps.The current version of the formalisms requiresthat the grammar contains a declaration on whichcategories are possible traces.
In such a declara-tion it is possible to assign features to a trace, forexample marking it as empty:erace(np) I np:e~pty = yes.Bounding nodes have to be declared as such inthe grammar by statements of the formbounding_node(np).bound ing_node(s )  \[ s : tense  = yes .As in the second case, bounding nodes maybe defined in terms of category symbols andfeatures 5.
Typical long distance movement phe-nomena re described within this formalism as inGB by trace hopping.
Below is a grammar frag-ment to describe the sentence Which books~ do youthink ti John knows ti Mary did'nt understand ti:bounding_node(s) .bounding_node(rip).s l  - - -> np<trace(vax,np) ,  s Is - - -> np, vp \[ .
.
.s - - ->  aux ,  np ,  vp \[ .
.
.np - - -> propernoun \[ .
.
.np - - -> det ,  n \[vp - - -> v, s l  \[ .
.
.vp - - -> v, np \[ .
.
.t race(r ip) .The main difference of argument movement toother approaches for the description of discontinu-ities like extraposition grammars (Pereira 1981)is that argument movement is not restricted tonested rule application.
This makes the approachespecially atractive for a scrambling analysis of therelative free word order in the German Mittel/eldas inIhml hatj das Buchk keiner ti tk gegeben tj.3 PROCESSING TRACE &UNIF ICAT ION GRAMMARTUG can be processed by a parser and a genera-tor.
Before parsing and generation, the grammaris compiled to a more efficient form.5Currently, only conjunction of equations i allowed inthe definition of bounding nodes.103The first compilation step is common to gener-ation and parsing.
The attribute-value-pair struc-ture is transformed to (PROLOG) term structureby a TUG-tO-.DCG converter.
This transformationmakes use of the type definitions.
As an exampleconsider the transformation f the grammara => f(al:tl).b => f(al:tl).tl => f(a2:t2,a3:t3).~2 => {1,2}.t3  => {2,3}.a - - ->  b Ia:al :a3 = 2 ,( a:a l :a2 = i; a:al = b:al  ).It is transformed to the following rammar in aDCG like format e.a( t l (A ,2 ) )  --->\[b(B), {A = 1 ; ~1(A,2) = B}\].The compilation steps following the TUG-to-DCGconverter are different for parsing and generation.3.1 THE PARSER GENERATORIn the LKP, a TUG is processed by a Tomitaparser (Tomita 1986).
For usage in that parser theresult of the TUG-tO-DCG converter is compiled inseveral steps:?
expansion of head movement rules?
transformation f argument movement rules?
elimination of empty productions?
conversion to LR(K) format?
computation of LR.
tablesFirst, head movement rules are eliminated andthe grammar is expanded by introducing slashrules for the head path by the head movement ex-pander.
Suppose the Tuo-to-DCG converter hasproduced the following fragment:eNote that the goal {A " 1 ; 1;1(A.2) ,m B} is inter-preted as a constraint and not as a PROLOG goal as inDCGs.
See Block/Schmld (1991) for the evaluation ftheconstraints.v(_) is_head_of vk(_).vk(_) is_head_of vp(_).vp(_) is_head_of s(_).s1(Sl) ---> Iv(v) + sCs)\].s(s) ---> \[...,vp(vP),...\].vp(VP) ---> \[.
.
.
,vk(VX) .
.
.
.
\].vk(VK) ---> \ [ .
.
.
, v (V) , .
.
.
\ ] .Then, the head movement expander introducesslash rules ~ along the head-path, thereby introduc-ing the empty nonterminals push(X) and pop(X).rules solar?
(s) ---> \[ .... vp(VP),...\].vp(VP) - - -> \ [ .
.
.
, vk (VX) , .
.
.
\ ] .vk(VZ) ---> \[...,v(V),...\].newly  introduced s lash ru lessl(S1) - - ->  \ [v(V) ,  push(v(V)) ,  s_v(S) \ ] .s_v(S) - - -> \ [ .
.
.
, vp_v(VP) , .
.
.
\ ] .vp_v(VP) - - ->  \[ .
.
.
.
vk_v(VX) .
.
.
.
\ ] .vk_v(VX) ---> \[ .
.
.
.
v_v (V) , .
.
.
\ ] .v_vCV)---> \[popCvCV))\].empty productions for  push and poppush(X) ---> \[\].pop(X) ---> \[\].push(X) and pop(X) are "marker rules"(Aho/Sethi/Ullman 1986) that invoke the parserto push and pop their argument onto and off aleft-to-right stack.
This treatment of head move-ment leads to a twofold prediction in the Tomitaparser.
First, the new slash categories will lead toLR parsing tables that predict hat the verb will bemissing if rule s l  - - -> .
.
.
has applied.
Second,the feature structure of the verb is transported tothe right on the left-to-right stack.
Therefore, assoon as a v_v is expected, the whole informationof the verb, e.g.
its subcategorization frame, isavailable.
This strategy leads to a considerableincrease in parsing efficiency.In the next compilation phase, argument move-ment rules are transformed tothe internal format.For the control of gaps a gap-threadding mecha-nism is introduced.
Following Chen e.a.
(1988),the gap features are designed as multisets, thus al-lowing crossing binding relations as mentioned insection 2.7 A slashed category Xl?
is represented using the under.-score character Z_?.104ITo see the effect of this compilation step, takethe following fragment as output of the head move-ment expander.boundlng_node(s(_)).sl(Si) ---> np(NP)<trace(var,np(Trace)),sCs).s(S) ---> np(NP), vp(VP).vp(VP) ---> v(V).vp(VP) ---> v(V), np(NP).t race(np(_) ) .The argument movement expander transformsthis to the followifig grammar.sl(Gi,Go0Sl) --~> np(Gi,Gt,NP),s(Gs,Go,S) I,{cut_t race( t race(var ,np(Trace) ) ,Gs,Gt)}.s(Gi,Go,S) --->!np(Gi,Gt,NP),vp(Gt,Go, VP),{bound(Gi)}.vp(Gi,Go,VP) --~> v(Gi,Go,V).vp(Gi,Go,VP) --~> v(Gi,Gt,V),np(Gt,Go,NP).np(\[trace(_,np(SP))\[G\],G,NP) ---> \[\].iThe predicates cut_trace/3 and bound/1 aredefined as in Chen e.a.
(1988).The next step, the empty production eliminater,eliminates all empty productions except those forpush and pop.
This transforms the output ofthe argument movement expander to the follow-ing grammar.s1(Gi,Go,S1) --i> np(Gi,Gt,NP),s(Gs,Go,S),{cut_trace(trace(var,np(Trace)),Gs,Gt)}.s l ( \ [ trace(_,np(NP))\[Gt\] ,Go,S1) --->s(Gs,Go,S).
{cut_trace(trace(var,np(Trace)),Gs,Gt)}.s(Gi,Go,S) --->inp(Gi,Gt,NP),vp(Gt,Go,VP),{bound(Gi)}.s(\[trace(_,np(NP))\[Gt\]0Go,S) --->vp(Gt,Go,VP),{bound(Gi)}.vp(Gi,Go,VP) ---> v(Gi,Go,V).vp(Gi,Go,VP) --~> v(Gi,Gt,V),np(Gt,Go,NP).vp(Gi,Go,VP) --~>v(Gi,\[trace(_,np(SP))\[Go\],V).Elimination of empty productions allows fora simpler implementation of the Tomita parser,which again leads to an increased efficiency.The next step, the DcG-to-LRK converter splitsthe grammar rules into a context free anda DCG part.
A context free rule is repre-sented as rule(No,LIIS,RHS), a DCG rule asdcg_rule (No, LHS, RHS, Constraint).
Rules aresynchronized by their numbers.
After this stepthe above grammar f agment is represented in thefollowing format.rule(l, sl 0 \[np, s\] ).rule (2, s I, \[s\] ).rule(S, s, \[np, vp\] ).ru le  (4, s, \[vp\] ).ru le(S,vp,  \[v\] ).rule(6,vp, \[v,np\] ).dcg_rule(1,s l (Gi ,Go,S1),\[np(Gi,Ot,NP),s(~s,Go,S)\],cut_ t race( t race(var ,np(Trace) ) ,~s,~t)).dcg_rule(2,sl(\[trace(_,np(NP))\]Gt\],Go,St),\[s(Gs,Go,S)\],cut_ t race( t race(var ,np(Trace) ) ,Gs,Gt)).dcg_rule(3,s(Gi,Go,S),\[np(Gi,Gt,NP),vp(Gt,Go,VP)\],bound(Gi)).dcg_rule(4,s( \ [~race(_,np(NP)) iGt\ ] ,Go,S),\[vp(Gt,Go,VP)\],bo~uad(Gi)).dcg_rule(S,vp(Gi,Go,VP),\[v(Gi,Gv,V)\],( Gv = Go; Gv = \[trace(_,np(NP))\[Go\])).dcg_rule(6,vp(Gi,Go,VP),\[v(Gi,Gt,V),np(Gt,Go,NP)\],t rue) .Note that during this step, different rules thatshare the same context free backbone are trans-formed to a single context free rule.
The differ-ence in their feature structure is expressed in adisjunction in the Constraint (e.g.
rule 5).
Asvery often traces occur in optional positions (e.g.objects, as in vp - - -> v. vp - - -> v, np), theelimination of empty productions (traces) consid-erably reduces the amount of edges the parser hasto build.105After these compilation steps the context freerules are transformed to YACC format and YACCis used to compute the LR parsing table.
Finally,YACC'S y. output file is transformed to PROLOG.3.2THE GENERATORGENERATORFor generation with TUG an improved versionof the semantic-head-driven g erator (SHDG) (seeShieber e.a .
1990) is used.
Before beeing usefulfor generation, the grammar is transformed in thefollowing steps:?
expansion of head movement rules* transformation to the semantic head drivengenerator format?
expansion of movement rules?
elimination of nonchainrules with uninstanti-ated semantics?
goal reordering and transformation to exe-cutable prolog codeFirst, the head movement expander transformsthe head movement rules.
As in the parser gen-erator, slashed categories are generated along thehead path, but no push and pop categories are in-troduces.
Instead, the head movement rule andthe trace are treated similar to argument move-ment.
The resulting relevant new rules from theexample above are:newly introduced slash rulessl(S1) - - -> \[v(V)<trace(var,v_v(V)) ,s_v(S)S.s_v(S) - - -> \[ .
.
.
.
vp_v(VP) , .
.
.
\ ] .vp_v(VP) - - -> \[ .
.
.
,vk_v(VK) .
.
.
.
\ ] .vk_v(VZ) - - -> \ [ .
.
.
, v_v (V) , .
.
.
\ ] .t race(_ ,v_v(V) ) .In the next step rule symbols are transformedto the node(Cat,S,S0) format needed by thesemantic-head-driven g erator.
Thereby disjunc-tions on the semantic argument as in the followingexamplea(Sem) ---> b(BSem), c(CSem),(BSem = Sem; CSem = Sam}.are unfolded (multiplied out) to different rules.The output of this step for the above rule is:node(a(Sem),S,SO) --->nods(b(Sem),S,Sl),node(c(CSem),S1~SO).node(a(Sem),S,SO) --->node(b(SSem),S,Sl) ,node(c(Sem),Sl,SO).Obviously, unfolding of semantic disjunctions isnecessary for a correct choice of the semantic head.The next compilation cycle expands the move-ment rules.
Similar to the parser generator twoarguments for gap threaddin8 are introduced.
Thefilling of the arguments and the transformation ofthe movement rules is different from the parsergenerator.
It is a rather complicated operationwhich is sensitive to the semantics control flow.Given a rulea(A) ---> b(B)<trace(var,b(BT)), c(C)}we can distinguish two cases:1) The rule is a nonchain rule in the sense ofShieber e.a.
(1990) or it is a chain rule and theantecedent of the trace is the semantic head.
Inthis case the antecedent has to be generated priorto the trace.
A typical example is a predicate logicanalysis as in:node(sl(Sem),S,S0) --->node(np(Sem,SemIn) <trace(vax0np(NPSem,NPSem)),S,Sl),nods(s(SemIn),Sl,SO).As the antecedent carries the semantic informa-tion, it is expanded at the landing site, while thetrace is just empty:node(sl(Gi,Go,Sem),S,SO) --->node(np(Gi,qt,Sem,SemIn),S,Sl),node(s(Gt,Gs,Semln),Sl,SO),{cut_trace(trace(var,np(NPSem,NPSem),Gs,Gi)}.node(np(\[trace(var,np(NPSem,NPSem))lGo\],Go,NPSem,NPSem),S,S).2) If any element other than the antecedent isthe semantic head, then this head has to be gen-erated prior to the antecedent.
As the head mightcontain the trace, it also has to be generated priorto its antecedent.
Consider the rule:node(sl(Sem),S,SO) --->106node(np(NPSem)<trace(var,np(NPSem)),S,SI),node(s(Sem),Sl,S0).In this rule s is generated prior to np.
Withins, the trace of np w'ill be generated.
Following thesuggestion in Shieber e.a.
(1990), rules like thisaxe compiled in such a way that an antecedentis generated in the~ trace position without linkingit to the input st,ing.
This antecedent is thenadded to the set of gaps together with its startingand ending position (coded as a difference list).When generation domes to the landing site, theantecedent is cut out of the trace set.
Therebyits starting and ending position is unified with thelanding site's star( and end positions.
The trans-lation of the above I rule is:node(sl(Gi,Go,Sem),S,SO) --->node(s(Gs,Go,Sem),Sl,SO),{cut_~race(trace(vax,np(NPSem),S,S1),Gs,Gi)}.node(np(\[trace(var,np(NPSem),S,SO)\[Go\],Go,NPSem),SX,SX) --->node(np(G,G~NPSem),S,SO).In the next steP, a certain class of nonchainrules is eliminated from the grammar.
One ofthe basic inefficiencies of the semantic-head-drivengenerator in Shiebcr e.a.
(1990) has its origin innonchaln rules who~se left-hand-side-semantics is avariable.
This kin d of nonchain rule often resultsfrom empty productions or lexicon entries of se-mantically empty words.
For instance, in a gram-mar and lexicon fragment likevk(SC)/Sem ---> aux(VKSem,SC,VKSC)/Sem,vk(VKSC)/VKSem,aux (VKSem, SC, SC)/past (VKSem) ---> \[has\].aux (Sere, SC, \[Subj \[ SC\] )/Sere ---> \[is\].the rule introducing is is a nonchain rule whosesemantics is a variable and thus cannot be indexedproperly.
Rules like this one are eliminated by apartial evaluation technique.
For each grammarrule that contains the left-hand-side of the rule onits right-hand-side/~ a copy of the rule is producedwhere the variables ~ are unified with the left-hand-side of the nonchain rule and the correspondingright-hand-side element is replaced with the right-hand-side of the nonchain rule.
E.g.
insertion ofthe rule for is into the vk-rule above leads tovk(SC)/Sem ---> \[is\], vk(\[Subj I SC\])/Sem.which is a normal chain rule.A final compilation transforms the rules to exe-cutable PROLOG code and sorts the right hand sideto achieve a proper semantics information flow.Suppose that, in the following nonchaln rule thefirst argument of a category is its semantics argu-ment.node(a(f(Sem)),S,SO) --->node(b(BSem)oS,Sl),node(c(CSem,BSem),SI,S2),node(d(Sem,CSem),S2,SO).The righthand side has to be ordered in such away that all semantics arguments have a chance tobe instantiated when the corresponding categoryis expanded, as in the following rule:node(a(f(Sem)),S,SO) - - ->node(d(Sem,CSem),S2,SO),node(c(CSem,BSem),Sl,S2),node(b(BSem),S,S1).This ordering is achieved by a bubble-sort likemechanism.
Elements of the right-hand-side aresorted into the new right-hand-side from right toleft.
To insert a new element e, ew into an (alreadysorted) list el ... ei, e , , ,  is inserted into e, ...ei-1if the semantics argument of e, ew is not equal tosome argument of ei, otherwise it is sorted afterei.In the final PROLOG code nonchaln rules are in-dexed by the functor of their lefthand side's se-mantics as in the following example.~(Z(Sem),Sxp) :-generate(Sem0node(d(Sem,CSem),s2,so)),genera~e(CSem,node(c(CSem,BSem),Sl,S2)),generate(BSem,node(b(BSem),S,S1)),a(node(a(f(Sem)),S,SO),gxp).Chain rules (like e.g.
the one that re-suits by replacing node(a(fCSem)),S,S0) bynode(a(Sem),S,S0) in the rule above) are in-dexed by their syntactic ategory:d(node(d(Sem),S2,SO),Exp) :-l ink(a(Sem),Exp),generate(CSem,node(c(CSem,BSem),107sl ,s2)),generate(BSem,node(b(BSem),S,S1)),a(node(a(Sem),S,SO),Exp).The auxiliary predicates needed for the genera-tor then can be reduced to bottom-up terminationrules C(X,X) for all syntactic ategory symbols Cand the predicate for generate/2:generate(Sem,Exp) :-func~or(Sem,F,A),functor(Goal,F,2),arg(1,Goal,Sem),arg(2,Goal,Exp),call(Goal).4 CONCLUSIONWe have distinguished three levels of reversibil-ity: runtime reversibility, interpretation reversibil-ity and compilation reversibility.
We then havepresented Trace & Unification Grammar, a gram-mar formalism that tries to bridge the gap be-tween uo and GB theory in an undogmatic wayand have presented a parser generator and a gen-erator generator that lead to effient runtime codeof the grammar both for parsing and for genera-tion.
No special effort has been invested to opti-mize the compilers themselves, o the compilationtakes about 1.5 secs.
per rule or lexicon entry.Due to space limitations many details of the com-pilation phase could not be discussed.The presented grammar formalism has beenused to describe a relevant subset of German lan-guage and a smaller subset of Chinese.
The gram-mars describe a mapping between German andChinese and QLF expressions.ACKNOWLEDGEMENTSI would like to thank Ms. Ping Peng and mycollegues Manfred Gehrke, Rudi Hunze, SteffiSchachtl and Ludwig Schmid for many discussionson the TUG-formalism.REFERENCESAho, A.V., R. Sethi and J.D.
Ullman (1986)Compilers.
Principles, Techniques and Tools.Addison-Wesley Publishing Company.Alshawi, H. (1990) "Resolving Quasi LogicalForms", Computational Linguistics, Vol.
16,pp.
133-144.Block, H. U.
(forthcoming) "Two optimizationsfor Semantic-Head-Driven G erators".Block, H. U. and L. A. Schmid (forthcoming) "Us-ing Disjunctive Constraints in a Bottom-UpParser".Chen, H.-H., I-P. Lin and C.-P. Wu (1988) "Anew design of Prolog-based bottom-up Pars-ing System with Government-Binding The-ory", Proc.
l~th International Conferenceon Computational Linguistics (COLING-88),pp.
112-116.Chen, H.-H. (1990) "A Logic-Based Government-Binding Parser for Mandarin Chinese", Proc.13th International Conference on Computa-tional Linguistics (COLING-90), pp.
1-6.Neumann, G. (1991) "A Bidirectional Model forNatural Language Processing" Proc.
5thConf.
of the European Chapter of the ACL(EACL-91) pp.
245-250.Pereira, F. (1981) "Extraposition Grammar"Computational Linguistics Vol.
7, pp.
243-256.Shieber, S.M.
(1984) "The design of a ComputerLanguage for Linguistic Information" Proc.lOth International Conference on Computa-tional Linguistics (COLING-84), pp.
362-366.Shieber, S.M.
(1988) "A Uniform Architecture forParsing and Generation", Proc.
l~th Interna-tional Conference on Computational Linguis-tics (COLING-88), pp.
614-619.Shieber, S.M., G. van Noord, F.C.N.
Pereiraand R.C.
Moore (1990).
"Semantic-Head-Driven Generation".
Computational Linguis-tics, Vol.
16, pp.
30-43.Strzalkowsi, T. and Ping Peng (1990).
"Auto-mated Inversion of Logic Grammars for Gen-eration" Proc.
Conf.
of the 28th AnnualMeeting of the ACL, (ACL-90) pp.
212-219.Strzalkowsiki, T. (1990).
"How to Invert a Nat-ural Language Parser into an Efficient Gen-erator: An Algorithm for Logic Grammars"Proc.
13th International Conference on Com-putational Linguistics (COLING-90), pp.
347-352.Tomita, M. (1986).
E~icient Parsing for NaturalLanguage: A fast Algorithm for Practical Sys-tems.
Boston: Kluwer Academic Publishers.108
