An Example-Based Chinese Word Segmentation System for CWSB-2Chunyu Kit Xiaoyue LiuDepartment of Chinese, Translation and LinguisticsCity University of Hong KongTat Chee Ave., Kowloon, Hong Kong{ctckit, xyliu0}@cityu.edu.hkAbstractThis paper reports the example-basedsegmentation system for our participa-tion in the second Chinese Word Seg-mentation Bakeoff (CWSB-2), present-ing its basic ideas, technical details andevaluation.
It is a preliminary imple-mentation.
CWSB-2 valuation showsthat it performs very well in identify-ing known words.
Its unknown worddetection module also illustrates greatpotential.
However, proper facilities foridentifying time expressions, numbersand other types of unknown words areneeded for improvement.1 IntroductionWord segmentation is to identify lexical items,especially individual word forms, in a text.
Itinvolves two fundamental tasks, both aiming atminimizing segmentation errors: one is to in-fer out-of-vocabulary (OOV) words, also knownas unknown (or unseen) word detection, and theother to identify in-vocabulary (IV) words, withan emphasis on disambiguation.
OOV words andambiguities are the two major causes to segmen-tation errors.Accordingly?word segmentation approachescan be divided into the categories summarized inTable 1 in terms of the resources in use to tacklethese two causes.
The closed and open tracks inCWSB correspond, respectively, to the last twocategories, both involving inferring OOV wordsCategory Resource in use Major TaskLexicon Tr.
Corpus OOV Disamb.WDa - (-)b +WS/CLc + - - +WS/ILd + - + +WS/TCe (+)f + + +WS/TC+Lg + + + +aWord discovery, or unsupervised lexical acquisitionbInput data is used for unsupervised trainingcWord segmentation with a complete lexicondWord segmentation with an incomplete lexiconeWord segmentation with a pre-segmented training corpusfIt can be extracted from the given training corpus.gWord segmentation with a pre-segmented training corpusand an extra lexiconTable 1: Categories of segmentation approachbeyond disambiguating IV words.
Word discov-ery and OOV word detection pursue a similar tar-get, i.e., inferring new words.
The continuumconnecting them is the size of the lexicon in use:the former assumes few words known and the lat-ter an existing lexicon to some scale.
Inferringnew words is an essential task in word segmen-tation, for a complete lexicon is rarely a realisticassumption in practice.This paper presents our segmentation systemfor participation in CWSB-2.
It takes an example-based approach to recognize IV words and fol-lows description length gain (DLG) to infer OOVwords in terms of their text compression effect.Sections 2 and 3 below introduce the example-based and DLG-based segmentation respectively.Section 4 presents a strategy to combine theirstrength and Section 5 reports our system?s per-formance in CWSB-2.
Following error analysisin Section 6, Section 7 concludes the paper.1462 Example-based segmentationHow to utilize as much information as possi-ble from the training corpus to adapt a segmen-tation system towards a segmentation standardhas been a critical issue.
Kit et al (2002) andKit et al (2003) attempt to integrate case-basedlearning with statistical models (e.g., n-gram) byextracting transformation rules from the train-ing corpus for disambiguation via error correc-tion; Gao et al (2004) adopt a similar strategyfor adaptive segmentation, with transformationtemplates (instead of case-based rules) to modifyword boundaries (instead of individual words).The basic idea of example-based segmentationis very simple: existing pre-segmented strings intraining corpus provide reliable examples for seg-menting similar strings in input texts.
In contrastto dictionary checking for locating possible wordsin an input sentence to facilitate later segmenta-tion operations, pre-segmented examples give ex-act segmentation to copy.The example-based segmentation can be im-plemented in the following steps.1.
Find all exemplar pre-segmented fragments,with regards to a training corpus, and allpossible words, with regards to a lexicon,from each character in an input sentence;2.
Identify the optimal sequence, among allpossibilities, of the above items over the sen-tence following some optimization criterion.If adopting the minimal number of fragments orwords in a sequence as optimization criterion, wehave a maximal matching approach to word seg-mentation.
However, it differs remarkably fromthe previous maximal matching approaches: itmatches pre-segmented fragments, instead of dic-tionary words, against an input sentence.
It can becarried out by a best-first strategy: repeatedly se-lect the next longest example or word until the en-tire sentence is properly covered.
Unfortunately,the best-first approach does not guarantee to givethe best answer.
For CWSB-2, we implementeda program following the Viterbi algorithm to per-form a complete search in terms of the number offragments, and then words, in a sequence.However, a serious problem with this example-based approach is the sparse data problem.
Longexemplar fragments are more reliable but smallin number, whereas short ones are large in num-ber but less reliable.
In the case of no exemplarfragment available for an input sentence, this ap-proach draws back to the maximal match segmen-tation with a dictionary.
How to incorporate sta-tistical inference into example-based segmenta-tion to infer more reliable optimal segmentationbeyond string matching remains a critical issuefor us to tackle.3 DLG-based segmentationDLG is formulated in Kit and Wilks (1999) andKit (2000) as an empirical measure for the com-pression effect of extracting a substring from agiven corpus as a lexical item.
DLG optimizationis applied to detect OOV words for our participa-tion in CWSB-2.
It works as follows in two steps.1.
Calculate the DLG for all known wordsand all new word candidate (i.e., substringswith frequency ?
2, preferably, in the testcorpus), based on frequency information inthe training and the test corpora;2.
Find the optimal sequence of such items overan input sentence with the greatest sum ofDLG.Step 2 above in our system re-implements onlythe first round of DLG-based lexical learning inKit (2000).
It is implemented by the same algo-rithm as the one for example-based segmentation,with DLG as optimization criterion.
Evaluationresults show that this learning-via-compressionapproach discovers many OOV words success-fully, in particular, person names.4 IntegrationThe example-based segmentation is good at iden-tifying IV words but incapable of recognizing anynew words.
In contrast, the DLG-based segmen-tation performs slightly worse but has potential todetect new words.
It is expected that the strengthof the two could be combined together for perfor-mance enhancement.However, because of inadequate time we hadto take a shortcut in order to catch the CWSB-2 deadline: DLG segmentation is only appliedto recognize new words among the sequences ofmono-character items in the example-based seg-mentation output.147Track P R F OOV ROOV RIVASc .944 .902 .923 .043 .234 .976PKUc .929 .904 .916 .058 .252 .971MSRc .965 .935 .950 .026 .189 .986Table 2: System performance in CWSB-25 PerformanceOur group took part in three closed tracks inCWSB-2, namely, ASc, PKUc and MSRc, with apreliminary implementation of the example-basedword segmentation presented above.
Our sys-tem?s performance in terms of CWSB-2?s offi-cial scores is presented in Table 2.
Its ROOVscores look undesirable, showing that applyingthe first round of DLG-based segmentation to se-quences of mono-character items is inadequatefor the OOV word discovery task.
Nevertheless,its RIV scores are, in general, quite close to thetop systems in CWSB-2, although it does not havea disambiguation module to polish its maximalmatching output.However, this is not to say that the DLG-basedsegmentation deserves no credit in unknown worddetection.
It does recognize many OOV words,as shown in Table 3.
The low ROOV rate has todo with our system?s incapability in handling timeexpressions, numbers, and foreign words.6 Error analysisMost errors made by our system are due tothe following causes: (1) no knowledge, overtor implicit, in use for recognizing time expres-sions, numbers and foreign words, as restricted byCWSB-2 rules, (2) a premature module for OOVword detection, (3) no further disambiguation be-sides example application, and (4) significant in-consistency in the training and test data.The inconsistency exists not only between thetraining and test corpora for each track but, moresurprisingly, also within individual training cor-pora.
Some suspected cases are illustrated in Ta-bles 4, 5 and 6.
They are observed to be in a largenumber in the CWSB-2 corpora.
Scoring with agolden standard involving so many of them ap-pears to be problematic, for it penalizes the sys-tems for handling such cases right and rewardsthe others for producing ?correct?
answers.
WhatASc: ??
(106) ???
(45) ??
(31) 29)??)
??
(21) ??
(20) ??
(18) ???
(17) ???
(16) ???
(15) ???
(13) ??
(12) ???
(11) ??
(11) ????
(11) ??10)?)
??
(9) ???
(8) ??
(8) ???
(7) ??
(7) ???
(7) ???
(6) ????
(6) ??
(5) ???
(5) ???
(5) ???
(5) ???
(5) ???
(5) ??
(5) ??5)?)
???
(4) ??
(4) ??
(4) ????
(4) ???
(3) ??
(3) ????
(3) ???
(2) ??
(2) ????2)?)
??
(2) ?
?
?
?
?
?PKUc: ??
(38) ??
(23) ??
(21) ???20)???)
??
(19) 17)???)
?16)?)
??
(15) ???
(12) ??
(11) ???
(10) ??
(10) ??9)?)
??
(9) ?8)??)
??
(8) ???
(8) ??
(7) ???
(7) ??
(6) ???
(6) ??6)?)
??
(6) ?6)?)
???
(5) ????
(5) 5)??)
???
(5) ???
(5) ??
(5) ??
(5) ??
(5) ???
(4) ???
(4) ???
(4) ?4)?)
???
(4) ??
(4) ??
(4) ??
(4) ?4)?)
???
(4) ???
(4) ??
(4) ??3)?)
???
(3) ?????
(3) ??
(3) ???
(3) ??
(3) ??
(3) ??
(3) ???
(3) ???
(3) ?
?
?
?
?
?MSRc: ?26)?)
??
(19) ???
(19) ???
(17) ?15)?)
?14)?)
??
(14) ???
(13) ??
(13) ????????
(12) ??
(12) ??
(11) ???
(10) ??
(10) ?10)???)
???
(10) ??
(10) ???
(9) ??9)?)
???
(8) ?8)?)
??
(8) ???
(7) ????
(7) ???
(7) ??
(6) ???
(6) ??
(6) ?6)?)
??
(6) ??
(5) ???
(5) ??
(5) ??
(5) ???
(5) ???
(5) ???
(4) ??
(4) ?4)?)
??
(4) ???
(4) ???
(4) ???
(3) ???
(3) ??
(3) ???
(3) ???
(3) ???
(3) ??3)?)
??
(3) ???
(3) ???
(3) ???
(3) ???
(3) ??
(3) ???
(3) ????
(2) ?
?
?
?
?
?Table 3: Illustration of new words successfullydetected, with frequency in parenthesesis even more worth noting is that (1) an inconsis-tent case involves more than one word, and (2)the difference between a correct and an erroneousjudgment of a word is 1, in a sense, but the differ-ence between one system that loses it for doingright and another that earns it by doing wrong issurely greater.7 ConclusionsIn the above sections we have reported theexample-based word segmentation system forour participation in CWSB-2, including its ba-sic ideas, technical details and evaluation results.It has illustrated an excellent performance in IVword identification and nice potential in OOVword discovery.
However, its weakness in han-dling time expressions, numbers and other typesof unknown words has hindered it from perform-ing better.
We are expecting to implement a full-fledged version of the system for improvement.AcknowledgementsThe work described in this paper was supportedby the RGC of HKSAR, China, through theCERG grant 9040861.
We wish to thank AlexFang and Robert Neather for their help.148Training & Answer fT/fA Golden Standard fT/fA??
?
4/8 ???
0/0?
?
28/7 ??
0/0??
?
5/7 ???
0/0?
??
11/6 ???
0/0?
?
186/5 ??
0/0??
?
41/4 ???
0/0?
?
?
29/4 ???
0/0?
?
?
129/4 ???
0/0?
?
?
23/3 ???
0/0?
??
47/3 ???
0/0??
??
33/2 ????
0/0??
??
32/2 ????
0/0??
??
85/2 ????
0/0????
10/2 ??
??
0/0??
?
62/2 ???
0/0?
??
23/2 ???
0/0????
192/1 ?
??
?
0/0???
149/1 ?
??
0/0??
??
66/1 ????
0/0???
31/1 ??
?
0/0?
??
80/1 ???
0/0??
?
68/1 ???
0/0?
?
??
13/1 ????
0/0??
??
13/1 ????
0/0?
??
20/1 ???
0/0?
?
?
?
6/1 ????
0/0?
?
?
29/1 ???
0/0??
?
?
?
4/1 ?????
0/0????
24/7 ??
??
25/0????
17/3 ??
??
53/0?
?
?
1201/2 ???
2/0Table 4: Some inconsistent cases in AS corpusTraining & Answer fT/fA Golden Standard fT/fA???
14/26 ?
??
0/0???
6/1 ?
??
0/0???
5/21 ?
??
0/0????
24/19 ??
?
?
0/0?
?
23/18 ??
0/0????
66/15 ??
??
0/0?????
10/9 ??
???
0/0?????
10/5 ?
??
??
0/0????
45/5 ??
??
0/0????
42/5 ??
??
0/0????
27/4 ??
??
0/0????
21/4 ??
??
0/0????
126/4 ??
??
0/0????
20/4 ??
??
0/0????
15/4 ??
??
0/0????
25/4 ?
???
0/0????
25/3 ??
??
0/0?????
13/3 ??
???
0/0???
32/3 ??
?
0/0????
30/3 ??
??
0/0???
11/3 ?
??
0/0????
15/3 ??
??
0/0????
22/3 ??
??
0/0??
?
11/2 ?
??
0/0??
25/2 ?
?
0/0???????
3/1 ????
?
?
?
0/0???
13/1 ?
?
?
0/0???
24/5 ?
??
1/0???
49/4 ??
?
1/0??
112/3 ?
?
14/0????
48/1 ??
??
1/0Table 5: Some inconsistent cases in PKU corpusTraining & Answer fT/fA Golden Standard fT/fA??
?
12/7 ???
0/0???
16/6 ?
??
0/0o ??
29/5 o??
0/0??
????
6/3 ????
??
0/0??
?
3/3 ?
??
0/0????
1/2 ??
??
0/0?????
4/2 ??
??
0/0?
?
10/2 ??
0/0??
3/2 ?
?
0/0????
?
?
7/1 ??????
0/0???
2/1 ??
?
0/0???
?
1/1 ?
?
??
0/0??a?a??
4/1 ??
a ?
a ?
0/0?????
1/1 ???
??
0/0?????
?
1/1 ??
????
0/0???
????
1/1 ?????
??
0/0?
???
10/1 ??
?
0/0???
16/1 ?
?
0/0???
4/1 ?
?
0/0????
16/1 ?
?
?
0/0????
122/1 ??
??
0/0????
??
3/1 ??
????
0/0Table 6: Some inconsistent cases in MSR corpusReferencesE.
Brill.
1993.
A Corpus-Based Approach to Lan-guage Learning.
PhD thesis, University of Pennsyl-vania, Philadelphia.J.
Gao, A. Wu, M. Li, C. Huang, H. Li, X. Xia and H.Qin.
2004.
Adaptive Chinese word segmentation.In ACL-04.
Barcelona, July 21-26.C.
Kit and Y. Wilks.
1999.
Unsupervised learning ofword boundary with description length gain.
In M.Osborne and E. T. K. Sang (eds.
), CoNLL-99, pp.1-6.
Bergen, Norway, June 12.C.
Kit 2000.
Unsupervised Lexical Learning asInductive Inference.
PhD thesis, University ofSheffield.C.
Kit, H. Pan and H. Chen.
2002.
Learning case-based knowledge for disambiguating Chinese wordsegmentation: A preliminary study.
SIGHAN-1,pp.33?39.
Taipei, Sept. 1, 2002.C.
Kit, Z. Xu and J. J. Webster.
2003.
Integratingn-gram model and case-based learning for Chineseword segmentation.
In Q. Ma and F. Xia (eds.
),SIGHAN-2, pp.160-163.
Sapporo, 11 July, 2003.D.
Palmer.
A trainable rule-based algorithm for wordsegmentation.
In ACL-97, pp.321-328.
Madrid.149
