Proceedings of NAACL HLT 2007, pages 236?243,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsJoint Determination of Anaphoricity and Coreference Resolution usingInteger ProgrammingPascal Denis and Jason BaldridgeDepartment of LinguisticsUniversity of Texas at Austin{denis,jbaldrid}@mail.utexas.eduAbstractStandard pairwise coreference resolutionsystems are subject to errors resultingfrom their performing anaphora identifi-cation as an implicit part of coreferenceresolution.
In this paper, we proposean integer linear programming (ILP) for-mulation for coreference resolution whichmodels anaphoricity and coreference as ajoint task, such that each local model in-forms the other for the final assignments.This joint ILP formulation provides f -score improvements of 3.7-5.3% over abase coreference classifier on the ACEdatasets.1 IntroductionThe task of coreference resolution involves impos-ing a partition on a set of entity mentions in a docu-ment, where each partition corresponds to some en-tity in an underlying discourse model.
Most worktreats coreference resolution as a binary classifica-tion task in which each decision is made in a pair-wise fashion, independently of the others (McCarthyand Lehnert, 1995; Soon et al, 2001; Ng and Cardie,2002b; Morton, 2000; Kehler et al, 2004).There are two major drawbacks with most sys-tems that make pairwise coreference decisions.
Thefirst is that identification of anaphora is done implic-itly as part of the coreference resolution.
Two com-mon types of errors with these systems are caseswhere: (i) the system mistakenly identifies an an-tecedent for non-anaphoric mentions, and (ii) thesystem does not try to resolve an actual anaphoricmention.
To reduce such errors, Ng and Cardie(2002a) and Ng (2004) use an anaphoricity classi-fier ?which has the sole task of saying whether ornot any antecedents should be identified for eachmention?
as a filter for their coreference system.They achieve higher performance by doing so; how-ever, their setup uses the two classifiers in a cascade.This requires careful determination of an anaphoric-ity threshold in order to not remove too many men-tions from consideration (Ng, 2004).
This sensi-tivity is unsurprising, given that the tasks are co-dependent.The second problem is that most coreference sys-tems make each decision independently of previousones in a greedy fashion (McCallum and Wellner,2004).
Clearly, the determination of membership ofa particular mention into a partition should be condi-tioned on how well it matches the entity as a whole.Since independence between decisions is an unwar-ranted assumption for the task, models that considera more global context are likely to be more appropri-ate.
Recent work has examined such models; Luo etal.
(2004) using Bell trees, and McCallum and Well-ner (2004) using conditional random fields, and Ng(2005) using rerankers.In this paper, we propose to recast the task ofcoreference resolution as an optimization problem,namely an integer linear programming (ILP) prob-lem.
This framework has several properties thatmake it highly suitable for addressing the two afore-mentioned problems.
The first is that it can uti-lize existing classifiers; ILP performs global infer-ence based on their output rather than formulating a236new inference procedure for solving the basic task.Second, the ILP approach supports inference overmultiple classifiers, without having to fiddle withspecial parameterization.
Third, it is much moreefficient than conditional random fields, especiallywhen long-distance features are utilized (Roth andYih, 2005).
Finally, it is straightforward to createcategorical global constraints with ILP; this is donein a declarative manner using inequalities on the as-signments to indicator variables.This paper focuses on the first problem, andproposes to model anaphoricity determination andcoreference resolution as a joint task, wherein thedecisions made by each locally trained model aremutually constrained.
The presentation of the ILPmodel proceeds in two steps.
In the first, interme-diary step, we simply use ILP to find a global as-signment based on decisions made by the corefer-ence classifier alone.
The resulting assignment isone that maximally agrees with the decisions of theclassifier, that is, where all and only the links pre-dicted to be coreferential are used for constructingthe chains.
This is in contrast with the usual clus-tering algorithms, in which a unique antecedent istypically picked for each anaphor (e.g., the mostprobable or the most recent).
The second step pro-vides the joint formulation: the coreference classi-fier is now combined with an anaphoricity classifierand constraints are added to ensure that the ultimatecoreference and anaphoricity decisions are mutuallyconsistent.
Both of these formulations achieve sig-nificant performance gains over the base classifier.Specifically, the joint model achieves f -score im-provements of 3.7-5.3% on three datasets.We begin by presenting the basic coreferenceclassifier and anaphoricity classifier and their per-formance, including an upperbound that shows thelimitation of using them in a cascade.
We then givethe details of our ILP formulations and evaluate theirperformance with respect to each other and the baseclassifier.2 Base models: coreference classifierThe classification approach tackles coreferencein two steps by: (i) estimating the probability,PC(COREF|?i, j?
), of having a coreferential out-come given a pair of mentions ?i, j?, and (ii) apply-ing a selection algorithm that will single out a uniquecandidate out of the subset of candidates i for whichthe probability PC(COREF|?i, j?)
reaches a particu-lar value (typically .5).We use a maximum entropy model for the coref-erence classifier.
Such models are well-suited forcoreference, because they are able to handle manydifferent, potentially overlapping learning featureswithout making independence assumptions.
Previ-ous work on coreference using maximum entropyincludes (Kehler, 1997; Morton, 1999; Morton,2000).
The model is defined in a standard fashionas follows:PC(COREF|?i, j?)
=exp(n?k=1?kfk(?i, j?, COREF))Z(?i, j?
)(1)Z(?i, j?)
is a normalization factor over both out-comes (COREF and ?COREF).
Model parametersare estimated using maximum entropy (Berger et al,1996).
Specifically, we estimate parameters withthe limited memory variable metric algorithm imple-mented in the Toolkit for Advanced DiscriminativeModeling1 (Malouf, 2002).
We use a Gaussian priorwith a variance of 1000 ?
no attempt was made tooptimize this value.Training instances for the coreference classifierare constructed based on pairs of mentions of theform ?i, j?, where j and i are the descriptions foran anaphor and one of its candidate antecedents, re-spectively.
Each such pair is assigned either a labelCOREF (i.e.
a positive instance) or a label ?COREF(i.e.
a negative instance) depending on whether ornot the two mentions corefer.
In generating the train-ing data, we followed the method of (Soon et al,2001) creating for each anaphor: (i) a positive in-stance for the pair ?i, j?
where i is the closest an-tecedent for j, and (ii) a negative instance for eachpair ?i, k?
where k intervenes between i and j.Once trained, the classifier is used to create a setof coreferential links for each test document; theselinks in turn define a partition over the entire set ofmentions.
In the system of Soon et.
al.
(2001) sys-tem, this is done by pairing each mention j with eachpreceding mention i.
Each test instance ?i, j?
thus1Available from tadm.sf.net.237formed is then evaluated by the classifier, which re-turns a probability representing the likelihood thatthese two mentions are coreferential.
Soon et.
al.
(2001) use ?Closest-First?
selection: that is, the pro-cess terminates as soon as an antecedent (i.e., a testinstance with probability > .5) is found or the be-ginning of the text is reached.
Another option is topick the antecedent with the best overall probability(Ng and Cardie, 2002b).Our features for the coreference classifier fall intothree main categories: (i) features of the anaphor, (ii)features of antecedent mention, and (iii) relationalfeatures (i.e., features that describe properties whichhold between the two mentions, e.g.
distance).
Thisfeature set is similar (though not equivalent) to thatused by Ng and Cardie (2002a).
We omit detailshere for the sake of brevity ?
the ILP systems weemploy here could be equally well applied to manydifferent base classifiers using many different fea-ture sets.3 Base models: anaphoricity classifierAs mentioned in the introduction, coreference clas-sifiers such as that presented in section 2 suf-fer from errors in which (a) they assign an an-tecedent to a non-anaphor mention or (b) they as-sign no antecedents to an anaphoric mention.
Ngand Cardie (2002a) suggest overcoming such fail-ings by augmenting their coreference classifier withan anaphoricity classifier which acts as a filter dur-ing model usage.
Only the mentions that are deemedanaphoric are considered for coreference resolu-tion.
Interestingly, they find a degredation in per-formance.
In particular, they obtain significant im-provements in precision, but with larger losses inrecall (especially for proper names and commonnouns).
To counteract this, they add ad hoc con-straints based on string matching and extended men-tion matching which force certain mentions to beresolved as anaphors regardless of the anaphoric-ity classifier.
This allows them to improve overallf -scores by 1-3%.
Ng (2004) obtains f -score im-provements of 2.8-4.5% by tuning the anaphoricitythreshold on held-out data.The task for the anaphoricity determination com-ponent is the following: one wants to decide for eachmention i in a document whether i is anaphoric ornot.
That is, this task can be performed using a sim-ple binary classifier with two outcomes: ANAPH and?ANAPH.
The classifier estimates the conditionalprobabilities P (ANAPH|i) and predicts ANAPH for iwhen P (ANAPH|i) > .5.We use the following model for our anaphoricityclassifier:PA(ANAPH|i) =exp(n?k=1?kfk(i, ANAPH))Z(i)(2)This model is trained in the same manner as thecoreference classifier, also with a Gaussian priorwith a variance of 1000.The features used for the anaphoricity classifierare quite simple.
They include information regard-ing (1) the mention itself, such as the number ofwords and whether it is a pronoun, and (2) propertiesof the potential antecedent set, such as the number ofpreceding mentions and whether there is a previousmention with a matching string.4 Base model resultsThis section provides the performance of the pair-wise coreference classifier, both when used alone(COREF-PAIRWISE) and when used in a cascadewhere the anaphoricity classifier acts as a filter onwhich mentions should be resolved (AC-CASCADE).In both systems, antecedents are determined in themanner described in section 2.To demonstrate the inherent limitations of cas-cading, we also give results for an oracle sys-tem, ORACLE-LINK, which assumes perfect linkage.That is, it always picks the correct antecedent foran anaphor.
Its only errors are due to being un-able to resolve mentions which were marked as non-anaphoric (by the imperfect anaphoricity classifier)when in fact they were anaphoric.We evaluate these systems on the datasets fromthe ACE corpus (Phase 2).
This corpus is di-vided into three parts, each corresponding to a dif-ferent genre: newspaper texts (NPAPER), newswiretexts (NWIRE), and broadcasted news transcripts(BNEWS).
Each of these is split into a trainpart and a devtest part.
Progress during the de-velopment phase was determined by using cross-validation on only the training set for the NPAPER238System BNEWS NPAPER NWIRER P F R P F R P FCOREF-PAIRWISE 54.4 77.4 63.9 58.1 80.7 67.6 53.8 78.2 63.8AC-CASCADE 51.1 79.7 62.3 53.7 79.0 63.9 53.0 81.8 64.3ORACLE-LINK 69.4 100 82.0 71.2 100 83.1 66.7 100 80.0Table 1: Recall (R), precision (P), and f -score (F) on the three ACE datasets for the basic coreference system(COREF-PAIRWISE), the anaphoricity-coreference cascade system (AC-CASCADE), and the oracle whichperforms perfect linkage (ORACLE-LINK).
The first two systems make strictly local pairwise coreferencedecisions.section.
No human-annotated linguistic informationis used in the input.
The corpus text was prepro-cessed with the OpenNLP Toolkit2 (i.e., a sentencedetector, a tokenizer, a POS tagger, and a NamedEntity Recognizer).In our experiments, we consider only the trueACE mentions.
This is because our focus is on eval-uating pairwise local approaches versus the globalILP approach rather than on building a full coref-erence resolution system.
It is worth noting thatprevious work tends to be vague in both these re-spects: details on mention filtering or providingperformance figures for markable identification arerarely given.Following common practice, results are given interms of recall and precision according to the stan-dard model-theoretic metric (Vilain et al, 1995).This method operates by comparing the equivalenceclasses defined by the resolutions produced by thesystem with the gold standard classes: these are thetwo ?models?.
Roughly, the scores are obtained bydetermining the minimal perturbations brought toone model in order to map it onto the other model.Recall is computed by trying to map the predictedchains onto the true chains, while precision is com-puted the other way around.
We test significant dif-ferences with paired t-tests (p < .05).The anaphoricity classifier has an average accu-racy of 80.2% on the three ACE datasets (using athreshold of .5).
This score is slightly lower thanthe scores reported by Ng and Cardie (2002a) foranother data set (MUC).Table 1 summarizes the results, in terms of recall(R), precision (P), and f -score (F) on the three ACEdata sets.
As can be seen, the AC-CASCADE system2Available from opennlp.sf.net.generally provides slightly better precision at the ex-pense of recall than the COREF-PAIRWISE system,but the performance varies across the three datasets.The source of this variance is likely due to the factthat we applied a uniform anaphoricity thresholdof .5 across all datasets; Ng (2004) optimizes thisthreshold for each of the datasets: .3 for BNEWSand NWIRE and .35 for NPAPER.
This variance re-inforces our argument for determining anaphoricityand coreference jointly.The limitations of the cascade approach are alsoshown by the oracle results.
Even if we had a sys-tem that can pick the correct antecedents for all trulyanaphoric mentions, it would have a maximum re-call of roughly 70% for the different datasets.5 Integer programming formulationsThe results in the previous section demonstrate thelimitations of a cascading approach for determin-ing anaphoricity and coreference with separate mod-els.
The other thing to note is that the results ingeneral provide a lot of room for improvement ?this is true for other state-of-the-art systems as well.The integer programming formulation we providehere has qualities which address both of these is-sues.
In particular, we define two objective func-tions for coreference resolution to be optimized withILP.
The first uses only information from the coref-erence classifier (COREF-ILP) and the second inte-grates both anaphoricity and coreference in a jointformulation (JOINT-ILP).
Our problem formulationand use of ILP are based on both (Roth and Yih,2004) and (Barzilay and Lapata, 2006).For solving the ILP problem, we use lp solve,an open-source linear programming solver whichimplements the simplex and the Branch-and-Bound239methods.3 In practice, each test document is pro-cessed to define a distinct ILP problem that is thensubmitted to the solver.5.1 COREF-ILP: coreference-only formulationBarzilay and Lapata (2006) use ILP for the problemof aggregation in natural language generation: clus-tering sets of propositions together to create moreconcise texts.
They cast it as a set partitioning prob-lem.
This is very much like coreference, whereeach partition corresponds to an entity in a discoursemodel.COREF-ILP uses an objective function that isbased on only the coreference classifier and theprobabilities it produces.
Given that the classifierproduces probabilities pC = PC(COREF|i, j), theassignment cost of commiting to a coreference linkis cC?i,j?
= ?log(pC).
A complement assignmentcost cC?i,j?
= ?log(1?pC) is associated with choos-ing not to establish a link.
In what follows, M de-notes the set of mentions in the document, and P theset of possible coreference links over these mentions(i.e., P = {?i, j?|?i, j?
?
M ?
M and i < j}).
Fi-nally, we use indicator variables x?i,j?
that are set to1 if mentions i and j are coreferent, and 0 otherwise.The objective function takes the following form:min??i,j??PcC?i,j?
?
x?i,j?
+ cC?i,j?
?
(1?
x?i,j?)
(3)subject to:x?i,j?
?
{0, 1} ?
?i, j?
?
P (4)This is essentially identical to Barzilay and Lapata?sobjective function, except that we consider onlypairs in which the i precedes the j (due to the struc-ture of the problem).
Also, we minimize rather thanmaximize due to the fact we transform the modelprobabilities with ?log (like Roth and Yih (2004)).This preliminary objective function merely guar-antees that ILP will find a global assignment thatmaximally agrees with the decisions made by thecoreference classifier.
Concretely, this amounts totaking all (and only) those links for which the classi-fier returns a probability above .5.
This formulationdoes not yet take advantage of information from aclassifier that specializes in anaphoricity; this is thesubject of the next section.3Available from http://lpsolve.sourceforge.net/.5.2 JOINT-ILP: joint anaphoricity-coreferenceformulationRoth and Yih (2004) use ILP to deal with the jointinference problem of named entity and relation iden-tification.
This requires labeling a set of named enti-ties in a text with labels such as person and loca-tion, and identifying relations between them suchas spouse of and work for.
In theory, each of thesetasks would likely benefit from utilizing the infor-mation produced by the other, but if done as a cas-cade will be subject to propogation of errors.
Rothand Yih thus set this up as problem in which eachtask is performed separately; their output is used toassign costs associated with indicator variables in anobjective function, which is then minimized subjectto constraints that relate the two kinds of outputs.These constraints express qualities of what a globalassignment of values for these tasks must respect,such as the fact that the arguments to the spouse ofrelation must be entities with person labels.
Impor-tantly, the ILP objective function encodes not onlythe best label produced by each classifier for eachdecision; it utilizes the probabilities (or scores) as-signed to each label and attempts to find a globaloptimum (subject to the constraints).The parallels to our anaphoricity/coreference sce-nario are straightforward.
The anaphoricity problemis like the problem of identifying the type of entity(where the labels are now ANAPH and ?ANAPH),and the coreference problem is like that of determin-ing the relations between mentions (where the labelsare now COREF or ?COREF).Based on these parallels, the JOINT-ILP systembrings the two decisions of anaphoricity and corefer-ence together by including both in a single objectivefunction and including constraints that ensure theconsistency of a solution for both tasks.
Let cAj andcAj be defined analogously to the coreference clas-sifier costs for pA = PA(ANAPH|j), the probabilitythe anaphoricity classifier assigns to a mention j be-ing anaphoric.
Also, we have indicator variables yjthat are set to 1 if mention j is anaphoric and 0 oth-erwise.
The objective function takes the following240form:min??i,j??PcC?i,j?
?
x?i,j?
+ cC?i,j?
?
(1?x?i,j?
)+?j?McAj ?
yj + cAj ?
(1?yj) (5)subject to:x?i,j?
?
{0, 1} ?
?i, j?
?
P (6)yj ?
{0, 1} ?j ?
M (7)The structure of this objective function is very sim-ilar to Roth and Yih?s, except that we do not uti-lize constraint costs in the objective function itself.Roth and Yih use these to make certain combina-tions impossible (like a location being an argumentto a spouse of relation); we enforce such effects inthe constraint equations instead.The joint objective function (5) does not constrainthe assignment of the x?i,j?
and yj variables to beconsistent with one another.
To enforce consistency,we add further constraints.
In what follows, Mj isthe set of all mentions preceding mention j in thedocument.Resolve only anaphors: if a pair of mentions ?i, j?is coreferent (x?i,j?=1), then mention j must beanaphoric (yj=1).x?i,j?
?
yj ?
?i, j?
?
P (8)Resolve anaphors: if a mention is anaphoric(yj=1), it must be coreferent with at least one an-tecedent.yj ??i?Mjx?i,j?
?j ?
M (9)Do not resolve non-anaphors: if a mention is non-anaphoric (yj=0), it should have no antecedents.yj ?1|Mj |?i?Mjx?i,j?
?j ?
M (10)These constraints thus directly relate the twotasks.
By formulating the problem this way, the de-cisions of the anaphoricity classifier are not takenon faith as they were with AC-CASCADE.
Instead,we optimize over consideration of both possibilitiesin the objective function (relative to the probabilityoutput by the classifier) while ensuring that the finalassignments respect the signifance of what it is to beanaphoric or non-anaphoric.6 Joint ResultsTable 2 summarizes the results for these differentsystems.
Both ILP systems are significantly betterthan the baseline system COREF-PAIRWISE.
Despitehaving lower precision than COREF-PAIRWISE, theCOREF-ILP system obtains very large gains in recallto end up with overall f -score gains of 4.3%, 4.2%,and 3.0% across BNEWS, NPAPER, and NWIRE, re-spectively.
The fundamental reason for the increasein recall and drop in precision is that COREF-ILP canposit multiple antecedents for each mention.
Thisis an extra degree of freedom that allows COREF-ILP to cast a wider net, with a consequent risk ofcapturing incorrect antecedents.
Precision is notcompletely degraded because the optimization per-formed by ILP utilizes the pairwise probabilities ofmention pairs as weights in the objective functionto make its assignments.
Thus, highly improbablelinks are still heavily penalized and are not chosenas coreferential.The JOINT-ILP system demonstrates the benefitILP?s ability to support joint task formulations.
Itproduces significantly better f -scores by regainingsome of the ground on precision lost by COREF-ILP.
The most likely source of the improved pre-cision of JOINT-ILP is that weights correspondingto the anaphoricity probabilities and constraints (8)and (10) reduce the number of occurrences of non-anaphors being assigned antecedents.
There are alsoimprovements in recall over COREF-ILP for NPAPERand NWIRE.
A possible source of this difference isconstraint (9), which ensures that mentions whichare considered anaphoric must have at least one an-tecedent.Compared to COREF-PAIRWISE, JOINT-ILP dra-matically improves recall with relatively smalllosses in precision, providing overall f -score gainsof 5.3%, 4.9%, and 3.7% on the three datasets.7 Related WorkAs was just demonstrated, ILP provides a principledway to model dependencies between anaphoricitydecisions and coreference decisions.
In a simi-lar manner, this framework could also be used tocapture dependencies among coreference decisionsthemselves.
This option ?which we will leave forfuture work?
would make such an approach akin to241System BNEWS NPAPER NWIRER P F R P F R P FCOREF-PAIRWISE 54.4 77.4 63.9 58.1 80.7 67.6 53.8 78.2 63.8COREF-ILP 62.2 75.5 68.2 67.1 77.3 71.8 60.1 74.8 66.8JOINT-ILP 62.1 78.0 69.2 68.0 77.6 72.5 60.8 75.8 67.5Table 2: Recall (R), precision (P), and f -score (F) on the three ACE datasets for the basic coreference system(COREF-PAIRWISE), the coreference only ILP system (COREF-ILP), and the joint anaphoricity-coreferenceILP system (JOINT-ILP).
All f -score differences are significant (p < .05).a number of recent global approaches.Luo et al (2004) use Bell trees to represent thesearch space of the coreference resolution problem(where each leaf is possible partition).
The prob-lem is thus recast as that of finding the ?best?
paththrough the tree.
Given the rapidly growing size ofBell trees, Luo et al resort to a beam search al-gorithm and various pruning strategies, potentiallyresulting in picking a non-optimal solution.
The re-sults provided by Luo et al are difficult to comparewith ours, since they use a different evaluation met-ric.Another global approach to coreference is theapplication of Conditional Random Fields (CRFs)(McCallum and Wellner, 2004).
Although both areglobal approaches, CRFs and ILP have importantdifferences.
ILP uses separate local classifiers whichare learned without knowledge of the output con-straints and are then integrated into a larger infer-ence task.
CRFs estimate a global model that di-rectly uses the constraints of the domain.
This in-volves heavy computations which cause CRFs togenerally be slow and inefficient (even using dy-namic programming).
Again, the results presentedin McCallum and Wellner (2004) are hard to com-pare with our own results.
They only considerproper names, and they only tackled the task ofidentifying the correct antecedent only for mentionswhich have a true antecedent.A third global approach is offered by Ng (2005),who proposes a global reranking over partitions gen-erated by different coreference systems.
This ap-proach proceeds by first generating 54 candidatepartitions, which are each generated by a differ-ent system.
These different coreference systemsare obtained as combinations over three differentlearners (C4.5, Ripper, and Maxent), three sam-pling methods, two feature sets (Soon et al, 2001;Ng and Cardie, 2002b), and three clustering al-gorithms (Best-First, Closest-First, and aggressive-merge).
The features used by the reranker are oftwo types: (i) partition-based features which arehere simple functions of the local features, and (ii)method-based features which simply identify thecoreference system used for generating the givenpartition.
Although this approach leads to significantgains on the both the MUC and the ACE datasets,it has some weaknesses.
Most importantly, the dif-ferent systems employed for generating the differentpartitions are all instances of the local classificationapproach, and they all use very similar features.
Thisrenders them likely to make the same types of errors.The ILP approach could in fact be integrated withthese other approaches, potentially realizing the ad-vantages of multiple global systems, with ILP con-ducting their interactions.8 ConclusionsWe have provided two ILP formulations for resolv-ing coreference and demonstrated their superiorityto a pairwise classifier that makes its coreference as-signments greedily.In particular, we have also shown that ILP pro-vides a natural means to express the use of bothanaphoricity classification and coreference classifi-cation in a single system, and that doing so provideseven further performance improvements, specifi-cally f -score improvements of 5.3%, 4.9%, and3.7% over the base coreference classifier on the ACEdatasets.With ILP, it is not necessary to carefully controlthe anaphoricity threshold.
This is in stark contrastto systems which use the anaphoricity classifier as afilter for the coreference classifier in a cascade setup.242The ILP objective function incorporates the proba-bilities produced by both classifiers as weights onvariables that indicate the ILP assignments for thosetasks.
The indicator variables associated with thoseassignments allow several constraints between thetasks to be straightforwardly stated to ensure consis-tency to the assignments.
We thus achieve large im-provements with a simple formulation and no fuss.ILP solutions are also obtained very quickly for theobjective functions and constraints we use.In future work, we will explore the use of globalconstraints, similar to those used by (Barzilay andLapata, 2006) to improve both precision and recall.For example, we expect transitivity constraints overcoreference pairs, as well as constraints on the en-tire partition (e.g., the number of entities in the doc-ument), to help considerably.
We will also considerlinguistic constraints (e.g., restrictions on pronouns)in order to improve precision.AcknowledgmentsWe would like to thank Ray Mooney, Rohit Kate,and the three anonymous reviewers for their com-ments.
This work was supported by NSF grant IIS-0535154.ReferencesRegina Barzilay and Mirella Lapata.
2006.
Aggregationvia set partitioning for natural language generation.
InProceedings of the HLT/NAACL, pages 359?366, NewYork, NY.A.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.A.
Kehler, D. Appelt, L. Taylor, and A. Simma.2004.
The (non)utility of predicate-argument frequen-cies for pronoun interpretation.
In Proceedings ofHLT/NAACL, pages 289?296.Andrew Kehler.
1997.
Probabilistic coreference in infor-mation extraction.
In Proceedings of EMNLP, pages163?173.Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, NandaKambhatla, , and Salim Roukos.
2004.
A mention-synchronous coreference resolution algorithm basedon the Bell tree.
In Proceedings of the ACL.Robert Malouf.
2002.
A comparison of algorithmsfor maximum entropy parameter estimation.
In Pro-ceedings of the Sixth Workshop on Natural LanguageLearning, pages 49?55, Taipei, Taiwan.Andrew McCallum and Ben Wellner.
2004.
Conditionalmodels of identity uncertainty with application to nouncoreference.
In Proceedings of NIPS.Joseph F. McCarthy and Wendy G. Lehnert.
1995.
Usingdecision trees for coreference resolution.
In Proceed-ings of IJCAI, pages 1050?1055.Thomas Morton.
1999.
Using coreference for ques-tion answering.
In Proceedings of ACL Workshop onCoreference and Its Applications.Thomas Morton.
2000.
Coreference for NLP applica-tions.
In Proceedings of ACL, Hong Kong.Vincent Ng and Claire Cardie.
2002a.
Identifyinganaphoric and non-anaphoric noun phrases to improvecoreference resolution.
In Proceedings of COLING.Vincent Ng and Claire Cardie.
2002b.
Improving ma-chine learning approaches to coreference resolution.In Proceedings of ACL, pages 104?111.Vincent Ng.
2004.
Learning noun phrase anaphoricity toimprove coreference resolution: Issues in representa-tion and optimization.
In Proceedings of ACL.Vincent Ng.
2005.
Machine learning for coreference res-olution: From local classification to global ranking.
InProceedings of ACL.Dan Roth and Wen-tau Yih.
2004.
A linear programmingformulation for global inference in natural languagetasks.
In Proceedings of CoNLL.Dan Roth and Wen-tau Yih.
2005.
Integer linear pro-gramming inference for conditional random fields.
InProceedings of ICML, pages 737?744.W.
Soon, H. Ng, and D. Lim.
2001.
A machine learningapproach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Marc Vilain, John Burger, John Aberdeen, Dennis Con-nolly, and Lynette Hirschman.
1995.
A model-theoretic coreference scoring scheme.
In Proceedingsfo the 6th Message Understanding Conference (MUC-6), pages 45?52, San Mateo, CA.
Morgan Kaufmann.243
