Proceedings of the TextGraphs-8 Workshop, pages 79?87,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsA Graph-Based Approach to Skill Extraction from Text?Ilkka Kivima?ki1, Alexander Panchenko4,2, Adrien Dessy1,2, Dries Verdegem3,Pascal Francq1, Ce?drick Fairon2, Hugues Bersini3 and Marco Saerens11ICTEAM, 2CENTAL, Universite?
catholique de Louvain, Belgium3IRIDIA, Universite?
libre de Bruxelles, Belgium4 Digital Society Laboratory LLC, RussiaAbstractThis paper presents a system that performsskill extraction from text documents.
It out-puts a list of professional skills that are rele-vant to a given input text.
We argue that thesystem can be practical for hiring and man-agement of personnel in an organization.
Wemake use of the texts and the hyperlink graphof Wikipedia, as well as a list of professionalskills obtained from the LinkedIn social net-work.
The system is based on first computingsimilarities between an input document andthe texts of Wikipedia pages and then using abiased, hub-avoiding version of the SpreadingActivation algorithm on the Wikipedia graphin order to associate the input document withskills.1 IntroductionOne of the most difficult tasks of an employer canbe the recruitment of a new employee out of a longlist of applicants.
Another challenge of the employeris to keep track of the skills and know-how of theiremployees in order to direct the right people to workon things they know.
In the scientific community,editors of journals and committees of conferencesalways face the task of assigning suitable reviewersfor a tall pile of submitted papers.
The tasks de-scribed above are example problems of expertise re-trieval (Balog et al 2012).
It is a subfield of in-formation retrieval that focuses on inferring asso-ciations between people, expertise and informationcontent, such as text documents.
?Part of this work has been funded by projects with the?Re?gion wallonne?.
We thank this institution for giving us theopportunity to conduct both fundamental and applied research.In addition, we thank Laurent Genard and Ste?phane Dessy fortheir contributions for the work.In this paper, we propose a method that makes astep towards a solution of these problems.
We de-scribe an approach for the extraction of professionalskills associated with a text or its author.
The goal ofour system is to automatically extract a set of skillsfrom an input text, such as a set of articles writtenby a person.
Such technology can be potentiallyuseful in various contexts, such as the ones men-tioned above, along with expertise management in acompany, analysis of professional blogs, automaticmeta-data extraction, etc.For succeeding in our goal, we exploit Wikipedia,a list of skills obtained from the LinkedIn social net-work and the mapping between them.
Our methodconsists of two phases.
First, we analyze a querydocument with a vector space model or a topicmodel in order to associate it with Wikipedia arti-cles.
Then, using these initial pages, we use theSpreading Activation algorithm on the hyperlinkgraph of Wikipedia in order to find articles that cor-respond to LinkedIn skills and are related or centralto the initial pages.One difficulty with this approach is that it of-ten results in some skills, which can be identifiedas hubs of the Wikipedia graph, constantly beingretrieved, regardless of what the input is.
In or-der to avoid this pitfall, we bias the activation toavoid spreading to general, or popular nodes.
Wetry different measures of node popularity to redirectthe spreading and perform evaluative experimentswhich show that this biasing in fact improves re-trieval results.We have built a web service that enables anyoneto test our skill extraction system.
The name of thesystem is Elisit, an abbreviation from ?ExpertiseLocalization from Informal Sources and Information79Technologies?
and conveying the idea of trying toelicit, i.e.
draw forth latent information about exper-tise in a target text.
According to the best of ourknowledge, we are the first to propose such a systemand describe openly the method behind it.2 Related workThe recent review of Balog et al(2012) gives athorough presentation of the problems of expertiseretrieval and of the methodology used for solvingthem.
They classify these problems in subcategoriesof expert retrieval and expert profiling.
The formermeans the task of providing a name of a person whois an expert in a field that is presented as a query,while the latter means assigning expertise to a per-son, or some other entity based on information thatis available of that entity.
Recent expertise retrievalresearch has focused on the TREC enterprise track,which uses the TREC W3C and CERC corpora (Ba-log et al 2008).
These datasets contain annotatedcrawls of websites.
The task in the TREC enterprisechallenge is to build a model that performs expertretrieval and document retrieval based on a set ofquery topics, which correspond to expertise areas.Our approach is quite different from the one usedin the TREC challenge, as we focus on a fixedlist of skills gathered from the LinkedIn website.Thus, we were not able to directly compare our sys-tem to the systems participating in the TREC enter-prise track.
Our problem shares some resemblancewith the INEX entity-ranking track (Demartini et al2010), where the goal was to rank Wikipedia pagesrelated to queries about a given topic.
Our skill re-trieval task can also be seen as an entity ranking task,where the entities are Wikipedia pages that corre-spond to skills.LinkedIn has developed methods for definingskills and for finding relations between them (Sko-moroch et al 2012).
These techniques are used intheir service, for example, for recommending jobopportunities to the users.
The key difference ofour technology is that it allows a user to searchfor skills by submitting an arbitrary text, instead ofonly searching for skills related to a certain skill.Although expertise retrieval has been an active re-search topic for some time, there have not beenmany methods for explicitly assigning particularskills to text content or people producing text con-tent.Our method consists of two steps.
First, we ap-ply a text similarity method to detect the relevantWikipedia pages.
Second, we enrich the resultswith graph mining techniques using the hyperlinkgraph of Wikipedia.
We have not found a simi-lar combination being applied for skill extractionbefore, although both parts have been well studiedin similar contexts before.
For instance, Steyverset al(2004) proposed the Author-Topic Model, agraphical model based on LDA (Blei et al 2003),that associates authors of texts with topics detectedfrom those texts.Wikipedia has been already used in NLP researchboth as a corpus and as a semantic network.
Its hy-perlink graph is a collaboratively constructed net-work, as opposed to manually crafted networkssuch as WordNet (Miller, 1995).
Gabrilovich andMarkovitch (2007) introduced Explicit SemanticAnalysis (ESA), where the words of a document arerepresented as mixtures of concepts, i.e.
Wikipediapages, according to their occurence in the body textsof the pages.
The experimental results show that thisstrategy works very well and outranks, for exam-ple, LSA (Landauer and Dumais, 1997) in the taskof measuring document similarity.
ESA was laterextended by taking into account the graph structureprovided by the links in Wikipedia (Yeh et al 2009).The authors of this work used a PageRank-based al-gorithm on the graph for measuring word and doc-ument similarity.
This approach was coined Wiki-Walk.Associating the elements of a text document un-der analysis with Wikipedia pages involves itself al-ready many problems often encountered in NLP.
Theprocess where certain words and multiword expres-sions are associated with a certain Wikipedia pagehas been called Wikification (Mihalcea and Csomai,2007).
In our work, we take a more general ap-proach, and try to associate the full input text to aset of Wikipedia pages according to different vec-tor space models.
The models and the details of thisstrategy are explained in section 3.3.The Elisit system uses the Spreading Activa-tion algorithm on the Wikipedia graph to establishassociations between texts and skills.
We choseto use Spreading Activation, as it tries to simulate80a cognitive associative memory (Anderson, 1983),and the Wikipedia hyperlink network can be under-stood as an associative network.
The simulationworks by finding associations in a network of con-cepts by spreading pulses of activation from con-cepts into their neighbours.
In the context of NLP,the Spreading Activation algorithm has been tradi-tionally used for word sense disambiguation (Hirst,1988) and information retrieval (Crestani, 1997).Gouws et al(2010) have shown that this algorithm,applied to the Wikipedia graph, can also be used tomeasure conceptual and document similarity.3 MethodologyIn this section, we will explain how the Elisitskill extraction system works.
We will first ex-plain how the system uses data from Wikipedia andLinkedIn.
Then, we will describe the two maincomponents of the system, the text2wiki mod-ule, which associates a query document with relatedWikipedia pages, and the wiki2skill module,which aims to associate the Wikipedia pages foundby the text2wiki module with Wikipedia pagesthat correspond to skills.3.1 Wikipedia texts and linksEach page in Wikipedia contains a text that may in-clude hyperlinks to other pages.
We make the as-sumption that there is a meaningful semantic rela-tionship between the pages that are linked with eachother and that the Wikipedia hyperlink graph can beexploited as an associative network.
The propertiesof the hyperlink structure of Wikipedia and the na-ture of the information contained in the links havebeen investigated by Koolen (2011).In addition to the encyclopedia pages, Wikipediaalso contains, among others, category, discussionand help pages.
In our system, we are only interestedin the encyclopedia pages and the hyperlinks be-tween them.
We are using data downloaded1 on May2nd 2012.
This dump encompasses 3,983,338 pageswith 247,560,469 links, after removal of the redi-rect pages.
The Wikipedia graph consists of a giantStrongly Connected Component (SCC) of 3,744,419nodes, 4130 SCC?s of sizes from 61 to 2 nodes and228,881 nodes that form their own SCC?s.1http://dumps.wikimedia.org/3.2 LinkedIn skillsWe gathered a list of skills from the LinkedIn socialnetwork2.
The list includes skills which the userscan assign to their profiles.
This enables the siteto recommend new contacts or open job opportu-nities to each user.
The skills in the list have beengenerated by an automated process developed byLinkedIn (Skomoroch et al 2012).
The process de-cides, whether a word or a phrase or a skill suggestedby a user is actually a skill through an analysis of thetext contained in the user profile pages.Each LinkedIn skill has its own webpage that con-tains information about the skill.
One piece of infor-mation contained in most of these pages is a linkto a Wikipedia article.
According to Skomoroch etal.
(2012), LinkedIn automatically builds this map-ping.
However, some links are manually verifiedthrough crowdsourcing.
Not all skill pages containa link to Wikipedia, but these skills are often ei-ther very specific or ambiguous.
Thus, we decidedto remove these skills from our final list.
The listof skills used in the system was extracted from theLinkedIn site in September 2012.
After removal ofthe skills without a link to Wikipedia, the list con-tained 27,153 skills.3.3 text2wiki moduleThe goal of the text2wiki module is to retrieveWikipedia articles that are relevant to an input text.The output of the module is a vector of sim-ilarities between the input document and all arti-cles of the English Wikipedia that contain at least300 characters.
There are approximately 3.3 mil-lion such pages.
We only retrieve the 200 Wikipediapages that are most similar to the input document.Thus, each input text is represented as a sparse vec-tor a(0), which has 200 non-zero elements out of3,983,338 dimensions corresponding to the full listof Wikipedia pages.
Each non-zero value ai(0) ofthis vector is a semantic similarity of the query withthe i-th Wikipedia article.
This approach stems fromESA, mentioned above.
The vector a(0) is given asinput to the second module wiki2skill.The text2wiki module relies on the Gensimlibrary (R?ehu?r?ek and Sojka, 2010)3.
In particular,2http://www.linkedin.com/skills3http://radimrehurek.com/gensim81we have used four different text similarity func-tions, based respectively on the classical VectorSpace Models (VSM?s) (Berry et al 1994), LSAand LDA:(a) TF-IDF (300,000 dimensions)(b) LogEntropy (300,000 dimensions)(c) LogEntropy + LSA (200 dimensions)(d) LogEntropy + LDA (200 topics)First, each text is represented as a vector x ina space of the 300,000 most frequent terms in thecorpus, each appearing at least in 10% of the docu-ments (excluding stopwords).
We limited the num-ber of dimensions to 300,000 to reduce computa-tional complexity.
The models (a) and (b) directlyuse this representation, while for (c) and (d) this ini-tial representation is transformed to a vector x?
in areduced space of 200 dimensions/topics.
For LSAand LDA, the number of dimensions is often empir-ically selected from the range [100 ?
500] (Foltz,1996; Bast and Majumdar, 2005).
We followed thispractice.
From the vector representations (x or x?
),the similarity between the input document and eachWikipedia article is computed using the cosine sim-ilarity.Pairwise comparison of a vector of 300,000 di-mensions against 3.3 million vectors of the samesize has a prohibitive computational cost.
To makeour application practical, we use an inverted index ofGensim to efficiently retrieve articles semanticallyrelated to an input document.3.4 wiki2skill moduleThe wiki2skill module performs the Spread-ing Activation algorithm using the initial activationsprovided by the text2wiki module and returns avector of final activations of all the nodes of the net-work and a vector containing the activations of onlythe nodes corresponding to skills.The basic idea of Spreading Activation is to ini-tially activate a set of nodes in a network and theniteratively spread the activation into the neighbour-ing nodes.
This can actually be interpreted in manyways opening up a wide space of algorithms that canlead to different results.
One attempt for an exactdefinition of the Spreading Activation algorithm canbe found in the work of Shrager et al(1987).
Theirformulation states that if a(0) is a vector containingthe initial activations of each node of the network,then after each iteration, or time step, or pulse t, thevector of activations isa(t) = ?a(t?
1) + ?WTa(t?
1) + c(t), (1)where ?
?
[0, 1] is a decay factor which controls theconservation of activation during time, ?
?
[0, 1] isa friction factor, which controls the amount of acti-vation that nodes can spread to their neighbors, c(t)is an activation source vector and W is a weightedadjacency matrix, where the weights control theamount of activation that flows through each link inthe network.
In some cases, iterating eq.
(1) leadsto a converged activation state, but often, especiallywhen dealing with large networks, it is more prac-tical to set the number of pulses, T , to some fixed,low number.As already stated, this formulation of Spread-ing Activation spans a wide space of different al-gorithms.
In particular, this space contains manyrandom walk based algorithms.
By considering thecase where ?
= 0, ?
= 1, c(t) = 0 and wherethe matrix W is row-stochastic, the Spreading Ac-tivation model boils down to a random walk modelwith a transition probability matrix W, where a(t)contains the proportion of random walkers at eachnode when the initial proportions are given by a(0).When the situation is changed by choosing c(t) =(1 ?
?
)a(0), we obtain a bounded Random Walkwith Restart model (Pan et al 2004; Mantrach etal., 2011).Early experiments with the first versions of the al-gorithm revealed an activation bias towards nodesthat correspond to very general Wikipedia pages(e.g.
the page ?ISBN?, which is often linked to inthe References section of Wikipedia pages).
Thesenodes have a high input degree, but are often not rel-evant for the given query.
This problem is often en-countered when analysing large graphs with randomwalk based measures.
It is known that they can bedominated by the stationary distribution of the cor-responding Markov Chain (Brand, 2005).To tackle this problem, we assign link weightsaccording to preferential transition probabilities,which define biased random walks that try to avoidhub nodes.
They have been studied e.g.
in the con-text of stochastic routing of packages in scale-free82networks (Fronczak and Fronczak, 2009).
Theseweights are given byw?ij =pi?j?k:(i,k)?Epi?k, (2)where pij is a popularity index and ?
is a biasingparameter, which controls the amount of activationthat flows from node i to node j based on the pop-ularity of node j.
For the popularity index, we con-sidered three options.
First, we tried simply the in-put degree of a node.
As a second option, we usedthe PageRank score of the node (Page et al 1999)which corresponds to the node?s weight in the sta-tionary distribution of a random surfer that surfsWikipedia by clicking on hyperlinks randomly.
As athird popularity index, we used a score based on theHITS algorithm (Kleinberg, 1999), which is simi-lar to PageRank, but instead assigns two scores, anauthority score and a hub score.
In short, a pagehas a high authority score, if it is linked to by manyhub pages, and vice versa.
In the case of HITS, thepopularity index was defined as the product of theauthority and hub scores of the node.
When ?
= 0,wij is equal for all links leaving from node i, butwhen ?
< 0, activation will flow more to less popu-lar nodes and less to popular nodes.
We included theselection of a suitable value for ?
as a parameter tobe tuned along with the rest of the spreading strat-egy in quantitative experiments that are presented insection 5.2.
These experiments show that biasingthe activation to avoid spreading to popular nodesindeed improves retrieval results.We also decided to investigate whether givingmore weight to links that exist in both directionswould improve results.
The Wikipedia hyperlinkgraph is directed, but in some cases two pages maycontain a link to each other.
We thus adjust the linkweights wij so that wij = ?w?ij if (j, i) ?
E andwij = w?ij otherwise, where ?
?
1 is a bidirectionallink weight.
With large values of ?, more activationwill flow through bidirectional links than links thatexist only in one direction.
After this weighting,the final link weight matrix W is obtained by nor-malizing each element with its corresponding rowsum to make the matrix row-stochastic.
This makesthe model easier to interpret by considering randomwalks.
However, in a traditional Spreading Activa-tion model the matrix W is not required to be row-stochastic.
We plan to investigate in the future, howmuch the normalization affects the results.The large size of the Wikipedia graph challengesthe use of Spreading Activation.
In order to pro-vide a usable web service, we would need the systemto provide results fast, preferably within fractions ofseconds.
So far, we have dealt with this issue withinthe wiki2skill module by respresenting the linkweight matrix W of the whole Wikipedia graph us-ing the sparse matrix library SciPy4.
Each itera-tion of the Spreading Activation is then achieved bysimple matrix arithmetic according to eq.
(1).
Asa result, the matrix W must be precomputed fromthe adjacency matrix for a given value of the bias-ing parameter ?
and the bidirectional link weight ?when the system is launched.
Thus, they cannot beselected separately for each query from the system.Currently, the system can perform one iteration ofspreading activation within less than one second, de-pending on the sparsity of the activation vector.
Ourexperiments indicate that the results are quite stableafter five spreading iterations, meaning that we nor-mally get results with the wiki2skill module inabout one to three seconds.4 The Elisit skill extraction systemThe Elisit system integrates the text2wikiand the wiki2skill modules.
We have built aweb application5 which lets everyone try our methodand use it from third-party applications.
Due to thisweb service, the Elisit technology can be eas-ily integrated into systems performing skill search,email or document analysis, HR automatization,analysis of professional blogs, automatic meta-dataextraction, etc.
The web interface presents the userthe result of the skill extraction (a list of skills) aswell as the result of the text2wiki module (a listof Wikipedia pages).
Each retrieved skill also con-tains a link to the corresponding Wikipedia page.Figure 1 presents an example of results providedby the Elisit system.
It lists skills extractedfrom the abstract of the chapter Support vector ma-chines and machine learning on documents from4http://www.scipy.org/5GUI: http://elisit.cental.be/; RESTful webservice: http://elisit.cental.be:8080/.83Figure 1: Skills extracted from a text about text documentcategorization.Introduction to Information Retrieval by Manninget al(2008).
As one can observe, the Wikipediapages found by the text2wiki module representmany low-level topics, such as ?Desicion bound-ary?, ?Ranking SVM?
or ?Least square SVM?.
Onthe other hand, the skills retrieved after using thewiki2skill module provide high-level topics rel-evant to the input text, such as ?SVM?, ?MachineLearning?
or ?Classification?.
These general topicsare more useful, since a user, such as an HR man-ager, may be confused by too low-level skills.5 Experiments & results5.1 Evaluation of the text2wiki moduleIn order to compare the four text similarity func-tions, we collected p = 200, 000 pairs of semanti-cally related documents from the ?See also?
sectionsof Wikipedia articles.
A good model is supposedto assign a high similarity to these pairs.
However,since the distribution of similarity scores dependson the model, one cannot simply compare the meansimilarity s?
over the set of pairs.
Thus, we used aModel z-scoreTF-IDF 8459LogEntropy 4370LogEntropy + LDA 2317LogEntropy + LSA 2143Table 1: Comparison of different text similarity functionson the Wikipedia ?See also?
dataset.z-score as evaluation metric.
The z-scores are com-puted asz =s??
????
?2/p(3)where ??
and ??
are sample estimates of mean andstandard deviation of similarity scores for a givenmodel.
These sample estimates have been calculatedfrom a set of 1,000,000 randomly selected pairs ofarticles.
Table 1 presents the results of this experi-ment.
It appears that more complex models (LSA,LDA) are outperformed on this task by the simplervector space models (TF-IDF, LogEntropy).
Thiscan be just a special case with this experimentalsetting and perhaps another choice of the numberof topics could give better results.
Thus, furthermeta-parameter optimization of LSA and LDA isone approach for improving the performance of thetext2wiki module.5.2 Evaluation of the wiki2skill moduleIn order to find the optimal strategy of applyingSpreading Activation, we designed an evaluationprotocol relying on related skills listed on eachLinkedIn skill page.
These are automatically se-lected by computing similarities between skills fromuser profiles (Skomoroch et al 2012).
Each skillpage contains at most 20 related skills.For the evaluation procedure, we choose an initialnode i, corresponding to a LinkedIn skill, and acti-vate it by setting a(0) = ei, that is a vector contain-ing 1 in its i-th element and zeros elsewhere.
Then,we compute a(T ) with some spreading strategy andfor some number of steps T , filter out the skill nodesand rank them according to their final activations.
Tomeasure how well the related skills are representedin this ranked list of skills, we use Precision at 1, 5and 10, and R-Precision to evaluate the accuracy ofthe first ranked results and Recall at 100 to see howwell the algorithm manages to activate all of the re-84lated skills.There are many LinkedIn skills that are not wellrepresented in the Wikipedia graph, because of am-biguity issues, for instance.
To prevent these anoma-lies from causing misguiding results, we selected afixed set of 16 representative skills for the evalua-tion.
These skills were ?Statistics?, ?Hidden MarkovModels?, ?Telecommunications?, ?MeeGo?, ?Digi-tal Printing?, ?OCR?, ?Linguistics?, ?Speech Syn-thesis?, ?Classical?, ?Impressionist?, ?Education?,?Secondary Education?, ?Cinematography?, ?Exec-utive producer?, ?Social Sciences?, ?Political Soci-ology?.Developing a completely automatic optimisationscheme for this model selection task would be diffi-cult because of the number of different parameters,the size of the Wikipedia graph and the heuristic na-ture of the whole methodology.
Thus, we decided torely on a manual evaluation of the results.Exploring the whole space of algorithms spannedby eq.
(1) would be too demanding as well.
That iswhy we have so far tested only a few models.
In thepreliminary experiments that we conducted with thesystem, we observed that using a friction factor ?smaller than one had little effect on the results, andthus we decided to always use ?
= 1.
Otherwise,we experimented with three models, which we willsimply refer to as models 1, 2 and 3 and which wedefine as follows?
model 1: ?
= 0 and c(t) = 0;?
model 2: ?
= 1 and c(t) = 0;?
model 3: ?
= 0 and c(t) = a(0).In model 1, activation is not conserved in a nodebut only depends on the activation it has receivedfrom its neighbors after each pulse.
In contrast, theactivation that a node receives is completely con-served in model 2.
Model 3 corresponds to the Ran-dom Walk with Restart model, where the initial ac-tivation is fed to the system at each pulse.
Models1 and 2 eventually converge to a stationary distribu-tion that is independent of the initial activation vec-tor.
This can be beneficial in situations where someof the initially activated nodes are noisy, or irrele-vant, because it allows the initial activation to dieout, or at least become lower than the activation ofother, possibly more relevant nodes.
With Model 3,the initially activated nodes remain always amongthe most activated nodes, which is not necessarily arobust choice.The outcomes of the experiments demonstratedthat model 2 and model 3 perform equally well.
In-deed, these models are very similar, and apparentlytheir small differences do not affect the results much.However, model 1 provided constantly worse resultsthan the two other models.
Thus, we decided to usemodel 3, corresponding to the Random Walk withRestart model, in the system and in selecting the restof the spreading strategy.We also evaluated different settings for the linkweighting scheme.
Here, we faced a startling result,namely that increasing the bidirectional link weight?
all the way up to the value ?
= 15 kept improvingthe results according to almost all evaluation mea-sures.
This would indicate that links that exist inonly one direction do not convey a lot of semanticrelatedness.
However, we assume that this is a phe-nomenon caused by the nature of the experiment andthe small subset of skills used in it, and not necessar-ily a general phenomenon for the whole Wikipediagraph.
In our experiments, the improvement wasmore drastic in the range ?
?
[1, 5] after which adamping effect can be observed.
For this reason,we decided to set the bidirectional link weight in theElisit system to ?
= 5.We observed a similar phenomenon for the num-ber of pulses T .
Increasing its value up to T = 8 im-proved constantly the results.
However, again, therewas no substantial change in the results in the rangeT ?
[5, 8].
In the web service, the number of pulsesof the spreading activation can be determined by theuser.In addition to the parameters discussed above, thelink weighting involves the popularity index pij andthe biasing parameter ?.
An overview of the ef-fect of these two choices can be seen in Table 2,which presents the results with the different eval-uation measures.
These results were obtained bysetting parameters as described earlier in this sec-tion.
First, we can see from this table that usingnegative values for ?
in the weighting improves re-sults compared to the natural random walk, i.e.
thecase ?
= 0.
This indicates that our strategy of bi-asing the spreading of activation to avoid popularnodes indeed improves the results.
We can also see85Pre@1 Pre@5 Pre@10 R-Pre Rec@100?
din PR HITS din PR HITS din PR HITS din PR HITS din PR HITS0 0 0 0 0.119 0.119 0.119 0.156 0.156 0.156 0.154 0.154 0.154 0.439 0.439 0.439-0.2 0 0 0 0.206 0.238 0.206 0.222 0.216 0.213 0.172 0.193 0.185 0.469 0.469 0.494-0.4 0 0 0 0.225 0.263 0.169 0.203 0.200 0.150 0.185 0.204 0.148 0.503 0.498 0.476-0.6 0 0 0.063 0.238 0.225 0.119 0.200 0.197 0.141 0.186 0.193 0.119 0.511 0.517 0.418-0.8 0 0 0 0.213 0.181 0.075 0.191 0.197 0.113 0.171 0.185 0.109 0.515 0.524 0.384-1 0 0 0 0.169 0.156 0.063 0.178 0.197 0.091 0.154 0.172 0.097 0.493 0.518 0.336Table 2: The effect of the biasing parameter ?
and the choice of popularity index on the results in the evaluation of thewiki2skill module.that using Pagerank as the popularity index providedoverall better results than using the input degree,which again yielded better results than using HITS.Thus, biasing according to the input connections ofnodes seems more preferable than biasing accord-ing to co-citation or co-reference connections.
Thelow scores with Precision@1 are understandable,because of the low number of positives (at most 20related skills) in comparison to the total number ofskills (over 27,000).
In the Elisit system, we usethe Pagerank score as the popularity index and setthe value of the biasing parameter to ?
= ?0.4.5.3 Evaluation of the whole Elisit systemWe adapted the evaluation procedure used for thewiki2skill module, described in the previoussection, in order to test the whole Elisit sys-tem.
This time, instead of activating the node ofa given skill, we activated the nodes found by thetext2wiki module when fed with the Wikipediaarticle corresponding to the skill.
We run the Spread-ing Activation algorithm with the setup presented inthe previous section.
To make the evaluation morerealistic, the initial activation of the target skill nodeis set to zero (instead of 1, i.e.
the cosine of a vectorwith itself).The system allows its user to set the number ofinitially activated nodes.
We investigated the ef-fect of this choice by measuring Precision and Re-call according to the related skills, and by lookingat the average rank of the target skill on the list offinal activations.
However, there was no clear trendin the results when testing with 1-200 initially ac-tivated nodes.
Nevertheless, we have noticed thatusing more than 20 initially activated nodes rarelyimproves the results.
We must also emphasize thatthe choice of the number of initially activated nodesdepends on the query, especially its length.We also wanted to compare the different VSM?sVSM Pre@1 Pre@5 Pre@10 R-Pre Rec@100TF-IDF 0.042 0.231 0.214 0.190 0.516LogEntropy 0.068 0.216 0.212 0.193 0.525LogEnt + LSA 0.042 0.180 0.181 0.163 0.491LogEnt + LDA 0.089 0.193 0.174 0.159 0.470Table 3: Comparison of the different models of thetext2wiki module in the performance of the wholeElisit system.of the text2wiki module when using the wholeElisit system.
We did this by comparing Pre-cision and Recall at different ranks w.r.t.
the re-lated skills of the target skill found on LinkedIn.Thus, this experiment combines the experiments in-troduced in sections 5.1, where the evaluation wasbased on the ?See also?
pages, and 5.2, where weused a set of 16 target skills and their related skills.Table 3 reports the Precision and Recall values ob-tained with the different VSM?s.
These values resultfrom an average over 12 different numbers of ini-tially activated nodes.
They confirm the conclusiondrawn from the experiment in section 5.1, namelythat the LogEntropy and TF-IDF models outperformLSA and LDA models for this task.6 Conclusion and future workWe have presented a method for skill extractionbased on Wikipedia articles, their hyperlink graph,and a set of skills built by LinkedIn.
We have alsopresented the Elisit system as a reference imple-mentation of this method.
This kind of a systemhas many potential applications, such as knowledgemanagement in a company or recommender systemsof websites.
We have demonstrated with examplesand with quantitative evaluations that the system in-deed extracts relevant skills from text.
The evalu-ation experiments have also allowed us to compareand finetune different strategies and parameters ofthe system.
For example, we have shown that usinga bias to avoid the spreading of activation to popular86nodes of the graph improves retrieval results.This work is still in progress, and we have manygoals for improvement.
One plan is to compute linkweights based on the contents of linked pages usingtheir vector space representation in the text2wikimodule.
The method and system proposed in thepaper could also be extended to other languages.
Fi-nally, our methodology can potentially be used todifferent problems than skill extraction by substitut-ing the LinkedIn skills with a list of Wikipedia pagesfrom another domain.ReferencesJohn R Anderson.
1983.
A spreading activation theory ofmemory.
Journal Of Verbal Learning And Verbal Behavior,22(3):261?295.Krisztian Balog, Paul Thomas, Nick Craswell, Ian Soboroff, Pe-ter Bailey, and Arjen P De Vries.
2008.
Overview of the trec2008 enterprise track.
Technical report, DTIC Document.Krisztian Balog, Yi Fang, Maarten de Rijke, Pavel Serdyukov,and Luo Si.
2012.
Expertise retrieval.
Foundations andTrends in Information Retrieval, 6(2-3):127?256.Holger Bast and Debapriyo Majumdar.
2005.
Why spectralretrieval works.
In Proceedings of the 28th annual interna-tional ACM SIGIR conference on Research and developmentin information retrieval, pages 11?18.
ACM.Michael W. Berry, Susan T. Dumais, and Gavin W. O?Brien.1994.
Using linear algebra for intelligent information re-trieval.
Technical Report UT-CS-94-270.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003.Latent dirichlet alcation.
Journal of Machine Learning Re-search, 3:993?1022, March.Matthew Brand.
2005.
A random walks perspective on max-imizing satisfaction and profit.
Proceedings of the 2005SIAM International Conference on Data Mining.Fabio Crestani.
1997.
Application of spreading activation tech-niques in information retrieval.
Artificial Intelligence Re-view, 11(6):453?482.Gianluca Demartini, Tereza Iofciu, and Arjen P De Vries.
2010.Overview of the inex 2009 entity ranking track.
In FocusedRetrieval and Evaluation, pages 254?264.
Springer.Peter W Foltz.
1996.
Latent semantic analysis for text-basedresearch.
Behavior Research Methods, Instruments, & Com-puters, 28(2):197?202.Agata Fronczak and Piotr Fronczak.
2009.
Biased randomwalks in complex networks: The role of local navigationrules.
Physical Review E, 80(1):016107.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Comput-ing semantic relatedness using wikipedia-based explicit se-mantic analysis.
In IJCAI?07: Proceedings of the 20th in-ternational joint conference on Artifical intelligence, pages1606?1611, San Francisco, CA, USA.
Morgan KaufmannPublishers Inc.Stephan Gouws, G-J van Rooyen, and Herman A. Engelbrecht.2010.
Measuring conceptual similarity by spreading acti-vation over wikipedia?s hyperlink structure.
In Proceedingsof the 2nd Workshop on The People?s Web Meets NLP: Col-laboratively Constructed Semantic Resources, pages 46?54,Beijing, China, August.
Coling 2010 Organizing Committee.Graeme Hirst.
1988.
Semantic interpretation and ambiguity.Artificial Intelligence, 34(2):131?177.Jon M. Kleinberg.
1999.
Authoritative sources in a hyperlinkedenvironment.
Journal of the ACM, 46(5):604?632.Marijn Koolen.
2011.
The Meaning Of Structure: the Valueof Link Evidence for Information Retrieval.
Ph.D. thesis,University of Amsterdam, The Netherlands.Thomas K. Landauer and Susan T. Dumais.
1997.
A solu-tion to plato?s problem: The latent semantic analysis theoryof acquisition, induction, and representation of knowledge.Psych.
review, 104(2):211.Christopher D Manning, Prabhakar Raghavan, and HinrichSchu?tze.
2008.
Introduction to information retrieval, vol-ume 1.
Cambridge University Press Cambridge.Amin Mantrach, Nicolas van Zeebroeck, Pascal Francq,Masashi Shimbo, Hugues Bersini, and Marco Saerens.2011.
Semi-supervised classification and betweenness com-putation on large, sparse, directed graphs.
Pattern Recogni-tion, 44(6):1212?1224.Rada Mihalcea and Andras Csomai.
2007.
Wikify!
: link-ing documents to encyclopedic knowledge.
In Ma?rio J.Silva, Alberto H. F. Laender, Ricardo A. Baeza-Yates, Debo-rah L. McGuinness, Bj?rn Olstad, ?ystein Haug Olsen, andAndre?
O. Falca?o, editors, CIKM, pages 233?242.
ACM.George A Miller.
1995.
Wordnet: a lexical database for english.Communications of the ACM, 38(11):39?41.Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Wino-grad.
1999.
The pagerank citation ranking: Bringing orderto the web.
Technical Report 1999-0120, Computer ScienceDepartment, Stanford University.Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and PinarDuygulu.
2004.
Automatic multimedia cross-modal corre-lation discovery.
In Proceedings of the tenth ACM SIGKDDinternational conference on Knowledge discovery and datamining, pages 653?658.
ACM.Radim R?ehu?r?ek and Petr Sojka.
2010.
Software Frameworkfor Topic Modelling with Large Corpora.
In Proceedingsof the LREC 2010 Workshop on New Challenges for NLPFrameworks, pages 45?50, Valletta, Malta, May.
ELRA.Jeff Shrager, Tad Hogg, and Bernardo A Huberman.
1987.Observation of phase transitions in spreading activation net-works.
Science, 236(4805):1092?1094.Peter N Skomoroch, Matthew T Hayes, Abhishek Gupta, andDhanurjay AS Patil.
2012.
Skill customization system, Jan-uary 24.
US Patent App.
13/357,360.Mark Steyvers, Padhraic Smyth, Michal Rosen-Zvi, andThomas Griffiths.
2004.
Probabilistic author-topic modelsfor information discovery.
In Proceedings of the 10th ACMInternational Conference on Knowledge Discovery and DataMining.
ACM Press.Eric Yeh, Daniel Ramage, Christopher D. Manning, EnekoAgirre, and Aitor Soroa.
2009.
Wikiwalk: Random walkson wikipedia for semantic relatedness.
In Graph-basedMethods for Natural Language Processing, pages 41?49.The Association for Computer Linguistics.87
