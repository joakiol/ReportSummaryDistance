A Mul t i -Purpose  In ter face  to an On- l ine D ic t ionaryBranimir Boguraev and David CarterUniversity of Cambridge, Computer LaboratoryCorn Exchange Street, Cambridge CB2 3QG, EnglandTed BriscoeDepartment of Linguistics, University of LancasterBailrigg, Lancaster LA1 4YT, EnglandAbst ractWe argue that there are two qualitatively differentmodes of using a machine-readable dictionary in thecontext of research in computational linguistics: batchprocessing of the source with the purpose of collatinginformation for subsequent use by a natural anguageapplication, and placing the dictionary on-line in anenvironment which supports fast interactive access todata selected on the basis of a number of linguisticconstraints.
While it is the former mode of dictionaryuse which is characteristic of most computational lin-guistics work to date, it is the latter which has thepotential of making maximal use of the informationtypically found in a machine-readable dictionary.
Wedescribe the mounting of the machine-readable sourceof the Longman Dictionary of Contemporary Englishon a single user workstation to make it available as adevelopment tool for a number of research projects.1 In t roduct ionA growing mass of work at present, both within thenarrower field of computational linguistics and in thewider context of building knowledge-based systems,is focussed on making use of the lexical resources tobe found in a number  of (monolingual) dictionaries ofthe style exemplified by e.g.
The Longman Dictionaryof Contemporary English, The Collins English Dictio-nary, or Webster's Seventh New Collegiate Dictionary.These contain a wealth of information relevant o awide range of natural anguage processing functions- -  a fact which is hardly surprising, given that suchsources typically (and almost by definition) containthe results of substantial efforts to collate and analysedata about real language, to elicit collocational anddistributional properties of words and to apply com-mon principles of defining their meaning.The availability of dictionary sources on-line, inthe form of machine-readable dictionaries (henceforthMRDs) and encyclopaedias, makes it possible to viewthese as repositories of large amounts of information,linguistic and extra-linguistic, which can be brought obear at various points of the natural anguage under-standing process.
Developments in hardware, as wellas research in computational linguistics, offer the tech-nology both to process lexical resources and to extractfrom them what is relevant to computer programs con-cerned with various natural anguage processing ac-tivities.
A number of recent projects have extracteddata from publishers' tapes and subsequently used itto support activities uch as syntactic parsing, speechsynthesis, lexical disambiguation, semantic interpreta-tion in context, spelling correction and machine trans-lation.
The common denominator in these projects isthat the end product incorporates in some form appro-priate fragments derived from the machine-readablesource.There are essentially two different modes in whichMRDs can be used (see Boguraev, 1987, for more de-tails).
The predominant technique to date involves anarbitrary amount of pro-processing, typically in batch,of the on-line source.
Those parts of the dictionaryentries which contain useful data for the task at handare extracted and suitably represented in a form di-rectly usable by a client program.
Such a model ofdictionary use does not in any way rely on the originalsource being available at the time the language pro-cessing application is active, and thus a batch deriva-tion of the appropriate information is a suitable wayof transforming the raw data into a usable repositoryof lexical knowledge.But the reality of trying to adapt information,originally packaged according to lexicographic and ty-pographic onventions for visual presentation and notat all intended for automated natural anguage pro-cessing, suggests a different model of dictionary use.The non-trivial task of developing suitable proceduresfor pre-processing of the machine-readable source typ-ically requires careful analysis of the properties of theparticular MILD, and is best aided by having fast in-teractive access to appropriate fragments of it.In addition, many research projects of a more ex-perimental nature focus on investigating the ways inwhich the availability of an MRD can aid the devel-opment of particular natural language processing sys-tems.
The assumption is that an analysis of the accu-mulated ata in the dictionary will reveal regularitieswhich can then be exploited for the task at hand.
Justone example, from a number of projects currently un-der way in Cambridge, illustrating this point is thework of Alshawi (1987), who has analysed efinitiontexts across an entire dictionary to produce a ~defini-tion grammar ~ together with an associated techniquefor parsing the natural language descriptions of wordsinto semantic structures.Such projects depend critically not only on theavailability of a machine-readable equivalent of a pub-lished dictionary, but also on a software system ca-pable of providing fast interactive access into the on-line source through various access routes.
Operationalnatural anguage processing systems clearly will havewell-defined requirements a far as their lexicons areconcerned, and once the format of lexical resources hasbeen settled, retrieval of individual entries can be im-plemented fairly efficiently using standard computa-tional and linguistic techniques ( ee e.g.
Russell et al,1986).
The placing of a dictionary on-line, however,with the intention of making it available to a numberof different research projects which need to locate and63collate dictionary samples atisfying a wide range ofconstraints, requires an efficient and flexible systemfor management and retrieval of linguistic data.This is not the computationally straightforward is-sue it appears to be, as conventional database man-agement systems (DBMS)  are not well suited for on-line dictionary support, particularly when the entiredictionary is viewed as a lezical knowledge b~e, morecomplex in structure and facing more taxing demandsin a natural language research environment.
This pa-per addresses the problem in greater detail, by placingit into the wider context of research into computa-tional linguistics and highlighting those issues whichpose a challenge for the current DBMS wisdom.
Wepropose a solution adequate to handle most of the lex-ical requirements of current systems, which is general-isable to a range of IVIRDs, and describe a particularimplementation for single user workstations used in anumber of on-going research projects at the universi-ties of Cambridge and Lancaster.2 The nature of the problemSeveral factors put the task of mounting a machine-readable dictionary as a proper development tool be-yond the scope of current DBMS practice and makeits conversion into a database of e.g.
a standard rela-tional kind quite difficult.Firstly, there is the nature of the data in a dictio-nary: typically, it contains far too much free text (def-initions, examples, cross-reference pointers, glosses onusage and so forth) to fit easily into the concept ofstructured ata.
On the other hand, the highly struc-tured and formallsed encoding of other types of in-formation (found in e.g.
the part of speech, syllab-ification or pronunciation fields) makes a dictionaryequally unsuitable for on-line access by informationretrieval methods.The second factor is due to the nature of the onlysource of machine-readable dictionaries so far availablenamely the publishers' typesetting tapes, originallyconstructed for the production of a printed version.The organisation of data there, aimed at visual pre-sentation, carries virtually no explicit structure; a tapeis simply a character stream containing an arbitrarymixture of typesetting commands and real data.
Thisnot only introduces the difficult problem of ~parsing ~a dictionary entry (addressed in detail by e.g.
Kaz-man, 1986), but also raises the issue of devising a suit-able representation for the potentially huge amount oflinguistic data; one which does not limit in any waythe language processing functions that could be sup-ported or constrain the complexity of the computa-tional counterpart of a dictionary entry.Finally, there is the nature of the data structuresthemselves.
A text processing application, typicallywritten in Lisp or Prolog, requires that its lexicai datais represented in a compatible form, say Lisp s-expres-sions of arbitrary complexity.
Therefore, even if wechoose to remain neutral with respect o representa-tion details, we still face the problem of interfacingto a vast number of symbolic s-expressions, held insecondary storage.
This problem arises from the un-suitability of conventional data models for handlingthe complex data structures underlying any sophisti-cated symbolic processing.
Partly, this is due to theinherent restrictions such models impose on the classof data structure they can represent easily - -  namelyrecords of fixed format.
But more importantly, con-ventional database systems make strong assumptionsabout the status and use of data they have to hold:databases are taken to consist of a large number ofdata records taken from a small number of rigidly-defined classes.
It is not clear that a lexical ~knowl-edge base ~, derived from a dictionary and intended tosupport a wide range of language processing applica-tions, fits this model well.Some solutions to these problems will no doubtbe offered by dedicated efforts to develop special pur-pose data models, capable of computationally repre-senting a dictionary and amenable to flexible and eff-cient DBMS support.
The work, at the University ofWaterloo, on computerising the Ozford English Dictio-nary (Tompa, 1986) is a good example here; similarly,the desire to be able to mount computerised dictio-naries on-llne for in-house research motivates Byrd'swork on a general purpose dictionary access method(Byrd etal., 1986).
In the short run, alternativeapproaches reduce the complexity of the problem bylimiting themselves to applying the machine readablesource of a dictionary to a small class of similar tasks,and building customlsed interfaces offering relativelynarrow access channels into the on-line data.
ThusIBM's WordSmith system (Byrd and Chodorow, 1985)is concerned primarily with providing a browsing func-tionality which supports retrieval of words ~close ~ toa given word along the dimensions of spelling, mean-ing and sound, while a group at Bell Labs has sev-eral large dictionaries on-line used only for researchon stress assignment (Church, 1985).
Alshawi et al(1985) have used a machine-readable source directlyfor syntactic analysis of texts; however, the approachtaken there -- namely that of simple pro-indexing byorthography -- does not generalise easily for applica-tions which require the rapid locating and retrieval ofentries satisfying more than one selection criterion.3 System functionalityThe motivation for the design described here is di-vided equally between the diverse nature of MRD-based projects in Cambridge and Lancaster and theunique properties of the particular dictionary that theyuse.
The suitability of the Longr~an Dictionarv of Con-temporary English (LDOCE) for research into compu-tationa~ linguistics has been discussed at length else-where (see, in particular, Michiels, 1982); below wewill outline several projects undertaken in Cambridgeas a context for highlighting its particularly usefulcharacteristics insofar as they are relevant to this pa-per.LDOCE carries pecial exicai and linguistic infor-mation which is useful for a number of natural an-guage processing tasks.I.
The dictionary is unique in tagging word senseswith grammar code8 which provide very elabo-rate syntactic subcategorisation information; aprocedure has been developed for mapping thegrammar codes into feature clusters (in the styleof e.g.
Generalised Phrase Structure Grammar),subsequently to be used by a syntactic parser(Boguraev and Briscoe, 1987, describe this indetail).
The transformation program is aboutto be integrated in a software system for gram-64mar support and development, both as a lexiconenerator and as a tool for grammar debuggingoguraev and Ritchie, 1987).2.
The pronunciation information in LDOCE hasprovided the basis for a study, in the larger con-text of speech recognition, of the implicationsof the phonetic structure of the English lexiconfor different methods for lexical access (Carter,1986).
Again in the context of speech recog-nition, we intend to tackle the problem of wordidentification from a lattice of phonemes by con-structing a parser that uses information aboutboth phoneme collocations and syntactic pre-dictions derived from independent analyses ofthe phonetic and grammar coding fields in thedictionary.3.
Furthermore, LDOCE carries pecial tags, knownas subjecf, and boz codas, which encode semanticnotions like the overall context in which a wordsense is likely to appear (e.g.
politics, religion,language) and selectional restrictions on verbs,nouns and compound phrases; we intend to usethis information for further guidance during theword recognition process.
Independently, anal-gorithm has been developed for analysing the se-mantic content proper of the dictionary entriesby converting the definition texts in LDOCEinto fragments of semantic networks (Alshawi,1987); this opens opportunities for building acomprehensive and robust semantic omponentwhich could then be incorporated into any ofthe projects mentioned above.It is clear that in order to make full use of the com-puterised LDOCE, we need a dictionary access ystemwith proper DBMS functionality, capable of efficientretrieval of entries atisfying selection criteria pplyingat various levels of linguistic description.
The designof the system described here allows precisely such het-erogeneous requests.
What we offer is a software nvi-ronment buffering the user from the typically baroqueand idiosyncratic format of the raw dictionary sourceand allowing, via a carefully crafted interface, multi-ple entry points and arbitrarily complex access pathsinto the on-line lexical knowledge base.4 Requirements for the dictionarydatabaseThree main requirements can be identified if the data-base is to perform the functions intended for it.Firstly, the source tape of the dictionary must beconverted into a format to which fast access can becoupled.
This involves, at the very least, overall seg-mentation of the original character stream into recordscorresponding to gross lexical categories such as headword, pronunciation a d part of speech.
This may be ahighly complex task, as in Kazman's (1986) project orestructure the text of the OED, or it may be concep-tually fairly straightforward, asin the case of LDOCEwhere considerable segmentation is already present.But in either case, given that the on-line dictionary isintended to support more than one application, a moreelaborate structuring of the entries' individual recordsmight turn out to be unsuitable for further unforeseenuse.
Fortunately, it is clear from work with comput-erlsed dictionaries in general that once an applicationhas located the relevant fragment of a dictionary en-try, local ~parsing ~ into whatever format is neededcan be fast and reliable, and can therefore be done%n the fiy~ by functions which manipulate individualentries on demand and have no permanent effect onthe underlying source.
Thus we should aim at incorpo-rating the segmented version of the source intact intothe database, to serve directly as its ~bottom layeff'in the sense that all access paths ultimately point tocomplete dictionary entries, which are then returnedas the results of queries.Secondly, it should be possible to execute queriesinvolving information of as many different types aspossible.
Even if the machine-readable source usedis a comparatively structured one such as LDOCE,the creation of access paths will involve, for at leastsome types of information, the non-trivlal (but fast)construction of an intermediate and temporary repre-sentation by means of the local parsing already men-tioned.
For example, subcategorisation nformation isoften specified in a rather elliptical form in LDOCE,for the sake of human readability; this must be madeexplicit by a parsing process, as described in Boguraevand Briscoe (1987).
Also, it is desirable to impose aphonologically motivated structure on pronunciations,which are typically given as a string of phonemes andstress markers.
This will allow the user to specify aconstraint on, say, ~the onset of the second syllable ofthe word s , whose position in the phoneme string willnot be the same for all words.
The straight indexingapproach used by e.g.
Boguraev and Briscoe (1987)for headword-based access cannot in general providesufficiently flexible access routes.Thirdly, the user or client program should be freeto specify different ypes of constraint in any combina-tion.
We cannot assume in advance that informationof a given type will always be present in great enoughquantities to allow efficient retrieval.
For example,if the system is being used by an automatic speechrecogniser, then at one point in the signal significantinformation on pronunciation may be available, butfew syntactic or semantic onstraints may be present;at another point, the situation may be reversed, withthe speech signal itself yielding little phonological in-formation but with an expectation-driven parser pro-viding quite specific higher-level constraints.
In eachcase, the stronger, more specific constraints must beused for access, and the weaker ones only for check-ing the entries retrieved.
To achieve this, the sys-tem must clearly be able to estimate in advance whatthe most efficient search strategy will be.
This abil-ity to perform maximally efficient searches given manydifferent kinds of constraint will also be important ifthe database is being used interactively to investigateproperties of the language.
If the system's claim to beinteractive is to be justified, it must be able to tell theuser in advance roughly how long a prospective querywould take to evaluate, and roughly how many entrieswould be returned as a result.5 Design and implementationThe design and implementation f the database sys-tem described here reflects the three requirements justidentified.The machine-readable source of LDOCE serves asthe bottom layer of the database after undergoing a65"lispification s process described in detail in Boguraevand Briscoe (1987).
This process preserves all the in-formation, lexical and typographic, on the tape, andinvolves little restructuring, serving primarily to re-format the source in a bracketed form in which it canbe much more easily read by Lisp programs.
The linkbetween the user or client program and the lisplfieddictionary is provided by a pointer file and a constraintfile whose nature and motivation will be described be-low.5.1 Ana lys ing  d ic t ionary  ent r iesInformation of six different types is analysed for theconstruction of access paths: semantic features clas-sifying the meanings of words and their dependents;semantic subject area; grammatical part of speech;grammatical subcategorisation; British English pro-nunciations; and definition texts.
All these types canbe mixed together in constructing search queries.
En-tries can also be accessed by spelling patterns.The codes used for the first three of these typesof information have a fairly simple structure, and arehence trivial to extract.
The fourth, subcategorisa-tion, is indicated by a complex and highly discrimina-tory set of codes; the extraction of these codes fromthe elliptical form in which they occur in LDOCE isdescribed in Boguraev and Briscoe (1987).
We willtherefore discuss here only the structuring of pronun-ciations and the treatment of definition texts.Pronunciations are represented in the dictionaryas strings of phonente8 and primary and secondarystress markers.
Syllable boundaries are not reliablyindicated.
Therefore, in order to allow the syllable-based access that a speech recogniser would probablyrequire, pronunciation fields are parsed into syllablesand, within a syllable, into onset, peak and coda, usin~the phonotactic constraints given in Gimson (1980}and employing a rnazintal onset principle (Selkirk, 1978)where these yield ambiguous syllable boundaries.
Thusfor example the internal syllable boundary in the pro-nunciation of ~constraint" is placed before the ~s ~.The parser used for analysing pronunciations isa special-purpose one whose (very simple) grammaris incorporated into its code.
This allows pronun-ciations to be parsed many times faster than by ageneral-purpose parser with a declarative grammar.It also allows constraints on relationships between syl-lable constituents to be relaxed when necessary.
Forexample, the LDOCE pronunciation of "bedouin" is?beduin~ which violates the constraint that a syllablewhose peak is u (as in "put s) cannot have a null coda;this constraint is therefore relaxed to obtain a parse.The strategy used for indexing entries according tothe words their definition texts was designed to reflectthe fact that it is the semantic content of these wordsthat is likely to be of interest to the user.
This hastwo main consequences:(1) It is more appropriate to take root forms ofwords as keys than to treat inflectional variants dif-ferently, because it is the root that holds most of thesemantic content.
Indeed, the inflection used with aparticular word often depends on the largely arbitrarychoice of syntactic constructions used in the definition.Thus for example, entries whose definitions containany of the words ~fllm ~, ~films ~ and "filmed ~ shouldall be indexed under "film s .
(2) Closed class words are unlikely to be usefulas keys because their semantic ontent is limited andoften highly context-dependent.
I  addition, many ofthem occur too often to be sufficiently discriminatingfor efficient lookup.
Therefore only open class wordsare made available as keys.The task of deriving root forms of words is mademuch easier by the fact that LDOCE's definition textsare constructed largely from a set of two thousandbasic words.
When other words are used, they (or, inthe case of inflectional variants, their root forms) areshown in a special font.
Accurate root extraction forwords not so marked can therefore be accomplishedsimply by stripping off affixes (which are themselvesin the basic word list) and applying a few simple rulesfor spelling changes until a basic word is found.
Allirregular forms of basic words are stored explicitly.Distinguishing open and closed class words is alsostraightforward; a 1/st of closed class words was de-rived by performing a database lookup using thosegrammar codes and categories that represent closedclasses.5.2 Const ruct ing  access  pathsOnce the relevant information has been extracted froman entry, constructing acess paths is straightforwardin the grammatical, semantic and definition text cases:a list of entry pointers is constructed for every codeand every suitable definition word found in the dictio-nary.
Pronunciations, however, are treated ifferently.To achieve flexibility and efficiency, a pointer list isformed for every distinct syllable in every position inwhich it occurs (e.g.
second syllable in a three-syllableword).When the whole dictionary has been analysed, apointer file is created containing all the entry pointerlists and, just before each llst, its length.
As describedbelow, this allows the system to estimate the workinvolved in evaluating a query without actually havingto read the (sometimes very long) list itself.The next stage is to construct he constraint file.This file takes the form of a discrimination net whichlinks every possible constraint on an entry (e.g.
a sub-ject area, a grammar code or a constituent of a sylla-ble) to one or, in the pronunciation case, several listsin the pointer file.5.3 Const ruct ing  search  quer iesA menu-driven graphical interface isprovided by meansof which the user can construct a search query in theform of a tree whose terminal nodes are constraint val-ues, dis\]unctions of them, or wild cards.
The menusare derived automatically from the constraint file, sothat only queries with some chance of being satisfiedcan be constructed.
For example, if the user is con-structing a specification of a syllable, the tree at onepoint may be as in Figure 1.66WORDPRONUNC I AT I ON:'S" TRE3:~?SYLLABLE\ "--..ON3ET PEAK CODA* ANO *ltd.%/z \ /?I0:~ - r  ourldFigure IIf the user selects the CODA node, the resultingmenu, shown in Figure 2, allows him to specify thecoda ~pst ~, but not, for example ~psm ~.
(In thismenu, and in terminal nodes of the PRONUNCIA-T ION subtree of Figure 1, ~*~ matches any sequenceof symbols; ~?"
matches any single symbol; and allother symbols have the phonetic values defined forthem in LDOCE).30~?e3bg ~mnfVX .x 9Figure 2A tree can be constructed either from a WORDnode alone, or by instructing the system to build a treefrom the entry for a specified word, and then editingit.
Once the tree is built, either a partial search (togather statistics) or a full search (to retrieve entries)can be requested.In a partial search, the system follows each con-straint to the pointer list(s) it leads to, and sumsthe lengths of these lists \[as recorded explicitly inthe pointer file) to display the approximate numberof dictionary entries that satisfy it.
It also indicateswhich constraints it would use to look up candidateentries in a full search, which ones it would merelyapply as tests to those candidates, and, to allow theuser to decide whether or not to order a full search,about how long the process would take.
It makes thelookup/test choice using figures for the expected timetaken to read (a) a pointer from the constraint fileand (b) a complete ntry from the dictionary.
Themost e~cient search strategy involves using the mostspecific few constraints as lookup keys (more specifickeys ultimately ielding fewer entries).
The optimalnumber of constraints o use is found by balancing thenumber of pointers that will have to be read, whichincreases with the number of lookup keys, against heexpected number of entries that will have to be read,which decreases.
(A.n entry will only be read if thereis a pointer to it in every pointer list.
Therefore iflookup keys are used, returning pointer lists of lengthsLI, L=, ... L , ,  then the expected number of entriesto be read, assuming statistical independence b tweenlists, is LIL2...L,/D"-l, where D is the number of en-tries in the dictionary.
This decreases with a becauseLi cannot exceed D, and is in fact normally very muchsmaller).In a full search, these statistics and choices are notonly displayed but are also acted on.
The pointer listsfor the lookup constraints are intersected, the numberof pointers resulting is displayed and, at the user'soption, the corresponding entries are read from thedictionary, the test constraints are applied to them,and the surviving entries are displayed.
Applying teststo a dictionary entry involves reanalysing the relevantparts of it in the same way as when the database isconstructed.6 An exampleAs an example, suppose the user wishes to see allentries for three-syllable nouns which describe mov-able solid objects, whose second syllable has a schwaas peak, and whose third syllable has a coda that is avoiced stop.
He constructs the tree in Figure 3 over-leaf, and selects the ~partial search" option.
This re-turns the information shown in Figure 4.Would look up on these constraint:s:,C*COOA* (OR b d g) / 3 3)-> 582  i tems~ould tes t  on these ones:?
PEAK" E / 2 3) (-> 3829 items)@B 5 J) (-> 5?79 items)~NSYLL3* 3) (-> %0~68 items)l!C n) (-> 23835 items)Estimated pointer+entry reading timei~ .5 -65.
.5 :~7.8  s~conds (5~2 ent r ies )Figure 467~IORD__._-.---.~-" -------...._.._.....8EI~ANTIO8 8RAt, l IAR PRONUNCIATION_.___.._---~ ~- -~-~OATESORY SYLLABLErl *BOX5 JSYLLABLE.
- /  / ",, - .
.$TRE88 ONSET PEAK CODAISYLLABLE.- / C'---.STRESS ONSET PEAK COOAI?
* ORb d gF igure 3Because of the expected large number of entriesin the result and the time that would be taken toread them, the user decides to look only at the en-tries for such words whose definitions contain the word"camera ~.
He  adds the relevant constraint to thetree (the system checking, as he does so, that %am-era ~ is a valid key) and orders another partial search.This time, the statistics are more manageable.
A fullsearch is therefore ordered, in which the definitionword %amera  ~ is used as the only lookup key, andthe other constraints are this time all used as tests.This returns the entries for the words %lapperboard ~and "Polaroid ~, shown in Figure 5.clztp.per.board /'l,.l~ep~ba:d II -ar~ora/n (subj ~aP--, box .... #) (when starting tofilm a scene for the cinema) a board onwhich ttte ,letails of \[Ite scene to bef i lmed are written, held up in front oft~te cameraPo.lar.oi4 /'p~ul~roid,:,~ t.z're~k i \[V\](subj st--.
box ....
z---x'., a material :vithw~ic}t -g'ass ;.s trea:ed in or,~er ",o :na~.eti~ht shine le~s br ight ly throw~h it, usedin making 3ut\[,3L.~.~zEa.~.
:ar '?,rifi,:l+3WS,etc.
2 \[C\] C:;u~j ~,3--.
box ....  s---.~', also (.,~,,~i,') Po l .~ro id  cam,e .
r~t  / 0""  " "  / - -a type of camera that produces af in ished pl'totograpPt only se,:on,:ts after~he picture has been tal..e-tFigure 57 ConclusionWe have sketched the requirements for, and the designof, a flexible interface to an on-line dictionary, capableof supporting the lexical requirements of a number ofactive research projects and adaptable to a range ofapplications.
The programs have been developed inLisp, and make heavy use of the interactive graphic ca-pabilities of Xerox's Lisp workstations.
Nothing, how-ever, depends critically on this; the Interllsp-D inter-active graphics simply make the task of constructingsearch specifications very easy for the end user.
Thedesign is sufficiently modular to allow easy modifica-tion, and the system would be capable of functioningon a conventional minicomputer or mainframe (as longas it supported random access to files) just as well asit does on a single user workstation.In order to make the lexical knowledge base avail-able to all the projects requiring access to it, the sys-tem had to be adapted to fit into the local environ-ment of networked workstations.
The database man-ager was easily repackaged to reflect the model of oneserver catering for several clients over a network; theRemote Procedure Call Protocol (XSIS, 1981) pro-vided the necessary functionality to incorporate themanager  into a dictionar!t server node (of the kinddiscussed by Kay, 1984) -- this bypassed the need forcostly flleservers and proved the integrity of the de-sign.
We also plan to develop a version of the systemrunning in Franz Lisp under UNIX  and accessing theM_RC dictionary database (Coltheart, 1981).While the system implements in effect a linguisti-cally motivated DBMS constructed round a suitablemachine-readable source, it stops short of full brows-ing capability (even though such a capability couldeasily be added by fully integrating AlshawFs defini-tions analysis program into the overall design).
In thissense the lexical knowledge base discussed here differs68from the concept of a lexical database as described inCalzolari (1986), or underlying Miller's WORDNET(1985).
Nonetheless, the methodology described hereis sufficiently flexible and powerful to satisfy a sub-stantial proportion of the needs of the computationallinguistics community till a proper mix of databaseand browsing capabilities becomes available.8 AcknowledgementsThis work was supported by a research grant (NumberGRID/4217.7) from the UK Science and EngineeringResearch Council.
We are grateful to the LongmanGroup Limited for kindly allowing us access to theLDOCE typesetting tape for research purposes.
Wethank Graham Titmus for his assistance in bringingthe dictionary server up.9 ReferencesAlshawi, H.; Boguraev, B.K.
and Briscoe, E.J.
(1985)'A dictionary support environment for real-timeparsing', Proceedings of the Second Conference ofthe European Chapter of the ACL, Geneva, pp.171-178Alshawi, H.A.
(1987,forthcoming) 'Processing dictio-nary definitions with phrasal pattern hierarchies',Computational LinguisticsBoguraev, B.K.
(1987,forthcoming) 'Machine-readabledictionaries and computational linguistics research'in Walker, D. and Zampolli, A.
(eds.
), Automatin 9the lezicon: theory and practice in a multilingualenvironment, Cambridge University Press, Cam-bridgeBoguraev, B.K.
and Briscoe, E.J.
(1987,forthcoming)'Large lexicons for natural language processing:utilising the grammar coding system of LDOCE',Computational Linguistics, vol.13Boguraev, B.K.
; Ritchie, G.D. et al(1987,forthcoming)'The lexical component of a natural anguage tool-kit' in Walker, D. and ZampoLli, A.
(eds.
), Au-tomating the lezicon: theory and practice in a mul-tilingual environment, Cambridge University Press,CambridgeByrd, R.J. and Chodorow, M.S.
(1985) 'Using an on-line dictionary to tlnd rhyming words and pro-nunciations for unknown words', Proceedings of theeSth Annual Meeting of the ACL, Chicago, Illinois,pp.277-284Byrd, R.3.
; Neumann, G. and Andersson, K.S.B.
(1986)DAM--  a dictionary access method, IBM researchreport, in preparationCalzolari, N.(1986,forthcoming) 'Machine-readable dic-tionaries, lexical data bases and the lexical system'in Walker, D. and Zampolli, A.
(eds.
), Automatingthe lezicon: theory and practice in a multilingualenvironment, Cambridge University Press, Cam-bridgeCarter, D.M.
(1986) An information-theoretic analysisof phonetic dictionary access, Computer Labora-tory, University of Cambridge (submitted to Com-puter Speech and Language).Church, K.(1985) 'Stress assignment in letter-to-soundrules for speech synthesis', Proceedings of the ~SthAnnual Meeting of the ACL, Chicago, IL, pp.246-254Coltheart, M.(1981) 'The MRC Psycholinguistic Data-base', Quarterly Journal of Ezperimental Psychol-ogy, vol.33A, 497-505Gimson, A.C.(1980) An introduction to the pronuncia-tion of English ($rd edition}, Edward Arnold, Lon-donKay, M.(1984) 'The dictionary server', Proceedings ofthe 10th International Congress of ComputationalLinguistics, Stanford, California, pp.461-462Kazman, R.(1986) Structuring the tezt of the OzfordEnglish Dictionary through finite state transduction,Technical Report TR-86-20, Department of Com-puter Science, University of Waterloo, Waterloo,OntarioMichiels, A.
(1982) Ezploiting a large dictionary database,Ph.D.
Thesis, Universit6 de Liege, BelgiumMiller, G.(1985) WORDNET: a dictionary browser, InProceedings of the First International Conferenceon Information in Data, University of Waterloocentre for the New OED, Waterloo, OntarioRussell, G.J.
et a1.
(1986) 'A dictionary and morpho-logical analyser for English', Proceedings of the 11thInternational Congress on Computational Linguis-tics, Bonn, pp.277-279Selkirk, E.O.
(1978) On prosodic structure and its rela-tion to syntactic structure, Indiana University Lin-guistics Club, Bloomington, IndianaTompa, F.(1986) Database design for a dictionary ofthe future, Preliminary report, Centre for the NewOxford English Dictionary, University of Water-loo, Waterloo, OntarioXSIS 038112(1981) Courier: the Remote Procedure Callprotocol, Xerox Systems Integration Standard, Xe-rox Corporation, Stamford, Connecticut69
