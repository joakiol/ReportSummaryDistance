Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1118?1127,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsCross-Language Text Classificationusing Structural Correspondence LearningPeter Prettenhofer and Benno SteinBauhaus-Universita?t WeimarD-99421 Weimar, Germany{peter.prettenhofer,benno.stein}@uni-weimar.deAbstractWe present a new approach to cross-language text classification that builds onstructural correspondence learning, a re-cently proposed theory for domain adap-tation.
The approach uses unlabeled doc-uments, along with a simple word trans-lation oracle, in order to induce task-specific, cross-lingual word correspon-dences.
We report on analyses that revealquantitative insights about the use of un-labeled data and the complexity of inter-language correspondence modeling.We conduct experiments in the fieldof cross-language sentiment classification,employing English as source language,and German, French, and Japanese as tar-get languages.
The results are convincing;they demonstrate both the robustness andthe competitiveness of the presented ideas.1 IntroductionThis paper deals with cross-language text classifi-cation problems.
The solution of such problemsrequires the transfer of classification knowledgebetween two languages.
Stated precisely: We aregiven a text classification task ?
in a target lan-guage T for which no labeled documents are avail-able.
?
may be a spam filtering task, a topic cate-gorization task, or a sentiment classification task.In addition, we are given labeled documents forthe identical task in a different source language S.Such type of cross-language text classificationproblems are addressed by constructing a clas-sifier fS with training documents written in Sand by applying fS to unlabeled documents writ-ten in T .
For the application of fS under lan-guage T different approaches are current practice:machine translation of unlabeled documents fromT to S, dictionary-based translation of unlabeleddocuments from T to S , or language-independentconcept modeling by means of comparable cor-pora.
The mentioned approaches have their prosand cons, some of which are discussed below.Here we propose a different approach to cross-language text classification which adopts ideasfrom the field of multi-task learning (Ando andZhang, 2005a).
Our approach builds upon struc-tural correspondence learning, SCL, a recentlyproposed theory for domain adaptation in thefield of natural language processing (Blitzer et al,2006).Similar to SCL, our approach induces corre-spondences among the words from both languagesby means of a small number of so-called pivots.
Inour context a pivot is a pair of words, {wS , wT },from the source language S and the target lan-guage T , which possess a similar semantics.
Test-ing the occurrence of wS or wT in a set of unla-beled documents from S and T yields two equiv-alence classes across these languages: one classcontains the documents where eitherwS orwT oc-cur, the other class contains the documents whereneither wS nor wT occur.
Ideally, a pivot splitsthe set of unlabeled documents with respect to thesemantics that is associated with {wS , wT }.
Thecorrelation between wS or wT and other words w,w 6?
{wS , wT } is modeled by a linear classifier,which then is used as a language-independent pre-dictor for the two equivalence classes.
As we willsee, a small number of pivots can capture a suffi-ciently large part of the correspondences betweenS and T in order to (1) construct a cross-lingualrepresentation and (2) learn a classifier fST for thetask ?
that operates on this representation.
Severaladvantages follow from our approach:?
Task specificity.
The approach exploits thewords?
pragmatics since it considers?duringthe pivot selection step?task-specific char-acteristics of language use.1118?
Efficiency in terms of linguistic resources.The approach uses unlabeled documentsfrom both languages along with a small num-ber (100 - 500) of translated words, insteadof employing a parallel corpus or an exten-sive bilingual dictionary.?
Efficiency in terms of computing resources.The approach solves the classification prob-lem directly, instead of resorting to a moregeneral and potentially much harder problemsuch as machine translation.
Note that the useof such technology is prohibited in certain sit-uations (market competitors) or restricted byenvironmental constraints (offline situations,high latency, bandwidth capacity).Contributions Our contributions to the outlinedfield are threefold: First, the identification and uti-lization of the theory of SCL to cross-languagetext classification, which has, to the best of ourknowledge, not been investigated before.
Sec-ond, the further development and adaptation ofSCL towards a technology that is competitive withthe state-of-the-art in cross-language text classifi-cation.
Third, an in-depth analysis with respectto important hyperparameters such as the ratioof labeled and unlabeled documents, the numberof pivots, and the optimum dimensionality of thecross-lingual representation.
In this connection wecompile extensive corpora in the languages En-glish, German, French, and Japanese, and for dif-ferent sentiment classification tasks.The paper is organized as follows: Section 2surveys related work.
Section 3 states the termi-nology for cross-language text classification.
Sec-tion 4 describes our main contribution, a new ap-proach to cross-language text classification basedon structural correspondence learning.
Section 5presents experimental results in the context ofcross-language sentiment classification.2 Related WorkCross-Language Text Classification Bel et al(2003) belong to the first who explicitly consid-ered the problem of cross-language text classi-fication.
Their research, however, is predatedby work in cross-language information retrieval,CLIR, where similar problems are addressed(Oard, 1998).
Traditional approaches to cross-language text classification and CLIR use linguis-tic resources such as bilingual dictionaries or par-allel corpora to induce correspondences betweentwo languages (Lavrenko et al, 2002; Olsson etal., 2005).
Dumais et al (1997) is considered asseminal work in CLIR: they propose a methodwhich induces semantic correspondences betweentwo languages by performing latent semantic anal-ysis, LSA, on a parallel corpus.
Li and Taylor(2007) improve upon this method by employingkernel canonical correlation analysis, CCA, in-stead of LSA.
The major limitation of these ap-proaches is their computational complexity and,in particular, the dependence on a parallel cor-pus, which is hard to obtain?especially for lessresource-rich languages.
Gliozzo and Strappar-ava (2005) circumvent the dependence on a par-allel corpus by using so-called multilingual do-main models, which can be acquired from com-parable corpora in an unsupervised manner.
In(Gliozzo and Strapparava, 2006) they show forparticular tasks that their approach can achieve aperformance close to that of monolingual text clas-sification.Recent work in cross-language text classifica-tion focuses on the use of automatic machinetranslation technology.
Most of these methods in-volve two steps: (1) translation of the documentsinto the source or the target language, and (2) di-mensionality reduction or semi-supervised learn-ing to reduce the noise introduced by the ma-chine translation.
Methods which follow this two-step approach include the EM-based approach byRigutini et al (2005), the CCA approach by For-tuna and Shawe-Taylor (2005), the informationbottleneck approach by Ling et al (2008), and theco-training approach by Wan (2009).Domain Adaptation Domain adaptation refersto the problem of adapting a statistical classifiertrained on data from one (or more) source domains(e.g., newswire texts) to a different target domain(e.g., legal texts).
In the basic domain adaptationsetting we are given labeled data from the sourcedomain and unlabeled data from the target domain,and the goal is to train a classifier for the targetdomain.
Beyond this setting one can further dis-tinguish whether a small amount of labeled datafrom the target domain is available (Daume, 2007;Finkel and Manning, 2009) or not (Blitzer et al,2006; Jiang and Zhai, 2007).
The latter setting isreferred to as unsupervised domain adaptation.1119Note that, cross-language text classificationcan be cast as an unsupervised domain adapta-tion problem by considering each language as aseparate domain.
Blitzer et al (2006) proposean effective algorithm for unsupervised domainadaptation, called structural correspondence learn-ing.
First, SCL identifies features that general-ize across domains, which the authors call pivots.SCL then models the correlation between the piv-ots and all other features by training linear clas-sifiers on the unlabeled data from both domains.This information is used to induce correspon-dences among features from the different domainsand to learn a shared representation that is mean-ingful across both domains.
SCL is related to thestructural learning paradigm introduced by Andoand Zhang (2005a).
The basic idea of structurallearning is to constrain the hypothesis space of alearning task by considering multiple different butrelated tasks on the same input space.
Ando andZhang (2005b) present a semi-supervised learningmethod based on this paradigm, which generatesrelated tasks from unlabeled data.
Quattoni et al(2007) apply structural learning to image classifi-cation in settings where little labeled data is given.3 Cross-Language Text ClassificationThis section introduces basic models and termi-nology.In standard text classification, a document dis represented under the bag-of-words model as|V |-dimensional feature vector x ?
X , where V ,the vocabulary, denotes an ordered set of words,xi ?
x denotes the normalized frequency of wordi in d, and X is an inner product space.
DSdenotes the training set and comprises tuples ofthe form (x, y), which associate a feature vectorx ?
X with a class label y ?
Y .
The goal is tofind a classifier f : X ?
Y that predicts the la-bels of new, previously unseen documents.
With-out loss of generality we restrict ourselves to bi-nary classification problems and linear classifiers,i.e., Y = {+1, -1} and f(x) = sign(wTx).
w is aweight vector that parameterizes the classifier, [?
]Tdenotes the matrix transpose.
The computation ofw from DS is referred to as model estimation ortraining.
A common choice for w is given by avector w?
that minimizes the regularized trainingerror:w?
= argminw?R|V |?
(x,y)?DSL(y, wTx) +?2?w?2 (1)L is a loss function that measures the qualityof the classifier, ?
is a non-negative regulariza-tion parameter that penalizes model complexity,and ?w?2 = wTw.
Different choices for L entaildifferent classifier types; e.g., when choosing thehinge loss function for L one obtains the popularSupport Vector Machine classifier (Zhang, 2004).Standard text classification distinguishes be-tween labeled (training) documents and unlabeled(test) documents.
Cross-language text classifica-tion poses an extra constraint in that training doc-uments and test documents are written in differentlanguages.
Here, the language of the training doc-uments is referred to as source language S, andthe language of the test documents is referred to astarget language T .
The vocabulary V divides intoVS and VT , called vocabulary of the source lan-guage and vocabulary of the target language, withVS ?
VT = ?.
I.e., documents from the trainingset and the test set map on two non-overlappingregions of the feature space.
Thus, a linear classi-fier fS trained on DS associates non-zero weightsonly with words from VS , which in turn means thatfS cannot be used to classify documents writtenin T .One way to overcome this ?feature barrier?
isto find a cross-lingual representation for docu-ments written in S and T , which enables the trans-fer of classification knowledge between the twolanguages.
Intuitively, one can understand sucha cross-lingual representation as a concept spacethat underlies both languages.
In the following,we will use ?
to denote a map that associates theoriginal |V |-dimensional representation of a doc-ument d written in S or T with its cross-lingualrepresentation.
Once such a mapping is found thecross-language text classification problem reducesto a standard classification problem in the cross-lingual space.
Note that the existing methods forcross-language text classification can be character-ized by the way ?
is constructed.
For instance,cross-language latent semantic indexing (Dumaiset al, 1997) and cross-language explicit semanticanalysis (Potthast et al, 2008) estimate ?
using aparallel corpus.
Other methods use linguistic re-sources such as a bilingual dictionary to obtain ?
(Bel et al, 2003; Olsson et al, 2005).11204 Cross-LanguageStructural Correspondence LearningWe now present a novel method for learning amap ?
by exploiting relations from unlabeled doc-uments written in S and T .
The proposed method,which we call cross-language structural corre-spondence learning, CL-SCL, addresses the fol-lowing learning setup (see also Figure 1):?
Given a set of labeled training documentsDSwritten in language S, the goal is to create atext classifier for documents written in a dif-ferent language T .
We refer to this classifi-cation task as the target task.
An example forthe target task is the determination of senti-ment polarity, either positive or negative, ofbook reviews written in German (T ) given aset of training reviews written in English (S).?
In addition to the labeled training docu-ments DS we have access to unlabeled doc-uments DS,u and DT ,u from both languagesS and T .
Let Du denote DS,u ?DT ,u.?
Finally, we are given a budget of calls to aword translation oracle (e.g., a domain ex-pert) to map words in the source vocabu-lary VS to their corresponding translations inthe target vocabulary VT .
For simplicity andwithout loss of applicability we assume herethat the word translation oracle maps eachword in VS to exactly one word in VT .CL-SCL comprises three steps: In the first step,CL-SCL selects word pairs {wS , wT }, called piv-ots, where wS ?
VS and wT ?
VT .
Pivots have tosatisfy the following conditions:Confidence Both words, wS and wT , are predic-tive for the target task.Support Both words, wS and wT , occur fre-quently in DS,u and DT ,u respectively.The confidence condition ensures that, in thesecond step of CL-SCL, only those correlationsare modeled that are useful for discriminativelearning.
The support condition, on the otherhand, ensures that these correlations can be es-timated accurately.
Considering our sentimentclassification example, the word pair {excellentS ,exzellentT } satisfies both conditions: (1) thewords are strong indicators of positive sentiment,Words in VSClasslabelterm frequenciesNegative class labelPositive class labelWords in VT... , x|V|)x = (x1 , ...DSDS,uDT,uDuNo valueyFigure 1: The document sets underlying CL-SCL.The subscripts S , T , and u designate ?source lan-guage?, ?target language?, and ?unlabeled?.and (2) the words occur frequently in book reviewsfrom both languages.
Note that the support of wSandwT can be determined from the unlabeled dataDu.
The confidence, however, can only be deter-mined for wS since the setting gives us access tolabeled data from S only.We use the following heuristic to form an or-dered set P of pivots: First, we choose a subsetVP from the source vocabulary VS , |VP |  |VS |,which contains those words with the highest mu-tual information with respect to the class label ofthe target task in DS .
Second, for each wordwS ?
VP we find its translation in the target vo-cabulary VT by querying the translation oracle; werefer to the resulting set of word pairs as the can-didate pivots, P ?
:P ?
= {{wS , TRANSLATE(wS)} | wS ?
VP }We then enforce the support condition by elim-inating in P ?
all candidate pivots {wS , wT } wherethe document frequency of wS in DS,u or of wTin DT ,u is smaller than some threshold ?
:P = CANDIDATEELIMINATION(P ?, ?
)Let m denote |P |, the number of pivots.In the second step, CL-SCL models the corre-lations between each pivot {wS , wT } ?
P and allother words w ?
V \ {wS , wT }.
This is done bytraining linear classifiers that predict whether ornot wS or wT occur in a document, based on theother words.
For this purpose a training set Dl iscreated for each pivot pl ?
P :Dl = {(MASK(x, pl), IN(x, pl)) | x ?
Du}1121MASK(x, pl) is a function that returns a copy ofx where the components associated with the twowords in pl are set to zero?which is equivalentto removing these words from the feature space.IN(x, pl) returns +1 if one of the components of xassociated with the words in pl is non-zero and -1otherwise.
For each Dl a linear classifier, charac-terized by the parameter vector wl, is trained byminimizing Equation (1) on Dl.
Note that eachtraining set Dl contains documents from both lan-guages.
Thus, for a pivot pl = {wS , wT } the vec-tor wl captures both the correlation between wSand VS \ {wS} and the correlation between wTand VT \ {wT }.In the third step, CL-SCL identifies correlationsacross pivots by computing the singular value de-composition of the |V |?m-dimensional parametermatrix W, W =[w1 .
.
.
wm]:U?VT = SVD(W)Recall that W encodes the correlation structurebetween pivot and non-pivot words in the formof multiple linear classifiers.
Thus, the columnsof U identify common substructures among theseclassifiers.
Choosing the columns of U associatedwith the largest singular values yields those sub-structures that capture most of the correlation inW.
We define ?
as those columns of U that areassociated with the k largest singular values:?
= UT[1:k, 1:|V |]Algorithm 1 summarizes the three steps of CL-SCL.
At training and test time, we apply the pro-jection ?
to each input instance x.
The vector v?that minimizes the regularized training error forDS in the projected space is defined as follows:v?
= argminv?Rk?
(x,y)?DSL(y, vT ?x) +?2?v?2 (2)The resulting classifier fST , which will operatein the cross-lingual setting, is defined as follows:fST (x) = sign(v?T ?x)4.1 An Alternative View of CL-SCLAn alternative view of cross-language structuralcorrespondence learning is provided by the frame-work of structural learning (Ando and Zhang,2005a).
The basic idea of structural learning isAlgorithm 1 CL-SCLInput: Labeled source data DSUnlabeled data Du = DS,u ?DT ,uParameters: m, k, ?, and ?Output: k ?
|V |-dimensional matrix ?1.
SELECTPIVOTS(DS ,m)VP = MUTUALINFORMATION(DS )P ?
= {{wS , TRANSLATE(wS)} | wS ?
VP }P = CANDIDATEELIMINATION(P ?, ?)2.
TRAINPIVOTPREDICTORS(Du,P )for l = 1 to m doDl = {(MASK(x, pl), IN(x, pl)) | x ?
Du}wl= argminw?R|V |?
(x,y)?DlL(y,wTx)) + ?2 ?w?2end forW =[w1 .
.
.
wm]3.
COMPUTESVD(W, k)U?VT = SVD(W)?
= UT[1:k, 1:|V |]output {?
}to constrain the hypothesis space, i.e., the space ofpossible weight vectors, of the target task by con-sidering multiple different but related predictiontasks.
In our context these auxiliary tasks are rep-resented by the pivot predictors, i.e., the columnsof W. Each column vector wl can be consideredas a linear classifier which performs well in bothlanguages.
I.e., we regard the column space of Was an approximation to the subspace of bilingualclassifiers.
By computing SVD(W) one obtainsa compact representation of this column space inthe form of an orthonormal basis ?T .The subspace is used to constrain the learning ofthe target task by restricting the weight vector w tolie in the subspace defined by ?T .
Following Andoand Zhang (2005a) and Quattoni et al (2007) wechoose w for the target task to be w?
= ?Tv?,where v?
is defined as follows:v?
= argminv?Rk?
(x,y)?DSL(y, (?Tv)Tx) +?2?v?2 (3)Since (?Tv)T = vT ?
it follows that this viewof CL-SCL corresponds to the induction of a newfeature space given by Equation 2.11225 ExperimentsWe evaluate CL-SCL for the task of cross-language sentiment classification using Englishas source language and German, French, andJapanese as target languages.
Special emphasis isput on corpus construction, determination of upperbounds and baselines, and a sensitivity analysis ofimportant hyperparameters.
All data described inthe following is publicly available from our projectwebsite.15.1 Dataset and PreprocessingWe compiled a new dataset for cross-languagesentiment classification by crawling product re-views from Amazon.
{de | fr | co.jp}.
The crawledpart of the corpus contains more than 4 millionreviews in the three languages German, French,and Japanese.
The corpus is extended with En-glish product reviews provided by Blitzer et al(2007).
Each review contains a category label,a title, the review text, and a rating of 1-5 stars.Following Blitzer et al (2007) a review with >3(<3) stars is labeled as positive (negative); otherreviews are discarded.
For each language the la-beled reviews are grouped according to their cate-gory label, whereas we restrict our experiments tothree categories: books, dvds, and music.Since most of the crawled reviews are posi-tive (80%), we decide to balance the number ofpositive and negative reviews.
In this study, weare interested in whether the cross-lingual repre-sentation induced by CL-SCL captures the differ-ence between positive and negative reviews; bybalancing the reviews we ensure that the imbal-ance does not affect the learned model.
Balancingis achieved by deleting reviews from the major-ity class uniformly at random for each language-specific category.
The resulting sets are split intothree disjoint, balanced sets, containing trainingdocuments, test documents, and unlabeled docu-ments; the respective set sizes are 2,000, 2,000,and 9,000-50,000.
See Table 1 for details.For each of the nine target-language-category-combinations a text classification task is createdby taking the training set of the product category inS and the test set of the same product category inT .
A document d is described as normalized fea-ture vector x under a unigram bag-of-words docu-ment representation.
The morphological analyzer1http://www.webis.de/research/corpora/webis-cls-10/MeCab is used for Japanese word segmentation.25.2 ImplementationThroughout the experiments linear classifiers areemployed; they are trained by minimizing Equa-tion (1), using a stochastic gradient descent (SGD)algorithm.
In particular, the learning rate schedulefrom PEGASOS is adopted (Shalev-Shwartz et al,2007), and the modified Huber loss, introduced byZhang (2004), is chosen as loss function L.3SGD receives two hyperparameters as input: thenumber of iterations T , and the regularization pa-rameter ?.
In our experiments T is always set to106, which is about the number of iterations re-quired for SGD to converge.
For the target task,?
is determined by 3-fold cross-validation, testingfor ?
all values 10?i, i ?
[0; 6].
For the pivot pre-diction task, ?
is set to the small value of 10?5, inorder to favor model accuracy over generalizabil-ity.The computational bottleneck of CL-SCL is theSVD of the dense parameter matrix W. Here wefollow Blitzer et al (2006) and set the negativevalues in W to zero, which yields a sparse repre-sentation.
For the SVD computation the Lanczosalgorithm provided by SVDLIBC is employed.4We investigated an alternative approach to obtaina sparse W by directly enforcing sparse pivot pre-dictors wl through L1-regularization (Tsuruoka etal., 2009), but didn?t pursue this strategy due tounstable results.
Since SGD is sensitive to fea-ture scaling the projection ?x is post-processed asfollows: (1) Each feature of the cross-lingual rep-resentation is standardized to zero mean and unitvariance, where mean and variance are estimatedon DS ?Du.
(2) The cross-lingual document rep-resentations are scaled by a constant ?
such that|DS |?1?x?DS???x?
= 1.We use Google Translate as word translation or-acle, which returns a single translation for eachquery word.5 Though such a context free transla-tion is suboptimum we do not sanitize the returnedwords to demonstrate the robustness of CL-SCLwith respect to translation noise.
To ensure the re-producibility of our results we cache all queries tothe translation oracle.2http://mecab.sourceforge.net3Our implementation is available at http://github.com/pprett/bolt4http://tedlab.mit.edu/?dr/SVDLIBC/5http://translate.google.com1123T CategoryUnlabeled data Upper Bound CL-MT CL-SCL|DS,u| |DT ,u| ?
?
?
?
?
?
?
?books 50,000 50,000 83.79 (?0.20) 79.68 (?0.13) 4.11 79.50 (?0.33) 4.29German dvd 30,000 50,000 81.78 (?0.27) 77.92 (?0.25) 3.86 76.92 (?0.07) 4.86music 25,000 50,000 82.80 (?0.13) 77.22 (?0.23) 5.58 77.79 (?0.02) 5.00books 50,000 32,000 83.92 (?0.14) 80.76 (?0.34) 3.16 78.49 (?0.03) 5.43French dvd 30,000 9,000 83.40 (?0.28) 78.83 (?0.19) 4.57 78.80 (?0.01) 4.60music 25,000 16,000 86.09 (?0.13) 75.78 (?0.65) 10.31 77.92 (?0.03) 8.17books 50,000 50,000 79.39 (?0.27) 70.22 (?0.27) 9.17 73.09 (?0.07) 6.30Japanese dvd 30,000 50,000 81.56 (?0.28) 71.30 (?0.28) 10.26 71.07 (?0.02) 10.49music 25,000 50,000 82.33 (?0.13) 72.02 (?0.29) 10.31 75.11 (?0.06) 7.22Table 1: Cross-language sentiment classification results.
For each task, the number of unlabeled docu-ments from S and T is given.
Accuracy scores (mean ?
and standard deviation ?
of 10 repetitions ofSGD) on the test set of the target language T are reported.
?
gives the difference in accuracy to theupper bound.
CL-SCL uses m = 450, k = 100, and ?
= 30.5.3 Upper Bound and BaselineTo get an upper bound on the performance ofa cross-language method we first consider themonolingual setting.
For each target-language-category-combination a linear classifier is learnedon the training set and tested on the test set.
Theresulting accuracy scores are referred to as upperbound; it informs us about the expected perfor-mance on the target task if training data in the tar-get language is available.We chose a machine translation baselineto compare CL-SCL to another cross-languagemethod.
Statistical machine translation technol-ogy offers a straightforward solution to the prob-lem of cross-language text classification and hasbeen used in a number of cross-language senti-ment classification studies (Hiroshi et al, 2004;Bautin et al, 2008; Wan, 2009).
Our baselineCL-MT works as follows: (1) learn a linear clas-sifier on the training data, and (2) translate the testdocuments into the source language,6 (3) predict6Again we use Google Translate.the sentiment polarity of the translated test doc-uments.
Note that the baseline CL-MT does notmake use of unlabeled documents.5.4 Performance Results and SensitivityTable 1 contrasts the classification performance ofCL-SCL with the upper bound and with the base-line.
Observe that the upper bound does not ex-hibit a great variability across the three languages.The average accuracy is about 82%, which is con-sistent with prior work on monolingual sentimentanalysis (Pang et al, 2002; Blitzer et al, 2007).The performance of CL-MT, however, differs con-siderably between the two European languagesand Japanese: for Japanese, the average differencebetween the upper bound and CL-MT (9.9%) isabout twice as much as for German and French(5.3%).
This difference can be explained by thefact that machine translation works better for Eu-ropean than for Asian languages such as Japanese.Recall that CL-SCL receives three hyperparam-eters as input: the number of pivots m, the di-mensionality of the cross-lingual representation k,PivotEnglish GermanSemantics Pragmatics Semantics Pragmatics{beautifulS , scho?nT } amazing, beauty, picture, pattern, poetry, scho?ner (more beautiful), bilder (pictures),lovely photographs, paintings traurig (sad) illustriert (illustrated){boringS , langweiligT } plain, asleep, characters, pages, langatmig (lengthy), charaktere (characters),dry, long story einfach (plain), handlung (plot),entta?uscht (disappointed) seiten (pages)Table 2: Semantic and pragmatic correlations identified for the two pivots {beautifulS , scho?nT } and{boringS , langweiligT } in English and German book reviews.1124Figure 2: Influence of unlabeled data and hyperparameters on the performance of CL-SCL.
The rowsshow the performance of CL-SCL as a function of (1) the ratio between labeled and unlabeled documents,(2) the number of pivots m, and (3) the dimensionality of the cross-lingual representation k.and the minimum support ?
of a pivot in DS,uand DT ,u.
For comparison purposes we use fixedvalues of m = 450, k = 100, and ?
= 30.The results show the competitiveness of CL-SCLcompared to CL-MT.
Although CL-MT outper-forms CL-SCL on most tasks for German andFrench, the difference in accuracy can be consid-ered as small (<1%); merely for French book andmusic reviews the difference is about 2%.
ForJapanese, however, CL-SCL outperforms CL-MTon most tasks with a difference in accuracy ofabout 3%.
The results indicate that if the dif-ference between the upper bound and CL-MT islarge, CL-SCL can circumvent the loss in accu-racy.
Experiments with language-specific settingsrevealed that for Japanese a smaller number of piv-ots (150<m<250) performs significantly better.Thus, the reported results for Japanese can be con-sidered as pessimistic.Primarily responsible for the effectiveness ofCL-SCL is its task specificity, i.e., the ways inwhich context contributes to meaning (pragmat-ics).
Due to the use of task-specific, unlabeleddata, relevant characteristics are captured by thepivot classifiers.
Table 2 exemplifies this with twopivots for German book reviews.
The rows of thetable show those words which have the highestcorrelation with the pivots {beautifulS , scho?nT }and {boringS , langweiligT }.
We can distinguishbetween (1) correlations that reflect similar mean-ing, such as ?amazing?, ?lovely?, or ?plain?, and(2) correlations that reflect the pivot pragmaticswith respect to the task, such as ?picture?, ?po-etry?, or ?pages?.
Note in this connection that au-thors of book reviews tend to use the word ?beau-tiful?
to refer to illustrations or poetry.
While thefirst type of word correlations can be obtained bymethods that operate on parallel corpora, the sec-ond type of correlation requires an understandingof the task-specific language use.In the following we discuss the sensitivity ofeach hyperparameter in isolation while keeping1125the others fixed atm = 450, k = 100, and ?
= 30.The experiments are illustrated in Figure 2.Unlabeled Data The first row of Figure 2 showsthe performance of CL-SCL as a function of theratio of labeled and unlabeled documents.
A ratioof 1 means that |DS,u| = |DT ,u| = 2,000, whilea ratio of 25 corresponds to the setting of Table 1.As expected, an increase in unlabeled documentsresults in an improved performance, however, weobserve a saturation at a ratio of 10 across all ninetasks.Number of Pivots The second row shows the in-fluence of the number of pivots m on the perfor-mance of CL-SCL.
Compared to the size of thevocabularies VS and VT , which is in 105 orderof magnitude, the number of pivots is very small.The plots show that even a small number of piv-ots captures a significant amount of the correspon-dence between S and T .Dimensionality of the Cross-Lingual Represen-tation The third row shows the influence of thedimensionality of the cross-lingual representationk on the performance of CL-SCL.
Obviously theSVD is crucial to the success of CL-SCL if mis sufficiently large.
Observe that the value of kis task-insensitive: a value of 75<k<150 worksequally well across all tasks.6 ConclusionThe paper introduces a novel approach to cross-language text classification, called cross-languagestructural correspondence learning.
The approachuses unlabeled documents along with a wordtranslation oracle to automatically induce task-specific, cross-lingual correspondences.
Our con-tributions include the adaptation of SCL for theproblem of cross-language text classification anda well-founded empirical analysis.
The analy-sis covers performance and robustness issues inthe context of cross-language sentiment classifica-tion with English as source language and German,French, and Japanese as target languages.
The re-sults show that CL-SCL is competitive with state-of-the-art machine translation technology whilerequiring fewer resources.Future work includes the extension of CL-SCLtowards a general approach for cross-lingual adap-tation of natural language processing technology.ReferencesRie-K. Ando and Tong Zhang.
2005a.
A frameworkfor learning predictive structures from multiple tasksand unlabeled data.
J. Mach.
Learn.
Res., 6:1817?1853.Rie-K. Ando and Tong Zhang.
2005b.
A high-performance semi-supervised learning method fortext chunking.
In Proceedings of ACL-05, pages 1?9, Ann Arbor.Mikhail Bautin, Lohit Vijayarenu, and Steven Skiena.2008.
International sentiment analysis for news andblogs.
In Proceedings of ICWSM-08, pages 19?26,Seattle.Nuria Bel, Cornelis H. A. Koster, and Marta Villegas.2003.
Cross-lingual text categorization.
In Proceed-ings of ECDL-03, pages 126?139, Trondheim.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural corre-spondence learning.
In Proceedings of EMNLP-06,pages 120?128, Sydney.John Blitzer, Mark Dredze, and Fernando Pereira.2007.
Biographies, bollywood, boom-boxes andblenders: Domain adaptation for sentiment classi-fication.
In Proceedings of ACL-07, pages 440?447,Prague.Hal Daume?
III.
2007.
Frustratingly easy domain adap-tation.
In Proceedings of ACL-07, pages 256?263,Prague.Susan T. Dumais, Todd A. Letsche, Michael L.Littman, and Thomas K. Landauer.
1997.
Auto-matic cross-language retrieval using latent semanticindexing.
In AAAI Symposium on CrossLanguageText and Speech Retrieval.Jenny-R. Finkel and Christopher-D. Manning.
2009.Hierarchical bayesian domain adaptation.
In Pro-ceedings of HLT/NAACL-09, pages 602?610, Boul-der.Blaz?
Fortuna and John Shawe-Taylor.
2005.
The useof machine translation tools for cross-lingual textmining.
In Proceedings of the ICML Workshop onLearning with Multiple Views.Alfio Gliozzo and Carlo Strapparava.
2005.
Cross lan-guage text categorization by acquiring multilingualdomain models from comparable corpora.
In Pro-ceedings of the ACL Workshop on Building and Us-ing Parallel Texts.Alfio Gliozzo and Carlo Strapparava.
2006.
Exploit-ing comparable corpora and bilingual dictionariesfor cross-language text categorization.
In Proceed-ings of ACL-06, pages 553?560, Sydney.Kanayama Hiroshi, Nasukawa Tetsuya, and WatanabeHideo.
2004.
Deeper sentiment analysis usingmachine translation technology.
In Proceedings ofCOLING-04, pages 494?500, Geneva.1126Jing Jiang and Chengxiang Zhai.
2007.
A two-stageapproach to domain adaptation for statistical classi-fiers.
In Proceedings of CIKM-07, pages 401?410,Lisbon.Victor Lavrenko, Martin Choquette, and W. BruceCroft.
2002.
Cross-lingual relevance models.
InProceedings of SIGIR-02, pages 175?182, Tampere.Yaoyong Li and John S. Taylor.
2007.
Advancedlearning algorithms for cross-language patent re-trieval and classification.
Inf.
Process.
Manage.,43(5):1183?1199.Xiao Ling, Gui-R. Xue, Wenyuan Dai, Yun Jiang,Qiang Yang, and Yong Yu.
2008.
Can chinese webpages be classified with english data source?
In Pro-ceedings of WWW-08, pages 969?978, Beijing.Douglas W. Oard.
1998.
A comparative study of queryand document translation for cross-language infor-mation retrieval.
In Proceedings of AMTA-98, pages472?483, Langhorne.J.
Scott Olsson, Douglas W. Oard, and Jan Hajic?.
2005.Cross-language text classification.
In Proceedingsof SIGIR-05, pages 645?646, Salvador.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification us-ing machine learning techniques.
In Proceedings ofEMNLP-02, pages 79?86, Philadelphia.Martin Potthast, Benno Stein, and Maik Anderka.2008.
A wikipedia-based multilingual retrievalmodel.
In Proceedings of ECIR-08, pages 522?530,Glasgow.Ariadna Quattoni, Michael Collins, and Trevor Darrell.2007.
Learning visual representations using imageswith captions.
In Proceedings of CVPR-07, pages1?8, Minneapolis.Leonardo Rigutini, Marco Maggini, and Bing Liu.2005.
An em based training algorithm for cross-language text categorization.
In Proceedings of WI-05, pages 529?535, Compie`gne.Shai Shalev-Shwartz, Yoram Singer, and Nathan Sre-bro.
2007.
Pegasos: Primal estimated sub-gradientsolver for svm.
In Proceedings of ICML-07, pages807?814, Corvalis.Yoshimasa Tsuruoka, Jun?ichi Tsujii, and Sophia Ana-niadou.
2009.
Stochastic gradient descent trainingfor l1-regularized log-linear models with cumulativepenalty.
In Proceedings of ACL/AFNLP-09, pages477?485, Singapore.Xiaojun Wan.
2009.
Co-training for cross-lingual sentiment classification.
In Proceedings ofACL/AFNLP-09, pages 235?243, Singapore.Tong Zhang.
2004.
Solving large scale linear predic-tion problems using stochastic gradient descent al-gorithms.
In Proceedings of ICML-04, pages 116?124, Banff.1127
