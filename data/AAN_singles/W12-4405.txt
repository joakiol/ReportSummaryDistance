Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 38?46,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsAutomatically generated NE tagged corpora for English and HungarianDa?vid Ma?rk NemeskeyResearch Institute forComputer Science and AutomationHungarian Academy of SciencesH-1111 Kende utca 13-17, Budapestnemeskey.david@sztaki.mta.huEszter SimonResearch Institute for LinguisticsHungarian Academy of SciencesH-1068 Benczu?r utca 33, Budapestsimon.eszter@nytud.mta.huAbstractSupervised Named Entity Recognizers requirelarge amounts of annotated text.
Since manualannotation is a highly costly procedure, reduc-ing the annotation cost is essential.
We presenta fully automatic method to build NE anno-tated corpora from Wikipedia.
In contrast torecent work, we apply a new method, whichmaps the DBpedia classes into CoNLL NEtypes.
Since our method is mainly language-independent, we used it to generate corporafor English and Hungarian.
The corpora arefreely available.1 IntroductionNamed Entity Recognition (NER), the task of iden-tifying Named Entities (NEs) in unstructured textsand classifying them into pre-selected classes, isone of the most important subtasks in many NLPtasks, such as information retrieval, information ex-traction or machine translation.
The NER taskwas introduced with the 6th Message UnderstandingConference (MUC) in 1995 (Grishman and Sund-heim, 1996).
In MUC shared tasks the NER con-sists of three subtasks: entity names, temporal andnumber expressions.
Although there is a generalagreement in the NER community about the inclu-sion of temporal expressions and some numericalexpressions, the most studied types are names ofpersons, locations and organizations.
The fourthtype, called ?miscellaneous?, was introduced in theCoNLL NER tasks in 2002 (Tjong Kim Sang, 2002)and 2003 (Tjong Kim Sang and De Meulder, 2003),and includes proper names falling outside the threeclassic types.
Since then, MUC and CoNLL datasetsand annotation schemes have been the major stan-dards applied in the field of NER.The standard datasets are highly domain-specific(mostly newswire) and are restricted in size.
Re-searchers attempting to merge these datasets to geta bigger training corpus are faced with the prob-lem of combining different tagsets and annotationschemes.
Manually annotating large amounts oftext with linguistic information is a time-consuming,highly skilled and delicate job, but large, accuratelyannotated corpora are essential for building robustsupervised machine learning NER systems.
There-fore, reducing the annotation cost is a key challenge.One approach is to generate the resources auto-matically, another one is to use collaborative anno-tation and/or collaboratively constructed resources,such as Wikipedia, Wiktionary, Linked Open Data,or DBpedia.
In this paper we combine these ap-proaches by automatically generating freely avail-able NE tagged corpora from Wikipedia.The paper is structured as follows.
In Section 2we give an overview of related work.
Section 3contains a description of our method, and Section4 shows how it is applied to Hungarian.
The corpusformat is described in Section 5.
In Section 6 wepresent experiments and results on the newly gener-ated datasets.
Section 7 concludes the paper with asummary.2 Wikipedia and NERWikipedia (WP, see http://wikipedia.org),a free multilingual Internet encyclopedia, writtencollaboratively by volunteers, is a goldmine of infor-38mation: at the time of writing, WP contains about 21million interlinked articles.
Of these, 3,903,467 areEnglish, and 212,120 are Hungarian.
WP has beenapplied to several NLP tasks such as word sense dis-ambiguation, ontology and thesaurus building, andquestion answering (see Medelyan et al (2009) fora survey).
It is recognized as one of the largestavailable collections of entities, and also as a re-source that can improve the accuracy of NER.
Themost obvious utilization of WP for NER is extract-ing gazetteers containing person names, locations ororganizations (e.g.
Toral and Mun?oz (2006)).
Cre-ating dictionaries of entities is also a common stepof NE disambiguation (Bunescu and Pasca, 2006;Cucerzan, 2007).
Both supervised and unsuper-vised NER systems use such lists, see e.g.
Nadeauet al (2006) The knowledge embodied in WP mayalso be incorporated in NER learning as features,e.g.
Kazama and Torisawa (2007) showed that au-tomatic extraction of category labels from WP im-proves the accuracy of a supervised NE tagger.Another approach to improve NER with WP isthe automatic creation of training data.
Richmanand Schone (2008) built corpora for less commonlytaught languages annotated with NE tags.
Theyused the inherent category structure of WP to de-termine the NE type of a proposed entity.
Nothmanet al (2008) used a similar method to create a NEannotated text in English.
They transformed the WPlinks into NE annotations by classifying the targetarticles into standard entity classes.
Their approachto classification is based primarily on category headnouns and the opening sentences of articles wheredefinitions are often given.Our approach to recognize and classify NEs incorpora generated from WP was to map the DBpediaontology classes to standard NE tags and assignthese to WP entities (see more details in Section3.1).
Except for the Semantically Annotated Snap-shot of the English WP (SASWP) (Zaragoza et al,2007), no such automatically built corpora are freelyavailable.
SASWP provides a wide range of lin-guistic information: POS tags, dependency labels,WordNet super senses and NE annotation accord-ing to WSJ and CoNLL tagsets.
Even though theSASWP NEs were tagged by the best available opensource taggers, the tags provided here, being basedon the manual judgement of thousands of WP volun-teers, are more reliable.
Given the huge number ofWP articles we can build sufficiently large corporafor less resourced languages as well, as our methodis largely language-independent.
We demonstratethis on Hungarian, a highly agglutinative language,with free word order and other typological char-acteristics detailed later in Section 4.
There aresmaller, manually annotated CoNLL-style datasets,but the one presented here is the first automaticallyNE annotated corpus for Hungarian.3 Creating the English CorpusOur goal is to create a large NE annotated corpus,automatically generated from WP articles.
We fol-lowed a similar path to Nothman et al (2008) andbroke down the process into four steps:1.
Classify WP articles into entity classes.2.
Parse WP and split articles into sentences.3.
Label named entities in the text.4.
Select the sentences for inclusion in the corpus.In this section, we describe how these steps wereimplemented.
This section explains the general ap-proach and its execution for English; Section 4 de-scribes how the idea is adapted to Hungarian.3.1 Articles as EntitiesMany authors, such as Kazama and Torisawa (2007)and Nothman et al (2008) used semi-supervisedmethods based on WP categories and text to clas-sify articles into NE types.
To avoid the inevitableclassification errors, we obtain entity type informa-tion from the DBpedia knowledge base (Bizer et al,2009), which presents type, properties, home pages,etc.
information about pages in WP in structuredform.
With DBpedia we have high precision infor-mation about entity types at the expense of recall:of the 3,903,467 English WP pages, 1,470,293 arecovered by DBpedia (as of 18 March, 2012).The types in DBpedia are organized into a classhierarchy, available as an OWL1 ontology contain-ing 320 frequent entity categories, arranged intoa taxonomy under the base class owl:Thing.1http://www.w3.org/TR/owl-ref/39Most of the classes belong to the 6 largest sub-hierarchies: Person, Organisation, Event,Place, Species and Work.
The taxonomy israther flat: the top level contains 44 classes and thereare several nodes with a branching factor of 20.The type of entities is extracted automaticallyfrom WP categories.
However, the mapping be-tween WP categories and classes in the DBpediaontology is manually defined.
This, together withthe fact that the existence of the reference ontologyprevents the proliferation of categories observable inWP (Bizer et al, 2009), ensures that type informa-tion in DBpedia can be considered gold quality.From the available NER annotation standards weelected to use the CoNLL (Tjong Kim Sang and DeMeulder, 2003) NE types.
It is not difficult to seethe parallels between the DBpedia sub-hierarchiesPerson, Organisation and Place and theCoNLL NE types PER, ORG and LOC.
The fourthcategory, MISC is more elusive; according to theCoNLL NER annotation guide2, the sub-hierarchiesEvent and Work belong to this category, as well asvarious other classes outside the main hierarchies.While the correspondence described above holdsfor most classes in the sub-hierarchies, thereare some exceptions.
For instance, the classSportsLeague is part of the Organisationsub-hierarchy, but according to the CoNLL anno-tation scheme, they should be tagged as MISC.
Toavoid misclassification, we created a file of DBpediaclass?NE category mappings.
Whenever an entity isevaluated, we look up its class and the ancestors ofits class, and assign to it the category of the classthat matches it most closely.
If no match is found,the entity is tagged with O.As of version 3.7, the DBpedia ontology allowsmultiple superclasses, making a directed acyclicgraph3.
Since selecting the right superclass, andhence, CoNLL tag, for classes with more than oneparent cannot be reliably done automatically, theclass-to-category mapping had to be determinedmanually.
The only such class in version 3.7,Library, can be traced back to both Place andOrganisation; its CoNLL tag is LOC.
Using themapping thus created, we compile a list that contains2http://www.cnts.ua.ac.be/conll2003/ner/annotation.txt3http://blog.dbpedia.org/2011/09/11/dbpedia-37-released-including-15-localized-editionsall entities in DBpedia tagged with the appropriateCoNLL category.We note here that our method can be triviallymodified to work with any tagset compatible withthe DBpedia ontology (indeed, the DBpedia classesdefine a NE tagset themselves), but we leave the ex-ploration of these possibilities for future work.3.2 Parsing WikipediaWP is a rich source of information; in addition tothe article text, a huge amount of data is embeddedin infoboxes, templates, and the category structure.Our task requires only the links between the articlesand the article text.
In addition to in-article links,our method takes advantage of the redirect and in-terlanguage links, available as SQL dumps.
TheEnglish corpus is based on the WP snapshot as ofJanuary 15, 2011.
The XML files were parsed bythe mwlib parser4, the raw text was tokenized by amodified version of the Punkt sentence and word to-kenizers (Kiss and Strunk, 2002).
For lemmatizationwe used the Wordnet Lemmatizer in NLTK (Bird etal., 2009), and for part-of-speech tagging the Hun-POS tagger (Hala?csy et al, 2007).3.3 Named Entity LabelingIn order to automatically prepare sentences whereNEs are accurately tagged, two tasks need to be per-formed: identifying entities in the sentence and tag-ging them with the correct tag.
Sentences for whichaccurate tagging could not be accomplished must beremoved from the corpus.
Our approach is based onthe work of Nothman et al (2008).
The WP cross-references found in the article text are used to iden-tify entities.
We assume that individual WP articlesdescribe NEs.
A link to an article can then be per-ceived as a mapping that identifies its anchor textwith a particular NE.The discovered entities are tagged with theCoNLL label assigned to them in the entity list ex-tracted from DBpedia.
If the link target is not inthe entity list, or the link points to a disambiguationpage, we cannot determine the type of the entity, andtag it as UNK for subsequent removal from the cor-pus.
Links to redirect pages are resolved to point in-stead to the redirect target, after which they are han-4http://code.pediapress.com40dled as regular cross-references.
Finally, sentenceswith UNK links in them are removed from the cor-pus.The following sub-sections describe how themethod explained above can be improved to in-crease precision, sentence coverage and to accountfor peculiarities in the English orthography and theCoNLL guidelines.3.3.1 Non-entity LinksStrictly speaking, our original assumption ofequating WP articles with NEs is not valid: manypages describe common nouns (Book, Aircraft),calendar-related concepts (March 15, 2007), or otherconcepts that fall outside the scope of NER.
To in-crease sentence coverage, we modified the algorithmto prevent it from misclassifying links to these pagesas unknown entities and discarding the sentence.Common noun links are filtered by POS tags; if alink contains no NNPs, it is ignored.Time expression links require special attention, be-cause dates and months are often linked to therespective WP pages.
We circumvented thisproblem by compiling a list of calendar-relatedpages and adding them to the main entity listtagged with the CoNLL category O.Lowercase links for entities referred to by commonnouns, such as republic to Roman Republic arenot considered NEs and are ignored.3.3.2 Unmarked EntitiesIn a WP article, typically only the first occurrenceof a particular entity is linked to the correspondingpage.
Subsequent mentions are unmarked and oftenincomplete ?
e.g.
family names are used instead offull names.
To account for such mentions, we ap-ply Nothman?s (2008) solution.
For each page, wemaintain a list of entities discovered in the page sofar and try to associate capitalized words in the ar-ticle text with these entities.
We augment the listwith the aliases of every entity, such as titles of redi-rect pages that target it, the first and last names incase of a PER entity and any numbers in the name.If the current page is a NE, the title and its aliasesare added to the list as well; moreover, as WP usu-ally includes the original name of foreign entities inthe article text, localized versions of the title are alsoadded to the list as aliases.
Nothman?s solution useda trie to store the entity list, while we use a set, withmore alias types than what he used.
We expect moreprecise tagging from our slightly more rigorous so-lution.3.3.3 Special CasesDerived words According to the CoNLL guide-lines, words derived from NEs are tagged asMISC.
We complied with this rule by taggingeach entity whose head is not a noun, as wellas when the link?s anchor text is not containedin the entity?s name, as MISC.
The most promi-nent example for such entities are nationalities,which can be linked to their home country, aLOC; e.g.
Turkish to Turkey.
Our solution as-signs the correct tag to these entities.First word in a sentence As first words are alwayscapitalized, labeling them is difficult if they areunlinked and not contained in the entity aliasset.
We base the decision on the POS tag ofthe first word: if it is NNP, we tag it as UNK;otherwise, O.Reference cleansing Page titles and anchor textsmay contain more than just the entity name.Personal titles are part of the entity name inWP, but not in CoNLL, and punctuation marksaround the entity may become part of the linkby mistake.
We tag all punctuation marks afterthe entity name as O.To handle personal titles, we extracted a listfrom the WP page List of titles, which con-tains titles in many languages.
We manuallyremoved all titles that also function as givennames, such as Regina.
If a link to a PER orUNK entity, or an unlinked entity starts with, orconsists solely of a title in the list, we tag thewords that make up the title as O.Incidental capitalization Various non-NNP wordsin English are capitalized: names of months,the pronoun I, and non-entity acronyms such asRSVP.
While the latter two types are unlikely toappear in WP text, we assembled a list of thesewords and tag them as O unless they are part ofthe alias set.413.4 Sentence FilteringAs mentioned above, sentences with words taggedas UNK are discarded.
Furthermore, there are manyincomplete sentences in the WP text: image cap-tions, enumerations items, contents of table cells,etc.
On the one hand, these sentence fragments maybe of too low quality to be of any use in the tra-ditional NER task.
On the other hand, they couldprove to be invaluable when training a NER tag-ger for User Generated Content, which is known tobe noisy and fragmented.
As a compromise we in-cluded these fragments in the corpus, but labelledthem as ?low quality?, so that users of the corpuscan decide whether they want to use them or not.
Asentence is labelled as such if it either lacks a punc-tuation mark at the end, or it contains no finite verb.4 Creating the Hungarian CorpusThe procedure described in the previous section wasused to generate the Hungarian corpus as well.
How-ever, typological differences posed several prob-lems.
In this section we describe the differences be-tween the two languages related to labeling NEs, andthe changes they prompted in the method.4.1 Parsing the Hungarian WikipediaAlthough Hungarian is reckoned to be a less re-sourced language, and it is not supported in NLTK,several high quality language processing tools havebeen developed for Hungarian in recent years.
Fortokenization and sentence segmentation we used anin-house statistical tool tailored for Hungarian.
Ithas been trained on the largest manually annotatedHungarian corpus (Csendes et al, 2004), and ithandles the peculiarities of Hungarian orthography,such as the periods placed after numbers in date ex-pressions.
Lemmatization was performed by Hun-Morph (Tro?n et al, 2005) and HunDisambig, anin-house disambiguator to select the right analysisbased on the word context.For the most part Hungarian expresses grammat-ical elements within a word form using affixes.HunMorph outputs KR-codes (Kornai et al, 2004),which, in addition to the POS category, also in-clude inflectional information, making it much bet-ter suited to agglutinative languages than Penn Tree-bank POS tags.
One shortcoming of the KR-code isthat it does not differentiate between common andproper nouns.
Since in Hungarian only proper nounsare capitalized, we can usually decide whether anoun is proper based on the initial letter.
However,this rule can not be used if the noun is at the be-ginning of a sentence, so sentences that begin withnouns have been removed from the corpus.4.2 Named Entity Labeling in HungarianFor well-resourced languages, DBpedia has interna-tionalized chapters, but not for Hungarian.
Instead,the Hungarian entity list comprises of the pages inthe English list that have their equivalents in theHungarian WP.
Two consequences follow.
First,in order to identify which pages denote entities inthe Hungarian WP, an additional step is required,in which the Hungarian equivalents of the Englishpages are added to the entity list.
The English titlesare retained because (due to the medium size of theHungarian WP) in-article links sometimes point toEnglish articles.Second, entities without a page in the English WPare absent from the entity list.
This gives rise to twopotential problems.
One is that compared to En-glish, the list is relatively shorter: the entity/pageratio is 12.12%, as opposed to the 37.66% of the En-glish WP.
The other, since mostly Hungarian people,places and organizations are missing, a NER taggerthat takes the surface forms of words into accountmight be mislead as to the language model of entitynames.
To overcome these problems, the list has tobe extended with Hungarian entity pages that do nothave a corresponding English page.
We leave thisfor future work.To annotate our corpus with NE tags, we choseto follow the annotation guidelines of the largesthuman-annotated NER corpus for Hungarian, theSzeged NER corpus (Szarvas et al, 2006).
It is sim-ilar to CoNLL standards: contains newswire texts,comprises ca.
200,000 tokens, and is annotated withNE class labels in line with the CoNLL annotationscheme.
However, the convention of what consti-tutes a NE is slightly different for Hungarian.4.2.1 Special casesThe Szeged NER guideline relies heavily on therules of capitalization to decide which words shouldbe marked as NEs.
The following concepts are not42train test precision recall F-measureSzeged NER Szeged NER 94.50 94.35 94.43huwiki huwiki 90.64 88.91 89.76huwiki Szeged NER 63.08 70.46 66.57Szeged NER with wikilists Szeged NER 95.48 95.48 95.48Szeged NER with wikitags Szeged NER 95.38 94.92 95.15Table 1: Hungarian results.proper nouns in Hungarian, and thus are not consid-ered as NEs: names of languages, nationalities, reli-gions, political ideologies; adjectives derived fromNEs; names of months, days, holidays; names ofspecial events and wars.There is another special case in Hungarian: unlikein English, the number of compound words is quitelarge, and NEs can also be subject to compounding.In this case the common noun following the NE isjoined with a hyphen, so they constitute one token.However, the joint common noun can modify theoriginal sense of NE, depending on the semanticsof the common noun.
For example in the compoundNobel-d?
?j [?Nobel Prize?]
the common noun changesthe labeling from PER to MISC, while in the caseof the compound WorldCom-botra?ny [?WorldComscandal?]
the NE tag changes from ORG to O. Thesolution to this problem is not obvious, and needsmore investigation.5 Data DescriptionThe corpora are available under the Creative Com-mons Attribution-Sharealike 3.0 Unported License(CC-BY-SA), the same license under which the textof WP is released.
The data files can be freely down-loaded from http://hlt.sztaki.hu.
Thecorpora will also be distributed through the META-SHARE network, which is an open, distributed fa-cility for exchanging and sharing resources, and isone of the lines of action of META-NET, a Networkof Excellence funded by the European Commission.The files are in multitag format.
Content linesare tab separated; there is one column for the tokensplus one column per tagset.
Sentence boundaries aremarked by empty lines.
The linguistic features in-clude the lemmatized form of the word and its POStag.
Two NE tags are included with each word: themost specific DBpedia category it belongs to and theCoNLL NE tag.
While the NE tags can be consid-ered as a ?silver standard?, the linguistic features areprovided on a ?best-effort?
basis.6 EvaluationHaving the obvious advantages, an automaticallygenerated corpus can not serve as a gold standarddataset.
Then what can we do with silver standardcorpora?
They can be very useful for improvingNER in several ways: (a) for less resourced lan-guages, they can serve as training corpora in lieu ofgold standard datasets; (b) they can serve as sup-plementary or independent training sets for domainsdiffering from newswire; (c) they can be sources ofhuge entity lists, and (d) feature extraction.To evaluate our corpora we used a maximum en-tropy NE tagger (Varga and Simon, 2007), whichwas originally developed for labeling NEs in Hun-garian texts, but can be tuned for different languagesas well.
Corpus-specific features (e.g.
NP chunks,WP links) were removed to get better comparability,so the feature set consists of gazetteer features; sen-tence start and end position; Boolean-valued ortho-graphic properties of the word form; string-valuedsurface properties of the word form; and morpho-logical information.We used the CoNLL standard method for evalu-ation.
According to this, an automatic labeling iscorrect if it gives the same start and end position,and the same NE class as the gold standard.
Basedon this, precision and recall can be calculated, andthe F-measure, as usual, the harmonic mean of thesetwo values.6.1 Wikipedia dataOur automatic annotation process retains all of theWP sentences which remained after our two-step fil-tering method, so sentences without NEs are also in-43enwiki enwiki filtered CoNLL huwiki huwiki filtered Szeged NERtoken 60,520,819 21,718,854 302,811 19,108,027 3,512,249 225,963NE 3,169,863 3,169,863 50,758 456,281 456,281 25,896NE density 5.23% 14.59% 16.76% 2.38% 12.99% 11.46%Table 2: Corpus size and NE density.train test precision recall F-measureCoNLL CoNLL 85.13 85.13 85.13enwiki enwiki 72.46 73.33 72.89enwiki CoNLL 56.55 49.77 52.94CoNLL with wikilists CoNLL 86.33 86.35 86.34CoNLL with wikitags CoNLL 85.88 85.94 85.91Table 3: English results.cluded in the corpus.
The rationale behind this isthat we wanted to reserve the original distributionof names in WP as much as possible.
However, afterfurther investigation of the NE density in our corporaand gold standard corpora, we decided not to includethe sentences without NEs in evaluation datasets.Table 2 summarizes the data regarding corpussize and NE density.
The English (enwiki) and theHungarian WP (huwiki) corpora originally have theNE density of 5.23% and 2.38%, respectively.
Incomparison to the gold standard datasets (CoNLL,Szeged NER) these counts are quite low.
It can bedue to the difference between domains: newswirearticles usually contain more NEs, typically ORG.The other reason might be that we discarded sen-tences containing unidentified NEs (cf.
Section 3).6.2 Experiments and resultsThe English WP corpus was evaluated against itselfand a manually annotated English corpus.
Since thefiltered English WP corpus, containing only the sen-tences with NEs, is still very large, our experimentswere performed with a sample of 3.5 million tokens,the size of our filtered Hungarian corpus, dividedinto train and test sets (90%-10%).For English cross-corpus evaluation the CoNLL-2003 corpus was chosen.
As is well known, train-ing and testing across different corpora decreases F-measure.
Domain differences certainly affect NERperformance, and the different annotation schemespose several compatibility problems.
Nothman etal.
(2008) showed that each set of gold standardtraining data performs better on corresponding testsets than on test sets from other sources.
The sit-uation here is similar (see Table 3 for results): theNE tagger trained on WP does not achieve as highperformance tested against CoNLL test set (enwiki-CoNLL) as one trained on its own train set (enwiki-enwiki).WP-derived corpora can also be used for improv-ing NER accuracy in other ways.
First, we collectedgazetteer lists from the corpus for each NE category,which improved the overall F-measure given to theNE tagger training and testing on CoNLL dataset(CoNLL with wikilists).
A second trial was label-ing the CoNLL datasets by the model trained on WPcorpus, and giving these labels as extra features tothe next CoNLL train (CoNLL with wikitags).
Bothmethods result in improved F-measure on CoNLLtest set.Since in Hungarian NE tagging we followed theSzeged NER corpus annotation guidelines, we per-formed the experiments on this dataset.
Hungarianresults are similar to the English ones (see Table 1),the only difference is that F-measures for Hungarianare significantly higher.
This can be due to the factthat the MISC category for Hungarian contains lesstypes of names, thus the inconsistency of this classis smaller (cf.
Section 4).
In contrast to the CoNLLcorpus, the Szeged NER corpus was accurately an-notated with an inter-annotator agreement over 99%.Due to the quite good F-measure of training on44our Hungarian train corpus and testing on the corre-sponding test set, our Hungarian corpus can serveas a training corpus to build NE taggers for non-newswire domains.7 ConclusionWe have presented freely available NE tagged cor-pora for English and Hungarian, fully automati-cally generated from WP.
In contrast to the meth-ods used so far for automatic annotation of NEs inWP texts, we applied a new approach, namely map-ping DBpedia ontology classes to standard CoNLLNE tags, and assigning them to WP entities.
Follow-ing Nothman (2008), the process can be divided intofour main steps: classifying WP articles into entityclasses; parsing WP and splitting articles into sen-tences; labeling NEs in the text; and selecting sen-tences for inclusion in the corpus.The huge amount of WP articles opens the pos-sibility of building large enough corpora for other-wise less resourced languages such as Hungarian.Due to the particularities of Hungarian, some stepsare slightly different, and special linguistic phenom-ena pose several problems related to the NER task tosolve.Automatically generated corpora can be useful forimproving NER in more ways.
We showed thatgazetteer lists extracted from our corpora, and train-ing with extra features given by the model trainedon our corpora, improve F-measure.
Moreover, ourHungarian corpus can serve as a training corpus formore general domains than the classic newswire.AcknowledgementsThis research was supported by OTKA grant no.82333 and the CESAR project under the ICT Pol-icy Support Programme (grant no.
271022).
Theauthors are grateful to Attila Zse?der for his work onWikipedia parsing and to Andra?s Kornai for his in-sightful comments.ReferencesSteven Bird, Ewan Klein, Edward Loper.
2009.
NaturalLanguage Processing with Python.
O?Reilly MediaInc.Christian Bizer, Jens Lehmann, Georgi Kobilarov, So?renAuer, Christian Becker, Richard Cyganiak, SebastianHellmann.
2009.
DBpedia ?
A Crystallization Pointfor the Web of Data.
In: Journal of Web Semantics:Science, Services and Agents on the World Wide Web,Issue 7, pages 154?165.B.
Bunescu and M. Pasca.
2006.
Using encyclope-dic knowledge for named entity disambiguation.
In:Proceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 9?16.Do?ra Csendes, Ja?nos Csirik, Tibor Gyimo?thy.
2004.
TheSzeged Corpus: A POS tagged and Syntactically An-notated Hungarian Natural Language Corpus.
In: Pro-ceedings of TSD 2004, vol.
3206, pages 41?49.S.
Cucerzan.
2007.
Large-scale named entity disam-biguation based on Wikipedia data.
In: Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning.
Prague, Czech Republic,June 2007. pages 708?716.Ralph Grishman and B. Sundheim.
1996.
Message Un-derstanding Conference ?
6.
In: Proc.
InternationalConference on Computational Linguistics.P.
Hala?csy, A. Kornai and Cs.
Oravecz.
2007.
Hunpos ?an open source trigram tagger.
In: Proceedings of the45th Annual Meeting of the Association for Computa-tional Linguistics, pages 209?212.Jun?ichi Kazama and Kentaro Torisawa.
2007.
Exploit-ing Wikipedia as External Knowledge for Named En-tity Recognition.
In: Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 698?707.Tibor Kiss, Jan Strunk.
2006.
Unsupervised Multilin-gual Sentence Boundary Detection.
In: Computa-tional Linguistics, 32 (4): pages 485?525.Andra?s Kornai, Pe?ter Rebrus, Pe?ter Vajda, Pe?ter Hala?csy,Andra?s Rung, Viktor Tro?n.
2004.
A?ltala?nos ce?lu?morfolo?giai elemzo?
kimeneti formalizmusa (The out-put formalism of a general-purpose morphological an-alyzer).
In: Proceedings of the 2nd Hungarian Com-putational Linguistics Conference.Olena Medelyan, David Milne, Catherine Legg, and IanH.
Witten.
2009.
Mining meaning from Wikipedia.International Journal of Human-Computer Studies,67: 716?754.David Nadeau, Peter D. Turney and Stan Matwin.
2006.Unsupervised named entity recognition: Generatinggazetteers and resolving ambiguity.
In: Proceedingsof the 19th Canadian Conference on Artificial Intelli-gence, volume 4013 of LNCS, pages 266?277.Joel Nothman, James R. Curran, and Tara Murphy.
2008.Transforming Wikipedia into Named Entity TrainingData.
In: Proceedings of the Australasian LanguageTechnology Workshop, Vol 6., pages 124?132.45Joel Nothman, Tara Murphy and James R. Curran.
2009.Analysing Wikipedia and Gold-Standard Corpora forNER Training.
In: Proceedings of the 12th Confer-ence of the European Chapter of the ACL, pages 612?620.Alexander E. Richman and Patrick Schone.
2008.
Min-ing Wiki Resources for Multilingual Named EntityRecognition.
In: Proceedings of ACL-08: HLT, pages1?9.Gyo?rgy Szarvas, Richa?rd Farkas, Andra?s Kocsor.
2006.A highly accurate Named Entity corpus for Hungar-ian.
In: Proceedings of International Conference onLanguage Resources and Evaluation.Erik F. Tjong Kim Sang.
2002.
Introduction tothe CoNLL-2002 shared task: Language-independentnamed entity recognition.
In: Proceedings of the 6thConference on Natural Language Learning, pages 1?4, Taipei, Taiwan.Erik F. Tjong Kim Sang and Fien De Meulder.
2003.
In-troduction to the CoNLL-2003 shared task: Language-independent named entity recognition.
In: Pro-ceedings of the 7th Conference on Natural LanguageLearning, pages 142?147, Edmonton, Canada.A.
Toral and R. Mun?oz.
2006.
A proposal to automati-cally build and maintain gazetteers for Named EntityRecognition by using Wikipedia.
In: EACL 2006.Viktor Tro?n, Gyo?rgy Gyepesi, Pe?ter Hala?csy, Andra?s Ko-rnai, La?szlo?
Ne?meth, Da?niel Varga.
2005.
Hunmorph:open source word analysis.
In: Proceedings of theACL 2005 Workshop on Software.Da?niel Varga and Eszter Simon.
2007.
Hungarian namedentity recognition with a maximum entropy approach.Acta Cybernetica, 18: 293?301.H.
Zaragoza and J. Atserias and M. Ciaramita and G.Attardi.
2007.
Semantically Annotated Snapshot ofthe English Wikipedia v.1 (SW1).
http://www.yr-bcn.es/semanticWikipedia46
