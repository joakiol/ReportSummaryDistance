Incremental  Parser Generat ion for Tree Adjo in ing Grammars*Anoop SarkarUn ivers i ty  of Pennsy lvan iaDepar tment  of Computer  and In format ion  Sc ience200 S. 33rd St.,  Ph i lade lph ia  PA 19104-6389, USAanoop?linc, cis.
upenn, eduAbst ractThis paper describes the incrementalgeneration of parse tables for the LR-type parsing of Tree Adjoining Languages(TALs).
The algorithm presented han-dles modifications to the input grammarby updating the parser generated so far.In this paper, a lazy generation of LR-type parsers for TALs is defined in whichparse tables are created by need whileparsing.
We then describe an incrementalparser generator for TALs which respondsto modification of the input grammar byupdating parse tables built so far.1 LR  Parser  Generat ionTree Adjoining Grammars (TAGs) are tree rewrit-ing systems which combine trees with the sin-gle operation of adjoining.
(Schabes and Vijay-Shanker, 1990) describes the construction of an LRparsing algorithm for TAGs 1.
Parser generationhere is taken to be the construction of LR(0) ta-bles (i.e., without any lookahead) for a particularTAG z.
The moves made by the parser can be ex-plained by an automaton which is weakly equivalentto TAGs called Bottom-Up Embedded PushdownAutomata (BEPDA) (Schabes and Vijay-Shanker,1990) 3.
Storage in a BEPDA is a sequence of stacks,*This work is partially supported by NSF grant NSF-STC SBR 8920230 ARPA grant N00014-94 and AROgrant DAAH04-94-G0426.
Thanks to Breck Baldwin,Dania Egedi, Jason Eisner, B. Srinivas and the threeanonymous reviewers for their valuable comments.1 Familiarity with TAGs and their parsing techniquesis assumed throughout he paper, see (Schabes andJoshi, 1991) for an introduction.
We assume that ourdefinition of TAG does not have the substitution pera-tion.
See (Aho et al, 1986) for details on LR parsing.2The algorithm described here can be extended to useSLR(1) tables (Schabes and Vijay-Shanker, 1990).SNote that the LR(0) tables considered here are deter-ministic and hence correspond to a subset of the TALs.Techniques developed in (Tomita, 1986) can be used toresolve nondeterminism in the parser.where new stacks can be introduced above and be-low the top stack in the automaton.
Recognition ofadjunction is equivalent to the unwrap  move shownin Fig.
1.ofFigure 1: Recognition of adjunction in a BEPDA.The LR parser (of (Schabes and Vijay-Shanker,1990)) uses a parsing table and a sequence of stacks(Fig.
1) to parse the input.
The parsing table en-codes the actions taken by the parser as follows (us-ing two GOTO functions):?
Shift  to a new state, pushed onto a new stackwhich appears on top of the current sequenceof stacks.
The current input token is removed.?
Resume R ight  when the parser has reachedright and below a node (in a dotted tree, ex-plained below) on which an auxiliary tree hasbeen adjoined.
The GOTOIoo, function en-codes the proper state such that the string tothe right of the footnode can be recognized.?
Reduce  Root ,  the parser executes an unwrapmove to recognize adjunction (Fig.
1).
Theproper state for the parser after adjunction isgiven by the GOTOr@h, function.?
Accept  and Er ror  functions as in conventionalLR parsing.There are four positions for a dot associated witha symbol in a dotted tree: left above, left below,right below and right above.
A dotted tree has onesuch dotted symbol.
The tree traversal in Fig.
2scans the frontier of the tree from left to right whiletrying to recognize possible adjunctions between the375above and below positions of the dot.
Adjunction ona node is recorded by marking it with an asterisk 4.IB$.
~C.
$Figure 2: Left to right dotted tree traversal.The parse table is built as a finite state automaton(FSA) with each state defined to be a set of dottedtrees.
The closure operations on states in the parsetable are defined in Fig.
3.
All the states in the parsetable must be closed under these operations 5.The FSA is built as follows: in state 0 put all theinitiM trees with the dot left and above the root.The state is then closed.
New states are built bythree transitions: s,{*a} - a sj {a'}, a is a terminalsymbol; s,{A,} #"g~' sj{A'},  fl can adjoin at nodeA; s,{.A} #.
?oo, s j{A,},  A is a footnode.
Entries inthe parse table are determined as follows:?
a shi f t  for each transition in the FSA.?
resume r ight  iff there is a node B .
with thedot right and below it.?
reduce  root  iff there is a rootnode in an aux-iliary tree with the dot right and above it.?
accept  and er ror  with the usual interpreta-tion.The items created in each state before closure appliesare called the kerne ls  of each state in the FSA.
Theinitial trees with the dot left and above the root formthe kernel for state 0.2 Lazy  Parser  Generat ionThe algorithm described so far assumes that theparse table is precompiled before the parser is used.Lazy parser generation generates only those parts ofthe parser that become necessary during actual pars-ing.
The approach is an extension of the algorithmfor CFGs given in (Heering et al, 1990; I-Ieering etM., 1989).
To modify the LR parsing strategy givenearlier we move the closure and computation of tran-sitions from the table generation stage to the LRparser.
The lazy technique xpands a kernel stateonly when the parser, looking at the current input,indicates o.
For example, a TAG and correspond-ing FSA is shown in Fig.
4 (ha rules out adjunctionat a node) 6, Computation of closure and transitionsin the state occurs while parsing as in Fig.
5 which4For example, B*.
This differs from the usual nota-tion for marking a footnode with an asterisk.5Fig.
5 is a partial FSA for the grammar in Fig.
4.6Unexpanded kernel states are marked with a bold-fa~=ed outline, acceptance states with double-lines.is the result of the LR parser expanding the FSA inFig.
4 while parsing the string aec.The modified parse function checks the type of thestate and may expand the kernel states while pars-ing a sentence.
Memory use in the lazy techniqueis greater as the FSA is needed during parsing andparser generation.TAG G: a: Se\] I~"~Snaa S~ FSA: 0Sna eFigure 4: TAG G where L(G) = {anec n) and corre-sponding FSA after lazy parse table generation./I "1 I a s lSna ??
a It, s= s=)?~na ~naa s a"  Sh e r'- cSno Snoa a sS~aa S* a S*"~c - ' c  Sna SnaS" S*"1 I e "es~ a sc~)~na Sna.a S h e .Snaa S* h e .Spa?a S asSr~ S,=~c ~c Sna Sna .~cFigure 5: The FSA after parsing the string aec.y.
ss d /Lb SnaFigure 6: New tree added to G with L(G) ={ anbm ecn d m}3 I nc rementa l  Parser  Generat ionAn incremental parser generator responds to gram-mar updates by throwing away only that informationfrom the FSA of the old grammar that is inconsistentin the updated grammar.
Incremental behaviour isobtained by selecting the states in the parse table af-fected by the change in the grammar and returningthem to their kernel form (i.e.
remove items addedby the closure operations).
The parse table FSA willnow become a disconnected graph.
The lazy parserwill expand the states using the new grammar.
Allstates in the disconnected graph are kept as the lazyparser will reconnect with those states (when thetransitions between states are computed) that areunaffected by the change in the grammar.
Consider376A .... ..... AA .... APreen I Move Dot UpA ..... A Skip Node X~ ~Figure 3: Closure Operations.the addition of a tree to the grammar (deletion willbe similar).?
for an initial tree a return state 0 to kernel formadding a with the dot left and above the rootnode.
Also return all states where a possibleLeft Completion on a can occur to their kernelform.?
for an auxiliary tree fl return all states where apossible Adjunction Prediction on/3 can occurand all states with a fl, ight transition to theirkernel form.For example, the addition of the tree in Fig.
6causes the FSA to fragment into the disconnectedgraph in Fig.
7.
It is crucial to keep the discon-nected states around; consider the re-expansion of asingle state in Fig.
8.
All states compatible with themodified grammar are eventually reused?4 ~Figure 7: The parse table after the addition of 7.The approach presented above causes certainstates to become unreachable from the start state 7.Frequent modifications of a grammar can causemany unreachable states.
A garbage collectionscheme defined in (Heering et al, 1990) can be usedhere which avoids overregeneration by retaining un-reachable states?4 Conc lus ionWhat we have described above is work in progress inimplementing an LR-type parser for a wide-coveragelexiealized grammar of English using TAGs (XTAGGroup, 1995)?
Incremental parser generation allowsthe addition and deletion of elementary trees from arQuantitative r sults on the performance of the algo-rithm presented are forthcoming.f ?S S S ~ 1 ~  2ff ,~.. 3?
t .
t , ,  s~ s~ s,, 8 7.~os~ bs,- bs.?
I6 5.s "b ~~'?"
c S~ S~4."
4asFigure 8: The parse table after expansion of state 0with the modified grammar.TAG without recompilation ofthe parse table for theupdated grammar?
This allows precompilation oftop-down dependencies such as the prediction of ad-junction while having the flexibility given by Earley-style parsers?ReferencesAho, Alfred V., Ravi Sethi and Jeffrey D. Ullman, Com-pilers: Principles, Techniques and Tools, AddisonWesley, Reading, MA, 1986.Heering, Jan, Paul Klint and Jan Rekers, IncrementalGeneration of Parsers, In IEEE Transactions on Soft-ware Engineering, vol.
16, no.
12, pp.
1344-1350, 1990.Heering, Jan, Paul Klint and Jan Rekers, IncrementalGeneration of Parsers, In ACM SIGPLAN Notices(SIGPLAN '89 Conference on Programming Lan-guage Design and Implementation), vol.
24, no.
7, pp.179-191, 1989.Schabes, Yves and K. Vijay-Shanker, Deterministic Leftto Right Parsing of Tree Adjoining Languages, In P8thMeeting of the Association for Computational Lin-guistics (ACL '90), Pittsburgh, PA, 1990.Schabes, Yves and Aravind K. Joshi, Parsing with Lexi-calized Tree Adjoining Grammars, In Tomita, Masaru(ed.)
Current Issues in Parsing Technologies, KluwerAcademic, Dordrecht, The Netherlands, 1991.Tomita, Masaru, Efficient Parsing/or Natural Language:A Fast Algorithm for Practical Systems, Kluwer Aca-demic, Dordrecht, The Netherlands, 1986.XTAG Research Group, A Lexicalized Tree AdjoiningGrammar for English, IRCS Technical Report 95-03,University of Pennsylvania, Philadelphia, PA. 1995.377
