Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 3?10,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsRandom Walk Weighting over SentiWordNet forSentiment Polarity Detection on TwitterA.
Montejo-Ra?ez, E.
Mart?
?nez-Ca?mara, M. T.
Mart?
?n-Valdivia, L. A. Uren?a-Lo?pezUniversity of Jae?nE-23071, Jae?n (Spain){amontejo, emcamara, maite, laurena}@ujaen.esAbstractThis paper presents a novel approach in Sen-timent Polarity Detection on Twitter posts, byextracting a vector of weighted nodes from thegraph of WordNet.
These weights are usedon SentiWordNet to compute a final estima-tion of the polarity.
Therefore, the methodproposes a non-supervised solution that isdomain-independent.
The evaluation over agenerated corpus of tweets shows that thistechnique is promising.1 IntroductionThe birth of Web 2.0 supposed a breaking down ofthe barrier between the consumers and producers ofinformation, i.e.
the Web has changed from a staticcontainer of information into a live environment inwhich any user, in a very simple manner, can pub-lish any type of information.
This simplified meansof publication has led to the rise of several differ-ent websites specialized in the publication of usersopinions.
Some of the most well-known sites in-clude Epinions1, RottenTomatoes2 and Muchocine3,where users express their opinions or criticisms on awide range of topics.
Opinions published on the In-ternet are not limited to certain sites, but rather canbe found in a blog, forum, commercial website orany other site allowing posts from visitors.On of the most representative tools of the Web 2.0are social networks, which allow millions of users1http://epinions.com2http://rottentomatoes.com3http://muchocine.netto publish any information in a simple way and toshare it with their network of contacts or ?friends?.These social networks have also evolved and be-come a continuous flow of information.
A clear ex-ample is the microblogging platform Twitter4.
Twit-ter publishes all kinds of information, disseminatingviews on many different topics: politics, business,economics and so on.
Twitter users regularly pub-lish their comments on a particular news item, a re-cently purchased product or service, and ultimatelyon everything that happens around them.
This hasaroused the interest of the Natural Language Pro-cessing (NLP) community, which has begun to studythe texts posted on Twitter, and more specifically re-lated to Sentiment Analysis (SA) challenges.In this manuscript we present a new approach toresolve the scoring of posts according to the ex-pressed positive or negative degree in the text.
Thispolarity detection problem is resolved by combin-ing SentiWordNet scores with a random walk analy-sis of the concepts found in the text over the Word-Net graph.
In order to validate our non-supervisedapproach, several experiments have been performedto analyze major issues in our method and to com-pare it with other approaches like plain SentiWord-Net scoring or machine learning solutions such asSupport Vector Machines in a supervised approach.The paper is structured as follows: first, an introduc-tion to the polarity detection problem is provided,followed by the description of our approach.
Then,the experimental setup is given with a description ofthe generated corpus and the results obtained.
Fi-nally, conclusions and further work are discussed.4http://twitter.com32 The polarity detection problemIn the literature related to the SA in long text a dis-tinction is made between studies of texts where weassume that the text is a opinion and therefore solelyneed to calculate its polarity, and those in which be-fore measuring polarity it is necessary to determinewhether the text is subjective or objective.
A widestudy on SA can be found in (Pang and Lee, 2008),(Liu, 2010) and (Tsytsarau and Palpanas, 2011).Concerning the study of the polarity in Twitter, mostexperiments assume that tweets5 are subjective.
Oneof the first studies on the classification of the polar-ity in tweets was published in 2009 by (Go et al,2009), in which the authors conducted a supervisedclassification study of tweets in English.Zhang et al (Zhang et al, 2011) proposed a hy-brid method for the classification of the polarity inTwitter, and they demonstrated the validity of theirmethod over an English corpus on Twitter.
The clas-sification is divided into two phases.
The first oneconsists on applying a lexicon-based method.
Inthe second one the authors used the SVM algorithmto determine the polarity.
For the machine learningphase, it is needed a labelled corpus, so the purposeof the lexicon-method is to tag the corpus.
Thus, theauthors selected a set of subjective words from allthose available in English and added hash-tags witha subjective meaning.
After labelling the corpus, itis used SVM for classifying new tweets.In (Agarwal et al, 2011) a study was conductedon a reduced corpus of tweets labelled manually.The experiment tests different methods of polarityclassification and starts with a base case consistingon the simple use of unigrams.
Then a tree-basedmodel is generated.
In a third step, several linguis-tic features are extracted and finally a final modellearned as combination of the different models pro-posed is computed.
A common feature used both inthe tree-based model and in the feature-based one isthe polarity of the words appearing in each tweet.
Inorder to calculate this polarity the authors used DALdictionary (Whissell, 1989).Most of the proposed systems for polarity detec-tion compute a value of negativeness or positiveness.Some of them even produce a neutrality value.
Wewill consider the following measurement of polar-5The name of posts in Twitter.ity (which is very common, indeed): a real valuein the interval [-1, 1] would be sufficient.
Valuesover zero would reflect a positive emotion expressedin the tweet, while values below zero would rathercorrespond to negative opinions.
The closer to thezero value a post is, the more its neutrality wouldbe.
Therefore, a polarity detection system could berepresented as a function p on a text t such as:p : RN ?
Rso that p(t) ?
[?1, 1].
We will define how tocompute this function, but before an explanation ofthe techniques implied in such a computation is pro-vided.3 The approach: Random Walk andSentiWordNet3.1 The Random Walk algorithmPersonalized Page Rank vectors (PPVs) consists ona ranked sequence of WordNet (Fellbaum, 1998)synsets weighted according to a random walk algo-rithm.
Taking the graph of WordNet, where nodesare synsets and axes are the different semantic re-lations among them, and the terms contained in atweet, we can select those synsets that correspond tothe closest sense for each term and.
Then, it startsan iterative process so more nodes are selected ifthey are not far from these ?seeds?.
After a num-ber of iterations or a convergence of the weights, afinal list of valued nodes can be retrieved.
A simi-lar approach has been used recently by (Ramage etal., 2009) to compute text semantic similarity in rec-ognizing textual entailment, and also as a solutionfor word sense disambiguation (Agirre and Soroa,2009).
We have used the UKB software from thislast citation to generate the PPVs used in our system.Random walk algorithms are inspired originally bythe Google PageRank algorithm (Page et al, 1999).The idea behind it is to represent each tweet as a vec-tor weighted synsets that are semantically close tothe terms included in the post.
In some way, we areexpanding these sort texts by a set of disambiguatedconcepts related to the terms included in the text.As an example of a PPV,the text ?Overall, we?restill having a hard time with it, mainly because we?renot finding it in an early phase.?
becomes the vectorof weighted synsets:4[02190088-a:0.0016, 12613907-n:0.0004,01680996-a:0.0002, 00745831-a:0.0002, ...]Here, the synset 02190088-a has a weight of0.0016, for example.3.2 SentiWordNetSentiWordNet (Baccianella et al, 2008) is a lexi-cal resource based on the well know WordNet (Fell-baum, 1998).
It provides additional information onsynsets related to sentiment orientation.
A synsetis the basic item of information in WordNet and itrepresents a ?concept?
that is unambiguous.
Mostof the relations over the lexical graph use synsetsas nodes (hyperonymy, synonymy, homonymy andmore).
SentiWordNet returns from every synset aset of three scores representing the notions of ?pos-itivity?, ?negativity?
and ?neutrality?.
Therefore,every concept in the graph is weighting accord-ing to its subjectivity and polarity.
The last ver-sion of SentiWordNet (3.0) has been constructedstarting from manual annotations of previous ver-sions, populating the whole graph by applying a ran-dom walk algorithm.
This resource has been usedby the opinion mining community, as it provides adomain-independent resource to get certain informa-tion about the degree of emotional charge of its con-cepts (Denecke, 2008; Ogawa et al, 2011).3.3 Computing the final estimationAs a combination of SentiWordNet scores with ran-dom walk weights is wanted, it is important thatthe final equation leads to comparable values.
Tothis end, the weights associated to synsets after therandom walk process are L1 normalized so vectorsof ?concepts?
sum up the unit as maximum value.The final polarity score is obtained by the product ofthis vector with associated SentiWordNet vector ofscores, as expressed in equation 1.p = r ?
s|t| (1)where p is the final score, r is the vector ofweighted synsets computed by the random walk al-gorithm of the tweet text over WordNet, s is the vec-tor of polarity scores from SentiWordNet, t is theset of concepts derived from the tweet.
The idea be-hind it is to ?expand?
the set of concepts with addi-tional ones that are close in the WordNet graph, cor-responding to those synset nodes which have beenactivated during the random walk process.
There-fore, terms like dog and bite (both mainly neutralin SentiWordNet) appearing in the same tweet couldeventually be expanded with a more emotional termlike hurt, which holds, in SentiWordNet, a negativescore of 0.75.4 Experiments and resultsOur experiments are focused in testing the validityof applying this unsupervised approach compared toa classical supervised one based on Support VectorMachines (Joachims, 1998).
To this end, the corpushas been processed obtaining lemmas, as this is thepreferred input for the UKB software.
The algorithmtakes the whole WordNet graph and performs a dis-ambiguation process of the terms as a natural con-sequence of applying random walk over the graph.In this way, the synsets that are associated to theseterms are all of them initialized.
Then, the iterativeprocess of the algorithm (similar to Page Rank butoptimized according to an stochastic solution) willchange these initial values and propagate weights tocloser synsets.
An interesting effect of this process isthat we can actually obtain more concepts that thosecontained in the tweet, as all the related ones willalso finalize with a certain value due to the propaga-tion of weights across the graph.
We believe that ourapproach benefits from this effect, as texts in tweetsuse to suffer from a very sort length, allowing us toexpand short posts.Another concern is, therefore, the final size of thePPV vector.
If too many concepts are taken into ac-count we may introduce noise in the understandingof the latent semantic of the text.
In order to studythis fact, different sizes of the vector have been ex-plored and evaluated.4.1 Our Twitter corpusThe analysis of the polarity on microblogging is avery recent task, so there are few free resources(Sas?a et al, 2010).
Thus, we have collected ourown English corpus in order to accomplish the ex-periments.
The work of downloading tweets is notnearly difficult due to the fact that Twitter offers twokinds of API to those purposes.
We have used the5Search API of Twitter6 for automatically accessingtweets through a query.
For a supervised polaritystudy and to evaluate our approach, we need to gen-erate a labelled corpus.
We have built a corpus oftweets written in English following the proceduredescribed in (Read, 2005) and (Go et al, 2009).According to (Read, 2005), when authors of anelectronic communication use an emotion, they areeffectively marking up their own text with an emo-tional state.
The main feature of Twitter is that thelength of the messages must be 140 characters, sothe users have to express their opinions, thoughts,and emotional states with few words.
Therefore,frequently users write ?smileys?
in their tweets.Thus, we have used positive emoticons to label pos-itive tweets and negative emoticons to tag negativetweets.
The full list of emoticons that we have con-sidered to label the retrieved tweets can be found inTable 1.
So, following (Go et al, 2009), the pre-sumption in the construction of the corpus is that thequery ?:)?
returns tweets with positive smileys, andthe query ?:(?
retrieves negative emotions.
We havecollected a set of 376,296 tweets (181,492 labelledas positive tweets and 194,804 labelled as negativetweets), which were published on Twitter?s publicmessage board from September 14th 2010 to March19th 2011.
Table 2 lists other characteristics of thecorpus.On the other hand, the language used in Twit-ter has some unique attributes, which have been re-moved because they do not provide relevant infor-mation for the polarity detection process.
These spe-cific features are:1.
Retweets: A retweet is the way to repeat a mes-sage that users consider interesting.
Retweetscan be done through the web interface usingthe Retweet option, or as the old way writingRT, the user name and the post to retweet.
Thefirst way is not a problem because is the sametweet, so the API only return it once, but oldway retweets are different tweets but with thesame content, so we removed them to avoid pit-ting extra weight on any particular tweet.2.
Mentions: Other feature of Twitter is the socalled Mentions.
When a user wants to refer6https://dev.twitter.com/docs/api/1/get/searchEmoticons mapped to :)(positive tweets):) : ) :-);) ;-) =)?
?
:-D :D:d =D C:Xd XD xDXd (x (=??
?o?
?u?n n *-* *O**o* * *Emoticons mapped to :((negative tweets):-( :( :((: ( D: Dx?n?
:\ /:):-/ :?
=?
[: ( /T T TOT; ;Table 1: Emoticons considered as positives and negativesto another one, he or she introduces a Mention.A Mention is easily recognizable because all ofthem start with the symbol ?@?
followed by theuser name.
We consider that this feature doesnot provide any relevance information, so wehave removed the mentions in all the tweets.3.
Links: It is very common that tweets includeweb directions.
In our approach we do not ana-lyze the documents that links those urls, so wehave eliminated them from all tweets.4.
Hash-tags: A hash-tag is the name of a topicin Twitter.
Anybody can begin a new topic bytyping the name of the topic preceded by thesymbol ?#?.
For this work we do not classifytopics so we have neglected all the hash-tags.Due to the fact that users usually write tweetswith a very casual language, it is necessary to pre-process the raw tweets before feeding the sentimentanalyzer.
For that purpose we have applied the fol-lowing filters:1.
Remove new lines: Some users write tweetsin two or three different lines, so all newlinessymbols were removed.2.
Opposite emoticons: Twitter sometimes con-siders positive or negative a tweet with smileys6TotalPositive tweets 181,492Negative tweets 194,804 376,296Unique users in positivetweets157,579Unique users in negativetweets167,479 325,058Words in positive tweets 418,234Words in negative tweets 334,687 752,921Average number ofwords per positive tweet9Average number ofwords per negative tweet10Table 2: Statistical description of the corpus.that have opposite senses.
For example:@Harry Styles I have all day to tryget a tweet off you :) when areyou coming back to dublin i missedyou last time,I was in spain :(The tweet has two parts one positive and theother one negative, so the post cannot be con-sidered as positive, but the search API returnsas a positive tweet because it has the positivesmiley ?:)?.
We have removed this kind oftweets in order to avoid ambiguity.3.
Emoticons with no clear sentiment: TheTwitter Search API considers some emoticonslike ?:P?
or ?:PP?
as negative.
However, someusers do not type them to express a negativesentiment.
Thus, we have got rid of all tweetswith this kind of smileys (see Table 3).Fuzzy emoticons :-P :P :PP \(Table 3: Emoticons considered as fuzzy sentiments4.
Repeated letters: Users frequently repeat sev-eral times letters of some words to emphasizetheir messages.
For example:Blood drive todayyyy!!!!!
:)Everyone donateeeee!
!This can be a problem for the classification pro-cess, because the same word with different rep-etitions of the same letter would be consideredas a different word.
Thus, we have normalizedall the repeated letters, and any letter occurringmore than two times in a word is replaced withtwo occurrences.
The example above would beconverted into:blood drive todayy :) everyonedonatee!!5.
Laugh: There is not a unique manner to ex-press laugh.
Therefore, we have normalizedthe way to write laugh.
Table 4 lists the con-versions.Laugh Conversionhahahaha... hahahehehehe... hehehihihihi... hihihohohoho... hohohuhuhuhu... huhuLol hahaHuashuashuas huasmuahahaha Buahabuahahaha BuahaTable 4: Normalization for expressions considered as?Laugh?Finally, although the emoticons have been usedto tag the positive and negative samples, the fi-nal corpora does not include these emoticons.In addition, all the punctuation characters havebeen neglected in order to reduce the noise inthe data.
Figure 1 shows the process to gener-ate our Twitter corpus.4.2 Results obtainedOur first experiment consisted on evaluating a super-vised approach, like Support Vector Machines, us-ing the well know vector space model to build thevector of features.
Each feature corresponds to theTF.IDF weight of a lemma.
Stop words have notbeen removed and the minimal document frequencyrequired was two, that is, if the lemma is not presentin two o more tweets, then it is discarded as a di-mension in the vectors.
The SVM-Light7 softwarewas used to compute support vectors and to evaluatethem using a random leave-one-out strategy.
From7http://svmlight.joachims.org/7Figure 1: Corpus generation work-flowa total of 376,284 valid samples 85,423 leave-one-out evaluations were computed.
This reported thefollowing measurements:Precision Recall F10.6429 0.6147 0.6285In our first implementation of our method, the fi-nal polarity score is computed as described in equa-tion 1.
More precisely, it is the average of the prod-uct between the difference of positive and negativeSentiWordNet scores, and the weight obtained withthe random walk algorithm, as unveiled in equa-tion 2.p =?
?s?t rws ?
(swn+s ?
swn?s )|t| (2)Where s is a synset in the tweet t, rws is theweight of the synset s after the random walk pro-cess over WordNet, swn+s and swn?s ) are positiveand negative scores for the synset s retrieved fromSentiWordNet.The results obtained are graphically shown in fig-ures 2, 3 and 4 for precision, recall and F1 valuesrespectively.
As can be noticed from the shapesof the graphs, the size of the PPV vectors affectsthe performance.
Sizes above 10 presents an sta-ble behavior, that is, considering a large number ofsynsets does not improves the performance of thesystem, but it gets worse neither.
The WordNetgraph considered for the random walk algorithm in-cludes antonyms relations, so we wanted to checkwhether discarding these connections would affectthe system.
From these graphs we can extract theconclusion that antonyms relations are worth keep-ing.Figure 2: Precision values against PPV sizesFigure 3: Recall values against PPV sizesComparing our best configuration to the SVM ap-proach, the results are not better, but quite close (ta-ble 5).
Therefore, this unsupervised solution is aninteresting alternative to the supervised one.8Figure 4: F1 values against PPV sizesPrecision Recall F1SVM 0.6429 0.6147 0.6285RW?SWN 0.6259 0.6207 0.6233Table 5: Approaches comparative table5 Conclusions and further workA new unsupervised approach to the polarity detec-tion problem in Twitter posts has been proposed.
Bycombining a random walk algorithm that weightssynsets from the text with polarity scores providedby SentiWordNet, it is possible to build a systemcomparable to a SVM based supervised approach interms of performance.
Our solution is a general ap-proach that do not suffer from the disadvantages as-sociated to supervised ones: need of a training cor-pus and dependence on the domain where the modelwas obtained.Many issues remain open and they will drive ourfuture work.
How to deal with negation is a ma-jor concern, as the score from SentiWordNet shouldbe considered in a different way in the final com-putation if the original term comes from a negatedphrase.
Our ?golden rules?
must be taken carefully,because emoticons are a rough way to classify thepolarity of tweets.
Actually, we are working in thegeneration of a new corpus in the politics domainthat is now under a manual labeling process.
An-other step is to face certain flaws in the computationof the final score.
In this sense, we plan to studythe context of a tweet among the time line of tweetsfrom that user to identify publisher?s mood and ad-just final scores.
As an additional task, the process-ing of original texts is important.
The numerousgrammatical and spelling errors found in this fastway of publication demand for a better sanitizationof the incoming data.
An automatic spell checker isunder development.As final conclusion, we believe that this first at-tempt is very promising and that it has arose manyrelevant questions on the subject of sentiment analy-sis.
More extensive research and experimentation isbeing undertaken from the starting point introducedin this paper.AcknowledgmentsThis work has been partially supported by a grantfrom the Fondo Europeo de Desarrollo Regional(FEDER), TEXT-COOL 2.0 project (TIN2009-13391-C04-02) from the Spanish Government.
Thispaper is partially funded by the European Commis-sion under the Seventh (FP7 - 2007-2013) Frame-work Programme for Research and Technologi-cal Development through the FIRST project (FP7-287607).
This publication reflects the views onlyof the author, and the Commission cannot be heldresponsible for any use which may be made of theinformation contained therein.ReferencesApoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,and Rebecca Passonneau.
2011.
Sentiment analysisof twitter data.
In Proceedings of the Workshop onLanguage in Social Media (LSM 2011), pages 30?38,Portland, Oregon, jun.
Association for ComputationalLinguistics.Eneko Agirre and Aitor Soroa.
2009.
Personalizingpagerank for word sense disambiguation.
In EACL?09: Proceedings of the 12th Conference of the Eu-ropean Chapter of the Association for ComputationalLinguistics, pages 33?41, Morristown, NJ, USA.
As-sociation for Computational Linguistics.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2008.
Sentiwordnet 3.0 : An enhanced lexicalresource for sentiment analysis and opinion mining.Proceedings of the Seventh conference on Interna-tional Language Resources and Evaluation LREC10,0:2200?2204.K.
Denecke.
2008.
Using sentiwordnet for multilingualsentiment analysis.
In Data Engineering Workshop,92008.
ICDEW 2008.
IEEE 24th International Confer-ence on, pages 507 ?512, april.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge, MA.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.Processing, pages 1?6.T.
Joachims.
1998.
Text categorization with support vec-tor machines: learning with many relevant features.
InEuropean Conference on Machine Learning (ECML).Bing Liu.
2010.
Sentiment analysis and subjectivity.Handbook of Natural Language Processing, 2nd ed.Tatsuya Ogawa, Qiang Ma, and Masatoshi Yoshikawa.2011.
News Bias Analysis Based on Stakeholder Min-ing.
IEICE TRANSACTIONS ON INFORMATIONAND SYSTEMS, E94D(3):578?586, MAR.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:Bringing order to the web.
Technical report, StanfordUniversity.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135.Daniel Ramage, Anna N. Rafferty, and Christopher D.Manning.
2009.
Random walks for text seman-tic similarity.
In TextGraphs-4: Proceedings of the2009 Workshop on Graph-based Methods for NaturalLanguage Processing, pages 23?31, Morristown, NJ,USA.
Association for Computational Linguistics.Jonathon Read.
2005.
Using emoticons to reduce de-pendency in machine learning techniques for senti-ment classification.
In Proceedings of the ACL Stu-dent Research Workshop, ACLstudent ?05, pages 43?48, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Petrovic?
Sas?a, Miles Osborne, and Victor Lavrenko.2010.
The edinburgh twitter corpus.
In Proceed-ings of the NAACL HLT 2010 Workshop on Compu-tational Linguistics in a World of Social Media, WSA?10, pages 25?26, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Mikalai Tsytsarau and Themis Palpanas.
2011.
Surveyon mining subjective data on the web.
Data Miningand Knowledge Discovery, pages 1?37, October.C M Whissell, 1989.
The dictionary of affect in lan-guage, volume 4, pages 113?131.
Academic Press.Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil, Me-ichun Hsu, and Bing Liu.
2011.
Combining lexicon-based and learning-based methods for twitter senti-ment analysis.
Technical Report HPL-2011-89, HP,21/06/2011.10
