Augmenting Lexicons Automatically: Clustering Semantically Related AdjectivesKathleen McKeownVasileios HatzivassiloglouDepartment of Computer Science450 Computer Science BuildingColumbia UniversityNew York, N.Y. 10027ABSTRACTOur work focuses on identifying various types of lexical data inlarge corpora through statistical analysis.
In this paper, wepresent amethod for grouping adjectives according to their mean-ing, as a step towards the automatic identification of adjectivalscales.
We describe how our system exploits two sources oflinguistic knowledge in a corpus to compute a measure ofsimilarity between two adjectives, using statistical techniques anda clustering algorithm for grouping.
We evaluate the significanceof the results produced by our system for a sample set of adjec-fives.1.
INTRODUCTIONA linguistic scale is a set of words, of the same gram-matical category, which can be ordered by their semanticstrength or degree of informativeness \[1\].
For example,"lukewarm," "warm",  "hot"  fall along a single adjec-tival scale since they indicate a variation in the intensity oftemperature of the modified noun.
Linguistic properties ofscales derive both from conventional logical entailment onthe linear ordering of their elements and from Griceanscalar implicature \[1\].
Despite these properties and theirpotential usefulness in both understanding and generatingnatural anguage text, dictionary entries are largely incom-plete for adjectives in this regard.
Yet, if systems are to usethe information encoded in adjectival scales for generationor interpretation (e.g.
for selecting an adjective with a par-ticular degree of semantic strength, or for handling nega-tion), they must have access to the sets of words compris-ing a scale.While linguists have presented various tests for acceptingor rejecting a particular scalar relationship between anytwo adjectives (e.g., \[2\], \[3\]), the common problem withthese methods is that they are designed to be applied by ahuman who incorporates the two adjectives in specific sen-tential frames (e.g.
"X is warm, even hot") and assessesthe semantic validity of the resulting sentences.
Such testscannot be used computationally to identify scales in adomain, since the specific sentences do not occur fre-quently enough in a corpus to produce an adequatedescription of the adjectival scales in the domain \[4\].
Asscales vary across domains, the task of compiling suchinformation is compounded.In this paper we describe a technique for automaticallygrouping adjectives according to their meaning based on agiven text corpus, so that all adjectives placed in one groupdescribe different values of the same property.
Our methodis based on statistical techniques, augmented with linguis-tic information derived from the corpus, and is completelydomain independent.
It demonstrates how high-levelsemantic knowledge can be computed from large amountsof low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations).
While ourcurrent system does not distinguish between scalar andnon-scalar adjectives, it is a first step in the automaticidentification of adjectival scales, since the scales can besubsequently ordered and the non-scalar adjectives filteredon the basis of independent tests, done in part automati-cally and in part by hand in a post-editing phase.
The resultis a semi-automated system for the compilation of adjec-tival scales.In the following sections, we first describe our algorithm indetail, present he results obtained, and finally provide aformal evaluation of the results.2.
ALGORITHMOur algorithm is based on two sources of linguistic data:data that help establish that two adjectives are related, anddata that indicate that two adjectives are unrelated.
Weextract adjective-noun pairs that occur in a modificationrelation in order to identify the distribution of nouns anadjective modifies and, ultimately, determine which adjec-tives it is related to.
This is based on the expectation thatadjectives describing the same property tend to modify thesame set of nouns.
For example, temperature is normallydefined for physical objects and we can expect o find thatadjectives conveying different values of temperature willall modify physical objects.
Therefore, our algorithm findsthe distribution of nouns that each adjective modifies andcategorizes adjectives as similar if they have similar dis-tributions.Second, we use adjective-adjective pairs occurring as pre-modifiers within the same NP as a strong indication thatthe two adjectives do not belong in the same group.
Thereare three cases:I.
If both adjectives modify the head noun andthe two adjectives are antithetical, the NP272would be self-contradictory, as in the scalarsequence hot cold or the non-scalar redblack.2.
For non-antithetical scalar adjectives whichboth modify the head noun, the NP wouldviolate the Gricean maxim of Manner\[1\] since the same information is conveyedby the strongest of the two adjectives (e.g.hot warm).3.
Finally, if one adjective modifies the other,the modifying adjective has to qualify themodified one in a different dimension.
Forexample, in light blue shirt, blue is a value ofthe property color, while light indicates theshade*.The use of linguistic data, in addition to statisticalmeasures, is a unique property of our work and sig-nificantly improves the accuracy of our results.
One otherpublished model for grouping semantically related words\[5\], is based on a statistical model of bigrams and trigramsand produces word groups using no linguistic knowledge,but no evaluation of the results is performed.Our method works in three stages.
First, we extract linguis-tic data from the parsed corpus in the form of syntacticallyrelated word pairs; in the second stage, we compute ameasure of similarity between any two adjectives based onthe information gathered in stage one; and in the last stage,we cluster the adjectives into groups according to thesimilarity measure, so that adjectives with a high degree ofsimilarity fall in the same cluster (and, consequently, ad-jectives with a low degree of similarity fall in differentclusters).2.1.
Stage One: Extracting Word PairsDuring the first stage, the system extracts adjective-nounand adjective-adjective pairs from the corpus.
To deter-mine the syntactic ategory of each word, and identify theNP boundaries and the syntactic relations between eachword, we used the Fidditch parser \[6\]**.
For each NP, wethen determine its minimal NP, that part of an NP consist-ing of the head noun and its adjectival pre-modifiers.
Wematch a set of regular expressions, consisting of syntacticcategories and representing the different forms a minimalNP can take, against he NPs.
From the minimal NP, weproduce the different pairs of adjectives and nouns.The resulting adjective-adjective and adjective-noun pairsare filtered by a morphology component, which removespairs that contain erroneous information (such as mistyped*Note that sequences such as blue-green are usually hyphenated andthus better considered as a compound.
**We thank Diane Litman and Donald Hindle for providing us withaccess to the parser at AT&T Bell Labs.words, proper names, and closed-class words which maybe mistakenly classified as adjectives (e.g.
possessivepronouns)).
This component also reduces the number ofdifferent pairs without losing information by transformingwords to an equivalent, base form (e.g.
plural nouns areconverted to singular) so that the expected and actual fre-quencies of each pair are higher.
Stage one then producesas output a simple list of adjective-adjective pairs that oc-curred within the same minimal NP and a table with theobserved frequencies of every adjective-noun combination.Each row in the table contains the frequencies of modifiednouns for a given adjective.2.2.
Stage Two: Computing SimilaritiesBetween AdjectivesThis stage processes the output of stage one, producing ameasure of similarity for each possible pair of adjectives.The adjective-noun frequency table is processed first; foreach possible pair in the table we compare the two dis-tfibutions of nouns.We use a robust non-parametric method to compute thesimilarity between the modified noun distributions for anytwo adjectives, namely Kendall's x coefficient \[7\] for tworandom variables with paired observations.
In our case, thetwo random variables are the two adjectives we are com-paring, and each paired observation is their frequency ofco-occurrence with a given noun.
Kendall's x coefficientcompares the two variables by repeatedly comparing twopairs of their corresponding observations.
Formally, if(Xi,Yi) and (Xj,Y~) are two pairs of observations for theadjectives X and ~Y on the nouns i and j respectively, wecall these pairs concordant if Xi>X/and Yi>Yj or i f  Xi<Xjand Yi<Yj; otherwise these pairs are discordant***.
If thedistributions for the two adjectives are similar, we expect alarge number of concordances, and a small number of dis-cordances.Kendall's x is defined as= Pc-Pdwhere Pc and Pd are the probabilities of observing a con-"cordance or discordance respectively, x ranges from -1 to+1, with +1 indicating complete concordance, -1 completediscordance, and 0 no correlation between X and Y.An unbiased estimator of x is the statisticT-  C-Qwhere n is the number of paired observations in the sampleand C and Q are the numbers of observed concordancesand discordances respectively \[8\].
We compute T for eachpair of adjectives, adjusting for possible ties in the values***We discard pairs of observations where Xi=X j or Yi=Yj.273of each variable.
We determine concordances and discor-dances by sorting the pairs of observations (noun fre-quencies) on one of the variables (adjectives), and comput-ing how many of the (~) pairs of paired observations agreeor disagree with the expected order on the other adjective.We normalize the result to the range 0 to 1 using a simplelinear transformation.After the similarities h/ave been computed for any pair ofadjectives, we utilize the knowledge offered by the ob-served adjective-adjective pairs; we know that the adjec-tives which appear in any such pair cannot be part of thesame group, so we set their similarity to 0, overriding thesimilarity produced by "r.2.3.
Stage Three: Clustering The AdjectivesIn stage three we first convert the similarities to dis-similarities and then apply a non-hierarchical clustering al-gorithm.
Such algorithms are in general stronger thanhierarchical methods \[9\].
The number of clusters producedis an input parameter.
We define dissimilarity as (1 -similarity), with the additional provision that pairs of ad-jectives with similarity 0 are given a higher dissimilarityvalue than 1.
This ensures that these adjectives will neverbe placed in the same cluster; recall that they were deter-mined to be definitively dissimilar based on linguistic data.The algorithm uses the exchange method \[10\] since themore commonly used K-means method \[9\] is not ap-plicable; the K-means method, like all centroid methods,requires the measure d between the clustered objects to bea distance; this means, among other conditions, that forany three objects x, y, and z the triangle inequality applies.However, this inequality does not necessarily hold for ourdissimilarity measure.
If the adjectives x and y were ob-served in the same minimal NP, their dissimilarity is quitelarge.
If neither z and x nor z and y were found in the sameminimal NP, then it is quite possible that the sum of theirdissimilarities could be less than the dissimilarity betweenx and y.The algorithm tries to produce a partition of the set ofadjectives in such a way that adjectives with high dis-similarities are placed in different clusters.
This is ac-complished by minimizing an objective function ?
whichscores a partition P. The objective function we use is~(~ = E \[-~- E d(x,y)\]CeP IClx,ye CThe algorithm starts by producing a random partition ofthe adjectives, computing its ?
value and then computingfor each adjective the improvement in ?
for every clusterwhere it can he moved; if there is at least one move for anadjective that leads to an overall improvement of ~, thenthe adjective is moved to the cluster that yields the bestimprovement and the next adjective is considered.
Thisprocedure is repeated until no more moves lead to an im-provement of ~.This is a hill-climbing method and therefore is guaranteedantitrust newbig oldeconomic politicalfinancial potentialforeign realglobal seriousinternational severelegal staggeringlittle technicalmajor unexpectedmechanicalFigure 1: Adjectives to be grouped.to converge, but it may lead to a local minimum of ~,inferior to the global minimum that corresponds to the op-timal solution.
To alleviate this problem, the partitioningalgorithm is called repeatedly with different random start-ing partitions and the best solution in these runs is kept.
Itshould be noted that the problem of computing the optimalsolution is NP-complete, as a generalization of the basicNP-complete clustering problem \[11 \].3.
RESULTSWe tested our system on a 8.2 million word corpus ofstock market reports from the AP news wire****.
A subsetof 21 of the adjectives in the corpus (Figure 1) wasselected for practical reasons (mainly for keeping theevaluation task tractable).
We selected adjectives that haveone modified noun in common (problem) to ensure somesemantic relatedness, and we included only adjectives thatoccurred frequently so that our similarity measure wouldbe meaningful.The partition produced by the system for 9 clusters appearsin Figure 2.
Since the number of clusters is not determinedby the system, we present the partition with a similar num-ber of clusters as humans used for the same set of adjec-tives (the average number of clusters in the human-mademodels was 8.56).Before presenting a formal evaluation of the results, wenote that this partition contains interesting data.
First, theresults contain two clusters of gradable adjectives whichfall in the same scale.
Groups 5 and 8 contain adjectivesthat indicate the size, or scope, of a problem; by augment-ing the system with tests to identify when an adjective isgradable, we could separate out these two groups fromother potential scales, and perhaps consider combiningthem.
Second, groups 1 and 6 clearly identify separate setsof non-gradable, non-scalar adjectives; the former groupcontains adjectives that describe the geographical scope ofthe problem, while the latter contains adjectives that.... We thank Karen Kukich and Frank Smadja for providing us accessto the corpus.274Answer should be Yes Answer should be NoThe system says Yes a bThe system says No c d1.
foreign global international2.
old3.
potentialTable 1: Contingency table model for evaluation.4.
EVALUATION4.
new real unexpected5.
little staggering6.
economic financial mechanical political technical7.
antitrust8.
big major serious evere9.
legalFigure 2: Partition found for 9 clusters.specify the nature of the problem.
It is interesting to notehere that the expected number of adjectives per cluster is~=2.33,  and the clustering algorithm employed dis-courages long groups; nevertheless, the evidence for theadjectives in group 6 is strong enough to allow the creationof a group with more than twice the expected number ofmembers.
Finally, note that even in group 4 which is theweakest group produced, there is a positive semantic or-To evaluate the performance of our system we comparedits output o a model solution for the problem designed byhumans.
Nine human judges were presented with the set ofadjectives to be partitioned, a description of the domain,and a simple example.
They were told that clusters houldnot overlap but they could select any number of clusters?For our scoring mechanism, we converted the comparisonof two partitions to a series of yes-no questions, each ofwhich has a correct answer (as dictated by the model) andan answer assigned by the system.
For each pair of adjec-tives, we asked if they fell in the same cluster ("yes")  ornot ("no").
Since human judges did not always agree, weused fractional values for the correctness of each answerinstead of 0 ("incorrect") and 1 ("correct").
We usedmultiple human models for the same set of adjectives anddefined the correctness of each answer as the relative fre-quency of the association between the two adjectivesamong the human models.
We then sum these correctnessvalues; in the case of perfect agreement between themodels, or of only one model, the measures reduce to theiroriginal definition.Then, the contingency table model \[12\], widely used inInformation Retrieval, is applicable.
Referring to the clas-sification of the yes-no answers in Table 1, the following relation between the adjectives new and unexpected.
Tosummarize, the system seems to be able to identify manyof the existent semantic relationships among the adjectives,while its mistakes are limited to creating singleton groupscontaining adjectives that are related to other adjectives inthe test set (e.g., missing the semantic associations be-tween new-old and potential-real) and "recognizing" anon-significant relationship between real andnew-unexpected in group 4.We produced good results with relatively little data; theaccuracy of the results can be improved if a larger,homogeneous corpus is used to provide the raw data.
Fur-thermore, some of the associations between adjectives thatthe system reports appear to be more stable than others,e.g.
when we vary the number of clusters in the partition.We have noticed that adjectives with a higher degree ofsemantic ontent (e.g.
international or severe) appear toform more stable associations than relatively semanticallyempty adjectives (e.g.
little or real).
This observation canbe used to actually filter out the adjectives which are toogeneral to be meaningfully clustered in groups.measures are defined :a?
Recall = ?
100%a+ca?
Precision =a~"  100%b?
Fallout = ?
100%b+dIn other words, recall is the percentage of correct "yes"answers that the system found among the model "yes"answers, precision is the percentage of correct "yes"answers among the total of "yes" answers that the systemreported, and fallout is the percentage of incorrect "~e.s.'.
'answers relative to the total number of "no"  answersWe also compute a combined measure for recall and preci-sion, the F-measure \[13\], which always takes a value be-tween the values of recall and precision, and is higherwhen recall and precision are closer; it is defined as*****Another measure used in information retrieval, overgenerat ion,  isin our case always equal to (100 - precision)%,275Recall Precision Fallout F-measure (15=1)7 clusters 50.78% 43.56% 7.48% 46.89%8 clusters 37.31% 38.10% 6.89% 37.70%9 clusters 49.74% 46.38% 6.54% 48.00%10 clusters 35.23% 41.98% 5.54% 38.31%Table 2: Evaluation results.F = (\[52+1) ?
Precision x Recall\[52 x Precision + Recallwhere 13 is the weight of recall relative to precision; we use~=1.0, which corresponds to equal weighting of the twomeasures.The results of applying our evaluation method to the sys-tem output (Figure 2) are shown in Table 2, which alsoincludes the scores obtained for several other sub-optimalchoices of the number of clusters.
We have made theseobservations related to the evaluation mechanism :1.
Recall is inversely related to fallout andprecision.
Decreasing the number of clustersgenerally increases the recall and fallout andsimultaneously decreases precision.2.
We have found fallout to be a better measureoverall than precision, since, in addition to itsdecision-theoretic advantages \[12\], it appearsto be more consistent across evaluations ofpartitions with different numbers of clusters.This has also been reported by other resear-chers in different evaluation problems \[14\].3.
For comparison, we evaluated each humanmodel against all the other models, using theabove evaluation method; the results rangedfrom 38 to 72% for recall, 1 to 12% for fall-out, 38 to 81% for precision, and, covering aremarkably short range, 49 to 59% for theF-measure, indicating that the performanceof the system is not far behind human perfor-mance.Finally, before interpreting the scores produced by ourevaluation module, we need to understand how they varyas the partition gets better or worse, and what are the limitsof their values.
Because of the multiple models used, per-fect scores are not attainable.
Also, because ach pair ofadjectives in a cluster is considered an observed associa-tion, the relationship between the number of associationsproduced by a cluster and the number of adjectives in thecluster is not linear (a cluster with k adjectives willproduce (2k)=O(k 2) associations).
This leads to lowervalues of recall, since moving a single adjective out of acluster with k elements in the model will cause the systemto miss k-1 associations.
In general, defining a scoringmechanism that compares one partition to another is a hardproblem.To quantify these observations, we performed a MonteCarlo analysis\[15\] for the evaluation metrics, byrepeatedly creating random partitions of the sample adjec-tives and evaluating the results.
Then we estimated a(smoothed) probability density function for each metricfrom the resulting histograms; part of the results obtainedare shown in Figure 3 for F-measure and fallout using 9clusters.
We observed that the system's performance (in-dicated by a square in the diagrams) was significantly bet-ter than what we would expect under the null hypothesis ofrandom performance; the probability of getting a betterpartition than the system's is extremely small for allmetrics (no occurrence in 20,000 trials) except for fallout,for which a random system may be better 4.9% of the time.The estimated ensity functions also show that the metricsare severely constrained by the structure imposed by theclustering as they tend to peak at some point and then fallrapidly.5.
CONCLUSIONS AND FUTURE WORKWe have described a system for extracting groups ofsemantically related adjectives from large text corpora.Our evaluation reveals that it has significantly high perfor-mance levels, comparable tohuman models.
Its results canbe filtered to produce scalar adjectives that are applicablein any given domain.Eventually, we plan to use the system output to augmentadjective ntries in a lexicon and test the augmented lex-icon in an application such as language generation.
Inaddition, we have identified many directions for improvingthe quality of our output:?
Investigating non-linear methods for convert-ing similarities to dissimilarities.?
Experimenting with different evaluationmodels, preferably ones based on the good-ness of each cluster and not of each associa-tion.?
Developing methods for automatically select-ing the desired number of clusters for theproduced partition.
Although this is a par-ticularly hard problem, a steepest-descentmethod based on the tangent of the objectivefunction may offer a solution.?
Investigating additional sources of linguistic276d0 10 20 30 40 SOF-~m (9 cluster)od0 5 10 15 20Fallout (9 dustars)Figure 3: Estimated probability densities for F-measureand fallout with 9 clusters.knowledge, such as the use of conjunctionsand adverb-adjective pairs.?
Augmenting the system with tests particular toscalar adjectives; for example, exploitinggradability, checking whether two adjectivesare antonymous (essentially developing testsin the opposite direction of the work by Jus-teson and Katz \[16\]), or comparing the relativesemantic strength of two adjectives.ACKNOWLEDGEMENTSThis work was supported jointly by DARPA and ONRunder contract N00014-89-J-1782, by NSFGER-90-24069, and by New York State Center for Ad-vanced Technology Contract NYSSTF-CAT(91)-053.REFERENCES1.
Levinson, S.C., Pragmatics, Cambridge University Press,Cambridge, England, 1983.2.
Horn, L., "A Presuppositional Analysis of Only andEven", Papers from the Fifth Regional Meeting, ChicagoLinguistics Society, 1969, pp.
98-107.3.
Bolinger, D., Neutrality, Norm, and Bias, Indiana Univer-sity Linguistics Club, Bloomington, IN, 1977.4.
Smadja, F., Retrieving Collocational Knowledge fromTextual Corpora.
An Application: Language Generation,PhD dissertation, Department of Computer Science,Columbia University, 1991.5 .
.
Brown P., Della Pietra V., deSouza P., Lai J., and MercerR., "Class-based n-gram Models of Natural Language",Computational Linguistics, Vol.
18:4, 1992, pp.
467-479.6.
Hindle, D. M., "Acquiring Disambiguation Rules fromText", Proceedings of the 27th meeting of the Associationfor Computational Linguistics, Vancouver, B.C., t989,pp.
118-125.7.
Kendall, M.G., "A New Measure of Rank Correlation",Biometrika, Vol.
30, 1938, pp.
81-93.8.
Wayne, D.W., Applied Nonparametric Statistics (2ndedition), PWS-KENT Publishing Company, Boston, TheDuxbury Advanced Series in Statistics and DecisionSciences, 1990.9.
Kaufman, L. and Rousseeuw, P.J., Finding Groups inData: An Introduction to Cluster Analysis, Wiley, NewYork, Wiley Series in Probability and MathematicalStatistics, 1990.10.
Spath, Helmuth, Cluster Dissection and Analysis :Theory, FORTRAN Programs, Examples, Ellis Horwood,Chichester, West Sussex, England, Ellis Horwood Seriesin Computers and their Applications, 1985.11.
Brucker, P., "On the complexity of clustering problems",in Optimierung und Operations Research, Henn, R.,Korte, B., and Oletti, W., eds., Springer, Berlin, LectureNotes in Economics and Mathematical Systems, 1978.12.
Swets, J.A., "Effectiveness of Information RetrievalMethods", American Documentation, Vol.20, January 1969, pp.
72-89.13.
Van Rijsbergen, C.J., Information Retrieval (2nd edition),Butterwoths, London, 1979.14.
Lewis, D. and Tong, R., "Text Filtering in MUC-3 andMUC-4", Proceedings of the Fourth Message Under-standing Conference (MUC-4), DARPA Software and In-telligent Systems Technology Office, 1992, pp.
51-66.15.
Rubinstein, R.Y., Simulation and the Monte Carlomethod, Wiley, New York, Wiley Series in Probabilityand Mathematical Statistics, 1981.16.
Justeson, J.S.
and Katz, S.M., "Co-occurences of An-tonymous Adjectives and Their Contexts",Computational Linguistics, Vol.
17:1, 1991, pp.
1-19.277
