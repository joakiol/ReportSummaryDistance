Cue Phrase  Se lec t ion  in  Ins t ruc t ion  D ia logueUs ing  Mach ine  Learn ingYukiko I. NakanoNTT Informat ion and Communicat ionSystems Laborator ies1-1 Hikari-no-oka, Yokosuka-shi,Kanagawa 239-0847 Japanyukiko~nttn ly .
is l .nt t .co.
jpTsuneaki  KatoNTT Communicat ion  ScienceLaborator ies2-4 Hikaridai, Seika-cho,Soraku-gun, Kyoto 619-0237 JapankatoQcslab.kecl .ntt .co.
jpAbst rac tThe purpose of this paper is to identify effective fac-tors for selecting discourse organization cue phrasesin instruction dialogue that signal changes in dis-course structure such as topic shifts and attentionalstate changes.
By using a machine learning tech-nique, a variety of features concerning discoursestructure, task structure, and dialogue context areexamined in terms of their effectiveness and the bestset of learning <features is identified.
Our result re-veals that, in addition to discourse structure, alreadyidentified in previous tudies, task structure and di-alogue context play an important role.
Moreover,an evaluation using a large dialogue corpus showsthe utihty of applying machine learning techniquesto cue phrase selection.1 In t roduct ionCue phrases are words and phrases, such as "first","and", "now", that connect discourse spans and addstructure to the discourse both in text and dialogue.They signal topic shifts and changes in attentionalstate (Grosz and Sidner, 1986) as well as expressingthe relation between the individual units of discourse(Moore, 1995; RSsner and Stede, 1992).
In thisstudy, we focus on the former kind of cue phrases,organization cue phrases that signal the structuralorganization of discourse.In instruction dialogue, the organization cuephrases play a crucial role in controlling dialogueand making the material easy to understand.
More-over, in dialogue systems, the user cannot compre-hend the structural organization of the dialogue un-less the appropriate cue phrases are included in thesystem's utterances.
Therefore, for dialogue gener-ation, we must identify the determining factors oforganization cue phrases and select the cue phrasesappropriately.In previous tudies that have investigated the rela-tionship between cue phrases and the types of struc-tural change (e.g.
pop, push), the taxonomies ofcue phrases have been presented (Grosz and Sid-ner, 1986; Cohen, 1984; Schiffrin, 1987).
These tax-onomies are, however, not sufficient for generationbecause the correspondence b tween cue phrase andstructural change is many-to-many quite often.
Forexample, "now","and", and "next" are all classifiedas the category signaling push in attentional state.Therefore, the indication of structural shifts in dis-course is not sufficient to fully constrain cue phraseselection.In this study, we reveal what factors affect or-ganization cue phrase selection, and establish moreprecise selection rules for generating instruction dia-logues.
As factors for cue phrase selection, we exam-ine a variety of features concerning discourse struc-ture, task structure, and dialogue context.
The rea-son that we examine these three factors is as fol-lows.
First, discourse structure is indispensable forselecting cue phrase as claimed in previous stud-ies (Grosz and Sidner, 1986; Cohen, 1984; Euge-nio et al, 1997).
We examine some features con-cerning this factor such as the global structure ofdiscourse and structural shifts in discourse.
Sec-ond, while the discourse structure provides informa-tion about the preceding discourse, Cawsey (1993)claimed that information about the succeeding dis-course (e.g., length and complexity) isalso necessaryin order to select cue phrases dynamically in dialoguesystems.
From this point of view, task structure isexpected to be effective because discourse structurestrongly reflects task structure in task oriented i-alogue (Grosz, 1977; Guindon, 1986).
Finally, incontrast o these structural aspects of dialogue, wethink it important o consider sequential contextsof dialogue such as the types of dialogue xchange(StenstrSm, 1994) immediately preceding to the cuephrase.In this paper, using a machine learning technique,C4.5 (Quinlan, 1993), we examine these features interms of their effectiveness in selecting organizationcue phrase and identify the most effective set oflearning features.
In addition, we evaluate the accu-racy of decision trees obtained using a large corpus.Our result reveals that, in addition to discoursestructure whose effectiveness has already revealed inprevious tudies, task structure and dialogue contextplay important roles.
Especially important are theplace of the segment in the global structure of thedialogue and the type of the immediately precedingdialogue xchange.The organization of this paper is as follows.
Sec-tion 2 discusses related work.
Section 3 mentionsthe annotation of our dialogue corpus while section4 details the learning experiment and its results arediscussed.
Section 5 refers to further work and con-cludes this paper.1002 Re la ted  workWhile cue phrases can appear in different places ininstruction dialogues, we focus on the organizationcue phrases that occur at the beginning of discoursesegments referring to goals or direct actions.
Thisis because such kind of cue phrases have the im-portant function of describing the basic structure ofthe dialogue.
In a procedural instruction dialogue,the sequence of actions for the procedure is directedstep by step.
In terms of Rhetorical Structure The-ory (RST) (Mann and Thompson, 1987), it is con-sidered that the basic structure of such kind of dis-course is constructed by connecting segments thatrefer to goals or primitive actions with "sequence"relation (RSsner and Stede, 1992; Kosseim and La-palme, 1994).
Therefore, the cue phrases which oc-cur at the beginning of segments that are connectedwith "sequence" relation and refer to goals or directactions play important roles in signaling the basicstructure of the dialogue.
Moreoyer, such kind of cuephrases are observed very frequently in instructiondialogues.
In their empirical study on the charac-teristics of task oriented dialogues, Oviatt and Co-hen (1990) reported that, in instruction dialogueson assembling a pump, cue phrases uch as "Okay","now" and "next" occur at the beginning of 98.6% ofthe new segments that instruct assembly actions intelephone dialogues.
Based on the above, we thinkit important for dialogue generation to select andset appropriate cue phrases at the beginning of dis-course segments that refer to goals or direct actions.Moser and Moore (1995a) and Moser and Moore(1995b) investigated the relationship between cueplacement and selection.
They showed that the cuephrases are selected and distinguished epending ontheir placement.
Somewhat differently, we tackle theproblem of selecting cue phrases that occur at thesame place in the segment (at the beginning of thesegment).As indicated in (Eugenio et al, 1997), in termsof natural language generation, cue usage consistsof three problems, occurrence: whether or not a cueshould be included, placement: where the cue shouldbe placed, and selection: what cue should be used.We tackle the third problem, the selection of cuephrases.
Our final goal is to establish a strategy forselecting organization cue phrases and apply it inthe generation of instruction dialogues.
While theempirical approach of this study is close to that of(Eugenio et al, 1997), they apply a machine learningtechnique to predicating cue occurrence and place-ment, not cue phrase selection.3 Annotat ion  o f  d ia logue  corpusIn this section, we mention the way of the annotationin our corpus.
Then, the inter-coder agreement forthe annotations i discussed.3.1  C lass  o f  cue  phrasesThe domain of our dialogue corpus in Japanese is toinstruct the initial setting of an answering machine.The corpus consists of nine dialogues with 5,855 ut-terances.
There are, 1,117 cue phrases in 96 distinctds3.3ds3.4ds3.5D T: And, there is a time-punch button underthe panel,{P: Yes. }
push it.P: Yes.I"" T: An.._.d month and day are input asL integers.
ds3.4.1 P: Yes.
T: Input by dial button.
P: Yesf-- T: First, It is January 27th.P: Yes.- -T ' Input0  1 2 7 ds3 4 21 .
.
.
.
.? "
|  i-P: Can I input under thisI ds3"4"2"1/ condition?| l -T :  Yest__ p: I've done.iT: Yes, ~ today is Thursday, {P:Yes } the days of the week arenumbered from one to sevends3.4.3 starting with Sunday, {P: Yes }since today is Thursday, inputnumber is5.t__p: Yes, I've input it. --T: An._..d, it is two thirty now, {P: Yes } using the 24 hour time ds3.4.4 system, {P: yes } input 1, 4, 3, O.m a__p: Yes.
I've input it.B T: Finally, push the registration buttonagain.-- P: Yes.Figure 1: An example of annotated ialoguecues 1.
There are 31 cue phrases that occur morethan five times.As the result of classifying these 31 cue phrasesbased on the classification of Japanese connectives(Ichikawa, 1978; Moriyama, 1997) and cue phraseclassification in Enghsh (Grosz and Sidner, 1986;Cohen, 1984; Knott and Dale, 1994; Moser andMoore, 1995b), 20 cue phrases, which occurred to-tal of 848 times, were classified into three classes:changeover, such as soredeha, deha ("now", "nowthen" in English), conjunctive, such as sore.de, de("and", "and then"), and ordinal, such as mazu,tsugini ("first", "next").
Besides these simple cuephrases, there are composite cue phrases such assoredeha-tsugini ("now first").
Note that meaningand the usage of each of these Japanese cue phrasesdoes not completely correspond to those of the En-glish words and phrases in parentheses.
For exam-ple.
the meaning of the Japanese cue phrase sore-deha is close to the English word now in its discoursesense.
However, soredeha does not have a sententialsense though now does.The purpose of this study is to decide which ofthese three classes of simple cue phrases hould beselected as the cue phrase at the beginning of a dis-ICue phrases which occur in the middle of the seg-ment and in the segment other than action direction suchas clarification segment are included.I01course segment.
We do not deal with compositetypes of cue phrases.3.2 Annotat ion  of  d iscourse s t ructureAs the basis for examining the relationship betweencue phrase and dialogue structure, discourse seg-ment boundary and the level of embedding of thesegments were annotated in each dialogue.
We de-fine discourse segment (or simply segment) as chunksof utterances that have a coherent goal (Grosz andSidner, 1986; Nakatani et al, 1995; Passonneau andLitman, 1997).
The annotation of hierarchical re-lations among segments was based on (Nakatani etal., 1995).Figure 1 shows an example from the annotateddialogue corpus.
This dialogue was translated fromthe original Japanese.
This example provides in-struction on setting the calendar and clock of theanswering machine.
The purpose of ds3.4 is to in-put numbers by dial buttons and each input actionis directed in ds3.4.2, ds3.4.3, and ds3.4.4, for in-putting the date, the day of the week, and the time,respectively.
Subdialogues such as confirmation andpupil initiative clarification are treated as one seg-ment as in ds3.4.2.1.
The  organization cue phrasesare underlined in the sample dialogue.
For example,the cue phrase for ds3.3 is "And", and that for ds3.5is "Finally" 23.3 Annotat ion  of  d iscourse purpose andpre-exchangeAs the information about task structure and dia-logue context, we annotated the discourse purposeof each segment and the dialogue exchange at theend of the immediately preceding segment.In annotating the discourse purpose, the codersselected the purpose of each segment from a topiclist.
The topic list consists of 127 topics.
It has ahierarchical structure and represents he task struc-ture of the domain of our corpus.
When the dis-course purpose cannot be selected from the topiclist, the segment was annotated as "others".
In suchsegments, the information about task structure can-not be obtained.The pre-exchange is annotated as a kind of dia-logue context and used as one of the learning fea-tures itself.
The coders annotated the kind of pre-exchange by selecting one of nine categories of ex-changes which are defined in section 4.1 in detail.3.4 Inter -coder  agreement  for the annotat ionAs mentioned in the previous ections, we annotatedour corpus with regard to the following characteris-tics: the class of cue phrases (ordinal, changeover,conjunctive), segment boundary, and hierarchicalstructure of the segment, the purpose of the seg-ment, and the dialogue exchange at the end of theimmediately preceding segment.The extent of inter-coder agreement between twocoders in these annotation are calculated by using:When a cue phrase follows acknowledgement (Yes)or a stammer, these speech fragments that do not have~ftropositional content axe ignored and the cue phraseser the fragments axe annotated as the beginning ofthe segment.Cohen's Kappa ~ (Bakeman and Gottman, 1986;Carletta, 1996).
The inter-coder agreement (to)about the class of cue phrase is 0.68, about the pur-pose of the segment is 0.79, and about the type ofpre-exchange is 0.67.
The extent of agreement aboutthe segment boundary and the hierarchical struc-ture is calculated using modified Cohen's Kappa pre-sented by (Flammia and Zue, 1995).
This Cohen'sKappa is 0.66.Fleiss et al (1981) characterizes kappas of .40 to.60 as fair, .60 to .75 as good, and over .75 as ex-cellent.
According to this categorization of levels ofinter-coder agreement, the inter-coder agreement forcue phrase, pre-exchange, and discourse boundaryand structure is good.
The agreement on segmentpurpose is excellent.
Thus, these results indicatethat our corpus coding is adequately rehable andobjective.When the two coders' analyses did not agree, thethird coder judged this point; only those parts whoseanalysis is output by more than two coders was usedas learning data.4 Learn ing  exper iment4.1 Learning featuresThis section describes a learning experiment usingC4.5 (Quinlan, 1993).
First, we define 10 learningfeatures concerned with three factors.
(1)Discourse s t ructure :  Structural informationabout the preceding dialogue.Embedd ing  The depth of embedding from thetop level.P lace  The number of elder sister segments.P lace2 The number of elder sister segmentsexcept pupil initiative segments.Recent  e lder  s i s te r ' s  cue  (Res -cue)  Thecue phrase that occurs at the beginning ofthe most recent elder sister segment.
Theyaxe classified into three kinds of simple cuephrases: ord (ordinal), ch (changeover),con (conjunctive) or a kind of compositecue phrase such as ch+ord (changeover +ordinal).Res-cue2 The cue phrase that occurs at thebeginning of the most recent elder sistersegment except pupil initiative segments.Discourse  t rans i t ion  (D- t rans)  Types ofchange in attentional state accompanied bytopic change 3 such as push and pop.
Popfrom the pupil initiative subdialogue is cat-egorized as "ui-pop".
(2)Task s t ructure :  Information that estimatesthe complexity of succeeding dialogue.3Clark (1997) presents a term "discourse topic" asconcept equivalent to focus space in (Grosz and Sidner,1986), and call their transition "discourse transition".For example, "push" is defied as the transition to thesub topic, and "next" is defined as the transition to thesame level proceeding topic.102factorDiscoursestructureTaskstructureDialoguestructureTable 1: The learning featuresfeature nameEmbeddingFla~:el~,lace2H.es-cuel~es-cue2D-transT-hmraxchy~ubgoalFre-exchangeFs-cuevaluesintegermtegermtegernil, ord, Oh, con, ch+ord,con?ord, con+ch, othernil, ord, C\[1, Cou, cn?ord~con+ord, con+ch, otherpop, push, next, m-pop, ~Aintegermtegerconf, req, inf, quest, ui-conf,ui-req, tti-inf, ui-quest, NAnil, oral, ch, con, ch+ord,con+ord, con+ch, otherTask-h ie rarchy  (T -h ie rarchy)  The numberof goal-subgoal relations from the currentgoal to primitive actions.
This estimatesthe depth of embedding in the succeedingdialogue.Subgoa l  The number of direct subgoals of thecurrent goal.
If zero, then it is a primitiveaction.
(3)D ia logue context  Information about the pre-ceding segment.P re -exchange Type of exchange that occursat the end of the immediately precedingsegment, or type of exchange immediatelypreceding the cue phrase.
There are fourcategories, conf (confirmation-answer), req(request-answer), inf (information-reply).ques (question-answer).
They are alsodistinguished by the initiator of the ex-change; explainer initiative or pupil initia-tive.
When the category of the exchange isnot clear, it is classified as not applicable(NA).
Therefore, there are nine values forthis feature.Preced ing  segment ' s  cue  (Ps -cue)  Thecue phrase that occurs at the beginning ofthe immediately preceding segment.The values of these features are shown in Ta-ble 1.
Among the above learning features, Embed-ding, Place, Place$, Res-cue, Res-cue~, Ps-cue, andD-trans are derived automatically from the infor-mation about segment boundary and the segmenthierarchy annotated in the corpus (an example isshown in Figure 1).
The depth of task hierarchy (T-hierarchy) and the number of direct subgoais (Sub-goal) are determined by finding the annotated seg-ment purpose in the given task structure.4.2 Learning a lgor i thmIn this study, C4.5 (Quinlan, 1993) is used as learn-ing program.
This program takes two inputs, (1)thedefinition of classes that should be learned, and thenames and the values of a set of features, and (2)the data which is a set of instances whose class andfeature values are specified.
As a result of machinelearning, the program outputs a decision tree fe~judgement.We use cross-validation for estimating the accu-racy of the model because this method avoids thedisadvantages common with small data sets whosenumber of cases is less than 1000.
In this study,10-fold cross-validation is applied, so that in eachrun 90% of the cases are used for training and theremaining 10% are used for testing.
The C4.5 pro-gram also has an option that causes the values ofdiscrete attribute to be grouped.
We selected this,option because there are many values in some fea-tures and the decision tree becomes very complex ifeach value has one branch.4.3 Resu l ts  and d iscuss ionDecision trees for distinguishing the usage of threekinds of cue phrases (changeover, ordinal, and con-junctive) were computed by the machine learning al:gorithm C4.5.
As learning features, the 10 featuresmentioned in section 4.1 are used.
From nine dia-logues; 545 instances were derived as training data.In 545 instances, 300 were conjunctive, 168 werechangeover, and 77 were ordinal.
The most frequentcategory, conjunctive, accounts for 557o of all cases.Thus, the baseline error rate is 4570.
This meansthat one would be wrong 45~0 of the time if thiscategory was always chosen.First, the prediction power of each learning fea-ture is examined.
The results of learning experi-ments using single features are shown in Table 2.
I.~pruning the initial tree, C4.5 calculates actual andestimated error rates for the pruned tree.
The errorrate shown in this table is the mean of estimatederror rates for the pruned trees under 10-fold cross-validation.
The 95% confidence intervals are shownafter "'?".
Those are calculated using Student's tdistribution.
The error rate el is significantly betterthan e2 if the upper bound of the 95% confidenceinterval for e~ is lower than the lower bound of the95% confidence interval for e2.
As shown in Table 2,the decision tree obtained with the Pre-exchange f n-103Table 2: The error rates with each modelEmbedding'PlacePlace'~-Res-cuel-tes-cue2D-transT-hierarchy" '  Subg0al46.5 2:0.142.5 ?
0.443.8 ::k 0.444.9 ?
0.345.1 ?
0.445.0 ?
0.542.4 ?
0.342.5 ?
0.3Fre-exchaageFs-cueDS modelTask modelD(_, modelAll Ieature modelSimplest model41.5 ?
0.546,5 =k 0.335,6 ?
0.441,8 2:0.339.1 ::l:: 0.629.9 2:0.430.6 ?
0.3Table 3: The set of learning features for each modelI Discourse Structure il rl'ask StructureModel Embedd- Flace I Place2 Res- l-tes- { D-trans I T- 5ubgoalin~; .
: cue cue 2 hierarchyDS ~ 4 4 4 V ,/Task V ,/DCAn feature ?
V ~ q ,/ ?
: ,?_ 4Simplest', h f ~/ ' ~/ Ii .. ~/II Dialogue ContextI Pre- Fs-cueexch~nse I4 44 44 4ture performs best, and its error rate is 41.5%.
Inall experiments, the error rates are more than 40%and none are considerably better than the baseline.These results suggest hat using only a single learn-ing feature is not sufficient for selecting cue phrasescorrectly.As the single feature models are not sufficient, itis necessary to find the best set of learning featuresfor selecting cue phrases.
We call a set of features amodel and the best model (the best set of features) isobtained using the following procedure.
First, we setsome multiple features models and carry out learn-ing experiments using these models in order to findthe best performing model and the best error rate.We then eliminate the features from the best perfor-mance model in order to make the model simpler.Thus, the best model we try to find is the one thatuses the smallest number of learning features butwhose performance equals the best error rate.We construct four multiple feature models.
Thename of the model and the combination of featuresin the model are shown in Table 3.
The discoursestructure model (the DS model) used learning fea-tures concerned with discourse structure.
The Taskmodel used those concerned with task structure, andthe dialogue context (the DC model) used those con-cerned with dialogue context.
The All .feature modeluses all learning features.
The best error rate amongthese models is 29.9% in All .feature model as shownin Table 2.
The error rate is reduced about 15%from the baseline.Therefore, the best model is the one that usesfewer learning features than the All .feature modeland that equals the performance of that model.
Inorder to reduce the number of features considered,we examined which features have redundant infor-mation, and omitted these features from the All \]ea-ture model.
The overlapping features were found byexamining the correlation between the features.
Asfor numerical features that take number values, thecorrelation coefficient between Place and Place~, andbetween T-hierarchy and Subgoal are high (p=0.694,0.784, respectively).
As for categorical features,agreement between Res-cue and Res-cue2 is 95%.These highly correlated features can be representedby just one of them.
As the result of many ex-periments varying the combination of features used,we determined the Simplest model which uses sixfeatures: Embedding, Place, D-trans, Subgoal, Pre-ezchange, and Ps-cue as shown at the bottom linein Table 3.
The error rate of the Simplest modelis 30.6% as shown in Table 2.
It is very close tothat of the All \]eature model though the differenceis statistically significant.In addition to comparing only the overall er-ror rates, in order to compare the performanceof these two models in more detail, we calculatedthe information retrieval metrics for each category,changeover, ordinal, and conjunctive.
Figure 2shows the equations used to calculate the metrics.For example, recall rate is the ratio of the cuephrases correctly predicted by the model as class Xto the cue phrases of class X in the corpus.
Precisionrate is the ratio of cue phrases correctly predicted tobe class X to all cue phrases predicted to be class X.In addition, in order to get an intuitive feel of over-all performance, we also calculated the sum of thedeviation from ideal values in each metric as in (Pas-sonneau and Litman, 1997).
The summed eviationis calculated by the following numerical formula:(1 - Recall) + (1 - Precision) +Fallout + ErrorTable 4 shows the results of these metrics for thetwo models.
Standard deviation is shown in paren-theses.
The value of each metric is the average of104Table 4: Performance on training set using cross-validation\[ Mode lAll featuremodelSimplestmodelCue phrase t.tecaU Precimon FaUout \[ Error \[ Summed Deviation Iordinal 0.50(0.HI) 0.64(0.10) 0.05(0.03) , 0.11 (0.03) , 1.03(0.23) ,changeover  0.53 (0.1,:) 0.58 (0.07) 0.17 (0.05) \[ 10"26  (0.04) 1.32 (0.23)conjunctive 0.80 (0.01;) 0.73 (0.05) 0.38 (0.11) 0.28 (0.04) 1.12 (0.16)ordinal 0.48 (0.17) 0.66 (0.17) 0.45 (0.03) 0.11 (0.02) 1.01 (0.26) Ichangeover I 0.50 (0.12) 0.62 (0.08) 0.14 (0.03) 0.25 (0.05) 1.27 (0.24) II conjunctive \[ 0.85 (0.04) 0.72 (0.04) 0.40 (0.08) 0.26 (0.04) 1.09 ~0.17) IClass-X C4.5Program not-Class-XCorpusClass-X not-Class-Xa bc dRecall = a Fallout = b (a+c) (b+d)Precision = a Error = (b+c)(a+b) (a+b+c+d)Figure 2: Information retrieval metricsthe metrics on the test set in each run of 10-foldcross-validation.
Comparing the summed deviation.the performance ofthe Simplest model is better thanthat of the All feature model in all categories of cuephrases.
The summed deviations of the Simplestmodel, 1.01 for ordinal, 1.27 for changeover, and 1.09for conjunctive, are lower than those of the All fea-ture model.
Thus, as a result of evaluating the mod-els in detail using the information retrieval metrics,it is concluded that the Simplest model is the bestperforming model.
In addition, the Simplest model isthe most elegant model because it uses fewer learn-ing features than the All feature model.
Just sixfeatures, Embedding, Place, D-trans, Subgoal, Pre-exchange, and Ps-cue, are enough for selecting orga-nization cue phrases.Classifying the six features in the Simplest model,it is found that these features come from all fac-tors, discourse structure, task structure, and dia-logue context.
Embedding, Place, D-trans are thefeatures of discourse structure, Subgoal is about taskstructure, and Pre-exchange and Ps-cue are aboutdialogue context.
This result indicates that all thefactors are necessary to predict cue phrases.
Theimportant factors for cue phrase selection are taskstructure and dialogue context as well as discoursestructure, the focus of many earlier studies.While we identified the six features from the threekinds of factors, by looking at the decision trees cre-ated in the learning experiment, we found which fea-tures were more important han others in selectingcue phr~es.
The features appearing near the rootnode are more important.
Figure 3 shows the toppart of a decision tree obtained from the Simplestmodel.
In all 10 decision trees resulting from thecross-validation experiment in the Simplest model,Place feature appears at the root node.
In 7 of10 trees, Embedding and Pre-exchange appeared justbelow the root node.
In these trees, if the Place ofthe segment is the first at that level (i.e.
there is noelder sister.
), then Embedding appears at the nextnode, otherwise if the segment is not the first oneat that level, then Pre-exchange appears a t the  nextnode.
Thus, if there are some elder sister segments,information about dialogue context is used for se-lecting cue phrases.
On the other hand, if there isno elder sister segment, information about discoursestructure is used for the judgement.
These resultssuggest hat the information about discourse struc-ture, especially place of segments and the depth ofembedding, and the dialogue context, especially thekind of immediately preceding dialogue exchange,play important roles in cue phrase selection.5 Conc lus ion  and  Fur ther  workThis paper reported the results of using a ma-chine learning algorithm for identifying learning fea-tures and obtaining decision trees for selecting cuephrases.
It also reported the result of a quantitativeevaluation of the decision trees learned.
Learningfeatures concerning three factors, discourse struc-ture, task structure, and dialogue context, were ex-amined.
By carrying out many experiments in whichthe combinations of learning features were varied, wefound the most simple and effective learning featureset.
The accuracy of the best model that uses 6learning features is about 70%.
The error rate is re-duced about 25% from the baseline.
These resultssupport he claims of previous tudies that discoursestructure influence cue selection.
In addition, it isrevealed that task structure and dialogue context arealso indispensable factors.We focus on predicting the cue phrases that oc-cur at the beginning of discourse segments for sig-naiing inter-segment "sequence" relation.
Elhadadand McKeown (1990), on the other hand, has pre-sented a model for distinguishing connectives, whichlink two propositions, using some pragmatic con-straints.
In (Moser and Moore, 1995a; Moser andMoore, 1995b), the relationship between placementand selection of cue phrases was investigated usingthe core:contributor relations among units within asegment (Moser and Moore, 1995a).
Although wediscussed only the "sequence" relation between the10,5( Ernbedding~ ~Pre-exchan'ge)>3~3 ?onf, ui-inf,~ req, inf, ui-o thers  "X~onf, ui-qchangeover .... ~ ....~ Oh, con, .ord, chord//other~ nilconjunctive changeover ....Figure 3: Top part of a decision treesegments, the methods presented here will be usefulin extending our model so as to select other kinds ofcue phrases.Re ferencesRoger Bakeman and John M. Gottmaa.
1986.
Ob-serving Interaction.
Cambridge University Press.Jean Carletta.
1996.
Assessing agreement on clas-sification tasks: The kappa statistic.
Computa-tional Linguistics, 22(2):249-254.Alison Cawsey.
1993.
Explanation and Interaction:The Computer Generation of Expalanatory Dia-logues.
MIT Press.Herbert H. Clark.
1997.
Using language.
CambridgeUniversity Press.Robin Cohen.
1984.
A computational theory of thefunction of clue words in argument understand-ing.
In Proceedings of the lOth International Con-ference on Computational Linguistics.
pages 251-258.Michael Elhadad and Kathleen R. McKeown.
1990.Generating connectives.
In Proceedings of the 13thInternational Conference on Computational Lin-guistics, pages 97-101.Barbara Di Eugenio; Johanna D. Moore, and Mas-simo Paolucci.
1997.
Learning features that pre-dict cue usage.
In Proceedings of the 35th An-nual Meeting o\] the Association for Computa-tional Linguistics and the 8th Conference of theEuropean Chapter off the Association off Computa-tional Linguistics, pages 80-87.Giovanni Flammia nd Victor Zue.
1995.
Empiricalevaluation of human performance and agreementin parsing discourse constituents in spoken dia-logue.
In Eurospeech, pages 1965-1968.J.
L. Fleiss, J. Cohen, and B. S. Everitt.
1981.Statistics Methods for Rates and Proportions.
Wi-ley.Barbara J. Grosz and Candace L. Sidner.
1986.
At-tention, intentions, and the structure of discourse.Computational Linguistics, 12(3):175-204.Barbara J. Grosz.
1977.
The representation a d useof focus in dialogue understanding.
Technical Re-port 151, Artificial Intelligence Center, SRI Inter-national.Raymonde Guindon.
1986.
The structure of user-adviser dialogues: Is there method in their mad-ness?
In Proceedings off the 2$th Annual Meetingof the Association/or Computational Linguistics,pages 224-230.Takashi Ichikawa.
1978.
Bunshouron gaisetsu (inJapanese).
Kyouiku shuppan.Alist~r Knott and Robert Dale.
1994.
Using lin-guistic phenomena to motivate a set of coherencerelations.
Discourse Processes, 18:35---62.Leila Kosseim mad Guy Lapalme.
1994.
Content andrhetorical status election in instruction texts.
InProceedings of the 7th International Workshop onNatural Language Generation, pages 53-60.William C. Mann and Sandra A. Thompson.
1987.Rhetorical structure theory: A theory of textorganization.
Technical Report ISI/RS-87-190,USC/ISI.Johanna D. Moore.
1995.
Participating in Explana-tory Dialogues: Interpreting and Responding toQuestions in Context.
MIT Press.Takurou Moriyama, 1997.
Speech and Grammar (inJapanese), chapter 5.
Kuroshio Shuppan.Megan Moser and Johanna D. Moore.
1995a.
In-vestigating cue selection and placement in tuto-rim discourse.
In Proceedings of the 33th An-nual Meeting of the Association for Computa-tional Linguistics, pages 130--135.Megan Moser and Johanna D. Moore.
1995b.
Us-ing discourse analysis and automatic text genera-tion to study discourse cue usage.
In AAAI 1995Spring Symposium Series: Empirical Methods inDiscourse Interpretation and Generation, pages92-98.Christine H. Nakatani, Barbara J. Grosz, David D.Ahn, and Julia Hirschberg.
1995.
Instructions forannotating discourses.
Technical Report TR-21-95, Center for Research in Computing Technology,Harvard University.Sharon L. Oviatt and Philip R. Cohen.
1990.
Dis-course structure and performance efficiency in in-teractive and noninteractive spoken modalities.Technical Report CSLI-90-138, Center for theStudy of Language and Information.Rebecca J. Passonneau and Diane J. Litman.
I997.Discourse segmentation byhuman and automatedmeans.
Computational Linguistics, 23(1):103-139.John Ross Quinlan.
1993.
C~.5: Programs for Ma-chine Learning.
Morgan Kaufmann.Deitmar RSsner and Manfred Stede.
1992.
Cus-tomizing nST for the automatic productionof technical manuals.
In R. Dale, E. Hovy,D.
RSsner, and O.
Stock.
editors, Proceedingsof the 6th International Workshop on NaturalLanguage Generation, pages 199--215.
Springer-Verlag.Deborah Schiffrin.
1987.
Discourse markers.
Cam-bridge University Press.Anna-Brita StenstrSm.
1994.
An Introduction toSpoken Interaction.
Longma~.106
