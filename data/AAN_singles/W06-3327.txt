Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 136?137,New York City, June 2006. c?2006 Association for Computational LinguisticsSubdomain adaptation of a POS tagger with a small corpus1 IntroductionFor the domain of biomedical research abstracts,two large corpora, namely GENIA (Kim et al2003) and Penn BioIE (Kulik et al2004) are avail-able.
Both are basically in human domain and theperformance of systems trained on these corporawhen they are applied to abstracts dealing withother species is unknown.
In machine-learning-based systems, re-training the model with additionof corpora in the target domain has achieved prom-ising results (e.g.
Tsuruoka et al2005, Lease et al2005).
In this paper, we compare two methods foradaptation of POS taggers trained for GENIA andPenn BioIE corpora to Drosophila melanogaster(fruit fly) domain.2 MethodMaximum Entropy Markov Models (MEMMs)(Ratnaparkhi 1996) and their extensions (Tutanovaet al2003, Tsuruoka et al2005) have been success-fully applied to English POS tagging.
Here we usesecond-order standard MEMMs for learning POS.where the model parameters are determined withmaximum entropy criterion in combination a regu-larization method called inequality constraints(Kazama and Tsujii 2003).
This regularizationmethod has one non-negative meta-parametercalled width-factor that controls the ?fitness?
of themodel parameters to the training data.We used two methods of adapting a POS taggingmodel.
One is to add the domain corpus to thetraining set.
The other is to use the reference distri-bution modeling, in which the training is per-This work is partially supported by SORST program, JapanScience and Technology Agency.formed only on the domain corpus and the infor-mation about the original training set is incorpo-rated in the form of the reference distribution inthe maximum entropy formulation (Johnson et al2000, Hara et al2005).A set of 200 MEDLINE abstracts on D.melanogaster, was manually annotated with POSaccording to the scheme of the GENIA POS corpus(Tateisi et al2004) by one annotator.
The new cor-pus consists of 40,200 tokens in 1676 sentences.From this corpus which we call ?Fly?
hereafter,1024 sentences are randomly taken and used fortraining.
Half of the remaining is used for devel-opment and the rest is used for testing.We measured the accuracy of the POS taggertrained in three settings:Original: The tagger is trained with the union ofWall Street Journal (WSJ) section of PennTreebank (Marcus et al1993), GENIA, andPenn BioIE.
In WSJ, Sections 0-18 for train-ing, 19-21 for development, and 22-24 fortest.
In GENIA and Penn BioIE, 90% of thecorpus is used for training and the rest isused for test.Combined: The tagger is trained with the unionof the Original set plus N sentences from Fly.Refdist: Tagger is trained with N sentencesfrom Fly, plus the Original set as reference.In Combined and Refdist settings, N is set to 8, 16,32, 64, 128, 256, 512, 1024 sentences to measurethe learning curve.3 ResultsThe accuracies of the tagger trained in the Origi-nal setting were 96.4% on Fly, 96.7% on WSJ,Yuka Tateisi Yoshimasa Tsuruoka Jun-ichi TsujiiFaculty of InformaticsKogakuin UniversityNishishinjuku 1-24-2Shinjuku-ku, Tokyo, 163-8677, JapanSchool of InformaticsUniversity of ManchesterManchester M60 1QD, U.K.Dept.
of Computer ScienceUniversity of TokyoHongo 7-3-1, Bunkyo-ku,Tokyo 113-0033, JapanSchool of InformaticsUniversity of ManchesterManchester M60 1QD, U.K.13698.1% on GENIA and 97.7% on Penn BioIE cor-pora respectively.
In the Combined setting, the ac-curacies were 97.9% on Fly, 96.7% on WSJ,98.1% on GENIA and 97.7% on Penn BioIE.
WithRefdist setting, the accuracy on the Fly corpus wasraised but those for WSJ and Penn BioIE corporadropped from Original.
When the width factor wwas 10, the accuracy was 98.1% on Fly, but 95.4%on WSJ, 98.3% on GENIA and 96.6% on PennBioIE.
When the tagger was trained only on WSJthe accuracies were 88.7% on Fly, 96.9% on WSJ,85.0% on GENIA and 86.0% on Penn BioIE.When the tagger was trained only on Fly, the accu-racy on Fly was even lower (93.1%).
The learningcurve indicated that the accuracies on the Fly cor-pus were still rising in both Combined and Refdistsettings, but both accuracies are almost as high asthose of the original tagger on the original corpora(WSJ, GENIA and Penn BioIE), so in practicalsense, 1024 sentences is a reasonable size for theadditional corpus.
When the width factor wassmaller (2.5 and 5) the accuracies on the Fly cor-pus were saturated with N=1024 with lower values(97.8% with w=2.5 and 98.0% with w=5).The amount of resources required for the Com-bined and the Refdist settings were drastically dif-ferent.
In the Combined setting, the learning timewas 30632 seconds and the required memory sizewas 6.4GB.
On the other hand, learning in the Ref-dist setting took only 21 seconds and the requiredmemory size was 157 MB.The most frequent confusions involved the con-fusion between FW (foreign words) with anotherclass.
Further investigation revealed that most ofthe error involved Linnaean names of species.
Lin-naean names are tagged differently in the GENIAand Penn BioIE corpora.
In the GENIA corpus,tokens that constitute a Linnaean name are taggedas FW (foreign word) but in the Penn BioIE corpusthey are tagged as NNP (proper noun).
This seemsto be one of the causes of the drop of accuracy onthe Penn BioIE corpus when more sentences fromthe Fly corpus, whose tagging scheme follows thatof GENIA, are added for training.4 ConclusionsWe compared two methods of adapting a POS tag-ger trained on corpora in human domain to fly do-main.
Training in Refdist setting required muchsmaller resources to fit to the target domain, butthe resulting tagger is less portable to other do-mains.
On the other hand, training in Combinedsetting is slower and requires huge memory, butthe resulting tagger is more robust, and fits rea-sonably to various domains.ReferencesTadayoshi Hara, Yusuke Miyao and Jun'ichi Tsujii.2005.
Adapting a probabilistic disambiguation modelof an HPSG parser to a new domain.
In Proceedingsof  IJCNLP 2005, LNAI 3651, pp.
199-210.Mark Johnson and Stefan Riezler.
2000.
Exploitingauxiliary distributions in stochastic unification-basedgrammars.
In Proceedings of 1st NAACL.Jun?ichi Kazama and Jun?ichi Tsujii.
2003.
Evaluationand extension of maximum entropy models with ine-quality constraints.
In Proceedings of EMNLP 2003.Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, andJun?ichi Tsujii.
2003.
GENIA corpus ?
a semanti-cally annotated corpus for bio-textmining.
Bioinfor-matics, 19(Suppl.
1):i180?i182.Seth Kulick, Ann Bies, Mark Liberman, Mark Mandel,Ryan McDonald, Martha Palmer, Andrew Schein,Lyle Ungar, Scott Winters, and Pete White.
2004.
In-tegrated annotation for biomedical information ex-traction.
In Proceedings of BioLINK 2004, pp.
61?68.Matthew Lease and Eugene Charniak.
2005.
ParsingBiomedical Literature, In Proceedings of  IJCNLP2005, LNAI 3651, pp.
58-69.Mitchell P. Marcus, Beatrice Sanorini and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: the Penn Treebank.
Computa-tional Linguistics, Vol.19, pp.
313-330.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Modelfor Part-Of-Speech Tagging.
In Proceedings ofEMNLP 1996.Yuka Tateisi and Jun'ichi Tsujii.
(2004).
Part-of-SpeechAnnotation of Biology Research Abstracts.
In theProceedings of LREC2004, vol.
IV, pp.
1267-1270.Kristina Toutanova,  Dan Klein, Christopher Manningand Yoram Singer.
2003.
Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.In Proceedings of HLT-NAACL 2003, pp.
173-180.Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,Tomoko Ohta, John McNaught, Sophia Ananiadou,and Jun'ichi Tsujii.
2005.
Developing a Robust Part-of-Speech Tagger for Biomedical Text.
In Proceed-ings of 10th Panhellenic Conference on Informatics,LNCS 3746, pp.
382-392.137
