Proceedings of the 8th International Conference on Computational Semantics, pages 128?139,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsDialogue Modelling and the Remitof Core GrammarEleni Gregoromichelaki?, Yo Sato?, Ruth Kempson?Andrew Gargett?, Christine Howes?
?King?s College London,?Queen Mary University of London1 IntroductionIn confronting the challenge of providing formal models of dialogue, withits plethora of fragments and rich variation in modes of context-dependentconstrual, it might seem that linguists face two types of methodologicalchoice: either (a) conversation employs dialogue-specific mechanisms, forwhich a grammar specific to such activity must be constructed; or (b) vari-ation arises due to independent parsing/production systems which invokea process-neutral grammar.
However, as dialogue research continues to de-velop, there are intermediate possibilities, and in this paper we discuss theapproach developed within Dynamic Syntax (DS, Kempson et al 2001,Cann et al 2005), a grammar framework within which, not only the parser,but indeed ?syntax?
itself are just a single mechanism allowing the pro-gressive construction of semantic representations in context.
Here we takeas a case study the set of phenomena classifiable as clarifications, reformu-lations, fragment requests and corrections accompanied by extensions, andargue that though these may seem to be uniquely constitutive of dialogue,they are grounded in the mechanisms of apposition equivalently usable inmonologue for presenting reformulations, extensions, self-corrections etc.2 BackgroundThe data we focus on are non-repetitive fragment forms of acknowledge-ments, clarifications and corrections (henceforth, A female, B male):(1) A: Bob left.B: (Yeah,) the accounts guy.
(2)A: They X-rayed me, and took a urine sample, took a blood sample.Er, the doctorB: Chorlton?A: Chorlton, mhm, he examined me, erm, he, he said now theywere on about a slight [shadow] on my heart.128(3) A: Bob left.B: Rob?A: (No,) (Bob,) the accounts guy.Even though in the literature the fragments in (2)-(3) might be characterisedas illustrating distinct construction-types, in our view, they all illustrate howspeakers and hearers may contribute, in some sense to be made precise, tothe joint enterprise of establishing some shared communicative content, inwhat might be loosely called split utterances.
Even (1), an acknowledgement,can be seen this way upon analysis: B?s addition is similar in structure toan afterthought extension that might have been added by A herself to A?sfully sentential utterance.
It can be seen in (2) that such joint constructionof content can proceed incrementally: the clarification request in the form ofa reformulation is provided by B and resolved by A within the constructionof a single proposition.
In (3) the fragment reply can be taken to involvecorrection, in the sense that, according to the DS analysis of B?s fragmentquestion, he has provided content construable as equivalent to that derivedby processing Rob left?
(see Kempson et al (2007)).
Nevertheless suchcorrections can also incorporate extensions in the above sense, enabling asingle conjoined propositional content to be derived in a single step.It might seem that such illustration of diversity of fragment usage is am-ple evidence of the need for conversation-specific rules.
Indeed, Ferna?ndez(2006) presents a thorough taxonomy, as well as detailed formal modellingof Non-Sentential Utterances (NSUs), referring to contributions such as (1)as repeated acknowledgements involving reformulation.
Ferna?ndez modelssuch constructions via type-specific ?accommodation rules?
which make aconstituent of the antecedent utterance ?topical?.
The semantic effect ofacknowledgement is then derived by applying an appropriately defined ut-terance type for such fragments to the newly constructed context.
A distinctform of contextual accommodation is employed to model so-called helpfulrejection fragments, as in (3) (without the reformulation), whereby a wh-question is accommodated in the context by abstracting over the contentof one of the sub-constituents of the previous utterance.
The content ofthe correction is derived by applying this wh-question in the context to thecontent of the fragment (see also Schlangen (2003) for another classificationand analysis).In contrast, the alternative explored here is whether phenomena suchas (1)-(2), both of which are non-repetitive next-speaker contributions, canbe handled uniformly using the mechanisms for structure-building madeavailable in the core grammar, without recourse to construction-specific ex-tensions of that grammar and contextual accommodation rules.
This isbecause, in our view, the range of interpretations these fragments receivein actual dialogue seem to form continua with no well-defined boundariesand mixing of functions (see also comments in Schlangen (2003)).
Thus we129propose that the grammar itself simply provides mechanisms for process-ing/integrating such fragments in the current structure while their precisecontribution to the interaction can be calculated by pragmatic inferencingif needed (as in e.g.
Schlangen (2003)) or, as seems most often to be thecase, be left underspecified without disruption to the dialogue.One bonus of the stance taken here is the promise it offers for elucidatingthe grammar-parser contribution to the disambiguation task.
Part of thechallenge of modelling dialogue is the apparent multiplicity of interpretiveand structural options opened up during processing by the recurrent, of-ten overlapping fragments as seen in (2) above.
Thus, it might seem thatthe rich array of elliptical fragments available in dialogue adds to its com-plexity.
However, an alternative point of view is to see such phenomena asproviding a window on how interlocutors exploit the incrementality affordedby the grammar.
The reliance of fragments on context for interpretation,when employed incrementally, enables the hearer to immediately respond toa previous utterance at any relevant point, in a constrained manner, with-out ?recovering?
a propositional unit.
Three features of the Dynamic Syntaxmodel of dialogue (Purver et al (2006)), presented below, provide the flex-ible control required for such processing: (a) word-by-word incrementality(b) interaction with contextually provided information at every step of theconstruction process (c) tight coordination of parsing and production.3 Dynamic Syntax: A SketchDynamic Syntax (DS ) is a parsing-based framework, involving strictly se-quential interpretation of linguistic strings.
The model is implemented viagoal-directed growth of tree structures and their annotations formalised us-ing LOFT (Blackburn and Meyer-Viol (1994)), with modal operators ??
?, ??
?to define concepts of mother and daughter, and their iterated counterparts,???
?, ???
?, to define the notions be dominated by and dominate.
Under-specification and update are core aspects of the grammar itself and involvestrictly monotonic information growth for any dimension of tree structuresand annotations.
Underspecification is employed at all levels of tree rela-tions (mother, daughter etc.
), as well as formulae and type values, eachhaving an associated requirement that drives the goal-directed process ofupdate.
For example, an underspecified subject node of a tree may have arequirement expressed in DS with the node annotation ?Ty(e), for whichthe only legitimate updates are logical expressions of type entity (Ty(e));but requirements may also take a modal form, e.g.
???
?Ty(e ?
t), a con-straint that the mother node be annotated with a formula of predicate type.Requirements are essential to the dynamics informing the DS account: allrequirements must be satisfied if the construction process is to lead to asuccessful outcome.130Semantic structure is built from lexical and general computational ac-tions.
Computational actions govern general tree-constructional processes,such as introducing and updating nodes, as well as compiling interpretationfor all non-terminal nodes in the tree.
Construction of only weakly spec-ified tree relations (unfixed nodes) can also be induced, characterised onlyas dominance by some current node, with subsequent update required.
In-dividual lexical items also provide procedures for building structure in theform of lexical actions, inducing both nodes and annotations.
Thus partialtrees grow incrementally, driven by procedures associated with particularwords as they are encountered, with a pointer, ?, recording the parser?sprogress (unlike van Leusen and Muskens (2003), partial trees are part ofthe model and, unlike in other frameworks, incrementality is word-by-wordrather than sentence-by-sentence).Complete individual trees are taken to correspond to predicate-argumentstructures (with an event term associated with tense, suppressed in thispaper).
The epsilon calculus (see e.g.
Meyer-Viol (1995)) provides the se-mantic representation language.
Complex structures are obtained via a gen-eral tree-adjunction operation licensing the construction of so-called linkedtrees, hosting information that is eventually transferred onto the tree fromwhich the link is made (Kempson et al2001).
Structures projected as suchpaired trees range over restrictive relatives, nonrestrictive relatives, condi-tionals, topic structures and appositions as here.
As the semantic represen-tations employ the epsilon calculus, eventual compound epsilon terms (e.g.
?, x, P (x)) are constructed incrementally through link-adjunction:(4) A consultant, a friend of Jo?s, is retiringTy(t),Retire?
((?, x, Consultant?
(x) ?
Friend?(Jo?
)(x)))Ty(e), (?, x, Consultant?
(x) ?
Friend?(Jo?
)(x)) Ty(e?
t), Retire?Ty(e), (?, x, Friend?(Jo?
)(x))Ty(cn), (x,Friend?(Jo?
)(x))x Friend?(Jo?)Jo?Friend?Ty(cn?
e), ?P.
?, PUnderspecification of content as well as structure are central to facilitat-ing successful linguistic interaction, our primary concern here.
Pronouns,the prototypical case, contribute a place-holding metavariable, noted as e.g.U, plus an associated requirement for update by an appropriate term value:??x.Fo(x).
Equally, definite NPs contribute place-holders plus a constraintproviding a restriction/?presupposition?
on the kind of entity picked out,e.g., the man contributes the annotation UMan?
(U), T y(e).
The subscriptspecification is shorthand for a transition to a linked tree whose root node is131annotated with a formula Man?(U)1.
The update of metavariables can beaccomplished if the context contains an appropriate term for substitution:context involves storage of parse states, i.e., storing of partial tree, word se-quence to date, plus the actions used in building up the partial tree (Purveret al2006).Scope dependencies between constructed terms or the index of evalua-tion (e.g.
S) are defined on completed propositional formulae, relative toincrementally collected scope constraints (of the form x < y for constructedterms containing variables x and y respectively).
Constraints reflect on-lineprocessing considerations modulo over-riding lexical stipulations.
For ex-ample, proper names contribute as iota terms, i.e, epsilon terms reflectinguniqueness in the context, ?, x,Bob?
(x), and these project a scope depen-dency solely on the index of evaluation reflecting their widest scope property(cf Kamp and Reyle 1994).
The structure projected from A?s utterance in(1) is thus (5) (note that trees are the result of processing words but donot encode the structure of strings, word order etc., only semantic contentderived in interaction with context, thus are the equivalents of DRSs):(5)S < x Ty(t),Leave?
((?, x,Bob?
(x)))Ty(e), (?, x,Bob?
(x)) Ty(e?
t), Leave?The scope evaluation rule reflects the predicate-logic/epsilon-calculus equiv-alence ?xF (x) ?
F (?, x, F (x)) so evaluated terms eventually reflect theircontaining structure.
Hence, evaluation of (5) yields:(6) Ty(t), Leave?
(?, x,Bob?
(x) ?
Leave?
(x))A major aspect of the DS dialogue model is that both generation andparsing are goal-directed and incremental, and hence are governed by es-sentially the same mechanism.
Under this model, a human hearer-parserbuilds a succession of partial parse trees based on what (s)he has heardthus far.
Importantly, however, unlike the conventional bottom-up parsing,the DS model assumes a strong predictive element in parsing: a hearer isassumed to entertain some goal to be reached eventually at any stage ofparsing.
In (1), for example, as soon as the hearer encounters Bob, an un-derspecified propositional tree is constructed, as in the first simplified andschematised tree in Figure 1.
Then the tree ?grows?
monotonically, i.e.
suchthat at each word input, it is ?updated?
to an ?incremented?
tree that issubsumed by the original tree, as depicted in the same Figure.
This can bedescribed as a process of specifying the relevant nodes towards a completetree.
This predictive element in DS allows a speaker-generator to be mod-elled as doing exactly the same, i.e.
going through monotonically updatedpartial trees, the only difference being that (s)he also has available a more1These linked structures are suppressed in all diagrams.132fully specified goal tree representing what (s)he wishes to say, correspondingto the rightmost tree in the Figure (with ?0?
in the ?generation?
row at thebottom indicating it is entertained before utterance).
Each licensed step ingeneration, i.e.
the utterance of a word, is governed by whatever step islicensed by the parsing formalism, constrained via a required subsumptionrelation of the goal tree.
By updating their growing ?parse?
tree relativeto the goal tree, speakers are licensed to produce the associated naturallanguage string.Parsing: 1 2 3?Ty(t)qqqqqqqMMMMMMMTy(e),Bob?,?
?Ty(e ?
t)7?
?Ty(t)qqqqqqqMMMMMMMTy(e),Bob?Ty(e ?
t),Leave?,?7?Ty(t),Leave?(Bob?
),?qqqqqqqMMMMMMMTy(e),Bob?Ty(e ?
t),Leave?Generation: 1 2 0,3Figure 1: Parallel parsing and generation in DSThis architecture allows for a dialogue model in which generation (whata speaker does) and parsing (what a hearer does) function in parallel.
Thespeaker goes through partial trees subsuming a specified goal tree, whilethe hearer attempts to ?mirror?
the same series of partial trees, albeit notknowing what the content of the unspecified nodes will be.
For the dialoguesin (1)-(3), therefore, B as the hearer will have the partial representation ofwhat he has successfully parsed, required also for generation.
This provideshim with the ability at any stage to become the speaker, interrupting toask for clarification, reformulating, or providing a correction, as and whennecessary.
As we shall see, B?s parse tree reveals where need of clarifica-tion or miscommunication occurs, as it will be at that node from which asub-routine extending it takes place2.
According to our model of dialogue,repeating or extending a constituent of A?s utterance by B is licensed onlyif B, the hearer of A turned now a speaker, entertains currently a goal treethat matches or extends the parse tree of what he has heard in a monotonicfashion, although he only utters the relevant subpart of A?s utterance.
In-deed, this update is what B is seeking to clarify, correct or acknowledge.
InDS, B can reuse the already constructed (partial) parse tree in his context,rather than having to rebuild an entire propositional tree or subtree3.2The account extends the implementation reported in Purver et al (2006)3Given the DS concept of linked trees projecting propositional content, we anticipatethat this mechanism will be extendable to fragment construal involving inference (see e.g.Schlangen (2003), Schlangen and Lascarides (2003))1334 NSU fragments in Dynamic Syntax4.1 Non-repetitive AcknowledgementFrom a DS perspective, phenomena like reformulations as in (1), or exten-sions to what one understands of the other speaker?s utterance, (2), canbe handled with exactly the same mechanisms as the sentence-internal phe-nomenon independently identifiable as apposition, as in (4), and equallyusable by a single individual as a means of incrementally reformulating, cor-recting or extending what they have just uttered.
The update rule for suchstructures, applicable to all terms, takes the two type e terms so formed andyields a new term whose compound content is a combination of both.We now have the basis for analysing extensions potentially functioningas acknowledgements which build on what has been previously said as a wayof confirming the previous utterance.
Recall (1), (2).
There are two ways forfragments which reformulate an interlocutor A?s utterance to occur: (a) asinterruptions of A?s utterance with immediate confirmation of identificationof the individual concerned, see (2); (b) as confirmations/extensions of A?sutterance after the whole of her utterance has been integrated, see (1).
Bothare modelled by DS as incremental additions.Turning to (1), B?s response (Yeah,) the accounts guy constitutes a re-formulation of A?s utterance and an extension of A?s referring expression,yielding a similar content as that of an appositive expression Bob, the ac-counts guy in this case jointly constructed.
B?s reformulation/extensioncounts in effect as an acknowledgement in virtue of signalling successfulprocessing of A?s utterance without objection raised.
Thus there is no needfor a separate grammatical mechanism to process these structures.
In DSterms, after processing A?s utterance, B?s context consists of the followingtree:(7) B?s Context for producing ?Yeah?Ty(t), Leave?
(?, x,Bob?
(x) ?
Leave?(x)),?
(?, x,Bob?
(x)) Leave?B, as a speaker, can now re-use this representation as point of departurefor generating the expression the accounts guy.
In this case his goal tree,the message to be expressed, will now be annotated with a composite termmade up from both the term recovered from parsing A?s utterance and thenew addition.
This requires attaching a linked tree to the correct nodeand an appropriate update of the context tree (for reasons of space, theexact structure of the linked tree is condensed below, with subscripting asshorthand):134(8) B?s goal tree:Ty(t), Leave?
((?, x,Bob?
(x) ?Acc.guy?
(x))) ?
Leave?
(x))(?, x,Bob?
(x) ?Acc.guy?(x))Leave?
(?, x,Bob?(x))Acc.guy?
(x)In order to license generation of the expression the accounts guy, B nowneeds to verify that processing these words in the context provided by thetree in (7) will produce a tree that matches this goal tree in (8).
To achievethis, starting from (7), a series of simulated ?parse?
trees are generatedwhich indeed result in the requisite matching.
Steps include shifting thepointer to the appropriate node, projection of a linked tree from that nodeand test-processing the words the accounts guy, each step checking againstthe goal tree that a subsumption relation between the current ?parse?
treeand the goal tree is always maintained:(9) B?s parse tree licensing production of the accounts guy: link adjunctionTy(t), Leave?
(?, x,Bob?
(x) ?
Leave?
(x))(?, x,Bob?
(x)) Leave?UAcc.guy?
(U),?The only way to update this representation relative to both the restrictionon the metavariable and monotonicity of growth on any one node in a treeinvolves replacing the metavariable with (?, x,Bob?
(x)), as this is commen-surate with an extension of the term annotating the node from which thelink transition was constructed:(10) Updating B?s parse tree licensing production of the accounts guyTy(t), Leave?
(?, x,Bob?
(x) ?Acc.guy?
(x) ?
Leave?(x)),?
(?, x,Bob?
(x) ?Acc.guy?
(x)) Leave?
(?, x,Bob?(x))Acc.guy?
(x)Finally, the information is passed up to the top node of the main tree,completing the parse tree to match B?s goal tree, (8), thus licensing theutterance of the expression the accounts guy.4.2 Non-repetitive ClarificationIn the acknowledgement case above, the proposition relative to which thelinked structure is built is completed (with an already extended epsilonterm); but the same mechanism can be used when the interlocutor needsclarification, prior to any such completion of the tree.
In (2), B again, asthe speaker, takes as his goal tree a tree annotated with an expansion of theterm constructed from parsing A?s utterance but nevertheless picking outthe same individual.
Using the very same mechanism as in (1) of building alinked structure, B, interrupting A, provides a distinct expression, the nameChorlton, this time before he has completed the parse tree for A?s utterance.All that has been achieved at this point is the definite?s contribution of ameta-variable with the restriction that the individual picked out must be adoctor:135(11) A/B?s parse tree for Chorlton:?Ty(t)UDoctor?(U),?
?Ty(e ?
t)(?, x, Chorlton?
(x))As in the acknowledgement case, but this time at the node initiating thelink transition, the only possible value to provide for the metavariable Ucompatible both with its restriction and the monotoniticity constraint isthe composite term (?, x,Doctor?
(x) ?
Chorlton?(x)).
The mechanism ofconstructing paired structures involving type e terms across linked treesis identical to that employed in B?s utterance in (1), though to a ratherdifferent effect at this intermediate stage in the interpretation process.
Thisextension of the term is confirmed by A, this time replicating the compositeterm which processing B?s utterance has led to.
The eventual effect of theprocess of inducing linked structures to be annotated by coreferential type eterms may thus vary across monologue and different dialogue applications,yielding different interpretations, but the mechanism is the same.4.3 CorrectionIt might be argued nonetheless that correction is intrinsically a dialoguephenomenon.
Consider (3), for example.
One of the possible interpretationsof (3), according to the DS analysis, is that B has offered the equivalent of thecontent derived by processing Rob left?.
That is, let?s assume here that B hasmisheard and requests confirmation of what he has perceived A as saying.A in turn rejects B?s understanding of her utterance and provides moreinformation.
Presuming rejection as simple disagreement (i.e.
the utterancehas been understood, but judged as incorrect), in DS terms, this means thatA has in mind a goal tree that licensed what she had produced, which isdistinct from the one derived by processing B?s clarification.
As shown inKempson et al (2007), this means that A has been unable to process B?sclarification request as an extension of her own context.
Instead, she has toparse the clarification by exploiting the potential for introducing an initiallystructurally underspecified tree-node to accommodate the contribution ofthe word Rob.
Subsequently, by re-running the actions stored in contextpreviously by processing her own utterance of the word left, she is able tocomplete the integration of the fragment in a new propositional structure.Now, in order for A to produce the following correction, what is requiredis for A to establish as the current most recent representation in context heroriginal goal tree.
This can be monotonically achieved by recovering andcopying this original goal tree to serve as the current most immediate con-text4.
An option available to A at this point is to introduce, in additionor exclusively, a reformulation of her original utterance in order to facilitate4Mistaken representations must be maintained in the context as they can provide an-tecedents for subsequent anaphoric expressions.136identification of the named individual which proved problematic for B previ-ously.
She can answer B?s utterance of Rob?
with (No,) Bob, the accountsguy, as in (3) or simply with (No,) the accounts guy.
Both are licensedby the DS parsing mechanism without more ado.
For both, the goal treewill be as follows and it will always be the point of reference for checkingthe subsumption relation relative to the simulated parsing steps describedfurther below:(12) A?s goal treeTy(t), Leave?
((?, x,Bob?
(x) ?Acc.guy?
(x)))(?, x,Bob?
(x) ?Acc.guy?
(x)) Leave?
(?, x,Bob?(x))Acc.guy?
(x)Under these circumstances, given the DS grammar-as-parser perspective,several strategies are now available for the licensing of generation of thefragment.
A is licensed to repeat the name Bob by locally extending thenode in the context tree where the representation of the individual referred tois located by using the rule of late*adjunction, a process which involvesbuilding a node of type e from a dominating node of that type (illustrated inKempson et al 2007).
An alternative way of licensing repetition of the wordBob is to employ one of the strategies generally available for the parsing oflong distance dependencies i.e.
constructing initial tree nodes as unfixed(*adjunction).
We show here how the latter strategy can be exploited tolicense the production of the fragment by A.
(13) Parsing simulation licensing generation of Bob, the accounts guyStep 1: *Adjunction Step 2: LINK-Adjuction + testing the accounts guy?Ty(t)(?, x,Bob?(x)),?
?Ty(t)(?, x,Bob?(x)),?UAcc.guy?
(U)The only way to develop the constructed tree at Step 2 commensurate withthe goal tree (12) is to identify the value of U as (?, x,Bob?
(x)), so thisis what is entered at the newly constructed linked tree, duly leading toextension of the term originally given as annotating the unfixed node as(?, x,Bob?
(x) ?
Acc.guy?(x)).
The structure5derived by processing such anextension is exactly that of (1) above (compare goal tree in (12) aboveand tree in (8)).
Now, as mentioned before, context, as defined in DS,keeps track not only of tree representations and words but also of actionscontributed by the words and utilised in building up the tree representations.Here, according to DS, production of the correction in (3) is licensed to be5Again note that DS trees represent derived content rather than structure over naturallanguage strings.137fragmental only because the original actions for parsing/producing the wordleft are available in the context and can be recalled to complete the structureinitiated by processing/producing the name Bob.
Now these stored actionscan be retrieved to develop the tree further:(14) Parsing simulation licensing generation of Bob, the accounts guyStep 3: test-processing stored actions for left?Ty(t)(?, x,Bob?
(x) ?Acc.guy?
(x)) ?Ty(e),?
Leave?
(?, x,Bob?(x))Acc.guy?(?,x,Bob?
(x))With this partial tree being commensurate with the goal tree, all actions thatfollow are general computational processes for completing the tree: unifyingthe unfixed node to determine the subject argument, applying the subjectto the predicate, evaluating the quantified terms.
Nothing specific to thisstructure is needed.
Indeed, all these mechanisms are equally applicable byan individual speaker, perhaps more familiar as right dislocation phenomena,but equally available incrementally:(15) Bob left, (Bob) the accounts guy.5 ConclusionAs these fragments and their construal have demonstrated, despite servingdistinct functions in dialogue, the mechanisms which make such diversitypossible are general strategies for tree growth.
In all cases, the advantagewhich use of fragments provides is a ?least effort?
means of re-employingprevious content/structure/actions which constitute the minimal local con-text.
As modelled in DS, it is more economical to reuse information fromthis local context rather than constructing representations afresh (via costlyprocesses of lexical retrieval, choice of alternative parsing strategies, etc.
).A further quandary in dialogue construal is that, despite such avenuesfor economising their efforts, interlocutors are nevertheless faced with anincreasing set of interpretive options at any point during the constructionof representations.
One strategy available to hearers is to delay a disam-biguating move until further input potentially resolves the uncertainty.
How-ever, as further input is processed and parsing/interpretive options increaserapidly, the human processor struggles.
The incremental definition of theDS formalism allows for the modelling of an alternative strategy availableto hearers: at any (sub-sentential) point they could opt to intervene imme-diately, and make a direct appeal to the speaker for more information asillustrated by the clause-medial fragment interruption (2).
It seems clearthat the grammar should allow the resources for modelling this behaviourwithout any complications.138The phenomena examined here are also cases where speakers?
and hear-ers?
representations, despite attempts at coordination, may nevertheless sep-arate sufficiently for them to have to seek ?repair?
(see especially (3)).
Inthe model presented here, the dynamics of interaction allow fully incremen-tal generation and integration of fragmental utterances so that interlocutorscan be taken to constantly provide optimal evidence of each other?s represen-tations with necessary adjuncts being able to be incrementally introduced.But such mechanisms apply equally within an individual utterance, with self-correction, extension, elaboration, repetition etc.
The effect is that all the de-vices which seem so characteristic of dialogue involve mechanisms invariablyavailable within an individual?s core grammar.
This suggests a new inversemethodology: it is the challenge of modelling dialogue that can be used asa point of departure for modelling grammars for individual speakers, ratherthan the other, more familiar, way round (see also Ginzburg (forthcmg)).This reversibility is, notably, straightforwardly available to grammar for-malisms in which the incremental dynamics of information growth is thecore structural concept because emergent dialogue structure crucially ex-hibits and interpretively relies on such incrementality.AcknowledgementsThis work was supported by grants ESRC RES-062-23-0962 and Leverhulme F07-04OU.
We are grateful for comments to: Robin Cooper, Alex Davies, Arash Eshghi,Jonathan Ginzburg, Pat Healey, Greg Mills.
Normal disclaimers apply.ReferencesPatrick Blackburn and Wilfried Meyer-Viol.
Linguistics, logic and finite trees.Bulletin of the IGPL, 2:3?31, 1994.Raquel Ferna?ndez.
Non-Sentential Utterances in Dialogue: Classification, Resolu-tion and Use.
PhD thesis, King?s College London, University of London, 2006.Jonathan Ginzburg.
Semantics for Conversation.
CSLI, forthcmg.Ruth Kempson, Andrew Gargett, and Eleni Gregoromichelaki.
Clarification re-quests: An incremental account.
In Proceedings of the 11th Workshop on theSemantics and Pragmatics of Dialogue (DECALOG), 2007.Wilfried Meyer-Viol.
Instantial Logic.
PhD thesis, University of Utrecht, 1995.Matthew Purver, Ronnie Cann, and Ruth Kempson.
Grammars as parsers: Meetingthe dialogue challenge.
Research on Language and Computation, 4(2-3):289?326,2006.David Schlangen.
A Coherence-Based Approach to the Interpretation of Non-Sentential Utterances in Dialogue.
PhD thesis, University of Edinburgh, 2003.David Schlangen and Alex Lascarides.
The interpretation of non-sentential utter-ances in dialogue.
In Proceedings of the 4th SIGdial Workshop on Discourse andDialogue, pages 62?71, Sapporo, Japan, July 2003.
Association for Computa-tional Linguistics.Noor van Leusen and Reinhard Muskens.
Construction by description in discourserepresentation.
In J. Peregrin, editor, Meaning: The Dynamic Turn, chapter 12,pages 33?65.
2003.139
