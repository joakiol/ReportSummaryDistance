Large scale testing of a descriptive phrase finderHideo JohoDepartment of Information StudiesUniversity of Sheffield, Western BankSheffield, S10 2TN, UK+44 (0)114 222 2675h.joho@sheffield.ac.ukYing Ki LiuDepartment of Information StudiesUniversity of Sheffield, Western BankSheffield, S10 2TN, UKMark SandersonDepartment of Information StudiesUniversity of Sheffield, Western BankSheffield, S10 2TN, UK+44 (0)114 222 2648m.sanderson@sheffield.ac.ukABSTRACTThis paper describes an evaluation of an existing technique thatlocates sentences containing descriptions of a query word orphrase.
The experiments expand on previous tests by exploringthe effectiveness of the system when searching from a muchlarger document collection.
The results showed the systemworking significantly better than when searching over smallercollections.
The improvement was such, that a more stringentdefinition of what constituted a correct description was devised tobetter measure effectiveness.
The results also pointed topotentially new forms of evidence that might be used inimproving the location process.KeywordsInformation retrieval, descriptive phrases, WWW.1.
INTRODUCTIONRetrieving descriptions of the words and phrases, which are notoften found in dictionaries, has potential benefits for a number offields.
The Descriptive Phrase Finder (DPF) is a system thatretrieves descriptions of a query term from free text.
The systemonly uses simple pattern matching to detect a description, andranks the sentences that hold the descriptive phrases based onwithin document and cross document term occurrenceinformation.
The system does not attempt to extract descriptionsfrom text, it simply locates sentences that are hopefully relevantto a user.
It is assumed that users are able to read a sentence andlocate any description within it.
The advantage of using such anapproach is that the DPF is much simplified and does not requireparsing to find the exact location of the phrase.
Due to itssimplicity, it achieves a level of domain independence.The DPF was implemented and succeeded in The DPF wasimplemented and succeeded in retrieving sentences holdingdescriptive phrases (DPs) of a wide range of proper nouns.
Initialtesting on a collection of LA Times articles from the TRECCollection showed that 90% of the queries had at least one correctDP in the top 5 ranked sentences and 94% in the top 10 ([3]).
Itwas shown that the effectiveness of the system was in part due tothe large amount of free text being searched.
What was not shownby the experiment was if performance could be further improvedby searching an even larger text.
Consequently, a larger scaleexperiment was conducted, searching for phrases from the WorldWide Web (WWW) using the output of a commercial Web searchengine to locate candidate documents that were then processedlocally by the DPF.In addition to increasing the number of documents searched, morequeries were tested and different definitions of relevance weretried.
The rest of this short paper explains the system and showsthe results of the expanded experiment, followed by pointers tofuture work.2.
THE SYSTEMThe Web-based DPF was composed of two parts: a front-end toan existing Web search engine, which fetched documents; and thesystem that located sentences holding descriptive phrases.The Web front end simply routed queries to a Web search engine(Google), and the text of the top 600 documents returned by theengine was fetched, split into sentences (using a locally developedsentence splitter), and those sentences holding the query termwere passed onto the DPF.It ranked sentences on a score calculated from multiple sources ofevidence.
A detailed description of the DPF is found in [3].
Theprimary clue to there being a descriptive phrase in a sentence wasthe presence of a key phrase within it.
An example key phrasewas ?such as?, which may be found in the sentence: ?He usedseveral search engines such as AltaVista, HotBot and WebTop tocompare the performance?.
If such a sentence were returned to auser who entered the query ?WebTop?, they would determine itwas a search engine.
Specifically, the DPF is searching for thekey phrase in proximity to a query noun (qn) to locate adescriptive phrase (dp) e.g.?
... dp such as qn ...other key phrases used, some suggested by [2], were?
... such dp as qn ...?
... qn (and | or) other dp ...?
... dp (especially | including) qn ...?
... qn (dp) ...?
... qn is a dp ...?
.. qn, (a | the) dp, ...The phrases form the key part of the DPF as they identify wellsentences likely to contain descriptions of qn.
While the numberof times a particular qn appears in a sentence with a key phraseare small, by searching a large corpus, like the Web, the chancesof finding a few (accurately identified) descriptions of qn in theform required are high.Based on results from a testing phase, certain key phrases werefound more accurate at locating a descriptive phrase than others.Consequently, when ranking matching sentences, different scoreswere assigned depending on the accuracy of the key phrase foundwithin.
Since unfamiliar words tend to be explained or rephrasedat the early part of a document, sentence position was also afactor in the rank score, with earlier sentences given preference.Finally, cross-document information was taken into account.Across all the matching sentences for a particular query, theoccurrence of all the terms within the sentences was noted.
It wasanticipated that terms occurring more frequently within the set ofsentences were likely to belong to descriptions.Consequently, sentences holding a high number of commonlyoccurring words were given further preference in the ranking.
Thelast two pieces of information not only improved the accuracy ofranking, but also enabled the system to produce reasonable resultswhen no key phrases were matched.
A training phase where theoptimum balance between the sources of information was run onexisting training data created from the LA Time corpus describedin [3].It may be reasonable to question why such a simple approach toextracting information from free-text sources be taken when moreprincipled NLP-based techniques are well-established (e.g.
[4],[5]).
There are a number of reasons:?
Any simple approach is likely to be much faster than one thatrequires operations such as parsing.?
We believe that the use of simple but accurate methodssearching over very large corpora provides a new means ofdetermining lexical relations from corpora that are worthy offurther exploration.3.
INITIAL STUDYA pilot study was conducted, searching ten queries using the tophundred documents returned by Google.
Of the ten queries, sixhad the best description located in the top two ranked sentences,two more queries had a good description in the top two.
For allqueries, a sentence holding a descriptive phrase was returned inthe top five ranked sentences.4.
DEFINING RELEVANCEIn this and the previous evaluation described in [3], relevance wasdefined as a sentence that told the user anything about the queryterm: a liberal view of relevance (described here as binaryrelevance).
The results from the pilot, under this interpretation,showed the system performed well.
Consequently a morestringent form of relevance was devised.
A sample answer foreach query was solicited from users: for example, ?the PrimeMinister of Great Britain?
for Tony Blair.
Those key answerswere taken as an acceptable criterion of highly relevantdescriptive phrases.
Sentences ranked by the system were thencompared to the key answer.
Correctness of DPs is not enough forthis aim.
Only a DP that described a query as well as a keyanswer was regarded as relevant.
To illustrate, the sentence ?TonyBlair is the current Prime Minister of the United Kingdom.?
wasregarded as relevant, but ?Tony Blair is a political leader?
wasnot.5.
THE MAIN EXPERIMENTA total of 146 queries were tested in the main experiment: 50 ofwhich were evaluated based on key answers; 96 using binaryevaluation.
In the binary test, the DPF returned a relevant(descriptive) sentence in the top twenty sentences for all 96queries.
On average sixteen of the sentences returned wererelevant to each query.
The minimum number of relevant was sixand maximum was twenty.
Across the 96 queries, at least onerelevant sentence was found in the top five for every tested query.This is a significant improvement over the previously reportedexperimental results where 90% of queries were answered in thetop five.Using more stringent key answer based relevance, the systemsucceeded in retrieving at least one relevant sentence in the topfive for 66% of the queries, at least one in the top ten for 82%,and one in the top twenty for 88%.These results show that the DPF searching the Web (1 billiondocuments) works dramatically better than the previousexperiment using LA Times (100,000 documents).
As was shownin previous work, the size of the collection impacts on theeffectiveness of the system.
This is because by searching a largercollection, there is a better chance of locating a relevantdescriptive phrase in the format of one of the searched for keyphrases.
However in the previous work, there appeared to be anupper bound on the accuracy of the descriptive phrases alone.
Bysearching a much larger collection it is speculated that the crossdocument term occurrence statistics used contributed significantlyto improving the effectiveness of the system.6.
CONCLUSIONAn existing descriptive phrase system was adapted to work with aWeb search engine to locate phrases describing query words.
Thesystem was found to be highly effective at locating gooddescriptions: finding at least one high quality descriptive phrase inthe top 10 returned sentences for 82% of test queries.7.
FUTURE WORKWe plan to undertake a number of further experiments, examiningthrough tests, the ability of people to locate descriptions withinthe retrieved sentences.
In addition, it was notable that the resultsof the full experiment were not as good as those from the pilotstudy.
One difference between the two tests was the number ofweb documents examined: 100 top-ranked documents in the pilot;600 for the expanded experiment.
Given that a search enginegenerally retrieves more relevant documents in the higher ranks,there is likely to be more noise lower down.
It is also significantthat the search engine used was Google, which uses the page rankauthority measure ([1]) to enhance its ranking.
Therefore, wespeculate that use of an authority measure can be used to furtherimprove the quality of our DPF.
This will be investigated infuture work.8.
REFERENCES[1] Brin, S., Page, L. The Anatomy of a Large-ScaleHypertextual Web Search Engine, in Proceedings ofthe 7th International WWW Conference, April 1998,Brisbane, Australia.
[2] Hearst, M.A.
Automated Discovery of WordNetRelations, in WordNet: an electronic lexical database,C.
Fellbaum (ed.
), MIT Press, 131-151, 1998.
[3] Joho, H., Sanderson, M. Retrieving DescriptivePhrases from Large Amounts of Free Text, inProceedings of the 9th ACM CIKM Conference,November 2000, McLean, VA, 180-186.
[4] Radev, D.R., McKeown, K.R.
Building a GenerationKnowledge Source using Internet-AccessibleNewswire, in Proceedings of the 5th ANLPConference, March 1997, Washington, D.C., 221-228.
[5] Srihari, R & Li, W. A Question Answering SystemSupported by Information Extraction, in Proceedingsof the 8th ANLP Conference, April-May 2000, Seattle,Washington.
