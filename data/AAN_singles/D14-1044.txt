Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 397?406,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsIncorporating Vector Space Similarity in Random Walk Inference overKnowledge BasesMatt GardnerCarnegie Mellon Universitymg1@cs.cmu.eduPartha Talukdar?Indian Institute of Scienceppt@serc.iisc.inJayant KrishnamurthyCarnegie Mellon Universityjayantk@cs.cmu.eduTom MitchellCarnegie Mellon Universitytom@cs.cmu.eduAbstractMuch work in recent years has gone intothe construction of large knowledge bases(KBs), such as Freebase, DBPedia, NELL,and YAGO.
While these KBs are verylarge, they are still very incomplete, ne-cessitating the use of inference to fill ingaps.
Prior work has shown how to makeuse of a large text corpus to augment ran-dom walk inference over KBs.
We presenttwo improvements to the use of such largecorpora to augment KB inference.
First,we present a new technique for combin-ing KB relations and surface text into asingle graph representation that is muchmore compact than graphs used in priorwork.
Second, we describe how to incor-porate vector space similarity into randomwalk inference over KBs, reducing the fea-ture sparsity inherent in using surface text.This allows us to combine distributionalsimilarity with symbolic logical inferencein novel and effective ways.
With exper-iments on many relations from two sepa-rate KBs, we show that our methods sig-nificantly outperform prior work on KBinference, both in the size of problem ourmethods can handle and in the quality ofpredictions made.1 IntroductionMuch work in recent years has gone into theconstruction of large knowledge bases, eitherby collecting contributions from many users,as with Freebase (Bollacker et al., 2008) and?Research carried out while at the Machine LearningDepartment, Carnegie Mellon University.DBPedia (Mendes et al., 2012), or automat-ically from web text or other resources, asdone by NELL (Carlson et al., 2010) andYAGO (Suchanek et al., 2007).
These knowl-edge bases contain millions of real-world enti-ties and relationships between them.
However,even though they are very large, they are stillvery incomplete, missing large fractions of possi-ble relationships between common entities (Westet al., 2014).
Thus the task of inference overthese knowledge bases, predicting new relation-ships simply by examining the knowledge base it-self, has become increasingly important.A promising technique for inferring new re-lation instances in a knowledge base is randomwalk inference, first proposed by Lao and Cohen(2010).
In this method, called the Path RankingAlgorithm (PRA), the knowledge base is encodedas a graph, and random walks are used to findpaths that connect the source and target nodes ofrelation instances.
These paths are used as featuresin a logistic regression classifier that predicts newinstances of the given relation.
Each path can beviewed as a horn clause using knowledge base re-lations as predicates, and so PRA can be thoughtof as a kind of discriminatively trained logical in-ference.One major deficiency of random walk inferenceis the connectivity of the knowledge base graph?if there is no path connecting two nodes in thegraph, PRA cannot predict any relation instancebetween them.
Thus prior work has introduced theuse of a text corpus to increase the connectivity ofthe graph used as input to PRA (Lao et al., 2012;Gardner et al., 2013).
This approach is not withoutits own problems, however.
Whereas knowledgebase relations are semantically coherent and dif-ferent relations have distinct meanings, this is not397true of surface text.
For example, ?The Nile flowsthrough Cairo?
and ?The Nile runs through Cairo?have very similar if not identical meaning.
Addinga text corpus to the inference graph increases con-nectivity, but it also dramatically increases featuresparsity.We introduce two new techniques for makingbetter use of a text corpus for knowledge base in-ference.
First, we describe a new way of incor-porating the text corpus into the knowledge basegraph that enables much more efficient process-ing than prior techniques, allowing us to approachproblems that prior work could not feasibly solve.Second, we introduce the use of vector space sim-ilarity in random walk inference in order to reducethe sparsity of surface forms.
That is, when fol-lowing a sequence of edge types in a random walkon a graph, we allow the walk to follow edges thatare semantically similar to the given edge types,as defined by some vector space embedding of theedge types.
If a path calls for an edge of type?flows through?, for example, we accept otheredge types (such as ?runs through?)
with probabil-ity proportional to the vector space similarity be-tween the two edge types.
This lets us combinenotions of distributional similarity with symboliclogical inference, with the result of decreasing thesparsity of the feature space considered by PRA.We show with experiments using both the NELLand Freebase knowledge bases that this methodgives significantly better performance than priorapproaches to incorporating text data into randomwalk inference.2 Graph ConstructionOur method for knowledge base inference, de-scribed in Section 3, performs random walks overa graph to obtain features for a logistic regressionclassifier.
Prior to detailing that technique, we firstdescribe how we produce a graph G = (N , E ,R)from a set of knowledge base (KB) relation in-stances and a set of surface relation instances ex-tracted from a corpus.
Producing a graph froma knowledge base is straightforward: the set ofnodes N is made up of the entities in the KB; theset of edge types R is the set of relation types inthe KB, and the typed edges E correspond to re-lation instances from the KB, with one edge oftype r connecting entity nodes for each (n1, r, n2)triple in the KB.
Less straightforward is how toconstruct a graph from a corpus, and how to con-nect that graph to the KB graph.
We describe ourmethods for each of those below.To create a graph from a corpus, we first prepro-cess the corpus to obtain a collection of surfacerelations, such as those extracted by open infor-mation extraction systems like OLLIE (Mausam etal., 2012).
These surface relations consist of a pairof noun phrases in the corpus, and the verb-likeconnection between them (either an actual verb,as done by Talukdar et al.
(2012), a dependencypath, as done by Riedel et al.
(2013), or OpenIErelations (Mausam et al., 2012)).
The verb-likeconnections are naturally represented as edges inthe graph, as they have a similar semantics to theknowledge base relations that are already repre-sented as edges.
We thus create a graph from thesetriples exactly as we do from a KB, with nodes cor-responding to noun phrase types and edges corre-sponding to surface relation triples.So far these two subgraphs we have createdare entirely disconnected, with the KB graph con-taining nodes representing entities, and the sur-face relation graph containing nodes representingnoun phrases, with no edges between these nounphrases and entities.
We connect these two graphsby making use of the ALIAS relation in the KB,which links entities to potential noun phrase ref-erents.
Each noun phrase in the surface relationgraph is connected to those entity nodes which thenoun phrase can possibly refer to according to theKB.
These edges are not the output of an entitylinking system, as done by Lao et al.
(2012), butexpress instead the notion that the noun phrase canrefer to the KB entity.
The use of an entity linkingsystem would certainly allow a stronger connec-tion between noun phrase nodes and entity nodes,but it would require much more preprocessing anda much larger graph representation, as each men-tion of each noun phrase would need its own node,as opposed to letting every mention of the samenoun phrase share the same node.
This graph rep-resentation allows us to add tens of millions of sur-face relations to a graph of tens of millions of KBrelations, and perform all of the processing on asingle machine.As will be discussed in more detail in Section 4,we also allow edge types to optionally have an as-sociated vector that ideally captures something ofthe semantics of the edge type.Figure 1 shows the graph constructions used inour experiments on a subset of KB and surface re-398KB Relations:(Monongahela, RIVERFLOWSTHROUGHCITY, Pittsburgh)(Pittsburgh, ALIAS, ?Pittsburgh?
)(Pittsburgh, ALIAS, ?Steel City?
)(Monongahela, ALIAS, ?Monongahela River?
)(Monongahela, ALIAS, ?The Mon?
)Surface Relations:(?The Mon?, ?flows through?, ?Steel City?
)(?Monongahela River?, ?runs through?, ?Pittsburgh?
)Embeddings:?flows through?
: [.2, -.1, .9]?runs through?
: [.1, -.3, .8](a) An example data set.
(c) An example graph that replaces surface relations with acluster label, as done by Gardner et al.
(2013).
Note, how-ever, that the graph structure differs from that prior work;see Section 5.
(b) An example graph that combines a KB and surface rela-tions.
(d) An example graph that uses vector space representationsof surface edges, as introduced in this paper.Figure 1: Example graph construction as used in the experiments in this paper.
A graph using only KBedges is simply a subset of these graphs containing only the RIVERFLOWSTHROUGHCITY edge, and isnot shown.lations.
Note that Figures 1b and 1c are shown asrough analogues of graphs used in prior work (de-scribed in more detail in Section 5), and we usethem for comparison in our experiments.3 The Path Ranking AlgorithmWe perform knowledge base inference using thePath Ranking Algorithm (PRA) (Lao and Cohen,2010).
We begin this section with a brief overviewof PRA, then we present our modification to thePRA algorithm that allows us to incorporate vectorspace similarity into random walk inference.PRA can be thought of as a method for exploit-ing local graph structure to generate non-linearfeature combinations for a prediction model.
PRAgenerates a feature matrix over pairs of nodes ina graph, then uses logistic regression to classifythose node pairs as belonging to a particular rela-tion.More formally, given a graph G with nodes N ,edges E , and edge labelsR, and a set of node pairs(si, ti) ?
D, one can create a connectivity matrixwhere rows correspond to node pairs and columnscorrespond to edge lables.
PRA augments thismatrix with additional columns corresponding tosequences of edge labels, called path types, andchanges the cell values from representing the pres-ence of an edge to representing the specificity ofthe connection that the path type makes betweenthe node pair.Because the feature space considered by PRAis so large (the set of all possible edge label se-quences, with cardinality?li=1|R|i, assuming abound l on the maximum path length), the firststep PRA must perform is feature selection, whichis done using random walks over the graph.
Thesecond step of PRA is feature computation, whereeach cell in the feature matrix is computed usinga constrained random walk that follows the pathtype corresponding to the feature.
We now explaineach of these steps in more detail.Feature selection finds path types pi that arelikely to be useful in predicting new instances ofthe relation represented by the input node pairs .These path types are found by performing randomwalks on the graph G starting at the source andtarget nodes in D, recording which paths connectsome source node with its target.
The edge se-quences are ranked by frequency of connecting asource node to a corresponding target node, andthe top k are kept.Feature computation.
Once a set of path types399is selected as features, the next step of the PRAalgorithm is to compute a value for each cell in thefeature matrix, corresponding to a node pair and apath type.
The value computed is the probabilityof arriving at the target node of a node pair, giventhat a random walk began at the source node andwas constrained to follow the path type: p(t|s, pi).Once these steps have been completed, the re-sulting feature matrix can be used with whatevermodel or learning algorithm is desired; in this andprior work, simple logistic regression has beenused as the prediction algorithm.4 Vector space random walksOur modifications to PRA are confined entirely tothe feature computation step described above; fea-ture selection (finding potentially useful sequencesof edge types) proceeds as normal, using the sym-bolic edge types.
When computing feature val-ues, however, we allow a walk to follow an edgethat is semantically similar to the edge type in thepath, as defined by Euclidean distance in the vec-tor space.More formally, consider a path type pi.
Re-call that pi is a sequence of edge types <e1, e2, .
.
.
, el>, where l is the length of the path;we will use piito denote the ithedge type in thesequence.
To compute feature values, PRA beginsat some node and follows edges of type piiuntilthe sequence is finished and a target node has beenreached.
Specifically, if a random walk is at a noden with m outgoing edge types {e1, e2, .
.
.
, em},PRA selects the edge type from that set whichmatches pii, then selects uniformally at randomfrom all outgoing edges of that type.
If there isno match in the set, the random walk restarts fromthe original start node.We modify the selection of which edge type tofollow.
When a random walk is at a node n withm outgoing edge types {e1, e2, .
.
.
, em}, insteadof selecting only the edge type that matches pii,we allow the walk to select instead an edge thatis close to piiin vector space.
For each edge typeat node n, we select the edge with the followingprobability:p(ej|pii) ?
exp(?
?v(ej) ?v(pii)), ?j, 1 ?
j ?
mwhere v(?)
is a function that returns the vectorrepresentation of an edge type, and ?
is a spiki-ness parameter that determines how much weightto give to the vector space similarity.
As ?
ap-proaches infinity, the normalized exponential ap-proximates a delta function on the closest edgetype to pii, in {e1, e2, .
.
.
, em}.
If piiis in the setof outgoing edges, this algorithm converges to theoriginal PRA.However, if piiis not in the set of outgoing edgetypes at a node and all of the edge types are verydissimilar to pii, this algorithm (with ?
not close toinfinity) will lead to a largely uniform distributionover edge types at that node, and no way for therandom walk to restart.
To recover the restart be-havior of the original PRA, we introduce an addi-tional restart parameter?, and add another value tothe categorical distribution before normalization:p(restart|pii) ?
exp(?
?
?
)When this restart type is selected, the randomwalk begins again, following pi1starting at thesource node.
With ?
set to a value greater than themaximum similarity between (non-identical) edgetype vectors, and ?
set to infinity, this algorithmexactly replicates the original PRA.Not all edge types have vector space representa-tions: the ALIAS relation cannot have a meaning-ful vector representation, and we do not use vec-tors to represent KB relations, finding that doingso was not useful in practice (which makes intu-itive sense: KB relations are already latent repre-sentations themselves).
While performing randomwalks, if piihas no vector representation, we fallback to the original PRA algorithm for selectingthe next edge.We note here that when working with vectorspaces it is natural to try clustering the vectors toreduce the parameter space.
Each path type pi isa feature in our model, and if two path types dif-fer only in one edge type, and the differing edgetypes have very similar vectors, the resultant fea-ture values will be essentially identical for bothpath types.
It seems reasonable that running asimple clustering algorithm over these path types,to reduce the number of near-duplicate features,would improve performance.
We did not find thisto be the case, however; all attempts we made touse clustering over these vectors gave performanceindistinguishable from not using clustering.
Fromthis we conclude that the main issue hindering per-formance when using PRA over these kinds ofgraphs is one of limited connectivity, not one oftoo many parameters in the model.
Though the400feature space considered by PRA is very large, thenumber of attested features in a real graph is muchsmaller, and it is this sparsity which our vectorspace methods address.5 Related WorkKnowledge base inference.
Random walk infer-ence over knowledge bases was first introduced byLao and Cohen (2010).
This work was improvedupon shortly afterward to also make use of a largecorpus, by representing the corpus as a graph andconnecting it to the knowledge base (Lao et al.,2012).
Gardner et al.
(2013) further showed thatreplacing surface relation labels with a represen-tation of a latent embedding of the relation ledto improved prediction performance.
This resultis intuitive: the feature space considered by PRAis exponentially large, and surface relations aresparse.
The relations ?
[river] flows through [city]?and ?
[river] runs through [city]?
have near iden-tical meaning, and both should be very predic-tive for the knowledge base relation RIVERFLOW-STHROUGHCITY.
However, if one of these rela-tions only appears in the training data and the otheronly appears in the test data, neither will be usefulfor prediction.
Gardner et al.
(2013) attempted tosolve this issue by finding a latent symbolic repre-sentation of the surface relations (such as a cluster-ing) and replacing the edge labels in the graph withthese latent representations.
This makes it morelikely for surface relations seen in training data toalso be seen at test time, and naturally improvedperformance.This representation, however, is still brittle, asit is still a symbolic representation that is prone tomismatches between training and test data.
If theclustering algorithm used is too coarse, the fea-tures will not be useful, and if it is too fine, therewill be more mismatches.
Also, verbs that are onthe boundaries of several clusters are problematicto represent in this manner.
We solve these prob-lems by modifying the PRA algorithm to directlyuse vector representations of edge types during therandom walk inference.These two prior techniques are the most directlyrelated work to what we present in this paper, andwe compare our work to theirs.Graph construction.
In addition to the incor-poration of vector space similarity into the PRAalgorithm, the major difference between our workand the prior approaches mentioned above is in theconstruction of the graph used by PRA.
We con-trast our method of graph construction with theseprior approaches in more detail below.Lao et al.
(2012) represent every word of ev-ery sentence in the corpus as a node in the graph,with edges between the nodes representing depen-dency relationships between the words.
They thenconnect this graph to the KB graph using a simpleentity linking system (combined with coreferenceresolution).
The resultant graph is enormous, suchthat they needed to do complex indexing on thegraph and use a cluster of 500 machines to per-form the PRA computations.
Also, as the edgesrepresent dependency labels, not words, with thisgraph representation the PRA algorithm does nothave access to the verbs or other predicative wordsthat appear in the corpus, which frequently expressrelations.
PRA only uses edge types as featurecomponents, not node types, and so the rich infor-mation contained in the words is lost.
This graphconstruction also would not allow the incorpora-tion of vector space similarity that we introduced,as dependency labels do not lend themselves wellto vector space representations.Gardner et al.
(2013) take an approach very sim-ilar to the one presented in Section 2, preprocess-ing the corpus to obtain surface relations.
How-ever, instead of creating a graph with nodes rep-resenting noun phrases, they added edges fromthe surface relations directly to the entity nodesin the graph.
Using the ALIAS relation, as we do,they added an edge between every possible con-cept pair that could be represented by the nounphrases in a surface relation instance.
This leadsto some nonsensical edges added to the graph,and if the ALIAS relation has high degree (as itdoes for many common noun phrases in Freebase),it quickly becomes unscalable?this method ofgraph construction runs out of disk space whenattempting to run on the Freebase experiments inSection 6.
Also, in conflating entity nodes in thegraph with noun phrases, they lose an importantdistinction that turns out to be useful for predic-tion, as we discuss in Section 6.4.11Recent notions of ?universal schema?
(Riedel et al.,2013) also put KB entities and noun phrases into the sameconceptual space, though they opt for using noun phrases in-stead of the KB entities used by Gardner et al.
In generalthis is problematic, as it relies on some kind of entity linkingsystem as preprocessing, and cannot handle common nounreferences of proper entities without losing information.
Ourmethod, and that of Lao et al., skirts this issue entirely by nottrying to merge KB entities with noun phrases.401Other related work.
Also related to the presentwork is recent research on programming lan-guages for probabilistic logic (Wang et al., 2013).This work, called ProPPR, uses random walks tolocally ground a query in a small graph before per-forming propositional inference over the groundedrepresentation.
In some sense this technique islike a recursive version of PRA, allowing for morecomplex inferences than a single iteration of PRAcan make.
However, this technique has not yetbeen extended to work with large text corpora, andit does not yet appear to be scalable enough to han-dle the large graphs that we use in this work.
Howbest to incorporate the work presented in this pa-per with ProPPR is an open, and very interesting,question.Examples of other systems aimed at reason-ing over common-sense knowledge are the CYCproject (Lenat, 1995) and ConceptNet (Liu andSingh, 2004).
These common-sense resourcescould easily be incorporated into the graphs weuse for performing random walk inference.Lines of research that seek to incorporate dis-tributional semantics into traditional natural lan-guage processing tasks, such as parsing (Socheret al., 2013a), named entity recognition (Passos etal., 2014), and sentiment analysis (Socher et al.,2013b), are also related to what we present in thispaper.
While our task is quite different from theseprior works, we also aim to combine distributionalsemantics with more traditional methods (in ourcase, symbolic logical inference), and we take in-spiration from these methods.6 ExperimentsWe perform both the feature selection step and thefeature computation step of PRA using GraphChi,an efficient single-machine graph processing li-brary (Kyrola et al., 2012).
We use MAL-LET?s implementation of logistic regression, withboth L1 and L2 regularization (McCallum, 2002).To obtain negative evidence, we used a closedworld assumption, treating any (source, target)pair found during the feature computation step asa negative example if it was not given as a positiveexample.
We tuned the parameters to our methodsusing a coarse, manual grid search with cross vali-dation on the training data described below.
Theparameters we tuned were the L1 and L2 regu-larization parameters, how many random walks toperform in the feature selection and computationNELL FreebaseEntities 1.2M 20MRelation instances 3.4M 67MTotal relation types 520 4215Relation types tested 10 24Avg.
instances/relation 810 200SVO triples used 404k 28MTable 1: Statistics of the data used in our experi-ments.steps of PRA, and spikiness and restart parametersfor vector space walks.
The results presented werenot very sensitive to changes in these parameters.6.1 DataWe ran experiments on both the NELL and Free-base knowledge bases.
The characteristics of theseknowledge bases are shown in Table 1.
The Free-base KB is very large; to make it slightly moremanageable we filtered out relations that did notseem applicable to relation extraction, as well as afew of the largest relations.2This still left a verylarge, mostly intact KB, as can be seen in the ta-ble.
For our text corpus, we make use of a set ofsubject-verb-object triples extracted from depen-dency parses of ClueWeb documents (Talukdar etal., 2012).
There are 670M such triples in thedata set, most of which are completely irrelevant tothe knowledge base relations we are trying to pre-dict.
For each KB, we filter the SVO triples, keep-ing only those which can possibly connect trainingand test instances of the relations we used in ourexperiments.
The number of SVO triples kept foreach KB is also shown in Table 1.
We obtainedvector space representations of these surface rela-tions by running PCA on the SVO matrix.We selected 10 NELL relations and 24 Free-base relations for testing our methods.
The NELLrelations were hand-selected as the relations withthe largest number of known instances that had areasonable precision (the NELL KB is automati-cally created, and some relations have low preci-sion).
We split the known instances of these rela-tions into 75% training and 25% testing, giving onaverage about 650 training instances and 160 test2We removed anything under /user, /common, /type (ex-cept for the relation /type/object/type), /base, and /freebase,as not applicable to our task.
We also removed relations deal-ing with individual music tracks, book editions, and TV epid-sodes, as they are very large, very specific, and unlikely to beuseful for predicting the relations in our test set.402instances for each relation.The 24 Freebase relations were semi-randomlyselected.
We first filtered the 4215 relations basedon two criteria: the number of relation instancesmust be between 1000 and 10000, and there mustbe no mediator in the relation.3Once we selectedthe relations, we kept all instances of each rela-tion that had some possible connection in the SVOdata.4This left on average 200 instances per rela-tion, which we again split 75%-25% into trainingand test sets.6.2 MethodsThe methods we compare correspond to the graphsshown in Figure 1.
The KB method uses the orig-inal PRA algorithm on just the KB relations, aspresented by Lao and Cohen (2010).
KB + SVOadds surface relations to the graph (Figure 1b).
Wepresent this as roughly analogous to the methodsintroduced by Lao et al.
(2012), though with somesignificant differences in graph representation, asdescribed in Section 5.
KB + Clustered SVO fol-lows the methods of Gardner et al.
(2013), but us-ing the graph construction introduced in this pa-per (Figure 1c; their graph construction techniqueswould have made graphs too large to be feasiblefor the Freebase experiments).
KB + Vector SVOis our method (Figure 1d).6.3 EvaluationAs evaluation metrics, we use mean average pre-cision (MAP) and mean reciprocal rank (MRR),following recent work evaluating relation extrac-tion performance (West et al., 2014).
We test sig-nificance using a paired permutation test.The results of these experiments are shown inTable 2 and Table 3.
In Table 4 we show averageprecision for every relation tested on the NELLKB, and we show the same for Freebase in Table 5.6.4 DiscussionWe can see from the tables that KB + Vector SVO(the method presented in this paper) significantlyoutperforms prior approaches in both MAP and3A mediator in Freebase is a reified relation in-stance meant to handle n-ary relations, for instance/film/performance.
PRA in general, and our implementationof it in particular, needs some modification to be well-suitedto predicting relations with mediators.4We first tried randomly selecting instances from these re-lations, but found that the probability of selecting an instancethat benefited from an SVO connection was negligible.
In or-der to make use of the methods we present, we thus restrictedourselves to only those that had a possible SVO connection.Method MAP MRRKB 0.193 0.635KB + SVO 0.218 0.763KB + Clustered SVO 0.276 0.900KB + Vector SVO 0.301 0.900Table 2: Results on the NELL knowledge base.The bolded line is significantly better than all otherresults with p < 0.025.Method MAP MRRKB 0.278 0.614KB + SVO 0.294 0.639KB + Clustered SVO 0.326 0.651KB + Vector SVO 0.350 0.670Table 3: Results on the Freebase knowledge base.The bolded line is significantly better than all otherresults with p < 0.0002.MRR.
We believe that this is due to the reductionin feature sparsity enabled by using vector spaceinstead of symbolic representations (as that is theonly real difference between KB + Clustered SVOand KB + Vector SVO), allowing PRA to makebetter use of path types found in the training data.When looking at the results for individual relationsin Table 4 and Table 5, we see that KB + VectorSVO outperforms other methods on the majorityof relations, and it is a close second when it doesnot.We can also see from the results that mean av-erage precision seems a little low for all meth-ods tested.
This is because MAP is computed asthe precision of all possible correct predictions ina ranked list, where precision is counted as 0 ifthe correct prediction is not included in the list.In other words, there are many relation instancesin our randomly selected test set that are not in-ferrable from the knowledge base, and the low re-call hurts the MAP metric.
MRR, which judges theprecision of the top prediction for each relation,gives us some confidence that the main issue hereis one of recall, as MRR is reasonably high, es-pecially on the NELL KB.
As further evidence, ifwe compute average precision for each query node(instead of for each relation), excluding queries forwhich the system did not return any predictions,MAP ranges from .29 (KB) to .45 (KB + VectorSVO) on NELL (with around 30% of queries hav-ing no prediction), and from .40 (KB) to .49 (KB +403Relation KB KB + SVO KB + Clustered SVO KB + Vector SVOActorStarredInMovie 0.000 0.032 0.032 0.037AthletePlaysForTeam 0.200 0.239 0.531 0.589CityLocatedInCountry 0.126 0.169 0.255 0.347JournalistWritesForPublication 0.218 0.254 0.291 0.319RiverFlowsThroughCity 0.000 0.001 0.052 0.076SportsTeamPositionForSport 0.217 0.217 0.178 0.180StadiumLocatedInCity 0.090 0.156 0.275 0.321StateHasLake 0.000 0.000 0.000 0.000TeamPlaysInLeague 0.934 0.936 0.947 0.939WriterWroteBook 0.144 0.179 0.195 0.202Table 4: Average precision for each relation tested on the NELL KB.
The best performing method oneach relation is bolded.Relation KB KB + SVO KB + C-SVO KB + V-SVO/amusement parks/park/rides 0.000 0.009 0.004 0.013/architecture/architect/structures designed 0.072 0.199 0.257 0.376/astronomy/constellation/contains 0.004 0.017 0.000 0.008/automotive/automotive class/examples 0.003 0.001 0.002 0.006/automotive/model/automotive class 0.737 0.727 0.742 0.768/aviation/airline/hubs 0.322 0.286 0.298 0.336/book/literary series/author s 0.798 0.812 0.818 0.830/computer/software genre/software in genre 0.000 0.001 0.001 0.001/education/field of study/journals in this discipline 0.001 0.003 0.003 0.001/film/film/rating 0.914 0.905 0.914 0.905/geography/island/body of water 0.569 0.556 0.580 0.602/geography/lake/basin countries 0.420 0.361 0.409 0.437/geography/lake/cities 0.111 0.134 0.177 0.175/geography/river/cities 0.030 0.038 0.045 0.066/ice hockey/hockey player/hockey position 0.307 0.243 0.222 0.364/location/administrative division/country 0.989 0.988 0.991 0.989/medicine/disease/symptoms 0.061 0.078 0.068 0.067/medicine/drug/drug class 0.169 0.164 0.135 0.157/people/ethnicity/languages spoken 0.134 0.226 0.188 0.223/spaceflight/astronaut/missions 0.010 0.186 0.796 0.848/transportation/bridge/body of water spanned 0.534 0.615 0.681 0.727/tv/tv program creator/programs created 0.164 0.179 0.163 0.181/visual art/art period movement/associated artists 0.044 0.040 0.046 0.037/visual art/visual artist/associated periods or movements 0.276 0.295 0.282 0.290Table 5: Average precision for each relation tested on the Freebase KB.
The best performing method oneach relation is bolded.
For space considerations, ?Clustered SVO?
is shortened to ?C-SVO?
and ?VectorSVO?
is shortened to ?V-SVO?
in the table header.404Vector SVO) on Freebase, (where 21% of queriesgave no prediction).
Our methods thus also im-prove MAP when calculated in this manner, but itis not an entirely fair metric,5so we use standardMAP to present our main results.One interesting phenomenon to note isa novel use of the ALIAS relation in someof the relation models.
The best exam-ple of this was found with the relation/people/ethnicity/languages spoken.
Ahigh-weighted feature when adding surfacerelations was the edge sequence <ALIAS, ALIASINVERSE>.
This edge sequence reflects thefact that languages frequently share a namewith the group of people that speaks them (e.g.,Maori, French).
And because PRA can gen-erate compositional features, we also find thefollowing edge sequence for the same relation:</people/ethnicity/included in group,ALIAS, ALIAS INVERSE>.
This feature capturesthe same notion that languages get their namesfrom groups of people, but applies it to subgroupswithin an ethnicity.
These features would bevery difficult, perhaps impossible, to include insystems that do not distinguish between nounphrases and knowledge base entities, such asthe graphs constructed by Gardner et al.
(2013),or typical relation extraction systems, whichgenerally only work with noun phrases afterperforming a heuristic entity linking.7 ConclusionWe have offered two main contributions to the taskof knowledge base inference.
First, we have pre-sented a new technique for combining knowledgebase relations and surface text into a single graphrepresentation that is much more compact thangraphs used in prior work.
This allowed us to ap-ply methods introduced previously to much largerproblems, running inference on a single machineover the entire Freebase KB combined with tens ofmillions of surface relations.
Second, we have de-scribed how to incorporate vector space similarityinto random walk inference over knowledge bases,reducing the feature sparsity inherent in using sur-face text.
This allows us to combine distributionalsimilarity with symbolic logical inference in noveland effective ways.
With experiments on many5MAP is intended to include some sense of recall, but ex-cluding queries with no predictions removes that and opensthe metric to opportunistic behavior.relations from two separate knowledge bases, wehave shown that our methods significantly outper-form prior work on knowledge base inference.The code and data used in the ex-periments in this paper are available athttp://rtw.ml.cmu.edu/emnlp2014 vector space pra/.AcknowledgmentsThis research has been supported in part byDARPA under contract number FA8750-13-2-0005, by NSF under grant 31043,18,1121946, andby generous support from Yahoo!
and Google.ReferencesKurt Bollacker, Colin Evans, Praveen Paritosh, TimSturge, and Jamie Taylor.
2008.
Freebase: a col-laboratively created graph database for structuringhuman knowledge.
In Proceedings of SIGMOD.Andrew Carlson, Justin Betteridge, Bryan Kisiel,Burr Settles, Estevam R Hruschka Jr, and Tom MMitchell.
2010.
Toward an architecture for never-ending language learning.
In AAAI.Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel,and Tom Mitchell.
2013.
Improving learning andinference in a large knowledge-base using latentsyntactic cues.
In Proceedings of EMNLP.
Associa-tion for Computational Linguistics.Aapo Kyrola, Guy Blelloch, and Carlos Guestrin.2012.
Graphchi: Large-scale graph computationon just a pc.
In Proceedings of the 10th USENIXSymposium on Operating Systems Design and Im-plementation (OSDI), pages 31?46.Ni Lao and William W Cohen.
2010.
Relational re-trieval using a combination of path-constrained ran-dom walks.
Machine learning, 81(1):53?67.Ni Lao, Amarnag Subramanya, Fernando Pereira, andWilliam W Cohen.
2012.
Reading the web withlearned syntactic-semantic inference rules.
In Pro-ceedings of EMNLP-CoNLL.Douglas B Lenat.
1995.
Cyc: A large-scale investmentin knowledge infrastructure.
Communications of theACM, 38(11):33?38.Hugo Liu and Push Singh.
2004.
Conceptnet: a practi-cal commonsense reasoning tool-kit.
BT TechnologyJournal, 22(4):211?226.Mausam, Michael Schmitz, Robert Bart, StephenSoderland, and Oren Etzioni.
2012.
Open languagelearning for information extraction.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 523?534.
Asso-ciation for Computational Linguistics.405Andrew Kachites McCallum.
2002.
Mallet: A ma-chine learning for language toolkit.Pablo N. Mendes, Max Jakob, and Christian Bizer.2012.
Dbpedia for nlp: A multilingual cross-domainknowledge base.
In Proceedings of the Eighth In-ternational Conference on Language Resources andEvaluation (LREC?12).Alexandre Passos, Vineet Kumar, and Andrew Mc-Callum.
2014.
Lexicon infused phrase embed-dings for named entity resolution.
arXiv preprintarXiv:1404.5367.Sebastian Riedel, Limin Yao, Andrew McCallum, andBenjamin M Marlin.
2013.
Relation extraction withmatrix factorization and universal schemas.
In Pro-ceedings of NAACL-HLT.Richard Socher, John Bauer, Christopher D Manning,and Andrew Y Ng.
2013a.
Parsing with compo-sitional vector grammars.
In In Proceedings of theACL conference.
Citeseer.Richard Socher, Alex Perelygin, Jean Y Wu, JasonChuang, Christopher D Manning, Andrew Y Ng,and Christopher Potts.
2013b.
Recursive deep mod-els for semantic compositionality over a sentimenttreebank.
In Proceedings of EMNLP.Fabian M Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowl-edge.
In Proceedings of WWW.Partha Pratim Talukdar, Derry Wijaya, and TomMitchell.
2012.
Acquiring temporal constraints be-tween relations.
In Proceedings of the 21st ACMinternational conference on Information and knowl-edge management, pages 992?1001.
ACM.William Yang Wang, Kathryn Mazaitis, andWilliam W. Cohen.
2013.
Programming withpersonalized pagerank: A locally groundablefirst-order probabilistic logic.
In Proceedings of the22Nd ACM International Conference on Conferenceon Information &#38; Knowledge Management,CIKM ?13, pages 2129?2138, New York, NY, USA.ACM.Robert West, Evgeniy Gabrilovich, Kevin Murphy,Shaohua Sun, Rahul Gupta, and Dekang Lin.
2014.Knowledge base completion via search-based ques-tion answering.
In WWW.406
