Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2087?2096, Dublin, Ireland, August 23-29 2014.Exploratory Relation Extraction in Large Text CorporaAlan Akbik Thilo MichaelDatabase Systems and Information Management GroupEinsteinufer 17, 10587 Berlin, Germany{firstname.lastname}@tu-berlin.deChristoph BodenAbstractIn this paper, we propose and demonstrate Exploratory Relation Extraction (ERE), a novelapproach to identifying and extracting relations from large text corpora based on user-drivenand data-guided incremental exploration.
We draw upon ideas from the information seekingparadigm of Exploratory Search (ES) to enable an exploration process in which users begin witha vaguely defined information need and progressively sharpen their definition of extraction tasksas they identify relations of interest in the underlying data.
This process extends the applicationof Relation Extraction to use cases characterized by imprecise information needs and uncertaintyregarding the information content of available data.We present an interactive workflow that allows users to build extractors based on entity typesand human-readable extraction patterns derived from subtrees in dependency trees.
In order toevaluate the viability of our approach on large text corpora, we conduct experiments on a datasetof over 160 million sentences with mentions of over 6 million FREEBASE entities extracted fromthe CLUEWEB09 corpus.
Our experiments indicate that even non-expert users can intuitivelyuse our approach to identify relations and create high precision extractors with minimal effort.1 Introduction1.1 Motivation and Problem StatementRelation Extraction (RE) is the task of creating extractors that automatically find instances of semanticrelations in unstructured data such as natural language text (Riloff, 1996).
An example extraction taskmight be to find instances of the EDUCATEDAT relation, which relates persons to their educational in-stitution and may include the entity pair <Sigmund Freud, University of Vienna> as relation instance.Motivated by an explosion of readily available sources of text data such as the Web, RE offers intriguingpossibilities for querying and analyzing data as well as extracting and organizing the contained informa-tion (Sarawagi, 2008).
As scalable computing architectures capable of processing ever larger amountsof data are being developed (Dean and Ghemawat, 2004) and dependency parsers are becoming moreaccurate and more robust (Petrov and McDonald, 2012), so rises the potential of developing means todirectly access the structured information contained in natural language text.In spite of such positive trends however, currently established methods of creating relation extractorssuffer from a number of limitations.
The first is one of cost; the process of creating extractors requireseither labeled data to be produced at sufficient quality and quantity in order to train a supervised machinelearning algorithm (Culotta and Sorensen, 2004; Mintz et al., 2009), or the manual creation of a complexset of extraction rules (Str?otgen and Gertz, 2010; Reiss et al., 2008).
In either case, the process is tediousand time-consuming and requires trained specialists with an extensive background in NLP, rule-writingor machine learning (Chiticariu et al., 2013).
Worse, this process needs to be repeated for every relationand domain of interest.
Due to this cost, great care must be taken when deciding which relation types tolook for in a given text corpus.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/2087This leads to the second limitation, namely the necessary a priori specification of relations.
Currentmethods generally require a careful upfront definition of the RE tasks in order to start producing labeledtraining data or extraction rule-sets.
Practical scenarios, however, are often characterized by impreciseand rapidly changing information needs and uncertainty regarding the type of information contained inlarge, given text corpora (Chiticariu et al., 2013).
This severely limits the practicability of currentlyestablished RE methods.1.2 Exploratory Search for RelationsTo address these limitations, we propose a process of exploration for relations of interest in available data.We propose to substantially reduce entry barriers into RE so that extraction tasks no longer need to beexactly pre-specified and expensively prepared by generating labeled training data in advance.
Instead,we propose a manual, rule-based approach in which extraction rules are kept very simple so that userscan formulate natural language-like patterns as exploratory queries for relations against a text corpus.We draw inspiration from the information seeking paradigm of Exploratory Search (ES) (Marchionini,2006; White and Roth, 2009), where users start with a vaguely defined information need and - with a mixof look-up, browsing, analysis and exploration - progressively discover information available to addressit and simultaneously concretize their information need.
One of the challenges associated with the oftendesired capability of ES is the design of interactive interfaces to support users as they navigate throughcomplex environments.
Similarly, our challenge is to create an intuitive workflow that allows non-expertsin NLP to engage in relation exploration.We propose to simplify the search for information by using natural language-like queries that matchsubtrees in large corpora of dependency parsed data while hiding the complexity from the users.
Explo-rative queries return matching relation instances and source sentences, as well as suggestions for furtherqueries computed from the available data.
By following a process of experimental querying and accept-ing or rejecting pattern suggestions, users identify relations of interest and group patterns into extractors.Our goal is to make use of such data-guidance to facilitate exploration while giving as much explicitcontrol to a user as possible.1.3 ContributionsIn this paper, we propose and demonstrate Exploratory Relation Extraction (ERE), a user-driven anddata-guided incremental exploration approach to Relation Extraction.
We give details on our relationextraction pattern language and introduce a guided, interactive workflow aimed at allowing users toexplore parsed text corpora for relations at minimal effort.
We conduct two experiments on a largecorpus of over 160 million sentences from the CLUEWEB09 to determine in how far non-experts can useERE to discover and extract relations.
We discuss the results of the user study, as well as strengths andweaknesses of our proposed approach.2 Exploratory Relation ExtractionIn this section, we present our approach for Exploratory Relation Extraction.
We provide details on howwe define extraction patterns and how we preemptively extract all subtrees in dependency trees froma given text corpus (Section 2.1).
We then outline a data-guided incremental workflow to explore theindexed data for relations (Section 2.2) and illustrate this with an exemplary execution (Section 2.3).2.1 Human-Readable Relation Extraction PatternsLike much previous work in RE (Culotta and Sorensen, 2004; Schutz and Buitelaar, 2005; Uszkoreit,2011), we define extraction patterns using features from dependency-parsed sentences.
As recent workhas shown (Del Corro and Gemulla, 2013; Akbik et al., 2013b), patterns in dependency trees are well-suited to manual rule based RE, as they enable more succinct and thus more human-readable rule sets.Following this work, we define RE patterns as subtrees in dependency trees.In our work, we follow the idea of Preemptive Information Extraction (Shinyama and Sekine, 2006)in which all possible relations for a given text corpus are preemptively generated in advance.
Applied2088A.
Dependency Parse SentenceB.
Extract Subtrees for Entity Pair C. Link Entities to Freebase + Retrieve Entity TypesEntity Text FreebaseID Type Freud m/06myp Person University of Vienna m/0dy04 Educational Institutionentered entered studyAt young age , Freud entered the University of Vienna to study medicineX X Y YAt young age entered X YD.
Index Subtrees, Entity Pairs,       Types and SentencesX-Entity Y-Entity Pattern X-Type Y-Type Sentence Freud University of Vienna X enter Y Person Educational_Institution At young age, Freud entered the ?
Freud University of Vienna X enter Y study Person Educational_Institution At young age, Freud entered the ?
Freud University of Vienna at young age X enter Y Person Educational_Institution At young age, Freud entered the ?
Freud University of Vienna X enter Y study medicine Person Educational_Institution At young age, Freud entered the ?
?
?
?
?
?
?Figure 1: Illustration of the subtree generation process.
We parse each sentence in a given documentcollection using a dependency parser and annotate all entities (A).
Then, we generate all possible subtreesin the dependency tree that span pairs of annotated entities, three of which are illustrated in (B), and linkentities to their FREEBASE IDs to determine their entity types (C).
We then generate a lexical, lemmatizedrepresentation of these subtrees which we store along with the entity pair, their entity types and sentencethey are observed with (D).to our problem this means that we generate all possible dependency subtrees, arguing that dependingon the user?s information need, any such pattern may be valuable.
Since we are interested in binaryrelations only, we generate only those subtrees that span two named entities in a sentence.
In addition,we also determine the fine-grained entity types for named entities in order to allow users to optionallyrestrict patterns to match only entities of certain types.
Previous work has shown the benefit of includingfine-grained type restrictions into patterns (Akbik et al., 2013a).We illustrate this process with an example sentence in Figure 1, for which we determine all subtreesthat span the indicated entity pair.
In the subtrees, we replace the entity tokens with the placeholders ?X?and ?Y?, where the former is the placeholder for the X-entity and the latter the placeholder for the Y-entity.
For better human-readability, we lexicalize the patterns by lemmatizing the words and discardinginformation on typed dependencies.
We also link the entities in the sentence to entries in the FREEBASEknowledge base (Bollacker et al., 2008), allowing us to retrieve their fine grained entity types.We then index the information on lexicalized patterns, the entities they span and their types, as well asthe sentences in which the patterns were found (Figure 1D).
This allows users to query for any combi-nations of patterns and entity type restrictions and retrieve matching entity pairs and sentences from theindex.
For instance, a user may query for all entity pairs that match the ?at young age X enter Y?
pattern,and optionally restrict the Y-entity to be only of type ORGANIZATION, or more specific types such asCHURCH or UNIVERSITY.
We argue that because patterns are lexicalized variants of dependency sub-trees and entity type restrictions can have human readable names, such queries are intuitive to users evenwithout an NLP background.
The use and preemptive indexing of human-readable patterns decreases theentry barriers into the ERE process, as this enables users to exploratively query parsed text corpora.2089X_Entity  Y_Entity  SentenceBill Gates  Harvard  While it has been around since the time Bill Gates dropped out of Harvard , it has just recently become big news.Johnny Knoxville  American Academy of Dramatic ArtJohnny Knoxville attended the American Academy of Dramatic Arts  in California but dropped out after just two weeks.Leo Tolstoy  Kazan University Leo Tolstoy also briefly attended Kazan University, although he never took a degree there.?
?
?Selected Patterns + TypesX_Type  PersonY_Type  Educational_InstitutionPattern X drop out of Y  OR   X attend Y but drop out OR  X briefly  attend YPattern SuggestionsX student at YX left Y Extractor CompleteacceptPattern SuggestionsX is professor at YX graduate from YX drop out of Yacceptl aunchA .
Launch Initial Query  B .
Accept or Reject  Suggested  PatternsC.
Mark Extractor Complete  D .
Run Extractor on CorpusInitial QueryX_Type  PersonY_Type  Educational InstitutionPatternSelected Patterns + TypesX_Type  PersonY_Type  Educational InstitutionPattern X drop out of YUpdated Pattern SuggestionsX attend Y but drop outX left YX briefly  attend YIndex  IndexIndexFigure 2: Illustration of the exploratory relation extraction process.
The user begins with specifyingentity types of interest and receives a set of pattern suggestions (A).
Intrigued by the pattern ?X drop outfrom Y?, the user affirms this pattern.
This prompts updated pattern suggestions which the user affirmsor rejects (B).
When no more interesting patters are offered, the user marks the extractor as complete (C)and runs it on a corpus, retrieving relation instances and matching sentences (D).2.2 Guidance From Available DataA second key component is to provide guidance in the exploration process by computing suggestions forpatterns from user input and enabling an interactive workflow that allows users to work with availabledata.
Such guidance is needed for two reasons: First, though much effort is invested in human-readableextraction patterns, users may need support in formulating patterns and choosing entity type restrictions.This is especially the case when users are non-experts in the domain of interest and they strive to identifya range of appropriate patterns.
Second, users may be uncertain of the information content of a given textcorpus.
By providing guidance through automatic pattern suggestions that reflect available information,we help users find patterns for their information need.Users formulate an entry point to launch the exploration process, either by providing entity types,patterns or both.
We guide the formulation of this initial query through autocomplete options.
If the userenters only types for the entities, the system offers the most common patterns that are observed betweenentities of these types.
The user can also search for patterns that contain a certain keyword.In either case, the system suggests patterns that meet the user-defined entry point.
Patterns are orderedby their absolute count in the corpus so that more common patterns are displayed at the top of the list.
Inaddition, verb-based patterns are favored using a scoring metric that assigns extra points to patterns thatinclude verbs.
To assist a user in understanding a pattern, we optionally display example sentences andentity pairs in which it matches.The user then starts a process of selecting (and de-selecting) entity type restrictions and pattern, thusrefining the extractor while being guided by constantly updated pattern suggestions.
The user continuesthis process until satisfied with the created extractor at which point it can be saved and the discoveredrelation instances downloaded.
The user can now repeat the workflow to create more extractors.20902.3 Exploration Workflow ExampleSuppose we have a user who is given a large text corpus and is asked to link persons to their respec-tive educational institutions, but is unsure of what type of relevant information may be found in thecorpus.
Knowing only that relations should hold between entities of type PERSON and entities of typeEDUCATIONAL INSTITUTION, the user starts an exploration process by providing only these entity typerestrictions.
This is illustrated in Figure 2A).A query is run against the index that identifies common patterns that hold between entities of suchtypes, including ?X be professor at Y?, ?X study at Y?
and ?X drop out from Y?.
Recall that each patternis a human-readable version of a subtree in a dependency tree with two placeholders for entities, namely?X?
and ?Y?.
These placeholders may match named entities of any type, or can be restricted to matchingonly entities of certain types such as persons, organizations or locations.
By clicking on a pattern, the userretrieves entity pairs and sentences in which a pattern matches; For example, the user is informed thatthe pattern ?X study at Y?
finds the relation instance <Bill Gates, Harvard University> in the sentence?Bill Gates briefly studied at Harvard University.
?.Intrigued by the pattern ?X drop out from Y?, the user affirms this pattern and rejects all other sug-gestions.
This causes a new query to be run against the parsed data, this time consisting of the entityrestrictions as well as the pattern.
As the query is now more concrete, the pattern suggestions are updatedto reflect this new information.
The user is presented with similar patterns such as ?Y dropout X?
and ?Xattend Y but drop out?.
This is illustrated in Figure 2B).The user repeats this, selecting or de-selecting patterns (Figure 2B).
At each interaction, suggestionsare updated to reflect the current selection.
When the user is satisfied with the identified relation, theselected set of patterns and restrictions is saved as an extractor (Figure 2C) and executed against theentire text corpus (Figure 2D).
This returns lists of matching relation instances and sentences.
The userhas thus started with an imprecise information need and identified a relation of interest in a given textcorpus, namely a relation for persons that attended an educational institution but did not graduate.3 ExperimentsIn order to examine in how far our approach indeed contributes to overcoming the limitations of REoutlined in Section 1.1, namely the significant cost and the necessary a-priory specification of relations,we conduct a user study with 10 subjects that have little or no NLP background.
We ask the users toapply the workflow for two separate tasks: An extraction task in which users are given four clearlydefined semantic relations and an exploration task in which users are asked to identify relations for morevaguely defined information needs.
We only provide the users with a brief introduction into the workflow.For the extraction task, we measure the time spent per extractor and estimate the quality of the createdextractors in terms of precision and recall.
For the exploration as well as for the extraction task we alsoqualitatively inspect discovered relations and evaluate user feedback.3.1 DatasetsClueWeb09.
As source of text data, we use the English language portion of the well-knownCLUEWEB091reference corpus, consisting of roughly 5 billion crawled Web pages.
We use boiler-plating to remove HTML markup and sentence splitting to determine English language sentences.FACC1.
We use the recently released FACC1 (Gabrilovich et al., 2013) resource, a high quality namedentity linking effort that was executed on the CLUEWEB09 corpus, linking over 6 billion entity mentionsto their corresponding FREEBASE entries.
Using this data, we identify over 160 million sentences inCLUEWEB09 that contain at least two entities we can link to FREEBASE.
We parse all such sentencesusing the ClearNLP toolkit (Choi and McCallum, 2013).Gold Standard Relation Annotations.
As gold standard, we use the FREEBASE relation annotationsas well as annotations from the ?Relation Extraction Corpus?2a large, human-judged dataset of fiverelations about public figures on Wikipedia that was released by Google.
Four of these relations involve1http://lemurproject.org/clueweb09/2http://code.google.com/p/relation-extraction-corpus/2091EDUCATEDAT GRADUATEDWITHDEGREE#INST P R #PAT TIME #INST P R #PAT TIMEUSER 1 58,611 0.99 0.2 51 12 min 17,698 1.0 0.27 34 17 minUSER 2 48,782 0.99 0.31 34 15 min 12,180 1.0 0.27 27 14 minUSER 3 25,435 0.88 0.12 12 8 min 54,371 0.93 0.53 24 8 minUSER 4 33,095 0.99 0.23 25 12 min 7,196 1.0 0.22 9 10 minUSER 5 47,668 0.76 0.16 29 13 min 34,942 1.0 0.48 3 5 minUSER 6 20,356 0.99 0.15 18 14 min 10,290 1.0 0.25 12 14 minUSER 7 22,889 0.62 0.01 8 4 min 37,119 0.71 0.6 19 4 minUSER 8 31,412 0.98 0.19 13 15 min 1,251 0.46 0.04 10 14 minUSER 9 14,169 0.99 0.1 6 8 min 13,104 0.6 0.17 13 12 minUSER 10 29,289 0.99 0.19 17 15 min 35 1.0 0.02 4 20 minAVERAGE 33,171 0.92 0.17 21 11.6 min 18,819 0.87 0.29 16 11.8 minBORNIN DIEDIN#INST P R #PAT TIME #INST P R #PAT TIMEUSER 1 158,222 0.7 0.26 18 9 min 25,779 0.7 0.14 32 9 minUSER 2 72,888 0.79 0.21 23 17 min 13,582 0.86 0.13 12 12 minUSER 3 89,825 0.84 0.22 21 7 min 15,849 0.86 0.13 12 7 minUSER 4 66,899 0.81 0.21 19 14 min 13,542 0.86 0.13 11 8 minUSER 5 65,213 0.82 0.19 19 15 min 21,105 0.85 0.13 10 9 minUSER 6 131,275 0.83 0.25 16 13 min 14,423 0.85 0.13 8 9 minUSER 7 7,851 0.85 0.03 5 4 min 15,980 0.85 0.14 17 4 minUSER 8 52,927 0.82 0.17 10 15 min 25,090 0.74 0.14 8 14 minUSER 9 56,724 0.84 0.18 10 12 min 15,728 0.85 0.14 8 9 minUSER 10 58,347 0.94 0.22 10 15 min 14,112 0.86 0.13 8 10 minAVERAGE 76,017 0.82 0.19 15 12.1 min 33,171 0.82 0.13 13 9.1 minTable 1: Evaluation results for the 4 well-defined relations in the extraction task.
We note differencesfrom user to user, especially with regards to the number of found instances (#INST), the number ofselected patterns (#PAT) and the time spent per relation.
Extractors generally find large amounts ofrelation instances at high precision (P), while recall values (R) are lower.
Users are ordered by the totalnumber of patterns they selected.
User 1 selected the most patterns overall and found the most instancesfor the BORNIN, DIEDIN and EDUCATEDAT relations (highlighted bold).
User 10 both spent the mosttime overall while selecting the fewest patterns.
User 7 spent the least amount of time overall.FREEBASE entities, namely BORNIN, DIEDIN, EDUCATEDAT and GRADUATEDWITHDEGREE.
Weuse these relations in the extraction task.3.2 Extraction TaskWe evaluated the user-created extractors against the gold standard annotations.
However, even withrelatively large sources of annotations, only roughly 5% of entity pairs in our 160 million sentences havea known FREEBASE relation.
We therefore compute precision and recall only for labeled entity pairs,and separately list the absolute number of extracted relation instances.Large amounts of relation instances at high precision.
As Table 1 indicates, many users were able tocreate extractors that find very large amounts of instances (over 100.000 instances in some cases) at highprecision in an average time of 9 to 12 minutes, while recall values tend to be lower.
This tendency tofavor precision at the cost of recall has been observed in previous works on rule-based RE (Wang et al.,2012).
Nevertheless, we analyzed precision and recall in greater detail by manually evaluating a sampleof 200 false positives and 200 false negatives by hand to discover the reasons for precision and recall2092loss.Mismatch between gold standard and results.
As Table 2 shows, false positives are most commonlydue to inconsistencies between extraction results and the gold standard annotations concerning the levelof granularity of a relation instance.
For example, we found BORNIN and DIEDIN relation instancesthat indicated a person?s place of birth or death at lower or higher granularity than FREEBASE records.An example of this is given in Table 2 for Abraham Lincoln?s place of death; we find the more granular<Lincoln, Hildene>, while the gold standard expects <Lincoln, Vermont>.
While different from thegold standard, such instances are not false, which suggests that actual precision may be higher than themeasured values indicate.Missed patterns and entity types.
The most common causes of recall loss are patterns that users failedto select.
In Table 2, we distinguish between ?common?
patterns that were found by at least one user and?long tail?
patterns that were found by none.
While we did not expect a user-driven approach to identifylong tail patterns, we were surprised that some users failed to find more common patterns.
Similarly,the second most common cause of precision loss are entity type restrictions that users failed to correctlyselect, again to our surprise.
We proceeded to interview the users to determine reasons for this.3.3 Exploration TaskWe also asked users to explore the corpus for a vaguely defined information need, namely for relationsthat pertain to ?celebrities?, as well as one arbitrary relation.
Users spent widely varying amounts of time(between 5 and 50 minutes) on this task due to differences in motivation, as some users had interpretedthe search for ?interesting?
relations as a challenge.
For each relation, users provided a short description.Some relations not in Freebase.
While the most common types of relations found for entities of typeCELEBRITY regarded different types of romantic involvements with other celebrities such as marriagesand divorces, some relations were identified that are not found in FREEBASE.
This included a relationthat connects a celebrity to the sports team they support or the car they drive (see Table 3).
This indicatesa potential for using ERE to identify new relations for addition to existing knowledge bases.Closed-class words can be relevant.
Interestingly, one user also worked with patterns that involvedclosed-class word classes, such as ?if?
and ?whether?.
Table 3 shown an example of a relation thatindicates speculative birthplaces using such words.3.4 User Feedback and DiscussionApproach more suited to exploration than extraction.
When interviewing the users, we found thatthey generally favored the exploration over the extraction tasks as here the search could be directed tomore fine-granular and specialized relations.
One of the main problems encountered was the ?haltingproblem?, i.e.
the question of when to stop adding patterns to an extractor.
For some relations, suchas BORNIN, users already found thousands of relation instances after selecting the first pattern, whichcaused two problems; First, they were unsure of the quality of the selected pattern(s), as they wereunable to manually check thousands of relation instances for their validity.
Second, they were unsure ifmore patterns were even needed if the first few already found such amounts of relation instances.
Theseproblems were not encountered in the exploration tasks, as here users could decide the information needfor themselves and select patterns accordingly.Difficulties concerning entity types.
Another main difficulty related to the precise meaning of FREE-BASE entity types; For instance, there are several location types, such as LOCATION.LOCATION, LO-CATION.DATED LOCATION and LOCATION.STATISTICAL REGION, which users found to be confusing,a problem that was compounded by occasional entity linking errors.
Many users expressed the desireto specify custom entity types as restrictions in order to have a similar level of control here as over thechoice of patterns.Low entry barriers but allow additional complexity.
Overall, we found that users were generallyable to start exploring the corpus using our workflow immediately after the brief introduction.
Usersstated the natural language-like representation of patterns to be intuitively readable, although for someit required a trial and error process to understand how patterns matched entities in sentences.
Similarly,some users wished to understand in greater detail how entity types are determined and whether this could2093FALSE POSITIVESCLASS COUNT EXAMPLE SENTENCEFB Mismatch 95 Lincoln died at Hildene , his Vermont home, on July 26, 1926.Type Error 82 [..] the scene where Boromir is killed in The Fellowship of the Ring.FB Incomplete 14 Later that year, on December 27, Dorr died in Providence, in his native Rhode Island.Other 9 Brieven van liederen Rascal Flatts die in het schijfcd album omvatten Feels Like Today.FALSE NEGATIVESCLASS COUNT EXAMPLE SENTENCECommon 87 Klein holds a Bachelor of Arts.Long Tail 79 Roger Blandford is a native of England and took his BA, MA and [..].Other 34 [..], 1974; MS, 1976; PhD, University of Pierre and Marie Curie, 1982.Table 2: Analysis of 200 false positives and 200 false negatives to determine error classes for precisionand recall loss.
Each error class is listed with an example sentence.
Main reasons for false positivesincluded a mismatch in granularity between extraction results and annotations, wrongly specified typesby the users or cases in which instances were found that were not in FREEBASE.
Main reasons for falsenegatives were mostly patterns that users failed so select, either common patterns, or more rare patternsfrom the long tail.NAME DESCRIPTION EXAMPLE PATTERNS EXAMPLE INSTANCESCELEBRITYDIVORCE Divorce between ?X and Y divorce?, <Nicole Kidman, Tom Cruise>two celebrities ?X divorce Y?, <Federline, Spears>CELEBRITYDRIVESCAR Finds the cars that ?X drives Y?, <Arnold Schwarzenegger, H1>celebrities drive ?X ?s car Y?, <Leonardo DiCaprio, Toyota Prius>CONTESTEDBITHPLACE Relates persons to ?if X born in Y?, <Barack Obama, Kenya>their speculative birthplace ?whether X born in Y?, <Barack Obama, Nigeria>Table 3: Examples for relations discovered in the exploration task.
CELEBRITYDIVORCE represents acommonly discovered relation, while CELEBRITYDRIVESCAR represents a relation that is presently notpart of Freebase.
CONTESTEDBITHPLACE is an example of a relation that utilizes closed-world wordsin patterns.be influenced.
This indicates the need for adding options in future work that give more experienced usersmore technical information (and control) on dependency trees and FREEBASE types.4 Previous WorkWhile no directly comparable approach to Exploratory Relation Extraction is known to us, we takeinspiration from a number of previous works.Exploratory Search (Marchionini, 2006; White and Roth, 2009) is an information seeking paradigmin the field of Information Retrieval, where - like in our proposed approach - users begin an explorationprocess with an imprecise information need and progressively discover available information to addressand sharpen it.
Unlike our approach, users search for documents and must consume the unstructuredinformation themselves.
We instead apply this paradigm to RE and strive to find structured, relationalinformation in text corpora of unknown content as well as generate Realtion Extractors in the process.Preemptive Information Extraction (Shinyama and Sekine, 2006), as well as much work in Open In-formation Extraction (Yates et al., 2007) that builds on this idea, is the preemptive (or open) extractionof all possible relations in a text corpus.
We draw inspiration from this idea in our preemptive sub-tree generation approach; however, while we extract all possible subtrees for each relation regardless ofwhether they point to a relation or not, Preemptive and OpenIE approaches aim to produce facts andtherefore much more narrowly extract predicates using rule-sets (Del Corro and Gemulla, 2013), classi-fiers (Schmitz et al., 2012) or both (Etzioni et al., 2011).Manual Rule-Based RE.
We also build our work on the field of manual, rule-based RE, which has beenobserved to be predominantly preferred industry solution due to interpretability of extraction rules and2094easy adaption to changing domains (Chiticariu et al., 2013; Chiticariu et al., 2010).
The lack of toolsto assist rule developers in exploring and choosing between different automatically generated rules hasbeen stated to be one of the major challenges associated with rule-based RE systems.
Recent researchhas moved towards more guided (Li et al., 2012) and more interactive (Akbik et al., 2013b) workflowsfor the creation of rule-based extractors.
Our proposed approach follows this direction, but is the firstapproach to combine both with automatic suggestions and enable exploratory search for relations.Precomputing Resources of Relational Patterns.
Our work also bears some resemblance to previouswork that have grouped similar extraction patterns into clusters (Li et al., 2011) or arranged them in ataxonomy (Nakashole et al., 2012), with the goal of facilitating relation extraction efforts.
Contrary tothese works, we do not precompute a static resource but rather continuously re-compute pattern sugges-tions on the basis of user interactions and the text corpus that the user is working with.
In addition, oursuggestions are based on both user-selected patterns as well as entity type restrictions.5 Conclusion and Future WorkIn this paper, we proposed Exploratory Relation Extraction as a method of exploring text corpora ofuncertain content for relations of interest given an imprecise information need.
We have presented andevaluated a user-driven and data-guided incremental exploration workflow that enables non-expert usersto identify relations and create high precision extractors with minimal effort.
Our results indicate thatapplying ideas from Exploratory Search to RE is beneficial and can extend the application of RE to usecases characterized by more imprecise information needs and uncertainty regarding the information con-tent of available data.
In order to facilitate the discussion of our approach with the research community,we release our work publicly through a Web demonstrator3.Future work will investigate extending the approach to relations that hold between an arbitrary numberof entities as well as the detection of custom entity types.
We aim to allow users to store and combine ex-tractors - for example relation extractors that use custom entity type detectors - to address more complexinformation needs and distribute the exploration and extraction processes along larger groups of users.This way we seek to enable collaborative RE approaches for creating large knowledge bases from text.AcknowledgementsWe would like to thank the anonymous reviewers for their helpful comments.
This research is funded by the European Union?sSeventh Framework Programme (FP7/2007-2013) under grant agreement no ICT-2009-4-1 270137 ?Scalable PreservationEnvironments?
(SCAPE) and the German Federal Ministry of Education and Research (BMBF) under grant no.
01ISI2033RADAR?.ReferencesA.
Akbik, L. Visengeriyeva, J. Kirschnick, and A. L?oser.
2013a.
Effective selectional restrictions for unsupervised relationextraction.
In Proceedings of the 6th International Joint Conference on Natural Language Processing.Alan Akbik, Oresti Konomi, and Michail Melnikov.
2013b.
Propminer: A workflow for interactive information extraction andexploration using dependency trees.
In ACL System Demonstrations.
Association for Computational Linguistics.Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor.
2008.
Freebase: a collaboratively createdgraph database for structuring human knowledge.
In Proceedings of the 2008 ACM SIGMOD international conference onManagement of data, pages 1247?1250.
ACM.Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao Li, Sriram Raghavan, Frederick R Reiss, and Shivakumar Vaithyanathan.2010.
Systemt: an algebraic approach to declarative information extraction.
In ACL, pages 128?137.
Association forComputational Linguistics.Laura Chiticariu, Yunyao Li, and Frederick R Reiss.
2013.
Rule-based information extraction is dead!
long live rule-basedinformation extraction systems!
In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Pro-cessing, pages 827?832.Jinho D Choi and Andrew McCallum.
2013.
Transitionbased dependency parsing with selectional branching.
In Proceedingsof the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria.3The demonstrator is available at http://lucene.textmining.tu-berlin.de/2095Aron Culotta and Jeffrey Sorensen.
2004.
Dependency tree kernels for relation extraction.
In Proceedings of the 42nd AnnualMeeting on Association for Computational Linguistics, page 423.
Association for Computational Linguistics.Jeffrey Dean and Sanjay Ghemawat.
2004.
MapReduce: simplified data processing on large clusters.
In Proceedings of the 6thconference on Symposium on Opearting Systems Design & Implementation - Volume 6, OSDI?04, pages 137?150, Berkeley,CA, USA.
USENIX Association.Luciano Del Corro and Rainer Gemulla.
2013.
Clausie: clause-based open information extraction.
In Proceedings of the22nd international conference on World Wide Web, pages 355?366.
International World Wide Web Conferences SteeringCommittee.Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam Mausam.
2011.
Open information extrac-tion: The second generation.
In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume One, pages 3?10.
AAAI Press.Evgeniy Gabrilovich, Michael Ringgaard, and Amarnag Subramanya.
2013.
FACC1: freebase annotation of ClueWeb corpora,version 1 (release date 2013-06-26, format version 1, correction level 0).Yunyao Li, Vivian Chu, Sebastian Blohm, Huaiyu Zhu, and Howard Ho.
2011.
Facilitating pattern discovery for relation ex-traction with semantic-signature-based clustering.
In Proceedings of the 20th ACM international conference on Informationand knowledge management, pages 1415?1424.
ACM.Yunyao Li, Laura Chiticariu, Huahai Yang, Frederick R Reiss, and Arnaldo Carreno-fuentes.
2012.
Wizie: a best practicesguided development environment for information extraction.
In Proceedings of the ACL 2012 System Demonstrations, pages109?114.
Association for Computational Linguistics.Gary Marchionini.
2006.
Exploratory search: from finding to understanding.
Communications of the ACM, 49(4):41?46.M.
Mintz, S. Bills, R. Snow, and D. Jurafsky.
2009.
Distant supervision for relation extraction without labeled data.
InACL/AFNLP, pages 1003?1011.Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek.
2012.
Patty: a taxonomy of relational patterns with se-mantic types.
In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing andComputational Natural Language Learning, pages 1135?1145.
Association for Computational Linguistics.Slav Petrov and Ryan McDonald.
2012.
Overview of the 2012 shared task on parsing the web.
In Notes of the First Workshopon Syntactic Analysis of Non-Canonical Language (SANCL), volume 59.Frederick Reiss, Sriram Raghavan, Rajasekar Krishnamurthy, Huaiyu Zhu, and Shivakumar Vaithyanathan.
2008.
An algebraicapproach to rule-based information extraction.
In Data Engineering, 2008.
ICDE 2008.
IEEE 24th International Conferenceon, pages 933?942.
IEEE.Ellen Riloff.
1996.
Automatically generating extraction patterns from untagged text.
In Proceedings of the national conferenceon artificial intelligence, pages 1044?1049.Sunita Sarawagi.
2008.
Information extraction.
Foundations and trends in databases, 1(3):261?377.Michael Schmitz, Robert Bart, Stephen Soderland, Oren Etzioni, et al.
2012.
Open language learning for information extrac-tion.
In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computa-tional Natural Language Learning, pages 523?534.
Association for Computational Linguistics.Alexander Schutz and Paul Buitelaar.
2005.
Relext: A tool for relation extraction from text in ontology extension.
In TheSemantic Web?ISWC 2005, pages 593?606.
Springer.Yusuke Shinyama and Satoshi Sekine.
2006.
Preemptive information extraction using unrestricted relation discovery.
InProceedings of the main conference on Human Language Technology Conference of the North American Chapter of theAssociation of Computational Linguistics, pages 304?311.
Association for Computational Linguistics.Jannik Str?otgen and Michael Gertz.
2010.
Heideltime: High quality rule-based extraction and normalization of temporalexpressions.
In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 321?324.
Association forComputational Linguistics.Hans Uszkoreit.
2011.
Learning relation extraction grammars with minimal human intervention: strategy, results, insights andplans.
In Computational Linguistics and Intelligent Text Processing, pages 106?126.
Springer.Chang Wang, Aditya Kalyanpur, James Fan, Branimir K Boguraev, and DC Gondek.
2012.
Relation extraction and scoring indeepqa.
IBM Journal of Research and Development, 56(3.4):9?1.Ryen W White and Resa A Roth.
2009.
Exploratory search: Beyond the query-response paradigm.
Synthesis Lectures onInformation Concepts, Retrieval, and Services, 1(1):1?98.Alexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead, and Stephen Soderland.
2007.
Tex-trunner: open information extraction on the web.
In Proceedings of Human Language Technologies: The Annual Conferenceof the North American Chapter of the Association for Computational Linguistics: Demonstrations, pages 25?26.
Associationfor Computational Linguistics.2096
