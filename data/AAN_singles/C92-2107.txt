Machine Translation by Case GeneralizationHirosh i  NomiyamaIBM Research ,  Tokyo  Research  Laboratory5-19 Sanbancho ,  Ch iyoda-ku ,Tokyo  102 JapanE -Ma i l :nomiyama@tr l .vnet .
ibm.comAbstractCase-based machine translation is a promising ~p-preach to resolving problems in rule-based machinetranslation systems, such as difficulties in control ofrules and low adaptability ospecific domains.
We pro-pose a new mechanism for case-based machine trans-lation, in which a large set of cases is generalized intoa smaller set of cases by using a thesaurus.1 Int roduct ionCase-Based/Example-Based Machine Translation(CBMT/EBMT) has been proposed as a way of over-coming the knowledge acquisition bottleneck in ma-chine translation.
This approach isbased on the simpleconcept of translating sentences by analogy with simi-lar cases tored in a set of cases(a case-base) \[1, 2, 3, 4\].This ~pproach has two advantages in terms of knowl-edge acquisition.
CBMT/EBMT ensures that (1) if thesame case as the input exists in the case-base, then thesame result will be obtained, and (2) if a similar caseexists in the case-base, then a similar result will be ob-tained.
In the first instance, which eases are regardedas the same depends on the equality metrics of the sys-tem.
In the second instance, which cases axe regardedas similar depends on the similarity metrics.
Rule de-velopers or users can control the system on the basisof equality and similarity without understanding theglobal flow of controls.In applying this idea to practical machine transla-tion systems, there are still two serious problems.
Oneis that CBMT/EBMT requires a great deal of compu-tation because of its inherent need to retrieve a hugenumber of cases and calculate their similarities to theinput.
For practical systems, several hundreds of thou-sands of cases must be accessible.CBMT/EBMT systems hould not impose any re-strictions on cases to be added to the case-base in aneffort to keep the case-base small, since the similaritymetrics depends on the frequencies ofcases.
If cases arerestricted, sufficient information to control the rules isnot acquired.The other problem of CBMT/EBMT is the diffi-culty of defining a semantic distance, Though the-sauri are used as bases for semantic distance calcula-tion in CBMT/EBMT, it may be impossible to definea general semantic distance by using thesauri alone.Semantic distances between words are defined accord-ing to which specific words axe related to their trans-lations.
For example, in translating the word "~t:"~"(eat,feed,... ), "9~ (dog)-;b~:"c,Y~"is equivalent to"a dog eats," "-'~ (cow)-7)~-~:"?,7~ '' is equivalent o"a cow feeds," and ".~ (horse)-7)e-~:"v-Yd '' is equiva-lent to "a horse feeds."
In these cases, "~i:"(cow) iscloser to ",~"(horse) than "::~"(dog), because differ-ent words are selected for each transla, tion of "~:"~~"  with "t~'(cow) and "Y~"(dog).
But in translating"~7z"(run,gal lop,.
.
.)
,  ":J~ (dog)-:6?.~.7o " is equiva-lent to "a dog runs," ,,-~t= (eow).
:~_:~=7~" is equivalentto "a cow runs," and ".~ (horse)-Z~L::i~--zo" is equivalentto "a horse gallops."
In these eases, "t\[='(cow) is closerto "9~"(dog) than ",~"(horse).If such incomplete semantic distances calculated bythesauri alone are used for CBMT/EBMT, excep-tional cases may be interpreted as general ones(over-generalization).
Over-generalization is a major prob-lem in translating idiomatic expressions.
For exanl-pie, "\[t\[I (head)-z)~AJ/J~L7o" has two translations: "hurtone's head " or, idiomatically, "be smart."
But "~\]i~(head) -~?-~-~ " has only one interpretation, "hurtone's head," though the word "~jl~\[~ '' has almost thesame meaning as ".U~.
".It is obvious that "~-~':~.~tt:~TJ;tl.~" can be trans-lated correctly by adding this translation pair intothe case-base.
The addition, however, cannot preventACRES DE COLING-92, NANTES, 23-28 ao6-r 1992 7 !
4 PRec.
OF COLING-92, NANTES, AUG. 23-28, 1992the idiomatic expression "~J~-7)?-~7o" from being in-terpreted generally.
The idiomatic interpretation stillmay be 'adopted for "X -~5?-~7~"  if X is more simi-lar to the word "~j~" than the words in the case-basewhose pattern is "X-z~-~/LTo.
"Sato \[3\] and Sumita \[4\] weigh each slot dependingon how much it affects the translation.
However, sincesuch weights are calculated only for each slot, the over-generalization that occurs inside of a slot is not re-solved.
To avoid over-generalization, we need somemechanism to encapsulate xceptions rather than toadjust the semantic distance.2 Machine Translat ion by CaseGeneral izationA case-base, in contrast o a set of rules, has inherentredundancy, because cases are collected without pre-selection.
In the simplest case, if the sentence "A" hasonly one translation equivalent "a," then the singleease "A" ~ "al' is enough to translate "A?
'But if we view the case-base as a collection of sen-tences, the santo sentences rarely seem to occur 1.
Sen-tences can, however, be divided into smaller fragmentswhich are meaningful units for translation according tothe some linguistic models, which we call translationpatterns.These fragments are combined for use in translatingsentences.
Fragments divided on the basis of trans-lation patterns are obviously more effectlvc than sen-fences, because smaller fragments are more likely tomatch than full sentences.We generalize such fragments extracted accordingto each translation pattern, using a thesaurus, by re-placing the words that occur in cases by more generalconcepts in the thesaurus.
The words to be replacedare determined by their frequencies in the case-base.Frequent occurring fragments should be assigned moreweight than less frequent by occurring fragments.
Thefrequencies of fragments axe used to weigh generalizedcases in generalization.Semantic distances are calculated for each transla-tion pattern as the importances of generalized cases.Only meaningful categories for the translation patteruare stored as generalized cases, except that the mostmeaningful category is taken as a default.
For example,1The ease-bane should contain natural sentences rather thanexamplt~ which ~re only the smallest fragments effective fortranslation.
We distinguish CBMT from EBMT in accordancewith this viewpaint.the word "9~"(dog) may be generalized into the cou-cept <dog> 2 for translation of ,qrJj < "("a dog barks"),whereas it may be replaced by tbe more general con-cept <animal>, for other translation patterns in whichthe concept <dog> is not ineaningful.While generalizing cases, we can identify exceptionalcases as those which cannot be generalized.
Once weidentify exceptions, then we can prevent such excep-tions from being interpreted generally.In this way, cases are generalized according to tbetranslation pattern into generalized cases with con-cepts as the values of their variables.In dd i t ion  to generalized cases, rules can be formu-latcd according to translation patterns.
Generalizedcases and manually written rules are assumed to bethe same as objects in CBMT.
It is valuable to haverules available as well as cases, especially when thecase-base contains iusnfficicnt cases.
If rules are notavailable, there must be sufficient cases from the timethe system is first used.
h~creinental development ofany domain is possible only if general rules are avail-able.In accordance with these basic ideas, we propose amethod of machine translation in which cases are gen-eralized.
In our approach, we define linguistic patternsin translation.
According to these patterns, the casesin the case-base are divided into smaller fragments andare generalized.
BotlL rules and generalized cases areused to translate senteuces.CBMT is divided into two sub-processes: (1) bestmatching, to search for the nmst similar cases in thecase-base, and (2) application control, to control thecombinatim~ of similar cases for translation.
Applica-tion coutrol is a general problem in machine transla-tion, whereas best matching is a problem unique toCBMT.
If the best matching process returns certaintyfactors, the system is controlled using these factors onthe basis of the some other model such as Watanabe's\[5\].In tiffs paper, we concentrate on best matching usinga thesaurus.2Concepts are enclosed between arrowheads (< and >) inthis paper.ACTES DE COL1NG-92, NANTES, 23-28 AO(ff 1992 7 I 5 PROC, OF COLING-92, NANTES, AUG, 23-28, 19923 Genera l i z ing  Cases3.1 Div is ion  and  L inear l i za t ion  o fCasesAt first, we define a translation pattern (TPi) as fol-lows.TP~ = \[P,,V,,P,,Vt\]P, : Structural Pattern in Source Language (SL)V, : List of Lexical Variables in SLPt : Transformation i to Target Language (TL)Vt : List of Variables in TLWe call the number of variables in V, the term num-ber (Mi) of TP,.Next, we extract translation pattern causes (TPC,)from the case-base by applying the pattern matchesdescribed in TPI to all cases in the case-base.TPCi = \[L,, C,, L,\]L, : List of Values of Lexieal Variables in SLC, : List of Constraints in SLLt : List of Values of Variables in TLIf some patterns other than those specified in P, arerelated in translation, those patterns axe described inconstraints (C,).These TPC, s are finearllzed into linearlized translw-tlon pattern cases (LTPCi).LTPCi : L. --* (Co, Lt)We call the right-hand part of LTPCi the value(V).
The examples in Fig.
1 are extracted LTPC, sin Japanese-to-English translations of "NOUN niVERB," where we assume a translation pattern inwhich an English preposition is determined by a bi-nary relation of a Japanese noun and a Japanese verb.In the following section, we show how to general-ize LTPCis into generalized linear translation patterncases (GLTPCI) by replacing words with more gen-eral concepts in the thesaurus, and calculate degreesof importance for them.\["Sangat u" (M arch) ,"Kowasu" (dest roy)\["Sigatu"(April) ,"Gironsnru"(discuss)\["Gogatu"(May) ,"Saiketusuru"(vote)\["Rokugatn"(June) ,"Hieru"(cool)\["Getuyou"(Monday) ,"Arau'(wash)\["Kayon" (Tuesday) ,"Kimaru"(decide)\["Sy .
.
.
.
.
.
t u" (weekend),"Agarn" (raise)\["Higasi"(east) ,"Uturu'(move)\["Toukyou" (Tokyo) ,"Idousuru" (move)\["Sitigatu"(July) ,"Idonsuru"(move)\] ~ (\[\],\["in"\])l ~ (\[\],\["in"l)\] ~ (\[\],\["in"l)~ (\[I,\["in"D(H,\["on"D(\[\],\[-on"D( \ [H"on'D~ (\[\],\["to"D(\[},\["to"\])~ (\[\],{"in"\])Figure I: Translations of "NOUN ni VERB"3 .2  Case  Genera l i za t ion  by  Means  o fa Thesaurus3.2.1 Creat ion of N-Term Part ia l  Thesaur iWe create working thesauri, PTH~(j) (1 < j < Mi),for each term.
They iuclude every word in the j-thterm, and set pairs of values and their frequencies ineach word node.Here we define ttle importances used to weigh gen-eralized cases.Impor tance  of a Link (.rL) The importance of alink (IL) is the probability of occurrence of eases thatoccurred in the subtree of PTH,(j).
IL is defined asfollows.S I L=- -  c,where S is the total number of cases in the subtreeconnected with the link, and C~ is the total numberof LPTCIs extracted from tile case-base according toTP.Impor tance  of a Node (IN) The importance ofnode (IN) shows the degree of variance of values in asubtree.
IN  is defined as follows.where Pk is the probability of each value in the sub-tree 3.Impor tance  of a Value (IV) The importance of avalue L (IV) in the node k is defined as follows.If node k is a word node, then\[Vkt = frequency of value L in node kaWe adopt the s~me xpre~ion as that used by Stanfill \[6\]and Sumita \[4\].AcrEs DE COLING-92, NAN'IXS, 23-28 AO0"r 1992 7 1 6 PROC.
OF COLING-92, NANTES, AUO.
23-28, 1992else\[V~,t = INj, t~__,(IL,, x IV,,i)where m is a node linked to node k, and/14,ais the importaatce of value L in node m.Impor tance  of a Genera l i zed  Case (IC) The im-portance of a GLTPCi (IC) is defined a.s follows.Mij=lwhere IVjt is tile importance of value L, which is thesame as the value of the GLTPCi.3.2.2 Subd iv is ion  of Conceptua l  Leaf  NodesAccording to the definitions given in the previoussection, at first ILs and INs are set in all the linksand nodes in PTHI(j), and IVs are calculated m con-ceptual eaf nodes in PTHi(j).If IV is not the maximum value in a conceptualleaf node and is greater than the prc-defined thresh-old value and its frequency is greater than 2, the nodeis subdivided into more specific concepts.Subdivision occurs because a specific category whichdoesn't exist ill the thesaurus is effective for a specifictranslation pattern.
Only the difference from tile ttle-saurus is kept a.s the translatlou pattern thcsanrus i(TPTHI).3.2.3 P ropagat ion  of Impor tance  of  ValuesNext, we calculate IV in all nodes other than COlt-ceptual eaf nodes by propagating IV.
The propaga-tion is done by multiplying the importances of valuesby the importances of links, and the sum of all thepropagated values is multiplied by the importance ofthe node.
At first, the propagation is done upward,starting from the conceptual leM nodes.
During up-ward propagation, downward propagation is done if achild node is a conceptual node and a propagated valueis greater than the maximum importance of values inthe child node.
Downward propagation prevents over-generalization.We show examples of results of importnnce calcu-lation in Fig.
2 and Fig.
3, for tile first and sec-ond terms respectively.
In Fig.
2, the subdivision oc-curred in the node <Time> and the new node <*X*>was created.
A downward propagation occurred inthe node <Concrete> in Fig.
2.
Tile word "in" wasmade more important han the word "to" in the node<Concrete>.\[<>,<Destruction>\] -~ ( [\],\["in"l)\[<>,<Speech>\] ~ (\[\],\["iil"\])\[<>,"Salket ....... "(decide)\] ~ (\[\],\["\[n"\])\ [<>,<>1 ~ (\[\],\["in"\])\ [<*X*>,<Act ion>\ ]  ~ (\[\],\["on"\])\[<*X*>?
'Kinlaru"(decide)\]-" (\[I,\["on"l)\[<*x*>,<Up-D .
.
.
.
>l~(\[\],\["?n"l)\[<Location>,<Abstract>\]-* (\[\],\["to"\])\ [<Di rect lon>,<Abst ract>\ ] - "  (\[l,\["to"\])\ [<>," Id  .
.
.
.
.
.
.
.
"( .
.
.
.
.
.
)l ~ (\[\],\["t?
"\])Figure 4: Result of the lntra-Term Generalization3.2 .4  I n t ra -Term Genera l i za t ion  of LTPCiAccording to importances calculated according tothe method described in the previous ection, LTPCisare generalized in the jail term.
If the value with thehighest IV  in tile child node is the same as the valuewith tile highest IV in tin> parent node, then tile wordin the term is generalized by the concept in the parentnodE.'.
This process of generalization is repeated un-til no further generalization is possible, and only themost generalized cases are kept.
If identical c~es areobtained as a result, only one case is kept.We show an ex~tmple of intra-term generalization of\["Kaymz"(Tnesday),"Ki ....... "(decide)\] ~ (\[1,\["on"\]).Initially, the firts term "K~vou"(Tuesday) is gener-Mized.
T1 .
.
.
.
1 .
.
.
.
f (hi .
.
.
.
.
(\[\],{"on"\]) is th .
.
.
.
.
.
.as tile vMue with tile highest IV in the parent node<*X*> (see Fig.
2), so "Kayou"(Tuesday) is re-placed by <*X*>.
The value (\[\],\["on"\]) is not tilevalue with tile highest IV  in the parent nede of<*X*>, and therefore generalization stops at the firstterm.
Next, the second term "Kimaru"(decide) isgeneralized.
In tt~e parent node <Decision> of "Ki-maru"(decide), tile value that is the same as tile valueof the ea.se is one of the values with the higtlestIV.
Consequently, parent nodes are checked to de-termine which value is more important.
In tile rootnode, (\[\],\["on"\]) is less important l .... (\[\],\["in'\]) .
.
.
.no generalization occurs for the second term.
Fi-nally, \[<*X*>,"Ki .
.
.
.
.
.
"(decide)\] ~ (\[\],\["on"\]) is ob-tained as tile result of intra-term generalization.Tile result of intra-term generallzatiml for all tileLTPC, s in Fig.
1 is slmwn in Fig.
4.3.2.5 In ter -Term Genera l i za t ion  of LTPCiNext we generalize cases over terms.
Inter-term gen-eralization takes ICs into consideration.
If M, = 1,ACRES DECOLING-92, NANTES, 23-28 AOI}T 1992 7 1 7 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992o.1"RokugllU",l,(fl,p+ln~} "0 etuyou ",l,(~\],Fon++\] )-SmOaW',1.
(fl,FIn"\]) "KJy~",l+(~,\["o.+\])-sangltu++.l ,(D,t'ln+J) "$ y uuma~u ",1 ,(a, p+o.+l)Figure 2: First-Term Partial Thesaurus0"um"" '+ ' I~ ' t : ' t . "
.~P_ .
,  I i - , .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
\ ]+ '::::=+:+:+,+++,,.,.++.++++.I +,.,, ., r,:?.u,.
., !?::?
:,:?+,, o.,o, +.,~-~o.1o, +-+ ~., +'+:+'?+"~lketusum",l,(\[l,\["ln"l).Glron~ru,,,(Q,\[.,in.l) "KImMu",l,(D,r'on"l)Figure 3: Second-Term Partial ThesaurusACTES DE COLING-92.
NANTES, 23-28 ^ oI3"r 1992 7 1 8 PROC.
OF COLING-92.
NANTES, AUG. 23-28.
1992then the result of intra-term generalization with ICsis the generalized linear translation pattern case i(GLTPCi).
If M, > 1, j th term ma~ximum gener-alization (1 ~ j < M~) is done for e~.ch term.
In j-thterm maximum generalization, terms other than thej-th term are fixed first and the j-th term is general-ized .as much a.s possible.
Then, the maxinmni possiblegeneralization is done for remaining of terms in turn.If Mi > 1, then M, x (Mi - 1) GLPTC, s axe obtained.If identical cases are obtained as a result, only one caseis kept.We show an exz~mple of inter-term generalizatlnnof \[<Directiou>,<Abstraet>\] - "  (\[\],\["to"\]).
Initially,first-term ma.ximum generalization is done.
IVs in thenode <Abstract> are shown betow (see PTHi(2) inFig.
3).
(N,\["to"l) : 0.027(~,\["in"\]) : 0.020(N,I"on")) : 0.006IVs in the node <Abstract>, which is the parent nodeof <Direction>, are shown below (see PTHi(1) in Fig.2).
(l\],\["in"\]) : 0.192(\[ \] , \["on' l)  : 0.035(\[\],\["to"\]) : 0.007Their totals are ms follows.
(~,\["to"\]) : 0.027 + 0.007 = 0.034(H,\["in"\]) : 0.020 + 0.192 = 0.212(\[l,\["on"\]) : 0.006 + 0.035 = o.04~Since (\[I,\["to"l) doesn't have the highest importance,the case is not generalized any further in the first term.Next, the second term is generalized.
The IVs inthe node <Direction> are shown below (see Fig.
2).
(\[\],\["to"l) : 0.1IVs in the node <>,  which is the parent node of<Abstract>, axe shown below (see Fig.
3).
(~,\[" in' l )  : 0.011(H,\["to"l) : o .o0s(N,i"on"I) : 0.006Their totals are as follows.\[<>,<>\] - ,  (\[},\["in"\]) 0.11s\ [<*X*>,<>\]  -~ (\[\],\["on"\]) 0.306{<C ......... te>,<Abst rac t>\ ]  -~ (\[\],\["to"l) 0.037\ [<Locat ion>,<>\]  -"  (\[\],\["to"\]) 0.108\ [<Di rec t ion>,<>\]  ~ (\[\],\["to"l) 0.108Figure 5: Result of the Inter-Term Generalizationd\],\["to"\]) : 0.1 + o.0os = 0.10s(\[\],\[' in"\]) : 0 + 0.011 = 0.011(I\],\['~on"\]) : 0 + 0.006 = 0.006Since (\[\],\["to'\]) has the highest import ...... th .
.
.
.
.end term isgenerMized into the root node <>, and the general-ization stops because there are no nlore parent nndes.Therefore \[<Direction>,<>\] ~ ({\],\["to'\]) 0.108 is theresult of first-term nlaxinlutn generalization of\[<Direction>,<Abstract>\] - "  (\[\],\["to"\]).The result of inter-tcrm generalization for all theLTCPis in Fig.
1 is shown in Fig.
5.3.2 ,6  Addi t ion  of T rans la t ion  RulesFinMly, translation rules (TRis) are added to the setof GLTPC, s. TRis are descriptions in which conceptsare specified as the values of variables of L. of LTPC, s.If the same case Mready exists in the set of GLTPC,,then it is not added.
If only the wJue of the ease isdifferent from TRi, then it is replaced by TR,.
Ottier-wise, TR, is added with its IC.
The ICs for TRis aree~dcnleAed in the same way as for GLTPC, s.4 Best -Match ing  A lgor i thmThe Tl'is, the set of GLTPC, s, the TPHis, aud tilethesaurus are used in hest matching.
The values ofvaxi~bleu in V. z.re extracted from the input sentence byapplying pattern matching according to the descriptionof TPi.
The best-matching process retrieves the mostsimilar case frmn the set of GLTPC,.If M'~ = 1, words which are equivalent 1o the wordthat is a value of the variable in l ;  axe first searchedfor in the value of the corresponding wriable in L,of GLTPCo.
If none are found, upper concepts re-trieved in either TPTHI or the thesaurus are searchedin turn.
The GLTPCI which is found first is theshortest-distance GLTPCi (SDGLTPCI).
If C; inGLTPCi is not null, then it is also evaluated, whetherit is true or false.AcrEs DE COLlNG-92, NANTES, 23-28 ^ Ot')q 1992 7 1 9 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992If Mi > 1, the j-th term shortest-distance GLTPC, s(SDGLTPCj) of each term are searched for.
If Mi =2, SDGLTPC~ holds the shortest-distance word orconcept in the first term, and SDGLTPC2 holds theshortest-distance word or concept in the second term.If 2!4, > 1, (M~ - 1) SDLTPCjs are obtaiued for eachj-th term.
A total of Mi x (M i -  1) SDLTPCjs are ob-tained.
The SDGLTPCj with the highest importanceis selected as the SDGLTPC.We will show an exmnple in retrieving the most sim-ilar example for "Getuyou(Monday)ni-Huru(rain).
"Suppose the parent node of "Huru" is <Climate>.
AtfirsL SDGLTPCI will be searched for iu GLTPCis(see Fig.
5).
"Getuyou" does not exist in any firstterms in the set of GLTPC~s.
Therfore <*X*> whichis the parent node of "Getuyou" is searched for and\[<*X*>,<>) ~ (\[\],\["on'\]) 0.306 is found.
T1 .
.
.
.
.
.ond term of this GLTPCi is a upper concept of"Huru," so this is SDGLTPC1.
Next, SDGLTPC2is searched for and is found to be the same asSDGTPC1.
Consequently, the most similar GLTPCiis \ [<*X*>,<>\] ~ (\[\],\["on"\]) 0.306, and the word "on"is set as a preposition.5 D iscuss ionIn the CBMT approach, the linguistic model, whichis a set of translation patterns, is important both forthe compaction ratio of a case-base and for similar-ity metrics.
If the model is not appropriate, mostcases remains ungeneralized, and unnatural cases areretrieved as similar eases to the inpnt.
The problemsof constructing linguistic models axe the same as inrule-based systems.However, our approach assumes that the linguisticnmdel does not include controls of rules and general-ized cases.
Whether or not this assumption is correct,it is very ditfieult to define controls in such a way thatany exceptional cases axe encapsulated properly.
Ourapproach provides a~l engineering solution to these dif-ficulties.In our approach, the quality of translations dependson the quantity of cases rather than the quality ofthe thesaurus.
Therefore, it is important o explore(semi-)automatic case acquisition from bilingual cor-pora.To construct a huge case-base is easier than to con-struct a well-defined thesaurus, because cases are con-strueted locally without taking account of side-effects.To define an effective thesaurus for translation, everyeffective category for translation must be included, andevery intermediate category that is effective for trans-lation must be included in order to calculate semanticdistances properly.If, on the other hand, thesauri can be developed in-dependently from the case-base, developers or userscan select the most appropriate thesaurus for the do-main,6 Concluding RemarksThis paper has descrlhed a framework for a machinetranslation using a mixture of rules and cases general-ized by means of a thesaurus, whict~ is much smallerthan the ease-base itself.
Since the importances of rulesand generalized cases are calculated in advance by gen-eralization, it is not necessary to calculate them duringthe best-matchlng, which is done by exact matching ofwords or upper concepts in the thesaurus.AcknowledgementsI would like to thank Masayuki Morohashi and themembers of Japanese Processing Group of Tokyo Re-search Laboratory, IBM Japan, for their valuable sug-gestions and encouragement, and Michael McDonaldfor his helpful advice on the wording of this paper.References\[1 t Nagao, M., ~A Framework of a Mechanical Transla-tion between Japanese and EngSsh by Analogy Princi-ple," Elithorn, A. and Banerji, R.
(eds.
): Artificial andHuman Intelligence, NATO, 1984.\[2\] Sadler, V., "Working with Analogical Semantics: Dis-ambiguation Techniques in DLT," FORIS Publications,1989.\[3\] Sato, S., and Nagao, M., "Toward Memory-basedTranslation," Proc.
of Coling '90.\[4\] Sumita, E., lida, H., and Kohyarna, t i ,  "Translatingwith Examples: A New Approach to Machine Transla-tion," Proe.
of the 3rd Int.
Conf.
on Theoretical andMethodological Issues in Machine Translation of Natu-ral Languages, 1990.\[5 !
Watanabe, H., ~A Similarity-Driven Transfer System,"Proc.
of Coling '92.\[6\] Stanfill, C. and Waltz, D., "Toward Memory-BasedReasoning," Comm.
of ACM, Vol.29, No.i2, pp.
1213-1228, 1986.AcrEs DE COLING-92, NANTES, 23-28 hOWl" t992 7 2 0 PROC.
OF COLING-92, NANTEs, AUG. 23-28, 1992
