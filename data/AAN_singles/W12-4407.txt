Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 52?56,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsSyllable-based Machine Transliteration with Extra Phrase FeaturesChunyue Zhang, Tingting Li, Tiejun ZhaoMOE-MS Key Laboratory of Natural Language Processing and SpeechHarbin Institute of TechnologyHarbin,China{cyzhang,ttli,tjzhao}@mtlab.hit.edu.cnAbstractThis paper describes our syllable-based phrasetransliteration system for the NEWS 2012shared task on English-Chinese track and itsback.
Grapheme-based Transliteration maps thecharacter(s) in the source side to the targetcharacter(s) directly.
However, character-basedsegmentation on English side will causeambiguity in alignment step.
In this paper weutilize Phrase-based model to solve machinetransliteration with the mapping betweenChinese characters and English syllables ratherthan English characters.
Two heuristic rule-based syllable segmentation algorithms areapplied.
This transliteration model alsoincorporates three phonetic features to enhancediscriminative ability for phrase.
The primarysystem achieved 0.330 on Chinese-English and0.177 on English-Chinese in terms of top-1accuracy.1 IntroductionMachine transliteration, based on the pronunciation,transforms the script of a word from a sourcelanguage to a target language automatically.With a continuous growth of out-of-vocabularynames to be transliterated, the traditionaldictionary-based methods are no longer suitable.So data-driven method is gradually prevailing now,and many new approaches are explored.Knight(1998) proposes a phoneme-basedapproach to solve the transliteration betweenEnglish names and Japanese katakana.
It makesuse of a common phonetic representation as a pivot.The phoneme-based approach needs apronunciation dictionary for one or two languages.These dictionaries usually do not exist or can'tcover all the names.
So grapheme-based(Li et al,2004) approach has gained lots of attentionrecently.
Huang(2011) proposes a novelnonparametric Bayesian using synchronousadaptor grammars to model the grapheme-basedtransliteration.
Zhang(2010) builds the pivottransliteration model with grapheme-based method.The hybrid approach tries to utilize both phonemeand grapheme information, and usually integratesthe output of multiple engines to improvetransliteration.
Oh and Choi(2006) integrate bothphoneme and grapheme features into a singleleaning framework.As an instance of grapheme-based approach,Jia(2009) views machine transliteration as a specialexample of machine translation and uses thephrase-based machine translation model to solve it.The approach is simple and effective.
Our paperfollows this way.
However, using the Englishletters and Chinese characters as basic mappingunits will make ambiguity in the alignment andtranslation step.
One Chinese character usuallymaps one syllable, so syllabifying English wordscan be more discriminative.We present a solution to this ambiguity byreplacing the English character with an Englishsyllable which is consecutive characters and cankeep some phonetic properties.
For this purpose,two heuristic and simple syllable segmentationalgorithms are used to syllabify English side intosyllables sequence.
Besides two above, three extraphrase features for transliteration are used toenhance the model.The rest of this paper is organized as follows.Section 2 introduces the phrase-based modelbriefly.
Section 3 describes two rule-based syllable52segmentation methods and three new specialfeatures for transliteration in detail.
Experimentsand analyses are discussed in section 4.Conclusions and future work are addressed insection 5.2 Phrase-based Machine TransliterationModelMachine transliteration can be regarded as aspecial instance of machine translation.
Jia(2009)solves transliteration with phrase-based modelfirstly.
There an English character is treated as aword in machine translation.
On the contrast,character is replaced by syllable in this paper.
Thentransliteration can be viewed as a pure translationtask.
The phrase-based machine transliteration canbe formulated by equation 1.???
?niiiexhxpe1~ )(exp)(maxarg ?(1)?
n is the number of features?i?
is the weight of feature iIn our phrase-based transliteration system, thefollowing features are used by default:?
the bidirectional probability betweensource phrase and the target phrase?
The bidirectional lexical probabilitybetween source phrase and target phrase?
the fluency of the output, namely languagemodel?
the length penalty3 Syllable Segmentation and ExtraPhrase FeaturesThis section describes two rule-based syllablesegmentation algorithms and three extra phrasefeatures added to machine transliteration model.3.1 Syllable Segmentation AlgorithmIn (Jia et al, 2009), the basic alignment units areEnglish character and Chinese character(calledc2c).
This setup is the simplest format toimplement the model.
However, transliterationfrom English to Chinese usually maps an Englishsyllable to a single Chinese character.
As oneChinese character usually corresponds to manyEnglish characters, the c2c method has only amodest discriminative ability.
Obviouslysyllabifying English is more suitable for thissituation.
Yang(2010) utilizes a CRF-basedsegmentor to syllabify English and Kwong(2011)syllabifies English with the Onset First Principle.Alternatively, inspired by (Jiang, 2007), twoheuristic rule-based methods are addressed tosyllabify the English names in this paper.Given an English name E, it can be syllabifiedinto a syllable sequence SE = {e1,e2,...,en} withone of the following two linguistic methods.Simple Segmentation Algorithm(SSA):1.
{'a', 'o' , 'e', 'i', 'u'} are defined as vowels.
'y' isdefined as a vowel when it is not followed by avowel; 'r' is defined as a vowel when it follows avowel and is followed by a consonant1.
All othercharacters are defined as consonants; this forms thebasic vowel set;2.
A consecutive vowels sequence, formed by thebasic vowel set, is treated as a new vowel symbol;Step 1 and 2 form the new vowel set;3.
A consonant and its following vowel are treatedas a syllable;4.
Consecutive consonants are separated; a vowelsymbol(in the new vowel set) followed by aconsonant is separated;5.
The rest isolated characters sequences areregarded as individual syllables in each word.SSA treats all the consecutive vowels as a singlenew vowel simply.
In fact, many consecutivevowels like "io" often align two or more Chinesecharacters, such as " zio ?
?".
It is better toseparate it as two syllables rather than one syllablein alignment step.
So we present another segmentalgorithm which takes more details intoconsideration.Fine-grained Segment Algorithm(FSA):1.
Replace 'x' in English names with 'k s' firstly;2.
{'a','o','e','i','u'} are defined as vowels.
'y' isdefined as a vowel when it is not followed by avowel;3.
When 'w' follows 'a','e','o' and isn't followed by'h', treat 'w' and the preceding vowel as a newvowel symbol; Step 2 and 3 form the basic vowelset;4.
A consecutive vowels sequence which is formedby the basic vowel set is treated as a new vowel1 A review points the SSA lacking of ability to deal with 'h'.We leave it for the future work.53symbol, excepting 'iu', 'eo', 'io', 'oi', 'ia', 'ui', 'ua','uo' ; Step 2, 3 and 4 form the new vowel set;5.
Consecutive consonants are separated; a vowelsymbol(in the new vowel set) followed by aconsonant sequence is separated;6.
A consonant and its following vowel are treatedas a syllable; the rest of the isolated consonantsand vowels are regarded as individual syllables ineach word.After segmenting the English characters sequence,the new transliteration units, syllables, will bemore discriminative.3.2 Extra phrase featuresThe default features of phrase can't express thespecial characteristic of transliteration.
We proposethree features trying to explore the transliterationproperty.Begin and End Feature(BE)When a Chinese character is chosen as thecorresponding transliteration, its position in thetransliteration result is important.
Such as asyllable "zu" that can be transliterate into "?"
or "?"
in Chinese while "?"
will be preferred if itappears at the beginning position.To explore this kind of information, the pseudocharacters "B" and "E" are added to the train andtest data.
So in the extracted phrase table, "B"always precedes the Chinese character that prefersat the first position, and "E" always follows theChinese character that appears at the last position.Phrase Length FeatureChinese character can be pronounced accordingto its pinyin format which is written like Englishword.
And the longer English syllable is, thelonger pinyin format it often has.
So the lengthinformation of Chinese character and its pinyin canbe used to disambiguate the phrase itself.
Here wedefinite two new features to address it.
Suppose<e,c> as a phrase pair, e= {e1,e2,...,em},c ={c1,c2,...,cn},ei stands for an English syllable andci stands for a Chinese character.
p(ci) is the pinyinformat of ci.
#(ei) is equal to the number ofcharacters in a syllable.
#p(cj) is equal to thenumber of characters in a pinyin sequence.
Andthen,L1 = Sum(#(ei)) / Sum(#(p(cj))L2 = m / n4 ExperimentsThis section describes the data sets, experimentalsetup, experimental results and analyses.4.1 Data SetsThe training set of English-Chinese transliterationtrack contains 37753 pairs of names.
We pick up3000 pairs from the training data randomly as theclosed test set and the rest 34753 pairs as ourtraining data set.
In the official dev set somesemantic translation pairs are found, such as"REPUBLIC OF CUBA ?????
", and somemany-to-one cases like "SHELL BEACH ????"
also appear.
We modify or delete these casesfrom the original dev set.
At last, 3223 pairs aretreated as the final dev set to tune the weights ofsystem features.Language Segmentation Algorithm NumberEnglishCharacter-based 6.82SSA  4.24FSA 4.48Chinese Character-based 3.17Table 1: Average syllables of names based ondifferent segmentation methodsLanguage Segmentation Algorithm NumberEnglishCharacter-based 26SSA  922FSA 463Chinese Character-based 368Table 2 :Total number of unique unitsFor the Chinese-English back transliteration track,the final training and test sets are formed in thesame way; the original dev set is used directly.Here we use Character-based which treats singlecharacter as a "syllable", Simple and Fine-grainedsegmentation algorithms to deal with Englishnames.
Table 1 and table 2 show some syllabicstatistics information.
Table 1 shows the averagesyllables of the three segmentation approaches intraining data.
Table 2 shows the total number ofunique units.4.2 Experimental SetupThe Moses (Koehn et al, 2007) is used toimplement the model in this paper.
TheSrilm(Stolcke et al, 2002) toolkit is used to count54n-gram on the target of the training set.
Here weuse a 3-gram language model.
In the transliterationmodel training step, the Giza++(Och et al, 2003)generates the alignment with the grow-diag-and-final heuristic, while other setup is default.
In orderto guarantee monotone decoding, the distortiondistance is limited to 0.
The MERT is used to tunemodel's weights.
The method of (Jia et al, 2009) isthe baseline setup.4.3 Evaluation MetricsThe following 4 metrics are used to measure thequality of the transliteration results (Li et al,2009a): Word Accuracy in Top-1 (ACC),Fuzziness in Top-1 (Mean F-score), MeanReciprocal Rank (MRR), MAPref.4.4 ResultsTable 3 shows the performance of our systemcorresponding to baseline, SSA and FSA on theclosed test set of EnCh track.
BE, L1,L2 andBE+L1+L2 are implemented on the basis of FSA.ACC MeanF-scoreMRR MAPrefBaseline 0.628 0.847 0.731 0.628SSA  0.639 0.850 0.738 0.639FSA 0.661 0.861 0.756 0.661BE  0.648 0.856 0.751 0.648L1 0.661 0.864 0.756 0.661L2 0.619 0.844 0.727 0.619BE+L1+L2 0.665 0.863 0.762 0.665Table 3:The held-in results of EnChTable 3 shows that the forward transliterationperformance gets consistent improvement frombaseline to FSA.
None of new three features canimprove by self, while combining three featurescan gain a little.ACC MeanF-scoreMRR MAPrefEnCh_Pri 0.330 0.676 0.408 0.319EnCh_2 0.317 0.667 0.399 0.308ChEn_pri 0.177 0.702 0.257 0.173Table 4:  The final official results of EnCh andChEnAccording to the performance of closed test, thetransliteration results of EnCh and ChEn based onBE+L1+L2 are chosen as the primarysubmissions(EnCh_Pri and ChEn_Pri).
And theresult of FSA is the contrastivesubmission(EnCh_2).
The table 4 shows the finalofficial results of EnCh and ChEn.5 Conclusions and future workThis paper uses the phrase-based machinetranslation to model the transliteration task and thestate-of-the-art translation system Moses is used toimplement it.
We participate in the NEWS 2012Machine Transliteration Shared Task English-Chinese and Chinese-English tracks.To improve the capability of the basic phrase-based machine transliteration, two heuristic andrule-based English syllable segmentation methodsare addressed.
System can also be more robustwith combination of three new special features fortransliteration.
The experimental results show thatthe Fine-grained Segmentation can improve theperformance remarkably in English-Chinesetransliteration track.In the future, extensive error analyses will bemade and methods will be proposed according tothe specific error type.
More syllable segmentationmethods such as statistical-based will be tried.AcknowledgmentsThe authors would like to thank all the reviews fortheir help about correcting grammatical errors ofthis paper and invaluable suggestions.
This work issupported by the project of National HighTechnology Research and Development Programof China (863 Program) (No.
2011AA01A207) andthe project of National Natural Science Foundationof China (No.
61100093).ReferencesAndreas Stolcke.
2002.
SRILM - an ExtensibleLanguage Modeling Toolkit.
In Proc.
of ICSLP,Denver, USA.Dong Yang, Paul Dixon and Sadaoki Furui.
2010.Jointly optimizing a two-step conditional randomfield model for machine transliteration and its fastdecoding algorithm.
In Proceedings of the ACL 2010Conference Short Papers.
pp.
275--280 Uppsala,Sweden.55Franz Josef Och, Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Comput.Linguistics 29, 1, 19?51.Haizhou Li , Min Zhang, Jian Su.
2004.
A Joint SourceChannel Model for Machine Transliteration.
InProceedings of the 42nd ACL, pp.
159-166.Kevin Knight, Jonathan Graehl.
1998.
MachineTransliteration.
Computational Linguistics, Vol.
24,No.
4, pp.
599-612.Long Jiang , Ming Zhou , Leefeng Chien and ChengNiu.
Named entity translation with web mining andtransliteration, Proceedings of the 20th internationaljoint conference on Artifical intelligence, p.1629-1634, January 06-12, 2007, Hyderabad, IndiaMin Zhang, Xiangyu Duan, Vladimir Pervouchine, andHaizhou Li.
2010.
Machine transliteration:Leveraging on third languages.
In Coling 2010:Posters, pages 1444?1452, Beijing, China, August.Coling 2010 Organizing Committee.Oi Yee Kwong.
2011.
English-Chinese PersonalName Transliteration by Syllable-Based MaximumMatching.
In the Proceedings of the 2011 NamedEntities Workshop,2011,pp.96-100.Philipp Koehn, Hieu Hoang, Marcello Federico NicolaBertoldi , Brooke Cowan and Wade Shen .
2007.Moses: Open Source Toolkit for Statistical MachineTranslation.
In Proceedings of the 45th ACLCompanion Volume of the Demo and Poster Sessions,pp.
177-180.Yun Huang, Min Zhang and Chewlim Tan.
2011.Nonparametric Bayesian Machine Transliterationwith Synchronous Adaptor Grammars.
InProceedings of ACL-HLT 2011: ShortPapers,Portland, Oregon, pp.534-539.Yuxiang Jia, Danqing Zhu, and Shiwen Y.
2009.
ANoisy Channel Model for Grapheme-based MachineTransliteration, In the Proceedings of the 2009Named Entities Workshop, 2009, pp.
88-91.56
