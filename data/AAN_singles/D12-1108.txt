Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1179?1190, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsDocument-Wide Decoding forPhrase-Based Statistical Machine TranslationChristian Hardmeier Joakim Nivre Jo?rg TiedemannUppsala UniversityDepartment of Linguistics and PhilologyBox 635, 751 26 Uppsala, Swedenfirstname.lastname@lingfil.uu.seAbstractIndependence between sentences is an as-sumption deeply entrenched in the models andalgorithms used for statistical machine trans-lation (SMT), particularly in the popular dy-namic programming beam search decoding al-gorithm.
This restriction is an obstacle to re-search on more sophisticated discourse-levelmodels for SMT.
We propose a stochastic lo-cal search decoding method for phrase-basedSMT, which permits free document-wide de-pendencies in the models.
We explore the sta-bility and the search parameters of this methodand demonstrate that it can be successfullyused to optimise a document-level semanticlanguage model.1 MotivationIn the field of translation studies, it is undisputed thatdiscourse-wide context must be considered care-fully for good translation results (Hatim and Mason,1990).
By contrast, the state of the art in statisticalmachine translation (SMT), despite significant ad-vances in the last twenty years, still assumes thattexts can be translated sentence by sentence understrict independence assumptions, even though it iswell known that certain linguistic phenomena suchas pronominal anaphora cannot be translated cor-rectly without referring to extra-sentential context.This is true both for the phrase-based and the syntax-based approach to SMT.
In the rest of this paper, weshall concentrate on phrase-based SMT.One reason why it is difficult to experimentwith document-wide models for phrase-based SMTis that the dynamic programming (DP) algorithmwhich has been used almost exclusively for decod-ing SMT models in the recent literature has verystrong assumptions of locality built into it.
DPbeam search for phrase-based SMT was describedby Koehn et al(2003), extending earlier work onword-based SMT (Tillmann et al 1997; Och et al2001; Tillmann and Ney, 2003).
This algorithm con-structs output sentences by starting with an emptyhypothesis and adding output words at the end untiltranslations for all source words have been gener-ated.
The core models of phrase-based SMT, in par-ticular the n-gram language model (LM), only de-pend on a constant number of output words to theleft of the word being generated.
This fact is ex-ploited by the search algorithm with a DP techniquecalled hypothesis recombination (Och et al 2001),which permits the elimination of hypotheses fromthe search space if they coincide in a certain numberof final words with a better hypothesis and no futureexpansion can possibly invert the relative ranking ofthe two hypotheses under the given models.
Hypoth-esis recombination achieves a substantial reductionof the search space without affecting search optimal-ity and makes it possible to use aggressive pruningtechniques for fast search while still obtaining goodresults.The downside of this otherwise excellent ap-proach is that it only works well with models thathave a local dependency structure similar to thatof an n-gram language model, so they only de-pend on a small context window for each targetword.
Sentence-local models with longer dependen-cies can be added, but doing so greatly increasesthe risk for search errors by inhibiting hypothesisrecombination.
Cross-sentence dependencies can-not be directly integrated into DP SMT decoding in1179any obvious way, especially if joint optimisation ofa number of interdependent decisions over an entiredocument is required.
Research into models witha more varied, non-local dependency structure is tosome extent stifled by the difficulty of decoding suchmodels effectively, as can be seen by the problemssome researchers encountered when they attemptedto solve discourse-level problems.
Consider, for in-stance, the work on cache-based language modelsby Tiedemann (2010) and Gong et al(2011), whereerror propagation was a serious issue, or the workson pronominal anaphora by Le Nagard and Koehn(2010), who implemented cross-sentence dependen-cies with an ad-hoc two-pass decoding strategy, andHardmeier and Federico (2010) with the use of anexternal decoder driver to manage backward-onlydependencies between sentences.In this paper, we present a method for decodingcomplete documents in phrase-based SMT.
Our de-coder uses a local search approach whose state con-sists of a complete translation of an entire documentat any time.
The initial state is improved by the ap-plication of a series of operations using a hill climb-ing strategy to find a (local) maximum of the scorefunction.
This setup gives us complete freedom todefine scoring functions over the entire document.Moreover, by optionally initialising the state withthe output of a traditional DP decoder, we can en-sure that the final hypothesis is no worse than whatwould have been found by DP search alone.
We startby describing the decoding algorithm and the stateoperations used by our decoder, then we present em-pirical results demonstrating the effectiveness of ourapproach and its usability with a document-level se-mantic language model, and finally we discuss somerelated work.2 SMT Decoding by Hill ClimbingIn this section, we formally describe the phrase-based SMT model implemented by our decoder aswell as the decoding algorithm we use.2.1 SMT ModelOur decoder is based on local search, so its state atany time is a representation of a complete translationof the entire document.
Even though the decoder op-erates at the document level, it is important to keeptrack of sentence boundaries, and the individual op-erations that are applied to the state are still confinedto sentence scope, so it is useful to decompose thestate of a document into the state of its sentences,and we define the overall state S as a sequence ofsentence states:S = S1S2 .
.
.SN , (1)where N is the number of sentences.
This impliesthat we constrain the decoder to emit exactly oneoutput sentence per input sentence.Let i be the number of a sentence and mi the num-ber of input tokens of this sentence, p and q (with1 ?
p ?
q ?
mi) be positions in the input sentenceand [p;q] denote the set of positions from p up to andincluding q.
We say that [p;q] precedes [p?;q?
], or[p;q]?
[p?;q?
], if q < p?.
Let ?i([p;q]) be the set oftranslations for the source phrase covering positions[p;q] in the input sentence i as given by the phrasetable.
We call A = ?[p;q],??
an anchored phrasepair with coverage C(A) = [p;q] if ?
?
?i([p;q]) isa target phrase translating the source words at posi-tions [p;q].
Then a sequence of ni anchored phrasepairsSi = A1A2 .
.
.Ani (2)is a valid sentence state for sentence i if the follow-ing two conditions hold:1.
The coverage sets C(A j) for j in 1, .
.
.
,ni aremutually disjoint, and2.
the anchored phrase pairs jointly cover thecomplete input sentence, orni?j=1C(A j) = [1;mi].
(3)Let f (S) be a scoring function mapping a state Sto a real number.
As usual in SMT, it is assumed thatthe scoring function can be decomposed into a linearcombination of K feature functions hk(S), each witha constant weight ?k, sof (S) =K?k=1?khk(S).
(4)The problem addressed by the decoder is the searchfor the state S?
with maximal score, such thatS?
= argmaxSf (S).
(5)1180The feature functions implemented in our baselinesystem are identical to the ones found in the popularMoses SMT system (Koehn et al 2007).
In particu-lar, our decoder has the following feature functions:1. phrase translation scores provided by thephrase table including forward and backwardconditional probabilities, lexical weights and aphrase penalty (Koehn et al 2003),2. n-gram language model scores implementedwith the KenLM toolkit (Heafield, 2011),3. a word penalty score,4.
a distortion model with geometric decay(Koehn et al 2003), and5.
a feature indicating the number of times a givendistortion limit is exceeded in the current state.In our experiments, the last feature is used with afixed weight of negative infinity in order to limit thegaps between the coverage sets of adjacent anchoredphrase pairs to a maximum value.
In DP search, thedistortion limit is usually enforced directly by thesearch algorithm and is not added as a feature.
Inour decoder, however, this restriction is not requiredto limit complexity, so we decided to add it amongthe scoring models.2.2 Decoding AlgorithmThe decoding algorithm we use (algorithm 1) isvery simple.
It starts with a given initial documentstate.
In the main loop, which extends from line 3to line 12, it generates a successor state S?
for thecurrent state S by calling the function Neighbour,which non-deterministically applies one of the oper-ations described in section 3 of this paper to S. Thescore of the new state is compared to that of the pre-vious one.
If it meets a given acceptance criterion,S?
becomes the current state, else search continuesfrom the previous state S. For the experiments inthis paper, we use the hill climbing acceptance cri-terion, which simply accepts a new state if its scoreis higher than that of the current state.
Other accep-tance criteria are possible and could be used to en-dow the search algorithm with stochastic behaviour.The main loop is repeated until a maximum num-ber of steps (step limit) is reached or until a maxi-mum number of moves are rejected in a row (rejec-tion limit).Algorithm 1 Decoding algorithmInput: an initial document state S;search parameters maxsteps and maxrejectedOutput: a modified document state1: nsteps?
02: nrejected?
03: while nsteps < maxsteps andnrejected < maxrejected do4: S??
Neighbour(S)5: if Accept( f (S?
), f (S)) then6: S?
S?7: nrejected?
08: else9: nrejected?
nrejected+110: end if11: nsteps?
nsteps+112: end while13: return SA notable difference between this algorithm andother hill climbing algorithms that have been usedfor SMT decoding (Germann et al 2004; Langlaiset al 2007) is its non-determinism.
Previous workfor sentence-level decoding employed a steepest as-cent strategy which amounts to enumerating thecomplete neighbourhood of the current state as de-fined by the state operations and selecting the nextstate to be the best state found in the neighbourhoodof the current one.
Enumerating all neighbours ofa given state, costly as it is, has the advantage thatit makes it easy to prove local optimality of a stateby recognising that all possible successor states havelower scores.
It can be rather inefficient, since atevery step only one modification will be adopted;many of the modifications that are discarded willvery likely be generated anew in the next iteration.As we extend the decoder to the document level,the size of the neighbourhood that would have to beexplored in this way increases considerably.
More-over, the inefficiency of the steepest ascent approachpotentially increases as well.
Very likely, a promis-ing move in one sentence will remain promising af-ter a modification has been applied to another sen-1181tence, even though this is not guaranteed to be truein the presence of cross-sentence models.
We there-fore adopt a first-choice hill climbing strategy thatnon-deterministically generates successor states andaccepts the first one that meets the acceptance cri-terion.
This frees us from the necessity of gener-ating the full set of successors for each state.
Onthe downside, if the full successor set is not known,it is no longer possible to prove local optimality of astate, so we are forced to use a different condition forhalting the search.
We use a combination of two lim-its: The step limit is a hard limit on the resources theuser is willing to expend on the search problem.
Thevalue of the rejection limit determines how much ofthe neighbourhood is searched for better successorsbefore a state is accepted as a solution; it is relatedto the probability that a state returned as a solutionis in fact locally optimal.To simplify notations in the description of the in-dividual state operations, we writeSi ??
S?i (6)to signify that a state operation, when presented witha document state as in equation 1 and acting on sen-tence i, returns a new document state ofS?
= S1 .
.
.Si?1 S?i Si+1 .
.
.SN .
(7)Similarly,Si : A j .
.
.A j+h?1 ??
A?1 .
.
.A?h?
(8)is equivalent toSi ??
A1 .
.
.A j?1 A?1 .
.
.A?h?
A j+h .
.
.Ani (9)and indicates that the operation returns a state inwhich a sequence of h consecutive anchored phrasepairs has been replaced by another sequence of h?anchored phrase pairs.2.3 Efficiency ConsiderationsWhen implementing the feature functions for the de-coder, we have to exercise some care to avoid re-computing scores for the whole document at everyiteration.
To achieve this, the scores are computedcompletely only once, at the beginning of the de-coding run.
In subsequent iterations, scoring func-tions are presented with the scores of the previousiteration and a list of modifications produced by thestate operation, a set of tuples ?i,r,s,A?1 .
.
.A?h?
?, eachindicating that the document should be modified asdescribed bySi : Ar .
.
.As ??
A?1 .
.
.A?h?
.
(10)If a feature function is decomposable in some way,as all the standard features developed under the con-straints of DP search are, it can then update the statesimply by subtracting and adding score componentspertaining to the modified parts of the document.Feature functions have the possibility to store theirown state information along with the document stateto make sure the required information is available.Thus, the framework makes it possible to exploit de-composability for efficient scoring without impos-ing any particular decomposition on the features asbeam search does.To make scoring even more efficient, scores arecomputed in two passes: First, every feature func-tion is asked to provide an upper bound on the scorethat will be obtained for the new state.
In somecases, it is possible to calculate reasonable upperbounds much more efficiently than computing theexact feature value.
If the upper bound fails to meetthe acceptance criterion, the new state is discardedright away; if not, the full score is computed and theacceptance criterion is tested again.Among the basic SMT models, this two-passstrategy is only used for the n-gram LM, which re-quires fairly expensive parameter lookups for scor-ing.
The scores of all the other baseline models arefully computed during the first scoring pass.
Then-gram model is more complex.
In its state informa-tion, it keeps track of the LM score and LM librarystate for each word.
The first scoring pass then iden-tifies the words whose LM scores are affected by thecurrent search step.
This includes the words changedby the search operation as well as the words whoseLM history is modified.
The range of the history de-pendencies can be determined precisely by consider-ing the ?valid state length?
information provided bythe KenLM library.
In the first pass, the LM scoresof the affected words are subtracted from the totalscore.
The model only looks up the new LM scoresfor the affected words and updates the total scoreif the new search state passes the first acceptancecheck.
This two-pass scoring approach allows us1182to avoid LM lookups altogether for states that willbe rejected anyhow because of low scores from theother models, e. g. because the distortion limit is vi-olated.Model score updates become more complex andslower as the number of dependencies of a model in-creases.
While our decoding algorithm does not im-pose any formal restrictions on the number or typeof dependencies that can be handled, there will bepractical limits beyond which decoding becomes un-acceptably slow or the scoring code becomes verydifficult to maintain.
These limits are however fairlyindependent of the types of dependencies handledby a model, which permits the exploration of morevaried model types than those handled by DP search.2.4 State InitialisationBefore the hill climbing decoding algorithm can berun, an initial state must be generated.
The closer theinitial state is to an optimum, the less work remainsto be done for the algorithm.
If the algorithm is to beself-contained, initialisation must be relatively unin-formed and can only rely on some general prior as-sumptions about what might be a good initial guess.On the other hand, if optimal results are sought after,it pays off to invest some effort into a good startingpoint.
One way to do this is to run DP search first.For uninformed initialisation, we chose to imple-ment a very simple procedure based only on the ob-servation that, at least for language pairs involvingthe major European languages, it is usually a goodguess to keep the word order of the output very sim-ilar to that of the input.
We therefore create the ini-tial state by selecting, for each sentence in the docu-ment, a sequence of anchored phrase pairs coveringthe input sentence in monotonic order, that is, suchthat for all pairs of adjacent anchored phrase pairsA j and A j+1, we have that C(A j)?C(A j+1).For initialisation with DP search, we first run theMoses decoder (Koehn et al 2007) with defaultsearch parameters and the same models as thoseused by our decoder.
Then we extract the best outputhypothesis from the search graph of the decoder andmap it into a sequence of anchored phrase pairs inthe obvious way.
When the document-level decoderis used with models that are incompatible with beamsearch, Moses can be run with a subset of the mod-els in order to find an approximation of the solutionwhich is then refined with the complete feature set.3 State OperationsGiven a document state S, the decoder uses a neigh-bourhood function Neighbour to simulate a movein the state space.
The neighbourhood function non-deterministically selects a type of state operation anda location in the document to apply it to and returnsthe resulting new state.
We use a set of three opera-tions that has the property that every possible docu-ment state can be reached from every other state ina sequence of moves.Designing operations for state transitions in lo-cal search for phrase-based SMT is a problem thathas been addressed in the literature (Langlais etal., 2007; Arun et al 2010).
Our decoder?s first-choice hill climbing strategy never enumerates thefull neighbourhood of a state.
We therefore placeless emphasis than previous work on defining a com-pact neighbourhood, but allow the decoder to makequite extensive changes to a state in a single stepwith a certain probability.
Otherwise our operationsare similar to those used by Arun et al(2010).All of the operations described in this paper makechanges to a single sentence only.
Each time it iscalled, the Neighbour function selects a sentencein the document with a probability proportional tothe number of input tokens in each sentence to en-sure a fair distribution of the decoder?s attention overthe words in the document regardless of varying sen-tence lengths.3.1 Changing Phrase TranslationsThe change-phrase-translation operation re-places the translation of a single phrase with a ran-dom translation with the same coverage taken fromthe phrase table.
Formally, the operation selects ananchored phrase pair A j by drawing uniformly fromthe elements of Si and then draws a new translation?
?
uniformly from the set ?i(C(A j)).
The new stateis given bySi : A j ??
?C(A j),?
??.
(11)3.2 Changing Word OrderThe swap-phrases operation affects the outputword order without changing the phrase translations.1183It exchanges two anchored phrase pairs A j and A j+h,resulting in an output state ofSi : A j .
.
.A j+h ??
A j+h A j+1 .
.
.A j+h?1 A j.
(12)The start location j is drawn uniformly from the el-igible sentence positions; the swap range h comesfrom a geometric distribution with configurable de-cay.
Other word-order changes such as a one-waymove operation that does not require another move-ment in exchange or more advanced permutationscan easily be defined.3.3 ResegmentationThe most complex operation is resegment, whichallows the decoder to modify the segmentation of thesource phrase.
It takes a number of anchored phrasepairs that form a contiguous block both in the inputand in the output and replaces them with a new setof phrase pairs covering the same span of the inputsentence.
Formally,Si : A j .
.
.A j+h?1 ??
A?1 .
.
.A?h?
(13)such thatj+h?1?j?= jC(A j?)
=h??j?=1C(A?j?)
= [p;q] (14)for some p and q, where, for j?
= 1, .
.
.
,h?, wehave that A?j?
= ?
[p j?
;q j?
],?
j?
?, all [p j?
;q j? ]
are mu-tually disjoint and each ?
j?
is randomly drawn from?i([p j?
;q j?
]).Regardless of the ordering of A j .
.
.A j+h?1, theresegment operation always generates a sequenceof anchored phrase pairs in linear order, such thatC(A?j?
)?C(A?j?+1) for j?
= 1, .
.
.
,h?
?1.As for the other operations, j is generated uni-formly and h is drawn from a geometric distributionwith a decay parameter.
The new segmentation isgenerated by extending the sequence of anchoredphrase pairs with random elements starting at thenext free position, proceeding from left to right untilthe whole range [p;q] is covered.4 Experimental ResultsIn this section, we present the results of a seriesof experiments with our document decoder.
Thegoal of our experiments is to demonstrate the be-haviour of the decoder and characterise its responseto changes in the fundamental search parameters.The SMT models for our experiments were cre-ated with a subset of the training data for theEnglish-French shared task at the WMT 2011 work-shop (Callison-Burch et al 2011).
The phrase ta-ble was trained on Europarl, news-commentary andUN data.
To reduce the training data to a manage-able size, singleton phrase pairs were removed be-fore the phrase scoring step.
Significance-based fil-tering (Johnson et al 2007) was applied to the re-sulting phrase table.
The language model was a 5-gram model with Kneser-Ney smoothing trained onthe monolingual News corpus with IRSTLM (Fed-erico et al 2008).
Feature weights were trained withMinimum Error-Rate Training (MERT) (Och, 2003)on the news-test2008 development set using the DPbeam search decoder and the MERT implementationof the Moses toolkit (Koehn et al 2007).
Experi-mental results are reported for the newstest2009 testset, a corpus of 111 newswire documents totalling2,525 sentences or 65,595 English input tokens.4.1 StabilityAn important difference between our decoder andthe classical DP decoder as well as previous work inSMT decoding with local search is that our decoderis inherently non-deterministic.
This implies that re-peated runs of the decoder with the same search pa-rameters, input and models will not, in general, findthe same local maximum of the score space.
Thefirst empirical question we ask is therefore how dif-ferent the results are under repeated runs.
The re-sults in this and the next section were obtained withrandom state initialisation, i. e. without running theDP beam search decoder.Figure 1 shows the results of 7 decoder runs withthe models described above, translating the news-test2009 test set, with a step limit of 227 and a rejec-tion limit of 100,000.
The x-axis of both plots showsthe number of decoding steps on a logarithmic scale,so the number of steps is doubled between two adja-cent points on the same curve.
In the left plot, they-axis indicates the model score optimised by thedecoder summed over all 2525 sentences of the doc-ument.
In the right plot, the case-sensitive BLEUscore (Papineni et al 2002) of the current decoder1184Figure 1: Score stability in repeated decoder runsstate against a reference translation is displayed.We note, as expected, that the decoder achievesa considerable improvement of the initial state withdiminishing returns as decoding continues.
Be-tween 28 and 214 steps, the score increases at aroughly logarithmic pace, then the curve flattens out,which is partly due to the fact that decoding forsome documents effectively stopped when the max-imum number of rejections was reached.
The BLEUscore curve shows a similar increase, from an initialscore below 5 % to a maximum of around 21.5 %.This is below the score of 22.45 % achieved by thebeam search decoder with the same models, whichis not surprising considering that our decoder ap-proximates a more difficult search problem, fromwhich a number of strong independence assump-tions have been lifted, without, at the moment, hav-ing any stronger models at its disposal to exploit thisadditional freedom for better translation.In terms of stability, there are no dramatic differ-ences between the decoder runs.
Indeed, the smalldifferences that exist are hardly discernible in theplots.
The model scores at the end of the decod-ing run range between ?158767.9 and ?158716.9,a relative difference of only about 0.03 %.
FinalBLEU scores range from 21.41 % to 21.63 %, an in-terval that is not negligible, but comparable to thevariance observed when, e. g., feature weights fromrepeated MERT runs are used with one and the sameSMT system.
Note that these results were obtainedwith random state initialisation.
With DP initialisa-tion, score differences between repeated runs rarelyexceed 0.02 absolute BLEU percentage points.Overall, we conclude that the decoding results ofour algorithm are reasonably stable despite the non-determinism inherent in the procedure.
In our sub-sequent experiments, the evaluation scores reportedare calculated as the mean of three runs for each ex-periment.4.2 Search Algorithm ParametersThe hill climbing algorithm we use has two param-eters which govern the trade-off between decodingtime and the accuracy with which a local maximumis identified: The step limit stops the search pro-cess after a certain number of steps regardless of thesearch progress made or lack thereof.
The rejectionlimit stops the search after a certain number of un-successful attempts to make a step, when continuedsearch does not seem to be promising.
In most of ourexperiments, we used a step limit of 227 ?
1.3 ?
108and a rejection limit of 105.
In practice, decodingterminates by reaching the rejection limit for the vastmajority of documents.
We therefore examined theeffect of different rejection limits on the learningcurves.
The results are shown in figure 2.The results show that continued search does payoff to a certain extent.
Indeed, the curve for re-jection limit 107 seems to indicate that the modelscore increases roughly logarithmically, albeit to ahigher base, even after the curve has started to flat-ten out at 214 steps.
At a certain point, however, theprobability of finding a good successor state dropsrather sharply by about two orders of magnitude, as1185Figure 2: Search performance at different rejection limitsevidenced by the fact that a rejection limit of 106does not give a large improvement over one of 105,while one of 107 does.
The continued model scoreimprovement also results in an increase in BLEUscores, and with a BLEU score of 22.1 % the systemwith rejection limit 107 is fairly close to the score of22.45 % obtained by DP beam search.Obviously, more exact search comes at a cost, andin this case, it comes at a considerable cost, which isan explosion of the time required to decode the testset from 4 minutes at rejection limit 103 to 224 min-utes at rejection limit 105 and 38 hours 45 minutesat limit 107.
The DP decoder takes 31 minutes forthe same task.
We conclude that the rejection limitof 105 selected for our experiments, while techni-cally suboptimal, realises a good trade-off betweendecoding time and accuracy.4.3 A Semantic Document Language ModelIn this section, we present the results of the applica-tion of our decoder to an actual SMT model withcross-sentence features.
Our model addresses theproblem of lexical cohesion.
In particular, it rewardsthe use of semantically related words in the trans-lation output by the decoder, where semantic dis-tance is measured with a word space model basedon Latent Semantic Analysis (LSA).
LSA has beenapplied to semantic language modelling in previousresearch with some success (Coccaro and Jurafsky,1998; Bellegarda, 2000; Wandmacher and Antoine,2007).
In SMT, it has mostly been used for domainadaptation (Kim and Khudanpur, 2004; Tam et al2007), or to measure sentence similarities (Banchsand Costa-jussa`, 2011).The model we use is inspired by Bellegarda(2000).
It is a Markov model, similar to a stan-dard n-gram model, and assigns to each contentword a score given a history of n preceding contentwords, where n = 30 below.
Scoring relies on a 30-dimensional LSA word vector space trained with theS-Space software (Jurgens and Stevens, 2010).
Thescore is defined based on the cosine similarity be-tween the word vector of the predicted word and themean word vector of the words in the history, whichis converted to a probability by histogram lookupas suggested by Bellegarda (2000).
The model isstructurally different from a regular n-gram modelin that word vector n-grams are defined over contentwords occurring in the word vector model only andcan cross sentence boundaries.
Stop words, identi-fied by an extensive stop word list and amounting toaround 60 % of the tokens, are scored by a differentmechanism based on their relative frequency (undis-counted unigram probability) in the training corpus.In sum, the score produced by the semantic docu-ment LM has the following form:h(w|h)=????
?punigr(w) if w is a stop word, else?
pcos(w|h) if w is known, else?
if w is unknown,(15)where ?
is the proportion of content words in thetraining corpus and ?
is a small fixed probability.It is integrated into the decoder as an extra featurefunction.
Since we lack an automatic method for1186training the feature weights of document-wide fea-tures, its weight was selected by grid search overa number of values, comparing translation perfor-mance for the newstest2009 test set.In these experiments, we used DP beam searchto initialise the state of our local search decoder.Three results are presented (table 1): The first tablerow shows the baseline performance using DP beamsearch with standard sentence-local features only.The scores in the second row were obtained by run-ning the hill climbing decoder with DP initialisation,but without adding any models.
A marginal increasein scores for all three test sets demonstrates that thehill climbing decoder manages to fix some of thesearch errors made by the DP search.
The last rowcontains the scores obtained by adding in the seman-tic language model.
Scores are presented for threepublicly available test sets from recent WMT Ma-chine Translation shared tasks, of which one (news-test2009) was used to monitor progress during de-velopment and select the final model.Adding the semantic language model results in asmall increase in NIST scores (Doddington, 2002)for all three test sets as well as a small BLEU scoregain (Papineni et al 2002) for two out of three cor-pora.
We note that the NIST score turned out to re-act more sensitively to improvements due to the se-mantic LM in all our experiments, which is reason-able because the model specifically targets contentwords, which benefit from the information weight-ing done by the NIST score.
While the resultswe present do not constitute compelling evidencein favour of our semantic LM in its current form,they do suggest that this model could be improvedto realise higher gains from cross-sentence seman-tic information.
They support our claim that cross-sentence models should be examined more closelyand that existing methods should be adapted to dealwith them, a problem addressed by our main contri-bution, the local search document decoder.5 Related WorkEven though DP beam search (Koehn et al 2003)has been the dominant approach to SMT decodingin recent years, methods based on local search havebeen explored at various times.
For word-basedSMT, greedy hill-climbing techniques were advo-cated as a faster replacement for beam search (Ger-mann et al 2001; Germann, 2003; Germann et al2004), and a problem formulation specifically tar-geting word reordering with an efficient word re-ordering algorithm has been proposed (Eisner andTromble, 2006).A local search decoder has been advanced as afaster alternative to beam search also for phrase-based SMT (Langlais et al 2007; Langlais et al2008).
That work anticipates many of the featuresfound in our decoder, including the use of localsearch to refine an initial hypothesis produced byDP beam search.
The possibility of using modelsthat do not fit well into the beam search paradigm ismentioned and illustrated with the example of a re-versed n-gram language model, which the authorsclaim would be difficult to implement in a beamsearch decoder.
Similarly to the work by Germannet al(2001), their decoder is deterministic and ex-plores the entire neighbourhood of a state in orderto identify the most promising step.
Our main con-tribution with respect to the work by Langlais et al(2007) is the introduction of the possibility of han-dling document-level models by lifting the assump-tion of sentence independence.
As a consequence,enumerating the entire neighbourhood becomes tooexpensive, which is why we resort to a ?first-choice?strategy that non-deterministically generates statesand accepts the first one encountered that meets theacceptance criterion.More recently, Gibbs sampling was proposed asa way to generate samples from the posterior distri-bution of a phrase-based SMT decoder (Arun et al2009; Arun et al 2010), a process that resembleslocal search in its use of a set of state-modifyingoperators to generate a sequence of decoder states.Where local search seeks for the best state attainablefrom a given initial state, Gibbs sampling producesa representative sample from the posterior.
Like allwork on SMT decoding that we know of, the Gibbssampler presented by Arun et al(2010) assumes in-dependence of sentences and considers the completeneighbourhood of each state before taking a sample.6 ConclusionIn the last twenty years of SMT research, there hasbeen a strong assumption that sentences in a text1187newstest2009 newstest2010 newstest2011BLEU NIST BLEU NIST BLEU NISTDP search only 22.56 6.513 27.27 7.034 24.94 7.170DP + hill climbing 22.60 6.518 27.33 7.046 24.97 7.169with semantic LM 22.71 6.549 27.53 7.087 24.90 7.199Table 1: Experimental results with a cross-sentence semantic language modelare independent of one another, and discourse con-text has been largely neglected.
Several factors havecontributed to this.
Developing good discourse-levelmodels is difficult, and considering the modest trans-lation quality that has long been achieved by SMT,there have been more pressing problems to solve andlower hanging fruit to pick.
However, we argue thatthe popular DP beam search algorithm, which deliv-ers excellent decoding performance, but imposes aparticular kind of local dependency structure on thefeature models, has also had its share in driving re-searchers away from discourse-level problems.In this paper, we have presented a decoding pro-cedure for phrase-based SMT that makes it possi-ble to define feature models with cross-sentence de-pendencies.
Our algorithm can be combined withDP beam search to leverage the quality of the tradi-tional approach with increased flexibility for modelsat the discourse level.
We have presented prelimi-nary results on a cross-sentence semantic languagemodel addressing the problem of lexical cohesion todemonstrate that this kind of models is worth explor-ing further.
Besides lexical cohesion, cross-sentencemodels are relevant for other linguistic phenomenasuch as pronominal anaphora or verb tense selection.We believe that SMT research has reached a point ofmaturity where discourse phenomena should not beignored any longer, and we consider our decoder tobe a step towards this goal.ReferencesAbhishek Arun, Chris Dyer, Barry Haddow, Phil Blun-som, Adam Lopez, and Philipp Koehn.
2009.
Montecarlo inference and maximization for phrase-basedtranslation.
In Proceedings of the Thirteenth Confer-ence on Computational Natural Language Learning(CoNLL-2009), pages 102?110, Boulder, Colorado,June.
Association for Computational Linguistics.Abhishek Arun, Barry Haddow, Philipp Koehn, AdamLopez, Chris Dyer, and Phil Blunsom.
2010.
MonteCarlo techniques for phrase-based translation.
Ma-chine translation, 24(2):103?121.Rafael E. Banchs and Marta R. Costa-jussa`.
2011.
A se-mantic feature for Statistical Machine Translation.
InProceedings of Fifth Workshop on Syntax, Semanticsand Structure in Statistical Translation, pages 126?134, Portland, Oregon, USA, June.
Association forComputational Linguistics.Jerome R. Bellegarda.
2000.
Exploiting latent semanticinformation in statistical language modeling.
Proceed-ings of the IEEE, 88(8):1279?1296.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Omar Zaidan.
2011.
Findings of the 2011 Work-shop on Statistical Machine Translation.
In Proceed-ings of the Sixth Workshop on Statistical MachineTranslation, pages 22?64, Edinburgh, Scotland, July.Association for Computational Linguistics.Noah Coccaro and Daniel Jurafsky.
1998.
Towards bet-ter integration of semantic predictors in statistical lan-guage modeling.
In Proceedings of the 5th Interna-tional Conference on Spoken Language Processing,Sydney.George Doddington.
2002.
Automatic evaluation of ma-chine translation quality using n-gram co-occurrencestatistics.
In Proceedings of the second Interna-tional conference on Human Language TechnologyResearch, pages 138?145, San Diego.Jason Eisner and Roy W. Tromble.
2006.
Local searchwith very large-scale neighborhoods for optimal per-mutations in machine translation.
In Proceedings ofthe HLT-NAACL Workshop on Computationally HardProblems and Joint Inference in Speech and LanguageProcessing, pages 57?75.Marcello Federico, Nicola Bertoldi, and Mauro Cettolo.2008.
IRSTLM: an open source toolkit for handlinglarge scale language models.
In Interspeech 2008,pages 1618?1621.
ISCA.Ulrich Germann, Michael Jahr, Kevin Knight, DanielMarcu, and Kenji Yamada.
2001.
Fast decoding andoptimal decoding for machine translation.
In Proceed-ings of 39th Annual Meeting of the Association forComputational Linguistics, pages 228?235, Toulouse,France, July.
Association for Computational Linguis-tics.1188Ulrich Germann, Michael Jahr, Kevin Knight, DanielMarcu, and Kenji Yamada.
2004.
Fast and optimal de-coding for machine translation.
Artificial Intelligence,154(1?2):127?143.Ulrich Germann.
2003.
Greedy decoding for Statis-tical Machine Translation in almost linear time.
InProceedings of the 2003 Human Language Technol-ogy Conference of the North American Chapter of theAssociation for Computational Linguistics.Zhengxian Gong, Min Zhang, and Guodong Zhou.2011.
Cache-based document-level Statistical Ma-chine Translation.
In Proceedings of the 2011 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 909?919, Edinburgh, Scotland, UK.,July.
Association for Computational Linguistics.Christian Hardmeier and Marcello Federico.
2010.
Mod-elling Pronominal Anaphora in Statistical MachineTranslation.
In Proceedings of the seventh Inter-national Workshop on Spoken Language Translation(IWSLT), pages 283?289.Basil Hatim and Ian Mason.
1990.
Discourse and theTranslator.
Language in Social Life Series.
Longman,London.Kenneth Heafield.
2011.
KenLM: faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197, Edinburgh, Scotland, July.
Association forComputational Linguistics.Howard Johnson, Joel Martin, George Foster, and RolandKuhn.
2007.
Improving translation quality by dis-carding most of the phrasetable.
In Proceedings of the2007 Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Natu-ral Language Learning (EMNLP-CoNLL), pages 967?975, Prague, Czech Republic, June.
Association forComputational Linguistics.David Jurgens and Keith Stevens.
2010.
The S-Spacepackage: An open source package for word spacemodels.
In Proceedings of the ACL 2010 SystemDemonstrations, pages 30?35, Uppsala, Sweden, July.Association for Computational Linguistics.Woosung Kim and Sanjeev Khudanpur.
2004.
Cross-lingual latent semantic analysis for language model-ing.
In IEEE international conference on acoustics,speech, and signal processing (ICASSP), volume 1,pages 257?260, Montre?al.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 conference of the North Ameri-can chapter of the Association for Computational Lin-guistics on Human Language Technology, pages 48?54, Edmonton.Philipp Koehn, Hieu Hoang, Alexandra Birch, et al2007.
Moses: open source toolkit for Statistical Ma-chine Translation.
In Annual meeting of the Associ-ation for Computational Linguistics: Demonstrationsession, pages 177?180, Prague.Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.2007.
A greedy decoder for phrase-based statisticalmachine translation.
In TMI-2007: Proceedings ofthe 11th International Conference on Theoretical andMethodological Issues in Machine Translation, pages104?113, Sko?vde.Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.2008.
Recherche locale pour la traduction statistiquepar segments.
In TALN 2008, pages 119?128, Avi-gnon, France, June.
ATALA.Ronan Le Nagard and Philipp Koehn.
2010.
Aiding pro-noun translation with co-reference resolution.
In Pro-ceedings of the Joint Fifth Workshop on Statistical Ma-chine Translation and MetricsMATR, pages 252?261,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Franz Josef Och, Nicola Ueffing, and Hermann Ney.2001.
An efficient A* search algorithm for Statisti-cal Machine Translation.
In Proceedings of the Data-Driven Machine Translation Workshop, 39th AnnualMeeting of the Association for Computational Linguis-tics (ACL), pages 55?62, Toulouse.Franz Josef Och.
2003.
Minimum error rate training inStatistical Machine Translation.
In Proceedings of the41st annual meeting of the Association for Computa-tional Linguistics, pages 160?167, Sapporo (Japan).Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of Machine Translation.
In Proceedings of the40th annual meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia.
ACL.Yik-Cheung Tam, Ian Lane, and Tanja Schultz.
2007.Bilingual LSA-based adaptation for Statistical Ma-chine Translation.
Machine Translation, 21(4):187?207.Jo?rg Tiedemann.
2010.
To cache or not to cache?
Ex-periments with adaptive models in Statistical MachineTranslation.
In Proceedings of the ACL 2010 JointFifth Workshop on Statistical Machine Translation andMetrics MATR, pages 189?194, Uppsala, Sweden.
As-sociation for Computational Linguistics.Christoph Tillmann and Hermann Ney.
2003.
Word re-ordering and a Dynamic Programming beam search al-gorithm for Statistical Machine Translation.
Compu-tational linguistics, 29(1):97?133.Christoph Tillmann, Stephan Vogel, Hermann Ney, andAlex Zubiaga.
1997.
A DP-based search using mono-tone alignments in Statistical Translation.
In Proceed-ings of the 35th Annual Meeting of the Association for1189Computational Linguistics, pages 289?296, Madrid,Spain, July.
Association for Computational Linguis-tics.Tonio Wandmacher and Jean-Yves Antoine.
2007.Methods to integrate a language model with seman-tic information for a word prediction component.
InProceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 506?513, Prague, Czech Republic,June.
Association for Computational Linguistics.1190
