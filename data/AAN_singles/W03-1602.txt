Text Simplification for Reading Assistance: A Project NoteKentaro Inui Atsushi Fujita Tetsuro Takahashi Ryu IidaNara Advanced Institute of Science and TechnologyTakayama, Ikoma, Nara, 630-0192, Japanfinui,atsush-f,tetsu-ta,ryu-ig@is.aist-nara.ac.jpTomoya IwakuraFujitsu Laboratories Ltd.Kamikodanaka, Nakahara, Kawasaki, Kanagawa, 211-8588, Japaniwakura.tomoya@jp.fujitsu.comAbstractThis paper describes our ongoing researchproject on text simplification for congenitallydeaf people.
Text simplification we are aimingat is the task of offering a deaf reader a syn-tactic and lexical paraphrase of a given text forassisting her/him to understand what it means.In this paper, we discuss the issues we shouldaddress to realize text simplification and re-port on the present results in three differentaspects of this task: readability assessment,paraphrase representation and post-transfer er-ror detection.1 IntroductionThis paper reports on our ongoing research intotext simplification for reading assistance.
Potentialusers targeted in this research are congenitally deafpeople (more specifically, students at (junior-)highschools for the deaf), who tend to have difficultiesin reading and writing text.
We are aiming at thedevelopment of the technology of text simplificationwith which a reading assistance system lexically andstructurally paraphrases a given text into a simplerand plainer one that is thus more comprehensible.The idea of using paraphrases for reading as-sistance is not necessarily novel.
For example,Carroll et al (1998) and Canning and Taito (1999)report on their project in which they address syn-tactic transforms aiming at making newspaper textaccessible to aphasics.
Following this trend of re-search, in this project, we address four unexploredissues as below besides the user- and task-orientedevaluation of the overall system.Before going to the detail, we first clarify the fourissues we have addressed in the next section.
Wethen reported on the present results on three of thefour, readability assessment, paraphrase representa-tion and post-transfer error detection, in the subse-quent sections.2 Research issues and our approach2.1 Readability assessmentThe process of text simplification for reading as-sistance can be decomposed into the following threesubprocesses:a.
Problem identification: identify which portions ofa given text will be difficult for a given user toread,b.
Paraphrase generation: generate possible candi-date paraphrases from the identified portions, andc.
Evaluation: re-assess the resultant texts to choosethe one in which the problems have been resolved.Given this decomposition, it is clear that one of thekey issues in reading assistance is the problem of as-sessing the readability or comprehensibility1 of textbecause it is involved in subprocesses (a) and (c).Readability assessment is doubtlessly a tough is-sue (Williams et al, 2003).
In this project, however,we argue that, if one targets only a particular popu-lation segment and if an adequate collection of datais available, then corpus-based empirical approachesmay well be feasible.
We have already proven thatone can collect such readability assessment data byconducting survey questionnaires targeting teachersat schools for the deaf.1In this paper, we use the terms readability and comprehen-sibility interchangeably, while strictly distinguishing them fromlegibility of each fragment (typically, a sentence or paragraph)of a given text.2.2 Paraphrase acquisitionOne of the good findings that we obtained throughthe aforementioned surveys is that there are a broadrange of paraphrases that can improve the readabil-ity of text.
A reading assistance system is, therefore,hoped to be able to generate sufficient varieties ofparaphrases of a given input.
To create such a sys-tem, one needs to feed it with a large collection ofparaphrase patterns.
Very timely, the acquisition ofparaphrase patterns has been actively studied in re-cent years: Manual collection of paraphrases in the context oflanguage generation, e.g.
(Robin and McKeown,1996), Derivation of paraphrases through existing lexicalresources, e.g.
(Kurohashi et al, 1999), Corpus-based statistical methods inspired by thework on information extraction, e.g.
(Jacquemin,1999; Lin and Pantel, 2001), and Alignment-based acquisition of paraphrases fromcomparable corpora, e.g.
(Barzilay and McKe-own, 2001; Shinyama et al, 2002; Barzilay andLee, 2003).One remaining issue is how effectively these meth-ods contribute to the generation of paraphrases in ourapplication-oriented context.2.3 Paraphrase representationOne of the findings obtained in the previous stud-ies for paraphrase acquisition is that the automaticacquisition of candidates of paraphrases is quite re-alizable for various types of source data but acquiredcollections tend to be rather noisy and need manualcleaning as reported in, for example, (Lin and Pan-tel, 2001).
Given that, it turns out to be important todevise an effective way of facilitating manual correc-tion and a standardized scheme for representing andstoring paraphrase patterns as shared resources.Our approach is (a) to define first a fully express-ible formalism for representing paraphrases at thelevel of tree-to-tree transformation and (b) devise anadditional layer of representation on its top that is de-signed to facilitate handcoding transformation rules.2.4 Post-transfer text revisionIn paraphrasing, the morpho-syntactic informa-tion of a source sentence should be accessiblethroughout the transfer process since a morpho-syntactic transformation in itself can often be a mo-tivation or goal of paraphrasing.
Therefore, suchan approach as semantic transfer, where morpho-syntactic information is highly abstracted away asin (Dorna et al, 1998; Richardson et al, 2001),does not suit this task.
Provided that the morpho-syntactic stratum be an optimal level of abstractionfor representing paraphrasing/transfer patterns, onemust recall that semantic-transfer approaches such asthose cited above were motivated mainly by the needfor reducing the complexity of transfer knowledge,which could be unmanageable in morpho-syntactictransfer.Our approach to this problem is to (a) leave the de-scription of each transfer pattern underspecified and(b) implement the knowledge about linguistic con-straints that are independent of a particular trans-fer pattern separately from the transfer knowledge.There are a wide range of such transfer-independentlinguistic constraints.
Constraints on morphemeconnectivity, verb conjugation, word collocation,and tense and aspect forms in relative clauses are typ-ical examples of such constraints.These four issues can be considered as differentaspects of the overall question how one can makethe development and maintenance of a gigantic re-source for paraphrasing tractable.
(1) The introduc-tion of readability assessment would free us fromcares about the purposiveness of each paraphrasingrule in paraphrase acquisition.
(2) Paraphrase ac-quisition is obviously indispensable for scaling upthe resource.
(3) A good formalism for representingparaphrasing rules would facilitate the manual re-finement and maintenance of them.
(4) Post-transfererror detection and revision would make the systemtolerant to flows in paraphrasing rules.While many researchers have addressed the issueof paraphrase acquisition reporting promising resultsas cited above, the other three issues have been leftrelatively unexplored in spite of their significance inthe above sense.
Motivated by this context, in therest of this paper, we address these remaining three.3 Readability assessmentTo the best of our knowledge, there have neverbeen no reports on research to build a computationalmodel of the language proficiency of deaf people, ex-cept for the remarkable reports by Michaud and Mc-Coy (2001).
As a subpart of their research aimed atdeveloping the ICICLE system (McCoy and Master-man, 1997), a language-tutoring application for deaflearners of written English, Michaud and McCoy de-veloped an architecture for modeling the writing pro-ficiency of a user called SLALOM.
SLALOM is de-signed to capture the stereotypic linear order of ac-quisition within certain categories of morphologicaland/or syntactic features of language.
Unfortunately,the modeling method used in SLALOM cannot bedirectly applied to our domain for three reasons. Unlike writing tutoring, in reading assistance, tar-get sentences are in principle unlimited.
Wetherefore need to take a wider range of morpho-syntactic features into account. SLALOM is not designed to capture the difficultyof any combination of morpho-syntactic features,which it is essential to take into account in readingassistance. Given the need to consider feature combinations,a simple linear order model that is assumed inSLALOM is unsuitable.3.1 Our approach: We ask teachersTo overcome these deficiencies, we took yet an-other approach where we designed a survey ques-tionnaire targeting teachers at schools for the deaf,and have been collecting readability assessment data.In this questionnaire, we ask the teachers to comparethe readability of a given sentence with paraphrasesof it.
The use of paraphrases is of critical importancein our questionnaire since it makes manual readabil-ity assessment significantly easier and more reliable.3.1.1 TargetsWe targeted teachers of Japanese or English liter-acy at schools for the deaf for the following reasons.Ideally, this sort of survey would be carried outby targeting the population segment in question, i.e.,deaf students in our study.
In fact, pedagogists andpsycholinguists have made tremendous efforts to ex-amine the language proficiency of deaf students bygiving them proficiency tests.
Such efforts are veryimportant, but they have had difficulty in capturingenough of the picture to develop a comprehensiveand implementable reading proficiency model of thepopulation due to the expense of extensive languageproficiency testing.In contrast, our approach is an attempt to modelthe knowledge of experts in this field (i.e., teachingdeaf students).
The targeted teachers have not onlyrich experiential knowledge about the language pro-ficiency of their students but are also highly skilled inparaphrasing to help their students?
comprehension.Since such knowledge gleaned from individual ex-periences already has some generality, extracting itthrough a survey should be less costly and thus morecomprehensive than investigation based on languageproficiency testing.3.1.2 QuestionnaireIn the questionnaire, each question consists of sev-eral paraphrases, as shown in Figure 1 (a), where(A) is a source sentence, and (B) and (C) are para-phrases of (A).
Each respondent was asked to as-sess the relative readability of the paraphrases givenfor each source sentence, as shown in Figure 1 (b).The respondent judged sentence (A) to be the mostdifficult and judged (B) and (C) to be comparable.A judgment that sentence siis easier than sentencesjmeans that siis judged likely to be understoodby a larger subset of students than sj.
We askedthe respondents to annotate the paraphrases withformat-free comments, giving the reasons for theirjudgments, alternative paraphrases, etc., as shown inFigure 1 (b).To make our questionnaire efficient for model ac-quisition, we had to carefully control the variation inparaphrases.
To do that, we first selected around 50morpho-syntactic features that are considered influ-ential in sentence readability for deaf people.
Foreach of those features, we collected several sim-ple example sentences from various sources (literacytextbooks, grammar references, etc.).
We then man-ually produced several paraphrases from each of thecollected sentences so as to remove the feature thatcharacterized the source sentence from each para-phrase.
For example, in Figure 1, the feature char-acterizing sentence (A) is a non-restrictive relativeclause (i.e., sentence (A) was selected as an exampleof this feature).
Neither (B) nor (C) has this feature.We also controlled the lexical variety to minimizethe effect of lexical factors on readability; we alsorestricted the vocabulary to a top-2000 basic wordset (NIJL, 1991).3.1.3 AdministrationWe administrated a preliminary survey targetingthree teachers.
Through the survey, we observed that(a) the teachers largely agreed in their assessments ofrelative readability, (b) their format-free commentsindicated that the observed differences in readabil-ity were largely explainable in terms of the morpho-syntactic features we had prepared, and (c) a larger-scaled survey was needed to obtain a statistically re-liable model.
Based on these observations, we con-ducted a more comprehensive survey, in which weprepared 770 questions and sent questionnaires witha random set of 240 of them to teachers of Japaneseor English literacy at 50 schools for the deaf.
WeFigure 1: Sample question and responseasked them to evaluate as many as possible anony-mously.
We obtained 4080 responses in total (8.0responses per question).3.2 Readability ranking modelThe task of ranking a set of paraphrases can be de-composed into comparisons between two elementscombinatorially selected from the set.
We considerthe problem of judging which of a given pair of para-phrase sentences is more readable/comprehensiblefor deaf students.
More specifically, given para-phrase pair (si; sj), our problem is to classify it intoeither left (siis easier), right (sjis easier), or com-parable (siand sjare comparable).Once the problem is formulated this way, we canuse various existing techniques for classifier learn-ing.
So far, we have examined a method of using thesupport vector machine (SVM) classification tech-nique.A training/testing example is paraphrase pair(si; sj) coupled with its quantified class labelD(si; sj) 2 [ 1; 1].
Each sentence siis character-ized by a binary feature vector Fsi, and each pair(si; sj) is characterized by a triple of feature vectorshFCsisj; FLsisj; FRsisji, where FCsisj= Fsi^ Fsj(features shared by siand sj), FLsisj= Fsi^Fsj(features belonging only to si), FRsisj= Fsi^Fsj(features belonging only to sj).D(si; sj) represents the difference in readability be-tween siand sj; it is computed in the following way.1.
Let Tsisjbe the set of respondents who assessed(si; sj).2.
Given the degree of readability respondent t as-signed to si(sj), map it to real value dor(t; s) 2[0; 1] so that the lowest degree maps to 0 and thehighest degree maps to 1.
For example, the de-gree of readability assigned to (A) in Figure 1 (b)maps to around 0.1, whereas that assigned to (B)maps to around 0.9.3.
D(si; sj) =1jTsisjjPt2Tsisjdor(t; si)  dor(t; sj):Output score ScM(si; sj) 2 [ 1; 1] for input(si; sj) was given by the normalized distance be-tween (si; sj) and the hyperplane.3.3 Evaluation and discussionTo evaluate the two modeling methods, we con-ducted a ten-fold cross validation on the set of 4055paraphrase pairs derived from the 770 questions usedin the survey.
To create a feature vector space, weused 355 morpho-syntactic features.
Feature annota-tion was done semi-automatically with the help of amorphological analyzer and dependency parser.The task was to classify a given paraphrase pairinto either left, right, or comparable.
Model M ?soutput class for (si; sj) was given byClsM(si; sj) =(left (ScM(si; sj)   m)right (ScM(si; sj)  m)comparable (otherwise);where m2 [ 1; 1] is a variable threshold used tobalance precision with recall.We used the 473 paraphrase pairs that satisfied thefollowing conditions: jD(si; sj)j was not less than threshold a(a=0:5).
The answer of (si; sj) is given byClsAns(si; sj) =nleft (D(si; sj)   a)right (D(si; sj)  a) : (si; sj) must have been assessed by more then onerespondent, i.e., jTsisjj > 1: Agreement ratio Agr(si; sj) must be suffi-ciently high, i.e., Agr(si; sj)  0:9, whereAgr(si; sj) = (for (si; sj)   agst(si; sj))=jTsisjj, and for (si; sj) and agst(si; sj) are thenumber of respondents who agreed and disagreedwith ClsAns(si; sj), respectively.We judged output class ClsM(si; sj) correct if andonly if ClsM(si; sj) = ClsAns(si; sj).
The overallperformance was evaluated based on recall Rc andprecision Pr:Rc =jf(si;sj)j ClsM(si; sj) is correctgjjf(si;sj)j ClsAns(si;sj)2fleft;rightggjPr =jf(si;sj)j ClsM(si; sj) is correctgjjf(si;sj)j ClsM(si;sj)2fleft;rightgj.The model achieved 95% precision with 89% re-call.
This result confirmed that the data we collectedthrough the questionnaires were reasonably noiselessand thus generalizable.
Furthermore, both modelsexhibited a clear trade-off between recall and preci-sion, indicating that their output scores can be usedas a confidence measure.4 Paraphrase representationWe represent paraphrases as transfer patterns be-tween dependency trees.
In this section, we proposea three-layered formalism for representing transferpatterns.4.1 Types of paraphrases of concernThere are various levels of paraphrases as the fol-lowing examples demonstrate:(1) a.
She burst into tears, and he tried to comforther.b.
She cried, and he tried to console her.
(2) a.
It was a Honda that John sold to Tom.b.
John sold a Honda to Tom.c.
Tom bought a Honda from John.
(3) a.
They got married three years ago.b.
They got married in 2000.Lexical vs. structural paraphrases Example (1)includes paraphrases of the single word ?comfort?and the canned phrase ?burst into tears?.
The sen-tences in (2), on the other hand, exhibit structuraland thus more general patterns of paraphrasing.
Bothtypes of paraphrases, lexical and structural para-phrases, are considered useful for many applicationsincluding reading assistance and thus should be inthe scope our discussion.Atomic vs. compositional paraphrases The pro-cess of paraphrasing (2a) into (2c) is compositionalbecause it can be decomposed into two subpro-cesses, (2a) to (2b) and (2b) to (2c).
In develop-ing a resource for paraphrasing, we have only tocover non-compositional (i.e., atomic) paraphrases.Compositional paraphrases can be handled if an ad-ditional computational mechanism for combiningatomic paraphrases is devised.Meaning-preserving vs. reference-preservingparaphrases It is also useful to distinguishreference-preserving paraphrases from meaning-preserving ones.
The above example in (3) is of thereference-preserving type.
This types of paraphras-ing requires the computation of reference to objectsoutside discourse and thus should be excluded fromour scope for the present purpose.4.2 Dependency trees (MDSs)Previous work on transfer-based machine transla-tion (MT) suggests that the dependency-based repre-sentation has the advantage of facilitating syntactictransforming operations (Meyers et al, 1996; Lavoieet al, 2000).
Following this, we adopt dependencytrees as the internal representations of target texts.We suppose that a dependency tree consists of a setof nodes each of which corresponds to a lexeme orcompound and a set of edges each of which repre-sents the dependency relation between its ends.
Wecall such a dependency tree a morpheme-based de-pendency structure (MDS).
Each node in an MDS issupposed to be annotated with an open set of typedfeatures that indicate morpho-syntactic and semanticinformation.
We also assume a type hierarchy in de-pendency relations that consists of an open set of de-pendency classes including dependency, compound,parallel, appositive and insertion.4.3 Three-layered representationPrevious work on transfer-based MT sys-tems (Lavoie et al, 2000; Dorna et al, 1998)and alignment-based transfer knowledge acqui-sition (Meyers et al, 1996; Richardson et al,2001) have proven that transfer knowledge can bebest represented by declarative structure mapping(transforming) rules each of which typically consistsof a pair of source and target partial structures as inthe middle of Figure 2.Adopting such a tree-to-tree style of representa-tion, however, one has to address the issue of thetrade-off between expressibility and comprehensi-bility.
One may want a formalism of structuralrule editingtranslationcompilationsimplified MDS transfer ruleN shika V- nai  ->  V no wa N dake da.
(someone does not V to nothing but N)   (it is only to N that someone does V)MDS transfer rulesp_rule(108, negation, RefNode) :-match(RefNode, X4=[pos:postp,lex: shika]),depend(X3=[pos:verb], empty, X4),depend(X1=[pos:aux_verb,lex: nai],X2=[pos:aux_verb*], X3),depend(X4, empty, X5=[pos:noun]),replace(X1, X6=[pos:aux_verb,lex: da]),substitute(X5, X12=[pos:noun]),move_dtrs(X5, X12),substitute(X3, X10=[pos:verb]),:pos: postplex: shika (except)pos: aux_verblex:  da (copula)pos: postplex: wa (TOP)X6X11X12pos: nounlex:  no (thing)pos: postplex: dake (only)pos: nounpos: nounaux_verb*pos: aux_verblex: nai (not)pos: verbX3X4X1X5X2 X7X8X10 pos: verbX9 vwsMDS processing operators(=X5)(=X2)(=X3)Figure 2: Three-layered rule representationtransformation patterns that is powerful enough torepresent a sufficiently broad range of paraphrasepatterns.
However, highly expressible formalismswould make it difficult to create and maintain rulesmanually.To mediate this trade-off, we devised a new layerof representation to add on the top of the layer oftree-to-tree pattern representation as illustrated inFigure 2.
At this new layer, we use an extended natu-ral language to specify transformation patterns.
Thelanguage is designed to facilitate the task of hand-coding transformation rules.
For example, to definethe tree-to-tree transformation pattern given in themiddle of Figure 2, a rule editor needs only to spec-ify its simplified form:(4) N shika V- nai !
V no ha N dake da.
(Someone does V to nothing but N !
It is only toN that someone does V)A rule of this form is then automatically translatedinto a fully-specified tree-to-tree transformation rule.We call a rule of the latter form an MDS rewritingrule (SR rule), and a rule of the former form a sim-plified SR rule (SSR rule).The idea is that most of the specifications of an SRrule can usually be abbreviated if a means to auto-matically complement it is provided.
We use a parserand macros to do so; namely, the rule translator com-plements an SSR rule by macro expansion and pars-ing to produce the corresponding SR rule specifica-tions.
The advantages of introducing the SSR rulelayer are the following: The SSR rule formalism allows a rule writer toedit rules with an ordinary text editor, whichmakes the task of rule editing much more efficientthan providing her/him with a GUI-based com-plex tool for editing SR rules directly. The use of the extended natural language alsohas the advantage in improving the readability ofrules for rule writers, which is particularly impor-tant in group work. To parse SSR rules, one can use the same parseras that used to parse input texts.
This also im-proves the efficiency of rule development becauseit significantly reduces the burden of maintainingthe consistency between the POS-tag set used forparsing input and that used for rule specifications.The SSR rule layer shares underlying motiva-tions with the formalism reported by Hermjakob etal.
(2002).
Our formalism is, however, considerablyextended so as to be licensed by the expressibility ofthe SR rule representation and to be annotated withvarious types of rule applicability conditions includ-ing constraints on arbitrary features of nodes, struc-tural constraints, logical specifications such as dis-junction and negation, closures of dependency rela-tions, optional constituents, etc.The two layers for paraphrase representationare fully implemented on our paraphrasing engineKURA (Takahashi et al, 2001) coupled with anotherlayer for processing MDSs (the bottom layer illus-trated in Figure 2).
The whole system of KURAand part of the transer rules implemented on it(see Section 5 below) are available at http://cl.aist-nara.ac.jp/lab/kura/doc/.5 Post-transfer error detectionWhat kinds of transfer errors tend to occur in lex-ical and structural paraphrasing?
To find it out, weconducted a preliminary investigation.
This sectionreports a summary of the results.
See (Fujita andInui, 2002) for further details.We implemented over 28,000 transfer rules forJapanese paraphrases on the KURA paraphrasing en-gine based on the rules previously reported in (Sato,1999; Kondo et al, 1999; Kondo et al, 2001; Iida etal., 2001) and existing lexical resources such as the-sauri and case frame dictionaries.
The implementedrules ranged from such lexical paraphrases as thosethat replace a word with its synonym to such syn-tactic/structural paraphrases as those that remove acleft construction from a sentence, devide a sentence,etc.
We then fed KURA with a set of 1,220 sentencesrandomly sampled from newspaper articles and ob-tained 630 transferred output sentences.The following are the tendencies we observed: The transfer errors observed in the experiment ex-hibited a wide range of variety from morphologi-cal errors to semantic and discourse-related ones. Most types of errors tended to occur regardlessof the types of transfer.
This suggests that if onecreates an error detection module specialized fora particular error type, it works across differenttypes of transfer. The most frequent error type involved inappropri-ate conjugation forms of verbs.
It is, however,a matter of morphological generation and can beeasily resolved. Errors in regard to verb valency and selectionalrestriction also tended to be frequent and fatal,and thus should have preference as a researchtopic. The next frequent error type was related to thedifference of meaning between near synonyms.However, this type of errors could often be de-tected by a model that could detect errors of verbvalency and selectional restriction.Based on these observations, we concluded thatthe detection of incorrect verb valences and verb-complement cooccurrence was one of the most se-rious problems that should have preference as a re-search topic.
We are now conducting experimentson empirical methods for detecting this type of er-rors (Fujita et al, 2003).6 ConclusionThis paper reported on the present results of ourongoing research on text simplification for readingassistance targeting congenitally deaf people.
Weraised four interrelated issues that we needed addressto realize this application and presented our previ-ous activities focuing on three of them: readabil-ity assessment, paraphrase representation and post-transfer error detection.Regarding readability assessment, we proposed anovel approach in which we conducted questionnairesurveys to collect readability assessment data andtook a corpus-based empirical method to obtain areadability ranking model.
The results of the sur-veys show the potential impact of text simplificationon reading assistance.
We conducted experiments onthe task of comparing the readability of a given para-phrase pair and obtained promising results by SVM-based classifier induction (95% precision with 89%recall).
Our approach should be equally applicableto other population segments such as aphasic read-ers and second-language learners.
Our next stepsincludes the investigation of the drawbacks of thepresent bag-of-features modeling approach.
We alsoneed to consider a method to introduce the notionof user classes (e.g.
beginner, intermediate and ad-vanced).
Textual aspects of readability will also needto be considered, as discussed in (Inui and Nogami,2001; Siddahrthan, 2003).Regarding paraphrase representation, we pre-sented our revision-based lexico-structural para-phrasing engine.
It provides a fully expressiblescheme for representating paraphrases, while pre-serving the easiness of handcraft paraphrasing rulesby providing an extended natural language as ameans of pattern editting.
We have handcrafted overa thousand transfer rules that implement a broadrange of lexical and structural paraphrasing.The problem of error detection is also critical.When we find a effective solution to it, we will beready to integrate the technologies into an applica-tion system of text simplification and conduct user-and task-oriented evaluations.AcknowledgmentsThe research presented in this paper was partlyfunded by PREST, Japan Science and TechnologyCorporation.
We thank all the teachers at the schoolsfor the deaf who cooperated in our questionnaire sur-vey and Toshihiro Agatsuma (Joetsu University ofEducation) for his generous and valuable coopera-tion in the survey.
We also thank Yuji Matsumotoand his colleagues (Nara Advanced Institute of Sci-ence and Technology) for allowing us to use theirNLP tools ChaSen and CaboCha, Taku Kudo (NaraAdvanced Institute of Science and Technology) forallowing us to use his SVM tool, and Takaki Makinoand his colleagues (Tokyo University) for allow-ing us to use LiLFeS, with which we implementedKURA.
We also thank the anonymous reviewers fortheir suggestive and encouraging comments.ReferencesBarzilay, R. and McKeown, K. 2001.
Extracting para-phrases from a parallel corpus.
In Proc.
of the 39th An-nual Meeting and the 10th Conference of the EuropeanChapter of Association for Computational Linguistics(EACL), pages 50?57.Barzilay, R. and Lee, L. 2003.
Learning to paraphrases: anunsupervised approach using multiple-sequence align-ment.
In Proc.
of HLT-NAACL.Canning, Y. and Taito, J.
1999.
Syntactic simplification ofnewspaper text for aphasic readers.
In Proc.
of the 22ndAnnual International ACM SIGIR Conference (SIGIR).Carroll, J., Minnen, G., Canning, Y., Devlin, S. and Tait, J.1998.
Practical simplification of English newspapertext to assist aphasic readers.
In Proc.
of AAAI-98Workshop on Integrating Artificial Intelligence and As-sistive Technology.Dorna, M., Frank, A., Genabith, J. and Emele, M. 1998.Syntactic and semantic transfer with F-structures.
InProc.
of COLING-ACL, pages 341?347.Fujita, A. and Inui, K. 2002.
Decomposing linguisticknowledge for lexical paraphrasing.
In InformationProcessing Society of Japan SIG Technical Reports,NL-149, pages 31?38.
(in Japanese)Fujita, A., Inui, K. and Matsumoto, Y.
2003.
Automaticdetection of verb valency errors in paraphrasing.
In In-formation Processing Society of Japan SIG TechnicalReports, NL-156.
(in Japanese)Hermjakob, U., Echihabi, A. and Marcu, D. 2002.
Nat-ural language based reformulation resource and Webexploitation for question answering.
In Proc.
of theTREC-2002 Conference.Iida, R., Tokunaga, Y., Inui, K. and Eto, J.
2001.
Explo-ration of clause-structural and function-expressionalparaphrasing using KURA.
In Proc.
of the 63th AnnualMeeting of Information Processing Society of Japan,pages 5?6.
(in Japanese).Inui, K. and Nogami, M. 2001.
A paraphrase-based explo-ration of cohesiveness criteria.
In Proc.
of the EighthEuropean Workshop on Natulan Language Generation,pages 101?110.Jacquemin, C. 1999.
Syntagmatic and paradigmatic rep-resentations of term variations.
In Proc.
of the 37thAnnual Meeting of the Association for ComputationalLinguistics (ACL), pages 341?349.Kondo, K., Sato, S. and Okumura, M. 1999.
Paraphras-ing of ?sahen-noun + suru?.
Journal of InformationProcessing Society of Japan, 40(11):4064?4074.
(inJapanese).Kondo, K., Sato, S. and Okumura, M. 2001.
Para-phrasing by case alternation.
Journal of Informa-tion Processing Society of Japan, 42(3):465?477.
(inJapanese).Kurohashi, S. and Sakai, Y.
1999.
Semantic analysis ofJapanese noun phrases: a new approach to dictionary-based understanding.
In Proc.
of the 37th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 481?488.Lavoie, B. Kittredge, R. Korelsky, T. Rambow, O.
2000.A framework for MT and multilingual NLG ystemsbased on uniform lexico-structural processing.
In Proc.of ANLP-NAACL.Lin, D. and Pantel, P. 2001.
Discovery of inference rulesfor question-answering.
Natural Language Engineer-ing, 7(4):343?360.McCoy ,K. F. and Masterman (Michaud), L. N. 1997.
ATutor for Teaching English as a Second Language forDeaf Users of American Sign Language, In Proc.
ofACL/EACL ?97 Workshop on Natural Language Pro-cessing for Communication Aids.Meyers, A., Yangarber, R. and Grishman, R. 1996.
Align-ment of shared forests for bilingual corpora.
In Proc.of the 16th International Conference on ComputationalLinguistics (COLING), pages 460?465.Michaud, L. N. and McCoy, K. F. 2001.
Error profiling:toward a model of English acquisition for deaf learn-ers.
In Proc.
of the 39th Annual Meeting and the 10thConference of the European Chapter of Association forComputational Linguistics (EACL), pages 386?393.NIJL, the National Institute for Japanese Language.
1991.Nihongo Kyo?iku-no tame-no Kihon-Goi Cho?sa (Thebasic lexicon for the education of Japanese).
ShueiShuppan, Japan.
(In Japanese)Richardson, S., Dolan, W., Menezes, A. and Corston-Oliver, M. 2001.
Overcoming the customization bottle-neck using example-based MT.
In Proc.
of the 39th An-nual Meeting and the 10th Conference of the EuropeanChapter of Association for Computational Linguistics(EACL), pages 9?16.Robin, J. and McKeown, K. 1996.
Empirically designingand evaluating a new revision-based model for sum-mary generation.
Artificial Intelligence, 85(1?2):135?179.Sato, S. 1999.
Automatic paraphrase of technical pa-pers?
titles.
Journal of Information Processing Societyof Japan, 40(7):2937?2945.
(in Japanese).Shinyama, Y., Sekine, S. Kiyoshi, Sudo.
and Grishman,R.
2002.
Automatic paraphrase acquisition from newsarticles.
In Proc.
of HLT, pages 40?46.Siddahrthan, A.
2003.
Preserving discourse structurewhen simplifying text.
In Proc.
of European Workshopon Natural Language Generation, pages 103?110.Takahashi, T., Iwakura, T., Iida, R., Fujita, A. and Inui, K.2001.
KURA: a transfer-based lexico-structural para-phrasing engine.
In Proc.
of the 6th Natural LanguageProcessing Pacific Rim Symposium (NLPRS) Workshopon Automatic Paraphrasing: Theories and Applica-tions, pages 37?46.Williams, S., Reiter, E. and Osman, L. 2003.
Experimentswith discourse-level choices and readability.
In Proc.
ofEuropean Workshop on Natural Language Generation,pages 127?134.
