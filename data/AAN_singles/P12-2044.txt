Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 223?227,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExtracting and modeling durations for habits and events from TwitterJennifer Williams Graham KatzDepartment of Linguistics Department of LinguisticsGeorgetown University Georgetown UniversityWashington, D.C., USA Washington, D.C., USAjaw97@georgetown.edu egk7@georgetown.eduAbstractWe seek to automatically estimate typicaldurations for  events  and  habits  describedin Twitter tweets.
A corpus of more than14 million tweets containing temporal du-ration  information  was  collected.
Thesetweets were classified as to their habitualitystatus  using a bootstrapped, decision tree.For each verb lemma,  associated durationinformation was collected for episodic andhabitual uses of the verb.
Summary statis-tics for  483 verb lemmas and their typicalhabit and episode durations has been com-piled and made available.
This automati-cally  generated  duration  information  isbroadly comparable to hand-annotation.1 IntroductionImplicit  information  about  temporal  durations  iscrucial to any natural language processing task in-volving  temporal  understanding  and  reasoning.This  information  comes  in  many  forms,  amongthem knowledge about typical durations for eventsand  knowledge  about  typical  times  at  which  anevent occurs.
We know that lunch lasts for half anhour  to  an  hour  and takes  place  around noon,  agame of chess lasts from a few minutes to a fewhours and can occur any time, and so when we in-terpret a text such as ?After they ate lunch, theyplayed a game of chess and then went to the zoo?we can infer that the zoo visit probably took placein the early afternoon.
In this paper we focus onduration.
Hand-annotation of event durations is ex-pensive slow (Pan et al, 2011), so it is desirable toautomatically determine typical durations.
This pa-per describes a method for automatically extractinginformation about typical durations for events fromtweets posted to the Twitter microblogging site.Twitter is a rich resource for information abouteveryday events ?
people post their tweets to Twit-ter publicly in real-time as they conduct their activ-ities throughout the day, resulting in a significantamount  of  mundane  information  about  commonevents.
For example, (1) and (2) were used to pro-vide information about how long a work event canlast:(1) Had  work for an hour and 30 mins nowgoing to disneyland with my cousins :)(2) I play in a loud rock band, I  worked at anight  club for  two years.
My ears  havenever  hurt  so  much  @melaniemarnie@giorossi88 @CharlieHi11In this paper, we sought to use this kind informa-tion to  determine likely durations  for  events  andhabits  of  a  variety  of  verbs.
This  involved  twosteps: extracting a wide range of tweets such as (1)and (2) and classifying these as to whether they re-ferred to specific event (as in (1)) or a general habit(as in (2)), then summarizing the duration informa-tion associated with each kind of use of a givenverb.This paper answers two investigative questions:?
How  well  can  we  automatically  extractfine-grain  duration information  for eventsand habits from Twitter??
Can we effectively distinguish episode andhabit duration distributions ?The results presented here show that Twitter can bemined  for  fine-grain  event  duration  information223with high precision using regular expressions.
Ad-ditionally, verb uses can be effectively categorizedas  to  their  habituality,  and  duration  informationplays an important role in this categorization.2 Prior WorkPast research on typical durations has made use ofstandard  corpora  with  texts  from  literature  ex-cerpts, news stories, and full-length weblogs (Panet al 2006;  2007;  2011; Kozareva & Hovy, 2011;Gusev et al, 2011).
For example, Pan et al (2011)hand-annotated of  a  portion  of  the  TIMEBANKcorpus that consisted of Wall Street  Journal  arti-cles.
For 58 non-financial articles, they annotatedover 2,200 events with typical temporal duration,specifying the upper and lower bounds for the du-ration of  each event.
In  addition they  used theircorpus to automatically determine event durationswith machine learning,  predicting features  of  theduration on the basis of the verb lemma, local tex-tual  context.
and  other  information.
Their best(SVM) classifier  achieved  precision of 78.2% onthe course-grained task of determining whether anevent's duration was longer or shorter than one day(compared with 87.7% human agreement).
For de-termining the fine-grained task of determining themost  likely  temporal  unit?second,  minute,  hour,day,  week,  etc.
?achieved  67.9%  (human  agree-ment: 79.8%).
This shows that lexical informationcan be effectively  leveraged for  duration predic-tion.To compile temporal duration information for awider range of verbs, Gusev et al (2011) exploredan automatic Web-based query method for harvest-ing typical durations of events.
Their data consist-ed of search engine ?hit-counts?
and they analyzedthe distribution of durations associated with  1000frequent verbs in terms of whether the  event lastsfor more or less than a day (course-grain task) orwhether it lasts for seconds, minutes, hours, days,weeks,  months,  or  years  (fine-grain  task).
Theynote that many verbs have a two-peaked distribu-tion and they suggest that the two-peaked distribu-tion could be a result  of the usage referring to ahabit or a single episode.
(When used with a dura-tion marker,  run,  for example, is used about 15%of the time with hour-scale and 38% with year-s-cale duration markers).
Rather than making a dis-tinction between habits and episodes in their data,they apply a heuristic to focus on episodes only.Kozareva and Hovy (2011) also collected typi-cal durations of events using Web query patterns.They proposed a six-way classification of ways inwhich events are related to time, but provided onlyprogrammatic analyses of a few verbs using We-b-based  query  patterns.
They  have  proposed  acompilation  of  the  5,000  most  common  verbsalong with their typical temporal durations.
In eachof  these  efforts,  automatically  collecting  a  largeamount of reliable to cover a wide range of verbshas been noted as a difficulty.
It is this task that weseek to take up.3 Corpus MethodologyOur goal was to discover the duration distributionas well as typical habit and typical episode dura-tions for each verb lemma that we found in our col-lection.
A wide range of factors influence typicalevent durations.
Among these are the character of averb's arguments, the presence of negation and oth-er embedding features.
For this preliminary work,we ignored the effects of arguments, and focusedonly on generating duration information for verblemmas.
Also, tweets that were negated, condition-al tweets, and tweets in the future tense  were putaside.3.1 Data CollectionA corpus of tweets was collected from the Twitterweb  service  API  using  an  open-source modulecalled  Tweetstream  (Halvorsen  &  Schierkolk,2010).
Tweets were collected that contained refer-ence to  a  temporal  duration.
The data  collectiontask began on February 1, 2011 and ended on Sep-tember 28, 2011.
Duplicate tweets were identifiedby their unique tweet ID provided by Twitter, andwere  removed from the data set.
Also tweets thatwere marked by Twitter as 'retweets' (tweets thathave been reposted to Twitter) were removed.
Thefollowing query terms (denoting temporal durationmeasure) were used to filter the Twitter stream fortweets containing temporal duration:second,  seconds,  minute,  minutes,  hour,hours,  day,  days,  week,  weeks,  month,months, year, years, decade, decades, cen-tury,  centuries,  sec,  secs,  min,  mins,  hr,hrs, wk, wks, yr, yrsThe number of tweets in  the  resulting  corpus was14,801,607 and the total number of words in the224corpus was 224,623,447.
Tweets were normalized,tokenized,  and  then  tagged  for  POS,  using  theNLTK Treebank Tagger (Bird & Loper, 2004).3.2 Extraction FramesTo associate each temporal duration with its event,events and durations were identified and extractedusing  four  types  of  regular  expression  extractionframes.
The  patterns  applied  a heuristic  to  asso-ciate each verb with a temporal expression, similarto  the  extraction  frames used  in  Gusev  et  al.(2011).
The four types of extraction frames were:?
verb for duration?
verb in duration?
spend duration verbing?
takes duration to verbwhere verb is the target verb and duration is a du-ration-measure term.
In (3), for example,  the verbwork is associated with the temporal duration term44 years.
(3) Retired watchmaker worked for 44 yearswithout a telephone, to avoid unnecessaryinterruptions, http://t.co/ox3mB6gThese four extraction frame types were also variedto  include different  tenses,  different  grammaticalaspects,  and  optional  verb  arguments to  reach  awide  range  of  event  mentions  and  ordering  be-tween the verb and the duration clause.
For eachmatched tweet  a  feature  vector  was created withthe  following  features:  verb  lemma,  temporalbucket  (seconds,  minutes,  hours,  weeks,  days,months or years), tense (past or present), grammat-ical aspect (simple, progressive, or perfect), dura-tion in seconds, and the extraction frame type (for,in, spend, or take).
For example, the features ex-tracted from (3) were:[work, years, past, simple, 1387584000, FOR]Tweets with verbal lemmas that occur fewer than100 times in the extracted corpus were filtered out.The  resulting  data  set contained  390,562 featurevectors covering 483 verb lemmas.3.3 Extraction PrecisionExtraction frame performance was estimated usingprecision on a random sample of 400 hand-labeledtweets.
Each instance in the sample was labeled ascorrect if the extracted feature vector was correctin its entirety.
The overall precision for extractionframes was estimated as 90.25%, calculated usinga  two-tailed t-test  for  sample size  of  proportionswith 95% confidence (p=0.05, n=400).3.4 Duration ResultsIn order to summarize information about dura-tion for each of the 483 verb lemmas, we calculat-ed the frequency distribution of tweets by durationin seconds.
This distribution can be represented inhistogram form, as in Figure 1 for the verb lemmasearch,  with with bins corresponding to temporalunits of measure (seconds, minutes, etc.
).Figure 1: Frequency distribution for searchThis  histogram  shows the  characteristic  bi-modal-distributions noted  by Pan et al, (2011) andGusev et.
al., (2011), an issue taken up in the nextsection.4 Episodic/Habitual ClassificationMost verbs have both episodic and habitual uses,which clearly correspond to different typical dura-tions.
In order to draw this distinction we built asystem to automatically classify our tweets  as totheir  habituality.
The  extracted  feature  vectorswere used in a machine learning task to label eachtweet  in the collection as denoting a habit  or  anepisode, broadly following Mathew & Katz (2009).This classification was done with bootstrapping, ina partially supervised manner.4.1 Bootstrapping ClassifierFirst, a random sample of 1000 tweets from the ex-tracted  corpus  was  hand-labeled  as  being  either225habit  or  episode (236 habits;  764 episodes).
Theextracted  feature  vectors  for  these  tweets  wereused to train a C4.5 decision tree classifier (Hall etal., 2009).
This classifier achieved an accuracy of83.6% during training.
We used this classifier andthe hand-labeled set to seed the generic YarowskyAlgorithm  (Abney,  2004), iteratively  inducing  ahabit or episode label for all the tweets in the col-lection,  using  the  WEKA output  for  confidencescoring and a confidence threshold of 0.96.The extracted corpus was classified into 94,643habitual tweets and  295,918 episodic tweets.
Toestimate  the  accuracy  of  the  classifier,  400  ran-domly  chosen  tweets  from  the  extracted  corpuswere hand-labeled, giving an estimated accuracy of85% accuracy with 95% confidence, using the two-tailed t-test for sample size of proportions (p=0.05,n=400).4.2 ResultsClearly the data in Figure 1 represents two com-bined distributions: one for episodes and one forhabits, as we illustrate in Figure 2.
We see that theverb search describes episodes that most often lastminutes or hours, while it describes habits that goon for years.Figure 2: Duration distribution for searchThese two different uses are illustrated in (4) and(5).
(4) Obviously I'm the one who found the tinylost black Lego in 30 seconds after the 3 ofthem searched for 5 minutes.
(5) @jaynecheeseman they've been searchingfor you for 11 years now.
I'd look out if Iwere you.In Table  1  we provide  summary information forseveral verb  lemmas, indicating the average dura-tion  for  each  verb  and  the  temporal  unit  corre-sponding to the largest bin for each verb.VerbEpisodic Use  Habitual UseModalbin MeanModalbin Meansnooze minutes 1.6 hrs decades 7.5 yrscoach hours 10 days years 8.5 yrsapprove minutes 1.7 mon.
years 1.4 yrseat minutes 5.3 wks days 5.7 yrskiss seconds 4.5 days weeks 1.8 yrsvisit weeks 7.2 wks.
years 4.9 yrsTable 1.
Mean duration and mode for 6 of the verbsIt is clear that the methodology  overestimates theduration of episodes somewhat ?
our estimates oftypical durations are 2-3 times as long as those thatcome from the annotation in  Pan,  et.
al.
(2009).Nevertheless, the modal bin corresponds approxi-mately to that the hand annotation in Pan, et.
al.,(2011) for nearly half (45%) of the verbs lemmas.5 ConclusionWe have presented a hybrid approach for extract-ing typical  durations  of  habits  and episodes.
Weare able to extract high-quality information abouttemporal  durations  and  to  effectively  classifytweets as to their habituality.
It is clear that Twittertweets contain a lot of unique data about differentkinds of events and habits, and mining this data fortemporal duration information has turned out to bea fruitful avenue for collecting the kind of world-knowledge that we need for robust temporal lan-guage processing.
Our verb lexicon is available at:https://sites.google.com/site/relinguistics/.226ReferencesSteven Abney.
2004.
?Understanding the Yarowsky Al-gorithm?.
Computational Linguistics 30(3): 365-395.Steven Bird and Edward Loper.
2004.
NLTK: The natu-ral language toolkit.
In Proceedings of 42nd AnnualMeeting  of  the  Association for  Computational  Lin-guistics (ACL-04).Andrey  Gusev,  Nathaniel  Chambers,  Pranav  Khaitan,Divye Khilnani, Steven Bethard, and Dan Jurafsky.2011.
?Using query patterns to learn the durations ofevents?.
IEEE IWCS-2011, 9th International Confer-ence on Web Services.
Oxford, UK 2011.Mark  Hall,  Eibe  Frank,  Geoffrey  Holmes,  BernhardPfahringer,  Peter  Reutemann,  and  Ian  H.  Witten.2009.
The WEKA  Data  Mining Software:  An Up-date; SIGKDD Explorations, Volume 11, Issue 1.Rune  Halvorsen,  and Christopher  Schierkolk.
2010.Tweetstream:  Simple  Twitter  Streaming  API  (Ver-sion  0.3.5)  [Software].
Available  from  https://bit-bucket.org/runeh/tweetstream/src/.Jerry Hobbs and James Pustejovsky.
2003.
?Annotatingand reasoning about time and events?.
In Proceed-ings of the AAAI Spring Symposium on Logical For-mulation of Commonsense Reasoning.
Stanford Uni-versity, CA 2003.Zornitsa  Kozareva  and Eduard  Hovy.
2011.
?LearningTemporal  Information  for  States  and  Events?.
InProceedings of  the Workshop on Semantic Annota-tion for Computational Linguistic Resources (ICSC2011), Stanford.Thomas  Mathew and  Graham  Katz.
2009.
?SupervisedCategorization of Habitual and Episodic Sentences?.Sixth  Midwest  Computational  Linguistics  Colloqui-um.
Bloomington, Indiana: Indiana University.Marc Moens and Mark Steedman.
1988.
?Temporal On-tology  and  Temporal  Reference?.
ComputationalLinguistics 14(2):15-28.Feng  Pan,  Rutu  Mulkar-Mehta,  and  Jerry  R.  Hobbs.2006.
?An Annotated Corpus of Typical Durations ofEvents?.
In Proceedings  of  the  Fifth  InternationalConference on Language Resources and Evaluation(LREC), 77-82.
Genoa, Italy.Feng  Pan,  Rutu  Mulkar-Mehta,  and  Jerry  R.  Hobbs.2011.
"Annotating and Learning Event Durations inText."
Computational Linguistics 37(4):727-752.227
