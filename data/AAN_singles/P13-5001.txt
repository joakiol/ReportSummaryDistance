Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, page 1,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsVisual Features for Linguists:Basic image analysis techniques for multimodally-curious NLPersElia BruniUniversity of Trentoelia.bruni@unitn.itMarco BaroniUniversity of Trentomarco.baroni@unitn.itDescriptionFeatures automatically extracted from images con-stitute a new and rich source of semantic knowl-edge that can complement information extractedfrom text.
The convergence between vision- andtext-based information can be exploited in scenar-ios where the two modalities must be combinedto solve a target task (e.g., generating verbal de-scriptions of images, or finding the right imagesto illustrate a story).
However, the potential ap-plications for integrated visual features go beyondmixed-media scenarios: Because of their comple-mentary nature with respect to language, visualfeatures might provide perceptually grounded se-mantic information that can be exploited in purelylinguistic domains.The tutorial will first introduce basic techniquesto encode image contents in terms of low-level fea-tures, such as the widely adopted SIFT descriptors.We will then show how these low-level descriptorsare used to induce more abstract features, focus-ing on the well-established bags-of-visual-wordsmethod to represent images, but also briefly in-troducing more recent developments, that includecapturing spatial information with pyramid repre-sentations, soft visual word clustering via Fisherencoding and attribute-based image representa-tion.
Next, we will discuss some example appli-cations, and we will conclude with a brief practi-cal illustration of visual feature extraction using asoftware package we developed.The tutorial is addressed to computational lin-guists without any background in computer vi-sion.
It provides enough background material tounderstand the vision-and-language literature andthe less technical articles on image analysis.
Afterthe tutorial, the participants should also be able toautonomously incorporate visual features in theirNLP pipelines using off-the-shelf tools.Outline1.
Why image analysis??
The grounding problem?
Multimodal datasets (Pascal, SUN, Im-ageNet and ESP-Game)2.
Extraction of low-level features from images?
Challenges (viewpoint, illumination,scale, occlusion, etc.)?
Feature detectors?
Feature descriptors3.
Visual words for higher-level representationof visual information?
Constructing a vocabulary of visualwords?
Classic Bags-of-visual-words represen-tation?
Recent advances?
Computer vision applications: Objectrecognition and emotion analysis4.
Going multimodal: Example applications ofvisual features in NLP?
Generating image descriptions?
Semantic relatedness?
Modeling selectional preference1
