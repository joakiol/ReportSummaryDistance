Navigating maps with little or no sight: An audio-tactile approachR.
Dan JacobsonDepartment ofGeographyUniversity of CaliforniaSanta Barbara, CA 93106 USAdjacobson@geog.ucsb.eduAbstractThis paper first presents a review of theoptions available for conveying maps andgraphics to visually impaired and blindpeople.
A novel audio-tactile methodologyis described, and the results from its pilotstudy reported.
Communication of spatialmedia, such as map, is problematic withoutsight.
Tactile perception is serial ratherthan synoptic.
By building a workingmodel of the environment that is uses bothtactile and auditory feedback, a map ismade far more accessible.
Results from thepilot study demonstrated simplicity andenjoyment of use of this novel approachwhich integrates speech, verbal andmarks,earcons and recorded environmental soundto build a small spatial hypermedia system.IntroductionWhether blind, visually impaired, or sighted,our quality of life is greatly dependent on ourability to make informed spatial decisions.Space is fundamental to human existence andhas great influence on human thinking.
Accessto representations of the geographic world (amap for example) are frequently denied a blindindividual due to his or her lack of sight.
For along time tactile maps have sought to solve thisproblem.
Tactile maps are static, cumbersometo create and have many associatedcartographic problems.
The fingertip'sresolution is far less than the eye, it perceivesserially - its "bandwidth" is very lowcompared to vision.
The sighted cartographeris faced with the problems of simplification,95generalisation, classification and symbolisationto render a visual map tactile.
A commonproblem with tactile maps is labelling.
Braillelabelling is inflexible and when enough labelsare applied to facilitate suitable understandingthe map often becomes cluttered and illegible(Tatham 1991).
Using labels in a separatelegend or key reduces the immediacy of thegraphic and introduces interpretative problemsas referencing is disrupted (Hinton 1993).Technologies are evolving to help addresssome of these problems.
The aim of thisresearch is to create a way of accessing mapinformation that is easy to learn and use, andsupports interaction that is natural, flexible andefficient.
It is hoped that this will expand theavailability of maps to a broader spectrum ofthe population.1 Enhancements and alternatives toconventional tactile mapsTechniques for producing hardcopy tactilemaps have improved (eg Andrews, 1988),however, the perceptual constraints remain thesame - fingertip resolution and a "static"media.
Moving from one map to an adjacentmap is physically clumsy and awkward.
Therehave been two major developments.
Firstly, theuse of computer technology for the generationof the art work that produces ther tactile map.Secondly computer systems to assist thereading of the tactile map.1.1 Automated tact i lemap creationGeographic Information Systems (GIS -loosely defined as a spatial database) can beused as a way to store, manage and manipulatespatial information for the generation of tactilemaps.
Coulson (1991) pioneered the use of aGIS, exploiting its cartographic functionality,for the production of tactile maps.
A sightedoperator would create a map, first plotted onpaper then rendered tactile by microcapsulepaper.
The structure of data stored on a GISand the ways in which this can be accessed arebeneficial to this map manipulation andmanagement.1.2 Augmented tactile mapsAn alternative solution has been to developaudio-based systems that link sound withtouch, enhancing the tactile map with theaddition of audio.
For example, when a raisedarea on a tactile map is touched acorresponding sound label is triggered.
Twosuch systems include NOMAD (Parkes 1988)and 'talking tactile maps' (Blenkhorn andEvans 1994).
Fanstone (1995) has exploitedthe GIS capabilities of NOMAD to build ahierarchical audio-tactile GIS of NottinghamUniversity campus.
Access within a map isvery efficient users reporting enjoyment andease of use (Jacobson, 1996), However, accessfrom one map to the next remains problematic.For example to 'zoom in' or to move to anadjacent the user has to locate the speech labelindicating that it is possible to zoom in.
Thenremove the tactile map, search for anothertactile map, register this on the touchpad andthen continue map exploration.
This break inthe continuum of map reading is disrupting andconfusing.1.3 Novel digital technologiesOne development that has great potential tosolve this problem is hypermedia.
Hypermediawhich comprises of text, still imagery, soundrecordings (even tactile and olfactory output)is a network of information 'linkedelectronically by multiple routes, chains, ortrails in an open-ended, perceptuallyunfinished assemblage described best in termsof links, nodes, networks, webs and paths'(Landow 1992, p.3).
A well known example ofa hypermedia environment would be the WorldWide Web.
Within a hypermedia environmenta user can navigate between textual andcartographic information odes in order to geta well documented, multi-facetedrepresentation f space, from varied sourcesand differing viewpoints (Milleret-Raffort1995).
A hypermedia document (if structuredcorrectly) should allow a seamless navigationthrough the document, passing through variousmedia, following a line of thought or inquiry.Conventional hypermedia systems aredesigned for predominantly visual in nature.They can, however, also offer people withvisual impairments a way of exploring theworld (Jacobson and Kitchin, in press)Non-visual hypermedia systems seek toprovide sensory substitution with spoken audioinformation replacing textual and image basedinformation.
Such a system now exists forblind users on the World Wide Web(Webspeak 1995).
Here, images are bypassed,textual information is converted to speech, andhypertext links are explained.
There has beena long period of development of auditoryalternatives tothe visually dominant GraphicalUser Interface (GUI), for example, Soundtrack(Edwards, 1989); Karshmer and Oliver (1993);The Graphical User Interface for Blind PeopleProject (GUIB- Savidis and Stephanidis,1995); the Mercator Project (Mynatt, 1997).These developments are important as theyallow a blind user to work in parallel with theirsighted counterpart.
However, the developmentof systems for accessing spatial information(map-like information, rather than pull-downmenus and screen icons) has been lacking.There are few notable exceptions (see Kurzeand Holmes, 1996; Kurze 1997).
Maps are ofcrucial importance, as they have the ability tonot only present information with an academicview of the world but have the potential toimpact on the daily living problems facingblind people.
As such they can lead to animproved quality of life through enhanced,orientation, mobility and independence.2 Preliminary GIS and web studiesResearch undertaken at the Univeristy ofWales, Aberystwyth, UK between 1994 and1996 explored the potential of GIS and96hypermedia for communicating spatialinformation to blind and visually imapairedpeople.A GIS front end, ArcView, was used toconstruct a spatial system for visually impairedpeople (legally blind, but with some residualvision).
The GUI was stripped own and manyunnecessary component buttons and menusremoved.
The final system worked in twomodes, a low vision zoom and pan query modewhich displayed a map of the campus.
With asingle mouse click users could zoom-in to thearea selected.
By re-clicking the mouse buttonthe user continued zooming-in until the area inquestion filled the display.
With a further clickan audio file was played, 'speaking' the nameof the building.
Finally a large photograph ofthe building was displayed.
In the second modethe user typed in the name or function of thebuilding (for example 'Llandinam Building' or'Earth Sciences') a map Was then displayed ofthe campus and subsequent maps, eachdisplayed after a mouse click zoomed the userin to the building requested (see Jaeobson andKitchin, in press.
)As such, ArcView was effectively reduced to apoint-and-click hypermedia system.
Users ofthe system expressed great interest andexcitement asking 'can you do this for thetown centre'; 'Now I can experience places Iwould never visit'.
Due to the 'simplicity' ofthe final slimmed down version of ArcViewand to allow optimum access and usability itwas decided to continue with the project usingthe World Wide Web environment.A series of hypermap World Wide Web pageswere built allowing the user to navigatebetween low vision maps and spoken textualscreens.
The interface utilised large fonthypertext mark-up language (HTML), and atthe bottom fight the screen magnifyingsoftware.
Large scale abstracted andsimplified maps were used to convey spatialinformation.
An enhanced cursor is used tofollow links, when a shape on the map isqueried an audio file was displayed escribingthe building.
This interface nabled users toaccess the low vision and spoken mapsremotely.3.
Protoype and pilot study of audio-tactile systemThe prototype used a low specification PC(DX4-100 processor, 16 megabytes of ram,and a 16bit souncard) The touch pad andassociated software retail for around $300 andwill work with any windows based PC.
Thetouch pad can be attached to a monitor so auser with limited vision is able to view thescreen, or used at table-top level where atotally blind individual is able to scan the padwith their fingertips.
Spatial information ispresented as an auditory map.
Areas of thetouch pad are overlain with sound, when themap users finger enters the designated area thesound is played.
By touching areas of the padusers were able to determine the size and shapeof a map feature by the change in sound.
Acollection of sounds are used to represent mapinformation usually conveyed by visualsymbols (text, color, line style, shape etc.).
Anoff-line World Wide Web site is being builtwhich utilizes interlinking auditory maps thatcan be traversed solely by sound and touch.
Asthe user's finger is dragged across the touchpad, the system 'talks', playing audio fileswhich are triggered by the position of theuser's finger.
By the use of spoken audio,verbal landmarks, environmental udio (suchas traffic noise for a road) and auditory icons(earcons - Blattner et al,1989) to denotespecific events like the edge of a map, a link tofurther maps, or for the user to press for moreinformation, an audio-tactile hypermedia isconstructed conveying cartographicinformation.Rather than direct manipulation of a tactilesurface, such as pressing on the tactile maps inNOMAD, this system uses a touch pad.Therefore the user has no direct cutaneousstimulus from tactile relief.
The encoding fromthe audio-tactile stimulus meant that map97Figure 1: Overview of sample audio-tactile map information (main map in pilot study)I7 l1iIil12 !6 8 I~  4SOUTH 1(a) Screen dump of main audio tactile map (numbers refer to l(c))Press to gohome to mainmanI 1 North IslandWaves - \[Press Westernto go OceanwestPress to g~ b" : ' - ck~ @ \[To previous mapPre.~q tn en noahElephant - \[tea farl nar'lcWater  \]bubblesCricketsmarshy areaCar zTassine -I Car horn -Congested roadM1 I+:.'+:.'.:.::+:,:.:.:.::.:.:.:.:-:.:+:.:.:.:-.::.:+:.:.:-:+:.:+:+:.:+:+:+:.:.:.:.:.
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::iPress to getHelp screen13- Pressto goeastPress to getinformationabout hisPregq tn an ~n.th  t~aRe(b) Audio overlay on visual map (dark  text  - indicates the playing of an environmental sound)1 To the south is a large conurbation: An area of many cities2 To the north is an area of rolling farmland3 To the west is a windy ocean4 To the east is a hot dusty plain5 The safari park has many animals from East Afi'ica6 The lake is a popular escape for the city people during the hot summer months7 Trains travel from the city into the wine countryg Open space and farmland around the city9 Many boats trawl the sea for shoals of cod10 North island is home to a large colony of seabirds11 South island is used for missile testing12 The marsh is an area once filled by the sea, now unsuitable for development13 The main map shows a city and its surroundings.
To The west is an ocean.
In thesouth west Is the city.
To the north a train line, to the east a motorway and to theeastern fr ing~ a marsh.
(c) Links to verbal information from the main scro-tactile map information (main map in pilot study)98information is built up from kinaesthetic sensingof movement across the.
pad, sensing of thedistance traversed across the pad, proprioceptivesensing of the location of the fingers andlocation information obtained by referencingwith the hands to the outside frame of the touchpad.
Linking enables a blind user to traversefrom one auditory map to another.
As each maploads, a verbal overview describing the map isplayed.
From all maps there is direct access to ahelp screen that explains the system and themodes of interaction.Figure l(a) displays the simple user interface forthe auditory hypermap system.
As the map-reader's finger moves across the touch pad andover the "SOUTIT' bar the audio message "Pressto go south" is played.
Once this part of thetouchpad is pressed the central area is filled withan auditory map to the south of the previous one.If no maps are available, this is verbally relayedto the user.
North, west and east all work in asimilar manner.
Home returns the user to themain auditory map.
The help button explainshow to use the system.
When exiting from helpthe user is returned to the correct map.
The "i"button plays information about he map in view(e.g., 'this is the city area map.
Downtown is inthe north of the urban area, and the harbor to thewest etc.').
The back and forward buttons allowthe user to traverse through the 'history' of theirlinks3.1 Methodolgycontent, stucture or links between the maps.During the evaluation phase individuals had 15minutes to navigate through and explore themaps.
They were told that they were free to gowhere they wished and to return to placespreviously visited.
At the end of this 15 minuteperiod, the computer was turned off and theparticipant gave a verbal desfiption of the mapsand map-layout imaging they had to explain themaps to somebody over a telephone.
Theparticipant hen graphical reconstructed themaps using a tactile drawing pad which enablesa blind user to feel what they are drawing.
Thewhole process was videotaped and a log made ofpeoples paths through the audio-tactile maps.Semi structured interviews were used to getimpressions of the system, feedback on how itcould be improved and for ideas of where it maybe beneficial (such as in schools or at touristsites).3.2 ResultsAll users were able to successfully interact withthe system.
This included people who had neverused a computer before.
Interview responsessuggest hat the system aroused great interestand that map access was 'simple, satisfying andfun' (totally blind participant).
Users were ableto both graphically and verbally reconstruct themaps with varying degrees of accuracy.
Furtherevluation is planned to directly compare theseresults to tactile map access of the same scenes.Figure 2 shows a graphical reconstruction by avisually impaired map user, and figure 3 agraphical reconstruction by a totally blindparticipantEvaluation of the system involved 5 visuallyimpaired people and 5 blind people.
The systemwas evaluated invidually.
Initial training tookplace for 15 minutes using the help screen of themodel.
Users were familiarised with thetouchpad, were shown how to follow a link,obtain more verbal information, and to follow alink.
The structure of the menu surrounding themap was explained (buttons north, south etc.
)and the function of the buttons to go back andhome shown.
Questions were answered andpeople familiafised themselves with the system,There were given no information about the99The audio-tactile hypermap system wasdesigned as a prototype to explore thepossibilities for conveying spatial information inthis 'touch-audio' manner.
Ultimately it isintended that such a system could act as a frontend to a more fully functional GIS, enabling theselection and presentation of map likeinformation to visually impaired people.
Forexample, to construct a map of 'y' town showingroads, location of crossings and publicconveniences, all at the request of the user.Figure 2 : Graphic reconsruction byvisuallyimpaired individualFigure 3 : Graphic reconstruction bya totallyblind individualand graphics.
Krygier 1994 outlined auditor~cartography and Blattner et al, 1994 hav;worked on the sonic enhancement of twodimensional graphic displays.
Clearly there i:the need for visually impaired people to b;active participants in the research process an~for the process to be user-led with frequenvalidationConclusionThis research is highly relevent and ha.implications beyond the blind community that iis targeted at.
New internet developments offegreat potential.
The internet is widely usedcommonplace and rapidly expanding.
Thinternet can potentially distribute informatio-from anywhere to anywhere.
The nature of thprotocols uch as VRML and HTML offer goodapproaches and techniques so a non-expert ca-build information is readily aecesible to blindand visually impaired people.
This novel audiotactile approach offers, a dynamic, flexible, lovsost media for the presentation of spatiainformation.4 Future researchThere is a need for future research to address thefurther development and use of new interfacetechnologies such as voice recognition, touchscreens and tactile displays.
Probably the mostpressing need is to improve the user interface, asthis is the largest barrier to successful andmeaningful interactions with representations ofspatial information.
There have been severalnovel and interesting approaches that requirefurther investigation.
A vibro-tactile mousewhich registers the mouse's position over adesired spatial object on a map (Nissen 1997),tonal interfaces for computer interaction (Alty1996), and 'The Voice' which can convert a twodimensional picture, map or representation nto a'tonal soundseape' (Meijers 1993, 1997).
Muchof GUI of this research could be directed atconveying representations of the real world(maps) to blind people in order to develop fullyfunctional non-visual GIS systems.
Furtherresearch is needed on the sonifieation of mapsBecause this audio-tactile mapping syster.resides within the protocols of the world widweb it means that the maps can be accesse.,audio-visually by sighted people using :conventional mouse.
With the addition of thtouch pad a partially or totally blind user is ablto remotely access the content of the auditor.maps from any computer with an interneconnection.
By adopting a 'design for allapproach the spectrum of people able to accesmap and graphic information is increased t.include not only people with limited vision, bualso potentially children, the elderly and peoplwith learning disabilities.Visually impaired people's need for spatizinformation is greater that their sighte.counterparts as they are unable to (fullyperceive the environment through vision.
Thilack of visual perception severely limitindependent travel.
The computing comrnunitis in a unique position to address this need animprove the quality of life for people with visu~impairments by increasing the capacity fGindependent ravel and education througi 00"obility and learning aids.cknowledgementsur thanks go to all the participants in Belfast,orthern Ireland who offered their time toarticipate in the pilot study.eferencesndrews S. (1988) The use of capsule paper inproducing tactile maps Journal of visualimpairment and blindness, 79, 396-399.lattner M.M., Sumikawa D.A.
and Greenberg, R.M.
(1989) Earcons and Icons: Their structure andcommon design principles.
Human-ComputerInteraction, 4 11-44.lattner M.M., Giinert E.P.
and Papp A.L.
(1994)Sonic Enhancement of Two-Dimensional GraphicDisplays.
In Auditory display: Sonification,Audification, and auditory interfaces (Ed) G.Kramer, Addison-Wesley, Santa Fe Inst, Reading,MA pp 447-460ienkhom P. and Evans D. G. (1994) A system forreading and producing talking tactile maps'.Proceedings of the 9th International CohErence ontechnology and persons with disabilities,California State University, Northridge.oulson M.R.C.
(1991) Tactile-map output fromgeographical information systems: the challengeand its importance.
International Journal ofGeographical Information Systems (5) 3,353-360..lwards A.D.N.
(1989) Soundtrack: An auditoryinterface for blind users.
Human-ComputerInteraction, 4, 45-66.Fanstone J 1995 Sound andtouch: a campus GIS for the visually impaired.
GISEurope, April, 44-45.~nton R.A.L (1993) Tactile and audio-tactile imagesas vehicles for learning.
Non-visual HumanComputer Interaction, 228,169-179..cobson R.D.
(1996) Talking tactile maps andenvironmental audio beacons: An orientation andmobility development tool for visually impairedpeople.
Proceedings of maps and diagrams forblind and visually impaired people: Needs,solutions and developments, October 21-25 1996,Ljubjiana, Slovenia.cbson R.D.
and Kitchin R.M.
(in press, due 1998)Geographic information systems and people withvisual impairments or blindnes: Exploring thepotential for education, orientation and navigation.Transactions in Geographical InformationSystems.=rshmer A.I.
and Oliver R.L (1993) Specialcomputer interfaces for the visually handicapped :FOB the manufacturer.
Proceedings of the ThirdInternational Conference EWHCI'93, Moscow,Russia, August 1993, 272-280.Kaygier J.B. (1994) Sound and geographicvisualisation I A M MacEachren and D R FraserTaylor (eds.)
lOsualisation i modern cartographyPergamon.
149-166.Kutze M. (1997) Rendering drawings for interactivehaptic perception.
Proceedings of Computer-Human Interaction, March 22-27, 1997, Atlanta,GA.Kurze M. and Holmes H. (1996) 3d concepts by thesighted, the blind, and from the computer.Proceedings of the Y~ international CohErence onComputers Helping People with Special Needs,July, 17-19, 1996, Linz, Austria.Landow G.P.
(1992) Hypertext: The convergence ofcontemporary critical theory and technology.Baltimore: Johns Hopkins University Press.Hatfield, UK, February 1-2.Meijer P.B.L (1992) An experimental system forauditory image representation.
1EEE transactionson biomedical engineering, 39(2), 112-121.Meijer P.B.L.
(1997) Soundscapes from the voice -Introduction and overview Intemet World WideWeb addresshttp://ourwodd.compuserve.com/homepages/Peter_Meijer/voicover.htmMilleret-Raffort F. (1995) Some cognitive andtechnical aspects of hypermaps In T. L. Nyerges etaL,( eds.)
Cognitive aspects of human-computerinterraction for geographic information systems,Kluwer academic publishers, Netherlands.Mynett E.D.
(1997) Transforming graphicalinterfaces into auditory interfaces for blind users.Human-Computerlnteraction, 12, 7..45.Nissen J 1997 (Pers.
Comm.
)Parkes D. (1988) NOMAD - An audio tactile tool forthe acquisition, use and management of spatiallydistributed information by partially sighted andblind people.
Proceedings of the secondinternational conj~rence onmaps and graphics forvisually disabled people :Nottingham, UK:Nottingham University, 24-29.Savidis A. and Stephanidis C. (1995) Building non-visual interaction through the development of therooms metaphor'.
Companion of the CH1'95Conj~rence on human factors in computingsystems, Denver, Colorado, 7-11 May, 1995, 244-245.Tatham A.F.
(1991) The design of tactile maps:Theoretical and practical considerations.Proceedings of international cartographicassociation: Mapping the nations.
(Ed) KRybaczak and M Blakemore.
London, ICA, 157-166.Webspeak (1995) The pwWEb Speak Project.i 01Intemet World Wide Web address athttp://www.prodworks.com/pwwebspeak.htm102
