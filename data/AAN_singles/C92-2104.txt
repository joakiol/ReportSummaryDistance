Learning Mechanism in Machine Trans la t ion  System "PIVOT"~i tsugu ~iura Mikito H i rata  Nami HoshinoC&C S~stems Engineer ing g iv i s ionNEC Corporat ion4-12-35, Shibaura,  Minato-ku,Tokyo, JAPANAbstract8EC's machine treuslat ion system "PIVOT" providesanalysis editing functions.
The user can iuterectivel~correct errors in analysis results, such as dependencyand case.
However, without a \]earning mechanism, theuser must correct similar dependency errors severaltimes.
We discuss the learning mechanism to u t i l i zedependency and case information specified by the user,We compare four types of matching methods by simulationand show non-restricted best matching is the mosteffective.1.
IntroductionIn the current machine translation system, userscannot always get correct translated sentences at thef i r s t  translat ion.
This is due to the low abi l i ty  ofthe grammar ules end low quality of the dictionarY.Woreover, the grealar rules and the dictionary needcustomization for each document of varying f ie lds andcontents.
It is very d i f f i cu l t  to prepare beforehandthe information corresponding to various f ie lds.NEC has developed a machine translat ion systea"PlV0T"(Jepanese to English/English to Japanese) as thetranslat ion support systea for business use.
The trans-lation part of PIVOT is the rule-based system andadopts the interl ingue method.
PIVOT provides a specialeditor so that the user can correct the analysisresults .
The user can interactively select suitabletranslat ion equivalents, can correct dependency, case(semantic relat ion),  and so on.
In technical manualdocuments which ere the main objects of machine trans-lation, there ore many expressions that appear morethan once.
The analysis results  of such expressions areoften the sane.
At present, PIVOT has learning functienfor selection of translat ion equivalents, but it doesnot have such mechanism for dependency and case.
Theuser has to correct many similar errors in dependencyand case, so a heavy burden is laid on the user.
Infor-mation give~ by the user can be regarded as customizinginformation for the document to be translated.
There-fore, for o practical use system, i t  is an importantissue to provide a framework to improve translat ionby using correction information froa the user.There are various approaches for analyzing seutencesby using accumulated ependencies.
One system auto-matically extracts al l  dependencies which have neambiguJty\[5\].
Another system accumulates only thedependencies which are direct ly corrected by the user\[2\].
In 8lure et a l .
\ [4 J ,  the s~stem accumulates al ldependencies in the sentence that are correctedor confirmed by the user.There ere two ways for remembering the keys in thedependency structures to he accumulated: one by thespell ing and the other by the semantic code.
However,the rougb selant ic code used in the current system doesnot have high distinguishing ab i l i ty ,  end often causesbad influence.
For example, consider the followingsentences.lie looked at the singing man with opera glasses.lie looked at the man who is singing with the aicro-phone.The seaantie code "Instrument" is usually assigned to"~-~ ?~(opera  glasses)" and "~4 ~ (microphone)".Therefore, it ien't  possible to fix dependence relat ionsuch as "~5(s ing ing)"  with "~4?
(microphone)" ,  and" .E~(look)" with "#"~P~X(opera  glasses)".In the process of using learning resul ts  there is anapproach that adopts best matching by computing s ia i -lar i ty  with accumulated inforaatioo\[i3.
The example-based approach that translates by retr ieving examplesand calculating s ia i la r i ty  has been investigated.
Thesesystems also adept best aatching\[ l \ ] \[6\]\[7\] .This paper proposes an approach that can i lprove thetranslat ion qual i ty b~ interact ive ly  accumulating de-pendency and case structures corrected by the user.
Inthe learning process, the syntactle head, tile syntacticdependent, and the ease between them are stored in theassociation database.
$o avoid side effects, head anddependent words are stored in the form of spel l ings.This makes it easier for the user to understand thebehavior of the system.
Four types of matching methodsare examined that ere used in matching betgeen thepossible analysis structures and the association date-base.Section 2 describes analysis edit ing function inPIY0T/JE(dapanese to English).
Section 3 explains thelearning mechanism, and the results  of simulation onactual manuals are presented in Section 4.2.
Analysis Editing FunctionThe user can interaetively ~peeify the followinginformation related to dependency relat ion by usinganalysis edit ing function of P1VOT/JE.
(I) Dependencg (syntactic dependent end syntactic head)(2) Case(3) Parallel(4) ScopeACRES DE COLING-92, NANTES, 23-28 AOtJT 1992 6 9 3 PROC.
OF COTING-92, NAt .S ,  AUO.
23-28, 1992(5) SharingThe dependency relation which the system analyzes isdisplayed on the screen as shown in Figure 1.
An under-line is drawn under each Japanese phrase (a word ~itbs part icle).
The dependency is shown by the linewhich connects tmo phrases.
The thick line indicatesthe dependency corrected by the user.
Case is displayedon the line of the dependency in the form of the part i -cles which have one-to-one correspondence with one ofthe cases.
The bo~ indicates the correct case specifiedby the user.
The user directly corrects above-mentionedinformation by using a louse and carries out trans-lation operation once again.
The translation rulecontrols the analysis to reflect the correction by theuser.Figure I :  Display of Analysis Result2.1 DependencyThe user can correct dependency.
In Figure 2, syn-tactic head of "~- -~(user ) "  is changed from "~1~)dT~-~ (analyze)" to "~r~31"~ (specify)".uAer ana lyze  necessary  In for=| t Jo~ spec l f~l _ _ J  \ [ _ _ J  L~ \ [ __ l  L _ _ IFigure 2: Example of 0ependency Correction2.2 CaseCase shows the semantic relation between two phraseswhich are in dependency relation.
PIVOT has more thanfort~ kinds of eases such as Agent and Reason.
On thescreen, particles are used to express cases.In Figure 3, the case between "EWS4800" and "11~31"~(run)" is changed froa "Contents" to "Place" .t r lns l t t ion  syste= run EIIS4800~1~, ~y ,~,~t  I J l~'?
'~ EWS4800.\ [ _ _1T~ (Contents)t~B~(PI~ee)Figure 3: ExamPle of Case Correction2.3 ParallelThe user can specify the information that twophrases are in parallel relation, Because parallelrelation is one of the PIVOT eases, this functionenables the user to correct dependency and case at thes~e time.2.4 ScopeThe user can specify scope.
Scope means the phrasesequence in which only the syntactic head has depen-dency relation with other phrases outside of i t .2.5 SharingIn Figure 1, "~(user ) "  is the subject of "~(specify)" and at the same time it is the subJect of" l~( t rans la te ) " .
In such a case, we say"user" isshared by "~ (specify)" and "~ '?
-$  (translate)".Specification of sharing is done by specifying morethan one syntactic heads for the dependent.
So thesharing is decomposed into dependency relations.Useful information on dependency relation is gottenfrom the user's specification of scope and so on, butthis paper discusses learning from correction operationfor dependency and case onlY.3.
Learning MechanismProposed learning mechanism is as follows.3.1 Learning Process(1) PIVOT analyzes a source sentence.
(2) PIVOT displays the analysis result.
(3) A user corrects mistakes in the analysis result.
(4) After the user finishes asking corrections, PIVOTtranslates the sentence again.
(5) PIVOT asks the user whether translation has been asuccess or not,(O) If the translation is s success, PIVOT stores theanalysis result together with the instruction iteminto an association database.
I f  the translation isa fai lure,  PIVOT does nothing further.3.2 Applying Process(I) PIVOT analyzes a source sentence,(2) If there is ambiguity at s certain stage ofanalysis, PIVOT retrieves data in the associationdatabase.
(3) PIVOT compares the possible analysis structures ofthe given sentence with the analysis resultsaccumulated in the association database.
(4) PIVOT selects the analysis structure that matcheswith the analysis results accumulated in the asso-ciation database.
If no matching occurs, PIVOTselects one structure by further application of theanalysis rules.PIVOT learns correct analysis structures related touser's instruction.
The smallest unit of PIVDT'sanalysis structure, that is, the t r ip let  of syntacticdependent (with particles and voice information), syn-tactic head (with voice information), and the easeACRES bE COUNG-92, NAN'IT.S, 23-28 AOt3"l" 1992 6 9 4 PROC.
OF COLING-92, NAI~'rEs.
AUG. 2.3-28, 1992betmeen them.
combined with the instruction item formsthe learning unit.
The instruction item shoms what thecorrection has been made on, namely, case or dependen-cy correction.
Each learning unit is accumulated in theassociation database.
The database nan be retrievedmith the spelling of the syntactic dependent or head asthe key.
The learning unit corresponds to the follol'ingstructure.mord2 (Syntactic head)ICASEI (Case)Iwordl (Syntactic dependent)Example of the learning process and the applyingprocess is shomn below.
This is the exaaple of correct-ing dependency.\[Translation process at the f i rs t  stage\]Source sentence:(Translation)Possible analysis structures:(Analysis structure 1) (Analysis structure 2)~ look .~  look/ / I \AGT OBJ AGT INS OBJ/ / l \~ ~,~ man ~ :t'J ~'~'~2~ ~ manhe he opera glasses IOBJ OBdi~-~ "~ ~,~  sing ~,~.~ ~ ~,~ 7~singINSkGT:kgent;iV ~;f ~3l'C" OBj:Objectopera l~lasses INS: InstrumentIf there is no information in the associationdatabase, analysis structure 1 is selected by furtherapplication of the rules.Translated sentence:He looked at the man who is singing with operaglasses.\[Instruction by User and the Learning Process\]The user corrects the analysis results.Correction of dependency:The user changes the syntactic head of ":t~,'~q'92~(opera glasses)" from "{1~-9~;5 (sing)" to "~.~(look).
"Translated sentence:lie looked at a singing man with opera glasses,Learning:PIVOT stores the correct analysis structure withdependency as the instruction itea in the associationdatabase.J~& look\INS\~'  9?
~R~ opera glasses\[Applying process\]PIVOT translates another similar sentence.Source sentence:(Translation)Possible analysis structures:(Analysis structure 1) (Analysis structure 2)~,~ look J~  look/ / I \AGT OBJ AGT INS Dad/ / I \~t,l~ 7J~:~ woman ~d~i~- ~l~" ~')' 92"Z' ~ womanI l opera glasses IOBd OBJI~'C~,5  laugh -~->'C~,~;5 laughINSopera glassesDatabase retrieval:PIVOT retr ieves information ill the associationdatabase, because there exist two possible analysisstructures.~& look\INS\~" ~O'~R'C opera glassesWatching:PIVOT succeedsstructure 2.in latching, and selects analysisTranslated sentence;I looked at a laughing woman with opera glasses.3.3 Watching MethodsThe learning mechanism decreases the number ofuser's instructions.
The problem is to find theeffective matching method in the learning mechanism.Ie made experiments on four types of matchingmethods and compared the efficiency of each method.The matching methods are:(1) Restricted exact matching(2) Non-restricted exact matching(3) Restricted best latchingAc'rEs DE COLING-92.
NANTES, 23-28 AO~r 1992 6 9 5 PROC.
OF COLING-92.
NANTEs.
AUG. 23-28.
1992(4) Non-restr ic ted best matchingRestricted exact matching is  a well-known method.This method is used in many f ie lds  now.
There is nostudy about non-restricted exact watching.
Restrictedbest watching is a comparatively new aethod.
Experimentby Wiura\[4\] is the f i r s t .
There is no study about non-res t r i c ted  best satchin?.3.3.1 Restr ic ted Ratchin?
and Non-restr ic ted NatchingIn res t r i c ted  matching, the item in applying processhas to be the same with the ins t ruct ion  item inlearning.
When the items are d i f fe rent ,  PIVOT wi l l  notuse learned data.
For example, i f  the inst ruct ion itemin learning is case, PIVOT wi l l  use the learnedcorrect  ana lys i s  s t ruc ture  only for case se lec t ion .
Itwi l l  not use the data for se lect ion  of dependency ort rans la t ion  equivalent of each word.In non- res t r i c ted  matching, the item in applyingprocess need not be the same with the ins t ruct ion  itemin learning.
For example, i f  the ins t ruct ion  itew inlearning is case, PIVOT wi l l  use th i s  learned data forse lect ion  of dependency and t rans la t ion  equivalent ofeach word as well .The d i f ference between the act ions of res t r i c tedmatching and non- res t r i c ted  matching is  described belo*.Consider a sentence mith two poss ib le  ana lys is  s t ruc -tures.
(Analysis s t ruc ture  1) (Analysis s t ruc ture  2)word5 word5/1 \  / \CASEI CASE3 CASE4 CASEI CASEd/ I \ / \wordl word3 word4 wordl worddI / \CASE2 CA.~E5 OASE6I / \word2 word2 word3Assume the following analysis structure is alreadylearned by correct ing case.word4/CkSE5/word2Using res t r i c ted  matching, the system se lec ts  s t ruc -ture 1 with i t s  usual ana lys is  procedure.
In th i s  case,data learned by case correct ion cannot be used inselection of dependenc~.
Using non-restricted matching,the system se lec ts  s t ructure  R, because the learnedpattern matches with the part  of s t ruc ture  2.3.3.2 Exact Watching and Best MatchingExact matching makes matching only once.
while bestmatching makes matching several times.
Best matching isalso called associative reasonin?.The d i f ference of act ions  between the two methods isillustrated below.wsrd2(head)/CASEI bet (CI,KR,Wl) stand for the learned/ s t ruc ture  as shown on the le f t .wordl(dependent)Suppose that the fol lowing data is  accumulated inthe assoc iat ion  database through dependency inst ruc-t ions .
(C4,W3,~7)(C3,W3,~Z)(C3,W5,~7)(Cl,WZ,~O)(Cl,W3,Wl)(C1,~5,\[1)(~,w3,w~)Exact matching:\[Assumption\]There are two poss ib le  syntact i c  heads, W7 and W3,for W2.\[Action\]The association database is searched for patterns(x.#T,WB) and (~,W3.#2).
(?
:don't care)Database Search pattern Watching(C4,W3,W?
)(C3,W3.12) (~.W3,W2) (C3==*,W3::W3,Wg==W2)Success(C~,15A7)(Cl,WR,w6)(CI ,W3,l l )(CI.WS,W\])(CZ,~3,W6)(C3,W3,WR) is selected as the correct answer.Best matching:\[Assumption\]There are two possible syntactic heads, W7 and 15,for W2.\[Action\]First, the association database is searched forpatterns (x,W7,W2) and (~.|5,W2).
(x:don't care)Database Search pattern Batching(c~,w3,wT)(~,W3,W2) (x,W7,WB) (C3::*,W3!=W7, W2==W2) Fai l(~,W5,W2) (C3:=x,W3!=W5,W2==W2) Fai l(c3,wS,WT)(CI,W2,W6)(CI,W3,Wl)(CI,W5,\[I)(Ce,W3,~8)In th is  case, there is no data that exact ly  matchesA(.TES DE COLING-92,  NANrl~, 23-28 AOt~'r 1992 6 9 6 Pgoc.
o1: COLING-92,  NANTES, AUG. 23-28, 1992with search patterns.
However, there is data (C3,W3,\[2)that matches mith syntactic dependent.
The systemretrieves more information in the database so as todecide mhich of W5 and W7 is more similar to W3.Searching database for patterns (=,x,W3) and (x,W3,*),the following data is obtained.
(C4,W3,WT)(C3,W3,W2) Let this set of data be called(C1,W3,WI) "database(W3).
"(cz,w3,w6)Searching database for patterns (*,*,WT) and (*,WT,*),the following data is obtained.
(C4,W3,W7) Let this set of data be called(C3,W5,W7) "database(W7).
"Searching database for patterns (~,~,W5) and (=.W5,x),the following data is obtained.
(C3,W5.WT) Let this set of data be called(C1,WB,W1) "database(15).
"On the assumption that W3 is tbe same as W7, thesystem performs exact matching between database(W3) anddatabase(W7).
In the following, \[W3\] is regarded as WT.Database(W3) Database(W7)(~,\[W3\], I7) (C4,W3,W7)(C3,\[W3U,IZ)(Cl,\[W3\],\[l)(C2,\[W3\],V6)(C3,WS,W7)WatchingFailbecause \[W3\]:=WTl=%3.FailOn the assumption that W3 is the same as W5, thesystem performs exact matching between database(W3) anddatabase(WB).
In the following, \[W3\] is regarded as WS.Database(W3) Oatabase(WS) Watching(CA, \[W3\],WT) (03,W5,WT) (C4!=C3,\[I3\]==WS,WT=:W?
)Fail(CI==CI,\[~3\]==WS,Wl==W1)Success(C:3,\[W3\],W2)(CI,\[W3\],Wl) (C1,WB,WI)(C2.\[W3\].W6)Because the number of matches between database(W3)and databaso(WB) is larger than that between date-base(W3) and database(W7), W5 is considered to be moresimilar to W3 than W7.
IS is selected as the head.3.3.3 Natching AlgorithmLet PDBi(PCi,PHi,PHi.PTi) (l<=i<=n) be a possibleanalysis structure, wherePCi: Case.
PHi: Head, PDi:Bependent, PTi:Item.PDB is called "possible analysis structures database".Let ADBk(ACk,AHk,ADk.ATk) (l<=k<=m) be an associ-ation database ntry, xhereACk: Case, AHk: Head, hOk:Dependent, ITk:Item.ADB is called "association database".Matching algorithm for dependency selection is shownbelom.
All PDi's in PDH are supposed to be the sameand lost of PCi's in PDB are supposed to be "don'tcare" for ease of understanding.First Step:Extract al l  hDBk's such that PDi==AHk(l<=i<=n, l<=k<=m) from ADB and create SADBj(SCj,SHj,SDj,STj) (l<=j<=p), mhereSCJ: Case, SHj: Head, SDJ:Dependent, STj:Item.SADB is a subset of ADH.I f  nothing is in SADB, stop search and return fa i l .Second Step:(l)Rostricted exact matchingLet WORK be an empty database.for i=l to nfor j=l to pi f  (SCj::PCi & SHj==Ptli & STj=:PTi)then add PDBi to WORK;endifendendreturn WORK;(2)Hoe-restricted exert matchingLet WORK be an empty database.for i=l to nfor j=l to pif (SCj==PCi & SHj==PHi)then add PDBi to WORK;endifendendreturn WORK;(3)Restricted best matchingLet WBRKI, WORK2 be empty databases.cnt=O;?
for i=1 to nfor j=l to pi f  (SCj==PCi & SHim=PHi & STj==PTi)thee add POBi to WflRKI;endifelse if (SCJ--PCi & SIU!=PHi & STJ==PTi &WOBKI==NULL)then/~ Calculate the similarity betweenSIIj and PHi.
=/extract al l  AgHk's such thatARk==SHj or AHR==Stlj (l<=k<=m)and create database X;extract al l  kDBk's such thatkHk==Ptli or kOk=Plli (l<=k<==)and create database Y;assume SHj==PHi and perform restr ictedexact matching between X and Y;Let cntl be the number of matchedentries between X and Y;if (cntl>O & cntl==cnt)then add PDBi to WORK2;endif/x Cat is tbe largest number of matchesACRES DE COLING-92, NANTES, 23-28 Ao{rr 1992 6 9 7 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992made betmeen X end Y, shoming thede~ree of s imi lar ity betmeen them.
*/else if (cntl>cnt)thencnt=cntl;clear fORK2;add PURl to WORK2;endifendifendendI f  (WORKI l= NULL)then return IORXI;endifelse return IORX2;(4)Non-restricted best matchingThe algorithm is the same as (3) except that non-restr icted exact matching is performed between X and Yinstead of restr icted exact matching.In the above, i f  more than one entries are in WORKor WORX1, the system mill select one that is mostrecently stored by the user 's  instruction.
If WORX2 hasmore than one entries, one entry will be selected byfurther application of the rules.Watching algorithm for case selection is similar tothat for dependency selection.4.
ExperimentsExperiments have been made to evaluate the effectof learning mechanism described in Section 3 by simula-tion.
In the experiments, the instruction iteas werelimited to case and dependency.k total of 1565 sentences were collected from sixkinds of technical manuals, These sentences mere trans-lated with PIVOT/J6.
Using the analysis edit ing func-tion stated previously, correction of mistakes independencies and cases were made.After al l  errors in the analysis results of thewhole text were corrected, correction information forcase end dependency was extracted and put into s f i le .k tool which simulates learning mechanism us prepared.After reading the f i l e  which stores the correctioninfor lat ion,  it counts the number of corrections to be=~e in each of the fol loaing eases: no application ofthe learned data, application with restr icted exactmatching, application with restr icted best matching,application with non-restricted exact matching and withnon-restricted best uteh ing.The results  are shown in the table and the graphbeloa.
The value is the sum of the estimated number ofthe corrections and the estimated number of the recor-factions needed to cancel the secondary effect.Table 1DX0A0nX0AeNumber of SentencesWithout LearningRestricted Exact WatchingRestricted Best WatchingNon-restricted Exact NatehingNon-restricted Best WatchingText i Text 2 Text 3 Text 4220 456 713 920112 220 345 37281 137 236 26276 127 217 2437B 131 232  25177 123 218: 238Text 5 Text 61138 1565447 760301 576!271 414289 524266 380Gr&ph 1888o 788o 688t~588oo ?88o 3BB288188ZBBx| xtoxnx ?x488 88fl 1280 I6flBNumber  o f  SentencesThe results are shown in order of effectiveness.1 non-restricted best matching2 restr icted best matching3 non-restricted exact matchingd restricted exact matching5 without learningNon-restricted best matching is the most effectiveamong the five methods.5.
ConclusionThis paper discussed the learning mechanism fordependency and case corrected by the user.
The learneddata is accumulated in the association database.
Fourtypes of matchins methods that are used in the applyingprocess mere examined.
The simulation sboms that non-restr icted best latching is the lost  effective alongthe four types.The \]earning mechanism discussed above is alsoeffective for selection of a translation equivalent.This mechanism will be incorporated in PIVOT, takingover the current learning mechanism for selection oftranslat ion equivalents.ACI'ES DE COTING-92, NANTES, 23-28 AOIYI" 1992 6 9 8 PREC.
OF COLING-92.
NAh-rES, AUO.
:23-28, 1992ReferencesI.
Nslao.M.
: "k Framework of a Mechanical Translationbetween Japanese and Entlish by knalogy Principle',in Artif icial  and Human Intelligence (Elithorn &BsnerJi, Eds.
), Elsevier Science Publishers, pp173-180, 1984.Z.
Shirai,K., Hayashi,Y., Hirata,Y., and Kubota,J.
:"Database Formulation and Lesrnint Procedure forXaknri-Uko Dependency knalrsis", Transactions ofIPSJ, Vol.20 No.4, 19BS(in Japanese).3.
StanfilI,C.
and h l t z ,B .
:  "Toward Weaory-BasedReasoning", CACW, 29-12. pplglJ-lg2B, 1986.4.
Wiurs.K., \[tshashi,S., and Nishino,H.
: "JapaneseText knalysis System with Valency Frame", WDNL 63-4,\[PSJ, 1987(in Japanese).5. lna#aki,H,, Kaboys,K., and Obsshi,F,: "Modificationknslysis using Semantic Psttern ~, WGNL 67-5, IPSJ,lgBS(in Japanese).6.
Sato, S.: "Welory-based Translation H", IGkl 70-3,\[PSJ, 1990(in Japanese).7.
Sumtta,E., and lida,H.
: "Experiments and Prospectsof Example-Based Machine Translation", #GNL BZ-5,IPSJ, 1991.AcrEs DE COLING-92.
NANTES, 23-28 AOUT 1992 6 9 9 PROC.
Or COL1NG-92, NANTES.
AUG. 23-28, 1902
