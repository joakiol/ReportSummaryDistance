Improving Text Segmentation Using LatentSemantic Analysis: A Reanalysis of Choi,Wiemer-Hastings, and Moore (2001)Yves Bestgen?FNRS - Universite?
Catholiquede LouvainChoi, Wiemer-Hastings, and Moore (2001) proposed to use Latent Semantic Analysis (LSA) toextract semantic knowledge from corpora in order to improve the accuracy of a text segmentationalgorithm.
By comparing the accuracy of the very same algorithm, depending on whether or notit takes into account complementary semantic knowledge, they were able to show the benefitderived from such knowledge.
In their experiments, semantic knowledge was, however, acquiredfrom a corpus containing the texts to be segmented in the test phase.
If this hyper-specificityof the LSA corpus explains the largest part of the benefit, one may wonder if it is possible touse LSA to acquire generic semantic knowledge that can be used to segment new texts.
The twoexperiments reported here show that the presence of the test materials in the LSA corpus has animportant effect, but also that the generic semantic knowledge derived from large corpora clearlyimproves the segmentation accuracy.1.
Improving Text Segmentation by Using Complementary Semantic KnowledgeFor the last ten years, many methods have been proposed for the segmentation of textsin topically related units on the basis of lexical cohesion.
The major distinction betweenthese methods is in the contrast between the approaches based exclusively on theinformation contained in the text to be segmented, such as lexical repetition (e.g., Choi2000; Hearst 1997; Heinonen 1998; Kehagias, Pavlina, and Petridis 2003; Utiyama andIsahara 2001), and those approaches that rest on complementary semantic knowledgeextracted from dictionaries and thesauruses (e.g., Kozima 1993; Lin et al 2004; Morrisand Hirst 1991), or from collocations collected in large corpora (Bolshakov and Gelbukh2001; Brants, Chen, and Tsochantaridis 2002; Choi et al 2001; Ferret 2002; Kaufmann1999; Ponte and Croft 1997).
According to their authors, methods that use additionalknowledge allow for a solution to problems encountered when sentences belonging toa unique topic do not share common words due to the use of hyperonyms or synonymsand allow words that are semantically related to be taken as positive evidence fortopic continuity.
Empirical arguments in favor of these methods have been providedrecently by Choi et al (2001) in a study using Latent Semantic Analysis (Latent SemanticIndexing, Deerwester et al 1990) to extract a semantic space from a corpus allowingdetermination of the similarity of meanings of words, sentences, or paragraphs.
By?
Center for Text and Discourse Studies, PSOR, Place du Cardinal Mercier 10, B-1348 Louvain-la-NeuveBelgium?
2006 Association for Computational LinguisticsComputational Linguistics Volume 32, Number 1comparing the accuracy of the very same algorithm according to whether or not it takesinto account complementary semantic knowledge, they were able to show the benefitderived from such knowledge.However, implications of Choi et al?s study for text segmentation and for the useof LSA in natural language processing are unclear due to the methodology employed.In their experiments, semantic knowledge was acquired from a corpus containing thematerials to be segmented in the test phase.
One could speculate whether the largestpart of the benefit obtained thanks to the addition of semantic knowledge was not dueto this hyper-specificity of the LSA corpus (i.e., the inclusion of the test materials).
Ifthis were the case, it would call into question the possibility of using LSA to acquiregeneric semantic knowledge that can be used to segment new texts.
A priori, the prob-lem does not seem serious for at least two reasons.
First, Choi et al?s segmentationprocedure does not rely on supervised learning in which a system learns how toefficiently segment a text from training data.
The LSA corpus only intervenes in anindirect manner by allowing the extraction of semantic proximities between words thatare then used to compute similarities between parts of the text to segment (see Section 2for details).
Second, Choi et al employed a large number of small test samples toevaluate their algorithm, each making up?on average?0.15% of the LSA corpus.
Thepresent study shows, however, that the presence of the test materials in the LSA corpushas an important effect, but also that the generic semantic knowledge derived fromlarge corpora clearly improves the segmentation accuracy.
This conclusion is drawnfrom two experiments in which the presence or absence of the test materials in theLSA corpus is manipulated.
The first experiment is based on the original materialsfrom Choi et al, which consisted of a small corpus (1,000,000 words).
The secondexperiment is based on a much larger corpus (25,000,000 words).
Before reportingthese experiments, Choi?s algorithm and the use of LSA within this framework aredescribed.2.
The Two Versions of Choi?s AlgorithmThe segmentation algorithm proposed by Choi (2000) is made up of the three stepsusually found in any segmentation procedure based on lexical cohesion.
Firstly, thedocument to be segmented is divided into minimal textual units, usually sentences.Then, a similarity index between every pair of adjacent units is calculated.
Each rawsimilarity value is cast on an ordinal scale by taking the proportion of neighboringvalues that are smaller than it.
Lastly, the document is segmented recursively accordingto the boundaries between the units that maximize the sum of the average similaritiesinside the segments thus comprised (divisive clustering).The step of greatest interest here is the one that calculates the inter-sentence sim-ilarities.
The procedure initially proposed by Choi (2000), C99, rests exclusively onthe information contained in the text to be segmented.
According to the vector spacemodel, each sentence is represented by a vector of word frequency count, and thesimilarity between two sentences is calculated by means of the cosine measure betweenthe corresponding vectors.
In a first evaluation based on the procedure described below,Choi showed that its algorithm outperforms several other approaches such as TextTiling(Hearst 1997) and Segmenter (Kan, Klavans, and McKeown 1998).Choi et al (2001) claimed that it was possible to improve the inter-sentence similar-ities index by taking into account the semantic proximities between words estimated onthe basis of Latent Semantic Analysis (LSA).
Briefly stated, LSA rests on the thesis that6Bestgen Improving Text Segmentationanalyzing the contexts in which words occur permits an estimation of their similarity inmeaning (Deerwester et al 1990; Landauer and Dumais 1997).
The first step in the analy-sis is to construct a lexical table containing an information-theoretic weighting of thefrequencies of the words occurrence in each document (i.e.
sentence, paragraph, or text)included in the corpus.
This frequency table undergoes a Singular Value Decompositionthat extracts the most important orthogonal dimensions, and, consequently, discards thesmall sources of variability in term usage.
After this step, every word is represented bya vector of weights indicating its strength of association with each of the dimensions.This makes it possible to measure the semantic proximity between any two words byusing, for instance, the cosine measure between the corresponding vectors.
Proximitybetween any two sentences (or any other textual units), even if these sentences werenot present in the original corpus, can be estimated by computing a vector for eachof these units?which corresponds to the weighted sum of the vectors of the wordsthat compose it?and then by computing the cosine between these vectors (Deerwesteret al 1990).
Choi et al (2001) have shown that using this procedure to compute theinter-sentence similarities results in the previous version of the algorithm (based solelyon word repetition) being outperformed.3.
Experiment 1The aim of this experiment is to determine the impact of the presence of the testmaterials in the LSA corpus on the results obtained by Choi et al (2001).
Does semanticknowledge acquired from a corpus that does not include the test materials also improvethe segmentation accuracy?3.1 MethodThis experiment was based on the procedure and test materials designed by Choi (2000),which was also used by several authors as a benchmark for comparing segmentationsystems (Brants et al 2002; Ferret 2002; Kehagias et al 2003; Utiyama and Isahara2001).
The task consists in finding the boundaries between concatenated texts.
Eachtest sample is a concatenation of ten text segments.
Each segment consisted in the firstn sentences of a randomly selected text from two sub-sections of the Brown corpus.For the present experiment, I used the most general test materials built by Choi (2000),in which the size of the segments within each sample varies randomly from 3 to 11sentences.
It is composed of 400 samples.The analysis related to the comparison between the accuracy of the algorithm whenthe test materials were included in the LSA corpus (Within) and when it was not(Without).
One Within semantic space, which corresponds to the one used by Choi et al,was built using the entire Brown corpus as the LSA corpus.
Four hundred differentWithout spaces were built, one for each test sample, by each time removing from theBrown corpus only the sentences that make this sample.To extract the LSA space and to apply the segmentation algorithm, a series ofparameters had to be set.
First of all, paragraphs were used as documents for buildingthe lexical tables because Choi et al observed that such middle-sized units were moreeffective than shorter units (i.e., sentences).
The words on Choi?s stoplist were removed,as were those that appeared only once in the whole corpus.
Words were not stemmed,as in Choi et al (2001).
To build the LSA space, the singular value decomposition wasrealized using the program SVDPACKC (Berry 1992; Berry et al 1993), and the first7Computational Linguistics Volume 32, Number 1Table 1Error rates and variance (in parentheses) for the Within and the Without conditions.Pk WindowDiffWithin 0.084 (0.005) 0.090 (0.005)Without 0.120 (0.006) 0.126 (0.006)300 singular vectors were retained.
Concerning the segmentation algorithm, I used theversion in which the number of boundaries to be found is imposed, and thus fixed atnine.
An 11 ?
11 rank mask was used for the ordinal transformation, as recommendedby Choi (2000).3.2 ResultsThe segmentation accuracy was evaluated by means of the index reported by Choi et al(2001): the Pk measure of segmentation inaccuracy (Beeferman, Berger, and Lafferty1999), which gives the proportion of sentences that are wrongly predicted to belong tothe same segment or wrongly predicted to belong to different segments.
I also report,for potential future comparison, Pevzner and Hearst?s (2002) WindowDiff index, whichremedies several problems in the Pk measure.Results are provided in Table 1.1 Compared with the Within condition, the perform-ance in the Without condition is definitely worse, as confirmed by t tests for pairedsample (each test sample being used as an observation) that are significant for an alphasmaller than 0.0001.
The C99 algorithm, which does not employ LSA to estimate thesimilarities between the sentences, produces a Pk of 0.13 (Choi et al 2001, Table 3, line 3:No stemming).
It appears that although the Without condition is still better than C99, thebenefit is very small.Before concluding that the presence of the test materials in the LSA corpus stronglymodified the semantic space, an alternative explanation must be considered.
The lossof accuracy in the Without condition could potentially be due to the fact that the wordsindexed in the corresponding LSA spaces are systematically slightly fewer than thosepresent in the Within space.
Removing each test sample led to the loss?on average?of 23 different words out of the 25,847 words that are indexed in the Within space.
Inthe Without spaces, these words are no longer available to estimate the similarity ofthe sentences, whereas they are employed in the Within space.
In order to determinewhether this factor can explain the difference in performance, a complementary analysiswas carried out on the Within space in which, for each test sample, only the wordspresent in the corresponding Without space were taken into account.
In this manner,only the semantic relations can come into play.
Compared with the complete Withinspace, almost no drop in performance was observed: the Pk error rate went from 0.084to 0.085 in the new analysis.
This result indicates that it is not the words selected forthe calculation of the proximities that matter, but the semantic relations in the spacesextracted from the word co-occurrences by the Singular Value Decomposition.1 The error rate is in fact slightly better than that reported by Choi et al (2001).
The difference could bedue to several factors, such as the pre-processing of the Brown corpus (e.g., tokenization and paragraphidentification) or the scaling function applied to the raw frequencies, which was here the standardinformation-theoretic weighting described in Landauer, Foltz, and Laham (1998).8Bestgen Improving Text Segmentation4.
Experiment 2Experiment 1 was conducted on the Choi et al (2001) LSA corpus, a 1,000,000-wordcollection of texts from very different genres and with varied themes.
The smallness ofthe corpus and diversity of the texts could have affected the results at two levels.
First,removing a few sentences of a text should have less impact if the corpus contains alot of texts on similar topics.
Second, a larger corpus would probably also permit theextraction of a more stable and efficient semantic space.
This could produce a greaterdifference between the LSA version of the algorithm and the version that does notuse additional semantic knowledge (C99).
For these reasons, a second experiment wasconducted on the basis of a much larger corpus consisting of the articles publishedduring 1997 and 1998 in the Belgian French-speaking newspaper Le Soir (roughly 52,000articles and 26,000,000 words).
In this corpus, the test materials from each sampleaccount for?on average?0.0066% of the complete corpus.
This second experimentalso made it possible to compare the Within and Without spaces with a Former spacecomposed of articles published in the same newspaper, but during the years 1995 and1996 (roughly 50,000 articles and more than 22,000,000 words).
This condition will showthe possibility of using LSA to build even more generic semantic knowledge, since theLSA corpus is earlier than the text to segment.4.1 MethodThe test materials were extracted from the 1997?1998 corpus following the guidelinesgiven in Choi (2000).
It is composed of 400 samples of ten segments, of which the lengthvaries randomly from 3 to 11 sentences.
Three types of LSA space were composed.
TheWithin space is based on the whole 1997?1998 corpus.
Four hundred different Withoutspaces were built as described in Experiment 1.
Finally, a Former space was built from the1995?1996 corpus.
The parameters employed to build the semantic spaces are identicalto those used in Experiment 1 with one exception: in order to reduce the size of thelexical tables the whole articles and not the paragraphs were used as documents.4.2 ResultsAlthough the results are mostly similar to those obtained in Experiment 1, Table 2 showssome interesting differences.
The discrepancy between the Within and Without conditionis much smaller, even if it remains statistically significant (p < 0.0001).
Using a corpusfrom the same source, but with earlier years, still returns a poorer performance (p <0.0001).
The C99 algorithm, which is not based on LSA, produces a Pk error rate of0.150, a value definitely worse than those obtained with the Without and Former spaces.This confirms the usefulness of semantic knowledge acquired from large corpora inestimating inter-sentence similarities.5.
ConclusionThe two experiments showed that the presence of the test materials in the LSA corpusincreases the algorithm accuracy even when a corpus of more than 25,000,000 words isused.
They also showed that the use of independent semantic knowledge improves thesegmentation accuracy and that this can be observed even when the semantic knowl-edge is extracted from former years of the same source.
This observation underlines9Computational Linguistics Volume 32, Number 1Table 2Error rates and variance (in parentheses) for the Within, Without and Former conditions.Pk WindowDiffWithin 0.069 (0.004) 0.073 (0.004)Without 0.080 (0.004) 0.085 (0.005)Former 0.097 (0.005) 0.101 (0.005)the possibility of building relatively generic semantic knowledge; that is, knowledgewhich could be employed to process new linguistic data, as has been recently proposedin a anaphora resolution algorithm, in a continuous speech recognition system, orin machine translation (Bellegarda 2000; Klebanov and Wiemer-Hastings 2002; Kim,Chang, and Zhang 2003).
A question the present study does not answer concernsthe possibility of employing a corpus drawn from another source, such as anothernewspaper.
Bellegarda (2000) observed in speech recognition tasks that such a semanticspace is definitely less effective.
It is nevertheless possible that evaluating the semanticproximity between two sentences is less affected by the style of composition of thesource than predicting the next word of a statement.Recently, several authors have proposed segmentation algorithms, based mainlyon dynamic programming, that equal or even outperform Choi?s results (Ji and Zha2003, Kehagias et al 2003; Utiyama and Isahara 2001).
These algorithms do not reston additional semantic knowledge.
According to the results of the present study, theycould still be improved by taking into account such knowledge.Finally, this study allows a more general conclusion about the use of LSA for nat-ural language processing.
If one?s objective is to analyze a linguistic phenomenon in alarge corpus such as for instance the factors determining the use of causal connectives(Degand, Spooren, and Bestgen 2004), it is preferable to extract the semantic space fromthe corpus at hand.
The two experiments did indeed show that such specific corporaallow the extraction of a more efficient semantic space.
However, if the objective is totest the effectiveness of an algorithm intended to process new linguistic data on the basisof a semantic space built beforehand, one must avoid including the material to analyzein the LSA corpus since that would produce an over-estimate of the effectiveness of theprocedure.AcknowledgmentsYves Bestgen is research fellow of the BelgianNational Fund for Scientific Research(FNRS).
This work was supported by grantFRFC 2.4535.02 and by a grant (Action deRecherche concerte) of the government of theFrench-language community of Belgium.A previous version was presented at TALN2005 (Traitement Automatique desLangues Naturelles, Dourdan, France).Thanks to the anonymous reviewers fortheir valuable comments.ReferencesBeeferman, Doug, Adam Berger, and JohnLafferty.
1999.
Statistical models for textsegmentation.
Machine Learning,34(1?3):177?210.Bellegarda, Jerome R. 2000.
Large vocabularyspeech recognition with multispanstatistical language models.
IEEETransactions on Speech and Audio Processing,8(1):78?84.Berry, Michael W. 1992.
Large scale singularvalue computations.
InternationalJournal of Supercomputer Applications,6(1):13?49.Berry, Michael W., Theresa Do, GavinO?Brien, Vijay Krishna, and SowminiVaradhan.
1993.
SVDPACKC: version 1.0user?s guide.
Tech.
Rep. CS-93-194,University of Tennessee, Knoxville, TN,October 1993.10Bestgen Improving Text SegmentationBolshakov, Igor A. and Alexander Gelbukh.2001.
Text segmentation into paragraphsbased on local text cohesion.
In Proceedingsof Text, Speech and Dialogue (TSD-2001).Springer-Verlag, Berlin, pages 158?166.Brants, Thorsten, Francine Chen, andIoannis Tsochantaridis.
2002.
Topic-based document segmentation withprobabilistic latent semantic analysis.In Proceedings of CIKM?02, McLean, VA,pages 211?218.Choi, Freddy Y. Y.
2000.
Advances in domainindependent linear text segmentation.
InProceedings of NAACL-00, Seattle, WA,pages 26?33.Choi, Freddy Y. Y., Peter Wiemer-Hastings,and Johanna Moore.
2001.
Latent semanticanalysis for text segmentation.
InProceedings of NAACL?01, Pittsburgh, PA,pages 109?117.Deerwester, Scott, Susan T. Dumais, GeorgeW.
Furnas, Thomas K. Landauer, andRichard Harshman.
1990.
Indexing bylatent semantic analysis.
Journal of theAmerican Society for Information Science,41(6):391?407.Degand, Liesbeth, Wilbert Spooren, andYves Bestgen.
2004.
On the use ofautomatic tools for large scale semanticanalyses of causal connectives.
InProceedings of ACL 2004 Workshopon Discourse Annotation, Barcelona,Spain, pages 25?32.Ferret, Olivier.
2002.
Using collocationsfor topic segmentation and link detection.In Proceedings of COLING 2002, Taipei,Taiwan, pages 260?266.Hearst, Marti.
1997.
TextTiling: Segmentingtext into multi-paragraph subtopicpassages.
Computational Linguistics,23(1):33?64.Heinonen, Oskari.
1998.
Optimalmulti-paragraph text segmentation bydynamic programming.
In Proceedingsof 17th International Conference onComputational Linguistics (COLING-ACL?98), Montreal, Canada,pages 1484?1486.Ji, Xiang and Hongyuan Zha.
2003.Domain-independent text segmentationusing anisotropic diffusion and dynamicprogramming.
In Proceedings of the26th Annual International ACM SIGIRConference on Research and Developmentin Information Retrieval, Toronto, Canada,pages 322?329.Kan, Min-Yen, Judith L. Klavans, andKathleen R. McKeown.
1998.
Linearsegmentation and segment significance.In Proceedings of the 6th InternationalWorkshop of Very Large Corpora, Montreal,Canada, pages 197?205.Kaufmann, Stefan.
1999.
Cohesion andcollocation: Using context vectors in textsegmentation.
In Proceedings of ACL?99,College Park, MD, pages 591?595.Kehagias, Athanasios, Fragkou Pavlina,and Vassilios Petridis.
2003.
Lineartext segmentation using a dynamicprogramming algorithm.
In Proceedingsof the 10th Conference of the EuropeanChapter of the Association for ComputationalLinguistics, Budapest, Hungary,pages 171?178.Kim, Yu-Seop, Jeong-Ho Chang, andByoung-Tak Zhang.
2003.
An empiricalstudy on dimensionality optimization intext mining for linguistic knowledgeacquisition.
In Lecture Notes in ComputerScience, vol.
2637.
Springer-Verlag, Berlin,pages 111?116.Klebanov, Beata and Peter M.Wiemer-Hastings.
2002.
Using LSAfor pronominal anaphora resolution.In Proceedings of the Third InternationalConference on Computational Linguisticsand Intelligent Text Processing,Lecture Notes in Computer Science,vol.
2276, Springer-Verlag, Berlin,pages 197?199.Kozima, Hideki.
1993.
Text segmentationbased on similarity between words.
InProceedings of the 31st Annual Meeting of theAssociation for Computational Linguistics,Columbus, OH, pages 286?288.Landauer, Thomas K. and Susan T. Dumais.1997.
A solution to Plato?s problem: Thelatent semantic analysis theory ofacquisition, induction and representationof knowledge.
Psychological Review,104(2):211?240.Landauer, Thomas K., Peter W. Foltz, andDarrell Laham.
1998.
An Introduction tolatent semantic analysis.
DiscourseProcesses, 25(2?3):259?284.Lin, Ming, Jay F. Nunamaker, Michael Chau,and Hsinchun Chen.
2004.
Segmentationof lecture videos based on text: Amethod combining multiple linguisticfeatures.
In Proceedings of the 37th HawaiiInternational Conference on System Sciences(HICSS-37), Big Island, HI, Track 1,Volume 1, pages 10003.Morris, Jane and Graeme Hirst.
1991.
Lexicalcohesion computed by thesauralrelations as an indicator of the structureof text.
Computational Linguistics,17(1):21?48.11Computational Linguistics Volume 32, Number 1Pevzner, Lev and Marti Hearst.
2002.
Acritique and improvement of an evaluationmetric for text segmentation.
ComputationalLinguistics, 28(1):19?36.Ponte, Jay M. and W. Bruce Croft.
1997.
Textsegmentation by topic.
In Proceedings of the1st European Conference on Research andAdvanced Technology for Digital Libraries,Lecture Notes in Computer Science,vol.
1324, Springer-Verlag, Berlin,pages 120?129.Utiyama, Masao and Hitoshi Isahara.2001.
A statistical model for domain-independent text segmentation.
InProceedings of ACL?2001, Toulouse,France, pages 491?498.12
