Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 145?153,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPAutomatic training of lemmatization rules that handle morphologicalchanges in pre-, in- and suffixes alikeBart JongejanCST-University of CopenhagenNjalsgade 140-142 2300 K?benhavn SDenmarkbartj@hum.ku.dkHercules Dalianis?
?
?DSV, KTH - Stockholm UniversityForum 100, 164 40 Kista, Sweden?Euroling AB, SiteSeekerIgeldammsgatan 22c112 49 Stockholm, Swedenhercules@dsv.su.seAbstractWe propose a method to automatically trainlemmatization rules that handle prefix, infixand suffix changes to generate the lemma fromthe full form of a word.
We explain how thelemmatization rules are created and how thelemmatizer works.
We trained this lemmatizeron Danish, Dutch, English, German, Greek,Icelandic, Norwegian, Polish, Slovene andSwedish full form-lemma pairs respectively.We obtained significant improvements of 24percent for Polish, 2.3 percent for Dutch, 1.5percent for English, 1.2 percent for Germanand 1.0 percent for Swedish compared to plainsuffix lemmatization using a suffix-only lem-matizer.
Icelandic deteriorated with 1.9 per-cent.
We also made an observation regardingthe number of produced lemmatization rules asa function of the number of training pairs.1 IntroductionLemmatizers and stemmers are valuable humanlanguage technology tools to improve precisionand recall in an information retrieval setting.
Forexample, stemming and lemmatization make itpossible to match a query in one morphologicalform with a word in a document in another mor-phological form.
Lemmatizers can also be usedin lexicography to find new words in text mate-rial, including the words?
frequency of use.
Otherapplications are creation of index lists for bookindexes as well as key word listsLemmatization is the process of reducing aword to its base form, normally the dictionarylook-up form (lemma) of the word.
A trivial wayto do this is by dictionary look-up.
More ad-vanced systems use hand crafted or automaticallygenerated transformation rules that look at thesurface form of the word and attempt to producethe correct base form by replacing all or parts ofthe word.Stemming conflates a word to its stem.
A stemdoes not have to be the lemma of the word, butcan be any trait that is shared between a group ofwords, so that even the group membership itselfcan be regarded as the group?s stem.The most famous stemmer is the Porter Stem-mer for English (Porter 1980).
This stemmer re-moves around 60 different suffixes, using rewrit-ing rules in two steps.The paper is structured as follows: section 2discusses related work, section 3 explains whatthe new algorithm is supposed to do, section 4describes some details of the new algorithm, sec-tion 5 evaluates the results, conclusions aredrawn in section 6, and finally in section 7 wemention plans for further tests and improve-ments.2 Related workThere have been some attempts in creatingstemmers or lemmatizers automatically.
Ek-mek?ioglu et al (1996) have used N-grammatching for Turkish that gave slightly betterresults than regular rule based stemming.
Theronand Cloete (1997) learned two-level rules forEnglish, Xhosa and Afrikaans, but only singlecharacter insertions, replacements and additionswere allowed.
Oard et al (2001) used a languageindependent stemming technique in a dictionarybased cross language information retrieval ex-periment for German, French and Italian whereEnglish was the search language.
A four stagebackoff strategy for improving recall was intro-145duced.
The system worked fine for French butnot so well for Italian and German.
Majumder etal.
(2007) describe a statistical stemmer, YASS(Yet Another Suffix Stripper), mainly for Ben-gali and French, but they propose it also forHindi and Gujarati.
The method finds clusters ofsimilar words in a corpus.
The clusters are calledstems.
The method works best for languages thatare basically suffix based.
For Bengali precisionwas 39.3 percent better than without stemming,though no absolute numbers were reported forprecision.
The system was trained on a corpuscontaining 301 562 words.Kanis & M?ller (2005) used an automatictechnique called OOV Words Lemmatization totrain their lemmatizer on Czech, Finnish andEnglish data.
Their algorithm uses two patterntables to handle suffixes as well as prefixes.
Plis-son et al (2004) presented results for a systemusing Ripple Down Rules (RDR) to generatelemmatization rules for Slovene, achieving up to77 percent accuracy.
Matja?
et al (2007) presentan RDR system producing efficient suffix basedlemmatizers for 14 languages, three of which(English, German and Slovene) our algorithmalso has been tested with.Stempel (Bia?ecki 2004) is a stemmer for Pol-ish that is trained on Polish full form ?
lemmapairs.
When tested with inflected out-of-vocabulary (OOV) words Stempel produces 95.4percent correct stems, of which about 81 percentalso happen to be correct lemmas.Hedlund (2001) used two different approachesto automatically find stemming rules from a cor-pus, for both Swedish and English.
Unfortunatelyneither of these approaches did beat the handcrafted rules in the Porter stemmer for English(Porter 1980) or the Euroling SiteSeeker stem-mer for Swedish, (Carlberger et al 2001).Jongejan & Haltrup (2005) constructed atrainable lemmatizer for the lexicographical taskof finding lemmas outside the existing diction-ary, bootstrapping from a training set of full form?
lemma pairs extracted from the existing dic-tionary.
This lemmatizer looks only at the suffixpart of the word.
Its performance was comparedwith a stemmer using hand crafted stemmingrules, the Euroling SiteSeeker stemmer forSwedish, Danish and Norwegian, and also with astemmer for Greek, (Dalianis & Jongejan 2006).The results showed that lemmatizer was as goodas the stemmer for Swedish, slightly better forDanish and Norwegian but worse for Greek.These results are very dependent on the quality(errors, size) and complexity (diacritics, capitals)of the training data.In the current work we have used Jongejan &Haltrup?s lemmatizer as a reference, referring toit as the ?suffix lemmatizer?.3 Delineation3.1 Why affix rules?German and Dutch need more advanced methodsthan suffix replacement since their affixing ofwords (inflection of words) can include both pre-fixing, infixing and suffixing.
Therefore we cre-ated a trainable lemmatizer that handles pre- andinfixes in addition to suffixes.Here is an example to get a quick idea of whatwe wanted to achieve with the new training algo-rithm.
Suppose we have the following Dutch fullform ?
lemma pair:afgevraagd ?
afvragen(Translation: wondered, to wonder)If this were the sole input given to the trainingprogram, it should produce a transformation rulelike this:*ge*a*d ?
***enThe asterisks are wildcards and placeholders.The pattern on the left hand side contains threewildcards, each one corresponding to one place-holder in the replacement string on the right handside, in the same order.
The characters matchedby a wildcard are inserted in the place kept freeby the corresponding placeholder in the replace-ment expression.With this ?set?
of rules a lemmatizer would beable to construct the correct lemma for somewords that had not been used during the training,such as the word verstekgezaagd (Transla-tion: mitre cut):Word verstek ge z a ag dPattern * ge * a * dReplacement *  *  * enLemma verstek  z  ag enTable 1.
Application of a rule to an OOV word.For most words, however, the lemmatizer wouldsimply fail to produce any output, because not allwords do contain the literal strings ge and a anda final d.  We remedy this by adding a one-size-fits-all rule that says ?return the input as output?
:* ?
*146So now our rule set consists of two rules:*ge*a*d ?
***en* ?
*The lemmatizer then finds the rule with the mostspecific pattern (see 4.2) that matches and ap-plies only this rule.
The last rule?s patternmatches any word and so the lemmatizer cannotfail to produce output.
Thus, in our toy rule setconsisting of two rules, the first rule handleswords like gevraagd, afgezaagd,geklaagd, (all three correctly) and getalmd(incorrectly) while the second rule handles wordslike directeur (correctly) and zei (incor-rectly).3.2 Inflected vs. agglutinated languagesA lemmatizer that only applies one rule per wordis useful for inflected languages, a class of lan-guages that includes all Indo-European lan-guages.
For these languages morphologicalchange is not a productive process, which meansthat no word can be morphologically changed inan unlimited number of ways.
Ideally, there areonly a finite number of inflection schemes andthus a finite number of lemmatization rulesshould suffice to lemmatize indefinitely manywords.In agglutinated languages, on the other hand,there are classes of words that in principle haveinnumerous word forms.
One way to lemmatizesuch words is to peel off all agglutinated mor-phemes one by one.
This is an iterative processand therefore the lemmatizer discussed in thispaper, which applies only one rule per word, isnot an obvious choice for agglutinated lan-guages.3.3 Supervised trainingAn automatic process to create lemmatizationrules is described in the following sections.
Byreserving a small part of the available trainingdata for testing it is possible to quite accuratelyestimate the probability that the lemmatizerwould produce the right lemma given any un-known word belonging to the language, evenwithout requiring that the user masters the lan-guage (Kohavi 1995).On the downside, letting a program constructlemmatization rules requires an extended list offull form ?
lemma pairs that the program canexercise on ?
at least tens of thousands and pos-sibly over a million entries (Dalianis and Jonge-jan 2006).3.4 Criteria for successThe main challenge for the training algorithm isthat it must produce rules that accurately lemma-tize OOV words.
This requirement translates totwo opposing tendencies during training.
On theone hand we must trust rules with a wide basis oftraining examples more than rules with a smallbasis, which favours rules with patterns that fitmany words.
On the other hand we have the in-compatible preference for cautious rules withrather specific patterns, because these must bebetter at avoiding erroneous rule applicationsthan rules with generous patterns.
The envisagedexpressiveness of the lemmatization rules ?
al-lowing all kinds of affixes and an unlimitednumber of wildcards ?
turns the challenge into adifficult balancing act.In the current work we wanted to get an ideaof the advantages of an affix-based algorithmcompared to a suffix-only based algorithm.Therefore we have made the task as hard as pos-sible by not allowing language specific adapta-tions to the algorithms and by not subdividingthe training words in word classes.4 Generation of rules and look-up datastructure4.1 Building a rule set from training pairsThe training algorithm generates a data structureconsisting of rules that a lemmatizer must trav-erse to arrive at a rule that is elected to fire.Conceptually the training process is as fol-lows.
As the data structure is being built, the fullform in each training pair is tentatively lemma-tized using the data structure that has been cre-ated up to that stage.
If the elected rule producesthe right lemma from the full form, nothingneeds to be done.
Otherwise, the data structuremust be expanded with a rule such that the newrule a) is elected instead of the erroneous ruleand b) produces the right lemma from the fullform.
The training process terminates when thefull forms in all pairs in the training set are trans-formed to their corresponding lemmas.After training, the data structure of rules ismade permanent and can be consulted by a lem-matizer.
The lemmatizer must elect and fire rulesin the same way as the training algorithm, so thatall words from the training set are lemmatizedcorrectly.
It may however fail to produce the cor-rect lemmas for words that were not in the train-ing set ?
the OOV words.1474.2 Internal structure of rules: prime andderived rulesDuring training the Ratcliff/Obershelp algorithm(Ratcliff & Metzener 1988) is used to find thelongest non-overlapping similar parts in a givenfull form ?
lemma pair.
For example, in the pairafgevraagd ?
afvragenthe longest common substring is vra, followedby af and g. These similar parts are replacedwith wildcards and placeholders:*ge*a*d ?
***enNow we have the prime rule for the training pair,the least specific rule necessary to lemmatize theword correctly.
Rules with more specific patterns?
derived rules ?
can be created by adding char-acters and by removing or adding wildcards.
Arule that is derived from another rule (derived orprime) is more specific than the original rule:Any word that is successfully matched by thepattern of a derived rule is also successfullymatched by the pattern of the original rule, butthe converse is not the case.
This establishes apartial ordering of all rules.
See Figures 1 and 2,where the rules marked ?p?
are prime rules andthose marked ?d?
are derived.Innumerous rules can be derived from a rulewith at least one wildcard in its pattern, but onlya limited number can be tested in a finite time.To keep the number of candidate rules withinpractical limits, we used the strategy that the pat-tern of a candidate is minimally different from itsparent?s pattern: it can have one extra literalcharacter or one wildcard less or replace onewildcard with one literal character.
Alternatively,a candidate rule (such as the bottom rule in Fig-ure 4) can arise by merging two rules.
Withinthese constraints, the algorithm creates all possi-ble candidate rules that transform one or moretraining words to their corresponding lemmas.4.3 External structure of rules: partial or-dering in a DAG and in a treeWe tried two different data structures to storenew lemmatizer rules, a directed acyclic graph(DAG) and a plain tree structure with depth first,left to right traversal.The DAG (Figure 1) expresses the completepartial ordering of the rules.
There is no prefer-ential order between the children of a rule and allpaths away from the root must be regarded asequally valid.
Therefore the DAG may lead toseveral lemmas for the same input word.
For ex-ample, without the rule in the bottom part of Fig-ure 1, the word gelopen would have been lem-matized to both lopen (correct) and gelopen(incorrect):gelopen:*ge* ?
**   lopen*pen ?
*pen  gelopenBy adding a derived rule as a descendent of boththese two rules, we make sure that lemmatizationof the word gelopen is only handled by onerule and only results in the correct lemma:gelopen:*ge*pen ?
**pen  lopenFigure 1.
Five training pairs as supporters forfive rules in a DAG.The tree in Figure 2 is a simpler data structureand introduces a left to right preferential orderbetween the children of a rule.
Only one rulefires and only one lemma per word is produced.For example, because the rule *ge* ?
** pre-cedes its sibling rule *en ?
*, whenever theformer rule is applicable, the latter rule and itsdescendents are not even visited, irrespective oftheir applicability.
In our example, the formerrule ?
and only the former rule ?
handles thelemmatization of gelopen, and since it pro-duces the correct lemma an additional rule is notnecessary.In contrast to the DAG, the tree implementsnegation: if the Nth sibling of a row of childrenfires, it not only means that the pattern of the Nthrule matches the word, it also means that the pat-terns of the N-1 preceding siblings do not matchthe word.
Such implicit negation is not possiblein the DAG, and this is probably the main reasonwhy the experiments with the DAG-structurelead to huge numbers of rules, very little gener-* ?
*ui ?
ui*ge* ?
**overgegaan ?
overgaan*en ?
*uien?
ui*pen ?
*penlopen ?
lopen*ge*pen ?
**pengelopen ?
lopenpp pdd148alization, uncontrollable training times (months,not minutes!)
and very low lemmatization qual-ity.
On the other hand, the experiments with thetree structure were very successful.
The buildingtime of the rules is acceptable, taking small re-cursive steps during the training part.
The mem-ory use is tractable and the quality of the resultsis good provided good training material.Figure 2.
The same five training pairs as sup-porters for only four rules in a tree.4.4 Rule selection criteriaThis section pertains to the training algorithmemploying a tree.The typical situation during training is that arule that already has been added to the treemakes lemmatization errors on some of the train-ing words.
In that case one or more correctivechildren have to be added to the rule1.If the pattern of a new child rule only matchessome, but not all training words that are lemma-tized incorrectly by the parent, a right siblingrule must be added.
This is repeated until alltraining words that the parent does not lemmatizecorrectly are matched by the leftmost child ruleor one of its siblings.A candidate child rule is faced with trainingwords that the parent did not lemmatize correctlyand, surprisingly, also supporters of the parent,because the pattern of the candidate cannot dis-criminate between these two groups.On the output side of the candidate appear thetraining pairs that are lemmatized correctly bythe candidate, those that are lemmatized incor-1 If the case of a DAG, care must be taken that thecomplete representation of the partial ordering ofrules is maintained.
Any new rule not only becomes achild of the rule that it was aimed at as a correctivechild, but often also of several other rules.rectly and those that do not match the pattern ofthe candidate.For each candidate rule the training algorithmcreates a 2?3 table (see Table 2) that counts thenumber of training pairs that the candidate lem-matizes correctly or incorrectly or that the candi-date does not match.
The two columns count thetraining pairs that, respectively, were lemmatizedincorrectly and correctly by the parent.
These sixparameters Nxy can be used to select the best can-didate.
Only four parameters are independent,because the numbers of training words that theparent lemmatized incorrectly (Nw) and correctly(Nr) are the same for all candidates.
Thus, afterthe application of the first and most significantselection criterion, up to three more selectioncriteria of decreasing significance can be appliedif the preceding selection ends in a tie.ParentChildIncorrect Correct(supporters)Correct  Nwr NrrIncorrect  Nww NrwNot matched Nwn NrnSum Nw NrTable 2.
The six parameters for rule selectionamong candidate rules.A large Nwr and a small Nrw are desirable.
Nwr is ameasure for the rate at which the updated datastructure has learned to correctly lemmatizethose words that previously were lemmatizedincorrectly.
A small Nrw indicates that only fewwords that previously were lemmatized correctlyare spoiled by the addition of the new rule.
It isless obvious how the other numbers weigh in.We have obtained the most success with crite-ria that first select for highest Nwr + Nrr - Nrw .
Ifthe competition ends in a tie, we select for lowestNrr among the remaining candidates.
If the com-petition again ends in a tie, we select for highestNrn ?
Nww .
Due to the marginal effect of a fourthcriterion we let the algorithm randomly selectone of the remaining candidates instead.The training pairs that are matched by the pat-tern of the winning rule become the supportersand non-supporters of that new rule and are nolonger supporters or non-supporters of the par-ent.
If the parent still has at least one non-supporter, the remaining supporters and non-supporters ?
the training pairs that the winning* ?
*ui ?
ui*ge* ?
**overgegaan ?
overgaangelopen ?
lopen*en ?
*uien?
ui*pen ?
*penlopen ?
lopenpp pd149candidate does not match ?
are used to select theright sibling of the new rule.5 EvaluationWe trained the new lemmatizer using trainingmaterial for Danish (STO), Dutch (CELEX),English (CELEX), German (CELEX), Greek(Petasis et al 2003), Icelandic (IFD), Norwegian(SCARRIE), Polish (Morfologik), Slovene(Jur?i?
et al 2007) and Swedish (SUC).The guidelines for the construction of thetraining material are not always known to us.
Insome cases, we know that the full forms havebeen generated automatically from the lemmas.On the other hand, we know that the Icelandicdata is derived from a corpus and only containsword forms occurring in that corpus.
Because ofthe uncertainties, the results cannot be used for aquantitative comparison of the accuracy of lem-matization between languages.Some of the resources were already disam-biguated (one lemma per full form) when we re-ceived the data.
We decided to disambiguate theremaining resources as well.
Handling homo-graphs wisely is important in many lemmatiza-tion tasks, but there are many pitfalls.
As weonly wanted to investigate the improvement ofthe affix algorithm over the suffix algorithm, wedecided to factor out ambiguity.
We simplychose the lemma that comes first alphabeticallyand discarded the other lemmas from the avail-able data.The evaluation was carried out by dividing theavailable material in training data and test data inseven different ratios, setting aside between1.54% and 98.56% as training data and the re-mainder as OOV test data.
(See section 7).
Tokeep the sample standard deviation s for the ac-curacy below an acceptable level we used theevaluation method repeated random subsamplingvalidation that is proposed in Voorhees (2000)and Bouckaert & Frank (2000).
We repeated thetraining and evaluation for each ratio with sev-eral randomly chosen sets, up to 17 times for thesmallest and largest ratios, because these ratioslead to relatively small training sets and test setsrespectively.
The same procedure was followedfor the suffix lemmatizer, using the same trainingand test sets.
Table 3 shows the results for thelargest training sets.For some languages lemmatization accuracyfor OOV words improved by deleting rules thatare based on very few examples from the trainingdata.
This pruning was done after the training ofthe rule set was completed.
Regarding the affixalgorithm, the results for half of the languagesbecame better with mild pruning, i.e.
deletingrules with only one example.
For Danish, Dutch,German, Greek and Icelandic pruning did notimprove accuracy.
Regarding the suffix algo-rithm, only English and Swedish profited frompruning.LanguageSuffix%Affix% ?
%N ?1000 nIcelandic 73.2?1.4 71.3?1.5 -1.9 58 17Danish 93.2?0.4 92.8?0.2 -0.4 553 5Norwegian 87.8?0.4 87.6?0.3 -0.2 479 6Greek 90.2?0.3 90.4?0.4 0.2 549 5Slovene 86.0?0.6 86.7?0.3 0.7 199 9Swedish 91.24?0.18 92.3?0.3 1.0 478 6German 90.3?0.5 91.46?0.17 1.2 315 7English 87.5?0.9 89.0?1.3 1.5 76 15Dutch 88.2?0.5 90.4?0.5 2.3 302 7Polish 69.69?0.06 93.88?0.08 24.2 3443 2Table 3.
Accuracy for the suffix and affix algo-rithms.
The fifth column shows the size of theavailable data.
Of these, 98.56% was used fortraining and 1.44% for testing.
The last columnshows the number n of performed iterations,which was inversely proportional to ?N with aminimum of two.6 Some language specific notesFor Polish, the suffix algorithm suffers fromovertraining.
The accuracy tops at about 100 000rules, which is reached when the training setcomprises about 1 000 000 pairs.Figure 3.
Accuracy vs. number of rules for PolishUpper swarm of data points: affix algorithm.Lower swarm of data points: suffix algorithm.Each swarm combines results from six rule setswith varying amounts of pruning (no pruning andpruning with cut-off = 1..5).If more training pairs are added, the number ofrules grows, but the accuracy falls.
The affix al-gorithm shows no sign of overtraining, even150though the Polish material comprised 3.4 milliontraining pairs, more than six times the number ofthe second language on the list, Danish.
See Fig-ure 3.The improvement of the accuracy for Polishwas tremendous.
The inflectional paradigm inPolish (as in other Slavic languages) can be leftfactorized, except for the superlative.
However,only 3.8% of the words in the used Polish datahave the superlative forming prefix naj, andmoreover this prefix is only removed from ad-verbs and not from the much more numerousadjectives.The true culprit of the discrepancy is the greatnumber (> 23%) of words in the Polish data thathave the negative prefix nie, which very oftendoes not recur in the lemma.
The suffix algo-rithm cannot handle these 23% correctly.The improvement over the suffix lemmatizerfor the case of German is unassuming.
To findout why, we looked at how often rules with infixor prefix patterns fire and how well they are do-ing.
We trained the suffix algorithm with 9/10 ofthe available data and tested with the remaining1/10, about 30 000 words.
Of these, 88% werelemmatized correctly (a number that indicates thesmaller training set than in Table 3).German DutchAcc.% Freq % Acc.
% Freq %all 88.1  100.0 87.7 100.0suffix-only 88.7 94.0 88.1 94.9prefix 79.9 4.4 80.9 2.4infix 83.3 2.3 77.4 3.0?
?
?
92.8 0.26 N/A 0.0ge infix 68.6 0.94 77.9 2.6Table 4.
Prevalence of suffix-only rules, rulesspecifying a prefix, rules specifying an infix andrules specifying infixes containing either ?, ?
or?
or the letter combination ge.Almost 94% of the lemmas were created usingsuffix-only rules, with an accuracy of almost89%.
Less than 3% of the lemmas were createdusing rules that included at least one infix sub-pattern.
Of these, about 83% were correctlylemmatized, pulling the average down.
We alsolooked at two particular groups of infix-rules:those including the letters ?, ?
or ?
and thosewith the letter combination ge.
The formergroup applies to many words that display umlaut,while the latter applies to past participles.
Thefirst group of rules, accounting for 11% of allwords handled by infix rules, performed betterthan average, about 93%, while the latter group,accounting for 40% of all words handled by infixrules, performed poorly at 69% correct lemmas.Table 4 summarizes the results for German andthe closely related Dutch language.7 Self-organized criticalityOver the whole range of training set sizes thenumber of rules goes like dNC.
with C<0 , and Nthe number of training pairs.
The value of C andd not only depended on the chosen algorithm, butalso on the language.
Figure 4 shows how thenumber of generated lemmatization rules for Pol-ish grows as a function of the number of trainingpairs.Figure 4.
Number of rules vs. number of trainingpairs for Polish (double logarithmic scale).Upper row: unpruned rule setsLower row: heavily pruned rule sets (cut-off=5)There are two rows of data, each row containingseven data points.
The rules are counted aftertraining with 1.54 percent of the available dataand then repeatedly doubling to 3.08, 6.16,12.32, 24.64, 49.28 and 98.56 percent of theavailable data.
The data points in the upper rowdesignate the number of rules resulting from thetraining process.
The data points in the lowerrow arise by pruning rules that are based on lessthan six examples from the training set.The power law for the upper row of data pointsfor Polish in Figure 4 is87.080.0 trainingrules NN =151As a comparison, for Icelandic the power law forthe unpruned set of rules is90.032.1 trainingrules NN =These power law expressions are derived for theaffix algorithm.
For the suffix algorithm the ex-ponent in the Polish power law expression isvery close to 1 (0.98), which indicates that thesuffix lemmatizer is not good at all at generaliz-ing over the Polish training data: the number ofrules grows almost proportionally with the num-ber of training words.
(And, as Figure 3 shows,to no avail.)
On the other hand, the suffix lem-matizer fares better than the affix algorithm forIcelandic data, because in that case the exponentin the power law expression is lower: 0.88 versus0.90.The power law is explained by self-organizedcriticality (Bak et al 1987, 1988).
Rule sets thatoriginate from training sets that only differ in asingle training example can be dissimilar to anydegree depending on whether and where the dif-ference is tipping the balance between competingrule candidates.
Whether one or the other rulecandidate wins has a very significant effect onthe parts of the tree that emanate as children or assiblings from the winning node.
If the differencehas an effect close to the root of the tree, a largeexpanse of the tree is affected.
If the differenceplays a role closer to a leaf node, only a smallpatch of the tree is affected.
The effect of addinga single training example can be compared withdropping a single rice corn on top of a pile ofrice, which can create an avalanche of unpredict-able size.8 ConclusionsAffix rules perform better than suffix rules if thelanguage has a heavy pre- and infix morphologyand the size of the training data is big.
The newalgorithm worked very well with the Polish Mor-fologik dataset and compares well with theStempel algorithm (Bia?ecki 2008).Regarding Dutch and German we have ob-served that the affix algorithm most often appliessuffix-only rules to OOV words.
We have alsoobserved that words lemmatized this way arelemmatized better than average.
The remainingwords often need morphological changes in morethan one position, for example both in an infixand a suffix.
Although these changes are corre-lated by the inflectional rules of the language, thenumber of combinations is still large, while atthe same time the number of training examplesexhibiting such combinations is relatively small.Therefore the more complex rules involving infixor prefix subpatterns or combinations thereof areless well-founded than the simple suffix-onlyrules.
The lemmatization accuracy of the com-plex rules will therefore in general be lower thanthat of the suffix-only rules.
The reason why theaffix algorithm is still better than the algorithmthat only considers suffix rules is that the affixalgorithm only generates suffix-only rules fromwords with suffix-only morphology.
The suffix-only algorithm is not able to generalize overtraining examples that do not fulfil this conditionand generates many rules based on very few ex-amples.
Consequently, everything else beingequal, the set of suffix-only rules generated bythe affix algorithm must be of higher quality thanthe set of rules generated by the suffix algorithm.The new affix algorithm has fewer rules sup-ported by only one example from the trainingdata than the suffix algorithm.
This means thatthe new algorithm is good at generalizing oversmall groups of words with exceptional mor-phology.
On the other hand, the bulk of ?normal?training words must be bigger for the new affixbased lemmatizer than for the suffix lemmatizer.This is because the new algorithm generates im-mense numbers of candidate rules with onlymarginal differences in accuracy, requiring manyexamples to find the best candidate.When we began experimenting with lemmati-zation rules with unrestricted numbers of affixes,we could not know whether the limited amountof available training data would be sufficient tofix the enormous amount of free variables withenough certainty to obtain higher quality resultsthan obtainable with automatically trained lem-matizers allowing only suffix transformations.However, the results that we have obtainedwith the new affix algorithm are on a par with orbetter than those of the suffix lemmatizer.
Thereis still room for improvements as only part of theparameter space of the new algorithm has beensearched.
The case of Polish shows the superior-ity of the new algorithm, whereas the poor re-sults for Icelandic, a suffix inflecting languagewith many inflection types, were foreseeable,because we only had a small training set.9 Future workWork with the new affix lemmatizer has untilnow focused on the algorithm.
To really know ifthe carried out theoretical work is valuable wewould like to try it out in a real search setting ina search engine and see if the users appreciatethe new algorithm?s results.152ReferencesPer Bak, Chao Tang and Kurt Wiesenfeld.
1987.
Self-Organized Criticality: An Explanation of 1/f Noise,Phys.
Rev.
Lett., vol.
59,. pp.
381-384, 1987Per Bak, Chao Tang and Kurt Wiesenfeld .
1988.Phys.
Rev.
A38, (1988), pp.
364-374Andrzej Bia?ecki, 2004, Stempel - AlgorithmicStemmer for Polish Languagehttp://www.getopt.org/stempel/Remco R. Bouckaert and Eibe Frank.
2000.
Evaluat-ing the Replicability of Significance Tests forComparing Learning Algorithms.
In H. Dai, R.Srikant, & C. Zhang (Eds.
), Proc.
8th Pacific-AsiaConference, PAKDD 2004, Sydney, Australia,May 26-28, 2004 (pp.
3-12).
Berlin: Springer.Johan Carlberger, Hercules Dalianis, Martin Hassel,and Ola Knutsson.
2001.
Improving Precision inInformation Retrieval for Swedish using Stem-ming.
In the Proceedings of NoDaLiDa-01 - 13thNordic Conference on Computational Linguistics,May 21-22, Uppsala, Sweden.Celex: http://celex.mpi.nl/Hercules Dalianis and Bart Jongejan 2006.
Hand-crafted versus Machine-learned Inflectional Rules:the Euroling-SiteSeeker Stemmer and CST's Lem-matiser, in Proceedings of the International Con-ference on Language Resources and Evaluation,LREC 2006.F.
?una Ekmek?ioglu, Mikael F. Lynch, and PeterWillett.
1996.
Stemming and N-gram matching forterm conflation in Turkish texts.
Information Re-search, 7(1) pp 2-6.Niklas Hedlund 2001.
Automatic construction ofstemming rules, Master Thesis, NADA-KTH,Stockholm, TRITA-NA-E0194.IFD: Icelandic Centre for Language Technology,http://tungutaekni.is/researchsystems/rannsoknir_12en.htmlBart Jongejan and Dorte Haltrup.
2005.
The CSTLemmatiser.
Center for Sprogteknologi, Universityof Copenhagen version 2.7 (August, 23 2005)http://cst.dk/online/lemmatiser/cstlemma.pdfJakub Kanis  and  Ludek M?ller.
2005.
AutomaticLemmatizer Construction with Focus on OOVWords Lemmatization in Text, Speech and Dia-logue, Lecture Notes in Computer Science, Berlin /Heidelberg, pp 132-139Ron Kohavi.
1995.
A study of cross-validation andbootstrap for accuracy estimation and model selec-tion.
Proceedings of the Fourteenth InternationalJoint Conference on Artificial Intelligence 2 (12):1137?1143, Morgan Kaufmann, San Mateo.Prasenjit Majumder, Mandar Mitra, Swapan K. Parui,Gobinda Kole, Pabitra Mitra, and KalyankumarDatta.
2007.
YASS: Yet another suffix stripper.ACM Transactions on Information Systems , Vol-ume 25 ,  Issue 4, October 2007.Jur?i?
Matja?, Igor Mozeti?, and Nada Lavra?.
2007.Learning ripple down rules for efficient lemmatiza-tion In proceeding of the Conference on Data Min-ing and Data Warehouses (SiKDD 2007), October12, 2007, Ljubljana, SloveniaMorfologik: Polish morphological analyzerhttp://mac.softpedia.com/get/Word-Processing/Morfologik.shtmlDouglas W. Oard, Gina-Anne Levow, and Clara I.Cabezas.
2001.
CLEF experiments at Maryland:Statistical stemming and backoff translation.
InCross-language information retrieval and evalua-tion: Proceeding of the Clef 2000 workshops CarolPeters Ed.
Springer Verlag pp.
176-187.
2001.Georgios Petasis, Vangelis Karkaletsis , Dimitra Far-makiotou , Ion Androutsopoulos  and ConstantineD.
Spyropoulo.
2003.
A Greek MorphologicalLexicon and its Exploitation by Natural LanguageProcessing Applications.
In Lecture Notes onComputer Science (LNCS), vol.2563, "Advancesin Informatics - Post-proceedings of the 8th Pan-hellenic Conference in Informatics", Springer Ver-lag.Jo?l Plisson, Nada Lavra?, and Dunja Mladenic.
2004,A rule based approach to word lemmatization,Proceedings of the 7th International Multi-conference Information Society, IS-2004, InstitutJozef Stefan, Ljubljana, pp.83-6.Martin F. Porter 1980.
An algorithm for suffix strip-ping.
Program, vol 14, no 3, pp 130-130.John W. Ratcliff and David Metzener, 1988.
PatternMatching: The Gestalt Approach, Dr. Dobb'sJournal, page 46, July 1988.SCARRIE 2009.
Scandinavian Proofreading Toolshttp://ling.uib.no/~desmedt/scarrie/STO: http://cst.ku.dk/sto_ordbase/SUC 2009.
Stockholm Ume?
corpus,http://www.ling.su.se/staff/sofia/suc/suc.htmlPieter Theron and Ian Cloete 1997 Automatic acquisi-tion of two-level morphological rules, Proceedingsof the fifth conference on Applied natural languageprocessing, p.103-110, March 31-April 03, 1997,Washington, DC.Ellen M. Voorhees.
2000.
Variations in relevancejudgments and the measurement of retrieval effec-tiveness, J. of Information Processing and Man-agement 36 (2000) pp 697-716153
