Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 105?112,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsUnsupervised Name Ambiguity Resolution Using A Generative ModelZornitsa Kozareva and Sujith RaviUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{kozareva,sravi}@isi.eduAbstractResolving ambiguity associated with namesfound on the Web, Wikipedia or medical textsis a very challenging task, which has beenof great interest to the research community.We propose a novel approach to disambiguat-ing names using Latent Dirichlet Allocation,where the learned topics represent the under-lying senses of the ambiguous name.
We con-duct a detailed evaluation on multiple data setscontaining ambiguous person, location and or-ganization names and for multiple languagessuch as English, Spanish, Romanian and Bul-garian.
We conduct comparative studies withexisting approaches and show a substantialimprovement of 15 to 35% in task accuracy.1 IntroductionRecently, ambiguity resolution for names found onthe Web (Artiles et al, 2007), Wikipedia articles(Bunescu and Pasca, 2006), news texts (Pedersen etal., 2005) and medical literature (Ginter et al, 2004)has become an active area of research.
Like words,names are ambiguous and can refer to multiple enti-ties.
For example, a Web search for Jerry Hobbs onGoogle returns a mixture of documents associatedwith two different entities in the top 10 search re-sults.
One refers to a computational linguist at Uni-versity of Southern California and the other refers toa fugitive and murderer.
Disambiguating the namesand identifying the correct entity is very importantespecially for Web search applications since 11-17%of the Web search queries are composed of personname and a term (Artiles et al, 2009a).In the past, there has been a substantial body ofwork in the area of name disambiguation under a va-riety of different names and using diverse set of ap-proaches.
Some refer to the task as cross-documentcoreference resolution (Bagga and Baldwin, 1998),name discrimination (Pedersen et al, 2005) or WebPeople Search (WebPS) (Artiles et al, 2007).
Themajority of the approaches focus on person nameambiguity (Chen and Martin, 2007; Artiles et al,2010), some have also explored organization and lo-cation name disambiguation (Pedersen et al, 2006).The intuition behind most approaches follows thedistributional hypothesis (Harris, 1954) accordingto which ambiguous names sharing the same con-texts tend to refer to the same individual.
To modelthese characteristics, Bunescu and Pasca (2006)and Cucerzan (2007) incorporate information fromWikipedia articles, Artiles et al (2007) use Webpage content, Mann and Yarowsky (2003) extract bi-ographic facts.
The approaches used in the WebPStasks mainly rely on bag-of-words representations(Artiles et al, 2007; Chen and Martin, 2007; Artileset al, 2009b).
Most methods suffer from a com-mon drawback?they rely on surface features suchas word co-occurrences, which are insufficient tocapture hidden information pertaining to the entities(senses) associated with the documents.We take a novel approach for tackling the prob-lem of name ambiguity using an unsupervised topicmodeling framework.
To our knowledge, no onehas yet explored the disambiguation of names usingLatent Dirichlet Allocation (LDA) nor has shownLDA?s behavior on multiple data sources and set-tings.
Our motivation for using an unsupervised105topic modeling framework for name disambiguationis based on the advantages generative models offerin contrast to the existing ones.
For instance, topicmodels such as Latent Dirichlet alocation (LDA)method (Blei et al, 2003) have been widely used inthe literature for other applications to uncover hid-den (or latent) groupings underlying a set of obser-vations.
Topic models are capable of handling ambi-guity and distinguishing between uses of words withmultiple meanings depending on context.
Thereby,they provide a natural fit for our name disambigua-tion task, where latent topics correspond to the en-tities (name senses) representing the documents foran ambiguous name.
Identifying these latent topicshelps us identify the particular sense of a given am-biguous name that is used in the context of a particu-lar document and hence resolve name ambiguity.
Inaddition, this approach offers several advantages?
(1) entities (senses) can be learnt automatically froma collection of documents in an unsupervised man-ner, (2) efficient methods already exist for perform-ing inference in this model so we can easily scaleto Web data, and (3) unlike typical approaches, wecan easily apply our learnt model to resolve nameambiguity for unseen documents.The main contributions of this paper are:?
We propose a novel model for name disam-biguation using Latent Dirichlet Allocation.?
Unlike previous approaches, which are de-signed for specific tasks, corpora and lan-guages, we conduct a detailed evaluation takinginto consideration the multiple properties of thedata and names.?
Our experimental study shows that LDA can beused as a general name disambiguation frame-work, which can be successfully applied onany corpora (i.e.
Web, news, Wikipedia), lan-guages (i.e.
English, Spanish, Romanian andBulgarian) and types of ambiguous names (i.e.people, organizations, locations).?
We conduct a comparative study with existingstate-of-the-art clustering approaches and showsubstantial improvements of 15 to 35% in taskaccuracy.The rest of the paper is organized as follows.
In Sec-tion 2 we describe related work.
Section 3 describesthe Latent Dirichlet Allocation model used to dis-ambiguate the names.
Section 4 describes the exper-iments we have conducted on multiple data sets andlanguages.
Finally, we conclude in Section 5.2 Related WorkAmbiguous names have been disambiguated withvarying success from structured texts (Pedersen etal., 2006), semi-structured texts such as Wikipediaarticles (Bunescu and Pasca, 2006; Cucerzan, 2007)or unstructured texts such as those found on the Web(Pedersen and Kulkarni, 2007; Artiles et al, 2009b).Most approaches (Artiles et al, 2009b; Chen et al,2009; Lan et al, 2009) focus on person name dis-ambiguation, while others (Pedersen et al, 2006)also explore ambiguity in organization and locationnames.
In the medical domain, Hatzivassiloglou etal.
(2001) and Ginter et al (2004) tackle the problemof gene and protein name disambiguation.Due to the high interest in this task, researchershave explored a wide range of approaches and fea-tures.
Among the most common and efficient onesare those based on clustering and bag-of-words rep-resentation (Pedersen et al, 2005; Artiles et al,2009b).
Mann and Yarowsky (2003) extract bio-graphic facts such as date or place of birth, occu-pation, relatives among others to help resolve am-biguous names of people.
Others (Bunescu andPasca, 2006; Cucerzan, 2007; Nguyen and Cao,2008) work on Wikipedia articles, using infoboxand link information.
Pedersen et al (2006) relyon second order co-occurrence vectors.
A few oth-ers (Matthias, 2005; Wan et al, 2005; Popescu andMagnini, 2007) identify names of people, locationsand organizations and use them as a source of evi-dence to measure the similarity between documentscontaining the ambiguous names.
The most simi-lar work to ours is that of Song et al (2007) whouse a topic-based modeling approach for name dis-ambiguation.
However, their method explicitly triesto model the distribution of latent topics with regardto person names and words appearing within docu-ments whereas in our method, the latent topics rep-resent the underlying entities (name senses) for anambiguous name.Unlike the previous approaches which werespecifically designed and evaluated on the WebPS106task or a corpus such as Wikipedia or the Web, inthis paper we show a novel unsupervised topic mod-eling approach for name disambiguation for any cor-pora (i.e.
Web, news, Wikipedia), languages (i.e.English, Spanish, Romanian and Bulgarian) and se-mantic categories (i.e.
people, location and organi-zation).
The obtained results show substantial im-provements over the existing approaches.3 Name Disambiguation with LDARecently, topic modeling methods have foundwidespread applications in NLP for varioustasks such as summarization (Daume?
III andMarcu, 2006), inferring concept-attribute attach-ments (Reisinger and Pasca, 2009), selectionalpreferences (Ritter et al, 2010) and cross-documentco-reference resolution (Haghighi and Klein, 2010).Topic models such as LDA are generative modelsfor documents and represent hidden or latent top-ics (where a topic is a probability distribution overwords) underlying the semantic structure of docu-ments.
An important use for methods such as LDAis to infer the set of topics associated with a givendocument (or a collection of documents).
Next, wepresent a novel approach for the task of name dis-ambiguation using unsupervised topic models.3.1 Method DescriptionGiven a document corpus D associated with a cer-tain ambiguous name, our task is to group the docu-ments into K sets such that each document set cor-responds to one particular entity (sense) for the am-biguous name.
We first formulate the name disam-biguation problem as a topic modeling task and thenapply the standard LDA method to infer hidden top-ics (senses).
Our generative story is as follows:for each name sense sk where k ?
{1, ...,K} doGenerate ?sk according to Dir(?
)end forfor each document i in the corpus D doChoose ?i ?
Dir(?
)for each word wi,j where j ?
{1, ..., Ni} doChoose a sense zi,j ?Multinomial(?i)Choose a word wi,j ?Multinomial(?zi,j )end forend for3.2 InferenceWe perform inference on this model using collapsedGibbs sampling, where each of the hidden sensevariables zi,j are sampled conditioned on an as-signment for all other variables, while integratingover all possible parameter settings (Griffiths andSteyvers, 2002).
We use the MALLET (McCallum,2002) implementation of LDA for our experiments.We ran LDA with different parameter settings on aheld out data set and found that the following con-figuration resulted in the best performance.
We setthe hyperparameter ?
to the default value of 0.01.For the name discrimination task, we have to choosefrom a smaller set of name senses and each docu-ment is representative of a single sense, so we usea sparse prior (?=0.1).
On the other hand, the WebPeople Search data is more noisy and also involvesa large number of senses, so we use a higher prior(?=50).For the name discrimination task (Section 4.1),we are given a set of senses to choose from andhence we can use this value to fix the number of top-ics (senses) K in LDA.
However, it is possible thatthe number of senses may be unknown to us apriori.For example, it is difficult to identify all the sensesassociated with names of people on the Web.
In suchscenarios, we set the value ofK to a fixed value.
Forexperiments on Web People Search, we set K = 40,which is roughly the average number of senses as-sociated with people names on the Web.
An alter-native strategy is to automatically choose the num-ber of senses based on the model that leads to thehighest posterior probability (Griffiths and Steyvers,2004).
It is easy to incorporate this technique intoour model, but we leave this for future work.3.3 Interpreting Name Senses From TopicsAs a result of training, our model outputs the topic(sense) distributions for each document in the cor-pus.
Although the LDA model can assign multi-ple senses to a document, the name disambiguationtask specifies that each document should be assignedonly to a single name sense.
Hence, for each docu-ment i we assign it the most probable sense from itssense distribution.
This allows us to cluster all thedocuments in D into K sets.To evaluate our results against the gold standard107data, we further need to find a mapping between ourdocument clusters and the true name sense labels.For each cluster k, we identify the true sense labels(using the gold data) for every document which wasassigned to sense k in our output, and pick the ma-jority sense label labelkmaj.
as being representativeof the entire cluster (i.e., all documents in cluster kwill be labeled as belonging to sense labelkmaj.).
Fi-nally, we evaluate our labeling against the gold data.4 Experimental EvaluationOur objective is to study LDA?s performance onmultiple datasets, name categories and languages.For this purpose, we evaluate our approach on twotasks: name discrimination and Web People Search,which are described in the next subsections.
We usefreely available data from (Pedersen et al, 2006) and(Artiles et al, 2009b), which enable us to compareperformance against existing methods.4.1 Name DiscriminationPedersen et al (2006) create ambiguous data byconflating together tuples of non-ambiguous wellknown names.
The goal is to cluster the contextscontaining the conflated names such that the origi-nal and correct names are re-discovered.
This task isknown as name discrimination.An advantage of the name conflation process isthat data can be easily created for any type of namesand languages.
In our study, we use the whole dataset developed by Pedersen et al (2006) for the En-glish, Spanish, Romanian and Bulgarian languages.Table 1 shows the conflated names and the seman-tic category they belong to (i.e.
person, organizationor location) together with the distribution of the in-stances for each underlying entity in the name.
Intotal there are eight person, eight location and threeorganization conflated name pairs which represent adiverse set of names of politicians, countries, cities,political parties and software companies.
For fourconflated name pairs the data is balanced.
For ex-ample, there are 3800 examples in total for the con-flated name Bill Clinton ?
Tony Blair of which 1900are for the underlying entity Bill Clinton and 1900for Tony Blair.
For the rest of the cases the data isimbalanced.
For example, there are 3344 examplesfor the conflated name Yaser Arafat ?
Bill Clinton ofwhich 1004 belong to Yaser Arafat and 2340 to BillClinton.
The balanced and imbalanced data also letsus study whether LDA?s performance if affected bythe different sense distributions.Next, we show in Table 2 the overall results fromthe disambiguation process.
For each name, we firstshow the baseline score which is calculated as thepercentage of instances belonging to the most fre-quent underlying entity over all instances of thatconflated name pair.
For example, for the Bill Clin-ton ?
Tony Blair conflated name pair, the baselineis 50% since both underlying entities have the samenumber of examples.
This baseline is equivalent toa clustering method that would assign all of the con-texts to exactly one cluster.The second column corresponds to the resultsachieved by the second order co-occurrence cluster-ing approach of (Pedersen et al, 2006).
This ap-proach is considered as state-of-the-art in name dis-crimination after numerous features like unigram,bigram, co-occurrence and multiple clustering algo-rithms were tested.
We denote this approach in Table2 as Pedersen and use it as a comparison.
Note thatin this experiment (Pedersen et al, 2006) predefinethe exact number of clusters, therefore we also usethe exact number of senses for the LDA topics.
Thethird column shows the results obtained by our LDAapproach.
The final two columns represent the dif-ference between our LDA approach and the baselinedenoted as ?B , as well as the difference betweenour LDA approach and those of Pedersen denoted as?P .
We have highlighted in bold the improvementsof LDA over these methods.The obtained results show that for all experimentsindependent of whether the name sense data was bal-anced or imbalanced, LDA has a positive increaseover the baseline.
For some conflated tuples like theSpanish NATO?ETZIN, the improvement over thebaseline is 47%.
For seventeen out of the twentyname conflated pairs LDA has also improved uponPedersen.
The improvements range from +1.29 to+19.18.Unfortunately, we are not deeply familiar withRomanian to provide a detailed analysis of the con-texts and the errors that occurred.
However, we no-ticed that for English, Spanish and Bulgarian oftenthe same context containing two or three of the con-flated names is used multiple times.
Imagine that108Category Name DistributionENGLISHperson/politician Bill Cinton ?
Tony Blair 1900+1900=3800person/politician Bill Clinton ?
Tony Blair ?
Ehud Barak 1900+1900+1900=5700organization IBM ?
Microsoft 2406+3401=5807location/country Mexico ?
Uganda 1256+1256=2512location/country&state Mexico ?
India ?
California ?
Peru 1500+1500+1500+1500=6000SPANISHperson/politician Yaser Arafat ?
Bill Clinton 1004+2340=3344person/politician Juan Pablo II ?
Boris Yeltsin 1447+1450=2897organization OTAN (NATO) ?
EZLN 1093+1093=2186location/city New York ?
Washington 1517+2418=3935location/city&country New York ?
Brasil ?
Washington 1517+1748+2418=5863ROMANIANperson/politician Traian Basescu ?
Adrian Nastase 1804+1932=3736person/politician Traian Basescu ?
Ion Illiescu ?
Adrian Nastase 1948+1966+2301=6215organization Romanian Democratic Party ?
Socialist Party 2037+3264=5301location/city Brasov ?
Bucarest 2310+2559=4869location/country France ?
USA ?
Romania 1370+2396+3890=7656BULGARIANperson/politician Petar Stoyanov ?
Ivan Kostov ?
Georgi Parvanov 318+524+811=1653person/politician Nadejda Mihaylova ?
Nikolay Vasilev ?
Stoyan Stoyanov 645+849+976=2470organization Bulgarian Socialist Party ?
Union Democratic Forces 2921+4680=7601location/country France ?
Germany ?Russia 1726+2095+2645=6466location/city Varna ?
Bulgaria 1240+1261=2501Table 1: Data Set Characteristics of the Name Discrimination Task.Name Baseline Pedersen LDA ?B ?PENGLISHBill Cinton ?
Tony Blair 50.00% 80.95% 81.13% +31.13 +0.18Bill Clinton ?
Tony Blair ?
Ehud Barak 33.33% 47.93% 67.19% +33.86 +19.26IBM ?
Microsoft 58.57% 63.70% 65.44% +6.87 +1.74Mexico ?
Uganda 50.00% 59.16% 78.34% +28.35 +19.18Mexico ?
India ?
California ?
Peru 25.00% 28.78% 46.43% +21.43 +17.65SPANISHYaser Arafat ?
Bill Clinton 69.98% 77.72% 83.67% +13.69 +5.95Juan Pablo II ?
Boris Yeltsin 50.05% 87.75% 52.36% +2.31 -35.39OTAN (NATO) ?
EZLN 50.00% 69.81% 96.89% +46.89 +27.08New York ?
Washington 61.45% 54.66% 66.73% +5.28 +12.07New York ?
Brasil ?
Washington 42.55% 42.88% 59.28% +16.73 +16.40ROMANIANTraian Basescu ?
Adrian Nastase 51.34% 51.34% 58.51% +7.17 +7.17Traian Basescu ?
Ion Illiescu ?
Adrian Nastase 37.02% 39.31% 47.69% +10.67 +8.38Romanian Democratic Party ?
Socialist Party 61.57% 77.70% 61.57% 0.00 -16.13Brasov ?
Bucarest 52.56% 63.67% 64.96% +12.40 +1.29France ?
USA ?
Romania 50.81% 52.66% 55.39% +4.58 +2.73BULGARIANPetar Stoyanov ?
Ivan Kostov ?
Georgi Parvanov 49.06% 58.68% 57.96% +8.90 -0.72Nadejda Mihaylova ?
Nikolay Vasilev ?
Stoyan Stoyanov 39.51% 59.39% 53.97% +14.46 -5.42Bulgarian Socialist Party ?
Union Democratic Forces 61.57% 57.31% 61.76% +0.19 +4.45France ?
Germany ?Russia 40.91% 41.60% 46.74% +5.83 +5.14Varna ?
Bulgaria 50.42% 50.38% 51.78% +1.36 +1.40Table 2: Results on the Multilingual and Multi-category Name Discrimination Task.109there is a single context in which both names Nade-jda Mihaylova and Stoyan Stoyanov are mentioned.This context is used to create two name conflatedexamples.
In the first case only the name NadejdaMihaylova was hidden with the Nadejda Mihaylova?
Nikolay Vasilev ?
Stoyan Stoyanov label while thename Stoyan Stoyanov was preserved as it is.
Inthe second case, the name Stoyan Stoyanov was hid-den with the label Nadejda Mihaylova ?
NikolayVasilev ?
Stoyan Stoyanov while the name NadejdaMihaylova was preserved.
Since the example con-tains two name conflations of the same context, itbecomes very difficult for any algorithm to identifythis phenomenon and discriminate the names cor-rectly.According to a study conducted by (Pedersen etal., 2006), the conflated entities in the automaticallycollected data sets can be ambiguous and can be-long to multiple semantic categories.
For example,they mention that the city Varna occurred in the col-lection as part of other named entities such as theUniversity of Varna, the Townhall of Varna.
There-fore, by conflating the name Varna in the organiza-tion named entity University of Varna, the contextstarts to deviate the meaning of Varna as a city intothe meaning of university.
Such cases transmit ad-ditional ambiguity to the conflated name pair andmake the task even harder.Finally, our current approach does not use stop-words except for English.
According to Pedersen etal.
(2006) the usage of stop-words is crucial for thistask and leads to a substantial improvement.4.2 Web People SearchRecently, Artiles et al (2009b) introduced the WebPeople Search task (WebPS), where given the top100 web search results produced for an ambiguousperson name, the goal is to produce clusters that con-tain documents referring to the same individual.We have randomly selected from the WebPS-2test data three names from the Wikipedia, ACL?08and Census categories.
Unlike the previous data,WebPS has (1) names with higher ambiguity from3 to 56 entities per name, (2) only person names and(3) unstructured and semi-structured texts from theWeb and Wikipedia1.
Table 3 shows the number of1We clean all html tags and remove stopwords.entities (senses) (#E) and the number of documentsfor each ambiguous name (#Doc).In contrast to the previous task where the numberof topics is equal to the exact number of senses, inthis task the number of topics is approximate to thenumber of senses2.
In our experiments we set thenumber of topics to 40.
We embarked on this exper-imental set up in order to make our results compara-ble with the rest of the systems in WebPS.
However,if we use the exact number of name senses then LDAachieves higher results.To evaluate the performance of our approach, weuse the official WebPS evaluation script.
We re-port BCubed Precision, Recall and F-scores for ourLDA approach, two baseline systems and the ECNU(Lan et al, 2009) system from the WebPS-2 chal-lenge.
We compare our results against ECNL, be-cause they use similar word representation but in-stead of relying on LDA they use a clustering algo-rithm.
We denote in Table 3 the difference betweenthe F-score performances of LDA and the ECNUsystem as ?F1 .
We highlight the differences in bold.Since a name disambiguation system must havegood precision and recall results, we decided tocompare our results against two baselines which rep-resent the extreme case of a system that reaches100% precision (called ONE-IN-ONE) or a sys-tem that reaches 100% recall (called ALL-IN-ONE).Practically ONE-IN-ONE corresponds to assign-ing each document to a different cluster (individ-ual sense), while the ALL-IN-ONE baseline groupstogether all web pages into a single cluster corre-sponding to one name sense (the majority sense).
Amore detailed explanation about the evaluation mea-sures and the intuition behind them can be found in(Artiles et al, 2007) and (Artiles et al, 2009b).For six out of the nine names, LDA outperformedthe two baselines and the ECNU system with 5 to41% on F-score.
Precision and recall scores for LDAare comparable except for Tom Linton and HelenThomas where precision is much higher.
The de-crease in performance is due to the low number ofsenses (entities associated with a name) and the factthat LDA was tuned to produce 40 topics.
To over-come this limitation, in the future we plan to workon estimating the number of topics automatically.2Researchers use from 15 to 50 number of clusters/senses.110ONE-IN-ONE ALL-IN-ONE ECNU LDAName #E #Doc BEP BER F1 BEP BER F1 BEP BER F1 BEP BER F1 ?F1Wikipedia NamesLouis Lowe 24 100 1.00 .32 .48 .23 1.00 .37 .39 .78 .52 .63 .52 .57 +5Mike Robertson 39 123 1.00 .44 .61 .11 1.00 .19 .14 .96 .25 .59 .62 .61 +36Tom Linton 10 135 1.00 .11 .19 .54 1.00 .70 .68 .48 .56 .89 .22 .35 -21ACL ?08 NamesBenjamin Snyder 28 95 1.00 .51 .67 .08 1.00 .15 .16 .79 .27 .59 .81 .68 +41Emily Bender 19 120 1.00 .21 .35 .24 1.00 .39 .45 .60 .51 .78 .42 .55 +4Hao Zhang 24 100 1.00 .26 .41 .21 1.00 .35 .45 .78 .57 .72 .36 .48 -9Census NamesHelen Thomas 3 127 1.00 .03 .06 .96 1.00 .98 .96 .24 .39 .97 .08 .15 -24Jonathan Shaw 26 126 1.00 .32 .49 .10 1.00 .18 .18 .60 .34 .66 .51 .58 +24Susan Jones 56 110 1.00 .70 .82 .03 1.00 .06 .13 .81 .22 .51 .79 .62 +40Table 3: Results for Web People Search-2.5 ConclusionWe have shown how ambiguity in names can bemodeled and resolved using a generative probabilis-tic model.
Our LDA approach learns a distributionover topics which correspond to entities (senses) as-sociated with an ambiguous name.
We evaluate ournovel approach on two tasks: name discriminationand Web People Search.
We conduct a detailed eval-uation on (1) Web, Wikipedia and news documents;(2) English, Spanish, Romanian and Bulgarian lan-guages; (3) people, location and organization names.Our method achieves consistent performance andsubstantial improvements over baseline and existingstate-of-the-art clustering methods.In the future, we would like to model the bi-ographical fact extraction approach of (Mann andYarowsky, 2003) in our LDA model.
We plan to es-timate the number of topics automatically from thedistributions.
We want to explore variants of ourcurrent model.
For example, currently all words aregenerated by multiple topics (senses), but ideally wewant them to be generated by a single topic.
Finally,we want to impose additional constraints within thetopic models using hierarchical topic models.AcknowledgmentsWe acknowledge the support of DARPA contractFA8750-09-C-3705 and NSF grant IIS-0429360.ReferencesJavier Artiles, Julio Gonzalo, and Satoshi Sekine.
2007.The semeval-2007 weps evaluation: Establishing abenchmark for the web people search task.
In Pro-ceedings of the Fourth International Workshop on Se-mantic Evaluations (SemEval-2007, pages 64?69.Javier Artiles, Enrique Amigo?, and Julio Gonzalo.2009a.
The role of named entities in Web PeopleSearch.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing,pages 534?542.Javier Artiles, Julio Gonzalo, and Satoshi Sekine.
2009b.WePS 2 evaluation campaign: overview of the webpeople search clustering task.
In 2nd Web Peo-ple Search Evaluation Workshop (WePS 2009), 18thWWW Conference.Javier Artiles, Andrew Borthwick, Julio Gonzalo, SatoshiSekine, and Enrique Amigo?.
2010.
WePS-3 evalu-ation campaign: Overview of the web people searchclustering and attribute extraction ta.
In Conferenceon Multilingual and Multimodal Information AccessEvaluation (CLEF).Amit Bagga and Breck Baldwin.
1998.
Entity-basedcross-document coreferencing using the vector spacemodel.
In Proceedings of the 36th Annual Meetingof the Association for Computational Linguistics and17th International Conference on Computational Lin-guistics - Volume 1, ACL ?98, pages 79?85.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
J. Mach.
Learn.Res., 3:993?1022, March.Razvan C. Bunescu and Marius Pasca.
2006.
Using en-cyclopedic knowledge for named entity disambigua-tion.
In EACL 2006, 11st Conference of the EuropeanChapter of the Association for Computational Linguis-tics, Proceedings of the Conference.Ying Chen and James H. Martin.
2007.
Cu-comsem:Exploring rich features for unsupervised web per-sonal name disambiguation.
In Proceedings of theFourth International Workshop on Semantic Evalua-tions (SemEval-2007), pages 125?128, June.111Ying Chen, Sophia Yat Mei Lee, and Chu-Ren Huang.2009.
Polyuhk: A robust information extractionsystem for web personal names.
In 2nd Web Peo-ple Search Evaluation Workshop (WePS 2009), 18thWWW Conference.Silviu Cucerzan.
2007.
Large-scale named entity dis-ambiguation based on wikipedia data.
In EMNLP-CoNLL 2007, Proceedings of the 2007 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing, pages 708?716.Hal Daume?
III and Daniel Marcu.
2006.
Bayesian query-focused summarization.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics, pages 305?312, Sydney, Aus-tralia, July.
Association for Computational Linguistics.Filip Ginter, Jorma Boberg, Jouni Ja?rvinen, and TapioSalakoski.
2004.
New techniques for disambiguationin natural language and their application to biologicaltext.
J. Mach.
Learn.
Res., 5:605?621, December.Thomas L Griffiths and Mark Steyvers.
2002.
A prob-abilistic approach to semantic representation.
In Pro-ceedings of the Twenty-Fourth Annual Conference ofCognitive Science Society.Thomas L Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences of the United States of America,101 Suppl 1(Suppl 1):5228?5235.Aria Haghighi and Dan Klein.
2010.
Coreference reso-lution in a modular, entity-centered model.
In HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, pages 385?393.Zellig Harris.
1954.
Distributional structure.10(23):146?162.Vasileios Hatzivassiloglou, Pablo A. Duboue, and An-drey Rzhetsky.
2001.
Disambiguating proteins, genes,and rna in text: A machine learning approach.
In Pro-ceedings of the 9th International Conference on Intel-ligent Systems for Molecular Biology.Man Lan, Yu Zhe Zhang, Yue Lu, Jian Su, and Chew LimTan.
2009.
Which who are they?
people attribute ex-traction and disambiguation in web search results.
In2nd Web People Search Evaluation Workshop (WePS2009), 18th WWW Conference.Gideon S. Mann and David Yarowsky.
2003.
Unsuper-vised personal name disambiguation.
In Proceedingsof the seventh conference on Natural language learn-ing at HLT-NAACL 2003 - Volume 4, CONLL ?03,pages 33?40.Matthias Blume Matthias.
2005.
Automatic entity dis-ambiguation: Benefits to ner, relation extraction, linkanalysis, and inference.
In International Conferenceon Intelligence Analysis.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://www.cs.umass.edu/ mccallum/mallet.Hien T. Nguyen and Tru H. Cao.
2008.
Named entity dis-ambiguation: A hybrid statistical and rule-based incre-mental approach.
In Proceedings of the 3rd Asian Se-mantic Web Conference on The Semantic Web, ASWC?08, pages 420?433.Ted Pedersen and Anagha Kulkarni.
2007.
Unsuper-vised discrimination of person names in web contexts.In Computational Linguistics and Intelligent Text Pro-cessing, 8th International Conference, CICLing 2007,pages 299?310.Ted Pedersen, Amruta Purandare, and Anagha Kulka-rni.
2005.
Name discrimination by clustering simi-lar contexts.
In Computational Linguistics and Intel-ligent Text Processing, 6th International Conference,CICLing 2005, pages 226?237.Ted Pedersen, Anagha Kulkarni, Roxana Angheluta, Zor-nitsa Kozareva, and Thamar Solorio.
2006.
Anunsupervised language independent method of namediscrimination using second order co-occurrence fea-tures.
In Computational Linguistics and IntelligentText Processing, 7th International Conference, CI-CLing 2006, pages 208?222.Octavian Popescu and Bernardo Magnini.
2007.
Irst-bp:Web people search using name entities.
In Proceed-ings of the Fourth International Workshop on SemanticEvaluations (SemEval-2007, pages 195?198.
Associa-tion for Computational Linguistics.Joseph Reisinger and Marius Pasca.
2009.
Latent vari-able models of concept-attribute attachment.
In Pro-ceedings of the Joint Conference of the 47th AnnualMeeting of the ACL and the 4th International JointConference on Natural Language Processing of theAFNLP, pages 620?628.
Association for Computa-tional Linguistics, August.Alan Ritter, Mausam, and Oren Etzioni.
2010.
A latentdirichlet alocation method for selectional preferences.In Proceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 424?434.Association for Computational Linguistics, July.Yang Song, Jian Huang, Isaac G. Councill, Jia Li, andC.
Lee Giles.
2007.
Efficient topic-based unsuper-vised name disambiguation.
In Proceedings of the 7thACM/IEEE-CS Joint Conference on Digital libraries,pages 342?351.Xiaojun Wan, Jianfeng Gao, Mu Li, and Binggong Ding.2005.
Person resolution in person search results: Web-hawk.
In Proceedings of the 14th ACM internationalconference on Information and knowledge manage-ment, CIKM ?05, pages 163?170.112
