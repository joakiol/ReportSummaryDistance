First Joint Conference on Lexical and Computational Semantics (*SEM), pages 696?700,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsCELI: An Experiment with Cross Language Textual EntailmentMilen KouylekovCeli S.R.L.via San Quintino 31Torino, Italykouylekov@celi.itLuca DiniCeli S.R.L.via San Quintino 31Torino, Italydini@celi.itAlessio BoscaCeli S.R.L.via San Quintino 31Torino, Italybosca@celi.itMarco TrevisanCeli S.R.L.via San Quintino 31Torino, Italytrevisan@celi.itAbstractThis paper presents CELI?s participation in theSemEval Cross-lingual Textual Entailment forContent Synchronization task.1 IntroductionThe Cross-Lingual Textual Entailment task (CLTE)is a new task that addresses textual entailment (TE)(Bentivogli et.
al., 2011), targeting the cross-lingual content synchronization scenario proposedin (Mehdad et.
al., 2011) and (Negri et.
al., 2011).The task has interesting application scenarios thatcan be investigated.
Some of them are content syn-chronization and cross language query alignment.The task is defined by the organizers as follows:Given a pair of topically related text fragments (T1and T2) in different languages, the CLTE task con-sists of automatically annotating it with one of thefollowing entailment judgments:?
Bidirectional: the two fragments entail eachother (semantic equivalence)?
Forward: unidirectional entailment from T1 toT2?
Backward: unidirectional entailment from T2to T1?
No Entailment: there is no entailment betweenT1 and T2In this task, both T1 and T2 are assumed to beTRUE statements; hence in the dataset there are nocontradictory pairs.Example for Spanish English pairs:?
bidirectionalMozart naci en la ciudad de SalzburgoMozart was born in Salzburg.?
forwardMozart naci en la ciudad de SalzburgoMozart was born on the 27th January 1756 inSalzburg.?
backwardMozart naci el 27 de enero de 1756 enSalzburgoMozart was born in 1756 in the city of Salzburg?
no entailmentMozart naci el 27 de enero de 1756 enSalzburgoMozart was born to Leopold and Anna MariaPertl Mozart.2 Our Approach to CLTEIn our participation in the 2012 SemEval Cross-lingual Textual Entailment for Content Synchroniza-tion task (Negri et.
al., 2012) we have developedan approach based on cross-language text similarity.We have modified our cross-language query similar-ity system TLike to handle longer texts.Our approach is based on four main resources:?
A system for Natural Language Processing ableto perform for each relevant language basictasks such as part of speech disambiguation,lemmatization and named entity recognition.?
A set of word based bilingual translation mod-ules.696?
A semantic component able to associate a se-mantic vectorial representation to words.?
We use Wikipedia as multilingual corpus.NLP modules are described in (Bosca and Dini,2008), and will be no further detailed here.Word-based translation modules are composed bya bilingual lexicon look-up component coupled witha vector based translation filter, such as the one de-scribed in (Curtoni and Dini, 2008).
In the context ofthe present experiments, such a filters has been de-activated, which means that for any input word thecomponent will return the set of all possible transla-tions.
For unavailable pairs, we make use of trian-gular translation (Kraaij, 2003).As for the semantic component we experimentedwith a corpus-based distributional approach capableof detecting the interrelation between different termsin a corpus; the strategy we adopted is similar to La-tent Semantic Analysis (Deerwester et.
al., 1990)although it uses a less expensive computational solu-tion based on the Random Projection algorithm (Linet.
al., 2003) and (Bingham et.
al., 2001).
Differentworks debate on similar issues: (Turney, 2001) usesLSA in order to solve synonymy detection questionsfrom the well-known TOEFL test while the methodpresented by (Inkpen, 2001) or by (Baroni and Bisi,2001) proposes the use of the Web as a corpus tocompute mutual information scores between candi-date terms.More technically, Random Indexing exploits analgebraic model in order to represent the seman-tics of terms in a Nth dimensional space (a vectorof length N); approaches falling into this category,actually create a Terms By Contexts matrix whereeach cell represents the degree of memberships of agiven term to the different contexts.
The algorithmassigns a random signature to each context (a highlysparse vector of length N , with few, randomly cho-sen, non-zero elements) and then generates the vec-tor space model by performing a statistical analysisof the documents in the domain corpus and by ac-cumulating on terms rows all the signatures of thecontexts where terms appear.According to this approach if two different termshave a similar meaning they should appear in similarcontexts (within the same documents or surroundedby the same words), resulting into close coordinatesin the so generated semantic space.In our case study semantic vectors have been gen-erated taking as corpus the set of metadata availablevia the CACAO project (Cacao Project, 2007) fed-eration (about 6 millions records).
After processingfor each word in the corpus we have:?
A vector of float from 0 to 1 representing itscontextual meaning;?
A set of neighbors terms selected among theterms with a higher semantic similarity, calcu-lated as cosine distance among vectors.We use Wikipedia as a corpus for calculatingword statistics in different languages.
We have in-dexed using Lucene1 the English, Italian, French,German, Spanish distributions of the resource.The basic idea behind our algorithm is to detectthe probability for two texts to be one a translationof the other.
In the simple case we expect that if allthe words in text TS have a translation in text TT andif TS and TT have the same number of terms, thenTS and TT are entailed.
Things are of course morecomplex than this, due to the following facts:?
The presence of compound words make theconstraints on cardinality of search terms notfeasible (e.g.
the Italian Carta di Credito vs.the German KreditCarte).?
One or more words in TS could be absent fromtranslation dictionaries.?
One or more words in TS could be presentin the translation dictionaries, but contextuallycorrect translation might be missing.?
There might be items which do not need to betranslated, notably Named Entities.The first point, compounding, is only partiallyan obstacle.
NLP technology developed duringCACAO Project, which adopted translation dictio-naries, deals with compound words both in termsof identification and translation.
Thus the Italian?Carta di Credito?
would be recognized and cor-rectly translated into ?KreditCarte?.
So, in an ideal1http://lucene.apache.org697word, the cardinality principle could be consideredstrict.
In reality, however, there are many com-pounding phenomena which are not covered by ourdictionaries, and this forces us to consider that a mis-match in text term cardinality decrease the probabil-ity that the two translations are translation of eachother, without necessarily setting it to zero.Concerning the second aspect, the absence ofsource (T1) words in translation dictionaries, it isdealt with by accessing the semantic repository de-scribed in the previous section.
We first obtain thelist of neighbor terms for the untranslatable sourceword.
This list is likely to contain many words thathave one or more translations.
For each translation,again, we consult our semantic repository and weobtain its semantic vector.Finally, we compose all vectors of all availabletranslations and we search in the target text (T2) forthe word whose semantic vector best matches thecomposed one (cosine distance).
Of course we can-not assume that the best matching vector is a transla-tion of the original word, but we can use the distancebetween the two vectors as a further weight for de-ciding whether the two texts are translations one ofthe other.There are of course cases when the source wordis correctly missing in the source dictionary.
Thisis typically the case of most named entities, suchas geographical and person names.
These entitiesshould be appropriately recognized and searched asexact matches in the target text, thus by-passing anydictionary look-up and any semantic based match-ing.
Notice that the recognition of named entitiesit is not just a matter of generalizing the statementaccording to which ?if something is not in the dic-tionaries, it is a named entity?.
Indeed there are wellknown cases where the named entity is homographwith common words (e.g.
the French author ?LaFontaine?
), and in these cases we must detect themin order to avoid the rejection of likely translationpairs.
In other words we must avoid that the twotexts ?La fontaine fables?
and ?La Fontaine fav-ole?
are rejected as translation pairs, just by virtueof the fact that ?La fontaine?
is treated as a com-mon word, thus generating the Italian translation?Lafontana?.
Fortunately CACAO disposes of a quiteaccurate subsystem for recognizing named entitiesin texts, mixing standard NLP technologies with sta-tistical processing and other corpus-oriented heuris-tics.We concentrated our work on handling caseswhere two texts are candidates to be mutual trans-lations, but one or more words receive a translationwhich is not contained in the target text.
Typicallythese cases are a symptom of a non-optimal qualityin translation dictionaries: the lexicographer prob-ably did not consider some translation candidate.To address this problem we have created a solutionbased on a weighting scheme.
For each word of thesource language we assign a weight that reflects itsimportance to the semantic interpretation of the text.We define a matchweight of a word using the for-mula represented in Figure 2.In this formula wis isa word from the source text, wkt is a word from thetarget text, w is a word in the source language andtrans is a boolean function that searches in the dic-tionary for translations between two words.The matchweight is relevant to the matching of atranslation of a word from the source with one ofthe words of the target.
If the system finds a directcorrespondence the weight is 0.
If the match wasmade using random indexing the weight is inverseto the cosine similarity between the vectors.In order to make an approximation of the signif-icance of the word to the meaning of the phrase wehave used as its cost the inverse document frequency(IDF) of the word calculated using Wikipedia as acorpus.
IDF is a most popular measure (a measurecommonly used in Information Retrieval) for calcu-lating the importance of a word to a text.
If N is thenumber of documents in a text collection and Nw isthe number of documents of the collection that con-tain w then the IDF of w is given by the formula:weight(wis) = idf(w) = log(NNw) (2)Using the matchweight and weight we define thematchscore of a source target pair as:matchscore(Ts, Tt) =?matchweigth(wis)?weight(wis)(3)If all the words of the source text have a transla-tion in the target text the score is 0.
If none is foundthe score is 1.
We have calculated the scores for each698matchweight(wis) =????
?0 ?wkt trans(wis) = wktw ?
(wis) ?
(1?
d) ?w &wkt distance(wis, w) = d&trans(w) = wktw ?
(wis) otherwise(1)Figure 1: Match Weight of a Wordpair taking t1 as a source and t2 as a target and viceversa.3 SystemsWe have submitted four runs in the SemEval CLTEchallenge.
We used the NaiveBayse algorithm im-plemented in Mallet2 to create a classifier that willproduce the output for each of the four categoriesForward , Backward , Bidirectional and No Entail-ment.System 1 As our first system we have created abinary classifier in the classical RTE (Bentivogli et.al., 2011) classification (YES & NO) for each direc-tion Forward and Backward.
We assigned the Bidi-rectional category if both classifiers returned YES.As features the classifiers used only the match scoresobtained for the corresponding direction as one andonly numeric feature.System 2 For the second system we trained a clas-sifier using all four categories as output.
Apart of thescores obtained matching the texts in both directionswe have included also a set of eight simple surfacemeasures.
Some of these are:?
The length of the two texts.?
The number of common words without transla-tions.?
The cosine similarity between the tokens of thetwo texts without translation.?
Levenshtein distance between the texts.System 3 For the third system we trained a classi-fier using all four categories as output.
We used asfeatures scores obtained matching the texts in bothdirections without the surface features used in theSystem 2.2http://mallet.cs.umass.edu/System 4 In the last system we trained a classifierusing all four categories as output.
We used as fea-tures the simple surface measures used in System 2.The results obtained are shown in Table 1.4 AnalysisAnalyzing the results of our participation we havereached several important conclusions.The dataset provided by the organizers presenteda significant challenge for our system which wasadapted from a query similarity approach.
The re-sults obtained demonstrate that only a similaritybased approach will not provide good results for thistask.
This fact is also confirmed by the poor perfor-mance of the simple similarity measures by them-selves (System 4) and by their contribution to thecombined run (System 2).The poor performance of our system can be par-tially explained also by the small dimensions of thecross-language dictionaries we used.
Expandingthem with more words and phrases can potentiallyincrease our results.The classifier with four categories clearly outper-forms the two directional one (System 1 vs. System3).Overall we are not satisfied with our experi-ment.
A radically new approach is needed to addressthe problem of Cross-Language Textual Entailment,which our similarity based system could not modelcorrectly.In the future we intend to integrate our approachin our RTE open source system EDITS (Kouylekovet.
al., 2011) (Kouylekov and Negri, 2010) availableat http://edits.sf.net.AcknowledgmentsThis work has been partially supported by theECfunded project Galateas (CIP-ICT PSP-2009-3-250430).699SPA-ENG ITA-ENG FRA-ENG DEU-ENGSystem 1 0.276 0.278 0.278 0.280System 2 0.336 0.336 0.300 0.352System 3 0.322 0.334 0.298 0.350System 4 0.268 0.280 0.280 0.274Table 1: Results obtained.ReferencesBaroni M., Bisi S. 2004.
Using cooccurrence statisticsand the web to discover synonyms in technical lan-guage In Proceedings of LREC 2004Bentivogli L., Clark P., Dagan I., Dang H, Giampic-colo D. 2011.
The Seventh PASCAL RecognizingTextual Entailment Challenge In Proceedings of TAC2011Bingham E., Mannila H. 2001.
Random projection indimensionality reduction: Applications to image andtext data.
In Knowledge Discovery and Data Mining,ACM Press pages 245250Bosca A., Dini L. 2008.
Query expansion via libraryclassification system.
In CLEF 2008.
Springer Verlag,LNCSCacao Project CACAO - project supported by the eCon-tentplus Programme of the European Commission.http://www.cacaoproject.eu/Curtoni P., Dini L. 2006.
Celi participation at clef 2006Cross language delegated search.
In CLEF2006 Work-ing notes.Deerwester S., Dumais S.T., Furnas G.W., Landauer T.K.,Harshman R. 1990.
Indexing by latent semantic anal-ysis.
Journal of the American Society for InformationScience 41 391407Inkpen D. 2007.
A statistical model for near-synonymchoice.
ACM Trans.
Speech Language Processing4(1)Kraaij W. 2003.
Exploring transitive translation meth-ods.
In Vries, A.P.D., ed.
: Proceedings of DIR 2003.Kouylekov M., Negri M. An Open-Source Package forRecognizing Textual Entailment.
48th Annual Meet-ing of the Association for Computational Linguistics(ACL 2010) ,Uppsala, Sweden.
July 11-16, 2010Kouylekov M., Bosca A., Dini L. 2011.
EDITS 3.0 atRTE-7.
Proceedings of the Seventh Recognizing Tex-tual Entailment Challenge (2011).Lin J., Gunopulos D. 2003.
Dimensionality reductionby random projection and latent semantic indexing.
Inproceedings of the Text Mining Workshop, at the 3rdSIAM International Conference on Data Mining.Mehdad Y.,Negri M., Federico M.. 2011.
Using Paral-lel Corpora for Cross-lingual Textual Entailment.
InProceedings of ACL-HLT 2011.Negri M., Bentivogli L., Mehdad Y., Giampiccolo D.,Marchetti A.
2011.
Divide and Conquer: Crowd-sourcing the Creation of Cross-Lingual Textual Entail-ment Corpora.
In Proceedings of EMNLP 2011.Negri M., Marchetti A., Mehdad Y., Bentivogli L., Gi-ampiccolo D. Semeval-2012 Task 8: Cross-lingualTextual Entailment for Content Synchronization.
InProceedings of the 6th International Workshop on Se-mantic Evaluation (SemEval 2012).
2012.Turney P.D.
2001.
Mining the web for synonyms: Pmi-ir versus lsa on toefl.
In EMCL 01: Proceedings ofthe 12th European Conference on Machine Learning,London, UK, Springer-Verlag pages 491502700
