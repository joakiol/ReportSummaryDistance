Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 10?18,Portland, OR, USA, 24 June 2011. c?2011 Association for Computational LinguisticsA Low-budget Tagger for Old CzechJirka HanaCharles University, MFFCzech Republicfirst.last@gmail.comAnna FeldmanMontclair State UniversityUSAfirst.last@montclair.eduKatsiaryna AharodnikMontclair State UniversityUSAogorodnichek@gmail.comAbstractThe paper describes a tagger for Old Czech(1200-1500 AD), a fusional language withrich morphology.
The practical restrictions(no native speakers, limited corpora and lex-icons, limited funding) make Old Czech anideal candidate for a resource-light cross-lingual method that we have been developing(e.g.
Hana et al, 2004; Feldman and Hana,2010).We use a traditional supervised tagger.
How-ever, instead of spending years of effort to cre-ate a large annotated corpus of Old Czech, weapproximate it by a corpus of Modern Czech.We perform a series of simple transformationsto make a modern text look more like a textin Old Czech and vice versa.
We also use aresource-light morphological analyzer to pro-vide candidate tags.
The results are worsethan the results of traditional taggers, but theamount of language-specific work needed isminimal.1 IntroductionThis paper describes a series of experiments in anattempt to create morphosyntactic resources for OldCzech (OC) on the basis of Modern Czech (MC) re-sources.
The purpose of this work is two-fold.
Thepractical goal is to create a morphologically anno-tated corpus of OC which will help in investigationof various morphosyntactic patterns underpinningthe evolution of Czech.
Our second goal is moretheoretical in nature.
We wanted to test the resource-light cross-lingual method that we have been devel-oping (e.g.
Hana et al, 2004; Feldman and Hana,2010) on a source-target language pair that is di-vided by time instead of space.
The practical restric-tions (no native speakers, limited corpora and lexi-cons, limited funding) make OC an ideal candidatefor a resource-light approach.We understand that the task we chose is hardgiven the 500+ years of language evolution.
We areaware of the fact that all layers of the language havechanged, including phonology and graphemics, syn-tax and vocabulary.
Even words that are still used inMC are often used with different distributions, withdifferent declensions, with different gender, etc.Our paper is structured as follows.
We first brieflydescribe related work and motivate our approach.Then we outline the relevant aspects of the Czechlanguage and compare its Modern and Old forms.Then we describe the corpora and tagsets used in ourexperiments.
The rest of the paper describes the ac-tual experiments, the performance of various modelsand concludes with a discussion of the results.2 Related WorkSince there are no morphological taggers devel-oped specifically for OC, we compare our workwith those for MC.
Morc?e (http://ufal.mff.cuni.cz/morce/) is currently the best tagger,with accuracy slightly above 95%.
It is based ona statistical (averaged perceptron) algorithm whichrelies on a large morphological lexicon containingaround 300K entries.
The tool has been trained andtuned on data from the Prague Dependency Tree-bank (PDT; Be?mova et al, 1999; Bo?hmova?
et al,2001).
The best set of features was selected af-ter hundreds of experiments were performed.
In10contrast, the resource-light system we developed isnot as accurate, but the amount of language-specificwork needed is incomparable to that of the state-of-the-art systems.
Language specific work on ourOC tagger, for example, was completed in about 20hours, instead of several years.Research in resource-light learning of mor-phosyntactic properties of languages is not new.Some have assumed only partially tagged train-ing corpora (Merialdo, 1994); some have begunwith small tagged seed wordlists (Cucerzan andYarowsky, 2002) for named-entity tagging, whileothers have exploited the automatic transfer of analready existing annotated resource in a differentgenre or a different language (e.g.
cross-languageprojection of morphological and syntactic informa-tion as in (Cucerzan and Yarowsky, 2000; Yarowskyet al, 2001), requiring no direct supervision in thetarget language).
The performance of our system iscomparable to the results cited by these researchers.In our work we wanted to connect to pre-existing knowledge that has been acquired and sys-tematized by traditional linguists, e.g.
morpholog-ical paradigms, sound changes, and other well-established facts about MC and OC.3 Czech LanguageCzech is a West Slavic language with significant in-fluences from German, Latin and (in modern times)English.
It is a fusional (flective) language with richmorphology and a high degree of homonymy of end-ings.3.1 Old CzechAs a separate language, Czech forms between 1000-1150 AD; there are very few written documentsfrom that time.
The term Old Czech usually refersto Czech roughly between 1150 and 1500.
It is fol-lowed by Humanistic Czech (1500-1650), BaroqueCzech (1650-1780) and then Czech of the so-calledNational Revival.
Old Czech was significantly in-fluenced by Old Church Slavonic, Latin and Ger-man.
Spelling during this period was not standard-ized, therefore the same word can have many dif-ferent spelling variants.
However, our corpus wastransliterated ?
its pronunciation was recorded usingthe rules of the Modern Czech spelling (see Lehec?kachange exampleu?
> ou non-init.
mu?ka > mouka ?flour?se?
> se se?no > seno ?hay?o?
> uo > u?
ko?n?
> kuon?
> ku?n?
?horse?s?c?
> s?t?
s?c??
?r > s?t?
?r ?scorpion?c?s > c c?so > co ?what?Table 1: Examples of sound/spelling changes from OC toMCand Volekova?, 2011, for more details).3.2 Modern CzechModern Czech is spoken by roughly 10 millionspeakers, mostly in the Czech Republic.
For a moredetailed discussion, see for example (Naughton,2005; Short, 1993; Janda and Townsend, 2002;Karl?
?k et al, 1996).
For historical reasons, thereare two variants of Czech: Official (Literary, Stan-dard) Czech and Common (Colloquial) Czech.
Theofficial variant is based on the 19th-century resur-rection of the 16th-century Czech.
Sometimes it isclaimed, with some exaggeration, that it is the firstforeign language the Czechs learn.
The differencesare mainly in phonology, morphology and lexicon.The two variants are influencing each other, result-ing in a significant amount of irregularity, especiallyin morphology.
The Czech writing system is mostlyphonological.3.3 DifferencesProviding a systematic description of differences be-tween Old and Modern Czech is well beyond thescope of this paper.
Therefore, we just briefly men-tion a few illustrative examples.
For a more detaileddescription see (Va?z?ny?, 1964; Dosta?l, 1967; Mann,1977).3.3.1 Phonology and SpellingExamples of some of the more regular changes be-tween OC and MC spelling can be found in Table 1(Mann (1977), Boris Lehec?ka p.c.
).3.3.2 Nominal MorphologyThe nouns of OC have three genders: feminine,masculine, and neuter.
In declension they distin-guish three numbers: singular, plural, and dual,and seven cases: nominative, genitive, dative, ac-cusative, vocative, locative and instrumental.
Voca-11category Old Czech Modern Czechinfinitive pe?c-i pe?c-t ?bake?present 1sg pek-u pec?-u1du pec?-eve?
?1pl pec?-em(e/y) pec?-eme:imperfect 1sg pec?-iech ?1du pec?-iechove?
?1pl pec?-iechom(e/y) ?
:imperative 2sg pec-i pec?2du pec-ta ?2pl pec-te pec?-te:verbal noun pec?-enie pec?-en?
?Table 2: A fragment of the conjugation of the verbpe?ci/pe?ct ?bake?
(OC based on (Dosta?l, 1967, 74-77))tive is distinct only for some nouns and only in sin-gular.MC nouns preserved most of the features of OC,but the dual number survives only in a few pairednames of parts of the body, in the declensions ofthe words ?two?
and ?both?
and in the word for?two hundred?.
In Common Czech the dual pluraldistinction is completely neutralized.
On the otherhand, MC distinguishes animacy in masculine gen-der, while this distinction is only emerging in lateOC.3.3.3 Verbal MorphologyThe system of verbal forms and constructions wasfar more elaborate in OC than in MC.
Many formsdisappeared all together (three simple past tenses,supinum), and some are archaic (verbal adverbs,plusquamperfectum).
Obviously, all dual forms areno longer in MC.
See Table 2 for an example.4 Corpora4.1 Modern Czech CorpusOur MC training corpus is a portion (700K tokens)of PDT.
The corpus contains texts from daily news-papers, business and popular scientific magazines.
Itis manually morphologically annotated.The tagset (Hajic?
(2004)) has more than 4200tags encoding detailed morphological information.It is a positional tagset, meaning the tags are se-quences of values encoding individual morpholog-ical features and all tags have the same length, en-coding all the features distinguished by the tagset.Features not applicable for a particular word have aN/A value.
For example, when a word is annotatedas AAFS4----2A---- it is an adjective (A), longform (A), feminine (F), singular (S), accusative (4),comparative (2), not-negated (A).4.2 Old Czech CorporaSeveral steps (e.g., lexicon acquisition) of ourmethod require a plain text corpus.
We used textsfrom the Old-Czech Text Bank (STB, http://vokabular.ujc.cas.cz/banka.aspx), intotal about 740K tokens.
This is significantly lessthan we have used in other experiments (e.g., 39Mtokens for Czech or 63M tokens for Catalan (Feld-man and Hana, 2010)).A small portion (about 1000 words) of the corpuswas manually annotated for testing purposes.
Againthis is much less than what we would like to have,and we plan to increase the size in the near future.The tagset is a modification of the modern tagset us-ing the same categories.5 MethodThe main assumption of our method (Feldman andHana, 2010) is that a model for the target languagecan be approximated by language models from oneor more related source languages and that inclusionof a limited amount of high-impact and/or low-costmanual resources is greatly beneficial and desirable.We use TnT (Brants, 2000), a second orderMarkov Model tagger.
The language model of sucha tagger consists of emission probabilities (corre-sponding to a lexicon with usage frequency infor-mation) and transition probabilities (roughly corre-sponding to syntax rules with strong emphasis on lo-cal word-order).
We approximate the emission andtransition probabilities by those trained on a mod-ified corpus of a related language.
Below, we de-scribe our approach in more detail.126 ExperimentsWe describe three different taggers:1. a TnT tagger using modified MC corpus as asource of both transition and emission proba-bilities (section 6.1);2. a TnT tagger using modern transitions butapproximating emissions by a uniformly dis-tributed output of a morphological analyzer(MA) (sections 6.2 and 6.3); and3.
a combination of both (section 6.4).6.1 Translation Model6.1.1 Modernizing OC and Aging MCTheoretically, we can take the MC corpus, translateit to OC and then train a tagger, which would proba-bly be a good OC tagger.
However, we do not needthis sophisticated, costly translation because we onlydeal with morphology.A more plausible idea is to modify the MC corpusso that it looks more like the OC just in the aspectsrelevant for morphological tagging.
In this case, thetranslation would include the tagset, reverse phono-logical/graphemic changes, etc.
Unfortunately, eventhis is not always possible or practical.
For exam-ple, historical linguists usually describe phonologi-cal changes from old to new, not from new to old.1In addition, it is not possible to deterministicallytranslate the modern tagset to the older one.
So, wemodify the MC training corpus to look more like theOC corpus (the process we call ?aging?)
and also thetarget OC corpus to look more like the MC corpus(?modernizing?
).6.1.2 Creating the Translation TaggerBelow we describe the process of creating a tagger.As an example we discuss the details for the Trans-lation tagger.
Figure 1 summarizes the discussion.1.
Aging the MC training (annotated) corpus:?
MC to OC tag translation:Dropping animacy distinction (OC did notdistinguish animacy).1Note that one cannot simply reverse the rules, as in general,the function is not a bijection.?
Simple MC to OC form transformations:E.g., modern infinitives end in -t, OC in-finitives ended in -ti;(we implemented 3 transformations)2.
Training an MC tagger.
The tagger is trainedon the result of the previous step.3.
Modernizing an OC plain corpus.
In thisstep we modernize OC forms by applyingsound/graphemic changes such as those in Ta-ble 1.
Obviously, these transformations are notwithout problems.
First, the OC-to-MC transla-tions do not always result in correct MC forms;even worse, they do not always provide formsthat ever existed.
Sometimes these transforma-tions lead to forms that do exist in MC, but areunrelated to the source form.
Nevertheless, wethink that these cases are true exceptions fromthe rule and that in the majority of cases, theseOC translated forms will result in existing MCwords and have a similar distribution.4.
Tagging.
The modernized corpus is taggedwith the aged tagger.5.
Reverting modernizations.
Modernized wordsare replaced with their original forms.
Thisgives us a tagged OC corpus, which can be usedfor training.6.
Training an OC tagger.
The tagger is trained onthe result of the previous step.
The result of thistraining is an OC tagger.The results of the translation model are providedin Tables 3 (for each individual tag position) and4 (across various POS categories).
What is evidentfrom these numbers is that the Translation tagger isalready quite good at predicting the POS, subPOSand number categories.
The most challenging POScategory is the category of verbs and the most diffi-cult feature is case.
Based on our previous experi-ence with other fusional languages, getting the casefeature right is always challenging.
Even thoughcase participates in syntactic agreement in both OCand MC, this category is more idiosyncratic than,say, person or tense.
Therefore, the MC syntacticand lexical information provided by the translation13STBold plainO2M: form translationtag & form(back) translationSTB'plainSTB'taggedSTBtaggedtaggingtrainOld CzechHMM taggerPDT corpusmodernannotatedM2O: tag & form translationPDT ' corpusannotatedtrainHMM tagger123456Figure 1: Schema of the Translation Taggermodel might not be sufficient to compute case cor-rectly.
One of the solutions that we explore in thispaper is approximating the OC lexical distributionby the resource-light morphological analyzer (seesection 6.3).While most nominal forms and their morpholog-ical categories (apart from dual) survived in MC,OC and MC departed in verbs significantly.
Thus,for example, three OC tenses disappeared in MCand other tenses replaced them.
These include theOC two aorists, supinum and imperfectum.
Thetransgressive forms are almost not used in MC any-more either.
Instead MC has periphrastic past, pe-riphrastic conditional and also future.
In addition,these OC verbal forms that disappeared in MC areunique and non-ambiguous, which makes it evenmore difficult to guess if the model is trained on theMC data.
The tagger, in fact, has no way of provid-ing the right answer.
In the subsequent sections weuse a morphological analyzer to address this prob-lem.
Our morphological analyzer uses very basichand-encoded facts about the target language.6.2 Resource-light Morphological AnalysisThe Even tagger described in the following sectionrelies on a morphological analyzer.
While it canuse any analyzer, to stay within a resource lightparadigm, we have used our resource-light analyzer(Hana, 2008; Feldman and Hana, 2010).
Our ap-proach to morphological analysis (Hana, 2008) takesthe middle road between completely unsupervisedsystems on the one hand and systems with exten-sive manually-created resources on the other.
It ex-ploits Zipf?s law (Zipf, 1935, 1949): not all wordsand morphemes matter equally.
A small number ofwords are extremely frequent, while most words arerare.
For example, in PDT, 10% most frequent nounlemmas cover about 75% of all noun tokens in thecorpus.
On the other hand, the less frequent 50% ofnoun lemmas cover only 5% of all noun tokens.Therefore, in our approach, those resources thatare easy to provide and that matter most are created14Tags: 70.6Position 0 (POS ): 91.5Position 1 (SubPOS ): 88.9Position 2 (Gender ): 87.4Position 3 (Number ): 91.0Position 4 (case ): 82.6Position 5 (PossGen): 99.5Position 6 (PossNr ): 99.5Position 7 (person ): 93.2Position 8 (tense ): 94.4Position 9 (grade ): 98.0Position 10 (negation): 94.4Position 11 (voice ): 95.9Table 3: Accuracy of the Translation Model on individualpositions (in %).All Full: 70.6SubPOS 88.9Nouns Full 63.1SubPOS 99.3Adjs Full: 60.3SubPos 93.7Verbs Full 47.8SubPOS 62.2Table 4: Performance of the Translation Model on majorPOS categories (in %).manually or semi-automatically and the rest is ac-quired automatically.
For more discussion see (Feld-man and Hana, 2010).Structure The system uses a cascade of modules.The general strategy is to run ?sure thing?
modules(ones that make fewer errors and that overgener-ate less) before ?guessing?
modules that are moreerror-prone and given to overgeneration.
Simplify-ing somewhat the current system for OC contains thefollowing three levels:1.
Word list ?
a list of 250 most frequent OCwords accompanied with their possible analy-ses.
Most of these words are closed class.2.
Lexicon-based analyzer ?
the lexicon has beenautomatically acquired from a plain corpus us-ing the knowledge of manually provided infor-mation about paradigms (see below).3a.
Guesser ?
this module analyzes words relyingpurely on the analysis of possible endings andtheir relations to the known paradigms.
Thusthe English word goes would be analyzed notonly as a verb, but also as plural of the po-tential noun goe, as a singular noun (with thepresumed plural goeses), etc.
In Slavic lan-guages the situation is complicated by high in-cidence of homonymous endings.
For exam-ple, the Modern Czech ending a has 14 differ-ent analyses (and that assumes one knows themorpheme boundary).Obviously, the guesser has low precision, andfails to use all kinds of knowledge that it po-tentially could use.
Crucially, however, it hashigh recall, so it can be used as a safety netwhen the more precise modules fail.
It is alsoused during lexicon acquisition, another con-text where its low precision turns out not to bea major problem.3b.
Modern Czech word list ?
a simple analyzerof Modern Czech; for some words this modulegives the correct answer (e.g., sva?tek ?holiday?,some proper names).The total amount of language-specific work neededto provide OC data for the analyzer (informationabout paradigms, analyses of frequent forms) isabout 12 hours and was done by a non-linguist onthe basis of (Va?z?ny?, 1964; Dosta?l, 1967).The results of the analyzer are summarized in Ta-ble 5.
They show a similar pattern to the results wehave obtained for other fusional languages.
As canbe seen, morphological analysis without any filters(the first two columns) gives good recall but alsovery high average ambiguity.
When the automat-ically acquired lexicon and the longest-ending fil-ter (analyses involving the longest endings are pre-ferred) are used, the ambiguity is reduced signifi-cantly but recall drops as well.
As with other lan-guages, even for OC, it turns out that the drop inrecall is worth the ambiguity reduction when the re-sults are used by our MA-based taggers.
Moreover,as we mentioned in the previous section, the tag-ger based purely on the MC corpus has no chanceon verbal forms that disappeared from the languagecompletely.15Old Czech te[tM$anal\zed OldCz te[ttaggedOld Cz te[t3tag translation4record of theoriginal tagscompiling tntemissions5tnttag backtranslationeYen OCzemissionsOld Czech te[ttag translation1tag translation2CztransitionsCzemissionsM$ Creation)reTuent forms/e[icon  Paradigms(nding based *uesserModern Czech )ormsFigure 2: Schema of the MA Based Even TaggerLexicon & leo no yesRecall Ambi Recall AmbiOverall 96.9 14.8 91.5 5.7Nouns 99.9 26.1 83.9 10.1Adjectives 96.8 26.5 96.8 8.8Verbs 97.8 22.1 95.6 6.2Table 5: Evaluation of the morphological analyzer on OldCzech6.3 Even TaggerThe Even tagger (see Figure 2) approximates emis-sions by using the output of the morphological ana-lyzer described in the previous section.The transition probabilities are based on the AgedModern Czech corpus (result of step 2 of Figure 1).This means that the transitions are produced duringthe training phase and are independent of the taggedtext.
However, the emissions are produced by themorphological analyzer on the basis of the taggedtext during tagging.
The reason why the modelis called Even is that the emissions are distributedevenly (uniformly; which is a crude approximationof reality).The overall performance of the Even tagger dropsdown, but it improves on verbs significantly.
Intu-All Full: 67.7SubPOS 87.0Nouns Full 44.3SubPOS 88.6Adjs Full: 50.8SubPos 87.3Verbs Full 74.4SubPOS 78.9Table 6: Performance of the Even Tagger on major POScategories (in %)itively, this seems natural, because there is a rel-atively small homonymy among many OC verbalendings (see Table 2 for an example) so they arepredicted by the morphological analyzer with lowor even no ambiguity.6.4 Combining the Translation and EvenTaggersThe TranslEven tagger is a combination of theTranslation and Even models.
The Even modelclearly performs better on the verbs, while the Trans-lation model predicts other categories much better.So, we decided to combine the two models in the fol-lowing way.
The Even model predicts verbs, while16the Translation model predicts the other categories.The TranslEven Tagger gives us a better overall per-formance and improves the prediction on each indi-vidual position of the tag.
Unfortunately, it slightlyreduces the performance on nouns (see Tables 7 and8).All Full: 74.1SubPOS 90.6Nouns Full 57.0SubPOS 91.3Adjs Full: 60.3SubPos 93.7Verbs Full 80.0SubPOS 86.7Table 7: Performance of the TranslEven tagger on majorPOS categories (in %)Full tags: 74.1Position 0 (POS ): 93.0Position 1 (SubPOS ): 90.6Position 2 (Gender ): 89.6Position 3 (Number ): 92.5Position 4 (case ): 83.6Position 5 (PossGen): 99.5Position 6 (PossNr ): 94.9Position 7 (person ): 94.9Position 8 (tense ): 95.6Position 9 (grade ): 98.6Position 10 (negation): 96.1Position 11 (voice ): 96.4Table 8: Performance of the TranslEven tagger on indi-vidual positions (in %).7 DiscussionWe have described a series of experiments to cre-ate a tagger for OC.
Traditional statistical taggersrely on large amounts of training (annotated) data.There is no realistic prospect of annotation for OC.The practical restrictions (no native speakers, lim-ited corpora and lexicons, limited funding) make OCan ideal candidate for a resource-light cross-lingualmethod that we have been developing.
OC and MCdeparted significantly over the 500+ years, at all lan-guage layers, including phonology, syntax and vo-cabulary.
Words that are still used in MC are oftenused with different distributions and have differentmorphological forms from OC.Additional difficulty of this task arises from thefact that our MC and OC corpora belong to differentgenres.
While the OC corpus includes poetry, cook-books, medical and liturgical texts, the MC corpusis mainly comprised of newspaper texts.
We can-not possibly expect a significant overlap in lexiconor syntactic constructions.
For example, the cook-books contain a lot of imperatives and second per-son pronouns which are rare or non-existent in thenewspaper texts.Even though our tagger does not perform as thestate-of-the-art tagger for Czech, the results are al-ready useful.
Remember that the tag is a combina-tion of 12 morphological features and if only one ofthem is incorrect, the whole positional tag is markedas incorrect.
So, the performance of the tagger(74%) on the whole tag is not as low in reality.
Forexample, if one is only interested in detailed POSinformation (the tagset that roughly corresponds tothe English Penn Treebank tagset in size), the per-formance of our system is over 90%.AcknowledgmentsThis research was generously supported bythe Grant Agency Czech Republic (project ID:P406/10/P328) and by the U.S. NSF grants#0916280, #1033275, and #1048406.
We wouldlike to thank Alena M. C?erna?
and Boris Lehec?kafor annotating the testing corpus and for answeringquestions about Old Czech.
We also thank Instituteof Czech Language of the Academy of Sciences ofthe Czech Republic for the plain text corpus of OldCzech.
Finally, we thank anonymous reviewers fortheir insightful comments.
All mistakes are ours.ReferencesBe?mova, A., J. Hajic, B.
Hladka?, and J.
Panevova?(1999).
Morphological and Syntactic Tagging ofthe Prague Dependency Treebank.
In Proceedingsof ATALA Workshop, pp.
21?29.
Paris, France.Bo?hmova?, A., J. Hajic, E.
Hajic?ova?, and B.
Hladka?(2001).
The Prague Dependency Treebank:Three-Level Annotation Scenario.
In A.
Abeille?(Ed.
), Treebanks: Building and Using Syntacti-17cally Annotated Corpora.
Kluwer Academic Pub-lishers.Brants, T. (2000).
TnT ?
A Statistical Part-of-Speech Tagger.
In Proceedings of ANLP-NAACL,pp.
224?231.Cucerzan, S. and D. Yarowsky (2000).
LanguageIndependent Minimally Supervised Induction ofLexical Probabilities.
In Proceedings of the 38thMeeting of the Association for ComputationalLinguistics (ACL), Hong Kong, pp.
270?277.Cucerzan, S. and D. Yarowsky (2002).
Bootstrap-ping a Multilingual Part-of-speech Tagger in OnePerson-day.
In Proceedings of the 6th Confer-ence on Natural Language Learning (CoNLL),pp.
132?138.
Taipei, Taiwan.Dosta?l, A.
(1967).
Historicka?
mluvnice c?eska?
II ?Tvaroslov??.
2.
C?asova?n??
[Historical Czech Gram-mar II - Morphology.
2.
Conjugation].
Prague:SPN.Feldman, A. and J. Hana (2010).
A resource-lightapproach to morpho-syntactic tagging.
Amster-dam/New York, NY: Rodopi.Hajic?, J.
(2004).
Disambiguation of Rich Inflection:Computational Morphology of Czech.
Praha:Karolinum, Charles University Press.Hana, J.
(2008).
Knowledge- and labor-light mor-phological analysis.
OSUWPL 58, 52?84.Hana, J., A. Feldman, and C. Brew (2004, July).
Aresource-light approach to Russian morphology:Tagging Russian using Czech resources.
In D. Linand D. Wu (Eds.
), Proceedings of EMNLP 2004,Barcelona, Spain, pp.
222?229.
Association forComputational Linguistics.Janda, L. A. and C. E. Townsend (2002).
Czech.Karl?
?k, P., M. Nekula, and Z.
Rus??nova?
(1996).Pr???ruc?n??
mluvnice c?es?tiny [Concise Grammar ofCzech].
Praha: Nakladatelstv??
Lidove?
Noviny.Lehec?ka, B. and K. Volekova?
(2011).(polo)automaticka?
poc???tac?ova?
transkripce[(semi)automatic computational transcription].In Proceedings of the Conference De?jiny c?eske?hopravopisu (do r. 1902) [History of the Czechspelling (before 1902)].
in press.Mann, S. E. (1977).
Czech Historical Grammar.Hamburg: Buske.Merialdo, B.
(1994).
Tagging English Text witha Probabilistic Model.
Computational Linguis-tics 20(2), 155?171.Naughton, J.
(2005).
Czech: An Essential Gram-mar.
Oxon, Great Britain and New York, NY,USA: Routledge.Short, D. (1993).
Czech.
In B. Comrie and G. G.Corbett (Eds.
), The Slavonic Languages, Rout-ledge Language Family Descriptions, pp.
455?532.
Routledge.Va?z?ny?, V. (1964).
Historicka?
mluvnice c?eska?
II?
Tvaroslov??.
1.
Sklon?ova?n??
[Historical CzechGrammar II - Morphology.
1.
Declension].Prague: SPN.Yarowsky, D., G. Ngai, and R. Wicentowski (2001).Inducing Multilingual Text Analysis via RobustProjection across Aligned Corpora.
In Proceed-ings of the First International Conference on Hu-man Language Technology Research (HLT), pp.161?168.Zipf, G. K. (1935).
The Psychobiology of Language.Houghton-Mifflin.Zipf, G. K. (1949).
Human Behavior and the Prin-ciple of Least-Effort.
Addison-Wesley.18
