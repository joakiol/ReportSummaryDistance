Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834?842,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPApplication-driven Statistical Paraphrase GenerationShiqi Zhao, Xiang Lan, Ting Liu, Sheng LiInformation Retrieval Lab, Harbin Institute of Technology6F Aoxiao Building, No.27 Jiaohua Street, Nangang DistrictHarbin, 150001, China{zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cnAbstractParaphrase generation (PG) is importantin plenty of NLP applications.
However,the research of PG is far from enough.
Inthis paper, we propose a novel method forstatistical paraphrase generation (SPG),which can (1) achieve various applicationsbased on a uniform statistical model, and(2) naturally combine multiple resourcesto enhance the PG performance.
In ourexperiments, we use the proposed methodto generate paraphrases for three differ-ent applications.
The results show thatthe method can be easily transformed fromone application to another and generatevaluable and interesting paraphrases.1 IntroductionParaphrases are alternative ways that convey thesame meaning.
There are two main threads in theresearch of paraphrasing, i.e., paraphrase recogni-tion and paraphrase generation (PG).
Paraphrasegeneration aims to generate a paraphrase for asource sentence in a certain application.
PG showsits importance in many areas, such as questionexpansion in question answering (QA) (Duboueand Chu-Carroll, 2006), text polishing in natu-ral language generation (NLG) (Iordanskaja et al,1991), text simplification in computer-aided read-ing (Carroll et al, 1999), and sentence similaritycomputation in the automatic evaluation of ma-chine translation (MT) (Kauchak and Barzilay,2006) and summarization (Zhou et al, 2006).This paper presents a method for statisticalparaphrase generation (SPG).
As far as we know,this is the first statistical model specially designedfor paraphrase generation.
It?s distinguishing fea-ture is that it achieves various applications with auniform model.
In addition, it exploits multipleresources, including paraphrase phrases, patterns,and collocations, to resolve the data shortage prob-lem and generate more varied paraphrases.We consider three paraphrase applications inour experiments, including sentence compression,sentence simplification, and sentence similaritycomputation.
The proposed method generatesparaphrases for the input sentences in each appli-cation.
The generated paraphrases are then man-ually scored based on adequacy, fluency, and us-ability.
The results show that the proposed methodis promising, which generates useful paraphrasesfor the given applications.
In addition, comparisonexperiments show that our method outperforms aconventional SMT-based PG method.2 Related WorkConventional methods for paraphrase generationcan be classified as follows:Rule-based methods: Rule-based PG methodsbuild on a set of paraphrase rules or patterns,which are either hand crafted or automaticallycollected.
In the early rule-based PG research,the paraphrase rules are generally manually writ-ten (McKeown, 1979; Zong et al, 2001), whichis expensive and arduous.
Some researchers thentried to automatically extract paraphrase rules (Linand Pantel, 2001; Barzilay and Lee, 2003; Zhaoet al, 2008b), which facilitates the rule-based PGmethods.
However, it has been shown that thecoverage of the paraphrase patterns is not highenough, especially when the used paraphrase pat-terns are long or complicated (Quirk et al, 2004).Thesaurus-based methods: The thesaurus-basedmethods generate a paraphrase t for a source sen-tence s by substituting some words in s withtheir synonyms (Bolshakov and Gelbukh, 2004;834Kauchak and Barzilay, 2006).
This kind of methodusually involves two phases, i.e., candidate extrac-tion and paraphrase validation.
In the first phase,it extracts all synonyms from a thesaurus, such asWordNet, for the words to be substituted.
In thesecond phase, it selects an optimal substitute foreach given word from the synonyms according tothe context in s. This kind of method is simple,since the thesaurus synonyms are easy to access.However, it cannot generate other types of para-phrases but only synonym substitution.NLG-based methods: NLG-based methods (Ko-zlowski et al, 2003; Power and Scott, 2005) gen-erally involve two stages.
In the first one, thesource sentence s is transformed into its semanticrepresentation r by undertaking a series of NLPprocessing, including morphology analyzing, syn-tactic parsing, semantic role labeling, etc.
In thesecond stage, a NLG system is employed to gen-erate a sentence t from r. s and t are paraphrasesas they are both derived from r. The NLG-basedmethods simulate human paraphrasing behavior,i.e., understanding a sentence and presenting themeaning in another way.
However, deep analysisof sentences is a big challenge.
Moreover, devel-oping a NLG system is also not trivial.SMT-based methods: SMT-based methodsviewed PG as monolingual MT, i.e., translating sinto t that are in the same language.
Researchersemploy the existing SMT models for PG (Quirket al, 2004).
Similar to typical SMT, a largeparallel corpus is needed as training data in theSMT-based PG.
However, such data are difficultto acquire compared with the SMT data.
There-fore, data shortage becomes the major limitationof the method.
To address this problem, we havetried combining multiple resources to improve theSMT-based PG model (Zhao et al, 2008a).There have been researchers trying to proposeuniform PG methods for multiple applications.But they are either rule-based (Murata and Isa-hara, 2001; Takahashi et al, 2001) or thesaurus-based (Bolshakov and Gelbukh, 2004), thus theyhave some limitations as stated above.
Further-more, few of them conducted formal experimentsto evaluate the proposed methods.3 Statistical Paraphrase Generation3.1 Differences between SPG and SMTDespite the similarity between PG and MT, thestatistical model used in SMT cannot be directlyapplied in SPG, since there are some clear differ-ences between them:1.
SMT has a unique purpose, i.e., producinghigh-quality translations for the inputs.
Onthe contrary, SPG has distinct purposes indifferent applications, such as sentence com-pression, sentence simplification, etc.
Theusability of the paraphrases have to be as-sessed in each application.2.
In SMT, words of an input sentence shouldbe totally translated, whereas in SPG, not allwords of an input sentence need to be para-phrased.
Therefore, a SPG model should beable to decide which part of a sentence needsto be paraphrased.3.
The bilingual parallel data for SMT are easyto collect.
In contrast, the monolingual paral-lel data for SPG are not so common (Quirket al, 2004).
Thus the SPG model shouldbe able to easily combine different resourcesand thereby solve the data shortage problem(Zhao et al, 2008a).4.
Methods have been proposed for automaticevaluation in MT (e.g., BLEU (Papineni etal., 2002)).
The basic idea is that a translationshould be scored based on their similarity tothe human references.
However, they cannotbe adopted in SPG.
The main reason is that itis more difficult to provide human referencesin SPG.
Lin and Pantel (2001) have demon-strated that the overlapping between the au-tomatically acquired paraphrases and hand-crafted ones is very small.
Thus the humanreferences cannot properly assess the qualityof the generated paraphrases.3.2 Method OverviewThe SPG method proposed in this work containsthree components, i.e., sentence preprocessing,paraphrase planning, and paraphrase generation(Figure 1).
Sentence preprocessing mainly in-cludes POS tagging and dependency parsing forthe input sentences, as POS tags and dependencyinformation are necessary for matching the para-phrase pattern and collocation resources in thefollowing stages.
Paraphrase planning (Section3.3) aims to select the units to be paraphrased(called source units henceforth) in an input sen-tence and the candidate paraphrases for the source835Multiple Paraphrase TablesPT1 ?
?ParaphrasePlanningParaphraseGeneration tSentencePreprocessingsAPT2 PTnFigure 1: Overview of the proposed SPG method.units (called target units) from multiple resourcesaccording to the given application A. Paraphrasegeneration (Section 3.4) is designed to generateparaphrases for the input sentences by selectingthe optimal target units with a statistical model.3.3 Paraphrase PlanningIn this work, the multiple paraphrase resources arestored in paraphrase tables (PTs).
A paraphrase ta-ble is similar to a phrase table in SMT, which con-tains fine-grained paraphrases, such as paraphrasephrases, patterns, or collocations.
The PTs used inthis work are constructed using different corporaand different score functions (Section 3.5).If the applications are not considered, all unitsof an input sentence that can be paraphrased us-ing the PTs will be extracted as source units.
Ac-cordingly, all paraphrases for the source units willbe extracted as target units.
However, when a cer-tain application is given, only the source and targetunits that can achieve the application will be kept.We call this process paraphrase planning, which isformally defined as in Figure 2.An example is depicted in Figure 3.
The ap-plication in this example is sentence compression.All source and target units are listed below the in-put sentence, in which the first two source unitsare phrases, while the third and fourth are a patternand a collocation, respectively.
As can be seen, thefirst and fourth source units are filtered in para-phrase planning, since none of their paraphrasesachieve the application (i.e., shorter in bytes thanthe source).
The second and third source units arekept, but some of their paraphrases are filtered.3.4 Paraphrase GenerationOur SPG model contains three sub-models: aparaphrase model, a language model, and a usabil-ity model, which control the adequacy, fluency,Input: source sentence sInput: paraphrase application AInput: paraphrase tables PTsOutput: set of source units SUOutput: set of target units TUExtract source units of s from PTs: SU={su1, ?, sun}For each source unit suiExtract its target units TUi={tui1, ?, tuim}For each target unit tuijIf tuij cannot achieve the application ADelete tuij from TUiEnd IfEnd ForIf TUi is emptyDelete sui from SUEnd IfEnd forFigure 2: The paraphrase planning algorithm.and usability of the paraphrases, respectively1.Paraphrase Model: Paraphrase generation is adecoding process.
The input sentence s is firstsegmented into a sequence of I units s?I1, whichare then paraphrased to a sequence of units t?I1.Let (s?i, t?i) be a pair of paraphrase units, theirparaphrase likelihood is computed using a scorefunction ?pm(s?i, t?i).
Thus the paraphrase scoreppm(s?I1, t?I1) between s and t is decomposed into:ppm(s?I1, t?I1) =I?i=1?pm(s?i, t?i)?pm (1)where ?pm is the weight of the paraphrase model.Actually, it is defined similarly to the translationmodel in SMT (Koehn et al, 2003).In practice, the units of a sentence may be para-phrased using different PTs.
Suppose we have KPTs, (s?ki , t?ki) is a pair of paraphrase units fromthe k-th PT with the score function ?k(s?ki , t?ki),then Equation (1) can be rewritten as:ppm(s?I1, t?I1) =K?k=1(?ki?k(s?ki , t?ki)?k) (2)where ?k is the weight for ?k(s?ki , t?ki).Equation (2) assumes that a pair of paraphraseunits is from only one paraphrase table.
However,1The SPG model applies monotone decoding, which doesnot contain a reordering sub-model that is often used in SMT.Instead, we use the paraphrase patterns to achieve word re-ordering in paraphrase generation.836The US government should take the overall situation into consideration and actively promote bilateral high-tech trades.The US governmentThe US administrationThe US government onoverall situationoverall interestoverall pictureoverviewsituation as a wholewhole situationtake [NN_1] into considerationconsider [NN_1]take into account [NN_1]take account of [NN_1]take [NN_1] into accounttake into consideration [NN_1]<promote, OBJ, trades><sanction, OBJ, trades><stimulate, OBJ, trades><strengthen, OBJ, trades><support, OBJ, trades><sustain, OBJ, trades>Paraphrase application: sentence compressionFigure 3: An example of paraphrase planning.we find that about 2% of the paraphrase units ap-pear in two or more PTs.
In this case, we onlycount the PT that provides the largest paraphrasescore, i.e., k?
= argmaxk{?k(s?i, t?i)?k}.In addition, note that there may be some unitsthat cannot be paraphrased or prefer to keep un-changed during paraphrasing.
Therefore, we havea self-paraphrase table in the K PTs, which para-phrases any separate word w into itself with a con-stant score c: ?self (w,w) = c (we set c = e?1).Language Model: We use a tri-gram languagemodel in this work.
The language model basedscore for the paraphrase t is computed as:plm(t) =J?j=1p(tj |tj?2tj?1)?lm (3)where J is the length of t, tj is the j-th word of t,and ?lm is the weight for the language model.Usability Model: The usability model prefersparaphrase units that can better achieve the ap-plication.
The usability of t depends on para-phrase units it contains.
Hence the usability modelpum(s?I1, t?I1) is decomposed into:pum(s?I1, t?I1) =I?i=1pum(s?i, t?i)?um (4)where ?um is the weight for the usability modeland pum(s?i, t?i) is defined as follows:pum(s?i, t?i) = e?
(s?i,t?i) (5)We consider three applications, including sentencecompression, simplification, and similarity com-putation.
?
(s?i, t?i) is defined separately for each:?
Sentence compression: Sentence compres-sion2 is important for summarization, subti-tle generation, and displaying texts in smallscreens such as cell phones.
In this appli-cation, only the target units shorter than thesources are kept in paraphrase planning.
Wedefine ?
(s?i, t?i) = len(s?i) ?
len(t?i), wherelen(?)
denotes the length of a unit in bytes.?
Sentence simplification: Sentence simplifi-cation requires using common expressions insentences so that readers can easily under-stand the meaning.
Therefore, only the targetunits more frequent than the sources are keptin paraphrase planning.
Here, the frequencyof a unit is measured using the languagemodel mentioned above3.
Specifically, thelangauge model assigns a score scorelm(?
)for each unit and the unit with larger scoreis viewed as more frequent.
We define?
(s?i, t?i) = 1 iff scorelm(t?i) > scorelm(s?i).?
Sentence similarity computation: Given areference sentence s?, this application aims toparaphrase s into t, so that t is more similar(closer in wording) with s?
than s. This ap-plication is important for the automatic eval-uation of machine translation and summa-rization, since we can paraphrase the humantranslations/summaries to make them moresimilar to the system outputs, which can re-fine the accuracy of the evaluation (Kauchakand Barzilay, 2006).
For this application,2This work defines compression as the shortening of sen-tence length in bytes rather than in words.3To compute the language model based score, thematched patterns are instantiated and the matched colloca-tions are connected with words between them.837only the target units that can enhance the sim-ilarity to the reference sentence are kept inplanning.
We define ?
(s?i, t?i) = sim(t?i, s?
)?sim(s?i, s?
), where sim(?, ?)
is simply com-puted as the count of overlapping words.We combine the three sub-models based on alog-linear framework and get the SPG model:p(t|s) =K?k=1(?k?kilog ?k(s?ki , t?ki))+ ?lmJ?j=1log p(tj |tj?2tj?1)+ ?umI?i=1?
(s?i, t?i) (6)3.5 Paraphrase ResourcesWe use five PTs in this work (except the self-paraphrase table), in which each pair of paraphraseunits has a score assigned by the score function ofthe corresponding method.Paraphrase phrases (PT-1 to PT-3): Para-phrase phrases are extracted from three corpora:(1) Corp-1: bilingual parallel corpus, (2) Corp-2: monolingual comparable corpus (comparablenews articles reporting on the same event), and(3) Corp-3: monolingual parallel corpus (paral-lel translations of the same foreign novel).
Thedetails of the corpora, methods, and score func-tions are presented in (Zhao et al, 2008a).
Inour experiments, PT-1 is the largest, which con-tains 3,041,822 pairs of paraphrase phrases.
PT-2and PT-3 contain 92,358, and 17,668 pairs of para-phrase phrases, respectively.Paraphrase patterns (PT-4): Paraphrase patternsare also extracted from Corp-1.
We applied the ap-proach proposed in (Zhao et al, 2008b).
Its basicassumption is that if two English patterns e1 and e2are aligned with the same foreign pattern f , thene1 and e2 are possible paraphrases.
One can referto (Zhao et al, 2008b) for the details.
PT-4 con-tains 1,018,371 pairs of paraphrase patterns.Paraphrase collocations (PT-5): Collocations4can cover long distance dependencies in sen-tences.
Thus paraphrase collocations are useful forSPG.
We extract collocations from a monolingual4A collocation is a lexically restricted word pair with acertain syntactic relation.
This work only considers verb-object collocations, e.g., <promote, OBJ, trades>.corpus and use a binary classifier to recognize ifany two collocations are paraphrases.
Due to thespace limit, we cannot introduce the detail of theapproach.
We assign the score ?1?
for any pairof paraphrase collocations.
PT-5 contains 238,882pairs of paraphrase collocations.3.6 Parameter EstimationTo estimate parameters ?k(1 ?
k ?
K), ?lm,and ?um, we adopt the approach of minimum errorrate training (MERT) that is popular in SMT (Och,2003).
In SMT, however, the optimization objec-tive function in MERT is the MT evaluation cri-teria, such as BLEU.
As we analyzed above, theBLEU-style criteria cannot be adapted in SPG.
Wetherefore introduce a new optimization objectivefunction in this paper.
The basic assumption is thata paraphrase should contain as many correct unitreplacements as possible.
Accordingly, we designthe following criteria:Replacement precision (rp): rp assesses the pre-cision of the unit replacements, which is definedas rp = cdev(+r)/cdev(r), where cdev(r) is thetotal number of unit replacements in the generatedparaphrases on the development set.
cdev(+r) isthe number of the correct replacements.Replacement rate (rr): rr measures the para-phrase degree on the development set, i.e., the per-centage of words that are paraphrased.
We definerr as: rr = wdev(r)/wdev(s), where wdev(r) isthe total number of words in the replaced units onthe development set, and wdev(s) is the number ofwords of all sentences on the development set.Replacement f-measure (rf): We use rf as theoptimization objective function in MERT, whichis similar to the conventional f-measure and lever-ages rp and rr: rf = (2?
rp?
rr)/(rp+ rr).We estimate parameters for each paraphrase ap-plication separately.
For each application, we firstask two raters to manually label all possible unitreplacements on the development set as correct orincorrect, so that rp, rr, and rf can be automati-cally computed under each set of parameters.
Theparameters that result in the highest rf on the de-velopment set are finally selected.4 Experimental SetupOur SPG decoder is developed by remodelingMoses that is widely used in SMT (Hoang andKoehn, 2008).
The POS tagger and depen-dency parser for sentence preprocessing are SVM-838Tool (Gimenez and Marquez, 2004) and MST-Parser (McDonald et al, 2006).
The languagemodel is trained using a 9 GB English corpus.4.1 Experimental DataOur method is not restricted in domain or sentencestyle.
Thus any sentence can be used in develop-ment and test.
However, for the sentence similaritycomputation purpose in our experiments, we wantto evaluate if the method can enhance the string-level similarity between two paraphrase sentences.Therefore, for each input sentence s, we need areference sentence s?
for similarity computation.Based on the above consideration, we acquireexperiment data from the human references ofthe MT evaluation, which provide several humantranslations for each foreign sentence.
In detail,we use the first translation of a foreign sentenceas the source s and the second translation as thereference s?
for similarity computation.
In our ex-periments, the development set contains 200 sen-tences and the test set contains 500 sentences, bothof which are randomly selected from the humantranslations of 2008 NIST Open Machine Transla-tion Evaluation: Chinese to English Task.4.2 Evaluation MetricsThe evaluation metrics for SPG are similar to thehuman evaluation for MT (Callison-Burch et al,2007).
The generated paraphrases are manuallyevaluated based on three criteria, i.e., adequacy,fluency, and usability, each of which has threescales from 1 to 3.
Here is a brief description ofthe different scales for the criteria:Adequacy 1: The meaning is evidently changed.2: The meaning is generally preserved.3: The meaning is completely preserved.Fluency 1: The paraphrase t is incomprehensible.2: t is comprehensible.3: t is a flawless sentence.Usability 1: t is opposite to the application purpose.2: t does not achieve the application.3: t achieves the application.5 Results and AnalysisWe use our method to generate paraphrases for thethree applications.
Results show that the percent-ages of test sentences that can be paraphrased are97.2%, 95.4%, and 56.8% for the applications ofsentence compression, simplification, and similar-ity computation, respectively.
The reason why thelast percentage is much lower than the first twois that, for sentence similarity computation, manysentences cannot find unit replacements from thePTs that improve the similarity to the referencesentences.
For the other applications, only somevery short sentences cannot be paraphrased.Further results show that the average number ofunit replacements in each sentence is 5.36, 4.47,and 1.87 for sentence compression, simplification,and similarity computation.
It also indicates thatsentence similarity computation is more difficultthan the other two applications.5.1 Evaluation of the Proposed MethodWe ask two raters to label the paraphrases basedon the criteria defined in Section 4.2.
The labelingresults are shown in the upper part of Table 1.
Wecan see that for adequacy and fluency, the para-phrases in sentence similarity computation get thehighest scores.
About 70% of the paraphrases arelabeled ?3?.
This is because in sentence similar-ity computation, only the target units appearingin the reference sentences are kept in paraphraseplanning.
This constraint filters most of the noise.The adequacy and fluency scores of the other twoapplications are not high.
The percentages of la-bel ?3?
are around 30%.
The main reason is thatthe average numbers of unit replacements for thesetwo applications are much larger than sentencesimilarity computation.
It is thus more likely tobring in incorrect unit replacements, which influ-ence the quality of the generated paraphrases.The usability is needed to be manually labeledonly for sentence simplification, since it can beautomatically labeled in the other two applica-tions.
As shown in Table 1, for sentence simplifi-cation, most paraphrases are labeled ?2?
in usabil-ity, while merely less than 20% are labeled ?3?.We conjecture that it is because the raters are notsensitive to the slight change of the simplificationdegree.
Thus they labeled ?2?
in most cases.We compute the kappa statistic between theraters.
Kappa is defined as K = P (A)?P (E)1?P (E) (Car-letta, 1996), where P (A) is the proportion of timesthat the labels agree, and P (E) is the proportionof times that they may agree by chance.
We defineP (E) = 13 , as the labeling is based on three pointscales.
The results show that the kappa statisticsfor adequacy and fluency are 0.6560 and 0.6500,which indicates a substantial agreement (K: 0.61-0.8) according to (Landis and Koch, 1977).
The839Adequacy (%) Fluency (%) Usability (%)1 2 3 1 2 3 1 2 3Sentence rater1 32.92 44.44 22.63 21.60 47.53 30.86 0 0 100compression rater2 40.54 34.98 24.49 25.51 43.83 30.66 0 0 100Sentence rater1 29.77 44.03 26.21 22.01 42.77 35.22 25.37 61.84 12.79simplification rater2 33.33 35.43 31.24 24.32 39.83 35.85 30.19 51.99 17.82Sentence rater1 7.75 24.30 67.96 7.75 22.54 69.72 0 0 100similarity rater2 7.75 19.01 73.24 6.69 21.48 71.83 0 0 100Baseline-1 rater1 47.31 30.75 21.94 43.01 33.12 23.87 - - -rater2 47.10 30.11 22.80 34.41 41.51 24.09 - - -Baseline-2 rater1 29.45 52.76 17.79 25.15 52.76 22.09 - - -rater2 33.95 46.01 20.04 27.61 48.06 24.34 - - -Table 1: The evaluation results of the proposed method and two baseline methods.kappa statistic for usability is 0.5849, which isonly moderate (K: 0.41-0.6).Table 2 shows an example of the generated para-phrases.
A source sentence s is paraphrased ineach application and we can see that: (1) for sen-tence compression, the paraphrase t is 8 bytesshorter than s; (2) for sentence simplification, thewords wealth and part in t are easier than theirsources asset and proportion, especially for thenon-native speakers; (3) for sentence similaritycomputation, the reference sentence s?
is listed be-low t, in which the words appearing in t but not ins are highlighted in blue.5.2 Comparison with Baseline MethodsIn our experiments, we implement two baselinemethods for comparison:Baseline-1: Baseline-1 follows the method pro-posed in (Quirk et al, 2004), which generatesparaphrases using typical SMT tools.
Similar toQuirk et al?s method, we extract a paraphrase ta-ble for the SMT model from a monolingual com-parable corpus (PT-2 described above).
The SMTdecoder used in Baseline-1 is Moses.Baseline-2: Baseline-2 extends Baseline-1 bycombining multiple resources.
It exploits all PTsintroduced above in the same way as our pro-posed method.
The difference from our method isthat Baseline-2 does not take different applicationsinto consideration.
Thus it contains no paraphraseplanning stage or the usability sub-model.We tune the parameters for the two baselinesusing the development data as described in Sec-tion 3.6 and evaluate them with the test data.
Sinceparaphrase applications are not considered by thebaselines, each baseline method outputs a singlebest paraphrase for each test sentence.
The gener-ation results show that 93% and 97.8% of the testsentences can be paraphrased by Baseline-1 andBaseline-2.
The average number of unit replace-ments per sentence is 4.23 and 5.95, respectively.This result suggests that Baseline-1 is less capa-ble than Baseline-2, which is mainly because itsparaphrase resource is limited.The generated paraphrases are also labeled byour two raters and the labeling results can be foundin the lower part of Table 1.
As can be seen,Baseline-1 performs poorly compared with ourmethod and Baseline-2, as the percentage of la-bel ?1?
is the highest for both adequacy and flu-ency.
This result demonstrates that it is necessaryto combine multiple paraphrase resources to im-prove the paraphrase generation performance.Table 1 also shows that Baseline-2 performscomparably with our method except that it doesnot consider paraphrase applications.
However,we are interested how many paraphrases gener-ated by Baseline-2 can achieve the given applica-tions by chance.
After analyzing the results, wefind that 24.95%, 8.79%, and 7.16% of the para-phrases achieve sentence compression, simplifi-cation, and similarity computation, respectively,which are much lower than our method.5.3 Informal Comparison with ApplicationSpecific MethodsPrevious research regarded sentence compression,simplification, and similarity computation as to-tally different problems and proposed distinctmethod for each one.
Therefore, it is interestingto compare our method to the application-specificmethods.
However, it is really difficult for us to840SourcesentenceLiu Lefei says that in the long term, in terms of asset alocation, overseas investment should occupy acertain proportion of an insurance company?s overall allocation.SentencecompressionLiu Lefei says that in [the long run]phr , [in area of [asset alocation][NN 1]]pat, overseas investmentshould occupy [a [certain][JJ 1] part of [an insurance company?s overall allocation][NN 1]]pat.SentencesimplificationLiu Lefei says that in [the long run]phr , in terms of [wealth]phr [distribution]phr , overseas investmentshould occupy [a [certain][JJ 1] part of [an insurance company?s overall allocation][NN 1]]pat.SentencesimilarityLiu Lefei says that in [the long run]phr , in terms [of capital]phr allocation, overseas investment shouldoccupy [the [certain][JJ 1] ratio of [an insurance company?s overall allocation][NN 1]]pat.
(reference sentence: Liu Lefei said that in terms of capital allocation, outbound investment should makeup a certain ratio of overall allocations for insurance companies in the long run .
)Table 2: The generated paraphrases of a source sentence for different applications.
The target units afterreplacement are shown in blue and the pattern slot fillers are in cyan.
[?
]phr denotes that the unit is aphrase, while [?
]pat denotes that the unit is a pattern.
There is no collocation replacement in this example.reimplement the methods purposely designed forthese applications.
Thus here we just conduct aninformal comparison with these methods.Sentence compression: Sentence compressionis widely studied, which is mostly reviewed as aword deletion task.
Different from prior research,Cohn and Lapata (2008) achieved sentence com-pression using a combination of several opera-tions including word deletion, substitution, inser-tion, and reordering based on a statistical model,which is similar to our paraphrase generation pro-cess.
Besides, they also used paraphrase patternsextracted from bilingual parallel corpora (like ourPT-4) as a kind of rewriting resource.
However,as most other sentence compression methods, theirmethod allows information loss after compression,which means that the generated sentences are notnecessarily paraphrases of the source sentences.Sentence Simplification: Carroll et al (1999)has proposed an automatic text simplificationmethod for language-impaired readers.
Theirmethod contains two main parts, namely the lex-ical simplifier and syntactic simplifier.
The for-mer one focuses on replacing words with simplersynonyms, while the latter is designed to transfercomplex syntactic structures into easy ones (e.g.,replacing passive sentences with active forms).Our method is, to some extent, simpler than Car-roll et al?s, since our method does not contain syn-tactic simplification strategies.
We will try to ad-dress sentence restructuring in our future work.Sentence Similarity computation: Kauchakand Barzilay (2006) have tried paraphrasing-basedsentence similarity computation.
They paraphrasea sentence s by replacing its words with Word-Net synonyms, so that s can be more similar inwording to another sentence s?.
A similar methodhas also been proposed in (Zhou et al, 2006),which uses paraphrase phrases like our PT-1 in-stead of WordNet synonyms.
These methods canbe roughly viewed as special cases of ours, whichonly focus on the sentence similarity computationapplication and only use one kind of paraphraseresource.6 Conclusions and Future WorkThis paper proposes a method for statistical para-phrase generation.
The contributions are as fol-lows.
(1) It is the first statistical model spe-cially designed for paraphrase generation, whichis based on the analysis of the differences betweenparaphrase generation and other researches, espe-cially machine translation.
(2) It generates para-phrases for different applications with a uniformmodel, rather than presenting distinct methods foreach application.
(3) It uses multiple resources,including paraphrase phrases, patterns, and collo-cations, to relieve data shortage and generate morevaried and interesting paraphrases.Our future work will be carried out along twodirections.
First, we will improve the componentsof the method, especially the paraphrase planningalgorithm.
The algorithm currently used is sim-ple but greedy, which may miss some useful para-phrase units.
Second, we will extend the method toother applications, We hope it can serve as a uni-versal framework for most if not all applications.AcknowledgementsThe research was supported by NSFC (60803093,60675034) and 863 Program (2008AA01Z144).Special thanks to Wanxiang Che, Ruifang He,Yanyan Zhao, Yuhang Guo and the anonymous re-viewers for insightful comments and suggestions.841ReferencesRegina Barzilay and Lillian Lee.
2003.
Learningto Paraphrase: An Unsupervised Approach UsingMultiple-Sequence Alignment.
In Proceedings ofHLT-NAACL, pages 16-23.Igor A. Bolshakov and Alexander Gelbukh.
2004.Synonymous Paraphrasing Using WordNet and In-ternet.
In Proceedings of NLDB, pages 312-323.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2007.
(Meta-) Evaluation of Machine Translation.
In Pro-ceedings of ACL Workshop on Statistical MachineTranslation, pages 136-158.Jean Carletta.
1996.
Assessing Agreement on Clas-sification Tasks: The Kappa Statistic.
In Computa-tional Linguistics, 22(2): 249-254.John Carroll, Guido Minnen, Darren Pearce, YvonneCanning, Siobhan Devlin, John Tait.
1999.
Simpli-fying Text for Language-Impaired Readers.
In Pro-ceedings of EACL, pages 269-270.Trevor Cohn and Mirella Lapata.
2008.
SentenceCompression Beyond Word Deletion In Proceed-ings of COLING, pages 137-144.Pablo Ariel Duboue and Jennifer Chu-Carroll.
2006.Answering the Question You Wish They Had Asked:The impact of paraphrasing for Question Answer-ing.
In Proceedings of HLT-NAACL, pages 33-36.Jesus Gimenez and Lluis Marquez.
2004.
SVMTool:A general POS tagger generator based on SupportVector Machines.
In Proceedings of LREC, pages43-46.Hieu Hoang and Philipp Koehn.
2008.
Design of theMoses Decoder for Statistical Machine Translation.In Proceedings of ACL Workshop on Software en-gineering, testing, and quality assurance for NLP,pages 58-65.Lidija Iordanskaja, Richard Kittredge, and AlainPolgue`re.
1991.
Lexical Selection and Paraphrasein a Meaning-Text Generation Model.
In Ce?cile L.Paris, William R. Swartout, and William C.
Mann(Eds.
): Natural Language Generation in ArtificialIntelligence and Computational Linguistics, pages293-312.David Kauchak and Regina Barzilay.
2006.
Paraphras-ing for Automatic Evaluation.
In Proceedings ofHLT-NAACL, pages 455-462.Philipp Koehn, Franz Josef Och, Daniel Marcu.
2003.Statistical Phrase-Based Translation.
In Proceed-ings of HLT-NAACL, pages 127-133.Raymond Kozlowski, Kathleen F. McCoy, and K.Vijay-Shanker.
2003.
Generation of single-sentenceparaphrases from predicate/argument structure us-ing lexico-grammatical resources.
In Proceedingsof IWP, pages 1-8.J.
R. Landis and G. G. Koch.
1977.
The Measure-ment of Observer Agreement for Categorical Data.In Biometrics 33(1): 159-174.De-Kang Lin and Patrick Pantel.
2001.
Discovery ofInference Rules for Question Answering.
In NaturalLanguage Engineering 7(4): 343-360.Ryan McDonald, Kevin Lerman, and Fernando Pereira.2006.
Multilingual Dependency Parsing with aTwo-Stage Discriminative Parser.
In Proceedings ofCoNLL.Kathleen R. McKeown.
1979.
Paraphrasing UsingGiven and New Information in a Question-AnswerSystem.
In Proceedings of ACL, pages 67-72.Masaki Murata and Hitoshi Isahara.
2001.
Univer-sal Model for Paraphrasing - Using TransformationBased on a Defined Criteria.
In Proceedings of NL-PRS, pages 47-54.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedingsof ACL, pages 160-167.Kishore Papineni, Salim Roukos, Todd Ward, Wei-JingZhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings ofACL, pages 311-318.Richard Power and Donia Scott.
2005.
Automatic gen-eration of large-scale paraphrases.
In Proceedings ofIWP, pages 73-79.Chris Quirk, Chris Brockett, and William Dolan.
2004.Monolingual Machine Translation for ParaphraseGeneration.
In Proceedings of EMNLP, pages 142-149.Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, At-sushi Fujita, Kentaro Inui.
2001.
KURA: ATransfer-based Lexico-structural Paraphrasing En-gine.
In Proceedings of NLPRS, pages 37-46.Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, andSheng Li.
2008a.
Combining Multiple Resourcesto Improve SMT-based Paraphrasing Model.
In Pro-ceedings of ACL-08:HLT, pages 1021-1029.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008b.
Pivot Approach for Extracting ParaphrasePatterns from Bilingual Corpora.
In Proceedings ofACL-08:HLT, pages 780-788.Liang Zhou, Chin-Yew Lin, Dragos Stefan Munteanu,and Eduard Hovy.
2006.
ParaEval: Using Para-phrases to Evaluate Summaries Automatically.
InProceedings of HLT-NAACL, pages 447-454.Chengqing Zong, Yujie Zhang, Kazuhide Yamamoto,Masashi Sakamoto, Satoshi Shirai.
2001.
Approachto Spoken Chinese Paraphrasing Based on FeatureExtraction.
In Proceedings of NLPRS, pages 551-556.842
