First Joint Conference on Lexical and Computational Semantics (*SEM), pages 506?513,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsZhou qiaoli: A divide-and-conquer strategy forsemantic dependency parsingQiaoli Zhou Ling Zhang Fei Liu DongfengCaiGuipingZhangKnowledge EngineeringResearch Center Shenyang Aerospace UniversityNo.37 Daoyi South AvenueShenyang, Liaoning, ChinaZhou_qiao_li@hotmail.com710138892@qq.comfei_l2011@163.comcaidf@vip.163.comzgp@ge-soft.comAbstractWe describe our SemEval2012 shared Task 5system in this paper.
The system includesthree cascaded components: the tagging se-mantic role phrase, the identification of se-mantic role phrase, phrase and frame semanticdependency parsing.
In this paper, semanticrole phrase is tagged automatically based onrules, and takes Conditional Random Fields(CRFs) as the statistical identification modelof semantic role phrase.
A projective graph-based parser is used as our semantic depend-ency parser.
Finally, we gain Labeled At-tachment Score (LAS) of 61.84%, whichranked the first position.
At present, we gainthe LAS of 62.08%, which is 0.24% higherthan that ranked the first position in the task 5.1 System ArchitectureTo solve the problem of low accuracy of long dis-tance dependency parsing, this paper proposes adivide-and-conquer strategy for semantic depend-ency parsing.
Firstly, Semantic Role (SR) phrase ina sentence are identified; next, SR phrase can bereplaced by their head or SR of head.
Therefore,the original sentence is divided into two kinds ofparts, which can be parsed separately.
The firstkind is SR phrase parsing; the second kind isparsing the sentence in which the SR phrases arereplaced by their head or SR of head.
Finally, thepaper takes graph-based parser as the semantic de-pendency parser for all parts.
They are described inSection 2 and Section 4.
Their experimental resultsare shown in Section5.
Section 6 gives our conclu-sion and future work.2 SR Phrase Tagging and FrameTo identify SR phrase, SR phrase of train corpusare tagged.
SR phrase is tagged automaticallybased on rules in this paper.
A phrase of the sen-tence is called Semantic Role phrase (SR phrase)when the parent of only one word of this phrase isout of this phrase.
The word with the parent out ofthe phrase is called Head of Phrase (HP).
Theshortest SR phrase is one word, while the longestSR phrase is a part of the sentence.
In this paper,the new sequence in which phrases are replaced bytheir head or SR of head is defined as the frame.
Inthis paper, firstly, SR phrases of the sentence areidentified; secondly, the whole sentence is dividedinto SR phrases and frame; thirdly, SR phrase andframe semantic dependency are parsed; finally, thedependency parsing results of all components arecombined into the dependency parsing result of thewhole sentence.SR of HP is used as the type of this phrase.
Onlyparts of types of SR phrases are tagged.
In this pa-per, the tagged SR phrases are divided into two506types: Main Semantic Role (MSR) phrase andPreposition Semantic Role (PSR) phrase.2.1 MSR Phrase TaggingIn this paper, MSR phrase includes: OfPart, agent,basis, concerning, content, contrast, cost, existent,experiencer, isa, partner, patient, possession, pos-sessor, relevant, scope and whole.
MSR phrasetagging rules are shown in figure1&2.Figure1: Tagging Rule of the Last Word of MSR PhraseFigure 1 shows the rule for identification of thelast word of MSR phrase.
If the SR of the currentword is MSR and its POS is not VV, VE, VC orVA, it is the last word of phrase.As shown in the figure 2, the first word ofphrase is found based on the last word of phrase.The child with the longest distance from the lastword of phrase is used as the current word, and ifthe current word has no child, it is the first word ofphrase; otherwise, the child of the current word isfound recursively.
If the first word of phrase POSis preposition and punctuation, and its parent is thelast word, the word following the first word servesas the first word of phrase.Figure2: Tagging Rule of the First Word of MSR PhraseFigure3: Example of the Tagging MSR PhraseAs shown in the figure 3, the first column isword ID and the seventh column is parent ID ofword.
SR of ID40 is content, so ID40 is the lastword of phrase.
Its children include ID39 and ID37,thus ID37 with the longest distance from ID40 isthe current word.
The child of ID37 is ID33, thechild of ID33 is ID32, ID32 has no child, and ID32is the first word of SR phrase.The tagged result in the above figure 3 is as fol-lows: ?/CC ?/VC ?
?/VV content[ ?
?/JJ ??
/NN ?
/CC ??
/NR ?
/ETC ??
/NN ?/DEG ?
?/NN ?
?/NN ]Input: wi: word index (ID) in a given sentence.N: the number of words.Mi: MSR list.Vi: POS tags listOutput: the last word ID of MSR phraseFunction: Findmainsemanticword(wi): return wordID when wi of semantic belongs to Mi.Otherwise return 0.Function: FindPOSword(wi): return true when wiof POS tagging not belongs to Vi.
Oth-erwise return 0.Function Findlastword(wi)For i?1 to N do beginIf (Findmainsemanticword(wi)&&FindPOSword(wi)){return wi;}else {i++;}endreturn 0;29  ?
?
CC  CC  _  30  aux-depend  _  _30  ?
?
VC  VC  _  58 s-succession  _  _31  ??
??
VV  VV  _  54  s-succession _  _32  ??
??
JJ   JJ  _  33  d-attribute  _  _33  ??
??
NN  NN  _  37  s-coordinate  _  _34  ?
?
CC  CC  _  37  aux-depend  _  _35  ??
??
NR  NR  _  37  d-member  _  _36  ?
?
ETC  ETC  _  35  aux-depend  _  _37  ??
??
NN  NN  _  40  d-genetive  _  _38  ?
?
DEG  DEG  _  37  aux-depend  _  _39  ??
??
NN  NN  _  40  s-coordinate  _ _40  ??
??
NN  NN  _  31  content  _  _Input: Lword: the last word ID of MSR phrase.Output: Fword: the first word ID of MSR phrase.Function: Findmaxlenchild (w): return child IDwith the longest distance from w when whas child.
Otherwise returns 0.Fuction: FindPOSword(w): return POS of w.Fuction:Findparent(w): return parent ID of w.Function Findfirstword(Lword)If(Findmaxlenchild (Lword)= =0){return Lword;}Else {Fword=Findmaxlenchildword(Lword);If(findPOSword(Fword)==P||findPOSword(Fword)= =PU){If (findparent(Fword)= =Lword)Return Fword +1;}Findfirstword(Fword);}507After phrases are tagged, a new sequence gener-ated by replacing the phrase with HP is calledMSR frame.MSR frame: ?/CC ?/VC ?
?/VV ?
?/NNExample of sentences with nested phrases:?/P ?
?/JJ ?
?/NN ?/PU ?
?/NT exis-tent[ ?
/P ??
/NR ??
/NN ??
/VV con-tent[ ?
?/NN ] ?/DEC ?
?/NN ??
?/NN ]?/AD ?/VE ????
?/CD ?/MAfter phrases are tagged, a new sequence gener-ated by replacing the phrase with HP is calledMSR frame.MSR frame: ?/P ?
?/JJ ?
?/NN ?/PU ??/NT??
?/NN ?/AD ?/VE ????
?/CD ?/M2.2 PSR Phrase TaggingIn this paper, SR phrase containing preposition isdefined as PSR phrase.
If the POS tags of the cur-rent word is Preposition (P), the first word and thelast word of PSR phrase are found based on thecurrent word.
PSR phrase tagging rule as figure 4& 5.Figure 4: Tagging Rule of the First Word of PSR PhraseAs shown in the figure 4, the child with thelongest distance from the current word is the firstword of phrase.
If the prep has no child, then it isPSR phrase.As shown in the figure 5, firstly, the parent ofthe prep is found; next, the parent is taken as thecurrent word, and the child with the longest dis-tance from the current word is found recursively.
Ifno child is found, the current word is the last wordof PSR phrase.
If preposition of SR is root or par-ent of preposition is root, and proposition is PSR.If ID of preposition is larger than ID of parent ofpreposition, and preposition is PSR.Figure5: Tagging Rule of the Last Word of PSR PhraseFigure6: Example of the Tagging PSR PhraseAs shown in the figure6, ID4 is prep, and it hasno child, so the first word is ID4.
The parent ofInput: Pword: the word ID that word POS tags is P.Output: Fword: the first word ID of PSR phrase.Function: Findmaxlenchildword(w): return word IDwith the longest distance from w when whas child.
Otherwise returns 0.Function Findfirstword(Pword)If(Findmaxlenchildword(Pword)= =0){return Pword;}Else {return Fwrod=Findmaxlenchildword(Pword);}Input: Pword: the word ID that word POS tags is P.Output: Lword: the last word ID of PSR phrase.Function: Findmaxchild (w): return word ID thatlength is max with w when w has child.Otherwise return 0.Function: Findparent (w): return word ID when w ofparent is not root.
Otherwise return 0.Function: Findroot(w): return 1 when w of semanticrole is root.
Other wise return 0.Function Findlastword(Pword)Var cword: parent IDIf(Findparentsword(Pword)= =0||findroot(Pword)= =1)  {return Pword;}else { cword=Findparent (Pword) )If(Pword>cword){return Pword;}else {if(Findmaxchild (cword)= =0) {return cword;}else{Lword=Findmaxchild (cword);Findlastword(Lword);}}}1  ??
??
NN  NN  _  2  j-agent  _  _2  ??
??
NN  NN  _  3  r-patient  _  _3  ??
??
NN  NN  _  11  agent  _  _4  ?
?
P P  _ 5  prep-depend  _ first word5  ??
??
VV  VV  _  11 duration _ head_6  ??
??
NR  NR _ 8  d-genetive  _ _7  ??
??
NN  NN _  8 r-patient _ _8  ??
??
NN  NN _ 9 d-host _  _9  ??
??
NN  NN _ 5 patient  _  _10  ?
?
LC  LC  _ 5  aux-depend _ last word_11  ??
??
VV VV  _  0  ROOT _  _12  ?
?
AS  AS  _ 11 aspect  _  _13 ??
??
JJ  JJ  _ 14 d-attribute  _  _14  ??
??
NN NN  _  11 content  _  _15  ?
?
PU  PU  _ 11  PU  _  _508ID4 is ID5, the child with the longest distance fromID5 is ID10, and ID10 with no child is the lastword of phrase.The tagged result in the above figure 6 is as fol-lows: ?
?/NN ?
?/NN ?
?/NN duration[?/P?
?/VV ?
?/NR ?
?/NN ?
?/NN ?/LC] ?
?/VV ?/AS ?
?/JJ ?
?/NN ?/PUThe position of HP in PSR phrase is not fixed.After phrases are tagged, a new sequence gener-ated by replacing the phrase with SR of HP iscalled PSR frame.PSR frame: ?
?/NN ?
?/NN ?
?/NN dura-tion/duration ??
/VV ?
/AS ??
/JJ ?
?/NN ?/PUExamples of sentences with nested phrases:s-cause[ ?
?/P ?
?/NR s-purpose[ ?/P ?
?/VV ??
?/NT ]  ?/MSP ?
?/VV ?
?/VV?/DT ?/M ?
?/NN ?
?/NN ],/PU ??/AD??
/NN ??
/NN ?
/VV ?
/VV ???
?/VV ?/PUPSR frame: s-cause/s-cause ,/PU ?
?/AD ?
?/NN ?
?/NN ?/VV ?/VV ???
?/VV ?/PU2.3 SR Phrase Tagging PerformanceIf the parent of only one word of the tagged phraseis out of this phrase, this phrase is tagged correctly.If each word in the generated frame has one parent(i.e.
words out of the phrase are dependent on HPinstead of other words of the phrase), the frame iscorrect.Phrase FrameMSR 99.99% 100%PSR 99.98% 99.70%Table 1.
Tagging Performance (P-score)As shown in the table 1, tagging results were ofvery high accuracy.
The wrong results were notcontained in phrase and frame train corpus of de-pendency parsing.3 SR Phrase IdentificationIn this paper, we divide SR phrase into two classes:Max SR phrase and Base SR phrase.
Max SRphrase refers to SR phrase is not included in anyother SR phrase in a sentence.
Base SR phrase re-fers to SR phrase does not include any other SRphrase in a SR phrase.
Therefore, MSR phrase isdivided into two classes: Max MSR (MMSR)phrase and Base MSR (BMSR) phrase.
PSR phrasewas divided into two classes: Max PSR (MPSR)phrase and Base PSR (BPSR) phrase.3.1 MMSR Phrase Identification based onCascaded Conditional Random FieldsReference (Qiaoli Zhou, 2010) is selected as ourapproach of MMSR phrase identification.
TheMMSR identifying process is conceptually verysimple.
The MMSR identification first performsidentifying BMSR phrase, and converts the identi-fied phrase to head.
It then performs identifying forthe updated sequence and converts the newly rec-ognized phrases into head.
The identification re-peats this process until the whole sequence has nophrase, and the top-level phrase are the MMSRphrases.
A common approach to the phrase identi-fication problem is to convert the problem into asequence tagging task by using the ?BIEO?
(B forbeginning, I for inside, E for ending, and O foroutside) representation.
If the phrase has one word,the tag is E. This representation enables us to usethe linear chain CRF model to perform identifying,since the task is simply assigning appropriate la-bels to sequence.There are two differences between our featureset and Qiaoli (2010)?s:1) We use dependency direction of word as iden-tification feature, while Qiaoli (2010) did notuse.2) We do not use scoring algorithm which is usedby Qiaoli (2010).Direction Unigrams D-3,D-2 ,D-1 , D0 , D+1 ,D+2 ,D+3Direction Bigrams D-2D-1, D-1D0, D0D+1, D+1D+2,Word & Direction W0D0Table 2.
Feature Templates of MMSR PhraseTable 2 is additional new feature templatesbased on Qiaoli (2010).
W represents a word, andD represents dependency direction of the word.With this approach, nested MSR phrases are identi-fied, and the top-level MSR phrase is the MMSRthat we obtained.corpus P R Fdev 81.41% 75.40% 78.29%test 81.23% 73.04% 76.92%Table 3.
MMSR Identification Performance5093.2 BMSR Phrase Identification based onCRFsWe use the tag set ?BIEO?
the same as that usedfor MMSR identification.Word Unigrams W-3, W-2, W-1, W0, W+1, W+2, W+3Word BigramsW-3W-2, W-2W-1, W-1W0, W0W+1,W+1W+2, W+2W+3POS Unigrams P-3 , P-2, P-1, P0, P+1, P+2, P+3POS BigramsP-3P-2, P-2P-1, P-1P0, P0P+1,P+1P+2, P+2P+3Word_X X0Word_Y Y0Word_D D0Word_S S-3, S-2 , S-1 , S0, S+1, S+2, S+3Word & POS W-1P-1, W0P0, W+1P+1Word & Word_X W-3X0Word & Word_DW0D0, W-3W-2D0, W-2W-1D0,W-1W0D0, W0W+1D0, W+1W+2D0,W+2W+3D0Word & Word_S W-1S-1, W0S0, W+1S+1, W+2S+2Word_X & Word_Y X0Y0POS & Word_DP0D0, P-3P-2D0, P-2P-1D0, P-1P0D0,P0P+1D0, P+1P+2D0, P+2P+3D0POS & Word_SP-1S-1, P-2S-2, P-3S-3, P0S0,P+1S+1, P+2S+2, P+3S+3Word_D & Word_SD-1S-1, D-2S-2, D-3S-3, D0S0,D+1S+1, D+2S+2, D+3S+3Word & POS &Word_DW-1P-1D0, W0P0D0, W+1P+1D0Word & POS &Word_D & Word_SW-3P-3D-3S-3, W-2P-2D-2S-2,W-1P-1D-1S-1, W0P0D0S0, W1P1D1S1,W2P2D2S2, W3P3D3S3Table 4.
Feature Templates of BMSR PhraseIn table 4, ?W?
represents a word, ?P?
repre-sents the part-of-speech of the word, ?X?
repre-sents the fourth word following the current word,?Y?
represents the fifth word following the currentword, ?D?
represents the dependency direction ofthe current word, and ?S?
represents the pairedpunctuation feature.
?S?
consists of ?RLIO?
(R forthe right punctuation, L for the left punctuation, Ifor the part between the paired punctuation and Ofor outside).corpus P R Fdev 79.32% 80.65% 79.98%test 79.22% 79.96% 79.59%Table 5.
BMSR Identification Performance (F-score)3.3 MPSR Phrase Identification Based onCollectionReference (Dongfeng, 2011) is selected as our ap-proach of MPSR phrase identification.
The posi-tion of HP in PSR phrase is not fixed.
Not onlyPSR phrase is identified, but also PSR phrase typeis identified.There are two major differences between ourfeature set and Dongfeng (2011)?s:1) We take the PSR phrase type (the SR of HP)as tag.2)  We use ?S-type?
represents that the PSRphrase is the single preposition.
?Type?
representsSR of the preposition.For example: ??
?/NN location [?/P ?
?/NR ?
?/NR] ?
?/VVO|W POSDongfeng(2011) TagOur Tag*|???
NN O O*|?
P O O?|??
NR I I?|??
NR E Location-E?|??
VV N NTable 6.
Example of PSR Phrase Tag SetIn table 6, Dongfeng(2011) takes ?E?
as the tagof last word of PSR phrase, but we take ?Location-E?
as the tag of last word of PSR phrase  (Locationis type of  PSR phrase).With this approach, nested PSR phrases areidentified, and the top-level PSR phrase is theMPSR that we obtained.corpus MPSR phrase MPSR phrase & typedev 84.00% 54.23%test 83.78% 51.60%Table 7.
MPSR Identification Performance (F-score)3.4 Combined Identification of MSR Phraseand PSR PhraseIdentification process: MSR phrase and PSRphrase are respectively identified in one sentence,and the results are combined in accordance withthis rule: if phrases are nested, only the top-levelphrase is tagged; if phrases are same, only the PSR510phrase is tagged; if phrases are overlapped, onlyPSR phrase is tagged.There are two combinations in this paper:1) MMSR phrase and MPSR phrase combinedresult is defined as MMMP phrase.
For exam-ple as follow (?
[ ]?represents MMSR,?
{}?represents MPSR):Example A: [ ?
?/NN ] ?/VC [ ?
?/VV ?
?/NR ?/DEC ?/CD ?/M ?
?/JJ ?
?/NN ?
?/NN ] ?/PU ?
?/DT ?/M ?/VE [ ?
?/CD?/M ?
?/NN ?
?/NN ?/PU ??
?/CD ?/M?
?/NN ?
?/NN ] ?
?/VV location{ ?/P ?/DT ?/M ?
?/NN ?/LC } ?/PUMMMP  frame: [ ?
?/NN ] ?/VC ?
?/NN ?/PU ?
?/DT ?/M ?/VE ?
?/NN ?
?/VVlocation/location ?/PU2) BMSR phrase and MPSR phrase combinedresult is defined as BMMP phrase.Example B: [ ?
?/NN ] ?/VC ?
?/VV [ ?
?/NR ] ?/DEC ?/CD ?/M ?
?/JJ ?
?/NN ?
?/NN ?/PU ?
?/DT ?/M ?/VE [ ?
?/CD ?/M ?
?/NN ?
?/NN ?/PU ??
?/CD ?/M ?
?/NN ?
?/NN ] ?
?/VV location{ ?/P ?/DT?/M ?
?/NN ?/LC } ?/PUBMMP  frame: ?
?/NN ?/VC ?
?/VV ?
?/NR ?/DEC ?/CD ?/M ?
?/JJ ?
?/NN ?
?/NN ?/PU ?
?/DT ?/M ?/VE ?
?/NN ?
?/VV location/location ?/PUcorpus phrase P R FBMMP 79.48% 81.60% 80.53%devMMMP 80.00% 76.79% 78.36%BMMP 80.14% 82.48% 81.30%testMMMP 80.19% 78.53% 79.35%Table 8.
Combination Phrase IdentificationPerformance3.5 Phrase and Frame Length DistributionWe count phrases, frame and Original Sentence(OS) length distribution in training set and dev set.BMMP MMMP MMSR BMSR OS[0,5) 80.07% 71.36% 75.36% 85.74% 9.07%[5,10) 16.15% 21.63% 18.93% 12.33% 8.30%[10,20) 3.35% 6.13% 5.05% 1.80% 17.23%20?
0.43% 0.88% 0.66% 0.13% 65.40%Table 9.
Length Distribution of Phrases and OSTable 9 shows, about 95% of phrases have lessthan 10 words, but about 65% of OS has more than20 words.BMMP MMMP MMSR BMSR OS[0,5) 16.00% 18.70% 16.43% 14.36% 9.07%[5,10) 18.87% 24.91% 19.41% 14.11% 8.30%[10,20) 34.26% 35.42% 33.94% 30.68% 17.23%20?
30.87% 20.97% 30.22% 40.85% 65.40%Table 10.
Length Distribution of Frames and OSTable 10 shows, about 70% of frames have lessthan 20 words, especially 80% of MMMP framehas less than 20 words, but about 65% of OS hasmore than 20 words.BMMP MMMP BMSR MMSR OSphrase 3.07 3.83 2.53 3.44 30.07frame 16.00 13.21 19.16 15.79 30.07Table 11.
Average LengthWe count phrases, frame and Original Sentence(OS) Average Length (AL) in training set and devset.
Table 11 shows phrase of AL accounted for10% of OS of AL, and frame of AL accounted for50% of OS of AL.
The AL shows that the semanticdependency paring unit length of OS is greatly re-duced after dividing an original sentence into SRphrases and frame.As shown in tables 9, 10 and 11, the length dis-tribution indicates that the divide-and-conquerstrategy reduces the complexity of sentences sig-nificantly.4 Semantic Dependency ParsingGraph-based parser is selected as our basic seman-tic dependency parser.
It views the semantic de-pendency parsing as problem of finding maximumspanning trees (McDonald, 2006) in directedgraphs.
In this paper, phrase and frame semanticdependency parsing result was obtained by Graph-based parser.
Training set of phrase comes fromphrases, and training set of frame comes fromframes.5 Experiments5.1 Direction of Identification511Dependency direction serves as feature of SRphrase identification, so we need to identify de-pendency direction of word.
We use tag set is {B,F}, B represents backward dependence, F repre-sents forward dependence.
The root?s dependencydirection in sentence is B.
Dependency directionidentification p-score has reached 94.87%.Word Unigrams W-4, W-3, W-2, W-1, W0, W+1,W+ 2, W+ 3, W+ 4Word Bigrams W-3W-2, W-2W-1, W-1W0, W0W+1,W+1W+2, W+2W+3Word Trigrams W-1W 0W+1Word Four-grams W-2W-1W0 W +1, W0W+1W+2W+3Word Five-grams W- 4W-3W-2W-1W0,W0W+1W+2W+3W+ 4POS Unigrams P-4, P-3, P-2, P-1, P0, P+1, P+2, P+3, P+ 4POS Bigrams P-3P-2, P-2P-1, P-1P0, P0P+1,P+1P+2, P +2P+3POS Trigrams P-1P0P+1POS Four-grams P-2P-1P0P+1, P0P+1P+2P+3POS Five-grams P-4P-3P-2P-1P0, P0P+1P+2P+3P+4Word & POS W-2 P-2, W-1P-1, W0P0, W+1P+1,W+2P+2Table 12.
Feature Templates of Dependency DirectionIn table12, w represents word, p represents POS.5.2 System and ModelFor a sentence for which phrases has been identi-fied, if phrases can be identified, then the wholesentence semantic dependency parsing result isobtained by phrase parsing model and frame pars-ing model.
Therefore, in this paper, the sentence isdivided into the following types based on thephrase identification results: (1) SentMMMP indi-cates MMSR phrase and MPSR phrase identifiedin a sentence; (2) SentBMMP indicates BMSRphrase and MPSR phrase identified in a sentence;(3) SentMMSR indicates only MMSR phrase iden-tified in a sentence; (4) SentMPSR indicates onlyMPSR phrase identified in a sentence; (5)SentBMSR indicates only BMSR phrase identifiedin a sentence; (6) SentNone indicates no phraseidentified in a sentence.Sentence type Phrase parsing ModelFrame parsingModelSentMMMP MMMP phrase MMMP frameSentBMMP BMMP phrase BMMP frameSentMMSR MMSR phrase MMSR frameSentMPSR MPSR phrase MPSR frameSentBMSR BMSR phrase BMSR frameSentNone Sentence modelTable 13.
Type of Sentence and Parsing ModelTable 13 shows types of sentence, and parsingmodels for every type of sentence.
For example,parsing SentMMMP needs MMMP phrase parsingmodel and MMMP frame paring modelThe corpus contains the sentence type deter-mined by the phrase identification strategy.Strategy of phraseidentification Sentence type in the corpusStrategy MMMP SentMMMP, SentMMSR, SentMPSR, SentNoneStrategy BMMP SentBMMP, SentMPSR, SentBMSR, SentNoneStrategy BMSR SentBMSR, SentNoneTable 14.
Sentence Types in the CorpusAs shown in table 14, Strategy MMMP indicatesthat MMMP phrase in the corpus was identified,and sentences in the corpus were divided intoSentMMMP, SentMMSR, SentMPSR and Sent-None.
Strategy BMMP indicates that BMMPphrase in the corpus was identified, and sentencesin the corpus were divided into SentBMMP,SentBMSR, SentMPSR and SentNone.
StrategyBMSR indicates that BMSR phrase in the corpuswas identified, and sentences in the corpus weredivided into SentBMSR and SentNone.5.3 Comparative ExperimentsIn this paper, we carry out comparative experi-ments of parsing for the test set by 3 systems.1) System1 represents strategy MMMP in thetable 14.2) System2 represents strategy BMMP in the ta-ble 14.3) System3 represents strategy BMSR in the table14.Dev TestG-parser 62.31% 61.68%System1(MMMP) 61.98% 61.84%System2(BMMP) 62.7% 62.08%System3(BMSR) 62.22% 61.15%Table 15.
Comparative ExperimentsAs shown in the table 15, system2 result is moreaccurate than system1, because BMMP phraseidentification is more accurate than MMMP asshown in the table 8.
Although, BMSR phraseidentification is more accurate than MMMP phraseas shown in the table 5 & 8, system 3 result is lessaccurate than systm1.
Compared with BMSR iden-512tification, MMMP identification reduces the com-plexity of sentences significantly, because the table11 shows that the AL of MMMP frame is about30% less than that of BMSR frame.
G-parser isgraph-based parser (Wangxiang Che, 2008).6 Conclusion and Future WorkTo solve the problem of low accuracy of long dis-tance dependency parsing, this paper proposes adivide-and-conquer strategy for semantic depend-ency parsing.
We present our SemEval2012 sharedTask 5 system which is composed of three cas-caded components: the tagging of SR phrase, theidentification of Semantic-role- phrase and seman-tic dependency parsing.Divide-and-conquer strategy is influenced bytwo factors: one is identifying the type of phrasewill greatly reduce the sentence complexity; theother is phrase identifying precision results in cas-caded errors.
The topic of this evaluation is seman-tic dependency parsing, and word and POS containless semantic information.
If we can make seman-tic label on words, then it will be more helpful forsemantic dependency parsing.
In the future, wewill study how to solve the long distance depend-ency parsing problem.AcknowledgmentsThe authors would like to thank the reviewers fortheir helpful comments.
This work was supportedby National Natural Science Foundation of China(NSFC) via grant 61073123 and Natural ScienceFoundation of Liaoning province via grant20102174.ReferencesDongfeng Cai, Ling Zhang, Qiaoli Zhou and Yue Zhao.A Collocation Based Approach for PrepositionalPhrase Identification.
IEEE NLPKE, 2011.McDonald, Ryan.
2006.
Discriminative Learning andSpanning Tree Algorithms for Dependency Parsing.Ph.D.
thesis, University of Pennsylvania.Guiping Zhang, Wenjing Lang, Qiaoli Zhou and Dong-feng Cai.
2010.
Identification of Maximal-LengthNoun Phrases Based on Maximal-Length PrepositionPhrases in Chinese, 2010 International Conferenceon Asian Language Processing, pages 65-68.Qiaoli Zhou, Wenjing Lang, Yingying Wang, YanWang, Dongfeng Cai.
2010.
The SAU Report for the1st CIPS-SIGHAN-ParsEval-2010, Proceedings ofthe First CIPS-SIGHAN Joint Conference on Chi-nese Language Processing, pp:304-311.Wanxiang Che, Zhenghua Li, Yuxuan Hu, YongqiangLi,Bing Qin, Ting Liu, and Sheng Li.
2008.
A cas-caded syntactic and semantic dependency parsingsystem.
In CoNLL-2008.513
