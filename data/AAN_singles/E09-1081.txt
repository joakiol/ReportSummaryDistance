Proceedings of the 12th Conference of the European Chapter of the ACL, pages 710?718,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsA General, Abstract Model of Incremental Dialogue ProcessingDavid SchlangenDepartment of LinguisticsUniversity of Potsdam, Germanydas@ling.uni-potsdam.deGabriel Skantze?Dept.
of Speech, Music and HearingKTH, Stockholm, Swedengabriel@speech.kth.seAbstractWe present a general model and concep-tual framework for specifying architec-tures for incremental processing in dia-logue systems, in particular with respectto the topology of the network of modulesthat make up the system, the way informa-tion flows through this network, how in-formation increments are ?packaged?, andhow these increments are processed by themodules.
This model enables the precisespecification of incremental systems andhence facilitates detailed comparisons be-tween systems, as well as giving guidanceon designing new systems.1 IntroductionDialogue processing is, by its very nature, incre-mental.
No dialogue agent (artificial or natural)processes whole dialogues, if only for the simplereason that dialogues are created incrementally, byparticipants taking turns.
At this level, most cur-rent implemented dialogue systems are incremen-tal: they process user utterances as a whole andproduce their response utterances as a whole.Incremental processing, as the term is com-monly used, means more than this, however,namely that processing starts before the input iscomplete (e.g., (Kilger and Finkler, 1995)).
Incre-mental systems hence are those where ?Each pro-cessing component will be triggered into activityby a minimal amount of its characteristic input?
(Levelt, 1989).
If we assume that the character-istic input of a dialogue system is the utterance(see (Traum and Heeman, 1997) for an attempt todefine this unit), we would expect an incrementalsystem to work on units smaller than utterances.Our aim in the work presented here is to de-scribe and give names to the options available to?The work reported here was done while the second au-thor was at the University of Potsdam.designers of incremental systems.
We define someabstract data types, some abstract methods thatare applicable to them, and a range of possibleconstraints on processing modules.
The notionsintroduced here allow the (abstract) specificationof a wide range of different systems, from non-incremental pipelines to fully incremental, asyn-chronous, parallel, predictive systems, thus mak-ing it possible to be explicit about similarities anddifferences between systems.
We believe that thiswill be of great use in the future development ofsuch systems, in that it makes clear the choicesand trade-offs one can make.
While we sketch ourwork on one such system, our main focus hereis on the conceptual framework.
What we arenot doing here is to argue for one particular ?bestarchitecture?
?what this is depends on the particu-lar aims of an implementation/model and on morelow-level technical considerations (e.g., availabil-ity of processing modules).1In the next section, we give some examples ofdifferences in system architectures that we want tocapture, with respect to the topology of the net-work of modules that make up the system, theway information flows through this network andhow the modules process information, in partic-ular how they deal with incrementality.
In Sec-tion 3, we present the abstract model that under-lies the system specifications, of which we give anexample in Section 4.
We close with a brief dis-cussion of related work.2 Motivating ExamplesFigure 1 shows three examples of module net-works, representations of systems in terms of theircomponent modules and the connections betweenthem.
Modules are represented by boxes, and con-nections by arrows indicating the path and the di-1As we are also not trying to prove properties of the spec-ified systems here, the formalisations we give are not sup-ported by a formal semantics here.710rection of information flow.
Arrows not comingfrom or going to modules represent the global in-put(s) and output(s) to and from the system.Figure 1: Module Network TopologiesOne of our aims here is to facilitate exact andconcise description of the differences betweenmodule networks such as in the example.
Infor-mally, the network on the left can be described asa simple pipeline with no parallel paths, the one inthe middle as a pipeline enhanced with a parallelpath, and the one on the right as a star-architecture;we want to be able to describe exactly the con-straints that define each type of network.A second desideratum is to be able to specifyhow information flows in the system and betweenthe modules, again in an abstract way, withoutsaying much about the information itself (as thenature of the information depends on details ofthe actual modules).
The directed edges in Fig-ure 1 indicate the direction of information flow(i.e., whose output is whose input); as an addi-tional element, we can visualise parallel informa-tion streams between modules as in Figure 2 (left),where multiple hypotheses about the same inputincrements are passed on.
(This isn?t meant toimply that there are three actual communicationschannels active.
As described below, we will en-code the parallelism directly on the increments.
)One way such parallelism may occur in an in-cremental dialogue system is illustrated in Fig-ure 2 (right), where for some stretches of an inputsignal (a sound wave), alternative hypotheses areentertained (note that the boxes here do not repre-sent modules, but rather bits of incremental infor-mation).
We can view these alternative hypothe-Figure 2: Parallel Information Streams (left) andAlternative Hypotheses (right)Figure 3: Incremental Input mapped to (less) in-cremental outputFigure 4: Example of Hypothesis Revisionses about the same original signal as being paral-lel to each other (with respect to the input they aregrounded in).We also want to be able to specify the ways in-cremental bits of input (?minimal amounts of char-acteristic input?)
can relate to incremental bits ofoutput.
Figure 3 shows one possible configuration,where over time incremental bits of input (shownin the left column) accumulate before one bit ofoutput (in the right column) is produced.
(As forexample in a parser that waits until it can com-pute a major phrase out of the words that are itsinput.)
Describing the range of possible modulebehaviours with respect to such input/output rela-tions is another important element of the abstractmodel presented here.It is in the nature of incremental processing,where output is generated on the basis of incom-plete input, that such output may have to be re-vised once more information becomes available.Figure 4 illustrates such a case.
At time-step t1,the available frames of acoustic features lead theprocessor, an automatic speech recogniser, to hy-pothesize that the word ?four?
has been spoken.This hypothesis is passed on as output.
However,at time-point t2, as additional acoustic frames havecome in, it becomes clear that ?forty?
is a bet-ter hypothesis about the previous frames togetherwith the new ones.
It is now not enough to justoutput the new hypothesis: it is possible that latermodules have already started to work with the hy-pothesis ?four?, so the changed status of this hy-pothesis has to be communicated as well.
This isshown at time-step t3.
Defining such operationsand the conditions under which they are necessary711is the final aim of our model.3 The Model3.1 OverviewWe model a dialogue processing system in an ab-stract way as a collection of connected processingmodules, where information is passed between themodules along these connections.
The third com-ponent beside the modules and their connections isthe basic unit of information that is communicatedbetween the modules, which we call the incremen-tal unit (IU).
We will only characterise those prop-erties of IUs that are needed for our purpose ofspecifying different system types and basic oper-ations needed for incremental processing; we willnot say anything about the actual, module specificpayload of these units.The processing module itself is modelled asconsisting of a Left Buffer (LB), the Processorproper, and a Right Buffer (RB).
When talkingabout operations of the Processor, we will some-times use Left Buffer-Incremental Unit (LB-IU)for units in LB and Right Buffer-Incremental Unit(RB-IU) for units in RB.This setup is illustrated in Figure 4 above.
IUsin LB (here, acoustic frames as input to an ASR)are consumed by the processor (i.e., is processed),which creates an internal result, in the case shownhere, this internal result is posted as an RB-IU onlyafter a series of LB-IUs have accumulated.
In ourdescriptions below, we will abstract away from thetime processing takes and describe Processors asrelations between (sets of) LBs and RBs.We begin our description of the model with thespecification of network topologies.3.2 Network TopologyConnections between modules are expressedthrough connectedness axioms which simply statethat IUs in one module?s right buffer are also inanother buffer?s left buffer.
(Again, in an imple-mented system communication between moduleswill take time, but we abstract away from thishere.)
This connection can also be partial or fil-tered.
For example, ?x(x ?
RB1 ?
NP (x) ?x ?
LB2) expresses that all and only NPs in mod-ule one?s right buffer appear in module two?s leftbuffer.
If desired, a given RB can be connected tomore than one LB, and more than one RB can feedinto the same LB (see the middle example in Fig-ure 1).
Together, the set of these axioms define thenetwork topology of a concrete system.
Differenttopology types can then be defined through con-straints on module sets and their connections.
I.e.,a pipeline system is one in which it cannot hap-pen that an IU is in more than one right buffer andmore than one left buffer.Note that we are assuming token identity here,and not for example copying of data struc-tures.
That is, we assume that it indeed is thesame IU that is in the left and right buffersof connected modules.
This allows a spe-cial form of bi-directionality to be implemented,namely one where processors are allowed to makechanges to IUs in their buffers, and where thesechanges automatically percolate through the net-work.
This is different to and independent ofthe bi-directionality that can be expressed throughconnectedness axioms.3.3 Incremental UnitsSo far, all we have said about IUs is that they areholding a ?minimal amount of characteristic input?
(or, of course, a minimal amount of characteris-tic output, which is to be some other module?s in-put).
Communicating just these minimal informa-tion bits is enough only for the simplest kind ofsystem that we consider, a pipeline with only asingle stream of information and no revision.
Ifmore advanced features are desired, there needs tobe more structure to the IUs.
In this section we de-fine what we see as the most complete version ofIUs, which makes possible operations like hypoth-esis revision, prediction, and parallel hypothesisprocessing.
(These operations will be explained inthe next section.)
If in a particular system some ofthese operations aren?t required, some of the struc-ture on IUs can be simplified.Informally, the representational desiderata areas follows.
First, we want to be able to repre-sent relations between IUs produced by the sameprocessor.
For example, in the output of an ASR,two word-hypothesis IUs may stand in a succes-sor relation, meaning that word 2 is what the ASRtakes to be the continuation of the utterance be-gun with word 1.
In a different situation, word 2may be an alternative hypothesis about the samestretch of signal as word 1, and here a different re-lation would hold.
The incremental outputs of aparser may be related in yet another way, throughdominance: For example, a newly built IU3, rep-resenting a VP, may want to express that it links712via a dominance relation to IU1, a V, and IU2, anNP, which were both posted earlier.
What is com-mon to all relations of this type is that they relateIUs coming from the same processor(s); we willin this case say that the IUs are on the same level.Information about these same level links will beuseful for the consumers of IUs.
For example, aparsing module consuming ASR-output IUs willneed to do different things depending on whetheran incoming IU continues an utterance or forms analternative hypothesis to a string that was alreadyparsed.The second relation between IUs that we wantto capture cuts across levels, by linking RB-IUs tothose LB-IUs that were used by the processor toproduce them.
For this we will say that the RB-IUis grounded in LB-IU(s).
This relation then tracksthe flow of information through the modules; fol-lowing its transitive closure one can go back fromthe highest level IU, which is output by the sys-tem, to the input IU or set of input IUs on which itis ultimately grounded.
The network spanned bythis relation will be useful in implementing the re-vision process mentioned above when discussingFigure 4, where the doubt about a hypothesis mustspread to all hypotheses grounded in it.Apart from these relations, we want IUs to carrythree other types of information: a confidencescore representing the confidence its producer hadin it being accurate; a field recording whether revi-sions of the IU are still to be expected or not; andanother field recording whether the IU has alreadybeen processed by consumers, and if so, by whom.Formally, we define IUs as tuples IU =?I,L,G,T , C,S,P?, where?
I is an identifier, which has to be unique foreach IU over the lifetime of a system.
(Thatis, at no point in the system?s life can there betwo or more IUs with the same ID.)?
L is the same level link, holding a statementabout how, if at all, the given IU relates toother IUs at the same level, that is, to IUs pro-duced by the same processor.
If an IU is notlinked to any other IU, this slot holds the spe-cial value ?.The definition demands that the same levellinks of all IUs belonging to the same largerunit form a graph; the type of the graph willdepend on the purposes of the sending andconsuming module(s).
For a one-best outputof an ASR it might be enough for the graphto be a chain, whereas an n-best output mightbe better represented as a tree (with all firstwords linked to ?)
or even a lattice (as inFigure 2 (right)); the output of a parser mightrequire trees (possibly underspecified).?
G is the grounded in field, holding an orderedlist of IDs pointing to those IUs out of whichthe current IU was built.
For example, an IUholding a (partial) parse might be groundedin a set of word hypothesis IUs, and these inturn might be grounded in sets of IUs holdingacoustic features.
While the same level linkalways points to IUs on the same level, thegrounded in link always points to IUs froma previous level.2 The transitive closure ofthis relation hence links system output IUs toa set of system input IUs.
For convenience,we may define a predicate supports(x,y) forcases where y is grounded in x; and hencethe closure of this relation links input-IUs tothe output that is (eventually) built on them.This is also the hook for the mechanism thatrealises the revision process described abovewith Figure 4: if a module decides to re-voke one of its hypotheses, it sets its confi-dence value (see below) to 0; on noticing thisevent, all consuming modules can then checkwhether they have produced RB-IUs that linkto this LB-IU, and do the same for them.
Inthis way, information about revision will au-tomatically percolate through the module net-work.Finally, an empty grounded in field can alsobe used to trigger prediction: if an RB-IU hasan empty grounded in field, this can be under-stood as a directive to the processor to findevidence for this IU (i.e., to prove it), usingthe information in its left buffer.?
T is the confidence (or trust) slot, throughwhich the generating processor can pass onits confidence in its hypothesis.
This then canhave an influence on decisions of the con-suming processor.
For example, if there areparallel hypotheses of different quality (con-fidence), a processor may decide to process2The link to the previous level may be indirect.
E.g.,for an IU holding a phrase that is built out of previouslybuilt phrases (and not words), this link may be expressed bypointing to the same level link, meaning something like ?I?mgrounded in whatever the IUs are grounded in that I link toon the same level link, and also in the act of combination thatis expressed in that same level link?.713(and produce output for) the best first.A special value (e.g., 0, or -1) can be definedto flag hypotheses that are being revoked bya processor, as described above.?
C is the committed field, holding a Booleanvalue that indicates whether the producingmodule has committed to the IU or not, thatis, whether it guarantees that it will never re-voke the IU.
See below for a discussion ofhow such a decision may be made, and howit travels through the module network.?
S is the seen field.
In this field consum-ing processors can record whether they have?looked at?
?that is, attempted to process?the IU.
In the simplest case, the positive factcan be represented simply by adding the pro-cessor ID to the list; in more complicatedsetups one may want to offer status infor-mation like ?is being processed by moduleID?
or ?no use has been found for IU bymodule ID?.
This allows processors both tokeep track of which LB-IUs they have al-ready looked at (and hence, to more easilyidentify new material that may have enteredtheir LB) and to recognise which of its RB-IUs have been of use to later modules, infor-mation which can then be used for exampleto make decisions on which hypothesis to ex-pand next.?
P finally is the actual payload, the module-specific unit of ?characteristic input?, whichis what is processed by the processor in orderto produce RB-IUs.It will also be useful later to talk about the com-pleteness of an IU (or of sets of IUs).
This we de-fine informally as its relation to (the type of) whatwould count as a maximal input or output of themodule.
For example, for an ASR module, suchmaximally complete input may be the recording ofthe whole utterance, for the parser maximal out-put may be a parse of type sentence (as opposedto one of type NP, for example).3 This allows usto see non-incremental systems as a special caseof incremental systems, namely those with onlymaximally complete IUs, which are always com-mitted.3This definition will only be used for abstractly classify-ing modules.
Practically, it is of course rarely possible toknow how complete or incomplete the already seen part ofan ongoing input is.
Investigating how a dialogue system canbetter predict completion of an utterance is in fact one of theaims of the project in which this framework was developed.3.4 Modules3.4.1 OperationsWe describe in this section operations that the pro-cessors may perform on IUs.
We leave open howprocessors are triggered into action, we simply as-sume that on receiving new LB-IUs or noticingchanges to LB or RB-IUs, they will eventually per-form these operations.
Again, we describe here thecomplete set of operations; systems may differ inwhich subset of the functions they implement.purge LB-IUs that are revoked by their producer(by having their confidence score set to the specialvalue) must be purged from the internal state of theprocessor (so that they will not be used in futureupdates) and all RB-IUs grounded in them mustbe revoked as well.Some reasons for revoking hypotheses have al-ready been mentioned.
For example, a speechrecogniser might decide that a previously outputword hypothesis is not valid anymore (i.e., is notanymore among the n-best that are passed on).
Or,a parser might decide in the light of new evidencethat a certain structure it has built is a dead end,and withdraw support for it.
In all these cases, all?later?
hypotheses that build on this IU (i.e., all hy-potheses that are in the transitive closure of thisIU?s support relation) must be purged.
If all mod-ules implement the purge operation, this revisioninformation will be guaranteed to travel throughthe network.update New LB-IUs are integrated into the in-ternal state, and eventually new RB-IUs are builtbased on them (not necessarily in the same fre-quency as new LB-IUs are received; see Figure 3above, and discussion below).
The fields of thenew RB-IUs (e.g., the same level links and thegrounded in pointers) are filled appropriately.
Thisis in some sense the basic operation of a processor,and must be implemented in all useful systems.We can distinguish two implementation strate-gies for dealing with updates: a) all state is thrownaway and results are computed again for the wholeinput set.
The result must then be compared withthe previous result to determine what the new out-put increment is.
b) The new information is in-tegrated into internal state, and only the new out-put increment is produced.
For our purposes here,we can abstract away from these differences andassume that only actual increments are commu-nicated.
(Practically, it might be an advantage tokeep using an existing processor and just wrap it714into a module that computes increments by differ-ences.
)We can also distinguish between modules alonganother dimension, namely based on which typesof updates are allowed.
To do so, we must firstdefine the notion of a ?right edge?
of a set ofIUs.
This is easiest to explain for strings, wherethe right edge simply is the end of the string, orfor a lattice, where it is the (set of) smallest ele-ment(s).
A similar notion may be defined for treesas well (compare the ?right frontier constraint?of Polanyi (1988)).
If now a processor only ex-pects IUs that extend the right frontier, we canfollow Wire?n (1992) in saying that it is only left-to-right incremental.
Within what Wire?n (1992)calls fully incremental, we can make more dis-tinctions, namely according to whether revisions(as described above) and/or insertions are allowed.The latter can easily be integrated into our frame-work, by allowing same-level links to be changedto fit new IUs into existing graphs.Processors can take supports information intoaccount when deciding on their update order.
Aprocessor might for example decide to first try touse the new information (in its LB) to extend struc-tures that have already proven useful to later mod-ules (that is, that support new IUs).
For example,a parser might decide to follow an interpretationpath that is deemed more likely by a contextualprocessing module (which has grounded hypothe-ses in the partial path).
This may result in betteruse of resources?the downside of such a strategyof course is that modules can be garden-pathed.4Update may also work towards a goal.
As men-tioned above, putting ungrounded IUs in a mod-ule?s RB can be understood as a request to themodule to try to find evidence for it.
For exam-ple, the dialogue manager might decide based onthe dialogue context that a certain type of dialogueact is likely to follow.
By requesting the dialogueact recognition module to find evidence for thishypothesis, it can direct processing resources to-wards this task.
(The dialogue recognition mod-ule then can in turn decide on which evidence itwould like to see, and ask lower modules to provethis.
Ideally, this could filter down to the interfacemodule, the ASR, and guide its hypothesis form-ing.
Technically, something like this is probablyeasier to realise by other means.
)4It depends on the goals behind building the modelwhether this is considered a downside or desired behaviour.We finally note that in certain setups it may benecessary to consume different types of IUs in onemodule.
As explained above, we allow more thanone module to feed into another modules LB.
Anexample where something like this could be usefulis in the processing of multi-modal information,where information about both words spoken andgestures performed may be needed to compute aninterpretation.commit There are three ways in which a proces-sor may have to deal with commits.
First, it candecide for itself to commit RB-IUs.
For example,a parser may decide to commit to a previously builtstructure if it failed to integrate into it a certainnumber of new words, thus assuming that the pre-vious structure is complete.
Second, a processormay notice that a previous module has committedto IUs in its LB.
This might be used by the proces-sor to remove internal state kept for potential re-visions.
Eventually, this commitment of previousmodules might lead the processor to also committo its output, thus triggering a chain of commit-ments.Interestingly, it can also make sense to let com-mits flow from right to left.
For example, if thesystem has committed to a certain interpretationby making a publicly observable action (e.g., anutterance, or a multi-modal action), this can berepresented as a commit on IUs.
This informationwould then travel down the processing network;leading to the potential for a clash between a re-voke message coming from the left and the com-mit directive from the right.
In such a case, wherethe justification for an action is revoked when theaction has already been performed, self-correctionbehaviours can be executed.53.4.2 Characterising Module BehaviourIt is also useful to be able to abstractly describe therelation between LB-IUs and RB-IUs in a moduleor a collection of modules.
We do this here alongthe dimensions update frequency, connectednessand completeness.Update Frequency The first dimension we con-sider here is that of how the update frequency ofLB-IUs relates to that of (connected) RB-IUs.We write f:in=out for modules that guaranteethat every new LB-IU will lead to a new RB-IU5In future work, we will explore in more detail if andhow through the implementation of a self-monitoring cycleand commits and revokes the various types of dysfluenciesdescribed for example by Levelt (1989) can be modelled.715(that is grounded in the LB-IU).
In such a setup,the consuming module lags behind the sendingmodule only for exactly the time it needs to pro-cess the input.
Following Nivre (2004), we cancall this strict incrementality.f:in?out describes modules that potentially col-lect a certain amount of LB-IUs before producingan RB-IU based on them.
This situation has beendepicted in Figure 3 above.f:in?out characterises modules that update RBmore often than their LB is updated.
This couldhappen in modules that produce endogenic infor-mation like clock signals, or that produce contin-uously improving hypotheses over the same input(see below), or modules that ?expand?
their input,like a TTS that produces audio frames.Connectedness We may also want to distin-guish between modules that produce ?island?
hy-potheses that are, at least when initially posted, notconnected via same level links to previously out-put IUs, and those that guarantee that this is notthe case.
For example, to achieve an f:in=out be-haviour, a parser may output hypotheses that arenot connected to previous hypotheses, in whichcase we may call the hypotheses ?unconnected?.Conversely, to guarantee connectedness, a parsingmodule might need to accumulate input, resultingin an f:in?out behaviour.6Completeness Building on the notion of com-pleteness of (sets of) IUs introduced above, wecan also characterise modules according to howthe completeness of LB and RB relates.In a c:in=out-type module, the most completeRB-IU (or set of RB-IUs) is only as complete asthe most complete (set of) LB-IU(s).
That is, themodule does not speculate about completions, nordoes it lag behind.
(This may technically be diffi-cult to realise, and practically not very relevant.
)More interesting is the difference between thefollowing types: In a c:in?out-type module, themost complete RB-IU potentially lags behind themost complete LB-IU.
This will typically be thecase in f:in?out modules.
c:in?out-type mod-ules finally potentially produce output that is morecomplete than their input, i.e., they predict contin-uations.
An extreme case would be a module thatalways predicts complete output, given partial in-put.
Such a module may be useful in cases where6The notion of connectedness is adapted from Sturt andLombardo (2005), who provide evidence that the humanparser strives for connectedness.modules have to be used later in the processingchain that can only handle complete input (that is,are non-incremental); we may call such a systemprefix-based predictive, semi-incremental.With these categories in hand, we can makefurther distinctions within what Dean and Boddy(1988) call anytime algorithms.
Such algorithmsare defined as a) producing output at any time,which however b) improves in quality as the al-gorithm is given more time.
Incremental mod-ules by definition implement a reduced form ofa): they may not produce an output at anytime, but they do produce output at more timesthan non-incremental modules.
This output thenalso improves over time, fulfilling condition b),since more input becomes available and eitherthe guesses the module made (if it is a c:out?inmodule) will improve or the completeness ingeneral increases (as more complete RB-IUs areproduced).
Processing modules, however, canalso be anytime algorithms in a more restrictedsense, namely if they continuously produce newand improved output even for a constant set ofLB-IUs, i.e.
without changes on the input side.
(Which would bring them towards the f:out?in be-haviour.
)3.5 System SpecificationCombining all these elements, we can finally de-fine a system specification as the following:?
A list of modules that are part of the system.?
For each of those a description in termsof which operations from Section 3.4.1 themodule implements, and a characterisation ofits behaviour in the terms of Section 3.4.2.?
A set of axioms describing the connectionsbetween module buffers (and hence the net-work topology), as explained in Section 3.2.?
Specifications of the format of the IUs thatare produced by each module, in terms of thedefinition of slots in Section 3.3.4 Example SpecificationWe have built a fully incremental dialogue system,called NUMBERS (for more details see Skantzeand Schlangen (2009)), that can engage in dia-logues in a simple domain, number dictation.
Thesystem can not only be described in the terms ex-plained here, but it also directly instantiates someof the data types described here.716Figure 5: The NUMBERS System Architecture(CA = communicative act)The module network topology of the system isshown in Figure 5.
This is pretty much a stan-dard dialogue system layout, with the exceptionthat prosodic analysis is done in the ASR and thatdialogue management is divided into a discoursemodelling module and an action manager.
As canbe seen in the figure, there is also a self-monitoringfeedback loop?the system?s actions are sent fromthe TTS to the discourse modeller.
The systemhas two modules that interface with the environ-ment (i.e., are system boundaries): the ASR andthe TTS.A single hypothesis chain connects the mod-ules (that is, no two same level links point to thesame IU).
Modules pass messages between themthat can be seen as XML-encodings of IU-tokens.Information strictly flows from LB to RB.
All IUslots except seen (S) are realised.
The purge andcommit operations are fully implemented.
In theASR, revision occurs as already described abovewith Figure 4, and word-hypothesis IUs are com-mitted (and the speech recognition search space iscleared) after 2 seconds of silence are detected.
(Note that later modules work with all IUs fromthe moment that they are sent, and do not haveto wait for them being committed.)
The parsermay revoke its hypotheses if the ASR revokes thewords it produces, but also if it recovers from a?garden path?, having built and closed off a largerstructure too early.
As a heuristic, the parserwaits until a syntactic construct is followed bythree words that are not part of it until it com-mits.
For each new discourse model increment,the action manager may produce new communica-tive acts (CAs), and possibly revoke previous onesthat have become obsolete.
When the system hasspoken a CA, this CA becomes committed, whichis recorded by the discourse modeller.No hypothesis testing is done (that is, no un-grounded information is put on RBs).
All moduleshave a f:in?out; c:in?out characteristic.The system achieves a very high degree ofresponsiveness?by using incremental ASR andprosodic analysis for turn-taking decisions, it canreact in around 200ms when suitable places forbackchannels are detected, which should be com-pared to a typical minimum latency of 750msin common systems where only a simple silencethreshold is used.5 Related Work, Future WorkThe model described here is inspired partially byYoung et al (1989)?s token passing architecture;our model can be seen as a (substantial) general-isation of the idea of passing smaller informationbits around, out of the domain of ASR and into thesystem as a whole.
Some of the characterisationsof the behaviour of incremental modules were in-spired by Kilger and Finkler (1995), but again wegeneralised the definitions to fit all kinds of incre-mental modules, not just generation.While there recently have been a number ofpapers about incremental systems (e.g., (DeVaultand Stone, 2003; Aist et al, 2006; Brick andScheutz, 2007)), none of those offer general con-siderations about architectures.
(Despite its title,(Aist et al, 2006) also only describes one particu-lar setup.
)In future work, we will give descriptions ofthese systems in the terms developed here.
Weare also currently exploring how more cognitivelymotivated models such as that of generation byLevelt (1989) can be specified in our model.
Afurther direction for extension is the implementa-tion of modality fusion as IU-processing.
Lastly,we are now starting to work on connecting themodel for incremental processing and ground-ing of interpretations in previous processing re-sults described here with models of dialogue-levelgrounding in the information-state update tradi-tion (Larsson and Traum, 2000).
The first pointof contact here will be the investigation of self-corrections, as a phenomenon that connects sub-utterance processing and discourse-level process-ing (Ginzburg et al, 2007).Acknowledgments This work was funded by a grant in theDFG Emmy Noether Programme.
Thanks to Timo Baumannand Michaela Atterer for discussion of the ideas reportedhere, and to the anonymous reviewers for their very detailedand helpful comments.717ReferencesG.S.
Aist, J. Allen, E. Campana, L. Galescu, C.A.Gomez Gallo, S. Stoness, M. Swift, and M Tanen-haus.
2006.
Software architectures for incrementalunderstanding of human speech.
In Proceedings ofthe International Conference on Spoken LanguageProcessing (ICSLP), Pittsburgh, PA, USA, Septem-ber.Timothy Brick and Matthias Scheutz.
2007.
Incremen-tal natural language processing for HRI.
In Proceed-ings of the Second ACM IEEE International Confer-ence on Human-Robot Interaction, pages 263?270,Washington, DC, USA.Thomas Dean and Mark Boddy.
1988.
An analysis oftime-dependent planning.
In Proceedings of AAAI-88, pages 49?54.
AAAI.David DeVault and Matthew Stone.
2003.
Domaininference in incremental interpretation.
In Proceed-ings of ICOS 4: Workshop on Inference in Computa-tional Semantics, Nancy, France, September.
INRIALorraine.Jonathan Ginzburg, Raquel Ferna?ndez, and DavidSchlangen.
2007.
Unifying self- and other-repair.In Proceeding of DECALOG, the 11th InternationalWorkshop on the Semantics and Pragmatics of Dia-logue (SemDial07), Trento, Italy, June.Anne Kilger and Wolfgang Finkler.
1995.
Incremen-tal generation for real-time applications.
TechnicalReport RR-95-11, DFKI, Saarbru?cken, Germany.Staffan Larsson and David Traum.
2000.
Informationstate and dialogue management in the TRINDI dia-logue move engine toolkit.
Natural Language Engi-neering, pages 323?340.Willem J.M.
Levelt.
1989.
Speaking.
MIT Press,Cambridge, USA.Joakim Nivre.
2004.
Incrementality in determinis-tic dependency parsing.
pages 50?57, Barcelona,Spain, July.Livia Polanyi.
1988.
A formal model of the structureof discourse.
Journal of Pragmatics, 12:601?638.Gabriel Skantze and David Schlangen.
2009.
Incre-mental dialogue processing in a micro-domain.
InProceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Lin-guistics (EACL 2009), Athens, Greece, April.Patrick Sturt and Vincenzo Lombardo.
2005.
Process-ing coordinated structures: Incrementality and con-nectedness.
Cognitive Science, 29:291?305.D.
Traum and P. Heeman.
1997.
Utterance units inspoken dialogue.
In E. Maier, M. Mast, and S. Lu-perFoy, editors, Dialogue Processing in Spoken Lan-guage Systems, Lecture Notes in Artificial Intelli-gence.
Springer-Verlag.Mats Wire?n.
1992.
Studies in Incremental NaturalLanguage Analysis.
Ph.D. thesis, Linko?ping Uni-versity, Linko?ping, Sweden.S.J.
Young, N.H. Russell, and J.H.S.
Thornton.
1989.Token passing: a conceptual model for con-nected speech recognition systems.
Technical re-port CUED/FINFENG/TR 38, Cambridge Univer-sity Engineering Department.718
