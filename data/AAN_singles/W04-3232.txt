Identifying Broken Plurals in Unvowelised Arabic TextAbduelbaset GowederUniversity of EssexDept.
of ComputerScienceWivenhoe Park,Colchester  CO4 3SQ,UKagowed@essex.ac.ukMassimo PoesioUniversity of EssexDept.
of ComputerScienceWivenhoe Park,Colchester  CO4 3SQ,UKpoesio@essex.ac.ukAnne De RoeckThe Open UniversityDept.
of ComputingWalton Hall, MiltonKeynesBuckinghamshire, MK76AA, UKA.DeRoeck@open.ac.ukJeff ReynoldsUniversity of EssexDept.
of ComputerScienceWivenhoe Park,Colchester  CO4 3SQ,UKreynt@essex.ac.ukAbstractIrregular (so-called broken) plural identificationin modern standard Arabic is a problematic issuefor information retrieval (IR) and languageengineering applications, but their effect on theperformance of IR has never been examined.Broken plurals (BPs) are formed by altering thesingular (as in English: tooth  teeth) throughan application of interdigitating patterns onstems, and singular words cannot be recoveredby standard affix stripping stemming techniques.We developed several methods for BP detection,and evaluated them using an unseen test set.
Weincorporated the BP detection component into anew light-stemming algorithm that conflates bothregular and broken plurals with their singularforms.
We also evaluated the new light-stemmingalgorithm within the context of informationretrieval, comparing its performance with otherstemming algorithms.1.
IntroductionBroken plurals constitute ~10% of texts in largeArabic corpora (Goweder and De Roeck, 2001), and~41% of plurals (Boudelaa and Gaskell, 2002).Detecting broken plurals is therefore an importantissue for light-stemming algorithms developed forapplications such as information retrieval, yet theeffect of broken plural identification on theperformance of information retrieval systems hasnot been examined.
We present several methods forBP detection, and evaluate them using an unseentest set containing 187,309 words.
We alsodeveloped a new light-stemming algorithmincorporating a BP recognition component, andevaluated it within an information retrieval context,comparing its performance with other stemmingalgorithms.We give a brief overview of Arabic in Section 2.Several approaches to BP detection are discussed inSection 3, and their evaluation in Section 4.
InSection 5, we present an improved light stemmerand its evaluation.
Finally in Section 6, ourconclusions are summarised.2.
Arabic Morphology and its NumberSystemArabic is a heavily inflected language.
Itsgrammatical system is traditionally described interms of a root-and-pattern structure, with about10,000 roots (Ali, 1988).
Roots such as drs ()and ktb () are listed alphabetically in standardArabic dictionaries like the Wehr-Cowan (Beesley,1996).
The root is the most basic verb form.
Rootsare categorized into: triliteral, quadriliteral, or rarelypentaliteral.
Most words are derived from a finite setof roots formed by adding diacritics1 or affixes(prefixes, suffixes, and infixes) through anapplication of fixed patterns which are templates tohelp in deriving inflectional and derivational formsof a word.
Theoretically, several hundreds ofArabic words can be derived from a single root.Traditional Arab grammarians describe Arabicmorphology in terms of patterns associated with thebasic root f3l (	, ?to do?
)- where f, 3, and l are likewildcards in regular expressions: the letter f (,?pronounced fa?)
represents the first consonant(sometimes called a radical), the letter 3 ( ,?pronounced ain?)
represents the second, and theletter l ( , ?pronounced lam?)
represents the third1Special characters which are superscript or subscript marksadded to the word.respectively.
Adding affixes to the basic root f3l(	, ?to do?)
allows additional such patterns to beformed.
For instance, adding the letter Alef () as aprefix to the basic root f3l (	, ?to do?)
we get thepattern Af3l () which is used to form words suchas: anhr (, ?rivers?
), arjl (, ?legs?
), and asqf(, ?ceilings?).
Some examples of the wordpatterns are Yf3l (), Mf3Wl (), Af3Al (	),MfA3l (), etc.The following example shows how we can usepatterns to form words.
the verb yktb ( , ?hewrites or he is writing?)
is formed by mapping theconsonants of the triliteral root ktb ( ) to thepattern yf3l (), where the letters f (), 3 (), andl () in the second, third, and fourth positions of thepattern respectively represent slots for a rootconsonant.
Figure 1 depicts the process of matchingthe root ktb ( ) to the pattern yf3l () toproduce the verb yktb ( , ?he writes or he iswriting?
), then adding prefixes and/or suffixes toobtain a word.Figure 1: The process of mapping the root ktb (  ) to thepattern yf3l ().The Arabic number system has singular, dual, andplural.
Plurals are traditionally distinguished intotwo categories: the regular (so-called sound)plurals, and the irregular (so-called broken) plurals.Sound Plurals are formed by appropriate suffixation(like English: hand  hands).
The sound masculineplural is formed by adding the suffix oun (!")
in thenominative case and the suffix een (#) in theaccusative & genitive cases.
The sound feminineplural is formed by attaching the suffix at () to thesingular.Irregular or broken plurals apply mostly to triliteralroots and are formed by altering the singular (as inEnglish: tooth  teeth).
Many nouns and adjectiveshave broken plurals (Haywood and Nahmad, 1976).In all cases, singulars are affected by applying anumber of different patterns that alter long vowels(Alef (), Waw ("), Yeh ($), and Alef-Maqsura (%)),within or outside the framework of the consonants(Cowan, 1958).
Table 1 gives some examples ofBPs and their patterns.Table 1: Broken Plural examples.Singular BP Pattern Pluralqlm(&'(, ?pen?)
Af3Al () AqlAm()*(, ?pens?
)qlb('(, ?heart?)
f3Wl (	) qlWb('(, ?hearts?
)ktab(, ?book?)
f3l (	) ktb(, ?books?
)The complexity of Arabic morphology hasmotivated a great deal of studies.
Some of whichespecially concerned with broken plurals (McCarthyand Prince, 1990b; Kiraz, 1996a; Idrissi, 1997).These are successful to varying degrees, but have amain practical drawback in the context ofinformation retrieval: they assume that words arefully vowelised.
Unfortunately, short vowels areusually not written in published Arabic text, withthe exception of the religious texts (e.g., the HolyQuran), poetry, and books for school children(Abuleil and Evens, 1998).3.
Different Approaches to BP IdentificationWe tested several different approaches for BPidentification: simple BP matching, restricted BPmatching (hand restricted & decision treerestricted), and a dictionary approach.3.1 The Simple BP Matching ApproachGiven the characterisation of broken plurals onefinds in standard Arabic grammars, the mostobvious method for identifying a broken plural is tolight stem it (strip off any prefixes and/or suffixes),then trying to match the obtained stem against BPpatterns found in standard grammars.
Since thismethod is widely used, we adopted it as a baseline.As a first step towards a simple BP matchingalgorithm, we developed a basic light stemmer forArabic by modifying an existing root stemmer(Khoja and Garside, 1999).
This basic light stemmerwas incorporated in a simple BP identificationmodule based on matching, using a list of 39 BPpatterns found in grammar books such as Haywoodand Nahmad (1976) and Cowan (1958).
The simpleBP matching algorithm takes in a word; light-stemsit to produce morphological information such asstem, prefix and suffix; and returns TRUE if thestem matches one of the BP patterns in the list.
Thestem matches a BP pattern if and only if they havethe same number of letters and the same letters inthe same positions, excluding the consonants f (),3 (), and l () of the basic root f3l (	, ?to do?
)found in the pattern.In information retrieval and statistical naturallanguage processing, recall and precision arecommon measures used to gauge a system?sperformance.
Recall (R) is the fraction of targetitems that a system selected, while the precision (P)is the fraction of selected items that a system gotright.
A third measure known as F-measure (F)2(combines R and P) is used in some situation whereR is very high and P is very low (Manning andSchutze, 1999).
We implemented R, P, and F toevaluate approaches we present in this paper.The simple BP matching algorithm waspreliminarily evaluated on a subset of an Arabiccorpus (referred to as A_Corpus1) obtained fromKhoja (1999).
It contains 7172 words whose  BPinstances were identified (this first set of BPs isreferred below as data set1).
The results showed thatthe simple BP matching approach has very highrecall (99.71%), but low precision (13.73%).We also tested two slightly modified versions of thesimple BP matching algorithm, exploitinginformation about affixes information and propername detection, respectively.
The first variant wasbased on the observation that only a limited set ofprefixes and suffixes can be attached to a BP stem.In addition,  some BP prefixes and suffixes cannotboth be concatenated to a BP stem at the same time.These observations led to a first variant of thesimple matching algorithm incorporating two post-processing strategies for refining the decisions madeby the simple BP matching algorithm.
The firstrefining strategy checks if the produced prefix orsuffix is in the list of BP prefixes or suffixes; if itisn?t, the stem will be classified as ?Not BrokenPlural (NBP)?.
The second refining strategy checksif the prefix is a definite article (e.g., al (, ?the?
),wal (", ?and the?
), bal (+, ?with the?
), etc.)
andthe suffix is a BP suffix, and changes the outputaccordingly.
An evaluation of the performance of2F=2PR/(P+R) for equal weighting.the simple BP matching algorithm with affix-basedrefinement strategies on  data set1 revealed a slightimprovement in precision (16.74%).We also made a preliminary test evaluating thepossible usefulness of incorporating a proper namedetector in the system.
We manually identified  theproper names in data set1, then modified the simpleBP matching algorithm to ignore proper names.
Ourresults only showed a small (if significant)improvement in precision (19.86%), that we didn?tfeel would justify the considerable effort required todevelop a proper name detector.
As a result,  welooked for simpler but more effective  ways toimprove the algorithm.3.2 The Restricted BP Matching ApproachThe main problem with the simple BP matchingapproach is that the BP patterns are too general toachieve a good performance.
Another way toimprove the precision of the algorithm is thereforeto obtain more specific BP patterns by restricting theoriginal ones.
The idea is to allow only a subset ofthe alphabet to be used in the meta characters f (),3 (), and l () positions of the patterns (see Section2), producing a number of more restrictive patternsout of each original BP pattern.
A larger number ofinstances of each BP pattern is required to developthis approach.
For this purpose, we used a largecorpus of ~18.5 million words (Goweder and DeRoeck, 2001).
In the remainder of the paper, werefer to this corpus as A_Corpus2.
The simple BPmatching algorithm with affix-based refinementstrategies was used to extract all instances of BPsthat occurred in A_Corpus2.
We adopted twoapproaches.
In a first experiment we tried to producethe more restrictive patterns by hand.
Later we triedto achieve the same goal using a decision treetechnique.
We discuss the first experiment here, thesecond in section 3.4.
The procedure we followed toidentify the BPs in A_Corpus2 is as follows:1.
A word frequencies tool was used togenerate word frequencies for A_Corpus2,obtaining 444,761 distinct word types.2.
Each word type was light-stemmed.3.
The word frequencies tool was run again onthe stemmed word types, producing roughly127,000 stem types.4.
The 127,000 stem types were fed to thesimple BP matching system to retrieve allstems that match BP patterns.
The outputfile, categorised according to each BPpattern, contained about 30,000 cases.
Eachspecific pattern contained a list of stemsmatching this pattern.We then studied separately each BP pattern.
SomeBP patterns were straightforward to restrict.
Forexample, all the stem types matching the BP patternAf3lAa (,*), are shown in Figure 2.
There are 107cases in total.
An analysis of the results reveals thatonly 18 cases are BPs, highlighted (bold andunderlined).
In the BP pattern Af3lAa (,*), themeta characters f (), 3 (), and l () are inpositions 2, 3, and 4 respectively.
The remainingcharacters - Alef () in positions 1 & 5, and Hamza(,) in position 6 - are fixed.
Our analysis showedthat the stems which have the letter Ta () in the 3rdposition are not BPs; they are nominalizations ofverbs.
For example, the word abtdaa (,-+,?starting?)
listed on the first row and last column isa noun derived from the verb yabtdi ( -./  , ?hestarts?).
There are 62 cases of this type.
Anexceptional rule could be induced to handle nounsderived from verbs.
The rule could be written as:			Figure 2: Results of the pattern Af3lAa (	).The simple BP matching algorithm was modified touse the manually restricted BP patterns.
Theperformance of the manual restriction method wasevaluated using the same data set used before, dataset1.
The results show that precision is noticeablyimproved, to 53.92%.
Recall is improved as well, to100%.
The improvement in both recall and precisioncaused a big increase in the F-measure, to roughly70%.
These results suggested to us that attemptingto restrict the BP patterns is worthwhile.
In section3.4, we discuss attempts to find restrictionsautomatically, using decision tree methods.
But theclassification of all words in A_Corpus2 as BP orNBP also allowed us to bootstrap a dictionary-basedapproach.
We discuss this next.3.3 The Dictionary ApproachIn information retrieval applications, ?the mostcommon measures of system performance are timeand space.
The shorter the response time, thesmaller the space used, the better the system isconsidered to be?
(Baeza-Yates and Ribeiro-Neto,1999).
The fastest way to detect BPs is to use alook-up table which lists all BP stems.Considering some of the facts about Arabic,discussed in Section 2, it is quite clear that it will befairly difficult to build look-up tables listing eitherBP stems or full words from language dictionaries.A_Corpus2, on the other hand - a large resource ofmodern, unvowelised, freeflowing Arabic text -provided a good foundation,  and after thedevelopment of the simple and restricted BPmatching algorithms discussed in the previoussections, only minor additional effort was requiredfor building such a table  (without such tools,collecting the table entries would have beenprohibitively expensive).The dictionary was built as follows:1.
The manually restricted BP matchingsystem was run on the 127,000 stem types,extracted from A_Corpus2 (see section 3.2),to retrieve all types that match (restrictedmatching) BP patterns.
The results wereabout 12,000 instances in total.2.
We then went through these 12,000instances, identifying the actual BPs.
A listof roughly 3,600 BP stems, alphabeticallyordered and categorised according to eachBP pattern, was extracted.List of all words retrieved by the pattern (,*)===>,-+,+,0+,*+,1+   ,,2,*,,34,54,64,4,74,4,.
'4,.8,68,8,*8, ,+,9:,-:,6:,;:,:,7:,:,,<,=<,*<,;,,0,,,*,,>, ,?,?  ,@A,-,*,7,1 ,3B,1B ,-,,(,-(,;(,(,1( ,,5,,,@,*,1.  ,-,6,,,7,,1C,D,*D,1E,"2,.5,;,@,@,,;  ,,E7,-=,=!
!
"!
,>',*<,:FTotal number of cases is 1073.
The list was further revised in collaborationwith a linguist, who is an Arabic nativespeaker.
The revised list contained exactly3,580 BP stems.We implemented the dictionary approach using hashtables, in which search, insertion, and deletionoperations can be done in constant time.Before carrying an extensive comparison of thedictionary approach to the previous approaches, itsperformance was first tested on the same data setalready used to evaluate both simple and restrictedBP matching approaches, data set1.
The results ofthe evaluation show that precision significantlyimproves (to 81.18%), while recall is still perfect(100%).
The F-measure recorded an increase(89.61%) due to the improvement in the precision.The results suggest that the dictionary approachoutperforms both the simple and manually restrictedBP matching approaches.3.4 Learning Restrictions AutomaticallyDecision tree learning is one of the most widelyused classification methods.
The decision treelearning algorithm C4.5 developed by Quinlan(1993) was used to generate a set of rules in theform of a decision tree and decision rules (if-thenstatements).
Because we are interested in how wecould restrict the BP patterns, specifically restrictingthe meta characters of the BP patterns (Fa, Ain, andLam), we chose them to be the attributes whichdescribe our data.
The outcome (class) of each caseis given as BP or NBP.
Figure 3 shows the classesand the name & description of each attribute.Figure 3: Set of attributes.Table 2 lists some examples of the BP patternAf3lAa (,*) to show how instances of the data canbe described according to the set of proposedattributes and a classification for each instance.Table 2: Sample of examples.Set of Attributes WordFa Ain LamClassAsdqaa(,(-A, ?friends?)
G  H BPAbtdaa(,-+, ?starting?)
 NBPAkhtbaa( , ?hiding?)
I   NBPAthryaa(,J, ?wealthy?)
K  $ BPData balance was an issue to be dealt with beforeconducting decision tree experiments.
For some BPpatterns, the number of BP cases is much smallerthan the number of NBP cases.
In such a situation,we are required to have equal cases for each class(50% for BP and 50% for NBP) because C4.5 tendsto classify all the cases as one class with some errorrate if there are an insufficient, or small number ofcases of one type compared to the other.
Balancingthe data was achieved by duplicating the infrequentcases until we have an equal number of cases forboth classes.Training data are generated using the simple BPmatching algorithm, on the text file containing127,000 stem types extracted from A_Corpus2 (seesection 3.2).
The simple BP matching algorithmlisted all instances that match every particular BPpattern.
So far, we have a list of instances, which arelabeled as BP, for each BP pattern, however, manyof the cases are not BPs.
As a result, we need torevise automatically the classification of each caseusing the dictionary-based approach (discussed insection 3.3).
After the revision, all the cases whichare labeled as BPs by the simple BP matchingalgorithm will be corrected by the dictionaryapproach.
At this stage, each BP pattern will have alist of BP and NBP cases.
The BP system will checkwhich class has fewer cases in order to duplicatethem to achieve the balancing.
Thirty nine outputfiles, one for each BP pattern, were produced by theBP system.Test data for each BP pattern are also generated byinvoking the BP system on a large unseen data set,containing 187,309 words (referred to as data set2)extracted from the Arabic Newswire corpus (a thirdcorpus referred to as A_Corpus3, and totallyBP, NBP.Fa: discrete (list of Arabic alaphabet).Ain: discrete (list of Arabic alaphabet).Lam: discrete (list of Arabic alaphabet).different from A_Corpus1 and A_Corpus2) in orderto test the models produced by C4.5 system.We generated one classification model for each ofthe 39 (mutually exclusive) BP patterns, andexamined their performance on unseen test cases.Each classification model was trained  on a datasetspecific to that BP pattern and consisting of 10,000cases, 50% for each class.
The classification modelswere then evaluated on 39 different test sets (one foreach BP pattern).
Most of the classifiers were ableto achieve the task with very low error rates andhigh recall & precision.
Some models performed theclassification without any errors and had a verysimple decision tree (e.g., the decision tree and setof rules produced for the BP pattern Af3lAa (,*)).This implies that the results are promising; however,some classifiers had large decision trees andsuffered from overfitting.A summary of recall and precision results for bothdecision trees and set of rules are drawn ashistograms to give us a better insight of how eachBP pattern performed as shown in Figures 4, 5, 6,and 7.
The analysis of the results shows that most ofthe models (Figures 4&6), representing BP patterns,achieved high recall (except a few of them, such aspatterns 16, 27, where the recall was low L 40%).On the other hand, some models (Figures 5&7)performed poorly (precision L 40%), such aspatterns 4, 10, 16, 17, 21, and 28.
The performanceof all combined models achieved an overall recalland precision of approximately 95% and 75%respectively.Decision Trees0204060801001201 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39BP patternsRecallOverall Recall =  95.56%Figure 4: Recall of decision trees for all BP patterns.Decision Trees0204060801001201 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39BP patternsPrecisionOverall precision =  75.59053%Figure 5: Precision of decision trees for all BP patterns.Set of Rules0204060801001201 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39BP patternsRecallOverall Recall =  95.91184%Figure 6: Recall of set of rules for all BP patterns.Set of Rules0204060801001201 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39BP patternsPrecisionOverall precision =  75.14395%Figure 7: Precision of set of rules for all BP patterns.4.
Comparing the Performance of the BPIdentification ApproachesThe BP matching methods discussed in the previoussection were evaluated on a larger unseen data set,data set2 (the same data set aleady used to generatetest cases to evaluate the decision tree approach, seesection 3.4).
The BPs in this data set were tagged asfollows:1.
A modified version of the dictionary-basedBP identification algorithm was run on dataset2 to tag all the occurrences of BPs.2.
We manually went through the output twiceto revise any mistakes made by the BPidentification algorithm.The evaluation results for  the different algorithmson data set2 are listed in Table 3.
These resultsconfirm that the simple BP matching approachperformed poorly, the restricted BP matchingapproach improved the performance significantly, amore significant improvement achieved by thedecision tree technique, and the dictionary approachoutperformed all the approaches.
The results alsosuggest that affix-based refinement strategiesimproved the performance of the simple matching,the restricted matching, and the dictionaryalgorithms.Table 3: An Evaluation of different BP identificationalgorithms using a large data set (data set2).Evaluation Criteria BPIdent.MethodR P FSM 99.5% 13.8% 24.2%SMR 100% 14.5% 25.4%MRM 99% 49.7% 66.2%MRMR 100% 52% 68.4%Dic 98.8% 86.9% 92.5%DicR 100% 92.3% 96.0%DT 95.9% 75.1% 84.3%Acronyms:Simple Matching SMSimple Matchingwith Refinement SMRManuallyRestrictedMatching  MRMManuallyRestrictedMatching withRefinement MRMRDictionary  DicDictionary withRefinement DicRDecision Trees DT5.
An Improved Light-Stemmer and itsTask-Based EvaluationThe dictionary-based BP detector with restrictionwas included  in a revised version of the lightstemmer described earlier (henceforth: Basic-LStemmer).
This revised stemmer (henceforth: BP-LStemmer) first runs the Basic-LStemmer on aword, then invokes the (dictionary-based) BPdetector.
If the BP detector returns TRUE, thesingular form of the word is output; otherwise, theoutput of the Basic-LStemmer.The BP-LStemmer was evaluated in an informationretrieval task by developing a new indexing method,referred to as ?stem+BP?.
This new indexingmethod was compared with the three standardindexing methods (full word, root, and ?basic?
stem).The Greenstone digital library, developed at theUniversity of Waikato in New Zealand, was used asan information retrieval system for our experiment.A collection of 385 documents (7 different domains)and a set of 50 queries (plausible queries that wemight use ourselves were created to search forparticular information in different domains) withtheir relevance judgments, were used to evaluate thefour indexing methods.The results (Figure 8) clearly indicate that theproposed ?stem+BP?
indexing method significantlyoutperforms the three standard indexing/stemmingmethods (p (1-tailed) < .01 both by the Sign test andthe Wilcoxon signed-rank test).
This suggests thatstemming has a substantial effect on informationretrieval for highly inflected languages such asArabic, confirming the results obtained by Al-Kharashi and Evens (1994), Hmeidi et al (1997),Abu-Salem et al (1999), Larkey and Connell(2001), and Larkey et al (2002).Average Recall versus Precision Figures010203040506070809010010 20 30 40 50 60 70 80 90 100RecallPrecision Stem+BPStemRootFull WordFigure 8: The Average Recall vs.
Precision Figures of theFour Indexing Methods for 50 Queries.6.
ConclusionWe discussed several different methods for BPidentification: simple BP matching, affix-basedsimple BP matching, simple BP matching+POS,manually-and-DT restricted, and dictionary-based.Although the simplest methods had poor ormediocre results, they were used to bootstrap betterperforming methods.The baseline, the simple BP matching method, has ahigh recall but a low precision (~14%).
Weattempted to improve the performance of the BPidentification algorithm by (i) using affixinformation, (ii) identifying proper names, and (iii)restricting the BP patterns.
Having implemented thesimple and restricted methods, and used them toanalyse all the BPs in a large corpus (A_Corpus2),made a dictionary approach possible.
All methodswere evaluated on a larger data set of 187,000words.
The results confirmed that the restrictedmethod clearly improved the overall performanceand the dictionary approach outperformed the otherones.We also developed a new light-stemming algorithmthat conflates both regular and broken plurals withtheir singular forms.
The new light-stemmingalgorithm was assessed in an information retrievalcontext, comparing its performance with otherstemming algorithms.
Our work provides evidencethat identifying broken plurals results in animproved performance for information retrievalsystems.
We found that any form of stemmingimproves retrieval for Arabic; and that light-stemming with broken plural recognitionoutperforms standard light-stemming, root-stemming, and no form of stemming.7.
AcknowledgmentsWe would like to express our gratitude to ShereenKhoja for providing her root stemmer.
We wouldalso like to thank the Libyan Secretariat ofEducation for supporting this work.8.
ReferencesAbuleil, Saleem and Evens, Martha W.
(1998).
?Discovering Lexical Information by Tagging ArabicNewspaper Text.?
Computational Approaches toSemitic Languages, Proceedings of the Workshop.Abu-Salem, Hani; Al-Omari, Mahmoud; and  Evens,Martha W. (1999).
?Stemming Methodologies overIndividual Query Words for an Arabic InformationRetrieval System.?
JASIST, 50(6):524-529.Ali , N. (1988).
?Computers and the Arabic Language.
?Cairo, Egypt: Al-khat Publishing Press, Ta?reep.Al-Kharashi, I. and Evens, Martha W.
(1994).
?Comparing words, stems and roots as index terms in anArabic Information retrieval system.?
JASIST,45(8):548-560.Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier (1999).
?Modern Information Retrieval?.
Addison-Wesley,ACM Press.Beesley, K. R. (1996) ?Arabic finite-state morphologicalanalysis and generation.?
In COLING-96: Proceedingsof the 16th international conference on ComputationalLinguistics, vol.
1, pp.
89--94.Boudelaa , Sami; Gaskell, M. Gareth (2002).
?A re-examination of the default system for Arabic plurals.
?Psychology Press Ltd, vol.
17, pp.
321-343, 2002.Cowan, David (1958).
?Modern Literary Arabic.
?Cambridge University Press.Goweder, Abduelbaset and De Roeck, Anne (2001).
?Assessment of a Significant Arabic Corpus.?
ACL2001.
Arabic language Processing.
pp.
73-79, 2001.Haywood, J.
A. and Nahmad, H. M. (1976).
?A newArabic Grammar of the written language.?
LundHumphries London.Hmeidi, Ismail; Kanaan, Ghassan; and Evens, Martha(1997).
?Design and Implementation of AutomaticIndexing for Information Retrieval with ArabicDocuments.?
Journal of the American Society forInformation Science.
48(10) (pp.
867-881), 1997.Idrissi, Ali (1997).
?Plural Formation in Arabic.?
InCurrent issues in Linguistic Theory, Perspectives onArabic Linguistics X. Edited by Mushira Eid and RobertRatcliffe.
Vol 153, pp 123-145.Khoja, S. and Garside, R. (1999) ?Stemming Arabic text.
?Computing Department, Lancaster University,Lancaster, United Kingdom.http://www.comp.lancs.ac.uk/computing/users/khoja/stemmer.psKiraz, G. (1996a).
Analysis of the Arabic broken pluraland diminutive.
In Proceedings of the 5th InternationalConference and Exhibition on Multi-LingualComputing.
Cambridge.Larkey, L. S. and Connell, M. E. (2001) ?Arabicinformation retrieval at UMass in TREC-10.?
In TREC2001.
Gaithersburg: NIST, 2001.Larkey, L.; Ballesteros, L.; and Connell, M.E (2002).
?Improving Stemming for Arabic Information Retrieval:Light Stemming and Co-occurrence Analysis.?
InSIGIR?02, August 11-15, 2002, Tampere, Finland, pp275?282, 2002.Manning, Christopher D. and Schutze, Hinrich (1999).
?Foundations of Statistical Natural LanguageProcessing.
?McCarthy, John J.; and Prince, Alan S (1990).
?Foot andWord in Prosodic Morphology: The Arabic BrokenPlural.?
Natural Language and Linguistic Theory 8,209?282.Quinlan, J. R. (1993).
?C4.5: Programs for Machine Learning.
?San Mateo: Morgan Kaufmann.
