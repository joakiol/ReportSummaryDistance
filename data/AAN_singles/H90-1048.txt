On Deftly Introducing Procedural Elementsinto Unification ParsingR.
BobrowLance RamshawBBN Systems and Technologies Corp.10 Moulton Street, Mailstop 6/4CCambridge, MA 021381 IntroductionUnification grammars based on complex feature structuresare theoretically well-founded, and their declarative naturefacilitates exploration of various parsing strategies.
How-ever, a straightfoward implementation f such parsers canbe painfully inefficient, exploding lists of possibilities andfailing to take advantage of search control methods long uti-lized in more procedurally-oriented parsers.
In the contextof BBN's Delphi NL system, we have explored modifica-tions that gain procedural efficiency without sacrificing thetheoretical dvantages of unification-based CFG's.One class of changes was to introduce varieties of struc-ture sharing or "folding" to control combinatorics.
One kindof sharing was achieved automatically by partially combin-ing similar grammar rules in the tables used by the parser.Another esulted from introducing a strictly limited form ofdisjunction that grammar writers could use to reduce thenumber of separate roles in the grammar.The other class of changes introduced procedural e ementsinto the parsing algorithm to increase xecution speed.
Themajor change here was adding partial prediction based ona procedurally-tractable andlinguistically-motivated subsetof grammar features.
Appropriate choice of the features onwhich to base the prediction allowed it to cut down sub-stantially the space that needed to be searched at mntime.We are also exploring the use of non-unification computationtechniques for certain subtasks, where the nature of the com-putation is such that approaches other than unification canbe significantly faster but can still be integrated effectivelyinto an overall unification framework.Together, the classes of changes discussed here resulted inup to a 40-fold reduction in the amount of structure createdby the parser for certain sentences and an average 5-foldparse time speedup in the BBN Delphi system.
We believethat they represent significant new directions for making thetheoretically elegant unification framework also an efficientenvironment for practical parses.2 Folding of Similar StructuresMajor improvements were obtained by partially combiningsimilar structures, either automatically, by combining com-mon elements of roles, or manually, through the use of alimited form of disjunction.2.1 Automatic Rule FoldingThe goal here is to provide an automatic process that can takeadvantage of the large degree of similarity frequently foundbetween different rules in a unification grammar by overlap-ping their storage or execution paths.
While the modularityand declarative nature of such a grammar are well-served byrepresenting each of a family of related possibilities with itsown rule, storing and testing and instantiating each role sep-arately can be quite expensive.
If common rule segmentscould be automatically identified, they could be partiallymerged, reducing both the storage space for them and thecomputational cost of matching against hem.We have implemented a first step toward this sort of auto-matic role folding, a scheme that combines roles with equiv-alent first elements on their right hand sides into rule-groups.This kind of equivalence between two roles is tested by tabing the first element of the right hand side of each role andseeing ff they mutually subsume ach other, meaning thatthey have the same information content.
If so, the vari-ables in the two roles are renamed so that the variables inthe first elements on their right hand sides are named thesame, meaning that those elements in the two rules becomeidentical, although the rest of the right hand sides and theleft hand sides may still be different.
This equivalence r la-tion is used to divide the rules into equivalence classes withidentical first right hand side elements.Before this scheme was adopted, the parser, working bot-tom up and having discovered a consituent of a particulartype covering a particular substring, would individually testeach role whose right hand side began with a constituent ofthat category to see if this element could be the first one in alarger constituent using that rule.
After adding role-groups,the parser only needs to match against the common first rightside element for each group.
If that unification fails, noneof the roles in the group are applicable; ff it succeeds, theresulting substitution fist can be used to set up continuingconfigurations for each of the rules in the group.
Use of therole-groups scheme collapsed a total of 1411 roles into 631role-groups, meaning that each single test of a role-group onthe average did the work of testing between two and threeindividual rules.The success of this first effort suggests the utility of fur-ther compilation methods, including folding based on rightside elements beyond the first, or on shared tails of roles, or237shared central subsequences.
Note that the kind of efficiencyadded by this use of role-groups closely resembles that foundin ATN's, which can represent the common prefixes of manyparse paths in a single state, with the paths only divergingwhen different tests or actions are required.
But because thisprocess here occurs as a compilation step, it can be addedwithout losing any of unificatinn's modularity and clarity.While similar goals could also be achieved by rewriting thegrammar, for example, by creating a new constituent typeto represent the shared element, such changes would makethe grammar less perspicuous.
The grammar writer shouldbe free to follow linguistic motivations in determining con-stituent structure and the like, and let the system take careof restructuring the grammar to allow it to be executed moreefficiently.2.2 Limited DisjunctionWhile in some circustances, it seems best to write indepen-dent rules and allow the system to discover the commonelements, there are other cases where it is better for thegrammar writer to be able to collapse similar ules using dis-junction.
That explicit kind of disjunction, of course, has thesame obvious advantage of allowing a single rule to expresswhat otherwise would take n separate roles which wouldhave to be matched against separately and which could addan additional factor of n ambiguity to all the structures builtby the parser.
For example, the agreement features for averb like "list" used to be expressed in BBN's Delphi sys-tem using five separate rules:(V (AGR (1ST) (SNG)) .
.
. )
~ (list)(V (AGR (2ND) (SNG)) ... ) ~ (list)(V (AGR (1ST) (PL)) .
.
. )
~ (list)(V (AGR (2ND) (PL)) .
.
. )
~ (list)(V (AGR (3RD) (PL))That information can berole:.
.
. )
-~ (lisOexpressed in a single disjunctive(V (:OR (AGR (1ST) (SNG))(AGR (2ND) (SNG))(AGR (1ST) (PL))(AGR (2ND) (PL))(AGR (3RD) (PL)))...) ~ (list)Many researchers have explored adding disjunction to uni-fication, either for grammar compactness or for the sake ofincreased efficiency at parse time.
The former goal can bemet as in Definite Clause Grartmmrs \[6\] by allowing disjunc-tion in the grammar formalism but multiplying such rolesout into disjunctive normal form at parse time.
However,making use of disjunction at parse time can make the unifi-cation algorithm significantly more complex.
In Karttunen'sscheme \[4\] for PATR-II, the result of a unification involv-ing a disjunction includes "constraints" that must be carriedalong and tested after each further unification, to be surethat at least one of the disjuncts is still possible, and toremove any others that have become impossible.
Kasper\[5\], while showing that the consistency problem for dis-junctive descriptions i NP-complete, proposed an approachwhose average complexity is controlled by separating outthe disjunctive lements and postponing their expansion orunification as long as possible.Rather than pursuing efficient techniques for handling fulldisjunction within unification, we have taken quite a differ-ent tack, defining a very limited form of disjunction that canbe implemented without substantially complicating the nor-real unification algorithm.
The advantage of this approachis that we already know that it can be implemented with-out significant loss of efficiency, but the question is whethersuch a limited version of disjunction will turn out to be suffi-ciently powerful to encode the phenomena that seem to callfor it.
Our experience seems to suggest that it is.Much of the complexity in unifying a structure against adisjunction arises only when more than one variable endsup being bound, so that dependencies between possible in-stantiations of the variables need to be remembered.
Forexample, the result of the following unification?AGR N (:OR (AGR (2ND) (SNG))(AGR (2ND) (PL))(AGR (3RD) (PL)))(where "?"
marks variables and "lq" means unification) caneasily be represented by a substitution list that binds ?AGRto the disjunction itself, but the following case(AGR ?P ?N) lq (:OR (AGR (2ND) (SNG))(AGR (2ND) (PL))(AGR (3RD) (PL)))requires that he values given to ?P and ?N in the substitutionlist be linked in some way to record their interdependence.In particular, it seemed that if we never allowed variables tooccur inside a disjunction or any structure containing morethan one variable to be matched against one, then the resultof a unification would always be expressible by a singlesubstitution list and that any disjunctions in that substitutionlist would also be only disjunctions of constants.
Thus werequired that disjuncts contain no variables, and that thevalue matched against adisjunction either be itself a variableor else contain no variables.However, enforcing the restriction against unifying dis-junctions with multi-variable terms turns out to be morecomplex than first appears.
It is not sufficient o ensure,while writing the grammar, that any element in a rule thatwill directly unify with a disjunctive term be either a con-slant term or a single variable, since a single variable in therole that directly matches the disjunctive lement might havealready, by the operation of other oles, become partially in-stantiated as a structure containing variables, and thus onethat our limited disjunlion facility would not be able to han-dle.For example, if the disjunctive agreement structure for"list" cited above occurs in a clause with a subject NP whoseagreement is (AGR (3RD) (PL)), and in a containing VProle that merely identifies the two values by binding themboth to a single variable, the conditions for our constraineddisjunction are met.
However, if the subject NP turns outto be pronoun with its agreement represented as (AGR ?P?N), the constraint is no longer met.238This problem with our fast but limited disjunction turnedup, for example, when a change in a clause rule causedagreement features to be unbound at the point where dis-junctive matching was encountered.
The change was intro-duced to allow for queries like "Do United or American havefl ights...", where the agreement between the conjoined sub-ject and the verb does not follow the normal rules.
The so-lution to that problem was to introduce aconstraint node \[1\]pseudo-constituent, placed by convention at the end of therole, to compute the permissible combinations of agreementvalues, with the values chained from the subject hroughthis constraint node to the VP.
Unfortunately, because ofthe placement of that constraint node in the rule, this meantthat the agreement features were still unbound when the VPwas reached, which caused our disjunctive unification to fail.In our current implementation, the grammar writer whomakes use of disjunction in a rule must also ensure that thecombination of that rule with the existing grammar and theknown parsing strategy will still maintain the property thatany elem_ent to be unified with a disjunctive lement willbe either a constant or a single variable.
Mistakes resultin errors flagged during parsing when such a unification isattempted.
We are not happy with this limitation, and areplanning to expand the power of our disjunction mechanismusing Kasper's methods \[51 insofar as we can do so whilemaintaining efficiency.
Nevertheless, the result of our workso far has been a many-fold reduction in the amount of struc-ture generated by the parser without any significant increasein the complexity of the unification itself.3 Procedural Algorithmic ElementsA second class of changes in addition to those that foldtogether similar structures are changes in the parsing algo-rithm that reduce the size of the search space that must beexplored.
The major type of such control was a form ofprediction from left context in the sentence.3.1 P red ic t ionA form of prediction for CFG's was described by Graham,Harrison, and Ruzzo \[3\] that was complete in the sense that,during its bottom-up, left-to-right parsing, their algorithmnever tries to build derivations at word w using role R un-less there is a partial derivation of the left context from thebeginning of the sentence up to word w - 1 that contains apartially matched rule whose next element can be the rootof a tree with R on its left frontier.
This is done by comput-ing at each position in the sentence the set of non-terminalsthat can follow partial derivations of the sentence up to thatpoint.While this style of prediction works well for CFG's,simple extension of that method to unification grammarsfounders due to the size of the prediction tables required,since a separate ntry in the prediction tables needs to bemade not just for each major category, but also for everydistinct set of feature values that occurs in the grammar.One alternative is to do only partial prediction, ignoringsome or all of the feature values.
(The equivalent for CFG'swould be predicting on the basis of sets of non-terminals.
)This reduces the size of the prediction tables at the costof reducing the selectivity of the predictions and thus rel-atively increasing the space that will have to be searchedwhile parsing.The amount of selectivity available from prediction basedon particular sets of feature values depends, of course, onthe structure of the particular grammar.
In the BBN Delphisystem, we found that prediction based on major categoryonly, ignoring all feature values, was only very weakly se-lective, since each major category predicted almost he fullset of possible categories.
Thus, it was important to makethe prediction sensitive to at least some feature values.
Weachieved the same effect by splitting certain categories basedon the values of key features and on context of applicabil-ity.
Prediction by categories in this adjusted grammar didsignificantly reduce the search space.For example, our former grammar used the single categorysymbol S to represent both matrix (or too0 clauses and sub-ordinate clauses.
This had the effect on prediction that anycontext which could predict a sub-clause nded up predict-ing both S itself and everything that could begin an S, whichmeant in practice almost all the categories in the grammar.By dividing the S category into two, called ROOT-S and S,we were able to limit such promiscuous prediction.
Further-more, the distinction between root and non-root clauses iswell estabfished in the linguistic literature (see e.g.
Emonds\[2\]).
Having this distinction encoded via separate categorysymbols, rather than through subfeatures, allows us to moreeasily separate out the phenomena that distinguish the twotypes of clause.
For example, root clauses express directquestions, which are signalled by subject-anx inversion ("Isthat a non-stop flight?")
while subordinate clauses expressindirect questions, which are signalled by "if" or "whether"("I wonder if/whether that is a non-stop flight.")
Thus itseems that the distinction eeded for predictive precision atleast in this case was also one of more general inguisticusefulness.A further major gain in predictive power occurred whenwe made linguistic trace information useable for prediction.The presence of a trace in the current left context was usedto control whether or not the prediction of one categorywould have the effect of predicting another, with the resultof avoiding the needless exploration of parse paths involvingtraces in contexts where they were not available.Like the role-groups described earfier, prediction bringsto a bottom-up, unification parser a kind of procedural effi-ciency that is common in other parsing formalisms, whereinformation from the left context cuts down the space ofpossibilities to be explored.
Note that this is not always anadvantage; for parsing fragmentary or ill-formed input, onemight like to be able to turn prediction off and revert o afull, bottom-up arse, in order to work with elements thatare not consistent with their left context.
However, it is easyto parameterize this kind of predictive control for a unifica-tion parser, so as to benefit from the additional speed in thetypical case, but also to be able to explore the full range ofpossibilities when necessary.2393.2 Non-Unification ComputationsWe are also exploring the integration of non-unification com-putations into the parser, where these can still provide theorder-independence andother theoretical dvantages of uni-fication.
There are some subproblems that need to be solveddunng parsing that do not seem well-suited to unification,but for which there are established, efficient solutions.
Wehave built into our parser an "escape" mechanism that allowsthese limited problems to be solved by some other computa-tional scheme, with the results then put into a form that canfit into the continuing unification parsing.
While our workin this area is still at an early stage, the following are thekinds of uses we intend to make of this mechanism.For example, there is a semantic "indexing" problem thatarises in parsing PP attachment, which involves access-ing the elements of a relation that can be schematized as(MATRIX-CLASS PREP MODIFIER-CLASS), for exam-ple, that "flights" can be "from" a "city".
This becomes anindexing problem because different elements of the relationcan be unknown in different circumstances.
Either class, forexample, can be unknown in questions or anaphors.
Whileunification can certainly handle such bidirectionality, it maynot do so efficiently, since it will typically do a linear searchbased on a particular argument order, while efficiency con-ceres, on the other hand, would suggest a doubly or eventriply indexed data structure, that could quickly return thematching elements, regardless of the known subset.Another example, also semantic in nature, is the task ofcomputing taxonomic relations.
There are various ways ofencoding such information in unification terms, includingone devised by Stallard \[7\] that is used in the Delphi sys-tem.
However, that approach is limited in expressivity inthat disjointness can only be expressed between siblings andit also suffers from practical problems due to the size of theencoding structures and to the fact that any change in thetaxonomy must be reflected in each separate type specifier.Thus there are many reasons to believe that it might be bet-ter to replace unification for computing taxonomic relationswith another known method, given that it is not difficult toreformulate the answers from such a component to fit theongoing unification process.The computations described here are all cases that couldbe implemented directly in terms of unification, but expand-ing the unification framework in these cases to allow directuse of other computational approaches for these limited sub-problems hould be able to significantly increase fficiencywithout hreatening the desireable f atures of the framework.between the purely declarative and the more procedural, canhelp us build fast and usable unification-based NL systemswithout compromising the theoretical elegance and flexibil-ity of the original formalism.AcknowledgementsThe work reported here was supported by the Advanced Re-search Projects Agency and was monitored by the Officeof Naval Research under Conlract No.
N00014-89-C-0008.The views and conclusions contained in this document arethose of the authors and should not be interpreted as neces-sarily representing the official policies, either expressed orimplied, of the Defense Advanced Research Projects Agencyor the United States GovernmentReferences\[1\] R. Bobrow, Robert Ingria, and David Stallard.
Syntac-tic and Semantic Knowledge in a Unification Grammar.Proceedings of the June 1990 DARPA Speech and Natu-ral Language Workshop, to appear.\[2\] Ernonds, J. E. A Transformational Approach to EnglishSyntax: Root, Structure-Preserving, and Local Transfor-mations, Academic Press, New York, 1976.\[3\] Susan L. Graham, Michael A. Harrison, and Walter L.Ruzzo.
An Improved Context-Free Recognizer.
ACMTransactions on Programming Languages and Systems2 (1980), 415-462.\[4\] Lauri Karttunen.
Features and Values.
Proceedings of theInternational Conference on Computational Linguistics1984, 28-33.\[5\] Robert T. Kasper.
A Unification Method for DisjunctiveFeature Descriptions.
Proceedings of the Association forComputational Linguistics 1987, 235-242.\[6\] F. C. N. Pereira and D. H. D. Warren.
Definite ClauseGrammars for Language Analysis--A Survey of the For-realism and a Comparison with Augmented TransitionNetworks.
Artificial Intelligence 13 (1980), 231-278.\[7\] David Stallard.
Unification-Based Semantic Interpreta-tion in the BBN Spoken Language System.
Speech andNatural Language, Proceedings of the October 1989DARPA Workshop, Morgan Kaufmann, 39-46.4 ConclusionsWe have described a number of approaches toward increas-ing the efficiency of a unification-based parser.
A compi-lation step can merge common rule elements automatically,while a limited but efficient form of disjunction allows thegrammar writer to combine roles by hand.
Prediction us-ing a tuned set of categories can cut down the search spacewithout excessive overhead, and the use of non-unificationComputation for certain subproblerns can add further effi-ciency.
Careful design of this sort, exploring the Iradeoffs240
