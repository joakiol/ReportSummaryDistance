Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 44?53,Portland, OR, USA, 24 June 2011. c?2011 Association for Computational LinguisticsEnrichment and Structuring of Archival Description MetadataKalliopi Zervanou?, Ioannis Korkontzelos?, Antal van den Bosch?
and Sophia Ananiadou??
Tilburg centre for Cognition and Communication (TiCC), University of TilburgWarandelaan 2 - PO Box 90153, 5000 LE Tilburg, The Netherlands{K.Zervanou, Antal.vdnBosch}@uvt.nl?
National Centre for Text Mining, University of Manchester131 Princess Street, Manchester M1 7DN, UK{Ioannis.Korkontzelos, Sophia.Ananiadou}@manchester.ac.ukAbstractCultural heritage institutions are making theirdigital content available and searchable on-line.
Digital metadata descriptions play an im-portant role in this endeavour.
This metadatais mostly manually created and often lacks de-tailed annotation, consistency and, most im-portantly, explicit semantic content descrip-tors which would facilitate online browsingand exploration of available information.
Thispaper proposes the enrichment of existingcultural heritage metadata with automaticallygenerated semantic content descriptors.
Inparticular, it is concerned with metadata en-coding archival descriptions (EAD) and pro-poses to use automatic term recognition andterm clustering techniques for knowledge ac-quisition and content-based document classi-fication purposes.1 IntroductionThe advent of the digital age has long changed theprocesses and the media which cultural heritage in-stitutions (such as libraries, archives and museums)apply for describing and cataloguing their objects:electronic cataloguing systems support classificationand search, while cultural heritage objects are asso-ciated to digital metadata content descriptions.
Theexpansion of the web and the increasing engagementof web users throughout the world has brought aboutthe need for cultural heritage institutions to maketheir content available and accessible to a wider au-dience online.In this endeavour, cultural heritage institutionsface numerous challenges.
In terms of metadata,different metadata standards currently exist for de-scribing various types of objects, both within thesame institution and across different institutions.Moreover, metadata object descriptions have beentypically both created by and addressed to librar-ian and archivist experts who have been expectedto assist visitors in their search.
For this reason,they primarily refer to bibliographic descriptions(e.g.
author/creator, title, etc.
), or physical descrip-tions (e.g.
size, shape, material, etc.
), and location.The lack of semantic descriptors in this type of meta-data makes it difficult for potential online visitors tobrowse and explore available information based onmore intuitive content criteria.Work on metadata in cultural heritage institu-tions has been largely focused on the issue of meta-data heterogeneity.
There have been efforts towardsthe development and adoption of collection-specificmetadata standards, such as MARC 21 (Library ofCongress, 2010) and EAD (Library of Congress,2002), for library and archival material respectively,which are intended to standardise metadata descrip-tions across different institutions.
To address the is-sue of heterogeneity across different types of objectcollections, generic metadata schemas have beenproposed, such as the Dublin Core Metadata Initia-tive (DCMI, 2011).
Moreover, current research hasattempted to integrate diverse metadata schemas bymappings across existing schemas (Bountouri andGergatsoulis, 2009), or mappings of existing meta-data to ontologies, either based on ad-hoc manuallydeveloped ontologies (Liao et al, 2010), or on ex-isting standard ontologies for cultural heritage pur-poses (Lourdi et al, 2009), such as the CIDOC Con-44ceptual Reference Model (CIDOC, 2006).
Otherapproaches attempt to address the issue of meta-data heterogeneity from a pure information retrievalperspective and discard the diverse metadata struc-tures in favour of the respective text content descrip-tions for full text indexing (Koolen et al, 2007).Zhang and Kamps (2009) attempt to exploit the ex-isting metadata XML structure for XML-based re-trieval, thus targeting individual document compo-nents.
Similarly to our approach, they investigatemetadata describing archive collections.The work presented in this paper focuses on meta-data for textual objects, such as archive documents,and on the issue of explicit, semantic, content de-scriptors in this metadata, rather than heterogene-ity.
In particular, we are concerned with the lackof explicit content descriptors which would supportexploratory information search.
For this purpose,we attempt to automatically enrich manually cre-ated metadata with content information.
We viewthe problem from an unsupervised, text mining per-spective, whereby multi-word terms recognised infree text are assumed to indicate content.
In turn,the respective inter-relationships among the recog-nised terms in the hierarchy are assumed to revealthe knowledge structure of the document collection.In this paper, we start with a description of ourEAD dataset and the challenges which our datasetposes in text processing.
Subsequently, we discussour approach to the enrichment and structuring ofthese archival descriptions and present our experi-ments.
We conclude with a discussion on our resultsand our considerations for future work.2 EAD and Challenges in Text ProcessingThe Encoded Archival Description (EAD) was con-ceived as ?a nonproprietary encoding standard formachine-readable finding aids such as inventories,registers, indexes, and other documents created byarchives, libraries, museums, and manuscript repos-itories to support the use of their holdings?
(Li-brary of Congress, 2002).
It is intended to be a datacommunication format based on SGML/XML syn-tax, aiming at supporting the accessibility to archivalresources across different institutions and focusingon the structural content of the archival descrip-tion, rather than its presentation.
For this reason,the EAD schema is characterised by a hierarchi-cal informational structure, where the deepest lev-els in the schema may inherit descriptive informa-tion defined in the upper levels.
The schema de-fines a total of 146 elements.
The three highest levelelements are <eadheader>, <frontmatter>,and <archdesc>.
<eadheader> is an ele-ment containing bibliographic and descriptive in-formation about the metadata document, while<frontmatter> is an optional element describ-ing the creation, publication, or use of the metadatadocument (Library of Congress, 2002).
Both thesetwo upper level elements do not contain informationabout the archival material itself.
The designated el-ement for this purpose is <archdesc> which de-scribes ?the content, context, and extent of a bodyof archival materials, including administrative andsupplemental information that facilitates use of thematerials?
(Library of Congress, 2002).EAD metadata files can be lengthy and com-plex in structure, with deep nesting of the XMLhierarchy elements.
As Zhang and Kamps (2009)also observe, the EAD elements may be of threetypes:i. atomic units (or text content elements) whichcontain only text and no XML elements;ii.
composite units (or nested elements) whichcontain as nested other XML elements;iii.
mixed elements which contain both atomic andcomposite units.The EAD documents used in this study describearchival collections of the International Institute ofSocial History (IISH).
They are of varying lengthand are often characterised by long spans of non-annotated, free text.
The degree of annotation, es-pecially within mixed element types is inconsistent.For example, some names may be annotated in oneelement and others not, while quite often repeatedmentions of the same name may not be annotated.Moreover, the text within an annotated element mayinclude annotator comments (e.g., translations, alter-nate names, questions, notes, etc.
), either in squarebrackets or parentheses, again in an inconsistentmanner.
The multilingual text content poses anotherchallenge.
In particular, the languages used in thedescription text vary, not only within a single EADdocument, but often also within an element (mixedor atomic).
In our approach, the former is addressed45by identifying the language at element level (cf.
Sec-tion 3.2).
However, the issue of mixed languageswithin an element is not addressed.
This introduceserrors, especially for multilingual elements of shorttext length.3 Enrichment and Structuring MethodThe overall rationale behind our method for the en-richment of EAD metadata with semantic content in-formation is based on two hypotheses:i. multi-word terms recognised in free text arevalid indicators of content, andii.
the respective term inter-relationships reflectthe knowledge structure of the collection.Thus, automatic term recognition and subsequentterm clustering constitute the two core componentsof our EAD processing.
In particular, as illustratedin Figure 1, we start with a pre-processing phase,where the EAD input SGML/XML files are firstparsed, in order to retrieve the respective text con-tent snippets, and then classified, based on language.Subsequently, terms are recognised automatically.The resulting terms are clustered as a hierarchy and,finally, the documents are classified according to theterm hierarchy, based on the terms that they contain.To evaluate our term recognition process, we exploitknowledge from two sources: existing annotationsin the EAD files, such as entity annotation residingin mixed elements (cf.
Section 2) and entity and sub-ject term information originating from the respectivecultural heritage institution Authority files, namelythe library files providing standard references for en-tities and terms that curators should use in their ob-ject descriptions.
In this section, we discuss in moredetail the methodology for each of the componentsof our approach.3.1 EAD Text Element ExtractionIn our processing of the EAD metadata XML, wefocused on the free text content structured belowthe <archdesc> root element.
As discussed inSection 2, it is the only top element which con-tains information about the archival material itself.In the text element extraction process, we parsethe EAD XML and, from the hierarchically struc-tured elements below <archdesc>, we select thetext contained in <abstract>, <bioghist>,<scopecontent>, <odd>, <note> , <dsc>and <descgrp> and their nested elements.Among these elements, the <dsc> (Descriptionof Subordinate Components) provides informationabout the hierarchical groupings of the materials be-ing described, whereas <descgrp> (DSC Group)defines nested encoded finding aids.
They were se-lected because they may contain nested informationof interest.
The rest of the elements were selectedbecause they contain important free text informationrelated to the archive content:- <bioghist>: describing the archive creatore.g.
the life of the individual or family, orthe administrative history of the organisationwhich created the archive;- <scopecontent>: referring to the rangeand topical coverage of the described materials,often naming significant organisations, individ-uals, events, places, and subjects represented;- <odd>: other descriptive data;- <note>: referring to archivist comments andexplanations;- <abstract>: brief summaries of all theabove information.All other elements not referring to the archive se-mantic content, such as administrative information,storage arrangement, physical location, etc.
were ig-nored.
Moreover, atomic or composite elementswithout free text descriptions were not selected, be-cause the descriptive information therein is assumedto be already fully structured.3.2 Language IdentificationAs mentioned in Section 2, the languages used inthe description text of the EAD documents vary, notonly within a single EAD document, but often alsowithin an EAD element.
In our approach, the objec-tive of the language identification process is to de-tect the language of the text content snippets, i.e.
theoutput of the text element extraction process, andclassify these snippets accordingly (cf.
Figure 1).Language identification is a text categorisationtask, whereby identifiers attempt to learn the mor-phology of a language based on training text and,subsequently, use this information to classify un-known text accordingly.
For this reason, training alanguage identification component requires a train-ing corpus for each language of interest.46Figure 1: Block diagram of EAD metadata enrichment and structuring processComputational approaches to language identifi-cation can be coarsely classified into information-theoretic, word-based, and N-gram-based.Information-theoretic approaches compare thecompressibility of the input text to the compress-ibility of text in the known languages.
Measuringcompressibility employs mutual information mea-sures (Poutsma, 2002).
Word-based approachesconsider the amount of common words or specialcharacters between the input text and a knownlanguage.
Finally, N-gram-based approaches con-struct language models beyond word boundaries,based on the occurrence statistics of N-grams upto some predefined length N (Dunning, 1994).The subsequent language identification in unknowntext is based on the similarity of the unknown textN-gram model to each training language model.As evidenced by these approaches, language iden-tification relies on some form of comparison of theunknown text to known languages.
For this reason,the respective text categorisation into a given lan-guage suffers when the input text is not long enough:the shorter the input text is, the fewer the availablefeatures for comparison against known languagemodels.
Moreover, errors in the categorisation pro-cess are also introduced, when the language modelsunder comparison share the same word forms.In our approach, we have opted for the most pop-ular language identification method, the one basedon N-grams.
Nevertheless, any other language iden-tification method could have been applied.3.3 Term RecognitionThe objective of term recognition is the identifica-tion of linguistic expressions denoting specialisedconcepts, namely domain or scientific terms.
For in-formation management and retrieval purposes, theautomatic identification of terms is of particular im-portance because these specialised concept expres-sions reflect the respective document content.Term recognition approaches largely rely on theidentification of term formation patterns.
Linguisticapproaches use either syntactic (Justeson and Katz,1995; Hearst, 1998), or morphological (Heid, 1998)rule patterns, often in combination with termino-logical or other lexical resources (Gaizauskas et al,2000) and are typically language and domain spe-cific.Statistical approaches typically combine linguis-tic information with statistical measures.
Thesemeasures can be coarsely classified into twocategories: unithood-based and termhood-based.Unithood-based approaches measure the attachmentstrength among the constituents of a candidateterm.
For example, some unithood-based mea-sures are frequency of co-occurrence, hypothesistesting statistics, log-likelihood ratios test (Dunning,1993) and pointwise mutual information (Churchand Hanks, 1990).
Termhood-based approaches at-tempt to measure the degree up to which a candidateexpression is a valid term, i.e.
refers to a specialisedconcept.
They attempt to measure this degree byconsidering nestedness information, namely the fre-47quencies of candidate terms and their subsequences.Examples of such approaches are C-Value and NC-Value (Frantzi et al, 2000) and the statistical barriermethod (Nakagawa, 2000).It has been experimentally shown that termhood-based approaches to automatic term extraction out-perform unithood-based ones and that C-Value(Frantzi et al, 2000) is among the best perform-ing termhood-based approaches (Korkontzelos etal., 2008).
For this reason, we choose to employthe C-Value measure in our pipeline.
C-Value ex-ploits nestedness and comes together with a com-putationally efficient algorithm, which scores can-didate multi-word terms according to the measure,considering:- the total frequency of occurrence of the candi-date term;- the frequency of the candidate term as part oflonger candidate terms;- the number of these distinct longer candidates;- the length of the candidate term (in tokens).These arguments are expressed in the followingnestedness formula:N(?)
=???f(?
), if ?
is not nestedf(?
)?1|T?|?b?T?f(b), otherwise (1)where ?
is the candidate term, f(?)
is its frequency,T?
is the set of candidate terms that contain ?
and|T?| is the cardinality of T?.
In simple terms, themore frequently a candidate term appears as a sub-string of other candidates, the less likely it is to be avalid term.
However, the greater the number of dis-tinct term candidates in which the target term can-didate occurs as nested, the more likely it is to bea valid term.
The final C-Value score considers thelength (|?|) of each candidate term (?)
as well:C-value(?)
= log2 |?| ?N(?)
(2)The C-Value method requires linguistic pre-processing in order to detect syntactic term for-mation patterns.
In our approach, we used Lex-Tagger (Vasilakopoulos, 2003), which combinestransformation-based learning with decision treesand we adapted its respective lexicon to our domain.We also included WordNet lemma information inour processing, for text normalisation purposes.
Lin-guistic pre-processing is followed by the computa-tion of C-Value on the candidate terms, in length or-der, longest first.
Candidates that satisfy a C-Valuethreshold are sorted in decreasing C-Value order.3.4 Hierarchical Agglomerative ClusteringIn our approach, term recognition provides contentindicators.
In order to make explicit the knowl-edge structure of the EAD, our method requiressome form of concept classification and structuring.The process of hierarchical agglomerative cluster-ing serves this objective.Agglomerative algorithms are very popular inthe field of unsupervised concept hierarchy induc-tion and are typically employed to produce unla-belled taxonomies (King, 1967; Sneath and Sokal,1973).
Hierarchical clustering algorithms are basedon measuring the distance (dissimilarity) betweenpairs of objects.
Given an object distance metric D,the similarity of two clusters, A and B, can be de-fined as a function of the distance D between theobjects that the clusters contain.
According to thissimilarity, also called linkage criterion, the choiceof which clusters to merge or split is made.
In ourapproach, we have experimented with the three mostpopular criteria, namely:Complete linkage (CL): The similarity of two clus-ters is the maximum distance between their elementssimCL(A,B) = maxx?A,y?BD(x, y) (3)Single linkage (SL): The similarity of two clustersis the minimum distance between their elementssimSL(A,B) = minx?A,y?BD(x, y) (4)Average linkage (AL): The similarity of two clustersis the average distance between their elementssimAL(A,B) =1|A| ?
|B|?x?A?y?BD(x, y) (5)To estimate the distance metric D we use eitherthe document co-occurrence or the lexical similar-ity metric.
The chosen distance metric D and link-age criterion are employed to derive a hierarchy ofterms by agglomerative clustering.Our document co-occurrence (DC) metric is de-fined as the number of documents (d) in the collec-tion (R) in which both terms (t1 and t2) co-occur:DC =1|R||{d : (d ?
R) ?
(t1 ?
d) ?
(t2 ?
d)}| (6)48The above metric accepts that the distance betweentwo terms is inversely proportional to the number ofdocuments in which they co-occur.Lexical Similarity (LS), as defined in Nenadic?and Ananiadou (2006), is based on shared term con-stituents:LS =|P (h1) ?
P (h2)||P (h1)|+ |P (h2)|+|P (t1) ?
P (t2)||P (t1)|+ |P (t2)|(7)where t1 and t2 are two terms, h1 and h2 their heads,P (h1) and P (h2) their set of head words, and P (t1)and P (t2) their set of constituent words, respec-tively.3.5 Document ClassificationThe term hierarchy is used in our approach for se-mantic classification of documents.
In this process,we start by assigning to each leaf node of the termhierarchy the set of EAD documents in which thecorresponding term occurs.
Higher level nodes areassigned the union of the document sets of theirdaughters.
The process is bottom-up and applied it-eratively, until all hierarchy nodes are assigned a setof documents.Document classification, i.e.
the assignment ofdocument sets to term hierarchy nodes, is use-ful, among others, for structured search and index-ing purposes.
Moreover, it provides a direct soft-clustering of documents based on semantics, giventhe number of desired clusters, C. C correspondsto a certain horizontal cut of the term hierarchy, sothat C top nodes appear, instead of one.
The doc-ument sets assigned to these C top nodes representthe C desired clusters.
This document clustering ap-proach is soft, since each document can occur in oneor more clusters.3.6 Evaluation ProcessThe automatic evaluation process, illustrated in Fig-ure 1, serves the purpose of evaluating the termrecognition accuracy.
Since the objective of termrecognition tools is the detection of linguistic ex-pressions denoting specialised concepts, i.e.
terms,the results evaluation would ideally require inputfrom the respective domain experts.
This is a la-borious and time consuming process which also en-tails finding the experts willing to dedicate effortand time for this task.
In response to this issue,we decided to exploit the available domain-specificknowledge resources and automate part of the eval-uation process by comparing our results to this ex-isting information.
Thus, the automatic evaluationprocess is intended to give us an initial estimateof our performance and reduce the amount of re-sults requiring manual evaluation.
The available re-sources used are of two types:i. entity annotations in the EAD documents (i.e.names of persons, organisations and geograph-ical locations);ii.
entity and subject terms originating from thecultural heritage institution Authority files.The entity annotations in the EAD documentswere not considered during our term recognition.The entity and subject terms of the respective Au-thority file records are encoded in MARC21/XMLformat (Library of Congress, 2010).
MARC(MAchine-Readable Cataloging) is a standard initi-ated by the US Library of Congress and concernsthe representation of bibliographic information andrelated data elements used in library catalogues.
TheMARC21 Authority files resource used in our eval-uation provides, among other information, the stan-dard references for entities and the respective pos-sible entity reference variations, such as alternatenames or acronyms, etc., that curators should usein their object descriptions.
The subject term Au-thority records provide mappings between a legacysubject term thesaurus which is no longer used forclassification, and current library records.In the evaluation process the EAD SGML/XMLand the MARC21/XML Authority files are firstparsed by the respective parsers in order to extractthe XML elements of interest.
Subsequently, thetext-content of the elements is processed for nor-malisation and variant generation purposes.
In thisprocess, normalisation involves cleaning up the textfrom intercepted comments and various types ofinconsistent notes, such as dates, aliases and al-ternate names, translations, clarifications, assump-tions, questions, lists, etc.
Variant generation in-volves detecting the acronyms, abbreviated namesand aliases mentioned in the element text and cre-ating the reversed variants for, e.g., [Last Name,First Name] sequences.
The results of this pro-cess, from both EAD and Authority files, are mergedinto a single list for every respective category (or-49language snippets language snippetsDutch 50,363 Spanish 3,430German 41,334 Danish 2,478English 19,767 Italian 1,100French 6,182 Swedish 699Table 1: Number of snippets per identified language.ganisations, persons, geographic locations and sub-ject terms) and are compared to our term results list.4 Experimental SettingFor training the language identification component,we used the European Parliament Proceedings Par-allel Corpus (Europarl) which covers the proceed-ings of the European Parliament from 1996 to 2006(Koehn, 2005).
The corpus size is 40 million wordsper language and is translated in Danish, German,Greek, English, Spanish, Finnish, French, Italian,Dutch, Portuguese and Swedish.
In our experiments,we take as input for subsequent term recognitiononly the snippets identified as English text.In the experiments reported in this work, we ac-cept as term candidates morpho-syntactic pattern se-quences which consist of adjectives and nouns, andend with a noun.
The C-Value algorithm (cf.
Sec-tion 3.3) was implemented under two different set-tings:i. one only considering as term candidates adjec-tive and noun sequences that appear at leastonce as non-nested in other candidate terms;andii.
one that considers all adjective and noun se-quences, even if they never occur as non-nested.Considering that part-of-speech taggers usually suf-fer high error rates when applied on specialty do-mains, the former setting is expected to increase pre-cision, whereas the latter to increase recall (cf.
Sec-tion 5).We accepted as valid terms all term candidateswhose C-Value score exceeds a threshold, whichwas set to 3.0 after experimentation.
In the subse-quent hierarchical agglomerative clustering process,we experimented with all six combinations of thethree linkage criteria (i.e.
complete, single and aver-age) with the two distance metrics (i.e.
documentco-occurrence and lexical similarity) described inFigure 2: Length of snippets per identified language.Section 3.4.5 ResultsThe EAD document collection used for this studyconsisted of 3, 093 SGML/XML files.
As shown onTable 1, according to our language identifier, the ma-jority of the text snippets of the selected EAD XMLelements were in Dutch, followed by German andEnglish.
We selected for later processing 19, 767snippets classified as English text, corresponding to419, 857 tokens.
A quantitative evaluation of thelanguage identifier results has not been performed.However, our observation of the term recognition re-sults showed that there were some phrases, mostlyDutch and German entity names (organisations andpersons mostly) classified as English.
This might bedue to these entities appearing in their original lan-guage within English text, as it is often the case inour EAD files.
Moreover, manual inspection of ourresults showed that other languages classified as En-glish, e.g.
Turkish and Czech, were not covered byEuroparl.As mentioned in Section 3.2, short text snip-pets may affect language identification performance.Figure 2 illustrates the snippet length per identifiedlanguage.
We observe that the majority of text snip-pets is below 10 tokens, few fall within an averagelength of 20 to 50 tokens approximately, and veryfew are above 100 tokens.Figure 3 shows the results of our automatic evalu-ation for the term recognition process.
In this graph,the upper, red curve shows the percentage of cor-rect terms for the C-Value setting considering asterm candidates adjective and noun sequences thatappear at least once as non-nested in other candi-date terms.
The lower, blue curve shows the per-50Figure 3: Term coverage for each C-Value setting basedon EAD & Authority entity and subject term evaluation.centage of correct terms for the C-Value setting con-sidering all adjective and noun sequences, even ifthey never occur as non-nested.
In this automaticevaluation, correct terms are, as presented in Sec-tion 3.6, those candidate terms matching the com-bined lists of entity and subject terms acquired bythe respective EAD and MARC21 Authority files.We observe that the C-Value setting which considersonly noun phrase patterns occurring at least once asnon-nested, displays precision up to approximately70% for the top terms in the ranked list, whereas theother setting considering all noun phrase sequences,reaches a maximum of 49%.
The entire result setabove the 3.0 C-Value threshold amounts to 1, 345and 2, 297 terms for each setting, and reaches pre-cision of 42.01% and 28.91% respectively.
Thus,regarding precision, the selective setting clearly out-performs the one considering all noun phrases, but italso reaches a lower recall, as indicated by the ac-tual terms within the threshold.
We also observethat precision drops gradually below the threshold,an indication that the ranking of the C-Value mea-sure is effective in promoting valid terms towardsthe top.
This automatic evaluation considers as erro-neous unknown terms which may be valid.
Furthermanual evaluation by domain experts is required fora more complete picture of the results.Figure 4 shows six dendrograms, each represent-ing the term hierarchy produced by the respectivecombination of linkage criterion to distance metric.The input for these experiments consists of all termsexceeding the C-Value threshold, and by consideringonly noun phrase sequences appearing at least onceas non-nested.
Since the hierarchies contain 1, 345terms, the dendrograms are very dense and difficultto inspect thoroughly.
However, we include thembased on the fact that the overall shape of the den-drogram can indicate how much narrow or broad thecorresponding hierarchy is and indirectly its quality.Narrow here characterises hierarchies whose mostnon-terminal nodes are parents of one terminal andone non-terminal node.
Narrow hierarchies are deepwhile broader hierarchies are shallower.Broad and shallow hierarchies are, in our case, ofhigher quality, since terms are expected to be relatedto each other and form distinct groups.
In this view,average linkage leads to richer hierarchies (Figures4(c), 4(f)), followed by single linkage (Figures 4(b),4(e)) and, finally, complete linkage (Figures 4(a),4(d)).
The hierarchy of higher quality seems tobe the result of average linkage and document co-occurrence combination (Figure 4(c)), followed bythe combination of average linkage and lexical sim-ilarity (Figure 4(f)).
Clearly, these two hierarchiesneed to be investigated manually and closely to ex-tract further conclusions.
Moreover, an application-based evaluation could investigate whether differentclustering settings suit different tasks.6 Conclusion and Future WorkIn this paper, we have presented a methodology forsemantically enriching archival description meta-data and structuring the metadata collection.
Weconsider that terms are indicators of content seman-tics.
In our approach, we perform term recogni-tion and then hierarchically structure the recognisedterms.
Finally, we use the term hierarchy to classifythe metadata documents.
We also propose an auto-matic evaluation of the recognised terms, by com-paring them to domain knowledge resources.For term recognition, we used the C-Value al-gorithm and found that considering noun phraseswhich appear at least once independently, outper-forms considering all noun phrases.
Regarding hier-archical clustering, we observe that the average link-age criterion combined with a distance metric basedon document co-occurrence produces a rich broadhierarchy.
A more thorough evaluation of these re-sults is required.
This should include a manual eval-uation of recognised terms by domain experts andan application-based evaluation of the resulting doc-ument classification.51(a) Complete linkage - DC (b) Single linkage - DC (c) Average linkage - DC(d) Complete linkage - LS (e) Single linkage - LS (f) Average linkage - LSFigure 4: Dendrograms showing the results of agglomerative clustering for all linkage criteria and distance metrics,document co-occurrence (DC) and Lexical Similarity (LS).ReferencesLina Bountouri and Manolis Gergatsoulis.
2009.
Inter-operability between archival and bibliographic meta-data: An EAD to MODS crosswalk.
Journal of Li-brary Metadata, 9(1-2):98?133.Kenneth Church and Patrick Hanks.
1990.
Word asso-ciation norms, mutual information, and lexicography.Computational Linguistics, 16(1):22?29.CIDOC.
2006.
The CIDOC Conceptual ReferenceModel.
CIDOC Documentation Standards WorkingGroup, International Documentation Committee, In-ternational Council of Museums.
http://www.cidoc-crm.org/.DCMI.
2011.
The Dublin Core Metadata Initiative.http://dublincore.org/.Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19(1):61?74.Ted Dunning.
1994.
Statistical identification of lan-guage.
MCCS 94-273.
Technical report, ComputingResearch Laboratory, New Mexico State University.Katerina Frantzi, Sophia Ananiadou, and Hideki Mima.2000.
Automatic recognition of multi-word terms: theC-value/NC-value method.
International Journal onDigital Libraries, 3(2):115?130.Robert Gaizauskas, George Demetriou, and KevinHumphreys.
2000.
Term recognition in biological sci-ence journal articles.
In Proc.
of the NLP 2000 Work-shop on Computational Terminology for Medical andBiological Applications, pages 37?44, Patras, Greece.Marti Hearst.
1998.
Automated discovery of WordNetrelations.
In Christiane Fellbaum, editor, WordNet:An Electronic Lexical Database, pages 131?153.
MITPress.Ulrich Heid.
1998.
A linguistic bootstrapping approachto the extraction of term candidates from german text.Terminology, 5(2):161?181.John Justeson and Slava Katz.
1995.
Technical terminol-ogy: some linguistic properties and an algorithm foridentification in text.
Natural Language Engineering,1(1):9?27.Benjamin King.
1967.
Step-Wise clustering proce-dures.
Journal of the American Statistical Association,62(317):86?101.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Machine Transla-tion Summit X, pages 79?86, Phuket, Thailand.Marijn Koolen, Avi Arampatzis, Jaap Kamps, Vincentde Keijzer, and Nir Nussbaum.
2007.
Unified accessto heterogeneous data in cultural heritage.
In Proc.
ofRIAO ?07, pages 108?122, Pittsburgh, PA, USA.Ioannis Korkontzelos, Ioannis Klapaftis, and SureshManandhar.
2008.
Reviewing and evaluating auto-matic term recognition techniques.
In Bengt Nord-stro?m and Aarne Ranta, editors, Proc.
of GoTAL ?08,volume 5221 of LNCS, pages 248?259, Gothenburg,Sweden.
Springer.Shu-Hsien Liao, Hong-Chu Huang, and Ya-Ning Chen.2010.
A semantic web approach to heterogeneousmetadata integration.
In Jeng-Shyang Pan, Shyi-MingChen, and Ngoc Thanh Nguyen, editors, Proc.
ofICCCI ?10, volume 6421 of LNCS, pages 205?214,Kaohsiung, Taiwan.
Springer.Library of Congress.
2002.
Encoded archival descrip-tion (EAD), version 2002.
Encoded Archival Descrip-tion Working Group: Society of American Archivists,52Network Development and MARC Standards Office,Library of Congress.
http://www.loc.gov/ead/.Library of Congress.
2010.
MARC standards.
NetworkDevelopment and MARC Standards Office, Library ofCongress, USA.
http://www.loc.gov/marc/index.html.Irene Lourdi, Christos Papatheodorou, and Martin Doerr.2009.
Semantic integration of collection description:Combining CIDOC/CRM and Dublin Core collectionsapplication profile.
D-Lib Magazine, 15(7/8).Hiroshi Nakagawa.
2000.
Automatic term recognitionbased on statistics of compound nouns.
Terminology,6(2):195?210.Goran Nenadic?
and Sophia Ananiadou.
2006.
Min-ing semantically related terms from biomedical liter-ature.
ACM Transactions on Asian Language Infor-mation Processing (TALIP), 5(1):22?43.Arjen Poutsma.
2002.
Applying monte carlo techniquesto language identification.
Language and Computers,45:179?189.Peter Sneath and Robert Sokal.
1973.
Numerical taxon-omy: the principles and practice of numerical classifi-cation.
Freeman, San Francisco, USA.Argyris Vasilakopoulos.
2003.
Improved unknown wordguessing by decision tree induction for POS taggingwith tbl.
In Proc.
of CLUK ?03, Edinburgh, UK.Junte Zhang and Jaap Kamps.
2009.
Focused searchin digital archives.
In Gottfried Vossen, Darrell D. E.Long, and Jeffrey Xu Yu, editors, Proc.
of WISE?09, volume 5802 of LNCS, pages 463?471, Poznan,Poland.
Springer.53
