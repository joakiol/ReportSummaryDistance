Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 24?28Manchester, August 2008Toward a cross-framework parser annotation standardDan FlickingerCSLI, Stanford Universitydanf@stanford.eduAbstractEfficient and precise comparison of parserresults across frameworks will require anegotiated agreement on a target represen-tation which embodies a good balance ofthree competing dimensions: consistency,clarity, and flexibility.
The various annota-tions provided in the COLING-08 sharedtask for the ten ?required?
Wall Street Jour-nal sentences can serve as a useful ba-sis for these negotations.
While there isof course substantial overlap in the con-tent of the various schemes for these sen-tences, no one of the schemes is ideal.This paper presents some desiderata fora negotiated target annotation scheme forwhich straightforward mappings can beconstructed from each of the supplied an-notation schemes.1 IntroductionEfficient and precise comparison of parser resultsacross frameworks will require a negotiated agree-ment on a target representation which embodies agood balance of three competing dimensions: con-sistency, clarity, and flexibility.
The various anno-tations provided in the COLING-08 shared task forthe ten ?required?
Wall Street Journal sentences canserve as a useful basis for these negotations.
Whilethere is of course substantial overlap in the contentof the various schemes for these sentences, no oneof the schemes is ideal, containing either too muchor too little detail, or sometimes both.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.2 Predicate-argument structures, notlabelled bracketingsCompeting linguistic frameworks can vary dramat-ically in the syntactic structures they assign to sen-tences, and this variation makes cross-frameworkcomparison of labelled bracketings difficult andin the limit uninteresting.
The syntactic struc-tures of Combinatory Categorial Grammar (CCG:Steedman (2000), Hockenmaier (2003), Clark andCurran (2003)), for example, contrast sharplywith those of the Penn Treebank Marcus et al(1993), and the PTB structures differ in many lessdramatic though equally important details fromthose assigned in Lexical Functional Grammar(LFG: Bresnan and Kaplan (1982)) or Head-drivenPhrase Structure Grammar (HPSG: Pollard andSag (1994)).
We even find variation in the assign-ments of part-of-speech tags for individual tokens,for example with words like ?missionary?
or ?clas-sical?
treated as adjectives in some of the annota-tions and as nouns in others.
Furthermore, a sim-ple labelled bracketing of surface tokens obscuresthe fact that a single syntactic constituent can fillmultiple roles in the logical structure expressedby a sentence, as with controlled subjects, relativeclauses, appositives, coordination, etc.
More de-tailed discussions of the obstacles to directly com-paring syntactic structures include Preiss (2003),Clark and Curran (2007), and most recently Sagaeet al (2008).Since it is this underlying logical content thatwe seek when parsing a sentence, the target anno-tation for cross-framework comparison should notinclude marking of syntactic constituents, but fo-cus instead on the predicate argument structuresdetermined by the syntactic analysis, as proposedten years ago by Carroll et al (1998).
Several of24the annotations provided in the shared task alreadydo this, providing a good set of starting points fornegotiating a common target.3 General annotation characteristicsSome of the issues in need of negotiation are quitegeneral in nature, while many others involve spe-cific phenomena.
First, the general ones:3.1 Unique identifiersSince a given word can appear multiple timeswithin a single sentence, each token-derived el-ement of the annotation needs a unique identi-fier.
Some of the supplied annotations use the to-ken position in the sentence for this purpose, butthis is not general enough to support competinghypotheses about the number of tokens in a sen-tence.
A sharp example of this is the word pixie-like in sentence 56, which one of the annotations(CONLL08) analyzes as two tokens, quite reason-ably, since -like is a fully productive compound-ing element.
So a better candidate for the uniqueidentifier for each annotation element would be theinitial character position of the source token in theoriginal sentence, including spaces and punctua-tion marks as characters.
Thus in the sentence thedog slept the annotation elements would be the-1, dog-5, and slept-9.
The original sentences inthis shared task were presented with spaces addedaround punctuation, and before ?n?t?.
so the char-acter positions for this task would be computedtaking this input as given.
Using character posi-tions rather than token positions would also betteraccommodate differing treatments of multi-wordexpressions, as for example with Los Angeles insentence 9, which most of the supplied schemesannotate as two tokens with Los modifying Ange-les, but which PARC treats as a single entity.3.2 One token in multiple rolesMost of the supplied annotations include some no-tational convention to record the fact that (a phraseheaded by) a single token can fill more than onelogical role at the predicate-argument level of rep-resentation.
This is clear for controlled subjectsas in the one for play in sentence 53: ?doesn?thave to play...concertos?, and equally clear for themissing objects in tough-type adjective phrases,like the object of apply in sentence 133: ?impos-sible to apply?.
This multiple filling of roles bya single syntactic constituent can be readily ex-pressed in a target annotation of the predicate argu-ment structure if the token heading that constituentbears the unique positional identifier which has al-ready been motivated above.
Supplied annotationschemes that already directly employ this approachinclude PARC and Stanford, and the necessarypositional information is also readily available inthe CCG-PA, HPSG-PA, and CONLL08 schemes,though not in the RASP-GR or PTB notations.
Itwill be desirable to employ this same conventionfor the logical dependencies in other constructionswith missing arguments, including relative clauses,other unbounded dependencies like questions, andcomparative constructions like sentence 608?s thanPresident Bush has allowed .3.3 Stem vs surface formSome of the supplied annotations (CCG-PA,RASP-GR, and Stanford) simply use the surfaceforms of the tokens as the elements of relations,while most of the others identify the stem formsfor each token.
While stemming might introducean additional source of inconsistency in the anno-tations, the resulting annotations will be better nor-malized if the stems rather than the surface formsof words are used.
This normalization would alsoopen the door to making such annotations moresuitable for validation by reasoning engines, or forlater word-sense annotation, or for applications.3.4 Identification of rootMost but not all of the supplied annotationschemes identify which token supplies the outer-most predication for the sentence, either directlyor indirectly.
An explicit marking of this outer-most element, typically the finite verb of the mainclause of a sentence, should be included in the tar-get annotation, since it avoids the spurious ambi-guity found for example in the HPSG-PA annota-tion for sentence 22, which looks like it would beidentical for both of the following two sentences:?
Not all those who wrote oppose the changes .?
Not all those who oppose the changes wrote .3.5 Properties of entities and eventsSome of the supplied annotation schemes includeinformation about morphosyntactically markedproperties of nouns and verbs, including person,number, gender, tense, and aspect.
Providing forexplicit marking of these properties in a common25target annotation is desirable, at least to the level ofdetail adopted by several of the supplied schemes.While several of the supplied annotationschemes marked some morphosyntactic propertiessome of the time, the PARC annotation of positivedegree for all adjectives reminds us that it would beuseful to adopt a notion of default values for theseproperties in the target annotation.
These defaultswould be explicitly defined once, and then onlynon-default values would need to be marked ex-plicitly in the annotation for a given sentence.
Forexample, the PARC annotation marks the ?perf?
(perfect) attribute for a verb only when it has apositive value, implicitly using the negative valueas the default.
This use of defaults would improvethe readability of the target annotation without anyloss of information.Marking of the contrast between declarative, in-terrogative, and imperative clauses is included insome but not all of the annotation schemes.
Sincethis contrast is highly salient and (almost always)easily determined, it should be marked explicitly inthe target annotation, at least for the main clause.3.6 Named entitiesThe supplied annotations represent a variety of ap-proaches to the treatment of named entities wheremultiple tokens comprise the relevant noun phrase,as in sentence 53?s ?The oboist Heinz Holliger?.Several schemes treat both oboist and Heinz sim-ply as modifiers of Holliger, drawing no distinc-tion between the two.
The PARC and PTB anno-tations identify Heinz Holliger as a named entity,with oboist as a modifier, and only the CONLL08scheme analyses this expression as an apposition,with oboist as the head predicate of the whole PN.Since complex proper names appear frequentlywith modifiers and in apposition constructions, andsince competing syntactic and semantic analysescan be argued for many such constituents, the tar-get annotation should contain enough detail to il-luminate the substantive differences without exag-gerating them.
Interestingly, this suggests that theevaluation of a given analysis in comparison with agold standard in the target annotation may requiresome computation of near-equivalence at least forentities in complex noun phrases.
If scheme Atreats Holliger as the head token for use in exter-nal dependencies involving the above noun phrase,while scheme B treats oboist as the head token, itwill be important in evaluation to exploit the factthat both schemes each establish some relation be-tween oboist and Holliger which can be interpretedas substitutional equivalence with respect to thoseexternal dependencies.
This means that even whena target annotation scheme has been agreed upon,and a mapping defined to convert a native anno-tated analyis into a target annotation, it will still benecessary to create non-trivial software which canevaluate the mapped analysis against a gold stan-dard analysis.4 Notational conventions to be negotiatedA number of notational conventions will have to benegotiated for a common target annotation scheme,ranging from quite general design decisions to de-tails about very specific linguistic phenomena.4.1 Naming of arguments and relationsIt seems plausible that agreement could be reachedquickly on the names for at least the core gram-matical functions of subject, direct object, indirectobject, and verbal complement, and perhaps alsoon the names for adjectival and adverbial modi-fiers.
Prepositions are more challenging, since theyare very often two-place relations, and often liveon the blurry border between arguments and ad-juncts.
For example, most of the supplied anno-tation schemes treated the by-PP following movedin sentence 608 as a marker for the logical subjectof the passive verb, but this was at least not clearin the CCG-PA annotation.
In sentence 56, therewas variation in how the from and to PPs were an-notated, with CONLL08 making the two to PPsdependents of the from PP rather than of the verbrange.Some of the supplied annotation schemes in-troduced reasonable but idiosyncratic names forother frequently occurring relations or dependen-cies such as relative clauses, appositives, noun-noun compounds, and subordinate clauses.
An in-ventory of these frequently occurring phenomenashould be constructed, and a target name negoti-ated for each, recognizing that there will always bea long tail of less frequently occurring phenomenawhere names will not (yet) have been negotiated.4.2 CoordinationPerhaps the single most frequent source of appar-ent incompatibility in the supplied annotations forthe ten required sentences in this task involves co-ordination.
Some schemes, like HPSG-PA and26Stanford, treat the first conjunct as the primary en-tity which participates in other predications, withthe other conjunct(s) dependent on the first, thougheven here they usually (but not always) distributeconjoined verbal arguments with separate predica-tions for each conjunct.
Some schemes, like thePTB, PARC, and RASP-GR, represent the group-ing of three or more conjuncts as flat, while otherslike the Stanford scheme represent them as pairs.Most schemes make each conjunction word itselfexplicit, but for example the PARC annotation of866 marks only one occurrence of and even thoughthis three-part coordinate structure includes twoexplicit conjunctions.While the distribution of conjoined elements incoordinate structures may be the most practical tar-get annotation, it should at least be noted that thisapproach will not accommodate collective read-ings of coordinate NPs as in well-known exampleslike ?Tom and Mary carried the piano upstairs.
?But the alternative, to introduce a new conjoinedentity for every coordinate structure, may be tooabstract to find common support among develop-ers of current annotation schemes, and perhaps notworth the effort at present.However, it should be possible to come to agree-ment on how to annotate the distribution of con-joined elements consistently, such that it is clearboth which elements are included in a coordinatestructure, and what role each plays in the relevantpredicate argument structures.4.3 Verb-particle expressionsAnother phenomenon exhibited several times inthese ten sentences involves verb-particle expres-sions, as with thrash out and perhaps also stop by.Most of the supplied schemes distinguished thisdependency, but some simply treated the particleas a modifier of the verb.
It would be desirableto explicitly distinguish in a target annotation thecontrast between stopped a session and stopped bya session without having to hunt around in the an-notation to see if there happens to be a modifier ofstop that would dramaticaly change its meaning.The example with stop by a session also high-lights the need for an annotation scheme which lo-calizes the differences between competing analy-ses where possible.
Though all of the supplied an-notations treat by as a particle just like up in ?lookup the answer?, in fact by fails the clearest test forbeing a particle, namely the ability to appear afterthe NP argument: ?
*He stopped the session by.
?An analysis treating ?by the session?
as a selected-for PP with a semantically empty by might bet-ter fit the linguistic facts, but the target annotationcould remain neutral about this syntactic debate ifit simply recorded the predicate as stop by, takingan NP argument just as is usually done for the com-plement of rely in ?rely on us?.4.4 Less frequent phenomenaSince each new phenomenon encountered maywell require negotiation in order to arrive at acommon target annotation, it will be important toinclude some provisional annotation for relationsthat have not yet been negotiated.
Even theseten example sentences include a few expressionswhere there was little or no agreement among theschemes about the annotations, such as ?if notmore so?
in sentence 30, or ?to be autographed?in sentence 216.
It would be convenient if thetarget annotation scheme included a noncommittalrepresentation for some parts of a given sentenceexplicitly noting the lack of clarity about what thestructure should be.4.5 Productive derivational morphologyIt was surprising that only one of the annota-tion schemes (CONLL08) explicitly annotated thenominal gerund conducting in sentence 53 as pro-ductively related to the verb conduct..
While theissue of derivational morphology is of course aslippery slope, the completely productive gerund-forming process in English should be accommo-dated in any target annotation scheme, as should asmall number of other highly productive and mor-phologically marked derivational regularities, in-cluding participial verbs used as prenominal mod-ifiers, and comparative and superlative adjectives.Including this stemming would provide an infor-mative level of detail in the target annotation, andone which can almost always be readily deter-mined from the syntactic context.5 Next stepsThe existing annotation schemes supplied for thistask exhibit substantial common ground in thenature and level of detail of information beingrecorded, making plausible the idea of investing amodest amount of joint effort to negotiate a com-mon target representation which addresses at leastsome of the issues identified here.
The initial com-27mon target annotation scheme should be one whichhas the following properties:?
Each existing scheme?s annotations can bereadily mapped to those of the target schemevia an automatic procedure.?
The annotations appear in compact, humanlyreadable form as sets of tuples recordingeither predicate-argument dependencies orproperties of entities and events, such as num-ber and tense.?
The inventory of recorded distinctions is richenough to accommodate most of what anyone scheme records, though it may not bea superset of all such distinctions.
For ex-ample, some scheme might record quantifierscope information, yet the target annotationscheme might not, either because it is not ofhigh priority for most participants, or becauseit would be difficult to produce consistently ina gold standard.The primary purposes of such a target annotationscheme should be to facilitate the automatic com-parison of results across frameworks, and to sup-port evaluation of results against gold standardanalyses expressed in this target scheme.
It mightalso be possible to define the scheme such that thetarget annotations contain enough information toserve as the basis for some application-level taskssuch as reasoning, but the primary design criteriashould be to enable detailed comparison of analy-ses.ReferencesBresnan, Joan and Ronald M. Kaplan, 1982.
Lexical-Functional Grammar.
A Formal System for Gram-matical Representation.
The Mental Representationof Grammatical Relations, ed.
Joan Bresnan.
MITPress, Cambridge, MA.Carroll, John, Edward Briscoe and Antonio Sanfilippo.1998.
Parser evaluation: a survey and a new pro-posal.
Proceedings of the 1st International Confer-ence on Language Resources and Evaluation.Clark, Stephen and James R. Curran.
2003.
Log-linearmodels for wide-coverage CCG parsing.
Proceed-ings of the 2003 conference on Empirical methods innatural language processing, pp.97?104.Clark, Stephen and James R. Curran.
2007.Formalism-Independent Parser Evaluation withCCG and DepBank.
Proceedings of the Associationfor Computational Linguistics 2007.Harrison, P., S. Abney, D. Flickinger, C. Gdaniec,R.
Grishman, D. Hindle, B. Ingria, M. Marcus, B.Santorini, , and T. Strzalkowski.
1991.
Evaluat-ing syntax performance of parser/grammars of En-glish.
Natural Language Processing Systems Eval-uation Workshop, Technical Report RL- TR-91-6, J.G.
Neal and S. M. Walter, eds.Hockenmaier, Julia.
2003.
Data and Models for Sta-tistical Parsing with Combinatory Categorial Gram-mar.
Ph.D. thesis, University of Edinburgh.Marcus, Mitchell P., Beatrice Santorini and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English.
The Penn Treebank.
Computa-tional Linguistics 19:313?330.Pollard, Carl and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
The University ofChicago Press and CSLI Publications, Chicago, ILand Stanford, CA.Preiss, Judita.
2003.
Using Grammatical Relations toCompare Parsers.
Proceedings of the European As-sociation for Computational Linguistics 2003.Sagae, Kenji, Yusuke Miyao, Takuya Matsuzaki andJun?ichi Tsujii.
2008.
Challenges in Map-ping of Syntactic Representations for Framework-Independent Parser Evaluation.
Proceedings of theWorkshop on Automated Syntatic Annotations for In-teroperable Language Resources at the 1st Inter-national Conference on Global Interoperability forLanguage Resources, pp.61?68.Steedman, Mark.
2000.
The syntactic process.
MITPress, Cambridge, MA.28
