AMBIGUITY RESOLUTION IN THE HUMAN SYNTACTIC PARSER: AN EXPERIMENTAL STUDYHoward S. KurtzmanDepartment of PsychologyMassachusetts Institute of TechnologyCambridge, MA 02139(This paper presents in summary form some majorpoints of Chapter 3 of Kurtzman, 1984.
)Models of the human syntactic parsing mecha-nism can be classified according to the ways inwhich they operate upon ambiguous input.
Each modeof operation carries particular requirements con-cerning such basic computational characteristics ofthe parser as its storage capacities and the sched-uling of its processes, and so specifying whichmode is actually embodied in human parsing is auseful approach to determining the functional orga-nization of the human parser.
In Section l ,  a pre-liminary taxonomy of parsing models is presented,based upon a consideration of modes of handlingambiguities; and then, in Section 2, psycholinguis-t ic evidence is presented which indicates whattype of model best describes the human parser.I.
Parsing ModelsParsing models can be in i t ia l l y  classified ac-cording to two basic binary features.
One featureis.
whether the model immediately analyzes an ambi-guity, i .e .
,  determines structure for the ambiguousportion of the string as soon as that portion be-gins, or delays the analysis, i .e .
,  determinesstructure only after further material of the stringis received.
The other feature is whether the modelconstructs just a single analysis of the ambiguityat one time, or instead constructs multiple anal-yses in ~ .
The following account developsand compITcates this in i t ia l  classification scheme.Not every type of model described here has actuallybeen proposed in the l iterature.
The purpose hereis to outline the space of possibil it ies so that afreer exploration and clearer evaluation of typescan be made.An Immediate Single Analysis (ISA) model ischaracterized by two properties: (1) An ambiguityis resolved as soon as i t  arises, i .e .
,  on itsf i r s t  word (or morpheme); (2) the analysis thatserves as the resolution of the ambiguity is adoptedwithout consideration of any of the other possibleanalyses.
Typically, such models lack the capabili-ty to store input material in a form which is notcompletely analyzed.
Pure top-down, depth-firstmodels such as classical ATN's (Woods, 1970) areexamples of ISA models.For certain sentences, Frazier & Fodor's (1978)Sausage Machine also behaves like an ISA model.
Inexplaining their Local Association principle, theyclaim that in the f i r s t  stage of parsing, structurecan be bui l t  for only a small number of words at atime.
As a result, in a sentence like "Rose readthe note, the memo and the letter to Mary," the PP"to Mary" is immediately attached into a complex NPwith "the letter" without any consideration of theother possible attachment directly into the VP, thehead of which ("read") is many words back.A Dela_eZay_ed_Single ~ (DSA) model is alsocharacterized by two propertles: (1) When an ambi-guity is reached, no analysis is attempted until acertain amount of further input is received; and (2)when an anlysis is attempted, then the analysis thatserves as the resolution of the ambiguity is adoptedwithout consideration of any other possible analyses( i f  any others are s t i l l  possible--i.e., i f  thestring is s t i l l  ambiguous).
A bottom-up parser isan example of a DSA model.
Another example is Marcus's(1980) Parsifal.
These models must have some sort ofstorage buffer for holding unanalyzed material.I t  is possible for Single Analysis models tocombine Immediate and Delayed determination ofstructure.
Ford, Bresnan, & Kaplan's (1982) versionof a GSP does so in a limited way.
Their Final Ar-guments principle permits a delay in the determina-tion of the attachment of particular constituentsinto the overall structure of the sentence that hasbeen determined at certain points.
(The GSP's Chartis what stores the unattached constituents.)
However,i t  must be noted that during the period in whichthat determination is delayed, other attachment pos-s ib i l i t i es  of the constituent into higher-levelstructures (which are themselves not yet attachedinto the overall sentence structure) are considered.Therefore, i t  is not the case in their model thatthere is a true delay in attempting any analysis.The fundamentally Immediate nature of the GSP re-quires that some attachment possibil ity always betested immedi-ai-e-ly.More authentic combinations of D- and ISA couldbe constructed by modifying bottom-up parsers orParsifal, which are both inherently Delaying, sothat under certain conditions auxil iary proceduresare called which implement Immediate Analysis.
(There is, though, no real motivation at present forsuch modifications.)
I t  can be noted that whilebottom-up mechanisms are logically capable of onlyDelayed Analysis, top-down mechanisms are capable ofeither Immediate or Delayed Analysis.Another type of model uti l izes Delayed ParallelAnalysis (DPA).
In this type, paralle-T-a-6aTysls--\]-s--6-f~an ambiguity is commenced only after some delay481beyond the beginning of the ambiguous portion ofthe string.
Such a model requires a buffer to holdinput material during the delay before i t  is anal-yzed.
Also, any model that allows parallelism re-quires that the parser's representational/storagemedium be capable of supporting and distinguishingbetween multiple analyses of the same input mater-ia l ,  and that the parser contain procedures thateventually oversee a decision of which analysis isto be adopted as resolution of the ambiguity.
Anexample of a DPA parser would be a generallybottom-up arser which was adjusted so that at cer-tain points, perhaps at the ends of sentences orclauses, more than one analysis could be con-structed.
Another example would be a (serious)modification of Parsifal such that when the patternof more than one production rule is matched, all  ofthose rules could be activated.There are actually two sorts of parallelism.One can be called momentary parallelism, in which achoice is made among the possible analyses accordingto some decision procedure immediately--before thenext word is received.
The other sort can be calledstrong parallelism, in which the possible analysescan stay active and be expanded as new input isreceived.
I f  further input is inconsistent with anyof the analyses, then that analysis is dropped.There might also be a limitation on how long paral-lel analyses can be held, with some decision pro-cedure choosing from the remaining possibil it iesonce the limiting point is reached.
( I t  would seemthat some limitation would be required in order toaccount for garden-pathing.
)In addition, in strong parallelism althoughmultiple analyses are all  available, they mights t i l l  be ranked in a preference order.A further type of model is characterized byImmediate Parallel Analysis (IPA), in which al l  ofthe possib~ analyses of an ambiguity are bui ltas soon as the ambiguous portion of the stringbegins.
Frazier & Fodor's (1978) parser is par-t ia l l y  describable as an IPA model with momentaryparallelism.
In explaining their Minimal Attachmentprinciple, they propose that an attempt is made tobuild in parallel al l  the possible available struc-tures, on the f i rs t  word of an ambiguity.
The par-t icular structure that contains the fewest con-necting nodes is the one that is then right awayadopted.Fodor, Bever, & Garrett (1974) proposed an IPAwith strong parallelism.
As soon as an ambiguityarises, the possible analyses are determined inparallel and can stay active until a clause boun-dary is reached, at which point a decision amongthem must be made.There is another design characteristic that aparser might have which has not been considered sofar.
Instead of the parser, after making a singleor parallel analysis of an ambiguity, maintainingthe analysis/es as further input is received, onecan imagine i t  just dropping whatever analysis i thad determined.
This can be called abandonment.Then analysis would be resumed at some later point,determined by some scheduling principles.
Perhapsthe most natural form of a parser which uti l izesabandonment would be an IPA model.
The constructionof more than one analysis for an ambiguity wouldtrigger the parser to throw out the analyses andwait until a later point to attempt analysis anew.Thus, the parser is not forced to make an early de-cision which might turn out to be incorrect, as inmomentary parallelism, nor is i t  forced to carrythe load of multiple analyses, as in strong paral-lelism.
At an implementation level, this abandonmentmight be realizedas mutual inhibition by the seve-ral analyses.Abandonment is also possible in an ISA model.Take, for instance, a generally bottom-up model inwhich constituents can be held free, not yet a t -tached into the overall sentence structure.
A con-straint could be plced on such a model which for-bade such free constituents, forcing the analysesof the constituents to be abandoned i f  they cannotimmediately be f i t  into the overall sentence struc-ture.
(Such a constraint might be implemented as al imit  on storage space for free constituents.
)Then, at some later point, a new analysis of theconstituents and their attachments would be made.Abandonment is also possible, though less in-tu i t ively satisfying, in delayed models.
In thesemodels, there would be a delay in beginning analy-sis, and then another delay as a result of abandon-ment.When analysis is begun again following aban-donment, i t  can proceed according to any of theabove models, though of course some would seem tobe more natural than others.2.
ExperimentPrevious psycholinguistic experiments haveoften used quite indirect methods for tappingparsing processes (e.g., Frazier & Rayner's (1982)measurements of eye-movements during reading andChodorow's (1979) measurements of subjects' recallof time-compressed speech) and have yielded con-f l ict ing results.
The present investigation set outto gather data concerning the determinants andscheduling of ambiguity resolution, through use ofan on-line task that provides readily interpretableresults.Subjects sat in front of a CRT screen and oneach tr ia l  were presented with a series of wordscomprising a sentence, one word at a time, eachword in the center of the screen.
Each word re-mained on the screen for 240 msec and was followedby a 60 msec blank screen.
Presentation of thewords stopped at some point, either within or atthe end of the sentence, and a beep was heard.
Thesubjects' task was to respond, by pressing one oftwo response keys, whether or not the sentence hadbeen completely grammatical up to that point.For experimental items, presentation alwaysstopped before the end of  the sentence, and thesentence was always grammatical.
These experimen-tal sentences contained ambiguities which wereshown to be correctly resolved in only one wayby the last word that was presented.
There were482two versions of each experimental item, which di f -ferred only in the last presented word.
And theselast words of the versions resolved the ambiguity indifferent ways.
An example is shown in (1) (alongwith possible completions of the sentences in paren-theses).
(1) The intel l igent scientist examined with amagnifier \[a\] our (leaves.
)\[b\] was (crazy.
)Any individual subject was presented with only oneversion of an item.
I f  subjects had chosen a par-t icular resolution for the ambiguity before the lastword was presented, i t  was expected that they wouldmake more errors and/or show longer correct responsetimes (RTs) for the version which did not match theresolution that they had chosen than for the versionwhich did match.
(Experimental items were embeddedamong a large number of f i l l e r  items whose presenta-tion stopped at a wide variety of points.
Many ofthese f i l l e rs  also contained ungrammaticalities, ofvarious sorts and in various locations in the sen-tence.
)A wide variety of ambiguities were tested, in-cluding those investigated in previous studies.
Onlya few highlights of the results are presented here,in order simply to i l lustrate the major findings.For items like (Ib), subjects made a large num-ber of errors--about 75%.
This indicates that theywere garden-pathed--just as in one's experience innormal reading of such sentences.
By contrast, foritems like (la), very few errors were made.
Further,the RTs for the correct responses to (la) were sig-nif icantly lower than those to (Ib).
For (la), RTsfeIY in the 450-650 msec range, while for (Ib) theRTs were lO0 to 400 msec higher.
Evidently, subjectshad resolved the ambiguity in (1) before receivingthe last word, and they chose the resolution f i t t ing(la), in which "examined" is a main-clause past-tense verb, rather than the resolution f i t t ing  (Ib),in which i t  is a past participle of a reduced rela-tive clause.However, quite different results were obtainedfor items like (2), which differs from (1) only bythe replacement of "scientist" by "alien".
(2) The intel l igent alien examined with amagnifier \[a\] our (leaves.
)\[b\] was (crazy.
)There was no difference between (2a) and (2b) ineither error rate or RT--both measures fe l l  into thesame low range as those for (la).
That is, subjectswere not garden-pathed on either sentence.
They keptopen both possibil it ies for analysis throughoutpresentation of the sentence.Several conclusions can be drawn from comparingresults of items like (1) and those like (2).
First,i t  i s  possible to delay the resolution of an analy-sis.
Two classes of parsing models can thus be ruledout as descriptions of the overall operations of thehuman system: ISA and IPA-with-momentary-parallelism.Second, the duration of this delay is variable, andtherefore any model in which the point of resolutionfor a particular syntactic structure is invariantis ruled out.
Marcus's Parsifal is an example ofsuch a disconfirmed model.
By the way, this does notmean that there must alw__~be some delay in resolu-tion.
In fact, for items like (1) i t  does appearthe resolution is made immediately upon receptionof "examined".
This is indicated by subjects' per-formance for (3) and (4) matching their performancefor (1) and (2), respectively.
(3) The intel l igent scientist examined\[a\] our (leaves.
)\[b\] was (crazy.
)(4) The intel l igent alien examined\[a\] our (leaves.
)\[b\] was (crazy.
)I t  seems then that the delay can vary from zero toevidently a quite substantial number of words (orconstituents).Third, the duration of the delay is apparentlydue to conceptual, or real-world knowledge, factors.With regard to (1) and (2), one component of ourreal-world knowledge is that scientists are l ikelyto examine something with a magnifier but unlikelyto be examined, but for aliens the likelihoods ofexamining and being examined with a magnifier aremore alike.
Thus, i t  seems that the point at whicha resolution is made is the point at which one ofthe possible meanings of the sentence can be con-f idently judged to be the more plausible one.
So,parsing decisions would be under significant inf lu-ence of coneptual mechanisms.
This f i t s  with workin Kurtzman (1984; Chapter 2), in which a substan-t ia l  amount of evidence is offered for the strongclaim that parsing strategies in the form of prefe-rences for particular structures (e.g., Frazier &Fodor, 1978; Ford et a l .
,  1982; Crain & Steedman,in press) do not exist.
I t  is argued rather thatal l  cases of preference for one resolution of anambiguity over another can be accounted for by amodel in which conceptual mechanisms judge whichpossible resolution of the ambiguity results in thesentence expressing a meaning which better satis-fies expectations for particular conceptual infor ~mation or for general plausibi l i ty.
Such a modelrequires that parallel analyses be presented to theconceptual mechanisms o that i t  may be judgedwhich analysis better meets the expectations.Therefore, an acceptable parsing model must havesome parallel analysis at the time a resolution ismade (which is consistent with some previous psycho-l inguist ic  evidence: Lackner & Garrett, 1973).
Thisrequirement of parallelism then leaves us with thefollowing models as candidates for describing thehuman parser: DPA with either kind of parallelism,IPA-with-strong-parallelism, or Abandonment-with-parallel-reanalysis.
(Abandonment might work in (2)by abandoning analysis upon the attempt at analysisof "examined" and then commencing re-analysis either(a) at a point determined by some internal schedule,or (b) upon a signal from conceptual mechanismsthat the conceptual content of the syntacticallyunanalyzed words was great enough to support a con-fident resolution decision.
)In contrast to the other remaining models,483IPA-with-strong-parallelism posits that input mate-rial is at all times analyzed.
A look at resultsfor other stimuli suggests that this might be thecase.
In a task similar to the present one, Crain& Steedman (in press) have shown that for itemssuch as (5), comprised of more than one sentence,the f i r s t  sentences (5a or 5b) can bias the per-ceiver towards one or the other resolution in thelast sentence (5c or 5d), which contains an ambig-uous "that"-clause (complement vs.
relative).
(5a) RELATIVE-BIASING CONTEXTA psychologist was counseling two marriedcouples.
One of the couples was fighting withhim but the other one was nice to him.
(5b) COMPLEMENT-BIASING CONTEXTA psychologist was counseling a married couple.One member of the pair was fighting with himbut the other one was nice to him.
(5c) RELATIVE SENTENCEThe psychologist old the wife that he washaving trouble with to leave her husband.
(5d) COMPLEMENT SENTENCEThe psychologist old the wife that he washaving trouble with her husband.So, for example, (5c) preceded by (Sa) is processedsmoothly, while (5c) preceded by (Sb) results ingarden-pathing at the point of disambiguation (theword "to").
In the present experiment, sentencesin which the "that"-clause was disambiguated immedi-ately following the beginning of the clause (5eor 5f) were presented following the contexts of (5a)or (5b).
(Se) RELATIVE SENTENCEThe psychologist old the wife thatwas (yelling to shut up.
)(Sf) COMPLEMENT SENTENCEThe psychologist old the wife thatto (yell was not constructive..)It  turned out that context had no effect on perfor-mance for this type of item.
Rather, subjects per-formed somewhat more poorly when the "that"-clausewas disambiguated as a relative (5e), showing about20% errors and sometimes elevated RTs, as comparedwith the complement disambiguation in (5f), whichshowed low RTs and practically no errors.
The effectdid not differ in strength between the two contexts.These results along with those of Crain & Steedmanshow that in i t ia l l y  the complement resolution ispreferred but that later this preference can beoverturned in favor of the relative resolution i fthat is what best f i t s  the context.
Now, there isno reason to believe that subjects are actuallygarden-pathed when they end up adopting the relativeresolution.
Note that there is no conscious experi-ence of garden-pathing, and that the error and RTeffects here are much weaker than for classicalgarden-pathing items like (1).
I t  seems more l ikelythat both possible analyses of "that" have beendetermined but that one--as a complementizer--hasbeen in i t ia l l y  ranked higher and so is in i t ia l l ymore accessible.
In this speeded task, i t  would beexpected that the less accessible relative pronounanalysis of "that" would sometimes be missed--resul-ting in incorrect responses for (5e)--or take longerto achieve.
Now, i f  "that" had simply not been ana-lyzed at all by the time of the presentation of thelast word, as in a DPA or Abandonment model, therewould be l i t t le  reason to expect that one analysisof i t  should cause more errors than the other.So, we may tentatively conclude that IPA-with-strong-parallelism describes the human parser'soperations for at least certain types of structures.Similar results with other sorts of structures areconsistent with this claim.
This does not rule outthe possibi l i ty, however, that the human parser isa hybrid, ut i l i z ing delay or abandonment in someother circumstances.Why is the complementizer analysis immediatelypreferred for "that"?
In these items all of themain verbs of the ambiguous entences had meaningswhich involved some notion of communication of amessage from one party to another (e.g., "told","taught", "reminded").
In Kurtzman (1984) i t  isargued that such verbs generate strong expectationsfor conceptual information about the nature of themessage that is communicated.
The complement reso-lution of the "that"-clause permits the clause todirectly express this expected information, and soi t  would be preferred over the relative resolution,which generally would not result in expression ofthe information.
I t  is also possible that such aconceptually-based preference gets encoded as ahigher ranking for the verbs' particular lexicalrepresentations which subcategorize for the com-plement (cf.
Ford et a l .
,  1982).REFERENCESChodorow, M.S.
Time-compressed speech and the studyof lexical and syntactic processing.
In W.E.Cooper & E.C.T.
Walker (Eds.
), Sentence proces-sing.
Hillsdale, NJ: Erlbaum, l~Crain, S. & Steedman, M. On not being led up thegarden path: The use of context by the psycho-logical parser.
In D. Dowty, L. Kartunnen, & A.Zwicky (Eds.
), Natural language processing.
NY:Cambridge Univers1~ress,  in press.Fodor, J.A., Bever, T.G., & Garrett, M.F.
The psy-chology o__f_flanguage.
NY: McGraw-Hill, 1974.Ford, M., Bresnan, J., & Kaplan, R.M.
A competence-based theory of syntactic closure.
In J.
Bresnan(Ed.
), The mental representation of grammaticalrelation-s~.
~dge,  MA: MIT Pre~, 1982.Frazier, L. & Fodor, J.D.
The sausage machine: Anew two-stage parsing model.
Cognition, 1978, 6,291-325.Frazier, L. & Rayner, K. Making and correcting er-rors during sentence comprehension: Eye movementsin the analysis of structurally ambiguous en-tences.
Cognitive Psychology, 1982, 14, 178-210.484Kurtzman, H.S.
Studies in syntactic ambiguity reso-lution.
Ph.D. Dissertation, MIT, 1984.
(Availablefrom author in autumn, 1984, at School of SocialSciences, Univ.
of Cal i fornia, I rvine, CA 92664.
)Lackner, J.R. & Garrett, M.F.
Resolving ambiguity:Effects of biasing context in the unattended ear.Cognition, 1973, I ,  359-372.Marcus, M. A theory o_f_f syntactic recognition fornatural language.
Cambridge, MA: MIT Press, 1980.Woods, W.A.
Transition network grammars for natu-ral language analysis.
Communications of ACM,1970, 13, 591-602.485
