Generating a Coherent Text Describing aTraffic SceneHans- Joach im Nova lPFachbere ich Informat ik ,  Un ivers i tgt  HamburgD-2000 Hamburg  13, West -GermanyAbst rac tIf a system that embodies a reference semanl;ic for motion verbs and prepo-sitions is to generate a coherent text describing the recognized motions itneeds it decision procedure ~,o select Ihe events.
In NAOS event, selectionis done by use of a specialization hierarchy of mellon verbs.
The st.rat-egy of ant ic ipated visual izat ion is used tbr the selection of optionaldeep cases, qJhe system exhibits low-level strategies which are based onverbinherent, properties that allow the generation of a coherent descriptiveI;ext.t I~t roduct lonThis contribution focuses on the verbalization component of t;heNAOS system (the acronym stands for NAtura l  language descrip-tion of Object movements in a traffic Scene).
NAOS is designedto explore the border area between computer vision and naturallanguage processing, especially the realm of recognizing and ver--balizing mot ion  concepts  in image sequences.NAOS goes  all the way h'om a representat ion of a real~worldtraffic scene to a natural language text describing the scene.The representation f the scene basically consists of its geometry(theretbre called geometric scene description (GSD))+ ~lk) giw~ animpression of the representation a GSD contains for each frame ofthe image sequence:o instance of t imeo visible objectso v iewpo in to i l luminationo 31) shapeo surface characteristics (color)o classo identity31) position and orientation in each flame(fl)r a detailed description ,,f the GSD see \[t6\]).For event recognition we use event models (\[18\], \[191) whichdefine a reference semantic for motion verbs.
In t, he current im-plementation of the NAOS system about 35 motion verbs and (,heprepositions bes ide,  1)y, in~fronl;oof, near,  and on may />e reco-gnized by matching the event models against he representation fthe scene.In this paper we are neither concerned with the representation ft.he underlying scene data nor with the question of event recognitionas tt ...... issues haw, bee,, put,list,ed elsewhere (see \[10\] [171 \[20\]).Instead, we fi)cns on the generation of a coherent ;exl, describingthe irnage sequel'lee.In the nexl, section we brielly describe the represent, ation of therecognized events which fi)rm the initial data for the verbalizatioueotllpo+lerlt, tl)hen I,}+e overall strategy fnr (:on+p(ming a coher(!lltdescription is discussed.
The fblk)wing section i,ltrodnces a part, ialsolution to the selection problem which is based on the strategyof anticipated visualization.
Fourth, we show how some linguisticchoiees like passlve~ res t r i c t ive  re lat ive  e lanses,  and negat ionI thank B. Neumamt who contributed several ideas to this article.are natural consequences of the task of generating unambiguousreferring expressions.
In the last section we relate our researchwith current work on language generation.\ ] \ [n i t ia J~  \ ]DataVerbalization starts when event reeognil, ion has been aclfiew~d.Besides complex event, s like over ta lm and turn  off, other predi--cares like in- f ront-of ,  I)esi(les, move, etc.
are also inst, antiated.Pleh)w is a section of the database after event recognition has takenplace (the original entries are ill German).1: (MOVE PERSONI  0 40)2: (WAI,K PERSONI  0 40)3: (RECE1)E PERSON I FBI 20 40)4: (OWmTAKE BMW~ VWI 00:12) (~,~ 3~,))5: (MOVE BMW1 l0 40)6: ( IN-FRONT-OF VWl TRAFFIC-LKHITI  27 32)"\]'he above entries are instantiations of event models containingsymbolic identifiers for scene objects (e.g.
BMWI).
Tile last twoelements of an instantiation denote the start and end time of theevent.We use the following notations to denote the event time:~.
( .
.
.
.
rb Te)~.
( .
.
.
.
( r< , , ,  Tb .
.
.
.  )
( ' r~ , , , , ,  r ,  ...... ))a.
(....(rb,,.,+ Tb ...... ) "r.)4.
(....rb re  .
.
.
.
.
.
))Tb, Te denote start and end t, ime of an event.
The first notationis used for (h t rat lve  events (e.g.
move).
A durat lve  event, is alsovalid for each subinterval of (Tb Te).The secolld t+oi, ation is tlsed for i lO\] l -d l l rat ive evelltl;(e.g.
over take) .
Start and end time of such an event are Imthrestrk:ted by lower and upper bounds.
Note, that nmt .
-dnrat lveevents are not wdid for each subinterval of the event boundarie~LThe third notation b; used for re.
(mltafive vents (e.g.
stop) .The start t ime ofa resn l ta t lve  vent lies within an interwd whereasthe end time is a time--point.Finally, the last notation is used for inchoat lve  events(e.g.
s ta r t  mov ing ,  corresponding to the German verb loafah-.ten) .  )
!nchoat ive vents have a well defined start t ime whereasthe end time lies within an interval.For the task of generating a coherent description of a tra\[ficscene NAOS first instantiates all event models and predicates whichmay be instantiated using the scene data.
This leads to the wellknown selection problem of natural language generation.
For oneobject, timre may be many instantiations with different ime inter-vals, hence the task of the verbalization component, o choose whatto say.
In the next section we discuss the theoretical backgroundon which our verbalization component is based.3 ' Iheoretmal BackgroundIn general, language is not generated per se but is Mways in.-tended for a hearer.
Furthermore, language is used to fulfil certain570goals of the speaker which may sometimes imply be to inform thehearer about certain facts.In NAOS the generatioo f a deseriptiou of the underlying imagesequence aims at diminishing the discrepancy between tim :~ystem'sknowledge of the scene and the heater's knowledge (the same mo-t ivation is nsed in Davcy's program \[61).
Concernig the hearer wemake the following assumptions:1.
S /he knows tide static baekgrmmd of the scene, i.e.
the streets,houses, traffic lights, etc.2.
S/he did not utter specific interests except: Describe ~hescel\]e!A description may be the result of snch diverse speech actsaa !N I?ORM,  PROMISE+ PERSUADE,  or CONVINCE.NAOS only generates the speech act INFORM.qb inform a hearer abotlL something means to tell her/his1 so-mething s/he has not known before, somethint, that is tr,le andnew.
In NAOS the definition of true utt, erances buiht~+ on the si-tuat ional  semantics of Barwise and Perry \[31.
'rhcy mtderstand t, heIueanillg Of an utterance as a relatiou t)etwcetl the t it\[clause alldthe described sitmation.
The interpretatiou of an utLerance by ahearer usually consists of a set, of possible situations with a mea-ning relation I;o the ut, terance.
We now define an uta:rance to betrue if the set of possible situations cooJ~ains the actual ly occnrredsituation.The requirement to generate true utterances has two consequell-ces for our verbalization component, l,'irst, the verbalization pro-cess nnlst take the bearer's lneanillg relations into account.
This co-incides with the eommtmication rule to tune one's utterances to theheater 's  comprehension ability.
Second, assumiug that the speakerhas tide same meatnng relations as the hearer, the speaker can itlt-t ic ipate the hearer's interpretation of an IILteraaee, ie.
the possibles i tuat ions implied solely by the utterance can be generated withoutknowledge of the actual situation.
In the case of scene descriptionsthese situations are equivalenl; to the heater's visualization of anunknown scene.An utteraace must be new to tile hearer in order I,o inform him.In the context of situational semantics we define an utterance tobe new if its interpretation restricts the set of possible situationsimplied by previous utterances.
Thus new information additionallyspecifies described situations.The task of a verbalization component is to choose utterancessuch that they inform in the above sense.
Therefore it is neces-sary to anticipate the hearer's understanding for judging whethera planned utterance carries new information,The general principle tbr hearer simulation is depicted in figure1.U1 TERANCE .
.
.
.
.
.
.
.
.
.
.
.
> UTTERANCECASE FRAMES CASE FffAMtST~_ _ DEEP CASE- -~ I"-- - SEMAN f lCS-- - -~EVENTS EVEN\[ST,5==: EVENT i NODELS =;~GEOMETRIC SCENE VISUAL\[ZEU SCh~\[DESCRI PT \] ON DESCR \[ P \[ IONSUEAKER iIERREUFigure l: l learersimulationOn the side of the speaker the event recognition process leads byuse of event models to instantiated event models (called events inthe figure).
A lirst seleclfion process chooses amoug the instantiati-otis those which are to be verbalized.
As event models are associa-ted with verbs the appropriat, c case frame of the verb is available.A second selection process now chooses among the optional deepcases of the verb.
This is where the deep case semantics comesinto play.
If, for instance, it it+ decided that a locative expressionshould be generated it is necessary to know how the location of anobject may be expressed in natural language as in the geometricscene descriptiou the location of an object is given by its x, y, andz coordinates.
'l+}le deep ease setnanties also eoilt~Lius informationabout the prepositions which may be used for expressing a specificdeep ease.Assuming that the hearer has the same meaning relations as thespeaker he basically can use the speaker's processes in reverse orderand reconstruct the underlying case fi'ame froro I.he utterance andthns build a visualized scene description.Note, however, that we agree with Olsou \[21\] that the verbali-zation of a visual ewmt always leads to a loss of infkwmation.
In ourcam~, for instance, we ca\[lllOt }lSSlli'Ile /~llat the  hearer knows the x,y, aud z coordinates of ,an object when he hears tim phrase i~l \[fonto{' the del;arf, lne,qt o# comptJter science.
5;llch a \[)hl'ase \[~elleraLesa set of coordinates delining the regi(m which corresponds t~ thepreposition in-.front+of The act.a\] Iocat, iun ++I' the object whichgave ri~+e to t, he geaeratiotl off t,he pln'ase lies somewhere within thatregion.
Preset,tly, hearer modeling sl,~>l)+; at  I,ho level of ease framesaml the visualized scene ia am.ieipaLed (see xect.ion ,1.2).As shown in figure I the case frame of a verb plays a cetttralrole in our verbalization compoaent.
We adopt the view of Fillmoreexpressed in his scelles-+and-fralnes s lnallLic \[71 I;ll+tt case  framesrelate sceues to natural language xpressions.4 The ~3election P rob lemUsually this ln'oblem is divided intc~ the subtasks of deeidingwhat  to mxy and how t,.
say it,.
As mentioned above NAOS usestwo selection processes.
First, it selects amoug the instantiatedevents and second, it selects among the optional deep cases of theverb associated with the choseu evellt.
The first selection processcorresponds to deciding what to say and the second one determineslargely how to say it as will be shown later.The selection processes are based on the representation of theease semantics of an event model and on a specialization hierarchyof the verbs.
Below is the representation of the case semantics fortile event model i iberho len  (over take) .Agent-RestL : VEIti(0LEDeep--canen : (VERB UEBERHflL)(UEBERI10LEN *SBJ1 *0B J2 *T1 *T2)Obligatory : (AGENT AGT-..EXP)(ItEF AgT-EXP *OBJI)(TENSE TNS.,I~XP)(TIME-REF 'fNS-EXP *T1 *T2)(OBJECTIVE SBJ F, XP)(REF OBJ-EXP *ON J2)Optional : (LOCA'rIVE LOO--EXP)(LOC-'N.EF LUC-EXP *SBJ1 *Ti *'1'2)Combilm~ionlJ : NILLoc-prep~3: (All AUI,' BEI IIINTER I~l NEITENUEI\]ER UNTF, R VOR Z~,'llSCttl;;tOThe first slot specifies the agent restriction.
The deep<asus slot571contains first the verb stem of iiberholen as needed by the gene-ration component and second the formal notation for an instantia-tion.
The obligatory cases must be generated but may be omittedin the surface string in case of elliptic utterances whereas optio-nal deep cases need not be generated at all.
In the combinationsslot it is represented which deep cases may be generated together(e.g.
for the verb fahren (drive) it is not allowed to generate asingle SOURCE but instead SOURCE and GOAL must be genera-ted).
The Lot-preps lot specifies the prepositions which may beused with the verb iiberholen to generate locative expressions.The case descriptions in the obligatory and optional slots consistof two parts: a declaration of an identifier for the case expression onthe language side, and a predicate (in general a list of predicates)relating the case expression to the scene data.
The most importantpredicates are REF, TIME-REF, and LOC-REF.REF generates referring phrases for internal object descriptorslike BMW1.
TIME-REF generates the tense of the verb.
As de-scriptions are usually given in present ense, presently TIME-REFonly generates this tensc.
LOC-REF relates the abstract locationof the object as given by its coordinates to a natural anguage x-pression for a reference object.
Note, that REF has to be used togenerate a referring phrase for the reference object.
Consider thesixth entry of the database in section 2.
The instantiation onlycontains internal identifiers for objects, like traflic-lightl, for whichreferring phrases have to be generated (see section 4 for furtherdetails on REF).In NAOS we use a specialization hierarchy for motion verbs.This hierarchy is pragmatically motivated and is rooted in situa-tional semantics.
It is no hierarchy of motion concepts as the oneproposed in \[23\].
It connects general verbs witb more special ones.A situation which may be described using a special verb implies theapplication of all more general verbs Take for instance the verbi iberholen (overtake).
\[t implies the use of the more generalverbs vorueberfahren~ vorl)nifahren (drive past), passieren(pass), naehern-r (approach), entfernen-r (recede), fahren(drive, move), and bewegen-r (move).It shonld be intuitively plausible that such a hierarchy is alsoused for event recognition.
If, for instance, no naehern-r  (ap-proach) can be instantiated the more special events need not betested.4.1 Event  Select ionIn NAOS the overall strategy for generating a descriptive textis as follows:* Group all moving objects according to their classmembership;?
For each object in each group describe the motions of theobject for the time interval during which it was visible in thescene,Event selection for an object is done according to the followingalgorithm:1.
Collect all events in the interval where the object was visibleand where the object was the agent;2. determine for each timepoint during the object's visibility themost special event of the above collected ones;3. if two events have the same specificity then either take theone which started earlier and has the same or longer durationas the other one or take the one with longer duration;4. put the selected events on the verbalization list of the objectin temporally consecutive order.Consider the following example.
All events which were foundfor PERSON1 are:572(RECEDE PERSON1 FBI 20 40)(ENTFERNEN-R PERSDI\]I FDI 20 40)(}/ALK PERSONI 0 40) (OEHEI~ PERSONI 0 40)(MOVE PERSONI O 40) (BE~//EGEN-R PERSOIll 0 40)The above algorithm leads by use of the specialization hierarchyto the following verbalization list for PERSON1:(((~IALK PERSOI~I 0 40) (0 20))((RECEDE PERSON1 FBI 20 40) (20 40)))(The last entry in parenthesis of each selected event denotes theinterval in which the event was the most special one.
)4.2 Select ion of  Opt iona l  Deep CasesThis selection process is our first implementation f the strategyof anticipated visualization.
The underlying question is: Which op-tional deep cases should be selected to restrict the hearer's possibi-lities o f  placing the trajectory of  an object  in his internal model  o fthe stat ic  background of  the scene?In NAOS the selection algorithm answering the above questionis rather straightforward.
It is based on the manner of action of theverb, the verbtype, and the heater's knowledge.
The algorithm isgraphically represented in figure 2.EVENTTYPENON-DURATIVE, INCHOATIVEDURATIVETl,,o = EB A T,,,a = SETb,~ = SB ^ T,,,d ?~ SET~,~ ~- S B A T,,d = S EVERBTYPEDIRLOCREDDIR,LOCREDREDDIR, STATLOCSTATDIR, REOLOCSTATDIRLOCREDDEEP CASESLOCATIVE?DIRECTION?, LOCATIVE?DIRECTION?LOCATIVE?NILNILLOCATIVE?DIRECTION?, LOCATIVE?LOCATIVE?NILDIRECTION?LOCATIVE?LOCATIVE?SOURCE?, DIRECTION?NILRED NILT~,~ ~ 8B ^ T,,a ~ SE  DIR, STAT LOCATIVE?LOC SOURCE?, GOAL7Figure 2: Selection of Deep CasesThe abbreviations denote: Tb~, Ten,t: start, end time of theevent; SB, SE: scene begin and scene end; I)IR, LOC, STAT, RED:directional (turn off, return), locomotion (walk, overtake), and sta-tic (stand, wait) verbs, finally verbs whose recognition implies re-ference objects (reach s.
th., arrive at).The figure has to be read as follows.
If an inchoative ventlike losfahren (start moving) has to be verbalized which hasthe verbtype locomotion, then choose direction?
and locative?as deep cases.
The question mark generally means, look into thepartnermodel Lo see whether this deep case has already been ge-nerated fi)r another event.
If so, determine by use of the object'sactual ocation (represnnted in the scene representation) whether itis still valid.
If this is the case don't generate a uatural anguageexpression for this deep case, otherwise do.Presently the partnermodel contains information about the sta-tic background of the scene and about what has been said so farin the same relational notation as was shown for instantiations insection 2.
It is being updated when an event is verbalized.Note, that for durative vents the decision is based on whetherthe start and end time of the event coincide with the beginning orending of the image sequence.
Consider the first case for durativeevents as given in figure 2.
Right from the beginning of the sequencethere is a car moving along a street until the sequence ends.
In sucha case it is not possible to verbalize a source as the object may havestarted its motion anywhere.
To restrict he hearer's visualization,direction and locative cases are verbalized, leading to a sentencelike: The car moves on Schliiterstreet in direction of HaHerplace.Verbalizing a direction when the static background is known re-stricts the trajectory to being on one side of the road.
Basically,our direction case is a goal or source ease where only two preposi-tional phrases are allowed, the German phrases in Richtung andaus Richtung (in direction~ from direction).
These phrasesdo not imply that the motion ends at the goal location as do mostprepositional phrases in German which have to be in accusative sur-face case to denote a goal.
The English language is in this respectinherently ambiguous.
In the sentence The car moves behind thetruck, the phrase behind the truck may denote a locative or goaldeep case.
In German these eases arc distinguished at the surface.\["or locative the above sentence translates to Des Aitto f~hrt hinterdem LKW,  for the goal case, it translates to Des Auto f~hrt hinterden LKW.We have to distinguish different verbtypes as e.g.
the meaningof a directional phrase changes with the verl)type.
Consider thesentences The car moves in direction of Hallerplace versus The carstands in direction of l\[allerplace (in German both sentences arcwell formed).
The first sentence denotes the direction of the mo-tion whereas the second one denotes the orientation of I, hc car.We thns distinguish between static (STAT) and h)eomotion (LOC)verbs.
The third verbtype, directional (I)IR), is used for verbs witha strong directional component like umkehren (return), abbie-gen (turn off), etc.
As they already imply a certain direction theadditional verbalization of a direction using a prepositional phrasedoes usually not lead to acceptable sentences.
The fourth type(REO) is used tbr verbs like erreichen (reach s.
th.)
having anobligatory locative case.The main result to note here is that the selection processes arelow-level and verboriented.
The only higher level goal is to informthe hearer and to convey as ranch information about an event aspossible.
In the next section we show by differem; verbalizations ofthe same scene how rather complex syntactic structures arise.5 Generat ionThe general scheme for the generation process is as follows:1.
Sort the objects according to their classmembership, vehiclesfirst, then persons;2. in the above partial order sort the objects according to theirtime of occurrence in the scene, earliest first;3. do for all elements in each verbalization list of each object(a) if the current event has a precedent and its event timeis included in the precedent's, begin the sentence withdabei (in the meantime); go to (c);(b) if the current event has a precedent and its event timeoverlaps the precedent's, begin the sentence with unter-dessen (approx, in the meantime); go to (c);(c) determine the optional deep cases and build a simpledeclarative sentence by using all chosen deep cases andapplying the deep case semantics.Two temporally consecutive events are not verbalized using a tem-poral adverb as in the cases of inclusion and overlapping.
This isdue to the fact that from the linear order of the sentences the hearerusually infers consecutivity.The result of the above algorithm is a formal representation fthe surface sentence which, rougidy, contains the w~rb's tem, gemlsverbi, modality, and person, all deep cases in random order, and allstems of the \[exical entries which appear in the surface sentence.This representation is taken as input by the system SUTRA (forfurther details on the formal represeutation a d the SUTRA systemsee \[41) which then generates a correctly inflected German sentence.Below is an example of the output of NAOS.18.
,ausgabe textDIE SZENE EN'rHAELT VIER BEWEGTE OBJEKTE: DREIPKWS UND EINEN FUSSGAENGER.The scene consists of four moving objects: three vehicles and a pede-strian.EIN GRUENER VW NAEHERT SICtt DEM GROSSENFUSSGAENGER AUS RICHTUNG tIALLERPLATZ.
ER FAE-IIRT AUF DER SCHLUETERSTRASSE.A green VW approaches the tall pedestrian from the direction of flal-terplaee.
It drives on Schlseterstreet.EIN GELBER VW FAEHRT VON DER ALTEN POST VORDIE AMPEL.
WAEHREN1)I)ESSEN ENTFERNT ER SICH VONDEM GRUENEN VW.A yellow VW drives from the old postoftice to the tra~c light, h~ themeantime it recedes from the green VW.EIN SCHWARZER BMW FAEHRT IN RICHTUNG ttAL-LERPLATZ.
DABEI UEBERIIOLT ER DEN GELBEN VW VORDEM I"ACIIBERI,\]ICI\[I INFORMATIK, DER SCltWARZE BMWENTFERNT S1CI1 VON I)EM GRUENEN VW.A black BMWdrives in the direction of Hallerpiace, During this timeit overtakes the yellow VW in front of the department of computer science.The black BMW recedes from the green VW.DER GROSSE FUSSGAENGER GEHT IN RICHTUNGDAMMTOR AUF I)EM SUEDLICIIEN FUSSWEG WEST-LICH DER SCHLUETERSTRASSE.
WAEHRFNDDESSEN ENT-FERNT ER SICH VON DEM FACIIBEREICH INFORMATIK.The tall pedestrian walks hJ the direction of Dammtnr on the southernsidewalk west of Sehlseterstreet.
h~ the meantime he recedes from thedepartment of compnter science.19.
,logoutThe first sentence above is a standard one having the samestructure for all different scenes.
The remaining four paragraphsare motion descriptions for the tbur moving objects.We now discuss tep (c) of the above algorithm in more detailas it covers ome interesting phenomena.Consider the third paragraph describing the motions of the yel-low VW.
The verbalization list for this object is:(((DRIVE VW1 10 20) (10 25))((RECEDE VW1 ~2 25 32) (25 32)))The beginning (SB) and ending of the sequence (SE) lie at points0 and 40, respectively.
According to the selection algorithm (figure3) a SOURCE should be verbalized for a durative event with theabove event ime if the verbtype is LOC.
The generation algorithmchecks whether the chosen optional cases are allowed for the verb,if so, it is further checked whether the combinations are allowed.As a SOURCE may not be generated alone for a fahren (drive,move) event, SOURCE and GOAL are generated.The fourth paragraph shows the outcome of a deep case selectionin which the chosen case is not allowed for the verb.
The verbaliza-tion llst for the black BMW contains only i lberholen (overtake)and entfernen-r (recede).
(((OVERTAKE BMWI VWI (10 12)(12 32) (10 32))((RECEDE Bl~qt ~/2 20 40) (32 40)))According to event- and verhtype D IRECT ION is chosen as theappropriate deep case.
As this case may not be used with the verbovertake two sentences are generated, one describing the direction573of the motion and the other one describing tbe specific event.
Thesecond sentence begins with a temporal advert) specifying that bothmotions occur at the same time.
In order to generate the two sen-tences first the classmembership of the agent of the verb which maynot take the chosen deep case is determined.
Then the speeializa-tionhierarehy is used to go up to either fahren  (dr iv% move)  orgnhen (walk)  as those verbs may take any deep case.
Then thesentences are generated.Consider the following verbalization list:(((OVERTAKE BI~WI VW1 (0 8) (12 18) ( 0 18))((DRIVE BI'~I 0 40) (18 40)) )Assuming the direction and location of the motion to be thesame as before the algorithm presented so fat" would generate Ablack BMW drives in the direction of Hallerplace.
During this timeit overtakes the yellow VW in front of the department of computerscience.
The black BMW drives.According to the deep ease selection algorithm a DIRECTIONand LOCATIVE should be generated for the second event above.As both cases have already been generated with the first event andare still valid the sentence The black BMW drives is not genera-ted because before generating a sentence it is checked whether theintbrmation is already known to the partner.5 .1 Refer r ing  PhrasesIn this section some aspects of the referring phrase generatorare discussed.
As can be seen from the example text objects arecharacterized by their properties, introdueed with indefinite nounphrases when they are not single representatives of a class and theymay also be pronominalized to add to the coherence of the text.Therefore we use standard techniques as e.g.
described in \[8\], \[9\].We want to stress one aspect of our referring phrase generator,namely its capability to generate restrictive relative clauses withmotion verbs.
As it may be easily the ease that a scene containstwo objects with similar properties the task arises to distinguishthem and generate unequivocal referring expressions.It is an interesting fact, that, we have several options to copewith this problem which each have their consequences.One option is to adopt McDonald's scheme of generation wi-thout precisely knowing what to say next \[13\].
According to thisscheme two similar objects are characterized in the following wayin NAOS.
When the first one is introduced it is characterized byit's properties e.g.
a yellow VW.
When the second one has to beintroduced, REF notices that a yellow VW is already known to thepartner and generates the phrase another yellow VW.
It starts get-t ing interesting in subsequent reference.
The objects are then cha-racterized by the events in which they were involved earlier whetheras agent or in another ole.
This leads to referring phrases like theyellow VW, which receded from the pedestrian or the yellow VW,which has been overtaken.
Note, how passive relative clauses arisenatural ly from the task of generating referring phrases in this para-digm.
The same is also true for negation.
Consider the case wherethe first yellow VW, say VWI,  has passed  an object and the secondyellow VW, say VW2, has over taken  an object and both event,sare already known to the partner.
If REF has to generate againa referring phrase for VWI  it notices that pass  is a more generalverb than over take  and may thus also be applied for the overtakeevent.
It therefore generates the phrase the yellow VW, which hasnot overtaken the other object to distinguish it unequivocally fromVW2,Be low is an example  of this strategy in a texL for the same sceneas above.
The difference to the th'st scene is that we replaced thegreen VW by a yellow one.10.
,ausgabe text;574DIE SZENE ENTItAI'~LT VIER BEWIdGTE OBJEKTE:  I)RE1PKWS UND EINEN FUSS(~AENGER.The scene consists of four moving objects: three vehicles and a pede..s~rian.EIN GELBER VW NAEIIERT SICIt DEM GROSSEN FUSS-GAENGER AUS RICI ITUNG tIALI,ERPI~ATZ.
ER FAEHRTAUF I)ER SCHLUETERSTRASSE.A yellow VW approaches the tall pedestrian from the direction offlallerplace.
It drives on 3chlueterstreet.EIN ANI)ERER GELBER VW FAEHRT VON DER AUPENPOST VOR DIE AMPEL.
WAEtIRENDDESSEN ENTFFRNTER S1Ctl VON DEM GIdLBEN VW, DER SICIt I)EM GROSSENFUSSGAENGER GENAEHERT HAT.Another yellow VW drives fi'om the old post office to the tralllc light.\[n the meantime it recedes from the yellow VW which approached the tallpedestrian.\[!
;IN SCHWARZER BMW FAEllRT IN R1CHTUNG IIALLER-PI,ATZ.
I)ABEI UEBEtHIOLT ER DEN ANDEREN CELBENVW, DF, R SICII VON 1)EM CELP, I~N VW ENTFERNT flAT,VOR DFM FACIIBFI-H~,ICtt INI,'OllMA'I'IK.
DER SCHWARZEBMW ENTI,'ERNT SICIt VON DEM GI!H,BI~;N VW, DEI{ NICI ITUEBERIIOILT WORI)F,N IST.A black BMW drives in direction of Ifallerphtce.
Dewing this time itovertakes the other VW which receded fronl the yellow VW, is ti'oet ofthe department of computer science.
Tile black BMW recedes fl'om theyellow VW which was not ow~rtaken.I)EI{ GROSSE FUSS(.~AEN(\]Ie, R ( IEI IT IN R1.CIITUNGI )AMMTOR AUF I)I,,M SUEI)LICHI,2N I,'USSWEG WEST-LICH DER SCIILUI'~TIt',I{STRASSE.
WAIi;III{ENDI)FSSI,;N ENT-FERNT El1.
SICH VON I)FM FACIIBh'J~.E\[Clt INFORMATIK.
"/'lie tall pedestrian walks in direction of Dammtor on the southernsidewalk west of Schlueterstreet.
\[n the meantime he recedes from thedepartment of computer science.11.
,logoutThe consequences of this first option are rather complex syn-tactic structures whieh are not inotivated by higher level stylisl.icchoices.1,el us now look at a second opt, ion which has also been imple-mented.
Experience with the above algorithm for dill%rent scenesshowed, that if more than two similar objects are in a scene therestrictive relative clauses become hardly mlderstandable.
We ~,husdetermine how many similar objects there are in the scene beforewe start the generation process.
If there are more than two, REFgenerates names for them and introduces them as e.g.
the first yel-low VW, the second yellow VW and so on and uses these phrasesin subsequent references.
An example of this strategy would looklike the first example text where the different vehicles are nanmdl, he first ..., the second .... Tbe rest of the text would remain thesame.Taking this option implies leaving McDonald's scheme and ap-proaching to a planning paradigm.It should be noted here that there is a third optimt which hashardly been investigated, namely to switch frmn contextual to co-textual  reference as in phrases like the VW I mentioned last.
Weneed filrther research efore we can use such techniques effectively.6 Conc lus ion  and  Re la ted  ResearchWe have proposed the scheme of anticipated visualization togenerate coherent exts describing reaL-wnrld events (visual data).The selection algorithms are based on low-level, verbinherent pro.-perties, and on a pragmatically motivated verb hierarchy.
'lk~getherwith t, he verbalization component he NAOS system is now fullyoperational from event, recognition to text generation in the do-main of trafl'ie scenes.
As this domain is rich enough to still posea 1ol; of problems I,his opens up l, he ol)portunity t,o inl;egral;e hig-her level sl, rabelJies for e.g.
combining sentences, selecting evengs,generating deie~ie expressions, el;e.The main difference between NAOS and other systems for lan-guage generation is that, we approach the verbalization problemfrom the visual side.
and thus are led to use basic selection algo-ril;hms.
Other systems like TAI,ESI'iN \[151, KI)S \[12J, TEXT \[1,t,KAMI' \[l\], and I1AM-ANS \[1()} start their proeessi,g wibh languagewhereas NAOS starts with images.
In close emmection to our re-sea,<, is U,e wo,'k ,,f \[21, 1~,4}, 1231, \[?
?,\], ~,.,,d \[,% 'rhe fi,.st iV)u,.authors deal wilJl questions of moqon recognition and with a re-.ferellcc senlant, ic for irlOt;iOrl verbs })Lit ~Ll'e IIot.
CoLleerlled wit}l i, exLgeneral~ion.
They showed that case frames can Iw used to generatesingle utl,erancem Conklin and Ivh:l)onald use the notion of salienceto deal wil, h ghe seleel,ion problem in the task of describing a singleimage of a nal)ural oul, door scene.TALESPIN exemplifies ~ha~; plans and goals of an actor mayform the underlying sl, rueture of narratives and may I;hus be mo-tivation for l;ext generation, hi KI)S a represental, ion of wha~ todo in ea~(., of fire a la rm is transformed into a natural language.text.
As the initial representa1,ion already contains lexieal eni, riesand primitive l)roposilfions the task is to organize tJds informationanew so that i~ may be expressed ill an English text.
Matll/ andMoore prol)ose rules for (:oml)ining l)ropositiolm and re,.ediL the texteonl, inuously to produce l,he final version.
TEXT gem.
'rate~; pars.gr~tplls as aiiswel's ~o qtlestiolls a\[)ollt da\[,abase Stl'llCtl/Fe.
\[~e/cl(ef)wI1}las idenl;ified discourse stra(.e, gie,~ for fulfilling three (;(mmmlaie~fl.ivegoals: detine, compare, aud describe.
These sl, rategi(~s g,dde, the t,;e-aeration l)ro(:e.<ls ill deciding what; to say \]lext.
Me}(,eowlI lses 1,hequcsl;ion to deteemine tile eommunh:al.ive goal that the text shouldfldfil.
Research of IJfis kind is very important o clarify ~he relationbetween l,he \[orln of (-z text and il;s underlying oals.
()ue of I;he domains of IIAM..ANS is the Mad of I;raflic scenewhich is also used in NAOS.
/n this domain I|AM-ANS deals withprimarily with answering questions about ~he tool, iota; o\[ ol@~ctsand wi~h overanswering yes/no que,%ions \[25 I.
The dialogue (:ore-i)onent, of IIAM-ANS may be commcted to NA()~g I;o also allowquest,ions of the user if' t}m generated text was not sM\[ieienl fi)r hisunderst;anding.
An evalual;ion of the kind of question being askedby a user may help in devising bel, ter generation strategies.|(AMP is a, system tbr plamfing natural languago ubteraneesia the domain of task oriented dialogues.
The 1)lantfinlg altorithmi;akes 1;he knowledge and I)elief'a of the hearer into account,.
'\['his y.-stem shows |low a priori beliefs of 1;he hearer may a\]L;o be integratedin NAOS to generat;e appropria/;e referring phrases.It would be interesting to use a phrasing componen~ for NAOSwhich would firs/, determine all deep eases uecessary ~o maximallyrestrict \[,he visualized t, ra.jeet;ory of an objeet's mot, ion sequence andthen try to distribute I;he cases to the di\[ferent verbs u.sed in thedescripl;ion in order to general;e smooth text.
}.~fl l ography\[1\] Appelt, \]).E., iPlamfi*Jtg Nat m'al-Lal:G'tmge Utt;era:nee~: to ~hd;i.~;fyM'ulLiple Goah~.
SRI lntecn,xtlonal, Technical Note 259, Menlo Park,CA., 1982{2} Bad\]or, N.I., '.l_~m~po:ral .~.Ice,te Analysis: (\]oxtceptnal \]i)e.,:(:ril)tioL~of Object Movemenl:m l{eport TR-.80, l)ept, of CS, University ofToronto, 197513\] Barwise, .I., Perry, J., ~il;L~atio~s and Attibnde.<;.
Bradford Books,MIT Press, 198314\] Busemann, S., ~qurlhc.e Transli)rmations dm'ing the Generat ionof Written German Senteneea.
hc llolc, L.
ted.
), Natural ,anguageGeneration Systems.
Springer, Berlin, 1984\[51 Conldin, E.J., McDomdd~ \]).D., ,qallenee: The.
Key t;o the Se-leeti(m Prol)lem in Nat:m'al Lanl,mage Generation.
COI,ING-82,129-13516\] Davey, A., l)iaeour~e Produel;i,m.
A Computer  Model of gomeAspeel:~ of  a Spealter.
Edinburt;h Uniwn'siW Press, 1978\[71 Filhnm'e, C.,\]., ,qeenes-and.-fl'ames gemantle,., ILL: Zampolli,A.
(ed.
), fAngui.stie Structures Processing.
NoLth-llolland, Amsterdam,1977, 55-81\[8\] Goldman, N.M., Coneeplaml (- 'eneration.
In: Scha.lq It.C, (ed.
),Concept.al hffolmation Processhlg, Noi~h.I\]olland, 1973, 289~371191 yon llahn, W., Hoeppner, W., ,lame.son, A., Wahlster, %i., '.FheAnaLomy of the Natural  Langm~ge rtlialogue b;ysl:em J(\]AM-~LPIVi.
In: Bole, i ,  (eLl.
), Natm'al \],anig,.age \]lased (1omimter .Systems.Ilanser/McMillan, Miinchen, 1980, 11!
).253\[101 l\[oeppner, W., ('hristalhw, T., Marburger, II., Morik, K., Nobel,\[I, O'Leary, M., WahMmr, W., lhWmld }.k,nah;o.~ndependcnee: Ex-perlenee with the Develolmuml; of a (-\]eriL|a\]l)#~lglla~2 A?
:ee!i\[i,~iysl;em to t{}(ighly Diverse }gaekgrmmd gy.'nh.
'r,.q, lJCAI..83,588..594Ill\] Jamesoa, A., WMdster, W., / lser Modelli~lg in/~nlflmra Gener-al;itnl: lglliptdtl a~td l)ei~nlte ))oserip(.ia~.
ECAI-82:222-227\[12\] Mami, W.C., Moore, J., ConLlmter GeneratiwL of Mnli;iparn-graph ~'exl;.
AJC}, 711), 1981, 1%29(J3 / McDonald, I).l)., Nat;m'al L.'nLgnage (~eneraLJon as a Com-prd.a|:ional )~rol)!enl: a~l ~'n|;lod'netion.
in: lh'ady, M., Bmwick,H.C.
(eds.
), ComputaiAonal Models of Discourse.
M\]T Press, Cambridl;e,Ms:Is., 1983, ?,09-.265114\] McI(eown, \[CII., })iL;eom'~m ~.
;I;ratxwje~ for (-~eneral;i,.~; N:qmral-iLaxiff, mlge Text.
Artificial hd.elligenee 27, 1985, 1-,tl115\] Meehan, J., 'YA.LIn...qPIN.
h< Schank, I{.C., lli,,d:,eck, C.K.
(e&;.
),hmicte Conllmter l.Indel-st~Lnding: Vive PioF, rarlu~ plus Miniat.ures.
I,EA,llillsdMe, New Jersey, 198i, i97-258\[161 Nemmmn, ll., Natural  l,angm~ge Descrii)l;im~ of 'Yi:~bm.SVaryi:,~g~3ee:nea.
ln: Walt, z, l).
ted.
), Advances in Natm'M I,:mge.age l'rocesses.Vohlme 1 (in press); also as I,'II\[-\[Ilt..\]L.105/8,t, l/'achbereich lformat, ik,Unlversitlit tlamburg, 1984117} Neumann, ll., On Natm'al Language Aecem; to \](mage 5h>quencet;: Ewml; \]Reeognition a~d Verbalization.
Proc.
Firsl Confer--trice oil Altilicial lnl.elllgence Apl)lications (CAIA-8,1), Denver, Celorz~clo,1984/18\] Neum~mn, B., Novak, II.oJ., Natm'al Language Orlen';ed ~,lventJVJ(odels fi~r l inage f:leqnence }\[:al;erpretat;ion: The }u:J~lles.
('.SRGq'echn.
Note // ad, University of 'l;)ronto, 1983\[191 Neumann, It, NovM?, I\[...J., F,~ent Models Rn' Recognition andNa|;m'al }.
',angnage Description of I'Ivenl;.,t in li~.ea\].
'World ~mage~;equeneem IJCAI..sa, 724-726\[20J Nowdq II..J., B 1~.elatitmal Matching Strategy tb'_,' tremlmralEvent li'.eeognitioyL.
ILL: l,aubscl h ./.
(ed.
), CWAI-84.
\]nformaeik Fach-berichte 10a, Springer~ 1985, 109-118121 / Olson I).R., Lang, Ual;e Use for (dommmdcat:i~G, -\[ntd:muq;inI>;mud '.lPhlnklng.
In: I'?eedle, l{.O., Carroll, .I.\[L (eds.
), I,an?,uage Con>prehension and l, he Acquisition of Knowledge.
Washington, 1972\[221 Okada, N., Concepl;ual Taxonomy of Japanese -Ve:<bs fo:e ()'n-dertLI;andlng Natnral l\[,a:nguage and }iqeture Pat, retire.
COI,\[NG-80, 127-135\[23\] il'sog:~os, J.K, A. Frameworlu :Cot Visaal Motion "crndersLa~Lding.CSttC "I?R.-114, University of Toronto, 198012/!}
'l'suji, S., Km'oda, S., Morizono, A., "(\].adersl;andhW; a Sh~JpleG'arl;oon Film by a Compul;er Vishm System.
lJCAI-77, 6(\]9-610\[2\[;\] Wahlat.er, W., Mi~rburger, H., Jameson, A., Bnsemann, S., Overm~-e~werh~g .'
-.eLi-No-Qneatioim: \]t'\]xtended \]t/.esponses ia a N}, i*_d:er-face f,o a gi0ion Syi*tem.
IJCAI..sa, 6,13-646575
