Proceedings of the 8th International Natural Language Generation Conference, pages 26?34,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsA language-independent method for the extraction of RDF verbalizationtemplatesBasil EllKarlsruhe Institute of Technology (KIT)Karlsruhe, Germanybasil.ell@kit.eduAndreas HarthKarlsruhe Institute of Technology (KIT)Karlsruhe, Germanyharth@kit.eduAbstractWith the rise of the Semantic Web moreand more data become available encodedusing the Semantic Web standard RDF.RDF is faced towards machines: de-signed to be easily processable by ma-chines it is difficult to be understood bycasual users.
Transforming RDF data intohuman-comprehensible text would facil-itate non-experts to assess this informa-tion.
In this paper we present a language-independent method for extracting RDFverbalization templates from a parallelcorpus of text and data.
Our method isbased on distant-supervised simultaneousmulti-relation learning and frequent maxi-mal subgraph pattern mining.
We demon-strate the feasibility of our method on aparallel corpus of Wikipedia articles andDBpedia data for English and German.1 IntroductionNatural Language Generation (NLG) systems re-quire resources such as templates (in case oftemplate-based NLG) or rules (in case of rule-based NLG).
Be it template-based or rule-basedsystems, these resources limit the variability andthe domain-specificity of the generated naturallanguage output and manual creation of these re-sources is tedious work.We propose a language-independent approachthat induces verbalization templates for RDFgraphs from example data.
The approach islanguage-independent since it does not rely onpre-existing language resources such as parsers,grammars or dictionaries.Input is a corpus of parallel text and data con-sisting of a set of documents D and an RDF graphG, where D and G are related via a set of entitiesE where an entity can be described by a documentin D and described by data in G. Output is a setof templates.
Templates consist of a graph patternthat can be applied to query the graph and of a sen-tence pattern that is a slotted sentence into whichparts of the query result are inserted.
A templateenables verbalization of a subgraph ofG as a com-plete sentence.An example is shown in Fig.
1.1 The graph pat-ternGP can be transformed into a SPARQL queryQGP .
Querying the data graph G results in thegraph GGP .
GGP can be verbalized as an English(German) sentence Sen (Sde) using the sentencepattern SPen (SPde).The approach employs the distant supervisionprinciple (Craven and Kumlien, 1999; Bunescuand Mooney, 2007; Carlson et al., 2009; Mintzet al., 2009; Welty et al., 2010; Hoffmann et al.,2011; Surdeanu et al., 2012) from relation extrac-tion: training data is generated automatically byaligning a database of facts with text; therefore,no hand-labeled data is required.
We apply si-multaneous multi-relation learning (Carlson et al.,2009) for text-data alignment and frequent maxi-mal subgraph pattern mining to observe common-alities among RDF graph patterns.Besides the general idea to allow for non-experts to assess information encoded in RDF, weenvision application of these verbalization tem-plates in three scenarios:(1) In query interfaces to semantic databases, ca-sual users - usually not capable of writing for-mal queries ?
specify their information needsusing keywords (Lei et al., 2006; Thomaset al., 2007; Wang et al., 2008), questionsin free-text or using a controlled language(Kaufmann et al., 2006; Cimiano et al., 2008;Wendt et al., 2012; Damljanovic et al., 2012),or forms (Hunter and Odat, 2011; Mendes1Further examples and the evaluation material can befound on our website at http://km.aifb.kit.edu/sites/bridge-patterns/INLG201426GPauthortype           typelabel        pubD                   label                label?book                              ?author?book_type             Writer?book_label  ?book_pubD           ?author_labelQGP SELECT?book_label?book_type_label?author_label?book_pubDWHERE {?book                 :author   ?author .
?book                 :type       ?book_type .
?book                 :label      ?book_label .
?book                 :pubD     ?book_pubD .
?author              :type       :Writer .
?author              :label      ?author_label .
?book_type      :label      ?book_type_label .
}Flash is a science fiction novel byL.
E. Modesitt published in 2004.
{M(book_label|rm())M} is a{M(book_type_label|lcfirst)M} by{M(author_label|id)M} published in{M(book_pubD|id)M}.SenSPenFlash ist ein Science-Fiction-Romanvon L.E.
Modesitt, erschienen 2004.Sde?book_type_labelGGPauthortype           typelabel     pubD                   label                labelFlash                           L_E_ModesittSFN              Writer?Flash (novel)?
@en                       ?L.
E.
Modesitt?
@en?Science fiction novel?
@en{M(book_label|rm())M} ist ein{M(book_type_label|lcfirst)M} von{M(author_label|id)M}, erschienen{M(book_pubD|id)M}.SPde?L.
E.
Modesitt?
@de ?Flash (Roman)?@de?Science-Fiction-Roman?@de?2004?
?book_label = ?Flash (novel)?
@en?book_type_label = ?Science fiction novel?
@en?author_label = ?L.
E.
Modesitt?
@en?book_pubD = "2004"?book = Flash?author = L_E_Modesitt?book_type = SFN?Figure 1: A template consists of a graph pattern GP and a sentence pattern SP .
The graph pattern GPcan be transformed into a SPARQL query QGP .
A result of querying the data graph is the RDF graphGGP with the list of solution mappings ?.
This graph can be verbalized as an English sentence Sen usingthe English sentence pattern SPen or as a German sentence Sde using the German sentence pattern SPde.The modifiers, e.g.
lcfirst, are explained in Table 1.et al., 2008).
The system queries an RDFdatabase according to its interpretation of theinput.
Query results could be verbalized.
(2) Since the introduction of the Google Knowl-edge Graph,2 when searching for an entitysuch as the city of Karlsruhe via Google, be-sides the search results shown on the left atable is displayed on the right which providesa short description of the entity taken fromWikipedia.
While these descriptions are de-coupled from data in the knowledge graphthey could be generated automatically.
(3) The collaboratively-edited knowledge baseWikidata provides machine-readable datawhich can be used, e.g., by the Wikipedia.The Wikidata browsing interface reasonatorcurrently explores the use of template-basedNLG in order to provide human-readable de-scriptions of its entities.3 Since the templatesare created manually, currently only for fewtypes of entities these verbalizations can beprovided.2http://googleblog.blogspot.com/2012/05/introducing-knowledge-graph-things-not.html (accessed 2014-03-20)3See for example the page about Johann SebastianBach: http://tools.wmflabs.org/reasonator/?q=Q1339 (accessed 2014-03-20)1.1 Main contributionsWe present an approach to induce RDF verbal-ization templates from a parallel text-data cor-pus.
(1) The approach is distant-supervised, sinceit does not require labeled data but instead auto-matically aligns a database of facts with text byperforming simultaneous multi-relation learning.
(2) Hypotheses about a sentence?s content are rep-resented as an RDF graph pattern.
Hypothesesgraphs are reduced via frequent maximal subgraphpattern mining.
(3) We introduce RDF verbal-ization templates consisting of a sentence patternwhich includes modifiers and a graph pattern ofunrestricted size.
(4) Our approach does not uselanguage resources such as parsers or dictionariesand is thus language independent and (5) does notdepend on a certain ontology or domain.
(6) Thefeasibility of the approach is validated for Englishand German given a large dataset which resulted inthe induction of a large number of templates thatare general in terms of enabling verbalization ofnumerous subgraphs in our dataset.1.2 Definitions?
A template is a tuple (sp, gp) where sp isa sentence pattern and gp is a graph pat-tern.
We denote the set of variables withina sentence pattern sp as V arSP (sp) and the27set of variables within a graph pattern gp asV arGP (gp).
A template (sp, gp) is safe if theset of variables within the sentence patternis a subset of the set of variables within thegraph pattern: V arSP (sp) ?
V arGP (gp).?
A sentence pattern (SP) is a string that con-sists of terminals, variables, and modifiers.Within an SP a (var., mod.)
tuple (v,m) isdenoted as {M(v|m)M}.
{M( and )M} serveas delimiters of a (var., mod.)
tuple.?
A graph pattern is a set of triples patterns(s, p, o) where s ?
U ?
V , p ?
U ?
V , ando ?
U ?
L ?
V .
U is a set of identifiers, L isa set of literals, and V is a set of variables.?
A modifier m ?
M is a function applicableto the value of a variable v - denoted bym(v).1.3 Template-based NLGA template can be applied for Natural LanguageGeneration as follows.
Given an RDF datagraph G and a template (sp, gp), a SPARQLSELECT query can be created: SELECT PVWHERE { gp?
}.
The list of projection variablesPV is the list of variables v?V arSP (sp).
gp?
isconstructed by adding each triple pattern to gp?.An example of a query (QGP ) created from agraph pattern (GP ) is shown in Fig.
1.Executing a query results in a solution se-quence4 which is a list of solution mappings?
:V?T from a set of variables V to a set of RDFterms T = U?L.
See Fig.
1 for an example of asolution mapping (?
).For each non-terminal in sp representing avariable-modifier tuple (v,m), the modifier m isapplied on ?
(v) resulting in m(?(v)).
Finally,the tuple (v,m), expressed as {M(v|m)M}, is re-placed in sp with m(?(v)).
After replacing eachsuch tuple the sentence creation is complete.2 Parallel corpusOur approach requires a parallel corpus of text anddata and consists of texts that describe entities innatural language and a data graph that semanti-cally describes entities.Formally, the parallel corpus consists of aset of entities E, a set of documents D, andan RDF data graph G. An entity can be de-scribed by a document in a certain language.4We adopt the terminology from the SPARQL 1.1Query Language documentation available at http://www.w3.org/TR/2013/REC-sparql11-query-20130321/.The relation document ?
E?L?D relates an(entity, language) tuple to a set of documents.document(e, l) denotes the (potentially empty)set of documents that describe an entity e?E inlanguage l?L.G is a set of triples (s, p, o) where s, p?U , ando?U?L.Each literal has a datatype, returned by the func-tion datatype:L?T .
Literals of type string canbe language-tagged.
The function ll:L?L returnsthe language ll(r)?L for a literal r?L if it ex-ists.
An entity can have a human-readable formwhich is a language-tagged literal.
The relation?
?E?L?L relates an entity e?E to a (possiblyempty) set of literals ?
(e, l)?L in language l?L.The property p?
relates an entity with its label.Each entity e?E occurs in the data graph.
Thismeans that G contains a triple (s, p, o) where s=eor o=e.3 ApproachOur approach consists of six steps:1.
For each entity e ?
E we collect sentencesfrom documents about the entity that mentionthe entity.2.
For each sentence we align the sentence andthe data graph by iteratively exploring thevicinity of the entity within the graph.
Thisleads to a set of identified entities: entitiesthat are believed to be mentioned within thesentence; and a set of observations.
The sub-graph ofG that consists of all triples that con-tain an identified entity serves as an hypothe-sis graph: no fact that is not expressed in thesubgraph is expressed in the sentence.3.
Each (sentence, identified entities, graph)triple is abstracted by replacing identified lit-erals in the sentence and in the graph withvariables and by replacing identified entitiesin the graph with variables.
This step canlead to multiple distinct (sentence pattern,graph pattern) tuples for each sentence.
Thisabstraction enables comparing different sen-tences that share the same sentence patternafter abstraction.4.
A set of (sentence pattern, graph patterns) tu-ples is built for each sentence pattern.5.
For each (sentence pattern, graph patterns)tuple the set of graph patterns is analyzed re-garding their commonalities.
This is realizedvia the frequent and maximal subgraph pat-28tern extraction (fmSpan) algorithm which re-sults in a set of graph patterns that are sub-graph patterns to the input graph patterns.6.
Given the output of this algorithm and the ab-stracted sentences the templates are created.3.1 Sentence collectionGiven a language name l, a set of entities E, aset of documents D and an ordered list of mod-ifiers M , for each entity e ?
E for each docu-ment d ?
document(e, l) (which describes e inlanguage l) the document is split into a set of sen-tences.
For each sentence that has an acceptablelength (measured as the number of characters), foreach label x ?
?
(e, l) and for each string modifierm ?
Mstring, we store the (sentence, entity, left,right, ?, matched) tuple if the modified labelm(x)matches the sentence.
See Alg.
1.Algorithm 1 Collect example sentences1: procedure COLLECT EXAMPLE SENTENCES(l, E,D,M )2: for each e ?
E do3: for each d ?
document(e, l) ?
D do4: for each s ?
sentences(d, lmin, lmax) do5: for each x ?
?
(e, l) do6: for each m ?Mstring do7: if applicable(m, x) then8: (left, right, x?)
= MatchesLabel(s, x,m, ?str?
)9: if (left, right, x?)
6= ?
then10: Output (s, e, left, right, x, x?, m)11: Continue with next sentenceAlgorithm 2 MatchesLabel1: procedure MATCHESLABEL(s, x,m, t)2: if t = ?str?
?
t 6= ?integer?
then3: if length(x) ?
4 then4: if s matches (\W |?
)\w{l0, l1}m(x)\w{r0, r1}(\W |$) then5: return (left, right,matched)6: else if t = integer then7: if s matches (\D|?
)m(x)(\D|$) then8: return (left, right,matched)9: return ?In Alg.
2, \W denotes a non-word character(such as a blank), \D denotes a non-digit, \w de-notes a word character5 (such as ?x?
), \w{a, b}denotes a sequence of at least a word-charactersand not more than b word characters, l0 and l1 arethe minimum and maximum number of word char-acters that may appear on the left side of the mod-ified string m(x) between this string and a non-word character or the beginning of the sentence(?).
r0 and r1 are the corresponding numbers re-garding the right side of the modified string.
$ de-notes the end of the sentence.
In case of a match,the string that is matched by \w{l0, l1} is stored5Note that word- and non-word characters are language-specific and may be defined for each language individually.as left, the string that is matched by \w{r0, r1}is stored as right and the part that matches m(x)is stored as matched.
Note that matched can bedifferent from m(x) since the application of themodifier m to the string x can result in a reg-ular expression that contains information for thematcher specifying that a part of the string needsto be matched case-insensitively.Allowing a certain number of characters to beadded to the left and to the right of a string hasthe intention to match even though prefixes andpostfixes are added.
For example, this allows tomatch ?German?
within its plural form ?Germans?or to match ?magic?
within magician.3.2 Sentence and data alignmentThe sentence and the data graph are aligned by it-eratively exploring the vicinity of an entity withinthe graph.
This exploration is described by Alg.
3which builds a set of observations obs.
A memberof this set is a 7-tuple where the first three mem-bers form a triple (entity, property, literal value),followed by the strings matched to the left and theright, the matched string and the modifier.
More-over, the algorithm creates a graph graph ?
Gconsisting of all triples that contain an identifiedentity.
Here, an entity e is identified if a modi-fier m ?
M exists such that an x ?
?
(e, l) existssuch that the sentence matches m(x).
Output isthe original sentence, the set of identified entities,the set of observations, and the subgraph.Algorithm 3 Data Collection1: procedure COLLECTDATA(s, e, lang, left, right, x, x?,m)2: identified = ?
; todo = (e); done = ?
;3: graph = ?
; obs = {(e, pl, x, left, right, x?,m)}4: while todo 6= ?
do5: e?
todo.first6: todo?
todo\{e}; done?
done ?
{e}7: for each (e, p, o) ?
G do8: graph?
graph ?
{(e, p, o)}9: if o is a literal then10: (l, r, o?, m) = CL(s, o)11: if (l, r, o?,m) 6= ?
then12: obs?
obs ?
{(e, p, o, l, r, o?,m)}13: if o = ?
(e, lang) then14: identified?
identified ?
{e}15: else if o is a URI then16: if o 6?
done ?
o 6?
todo then17: todo.add(o)18: for each (e2, p, e) ?
G do19: graph?
graph ?
{(e2, p, e)}20: if e2 6?
done ?
o 6?
todo then21: todo.add(e2)22: Output (sentence, identified, obs, graph)3.3 Sentence and graph abstractionIn the previous step, ambiguities may exist.For example, given two triples (e1, p1, v) and29(e2, p2, v) where v is a literal value and the en-tities e1 and e2 are identified, if the value v isfound in the sentence, then it cannot be resolvedwhether the sentence expresses the fact (e1, p1, v)or (e2, p2, v).
Therefore, for each situation wherea value appears in two distinct contexts or wherevalues overlap (two values overlap if the inter-vals of their character positions overlap), the sen-tence and graph pattern is copied and on each copyanother abstraction is performed thus leading tomultiple abstractions per sentence.
Alg.
4 iter-atively creates all sentence abstractions given alanguage name l, a sentence S, and a set of ob-servations obs.
The function poss evaluates theset of observations that are still valid.
The func-tion apply replaces a string in a sentence withvariable and modifier.
Thereby, the left and rightparts are added to the modifier.
For an obser-vation (e, p, o, l, r, o?,m) the string concatenationl+o?+r is replaced with {M(vi|m?)M}.
For eachobservation a new variable vi is introduced.
m?is a modifier to which the modifiers +l(l) and+r(r) are appended which denote that certainstrings are added to the left and the right of theliteral.
The graph is abstracted by replacing thetriple (e, p, o) with the triple pattern (e, p, v1).
Af-ter completely abstracting a sentence pattern, eachidentified entity is replaced by a variable; triplesthat do not contain any variable are removed.Algorithm 4 Sentence abstraction1: procedure ABSSENTENCE(l, S, obs)2: P ?
poss(l, S, obs)3: if P = ?
then4: Output(S)5: else6: O ?
overlap(S, P )7: for each p ?
P do8: if p 6?
O then9: S ?
apply(S, p)10: if O = ?
then11: Output(S)12: else13: for each p ?
O do14: S?
?
apply(S, p)15: AbsSentence(l, S?, P)3.4 GroupingGiven a set of (sp, gp) tuples, for each lan-guage we build groups of tuples where in eachgroup the sentence patterns are pairwise equiv-alent when ignoring modifiers.
Sentence pat-terns spi and spj are equivalent if either theyare identical (spi=spj), or if an injective func-tion m:V arSP (spi)?V arSP (spj) exists suchthat when each variable v in spi is replaced withm(v), the resulting string sp?i is identical to spj .For each group the set of graph patterns is usedas input for the algorithm presented in the follow-ing section.3.5 Frequent maximal subgraph patternextractionBefore we describe the fmSpan algorithm(fmSpan: Frequent Maximal Subgraph PAtternextractioN) we need to introduce our notation:Two graph patterns gpi and gpj are equiv-alent (gpi=gpj) if an injective functionm:V arGP (gpi)?V arGP (gpj) exists suchthat when each variable v in gpi is replacedwith m(v), the resulting graph pattern gp?i isidentical to gpj .
A graph pattern gpi is sub-graph pattern to another graph pattern gpj ,denoted by gpi?pgpj , if an injective functionm:V arGP (gpi)?V arGP (gpj) exists such thatwhen each variable v in gpi is replaced withm(v), resulting in gp?i, each triple pattern in gp?i isalso a triple pattern in gpj .
Given a set of graphpatterns GP={gp1, ..., gpn} and given a graphpattern x, the coverage of x regarding GP is thenumber of graphs in GP to which x is a subgraphpattern: c(x,GP ) := |{gpi ?
GP |x ?p gpi}|.Given a set of graph patterns I={gp1, ..., gpn},from the set of all subgraph patterns P=2gp1?...
?2gpn a set of graph patterns K={gpi, ..., gpj}?Pis selected where:1. for each gpk ?
K:(a) c(gpk, I) ?
min coverage(b) ?
?gpl ?
P : gpk 6= gpl ?
gpk ?p gpl ?c(gpl, I) ?
min coverage2.
?
?gpl ?
P : c(gpl, I) ?
min coverage ?(?
?gpm ?
P : ?
(gpm, gpl) ?
c(gpm, I) ?min coverage) ?
gpl 6?
KThis means that each member of K is suffi-ciently frequent (1a) and maximal (2b) and thatevery maximal graph pattern is contained in K (2).3.6 Template creationFor each (sentence pattern, graph patterns) tuplethe frequent maximal subgraph pattern mining isperformed on the group of graph patterns whichresults in a set K of subgraph patterns.
Eachk ?
K is pruned with Alg.
5.
Thereby, if a vari-able appears in a high number of triples that donot contain any other variable, then these triplesare removed.
After the pruning each k ?
K isthen rejected if it is either not safe, not connected,or, when queried against G returns no results.30Algorithm 5 Graph-pattern pruning1: procedure PRUNEGRAPHPATTERN(k)2: for each v ?
V arGP (k) do3: T ?
{(s, p, o) ?
k|(s = v ?
o 6?
V arGP (k)) ?
(o = v ?
s 6?V arGP (k))}4: if |T | > maxt then5: k ?
k\TDatatype Modifier Descriptionxsd:stringid Does not change the string.lcfirst Sets the first char to lower caseif that char is upper case.ucfirst Sets the first char to upper caseif that char is lower case.case-i Case-insensitive matchrm() If a string ends with a stringin round braces, e.g.
?Dublin(Ohio)?, that part is cut off.-1r Removes the rightmost char.xsd:gYear YYYY Transforms a year value into afour-digit representation.xsd:integerinteger id Does not change the integer.enInt sep Adds English thousands separa-tors, e.g., 10,000.deInt sep Adds German thousands sepa-rators, e.g., 10.000.xsd:dateenM, D Y Result, e.g., March, 22 2014enD M Y Result, e.g., 22 March 2014deM D, Y Result, e.g., Ma?rz 22, 2014deD M Y Result, e.g., 22.
Ma?rz 2014Table 1: List of modifiers per datatype4 ExperimentsWe created a multilingual (English, German) par-allel text-data corpus using data from DBpedia6and documents from the Wikipedia.
The graphG consists of 88, 708, 622 triples, the set of doc-uments D consists of 4, 004, 478 English docu-ments and 716, 049 German documents.
The cor-pus relations and functions are defined as follows:?
document(e, l) :={d|(e, dbo:abstract, ?d?
@l) ?
G}.?
?
(e, l) := {v|(e, rdfs:label, ?v?
@l) ?
G}?
The datatype of a literal "r?
?t" is t.?
The language ll of a literal "d"@l is l.The modifiers we used in the experiment aregiven in Table 1.7 Application of date and inte-6http://wiki.dbpedia.org/Downloads39We used the files long abstracts en, long abstracts en-uris de, mappingbased properties en, raw infobox prop-erties en, article categories en, instance types en, labels en,labels en uris de, category labels en, and category labels-en uris de.7Modifiers are only applied if their application to a literalmodifies that literal.
For example, if a string begins with agroups ?
5 templates all groupsen 4569 3816 686,687de 2130 1250 269,551Table 3: Number of groups with a cardinality?
5,the number of induced templates and the numberof all groups.ger modifiers may also depend on the language ofa sentence.
On a value a list of modifiers can beapplied.
The list of string modifier lists is shownin Fig.
2.
The table also shows how often each listof modifiers was applied during the abstraction ofEnglish and German sentences.We created two sets of entities Een (Ede): thosefor which an English (German) document existthat consists of at least 100 characters.
Een andEde contain 3, 587, 146 and 613, 027 entities, re-spectively.
For each entity for each document wesplit the text into sentences using the Perl moduleLingua::Sentence8 and discarded sentences thatdo not end with a full stop, an exclamation mark,or a question mark or that were shorter (longer)than 50 (200) characters.
We used the set of stringmodifiers presented in Fig.
2 to identify entities viaoccurrence of a modified version of their labels ina sentence.
The results are 3, 811, 992 (794, 040)English (German) sentences.Abstraction resulted in 3,434,108 (530,766) ab-stracted English (German) sentences where atleast two entities are identified per sentence.The group size histogram is displayed in Fig.
2.9The majority (90%) of all groups of English (Ger-man) sentences contain between 5 and 164 (5 and39) sentences.Table 3 gives for each language the number ofgroups that contain more than 5 graph patterns, thenumber of templates we induced, and the num-ber of all groups.
Results of the coverage evalu-ation covt(G) are shown as a histogram in Fig.
3.It shows that for the majority of the templates ahigh number of subgraphs of G can be verbalized,which means that the templates are not fitted toonly a small number of subgraphs: e.g.
for 221English templates verbalize between 105 and 106subgraphs, each.lower case character, then the lcfirst modifier is inapplicable.8http://search.cpan.org/?achimru/Lingua-Sentence-1.059We cut off the long tail.31No Modifier list en de No Modifier list en de No Modifier list en de(1) id 10,619,509 1,349,922 (9) -1r 42,754 15,025 (17) -1r, -1r, lcfirst 8430 90(2) lcfirst 141,865 868 (10) -1r, lcfirst 7513 99 (18) -1r, -1r, ucfirst 1020 5(3) ucfirst 11,018 8 (11) -1r, ucfirst 875 4 (19) -1r, -1r, case-i 733 92(4) case-i 295,593 16,351 (12) -1r, case-i 863 50 (20) rm(), -1r, -1r, lcfirst 0 0(5) rm() 2705 762 (13) rm(), -1r, lcfirst 0 0 (21) rm(), -1r, -1r, ucfirst 0 0(6) rm(), lcfirst 13 0 (14) rm(), -1r, ucfirst 0 0 (22) rm(), -1r, -1r, case-i 66 1(7) rm(), ucfirst 0 0 (15) rm(), -1r, case-i 55 6(8) rm(), case-i 50 0 (16) -1r, -1r 39,113 11,632Table 2: List of lists of string modifiers and their number of applications1101001000100005-910-1415-1920-2425-2930-3435-3940-4445-4950-5455-5960-6465-6970-7475-7980-8485-8990-9495-99100-104105-109110-114115-119120-124125-129130-134135-139140-144145-149150-154155-159160-164en-groupsde-groupsFigure 2: Histogram depicting how often sentence groups occurred with a particular size5 EvaluationWe evaluate the results from the experiment de-scribed in the previous section along the dimen-sions coverage, accuracy, syntactic correctness,and understandability where the latter three are in-spired by (Lester and Porter, 1997; Mellish andDale, 1998; Reiter and Belz, 2009).Coverage: we define cov(t, G) of a templatet=(sp, gp) regarding a data graph G as thenumber of subgraphs ofG that can be verbal-ized with that template i.e.
match gp.Accuracy: is measured in two parts:1.
The extent to which everything that is ex-pressed in gp is also expressed in sp is mea-sured for each triple pattern within the graphpattern on a 4-point scale: (1) The triple pat-tern is explicitly expressed, (2) The triple pat-tern is implied, (3) The triple pattern is notexpressed, and (4) Unsure.2.
The extent to which the sp expresses in-formation that is expr.
in gp is measured ona 4-point scale: (1) Everything is expressed,(2) Most things are expressed, (3) Somethings are expressed, and (4) Nothing is expr..Syntactic correctness: the degree to which theverb.
is syntactically correct, in particu-lar whether it adheres to English or Germangrammar: (1) The verb.
is completely synt.correct.
(2) The verb.
is almost synt.
correct.
(3) The verb.
presents some syntactical er-rors.
(4) The verb.
is strongly synt.
incorrect.Understandability: Adapted from (Nagao et al.,1985): (1) The meaning of the verb.
isclear.
(2) The meaning of the verb.
is clear,but there are some problems in word usage,050100150200250300350#en#deFigure 3: Histogram of the coverage cov(t, G)and/or style.
(3) The basic thrust of the verb.is clear, but the evaluator is not sure of somedetailed parts because of word usage prob-lems.
(4) The verb.
contains many wordusage problems, and the evaluator can onlyguess at the meaning.
(5) The verb.
cannotbe understood at all.We evaluated a random sample of 10 Englishand 10 German templates using a group of 6 eval-uators which are experts in the fields of RDF andSPARQL and that are proficient in both Englishand German.
Each template was evaluated by 3experts, each expert evaluated 10 templates.
Foreach template we retrieved a maximum of 100subgraphs that matched the graph pattern, ran-domly selected 10 subgraphs and verbalized them.For each template an evaluator was asked to evalu-ate accuracy given the graph pattern and given thesentence pattern and, given the list of 10 verbal-izations, to evaluate each sentence regarding syn-tactic correctness and understandability.cov(t, G) of all 5066 templates is shown inFig.
3.
For example, it shows that there are about300 templates where each template can be used32050100150200(1)  (2) (3)  (4)Accuracy (1)en de05101520(1)  (2) (3)  (4)Accuracy (2)en de0100200300(1)  (2) (3)  (4)Syntactical Correctnessen de0100200300(1)  (2) (3)  (4) (5)Understandabilityen deFigure 4: Evaluation results regarding accuracy,syntactical correctness, and understandabilityto verbalize between 104 and 105 subgraphs ofG.
Results regarding the remaining dimensionsare shown in Fig.
4.
The values of the x-axescorrespond to the scale of the respective dimen-sion.
The majority of the triple patterns are eitherexplicitly or implicitly expressed in the sentencepattern.
However, some triple patterns are not ex-pressed in the sentence pattern.
Syntactical cor-rectness and understandability are mostly high.6 Related work(Welty et al., 2010) present a technique for readingsentences and producing sets of hypothetical rela-tions that the sentence may be expressing.
Givena parallel text-data corpus, entities identified asproper nouns in parsed sentences are replaced withvariables.
For each (pattern, set of relations) tu-ple for each sentence that matches this patternit is counted in how many sentences that matchthis pattern a certain relation exists between thetwo entities identified in the sentence.
This leadsto positive weights assigned to patterns.
Nega-tive weights are assigned by applying patterns tosentences, identifying the entities and assigning anegative weight to the relation if the relation ex-pressed by the pattern is not expressed in the data.In contrast to this approach, our approach 1)does not require to parse input sentences 2) doesnot only regard relations between proper nouns,3) constrains candidate entities to the vicinity ofalready identified entities.
Moreover, 4) our ap-proach takes into account the graph of entitiesidentified in a sentence (hypothesis graphs) com-pared to sets of relations and can thus express mul-tiple relations between entities.
(Duma and Klein, 2013) present an unsuper-vised approach to NLG template extraction from aparallel text-data corpus.
Similar to our approach,text and data are aligned by identifying labels ofentities in sentences.
The search space is limitedby only allowing to match entities that are directlylinked to the entity a text is about.
Sentences areabstracted by replacing the entity with the name ofthe property that links the entity with the entity thetext is about thus limiting the depth of the graphto 1.
Abstracted sentences are parsed and prunedby removing constituents that could not be alignedto the database and by removing constituents ofcertain classes and then post-processed using man-ually created rules.
(Gerber and Ngomo, 2011) present an approachto learning natural language representations ofpredicates from a parallel text-data corpus.
Foreach predicate where a tuple of entities is identi-fied in a sentence, the predicate?s natural languagerepresentation is the string between the two enti-ties, e.g.
?s acquisition of for the predi-cate subsidiary and the sentence Google?s ac-quisition of Youtube comes as online video is reallystarting to hit its stride.
The main differences toour approach are 1) that we do not focus on learn-ing how a single predicate is expressed but ratherhow a graph, consisting of multiple related enti-ties, can be expressed in natural language and 2)that a relation between two entities is not only ex-pressed by the string between two entities.7 ConclusionsWe have shown that verbalization templates canbe extracted from a parallel text-data corpus in adistant-supervised manner ?
without the need forpre-existing language resources such as parsers,grammars or dictionaries ?
and that applying thesetemplates for NLG leads to promising results.
Themain novelty is the application of frequent max-imal subgraph pattern mining for the purpose ofanalyzing commonalities in sets of hypothesesgraphs.
Even though the approach is linguisti-cally shallow, verbalizations are already syntacti-cally mostly correct and understandable.AcknowledgementsThe authors acknowledge the support of the Eu-ropean Commission?s Seventh Framework Pro-gramme FP7-ICT-2011-7 (XLike, Grant 288342).33ReferencesRazvan Bunescu and Raymond Mooney.
2007.
Learn-ing to extract relations from the web using mini-mal supervision.
In Annual meeting-association forComputational Linguistics, volume 45, pages 576?583.Andrew Carlson, Justin Betteridge, Estevam R Hr-uschka Jr, and Tom M Mitchell.
2009.
Couplingsemi-supervised learning of categories and relations.In Proceedings of the NAACL HLT 2009 Workshopon Semi-supervised Learning for Natural LanguageProcessing, pages 1?9.
Association for Computa-tional Linguistics.P.
Cimiano, P. Haase, J. Heizmann, M. Mantel, andR.
Studer.
2008.
Towards portable natural lan-guage interfaces to knowledge bases?The case of theORAKEL system.
Data & Knowledge Engineering,65(2):325?354.Mark Craven and Johan Kumlien.
1999.
Constructingbiological knowledge bases by extracting informa-tion from text sources.
In Thomas Lengauer, Rein-hard Schneider, Peer Bork, Douglas L. Brutlag, Jan-ice I. Glasgow, Hans-Werner Mewes, and Ralf Zim-mer, editors, ISMB, pages 77?86.
AAAI.D.
Damljanovic, M. Agatonovic, and H. Cunningham.2012.
FREyA: An interactive way of queryingLinked Data using natural language.
In The Seman-tic Web: ESWC 2011 Workshops, pages 125?138.Springer.Daniel Duma and Ewan Klein, 2013.
Generating Natu-ral Language from Linked Data: Unsupervised tem-plate extraction, pages 83?94.
Association for Com-putational Linguistics, Potsdam, Germany.Daniel Gerber and A-C Ngonga Ngomo.
2011.
Boot-strapping the linked data web.
In 1st Workshop onWeb Scale Knowledge Extraction @ InternationalSemantic Web Conference, volume 2011.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S Weld.
2011.
Knowledge-based weak supervision for information extractionof overlapping relations.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies-Volume 1, pages 541?550.
Association for Compu-tational Linguistics.J.
Hunter and S. Odat.
2011.
Building a SemanticKnowledge-base for Painting Conservators.
In E-Science (e-Science), pages 173?180.
IEEE.E.
Kaufmann, A. Bernstein, and R. Zumstein.
2006.Querix: A natural language interface to query on-tologies based on clarification dialogs.
In Inter-national Semantic Web Conference (ISWC 2006),pages 980?981.Yuangui Lei, Victoria Uren, and Enrico Motta.
2006.SemSearch: A Search Engine for the Semantic Web.pages 238?245.
Springer.J.C.
Lester and B.W.
Porter.
1997.
Developing andempirically evaluating robust explanation genera-tors: The KNIGHT experiments.
Comp.
Linguistics,23(1):65?101.C.
Mellish and R. Dale.
1998.
Evaluation in the conextof natural language generation.
Computer Speechand language, 12(4):349?374.P.N.
Mendes, B. McKnight, A.P.
Sheth, and J.C.Kissinger.
2008.
TcruziKB: Enabling ComplexQueries for Genomic Data Exploration.
In SemanticComputing, 2008, pages 432?439.Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-sky.
2009.
Distant supervision for relation extrac-tion without labeled data.
Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP: Volume 2 -ACL-IJCNLP 09, pages 1003?1011.Makoto Nagao, Jun-ichi Tsujii, and Jun-ichi Naka-mura.
1985.
The Japanese government projectfor machine translation.
Computational Linguistics,11(2-3):91?110.E.
Reiter and A. Belz.
2009.
An investigation into thevalidity of some metrics for automatically evaluat-ing natural language generation systems.
Computa-tional Linguistics, 35(4):529?558.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,and Christopher D Manning.
2012.
Multi-instancemulti-label learning for relation extraction.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, pages 455?465.
Association for Computational Linguistics.E.
Thomas, J.Z.
Pan, and D. Sleeman.
2007.
ON-TOSEARCH2: Searching ontologies semantically.In Proceedings of the OWLED 2007 Workshop onOWL: Experiences and Directions, pages 70?72.H.
Wang, T. Tran, P. Haase, T. Penin, Q. Liu, L. Fu, andY.
Yu.
2008.
SearchWebDB: Searching the BillionTriples.
In Billion Triple Challenge at the Interna-tional Semantic Web Conference (ISWC 2008).Chris Welty, James Fan, David Gondek, and AndrewSchlaikjer.
2010.
Large scale relation detection.In Proceedings of the NAACL HLT 2010 First Inter-national Workshop on Formalisms and Methodologyfor Learning by Reading, pages 24?33.
Associationfor Computational Linguistics.M.
Wendt, M. Gerlach, and H. Du?wiger.
2012.
Lin-guistic Modeling of Linked Open Data for Ques-tion Answering.
Interacting with Linked Data (ILD2012), pages 75?86.34
