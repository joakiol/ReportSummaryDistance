Efficient Construction of Underspecified Semantics underMassive AmbiguityJ ochen  D5rre*Institut fiir maschinelle SprachverarbeitungUniversity of StuttgartAbst ractWe investigate the problem of determin-ing a compact underspecified semanticalrepresentation for sentences that may behighly ambiguous.
Due to combinatorialexplosion, the naive method of building se-mantics for the different syntactic readingsindependently is prohibitive.
We presenta method that takes as input a syntac-tic parse forest with associated constraint-based semantic onstruction rules and di-rectly builds a packed semantic structure.The algorithm is fully implemented andruns in O(n4log(n)) in sentence length, ifthe grammar meets some reasonable 'nor-mality' restrictions.1 BackgroundOne of the most central problems that any NL sys-tem must face is the ubiquitous phenomenon of am-biguity.
In the last few years a whole new branch de-veloped in semantics that investigates underspecifiedsemantic representations i  order to cope with thisphenomenon.
Such representations do not stand forthe real or intended meaning of sentences, but ratherfor the possible options of interpretation.
Quanti-fier scope ambiguities are a semantic variety of am-biguity that is handled especially well by this ap-proach.
Pioneering work in that direction has been(Alshawi 92) and (Reyle 93).More recently there has been growing interest indeveloping the underspecification approach to alsocover syntactic ambiguities (cf.
(Pinkal 95; EggLe-beth 95; Schiehlen 96)).
Schiehlen's approach is out-standing in that he fully takes into account syntactic*This research as been carried out While the au-thor visited the Programming Systems Lab of Prof.Gert Smolka t the University of Saarland, Saarbriicken.Thanks to John Maxwell, Martin Miiller, JoachimNiehren, Michael Schiehlen, and an anonymous reviewerfor valuable feedback and to all at PS Lab for their help-ful support with the OZ system.constraints.
In (Schiehlen 96) he presents an algo-rithm which directly constructs a single underspec-ified semantic structure from the ideal "underspeci-fled" syntactic structure, a parse forest.On the other hand, a method for producing"packed semantic structures", in that case "packedquasi-logical forms", has already been used in theCore Language Engine, informally described in (A1-shawi 92, Chap.
7).
However, this method only pro-duces a structure that is virtually isomorphic tothe parse forest, since it simply replaces parse for-est nodes by their corresponding semantic oper-ators.
No attempt is made to actually apply se-mantic operators in the phase where those "packedQLFs" are constructed.
Moreover, the packing ofthe QLFs seems to serve no purpose in the process-ing phases following semantic analysis.
Already theimmediately succeeding phase "sortal filtering" re-quires QLFs to be unpacked, i.e.
enumerated.Contrary to the CLE method, Schiehlen's methodactively packs semantic structures, even when theyresult from distinct syntactic structures, extractingcommon parts.
His method, however, may take timeexponential w.r.t, sentence length.
Already the se-mantic representations it produces can be exponen-tially large, because they grow linear with the num-ber of (syntactic) readings and that can be exponen-tial, e.g., for sentences that exhibit the well-knownattachment ambiguity of prepositional phrases.
It istherefore an interesting question to ask, whether wecan compute compact semantic representations fromparse forests without falling prey to exponential ex-plosion.The purpose of the present paper is to show thatconstruction of compact semantic representationslike in Schiehlen's approach from parse forests is notonly possible, but also cheap, i.e., can be done inpolynomial time.To illustrate our method we use a simple DCGgrammar for PP-attachment .ambiguities, adaptedfrom (Schiehlen 96), that yields semantic represen-tations (called UDI~Ss) according to the Underspec-ified Discourse Representation Theory (Reyle 93;KampReyle 93).
The grammar is shown in Fig.
1.386start(DRS) --> s(\[ .... itop\], \[\],DRS).s(\[Evenc,VerbL,DomL\],DRS i,PRS_o) -->np(\[X,VerbL,DomL\],DRS_i,DRSI),vp(\[Event,X,VerbL,DomL\],DRS1,DRS_o).s(\[Event,VerbL,DomL\],DRS_i,DRS_o) -->s(\[Event,VerbL, DomL\],DRSi,DRSl) ,pp(\[Event,VerbL,DomL\],DRSi,DRSo).vp(\[Ev,X,VerbL,DomL\],DRS_i ,DRSo) -->vt(\[Ev,X,Y,VerbL,DomL\],DRS_i,DRSI),np(\[Y,VerbL,DomL\],DRSI,DRS_O).np(\[X, VbL,DomL\],DRS i,DRS_o) -->det(\[X,Nou~,L,VbL,DomL\],DRS_i,DRSI),n(\[X,NounL,DomL\],DRSI,DRSo).n(\[X,NounL,DomL\],DRS i,DRS_o) -->n(\[X,NounL,DomL\],DRS i,DRSI),pp(\[X,NounL,DomL\],DRSI,DRS_o).pp(\[X,L,DomL\],DRS_i,DRS o) -->prep(Cond,X,Y),np(\[Y,L,DomL\], \[L:CondlDRS i\],DRS o).vt(\[Ev, X,Y,L,_DomL\],DRS_i,DRS) --> \[saw\],\[DRS=\[L:see(Ev,X,Y) IDRS_i\]}.det(\[X,Lab,VerbL,_\] ,DRS i,DRS) -->\[a\],\[DRS=\[It(Lab, ltop),It(VerbL,Lab),Lab:XIDRS_i\],gensym(l,Lab),gensym(x,X)}.det(\[X,ResL;VbL,DomL\],DRSi,DRS) -->\[ every  \ ] ,(DRS=\[lt(L,DomL), lt(VbL,ScpL),ResL:X,L:every(ResL,ScpL) IDRS_i\],gensym(l,L),gensym(l,ResL),gensym(l,ScpL),gensym(x,X)}.np(\[X .... \],DRS_i,DRS) --> \[i\],\[DRS=\[itop:X,anchor(X, speaker) IDRS_i\],gensyrn(x,X)}.n(\[X,L,_\],DRS, \[L:man(X) IDRS\]) --> \[man\].n(\[X,L,_\],DRS, \[L:hilI(X) IDRS\]) --> \[hill\].prep(on(X,Y),X,Y) --> \[on\].prep(with(X,Y),X,Y) --> \[with\].Figure h Example DCGThe UDRSs constructed by the grammar are flatlists of the UDRS-constraints I <__ l' (subordination(partial) ordering between labels; Prolog represen-tation: i t  ( l , l ' ) ) ,  l : Cond (condition introductionin subUDRS labeled l), I : X (referent introduc-tion in l), l : GenQuant( l ' , l ")  (generalised quan-tifier) and an anchoring function.
The meaning of aUDKS as a set of denoted DRSs can be explainedas follows.
1 All conditions with the same label forma subUDRS and labels occurring in subUDRSs de-note locations (holes) where other subUDRSs canbe plugged into.
The whole UDRS denotes the setof well-formed DRSs that can be formed by someplugging of the subUDRSs that does not violate theordering <.
Scope of quantifiers can be underspec-ified in UDRSs, because subordination can be leftpartial.In our example grammar every nonterminal hasthree arguments.
The 2nd and the 3rd argument rep-resent a UDRS list as a difference list, i.e., the UDRSis "threaded through".
The first argument is a list ofobjects occurring in the UDRS that play a specificrole in syntactic ombinations of the current node.
2An example of a UDRS, however a packed UDRS, isshown later on in ?5.To avoid the dependence on a particular grammarformalism we present our method for a constraint-based grammar abstractly from the actual constraint1Readers unfamiliar with DRT should think of thesestructures as some Prolog terms, representing semantics,built by unifications according to the semantic rules.
It isonly important o notice how we extract common partsof those structures, irrespective of the structures' mean-ings.~E.g., for an NP its referent, as well as the upper andlower label for the current clause and the top label.system employed.
We only require that semanticrules relate the semantic 'objects' or structures thatare associated with the nodes of a local tree by em-ploying constraints.
E.g., we can view the DCG rules ~ np vp as a relation between three 'seman-tic construction terms' or variables SereS, SemNP,SemVP equivalent to the constraintsSeres = \[ \[Event, VerbL,DomL, TopL\] , DRS_i, DRS_o\]SemNP = \[\[X,VerbL,DomL,TopL\] ,DRS_i,DRSI\]SemVP = \[ \[Event, X, VerbL, DomL, TopL\] , DRS 1, DRS_o\]Here is an overview of the paper.
?2 gives the pre-liminaries and assumptions needed to precisely statethe problem we want to solve.
?3 presents the ab-stract algorithm.
Complexity considerations followin ?4.
Finally, we consider implementation issues,present results of an experiment in ?5, and close witha discussion.2 The  Prob lemAs mentioned already, we aim at calculating fromgiven parse forests the same compact semantic struc-tures that have been proposed by (Schiehlen 96),i.e.
structures that make explicit the common partsof different syntactic readings, so that subsequentsemantic processes can use this generalised infor-mation.
As he does, we assume a constraint-basedgrammar, e.g.
a DCG (PereiraWarren 80) or HPSG(PollardSag 94) , in which syntactic onstraints andconstraints that determine a resulting semantic rep-resentation can be seperated and parsing can be per-formed using the syntactic onstraints only.Second, we assume that the set of syntax treescan be compactly represented as a parse forest(cf.
(Earley 70; BillotLang 89; Tomita 86)).
Parseforests are rooted labeled directed acyclic graphswith AND-nodes (standing for context-free branch-387s s snp5n np / \ / /np np12 / ,3PP1816PP19np v d n p d n p23 24 25 26 27 28 29 30np22d n31 32I saw a man on the hill with the teleFigure 2: Example of a parse foresting) and OR-nodes (standing for alternative sub-trees), that call be characterised asfollows (cf.
Fig.
2for an example).31.
The terminal yield as well as the label of twoAND-nodes are identical, if and only if theyboth are children of one OR-node.2.
Every tree reading is .a valid parse tree.Tree readings of such graphs are obtained by replac-ing any OR-node by one of its children.
Parse forestscan represent an exponential number of phrasestructure alternatives in o(n 3) space, where n is thelength of the sentence.
The example uses the 3 OR-nodes (A, B, C) and the AND-nodes 1 through 32to represent 5 complete parse trees, that would use5 x 19 nodes.Third, we assume the rule-to-rule hypothesis, i.e.,3The graphical representation f an OR-node is a boxsurroux~ding its children, i.e.
the AND-OR-graph struc-ture of ~ is o~.NDthat the grammar associates with each local tree a'semantic rule' that specifies how to construct hemother node's semantics from those of its children.Hence, input to the algorithm is?
a parse forest?
an associated semantic rule for every local tree(AND-node together with its children) therein?
and a semantic representation for each leaf(coming from a semantic lexicon).To be more precise, we assume a constraint lan-guage C over a denumerable set of variables X,that is a sublanguage of Predicate Logic with equal-ity and is closed under conjunction, disjunction,and variable renaming.
Small greek letters ?, ?
willhenceforth denote constraints (open formulae) andletters X, Y, Z (possibly with indeces) will denotevariables.
Writing ?
(X1, .
.
.
,  Xk) shall indicate thatX1 .
.
.
.
, Xk are the free variables in the constraint ~.Frequently used examples for constraint languagesare the language of equations over first-order terms388for DCGs, 4 PATR-style feature-path equations, ortyped feature structure description languages (likethe constraint languages of ALE (Carpenter 92) orCUF (D6rreDorna 93)) for HPSG-style grammars.Together with the constraint language we requirea constraint solver, that checks constraints for satis-fiability, usually by transforming them into a normalform (also called 'solved form').
Constraint solvingin the DCG case is simply unification of terms.The semantic representations mentioned beforeare actually not given directly, but rather as a con-straint on some variable, thus allowing for partialityin the structural description.
To that end we assumethat every node in the parse forest u has associatedwith it a variable Xv that is used for constraining the(partial) semantic structure of u.
The semantics ofa leaf node # is hence given as a constraint ?
, (X , ) ,called a leaf constraint.A final assumption that we adopt concerns the na-ture of the 'semantic rules'.
The process of semanticsconstruction shall be a completely monotonous pro-cess of gathering constraints that never leads to fail-ure.
We assume that any associated (instantiated)semantic rule r(u) of a local tree (AND-branching)u(ul, .
.
.
,u~) determines u's semantics Z(u) as fol-lows from those of its children:Z(,,) = 3X,, , .
.
.
3X~, (?~(,,)(X,,, X, , , , .
.
.
,  X,,,) AZ(I.
"I) A .
.
.
A E(Uk) ).The constraint Cr(v)(Xv, Xv l , .
.
.
,  X~)  is called therule constraint for ~,.
It is required to only dependon the variables X~, X~I, .
.
.
,  X~,.
Note that if thesame rule is to be applied at another node, we havea different rule constraint.Note that any F,(~,) depends only on Xv and canbe thought of as a unary predicate.
Now, let us con-sider semantics construction for a single parse treefor the moment.
The leaf constraints together withthe rules define a semantics constraint Z(~,) for ev-ery node u, and the semantics of the full sentenceis described by the T-constraint of the root node,~,(root).
In the T-constraints, we actually can sup-press the existential quantifiers by adopting the con-vention that any variable other than the one of thecurrent node is implicitly existentially bound on theformula toplevel.
Name conflicts, that would forcevariable renaming, cannot occur.
Therefore ~(root)is (equivalent to) just a big conjunction of all ruleconstraints for the inner nodes and all leaf con-straints.Moving to parse forests, the semantics of an OR-node u(~,l,..., uk) is to be defined asz(,.,) = 3x~, .
.
.
3x,~(z( , ,~)  ^  x~=x~,  v .
.
.v z(~k) ^  x~=x~),4DCG shall refer in this paper to a logically pure ver-sion, Definite Clause Grammars based on pure PROLOC,involving no nonlogical devices like Cut, var/1, etc.specifying that the set of possible (partial) semanticrepresentations foru is the union of those of u's chil-dren.
However, we can simplify this formula once andfor all by assuming that for every OR-node there isonly one variable Xu that is associated with it and allof its children.
Using the same variable for ul ... ukis unproblematic, because no two of these nodes canever occur in a tree reading.
Hence, the definition weget is~"\](IJ) : Z(I\]I) V .
.
.
V Z(lYk).Now, in the same way as in the single-tree case, wecan directly "read off" the T-constraint for the wholeparse forest representing the semantics of all read-ings.
Although this constraint is only half the wayto the packed semantic representation we are aim-ing at, it is nevertheless worthwhile to consider itsstructure a little more closely.
Fig.
3 shows the struc-ture of the F,-constraint for the OR-node B in theexample parse forest.In a way the structure of this constraint directlymirrors the structure of the parse forest.
However,by writing out the constraint, we loose the sharingspresent in the forest.
A subformula coming from ashared subtree (as Z(18) in Fig.
3) has to be statedas many times as the subtree appears in an unfoldingof the forest graph.
In our PP-attachment examplethe blowup caused by this is in fact exponential.On the other hand, looking at a T-constraint as apiece of syntax, we can represent this piece of syntaxin the same manner in which trees are represented inthe parse forest, i.e.
we can have a representation fZ(root) with a structure isomorphic to the forest'sgraph structure, s In practice this difference becomesa question of whether we have full control over therepresentations the constraint solver employs (or anyother process that receives this constraint as input).If not, we cannot contend ourselves with the possi-bility of compact representation f constraints, butrather need a means to enforce this compactness onthe constraint level.
This means that we have to in-troduce some form of functional abstraction i to theconstraint language (or anything equivalent that al-lows giving names to complex constraints and refer-encing to them via their names).
Therefore we en-hance the constraint language as follows.
We allowto our disposition a second set of variables, callednames, and two special forms of constraints1.
def(<name>, <constraint>)name definition2.
<name> name usewith the requirements, that a name may only beused, if it is defined and that its definition is unique.Thus, the constraint Z(B) above can be written as(?r(6) A. .
.
A ?26 A NV ?~(7) A .
.
.
A ?26 A N )A def(N, ?r(18) A?27 A ?r(21) A?2S A?29)5The packed QLFs in the Core Language Engine (A1-shawl 92) are an example of such a representation.3896r(6) A 623 A d)r(10) A 024 A 6r(12i A (~25 A Cr(lS) A 626 A ~r(IS} A ~27 A (~r(21) A628 A ~29.
z( s)~(6)v6r(7) A ~r(14) A 623 A Or(17) A 624 A 6r(20) A 625 A 626/~ ~r(18) A ~27 A 6r(21) A 628 A 629E(181Figure 3: Constraint E(B) of example parse forestThe packed semantic representation as con-structed by the method described so far still callsfor an obvious improvement.
Very often the dif-ferent branches of disjunctions contain constraintsthat have large parts in common.
However, althoughthese overlaps are efficiently handled on the rep-resentational level, they are invisible at the logicallevel.
Hence, what we need is an algorithm that fac-tores out common parts of the constraints on thelogical level, pushing disjunctions down.
6 There aretwo routes that we can take to do this efficiently.In the first we consider only the structure of theparse forest, however ignore the content of (rule orleaf) constraints.
I.e.
we explore the fact that theparts of the E-constraints in a disjunction that stemfrom nodes shared by all disjuncts must be identical,and hence can be factored out /  More precisely, wecan compute for every node v the set must-occur(v)of nodes (transitively) dominated by v that must oc-cur in a tree of the forest, whenever u occurs.
We canthen use this information, when building the disjunc-tion E(u) to factor out the constraints introducedby nodes in must-occur(v),  i.e., we build the fac-tor ?
= Av'emust-occur(v) Z(u') and a 'remainder'constraint E(ui)\~ for each disjunct.The other route goes one step further and takesinto account he content of rule and leaf constraints.For it we need an operation genera l i se  that can becharacterised informally as follows.For two satisfiable constraints ?
and ~,genera l i se (?
,  !b) yields the triple ~, ?
', ~3',such that ~ contains the 'common part' of?
and 19 and ?'
represents the 'remainder'6\~ and likewise 19' represents 19\~.6Actually, in the E(B) example such a factoringmakes the use of the name N superfluous.
In general,however, use of names is actually necessary to avoid ex-ponentially large constraints.
Subtrees may be sharedby quite different parts of the structure, not only by dis-juncts of the same disjunction.
In the PP-attachment ex-ample, a compression of the E-constraint to polynomialsize cannot be achieved with factoring alone.7(Maxwell IIIKaplan 93) exploit the same idea forefficiently solving the functional constraints hat an LFGgrammar associates with a parse forest.The exact definition of what the 'common part' orthe 'remainder' shall be, naturally depends on theactual constraint system chosen.
For our purpose itis sufficient o require the following properties:If genera l i se (~.
19) ~-~ (~, ~', ~b'), then ~ I-andOf -~ando=~A?
'and~b-=~A~b' .We shall call such a generalisation operation sim-plifying if the normal form of ~ is not larger thanany of the input constraints' normal form.Example :  An example for such a generalisa-tion operation for PROLOG'S constraint system(equations over first-order terms) is the so-calledanti-unify operation, the dual of unification, thatsome PROLOG implementations provide as a librarypredicate, s Two terms T1 and T2 'anti-unify' to T,iff T is the (unique) most specific term that sub-sumes both T1 and T2.
The 'remainder constraints'in this case are the residual substitutions al and a2that transform T into T1 or T2, respectively.Let us now state the method informally.
We usegenera l i se  to factor out the common parts of dis-junctions.
This is, however, not as trivial as it mightappear at first sight.
Genera l i se  should operateon solved forms, but when we try to eliminate thenames introduced for subtree constraints in orderto solve the corresponding constraints, we end upwith constraints that are exponential in size.
In thefollowing section we describe an algorithm that cir-cumvents this problem.3 The  A lgor i thmWe call an order < on the nodes of a directedacyclic graph G = (N, E) with nodes N and edges Ebottom-up, iff whenever (i, j) E E ("i is a predecessorto j") ,  then j < i.For the sake of simplicity let us assume thatany nonterminal node in the parse forest is binarybranching.
Furthermore, we leave implicit, whenconjunctions of constraints are normalised by theconstraint solver.
Recall that for the generalisationoperation it is usually meaningful to operate onSanti_unify in Quintus Prolog , term_subsumer inSicstus Prolog.390Input :  ?
parse'forest, leaf and rule constraints as described above?
array of variables X~ indexed by node s.t.
if v is a child of OR-node v', then Xv = Xv,Data  st ructures:  ?
an array SEM of constraints and an array D of names, both indexed by node?
a stack ENV of def constraintsOutput :  a constraint representing a packed semantic representationMethod:  ENV := nilprocess nodes in a bottom-up orderdoing with node u:if u is a leaf thenSEM\[v\] := ?,D\[v\] : :  t rueeiseif v is AND(v1, v2) thenSEIVlIv\] := Cr(,) A SEM\[vl\] A SEM\[v2\]if D\[vl\] = t rue  then D\[v\] := D\[u2\]elseif Dive\] = t rue  then D\[v\] := D\[vl\]else D\[v\] := newnamepush def(D\[v\], D\[vl\] A D\[v2\]) onto ENVendelseif v is OR(v1, v2) thenlet GEN, REM1, REM2 such thatgeneralise(SEM\[vl\], SEM\[v2\]) ~-+ (GEN, REM1, REM2)SEM\[v\] := GEND\[v\] := newnamepush def(D\[v\], REM1 A D\[vl \]  V REM2 A D\[v2\]) onto ENVend return SEM\[root\]  A D\[root\] A ENVFigure 4: Packed Semantics Construction Algorithmsolved forms.
However, at least the simplificationst rue  A ?
-- ?
and ?
A t rue =-- ?
should be assumed.The Packed Semantics Construction Algorithm isgiven in Fig.
4.
It enforces the following invariants,which can easily be shown by induction.1.
Every name used has a unique definition.2.
For any node v we have the equivalence ~(v) -SEM\[u\] A \[D\[v\]\], where \[D\[u\]\] shall denote theconstraint obtained from D\[v\] when recursivelyreplacing names by the constraints they arebound to in ENV.3.
For any node u the constraint SEM\[v\] is neverlarger than the ~-constraint of any single treein the forest originating in u.Hence.
the returned constraint correctly representsthe semantic representation for all readings.4 Complex i tyThe complexity of this abstract algorithm dependsprimarily on the actual constraint system and gen-eralisation operation employed.
But note also thatthe influence of the actual semantic operations pre-scribed by the grammar can be vast, even for thesimplest constraint systems.
E.g., we can write aDCGs that produce abnormal large "semantic struc-tures" of sizes growing exponentially with sentencelength (for a single reading).
For meaningful gram-mars we expect his size function to be linear.
There-fore, let us abstract away this size by employinga function fa(n) that bounds the size of semanticstructures (respectively the size of its describing con-straint system in normal form) that grammar G as-signs to sentences of length n.Finally, we want to assume that generalisation issimplifying and can be performed within a bound ofg(m) steps, where m is the total size of the inputconstraint systems.With these assumptions in place, the time com-plexity for the algorithm can be estimated to be (n= sentence length, N = number of forest nodes)O(g( fc (n)  ) " N) <_ O(g( fa(n)  ) .
n3),since every program step other than the generali-sation operation can be done in constant ime pernode.
Observe that because of Invariant 3. the inputconstraints to generalise are bounded by fc as anyconstraint in SEM.In the case of a DCG the generalisation oper-ation is ant i_uni fy ,  which can be performed ino(n. log(n)) time and space (for acyclic s t ruc -tures).
Hence, together with the assumption thatthe semantic structures the DCG computes canbe bounded linearly in sentence length (and areacyclic), we obtain a O(n. log(n).
N) < O(n41og(n))total time complexity.391SEM\[top\]:\[itop : xl,anchor(xl,'Speaker')ii : see(el ,x l ,x2) ,i t (12,1top),i t( l l ,12),12 : x2,12 : man(x2),A : on(B,x3),i t (13,1top),It(A,15),14 : x3,13 : every(14,15),14 : hi l l (x3),C : with(D,x4),i t (16,1top),it(C,16),16 : x4,16 : tele(x4)\]D\[top\] (a Prolog goal):dEnv(509,1,\[B,A,D,C\])ENV (as Prolog predicates):deny(506, i, A)( A=\[e{, l l \ ]i A= \[x2, 12 \]dEnv(339, i, A) :-( A= \[C,B,C,B\]; A= Ix3,14 ... .
\])dEnv(509, 2, A) :-( A= \[el, l l ,x3,14\]; A= Ix2,12,C,B\],dEny(339, I, \ [C,B,x2,12\]))dEnv(509, i, A) :-( A=\[G,F ,e I , I I \ ] ,deny(506, i, \[G,F\])A= \[E,D,C,B\] ,dEny(509, 2, \[E,D,C,B\])Figure 5: Packed UDRS: conjunctive part (left column) and disjunctive binding environment5 Imp lementat ion  and  Exper imenta lResu l tsThe algorithm has been implemented for the PRO-LOG (or DCG) constraint system, i.e., constraintsare equations over first-order terms.
Two implemen-tations have been done.
One in the concurrent con-straint language OZ (SmolkaTreinen 96) and one inSicstus Prolog.
9 The following results relate to theProlog implementation, l?Fig.
5 shows the resulting packed UDRS for theexample forest in Fig.
2.
Fig.
6 displays the SEMpart as a graph.
The disjunctive binding environ-ment only encodes what the variable referents B andD (in conjunction with the corresponding labels Aand C) may be bound to to: one of el, x2, or x3 (andlikewise the corresponding label).
Executing the goaldeny (509,1, \[B, A, D, C\] ) yields the five solutions:A = i i, B = e l ,  C = i i ,  D = e l  ?
;A = 12,  B = x2,  C = i i ,  D = e l  ?
;A = 11,  B = el ,  C = 14,  D = x3  ?
;A = 12,  B = x2.
C = 12,  D = x2  ?
;A = 12,  B = x2,  C = 14,  D = x3  ?
;noI ?-Table 1 gives execution times used for semanticsconstruction of sentences of the form I saw a man(on a hill) n for different n. The machine used for?The OZ implementation has the advantage that fea-ture structure constraint solving is built-in.
Our imple-mentation actually represents he DCG terms as a fea-ture structures.
Unfortunately it is an order of magni-tude slower than the Prolog version.
The reason for thispresumably ies in the fact that meta-logical operationsthe algorithm needs, like generalise and copy_termhave been modeled in OZ and not on the logical levelwere they properly belong, namely the constraint solver.1?This implementation is available fromhttp://www.ims.uni-stuttgart.de/'jochen/CBSem.12 ~x2 14 15 Iman(x2) I x3' \[ hill?x3) x~ I11 ' A /I see(el'x l'x2) l ?n(B'x3) Jltopanchor(x 1 ,' Speaker')I.CI with(D,x4)Figure 6: Conjunctive part of UDRS, graphicallyn246810121416Readings5 3542 91429 1834862 31958786 507742900 7559694845 1071129Mio.
1463AND- + OR-nodes Time4 msec16 msec48 msecl l4  msec220 msec430 msec730 mseci140 msecTable 1: Execution timesthe experiment was a Sun Ultra-2 (168MHz), run-ning Sicstus 3.0~3.
In a further experiment an n-aryant i_uni fy  operation was implemented, which im-proved execution times for the larger sentences, e.g.,the 16 PP sentence took 750 msec.
These results ap-proximately fit the expectations from the theoreticalcomplexity bound.3926 D iscuss ionOur algorithm and its implementation show that itis not only possible in theory, but also feasible inpractice to construct packed semantical representa-tions directly from parse forests for sentence that ex-hibit massive syntactic ambiguity.
The algorithm isboth in asymptotic omplexity and in real numbersdramatically faster than an earlier approach, thatalso tries to provide an underspecified semantics forsyntactic ambiguities.
The algorithm has been pre-sented abstractly from the actual constraint systemand can be 2dapted to any constraint-based gram-mar formalism.A critical assumption for the method has beenthat semantic rules never fail, i.e., no search is in-volved in semantics construction.
This is requiredto guarantee that the resulting constraint is a kindof 'solved form' actually representing so-to-speak thefree combination of choices it contains.
Nevertheless,our method (modulo small changes to handle failure)may still prove useful, when this restriction is notfulfilled, since it focuses on computing the commoninformation of disjunctive branches.
The conjunctivepart of the output constraint of the algorithm canthen be seen as an approximation of the actual re-sult, if the output constraint is satisfiable.
Moreover,the disjunctive parts are reduced, so that a subse-quent full-fledged search will have considerably lesswork than when directly trying to solve the originalconstraint system.ReferencesH.
Alshawi (Ed.).
The Core Language Engine.ACL-MIT Press Series in Natural Languages Pro-cessing.
MIT Press, Cambridge, Mass., 1992.S.
Billot and B. Lang.
The Structure of SharedForests in Ambiguous Parsing.
In Proceedings ofthe 27th Annual Meeting of the A CL, University ofBritish Columbia, pp.
143-151, Vancouver, B.C.,Canada, 1989.B.
Carpenter.
ALE: The Attribute Logic EngineUser's Guide.
Laboratory for Computational Lin-guistics, Philosophy Department, Carnegie MellonUniversity, Pittsburgh PA 15213, December 1992.J.
DSrre and M. Dorna.
CUF - -  A Formalism forLinguistic Knowledge Representation.
I  J.
DSrre(Ed.
), Computational Aspects of Constraint-BasedLinguistic Description I, DYANA-2 deliverableR1.2.A.
ESPRIT, Basic Research Project 6852,July 1993.J.
Earley.
An Efficient Context-Free Parsing Algo-rithm.
Communications of the ACM, 13(2):94-102, 1970.M.
Egg and K. Lebeth.
Semantic Underspeci-fication and Modifier Attachment Ambiguities.In J. Kilbury and R. Wiese (Eds.
), Integra-tive Ansiitze in der Computerlinguistik.
Beitriigezur 5.
Fachtagung der Sektion Computerlinguis-tik der Deutschen Gesellschaft fiir Spraehwis-senschaft (DGfS), pp.
19-24.
Dfisseldorf, Ger-many, 1995.H.
Kamp and U. Reyle.
From Discourse to Logic.
In-troduction to Modeltheoretic Semantics of NaturalLanguage, Formal Logic and Discourse Represen-tation Theory.
Studies in Linguistics and Philoso-phy 42.
Kluwer Academic Publishers, Dordrecht,The Netherlands, 1993.J.
T. Maxwell III and R. M. Kaplan.
The Inter-face between Phrasal and Functional Constraints.Computational Linguistics, 19(4):571-590, 1993.F.
C. Pereira and D. H. Warren.
Definite ClauseGrammars for Language Analysis--A Survey ofthe Formalism and a Comparison with Aug-mented Transition Networks.
Artificial Intelli-gence, 13:231-278, 1980.M.
Pinkai.
Radical Underspecification.
In Pro-ceedings of the lOth Amsterdam Colloquium, pp.587-606, Amsterdam, Holland, December 1995.ILLC/Department of Philosophy, University ofAmsterdam.C.
Pollard and I.
A.
Sag.
Head Driven PhraseStructure Grammar.
University of Chicago Press,Chicago, 1994.U.
Reyle.
Dealing with Ambiguities by Underspecifi-cation: Construction, Representation, and Deduc-tion.
Journal of Semantics, 10(2):123-179, 1993.M.
Schiehlen.
Semantic Construction from ParseForests.
In Proceedings of the 16th InternationalConference on Computational Linguistics, Copen-hagen, Denmark, 1996.G.
Smolka and R. Treinen (Eds.).
DFKI Oz Doc-umentation Series.
German Research Centerfor Artificial Intelligence (DFKI), Stuhlsatzen-hausweg 3, D-66123 Saarbriicken, Germany, 1996.http://www.ps.uni-sb.de/oz.M.
Tomita.
Efficient Parsing for Natural Languages.Kluwer Academic Publishers, Boston, 1986.393
