Proceedings of the 2012 Student Research Workshop, pages 37?42,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTopicTiling: A Text Segmentation Algorithm based on LDAMartin Riedl and Chris BiemannUbiquitous Knowledge Processing LabComputer Science Department, Technische Universita?t DarmstadtHochschulstrasse 10, D-64289 Darmstadt, Germany{riedl,biemann}@cs.tu-darmstadt.deAbstractThis work presents a Text Segmentation al-gorithm called TopicTiling.
This algorithmis based on the well-known TextTiling algo-rithm, and segments documents using the La-tent Dirichlet Allocation (LDA) topic model.We show that using the mode topic ID as-signed during the inference method of LDA,used to annotate unseen documents, improvesperformance by stabilizing the obtained top-ics.
We show significant improvements overstate of the art segmentation algorithms on twostandard datasets.
As an additional benefit,TopicTiling performs the segmentation in lin-ear time and thus is computationally less ex-pensive than other LDA-based segmentationmethods.1 IntroductionThe task tackled in this paper is Text Segmentation(TS), which is to be understood as the segmentationof texts into topically similar units.
This implies,viewing the text as a sequence of subtopics, that asubtopic change marks a new segment.
The chal-lenge for a text segmentation algorithm is to find thesub-topical structure of a text.In this work, this semantic information is gainedfrom Topic Models (TMs).
We introduce a newlydeveloped TS algorithm called TopicTiling.
Thecore algorithm is a simplified version of TextTil-ing (Hearst, 1994), where blocks of text are com-pared via bag-of-word vectors.
TopicTiling usestopic IDs, obtained by the LDA inference method,instead of words.
As some of the topic IDs ob-tained by the inference method tend to change fordifferent runs, we recommend to use the most prob-able topic ID assigned during the inference.
We de-note this most probable topic ID as the mode (mostfrequent across all inference steps) of the topic as-signment.
These IDs are used to calculate the co-sine similarity between two adjacent blocks of sen-tences, represented as two vectors, containing thefrequency of each topic ID.
Without parameter opti-mization we obtain state-of-the-art results based onthe Choi dataset (Choi, 2000).
We show that themode assignment improves the results substantiallyand improves even more when parameterizing thesize of sampled blocks using a window size param-eter.
Using these optimizations, we obtain signif-icant improvements compared to other algorithmsbased on the Choi dataset and also on a more diffi-cult Wall Street Journal (WSJ) corpus provided byGalley et al (2003).
Not only does TopicTilingdeliver state-of-the-art segmentation results, it alsoperforms the segmentation in linear time, as opposedto most other recent TS algorithms.The paper is organized as follows: The next sec-tion gives an overview of text segmentation algo-rithms.
Section 3 introduces the TopicTiling TS al-gorithm.
The Choi and the Galley datasets usedto measure the performance of TopicTiling are de-scribed in Section 4.
In the evaluation section, theresults of TopicTiling are demonstrated on thesedatasets, followed by a conclusion and discussion.2 Related WorkTS can be divided into two sub-fields: (i) linearTS and (ii) hierarchical TS.
Whereas linear TSdeals with the sequential analysis of topical changes,37hierarchical segmentation is concerned with find-ing more fine grained subtopic structures in texts.One of the first unsupervised linear TS algorithmswas introduced by Hearst (1994): TextTiling seg-ments texts in linear time by calculating the sim-ilarity between two blocks of words based on thecosine similarity.
The calculation is accomplishedby two vectors containing the number of occur-ring terms of each block.
LcSeg (Galley et al,2003), a TextTiling-based algorithm, uses tf-idf termweights and improved TS results compared to Text-Tiling.
Utiyama and Isahara (2001) introduced oneof the first probabilistic approaches using DynamicProgramming (DP) called U00.
Related to our workare the DP approaches described in Misra et al(2009) and Sun et al (2008): here, topic modeling isused to alleviate the sparsity of word vectors.
Thisapproach was extended by (Misra et al, 2009) and(Sun et al, 2008) using topic information achievedfrom the LDA topic model.
The first hierarchicalalgorithm was proposed by Yaari (1997), using thecosine similarity and agglomerative clustering ap-proaches.
A hierarchical Bayesian algorithm basedon LDA is introduced with Eisenstein (2009).
In ourwork, however, we focus on linear TS.LDA was introduced by Blei et al (2003) and isa generative model that discovers topics based on atraining corpus.
Model training estimates two dis-tributions: A topic-word distribution and a topic-document distribution.
As LDA is a generative prob-abilistic model, the creation process follows a gen-erative story: First, for each document a topic distri-bution is sampled.
Then, for each document, wordsare randomly chosen, following the previously sam-pled topic distribution.
Using the Gibbs inferencemethod, LDA is used to apply a trained model forunseen documents.
Here, words are annotated bytopic IDs by assigning a topic ID sampled by thedocument-word and word-topic distribution.
Notethat the inference procedure, in particular, marks thedifference between LDA and earlier dimensionalityreduction techniques such as Latent Semantic Anal-ysis.3 TopicTilingThis section introduces the TopicTiling algorithm,first introduced in (Riedl and Biemann, 2012a).In contrast to the quite similar TextTiling algo-rithm, TopicTiling is not based on words, but onthe last topic IDs assigned by the Bayesian Infer-ence method of LDA.
This increases sparsity sincethe word space is reduced to a topic space of muchlower dimension.
Therefore, the documents that areto be segmented have first to be annotated with topicIDs.
For useful topic distinctions, however, the topicmodel must be trained on documents similar in con-tent to the test documents.
Preliminary experimentshave shown that repeating the Bayesian inference,often leads to different topic distributions for a givensentence in several runs.
Memorizing each topic IDassigned to a word in a document during each in-ference step can alleviate this instability, which isrooted in the probabilistic nature of LDA.
After fin-ishing the inference on the unseen documents, weselect the most frequent topic ID for each word andassign it to the word.
We call this method the modeof a topic assignment, denoted with d = true inthe remainder (Riedl and Biemann, 2012b).
Notethat this is different from using the overall topic dis-tribution as determined by the inference step, sincethis winner-takes-it-all approach reduces noise fromrandom fluctuations.
As this parameter stabilizesthe topic IDs at low computational costs, we rec-ommend using this option in all setups where subse-quent steps rely on a single topic assignment.TopicTiling assumes a sentence si as the small-est basic unit.
At each position p, located betweentwo adjacent sentences, a coherence score cp is cal-culated.
With w we introduce a so-called windowparameter that specifies the number of sentences tothe left and to the right of position p that define twoblocks: sp?w, .
.
.
, sp and sp+1, .
.
.
, sp+w+1.
In con-trast to the mode topic assignment parameter d, wecannot state a recommended value for w, as this pa-rameter is dependent on the number of sentences asegment should contain.
This is conditioned on thecorpus that is segmented.To calculate the coherence score, we exclusivelyuse the topic IDs assigned to the words by infer-ence: Assuming an LDA model with T topics, eachblock is represented as a T -dimensional vector.
Thet-th element of each vector contains the frequencyof the topic ID t obtained from the according block.The coherence score is calculated by the vector dotproduct, also referred to as cosine similarity.
Val-38ues close to zero indicate marginal relatedness be-tween two adjacent blocks, whereas values close toone denote a substantial connectivity.
Next, the co-herence scores are plotted to trace the local minima.These minima are utilized as possible segmentationboundaries.
But rather using the cp values itself, adepth score dp is calculated for each minimum (cf.TextTiling, (Hearst, 1994)).
In comparison to Topic-Tiling, TextTiling calculates the depth score for eachposition and than searches for maxima.
The depthscore measures the deepness of a minimum by look-ing at the highest coherence scores on the left and onthe right and is calculated using following formula:dp = 1/2(hl(p)?
cp + hr(p)?
cp).The function hl(p) iterates to the left as long asthe score increases and returns the highest coherencescore value.
The same is done, iterating in the otherdirection with the hr(p) function.
If the number ofsegments n is given as input, the n highest depthscores are used as segment boundaries.
Otherwise, athreshold is applied (cf.
TextTiling).
This thresholdpredicts a segment if the depth score is larger than?
?
?/2, with ?
being the mean and ?
being thestandard variation calculated on the depth scores.The algorithm runtime is linear in the number ofpossible segmentation points, i.e.
the number of sen-tences: for each segmentation point, the two adja-cent blocks are sampled separately and combinedinto the coherence score.
This, and the parameters dand w, are the main differences to the dynamic pro-gramming approaches for TS described in (Utiyamaand Isahara, 2001; Misra et al, 2009).4 Data SetsThe performance of the introduced algorithm isdemonstrated using two datasets: A dataset pro-posed by Choi and another more challenging one as-sembled by Galley.4.1 Choi DatasetThe Choi dataset (Choi, 2000) is commonly used inthe field of TS (see e.g.
(Misra et al, 2009; Sun etal., 2008; Galley et al, 2003)).
It is a corpus, gen-erated artificially from the Brown corpus and con-sists of 700 documents.
For document generation,ten segments of 3-11 sentences each, taken from dif-ferent documents, are combined forming one doc-ument.
400 documents consist of segments with asentence length of 3-11 sentences and there are 100documents each with sentence lengths of 3-5, 6-8and 9-11.4.2 Galley DatasetGalley et al (2003) present two corpora for writ-ten language, each having 500 documents, which arealso generated artificially.
In comparison to Choi?sdataset, the segments in its ?documents?
vary from 4to 22 segments, and are composed by concatenat-ing full source documents.
One dataset is gener-ated based on WSJ documents of the Penn Treebank(PTB) project (Marcus et al, 1994) and the other isbased on Topic Detection Track (TDT) documents(Wayne, 1998).
As the WSJ dataset seems to beharder (consistently higher error rates across severalworks), we use this dataset for experimentation.5 EvaluationThe performance of TopicTiling is evaluated usingtwo measures, commonly used in the TS task: ThePk measure and the WindowDiff (WD) measure(Beeferman et al, 1999; Pevzner and Hearst, 2002).Besides the training corpus, the following parame-ters need to be specified for LDA: The number oftopics T , the number of sample iterations for themodel m and two hyperparameters ?
and ?, spec-ifying the sparseness of the topic-document and thetopic-word distribution.
For the inference method,the number of sampling iterations i is required.
Inline with Griffiths and Steyvers (2004), the follow-ing standard parameters are used: T = 100, ?
=50/T , ?
= 0.01, m = 500, i = 100.
We use theJGibbsLDA implementation described in Phan andNguyen (2007).5.1 Evaluation of the Choi DatasetFor the evaluation we use a 10-fold Cross Validation(CV): the full dataset of 700 documents is split into630 documents for training the topic model and 70documents that are segmented.
These two steps arerepeated ten times to have all 700 documents seg-mented.
For this dataset, no part-of-speech basedword filtering is necessary.
The results for differentparameter settings are listed in Table 1.When using only the window parameter withoutthe mode (d=false), the results demonstrate a sig-39seg.
size 3-5 6-8 9-11 3-11Pk WD Pk WD Pk WD Pk WDd=false,w=1 2.71 3.00 3.64 4.14 5.90 7.05 3.81 4.32d=true,w=1 3.71 4.16 1.97 2.23 2.42 2.92 2.00 2.30d=false,w=2 1.46 1.51 1.05 1.20 1.13 1.31 1.00 1.15d=true,w=2 1.24 1.27 0.76 0.85 0.56 0.71 0.95 1.08d=false,w=5 2.78 3.04 1.71 2.11 4.47 4.76 3.80 4.46d=true,w=5 2.34 2.65 1.17 1.35 4.39 4.56 3.20 3.54Table 1: Results based on the Choi dataset with varyingparameters.nificant error reduction when using a window of 2sentences.
An impairment is observed when usinga too large window (w=5).
This is expected, as thesize of the segments is in a range of 3-11 sentences:A window of 5 sentences therefore leads to blocksthat contain segment boundaries.
We can also seethat the mode method improves the results whenusing a window of one, except for the documentshaving small segments ranging from 3-5 sentences.The lowest error rates are obtained with the modemethod and a window size of 2.As described above, the algorithm is also able toautomatically estimate the number of segments us-ing a threshold value (see Table 2).3-5 6-8 9-11 3-11Pk WD Pk WD Pk WD Pk WDd=false,w=1 2.39 2.45 4.09 5.85 9.20 15.44 4.87 6.74d=true,w=1 3.54 3.59 1.98 2.57 3.01 5.15 2.04 2.62d=false,w=2 15.53 15.55 0.79 0.88 1.98 3.23 1.03 1.36d=true,w=2 14.65 14.69 0.62 0.62 0.67 0.88 0.66 0.78d=false,w=5 21.47 21.62 16.30 16.30 6.01 6.14 14.31 14.65d=true,w=5 21.57 21.67 17.24 17.24 6.44 6.44 15.51 15.74Table 2: Results on the Choi dataset without given num-ber of segments as parameter.The results show that for small segments, thenumber of segments is not correctly estimated, asthe error rates are much higher than with given seg-ments.
As the window parameter has a smoothingeffect on the coherence score function, less possibleboundary candidates are detected.
We can also seethat the usage of the mode parameter leads to worseresults with w=1 compared to the results where themode is deactivated for the documents containingsegments of length 3-5.
Especially, results on thesedocuments suffer when not providing the number ofsegments.
But for the other documents, results aremuch better.
Some results (see segment lengths 6-8 and 3-11 with d=true and w=2) are even betterthan the results with segments provided (see Table1).
The threshold method can outperform the setupwith given a number of segments, since not recog-nizing a segment produces less error in the measuresthan predicting a wrong segment.Table 3 presents a comparison of the performanceof TopicTilig compared to different algorithms in theliterature.Method 3-5 6-8 9-11 3-11TT (Choi, 2000) 44 43 48 46C99 (Choi, 2000) 12 9 9 12U00 (Utiyama and Isahara, 2001) 9 7 5 10LCseg (Galley et al, 2003) 8.69F04 (Fragkou et al, 2004) 5.5 3.0 1.3 7.0M09 (Misra et al, 2009) 2.2 2.3 4.1 2.3TopicTiling (d=true, w=2) 1.24 0.76 0.56 0.95Table 3: Lowest Pk values for the Choi data set for vari-ous algorithms in the literature with number of segmentsprovidedIt is obvious that the results are far better than cur-rent state-of-the-art results.
Using a one-sampled t-test with ?
= 0.05 we can state significant improve-ments in comparison to all other algorithms.While we aim not using the same documents fortraining and testing by using a CV scheme, it is notguaranteed that all testing data is unseen, since thesame source sentences can find their way in severalartificially crafted ?documents?.
We could detect re-occurring snippets in up to 10% of the documentsprovided by Choi.
This problem, however, appliesfor all evaluations on this dataset that use any kindof training, be it LDA models in Misra et al (2009)or tf-idf values in Fragkou et al (2004) and Galleyet al (2003).5.2 Evaluation on Galley?s WSJ DatasetFor the evaluation on Galley?s WSJ dataset, a topicmodel is created from the WSJ collection of the PTBproject.
The dataset for model estimation consistsof 2499 WSJ articles, and is the same dataset Galleyused as a source corpus.
The evaluation generallyleads to higher error rates than in the evaluation forthe Choi dataset, as shown in Table 4.This table shows results of the WSJ data when us-ing all words of the documents for training a topicmodel and assigning topic IDs to new documentsand also filtered results, using only nouns (proper40Parameters All words FilteredPk WD Pk WDd=false,w=1 37.31 43.20 37.01 43.26d=true,w=1 35.31 41.27 33.52 39.86d=false,w=2 22.76 28.69 21.35 27.28d=true,w=2 21.79 27.35 19.75 25.42d=false,w=5 14.29 19.89 12.90 18.87d=true,w=5 13.59 19.61 11.89 17.41d=false,w=10 14.08 22.60 14.09 22.22d=true,w=10 13.61 21.00 13.48 20.59Table 4: Results for Galley?s WSJ dataset using differ-ent parameters with using unfiltered documents and withfiltered documents using only verbs, nouns (proper andcommon) and adjectives.and common), verbs and adjectives1.
Consideringthe unfiltered results we observe that results improvewhen using the mode assigned topic ID and a win-dow of larger than one sentence.
In case of the WSJdataset, we find the optimal setting for w=5.
As thetest documents contain whole articles, which con-sist of at least 4 sentences, a larger window is ad-vantageous here, yet a value of 10 is too large.
Fil-tering the documents for parts of speech leads to ?1% absolute error rate reduction, as can be seen inthe last two columns of Table 4.
Again, we observethat the mode assignment always leads to better re-sults, gaining at least 0.6%.
Especially the windowsize of 5 helps TopicTiling to decrease the error rateto a third of the value observed with d=false andw=1.
Similar to the previous findings, results de-cline when using a too large window.Table 5 shows the results we achieve with thethreshold-based estimation of segment boundariesfor the unfiltered and filtered data.Parameters All words FilteredPk WD Pk WDd=false,w=1 53.07 72.78 52.63 72.66d=true,w=1 53.42 74.12 51.84 72.57d=false,w=2 46.68 65.01 44.81 63.09d=true,w=2 46.08 64.41 43.54 61.18d=false,w=5 30.68 43.73 28.31 40.36d=true,w=5 28.29 38.90 26.96 36.98d=false,w=10 19.93 32.98 18.29 29.29d=true,w=10 17.50 26.36 16.32 24.75Table 5: Table with results the WSJ dataset without num-ber of segments given, using all words and content wordsonly.1The Treetagger http://code.google.com/p/tt4j/ is applied to POS-tag the dataIn contrast to the results obtained with the Choidataset (see Table 2) no decline is observed when thethreshold approach is used in combination with thewindow approach.
We attribute this due to the smallsegments and documents used in the Choi setting.Comparing the all-words data with pos-filtered data,an improvement is always observed.
Also a contin-uous decreasing of both error rates, Pk and WD,is detected when using the mode and using a largerwindow size, even for w=10.
The reason for this isthat too many boundaries are detected when usingsmall windows.
As the window approach smoothesthe similarity scores, this leads to less segmentationboundaries, which improve results.For comparison, we present the evaluation resultsof other algorithms, shown in Table 6, as publishedin Galley et al (2003).Method Pk WDC99 (Choi, 2000) 19.61 26.42U00 (Utiyama and Isahara, 2001) 15.18 21.54LCseg (Galley et al, 2003) 12.21 18.25TopicTiling (d=true,w=5) 11.89 17.41Table 6: List of results based on the WSJ dataset.
Valuesfor C99, U00 and LCseg as stated in (Galley et al, 2003).Again, TopicTiling improves over the state of theart.
The improvements with respect to LCseg aresignificant using a one-sample t-test with ?
= 0.05.6 Conclusion and Further WorkWe introduced TopicTiling, a new TS algorithmthat outperforms other algorithms as shown on twodatasets.
The algorithm is based on TextTiling anduses the topic model LDA to find topical changeswithin documents.
A general result with implica-tions to other algorithms that use LDA topic IDs isthat using the mode of topic assignments across thedifferent inference steps is recommended to stabilizethe topic assignments, which improves performance.As the inference method is relatively fast in compar-ison to building a model, this mechanism is a usefuland simple improvement, not only restricted to thefield of TS.
Using more than a single sentence in in-ference blocks leads to further stability and less spar-sity, which improves the results further.
In contrastto other TS algorithms using topic models (Misraet al, 2009; Sun et al, 2008), the runtime of Top-icTiling is linear in the number of sentences.
This41makes TopicTiling a fast algorithm with complex-ity of O(n) (n denoting the number of sentences)as opposed to O(n2) of the dynamic programmingapproach as discussed in Fragkou et al (2004).Text segmentation benefits from the usage of topicmodels.
As opposed to general-purpose lexical re-sources, topic models can also find fine-grained sub-topical changes, as shown with the segmentation re-sults of the WSJ dataset.
Here, most articles havefinancial content and the topic model can e.g.
dis-tinguish between commodity and stock trading.
Thetopic model adapts to the subtopic distribution of thetarget collection, in contrast e.g.
to static WordNetdomain labels as in Bentivogli et al (2004).For further work, we would like to devise amethod to detect the optimal setting for the windowparameter w automatically, especially in a settingwhere the number of target segments is not known inadvance.
This is an issue that is shared with the orig-inal TextTiling algorithm.
Moreover, we will extendthe usage of our algorithm to more realistic corpora.Another direction of research that is more genericfor approaches based on topic models is the ques-tion of how to automatically select appropriate datafor topic model estimation, given only a small targetcollection.
Since topic model estimation is computa-tionally expensive, and topic models for generic col-lections (think Wikipedia) might not suit the needsof a specialized domain (such as with the WSJ data),it is a promising direction to look at target-domain-driven automatic corpus synthesis.AcknowledgmentsThis work has been supported by the Hessian re-search excellence program ?Landes-Offensive zurEntwicklung Wissenschaftlich-konomischer Exzel-lenz?
(LOEWE) as part of the research center ?Dig-ital Humanities?.ReferencesD.
Beeferman, A. Berger, and J. Lafferty.
1999.
Sta-tistical models for text segmentation.
Mach.
learn.,34(1):177?210.L.
Bentivogli, P. Forner, B. Magnini, and E. Pianta.
2004.Revising the wordnet domains hierarchy: semantics,coverage and balancing.
In Proc.
COLING 2004 MLR,pages 101?108, Geneva, Switzerland.D.
M. Blei, A. Y Ng, and M. I. Jordan.
2003.
LatentDirichlet Allocation.
JMLR ?03, 3:993?1022.F.
Y. Y. Choi.
2000.
Advances in domain indepen-dent linear text segmentation.
In Proc 1st NAACL ?00,pages 26?33, Seattle, WA, USA.J.
Eisenstein.
2009.
Hierarchical text segmentation frommulti-scale lexical cohesion.
In Proc.
NAACL-HLT?09, pages 353?361, Boulder, CO, USA.P.
Fragkou, V. Petridis, and A. Kehagias.
2004.
A Dy-namic Programming Algorithm for Linear Text Seg-mentation.
JIIS ?04, 23(2):179?197.M.
Galley, K. McKeown, E. Fosler-Lussier, and H. Jing.2003.
Discourse segmentation of multi-party conver-sation.
In Proc 41st ACL ?03, volume 1, pages 562?569, Sapporo, Japan.T.
L. Griffiths and M. Steyvers.
2004.
Finding scientifictopics.
PNAS, 101:5228?5235.M.
A. Hearst.
1994.
Multi-paragraph segmentation ofexpository text.
In Proc.
32nd ACL ?94, pages 9?16,Las Cruces, NM, USA.M.
Marcus, G. Kim, M. A. Marcinkiewicz, R. Macintyre,A.
Bies, M. Ferguson, K. Katz, and B. Schasberger.1994.
The Penn treebank: Annotating predicate ar-gument structure.
In Proc.
ARPA-HLT Workshop ?94,pages 114?119, Plainsboro, NJ, USA.Hemant Misra, Joemon M Jose, and Olivier Cappe?.
2009.Text Segmentation via Topic Modeling : An Analyti-cal Study.
In Proc.
18th CIKM ?09, pages 1553?1556,Hong Kong.L.
Pevzner and M. A. Hearst.
2002.
A Critique and Im-provement of an Evaluation Metric for Text Segmen-tation.
Computational Linguistics, 28.X.-H. Phan and C.-T. Nguyen.
2007.
GibbsLDA++: AC/C++ implementation of latent Dirichlet alocation(LDA).
http://jgibblda.sourceforge.net/.M.
Riedl and C. Biemann.
2012a.
How text segmen-tation algorithms gain from topic models.
In Proc.NAACL-HLT ?12, Montreal, Canada.M.
Riedl and C. Biemann.
2012b.
Sweeping throughthe Topic Space: Bad luck?
Roll again!
In ROBUS-UNSUP at EACL ?12, Avignon, France.Q.
Sun, R. Li, D. Luo, and X. Wu.
2008.
Text segmen-tation with LDA-based Fisher kernel.
In Proc.
46thACl-HLT ?08, pages 269?272, Columbus, OH, USA.M.
Utiyama and H. Isahara.
2001.
A statistical model fordomain-independent text segmentation.
In Proc.
39thACL ?00, pages 499?506, Toulouse, France.C.
Wayne.
1998.
Topic detection and tracking (TDT):Overview & perspective.
In Proc.
DARPA BNTUW,Lansdowne, Virginia.Y.
Yaari.
1997.
Segmentation of expository texts by hi-erarchical agglomerative clustering.
In Proc.
RANLP?97, Tzigov Chark, Bulgaria.42
