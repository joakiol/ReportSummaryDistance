A Graph Model for Unsupervised Lexical AcquisitionDominic Widdows and Beate DorowCenter for the Study of Language and Information210 Panama StreetStanford UniversityStanford CA 94305-4115{dwiddows,beate}@csli.stanford.eduAbstractThis paper presents an unsupervised method forassembling semantic knowledge from a part-of-speech tagged corpus using graph algorithms.The graph model is built by linking pairs ofwords which participate in particular syntacticrelationships.
We focus on the symmetric rela-tionship between pairs of nouns which occur to-gether in lists.
An incremental cluster-buildingalgorithm using this part of the graph achieves82% accuracy at a lexical acquisition task, eval-uated against WordNet classes.
The model nat-urally realises domain and corpus specific am-biguities as distinct components in the graphsurrounding an ambiguous word.1 IntroductionSemantic knowledge for particular domains isincreasingly important in NLP.
Many applica-tions such as Word-Sense Disambiguation, In-formation Extraction and Speech Recognitionall require lexicons.
The coverage of hand-built lexical resources such as WordNet (Fell-baum, 1998) has increased dramatically in re-cent years, but leaves several problems andchallenges.
Coverage is poor in many criti-cal, rapidly changing domains such as currentaffairs, medicine and technology, where muchtime is still spent by human experts employedto recognise and classify new terms.
Mostlanguages remain poorly covered in compari-son with English.
Hand-built lexical resourceswhich cannot be automatically updated can of-ten be simply misleading.
For example, usingWordNet to recognise that the word apple refersto a fruit or a tree is a grave error in the manysituations where this word refers to a computermanufacturer, a sense which WordNet does notcover.
For NLP to reach a wider class of appli-cations in practice, the ability to assemble andupdate appropriate semantic knowledge auto-matically will be vital.This paper describes a method for arrangingsemantic information into a graph (Bolloba?s,1998), where the nodes are words and the edges(also called links) represent relationships be-tween words.
The paper is arranged as follows.Section 2 reviews previous work on semanticsimilarity and lexical acquisition.
Section 3 de-scribes how the graph model was built from thePoS-tagged British National Corpus.
Section 4describes a new incremental algorithm used tobuild categories of words step by step from thegraph model.
Section 5 demonstrates this algo-rithm in action and evaluates the results againstWordNet classes, obtaining state-of-the-art re-sults.
Section 6 describes how the graph modelcan be used to recognise when words are poly-semous and to obtain groups of words represen-tative of the different senses.2 Previous WorkMost work on automatic lexical acquisition hasbeen based at some point on the notion ofsemantic similarity.
The underlying claim isthat words which are semantically similar occurwith similar distributions and in similar con-texts (Miller and Charles, 1991).The main results to date in the field of au-tomatic lexical acquisition are concerned withextracting lists of words reckoned to belong to-gether in a particular category, such as vehiclesor weapons (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998).
Roark and Charniak de-scribe a ?generic algorithm?
for extracting suchlists of similar words using the notion of seman-tic similarity, as follows (Roark and Charniak,1998, ?1).1.
For a given category, choose a smallset of exemplars (or ?seed words?)2.
Count co-occurrence of words andseed words within a corpus3.
Use a figure of merit based uponthese counts to select new seed words4.
Return to step 2 and iterate n times5.
Use a figure of merit to rank wordsfor category membership and output aranked listAlgorithms of this type were used by Riloffand Shepherd (1997) and Roark and Charniak(1998), reporting accuracies of 17% and 35%respectively.
Like the algorithm we present inSection 5, the similarity measure (or ?figure ofmerit?)
used in these cases was based on co-occurrence in lists.Both of these works evaluated their resultsby asking humans to judge whether items gen-erated were appropriate members of the cate-gories sought.
Riloff and Shepherd (1997) alsogive some credit for ?related words?
(for examplecrash might be regarded as being related to thecategory vehicles).One problem with these techniques is thedanger of ?infections?
?
once any incorrect orout-of-category word has been admitted, theneighbours of this word are also likely to be ad-mitted.
In Section 4 we present an algorithmwhich goes some way towards reducing such in-fections.The early results have been improved upon byRiloff and Jones (1999), where a ?mutual boot-strapping?
approach is used to extract words inparticular semantic categories and expressionpatterns for recognising relationships betweenthese words for the purposes of information ex-traction.
The accuracy achieved in this experi-ment is sometimes as high as 78% and is there-fore comparable to the results reported in thispaper.Another way to obtain word-senses directlyfrom corpora is to use clustering algorithmson feature-vectors (Lin, 1998; Schu?tze, 1998).Clustering techniques can also be used to dis-criminate between different senses of an ambigu-ous word.
A general problem for such cluster-ing techniques lies in the question of how manyclusters one should have, i.e.
how many sensesare appropriate for a particular word in a givendomain (Manning and Schu?tze, 1999, Ch 14).Lin?s approach to this problem (Lin, 1998) isto build a ?similarity tree?
(using what is in ef-fect a hierarchical clustering method) of wordsrelated to a target word (in this case the wordduty).
Different senses of duty can be discernedas different sub-trees of this similarity tree.
Wepresent a new method for word-sense discrimi-nation in Section 6.3 Building a Graph from aPoS-tagged CorpusIn this section we describe how a graph ?
acollection of nodes and links ?
was built torepresent the relationships between nouns.
Themodel was built using the British National Cor-pus which is automatically tagged for parts ofspeech.Initially, grammatical relations between pairsof words were extracted.
The relationships ex-tracted were the following:?
Noun (assumed to be subject) Verb?
Verb Noun (assumed to be object)?
Adjective Noun?
Noun Noun (often the first noun is modify-ing the second)?
Noun and/or NounThe last of these relationships often occurswhen the pair of nouns is part of a list.
Sincelists are usually comprised of objects which aresimilar in some way, these relationships havebeen used to extract lists of nouns with similarproperties (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998).
In this paper we too fo-cus on nouns co-occurring in lists.
This is be-cause the noun and/or noun relationship is theonly symmetric relationship in our model, andsymmetric relationships are much easier to ma-nipulate than asymmetric ones.
Our full graphcontains many directed links between words ofdifferent parts of speech.
Initial experimentswith this model show considerable promise butare at too early a stage to be reported upon yet.Thus the graph used in most of this paper repre-sents only nouns.
Each node represents a nounand two nodes have a link between them if theyco-occur separated by the conjunctions and oror, and each link is weighted according to thenumber of times the co-occurrence is observed.Various cutoff functions were used to deter-mine how many times a relationship must beobserved to be counted as a link in the graph.A well-behaved option was to take the top nneighbours of each word, where n could be de-termined by the user.
In this way the link-weighting scheme was reduced to a link-rankingscheme.
One consequence of this decision wasthat links to more common words were preferredover links to rarer words.
This decision mayhave effectively boosted precision at the expenseof recall, because the preferred links are to fairlycommon and (probably) more stable words.
Re-search is need to reveal theoretically motivatedor experimentally optimal techniques for select-ing the importance to assign to each link ?
thechoices made in this area so far are often of anad hoc nature.The graph used in the experiments describedhas 99,454 nodes (nouns) and 587,475 links.There were roughly 400,000 different typestagged as nouns in the corpus, so the graphmodel represents about one quarter of thesenouns, including most of the more commonones.4 An Incremental Algorithm forExtracting Categories of SimilarWordsIn this section we describe a new algorithm foradding the ?most similar node?
to an existingcollection of nodes in a way which incremen-tally builds a stable cluster.
We rely entirelyupon the graph to deduce the relative impor-tance of relationships.
In particular, our algo-rithm is designed to reduce so-called ?infections?
(Roark and Charniak, 1998, ?3) where the inclu-sion of an out-of-category word which happensto co-occur with one of the category words cansignificantly distort the final list.Here is the process we use to select and addthe ?most similar node?
to a set of nodes:Definition 1 Let A be a set of nodes andlet N(A), the neighbours of A, be the nodeswhich are linked to any a ?
A.
(So N(A) =?a?AN(a).
)The best new node is taken to be the nodeb ?
N(A)\A with the highest proportion of linksto N(A).
More precisely, for each u ?
N(A)\A,let the affinity between u and A be given by theratio|N(u) ?N(A)||N(u)| .The best new node b ?
N(A) \ A is the nodewhich maximises this affinity score.This algorithm has been built into an on-linedemonstration where the user inputs a givenseed word and can then see the cluster of re-lated words being gradually assembled.The algorithm is particularly effective atavoiding infections arising from spurious co-occurrences and from ambiguity.
Consider, forexample, the graph built around the word ap-ple in Figure 6.
Suppose that we start with theseed-list apple, orange, banana.
However manytimes the string ?Apple and Novell?
occurs inthe corpus, the novell node will not be addedto this list because it doesn?t have a link to or-ange, banana or any of their neighbours exceptfor apple.
One way to summarise the effect ofthis decision is that the algorithm adds wordsto clusters depending on type frequency ratherthan token frequency.
This avoids spurious linksdue to (for example) particular idioms ratherthan geniune semantic similarity.5 Examples and EvaluationIn this section we give examples of lexical cat-egories extracted by our method and evaluatethem against the corresponding classes in Word-Net.5.1 MethodologyOur methodology is as follows.
Consider anintuitive category of objects such as musicalinstruments.
Define the ?WordNet class?
or?WordNet category?
of musical instruments tobe the collection of synsets subsumed in Word-Net by the musical instruments synset.
Take a?protypical example?
of a musical instrument,such as piano.
The algorithm defined in (1)gives a way of finding the n nodes deemed to bemost closely related to the piano node.
Thesecan then be checked to see if they are mem-bers of the WordNet class of musical instru-ments.
This method is easier to implement andless open to variation than human judgements.While WordNet or any other lexical resource isnot a perfect arbiter, it is hoped that this exper-iment procedure is both reliable and repeatable.The ten classes of words chosen were crimes,places, tools, vehicles, musical instruments,clothes, diseases, body parts, academic subjectsand foodstuffs.
The classes were chosen beforethe experiment was carried out so that the re-sults could not be massaged to only use thoseclasses which gave good results.
(The first 4 cat-egories are also used by (Riloff and Shepherd,1997) and (Roark and Charniak, 1998) and sowere included for comparison.)
Having chosenthese classes, 20 words were retrieved using asingle seed-word chosen from the class in ques-tion.This list of words clearly depends on the seedword chosen.
While we have tried to optimisethis choice, it depends on the corpus and thethe model.
The influence of semantic Proto-type Theory (Rosch, 1988) is apparent in thisprocess, a link we would like to investigate inmore detail.
It is possible to choose an optimalseed word for a particular category: it should bepossible to compare these optimal seed wordswith the ?prototypes?
suggested by psychologi-cal experiments (Mervis and Rosch, 1981).5.2 ResultsThe results for a list of ten classes and proto-typical words are given in Table 1.
Words whichare correct members of the classes sought arein Roman type: incorrect results are in ital-ics.
The decision between correctness and in-correctness was made on a strict basis for thesake of objectivity and to enable the repeata-bility of the experiment: words which are inWordNet were counted as correct results only ifthey are actual members of the WordNet classin question.
Thus brigandage is not regardedas a crime even though it is clearly an act ofwrongdoing, orchestra is not regarded as a mu-sical instrument because it is a collection of in-struments rather than a single instrument, etc.The only exceptions we have made are the termswynd and planetology (marked in bold), whichare not in WordNet but are correct nonethe-less.
These conditions are at least as stringentas those of previous experiments, particularlythose of Riloff and Shepherd (1997) who alsogive credit for words associated with but notbelonging to a particular category.
(It has beenpointed out that many polysemous words mayoccur in several classes, making the task easierbecause for many words there are several classeswhich our algorithm would give credit for.
)With these conditions, our algorithm re-trieves only 36 incorrect terms out of a totalof 200, giving an accuracy of 82%.5.3 AnalysisOur results are an order of magnitude betterthan those reported by Riloff and Shepherd(1997) and Roark and Charniak (1998), whoreport average accuracies of 17% and 35% re-spectively.
(Our results are also slightly betterthan those reported by Riloff and Jones (1999)).Since the algorithms used are in many waysvery similar, this improvement demands expla-nation.Some of the difference in accuracy can be at-tributed to the corpora used.
The experimentsin (Riloff and Shepherd, 1997) were performedon the 500,000 word MUC-4 corpus, and thoseof (Roark and Charniak, 1998) were performedusing MUC-4 and the Wall Street Journal cor-pus (some 30 million words).
Our model wasbuilt using the British National Corpus (100million words).
On the other hand, our modelwas built using only a part-of-speech tagged cor-pus.
The high accuracy achieved thus questionsthe conclusion drawn by Roark and Charniak(1998) that ?parsing is invaluable?.
Our resultsclearly indicate that a large PoS-tagged corpusmay be much better for automatic lexical ac-quisition than a small fully-parsed corpus.
Thisclaim could of course be tested by comparingtechniques on the same corpus.To evaluate the advantage of using PoS infor-mation, we compared the graph model with asimilarity thesaurus generated using Latent Se-mantic Indexing (Manning and Schu?tze, 1999,Ch 15), a ?bag-of-words?
approach, on the samecorpus.
The same number of nouns was re-trieved for each class using the graph modeland LSI.
The LSI similarity thesaurus obtainedan accuracy of 31%, much less than the graphmodel?s 82%.
This is because LSI retrieveswords which are related by context but are notin the same class: for example, the neighboursof piano found using LSI cosine-similarity on theBNC corpus include words such as composer,music, Bach, concerto and dance, which are re-lated but certainly not in the same semanticclass.The incremental clustering algorithm of Def-inition (1) works well at preventing ?infections?Class Seed Word Neighbours Produced by Graph Modelcrimes murder crime theft arson importuning incest fraud larceny parricideburglary vandalism indecency violence offences abuse brig-andage manslaughter pillage rape robbery assault lewdnessplaces park path village lane viewfield church square road avenue gardencastle wynd garage house chapel drive crescent home placecathedral streettools screwdriver chisel naville nail shoulder knife drill matchstick morgenthaugizmo hand knee elbow mallet penknife gallie leg arm sicklebolster hammervehicleconveyancetrain tram car driver passengers coach lorry truck aeroplane coonsplane trailer boat taxi pedestrians vans vehicles jeep bus buseshelicoptermusicalinstrumentspiano fortepiano orchestra marimba clarsach violin cizek viola oboeflute horn bassoon culbone mandolin clarinet equiluz contra-bass saxophone guitar celloclothes shirt chapeaubras cardigan trousers breeches skirt jeans boots pairshoes blouse dress hat waistcoat jumper sweater coat cravattie leggingsdiseases typhoid malaria aids polio cancer disease atelectasis illnesses cholerahiv deaths diphtheria infections hepatitis tuberculosis cirrho-sis diptheria bronchitis pneumonia measles dysenterybody parts stomach head hips thighs neck shoulders chest back eyes toes breastsknees feet face belly buttocks haws ankles waist legsacademicsubjectsphysics astrophysics philosophy humanities art religion science pol-itics astronomy sociology chemistry history theology eco-nomics literature maths anthropology culture mathematicsgeography planetologyfoodstuffs cake macaroons confectioneries cream rolls sandwiches croissantbuns scones cheese biscuit drinks pastries tea danish butterlemonade bread chocolate coffee milkTable 1: Classes of similar words given by the graph model.and keeping clusters within one particular class.The notable exception is the tools class, wherethe word hand appears to introduce infection.In conclusion, it is clear that the graph modelcombined with the incremental clustering algo-rithm of Definition 1 performs better than mostprevious methods at the task of automatic lex-ical acquisition.6 Recognising PolysemySo far we have presented a graph model builtupon noun co-occurrence which performs muchbetter than previously reported methods at thetask of automatic lexical acquisition.
This isan important task, because assembling and tun-ing lexicons for specific NLP systems is increas-ingly necessary.
We now take a step furtherand present a simple method for not only as-sembling words with similar meanings, but forempirically recognising when a word has severalmeanings.Recognising and resolving ambiguity isan important task in semantic processing.The traditional Word Sense Disambiguation(WSD) problem addresses only the ambiguity-resolution part of the problem: compiling a suit-able list of polysemous words and their possiblesenses is a task for which humans are tradition-ally needed (Kilgarriff and Rosenzweig, 2000).This makes traditional WSD an intensively su-pervised and costly process.
Breadth of cover-age does not in itself solve this problem: generallexical resources such as WordNet can providetoo many senses many of which are rarely usedin particular domains or corpora (Gale et al,1992).The graph model presented in this paper sug-gests a new method for recognising relevant pol-ysemy.
We will need a small amount of termi-nology from graph theory (Bolloba?s, 1998).Definition 2 (Bolloba?s, 1998, Ch 1 ?1)Let G = (V,E) be a graph, where V is the setof vertices (nodes) of G and E ?
V ?
V is theset of edges of G.?
Two nodes v1, vn are said to be connectedif there exists a path {v1, v2, .
.
.
, vn?1, vn}such that (vj , vj+1) ?
E for 1 ?
j < n.?
Connectedness is an equivalence relation.?
The equivalence classes of the graph G un-der this relation are called the componentsof G.We are now in a position to define the sensesof a word as represented by a particular graph.Definition 3 Let G be a graph of words closelyrelated to a seed-word w, and let G \ w be thesubgraph which results from the removal of theseed-node w.The connected components of the subgraphG \ w are the senses of the word w with respectto the graph G.As an illustrative example, consider the localgraph generated for the word apple (6).
The re-moval of the apple node results in three separatecomponents which represent the different sensesof apple: fruit, trees, and computers.
Definition3 gives an extremely good model of the sensesof apple found in the BNC.
(In this case betterthan WordNet which does not contain the verycommon corporate meaning.
)The intuitive notion of ambiguity being pre-sented is as follows.
An ambiguous word oftenconnects otherwise unrelated areas of meaning.Definition 3 recognises the ambiguity of applebecause this word is linked to both banana andnovell, words which otherwise have nothing todo with one another.It is well-known that any graph can bethought of as a collection of feature-vectors, forexample by taking the row-vectors in the adja-cency matrix (Bolloba?s, 1998, Ch 2 ?3).
Theremight therefore be fundamental similarities be-tween our approach and methods which rely onsimilarities between feature-vectors.Extra motivation for this technique is pro-vided by Word-Sense Disambiguation.
Thestandard method for this task is to use hand-labelled data to train a learning algorithm,which will often pick out particular words asBayesian classifiers which indicate one sense orthe other.
(So if microsoft occurs in the samesentence as apple we might take this as evidencethat apple is being used in the corporate sense.
)Clearly, the words in the different componentsin Diagram 6 can potentially be used as classi-fiers for just this purpose, obviating the need fortime-consuming human annotation.
This tech-nique will be assessed and evaluated in futureexperiments.DemonstrationAn online version of the graph model and the in-cremental clustering algorithm described in thispaper are publicly available 1 for demonstrationpurposes and to allow users to observe the gen-erality of our techniques.
A sample output isincluded in Figure 6.AcknowledgementsThe authors would like to thank the anonymousreviewers whose comments were a great help inmaking this paper more focussed: any short-comings remain entirely our own responsibility.This research was supported in part by theResearch Collaboration between the NTT Com-munication Science Laboratories, Nippon Tele-graph and Telephone Corporation and CSLI,Stanford University, and by EC/NSF grant IST-1999-11438 for the MUCHMORE project.
21http://infomap.stanford.edu/graphs2http://muchmore.dfki.deFigure 1: Automatically generated graph show-ing the word apple and semantically relatednounsReferencesBe?la Bolloba?s.
1998.
Modern Graph Theory.Number 184 in Graduate texts in Mathemat-ics.
Springer-Verlag.Christiane Fellbaum.
1998.
WordNet: An elec-tronic lexical database.
MIT press, Cam-bridge MA.W.
Gale, K. Church, and D. Yarowsky.
1992.One sense per discourse.
In DARPA speechand Natural Language Workshop, Harriman,NY.Adam Kilgarriff and Joseph Rosenzweig.
2000.English senseval: report and results.
InLREC, Athens.Dekang Lin.
1998.
Automatic retrieval andclustering of similar words.
In COLING-ACL, Montreal, August.Christopher D. Manning and Hinrich Schu?tze.1999.
Foundations of Statistical Natural Lan-guage Processing.
The MIT Press, Cam-bridge, Massachusetts.C.
Mervis and E. Rosch.
1981.
Categorizationof natural objects.
Annual Review of Psychol-ogy, 32:89?115.George A. Miller and William G. Charles.
1991.Contextual correlates of semantic similarity.Language and Cognitive Processes, 6(1):1?28.Ellen Riloff and Rosie Jones.
1999.
Learn-ing dictionaries for infomation extraction bymulti-level bootstrapping.
In Proceedings ofthe Sixteenth National Conference on Artifi-cial Intelligence, pages 472?479.
AAAI.Ellen Riloff and Jessica Shepherd.
1997.
Acorpus-based approach for building seman-tic lexicons.
In Claire Cardie and RalphWeischedel, editors, Proceedings of the SecondConference on Empirical Methods in NaturalLanguage Processing, pages 117?124.
Associ-ation for Computational Linguistics, Somer-set, New Jersey.Brian Roark and Eugene Charniak.
1998.Noun-phrase co-occurence statistics for semi-automatic semantic lexicon construction.
InCOLING-ACL, pages 1110?1116.E.
Rosch.
1988.
Principles of categorization.
InA.
Collins and E. E. Smith, editors, Read-ings in Cognitive Science: A Perspective fromPsychology and Artificial Intelligence, pages312?322.
Kaufmann, San Mateo, CA.Hinrich Schu?tze.
1998.
Automatic word sensediscrimination.
Computational Linguistics,24(1):97?124.
