Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 15?22,New York City, New York, June 2006. c?2006 Association for Computational LinguisticsComputational Measures for Language Similarity across Timein Online CommunitiesDavid Huffaker   Joseph Jorgensen    Francisco Iacobelli    Paul Tepper   Justine CassellNorthwestern University{d-huffaker, josephj, f-iacobelli, ptepper, justine}@northwestern.eduAbstractThis paper examines language similarityin messages over time in an online com-munity of adolescents from around theworld using three computational meas-ures: Spearman?s Correlation Coefficient,Zipping and Latent Semantic Analysis.Results suggest that the participants?
lan-guage diverges over a six-week period,and that divergence is not mediated bydemographic variables such as leadershipstatus or gender.
This divergence mayrepresent the introduction of more uniquewords over time, and is influenced by acontinual change in subtopics over time,as well as community-wide historicalevents that introduce new vocabulary atlater time periods.
Our results highlightboth the possibilities and shortcomings ofusing document similarity measures to as-sess convergence in language use.1 IntroductionWhile document similarity has been a concern incomputational linguistics for some time, less atten-tion has been paid to change in similarity acrosstime.
And yet, while historical linguists have longaddressed the issue of divergence or convergenceamong language groups over long periods of time,there has also been increasing interest in conver-gence (also referred to as entrainment, speech ac-commodation, or alignment) in other areas ofLinguistics, with the realization that we have littleunderstanding of change in very short periods oftime, such as months, in a particular conversationalsetting, between two people, or in a large group.The Internet provides an ideal opportunity to ex-amine questions of this sort since all texts perse-vere for later analysis, and the diversity in kinds ofonline communities ensures that the influence ofsocial behavior on language can be examined.
Yetthere has been very little work on language similar-ity in online communities.In this paper we compare the use of three sepa-rate tools to measure document or message similar-ity in a large data set from an online community ofover 3,000 participants from 140 different coun-tries.
Based on a review of related work on corpussimilarity measures and document comparisontechniques (Section 2.2), we chose Spearman?sCorrelation Coefficient, a comparison algorithmthat utilizes GZIP (which we will refer to as ?Zip-ping?)
and Latent Semantic Analysis.
These threetools have all been shown effective for documentcomparison or corpus similarity, but never to ourknowledge have any of them been used for docu-ment similarity over time, nor have they beencompared to one another.
Even though each ofthese tools is quite different in what it specificallymeasures and how it is used, and each has beenused by quite different communities of researchers,they are all fairly well-understood (Section 4).2 Related WorkIn the next sections, we review literature on lan-guage similarity or convergence.
We also reviewliterature on the three computational tools, Spear-man?s Correlation Coefficient (SCC), Zipping, andLatent Semantic Analysis (LSA).2.1 Language Similarity in Computer-mediated CommunicationIn dyadic settings, speakers often converge to oneanother?s speech styles, not only matching thechoice of referring expressions or other words, butalso structural dimensions such as syntax, soundcharacteristics such as accent, prosody, or phonol-15ogy, or even non-verbal behaviors such as gesture(Brennan & Clark, 1996; Street & Giles, 1982).Some scholars suggest that this convergence orentrainment is based on a conscious need to ac-commodate to one?s conversational partner, or as astrategy to maximize communication effectiveness(Street & Giles, 1982).
Others suggest that thealignment is an automatic response, in whichechoic aspects of speech, gesture and facial expres-sions are unconscious reactions (Garrod & Ander-son, 1987; Lakin, Jefferies, Cheng, & Chartrand,2003).
In short, conversational partners tend toaccommodate to each other by imitating or match-ing the semantic, syntactic and phonological char-acteristics of their partners (Brennan & Clark,1996; Garrod & Pickering, 2004).Many studies have concentrated on dyadic inter-actions, but large-scale communities also demon-strate language similarity or convergence.
In fact,speech communities have a strong influence in cre-ating and maintaining language patterns, includingword choice or phonological characteristics(Labov, 2001).
Language use often plays an impor-tant role in constituting a group or communityidentity (Eckert, 2003).
For example, language?norms?
in a speech community often result in theconformity of new members in terms of accent orlexical choice (Milroy, 1980).
This effect has beenquite clear among non-native speakers, whoquickly pick up the vernacular and speech patternsof their new situation (Chambers, 2001), but theopposite is also true, with native speakers pickingup speech patterns from non-native speakers (Auer& Hinskens, 2005)Linguistic innovation is particularly salient onthe Internet, where words and linguistic patternshave been manipulated or reconstructed by indi-viduals and quickly adopted by a critical mass ofusers (Crystal, 2001).
Niederhoffer & Pennebaker(2002) found that users of instant messenger tendto match each other?s linguistic styles.
A study oflanguage socialization in a bilingual chat roomsuggests that participants developed particular lin-guistic patterns and both native and non-nativespeakers were influenced by the other (Lam,2004).
Similar language socialization has beenfound in ethnographic research of large-scaleonline communities as well, in which various ex-pressions are created and shared by group mem-bers (Baym, 2000; Cherny, 1999).Other research not only confirms the creation ofnew linguistic patterns online, and subsequentadoption by users, but suggests that the strength ofthe social ties between participants influences howpatterns are spread and adopted (Paolillo, 2001).However, little research has been devoted to howlanguage changes over longer periods of time inthese online communities.2.2 Computational Measures of LanguageSimilarityThe unit of analysis in online communities is the(e-mail or chat) message.
Therefore, measuringentrainment in online communities relies on as-sessing whether or not similarity between the mes-sages of each participant increases over time.
Mosttechniques for measuring document similarity relyon the analysis of word frequencies and their co-occurrence in two or more corpora (Kilgarriff,2001), so we start with these techniques.Spearman?s Rank Correlation Coefficient (SCC)is particularly useful because it is easy to computeand not dependent on text size.
Unlike some otherstatistical approaches (e.g.
chi-square), SCC hasbeen shown effective on determining similaritybetween corpora of varying sizes, therefore SCCwill serve as a baseline for comparison in this pa-per (Kilgarriff, 2001).More recently, researchers have experimentedwith data compression algorithms as a measure ofdocument complexity and similarity.
This tech-nique uses compression ratios as an approximationof a document?s information entropy (Baronchelli,Caglioti, & Loreto, 2005; Benedetto, Caglioti, &Loreto, 2002).
Standard Zipping algorithms havedemonstrated effectiveness in a variety of docu-ment comparison and classification tasks.
Behr etal.
(2003) found that a document and its translationinto another language compressed to approxi-mately the same size.
They suggest that this couldbe used as an automatic measure for testing ma-chine translation quality.
Kaltchenko (2004) arguesthat using compression algorithms to compute rela-tive entropy is more relevant than using distancesbased on Kolmogorov complexity.
Lastly, Ben-detto et al (2002) present some basic findings us-ing GZIP for authorship attribution, determiningthe language of a document, and building a tree oflanguage families from a text written in differentlanguages.
Although Zipping may be a conten-16tious technique, these results present intriguingreasons to continue exploration of its applications.Latent Semantic Analysis is another techniqueused for measuring document similarity.
LSA em-ploys a vector-based model to capture the seman-tics of words by applying Singular ValueDecomposition on a term-document matrix(Landauer, Foltz, & Laham, 1998).
LSA has beensuccessfully applied to tasks such as measuringsemantic similarity among corpora of texts(Coccaro & Jurafsky, 1998), measuring cohesion(Foltz, Kintsch, & Landauer, 1998 ), assessing cor-rectness of answers in tutoring systems (Wiemer-Hastings & Graesser, 2000) and dialogue act clas-sification (Serafin & Di Eugenio, 2004).To our knowledge, statistical measures likeSCC, Zipping compression algorithms, or LSAhave never been used to measure similarity of mes-sages over time, nor have they been applied toonline communities.
However, it is not obvioushow we would verify their performance, and giventhe nature of the task ?
similarity in over 15,000 e-mail messages ?
it is impossible to compare thecomputational methods to hand-coding.
As a pre-liminary approach, we therefore decided to applyall three methods in turn to the messages in anonline community to examine change in linguisticsimilarity over time, and to compare their results.Through the combination of lexical, phrasal andsemantic similarity metrics, we hope to gain in-sight into the questions of whether entrainmentoccurs in online communities, and of what compu-tational measures can be used to measure it.2.3 The Junior SummitThe Junior Summit launched in 1998 as a closedonline community for young people to discuss howto use technology to make the world better.
3000children ages 10 to 16 participated in 1000 teams(some as individuals and some with friends).
Par-ticipants came from 139 different countries, andcould choose to write in any of 5 languages.
After2 weeks online, the young people divided into 20topic groups of their own choosing.
Each of thesetopic groups functioned as a smaller communitywithin the community of the Junior Summit; afteranother 6 weeks, each topic group elected 5 dele-gates to come to the US for an in-person forum.The dataset from the Junior Summit comprisesmore than 40,000 e-mail messages; however, in thecurrent paper we look at only a sub-set of thesedata ?
messages written in English during the 6-week topic group period.
For complete details,please refer to Cassell & Tversky (2005).3 The Current StudyIn this paper, we examine entrainment among 419of the 1000 user groups (the ones who wrote inEnglish) and among the 15366 messages theywrote over a six-week period (with participantsdivided into 20 topic groups, with an average of20.95 English writers per group).
We ask whetherthe young people?s language converges over timein an online community.
Is similarity between thetexts that are produced by the young people greaterbetween adjacent weeks than between the lessproximally-related weeks?
Furthermore, whatcomputational tools can effectively measure trendsin similarity over time?3.1 HypothesesIn order to address these questions, we chose toexamine change in similarity scores along two di-mensions: (1) at the level of the individual; and (2)across the group as a whole.
More specifically, weexamine similarity between all pairs of individualsin a given topic group over time.
We also com-pared similarity across the entire group at differenttime periods.As depicted below, we first look at pairwisecomparisons between the messages of participantsin a particular topic group within a given time pe-riod, Tk (one week).
For every pair of participantsin a group, we calculated the similarity betweentwo documents, each comprising all messages for aparticipant in the pair.
Then we averaged thescores computed for all topic groups within a timeperiod Tk and produced PTk, the average, pairwisesimilarity score for Tk.
Our first hypothesis is thatthe average, pairwise similarity will increase overtime, such that:PT1 < PT2 < PT3 < PT4 < PT5 < PT6For our second set of tests, we compared allmessages from a single time period to all messagesof a previous time period within a single topicgroup.
Our hypothesis was that temporal proximitywould correlate with mean similarity, such that themessages of two adjacent time periods would ex-hibit more similarity than those of more distant17time periods.
In order to examine this, we performtwo individual hypothesis tests, where Mk is thedocument containing all the messages produced intime period Tk, and S(X,Y) is the similarity scorefor the two documents X and Y.a) S(Mk, Mk-1) > S(Mk, Mk-2)b) S(Mk, Mk-1) > S(Mk, M1)Finally, we posit that SCC, Zipping and LSAwill yield similar results for these tests.4 MethodTo prepare the data, we wrote a script to removethe parts of messages that could interfere withcomputing their similarity, in particular quotedmessages and binary attachments, which are com-mon in a corpus of email-like messages.
We alsoremoved punctuation and special characters.4.1 Spearman?s Correlation CoefficientSCC is calculated as in Kilgarriff (2001).
First, wecompile a list of the common words between thetwo documents.
The statistic can be calculated onthe n most common words, or on all commonwords (i.e.
n = total number of common words).We applied the latter approach, using all the wordsin common for each document pair.
For each docu-ment, the n common words are ranked by fre-quency, with the lowest frequency word ranked 1and the highest ranked n. For each common word,d is the difference in rank orders for the word ineach document.
SCC a normalized sum of thesquared differences:The sum is taken over the n most frequent commonwords.
In the case of ties in rank, where more thanone word in a document occurs with the same fre-quency, the average of the ranks is assigned to thetying words.
(For example, if words w1, w2 and w3are ranked 5th, 6th and 7th then all three wordswould be assigned the same rank of 5 6 73+ + = 6).4.2 ZippingWhen compressing a document, the resulting com-pression ratio provides an estimate of the docu-ment's entropy.
Many compression algorithmsgenerate a dictionary of sequences based on fre-quency that is used to compress the document.Likewise, one can leverage this technique to de-termine the similarity between two documents byassessing how optimal the dictionary generatedwhen compressing one document is when appliedto another document.
We used GZIP for compres-sion, which employs a combination of the LZ77algorithm and Huffman coding.
We based our ap-proach on the algorithm used by (Benedetto,Caglioti, & Loreto, 2002), where the cross-entropyper character is defined as:Here, A and B are documents; A B+  is docu-ment B appended to document A; zip(A) is thezipped document; and length(A) is the length of thedocument.
It is important to note that the testdocument (B) needs to be small enough that itdoesn't cause the dictionary to adapt to the ap-pended piece.
(Benedetto, Caglioti, & Loreto,2002) refer to this threshold as the crossoverlength.
The more similar the appended portion is,the more it will compress, and vice versa.
We ex-tended the basic algorithm to handle the extremelyvaried document sizes found in our data.
Our algo-rithm does two one-way comparisons and returnsthe mean score.
Each one-way comparison be-tween two documents, A and B, is computed bysplitting B into 300 character chunks.
Then foreach chunk, we calculated the cross entropy percharacter when appending the chunk onto A. Eachone-way comparison returns the mean calculationfor every chunk.We fine-tuned the window size with a small,hand-built corpus of news articles.
The differencesare slightly more pronounced with larger windowsizes, but that trend starts to taper off betweenwindow sizes of 300 and 500 characters.
In theend we chose 300 as our window size, because itprovided sufficient contrast and yet still gave a fewsamples from even the smallest documents in ourprimary corpus.4.3 Latent Semantic Analysis (LSA)For a third approach, we used LSA to analyze thesemantic similarity between messages across dif-ferent periods of time.
We explored three imple-length(zip( )) length(zip( ))length( )A B AB+ ?2261( 1)dn n?
= ?
?
?18mentations of LSA: (a) the traditional algorithmdescribed by Foltz et al(1998 )  with one semanticspace per topic group, (b) the same algorithm butwith one semantic space for all topic groups and(c) an implementation based on Word Space(Schutze, 1993) called Infomap.
All three weretested with several settings such as variations in thenumber of dimensions and levels of control forstop words, and all three demonstrated similar re-sults.
For this paper, we present the Infomap re-sults due to its wide acceptance among scholars asa successful implementation of LSA.To account for nuances of the lexicon used inthe Junior Summit data, we built a semantic spacefrom a subset of this data comprised of 7000 smallmessages (under one kb) and 100 dimensions with-out removing stop words.
We then built vectors foreach document and compared them using cosinesimilarity (Landauer, Foltz, & Laham, 1998).5 ResultsThe tools we employ approach document similarityquite differently; we therefore compare findings asa way of triangulating on the nature of entrainmentin the Junior Summit online community.5.1 Pairwise Comparisons over TimeFirst, we hypothesized that messages between in-dividuals in a given topic group would demonstratemore similarity over time.
Our findings did notsupport this claim; in fact, they show the opposite.All three tests show slight convergence betweentime period one and two, some variation, and thendivergence between time periods four, five and six.Spearman?s Correlation Coefficient demon-strates a steady decline in similarity.
As shown inFigure 1, the differences between time periodswere all significant, F(5,1375) = 21.475, p<.001,where N=1381 (N represents user pairs across allsix time periods).Zipping also shows a significant difference be-tween each time period, F(5,1190) = 39.027, p<.001,N=1196, demonstrating a similar decline in simi-larity, although not as unwavering.
See Figure 2.LSA demonstrates the same divergent trend overtime, F(5,1410) = 27.139, p<.001, N=1416, with aslight spike at T4 and T5.
While the dip at time 3 ismore pronounced than SCC and Zipping, it is stillconsistent with the overall findings of the othermeasures.
See Figure 3.0.4950.5050.5150.5250.5350.5450.5550.5650.575T1 T2 T3 T4 T5 T6Time PeriodFigure 1.
Spearman's Correlation Coefficient Simi-larity Scores for all Pairwise comparisons, T1 ?
T60.5350.540.5450.550.5550.560.5650.570.5750.58T1 T2 T3 T4 T5 T6Time PeriodFigure 2.
Zipping Similarity Scores for all Pairwisecomparisons, T1 ?
T60.820.830.840.850.860.870.880.890.90.91T1 T2 T3 T4 T5 T6Time PeriodFigure 3.
LSA Similarity Scores for all Pairwisecomparisons, T1 ?
T6.Because of these surprising findings, we exam-ined the influence of demographic variables, suchas leadership (those chosen as delegates from eachtopic group to the in-person forum), gender, andthe particular topic groups the individuals were apart of.
We divided delegate pairs into (a) pairswhere both individuals are delegates; (b) pairswhere both individuals are non-delegates; and (c)mixed pairs of delegates and non-delegates.
Simi-larly, gender pairs were divided into same-sex(e.g., male-male, female-female) and mixed-sex19pairs.
For topic groups, we re-ran our analyses oneach of the 20 topic groups separately.Overall, both leaders and gender pairs demon-strate the same divergent trends as the group as awhole.
However, not all tests showed significantdifferences when comparing these pairs.For instance, Spearman?s Correlation Coeffi-cient found a significant difference in similaritybetween three groups, where F(2,273) = 6.804,p<.001, n=276, such that delegate-delegate pairsdemonstrate higher similarity scores than non-delegate pairs and mixed pairs.
LSA found thesame result, F(2,280) = 11.122,  p<.001 n=283.
Bycontrast, Zipping did not find this to be the case,where F(2,226) = 2.568, p=.079, n=229.In terms of the potential effect of gender onsimilarity scores, Zipping showed a significant dif-ference between the three groups, F(2,236) = 3.546,p<.05, n=239, such that female-female pairs andmixed-sex pairs demonstrate more similarity thanmale-male pairs.
LSA found the same relationship,F(2,280) = 4.79, p<.005 n=283.
By contrast, Spear-man?s Correlation Coefficient does not show a sig-nificant between-groups difference, F(2,273) = .699,p=.498, n=276.In terms of differences among the topic groups,we did indeed find differences such that some topicgroups demonstrated the fairly linear slope withdecreasingly similarity shown above, while othersdemonstrated dips and rises resulting in a level ofsimilarity at T6 quite similar to T1.
There is noneat way to statistically measure the differences inthese slopes, but it does indicate that future analy-ses need to take topic group into account.In sum, we did not find leadership or gender tomediate language similarity in this community.Topic group, on the other hand, did play a role,however no topic groups showed increasing simi-larity across time.5.2 Similarity and Temporal ProximityOur second hypothesis concerned the gradualchange of language over time such that temporalproximity of time periods would correlate withmean similarity.
In other words, we expect thatmessages in close time periods (e.g., adjacentweeks) should be more similar than messages frommore distant time periods.
In order to examinethis, we performed two individual tests, in whichour predictions can be described as follows: (a) thesimilarity between texts in one time period andtexts in the neighboring time period is greater thantexts in one time period, and texts that came twoperiods previously, S(Mk, Mk-1) > S(Mk, Mk-2); and(b) the similarity between texts in one time periodand texts in the neighboring time period is greaterthan the similarity between texts in one time pe-riod, and texts in the very first time period, S(Mk,Mk-1) > S(Mk, M1).As shown in Table 1, SCC and Zipping testsconfirm these hypotheses, while none of the LSAtests revealed significant differences.Table 1.
Temporal Proximity Similarities SCC,Zipping, and LSA, n=20 topic groupsS(Mk,Mk-1)> S(Mk ,Mk-2)S(Mk,Mk-1)> S(Mk ,M1)S(Mk,Mk-2)> S(Mk ,M1)SCC .665 > .653?
.665 > .639?
.653 > .639?ZIP .628 > .608?
.628 > .605?
.608 > .605?LSA 9.74 > .971 9.74 > .971 .97166 < .97168Note: *p<.05, ?p<.01, ?p<.001, ?p = .0525, one-tailed6 DiscussionThis work presents several novel contributionsto the analysis of text-based messages in onlinecommunities.
Using three separate tools, Spear-man?s Correlation Coefficient, Zipping and LatentSemantic Analysis measures, we found that acrosstime, members of an online community diverge inthe language they use.
More specifically, a com-parison of the words contributed by any pair ofusers in a particular topic group shows increasingdissimilarity over the six-week period.This finding seems counter-intuitive given workin linguistics and psychology, which shows thatdyads and communities converge, entrain and echoeach other?s lexical choices and communicationstyles.
Similarly, our own temporal proximity re-sults appear to indicate convergence, since closertime periods are more similar than more distantones.
Finally, previous hand-coding of these datarevealed convergence, for example between boysand girls on the use of emotion words, betweenolder and younger children on talk about the future(Cassell & Tversky, 2005).
So we ask, why do ourtools demonstrate this divergent trend?We believe that one answer comes from the factthat, while the young people may be discussing amore restricted range of topics, they are contribut-ing a wider variety of vocabulary.
In order to ex-amine whether indeed there were more unique20words over time, we first simply manually com-pared the frequency of words over time and foundthat, on the contrary, there are consistently fewerunique words by T6, which suggests convergence.However, there are also fewer and fewer totalwords by the end of the forum.
This is due to thenumber of participants who left the forum afterthey were not elected to go to Boston.
If we dividethe unique words by the total words, we find thatthe ratio of unique words consistently increasesover time (see Figure 4).
It is likely that this ratiocontributes to our results of divergence.0.030.0350.040.0450.050.0550.060.0650.070.0751 2 3 4 5 6Time PeriodFigure 4.
Ratio of Unique to Total Words, T1 ?
T6In order to further examine the role of increasingvocabulary in the Junior Summit as a whole, wealso created several control groups comprised ofrandom pairs of users (i.e., users that had neverwritten to each other), and measured their pairwisesimilarity across time.
The results were similar tothe experimental groups, demonstrating a slopewith roughly the same shape.
This argues for con-vergence and divergence being affected by some-thing at a broader, community-level such as anincrease in vocabulary.This result is interesting for an additional rea-son.
Some users ?
perhaps particularly non-nativespeakers or younger adolescents, may be learningnew vocabulary from other speakers, which theybegin to introduce at later time periods.
An in-creasingly diversified vocabulary could conceiva-bly result in differences in word frequency amongspeakers.
This leads us to some key questions: towhat extent does the language of individualschange over time?
Is individual language influ-enced by the language of the community?
This isheart of entrainment.In conclusion, we have shown that SCC, Zip-ping and LSA can be used to assess message simi-larity over time, although they may be somewhatblunt instruments for our purposes.
In addition,while Zipping is somewhat contentious and not aswidely-accepted as SCC or LSA is, we found thatthe three tools provide very similar results.
This isparticularly interesting given that, while all threemethods take into account word or word-sequencefrequencies, LSA is designed to also take into ac-count aspects of semantics beyond the surfacelevel of lexical form.All in all, these tools not only contribute to waysof measuring similarity across documents, but canbe utilized in measuring smaller texts, such asonline messages or emails.
Most importantly,these tools remind us how complex and dynamiceveryday language really is, and how much thiscomplexity must be taken into account when build-ing computational tools for the analysis of text andconversation.6.1 Future DirectionsIn future work, we intend to find ways to comparethe results obtained from different topic groups andalso to examine differences among individual us-ers, including re-running our analyses after remov-ing outliers.
We also hope to explore the interplaybetween individuals and the community andchanges in language similarity.
In other words,can we find those individuals who may be acquir-ing new vocabulary?
Are there ?language leaders?responsible for language change online?We also plan to analyze words in terms of theirlocal contexts, to see if this changes over time andhow it impacts our results.
Furthermore, we intendto go beyond word frequency to classify topicchanges over time to get a better understanding ofthe dynamics of the groups (Kaufmann, 1999).Finally, as we have done in the past with ouranalyses of this dataset, we would like to perform apercentage of hand-coded, human content analysisto check reliability of these statistical methods.AcknowledgementsThanks to members of the Articulab, Stefan Kauf-mann, Stefan Wuchty, Will Thompson, DebbieZutty and Lauren Olson for invaluable input.
Thisresearch was in part supported by a generous grantfrom the Kellogg Foundation.ReferencesAuer, P., & Hinskens, F. (2005).
The role of interper-sonal accommodation in a theory of languagechange.
In P. Auer, F. Hinskens & P.
Kerswill21(Eds.
), Dialect change: The convergence anddivergence of dialects in European languages(pp.
335-357).
Cambridge, MA: CambridgeUniversity Press.Baronchelli, A., Caglioti, E., & Loreto, V. (2005).
Arti-ficial sequences and complexity measures.Journal of Statistical Mechanics: Theory andExperiment, P04002, 1-26.Baym, N. K. (2000).
Tune in, log on: Soaps, fandom,and online community.
New York: Sage Publi-cations.Benedetto, D., Caglioti, E., & Loreto, V. (2002).
Lan-guage trees and zipping.
Physical Review Let-ters, 88(4), 1-4.Brennan, S. E., & Clark, H. H. (1996).
Conceptual pactsand lexical choice in conversation.
Journal ofExperimental Psychology: Learning, Memory,and Cognition, 22(6), 1482-1493.Cassell, J., & Tversky, D. (2005).
The language ofonline intercultural community formation.Journal of Computer-Mediated Communica-tion, 10(2), Article 2.Chambers, J. K. (2001).
Dynamics of dialect conver-gence.
Journal of Sociolinguistics, 6(1), 117-130.Cherny, L. (1999).
Conversation and Community: Chatin a Virtual World.
Stanford: Center for theStudy of Language and Information.Coccaro, N., & Jurafsky, D. (1998, November 1998).Towards better integration of semantic predic-tors in statistical language modeling.
Paperpresented at the International Conference onSpoken Language Processing (ICSLP-98),Sidney, Australia.Crystal, D. (2001).
Language and the Internet.
NewYork: Cambridge University Press.Eckert, P. (2003).
Language and adolescent peer groups.Journal of Language and Social Psychology,22(1), 112-118.Foltz, P. W., Kintsch, W., & Landauer, T. K. (1998 ).The measurement of textual Coherence withLatent Semantic Analysis.
Discourse Proc-esses, 25, 285-307.Garrod, S., & Anderson, A.
(1987).
Saying what youmean in dialogue: A study in conceptual andsemantic coordination.
Cognition, 27, 181-218.Garrod, S., & Pickering, M. J.
(2004).
Why is conversa-tion so easy?
Trends in Cognitive Sciences,8(1), 8-11.Kalthchenko, A.
(2004, May 2-5, 2004).
Algorithms forestimation of information distance with appli-cation to bioinformatics and linguistics.
Paperpresented at the Canadian Conference on Elec-trical and Computer Engineering (CCECE2004), Niagara Falls, Ontario, Canada.Kaufmann, S. (1999).
Cohesion and collocation: Usingcontext vectors in text segmentation.
Paper pre-sented at the 37th Annual Meeting of the Asso-ciation for Computational Linguistics, CollegePark, MD.Kilgarriff, A.
(2001).
Comparing corpora.
InternationalJournal of Corpus Linguistics, 6(1), 97-133.Labov, W. (2001).
Principles of linguistic change (Vol.2: Social Factors).
Oxford: Blackwell Publish-ers.Lakin, J. L., Jefferies, V. E., Cheng, C. M., & Char-trand, T. L. (2003).
The chameleon effect associal glue: Evidence for the evolutionary sig-nificance of nonconscious mimicry.
Journal ofNonverbal Behavior, 27(3), 145-162.Lam, W. S. E. (2004).
Second language socialization ina bilingual chat room: Global and local consid-erations.
Language Learning & Technology,8(3), 44-65.Landauer, T. K., Foltz, P. W., & Laham, D. (1998).
In-troduction to latent semantic analysis.
Dis-course Processes, 25, 259-284.Milroy, L. (1980).
Language and social networks.
Ox-ford: Blackwell Publishers.Niederhoffer, K. G., & Pennebaker, J. W. (2002).
Lin-guistic style matching in social interaction.Journal of Language and Social Psychology,21(4), 337-360.Paolillo, J.
(2001).
Language variation on internet relaychat: A social network approach.
Journal ofSociolinguistics, 5(2), 180-213.Schutze, H. (1993).
Word space.
In S. J. Hanson, J. D.Cowan & C. L. Giles (Eds.
), Advances in Neu-ral Information Processing Systems 5.
SanMateo, CA: Morgan Kaufmann Publishers.Serafin, R., & Di Eugenio, B.
(2004, July 21-26, 2004).FLSA: Extending latent semantic analysis withfeatures for dialogue act classification.
Paperpresented at the 42nd Annual Meeting for theAssociation of Computational Linguistics(ACL04), Barcelona, Spain.Street, R. L., & Giles, H. (1982).
Speech accommoda-tion theory.
In M. E. Roloff & C. R.
Berger(Eds.
), Social cognition and communication(pp.
193-226).
London: Sage Publications.Wiemer-Hastings, P., & Graesser, A. C. (2000).
Select-a-Kibitzer: A computer tool that gives mean-ingful feedback on student compositions.Interactive Learning Environments, 8(2), 149?169.22
