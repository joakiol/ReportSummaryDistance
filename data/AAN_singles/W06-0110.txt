Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 72?78,Sydney, July 2006. c?2006 Association for Computational LinguisticsHybrid Modelsfor Chinese Named Entity RecognitionLishuang Li, Tingting Mao, Degen Huang, Yuansheng YangDepartment of Computer Science and EngineeringDalian University of Technology116023 Dalian, China{computer, huangdg, yangys}@dlut.edu.cnmaotingting1007@sohu.comAbstractThis paper describes a hybrid model andthe corresponding algorithm combiningsupport vector machines (SVMs) withstatistical methods to improve the per-formance of SVMs for the task of Chi-nese Named Entity Recognition (NER).In this algorithm, a threshold of the dis-tance from the test sample to the hyper-plane of SVMs in feature space is used toseparate SVMs region and statisticalmethod region.
If the distance is greaterthan the given threshold, the test sampleis classified using SVMs; otherwise, thestatistical model is used.
By integratingthe advantages of two methods, the hy-brid model achieves 93.18% F-measurefor Chinese person names and 91.49% F-measure for Chinese location names.1 IntroductionNamed entity (NE) recognition is a fundamentalstep to many language processing tasks such asinformation extraction (IE), question answering(QA) and machine translation (MT).
On its own,NE recognition can also provide users who arelooking for person or location names with quickinformation.
Palma and Day (1997) reported thatperson (PER), location (LOC) and organization(ORG) names are the most difficult sub-tasks ascompared to other entities as defined in MessageUnderstanding Conference (MUC).
So we focuson the recognition of PER, LOC and ORG enti-ties.Recently, machine learning approaches arewidely used in NER, including the hiddenMarkov model (Zhou and Su, 2000; Miller andCrystal, 1998), maximum entropy model(Borthwick, 1999), decision tree (Qin and Yuan,2004), transformation-based learning (Black andVasilakopoulos, 2002), boosting (Collins, 2002;Carreras et al, 2002), support vector machine(Takeuchi and Collier, 2002; Yu et al, 2004;Goh et al, 2003), memory-based learning (Sang,2002).
SVM has given high performance in vari-ous classification tasks (Joachims, 1998; Kudoand Matsumoto, 2001).
Goh et al (2003) pre-sented a SVM-based chunker to extract Chineseunknown words.
It obtained higher F-measurefor person names and organization names.Like other classifiers, the misclassified testingsamples by SVM are mostly near the decisionplane (i.e., the hyperplane of SVM in featurespace).
In order to increase the accuracy of SVM,we propose a hybrid model combining SVMwith a statistical approach for Chinese NER, thatis, in the region near the decision plane, statisti-cal method is used to classify the samples insteadof SVM, and in the region far away from the de-cision plane, SVM is used.
In this way, the mis-classification by SVM near the decision planecan be decreased significantly.
A higher F-measure for Chinese NE recognition can beachieved.In the following sections, we shall describeour approach in details.2 Recognition of Chinese Named EntityUsing SVMFirstly, we segment and assign part-of-speech(POS) tags to words in the texts using a Chineselexical analyzer.
Secondly, we break segmentedwords into characters and assign each characterits features.
Lastly, a model based on SVM toidentify Chinese named entities is set up bychoosing a proper kernel function.In the following, we will exemplify the personnames and location names to illustrate the identi-fication process.722.1 Support Vector MachinesSupport Vector Machines first introduced byVapnik (1996) are learning systems that use ahypothesis space of linear functions in a highdimensional feature space, trained with a learn-ing algorithm from optimization theory that im-plements a learning bias derived from statisticaltheory.
SVMs are based on the principle of struc-tural risk minimization.
Viewing the data aspoints in a high-dimensional feature space, thegoal is to fit a hyperplane between the positiveand negative examples so as to maximize thedistance between the data points and the hyper-plane.Given training examples:},1,1{,)},,(),...,,(),,{( 2211 +??
?= iill ynRxyxyxyxS  (1)ix is a feature vector (n dimension) of the i-thsample.
is the class (positive(+1) or nega-tive(-1) class) label of the i-th sample.
l  is thenumber of the given training samples.
SVMs findan ?optimal?
hyperplane:  to sepa-rate the training data into two classes.
The opti-mal hyperplane can be found by solving the fol-lowing quadratic programming problem (weleave the details to Vapnik (1998)):iy0)( =+ bwx.,...,2,1,0    ,0           tosubject),(21max1 11licyKyyiil1iililjjjiilii=???=???????
?
?== ==ji xx    (2)The function  is calledkernel function, is the mapping from pri-mary input space to feature space.
Given a testexample, its label y is decided by the followingfunction:)()()( jiji xxx,x ???=K)(x?.
]),(sgn[)( ?
?+?=svii bKyfixi xxx            (3)Basically, SVMs are binary classifiers, andcan be extended to multi-class classifiers in orderto solve multi-class discrimination problems.There are two popular methods to extend a bi-nary classification task to that of K classes: oneclass vs. all others and pairwise.
Here, we em-ploy the simple pairwise method.
This idea is tobuild  classifiers considering allpairs of classes, and final decision is given bytheir voting.2/)1( ??
KK2.2 Recognition of Chinese Person NamesBased on SVMWe use a SVM-based chunker, YamCha (Kudoand Masumoto, 2001), to extract Chinese personnames from the Chinese lexical analyzer.1) Chinese Person Names Chunk TagsWe use the Inside/Outside representation forproper chunks:I    Current token is inside of a chunk.O   Current token is outside of any chunk.B   Current token is the beginning of a chunk.A chunk is considered as a Chinese personname in this case.
Every character in the trainingset is given a tag classification of B, I or O, thatis, },,{ OIByi ?
.
Here, the multi-class decisionmethod pairwise is selected.2) Features Extraction for Chinese PersonNamesSince Chinese person names are identifiedfrom the segmented texts, the mistakes of wordsegmentation can result in error identification ofperson names.
So we must break words intocharacters and extract features for every charac-ter.
Table 1 summarizes types of features andtheir values.Type of feature ValuePOS tag n-B, v-I, p-SWhether a characteris a surname  Y or NCharacter surface form of the  character itselfThe frequency of acharacter in personnames tableY or NPrevious BIO tag B-character, I-character, O-characterTable 1.
Summary of Features and Their ValuesThe POS tag from the output of lexical analy-sis is subcategorized to include the position ofthe character in the word.
The list of POS tags isshown in Table 2.POS tag Description of the position of the character in a word<POS>-S One-character word<POS>-B first character in a multi-character word<POS>-I intermediate character in a multi-character word<POS>-E last character in a multi-character wordTable 2.
POS Tags in A WordIf the character is a surname, the value is as-signed to Y, otherwise assigned to N.The ?character?
is surface form of the charac-ter in the word.We extract all person names in January 1998of the People?s Daily to set up person names ta-ble and calculate the frequency of every charac-73ter (F) of person names table in the training cor-pus.
The frequency of F is defined as,)(F of number  total  thenames person of character a as F of number theFP = (4)if P(F) is greater than the given threshold, thevalue is assigned to Y, otherwise assigned to N.We also use previous BIO-tags as features.Whether a character is inside a person name ornot, it depends on the context of the character.Therefore, we use contextual information of twoprevious and two successive characters of thecurrent character as features.Figure 1 shows an example of features extrac-tion for the i-th character.
When training, the fea-tures of the character ?Min?
contains all the fea-tures surrounded in the frames.
If the same sen-tence is used as testing, the same features areused.PositionCharacterPOS tagsThe frequency of a character inthe person names tablePrevious BIO tags-2    -1    0   +1   +2Jiang  Ze   Min  zhu  xin-S  n-B  n-E  n-B  n-EY     Y    Y    N    NB     I    I    O    OiWhether the characteris a surnameY     N    N    N    YFigure 1.
An example of features extraction3) Choosing Kernel FunctionsHere, we choose polynomial kernel functions:to build an optimalseparating hyperplane.dii xxxxK ]1)[(),( +?=2.3 Recognition of Chinese Location NamesBased on SVMThe identification process of location names isthe same as that of person names except for thefeatures extraction.
Table 3 summarizes types offeatures and their values of location names ex-traction.Type of feature ValuePOS tag n-B, v-I, p-SWhether a characterappears in location namescharacteristic tableY or NCharacter surface form of the character itselfPrevious BIO tagB-character, I-character, O-characterTable 3.
Summary of Features and Their ValuesThe location names characteristic table is setup in advance, and it includes the characters orwords expressing the characteristics of locationnames such as ?sheng (province)?, ?shi (city)?,?xian (county)?etc.
If the character is in the loca-tion names characteristic table, the value is as-signed to Y, otherwise assigned to N.3 Statistical ModelsMany statistical models for NER have been pre-sented (Zhang et al, 1992; Huang et al, 2003etc).
In this section, we proposed our statisticalmodels for Chinese person names recognitionand Chinese location names recognition.3.1 Chinese Person NamesWe define a function to evaluate the person namecandidate PN.
The evaluated function Total-Probability(PN) is composed of two parts: thelexical probability LP(PN) and contextual prob-ability CP(PN) based on POS tags.
),()1()()( PNCPPNLPPNbilityTotalProba ?
?+?=  (5)where PN is the evaluated person name and ?
isthe balance cofficient.1) lexical probability LP(PN)We establish the surname table (SurName) andthe first name table (FirstName) from thestudents of year 1999 in a university (containing9986 person names).Suppose PN=LF1F2, where L is the surnameof the evaluated person name PN, Fi (i=1,2) is thei-th first name of the evaluated person name PN.The probability of the surname Pl(L) is definedas,)()()(00?
?=SurNameylll yPLPLP                                (6)where ,  is thenumber of L as the single or multiple surname ofperson names in the SurName.
)2)((log)( 20 += LNLPl )(LNThe probability of the first name Pf(F) isdefined as,)()()(00?
?=FirstNameyfff yPFPFP                                 (7)where ,  is thenumber of F in the FirstName.
)2)((log)( 20 += FNFPf )(FNThe lexical probability of the person name PNis defined as,)FLFif(PN       FP   FPCLPPNLP)LFif(PN                                FPLPPNLPffblfl212111))()(()()()()()(=+?
?==?=  (8)74where Cb is the balance cofficient between thesingle name and the double name.
Here,Cb=0.844 (Huang et al, 2001).2) contextual probability based on POS tagsCP(PN)Chinese person names have characteristiccontexual POS tags in real Chinese texts, forexample, in the phrase ?dui Zhangshuai shuo(say to Zhangshuai)?, the POS tag before theperson name ?Zhangshuai?
is prepnoun and verboccurs after the person name.
We define thebigram contextual probability CP(PN) of theperson name PN as the following equation:CP(PN)= ,),,(TotalPOSrposPNlposPersonPOS ><            (9)where lpos is the POS tag of the character beforePN (called POS forward), rpos is the POS tag ofthe character after PN (called POS backward),and is the numberof PN as a pereson name whose POS forward islpos and POS backward is rpos in training corpus.is the total number of the contexualPOS tags of every person name in the wholetraining corpus.
),,( >< rposPNlposPersonPOSTotalPOS3.2 Chinese Location NamesWe also define a function to evaluate the locationname candidate LN.
The evaluated function To-talProbability(LN) is composed of two parts: thelexical probability LP (LN) and contextual prob-ability CP (LN) based on POS tags.
),()1()()( LNCPLNLPLNbilityTotalProba ?
?+?= (10)where LN is the evaluated location name and?
isthe balance cofficient.1) lexical probability LP (LN)Suppose LN=F0F+S, F+=F1?Fn, (i=1,?,n),where F0 is the first character of the evaluatedlocation name LN, F+ is the middle characters ofthe evaluated location name LN, S is the lastcharacter of the evaluated location name LN.The probability of the first character of theevaluated location name is defined as )( 0FPh,)()()(00000 FPFPFPhhh ?=                                      (11)where ,  is thenumber of F)2)((log)( 0200 += FCFPh )( 0FC0 as the first character of locationnames in the Chinese Location Names Record.
)2)((log)( 0200 +?=?
FCFPh ,  is the totalnumber of F)( 0FC ?0 in the Chinese Location NamesRecord.The probability of the middle character of theevaluated location name is defined as )( +FPf,)()()(1?=+?=ni ififf FPFPFP                                  (12)where ,  is thenumber of F)2)((log)( 2 += iif FCFP )( iFCi as the i-th middle character of loca-tion names in the Chinese Location Names Re-cord.
)2)((log)( 2 +?=?
iif FCFP ,  is the totalnumber of F)( iFC ?i in the Chinese Location NamesRecord.The probability of the last character of theevaluated location name is defined as )(SPl,)()()(SPSPSPlll ?=                                          (13)where ,  is thenumber of  S as the last character of locationnames in the Chinese Location Names Record.
)2)((log)( 2 +?= SCSPl )(SC)2)((log)( 2 +?=?
SCSPl , )(SC ?
is the total numberof S in the Chinese Location Names Record.The lexical probability of the location nameLN is defined as),(/))()()(( 0 LNLenSPFPFPLN lfh ++= +    (14)where Len(LN) is the length of the evaluated lo-cation name LN.2) contextual probability based on POS tags CP(LN)Location names also have characteristiccontexual POS tags in real Chinese texts, forexample, in the phrase ?zai Chongqing shijunxing (to be held in Chongqing)?, the POS tagbefore the location name ?Chongqing?isprepnoun and verb occurs after the location name.We define the bigram contextual probabilityCP(LN) of the location name LN similar to thatof the person name PN in equation (9), where PNis replaced with LN.4 Recognition of Chinese Named EntityUsing Hybrid ModelAnalyzing the classification results (obtained bysole SVMs described in section 2) between Band I, B and O, I and O respectively, we find thatthe error is mainly caused by the second classifi-cation.
The samples which attribute to B classare misclassified to O class, which leads to Bclass vote?s diminishing and the correspondingnamed entities are lost.
Therefore the Recall islower.
In the meantime, the number of the mis-classified samples whose function distances tothe hyperplane of SVM in feature space are lessthan 1 can reach over 83% of the number of totalmisclassified samples.
That means the misclassi-75fication of a classifier is occurred in the region oftwo overlapping classes.
Considering this fact,we can expect to improve SVM using the follow-ing hybrid model.The hybrid model includes the followingprocedure:1) compute the distance from the test sampleto the hyperplane of SVM in feature space.2) compare the distance with given threshold.The algorithm of hybrid model can be de-scribed as follows:Suppose T is the testing set,(1) if  ?
?T , select Tx?
, else stop;(2) compute  ?=+?= liii bxxKyxg1),()((3) if ?>)(xg , output, else use the statisticmodels and output the returned results.
[ ]1,0??
))(sgn()( xgxf =(4) , repeat(1) { }xTT ?
?5 ExperimentsOur experimental results are all based on thecorpus of Peking University.5.1 Extracting Chinese Person NamesWe use 180 thousand characters corpus of year1998 from the People?s Daily as the training cor-pus and extract other sentences (containing 1526Chinese person names) as testing corpus to con-duct an open test experiment.
The results are ob-tained as follows based on different models.1) Based on Sole SVMAn experiment is carried out to recognize Chi-nese person names based on sole SVM by themethod as described in Section 2.
The Recall,Precision and F-measure using different numberof degree of polynomial kernel function aregiven in Table 4.
The best result is obtainedwhen d=2.Recall Precision F-measured=1 87.22% 94.26% 90.61%d=2 87.16% 96.10% 91.41%d=3 84.67% 95.14% 89.60%Table 4.
Results for Person Names ExtractionBased on Sole SVM2) Using Hybrid ModelAs mentioned in section 4, the test sampleswhich attribute to B class are misclassified to Oclass and therefore the Recall for person namesextraction from sole SVM is lower.
So we onlydeal with the test samples (B class and O class)whose function distances to the hyperplane ofSVM in feature space (i.e.
g(x)) is between 0 and?
.
We move class-boundary learned by SVMtowards the O class, that is, the O class samplesare considered as B class in that area.
93.64% ofthe Chinese person names in testing corpus arerecalled when ?
=0.9 (Here, ?
also representshow much the boundary is moved).
However, anumber of non-person names are also identifiedas person names wrongly and the Precision isdecreased correspondingly.
Table 5 shows theRecall and Precision of person names extractionwith different ?
.Recall Precision F-measure?
=1 93.05% 75.17% 83.16%?
=0.9 93.64% 81.75% 87.29%?
=0.8 93.51% 85.91% 89.55%?
=0.7 93.05% 88.31% 90.62%?
=0.6 92.39% 90.21% 91.29%?
=0.5 91.81% 91.87% 91.84%?
=0.4 91.02% 93.28% 92.13%?
=0.3 90.56% 95.05% 92.75%?
=0.2 90.03% 95.48% 92.68%?
=0.1 88.66% 95.82% 92.10%Table 5.
Results for Person Names Extractionwith Different ?We use the evaluated function TotalProbabil-ity(PN) as described in section 3 to filter thewrongly recalled person names using SVM.
Wetune?
in equation (5) to obtain the best results.The results based on the hybrid model with dif-ferent ?
are listed in Table 6 (when d=2).
Wecan observe that the result is best when ?
=0.4.Table 7 shows the results based on the hybridmodel with different ?
when =0.4.
We canobserve that the Recall rises and the Precisiondrops on the whole when??
increases.
The syn-thetic index F-measures are improved when ?
isbetween 0.1 and 0.8 compared with sole SVM.The best result is obtained when ?
=0.3.
The Re-call and the F-measure increases 3.27% and1.77% respectively.Recall Precision F-measure?
=0.1 90.37% 95.76% 92.99%?
=0.2 90.37% 96.03% 93.11%?
=0.3 90.43% 96.03% 93.15%?
=0.4 90.43% 96.10% 93.18%?
=0.5 90.63% 95.76% 93.13%?
=0.6 90.43% 95.97% 93.12%76?
=0.7 90.43% 95.90% 93.09%?
=0.8 90.43% 95.90% 93.09%?
=0.9 90.37% 95.90% 93.05%Table 6.
Results for Person Names ExtractionBased on The Hybrid Model with Different?Recall Precision F-measure?
=1 92.53% 84.96% 88.58%?
=0.9 93.05% 88.81% 90.88%?
=0.8 92.86% 90.95% 91.89%?
=0.7 92.46% 92.04% 92.25%?
=0.6 91.93% 93.22% 92.58%?
=0.5 91.48% 94.26% 92.85%?
=0.4 90.76% 95.25% 92.95%?
=0.3 90.43% 96.10% 93.18%?
=0.2 90.04% 96.15% 92.99%?
=0.1 88.73% 96.23% 92.32%Table 7.
Results for Person Names ExtractionBased on The Hybrid Model ( =0.4) ?5.2 Extracting Chinese Location NamesWe use 1.5M characters corpus of year 1998from the People?s Daily as the training corpusand extract sentences of year 2000 from the Peo-ple?s Daily (containing 2919 Chinese locationnames) as testing corpus to conduct an open testexperiment.
The results are obtained as followsbased on different models.1) Based on Sole SVMThe Recall, Precision and F-measure usingdifferent number of degree of polynomial kernelfunction are given in Table 8.
The best result isobtained when d=2.Recall Precision F-measured=1 84.66% 91.95% 88.16%d=2 86.69% 93.82% 90.12%d=3 86.27% 94.23% 90.07%Table 8.
Results for Location Names ExtractionBased on Sole SVM2) Using Hybrid ModelThe results for Chinese location names extrac-tion based on the hybrid model are listed in Ta-ble 9 (when d=2; ?
=0.2 in equation (10)).
Wecan observe that the Recall rises and the Preci-sion drops on the whole when ?
increases.
Thesynthetic index F-measures are improved when?
is between 0.1 and 0.7 compared with soleSVM.
The best result is obtained when ?
=0.3.The Recall increases 3.55%, the Precision de-creases 1.05% and the F-measure increases1.37%.Recall Precision F-measure?
=1 90.75% 83.00% 86.71%?
=0.9 90.85% 85.33% 88.01%?
=0.8 91.42% 87.42% 89.37%?
=0.7 91.65% 89.05% 90.33%?
=0.6 91.75% 90.38% 91.06%?
=0.5 91.32% 90.98% 91.15%?
=0.4 90.66% 91.87% 91.26%?
=0.3 90.24% 92.77% 91.49%?
=0.2 89.10% 93.28% 91.15%?
=0.1 87.83% 93.38% 90.52%Table 9.
Results for Location Names ExtractionBased on The Hybrid Model (?=0.2)6 Comparison with other workThe same corpus was also tested using statistics-based approach to identify Chinese person names(Huang et al 2001) and location names (Huangand Yue, 2003).
In their systems, lexical reliabil-ity and contextual reliability were used to iden-tify person names and location names calculatedfrom statistical information drawn from a train-ing corpus.
The results of our models and thestatistics-based methods (Huang 2001; Huang2003) are shown in Table 10 for comparison.
Wecan see that the Recall and F-measure in ourmethod all increase a lot.Recall Precision F-measureOurmodels 90.10% 96.15% 93.03%Personnames Huang(2001) 88.62% 92.37% 90.46%Ourmodels 90.24% 92.77% 91.49%Locationnames Huang(2003) 86.86% 91.48% 89.11%Table 10.
Results of Our Method and Huang(2001; 2003) for Comparison7 Conclusions and Future workWe recognize Chinese named entities using ahybrid model combining support vector ma-chines with statistical methods.
The model inte-grates the advantages of two methods and theexperimental results show that it can achievehigher F-measure than the sole SVM and indi-vidual statistical approach.Future work includes optimizing statisticalmodels, for example, we can add the probabilityinformation of Chinese named entities in realtexts to compute lexical probability, and we can77also use trigram models to compute contextualprobability.The hybrid model is expected to extend to for-eign names in transliteration to obtain improvedresults by sole SVMs.
The identification of trans-literated names by SVMs has been completed (Liet al, 2004).
The future work includes: set upstatistical models for transliterated names andcombine statistical models with SVMs to identifytransliterated names.ReferencesWilliam J.
Black and Argyrios Vasilakopoulos.
2002.Language Independent Named Entity Classifica-tion by Modified Transformation-based Learningand by Decision Tree Induction.
The 6th Confer-ence on Natural Language Learning, Taipei.Andrew Eliot Borthwick.
1999.
A Maximum EntropyApproach to Named Entity Recognition.
PhD Dis-sertation.
New York University.Xavier Carreras, Lluis Marquez, and Lluis Padro.2002.
Named Entity Extraction Using AdaBoost.The 6th Conference on Natural Language Learning,Taipei.Michael Collins.
2002.
Ranking Algorithms forNamed-entity Extraction: Boosting and the VotedPerceptron.
Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguis-tics (ACL-2002), Philadelphia, 489-496.Chooi-Ling Goh, Masayuki Asahara and Yuji Ma-tsumoto.
2003.
Chinese Unknown Word Identifica-tion Based on Morphological Analysis and Chunk-ing.
The Companion Volume to the Proceedings of41st Annual Meeting of the Association for Compu-tational Linguistics (ACL-2003), Sapporo, 197-200.De-Gen Huang, Yuan-Sheng Yang, and Xing Wang.2001.
Identification of Chinese Names Based onStatistics.
Journal of Chinese Information Process-ing, 15(2): 31-37.De-Gen Huang and Guang-Ling Yue.
2003.
Identifi-cation of Chinese Place Names Based on Statistics.Journal of Chinese Information Processing, 17(2):46-52.Thorsten Joachims.
1998.
Text Categorization withSupport Vector Machines: Learning with ManyRelevant Features.
In Proceedings of the EuropeanConference on Machine Learning, 1398:137-142.Taku Kudo and Yuji Matsumoto.
2001.
Chunkingwith Support Vector Machines.
In Proceedings ofNAACL 2001.Li-Shuang Li, Chun-Rong Chen, De-Gen Huang andYuan-Sheng Yang.
2004.
Identifying Pronuncia-tion-Translated Names from Chinese Texts Basedon Support Vector Machines.
Advances in NeuralNetworks-ISNN 2004, Lecture Notes in ComputerScience, Berlin Heidelberg, 3173: 983-988.Scott Miller and Michael Crystal.
1998.
BBN: De-scription of the SIFT System as Used for MUC-7.Proceedings of 7th Message Understanding Con-ference, Washington.David D. Palmer.
1997.
A Trainable Rule-Based Al-gorithm for Word Segmentation.
In Proc of 35th ofACL & 8th conf.
of EACL, 321-328.Wen Qin and Chun-Fa Yuan.
2004.
Identification ofChinese Unknown Word Based on Decision Tree.Journal of Chinese Information Processing, 18(1):14-19.Erik Tjong Kim Sang.
2002.
Memory-based NamedEntity Recognition.
The 6th Conference on NaturalLanguage Learning, Taipei.Koichi Takeuchi and Nigel Collier.
2002.
Use ofSupport Vector Machines in Extended Named En-tity Recognition.
The 6th Conference on NaturalLanguage Learning, Taipei.Vladimir N. Vapnik.
1995.
The Nature of StatisticalLearning Theory.
Springer-Verlag, Berlin.Vladimir N. Vapnik.
1998.
Statistical Learning The-ory.
John Wiley & Sons, New York.Ying Yu, Xiao-Long Wang, Bing-Quan Liu, and HuiWang.
2004.
Efficient SVM-based Recognition ofChinese Personal Names.
High Technology Letters,10(3): 15-18.Jun-Sheng Zhang, Shun-De Chen, Ying Zheng, Xian-Zhong Liu and Shu-Jin Ke.
1992.
Large-Corpus-Based Methods for Chinese Personal Name.
Jour-nal of Chinese Information Processing, 6(3): 7-15.Guo-Dong Zhou and Jian Su.
2002.
Named EntityRecognition Using an HMM-based Chunk Tagger.Proceedings of the 40th Annual Meeting of theACL, Philadelphia, 473-480.78
