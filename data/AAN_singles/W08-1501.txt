Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 1?4Manchester, August 2008Mitigation of data sparsity in classifier-based translationEmil Ettelaie, Panayiotis G. Georgiou, Shrikanth S. NarayananSignal Analysis and Interpretation LaboratoryMing Hsieh Department of Electrical EngineeringViterbi School of EngineeringUniversity of Southern Californiaettelaie@usc.eduAbstractThe concept classifier has been used as atranslation unit in speech-to-speech trans-lation systems.
However, the sparsity ofthe training data is the bottle neck of itseffectiveness.
Here, a new method basedon using a statistical machine translationsystem has been introduced to mitigate theeffects of data sparsity for training classi-fiers.
Also, the effects of the backgroundmodel which is necessary to compensatethe above problem, is investigated.
Exper-imental evaluation in the context of cross-lingual doctor-patient interaction applica-tion show the superiority of the proposedmethod.1 IntroductionStatistical machine translation (SMT) methodsare well established in speech-to-speech transla-tion systems as the main translation technique(Narayanan et al, 2003; Hsiao et al, 2006).
Dueto their flexibility these methods provide a goodcoverage of the dialog domain.
The fluency ofthe translation, however, is not guaranteed.
Dis-fluencies of spoken utterances plus the speech rec-ognizer errors degrade the translation quality evenmore.
All these ultimately affect the quality of thesynthesized speech output in the target language,and the effectiveness of the concept transfer.It is quite common, though, to use other means oftranslation in parallel to the SMT methods (Gao etal., 2006; Stallard et al, 2006).
Concept classifica-tion, as an alternative translation method, has beensuccessfully integrated in speech-to-speech transla-tors (Narayanan et al, 2003; Ehsani et al, 2006).A well defined dialog domain, e.g.
doctor-patientdialog, can be partly covered by a number of con-cept classes.
Upon a successful classification ofthe input utterance, the translation task reduces toc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.synthesizing a previously created translation of theconcept, as a mere look up.
Since the main goal insuch applications is an accurate exchange of con-cepts, this method would serve the purpose as longas the input utterance falls within the coverage ofthe classifier.
This process can be viewed as a quan-tization of a continuous ?semantic?
sub-space.
Theclassifier is adequate when the quantization error issmall (i.e.
the derived concept and input utteranceare good matches), and when the utterance falls inthe same sub-space (domain) as the quantizer at-tempts to cover.
Since it is not feasible to accu-rately cover the whole dialog domain (since a largenumber of quantization levels needed) the classi-fier should be accompanied by a translation systemwith a much wider range such as an SMT engine.A rejection mechanism can help identify the casesthat the input utterance falls outside the classifiercoverage (Ettelaie et al, 2006).In spite of this short coming, the classifier-based translator is an attractive option for speech-to-speech applications because of its tolerance to?noisy?
input and the fluency of its output, when itoperates close to its design parameters.
In practicethis is attainable for structured dialog interactionswith high levels of predictability.
In addition, it canprovide the users with both an accurate feedbackand different translation options to choose from.The latter feature, specially, is useful for applica-tions like doctor-patient dialog.Building a concept classifier starts with identify-ing the desired concepts and representing them withcanonical utterances that express these concepts.
Agood set of concepts should consist of the ones thatare more frequent in a typical interaction in the do-main.
For instance in a doctor-patient dialog, theutterance ?Where does it hurt??
is quite commonand therefore its concept is a good choice.
Phrasebooks, websites, and experts?
judgment are some ofthe resources that can be used for concept selection.Other frequently used concepts include those thatcorrespond to basic communicative and social as-pects of the interaction such as greeting, acknowl-edgment and confirmation.After forming the concept space, for each class,1utterances that convey its concept must be gath-ered.
Hence, this training corpus would consist ofa group of paraphrases for each class.
This form ofdata are often very difficult to collect as the numberof classes grow.
Therefore, the available trainingdata are usually sparse and cannot produce a classi-fication accuracy to the degree possible.
Since theclassifier range is limited, high accuracy within thatrange is quite crucial for its effectiveness.
One ofthe main issues is dealing with data sparsity.
Othertechniques have also been proposed to improve theclassification rates.
For example in (Ettelaie et al,2006) the accuracy has been improved by introduc-ing a dialog model.
Also, a background model hasbeen used to improve the discrimination ability of agiven concept class model.In this work a novel method for handling thesparsity is introduced.
This method utilizes an SMTengine to map a single utterance to a group of them.Furthermore, the effect of the background model onclassification accuracy is investigated.Section 2 reviews the concept classification pro-cess and the background model.
In Section 3 thesparsity handling method using an SMT is intro-duced.
Data and experiments are described in Sec-tion 4.
The results are discussed in Section 5.2 Concept classifier and backgroundmodelThe concept classifier based on the maximum like-lihood criterion can be implemented as a languagemodel (LM) scoring process.
For each class a lan-guage model is built using data expressing the classconcept.
The classifier scores the input utteranceusing the class LM?s and selects the class with high-est score.
In another word if C is the set of conceptclasses and e is the input utterance, the classifica-tion process is,c?
= argmaxc?C{Pc(e | c)} (1)where Pc(e | c) is the score of e from the LM ofclass c. The translation job is concluded by playingout a previously constructed prompt that expressesthe concept c?
in the target language.It is clear that a class with limited training dataitems will have an undertrained associated LM withpoor coverage.
In practice such a model fails to pro-duce a usable LM score and leads to a poor classifi-cation accuracy.
Interpolating the LM with a back-ground language model results in a smoother model(Stolcke, 2002) and increases the overall accuracyof the classifier.The background model should be built from alarger corpus that fairly covers the domain vocab-ulary.
The interpolation level can be optimized forthe best performance based on heldout set.3 Handling sparsity by statisticalmachine translationThe goal is to employ techniques that limit the ef-fects of data sparsity.
What is proposed here is togenerate multiple utterances ?
possibly with lowerquality ?
from a single original one.
One approachis to use an SMT to generate n-best lists of trans-lation candidates for the original utterances.
Suchlists are ranked based on a combination of scoresfrom different models (Ney et al, 2000).
The hy-pothesis here is that for an SMT trained on a largecorpus, the quality of the candidates would not de-grade rapidly as one moves down the n-best list.Therefore a list with an appropriate length wouldconsist of translations with acceptable quality with-out containing a lot of poor candidates.
This pro-cess would result in more data, available for train-ing, at the cost of using noisier data.Although the source language of the SMT mustbe the same as the classifier?s, its target languagecan be selected deliberately.
It is clear that a lan-guage with large available resources (in the form ofparallel corpora with the source language) must beselected.
For simplicity this language is called the?intermediate language?
here.A classifier in the intermediate language can bebuilt by first generating an n-best list for everysource utterance in the classifier?s training corpus.Then the n-best lists associated with each class arecombined to form a new training set.
The classLM?s are now built from these training sets ratherthan the original sets of the source utterances.To classify a source utterance e, first the SMTis deployed to generate an n-best list (in the inter-mediate language) from it.
The list will consist ofcandidates f1, f2,..., fn.
The classification processcan be reformulated as,c?
= argmaxc?C{n?i=1?Pc(fi| c)}(2)Here,?Pc(fi| c) is the score of the ithcandidate fifrom the LM of class c. The scores are consideredin the probability domain.The new class LM?s can also be smoothed by in-terpolation with a background model in the inter-mediate language.4 Data and Experiments4.1 DataThe data used in this work were originally collectedfor, and used in, the Transonics project (Narayananet al, 2003) to develop an English/Farsi speech-to-speech translator in the doctor-patient interactiondomain.
For the doctor side, 1,269 concept classeswere carefully chosen using experts?
judgment andmedical phrase books.
Then, for each concept, En-glish data were collected from a website, a web-based game, and multiple paraphrasing sessions atthe Information Sciences Institute of the University2Conventional n-best length(baseline) 100 500 1,000 2,000Accuracy [%]74.9 77.4 77.5 76.8 76.4Relative errorreduction [%]0.0 10.0 10.4 7.6 6.0Accuracy in4-best [%]88.6 90.7 91.0 91.3 90.5Relative errorreduction [%]0.0 18.4 21.1 23.7 16.7Table 1: Classification accuracy for the conventional methodand the proposed method with different lengths of n-best listof Southern California.
The total size of the dataset consists of 9,893 English phrases.As the test corpus for this work, 1,000 phraseswere randomly drawn from the above set and therest were used for training.
To make sure that thetraining set covered every class, one phrase perclass was excluded from the test set selection pro-cess.To generate the n-best lists, a phrase based SMT(Koehn et al, 2003) was used.
The intermedi-ate language was Farsi and the SMT was trainedon a parallel English/Farsi corpus with 148K lines(1.2M words) on the English side.
This corpuswas also used to build the classification backgroundmodels in both languages.
The SMT was opti-mized using a parallel development set with 915lines (7.3K words) on the English side.4.2 Classification Accuracy MeasuresClassifier accuracy is often used as the the qual-ity indicator of the classification task.
However, itis common in the speech-to-speech translation sys-tems to provide the user with a short list of potentialtranslations to choose from.
For example the userof system in (Narayanan et al, 2003) is providedwith the top four classifier outputs.
In such cases, itis practically useful to measure the accuracy of theclassifier within its n-best outputs (e.g., n = 4 forthe above system).
In this work the classificationaccuracy was measured on both the single outputand the 4-best outputs.4.3 ExperimentsTo compare the proposed method with the con-ventional classification, a classifier based on eachmethod was put to test.
In the proposed method,it is expected that the accuracy is affected by thelength of the n-best lists.
To observe that, n-bestlists of lengths 100, 500, 1000, and 2000 were usedin the experiments.
The results are shown in Table1.
In all of the above experiments the backgroundinterpolation factor was set to 0.9 which is closeto the optimum value obtained in (Ettelaie et al,2006).To examine the effect of the background model,the conventional and proposed methods were triedwith different values of the interpolation factor ?
(the background model is weighted by 1 ?
?).
Forthe conventional method the length of the n-bestlist was set to 500.
Figure 1 shows the accuracy0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.045%50%55%60%65%70%75%80%85%90%95%Conv.
4-bestConv.New 4-bestNewBackground Interpolation FactorAccuracy0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.00%5%Background Interpolation Factor (?
)AccuracyFigure 1: The effect of background model on classificationaccuracychanges with respect to the interpolation factor forthese two methods.5 DiscussionTable 1 shows the advantage of the proposedmethod over the conventional classification with arelative error rate reduction up to 10.4% (achievedwhen the length of the SMT n-best list was 500).However, as expected, this number decreases withlonger SMT n-best lists due to the increased noisepresent in lower ranked outputs of the SMT.Table 1 also shows the accuracy within 4-bestclassifier outputs for each method.
In that casethe proposed method showed an error rate whichwas relatively 23.7% lower than the error rate ofthe conventional method.
That was achieved at thepeak of the accuracy within 4-best, when the lengthof the SMT n-best list was 1,000.
In this case too,further increase in the length of the n-best list ledto an accuracy degradation as the classifier modelsbecame noisier.The effect of the background model on classifieraccuracy is shown in Figure 1.
The figure showsthe one-best accuracy and the accuracy within 4-best outputs, versus the background interpolationfactor (?)
for both conventional and proposed meth-ods.
As the curves indicate, with ?
equal to zero theclassifier has no discriminating feature since all theclass scores are driven solely from the backgroundmodel.
However, a slight increase in ?, leads toa large jump in the accuracy.
The reason is thatthe background model was built from a large gen-eral domain corpus and hence, had no bias towardany of the classes.
With a small ?, the score fromthe background model dominates the overall classscores.
In spite of that, the score differences causedby the class LM?s are notable in improving the clas-sifier performance.As ?
increases the role of the class LM?s be-comes more prominent.
This makes the classifiermodels more discriminative and increases its accu-racy as shown in Figure 1.
When the factor is inthe close vicinity of one, the smoothing effect ofthe background model diminishes and leaves the3classes with spiky models with very low vocabu-lary coverage (lots of zeros).
This leads to a rapiddrop in accuracy as ?
reaches one.Both the conventional and proposed methodsfollow the above trend as Figure 1 shows, al-though, the proposed method maintains its supe-riority throughout the range of ?
that was exam-ined.
The maximum measured accuracies for con-ventional and proposed methods were 75.2% and78.7% respectively and was measured at ?
= 0.999for both methods.
Therefore, the error rate of theproposed method was relatively 14.1% lower thanits counterpart from the conventional method.Figure 1 also indicates that when the accuracy ismeasured within the 4-best outputs, again the pro-posed method outperforms the conventional one.The maximum 4-best accuracy for the conventionalmethod was measured at the sample point ?
= 0.9and was equal to 88.6%.
For the proposed method,that number was measured as 91.5% achieved at thesample point ?
= 0.999.
In another words, consid-ering the 4-best classifier outputs, the error rate ofthe proposed method was relatively 25.4% lower.6 ConclusionThe proposed language model based method can beused to improve the accuracy of the concept classi-fiers specially in the case of sparse training data.It outperformed the conventional classifier, trainedon the original source language paraphrases, in theexperiments.
With this method, when the input ut-terance is within the classification domain, the clas-sifier can be viewed as a filter that produces fluenttranslations (removes the ?noise?)
from the SMToutput.The experiments also emphasized the impor-tance of the background model, although indicatedthat the classification accuracy was not very sen-sitive to the value of the background interpolationfactor.
This relieves the developers from the finetuning of that factor and eliminates the need for adevelopment data set when a suboptimal solution isacceptable.We believe that significant improvements to thetechnique can be made through the use of weightedn-best lists based on the SMT scores.
In additionwe believe that using a much richer SMT enginecould provide significant gains through increaseddiversity in the output vocabulary.
We intend to ex-tend on this work through the use of enriched, mul-tilingual SMT engines, and the creation of multipleclassifiers (in several intermediate languages).7 AcknowledgmentThis work was supported in part by funds fromDARPA.ReferencesEhsani, F., J. Kinzey, D. Master, K. Sudre, D. Domingo,and H. Park.
2006.
S-MINDS 2-way speech-to-speech translation system.
In Proc.
of the Medi-cal Speech Translation Workshop, Conference of theNorth American Chapter of the Association for Com-putational Linguistics on Human Language Technol-ogy (NAACL-HLT), pages 44?45, New York, NY,USA, June.Ettelaie, E., P. G. Georgiou, and S. Narayanan.
2006.Cross-lingual dialog model for speech to speechtranslation.
In Proc.
of the Ninth International Con-ference on Spoken Language Processing (ICLSP),pages 1173?1176, Pittsburgh, PA, USA, September.Gao, Y., L. Gu, B. Zhou, R. Sarikaya, M. Afify, H. Kuo,W.
Zhu, Y. Deng, C. Prosser, W. Zhang, and L. Be-sacier.
2006.
IBM MASTOR SYSTEM: Multilin-gual automatic speech-to-speech translator.
In Proc.of the Medical Speech Translation Workshop, Con-ference of the North American Chapter of the As-sociation for Computational Linguistics on HumanLanguage Technology (NAACL-HLT), pages 53?56,New York, NY, USA, June.Hsiao, R., A. Venugopal, T. Kohler, Y. Zhang,P.
Charoenpornsawat, A. Zollmann, S. Vogel, A. W.Black, T. Schultz, and A. Waibel.
2006.
Optimiz-ing components for handheld two-way speech trans-lation for an English-Iraqi Arabic system.
In Proc.
ofthe Ninth International Conference on Spoken Lan-guage Processing (ICLSP), pages 765?768, Pitts-burgh, PA, USA, September.Koehn, P., F. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
of the Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology (NAACL-HLT), volume 1, pages 48?54,Edmonton, AB, Canada, May-June.Narayanan, S., S. Ananthakrishnan, R. Belvin, E. Ette-laie, S. Ganjavi, P. Georgiou, C. Hein, S. Kadambe,K.
Knight, D. Marcu, H. Neely, N. Srinivasamurthy,D.
Traum, and D. Wang.
2003.
Transonics: Aspeech to speech system for English-Persian inter-actions.
In Proc.
of IEEE Workshop on AutomaticSpeech Recognition and Understanding (ASRU),pages 670?675, St.Thomas, U.S. Virgin Islands,November-Decmeber.Ney, H., S. Nie?en, F. J. Och, C. Tillmann, H. Sawaf,and S. Vogel.
2000.
Algorithms for statistical trans-lation of spoken language.
IEEE Trans.
on Speechand Audio Processing, Special Issue on LanguageModeling and Dialogue Systems, 8(1):24?36, Jan-uary.Stallard, D., F. Choi, K. Krstovski, P. Natarajan,R.
Prasad, and S. Saleem.
2006.
A hybridphrase-based/statistical speech translation system.In Proc.
of the Ninth International Conference onSpoken Language Processing (ICLSP), pages 757?760, Pittsburgh, PA, USA, September.Stolcke, A.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proc.
of the International Con-ference on Spoken Language Processing (ICSLP),pages 901?904, Denver, CO, USA, September.4
