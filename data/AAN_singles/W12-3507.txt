Proceedings of the 1st Workshop on Speech and Multimodal Interaction in Assistive Environments, pages 43?46,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Bengali Speech Synthesizer on Android OSSankar Mukherjee, Shyamal Kumar Das MandalCenter for Educational TechnologyIndian Institute of Technology Kharagpursankar1535@gmail.comsdasmandal@cet.iitkgp.ernet.inAbstractDifferent Bengali TTS systems are alreadyavailable on a resourceful platform such as apersonal computer.
However, porting thesesystems to a resource limited device such as amobile phone is not an easy task.
Practicalaspects including application size andprocessing time have to be concerned.
Thispaper describes the implementation of aBengali speech synthesizer on a mobile device.For speech generation we used EpochSynchronous Non Overlap Add (ESNOLA)based concatenative speech synthesis techniquewhich uses the partnemes as the smallest signalunits for concatenations.1 IntroductionTechnologies for handheld devices with openplatforms have made rapid progresses.
Recentlyopen-platforms Android is getting momentum.Mobile devices with microphone and speaker,video camera, touch screen, GPS, etc, are served assensors for experiencing with augmented reality inhuman life.
Speech synthesis may become one ofthe main modalities on mobile devices as thescreen size and several application scenarios (e.g.,driving, jogging) limits the use of visual modality.Optimizing a speech synthesis system on mobiledevices is a challenging task because the storagecapacity and the computing performance arelimited.
Even if the storage capacity of the deviceis quite high, it is unlikely that users will let e.g.,the half of their storage for speech synthesispurposes.
So it is necessary to have small footprint.Until now, text-to-speech applications have beendeveloped on many platforms, such as PC,electronic dictionary and mobile device.
However,most applications are for English language.
Earlyworks on developing a TTS system on a mobiledevice focused mainly on migration of an existingTTS system from a resourceful platform to aresource-limited platform (W. Black and K. A.Lenzo, 2001; Hoffmann, R et al, 2003).
Most ofthe effort was spent on code optimization anddatabase compression.
Since the space was quitelimited, only a small diphone database could beutilized which reduced the quality of synthesizedspeech.
To improve the output speech quality someresearchers attempted to apply a unit selectiontechnique on a resource limited device.
(Tsiakoulis, et al 2008) used a database smallenough for an embedded device without muchreduction in speech quality.
(Pucher, M. andFrohlich, 2005) used a large unit selection databasebut synthesize an output speech on a server andthen transferred the wave form to a mobile deviceover a network.Bengali TTS systems have been alreadydeveloped and produced reasonably acceptablesynthesized output quality on PC, as ShyamalKumar Das Mandal and Asoke Kumar Datta(2007).
However the same has not yet beenimplemented for resource-limited or embeddeddevices such as mobile phones.The goal of our research is to develop a Bengalispeech synthesizer that can produce an acceptablequality of synthesized output in almost real-timeon mobile device.432  Speech Synthesis TechniquesSpeech synthesis involves the algorithmicconversion of input text data to speech waveforms.Speech synthesizers are characterized by themethods used for storage, encoding and synthesisof the speech.
The synthesis method is determinedby the vocabulary size, as all possible utterances ofthe language need to be modeled.
There aredifferent approaches to speech synthesis, such asrule-based, articulatory modeling andconcatenative technique.
Recent speech researchhas been directed towards concatenative speechsynthesizers.
We develop our synthesizer based onEpoch Synchronous Non Overlap Add (ESNOLA)concatenative speech synthesis method, asShyamal Kumar Das Mandal and Asoke KumarDatta (2007).ESNOLA allows judicious selection of signalsegment so that the smaller fundamental parts ofthe phoneme may be used as unit for reducing boththe number and the size of the signal elements inthe dictionary.
This is called Partnemes.
Furtherthe methodology of concatenation providesadequate processing for proper matching betweendifferent segments during concatenation and itsupports unlimited vocabulary without decreasingthe quality.3 TTS  System Based on ESNOLA MethodA schematic diagram of the speech synthesissystem is shown in Figure 1.Figure 1: Text-to-Speech process diagramThe Text-to-Speech system consists of two mainparts: Text analysis module and Synthesizermodule.3.1 Text Analysis ModuleThe text analysis module has two broad sectionsone is the phonological analysis module and otheris the analysis of the text for prosody andintonation.
Bangla is a syllabic script, phonologicalanalysis i.e.
Grapheme to Phoneme conversation isa formidable problem (Suniti Kumar Chatterji,2002; Sarkar Pabitra, 1990) specially found in caseof two vowels /a/ and /e/ and some consonantclusters.
A set of phonological rule includingexception dictionary is developed andimplemented, as (Basu, J et al, 2009).
Thephonological rules also depend upon POS andsemantics.
But due to its requirement of languageanalysis it is taken care by exception dictionary.3.2 Synthesizer ModuleSynthesizer module has two parts.
First generatetoken and second combine splices of pre-recordedspeech and generate the synthesized voice outputusing ESNOLA approach as in Shyamal Kr DasMandal, et al (2007).
In ESNOLA approach, thesynthesized output is generated by concatenatingthe basic signal segments from the signaldictionary at epoch positions.
The epochs are mostimportant for signal units, which represent vocalicor quasi-periodic sounds.
An epoch position isrepresented in Figure 2.Figure 2: Epoch position of a speech segmentSteady states in the nucleus vowel segment ofthe synthesized signal are generated by the linearinterpolation with appropriate weights of the lastperiod and the first period respectively of thepreceding and the succeeding segments.
Thegenerated signals require some smoothing at thepoint of concatenation.
This is achieved by aproper windowing of the output signal withouthampering the spectral quality.44The synthesized voiced output for the name??????
is shown in Figure 3.Figure 3:  Represent a synthesized voiced output for agiven text input / b?arot /4 Implementation on AndroidThe exact system specification is shown on Table1.
An Android application will run on a mobiledevice with limited computing power and storage,and constrained battery life.
Because of this, itshould be efficient.
Following actions are taken torun the application on Android ?Table 1: System SpecificationsFeatures LG Optimus One P500Operating System Android OS, v2.2Processor ARM 11CPU speed 600 MHzRAM 512 MBDisplay 256K colors, TFTInput method Touch-screenConnectivity USB4.1 Memory ManagementOn Android, a Context is an abstract class which isused for many operations but mostly to load andaccess resources.
But keeping a long-livedreference to a Context and preventing the GC(Garbage Collection) from collecting it causesmemory leaks issues.
But in here this system has tohave long-lived objects that needed a context.
Soto overcome this Application-Context Class isused.
This context will live as long as yourapplication is alive and does not depend on theactivities life cycle.
It is obtained by callingActivity.getApplication().
Apart from that thepartneme database is kept in external storage card.Owing to memory constraints, the speech outputfile is deleted after the speech is produced.4.2 Optimizing the Source CodeOn Android virtual method calls are expensive,much more so than instance field lookups.
Socommon object-oriented programming practicesare followed and have getters and setters in thepublic interface.All total 596 sound files are stored in thepartneme database.
Total size of the database is 1.0Mb and application size is 2.26 Mb.The TTS system has two major functionality.Firstly, it can read the Bengali massage stored inthe phones inbox and secondly, user can generateBengali speech by typing the Bengali word inEnglish alphabet format.The input text in English alphabet can be keyedin the provided text box (Figure 3).
The ?Speak tome?
button generates the speech file correspondingto the text keyed in and plays the audio filegenerated.
Graphical user interface is shown inFigure.
4-5.Figure 4        Figure 5Fig.
4-5 is the internal interface of the applicationApplication can be distributed to end userdirectly by developer website or by AndroidMarket an on device application store.
This TTSapplication has not published yet but it can bedownloaded on the android device connected to adesktop PC through the USB port.5 Performance And Quality Evaluation5.1 Processing Speed TestMeasurement of processing speed is done bycounting the synthesis time manually.
We startedmeasuring the time when a "speak" button (Figure5) is pressed until the first speech sound ispronounced.
Results are shown in Table 2.45Table 2 speed time testUtterance(words)No.
ofsyllablesProcessing Speed[in sec.
]2 6 0.453 8 0.564 11 0.865 15 1.195.2 Speech Quality EvaluationTo measure the output speech quality 5 subjects, 3male (L1, L2, L3) and 2 female (L4, L5), areselected and their age ranging from 24 to 50.
Allsubjects are native speakers of Standard ColloquialBangla and non speech expert.
10 original (asuttered by speaker) and modified (as uttered withandroid version) sentences are randomly presentedfor listening and their judgment in 5 point score(1=less natural ?
5=most natural).
Table 3represents the tabulated mean opinion scores for allsentences of each subject for original as well asmodified sentences.Table 3 result of listing testL1 L2 L3 L4 L5ModifiedSentencesAvg 3.82 1.76 2.62 2.73 3.5Stdev 0.73 1.15 0.82 0.81 0.5OriginalSentencesAvg 4.91 4.33 4.82 4.76 4.8Stdev 0.11 0.23 0.83 0.42 0.3The total average score for the original sentences is4.72 and the modified sentence is 2.88.
Figure 6graphically represents the mean opinion score tovisualize the closeness of the employed prosodicrules to the original sentences.Figure 6: Bar chart of the listening test6 Conclusion And Future WorksIn this paper, we describe our implementation of aBengali speech synthesizer on a mobile device.Our goal is to develop a text-to-speech (TTS)application that can produce an output speech inalmost real-time on an average smart phone.
Oursynthesizer is based on Epoch Synchronous NonOverlap Add (ESNOLA) suitable forimplementing a fast and small TTS application.We modified several components in ESNOLA tomake it run on android device.
As for the outputsound quality of TTS, there is plenty of room forimprovement.
We also plan to develop a morecomplete text analysis module which can handlethe prosody at the sentence better way.ReferencesBasu, J.,  Basu, T., Mitra, M.,  Mandal, S. 2009.Grapheme to Phoneme (G2P) conversion for Bangla.Speech Database and Assessments, OrientalCOCOSDA International Conference,  pp.
66-71.Chatterji Suniti Kumar.
2002.
The Original andDevelopment of the Bengali Language.
Published byRupa.Co, ISBN 81-7167-117-9, 1926.Das Mandal Shyamal Kr, Saha Arup, Sarkar IndranilDatta Asoke Kumar.
2005.
Phonological,International & Prosodic Aspects of ConcatenativeSpeech Synthesizer Development for Bangla.Proceeding of SIMPLE-05, pp56-60.Hoffmann, R et aL.
2003.
A Multilingual TTS Systemwith less than 1: MByte Footprint for EmbeddedApplications.
Proceeding of  ICASSP.M.
Pucher, and P. Frohlich.
2005.
A User Study on theInfluence of Mobile Device Class, SynthesisMethod, Data Rate and Lexicon on SpeechSynthesis Quality.
Inter Speech.P.
Tsiakoulis, A. Chalamandaris, S. Karabetsos, and S.Raptis.
2008.
A Statistical Method for DatabaseReduction for Embedded Unit Selection SpeechSynthesis.
ICASSP, Las Vegas, Nevada, USA.Sarkar Pabitra.
1990.
Bangla Balo.
Prama prakasani.Shyamal Kumar Das MandaI and Asoke Kumar Datta,.2007.
Epoch synchronous non-overlap-add(ESNOLA) method-based concatenative speechsynthesis system for Bangla.
6th ISCA Workshop onSpeech Synthesis, Germany, pp.
351-355.W.
Black and K. A. Lenzo.
2001.
Flite: a small fast nm-time synthesis engine.
4th ISCA Workshop onSpeech Synthesis.46
