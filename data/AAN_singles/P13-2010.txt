Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 53?57,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsA relatedness benchmark to test the role of determinersin compositional distributional semanticsRaffaella Bernardi and Georgiana Dinu and Marco Marelli and Marco BaroniCenter for Mind/Brain Sciences (University of Trento, Italy)first.last@unitn.itAbstractDistributional models of semantics cap-ture word meaning very effectively, andthey have been recently extended to ac-count for compositionally-obtained rep-resentations of phrases made of contentwords.
We explore whether compositionaldistributional semantic models can alsohandle a construction in which grammat-ical terms play a crucial role, namely de-terminer phrases (DPs).
We introduce anew publicly available dataset to test dis-tributional representations of DPs, and weevaluate state-of-the-art models on this set.1 IntroductionDistributional semantics models (DSMs) approx-imate meaning with vectors that record the dis-tributional occurrence patterns of words in cor-pora.
DSMs have been effectively applied to in-creasingly more sophisticated semantic tasks inlinguistics, artificial intelligence and cognitive sci-ence, and they have been recently extended tocapture the meaning of phrases and sentences viacompositional mechanisms.
However, scaling upto larger constituents poses the issue of how tohandle grammatical words, such as determiners,prepositions, or auxiliaries, that lack rich concep-tual content, and operate instead as the logical?glue?
holding sentences together.In typical DSMs, grammatical words are treatedas ?stop words?
to be discarded, or at best usedas context features in the representation of contentwords.
Similarly, current compositional DSMs(cDSMs) focus almost entirely on phrases madeof two or more content words (e.g., adjective-nounor verb-noun combinations) and completely ig-nore grammatical words, to the point that eventhe test set of transitive sentences proposed byGrefenstette and Sadrzadeh (2011) contains onlyTarzan-style statements with determiner-less sub-jects and objects: ?table show result?, ?priest saymass?, etc.
As these examples suggest, however,as soon as we set our sight on modeling phrasesand sentences, grammatical words are hard toavoid.
Stripping off grammatical words has moreserious consequences than making you sound likethe Lord of the Jungle.
Even if we accept theview of, e.g., Garrette et al (2013), that the log-ical framework of language should be left to otherdevices than distributional semantics, and the lat-ter should be limited to similarity scoring, still ig-noring grammatical elements is going to dramat-ically distort the very similarity scores (c)DSMsshould provide.
If we want to use a cDSM forthe classic similarity-based paraphrasing task, themodel shouldn?t conclude that ?The table showsmany results?
is identical to ?the table shows noresults?
since the two sentences contain the samecontent words, or that ?to kill many rats?
and ?tokill few rats?
are equally good paraphrases of ?toexterminate rats?.We focus here on how cDSMs handle determin-ers and the phrases they form with nouns (deter-miner phrases, or DPs).1 While determiners areonly a subset of grammatical words, they are alarge and important subset, constituting the natu-ral stepping stone towards sentential distributionalsemantics: Compositional methods have alreadybeen successfully applied to simple noun-verb andnoun-verb-noun structures (Mitchell and Lapata,2008; Grefenstette and Sadrzadeh, 2011), and de-terminers are just what is missing to turn theseskeletal constructions into full-fledged sentences.Moreover, determiner-noun phrases are, in super-ficial syntactic terms, similar to the adjective-nounphrases that have already been extensively studiedfrom a cDSM perspective by Baroni and Zampar-1Some linguists refer to what we call DPs as noun phrasesor NPs.
We say DPs simply to emphasize our focus on deter-miners.53elli (2010), Guevara (2010) and Mitchell and Lap-ata (2010).
Thus, we can straightforwardly extendthe methods already proposed for adjective-nounphrases to DPs.We introduce a new task, a similarity-basedchallenge, where we consider nouns that arestrongly conceptually related to certain DPs andtest whether cDSMs can pick the most appropri-ate related DP (e.g., monarchy is more related toone ruler than many rulers).2 We make our newdataset publicly available, and we hope that it willstimulate further work on the distributional seman-tics of grammatical elements.32 Composition modelsInterest in compositional DSMs has skyrocketedin the last few years, particularly since the influ-ential work of Mitchell and Lapata (2008; 2009;2010), who proposed three simple but effectivecomposition models.
In these models, the com-posed vectors are obtained through component-wise operations on the constituent vectors.
Giveninput vectors u and v, the multiplicative model(mult) returns a composed vector p with: pi =uivi.
In the weighted additive model (wadd), thecomposed vector is a weighted sum of the two in-put vectors: p = ?u+?v, where ?
and ?
are twoscalars.
Finally, in the dilation model, the outputvector is obtained by first decomposing one of theinput vectors, say v, into a vector parallel to u andan orthogonal vector.
Following this, the parallelvector is dilated by a factor ?
before re-combining.This results in: p = (??
1)?u,v?u+ ?u,u?v.A more general form of the additive model(fulladd) has been proposed by Guevara (2010)(see also Zanzotto et al (2010)).
In this approach,the two vectors to be added are pre-multiplied byweight matrices estimated from corpus-extractedexamples: p = Au+Bv.Baroni and Zamparelli (2010) and Coecke etal.
(2010) take inspiration from formal semanticsto characterize composition in terms of functionapplication.
The former model adjective-nounphrases by treating the adjective as a function fromnouns onto modified nouns.
Given that linearfunctions can be expressed by matrices and theirapplication by matrix-by-vector multiplication, a2Baroni et al (2012), like us, study determiner phraseswith distributional methods, but they do not model them com-positionally.3Dataset and code available from clic.cimec.unitn.it/composes.functor (such as the adjective) is represented by amatrix U to be multiplied with the argument vec-tor v (e.g., the noun vector): p = Uv.
Adjectivematrices are estimated from corpus-extracted ex-amples of noun vectors and corresponding outputadjective-noun phrase vectors, similarly to Gue-vara?s approach.43 The noun-DP relatedness benchmarkParaphrasing a single word with a phrase is anatural task for models of compositionality (Tur-ney, 2012; Zanzotto et al, 2010) and determin-ers sometimes play a crucial role in defining themeaning of a noun.
For example a trilogy is com-posed of three works, an assemblage includes sev-eral things and an orchestra is made of manymusicians.
These examples are particularly in-teresting, since they point to a ?conceptual?
useof determiners, as components of the stable andgeneric meaning of a content word (as opposed tosituation-dependent deictic and anaphoric usages):for these determiners the boundary between con-tent and grammatical word is somewhat blurred,and they thus provide a good entry point for testingDSM representations of DPs on a classic similaritytask.
In other words, we can set up an experimentin which having an effective representation of thedeterminer is crucial in order to obtain the correctresult.Using regular expressions over WordNetglosses (Fellbaum, 1998) and complementingthem with definitions from various online dic-tionaries, we constructed a list of more than 200nouns that are strongly conceptually related to aspecific DP.
We created a multiple-choice test setby matching each noun with its associated DP(target DP), two ?foil?
DPs sharing the same nounas the target but combined with other determiners(same-N foils), one DP made of the target deter-miner combined with a random noun (same-Dfoil), the target determiner (D foil), and the targetnoun (N foil).
A few examples are shown in Table1.
After the materials were checked by all authors,two native speakers took the multiple-choice test.We removed the cases (32) where these subjectsprovided an unexpected answer.
The final set,4Other approaches to composition in DSMs have been re-cently proposed by Socher et al (2012) and Turney (2012).We leave their empirical evaluation on DPs to further work,in the first case because it is not trivial to adapt their complexarchitecture to our setting; in the other because it is not clearhow Turney would extend his approach to represent DPs.54noun target DP same-N foil 1 same-N foil 2 same-D foil D foil N foilduel two opponents various opponents three opponents two engineers two opponentshomeless no home too few homes one home no incision no homepolygamy several wives most wives fewer wives several negotiators several wivesopulence too many goods some goods no goods too many abductions too many goodsTable 1: Examples from the noun-DP relatedness benchmarkcharacterized by full subject agreement, contains173 nouns, each matched with 6 possible answers.The target DPs contain 23 distinct determiners.4 SetupOur semantic space provides distributional repre-sentations of determiners, nouns and DPs.
Weconsidered a set of 50 determiners that include allthose in our benchmark and range from quanti-fying determiners (every, some.
.
. )
and low nu-merals (one to four), to multi-word units analyzedas single determiners in the literature, such as afew, all that, too much.
We picked the 20K mostfrequent nouns in our source corpus consideringsingular and plural forms as separate words, sincenumber clearly plays an important role in DP se-mantics.
Finally, for each of the target determinerswe added to the space the 2K most frequent DPscontaining that determiner and a target noun.Co-occurrence statistics were collected from theconcatenation of ukWaC, a mid-2009 dump of theEnglish Wikipedia and the British National Cor-pus,5 with a total of 2.8 billion tokens.
We usea bag-of-words approach, counting co-occurrencewith all context words in the same sentence witha target item.
We tuned a number of parameterson the independent MEN word-relatedness bench-mark (Bruni et al, 2012).
This led us to pick thetop 20K most frequent content word lemmas ascontext items, Pointwise Mutual Information asweighting scheme, and dimensionality reductionby Non-negative Matrix Factorization.Except for the parameter-free mult method, pa-rameters of the composition methods are esti-mated by minimizing the average Euclidean dis-tance between the model-generated and corpus-extracted vectors of the 20K DPs we consider.6For the lexfunc model, we assume that the deter-miner is the functor and the noun is the argument,5wacky.sslmit.unibo.it; www.natcorp.ox.ac.uk6All vectors are normalized to unit length before compo-sition.
Note that the objective function used in estimationminimizes the distance between model-generated and corpus-extracted vectors.
We do not use labeled evaluation data tooptimize the model parameters.method accuracy method accuracylexfunc 39.3 noun 17.3fulladd 34.7 random 16.7observed 34.1 mult 12.7dilation 31.8 determiner 4.6wadd 23.1Table 2: Percentage accuracy of compositionmethods on the relatedness benchmarkand estimate separate matrices representing eachdeterminer using the 2K DPs in the semantic spacethat contain that determiner.
For dilation, we treatdirection of stretching as a parameter, finding thatit is better to stretch the noun.Similarly to the classic TOEFL synonym detec-tion challenge (Landauer and Dumais, 1997), ourmodels tackle the relatedness task by measuringcosines between each target noun and the candi-date answers and returning the item with the high-est cosine.5 ResultsTable 2 reports the accuracy results (mean ranksof correct answers confirm the same trend).
Allmodels except mult and determiner outperform thetrivial random guessing baseline, although theyare all well below the 100% accuracy of the hu-mans who took our test.
For the mult method weobserve a very strong bias for choosing a singleword as answer (>60% of the times), which inthe test set is always incorrect.
This leads to itsaccuracy being below the chance level.
We sus-pect that the highly ?intersective?
nature of thismodel (we obtain very sparse composed DP vec-tors, only ?4% dense) leads to it not being a re-liable method for comparing sequences of wordsof different length: Shorter sequences will be con-sidered more similar due to their higher density.The determiner-only baseline (using the vector ofthe component determiner as surrogate for the DP)fails because D vectors tend to be far from N vec-tors, thus the N foil is often preferred to the correctresponse (that is represented, for this baseline, byits D).
In the noun-only baseline (use the vectorof the component noun as surrogate for the DP),55the correct response is identical to the same-N andN foils, thus forcing a random choice betweenthese.
Not surprisingly, this approach performsquite badly.
The observed DP vectors extracted di-rectly from the corpus compete with the top com-positional methods, but do not surpass them.7The lexfunc method is the best compositionalmodel, indicating that its added flexibility in mod-eling composition pays off empirically.
The ful-ladd model is not as good, but also performs well.The wadd and especially dilation models performrelatively well, but they are penalized by the factthat they assign more weight to the noun vectors,making the right answer dangerously similar to thesame-N and N foils.Taking a closer look at the performance of thebest model (lexfunc), we observe that it is notequally distributed across determiners.
Focusingon those determiners appearing in at least 4 cor-rect answers, they range from those where lexfuncperformance was very significantly above chance(p<0.001 of equal or higher chance performance):too few, all, four, too much, less, several; tothose on which performance was still significantbut less impressively so (0.001<p< 0.05): sev-eral, no, various, most, two, too many, many, one;to those where performance was not significantlybetter than chance at the 0.05 level: much, more,three, another.
Given that, on the one hand, per-formance is not constant across determiners, andon the other no obvious groupings can accountfor their performance difference (compare the ex-cellent lexfunc performance on four to the lousyone on three!
), future research should explore thecontextual properties of specific determiners thatmake them more or less amenable to be capturedby compositional DSMs.6 ConclusionDSMs, even when applied to phrases, are typicallyseen as models of content word meaning.
How-ever, to scale up compositionally beyond the sim-plest constructions, cDSMs must deal with gram-matical terms such as determiners.
This paperstarted exploring this issue by introducing a newand publicly available set testing DP semantics ina similarity-based task and using it to systemati-cally evaluate, for the first time, cDSMs on a con-7The observed method is in fact at advantage in our ex-periment because a considerable number of DP foils are notfound in the corpus and are assigned similarity 0 with the tar-get.struction involving grammatical words.
The mostimportant take-home message is that distributionalrepresentations are rich enough to encode infor-mation about determiners, achieving performancewell above chance on the new benchmark.Theoretical considerations would lead one toexpect a ?functional?
approach to determiner rep-resentations along the lines of Baroni and Zampar-elli (2010) and Coecke et al (2010) to outperformthose approaches that combine vectors separatelyrepresenting determiners and nouns.
This predic-tion was largely borne out in the results, althoughthe additive models, and particularly fulladd, werecompetitive rivals.We attempted to capture the distributional se-mantics of DPs using a fairly standard, ?vanilla?semantic space characterized by latent dimensionsthat summarize patterns of co-occurrence withcontent word contexts.
By inspecting the con-text words that are most associated with the var-ious latent dimensions we obtained through Non-negative Matrix Factorization, we notice how theyare capturing broad, ?topical?
aspects of meaning(the first dimension is represented by scripture, be-liever, resurrection, the fourth by fever, infection,infected, and so on).
Considering the sort of se-mantic space we used (which we took to be a rea-sonable starting point because of its effectivenessin a standard lexical task), it is actually surpris-ing that we obtained the significant results we ob-tained.
Thus, a top priority in future work is to ex-plore different contextual features, such as adverbsand grammatical terms, that might carry informa-tion that is more directly relevant to the semanticsof determiners.Another important line of research pertains toimproving composition methods: Although thebest model, at 40% accuracy, is well above chance,we are still far from the 100% performance of hu-mans.
We will try, in particular, to include non-linear transformations in the spirit of Socher et al(2012), and look for better ways to automaticallyselect training data.Last but not least, in the near future wewould like to test if cDSMs, besides dealing withsimilarity-based aspects of determiner meaning,can also help in capturing those formal propertiesof determiners, such as monotonicity or definite-ness, that theoretical semanticists have been tradi-tionally interested in.567 AcknowledgmentsThis research was supported by the ERC 2011Starting Independent Research Grant n. 283554(COMPOSES).ReferencesMarco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of EMNLP, pages 1183?1193, Boston,MA.Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do,and Chung-Chieh Shan.
2012.
Entailment abovethe word level in distributional semantics.
In Pro-ceedings of EACL, pages 23?32, Avignon, France.Elia Bruni, Gemma Boleda, Marco Baroni, andNam Khanh Tran.
2012.
Distributional semanticsin Technicolor.
In Proceedings of ACL, pages 136?145, Jeju Island, Korea.Bob Coecke, Mehrnoosh Sadrzadeh, and StephenClark.
2010.
Mathematical foundations for a com-positional distributional model of meaning.
Linguis-tic Analysis, 36:345?384.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,MA.Dan Garrette, Katrin Erk, and Ray Mooney.
2013.
Aformal approach to linking logical form and vector-space lexical semantics.
In H. Bunt, J. Bos, andS.
Pulman, editors, Computing Meaning, Vol.
4.
Inpress.Edward Grefenstette and Mehrnoosh Sadrzadeh.
2011.Experimental support for a categorical composi-tional distributional model of meaning.
In Proceed-ings of EMNLP, pages 1394?1404, Edinburgh, UK.Emiliano Guevara.
2010.
A regression model ofadjective-noun compositionality in distributional se-mantics.
In Proceedings of GEMS, pages 33?37,Uppsala, Sweden.Thomas Landauer and Susan Dumais.
1997.
A solu-tion to Plato?s problem: The latent semantic analysistheory of acquisition, induction, and representationof knowledge.
Psychological Review, 104(2):211?240.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In Proceedings ofACL, pages 236?244, Columbus, OH.Jeff Mitchell and Mirella Lapata.
2009.
Languagemodels based on semantic composition.
In Proceed-ings of EMNLP, pages 430?439, Singapore.Jeff Mitchell and Mirella Lapata.
2010.
Compositionin distributional models of semantics.
Cognitive Sci-ence, 34(8):1388?1429.Richard Socher, Brody Huval, Christopher Manning,and Andrew Ng.
2012.
Semantic compositionalitythrough recursive matrix-vector spaces.
In Proceed-ings of EMNLP, pages 1201?1211, Jeju Island, Ko-rea.Peter Turney.
2012.
Domain and function: A dual-space model of semantic relations and compositions.Journal of Artificial Intelligence Research, 44:533?585.Fabio Zanzotto, Ioannis Korkontzelos, FrancescaFalucchi, and Suresh Manandhar.
2010.
Estimat-ing linear models for compositional distributionalsemantics.
In Proceedings of COLING, pages 1263?1271, Beijing, China.57
