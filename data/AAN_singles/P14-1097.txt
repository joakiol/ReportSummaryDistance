Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1030?1040,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Step-wise Usage-based Method for InducingPolysemy-aware Verb ClassesDaisuke Kawahara?Daniel W. Peterson?Martha Palmer?
?Kyoto University, Kyoto, Japan?University of Colorado at Boulder, Boulder, CO, USAdk@i.kyoto-u.ac.jp, {Daniel.W.Peterson, Martha.Palmer}@colorado.eduAbstractWe present an unsupervised method for in-ducing verb classes from verb uses in giga-word corpora.
Our method consists oftwo clustering steps: verb-specific seman-tic frames are first induced by clusteringverb uses in a corpus and then verb classesare induced by clustering these frames.By taking this step-wise approach, we cannot only generate verb classes based on amassive amount of verb uses in a scalablemanner, but also deal with verb polysemy,which is bypassed by most of the previousstudies on verb clustering.
In our exper-iments, we acquire semantic frames andverb classes from two giga-word corpora,the larger comprising 20 billion words.The effectiveness of our approach is veri-fied through quantitative evaluations basedon polysemy-aware gold-standard data.1 IntroductionA verb plays a primary role in conveying themeaning of a sentence.
Capturing the sense of averb is essential for natural language processing(NLP), and thus lexical resources for verbs playan important role in NLP.Verb classes are one such lexical resource.Manually-crafted verb classes have been devel-oped, such as Levin?s classes (Levin, 1993) andtheir extension, VerbNet (Kipper-Schuler, 2005),in which verbs are organized into classes on thebasis of their syntactic and semantic behavior.Such verb classes have been used in many NLP ap-plications that need to consider semantics in par-ticular, such as word sense disambiguation (Dang,2004), semantic parsing (Swier and Stevenson,2005; Shi andMihalcea, 2005) and discourse pars-ing (Subba and Di Eugenio, 2009).There have also been many attempts to auto-matically acquire verb classes with the goal of ei-ther adding frequency information to an existingresource or of inducing similar verb classes forother languages.
Most of these approaches assumethat all target verbs are monosemous (Stevensonand Joanis, 2003; Schulte im Walde, 2006; Joa-nis et al, 2008; Li and Brew, 2008; Sun et al,2008; Sun and Korhonen, 2009; Vlachos et al,2009; Parisien and Stevenson, 2010; Parisien andStevenson, 2011; Falk et al, 2012; Lippincott etal., 2012; Reichart and Korhonen, 2013; Sun et al,2013).
This monosemous assumption, however, isnot realistic because many frequent verbs actuallyhave multiple senses.
Moreover, to the best of ourknowledge, none of the following approaches at-tempt to quantitatively evaluate soft clusterings ofverb classes induced by polysemy-aware unsuper-vised approaches (Korhonen et al, 2003; Lapataand Brew, 2004; Li and Brew, 2007; Schulte imWalde et al, 2008).In this paper, we propose an unsupervisedmethod for inducing verb classes that is awareof verb polysemy.
Our method consists of twoclustering steps: verb-specific semantic frames arefirst induced by clustering verb uses in a cor-pus and then verb classes are induced by clus-tering these frames.
By taking this step-wise ap-proach, we can not only induce verb classes withfrequency information from a massive amount ofverb uses in a scalable manner, but also deal withverb polysemy.Our novel contributions are summarized as fol-lows:?
induce both semantic frames and verb classesfrom a massive amount of verb uses by a scal-able method,?
explicitly deal with verb polysemy,?
discover effective features for each of theclustering steps, and?
quantitatively evaluate a soft clustering ofverbs.1030!"#$%&'(#)*#+%!"#%#,#-!
( %%%$&.%&'(#)*#%$&.
)%-"/0+%-"/0+)#1%&'(#)*#+%'/)+( %%%2#%&'(#)*#+%1/-#%'/)+(%3#%&'(#)*#+%!"#%)#(.0!
%%%%2#%&'(#)*#+%445%6#&60#%7 % % % % %%%7%7 % % % % %%%7!&'(#)*#84%9!"#$:%"#:%7;%&'(#)*#%%%%%%%%9#,#-!:%)#(.0!:%7;!&'(#)*#8<%9$&.:%2#:%7;%&'(#)*#%%%%%%%9-"/0+:%6#&60#:%7;!&'(#)*#8=%92#:%-"/0+:%7;%&'(#)*#%%%%%%%%%%9'/)+:%2/0+0/>#:%7;!2?!-"8@%9A:%2#:%7;%2?!-"%%%%%%%%%%9'/)+:%?1/B?0:%7;!7!/1*#(CD?!#E=@FG!
(/D"!E=5F<!2#%2?!-"%&.)%'/)+(%A%2?!-"#+%!"#%B&*/#%H#%2/00%2?!-"%!"#%D?B#%7%7!7!I#)'%-0?((#(8!J#B?1C-%>)?B#(8!I#)'%.
(#(8!Figure 1: Overview of our two-step approach.
Verb-specific semantic frames are first induced from verbuses (lower part) and then verb classes are induced from the semantic frames (upper part).
The labels ofverb classes are manually assigned here for better understanding.2 Related WorkAs stated in Section 1, most of the previous studieson verb clustering assume that verbs are monose-mous.
A typical method in these studies is to rep-resent each verb as a single data point and applyclassification (e.g., Joanis et al (2008)) or clus-tering (e.g., Sun and Korhonen (2009)) to thesedata points.
As a representation for a data point,distributions of subcategorization frames are oftenused, and other semantic features (e.g., selectionalpreferences) are sometimes added to improve theperformance.Among these studies on monosemous verb clus-tering (i.e., predominant class induction), therehave been several Bayesian methods.
Vlachoset al (2009) proposed a Dirichlet process mix-ture model (DPMM; Neal (2000)) to cluster verbsbased on subcategorization frame distributions.They evaluated their result with a gold-standardtest set, where a single class is assigned to a verb.Parisien and Stevenson (2010) proposed a hierar-chical Dirichlet process (HDP; Teh et al (2006))model to jointly learn argument structures (sub-categorization frames) and verb classes by usingsyntactic features.
Parisien and Stevenson (2011)extended their model by adding semantic features.They tried to account for verb learning by childrenand did not evaluate the resultant verb classes.Modi et al (2012) extended the model of Titovand Klementiev (2012), which is an unsupervisedmodel for inducing semantic roles, to jointly in-duce semantic roles and frames across verbs usingthe Chinese Restaurant Process (Aldous, 1985).All of the above methods considered verbs to bemonosemous and did not deal with verb polysemy.Our approach also uses Bayesian methods, but isdesigned to capture verb polysemy.We summarize a few studies that consider poly-semy of verbs in the rest of this section.Miyao and Tsujii (2009) proposed a supervisedmethod that can handle verb polysemy.
Theirmethod represents a verb?s syntactic and seman-tic features, and learns a log-linear model fromthe SemLink corpus (Loper et al, 2007).
Boledaet al (2007) also proposed a supervised methodfor Catalan adjectives considering the polysemy ofadjectives.The most closely related work to our polysemy-aware task of unsupervised verb class induction isthe work of Korhonen et al (2003), who used dis-tributions of subcategorization frames to clusterverbs.
They adopted the Nearest Neighbor (NN)and Information Bottleneck (IB) methods for clus-tering.
In particular, they tried to consider verbpolysemy by using the IB method, which is a softclustering method (Tishby et al, 1999).
However,the verb itself is still represented as a single datapoint.
After performing soft clustering, they notedthat most verbs fell into a single class, and theydecided to assign a single class to each verb byhardening the clustering.
They considered multi-ple classes only in the gold-standard data used fortheir evaluations.
We also evaluate our inducedverb classes on this gold-standard data, which wascreated on the basis of Levin?s classes (Levin,1993).Lapata and Brew (2004) and Li and Brew(2007) proposed probabilistic models for calculat-ing prior probabilities of verb classes for a verb.These models are approximated to condition not1031on verbs but on subcategorization frames.
Asmentioned in Li and Brew (2007), it is desirableto extend the model to depend on verbs to fur-ther improve accuracy.
They conducted severalevaluations including predominant class inductionand token-level verb sense disambiguation, but didnot evaluate multiple classes output by their mod-els.
Schulte im Walde et al (2008) also appliedprobabilistic soft clustering to verbs by incorporat-ing subcategorization frames and selectional pref-erences based on WordNet.
This model is basedon the Expectation-Maximization algorithm andthe Minimum Description Length principle.
Sincethey focused on the incorporation of selectionalpreferences, they did not evaluate verb classes butevaluated only selectional preferences using a lan-guage model-based measure.Materna proposed LDA-frames, which are de-fined across verbs and can be considered to bea kind of verb class (Materna, 2012; Materna,2013).
LDA-frames are probabilistic semanticframes automatically induced from a raw corpus.He used a model based on latent Dirichlet alo-cation (LDA; Blei et al (2003)) and the Dirichletprocess to cluster verb instances of a triple (sub-ject, verb, object) to produce semantic frames androles.
Both of these are represented as a proba-bilistic distribution of words across verbs.
He ap-plied this method to the BNC and acquired 1,200frames and 400 roles (Materna, 2012).
He did notevaluate the resulting frames as verb classes.In sum, there have been no studies that quantita-tively evaluate polysemous verb classes automati-cally induced by unsupervised methods.3 Our Approach3.1 OverviewOur objective is to automatically learn semanticframes and verb classes from a massive amountof verb uses following usage-based approaches.Although Bayesian approaches are a possible so-lution to simultaneously induce frames and verbclasses from a corpus as used in previous stud-ies, it has prohibitive computational cost.
For in-stance, Parisien and Stevenson applied HDP onlyto a small-scale child speech corpus that contains170K verb uses to jointly induce subcategoriza-tion frames and verb classes (Parisien and Steven-son, 2010; Parisien and Stevenson, 2011).
Ma-terna applied an LDA-based method to the BNC,which contains 1.4M verb uses, to induce seman-tic frames across verbs that can be considered tobe verb classes (Materna, 2012; Materna, 2013).However, it would take three months for this ex-periment using this 100 million word corpus.1Al-though it is best to use the largest possible cor-pus for this kind of knowledge acquisition tasks(Sasano et al, 2009), it is infeasible to scale togiga-word corpora using such joint models.In this paper, we propose a two-step approachfor inducing semantic frames and verb classes.First, we make multiple data points for each verbto deal with verb polysemy (cf.
polysemy-awareprevious studies still represented a verb as onedata point (Korhonen et al, 2003; Miyao and Tsu-jii, 2009)).
To do that, we induce verb-specificsemantic frames by clustering verb uses.
Then,we induce verb classes by clustering these verb-specific semantic frames across verbs.
An interest-ing point here is that we can use exactly the samemethod for these two clustering steps.Our procedure to automatically induce verbclasses from verb uses is summarized as follows:1. induce verb-specific semantic frames by clus-tering predicate-argument structures for eachverb extracted from automatic parses asshown in the lower part of Figure 1, and2.
induce verb classes by clustering the inducedsemantic frames across verbs as shown in theupper part of Figure 1.Each of these two steps is described in the follow-ing sections in detail.3.2 Inducing Verb-specific Semantic FramesWe induce verb-specific semantic frames fromverb uses based on the method of Kawahara et al(2014).
Our semantic frames consist of case slots,each of which consists of word instances that canbe filled.
The procedure for inducing these seman-tic frames is as follows:1. apply dependency parsing to a raw corpusand extract predicate-argument structures foreach verb from the automatic parses,2.
merge the predicate-argument structures thathave presumably the same meaning basedon the assumption of one sense per colloca-tion (Yarowsky, 1993) to get a set of initialframes, and1In our replication experiment, it took a week to perform70 iterations usingMaterna?s code and an Intel Xeon E5-2680(2.7GHz) CPU.
To reach 1,000 iterations, which are reportedto be optimum, it would take three months.10323.
apply clustering to the initial frames basedon the Chinese Restaurant Process (Al-dous, 1985) to produce verb-specific seman-tic frames.These three steps are briefly described below.3.2.1 Extracting Predicate-argumentStructures from a Raw CorpusWe apply dependency parsing to a large raw cor-pus.
We use the Stanford parser with Stanforddependencies (de Marneffe et al, 2006).2Col-lapsed dependencies are adopted to directly extractprepositional phrases.Then, we extract predicate-argument structuresfrom the dependency parses.
Dependents that havethe following dependency relations to a verb areextracted as arguments:nsubj, xsubj, dobj, iobj, ccomp, xcomp,prep ?In this process, the verb and arguments are lem-matized, and only the head of an argument is pre-served for compound nouns.Predicate-argument structures are collected foreach verb and the subsequent processes are ap-plied to the predicate-argument structures of eachverb.3.2.2 Constructing Initial Frames fromPredicate-argument StructuresTo make the computation feasible, we merge thepredicate-argument structures that have the sameor similar meaning to get initial frames.
These ini-tial frames are the input of the subsequent cluster-ing process.
For this merge, we assume one senseper collocation (Yarowsky, 1993) for predicate-argument structures.For each predicate-argument structure of a verb,we couple the verb and an argument to make a unitfor sense disambiguation.
We select an argumentin the following order by considering the degree ofeffect on the verb sense:3dobj, ccomp, nsubj, prep ?, iobj.Then, the predicate-argument structures thathave the same verb and argument pair (slot andword, e.g., ?dobj:effect?)
are merged into an ini-tial frame.
After this process, we discard minorinitial frames that occur fewer than 10 times.2http://nlp.stanford.edu/software/lex-parser.shtml3If a predicate-argument structure has multiple preposi-tional phrases, one of them is randomly selected.3.2.3 Clustering MethodWe cluster initial frames for each verb to pro-duce semantic frames using the Chinese Restau-rant Process (Aldous, 1985), regarding each initialframe as an instance.We calculate the posterior probability of a clus-ter cjgiven an initial frame fias follows:P (cj|fi) ?{n(cj)N+??
P (fi|cj) cj?= new?N+??
P (fi|cj) cj= new,(1)whereN is the number of initial frames for the tar-get verb and n(cj) is the current number of initialframes assigned to the cluster cj.
?
is a hyper-parameter that determines how likely it is for anew cluster to be created.
In this equation, the firstterm is the Dirichlet process prior and the secondterm is the likelihood of fi.P (fi|cj) is defined based on the Dirichlet-Multinomial distribution as follows:P (fi|cj) =?w?VP (w|cj)count(fi,w), (2)where V is the vocabulary in all case slots cooc-curring with the verb and count(fi, w) is the num-ber of w in the initial frame fi.
The originalmethod in Kawahara et al (2014) defined w aspairs of slots and words, e.g., ?nsubj:child?
and?dobj:bird,?
but does not consider slot-only fea-tures, e.g., ?nsubj?
and ?dobj,?
which ignore lex-ical information.
Here we experiment with bothrepresentations and compare the results.P (w|cj) is defined as follows:P (w|cj) =count(cj, w) + ?
?t?Vcount(cj, t) + |V | ?
?, (3)where count(cj, w) is the current number of win the cluster cj, and ?
is a hyper-parameter ofDirichlet distribution.
For a new cluster, this prob-ability is uniform (1/|V |).We regard each output cluster as a semanticframe, by merging the initial frames in a clus-ter into a semantic frame.
In this way, semanticframes for each verb are acquired.We use Gibbs sampling to realize this cluster-ing.3.3 Inducing Verb Classes from SemanticFramesTo induce verb classes across verbs, we applyclustering to the induced verb-specific semantic1033frames.
We can use exactly the same clusteringmethod as described in Section 3.2.3 by using se-mantic frames for multiple verbs as an input in-stead of initial frames for a single verb.
This isbecause an initial frame has the same structure asa semantic frame, which is produced by merginginitial frames.
We regard each output cluster as averb class this time.For the features, w, in equation (2), we try thetwo representations again: slot-only features andslot-word pair features.
The representation usingonly slots corresponds to the consideration of onlysyntactic argument patterns.
The other representa-tion using the slot-word pairs means that semanticsimilarity based on word overlap is naturally con-sidered by looking at lexical information.
We willcompare in our experiments four possible combi-nations: two feature representations for each of thetwo clustering steps.4 Experiments and EvaluationsWe first describe our experimental settings and de-fine evaluation metrics to evaluate induced softclusterings of verb classes.
Then, we con-duct type-level multi-class evaluations, type-levelsingle-class evaluations and token-level multi-class evaluations.
These two levels of evaluationsare performed by considering the work of Reichartet al (2010) on clustering evaluation.
Finally, wediscuss the results of our full experiments.4.1 Experimental SettingsWe use two kinds of large-scale corpora: a webcorpus and the English Gigaword corpus.To prepare a web corpus, we extracted sen-tences from crawled web pages that are judged tobe written in English based on the encoding infor-mation.
Then, we selected sentences that consistof at most 40 words, and removed duplicated sen-tences.
From this process, we obtained a corpus ofone billion sentences, totaling approximately 20billion words.
We focused on verbs whose fre-quency in the web corpus was more than 1,000.There were 19,649 verbs, including phrasal verbs,and separating passive and active constructions.We extracted 2,032,774,982 predicate-argumentstructures.We also used the English Gigaword corpus(LDC2011T07; English Gigaword Fifth Edition).This corpus consists of approximately 180 mil-lion sentences, which totaling four billion words.There were 7,356 verbs after applying the samefrequency threshold as the web corpus.
We ex-tracted 423,778,278 predicate-argument structuresfrom this corpus.We set the hyper-parameters ?
in (1) and ?
in(3) to 1.0.
The cluster assignments for all the com-ponents were initialized randomly.
We took 100samples for each input frame and selected the clus-ter assignment that has the highest probability.4.2 Evaluation MetricsTo measure the precision and recall of a cluster-ing, modified purity and inverse purity (also calledcollocation or weighted class accuracy) are com-monly used in previous studies on verb clustering(e.g., Sun and Korhonen (2009)).
However, sincethese measures are only applicable to a hard clus-tering, it is necessary to extend them to be applica-ble to a soft clustering, because in our task a verbcan belong to multiple clusters or classes.4Wepropose a normalized version of modified purityand inverse purity.
This kind of normalization forsoft clusterings was performed for other evalua-tion metrics as in Springorum et al (2013).To measure the precision of a clustering, a nor-malized version of modified purity is defined asfollows.
Suppose K is the set of automatically in-duced clusters and G is the set of gold classes.
LetKibe the verb vector of the i-th cluster and Gjbethe verb vector of the j-th gold class.
Each com-ponent of these vectors is a normalized frequency,which equals a cluster/class attribute probabilitygiven a verb.
Where there is no frequency in-formation available for class distribution, such asthe gold-standard data described in Section 4.3,we use a uniform distribution across the verb?sclasses.
The core idea of purity is that each clus-ter Kiis associated with its most prevalent goldclass.
In addition, to penalize clusters that consistof only one verb, such singleton clusters in K areconsidered as errors, as is usual with modified pu-rity.
The normalized modified purity (nmPU) canthen be written as follows:nmPU =1N?i s.t.
|Ki|>1maxj?Ki(Ki?
Gj), (4)?Ki(Ki?
Gj) =?v?Ki?Gjciv, (5)4Korhonen et al (2003) evaluated hard clusterings basedon a gold standard with multiple classes per verb.
They re-ported only precision measures including modified purity,and avoided extending the evaluation metrics for soft clus-terings.1034verb classes verb classesplace 9 drop 9, 45, 004, 47,51, A54, A30dye 24, 21, 41focus 31, 45 bake 26, 45stare 30 persuade 002lay 9 sparkle 43build 26, 45 pour 9, 43, 26, 57,13, 31force 002, 11glow 43 invent 26, 27Table 1: An excerpt of the gold-standard verbclasses for several verbs from Korhonen et al(2003).
The classes starting with ?0?
were de-rived from the LCS database, those starting with?A?
were defined by Korhonen et al, and the otherclasses were from Levin?s classes.
A bolded classis the predominant class for each verb.where N denotes the total number of verbs, |Ki|denotes the number of positive components inKi, and civdenotes the v-th component of Ki.?Ki(Ki?
Gj) means the total mass of the set ofverbs in Ki?Gj, given by summing up the valuesin Ki.
In case of evaluating a hard clustering, thisis equal to |Ki?
Gj| because all the values of civare equal to 1.As usual, the following normalized inverse pu-rity (niPU) is used to measure the recall of a clus-tering:niPU =1N?jmaxi?Gj(Ki?
Gj).
(6)Finally, we use the harmonic mean (F1) of nmPUand niPU as a single measure of clustering quality.4.3 Type-level Multi-class EvaluationsWe first evaluate our induced verb classes on thetest set created by Korhonen et al (2003) (Table 1of their paper) which was created by consideringverb polysemy on the basis of Levin?s classes andthe LCS database (Dorr, 1997).
It consists of 62classes and 110 verbs, out of which 35 verbs aremonosemous and 75 verbs are polysemous.
Theaverage number of verb classes per verb is 2.24.An excerpt from this data is shown in Table 1.As our baselines, we adopt two previously pro-posed methods.
We first implemented a soft clus-tering method for verb class induction proposed byKorhonen et al (2003).
They used the informationbottleneck (IB) method for assigning probabilitiesof classes to each verb.
Note that Korhonen et al(2003) actually hardened the clusterings and leftmethod K nmPU niPU F1IB (k=35, t=0.10) 35.0 53.59 51.44 52.44IB (k=35, t=0.05) 35.0 53.67 52.62 53.10IB (k=35, t=0.02) 35.0 54.42 54.43 54.40IB (k=35, t=0.01) 35.0 54.60 55.54 55.04IB (k=42, t=0.10) 41.6 55.42 49.46 52.24IB (k=42, t=0.05) 41.8 55.55 49.97 52.59IB (k=42, t=0.02) 42.0 56.19 51.24 53.58IB (k=42, t=0.01) 42.0 56.80 51.92 54.24LDA-frames (t=0.10) 100 47.52 56.83 51.76LDA-frames (t=0.05) 165 50.46 67.94 57.91LDA-frames (t=0.02) 306 49.98 75.50 60.14LDA-frames (t=0.01) 458 49.55 82.71 61.97Gigaword/S-S 272.8 63.46 67.66 65.49Gigaword/S-SW 36.4 31.49 95.70 47.38Gigaword/SW-S 186.2 63.52 64.18 63.84Gigaword/SW-SW 30.0 36.27 94.66 52.40web/S-S 363.6 61.32 78.64 68.90web/S-SW 52.2 35.80 99.30 52.62web/SW-S 212.2 66.26 77.38 71.39web/SW-SW 55.0 36.70 96.25 53.13Table 2: Type-level multi-class evaluations.
K rep-resents the (average) number of induced classes.?S?
denotes the use of slot-only features and ?SW?denotes the use of slot-word pair features.
For ex-ample, ?SW-S?
means that slot-word pair featuresare used for semantic frame induction and slot-only features are used for verb class induction.the evaluations of soft clusterings for their futurework.
For input data, we employ VALEX (Ko-rhonen et al, 2006), which is a publicly-availablelarge-scale subcategorization lexicon.5By follow-ing the method of Korhonen et al (2003), preposi-tional phrases (pp) are parameterized for two fre-quent subcategorization frames (NP and NP PP),and the unfiltered raw frequencies of subcatego-rization frames are used as features to representa verb.
It is necessary to specify the number ofclusters, k, for the IB method beforehand, andwe adopt 35 and 42 clusters according to their re-ported high accuracies.
To output multiple classesfor each verb, we set a threshold, t, for class at-tribute probabilities.
That is, classes that have ahigher class attribute probability than the thresh-old are output for each verb.
We report the resultsof the following threshold values: 0.01, 0.02, 0.05and 0.10.The other baseline is LDA-frames (Materna,2012).
We use the induced LDA-frames that are5http://ilexir.co.uk/applications/valex/1035predominant class eval multiple class evalmethod K mPU iPU F1mPU niPU F1NN 24 46.36 52.73 49.34 52.73 46.85 49.62IB (k=35) 34.8 42.73 51.82 46.82 51.64 46.83 49.09IB (k=42) 41.0 47.45 50.91 49.11 55.27 45.45 49.87LDA-frames 53 30.00 47.27 36.71 41.82 44.28 43.01Gigaword/S 9.6 25.64 71.27 37.70 32.91 64.71 43.62Gigaword/SW 10.6 30.36 71.09 42.25 39.82 66.92 49.70web/S 20.4 42.73 61.46 50.31 54.91 57.12 55.86web/SW 11.8 34.36 71.82 46.40 49.09 67.01 56.50Table 3: Type-level single-class evaluations against predominant/multiple classes.
K represents the (av-erage) number of induced classes.available on the web site.6This frame data was in-duced from the BNC and consists of 1,200 framesand 400 semantic roles.
Again, we set a thresholdfor frame attribute probabilities.We report results using our methods with fourfeature combinations (slot-only (S) and slot-wordpair (SW) features each used for both the frame-generation and verb-class clustering steps) forboth the Gigaword and web corpora.
Table 2 listsevaluation results for the baseline methods and ourmethods.7The results of the IB baseline and ourmethods are obtained by averaging five runs.We can see that ?web/SW-S?
achieved the bestperformance and obtained a higher F1than thebaselines by more than nine points.
?Web/SW-S?
uses the combination of slot-word pair fea-tures for clustering verb-specific frames and slot-only features for clustering across verbs.
Inter-estingly, this result indicates that slot distributionsare more effective than lexical information in slot-word pairs for inducing verb classes similar to thegold standard.
This result is consistent with ex-pectations, given a gold standard based on Levin?sverb classes, which are organized according to thesyntactic behavior of verbs.
The use of slot-wordpairs for verb class induction generally merged toomany frames into each class, apparently due to ac-cidental word overlaps across verbs.The verb classes induced from the web corpusachieved a higher F1than those from the Gigawordcorpus.
This can be attributed to the larger size ofthe web corpus.
The employment of this kind ofhuge corpus is enabled by our scalable method.6http://nlp.fi.muni.cz/projekty/lda-frames/7Although we do not think that the classes with very smallattribute probabilities are meaningful, the F1scores for lowerthresholds than 0.01 converged to about 66 in the case ofLDA-frames.4.4 Type-level Single-class Evaluationsagainst Predominant/Multiple ClassesSince we focus on the handling of verb polysemy,predominant class induction for each verb is notour main objective.
However, we wish to compareour method with previous work on the induction ofa predominant (monosemous) class for each verb.To output a single class for each verb by us-ing our proposed method, we skip the inductionof verb-specific semantic frames and instead cre-ate a single frame for each verb by merging allpredicate-argument structures of the verb.
Then,we apply clustering to these frames across verbs.For clustering features, we again compare two rep-resentations: slot-only features (S) and slot-wordpair features (SW).We evaluate the single-class output for eachverb based on the predominant gold-standardclasses, which are defined for each verb in thetest set of Korhonen et al (2003).
This data con-tains 110 verbs and 33 classes.
We evaluate thesesingle-class outputs in the same manner as Korho-nen et al (2003), using the gold standard with mul-tiple classes, which we also use for our multi-classevaluations.As we did with the multi-class evaluations, weadopt modified purity (mPU), inverse purity (iPU)and their harmonic mean (F1) as the metrics for theevaluation with predominant classes.
It is not nec-essary to normalize these metrics when we treatverbs as monosemous, and evaluate against thepredominant sense.
When we evaluate against themultiple classes in the gold standard, we do nor-malize the inverse purity.For baselines, we once more adopt the NearestNeighbor (NN) and Information Bottleneck (IB)methods proposed by Korhonen et al (2003), andLDA-frames proposed by Materna (2012).
The1036clusterings with the NN and IB methods are ob-tained by using the VALEX subcategorization lex-icon.
To harden the clusterings of the IB methodand the LDA-frames, the class with the highestprobability is selected for each verb.
This hard-ening process is exactly the same as Korhonen etal.
(2003).
Note that our results of the NN and IBmethods are different from those reported in theirpaper since the data source is different.8Table 3 lists accuracies of baseline methods andour methods.
Our proposed method using the webcorpus achieved comparable performance with thebaseline methods on the predominant class evalu-ation and outperformed them on the multiple classevaluation.
More sophisticated methods for pre-dominant class induction, such as the method ofSun and Korhonen (2009) using selectional pref-erences, could produce better single-class outputs,but have difficulty in producing polysemy-awareverb classes.From the result, we can see that the inducedverb classes based on slot-only features did notachieve a higher F1than those based on slot-wordpair features in many cases.
This result is differ-ent from that of multi-class evaluations in Section4.3.
We speculate that slot distributions are not sodifferent among verbs when all uses of a verb aremerged into one frame, and thus their discrimina-tion power is lower than that in the intermediateconstruction of semantic frames.4.5 Token-level Multi-class EvaluationsWe conduct token-level multi-class evaluations us-ing 119 verbs, which appear 100 or more times insections 02-21 of the SemLink WSJ corpus.
These119 verbs cover 102 VerbNet classes, and 48 ofthem are polysemous in the sense of being in morethan one VerbNet class.
Each instance of these 119verbs in this corpus belongs to one of 102 Verb-Net classes.
We first add these instances to theinstances from a raw corpus and apply the two-step clustering to these merged instances.
Then,we compare the induced verb classes of the Sem-Link instances with their gold-standard VerbNetclasses.
We report the values of modified purity(mPU), inverse purity (iPU) and their harmonicmean (F1).
It is not necessary to normalize thesemetrics because the clustering of these instances ishard.8Korhonen et al (2003) reported that the highest modifiedpurity was 49% against predominant classes and 60% againstmultiple classes.method K mPU iPU F1Gigaword/S-NIL ?
93.43 20.06 33.03Gigaword/SW-NIL ?
94.45 41.07 57.25Gigaword/S-S 512.2 75.06 45.26 56.47Gigaword/SW-S 260.6 73.98 56.45 64.04web/S-NIL ?
93.70 32.96 48.76web/SW-NIL ?
94.51 44.95 60.92web/S-S 500.0 72.25 52.48 60.79web/SW-S 255.2 72.65 61.00 66.31Table 4: Token-level evaluations against VerbNetclasses.
K represents the average number of in-duced classes.For clustering features, we compare two fea-ture combinations: ?S-S?
and ?SW-S,?
whichachieved high performance in the type-level multi-class evaluations (Section 4.3).
The results ofthese methods are obtained by averaging five runs.For a baseline, we use verb-specific semanticframes without clustering across verbs (?S-NIL?and ?SW-NIL?
), where these frames are consid-ered to be verb classes but not shared across verbs.Table 4 lists accuracies of these methods for thetwo corpora.
We can see that ?SW-S?
achieveda higher F1than ?S-S?
and the baselines withoutverb class induction (?S-NIL?
and ?SW-NIL?
).Modi et al (2012) induced semantic framesacross verbs using the monosemous assumptionand reported an F1of 44.7% (77.9% PU and31.4% iPU) for the assignment of FrameNetframes to the FrameNet corpus.
We also con-ducted the above evaluation against FrameNetframes for 75 verbs.9We achieved an F1of62.79% (66.97% mPU and 59.09% iPU) for?web/SW-S,?
and an F1of 60.06% (65.58% mPUand 55.39% iPU) for ?Gigaword/SW-S.?
It is dif-ficult to directly compare these results with Modiet al (2012), but our induced verb classes seem tohave higher F1accuracy.4.6 Full Experiments and DiscussionsWe finally induce verb classes from the semanticframes of 1,667 verbs, which appear at least oncein sections 02-21 of the WSJ corpus.
Based onthe best results in the above evaluations, we in-duced semantic frames using slot-word pair fea-tures, and then induced verb classes using slot-only features.
We ended with 38,481 semanticframes and 699 verb classes from the Gigaword9Since FrameNet frames are not assigned to all verbs ofSemLink, the number of verbs is different from the evalua-tions against VerbNet classes.1037class semantic framesClass 1 rave:1, talk:1Class 2 need:2, say:2Class 3 smell:1, sound:1Class 4 concentrate:1, focus:1Class 5 express:2, inquire:62, voice:1Class 6 revolve:1, snake:2, wrap:2Class 7 hand:1, hand:3, hand:4Class 8 depend:1, rely:1, rely:3Class 9 collaborate:1, compete:2, work:1Class 10 coach:3, teach:3, teach:4Class 11 dance:1, react:1, stick:1Class 12 advise:8, express:4, quiz:10, voice:2Class 13 give:18, grant:6, offer:11, offer:12Class 14 keep:14, keep:18, stay:4, stay:488Class 15 cuff:5, fasten:2, tie:1, tie:4Class 16 arrange:3, book:4, make:27, reserve:5Class 17 deport:6, differ:1, fluctuate:1, vary:1Class 18 peek:1, peek:3, peer:1, peer:7, ...Class 19 groan:1, growl:1, hiss:1, moan:1, purr:1Class 20 inform:1, notify:2, remind:1, beware:1, ...Table 5: Examples of induced verb classes.
Un-derlined semantic frames are shown in Table 6.corpus, and 61,903 semantic frames and 840 verbclasses from the web corpus.
It took two days toinduce verb classes from the Gigaword corpus andthree days from the web corpus.Examples of verb classes and semantic framesinduced from the web corpus are shown in Table5 and Table 6.
While there are many classes withconsistent meanings, such as ?Class 4?
and ?Class16,?
some classes have mixed meanings.
For in-stance, ?Class 2?
consists of the semantic frames?need:2?
and ?say:2.?
These frames were mergeddue to the high syntactic similarity of constitutingslot distributions, which are comprised of a sub-ject and a sentential complement.
To improve thequality of verb classes, it is necessary to developa clustering model that can consider syntactic andlexical similarity in a balanced way.5 ConclusionWe presented a step-wise unsupervised methodfor inducing verb classes from instances in giga-word corpora.
This method first clusters predicate-argument structures to induce verb-specific se-mantic frames and then clusters these semanticframes across verbs to induce verb classes.
Bothclustering steps are performed with exactly thesame method, which is based on the ChineseRestaurant Process.
The resulting semantic framesand verb classes are open to the public and also canbe searched via our web interface.1010http://nlp.ist.i.kyoto-u.ac.jp/member/kawahara/cf/crp.en/slot instance wordsnsubj you:2150273, i:7678, we:4599, ...need:2ccomp ?s?
:2193321nsubj she:1705781, he:20693, i:9422, ...say:2ccomp ?s?
:1829616nsubj i:11100, he:10323, we:6373, ...dobj me:30646, you:27678, us:21642, ...inform:1prep of decision:846, this:759, situation:688, ......nsubj we:7505, you:3439, i:1035, ...dobj you:18604, us:7281, them:3649, ...notify:2prep of change:1540, problem:496, status:386, ......Table 6: Examples of induced semantic frames.The number following an instance word denotesits frequency and ?s?
denotes a sentential comple-ment.From the results, we can see that the combi-nation of the slot-word pair features for cluster-ing verb-specific frames and the slot-only featuresfor clustering across verbs is the most effectiveand outperforms the baselines by approximately10 points.
This indicates that slot distributionsare more effective than lexical information in slot-word pairs for the induction of verb classes, whenLevin-style classes are used for evaluation.
Thisis consistent with Levin?s principle of organizingverb classes according to the syntactic behavior ofverbs.As applications of the resulting semantic framesand verb classes, we plan to integrate them intosyntactic parsing, semantic role labeling and verbsense disambiguation.
For instance, Kawaharaand Kurohashi (2006) improved accuracy of de-pendency parsing based on Japanese semanticframes automatically induced from a raw corpus.It is also valuable and promising to apply the in-duced verb classes to NLP applications as used inmetaphor identification (Shutova et al, 2010) andargumentative zoning (Guo et al, 2011).AcknowledgmentsThis work was supported by Kyoto UniversityJohn Mung Program and JST CREST.
We alsogratefully acknowledge the support of the NationalScience Foundation Grant NSF-IIS-1116782, ABayesian Approach to Dynamic Lexical Re-sources for Flexible Language Processing.
Anyopinions, findings, and conclusions or recommen-dations expressed in this material are those of theauthors and do not necessarily reflect the views ofthe National Science Foundation.1038ReferencesDavid Aldous.
1985.
Exchangeability and related top-ics.
?Ecole d?
?Et?e de Probabilit?es de Saint-Flour XIII?1983, pages 1?198.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alocation.
the Journal ofMachine Learning Research, 3:993?1022.Gemma Boleda, Sabine Schulte im Walde, and ToniBadia.
2007.
Modelling polysemy in adjectiveclasses by multi-label classification.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 171?180.Hoa Trang Dang.
2004.
Investigations into the roleof lexical semantics in word sense disambiguation.Ph.D.
thesis, University of Pennsylvania.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation, pages 449?454.Bonnie J. Dorr.
1997.
Large-scale dictionary con-struction for foreign language tutoring and inter-lingual machine translation.
Machine Translation,12(4):271?322.Ingrid Falk, Claire Gardent, and Jean-Charles Lamirel.2012.
Classifying French verbs using French andEnglish lexical resources.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics, pages 854?863.Yufan Guo, Anna Korhonen, and Thierry Poibeau.2011.
A weakly-supervised approach to argumen-tative zoning of scientific documents.
In Proceed-ings of the 2011 Conference on Empirical Methodsin Natural Language Processing, pages 273?283.Eric Joanis, Suzanne Stevenson, and David James.2008.
A general feature space for automaticverb classification.
Natural Language Engineering,14(3):337?367.Daisuke Kawahara and Sadao Kurohashi.
2006.
Afully-lexicalized probabilistic model for Japanesesyntactic and case structure analysis.
In Proceedingsof the Human Language Technology Conference ofthe NAACL, pages 176?183.Daisuke Kawahara, Daniel W. Peterson, OctavianPopescu, and Martha Palmer.
2014.
Inducingexample-based semantic frames from a massiveamount of verb uses.
In Proceedings of the 14thConference of the European Chapter of the Associa-tion for Computational Linguistics.Karin Kipper-Schuler.
2005.
VerbNet: A Broad-Coverage, Comprehensive Verb Lexicon.
Ph.D. the-sis, University of Pennsylvania.Anna Korhonen, Yuval Krymolowski, and ZvikaMarx.
2003.
Clustering polysemic subcategoriza-tion frame distributions semantically.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 64?71.Anna Korhonen, Yuval Krymolowski, and Ted Briscoe.2006.
A large subcategorization lexicon for naturallanguage processing applications.
In Proceedings ofthe 5th International Conference on Language Re-sources and Evaluation, pages 345?352.Mirella Lapata and Chris Brew.
2004.
Verb classdisambiguation using informative priors.
Computa-tional Linguistics, 30(1):45?73.Beth Levin.
1993.
English verb classes and alterna-tions: A preliminary investigation.
The Universityof Chicago Press.Jianguo Li and Chris Brew.
2007.
DisambiguatingLevin verbs using untagged data.
In Proceedingsof the International Conference Recent Advances inNatural Language Processing.Jianguo Li and Chris Brew.
2008.
Which are the bestfeatures for automatic verb classification.
In Pro-ceedings of ACL-08: HLT, pages 434?442.Thomas Lippincott, Anna Korhonen, and Diarmuid?O S?eaghdha.
2012.
Learning syntactic verb framesusing graphical models.
In Proceedings of the 50thAnnual Meeting of the Association for Computa-tional Linguistics, pages 420?429.Edward Loper, Szu-Ting Yi, and Martha Palmer.
2007.Combining lexical resources: mapping betweenPropBank and VerbNet.
In Proceedings of the 7thInternational Workshop on Computational Linguis-tics.Ji?r??
Materna.
2012.
LDA-frames: An unsupervised ap-proach to generating semantic frames.
In Proceed-ings of the 13th International Conference CICLing2012, Part I, pages 376?387.Ji?r??
Materna.
2013.
Parameter estimation for LDA-frames.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 482?486.Yusuke Miyao and Jun?ichi Tsujii.
2009.
Supervisedlearning of a probabilistic lexicon of verb semanticclasses.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing, pages 1328?1337.Ashutosh Modi, Ivan Titov, and Alexandre Klementiev.2012.
Unsupervised induction of frame-semanticrepresentations.
In Proceedings of the NAACL-HLTWorkshop on the Induction of Linguistic Structure,pages 1?7.1039Radford M. Neal.
2000.
Markov chain sampling meth-ods for Dirichlet process mixture models.
Journalof computational and graphical statistics, 9(2):249?265.Christopher Parisien and Suzanne Stevenson.
2010.Learning verb alternations in a usage-basedBayesian model.
In Proceedings of the 32nd AnnualMeeting of the Cognitive Science Society.Christopher Parisien and Suzanne Stevenson.
2011.Generalizing between form and meaning usinglearned verb classes.
In Proceedings of the 33rd An-nual Meeting of the Cognitive Science Society.Roi Reichart and Anna Korhonen.
2013.
Improvedlexical acquisition through DPP-based verb cluster-ing.
In Proceedings of the 51st Annual Meetingof the Association for Computational Linguistics,pages 862?872.Roi Reichart, Omri Abend, and Ari Rappoport.
2010.Type level clustering evaluation: New measures anda POS induction case study.
In Proceedings of the14th Conference on Computational Natural Lan-guage Learning, pages 77?87.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2009.
The effect of corpus size on case frameacquisition for discourse analysis.
In Proceedings ofHuman Language Technologies: The 2009 AnnualConference of the North American Chapter of theAssociation for Computational Linguistics, pages521?529.Sabine Schulte im Walde, Christian Hying, ChristianScheible, and Helmut Schmid.
2008.
CombiningEM training and the MDL principle for an automaticverb classification incorporating selectional prefer-ences.
In Proceedings of ACL-08: HLT, pages 496?504.Sabine Schulte im Walde.
2006.
Experiments onthe automatic induction of German semantic verbclasses.
Computational Linguistics, 32(2):159?194.Lei Shi and Rada Mihalcea.
2005.
Putting pieces to-gether: Combining FrameNet, VerbNet and Word-Net for robust semantic parsing.
In ComputationalLinguistics and Intelligent Text Processing, pages100?111.
Springer.Ekaterina Shutova, Lin Sun, and Anna Korhonen.2010.
Metaphor identification using verb and nounclustering.
In Proceedings of the 23rd InternationalConference on Computational Linguistics, pages1002?1010.Sylvia Springorum, Sabine Schulte im Walde, and Ja-son Utt.
2013.
Detecting polysemy in hard andsoft cluster analyses of German preposition vectorspaces.
In Proceedings of the 6th International JointConference on Natural Language Processing, pages632?640.Suzanne Stevenson and Eric Joanis.
2003.
Semi-supervised verb class discovery using noisy features.In Proceedings of the 7th Conference on NaturalLanguage Learning, pages 71?78.Rajen Subba and Barbara Di Eugenio.
2009.
An effec-tive discourse parser that uses rich linguistic infor-mation.
In Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 566?574.Lin Sun and Anna Korhonen.
2009.
Improving verbclustering with automatically acquired selectionalpreferences.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 638?647.Lin Sun, Anna Korhonen, and Yuval Krymolowski.2008.
Automatic classification of English verbs us-ing rich syntactic features.
In Proceedings of the3rd International Joint Conference on Natural Lan-guage Processing, pages 769?774.Lin Sun, Diana McCarthy, and Anna Korhonen.
2013.Diathesis alternation approximation for verb clus-tering.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics, Short Papers, pages 736?741.Robert Swier and Suzanne Stevenson.
2005.
Exploit-ing a verb lexicon in automatic semantic role la-belling.
In Proceedings of Human Language Tech-nology Conference and Conference on EmpiricalMethods in Natural Language Processing, pages883?890.Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,and David M. Blei.
2006.
Hierarchical Dirichletprocesses.
Journal of the American Statistical Asso-ciation, 101(476).Naftali Tishby, Fernando C. Pereira, and WilliamBialek.
1999.
The information bottleneck method.In Proceedings of the 37th Annual Allerton Confer-ence on Communication, Control and Computing,pages 368?377.Ivan Titov and Alexandre Klementiev.
2012.
ABayesian approach to unsupervised semantic role in-duction.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 12?22.Andreas Vlachos, Anna Korhonen, and ZoubinGhahramani.
2009.
Unsupervised and constrainedDirichlet process mixture models for verb cluster-ing.
In Proceedings of the Workshop on Geometri-cal Models of Natural Language Semantics, pages74?82.David Yarowsky.
1993.
One sense per collocation.
InProceedings of the Workshop on Human LanguageTechnology, pages 266?271.1040
