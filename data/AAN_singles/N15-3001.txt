Proceedings of NAACL-HLT 2015, pages 1?5,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsTwo Practical Rhetorical Structure Theory ParsersMihai Surdeanu, Thomas Hicks, and Marco A. Valenzuela-Esc?arcegaUniversity of Arizona, Tucson, AZ, USA{msurdeanu, hickst, marcov}@email.arizona.eduAbstractWe describe the design, development, andAPI for two discourse parsers for Rhetori-cal Structure Theory.
The two parsers usethe same underlying framework, but one usesfeatures that rely on dependency syntax, pro-duced by a fast shift-reduce parser, whereasthe other uses a richer feature space, includ-ing both constituent- and dependency-syntaxand coreference information, produced by theStanford CoreNLP toolkit.
Both parsers ob-tain state-of-the-art performance, and use avery simple API consisting of, minimally, twolines of Scala code.
We accompany this codewith a visualization library that runs the twoparsers in parallel, and displays the two gen-erated discourse trees side by side, which pro-vides an intuitive way of comparing the twoparsers.1 IntroductionThis paper describes the design and development oftwo practical parsers for Rhetorical Structure The-ory (RST) discourse (Mann and Thompson, 1988).This work contributes to the already vast body ofresearch on RST parsing (see, inter alia, Soricut andMarcu, 2003; Feng and Hirst, 2012; Joty et al, 2013,Joty et al, 2014) with the following:1.
We propose two parsers that use constituent-based and dependency-based syntax, respec-tively.
The underlying framework, other thanthe syntax-based features, is identical betweenthe parsers, which permits a rigorous analy-sis of the impact of constituent and depen-dency syntax to RST parsing.
We describethe parsers in Section 2 and empirically com-pare the impact of the two syntactic represen-tations in Section 3.
Our analysis indicatesthat both parsers achieve state-of-the-art perfor-mance.
The parser based on dependency syntaxperforms marginally worse (by 0.1 F1points)but runs approximately 2.5 times faster than theparser based on constituent syntax.
On average,the faster parser processes one document fromthe RST corpus in 2.3 seconds.2.
Both parsers have been released as open-sourceScala code with a very simple API; consistingof, minimally, two lines of code.
We discussthis API in Section 4.3.
We also introduce a visualization tool that runsthe two parsers in parallel, and displays thetwo generated discourse structures side by side.This allows users to directly compare the run-times and outputs of the two parsers.
This visu-alization tool will be the centerpiece of the pro-posed demo session.
We summarize this tool inSection 5.2 The Two ParsersThe proposed parsing approach follows the archi-tecture introduced by Hernault et al (2010), andFeng and Hirst (2012).
The parser first segmentsthe text into elementary discourse units (EDUs) us-ing an i.i.d.
classifier that identifies which tokensend an EDU.
Then the parser iteratively constructsthe discourse tree (consisting of binary relations be-tween discourse units) using a greedy bottom-up ap-proach that interleaves two classifiers: the first de-1tects which two adjacent discourse units are mostlikely to be connected given the current sequence ofunits; and the second labels the corresponding rela-tion.
The resulting discourse unit produced by thenew relation replaces its two children.
The processrepeats until there is a single discourse unit spanningthe text.1We chose this algorithm rather than other recentproposed approaches (Joty et al, 2013; Joty andMoschitti, 2014) because: (a) it promotes a sim-ple, modular architecture; (b) it is fast, and (c)as we show later, it performs well.
For classifi-cation, we experimented with Support Vector Ma-chines (SVM), Perceptron, and Logistic Regression(LR).
The results reported here use Perceptron forEDU segmentation and relation detection, and LRfor relation labeling, thus offering a good balancebetween performance and quick training.With respect to features, our approach builds onprevious work (Hernault et al, 2010; Feng andHirst, 2012; Joty et al, 2013) and extends it in twoways.
First, we implement all syntactic features us-ing both constituent and dependency syntax.
For ex-ample, a crucial feature used by the relation detec-tion/labeling classifiers is the dominance relationsof Soricut and Marcu (2003), which capture syntac-tic dominance between discourse units located in thesame sentence.
While originally these dominancerelations were implemented using constituent syn-tax, we provide an equivalent implementation thatrelies on dependency syntax.
There are two advan-tages to this approach: (a) we can now implement afull RST discourse parser using a (much faster) de-pendency parser; (b) when using a parser that pro-duces both constituent and dependency syntax, suchas Stanford?s CoreNLP2, our experiments show thatusing both these feature sets increases the perfor-mance of the model.Our second contribution is adding features basedon coreference links.
We currently use corefer-ence information in two of the latter classifiers (re-lation detection and labeling) by counting the num-ber of coreference links crossing between the two1Interleaving the two classifiers in this iterative procedureguarantees that the classifiers have access to features extractedfrom the discourse subtrees constructed in previous iterations.2http://nlp.stanford.edu/software/corenlp.shtmldiscourse units under consideration.
The intuitionbehind this feature is that the more coreferential re-lations exist between two discourse units, the morelikely they are to be directly connected.Using the above framework, we implementedtwo discourse parsers.
The first uses CoreNLP forsyntactic parsing and coreference resolution.
Thisparser uses both constituent- and dependency-basedfeatures generated using the parser of Manning andKlein (2003).
The second discourse parser uses ei-ther Malt3or the recent neural-network-based parserof Chen and Manning (2014) for dependency pars-ing.
The second discourse parser does not useconstituent- nor coreference-based features.
For allsyntactic parsers, we used the ?basic?
Stanford de-pendency representation (de Marneffe et al, 2006).Empirically, we found that this representation yieldsbetter discourse parsing performance than any of the?collapsed?
representations.3 AnalysisWe analyze the performance of the two discourseparsers in Table 1.
For conciseness, we identify theparser that uses both constituent- and dependency-based syntax and coreference resolution (all pro-duced using CoreNLP) as C, and the parser that usesonly dependency-based features as D. The latter oneis subclassed as Dmalt, if the syntactic analysis isperformed with the Malt parser, or Dstanford, if syn-tactic parsing is performed with the parser of Chenand Manning (2014).
Because we are interested inend-to-end performance, we report solely end-to-end performance on the RST test corpus (Carlson etal., 2003).
This analysis yields several observations:?
The overall performance of the proposedparsers compares favorably with the state of theart.
Both the C and D parsers outperform theparser of Hernault et al (2010), and performcomparably to the parser of Joty et al (2013).The recent work of Joty et al (2014), whichuses a considerably more complex architecturebased on reranking, outperforms our parsers by1.8 F1points.?
In general, the C parser performs better thanD on all metrics.
This is to be expected3http://www.maltparser.org2Manual PredictedEDUs EDUsF1P R F1Dmalt54.3 48.3 47.5 47.9Dstanford55.2 49.1 48.5 48.8C 55.5 49.2 48.5 48.9C ?
dep 55.5 47.9 47.6 47.7C ?
const 53.7 47.7 47.0 47.3C ?
coref 55.2 49.0 48.3 48.7C ?
const ?
coref 53.9 47.9 47.2 47.5Hernault 2010 54.8 47.7 46.9 47.3Joty 2013 55.8 ?
?
?Joty 2014 57.3 ?
?
?Table 1: Performance of the two discourse parsers: onerelying on constituent-based syntactic parsing (C), andanother using a dependency parser (D).
We report end-to-end results on the 18 relations with nuclearity infor-mation used by (Hernault et al, 2010; Feng and Hirst,2012), using both manual segmentation of text into EDUs(left table block), and EDUs predicted by the parser(right block).
We used the Precision/Recall/F1metricsintroduced by Marcu (2000).
The ablation test removesvarious feature groups: features extracted from the de-pendency representation (dep), features from constituentsyntax (const), and coreference features (coref).
We com-pare against previous work that reported end-to-end per-formance of their corresponding approaches (Hernault etal., 2010; Joty et al, 2013; Joty and Moschitti, 2014).considering that C uses both constituent- anddependency-based features, and coreference in-formation.
However, the improvement is small(e.g., 0.2 F1points when gold EDUs are used)and the D parser is faster: it processes the en-tire test dataset in 88 seconds (at an average of2.3 seconds/document) vs. 224 seconds for C.4For comparison, the (Feng and Hirst, 2012) dis-course parser processes the same dataset in 605seconds.?
The comparison of the two configurationsof the dependency-based parser (?Dmalt?
vs.?Dstanford?)
indicates that the parser of Chenand Manning (2014) yields better RST parsingperformance than the Malt parser, e.g., by 0.9F1points when predicted EDUs are used.4These times were measured on a laptop with an i7 IntelCPU and 16GB of RAM.
The times include end-to-end execu-tion, including model loading and complete preprocessing oftext, from tokenization to syntactic parsing and coreference res-olution.?
The ablation test in rows 4?5 of the ta-ble indicate that the two syntactic representa-tions complement each other well: removingdependency-based features (the ?C ?
dep?
row)drops the F1score for predicted EDUs by 1.2points (because of the worse EDU segmenta-tion); removing constituent-based features (?C?
const?)
drops performance by 1.6 F1points.?
Feature wise, the ?C ?
const ?
coref?
system isequivalent to D, but with dependency parsingperformed by converting the constituent treesproduced by the Stanford parser to dependen-cies, rather than direct dependency parsing.
Itis interesting to note that the performance ofthis system is lower than both configurations ofthe D parser, suggesting that direct dependencyparsing with a dedicated model is beneficial.?
The ?C ?
coref?
ablation experiment indicatesthat coreference information has a small contri-bution to the overall performance (0.3 F1pointswhen gold EDUs are used).
Nevertheless, wefind this result exciting, considering that this isa first attempt at using coreference informationfor discourse parsing.4 UsageWith respect to usage, we adhere to the simplic-ity principles promoted by Stanford?s CoreNLP,which introduced a simple, concrete Java APIrather than relying on heavier frameworks, such asUIMA (Ferrucci and Lally, 2004).
This guaran-tees that a user is ?up and running in ten minutesor less?, by ?doing one thing well?
and ?avoid-ing over-design?
(Manning et al, 2014).
Follow-ing this idea, our API contains two Processorobjects, one for each discourse parser, and a sin-gle method call, annotate(), which implementsthe complete analysis of a document (representedas a String), from tokenization to discourse pars-ing.5Figure 1 shows sample API usage.
Theannotate() method produces a Document ob-ject, which stores all NLP annotations: tokens,part-of-speech tags, constituent trees, dependencygraphs, coreference relations, and discourse trees.5Additional methods are provided for pre-existing tokeniza-tion and/or sentence segmentation.3import edu.arizona.sista.processors.corenlp._import edu.arizona.sista.processors.fastnlp._//// CoreNLPProcessor:// - syntax/coref with CoreNLP;// - constituent-based RST parser.// FastNLPProcessor:// - syntax with Malt or CoreNLP.// - dependency-based RST parser.//val processor = new CoreNLPProcessor()val document = processor.annotate("Tandy Corp. said it won?t join U.S.Memories, the group that seeks to battlethe Japanese in the market for computermemory chips.
")println(document.discourseTree.get)Figure 1: Minimal (but complete) code for usingthe discourse parser.
Use CoreNLPProcessorfor the constituent-based RST parser, andFastNLPProcessor for the dependency-baseddiscourse parser.
Other than the different constructors,the APIs are identical.The DiscourseTree class is summarized in Fig-ure 2.The code for the two parsers is available onGitHub, and is also packaged as two JAR files in theMaven Central Repository (one JAR file for code,and another for the pre-trained models), which guar-antees that others can install and use it with minimaleffort.
For code and more information, please seethe project?s GitHub page: https://github.com/sistanlp/processors.5 Visualization of Discourse TreesWe accompany the above Scala library with a web-based visualization tool that runs the two parsers inparallel and visualizes the two outputs for the sametext side by side.
This allows the users to: (a) di-rectly compare the runtimes of the two systems inrealtime for arbitrary texts; (b) analyze the qualita-tive difference in the outputs of two parsers; and (c)debug incorrect outputs (e.g., is the constituent treecorrect?).
Figure 3 shows a screenshot of this visu-alization tool.The visualization tool is implemented as a client-server Grails6web application which runs theparsers (on the server) and collects and displaysthe results (on the client side).
The application?sclient-side code displays both the discourse trees and6https://grails.orgclass DiscourseTree (/**Label of this tree, if non-terminal*/var relationLabel:String,/**Direction of the relation,*if non-terminal.
It can be:*LeftToRight, RightToLeft,*or None.
*/var relationDir:RelationDirection.Value,/**Children of this non-terminal node*/var children:Array[DiscourseTree],/**Raw text attached to this node*/val rawText:String,/**Position of the first token in the*text covered by this discourse tree*/var firstToken: TokenOffset,/**Position of the last token in the*text covered by this discourse tree;*this is inclusive!
*/var lastToken: TokenOffset)Figure 2: Relevant fields in the DiscourseTree class,which stores the RST tree produced by the parsers for agiven document.
The token offsets point to tokens storedin the Document class returned by the annotate()method above.syntactic information using Dagre-d37, a D3-based8renderer for the Dagre graph layout engine.6 ConclusionsThis work described the design, development andthe resulting open-source software for a parsingframework for Rhetorical Structure Theory.
Withinthis framework, we offer two parsers, one built ontop of constituent-based syntax, and the other thatuses dependency-based syntax.
Both parsers obtainstate-of-the-art performance, are fast, and are easyto use through a simple API.In future work, we will aim at improving the per-formance of the parsers using joint parsing models.Nevertheless, it is important to note that RST parsershave already demonstrated their potential to improvenatural language processing applications.
For ex-ample, in our previous work we used features ex-tracted from RST discourse relations to enhance anon-factoid question answering system (Jansen etal., 2014).
In recent work, we showed how to usediscourse relations to generate artificial training datafor mono-lingual alignment models for question an-swering (Sharp et al, 2015).7https://github.com/cpettitt/dagre-d38http://d3js.org4Figure 3: Screenshot of the discourse parser visualization tool for the input: ?Tandy Corp. said it won?t join U.S.Memories, the group that seeks to battle the Japanese in the market for computer memory chips.?
The left pane showsthe output of the C parser; the right one shows the output of the D parser.
Hovering with the cursor over a tree nodeshows its full content.
Not shown here but included in the visualization: syntactic analyses used by the two parses andruntimes for each component (from tokenization to syntactic analysis).AcknowledgmentsThis work was funded by the DARPA Big Mecha-nism program under ARO contract W911NF-14-1-0395.ReferencesL.
Carlson, D. Marcu, and M. E. Okurowski.
2003.Building a Discourse-Tagged Corpus in the Frame-work of Rhetorical Structure Theory.
In Jan van Kup-pevelt and Ronnie Smith, editors, Current Directionsin Discourse and Dialogue, pages 85?112.
KluwerAcademic Publishers.D.
Chen and C. D. Manning.
2014.
A fast and accu-rate dependency parser using neural networks.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing (EMNLP).M.-C. de Marneffe, B. MacCartney, and C. D. Man-ning.
2006.
Generating typed dependency parses fromphrase structure parses.
In Proceedings of the Interna-tional Conference on Language Resources and Evalu-ation (LREC).V.
W. Feng and G. Hirst.
2012.
Text-level discourse pars-ing with rich linguistic features.
In Proceedings of theAssociation for Computational Linguistics.D.
Ferrucci and A. Lally.
2004.
UIMA: an architec-tural approach to unstructured information processingin the corporate research environment.
Natural Lan-guage Engineering, 10:327?348.H.
Hernault, H. Prendinger, D. duVerle, and M. Ishizuka.2010.
HILDA: A discourse parser using support vec-tor machine classification.
Dialogue and Discourse,1(3):1?33.P.
Jansen, M. Surdeanu, and P. Clark.
2014.
Discoursecomplements lexical semantics for non-factoid answerreranking.
In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguistics.S.
Joty and A. Moschitti.
2014.
Discriminative rerankingof discourse parses using tree kernels.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.S.
Joty, G. Carenini, R. Ng, and Y. Mehdad.
2013.
Com-bining intra- and multi-sentential rhetorical parsing fordocument-level discourse analysis.
In Proceedings ofthe 51st Annual Meeting of the Association for Com-putational Linguistics.D.
Klein and C. D. Manning.
2003.
Accurate unlexical-ized parsing.
In Proceedings of the 41st Annual Meet-ing of the Association for Computational Linguistics(ACL).W.
C. Mann and S. A. Thompson.
1988.
Rhetoricalstructure theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.C.
D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J.Bethard, and D. McClosky.
2014.
The StanfordCoreNLP natural language processing toolkit.
In Pro-ceedings of the 52nd Annual Meeting of the Associa-tion for Computational Linguistics.D.
Marcu.
2000.
The Theory and Practice of DiscourseParsing and Summarization.
MIT Press.R.
Sharp, P. Jansen, M. Surdeanu, and P. Clark.
2015.Spinning straw into gold: Using free text to trainmonolingual alignment models for non-factoid ques-tion answering.
In Proceedings of the Conference ofthe North American Chapter of the Association forComputational Linguistics - Human Language Tech-nologies (NAACL HLT).R.
Soricut and D. Marcu.
2003.
Sentence level discourseparsing using syntactic and lexical information.
InProceedings of the Human Language Technology andNorth American Association for Computational Lin-guistics Conference.5
