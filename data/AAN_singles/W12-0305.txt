Proceedings of the EACL 2012 Workshop on Computational Linguistics and Writing, pages 35?38,Avignon, France, April 23, 2012. c?2012 Association for Computational LinguisticsLELIE: A Tool Dedicated to Procedure and Requirement AuthoringFlore Barcellini, Corinne GrosseCNAM, 41 Rue Gay Lussac,Paris, France,Flore.Barcellini@cnam.frCamille Albert, Patrick Saint-DizierIRIT-CNRS, 118 route de Narbonne,31062 Toulouse cedex Francestdizier@irit.frAbstractThis short paper relates the main features ofLELIE, phase 1, which detects errors madeby technical writers when producing pro-cedures or requirements.
This results fromergonomic observations of technical writersin various companies.1 ObjectivesThe main goal of the LELIE project is to producean analysis and a piece of software based on lan-guage processing and artificial intelligence thatdetects and analyses potential risks of differentkinds (first health and ecological, but also socialand economical) in technical documents.
We con-centrate on procedural documents and on require-ments (Hull et al 2011) which are, by large, themain types of technical documents used in compa-nies.Given a set of procedures (e.g., productionlaunch, maintenance) over a certain domain pro-duced by a company, and possibly given somedomain knowledge (ontology, terminology, lexi-cal), the goal is to process these procedures and toannotate them wherever potential risks are identi-fied.
Procedure authors are then invited to revisethese documents.
Similarly, requirements, in par-ticular those related to safety, often exhibit com-plex structures (e.g., public regulations, to cite theworse case): several embedded conditions, nega-tion, pronouns, etc., which make their use difficult,especially in emergency situations.
Indeed, proce-dures as well as safety requirements are dedicatedto action: little space should be left to personalinterpretations.Risk analysis and prevention in LELIE is basedon three levels of analysis, each of them potentiallyleading to errors made by operators in action:1.
Detection of inappropriate ways of writing:complex expressions, implicit elements, com-plex references, scoping difficulties (connec-tors, conditionals), inappropriate granularitylevel, involving lexical, semantic and prag-matic levels, inappropriate domain style,2.
Detection of domain incoherencies in proce-dures: detection of unusual ways of realizingan action (e.g., unusual instrument, equip-ment, product, unusual value such as temper-ature, length of treatment, etc.)
with respectto similar actions in other procedures or todata extracted from technical documents,3.
Confrontation of domain safety requirementswith procedures to check if the required safetyconstraints are met.Most industrial areas have now defined author-ing recommendations on the way to elaborate,structure and write procedures of various kinds.However, our experience with technical writersshows that those recommendations are not verystrictly followed in most situations.
Our objectiveis to develop a tool that checks ill-formed struc-tures with respect to these recommendations andgeneral style considerations in procedures and re-quirements when they are written.In addition, authoring guidelines do not specifyall the aspects of document authoring: our investi-gations on author practices have indeed identifieda number of recurrent errors which are linguisticor conceptual which are usually not specified inauthoring guidelines.
These errors are basicallyidentified from the comprehension difficulties en-countered by technicians in operation using thesedocuments to realize a task or from technical writ-ers themselves which are aware of the errors theyshould avoid.352 The Situation and our contributionRisk management and prevention is now a majorissue.
It is developed at several levels, in particu-lar via probabilistic analysis of risks in complexsituations (e.g., oil storage in natural caves).
De-tecting potential risks by analyzing business errorson written documents is a relatively new approach.It requires the taking into account of most of thelevels of language: lexical, grammatical and styleand discourse.Authoring tools for simplified language are nota new concept; one of the first checkers was de-veloped at Boeing1, initially for their own simpli-fyed English and later adapted for the ASD Sim-plified Technical English Specification2.
A morerecent language checking system is Acrolinx IQ byAcrolinx3.
Some technical writing environmentsalso include language checking functionality, e.g.,MadPak4.
Ament (2002) and Weiss (2000) devel-oped a number of useful methodological elementsfor authoring technical documents and error iden-tification and correction.The originality of our approach is as follows.Authoring recommendations are made flexible andcontext-dependent, for example if negation is notallowed in instructions in general, there are, how-ever, cases where it cannot be avoided becausethe positive counterpart cannot so easily be formu-lated, e.g., do not dispose of the acid in the sewer.Similarly, references may be allowed if the refer-ent is close and non-ambiguous.
However, thisrequires some knowledge.Following observations in cognitive ergonomicsin the project, a specific effort is realized concern-ing the well-formedness (following grammaticaland cognitive standards) of discourse structuresand their regularity over entire documents (e.g.,instruction or enumerations all written in the sameway).The production of procedures includes somecontrols on contents, in particular action verb argu-ments, as indicated in the second objective above,via the Arias domain knowledge base, e.g., avoid-ing typos or confusions among syntactically andsemantically well-identified entities such as instru-ments, products, equipments, values, etc.1http://www.boeing.com/phantom/sechecker/2ASD-STE100, http://www.asd-ste100.org/3http://www.acrolinx.com/4http://www.madcapsoftware.com/products/madpak/There exists no real requirement analysis sys-tem based on language that can check the qual-ity and the consistency of large sets of authoringrecommendations.
The main products are IBMDoors and Doors Trek5, Objecteering6, and Re-qtify7, which are essentially textual databases withadvanced visual and design interfaces, query facil-ities for retrieving specific requirements, and sometraceability functions carried out via predefinedattributes.
These three products also include a for-mal language (essentially based on attribute-valuepairs) that is used to check some simple forms ofcoherence among large sets of requirements.The authoring tool includes facilities for French-speaking authors who need to write in English,supporting typical errors they make via ?languagetransfer?
(Garnier, 2011).
We will not address thispoint here.This project, LELIE, is based on the TextCoopsystem (Saint-Dizier, 2012), a system dedicatedto language analysis, in particular discourse (in-cluding the taking into account of long-distancedependencies).
This project also includes the Ariasaction knowledge base that stores prototypical ac-tions in context, and can update them.
It also in-cludes an ASP (Answer Set Programming) solver8 to check for various forms of incoherence and in-completeness.
The kernel of the system is writtenin SWI Prolog, with interfaces in Java.
The projectis currently realized for French, an English versionis under development.The system is based on the following principles.First, the system is parameterized: the technicalwriter may choose the error types he wants to bechecked, and the severity level for each error typewhen there are several such levels (e.g., there areseveral levels of severity associated with fuzzyterms which indeed show several levels of fuzzi-ness).
Second, the system simply tags elementsidentified as errors, the correction is left to theauthor.
However, some help or guidelines are of-fered.
For example, guidelines for reformulatinga negative sentence into a positive one are pro-posed.
Third, the way errors are displayed can becustomized to the writer?s habits.We present below a kernel system that deals5http://www.ibm.com/software/awdtools/doors/6http://www.objecteering.com/7http://www.geensoft.com/8For an overview of ASP see Brewka et al (2011).36with the most frequent and common errors madeby technical writers independently of the technicaldomain.
This kernel needs an in-depth customiza-tion to the domain at stake.
For example, the verbsused or the terminological preferences must be im-plemented for each industrial context.
Our systemoffers the control operations, but these need to beassociated with domain data.Finally, to avoid the variability of document for-mats, the system input is an abstract documentwith a minimal number of XML tags as requiredby the error detection rules.
Managing and trans-forming the original text formats into this abstractformat is not dealt with here.3 Categorizing language and conceptualerrors found in technical documentsIn spite of several levels of human proofreadingand validation, it turns out that texts still containa large number of situations where recommenda-tions are not followed.
Reasons are analyzed in e.g.e.g., (B?guin, 2003), (Mollo et al, 2004, 2008).Via ergonomics analysis of the activity of techni-cal writers, we have identified several layers of re-current error types, which are not in general treatedby standard text editors such as Word or Visio, thefavorite editors for procedures.Here is a list of categories of errors we haveidentified.
Some errors are relevant for a wholedocument, whereas others must only be detected inprecise constructions (e.g., in instructions, whichare the most constrained constructions):?
General layout of the document: size of sen-tences, paragraphs, and of the various formsof enumerations, homogeneity of typography,structure of titles, presence of expected struc-tures such as summary, but also text global or-ganization following style recommendations(expressed in TextCoop via a grammar), etc.?
Morphology: in general passive constructionsand future tenses must be avoided in instruc-tions.?
Lexical aspects: fuzzy terms, inappropriateterms such as deverbals, light verb construc-tions or modals in instructions, detection ofterms which cannot be associated, in partic-ular via conjunctions.
This requires typinglexical data.?
Grammatical complexity: the system checksfor various forms of negation, referentialforms, sequences of conditional expressions,long sequences of coordination, complexnoun complements, and relative clause em-beddings.
All these constructions often makedocuments difficult to understand.?
Uniformity of style over a set of instructions,over titles and various lists of equipments,uniformity of expression of safety warningsand advice.?
Correct position in the document of specificfields: safety precautions, prerequisites, etc.?
Structure completeness, in particular com-pleteness of case enumerations with respectto to known data, completeness of equipmentenumerations, via the Arias action base.?
Regular form of requirements: context ofapplication properly written (e.g., via con-ditions) followed by a set of instructions.?
Incorrect domain value, as detected by Arias.When a text is analyzed, the system annotatesthe original document (which is in our currentimplementation a plain text, a Word or an XMLdocument): revisions are only made by technicalwriters.Besides tags which must be as explicit as possi-ble, colors indicate the severity level for the errorconsidered (the same error, e.g., use of fuzzy term,can have several severity levels).
The most severeerrors must be corrected first.
At the moment, wepropose four levels of severity:ERROR Must be corrected.AVOID Preferably avoid this usage, think aboutan alternative,CHECK this is not really bad, but it is recom-mended to make sure this is clear; this is alsoused to make sure that argument values arecorrect, when a non-standard one is found.ADVICE Possibly not the best language realiza-tion, but this is probably a minor problem.
Itis not clear whether there are alternatives.The model, the implementation and the resultsare presented in detail in (Barcellini et al, 2012).374 PerspectivesWe have developed the first phase of the LELIEproject: detecting authoring errors in technicaldocuments that may lead to risks.
We identified anumber of errors: lexical, business, grammatical,and stylistic.
Errors have been identified from er-gonomics investigations.
The system is now fullyimplemented on the TextCoop platform and hasbeen evaluated on a number of documents.
It isnow of much interest to evaluate user?s reactions.We have implemented the system kernel.
Themain challenge ahead of us is the customization toa given industrial context.
This includes:?
Accurately testing the system on the com-pany?s documents so as to filter out a fewremaining odd error detections,?
Introducing the domain knowledge via thedomain ontology and terminology, and en-hancing the rules we have developed to takeevery aspect into account,?
Analyzing and incorporating into the systemthe authoring guidelines proper to the com-pany that may have an impact on understand-ing and therefore on the emergence of risks,?
Implementing the interfaces between the orig-inal user documents and our system, with theabstract intermediate representation we havedefined,?
Customizing the tags expressing errors to theusers profiles and expectations, and enhanc-ing correction schemas.When sufficiently operational, the kernel of thesystem will be made available on line, and proba-bly the code will be available in open-source modeor via a free or low cost license.AcknowledgementsThis project is funded by the French National Re-search Agency ANR.
We also thanks reviewersand the companies that showed a strong interest inour project, let us access to their technical docu-ments and allowed us to observed their technicalwriters.ReferencesKurt Ament.
2002.
Single Sourcing.
Building modulardocumentation, W. Andrew Pub.Flore Barcellini, Camille Albert, Corinne Grosse,Patrick Saint-Dizier.
2012.
Risk Analysis and Pre-vention: LELIE, a Tool dedicated to Procedure andRequirement Authoring, LREC 2012, Istanbul.Patrice B?guin.
2003.
Design as a mutual learning pro-cess between users and designers, Interacting withcomputers, 15 (6).Sarah Bourse, Patrick Saint-Dizier.
2012.
A Repositoryof Rules and Lexical Resources for Discourse Struc-ture Analysis: the Case of Explanation Structures,LREC 2012, Istanbul.Gerhard Brewka, Thomas Eiter, Miros?awTruszczyn?ski.
2011.
Answer set programming ata glance.
Communications of the ACM 54 (12),92?103.Marie Garnier.
2012.
Automatic correction of adverbplacement errors: an innovative grammar checkersystem for French users of English, Eurocall?10 pro-ceedings, Elsevier.Walther Kintsch.
1988.
The Role of Knowledge in Dis-course Comprehension: A Construction-IntegrationModel, Psychological Review, vol 95-2.Elizabeth C. Hull, Kenneth Jackson, Jeremy Dick.
2011.Requirements Engineering, Springer.William C. Mann, Sandra A. Thompson.
1988.
Rhetor-ical Structure Theory: Towards a Functional Theoryof Text Organisation, TEXT 8 (3), 243?281.
SandraA.
Thompson.
(ed.
), 1992.
Discourse Description:diverse linguistic analyses of a fund raising text,John Benjamins.Dan Marcu.
1997.
The Rhetorical Parsing of NaturalLanguage Texts, ACL?97.Dan Marcu.
2000.
The Theory and Practice of Dis-course Parsing and Summarization, MIT Press.Vanina Mollo, Pierre Falzon.
2004.
Auto and allo-confrontation as tools for reflective activities.
Ap-plied Ergonomics, 35 (6), 531?540.Vanina Mollo, Pierre Falzon.
2008.
The development ofcollective reliability: a study of therapeutic decision-making, Theoretical Issues in Ergonomics Science,9(3), 223?254.Dietmar R?sner, Manfred Stede.
1992.
CustomizingRST for the Automatic Production of TechnicalManuals, In Robert Dale et al (eds.)
Aspects ofAutomated Natural Language Generation.
Berlin:Springer, 199?214.Dietmar R?sner, Manfred Stede.
1994.
Generatingmultilingual technical documents from a knowledgebase: The TECHDOC project, In: Proc.
of the Inter-national Conference on Computational Linguistics,COLING-94, Kyoto.Patrick Saint-Dizier.
2012.
Processing Natural Lan-guage Arguments with the TextCoop Platform, Jour-nal of Argumentation and Computation.Edmond H. Weiss.
2000.
Writing remedies.
Practicalexercises for technical writing, Oryx Press.38
