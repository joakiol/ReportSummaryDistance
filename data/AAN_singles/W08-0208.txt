Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 62?70,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsMultidisciplinary Instruction with the Natural Language ToolkitSteven BirdDepartment of Computer ScienceUniversity of Melbournesb@csse.unimelb.edu.auEwan KleinSchool of InformaticsUniversity of Edinburghewan@inf.ed.ac.ukEdward LoperComputer and Information ScienceUniversity of Pennsylvaniaedloper@gradient.cis.upenn.eduJason BaldridgeDepartment of LinguisticsUniversity of Texas at Austinjbaldrid@mail.utexas.eduAbstractThe Natural Language Toolkit (NLTK) iswidely used for teaching natural languageprocessing to students majoring in linguisticsor computer science.
This paper describesthe design of NLTK, and reports on howit has been used effectively in classes thatinvolve different mixes of linguistics andcomputer science students.
We focus on threekey issues: getting started with a course,delivering interactive demonstrations in theclassroom, and organizing assignments andprojects.
In each case, we report on practicalexperience and make recommendations onhow to use NLTK to maximum effect.1 IntroductionIt is relatively easy to teach natural language pro-cessing (NLP) in a single-disciplinary mode to a uni-form cohort of students.
Linguists can be taught toprogram, leading to projects where students manip-ulate their own linguistic data.
Computer scientistscan be taught methods for automatic text processing,leading to projects on text mining and chatbots.
Yetthese approaches have almost nothing in common,and it is a stretch to call either of these NLP: moreapt titles for such courses might be ?linguistic datamanagement?
and ?text technologies.
?The Natural Language Toolkit, or NLTK, wasdeveloped to give a broad range of students accessto the core knowledge and skills of NLP (Loperand Bird, 2002).
In particular, NLTK makes itfeasible to run a course that covers a substantialamount of theory and practice with an audienceconsisting of both linguists and computer scientists.NLTK is a suite of Python modules distributedunder the GPL open source license via nltk.org.NLTK comes with a large collection of corpora,extensive documentation, and hundreds of exercises,making NLTK unique in providing a comprehensiveframework for students to develop a computationalunderstanding of language.
NLTK?s code base of100,000 lines of Python code includes supportfor corpus access, tokenizing, stemming, tagging,chunking, parsing, clustering, classification,language modeling, semantic interpretation,unification, and much else besides.
As a measure ofits impact, NLTK has been used in over 60 universitycourses in 20 countries, listed on the NLTK website.Since its inception in 2001, NLTK has undergoneconsiderable evolution, based on the experiencegained by teaching courses at several universities,and based on feedback from many teachers andstudents.1 Over this period, a series of practicalonline tutorials about NLTK has grown up into acomprehensive online book (Bird et al, 2008).
Thebook has been designed to stay in lock-step with theNLTK library, and is intended to facilitate ?activelearning?
(Bonwell and Eison, 1991).This paper describes the main features ofNLTK, and reports on how it has been usedeffectively in classes that involve a combinationof linguists and computer scientists.
First wediscuss aspects of the design of the toolkit that1(Bird and Loper, 2004; Loper, 2004; Bird, 2005; Hearst,2005; Bird, 2006; Klein, 2006; Liddy and McCracken, 2005;Madnani, 2007; Madnani and Dorr, 2008; Baldridge and Erk,2008)62arose from our need to teach computationallinguistics to a multidisciplinary audience (?2).
Thefollowing sections cover three distinct challenges:getting started with a course (?3); interactivedemonstrations (?4); and organizing assignmentsand projects (?5).2 Design Decisions Affecting Teaching2.1 PythonWe chose Python2 as the implementation languagefor NLTK because it has a shallow learning curve, itssyntax and semantics are transparent, and it has goodstring-handling functionality.
As an interpretedlanguage, Python facilitates interactive exploration.As an object-oriented language, Python permitsdata and methods to be encapsulated and re-usedeasily.
Python comes with an extensive standardlibrary, including tools for graphical programmingand numerical processing, which means it can beused for a wide range of non-trivial applications.Python is ideal in a context serving newcomers andexperienced programmers (Shannon, 2003).We have taken the step of incorporating a detailedintroduction to Python programming in the NLTKbook, taking care to motivate programming con-structs with linguistic examples.
Extensive feedbackfrom students has been humbling, and revealed thatfor students with no prior programming experience,it is almost impossible to over-explain.
Despite thedifficulty of providing a self-contained introductionto Python for linguists, we nevertheless have alsohad very positive feedback, and in combination withthe teaching techniques described below, have man-aged to bring a large group of non-programmer stu-dents rapidly to a point where they could carry outinteresting and useful exercises in text processing.In addition to the NLTK book, the code in theNLTK core is richly documented, using Python doc-strings and Epydoc3 support for API documenta-tion.4 Access to the code documentation is availableusing the Python help() command at the interac-tive prompt, and this can be especially useful forchecking the parameters and return type of func-tions.2http://www.python.org/3http://epydoc.sourceforge.net/4http://nltk.org/doc/api/Other Python libraries are useful in the NLP con-text: NumPy provides optimized support for linearalgebra and sparse arrays (NumPy, 2008) and PyLabprovides sophisticated facilities for scientific visual-ization (Matplotlib, 2008).2.2 Coding RequirementsAs discussed in Loper & Bird (2002), the prioritiesfor NLTK code focus on its teaching role.
When codeis readable, a student who doesn?t understand themaths of HMMs, smoothing, and so on may benefitfrom looking at how an algorithm is implemented.Thus consistency, simplicity, modularity are all vitalfeatures of NLTK code.
A similar importance isplaced on extensibility, since this helps to ensure thatthe code grows as a coherent whole, rather than byunpredictable and haphazard additions.By contrast, although efficiency cannot beignored, it has always taken second place tosimplicity and clarity of coding.
In a similar vein,we have tried to avoid clever programming tricks,since these typically hinder intelligibility of thecode.
Finally, comprehensiveness of coverage hasnever been an overriding concern of NLTK; thisleaves open many possibilities for student projectsand community involvement.2.3 NamingOne issue which has absorbed a considerableamount of attention is the naming of user-orientedfunctions in NLTK.
To a large extent, the system ofnaming is the user interface to the toolkit, and it isimportant that users should be able to guess whataction might be performed by a given function.Consequently, naming conventions need to beconsistent and semantically transparent.
At the sametime, there is a countervailing pressure for relativelysuccinct names, since excessive verbosity can alsohinder comprehension and usability.
An additionalcomplication is that adopting an object-orientedstyle of programming may be well-motivated fora number of reasons but nevertheless baffling tothe linguist student.
For example, although it isperfectly respectable to invoke an instance methodWordPunctTokenizer().tokenize(text)(for some input string text), a simpler version isalso provided: wordpunct tokenize(text).632.4 Corpus AccessThe scope of exercises and projects that studentscan perform is greatly increased by the inclusionof a large collection of corpora, along with easy-to-use corpus readers.
This collection, which currentlystands at 45 corpora, includes parsed, POS-tagged,plain text, categorized text, and lexicons.5In designing the corpus readers, we emphasizedsimplicity, consistency, and efficiency.
Corpusobjects, such as nltk.corpus.brown andnltk.corpus.treebank, define commonmethods for reading the corpus contents, abstractingaway from idiosyncratic file formats to provide auniform interface.
See Figure 1 for an example ofaccessing POS-tagged data from different taggedand parsed corpora.The corpus objects provide methods for loadingcorpus contents in various ways.
Common meth-ods include: raw(), for the raw contents of thecorpus; words(), for a list of tokenized words;sents(), for the same list grouped into sentences;tagged words(), for a list of (word, tag) pairs;tagged sents(), for the same list grouped intosentences; and parsed sents(), for a list of parsetrees.
Optional parameters can be used to restrictwhat portion of the corpus is returned, e.g., a partic-ular section, or an individual corpus file.Most corpus reader methods return a corpus viewwhich acts as a list of text objects, but maintainsresponsiveness and memory efficiency by only load-ing items from the file on an as-needed basis.
Thus,when we print a corpus view we only load the firstblock of the corpus into memory, but when we pro-cess this object we load the whole corpus:>>> nltk.corpus.alpino.words()[?De?, ?verzekeringsmaatschappijen?,?verhelen?, ...]>>> len(nltk.corpus.alpino.words())1398202.5 Accessing Shoebox FilesNLTK provides functionality for working with?Shoebox?
(or ?Toolbox?)
data (Robinson etal., 2007).
Shoebox is a system used by manydocumentary linguists to produce lexicons andinterlinear glossed text.
The ability to work5http://nltk.org/corpora.htmlstraightforwardly with Shoebox data has created anew incentive for linguists to learn how to program.As an example, in the Linguistics Department atthe University of Texas at Austin, a course has beenoffered on Python programming and working withcorpora,6 but so far uptake from the target audienceof core linguistics students has been low.
They usu-ally have practical computational needs and many ofthem are intimidated by the very idea of program-ming.
We believe that the appeal of this course canbe enhanced by designing a significant componentwith the goal of helping documentary linguistics stu-dents take control of their own Shoebox data.
Thiswill give them skills that are useful for their researchand also transferable to other activities.
Althoughthe NLTK Shoebox functionality was not originallydesigned with instruction in mind, its relevance tostudents of documentary linguistics is highly fortu-itous and may prove appealing for similar linguisticsdepartments.3 Getting StartedNLP is usually only available as an elective course,and students will vote with their feet after attendingone or two classes.
This initial period is importantfor attracting and retaining students.
In particular,students need to get a sense of the richness of lan-guage in general, and NLP in particular, while gain-ing a realistic impression of what will be accom-plished during the course and what skills they willhave by the end.
During this time when rapportneeds to be rapidly established, it is easy for instruc-tors to alienate students through the use of linguisticor computational concepts and terminology that areforeign to students, or to bore students by gettingbogged down in defining terms like ?noun phrase?or ?function?
which are basic to one audience andnew for the other.
Thus, we believe it is crucialfor instructors to understand and shape the student?sexpectations, and to get off to a good start.
The bestoverall strategy that we have found is to use succinctnuggets of NLTK code to stimulate students?
interestin both data and processing techniques.6http://comp.ling.utexas.edu/courses/2007/corpora07/64>>> nltk.corpus.treebank.tagged_words()[(?Pierre?, ?NNP?
), (?Vinken?, ?NNP?
), (?,?, ?,?
), ...]>>> nltk.corpus.brown.tagged_words()[(?The?, ?AT?
), (?Fulton?, ?NP-TL?
), ...]>>> nltk.corpus.floresta.tagged_words()[(?Um?, ?>N+art?
), (?revivalismo?, ?H+n?
), ...]>>> nltk.corpus.cess_esp.tagged_words()[(?El?, ?da0ms0?
), (?grupo?, ?ncms000?
), ...]>>> nltk.corpus.alpino.tagged_words()[(?De?, ?det?
), (?verzekeringsmaatschappijen?, ?noun?
), ...]Figure 1: Accessing Different Corpora via a Uniform Interface3.1 Student ExpectationsComputer science students come to NLP expectingto learn about NLP algorithms and data structures.They typically have enough mathematical prepara-tion to be confident in playing with abstract for-mal systems (including systems of linguistic rules).Moreover, they are already proficient in multipleprogramming languages, and have little difficulty inlearning NLP algorithms by reading and manipulat-ing the implementations provided with NLTK.
At thesame time, they tend to be unfamiliar with the termi-nology and concepts that linguists take for granted,and may struggle to come up with reasonable lin-guistic analyses of data.Linguistics students, on the other hand, areinterested in understanding NLP algorithms anddata structures only insofar as it helps them touse computational tools to perform analytic tasksfrom ?core linguistics,?
e.g.
writing a set of CFGproductions to parse some sentences, or pluggingtogether NLP components in order to derive thesubcategorization requirements of verbs in a corpus.They are usually not interested in reading significantchunks of code; it isn?t what they care about andthey probably lack the confidence to poke around insource files.In a nutshell, the computer science students typ-ically want to analyze the tools and synthesize newimplementations, while the linguists typically wantto use the tools to analyze language and synthe-size new theories.
There is a risk that the formergroup never really gets to grips with natural lan-guage, while the latter group never really gets togrips with processing.
Instead, computer sciencestudents need to learn that NLP is not just an applica-tion of techniques from formal language theory andcompiler construction, and linguistics students needto understand that NLP is not just computer-basedhousekeeping and a solution to the shortcomings ofoffice productivity software for managing their data.In many courses, linguistics students or computerscience students will dominate the class numeri-cally, simply because the course is only listed inone department.
In such cases it is usually enoughto provide additional support in the form of someextra readings, tutorials, and exercises in the open-ing stages of the course.
In other cases, e.g.
courseswe have taught at the universities of Edinburgh, Mel-bourne, Pennsylvania, and Texas-Austin or in sum-mer intensive programs in several countries, there ismore of an even split, and the challenge of servingboth cohorts of students becomes acute.
It helps toaddress this issue head-on, with an early discussionof the goals of the course.3.2 Articulating the GoalsDespite an instructor?s efforts to add a cross-disciplinary angle, students easily ?revert totype.?
The pressure of assessment encouragesstudents to emphasize what they do well.
Students?desire to understand what is expected of themencourages instructors to stick to familiarassessment instruments.
As a consequence,the path of least resistance is for students toremain firmly monolingual in their own discipline,while acquiring a smattering of words from aforeign language, at a level we might call ?survivallinguistics?
or ?survival computer science.?
If theyever get to work in a multidisciplinary team they are65likely only to play a type-cast role.Asking computer science students to write theirfirst essay in years, or asking linguistics studentsto write their first ever program, leads to stressedstudents who complain that they don?t know whatis expected of them.
Nevertheless, students needto confront the challenge of becoming bilingual, ofworking hard to learn the basics of another disci-pline.
In parallel, instructors need to confront thechallenge of synthesizing material from linguisticsand computer science into a coherent whole, anddevising effective methods for teaching, learning,and assessment.3.3 Entry PointsIt is possible to identify several distinct pathwaysinto the field of Computational Linguistics.
Bird(2008) identifies four; each of these are supportedby NLTK, as detailed below:Text Processing First: NLTK supports variety ofapproaches to tokenization, tagging, evaluation, andlanguage engineering more generally.Programming First: NLTK is based on Pythonand the documentation teaches the language andprovides many examples and exercises to test andreinforce student learning.Linguistics First: Here, students come with agrounding in one or more areas of linguistics, andfocus on computational approaches to that area byworking with the relevant chapter of the NLTK bookin conjunction with learning how to program.Algorithms First: Here, students come with agrounding in one or more areas of computer sci-ence, and can use, test and extend NLTK?S referenceimplementations of standard NLP algorithms.3.4 The First LectureIt is important that the first lecture is effective atmotivating and exemplifying NLP to an audienceof computer science and linguistics students.
Theyneed to get an accurate sense of the interestingconceptual and technical challenges awaiting them.Fortunately, the task is made easier by the simplefact that language technologies, and language itself,are intrinsically interesting and appealing to a wideaudience.
Several opening topics appear to workparticularly well:The holy grail: A long term challenge,mythologized in science fiction movies, is tobuild machines that understand human language.Current technologies that exhibit some basic levelof natural language understanding include spokendialogue systems, question answering systems,summarization systems, and machine translationsystems.
These can be demonstrated in classwithout too much difficulty.
The Turing test is alinguistic test, easily understood by all students, andwhich helps the computer science students to seeNLP in relation to the field of Artificial Intelligence.The evolution of programming languages hasbrought them closer to natural language, helpingstudents see the essentially linguistic purpose ofthis central development in computer science.The corresponding holy grail in linguistics is fullunderstanding of the human language faculty;writing programs and building machines surelyinforms this quest too.The riches of language: It is easy to findexamples of the creative richness of language in itsmyriad uses.
However, linguists will understandthat language contains hidden riches that can onlybe uncovered by careful analysis of large quantitiesof linguistically annotated data, work that benefitsfrom suitable computational tools.
Moreover, thecomputational needs for exploratory linguisticresearch often go beyond the capabilities of thecurrent tools.
Computer scientists will appreciatethe cognate problem of extracting information fromthe web, and the economic riches associated withstate-of-the-art text mining technologies.Formal approaches to language: Computer sci-ence and linguistics have a shared history in the areaof philosophical logic and formal language theory.Whether the language is natural or artificial, com-puter scientists and linguists use similar logical for-malisms for investigating the formal semantics oflanguages, similar grammar formalisms for model-ing the syntax of languages, and similar finite-statemethods for manipulating text.
Both rely on therecursive, compositional nature of natural and arti-ficial languages.3.5 First AssignmentThe first coursework assignment can be a significantstep forwards in helping students get to grips with66the material, and is best given out early, perhapseven in week 1.
We have found it advisable forthis assignment to include both programming andlinguistics content.
One example is to ask studentsto carry out NP chunking of some data (e.g.
a sectionof the Brown Corpus).
The nltk.RegexpParserclass is initialized with a set of chunking rulesexpressed in a simple, regular expression-orientedsyntax, and the resulting chunk parser can be runover POS-tagged input text.
Given a Gold Standardtest set like the CoNLL-2000 data,7 precisionand recall of the chunk grammar can be easilydetermined.
Thus, if students are given an existing,incomplete set of rules as their starting point, theyjust have to modify and test their rules.There are distinctive outcomes for each set of stu-dents: linguistics students learn to write grammarfragments that respect the literal-minded needs ofthe computer, and also come to appreciate the noisi-ness of typical NLP corpora (including automaticallyannotated corpora like CoNLL-2000).
Computerscience students become more familiar with partsof speech and with typical syntactic structures inEnglish.
Both groups learn the importance of formalevaluation using precision and recall.4 Interactive Demonstrations4.1 Python DemonstrationsPython fosters a highly interactive style of teaching.It is quite natural to build up moderately complexprograms in front of a class, with the less confi-dent students transcribing it into a Python sessionon their laptop to satisfy themselves it works (butnot necessarily understanding everything they enterfirst time), while the stronger students quickly graspthe theoretical concepts and algorithms.
While bothgroups can be served by the same presentation, theytend to ask quite different questions.
However, thisis addressed by dividing them into smaller clustersand having teaching assistants visit them separatelyto discuss issues arising from the content.The NLTK book contains many examples, andthe instructor can present an interactive lecture thatincludes running these examples and experiment-ing with them in response to student questions.
In7http://www.cnts.ua.ac.be/conll2000/chunking/early classes, the focus will probably be on learningPython.
In later classes, the driver for such interac-tive lessons can be an externally-motivated empiri-cal or theoretical question.As a practical matter, it is important to considerlow-level issues that may get in the way of students?ability to capture the material covered in interactivePython sessions.
These include choice of appropri-ate font size for screen display, avoiding the prob-lem of output scrolling the command out of view,and distributing a log of the instructor?s interactivesession for students to study in their own time.4.2 NLTK DemonstrationsA significant fraction of any NLP syllabus coversfundamental data structures and algorithms.
Theseare usually taught with the help of formal notationsand complex diagrams.
Large trees and charts arecopied onto the board and edited in tedious slowmotion, or laboriously prepared for presentationslides.
It is more effective to use live demonstrationsin which those diagrams are generated and updatedautomatically.
NLTK provides interactive graphicaluser interfaces, making it possible to view programstate and to study program execution step-by-step.Most NLTK components have a demonstrationmode, and will perform an interesting task withoutrequiring any special input from the user.
It iseven possible to make minor modifications toprograms in response to ?what if?
questions.
In thisway, students learn the mechanics of NLP quickly,gain deeper insights into the data structures andalgorithms, and acquire new problem-solving skills.An example of a particularly effective setof demonstrations are those for shift-reduceand recursive descent parsing.
These makethe difference between the algorithms glaringlyobvious.
More importantly, students get a concretesense of many issues that affect the design ofalgorithms for tasks like parsing.
The partialanalysis constructed by the recursive descentparser bobs up and down as it steps forward andbacktracks, and students often go wide-eyed as theparser retraces its steps and does ?dumb?
thingslike expanding N to man when it has alreadytried the rule unsuccessfully (but is now tryingto match a bare NP rather than an NP with a PPmodifier).
Linguistics students who are extremely67knowledgeable about context-free grammars andthus understand the representations gain a newappreciation for just how naive an algorithm can be.This helps students grasp the need for techniqueslike dynamic programming and motivates them tolearn how they can be used to solve such problemsmuch more efficiently.Another highly useful aspect of NLTK is the abil-ity to define a context-free grammar using a sim-ple format and to display tree structures graphically.This can be used to teach context-free grammarsinteractively, where the instructor and the studentsdevelop a grammar from scratch and check its cov-erage against a testbed of grammatical and ungram-matical sentences.
Because it is so easy to modifythe grammar and check its behavior, students readilyparticipate and suggest various solutions.
When thegrammar produces an analysis for an ungrammaticalsentence in the testbed, the tree structure can be dis-played graphically and inspected to see what wentwrong.
Conversely, the parse chart can be inspectedto see where the grammar failed on grammatical sen-tences.NLTK?s easy access to many corpora greatly facil-itates classroom instruction.
It is straightforward topull in different sections of corpora and build pro-grams in class for many different tasks.
This notonly makes it easier to experiment with ideas on thefly, but also allows students to replicate the exer-cises outside of class.
Graphical displays that showthe dispersion of terms throughout a text also givestudents excellent examples of how a few simplestatistics collected from a corpus can provide usefuland interesting views on a text?including seeing thefrequency with which various characters appear in anovel.
This can in turn be related to other resourceslike Google Trends, which shows the frequency withwhich a term has been referenced in news reports orbeen used in search terms over several years.5 Exercises, Assignments and Projects5.1 ExercisesCopious exercises are provided with the NLTK book;these have been graded for difficulty relative to theconcepts covered in the preceding sections of thebook.
Exercises have the tremendous advantage ofbuilding on the NLTK infrastructure, both code anddocumentation.
The exercises are intended to besuitable both for self-paced learning and in formallyassigned coursework.A mixed class of linguistics and computer sci-ence students will have a diverse range of program-ming experience, and students with no programmingexperience will typically have different aptitudes forprogramming (Barker and Unger, 1983; Caspersenet al, 2007).
A course which forces all studentsto progress at the same rate will be too difficult forsome, and too dull for others, and will risk alien-ating many students.
Thus, course materials needto accommodate self-paced learning.
An effectiveway to do this is to provide students with contextsin which they can test and extend their knowledge attheir own rate.One such context is provided by lecture or lab-oratory sessions in which students have a machinein front of them (or one between two), and wherethere is time to work through a series of exercises toconsolidate what has just been taught from the front,or read from a chapter of the book.
When this can bedone at regular intervals, it is easier for students toknow which part of the materials to re-read.
It alsoencourages them to get into the habit of checkingtheir understanding of a concept by writing code.When exercises are graded for difficulty, it iseasier for students to understand how much effortis expected, and whether they even have time toattempt an exercise.
Graded exercises are also goodfor supporting self-evaluation.
If a student takes20 minutes to write a solution, they also need tohave some idea of whether this was an appropriateamount of time.The exercises are also highly adaptable.
It is com-mon for instructors to take them as a starting pointin building homework assignments that are tailoredto their own students.
Some instructors prefer toinclude exercises that do not allow students to takeadvantage of built-in NLTK functionality, e.g.
usinga Python dictionary to count word frequencies in theBrown corpus rather than NLTK?s FreqDist (seeFigure 2).
This is an important part of buildingfacility with general text processing in Python, sinceeventually students will have to work outside ofthe NLTK sandbox.
Nonetheless, students often useNLTK functionality as part of their solutions, e.g.,for managing frequencies and distributions.
Again,68nltk.FreqDist(nltk.corpus.brown.words())fd = nltk.FreqDist()for filename in corpus_files:text = open(filename).read()for w in nltk.wordpunct_tokenize(text):fd.inc(w)counts = {}for w in nltk.corpus.brown.words():if w not in counts:counts[w] = 0counts[w] += 1Figure 2: Three Ways to Build up a Frequency Distribu-tion of Words in the Brown Corpusthis flexibility is a good thing: students learn towork with resources they know how to use, and canbranch out to new exercises from that basis.
Whencourse content includes discussion of Unix com-mand line utilities for text processing, students canfurthermore gain a better appreciation of the prosand cons of writing their own scripts versus usingan appropriate Unix pipeline.5.2 AssignmentsNLTK supports assignments of varying difficulty andscope: experimenting with existing components tosee what happens for different inputs or parametersettings; modifying existing components andcreating systems using existing components;leveraging NLTK?s extensible architecture bydeveloping entirely new components; or employingNLTK?s interfaces to other toolkits such as Weka(Witten and Frank, 2005) and Prover9 (McCune,2008).5.3 ProjectsGroup projects involving a mixture of linguistsand computer science students have an initialappeal, assuming that each kind of student canlearn from the other.
However, there?s a complexsocial dynamic in such groups, one effect of whichis that the linguistics students may opt out of theprogramming aspects of the task, perhaps withview that their contribution would only hurt thechances of achieving a good overall project mark.It is difficult to mandate significant collaborationacross disciplinary boundaries, with the morelikely outcome being, for example, that a parser isdeveloped by a computer science team member,then thrown over the wall to a linguist who willdevelop an appropriate grammar.Instead, we believe that it is generally more pro-ductive in the context of a single-semester introduc-tory course to have students work individually ontheir own projects.
Distinct projects can be devisedfor students depending on their background, or stu-dents can be given a list of project topics,8 andoffered option of self-proposing other projects.6 ConclusionWe have argued that the distinctive features ofNLTK make it an apt vehicle for teaching NLPto mixed audiences of linguistic and computerscience students.
On the one hand, completenovices can quickly gain confidence in their abilityto do interesting and useful things with languageprocessing, while the transparency and consistencyof the implementation also makes it easy forexperienced programmers to learn about naturallanguage and to explore more challenging tasks.The success of this recipe is borne out by thewide uptake of the toolkit, not only within tertiaryeducation but more broadly by users who just wanttry their hand at NLP.
We also have encouragingresults in presenting NLTK in classrooms at thesecondary level, thereby trying to inspire thecomputational linguists of the future!Finally, we believe that NLTK has gained muchby participating in the Open Source software move-ment, specifically from the infrastructure providedby SourceForge.net and from the invaluablecontributions of a wide range of people, includingmany students.7 AcknowledgmentsWe are grateful to the members of the NLTK com-munity for their helpful feedback on the toolkit andtheir many contributions.
We thank the anonymousreviewers for their feedback on an earlier version ofthis paper.8http://nltk.org/projects.html69ReferencesJason Baldridge and Katrin Erk.
2008.
Teaching com-putational linguistics to a large, diverse student body:courses, tools, and interdepartmental interaction.
InProceedings of the Third Workshop on Issues in Teach-ing Computational Linguistics.
Association for Com-putational Linguistics.Ricky Barker and E. A. Unger.
1983.
A predictor forsuccess in an introductory programming class basedupon abstract reasoning development.
ACM SIGCSEBulletin, 15:154?158.Steven Bird and Edward Loper.
2004.
NLTK: The Nat-ural Language Toolkit.
In Companion Volume to theProceedings of 42st Annual Meeting of the Associationfor Computational Linguistics, pages 214?217.
Asso-ciation for Computational Linguistics.Steven Bird, Ewan Klein, and Edward Loper.
2008.Natural Language Processing in Python.
http://nltk.org/book.html.Steven Bird.
2005.
NLTK-Lite: Efficient scriptingfor natural language processing.
In 4th InternationalConference on Natural Language Processing, Kanpur,India, pages 1?8.Steven Bird.
2006.
NLTK: The Natural LanguageToolkit.
In Proceedings of the COLING/ACL 2006Interactive Presentation Sessions, pages 69?72, Syd-ney, Australia, July.
Association for ComputationalLinguistics.Steven Bird.
2008.
Defining a core body of knowledgefor the introductory computational linguistics curricu-lum.
In Proceedings of the Third Workshop on Issuesin Teaching Computational Linguistics.
Associationfor Computational Linguistics.Charles C. Bonwell and James A. Eison.
1991.
ActiveLearning: Creating Excitement in the Classroom.Washington, D.C.: Jossey-Bass.Michael Caspersen, Kasper Larsen, and Jens Benned-sen. 2007.
Mental models and programming aptitude.SIGCSE Bulletin, 39:206?210.Marti Hearst.
2005.
Teaching applied natural languageprocessing: Triumphs and tribulations.
In Proceedingsof the Second ACL Workshop on Effective Tools andMethodologies for Teaching NLP and CL, pages 1?8,Ann Arbor, Michigan, June.
Association for Compu-tational Linguistics.Ewan Klein.
2006.
Computational semantics in the Nat-ural Language Toolkit.
In Proceedings of the Aus-tralasian Language Technology Workshop, pages 26?33.Elizabeth Liddy and Nancy McCracken.
2005.
Hands-onNLP for an interdisciplinary audience.
In Proceedingsof the Second ACL Workshop on Effective Tools andMethodologies for Teaching NLP and CL, pages 62?68, Ann Arbor, Michigan, June.
Association for Com-putational Linguistics.Edward Loper and Steven Bird.
2002.
NLTK: The Nat-ural Language Toolkit.
In Proceedings of the ACLWorkshop on Effective Tools and Methodologies forTeaching Natural Language Processing and Computa-tional Linguistics, pages 62?69.
Association for Com-putational Linguistics.Edward Loper.
2004.
NLTK: Building a pedagogicaltoolkit in Python.
In PyCon DC 2004.
Python Soft-ware Foundation.Nitin Madnani and Bonnie Dorr.
2008.
Combiningopen-source with research to re-engineer a hands-onintroductory NLP course.
In Proceedings of the ThirdWorkshop on Issues in Teaching Computational Lin-guistics.
Association for Computational Linguistics.Nitin Madnani.
2007.
Getting started on natural lan-guage processing with Python.
ACM Crossroads,13(4).Matplotlib.
2008.
Matplotlib: Python 2D plottinglibrary.
http://matplotlib.sourceforge.net/.William McCune.
2008.
Prover9: Automatedtheorem prover for first-order and equational logic.http://www.cs.unm.edu/?mccune/mace4/manual-examples.html.NumPy.
2008.
NumPy: Scientific computing withPython.
http://numpy.scipy.org/.Stuart Robinson, Greg Aumann, and Steven Bird.
2007.Managing fieldwork data with Toolbox and the Natu-ral Language Toolkit.
Language Documentation andConservation, 1:44?57.Christine Shannon.
2003.
Another breadth-firstapproach to CS I using Python.
In Proceedings ofthe 34th SIGCSE Technical Symposium on ComputerScience Education, pages 248?251.
ACM.Ian H. Witten and Eibe Frank.
2005.
Data Mining: Prac-tical machine learning tools and techniques.
MorganKaufmann.70
