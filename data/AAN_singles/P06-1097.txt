Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 769?776,Sydney, July 2006. c?2006 Association for Computational LinguisticsSemi-Supervised Training for Statistical Word AlignmentAlexander FraserISI / University of Southern California4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292fraser@isi.eduDaniel MarcuISI / University of Southern California4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292marcu@isi.eduAbstractWe introduce a semi-supervised approachto training for statistical machine transla-tion that alternates the traditional Expecta-tion Maximization step that is applied on alarge training corpus with a discriminativestep aimed at increasing word-alignmentquality on a small, manually word-alignedsub-corpus.
We show that our algorithmleads not only to improved alignmentsbut also to machine translation outputs ofhigher quality.1 IntroductionThe most widely applied training procedure forstatistical machine translation ?
IBM model 4(Brown et al, 1993) unsupervised training fol-lowed by post-processing with symmetrizationheuristics (Och and Ney, 2003) ?
yields lowquality word alignments.
When compared withgold standard parallel data which was manuallyaligned using a high-recall/precision methodology(Melamed, 1998), the word-level alignments pro-duced automatically have an F-measure accuracyof 64.6 and 76.4% (see Section 2 for details).In this paper, we improve word alignment and,subsequently, MT accuracy by developing a rangeof increasingly sophisticated methods:1.
We first recast the problem of estimating theIBM models (Brown et al, 1993) in a dis-criminative framework, which leads to an ini-tial increase in word-alignment accuracy.2.
We extend the IBM models with new(sub)models, which leads to additional in-creases in word-alignment accuracy.
In theprocess, we also show that these improve-ments are explained not only by the powerof the new models, but also by a novel searchprocedure for the alignment of highest prob-ability.3.
Finally, we propose a training procedure thatinterleaves discriminative training with max-imum likelihood training.These steps lead to word alignments of higheraccuracy which, in our case, correlate with higherMT accuracy.The rest of the paper is organized as follows.In Section 2, we review the data sets we use tovalidate experimentally our algorithms and the as-sociated baselines.
In Section 3, we present itera-tively our contributions that eventually lead to ab-solute increases in alignment quality of 4.8% forFrench/English and 4.8% for Arabic/English, asmeasured using F-measure for large word align-ment tasks.
These contributions pertain to thecasting of the training procedure in the discrim-inative framework (Section 3.1); the IBM modelextensions and modified search procedure for theViterbi alignments (Section 3.2); and the in-terleaved, minimum error/maximum likelihood,training algorithm (Section 4).
In Section 5, we as-sess the impact that our improved alignments haveon MT quality.
We conclude with a comparison ofour work with previous research on discriminativetraining for word alignment and a short discussionof semi-supervised learning.2 Data Sets and BaselineWe conduct experiments on alignment andtranslation tasks using Arabic/English andFrench/English data sets (see Table 1 for details).Both sets have training data and two gold stan-dard word alignments for small samples of thetraining data, which we use as the alignment769ARABIC/ENGLISH FRENCH/ENGLISHA E F ETRAININGSENTS 3,713,753 2,842,184WORDS 102,473,086 119,994,972 75,794,254 67,366,819VOCAB 489,534 231,255 149,568 114,907SINGLETONS 199,749 104,155 60,651 47,765ALIGN DISCR.SENTS 100 110WORDS 1,712 2,010 1,888 1,726LINKS 2,129 2,292ALIGN TESTSENTS 55 110WORDS 1,004 1,210 1,899 1,716LINKS 1,368 2,176MAX BLEU SENTS 728 (4 REFERENCES) 833 (1 REFERENCE)WORDS 17664 22.0K TO 24.5K 20,562 17,454TRANS.
TEST SENTS 663 (4 REFERENCES) 2,380 (1 REFERENCE)WORDS 16,075 19.0K TO 21.6K 58,990 49,182Table 1: DatasetsSYSTEM F-MEASURE F TO E F-MEASURE E TO F F-MEASURE BEST SYMM.A/E MODEL 4: ITERATION 4 65.6 / 60.5 53.6 / 50.2 69.1 / 64.6 (UNION)F/E MODEL 4: ITERATION 4 73.8 / 75.1 74.2 / 73.5 76.5 / 76.4 (REFINED)Table 2: Baseline Results.
F-measures are presented on both the alignment discriminative training setand the alignment test set sub-corpora, separated by /.discriminative training set and alignment test set.Translation quality is evaluated by translatinga held-out translation test set.
An additionaltranslation set called the Maximum BLEU set isemployed by the SMT system to train the weightsassociated with the components of its log-linearmodel (Och, 2003).The training corpora are publicly avail-able: both the Arabic/English data and theFrench/English Hansards were released byLDC.
We created the manual word alignmentsourselves, following the Blinker guidelines(Melamed, 1998).To train our baseline systems we follow a stan-dard procedure.
The models were trained twotimes, first using French or Arabic as the sourcelanguage and then using English as the sourcelanguage.
For each training direction, we runGIZA++ (Och and Ney, 2003), specifying 5 iter-ations of Model 1, 4 iterations of the HMM model(Vogel et al, 1996), and 4 iterations of Model 4.We quantify the quality of the resulting hypothe-sized alignments with F-measure using the manu-ally aligned sets.We present the results for three different con-ditions in Table 2.
For the ?F to E?
direction themodels assign non-zero probability to alignmentsconsisting of links from one Foreign word to zeroor more English words, while for ?E to F?
themodels assign non-zero probability to alignmentsconsisting of links from one English word to zeroor more Foreign words.
It is standard practice toimprove the final alignments by combining the ?Fto E?
and ?E to F?
directions using symmetriza-tion heuristics.
We use the ?union?, ?refined?
and?intersection?
heuristics defined in (Och and Ney,2003) which are used in conjunction with IBMModel 4 as the baseline in virtually all recent workon word alignment.
In Table 2, we report the bestsymmetrized results.The low F-measure scores of the baselines mo-tivate our work.3 Improving Word Alignments3.1 Discriminative Reranking of the IBMModelsWe reinterpret the five groups of parameters ofModel 4 listed in the first five lines of Table 3 assub-models of a log-linear model (see Equation 1).Each sub-model hm has an associated weight ?m.Given a vector of these weights ?, the alignmentsearch problem, i.e.
the search to return the bestalignment a?
of the sentences e and f according tothe model, is specified by Equation 2.p?
(f, a|e) =exp(?i ?ihi(a, e, f))?a?,f ?
exp(?i ?ihi(a?, e, f ?))(1)a?
= argmaxa?i?ihi(f, a, e) (2)770m Model 4 Description m Description1 t(f |e) translation probs, f and e are words 9 translation table using approx.
stems2 n(?|e) fertility probs, ?
is number of words generated by e 10 backoff fertility (fertility estimatedover all e)3 null parameters used in generating Foreign words whichare unaligned11 backoff fertility for words with count<= 54 d1(4j) movement probs of leftmost Foreign word translatedfrom a particular e12 translation table from HMM iteration 45 d>1(4j) movement probs of other Foreign words translatedfrom a particular e13 zero fertility English word penalty6 translation table from refined combination of bothalignments14 non-zero fertility English word penalty7 translation table from union of both alignments 15 NULL Foreign word penalty8 translation table from intersection of both alignments 16 non-NULL Foreign word penaltyTable 3: Sub-Models.
Note that sub-models 1 to 5 are IBM Model 4, sub-models 6 to 16 are new.Log-linear models are often trained to maxi-mize entropy, but we will train our model di-rectly on the final performance criterion.
We use1?F-measure as our error function, comparing hy-pothesized word alignments for the discriminativetraining set with the gold standard.Och (2003) has described an efficient exactone-dimensional error minimization technique fora similar search problem in machine translation.The technique involves calculating a piecewiseconstant function fm(x) which evaluates the er-ror of the hypotheses which would be picked byequation 2 from a set of hypotheses if we hold allweights constant, except for the weight ?m (whichis set to x).The discriminative reranking algorithm is ini-tialized with the parameters of the sub-models ?,an initial choice of the ?
vector, gold standardword alignments (labels) for the alignment dis-criminative training set, the constant N specifyingthe N-best list size used1, and an empty master setof hypothesized alignments.
The algorithm is athree step loop:1.
Enrich the master set of hypothesized align-ments by producing an N-best list using ?.If all of the hypotheses in the N-best list arealready in the master set, the algorithm hasconverged, so terminate the loop.2.
Consider the current ?
vector and 999 addi-tional randomly generated vectors, setting ?to the vector with lowest error on the masterset.3.
Repeatedly run Och?s one-dimensional errorminimization step until there is no further er-ror reduction (this results in a new vector ?
).1N = 128 for our experiments3.2 Improvements to the Model and Search3.2.1 New Sources of KnowledgeWe define new sub-models to model factors notcaptured by Model 4.
These are lines 6 to 16of Table 3, where we use the ?E to F?
align-ment direction as an example.
We use word-leveltranslation tables informed by both the ?E to F?and the ?F to E?
translation directions derived us-ing the three symmetrization heuristics, the ?E toF?
translation table from the final iteration of theHMM model and an ?E to F?
translation table de-rived using approximative stemming.
The approx-imative stemming sub-model (sub-model 9) usesthe first 4 letters of each vocabulary item as thestem for English and French while for Arabic weuse the full word as the stem.
We also use sub-models for backed off fertility, and direct penal-ization of unaligned English words (?zero fertil-ity?)
and aligned English words, and unalignedForeign words (?NULL-generated?
words) andaligned Foreign words.
This is a small samplingof the kinds of knowledge sources we can use inthis framework; many others have been proposedin the literature.Table 4 shows an evaluation of discriminativereranking.
We observe:1.
The first line is the starting point, which isthe Viterbi alignment of the 4th iteration ofHMM training.2.
The 1-to-many alignments generated by dis-criminatively reranking Model 4 are betterthan the 1-to-many alignments of four itera-tions of Model 4.3.
The 1-to-many alignments of the discrimina-tively reranked extended model are much bet-ter than four iterations of Model 4.771SYSTEM F-MEASURE F TO E F-MEASURE E TO F F-MEASURE BEST SYMM.A/E LAST ITERATION HMM 58.6 / 54.4 47.7 / 39.9 62.1 / 57.0 (UNION)A/E MODEL 4 RERANKING 65.3 / 59.5 55.7 / 51.4 69.7 / 64.6 (UNION)A/E EXTENDED MODEL RERANKING 68.4 / 62.2 61.6 / 57.7 72.0 / 66.4 (UNION)A/E MODEL 4: ITERATION 4 65.6 / 60.5 53.6 / 50.2 69.1 / 64.6 (UNION)F/E LAST ITERATION HMM 72.4 / 73.9 71.5 / 71.8 76.4 / 77.3 (REFINED)F/E MODEL 4 RERANKING 77.9 / 77.9 78.4 / 77.7 79.2 / 79.4 (REFINED)F/E EXTENDED MODEL RERANKING 78.7 / 80.2 79.3 / 79.6 79.6 / 80.4 (REFINED)F/E MODEL 4: ITERATION 4 73.8 / 75.1 74.2 / 73.5 76.5 / 76.4 (REFINED)Table 4: Discriminative Reranking with Improved Search.
F-measures are presented on both the align-ment discriminative training set and the alignment test set sub-corpora, separated by /.4.
The discriminatively reranked extendedmodel outperforms four iterations of Model4 in both cases with the best heuristicsymmetrization, but some of the gain islost as we are optimizing the F-measure ofthe 1-to-many alignments rather than theF-measure of the many-to-many alignmentsdirectly.Overall, the results show our approach is betterthan or competitive with running four iterations ofunsupervised Model 4 training.3.2.2 New Alignment Search AlgorithmBrown et al (1993) introduced operations defin-ing a hillclimbing search appropriate for Model 4.Their search starts with a complete hypothesis andexhaustively applies two operations to it, selectingthe best improved hypothesis it can find (or termi-nating if no improved hypothesis is found).
Thissearch makes many search errors2.
We developeda new alignment algorithm to reduce search errors:?
We perform an initial hillclimbing search (asin the baseline algorithm) but construct a pri-ority queue of possible other candidate align-ments to consider.?
Alignments which are expanded are markedso that they will not be returned to at a futurepoint in the search.?
The alignment search operates by consider-ing complete hypotheses so it is an ?anytime?algorithm (meaning that it always has a cur-rent best guess).
Timers can therefore beused to terminate the processing of the pri-ority queue of candidate alignments.The first two improvements are related to thewell-known Tabu local search algorithm (Glover,2A search error in a word aligner is a failure to find thebest alignment according to the model, i.e.
in our case a fail-ure to maximize Equation 2.1986).
The third improvement is important forrestricting total time used when producing align-ments for large training corpora.We performed two experiments.
The first evalu-ates the number of search errors.
For each corpuswe sampled 1000 sentence pairs randomly, withno sentence length restriction.
Model 4 parametersare estimated from the final HMM Viterbi align-ment of these sentence pairs.
We then search totry to find the Model 4 Viterbi alignment with boththe new and old algorithms, allowing them bothto process for the same amount of time.
The per-centage of known search errors is the percentageof sentences from our sample in which we wereable to find a more probable candidate by apply-ing our new algorithm using 24 hours of compu-tation for just the 1000 sample sentences.
Table5 presents the results, showing that our new algo-rithm reduced search errors in all cases, but fur-ther reduction could be obtained.
The second ex-periment shows the impact of the new search ondiscriminative reranking of Model 4 (see Table 6).Reduced search errors lead to a better fit of the dis-criminative training corpus.4 Semi-Supervised Training for WordAlignmentsIntuitively, in approximate EM training for Model4 (Brown et al, 1993), the E-step corresponds tocalculating the probability of all alignments ac-cording to the current model estimate, while theM-step is the creation of a new model estimategiven a probability distribution over alignments(calculated in the E-step).In the E-step ideally all possible alignmentsshould be enumerated and labeled with p(a|e, f),but this is intractable.
For the M-step, we wouldlike to count over all possible alignments for eachsentence pair, weighted by their probability ac-cording to the model estimated at the previous772SYSTEM F TO E ERRORS % E TO F ERRORS %A/E OLD 19.4 22.3A/E NEW 8.5 15.3F/E OLD 32.5 25.9F/E NEW 13.7 10.4Table 5: Comparison of New Search Algorithm with Old Search AlgorithmSYSTEM F-MEASURE F TO E F-MEASURE E TO F F-MEASURE BEST SYMM.A/E MODEL 4 RERANKING OLD 64.1 / 58.1 54.0 / 48.8 67.9 / 63.0 (UNION)A/E MODEL 4 RERANKING NEW 65.3 / 59.5 55.7 / 51.4 69.7 / 64.6 (UNION)F/E MODEL 4 RERANKING OLD 77.3 / 77.8 78.3 / 77.2 79.2 / 79.1 (REFINED)F/E MODEL 4 RERANKING NEW 77.9 / 77.9 78.4 / 77.7 79.2 / 79.4 (REFINED)Table 6: Impact of Improved Search on Discriminative Reranking of Model 4step.
Because this is not tractable, we make theassumption that the single assumed Viterbi align-ment can be used to update our estimate in the M-step.
This approximation is called Viterbi training.Neal and Hinton (1998) analyze approximate EMtraining and motivate this type of variant.We extend approximate EM training to performa new type of training which we call Minimum Er-ror / Maximum Likelihood Training.
The intuitionbehind this approach to semi-supervised trainingis that we wish to obtain the advantages of bothdiscriminative training (error minimization) andapproximate EM (which allows us to estimate alarge numbers of parameters even though we havevery few gold standard word alignments).
We in-troduce the EMD algorithm, in which discrimina-tive training is used to control the contributionsof sub-models (thereby minimizing error), while aprocedure similar to one step of approximate EMis used to estimate the large number of sub-modelparameters.A brief sketch of the EMD algorithm appliedto our extended model is presented in Figure 1.Parameters have a superscript t representing theirvalue at iteration t. We initialize the algorithmwith the gold standard word alignments (labels) ofthe word alignment discriminative training set, aninitial ?, N, and the starting alignments (the iter-ation 4 HMM Viterbi alignment).
In line 2, wemake iteration 0 estimates of the 5 sub-models ofModel 4 and the 6 heuristic sub-models which areiteration dependent.
In line 3, we run discrimi-native training using the algorithm from Section3.1.
In line 4, we measure the error of the result-ing ?
vector.
In the main loop in line 7 we alignthe full training set (similar to the E-step of EM),while in line 8 we estimate the iteration-dependentsub-models (similar to the M-step of EM).
Then1: Algorithm EMD(labels, ?
?, N, starting alignments)2: estimate ?0m for m = 1 to 113: ?0 = Discrim(?0, ?
?, labels, N)4: e0 = E(?0, labels)5: t = 16: loop7: align full training set using ?t?1 and ?t?1m8: estimate ?tm for m = 1 to 119: ?t = Discrim(?t, ??
?, labels, N)10: et = E(?t, labels)11: if et >= et?1 then12: terminate loop13: end if14: t = t + 115: end loop16: return hypothesized alignments of full training setFigure 1: Sketch of the EMD algorithmwe perform discriminative reranking in line 9 andcheck for convergence in lines 10 and 11 (conver-gence means that error was not decreased from theprevious iteration).
The output of the algorithm isnew hypothesized alignments of the training cor-pus.Table 7 evaluates the EMD semi-supervisedtraining algorithm.
We observe:1.
In both cases there is improved F-measureon the second iteration of semi-supervisedtraining, indicating that the EMD algorithmperforms better than one step discriminativereranking.2.
The French/English data set has converged3after the second iteration.3.
The Arabic/English data set converged afterimprovement for the first, second and thirditerations.We also performed an additional experiment forFrench/English aimed at understanding the poten-tial contribution of the word aligned data without3Convergence is achieved because error on the wordalignment discriminative training set does not improve.773SYSTEM F-MEASURE F TO E F-MEASURE E TO F BEST SYMM.A/E STARTING POINT 58.6 / 54.4 47.7 / 39.9 62.1 / 57.0 (UNION)A/E EMD: ITERATION 1 68.4 / 62.2 61.6 / 57.7 72.0 / 66.4 (UNION)A/E EMD: ITERATION 2 69.8 / 63.1 64.1 / 59.5 74.1 / 68.1 (UNION)A/E EMD: ITERATION 3 70.6 / 65.4 64.3 / 59.2 74.7 / 69.4 (UNION)F/E STARTING POINT 72.4 / 73.9 71.5 / 71.8 76.4 / 77.3 (REFINED)F/E EMD: ITERATION 1 78.7 / 80.2 79.3 / 79.6 79.6 / 80.4 (REFINED)F/E EMD: ITERATION 2 79.4 / 80.5 79.8 / 80.5 79.9 / 81.2 (REFINED)Table 7: Semi-Supervised Training Task F-measurethe new algorithm4.
Like Ittycheriah and Roukos(2005), we converted the alignment discrimina-tive training corpus links into a special corpusconsisting of parallel sentences where each sen-tence consists only of a single word involved inthe link.
We found that the information in thelinks was ?washed out?
by the rest of the data andresulted in no change in the alignment test set?sF-Measure.
Callison-Burch et al (2004) showedin their work on combining alignments of lowerand higher quality that the alignments of higherquality should be given a much higher weight thanthe lower quality alignments.
Using this insight,we found that adding 10,000 copies of the specialcorpus to our training data resulted in the highestalignment test set gain, which was a small gainof 0.6 F-Measure.
This result suggests that whilethe link information is useful for improving F-Measure, our improved methods for training areproducing much larger improvements.5 Improvement of MT QualityThe symmetrized alignments from the last iter-ation of EMD were used to build phrasal SMTsystems, as were the symmetrized Model 4 align-ments (the baseline).
Aside from the final align-ment, all other resources were held constant be-tween the baseline and contrastive SMT systems,including those based on lower level alignmentsmodels such as IBM Model 1.
For all of our ex-periments, we use two language models, one builtusing the English portion of the training data andthe other built using additional English news data.We run Maximum BLEU (Och, 2003) for 25 iter-ations individually for each system.Table 8 shows our results.
We report BLEU (Pa-pineni et al, 2001) multiplied by 100.
We alsoshow the F-measure after heuristic symmetrizationof the alignment test sets.
The table shows that4We would like to thank an anonymous reviewer for sug-gesting that this experiment would be useful even when usinga small discriminative training corpus.our algorithm produces heuristically symmetrizedfinal alignments of improved F-measure.
Us-ing these alignments in our phrasal SMT system,we produced a statistically significant BLEU im-provement (at a 95% confidence interval a gain of0.78 is necessary) on the French/English task anda statistically significant BLEU improvement onthe Arabic/English task (at a 95% confidence in-terval a gain of 1.2 is necessary).5.1 Error CriterionThe error criterion we used for all experimentsis 1 ?
F-measure.
The formula for F-measure isshown in Equation 3.
(Fraser and Marcu, 2006) es-tablished that tuning the trade-off between Preci-sion and Recall in the F-Measure formula will leadto the best BLEU results.
We tuned ?
by build-ing a collection of alignments using our baselinesystem, measuring Precision and Recall againstthe alignment discriminative training set, build-ing SMT systems and measuring resulting BLEUscores, and then searching for an appropriate ?setting.
We searched ?
= 0.1, 0.2, ..., 0.9 and set?
so that the resulting F-measure tracks BLEU tothe best extent possible.
The best settings were?
= 0.2 for Arabic/English and ?
= 0.7 forFrench/English, and these settings of ?
were usedfor every result reported in this paper.
See (Fraserand Marcu, 2006) for further details.F (A, S, ?)
= 1?Precision(A,S) +(1??
)Recall(A,S)(3)6 Previous ResearchPrevious work on discriminative training for word-alignment differed most strongly from our ap-proach in that it generally views word-alignmentas a supervised task.
Examples of this perspectiveinclude (Liu et al, 2005; Ittycheriah and Roukos,2005; Moore, 2005; Taskar et al, 2005).
Allof these also used knowledge from one of theIBM Models in order to obtain competitive results774SYSTEM BLEU F-MEASUREA/E UNSUP.
MODEL 4 UNION 49.16 64.6A/E EMD 3 UNION 50.84 69.4F/E UNSUP.
MODEL 4 REFINED 30.63 76.4F/E EMD 2 REFINED 31.56 81.2Table 8: Evaluation of Translation Qualitywith the baseline (with the exception of (Moore,2005)).
We interleave discriminative training withEM and are therefore performing semi-supervisedtraining.
We show that semi-supervised trainingleads to better word alignments than running unsu-pervised training followed by discriminative train-ing.Another important difference with previouswork is that we are concerned with generatingmany-to-many word alignments.
Cherry and Lin(2003) and Taskar et al (2005) compared their re-sults with Model 4 using ?intersection?
by look-ing at AER (with the ?Sure?
versus ?Possible?
linkdistinction), and restricted themselves to consider-ing 1-to-1 alignments.
However, ?union?
and ?re-fined?
alignments, which are many-to-many, arewhat are used to build competitive phrasal SMTsystems, because ?intersection?
performs poorly,despite having been shown to have the best AERscores for the French/English corpus we are using(Och and Ney, 2003).
(Fraser and Marcu, 2006)recently found serious problems with AER bothempirically and analytically, which explains whyoptimizing AER frequently results in poor ma-chine translation performance.Finally, we show better MT results by using F-measure with a tuned ?
value.
The only previousdiscriminative approach which has been shown toproduce translations of similar or better quality tothose produced by the symmetrized baseline was(Ittycheriah and Roukos, 2005).
They had accessto 5000 gold standard word alignments, consider-ably more than the 100 or 110 gold standard wordalignments used here.
They also invested signif-icant effort in sub-model engineering (producingboth sub-models specific to Arabic/English align-ment and sub-models which would be useful forother language pairs), while we use sub-modelswhich are simple extensions of Model 4 and lan-guage independent.The problem of semi-supervised learning is of-ten defined as ?using unlabeled data to help su-pervised learning?
(Seeger, 2000).
Most work onsemi-supervised learning uses underlying distribu-tions with a relatively small number of parame-ters.
An initial model is estimated in a supervisedfashion using the labeled data, and this supervisedmodel is used to attach labels (or a probability dis-tribution over labels) to the unlabeled data, then anew supervised model is estimated, and this is it-erated.
If these techniques are applied when thereare a small number of labels in relation to the num-ber of parameters used, they will suffer from the?overconfident pseudo-labeling problem?
(Seeger,2000), where the initial labels of poor quality as-signed to the unlabeled data will dominate themodel estimated in the M-step.
However, thereare tasks with large numbers of parameters wherethere are sufficient labels.
Nigam et al (2000) ad-dressed a text classification task.
They estimatea Naive Bayes classifier over the labeled data anduse it to provide initial MAP estimates for unla-beled documents, followed by EM to further re-fine the model.
Callison-Burch et al (2004) exam-ined the issue of semi-supervised training for wordalignment, but under a scenario where they simu-lated sufficient gold standard word alignments tofollow an approach similar to Nigam et al (2000).We do not have enough labels for this approach.We are aware of two approaches to semi-supervised learning which are more similar inspirit to ours.
Ivanov et al (2001) used discrimi-native training in a reinforcement learning contextin a similar way to our adding of a discriminativetraining step to an unsupervised context.
A largebody of work uses semi-supervised learning forclustering by imposing constraints on clusters.
Forinstance, in (Basu et al, 2004), the clustering sys-tem was supplied with pairs of instances labeledas belonging to the same or different clusters.7 ConclusionWe presented a semi-supervised algorithm basedon IBM Model 4, with modeling and search ex-tensions, which produces alignments of improvedF-measure over unsupervised Model 4 training.We used these alignments to produce transla-tions of higher quality.775The semi-supervised learning literature gen-erally addresses augmenting supervised learningtasks with unlabeled data (Seeger, 2000).
In con-trast, we augmented an unsupervised learning taskwith labeled data.
We hope that Minimum Error /Maximum Likelihood training using the EMD al-gorithm can be used for a wide diversity of taskswhere there is not enough labeled data to allowsupervised estimation of an initial model of rea-sonable quality.8 AcknowledgmentsThis work was partially supported under theGALE program of the Defense Advanced Re-search Projects Agency, Contract No.
HR0011-06-C-0022.
We would like to thank the USC Cen-ter for High Performance Computing and Commu-nications.ReferencesSugato Basu, Mikhail Bilenko, and Raymond J.Mooney.
2004.
A probabilistic framework for semi-supervised clustering.
In KDD ?04: Proc.
of theACM SIGKDD international conference on knowl-edge discovery and data mining, pages 59?68, NewYork.
ACM Press.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and R. L. Mercer.
1993.
The mathe-matics of statistical machine translation: Parameterestimation.
Computational Linguistics, 19(2):263?311.Chris Callison-Burch, David Talbot, and Miles Os-borne.
2004.
Statistical machine translation withword- and sentence-aligned parallel corpora.
InProc.
of the 42nd Annual Meeting of the Associationfor Computational Linguistics, Barcelona, Spain,July.Colin Cherry and Dekang Lin.
2003.
A probabilitymodel to improve word alignment.
In Proc.
of the41st Annual Meeting of the Association for Compu-tational Linguistics, Sapporo, Japan, July.Alexander Fraser and Daniel Marcu.
2006.
Measur-ing word alignment quality for statistical machinetranslation.
In Technical Report ISI-TR-616.
Avail-able at http://www.isi.edu/ fraser/research.html,ISI/University of Southern California, May.Fred Glover.
1986.
Future paths for integer program-ming and links to artificial intelligence.
Computersand Operations Research, 13(5):533?549.Abraham Ittycheriah and Salim Roukos.
2005.
Amaximum entropy word aligner for Arabic-Englishmachine translation.
In Proc.
of Human LanguageTechnology Conf.
and Conf.
on Empirical Methodsin Natural Language Processing, Vancouver, BC.Yuri A. Ivanov, Bruce Blumberg, and Alex Pentland.2001.
Expectation maximization for weakly labeleddata.
In ICML ?01: Proc.
of the Eighteenth Interna-tional Conf.
on Machine Learning, pages 218?225.Yang Liu, Qun Liu, and Shouxun Lin.
2005.
Log-linear models for word alignment.
In Proc.
of the43rd Annual Meeting of the Association for Compu-tational Linguistics, pages 459?466, Ann Arbor, MI.I.
Dan Melamed.
1998.
Manual annotation of trans-lational equivalence: The blinker project.
Techni-cal Report 98-07, Institute for Research in CognitiveScience, Philadelphia, PA.Robert C. Moore.
2005.
A discriminative frameworkfor bilingual word alignment.
In Proc.
of HumanLanguage Technology Conf.
and Conf.
on EmpiricalMethods in Natural Language Processing, Vancou-ver, BC, October.Radford M. Neal and Geoffrey E. Hinton.
1998.
Aview of the EM algorithm that justifies incremental,sparse, and other variants.
In M. I. Jordan, editor,Learning in Graphical Models.
Kluwer.Kamal Nigam, Andrew K. McCallum, SebastianThrun, and Tom M. Mitchell.
2000.
Text classifi-cation from labeled and unlabeled documents usingEM.
Machine Learning, 39(2/3):103?134.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proc.
of the 41stAnnual Meeting of the Association for Computa-tional Linguistics, pages 160?167, Sapporo, Japan.Kishore A. Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2001.
BLEU: a method for auto-matic evaluation of machine translation.
TechnicalReport RC22176 (W0109-022), IBM Research Di-vision, Thomas J. Watson Research Center, York-town Heights, NY, September.Matthias Seeger.
2000.
Learning with labeled and un-labeled data.
In Technical report, 2000.
Available athttp://www.dai.ed.ac.uk/ seeger/papers.html.Ben Taskar, Simon Lacoste-Julien, and Dan Klein.2005.
A discriminative matching approach to wordalignment.
In Proc.
of Human Language Technol-ogy Conf.
and Conf.
on Empirical Methods in Natu-ral Language Processing, Vancouver, BC, October.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statisticaltranslation.
In COLING ?96: The 16th Int.
Conf.
onComputational Linguistics, pages 836?841, Copen-hagen, Denmark, August.776
