Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 52?61,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsA Fast and Accurate Method for Approximate String SearchZiqi Wang?School of EECSPeking UniversityBeijing 100871, Chinawangziqi@pku.edu.cnGu XuMicrosoft Research AsiaBuilding 2, No.5 Danling Street,Beijing 100080, Chinaguxu@microsoft.comHang LiMicrosoft Research AsiaBuilding 2, No.5 Danling Street,Beijing 100080, Chinahangli@microsoft.comMing ZhangSchool of EECSPeking UniversityBeijing 100871, Chinamzhang@net.pku.edu.cnAbstractThis paper proposes a new method for ap-proximate string search, specifically candidategeneration in spelling error correction, whichis a task as follows.
Given a misspelled word,the system finds words in a dictionary, whichare most ?similar?
to the misspelled word.The paper proposes a probabilistic approach tothe task, which is both accurate and efficient.The approach includes the use of a log linearmodel, a method for training the model, andan algorithm for finding the top k candidates.The log linear model is defined as a condi-tional probability distribution of a correctedword and a rule set for the correction con-ditioned on the misspelled word.
The learn-ing method employs the criterion in candidategeneration as loss function.
The retrieval al-gorithm is efficient and is guaranteed to findthe optimal k candidates.
Experimental re-sults on large scale data show that the pro-posed approach improves upon existing meth-ods in terms of accuracy in different settings.1 IntroductionThis paper addresses the following problem, re-ferred to as approximate string search.
Given aquery string, a dictionary of strings (vocabulary),and a set of operators, the system returns the topk strings in the dictionary that can be transformedfrom the query string by applying several operatorsin the operator set.
Here each operator is a rulethat can replace a substring in the query string withanother substring.
The top k results are defined in?
Contribution during internship at Microsoft Research Asia.terms of an evaluation measure employed in a spe-cific application.
The requirement is that the taskmust be conducted very efficiently.Approximate string search is useful in many ap-plications including spelling error correction, sim-ilar terminology retrieval, duplicate detection, etc.Although certain progress has been made for ad-dressing the problem, further investigation on thetask is still necessary, particularly from the view-point of enhancing both accuracy and efficiency.Without loss of generality, in this paper we ad-dress candidate generation in spelling error correc-tion.
Candidate generation is to find the most pos-sible corrections of a misspelled word.
In such aproblem, strings are words, and the operators rep-resent insertion, deletion, and substitution of char-acters with or without surrounding characters, forexample, ?a???e?
and ?lly???ly?.
Note that can-didate generation is concerned with a single word;after candidate generation, the words surrounding itin the text can be further leveraged to make the finalcandidate selection, e.g., Li et al (2006), Goldingand Roth (1999).In spelling error correction, Brill and Moore(2000) proposed employing a generative model forcandidate generation and a hierarchy of trie struc-tures for fast candidate retrieval.
Our approach isa discriminative approach and is aimed at improv-ing Brill and Moore?s method.
Okazaki et al (2008)proposed using a logistic regression model for ap-proximate dictionary matching.
Their method is alsoa discriminative approach, but it is largely differ-ent from our approach in the following points.
Itformalizes the problem as binary classification and52assumes that there is only one rule applicable eachtime in candidate generation.
Efficiency is also not amajor concern for them, because it is for offline textmining.There are two fundamental problems in researchon approximate string search: (1) how to build amodel that can archive both high accuracy and ef-ficiency, and (2) how to develop a data structure andalgorithm that can facilitate efficient retrieval of thetop k candidates.In this paper, we propose a probabilistic approachto the task.
Our approach is novel and unique inthe following aspects.
It employs (a) a log-linear(discriminative) model for candidate generation, (b)an effective algorithm for model learning, and (c) anefficient algorithm for candidate retrieval.The log linear model is defined as a conditionalprobability distribution of a corrected word and arule set for the correction given the misspelled word.The learning method employs, in the training pro-cess, a criterion that represents the goal of mak-ing both accurate and efficient prediction (candidategeneration).
As a result, the model is optimallytrained toward its objective.
The retrieval algorithmuses special data structures and efficiently performsthe top k candidates finding.
It is guaranteed to findthe best k candidates without enumerating all thepossible ones.We empirically evaluated the proposed method inspelling error correction of web search queries.
Theexperimental results have verified that the accuracyof the top candidates given by our method is signifi-cantly higher than those given by the baseline meth-ods.
Our method is more accurate than the baselinemethods in different settings such as large rule setsand large vocabulary sizes.
The efficiency of ourmethod is also very high in different experimentalsettings.2 Related WorkApproximate string search has been studied by manyresearchers.
Previous work mainly focused on effi-ciency rather than model.
Usually, it is assumed thatthe model (similarity distance) is fixed and the goalis to efficiently find all the strings in the collectionwhose similarity distances are within a threshold.Most existing methods employ n-gram based algo-rithms (Behm et al, 2009; Li et al, 2007; Yang etal., 2008) or filtering algorithms (Mihov and Schulz,2004; Li et al, 2008).
Instead of finding all the can-didates in a fixed range, methods for finding the topk candidates have also been developed.
For exam-ple, the method by Vernica and Li (2009) utilizedn-gram based inverted lists as index structure anda similarity function based on n-gram overlaps andword frequencies.
Yang et al (2010) presented ageneral framework for top k retrieval based on n-grams.
In contrast, our work in this paper aims tolearn a ranking function which can achieve both highaccuracy and efficiency.Spelling error correction normally consists ofcandidate generation and candidate final selection.The former task is an example of approximate stringsearch.
Note that candidate generation is only con-cerned with a single word.
For single-word candi-date generation, rule-based approach is commonlyused.
The use of edit distance is a typical exam-ple, which exploits operations of character deletion,insertion and substitution.
Some methods generatecandidates within a fixed range of edit distance ordifferent ranges for strings with different lengths (Liet al, 2006; Whitelaw et al, 2009).
Other meth-ods make use of weighted edit distance to enhancethe representation power of edit distance (Ristad andYianilos, 1998; Oncina and Sebban, 2005; McCal-lum et al, 2005; Ahmad and Kondrak, 2005).Conventional edit distance does not take in con-sideration context information.
For example, peo-ple tend to misspell ?c?
to ?s?
or ?k?
dependingon contexts, and a straightforward application ofedit distance cannot deal with the problem.
To ad-dress the challenge, some researchers proposed us-ing a large number of substitution rules containingcontext information (at character level).
For exam-ple, Brill and Moore (2000) developed a genera-tive model including contextual substitution rules;and Toutanova and Moore (2002) further improvedthe model by adding pronunciation factors intothe model.
Schaback and Li (2007) proposed amulti-level feature-based framework for spelling er-ror correction including a modification of Brill andMoore?s model (2000).
Okazaki et al (2008) uti-lized substring substitution rules and incorporatedthe rules into a L1-regularized logistic regressionmodel.
Okazaki et al?s model is largely different53from the model proposed in this paper, althoughboth of them are discriminative models.
Their modelis a binary classification model and it is assumed thatonly a single rule is applied in candidate generation.Since users?
behavior of misspelling and correc-tion can be frequently observed in web search logdata, it has been proposed to mine spelling-errorand correction pairs by using search log data.
Themined pairs can be directly used in spelling errorcorrection.
Methods of selecting spelling and cor-rection pairs with maximum entropy model (Chen etal., 2007) or similarity functions (Islam and Inkpen,2009; Jones et al, 2006) have been developed.
Themined pairs can only be used in candidate genera-tion of high frequency typos, however.
In this paper,we work on candidate generation at the characterlevel, which can be applied to spelling error correc-tion for both high and low frequency words.3 Model for Candidate GenerationAs an example of approximate string search, weconsider candidate generation in spelling correction.Suppose that there is a vocabulary V and a mis-spelled word, the objective of candidate generationis to select the best corrections from the vocabularyV .
We care about both accuracy and efficiency of theprocess.
The problem is very challenging when thesize of vocabulary is large, because there are a largenumber of potential candidates to be verified.In this paper, we propose a probabilistic approachto candidate generation, which can achieve bothhigh accuracy and efficiency, and is particularlypowerful when the scale is large.In our approach, it is assumed that a large num-ber of misspelled words and their best correctionsare given as training data.
A probabilistic model isthen trained by using the training data, which canassign ranking scores to candidates.
The best can-didates for correction of a misspelled word are thusdefined as those candidates having the highest prob-abilistic scores with respect to the training data andthe operators.Hereafter, we will describe the probabilisticmodel for candidate generation, as well as trainingand exploitation of the model.n i c o s o o f t^ $Derived rulesEdit-distance based aligmentExpended rules with contextm i c r o s o f t^ $Figure 1: Example of rule extraction from word pair3.1 ModelThe operators (rules) represent insertion, deletion,and substitution of characters in a word with orwithout surrounding context (characters), which aresimilar to those defined in (Brill and Moore, 2000;Okazaki et al, 2008).
An operator is formally rep-resented a rule ?
?
?
that replaces a substring ?
ina misspelled word with ?, where ?, ?
?
{s|s =t, s = ?t, or s = t$} and t ?
??
is the set ofall possible strings over the alphabet.
Obviously,V ?
??.
We actually derive all the possible rulesfrom the training data using a similar approach to(Brill and Moore, 2000) as shown in Fig.
1.
Firstwe conduct the letter alignment based on the min-imum edit-distance, and then derive the rules fromthe alignment.
Furthermore we expand the derivedrules with surrounding words.
Without loss of gen-erality, we only consider using +2,+1, 0,?1,?2characters as contexts in this paper.If we can apply a set of rules to transform the mis-spelled word wm to a correct word wc in the vocab-ulary, then we call the rule set a ?transformation?for the word pair wm and wc.
Note that for a givenword pair, it is likely that there are multiple possibletransformations for it.
For example, both ?n??
?m?and ?ni???mi?
can transform ?nicrosoft?
to ?mi-crosoft?.Without loss of generality, we set the maximumnumber of rules applicable to a word pair to be afixed number.
As a result, the number of possibletransformations for a word pair is finite, and usuallylimited.
This is equivalent to the assumption that thenumber of spelling errors in a word is small.Given word pair (wm, wc), let R(wm, wc) denoteone transformation (a set of rules) that can rewrite54wm to wc.
We consider that there is a probabilisticmapping between the misspelled word wm and cor-rect word wc plus transformation R(wm, wc).
Wedefine the conditional probability distribution of wcandR(wm, wc) givenwm as the following log linearmodel:P (wc, R(wm, wc)|wm) (1)=exp(?r?R(wm,wc) ?r)?
(w?c,R(wm,w?c))?Z(wm) exp(?o?R(wm,w?c) ?o)where r or o denotes a rule in rule setR, ?r or ?o de-notes a weight, and the normalization is carried overZ(wm), all pairs of word w?c in V and transforma-tion R(wm, w?c), such that wm can be transformedto w?c by R(wm, w?c).
The log linear model actuallyuses binary features indicating whether or not a ruleis applied.In general, the weights in Equ.
(1) can be any realnumbers.
To improve efficiency in retrieval, we fur-ther assume that all the weights are non-positive, i.e.,?
?r ?
0.
It introduces monotonicity in rule applica-tion and implies that applying additional rules can-not lead to generation of better candidates.
For ex-ample, both ?office?
and ?officer?
are correct candi-dates of ?ofice?.
We view ?office?
a better candidate(with higher probability) than ?officer?, as it needsone less rule.
The assumption is reasonable becausethe chance of making more errors should be lowerthan that of making less errors.
Our experimentalresults have shown that the change in accuracy bymaking the assumption is negligible, but the gain inefficiency is very large.3.2 Training of ModelTraining data is given as a set of pairs T ={(wim, wic)}Ni=1, where wim is a misspelled word andwic ?
V is a correction ofwim.
The objective of train-ing would be to maximize the conditional probabil-ity P (wic, R(wim, wic)|wim) over the training data.This is not a trivial problem, however, becausethe ?true?
transformationR?
(wim, wic) for each wordpair wim and wic is not given in the training data.
It isoften the case that there are multiple transformationsapplicable, and it is not realistic to assume that suchinformation can be provided by humans or automat-ically derived.
(It is relatively easy to automaticallyfind the pairs wim and wic as explained in Section5.1).In this paper, we assume that the transformationthat actually generates the correction among all thepossible transformations is the one that can give themaximum conditional probability; the exactly samecriterion is also used for fast prediction.
Thereforewe have the following objective function??
=argmax?L(?)
(2)=argmax?
?imaxR(wim,wic)logP (wic, R(wim, wic)|wim)where ?
denotes the weight parameters and the maxis taken over the set of transformations that cantransform wim to wic.We employ gradient ascent in the optimization inEqu.
(2).
At each step, we first find the best trans-formation for each word pair based on the currentparameters ?(t)R?
(wim, wic) (3)= argmaxR(wim,wic)logP?
(t)(wic, R(wim, wic)|wim)Next, we calculate the gradients,?L?
?r=?i logP?
(t)(wic, R?
(wim, wic)|wim)?
?r(4)In this paper, we employ the bounded L-BFGS(Behm et al, 2009) algorithm for the optimizationtask, which works well even when the number ofweights ?
is large.3.3 Candidate GenerationIn candidate generation, given a misspelled wordwm, we find the k candidates from the vocabu-lary, that can be transformed from wm and have thelargest probabilities assigned by the learned model.We only need to utilize the following rankingfunction to rank a candidate wc given a misspelledword wm, by taking into account Equs.
(1) and (2)rank(wc|wm) = maxR(wm,wc)???r?R(wm,wc)?r??
(5)For each possible transformation, we simply takesummation of the weights of the rules used in thetransformation.
We then choose the sum as a rank-ing score, which is equivalent to ranking candidatesbased on their largest conditional probabilities.55aaa NULLNULL....................................______esa0.0-0.3-0.1failure linkleaf node linkAho Corasick Treea   ea   saa   aeeaFigure 2: Rule Index based on Aho Corasick Tree.4 Efficient Retrieval AlgorithmIn this section, we introduce how to efficiently per-form top k candidate generation.
Our retrieval algo-rithm is guaranteed to find the optimal k candidateswith some ?pruning?
techniques.
We first introducethe data structures and then the retrieval algorithm.4.1 Data StructuresWe exploit two data structures for candidate genera-tion.
One is a trie for storing and matching words inthe vocabulary, referred to as vocabulary trie, and theother based on what we call an Aho-Corasick tree(AC tree) (Aho and Corasick, 1975), which is usedfor storing and applying correction rules, referred toas rule index.
The vocabulary trie is the same as thatused in existing work and it will be traversed whensearching the top k candidates.Our rule index is unique because it indexes all therules based on an AC tree.
The AC tree is a trie with?failure links?, on which the Aho-Corasick stringmatching algorithm can be executed.
Aho-Corasickalgorithm is a well known dictionary-matching al-gorithm which can quickly locate all the words in adictionary within an input string.
Time complexityof the algorithm is of linear order in length of inputstring plus number of matched entries.We index all the ?
?s in the rules on the AC tree.Each ?
corresponds to a leaf node, and the ?
?s of the?
are stored in an associated list in decreasing orderof rule weights ?, as illustrated in Fig.
2.
11One may further improve the index structure by using a trierather than a ranking list to store ?s associated with the same?.
However the improvement would not be significant becausethe number of ?s associated with each ?
is usually very small.4.2 AlgorithmOne could employ a naive algorithm that applies allthe possible combinations of rules (?
?s) to the cur-rent word wm, verifies whether the resulting words(candidates) are in the vocabulary, uses the functionin Equ.
(5) to calculate the ranking scores of the can-didates, and find the top k candidates.
This algo-rithm is clearly inefficient.Our algorithm first employs the Aho-Corasick al-gorithm to locate all the applicable ?
?s within the in-put word wm, from the rule index.
The correspond-ing ?
?s are retrieved as well.
Then all the applicablerules are identified and indexed by the applied posi-tions of word wm.Our algorithm next traverses the vocabulary trieand searches the top k candidates with some pruningtechniques.
The algorithm starts from the root nodeof the vocabulary trie.
At each step, it has multiplesearch branches.
It tries to match at the next positionof wm, or apply a rule at the current position of wm.The following two pruning criteria are employed tosignificantly accelerate the search process.1) If the current sum of weights of applied rulesis smaller than the smallest weight in the top klist, the search branch is pruned.
This criterionis derived from the non-negative constraint onrule weights ?.
It is easy to verify that the sumof weights will not become larger if one contin-ues to search the branch because all the weightsare non-positive.2) If two search branches merge at the same nodein the vocabulary trie as well as the same po-sition on wm, the search branches with smallersum of weights will be pruned.
It is based onthe dynamic programming technique becausewe take max in the ranking function in Equ.
5.It is not difficult to prove that our algorithm is guar-anteed to find the best k candidates in terms of theranking scores, because we only prune those candi-dates that cannot give better scores than the ones inthe current top k list.
Due to the limitation of space,we omit the proof of the theorem that if the weightsof rules ?
are non-positive and the ranking functionis defined as in Equ.
5, then the top k candidates ob-tained with the pruning criteria are the same as thetop k candidates obtained without pruning.565 Experimental ResultsWe have experimentally evaluated our approach inspelling error correction of queries in web search.The problem is more challenging than usual due tothe following reasons.
(1) The vocabulary of queriesin web search is extremely large due to the scale, di-versity, and dynamics of the Internet.
(2) Efficiencyis critically important, because the response time oftop k candidate retrieval for web search must be keptvery low.
Our approach for candidate generation isin fact motivated by the application.5.1 Word Pair MiningIn web search, a search session is comprised of a se-quence of queries from the same user within a timeperiod.
It is easy to observe from search session datathat there are many spelling errors and their correc-tions occurring in the same sessions.
We employedheuristics to automatically mine training pairs fromsearch session data at a commercial search engine.First, we segmented the query sequence fromeach user into sessions.
If two queries were issuedmore than 5 minutes apart, then we put a sessionboundary between them.
We used short sessionshere because we found that search users usually cor-rect their misspelled queries very quickly after theyfind the misspellings.
Then the following heuristicswere employed to identify pairs of misspelled wordsand their corrections from two consecutive querieswithin a session:1) Two queries have the same number of words.2) There is only one word difference between twoqueries.3) For the two distinct words, the word in the firstquery is considered as misspelled and the sec-ond one as its correction.Finally, we aggregated the identified training pairsacross sessions and users and discarded the pairswith low frequencies.
Table 1 shows some examplesof the mined word pairs.5.2 Experiments on AccuracyTwo representative methods were used as baselines:the generative model proposed by (Brill and Moore,2000) referred to as generative and the logistic re-gression model proposed by (Okazaki et al, 2008)Misspelled Correct Misspelled Correctaacoustic acoustic chevorle chevroletliyerature literature tournemen tournamentshinngle shingle newpape newspaperfinlad finland ccomponet componentreteive retrieve olimpick olympicTable 1: Examples of Word Pairsreferred to as logistic.
Note that Okazaki et al(2008)?s model is not particularly for spelling errorcorrection, but it can be employed in the task.
Whenusing their method for ranking, we used outputs ofthe logistic regression model as rank scores.We compared our method with the two baselinesin terms of top k accuracy, which is ratio of the truecorrections among the top k candidates generated bya method.
All the methods shared the same settings:973,902 words in the vocabulary, 10,597 rules forcorrection, and up to two rules used in one transfor-mation.
We made use of 100,000 word pairs minedfrom query sessions for training, and 10,000 wordpairs for testing.The experimental results are shown in Fig.
3.
Wecan see that our method always performs the bestwhen compared with the baselines and the improve-ments are statistically significant (p < 0.01).
Thelogistic method works better than generative, whenk is small, but its performance becomes saturated,when k is large.
Usually a discriminative modelworks better than a generative model, and that seemsto be what happens with small k?s.
However, logis-tic cannot work so well for large k?s, because it onlyallows the use of one rule each time.
We observethat there are many word pairs in the data that needto be transformed with multiple rules.Next, we conducted experiments to investigatehow the top k accuracy changes with different sizesof vocabularies, maximum numbers of applicablerules and sizes of rule set for the three methods.
Theexperimental results are shown in Fig.
4, Fig.
5 andFig.
6.For the experiment in Fig.
4, we enlargedthe vocabulary size from 973,902 (smallVocab) to2,206,948 (largeVocab) and kept the other settingsthe same as in the previous experiment.
Becausemore candidates can be generated with a larger vo-cabulary, the performances of all the methods de-570 5 10 15 20 25 3040%50%60%70%80%90%100%top kAccuracyGenerativeLogisticOur MethodFigure 3: Accuracy Comparison between Our Methodand Baselinescline.
However, the drop of accuracy by our methodis much smaller than that by generative, whichmeans our method is more powerful when the vo-cabulary is large, e.g., for web search.
For the exper-iment in Fig.
5, we changed the maximum number ofrules that can be applied to a transformation from 2to 3.
Because logistic can only use one rule at a time,it is not included in this experiment.
When thereare more applicable rules, more candidates can begenerated and thus ranking of them becomes morechallenging.
The accuracies of both methods drop,but our method is constantly better than generative.Moreover, the decrease in accuracy by our methodis clearly less than that by generative.
For the ex-periment in Fig.
6, we enlarged the number of rulesfrom 10,497 (smallRuleNum) to 24,054 (largeRu-leNum).
The performance of our method and thoseof the two baselines did not change so much, and ourmethod still visibly outperform the baselines whenmore rules are exploited.5.3 Experiments on EfficiencyWe have also experimentally evaluated the effi-ciency of our approach.
Because most existing workuses a predefined ranking function, it is not fair tomake a comparison with them.
Moreover, Okazakiet al?
method does not consider efficiency, and Brilland Moore?s method is based a complicated retrievealgorithm which is very hard to implement.
Insteadof making comparison with the existing methods interms of efficiency, we evaluated the efficiency ofour method by looking at how efficient it becomeswith its data structure and pruning technique.0 5 10 15 20 25 3030%40%50%60%70%80%90%100%top kAccuracyGenerative (smallVocab)Generative (largeVocab)Logistic (smallVocab)Logistic (largeVocab)Our Method (smallVocab)Our Method (largeVocab)Figure 4: Accuracy Comparisons between Baselines andOur Method with Different Vocabulary Sizes0 5 10 15 20 25 3030%40%50%60%70%80%90%100%top kAccuracyGenerative (2 applicable rules)Generative (3 applicable rules)Our Method (2 applicable rules)Our Method (3 applicable rules)Figure 5: Accuracy Comparison between Generative andOur Method with Different Maximum Numbers of Ap-plicable Rules0 5 10 15 20 25 3040%50%60%70%80%90%100%Accuracytop kGenerative (largeRuleSet)Generative (smallRuleSet)Logistic (largeRuleSet)Logistic (smallRuleSet)Our Method (largeRuleSet)Our Method (smallRuleSet)Figure 6: Accuracy Comparison between Baselines andOur Method with Different Numbers of RulesFirst, we tested the efficiency of using Aho-Corasick algorithm (the rule index).
Because the580 5000 10000 15000 20000 250002468101214161820222426283032Number of RulesWord LengthNumberofMatchingRules45678910Figure 7: Number of Matching Rules v.s.
Number ofRulestime complexity of Aho-Corasick algorithm is de-termined by the lengths of query strings and thenumber of matches, we examined how the numberof matches on query strings with different lengthschanges when the number of rules increases.
Theexperimental results are shown in Fig.
7.
We can seethat the number of matches is not largely affected bythe number of rules in the rule index.
It implies thatthe time for searching applicable rules is close to aconstant and does not change much with differentnumbers of rules.Next, since the running time of our method isproportional to the number of visited nodes on thevocabulary trie, we evaluated the efficiency of ourmethod in terms of number of visited nodes.
Theresult reported here is that when k is 10.Specifically, we tested how the number of visitednodes changes according to three factors: maximumnumber of applicable rules in a transformation, vo-cabulary size and rule set size.
The experimental re-sults are shown in Fig.
8, Fig.
9 and Fig.
10 respec-tively.
From Fig.
8, with increasing maximum num-ber of applicable rules in a transformation, numberof visited nodes increases first and then stabilizes,especially when the words are long.
Note that prun-ing becomes even more effective because number ofvisited nodes without pruning grows much faster.
Itdemonstrates that our method is very efficient whencompared to the non-pruning method.
Admittedly,the efficiency of our method also deteriorates some-what.
This would not cause a noticeable issue inreal applications, however.
In the previous section,1 2 3 4 5 6 7020004000600080001000012000140001600018000Maximum Number of Applicable RulesNumberofVisitedNodesWord Length45678910Figure 8: Efficiency Evaluation with Different MaximumNumbers of Applicable Rules0 100 200 300 400 50001000200030004000500060007000Vocabulary Size (million)NumberofVisitedNodesWord Length45678910Figure 9: Efficiency Evaluation with Different Sizes ofVocabularywe have seen that using up to two rules in a transfor-mation can bring a very high accuracy.
From Fig.
8and Fig.
9, we can conclude that the numbers of vis-ited nodes are stable and thus the efficiency of ourmethod keeps high with larger vocabulary size andnumber of rules.
It indicates that our pruning strat-egy is very effective.
From all the figures, we can seethat our method is always efficient especially whenthe words are relatively short.5.4 Experiments on Model ConstraintsIn Section 3.1, we introduce the non-positive con-straints on the parameters, i.e., ?
?r ?
0, to en-able the pruning technique for efficient top k re-trieval.
We experimentally verified the impact ofthe constraints to both the accuracy and efficiency.For ease of reference, we name the model with thenon-positive constraints as bounded, and the origi-595000 10000 15000 20000 2500001000200030004000500060007000Number of RulesNumberofVisitedNodesWord Length45678910Figure 10: Efficiency Evaluation with Different Numberof Rules0 5 10 15 20 25 3040%50%60%70%80%90%100%top kAccuracyBoundedUnboundedFigure 11: Accuracy Comparison between Bounded andUnbounded Modelsnal model as unbounded.
The experimental resultsare shown in Fig.
11 and Fig.
12.
All the experi-ments were conducted based on the typical settingof our experiments: 973,902 words in the vocabu-lary, 10,597 rules, and up to two rules in one trans-formation.
In Fig.
11, we can see that the differ-ence between bounded and unbounded in terms ofaccuracy is negligible, and we can draw a conclu-sion that adding the constraints does not hurt the ac-curacy.
From Fig.
12, it is easy to note that boundedis much faster than unbounded because our pruningstrategy can be applied to bounded.6 ConclusionIn this paper, we have proposed a new method forapproximate string search, including spelling errorcorrection, which is both accurate and efficient.
Ourmethod is novel and unique in its model, learning4 6 8 10 12010002000300040005000600070008000900010000NumberofVisitedNodesWord LengthBoundedUnboundedFigure 12: Efficiency Comparison between Bounded andUnbounded Modelsalgorithm, and retrieval algorithm.
Experimental re-sults on a large data set show that our method im-proves upon existing methods in terms of accuracy,and particularly our method can perform better whenthe dictionary is large and when there are manyrules.
Experimental results have also verified thehigh efficiency of our method.
As future work, weplan to add contextual features into the model andapply our method to other data sets in other tasks.ReferencesFarooq Ahmad and Grzegorz Kondrak.
2005.
Learninga spelling error model from search query logs.
In Pro-ceedings of the conference on Human Language Tech-nology and Empirical Methods in Natural LanguageProcessing, HLT ?05, pages 955?962, Morristown, NJ,USA.
Association for Computational Linguistics.Alfred V. Aho and Margaret J. Corasick.
1975.
Efficientstring matching: an aid to bibliographic search.
Com-mun.
ACM, 18:333?340, June.Alexander Behm, Shengyue Ji, Chen Li, and Jiaheng Lu.2009.
Space-constrained gram-based indexing for effi-cient approximate string search.
In Proceedings of the2009 IEEE International Conference on Data Engi-neering, pages 604?615, Washington, DC, USA.
IEEEComputer Society.Eric Brill and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InProceedings of the 38th Annual Meeting on Associa-tion for Computational Linguistics, ACL ?00, pages286?293, Morristown, NJ, USA.
Association for Com-putational Linguistics.Qing Chen, Mu Li, and Ming Zhou.
2007.
Improv-ing query spelling correction using web search re-60sults.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning,pages 181?189.Andrew R. Golding and Dan Roth.
1999.
A winnow-based approach to context-sensitive spelling correc-tion.
Mach.
Learn., 34:107?130, February.Aminul Islam and Diana Inkpen.
2009.
Real-wordspelling correction using google web it 3-grams.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume 3- Volume 3, EMNLP ?09, pages 1241?1249, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Rosie Jones, Benjamin Rey, Omid Madani, and WileyGreiner.
2006.
Generating query substitutions.
InProceedings of the 15th international conference onWorld Wide Web, WWW ?06, pages 387?396, NewYork, NY, USA.
ACM.Mu Li, Yang Zhang, Muhua Zhu, and Ming Zhou.
2006.Exploring distributional similarity based models forquery spelling correction.
In Proceedings of the 21stInternational Conference on Computational Linguis-tics and the 44th annual meeting of the Associationfor Computational Linguistics, ACL-44, pages 1025?1032, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Chen Li, Bin Wang, and Xiaochun Yang.
2007.
Vgram:improving performance of approximate queries onstring collections using variable-length grams.
In Pro-ceedings of the 33rd international conference on Verylarge data bases, VLDB ?07, pages 303?314.
VLDBEndowment.Chen Li, Jiaheng Lu, and Yiming Lu.
2008.
Effi-cient merging and filtering algorithms for approximatestring searches.
In Proceedings of the 2008 IEEE 24thInternational Conference on Data Engineering, pages257?266, Washington, DC, USA.
IEEE Computer So-ciety.AndrewMcCallum, Kedar Bellare, and Fernando Pereira.2005.
A conditional random field for discriminatively-trained finite-state string edit distance.
In Conferenceon Uncertainty in AI (UAI).Stoyan Mihov and Klaus U. Schulz.
2004.
Fast approx-imate search in large dictionaries.
Comput.
Linguist.,30:451?477, December.Naoaki Okazaki, Yoshimasa Tsuruoka, Sophia Anani-adou, and Jun?ichi Tsujii.
2008.
A discriminativecandidate generator for string transformations.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing, EMNLP ?08, pages447?456, Morristown, NJ, USA.
Association for Com-putational Linguistics.Jose Oncina and Marc Sebban.
2005.
Learning unbiasedstochastic edit distance in the form of a memorylessfinite-state transducer.
In International Joint Confer-ence on Machine Learning (2005).
Workshop: Gram-matical Inference Applications: Successes and FutureChallenges.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learningstring-edit distance.
IEEE Trans.
Pattern Anal.
Mach.Intell., 20:522?532, May.Johannes Schaback and Fang Li.
2007.
Multi-level fea-ture extraction for spelling correction.
In IJCAI-2007Workshop on Analytics for Noisy Unstructured TextData, pages 79?86, Hyderabad, India.Kristina Toutanova and Robert C. Moore.
2002.
Pro-nunciation modeling for improved spelling correction.In Proceedings of the 40th Annual Meeting on Associ-ation for Computational Linguistics, ACL ?02, pages144?151, Morristown, NJ, USA.
Association for Com-putational Linguistics.Rares Vernica and Chen Li.
2009.
Efficient top-k algo-rithms for fuzzy search in string collections.
In Pro-ceedings of the First International Workshop on Key-word Search on Structured Data, KEYS ?09, pages 9?14, New York, NY, USA.
ACM.Casey Whitelaw, Ben Hutchinson, Grace Y. Chung, andGerard Ellis.
2009.
Using the web for language in-dependent spellchecking and autocorrection.
In Pro-ceedings of the 2009 Conference on Empirical Meth-ods in Natural Language Processing: Volume 2 - Vol-ume 2, EMNLP ?09, pages 890?899, Morristown, NJ,USA.
Association for Computational Linguistics.Xiaochun Yang, Bin Wang, and Chen Li.
2008.
Cost-based variable-length-gram selection for string collec-tions to support approximate queries efficiently.
InProceedings of the 2008 ACM SIGMOD internationalconference on Management of data, SIGMOD ?08,pages 353?364, New York, NY, USA.
ACM.Zhenglu Yang, Jianjun Yu, and Masaru Kitsuregawa.2010.
Fast algorithms for top-k approximate stringmatching.
In Proceedings of the Twenty-Fourth AAAIConference on Artificial Intelligence, AAAI ?10, pages1467?1473.61
