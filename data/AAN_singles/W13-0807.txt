Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 58?67,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsA Formal Characterization of Parsing Word Alignments by SynchronousGrammars with Empirical Evidence to the ITG HypothesisGideon Maillette de Buy Wenniger?University of Amsterdamgemdbw@gmail.comKhalil Sima?an?University of Amsterdamk.simaan@uva.nlAbstractDeciding whether a synchronous grammarformalism generates a given word alignment(the alignment coverage problem) depends onfinding an adequate instance grammar andthen using it to parse the word alignment.
Butwhat does it mean to parse a word align-ment by a synchronous grammar?
This is for-mally undefined until we define an unambigu-ous mapping between grammatical deriva-tions and word-level alignments.
This pa-per proposes an initial, formal characteriza-tion of alignment coverage as intersecting twopartially ordered sets (graphs) of translationequivalence units, one derived by a gram-mar instance and another defined by the wordalignment.
As a first sanity check, we reportextensive coverage results for ITG on auto-matic and manual alignments.
Even for theITG formalism, our formal characterizationmakes explicit many algorithmic choices of-ten left underspecified in earlier work.1 IntroductionThe training data used by current statistical machinetranslation (SMT) models consists of source andtarget sentence pairs aligned together at the wordlevel (word alignments).
For the hierarchical andsyntactically-enriched SMT models, e.g., (Chiang,2007; Zollmann and Venugopal, 2006), this trainingdata is used for extracting statistically weighted Syn-chronous Context-Free Grammars (SCFGs).
For-mally speaking, a synchronous grammar defines aset of (source-target) sentence pairs derived syn-chronously by the grammar.
Contrary to common?
Institute for Logic, Language and Computation.belief, however, a synchronous grammar (see e.g.,(Chiang, 2005; Satta and Peserico, 2005)) does notaccept (or parse) word alignments.
This is becausea synchronous derivation generates a tree pair witha bijective binary relation (links) between their non-terminal nodes.
For deciding whether a given wordalignment is generated/accepted by a given syn-chronous grammar, it is necessary to interpret thesynchronous derivations down to the lexical level.However, it is formally defined yet how to unam-biguously interpret the synchronous derivations ofa synchronous grammar as word alignments.
Onemajor difficulty is that synchronous productions, intheir most general form, may contain unaligned ter-minal sequences.
Consider, for instance, the rela-tively non-complex synchronous production?X ?
?
X(1) ?
X(2) ?
X(3), X ?
?
X(2) ?
X(1) ?
X(3)?where superscript (i) stands for aligned instancesof nonterminal X and all Greek symbols stand forarbitrary non-empty terminals sequences.
Given aword aligned sentence pair it is necessary to bindthe terminal sequence by alignments consistent withthe given word alignment, and then parse the wordalignment with the thus enriched grammar rules.This is not complex if we assume that each of thesource terminal sequences is contiguously alignedwith a target contiguous sequence, but difficult if weassume arbitrary alignments, including many-to-oneand non-contiguously aligned chunks.One important goal of this paper is to proposea formal characterization of what it means to syn-chronously parse a word alignment.
Our formalcharacterization is borrowed from the ?parsing as in-tersection" paradigm, e.g., (Bar-Hillel et al 1964;Lang, 1988; van Noord, 1995; Nederhof and Satta,582004).
Conceptually, our characterization makes useof three algorithms.
Firstly, parse the unaligned sen-tence pair with the synchronous grammar to obtain aset of synchronous derivations, i.e., trees.
Secondly,interpret a word alignment as generating a set ofsynchronous trees representing the recursive trans-lation equivalence relations of interest1 perceived inthe word alignment.
And finally, intersect the setsof nodes in the two sets of synchronous trees tocheck whether the grammar can generate (parts of)the word alignment.
The formal detail of each ofthese three steps is provided in sections 3 to 5.We think that alignment parsing is relevant forcurrent research because it highlights the differ-ence between alignments in training data and align-ments accepted by a synchronous grammar (learnedfrom data).
This is useful for literature on learn-ing from word aligned parallel corpora (e.g., (Zensand Ney, 2003; DeNero et al 2006; Blunsom et al2009; Cohn and Blunsom, 2009; Riesa and Marcu,2010; Mylonakis and Sima?an, 2011; Haghighi etal., 2009; McCarley et al 2011)).
A theoretical,formalized characterization of the alignment pars-ing problem is likely to improve the choices made inempirical work as well.
We exemplify our claims byproviding yet another empirical study of the stabilityof the ITG hypothesis.
Our study highlights some ofthe technical choices left implicit in preceding workas explained in the next section.2 First application to the ITG hypothesisA grammar formalism is a whole set/family of syn-chronous grammars.
For example, ITG (Wu, 1997)defines a family of inversion-transduction gram-mars differing among them in the exact set of syn-chronous productions, terminals and non-terminals.Given a synchronous grammar formalism and aninput word alignment, a relevant theoretical ques-tion is whether there exists an instance synchronousgrammar that generates the word alignment exactly.We will refer to this question as the alignment cover-age problem.
In this paper we propose an approachto the alignment coverage problem using the three-step solution proposed above for parsing word align-1The translation equivalence relations of interest may varyin kind as we will exemplify later.
The known phrase pairs aremerely one possible kind.ments by arbitrary synchronous grammars.Most current use of synchronous grammars islimited to a subclass using a pair of nonterminals,e.g., (Chiang, 2007; Zollmann and Venugopal, 2006;Mylonakis and Sima?an, 2011), thereby remain-ing within the confines of the ITG formalism (Wu,1997).
On the one hand, this is because of computa-tional complexity reasons.
On the other, this choicerelies on existing empirical evidence of what we willcall the ?ITG hypothesis", freely rephrased as fol-lows: the ITG formalism is sufficient for represent-ing a major percentage of reorderings in translationdata in general.Although checking whether a word alignment canbe generated by ITG is far simpler than for arbi-trary synchronous grammars, there is a striking vari-ation in the approaches taken in the existing litera-ture, e.g., (Zens and Ney, 2003; Wellington et al2006; S?gaard and Wu, 2009; Carpuat and Wu,2007; S?gaard and Kuhn, 2009; S?gaard, 2010).S?gaard and Wu (S?gaard and Wu, 2009) observejustifiably that the literature studying the ITG align-ment coverage makes conflicting choices in methodand data, and reports significantly diverging align-ment coverage scores.
We hypothesize here thatthe major conflicting choices in method (what tocount and how to parse) are likely due to the ab-sence of a well-understood, formalized method forparsing word alignments even under ITG.
In this pa-per we apply our formal approach to the ITG case,contributing new empirical evidence concerning theITG hypothesis.For our empirical study we exemplify our ap-proach by detailing an algorithm dedicated to ITG inNormal-Form (NF-ITG).
While our algorithm is inessence equivalent to existing algorithms for check-ing binarizability of permutations, e.g.,(Wu, 1997;Huang et al 2009), the formal foundations pre-ceding it concern nailing down the choices madein parsing arbitrary word alignments, as opposed to(bijective) permutations.
The formalization is ourway to resolve some of the major points of differ-ences in existing literature.We report new coverage results for ITG parsingof manual as well as automatic alignments, showingthe contrast between the two kinds.
While the latterseems built for phrase extraction, trading-off preci-sion for recall, the former is heavily marked with id-59iomatic expressions.
Our coverage results make ex-plicit a relevant dilemma.
To hierarchically parse thecurrent automatic word alignments exactly, we willneed more general synchronous reordering mecha-nisms than ITG, with increased risk of exponentialparsing algorithms (Wu, 1997; Satta and Peserico,2005).
But if we abandon these word alignments,we will face the exponential problem of learning re-ordering arbitrary permutations, cf.
(Tromble andEisner, 2009).
Our results also exhibit the impor-tance of explicitly defining the units of translationequivalence when studying (ITG) coverage of wordalignments.
The more complex the choice of trans-lation equivalence relations, the more difficult it is toparse the word alignments.3 Translation equivalence in MTIn (Koehn et al 2003), a translation equivalenceunit (TEU) is a phrase pair: a pair of contiguoussubstrings of the source and target sentences suchthat the words on the one side align only with wordson the other side (formal definitions next).
The hier-archical phrase pairs (Chiang, 2005; Chiang, 2007)are extracted by replacing one or more sub-phrasepairs, that are contained within a phrase pair, bypairs of linked variables.
This defines a subsumptionrelation between hierarchical phrase pairs (Zhang etal., 2008).
Actual systems, e.g., (Koehn et al 2003;Chiang, 2007) set an upperbound on length or thenumber of variables in the synchronous productions.For the purposes of our theoretical study, these prac-tical limitations are irrelevant.We give two definitions of translation equivalencefor word alignments.2 The first one makes no as-sumptions about the contiguity of TEUs, while thesecond does require them to be contiguous sub-strings on both sides (i.e., phrase pairs).As usual, s = s1...sm and t = t1...tn are source andtarget sentences respectively.
Let s?
be the sourceword at position ?
in s and t?
be the target word atposition ?
in t. An alignment link a ?
a in a wordalignment a is a pair of positions ?
?, ??
such that 1 ?2Unaligned words tend to complicate the formalization un-necessarily.
As usual we also require that unaligned words mustfirst be grouped with aligned words adjacent to them beforetranslation equivalence is defined for an alignment.
This stan-dard strategy allows us to informally discuss unaligned wordsin the following without loss of generality.?
?
m and 1 ?
?
?
n. For the sake of brevity, wewill often talk about alignments without explicitlymentioning the associated source and target words,knowing that these can be readily obtained from thepair of positions and the sentence pair ?s, t?.
Givena subset a?
?
a we define wordss(a?)
= {s?
| ?X :?
?, X?
?
a?}
and wordst(a?)
= {t?
| ?X : ?X, ??
?
a?
}.Now we consider triples (s?, t?, a?)
such thata?
?
a, s?
= wordss(a?)
and t?
= wordst(a?).
Wedefine the translation equivalence units (TEUs) inthe set TE(s, t, a) as follows:Definition 3.1 (s?, t?, a?)
?
TE(s, t, a) iff ?
?, ??
?
a??
(for all X, if ?
?, X?
?
a then ?
?, X?
?
a?)
?
(forall X, if ?X, ??
?
a then ?X, ??
?
a?
)In other words, if some alignment involving sourceposition ?
or ?
is included in a?, then all alignmentsin a containing that position are in a?
as well.
Thisdefinition allows a variety of complex word align-ments such as the so-called Cross-serial Discontigu-ous Translation Units and Bonbons (S?gaard andWu, 2009).We also define the subsumption relation (partialorder) <a as follows:Definition 3.2 A TEU u2 = (s2, t2, a2) subsumes(<a) a TEU u1 = (s1, t1, a1) iff a1 ?
a2.
The sub-sumption order will be represented by u1 <a u2.Based on the subsumption relation we can par-tition TE(s, t, a) into two disjoint sets : atomicTEAtom(s, t, a) and composed TEComp(s, t, a).Definition 3.3 u1 ?
TE(s, t, a) is atomic iff @ u2 ?TE(s, t, a) such that (u2 <a u1).Now the set TEAtom(s, t, a) is simply the setof all atomic translation equivalents, andthe set of composed translation equivalentsTEComp(s, t, a) = (TE(s, t, a) \ TEAtom(s, t, a)).Based on the general definition of translationequivalence, we can now give a more restricteddefinition that allows only contiguous translationequivalents (phrase pairs):Definition 3.4 (s?, t?, a?)
constitutes a contiguoustranslation equivalent iff:1.
(s?, t?, a?)
?
TE(s, t, a) and602.
Both s?
and t?
are contiguous substrings of sand t?
respectively.This set of translation equivalents is the unlimitedset of phrase pairs known from phrase-based ma-chine translation (Koehn et al 2003).
The relation<a as well as the division into atomic and composedTEUs can straightforwardly be adapted to contigu-ous translation equivalents.4 Grammatical translation equivalenceThe derivations of a synchronous grammar can beinterpreted as deriving a partially ordered set ofTEUs as well.
A finite derivation S ?+ ?s, t, aG?of an instance grammar G is a finite sequence ofterm-rewritings, where at each step of the sequence asingle nonterminal is rewritten using a synchronousproduction of G. The set of the finite derivationsof G defines a language, a set of triples ?s, t, aG?consisting of a source string of terminals s, a targetstring of terminals t and an alignment between theirgrammatical constituents.
Crucially, the alignmentaG is obtained by recursively interpreting the align-ment relations embedded in the synchronous gram-mar productions in the derivation for all constituentsand concerns constituent alignments (as opposed toword alignments).Grammatical translation equivalents TEG(s, t)A synchronous derivation S ?+ ?s, t, aG?
can beviewed as a deductive proof that ?s, t, aG?
is a gram-matical translation equivalence unit (grammaticalTEU).
Along the way, a derivation also proves otherconstituent-level (sub-sentential) units as TEUs.We define a sub-sentential grammatical TEU of?s, t, aG?
to consist of a triple ?sx, tx, ax?, where sxand tx are two subsequences3 (of s and t respec-tively), derived synchronously from the same con-3A subsequence of a string is a subset of the word-positionpairs that preserves the order but do not necessarily constitutecontiguous substrings.Figure 2: Alignment with both contiguous and dis-contiguous TEUs (example from Europarl En-Ne).stituent X in some non-empty ?tail" of a derivationS ?+ ?s, t, aG?
; importantly, by the workings of G,the alignment ax ?
aG fulfills the requirement that aword in sx or in tx is linked to another by aG iff it isalso linked that way by ax (i.e., no alignments startout from terminals in sx or tx and link to terminalsoutside them).
We will denote with TEG(s, t) the setof all grammatical TEUs for the sentence pair ?s, t?derived by G.Subsumption relation <G(s,t) Besides derivingTEUs, a derivation also shows how the differentTEUs compose together into larger TEUs accordingto the grammar.
We are interested in the subsump-tion relation: one grammatical TEU/constituent (u1)subsumes another (u2) (written u2 <G(s,t) u1) iff thelatter (u2) is derived within a finite derivation of theformer (u1).4The set of grammatical TEUs for a finite set ofderivations for a given sentence pair is the union ofthe sets defined for the individual derivations.
Simi-larly, the relation between TEU?s for a set of deriva-tions is defined as the union of the individual rela-tions.5 Alignment coverage by intersectionLet a word aligned sentence pair ?s, t, a?
be given,and let us assume that we have a definition of an or-dered set TE(s, t, a) with partial order <a.
We willsay that a grammar formalism covers a iff there ex-ists an instance grammar G that fulfills two intersec-tion equations simultaneously:5(1) TE(s, t, a) ?
TEG(s, t) = TE(s, t, a)(2) <a ?
<G(s,t)=<aIn the second equation, the intersection of partial or-ders is based on the standard view that these are inessence also sets of ordered pairs.
In practice, itis sufficient to implement an algorithm that shows4Note that we define this relation exhaustively thereby defin-ing the set of paths in synchronous trees derived by the grammarfor ?s, t?.
Hence, the subsumption relation can be seen to definea forest of synchronous trees.5In this work we have restricted this definition to full cover-age (i.e., subset) version but it is imaginable that other measurescan be based on the cardinality (size) of the intersection in termsof covered TEUs, in following of measures found in (S?gaardand Kuhn, 2009; S?gaard and Wu, 2009).
We leave this to fu-ture work.61Figure 1: Alignment with only contiguous TEUs (example from LREC En-Fr).that G derives every TEU in TE(s, t, a), and thatthe subsumption relation <a between TEUs in amust be realized by the derivations of G that de-rive TE(s, t, a).
In effect, this way every TEU thatsubsumes other TEUs must be derived recursively,while the minimal, atomic units (not subsuming anyothers) must be derived using the lexical produc-tions (endowed with internal word alignments) ofNF-ITG.
Again, the rationale behind this choice isthat the atomic units constitute fixed translation ex-pressions (idiomatic TEUs) which cannot be com-posed from other TEUs, and hence belong in the lex-icon.
We will exhibit coverage algorithms for doingso for NF-ITG for the two kinds of semantic inter-pretations of word alignments.A note on dedicated instances of NF-ITG Givena translation equivalence definition over word align-ments TE(s, t, a), the lexical productions for a ded-icated instance of NF-ITG are defined6 by the set{X ?
u | u ?
TEAtom(s, t, a)}.
This means that thelexical productions have atomic TEUs at the right-hand side including alignments between the wordsof the source and target terminals.
In the sequel, wewill only talk about dedicated instances of NF-ITGand hence we will not explicitly repeat this everytime.Given two grammatical TEUs u1 and u2, an NF-ITG instance allows their concatenation either inmonotone [] or inverted <> order iff they are ad-jacent on the source and target sides.
This factimplies that for every composed translation equiv-alent u ?
TE(s, t, a) we can check whether it isderivable by a dedicated NF-ITG instance by check-ing whether it recursively decomposes into adjacentpairs of TEUs down to the atomic TEUs level.
Notethat by doing so, we are also implicitly checking6Unaligned words add one wrinkle in this scheme: infor-mally, we consider a TEU u formed by attaching unalignedwords to an atomic TEU also as atomic iff u is absolutely neededto cover the aligned sentence pair.whether the subsumption order between the TEUsin TE(s, t, a) is realized by the grammatical deriva-tion (i.e, <G(s,t)?<a).
Formally, an aligned sentencepair ?s, t, a?
is split into a pair of TEUs ?s1, t1, a1?and ?s2, t2, a2?
that can be composed back usingthe [] and <> productions.
If such a split exists,the splitting is conducted recursively for each of?s1, t1, a1?
and ?s2, t2, a2?
until both are atomic TEUsin TE(s, t, a).
This recursive splitting is the checkof binarizability and an algorithm is described in(Huang et al 2009).6 A simple algorithm for ITGWe exemplify the grammatical coverage for (nor-mal form) ITG by employing a standard tabular al-gorithm based on CYK (Younger, 1967).
The al-gorithm works in two phases creating a chart con-taining TEUs with associated inferences.
In the ini-tialization phase (Algorithm 1), for all source spansthat correspond to translation equivalents and whichhave no smaller translation equivalents they contain,atomic translation equivalents are added as atomicinferences to the chart.
In the second phase, basedon the atomic inferences, the simple rules of NF-ITG are applied to add inferences for increasinglylarger chart entries.
An inference is added (Algo-rithms 2 and 3) iff a chart entry can be split into twosub-entries for which inferences already exist, andfurthermore the union of the sets of target positionsfor those two entries form a consecutive range.7 TheaddMonotoneInference and addInvertedInference inAlgorithm 3 mark the composit inferences by mono-tone and inverted productions respectively.7We are not treating unaligned words formally here.
For un-aligned source and target words, we have to generate the differ-ent inferences corresponding to different groupings with theirneighboring aligned words.
Using pre-processing we set asidethe unaligned words, then parse the remaining word alignmentfully.
After parsing, by post-processing, we introduce in theparse table atomic TEUs that include the unaligned words.62InitializeChartInput : ?s, t, a?Output: Initialized chart for atomic unitsfor spanLength?
2 to n dofor i?
0 to n ?
spanLength + 1 doj?
i + spanLength ?
1u?
{?X,Y?
: X ?
{i... j}}if (u ?
TEAtom(s, t, a)) thenaddAtomicIn f erence(chart[i][ j],u)endendendAlgorithm 1: Algorithm that initializes the Chartwith atomic sub-sentential TEUs.
In order to beatomic, a TEU may not contain smaller TEUs thatconsist of a proper subset of the alignments (andassociated words) of the TEU.ComputeTEUsNFITGInput : ?s, t, a?Output: TRUE/FALSE for coverageInitializeChart(chart)for spanLength?
2 to n dofor i?
0 to n ?
spanLength + 1 doj?
i + spanLength ?
1if chart[i][ j] ?
TE(s, t, a) thencontinueendfor splitPoint ?
i + 1 to j doa?
?
(chart[i][k ?
1] ?
chart[k][ j])if (chart[i][k ?
1] ?
TE(s, t, a)) ?
(chart[k][ j] ?
TE(s, t, a)) ?(a?
?
TE(s, t, a)) thenaddT EU(chart, i, j, k, a?
)endendendif (chart[0][n ?
1] , ?)
thenreturn TRUEelsereturn FALSEendendAlgorithm 2: Algorithm that incrementally buildscomposite TEUs using only the rules allowed byNF-ITGaddTEUInput :chart - the charti,j,k - the lower, upper and split point indicesa?
- the TEU to be addedOutput: chart with TEU a?
added in theintended entryif MaxYt ({Yt : ?Xs,Yt?
?
chart[i][k ?
1]})< MaxYt ({Yt : ?Xs,Yt?
?
chart[k][ j]}) thenaddMonotoneIn f erence(chart[i][ j], a?
)elseaddInvertedIn f erence(chart[i][ j], a?
)endAlgorithm 3: Algorithm that adds a TEU and as-sociated Inference to the chart7 ExperimentsData Sets We use manually and automaticallyaligned corpora.
Manually aligned corpora comefrom two datasets.
The first (Grac?a et al2008) consists of six language pairs: Portuguese?English, Portuguese?French, Portuguese?Spanish,English?Spanish, English?French and French?Spanish.
These datasets contain 100 sentence pairseach and distinguish Sure and Possible alignments.Following (S?gaard and Kuhn, 2009), we treat thesetwo equally.
The second manually aligned dataset(Pad?
and Lapata, 2006) contains 987 sentence pairsfrom the English-German part of Europarl anno-tated using the Blinker guidelines (Melamed, 1998).The automatically aligned data comes from Europarl(Koehn, 2005) in three language pairs (English?Dutch, English?French and English?German).
Thecorpora are automatically aligned using GIZA++(Och and Ney, 2003) in combination with the grow-diag-final-and heuristic.
With sentence length cut-off 40 on both sides these contain respectively 945k,949k and 995k sentence pairs.Grammatical Coverage (GC) is defined as thepercentage word alignments (sentence pairs) in aparallel corpus that can be covered by an instanceof the grammar (NF-ITG) (cf.
Section 5).
Clearly,GC depends on the chosen semantic interpretationof word alignments: contiguous TE?s (phrase pairs)or discontiguous TE?s.63Alignments Set GC contiguous TEs GC discontiguous TEsHand aligned corporaEnglish?French 76.0 75.0English?Portuguese 78.0 78.0English?Spanish 83.0 83.0Portuguese?French 78.0 74.0Portuguese?Spanish 91.0 91.0Spanish?French 79.0 74.0LREC Corpora Average 80.83?5.49 79.17?6.74English?German 45.427 45.325Automatically aligned CorporaEnglish?Dutch 45.533 43.57English?French 52.84 49.95English?German 45.59 43.72Automatically aligned corpora average 47.99?4.20 45.75?3.64Table 1: The grammatical coverage (GC) of NF-ITG for different corpora dependent on the interpretationof word alignments: contiguous Translation Equivalence or discontiguous Translation EquivalenceResults Table 1 shows the Grammatical Coverage(GC) of NF-ITG for the different corpora depen-dent on the two alternative definitions of translationequivalence.
The first thing to notice is that thereis just a small difference between the GrammaticalCoverage scores for these two definitions.
The dif-ference is in the order of a few percentage points,the largest difference is seen for Portuguese?French(79% v.s 74% Grammatical Coverage), for somelanguage pairs there is no difference.
For the au-tomatically aligned corpora the absolute differenceis on average about 2%.
We attribute this to the factthat there are only very few discontiguous TEUs thatcan be covered by NF-ITG in this data.The second thing to notice is that the scores aremuch higher for the corpora from the LREC datasetthan they are for the manually aligned English?German corpus.
The approximately double sourceand target length of the manually aligned English?German corpus, in combination with somewhat lessdense alignments makes this corpus much harderthan the LREC corpora.
Intuitively, one wouldexpect that more alignment links make alignmentsmore complicated.
This turns out to not always bethe case.
Further inspection of the LREC alignmentsalso shows that these alignments often consist ofparts that are completely linked.
Such completelylinked parts are by definition treated as atomicTEUs, which could make the alignments look sim-pler.
This contrasts with the situation in the man-ually aligned English?German corpus where on av-erage less alignment links exist per word.
Exam-ples 1 and 2 show that dense alignments can be sim-pler than less dense ones.
This is because sometimesthe density implies idiomatic TEUs which leads torather flat lexical productions.
We think that id-iomatic TEUs reasonably belong in the lexicon.When we look at the results for the automati-cally aligned corpora at the lowest rows in the ta-ble, we see that these are comparable to the resultsfor the manually aligned English?German corpus(and much lower than the results for the LREC cor-pora).
This could be explained by the fact that themanually aligned English?German is not only Eu-roparl data, but possibly also because the manualalignments themselves were obtained by initializa-tion with the GIZA++ alignments.
In any case, themanually and automatically acquired alignments forthis data are not too different from the perspective ofNF-ITG.
Further differences might exist if we wouldemploy another class of grammars, e.g., full SCFGs.One the one hand, we find that manual align-ments are well but not fully covered by NF-ITG.On the other, the automatic alignments are not cov-ered well but NF-ITG.
This suggests that these au-tomatic alignments are difficult to cover by NF-ITG,and the reason could be that these alignments arebuilt heuristically by trading precision for recall cf.64(Och and Ney, 2003).
Sogaard (S?gaard, 2010) re-ports that full ITG provides a few percentage pointsgains over NF-ITG.Overall, we find that our results for the LREC dataare far higher Sogaard?s (S?gaard, 2010) results butlower than the upperbounds of (S?gaard and Wu,2009).
A similar observation holds for the English?German manually aligned EuroParl data, albeit themaximum length (15) used in (S?gaard and Wu,2009; S?gaard, 2010) is different from ours (40).
Weattribute the difference between our results and So-gaard?s approach to our choice to adopt lexical pro-ductions of NF-ITG that contain own internal align-ments (the detailed version) and determined by theatomic TEUs of the word alignment.
Our resultsdiffer substantially from (S?gaard and Wu, 2009)who report upperbounds (indeed our results still fallwithin these upperbounds for the LREC data).8 Related WorkThe array of work described in (Zens and Ney,2003; Wellington et al 2006; S?gaard and Wu,2009; S?gaard and Kuhn, 2009; S?gaard, 2010) con-centrates on methods for calculating upperboundson the alignment coverage for all ITGs, includingNF-ITG.
Interestingly, these upperbounds are deter-mined by filtering/excluding complex alignment phe-nomena known formally to be beyond (NF-)ITG.None of these earlier efforts discussed explicitly thedilemmas of instantiating a grammar formalism orhow to formally parse word alignments.The work in (Zens and Ney, 2003; S?gaard andWu, 2009), defining and counting TEUs, providesa far tighter upperbound than (Wellington et al2006), who use the disjunctive interpretation ofword alignments, interpreting multiple alignmentlinks of the same word as alternatives.
We adopt theconjunctive interpretation of word alignments like amajority of work in MT, e.g., (Ayan and Dorr, 2006;Fox, 2002; S?gaard and Wu, 2009; S?gaard, 2010).In deviation from earlier work, the work in (S?-gaard and Kuhn, 2009; S?gaard and Wu, 2009;S?gaard, 2010) discusses TEUs defined over wordalignments explicitly, and defines evaluation metricsbased on TEUs.
In particular, Sogaard (S?gaard,2010) writes that he employs "a more aggressivesearch" for TEUs than earlier work, thereby leadingto far tighter upperbounds on hand aligned data.
Ourresults seem to back this claim but, unfortunately, wecould not pin down the formal details of his proce-dure.More remotely related, the work described in(Huang et al 2009) presents a binarization algo-rithm for productions of an SCFG instance (as op-posed to formalism).
Although somewhat related,this is different from checking whether there existsan NF-ITG instance (which has to be determined)that covers a word alignment.In contrast with earlier work, we present the align-ment coverage problem as an intersection of two par-tially ordered sets (graphs).
The partial order overTEUs as well as the formal definition of parsing asintersection in this work are novel elements, mak-ing explicit the view of word alignments as automatagenerating partially order sets.9 ConclusionsIn this paper we provide a formal characterizationfor the problem of determining the coverage of aword alignment by a given grammar formalism asthe intersection of two partially ordered sets.
Thesepartially ordered set of TEUs can be formalized interms of hyper-graphs implementing forests (packedsynchronous trees), and the coverage as the intersec-tion between sets of synchronous trees generalizingthe trees of (Zhang et al 2008).Practical explorations of our findings for the bene-fit of models of learning reordering are underway.
Infuture work we would like to investigate the exten-sion of this work to other limited subsets of SCFGs.We will also investigate the possibility of devisingITGs with explicit links between terminal symbolsin the productions, exploring different kinds of link-ing.Acknowledgements We thank reviewers for theirhelpful comments, and thank Mark-Jan Nederhof forilluminating discussions on parsing as intersection.This work is supported by The Netherlands Orga-nization for Scientific Research (NWO) under grantnr.
612.066.929.65ReferencesNacip Ayan and Bonnie Dorr.
2006.
Going beyond AER:an extensive analysis of word alignments and their im-pact on MT.
In Proc.
of the 21st International Confer-ence on Computational Linguistics and the 44th An-nual Meeting of the ACL, pages 9?16, Morristown, NJ,USA.Yehoshua Bar-Hillel, Micha Perles, and Eli Shamir.1964.
On formal properties of simple phrase struc-ture grammars.
In Y. Bar-Hillel, editor, Language andInformation: Selected Essays on their Theory and Ap-plication, chapter 9, pages 116?150.
Addison-Wesley,Reading, Massachusetts.Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-borne.
2009.
A gibbs sampler for phrasal synchronousgrammar induction.
In ACL/AFNLP, pages 782?790.Marine Carpuat and Dekai Wu.
2007.
Improving statisti-cal machine translation using word sense disambigua-tion.
In Proc.
of the Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL2007), page 61?72.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofthe 43rd Annual Meeting of the ACL, pages 263?270,June.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Trevor Cohn and Phil Blunsom.
2009.
A bayesian modelof syntax-directed tree to string grammar induction.
InEMNLP, pages 352?361.John DeNero, Daniel Gillick, James Zhang, and DanKlein.
2006.
Why generative phrase models underper-form surface heuristics.
In Proceedings of the work-shop on SMT, pages 31?38.Heidi J.
Fox.
2002.
Phrasal cohesion and statisticalmachine translation.
In Proceedings of the ACL-02conference on Empirical methods in natural languageprocessing - Volume 10, Proceedings of EMNLP,pages 304?311, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Joao Grac?a, Joana Pardal, Lu?sa Coheur, and DiamantinoCaseiro.
2008.
Building a golden collection of paral-lel multi-language word alignment.
In LREC?08, Mar-rakech, Morocco.
European Language Resources As-sociation (ELRA).Aria Haghighi, John Blitzer, John DeNero, and DanKlein.
2009.
Better word alignments with superviseditg models.
In Proceedings of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th Inter-national Joint Conference on Natural Language Pro-cessing of the AFNLP, pages 923?931, Suntec, Singa-pore, August.
Association for Computational Linguis-tics.Liang Huang, Hao Zhang, Daniel Gildea, and KevinKnight.
2009.
Binarization of synchronouscontext-free grammars.
Computational Linguistics,35(4):559?595.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proc.of the Human Language Technology Conference, HLT-NAACL, May.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proc.
of MT Summit.Bernard Lang.
1988.
Parsing incomplete sentences.
InProceedings of COLING, pages 365?371.J.
Scott McCarley, Abraham Ittycheriah, Salim Roukos,Bing Xiang, and Jian-Ming Xu.
2011.
A correc-tion model for word alignments.
In Proceedings ofEMNLP, pages 889?898.Dan Melamed.
1998.
Annotation style guide for theblinker project, version 1.0.
Technical Report IRCSTR #98-06, University of Pennsylvania.Markos Mylonakis and Khalil Sima?an.
2011.
Learninghierarchical translation structure with linguistic anno-tations.
In Proceedings of the HLT/NAACL-2011.Mark-Jan Nederhof and Giorgio Satta.
2004.
The lan-guage intersection problem for non-recursive context-free grammars.
Inf.
Comput., 192(2):172?184.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Sebastian Pad?
and Mirella Lapata.
2006.
Optimal con-stituent alignment with edge covers for semantic pro-jection.
In ACL-COLING?06, ACL-44, pages 1161?1168, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Jason Riesa and Daniel Marcu.
2010.
Hierarchicalsearch for word alignment.
In Proceedings of ACL,pages 157?166.Giorgio Satta and Enoch Peserico.
2005.
Some com-putational complexity results for synchronous context-free grammars.
In Proceedings of Human LanguageTechnology Conference and Conference on EmpiricalMethods i n Natural Language Processing, pages 803?810, Vancouver, British Columbia, Canada, October.Association for Computational Linguistics.Anders S?gaard and Jonas Kuhn.
2009.
Empirical lowerbounds on alignment error rates in syntax-based ma-chine translation.
In SSST ?09, pages 19?27, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Anders S?gaard and Dekai Wu.
2009.
Empirical lowerbounds on translation unit error rate for the full classof inversion transduction grammars.
In Proceedings ofthe 11th International Workshop on Parsing Technolo-gies (IWPT-2009), 7-9 October 2009, Paris, France,66pages 33?36.
The Association for Computational Lin-guistics.Anders S?gaard.
2010.
Can inversion transductiongrammars generate hand alignments?
In Proccedingsof the 14th Annual Conference of the European Asso-ciation for Machine Translation (EAMT).Roy Tromble and Jason Eisner.
2009.
Learning linear or-dering problems for better translation.
In Proceedingsof EMNLP?09, pages 1007?1016, Singapore.Gertjan van Noord.
1995.
The intersection of finite stateautomata and definite clause grammars.
In Proceed-ings of ACL, pages 159?165.Benjamin Wellington, Sonjia Waxmonsky, and I. DanMelamed.
2006.
Empirical lower bounds on the com-plexity of translational equivalence.
In Proceedings ofthe Annual Meeting of the Association for Computa-tional Linguistics (ACL).Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 3(23):377?403.D.H.
Younger.
1967.
Recognition and parsing ofcontext-free languages in time n3.
Information andControl, 10(2):189?208.Richard Zens and Hermann Ney.
2003.
A comparativestudy on reordering constraints in statistical machinetranslation.
In Proceedings of the Annual Meeting ofthe ACL, pages 144?151.Hao Zhang, Daniel Gildea, and David Chiang.
2008.
Ex-tracting synchronous grammar rules from word-levelalignments in linear time.
In Proceedings of COLING,pages 1081?1088.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart parsing.In Proceedings of the North-American Chapter of theACL (NAACL?06), pages 138?141.67
