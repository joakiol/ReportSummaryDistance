Mostly-Unsupervised Statistical Segmentation of Japanese:Applications to KanjiRie Kubota Ando and Lillian LeeDepartment of Computer ScienceCornell UniversityIthaca, NY 14853-7501{kubotar, llee} @cs.cornell.eduAbstractGiven the lack of word delimiters in writtenJapanese, word segmentation is generally consid-ered a crucial first step in processing Japanese texts.Typical Japanese segmentation algorithms rely ei-ther on a lexicon and grammar or on pre-segmenteddata.
In contrast, we introduce a novel statisticalmethod utilizing unsegmented training data, withperformance on kanji sequences comparable to andsometimes surpassing that of morphological nalyz-ers over a variety of error metrics.I IntroductionBecause Japanese is written without delimiters be-tween words) accurate word segmentation to re-cover the lexical items is a key step in Japanese textprocessing.
Proposed applications of segmentationtechnology include extracting new technical terms,indexing documents for information retrieval, andcorrecting optical character recognition (OCR) er-rors (Wu and Tseng, 1993; Nagao and Mori, 1994;Nagata, 1996a; Nagata, 1996b; Sproat et al, 1996;Fung, 1998).Typically, Japanese word segmentation is per-formed by morphological nalysis based on lexicaland grammatical knowledge.
This analysis is aidedby the fact that there are three types of Japanesecharacters, kanji, hiragana, and katakana: changesin character type often indicate word boundaries, al-though using this heuristic alone achieves less than60% accuracy (Nagata, 1997).Character sequences consisting solely of kanjipose a challenge to morphologically-based seg-reenters for several reasons.
First and mostimportantly, kanji sequences often contain domainterms and proper nouns: Fung (1998) notes that50-85% of the terms in various technical dictio-~The analogous situation i English would be if words werewritten without spaces between them.Sequence l ngth # of characters % of corpus1 - 3 kanji 20,405,486 25.64 - 6 kanji 12,743,177 16.1more than 6 kanji 3,966,408 5.1Total 37,115,071 46.8Figure 1: Statistics from 1993 Japanese newswire(NIKKEI), 79,326,406 characters total.naries are composed at least partly of kanji.
Suchwords tend to be missing from general-purposelexicons, causing an unknown word problem formorphological nalyzers; yet, these terms are quiteimportant for information retrieval, informationextraction, and text summarization, making correctsegmentation f these terms critical.
Second, kanjisequences often consist of compound nouns, sogrammatical constraints are not applicable.
Forinstance, the sequence sha-chohlkenlgyoh-mulbu-choh (presidentlandlbusinesslgeneral m nager= "a president as well as a general manager ofbusiness") could be incorrectly segmented as: sha-chohlken-gyohlmulbu-choh (presidentl subsidiarybusiness\[Tsutomu \[a name\]\[general manager);since both alternatives are four-noun sequences,they cannot be distinguished by part-of-speechinformation alone.
Finally, heuristics based onchanges in character type obviously do not apply tokanji-only sequences.Although kanji sequences are difficult to seg-ment, they can comprise a significant portion ofJapanese text, as shown in Figure 1.
Since se-quences of more than 3 kanji generally consist ofmore than one word, at least 21.2% of 1993 Nikkeinewswire consists of kanji sequences requiring seg-mentation.
Thus, accuracy on kanji sequences i  animportant aspect of the total segmentation process.As an alternative to lexico-grammatical and su-pervised approaches, we propose a simple, effi-241cient segmentation method which learns mostlyfrom very large amounts of unsegmented trainingdata, thus avoiding the costs of building a lexiconor grammar or hand-segmenting large amounts oftraining data.
Some key advantages of this methodare:?
No  Japanese-specific rules are employed, en-hancing portability to other languages.?
A very small number of pre-segmented train-ing examples (as few as 5 in our experiments)are needed for good performance, as long aslarge amounts of unsegmented data are avail-able.?
For long kanji strings, the method produces re-sults rivalling those produced by Juman 3.61(Kurohashi and Nagao, 1998) and Chasen 1.0(Matsumoto et al, 1997), two morphologicalanalyzers in widespread use.
For instance, weachieve 5% higher word precision and 6% bet-ter morpheme r call.2 A lgor i thmOur algorithm employs counts of character n-gramsin an unsegmented corpus to make segmentation de-cisions.
We illustrate its use with an example (seeFigure 2).Let "A B C D W X Y Z" represent an eight-kanjisequence.
To decide whether there should be a wordboundary between D and W, we check whether n-grams that are adjacent to the proposed boundary,such as the 4-grams l ="A B C D" and 82 ="WX Y Z", tend to be more frequent than n-grams thatstraddle it, such as the 4-gram tl ---- "B C D W".
Ifso, we have evidence of a word boundary betweenD and W, since there seems to be relatively littlecohesion between the characters on opposite sidesof this gap.The n-gram orders used as evidence in the seg-mentation decision are specified by the set N. Forinstance, if N = {4} in our example, then we posethe six questions of the form, "Is #(s~) > #(t j)?
",where #(x)  denotes the number of occurrences ofx in the (unsegmented) training corpus.
If N ={2,4}, then two more questions (Is "#(C D) >#(D W)?"
and "Is #(W X) > #(O W)?")
areadded.More formally, let s~ and 8~ be the non-straddling n-grams just to the left and right of lo-cation k, respectively, and let t~ be the straddlingn-gram with j characters to the right of location k.s, ?Ii ABCb{WXYZt,% ?/,Figure 2: Collecting evidence for a word boundary- are the non-straddling n-grams 81 and 82 morefrequent than the straddling n-grams tl, t2, and t3?Let I> (y, z) be an indicator function that is 1 wheny > z, and 0 otherwise, 2 In order to compensate forthe fact that there are more n-gram questions than(n - 1)-gram questions, we calculate the fraction ofaffirmative answers eparately for each n in N:2 n--1 1vn(k) = 2(n -  1) x>(#(87),~=1 j=lThen, we average the contributions of each n-gramorder:1VN(k) = INI ~ vn(k)nENAfter vN(k) is computed for every location, bound-aries are placed at all locations ~ such that either:?
VN(g) > VN(e -- 1) and VN(g) > VN(e + 1)(that is, e is a local maximum), or?
VN (2) > t, a threshold parameter.The second condition is necessary to allow forsingle-character words (see Figure 3).
Note that italso controls the granularity of the segmentation:low thresholds encourage shorter segments.Both the count acquisition and the testing phaseare efficient.
Computing n-gram statistics for allpossible values of n simultaneously can be done inO(m log m) time using suffix arrays, where m isthe training corpus size (Manber and Myers, 1993;Nagao and Mori, 1994).
However, if the set N ofn-gram orders is known in advance, conceptuallysimpler algorithms uffice.
Memory allocation for:Note that we do not take into account he magnitude ofthe difference between the two frequencies; see section 5 fordiscussion.242v~(k)A B \[C DI W X IY\] ZFigure 3: Determining word boundaries.
The X- Yboundary is created by the threshold criterion, theother three by the local maximum condition.count tables can be significantly reduced by omit-ting n-grams occurring only once and assuming thecount of unseen n-grams to be one.
In the applica-tion phase, the algorithm is clearly linear in the testcorpus size if \[NI is treated as a constant.Finally, we note that some pre-segmented data isnecessary in order to set the parameters N and t.However, as described below, very little such datawas required to get good performance; we thereforedeem our algorithm to be "mostly unsupervised".3 Experimental FrameworkOur experimental data was drawn from 150megabytes of 1993 Nikkei newswire (see Figure1).
Five 500-sequence held-out subsets were ob-tained from this corpus, the rest of the data serv-ing as the unsegmented corpus from which to derivecharacter n-gram counts.
Each held-out subset washand-segmented and then split into a 50-sequenceparameter-training set and a 450-sequence t st set.Finally, any sequences occurring in both a test setand its corresponding parameter-training set werediscarded from the parameter-training set, so thatthese sets were disjoint.
(Typically no more thanfive sequences were removed.
)3.1 Held-out set annotationEach held-out set contained 500 randomly-extractedkanji sequences at least ten characters long (abouttwelve on average), lengthy sequences being themost difficult to segment (Takeda and Fujisaki,1987).
To obtain the gold-standard annotations, wesegmented the sequences by hand, using an observa-tion of Takeda and Fujisaki (1987) that many kanjicompound words consist of two-character stemwords together with one-character p efixes and suf-fixes.
Using this terminology, our two-level bracket-ing annotation may be summarized as follows.
3 At3A complete description of the annotation policy, includingthe treatment of numeric expressions, may be found in a tech-nical report (Ando and Lee, 1999).the word level, a stem and its affixes are bracketedtogether as a single unit.
At the morpheme level,stems are divided from their affixes.
For example,although both naga-no (Nagano) and shi (city) canappear as individual words, naga-no-shi (Naganocity) is bracketed as \[\[naga-no\]\[shi\]\], since here shiserves as a suffix.
Loosely speaking, word-levelbracketing demarcates discourse entities, whereasmorpheme-level brackets enclose strings that cannotbe further segmented without loss of meaning.
4 Forinstance, if one segments naga-no in naga-no-shiinto naga (long) and no (field), the intended mean-ing disappears.
Here is an example sequence fromour datasets:Three native Japanese speakers participated inthe annotation: one segmented all the held-out databased on the above rules, and the other two reviewed350 sequences in total.
The percentage of agree-ment with the first person's bracketing was 98.42%:only 62 out of 3927 locations were contested by averifier.
Interestingly, all disagreement was at themorpheme l vel.3.2 Baseline algorithmsWe evaluated our segmentation method by com-paring its performance against Chasen 1.05 (Mat-sumoto et al, 1997) and Juman 3.61, 6 (Kurohashiand Nagao, 1998), two state-of-the-art, publically-available, user-extensible morphological analyzers.In both cases, the grammars were used as distributedwithout modification.
The sizes of Chasen's and Ju-man's default lexicons are approximately 115,000and 231,000 words, respectively.Comparison issues An important question thatarose in designing our experiments was how to en-able morphological analyzers to make use of theparameter-training data, since they do not have pa-rameters to tune.
The only significant way that theycan be updated is by changing their grammars orlexicons, which is quite tedious (for instance, wehad to add part-of-speech information ' to new en-tries by hand).
We took what we felt to be a rea-sonable, but not too time-consuming, course of cre-ating new lexical entries for all the bracketed wordsin the parameter-training data.
Evidence that this4This level of segmentation is consistent with Wu's (1998)Monotonicity Principle for segmentation.5http://cactus.aist-nara.ac.jp/lab/nlt/chasen.html6http:/Ipine.kuee.kyoto-u.ac.jplnl-resourceljuman.e.html24390858o7570Word accuracyCHASEN JUMAN ~otimize optimize recaU optindze F~'ecisionFigure 4: Word accuracy.
The three rightmostgroups represent our algorithm with parameterstuned for different optimization criteria.was appropriate comes from the fact that these ad-ditions never degraded test set performance, and in-deed improved itby one percent in some cases (onlysmall improvements are to be expected because theparameter-training sets were fairly small).It is important to note that in the end, we are com-paring algorithms with access to different sourcesof knowledge.
Juman and Chasen use lexicons andgrammars developed by human experts.
Our al-gorithm, not having access to such pre-compiledknowledge bases, must of necessity draw on otherinformation sources (in this case, a very large un-segmented corpus and a few pre-segmented xam-ples) to compensate for this lack.
Since we are in-terested in whether using simple statistics can matchthe performance of labor-intensive methods, we donot view these information sources as conveyingan unfair advantage, specially since the annotatedtraining sets were small, available to the morpho-logical analyzers, and disjoint from the test sets.4 ResultsWe report he average r sults over the five test setsusing the optimal parameter settings for the corre-sponding training sets (we tried all nonempty sub-sets of {2, 3, 4, 5, 6} for the set of n-gram orders Nand all values in {.05, .1, .15, .
.
.
,  1} for the thresh-old t) 7.
In all performance graphs, the "error bars"represent one standard eviation.
The results forChasen and Juman reflect he lexicon additions de-7For simplicity, ties were deterministically broken by pre-ferring smaller sizes of N, shorter n-grams in N, and largerthreshold values, in that order.scribed in section 3.2.Word and morpheme accuracy The standardmetrics in word segmentation are word precisionand recall.
Treating a proposed segmentation as anon-nested bracketing (e.g., "lAB ICI" correspondsto the bracketing "[AB][C]"), word precision (P) isdefined as the percentage of proposed brackets thatexactly match word-level brackets in the annotation;word recall (R) is the percentage of word-level an-notation brackets that are proposed by the algorithmin question; and word F combines precision and re-call: F = 2PR/(P + R).One problem with using word metrics is thatmorphological analyzers are designed to producemorpheme-level segments.
To compensate, we al-tered the segmentations produced by Juman andChasen by concatenating stems and affixes, as iden-tified by the part-of-speech information the analyz-ers provided.
(We also measured morpheme accu-racy, as described below.
)Figures 4 and 8 show word accuracy for Chasen,Juman, and our algorithm for parameter settingsoptimizing word precision, recall, and F-measurerates.
Our algorithm achieves 5.27% higher preci-sion and 0.25% better F-measure accuracy than Ju-man, and does even better (8.8% and 4.22%, respec-tively) with respect o Chasen.
The recall perfor-mance falls (barely) between that of Juman and thatof Chasen.As noted above, Juman and Chasen were de-signed to produce morpheme-level segmentations.We therefore also measured morpheme precision,recall, and F measure, all defined analogously totheir word counterparts.Figure 5 shows our morpheme accuracy results.We see that our algorithm can achieve better ecall(by 6.51%) and F-measure (by 1.38%) than Juman,and does better than Chasen by an even wider mar-gin (11.18% and 5.39%, respectively).
Precisionwas generally worse than the morphological nalyz-ers.Compatible Brackets Although word-level accu-racy is a standard performance metric, it is clearlyvery sensitive to the test annotation.
Morpheme ac-curacy suffers the same problem.
Indeed, the au-thors of Juman and Chasen may well have con-structed their standard ictionaries using differentnotions of word and morpheme than the definitionswe used in annotating the data.
We therefore devel-oped two new, more robust metrics to measure thenumber of proposed brackets that would be incor-244[ [data] [base] ] [system] (annotation bracketsProposedsegmentadon wo~ morphemee~o~ e~o~[data][base] [system] 2 0[data][basesystem] 2 I[database] [sys][tem] 2 3compatible-bracket errorscrossing morpheme-dividing0 01 00 2Figure 6: Examples of word, morpheme, and compatible-bracket errors.
The sequence "data base" has beenannotated as "[[data] [base]]" because "data base" and "database" are interchangeable.8O,?
::~- 75Morpheme accuracy85 1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.oCHASEN JUMAN optimize optimize recall optir#.ze FIxacir,~Figure 5: Morpheme accuracy.rect with respect to any reasonable annotation.Our novel metrics account for two types of er-rors.
The first, a crossing bracket, is a proposedbracket hat overlaps but is not contained within anannotation bracket (Grishman et al, 1992).
Cross-ing brackets cannot coexist with annotation brack-ets, and it is unlikely that another human wouldcreate such brackets.
The second type of er-ror, a morpheme-dividing bracket, subdivides amorpheme-level annotation bracket; by definition,such a bracket results in a loss of meaning.
See Fig-ure 6 for some examples.We define a compatible bracket as a proposedbracket that is neither crossing nor morpheme-dividing.
The compatible brackets rate is simply thecompatible brackets precision.
Note that this met-ric accounts for different levels of segmentation si-multaneously, which is beneficial because the gran-ularity of Chasen and Juman's segmentation variesfrom morpheme l vel to compound word level (byour definition).
For instance, well-known universitynames are treated assingle segments by virtue of be-ing in the default lexicon, whereas other universitynames are divided into the name and the word "uni-versity".
Using the compatible brackets rate, bothsegmentations can be counted as correct.We also use the all-compatible brackets rate,which is the fraction of sequences for which allthe proposed brackets are compatible.
Intuitively,this function measures the ease with which a humancould correct he output of the segmentation algo-rithm: if the all-compatible brackets rate is high,then the errors are concentrated in relatively fewsequences; if it is low, then a human doing post-processing would have to correct many sequences.Figure 7 depicts the compatible brackets and all-compatible brackets rates.
Our algorithm does bet-ter on both metrics (for instance, when F-measureis optimized, by 2.16% and 1.9%, respectively, incomparison to Chasen, and by 3.15% and 4.96%,respectively, in comparison to Juman), regardless oftraining optimization function (word precision, re-call, or F - -  we cannot directly optimize the com-patible brackets rate because "perfect" performanceis possible simply by making the entire sequence asingle segment).Compatible and all-compatible brackets rateslOOTIg5 t85 .
.
.
.
.
.80  .
.
.
.75CI'~SEN JUMAN 0ptimize precision 00timize recall optimize F10 compatib4e brackets rates ?
all-compatible brackets rates,Figure 7: Compatible brackets and all-compatiblebracket rates when word accuracy is optimized.245precisionrecallF-measureJuman5 vs. Juman50 Our50 vs Juman50 Our5 vs. Juman5- 1.04 +5.27 +6.18-0.63 -4.39 -3.73-0.84 +0.26 +1.14Our5 vs. Juman50+5.14-4.36+0.30Figure 8: Relative word accuracy as a function of training set size.
"5" and "50" denote training set sizebefore discarding overlaps with the test sets.4.1 DiscussionMinimal human effort is needed.
In contrastto our mostly-unsupervised method, morphologicalanalyzers need a lexicon and grammar ules builtusing human expertise.
The workload in creatingdictionaries on the order of hundreds of thousandsof words (the size of Chasen's and Juman's de-fault lexicons) is clearly much larger than annotat-ing the small parameter-training sets for our algo-rithm.
We also avoid the need to segment a largeamount of parameter-training data because our al-gorithm draws almost all its information from anunsegmented corpus.
Indeed, the only human effortinvolved in our algorithm is pre-segmenting the five50-sequence parameter training sets, which tookonly 42 minutes.
In contrast, previously proposedsupervised approaches have used segmented train-ing sets ranging from 1000-5000 sentences (Kash-ioka et al, 1998) to 190,000 sentences (Nagata,1996a).To test how much annotated training data is actu-ally necessary, we experimented with using minis-cule parameter-training sets: five sets of only fivestrings each (from which any sequences repeated inthe test data were discarded).
It took only 4 minutesto perform the hand segmentation in this case.
Asshown in Figure 8, relative word performance wasnot degraded and sometimes even slightly better.
Infact, from the last column of Figure 8 we see thateven if our algorithm has access to only five anno-tated sequences when Juman has access to ten timesas many, we still achieve better precision and betterF measure.Both the local maximum and threshold condi-tions contribute.
In our algorithm, a location kis deemed a word boundary if VN(k) is either (1) alocal maximum or (2) at least as big as the thresh-old t. It is natural to ask whether we really need twoconditions, or whether just one would suffice.We therefore studied whether optimal perfor-mance could be achieved using only one of the con-ditions.
Figure 9 shows that in fact both contributeto producing ood segmentations.
Indeed, in somecases, both are needed to achieve the best perfor-mance; also, each condition when used in isolationyields suboptimal performance with respect to someperformance metrics.accuracy optimize optimize optimizeprecision recall F-measureword M M & T Mmorpheme M & T T TFigure 9: Entries indicate whether best performanceis achieved using the local maximum condition (M),the threshold condition (T), or both.5 Related WorkJapanese Many previously proposed segmenta-tion methods for Japanese text make use of eithera pre-existing lexicon (Yamron et al, 1993; Mat-sumoto and Nagao, 1994; Takeuchi and Matsumoto,1995; Nagata, 1997; Fuchi and Takagi, 1998) orpre-segmented training data (Nagata, 1994; Papa:georgiou, 1994; Nagata, 1996a; Kashioka et al,1998; Mori and Nagao, 1998).
Other approachesbootstrap from an initial segmentation provided bya baseline algorithm such as Juman (Matsukawa etal., 1993; Yamamoto, 1996).Unsupervised, non-lexicon-based methods forJapanese segmentation doexist, but they often havelimited applicability.
Both Tomokiyo and Ries(1997) and Teller and Batchelder (1994) explicitlyavoid working with kanji charactes.
Takeda andFujisaki (1987) propose the short unit model, atype of Hidden Markov Model with linguistically-determined topology, to segment kanji compoundwords.
However, their method does not handlethree-character stem words or single-character stemwords with affixes, both of which often occur inproper nouns.
In our five test datasets, we foundthat 13.56% of the kanji sequences contain wordsthat cannot be handled by the short unit model.Nagao and Mori (1994) propose using the heuris-246tic that high-frequency haracter n-grams may rep-resent (portions of) new collocations and terms,but the results are not experimentally evaluated,nor is a general segmentation algorithm proposed.The work of Ito and Kohda (1995) similarly relieson high-frequency haracter n-grams, but again, ismore concerned with using these frequent n-gramsas pseudo-lexicon entries; a standard segmentationalgorithm is then used on the basis of the inducedlexicon.
Our algorithm, on the hand, is fundamen-tally different in that it incorporates no explicit no-tion of word, but only "sees" locations betweencharacters.Chinese According to Sproat et al (1996), mostprior work in Chinese segmentation has exploitedlexical knowledge bases; indeed, the authors assertthat they were aware of only one previously pub-lished instance (the mutual-information method ofSproat and Shih (1990)) of a purely statistical ap-proach.
In a later paper, Palmer (1997) presentsa transformation-based algorithm, which requirespre-segmented training data.To our knowledge, the Chinese segmenter mostsimilar to ours is that of Sun et al (1998).
Theyalso avoid using a lexicon, determining whether agiven location constitutes a word boundary in partby deciding whether the two characters on eitherside tend to occur together; also, they use thresholdsand several types of local minima and maxima tomake segmentation decisions.
However, the statis-tics they use (mutual information and t-score) aremore complex than the simple n-gram counts thatwe employ.Our preliminary reimplementation of theirmethod shows that it does not perform as well asthe morphological analyzers on our datasets, al-though we do not want to draw definite conclusionsbecause some aspects of Sun et als method seemincomparable to ours.
We do note, however, thattheir method incorporates numerical differencesbetween statistics, whereas we only use indicatorfunctions; for example, once we know that onetrigram is more common than another, we do nottake into account he difference between the twofrequencies.
We conjecture that using absolutedifferences may have an adverse effect on raresequences.6 ConclusionIn this paper, we have presented a simple, mostly-unsupervised algorithm that segments Japanese se-quences into words based on statistics drawn froma large unsegmented corpus.
We evaluated per-formance on kanji with respect o several metrics,including the novel compatible brackets and all-compatible brackets rates, and found that our al-gorithm could yield performances rivaling that oflexicon-based morphological nalyzers.In future work, we plan to experiment onJapanese sentences with mixtures of charactertypes, possibly in combination with morphologi-cal analyzers in order to balance the strengths andweaknesses of the two types of methods.
Sinceour method does not use any Japanese-dependentheuristics, we also hope to test it on Chinese or otherlanguages as well.AcknowledgmentsWe thank Minoru Shindoh and Takashi Ando forreviewing the annotations, and the anonymous re-viewers for their comments.
This material was sup-ported in part by a grant from the GE Foundation.ReferencesRie Ando and Lillian Lee.
1999.
Unsupervised sta-tistical segmentation of Japanese kanji strings.Technical Report TR99-1756, Cornell University.Takeshi Fuchi and Shinichiro Takagi.
1998.Japanese morphological nalyzer using word co-occurrence - JTAG.
In Proc.
of COLING-ACL'98, pages 409-413.Pascale Fung.
1998.
Extracting key terms fromChinese and Japanese texts.
Computer Process-ing of Oriental Languages, 12(1 ).Ralph Grishman, Catherine Macleod, and JohnSterling.
1992.
Evaluating parsing strategies us-ing standardized parse files.
In Proc.
of the 3rdANLP, pages 156--161.Akinori Ito and Kasaki Kohda.
1995.
Languagemodeling by string pattern N-gram for Japanesespeech recognition.
In Proc.
oflCASSP.Hideki Kashioka, Yasuhiro Kawata, Yumiko Kinjo,Andrew Finch, and Ezra W. Black.
1998.
Useof mutual information based character clus-ters in dictionary-less morphological nalysis ofJapanese.
In Proc.
of COL1NG-ACL '98, pages658-662.Sadao Kurohashi and Makoto Nagao.
1998.Japanese morphological nalysis ystem JUMANversion 3.6 manual.
In Japanese.Udi Manber and Gene Myers.
1993.
Suffix arrays:247A new method for on-line string searches.
SIAMJournal on Computing, 22(5):935-948.T.
Matsukawa, Scott Miller, and Ralph Weischedel.1993.
Example-based correction of word seg-mentation and part of speech labelling.
In Proc.of the HLT Workshop, ages 227-32.Yuji Matsumoto and Makoto Nagao.
1994.
Im-provements of Japanese morphological nalyzerJUMAN.
In Proc.
of the International Workshopon Sharable Natural Language Resources, pages22-28.Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita,Yoshitaka Hirano, Osamu Imaichi, and TomoakiImamura.
1997.
Japanese morphological nal-ysis system ChaSen manual.
Technical ReportNAIST-IS-TR97007, Nara Institute of Scienceand Technology.
In Japanese.Shinsuke Mori and Makoto Nagao.
1998.
Un-known word extraction from corpora using n-gram statistics.
Journal of the Information Pro-cessing Society of Japan, 39(7):2093-2100.
InJapanese.Makoto Nagao and Shinsuke Mori.
1994.
A newmethod of N-gram statistics for large number ofn and automatic extraction of words and phrasesfrom large text data of Japanese.
In Proc.
of the15th COLING, pages 611-615.Masaaki Nagata.
1994.
A stochastic Japanesemorphological analyzer using a forward-DPbackward-A* n-best search algorithm.
In Proc.of the 15th COLING, pages 201-207.Masaaki Nagata.
1996a.
Automatic extraction ofnew words from Japanese texts using generalizedforward-backward search.
In Proc.
of the Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 48-59.Masaaki Nagata.
1996b.
Context-based spellingcorrection for Japanese OCR.
In Proc.
of the 16thCOLING, pages 806-811.Masaaki Nagata.
1997.
A self-organizing Japaneseword segmenter using heuristic word identifica-tion and re-estimation.
In Proc.
of the 5th Work-shop on Very Large Corpora, pages 203-215.David Palmer.
1997.
A trainable rule-based algo-rithm for word segmentation.
I  Proc.
of the 35thACL/8th EACL, pages 321-328.Constantine P.Papageorgiou.
1994.
Japanese wordsegmentation by hidden Markov model.
In Proc.of the HLT Workshop, ages 283-288.Richard Sproat and Chilin Shih.
1990.
A statisticalmethod for finding word boundaries in Chinesetext.
Computer Processing of Chinese and Ori-ental Languages, 4:336-351.Richard Sproat, Chilin Shih, William Gale, andNancy Chang.
1996.
A stochastic finite-sateword-segmentation algorithm for Chinese.
Com-putational Linguistics, 22(3).Maosong Sun, Dayang Shen, and Benjamin K.Tsou.
1998.
Chinese word segmentation withoutusing lexicon and hand-crafted training data.
InProc.
of COLING-ACL '98, pages 1265-1271.Koichi Takeda and Tetsunosuke Fujisaki.
1987.Automatic decomposition of kanji compoundwords using stochastic estimation.
Journal ofthe Information Processing Society of Japan,28(9):952-961.
In Japanese.Kouichi Takeuchi and Yuji Matsumoto.
1995.HMM parameter learning for Japanese morpho-logical analyzer.
In Proc, of the lOth Pacific AsiaConference on Language, Information and Com-putation (PACLING), pages 163-172.Virginia Teller and Eleanor Olds Batchelder.
1994.A probabilistic algorithm for segmenting non-kanji Japanese strings.
In Proc.
of the 12th AAAI,pages 742-747.Laura Mayfield Tomokiyo and Klaus Ries.
1997.What makes a word: learning base units inJapanese for speech recognition.
In Proc.
of theACL Special Interest Group in Natural LanguageLearning (CoNLL97), pages 60-69.Zimin Wu and Gwyneth Tseng.
1993.
Chinese textsegmentation for text retrieval: Achievementsand problems.
Journal of the American Societyfor Information Science, 44(9):532-542.Dekai Wu.
1998.
A position statement on Chinesesegmentation, http://www.cs.ust.hk/-,~dekai/-papers/segmentation.html.
Presented at theChinese Language Processing Workshop,University of Pennsylvania.Mikio Yamamoto.
1996.
A re-estimation methodfor stochastic language modeling from ambigu-ous observations.
In Proc.
of the 4th Workshopon Very Large Corpora, pages 155-167.J.
Yamron, J. Baker, P. Bamberg, H. Chevalier,T.
Dietzel, J.
Elder, F. Kampmann, M. Mandel,L.
Manganaro, T. Margolis, and E. Steele.
1993.LINGSTAT: An interactive, machine-aided trans-lation system.
In Proc.
of the HLT Workshop,pages 191-195.248
