First Joint Conference on Lexical and Computational Semantics (*SEM), pages 100?104,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsCombining resources for MWE-token classificationRichard Fothergill and Timothy BaldwinDepartment of Computing and Information SystemsThe University of MelbourneVIC 3010 Australiar.fothergill@student.unimelb.edu.au, tb@ldwin.netAbstractWe study the task of automatically disam-biguating word combinations such as jumpthe gun which are ambiguous between a lit-eral and MWE interpretation, focusing on theutility of type-level features from an MWElexicon for the disambiguation task.
Tothis end we combine gold-standard idiomatic-ity of tokens in the OpenMWE corpus withMWE-type-level information drawn from therecently-published JDMWE lexicon.
We findthat constituent modifiability in an MWE-typeis more predictive of the idiomaticity of itstokens than other constituent characteristicssuch as semantic class or part of speech.1 IntroductionA multiword expression (MWE) is a phrase orsequence of words which exhibits idiosyncratic be-haviour (Sag et al, 2002; Baldwin and Kim, 2009).The nature of this idiosyncracy may be purely dis-tributional ?
such as hot and cold being more com-mon than cold and hot ?
but in this paper we studyMWEs with idiosyncratic semantics.
Specificallywe are concerned with expressions such as jump thegun which are ambiguous between a literal interpre-tation of ?to leap over a firearm?, and an idiomaticinterpretation of ?to act prematurely?.While MWEs are increasingly entering the main-stream of NLP, the accurate identification of MWEsremains elusive for current methods, particularly inthe absence of MWE type-specialised training data.This paper builds on the work of Hashimoto et al(2006) and Fothergill and Baldwin (2011) in ex-ploring whether type-level MWE properties sourcedfrom an idiom dictionary can boost the accuracy ofcrosstype MWE-token classification.
That is, weattempt to determine whether token occurrences ofambiguous expressions such as Kim jumped the gunon this issue are idiomatic or literal, based on: (a)annotated instances for MWEs other than jump thegun (e.g.
we may only have token-level annotationsfor kick the bucket and throw in the towel), and (b)dictionary-based information on the syntactic prop-erties of the idiom in question.We find that constituent modifiability judgmentsextracted from the idiom dictionary are more predic-tive of the idiomaticity of tokens than other featuresof the idiom?s constituents such as part of speechor lexeme.
However, violations of the dictionary?smodifiability rules have variable utility for machinelearning classification, being suggestive of the literalclass but not definitive.
Finally, we present novel re-sults illuminating the effectiveness of contextual se-mantic vectors at MWE-token classification.2 Related WorkThe OpenMWE corpus (Hashimoto and Kawahara,2009) is a gold-standard corpus of over 100, 000Japanese MWE-tokens covering 146 types.
It is thelargest resource we are aware of which has hand-annotated instances of MWEs which are ambiguousbetween a literal and idiomatic interpretation, andhas been used by Hashimoto and Kawahara (2009)and Fothergill and Baldwin (2011) for supervisedclassification of MWE-tokens using features cap-turing lexico-syntactic variation and traditional se-mantic features borrowed from word sense disam-biguation (WSD) .
Similar work in other languageshas been performed by Li and Sporleder (2010) andDiab and Bhutada (2009).
We build on this work inexploring the use of MWE-type-level features drawnfrom an idiom dictionary for MWE identification.100Hashimoto and Kawahara (2009) developed a va-riety of features capturing lexico-syntactic variationbut only one ?
a Boolean feature for ?internal mod-ification?, which fired only when a non-constituentword appeared between constituent words in anMWE-token ?
had an appreciable impact on classi-fication.
However, they found that this effect was farovershadowed by semantic context features inspiredby WSD.
That is, treating each MWE-type as a wordwith two senses and performing sense disambigua-tion was far more successful than any features basedon lexico-syntactic characteristics of idioms.
Intu-itively, we would expect that if we had access to arich inventory of expression-specific type-level fea-tures encoding the ability of the expression to partic-ipate in different syntactic alternations, we should bebetter equipped to disambiguate token occurrencesof that expression.
Indeed, the work of Fazly et al(2009) would appear to support this hypothesis, inthat the authors used unsupervised methods to learntype-level preferences for a range of MWE types,and demonstrated that these could be successfullyapplied to a token-level disambiguation task.Hashimoto and Kawahara (2009) trained indi-vidual classifiers for each MWE-type in their cor-pus and tested them only on instances of the typethey were trained on.
In contrast to this type-specialised classification, Fothergill and Baldwin(2011) trained classifiers on a subset of MWE-typesand tested on instances of the remaining held-outMWE-types.
The motivation for this crosstypeclassification was to test the use of data from theOpenMWE corpus for MWE-token classification ofMWE-types with no gold-standard data available(which are by far the majority).
Fothergill and Bald-win (2011) introduced features for crosstype classi-fication which captured features of the MWE-type,reasoning that similar expressions would have sim-ilar propensity for idiomaticity.
We introduce newMWE-type features expressing the modifiability ofconstituents based on information extracted from anMWE dictionary with wide coverage.Fothergill and Baldwin (2011) expected thatWSD features ?
however successful at type spe-cialised classification ?
would lose their advantagein crosstype classification because of the lack of acommon semantics between MWE-types.
However,this turned out not to be the case, with by far themost successful results arising again from use ofWSD features.
This surprising result raises the pos-sibility of distributional similarity between the con-texts of idiomatic MWE-tokens of different MWE-types, however the result was not explained or ex-plored further.
In this paper we offer new insightsinto the distributional similarity hypothesis.The recently-published JDMWE (Japanese Dic-tionary of Multiword Expressions) encodes type-level information on thousands of Japanese MWEs(Shudo et al, 2011).
A subset of the dictionary hasbeen released, and overlaps to some extent with theMWE-types in the OpenMWE corpus.
JDMWE en-codes information about lexico-syntactic variationsallowed by each MWE-type it contains.
For exam-ple, the expression hana wo motaseru ?
literally?to have [someone] hold flowers?
but figuratively?to let [someone] take the credit?
?
has the syntac-tic form entry [N wo] *V30.
The asterix indicatesmodifiability, telling us that the head [V]erb mo-taseru ?cause to hold?
allows modification by non-constituent dependents ?
such as adverbs ?
but thedependent [N]oun hana ?flowers?
does not.3 Features for classificationWe introduce features based on the lexico-syntacticflexibility constraints encoded in JDMWE and com-pare them with similar features from related work.3.1 Type-level featuresWe extracted the modifiability flags from the syntac-tic field of entries in JDMWE and generated a featurefor each modifiable constituent, identified by its po-sition in the type?s parse tree.
The motivation forthis is to allow machine learning algorithms to cap-ture any similarities in idiomaticity between MWE-types with similar modifiability.Fothergill and Baldwin (2011) also aimed toexploit crosstype similarity with their type fea-tures.
They extracted lexical features (part-of-speech, lemma and semantic category) of the typeheadword and other constituents.
We use these fea-tures as point of contrast.3.2 Token featuresAn internal modifier is a dependent of a constituentwhich is not a constituent itself but divides an MWE-token into two parts, such as the word seven in kick101seven buckets.
Features in related work have flaggedthe presence of any internal modifier uncondition-ally (Hashimoto and Kawahara, 2009; Fothergill andBaldwin, 2011).
We introduce a refined featurewhich fires only when a MWE-token has an internalmodifier which violates the constituent modificationconstraints encoded in JDMWE.JDMWE modifiability constraints could also beconstrued to proscribe external modifiers.
Sententialsubjects and other external arguments of the headverb are too common to be sensibly proscribed butwe did include a feature flagging proscribed exter-nal modification of leaf constituents such as wa-ter in kick the bucket of water.
This feature effec-tively refines the adnominal modification feature ofHashimoto and Kawahara (2009) which indiscrimi-nately flags external modifications on a leaf noun.We include in our analysis a contrast of these fea-tures to token-based features in related work.
Theclosest related features are those focussed on theMWE characteristic of lexico-syntactic fixednesstermed idiom features by Hashimoto and Kawahara(2009) and Fothergill and Baldwin (2011):?
the flag for internal modification;?
the flag for adnominal modification;?
lexical features such as part-of-speech, lemmaand semantic category extracted from an inter-nal or adnominal modifier;?
inflections of the head constituent.Additionally, we include WSD-inspired featuresused by Hashimoto and Kawahara (2009) andFothergill and Baldwin (2011).
These are all lexi-cal features extracted from context, including part-of-speech, lemma and semantic category of wordsin the paragraph, local and syntactic contexts of theMWE-token.
These features set the high water markfor classification accuracy in both type-specialisedand crosstype classification scenarios.3.3 Example JDMWE feature extractionThe following is a short literal token of the exampletype from Section 2, with numbered constituents:kireina hanawo(2) motaseta(1) (?
[He] had [me] holdthe pretty flowers?).
The JDMWE features emittedfor this token are the type feature modifiable(1) andthe token feature proscribed premodifier(2).4 ResultsWe worked with a subset of the OpenMWE cor-pus comprising those types having: (a) an entry inthe released subset of the JDMWE, and (b) both lit-eral and idiomatic classes represented by at least 50MWE-tokens each in the corpus.
This leaves only 27MWE-types and 23, 392 MWE-tokens and meansthat our results are not directly comparable to thoseof Hashimoto and Kawahara (2009) and Fothergilland Baldwin (2011).
The release of the full JDMWEshould enable more comparable results.We constructed a crosstype classification taskby ten-fold cross validation of the MWE-types inthe OpenMWE subset, with micro-averaged results.Training sets were the union of all MWE-tokens ofMWE-types in a partition.
The majority class wasthe idiomatic sense and provided a baseline accu-racy of 0.594.
Support Vector Machine models withlinear kernels were trained on various feature com-binations using the libSVM package.Our JDMWE type-level features performed com-paratively well at the crosstype task, with an accu-racy of 0.647, at 5.3 percentage points above thebaseline.
This is a marked improvement on the lex-ical type-level features from related work, whichachieved an accuracy of 4.0 points above baseline.As has been observed in related work, the accuracygained by using type-level features is much smallerthan the token-level WSD features.
However, therelative performance of the JDMWE type features tothe lexical type features is sustained in combinationwith other feature types, as shown in Figure 1a.Our JDMWE token-level features on the otherhand perform quite badly at crosstype classification.When measured against the baseline or used to aug-ment other token features, they degraded or onlymarginally improved performance.
The fact that us-ing these features resulted in worse-than-baselineperformance suggests that the constituent modifia-bility features extracted from JDMWE may not bestrict constraints as they are construed.To better examine the quality of the JDMWE con-stituent modifiability constraint features, we con-structed a heuristic classifier.
The classifier appliesthe idiomatic class by default, but the literal class toany MWE-token which violates the JDMWE con-stituent modifiability constraints.
This classifier?s102(a) Accuracy using JDMWE type-levelfeatures and lexical type-level features incombination with various token-level fea-tures(b) Recall for idiomatic instances for var-ious feature combinations with and with-out WSD context features, in a type-specialised classification setting(c) Recall for literal instances for vari-ous feature combinations with and with-out WSD context features, in a type-specialised classification setting.Figure 1: Resultsprecision on the literal class was 0.624, meaning thatfully 0.376 of modifiability constraint violations inthe corpus occured for idiomatic tokens.However, the classifier was correct in its literalclass labels more than half the time so it achieved abetter accuracy than the majority class classifer, at0.612.
As such, the heuristic classifier comfortablyoutperformed the Support Vector Machine classifierbased on the same features.
This shows that our poorresults with regards to the JDMWE constraint viola-tion features are due mainly to failures of the ma-chine learning model to take advantage of them.As to the strength of the constraints encoded inJDMWE, we found that 4.4% of all idiomatic tokensin the corpus violated constituent modification con-straints, and 10.8% of literal tokens.
Thus the con-straints seem sound but not as rigid as presented bythe JDMWE developers.Figure 1a shows that even with our improvementsto type-level features, the finding of Fothergill andBaldwin (2011) that WSD context features performbest at crosstype classification still holds.
We can-not fully account for this, but one observation re-garding the results of our type-specialised evaluationmay have bearing on the crosstype scenario.For our type-specialised classification task weperformed cross-validation for each MWE-type inisolation, aggregating final results.
Some types hada literal majority class, so the baseline accuracy was0.741.
Figure 1b shows that type-specialised classi-fication performance is basically constant when re-stricting analysis to only the idiomatic test instances.The huge performance boost produced through theuse of WSD features occurs only on literal instances(see Figure 1c).
That is, our type-specialised clas-sifiers are capturing distributional similarity of con-text for the literal instances of a MWE-type but notfor the idiomatic instances.
Since the contexts of id-iomatic instances of the same MWE-type do not ex-hibit a usable distributional similarity, it is unlikelythat crosstype similarities between idiomatic MWE-token contexts can explain the efficacy of WSD fea-tures for crosstype classification.5 ConclusionUsing a MWE dictionary as input to a supervisedcrosstype MWE-token classification task we haveshown that the constituents?
modifiability character-istics tell more about idiomaticity than their lexicalcharacteristics.
We found that the constituent modi-fication constraints in JDMWE are not hard-and-fastrules but do show up statistically in the OpenMWEcorpus.
Finally, we found that distributional simi-larity of the contexts of idiomatic MWE-tokens isunlikely to be the source of the success of WSD fea-tures on MWE-token classification accuracy.103ReferencesTimothy Baldwin and Su Nam Kim.
2009.
Multiwordexpressions.
In Nitin Indurkhya and Fred J. Damerau,editors, Handbook of Natural Language Processing,pages 267?292.
CRC Press, Boca Raton, USA, 2ndedition.Mona T. Diab and Pravin Bhutada.
2009.
Verb nounconstruction MWE token supervised classification.
InMWE ?09: Proceedings of the Workshop on MultiwordExpressions, pages 17?22, Singapore.Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.2009.
Unsupervised type and token identificationof idiomatic expressions.
Computational Linguistics,35(1):61?103.Richard Fothergill and Timothy Baldwin.
2011.
Flesh-ing it out: A supervised approach to MWE-token andMWE-type classification.
In Proceedings of 5th Inter-national Joint Conference on Natural Language Pro-cessing, Chiang Mai, Thailand.Chikara Hashimoto and Daisuke Kawahara.
2009.
Com-pilation of an idiom example database for supervisedidiom identification.
Language Resources and Evalu-ation, 43:355?384.Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro.2006.
Detecting Japanese idioms with a linguisticallyrich dictionary.
Language Resources and Evaluation,40:243?252.Linlin Li and Caroline Sporleder.
2010.
Linguistic cuesfor distinguishing literal and non-literal usages.
InColing 2010: Posters, pages 683?691, Beijing, China.Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-take, and Dan Flickinger.
2002.
Multiword expres-sions: A pain in the neck for NLP.
In Compu-tational Linguistics and Intelligent Text Processing,pages 189?206, Mexico City, Mexico.Kosho Shudo, Akira Kurahone, and Toshifumi Tanabe.2011.
A comprehensive dictionary of multiword ex-pressions.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Hu-man Language Technologies, Portland, USA.104
