2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 573?576,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsAre You Sure?
Confidence in Prediction of Dependency Tree EdgesAvihai MejerDepartment of Electrical EngineeringTechnion-Israel Institute of TechnologyHaifa 32000, Israelamejer@tx.technion.ac.ilKoby CrammerDepartment of Electrical EngineeringTechnion-Israel Institute of TechnologyHaifa 32000, Israelkoby@ee.technion.ac.ilAbstractWe describe and evaluate several methods forestimating the confidence in the per-edge cor-rectness of a predicted dependency parse.
Weshow empirically that the confidence is asso-ciated with the probability that an edge is se-lected correctly and that it can be used to de-tect incorrect edges very efficiently.
We eval-uate our methods on parsing text in 14 lan-guages.1 IntroductionDependency parsers construct directed edges be-tween words of a given sentence to their argumentsaccording to syntactic or semantic rules.
We useMSTParser of McDonald et al (2005) and focuson non-projective dependency parse trees with non-typed (unlabeled) edges.
MSTParser produces aparse tree for a sentence by constructing a full, di-rected and weighted graph over the words of thesentence, and then outputting the maximal spanningtree (MST) of the graph.
A linear model is em-ployed for computing the weights of the edges usingfeatures depending on the two words the edge con-nects.
Example features are the distance between thetwo words, words identity and words part-of-speech.MSTParser is training a model using online learningand specifically the MIRA algorithm (Crammer etal., 2006).
The output of MSTParser is the highestscoring parse tree, it is not accompanied by any ad-ditional information about its quality.In this work we evaluate few methods for estimat-ing the confidence in the correctness of the predic-tion of a parser.
This information can be used inseveral ways.
For example, when using parse treesas input to another system such as machine transla-tion, the confidence information can be used to cor-rect inputs with low confidence.
Another exampleis to guide manual validation to outputs which aremore likely to be erroneous, saving human labor.We adapt methods proposed by Mejer and Cram-mer (2010) in order to produce per-edge confidenceestimations in the prediction.
Specifically, one ap-proach is based on sampling, and another on a gen-eralization of the concept of margin.
Additionally,we propose a new method based on combining bothapproaches, and show that is outperforms both.2 Confidence Estimation In PredictionMSTParser produces the highest scoring parse treesusing the trained linear model with no additionalinformation about the confidence in the predictedtree.
In this work we compute per-edge confidencescores, that is, a numeric confidence value, forall edges predicted by the parser.
Larger scorevalues indicate higher confidence.
We use threeconfidence estimation methods that were proposedfor sequence labeling (Mejer and Crammer, 2010),adapted here for dependency parsing.
A fourthmethod, described in Sec.
3, is a combination of thetwo best performing methods.The first method, named Delta, is a margin-basedmethod.
For computing the confidence of each edgethe method generates an additional parse-tree, whichis the best parse tree that is forced not to contain thespecific edge in question.
The confidence score ofthe edge is defined as the difference in the scores be-573tween the two parse trees.
The score of a tree is thesum of scores of the edges it contains.
These con-fidence scores are always positive, yet not limitedto [0, 1].
Delta method does not require parametertuning.The second method, named Weighted K-Best(WKB), is a deterministic method building on prop-erties of the inference algorithm.
Specifically,we use k-best Maximum Spanning Tree algorithm(Hall, 2007) to produce the K parse trees with thehighest score.
This collection of K-trees is used tocompute the confidence in a predicted edge.
Theconfidence score is defined to be the weighted-fraction of parse trees that contain the edge.
Thecontribution of different trees to compute this frac-tion is proportional to their absolute score, where thetree with the highest score has the largest contribu-tion.
Only trees with positive scores are included.The computed score is in the range [0, 1].
The valueof K was tuned using a development set (optimiz-ing the average-precision score of detecting incor-rect edges, see below) and for most datasets K wasset to a value between 10?
20.The third method, K Draws by Fixed StandardDeviation (KD-Fix) is a probabilistic method.
Herewe sample K weight vectors using a Gaussian dis-tribution, for which the mean parameters are thelearned model and isotropic covariance matrix withfixed variance s2.
The value s is tuned on a develop-ment set (optimizing the average-precision score ofdetecting incorrect edges).
The confidence of eachedge is the probability of this edge induced from thedistribution over parameters.
We approximate thisquantity by sampling K parse trees, each obtained byfinding the MST when scores are computed by oneof K sampled models.
Finally, the confidence scoreof each edge predicted by the model is defined tobe the fraction of parse trees among the K trees thatcontain this edge.
Formally, the confidence score is?
= j/K where j is the number of parse trees thatcontain this edge (j ?
{0. .
.K}) so the score is inthe range [0, 1].
We set K = 50.Finally, we describe below a fourth method,we call KD-Fix+Delta, which is a weighted-linearcombination of KD-Fix and Delta.3 EvaluationWe evaluated the algorithms using 13 languagesused in CoNLL 2006 shared task1, and the EnglishPenn Treebank.
The number of training sentences isbetween 1.5-72K, with an average of 20K sentencesand 50K-1M words.
The test sets contain ?
400sentences and ?6K words for all datasets, exceptEnglish with 2.3K sentences and 55K words.
Pa-rameter tuning was performed on development setswith 200 sentences per dataset.
We trained a modelper dataset and used it to parse the test set.
Pre-dicted edge accuracy of the parser ranges from 77%on Turkish to 93% on Japanese, with an average of85%.
We then assigned each predicted edge a confi-dence score using the various confidence estimationmethods.Absolute Confidence: We first evaluate the accu-racy of the actual confidence values assigned by allmethods.
Similar to (Mejer and Crammer, 2010) wegrouped edges according to the value of their con-fidence.
We used 20 bins dividing the confidencerange into intervals of size 0.05.
Bin indexed jcontains edges with confidence value in the range[ j?120 ,j20 ] , j = 1..20.
Let bj be the center value ofbin j and let cj be the fraction of edges predictedcorrectly from the edges assigned to bin j.
For agood confidence estimator we expect bj ?
cj .Results for 4 datasets are presented in Fig.
1.
Plotsshow the measured fraction of correctly predictededges cj vs. the value of the center of bin bj .
Bestperformance is obtained when a line correspondingto a method is close to the line y = x.
Results areshown for KD-Fix and WKB; Delta is omitted as itproduces confidence scores out of [0, 1].
In two ofthe shown plots (Chinese and Swedish) KD-Fix (cir-cles) follows closely the expected accuracy line.
Inanother plot (Danish) KD-Fix is too pessimistic withline above y = x and in yet another case (Turkish) itis too optimistic.
The distribution of this qualitativebehavior among the 14 datasets is: too optimisticin 2 datasets, too pessimistic in 7 and close to theline y = x in 5 datasets.
The confidence scoresproduced by the WKB are in general worse thanKD-Fix, too optimistic in some confidence range1Arabic, Bulgarian, Chinese, Czech, Danish, Dutch, Ger-man, Japanese, Portuguese, Slovene, Spanish, Swedish andTurkish .
See http://nextens.uvt.nl/?conll/5740 0.2 0.4 0.6 0.8 100.20.40.60.81Expected Accuracy (bin center)Actual AccuracyChineseKD?FixWKB 0 0.2 0.4 0.6 0.8 100.20.40.60.81Expected Accuracy (bin center)Actual AccuracySwedishKD?FixWKB 0 0.2 0.4 0.6 0.8 100.20.40.60.81Expected Accuracy (bin center)Actual AccuracyTurkishKD?FixWKB 0 0.2 0.4 0.6 0.8 100.20.40.60.81Expected Accuracy (bin center)Actual AccuracyDanishKD?FixWKBFigure 1: Evaluation of KD-Fix and WKB by comparing predicted accuracy vs. actual accuracy in each bin on 4 datasets.
Bestperformance is obtained for curves close to the line y=x (black line).
Delta method is omitted as its output is not in the range [0, 1].KD WKB Delta KD-Fix RandomFix +DeltaAvg-Prec 0.535 0.304 0.518 0.547 0.147Prec @10% 0.729 0.470 0.644 0.724 0.145Prec @90% 0.270 0.157 0.351 0.348 0.147RMSE 0.084 0.117 - - 0.458Table 1: Row 1: Average precision in ranking all edges ac-cording confidence values.
Rows 2-3: Precision in detection ofincorrect edges when detected 10% and 90% of all the incorrectedges.
Row 4: Root mean square error.
All results are averagedover all datasets.and too pessimistic in another range.
We computedthe root mean square-error (RMSE) in predicting thebin center value given by?
(?j nj(bj?cj)2)/(?j nj) ,where nj is the number of edges in the jth bin.The results, summarized in the 4th row of Table 1,support the observation that KD-Fix performs betterthan WKB, with smaller RMSE.Incorrect Edges Detection: The goal of this taskis to efficiently detect incorrect predicted-edges.We ranked all predicted edges of the test-set (perdataset) according to their confidence score, order-ing from low to high.
Ideally, erroneous edges bythe parser are ranked at the top.
A summary ofthe average precision, computed at all ranks of erro-neous edges, (averaged over all datasets, due to lackof space), for all confidence estimation methods issummarized in the first row of Table 1.
The aver-age precision achieved by random ordering is aboutequal to the error rate for each dataset.
The Deltamethod improves significantly over both the randomordering and WKB.
KD-Fix achieves the best per-formance in 12 of 14 datasets and the best average-performance.
These results are consistent with theresults obtained for sequence labeling by Mejer andCrammer (2010).Average precision summarizes the detection ofall incorrect edges into a single number.
More re-fined analysis is encapsulated in Precision-Recall(PR) plots, showing the precision as more incorrectedges are detected.
PR plots for three datasets areshown in Fig.
2.
From these plots (applied also toother datasets, omitted due to lack of space) we ob-serve that in most cases KD-Fix performs signifi-cantly better than Delta in the early detection stage(first 10-20% of the incorrect edges), while Deltaperforms better in late detection stages (last 10-20%of the incorrect edges).
The second and third rows ofTable 1 summarize the precision after detecting only10% incorrect edges and after detecting 90% of theincorrect edges, averaged over all datasets.
For ex-ample, in Czech and Portuguese plots of Fig.
2, weobserve an advantage of KD-Fix for low recall andan advantage of Delta in high recall.
Yet for Ara-bic, for example, KD-Fix outperforms Delta alongthe entire range of recall values.KD-Fix assigns at most K distinct confidence val-ues to each edge - the number of models that agreedon that particular edge.
Thus, when edges are rankedaccording to the confidence, all edges that are as-signed the same value are ordered randomly.
Fur-thermore, large fraction of the edges, ?
70 ?
80%,are assigned one of the top-three scores (i.e.
K-2,K-1, K).
As a results, the precision performance ofKD-Fix drops sharply for recall values of 80% andabove.
On the other hand, we hypothesize that thelower precision of Delta at low recall values (dia-mond in Fig.
2) is because by definition Delta takesinto account only two parses, ignoring additionalpossible parses with score close to the highest score.This makes Delta method more sensitive to smalldifferences in score values compared to KD-Fix.Based on this observation, we propose combin-ing both KD-Fix and Delta.
Our new method setsthe confidence score of an edge to be a weightedmean of the score values of KD-Fix and Delta, withweights a and 1-a, respectively.
We use a value57520 40 60 80 1000.20.40.60.8Recall as Percent of Incorect EdgesPrecisionCzechKD?FixDeltaKD?Fix+DeltaWKBRandom20 40 60 80 1000.20.40.60.8Recall as Percent of Incorect EdgesPrecisionPortugueseKD?FixDeltaKD?Fix+DeltaWKBRandom20 40 60 80 1000.20.40.60.8Recall as Percent of Incorect EdgesPrecisionArabicKD?FixDeltaKD?Fix+DeltaWKBRandom0 20 40 60 800.20.30.40.50.60.7KAveragePrecisionArabicChineseDanishDutchSloveneSpanishFigure 2: (Best shown in color.)
Three left plots: Precision in detection of incorrect edges as recall increases.
Right plot: Effect ofK value on KD-Fix method performance (for six languages, the remaining languages follow similar trend, omitted for clarity).a ?
1, so if the confidence value of two edges ac-cording to KD-Fix is different, the contribution ofthe score from Delta is negligible, and the final scoreis very close as score of only KD-Fix.
On the otherhand, if the score of KD-Fix is the same, as hap-pens for many edges at high recall values, then Deltabreaks arbitrary ties.
In other words, the new methodfirst ranks edges according to the confidence scoreof KD-Fix, then among edges with equal KD-Fixconfidence score a secondary order is employed us-ing Delta.
Not surpassingly, we name this methodKD-Fix+Delta.
This new method enjoys the bene-fits of the two methods.
From the first row of Table 1we see that it achieves the highest average-precisionaveraged over the 14 datasets.
It improves average-precision over KD-Fix in 12 of 14 datasets and overDelta in all 14 datasets.
From the second and thirdrow of the table, we see that it has Precision veryclose to KD-Fix for recall of 10% (0.729 vs. 0.724),and very close to Delta for recall of 90% (0.351 vs.0.348).
Moving to Fig.
2, we observe that the curveassociated with the new method (red ticks) is in gen-eral as high as the curves associated with KD-Fixfor low values of recall, and as high as the curvesassociated with Delta for large values of recall.To illustrate the effectiveness of the incorrectedges detection process, Table 2 presents the num-ber of incorrect edges detected vs. number of edgesinspected for the English dataset.
The test set for thistask includes 55K words and the parser made mis-take on 6, 209 edges, that is, accuracy of 88.8%.
Wesee that using the ranking induced by KD-Fix+Deltamethod, inspection of 550, 2750 and 5500 edges(1, 5, 10% of all edges), allows detection of 6.6 ?46% of all incorrect edges, over 4.5 times more ef-fective than random validation.Edges inspected Incorrect edges detected(% of total edges) (% of incorrect edges)550 (1%) 412 (6.6%)2,750 (5%) 1,675 (27%)5,500 (10%) 2,897 (46%)Table 2: Number of incorrect edges detected, and the corre-sponding percentage of all mistakes, after inspecting 1 ?
10%of all edges, using ranking induced by KD-Fix+Delta method.Effect of K value on KD-Fix method perfor-mance The right plot of Fig.
2 shows the average-precision of detecting incorrect edges on the test setusing the KD-Fix method for K values ranging be-tween 2 and 80.
We see that even with K = 2,only two samples per sentence, the average preci-sion results are much better than random ranking inall tasks.
AsK is increased the results improve untilreaching maximal results at K ?
30.
Theoreticalcalculations, using concentration inequalities, showthat accurate estimates based on the sampling proce-dure requires K ?
102 ?
103.
Yet, we see that forpractical uses, smaller K values by 1 ?
2 order ofmagnitude is suffice.References[Crammer et al2006] K. Crammer, O. Dekel, J. Keshet,S.
Shalev-Shwartz, and Y.
Singer.
2006.
Onlinepassive-aggressive algorithms.
JMLR, 7:551?585.
[Hall2007] Keith Hall.
2007. k-best spanning tree pars-ing.
In In Proceedings of the 45th Annual Meeting ofthe Association for Computational Linguistics.
[McDonald et al2005] R. McDonald, F. Pereira, K. Rib-arov, and J. Hajic.
2005.
Non-projective depen-dency parsing using spanning tree algorithms.
InHLT/EMNLP.
[Mejer and Crammer2010] A. Mejer and K. Crammer.2010.
Confidence in structured-prediction usingconfidence-weighted models.
In EMNLP.576
