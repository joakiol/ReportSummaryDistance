Semantic Language Models forTopic Detection and TrackingRamesh NallapatiCenter for Intelligent Information Retrieval,Department of Computer Science,University of Massachusetts,Amherst, MA 01003.nmramesh@cs.umass.eduAbstractIn this work, we present a new semantic lan-guage modeling approach to model news sto-ries in the Topic Detection and Tracking (TDT)task.
In the new approach, we build a unigramlanguage model for each semantic class in anews story.
We also cast the link detection sub-task of TDT as a two-class classification prob-lem in which the features of each sample con-sist of the generative log-likelihood ratios fromeach semantic class.
We then compute a lin-ear discriminant classifier using the perceptronlearning algorithm on the training set.
Resultson the test set show a marginal improvementover the unigram performance, but are not veryencouraging on the whole.1 IntroductionTDT is a research program investigating methods for au-tomatically organizing news stories by the events thatthey discuss (Allan, 2002a).
The goal of TDT consists ofbreaking the stream of news into individual news stories,to monitor the stories for events that have not been seenbefore and to gather stories into groups that each discussa single topic.Several approaches have been explored for compar-ing news stories in TDT.
The traditional vector space ap-proach (Yang et al, 1999) using cosine similarity has byfar been the most consistently successful approach acrossdifferent tasks and several data sets.In the recent past, a new probabilistic approach calledLanguage Modeling (Ponte and Croft, 1998) has provento be very effective in several information retrieval tasks.One of the attractive features of language models is thatthey are firmly rooted in the theory of probability therebyallowing a researcher to explore more sophisticated mod-els guided by the theoretical framework.Allan et al(Allan et al, 1999) applied language mod-els to the first story detection task of TDT and found thatits performance is on par with the traditional vector spacemodels, if not better.
In the language modeling approachto TDT, we measure the similarity of a news story D toa topic by the probability of its generation from the topicmodel M .
Using the unigram assumption of indepen-dence of terms, one can compute the probability of gen-eration of a news story as the product of probabilities ofgeneration of the terms in the story, as shown in the fol-lowing equation:P (D|M) =|D|?i=1P (wi|M) (1)where wi is the i-th term in the story.
The topic model Mis typically evaluated from the statistics of a set of storiesthat are known to be on the topic in consideration.One potential drawback of the unigram languagemodel is that it treats all terms on an equal footing andseems to ignore semantic information of the terms.
Webelieve that such information could be useful in determin-ing the relative importance of a term to the topic of thestory.
For example, terms that belong to the named-entitytype such as person, location, organization may conveymore information about the topic of the story than otherentity types.
Likewise, one might expect that nouns andverbs play a more important role than adjectives, adverbsor propositions in determining the topic of the story.The present work is an attempt to extend the languagemodeling framework to incorporate a model of the rela-tive importance of terms according to the semantic classthey belong to.The remainder of the report is organized as follows.Section 2 summarizes attempts made in the past in cap-turing semantic-class information in information retrievalrelated tasks.
We present the methodology of the new se-mantic language modeling approach in section 3.
In sec-tion 4, we present details of the link detection task andEdmonton, May-June 2003Student Research Workshop , pp.
1-6Proceedings of HLT-NAACL 2003its evaluation.
Section 5 describes the experiments per-formed and presents the results obtained.
In section 6we analyze the performance of the new model.
Section7 ends the discussion with a few observations and laysdown the path to future work.2 Past workTraditionally NLP techniques have not met with muchsuccess in the IR domain.
However, after several ad-vances in tasks such as automatic tagging of text withhigh level semantics such as parts-of-speech (Ratna-parkhi, 1996), named-entities (Bikel et al, 1999),sentence-parsing (Charniak, 1997), etc., there is increas-ing hope that one could leverage this information into IRtechniques.
Traditional vector space models (Salton etal., 1975) and the more recent language models (Ponteand Croft, 1998) tend to ignore any semantic informationand consider only word-tokens or word-stems as basicfeatures.We know of no prior work in the language model-ing framework that tries to incorporate semantic informa-tion into IR models.
However, in vector space modelingframework, there have been a few attempts.
For example,Allan, et al(Allan et al, 1999) use an ad-hoc weight-ing scheme to weight named-entities higher than othertokens in their vector space models for the new event de-tection task of TDT.
They do not report any significantimprovements in their results.
Additionally, the weight-ing scheme is empirical and they present no principledapproach to compute the weights.In the field of ad-hoc retrieval, emerging research onintegrating NLP tools into retrieval models seems encour-aging.
Mihalcea and Mihalcea (Mihalcea and Mihalcea,2001) show that retrieval effectiveness can be improvedby indexing words with their semantic classes such asparts-of-speech, named-entity-type, WordNet synonyms,hypernyms, hyponyms, etc.In this work, we present a principled approach to inte-grating semantic information into the language modelingframework and show how to compute the relative impor-tance of various semantic classes automatically.3 Semantic language modelsRecall that our task involves analyzing and comparing thecontent of news stories by the topics that they discuss.The topic of a news story is typically characterized by anevent, one or more key players which may include per-sons or organizations (the who?
of the event), a locationto which the event is associated (the where?
of the event),a time of occurrence of the event (the when?
of the event)and a description of the event (the what?
of the event).Hence, when comparing news stories, it makes sense tocompare those features between the stories that answerthe above mentioned four ?wh?
questions (Allan et al,2002b).
However, extracting these features may not bea trivial task.
It may need a deep understanding of thesemantics of the story.As a first step towards that end, we can leveragethe ability of statistical taggers that can recognize au-tomatically all instances of named-entities such as per-sons, locations, organizations, and parts-of-speech suchas nouns, verbs, adjectives, etc., in a news story.
As anapproximation to our exact answers to the four ?wh?
ques-tions, we will assume that the set of tokens labeled as per-sons and organizations by the taggers correspond to ananswer to the who?
question, the set of dates correspondto the when?
question, the set of locations to the where?question and lastly, the set of nouns, verbs and adjectivesto the what?
question.
Our hope is that these categoriesof named-entities and parts-of-speech help us capture thesemantics of the news story.
Hence we will address thesecategories as semantic classes in this work and our modelas semantic language model.
Our model is a two-stageprocess in which the first stage involves computing class-specific likelihood ratios while the second stage consistsof combining the ratios using a weighted perceptron.
Theensuing discussion presents the mathematical descriptionof the two stage process.3.1 Class-specific likelihood ratioLet C = {C1, .., C|C|} be the set of semantic classes.Let C(w) be a relation that maps a given occurrence ofa word w to its semantic class C ?
C. Then, for anystory D, we define the list of features Fi(D) that belongto class Ci as follows:Fi(D) = {w1, .., wn | ?nj=1 (wj ?
D)?
(C(wj) = Ci)}(2)where n = |Fi(D)|.
In other words, Fi(D) representsthe list of all tokens in the story D that fall into the cate-gory Ci.
Thus, each story is now represented as a set offeature-lists of all the semantic-classes as shown below:D ?
{F1(D), ..., F|C|(D)} (3)For each semantic class Ci and story D, we define theclass-specific semantic language model Mi(D) as fol-lows:P (w|Mi(D)) = ?f(w,Fi(D))|Fi(D)|+(1??
)f(w,Fi(GE))|Fi(GE)|(4)where f(w,Fi(D)) is the number of occurrences of aword w in a story D in the class Ci and GE is a gen-eral English collection, while ?
is a smoothing parameterthat lies between 0 and 1.
Thus, the class-specific se-mantic language model Mi(D) is a smoothed probabilitydistribution of words in class Ci of story D. This is anal-ogous to the standard document language models used byIR researchers.Given two stories D1 and D2, the semantic class spe-cific likelihood of D2 with respect to D1 is given by:Li(D2|D1) = ln(P (Fi(D2))|Mi(D1)P (Fi(D2))|Mi(GE))= ln(n?j=1( P (wj |Mi(D1))P (wj |Mi(GE)))f(wj ,Fi(D2)))(5)where n = |Fi(D2)|.
We compute the log-likelihood ratio instead of just the generative probabilityP (D2|M(D1)) to overcome the tendency of the genera-tive probability to favor shorter stories.The generative semantic-class-specific general Englishmodel is given by:P (w|Mi(GE)) =f(w,Fi(GE))|Fi(GE)|(6)3.2 Weighted Perceptron approachNow, all that remains to be done is to com-bine the semantic class-specific log-likelihood scores[L1(D2|D1), .., L|C|(D2|D1)]T in a principled way toobtain the overall similarity score of D1 with respect toD2.
Towards that end, we cast the link detection task asa two-class classification problem, the two classes being?on-topic?
and ?off-topic?.
In other words, each story-pair (D1, D2) is a sample and the classification task in-volves assigning the label ?on-topic?
or ?off-topic?
to thestory pair.
We compute the semantic-class-specific log-likelihood scores for all classes and treat them as com-ponents of the feature vector x of the sample as shownbelow:xi(D1, D2) = Li(D2|D1) (7)We use a linear discriminant function that is a linearcombination of the components of x for classification asshown in the following equation:g(y) = wT y (8)where y is the augmented feature vector given by y =[1,x]T , w = [w0, w1, .., w|C|]T is the weight vector.
Inparticular w0 is called the bias or threshold weight.
Fora discriminant function of the form of equation 8, a two-class classifier implements the following decision rule:Decide ?on-topic?
if g(y) > 0 and ?off-topic?
otherwise.The linear discriminant function clearly constitutes a per-ceptron.
Figure 1 shows a graphical representation ofthe perceptron that takes the semantic-class-specific log-likelihood scores as input.|D2(D1L1w)2(DnF)2(DiF)2(D10w?
)1|D2(DnLnw)1|D2(DiiLw)1::::DF)1(DnM)1(DiM)1(D1M::2D1Figure 1: A graphical representation of the semantic lan-guage modelAs the figure indicates, for each story pair(D1, D2), we build semantic-class-specific models[M1(D1), ..,M|C|(D1)] from story D1 as given byequation 4.
We also construct the semantic class-specificfeature lists {F1(D2), .., F|C|(D2)} from story D2 asdefined in equation 2 and then compute the feature vectorx = [L1(D2|D1), .., L|C|(D2|D1)]T where each com-ponent likelihood ratio is computed as given in equation5.
We then perform an inner product of the augmentedfeature vector y and the weight vector w of the percep-tron and the resulting score is output as shown in thefigure.The standard perceptron learns the optimal weight vec-tor w by minimizing its misclassification rate on a train-ing set (Duda et al, 2000).
However, in TDT, misses(classification of an on-topic story pair as off-topic) arepenalized 10 times more strongly than false alarms (clas-sification of an off-topic story pair as on-topic) (Allan,2002a).
We have therefore incorporated these penaltiesinto the criterion function to force the perceptron learnthe optimal classification based on TDT?s cost function.4 Link Detection task and EvaluationIn this section, we describe one of the tasks called link de-tection, on which we performed the experiments reportedin this work.Link detection requires determining whether or nottwo randomly selected stories (D1, D2) discuss the sametopic.
The evaluation methodology of a link detectionsystem requires the system to output a score for eachstory pair that represents the system?s confidence thatboth stories in the pair discuss the same topic.
Thesystem?s performance is then evaluated using a topic-weighted Detection Error Trade-off (DET) curve (Mar-tin et al, 1997) that plots miss rate against false alarmover a large number of story pairs, at different values ofdecision-threshold.
A Link Detection cost function Clinkis then used to combine the miss and false alarm proba-bilities at each value of threshold into a single normalizedevaluation score (Allan, 2002a).
We use the minimumvalue of Clink as the primary measure of effectivenessand show DET curves to illustrate the error trade-offs.
Itmay be useful for the reader to remember that, since theDET curve is an error-tradeoff plot, the closer the curveis to the origin, the better is the performance, unlike thestandard precision-recall curve familiar to the IR commu-nity.5 Experiments and resultsWe have used Identifinder (Bikel et al, 1999) and Jtag(Xu et al, 1994) respectively, to tag each term by itsnamed-entity type and its part of speech category.
Addi-tionally, we have used a list of 423 most frequent wordsto remove stop words from stories.
Stemming is done us-ing the Porter stemmer (Porter, 1980) while the model isimplemented using Java.As a training set, we have used a subset of TDT3corpus that consists of news stories from eight Englishsources collected roughly from October through Decem-ber 1998.
We have used manual transcriptions of storieswhen the source is audio/video.
The training set consistsof 7200 story pairs.
For the general English model for thisset, we have used the same TDT3 natural English manu-ally transcribed set consisting of 37,526 news stories.For the test set, we have used a randomly chosen sub-set of natural English, manually transcribed stories fromTDT2 corpus.
It consists of 6,363 story pairs and the gen-eral English statistics are derived from 40,851 stories.In the unigram language modeling approach to linkdetection, which we have used as baseline in our ex-periments, we build a topic model M(D1) from one ofthe stories D1 in the pair.
We then compute the log-likelihood ratio L(D2|D1) of the second story D2 withrespect to M(D1) similar to equation 5 but consideringthe entire document as a single feature list.
The semanticlanguage model score, on the other hand, is computed asdescribed in section 3.Sometimes we may use a symmetrized version of theformula, as shown below:score(D1, D2) =12(L(D2|D1) + L(D1|D2)) (9)However, in this work, we have considered only theasymmetric version of the formula to maintain simplic-ity of the scoring function.
For fair comparison, we haveused an asymmetric version of the baseline unigram lan-guage model too.We have considered the categories in figure 2 as oursemantic classes.
Note that only terms that are not classi-fied as persons, organizations or locations are consideredas candidates for nouns.
The numbers in the table indi-cate the weight assigned by the perceptron to each class.We have trained the perceptron using the 7200 labeledstory-pairs of the training set.The class All corresponds to the unigram model andconsists of all the terms of the story.
Note that some ofthe classes are defined as the union of two or more sub-classes.
We have done this to nullify the labeling error ofthe named-entity and parts-of-speech taggers.
For exam-ple, we have noticed that Identinder mislabels Personsas Organizations and vice versa quite frequently.
Ourhope is that creating a new class that is a union of bothPersons and Organizations will offset such tagging er-rors.Class Perceptron weightPersons(P) 0.034998Organizations(O) 0.0258486Locations(L) 0.0374133Nouns(N) 0.134969Verbs(V) -7.99771e-05Adjectives(A) 0.017435Adverbs(Ad) -0.0010557P ?
O 0.0647334P ?
O ?
L 0.106417N ?
V 0.138696N ?
V ?
A 0.16157All 0.279056Figure 2: Semantic classes and their weightsThe optimum class-weights as learnt by the Percep-tron offer some interesting insights.
First we note thatthe class All receives the highest weight and this seemsquite intuitive since this class contains all the informa-tion in the story.
However, somewhat surprisingly, theclass N ?
V ?
A receives higher weight than the classP?O?L indicating that the former class contains moretopical information than the latter.
Also, note that Per-sons are more important than Locations which are in turnmore important than Organizations which seems to agreewith common sense.Next we trained the unigram model on the training setand found the optimum value of the smoothing parameter?
to be 0.2.
We have used the same value for the smooth-ing parameter in all the classes of the class-specific lan-guage models and combined the class-specific likelihoodscores using the perceptron weights.
A comparison of theperformance of semantic language model and unigrammodel on the training set is shown in the DET curve offigure 3.
Quite disappointingly, the results indicate thatthe overall performance as indicated by the minimum costin the DET curve has only worsened.Figure 4 presents a comparison between unigram andsemantic language models on the test set.
The smoothingparameters and the perceptron weights are set to the val-125102040608090.01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90Missprobability(in%)False Alarms probability (in %)Lambda = 0.2Random PerformancePerceptron weighted class-specific LMPerceptron weighted class-specific LM TW Min DET Norm(Cost) = 0.1200UnigramUnigram TW Min DET Norm(Cost) = 0.1136Figure 3: Comparison of semantic LM and unigram per-formance on training setues learnt on the training set.
This time, however, we notethat the minimum cost of the semantic language model isslightly lower than that of the unigram model, but the im-provement is very insignificant.125102040608090.01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90Missprobability(in%)False Alarms probability (in %)lambda = 0.2Random PerformancePerceptron weighted class-specific LMPerceptron weighted class-specific LM TW Min DET Norm(Cost) = 0.1248UnigramUnigram TW Min DET Norm(Cost) = 0.1260Figure 4: Comparison of semantic LM and unigram per-formance on test set6 DiscussionIn this section, we first briefly touch upon the variationsin the model we considered and the various experimentswe performed, but could not report in detail owing tospace constraints.
Secondly we discuss why we think themodel?s performance is unsatisfactory.We have considered a simple mixture model to startwith, wherein each class-specific model Mi(D1) gener-ates a list of features in its class Fi(D2) but the modelitself is sampled with a prior probability of P (Mi(D1))which we made dependent on |Fi(D1)|.
This model?sperformance is found to be far below that of the uni-gram approach and hence we abandoned it to favor theperceptron-weighted likelihood ratios.In terms of experiments done, we started out with thebasic semantic classes of P,O,L,N, V,A and Ad with-out considering unions of the classes.
We found that tak-ing unions improved performance and we report the listof classes whose combination performed the best.Coming to the second part of our discussion, we areyet to perform exploratory data analysis to understand thereasons behind the unsatisfactory performance of the newapproach, but we believe the reasons could be three-fold:Firstly, it is possible that we are operating the semanticlanguage model at a sub-optimal level.
For example, wehave used the same value of the smoothing parameter thatwe have learnt for the unigram model in all the classes ofthe semantic language model.
It is possible that differentclasses may require different levels of smoothing for op-timum performance.
We believe one could use a gradientdescent algorithm on TDT?s cost function to learn fromthe training set the optimum values of the smoothing pa-rameters for different classes.Secondly, a linear discriminant function that a percep-tron implements is an overly simplistic classifier and maynot be doing a good job on separating the on-topic pairsfrom the off-topic ones.
A non-linear classifier such as anSVM (Burges, 1998) could help improve our accuracy.Lastly, it is possible that the unigram model is alreadycapturing the relative importance of terms that we are try-ing to model using our semantic language models.
Thelikelihood ratio score we use in the unigram approach be-haves similar to the tf-idf weights, which we know area powerful statistic to capture the relative importance ofterms.
If this were true, then the semantic language modelmay be rendered redundant.The real reasons will only be revealed by an analysisof the data and we hope to do this as part of our futurework.7 Conclusions and Future workIn this work, we have presented a novel approach for linkdetection task of TDT.
The new approach has three keyideas, namely modeling the relative importance of termsby their semantic classes through a new semantic lan-guage modeling approach, casting the link detection taskas a two-class classification problem and learning the op-timum linear discriminant function using the perceptronlearning algorithm.
We believe this is one of the earli-est works that attempts incorporating semantic informa-tion into the language modeling framework.
Althoughwe have built the model specifically for the link detec-tion task, it is general enough to be extended to the othertasks of TDT such as Tracking, New Event Detection andClustering.The results on train and test sets indicate that there is alittle or no improvement in the performance from the newmodel as compared to the unigram approach.As part of our future work, we would like to under-stand the reasons behind the unsatisfactory performanceof the new model and try out a few improvements sug-gested in section 6.
The possible improvements couldconsist of finding the optimal smoothing parameters foreach semantic class and using better non-linear classifierslike SVM.
Another possible area of improvement is toconsider more semantic classes such as dates, numbers,etc.We would also like to build systems for other tasks inTDT based on semantic language models and test theirperformance.
We believe that semantic information ismore critical in tasks such as New Event Detection whichinvolves identifying the first story that discusses a par-ticular event.
New events are typically characterized bymentions of new persons, locations or actions and our se-mantic models are capable of capturing exactly such in-formation.Additionally, it has been suggested that statistical mod-els such as the aspect model (Hoffman, 1999) and thelatent Dirichlet alocation (Blei et al, 2001) which gen-erate words from a mixture of aspect-models can be ex-ploited by modeling semantic classes as the aspects.
Wewill be studying the applicability of these ideas to the cur-rent task as part of our future work.We believe the main contribution of our work lies inour attempt at incorporating semantic information in thelanguage modeling framework and combining scores ina principled way.
We believe we have only taken a firststep in this direction and much remains to be done as partof future work.AcknowledgmentsI would like to thank Prof. James Allan for motivating theidea of exploiting semantic information for TDT and Vic-tor Lavrenko for his valuable comments.
I am also grate-ful to the anonymous reviewers for their very insightfulcomments and suggestions.
This work was supportedin part by the Center for Intelligent Information Re-trieval and in part by SPAWARSYSCEN-SD grant num-bers N66001-99-1-8912 and N66001-02-1-8903.
Anyopinions, findings and conclusions or recommendationsexpressed in this material are the author?s and do not nec-essarily reflect those of the sponsor.ReferencesAllan, J., Jin, H., Rajman, M., Wayne, C., Gildea, D.,Lavrenko, V., Hoberman, R., Caputo, D., Topic-BasedNovelty Detection, Summer Workshop Final Report,Center for Language and Speech Processing, JohnsHopkins University, 1999.Allan, J., Introduction to Topic Detection and Tracking,Topic Detection and Tracking: Event-based Informa-tion Organization, James Allan, Editor, Kluwer Aca-demic Publishers, 1-16, 2002a.Allan, J., Lavrenko, V. and Nallapati, R. UMass atTDT 2002, Topic Detection and Tracking: Workshop,2002b.Bikel, D. M., Schwartz, R. L. and Weischedel, R. M., AnAlgorithm that Learns What?s in a Name, MachineLearning, Vol.
34(1-3), p 211-231, 1999.Blei, D. M., and Ng, A. Y., and Jordan, M. I., LatentDirichlet Allocation, Neural Information ProcessingSystems 14, 2001.Burges, C. J. C., A Tutorial on Support Vector Machinesfor Pattern Recognition, Data Mining and KnowledgeDiscovery, vol.
2(2), p 121-167, 1998.Charniak, E., Statistical Parsing with a Context-FreeGrammar and Word Statistics, AAAI, p 598-603, 1997.Duda, R. O., Hart, P. E. and Stork, D. G., Pattern Classi-fication, Wiley-Interscience, 2nd edition, 2000.Hoffman, T., Probabilistic Latent Semantic Analysis,Proc.
of Uncertainty in Articial Intelligence, 1999.Martin, A., Doddington, G., Kamm, T. and Ordowski,M., The DET curve in assessment of detection taskperformance, EuroSpeech, 1895?1898, 1997.Mihalcea R. and Mihalcea, S., Word Semantics for In-formation Retrieval: Moving One Step Closer to theSemantic Web, International Conference on Toolswith Articial Intelligence, 280-287, 2001.Ponte, J. M. and Croft, W. B., A Language ModelingApproach to Information Retrieval, ACM SIGIR, 275-281, 1998.Porter, M. F., An algorithm for suffix stripping, Pro-gram, 14(3):130-137, 1980.Ratnaparkhi, A., A maximum entropy part-of-speechtagger, In Proceedings of the Empirical Methods inNatural Language Processing Conference, Universityof Pennsylvania, May 1996.Salton, G., Yang, C., and Wong, A., A vector-spacemodel for information retrieval, Comm.
of the ACM,18, 1975.Xu, J., Broglio, J. and Croft, W. B., The design and im-plementation of a part of speech tagger for English,Technical Report IR-52, Center for Intelligent Informa-tion Retrieval, University of Massachusetts, Amherst,1994.Yang, Y., Carbonell, J., Brown, R., Pierce, T., Archibald,B.T.
and Liu, X., Learning Approaches for Detectingand Tracking News Events.
IEEE Intelligent Systems:Special Issue on Applications of Intelligent Informa-tion Retrieval, Vol 14(4), 32-43, 1999.
