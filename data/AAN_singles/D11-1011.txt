Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 118?128,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsClass Label Enhancement via Related InstancesZornitsa KozarevaUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695kozareva@isi.eduKonstantin VoevodskiBoston University111 Cummington St.Boston, MA, 02215kvodski@bu.eduShang-Hua TengUniversity of Southern California941 Bloom Walk, SAL 300Los Angeles, CA 90089shanghua@usc.eduAbstractClass-instance label propagation algorithmshave been successfully used to fuse informa-tion from multiple sources in order to enricha set of unlabeled instances with class labels.Yet, nobody has explored the relationships be-tween the instances themselves to enhance aninitial set of class-instance pairs.
We pro-pose two graph-theoretic methods (centralityand regularization), which start with a smallset of labeled class-instance pairs and use theinstance-instance network to extend the classlabels to all instances in the network.
We carryout a comparative study with state-of-the-artknowledge harvesting algorithm and show thatour approach can learn additional class labelswhile maintaining high accuracy.
We conducta comparative study between class-instanceand instance-instance graphs used to propa-gate the class labels and show that the latterone achieves higher accuracy.1 IntroductionMany natural language processing applications useand rely on semantic knowledge resources.
Sincemanually built lexical repositories such as Word-Net (Fellbaum, 1998) cover a limited amount ofknowledge and are tedious to maintain over time, re-searchers have developed algorithms for automaticknowledge extraction from structured and unstruc-tured texts.
There is a substantial body of workon extracting is-a relations (Etzioni et al, 2005;Kozareva et al, 2008), part-of relations (Girju et al,2003; Pantel and Pennacchiotti, 2006) and generalfacts (Lin and Pantel, 2001; Davidov and Rappoport,2009; Jain and Pantel, 2010).
The usefulness of thegenerated resources has been shown to be valuableto information extraction (Riloff and Jones, 1999),question answering (Katz et al, 2003) and textualentailment (Zanzotto et al, 2006) systems.Among the most common knowledge acquisi-tion approaches are those based on lexical patterns(Hearst, 1992; Etzioni et al, 2005; Kozareva et al,2008) and clustering (Lin and Pantel, 2002; Davidovand Rappoport, 2008).
While clustering can find in-stances and classes that are not explicitly expressedin text, they often may not generate the granularityneeded by the users.
In contrast, pattern-based ap-proaches generate highly accurate lists, but they areconstraint to the information matched by the patternand often suffer from recall.
(Pas?ca, 2004; Snowet al, 2006; Kozareva and Hovy, 2010) have shownthat complete lists of semantic classes and instancesare valuable for the enrichment of existing resourceslike WordNet and for taxonomy induction.
There-fore, researchers have focused on the developmentof methods that can automatically augment the ini-tially extracted class-instance pairs.
(Pennacchiotti and Pantel, 2009) fused informa-tion from pattern-based and distributional systemsusing an ensemble method and a rich set of featuresderived from query logs, web-crawl and Wikipedia.
(Talukdar et al, 2008) improved class-instance ex-tractions exploring the relationships between theclasses and the instances to propagate the initialclass-labels to the remaining unlabeled instances.Later on (Talukdar and Pereira, 2010) showed thatclass-instance extraction with label propagation canbe further improved by adding semantic information118in the form of instance-attribute edges derived fromindependently developed knowledge base.
Similarlyto (Talukdar et al, 2008) and (Talukdar and Pereira,2010), we are interested in enriching class-instanceextractions with label propagation.
However, un-like the previous work, we model the relationshipsbetween the instances themselves to propagate theinitial set of class labels to the remaining unlabeledinstances.
To our knowledge, this is the first workto explore the connections between instances for thetask of class-label propagation.Our work addresses the following question: Is itpossible to effectively explore the structure of thetext-mined instance-instance networks to enhancean incomplete set of class labels?
Our intuition isthat if an instance like bear belongs to a seman-tic class carnivore, and the instance bear is con-nected to the instance fox, then it is more likely thatthe unlabeled instance fox is also of class carnivore.To solve this problem, we propose two graph-basedapproaches that use the structure of the instance-instance graph to propagate the class labels.
Ourmethods are agnostic to the sources of semantic in-stances and classes.
In this work, we carried out ex-periments with a state-of-the-art instance extractionsystem and conducted a comparative study betweenthe original and the enhanced class-instance pairs.The results show that this labeling procedure can be-gin to bridge the gap between the extraction powerof the pattern-based approaches and the desired re-call by finding class-instance pairs that are not ex-plicitly mentioned in text.
The contributions of thepaper are as follows:?
We use only the relationships between the in-stances themselves to propagate class labels.?
We observe how often labels are propagatedalong the edges of our semantic network, andpropose two ways to extend an initial set ofclass labels to all the instance nodes in the net-work.
The first approach uses a linear sys-tem to compute the network centrality relativeto the initially labeled instances.
The secondapproach uses a regularization framework withrespect to a random walk on the network.?
We evaluate the proposed approaches and showthat they discover many new class-instancepairs compared to state-of-the-art knowledgeharvesting algorithm, while still maintaininghigh accuracy.?
We conduct a comparative study between class-instance and instance-instance graphs usedto propagate class labels.
The experimentsshow that considering relationships between in-stances achieves higher accuracy.The rest of the paper is organized as follows.
InSection 2, we review related work.
Section 3 de-scribes the Web-based knowledge harvesting algo-rithm used to extract the instance network and theclass-instance pairs necessary for our experimen-tal evaluation.
Section 4 describes the two graph-theoretic methods for class label propagation usingan instance-instance network.
Section 5 shows acomparative study between the proposed graph al-gorithms and different baselines.
We also showa comparison between class-instance and instance-instance graphs used in the label propagation.
Fi-nally, we conclude in Section 6.2 Related WorkIn the past decade, we have reached a good under-standing on the knowledge harvesting technologyfrom structured (Suchanek et al, 2007) and unstruc-tured text.
Researchers have harvested with vary-ing success semantic lexicons (Riloff and Shepherd,1997) and concept lists (Katz et al, 2003).
Manyefforts have also focused on the extraction of is-arelations (Hearst, 1992; Pas?ca, 2004; Etzioni et al,2005; Pas?ca, 2007; Kozareva et al, 2008), part-of re-lations (Girju et al, 2003; Pantel and Pennacchiotti,2006) and general facts (Etzioni et al, 2005; Davi-dov and Rappoport, 2009; Jain and Pantel, 2010).Various approaches have been proposed followingthe patterns of (Hearst, 1992) and clustering (Linand Pantel, 2002; Davidov and Rappoport, 2008).
Asubstantial body of work has explored issues such asreranking the harvested knowledge using mutual in-formation (Etzioni et al, 2005) and graph algorithms(Hovy et al, 2009), estimating the goodness of text-mining seeds (Vyas et al, 2009), organizing theextracted information (Cafarella et al, 2007a; Ca-farella et al, 2007b) and inducing term taxonomieswith WordNet (Snow et al, 2006) or starting fromscratch (Kozareva and Hovy, 2010).119Since pattern-based approaches tend to be high-precision and low-recall in nature, recently of greatinterest to the research community is the develop-ment of approaches that can increment the recall ofthe harvested class-instance pairs.
(Pennacchiottiand Pantel, 2009) proposed an ensemble seman-tic framework that mixes distributional and pattern-based systems with a large set of features from aweb-crawl, query logs, and Wikipedia.
(Talukdaret al, 2008) combined extractions from free textand structured sources using graph-based label prop-agation algorithm.
(Talukdar and Pereira, 2010)conducted a comparative study of graph algorithmsand showed that class-instance extraction can beimproved using additional information that can bemodeled as instance-attribute edges.Closest to our work is that of (Talukdar et al,2008; Talukdar and Pereira, 2010) who model class-instance relations to propagate class-labels.
Al-though these algorithms can be applied to other rela-tions (Alfonseca et al, 2010), to our knowledge yetnobody has modeled the connections between the in-stances themselves for the task of class-label prop-agation.
We propose regularization and centralitygraph-theoretic methods, which exploit the instance-instance network and a small set of class-instancepairs to propagate the class-labels to the remainingunlabeled instances.
While objectives similar to reg-ularization have been used for class-label propaga-tion, the application of node centrality for this task isalso novel.
The proposed solutions are intuitive andalmost parameter-free (both methods have a singleparameter, which is easy to interpret and does notrequire careful tuning).3 Knowledge Harvesting from the WebOur proposed class-label enhancement approachesare agnostic to the sources of semantic instances andclasses.
Several methods have been developed toharvest instances from the Web (Pas?ca, 2004; Et-zioni et al, 2005; Pas?ca, 2007; Kozareva et al,2008) and potentially we can use any of them.In our experiments, we use the doubly-anchored(DAP) method of (Kozareva et al, 2008), because itachieves higher precision than (Etzioni et al, 2005;Pas?ca, 2007), it is easy to implement and requiresminimum supervision (only one seed instance and alexico-syntactic pattern).For a given semantic class of interest say ani-mals, the algorithm starts with a seed example ofthe class, say whales.
The seed instance is fed intoa doubly-anchored pattern ?<semantic-class> suchas <seed> and *?, which extracts on the positionof the * new instances of the semantic class.
Then,the newly acquired instances are individually placedon the position of the seed in the DAP pattern.
Thebootstrapping procedure is repeated until no new in-stances are found.
We use the harvested instances tobuild the instance-instance graph in which the nodesare the learned instances and directed edges like(whales,dolphins) indicate that the instance whalesextracted the instance dolphins.
The edges betweenthe instances are weighted based on the number oftimes the DAP pattern extracted the instances to-gether.Different strategies can be employed to acquiresemantic classes for each instance.
We follow thefully automated approach of (Hovy et al, 2009),which takes the learned instance pairs from DAP andfeeds them into the pattern ?
* such as <instance1>and <instance2>?.
The algorithm extracts on theposition of the * new semantic classes related toinstance1.
According to (Hovy et al, 2009), theusage of two instances acts as a disambiguator andleads to much more accurate semantic class extrac-tion compared to (Ritter et al, 2009).4 MethodsWe model the output of the instance harvesting al-gorithm as a directed weighted graph that is givenby a set of vertices V and a set of edges E. We usen to denote the number of vertices.
A node u corre-sponds to a learned instance, and an edge (u, v) ?
Eindicates that the instance v was learned from the in-stance u using the DAP pattern.
The weight of theedge w(u, v) specifies the number of times the pairof instances were found by the DAP pattern.
We de-fine the adjacency matrix of the graph as:A(u, v) ={w(u, v) if (u, v) ?
E0 otherwise.We use dout(u) to specify the out-degree of u:dout(u) =?
(u,v)?E w(u, v), and din(v) to specifythe in-degree of v: din(v) = ?
(u,v)?E w(u, v).120We represent the initial set of instances L that arebelieved to belong to class C (the set of labeled in-stances) by a row vector l ?
{0, 1}n, where l(u) = 1if u ?
L. Our objective is to compute a vector l?where l?
(u) is proportional to how likely it is that ubelongs to C. We write all vectors as row vectors,and use ~c to denote a 1 by n constant vector suchthat ~c(u) = c for all u ?
V .4.1 Personalized CentralityOur first approach is based on the intuition that ifu ?
C and (u, v) ?
E, then it is more likely thatv ?
C. Moreover, the larger the weight of the edgew(u, v), the more likely it is that v ?
C. When weextend this intuition to all the in-neighbors, we saythat the score of each node is proportional to the sumof the scores of its in-neighbors scaled by the edgeweights: l?
(v) = ??
(u,v)?E l?
(u)w(u, v).
We canverify that the vector l?
must then satisfy l?
= ?l?A,so it is an eigenvector of the adjacency matrix of thegraph with an eigenvalue of ?.However, this formulation is insufficient becauseeven though it captures our intuition that the nodesget their scores from their in-neighbors, we are stillignoring the initial scores of the nodes.
A way totake the initial scores into consideration is to com-pute the following steady-state equation:l?
= l + ?
?
l?A.
(1)Equation 1 specifies that the score l?
(u) of each nodeu is the sum of its initial score l(u) and the weightedsum of the scores of its neighbors, which is scaledby ?.
This equation is known as ?-centrality, whichwas first introduced by (Bonacich and Lloyd, 2001).The ?
parameter controls how much the score ofeach node depends on the scores of its neighbors.When ?
= 0 the score of each node is equivalent toits initial score, and does not depend on the scoresof its neighbors at all.Alternately, we can think of the vector l?
as thefixed-point of the process in which in each iterationsome node v updates its score l?
(v) by setting l?
(v) =l(v) + ??
(u,v)?E w(u, v)l?
(u).Solving Equation 1 we can see that l?
= l(I ?
?A)?1, where I is the identity matrix of size n.The solution is also closely related to the followingexpression, which is known as a Katz score (Katz,1953):s?
?t=1?tAt.We can verify that At(u, v) gives the number ofpaths of length t between u and v. Katz proposedusing the above expression with the starting vectors = ~1 to measure centrality in a network.
Therefore,the score of node v is given by the number of pathsfrom u to v for all u ?
V , with longer paths givenless weight based on the value of ?.
The methodproposed here measures a similar quantity with anon-uniform starting vector.
To show the relation-ship between the two measures we use the identitythat?
?t=1 ?tAt = (I ??A)?1?
I .
It is easy to seethat l?
= l(I ?
?A)?1= l(?
?t=1 ?tAt + I)= l?
?t=1 ?tAt + l= l?
?t=0 ?tAt.
(2)Equation 2 shows that l?
(v) is given by the numberof paths from u to v for all u ?
L (the initial labeledset).
Using a larger value of ?
corresponds to givingmore weight to paths of longer length.
The summa-tion?
?t=0 ?tAt converges as long as |?| < 1/?max,where ?max is the largest eigenvalue of A. There-fore, we can only consider values of ?
in this range.4.2 Regularization Using Random WalksOur second approach constrains l?
to be as consistentor smooth as possible with respect to the structureof the graph.
The simplest way to express this isto require that for each edge (u, v) ?
E, the scoresof the endpoints l?
(u) and l?
(v) must be as similar aspossible.
Moreover, the greater the weight of theedge w(u, v) the more important it is for the scoresto match.
Using this intuition we can define the fol-lowing optimization problem:argminl??{0,1}n?(u,v)?E(l?(u)?
l?
(v))2.Setting l?
= ~0 or l?
= ~1 clearly optimizes this func-tion, but does not give a meaningful solution.
How-ever, we can additionally constrain l?
by requiringthat the initial labels cannot be modified, or moregenerally penalizing the discrepancy between l?
(u)and l(u) for u ?
L. The methods of (Talukdar andPereira, 2010) optimize objective functions of thistype.121Unlike the work of (Talukdar and Pereira, 2010),here we use an objective function that considerssmoothness with respect to a random walk on thegraph.
Performing a random walk allows us to takemore of the graph structure into account.
For exam-ple, if nodes u and v are part of the same cluster thenit is likely that the edge (u, v) is heavily traversedduring the random walk, and should have a lot ofprobability in the stationary distribution of the walk.Simply considering the weight of the edge w(u, v)gives us no such information.
Therefore if our objec-tive function requires the scores to be consistent withrespect to the stationary probability of the edges inthe random walk, we can compute scores that areconsistent with the clustering structure of the graph.Our semantic network is not strongly connected,so we must make some modifications to the randomwalk to ensure that it has a stationary distribution.Section 4.2.1 describes our random walk and howwe compute the transition probability matrix P andits stationary probability distribution pi.
The defini-tion of our objective function and the description ofhow it is optimized is given in Section 4.2.2.4.2.1 Teleporting Random WalkFormally, a random walk is a process where ateach step we move from some node to one of itsneighbors.
The transition probabilities are givenby edge weights, therefore the transition probabilitymatrix W is the normalized adjacency matrix whereeach row sums to one:W = D?1A.Here the D matrix is the degree matrix, which is adiagonal matrix given byD(u, v) ={dout(u) if u = v0 otherwise.In our semantic network some nodes have no out-neighbors, so in order to compute W we first add aself-loop to any such node.
In addition, we modifythe random walk to reset at each step with nonzeroprobability ?
to ensure that it has a steady-stateprobability distribution.
When the walk resets itjumps or teleports to any node in the graph withequal probability.
The transition probability matrixof this process is given byP = ?K + (1?
?
)W,where K is an n by n matrix given by K(u, v) = 1nfor all u, v ?
V .
The stationary distribution pi mustsatisfy pi = piP .
Equivalently pi can be viewed as asolution to the following PageRank equation:pi = ?s+ (1?
?
)piW.Here the starting vector s = 1n~1 gives the prob-ability distribution for where the walk transitionswhen it resets.
In our computations we use a jumpprobability ?
= 0.15, which is standard for com-putations of PageRank.
The stationary distributionpi can be computed by either solving the PageRankequation or computing the eigenvector of P corre-sponding to the eigenvalue of 1.4.2.2 Regularization(Zhou et al, 2005) propose the following functionto measure the smoothness of l?
with respect to thestationary distribution of the random walk:?(l?)
= 12?
(u,v)?Epi(u)P (u, v)( l?(u)?pi(u)?
l?
(v)?pi(v))2.Here pi(u)P (u, v) gives the steady-state proba-bility of traversing the edge (u, v), and pi(u) andpi(v) specify how much probability u and v havein the stationary distribution pi.
Zhou et al pointout that using this function gives better results thansmoothness with respect to the edge weights, whichcan be formulated by replacing pi(u)p(u, v) withw(u, v), and replacing pi(u) and pi(v) with dout(u)and din(v), respectively.
This observation is con-sistent with our intuition that considering a randomwalk takes more of the graph structure into account.In addition to minimizing ?(l?
), we also want l?
tobe as close as possible to l, which gives the follow-ing optimization problem:argminl??Rn{?(y?)
+ ?||l?
?
l||2}.
(3)Here the ?
> 0 parameter specifies the tradeoff be-tween the two terms: using a larger ?
corresponds toplacing more emphasis on agreement with the initiallabels.
(Zhou et al, 2005) show that this objective isoptimized by computingl?
= (I ?
??
)?1l, (4)where ?
= (?1/2P?
?1/2 + ?
?1/2P?1/2)/2, and?
= 1/(1 + ?).
?
is a diagonal matrix given by122?
(u, v) ={pi(u) if u = v0 otherwise.Zhou et al propose this approach for semi-supervised learning of labels on the graph, given aninitial vector l such that l(u) = 1 if vertex u has thelabel, l(u) = ?1 if u does not have the label, andl(u) = 0 if the vertex is unlabeled.
They proposetaking the sign of l?
(u) to classify u as positive ornegative.
Using our labeling procedure we do nothave any negative examples, so our initial vector lis non-negative, resulting in a non-negative vector l?.This is not a problem because we can still interpretl?
(u) to be proportional to how likely it is that u hasthe label.
Rather than trying different settings of ?,we directly vary ?, with a smaller ?
placing moreemphasis on agreement with initial labels.5 Experimental Evaluation5.1 Data CollectionFor our experimental study, we select three widelyused domains in the harvesting community (Et-zioni et al, 2005; Pas?ca, 2007; Hovy et al, 2009;Kozareva and Hovy, 2010): animals and vehicles.For each domain we randomly selected different se-mantic classes, which resulted in 20 classes alto-gether.
To generate the instance-instance seman-tic network, we use the harvesting procedure de-scribed in Section 3.
For example, to learn instancesassociated with animals, we instantiate the boot-strapping algorithm with the semantic class animals,the seed instance bears and the pattern ?animalssuch as bears and *?.
We submitted the pattern asqueries to Yahoo!Boss and collected new instances.We ranked the instances following (Kozareva et al,2008) which resulted in 397 animal, 4471 plant and1425 vehicle instances.
Table 1 shows the numberof nodes (instances) and directed edges for the con-structed semantic networks.class #instances #directed-edgesanimals 397 2812vehicles 1425 3191Table 1: Nodes & Edges in the Instance Network.Next, we use the harvested instances to auto-matically learn the semantic classes associated withthem.
For example, bears and wolves are animalsbut also mammals, predators, vertebrates amongothers.
The obtained class harvesting results areshown in Table 2.
We indicate with Inst(Hovy etal., 2009) the number of instances in the semanticnetwork that discovered the class during the pattern-based harvesting, and with InstInWordNet the num-ber of instances in the semantic network belongingto the class according to WordNet.ClassName Inst(Hovy et al, 2009) InstInWordNetarthropods 12 50carnivores 24 57chordates 2 313eutherians 3 193insects 5 29invertebrates 53 84mammals 114 205reptile 5 22ruminants 14 34ungulates 16 66crafts 24 68motor vehicles 27 127self-propelled vehicles 36 145vessels 11 36wheeled vehicles 54 190Table 2: Learned & Gold Standard Class-Instances.We can see that the pattern-based approach of(Hovy et al, 2009) does not recover a lot of theclass-instance relations present in WordNet.
Be-cause of this gap between the actual and the har-vested class-instance pairs arises the objective of ourwork, which is to explore the relationships betweenthe instances to propagate the initially learned classlabels to the remaining unlabeled instances.
To eval-uate the performance of our approach, we use as agold standard the WordNet class-instance mappings.5.2 Testing Our ApproachOur approach is based on the intuition that given alabeled instance u of class C, and an instance v inour network, if there is an edge (u, v) then it is morelikely that v has the label C as well.
For example,if the instance bears is of class vertebrates and thereis an edge between the instances bears and wolves,then it is likely that wolves are also vertebrates.Before proceeding with the instance-instance class-label propagation algorithms, first we study whetherthis intuition is correct.Individually for each class label C, we construct aset TC that contains all instances in the network be-longing to C according to WordNet.
Then we com-pute the probability that v belongs to C in WordNet123given that (u, v) is an edge in the instance networkand u belongs to C in WordNet: Prh = Pr[v ?TC | (u, v) ?
E and u ?
TC ].
We comparethis to the background probability Prb = Pr[v ?TC | u, v ?
V and u ?
TC ], which gives the proba-bility that v belongs to C in WordNet if it is chosenat random.
In other words, if Prh = 1, this meansthat whenever u has the label C and (u, v) is anedge, then v is always labeled with C. If indeed thisis the case, then a good classifier can simply take theinitial set L and extend the labels to all nodes reach-able from L in the semantic network.
The larger thedifference between Prh and Prb, the more informa-tion the links of the instance network carry for thetask of label propagation.
Table 3 shows the Prhand Prb values for each class.CLASS Prh Prbarthropods .46 .12carnivores .49 .14chordates .95 .80eutherians .80 .49insects .31 .07invertebrates .74 .21mammals .82 .52reptile .27 .05ruminants .39 .08ungulates .60 .16crafts .07 .05motor vehicles .10 .09self-propelled vehicles .11 .10vessels .08 .02wheeled vehicles .13 .13Table 3: Learned & Gold Standard Class-Instances.This study verifies our intuition that using the re-lationships between the instances to extend a classlabel to the remaining unlabeled nodes is an effec-tive approach to enhancing an incomplete set of ini-tial labels.5.3 Comparative StudyThe objective of our work is given a set of initiallylabeled nodes L, to assign to each node a scorethat indicates how likely it is to belong to L. Thesimplest way to do this using the edges of the in-stance network is to say that a node that has morein-neighbors that have a certain label is more likelyto have this label.
We define the in-neighbor scorei(v) of a node v as i(v) = |{u ?
V |(u, v) ?E and u ?
L}|.
We expect that the higher the in-neighbor score of v, the more likely it is that v hasthe label L. The personalized centrality methodthat we proposed generalizes this intuition to indi-rect neighbors (see Methods).
Our regularizationusing random walks technique further explores thelink structure of the instance network by consideringa random walk on it (see Methods).
We compare ourapproaches with a method that labels nodes at ran-dom.
The expected accuracy for class C is given by|TC |n , where n is the number of nodes in the network,and TC is the set containing all nodes that belong toC according to WordNet.
In other words, given thatthere are 84 nodes in the network that are classifiedas invertebrate according to WordNet, and there are397 nodes in total, if we choose any number of nodesat random our expected accuracy is 21%.We evaluate the performance of our approachesagainst the WordNet gold standard and show the ob-tained results in Tables 4 and 5.Invertebratesrank centrality regularization in-neighbor random5 1.0 1.0 .80 .2110 1.0 1.0 .70 .2120 .95 1.0 .75 .2150 .96 .98 .76 .21100 .69 .73 .67 .21Mammalsrank centrality regularization in-neighbor random5 .80 1.0 .80 .5210 .90 1.0 .90 .5220 .95 .95 .85 .5250 .86 .96 .80 .52100 .92 .92 .76 .52Carnivoresrank centrality regularization in-neighbor random5 1.0 1.0 .80 .1410 .80 .80 .60 .1420 .80 .85 .55 .1450 .50 .68 .48 .14100 .41 .44 .41 .14Table 4: Accuracy @ Different Ranks.Table 4 shows the accuracy at rank R calculatedas the number of correctly labeled instances withclass C at rank R divided by the total number ofinstances with class C at rank R. Due to space limi-tation, we show detailed ranking only for three of theclasses.
We can see that using the semantic networksignificantly enhances our ability to learn class la-bels.
Even the simple in-neighbor method producesresults that are very significant compared to chance.Our centrality and regularization techniques furtherexplore the structure of the semantic network to give124better predictions.Table 5 shows the accuracy of the class label prop-agation algorithms for each class.
For each class weconsider the top k ranked nodes, where k is the num-ber of instances that belong to this class accordingto WordNet.
For example, the accuracy of central-ity for carnivores is 80% showing that from the top57 ranked animal instances, 80% belong to carni-vores.
In the final column we also report the per-formance of a label propagation algorithm that usesclass-instance graph instead of an instance-instancegraph.
To build the graph we remove the edgesbetween the instances and keep the class-instancemappings discovered by the harvesting algorithm of(Hovy et al, 2009).
We use the modified adsorptionalgorithm (MAD) of (Talukdar et al, 2008), whichis freely available from the Junto toolkit1.
To rankthe instances for each class label produced by Junto,we use the computed label scores as a ranking crite-ria and measure accuracy similarly to centrality andregularization.class Centrality Regular.
Rand MADarthropods .50 .60 .12 .56carnivores .80 .85 .14 .44chordates .81 .83 .80 .79eutherians .54 .60 .49 .60insects .38 .52 .07 .17invertebrates .94 .96 .21 .64mammals .82 .90 .52 .63reptile .45 .55 .05 .14ruminants .41 .44 .08 .41ungulates .44 .61 .16 .32crafts .47 .56 .05 .35motor vehicle .45 .48 .09 .24self-propelled vehicle .49 .47 .10 .27vessel .33 .39 .02 .31wheeled vehicle .51 .52 .13 .33Table 5: Comparative Study.The obtained results show that for almost all casesthe methods that use the structure of the instance net-work significantly outperform predictions that usethe class-instance graph.
This indicates that wecan indeed learn a lot form the instance-instancerelationships by exploring the structure of the in-stance network.
Among all approaches regulariza-tion achieves the best results.
We believe that reg-ularization works well because it considers a ran-dom walk on the semantic graph, and within-cluster1http://code.google.com/p/junto/edges are traversed more often in a random walk.The regularization technique computes scores thatare consistent with the clustering structure of thegraph by requiring that the endpoints of highly tra-versed edges, which are likely in the same cluster,have similar scores (see Methods).
Overall, regu-larization enhanced the original output generated bythe pattern-based knowledge harvesting approach of(Hovy et al, 2009) with 1219 new class-instancepairs (75% additional information) while maintain-ing 61.87% accuracy.00.10.20.30.40.50.60.70.80.9150  100  150  200  250  300  350AccuracyRankCentrality_=0.01/hmax _=0.05/hmax _=0.10/hmax _=0.25/hmax _=0.50/hmax _=0.99/hmax Random00.10.20.30.40.50.60.70.80.9150  100  150  200  250  300  350AccuracyRankRegularizationa=0.01 a=0.05a=0.10a=0.25a=0.50a=0.99RandomFigure 1: Parameter Tuning For Invertebrates.5.4 Parameter TuningBoth of our centrality and regularization methodshave a single tunable parameter.
For centrality theparameter ?
controls how much the label of eachnode depends on the labels of its neighbors in the125graph.
The values range from 0 to 1/?max, where?max is the largest eigenvalue of the adjacency ma-trix of the semantic network.
When ?
= 0 the labelof each node is equivalent to its initial label, whilehigher values of ?
give more weight to the labels ofnodes that are further away.For regularization the parameter ?
controls howmuch emphasis is placed on the agreement betweenthe initial and learned labels.
The values of ?
arebetween 0 and 1.
Smaller values require that thelearned labels be more consistent with the originallabels.
When ?
= 0 the learned labels will exactlymatch the original labels.For each method we try several parameter settingsand show the results in Figure 1 for the propagationof the class label invertebrate.
We can see that bothmethods are quite insensitive to the parameter set-tings, unless we choose very extreme values that ig-nore the original labels.5.5 Effect of number of labeled class-instancesWe also study how the quality of the results is af-fected by the number of initial class-instance pairsused by our propagation methods.
We conduct ex-periments using only 25%, 50%, 75% and 100% ofthe initial class-instance pairs learned by (Hovy etal., 2009).
Figure 2 shows the results for the labelpropagation of the class invertebrate.The performance of our methods significantly im-proves when we incorporate more labels.
Still, if weare less concerned with recall and want to find smallsets of nodes with very high accuracy, the numberof initial labels is less important.
For example, start-ing with only 13 labeled nodes we can still achieve100% accuracy for the top 30 nodes using regular-ization, and 96% accuracy for the top 25 nodes usingcentrality.6 ConclusionsIn this paper we proposed a centrality and regular-ization graph-theoretic methods that explore the re-lationships between the instances themselves to ef-fectively extend a small set of class-instance labelsto all instances in a semantic network.
The proposedapproaches are intuitive and almost parameter-free.We conducted a series of experiments in which wecompared the effectiveness of the centrality and reg-0 0.1 0.2 0.3 0.4 0.50.6 0.7 0.8 0.9 150  100  150  200AccuracyRankCentrality Random25% Initial Label50% Initial Label100% Initial Label0 0.1 0.2 0.3 0.4 0.50.6 0.7 0.8 0.9 150  100  150  200AccuracyRankRegularizationRandom25% Initial Label50% Initial Label100% Initial LabelFigure 2: Effect of Number of Initial Class-InstancePairs for Invertebrates.ularization methods to learn new labels for the un-labeled instances.
We showed that the enhancedclass labels improve the original output generated bythe pattern-based knowledge harvesting approach of(Hovy et al, 2009).
Finally, we have studied theimpact of the class-instance and instance-instancegraphs for the class-label propagation task.
The lat-ter approach has shown to produce much more ac-curate results.
In the future, we want to apply ourapproach to Web-based taxonomy induction, whichaccording to (Kozareva and Hovy, 2010) is stifleddue to the lacking relations between the instancesand the classes, and the classes themselves.
The pro-posed methods can be also applied to enhance fact126farms (Jain and Pantel, 2010).AcknowledgmentsWe acknowledge the support of DARPA contractnumber FA8750-09-C-3705 and NSF grant IIS-0429360.
We would like to thank the three anony-mous reviewers for their useful comments and sug-gestions and Partha Talukdar for the discussions onmodified adsorption.ReferencesEnrique Alfonseca, Marius Pasca, and Enrique Robledo-Arnuncio.
2010.
Acquisition of instance attributesvia labeled and related instances.
In Proceeding ofthe 33rd international ACM SIGIR conference on Re-search and development in information retrieval, SI-GIR ?10, pages 58?65.Phillip Bonacich and Paulette Lloyd.
2001.
Social Net-works, 23(3):191?201.Michael J. Cafarella, Christopher R, Dan Suciu, Oren Et-zioni, and Michele Banko.
2007a.
Structured query-ing of web text: A technical challenge.
In in CIDR.Michael J. Cafarella, Dan Suciu, and Oren Etzioni.2007b.
Navigating extracted data with schema discov-ery.
In Tenth International Workshop on the Web andDatabases, WebDB 2007WebDB.Dmitry Davidov and Ari Rappoport.
2008.
Classificationof semantic relationships between nominals using pat-tern clusters.
In Proceedings of ACL-08: HLT, pages227?235, June.Dmitry Davidov and Ari Rappoport.
2009.
Geo-mining:Discovery of road and transport networks using direc-tional patterns.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP-09, pages 267?275.Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2005.
Unsuper-vised named-entity extraction from the web: an exper-imental study.
Artificial Intelligence, 165(1):91?134,June.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Bradford Books.Roxana Girju, Adriana Badulescu, and Dan Moldovan.2003.
Learning semantic constraints for the automaticdiscovery of part-whole relations.
In Proceedings ofthe 2003 Conference of the North American Chapter ofthe Association for Computational Linguistics on Hu-man Language Technology, pages 1?8.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14thconference on Computational linguistics, pages 539?545.Eduard Hovy, Zornitsa Kozareva, and Ellen Riloff.
2009.Toward completeness in concept extraction and clas-sification.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing,pages 948?957.Alpa Jain and Patrick Pantel.
2010.
Factrank: Randomwalks on a web of facts.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(Coling 2010), pages 501?509.Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hilde-brandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-des, Gregory Marton, and Federico Mora.
2003.
In-tegrating web-based and corpus-based techniques forquestion answering.
In Proceedings of the twelfth textretrieval conference (TREC), pages 426?435.Leo Katz.
1953.
A new status index derived from socio-metric analysis.
Psychometrika, 18:39?43.Zornitsa Kozareva and Eduard Hovy.
2010.
A semi-supervised method to learn and construct taxonomiesusing the web.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing, pages 1110?1118.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponympattern linkage graphs.
In Proceedings of the 46thAnnual Meeting of the Association for ComputationalLinguistics ACL-08: HLT, pages 1048?1056.Dekang Lin and Patrick Pantel.
2001.
Dirt - discoveryof inference rules from text.
In In Proceedings of theACM SIGKDD Conference on Knowledge Discoveryand Data Mining, pages 323?328.Dekang Lin and Patrick Pantel.
2002.
Concept discoveryfrom text.
In Proc.
of the 19th international confer-ence on Computational linguistics, pages 1?7.Marius Pas?ca.
2004.
Acquisition of categorized namedentities for web search.
In Proceedings of the thir-teenth ACM international conference on Informationand knowledge management, pages 137?145.Marius Pas?ca.
2007.
Organizing and searching the worldwide web of facts ?
step two: harnessing the wisdomof the crowds.
In Proceedings of the 16th internationalconference on World Wide Web, pages 101?110.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:leveraging generic patterns for automatically harvest-ing semantic relations.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand the 44th annual meeting of the Association forComputational Linguistics, ACL-44, pages 113?120.Marco Pennacchiotti and Patrick Pantel.
2009.
Entityextraction via ensemble semantics.
In Proceedings ofthe 2009 Conference on Empirical Methods in Natural127Language Processing: Volume 1 - Volume 1, EMNLP?09, pages 238?247.Ellen Riloff and Rosie Jones.
1999.
Learning dictionar-ies for information extraction by multi-level bootstrap-ping.
In AAAI ?99/IAAI ?99: Proceedings of the Six-teenth National Conference on Artificial intelligence.Ellen Riloff and Jessica Shepherd.
1997.
A corpus-basedapproach for building semantic lexicons.
In Proceed-ings of the Empirical Methods for Natural LanguageProcessing, pages 117?124.Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009.What is this, anyway: Automatic hypernym discov-ery.
In Proceedings of the AAAI Spring Symposium onLearning by Reading and Learning to Read.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenous evi-dence.
In Proceedings of the 21st International Con-ference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, ACL-44, pages 801?808.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowledge.In WWW ?07: Proceedings of the 16th internationalconference on World Wide Web, pages 697?706.Partha Pratim Talukdar and Fernando Pereira.
2010.Experiments in graph-based semi-supervised learningmethods for class-instance acquisition.
In Proceed-ings of the 48th Annual Meeting of the Association forComputational Linguistics, pages 1473?1481.Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca,Deepak Ravichandran, Rahul Bhagat, and FernandoPereira.
2008.
Weakly-supervised acquisition of la-beled class instances using graph random walks.
InProceedings of the 2008 Conference on EmpiricalMethods in Natural Language Processing, pages 582?590.Vishnu Vyas, Patrick Pantel, and Eric Crestan.
2009.Helping editors choose better seed sets for entity setexpansion.
In Proceeding of the 18th ACM conferenceon Information and knowledge management, CIKM?09, pages 225?234.Fabio Massimo Zanzotto, Marco Pennacchiotti, andMaria Teresa Pazienza.
2006.
Discovering asym-metric entailment relations between verbs using selec-tional preferences.
In ACL-44: Proceedings of the 21stInternational Conference on Computational Linguis-tics and the 44th annual meeting of the Association forComputational Linguistics, pages 849?856.Dengyong Zhou, Jiayuan Huang, and BernhardScho?lkopf.
2005.
Learning from labeled andunlabeled data on a directed graph.
In Proceedingsof the 22nd international conference on Machinelearning, ICML ?05, pages 1036?1043.128
