Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 94?103,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsEACL - Expansion of Abbreviations in CLinical textLisa Tengstrand*, Be?ata Megyesi*, Aron Henriksson+, Martin Duneld+and Maria Kvist+*Department of Linguistics and Philology,Uppsala University, Swedentengstrand@ling.su.se, beata.megyesi@lingfil.uu.se+Department of Computer and System Sciences,Stockholm University, Swedenaronhen@dsv.su.se, xmartin@dsv.su.se, maria.kvist@karolinska.seAbstractIn the medical domain, especially in clin-ical texts, non-standard abbreviations areprevalent, which impairs readability forpatients.
To ease the understanding of thephysicians?
notes, abbreviations need to beidentified and expanded to their originalforms.
We present a distributional seman-tic approach to find candidates of the origi-nal form of the abbreviation, and combinethis with Levenshtein distance to choosethe correct candidate among the semanti-cally related words.
We apply the methodto radiology reports and medical journaltexts, and compare the results to generalSwedish.
The results show that the cor-rect expansion of the abbreviation can befound in 40% of the cases, an improve-ment by 24 percentage points compared tothe baseline (0.16), and an increase by 22percentage points compared to using wordspace models alone (0.18).1 IntroductionAbbreviations are prevalent in text, especially incertain text types where the author has either lim-ited space or time to write the written message andtherefore shortens some words or phrases.
Thismight, however, make it difficult for the readerto understand the meaning of the actual abbre-viation.
Although some abbreviations are well-known, and frequently used by most of us (e.g.,i.e., pm, etc.
), most of the abbreviations used inspecialized domains are often less known to thepublic.
Interpreting them is not an easy task, as ab-breviations are often ambiguous and their correctmeaning depends on the context in which they ap-pear.
For example, military and governmental staffwould naturally read EACL as Emergency ActionChecklist, people in the food and beverage busi-ness might think of the company name EACL, lin-guists would probably interpret it as the EuropeanChapter of Chinese Linguistics, while computa-tional linguists would generally claim that EACLstands for the European Chapter of the Associa-tion for Computational Linguistics.
However, thereaders of this particular article know, as the titlesuggests, that the intended meaning here is the Ex-pansion of Abbreviations in CLinical text.It has been shown that abbreviations are fre-quently occurring in various domains and genres,such as in historical documents, messages in so-cial media, as well as in different registers usedby specialists within a particular field of exper-tise.
Clinical texts produced by health care per-sonnel is an example of the latter.
The clinicaltexts are communication artifacts, and the clini-cal setting requires that information is expressedin an efficient way, resulting in short telegraphicmessages.
Physicians and nurses need to docu-ment their work to describe findings, treatmentsand procedures precisely and compactly, often un-der time pressure.In recent years, governments and health care ac-tors have started making electronic health recordsaccessible, not only to other caretakers, but alsoto patients in order to enable them to participateactively in their own health care processes.
How-ever, several studies have shown that patients havedifficulties to comprehend their own health carereports and other medical texts due to the differentlinguistic features that characterize these, aswellas to medical jargon and technical terminology(Elhadad, 2006; Rudd et al., 1999; Keselman etal., 2007).
It has also been shown that physiciansrarely adapt their writing style in order to producedocuments that are accessible to lay readers (Al-lvin, 2010).
Besides the use of different termi-nologies and technical terms, an important obsta-cle for patients to comprehend medical texts is thefrequent use of ?
for the patients unknown ?
ab-94breviations (Keselman et al., 2007; Adnan et al.,2010).In health records, abbreviations, which consti-tute linguistic units that are inherently difficult todecode, are commonly used and often non stan-dard (Skeppstedt, 2012).
An important step inorder to increase readability for lay readers is totranslate abbreviated words into their correspond-ing full length words.The aim of this study is to explore a distri-butional semantic approach combined with wordnormalization, measured by Levenshtein distance,to abbreviation expansion.
Using distributionalsemantic models, which can be applied to largeamounts of data, has been shown to be a viableapproach to extracting candidates for the underly-ing, original word of an abbreviation.
In order tofind the correct expansion among the semanticallyrelated candidates, we apply the Levenshtein dis-tance measure.
We report on experiments on com-parative studies of various text types in Swedish,including radiology reports, medical journals andtexts taken from a corpus of general Swedish.2 BackgroundAn abbreviation is a shorter ?
abbreviated ?
formof a word or phrase, often originating from a tech-nical term or a named entity.
Abbreviations aretypically formed in one of three ways: by (i) clip-ping the last character sequence of the word (e.g.,pat for patient or pathology), (ii) merging the ini-tial letter(s) of the words to form an acronym (e.g.,UU for Uppsala University), or (iii) merging someof the letters ?
often the initial letter of the sylla-bles ?
in the word (e.g., msg for message).
Abbre-viations can also be formed as a combination ofthese three categories (e.g., EACL for Expansionof Abbreviations in CLinical text).Automatically expanding abbreviations to theiroriginal form has been of interest to computationallinguists as a means to improve text-to-speech, in-formation retrieval and information extraction sys-tems.
Rule-based systems as well as statistical andmachine learning methods have been proposed todetect and expand abbreviations.
A common com-ponent of most solutions is their reliance on the as-sumption that an abbreviation and its correspond-ing definition will appear in the same text.Taghva and Gilbreth (1999) present a methodfor automatic acronym-definition extraction intechnical literature, where acronym detection isbased on case and token length constraints.
Thesurrounding text is subsequently searched for pos-sible definitions corresponding to the detectedacronym using an inexact pattern-matching algo-rithm.
The resulting set of candidate definitionsis then narrowed down by applying the LongestCommon Subsequence (LCS) algorithm (Nakatsuet al., 1982) to the candidate pairs.
They report98% precision and 93% recall when excludingacronyms of two or fewer characters.Park and Byrd (2001), along somewhat similarlines, propose a hybrid text mining approach forabbreviation expansion in technical literature.
Or-thographic constraints and stop lists are first usedto detect abbreviations; candidate definitions arethen extracted from the adjacent text based on a setof pre-specified conditions.
The abbreviations anddefinitions are converted into patterns, for whichtransformation rules are constructed.
An initialrule-base comprising the most frequent rules issubsequently employed for automatic abbreviationexpansion.
They report 98% precision and 94%recall as an average over three document types.In the medical domain, most approaches toabbreviation resolution also rely on the co-occurrence of abbreviations and definitions in atext, typically by exploiting the fact that abbrevi-ations are sometimes defined on their first men-tion.
These studies extract candidate abbreviation-definition pairs by assuming that either the defi-nition or the abbreviation is written in parenthe-ses (Schwartz and Hearst, 2003).
The process ofdetermining which of the extracted abbreviation-definition pairs are likely to be correct is thenperformed either by rule-based (Ao and Takagi,2005) or machine learning (Chang et al., 2002;Movshovitz-Attias and Cohen, 2012) methods.Most of these studies have been conducted onEnglish corpora; however, there is one study onSwedish medical text (Dann?ells, 2006).
There areproblems with this popular approach to abbrevia-tion expansion: Yu et al.
(2002) found that around75% of all abbreviations in the biomedical litera-ture are never defined.The application of this method to clinical textis even more problematic, as it seems highly un-likely that abbreviations would be defined in thisway.
The telegraphic style of clinical narrative,with its many non-standard abbreviations, is rea-sonably explained by time constraints in the clin-ical setting.
There has been some work on iden-95tifying such undefined abbreviations in clinicaltext (Isenius et al., 2012), as well as on findingthe intended abbreviation expansion among candi-dates in an abbreviation dictionary (Gaudan et al.,2005).Henriksson et al.
(2012; 2014) present a methodfor expanding abbreviations in clinical text thatdoes not require abbreviations to be defined, oreven co-occur, in the text.
The method is basedon distributional semantic models by effectivelytreating abbreviations and their corresponding def-inition as synonymous, at least in the sense of shar-ing distributional properties.
Distributional se-mantics (see Cohen and Widdows (2009) for anoverview) is based on the observation that wordsthat occur in similar contexts tend to be semanti-cally related (Harris, 1954).
These relationshipsare captured in a Random Indexing (RI) wordspace model (Kanerva et al., 2000), where se-mantic similarity between words is represented asproximity in high-dimensional vector space.
TheRI word space representation of a corpus is ob-tained by assigning to each unique word an ini-tially empty, n-dimensional context vector, as wellas a static, n-dimensional index vector, which con-tains a small number of randomly distributed non-zero elements (-1s and 1s), with the rest of theelements set to zero1.
For each occurrence of aword in the corpus, the index vectors of the sur-rounding words are added to the target word?s con-text vector.
The semantic similarity between twowords can then be estimated by calculating, for in-stance, the cosine similarity between their contextvectors.
A set of word space models are inducedfrom unstructured clinical data and subsequentlycombined in various ways with different parame-ter settings (i.e., sliding window size for extractingword contexts).
The models and their combina-tions are evaluated for their ability to map a givenabbreviation to its corresponding definition.
Thebest model achieves 42% recall.
Improvement ofthe post-processing of candidate definitions is sug-gested in order to obtain enhanced performance onthis task.The estimate of word relatedness that is ob-tained from a word space model is purely statis-tical and has no linguistic knowledge.
When wordpairs should not only share distributional proper-ties, but also have similar orthographic represen-1Generating sparse vectors of a sufficiently high dimen-sionality in this manner ensures that the index vectors will benearly orthogonal.tations ?
as is the case for abbreviation-definitionpairs ?
normalization procedures could be ap-plied.
Given a set of candidate definitions for agiven abbreviation, the task of identifying plausi-ble candidates can be viewed as a normalizationproblem.
Petterson et al.
(2013) utilize a stringdistance measure, Levenshtein distance (Leven-shtein, 1966), in order to normalize historicalspelling of words into modern spelling.
Adjustingparameters, i.e., the maximum allowed distancebetween source and target, according to observeddistances between known word pairs of historicaland modern spelling, gives a normalization accu-racy of 77%.
In addition to using a Levenshteindistance weighting factor of 1, they experimentwith context free and context-sensitive weights forfrequently occurring edits between word pairs in atraining corpus.
The context-free weights are cal-culated on the basis of one-to-one standard editsinvolving two characters; in this setting the nor-malization accuracy is increased to 78.7%.
Fre-quently occurring edits that involve more than twocharacters, e.g., substituting two characters forone, serve as the basis for calculating context-sensitive weights and gives a normalization accu-racy of 79.1%.
Similar ideas are here applied toabbreviation expansion by utilizing a normaliza-tion procedure for candidate expansion selection.3 MethodThe current study aims to replicate and extenda subset of the experiments conducted by Hen-riksson et al.
(2012), namely those that concernthe abbreviation expansion task.
This includesthe various word space combinations and the pa-rameter optimization.
The evaluation procedureis similar to the one described in (Henriksson etal., 2012).
The current study, however, focuses onpost-processing of the semantically related wordsby introducing a filter and a normalization proce-dure in an attempt to improve performance.
Anoverview of the approach is depicted in Figure 1.Abbreviation expansion can be viewed as a two-step procedure, where the first step involves de-tection, or extraction, of abbreviations, and thesecond step involves identifying plausible expan-sions.
Here, the first step is achieved by extractingabbreviations from a clinical corpus with clinicalabbreviation detection software and using a list ofknown medical abbreviations.
The second step isperformed by first extracting a set of semantically96clinical textabbreviationextractionabbreviationsbaseline corpusword spaceinductionexpansionwordextractionclinical word spaceexpansionwordfilteringLevenshteindistancenormal-izationabbreviation-candidate expansionsevaluationFigure 1: The abbreviation expansion process ofthe current study.similar words for each abbreviation and treatingthese as initial expansions.
More plausible expan-sions of each abbreviation are then obtained by fil-tering the expansion words and applying a normal-ization procedure.3.1 Data3.1.1 CorporaFour corpora are used in the experiments: twoclinical corpora, a medical (non-clinical) corpusand a general Swedish corpus (Table 1).The clinical corpora are subsets of the Stock-holm EPR Corpus (Dalianis et al., 2009), com-prising health records for over one million pa-tients from 512 clinical units in the Stockholm re-gion over a five-year period (2006-2010)2.
Oneof the clinical corpora contains records from vari-ous clinical units, for the first five months of 2008,henceforth referred to as SEPR, and the other con-tains radiology examination reports, produced in2009 and 2010, the Stockholm EPR X-ray Corpus(Kvist and Velupillai, 2013) henceforth referred toas SEPR-X.
The clinical corpora were lemmatized2This research has been approved by the Regional EthicalReview Board in Stockholm (Etikpr?ovningsnamnden i Stock-holm), permission number 2012/2028-31/5using Granska (Knutsson et al., 2003).The experiments in the current study also in-clude a medical corpus.
The electronic editions ofL?akartidningen (Journal of the Swedish MedicalAssociation), with issues from 1996 to 2010, havebeen compiled into a corpus (Kokkinakis, 2012),here referred to as LTK.To compare the medical texts to generalSwedish, the third version of the Stockholm Ume?aCorpus (SUC 3.0) (K?allgren, 1998) is used.
It isa balanced corpus and consists of written Swedishtexts from the early 1990?s from various genres.Corpus #Tokens #Types #LemmasSEPR 109,663,052 853,341 431,932SEPR-X 20,290,064 200,703 162,387LTK 24,406,549 551,456 498,811SUC 1,166,593 97,124 65,268Table 1: Statistical descriptions of the corpora3.1.2 Reference standardsA list of medical abbreviation-definition pairs isused as test data and treated as the reference stan-dard in the evaluation.
The list is derived fromCederblom (2005) and comprises 6384 unique ab-breviations from patient records, referrals and sci-entific articles.
To increase the size of the testdata, the 40 most frequent abbreviations are ex-tracted by a heuristics-based clinical abbreviationdetection tool called SCAN (Isenius et al., 2012).A domain expert validated these abbreviations andmanually provided the correct expansion(s).An inherent property of word space models isthat they model semantic relationships betweenunigrams.
There are, however, abbreviations thatexpand into multiword expressions.
Ongoing re-search on modeling semantic composition withword space models exists, but, in the current studyabbreviations that expanded to multiword defini-tions were simply removed from the test data set.The two sets of abbreviation-expansion pairs weremerged into a single test set, containing 1231unique entries in total.In order to obtain statistically reliable seman-tic relations in the word space, the terms of inter-est must be sufficiently frequent in the data.
As aresult, only abbreviation-expansion pairs with fre-quencies over 50 in SEPR and SEPR-X, respec-tively, were included in each test set.
The SEPRtest set contains 328 entries and the SEPR-X test97set contains 211 entries.
Each of the two test datasets is split into a development set (80%) for modelselection, and a test set (20%) for final perfor-mance estimation.3.2 Expansion word extractionFor the experiments where semantically relatedwords were used for extraction of expansionwords, the top 100 most correlated words for eachof the abbreviations were retrieved from each ofthe word space model configurations that achievedthe best results in the parameter optimization ex-periments.The optimal parameter settings of a word spacevary with the task and data at hand.
It has beenshown that when modeling paradigmatic (e.g.,synonymous) relations in word spaces, a fairlysmall context window size is preferable (Sahlgren,2006).
Following the best results of Henriksson etal.
(2012), we experiment with window sizes of1+1, 2+2, and 4+4.Two word space algorithms are explored: Ran-dom Indexing (RI), to retrieve the words that occurin a similar context as the query term, and RandomPermutation (RP), which also incorporates wordorder information when accumulating the contextvectors (Sahlgren et al., 2008).
In order to exploitthe advantages of both algorithms, and to combinemodels with different parameter settings, RI andRP model combinations are also evaluated.
Themodels and their combinations are:?
Random Indexing (RI): words with a contextually highsimilarity are returned; word order within the contextwindow is ignored.?
Random Permutation (RP): words that are contextu-ally similar and used in the same relative positions arereturned; these are more likely to share grammaticalproperties.?
RP-filtered RI candidates (RI RP): returns the top tenterms in the RI model that are among the top thirtyterms in the RP model.?
RI-filtered RP candidates (RP RI): returns the top tenterms in the RP model that are among the top thirtyterms in the RI model.?
RI and RP combination of similarity scores (RI+RP):sums the cosine similarity scores from the two modelsfor each candidate term and returns the candidates withthe highest aggregate score.All models are induced with three different con-text window sizes for the two clinical corpora,SEPR and SEPR-X.
For each corpus, two variantsare used for word space induction, one where stopwords are removed and one where stop words areretained.
All word spaces are induced with a di-mensionality of 1000.For parameter optimization and model selec-tion, the models and model combinations arequeried for semantically similar words.
For eachof the abbreviations in the development set, the tenmost similar words are retrieved.
Recall is com-puted with regard to this list of candidate words,whether the correct expansion is among these tencandidates.
Since the size of the test data is ratherlimited, 3-fold cross validation is performed onthe development set for the parameter optimiza-tion experiments.
For both SEPR and SEPR-X de-velopment sets, a combination of a RI model witha context window size of 4+4 and a RP model with4+4 context window size in the summing similar-ity scores setting were among the most successfulwith recall scores of 0.25 for SEPR and 0.17 forSEPR-X.3.3 Filtering expansion wordsGiven the expansion words, extracted from clini-cal word spaces or baseline corpora (the baselinesare more thoroughly accounted for in 3.5), a filterwas applied in order to generate candidate expan-sions.
The filter was defined as a set of require-ments, which had to be met in order for the expan-sion word to be extracted as a candidate expansion.The requirements were that the intitial letter of theabbreviation and expansion word had to be iden-tical.
All the letters of the abbreviation also hadto be present in the expansion word in the sameorder.String length difference was also a part of therequirements: the expansion word had to be atleast one character longer than the abbreviation.In order to define an upper bound for expansion to-ken length, string length differences of the SEPRand SEPR-X development sets were obtained.The distribution of string length differences forabbreviation-expansion pairs in the SEPR devel-opment set ranged from 1 to 21 characters.
If amaximum string length difference of 14 was al-lowed, 95.2% of the abbreviation-expansion pairswere covered.
As for the string length differencesin the SEPR-X development set, the distributionranged from 1 to 21 characters.
If a string lengthdifference of up to and including 14 characterswas allowed, 96.3% of the abbreviation-expansionpairs were covered.
Thus, a maximum difference98in string length of 14 was also required for the ex-pansion word to be extracted as a candidate expan-sion.3.4 Levenshtein distance normalizationGiven the set of filtered candidate expansions forthe abbreviations, choosing the correct one can beseen as a normalization problem.
The goal is tomap a source word to a target word, similarly tofor instance methods for spelling correction.
Thetarget word is chosen from a list of words, and thechoice is based on the distance between the sourceand the target where a small distance implies highplausibility.
However, we cannot adopt the sameassumptions as for the problem of spelling correc-tion, where the most common distance between asource word and the correct target word is 1 (Ku-kich, 1992).
Intuitively, we can expect that thereare abbreviations that expand to words within alarger distance than 1.
It would seem somewhatuseless to abbreviate words by one character only,although it is not entirely improbable.Similarly to measuring the string length differ-ence in order to define an upper bound for filteringcandidate expansions, the Levenshtein distancesfor abbreviation-expansion pairs in the develop-ment sets were obtained.For the SEPR and SEPR-X development sets,allowing a Levenshtein distance up to and in-cluding 14 covers 97.8% and 96.6% of theabbreviation-expansion pairs, as shown in Table 2.Given the filtered candidate expansions, theLevenshtein distance for the abbreviation and eachof the candidate expansions were computed.
Foreach one of the candidate expansions, the Leven-shtein distance beween the entry and the abbrevi-ation was associated with the entry.
The result-ing list was sorted in ascending order according toLevenshtein distance.Going through the candidate expansion list, ifthe Levenshtein distance was less than or identicalto the upper bound for Levenshtein distance (14),the candidate expansion was added to the expan-sion list that was subsequently used in the evalu-ation.
In the Levenshtein distance normalizationexperiments, a combination of semantically re-lated words and words from LTK was used.
Whencompiling the expansion list, semantically relatedwords were prioritized.
This implied that wordspace candidate expansion would occupy the toppositions in the expansion list, in ascending orderSEPR SEPR SEPR-X SEPR-XLD Avg % SDev Avg % SDev1 1 0.3 0.4 0.22 4.6 0.4 5 0.63 13 1.2 14.7 1.34 12.2 1 15.1 0.65 12.7 1.3 14.5 2.26 12.7 0.8 12.9 0.97 8.4 0.7 7.8 0.38 10.4 1.5 9.8 29 5.7 0.7 4.9 0.510 4.1 0.7 2.9 0.311 3 0.5 2.6 0.412 3 0.6 2.6 0.413 3.8 5.5 1.3 0.514 3.5 1.1 2.2 0.815 1.3 0.5 1.3 0.516 1.6 0.4 0.4 0.217 0.2 0.118 0.8 0.3 1 0.120 0.2 0.121 0.2 0.1 0.5 0Table 2: Levenshtein distance distribution forabbreviation-expansion pairs.
Average proportionover 5 folds at each Levensthein distance withstandard deviation (SDev) in SEPR and SEPR-Xdevelopment sets.according to Levenshtein distance.
The size of thelist was restricted to ten, and the remaining posi-tions, if there were any, were populated by LTKcandidate expansions in ascending order accord-ing to Levenshtein distance to the abbreviation.
Ifthere were more than one candidate expansion ata specific Levenshtein distance, ranking of thesewas randomized.3.5 EvaluationThe evaluation procedure of the abbreviation ex-pansion implied assessing the ability of finding thecorrect expansions for abbreviations.
In order toevaluate the performance gain of using semanticsimilarity to produce the list of candidate expan-sions over using the filtering and normalizationprocedure alone, a baseline was created.
For thebaseline, expansion words were instead extractedfrom the baseline corpora, the corpus of generalSwedish SUC 3.0 and the medical corpus LTK.A list of all the lemma forms from each baseline99corpus (separately) was provided for each abbre-viation as initial expansion words.
The filter andnormalization procedure was then applied to theseexpansion words.The reference standard contained abbreviation-expansion pairs, as described in 3.1.2.
If any of thecorrect expansions (some of the abbreviations hadmultiple correct expansions) was present in the ex-pansion list provided for each abbreviation in thetest set, this was regarded as a true positive.
Preci-sion was computed with regard to the position ofthe correct expansion in the list and the number ofexpansions in the expansion list, as suggested inHenriksson (2013).
For an abbreviation that ex-panded to one word only, this implied that the ex-pansion list besides holding the correct expansion,also contained nine incorrect expansions, whichwas taken into account when computing precision.The list size was static: ten expansions were pro-vided for each abbreviation, and this resulted inan overall low precision.
Few of the abbreviationsin the development set expanded to more than oneword, giving a precision of 0.17-0.18 for all exper-iments.Results of baseline abbreviation expansion inthe development sets are given in table 3.
Recallis given as an average of 5 folds, as cross valida-tion was performed.
The baseline achieves over-all low recall, with the lowest score of 0.08 for theSEPR-X development set using SUC for candidateexpansion extraction.
The rest of the recall resultsare around 0.11.Corpus SEPR SEPR SEPR-X SEPR-XRecall SDev Recall SDevSUC 0.10 0.05 0.08 0.06LTK 0.11 0.06 0.11 0.11Table 3: Baseline average recall for SEPR andSEPR-X development sets.Results from abbreviation expansion using se-mantically related words with filtering and nor-malization to refine the selection of expansions onSEPR and SEPR-X development sets are shown inTable 4.
Recall is given as an average of 5 folds,as cross validation was performed.
The seman-tically related words are extracted from the wordspace model configuration that had the top recallscores in the parameter optimization experimentsdescribed in 3.2, namely the combination of anRI model and an RP model both with 4+4 contextwindow sizes.
Recall is increased by 14 percent-age points for SEPR and 20 percentage points forSEPR-X when applying filtering and normaliza-tion to the semantically related words.SEPR SEPR SEPR-X SEPR-XRecall SDev Recall SDev0.39 0.05 0.37 0.1Table 4: Abbreviation expansion results for SEPRand SEPR-X development sets using the bestmodel from parameter optimization experiments(RI.4+4+RP.4+4).4 Results4.1 Expansion word extractionThe models and model combinations that had thebest recall scores in the word space parameter op-timization were also evaluated on the test set.
Themodels that had top recall scores in 3.2 achieved0.2 and 0.18 for SEPR and SEPR-X test sets re-spectively, compared to 0.25 and 0.17 in the wordspace parameter optimization.4.2 Filtering expansion words andLevenshtein normalizationAbbreviation expansion with filtering and normal-ization was evaluated on the SEPR and SEPR-Xtest sets.
The results are summarized in Table 5.SEPR SEPR-XSUC 0.09 0.16LTK 0.08 0.14Expansion word extraction 0.20 0.18Filtering and normalization 0.38 0.40Table 5: SEPR and SEPR-X test set results in ab-breviation expansion.Baseline recall scores were 0.09 and 0.08 forSUC and LTK respectively, showing a lower scorefor LTK compared to the results on the SEPR de-velopment set.
For abbreviation expansion (withfiltering and normalization) using semantically re-lated words in combination with LTK, the best re-call score was 0.38 for the SEPR test set, com-pared to 0.39 for the same model evaluated on theSEPR development set.
Compared to the results ofusing semantically related words only (expansionword extraction), recall increased by 18 percent-100age points for the same model when filtering andnormalization was applied.Evaluation on the SEPR-X test set gave higherrecall scores for both baseline corpora comparedto the baseline results for the SEPR-X develop-ment set: the SUC result increased by 8 percentagepoints for recall.
For LTK, there was an increase inrecall of 3 percentage points.
For the SEPR-X testset, recall increased by 22 percentage points whenfiltering and normalization was applied to seman-tically related words extracted from the best modelconfiguration.In comparison to the results of Henriksson etal (2012), where recall of the best model is 0.31without and 0.42 with post-processing of the ex-pansion words for word spaces induced from thedata set (i.e., an increase in recall by 11 percentagepoints), the filtering and normalization procedurefor expansion words of the current study yieldedan increase by 18 percentage points.5 DiscussionThe filter combined with the Levenshtein normali-sation procedure to refine candidate expansion se-lection showed a slight improvement compared tousing post-processing, although the normalizationprocedure should be elaborated in order to be ableto confidently claim that Levenshtein distance nor-malization is a better approach to expansion candi-date selection.
A suggestion for future work is tointroduce weights based on frequently occurringedits between abbreviations and expansions and toapply these in abbreviation normalization.The approach presented in this study is limitedto abbreviations that translate into one full lengthword.
Future research should include handlingmultiword expressions, not only unigrams, in or-der to process acronyms and initialisms.Recall of the development sets in the wordspace parameter optimization experiments showedhigher scores for SEPR (0.25) compared to SEPR-X (0.17).
An explanation to this could be that theamount of data preprocessing done prior to wordspace induction might have varied, in terms of ex-cluding sentences with little or no clinical con-tent.
This will of course affect word space co-occurrence information, as word context is accu-mulated without taking sentence boundaries intoaccount.The lemmatization of the clinical text used forword space induction left some words in theiroriginal form, causing test data and semanticallyrelated words to be morphologically discrepant.Lemmatization adapted to clinical text might haveimproved results.
Spelling errors were also fre-quent in the clinical text, and abbreviations weresometimes normalized into a misspelled variant ofthe correct expansion.
In the future, spelling cor-rection could be added and combined with abbre-viation expansion.The impact that this apporach to abbreviationexpansion might have on readability of clinicaltexts should also be assessed by means of an ex-trinsic evaluation, a matter to be pursued in futureresearch.6 ConclusionsWe presented automatic expansion of abbrevia-tions consisting of unigram full-length words inclinical texts.
We applied a distributional semanticapproach by using word space models and com-bined this with Levenshtein distance measures tochoose the correct candidate among the semanti-cally related words.
The results show that the cor-rect expansion of the abbreviation can be foundin 40% of the cases, an improvement by 24 per-centage points compared to the baseline (0.16) andan increase by 22 percentage points compared tousing word space models alone (0.18).
ApplyingLevenshtein distance to refine the selection of se-mantically related candidate expansions yields atotal recall of 0.38 and 0.40 for radiology reportsand medical health records, respectively.AcknowledgmentsThe study was partly funded by the V?ardal Fun-dation and supported by the Swedish Foundationfor Strategic Research through the project High-Performance Data Mining for Drug Effect Detec-tion (ref.
no.
IIS11-0053) at Stockholm Univer-sity, Sweden.
The authors would also like to directthanks to the reviewers for valuable comments.ReferencesM.
Adnan, J. Warren, and M. Orr.
2010.
Assess-ing text characteristics of electronic discharge sum-maries and their implications for patient readability.In Proceedings of the Fourth Australasian Workshopon Health Informatics and Knowledge Management-Volume 108, pages 77?84.
Australian Computer So-ciety, Inc.101H.
Allvin.
2010.
Patientjournalen som genre: En text-och genreanalys om patientjournalers relation till pa-tientdatalagen.
Master?s thesis, Stockholm Univer-sity.H.
Ao and T. Takagi.
2005.
ALICE: an algorithmto extract abbreviations from MEDLINE.
Journalof the American Medical Informatics Association,12(5):576?586.S.
Cederblom.
2005.
Medicinska f?orkortningar ochakronymer (In Swedish).
Studentlitteratur.J.T.
Chang, H. Sch?utze, and R.B.
Altman.
2002.
Creat-ing an online dictionary of abbreviations from med-line.
Journal of the American Medical InformaticsAssociation, 9:612?620.T.
Cohen and D. Widdows.
2009.
Empirical dis-tributional semantics: Methods and biomedical ap-plications.
Journal of Biomedical Informatics,42(2):390?405.H.
Dalianis, M. Hassel, and S. Velupillai.
2009.
TheStockholm EPR Corpus ?
Characteristics and someinitial findings.
In Proceedings of the 14th Interna-tional Symposium on Health Information Manage-ment Research, pages 243?249.D.
Dann?ells.
2006.
Automatic acronym recognition.In Proceedings of the 11th conference on Europeanchapter of the Association for Computational Lin-guistics (EACL), pages 167?170.N.
Elhadad.
2006.
User-sensitive text summarization:Application to the medical domain.
Ph.D. thesis,Columbia University.S.
Gaudan, H. Kirsch, and D. Rebholz-Schuhmann.2005.
Resolving abbreviations to their senses inMEDLINE.
Bioinformatics, 21(18):3658?3664,September.Z.S.
Harris.
1954.
Distributional structure.
Word,10:146?162.A.
Henriksson, H. Moen, M. Skeppstedt, A. Eklund,V.
Daudaravicius, and M. Hassel.
2012.
Syn-onym Extraction of Medical Terms from ClinicalText Using Combinations of Word Space Models.In Proceedings of Semantic Mining in Biomedicine(SMBM 2012), pages 10?17.A.
Henriksson, H. Moen, M. Skeppstedt, V. Daudar-avicius, and M. Duneld.
2014.
Synonym extrac-tion and abbreviation expansion with ensembles ofsemantic spaces.
Journal of Biomedical Semantics,5(6).A.
Henriksson.
2013.
Semantic Spaces of Clini-cal Text: Leveraging Distributional Semantics forNatural Language Processing of Electronic HealthRecords.
Licentiate thesis, Department of Computerand Systems Sciences, Stockholm University.N.
Isenius, S. Velupillai, and M. Kvist.
2012.Initial Results in the Development of SCAN: aSwedish Clinical Abbreviation Normalizer.
In Pro-ceedings of the CLEF 2012 Workshop on Cross-Language Evaluation of Methods, Applications, andResources for eHealth Document Analysis (CLEFe-Health2012).G.
K?allgren.
1998.
Documentation of the Stockholm-Ume?a corpus.
Department of Linguistics, StockholmUniversity.P.
Kanerva, J. Kristoferson, and A. Holst.
2000.
Ran-dom indexing of text samples for latent semanticanalysis.
In Proceedings of the 22nd annual con-ference of the cognitive science society, page 1036.A.
Keselman, L. Slaughter, C. Arnott-Smith, H. Kim,G.
Divita, A. Browne, C. Tsai, and Q. Zeng-Treitler.2007.
Towards consumer-friendly PHRs: patientsexperience with reviewing their health records.In AMIA Annual Symposium Proceedings, volume2007, pages 399?403.O.
Knutsson, J. Bigert, and V. Kann.
2003.
A ro-bust shallow parser for Swedish.
In Proceedings ofNodalida.D.
Kokkinakis.
2012.
The Journal of theSwedish Medical Association-a Corpus Resourcefor Biomedical Text Mining in Swedish.
In Pro-ceedings of Third Workshop on Building and Eval-uating Resources for Biomedical Text Mining Work-shop Programme, page 40.K.
Kukich.
1992.
Techniques for automatically cor-recting words in text.
ACM Computing Surveys(CSUR), 24(4):377?439.M.
Kvist and S. Velupillai.
2013.
Professional Lan-guage in Swedish Radiology Reports ?
Charac-terization for Patient-Adapted Text Simplification.In Scandinavian Conference on Health Informatics2013, pages 55?59.V.I.
Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions and reversals.
In Sovietphysics doklady, volume 10, page 707.D.
Movshovitz-Attias and W.W. Cohen.
2012.Alignment-HMM-based Extraction of Abbrevia-tions from Biomedical Text.
In Proceedings of the2012 Workshop on Biomedical Natural LanguageProcessing (BioNLP 2012), pages 47?55.N.
Nakatsu, Y. Kambayashi, and S. Yajima.
1982.
Alongest common subsequence algorithm suitable forsimilar text strings.
Acta Informatica, 18(2):171?179.Y.
Park and R.J. Byrd.
2001.
Hybrid text mining forfinding abbreviations and their definitions.
In Pro-ceedings of the 2001 conference on empirical meth-ods in natural language processing, pages 126?133.102E.
Pettersson, B. Megyesi, and J. Nivre.
2013.
Nor-malisation of historical text using context-sensitiveweighted levenshtein distance and compound split-ting.
In Proceedings of the 19th Nordic Conferenceof Computational Linguistics (NODALIDA 2013),pages 163?179.R.E.
Rudd, B.A.
Moeykens, and T.C.
Colton.
1999.Health and literacy: a review of medical and pub-lic health literature.
Office of Educational Researchand Improvement.M.
Sahlgren, A. Holst, and P. Kanerva.
2008.
Permu-tations as a means to encode order in word space.
InProceedings of the 30th Annual Meeting of the Cog-nitive Science Society, pages 1300?1305.M.
Sahlgren.
2006.
The Word-space model.
Ph.D.thesis, Stockholm University.A.S.
Schwartz and M.A.
Hearst.
2003.
A simple al-gorithm for identifying abbreviation definitions inbiomedical text.
In Proceedings of Pacific Sympo-sium on Biocomputing, pages 451?462.M.
Skeppstedt.
2012.
From Disorder to Order: Ex-tracting clinical findings from unstructured text.
Li-centiate thesis, Department of Computer and Sys-tems Sciences, Stockholm University.K.
Taghva and J. Gilbreth.
1999.
Recogniz-ing acronyms and their definitions.
InternationalJournal on Document Analysis and Recognition,1(4):191?198.H.
Yu, G. Hripcsak, and C. Friedman.
2002.
Map-ping abbreviations to full forms in biomedical arti-cles.
Journal of the American Medical InformaticsAssociation, 9(3):262?272.103
