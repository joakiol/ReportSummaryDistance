Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1573?1582,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsAutomated planning for situated natural language generationKonstantina Garoufi and Alexander KollerCluster of Excellence ?Multimodal Computing and Interaction?Saarland University, Saarbru?cken, Germany{garoufi,koller}@mmci.uni-saarland.deAbstractWe present a natural language genera-tion approach which models, exploits, andmanipulates the non-linguistic context insituated communication, using techniquesfrom AI planning.
We show how to gen-erate instructions which deliberately guidethe hearer to a location that is convenientfor the generation of simple referring ex-pressions, and how to generate referringexpressions with context-dependent adjec-tives.
We implement and evaluate ourapproach in the framework of the Chal-lenge on Generating Instructions in Vir-tual Environments, finding that it performswell even under the constraints of real-time generation.1 IntroductionThe problem of situated natural language gen-eration (NLG)?i.e., of generating natural lan-guage in the context of a physical (or virtual)environment?has received increasing attention inthe past few years.
On the one hand, this is be-cause it is the foundation of various emerging ap-plications, including human-robot interaction andmobile navigation systems, and is the focus of acurrent evaluation effort, the Challenges on Gener-ating Instructions in Virtual Environments (GIVE;(Koller et al, 2010b)).
On the other hand, situatedgeneration comes with interesting theoretical chal-lenges: Compared to the generation of pure text,the interpretation of expressions in situated com-munication is sensitive to the non-linguistic con-text, and this context can change as easily as theuser can move around in the environment.One interesting aspect of situated communica-tion from an NLG perspective is that this non-linguistic context can be manipulated by thespeaker.
Consider the following segment of dis-course between an instruction giver (IG) and aninstruction follower (IF), which is adapted fromthe SCARE corpus (Stoia et al, 2008):(1) IG: Walk forward and then turn right.IF: (walks and turns)IG: OK. Now hit the button in the middle.In this example, the IG plans to refer to an ob-ject (here, a button); and in order to do so, gives anavigation instruction to guide the IF to a conve-nient location at which she can then use a simplereferring expression (RE).
That is, there is an inter-action between navigation instructions (intendedto manipulate the non-linguistic context in a cer-tain way) and referring expressions (which exploitthe non-linguistic context).
Although such subdi-alogues are common in SCARE, we are not awareof any previous research that can generate them ina computationally feasible manner.This paper presents an approach to generationwhich is able to model the effect of an utter-ance on the non-linguistic context, and to inten-tionally generate utterances such as the above aspart of a process of referring to objects.
Our ap-proach builds upon the CRISP generation system(Koller and Stone, 2007), which translates gener-ation problems into planning problems and solvesthese with an AI planner.
We extend the CRISPplanning operators with the perlocutionary effectsthat uttering a particular word has on the physi-cal environment if it is understood correctly; morespecifically, on the position and orientation of thehearer.
This allows the planner to predict the non-linguistic context in which a later part of the ut-terance will be interpreted, and therefore to searchfor contexts that allow the use of simple REs.
As aresult, the work of referring to an object gets dis-tributed over multiple utterances of low cognitiveload rather than a single complex noun phrase.A second contribution of our paper is the gen-eration of REs involving context-dependent adjec-tives: A button can be described as ?the left blue1573button?
even if there is a red button to its left.
Wemodel adjectives whose interpretation depends onthe nominal phrases they modify, as well as on thenon-linguistic context, by keeping track of the dis-tractors that remain after uttering a series of mod-ifiers.
Thus, unlike most other RE generation ap-proaches, we are not restricted to building an REby simply intersecting lexically specified sets rep-resenting the extensions of different attributes, butcan correctly generate expressions whose mean-ing depends on the context in a number of ways.In this way we are able to refer to objects earlierand more flexibly.We implement and evaluate our approach inthe context of a GIVE NLG system, by usingthe GIVE-1 software infrastructure and a GIVE-1evaluation world.
This shows that our system gen-erates an instruction-giving discourse as in (1) inabout a second.
It outperforms a mostly non-situated baseline significantly, and compares wellagainst a second baseline based on one of thetop-performing systems of the GIVE-1 Challenge.Next to the practical usefulness this evaluation es-tablishes, we argue that our approach to jointlymodeling the grammatical and physical effects ofa communicative action can also inform new mod-els of the pragmatics of speech acts.Plan of the paper.
We discuss related work inSection 2, and review the CRISP system, on whichour work is based, in Section 3.
We then showin Section 4 how we extend CRISP to generatenavigation-and-reference discourses as in (1), andadd context-dependent adjectives in Section 5.
Weevaluate our system in Section 6; Section 7 con-cludes and points to future work.2 Related workThe research reported here can be seen in thewider context of approaches to generating refer-ring expressions.
Since the foundational work ofDale and Reiter (1995), there has been a consider-able amount of literature on this topic.
Our workdeparts from the mainstream in two ways.
First, itexploits the situated communicative setting to de-liberately modify the context in which an RE isgenerated.
Second, unlike most other RE genera-tion systems, we allow the contribution of a modi-fier to an RE to depend both on the context and onthe rest of the RE.We are aware of only one earlier study on gen-eration of REs with focus on interleaving naviga-tion and referring (Stoia et al, 2006).
In this ma-chine learning approach, Stoia et al train classi-fiers that signal when the context conditions (e.g.visibility of target and distractors) are appropriatefor the generation of an RE.
This method can bethen used as part of a content selection componentof an NLG system.
Such a component, however,can only inform a system on whether to choosenavigation over RE generation at a given point ofthe discourse, and is not able to help it decidewhat kind of navigational instructions to generateso that subsequent REs become simple.To our knowledge, the only previous researchon generating REs with context-dependent modi-fiers is van Deemter?s (2006) algorithm for gener-ating vague adjectives.
Unlike van Deemter, weintegrate the RE generation process tightly withthe syntactic realization, which allows us to gen-erate REs with more than one context-dependentmodifier and model the effect of their linear or-der on the meaning of the phrase.
In modelingthe context, we focus on the non-linguistic con-text and the influence of each of the RE?s words;this is in contrast to previous research on context-sensitive generation of REs, which mainly focusedon the discourse context (Krahmer and Theune,2002).
Our interpretation of context-dependentmodifiers picks up ideas by Kamp and Partee(1995) and implements them in a practical system,while our method of ordering modifiers is linguis-tically informed by the class-based paradigm (e.g.,Mitchell (2009)).On the other hand, our work also stands in a tra-dition of NLG research that is based on AI plan-ning.
Early approaches (Perrault and Allen, 1980;Appelt, 1985) provided compelling intuitions forthis connection, but were not computationally vi-able.
The research we report here can be seenas combining Appelt?s idea of using planning forsentence-level NLG with a computationally be-nign variant of Perrault et al?s approach of model-ing the intended perlocutionary effects of a speechact as the effects of a planning operator.
Our workis linked to a growing body of very recent workthat applies modern planning research to variousproblems in NLG (Steedman and Petrick, 2007;Brenner and Kruijff-Korbayova?, 2008; Benotti,2009).
It is directly based on Koller and Stone?s(2007) reimplementation of the SPUD generator(Stone et al, 2003) with planning.
As far as weknow, ours is the first system in the SPUD tradi-1574S:selfNP:subj ?VP:selfV:selfpushesNP:obj ?semcontent: {push(self,subj,obj)}JohnNP:selfsemcontent: {John(self)}NP:selftheN:selfbuttonsemcontent: {button(self)}N:selfred N *semcontent: {red(self)}(a)S:eNP:j ?VP:eV:epushesNP:b1?
(b)JohnNP:jNP:b1theN:b1buttonN:b1red N *Figure 1: (a) An example grammar; (b) a derivation of ?John pushes the red button?
using (a).tion that explicitly models the context change ef-fects of an utterance.While nothing in our work directly hinges onthis, we implemented our approach in the contextof an NLG system for the GIVE Challenge (Kolleret al, 2010b), that is, as an instruction giving sys-tem for virtual worlds.
This makes our systemcomparable with other approaches to instructiongiving implemented in the GIVE framework.3 Sentence generation as planningOur work is based on the CRISP system (Kollerand Stone, 2007), which encodes sentence gener-ation with tree-adjoining grammars (TAG; (Joshiand Schabes, 1997)) as an AI planning problemand solves that using efficient planners.
It thendecodes the resulting plan into a TAG derivation,from which it can read off a sentence.
In this sec-tion, we briefly recall how this works.
For spacereasons, we will present primarily examples in-stead of definitions.3.1 TAG sentence generationThe CRISP generation problem (like that of SPUD(Stone et al, 2003)) assumes a lexicon of entriesconsisting of a TAG elementary tree annotatedwith semantic and pragmatic information.
An ex-ample is shown in Fig.
1a.
In addition to the el-ementary tree, each lexicon entry specifies its se-mantic content and possibly a semantic require-ment, which can express certain presuppositionstriggered by this entry.
The nodes in the tree maybe labeled with argument names such as semanticroles, which specify the participants in the rela-tion expressed by the lexicon entry; in the exam-ple, every entry uses the semantic role self repre-senting the event or individual itself, and the en-try for ?pushes?
furthermore uses subj and obj forthe subject and object argument, respectively.
Wecombine here for simplicity the entries for ?the?and ?button?
into ?the button?.For generation, we assume as input a knowl-edge base and a communicative goal in addition tothe grammar.
The goal is to compute a derivationthat expresses the communicative goal in a sen-tence that is grammatically correct and complete;whose meaning is justified by the knowledge base;and in which all REs can be resolved to uniqueindividuals in the world by the hearer.
Let?s say,for example, that we have a knowledge base{push(e, j, b1), John(j), button(b1), button(b2),red(b1)}.
Then we can combine instances of thetrees for ?John?, ?pushes?, and ?the button?
intoa grammatically complete derivation.
However,because both b1 and b2 satisfy the semanticcontent of ?the button?, we must adjoin ?red?
intothe derivation to make the RE refer uniquely tob1.
The complete derivation is shown in Fig.
1b;we can read off the output sentence ?John pushesthe red button?
from the leaves of the derived treewe build in this way.3.2 TAG generation as planningIn the CRISP system, Koller and Stone (2007)show how this generation problem can be solvedby converting it into a planning problem (Nau etal., 2004).
The basic idea is to encode the partialderivation in the planning state, and to encode theaction of adding each elementary tree in the plan-ning operators.
The encoding of our example as aplanning problem is shown in Fig.
2.In the example, we start with an initial statewhich contains the entire knowledge base, plusatoms subst(S, root) and ref(root, e) expressingthat we want to generate a sentence about the evente.
We can then apply the (instantiated) actionpushes(root, n1, n2, n3, e, j, b1), which models theact of substituting the elementary tree for ?pushes?1575pushes(u, u1, u2, un, x, x1, x2):Precond: subst(S, u), ref(u, x), push(x, x1, x2),current(u1), next(u1, u2), next(u2, un)Effect: ?subst(S, u), subst(NP, u1), subst(NP, u2),ref(u1, x1), ref(u2, x2), ?y.distractor(u1, y),?y.distractor(u2, y)John(u, x):Precond: subst(NP, u), ref(u, x), John(x)Effect: ?subst(NP, u), ?y.
?John(y) ?
?distractor(u, y)the-button(u, x):Precond: subst(NP, u), ref(u, x), button(x)Effect: ?subst(NP, u), canadjoin(N, u),?y.
?button(y) ?
?distractor(u, y)red(u, x):Precond: canadjoin(N, u), ref(u, x), red(x)Effect: ?y.
?red(y) ?
?distractor(u, y)Figure 2: CRISP planning operators for the ele-mentary trees in Fig.
1.into the substitution node root: It can only beapplied because root is an unfilled substitutionnode (precondition subst(S, root)), and its effectis to remove subst(S, root) from the planning statewhile adding two new atoms subst(NP, n1) andsubst(NP, n2) for the substitution nodes of the?pushes?
tree.
The planning state maintains in-formation about which individual each node refersto in the ref atoms.
The current and next atomsare needed to select unused names for newly in-troduced syntax nodes.1 Finally, the action in-troduces a number of distractor atoms includingdistractor(n2, e) and distractor(n2, b2), express-ing that the RE at n2 can still be misunderstoodby the hearer as e or b2.In this new state, all subst and distractoratoms for n1 can be eliminated with the ac-tion John(n1, j).
We can also apply the actionthe-button(n2, b1) to eliminate subst(NP, n2)and distractor(n2, e), since e is not a button.However distractor(n2, b2) remains.
Now be-cause the action the-button also introduced theatom canadjoin(N, n2), we can remove the fi-nal distractor atom by applying red(n2, b1).This brings us into a goal state, and weare done.
Goal states in CRISP planningproblems are characterized by axioms such as?A?u.
?subst(A, u) (encoding grammatical com-pleteness) and ?u?x.
?distractor(u, x) (requiringunique reference).1This is a different solution to the name-selection problemthan in Koller and Stone (2007).
It is simpler and improvescomputational efficiency.12341 2 3 4b1b2b3f1northFigure 3: An example map for instruction giving.3.3 Decoding the planAn AI planner such as FF (Hoffmann and Nebel,2001) can compute a plan for a planning problemthat consists of the planning operators in Fig.
2and a specification of the initial state and the goal.We can then decode this plan into the TAG deriva-tion shown in Fig.
1b.
The basic idea of thisdecoding step is that an action with a precondi-tion subst(A, u) fills the substitution node u, whilean action with a precondition canadjoin(A, u) ad-joins into a node of category A in the elementarytree that was substituted into u.
CRISP allowsmultiple trees to adjoin into the same node.
In thiscase, the decoder executes the adjunctions in theorder in which they occur in the plan.4 Context manipulationWe are now ready to describe our NLG ap-proach, SCRISP (?Situated CRISP?
), which ex-tends CRISP to take the non-linguistic context ofthe generated utterance into account, and deliber-ately manipulate it to simplify RE generation.As a simplified version of our introductory in-struction giving example (1), consider the map inFig.
3.
The instruction follower (IF), who is lo-cated on the map at position pos3,2 facing north,sees the scene from the first-person perspective asin Fig.
7.
Now an instruction giver (IG) could in-struct the IF to press the button b1 in this scene bysaying ?push the button on the wall to your left?.Interpreting this instruction is difficult for the IFbecause it requires her to either memorize the REuntil she has turned to see the button, or to per-form a mental rotation task to visualize b1 inter-nally.
Alternatively, the IG can first instruct theIF to ?turn left?
; once the IF has done this, the IGcan then simply say ?now push the button in front1576S:selfV:selfpushNP:obj ?semreq: visible(p, o, obj)nonlingcon: player?pos(p),player?ori(o)impeff: push(obj)S:selfV:selfturnAdvleftnonlingcon: player?ori(o1),next?ori?left(o1, o2)nonlingeff: ?player?ori(o1),player?ori(o2)impeff: turnleftS:selfS:self *S:other ?andFigure 4: An example SCRISP lexicon.of you?.
This lowers the cognitive load on the IF,and presumably improves the rate of correctly in-terpreted REs.SCRISP is capable of deliberately generat-ing such context-changing navigation instructions.The key idea of our approach is to extend theCRISP planning operators with preconditions andeffects that describe the (simulated) physical envi-ronment: A ?turn left?
action, for example, mod-ifies the IF?s orientation in space and changes theset of visible objects; a ?push?
operator can thenpick up this changed set and restrict the distractorsof the forthcoming RE it introduces (i.e.
?the but-ton?)
to only objects that are visible in the changedcontext.
We also extend CRISP to generate imper-ative rather than declarative sentences.4.1 Situated CRISPWe define a lexicon for SCRISP to be a CRISPlexicon in which every lexicon entry may also de-scribe non-linguistic conditions, non-linguistic ef-fects and imperative effects.
Each of these is aset of atoms over constants, semantic roles, andpossibly some free variables.
Non-linguistic con-ditions specify what must be true in the worldso a particular instance of a lexicon entry can beuttered felicitously; non-linguistic effects specifywhat changes uttering the word brings about in theworld; and imperative effects contribute to the IF?s?to-do list?
(Portner, 2007) by adding the proper-ties they denote.A small lexicon for our example is shown inFig.
4.
This lexicon specifies that saying ?pushX?
puts pushing X on the IF?s to-do list, and car-ries the presupposition that X must be visible fromthe location where ?push X?
is uttered; this re-flects our simplifying assumption that the IG canturnleft(u, x, o1, o2):Precond: subst(S, u), ref(u, x), player?ori(o1),next?ori?left(o1, o2), .
.
.Effect: ?subst(S, u),?player?ori(o1), player?ori(o2),to?do(turnleft), .
.
.push(u, u1, un, x, x1, p, o):Precond: subst(S, u), ref(u, x), player?pos(p),player?ori(o), visible(p, o, x1), .
.
.Effect: ?subst(S, u), subst(NP, u1), ref(u1, x1),?y.
(y 6= x1 ?
visible(p, o, y) ?
distractor(u1, y)),to?do(push(x1)), canadjoin(S, u), .
.
.and(u, u1, un, e1, e2):Precond: canadjoin(S, u), ref(u, e1), .
.
.Effect: subst(S, u1), ref(u1, e2), .
.
.Figure 5: SCRISP planning operators for the lexi-con in Fig.
4.only refer to objects that are currently visible.Similarly, ?turn left?
puts turning left on the IF?sagenda.
In addition, the lexicon entry for ?turnleft?
specifies that, under the assumption that theIF understands and follows the instruction, theywill turn 90 degrees to the left after hearing it.
Theplanning operators are written in a way that as-sumes that the intended (perlocutionary) effects ofan utterance actually come true.
This assumptionis crucial in connecting the non-linguistic effectsof one SCRISP action to the non-linguistic pre-conditions of another, and generalizes to a scalablemodel of planning perlocutionary acts.
We discussthis in more detail in Koller et al (2010a).We then translate a SCRISP generation prob-lem into a planning problem.
In addition to whatCRISP does, we translate all non-linguistic condi-tions into preconditions and all non-linguistic ef-fects into effects of the planning operator, addingany free variables to the operator?s parameters.An imperative effect P is translated into an ef-fect to?do(P ).
The operators for the example lex-icon of Fig.
4 are shown in Fig.
5.
Finally, weadd information about the situated environment tothe initial state, and specify the planning goal byadding to?do(P ) atoms for each atom P that is tobe placed on the IF?s agenda.4.2 An exampleNow let?s look at how this generates the appropri-ate instructions for our example scene of Fig.
3.We encode the state of the world as depictedin the map in an initial state which contains,among others, the atoms player?pos(pos3,2),player?ori(north), next?ori?left(north,west),1577visible(pos3,2,west, b1), etc.2 We want the IF topress b1, so we add to?do(push(b1)) to the goal.We can start by applying the actionturnleft(root, e, north,west) to the initialstate.
Next to the ordinary grammatical effectsfrom CRISP, this action makes player?ori(west)true.
The new state does not contain any substatoms, but we can continue the sentence byadjoining ?and?, i.e.
by applying the actionand(root, n1, n2, e, e1).
This produces a newatom subst(S, e1), which satisfies one precon-dition of push(n1, n2, n3, e1, b1, pos3,2,west).Because turnleft changed the player orientation,the visible precondition of push is now satisfiedtoo (unlike in the initial state, in which b1 was notvisible).
Applying the action push now introducesthe need to substitute a noun phrase for the object,which we can eliminate with an application ofthe-button(n2, b1) as in Subsection 3.2.Since there are no other visible buttons frompos3,2 facing west, there are no remainingdistractor atoms at this point, and a goal statehas been reached.
Together, this four-step plandecodes into the sentence ?turn left and pushthe button?.
The final state contains the atomsto?do(push(b1)) and to?do(turnleft), indicatingthat an IF that understands and accepts this in-struction also accepts these two commitments intotheir to-do list.5 Generating context-dependentadjectivesNow consider if we wanted to instruct the IF topress b2 in Fig.
3 instead of b1, say with theinstruction ?push the left button?.
This is stillchallenging, because (like most other approachesto RE generation) CRISP interprets adjectives bysimply intersecting all their extensions.
In the caseof ?left?, the most reasonable way to do this wouldbe to interpret it as ?leftmost among all visible ob-jects?
; but this is f1 in the example, and so there isno distinguishing RE for b2.In truth, spatial adjectives like ?left?
and ?up-per?
depend on the context in two different ways.On the one hand, they are interpreted with respectto the current spatio-visual context, in that what ison the left depends on the current position and ori-entation of the hearer.
On the other hand, they also2In a more complex situation, it may be infeasible to ex-haustively model visibility in this way.
This could be fixed byconnecting the planner to an external spatial reasoner (Dorn-hege et al, 2009).left(u, x):Precond: ?y.?
(distractor(u, y) ?
left?of(y, x)),canadjoin(N, u), ref(u, x)Effect: ?y.
(left?of(x, y) ?
?distractor(u, y)),premod?index(u, 2), .
.
.red(u, x):Precond: red(x), canadjoin(N, u), ref(u, x),?premod?index(u, 2)Effect: ?y.
(?red(y) ?
?distractor(u, y)),premod?index(u, 1), .
.
.Figure 6: SCRISP operators for context-dependent and context-independent adjectives.depend on the meaning of the phrase they modify:?the left button?
is not necessarily both a buttonand further to the left than all other objects, it isonly the leftmost object among the buttons.We will now show how to extend SCRISP so itcan generate REs that use such context-dependentadjectives.5.1 Context-dependence of adjectives inSCRISPAs a planning-based approach to NLG, SCRISPis not limited to simply intersecting sets of po-tential referents that only depend on the attributesthat contribute to an RE: Distractors are removedby applying operators which may have context-sensitive conditions depending on the referent andthe distractors that are still left.Our encoding of context-dependent adjectivesas planning operators is shown in Fig.
6.
We onlyshow the operators here for lack of space; they canof course be computed automatically from lexiconentries.
In addition to the ordinary CRISP precon-ditions, the left operator has a precondition requir-ing that no current distractor for the RE u is to theleft of x, capturing a presupposition of the adjec-tive.
Its effect is that everything that is to the rightof x is no longer a distractor for u.
Notice that weallow that there may still be distractors after lefthas been applied (above or below x); we only re-quire unique reference in the goal state.
(Ignorethe premod?index part of the effect for now; wewill get to that in a moment.
)Let?s say that we are computing a plan for re-ferring to b2 in the example map of Fig.
3, startingwith push(root, n1, n2, e, b2, pos3,1, north) andthe-button(n1, b2).
The state after these two ac-tions is not a goal state, because it still containsthe atom distractor(n1, b3) (the plant f1 was re-moved as a distractor by the action the-button).1578Now assume that we have modeled the spatialrelations between all objects in the initial statein left?of and above atoms; in particular, wehave left?of(b2, b3).
Then the action instanceleft(n1, b2) is applicable in this state, as there isno other object that is still a distractor in this stateand that is to the left of b2.
Applying left removesdistractor(n1, b3) from the state.
Thus we havereached a goal state; the complete plan decodes tothe sentence ?push the left button?.This system is sensitive to the order in whichoperators for context-dependent adjectives are ap-plied.
To generate the RE ?the upper left but-ton?, for instance, we first apply the left action andthen the upper action, and therefore upper onlyneeds to remove distractors in the leftmost posi-tion.
On the other hand, the RE ?the left upperbutton?
corresponds to first applying upper andthen left.
These action sequences succeed in re-moving all distractors for different context states,which is consistent with the difference in meaningbetween the two REs.Furthermore, notice that the adjective operatorsthemselves do not interact directly with the en-coding of the context in atoms like visible andplayer?pos, just like the noun operators in Sec-tion 4 didn?t.
The REs to which the adjectives andnouns contribute are introduced by verb operators;it is these verb operators that inspect the currentcontext and initialize the distractor set for the newRE appropriately.
This makes the correctness ofthe generated sentence independent of the order inwhich noun and adjective operators occur in theplan.
We only need to ensure that the verbs areordered correctly, and the workload of modelinginteractions with the non-linguistic context is lim-ited to a single place in the encoding.5.2 Adjective word orderOne final challenge that arises in our system is togenerate the adjectives in the correct order, whichon top of semantically valid must be linguisti-cally acceptable.
In particular, it is known thatsome types of adjectives are limited with respectto the word order in which they can occur in anoun phrase.
For instance, ?large foreign finan-cial firms?
sounds perfectly acceptable, but ??
for-eign large financial firms?
sounds odd (Shaw andHatzivassiloglou, 1999).
In our setting, some ad-jective orders are forbidden because only one or-der produces a correct and distinguishing descrip-Figure 7: The IF?s view of the scene in Fig.
3, asrendered by the GIVE client.tion of the target referent (cf.
?upper left?
vs. ?leftupper?
example above).
However, there are alsoother constraints at work: ??
the red left button?
israther odd even when it is a semantically correctdescription, whereas ?the left red button?
is fine.To ensure that SCRISP chooses to generatethese adjectives correctly, we follow a class-basedapproach to the premodifier ordering problem(Mitchell, 2009).
In our lexicon we assign adjec-tives denoting spatial relations (?left?)
to one classand adjectives denoting color (?red?)
to another;then we require that spatial adjectives must alwaysprecede color adjectives.
We enforce this by keep-ing track of the current premodifier index of the REin atoms of the form premod?index.
Any newlygenerated RE node starts off with a premodifierindex of zero; adjoining an adjective of a certainclass then raises this number to the index for thatclass.
As the operators in Fig.
6 illustrate, coloradjectives such as ?red?
have index one and canonly be used while the index is not higher; oncean adjective from a higher class (such as ?left?, ofa class with index two) is used, the premod?indexprecondition of the ?red?
operator will fail.
Forthis reason, we can generate a plan for ?the leftred button?, but not for ??
the red left button?, asdesired.6 EvaluationTo establish the quality of the generated instruc-tions, we implemented SCRISP as part of a gener-ation system in the GIVE-1 framework, and eval-uated it against two baselines.
GIVE-1 was theFirst Challenge on Generating Instructions in Vir-tual Environments, which was completed in 20091579SCRISP1.
Turn right and move one step.2.
Push the right red button.Baseline A1.
Press the right red button on thewall to your right.Baseline B1.
Turn right.2.
Walk forward 3 steps.3.
Turn right.4.
Walk forward 1 step.5.
Turn left.6.
Good!
Now press the left button.Table 1: Example system instructions generated inthe same scene.
REs for the target are typeset inboldface.
(Koller et al, 2010b).
In this challenge, sys-tems must generate real-time instructions that helpusers perform a task in a treasure-hunt virtual en-vironment such as the one shown in Fig.
7.We conducted our evaluation in World 2 fromGIVE-1, which was deliberately designed to bechallenging for RE generation.
The world con-sists of one room filled with several objects andbuttons, most of which cannot be distinguished bysimple descriptions.
Moreover, some of those mayactivate an alarm and cause the player to lose thegame.
The player?s moves and turns are discreteand the NLG system has complete and accuratereal-time information about the state of the world.Instructions that each of the three systems undercomparison generated in an example scene of theevaluation world are presented in Table 1.The evaluation took place online via the Ama-zon Mechanical Turk, where we collected 25games for each system.
We focus on four mea-sures of evaluation: success rates for solving thetask and resolving the generated REs, averagetask completion time (in seconds) for successfulgames, and average distance (in steps) between theIF and the referent at the time when the RE wasgenerated.
As in the challenge, the task is consid-ered as solved if the player has correctly been ledthrough manipulating all target objects required todiscover and collect the treasure; in World 2, theminimum number of such targets is eight.
An REis successfully resolved if it results in the manipu-lation of the referent, whereas manipulation of analarm-triggering distractor ends the game unsuc-cessfully.6.1 The SCRISP systemOur system receives as input a plan for what theIF should do to solve the task, and successivelytakes object-manipulating actions as the commu-success RErate time success distanceSCRISP 69% 306 71% 2.49Baseline A 16%** 230 49%** 1.97*Baseline B 84% 288 81%* 2.00*Table 2: Evaluation results.
Differences toSCRISP are significant at *p < .05, **p < .005(Pearson?s chi-square test for system success rates;unpaired two-sample t-test for the rest).nicative goals for SCRISP.
Then, for each of thecommunicative goals, it generates instructions us-ing SCRISP, segments them into navigation andaction parts, and presents these to the user as sep-arate instructions sequentially (see Table 1).For each instruction, SCRISP thus draws froma knowledge base of about 1500 facts and a gram-mar of about 30 lexicon entries.
We use theFF planner (Hoffmann and Nebel, 2001; Kollerand Hoffmann, 2010) to solve the planning prob-lems.
The maximum planning time for any in-struction is 1.03 seconds on a 3.06 GHz Intel Core2 Duo CPU.
So although our planning-based sys-tem tackles a very difficult search problem, FF isvery good at solving it?fast enough to generateinstructions in real time.6.2 Comparison with Baseline ABaseline A is a very basic system designed to sim-ulate the performance of a classical RE genera-tion module which does not attempt to manipu-late the visual context.
We hand-coded a correctdistinguishing RE for each target button in theworld; the only way in which Baseline A reactsto changes of the context is to describe on whichwall the button is with respect to the user?s currentorientation (e.g.
?Press the right red button on thewall to your right?
).As Table 2 shows, our system guided 69% ofusers to complete the task successfully, comparedto only 16% for Baseline A (difference is statis-tically significant at p < .005; Pearson?s chi-square test).
This is primarily because only 49%of the REs generated by Baseline A were success-ful.
This comparison illustrates the importance ofREs that minimize the cognitive load on the IF toavoid misunderstandings.6.3 Comparison with Baseline BBaseline B is a corrected and improved versionof the ?Austin?
system (Chen and Karpov, 2009),1580one of the best-performing systems of the GIVE-1Challenge.
Baseline B, like the original ?Austin?system, issues navigation instructions by precom-puting the shortest path from the IF?s current lo-cation to the target, and generates REs using thedescription logic based algorithm of Areces et al(2008).
Unlike the original system, which inflex-ibly navigates the user all the way to the target,Baseline B starts off with navigation, and oppor-tunistically instructs the IF to push a button once ithas become visible and can be described by a dis-tinguishing RE.
We fixed bugs in the original im-plementation of the RE generation module, so thatBaseline B generates only unambiguous REs.
Themodule nonetheless naively treats all adjectives asintersective and is not sensitive to the context oftheir comparison set.
Specifically, a button can-not be referred to as ?the right red button?
if it isnot the rightmost of all visible objects?which ex-plains the long chain of navigational instructionsthe system produced in Table 1.We did not find any significant differences inthe success rates or task completion times betweenthis system and SCRISP, but the former achieveda higher RE success rate (see Table 2).
However,a closer analysis shows that SCRISP was able togenerate REs from significantly further away.
Thismeans that SCRISP?s RE generator solves a harderproblem, as it typically has to deal with more vis-ible distractors.
Furthermore, because of the in-creased distance, the system?s execution monitor-ing strategies (e.g.
for detection and repair of mis-understandings) become increasingly important,and this was not a focus of this work.
In summary,then, we take the results to mean that SCRISP per-forms quite capably in comparison to a top-rankedGIVE-1 system.7 ConclusionIn this paper, we have shown how situated instruc-tions can be generated using AI planning.
We ex-ploited the planner?s ability to model the perlocu-tionary effects of communicative actions for effi-cient generation.
We showed how this made it pos-sible to generate instructions that manipulate thenon-linguistic context in convenient ways, and togenerate correct REs with context-dependent ad-jectives.We believe that this illustrates the power ofa planning-based approach to NLG to flexiblymodel very different phenomena.
An interestingtopic for future work, for instance, is to expand ournotion of context by taking visual and discoursesalience into account when generating REs.
In ad-dition, we plan to experiment with assigning coststo planning operators in a metric planning problem(Hoffmann, 2002) in order to model the cognitivecost of an RE (Krahmer et al, 2003) and computeminimal-cost instruction sequences.On a more theoretical level, the SCRISP actionsmodel the physical effects of a correctly under-stood and grounded instruction directly as effectsof the planning operator.
This is computationallymuch less complex than classical speech act plan-ning (Perrault and Allen, 1980), in which the in-tended physical effect comes at the end of a longchain of inferences.
But our approach is also veryoptimistic in estimating the perlocutionary effectsof an instruction, and must be complemented by anappropriate model of execution monitoring.
Whatthis means for a novel scalable approach to thepragmatics of speech acts (Koller et al, 2010a)is, we believe, an interesting avenue for future re-search.Acknowledgments.
We are grateful to Jo?rgHoffmann for improving the efficiency of FF in theSCRISP domain at a crucial time, and to MargaretMitchell, Matthew Stone and Kees van Deemterfor helping us expand our view of the context-dependent adjective generation problem.
We alsothank Ines Rehbein and Josef Ruppenhofer fortesting early implementations of our system, andAndrew Gargett as well as the reviewers for theirhelpful comments.ReferencesDouglas E. Appelt.
1985.
Planning English sentences.Cambridge University Press, Cambridge, England.Carlos Areces, Alexander Koller, and Kristina Strieg-nitz.
2008.
Referring expressions as formulas ofdescription logic.
In Proceedings of the 5th Inter-national Natural Language Generation Conference,pages 42?49, Salt Fork, Ohio, USA.Luciana Benotti.
2009.
Clarification potential of in-structions.
In Proceedings of the SIGDIAL 2009Conference, pages 196?205, London, UK.Michael Brenner and Ivana Kruijff-Korbayova?.
2008.A continual multiagent planning approach to situ-ated dialogue.
In Proceedings of the 12th Workshopon the Semantics and Pragmatics of Dialogue, Lon-don, UK.1581David Chen and Igor Karpov.
2009.
TheGIVE-1 Austin system.
In The FirstGIVE Challenge: System descriptions.http://www.give-challenge.org/research/files/GIVE-09-Austin.pdf.Robert Dale and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the genera-tion of referring expressions.
Cognitive Science, 19.Christian Dornhege, Patrick Eyerich, Thomas Keller,Sebastian Tru?g, Michael Brenner, and BernhardNebel.
2009.
Semantic attachments for domain-independent planning systems.
In Proceedings ofthe 19th International Conference on AutomatedPlanning and Scheduling, pages 114?121.Jo?rg Hoffmann and Bernhard Nebel.
2001.
TheFF planning system: Fast plan generation throughheuristic search.
Journal of Artificial IntelligenceResearch, 14:253?302.Jo?rg Hoffmann.
2002.
Extending FF to numerical statevariables.
In Proceedings of the 15th European Con-ference on Artificial Intelligence, Lyon, France.Aravind K. Joshi and Yves Schabes.
1997.
Tree-Adjoining Grammars.
In G. Rozenberg and A. Salo-maa, editors, Handbook of Formal Languages, vol-ume 3, pages 69?123.
Springer-Verlag, Berlin, Ger-many.Hans Kamp and Barbara Partee.
1995.
Prototype the-ory and compositionality.
Cognition, 57(2):129 ?191.Alexander Koller and Jo?rg Hoffmann.
2010.
Wakingup a sleeping rabbit: On natural-language sentencegeneration with FF.
In Proceedings of the 20th In-ternational Conference on Automated Planning andScheduling, Toronto, Canada.Alexander Koller and Matthew Stone.
2007.
Sentencegeneration as planning.
In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics, Prague, Czech Republic.Alexander Koller, Andrew Gargett, and KonstantinaGaroufi.
2010a.
A scalable model of planning per-locutionary acts.
In Proceedings of the 14th Work-shop on the Semantics and Pragmatics of Dialogue,Poznan, Poland.Alexander Koller, Kristina Striegnitz, Donna Byron,Justine Cassell, Robert Dale, Johanna Moore, andJon Oberlander.
2010b.
The First Challenge onGenerating Instructions in Virtual Environments.In M. Theune and E. Krahmer, editors, Empir-ical Methods in Natural Language Generation,volume 5790 of LNCS, pages 337?361.
Springer,Berlin/Heidelberg.
To appear.Emiel Krahmer and Mariet Theune.
2002.
Effi-cient context-sensitive generation of referring ex-pressions.
In Kees van Deemter and Rodger Kibble,editors, Information Sharing: Reference and Pre-supposition in Language Generation and Interpre-tation, pages 223?264.
CSLI Publications.Emiel Krahmer, Sebastiaan van Erk, and Andre?
Verleg.2003.
Graph-based generation of referring expres-sions.
Computational Linguistics, 29(1):53?72.Margaret Mitchell.
2009.
Class-based ordering ofprenominal modifiers.
In Proceedings of the 12thEuropean Workshop on Natural Language Genera-tion, pages 50?57, Athens, Greece.Dana Nau, Malik Ghallab, and Paolo Traverso.
2004.Automated Planning: Theory and Practice.
MorganKaufmann.C.
Raymond Perrault and James F. Allen.
1980.
Aplan-based analysis of indirect speech acts.
Amer-ican Journal of Computational Linguistics, 6(3?4):167?182.Paul Portner.
2007.
Imperatives and modals.
NaturalLanguage Semantics, 15(4):351?383.James Shaw and Vasileios Hatzivassiloglou.
1999.
Or-dering among premodifiers.
In Proceedings of the37th Annual Meeting of the Association for Compu-tational Linguistics, pages 135?143, College Park,Maryland, USA.Mark Steedman and Ronald P. A. Petrick.
2007.
Plan-ning dialog actions.
In Proceedings of the 8th SIG-dial Workshop on Discourse and Dialogue, pages265?272, Antwerp, Belgium.Laura Stoia, Donna K. Byron, Darla Magdalene Shock-ley, and Eric Fosler-Lussier.
2006.
Sentenceplanning for realtime navigational instructions.
InNAACL ?06: Proceedings of the Human LanguageTechnology Conference of the NAACL, pages 157?160, Morristown, NJ, USA.Laura Stoia, Darla M. Shockley, Donna K. Byron,and Eric Fosler-Lussier.
2008.
SCARE: A sit-uated corpus with annotated referring expressions.In Proceedings of the 6th International Conferenceon Language Resources and Evaluation, Marrakech,Morocco.Matthew Stone, Christine Doran, Bonnie Webber, To-nia Bleam, and Martha Palmer.
2003.
Microplan-ning with communicative intentions: The SPUDsystem.
Computational Intelligence, 19(4):311?381.Kees van Deemter.
2006.
Generating referring ex-pressions that involve gradable properties.
Compu-tational Linguistics, 32(2).1582
