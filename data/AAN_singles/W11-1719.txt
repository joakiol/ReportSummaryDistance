Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 146?152,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsOn the Difficulty of Clustering Microblog Texts forOnline Reputation ManagementFernando Perez-TellezSMRG, Institute of TechnologyTallaght Dublin, Irelandfernandopt@gmail.comJohn CardiffSMRG, Institute of TechnologyTallaght Dublin, IrelandJohn.Cardiff@ittdublin.ieDavid PintoFCC, Beneme?rita UniversidadAuto?noma de Puebla, Mexicodpinto@cs.buap.mxPaolo RossoNLE Lab.
-ELiRF, UniversidadPolite?cnica de Valencia, Spainprosso@dsic.upv.esAbstractIn recent years microblogs have taken on animportant role in the marketing sphere, inwhich they have been used for sharing opin-ions and/or experiences about a product or ser-vice.
Companies and researchers have becomeinterested in analysing the content generatedover the most popular of these, the Twitterplatform, to harvest information critical fortheir online reputation management (ORM).Critical to this task is the efficient and accurateidentification of tweets which refer to a com-pany distinguishing them from those which donot.
The aim of this work is to present andcompare two different approaches to achievethis.
The obtained results are promising whileat the same time highlighting the difficulty ofthis task.1 IntroductionTwitter1 - a microblog of the Web 2.0 genre that al-lows users to publish brief message updates - hasbecome an important channel through which userscan share their experiences or opinions about a prod-uct, service or company.
In general, companies havetaken advantage of this medium for developing mar-keting strategies.Online reputation management - the monitoringof media and the detection and analysis of opinionsabout an entity - is becoming an important area ofresearch as companies need up to the minute infor-mation on what is being send on the WWW aboutthem and their products.
Being unaware of negative1http://twitter.comcomments regarding a company may affect its repu-tation and misguide consumers into not buying par-ticular products.
On the other hand companies mayidentify user feedback and use it in order to providebetter products and services which could make themmore competitive.A first step in this process is the automatic col-lection of tweets relating to a company.
In this pa-per we present an approach to the categorisation oftweets which contain a company name, into twoclusters corresponding to those which refer to thecompany and those which do not.
Clearly this is notas straightforward as matching keywords due to thepotential for ambiguity.
Providing a solution to thisproblem will allow companies to access to the im-mediate user reaction to their products or services,and thereby manage their reputations more effec-tively (Milstein et al, 2008).The rest of this paper is organised as follows.
Sec-tion 2 describes the problem and the related work.Section 3 presents the data set used in the experi-ments.
Section 4 explains the approaches used inthis research work.
Section 5 shows the experi-ments, the obtained results and a discussion of them.Finally, Section 6 presents the conclusions.2 Problem Description and Related WorkWe are interested in discriminating between Twit-ter entries that correspond to a company from thosethat do not, in particular where the company namealso has a separate meaning in the English language(e.g.
delta, palm, ford, borders).
In this researchwork, we regard a company name as ambiguous ifthe word/s that comprise its name can be used in146different contexts.
An example can be seen in Ta-ble 1 where the word borders is used in the con-text of a company (row 1 & 3) and as the bound-ary of a country (row 2).
We adapt a clustering ap-proach to solving this problem although the size oftweets presents a considerable challenge.
Moreoverthe small vocabulary size in conjunction with thewriting style makes the task more difficult.
Tweetsare written in an informal style, and may also con-tain misspellings or be grammatically incorrect.
Inorder to improve the representation of the tweets wehave proposed two approaches based on an expan-sion procedure (enriching semantic similarity hid-den behind the lexical structure).
In this researchTable 1: Examples of ?True?
and ?False?
tweets that con-tains the Borders wordTRUE excessively tracking the book iordered from borders.com.
kfjgjdfkgjfd.FALSE With a severe shortage of manpower, existing threatto our borders, does it make any sense to send troopsto Afghanistan?
@centerofrightTRUE 33% Off Borders Coupon : http://wp.me/pKHuj-qjwork we demonstrate that a term expansion method-ology, as presented in this paper, can improve therepresentation of the microblogs from a clusteringperspective, and as a consequence the performanceof the clustering task.
In addition, we test the hy-pothesis that specific company names - names thatcan not be found in a dictionary - such as Lennar orWarner may be more easily identified than genericcompany names such as Borders, Palm or Delta,because of the ambiguity of the latter.We describe briefly here the work related to theproblem of clustering short texts related to compa-nies.
In particular those works in the field of cate-gorisation of tweets and clustering of short texts.In (Sankaranarayanan et al, 2009) an approach ispresented for binary classification of tweets (class?breaking news?
or other).
The class ?breakingnews?
is then clustered in order to find the mostsimilar news tweets, and finally a location of thenews for each cluster is provided.
Tweets are con-sidered short texts as mentioned in (Sriram et al,2010) where a proposal for classifying tweets is pre-sented.
This work addressed the problem by using asmall set of domain-specific features extracted fromthe author?s profile and the tweet text itself.
Theyclaim to effectively classify the tweet to a predefinedset of generic classes such as News, Events, Opin-ions, Deals, and Private Messages.
Therefore, it isimportant to analyse some techniques for categori-sation of short texts.The main body of relevant related research em-anates from the WePS-3 evaluation campaign inthe task 2 called Online Reputation Management(Amigo?
et al, 2010).
In (Garc?
?a-Cumbreras et al,2010) the authors based their approach on recog-nising named entities, extracting external informa-tion and predefining rules.
They use the well-knownName Entity Recogniser (NER) included in GATE2for recognising all the entities in their Tweets.
Theyalso use the web page of the organisation, Wikipediaand DBpedia3.
Predefined rules are then applied todetermine if a Twitter entry belongs to an organisa-tion or not.The work presented in (Kalmar, 2010) uses datafrom the company website.
This data is used to cre-ate a initial model from which to bootstrap a modelfrom the Tweets, the keywords and description areweighted.
The features used are the co-occurringwords in each tweet and the relevance of them wascalculated according to the Pointwise Mutual Infor-mation value.
Although it seems to be an interestingapproach the results shown are disappointing.In (Yerva et al, 2010) a support vector machine(SVM) classifier is used with the profiles built apriori.
Profiles are constructed for each companywhich are sets of keywords that are related to thecompany or sets of keywords unrelated to the com-pany.
This system uses external resources such asWordnet4, meta-data from the company web page,GoogleSet5 and user feedback.
The research pre-sented in (Yoshida et al, 2010) propose that organi-sation names can be classified as ?organization-linenames?
or ?general-word-like names?.
The authorshave observed that the fact that ratio of positive ornegative (if the tweet is related to the organisation ornot) has a strong correlation with the types of organ-isation names i.e., ?organization-like names?
havehigh percentages of tweets related to the company2http://gate.ac.uk/3http://dbpedia.org/4http://wordnet.princeton.edu/5http://labs.google.com/sets147and when compared to ?general-word-like names?Another approach is described in (Tsagkias and Ba-log, 2010), in which the authors trained the well-known J48 decision tree classifier using as featuresthe company name, content value such as the pres-ence of URLs, hashtags or is-part-of-a-conversation,content quality such as ratio of punctuation and cap-ital characters and organisational context.
This ap-proach is quite interesting but they require a trainingset.3 Dataset DescriptionWe base our experiments on the corpus provided fortask two of the WePS-3 evaluation campaign6, re-lated to Online Reputation Management for organi-sations, or specifically on the problem of organisa-tion (company) name ambiguity.Table 2: Statistics of company tweets used in the experi-ments.Company T/F 3 4 ?
5Bestbuy 24/74 704 14.70 6 22Borders 25/69 665 12.29 2 20Delta 39/57 584 12.27 5 20Ford 62/35 700 12.79 2 22Leapfrog 70/26 1262 13.14 3 20Opera 25/73 671 12.32 1 25Overstock 70/24 613 13.84 3 22Palm 28/71 762 14.20 4 22Southwest 39/60 665 13.61 4 21Sprint 56/38 624 12.10 3 22Armani 312/103 2325 13.64 2 23Barclays 286/133 2217 14.10 2 24Bayer 228/143 2105 13.63 3 22Blockbuster 306/131 5595 11.75 3 21Cadillac 271/156 2449 12.19 2 24Harpers 142/295 2356 12.20 2 23Lennar 74/25 438 13.37 5 21Mandalay 322/113 2085 12.42 2 22Mgm 177/254 1977 13.63 2 24Warner 23/76 596 13.15 4 20T/F - No.
of true/false Tweets,3 - Vocabulary size,4 - Average words in Tweets,?
- Minimum number of words in Tweets,5 - Maximum number of words in Tweets.The corpus was obtained from the trial and train-ing data sets of this evaluation campaign.
The trialcorpus of task 2 contains entries for 17 (English)6WePS3: searching information about entities in the Web,http://nlp.uned.es/weps/, February 2010and 6 (Spanish) organisations; whereas the train-ing data set contains 52 (English) organisations.
Thecorpus was labelled by five annotators: the true la-bel means that the tweet is associated to a company,whereas the false one means that the tweet is notrelated to any company, and the unknown label isused where the annotators were unable to make adecision.In order to gauge the problem and to estab-lish a baseline for the potential of a clustering ap-proach.
We decided to cluster the data sets (trialand training) using the K-means algorithm (Mac-Queen, 1967) with k equal to three in order to havea clear reference and detect possible drawbacks thatthe collections may contain.
The results were eval-uated using the F-measure (van Rijsbergen, 1979)and gave values of 0.52 and 0.53 for the trial andtraining data sets respectively.
This was expected, asclustering approaches typically work best with longdocuments and balanced groups (Perez-Tellez et al,2009).
Using this baseline, we then considered howa clustering approach could be improved by apply-ing text enrichment methods.
In order to compareonly the effect of the enrichment however, we havemodified the data set by including only those tweetswritten in English and for which a true or falselabel has been established, i.e., in the experimentscarried out we do not consider the unknown label.Furthermore, the subset used in the experimentsincludes only those 20 companies with a sufficientnumber of positive and negative samples (true/false),i.e., at least 20 items must be in each category.
Fi-nally, each selected company must contain at least90 labeled tweets, which was the minimum num-ber of tweets associated with a company found inthe collection.
In Table 2 we present a detailed de-scription of the corpus features such as the numberof true and false tweets, the average length of thetweets (average number of words),the minimum andmaximum number of words contained in tweets.
Inthe following section we present and compare thedifferent approaches we propose for dealing withthis problem.4 Clustering Company TweetsThe purpose of this research work is to cluster tweetsthat contain a possible company entity into two148groups, those that refer to the company and thosethat refer to a different topic.
We approach thisproblem by introducing and, thereafter, evaluatingtwo different methodologies that use term expan-sion.
The term expansion of a set of documents is aprocess for enriching the semantic similarity hiddenbehind the lexical structure.
Although the idea hasbeen previously studied in literature (Qiu and Frei,1993; Grefenstette, 1994; Banerjee and Pedersen,2002; Pinto et al, 2010) we are not aware of anywork in which has applied it to microblog texts.
Inthis paper, we evaluate the performance of two dif-ferent approaches for term enriching in the task ofclustering company tweets.In order to establish the difficulty of clusteringcompany tweets, we split the 20 companies groupinto two groups that we hypothetically consideredeasier and harder to be clustered.
The first groupis composed of 10 companies with generic names,i.e., names that can be ambiguous (i.e., they have an-other common meaning and appear in a dictionary).The second group contains specific names which areconsidered to be less ambiguous (words that can beused in limited number of contexts or words that donot appear in a dictionary).
We expect the lattergroup will be easier to be categorised than the for-mer one.
In Table 3 we see the distribution of thetwo groups.
We have selected the K-means cluster-Table 3: Types of Company namesGeneric Company NamesBestBuy Borders Delta FordLeapfrog Opera Overstock PalmSouthwest SprintSpecific Company NamesArmani Barclays Bayer BlockbusterCadillac Harpers Mandalay MgmLennar Warnering method (MacQueen, 1967) for the experimentscarried out in this paper.
The reason is that it is awell-known method, it produces acceptable resultsand our approaches may be compared with futureimplementations.
The clustering algorithm (includ-ing the representation and matrix calculation) is ap-plied after we have improved the representation oftweets in order to show the improvement gained byapplying the enriching process.Figure 1: Full Term Expansion Methodology4.1 Full Term Expansion Methodology(TEM-Full)In this methodology we expand only the ambiguousword (the company name) with all the words that co-occur alongside it, without restrictions for the levelof co-occurrence.
Our hypothesis states that theambiguous words may bring important informationfrom the identification of co-occurrence-relations tothe next step of filtering relevant terms.
It is impor-tant to mention that we have used the Term Selectiontechnique in order to select the most discriminativeterms for the categories.
The process is shown inFigure 1.
Note that this expansion process does notuse an external resource.
We believe that due to thelow term frequency and the shortness of the data, itis better to include all the information that co-occursin the corpus of a company and provide more infor-mation to the enriching process.The Term Selection Technique helps us to identifythe best features for the clustering process.
How-ever, it is also useful to reduce the computing timeof the clustering algorithms.4.2 Full Tem Expansion Methodology with aText Formaliser (TEM-Full+F)In this approach, we test the hypothesis that we canimprove the cluster quality by increasing the levelof formality in the document text.
Due to the lengthrestriction of 140 characters users tend to write com-ments using abbreviations.
We have used an ab-breviation dictionary7 that contains 5,173 abbrevi-ations commonly used in microblogs, tweets andshort messages.
After the formalisation step, the ex-pansion is performed but it is only applied to theambiguous word (the company name) and words7http://noslang.com/dictionary149Figure 2: Full Term Expansion Methodology with a TextFormaliser (TEM-Full+F)which highly co-occur with it.
These words wereselected as they appear in frequently with the am-biguous word in positive tweets (i.e., those relatedto the companies).
We consider that this kind ofword may help us take the correct decision duringthe clustering process because they are highly re-lated with the company tweets.
The words selectedto be expanded were closely related to the companysuch as crew, jet, flight, airlines, airplane for Deltacompany name.
In the case of the Opera companyname the words expanded were software, technol-ogy, developers, interface, web, browser.
The num-ber of words per company name were between fiveand ten, showing that even a small number of wordsthat co-occur highly may help in the enriching pro-cess.
We have used the Term Selection Techniqueas described in 4.1 and no external resource.
Theprocess is shown in Figure 2.5 Experimental ResultsIn this section we present the results obtain by therelated approaches and also the results obtained byour methodologies proposed.5.1 Related ApproachesAlthough the results are not directly comparablewith our approaches due to the slightly differentdataset used in the experiments (see Section 3), wewould like to provide a clear description of the dif-ferent approaches with the objective of highlight thestrengths of the related approaches developed forthis purpose.In Table 4, the best results (F-measure relatedclasses) reported by the approaches presented tothe task two of the WePS-3 evaluation campaignTable 4: Related approaches (F-measure related)ApproachesL S I U K0.74 0.36 0.51 0.36 0.47L = LSIR-EPFL, S = SINAI, I = ITC-UT,U = UVA, K = KALMAR(Amigo?
et al, 2010).
It is important to mention thatall these systems used the whole collection even ifthe companies subsets where very imbalanced.
Inour case, we are interested in proposing approachesthat can deal with two different kind of companynames such as ?generic?
and ?specific?
rather thanone methodology for both.In Table 4 the LSIR-EPFL system (Yerva et al,2010) showed very good performance even whenthe subsets are very imbalanced.
The SINAI sys-tem (Garc?
?a-Cumbreras et al, 2010) took advan-tage of the entity recognition process and they re-port that named entities contained in the microblogdocuments seem to be appropriate for certain com-pany names.
ITC-UT (Yoshida et al, 2010) incor-porated a classifier and made use of Named EntityRecognition and Part-of-Speech tagger is also goodin their performance but as the authors in (Amigo?et al, 2010) have mentioned ?it is difficult to knowwhat aspect lead the system to get ahead other sys-tems?
as each takes advantage of different aspectsavailable such as external resources or tools.
UVA(Tsagkias and Balog, 2010) is an interesting contri-bution but the only problem is training data will notalways be available for some domains.
Finally, theKALMAR system (Kalmar, 2010) seems to achievegood performance when applied to well-balancedcollections.
In contrast to these approaches, wewould like to emphasize that our approaches are pre-dominantly based on the information to be clustered.5.2 Results of Our ExperimentsIn order to present the performance of the differentproposed approaches, we have calculated a baselinebased on clustering, with K-means, and with no en-riching procedure.
The obtained results using thetwo methodologies are compared in Table 5.
Wehave shown in bold text the cases in which the resultequalled or improved upon the baseline.
We havecompared the methodologies presented with the two150subsets (generic and specific company names sub-sets) described previously.Table 5: A comparison of each methodology with respectto one baseline using the F -measure.Company MethodologiesTEM-Full TEM-Full+F BGeneric Company Names SubsetBestbuy 0.74 0.75 0.62Borders 0.73 0.72 0.60Delta 0.71 0.70 0.61Ford 0.67 0.65 0.64Leapfrog 0.71 0.63 0.63Opera 0.73 0.74 0.70Overstock 0.66 0.72 0.58Palm 0.72 0.70 0.62Southwest 0.67 0.72 0.64Sprint 0.67 0.65 0.64Average 0.70 0.69 0.62Specific Company Names SubsetArmani 0.73 0.70 0.62Barclays 0.72 0.72 0.55Bayer 0.71 0.70 0.63Blockbuster 0.71 0.71 0.66Cadillac 0.69 0.69 0.61Harpers 0.68 0.68 0.63Mandalay 0.74 0.84 0.64Mgm 0.54 0.75 0.69Lennar 0.72 0.97 0.96Warner 0.54 0.67 0.67Average 0.67 0.74 0.66OA 0.68 0.72 0.64B - Baseline, OA - Overall AverageWe consider that there still some limitations onobtaining improved results due to the particular writ-ing style of tweets.
The corpus exhibits a poorgrammatical structure and many out-of-vocabularywords, a fact that makes the task of clustering tweetsvery difficult.
There is, however, a clear improve-ment in most cases in comparison with the baseline.This indicates that the enriching procedure yieldsbenefits for the clustering process.The TEM-Full methodology has demonstratedgood performance with the corpus of generic com-pany names with 0.70 average (F-measure value) 8points over the average baseline.
In this case, wehave expanded only the ambiguous word (the nameof the company), whereas the TEM-Full+F method-ologies performed well (0.74 F-measure) with thecorpus of specific company names.
We have ob-served that, regardless of whether or not we areusing an external resource in TEM-Full and TEM-Full+F approaches, we may improve the representa-tion of company tweets for the clustering task.
Itis important to mention that the good results pre-sented in companies such as Bestbuy or Lennarwere obtained because the low overlapping vocabu-lary between the two categories (positive and neg-ative) and, therefore, the clustering process couldfind well-delimited groups.
We also would like tonote that sometimes the methodologies have pro-duced only minor performance improvement.
Thiswe believe is largely due to the length of the tweets,as it has been demonstrated in other experiments thatbetter results can be achieved with longer documents(Perez-Tellez et al, 2009; Pinto et al, 2010).The best result has been achieved with the TEM-Full+F methodology which achieved an overall av-erage F-measure value 0.72, it is 8 points more thanthe overall average of the baseline.
This methodol-ogy has not disimproved on the baseline in any in-stance and it produces good results in most cases.Although the term expansion procedure has beenshown to be effective for improving the task of clus-tering company tweets, we believe that there is stillroom for improving the obtained F -Measure valuesby detecting and filtering stronger relations that mayhelp in the identification of the positive companytweets.
This fact may lead us to consider that re-gardless of the resource used (internal or external),the clustering company tweets is a very difficult task.6 ConclusionsClustering short text corpora is a difficult task.
Sincetweets are by definition short texts (having a maxi-mum of 140 characters), the clustering of tweets isalso a challenging problem as stronger results typ-ically achieved with longer text documents.
Fur-thermore, due to the nature of writing style of thesekinds of texts - typically they exhibits an informalwriting style, with poor grammatical structure andmany out of vocabulary words - this kind of datatypically causes most clustering methods to obtainpoor performance.The main contribution of this paper has been topropose and compare two different approaches forrepresenting tweets on the basis term expansion andtheir impact on the problem of clustering company151tweets.
In particular, we introduced two methodolo-gies for enriching term representation of tweets.
Weexpected that these different representations wouldlead classical clustering methods, such as K-means,to obtain a better performance than when clusteringthe same data set and the enriching methodology isnot applied.We consider that TEM-Full performed well onthe former data set and, another methodology ob-tained the best results on the latter data set TEM-Full+F.
However, the TEM-Full+F methodologyappears suitable for both kinds of corpora, anddoes not require any external resource.
TEM-Fulland TEM-Full+F are completely unsupervised ap-proaches which construct a thesaurus from the samedata set to be clustered and, thereafter, uses this re-source for enriching the terms.
On the basis of theresults presented, we can say that using this par-ticular data, the unsupervised methodology TEM-Full+F has shown improved results.This paper has reported on our efforts to ap-ply clustering and term enrichment to the importantproblem of company identification in microblogs.We expect to do further work in proposing highlyscalable methods that may be able to deal with thehuge amounts of information published every day inTwitter.AcknowledgmentsThis work was carried out in the frameworkof the MICINN Text-Enterprise TIN2009-13391-C04-03 research project and the MicroclusterVLC/Campus (International Campus of Excel-lence) on Multimodal Intelligent Systems, PROMEP#103.5/09/4213 and CONACYT #106625, as wellas a grant provided by the Mexican Council of Sci-ence and Technology (CONACYT).ReferencesE.
Amigo?, J. Artiles, J. Gonzalo, D. Spina, B. Liu, andA.
Corujo.
2010.
WePS-3 evaluation campaign:Overview of the online reputation management task.In CLEF 2010 (Notebook Papers/LABs/Workshops).S.
Banerjee and T. Pedersen.
2002.
An adapted lesk al-gorithm for word sense disambiguation using wordnet.In Proc.
of the CICLing 2002 Conf., pages 136?145.LNCS Springer-Verlag.M.
A.
Garc?
?a-Cumbreras, M.
Garc?
?a Vega, F.
Mart?
?nezSantiago, and J. M. Perea-Ortega.
2010.
Sinai atweps-3: Online reputation management.
In CLEF2010 (Notebook Papers/LABs/Workshops).G.
Grefenstette.
1994.
Explorations in Automatic The-saurus Discovery.
Kluwer Ac.P.
Kalmar.
2010.
Bootstrapping websites for classifica-tion of organization names on twitter.
In CLEF 2010(Notebook Papers/LABs/Workshops).J.B.
MacQueen.
1967.
Some methods for classificationand analysis of multivariate observations.
In Proc.
ofthe 5th Berkeley Symposium on Mathematical Statis-tics and Probability, pages 281?297.
University ofCalifornia Press.S.
Milstein, A. Chowdhury, G. Hochmuth, B. Lorica,and R. Magoulas.
2008.
Twitter and the micro-messaging revolution: Communication, connections,and immediacy-140 characters at a time.
O?ReallyReport.F.
Perez-Tellez, D. Pinto, Cardiff J., and P. Rosso.
2009.Improving the clustering of blogosphere with a self-term enriching technique.
In Proc.
of the 12th Int.Conf.
on Text, Speech and Dialogue, pages 40?49.LNAI.D.
Pinto, P. Rosso, and H. Jimenez.
2010.A self-enriching methodology for clustering nar-row domain short texts.
The Computer Journal,doi:10.1093/comjnl/bxq069.Y.
Qiu and H.P.
Frei.
1993.
Concept based query ex-pansion.
In Proc.
of the 16th Annual Int.
ACM SIGIRConf.
on Research and Development in InformationRetrieval, pages 160?169.
ACM.J.
Sankaranarayanan, H. Samet, B.E.
Teitler, M.D.Lieberman, and J. Sperling.
2009.
Twitterstand: newsin tweets.
In Proc.
of the 17th ACM SIGSPATIAL Int.Conf.
on Advances in Geographic Information Sys-tems, pages 42?51.
ACM.B.
Sriram, D. Fuhry, E. Demir, and H. Ferhatosmanoglu.2010.
Short text classification in twitter to improve in-formation filtering.
In The 33rd ACM SIGIR?10 Conf.,pages 42?51.
ACM.M.
Tsagkias and K. Balog.
2010.
The university ofamsterdam at weps3.
In CLEF 2010 (Notebook Pa-pers/LABs/Workshops).C.J.
van Rijsbergen.
1979.
Information Retrieval.
But-terworths, London.S.
R. Yerva, Z. Miklo?s, and K. Aberer.
2010.
It waseasy, when apples and blackberries were only fruits.In CLEF 2010 (Notebook Papers/LABs/Workshops).M.
Yoshida, S. Matsushima, S. Ono, I. Sato, and H. Nak-agawa.
2010.
Itc-ut: Tweet categorization by querycategorization for on-line reputation management.
InCLEF (Notebook Papers/LABs/Workshops).152
