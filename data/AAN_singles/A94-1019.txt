Recycl ing Terms into a Part ial  ParserChristian JacqueminInstitut de Recherche n Informatique de Nantes (IRIN)IUT de Nantes3, rue du Mar6chal JoffreF-44041 NANTES Cedex 01 - FRANCEjaequemin @ irin.iut-nantos.univ-nantos.frAbstractBoth full-text information retrieval and large scaleparsing require text preprocessing to identifystrong lexical associations in textual databases.
Inorder to associate linguistic felicity withcomputational efficiency, we have conceivedFASTR a unification-based parser supportinglarge textual and grammatical databases.
Thegrammar is composed of term rules obtained bytagging and lemmatizing term lists with an on-line dictionary.
Through FASTR,  largeterminological data can be recycled for textprocessing purposes.
Great stress is placed on thehandling of term variations through metaruleswhich relate basic terms to their semanticallyclose morphosyntactic variants.The quality of terminological extraction andthe computational efficiency of FASTR areevaluated through a joint experiment with anindustrial documentation center.
The processingof two large technical corpora shows that theapplication is scalable to such industrial data andthat accounting for term variants results in anincrease of recall by 20%.Although automatic indexing is the moststraightforward application of FASTR, it can beextended fruitfully to terminological cquisitionand compound interpretation.IntroductionLarge terminological databases are now available and canbe used as lexicons in Natural Language Processing(NLP) systems aimed at terminology extraction.
InFASTR term lists are transformed into large lexicalizedgrammars and are parsed with a robust andcomputationally tractable unification-based parser.
Ourmethod contrasts with pattern-matching techniques byoffering an expressive and convenient descriptiveframework.
It also differs from a general multipurposeparser by an ability to recycle linguistic knowledgeembodied in terminological data.
Higher quality interminological extraction is achieved thanks to adescription of term variations.Areas of application using such a tool forterminology extraction include automatic indexingthrough an assignment of text pointers to thesaurusentries, knowledge acquisition form textual databases,noun phrase structural disambiguation and machinetranslation with a specific concern for the translation ofidioms, compounds and terms.When designing any NLP system with largelinguistic resources, there is tension between tractabilityand descriptive power.
Finite state automata are efficienttools for lexical extraction.
But their lack of conveniencefor information description makes the testing of differentmethodological choices difficult.
Such a limitation isspecifically problematic during the development s age.Symmetrically, unification-based parsers offer rich andconceptual ly tractable formalisms, but theircomputational cost is very high.
The approach taken inFASTR is to use a convenient grammatical descriptionstemming from PATR-H (Shieber 1986) associated withan optimized computational engine.
Efficiency andconstraint-based grammar formalism have motivated theacronym of the application (FAST + PATR-H) thatstands for FAST TERM RECOGNIZER.When terminology extraction is applied to automaticindexing, two measures are important: recall andprecision.
Precision is crucial for applications usingacquisition methods which are subject o an excessiverecall, blurring terminological entries with syntacticrecurrences or semantic preferences.
Conversely, in aknowledge-based method like FASTR, recall is adecisive valuation of the coverage of the extraction.
Therecall rate mainly depends on the ability of the processorto extract term occurrences which differ from theirdescription i  the terminological base.
With the purposeof enhancing the recall rate, FASTR includes ametagrammar used to generate term variant rules fromterm rules.
Such an addition of robustness does notentail a degradation of precision because variations arerestricted to a "safe" window bordered by the termcomponents.The formalism of FASTR is organized into threelevels : a single word lexicon, a terminological grammarand a metagrammar for term variations.
Theinitialization of FASTR consists of the description ofthe inflectional system of the language under study, thegeneration of a lexicon and a grammar from a list ofterms with an on-line lexicon and the handcraftedcreation of a set of paradigmatic metarules (about ahundred) which are refmed according to the experimentalresults.113Processing in FASTR starts with segmentation andstemming.
During stemming, a few term rules areactivated through a bottom-up filtering.
Then, metarulesare applied to these rules and yield transformed rules usedto extract erms and their variants.
For example, fromthe preceding sentence and from a grammar includingterm variant, the sequence terms and their variants wouldbe extracted as a variation of term variant.
The datarequired by FASTR consist of a declension file, aninitial terminological database and an on-line dictionaryto transform terms into compilable linguistic data.
Asfar as human time is concerned, only a slightexperimental tuning of the metarules i necessary.A Three-tier FormalismThe formalism of FASTR stems from PATR-H (Shieber1986).
Rules are composed of a context-free portiondescribing the concatenation f the constituents and a setof equations constraining information of theseconstituents.The description of a single word includes minimallythe string of the word stem, a part-of-speech ategory andits inflection number.
These three values are used todynamically rebuild the different inflections of the word.They are automatically extracted from an on-linedictionary with morphological information.
We currentlyuse the DELAS dictionary of LADL laboratory(University of Paris 7).
For example, rule (1) describesthe noun ray, plural rays.
(1) Word : 'ray'<cat> = 'N'<inflection> = 1.Terms are described by grammar rules.
Theformalism of PATR-H has been extended to support suchadditional facilities as rules with an extended omain oflocality, structure disjunction and negative atomicvalues.
Rule (2) represents he term IX ray\] diffraction.This rule localizes the embedded structure X ray.
Lexicalanchors, indicated by the value of the featurelexicallzation, are used prior to the parsing phase for aselective bottom-up activation of the rules.
For example,rule (2) is anchored to diffraction and is activated whenthis word is encountered in the input sentence.
(2) Rule : NI ---> (N2 ---> N3 N4) N 5<N I label> = 'XRD'<N I metaLabel> = 'XX'<N I lexicalization> = 'Ns'<N 3 lenuna> = 'X'<N 3 inflection> = 7<N 4 lemma> = 'ray'<N 4 inflection> = I<Ns lemma> = 'diffraction'<N5 inflection> = I.The third level of the formalism consists of ametagrammar.
Metarules are composed of two context-free descriptions : the source and the target and a set ofequations constraining them.
Information shared by thesource and the target is embodied by identical symbols.For example, metarule (3) describes a coordination of atwo-constituent term inserting a conjunction (except but)and a word (except a definite or indefinite determiner)between both constituents.
When applied to rule (2), itoutputs a novel rule which accepts X ray or neutrondiffraction as a variant of X ray diffraction.
(3) Metarule : Coor{X 1 --> X 2 X 3)= X I --~ X 2 C 3 X 4 X 3 "'C' = conjunction "<X 1 metaLabel> = 'XX'"<Ca lemma> 1'but .
.
.
.
I denotes inequality"'<X 4 cat> I 'Dd .
.
.
.
Dd'= definite determiner"<X4 cat> I 'Di'.
"'Di'= indefinite determiner"ParsingMorphologyFASTR has been applied to the French and the Englishlanguages and can be easily extended to any languagewithout word agglutination thanks to an externaldescription of morphology.
The suffix strippingoperation precedes yntactic analysis and requires adictionary of lemmas and a declension file (Savoy 1993).Each entry in the dictionary has a basic stem and wordswith an irregular inflectional morphology such asmouse/mice have one or more auxiliary stems.Derivational links such as synapselsynaptic can also beaccounted for through multi-valued part-of-speechcategories such as noun-adjective.
The declension file isillustrated by formulae (4) and (5).
A set of features isprovided for each inflectional case of each inflectedcategory (e.g.
(4) for nouns).
A list of suffixescorresponds toeach declension class (e.g.
(5) for the fn'sttwo classes of nouns).
?
1 indicates the first auxiliarystem.
The inflection class of a word is denoted by thevalue of the feature inflection in word rule (1) and termrule (2)."
The two cases of nouns "(4) N\[ 1 1 <number> = 'singular'.N\[ 2 1 <number> = 'plural'."
dog/dog-s  (stem dog) "(5) N\[ 1 \] 0 s" mouse /mice  (stem mouse, aux.
s tem mice) "N!
2 \] 0 ?1In order to prepare suffix stripping, a generalizedlexicographic tree is built form the whole set of thereversed suffixes of the current language.
Each inflectedword is also reversed and all its endings corresponding toan actual suffix are removed.
The corresponding stemsare looked for in the dictionary.
If one of their inflectionsis equal to the current inflected word, the featuresassociated with the declension case are unified with thefeatures of the lemma and attached to the inflected word.Thus, the morphological stemmer associates all itshomographic nflections to an inflected word.114The term rules whose lexical anchor is equal to oneof the lemmas in the input are activated and processed bya top-down algorithm.
In order to ensure short parsingtimes, unification is delayed until rewriting is achieved.Whenever a rule fails to be parsed, it is repeatedly triedagain on its variants generated by metarules.Term syntax and local syntaxMetarules can be straightforwardly described byembedding the formalism into a logical framework whererule generation by metarules is calculated throughunification.
With this aim in mind, the definitions ofterm rules and metarules given in the preceding part canbe transformed into logical (in)equations by using theformulae of Kasper and Rounds (1986).
As in (Vijay-Shanker 1992), type variables whose denotations are setsof structures derived from non-terminals can be replacedby monoadic predicates.
Individual variables that standfor individual feature structures are used to capturereentrance.
For example, rule (2) is translated intoformula (6).
A monoadic predicate ar i ty  is added torestrict he application of metarules.
(6) XRD(x) ca cat(x) = 'N' ^  arlty(x) = 2^ lexicallzation(x) =x4 ^  metaLabel(x) = 'XX'^ l (x) = x I ^ cat(xl) = 'N' ^  arity(xl) --- 2^ 1 (x I) --- x 2 A 2(XI) ----- X 3 ^  cat(x2) = 'N'^ lemma(x 2) = 'X' ^  inflection(x2) = I^ cat(x 3) = 'N'A lemma(x3) = 'ray'^ inflection(x 3) = I ^ 2(x) = x 4 ^  cat(x4) = 'N'^ lemma(x 4) --- 'diffraction'  ^ inflectlon(x4) = IStandard fixed-point semantics is associated to this syn-tax which is used to calculate the interpretation of  suchformulae.
The denotation of a formula is an automatoncalculated through an inductive interpretation of  theterms it contains (Rounds and Manaster-Ramer 1987).As a consequence of this mathematical formulation, themetarules are expressed as couples of  monoadicpredicates with shared variables, For example, themetanfle of coordination (3) is described by formula (7).The syntax of both sides of  the metarule is identical tothe syntax of rules except for the monoadic rule predicatep which is a variable.
-, stands for negation.
(7) Coor(p(y) ca arity(y)-2  ^  I (y) = Yl ^ 2(y) = Y2)= (Coot(p) (y) ca  arity(y) = 4 ^ l(y) = Yl^ 2(y) ~- Y3 A 3(y) = Y4 ^  4(y) = Y2^ cat(y 3) = 'C' ^  -~(lemma(y4) -- 'but')^ -~(cat(y4) = 'Di') ^  -,(cat(y 4) = 'Dd') )The result of the application of  a metarule to a rule iscalculated in two steps.
Firstly, the left-hand-side of themetarule is unified with the rule.
If unification falls, nooutput rule is generated.
Otherwise, let ?~ be thesubstitution providing the unification.
Then, the formulaof the transformed rule is equal to the right-hand-side ofthe metarule, where the variables are substitutedaccording to s .
The computational implementation isstraightforwardly derived from this calculus.
Forexample, metarule (7) applies to rule (6) with thesubstitution ct (8) and yields the transformed rule (9)whose PATR-H expression is (10).
(8) ~ -= \[y = x, XRD / p, x I = Yl, x4 = Y2I(9) Coor(XRD)(x) ca  cat(x) --- 'N' ^  arlty(x) --- 4A lexlcaIlzation(x) =x 4 A metaLabel(x) --- 'XX'^ l(x) = x I ^ cat(xl) = 'N' ^  arlty(x I) = 2^ l (Xl) = x2 ^  2(Xl) = x3 ^  cat(x2) = 'N'^ lemma(x 2) = 'X' ^  inflection(x2) = I^ cat(x3} = 'N '^ lemma(x3) = 'ray'A inflection(x3) = I ^ 4(x) = x4 ^  cat(x4) = 'N'^ lemma(x4) = 'diffraction'  ^ Inflection(x4) - I^ 2(y) = Y3 ^ 3(y) = Y4 ^ cat(y3) = 'C'(I0) Rule : NI ---> (N2 ---> N3 N4) C6 N7 N s<NI label> = 'Coor(XRD)'<N l metaLabel> = 'XX'<N I lexicallzation> = 'N 5'<N 3 lernma> = 'X'<N 3 inflection> = l<N4 lemma> = 'ray'<N 4 inflection> = I<N s lemma> = 'diffraction'<N 5 inflection> = I.The mapping performed by the metarules in FASTRdiffers from the definition of  metarules in GPSG (Gazdaret al 1985) on the following points :?
The matching of the input rule and the source isreplaced by their unification.
The correspondencebetween source and target is achieved by identicalvariables hared by both sides of  the metarule.?
In GPSG, when input rule and target disagree aboutthe value of some feature, the target alays wins.
InFASTR, the target wins if its value for this feature isindependent of  its source.
Conversely, ff source andtarget share this value, the unification of  the sourceand the rule falls and no output is provided.?
The metavariable W used in GPSG and standing for aset of  categories is not available in FASTR.However, an empty category in the context-freeskeleton can stand for any subtree of  the originalrule.
Thus, variable Yl from metarule (7), associatedto X 2 in formula (3), stands for the subterm X raywhen applied to rule (6).When implementing metarules in a grammar parser,there are two possibilities for the time to apply themetarules to a rule.
The compi le - t ime applicationcalculates all the images of  all the rules in the grammarprior to parsing.
In the run-time approach, metarules aredynamically applied to the active rules during parsing.Weisweber and Preu6 (1992) demonstrate hat there is nodifference in complexity between both approaches.Moreover, in the compile-time approach, metarulesgenerate a huge set of transformed rules which may makethe parsing process totally inefficient.
Due to the verylarge size of  our grammar, we have opted for thedynamic approach.
The computational performances ofthe application reported in (Jacquemin 1994a) indicatethat the parser only spends 10% of its time in generatingmetarules and fully justify the run-time approach.115Computational LexicalizationThe keystone of the computational tractability islexicalization which allows for a bottom-up filtering ofthe rules before parsing.
It is completed by fastmechanisms for data access uch as a B-Tree (for the diskresident lexicon of single words) and a Hash-Code table(for the memory resident stop words).The formalism of FASTR is lexicalized in the senseof Schabes and Joshi (1990) because it is composed ofrules associated with each lexical item which is theanchor of the corresponding rules.
The parsing algorithmfor lexicalized grammars takes advantage of lexicalizationthrough a two-step strategy.
The first step is a selectionof the rules linked to the lexical items in the input.
Thesecond step parses the input with a grammar restricted tothe filtered rules.
In case of rules with multiple lexicalitems such as the rules representing multi-word terms,the anchor can be any of the lexical items.
For example,the term aortic disease can be anchored either to aortic orto disease.
In Jacquemin (1994b), an algorithm foroptimizing the determination of computational nchorsis described.
It yields a uniform distribution of the ruleson to the lexical items with respect to a given weightingfunction.
A comparison between the "natural"lexicalization on the head nouns and the optimized onehas been made with FASTR.
It shows that the rulesfiltered by the optimized lexicalization represent only57% of the rules selected by the natural lexicalizationand ensure a2.6-time higher parsing speed.The computational performances of parsing withFASTR mainly depend on the size of the grammar (seeFigure 1).
The parsing speed with a 71,623-ruleterminological grammar, a 38,536-word lexicon and 110metarules is 2,562 words/minute on a Sparc 2workstation (real time), As 71,623 terms is a reasonablesize for a real-word multi-domain list of terms (forexample WordNet currently includes 35,155 synonymssets), a workstation is well-suited for processing largecorpora with such terminological databases.documentation center INIST/CNRS : a 118,563-wordcorpus on metallurgy \[METAL\] and a 1.5-million wordmedical corpus \[MEDIC\].
The laboratory ofINIST/CNRS has achieved tagging and lemmatization fterms and has evaluated the results of the indexingprovided by FASTR.In this experiment, he metagrammar consists ofpositive paradigmatic metarules (e.g.
(11)) and filteringnegative metarules rejecting the spurious variationsextracted by the positive ones (e.g.
(12)).
Examples ofvariations from \[MEDIC\] accepted by (11) or rejected by(12) are shown in Figure 2.
(11) Metarule Coor( Xl ---> X2 X3 )=x, -~x~.
c~ x4 x3<X l metaLabel> = 'XX'.
(12) Metarule NegCoor( Xi ---> X2 X3 )= x ,  ~ x2 c3 x4 xs<Xi metaLabel> = 'XX'<X4 cat> = 'P .
.
.
.
P' = preposition"<X 4 cat> = 'Dd'<X 4 cat> = 'Di'.Variations accepted by (11)mechanical nd enzymatic methodsDown and Williams syndromesamplitude and frequency modulationsNorthern and Western blottingVariations rejected by (12)relaxation and the timesatellite and whole chromosomecells or after culturetissue or a factorFigure 2.
Antagonist description of variations13-0100,00030,00020,00010,0003,0002,0001,000 i i i I i i0 20,000 40,000 60,000 80,000Number of terms (in the grammar)Figure 1.
Parsing speed of FASTR (Sparc 2, real time)Application to Automatic IndexingA list of 71,623 multi-domain terms and two corpora ofscientific abstracts have been provided by theNegative metarules are used instead of negativeconstraints such as the ones stated in (3) to keep a traceof the rejected variations.
More details about thisdescription are reported in (Jacquemin and Royaut61994).
An evaluation of terminology extraction oncorpus \[METAL\] indicates that term variations represent16.7% of multi-word term occurrences extracted byFASTR (an account for term variants increases recall by20%).
The three kinds of variants retrieved throughmetarules are coordinations (2%), modifier insertions(8.3%) and permutations (6.4%).
See Figure 3 forexamples.
Elisions such as Kerrr ma~netoootical effect---> Kerr effect are not accounted for because our localapproach to variation is not appropriate to ellipticreferences.
In this framework, FASTR retrieves 74.9%of the term variants with a precision of 86.7%.
Theseresults confirm the substantial gain in recall obtained byaccounting for term variants in automatic indexing.
A11~,better precision could be reached through amore accuratedescription of permutation.
An improvement in termvariant recall requires the handling of elision.Rela ted  WorkFirstly, our formalism is inspired by two fields oflexicalized and logical tree formalisms.
The f'n'st one isthe general framework of Lexicalized Tree AdjoiningGrammar (LTAG) which has shown to be fruitful for thedescription of idioms (Abeill6 and Schabes 1989).
Thesecond one is the important extension of Tree AdjoiningGrammar (TAG) to a logical framework (Vijay-Shanker1992) which contrasts with the traditional approach thatoperations in a TAG combine trees.
From these works,we have adopted the constraint of LTAG which statesthat rules must have at least one lexical frontier nodetogether with the logical representation f Vijay-Shanker(1992) where rules are not restricted to immediatedependency.
The lexicalized tree grammar is motivatedby the domain to be described : terms mainly consist ofcompounds with an internal structure and lexicalconstituents.
The logical formalism provides us with astraightforward extension to metandes.Secondly, our approach to text processing is a formof partial parsing.
A current rend in large scale NLPsystem (Jacobs 1992) refuses to consider parsing as anexhaustive derivation of a very large grammar whichwould process any encountered sentence.
To alleviatethese problems parsing should be planned as thecooperation of several methods such as textpreprocessing, parsing by chunks, multiple-step partialparsing, shallow parsing.., etc.
The scope of thepreprocessing task is "abstract\[ing\] idiosyncrasies,highlight\[ing\] regularities, and, in general feed\[ing\]digested text into the unification parser" (Zernik 1992).With this aim in mind FASTR brings forth occurrencesof complex lexical entries and their local variations.
It isadapted to integration i  a multi-step arsing strategy.
Ittakes as input a raw corpus and yields chunkscorresponding to partial parses.
This output can be fedinto a following module or reprocessed with moreprecise metarules.Thirdly, our research on term extraction places greatstress on term variations.
The most direct precursors ofthe use of term variation in information retrieval areSparck Jones and Tait (1984).
These authors advocate thesystematic generation of syntactic term variants in queryprocessing.
Their approach, however, makes theassumption that only semantic equivalent variant shouldbe generated and that each of the words in a variantshould be given instead of allowing paradignmtic places.They only account for restricted associations such asinformation retrieval/retrieval of information.Strzalkowski and Vauthey (1992) follow the waysuggested by Sparck Jones and Tait (1984) at the end oftheir paper.
Instead of generating term variants in aquery, they look for different erm occurrences in textdocuments analyzed by a general multipurpose parser.Their parse trees are composed of head/modifier relationsof four categories.
These four classes account for most ofthe syntactic variants of two-word terms into pairs withcompatible semantic content such as informationretrieval/information retrieval system~retrieval ofinformation from databases... We think however thatmost of these variants can be extracted without parsingthe whole sentence.
They can be detected safely througha local parse with a noun-phrase micro-syntax.Extens ions  and  Conc lus ionAlthough applied straightforwardly to automaticindexing, FASTR can be extended to terminologyacquisition through a bootstrapping method where newterms are acquired by observing the variations ofcontrolled terms in corpora.
Figure 3 reports fouroccurrences of term variants retrieved through threemetarules belonging to three different families.
Each ofthese occurrences yields a novel candidate term whicheither already belongs to the terminology or can be addedafter validation.A second extension of FASTR concerns acquisitionof noun phrase interpretation from a corpus.
Observationof variation is an opportunity to find objective linguisticclues which denote the semantic relation between bothwords of a binominal compound.
For example, cell intoa metastatic tumor is a permutation of tumor cellinvolving the preposition into.
Figure 4 lists four Ncell terms for which more than four permutations cellPrep X N have been encountered in corpus \[MEDIC\].The prepositions found in more than one permutation arefollowed by their number of occurrences.
For example,the prepositions encountered in the permutations ofblood cell are from, in, into and on.
These fourprepositions denote a relation of spatial inclusion of atrajector cell into a landmark blood (Langacker 1987).Term Variation Candidate termwater absorptionCentraI Africacontrolled eliverymagnetic ouplinginformation accesswave effectwater and sodium absorption (coordination)Central and West Africa (coordination)controlled rug delivery (insertion)magnetic transcutaneous coupling (insertion)access to lexical information (permutation)effect of short wave (permutation)sodium absorptionWestAfricadrug deliverytranscutaneous couplinglexical informationshort waveFigure 3.
Acquisition of candidate terms through variation117Term PrepositionsMembrane cell in \[4\], into, toMyeloid cell of \[3\], fromBlood cell from \[8\], in \[13\], into, onTumor cell in \[3\], from \[4\], into, with, ofFigure 4.
Noun phrase interpretation through variationAlthough initially devised for automatic indexing,FASTR can play a crucial role in other text-basedintelligent tasks.
This part has sketched out a picture ofincremental terminological cquisition and noun-phraseunderstanding through the analysis of term variants.As Resnik (1993) points out, large-scale knowledgesources can be used as a source of lexical information.Similarly, our approach to corpus linguistics makes aextensive use of terminological data and investigatessystematically and precisely the variations of terms intechnical corpora.
The next natural step in term andcompound processing is to provide FASTR with alearning ability.
With this aim in mind, we are currentlyinvestigating two novel research directions : firstly, ahybridisation of FASTR with a connectionist modeldedicated to nominal composition (Jacquemin 1993) and,secondly, a cooperation between FASTR and LEXTER(Bourigault 1993) a tool for term acquisition through thefiltering of part-of-speech patterns.AcknowledgementI would like to thank Jean Royaut6 from INIST/CNRSfor his helpful and friendly collaboration on this project.Many thanks also to Benoit Habert from ENS Fontenayfor numerous constructive discussions.ReferencesAbeill6, Anne and Yves Schabes.
1989.
Parsing Idiomsin Lexicalized Tags.
In Proceedings, 4th Conference ofthe European Chapter of the Association forComputational Linguistics (EACL'89), Manchester, June1989, 1-9.Bourigault, Didier.
1993.
An Endogeneous Corpus-Based Method for Structural Noun PhraseDisambiguation.
I  Proceedings, 6th European Chapter ofthe Association for Computational Linguistics(EACL'93), Utrecht, June 1993.Gazdar, Gerald, Ewan Klein, Geoffrey Pullum, IvanSag.
1985.
Generalized Phrase Structure Grammar,Oxford : Blackwell.Jacobs, Paul S. (edt).
1992.
Text-based Intelligentsystems, Current Research and Practice in InformationExtraction and Retrieval.
Hillsdale :Lawrence Erlbaum.Jacquemin, Christian.
1993.
A Coincidence DetectionNetwork for Spatio-Temporal Coding: Application toNominal Composition.
In Proceedings, 13th InternationalJoint Conference on Artificial Intelligence (IJCAI'93),Chamb6ry, August 1993, 1346-1351.Jacquemin, Christian.
1994a.
FASTR : A unificationgrammar and a parser for terminology extraction fromlarge corpora.
In Proceedings, IA-94, Paris, June 1994.Jacquemin, Christian.
1994b.
Optimizing thecomputational lexicalization of large grammars.
InProceedings, 32nd Annual Meeting of the Association forComputational Linguistics, Las Cruces, June 1994.Jacquemin, Christian and Jean Royaut6.
1994.Retrieving terms and their variants in a lexicalizedunification-based framework.
In Proceedings, 17th AnnualInternational ACM SIGIR Conference (SIGIR'94),Dublin, July 1994.Kasper, Robert T. and William C. Rounds.
1986.
Alogical semantics for feature structures.
In Proceedings,24th Annual Meeting of the Association forComputational Linguistics, NY, June 1986, 257-266.Langacker Ronald W. 1987.
Foundations of CognitiveGrammar.
Vol L Theoretical Prerequisites.
Stanford:Stanford University Press.Resnik, Philip S. 1993.
Selection and Information :A Class-Based Approach to Lexical Relationships.
Ph Ddiss in Computer Science, University of Pennsylvania.Rounds, William C. and Alexis Manaster-Ramer.1987.
A logical version of functional grammar.
InProceedings, 24th Annual Meeting of the Association forComputational Linguistics, Stanford CA, July 1987,257-266.Savoy, Jacques.
1993.
Stemming of French wordsbased on grammatical categories.
1993.
Journal of theAmerican Society for Information Science, Vol.
44,No 1, January 1993, 1-10.Schabes, Yves and Aravind K. Joshi.
1990.
Parsingwith Lexicalized Tree Adjoining Grammar.
In CurrentIssues in Parsing Technologies, Masaru Tomita (edt),Dordrecht : Kluwer Academic Publishers.Shieber, Stuart N. 1986.
An Introduction toUnification-Based Approaches to Grammar.
CSLI LectureNotes 4, Stanford, CA : CSLI.Sparck Jones, Karen and J. I. Tait.
1984.
AutomaticSearch Term Variant Generation.
Journal ofDocumentation, Vol.
40, No.
1, March 1984, 50-66.Strzalkowski, Tomek and Barbara Vauthey.
1992.Information Retrieval Using Robust Natural LanguageProcessing.
In Proceedings, 30th Annual Meeting of theAssociation for Computational Linguistics (ACL'92),Newark, DE, June 1992, 104-111.Vijay-Shanker, K. 1992.
Using Description of Treesin a Tree Adjoining Grammar.
Computat ionalLinguistics, Vol.
18, No.
4, December 1992, 481-518.Weisweber, Wilhelm and Susanne PreulL 1992.
DirectParsing with Metarules.
In Proceedings, 14thInternational Conference on Computational Linguistics(COLING'92), Nantes, July 1992, 1111-1115.Zernik, Uri.
1992.
Shipping Departments vs.Shipping Pacemakers: Using Thematic Analysis toImprove Tagging Accuracy.
In Proceedings, AnnualMeeting of the American Association for ArtificialIntelligence (AAA1-92 ), 335-342.118
