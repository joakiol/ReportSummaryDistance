SPOKEN-LANGUAGE RESEARCH AT CARNEGIE MELLONRaj Reddy, Principal InvestigatorSchool  o f  Computer  ScienceCarnegie Mel lon Univers i tyPittsburgh, Pennsylvania 15213PROJECT GOALSThe goal of speech research at Carnegie Mellon continues tobe the development of spoken language systems that effectivelyintegrate speech processing into the human-computer interface ina way that facilitates the use of computers in the performance ofpractical tasks.
Component technologites are being developed inthe context of spoken language systems in two domains: theDARPA-standard ATIS travel planning task, and CMU's officemanagement task.
Research in spoken language is currentlyfocussed in the following areas:?
Improved speech recognition technologies.
Research isdirected toward increasing the useful vocabulary of the speechrecognizer, using better subword models and vocabulary-independent recognition techniques, providing for rapid con-figuration for new tasks.?
Fluent human/machine interfaces.
The goal of reserach inthe spoken language interface is the development of an under-standing of how people interact by voice with computer sys-tems.
Specific development systems such as the OfficeManager are used to study this interaction.?
Understanding spontaneous poken language.
Actualspoken language is ill-formed with respect to grammar, syntax,and semantics.
We are analyzing many types of spontaneousspeech phenomena and developing appropriate syntactic andsemantic representations of language that enable spontaneousspeech to be understood ina robust fashion.?
Dialog modeling.
This goal of this research is to identifyinvariant properties of spontaneous spoken dialog at both theutterance and dialog level, and to apply constraints based ondialog, semantic, and pragmantic knowledge to enhance speechrecognition.
These knowledge sources can also be used tolearn new vocabulary items incrementally.?
Acoustical and environmental robustness.
The goal of thiswork is to make speech recognition robust with respect ovariability in acoustical ambience and choice of microphone,so that recognition accuracy using desk-top or bezel-mountedmicrophones in office environments will become comparableto performance using close-talking microphones.RECENT RESULTS?
Incorporation of semi-continuous HMMs and speaker adap-tation has produced speaker-adaptive recognition performancethat is comparable to speaker-dependent performance r portedpreviously by other sites.
Speaker-adaptation algorithms usingneural networks have also been developed with encouragingpreliminary r~ults.?
A vocabulary-independent speech recognition system has beendeveloped.
Improvements including the use of second ordercepstra, between-word triphones and decision-tree clusteringhave produced a level of vocabulary-independent p rformancethat is better than the corresponding vocabulary-dependent p r-formance.?
A dynamic recognition-knowledge base has been incorporatedinto the Office Manager system, as well as models of noisephenomena.
The natural anguage and situational knowledgecapabilities of the system have also been extended.?
The ATIS system has been augmented by incorporating theuse of padded bigrams and models for non-lexical events,providing for increased coverage at reduced perplexity.
Thesechanges have produced major improvements in accuracy usingboth speech and transcripts of ATIS dialogs as input.?
Six principles of dialog that characterize spontaneous speechat the pragmatic and semantic levels were identified.
Al-gorithms were developed to invoke these principles at theutterance l vels to constrain the search space for speech inputand transcripts of ATIS dialogs.?
Pre-processing algorithms that normalize cepstral coefficientsto compensate for additive noise and spectral tilt have beenmade more efficient.PLANS FOR THE COMING YEAR?
We will continue to investigate neural-network-based peakernonnalization and its application to speaker-independentspeech recognitiorL.The vocabulary-independent system will be improved byrefinements in decision-tree clustering, pruning strategies, andselection of contextual questions.
Non-intrusive task and en-vironmental normalization will be introduced.?
We will continue refining the Office Manager system andbegin using it as a testbed for the development of error repairstrategies and intelligent interaction management.?
The constraints imposed by dialog models will be extended toallow more dialog and pragmatic knowledge to be used by theATIS system in the understanding process.
The ATIS systemwill be improved by the addition of out-of-vocabulary modelsand an improved rejection capability and user interface.?
Dialog-level knowledge will be applied to incremental wordlearning.?
Passive nvironmental adaptation will be incorporated into thespeech recognizer in the Portable Speech Library.
We willmeasure the extent to which processing using multiplemicrophones and physiologically-motivated front ends comple-ments the robustness provided by acoustical pre-processing.411
