Generat ing  from a Deep Structure *Claire GardentUniversitfi Blaise Pascal- Clermont Ferrand (France)and University of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW (Scotland)Agnes PlainfossfiLaboratoires de MarcoussisRoute de Nozay91460 Marcoussis (France)ABSTRACT:  Noncanonical semantic representationsare representations which cannot be derived by somegrammar G although they are semanticMly equivalent torepresentations which can be derived by G. This paperpresents a generation Mgorithm which deals with non-canonical input.
The proposed approach also enhancesportabil ity and language independence in that (i) linguis-tic decisions made by independent modules (e.g., planner,transfer component) can be communicated to the gener-ater in a naturM way and (ii) the same algorithm coupledwith different grammars will yield sentences in the cor-responding languages.1 Introduct ionnot derivable under G. Representations that cannot bederived under a grammar G are said to be noncanonicalwith respect to G.In this paper, we present a generation algorithm for Uni-fication Categorial Grammar \[6\] ( , ca )  which addressesthe problem raised by non-canonicM input (section 2 and3).
An interesting upshot of the strategy we propose isthat it allows :\['or language independent generation.
Sec-tion 4 il lustrates this point by considering how, startingfrom one semantic representation, two sentences can begenerated: one in English and one in French.
Section 5relates our work to previous proposals by Van Noord andShieber.Two major requirements on a generator is that it be cor-rect and complete.
A generator is said to be correct ifgiven two semantic representations R1 and R.~ which arenot semantically equivalent, R1 and R2 do not generatethe same string.
A generator is said to be complete ifany two senmn tically equivalent representations generatethe same set of strings.An obvious case of incompleteness occurs when the gen-erator fails to terminate on some well-defined input.
An-other less obvious cause for incompleteness can be ex-plMned as follows.
Consider a grammar G and its as-sociated semantic representation language L. It is oftenthe case that syntactically different strings of L will haveequivalent semantics.
A simple case in point is the se-mantic equivalence holding between ?
A ?
and ?
A ?
ine.g.
propositional ogic.
On the other hand, it is alsooften the case that the same grammar G will not derivefor a given string all the formulae which may representits meaning.
From the point of view of generation, thismeans that given two semanticMly equivalent represen-tations R1 and R2 there is always a possibility that R1generates a string S but that R2 doesn't because R2 is*The work reported here has been carried out ,as part of theESPRIT project P393 ACORD on "The Construction and In-terrogation of Knowledge-B~es using Natural Language Textand Graphics".
It is the result of joint work with MichaelReape of the Center for Cognitive Science, University of Ed-inburgh (Scotland, UK).2 Generating from a deepstructureIt is sometimes the case that a grammar will assign to astring several possible derivations with equivalent semen-ties.
This phenomena is particularly acute in categorialgrammars \[2\] and is referred to in the l iterature as thatof spurious ambiguity.
In grammars where the semanticsis built by unification, the syntactic differences holdingbetween these equivalent semantics resides in the relativeordering of the subformulae within the formula.
That is,there is a direct relationship between the syntactic shapeof a semantic formula and the derivational history of thecorresponding string.
Consequently, a given formula willbe non-canonk:al wrt to a particular grammar G if therelative sequencing of its subformulae does not reflect apossible derivation in C .
Hence, to allow for generationfrom non-canonical input, we need to abstract away fromthe derivational information reflected in the linear order-ing of the input formula.
Three major alternatives cometo mind.
First, we could try to generate all sentenceswhose semantics are logically equivalent o the input se-mantics.
In uc(~, this means that generation is carriedout with the two additional ogical axioms of associativ-ity and commutativity.
However, this solution produces asearch space factorial in the number of conjunction s andmust thus be rejected as computational ly intractable.1 127The second possibility is to define a semantic represen-tation language for which all well-formed formulas arein normal form.
This approach is essentially unavailableto any grammar framework in which the semantics of agiven expression results from the unification of partiallyspecified semantic representations because normal formscan only be defined on languages with fully instantiatedformulae.A third possibility consists in generating from an alterna-tive representation i.e.
one that is related to but not iden-tical with the semantic representation used by the gram-mar.
This is what we chose to do.
The alternative rep-resentation we adopted is closely related to D-structurein cn theory where D-structure is a level of syntacticstructure which mirrors semantic functor-argument de-pendencies.
Syntactic information is encoded in termsof schematic X theory familiar from modern generativegrammar.
The deep structures (DS) we generate fromconsist of four types: heads, complements, modifiers andspecifiers (we follow LEG f-structure and ucc subcate-gorisation structure in treating subjects as ordinary com-plements rather than specifiers of clauses) whereby Spec-ifiers are of the form: spec i f ier (Semant ics ,  Head).That is, they specify their own semantics and the prop-erties of their head.
In contrast, Heads are of theform: head(Semantics, ArgList, AdjunctList) .
Thatis, they specify their own head semantics and a list ofarguments and adjuncts which are also either specifieror head structures.
All of these structures also allow theencoding of syntactic requirements onarguments and ad-juncts.The use of DSs has two other consequences.
First, byallowing for the association of syntactic with semanticinformation, D-structures offer a way to mediate the re-sults of linguistic decisions made by an eventual plannerto the generator.
This may be useful.
For instance, NPplanning could be accounted for.
In the present context,a planner is any system which given some informationabout what to say will return some decision about howto say it.
For instance, if we want to expre,~s the factthat Jon runs, the planner will have to decide on howto refer to Jon, i.e.
it could decide to describe him us-ing a complex NP as in 'the man with the red scarf whostands negt to Irene', or a pronoun e.g.
'he' or simplyhis name i.e.
'.Ion'.
The point is that the syntactic deci-sion made by the planner must be communicated to thegenerator.
Since DSs contain syntactic information, theyare a good candidate for the necessary interface betweenplanner and generator.A second advantage of DSs is that because they are lan-guage independent, they allow for language independentgeneration.
That is, for any acceptable input deep struc-ture, the algorithm presented below will generate .g.,a French sentence if coupled with a UCG grammar forFrench and an English sentence if coupled with a coogrammar for English.
This is only possible because theinput deep structure the generation algorithm relies onis both sufficiently abstract o be language-independentand general enough that it can be mapped onto languagedependent surface syntactic structures.
Language inde-pendent generation is discussed in more detail in section4.In relation with the problem raised by non-canonical in-put, an important property of DSs is that they containno indication of either surface syntactic order of the com-plements and adjuncts or of the relative scope of quan-tifiers occurring in either complements or modifiers.
In-stead, thematic dependencies between subformulae arekept track of by the X schema where no reference is madeto derivational history.
The generator is thus free to real-ize both scope and surface syntactic structure in any waywhich is consistent with the deep structure specificationand the particular grammar used.
The reader might ob-ject to this elimination of scope distinctions.
However,within UOG any scope distinctions which are produced bythe individual grammars or as a result of some seman-tics construction process are in fact artefactual.
Further-more, it might reasonably be argued that it should bepossible to generate all possible scopes.
This is typicallydone with quantifier shifting rules.
Our solution is simplynot to specify scope.An immediate consequence of using DSs is that non-canonical input is no longer a problem.
The reason forthis simply is that the generation algorithm no longerrelies on the assumption that the input semantic repre-sentation i8 canonical i.e.
derivable under the grammarused.
Rather, the assumption is that the input will besome well-formed DS that will contain all the informationcontained in the corresponding semantics but none of theinformation embodied in the linear ordering of the for-mula about the derivational history of the correspondingstring.3 The basic a lgor i thm3.1 A br ie f  in t roduct ion  to  UCGIn UOO the basic linguistic unit is a sign which includesphonological, syntactic, semantic and ordering informa-tion.
In the sequel, a sign will be represented either bya complex feature structure or as Pho :Synt :Sera: Drder.The phonological field of a sign contains its orthographicstring.
The syntactic field is categorial i.e.
it can beeither basic (e.g s,np,n etc) or complex in which case,it will be of the form C/S ign where C is a syntacticfield and Sign is a sign.
Moreover, any basic categorycan be assigned some morphosyntactic information.
Forinstance s\[fin\] denotes the category sentence with mor-pholog-y feature value: finite.
The semantic field containsthe semantics ofthe expression whereby the semantic rep-resentation language is a linear version of Discourse Rep-resentation Theory in which each condition is precededby a sorted variable called the index.
As in most unifi-cation based grammars, the semantics of any expressionresults from the unification of the semantics of its sub-parts.
Finally, the Order field is a binary feature withvalue either pre or post which constrains the applicabil-ity of grammar rules.Grammar ules in uco are of two types: binary and128 2unary.
Binary rules include forward and backward func-tional application.
These are stated below.Pho : (Synt /S ign) :Sem:0rder ,  Sign- -> Pho:Synt :Sem:Orderif the order value of Sign is proSign, Pho:(Synt/Sign):Sem:Order--> Pho:Synt :Sem:0rderif the order value of Sign i8 postUnary rules are of the form c~ --+ fl where c, and fl aresigns.
Unary rules are used for the treatment of un-bounded dependencies, syntactic forms of type-raisingand subcategorlsation for optional modifiers.aetive(SignO,Active),apply(SignOoActive,Result),retrleve(DS,SubDS,NewDS),generate(SubDS, Active),reduee(Result,Sign,NewDS).The algorithm presented above makes many simplifyingassumptions which are incompatible with a wide coverageuoc  grammar.
To produce a complete generator with re-spect to uoo we need to extend the basic algorithm toaccount for type-raised NPs, identity semantic functors,lexical modifiers and unary rules.
For more details on thegeneral content of these extensions ee Ill. For their im-plementation cf.
the listing of the generation algorithmgiven in the appendix.3.2 A sketch of the a lgor i thmFollowing work by \[11, \[5\] and \[3\], the algorithm wepresent here follows a mixed top-down and bottom-upstrategy.The generation process starts with a deep structure DSand a sign Sign whose syntax embodies the goal cate-gory (e.g.
sentence(finite)), get deepstr info extractsfrom the deep structure some semantic (Sere) and syntac-tic (Synt) information on the next sign to be generated.c reate  s ign  creates a new sign Sign0 on the basis of Semand Syn~.
Lexlcal look-up on Sign0 returns a sign withinstantiated syntax and phonology.
The call to reduceensures that this lexical sign is reduced to the goal signSign in the process instantiating the generated string.generate(DS.
Sign) :-get_dsepst r_ in fo (DS, \ [Synt ,Sem\] ,RestQfDS) ,create sign(Synt,Sem,SignO),lexical(SignO),reduce(SignO,Sign0Rest0fDS).There are two main ways of reducing a sign Sign0 to agoalsign Sign.
The base case occurs when Sign0 unifieswith Sign and the deep-structure is empty i.e.
all theinput semantic material has been made use of in gener-ating the result string.
The recursive case occurs whenSign0 is a syntactic functor.
If the syntax of Sign0 isof the form Resu l t /Ac t ive ,  we apply Resu l t /Ac t ive  toAct ive  thus getting a new sign Resul t .
re t r ieve  non-deterministically retrieves from the current deep struc-ture DS, a substructure SubDS and returns the remainingdeep-structure NewDS.
The argument Act ive  is then gen-erated on the basis of the extracted sub..structure SubDSwith a new goal sign whose syntax is that predicted bythe syntactic functor Sign0.
The resulting sign Resu l tis recursively reduced to the original go,~l sign Sign.reduce (Sign.
S ign,  \[ \[\] 0 \[\] \] ) .reduce (SignO, Sign, DS) :-4 Bi l ingual Generat ionConsider the following synonymous entences.a The mou.,m misses the catb Le chat manque ~l la souris(Lit.
the cat misses to the mouse)(1)There are two main differences between (la) and (lb).First, a NP (the mouse) translates to a PP ( g~ la souria).Second, a structural transfer occurs i.e.
the object NP in( la) becomes a subject in ( lb) and vice-versa.
For thegenerator described above, this poses no particular prob-lem.
Because DSs encode thematic rather than grammat-ical dependencies, tructural  transfer is no issue.
Further,since at DS all arguments are represented as NPs x, thegeneration of ( la) is straightforward.
Generating (lb)is a little more intricate but results naturally from theinteraction of the generator with the grammar =.
Notethat if the PP  were represented as such in the DS, thengeneration would fail for the English sentence.
This sug-gests that the deep structures we generate from offer theright level of abstraction for generation to be possible inseveral anguages.The case of structural  transfer i l lustrated in (1) is a goodexample of the problems that occur with generators thatare unable to deal with non-canonical input.
To il lustratethis consider the following situation.
Suppose that giventwo grammars, one for Engl lsh(G~) and one for French(GF), ( la) and (lb) each have one unique derivation withresulting semantics as in (2).a The(mouse(m),  the(cat(c), miss(re,c))b The(cat(c),  the(mouse(m), tulsa(re,c)))(2)Furthermore, suppose (3a) is non-canonlcal with respectto C,~ (i.e.
(an) is not derivable under C,~) and (3b) isnon-canonic.M wrt GE.
For any generator G that cannotdeal with non-canonical input, this means that G cannotbe used in a system where parsing occurs on one languageIThis is in accordance with the view that prepositions oc?curing within argumental PPs have no semantic ontent.2For more details on the generation of subcategorised PPswithin UCG see \[1}.3 129  'and generation on another.
More to the point, if G is cou-pled with the grammar GE, then it will fail to generatewhen given (2b) as input - and similarly when coupledwith GF and given input (2a).
To understand why deepstructures allow for grammar independent generation,let us first examine why tradit ional top-down/bottom-up generators uch as the one described in \[1\] fail onnon-canonical input.
3 Consider the case where we tryto generate under Gs  the English sentence in ( la) fromthe semantic (2b) and- as already mentioned- (2b) isnon-canonical wrt GE.
The main steps of the genera-tion process will be as follows.
4 Suppose the goal sign isSignO with category s\[fin\].
First, a sign Sig~l is createdwhose semantics i as in (2b).
Lexical access on Signl re-turns the sign for 'the'.
On the basis of the syntactic andsemantic predictions made by Signl, the sign Sign2 for'cat' is then generated.
Reduction of Signl with Sign2yields a new sign Sign3 with phonology 'the cat'and syn-tax C/(C/np) 5.
In turn, Sign3 makes some predictionswhich lead to the generation of a new sign Sign4 withsyntax C/(C/np) and phonology 'the mouse'.
Finally,on the basis of Sign4, the sign Sign5 for 'miss' is gen-erated.
At this point in generating, the two signs in (3)must combine to reduce to a sign with category C/np.pho:~i~)synt : C/pho : Wasynt:C/pho:themousesyat:npsem :m.mouse(m)order:Ofsem:VPorder:Oforder :02pho : missesI pho : Wasynt :s/ synt : np\[nom\]sere : m.NPIorder : presem : m.miss(m,c)order : 03pho : Wb/ sr t: npb  \]sere : c.NP2order : postBut under ti~e UCG rules of combination (see 3.1), thesetwo signs cannot combine because of the unification clashoccuring between the semantics of the accusative NP inthe verbal sign (c.NP2) and that of the NP sign withinaNote that in this case, reduction to normal form is nolonger a possible solution even if we were able to define anormal form for our semantic representation language.
Forsuppose that (2a) is the normal form, then (lb) is not derivableand if (2b) is, then (la) is not derivable.4For more information on the details of the generation pro-cedure, see \[1\].~For the sake of clarity, the syntactic part of Sign3 is heresimplified in that non-syntactic fields (Phonology, Semanticsetc.)
are omitted.
Note also that in UCG, NPs are typer-aised i.e they are assigned the syntactic ategory C/(C/np)as opposed\[ to just np.the sign for 'the mouse' (m.mouse(m)).
Hence generationfails.
Consider now how the problem is dealt with whengenerating from deep structures.
Rather than being asindicated in (2b), the input to the generator is 6head(miss(m, e),\[specifier(the, head(moose(m), \[\], \[\])),specifier(the, head(cat(e), \[l, \[l))\]\[\])(3)Roughly, generation will proceed as follows.
Suppose thegoal sign SignO has category s\[fin\].
First, the semanticscorresponding to the head of the clause (i.e.
mi,Js(m, c))is extracted from (3) and a sign Signl is created withsemantics miss(re, c).
Lexical access on Signl returnsthe sign given in (3) above.
Signl must then be re-duced to SignO with category s\[fin\].
At this stage, theremaining DS is \[specifler(the, head(mouse(m), \[\],\[\])),speci/ier(the, head(cat(c), \[l, \[\]))\] Togenerate the first ar-gumentof Signl, we then have the choice between generatingon the basis of specifier(the, head(mouse(m), \[\],\[\])) orof specifier(the, head(cat(c), \[\], \[1)) 7 As demonstratedabove, if we generate the sign for 'the mouse' first, re-duction cannot apply and generation will fail.
But here,failure is only temporary and on backtracking, the signfor 'the cat' will eventually be generated; it will thenreduce with Signl to generate Sign2 with phonology'misses the cat'.
At this point, the remaining DS willbe \[specifier(the, head(mouse(m), \[\],\[\]))\].
This will trig-ger the generation of Sign3 with phonology 'the mouse'which will then combine with Sign2 to reduce to SignOwith resulting phonology 'the mouse misses the cat'.To generate the French sentence 'Is chat manque h la8ouris ', the same generation process applies but this timein connection with GF and in a reverse order i.e.
the signfor 'Is souris'(the mouse) is generated before the sign cor-responding to the NP 'Is chat' (the cat).
Further, becausein the French lexicon 'manque' (miss) subcategorises fora dative NP, the preposition ~ is generated and combinedwith the sign for 'Is souris' before reduction of the thusobtained PP  with the verb.
Because DSs make no as-sumption about the linear ordering of the constituentsto be generated, the problem raised by non-canonicitysimply does not arise.5 Compar i sons  w i th  Re \ ] \ [a tedResearchTo compare our algorithm with previous work, we firstshow how it can be amended to phrase structure gram-mars.
Consider the following extension to reduce.reduce(SignO, Sign, DS) :-rule(Morn, SignO, Kids),6For the sake of simplicity, the syntactic information usu-ally contained in the deep structures input to the generator ishere omitted.7cf.
the non-determinism of the retr ieve predicate.130 4generate_s i s te rs  (Kids,  DS, NewDS),reduce(gem, Sign, NewDS).gene: t : 'a te_s is ters( \ [ \ ]  , DS, DS).gene:t:afie_sisfiers(\[HIT\], DS, NewDS) : -index (tI, Idx) ,me I; eh ( Idx,  DS, SubDS, NewDS 1 ) ,generate(SubDS,  H),generate  s i s te rs (T ,  NewDS1, llewDS).This clause is very similar in structure to the secondclause of reduce,  the main difference being that the newclaus(, makes fewer assumptions about the feature struo-tures being manipulated, ru le  enmnerates rules of thegrammar, its first argument representing the mother con.stitu~ut, its second the head daughter and its third a listof non-head daughters which are to be recursively gener-ated by the predicate generate  s i s te rs .
The behaviourof this clause is just like that of the clause for reducewhich implements the uc(; rules of function application.On tire basis of the generated lexical sign Sign0 an ap-plical.ion of the rule is hypothesised and we then attemptto prove that ru\]e application will lead to a new sign gemwhiel, reduces to the original goal Sign.Having generalised our basic algorithm to phrase struc-ture ~ran\]mars, we can now compare it to previous workby \[5} and \[3\]Van Iqoord's Bottom-Up Generator (BUG) is very similarin structure to our basic algorkhm.
Closer examinationof the.
two programs however eveals two differences.
Thefirst is that daugthers in a rule are separated into thosethat })recede the semantic head and those that follow it.The ,'.econd more meaningful difference involves the useof a ' l ink' predicate implementing the transitive closureof the semantic head relation over the grammar rules.The link predicate is similar in purpose to reachibilitytable~ in parsing algorithms and contributes to reducingthe search space by producing some syntactic informationon the sign to be generated.
Itowever, such a predicate isof litt.le use when generating with a categorial grammarin particular and with any strongly lexicalist linguistictheory in general since in these, the grammar rules areextremely schematised.
Their information content is soimpoverished that the computat ion of and resort to a linkpredicate cannot be expected to reduce the search spacein an/meaningf l f l  way.
In the algorithm presented abovehowever~ this shortcoming is redressed by exploiting thesyntactic information contained in the deep-structure westart from.In \[5\], Shieber et al present a "semantic-head-driven"generation algorithm that is closely related to van No-ord's.
In contrast to Van Noord's algorithm however,this ~dgorithm also operate on grammars violating thesema~dic head con.~traint (SHC) according to which anysema~tic representation is a further instantiation of thesemantic representation of one of i~s constituents calledthe semantic head.
This is achieved as follows.
First, adistlnction is made between chain--rules and non-chain-rules whereby non-chain-rules are used to introduce se-mantic material syncategorematically.
The distinctionbetween the two types of rules can be sketched as fol-lows.i.
Chain-rule (Sem, lhs --> Head(Sem), Sisters)2.
Non-Chain-rule (Sem, lhs(Sem) --> Daughters)(1) indicates that given a semantic Sere, a chain rulewill be such that Sere unifies with the head daughter'ssemantics whilst (2) shows that non-chMn-rules are suchthat the input semantics must unify with the semantics ofthe lhs of the rule.
The intuition is that non-chain-ruleswill help find the lowest node in the derivation tree whosesemantics unify with the input semantics.
Furthermore,the top-down base case for non-chain-rules corresponds tothe case in which the lhs of the rule has no non-terminaldaughters i.e.
to lexieal look up.
Consider now the topcall to generate.generate(Root )  :-non_chain ru le (Root ,P ivot ,P .hs ) ,generate  rhs(Rhs)0connect (P ivot ,Root ) .Two cases obtain with regard to the applicatlon of thenon- cha in - ru le  predicate.
Either the base case occursand lexical look-up takes place exactly as in our algo-rithm or a non-chain-rule is triggered top-down beforethe conatituents in the rhs are generated by a recursivecall to generate .
Hence the solution to the introductionof syncategorematic material  is essentially a reintroduc-tion of the top-down generation strategy.
The result isthat there is no guarantee that the algorithm will termi-nate.
This point seems to have been overlooked in \[5 t.Therefore, the extension may be of less utility than it ap-pears to be at first sight although it may well be the casefor linguistically motivated grammars that terminationproblems never arise.6 Fur ther  ResearchThe general backtracking reghne characterising the al-gorithm presented in this paper means that  failure at afirst attempt to generate might induce the recomputa-tion of partial results.
Perhaps the use of a chart couldcontribute to enhance generation efficiency.
Ii1 relationto \[4\] where chart edges contain no ordering information,it would be interesting to investigate whether during thegeneration process some ordering information can be re-covered.
That is, whether the chart could be constructedin such a way that t:he relative positioning of edges mir-rors the knowledge mbodied in the grammar about lin-ear precedence within and between constituents.
In thisway, only the relevant part of the chart would need to belooked up before attempting to build a new edge.The algorithm described above is implemented ill CPro-log on a Sun4 and constitutes part of the generation cola-5 131ponent in the ACORD prototype.
The generator can becoupled with either a UCG grammar for French or onefor English thus generating either French or English sen-tences.References\[l\] Calder,  J., Reape,  M. and Zeevat, H. \[1989\]An Algorithm for Generation in Unification Cate-gorial Grammar.
In Proceedings of the Fourth Con-ference of the European Chapter of the Associationfor Computational Linguistics, University of Manch-ester Institute of Science and Technology, Manch-ester, England, 10-12 April, 1989, 233-240.\[2\] Gardent, C., Bes, G., Jurle,P.F.
andBaschung,  K. \[1989\] Efficient P;~rsing for French.In Proceedings of the 27th annual meeting of the As-sociation for Computational Linguistics, Universityof British Columbia.
Vancouver, 26-29 June 1989,280-287.\[3\] van Noord,  G. \[1989\] BUG: A Directed BottomUp Generator for Unification Based Formalisms.Manuscript.
Department of Linguistics, Universityof Utrecht, M~rch 14, 1989.\[4\] Shieber, S. \[1988\] A Uniform Architecture forParsing and Generation.
In Proceedings of the 12thInternational Conference on Computational Linguis-tics, Budapest, 22-27 August, 1988, 614-619.\[5\] Shieber, S., van Noord ,  G., Moore,  R. andPereira,  F .C.N.
\[1989\] A Semantic-Head-DrivenGeneration Algorithm for Unification-B,nsed For-malisms.
In Proceedings of the 27th Annual Meet-ing of the Association/or Computational Linguistics.University of British Columbi.% Vancouver, BritishColumbia, Canada, 26-29 June, 1989, 7-17.\[61 Zeevat H., Klein, E. and Calder,  J.
\[19871 AnIntroduction to Unification C~tegorial Grammar.
InHaddock, N.J., Klein, E. and Morrill, G.
(eds.)
Edin-burgh Working Papers in Cognitive Science, Volume1: Categorial Grammar, Unification Grammar andParsing.Listing of the whole program(Low level procedures have been omitted)generate(DeepStro Sign) :-get_deepstr_info(DeepStr?\[Synt.
Sem\],RestOfDeepStr).create_sign(Synt?Sem?SignO),lexical(Sign0),reduce(SignO,Sign,Rest0fDeepStr).reduce(SignoSigno \[ \[\] o \[\] \] ).reduce(SignO?Sign?
DeepStr) :-active(SignO,Active),apply(SignO?Active,Reault),retrieve(DeepStr,SubDeepStr,NewDeepStr)?generate(SubDeepStr, Active),reduce(ResultoSign?NewDeepStr).reduce(SignO, Sign.
DeepStr) :-transform(SignO, Signl, DeepStr, NewDeepStr)reduce(Signl?
Sign, NewDeepStr).Identity Semantic Fun(torntransform(Sign,NewSign,DeepStr,DeepStr) :-not_idsign(Sign).create_id_functor(IdSemFctor, Sign),identity(IdSemFctor),apply(NewSign.
IdSemFctor0Sign)?defreeze_order(AdjSign, Sign, NewSign)% Lexical Adjtmctstraneform(Sign,NewSign0DS,NewDS) :-create_lexical_adjunct(Sign,ASign0DS,NewDS,DS2) ogenerer(DS2, ASign),apply(NewSign, ASign, Sign).Type-raise Verbs to C/(C/NP)transform(Sign,NewSign,DS,NewDS) :-type_raise vb to_np(Sign, RaisedSign),getjub deepstr(Sign0 DS, SubDS, NewDS)generer(SubDS, RaisedSign),apply(NewSign, RaisedSign, Sign)132Unary rulestransform(Sign,NewSign?DeepStr,DeepStr)unary_rule(NewSign,Sign).Identity Semantic Functor(Case marking Prepositions)transform(Sign,NewSign,DeepStr,DeepStr)active(Sign,VB),active(VB, NP),category(NP, np) ocreate_id_prep(Np,PREP)?identity(PREP),
