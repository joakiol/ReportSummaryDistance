Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 150?153,Sydney, July 2006. c?2006 Association for Computational LinguisticsBoosting for Chinese Named Entity RecognitionXiaofeng YU Marine CARPUAT Dekai WU*Human Language Technology CenterHKUSTDepartment of Computer Science and EngineeringUniversity of Science and TechnologyClear Water Bay, Hong Kong{xfyu,marine,dekai}@cs.ust.hkAbstractWe report an experiment in which a high-performance boosting based NER modeloriginally designed for multiple Europeanlanguages is instead applied to the Chi-nese named entity recognition task of thethird SIGHAN Chinese language process-ing bakeoff.
Using a simple character-based model along with a set of featuresthat are easily obtained from the Chi-nese input strings, the system describedemploys boosting, a promising and the-oretically well-founded machine learningmethod to combine a set of weak classi-fiers together into a final system.
Eventhough we did no other Chinese-specifictuning, and used only one-third of theMSRA and CityU corpora to train thesystem, reasonable results are obtained.Our evaluation results show that 75.07 and80.51 overall F-measures were obtainedon MSRA and CityU test sets respectively.1 IntroductionNamed entity recognition (NER), which includesthe identification and classification of certainproper nouns, such as person names, organiza-tions, locations, temporal, numerical and mon-etary phrases, plays an important part in manynatural language processing applications, suchas machine translation, information retrieval, in-formation extraction and question answering.Much of the NER research was pioneered inthe MUC/DUC and Multilingual Entity Task(MET) evaluations, as a result of which signif-icant progress has been made and many NER?This work was supported in part by DARPA GALEcontract HR0011-06-C-0023, and by the Hong Kong Re-search Grants Council (RGC) research grants RGC6083/99E,RGC6256/00E, and DAG03/04.EG09.systems of fairly high accuracy have been con-structed.
In addition, the shared tasks of CoNLL-2002 and CoNLL-2003 helped spur the devel-opment toward more language-independent NERsystems, by evaluating four types of entities (peo-ple, locations, organizations and names of miscel-laneous entities) in English, German, Dutch andSpanish.However, these are all European languages, andChinese NER appears to be significantly morechallenging in a number of important respects.We believe some of the main reasons to be asfollows: (1) Unlike European languages, Chi-nese lacks capitalization information which playsa very important role in identifying named enti-ties.
(2) There is no space between words in Chi-nese, so ambiguous segmentation interacts withNER decisions.
Consequently, segmentation er-rors will affect the NER performance, and viceversa.
(3) Unlike European languages, Chinese al-lows an open vocabulary for proper names of per-sons, eliminating another major source of explicitclues used by European language NER models.This paper presents a system that introducesboosting to Chinese named entity identificationand classification.
Our primary aim was to con-duct a controlled experiment to test how wellthe boosting based models we designed for Eu-ropean languages would fare on Chinese, withoutmajor modeling alterations to accommodate Chi-nese.
We evaluated the system using data fromthe third SIGHAN Chinese language processingbakeoff, the goal of which was to perform NERon three types of named entities: PERSON, LO-CATION and ORGANIZATION.1 Three trainingcorpora from MSRA, CityU and LDC were given.TheMSRA and LDC corpora were simplified Chi-nese texts while the CityU corpus was traditional1Except in the LDC corpus, which contains four typesof entities: PERSON, LOCATION, ORGANIZATION andGEOPOLITICAL.150Chinese.
In addition, the competition also spec-ified open and closed tests.
In the open test, theparticipants may use any other material includingmaterial from other training corpora, proprietarydictionaries, and material from the Web besidesthe given training corpora.
In the closed test, theparticipants can only use the three training cor-pora.
No other material or knowledge is allowed,including part-of-speech (POS) information, ex-ternally generated word-frequency counts, Arabicand Chinese numbers, feature characters for placenames, common Chinese surnames, and so on.The approach we used is based on selecting anumber of features, which are used to train severalweak classifiers.
Using boosting, which has beenshown to perform well on other NLP problems andis a theoretically well-founded method, the weakclassifiers are then combined to perform a strongclassifier.2 BoostingThe main idea behind the boosting algorithm isthat a set of many simple and moderately accu-rate weak classifiers (also called weak hypothe-ses) can be effectively combined to yield a sin-gle strong classifier (also called the final hypoth-esis).
The algorithm works by training weak clas-sifiers sequentially whose classification accuracyis slightly better than random guessing and finallycombining them into a highly accurate classifier.Each weak classifier searches for the hypothesis inthe hypotheses space that can best classify the cur-rent set of training examples.
Based on the eval-uation of each iteration, the algorithm reweightsthe training examples, forcing the newly generatedweak classifier to give higher weights to the exam-ples that are misclassified in the previous iteration.The boosting algorithm was originally created todeal with binary classification in supervised learn-ing.
The boosting algorithm is simple to imple-ment, does feature selection resulting in a rela-tively simple classifier, and has fairly good gen-eralization.Based on the boosting framework, our systemuses the AdaBoost.MH algorithm (Schapire andSinger, 1999) as shown in Figure 1, an n-ary clas-sification variant of the original well-known bi-nary AdaBoost algorithm (Freund and Schapire,1997).
The original AdaBoost algorithm was de-signed for the binary classification problem but didnot fulfill the requirements of the Chinese NERInput: A training set Tr = {< d1, C1 >, .
.
.
, < dg, Cg >}where Cj ?
C = {c1, ..., cm} for all j = 1, .
.
.
, g.Output: A final hypothesis ?
(d, c) =?Ss=1 ?s?s(d, c).Algorithm: LetD1(dj , ci) = 1mg for all j = 1, .
.
.
, g andfor all i = 1, .
.
.
,m. For s = 1, .
.
.
, S do:?
pass distribution Ds(dj , ci)to the weak classifier;?
derive the weak hypothesis ?s from the weakclassifier;?
choose ?s ?
R;?
set Ds+1(dj , ci) =Ds(dj ,ci)exp(?
?sCj [ci]?s(dj ,ci))ZswhereZs =?mi=1?gj=1 Ds(dj , ci )exp( ?
?sCj [ci] ?s(dj , ci))is a normalization factor chosen so that?mi=1?gj=1 Ds+1(dj , ci) = 1.Figure 1: The AdaBoost.MH algorithm.task.
AdaBoost.MH has shown its usefulness onstandard machine learning tasks through exten-sive theoretical and empirical studies, where dif-ferent standard machine learning methods havebeen used as the weak classifier (e.g., Bauer andKohavi (1999), Opitz and Maclin (1999), Schapire(2002)).
It also performs well on a number of nat-ural language processing problems, including textcategorization (e.g., Schapire and Singer (2000),Sebastiani et al (2000)) and word sense disam-biguation (e.g., Escudero et al (2000)).
In partic-ular, it has also been demonstrated that boostingcan be used to build language-independent NERmodels that perform exceptionally well (Wu et al(2002), Wu et al (2004), Carreras et al (2002)).The weak classifiers used in the boosting algo-rithm come from a wide range of machine learningmethods.
We have chosen to use a simple classifiercalled a decision stump in the algorithm.
A deci-sion stump is basically a one-level decision treewhere the split at the root level is based on a spe-cific attribute/value pair.
For example, a possibleattribute/value pair could beW2 =?/.3 Experiment DetailsIn order to implement the boosting/decisionstumps, we used the publicly available softwareAT&T BoosTexter (Schapire and Singer, 2000),which implements boosting on top of decisionstumps.
For preprocessing we used an off-the-shelf Chinese lexical analysis system, the opensource ICTCLAS (Zhang et al, 2003), to segmentand POS tag the training and test corpora.1513.1 Data PreprocessingThe training corpora provided by the SIGHANbakeoff organizers were in the CoNLL two col-umn format, with one Chinese character per lineand hand-annotated named entity chunks in thesecond column.In order to provide basic features for trainingthe decision stumps, the training corpora were seg-mented and POS tagged by ICTCLAS, which la-bels Chinese words using a set of 39 tags.
Thismodule employs a hierarchical hidden Markovmodel (HHMM) and provides word segmentation,POS tagging and unknown word recognition.
Itperforms reasonably well, with segmentation pre-cision recently evaluated at 97.58%.2 The recallrate of unknownwords using role tagging was over90%.We note that about 200 words in each train-ing corpora remained untagged.
For these wordswe simply assigned the most frequently occurringtags in each training corpora.3.2 Feature SetThe boosting/decision stumps were able to accom-modate a large number of features.
The primitivefeatures we used were:?
The current character and its POS tag.?
The characters within a window of 2 charac-ters before and after the current character.?
The POS tags within a window of 2 charac-ters before and after the current character.?
The chunk tags (gold standard named entitylabel during the training) of the previous twocharacters.The chunk tag is the BIO representation, whichwas employed in the CoNLL-2002 and CoNLL-2003 evaluations.
In this representation, eachcharacter is tagged as either the beginning of anamed entity (B tag), a character inside a namedentity (I tag), or a character outside a named entity(O tag).When we used conjunction features, we foundthat they helped the NER performance signifi-cantly.
The conjunction features used are basi-cally conjunctions of 2 consecutive characters and2 consecutive POS tags.
We also found that a2Results from the recent official evaluation in the national973 project.Table 1: Dev set results on MSRA and CityU.Precision Recall F?=1MSRALOC 82.00% 85.93% 83.92ORG 76.99% 61.44% 68.34PER 89.33% 74.47% 81.22Overall 82.62% 76.45% 79.41CityULOC 88.62% 81.69% 85.02ORG 82.50% 66.44% 73.61PER 84.05% 84.58% 84.31Overall 86.46% 79.26% 82.71Table 2: Test set results on MSRA, CityU, LDC.Precision Recall F?=1MSRALOC 84.98% 80.94% 82.91ORG 72.82% 57.78% 64.43PER 82.89% 59.91% 69.55Overall 81.95% 69.26% 75.07CityULOC 88.65% 83.58% 86.04ORG 83.75% 57.25% 68.01PER 86.11% 76.42% 80.98Overall 86.92% 74.98% 80.51LDCLOC 65.84% 76.51% 70.78ORG 53.69% 39.52% 45.53PER 80.29% 68.97% 74.20Overall 67.20% 65.54% 66.36LDC (w/GPE)GPE 0.00% 0.00% 0.00LOC 1.94% 37.74% 3.70ORG 53.69% 39.52% 45.53PER 80.29% 68.97% 74.20Overall 30.58% 29.82% 30.19larger context window (3 characters instead of 2before and after the current character) to be quitehelpful to performance.Apart from the training and test corpora, weconsidered the gazetteers from LDC which con-tain about 540K persons, 242K locations and 98Korganization names.
Named entities in the train-ing corpora which appeared in the gazetteers wereidentified lexically or by using a maximum for-ward match algorithm.
Once named entities havebeen identified, each character can then be anno-tated with an NE chunk tag.
The boosting learner152can view the NE chunk tag as an additional fea-ture.
Here we used binary gazetteer features.
Ifthe character was annotated with an NE chunktag, its gazetteer feature was set to 1; otherwiseit was set to 0.
However we found that adding bi-nary gazetteer features does not significantly helpthe performance when conjunction features wereused.
In fact, it actually hurt the performanceslightly.The features used in the final experiments were:?
The current character and its POS tag.?
The characters within a window of 3 charac-ters before and after the current character.?
The POS tags within a window of 3 charac-ters before and after the current character.?
A small set of conjunctions of POS tags andcharacters within a window of 3 characters ofthe current character.?
The BIO chunk tags of the previous 3 charac-ters.4 ResultsTable 1 presents the results obtained on the MSRAand CityU development test set.
Table 2 presentsthe results obtained on theMSRA, CityU and LDCtest sets.
These numbers greatly underrepresentwhat could be expected from the boosting model,since we only used one-third of MSRA and CityUtraining corpora due to limitations of the boost-ing software.
Another problem for the LDC cor-pus was training/testing mismatch: we did nottrain any models at all with the LDC training cor-pus, which was the only training set annontatedwith geopolitical entities (GPE).
Instead, for theLDC test set, we simply used the system trainedon the MSRA corpus.
Thus, when we considerthe geopolitical entity (GPE), our low overall F-measure on the LDC test set cannot be interpretedmeaningfully.3 Even so, using only one-third ofthe training data, the results on the MSRA andCityU test sets are reasonable: 75.07 and 80.51overall F-measures were obtained on the MSRAand CityU test sets, respectively.5 ConclusionWe have described an experiment applying aboosting based NER model originally designed3Our LDC test result was scored twice by the organizer.for multiple European languages instead to theChinese named entity recognition task.
Eventhough we only used one-third of the MSRA andCityU corpora to train the system, the modelproduced reasonable results, obtaining 75.07 and80.51 overall F-measures on MSRA and CityUtest sets respectively.Having established this baseline for compari-son against our multilingual European languageboosting based NER models, our next step will beto incorporate Chinese-specific attributes into themodel to compare with.ReferencesEric Bauer and Ron Kohavi.
An empirical comparison ofvoting classification algorithms: Bagging, boosting, andvariants.
Machine Learning, 36:105?142, 1999.Xavier Carreras, Llu?
?s Ma`rquez, and Llu?
?s Padro?.
Named en-tity extraction using AdaBoost.
In Computational NaturalLanguage Learning (CoNLL-2002), at COLING-2002,pages 171?174, Taipei, Sep 2002.Gerard Escudero, Llu?
?s Ma`rquez, and German Rigau.
Boost-ing applied to word sense disambiguation.
In 11th Euro-pean Conference on Machine Learning (ECML-00), pages129?141, 2000.Yoav Freund and Robert E. Schapire.
A decision-theoreticgeneralization of on-line learning and an application toboosting.
Computer and System Sciences, 55(1):119?139,1997.David Opitz and Richard Maclin.
Popular ensemble meth-ods: An empirical study.
Journal of Artificial IntelligenceResearch, 11:169?198, 1999.Robert E. Schapire and Yoram Singer.
Improved boostingalgorithms using confidence-rated predictions.
MachineLearning, 37(3):297?336, 1999.Robert E. Schapire and Yoram Singer.
Boostexter: Aboosting-based system for text categorization.
MachineLearning, 39(2-3):135?168, 2000.Robert E. Schapire.
The boosting approach to machine learn-ing: An overview.
In MSRI workshop on Nonlinear Esti-mation and Classification, 2002.Fabrizio Sebastiani, Alessandro Sperduti, and Nicola Val-dambrini.
An improved boosting algorithm and its appli-cation to automated text categorization.
In Proceedingsof 9th ACM International Conference on Information andKnowledge Management, pages 78?85, 2000.Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, andYongsheng Yang.
Boosting for named entity recognition.In Computational Natural Language Learning (CoNLL-2002), at COLING-2002, pages 195?198, Taipei, Sep2002.Dekai Wu, Grace Ngai, and Marine Carpuat.
Why nitpickingworks: Evidence for Occam?s razor in error correctors.
In20th International Conference on Computational Linguis-tics (COLING-2004), Geneva, 2004.Hua Ping Zhang, Qun Liu, Xue-Qi Cheng, Hao Zhang, andHong Kui Yu.
Chinese lexical analysis using Hierarchi-cal Hidden Markov Model.
In Proceedings of the secondSIGHAN workshop on Chinese language processing, vol-ume 17, pages 63?70, 2003.153
