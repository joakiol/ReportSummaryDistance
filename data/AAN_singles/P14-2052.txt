Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 315?320,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsSingle Document Summarization based on Nested Tree StructureYuta Kikuchi?Tsutomu Hirao?Hiroya Takamura?
?Tokyo Institute of technology4295, Nagatsuta, Midori-ku, Yokohama, 226-8503, Japan{kikuchi,takamura,oku}@lr.pi.titech.ac.jp?NTT Communication Science Laboratories, NTT Corporation2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan{hirao.tsutomu,nagata.masaaki}@lab.ntt.co.jpManabu Okumura?Masaaki Nagata?AbstractMany methods of text summarizationcombining sentence selection and sen-tence compression have recently been pro-posed.
Although the dependency betweenwords has been used in most of thesemethods, the dependency between sen-tences, i.e., rhetorical structures, has notbeen exploited in such joint methods.
Weused both dependency between words anddependency between sentences by con-structing a nested tree, in which nodesin the document tree representing depen-dency between sentences were replaced bya sentence tree representing dependencybetween words.
We formulated a sum-marization task as a combinatorial opti-mization problem, in which the nestedtree was trimmed without losing impor-tant content in the source document.
Theresults from an empirical evaluation re-vealed that our method based on the trim-ming of the nested tree significantly im-proved the summarization of texts.1 IntroductionExtractive summarization is one well-known ap-proach to text summarization and extractive meth-ods represent a document (or a set of documents)as a set of some textual units (e.g., sentences,clauses, and words) and select their subset as asummary.
Formulating extractive summarizationas a combinational optimization problem greatlyimproves the quality of summarization (McDon-ald, 2007; Filatova and Hatzivassiloglou, 2004;Takamura and Okumura, 2009).
There has re-cently been increasing attention focused on ap-proaches that jointly optimize sentence extractionand sentence compression (Tomita et al, 2009;Qian and Liu, 2013; Morita et al, 2013; Gillickand Favre, 2009; Almeida and Martins, 2013;Berg-Kirkpatrick et al, 2011).
We can only ex-tract important content by trimming redundantparts from sentences.However, as these methods did not include thediscourse structures of documents, the generatedsummaries lacked coherence.
It is important forgenerated summaries to have a discourse struc-ture that is similar to that of the source docu-ment.
Rhetorical Structure Theory (RST) (Mannand Thompson, 1988) is one way of introduc-ing the discourse structure of a document to asummarization task (Marcu, 1998; Daum?e III andMarcu, 2002; Hirao et al, 2013).
Hirao et alrecently transformed RST trees into dependencytrees and used them for single document summa-rization (Hirao et al, 2013).
They formulated thesummarization problem as a tree knapsack prob-lem with constraints represented by the depen-dency trees.We propose a method of summarizing a singledocument that utilizes dependency between sen-tences obtained from rhetorical structures and de-pendency between words obtained from a depen-dency parser.
We have explained our method withan example in Figure 1.
First, we represent a doc-ument as a nested tree, which is composed of twotypes of tree structures: a document tree and asentence tree.
The document tree is a tree that hassentences as nodes and head modifier relationshipsbetween sentences obtained by RST as edges.
Thesentence tree is a tree that has words as nodesand head modifier relationships between wordsobtained by the dependency parser as edges.
Wecan build the nested tree by regarding each node ofthe document tree as a sentence tree.
Finally, weformulate the problem of single document sum-marization as that of combinatorial optimization,which is based on the trimming of the nested tree.315John  was  running  on  a  track  in  the  park.He  looks very tired.
Mike  said  he  is  trainning  for  a  race.The  race  is  held  on  next  month.
?Source documentJohn was running on a track in the park.He looks very tired.Mike said he is training for a race.The race is held on next month.SummaryJohn was running on a track.he is training for a race.
*The race is held on next month.EDU??
????
???
???
?0246810121416EDUselsectionsentence subtreeselectionsentenceselectionreferencesummaryNumber ofselectedsentencesfromsourcedocumentJohn  was  running  on  a  track  in  the  park.He  looks very tired.
Mike  said  he  is  training  for  a  race.The  race  is  held  next  month.
?Source documentJohn was running on a track in the park.He looks very tired.Mike said he is training for a race.The race is held next month.SummaryJohn was running on a track.he is training for a race.
*The race is held next month.Figure 1: Overview of our method.
The source document is represented as a nested tree.
Our methodsimultaneously selects a rooted document subtree and sentence subtree from each node.Our method jointly utilizes relations between sen-tences and relations between words, and extractsa rooted document subtree from a document treewhose nodes are arbitrary subtrees of the sentencetree.Elementary Discourse Units (EDUs) in RST aredefined as the minimal building blocks of dis-course.
EDUs roughly correspond to clauses.Most methods of summarization based on RST useEDUs as extraction textual units.
We convertedthe rhetorical relations between EDUs to the re-lations between sentences to build the nested treestructure.
We could thus take into account bothrelations between sentences and relations betweenwords.2 Related workExtracting a subtree from the dependency tree ofwords is one approach to sentence compression(Tomita et al, 2009; Qian and Liu, 2013; Moritaet al, 2013; Gillick and Favre, 2009).
However,these studies have only extracted rooted subtreesfrom sentences.
We allowed our model to extracta subtree that did not include the root word (Seethe sentence with an asterisk ?
in Figure 1).
Themethod of Filippova and Strube (2008) allows themodel to extract non-rooted subtrees in sentencecompression tasks that compress a single sentencewith a given compression ratio.
However, it is nottrivial to apply their method to text summariza-tion because no compression ratio is given to sen-tences.
None of these methods use the discoursestructures of documents.Daum?e III and Marcu (2002) proposed a noisy-channel model that used RST.
Although theirmethod generated a well-organized summary, nooptimality of information coverage was guaran-teed and their method could not accept large textsbecause of the high computational cost.
In addi-- The scare over Alar, a growth regulator- that makes apples redder and crunchier- but may be carcinogenic,- made consumers shy away from the Delicious,- though they were less affected than the McIntosh.Figure 2: Example of one sentence.
Each line cor-responds to one EDU.tion, their method required large sets of data to cal-culate the accurate probability.
There have beensome studies that have used discourse structureslocally to optimize the order of selected sentences(Nishikawa et al, 2010; Christensen et al, 2013).3 Generating summary from nested tree3.1 Building Nested Tree with RSTA document in RST is segmented into EDUs andadjacent EDUs are linked with rhetorical relationsto build an RST-Discourse Tree (RST-DT) that hasa hierarchical structure of the relations.
There are78 types of rhetorical relations between two spans,and each span has one of two aspects of a nu-cleus and a satellite.
The nucleus is more salientto the discourse structure, while the other span, thesatellite, represents supporting information.
RST-DT is a tree whose terminal nodes correspondto EDUs and whose nonterminal nodes indicatethe relations.
Hirao et al converted RST-DTsinto dependency-based discourse trees (DEP-DTs)whose nodes corresponded to EDUs and whoseedges corresponded to the head modifier relation-ships of EDUs.
See Hirao et al for details (Hiraoet al, 2013).Our model requires sentence-level dependency.Fortunately we can simply convert DEP-DTs toobtain dependency trees between sentences.
Wespecifically merge EDUs that belong to the samesentence.
Each sentence has only one root EDUthat is the parent of all the other EDUs in the sen-tence.
Each root EDU in a sentence has the parent316max.n?imi?jwijzijs.t.?ni?mijzij?
L; (1)xparent(i)?
xi; ?i (2)zparent(i,j)?
zij+ rij?
0; ?i, j (3)xi?
zij; ?i, j (4)?mijzij?
min(?, len(i))xi; ?i (5)?mijrij= xi; ?i (6)?j /?Rc(i)rij= 0; ?i (7)rij?
zij; ?i, j (8)rij+ zparent(i,j)?
1; ?i, j (9)riroot(i)= ziroot(i); ?i (10)?j?sub(i)zij?
xi; ?i (11)?j?obj(i)zij?
xi; ?i (12)Figure 3: ILP formulation (xi, zij, rij?
{0, 1})EDU in another sentence.
Hence, we can deter-mine the parent-child relations between sentences.As a result, we obtain a tree that represents theparent-child relations of sentences, and we can useit as a document tree.
After the document tree isobtained, we use a dependency parser to obtain thesyntactic dependency trees of sentences.
Finally,we obtain a nested tree.3.2 ILP formulationOur method generates a summary by trimming anested tree.
In particular, we extract a rooted docu-ment subtree from the document tree, and sentencesubtrees from sentence trees in the document tree.We formulate our problem of optimization in thissection as that of integer linear programming.
Ourmodel is shown in Figure 3.Let us denote by wijthe term weight of wordij (word j in sentence i).
xiis a variable thatis one if sentence i is selected as part of a sum-mary, and zijis a variable that is one if word ijis selected as part of a summary.
According to theobjective function, the score for the resulting sum-mary is the sum of the term weights wijthat areincluded in the summary.
We denote by rijthevariable that is one if word ij is selected as a rootof an extracting sentence subtree.
Constraint (1)guarantees that the summary length will be lessthan or equal to limit L. Constraints (2) and (3)are tree constraints for a document tree and sen-tence trees.
rijin Constraint (3) allows the systemto extract non-rooted sentence subtrees, as we pre-viously mentioned.
Function parent(i) returns theparent of sentence i and function parent(i, j) re-turns the parent of word ij.
Constraint (4) guaran-tees that words are only selected from a selectedsentence.
Constraint (5) guarantees that each se-lected sentence subtree has at least ?
words.
Func-tion len(i) returns the number of words in sentencei.
Constraints (6)-(10) allow the model to extractsubtrees that have an arbitrary root node.
Con-straint (6) guarantees that there is only one rootper selected sentence.
We can set the candidatefor the root node of the subtree by using constraint(7).
The Rc(i) returns a set of the nodes that arethe candidates of the root nodes in sentence i. Itreturned the parser?s root node and the verb nodesin this study.
Constraint (8) maintains consistencybetween zijand rij.
Constraint (9) prevents thesystem from selecting the parent node of the rootnode.
Constraint (10) guarantees that the parser?sroot node will only be selected when the systemextracts a rooted sentence subtree.
The root(i) re-turns the word index of the parser?s root.
Con-straints (11) and (12) guarantee that the selectedsentence subtree has at least one subject and oneobject if it has any.
The sub(i) and obj(i) returnthe word indices whose dependency tag is ?SUB?and ?OBJ?.3.3 Additional constraint for grammaticalityWe added two types of constraints to our modelto extract a grammatical sentence subtree from adependency tree:zik= zil, (13)?k?s(i,j)zik= |s(i, j)|xi.
(14)Equation (13) means that words zikand zilhaveto be selected together, i.e., a word whose depen-dency tag is PMOD or VC and its parent word, anegation and its parent word, a word whose de-pendency tag is SUB or OBJ and its parent verb,a comparative (JJR) or superlative (JJS) adjectiveand its parent word, an article (a/the) and its par-ent word, and the word ?to?
and its parent word.Equation (14) means that the sequence of wordshas to be selected together, i.e., a proper noun se-quence whose POS tag is PRP$, WP%, or POSand a possessive word and its parent word and thewords between them.
The s(i, j) returns the set ofword indices that are selected together with wordij.317Table 1: ROUGE score of each model.
Note thatthe top two rows are both our proposals.ROUGE-1Sentence subtree 0.354Rooted sentence subtree 0.352Sentence selection 0.254EDU selection (Hirao et al, 2013) 0.321LEADEDU0.240LEADsnt0.1574 Experiment4.1 Experimental SettingsWe experimentally evaluated the test collection forsingle document summarization contained in theRST Discourse Treebank (RST-DTB) (Carlson etal., 2001) distributed by the Linguistic Data Con-sortium (LDC)1.
The RST-DTB Corpus includes385 Wall Street Journal articles with RST anno-tations, and 30 of these documents also have onemanually prepared reference summary.
We set thelength constraint, L, as the number of words ineach reference summary.
The average length ofthe reference summaries corresponded to approxi-mately 10% of the length of the source document.This dataset was first used by Marcu et al forevaluating a text summarization system (Marcu,1998).
We used ROUGE (Lin, 2004) as an eval-uation criterion.We compared our method (sentence subtree)with that of EDU selection (Hirao et al, 2013).We examined two other methods, i.e., rooted sen-tence subtree and sentence selection.
These twoare different from our method in the way that theyselect a sentence subtree.
Rooted sentence subtreeonly selects rooted sentence subtrees2.
Sentenceselection does not trim sentence trees.
It simplyselects full sentences from a document tree3.
Webuilt all document trees from the RST-DTs thatwere annotated in the corpus.We set the term weight, wij, for our model as:wij=log(1 + tfij)depth(i)2, (15)where tfijis the term frequency of word ij in adocument and depth(i) is the depth of sentence1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002T072We achieved this by making Rc(i) only return theparser?s root node in Figure 7.3We achieved this by setting ?
to a very large number.i within the sentence-level DEP-DT that we de-scribed in Section 3.1.
For Constraint (5), we set?
to eight.4.2 Results and Discussion4.2.1 Comparing ROUGE scoresWe have summarized the Recall-Oriented Under-study for Gisting Evaluation (ROUGE) scores foreach method in Table 1.
The score for sentenceselection is low (0.254).
However, introducingsentence compression to the system greatly im-proved the ROUGE score (0.354).
The score isalso higher than that with EDU selection, whichis a state-of-the-art method.
We applied a multi-ple test by using Holm?s method and found thatour method significantly outperformed EDU se-lection and sentence selection.
The difference be-tween the sentence subtree and the rooted sentencesubtree methods was fairly small.
We thereforequalitatively analyzed some actual examples thatwill be discussed in Section 4.2.2.
We also exam-ined the ROUGE scores of two LEAD4methodswith different textual units: EDUs (LEADEDU)and sentences (LEADSNT).
Although LEADworks well and often obtains high ROUGE scoresfor news articles, the scores for LEADEDUandLEADSNTwere very low.4.2.2 Qualitative Evaluation of SentenceSubtree SelectionThis subsection compares the methods of subtreeselection and rooted subtree selection.
Figure 4has two example sentences for which both meth-ods selected a subtree as part of a summary.
The{?}
indicates the parser?s root word.
The [?]
indi-cates the word that the system selected as the rootof the subtree.
Subtree selection selected a root inboth examples that differed from the parser?s root.As we can see, subtree selection only selected im-portant subtrees that did not include the parser?sroot, e.g., purpose-clauses and that-clauses.
Thiscapability is very effective because we have tocontain important content in summaries withingiven length limits, especially when the compres-sion ratio is high (i.e., the method has to gener-ate much shorter summaries than the source docu-ments).4LEADmethods simply take the firstK textual units froma source document until the summary length reaches L.318Original sentence : John Kriz, a Moody?s vice president, {said} Boston Safe Deposit?s performance has beenhurt this year by a mismatch in the maturities of its assets and liabilities.Rooted subtree selection : John Kriz a Moody?s vice president [{said}] Boston Safe Deposit?s performance has beenhurt this yearSubtree selection : Boston Safe Deposit?s performance has [been] hurt this yearOriginal sentence : Recent surveys by Leo J. Shapiro & Associates, a market research firm in Chicago,{suggest} that Sears is having a tough time attracting shoppers because it hasn?t yet doneenough to improve service or its selection of merchandise.Rooted subtree selection : surveys [{suggest}] that Sears is having a timeSubtree selection : Sears [is] having a tough time attracting shoppersFigure 4: Example sentences and subtrees selected by each method.Table 2: Average number of words that individualextracted textual units contained.Subtree Sentence EDU15.29 18.96 9.984.2.3 Fragmentation of InformationMany studies that have utilized RST have simplyadopted EDUs as textual units (Mann and Thomp-son, 1988; Daum?e III and Marcu, 2002; Hirao etal., 2013; Knight and Marcu, 2000).
While EDUsare textual units for RST, they are too fine grainedas textual units for methods of extractive summa-rization.
Therefore, the models have tended to se-lect small fragments from many sentences to max-imize objective functions and have led to frag-mented summaries being generated.
Figure 2 hasan example of EDUs.
A fragmented summaryis generated when small fragments are selectedfrom many sentences.
Hence, the number of sen-tences in the source document included in the re-sulting summary can be an indicator to measurethe fragmentation of information.
We countedthe number of sentences in the source documentthat each method used to generate a summary5.The average for our method was 4.73 and its me-dian was four sentences.
In contrast, methodsof EDU selection had an average of 5.77 and amedian of five sentences.
This meant that ourmethod generated a summary with a significantlysmaller number of sentences6.
In other words, ourmethod relaxed fragmentation without decreasingthe ROUGE score.
There are boxplots of the num-bers of selected sentences in Figure 5.
Table 2 liststhe number of words in each textual unit extractedby each method.
It indicates that EDUs are shorterthan the other textual units.
Hence, the number ofsentences tends to be large.5Note that the number for the EDU method is not equal toselected textual units because a sentence in the source docu-ment may contain multiple EDUs.6We used the Wilcoxon signed-rank test (p < 0.05).John  was  running  on  a  track  in  the  park.He  looks very tired.
Mike  said  he  is  trainning  for  a  race.The  race  is  held  on  next  month.Source document                                   John was running on a track in the park.He looks very tired.Mike said he is training for a race.The race is held on next month.Summary                                              John was running on a track.he is training for a race.The race is held on next month.EDU??
????
???
???
?0246810121416EDUselsection sentence subtreeselection sentenceselection reference summaryNumber of  selectedsentencesfromsource documentFigure 5: Number of sentences that each methodselected.5 ConclusionWe proposed a method of summarizing a sin-gle document that included relations between sen-tences and relations between words.
We built anested tree and formulated the problem of summa-rization as that of integer linear programming.
Ourmethod significantly improved the ROUGE scorewith significantly fewer sentences than the methodof EDU selection.
The results suggest that ourmethod relaxed the fragmentation of information.We also discussed the effectiveness of sentencesubtree selection that did not restrict rooted sub-trees.
Although ROUGE scores are widely usedas evaluation metrics for text summarization sys-tems, they cannot take into consideration linguis-tic qualities such as human readability.
Hence, weplan to conduct evaluations with people7.We only used the rhetorical structures betweensentences in this study.
However, there were alsorhetorical structures between EDUs inside individ-ual sentences.
Hence, utilizing these for sentencecompression has been left for future work.
In addi-tion, we used rhetorical structures that were man-ually annotated.
There have been related studieson building RST parsers (duVerle and Prendinger,2009; Hernault et al, 2010) and by using suchparsers, we should be able to apply our model toother corpora or to multi-document settings.7For example, the quality question metric from the Docu-ment Understanding Conference (DUC).319ReferencesMiguel Almeida and Andre Martins.
2013.
Fastand robust compressive summarization with dual de-composition and multi-task learning.
In ACL, pages196?206, August.Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.2011.
Jointly learning to extract and compress.
InACL, pages 481?490, Portland, Oregon, USA, June.Lynn Carlson, Daniel Marcu, and Mary EllenOkurowski.
2001.
Building a discourse-tagged cor-pus in the framework of rhetorical structure theory.In SIGDIAL, pages 1?10.Janara Christensen, Mausam, Stephen Soderland, andOren Etzioni.
2013.
Towards coherent multi-document summarization.
In NAACL:HLT, pages1163?1173.Hal Daum?e III and Daniel Marcu.
2002.
A noisy-channel model for document compression.
ACL,pages 449?456.David duVerle and Helmut Prendinger.
2009.
A noveldiscourse parser based on support vector machineclassification.
In IJCNLP, pages 665?673.Elena Filatova and Vasileios Hatzivassiloglou.
2004.A formal model for information selection in multi-sentence text extraction.
In COLING.Katja Filippova and Michael Strube.
2008.
Depen-dency tree based sentence compression.
In INLG,pages 25?32.Dan Gillick and Benoit Favre.
2009.
A scalable globalmodel for summarization.
In ILP, pages 10?18.Hugo Hernault, Helmut Prendinger, David duVerle,and Mitsuru Ishizuka.
2010.
Hilda: A discourseparser using support vector machine classification.Dialogue & Discourse, 1(3):1?30.Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,Norihito Yasuda, and Masaaki Nagata.
2013.Single-document summarization as a tree knapsackproblem.
In EMNLP, pages 1515?1520.Kevin Knight and Daniel Marcu.
2000.
Statistics-based summarization - step one: Sentence compres-sion.
In National Conference on Artificial Intelli-gence (AAAI), pages 703?710.Chin-Yew Lin.
2004.
Rouge: A package for automaticevaluation of summaries.
In Proc.
ACL workshop onText Summarization Branches Out, pages 74?81.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, pages 243?281.Daniel Marcu.
1998.
Improving summarizationthrough rhetorical parsing tuning.
In In Proc.
of the6th Workshop on Very Large Corpora, pages 206?215.Ryan T. McDonald.
2007.
A study of global infer-ence algorithms in multi-document summarization.In ECIR, pages 557?564.Hajime Morita, Ryohei Sasano, Hiroya Takamura, andManabu Okumura.
2013.
Subtree extractive sum-marization via submodular maximization.
In ACL,pages 1023?1032.Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Mat-suo, and Genichiro Kikui.
2010.
Opinion summa-rization with integer linear programming formula-tion for sentence extraction and ordering.
In COL-ING, pages 910?918.Xian Qian and Yang Liu.
2013.
Fast joint compres-sion and summarization via graph cuts.
In EMNLP,pages 1492?1502.Hiroya Takamura and Manabu Okumura.
2009.
Textsummarization model based on the budgeted medianproblem.
In CIKM, pages 1589?1592.Kohei Tomita, Hiroya Takamura, and Manabu Oku-mura.
2009.
A new approach of extractive sum-marization combining sentence selection and com-pression.
IPSJ SIG Notes, pages 13?20.320
