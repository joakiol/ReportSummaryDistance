Cross Modal Comprehension i ZARDOZAn English to Sign-Language Translation SystemTony Veale and Alan ConwayHitachi Dublin Laboratory, O'Reilly Institute, Trinity College, Dublin 2, Ireland.Phone: +353-1-6798911, Fax: +353-1-6798926E-mail: Tony.
Veale@hdl.ie, Alan.Conway@hdl.ieThe sign languages used by deaf communities around the world represent a linguistic challenge thatnatural language researchers have only recently begun to take up.
Zardoz is a system which tackles thecross-modal machine-translation problem, translating speech and text into animated sign language.Native sign !languages, such as ISL (Ireland), BSL (Britain) and ASL (U.S.A.) have evolved in deafcommunities as natural methods of gestural communication.
These languages differ from English, notonly in modality, but in grammatical structure, exploiting the dimensions of space as well as time.
Thispaper presents an architectural overview of Zardoz, and describes the methods employed to analyse theverbal input and generate the corresponding signed output.I.
IntroductionThe fluid articulation of animated sign languagefrom English in'put represents a unique linguisticchallenge of cross-modal translation.
There is a sizeablebody of sign language users world-wide, for whom suchtechnology can provide valuable tools for education andinformatiort access.
From a linguistic perspective, thepursuit of cross-modal translation poses new problemsin translation and generation, and forces us to questionour conceptions of language universals.This paper describes the architecture andmethodology of the ZARDOZ multilingual signtranslation system, which is designed to translatespoken language (specifically English text) into anumber of different sign-languages, in particular ISL(Irish), ASL (American) and JSL (Japanese).The paper has the following structure: Section 2presents a brief introduction to sign languages whichplaces the problem in context.
Section 3 describes thesystem architecture of ZARDOZ.
Section 4 discussesthe conceptual Interlingua representation used intranslation.
Section 5 discusses yntactic generation,while Section 6 addresses articulation and animationissues.
Finally Section 7 summarises the present statusof the project and our future research goals.2.
Sign Language as a CommunicationMediumThere is a strong tendency among the speakingcommunity to trivialise the capacity of sign as a fullcommunication medium.
It is a common assumptionthat sign language, being iconic in nature, is a universallanguage shared by the deaf communities of the world.In fact countries which share the same spoken language(e.g.
English in the cases of Britain, Ireland andAmerica) do not necessarily employ the same form ofsign ( BSL, ISL and ASL respectively).
Certainlyiconicity plays a stronger role in sign language thansound symbolism does in spoken language but, as withany language, there is a strong tendency to move fromiconicity to arbitrariness ( ee Klima & Bellugi 1979).A second common misconception is that signlanguage is a gestural coding of spoken language.While sign languages can be employed for this type ofcoding (e.g.
SEE: Signed Exact English), native signlanguages possesses a syntax which is independent ofany spoken language, and is considerably better adaptedto manual communication.
Thus there is a genuinetranslation problem in generating native sign languagefrom English, as well as the obvious articulationproblem of generating animated signs.3.
An Overview of the ZARDOZ systemIn this section we present an overview of thesystem architecture of ZARDOZ, a modular systemorganised around a blackboard control structure(Cunningham & Veale 1991, Veale & Cunningham1992).
This blackboard is built upon the frame-basedKR-language KRELL (Veale & Smyth 1992).A process-oriented view of the system is illustratedin Figure 1, which presents the blackboardcompartmentalised into distinct panels.
Task-specificknowledge agencies (composed of autonomous, write-activated emons) communicate by reading from andwriting to these panels.Taking a clockwise tour around Figure 1, systemoperation proceeds as follows: (i) incoming text isprocessed by a swarm of Lexperts - lexical expertdemons which implement morphological rules andheuristics for recognising compound word constructs.The digested text then undergoes (ii) idiomaticreduction, before it is (iii) parsed, using a unificationgrammar, to produce a deep syntactic/semanticrepresentation.
From the unification structure a first-cutInterlingua representation is (iv) composed; but beforethis representation can be considered language-independent, metaphoric and metonymic structuresspecific to the source language are removed by (v)schematization (see Section 4).
The refined interlinguaprovides grist for the (vi) discourse tracking agency,which does anaphoric resolution, before being passed tothe generation panels of the system: (vii) the sign syntaxagency, which employs a robust scheme of spatialdependency graphs (see Section 5), and (viii) the sign2497th International Generation Workshop * Kennebunkport, Maine ?
June 21-24, 1994Schematizafion Discourse Tr.acker Sr-,_~,anizor,~t;*lo~o Correspondence ~lxN.................. ~i i I~ ........................ ~i ~ ........................... ~i '111; .. ;iiT: L ............. !iiowl ii :.
iiiiiiiiiii iN:..., iiii!/iInterlingua Composer ~ Idiomatic ~ ~ '  ~ 'Preprocessor Lexical ExpertsFigure 1: The ZARDOZ Blackboard Architecture.mapping agency, which assigns concept-to-signcorrespondences to the tokens in the interlinguastructure.
The syntax and mapping agencies transducethe interlingua structure into a flat output stream of signtokens, which are compiled into a Doll ControlLanguage (DCL) program by (ix) the DCL animator.The DCL program controls an on-screen animated oll,causing the correct gesture sequence to be articulated tothe end-user.
(Conway & Veale 1994).4.
I n ter l ingua  and  Schemat izat ionTo decouple the input and output languages,ZARDOZ adopts an lnterlingua approach (e.g.Mitamura et al1991), which places a language-independent interface between source and target.
Ratherthan attempting to construct a universal grammargeneralising over the syntactic forms of manylanguages, we take the knowledge based path ofmodelling sentence meaning in the interlingua.
Thisreflects the origins of ZARDOZ in the TWIGknowledge-acquisition system (Veale & Cunningham1992).The first-cut interlingua representation of anutterance is derived compositionally from lexeme-to-concept correspondences.
Next schematization removesconventional metonymies and metaphors as illustratedin Figure 2, which demonstrates the use of the coreEnglish metaphor POSSESSION-AS-ABSTRACT-STATE(see Veale & Keane 1992 for a discussion of thecomputational treatment of metaphor).The first-cut representation is the interlingua frameHAVE-0, with the concepts *SPEAKER* andHEADACHE-0 in the slots POSSESSOR andPOSSESSION.
Next the system looks for the mostsuitable schema for this frame, using spreadingactivation from the nodes HAVE, *SPEAKER* andHEADACHE.
On finding a suitable schema, SUFFER-FROM-AILMENT, the concepts *SPEAKER* andHEADACHE-0 are re-mapped into the slots SUFFERERand AILMENT.The importance of the schematization phase can beseen when one considers that ASL has a sign for HAVE(possession), but does not use the metaphor ofpossession for ailments.
Thus a translation from thefirst-cut representation meaning "I posses a headache"is possible, but incorrect in ASL.I have a terrible headachePossessor: *SPEAKER* \[Posession: H EADACHE-OTense: PRESENTSurface-Form: ACTIVE-VOICE~"\]11IiF1'1 a <,r.~:~h.raa e\]Sufferer: *SPEAKER* IAilment: HEADACHE-O I Tense: PRESENT Surface-Form: ACTIVE-VOICE bASL-ME ASL-INTENSE Forehead::ASL-HURTFigure 2: Example of lnterlingual representation,Schernatization, and ASL output5.
Sign Generation: Syntactic IssuesIn parsing, structure is imposed upon a flat inputstream.
Conversely, generation removes tructure froma meaning representation to produce a flat outputstream.
The heart of a generation system is a linearizerwhich selects and orders elements of the meaningrepresentation.5.1 Spatial Dependency GraphsIn this section we introduce the syntacticframework of Spatial Dependency Graphs.
An SD-graph is a partial ordering of case types from thesyntactic/semantic case ontology, which indicateswhich elements are to be selected from an interlinguastructure, and their relative order in the output stream.An SD-graph represents a syntactic ontext, orgeneral state of affairs, rather than a rule of grammar; ineffect, an SD-graph is a collection of weak rules (orpreferences) folded together.
Figure 3 depicts the SD-graph representation f some basic ASL syntax.
Thesegraphs represent stand-alone, syntactic contexts,inasmuch as they are capable of transforming (i.e.2507th International Generation Workshoplinearizing) an interlingual frame without recourse toadditional syntactic information.
(a) Core Sentence Syntax (Active Voice, Indicative Mood)(b) Basic Noun Phrase SyntaxFigure 3: SD-groph of core ASL Sign Syntax..Key: left to right arrows irmlicate Before; right to leftarrows indicate After; vertical arrows indicate SamePosition As; Grey arrows indicate Closer Proximity;Grey nodes indicate Sign Literals as opposed toconstituent types, while black nodes represent the J'~edpoints of the graph)An SD-graph is a collection of constraints forordering the elements of an interlingua frame structure.Following the constraints of Figure 3, the linearizer willplace the occupants of the AGENT and ASPECT casesbefore the predicate in the output, but will also ensurethat the ASPECT follows the AGENT and directlyprecedes the verb.As well as stand-alone syntactic ontexts there areaugmentative graphs for syntactic flourishes of surfaceform in the target language - e.g.
passive voice, andverb gapping in ASL (Figure 4).
These augmentationsare triggered by style markers in the S URFACE-FORMslot of each interlingual frame.
(a) Passive Voice (b) Verb GappingFigure 4: SD-graphs for augmentations to the coresyntax of Figure 3.When linearizing, the augmentation graph iscombined with the core syntax by pooling constraints,giving precedence to the constraints in theaugmentation graph.
The constraints of the combinedgraph are instantiated with the contents of the currentframe, and resolved relative to the fixed nodes STARTand END to produce the final linearized ordefing.5.3 Content-Dependent Syntactic ContextsThe graphs Of Figures 3 and 4 are content-independent, i.e.
are applicable to an interlingua frameregardless of its conceptual content.
It is oftennecessary to employ content-dependent contexts whichare triggered by particular elements of the interlinguastructure.
Such a context is depicted in Figure 5.Figure 5: SD-graph for WH-questions inASL?
Kennebunkport, Maine ?
June 21-24, 1994WH-quesfion words in ASL require an eyebrowsdownward facial pose for the duration of theinterrogative context (see LiddeU 1980).
Thus thecontent-dependent context of Figure 5 is associatedwith ASL-WH-QUESTION in the sign hierarchy, whereit is inherited by all ASL wh-question signs.
When thetarget ranslation contains any member of this class, thewh-quesfion context is invoked to add the appropriatefacial features.~.4 Anaphora nd Spatial DesignationAnaphoric resolution is required in translationwhenever source and target languages use differentanaphofic discrimination systems.
For instance, theEnglish "They", neutral in gender, can map onto eitherof "Elles" or "Ils" in French.
It is thus necessary toresolve the reference of a pronoun before translation, sothat the correct referring term can be generated in thetarget language.
ZARDOZ employs the basic Hobbsalgorithm for this task (see Hobbs 1978), augmentedwith discourse registers which track the movement ofreferents between peripheral and central focus.Sign language makes use of index locations inspace to refer to entities in a conversation.
Thus,locations hould be allocated sign space in such a waythat possible referential conflicts are minimised.ZARDOZ strives to allocate a different locations to themajor cases of an utterance ( .g., agent, patient), and tomaintain those assignments hroughout a narrative asfar as is possible.5.2 Word Order in SignWord order, the dominant syntactic onstraint inEnglish, has a reduced role in ASL which can alsoemploy the dimensions of space to indicate case roles(see Liddell 1980), The referents of a verb may beestablished atindex locations in signing space, and thedirection of movement of the verb between locationsthen indicates which is the agent and which the patient.For example, if B1LL is signed on the left andMARY on the fight, then a left to right motion whilesigning the verb ASL-CHASE, indicates BILL is thepursuer and MARY the pursued.
Thus using the passivevoice in ASL is simply a matter of reversing the orderof agent and patient.
Of course, the verb/predicate willnow have to be signed after both agent and patient havebeen articulated.
The SD-graph representing thistransformation is presented inFigure 4(a).6.
M0de-Interleaved Sign GenerationWe have already mentioned the distinction betweennative sign languages (e.g.
ASL) and borrowed signsystem (like SEE).
Native sign language is thedominant means of communication among deafsigners, however, borrowed sign language is often usedfor educational purposes (where hearing signers areinvolved), and for such ends as signed news summarieson television.
As a result, most native signers arecomfortable with both types of sign, and encounter littledifficulty in segueing between the two forms.This ability affords a system such as ZARDOZwith a base-level performance that can be guaranteed by2517th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994the system.
Should the source parser be unable togenerate a syntactic structure that spans the entire input,the system can still produce a full output representationby interleaving native and coded sign.
Native sign isused for those input fragments which produce case-frame interlingual representations, while the coded signis used for troublesome link words which cause theparser to fail.6.
Sign Art icu lat ion and An imat ionHaving generated a syntactic form of a signutterance it remains to create a fluid articulation of theutterance to display as an animated sequence.
In thecase of coded sign systems such as SEE this is a simplematter of mapping sign tokens to pre-stored animationsequences and smoothing over inter-sign gaps.However, native sign languages employ a much richersign structure, which requires a correspondingly richerrepresentation for the output lexicon.Native sign languages are heavily inflected, with amuch of syntactic information encoded in parallel on asingle lexeme.
One example already mentioned is theuse of verb movement to indicate agent and patient.Another example in ASL is the rich aspectual inflectionsystem employed.
For example the sign ASL-SICKwith a circular motion added means 'sickly' or'sickness prone'.
A repeated, tense motion indicates themeaning 'extremely sick'.
These and many moreinflections apply in a regular manner to ASL signs, andmay be compounded.
For example, the verb ASL-LOOK-AT can be inflected to mean 'he watches itregularly' or 'I look at each of them in turn'.Because of the richness of the inflection system, itis impractical to store every inflected form directly asan animation sequence.
We adopt the approach ofstoring signs in their citation or root form only, andstoring inflection rules separately.
Inflected signs aregenerated as needed by applying the appropriate rules tothe root sign forms.
Signs are stored using aphonological model of sign structure, based onSandler's Hand-Tier model (Sandler, 1989).
Thephonological representations are not mapped toconcrete animation values in a DCL program until afterinflection rules have been applied.7.
Summary  and Future  ResearchTo date, we have implementedthe infrastructure ofthe Zardoz system, including parsing, interlingua,generation and animation components, but have yet toimplement a comprehensive sign grammar or lexicon.The phonological model of sign structure and inflectionrules, mentioned in Section 6, is also in an early stageof development.Our current research efforts are concentrated ondeveloping more a comprehensive computationalgrammar, morphology and lexicon for ISL, the nativesign language of Ireland where our research is based.The examples in this paper are taken from ASL, aslinguistic information on ASL is more readily available,but in future work will focus on ISL, as we feel that theevaluation and advice of native signers will be crucialto the success of our research.Though our work is still in an early stage, we areconfident that the framework outlined here will providea sound basis for tackling the challenges of cross-modeltranslation.
The issues of translation between differentlanguage media holds considerable theoretical interest,but we also believe that the A.I./linguistic technology ismature nough to build systems of value to sign users inthe near future.
We hope to contribute to thedevelopment of such systems.ReferencesConway, A.
& T. Veale.
(1994).
A LinguisticApproach to Sign Language Synthesis, to be presentedat the Human Computer Interaction conference,HCI'94, Glasgow.Cunningham, P. & T. Veale.
(1991).
Organizationalissues arising from the integration of the ConceptNetwork & Lexicon in a text understanding System, inthe proceedings of the 12th International JointConference on Artificial Intelligence.
MorganKaufmann.Hobbs, J.
(1978).
Resolving Pronoun References,Lingua 44, p 311-338.Klima, E. & U. Bellugi.
(1979).
The Signs ofLanguage.
Harvard University Press.Lee, J.
& T. L. Kunii.
(1992).
Visual Translation: fromNative Language to Sign Language, in the proceedingsof the IEEE workshop on Visual Languages, SeattleWashington.Liddell, S. K. (1980).
American Sign Language Syntax.Mouton.Mitamura, T., E. H. Nyberg and J. G.
Carboneli.(1991).
An Efficient Interlingua Translation System forMulti-lingual Document Production, in the proceedingsof Machine Translation summit III, Washington D.C.,July 2-4, 1991.Patten, T. & Hartigan, J.
(1993).
AutomaticTranslation of English to American Sign Language,presented atthe 1993 National Conference on Deafness,Columbus Ohio.Sandier, W. (1989).
Phonological representation f thesign: Linearity and non linearity in American SignLanguage.
Foils Publications.Veale, T. & B. Smyth.
(1992).
KRELL: KnowledgeRepresentation E try-Level Language, the User GuideVersion 1.0.
Hitachi Dublin Laboratory TechnicalReport, HDL-TR-92-051.Veale, T. & M. T. Keane.
(1992).
ConceptualScaffolding: A spatially founded meaningrepresentation for metaphor comprehension,Computational Intelligence 8(3), p 494-519.Veale, T. & P. Cunningham.
(1992).
CompetitiveHypothesis Resolution in TWIG: A Blackboard-DrivenText-Understanding System, in the proceedings of thelOth European Conference on Artificial Intelligence,Chichester: John Wiley.252
