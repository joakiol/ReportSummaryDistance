Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 48?56,Gothenburg, Sweden, 26-27 April 2014. c?2014 Association for Computational LinguisticsGerman Compounds and Statistical Machine Translation.Can they get along?Carla Parra Escart?nUniversity of BergenBergen, Norwaycarla.parra@uib.noStephan PeitzRWTH Aachen UniversityAachen, Germanypeitz@cs.rwth-aachen.deHermann NeyRWTH Aachen UniversityAachen, Germanyney@cs.rwth-aachen.deAbstractThis  paper  reports  different  experimentscreated  to  study  the  impact  of  usinglinguistics  to  preprocess  German  com-pounds  prior  to  translation  in  StatisticalMachine  Translation  (SMT).
Compoundsare a known challenge both in MachineTranslation (MT) and Translation in gen-eral as well as in other Natural LanguageProcessing (NLP) applications.
In the caseof SMT, German compounds are split intotheir constituents to decrease the numberof  unknown words  and  improve  the  re-sults of evaluation measures like the Bleuscore.
To assess to which extent it is neces-sary to deal with German compounds as apart of preprocessing in SMT systems, wehave  tested  different  compound splittersand strategies, such as adding lists of com-pounds and their translations to the train-ing set.
This  paper  summarizes  the re-sults of our experiments and attempts toyield better translations of German nom-inal compounds into Spanish and showshow our approach improves by up to 1.4Bleu points with respect to the baseline.1 IntroductionThe pair of languages German?Spanish is not awidely researched combination in Statistical Ma-chine Translation (SMT) and yet it is a challengingone as both languages belong to different languagefamilies (Germanic and Romance) and their char-acteristics and inner structure differ greatly.
As itmay happen with other language pair combinationsinvolving a Germanic and a Romance language,when it comes to the translation of German com-pounds into Spanish, the challenge is greater thanwhen translating into other Germanic languagessuch as English.
The translation of the Germancompound does not correspond to the translationof its parts, but rather constitutes a phraseologicalstructure which must conform the Spanish gram-matical rules.
Examples 1 and 2 show the split-tings of the German compoundsWarmwasserbere-itung andW?rmer?ckgewinnungssysteme and theirtranslations into English and Spanish.
(1) WarmcalientewarmWasseraguawaterBereitungpreparaci?nproduction[ES]: ?Preparaci?n de agua caliente?
[EN]: ?Warm water production?
(2) W?rmecalorheatR?ckgewinnungrecuperaci?nrecoverys?
?SystemesistemasSystems[ES]: ?sistemas de recuperaci?n de calor?
[EN]: ?heat recovery systems?As may be observed in Examples 1 and 2, inSpanish not only there is word reordering, but alsothere is usage of other word categories such asprepositions.
While the examples above are quitesimple, the work done by researchers such as An-gele (1992), G?mez P?rez (2001) and Oster (2003)for the pair of languages German?Spanish showsthat the translational equivalences in Spanish notonly are very varied, but also unpredictable to acertain extent.
Thus, while a mere compound split-ting strategy may work for English, in the case ofSpanish further processing is required to yield thecorrect translation.According  to  Atkins  et  al.
(2001)1, complexnominals  (i.e.
nominal  compounds  and  somenominal phrases) are to be considered a specialtype of MWE because they do have some partic-ular features and to some extent they behave asa single unit because they refer to a single con-cept.
Despite focusing on another language pair1Appendix  F of  Deliverable  D2.2-D3.2  of  the  ISLEproject.48(English?Italian), in the case of our language pair(German?Spanish) a similar claim could be done.Besides, the issue of compounds being translatedinto phrases in different languages is essentially aMWE problem.In this paper, we report on the results of ourresearch facing this  particular  challenge.
Moreconcretely, Section 2 briefly discusses the prob-lem of compounds in general and Section 3 de-scribes our case of study.
Subsection 3.1 brieflydiscusses the large presence of German nominalcompounds in specialized corpora and presents theresults of a preliminary study and Subsection 3.2summarizes the state-of-the-art strategies to dealwith compounds in SMT.
Section 4 focuses on theexperiments carried out and reported here and theresults thereof are presented and discussed in Sec-tion 5.
Finally, Section 6 summarizes the findingsof our research and discusses future work.2 German CompoundsGerman compounds  may be  lexicalized  or  not.Lexicalized compounds are those which can befound  in  general  dictionaries, such  as Stra?en-lampe (?street lamp/light?
in German).
Non lex-icalized compounds are formed in a similar man-ner  to  that  of  phrases  and/or  sentences and arecoined on-the-fly (i.e.
Warmwasserbereitungsan-lagen, see  Example  3).
Non  lexicalized  com-pounds usually appear in technical and formal textsand German shows a great tendency to producethem.
In SMT, the translational correspondencesare computed from a sentence aligned training cor-pus and translation dictionaries  are  not  present.Rather, word alignment algorithms are used to pro-duce the phrase tables that will  in turn be usedto produce the translations.
Thus, although nonlexicalized compounds pose a greater  challenge(they are unpredictable), lexicalized compoundsare not distinguished either.
As this formal distinc-tion cannot be done when dealing with SMT, herewe will refer to compounds irrespectively whetherthey are lexicalized or not, unless otherwise spec-ified.Moreover, German compounds may be nouns,adjectives, adverbs and verbs, although the largestgroup is the one corresponding to nominal com-pounds.
Finally, it is also important to highlightthat sometimes more than one compound-formingphenomenon may take place subsequently to forma new, longer, compound.
Previous Example 1 isthe result of such a process, and as illustrated in Ex-ample 3 it can, in turn, be the base for a yet newercompound.
(3) warm (ADJ) + Wasser(N) =Warmwasser (N)+ Bereitung(N) =Warmwasserbereitung(N) + s + Anlagen(N) =Warmwasserbereitungsanlagen (N) [EN:warm water production systems]As may also be observed in Example 3, the wordclass of the compound is determined by the ele-ment located in the rightmost position of the com-pound (i.e.
the combination of the adjective warmand the nounWasser yields a nominal compound).Finally, it is also important to highlight that be-sides words, compounds may also include particlesto join those words together, as the ?s?
betweenWarmwasserbereitung and Anlagen in Example 3or truncations (part of one of the component wordsis deleted).
Example 4 illustrates the case whenone of the component words has been truncated:(4) abstellen(V) - en + Anlagen(N) =Abstellanlagen (N) [EN: parking facilities]The  morphology  of  German  compounds  hasbeen  widely  researched, both  within  linguistics(Fleischer, 1975; Wellman, 1984; Eichinger, 2000,among others), as in NLP (Langer, 1998; Girju etal., 2005; Marek, 2006; Girju, 2008, among oth-ers).
Here, we will focus on the impact of prepro-cessing nominal compounds in SMT.Baroni et al.
(2002) report that 47% of the vo-cabulary (types)  in  the APA corpus2were com-pounds.
As will be observed in Section 4, the com-pound splitters we used also detected a high per-centage of compounds in the corpora used in ourexperiments.
This fact confirms that it is crucial tofind a successful way of processing compounds inNLP applications and in our case in SMT.3 Case StudyThe experiments carried out here have used thetexts corresponding to the domain B00: Construc-tion of  the TRIS corpus  (Parra Escart?n, 2012),and an internally compiled version of the EuroparlCorpus (Koehn, 2005) for the pair of languagesGerman-Spanish3.
The domain (B00: Construc-tion) was selected because it is the biggest one of2Corpus of the Austria Presse Agentur (APA).
Recently ithas been released as the AMC corpus (Austrian Media Cor-pus) (Ransmayr et al., 2013).3See Table 2 for an overview of the corpus statistics.49the three domains currently available in the TRIScorpus4.
Only one domain was used because weaimed at testing in-domain translation.
Besides,the TRIS corpus was selected because it is a spe-cialised German-Spanish parallel corpus.
As op-posed to the Europarl, the TRIS corpus is divided indomains and the source and target languages havebeen verified (i.e.
the texts were originally writtenin German and translated into Spanish).
Moreover,the texts included in the Europarl are transcrip-tions of the sessions of the European Parliament,and thus the style is rather oral and less technical.As compounds tend to be more frequent in domainspecific texts, the TRIS corpus has been used fortesting, while the Europarl Corpus has been usedin the training set to avoid data scarcity problemsand increase the vocabulary coverage of the SMTsystem.In the case of Machine Translation (MT), bothrule-based MT systems (RBMT systems) and Sta-tistical MT systems (SMT systems) encounter prob-lems when dealing with compounds.
For the pur-poses of this paper, the treatment of compoundsin German has been tested within the SMT toolkitJane (Wuebker et al., 2012; Vilar et al., 2010).We have carried out several experiments translat-ing German specialized texts into Spanish to testto which extent incorporating a linguistic analy-sis of the corpora and compiling compound listsimproves the overall SMT results.
At this stage, in-cluding further linguistic information such as Part-of-Speech tagging (POS tagging) or phrase chunk-ing has been disregarded.
Forcing the translationof compounds in the phrase tables produced byJane has also been disregarded.
The overall aimwas to test how the SMT system performs using dif-ferent pre-processing strategies of the training databut without altering its mechanism.
Since it is achallenge to factor out what is really the translationof the compounds, the overall quality of the trans-lations at document level has been measured as anindirect way of assessing the quality of the com-pound translations5.
To evaluate the compoundtranslations into Spanish, these need to be man-ually validated because we currently do not haveaccess to fully automatic methods.
A qualitativeanalysis of the compound translations will be donein future work.4The domain C00A: Agriculture, Fishing and Foodstuffshas 137.354 words and the domain H00: Domestic LeisureEquipment has 58328 words).5The results of this evaluation are reported in Section 5.3.1 Preliminary studyWith the purpose of assessing the presence of com-pounds in the TRIS corpus and evaluating the split-tings at a later stage as well as the impact of suchsplittings in SMT, we analysed manually two shorttexts of the TRIS corpus.
The two files correspondto the subcorpus B30: Construction - Environmentand account for 261 sentences and 2870 words.For this  preliminary study, all  German nominalcompounds and their corresponding Spanish trans-lations were manually extracted.
Adjectival andverbal compounds were not included at this stage.Abbreviated nominal compounds (i.e.
?EKZ?
in-stead of ?Energiekennzahl?, [energy index]) werenot included either.
Table 1 offers an overview ofthe number of running words in each file withoutpunctuation, the number of nominal compoundsfound (with an indication as to which percentageof the total number of words they account for),the number of unique compounds (i.e.
compoundtypes), and the number of lexicalized and non lexi-calized compounds in total (with the percentage ofthe text they account for), and unique.
For the pur-poses of this study, all compounds found in a Ger-man monolingual dictionary were considered lex-icalized, whereas those not appearing where con-sidered non-lexicalized.As can be seen in Table 1, compound nominalsconstitute a relatively high percentage of the totalnumber of words in a text.
This is specially thecase of domain specific texts such as the ones takeninto consideration here.
We can thus assume thatfinding a way to translate compounds appropri-ately into other languages would improve the over-all quality of the translations produced by SMT.3.2 Related work: compounds in SMTRBMT systems  require  that  compounds  are  in-cluded in their dictionaries to be able to retrievethe appropriate translation in each case.
Alterna-tively, they should include a special rule for han-dling compounds which are beyond their lexicalcoverage.
On the other hand, SMT systems en-counter problems when dealing with compoundsbecause they rely on the words observed during thetraining phase.
Thus, if the compound did not ap-pear in the training set of the system its translationwill subsequently fail.
The state-of-the-art strat-egy to deal with compounds in SMT systems con-sists on splitting the compounds to reduce the num-ber of unseen words.
Previous research (Koehn50Text A Text BNumber of words 2431 439Number of comp.
265 (10.9%) 62 (14.12%)Number of unique comp.
143 25Lexicalized comp.
99 (4.07%) 18 (4.1%)Unique lexicalized comp.
63 4Not lexicalized comp.
166 (6.8%) 44 (10.06%)Unique not lexicalized comp.
80 21Table 1: Compound nominals found in the two texts taken for the preliminary study.and Knight, 2003; Popovi?
et al., 2006; Stymne,2008; Fritzinger and Fraser, 2010; Stymne et al.,2013) has shown that splitting the compounds inGerman results in better Bleu scores (Papineni etal., 2001) and vocabulary coverage (fewer ?un-known?
words).
However, the experiments car-ried out so far have also claimed that significantchanges in error measures were not to be expectedbecause the percentage of running words affectedby compound splitting was rather low (Popovi?
etal., 2006; Stymne, 2008).
As will be observed inSection 4.1, in our case the percentage of runningwords affected by compound splitting was higher.This might be due to the kind of texts used in ourexperiments.4 ExperimentsAs  mentioned  in  Section 3, for  the  experi-ments reported here two corpora have been used:the TRIS corpus  and  the  Europarl  corpus  forGerman?Spanish.
In order to focus on in-domaintranslation, only the largest subcorpus of TRIS hasbeen used.Table 2 summarizes the number of sentencesand words in our experiment setup.To reduce possible mistakes and mismatches ob-served in the corpora used in the experiments, thespelling of the German vowels named umlaut (???
)was simplified.
Thus, ?
?, ?, ?, ?, ?, ??
were trans-formed into ?Ae, Oe, Ue, ae, oe, ue?
correspond-ingly.
Also the German ???
was substituted by adouble s: ?ss?.
By doing this, words appearing inthe corpus and written differently were unified andthus their frequencies were higher.Additionally, a list of 185 German nominal com-pounds present in the training set was manually ex-tracted together with their translations into Span-ish.
If different translations had been found forthe same compound, these were included in ourlist too.
This list was used in some of our exper-iments to determine whether extracting such listshas an impact in the overall translation quality ofSMT systems.
As the texts belong to the samedomain, there was partial overlap with the com-pounds found in the test set.
However, not all com-pounds in the test set were present in the trainingcorpus and viceversa.4.1 Training environmentsTaking the normalised version of our corpus asa baseline, different training environments havebeen tested.
We designed five possible trainingenvironments in which German compounds werepreprocessed.In our first experiment (hereinafter ?compList?
),the list of manually extracted compounds was ap-pended to the end of the training set and no furtherpreprocessing was carried out.In our second experiment (hereinafter ?RWTH?
),the state-of-the-art compound splitting approachimplemented by Popovi?
et al.
(2006) was used tosplit all possible compounds.
As also implementedby Koehn and Knight (2003), this approach usesthe corpus itself to create a vocabulary that is thensubsequently used to calculate the possible split-tings in the corpus.
It has the advantage of beinga stand-alone approach which does not depend onany external resources.
A possible drawback ofthis approach would be that it relies on a large cor-pus to be able to compute the splittings.
Thus, itmay not be as efficient with smaller corpora (i.e.
ifwe were to use only the TRIS corpus, for instance).The  third  experiment  (hereinafter?RWTH+compList?)
used  the  split  corpus  pre-pared  in  our  second  experiment  (?RWTH?)
butmerged with the list of compounds that was alsoused in the first experiment.
In total, 128 of allcompounds detected by the splitter were also inour compound list.
In order to avoid noise, thecompounds present in the list were deleted from51training dev testSentences 1.8M 2382 1192Running words without punctuation (tokens) 40.8M 20K 11KVocabulary size (types) 338K 4050 2087Table 2: Corpus statistics.
The training corpus is a concatenation of the complete Europarl CorpusGerman?Spanish and a greater part of the TRIS corpus, while in dev and test only texts from theTRIS corpus were used.the list of splittings to be carried out in the corpus.Thus, after all possible splittings were calculated,those splittings that were present in the manuallycompiled compound list  were deleted to ensurethat they were not split in the corpus and remainedthe same.In the fourth experiment (hereinafter ?IMS?)
weused another compound splitter developed at theInstitut f?r Maschinelle Sprachverarbeitung of theUniversity of Stuttgart (Weller and Heid, 2012).This splitter was also developed using a frequency-based approach.
However, in this case the train-ing data consists  of  a  list  of  lemmatized word-forms together with their POS tags.
A set of rulesto model transitional elements is also used.
Whilethis splitter might be used by processing our corpuswith available tools such as TreeTagger (Schmid,1994)6and then computing frequencies, in our ex-periments we used the CELEX7database for Ger-man (Baayen et al., 1993).
This was done so be-cause CELEX is an extensive high quality lexicaldatabase which already included all the informa-tion we needed to process and did not require anyfurther preprocessing and clean up of our corpus.In  the  fifth  experiment  (hereinafter?IMS+compList?
), we repeated the same procedureof our third experiment (?RWTH+compList?
): weadded the compound list  to  our training corpusalready split, but this time using the compoundsplitter  developed  in  Stuttgart.
In  total, 125of  all  compounds  detected  by  the  splitter  werealso in our compound list.
The splitting of suchcompounds was avoided.4.2 Compounds detectedTable 3 summarizes the number of compounds de-tected by the two compound splitters and the per-centage they account for with respect to the vocab-ulary and the number of running words.6http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/7http://wwwlands2.let.kun.nl/members/As can be observed in Table 3, the percentageof compounds in the test set is considerably higherthan in the training set.
This is due to the fact thatin the test set only a subcorpus of the TRIS corpuswas used, whereas in the training corpus Europarlwas also used and as stated earlier (cf.
Subsec-tion 3.1 and table 1), domain specific corpora tendto have more compounds.
It is also noticeable thatthe compound splitter developed in Stuttgart de-tects and splits fewer compounds.
A possible ex-planation would be that Weller and Heid (2012)only split words into content words and use POStags to filter out other highly frequent words that donot create compounds.
The presence of lexicalizedcompounds in the CELEX database does not seemto have affected the accuracy of the splitter (i.e.they were not skipped by the splitter).
Finally, it isalso noticeable that the percentage of compoundsdetected in the training set is similar to the one re-ported by Baroni et al.
(2002) and referenced to inSection 2.
This seems to indicate that both splittingalgorithms perform correctly.
A thorough analy-sis of their outputs has been carried out confirm-ing this hypothesis as the accuracies of both split-ters were considerably high: 97.19% (RWTH) and97.49% IMS (Parra Escart?n, forthcoming)8.As SMT system, we  employ  the  state-of-the-art  phrase-based translation approach (Zens andNey, 2008) implemented in Jane.
The baseline istrained on the concatination of the TRIS and Eu-roparl corpus.
Word alignments are trained withfastAlign (Dyer et al., 2013).
Further, we applya 4-gram language model trained with the SRILMtoolkit (Stolcke, 2002) on the target side of thetraining corpus.
The log-linear parameter weightsare tuned with MERT (Och, 2003) on the develop-ment set (dev).
As optimization criterion we useBleu.
The parameter setting for all experimentswas the same to allow for comparisons.software/celex_gug.pdf8The analysis was done following the method proposed byKoehn and Knight (2003).52Popovic et al.
(2006) Weller and Heid (2012)Compounds in training 182334 141789% Vocabulary 54% 42%% Running words 0.4% 0.3%Compounds in test 924 444% Vocabulary 44.3% 21.3%% Running words 8.5% 4%Table 3: Number of compounds detected by each of the splitters used and the percentages they accountfor with respect to the vocabulary (types) and the number of running words (tokens) in the corpora usedin the experiments.5 ResultsTable 4 reports the results of the five training en-vironments described in Subsection 4.1 and thebaseline.
We report results in Bleu [%] and Ter[%] (Snover et al., 2006).
All reported results areaverages over three independent MERT runs, andwe evaluate statistical significance with MultEval(Clark et al., 2011).As can be observed in Table 4, adding com-pound  lists  to  the  training  set  significantly  im-proves the Bleu and Ter scores with respect to thebaseline.
This is also the case when compoundswere preprocessed and split.
Moreover, while theBleu scores for both splitters are the same whenprocessing the entire corpus, adding the compoundlist to the training corpus yields better scores.
Infact, the combination of the compound list  andthe compound splitter  developed by Weller  andHeid (2012) improves by 3.8 points in Bleu, whilethe approach by Popovi?
et al.
(2006) improves by3.4 Bleu points against Baseline.
When comparingit with compList, the improvements are of 3% and2.4% Bleu respectively.
To ensure a fair compar-ison, RWTH is defined as second baseline.
Again,we observe significant improvement over this sec-ond baseline by adding the compound list to thetraining corpus.
In terms of Bleu we gain an im-provement of up to 1.4 points.These results seem promising as they show sig-nificant improvements both in terms of Bleu andTer scores.
As  previously  mentioned  in  Sec-tion 3.2, one possible explanation to the higherBleu scores we obtained might be that the num-ber of running words affected by compound split-ting  was  higher  than  in  other  experiments  likethe  ones  carried  out  by  Popovi?
et  al.
(2006)and Stymne (2008).
Fritzinger and Fraser (2010)used a hybrid splitting algorithm which combinedthe  corpus-based  approach  and  linguistic  infor-mation and also reported better Bleu scores forGerman?English translations than splitting algo-rithms based only in corpus frequencies.
They sug-gested that fewer split compounds but better splitcould yield better results.
However, in our case thetwo splitters score the same in terms of Bleu.
Fur-ther experiments with other language pairs shouldbe carried out to test whether this is only the casewith  German?Spanish translation tasks  or  not.If this were to be confirmed, a language depen-dent approach to dealing with compounds in SMTmight then be needed.
The improvements in termsof Bleu and Ter obtained when adding the man-ually extracted compound list to our training cor-pus (particularly in the IMS+compList experiment)suggest that further preprocessing than just split-ting the compounds in the corpora would resultin  overall  better  quality  translations.
It  is  par-ticularly noticeable that while the fewest numberof unknown words occurs when using a corpus-based splitting algorithm (experiments RWTH andRWTH+compList), this does not seem to directlycorrelate with better Bleu and Ter scores.
Exper-iments IMS and IMS+compList had in fact a largernumber of unknown words and yet obtain betterscores.Table 5 reports the number of compounds of thecompound list found in the test sets across the dif-ferent experiments.
As the compound list was notpreprocessed, the number of compounds found inRWTH and IMS is smaller than those found in Base-line and compList.
In the case of RWTH+compListand IMS+compList, however, the productivity ofGerman compounds mentioned earlier in Section 2may have influenced the number of compoundsfound.
If a compound found in our compound listwas present in other compounds and those weresplit in such a way that it resulted in one of the53testExperiment Splitting Method Compound List Bleu[%]Ter[%]OOVsBaseline - no 45.9 43.9 181compList - yes 46.7 42.9 169RWTH Popovi?
et al.
(2006) no 48.3 40.8 104RWTH+compList yes 49.1 40.5 104IMS Weller and Heid (2012) no 48.3 40.5 114IMS+compList yes 49.7 39.2 114Table 4: Results for the German?Spanish TRIS data.
Statistically significant improvements with at least99% confidence over the respective baselines (Baseline and RWTH) are printed in boldface.formants being that compound, its frequency gothigher.
As can be observed, the highest number ofcorrect translations of compounds corresponds toRWTH+compList and IMS+compList.Table 6 shows the results of a sample sentencein our test set including several compounds.
Ascan be observed, in the IMS+compList experimentall compounds are correctly translated.
This seemsto indicate that the manually compiled list of com-pounds added to the training corpus helped to in-crease the probabilities of alignment of 1:n corre-spondences (German compound ?
Spanish MWE)and thus the compound translations in the phrasetables are better.6 Conclusion and future workIn this paper, we have reported the results of ourexperiments processing German compounds andcarrying out SMT tasks into Spanish.
As has beenobserved, adding manually handcrafted compoundlists to the training set significantly improves thequalitative results of SMT and therefore a way ofautomating their extraction would be desired.
Fur-thermore, a combination of splitting compoundsand adding them already aligned to their transla-tions in the training corpus yields also significantimprovements with respect to the baseline.
A qual-itative analysis is currently being done to assess thekind of improvements that come from the splittingand/or the compound list added to training.As a follow up of the experiments reported here,the compound splitters used have being evaluatedto assess their precision and recall and determinewhich splitting algorithms could be more promis-ing for SMT tasks and whether or not their qualityhas a correlation with better translations.
From theexperiments carried out so far, it seems that it maybe the case, but this shall be further explored as ourresults do not differ greatly between each other.In future work we will research whether the ap-proach suggested here also yields better results indata used by the MT community.
Obtaining bet-ter overall results would confirm that our approachis right, in which case we will research how wecan combine both strategies (compound splittingand adding compound lists and their translationsto training corpora) in a successful and automaticway.
We also intend to explore how we can doso minimizing the amount of external resourcesneeded.Obtaining positive results in these further ex-periments would suggest that a similar approachmay also yield positive results in dealing with othertypes of MWEs within SMT.AcknowledgmentsThe research reported in this paper has receivedfunding from the EU under FP7, Marie Curie Ac-tions, SP3 People ITN, grant agreement no238405(project CLARA9).
The authors would also like tothank the anonymous reviewers for their valuablecomments.ReferencesSybille  Angele.
1992.
Nominalkomposita  desDeutschen und ihre Entsprechungen im Spanischen.Eine  kontrastive  Untersuchung  anhand  von  Tex-ten aus Wirtschaft und Literatur.
iudicium verlagGmbH, M?nchen.S.
Atkins, N. Bel, P. Bouillon, T. Charoenporn, D. Gib-bon, R. Grishman, C.-R. Huan, A. Kawtrakul, N. Ide,H.-Y.
Lee, P. J. K.  Li, J. McNaught, J. Odijk,M.
Palmer, V. Quochi, R. Reeves, D. M. Sharma,V.
Sornlertlamvanich, T. Tokunaga, G. Thurmair,M.Villegas, A. Zampolli, and E. Zeiton.
2001.
Stan-dards and Best Practice for Multiligual Computa-tional Lexicons.
MILE (the Multilingual ISLE Lex-9http://clara.uib.no54Experiment Compounds (DE) Compound translations (ES)Baseline 154 48compList 154 54RWTH 85 61RWTH+compList 175 80IMS 46 57IMS+compList 173 76Table 5: Number of compounds present in our compound list found in the test set for each of the experi-ments both in German and in Spanish.
The experiments with the highest number of translations presentin our compound list are printed in boldface.Sentence type ExampleOriginal (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecksmit mindestens zwei GeschossenReference (ES) instalaciones de estacionamiento de autom?viles en garajes subterr?neoso en estacionamientos cubiertos que tengan como m?nimo dos plantasBaseline (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecksmit mindestens zwei GeschossenBaseline (ES) plazas para veh?culos en aparcamientos subterr?neos o en plantascon al menos dos pisosIMS (DE) abstellen Anlagen fuer Kraft fahren Zeuge in tief Garagen oder in Park Decksmit mindestens zwei GeschossenIMS (ES) plazas para veh?culos en aparcamientos subterr?neos o en plantascon al menos dos pisosIMS+compList (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecksmit mindestens zwei GeschossenIMS+compList (ES) instalaciones de estacionamiento para autom?viles estacionamientos cubiertosen garajes subterr?neos o en plantas con al menos dos pisosTable 6: Sample  translations  for  German?Spanish  for  the  baseline  and  the  experiments IMS andIMS+compList.
Each compound and its translation have the same format.ical Entry) Deliverable D2.2-D3.2.
ISLE project:ISLE Computational Lexicon Working Group.R.
H. Baayen, R. Piepenbrock, and H. van Rijn.
1993.The CELEX Lexical Database (CD-ROM).
Linguis-tic  Data  Consortium, University  of  Pennsylvania,Philadelphia, PA.Marco Baroni, Johannes Matiasek, and Harald Trost.2002.
Wordform- and Class-based Prediction of theComponents of German Nominal Compounds in anAAC System.
In 19th International Conference onComputational Linguistics, COLING 2002, Taipei,Taiwan, August 24 - September 1, 2002.Jonathan H.  Clark, Chris  Dyer, Alon  Lavie, andNoah A.  Smith.
2011.
Better  hypothesis  test-ing for statistical machine translation: Controllingfor  optimizer  instability.
In 49th  Annual  Meet-ing of the Association for Computational Linguis-tics:shortpapers, pages  176?181, Portland, Ore-gon, June.Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013.
A simple, fast, and effective reparameteriza-tion of ibm model 2.
In Proc.
of NAACL.Ludwig M. Eichinger.
2000.
Deutsche Wortbildung.Eine Einf?hrung.
Gunter Narr Verlag T?bingen.Wolfgang Fleischer.
1975.
Wortbildung der deutschenGegenwartssprache.
Max Niemeyer Verlag T?bin-gen, 4 edition.Fabienne Fritzinger and Alexander Fraser.
2010.
Howto  Avoid  Burning  Ducks: Combining  LinguisticAnalysis  and Corpus Statistics  for  German Com-pound Processing.
In Proceedings of the Joint FifthWorkshop on Statistical  Machine Translation andMetricsMATR, WMT ?10, pages 224?234, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Roxana Girju, Dan Moldovan, Marta Tatu, and DanielAntohe.
2005.
On  the  semantics  of  nouncompounds.
Computer  Speech  and  Language,(4):479?496.Roxana  Girju.
2008.
The  Syntax  and  Semanticsof  Prepositions  in  the  Task  of  Automatic  Inter-pretation of Nominal Phrases and Compounds: ACross-Linguistic Study.
Computational Linguistics,35(2):185?228.Carmen G?mez P?rez.
2001.
La composici?n nominalalemana desde la perspectiva textual: El compuestonominal como dificultad de traducci?n del alem?n alespa?ol.
Ph.D. thesis, Departamento de Traducci?n55e Interpretaci?n, Universidad de Salamanca, Sala-manca.Philipp  Koehn and Kevin  Knight.
2003.
Empiri-cal Methods for Compound splitting.
In Proceed-ings of the Tenth Conference of the European Chap-ter of the Association for Computational Linguistics,pages 187?193, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Philipp Koehn.
2005.
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In ConferenceProceedings: the Tenth Machine Translation Sum-mit, pages 79?86, Phuket, Thailand.Stefan Langer.
1998.
Zur morphologie und seman-tik  von  nominalkomposita.
In Tagungsband  der4.
Konferenz zur Verarbeitung nat?rlicher Sprache(KOVENS).Torsten Marek.
2006.
Analysis of German CompoundsUsing Weighted Finite State Transducers.
Technicalreport, Eberhard-Karls-Universit?t T?bingen.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
pages 160?167,Sapporo, Japan, July.Ulrike Oster.
2003.
Los t?rminos de la cer?mica enalem?n y en espa?ol.
An?lisis sem?ntico orientadoa la traducci?n de los compuestos nominales ale-manes.
Ph.D. thesis, Departament de Traducci?
iComunicaci?, Universitat Jaume I, Castell?n.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a Method for AutomaticEvaluation of Machine Translation.
IBM ResearchReport RC22176 (W0109-022), IBMResearch Divi-sion, Thomas J. Watson Research Center, P.O.
Box218, Yorktown Heights, NY 10598, September.Carla  Parra Escart?n.
2012.
Design and compila-tion of a specialized Spanish-German parallel cor-pus.
In Proceedings  of  the  Eight  InternationalConference on Language Resources and Evaluation(LREC?12), Istanbul, Turkey, May.
European Lan-guage Resources Association.Carla Parra Escart?n.
forthcoming.
Chasing the perfectsplitter: A comparison of different compound split-ting tools.
In Proceedings of the Ninth Conferenceon International Language Resources and Evalua-tion (LREC?14), Reykjavik, Island, May.
EuropeanLanguage Resources Association.Maja Popovi?, Daniel Stein, and Hermann Ney.
2006.Statistical machine translation of german compoundwords.
In Proceedings of the 5th international con-ference on Advances in Natural Language Process-ing, FinTAL?06, pages 616?624, Berlin, Heidelberg.Springer-Verlag.Jutta Ransmayr, Karlheinz Moerth, and Matej Durco.2013.
Linguistic variation in the austrian media cor-pus.
dealing with the challenges of large amounts ofdata.
In Proceedings of International Conference onCorpus Linguistics (CILC), Alicante.
University Al-icante, University Alicante.Helmut Schmid.
1994.
Probabilistic Part-of-SpeechTagging  Using  Decision  Trees.
In InternationalConference on New Methods in Language Process-ing, pages 44?49, Manchester, UK.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings of the 7th Conference of the As-sociation for Machine Translation in the Americas,pages 223?231, Cambridge, Massachusetts, USA,August.Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
In Proc.
of the Int.
Conf.on Speech and Language Processing (ICSLP), vol-ume 2, pages 901?904, Denver, CO, September.Sara Stymne, Nicola Cancedda, and Lars Ahrenberg.2013.
Generation of Compound Words in StatisticalMachine Translation into Compounding Languages.Computational Linguistics, pages 1?42.Sara  Stymne.
2008.
German Compounds in  Fac-tored Statistical Machine Translation.
InGoTAL?08:Proceedings of the 6th international conference onAdvances in Natural Language Processing, pages464?475.
Springer-Verlag.David Vilar, Daniel  Stein, Matthias Huck, and Her-mann Ney.
2010.
Jane: open source hierarchi-cal translation, extended with reordering and lexi-con models.
In Proceedings of the Joint Fifth Work-shop on Statistical Machine Translation and Met-ricsMATR, WMT ?10, pages 262?270, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Marion Weller and Ulrich Heid.
2012.
Analyzingand Aligning German compound nouns.
In Pro-ceedings of the Eight International Conference onLanguage Resources and Evaluation (LREC?12), Is-tanbul, Turkey, May.
European Language ResourcesAssociation.Hans Wellman, 1984.
DUDEN.
Die Grammatik.
Un-entbehrlich f?r richtiges Deutsch, volume 4, chapterDie Wortbildung.
Duden Verlag.Joern Wuebker, Matthias Huck, Stephan Peitz, MalteNuhn, Markus  Freitag, Jan-Thorsten  Peter, SaabMansour, and Hermann Ney.
2012.
Jane 2: Opensource phrase-based and hierarchical statistical ma-chine translation.
In International Conference onComputational Linguistics, pages 483?491, Mum-bai, India, December.Richard Zens and Hermann Ney.
2008.
Improvementsin Dynamic Programming Beam Search for Phrase-based Statistical Machine Translation.
In Interna-tional Workshop on Spoken Language Translation,pages 195?205, Honolulu, Hawaii, October.56
