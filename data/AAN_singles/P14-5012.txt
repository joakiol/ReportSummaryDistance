Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 67?72,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsWoSIT: A Word Sense Induction Toolkitfor Search Result Clustering and DiversificationDaniele Vannella, Tiziano Flati and Roberto NavigliDipartimento di InformaticaSapienza Universit`a di Roma{vannella,flati,navigli}@di.uniroma1.itAbstractIn this demonstration we present WoSIT,an API for Word Sense Induction (WSI)algorithms.
The toolkit provides imple-mentations of existing graph-based WSIalgorithms, but can also be extended withnew algorithms.
The main mission ofWoSIT is to provide a framework for theextrinsic evaluation of WSI algorithms,also within end-user applications such asWeb search result clustering and diversifi-cation.1 IntroductionThe Web is by far the world?s largest informationarchive, whose content ?
made up of billions ofWeb pages ?
is growing exponentially.
Unfortu-nately the retrieval of any given piece of infor-mation is an arduous task which challenges evenprominent search engines such as those developedby Google, Yahoo!
and Microsoft.
Even today,such systems still find themselves up against thelexical ambiguity issue, that is, the linguistic prop-erty due to which a single word may convey dif-ferent meanings.It has been estimated that around 4% of Webqueries and 16% of the most frequent queries areambiguous (Sanderson, 2008).
A major issue as-sociated with the lexical ambiguity phenomenonon the Web is the low number of query words sub-mitted by Web users to search engines.
A pos-sible solution to this issue is the diversification ofsearch results obtained by maximizing the dissimi-larity of the top-ranking Web pages returned to theuser (Agrawal et al., 2009; Ashwin Swaminathanand Kirovski, 2009).
Another solution consists ofclustering Web search results by way of clusteringengines such as Carrot1and Yippy2and presentingthem to the user grouped by topic.1http://search.carrot2.org2http://yippy.comDiversification and Web clustering algorithms,however, do not perform any semantic analysis ofsearch results, clustering them solely on the basisof their lexical similarity.
Recently, it has beenshown that the automatic acquisition of the mean-ings of a word of interest, a task referred to asWord Sense Induction, can be successfully inte-grated into search result clustering and diversifica-tion (Navigli and Crisafulli, 2010; Di Marco andNavigli, 2013) so as to outperform non-semanticstate-of-the-art Web clustering systems.In this demonstration we describe a new toolkitfor Word Sense Induction, called WoSIT, whichi) provides ready implementations of existingWSI algorithms; ii) can be extended with addi-tional WSI algorithms; iii) enables the integrationof WSI algorithms into search result clusteringand diversification, thereby providing an extrinsicevaluation tool.
As a result the toolkit enables theobjective comparison of WSI algorithms within anend-user application in terms of the degree of di-versification of the search results of a given am-biguous query.2 WoSITIn Figure 1 we show the workflow of the WoSITtoolkit, composed of three main phases: WSI;semantically-enhanced search result clusteringand diversification; evaluation.
Given a targetquery q whose meanings we want to automati-cally acquire, the toolkit first builds a graph for q,obtained either from a co-occurrence database, orconstructed programmatically by using any user-provided input.
The co-occurrence graph is theninput to a WSI algorithm, chosen from amongthose available in the toolkit or implemented bythe user.
As a result, a set of word clustersis produced.
This concludes the first phase ofthe WoSIT workflow.
Then, the word clustersproduced are used for assigning meanings to thesearch results returned by a search engine for thequery q, i.e.
search result disambiguation.
The67+ MANUAL ANNOTATIONSDBDBSearch resultdisambiguationw1w3w2w4w5w6 s4s5s1 s3s2Eval ResultsWord ClustersWSIAlgorithm WSI EvaluatorAssignment of results to clustersCo-occurrence graphCo-occurrence Information Web search engineWSI Semantically EnhancedSearch Result ClusteringDatasetEvaluationFigure 1: The WoSIT workflow.outcome is that we obtain a clustering of searchresults.
Finally, during the third phase, we applythe evaluation module which performs an evalua-tion of the search result clustering quality and thediversification performance.We now describe in detail the three main phasesof WoSIT.2.1 Word Sense InductionThe first phase of WoSIT consists of the automaticidentification of the senses of a query of inter-est, i.e.
the task of Word Sense Induction.
Al-though WoSIT enables the integration of customimplementations which can potentially work withany WSI paradigm, the toolkit provides ready-to-use implementations of several graph-based algo-rithms that work with word co-occurrences.
Allthese algorithms carry out WSI in two steps: co-occurrence graph construction (Section 2.1.1) anddiscovery of word senses (Section 2.1.2).2.1.1 Co-occurrence graph constructionGiven a target query q, we build a co-occurrencegraph Gq= (V,E) such that V is the set ofwords co-occurring with q and E is the set of undi-rected edges, each denoting a co-occurrence be-tween pairs of words in V .
In Figure 2 we showan example of a co-occurrence graph for the targetword excalibur.WoSIT enables the creation of the co-occurrence graph either programmatically, byadding edges and vertices according to any user-specific algorithm, or starting from the statis-tics for co-occurring words obtained from a co-occurrence database (created, e.g., from a text cor-pus, as was done by Di Marco and Navigli (2013)).In either case, weights for edges have to be pro-vided in terms of the correlation strength betweenpairs of words (e.g.
using Dice, Jaccard or otherco-occurrence measures).The information about the co-occurrencedatabase, e.g.
a MySQL database, is providedprogrammatically or via parameters in the prop-erties configuration file (db.properties).The co-occurrence database has to follow agiven schema provided in the toolkit docu-mentation.
An additional configuration file(wosit.properties) also allows the userto specify additional constraints, e.g.
theminimum weight value of co-occurrence (thewordGraph.minWeight parameter) to beadded as edges to the graph.The graphs produced can also be saved to binary(i.e.
serialized) or text file:g.saveToSer(fileName);g = WordGraph.loadFromSer(fileName);g.saveToTxt(fileName);g = WordGraph.loadFromTxt(fileName);We are now ready to provide our co-occurrencegraph, created with just a few lines of code, as in-put to a WSI algorithm, as will be explained in thenext section.2.1.2 Discovery of Word SensesOnce the co-occurrence graph for the query q isbuilt, it can be input to any WSI algorithm whichextends the GraphClusteringAlgorithmclass in the toolkit.
WoSIT comes with a numberof ready-to-use such algorithms, among which:68CarLimousineKing ArthurExcaliburFilmFantasyBook0.020.0150.0250.0050.040.0060.0070.010.0130.0120.02Figure 2: Example of a co-occurrence graph forthe word excalibur.?
Balanced Maximum Spanning Tree (B-MST) (Di Marco and Navigli, 2013), an ex-tension of a WSI algorithm based on thecalculation of a Maximum Spanning Tree(Di Marco and Navigli, 2011) aimed at bal-ancing the number of co-occurrences in eachsense cluster.?
HyperLex (V?eronis, 2004), an algorithmwhich identifies hubs in co-occurrencegraphs, thereby identifying basic meaningsfor the input query.?
Chinese Whispers (Biemann, 2006), a ran-domized algorithm which partitions nodes bymeans of the iterative transfer of word senseinformation across the co-occurrence graph(Biemann, 2006).?
Squares, Triangles and Diamonds(SquaT++) (Di Marco and Navigli, 2013),an extension of the SquaT algorithm (Navigliand Crisafulli, 2010) which exploits threecyclic graph patterns to determine anddiscard those vertices (or edges) with weakdegree of connectivity in the graph.We also provide an implementation of a wordclustering algorithm, i.e.
Lin98 (Lin, 1998),which does not rely on co-occurrence graphs, butjust on the word co-occurrence information to it-eratively refine word clusters on the basis of their?semantic?
relationships.A programmatic example of use of the B-MSTWSI algorithm is as follows:BMST mst = new BMST(g);mst.makeClustering();Clustering wordClusters =mst.getClustering();where g is a co-occurrence graph created as ex-plained in Section 2.1.1, provided as input tothe constructor of the algorithm?s class.
ThemakeClustering method implements the in-duction algorithm and creates the word clus-ters, which can then be retrieved calling thegetClustering method.
As a result an in-stance of the Clustering class is provided.As mentioned above, WoSIT also enablesthe creation of custom WSI implementa-tions.
This can be done by extending theGraphClusteringAlgorihm abstract class.The new algorithm just has to implement twomethods:public void makeClustering();public Clustering getClustering();As a result, the new algorithm is readily inte-grated into the WoSIT toolkit.2.2 Semantically-enhanced Search ResultClustering and DiversificationWe now move to the use of the induced senses ofour target query q within an application, i.e.
searchresult clustering and diversification.Search result clustering.
The next step (cf.
Fig-ure 1) is the association of the search results re-turned by a search engine for query q with the mostsuitable word cluster (i.e.
meaning of q).
This canbe done in two lines:SnippetAssociator associator =SnippetAssociator.getInstance();SnippetClustering clustering =associator.associateSnippet(targetWord,searchResults,wordClusters,AssociationMetric.DEGREE_OVERLAP);The first line obtains an instance of the classwhich performs the association between search re-sult snippets and the word clusters obtained fromthe WSI algorithm.
The second line calls the asso-ciation method associateSnippet which in-puts the target word, the search results obtainedfrom the search engine, the word clusters and, fi-nally, the kind of metric to use for the associa-tion.
Three different association metrics are im-plemented in the toolkit:?
WORD OVERLAP performs the association bymaximizing the size of the intersection be-tween the word sets in each snippet and theword clusters;?
DEGREE OVERLAP performs the associationby calculating for each word cluster the sum69of the vertex degrees in the co-occurrencegraph of the words occurring in each snippet;?
TOKEN OVERLAP is similar in spirit toWORD OVERLAP, but takes into account eachtoken occurrence in the snippet bag of words.Search result diversification.
The above twolines of code return a set of snippet clusters and, asa result, semantically-enhanced search result clus-tering is performed.
At the end, the resulting clus-tering can be used to provide a diversified rerank-ing of the results:List<Snippet> snippets =clustering.diversify(sorter);The diversify method returns a flat list ofsnippet results obtained according to the Sorterobject provided in input.
The Sorter abstractclass is designed to rerank the snippet clusters ac-cording to some predefined rule.
For instance, theCardinalitySorter class, included in thetoolkit, sorts the clusters according to the size ofeach cluster.
Once a sorting order has been es-tablished, an element from each snippet cluster isadded to an initially-empty list; next, a second el-ement from each cluster is added, and so on, untilall snippets are added to the list.The sorting rules implemented in the toolkit are:?
CardinalitySorter: sorts the clustersaccording to their size, i.e.
the number of ver-tices in the cluster;?
MeanSimilaritySorter: sorts the clus-ters according to the average associationscore between the snippets in the cluster andthe backing word cluster (defined by the se-lected association metrics).Notably, the end user can then implement his orher own custom sorting procedure by simply ex-tending the Sorter class.2.2.1 Search Result DatasetsThe framework comes with two search resultdatasets of ambiguous queries: the AMBI-ENT+MORESQUE dataset made available byBernardini et al.
(2009) and Navigli and Crisa-fulli (2010), respectively, and the SemEval-2013-Task11 dataset.3New result datasets can be pro-vided by users complying with the dataset formatdescribed below.3For details visit http://lcl.uniroma1.it/wosit/.A search result dataset in WoSIT is made up ofat least two files:?
topics.txt, which contains the queries(topics) of interest together with their nu-meric ids.
For instance:id description1 polaroid2 kangaroo3 shakira... ...?
results.txt, which lists the search re-sults for each given query, in terms of URL,page title and page snippet:ID url title snippet1.1 http://www.polaroid.com/ Polaroid | Home ...1.2 http://www.polaroid.com/products products...1.3 http://en.wikipedia.org/wiki/Polaroid_Cor......
...Therefore, the two files provide the queries and thecorresponding search results returned by a searchengine.
In order to enable an automatic evaluationof the search result clustering and diversificationoutput, two additional files have to be provided:?
subTopics.txt, which for each queryprovides the list of meanings for that query,e.g.
:ID description1.1 Polaroid Corporation, a multinational con...1.2 Instant film photographs are sometimes kn...1.3 Instant camera (or Land camera), sometime...... ...?
STRel.txt, which provides the manual as-sociations between each search result and themost suitable meaning as provided in thesubTopics.txt file.
For instance:subTopicID resultID1.1 1.11.1 1.21.1 1.3... ...2.3 WSI EvaluatorAs shown in Figure 1 the final component of ourworkflow is the evaluation of WSI when integratedinto search result clustering and diversification (al-ready used by Navigli and Vannella (2013)).
Thiscomponent, called the WSI Evaluator, takes asinput the snippet clusters obtained for a givenquery together with the fully annotated search re-sult dataset, as described in the previous section.Two kinds of evaluations are carried out, describedin what follows.701 Dataset searchResults = Dataset.getInstance();2 DBConfiguration db = DBConfiguration.getInstance();3 for(String targetWord : dataset.getQueries())4 {5 WordGraph g = WordGraph.createWordGraph(targetWord, searchResults, db);6 BMST mst = new BMST(g);7 mst.makeClustering();8 SnippetAssociator snippetAssociator = SnippetAssociator.getInstance();9 SnippetClustering snippetClustering = snippetAssociator.associateSnippet(10 targetWord, searchResults, mst.getClustering(), AssociationMetric.WORD_OVERLAP);11 snippetClustering.export("output/outputMST.txt", true);12 }13 WSIEvaluator.evaluate(searchResults, "output/outputMST.txt");Figure 3: An example of evaluation code for the B-MST clustering algorithm.2.3.1 Evaluation of the clustering qualityThe quality of the output produced bysemantically-enhanced search result cluster-ing is evaluated in terms of Rand Index (Rand,1971, RI), Adjusted Rand Index (Hubert andArabie, 1985, ARI), Jaccard Index (JI) and,finally, precision and recall as done by Crabtree etal.
(2005), together with their F1 harmonic mean.2.3.2 Evaluation of the clustering diversityTo evaluate the snippet clustering diversity themeasures of S-recall@K and S-precision@r (Zhaiet al., 2003) are calculated.
These measures de-termine how many different meanings of a queryare covered in the top-ranking results shown to theuser.
We calculate these measures on the output ofthe three different association metrics illustrated inSection 2.2.3 A Full ExampleWe now show a full example of usage of theWoSIT API.
The code shown in Figure 3 initiallyobtains a search result dataset (line 1), selects adatabase (line 2) and iterates over its queries (line3).
Next, a co-occurrence graph for the currentquery is created from a co-occurrence database(line 5) and an instance of the B-MST WSI algo-rithm is created with the graph as input (line 6).After executing the algorithm (line 7), the snippetsfor the given query are clustered (lines 8-10).
Theresulting snippet clustering is appended to an out-put file (line 11).
Finally, the WSI evaluator is runon the resulting snippet clustering using the givendataset (line 13).3.1 ExperimentsWe applied the WoSIT API to the AMBI-ENT+MORESQUE dataset using 4 induction al-AlgorithmAssoc.
Web1Tmetr.
ARI JI F1 # cl.SquaT++WO 69.65 75.69 59.19 2.1DO 69.21 75.45 59.19 2.1TO 69.67 75.69 59.19 2.1B-MSTWO 60.76 71.51 64.56 5.0DO 66.48 69.37 64.84 5.0TO 63.17 71.21 64.04 5.0HyperLexWO 60.86 72.05 65.41 13.0DO 66.27 68.00 71.91 13.0TO 62.82 70.87 65.08 13.0Chinese WhispersWO 67.75 75.37 60.25 12.5DO 65.95 69.49 70.33 12.5TO 67.57 74.69 60.50 12.5Table 1: Results of WSI algorithms with a Web1Tco-occurrence database and the three associationmetrics (Word Overlap, Degree Overlap and To-ken Overlap).
The reported measures are Ad-justed Rand Index (ARI), Jaccard Index (JI) andF1.
We also show the average number of clustersper query produced by each algorithm.gorithms among those available in the toolkit,where co-occurrences were obtained from theGoogle Web1T corpus (Brants and Franz, 2006).In Table 1 we show the clustering quality resultsoutput by the WoSIT evaluator, whereas in Fig-ure 4 we show the diversification performance interms of S-recall@K.3.2 ConclusionsIn this demonstration we presented WoSIT, a full-fledged toolkit for Word Sense Induction algo-rithms and their integration into search result clus-tering and diversification.
The main contributionsare as follows: first, we release a Java API forperforming Word Sense Induction which includesseveral ready-to-use implementations of existingalgorithms; second, the API enables the use of theacquired senses for a given query for enhancing710.20.30.40.50.60.70.80.91.02.0 4.0 6.0 8.0 10.0 12.0 14.0 16.0 18.0 20.0S-recall-at-KKHyperLexBMSTChineseWSquaT++Figure 4: S-recall@K performance.search result clustering and diversification; third,we provide an evaluation component which, givenan annotated dataset of search results, carries outdifferent kinds of evaluation of the snippet cluster-ing quality and diversity.WoSIT is the first available toolkit which pro-vides an end-to-end approach to the integration ofWSI into a real-world application.
The toolkit en-ables an objective comparison of WSI algorithmsas well as an evaluation of the impact of apply-ing WSI to clustering and diversifying search re-sults.
As shown by Di Marco and Navigli (2013),this integration is beneficial and allows outperfor-mance of non-semantic state-of-the-art Web clus-tering systems.The toolkit, licensed under a Creative Com-mons Attribution-Non Commercial-Share Alike3.0 License, is available at http://lcl.uniroma1.it/wosit/.ReferencesRakesh Agrawal, Sreenivas Gollapudi, Alan Halver-son, and Samuel Ieong.
2009.
Diversifying searchresults.
In Proc.
of the Second International Confer-ence on Web Search and Web Data Mining (WSDM2009), pages 5?14, Barcelona, Spain.Cherian V. Mathew Ashwin Swaminathan and DarkoKirovski.
2009.
Essential Pages.
In Proc.
of the2009 IEEE/WIC/ACM International Joint Confer-ence on Web Intelligence and Intelligent Agent Tech-nology, volume 1, pages 173?182.Andrea Bernardini, Claudio Carpineto, and Massim-iliano D?Amico.
2009.
Full-Subtopic Retrievalwith Keyphrase-Based Search Results Clustering.In Proc.
of Web Intelligence 2009, volume 1, pages206?213, Los Alamitos, CA, USA.Chris Biemann.
2006.
Chinese Whispers - an Effi-cient Graph Clustering Algorithm and its Applica-tion to Natural Language Processing Problems.
InProc.
of TextGraphs: the First Workshop on GraphBased Methods for Natural Language Processing,pages 73?80, New York City.Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gram, ver.
1, LDC2006T13.
In Linguistic Data Con-sortium, Philadelphia, USA.Daniel Crabtree, Xiaoying Gao, and Peter Andreae.2005.
Improving web clustering by cluster selec-tion.
In Proc.
of the 2005 IEEE/WIC/ACM Interna-tional Conference on Web Intelligence, pages 172?178, Washington, DC, USA.Antonio Di Marco and Roberto Navigli.
2011.
Clus-tering Web Search Results with Maximum SpanningTrees.
In Proc.
of the XIIth International Confer-ence of the Italian Association for Artificial Intelli-gence (AI*IA), pages 201?212, Palermo, Italy.Antonio Di Marco and Roberto Navigli.
2013.
Clus-tering and Diversifying Web Search Results withGraph-Based Word Sense Induction.
Computa-tional Linguistics, 39(3):709?754.Lawrence Hubert and Phipps Arabie.
1985.
Compar-ing Partitions.
Journal of Classification, 2(1):193?218.Dekang Lin.
1998.
Automatic Retrieval and Cluster-ing of Similar Words.
In Proc.
of the 17thInter-national Conference on Computational linguistics(COLING), pages 768?774, Montreal, Canada.Roberto Navigli and Giuseppe Crisafulli.
2010.
In-ducing Word Senses to Improve Web Search ResultClustering.
In Proc.
of the 2010 Conference on Em-pirical Methods in Natural Language Processing,pages 116?126, Boston, USA.Roberto Navigli and Daniele Vannella.
2013.SemEval-2013 Task 11: Evaluating Word Sense In-duction & Disambiguation within An End-User Ap-plication.
In Proc.
of the 7thInternational Work-shop on Semantic Evaluation (SemEval 2013), inconjunction with the Second Joint Conference onLexical and Computational Semantics (*SEM 2013),pages 193?201, Atlanta, USA.William M. Rand.
1971.
Objective criteria for the eval-uation of clustering methods.
Journal of the Ameri-can Statistical association, 66(336):846?850.Mark Sanderson.
2008.
Ambiguous queries: test col-lections need more sense.
In Proc.
of the 31st an-nual international ACM SIGIR conference on Re-search and development in information retrieval,pages 499?506, Singapore.Jean V?eronis.
2004.
HyperLex: lexical cartographyfor information retrieval.
Computer, Speech andLanguage, 18(3):223?252.ChengXiang Zhai, William W. Cohen, and John Laf-ferty.
2003.
Beyond independent relevance: Meth-ods and evaluation metrics for subtopic retrieval.
InProc.
of the 26th annual international ACM SIGIRconference on Research and development in infor-mation retrieval, pages 10?17, Toronto, Canada.72
