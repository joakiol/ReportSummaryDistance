Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 109?112,Prague, June 2007. c?2007 Association for Computational LinguisticsCITYU-HIF: WSD with Human-Informed Feature PreferenceOi Yee KwongLanguage Information Sciences Research CentreCity University of Hong KongTat Chee Avenue, Kowloon, Hong Kongrlolivia@cityu.edu.hkAbstractThis paper describes our word sense dis-ambiguation (WSD) system participating inthe SemEval-2007 tasks.
The core systemis a fully supervised system based on a Na-?ve Bayes classifier using multiple knowl-edge sources.
Toward a larger goal of in-corporating the intrinsic nature of individ-ual target words in disambiguation, thus in-troducing a cognitive element in automaticWSD, we tried to fine-tune the results ob-tained from the core system with human-informed feature preference, and comparedit with automatic feature selection as com-monly practised in statistical WSD.
De-spite the insignificant improvement ob-served in this preliminary attempt, moresystematic analysis remains to be done fora cognitively plausible account of the fac-tors underlying the lexical sensitivity ofWSD, which would inform and enhancethe development of WSD systems in return.1 IntroductionIn recent years, many research teams all over theworld have gained rich experience on word sensedisambiguation (WSD) from the shared tasks ofthe SENSEVAL workshops.
The need for multipleknowledge sources has become a golden rule, andthe ?lexical sensitivity?
once remarked by Resnikand Yarowsky (1997) is addressed by variousmeans in statistical classifiers, such as learning anoptimal combination of the various knowledgesources for individual target words (e.g.
Mihalcea,2002; Escudero et al, 2004).
Another commonpractice is to use an ensemble of classifiers.
Aspointed out by Mihalcea et al (2004), among theparticipating systems in the SENSEVAL-3 Englishlexical sample task, ?several of the top perform-ance systems are based on combination of multipleclassifiers, which shows once again that votingscheme that combine several learning algorithmsoutperform the accuracy of individual classifiers?.However, the advancement in WSD is rarely ac-companied by any extensive account on the cogni-tive aspects of the task or qualitative analysis ofthe relation between the disambiguation results andthe nature of individual target words underlyingthe apparent lexical sensitivity of the task.Given that humans apparently use differentstrategies in making sense of words, it might bebeneficial to have such cognitive aspects, includingthe type and strength of various kinds of semanticassociation, realised in NLP systems explicitly.Thus in addition to an optimal combination of clas-sifiers alone, to better understand the contributionof different information types for different types oftarget words, it is important to look at WSD in re-lation to the very intrinsic nature of individual tar-get words, which could comprise many factorssuch as frequency, abstractness, sense relatednessand parts-of-speech (POS).
We thus use the con-cept Information Susceptibility (Kwong, 2005) torefer to the relationship between the intrinsic fea-tures of a target word and its senses, and the effec-tiveness of various lexical information to charac-terise them.Our current participation in SemEval-2007 isthus intended as a means toward a larger goal, i.e.,to incorporate a cognitive element into automaticWSD systems.
In particular, we tried to fine-tunethe results obtained from the core system with hu-man-informed feature preference.In Section 2, we will briefly describe the imple-mentation of our disambiguation system and thefeatures used.
In Section 3 we will discuss the109human input on the target nature and the informa-tiveness of various features.
The experiments andresults are presented in Section 4, followed by aconclusion in Section 5.2 System Description2.1 Core ClassifierThe core system is a fully supervised one based ona Na?ve Bayes classifier.
We made use of theWeka API (Witten and Frank, 2005) in ourimplementation.
According to Yarowsky andRadu (2002), Bayesian classifiers belong to one ofthe aggregative models which depend heavily onthe multiple reinforcing feature clues obtainablefrom wide context.
Thus we use all featuresdescribed in Section 2.2 below for our core system.2.2 Knowledge SourcesOnly the training data provided by the task organ-isers was used to train the system.
We used fourmajor types of contextual features, which could beclassified into Target features, Local features,Topical features and Syntactic features, as de-scribed in Table 1.
All features were converted tobinary features.2.3 Feature SelectionOn top of the core system, we tested two value-added steps to accommodate for the lexical sensi-tivity of WSD.
One is automatic feature selection(AFS), for which we used CfsSubsetEval (correla-tion-based feature selection) as implemented inWeka, based on the training samples of each targetword.
The other is human-informed feature pref-erence (HIF), for which we ran another Na?veBayes classifier in parallel with a feature subsetdeemed informative by human judges to fine-tunethe disambiguation results obtained from the coresystem (see Sections 3 and 4 below).3 Intrinsic Nature of Target WordsLeacock et al (1998), for example, observed that?the benefits of adding topical to local contextalone depend on syntactic category as well as onthe characteristics of the individual word?.
Inother words, some target words happen to be more?topical?
than others and might therefore be moresusceptible to topical contextual features duringdisambiguation.
Others, however, might only beoptimally disambiguated with other types of in-formation.Target FeaturesW0  Word form of the target wordP0 POS of the target wordLocal FeaturesP-2P-1P+1P+2POS of words at fixed positionsfrom the target word, includingthe first and second word on itsleft and the first and second wordon its rightW-2W-1W+1W+2Word forms of the words at fixedpositions from the target word,including the first and secondword on its left and the first andsecond word on its rightTopical FeaturesW-10?W+10 Content words appearing withinthe window of ten words on eachside of the target wordSyntactic FeaturesP-2 P0P-1 P0P0 P+1P0 P+2POS bigrams composed of thetarget word and its neighbouringwords, the non-immediate P-2 P0and P0 P+2 are included to ac-commodate for some flexibilityP-2 P-1 P0P0 P+1 P+2POS trigrams composed of thetarget word and its neighbouringwordsTable 1  Features Used in the Na?ve Bayes ClassiferWhile statistical WSD has more or less reachedits ceiling, it is assumed that a more thorough un-derstanding of the effectiveness of different typesof lexical information for characterising a wordsense and distinguishing it from others should beable to further inform and enhance the develop-ment of WSD systems.
To this end, three under-graduate linguistics students in the City Universityof Hong Kong were asked to go through the train-ing data for the Chinese lexical sample task inSENSEVAL-3 and that for the multilingual Chi-nese-English lexical sample task (Task 5) in Se-mEval-2007.
For each sense of a given targetword, they were asked to rate the difficulty, ab-stractness, and topicality of the sense on a 3-pointscale.
At the same time, they were asked to indi-110cate the type of information, among local POS,local words, and contextual words (i.e.
the topicalfeatures in Table 1), which they reckon to be mostuseful for disambiguating a given sample of thetarget word.1While the information collected from the humanjudges is pending in-depth analysis, the featurepreference indicated by them was used to fine-tunethe results obtained from our core system.
Duringdisambiguation, we run two Na?ve Bayes classifi-ers in parallel, the core one on all features above,and the other only on the type of informationdeemed most useful by two or more of the humanjudges, and use the latter to adjust the results fromthe former, as further discussed in Section 4.2.4 Experiment and Results4.1 DatasetsWe participated in the Multilingual Chinese-English Lexical Sample Task (Task 5) and theEnglish Lexical Sample Task via English-ChineseParallel Text (Task 11).Task 5 consists of 40 Chinese target words, 19nouns and 21 verbs.
The number of senses for thetarget words ranges from 2 to 8, with an average of3.
There are altogether 2,680 training samples, i.e.on average about 22 for each sense.
A total of 935testing instances were to be tagged, i.e.
on averageabout 23 for each target word.
The data were fromPeople?s Daily.
The sense tags are given in theform of their English translations in the ChineseSemantic Dictionary developed by the Institute ofComputational Linguistics of Peking University.The task organiser has provided the data with wordsegmentation and POS for each segmented word.Task 11 consists of 40 English target words, in-cluding 20 nouns and 20 adjectives.
The averagenumber of training samples for each sense is about42.
The number of senses for the target wordsranges from 2 to 6, with an average of 3.125.
Theaverage number of testing samples for each targetword is 68.
The data were gathered from word-aligned English-Chinese parallel texts.In addition, we also used the SENSEVAL-3Chinese lexical sample data during evaluation,which contains 20 target words.1 To simplify the task for the human judges, we did notdistinguish between fixed-position local POS and n-gram syntactic features, and only used the former.4.2 EvaluationFor Task 5, we made use of the segmentation andPOS information provided by the task organiser.For Task 11, we first ran the data through the Brilltagger (Brill, 1994) to obtain the POS, from whichwe then extracted the feature values.On top of the core system, we also tested twovalue-added conditions, namely automatic featureselection (AFS) and human-informed feature pref-erence (HIF).
For the latter, we run a separate Na-?ve Bayes classifier in parallel to the core system,using the knowledge source deemed most usefulfor a given target word by two or more humanjudges.
When the probability of the best guessfrom the core classifier is under a certain threshold,the best guess from the other is used instead.
Forthe current experiment, the probability of the bestguess from the core classifier must at least doublethat for the next best guess.For evaluation, we ran a 10-fold cross validationon the SemEval-2007 Task 5 training data, withthe core system and AFS.
In addition, we testedwith the Senseval-3 Chinese lexical sample data.We trained the classifier with the Senseval-3 train-ing data, with the core classifier, AFS, and HIF.The results are discussed below.4.3 ResultsTable 2 shows the evaluation results of the variousconditions described above.Condition Ave. PrecisionSemEval-2007 training data (10-fold CV)Core classifier 77.33%Core classifier + AFS 85.51%Senseval-3 testing dataCore classifier 60.2%Core classifier + AFS 61.7%Core classifier + HIF 60.7%Table 2  Evaluation ResultsApparently, and as known and expected, featureselection is useful for choosing an optimal set offeatures for each target word.
How this comparesand works together with human intuition and thenature of the individual target words and senses iswhat we would like to further investigate.
In theabove experiment, fine-tuning with human-111informed feature preference did not improve theperformance as significantly as one would like tosee, and the effect varied with individual targetwords.
One possibility is that Na?ve Bayes classi-fiers favour aggregative features, so it might not bemost appropriate to do the fine-tuning with a sepa-rate classifier.
Rather, we could explore the feasi-bility of adjusting the weights of individual fea-tures based on the feature preference.Our next step is to perform in-depth and system-atic analysis on the difficulty, abstractness andtopicality of the target words and senses, with theinformation gathered from the human judges andthe confusion matrices generated from the experi-ment, in association with psychological evidencelike semantic activation and the organisation of themental lexicon (e.g.
Kwong, 2007).4.4 Official Scores in SemEval-2007The official scores for our system are shown inTable 3.Task System MicroAvg MacroAvg Rank5 HIF 71.0% 74.9% 3 / 611 AFS 75.3%2 - 3 / 3Table 3  Official Scores for CITYU in SemEval-2007Our scores are comparable to the state-of-the-artresults.
Although the HIF step did not increase theperformance significantly, in view of the limitationof state-of-the-art statistical WSD systems, everyminor improvement counts.
It therefore remainsfor us to further investigate the cognitive aspects ofWSD in relation to target nature and have themsystematically realised in WSD systems.5 ConclusionIn this paper, we have described our system par-ticipating in the SemEval-2007 multilingual Chi-nese-English lexical sample task and English lexi-cal sample task via English-Chinese parallel text.Toward a larger goal of supplementing statistical2 A post-hoc analysis reveals a technical problem for sixof the target words in Task 11 (educational.a, change.n,future.n, interest.n, need.n, program.n) which were notproperly processed by the system in one of the steps,and the most frequent sense was used by default.
Ignor-ing these cases, a precision of 78.3% was obtained usingthe task organiser?s key and scoring program.methods with some cognitive elements of WSD,more systematic analysis of the intrinsic nature oftarget words underlying the lexical sensitivity ofWSD is underway.AcknowledgementsThe work described in this paper was supported bya grant from the Research Grants Council of theHong Kong Special Administrative Region, China(Project No.
CityU 1508/06H).ReferencesBrill, E. (1994)  Some advances in transformation-basedpart of speech tagging.
In Proceedings of the 12thNational Conference on Artificial Intelligence (AAAI-94), pp.722-727.Escudero, G., M?rquez, L. and Rigau, G. (2004)  TALPSystem for the English Lexical Sample Task.
InProceedings of SENSEVAL-3, Barcelona, Spain.Kwong, O.Y.
(2005)  Word Sense Classification Basedon Information Susceptibility.
In A. Lenci, S. Mon-temagni and V. Pirrelli (Eds.
), Acquisition and Rep-resentation of Word Meaning.
Linguistica Compu-tazionale, pp.89-115.Kwong, O.Y.
(2007)  Sense Abstractness, SemanticActivation and Word Sense Disambiguation: Impli-cations from Word Association Norms.
To appear inProceedings of NLPCS-2007, Madeira, Portugal.Leacock, C., Miller, G.A.
and Chodorow, M. (1998)Using Corpus Statistics and WordNet Relations forSense Identification.
Computational Linguistics,24(1):147-166.Mihalcea, R.F.
(2002) Word sense disambiguation withpattern learning and automatic feature selection.Natural Language Engineering, 8(4):343-358.Mihalcea, R., Chklovski, T. and Kilgarriff, A.
(2004)The SENSEVAL-3 English Lexical Sample Task.
InProceedings of SENSEVAL-3, Barcelona, Spain.Resnik, P. and Yarowsky, D. (1997)  A perspective onword sense disambiguation methods and their evalua-tion.
In Proceedings of SIGLEX?97 Workshop: Tag-ging Text with Lexical Semantics: Why, What, andHow?, Washington, D.C., pp.79-86.Witten, I.H.
and Frank, E. (2005)  Data Mining: Practi-cal Machine Learning Tools and Techniques withJava Implementations.
Morgan Kaufmann.Yarowsky, D. and Radu, F. (2002)  Evaluating sensedisambiguation across diverse parameter spaces.Natural Language Engineering, 8(4):293-310.112
