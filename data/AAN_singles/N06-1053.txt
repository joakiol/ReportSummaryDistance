Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 415?422,New York, June 2006. c?2006 Association for Computational LinguisticsTowards Spoken-Document Retrieval for the Internet:Lattice Indexing For Large-Scale Web-Search ArchitecturesZheng-Yu Zhou?, Peng Yu, Ciprian Chelba+, and Frank Seide?Chinese University of Hong Kong, Shatin, Hong KongMicrosoft Research Asia, 5F Beijing Sigma Center, 49 Zhichun Road, 100080 Beijing+Microsoft Research, One Microsoft Way, Redmond WA 98052zyzhou@se.cuhk.edu.hk, {rogeryu,chelba,fseide}@microsoft.comAbstractLarge-scale web-search engines are generallydesigned for linear text.
The linear text repre-sentation is suboptimal for audio search, whereaccuracy can be significantly improved if thesearch includes alternate recognition candi-dates, commonly represented as word lattices.This paper proposes a method for indexingword lattices that is suitable for large-scaleweb-search engines, requiring only limitedcode changes.The proposed method, called Time-basedMerging for Indexing (TMI), first converts theword lattice to a posterior-probability represen-tation and then merges word hypotheses withsimilar time boundaries to reduce the indexsize.
Four alternative approximations are pre-sented, which differ in index size and the strict-ness of the phrase-matching constraints.Results are presented for three types of typi-cal web audio content, podcasts, video clips,and online lectures, for phrase spotting and rel-evance ranking.
Using TMI indexes that areonly five times larger than corresponding linear-text indexes, phrase spotting was improved oversearching top-1 transcripts by 25-35%, and rel-evance ranking by 14%, at only a small losscompared to unindexed lattice search.1 IntroductionSearch engines have become the essential tool for find-ing and accessing information on the Internet.
The re-cent runaway success of podcasting has created a needfor similar search capabilities to find audio on the web.As more news video clips and even TV shows are offeredfor on-demand viewing, and educational institutions likeMIT making lectures available online, a need for audiosearch arises as well, because the most informative partof many videos is its dialogue.There is still a significant gap between current web au-dio/video search engines and the relatively mature textsearch engines, as most of today?s audio/video search en-gines rely on the surrounding text and metadata of an au-dio or video file, while ignoring the actual audio content.This paper is concerned with technologies for searchingthe audio content itself, in particular how to represent thespeech content in the index.Several approaches have been reported in the litera-ture for indexing spoken words in audio recordings.
TheTREC (Text REtrieval Conference) Spoken-DocumentRetrieval (SDR) track has fostered research on audio-retrieval of broadcast-news clips.
Most TREC bench-marking systems use broadcast-news recognizers to gen-erate approximate transcripts, and apply text-based infor-mation retrieval to these.
They achieve retrieval accuracysimilar to using human reference transcripts, and ad-hocretrieval for broadcast news is considered a ?solved prob-lem?
(Garofolo, 2000).
Noteworthy are the rather lowword-error rates (20%) in the TREC evaluations, and thatrecognition errors did not lead to catastrophic failures dueto redundancy of news segments and queries.
However, inour scenario, unpredictable, highly variable acoustic con-ditions, non-native and accented speaker, informal talk-ing style, and unlimited-domain language cause word-error rates to be much higher (40-60%).
Directly search-ing such inaccurate speech recognition transcripts suffersfrom a poor recall.A successful way for dealing with high word error ratesis the use of recognition alternates (lattices) (Saraclar,2004; Yu, 2004; Chelba, 2005).
For example, (Yu, 2004)reports a 50% improvement of FOM (Figure Of Merit) fora word-spotting task in voice-mails, and (Yu, HLT2005)adopted the approach for searching personal audio collec-tions, using a hybrid word/phoneme lattice search.Web-search engines are complex systems involvingsubstantial investments.
For extending web search to au-dio search, the key problem is to find a (approximate)415representation of lattices that can be implemented in astate-of-the-art web-search engine with as little changesas possible to code and index store and without affectingits general architecture and operating characteristics.Prior work includes (Saraclar, 2004), which proposeda direct inversion of raw lattices from the speech recog-nizer.
No information is lost, and accuracy is the sameas for directly searching the lattice.
However, raw latticescontain a large number of similar entries for the same spo-ken word, conditioned on language-model (LM) state andphonetic cross-word context, leading to inefficient usageof storage space.
(Chelba, 2005) proposed a posterior-probability basedapproximate representation in which word hypotheses aremerged w.r.t.
word position, which is treated as a hiddenvariable.
It easily integrates with text search engines, asthe resulting index resembles a normal text index in mostaspects.
However, it trades redundancy w.r.t.
LM stateand context for uncertainty w.r.t.
word position, and onlyachieves a small reduction of index entries.
Also, timeinformation for individual hypotheses is lost, which weconsider important for navigation and previewing.
(Mangu, 2000) presented a method to align a speechlattice with its top-1 transcription, creating so-called?confusion networks?
or ?sausages.?
Sausages are a par-simonious approximation of lattices, but due to the pres-ence of null links, they do not lend themselves naturallyfor matching phrases.
Nevertheless, the method was a keyinspiration for the present paper.This paper is organized as follows.
The next sectionstates the requirements for our indexing method and de-scribes the overall system architecture.
Section 3 intro-duces our method, and Section 4 the results.
Section 5briefly describes a real prototype built using the approach.2 Indexing Speech Lattices, Internet ScaleSubstantial investments are necessary to create and oper-ate a web search engine, in software development and op-timization, infrastructure, as well as operation and main-tainance processes.
This poses constraints on what canpractically be done when integrating speech-indexing ca-pabilities to such an engine.2.1 RequirementsWe have identified the following special requirements forspeech indexing:?
realize best possible accuracy ?
speech alternatesmust be indexed, with scores;?
provide time information for individual hits ?
to fa-cilitate easy audio preview and navigation in the UI;?
encode necessary information for phrase matching ?phrase matching is a basic function of a search en-gine and an important feature for document ranking.This is non-trivial because boundaries of recognitionalternates are generally not aligned.None of these capabilities are provided by text searchengines.
To add these capabilities to an existing web en-gine, we are facing practical constraints.
First, the struc-ture of the index store cannot be changed fundamentally.But we can reinterpret existing fields.
We also assumethat the index attaches a few auxiliary bits to each wordhit.
E.g., this is done in (early) Google (Brin, 1998) andMSN Search.
These can be used for additional data thatneeds to be stored.Secondly, computation and disk access should remainof similar order of magnitude as for text search.
ExtraCPU cycles for phrase-matching loops are possible aslong as disk access remains the dominating factor.
Theindex size cannot be excessively larger than for indexingtext.
This precludes direct inversion of lattices (and un-fortunately also the use of phonetic lattices).Last, while local code changes are possible, the over-all architecture and dataflow cannot be changed.
E.g.,this forbids the use of a two-stage method as in (Yu,HLT2005).2.2 ApproachWe take a three-step approach.
First, following (Chelba,2005), we use a posterior-probability representation, asposteriors are resilient to approximations and can bequantized with only a few bits.
Second, we reduce the in-herent redundancy of speech lattices by merging word hy-potheses with same word identity and similar time bound-aries, hence the name ?Time-based Merging for Indexing?(TMI).
Third, the resulting hypothesis set is representedin the index by reinterpreting existing data fields and re-purposing auxiliary bits.2.3 System ArchitectureFig.
1 shows the overall architecture of a search enginefor audio/video search.
At indexing time, a media de-coder first extracts the raw audio data from different for-mats of audio found on the Internet.
A music detectorprevents music from being indexed.
The speech is thenfed into a large-vocabulary continuous-speech recognizer(LVCSR), which outputs word lattices.
The lattice in-dexer converts the lattices into the TMI representation,which is then merged into the inverted index.
Availabletextual metadata is also indexed.At search time, all query terms are looked up in the in-dex.
For each document containing all query terms (deter-mined by intersection), individual hit lists of each queryterm are retrieved and fed into a phrase matcher to iden-tify full and partial phrase hits.
Using this information,the ranker computes relevance scores.
To achieve accept-able response times, a full-scale web engine would splitthis process up for parallel execution on multiple servers.Finally the result presentation module will create snippets416mediadecoder speechstream speechrecognizerindexlookupresult pagequeryaudiostreamresultpresentationindexingsearchinvertedindexwavestream latticeindexerspeechlatticeTMI representationmetadata textindexerrankertime informationdoclist phrasematch hitinformationhitlistmusicdetectorFigure 1: System Architecture.for the returned documents and compose the result page.In audio search, snippets would contain time informationfor individual word hits to allow easy navigation and pre-view.3 Time-based Merging for IndexingOur previous work (Yu, IEEE2005) has shown that in aword spotting task, ranking by phrase posteriors is in the-ory optimal if (1) a search hit is considered relevant if thequery phrase was indeed said there, and (2) the user ex-pects a ranked list of results such that the accumulativerelevance of the top-n entries of the list, averaged overa range of n, is maximized.
In the following, we willfirst recapitulate the lattice notation and how phrase pos-teriors are calculated from the lattice.
We then introducetime-based merging, which leads to an approximate rep-resentation of the original lattice.
We will describe twostrategies of merging, one by directly clustering word hy-potheses (arc-based merging) and one by grouping latticenodes (node-based merging).3.1 Posterior Lattice RepresentationA lattice L = (N ,A, nstart, nend) is a directed acyclicgraph (DAG) with N being the set of nodes, A is theset of arcs, and nstart, nend ?
N being the unique ini-tial and unique final node, respectively.
Nodes representtimes and possibly context conditions, while arcs repre-sent word or phoneme hypotheses.1Each node n ?
N has an associated time t[n] andpossibly an acoustic or language-model context condi-tion.
Arcs are 4-tuples a = (S[a], E[a], I[a], w[a]).
S[a],E[a] ?
N denote the start and end node of the arc.
I[a]is the word identity.
Last, w[a] shall be a weight as-signed to the arc by the recognizer.
Specifically, w[a] =pac(a)1/?
?
PLM(a) with acoustic likelihood pac(a), LMprobability PLM, and LM weight ?.1Alternative definitions of lattices are possible, e.g.
nodesrepresenting words and arcs representing word transitions.In addition, we define paths pi = (a1, ?
?
?
, aK) assequences of connected arcs.
We use the symbols S,E, I , and w for paths as well to represent the respec-tive properties for entire paths, i.e.
the path start nodeS[pi] = S[a1], path end node E[pi] = E[aK ], path la-bel sequence I[pi] = (I[a1], ?
?
?
, I[aK ]), and total pathweight w[pi] = ?Kk=1 w[ak].Based on this, we define arc posteriors Parc[a] andnode posteriors Pnode[n] asParc[a] =?S[a] ?
w[a] ?
?E[a]?nend; Pnode[n] = ?n ?
?n?nend,with forward-backward probabilities ?n, ?n defined as:?n =?pi:S[pi]=nstart?E[pi]=nw[pi] ; ?n =?pi:S[pi]=n?E[pi]=nendw[pi]?n and ?n can be conveniently computed using the well-known forward-backward recursion, e.g.
(Wessel, 2000).With this, an alternative equivalent representation ispossible by using word posteriors as arc weights.
Theposterior lattice representation stores four fields witheach edge: S[a], E[a], I[a], and Parc[a], and two fieldswith each node: t[n], and Pnode[a].With the posterior lattice representation, the phraseposterior of query string Q is computed asP (?, ts, Q, te, ?|O)=?pi=(a1,???
,aK ):t[S[pi]]=ts?t[E[pi]]=te?I[pi]=QParc[a1] ?
?
?Parc[aK ]Pnode[S[a2]] ?
?
?Pnode[S[aK ]] .
(1)This posterior representation is lossless.
Its advantage isthat posteriors are much more resiliant to approximationsthan acoustic likelihoods.
This paves the way for lossyapproximations aiming at reducing lattice size.3.2 Time-based Merging for IndexingFirst, (Yu, HLT2005) has shown that node posteriors canbe replaced by a constant, with no negative effect on417search accuracy.
This approximation simplifies the de-nominator in Eq.
1 to pK?1node .We now merge all nodes associated with the same timepoints.
As a result, the connection condition for two arcsdepends only on the boundary time point.
This operationgave the name Time-based Merging for Indexing.TMI stores arcs with start and end time, while dis-carding the original node information that encoded de-pendency on LM state and phonetic context.
This formis used, e.g., by (Wessel, 2000).
Lattices are viewed assets of items h = (ts[h], dur[h], I[h], P [h]), with ts[h]being the start time, dur[h] the time duration, I[h] theword identity, and P [h] the posterior probability.
Arcswith same word identity and time boundaries but differ-ent start/end nodes are merged together, their posteriorsbeing summed up.These item sets can be organized in an inverted index,similar to a text index, for efficient search.
A text searchengine stores at least two fields with each word hit: wordposition and document identity.
For TMI, two more fieldsneed to be stored: duration and posterior.
Start times canbe stored by repurposing the word-position information.Posterior and duration go into auxiliary bits.
If the indexhas the ability to store side information for documents,bits can be saved in the main index by recording all timepoints in a look-up table, and storing start times and du-rations as table indices instead of absolute times.
Thisworks because the actual time values are only needed forresult presentation.
Note that the TMI index is really anextension of a linear-text index, and the same code basecan easily accomodate indexing both speech content andtextual metadata.With this, multi-word phrase matches are defined asa sequence of items h1...hK matching the query string(Q = (I[h1], ?
?
?
, I[hK ])) with matching boundaries(ts[hi] + dur[hi] = ts[hi+1]).
The phrase posterior iscalculated (using the approximate denominator) asP (?, ts, Q, te, ?|O) ??
P [h1] ?
?
?P [hK ]pK?1node, (2)summing over all item sequences with ts = ts[h1] andte = ts[hK ] + dur[hK ].Regular text search engines can not directly supportthis, but the code modification and additional CPU costis small.
The major factor is disk access, which is stilllinear with the index size.We call this index representation ?TMI-base.?
It pro-vides a substantial reduction of number of index entriescompared to the original lattices.
However, it is obviouslyan approximative representation.
In particular, there arenow conditions under which two word hypotheses can bematched as part of a phrase that were not connected inthe original lattice.
This approximation seems sensible,though, as the words involved are still required to haveTable 1: Test corpus summary.test set dura- #seg- #keywords WERtion ments (#multi-word) [%]podcasts 1.5h 367 3223 (1709) 45.8videos 1.3h 341 2611 (1308) 50.8lectures 169.6h 66102 96 (74) 54.8precisely matching word boundaries.
In fact it has beenshown that this representation can be used for direct word-error minimization during decoding (Wessel, 2000).For further reduction of the index size, we are now re-laxing the merging condition.
The next two sections willintroduce two alternate ways of merging.3.3 Arc-Based MergingA straightforward way is to allow tolerance of timeboundaries.
Practically, this is done by the followingbottom-up clustering procedure:?
collect arcs with same word identity;?
find the arc a?
with the best posterior, set the result-ing item time boundary same as a?;?
merge all overlapping arcs a satisfying t[S[a?]]
?41 ?
t[S[a]] ?
t[S[a?]]
+41 and t[E[a?
]]?41 ?t[E[a]] ?
t[E[a?]]
+41;?
repeat with remaining arcs.We call this method ?TMI-arc?
to denote its origin fromdirect clustering of arcs.Note that the resulting structure can generally not bedirectly represented as a lattice anymore, as formally con-nected hypotheses now may have slightly mismatchingtime boundaries.
To compensate for this, the item connec-tion condition in phrase matching needs to be relaxed aswell: ts[hi+1]?41 ?
ts[hi]+dur[hi] ?
ts[hi+1]+41.The storage cost for each TMI-arc item is same as forTMI-base, while the number of items will be reduced.3.4 Node-Based MergingAn alternative way is to group ranges of time points,and then merge hypotheses whose time boundaries gotgrouped together.The simplest possibility is to quantize time points intofixed intervals, such as 250 ms.
Hypotheses are mergedif their quantized time boundaries are identical.
Thismethod we call ?TMI-timequant.
?Besides reducing index size by allowing more itemmerging, TMI-timequant has another important property:since start times and duration are heavily quantized, thenumber of bits used for storing the information with theitems in the index can be significantly reduced.The disadvantage of this method is that loops are fre-quently being generated this way (quantized duration of0), providing sub-optimal phrase matching constraints.To alleviate for this problem, we modify the mergingby forbidding loops to be created: Two time points can be418Table 2: Lattice search accuracy on different dataset.setup best path raw latticekeywords all sing.
mult.
all sing.
mult.Phrase spotting, FOM[%]podcasts 55.0 59.9 50.1 69.5 74.7 64.2videos 47.0 50.6 43.0 64.4 67.4 61.1lectures 65.5 69.5 47.1 77.0 80.8 58.8Relevance ranking, mAP[%]lectures 52.6 52.7 52.6 61.6 66.4 60.2grouped together if (1) their difference is below a thresh-old (like 250 ms); and (2) if there is no word hypothesisstarting and ending in the same group.
As a refinement,the second point is relaxed by a pruning threshold in thathypotheses with posteriors below the threshold will notblock nodes merging.Amongst the manifold of groupings that satisfy thesetwo conditions, the one leading to the smallest number ofgroups is considered the optimal solution.
It can be foundusing dynamic programming:?
line up all existing time boundaries in ascending or-der, ti < ti+1, i = 1, ?
?
?
, N ;?
for each time point ti, find out the furthest time pointthat it can be grouped with given the constraints, de-noting its index as T [ti];?
set group count C[t0] = 1; C[ti] = ?, i > 0;?
set backpointer B[t0] = ?1; B[ti] = ti, i > 0;?
for i = 1, ?
?
?
, N :?
for j = i+1, ?
?
?
, T [ti]: if C[tj+1] > C[ti]+1:?
C[tj+1] = C[ti] + 1;?
B[tj+1] = ti;?
trace back and merge nodes:?
set k = N , repeat until k = ?1:?
group time points from B[tk] to tk?1;?
k = B[tk].This method can be applied to the TMI-base represen-tation, or alternatively directly to the posterior lattice.
Inthis case, the above algorithm needs to be adapted to op-erate on nodes rather than time points.
The above methodis called ?TMI-node.
?If, as mentioned before, times and durations are storedas indexes into a look-up table, TMI-node is highly spaceefficient.
In most cases, the index difference between endand start point is 1, and in practical terms, the index dif-ference can be capped by a small number below 10.4 Results4.1 SetupWe have evaluated our system on three different corpora,in an attempt to represent popular types of audio currentlyfound on the Internet:?
podcasts: short clips ranging from mainstream me-dia like ABC and CNN to non-professionally pro-duced edge content;?
video clips, acquired from MSN Video;?
online lectures: a subset of the MIT iCampus lecturecollection (Glass, 2004).In relation to our goal of web-scale indexing, the pod-cast and video sets are miniscule in size (about 1.5 hourseach).
Nevertheless they are suitable for investigating theeffectiveness of the TMI method w.r.t.
phrase spottingaccuracy.
Experiments on relevance ranking were con-ducted only on the much larger lecture set (170 hours).For the iCampus lecture corpus, the same set of querieswas used as in (Chelba, 2005), which was collected froma group of users.
Example keywords are computer scienceand context free grammar.
On the other two sets, an au-tomatic procedure described in (Seide, 2004) was used toselect keywords.
Example keywords are playoffs, beachFlorida, and American Express financial services.A standard speaker-independent trigram LVCSR sys-tem was used to generate raw speech lattices.
For videoand podcasts, models were trained on a combination oftelephone conversations (Switchboard), broadcast news,and meetings, downsampled to 8 kHz, to accomodate fora wide range of audio types and speaking styles.
For lec-tures, an older setup was used, based on a dictation enginewithout adaptation to the lecture task.
Due to the largercorpus size, lattices for lectures were pruned much moresharply.
Word error rates (WER) and corpus setups arelisted in Table 1.
It should be noted that the word-errorrates vary greatly within the podcast and video corpora,ranging from 30% (clean broadcast news) to over 80%(accented reverberated speech with a cheering crowd).Each indexing method is evaluated by a phrase spottingtask and a document retrieval task.4.1.1 Phrase SpottingWe use the ?Figure Of Merit?
(FOM) metric defined byNIST for word-spotting evaluations.
In its original form,FOM is the detection/false-alarm curve averaged over therange of [0..10] false alarms per hour per keyword.
Wegeneralized this metric to spotting of phrases, which canbe multi-word or single-word.
A multi-word phrase ismatched if all of its words match in order.Since automatic word alignment can be troublesomefor long audio files in the presence of errors in the ref-erence transcript, we reduced the time resolution of theFOM metric and used the sentence as the basic time unit.A phrase hit is considered correct if an actual occurenceof the phrase is found in the same sentence.
Multiple hitsof the same phrase within one sentence are counted as asingle hit, their posterior probabilities being summed upfor ranking.The segmentation of the audio files is based on the ref-erence transcript.
Segments are on average about 10 sec-onds long.
In a real system, sentence boundaries are ofcourse unknown, but previous experiments have shown419Table 3: Comparison of different indexing methods.
Only results for multi-words queries are shown, because resultsfor single-word queries are identical across lattice-indexing methods (approximately identical in the case of pruning.
)dataset podcasts videos lecturesFOM [%] size FOM [%] size FOM [%] mAP [%] sizebestpath 50.1 1.1 43.0 1.0 47.1 52.6 1.0raw lattice 64.2 527.6 61.1 881.7 58.8 60.2 23.3Pnode = const 64.3 527.6 61.1 881.7 58.8 60.3 23.3no pruningTMI-base 65.3 55.2 62.6 78.8 58.8 60.2 7.7TMI-arc 62.9 16.1 58.5 20.7 57.9 60.1 4.4TMI-timequant 66.7 15.4 64.2 19.5 58.8 60.3 4.5TMI-node 66.5 20.7 63.4 27.6 58.7 59.7 4.4PSPL 68.9 182.0 66.2 212.0 58.7 61.0 21.2pruned to about 5 entries per spoken wordTMI-base 62.1 5.6 54.1 5.1 57.0 60.3 4.5TMI-arc 60.7 4.6 53.6 5.0 57.9 60.1 4.4TMI-timequant 63.1 4.7 57.1 5.1 58.8 60.3 4.5TMI-node 63.7 4.6 57.7 5.1 58.7 59.7 4.4PSPL 57.3 6.0 49.8 5.8 53.6 61.0 4.4that the actual segmentation does not have significant im-pact on the results.4.1.2 Relevance RankingThe choice and optimization of a relevance ranking for-mula is a difficult problem that is beyond the scope of thispaper.
We chose a simple document ranking method asdescribed in (Chelba, 2005):Given query Q = (q1, ?
?
?
, qL), for each documentD, expected term frequencies (ETF) of all sub-stringsQ[i,j] = (qi, ?
?
?
, qj) are calculated:ETF(Q[i,j]|D)=?ts,teP (?, ts, Q[i,j], te, ?|O,D) (3)A document is returned if all query words are present.
Therelevance score is calculated asS(D,Q)=L?i=1L?j=iwj?i log[1+ETF(Q[i,j]|D)] (4)where the weights w` have the purpose to give higherweight to longer sub-strings.
They were chosen as w` =1 + 1000 ?
`, no further optimization was performed.Only the lecture set is used for document retrieval eval-uation.
The whole set consists of 169 documents, with anaverage of 391 segments in each document.
The eval-uation metric is the mean average precision (mAP) ascomputed by the standard trec_eval package used bythe TREC evaluations (NIST, 2005).
Since actual rele-vance judgements were not available for this corpus, weuse the output of a state-of-the-art text retrieval engine onthe ground truth transcripts as the reference.
The idea isthat if human judgements are not available, the next bestthing to do is to assess how close our spoken-documentretrieval system gets to a text engine applied to referencetranscripts.
Although one should take the absolute mAPscores with a pinch of salt, we believe that comparing therelative changes of these mAP scores is meaningful.4.2 Lattice Search and Best Path BaselineTable 2 lists the word spotting and document retrieval re-sult of direct search in the original raw lattice, as wellas for searching the top-1 path.
Results are listed sepa-rately for single- and multi-word queries.
For the phrase-spotting task, a consistent about 15% improvement isobserved on all sets, re-emphasizing the importance ofsearching alternates.
For document retrieval, the accuracy(mAP) is also significantly improved from 53% to 62%.4.2.1 Comparing Indexing MethodsTable 3 compares different indexing methods with re-spect to search accuracy and index size.
We only showresults for multi-words queries results, as it can be shownthat results for single-word queries must be identical.
Theindex size is measured as index entries per spoken word,i.e.
it does not reflect that different indexing methods mayrequire different numbers of bits in the actual index store.In addition to four types of TMI methods, we includean alternative posterior-lattice indexing method in ourcomparison called PSPL (position-specific posterior lat-tices) (Chelba, 2005).
A PSPL index is constructed byenumerating all paths through a lattice, representing eachpath as a linear text, and adding each text to the index,each time starting over from word position 1.
Each wordhypothesis on each path is assigned the posterior proba-bility of the entire path.
Instances of the same word oc-curing at the same text position are merged, accumulatingtheir posterior probabilities.
This way, each index entryrepresents the posterior probability that a word occurs ata particular position in the actual spoken word sequence.PSPL is an attractive alternative to the work presented in4200246810121416182048 53 58 63 68Phrase Spotting Accuracy (Figure Of Merit [%])(a) podcastsindexentries/spokenword bestpathbaselinePSPLTMI-baseTMI-arcTMI-tqTMI-node0246810121416182042 47 52 57 62Phrase Spotting Accuracy (Figure Of Merit [%])(b) videosindexentries/spokenword bestpathbaselinePSPLTMI-baseTMI-arcTMI-tqTMI-node0246810121416182040 45 50 55 60Phrase Spotting Accuracy (Figure Of Merit [%])(c) lecturesindexentries/spokenword bestpathbaselinePSPLTMI-baseTMI-arcTMI-tqTMI-node0246810121416182052 54 56 58 60 62 64Relevance Ranking Accuracy (mAP [%])(d) lecturesindexentries/spokenword bestpathbaselinePSPLTMI-baseTMI-arcTMI-tqTMI-nodeFigure 2: Index size vs. accuracy for different pruning thresholds for word-spotting on (a) podcasts, (b) videos, (c)lectures, and (d) relevance ranking for lectures.this paper because it continues to use the notion of a wordposition instead of time, with the advantage that exist-ing implementations of phrase-matching conditions applywithout modification.The results show that, comparing with the direct raw-lattice search, all indexing methods have only slight im-pact on both word spotting and document retrieval accu-racies.
Against our expectation, in many cases improvedaccuracies are observed.
These are caused by creating ad-ditonal paths compared to the original lattice, improvingrecall.
It is not yet clear how to exploit this in a systematicmanner.W.r.t.
storage efficiency, the TMI merging methodshave about 5 times less index entries than the original lat-tice for lectures (and an order of magnitude less for pod-casts and videos that were recognized with rather waste-ful pruning thresholds).
This can be further improved bypruning.4.2.2 PruningIndex size and accuracy can be balanced by pruninglow-scoring index entries.
Experiments have shown thatthe optimal pruning strategy differs slightly from methodto method.
For the TMI set, the index is pruned by remov-ing all entries with posterior probabilities below a certainfixed threshold.
In addition, for TMI-node we enforcethat the best path is not pruned.
For PSPL, an index entryat a particular word position is removed if its posterior isworse by a fixed factor compared to the best index entryfor the same word position.
This also guarantees that thebest path is never pruned.Fig.
2 depicts the trade-off of size and accuracy fordifferent indexing methods.
TMI-node provides the besttrade-off.
The last block of Table 3 shows results for allindexing methods when pruned with the respective prun-ing thresholds adjusted such that the number of index en-tries is approximately five times that for the top-1 tran-script.
We chose this size because reducing the index sizestill has limited impact on accuracy (0.5-points for pod-casts, 3.5 for videos, and none for lectures) while keepingoperating characteristics (storage size, CPU, disk) withinan order of magnitude from text search.5 The SystemThe presented technique was implemented in a researchprototype shown in Fig.
3.
About 780 hours of audio doc-uments, including video clips from MSN Video and audiofiles from most popular podcasts, were indexed.
The in-dex is disk-based, its size is 830 MB, using a somewhatwasteful XML representation for research convenience.Typically, searches are executed within 0.5 seconds.The user interface resembles a typical text search en-gine.
A media player is embedded for immediate within-page playback.
Snippets are generated for previewing thesearch results.
Each word in a snippet has its originaltime point associated, and a click on it positions the me-dia player to the corresponding time in the document.6 ConclusionWe targeted the paper to the task of searching audio con-tent from the Internet.
Aiming at maximizing reuse ofexisting web-search engines, we investigated how best to421Figure 3: Screenshot of the video/audio-search prototype.
For each document, in addition to the title and descriptiontext from meta-data, the system displays recognition-transcript snippets around the audio hits, e.g.
?...
bird flu hasbeen a ...?
in the first document.
Clicking on a word in a snippet starts playing back the video at that position usingthe embedded video player.represent important lattice properties ?
recognition alter-nates with scores, time boundaries, and phrase-matchingconstraints ?
in a form suitable for large-scale web-searchengines, while requiring only limited code changes.The proposed method, Time-based Merging for Index-ing (TMI), first converts the word lattice to a posterior-probability representation and then merges word hypothe-ses with similar time boundaries to reduce the index size.Four approximations were presented, which differ in sizeand the strictness of phrase-matching constraints.Results were presented for three typical types of webaudio content ?
podcasts, video clips, and online lectures?
for phrase spotting and relevance ranking.
Using TMIindexes that are only five times larger than correspondinglinear-text indexes, accuracy was improved over search-ing top-1 transcripts by 25-35% for word spotting and14% for relevance ranking, very close to what is gainedby a direct search of unindexed lattices.Practical feasibility has been demonstrated by a re-search prototype with 780 hours indexed audio, whichcompletes searches within 0.5 seconds.To our knowledge, this is also the first paper to reportspeech recognition results for podcasts.7 AcknowledgementsThe authors wish to thank Jim Glass and T. J. Hazen atMIT for providing the iCampus data.ReferencesS.
Brin and L. Page, The anatomy of a large-scale hypertextualWeb search engine.
Computer Networks and ISDN Systems,30(1-7):107-117.C.
Chelba and A. Acero, Position specific posterior lattices forindexing speech.
Proc.
ACL?2005, Ann Arbor, 2005.J.
Garofolo, TREC-9 Spoken Document Retrieval Track.National Institute of Standards and Technology, http://trec.nist.gov/pubs/trec9/sdrt9_slides/sld001.htm.J.
Glass, T. J. Hazen, L. Hetherington, C. Wang, Analysis andProcessing of Lecture Audio data: Preliminary investiga-tion.
Proc.
HLT-NAACL?2004 Workshop: InterdisciplinaryApproaches to Speech Indexing and Retrieval, Boston, 2004.L.
Mangu, E. Brill, A. Stolcke, Finding Consensus in SpeechRecognition: Word Error Minimization and Other Applica-tions of Confusion Networks.
Computer, Speech and Lan-guage, 14(4):373-400.MSN Video.
http:// video.msn.com.The TREC evaluation package.
http:// www - lpir .
nist.
gov / projects / trecvid / trecvid .
tools /trec_eval.M.
Saraclar, R. Sproat, Lattice-based search for spoken utter-ance retrieval.
Proc.
HLT?2004, Boston, 2004.F.
Seide, P. Yu, et al, Vocabulary-independent search in sponta-neous speech.
Proc.
ICASSP?2004, Montreal, 2004.F.
Wessel, R. Schlu?ter, and H. Ney, Using posterior word proba-bilities for improved speech recognition.
Proc.
ICASSP?2000,Istanbul, 2000.P.
Yu, K. J.
.Chen, L. Lu, F. Seide, Searching the AudioNotebook: Keyword Search in Recorded Conversations.Proc.
HLT?2005, Vancouver, 2005.P.
Yu, K. J. Chen, C. Y. Ma, F. Seide, Vocabulary-IndependentIndexing of Spontaneous Speech, IEEE transaction onSpeech and Audio Processing, Vol.13, No.5, Special Issueon Data Mining of Speech, Audio and Dialog.P.
Yu, F. Seide, A hybrid word / phoneme-based approachfor improved vocabulary-independent search in spontaneousspeech.
Proc.
ICLSP?04, Jeju, 2004.422
