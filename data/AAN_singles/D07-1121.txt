Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp.
1124?1128,Prague, June 2007. c?2007 Association for Computational LinguisticsA Constraint Satisfaction Approach to Dependency ParsingSander CanisiusILK / Communication and Information ScienceTilburg University, P.O.
Box 90153,NL-5000 LE Tilburg, The NetherlandsS.V.M.Canisius@uvt.nlErik Tjong Kim SangISLA, University of Amsterdam,Kruislaan 403, NL-1098 SJ Amsterdam,The Netherlandserikt@science.uva.nlAbstractWe present an adaptation of constraint satis-faction inference (Canisius et al, 2006b) forpredicting dependency trees.
Three differ-ent classifiers are trained to predict weightedsoft-constraints on parts of the complex out-put.
From these constraints, a standardweighted constraint satisfaction problem canbe formed, the solution to which is a validdependency tree.1 IntroductionLike the CoNLL-2006 shared task, the 2007 sharedtask focuses on dependency parsing and aims atcomparing state-of-the-art machine learning algo-rithms applied to this task (Nivre et al, 2007).
Forour official submission, we used the dependencyparser described by Canisius et al (2006a).
In thispaper, we present a novel approach to dependencyparsing based on constraint satisfaction.
The methodis an adaptation of earlier work using constraint sat-isfaction techniques for predicting sequential out-puts (Canisius et al, 2006b).
We evaluated our ap-proach on all ten data sets of the 2007 shared task1.In the remainder of this paper, we will present thenew constraint satisfaction method for dependencyparsing in Section 2.
The method is evaluated inSection 3, in which we will also present a brief error1Hajic?
et al (2004), Aduriz et al (2003), Mart??
et al (2007),Chen et al (2003), Bo?hmova?
et al (2003), Marcus et al(1993), Johansson and Nugues (2007), Prokopidis et al (2005),Csendes et al (2005), Montemagni et al (2003), Oflazer et al(2003)analysis.
Finally, Section 4 presents our main con-clusions.2 Constraint Satisfaction Inference forDependency TreesThe parsing algorithm we used is an adaptation fordependency trees of the constraint satisfaction in-ference method for sequential output structures pro-posed by Canisius et al (2006b).
The techniqueuses standard classifiers to predict a weighted con-straint satisfaction problem, the solution to which isthe complete dependency tree.
Constraints that arepredicted each cover a small part of the completetree, and overlap between them ensures that globaloutput structure is taken into account, even thoughthe classifiers only make local predictions in isola-tion of each other.A weighted constraint satisfaction problem (W-CSP) is a tuple (X,D,C,W ).
Here, X ={x1, x2, .
.
.
, xn} is a finite set of variables.
D(x)is a function that maps each variable to its domain,and C is a set of constraints on the values assignedto the variables.
For a traditional (non-weighted)constraint satisfaction problem, a valid solution isan assignment of values to the variables that (1) area member of the corresponding variable?s domain,and (2) satisfy all constraints in the set C .
Weightedconstraint satisfaction, however, relaxes this require-ment to satisfy all constraints.
Instead, constraintsare assigned weights that may be interpreted as re-flecting the importance of satisfying that constraint.The optimal solution to a W-CSP is the solution thatassigns those values that maximise the sum of theweights of satisfied constraints.1124Figure 1: Dependency tree for the sentence No itwasn?t Black MondayTo adapt this framework to predicting a depen-dency tree for a sentence, we construct a constraintsatisfaction problem by first introducing one vari-able xi for each token of the sentence.
This vari-able?s value corresponds to the dependency relationthat token is the modifier of, i.e.
it should specify arelation type and a head token.
The constraints of theCSP are predicted by a classifier, where the weightfor a constraint corresponds to the classifier?s confi-dence estimate for the prediction.For the current study, we trained three classifiersto predict three different types of constraints.1.
Cdep(head, modifier, relation), i.e.
the re-sulting dependency tree should have adependency arc from head to modifier la-belled with type relation.
For the exampletree in Figure 1, among others the constraintCdep(head=was, modifier=No, relation=VMOD)should be predicted.2.
Cdir(modifier, direction), the relative posi-tion (i.e.
to its left or to its right) ofthe head of modifier.
The tree in Fig-ure 1 will give rise to constraints such asCdir(modifier=Black, direction=RIGHT).3.
Cmod(head, relation), in the dependencytree, head should be modified by a relationof type relation.
The constraints gener-ated for the word was in Figure 1 wouldbe Cmod(head=was, relations=SBJ), andCmod(head=was, relations=VMOD).Predicting constraints of type Cdep is essentiallywhat is done by Canisius et al (2006a); a classi-fier is trained to predict a relation label, or a sym-bol signalling the absence of a relation, for eachpair of tokens in a sentence2.
The training datafor this classifier consists of positive examples ofconstraints to generate, e.g.
was, No, VMOD, andnegative examples, of constraints not to generate,e.g.
was, Black, NONE, but also No, was, NONE.
Inthe aforementioned paper, it is shown that downsam-pling the negative class in the classifier?s trainingdata improves the recall for predicted constraints.The fact that improved recall comes at the cost of areduced precision is compensated for by our choicefor the weighted constraint satisfaction framework:an overpredicted constraint may still be left unsatis-fied if other, conflicting constraints outweigh its ownweight.In addition to giving rise to a set of constraints,this classifier differs from the other two in the sensethat it is also used to predict the domains of the vari-ables, i.e.
any dependency relation not predicted bythis classifier will not be considered for inclusion inthe output tree.Whereas the Cdep classifier classifies instancesfor each pair of words, the classifiers for Cdir andCmod only classify individual tokens.
The featuresfor these classifiers have been kept simple and thesame for both classifiers: a 5-slot wide window ofboth tokens and part-of-speech tags, centred on thetoken currently being classified.
The two classifiersdiffer in the classes they predict.
For Cdir , there areonly three possible classes: LEFT, RIGHT, NONE.Instances classified as LEFT, or RIGHT give rise toconstraints, whereas NONE implies that no Cdir con-straint is added for that token.For Cmod there is a rather large class space; aclass label reflects all modifying relations for the to-ken, e.g.
SBJ+VMOD.
From this label, as many con-straints are generated as there are different relationtypes in the label.With the above, a weighted constraint satisfactionproblem can be formulated that, when solved, de-scribes a dependency tree.
As we formulated ourproblem as a constraint satisfaction problem, anyoff-the-shelf W-CSP solver could be used to obtainthe best dependency parse.
However, in general suchsolvers have a time complexity exponential in the2For reasons of efficiency and to avoid having too many neg-ative instances in the training data, we follow the approach ofCanisius et al (2006a) of limiting the maximum distance be-tween a potential head and modifier.1125Language LAS ?06 UAS ?06Arabic 60.36 +1.2 78.61 +1.7Basque 64.23 +1.1 72.24 +2.1Catalan 77.33 +1.9 84.73 +3.1Chinese 71.73 +1.3 77.29 +2.5Czech 57.58 +1.4 75.61 +3.5English 79.47 +2.2 81.05 +2.8Greek 62.32 +2.0 76.42 +4.0Hungarian 66.86 +2.6 72.52 +4.7Italian 77.04 +1.5 81.24 +2.2Turkish 67.80 -0.3 75.58 +0.4Table 1: Performance of the system applied to thetest data for each language.
The ?06 columns showthe gain/loss with respect to the parser of Canisius etal.
(2006a).number of variables, and thus in the length of thesentence.
As a more efficient alternative we chose touse the CKY algorithm for dependency parsing (Eis-ner, 2000) for computing the best solution, whichhas only cubic time complexity, but comes with thedisadvantage of only considering projective trees ascandidate solutions.3 Results and discussionWe tested our system on all ten languages of theshared task.
The three constraint classifiers havebeen implemented with memory-based learning.
Nolanguage-specific parameter optimisation or featureengineering has been performed, but rather the exactsame system has been applied to all languages.
La-belled and unlabelled attachment scores are listed inTable 1.
In addition, we show the increase/decreasein performance when compared with the parser ofCanisius et al (2006a); for all languages but Turk-ish, there is a consistent increase, mostly somewherebetween 1.0 and 2.0 percent in labelled attachmentscore.The parser by Canisius et al (2006a) can beconsidered a rudimentary implementation of con-straint satisfaction inference that only uses Cdep con-straints.
The parser described in this paper elabo-rates this by adding (1) the Cmod and Cdir soft con-straints, and (2) projectivity and acyclicity hard con-straints, enforced implicitly by the CKY algorithm.To evaluate the effect of each of these constraints,Language ?06 Cdep Cmod/dep Cdir/dep allArabic 59.13 +0.3 +0.9 +0.9 +1.2Basque 63.17 +0.3 +0.4 +0.9 +1.1Catalan 75.44 +0.8 +1.2 +1.4 +1.9Chinese 70.45 +0.4 +1.2 +0.4 +1.3Czech 56.14 +0.5 +0.5 +1.1 +1.4English 77.27 +0.4 +1.4 +1.2 +2.2Greek 60.35 +0.4 +0.6 +1.6 +2.0Hungarian 64.31 +1.9 +1.3 +2.8 +2.6Italian 75.57 +0.2 +1.0 +1.1 +1.5Turkish 68.09 -0.2 -0.3 -0.3 -0.3Table 2: Performance of the parser by Canisius et al(2006a) and the performance gain of the constraintsatisfaction inference parser with various constraintconfigurations.Table 2 shows the labelled attachment scores forseveral parser configurations; starting with the 2006parser, i.e.
a parser with only Cdep constraints, thenthe CKY-driven Cdep parser, i.e.
with acyclicity andprojectivity constraints, then with Cmod, and Cdirseparately, and finally, the full parser based on allconstraints.
It can be seen that supplementing theCdep-only parser with hard constraints for acyclicityand projectivity already gives a small performanceimprovement.
For some languages, such as Ital-ian (+0.2), this improvement is rather small, how-ever for Hungarian 1.9 is gained only by using CKY.The remaining columns show that adding more con-straints improves performance, and that for all lan-guages but Turkish and Hungarian, using all con-straints works best.While in comparison with the system of Canisiuset al (2006a) the addition of extra constraints hasclearly shown its use, we expect the Cdep classifierstill to be the performance bottleneck of the sys-tem.
This is mainly due to the fact that this classifieris also responsible for defining the domains of theCSP variables, i.e.
which dependency relations willbe considered for inclusion in the output.
For thisreason, we performed an error analysis of the out-put of the Cdep classifier and the effect it has on theperformance of the complete system.In our error analysis, we distinguish three types oferrors: 1) label errors, a correct dependency arc wasadded to the tree, but its label is incorrect, 2) recall1126Cdep prec.
rec.Language prec.
rec.
%OOD %OODArabic 54.90 73.66 78.83 77.95Basque 55.82 74.10 85.05 83.66Catalan 65.19 87.25 80.29 80.00Chinese 65.10 76.49 83.79 82.94Czech 53.64 74.35 81.16 80.27English 59.37 90.08 67.51 66.63Greek 53.24 76.29 79.96 79.08Hungarian 44.71 78.64 69.08 67.45Italian 71.70 82.57 87.97 87.32Turkish 64.92 72.79 89.11 88.51Table 3: Columns two and three: precision and re-call on dependency predictions by the Cdep classi-fier.
Columns four and five: percentage of depen-dency arc precision and recall errors caused by out-of-domain errors.errors, the true dependency tree contains an arc thatis missing from the predicted tree, and 3) precisionerrors, the predicted tree contains a dependency arcthat is not part of the true dependency parse.Label errors are always a direct consequence oferroneous Cdep predictions.
If the correct arc waspredicted, but with an incorrect label, then by defi-nition, the correct arc with the correct label cannothave been predicted at the same time.
In case of theother two types of errors, the correct constraints maywell have been predicted, but afterwards outweighedby other, conflicting constraints.
Nevertheless, pre-cision and recall errors may also be caused by thefact that the Cdep classifier simply did not predict adependency arc where it should have.
We will referto those errors as out-of-domain errors, since the do-main of at least one of the CSP variables does notcontain the correct value.
An out-of-domain erroris a direct consequence of a recall error made bythe Cdep classifier.
To illustrate these interactions,Table 3 shows for all languages the precision andrecall of the Cdep classifier, and the percentage ofdependency precision and recall errors that are out-of-domain errors.The table reveals several interesting facts.
For En-glish, which is the language for which our system at-tains its highest score, the percentage of dependencyprecision and recall errors caused by Cdep recall er-rors is the lowest of all languages.
This can directlybe related to the 90% recall of the English Cdep clas-sifier.
Apparently, the weak precision (59%), causedby down-sampling the training data, is compensatedfor in the subsequent constraint satisfaction process.For Italian, the percentage of out-of-domain-related errors is much higher than for English.
Atthe same time, the precision and recall of the Cdepclassifier are much more in balance, i.e.
a higherprecision, but a lower recall.
We tried breaking thisbalance in favour of a higher recall by applying aneven stronger down-sampling of negative instances,and indeed the parser benefits from this.
Labelledattachment increases from 77.04% to 78.41%.
Theprecision and recall of this new Cdep classifier are58.65% and 87.15%, respectively.The lowest Cdep precision has been observed forHungarian (44.71), which unfortunately is not mir-rored by a high recall score.
Remarkably however,after English, Hungarian has the lowest percentageof dependency errors due to Cdep recall errors (69.08and 67.45).
It is therefore hypothesised that notthe low recall, but the low precision is the maincause for errors made on Hungarian.
With this inmind, we briefly experimented with weaker down-sampling ratios in order to boost precision, but sofar we did not manage to attain better results.4 Concluding remarksWe have presented a novel dependency parsingmethod based on a standard constraint satisfactionframework.
First results on a set of ten different lan-guages have been promising, but so far no extensiveoptimisation has been performed, which inevitablyreflects upon the scores attained by the system.
Fu-ture work will focus on tuning the many parametersour system has, as well as on experimenting with dif-ferent types of constraints to supplement or replaceone or more of the three types used in this study.AcknowledgementsThe authors wish to thank Antal van den Bosch fordiscussions and suggestions.
This research is fundedby NWO, the Netherlands Organization for Scien-tific Research under the IMIX programme.1127ReferencesA.
Abeille?, editor.
2003.
Treebanks: Building and UsingParsed Corpora.
Kluwer.I.
Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,A.
Diaz de Ilarraza, A. Garmendia, and M. Oronoz.2003.
Construction of a Basque dependency treebank.In Proc.
of the 2nd Workshop on Treebanks and Lin-guistic Theories (TLT), pages 201?204.A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, and B. Hladka?.
2003.The PDT: a 3-level annotation scenario.
In Abeille?
(Abeille?, 2003), chapter 7, pages 103?127.S.
Canisius, T. Bogers, A. van den Bosch, J. Geertzen,and E. Tjong Kim Sang.
2006a.
Dependency parsingby inference over high-recall dependency predictions.In Proceedings of CoNLL-X.
New York, NY, USA.S.
Canisius, A. van den Bosch, and W. Daelemans.2006b.
Constraint Satisfaction Inference: Non-probabilistic Global Inference for Sequence Labelling.Proceedings of the EACL 2006 Workshop on LearningStructured Information in Natural Language Applica-tions, pages 9?16.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeille?
(Abeille?, 2003), chapter 13, pages 231?248.D.
Csendes, J. Csirik, T. Gyimo?thy, and A. Kocsor.
2005.The Szeged Treebank.
Springer.J.
Eisner.
2000.
Bilexical grammars and their cubic-time parsing algorithms.
Advances in Probabilisticand Other Parsing Technologies, pages 29?62.J.
Hajic?, O.
Smrz?, P. Zema?nek, J.
?Snaidauf, and E. Bes?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.R.
Johansson and P. Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProc.
of the 16th Nordic Conference on ComputationalLinguistics (NODALIDA).M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: the PennTreebank.
Computational Linguistics, 19(2):313?330.M.
A.
Mart?
?, M.
Taule?, L. Ma`rquez, and M. Bertran.2007.
CESS-ECE: A multilingual and multilevelannotated corpus.
Available for download from:http://www.lsi.upc.edu/?mbertran/cess-ece/.S.
Montemagni, F. Barsotti, M. Battista, N. Calzolari,O.
Corazzari, A. Lenci, A. Zampolli, F. Fanciulli,M.
Massetani, R. Raffaelli, R. Basili, M. T. Pazienza,D.
Saracino, F. Zanzotto, N. Nana, F. Pianesi, andR.
Delmonte.
2003.
Building the Italian Syntactic-Semantic Treebank.
In Abeille?
(Abeille?, 2003), chap-ter 11, pages 189?210.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nils-son, S. Riedel, and D. Yuret.
2007.
The CoNLL2007 shared task on dependency parsing.
In Proc.of the CoNLL 2007 Shared Task.
Joint Conf.
on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL).K.
Oflazer, B.
Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.2003.
Building a Turkish treebank.
In Abeille?
(Abeille?, 2003), chapter 15, pages 261?277.P.
Prokopidis, E. Desypri, M. Koutsombogera, H. Papa-georgiou, and S. Piperidis.
2005.
Theoretical andpractical issues in the construction of a Greek depen-dency treebank.
In Proc.
of the 4th Workshop on Tree-banks and Linguistic Theories (TLT), pages 149?160.1128
