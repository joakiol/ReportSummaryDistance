Proceedings of the Workshop on BioNLP, pages 28?36,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsLearning the scope of hedge cues in biomedical textsRoser Morante, Walter DaelemansCNTS - Language Technology GroupUniversity of AntwerpPrinsstraat 13, B-2000 Antwerpen, Belgium{Roser.Morante,Walter.Daelemans}@ua.ac.beAbstractIdentifying hedged information in biomedicalliterature is an important subtask in informa-tion extraction because it would be mislead-ing to extract speculative information as fac-tual information.
In this paper we present amachine learning system that finds the scopeof hedge cues in biomedical texts.
The sys-tem is based on a similar system that finds thescope of negation cues.
We show that the samescope finding approach can be applied to bothnegation and hedging.
To investigate the ro-bustness of the approach, the system is testedon the three subcorpora of the BioScope cor-pus that represent different text types.1 IntroductionResearch on information extraction of biomedicaltexts has grown in the recent years.
Most workconcentrates on finding relations between biologi-cal entities, like genes and proteins (Krauthammeret al, 2002; Mitsumori et al, 2006; Krallinger etal., 2008a; Krallinger et al, 2008b).
Determiningwhich information has been hedged in biomedicalliterature is an important subtask of information ex-traction because extracted information that falls inthe scope of hedge cues cannot be presented as fac-tual information.
It should be discarded or presentedseparately with lower confidence.
The amount ofhedged information present in texts cannot be un-derstimated.
Vincze et al (2008) report that 17.70%of the sentences in the abstracts section of the Bio-Scope corpus and 19.44% of the sentences in thefull papers section contain hedge cues.
Light et al(2004) estimate that 11% of sentences in MEDLINEabstracts contain speculative fragments.
Szarvas(2008) reports that 32.41% of gene names men-tioned in the hedge classification dataset describedin Medlock and Briscoe (2007) appears in a specu-lative sentence.In this paper we present a machine learning sys-tem that finds the scope of hedge cues in biomedicaltexts.
Finding the scope of a hedge cue means deter-mining at sentence level which words in the sentenceare affected by the hedge cue.
The system combinesseveral classifiers and works in two phases: in thefirst phase hedge cues (i.e., words indicating spec-ulative language) are identified, and in the secondphase the full scope of these hedge cues is found.This means that for a sentence like the one in Ex-ample (1) taken from the BioScope corpus (Szarvaset al, 2008), the system performs two actions: first,it detects that suggest, might, and or are hedge sig-nals; second, it detects that suggest has as its scopeexpression of c-jun, jun B and jun D genes might beinvolved in terminal granulocyte differentiation or inregulating granulocyte functionality, that might hasas its scope be involved in terminal granulocyte dif-ferentiation or in regulating granulocyte functional-ity, and that or has as its scope in regulating granu-locyte functionality.
(1) These results <xcope id=?X7.5.3?
><cue type= ?speculation?
ref=?X7.5.3?> suggest </cue> that <xcopeid= ?X7.5.2?>expression of c-jun, jun B and jun Dgenes <cue type= ?speculation?
ref= ?X7.5.2?> might</cue> be involved <xcope id=?X7.5.1?>in terminalgranulocyte differentiation <cue type= ?speculation?ref=?X7.5.1?
>or</cue> in regulating granulocytefunctionality </xcope></xcope></xcope>.28Contrary to current practice to only detect modal-ity, our system also determines the part of the sen-tence that is hedged.
We are not aware of other sys-tems that perform this task.
The system is based on asimilar system that finds the scope of negation cues(Morante and Daelemans, 2009).
We show that thesystem performs well for this task and that the samescope finding approach can be applied to both nega-tion and hedging.
To investigate the robustness ofthe approach, the system is tested on three subcor-pora of the BioScope corpus that represent differenttext types.
Although the system was developed andtested on biomedical text, the same approach canalso be applied to text from other domains.The paper is organised as follows.
In Section 2,we summarise related work.
In Section 3, we de-scribe the corpus on which the system has been de-veloped.
In Section 4, we introduce the task to beperformed by the system, which is described in Sec-tion 5.
Results are presented and discussed in Sec-tion 6.
Finally, Section 7 puts forward some conclu-sions.2 Related workHedging has been broadly treated from a theoreticalperspective.
The term hedging is originally due toLakoff (1972), who introduces it in relation to pro-totype theory.
Palmer (1986) defines a term relatedto hedging, epistemic modality, which expresses thespeaker?s degree of commitment to the truth of aproposition.
Saur??
et al (2006) research the modal-ity of events, which ?expresses the speaker?s degreeof of commitment to the events being referred to ina text?.
They treat a wide spectrum of modal typesand present the codification of modality informationwith the specification language TimeML, which al-lows to mark modality cues at a lexical level and ata syntactic level.As for research that focuses specifically on scien-tific texts with descriptive purposes, Hyland (1998)describes hedging in scientific research articles,proposing a pragmatic classification of hedge ex-pressions based on an exhaustive analysis of a cor-pus.
The catalogue of hedging cues includes modalauxiliaries, epistemic lexical verbs, epistemic ad-jectives, adverbs, and nouns.
Additionally, it in-cludes also a variety of non?lexical cues.
Light etal.
(2004) analyse the use of speculative languagein MEDLINE abstacts.
They studied the expressionof levels of belief (hypothesis, tentative conclusions,hedges, and speculations) and annotated a corpusof abstracts in order to check if the distinction be-tween high speculative, low speculative and definitesentences could be made reliably.
They found thatthe speculative vs. definite distinction was reliable,but the distinction between low and high speculativewas not.
Thompson et al (2008) report on a list ofwords and phrases that express modality in biomed-ical texts and put forward a categorisation scheme.The list and the scheme are validated by annotating202 MEDLINE abstracts.Some NLP applications incorporate modality in-formation.
Friedman et al (1994) develop a med-ical text processor ?that translates clinical informa-tion in patient documents into controlled vocabularyterms?.
The system uses a semantic grammar thatconsists of rules that specify well-formed semanticpatterns.
The extracted findings are assigned oneof five types of modality information: no, low cer-tainty, moderate certainty, high certainty and cannotevaluate.
Di Marco and Mercer (2005) use hedginginformation to classify citations.
They observe thatcitations appear to occur in sentences marked withhedging cues.Work on hedging in the machine learning fieldhas as a goal to classify sentences into speculativeor definite (non speculative).
Medlock and Briscoe(2007) provide a definition of what they consider tobe hedge instances and define hedge classificationas a weakly supervised machine learning task.
Themethod they use to derive a learning model froma seed corpus is based on iteratively predicting la-bels for unlabeled training samples.
They report ex-periments with SVMs on a dataset that they makepublicly available1.
The experiments achieve a re-call/precision break even point (BEP) of 0.76.
Theyapply a bag-of-words (BOG) approach to samplerepresentation.
Medlock (2008) presents an exten-sion of this work by experimenting with more fea-tures (part-of-speech (PoS), lemmas, and bigrams).Experiments show that the PoS representation doesnot yield significant improvement over the results in1Available athttp://www.benmedlock.co.uk/hedgeclassif.html.29Medlock and Briscoe (2007), whereas with a lemmarepresentation the system achieves a peak perfor-mance of 0.8 BEP, and with bigrams of 0.82 BEP.Szarvas (2008) follows Medlock and Briscoe (2007)in classifying sentences as being speculative or non-speculative.
Szarvas develops a MaxEnt system thatincorporates bigrams and trigrams in the feature rep-resentation and performs a complex feature selectionprocedure in order to reduce the number of keywordcandidates.
It achieves up to 0.85 BEP and 85.08F1 by using an external dictionary.
Kilicoglu andBergler (2008) apply a linguistically motivated ap-proach to the same clasification task by using knowl-edge from existing lexical resources and incorpo-rating syntactic patterns.
Additionally, hedge cuesare weighted by automatically assigning an informa-tion gain measure and by assigning weights semi?automatically depending on their types and central-ity to hedging.
The system achieves results of 0.85BEP.As mentioned earlier, we are not aware of re-search that has focused on learning the scope ofhedge signals inside or outside of the biomedical do-main, which makes a direct comparison with the ap-proaches described here impossible.3 Hedge cues in the BioScope CorpusThe system has been developed using the BioScopecorpus (Szarvas et al, 2008; Vincze et al, 2008)2,a freely available resource that consists of medicaland biological texts.
In the corpus, every sentence isannotated with information about negation and spec-ulation.
The annotation indicates the boundaries ofthe scope and the keywords, as shown in (1) above.In the annotation, scopes are extended to the biggestsyntactic unit possible, so that scopes have the max-imal length, and the speculation cue is always in-cluded in the scope.The BioScope corpus consists of three parts: clin-ical free-texts (radiology reports), biological full pa-pers and biological paper abstracts from the GENIAcorpus (Collier et al, 1999).
Table 1 shows statisticsabout the corpora.
Hedge cues are represented byone or more tokens, as (2) shows, where the hedgecues that appear in the three corpora are listed.
Thecomplete list of all hedge cues comprises 176 cues.2Web page: www.inf.u-szeged.hu/rgai/bioscope.In the same corpora the number of negation cues islower, 38.
(2) apparent, apparently, appear, assume, can, consider,consistent with, could, either, indicate, likely, may, noevidence, not, or, perhaps, possible, possibly,presumably, probable, probably, should, suggestion,support, think, unclear, whether, would35 hedge cues that occur in the clinical reportssubcorpus do not occur in the abstracts subcorpus,and 34 hedge cues that appear in the papers subcor-pus do not appear in the abstracts subcorpus.
Only15.90% of the total of hedge cues appear in the threesubcorpora.
The most frequent hedge cues in the ab-stracts subcorpus are may (19.15 %), appear (5.30%), and or (4.45 %); in the papers subcorpus, sug-gest (10.26 %), may (9.97 %), and might (5.86 %);and in the clinical subcorpus, or (24.27 %), suggest(5.62 %), and evaluate for (5.27 %).Clinical Papers Abstracts#Documents 1954 9 1273#Sentences 6383 2670 11871#Words 41985 60935 282243#Lemmas 2320 5566 14506Av.
length sentences 7.73 26.24 26.43%Hedge sentences 13.39 19.44 17.70# Hedge cues 1189 714 2769Av.
length scopes 5.92 14.37 16.27Av.
length scopes 5.15 13.00 15.44to the rightAv.
length scopes 2.46 5.94 5.60to the left% Scopes to the right 73.28 76.55 82.45% Scopes to the left 26.71 23.44 17.54Table 1: Statistics about the subcorpora in the BioScopecorpus and the hedge scopes (?Av?.
stands for average).The texts have been processed with the GENIAtagger (Tsuruoka and Tsujii, 2005; Tsuruoka et al,2005), a bidirectional inference based tagger that an-alyzes English sentences and outputs the base forms,part-of-speech tags, chunk tags, and named entitytags in a tab-separated format.
Additionally, we con-verted the annotation about scope of negation into atoken-per-token representation, following the stan-dard format of the 2006 CoNLL Shared Task (Buch-holz and Marsi, 2006), where sentences are sepa-rated by a blank line and fields are separated by asingle tab character.
A sentence consists of a se-quence of tokens, each one starting on a new line.304 Finding the scope of hedge cuesWe model this task in the same way that we mod-elled the task for finding the scope of negation(Morante and Daelemans, 2009), i.e., as two con-secutive classification tasks: a first one that consistsof classifying the tokens of a sentence as being at thebeginning of a hedge signal, inside or outside.
Thisallows the system to find multiword hedge cues.
Thesecond classification task consists of classifying thetokens of a sentence as being the first element of thescope, the last, or neither.
This happens as manytimes as there are hedge cues in the sentence.5 System descriptionThe two classification tasks (identifying hedge cuesand finding the scope) are implemented using super-vised machine learning methods trained on part ofthe annotated corpus.5.1 Identifying hedge cuesIn this phase, a classifier predicts for all tokens in asentence whether a token is the first token of a hedgecue (B-cue), inside a hedge cue (I-cue), or outside ofit (O-cue).
For sentence (3) the system assigns theB-cue class to indicate, the I-cue class to that andthe O-cue class to the rest of tokens.
(3) These results indicate that a component orcomponents of NF?AT have the potential toreconstitute NF(P)The instances represent all tokens in the corpusand they have features about the token: lemma,word, part-of-speech (POS) and IOB3 chunk tag;and features about the token context: Word, POSand IOB chunk tag of 3 tokens to the right and 3 tothe left.We use IGTREE as implemented in TiMBL (ver-sion 6.1.2) (Daelemans et al, 2007).
We also ex-perimented with IB1, but it produced lower results.The classifier was parameterised by using gain ratiofor feature weighting.
According to the gain ratioscores, the most informative features are the lemmaand word of the token in focus, followed by the wordof the token to the right and of the token to the left.We performed two experiments.
In one, the testfile is preprocessed using a list of hedge cues ex-3I stands for ?inside?, B for ?beginning?, and O for ?outside?.tracted from the training corpus.
The list comprisesthe following hedge cues listed in (4).
Instances withthese hedge cues are directly assigned their class.The classifier predicts the class of the rest of tokens.In the other experiment we don?t preprocess the testfile.
(4) appear, apparent, apparently, believe, either, estimate,hypothesis, hypothesize, if, imply, likely, may, might, or,perhaps, possible, possibly, postulate, potential,potentially, presumably, probably, propose, putative,should, seem, speculate, suggest, support, suppose,suspect, think, uncertain, unclear, unkwown, unlikely,whether, would5.2 Scope findingIn this phase three classifiers predict for all tokensin the sentence whether a token is the first token inthe scope sequence (F-scope), the last (L-scope), orneither (NONE).
For the sentence in 3, the classi-fiers assign the class F-scope to indicate, L-scope toNF(P), and NONE to the rest of tokens.
A fourthclassifier is a metalearner that uses the predictionsof the three classifiers to predict the scope classes.An instance represents a pair of a hedge cue and atoken from the sentence.
This means that all tokensin a sentence are paired with all hedge cues that oc-cur in the sentence.
Hedge cues are those that havebeen classified as such in the previous phase.
Onlysentences that have hedge cues are selected for thisphase.
The three object classifiers that provide inputto the metalearner were trained using the followingmachine learning methods:?
Memory-based learning as implemented inTiMBL (Daelemans et al, 2007), a supervisedinductive algorithm for learning classification tasksbased on the k-nearest neighbor classificationrule (Cover and Hart, 1967).
In this lazy learningapproach, all training data is kept in memoryand classification of a new item is achieved byextrapolation from the most similar rememberedtraining items.?
Support vector machines (SVM) as implemented inSVMlightV6.01 (Joachims, 1999).
SVMs are de-fined on a vector space and try to find a decisionsurface that best separates the data points into twoclasses.
This is achieved by using quadratic pro-gramming techniques.
Kernel functions can be usedto map the original vectors to a higher-dimensionalspace that is linearly separable.31?
Conditional random fileds (CRFs) as implementedin CRF++-0.51 (Lafferty et al, 2001).
CRFs de-fine a conditional probability distribution over labelsequences given a particular observation sequencerather than a joint distribution over label and ob-servation sequences, and are reported to avoid thelabel bias problem of HMMs and other learning ap-proaches.The memory-based learning algorithm was pa-rameterised in this case by using overlap as the sim-ilarity metric, gain ratio for feature weighting, using7 k-nearest neighbors, and weighting the class voteof neighbors as a function of their inverse linear dis-tance.
The SVM was parameterised in the learningphase for classification, cost factor of 1 and biasedhyperplane, and it used a linear kernel function.
TheCRFs classifier used regularization algorithm L2 fortraining, the hyper-parameter and the cut-off thresh-old of features were set to 1.We have used the same features used for the sys-tem that finds the scope of negation.
The features ofthe first three classifers are:?
Of the hedge signal: Chain of words.?
Of the paired token: Lemma, POS, chunk IOB tag,type of chunk; lemma of the second and third tokensto the left; lemma, POS, chunk IOB tag, and type ofchunk of the first token to the left and three tokensto the right; first word, last word, chain of words,and chain of POSs of the chunk of the paired tokenand of two chunks to the left and two chunks to theright.?
Of the tokens between the hedge cue and the tokenin focus: Chain of POS types, distance in numberof tokens, and chain of chunk IOB tags.?
Others: A feature indicating the location of the to-ken relative to the hedge cue (pre, post, same).The fourth classifier, a metalearner, is also a CRFsas implemented in CRF++.
The features of this clas-sifier are:?
Of the hedge signal: Chain of words, chain of POS,word of the two tokens to the right and two tokens tothe left, token number divided by the total of tokensin the sentence.?
Of the paired token: Lemma, POS, word of two to-kens to the right and two tokens to the left, tokennumber divided by the total of tokens in the sen-tence.?
Of the tokens between the hedge cue and the to-ken in focus: Binary features indicating if there arecommas, colons, semicolons, verbal phrases or oneof the following words between the hedge cue andthe token in focus: Whereas, but, although, nev-ertheless, notwithstanding, however, consequently,hence, therefore, thus, instead, otherwise, alterna-tively, furthermore, moreover.?
About the predictions of the three classifiers: pre-diction, previous and next predictions of each ofthe classifiers, full sequence of previous and full se-quence of next predictions of each of the classifiers.?
Others: A feature indicating the location of the to-ken relative to the hedge cue (pre, post, same).Hedge cues in the BioScope corpus always scopeover a consecutive block of tokens, including the cuetoken itself.
However, the classifiers only predictthe first and last element of the scope.
We need toprocess the output of the classifers in order to buildthe complete sequence of tokens that constitute thescope.
We apply the following postprocessing:(5) - If one token has been predicted as FIRST and oneas LAST, the sequence is formed by the tokensbetween first and last.- If one token has been predicted as FIRST andnone has been predicted as LAST, the sequence isformed by the token predicted as FIRST.- If one token has been predicted as LAST andnone as FIRST, the sequence will start at the hedgecue and it will finish at the token predicted asLAST.- If one token has been predicted as FIRST andmore than one as LAST, the sequence will end withthe first token predicted as LAST after the tokenpredicted as FIRST, if there is one.- If one token has been predicted as LAST andmore than one as FIRST, the sequence will start atthe hedge signal.- If no token has been predicted as FIRST andmore than one as LAST, the sequence will start atthe hedge cue and will end at the first tokenpredicted as LAST after the hedge signal.6 ResultsThe results provided for the abstracts part of the cor-pus have been obtained by performing 10-fold crossvalidation experiments, whereas the results provided32for papers and clinical reports have been obtained bytraining on the full abstracts subcorpus and testingon the papers and clinical reports subcorpus.
Thelatter experiment is therefore a test of the robustnessof the system when applied to different text typeswithin the same domain.
The evaluation is made us-ing the precision and recall measures (Van Rijsber-gen, 1979), and their harmonic mean, F-score.
Wereport micro F1.In the hedge finding task, a hedge token is cor-rectly classified if it has been classified as being atthe beginning or inside the hedge signal.
We alsoevaluate the percentage of hedge cues that have beencorrectly identified.
In the scope finding task, a to-ken is correctly classified if it has been correctlyclassified as being inside or outside of the scope ofall the hedge cues that there are in the sentence.
Thismeans that when there is more than one hedge cuein the sentence, the token has to be correctly as-signed a class for as many hedge signals as thereare.
Additionally, we evaluate the percentage of cor-rect scopes (PCS).
A scope is correct if all the tokensin the sentence have been assigned the correct scopeclass for a specific hedge signal.
The evaluation interms of precision and recall measures takes as unit atoken, whereas the evaluation in terms of PCS takesas unit a scope.6.1 Hedge cue findingAn informed baseline system has been created bytagging as hedge cues the tokens with the wordslisted in (4) above.
The list has been extracted fromthe training corpus.
The results are shown in Table 2.Corpus Prec.
Recall F1 % CorrectAbstracts 55.62 71.77 62.67 70.91Papers 54.39 61.21 57.60 64.46Clinical 66.55 40.78 50.57 51.38Table 2: Baseline results of the hedge finding system.The fact that the results are lower for the papersand clinical subcorpora can be explained by the factthat the list of cues has been extracted from the train-ing corpus.Table 3 shows the results of the system.
Theresults of the system for abstracts and papers arehigher than baseline, but for clinical they are lower.This is due to the fact that in the baseline system thehedge cue or that accounts for 24.53 % of the hedgecues is 100 % correct, whereas the system achievesonly 0.72 % of correct predictions.
The score ob-tained by or is also the reason why the system pro-duces lower results for the clinical subcorpus.Corpus Prec.
Recall F1 % CorrectAbstracts 90.81 79.84 84.77 78.67Papers 75.35 68.18 71.59 69.86Clinical 88.10 27.51 41.92 33.36Table 3: Results of the hedge finding system without pre-processing.Table 4 shows the results of the system with pre-processing.
In terms of % of correct cues, the systemthat uses a preprocessed test set gets higher scores,but in terms of F1 it gets lower results, except for theclinical subcorpus.
The drop in F1 of this system iscaused by a drop in precision due to the excess offalse positives.Corpus Prec.
Recall F1 % CorrectAbstracts 60.74 94.83 74.05 96.03Papers 56.56 84.03 67.61 88.60Clinical 71.25 52.33 60.34 64.49Table 4: Results of the hedge finding system with prepro-cessing.In the abstracts subcorpus the hedge cue that hasthe biggest proportion of false positives is or.
Of the1062 accurrences of or, in 88.32% of the cases or isnot a hedge cue.
The system that uses preprocessingproduces 938 false positives and 4 false negatives,whereas the other system produces 21 false positivesand 108 false negatives.
In the papers subcorpus, thehedge cues if, or, can, indicate and estimate cause67.38% of the false positives.
In the clinical subcor-pus the hedge cues evidence, evidence of, no and ap-pear cause 88.27% of the false positives.
In contrastwith the abstracts subcorpus, the hedge cue or hasonly 5 false positives and scores an F1 of 99.10.
So,in the clinical corpus or is not ambiguous, whereasin the abstracts subcorpus it is very ambiguous.
Anexample of or as hedge cue in the clinical subcorpusis shown in (6).
An example of or as hedge cue inthe abstracts subcorpus is shown in (7), and as a noncue in (8).33(6) Findings compatible with reactive airway diseaseor viral lower respiratory tract infection.
(7) Nucleotide sequence and PCR analysesdemonstrated the presence of novel duplications ordeletions involving the NF-kappa B motif.
(8) In nuclear extracts from monocytes ormacrophages, induction of NF-KB occurred only ifthe cells were previously infected with HIV-1.Compared to negation cues, hedge cues are morevaried and more ambiguous.
Both the system with-out and with preprocessing for negation finding per-formed better than the hedge finding system.6.2 Scope findingAn informed baseline system has been created bycalculating the average length of the scope to theright of the hedge cue in each corpus and taggingthat number of tokens as scope tokens.
We take thescope to the right for the baseline because it is muchmore frequent than the scope to the left, as is shownby the statistics contained in Table 1 of Section 3.Baseline results are presented in Table 5.
The lowPCS for the three subcorpora indicates that findingthe scope of hedge cues is not a trivial task.
The factthat, despite a very low PCS, precision, recall andF1 are relatively high indicates that these measuresare in themselves not reliable to evaluate the perfor-mance of the system.Corpus Prec.
Recall F1 PCSAbstracts 78.92 62.19 69.56 3.15Papers 72.03 50.43 59.33 2.19Clinical 64.92 25.10 36.20 2.72Table 5: Baseline results of the scope finding system.The upper-bound results of the metalearner sys-tem assuming gold standard identification of hedgecues are shown in Table 6.Corpus Prec.
Recall F1 PCS PCS-2Abstracts 89.71 89.09 89.40 77.13 78.21Papers 77.78 77.10 77.44 47.94 58.21Clinical 79.16 78.13 78.64 60.59 63.94Table 6: Results of the scope finding system with gold-standard hedge signals.The percentage of correct scopes has been mea-sured in two ways: PCS measures the proportionof correctly classified tokens in the scope sequence,whereas PCS-2 measures the proportion of nounsand verbs that are correctly classifed in the scopesequence.
This less strict way of computing correct-ness is motivated by the fact that being able to deter-mine the concepts and relations that are speculated(indicated by content words) is the most importantuse of the hedge scope finder.Results show that the system achieves a high per-centage of fully correct scopes, and that, althoughperformance is lower for the papers and clinical cor-pora, the system is portable.
Table 7 shows the re-sults of the negation scope finding system also withgold standard negation cues.
The comparison of re-sults shows that for abstracts and papers the scoresare higher for the hedge system, which means thatthe system can be used for finding both types ofscope.Corpus Prec.
Recall F1 PCS PCS-2Abstracts 90.68 90.68 90.67 73,36 74.10Papers 84.47 84.95 84.71 50.26 54.23Clinical 91.65 92.50 92.07 87.27 87.95Table 7: Results of the negation scope finding systemwith gold-standard negation signals.The results of the hedge system with predictedhedge cues are presented in Table 8.
The hedge cueshave been predicted by the system without the pre-processing step presented in Subsection 6.1.Corpus Prec.
Recall F1 PCS PCS-2Abstracts 85.77 72.44 78.54 65.55 66.10Papers 67.97 53.16 59.66 35.92 42.37Clinical 68.21 26.49 38.16 26.21 27.44Table 8: Results of the scope finding system with pre-dicted hedge signals.In terms of PCS, which is a scope based measure,results are considerably higher than baseline results,whereas in terms of precision, recall and F1, whichare token based measures, results are lower.
Eval-uating the system in terms of a more relaxed mea-sure (PCS-2) does not reflect a significant increasein its performance.
This suggests that when a scopeis incorrectly predicted, main content tokens are alsoincorrectly left out of the scope or added.Results also show that the system based on pre-dicted hedge cues performs lower for all corpora,34which is also a trend observed for the negation scopefinding system.
The difference in performance forabstracts and papers follows the same trends as inthe negation system, whereas the drop in perfor-mance for the clinical subcorpus is bigger.
Thiscan be explained by the results obtained in the cuesfinding phase, where the clinical subcorpus obtainedonly 41.92% F1.
However, gold standard resultsshow that if the hedge cues are identified, then thesystem is portable.Abstracts Papers Clinical# PCS # PCS # PCSappear 143 58.04 39 28.20 - -can 48 12.5 25 0.00 22 0.00consistent with - - - - 67 0.00could 67 11.94 28 14.28 36 22.22either 28 0.00 - - - -evaluate for - - - - 86 3.84imply 21 90.47 - - - -indicate 23 73.91 - - - -indicate that 276 89.49 - - - -likely 59 59.32 36 30.55 63 66.66may 516 81.39 68 54.41 107 80.37might 72 73.61 40 35.00 - -or 120 0.00 - - 276 0.00possible 50 66.00 24 54.16 26 80.76possibly 25 52.00 - - - -potential 45 28.88 - - - -potentially 21 52.38 - - - -propose 38 63.15 - - - -putatitve 39 17.94 - - - -rule out - - - - 61 0.00suggest 613 92.33 70 62.85 64 90.62think 35 31.42 - - - -unknown 26 15.38 - - - -whether 96 72.91 - - - -would - - 21 28.57 - -Table 9: PCS per hedge cue for hedge cues that occurmore than 20 times in one of the subcorpus.Table 9 shows the PCS results per hedge cue.
Thecues that get better scores in the clinical and paperssubcorpora are cues that appear in the abstracts sub-corpus and get a good score.
Cues that occur in theclinical subcorpus and do not occur in the abstracts(training) subcorpus, get 0.00 score or close to 0.00,whereas cues that appear in both subcorpora tend toget a similar or better score in the clinical subcor-pus.
This is a trend that we also observed in thenegation scope finding system.
As with that system,we also observed that the papers subcorpus tends toget lower scores than the abstracts subcorpus.The results of the system based on gold standardhedge cues showed that the system can be appliedto negation scope finding and hedge scope finding,but these results show that the results of the secondphase of the system depend on the results of the firstphase of the system, and that finding hedge cuesis a domain dependent task.
The cues that are notpresent in the training data cannot be learned in thetest data and the same applies to their scope.
Thisobservation is consistent with the observation thatthe portability of hedge classifiers is limited, madeby Szarvas (Szarvas, 2008).7 ConclusionsIn this paper we have presented a metalearning ap-proach to processing the scope of hedge cues, basedon a system that finds the scope of negation cues.
Wehave shown that the same system can find both thescope of negation and hedge cues.
The performanceof the system is evaluated in terms of percentage ofcorrect scopes on three text types.In the hedge finding phase, the system achievesan F1 of 84.77% in the abstracts subcorpus.
Ex-isting systems that classify sentences as speculativeor not reach an 85.00 BEP.
Although the tasks aredifferent, we consider that the results of our systemare competitive.
In the scope finding phase, the sys-tem that uses predicted hedge cues achieves 65.55%PCS in the abstracts corpus, which is very similarto the result obtained by the negation scope findingsystem with predicted negation cues (66.07% PCS).However, the results for the papers and clinical sub-corpora are considerably lower than the results forthe abstracts subcorpus in the two phases.
In thecase of the negation scope finding system, the evalu-ation on the clinical subcorpus yielded a 4.23% PCShigher result, whereas in the case of the hedge scopefinding system the results are almost 30.00% PCSlower, confirming the observation that the portabil-ity of hedge classifers is limited.
Future researchwill focus on trying to improve the first phase of thesystem and anlysing errors in depth in order to getinsights into how to get a better performance.AcknowledgmentsOur work was made possible through financial sup-port from the University of Antwerp (GOA projectBIOGRAPH).
We are thankful to three anonymousreviewers for their valuable comments.35ReferencesS.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In Proc.
of the XCoNLL Shared Task, New York.
SIGNLL.N.
Collier, H.S.
Park, N. Ogata, Y. Tateisi, C. Nobata,T.
Sekimizu, H. Imai, and J. Tsujii.
1999.
The GE-NIA project: corpus-based knowledge acquisition andinformation extraction from genome research papers.In Proc.
of EACL 1999.T.
M. Cover and P. E. Hart.
1967.
Nearest neighborpattern classification.
Institute of Electrical and Elec-tronics Engineers Transactions on Information The-ory, 13:21?27.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A. Vanden Bosch.
2007.
TiMBL: Tilburg memory basedlearner, version 6.1, reference guide.
Technical ReportSeries 07-07, ILK, Tilburg, The Netherlands.C.
Di Marco and R.E.
Mercer, 2005.
Computing attitudeand affect in text: Theory and applications, chapterHedging in scientific articles as a means of classifyingcitations.
Springer-Verlag, Dordrecht.C.
Friedman, P. Alderson, J. Austin, J.J. Cimino, and S.B.Johnson.
1994.
A general natural?language text pro-cessor for clinical radiology.
JAMIA, 1(2):161?174.K.
Hyland.
1998.
Hedging in scientific research articles.John Benjamins B.V, Amsterdam.T.
Joachims, 1999.
Advances in Kernel Methods -Support Vector Learning, chapter Making large-ScaleSVM Learning Practical, pages 169?184.
MIT-Press,Cambridge, MA.H.
Kilicoglu and S. Bergler.
2008.
Recognizing specu-lative language in biomedical research articles: a lin-guistically motivated perspective.
BMC Bioinformat-ics, 9(Suppl 11):S10.M.
Krallinger, F. Leitner, C. Rodriguez-Penagos, andA.
Valencia.
2008a.
Overview of the protein?proteininteraction annotation extraction task of BioCreativeII.
Genome Biology, 9(Suppl 2):S4.M.
Krallinger, A. Valencia, and L. Hirschman.
2008b.Linking genes to literature: text mining, informa-tion extraction, and retrieval applications for biology.Genome Biology, 9(Suppl 2):S8.M.
Krauthammer, P. Kra, I. Iossifov, S.M.
Gomez,G.
Hripcsak, V. Hatzivassiloglou, C. Friedman, andA.Rzhetsky.
2002.
Of truth and pathways: chasingbits of information through myriads of articles.
Bioin-formatics, 18(Suppl 1):S249?57.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of ICML2001, pages 282?289.G.
Lakoff.
1972.
Hedges: a study in meaning criteriaand the logic of fuzzy concepts.
Chicago LinguisticsSociety Papers, 8:183?228.M.
Light, X.Y.Qiu, and P. Srinivasan.
2004.
The lan-guage of bioscience: facts, speculations, and state-ments in between.
In Proc.
of the BioLINK 2004,pages 17?24.B.
Medlock and T. Briscoe.
2007.
Weakly supervisedlearning for hedge classification in scientific literature.In Proc.
of ACL 2007, pages 992?999.B.
Medlock.
2008.
Exploring hedge identification inbiomedical literature.
JBI, 41:636?654.T.
Mitsumori, M. Murata, Y. Fukuda, K Doi, and H. Doi.2006.
Extracting protein-protein interaction informa-tion from biomedical text with svm.
IEICE - Trans.Inf.
Syst., E89-D(8):2464?2466.R.
Morante and W. Daelemans.
2009.
A metalearningapproach to processing the scope of negation.
In Proc.of CoNLL 2009, Boulder, Colorado.F.R.
Palmer.
1986.
Mood and modality.
CUP, Cam-bridge, UK.R.
Saur?
?, M. Verhagen, and J. Pustejovsky.
2006.
Anno-tating and recognizing event modality in text.
In Proc.of FLAIRS 2006, pages 333?339.G.
Szarvas, V. Vincze, R. Farkas, and J. Csirik.
2008.The BioScope corpus: annotation for negation, uncer-tainty and their scope in biomedical texts.
In Proc.
ofBioNLP 2008, pages 38?45, Columbus, Ohio.
ACL.G.
Szarvas.
2008.
Hedge classification in biomedi-cal texts with a weakly supervised selection of key-words.
In Proc.
of ACL 2008, pages 281?289, Colum-bus, Ohio, USA.
ACL.P.
Thompson, G. Venturi, J. McNaught, S. Montemagni,and S. Ananiadou.
2008.
Categorising modality inbiomedical texts.
In Proc.
of the LREC 2008 Workshopon Building and Evaluating Resources for BiomedicalText Mining 2008, pages 27?34, Marrakech.
LREC.Y.
Tsuruoka and J. Tsujii.
2005.
Bidirectional in-ference with the easiest-first strategy for tagging se-quence data.
In Proc.
of HLT/EMNLP 2005, pages467?474.Y.
Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught,S.
Ananiadou, and J. Tsujii, 2005.
Advances in Infor-matics - 10th Panhellenic Conference on Informatics,volume 3746 of LNCS, chapter Part-of-Speech Taggerfor Biomedical Text, Advances in Informatics, pages382?392.
Springer, Berlin/Heidelberg.C.J.
Van Rijsbergen.
1979.
Information Retrieval.
But-terworths, London.V.
Vincze, G. Szarvas, R. Farkas, G. Mo?ra, and J. Csirik.2008.
The BioScope corpus: biomedical texts anno-tated for uncertainty, negation and their scopes.
BMCBioinformatics, 9(Suppl 11):S9.36
