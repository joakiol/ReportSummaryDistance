Entity-Oriented ParsingPhilip J. HayesComputer Science Department, Carnegie.Mellon LlniversityPi~tsbur~ih, PA 152_13, USAAbst ract  fAn entity-oriented approach to restricted-domain parsing isproposed, In this approach, the definitions of the structure andsurface representation of domain entities are grouped together.Like semantic grammar, this allows easy exploitation of limiteddolnain semantics.
In addition, it facilitates fragmentaryrecognition and the use of multiple parsing strategies, and so isparticularly useful for robust recognition of extragrammaticalinput.
Several advantages from the point of view of languagedefinition are also noted.
Representative samples from anenlity-oriented language definition are presented, along with acontrol structure for an entity-oriented parser, some parsingstrategies that use the control structure, and worked examplesof parses.
A parser incorporaling the control structure and theparsing strategies is currently under implementation.1.
Introduct ionThe task of lypical natural language interface systems is muchsimpler than the general problem of natural languageunderstanding: The simplificati~ns arise because:1. the systems operate within a highly restricted domain ofdiscourse, so that a preci..~e set of object types c;~n beestablished, and many of tl;e ambiguities that come up inmore general natural language processing can be ignored orconstrained away;2. even within the restricted dolnain of discourse, a naturallanguage i.terface system only needs to recognize a limitedsubset of all the Ihings that could be said - -  the subset thatits back-end can respond to.The most commonly used tr:chnique to exploit these limiteddomain constraints is semantic ~j~amrnar \[I, 2, 9\] in whichsemantically defined categories (such as <ship> or <ship-attrihute>) are used in a gramrnur (usually ATN based) in place ofsyntactic categories (such as <noun> or <adjective>).
Whilesemantic grammar has been very successful in exploiting limiteddomain constraint.~ to reduce ambiguities and eliminate spuriousparses of grammatical input, it still suffers from the fragility in theface of extragrammatical input characteristic of parsing based ontransition nets \[41.
AI~o.
the task of restricted-domain languagedefinition is typically difficult in interlaces based on semanticgrammar, in part bscaus~ th.,: grammar definition formalism is notwell imegrated with the method of d~..fining the object and actionsof tl~e domain of discourse (though see \[6\]).1This r~t,;e~rch wmJ spont;(.cd by the At; Fnrco Office of Scient=fic Resr.,'l?,";hund{;r Cow,tract AFOC, R-82-0219\]his paper proposes an alternat;ve approach to restricteddomain langua~fe recognition calI~d entity-oriented p;rsing.Entity-orie=-ted parsing uses the same notion of semar~tlcally-defined catctjeries a.
', ~2mantic grammar, but does net embedthese cate,:.iories in a grammatical structure designed for sy.tacticrecognition.
Instead, a scheme more reminiscent of conceptual orcase.frame parsers \[3, 10, I I \ ]  is employmf.
An entity-orientedparser operates from a collection of definitions of the variousentities (objects.
events, cem, m~mds, states, etc.)
that a particularinterf:~ce sy-~teln needs to r:.~cognize.
These definitions containinformatiol~ about the internal structure of the entities, about theway the entitie:~ will be manifested in the natural language input,s~}(I about the correspondence belween the internal shucture andsurface repres.~ntation.
\]his arrangement provides a goodfrarnewo~k for exploiting the simplifications possible in restricted?locY~ain att:rnl anouage recognition because:1. the entitle:z; form a ~dtural set of !ypes through which tocun:~train Ih~; recognition semantically.
the types also form ap.alura~ basis fnr the structurctl definitions of entities.2.
the set of things thai the back-end can respond tocorresponds to a subSet of the domain -:-nlities (rememberthat entities can be events or commar,ds as well as objects).Re the f~o~l of an entity.ori,;nted ~ystem will normally be torecognize one of a "top.ievel" class of entities.
This isanalogous to the sot el basic message pa~.terns that Lheir;\[~.chin~; translation system of Wilks \[11\] aimed to recognizein any input.In addition to providing a good general basis for restricteddomain n41ural language recognition, we claim that the entity~o;iented ,~pproach also fa,.
;iJitate5 rubu:.
;tness in the face ofex~r~tgrammatical input ~.l~(I ease nf k~guage definition forros;r!ctc:l d'm;cJn I~ng~.~Ua:~.
EnLity.arie,~ted parsh;g I',.~.s thepotential to provide better parsing robustness Lhan moretraditional semantic gramn~;\]r techniques for two major reasons:?
The individual definition of aq domain entities facilit~los theirindepcncl,~mt recoL4rfilion.
As:,um;;t,':l there is apl)rof~riaLeinde'<ing at entiLies tl~rough lex~cai ~toms that mir;iht appt~ar ina surface dt.
'.~cription '.
}f them.
thi:~ rc.cognitior: c;;n be donebottom.up, thus rnuking pos:.ible recognition of elliptical,tru~Fner{~ary, or p~rtially incornpr~.h~;,,siblo input.
The samede~imtions can ~i..-;(, be us~cl i~ a m.:.~re ft;cic:nt top-downf\[l;Jt*ll!~:'l when t!le input conlorrns to the system'sexDect.alio~\]s.,, Recem work \[5, 8\] h~ls suggested the usefulness of multiplecor~structioq.specific reco.qnition str;tt(;gies f,ar restrict,~ddomah\] parsing, pat ticularly for dealing witllextragr;.'nimaiic.q!
input.
1 he ir~dividual entity cJo!initlons forman i(h;al \[rc, rnewur}~ arcq~,d which to organize lhr multiple212strateg!es.
In particular, each definitio~ can specify whichstrategies are applicable to recognizing it.
Of course, "thisonly provides a framework for robust recognition, therobustness achieved still depends on the quality of the actualrecognition strategies used.The advantages of entity-oriented parsing for languagedefinition include:?
All information relating to an entity is grouped in one place,so that a language definer will be able to see more clearlywhether a dehnition is complete and what would be theconseouences of any addition or change to the definition.?
Since surface (syntactic) nnd structural information about anentity is groupe~t o~\]ether, tile s,.trface information cau referto the structure in a clear al';{\] coherent way.
In particular,this allows hierarchical surface information to use the naturalhierarchy defined by the structural informatiol~, leading togreater consistency of coverage in the surface language.?
Since entity definitions are independent, the informationnecessary In drive Jecognilion by the mulliple construction-spucific strL, tegi~:s mentioned above can be representeddirectly in the form most useful to each strategy, thusremoving the need for any kind of "grammar co~pilation"step and allowing more rapid ?irammar development.In the remainder of the paper, we make these arguments moreconcrete by looking at some fragments of an entity-orientedlan(\]u~ge definition, by outlining the control :~truclure of a robustresUicted-domain parser driven by such defiqitions, and by tracingthrough some worked examples of !he parser in operation.
Theseexamples also shown describe some specifi~ parsing strategiesthat exploit the control structures.
A parser i~=corporating thecontrol structure and the parsing strategies is currently underimplementation.
Its design embodies our e;{perience with ~ pilotentily-oriented parser that has already been implemented, but isnot described here.r - -v  4 .,.
~ , ,ampie  Ent i ty  Def in i t ionsThis section present'~ .~r)me example eat=t,/ and language(lefi,fitions suitable for use in entity-oriente(\] parsing.
Theexamples are drawn fi om the Oomain of an in!~rface to a databaseof college courses.
Here is the (partial) de\[initio=~ of a course,\[Ent ttyNarne : Col legeCoursetype :  S t ructuredComponents : (\[Componen tName: ?.otlrseNumbertype:  In tegerGreater1han : g9LeSSI I~an : |000\]\[ComponentName : CourseDepartmentlype :  Co1 legeDepartment\]\[ C 011ll}0 n e n L N ~ll\[le : CourseC I&ssF3,po : Col legeC lass\]\[CemponentName : Cuurse \ [ns t ructo?lype:  Co l |egeProressorJ)Silt raceRupresen LaL ion:\ [SynLaxfype  : NounPhr~seIIo,l?l: ( course  I sesninsr$CoursoDepartmenL SCour'set, umber I ?
?
?
)Ad iec t iva lCo , lponen?s :  (Courseaepartment  .
.
.
)Ad jec t ives :  (JAd jecL iva \ ]Phrase :  (new J most.
recent )CotllpOllOn L : CollrseSemos te rValue:  CUI'I t!q LSdm(}S ter\]i "PostNomina ICases: (\ [P repos iL ion :  ( ?
in tended For J d i rec ted  to J .
)Cofi|ponellt : CourseClassJLPr l :pos iL ion :  (?L~ughL b v I .
.
, )Colnpollel1 t : Co(~rse \[ i1.~ L rl lc to t\])J\]For reasons of space, we cannot explain all the details of thislanguage.
In essence, zz course is definc'd as 3 structured objectwith components: number, department, instructor, etc.
(squarebrackets denote attribute/value lists, and round brackets ordinarylists).
"lhis definition is kept separate from the surfacerepresentation of a course which is defined to be a noun phrasewith adjectives, postnor~irla!
cases, etc.. At a more deiailed level,note the special purpose way of specifying a course by itsdepartment juxtaposed with its number (e.g.
Computer Science101) is handled by an alternate patt.
'.,rn for the head of the nounphrase (dollar signs refer back to the components).
Tiffs allowsthe user to s,sy (redur=,~antly) phrases like "CS 101 taught bySmith".
Nolo.
also that the way the dep~?rtment of a course canappear in the surface representation of a course is specified interms of the ?
:ourseDepartment component (and hence in terms ofits type, Colleg(;Depmln\]ent) rather than directly as an explicitsurface representation.
This ensures consistency througl~out thelanguage in what will be recognized as a description of adepartment.
Coupled wdh the ability to use general syntacticdescriptors (like NounPhrase in the description of aSurfaceRepresentation), this can prevent the ki~,J of patchycoveraqe prevalent with standard semantic grammar languagedefinitions.Subsidiary objects like CollegeDepartment are defined in similarfashion.\[r n t i LyNnmn : ?o I I egel)epa v Linen t|ypo:  Er.uiiler'~L ionE numeratodVa lues : {Conlptltel SC i ,nceDepar tmentMa t hema I. i c sl)el)a r Linen tII i s tory l JeparLment"i"Sur faceRepresentat  ion :J Syntax lype :  PaLternSetPat terns :  (\ [Pat t * : rn :  (CS I Computer Sc ie ,ce  J Camp Sol J .
.
.
)Va hte : CompuLerSc ietLcel}~lpal'tment\])\]1213r;cllegeCoursu will also be involved in higher-level entities ef ourrestricted domain such as a cc}mrnan(I to the data base ay.
*t:.~m to+:.rol a student in a course.\[I Ill. i~l,lall lO: \[l)l'O|COlll/ll~tl(Il ype :  S t ructuredComllonul~ts : (I.CompononI.Nam+!
: Fnro l  leofypo :  CO I I~UeSL.det~L.I\[CemponenLNamu : I :nee\]  \[nType: Co I leg,'~Co,lrse\])Sur f 'aceRopr , ; se .
ta  L =el;:Sy=lta~ \[:tp~,: \[lll;~.~r.lt.
iveC.tsel 'ramoIlea'J: ( corg i  I ?et l iSLe?
\] inc l~( le  \[ .
.
.
)II i re?
LObju,: I.: ($E .
ro l  lee)Cases: (\ [P repos iL i ,~n:  ( in  I to te  J .
.
.
)CO;tlpOltOl| L : ~: It I'01 \] I}\])\]\]These examples als~ show how all information about an entity,co.cerning both tundamental structure and surfacerepresentation, is grouped tooeth',~r al~d integrated.
Tiff,.
; supportsthe claim that entity-c~ri~nted lanuuage definition makes it easier todeter.nine whether a language definition is complete.3.
Control Structure for a tqcbust Entity-Oriented Parserl he  potential advanta.qes of an entily-oriented approach fromtile point of view of robLmtne.~3 in the face of ungr:?mmatical inputwere outlined in the inlrodu(.tion.
To exploit this potential whilemaintaining efficiency in parsing grammatical input, specialattention must he paid to the control structure of the parser used.Desirable characteri,=.tics for the control Structure uf ;my parsercapable of handling ungrammatical as well as grammatical inputinclude:.
the control structure allows grammatical input to be parsedstraightforwardly without consider.ring any of the possiblegralnmatical deviations d;at could occur;?
the om~trol structure enables progr~:,~siw:.ly highP.r degrees ofgrammatical (leviatior~ Io be consi(Ic~:.~d when the ilt\[~LIt doesnot satisfy grammatical exp,~ctations;?
the control structure ;dlows simpler deviatio.s to beconsidered before more complex deviations.\ ]he first two points are self-evident, but the third lll;+ty requiresome explanalion.
"The r, robl~m it addresses arises particularlywhen there are several alternative parses under consideration.
Ins.ch cases, it is important o prevent the parser h'om cons!tieringdrastic (levi.xtions in one branch of the par.~'e before cor~si(leringsi~nple ones in the othur.
For in::'.ance, tile par.~er sh(;uld not starthypothesizir=g missing words ir; one bra.ch when a ~;impl,~) sp~flli~l Ocorrection in another blanch would allow tile parse I?~ go through.We have (le-;i(jned a parser control .~hucture for use in e~,tity-oriented p~.
':;in U which i}a~; all (,~, the rh;lracteristics lis~e,t above.Thi.~ control structure operates thrr~u~;h an acJenda mechanism.Each item of the agenda represents a dii'ier,.
:nt nonU/\]uati.on of thepaine, i.e.
a partial parse plus a specificatit,+~ of what to do next tocontinue that partial parse, With each cont}nuation is associatedan integer flexibility level that represents the degree ofgrammatical deviation imphed by the continuation.
That is, theflexibility level represents the degree of grammatical deviation inthe input if the continuation were to produce a complete parse'without finding any more deviation.
Continuations with a lowerflexibility are run before continuations with a higher flexibility level.Once a complete parse has been obtained, continuations with a,flexibility level higher than that of the continuation which resultedin the parse are abandoned.
This means that the agendamechanism never activates any continuations with a flexibilitylevel higher than the level representing the lowest level ofgrammatical deviation necessary to account for the input.
Thuseffort is not wasted exploring more exotic grammatical deviationswhen the input can be accounted for by simpler ones.
This showsthat the parser has the first two of the characteristics listed above.In addition to taking care of alternatives at different flexibilitylevels, this control structure also handles the more usual kind ofalternatives faced by parsers - -  those representing alternativeparses due to local ambiguity in the input.
Whenever such anambiguity arises, the control structure duplicates the relevantcontinuation as many times as there are ambiguous alternatives,giving each of the duplicated continuations the same flexibilitylevel.
From there on, the same agenda mechanism used for thevarious flexibility levels will keep each of the ambiguousalternatives eparate and ensure that all are investigated (as longas their flexibility level is not too high).
Integrating the treatment ofthe normal kind of ambiguities with the treatment of alternativeways of handling grammatical deviations ensures that the level ofgrammatical deviation under consideration can be kept the samein locally cmbiguous branches of a parse.
This fulfills the thirdcharacteristic listed above.Flexibility levels are additive, i.e.
if some grammatical deviationhas already been found in the input, then finding a new one willraise the flexibility level of the continuation concerned to the sumof the flexibility levels involved.
This ensures a relatively h!ghflexibility level and thus a relatively low likelihood of activation forcontinuations in which combinations of deviations are beingpostulated to account for the input,Since space is limited, we cannot go into the implementation ofthis control structure.
However, it is possible to give a briefdescription of the control structure primitives used inprogramming the parser.
Recall first that the kind of entity-oriented parser we have been discussing consists of a collectionof recognition strategies.
The more specific strategies exploit theidiosyncratic features of the entities/construction types they arespecific to, while the more general strategies apply to widercl3sses of entities and depend on more universal characteristics.In either case, the strategies are pieces of (Lisp) program r~.therthan more abstract rules or networks.
Integration of suchstrategies with the general scheme of flexibility levels describedabove is made straightforward through a special split functionwhich the control structure supports as a primitive.
This splitfunction allows the programmer of a strategy to specify one ormore alternative continuations from any point in the strategy andto associate a different flexibility increment with each of them.214The implementation of this statement akes care of restarting eachof the alternative continuations at the appropriate time and withthe appropriate local context.Some examples should make this account of the controlstructure much clearer.
The examples will also present somespecific parsing strategies and show how they use the splitfunction described above.
These strategies are designed to effectrobust recognition of extragrammatical input and efficientrecognition of grammatical input by exploiting entity-orientedlanguage definitions like those in the previous section.4.
Example Parsest.et us examine first how a simple data base command like:Enro; Susan Smith in CS 101might be parsed with the control structure and languagedefin;tions presented in the two previous sections.
We start offwith the top-level parsing strategy, RecognizeAnyEntity.
Thisstrategy first tries to identify a top-level domain entity (in this casea data base command) that might account for the entire input.
Itdoes this in a bottom-up manner by indexing from words in theinput to those entities that they could appear in.
In this case, thebest indexer is the first word, 'enro!
', which indexesEnrolCommand.
In general, however, the best indexer need notbe the first word of the input and we need to consider all words,thus raising the potential of indexing more than one entity.
In ourexample, we would also index CollegeStudent, CollegeCourse,and Co!legeDepartment However, tt'ese are not top.level domainentities and are subsumed by EnrolCommand, and so can beignored in favour of it.Once EnrolCommand has been identified as an entity that mightaccount for the input, RecognizeAnyEntity initiates an attempt orecognize it.
Since EnrolCommand is listed as an imperative caseframa, this task is handled by the ImperativeCaseFramerecognizer strategy.
In contrast to the bottom-up approach ofRecognizeAnyEntity, this strategy tackles its more specific task ina top-down manner using the case frame recognition algorithmdeveloped for the CASPAR parser \[8\].
In particular, the strategywill match the case frame header and the preposition 'in', andinitiate recognitions of fillers of its direct object case and its casemarked by 'in'.
These subgoals are to recognize a CollegeStudentto fill the Enrollee case on the input segment "Susan Smith'" anda CollegeCourse to fill the Enrolln case on the segment "CS 101 ".Both of the~e recognitions will be successful, hence causing theImperativeCaseFrame r cognizer to succeed and hence the entirerecognition.
The resulting parse would be:\[InstanceOf : Enro ICo~nand?nrol\]ee: \[InstanceOt': Co\]\]egeStudentFirstNaaes : (Susan)Surname: Smith\]\[nrotZn: \[\]nstance0?
: CollegeCourseEourseDepar tment : Compute rSc I enceDepar tment.CourseNumber : t01\]\]Note how this parse result is expressed in terms of the underlyingstructural representation used in the entity definitions without theneed for a separate semantic interpretation step.The last example was completely grammatical and so did notrequire any flexibility.
After an initial bottom-up step to find adominant entity, that entity was recognized in a highly efficienttop-down manner.
For an example involving input that isungrammaUcal (as far as the parser is concerned), consider:Place Susan Smith in computer science for freshmenThere are two problems here: we assume that the user intended'place' as a synonym for 'enror, but that it happens not to be in thesystem's vocabulary; the user has a!so shortened thegrammatically acceptable phrase, 'the computer science coursefor freshmen', to an equivalent phrasenot covered by the surfacerepresentation for CollegeCourse as defined earlier.
Since 'place'is not a synonym for 'enrol' in the language as presently defined,the RecognizeAnyEntity strategy cannot index EnrolCommandfrom it and hence cannot (as it did in tl~e previous example) initiatea top-down recognition of the entire input.To deal with such eventualities, RecognizeAnyEntity executes asplit statement specifying two continuations immediately after ithas found all the entities indexed by the input.
The firstcontinuation has a zero flexibility level increment.
It looks at theindexed entities to see if one subsumes all the others.
If it findsone, it attempts a top-down recognition as described in theprevious example.
If it cannot find one, or if it does and the top-down recognition fails, then the continuation itself fails.
Thesecond continuation has a positive flexibility increment andfollows a more robust bottom-up approach described below.
Thissecond continuation was established in the previous example too,but was never activated since a complete parse was found at thezero flexibility level.
So we did not mention it.
In the presentexample, the first continuation fails since there is no subsumingentity, and so the second continuation gets a chance to run.Instead of insisting on identifyir,g a single top-level entity, thissecond continuation attempts to recognize all of the entities thatare indexed in the hope of later being able to piece together thevarious fragmentary recognitions that result.
The entities directlyindexed are CollegeStudent by "Susan" and "Smith", 2CollegeDepartment by "computer" and "science", andCollegeClass by "freshmen".
So a top-down attempt is made torecognize each of these entities.
We can assume these goals arefulfilled by simple top-down strategies, appropriate to theSurfaceRepresentation of the corresponding entities, andoperating with no flexibility level increment.Having recognized the low-level fragments, the secondcontinuation of RecognizeAnyEntity now attempts to unify theminto larger fragments, with the ultimate goal of unifying them into adescription of a single entity that spans the whole input.
To dothis, it takes adjacent fragments pairwise and looks for entities ofwhich they are both components, and then tries to recognize thesubsuming entity in the spanning segment.
The two pairs here areCollegeStudent and CollegeDepartment (subsumed byCollegeStudent) and CollegeDepartment and CollegeClass(subsumed by CollegeCourse).To investigate the second of these pairings, RecognizeAnyEntitywould try to recognize a CollegeCourse in the spanning segment'computer science for freshmen' using an elevated level offlexibility.
This gGal would be handled, just like all recognitions of215CollegeCourse, by the NominalCaseFrame recognizer.
With noflexibility increment, tiffs strategy fails because the head noun ismissing.
However.
with another flexibility increment, therecognition can go through with the CcllegeDepartment beingtreated as an adjective and the CollegeClass being treated as apostnominal case - -  it has the right case marker, "for", and theadjective and post-nominal are in the right order.
This successfulfragment unification leaves two fragments to unify - -  the oldCollegeStudent and the newly derived CollegeCourse.There are several ways of unifying a CollegeStudent and aCollegeCourse - -  either could subsume the other, or they couldform the parameters to one of three database modificationcommands: EnrolCommand, WithdrawCommand, andTransferCommand (with the obvious interpretations).
Since thecommands are higher level entities than CollegeStudent andCollegeCourse, they would be preferred as top.level fragmentunifiers.
We can also rule out TransferCommand in favour of thefirst two because it requires two courses and we only have one.
Inaddition, a recognition of EnrolCommand would succeed at alower Ile?ibility increment than WithdrawCommand, 3 since thepreposition 'in' tilat marks the CollegeCourse in the input is thecorrect marker of the Enrolln case of EnrolCommand, but is notthe appropriate marker for WithdrawFrom, the course-containingcase of WithdrawCommand.
Thus a fragment unification basedon EnrolCommand would be preferred.
Also, the alternate path offragment amalgamation - -  combining CollegeStudent andCollegeDepartment into CollegeStudent and then combiningCoilegeStudent and CollegeCourse - -  that we left pending abovecannot lead to a complete instantiation of a top-level databasecommand.
So RecognizeAnyEntity will be in a position to assumethat the user really intended the EnrolCommand.Since th~s recognition involved several significant assumptions,we would need to use focused interaction techniques\[7\] topresent the interpretation to the user for approval before acting onit.
Note that if the user does approve it, it should be possible (withfurther approval) to add 'place' to the vocabulary as a synonym for'enrol' since 'place' was an unrecognized word in the surfaceposition where 'enrol' should have been.For a final example, let us examine an extragrammatical inputthat involves continuations at several different flexibility levels:Transfel Smith from Coi,~pter Science 101 Economics 203The problems here are that 'Computer' has been misspelt and thepreposition 'to' is missing from before 'Economics'.
The exampleis similar to the first one in that RecognizeAnyEntity is able toidentify a top-level entity to be recognized top-down, in this case,TransferCommand.
Like EnrolCommand, TransferCommand is animperative case frame, and so the task of recognizing it is handledby the ImperativeCaseFrame strategy.
This strategy can find thepreposition 'from', and so can !nitiate the appropriate recognitionsfor fillers of the O.tOfCour~e and Student cases.
The recognitionfor the student case succeeds without trouble, but the recognitionfor the OutOfCourse case requires a spelling correction.2We assume we have a complete listing of students and SO can index from theirnames .Whenever a top-down parsing strategy fails to verify that aninput word is in a specific lexical class, there is the possibility thatthe word that failed is a misspelling of a word that would havesucceeded.
In such cases, the lexical lookup mechanismexecutes a split statement.
4 A zero increment branch failsimmediately, but a second branch with a small positive incrementtries spelling correction against the words in the predicted lexicalclass.
If the correction fails, this second branch fails, but if thecorrection succeeds, the branch succeeds also.
In our example,the continuation involving the second branch of the lexical lookupis highest on the agenda after the primary branch has failed.
Inparticular, it is higher than the second branch ofRecognizeAnyEntity described in the previous example, since theflexibility level increment for spelling correction is small.
Thismeans that the lexical lookup is continued with a spellingcorrection, thus resolving the problem.
Note also that since thespelling correction is only attempted within the context ofrecognizing a CollegeCourse - -  the filler of OutOfCourse - -  thetarget words are limited to course names.
This means spellingcorrection is much more accurate and efficient than if correctionwere attempted against the whole dictionary.After the OutOfCourse and Student cases have beensuccessfully filled, the ImperativeCaseFrame strategy can do nomore without a flexibility level increment.
But it has not filled allthe required cases of TransferCommand, and it has not used upall the input it was given, so it splits and fails at the zero-levelflexibility increment.
However, in a continuation with a positiveflexibility level increment, it is able to attempt recognition of caseswithout their marking prepositions.
Assuming the sum of thisincrement and the 3pelling correction increment are still less thanthe increment associated with the second branch ofRecognizeAnyEntity, this continuation would be the next one run.In this continuation, the ImperativeCaseFrameRecognizerattempts to match unparsed segments of the input against unfilledcases.
There is only one of each, and the resulting attempt torecognize 'Economics 203' as the filler of IntoCourse succeedsstraightforwardly.
Now all required cases are filled and all input isaccounted for, so the ImperativeCaseFrame strategy and hencethe whole parse succeeds with the correct result.For the example just presented, obtaining the ideal behaviourdepends on careful choice of the flexibility level increments.There is a danger here that the performance of the parser as awhole will be dependent on iterative tuning of these increments,and may become unstable with even small changes in theincrements.
It is too early yet to say how easy it will be to managethis problem, but we plan to pay close attention to it as the parsercomes into operatio n.3This relatively fine distinction between Enro\]Command andWithd~awCemmand.
based on the appropriateness of the preposition 'in', isproblem~',tical in that it assumes that the flexibility level would be incremented invery fine grained steps.
If that was impractical, the final outcome of the parsewould be ambiguous between an EnrolCommand and a WithdrawCommand andthe user would have to be asked to make the discrimination.4If this causes too many splits, an alternative is only to do the split when theinput word in question is not in the system's lexicon at all.2165.
ConclusionEntity-oriented parsing has several ~dvantages as a basisforlanguage rueognilion in restricted domain natural languageint.?\[faces.
Like techniques based on semantic grammar, itext~loits limited domain semantics through a series of domain-specific entity types.
However, because of its suitability forfragmentary recogniticn and its ability to accornmodate multipleconstruction.specific parsing strategies, it has the i>otential forgreater robustness in the face of extragrammaLical input than theusu\[;I semantic grammar techniques.
In this way, it more closelyresembles conceptual or case-frame parsi~lg tc{:t,niques.Moreover, entity-oriented pursing offers advanta.
'jes h:, I:~ngua0ed~inition because of the integration of struchlr;tl anJ :aurfJ'c~representutio~z information and the ability to ropr~ sent surta.
'.einformation in the form most convenient to drive co+zstruction.specific recogqifion strategies directly.A pilot implementation of a~ entity-oriented parser has beencompleted and provides preliminary support for our claims.t4owever, a more rigorous lest of the entity-oriented approachrnust wait for the more complete implementation <:urrently beingundertaken.
\ ]he agenda-style control structure we plan to use inthis imptementath)~ is described above, along wilh some parsingsbateGies it will employ and some worked examples of thesbategies and control structure in action.Acknowler.igementsI-he ideas in this paper benefited cousiderably from discussionswith other membr~rs of the Multipar group at Carnegie-MellonCnraputer Science Department, parlicu!arly Jaimo CarbonelL JillFain, ..rod Ste,~e F4inton.
Steva Minton was a co-dc~si?ner o!
the.control stru<;tu+e ;~resented att)ov.~:, and also founrl :m efficient w:wto iruplement he split function de.
'..cribed in coa+~ec+tion with thatcontrol structure.References1.
Brown, J. S. and Bt;rton.
R. I::l. Multiple Representations of"Q~owl~dgo for I utoriai Reasoning.
In Repf(~s,'~nt;ttion andUod~-:rstan'.'.
'mrj, Bubr,,w, D. ,.G.
and Collins, A., Ed.,AcademicPress, New York, 1975, pp.
,311-349.2.
Burton, R. R. Semantic Grammar: An Engineering Techniquefor Ccnstructing Natural I.ai%luae, ~Understanding Systems.
BBNReporl 3453, Bolt, Beranek, and Newman, Inc., Cambridge, Mass.,December, 1976.3.
Carbonell, J. G., Boggs, W. M., Mau\]din, M. L., and Anick, P. G.The ?CAI.tBUR Project: A Natural Lan{luage Interface ~o ExpertSystems.
Prt;c. Eighth Int.
Jt.
Conf.
on Artificial Intelligence,Karl.
'~ruhe, August, 1983.4.
Carbonell, J. G+ and Hayes, P.J.
"Recovery Strategies forParsing Extragrammatical Language."
Com~utational Linguistics10 (t 984).5.
Carbonell, J. G. and 14ayes, P. J.
Robust Parsing UsingMultiple Construction-Specific Strategies.
In Natural LanguagePcrsing Systems, L. Bole, Ed.,Springer-Verlag, 1984.6.
Grosz, B. J.
TEAM: A Transport\[~ble Nalural LanguageInterface System.
Prec.
Conf.
on Applie(I Natural L:~n~tuageProcessing, S'mta Monica, February, 198,3.7.
Hayes P. J.
A Construction Specific Approach to Focusedh,teraction in Flexible Parsing.
Prec.
of 19th Annual Nl~-.,~ting ofthe Assoc.
for Comp~Jt.
ling.. Stanford University, June, 1981, pp.149-152.8.
Hi:yes, P. J. and Ca~t:onell, J. G. lvtulti-Strategy P~r,~i+~g ~;nd itsRole in \[~'obust Man.
I~,tachin?.~ Cnmmunicatio'.~.
Carnegie-MellonIJ~iversity Computer Sc~olJce Department.
,May, 1981.9.
I'lendrix, G. G. Hum~.n Engine+;ring for At)plied NaturalLanguage Processi~;g. Prec.
Fifth Int.
Jt.
Conf.
on ArlificialInto!l;genc,~., t,.
;; r. 1077, pp.
183. !
91.IO.
i:hes;)e,.;;~.
C K. ao,-I Sch~-nk.
R.C.
Comprehension byC'ompuLr~r: Expectation.\[lase, l An;.tly:,;3 el S~nteac+~G irtContext.rech.
Ru'pL 7~5, C, omputc;r Science Dept., Y?1e Uoiveruity, 1976.1 I. W~lks, ?.
A. Prefere:-,ce Semantics.
In F-ormal Semantics ofIV~tural L~.ngu:zge , Keer;an, k(I..Can}bridge University Press, 1975.217
