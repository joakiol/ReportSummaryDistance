Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1455?1464,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPA Probabilistic Model for Associative Anaphora ResolutionRyohei Sasano and Sadao KurohashiGraduate School of Informatics, Kyoto University,Yoshida-honmachi, Sakyo-ku, Kyoto{sasano,kuro}@i.kyoto-u.ac.jpAbstractThis paper proposes a probabilistic modelfor associative anaphora resolution inJapanese.
Associative anaphora is atype of bridging anaphora, in which theanaphor and its antecedent are not coref-erent.
Our model regards associativeanaphora as a kind of zero anaphora andresolves it in the same manner as zeroanaphora resolution using automaticallyacquired lexical knowledge.
Experimen-tal results show that our model resolvesassociative anaphora with good perfor-mance and the performance is improvedby resolving it simultaneously with zeroanaphora.1 IntroductionThe correct interpretation of anaphora is vitalfor natural language understanding.
Bridginganaphora (Clark, 1975) represents a special part ofthe general problem of anaphora resolution, whichhas been studied and discussed for various lan-guages and domains (Hahn et al, 1996; Murata etal., 1999; Poesio et al, 2004; Gasperin and Vieira,2004; Gasperin and Briscoe, 2008).Usually bridging anaphora considers twotypes:1associative anaphors are noun phrases(NPs) that have an antecedent that is necessaryto their interpretation but the relation between theanaphor and its antecedent is different from iden-tity; and indirect anaphors are those that havean identity relation with their antecedents but theanaphor and its antecedent have different head1The terminology that we use here is introduced byHawkins (1978), which is also used in (Vieira et al, 2006).nouns.
In this paper, we focus on associativeanaphora in Japanese.Associative anaphora resolution is decomposedinto two steps: acquiring lexical knowledge for as-sociative anaphora resolution, and resolving asso-ciative anaphora using the acquired knowledge.Grammatical salience plays a lesser role forresolving anaphors with full lexical heads, thanfor pronominal anaphora (Strube and Hahn, 1999;Modjeska, 2002).
Furthermore, since associativeanaphors and their antecedents usually have differ-ent head nouns, string matching technique cannotbe applied.
Therefore, a large and diverse amountof lexical knowledge is essential to understand as-sociative anaphora.
For example, to recognize themeronymic relation between ?a house?
and ?theroof?
in (1), such knowledge as ?a roof?
is a partof a building or vehicle is required.
To recognizethe attributive relation between ?Prius?
and ?theprice?
in (2), such knowledge as ?price?
is a priceof some goods or service is required.
(1) There was a house.
The roof was white.
(2) Toyota launched the hybrid car Prius in1997.
The price was 21.5 million yen.To acquire such lexical knowledge, variousstudies have been carried out.
Early studies usedhand-crafted lexical knowledge such as Word-Net (Strube and Hahn, 1999; Vieira and Poe-sio, 2000; Meyer and Dale, 2002), but obtainedpoor or mediocre results.
Hence, Poesio et al(2002) proposed to exploit ?Nhof Nm?
phrasesin large corpora to resolve associative anaphorain English; Murata et al (1999) proposed to ex-ploit ?Nmno Nh?
phrases to resolve associativeanaphora in Japanese.
Here, the Japanese postpo-sition ?no?
roughly corresponds to ?of,?
but it has1455much broader usage.
These studies obtained rea-sonable results, but the coverage of the acquiredknowledge was not sufficient.
Recently, a num-ber of researchers argued for using the Web as asource of lexical knowledge, and theWeb has beenshown to be a useful resource for anaphora resolu-tion (Bunescu, 2003; Markert et al, 2003; Poesioet al, 2004).Hence, in this study, we acquire the lexi-cal knowledge for associative anaphora resolutionfrom ?NmnoNh?
phrases in the Web by using themethod described in (Sasano et al, 2004).
We pro-posed a method for acquiring such lexical knowl-edge, called nominal case frames (NCFs), usingan ordinary language dictionary and ?Nmno Nh?phrases, and constructed NCFs from newspapercorpora.
In this study, we aim to acquire a suffi-cient amount of lexical knowledge by constructingNCFs from the Web.As for associative anaphora resolution itself, wepropose an integrated probabilistic model for zeroanaphora and associative anaphora resolution, inwhich associative anaphora is regarded as a kindof zero anaphora and resolved by using the samemodel as zero anaphora.
Our model assumes zeropronouns that represent indispensable entities oftarget noun phrases, which are called zero adnom-inal in (Yamura-Takei, 2003), and conducts zeropronoun resolution.Let us consider the associative anaphoric re-lation between ?Prius?
and ?kakaku?
(price).Although ?kakaku?
itself is considered as theanaphor from a conventional point of view (3a),our model assumes a zero pronoun ?
and consid-ers it as the anaphor (3b).
(3) a. Prius - kakaku (price)[antecedent: Prius, anaphor: kakaku (price)]b. Prius - (?-no) kakaku (price (of ?
))[antecedent: Prius, anaphor: ?
]The point of this study is three-fold: the ac-quisition of the lexical knowledge for associativeanaphora resolution from the Web, the applicationof zero anaphora resolution model to associativeanaphora resolution, and the integrated resolutionof zero anaphora and associative anaphora.2 Construction of Nominal Case FramesMost nouns have their indispensable entities:?price?
is a price of some goods or service, ?roof?is a roof of some building, and ?coach?
is a coachof some sports.
The relation between a noun andits indispensable entities is parallel to that betweena verb and its arguments or obligatory cases.
Inthis paper, we call indispensable entities of nounsobligatory cases.
Note that, obligatory does notmean grammatically obligatory but obligatory tointerpret the meaning of the noun.
Associativeanaphora resolution needs comprehensive infor-mation of obligatory cases of nouns.
Nominal caseframes (NCFs) describe such information, and weconstruct them from the Web.2.1 Automatic Construction of NCFsFirst, we briefly introduce our method for con-structing NCFs from raw corpora proposed in(Sasano et al, 2004).Whereas verbal case frame construction uses ar-guments of each verb (Kawahara and Kurohashi,2002), nominal case frame construction basicallyuses adnominal constituents of each noun.
How-ever, while the meaning of a verbal argument canbe distinguished by the postposition, such as ?ga?
(nominative), ?wo?
(accusative), and ?ni?
(dative),the meaning of an adnominal constituent can notbe distinguished easily, because most adnominalconstituents appear with the same postposition?no?
(of).
Thus, we first conduct a semantic anal-ysis of adnominal constituents, and then constructNCFs using the results as follows:1.
Collect syntactically unambiguous nounphrases ?Nmno Nh?
from the automatic re-sulting parses of large corpora.2.
Analyze the relation between Nmand Nhby Kurohashi and Sakai?s method (1999) thatexploits an ordinary language dictionary.3.
Depending on the results, classify Nm, andobtain preliminary case slots for Nh.4.
Merge case slots if two preliminary case slotsof Nhare similar.5.
Consider frequent case slots as obligatorycases of Nh.
The frequency thresholds arevaried according to semantic analyses.6.
For each meaning of Nh, collect case slotsand construct case frames.The point of this method is the integrated use ofan ordinary dictionary and example phrases from1456Table 1: Examples of constructed nominal case frames.Case slot Examples with freq Generalized examples with rateDefinition: the amount of money you have to pay for something.kakaku (1) [something] sh?ohin(goods):9289, seihin(product):2520, [CT:ARTIFACT]:0.93, ?
?
?
(price) buhin(part):341, yunyuhin(importation):232, ?
?
?Definition: the structure that covers or forms the top of a building etc.yane (1) [building] ie(house):2505, kuruma(car):1565, koya(hut):895, [CT:FACILITY]:0.44,(roof) tatemono(building):883,minka(private house):679, ?
?
?
[CT:VEHICLE]:0.13,?
?
?Definition: the elected leader of the government in a country that has a parliament.shusho (1) [country] nihon(Japan):2355, kuni(country):272, [NE:LOCATION]:0.82,(prime minister) doitsu(Germany):157, ch?ugoku(China):130, ?
?
?
[CT:VEHICLE]:0.13,?
?
?Definition: a girl or woman who has the same parents as you.imouto (1) <relationship> watashi(me):3385, ore(me):1188, boku(me):898, [CT:PERSON]:0.74,(sister) jibun(oneself):341, tomodachi(friend):537, ?
?
?
[NE:PERSON]:0.22, ?
?
?Definition: a stick or handle on a machine.reb?a(1) [machine] bu?reki(brake):122, sokketo(sochet):67, [CT:ARTIFACT]:0.61,(lever) waip?a(wiper):54, souchi(device):52,?
?
?
[CT:VEHICLE]:0.04, ?
?
?Definition: the liver of an animal, used as food.reb?a(2) [animal] niwatori(chicken):153, buta(pig):153, [CT:ANIMAL]:0.98, ?
?
?
(liver) ushi(cattle):62, doubutsu(animal):25,?
?
?Definition: someone who takes part in a sport.senshu(1) [sport] yaky?u(baseball):1252, rir?e(relay):736, [CT:ABSTRACTION]:0.56, ?
?
?
(player) ky?ogi(competition):430, sakk?a(soccer):394, ?
?
?<affiliation> ch?
?mu(team):4409, nihon(Japan):3222, [NE:LOCATION]:0.33,reddu(Reds):771, kankoku(Korea):644,r?
?gu(league) ?
?
?
[CT:ORGANIZATION]:0.30, ?
?
?
* ?[]?
and ?<>?
denote dictionary-based and semantic feature-based analysis respectively.
For details see (Sasano et al, 2004).large corpora.
Dictionary definition sentences arean informative resource to recognize obligatorycases of nouns.
However, it is difficult to resolveassociative anaphora by using a dictionary as it is,because all nouns in a definition sentence are notan obligatory case, and only the frequency infor-mation of noun phrases tells us which is the oblig-atory case.
On the other hand, a simple methodthat just collects and clusters ?Nmno Nh?
phrasesbased on some similarity measure of nouns cannotconstruct comprehensive nominal case frames, be-cause of polysemy and multiple obligatory cases.For details see (Sasano et al, 2004).It is desirable to use a probability distributionfor deciding whether a case slot is obligatory ornot.
However, it is difficult to estimate a prob-ability distribution, since we construct nominalcase frames not by using the examples of associa-tive anaphora itself but by using the examples ofnoun phrases ?Nmno Nh?
(Nhof Nm).
We usesuch noun phrases because indispensable entitiesof noun ?Nh?
often appear as ?Nm.?
However, wecan say neither frequently appeared ?Nm?
is an in-dispensable entity of ?Nh.?
nor an indispensableentity frequently appears as ?Nm.?
For example,the name of a country is considered as an indis-pensable entity of ?shusho?
(prime minister), butdoes not frequently appear as ?Nm.
?2Thus, it isdifficult to estimate a probability distribution andwe use a hard decision.2.2 NCF Construction from the WebWe constructed nominal case frames from theWebCorpus (Kawahara and Kurohashi, 2006), whichcomprises 1.6 billion unique Japanese sentences.In this corpus, there were about 390 million nounphrases ?Nmno Nh,?
about 100 million uniquenoun phrases, and about 17 million unique headnouns ?Nh.?
There were about 4.07 million headnouns that appeared more than 10 times in the cor-pus, and we used only such head nouns.The resultant nominal case frames consisted ofabout 564,000 nouns including compound nouns.We show examples of constructed nominal caseframes in Table 1.
The average number of caseframes for a noun that has case frames was 1.0031,and the average number of case slots for a caseframe was 1.0101.
However, these statistics dif-fered with the frequency of the noun.
Therefore,we investigated the statistics of constructed nom-inal case frames for each group classified by thefrequency of the nouns.
Table 2 shows the re-2It is because ?the prime minister of Japan?
is often men-tioned by simply ?the prime minister?
in Japanese.1457Table 2: The statistics of constructed NCFs.Frequency Proportion # of NCFs # of CSs Coverageranking of nouns per noun per NCFwith NCF with NCF-100 56.0% 1.34 1.07 17.3%-1000 68.8% 1.17 1.16 25.6%-10000 51.7% 1.11 1.17 27.0%-100000 14.8% 1.05 1.13 17.6%100001- 13.7% 1.0009 1.0053 12.5%all 13.9% 1.0031 1.0101 100%Table 3: Evaluation of constructed NCFs.Precision Recall F-measure62/70 (0.89) 62/84 (0.74) 0.81sult.
As for the 10,000 most frequently appearednouns, which occupied about 70% of all noun ap-pearances, the average number of case frames fora noun was 1.11, and the average number of caseslots for a case frame was 1.17.For evaluating the resultant case frames, we ran-domly selected 100 nouns from the 10,000 mostfrequent nouns, and created gold standard caseframes for these nouns by hand.
For each noun,case frames were given if the noun was consideredto have any indispensable entity, and for each caseframe, obligatory case slots were given manually:70 case frames were created that had 84 case slots;56 case frames had only one case slot, the other 14case frames had two case slots.
30 nouns had nocase frames.We then evaluated the automatically con-structed case slots for these selected nouns.
Theevaluation result is shown in Table 3: the sys-tem output 70 case slots, and out of them, 62 caseframes were judged as correct.
The F-measure was0.81.
Since the boundary between indispensablecases and optional cases of a noun is not alwaysobvious, this score is considered to be reasonable.2.3 Generalization of ExamplesBy using nominal case frames constructed fromthe Web, sparseness problem was alleviated tosome extent, but still remained.
For instance, therewere thousands of named entities (NEs), whichcould not be covered intrinsically.
To deal withthis sparseness problem, we generalized the exam-ples of case slots.First, we used the categories that Japanese mor-phological analyzer JUMAN3adds to commonnouns.
In JUMAN, about twenty categories aredefined and tagged to common nouns.
For ex-ample, ?kuruma (car),?
?niwatori (chicken),?
and?tatemono (building)?
are tagged as ?VEHICLE,??ANIMAL?
and ?FACILITY,?
respectively.
Foreach category, we calculated the rate of catego-rized examples among all case slot examples, andadded it to the case slot as ?[CT:VEHICLE]:0.13.
?We also generalized NEs.
We used a com-mon standard NE definition for Japanese pro-vided by IREX workshop (1999).
We first rec-ognized NEs in the source corpus by using anNE recognizer (Sasano and Kurohashi, 2008), andthen constructed NCFs from the NE-recognizedcorpus.
As well as categories, for each NEclass, we calculated the NE rate among all caseslot examples, and added it to the case slot as?[NE:PERSON]:0.22.?
The generalized examplesare also included in Table 1.3 Probabilistic ModelIn this study, we apply a lexicalized probabilis-tic model for zero anaphora resolution proposed in(Sasano et al, 2008) to associative anaphora reso-lution.3.1 A Lexicalized Probabilistic Model forZero Anaphora ResolutionIn English, overt pronouns such as ?she?
anddefinite noun phrases such as ?the company?are anaphors that refer to preceding entities (an-tecedents).
On the other hand, in Japanese,anaphors are often omitted, which are called zeropronouns, and zero anaphora resolution is one ofthe most important techniques for semantic analy-sis in Japanese.Here, we introduce our model for zero anaphoraresolution (Sasano et al, 2008).
This model firstresolves coreference and identifies discourse enti-ties; then from the end of each sentence, analyzeseach predicate by the following steps:1.
Select a case frame temporarily.2.
Consider all possible correspondences be-tween each input argument and a case slot ofthe selected case frame.3.
Regard case slots that have no correspon-dence as zero pronoun candidates.3http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html14584.
Consider all possible correspondences be-tween zero pronoun candidates and existingentities.5.
For each possible case frame, estimate eachcorrespondence probabilistically, and selectthe most likely case frame and correspon-dence.Figure 1 shows an example of correspondencesbetween case frames and discourse entities.The probabilistic model gives a probability toeach possible case frame CF and case assignmentCA when target predicate v, input arguments IAand existing discourse entities ENT are given,and outputs the case frame and case assignmentthat have the highest probability.
That is to say,their model selects the case frame CFbestand thecase assignment CAbestthat maximize the proba-bility P (CF,CA|v, IA,ENT ):(CFbest, CAbest)= argmaxCF,CAP (CF,CA|v, IA,ENT ) (i)By decomposing case assignment (CA) intodirect case assignment (DCA) and the indirectcase assignment (ICA) and using several inde-pendence assumptions, Equation (i) is transformedinto the following equation:4(CFbest, DCAbest,ICAbest) =argmaxCF,DCA,ICA(P (CF |v)?
P (DCA, IA|CF )?P (ICA|ENT,CF,DCA))(ii)Here, P (CFl|v) denotes the probability to se-lect CFlwhen target predicate v is given, and es-timated by using case structure analysis of largeraw corpora.P (DCAk, IA|CFl) denotes the probability togenerate direct case assignment and input argu-ments when a case frame is given, and estimatedby using case structure analysis of large raw cor-pora, the frequency of a case slot example in theautomatically constructed verbal case frames, andthe web corpus in which the relation between asurface case marker and a case slot is manuallyannotated.P (ICAk|ENT,CFl, DCAk) denotes theprobability to generate indirect case assignmentwhen existing discourse entities, a case frame and4For details see (Sasano et al, 2008).Toyota-waPrius-wohybrid carhatsubai.kaigai-demohanbai-shiteiru.1997-nen2000-nen-karawa{Toyota, ??
}{hybrid car, Prius, ?2 }{kaigai}Entities(overseas)(launch)(sell)hatsubai (launch)ganominative company, SONY, firm, ?
[NE:ORGANIZATION] 0.15, ?woaccusative product, CD, model, car,  ?
[CT:ARTIFACT] 0.40, ?de      locative area, shop, world, Japan, ?
[CT:FACILITY] 0.13, ?hanbai (sell)ganominative company, Microsoft, ?
[NE:ORGANIZATION] 0.16, ?woaccusative goods, product, ticket, ?
[CT:ARTIFACT] 0.40, ?nidative customer, company, user, ?
[CT:PERSON] 0.28, ?de      locative shop, bookstore, site, ?
[CT:FACILITY] 0.40, ?
:direct case assignment:indirect case assignment (zero anaphora)Verbal case framesInput sentencesToyota launched the hybrid car Prius in 1997.
?
?started selling ?2 overseas in 2000.
{1997-nen}{2000-nen}Figure 1: An example of correspondences be-tween verbal case frames and discourse entities.direct case assignments are given, and estimatedby using several preferences on the relationbetween a zero pronoun and an antecedent, suchas a lexical preference, a surface case preferences,and a locational preference.For example, the lexical preference representshow likely an entity that contains njmas a con-tent part is considered to be an antecedent and isestimated by the following equation.P (njm|CFl, sj, A?
(sj)=1)P (njm)(iii)where, the function A?
(sj) returns 1 if a case slotsjis filled with an antecedent of a zero pronoun;otherwise 0.
P (nj|CFl, sj, A?
(sj) = 1) is calcu-lated by using case frames and denotes the proba-bility of generating a content part njof a zero pro-noun, when a case frame and a case slot are givenand the case slot is filled with an antecedent of azero pronoun.3.2 Extension to Associative AnaphoraResolutionWe then extend this probabilistic model to associa-tive anaphora resolution.
In this model, associativeanaphora is regarded as a kind of zero anaphora,that is, the relation between a noun and its oblig-atory cases is considered to be parallel to that be-tween a verb and its arguments.
Omitted obliga-tory cases are considered to be zero pronouns andresolved by the same process as zero anaphora res-olution.We conduct associative anaphora resolution foronly non-coreferent noun phrases.
This is becausemost of the relationships between coreferent noun1459Toyota-waPrius-wohybrid carkakaku-wa215-man-yen-datta.1997-nenHatsubai-tosho{Toyota, ??
}{hybrid car, Prius, ?2 }Entities(price)(ten thousands)kakaku (price)something goods, product, part, importation, ?
[CT:ARTIFCAT] 0.40, ?Nominal case framesInput sentences{1997-nen}{215-man-yen}{kaigai}Toyota launched the hybrid car Prius ???.
The initial price of ?2 was 21.5 million yen.
:indirect case assignment (associative anaphora)(initial)Figure 2: An example of correspondences be-tween a nominal case frame and discourse entities.phrases and its obligatory entities are easy to rec-ognize by following up the coreference chains.For example, the second appearance of ?the roof?in (4) means ?the roof of the house,?
and it iseasy to recognize by looking the first appearanceof ?the roof.?
(4) I saw the roof of the house.
The roof waspainted dark green.While verbal case frames describe both obliga-tory and optional cases, nominal case frames de-scribe only obligatory cases.
Therefore, we con-sider all case slots of nominal case frames as thetarget of associative anaphora resolution.Let us consider following example:(5) Toyota-wa 1997-nen hybrid car Prius-woyearhatsubai.
2000-nen-kara-wa kaigai-demolaunched year overseashanbai-shiteiru.
Hatsubai tosho,selling initial(?-no) kakaku-wa 215-man yen-datta.price ten thousands(Toyota1launched the hybrid car Prius2in 1997.
?1started selling ?2overseas in 2000.
The initial priceof ?2was 21.5 million yen.)?Kakaku?
(price) in this example has an omittedobligatory case ?[something]?
as shown in Table1.
Therefore, our model assumes a zero pronounand identifies the antecedent from the existing dis-course entities, such as {Toyota}, {hybrid-car,Prius},5and {kaigai}.
Figure 2 shows an exam-ple of correspondences between the nominal caseframe of ?kakaku?
(price) and discourse entities.In addition, as well as zero anaphora resolution,we exploit generalized examples to estimate lexi-cal preference.
When one mention of an entity is5?Hybrid car?
and ?Prius?
are in apposition and these twophrases are considered to refer to the same discourse entity.tagged any category or recognized as an NE, ourmodel also uses the category or the NE class as thecontent part of the entity.
Specifically, for estimat-ing Equation (iii), our model also calculates:P (NE :ARTIFACT |kakaku(1), no, A?
(no)=1)P (NE :ARTIFACT )besides:P (Prius|kakaku(1), no, A?
(no) = 1)P (Prius)and uses the geometric mean of them.3.3 Salience Score FilteringPrevious work has reported the usefulness ofsalience for anaphora resolution (Lappin and Le-ass, 1994; Mitkov et al, 2002).
In order to con-sider the salience of a discourse entity, we intro-duce the concept of salience score, which is calcu-lated by the following set of simple rules, and onlyconsider the entities that have the salience score noless than 1 as candidate antecedents of an associa-tive anaphor.?
+2 : mentioned with topical marker ?wa,?
orat the end of a sentence.?
+1 : mentioned without topical marker ?wa.??
+1 : assigned to a zero pronoun.?
??
: beginning of each sentence.We call ?
a decay rate.
If ?
?
1, we do notfilter out any entities.
If ?
= 0, we only considerthe entities that appears in the same sentence ascandidate antecedents.
For example, we considerthe salience score of the discourse entity {hybrid-car, Prius} in the example (5) when using ?=0.6.In the first sentence, since {hybrid-car, Prius} ismentioned twice, the salience score is 2.0.
At thebeginning of the second sentence it becomes 1.2,and after the zero anaphora resolution of ?hanbai?it becomes 2.2.
At the beginning of the third sen-tence it becomes 1.32.Note that, this is an ideal case.
Practically, somezero pronouns are not detected and some pronounsare assigned wrong antecedent; thus the saliencescore varies according to the preceding analysis.In addition, the salience score also depends onwhether we resolve only associative anaphora orresolve associative anaphora simultaneously withzero anaphora.
If zero pronoun resolution is not1460conducted, zero pronouns that represent omittedcases of verbs are not considered.For example, in case of {hybrid-car, Prius}with ?
= 0.6, if zero anaphora resolution is notconducted, the salience score at the beginning ofthe third sentence becomes 0.72, because the zeroanaphora resolution of ?hanbai?
is not considered;and thus {hybrid-car, Prius} is not considered asan antecedent candidate.In order to recognize discourse structure moreproperly, our model basically resolves associa-tive anaphora simultaneously with zero anaphora,and aims to consider zero pronouns that representomitted cases of verbs.3.4 Summary of Our modelOur model is summarized as follows:1.
Parse an input text using the Japanese parserKNP6and recognize NEs.2.
Resolve coreference, and link each mentionto an entity or create a new entity.3.
From the end of each sentence, zero anaphoraand associative anaphora resolution is con-ducted for each verb and non-coreferent nounby the following steps:(a) Select a case frame temporarily.
(b) Consider all possible correspondencesbetween each input argument and a caseslot of the selected case frame.
(c) Regard case slots that have no corre-spondence as zero pronoun candidates.
(d) Consider all possible correspondencesbetween zero pronoun candidates andexisting entities that has a salience scoreno less than 1.0.
(e) Estimate each correspondence proba-bilistically, and select the most likelycase frame and a correspondence.4 Experiments4.1 SettingWe created an anaphoric relation-tagged corpusconsisting of 186 web documents (979 sentences),in which all predicate-argument relations and re-lations between nouns were manually tagged.
Weshow some examples:6http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html(6) Toyota-wa 1997-nen Prius-wo hatsubai.year launch2000-nen-kara-wa kaigai-demo hanbai.year overseas sell(Toyota launched Prius in 1997.?1started selling ?2overseas in 2000.
)TAG: hatsubai ?
ga:Toyota, wo:Prius,(NOM) (ACC)hanbai ?
ga:Toyota, wo:Prius(NOM) (ACC)For the predicate ?hatsubai?
(launch), ?Toyota?is tagged as ga (nominative) case and ?Prius?
istagged as wo (accusative) case.
For the predicate?hanbai?
(sell), ?Toyota?
is tagged as omitted ga(nominative) case and ?Prius?
is tagged as omit-ted wo (accusative) case, which are indicated inbold, and such omitted cases are the target of zeroanaphora resolution.As for relations between nouns, both overt andimplicit relations are tagged with the Japanesecase marker ?no?
(adnominal).
In addition, rela-tions between nouns are classified into three cate-gories: indispensable, possible, and adjunct.
Sinceit is not always obvious whether the relations areindispensable or not, borderline relations betweenindispensable and adjunct are tagged possible.
Weconsider only the implicit relations that are taggedindispensable as the target of associative anaphoraresolution.
(7) Ken-wa imouto-to yatte-kita.sister came.
(Ken came with ?
?s sister.
)TAG: imouto ?
no:Ken (indispensable)(ADN)(8) K?oen-ni ikuto benchi-ga atta.park went bench was(I went to the park.
There was a bench in ?.
)TAG: benchi ?
no:k?oen (possible)(ADN)We used 62 documents for testing and used theother 124 documents for calculating several prob-abilities.
In the 62 test documents, 110 associa-tive anaphoric relations were tagged.
Each param-eter for the proposed model was estimated usingmaximum likelihood from raw corpora, the taggedcorpus, and case frames.
As verbal case frames,we used the case frames constructed from the Webcorpus comprising 1.6 billion sentences (Sasano etal., 2009).In order to concentrate on associative anaphoraresolution, we used the correct morphemes, namedentities, syntactic structures, and coreference re-14610.250.300.350.400.450.500.550.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0Decay Rate ?RecallF-measure.427PrecisionFigure 3: Experimental results of associativeanaphora resolution on several salience decayrates ?.lations that were annotated by hand.
Since cor-rect coreference relations were given, the numberof created entities was the same between the goldstandard data and the system output because zeroanaphora and associative anaphora resolution didnot create new entities.4.2 ResultsFigure 3 shows the experimental results of asso-ciative anaphora resolution, in which we used gen-eralized examples, resolved zero anaphora auto-matically, and varied the decay rate ?
introducedin Section 3.3 from 0 to 1.
When we used the de-cay rates smaller than 0.5, the recall score wors-ened clearly.
On the other hand, although we ex-pected to obtain higher precision with small decayrate, the highest precision was achieved by the de-cay rate 0.5.
Consequently, we obtained the high-est F-measure of 0.427 with the decay rate 0.5.
Inthe following experiments, we fixed the decay rate0.5.We utilized two baseline models for demon-strating the effectiveness of our approach: a ran-dom model and a salience-based model.
The ran-dom model selects a case frame and its correspon-dence randomly from all possible case frames andcorrespondences.
The salience-based model se-lects a case frame and its correspondence that as-sign a zero pronoun candidate the existing entitythat have highest salience score.
In addition, in or-der to confirm the effectiveness of generalized ex-amples of NCFs, we conducted experiments with-out using generalized examples.
Table 4 showsthe experimental results.
We can confirm that ourproposed model outperforms two baseline mod-els.
Without using any generalized examples, theTable 4: Experimental results of associativeanaphora resolution with two baseline models andour model with/without generalized examples.Model Recall Precision F-measureRandom* 0.148 0.035 0.056(16.3/110) (16.3/467.5)Salience- 0.400 0.135 0.202based (44/110) (44/325)ProposedCT NE0.318 0.257 0.285(35/110) (35/136)?0.345 0.268 0.302(38/110) (38/142)?0.464 0.333 0.388(51/110) (51/153)?
?0.518 0.363 0.427(57/110) (57/157)CT: Using examples generalized by categories.NE: Using examples generalized by named entities.
* The average of 10 trials is shown.F-measure was about 0.14 lower than the methodusing generalized examples, and we can also con-firm the effectiveness of the generalized examples.While generalization of categories much improvedthe F-measure, generalization of NEs contributedlittle.
This is because the NE rate was smaller thanthe common noun rate, and so the effect was lim-ited.
This tendency was also seen in zero anaphoraresolution (Sasano et al, 2008).In order to investigate the effects of zeroanaphora resolution, we tested our model underthree conditions: without zero anaphora resolu-tion (no resolution), with zero anaphora resolution(automatically resolved), and with using correctzero anaphora relations that are manually tagged(manually identified).
The performance of auto-matic zero anaphora resolution resulted in a recallof 0.353, a precision of 0.375, and an F-measure of0.364.
Table 5 shows the experimental results.
Toresolve associative anaphora simultaneously withzero anaphora improved F-measure by 0.072; us-ing correct zero anaphora relations improved F-measure by 0.103.
We can confirm that the per-formance of associative anaphora resolution is im-proved by considering zero anaphora.Note that, strictly speaking, these comparisonsare not fair because we set the decay rate ?
to max-imize the performance when using generalized ex-amples and resolving zero anaphora automatically.However, these tendencies described above werealso seen with other decay rates.1462Table 5: The effects of zero anaphora resolution.Zero anaphora Recall Precision F-measureNo resolution 0.373 0.339 0.355(41/110) (41/121)Automatically 0.518 0.363 0.427resolved (57/110) (57/157)Manually 0.573 0.382 0.458identified (63/110) (63/165)4.3 DiscussionBy using generalized examples and resolvingsimultaneously with zero anaphora, our modelachieved a recall of 0.518 (57/110), but there werestill 53 associative anaphoric relations that werenot recognized.
Table 6 shows the causes of them.22 false negatives were caused by salience scorefiltering.
Note that, it does not mean that these 22associative anaphoric relations were always recog-nized correctly if the correct antecedents were notfiltered by salience score.Case frame sparseness caused only 5 false neg-atives.
Considering that the recall of nominal caseframes was 74% as shown in Table 3, this seems tobe too few.
This is because we do not consideredthe relations that tagged possible, and only con-sidered obviously indispensable relations.
Fromthis result, we can say that coverage of nominalcase frames for nouns that have obviously indis-pensable entities is much higher than 74%, whichis considered to achieve a coverage of about 95%(105/110).4.4 Comparison with previous workMurata et al (1999) proposed a method of utiliz-ing ?Nmno Nh?
phrases for associative anaphoraresolution.7They basically used all ?Nmno Nh?phrases from corpora as a lexical knowledge, andused rule-based approach.
They obtained a recallof 0.63 and a precision of 0.68 by using exam-ples of ?X no Y?
(Y of X), a recall of 0.71 and aprecision of 0.82 by assuming ideal nominal caseframes.
One reason of such high performance maybe that they considered referential properties ofnoun phrases, such as generic, indefinite, and defi-nite, while our model does not.
We can also saythat their experiments were conducted on smalland supposedly easy corpora.
Half of their corpora7Murata et al (1999) and we (Sasano et al, 2004) usedthe terminology indirect anaphora, but concerned with thesame phenomena as we concerned with in this paper.Table 6: Causes of false negatives.Causes NumFiltered by salience score 22 (15)Judge as non-anaphoric 13 (14)Select false antecedents 13 (13)Case frame sparseness 5 (5)Total 53 (47)*?()?
denotes the number of causes whenusing correct zero anaphora tags.were occupied by fairy tale, against which domainspecific rules are considered to be effective.We proposed a rule-based approach for asso-ciative anaphora resolution based on automati-cally acquired nominal case frames (Sasano et al,2004).7We obtained a recall of 0.633 and a pre-cision of 0.508 against news paper articles.
How-ever, we regarded some additional relations thatcan be interpreted by considering coreference re-lations as associative anaphoric relations.
(9) Chechen Ky?owakoku-no shuto-ni ...Chechen Republic capital... shuto seiatsu-no saishu dankai-ni ...capital conquer last stage(... to the capital of Chechen Republic ... in the laststage to conquer the capital ...)For example, although the second mention of?shuto?
(capital) in example (9) means ?ChechenKy?owakoku-no shuto?
(the capital of Chechen Re-public), it can be interpreted by recognizing thecoreference relation between the first and secondmentions of ?shuto?
(capital).
Therefore, as men-tioned in Section 3.2, we do not consider such re-lations as associative anaphora in this study; weincluded such relations as associative anaphora in(Sasano et al, 2004).
The relatively high score iscaused by this criterion.5 ConclusionIn this paper, we proposed a probabilistic modelfor associative anaphora resolution.
Our modelregards associative anaphora as a kind of zeroanaphora and resolves it in the same manner aszero anaphora resolution that uses automaticallyacquired case frames.
We also showed that theperformance of associative anaphora resolutioncan be improved by resolving it simultaneouslywith zero anaphora.
As future work, we plan toconsider referential properties of noun phrases inassociative anaphora resolution.1463ReferencesRazvan Bunescu.
2003.
Associative anaphora res-olution: A web-based approach.
In Proc.
ofEACL?03: Workshop on The Computational Treat-ment of Anaphora, pages 47?52.Herbert H Clark.
1975.
Bridging.
In Proc.
of the Con-ference on Theoretical Issues in Natural LanguageProcessing, pages 169?174.Caroline Gasperin and Ted Briscoe.
2008.
Statisticalanaphora resolution in biomedical texts.
In Proc.
ofCOLING?08, pages 257?264.Caroline Gasperin and Renata Vieira.
2004.
Usingword similarity lists for resolving indirect anaphora.In Proc.
of ACL?04: Workshop on Reference Resolu-tion and its Applications, pages 40?46.Udo Hahn, Michael Strube, and Katja Markert.
1996.Bridging textual ellipsis.
In Proc.
of COLING?96,pages 496?501.John A. Hawkins.
1978.
Definiteness and indefinite-ness: a study in reference and grammaticality pre-diction.
Croom Helm Ltd.IREX Committee, editor.
1999.
Proc.
of the IREXWorkshop.Daisuke Kawahara and Sadao Kurohashi.
2002.
Fertil-ization of case frame dictionary for robust Japanesecase analysis.
In Proc.
of COLING?02, pages 425?431.Daisuke Kawahara and Sadao Kurohashi.
2006.Case frame compilation from the web using high-performance computing.
In Proc.
of LREC?06,pages 1344?1347.Sadao Kurohashi and Yasuyuki Sakai.
1999.
Seman-tic analysis of Japanese noun phrases: A new ap-proach to dictionary-based understanding.
In Proc.of ACL?99, pages 481?488.Shalom Lappin and Herbert J. Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Compu-tational Linguistics, 20(4):535?562.Katja Markert, Malvina Nissim, and Natalia N Mod-jeska.
2003.
Using the web for nominal anaphoraresolution.
In Proc.
of EACL?03: Workshop on theComputational Treatment of Anaphora, pages 39?46.Josef Meyer and Robert Dale.
2002.
Using the Word-Net hierarchy for associative anaphora resolution.
InProc.
of SemaNet?02: Building and Using SemanticNetworks.Ruslan Mitkov, Richard Evans, and Constantin Or?asan.2002.
A new, fully automatic version of Mitkov?sknowledge-poor pronoun resolution method.
InProc.
of CICLing?02.Natalia N Modjeska.
2002.
Lexical and grammati-cal role constraints in resolution other-anaphora.
InProc.
of DAARC?02.Masaki Murata, Hitoshi Isahara, and Makoto Nagao.1999.
Resolution of indirect anaphora in Japanesesentences using examples ?X no Y?
(Y of X).
InProc.
of ACL?99: Workshop on Coreference and ItsApplications.Massimo Poesio, Tomonori Ishikawa, Sabine Schulteim Walde, and Renata Vieira.
2002.
Acquiring lex-ical knowledge for anaphora resolution.
In Proc.
ofLREC?02, pages 1220?1224.Massimo Poesio, Pahul Mehta, Axel Maroudas, andJanet Hitzeman.
2004.
Learning to Resolve Bridg-ing References.
In Proc.
of ACL?04, pages 143?150.Ryohei Sasano and Sadao Kurohashi.
2008.
Japanesenamed entity recognition using structural naturallanguage processing.
In Proc.
of IJCNLP?08, pages607?612.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2004.
Automatic construction of nominalcase frames and its application to indirect anaphoraresolution.
In Proc.
of COLING?04, pages 1201?1207.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2008.
A fully-lexicalized probabilistic modelfor japanese zero anaphora resolution.
In Proc.
ofCOLING?08, pages 769?776.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2009.
The effect of corpus size on caseframe acquisition for discourse analysis.
In Proc.of NAACL-HLT?09, pages 521?529.Michael Strube and Udo Hahn.
1999.
Functionalcentering ?
grounding referential coherence in in-formation structure.
Computational Linguistics,25(3):309?344.Renata Vieira and Massimo Poesio.
2000.
An empir-ically based system for processing definite descrip-tions.
Computational Linguistics, 26(4):539?592.Renata Vieira, Eckhard Bick, Jorge Coelho, ViniciusMuller, Sandra Collovini, Jose Souza, and LuciaRino.
2006.
Semantic tagging for resolution of indi-rect anaphora.
In Proc.
of the 7th SIGdial Workshopon Discourse and Dialogue, pages 76?79.Mitsuko Yamura-Takei.
2003.
Approaches to zero ad-nominal recognition.
In Proc.
of ACL?03: StudentResearch Workshop, pages 87?94.1464
