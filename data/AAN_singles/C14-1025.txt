Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 245?256, Dublin, Ireland, August 23-29 2014.High Performance Word Sense Alignment by Joint Modeling of SenseDistance and Gloss SimilarityMichael Matuschek?and Iryna Gurevych???
Ubiquitous Knowledge Processing Lab (UKP-DIPF),German Institute for Educational Research and Educational InformationSchlo?str.
29, 60486 Frankfurt, Germany?Ubiquitous Knowledge Processing Lab (UKP-TUDA),Department of Computer Science, Technische Universit?at DarmstadtHochschulstr.
10, 64289 Darmstadt, Germanyhttp://www.ukp.tu-darmstadt.deAbstractIn this paper, we present a machine learning approach for word sense alignment (WSA) whichcombines distances between senses in the graph representations of lexical-semantic resourceswith gloss similarities.
In this way, we significantly outperform the state of the art on each of thefour datasets we consider.
Moreover, we present two novel datasets for WSA between Wiktionaryand Wikipedia in English and German.
The latter dataset in not only of unprecedented size, butalso created by the large community of Wiktionary editors instead of expert annotators, makingit an interesting subject of study in its own right as the first crowdsourced WSA dataset.
We willmake both datasets freely available along with our computed alignments.1 IntroductionLexical-semantic resources (LSRs) are an important foundation for numerous natural language process-ing (NLP) tasks such as word sense disambiguation (WSD) or information extraction (IE).
However,large-scale LSRs are only available for a few languages.
The Princeton WordNet (Fellbaum, 1998)is commonly used for English, but for most languages such resources are small or missing altogether.Another problem is that, even for English, there is no single LSR which is suitable for all differentapplication scenarios, because the resources contain different words, senses or even information types.Recently, it has been argued that collaboratively constructed resources (e.g.
Wiktionary (Meyer andGurevych, 2012))) are a viable alternative, especially for smaller languages (Matuschek et al., 2013), butthere are still considerable drawbacks in coverage which make their usage challenging.These observations have led to the insight that word sense alignment (WSA), i.e.
linking at the levelof word senses, is key for the efficient exploitation of LSRs, and it was shown that the usage of linkedresources can indeed yield performance improvements.
Examples include WSD using aligned Word-Net and Wikipedia (Navigli and Ponzetto, 2012a), semantic role labeling using PropBank, VerbNet andFrameNet (Palmer, 2009), the construction of a semantic parser using FrameNet, WordNet, and VerbNet(Shi and Mihalcea, 2005) and IE using WordNet and Wikipedia (Moro et al., 2013).
Cholakov et al.
(2014) address the special task of verb sense disambiguation.
They use the large-scale resource UBY(Gurevych et al., 2012) which contains nine resources in two languages, mapped to a uniform represen-tation using the LMF standard for interoperability (Eckle-Kohler et al., 2012), and also (among others)sense alignments between WordNet, FrameNet, VerbNet and Wiktionary which are exploited in theirapproach.However, WSA is challenging because of word ambiguities, different sense granularities and informa-tion types (Navigli, 2006), so that past efforts mostly focused on specific resources or applications, whereexpert-built resources such as WordNet played a central role in most cases.
Approaches which aim atbeing more generic (i.e.
applicable to a wider range of LSRs) usually focused on only one informationsource for the alignment (e.g.
glosses or graph structures) without combining them in an elaborate way.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/245In this paper, we want to go beyond this previous work in two ways: i) For the first time, we presentan alignment between the large-scale collaboratively constructed resources Wiktionary and Wikipedia.While both LSRs have been extensively used in NLP and especially WSA (see Section 2), no attempt hasbeen made to combine them, although Wiktionary was explicitly designed to complement the encyclope-dic knowledge in Wikipedia with linguistic knowledge.
Apart from already established tasks like WSD,the strong multilingual focus of both resources makes their combination especially promising for appli-cations such as knowledge-based machine translation or computer-assisted translation where additionalbackground knowledge and translation options can be crucial (Matuschek et al., 2013).
To fill this gap inthe body of research, we present two new evaluation datasets for English and German, where the latteris not only of remarkable size, but also directly extracted from Wiktionary in a novel approach, makingit the first crowdsourced WSA dataset.
ii) Also for the first time, we jointly model different aspects ofsense similarity by applying machine learning techniques to WSA.
However, unlike previous approaches,we do not engineer our features towards a specific resource pair, rendering the approach powerful butproprietary.
Instead, we aim to combine generic features which are applicable to a variety of resources,and we show that combining them leads to state-of-the-art WSA performance.
In particular, we employdistances calculated with Dijkstra-WSA (Matuschek and Gurevych, 2013), an algorithm which workson graph representations of resources, as well as gloss similarity values.
This lets us take advantageof both (orthogonal) ways of identifying equivalent senses and yields a very robust and flexible WSAframework.The rest of this paper is structured as follows: In Section 2 we discuss related work, in Section 3 wedescribe our approach and introduce the resources and datasets we use in our experiments, in Section 4we evaluate our results, and we conclude in Section 5 with some directions for future work.2 Related WorkThere are two main approaches to WSA which have been applied: Similarity-based and graph-basedones.
To our knowledge, there exists no previous work which effectively combines both approaches in aunified framework, and only few works which combine both kinds of features for different purposes.2.1 Similarity-based ApproachesWordNet was aligned to Wikipedia (Niemann and Gurevych, 2011) and Wiktionary (Meyer andGurevych, 2011) using a framework based on gloss similarity, in spirit of the earliest work in WSDpresented by Lesk (1986).
In both cases, cosine and personalized PageRank (PPR) similarity (Agirreand Soroa, 2009) were calculated, and a simple machine learning approach was used to classify eachpair of senses (see Section 3.3).
This idea was also applied to cross-lingual alignment between WordNetand the German part of OmegaWiki (Gurevych et al., 2012), using machine translation as an intermediatecomponent.
Henrich et al.
(2011) use a similar approach for aligning GermaNet and Wiktionary, but withword overlap as the similarity measure.
De Melo and Weikum (2010) report an alignment of WordNetsynsets to Wikipedia articles which is also based on word overlap.
We later report results based on glosssimilarity as one of our baselines (Tables 2 and 3).2.2 Graph-based ApproachesIn one of the earliest structure-based works, Daud?e et al.
(2003) map different versions of WordNet basedon the synset hierarchy.
Navigli (2009) disambiguates WordNet glosses, i.e.
sense markers are assignedto all non-stopwords in each WordNet gloss.
The approach is based on finding circles in the WordNetrelation graph to identify disambiguations.
In later work, this idea was applied to the disambiguationof translations in a bilingual dictionary (Flati and Navigli, 2012).
While this ?alignment?
of dictionaryentries is related to our problem, it was not discussed how this idea could be applied to word sensealignment of two resources.
Laparra et al.
(2010) use a shortest path algorithm (SSI-Dijkstra+) to alignFrameNet lexical units (LUs) with WordNet synsets.
They align monosemous LUs first and then searchfor the closest synset in WordNet for the other LUs in the same frame.
The LUs are, however, consideredas mere texts to be disambiguated; there is no attempt made to exploit the graph structure of FrameNet.246Ponzetto and Navigli (2009) use a graph-based method for aligning WordNet synsets and Wikipediacategories.
Using semantic relations, they build subgraphs of WordNet for each category and then alignsenses to categories based on the structural features.
In our own previous work, we presented Dijkstra-WSA, a graph-based approach working with shortest paths (Matuschek and Gurevych, 2013).
It achievesstate-of-the-art precision, but recall is an issue if the graphs are sparse (i.e.
in case of only few semanticrelations).
As Dijkstra-WSA distances are one of the features we use for our machine learning approach,we will present this approach in more detail in section 3.2.2 and also report results for Dijkstra-WSA onour evaluation datasets for comparison.2.3 Hybrid ApproachesIn later work, Navigli and Ponzetto (2012a) also align WordNet with the full Wikipedia.
Besides usingbag-of-words overlap to compute gloss similarity, they also build a graph structure for the senses in bothresources by using WordNet semantic relations.
The goal is to determine which WordNet sense is closestto the Wikipedia sense to be aligned.
However, the graph structure of Wikipedia is disregarded, as is theglobal structure of WordNet, as just a locally restricted subset of WordNet relations is used.
In the samecontext of BabelNet, Navigli and Ponzetto (2012b) also present BabelRelate, an approach which relies ontranslations to compute cross-lingual semantic similarity; however, they do not apply it to WSA.
Dijkstra-WSA was enhanced by using a backoff, by means of performing a graph-based alignment first, and incases where no alignment target sense can be found, a decision is made based on the similarity of glosses(Matuschek and Gurevych, 2013).
While this simple two-step approach increases recall substantially,it comes at the expense of lower precision.
However, the overall F-measure achieved state-of-the-artperformance on every considered dataset (0.65?0.87).
We also report the results for this hybrid approachas a baseline (Tables 2 and 3).
De Melo and Weikum (2008) use a machine learning approach with acombination of structural and content-based features of WordNet, but for building new wordnets in otherlanguages, not aligning existing ones.In summary, the different approaches to compute similarity have mostly been used in isolation, orcombined in a shallow or restricted way.
More complex approaches usually require resource-specificfeature engineering, which makes their transferability to other resources or languages difficult.
Thus,we present a framework which combines different similarity measures in a generic and flexible way andenables state-of-the-art WSA performance on a variety of resources with modest effort.3 The Alignment ProcedureThe basic steps of our alignment algorithm are:1.
For each sense in one resource, all possible candidates in the other resource are retrieved.
Can-didates are senses which have the same attached lemma and part of speech.
For instance, for theprogramming sense of Java in one resource, their might exist senses for programming, island orcoffee in the other one which are all possible alignment targets.2.
For each candidate pair, we calculate a set of features describing their similarity in different ways.3.
For a set of word senses (the gold standard), the alignment decision is made by human annotators.4.
A machine learning classifier is trained on this gold standard, and an alignment decision is made forthe remainder of the candidate pairs to produce a complete alignment of the resources.
In our setup,we use 10-fold cross validation to train the classifier.The different datasets and steps of the algorithm are explained in more detail in the following sections.3.1 Resources and DatasetsWe use four different WSA evaluation datasets, two of which are presented for the first time.
To ensurecompatibility with previous work, we use the same versions of the resources as reported in (Gurevych etal., 2012) and (Matuschek and Gurevych, 2013).247Pair Pos.
Neg.
Polysemy One cand.
F1A0CompositionWordNet-OmegaWiki 210 473 1.50 75.2% 0.84 0.85 randomWordNet-Wiktionary 313 2 110 4.76 18.6% 0.78 0.93 manualWiktionary-Wikipedia (En) 75 292 1.27 87.6% 0.79 0.95 automaticWiktionary-Wikipedia (De) 21 855 9 953 1.47 77.6% 0.85 0.89 crowdTable 1: Characteristics of the gold standards used in the evaluation.
The degree of polysemy (i.e.the number of possible alignment targets per sense) hints towards the difficulty of the task, as doesthe number of senses with only one alignment candidate.
WordNet-Wiktionary stands out as it wasmanually composed and is not representative of the full alignment (Meyer and Gurevych, 2011).
Theinter-annotator agreements A0and F1can be considered as upper bounds for automatic alignment accu-racy and F-measure.
Note that for the Wiktionary-Wikipedia datasets, due to the nature of their creation,the agreement was originally not available; we estimated it by manually re-annotating a sample of 100examples with two annotators.3.1.1 ResourcesWordNet (Fellbaum, 1998) is a computational lexicon for English created at Princeton University.
Itis organized in sets of synonyms (synsets), each expressing a distinct concept.
Synsets are representedby textual definitions (so-called glosses).
A hierarchical organization is encoded via semantic relationssuch as hyponymy.Wikipedia is a collaboratively created online encyclopedia available in almost 300 languages.
Thecurrent English version contains around 4 400 000 articles, and the German one around 1 700 000 articles,each usually describing a particular concept.
Due to its encyclopedic nature, Wikipedia mostly coversnouns, while the other LSRs discussed also cover verbs, adjectives, etc.
Articles are connected viahyperlinks in the article text (implying a graph structure), and the first paragraph usually gives a shortsummary of the topic, serving as a gloss for our purposes.
Articles are also linked to the equivalentarticles in other languages.Wiktionary is a dictionary ?side project?
of Wikipedia, available in over 500 languages.
Currently,the English Wiktionary contains over 500 000 lexical entry pages, while the German one contains around350 000 ones.
For a word, multiple senses can be encoded, and these are usually represented by glosses.Wiktionary also contains hyperlinks to synonyms, hypernyms, etc.
and translations into other languages.OmegaWiki is a freely editable online dictionary like Wiktionary.
However, instead of distinct lan-guage editions, OmegaWiki contains language-independent concepts (?Defined Meanings?)
which carrylexicalizations in different languages.
These concepts are connected via semantic relations.
OmegaWikicontains over 46 000 concepts and lexicalizations in almost 500 languages.3.1.2 DatasetsWordNet?OmegaWiki: The first alignment between these LSRs based on the German part ofOmegaWiki was reported in (Gurevych et al., 2012).
As OmegaWiki Defined Meanings are multilin-gual, we used the same dataset for monolingual WSA in later work (Matuschek and Gurevych, 2013).Table 1 presents details about this and the other evaluation datasets.WordNet?Wiktionary: Meyer and Gurevych (2011) originally used this dataset for similarity-basedalignment.
While we could not improve upon this using Dijkstra-WSA on its own (Matuschek andGurevych, 2013), the backoff approach yielded a significant improvement.
This dataset was manuallycomposed according to specific criteria, hence it differs from the others and is not fully representative ofthe full alignment.Wiktionary?Wikipedia (English): No evaluation dataset (let alone a full alignment) has beenreported for this resource pair yet.
However, as the datasets for WordNet-Wiktionary (Meyer andGurevych, 2011) and WordNet-Wikipedia (Niemann and Gurevych, 2011) are lexically overlapping,we were able to automatically create a gold standard for Wiktionary-Wikipedia by exploiting the transi-tivity of the alignment relation, i.e.
by using WordNet as a pivot.
Note that, unlike Wiktionary, Word-248Net synsets have multiple lexicalizations for the same meaning, introducing alignment candidates fromWikipedia which might not be applicable to a particular Wiktionary sense.
Hence, we decided to filterthe examples where the lexeme of the Wiktionary sense and the Wikipedia article title did not match.
Aneffect of this process was that words not contained in all three resources were filtered out, and many ex-amples were left with few or only one candidate, leading to a low polysemy.
We also manually checkedthe derived gold standard and corrected a small number of wrong annotations introduced through theautomatic process.
The resulting dataset is thus considerably smaller than the others, but it still turnedout to be sufficient for machine learning experiments.Wiktionary?Wikipedia (German): Same as for the English editions, neither a gold standard nor analignment was previously reported for this pair.
We were able to create a gold standard in a novel way byexploiting the fact that many German Wiktionary senses contain links to the corresponding Wikipediaarticles, inducing a sense alignment between the two LSRs manually validated by the Wiktionary com-munity.
However, we were unable to extract such an alignment for English, as Wikipedia articles areattached to the lexical entry page in this version and not to a specific sense.In the German Wiktionary, a large portion of the senses is linked in this way, and even after aggres-sively filtering out invalid link targets (e.g.
disambiguation pages or pages with a non-matching title),we retained over 20 000 alignments between Wiktionary senses and Wikipedia pages, a sample of whichwe manually confirmed to be correct.
Of course, this only yields positive examples; to also include casesof non-alignment, we extracted the other candidate (i.e.
lexically matching) Wikipedia articles for eachaligned Wiktionary sense, assuming that Wiktionary editors also considered and discarded them beforeeventually creating a link.
Interestingly, the number of negative examples derived in this way is rela-tively low in comparison to the other datasets.
An analysis revealed that a large fraction of the linkedWiktionary senses are either scientific terms (e.g.
from biology) or named entities such as cities.
Bothtypes of senses tend to have few alternative candidates in Wikipedia due to their specificity, and it seemslogical that Wiktionary users predominantly link these senses to the explanatory Wikipedia articles whichare not familiar to the majority of users.In the end, this process yielded a WSA dataset with unprecedented characteristics: It was not onlycreated and validated by a crowd of editors rather than a handful of annotators, but it is also an order ofmagnitude larger than previously reported datasets (Table 1).
This enables us to assess the performanceof our WSA approach in a scenario which is close in size to a full alignment task, allowing a morewell-grounded statement about its effectiveness.3.2 Feature EngineeringThe selection of features for our machine learning approach was driven by the premise to keep theframework as generic and resource-agnostic as possible, in order to ensure applicability to many differentLSRs without additional engineering effort.
Thorough analysis of existing resources and approachesrevealed that two types of information are available for the vast majority of LSRs: i) Glosses, or moregeneral, textual descriptions of concepts, and ii) Relationships between concepts inducing a graph, giventhrough semantic relations, links, or other means.
We also evaluated some features which are specific toa smaller subset of resources (see Section 3.2.3).3.2.1 Gloss SimilarityCosine similarity (COS) calculates the cosine of the angle between a vector representation of twosenses s1and s2.
For the vector representation of a sense, we use a bag-of-words approach, i.e., a vectorBoW(s) contains the term frequencies of all words in the description of s. In this work, we only rely onthe textual definition of a sense to keep the approach as generic as possible, while the usage of examplesentences, related words, synonyms etc.
would also be possible.Personalized PageRank similarity (PPR) (Agirre and Soroa, 2009) measures the semantic related-ness between two word senses s1and s2by comparing semantic vectors which can be derived in differentways; we utilize the variant introduced by Niemann and Gurevych (2011).
The idea is to identify sensesof words in a sense?s gloss which are central for describing its meaning.
These senses (represented in agraph derived from an LSR such as WordNet) should have a high PageRank score (i.e.
a high centrality).2493.2.2 Dijkstra-WSA DistanceDijkstra-WSA (Matuschek and Gurevych, 2013) is the graph-based WSA algorithm we use to calculatea distance-based similarity measure between word senses.
We will briefly explain its two steps.Graph construction: The resource graph is comprised of a set of nodes V which represents the sensesof an LSR and a set of edges E ?
V ?
V which expresses semantic relatedness between them.
Onecan use semantic relations, hyperlinks, or other relatedness indicators.
For sparse LSRs, it is advisableto add edges between senses s1and s2if a monosemous term t with sense s2is included in the gloss ofs1.
For example, one can link a sense of Java to programming language if the latter term is included inthe former?s definition text.
This monosemous linking enhances the graph density (and hence, the recall)significantly.Computing sense alignments: First, trivial alignments between the two resource graphs A and B arecreated.
Alignments are trivial if two senses have the same attached lexeme in A and B and this lexemeis also unique in either resource.
Intuitively, these alignments serve as ?bridges?
between highly relatedregions of A and B.
Next, for each remaining sense s ?
A, the set of possible target senses T ?
Bis retrieved in a similar fashion as for our approach, and for each of them the shortest path is computedusing Dijkstra?s algorithm (Dijkstra, 1959).
While Dijkstra-WSA then goes on to directly align the sensewhich is closest to the source sense, we save the distance for each candidate sense and directly use it asa feature, expressing semantic relatedness based on the structure of both underlying resources.
When nodistance can be computed (in case of a disconnected graph), we assume infinite distance.3.2.3 Other FeaturesWe also experimented with other features which were accessible directly from the resources, i.e.
with-out the need for external knowledge or extensive computational effort; these were usually not availablefor every resource pair.
Features we tried were the part of speech (Wiktionary, OmegaWiki, Word-Net), the sense index, i.e.
the position in the sense list for a lexeme (WordNet, Wiktionary), similarityof example sentences (WordNet, Wiktionary), overlap of translations into other languages (Wikipedia,Wiktionary, cf.
(Bond and Foster, 2013)) and overlap of domain labels (Wikipedia, Wiktionary, Word-Net, OmegaWiki).
However, for none of these features we could observe any significant1impact onthe results, mostly due to sparsity of the respective features.
Thus, we do not report them, but on theother hand we consider this an indicator that gloss similarity and distance in the resource graph alreadysufficiently capture the similarity between senses.3.3 Machine Learning ClassifiersWe experimented with different machine learning classifiers using WEKA (Hall et al., 2009).
While adetailed discussion of these classifiers is beyond the scope of this work, we will at least give a shortdescription of the ones we eventually used.
For more details, please refer to textbooks such as (Murphy,2012).
We used WEKA?s standard configuration in every case.Threshold-based classifiers work by simply trying to learn a numeric boundary value which separatespositive examples from negative ones.
Although this approach is rather naive, it has been successfullyused in previous WSA efforts (Meyer and Gurevych, 2011; Niemann and Gurevych, 2011).A Naive Bayes classifier assumes that features are independent (i.e.
the value of one feature is unre-lated to any other feature), and is thus able to learn reliable classification probabilities on relatively smalltraining sets.
While the independence assumption can be considered an oversimplification, the algorithmis widely used due to its efficiency and good precision.Bayesian Networks (or belief networks) also classify based on probabilities learned from trainingdata, however, they offer the advantage of modeling dependencies between features, hence allowing amore accurate representation of the data.
Technically, such a network is a directed acyclic graph modelingthe conditional dependencies between variables.A Perceptron is a classifier which maps a real-valued input vector to a binary output, by means of anartificial neural network.
It is commonly used for pattern recognition, also in NLP (Collins, 2002).1All significance claims in this paper are based on McNemar?s test at a confidence level of 1%.250Support Vector Machines (SVMs) construct a hyperplane in a multi-dimensional space which yieldsa good separation between positive and negative training examples, represented as data points.Decision Trees are built from training input by iteratively splitting the set of samples based on attributevalues so that the resulting subset is as homogeneous as possible with regard to the class label.
Unseenexamples can be classified by testing the attribute values and following different branches of the tree.One of the main advantages (e.g.
in comparison to SVMs) is that this approach is easily interpretable.4 Experimental Results and AnalysisBaselines For reference, we report six different baselines: i) Random: A random sense from the set ofcandidates is chosen in each case, ii) 1:1: An alignment is always made if and only if there is exactly onecandidate, iii) 1st: The first of the candidate senses is always selected2, iv) SIM: A similarity thresholdis learned for gloss similarity values as suggested by Meyer and Gurevych (2011), cf.
Section 3.2.1,v) DWSA: The closest candidate sense in the resource graph is aligned as we suggested in (Matuschekand Gurevych, 2013), cf.
Section 3.2.2, vi) HYB: A hybrid approach of using DWSA first and then SIMas a backoff, also suggested by us (Matuschek and Gurevych, 2013).
The latter approach representsstate-of-the-art performance for WSA.
Note that for the two Wiktionary-Wikipedia datasets, no previousresults were available, so we created similarity-based and Dijkstra-WSA alignments ourselves, based onthe same versions of the resources as in the previous work.
For the other datasets, we used the numbersreported in the original papers (Matuschek and Gurevych, 2013; Meyer and Gurevych, 2011).Overview Tables 2 and 3 present the results for all setups.
Although the best classifiers for eachdataset always outperform the previous state of the art and the baselines by a significant margin, thereis no consistent pattern in the results across different LSRs and classifiers.
One reason for this is thatthe range of feature values varies substantially between different datasets.
For instance, Dijkstra-WSAdistances tend to be greater when Wikipedia is involved simply by its virtue of being larger than the otherLSRs, and gloss similarities also differ depending on the average length of the glosses and the language.Another factor are the gold standards, which are quite different in terms of size and composition (seeTable 1).
Thus, no classifier is the undisputed ?winner?, but Bayesian Networks proved most robustin our experiments, showing competitive results in every case.
As training them is also computationallycheap (compared to SVMs, for instance), we would generally recommend this kind of classifier for WSAtasks.
In the following, we also provide a more detailed discussion of the results for each individualdataset.WordNet-OmegaWiki In this case, the precision of the alignment is satisfactory for every classifier,while both previously reported approaches struggle for different reasons (Gurevych et al., 2012; Ma-tuschek and Gurevych, 2013).
The strength of the machine learning becomes apparent especially incomparison with the HYB approach: While the latter merely combines independent alignment decisions,hence achieving better recall but failing to improve precision (cf.
Section 2.3), the joint usage of featuresleads to a massive improvement.
Analysis of the decision tree classifier shows that, as we suspected, the?edge cases?
are explicitly reflected in the learned model, i.e.
examples with high gloss similarity butalso a high Dijkstra-WSA distance (or vice versa) are ruled out with higher confidence.
This observationgenerally also holds for the other datasets.
As an example, the two senses of genome in biology (?Thenon-redundant genetic information stored in DNA sequences that defines an individual organism?)
andalgorithmics (?In the context of a genetic algorithm, the information that defines an individual entity?
)have similar glosses; they are, however, quite far apart in the graph and thus not aligned.
The BayesianNetwork achieves the best results as it comprehensively models this interdependence of features.
TheSVM achieves the best precision, but the distribution of feature values does not lend itself well to linearseparation in this case, leading to unsatisfactory recall.WordNet-Wiktionary For this dataset, the results look similar to WordNet-OmegaWiki as far as theimprovement of precision is concerned, as the joint usage of features helps to make a correct decision on2While this corresponds to the most frequent sense baseline in other setups, note that no explicit frequency information isavailable for OmegaWiki, Wiktionary and Wikipedia, so that the first sense baseline is only a rough approximation.251WordNet-OmegaWiki WordNet-WiktionaryP R F1A P R F1ARandom 0.46 0.35 0.40 0.51 0.21 0.59 0.31 0.671:1 0.36 0.64 0.46 0.55 0.68 0.19 0.30 0.881st 0.34 0.80 0.48 0.47 0.33 0.51 0.40 0.80SIM 0.55 0.53 0.54 0.73 0.67 0.65 0.66 0.91DWSA 0.56 0.69 0.62 0.74 0.68 0.27 0.39 0.89HYB 0.57 0.75 0.65 0.75 0.68 0.71 0.69 0.92SVM 0.95 0.32 0.48 0.79 0.82 0.61 0.70 0.93Naive Bayes 0.73 0.62 0.67 0.82 0.71 0.79 0.75 0.92Bayesian Network 0.75 0.72 0.74 0.84 0.70 0.84 0.77 0.94Perceptron 0.73 0.58 0.65 0.81 0.74 0.72 0.73 0.92Decision Tree 0.68 0.63 0.66 0.80 0.78 0.66 0.72 0.93Agreement - - 0.84 0.85 - - 0.78 0.93Table 2: Alignment results for WordNet-OmegaWiki and WordNet-Wiktionary: Using baselines (top),approaches from previous work (middle) and different machine learning classifiers (bottom).
We reportprecision, recall, F-measure (the harmonic mean of both) and accuracy.
Best results for each value anddataset are marked in bold.
The inter-annotator agreements A0and F1are given as upper bounds.borderline examples.
However, in this case the recall is also substantially improved, especially for theBayesian classifiers.
This was an issue in the original Dijkstra-WSA results (Matuschek and Gurevych,2013) due to the low connectivity of the English Wiktionary graph.
The combination of distances andgloss similarities is able to alleviate this shortcoming of Wiktionary to some extent, as examples withmissing Dijkstra-WSA distance can still be aligned in case of sufficient gloss similarity.
SVMs also showthe best precision here, but are challenged by the suboptimal separability of the feature space.Wiktionary-Wikipedia (English) The low connectivity of Wiktionary is not as much an issue here asfor WordNet-Wiktionary, mostly due to the different composition of the gold standard ?
higher-frequencywords tended to be retained (see Section 3.1.2), which in turn are better connected within Wiktionary.This leads to reasonable results for Dijkstra-WSA alone.
The hybrid approach reaches the best recall, butdue to the relatively low precision of the SIM alignment, the overall result leaves room for improvement.This improvement is again achieved via joint modeling of features.
As for the datasets discussed above,the precision is improved significantly; this is especially true for the Bayesian Network classifier.
Preci-sion and recall for the SVM classifier are also satisfactory in this case (due to the better linear separabilityof the feature space), making it the best overall classifier along with the Perceptron.Wiktionary-Wikipedia (German) On this dataset, the naive baselines are very strong, due to the dis-proportionately large number of positive examples ?
this is especially true for the 1:1 setup which reachesperfect precision.
In other words, whenever there is only one alignment candidate, it is already the cor-rect one.
The HYB approach also yields good results thanks to the high precision of its two components,but recall is an issue for gloss similarity due to the richer morphology and different formation of com-pounds in German.
We did not use a compound splitter (an obvious extension for future work), so that,for instance ?Kinderspiel?
and ?Spiel f?ur Kinder?
(both meaning ?a game for children?)
could not belexically matched.
However, when machine learning is applied, the recall can again be significantly im-proved at only a negligible expense of precision.
Here, as for the WordNet-Wiktionary dataset, the jointmodeling of distance and gloss similarity allows to correctly align more borderline examples.
While thestrong bias towards positive examples might make this dataset not fully representative of a full alignmenttask (which is the eventual goal of WSA), the results still beat the strong baselines in terms of F-measureand thus indicate that WSA, and especially our approach, works well on such a large-scale dataset.252Wiktionary-Wikipedia (En) Wiktionary-Wikipedia (De)P R F1A P R F1ARandom 0.41 0.49 0.45 0.48 0.68 0.40 0.51 0.461:1 0.17 0.56 0.26 0.33 1.0 0.63 0.77 0.751st 0.23 0.88 0.36 0.37 0.93 0.66 0.78 0.74SIM 0.60 0.67 0.63 0.84 0.85 0.46 0.60 0.57DWSA 0.78 0.55 0.65 0.87 0.85 0.61 0.71 0.66HYB 0.62 0.79 0.70 0.86 0.90 0.72 0.80 0.75SVM 0.82 0.70 0.76 0.92 0.76 0.84 0.80 0.71Naive Bayes 0.79 0.69 0.73 0.92 0.85 0.54 0.66 0.62Bayesian Network 0.91 0.63 0.74 0.93 0.86 0.81 0.83 0.77Perceptron 0.82 0.70 0.76 0.92 0.75 0.92 0.82 0.73Decision Tree 0.79 0.69 0.73 0.92 0.87 0.81 0.84 0.78Agreement - - 0.79 0.95 - - 0.85 0.89Table 3: Results for Wiktionary-Wikipedia alignment in English and German: Using baselines (top),approaches from previous work (middle) and different machine learning classifiers (bottom).
We reportprecision, recall, F-measure (the harmonic mean of both) and accuracy.
Best results for each value anddataset are marked in bold.
The inter-annotator agreements A0and F1are given as upper bounds.Error analysis Error sources for our system are mostly the same as for the previously reported ap-proaches ?
if equivalent concepts are described very differently (known as the ?lexical gap?, e.g.
thesenses ?divulge confidential information?
and ?to confess under interrogation?
of the verb to sing) andhappen to be not very close in the resource graph, i.e.
both similarity measures fail at once, they are likelynot aligned (false negatives).
On the other hand, false positives occur for examples such as Brand, whichis the name of districts in two different German cities (Aachen and Zwickau).
The sense descriptionsare very much alike, and the senses are also located in similar regions of the resource graphs (roughlyspeaking, German geography), which makes the distinction hard.
Addressing these issues might be pos-sible by computing more sophisticated gloss similarity measures (e.g.
using lexical expansion (Iida etal., 2008)) or enhancing the graph construction process.
In general, however, there are no discerniblesystematic errors made by our system.5 Conclusions and future workWe have shown that through joint modeling of different similarity measures for WSA the overall align-ment quality in terms of F-measure can be significantly improved over the state of the art for each andevery of the considered four datasets.
This proves that such a joint usage of global structure as well asthe content of the LSRs is indeed preferable over using either of them in isolation or combining them ina simple backoff approach, since it effectively utilizes both ways of calculating similarity.Apart from substantially improving WSA performance, we also present two new datasets forWiktionary-Wikipedia alignment in English and German which fill a considerable gap in the previouswork on WSA.
One of Wiktionary?s explicit purposes is to complement the knowledge in Wikipedia,so that an alignment between these widely used resources seems a natural and important extension tothe body of work in this field.
Especially for (semi-) automatic translation tasks, this resource combina-tion seems extremely promising due to the abundant multilingual content in both resources (see Section3.1.1).
We suggested a comparable combination of Wiktionary and OmegaWiki in the past (Matuscheket al., 2013), but the much larger Wikipedia is bound to hold even more potential.
Moreover, the Ger-man dataset is of unprecedented size, allowing more credible statements about the performance of WSAalgorithms in a full alignment scenario.
Another interesting aspect is that this dataset was derived fromlinks created by the crowd of Wiktionary editors, not by expert annotators; thus, it can be considered thefirst crowdsourced WSA dataset.
This type of dataset creation is also one aspect of future work.
We wantto investigate in more detail to what extent these alignments are trustworthy, what steps are necessary253to improve the dataset?s size and quality, and how negative examples (i.e.
non-alignments) can be morereliably derived.
We also plan to find out if such datasets could be created for other Wiktionary languageeditions.The fact that the achieved results are close to the human agreement suggests that, for the datasetsconsidered, there is not much room for improvement.
Thus, we plan to apply and adapt the algorithm toLSRs with different properties than the ones considered here, such as the more syntax-focused FrameNet(Ruppenhofer et al., 2010) which only recently has received research attention in automatic WSA (Hart-mann and Gurevych, 2013).
The usage of syntactic features to express sense similarity has not beenthoroughly explored yet, and it seems a promising direction to make further progress in WSA.
Usage ofmore elaborate textual similarity features (e.g.
covering semantic similarity or using lexical expansion)as it was suggested for text reuse detection (B?ar et al., 2012) would be another direction worth exploring.Inspired by the semi-automatic construction of the Wiktionary-Wikipedia gold standard for Englishfrom existing datasets, we also want to investigate whether an alignment of more than two resourcesat once (n-way alignment) is feasible, using joint knowledge from all LSRs involved.
For instance,the information that two senses in resources A and B share a strong resemblance to a sense in anotherresource C could be expressed by an additional feature.AcknowledgementsThis work has been supported by the Volkswagen Foundation as part of the Lichtenberg ProfessorshipProgram under grant No.
I/82806 and by the Hessian research excellence program ?Landes-Offensivezur Entwicklung Wissenschaftlich-?okonomischer Exzellenz (LOEWE)?
as part of the research center?Digital Humanities?.
We would also like to thank the anonymous reviewers for their helpful remarks.ReferencesEneko Agirre and Aitor Soroa.
2009.
Personalizing PageRank for Word Sense Disambiguation.
In Proceedings ofthe 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 33?41,Athens, Greece.Daniel B?ar, Torsten Zesch, and Iryna Gurevych.
2012.
Text Reuse Detection Using a Composition of Text Simi-larity Measures.
In Proceedings of the 24th International Conference on Computational Linguistics (COLING2012), pages 167?184, Mumbai, India, December.Francis Bond and Ryan Foster.
2013.
Linking and Extending an Open Multilingual Wordnet.
In Proceedingsof the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages1352?1362, Sofia, Bulgaria, August.Kostadin Cholakov, Judith Eckle-Kohler, and Iryna Gurevych.
2014.
Automated verb sense labelling based onlinked lexical resources.
In Proceedings of the 14th Conference of the European Chapter of the Association forComputational Linguistics (EACL 2014), pages 68?77, Gothenburg, Sweden, April.Michael Collins.
2002.
Discriminative training methods for hidden markov models: Theory and experiments withperceptron algorithms.
In Proceedings of the ACL-02 Conference on Empirical Methods in Natural LanguageProcessing - Volume 10, pages 1?8, Philadelphia, USA.Jordi Daud?e, Llu?
?s Padr?o, and German Rigau.
2003.
Validation and tuning of wordnet mapping techniques.
InProceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP?03),Borovets, Bulgaria.Gerard De Melo and Gerhard Weikum.
2008.
A Machine Learning Approach to Building Aligned Wordnets.
InProceedings of the First International Conference on Global Interoperability for Language Resources, pages163?170, Hong Kong.Gerard De Melo and Gerhard Weikum.
2010.
Providing Multilingual, Multimodal Answers to Lexical DatabaseQueries.
In Proceedings of the 7th Language Resources and Evaluation Conference (LREC 2010), pages 348?355, Valetta, Malta.Edsger W. Dijkstra.
1959.
A note on two problems in connexion with graphs.
Numerische Mathematik, 1:269?271.254Judith Eckle-Kohler, Iryna Gurevych, Silvana Hartmann, Michael Matuschek, and Christian M. Meyer.
2012.UBY-LMF - A Uniform Model for Standardizing Heterogeneous Lexical-Semantic Resources in ISO-LMF.
InProceedings of the 8th International Conference on Language Resources and Evaluation (LREC?12), pages275?282, Istanbul, Turkey.Christiane Fellbaum, editor.
1998.
WordNet: An Electronic Lexical Database.
MIT Press, Cambridge, MA, USA.Tiziano Flati and Roberto Navigli.
2012.
The CQC algorithm: Cycling in graphs to semantically enrich andenhance a bilingual dictionary.
Journal of Artificial Intelligence Research (JAIR), 43:135?171.Iryna Gurevych, Judith Eckle-Kohler, Silvana Hartmann, Michael Matuschek, Christian M. Meyer, and ChristianWirth.
2012.
UBY - A Large-Scale Unified Lexical-Semantic Resource Based on LMF.
In Proceedings of the13th Conference of the European Chapter of the Association for Computational Linguistics (EACL?12), pages580?590, Avignon, France.Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten.
2009.
TheWEKA Data Mining Software: An Update.
volume 11, pages 10?18.Silvana Hartmann and Iryna Gurevych.
2013.
FrameNet on the Way to Babel: Creating a Bilingual FrameNetUsing Wiktionary as Interlingual Connection.
In Proceedings of the 51st Annual Meeting of the Association forComputational Linguistics (ACL 2013), volume 1, pages 1363?1373, August.Verena Henrich, Erhard Hinrichs, and Tatiana Vodolazova.
2011.
Semi-Automatic Extension of GermaNet withSense Definitions from Wiktionary.
In Proceedings of the 5th Language and Technology Conference (LTC2011), pages 126?130, Poznan, Poland.Ryu Iida, Diana McCarthy, and Rob Koeling.
2008.
Gloss-based semantic similarity metrics for predominantsense acquisition.
In Proceedings of the Third International Joint Conference on Natural Language Processing(IJCNLP ?08), pages 561?568.Egoitz Laparra, German Rigau, and Montse Cuadros.
2010.
Exploring the integration of WordNet and FrameNet.In Proceedings of the 5th Global WordNet Conference (GWC?10), Mumbai, India.Michael Lesk.
1986.
Automatic sense disambiguation using machine readable dictionaries: How to tell a pine conefrom an ice cream cone.
In Proceedings of the 5th Annual International Conference on Systems Documentation(SIGDOC ?86), pages 24?26, Toronto, Canada.Michael Matuschek and Iryna Gurevych.
2013.
Dijkstra-WSA: A Graph-Based Approach to Word Sense Align-ment.
Transactions of the Association for Computational Linguistics (TACL), 1:151?164, May.Michael Matuschek, Christian Meyer, and Iryna Gurevych.
2013.
Multilingual Knowledge in Aligned Wiktionaryand OmegaWiki for Translation Applications.
Translation: Computation, Corpora, Cognition, 3(1):87?118.Christian M. Meyer and Iryna Gurevych.
2011.
What psycholinguists know about chemistry: Aligning Wiktionaryand WordNet for increased domain coverage.
In Proceedings of the 5th International Joint Conference onNatural Language Processing (IJCNLP 2011), pages 883?892, Chiang Mai, Thailand.Christian M. Meyer and Iryna Gurevych.
2012.
Wiktionary: A new rival for expert-built lexicons?
Exploringthe possibilities of collaborative lexicography.
In Sylviane Granger and Magali Paquot, editors, ElectronicLexicography, chapter 13, pages 259?291.
Oxford University Press.Andrea Moro, Hong Li, Sebastian Krause, Feiyu Xu, Roberto Navigli, and Hans Uszkoreit.
2013.
Semantic rulefiltering for web-scale relation extraction.
In Proceedings of the 12thInternational Semantic Web Conference(ISWC 2013), pages 347?362, Sydney, Australia.Kevin P. Murphy.
2012.
Machine Learning: A Probabilistic Perspective (Adaptive Computation and MachineLearning series).
The MIT Press, August.Roberto Navigli and Simone Paolo Ponzetto.
2012a.
BabelNet: The automatic construction, evaluation andapplication of a wide-coverage multilingual semantic network.
Artificial Intelligence, 193:217?250.Roberto Navigli and Simone Paolo Ponzetto.
2012b.
BabelRelate!
A Joint Multilingual Approach to ComputingSemantic Relatedness.
In Proceedings of the 26th AAAI Conference on Artificial Intelligence, Toronto, Canada,July.Roberto Navigli.
2006.
Meaningful Clustering of Senses Helps Boost Word Sense Disambiguation Performance.In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meetingof the Association for Computational Linguistics, pages 105?112, Sydney, Australia.255Roberto Navigli.
2009.
Using Cycles and Quasi-Cycles to Disambiguate Dictionary Glosses.
In Proceedingsof the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL?09),pages 594?602, Athens, Greece.Elisabeth Niemann and Iryna Gurevych.
2011.
The People?s Web meets Linguistic Knowledge: Automatic SenseAlignment of Wikipedia and WordNet.
In Proceedings of the 9th International Conference on ComputationalSemantics (IWCS), pages 205?214, Oxford, UK.Martha Palmer.
2009.
SemLink: Linking PropBank, VerbNet and FrameNet.
In Proceedings of the GenerativeLexicon Conference (GenLex-09), pages 9?15, Pisa, Italy.Simone Paolo Ponzetto and Roberto Navigli.
2009.
Large-scale taxonomy mapping for restructuring and inte-grating Wikipedia.
In Proceedings of the 21stInternational Joint Conference on Artificial Intelligence, pages2083?2088, Pasadena, CA, USA.Josef Ruppenhofer, Michael Ellsworth, Miriam R. L. Petruck, Christopher R. Johnson, and Jan Scheffczyk.
2010.FrameNet II: Extended Theory and Practice.
International Computer Science Institute, Berkeley, CA, Septem-ber.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces Together: Combining FrameNet, VerbNet and WordNet forRobust Semantic Parsing.
In Computational Linguistics and Intelligent Text Processing: 6th InternationalConference, volume 3406 of Lecture Notes in Computer Science, pages 100?111.
Berlin/Heidelberg: Springer.256
