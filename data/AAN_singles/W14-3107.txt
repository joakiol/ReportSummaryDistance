Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 45?52,Baltimore, Maryland, USA, June 27, 2014.c?2014 Association for Computational LinguisticsInteractive Exploration of Asynchronous Conversations: Applying aUser-centered Approach to Design a Visual Text Analytic SystemEnamul Hoque, Giuseppe Carenini{enamul,carenini}@cs.ubc.caDepartment of Computer ScienceUniversity of British ColumbiaVancouver, CanadaShafiq Jotysjoty@qf.org.qaQatar Computing Research InstituteQatar FoundationDoha, QatarAbstractExploring an online conversation can bevery difficult for a user, especially whenit becomes a long complex thread.
We fol-low a human-centered design approach totightly integrate text mining methods withinteractive visualization techniques to sup-port the users in fulfilling their informa-tion needs.
The resulting visual text ana-lytic system provides multifaceted explo-ration of asynchronous conversations.
Wediscuss a number of open challenges andpossible directions for further improve-ment including the integration of interac-tive human feedback in the text miningloop, applying more advanced text analy-sis methods with visualization techniques,and evaluating the system with real users.1 IntroductionWith the rapid adoption of Web-based social me-dia, asynchronous online conversations are be-coming extremely common for supporting com-munication and collaboration.
An asynchronousconversation such as a blog may start with a newsarticle or an editorial opinion, and later generate along and complex thread as comments are addedby the participants (Carenini et al., 2011).
Con-sider a scenario, where a reader opens a blog con-versation about Obama?s healthcare policy.
Thereader wants to know why people are supportingor opposing ObamaCare.
However, since somerelated discussion topics like student loan and jobrecession are introduced, the reader finds it hardto keep track of the comments about ObamaCare,which end up being buried in the long discussion.This may lead to an information overload problem,where the reader gets overwhelmed, starts to skipcomments, and eventually leaves the conversationwithout satisfying her information needs (Jones etal., 2004).How can we support the user in performing thisand similar information seeking tasks?
Arguably,supporting this task requires tight integration be-tween Natural Language Processing (NLP) and in-formation visualization (InfoVis) techniques, butwhat specific text analysis methods should be ap-plied?
What metadata of the conversation could beuseful to the user?
How this data should be visual-ized to the user?
And even more importantly, howNLP and InfoVis techniques should be effectivelyintegrated?
Our hypothesis is that to answer thesequestions effectively, we need to apply human-centered design methodologies originally devisedfor generic InfoVis (e.g., (Munzner, 2009; Sedl-mair et al., 2012)).
Starting from an analysis ofuser behaviours and needs in the target conversa-tional domain, such methods help uncover usefultask and data abstractions that can guide systemdesign.
On the one hand, task and data abstrac-tions can characterize the type of information thatneeds to be extracted from the conversation; on theother hand, they can inform the design of the vi-sual encodings and interaction techniques.
Moretellingly, as both the NLP and the InfoVis compo-nents of the resulting system refer to a common setof task and data abstractions, they are more likelyto be consistent and synergistic.We have explored this hypothesis in developingConVis, a visual analytic system to support the in-teractive analysis of blog conversations.
In the firstpart of the paper, we describe the development ofConVis, from characterizing the domain of blogs,its users, tasks and data, to designing and imple-menting specific NLP and InfoVis techniques in-formed by our user-centered design.
In the secondpart of the paper, starting from an informal evalu-ation of Convis and a comprehensive literature re-view, we discuss several ideas on howConVis (andsimilar systems) could be further improved andtested.
These include the integration of interac-tive human feedback in the text mining techniques45(which are based on Machine Learning), the cou-pling of even more advanced NLP methods withthe InfoVis techniques, and the challenges in run-ning evaluations of ConVis and similar interfaces.2 Related WorkWhile in the last decade, NLP and InfoVis meth-ods have been investigated to support the user inmaking sense of conversational data, most of thiswork has been limited in several ways.For example, earlier works on visualizingasynchronous conversations primarily investigatedhow to reveal the thread structure of a conversationusing tree visualization techniques, such as usinga mixed-model visualization to show both chrono-logical sequence and reply relationships (Venoliaand Neustaedter, 2003), thumbnail metaphor usinga sequence of rectangles (Wattenberg and Millen,2003; Kerr, 2003), and radial tree layout (Pascual-Cid and Kaltenbrunner, 2009).
However, such vi-sualizations did not focus on analysing the actualcontent (i.e., the text) of the conversations, whichis something that according to our user-centred de-sign users are very interested in.On the other hand, text mining approachesthat perform content analysis of the conversations,such as finding primary themes (or topics) withinconversations (Sack, 2000; Dave et al., 2004), orvisualizing the content evolution over time (Wei etal., 2010; Vi?egas et al., 2006), often did not derivetheir visual encodings and interactive techniquesfrom task and data abstractions based on a detailedanalysis of specific user needs and requirements inthe target domains.Furthermore, more on the technical side, thetext analysis methods employed by these ap-proaches are not designed to exploit the spe-cific characteristics of asynchronous conversations(e.g., use of quotation).
Recently, (Joty et al.,2013b) has shown that topic segmentation and la-beling models are more accurate when these spe-cific characteristics are taken into account.
Themethods presented in (Joty et al., 2013b) areadopted in ConVis.In general, to the best of our knowledge, noprevious work has applied user-centred design totightly integrate text mining methods with interac-tive visualization in the domain of asynchronousconversations.3 Domains and User ActivitiesConversational domains: The phenomenal adop-tion of novel Web-based social media has lead tothe rise of textual conversations in many differentmodalities.
While email remains a fundamentalway of communicating for most people, other con-versational modalities such as blogs, microblogs(e.g., Twitter) and discussion fora have quickly be-come widely popular.
Since the nature of data andtasks may vary significantly from one domain tothe other, rather than trying to build an one-size-fit-all interface, we follow a design methodologythat is driven by modeling the tasks and usagecharacteristics in a specific domain.In this work, we focus on blogs, where peoplecan express their thoughts and engage in onlinediscussions.
Due to the large number of commentswith complex thread structure (Joty et al., 2013b),mining and visualizing blog conversations can be-come a challenging problem.
However, the visual-ization can be effective for other threaded discus-sions (e.g., news stories, Youtube comments).Users: As shown in Table 1, blog users can becategorized into two groups based on their activ-ities: (a) participants who already contributed tothe conversations, and (b) non-participants whowish to join the conversations or analyze the con-versations.
Depending on different user groups thetasks might vary as well, something that needs tobe taken into account in the design process.For example, imagine a participant who has ex-pressed her opinion about a major political issue.After some time, she may become interested toknow what comments were made supporting oropposing her opinion, and whether those com-ments require a reply right away.
On the contrary,a non-participant, who is interested in joining theongoing conversation on that particular politicalissue, may want to decide whether and how sheshould contribute by quickly skimming through along thread of blog comments.
Another group ofusers may include the analysts, a policy maker forinstance, who does not wish to join the conversa-tion, but may want to make an informed decisionbased on a summary of arguments used to supportor oppose the political issue.Once the conversation becomes inactive (i.e.,no further comments are added), still a distinctionmay remain between the activities of participantsand non-participants on tasks (see Table 1).
In ourwork, we have initially concentrated on supporting46UsertypesOngoing conver-sationInactive/past conver-sationParticipant Already joined theconversation (wantsto get updated andpossibly make newcomments)Wants to delve intothe past conversationsand re-examine whatwas discussed, whatshe commented on,what other peoplereplied, etc.Non-participantPotential partici-pant (wants to jointhe conversation)Analyst (wants toanalyze the ongo-ing conversation,but does not intendto join)Wants to analyze andgain insight about thepast conversation.Table 1: User categorization for asynchronousconversation.the non-participant?s activity on an inactive con-versation (as opposed to an ongoing conversation).4 Designing ConVis: From Tasks to NLPand InfoVis TechniquesWe now briefly describe our design approach forintegrating text mining techniques with interactivevisualization in ConVis.
We first characterize thedomain of blogs and perform the data and tasksabstraction according to the nested model of de-sign study (Munzner, 2009).
We then mine thedata as appeared to be essential from that data andtask analysis, followed by iteratively refining thedesign of ConVis that aims to effectively supportthe identified blog reading tasks (A more detailedanalysis of the task abstractions and visual designis provided in (Hoque and Carenini, 2014)).4.1 TasksTo understand the blog reading tasks, we re-viewed the literature focusing on why and howpeople read blogs.
From the analysis, wefound that the primary goals of reading blogs in-clude information seeking, fact checking, guid-ance/opinion seeking, and political surveillance(Kaye, 2005).
People may also read blogs to con-nect to their communities of interest (Dave et al.,2004; Mishne, 2006), or just for fun/ enjoyment(Baumer et al., 2008; Kaye, 2005).Some studies have also revealed interesting be-havioural patterns of blog readers.
For example,people often look for variety of opinions and havetendencies to switch from one topic to anotherquickly (Singh et al., 2010; Munson and Resnick,2010).
In addition, they often exhibit exploratorybehaviour, i.e., they quickly skim through a fewposts about a topic before delving deeper into itsdetails (Zinman, 2011).
Therefore, the interfaceshould facilitate open-ended exploration, by pro-viding navigational cues that help the user to seekinteresting comments.From the analyses of primary goals of blogreading, we compile a list of tasks and the asso-ciated data variables that one would wish to visu-alize for these tasks.
These tasks can be framedas a set of questions, for instance, ?what do peo-ple say about topic X?
?, ?how other people?s view-points differ from my current viewpoint on topicX?
?, ?what are some interesting/funny commentsto read??
We then identify the primary data vari-ables involved in these tasks and their abstracttypes.
For instance, most of these questions in-volve topics discussed and sentiments expressedin the conversation.
Note that some questions mayadditionally require to know people-centric infor-mation and relate such information to the visual-ization design.
We also identify a set of meta-data to be useful cues for navigating a conversa-tion (the position of the comments, thread struc-ture, and comment length) (Narayan and Cheshire,2010; Baumer et al., 2008).
We choose to encodethe position of the comments (ordinal) as opposedto their timestamps (quantitative); since the exacttimestamp of a comment is less important to usersthan its chronological position with respect to theother comments (Baumer et al., 2008).4.2 Text AnalysisSince most of the blog reading tasks we identi-fied involved topics and sentiments expressed inthe conversation, we applied both topic modelingand sentiment analysis on a given conversation.In topic modeling, we group the sentences of ablog conversation into a number of topical clustersand label each cluster by assigning a short infor-mative topic descriptor (i.e., a keyphrase).
To findthe topical clusters and their associated labels, weapply the topic segmentation and labeling modelsrecently proposed by (Joty et al., 2013b) for asyn-chronous conversations, and successfully evalu-ated on email and blog datasets.
More specifically,for topic segmentation, we use their best unsu-pervised topic segmentation model LCSeg+FQG,which extends the generic lexical cohesion basedtopic segmenter (LCSeg) (Galley et al., 2003)47Figure 1: A snapshot of ConVis showing a blog conversation from Slashdot, where the user has hoveredthe mouse over a topic element (?major army security?)
that highlights the connecting visual links, brush-ing the related authors(right), and providing visual prominence to the related comments in the ThreadOverview (middle).to consider a fine-grain conversational structureof the conversation, i.e., the Fragment QuotationGraph (FQG) (Carenini et al., 2007).
The FQGcaptures the reply relations between text frag-ments, which are extracted by analyzing the actualbody of the comments, thus provides a finer rep-resentation of the conversation than the reply-tostructure.
Similarly, the topic labels are found byusing their best unsupervised graph-based rank-ing model (i.e., BiasedCorank) that extracts rep-resentative keyphrases for each topical segmentby combining informative clues from initial sen-tences of the segment and the fine-grain conversa-tional structure, i.e., the FQG.For sentiment analysis, we apply the Seman-tic Orientation CALculator (SO-CAL) (Taboadaet al., 2011), which is a lexicon-based approach(i.e., unsupervised) for determining sentiment ofa text.
Its performance is consistent across vari-ous domains and on completely unseen data, thusmaking a suitable tool for our purpose.
We definefive different polarity intervals (-2 to +2), and foreach comment we count how many sentences fallin any of these polarity intervals to compute thepolarity distribution for that comment.While designing and implementing ConVis, wehave been mainly working with blog conversationsfrom two different sources: Slashdot1?a technol-ogy related blog site, and Daily Kos2?
a politicalanalysis blog site.1http://slashdot.org2http://www.dailykos.com4.3 Designing Interactive VisualizationUpon identifying the tasks and data variables, wedesign the visual encoding and user interactions.Figure 1 shows an initial prototype of ConVis.3It is designed as an overview + details interface,since it has been found to be more effective fortext comprehension tasks than other approachessuch as zooming and focus+context (Cockburn etal., 2008).
The overview consists of what was dis-cussed by whom (i.e., topics and authors) and avisual summary of the whole conversation (i.e.,the Thread Overview), while the detailed viewrepresents the actual conversation.
The ThreadOverview visually represents each comment ofthe discussion as a horizontal stacked bar, whereeach stacked bar encodes three different meta-data (comment length, position of the commentin the thread, and depth of the comment withinthe thread).
To express the sentiment distributionwithin a comment, the number of sentences thatbelong to a particular sentiment orientation is in-dicated by the width of each cell within a stackedbar.
A set of five diverging colors was used to vi-sualize this distribution in a perceptually meaning-ful order, ranging from purple (highly negative) toorange (highly positive).
Thus, the distribution ofcolors in the Thread Overview can help the user toperceive the kind of conversation they are going todeal with.
For example, if the Thread Overview is3https://www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/ConVis.html48mostly in strong purple color, then the conversa-tion has many negative comments.The primary facets of the conversations, namelytopics and authors are presented in a circularlayout around the Thread Overview.
Both top-ics and authors are positioned according to theirchronological order in the conversation startingfrom the top, allowing the user to understand howthe conversation evolves as the discussion pro-gresses.
The font size of facet items helps theuser to quickly identify what are the mostly dis-cussed themes and who are the most dominantparticipants within a conversation.
Finally, thefacet elements are connected to their correspond-ing comments in the Thread Overview via subtlecurved links indicating topic-comment-author re-lationships.
While a common way to relate variouselements in multiple views is synchronized visualhighlighting, we choose visual links to connectrelated entities.
This was motivated by the find-ings that users can locate visually linked elementsin complex visualizations more quickly and withgreater subjective satisfaction than plain highlight-ing (Steinberger et al., 2011).
Finally, the Conver-sation View displays the actual text of the com-ments in the discussion as a scrollable list.
Atthe left side of each comment, the following meta-data are presented: title, author name, photo, and astacked bar representing the sentiment distribution(mirrored from Thread Overview).Exploring Conversations: ConVis sup-ports multi-faceted exploration of conversationsthrough a set of lightweight interactions (Lam,2008) that can be easily triggered without causingdrastic modifications to the visual encoding.
Theuser can explore interesting topics/ authors byhovering the mouse on them, which highlightsthe connecting curved links and related commentsin the Thread Overview (see Figure 1).
As such,one can quickly understand how multiple facetelements are related, which is useful for the tasksthat require the user to interpret the relationshipsbetween facets.
If the reader becomes furtherinterested in specific topic/ author, she cansubsequently click on it, resulting in drawing athick vertical outline next to the correspondingcomments in the Thread Overview.
Such outlinesare also mirrored in the Conversation View.Moreover, the user can select multiple facet items(for instance a topic and an author) to quicklyunderstand who said about what topics.Besides exploring by the topics/ authors, thereader can browse individual comments by hover-ing and clicking on them in the Thread Overview,that causes to highlight its topic and scrolling tothe relevant comment in the Conversation View.Thus, the user can easily locate the comments thatbelong to a particular topic and/or author.
More-over, the keyphrases of the relevant topic and sen-timents are highlighted in the Conversation Viewupon selection, providing more details on demandabout what makes a particular comment positive/negative or how it is related to a particular topic.5 Further Challenges and DirectionsAfter implementing the prototype, we ran an infor-mal evaluation (Lam et al., 2012) with five targetusers (age range 18 to 24, 2 female) to evaluatethe higher levels of the nested model (Munzner,2009), where the aim was to collect anecdotal ev-idence that the system met its design goals.
Theparticipants?
feedback from our evaluation sug-gests that ConVis can help the user to identifythe topics and opinions expressed in the conver-sation; supporting the user in exploring commentsof interest, even if they are buried near the end ofthe thread.
We also identified further challengesfrom the observations and participants feedback.Based on our experience and literature review, weprovide potential directions to address these chal-lenges as we describe below.5.1 Human in the Loop: Interactive TopicRevisionAlthough the topic modeling method we appliedenhances the accuracy over traditional methodsfor non-conversational text, the informal evalua-tion reveals that still the extracted topics may notalways match user?s information need.
In somecases, the results of topic modeling can mismatchwith the reference set of topics/ concepts describedby human (Chuang et al., 2013).
Even the in-terpretations of topics can vary among people ac-cording to expertise and the current task in hand.In fact, during topic annotations by human experts,there was considerable disagreement on the num-ber of topics and on the assignment of sentencesto topic clusters (Joty et al., 2013b).
Dependingon user?s mental model and current tasks, the topicmodeling results may require to be more specificin some cases, and more generic in other cases.
Assuch, the topic model needs to be revised based49on user feedback to better support her analysistasks.
Thus, our goal is to support a human-in-the-loop topic modeling for asynchronous conver-sations via interactive visualization.There have been some recent works for incorpo-rating user supervision in probabilistic topic mod-els (e.g., Latent Dirichlet Allocation (LDA)) byadding constraints in the form of must-link andcannot-link (Andrzejewski et al., 2009; Hu et al.,2011), or in the form of a one-to-one mapping be-tween LDA?s latent topics and user tags (Ramageet al., 2009).
The feedback from users has beenalso integrated through visualizations, that steers asemi-supervised topic model (Choo et al., 2013).In contrast to the above-mentioned methods thatare designed for generic documents, we are fo-cusing on how our topic modeling approach thatis specific to asynchronous conversations, can besteered by the end-users.
We are planning to com-bine a visual interface for expressing the user?s in-tention via a set of actions, and a semi-supervisedversion of the topic model that can be iterativelyrefined from such user actions.A set of possible topic revision operations areshown in Figure 2.
Splitting a topic into furthersub-topics can be useful when the user wants toexplore the conversation at a finer-topic granular-ity (Figure 2(a)).
A merging operation serves theopposite purpose, i.e., when the user wants to ana-lyze the conversation at a coarser topic granularity(Figure 2(b)).
Together, these two operations areintended to help the user in dynamically changingthe granularity levels of different topics.Since each topic is currently represented by aset of keyphrases, they can also be effectivelyused to revise the topic model.
Consider an ex-ample, where the sentences related to two dif-ferent keyphrases, namely ?Obama health policy?and ?job recession?
are grouped together under thesame topic.
The user may realize that the sen-tences related to ?job recession?
should have beenseparated from its original topic into a new one(Figure 2(c)).
Finally, topic assignment modifi-cation can be performed, when the domain ex-pert believes that a group of sentences are wronglygrouped/clustered (Figure 2(d)) by the system.In order to design the interactive visualizationand algorithms for incorporating user feedback, anumber of open questions need to be answered.Some of these questions are related to the user re-quirement analysis of the problem domain, e.g.,(a) Split (b) Merge(c) Create topic by akeyphrase(d) Topic assignmentmodificationFigure 2: Four different possible user actions fortopic revisionwhat are the tasks for exploring asynchronous con-versation that require the introduction of user feed-back to refine the topic model?
What data shouldbe shown to the user to help her decide what topicrefinement actions are appropriate?In terms of designing the set of interaction tech-niques, the aim is to define a minimum set ofmodel refinement operations, and allowing theuser to express these operations from the visualinterface in a way that enhances the ability to pro-vide feedback.
A domain expert could possiblyexpress these operations through the direct manip-ulation method (e.g., dragging a topic node overanother).
A related open question is: how can weminimize the cognitive load associated with inter-preting the modeling results and deciding the nextround of topic revision operations?From the algorithmic perspective, the most cru-cial challenge seems to be devising an efficientsemi-supervised method in the current graph-based topic segmentation and labeling framework(Joty et al., 2013b).
It needs to be fast enough torespond to the user refinement actions and updateresults in an acceptable period of time.
In addition,determining the number of topics is a challengingproblem when running the initial model and whensplitting a topic further.5.2 Coupling Advanced NLP Methods withInteractive VisualizationsIn light of the informal evaluation, we also investi-gate how current NLP methods are supporting thetasks we identified and what additional methodscould be incorporated?
For example, one of thecrucial data variable in most of the tasks is opin-ion.
However, during the evaluation two users did50not find the current sentiment analysis sufficientenough in revealing whether a comment is sup-porting/ opposing a preceding one.
It seems thatopinion seeking tasks (e.g., ?why people were sup-porting or opposing an opinion??)
would requirethe reader to know the argumentation flow withinthe conversation, namely the rhetorical structureof each comment (Joty et al., 2013a) and howthese structures are linked to each other.An early work (Yee and Hearst, 2005) at-tempted to organize the comments using a tree-map like layout, where the parent comment isplaced on top as a text block and the space belowthe parent node is divided between supporting andopposing statements.
We plan to follow this ideain ConVis, but incorporating a higher level dis-course relation analysis of the conversations anddetecting controversial topics.Incorporating additional complex text analysisresults into the visualization may require us to re-visit some of the higher levels of the nested model,i.e., data abstraction and visual encoding.
It mayimpose further tradeoffs for visual encoding; forinstance how can we visually represent the argu-mentation structure within a conversation?
Howcan we represent such structure, while preserv-ing the data already found to be useful such astopic and thread structure?
How can we representthat a topic is controversial?
Besides text analysisresults, some additional facets can become moreuseful to the participants (e.g., moderation scores,named entities), while an existing facet being lessuseful.
In such cases, allowing the user to dynam-ically change the facets of interest can be useful.5.3 Evaluation in the WildWhile controlled experiments allow us to mea-sure the user performance on specific tasks for thegiven interface, they may not accurately capturereal world uses scenario (Lam et al., 2012).
In thiscontext, an ecologically valid evaluation of Con-Vis would be to allow the users to use the systemto read their own conversations of interest over anextended period of time.
Such longitudinal studywould provide valuable insights regarding the util-ity of the interface.Evaluating the topic refinement approach forasynchronous conversation can be even more chal-lenging.
An initial approach could be to formu-late some quantitative evaluation metrics, that helpus understand whether the iterative feedback fromthe user would improve the resultant topic modelin terms of agreement with the reference set oftopics described by human annotators.
However,such approach would not capture the subjectivedifferences of the users in interpreting the topicmodel.
It would be more interesting to see, howmuch users would actually care about providingthe feedback to refine the model in a real worldscenario?
What refinement operations would beperformed more often?
Would these operationseventually support the user to perform some anal-ysis tasks more effectively?6 ConclusionsUnderstanding the user behaviours, needs, and re-quirements in the target domain is critical in ef-fectively combining NLP and InfoVis techniques.In this paper, we apply a visualization designmethod (Munzner, 2009) to identify what infor-mation should be mined from the conversation aswell as how the visual encoding and interactiontechniques should be designed.
We claim that theNLP and the InfoVis components of the resultingsystem, ConVis, are more consistent and better in-tegrated, because they refer to a common set oftask and data abstractions.
In future work, we aimto explore a set of open challenges that were moti-vated by an initial informal evaluation of ConVis.ReferencesDavid Andrzejewski, Xiaojin Zhu, and Mark Craven.2009.
Incorporating domain knowledge into topicmodeling via dirichlet forest priors.
In Proc.
Conf.on Machine Learning, pages 25?32.Eric Baumer, Mark Sueyoshi, and Bill Tomlinson.2008.
Exploring the role of the reader in the activityof blogging.
In Proc.
of CHI, pages 1111?1120.G.
Carenini, R. T. Ng, and X. Zhou.
2007.
Summariz-ing Email Conversations with Clue Words.
In Proc.conf.
on World Wide Web, pages 91?100.Giuseppe Carenini, Gabriel Murray, and Raymond Ng.2011.
Methods for Mining and Summarizing TextConversations.
Morgan Claypool.Jaegul Choo, Changhyun Lee, Chandan K Reddy, andHaesun Park.
2013.
Utopian: User-driven topicmodeling based on interactive nonnegative matrixfactorization.
IEEE Trans.
Visualization & Comp.Graphics, 19(12):1992?2001.Jason Chuang, Sonal Gupta, Christopher Manning, andJeffrey Heer.
2013.
Topic model diagnostics: As-sessing domain relevance via topical alignment.
InProc.
Conf.
on Machine Learning, pages 612?620.51Andy Cockburn, Amy Karlson, and Benjamin B Bed-erson.
2008.
A review of overview+ detail, zoom-ing, and focus+ context interfaces.
ACM ComputingSurveys (CSUR), 41(1):2.Kushal Dave, Martin Wattenberg, and Michael Muller.2004.
Flash forums and forumreader: navigating anew kind of large-scale online discussion.
In Proc.ACM Conf.
on CSCW, pages 232?241.Michel Galley, Kathleen McKeown, Eric Fosler-Lussier, and Hongyan Jing.
2003.
Discourse seg-mentation of multi-party conversation.
In Proc.
ofACL, pages 562?569.Enamul Hoque and Giuseppe Carenini.
2014.
ConVis:A visual text analytic system for exploring blog con-versations.
(Computer Graphic Forum (to appear)).Yuening Hu, Jordan Boyd-Graber, and Brianna Sati-noff.
2011.
Interactive topic modeling.
In Proc.
ofACL.Quentin Jones, Gilad Ravid, and Sheizaf Rafaeli.
2004.Information overload and the message dynamicsof online interaction spaces: A theoretical modeland empirical exploration.
Information Systems Re-search, 15(2):194?210.Shafiq Joty, Giuseppe Carenini, Raymond Ng, andYashar Mehdad.
2013a.
Combining intra-andmulti-sentential rhetorical parsing for document-level discourse analysis.
In Proc.
of ACL.Shafiq Joty, Giuseppe Carenini, and Raymond T Ng.2013b.
Topic segmentation and labeling in asyn-chronous conversations.
Journal of Artificial Intelli-gence Research, 47:521?573.B.
K. Kaye.
2005.
Web side story: An exploratorystudy of why weblog users say they use weblogs.AEJMC Annual Conf.Bernard Kerr.
2003.
Thread arcs: An email threadvisualization.
In IEEE Symposium on InformationVisualization, pages 211?218.H.
Lam, E. Bertini, P. Isenberg, C. Plaisant, andS.
Carpendale.
2012.
Empirical studies in infor-mation visualization: Seven scenarios.
IEEE Trans.Visualization & Comp.
Graphics, 18(9):1520?1536.Heidi Lam.
2008.
A framework of interaction costsin information visualization.
IEEE Trans.
Visualiza-tion & Comp.
Graphics, 14(6):1149?1156.Gilad Mishne.
2006.
Information access challenges inthe blogspace.
In Workshop on Intelligent Informa-tion Access (IIIA).Sean A Munson and Paul Resnick.
2010.
Presentingdiverse political opinions: how and how much.
InProc.
of CHI, pages 1457?1466.Tamara Munzner.
2009.
A nested model for visualiza-tion design and validation.
IEEE Trans.
Visualiza-tion & Comp.
Graphics, 15(6):921?928.S.
Narayan and C. Cheshire.
2010.
Not too long toread: The tldr interface for exploring and navigatinglarge-scale discussion spaces.
In Hawaii Conf.
onSystem Sciences (HICSS), pages 1?10.V?ctor Pascual-Cid and Andreas Kaltenbrunner.
2009.Exploring asynchronous online discussions throughhierarchical visualisation.
In IEEE Conf.
on Infor-mation Visualization, pages 191?196.Daniel Ramage, David Hall, Ramesh Nallapati, andChristopher D Manning.
2009.
Labeled LDA: A su-pervised topic model for credit attribution in multi-labeled corpora.
In Proc.
of EMNLP, pages 248?256.Warren Sack.
2000.
Conversation map: an interfacefor very-large-scale conversations.
Journal of Man-agement Information Systems, 17(3):73?92.Michael Sedlmair, Miriah Meyer, and Tamara Mun-zner.
2012.
Design study methodology: reflectionsfrom the trenches and the stacks.
IEEE Trans.
Visu-alization & Comp.
Graphics, 18(12):2431?2440.Param Vir Singh, Nachiketa Sahoo, and TridasMukhopadhyay.
2010.
Seeking variety: A dynamicmodel of employee blog reading behavior.
Availableat SSRN 1617405.Markus Steinberger, Manuela Waldner, Marc Streit,Alexander Lex, and Dieter Schmalstieg.
2011.Context-preserving visual links.
IEEE Trans.
Visu-alization & Comp.
Graphics, 17(12):2249?2258.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-based methods for sentiment analysis.
Computa-tional linguistics, 37(2):267?307.Gina Danielle Venolia and Carman Neustaedter.
2003.Understanding sequence and reply relationshipswithin email conversations: a mixed-model visual-ization.
In Proc.
of CHI, pages 361?368.Fernanda B Vi?egas, Scott Golder, and Judith Donath.2006.
Visualizing email content: portraying rela-tionships from conversational histories.
In Proc.
ofCHI, pages 979?988.Martin Wattenberg and David Millen.
2003.
Conver-sation thumbnails for large-scale discussions.
In ex-tended abstracts on CHI, pages 742?743.Furu Wei, Shixia Liu, Yangqiu Song, Shimei Pan,Michelle X Zhou, Weihong Qian, Lei Shi, Li Tan,and Qiang Zhang.
2010.
Tiara: a visual exploratorytext analytic system.
In Proc.
ACM Conf.
on Knowl-edge Discovery and Data Mining, pages 153?162.Ka-Ping Yee and Marti Hearst.
2005.
Content-centered discussion mapping.
Online Deliberation2005/DIAC-2005.Aaron Robert Zinman.
2011.
Me, myself, and my hy-perego: understanding people through the aggrega-tion of their digital footprints.
Ph.D. thesis, MIT.52
