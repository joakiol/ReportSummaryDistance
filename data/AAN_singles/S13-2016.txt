Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 93?97, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUMCC_DLSI-(EPS): Paraphrases Detection Based on SemanticDistanceH?ctor D?vila, Antonio Fern?ndez Orqu?n,Alexander Ch?vez, Yoan Guti?rrez, ArmandoCollazo, Jos?
I. AbreuDI, University of MatanzasAutopista a Varadero km 3 ?Matanzas, Cuba.
{hector.davila, tony,alexander.chavez, yoan.gutierrez,armando.collazo,jose.abreu}@umcc.cuAndr?s Montoyo, Rafael Mu?ozDLSI, University of Alicante Carreterade San Vicente S/N Alicante, Spain.
{montoyo,rafael}@dlsi.ua.esAbstractThis paper describes the specifications andresults of UMCC_DLSI-(EPS) system, whichparticipated in the first Evaluating PhrasalSemantics of SemEval-2013.
Our supervisedsystem uses different kinds of semanticfeatures to train a bagging classifier used toselect the correct similarity option.
Related tothe different features we can highlight theresource WordNet used to extract semanticrelations among words and the use of differentalgorithms to establish semantic similarities.Our system obtains promising results with aprecision value around 78% for the Englishcorpus and 71.84% for the Italian corpus.1 IntroductionIt is well known finding words similarity, evenwhen it is lexical or semantic can improveentailment recognition and paraphraseidentification; and ultimately lead to improvementsin a wide range of applications in NaturalLanguage Processing (NLP).
Several areas likequestion answering, query expansion, informationretrieval, and many others, depend on phrasalsemantics (PS).
PS, is concerned with how themeaning of a sentence is composed both from themeaning of the constituent words, and from extrameaning contained within the structuralorganization of the sentence itself (Dominey,2005).The aim of SemEval 2013 competition is alsodiscovering similarity, specifically in EvaluatingPhrasal Semantics (EPS).
The goal of this task is toevaluate how well systems can judge the semanticsimilarity of a word and a short sequence of words.That is, given a set of pairs of this type; classify iton negative (if the meaning of the word issemantically different to the meaning of thesequence) or positive (if the meaning of thesequence, as a whole, is semantically close to themeaning of the word).Based on this, we developed a system capable todetect if two phrases are semantically close.The rest of this paper, specifically section 2 is abrief Related Work.
Section 3 describes the systemarchitecture and our run.
Continuing with section 4we describe the training phase.
Following that,section 5 presents the results and discussion for ourMachine Learning System.
Finally we concludeand propose our future works (Section 6).2 Related WorkThere have been many WordNet-based similaritymeasures, among other highlights the work ofresearchers like (Budanitsky and Hirst, 2006;Leacock and Chodorow, 1998; Mihalcea et al2006; Richardson et al 1994).On the other hand, WordNet::Similarity1(Pedersen et al 2004) has been used by otherresearchers in an interesting array of domains.WordNet::Similarity implements measures ofsimilarity and relatedness between a pair ofconcepts (or synsets2) based on the structure andcontent of WordNet.
According to (Pedersen et al2004), three of the six measures of similarity arebased on the information content of the least1http://sourceforge.net/projects/wn-similarity/2 A group of English words into sets of synonyms.93common subsumer (LCS).
These measures includeres (Resnik, 1995), lin (Lin, 1998), and jcn (Jiangand Conrath, 1997).Pursuant to Pedersen, there are three othersimilarity measures based on path lengths betweena pair of concepts: lch (Leacock and Chodorow,1998), wup (Wu and Palmer, 1994), and path.Our proposal differs from those ofWordNet::Similarity and other measures ofsimilarity in the way we selected the relevantWordNet relations (see section 3.2 for detail).Unlike others, our measure assign weight toWordNet relations (any we consider relevant)depending to the place they occupy in theminimum path and the previously visited relations.Besides these, the novelty of our approach isusing the weights as a function of semanticrelations in a minimal distance path and also themethod we used to arrive to those weight functionsor rules.3 System Architecture and description ofthe runAs we can see in Figure 1 our run begin with thepre-processing of SemEval 2013?s training set.Every sentence pair is tokenized, lemmatized andPOS-tagged using Freeling 2.2 tool (Atserias et al2006).
Afterwards, several methods and algorithmsare applied in order to extract all features for ourMachine Learning System (MLS).
The systemtrains the classifier using a model based onbagging (using JRip3).
The training corpus hasbeen provided by SemEval-2013 competition, inconcrete by the EPS task.
As a result, we obtain atrained model capable to detect if one phraseimplies other.
Finally, we test our system with theSemEval 2013 test set (see Table 2 with the resultsof our run).
The following section describes thefeatures extraction process.3.1 Description of the features used in theMachine Learning SystemIn order to detect entailment between a pair ofphrases, we developed an algorithm that searches asemantic distance, according to WordNet (Miller etal., 1990), between each word in the first phrasewith each one in the second phrase.We used four features which intend to measurethe level of proximity between both sentences:3 JRip is an inference and rules-based learner.?
The minimum distance to align the firstphrase with the second (MinDist).
See section3.2 for details.?
The maximal distance to align the first phrasewith the second (MaxDist).?
The average of all distances results to alignthe first phrase with the second one.(AverageDistance).?
The absolute relative error of all distancesresults to align the first phrase with thesecond respect to the average of them.Figure 1.
System Architecture.Other features included are the most frequentrelations contained in the shorted path of theminimum distance; result to align the first phrasewith the second one.
Following table shows therelations selected as most frequent.A weight was added to each of them, accordingto the place it occupy in the shortest path betweentwo synsets.
The shortest path was calculated usingBreadth -First-Search algorithm (BFS) (Cormen etal., 2001).In addition, there is one feature that takes intoaccount any other relationship that is notpreviously considered.Finally, as a result we obtain 22 features fromthis alignment method.Semeval 2013 testset?Pre-Processing (using Freeling 2.2)Tokenizing Lemmatizing POS TaggingRun 1Bagging Classifier (JRip)Feature ExtractionMinDistance MaxDistance error ?Training set fromSemeval 2013Pre-Processing (using Freeling 2.2)Tokenizing Lemmatizing POS TaggingFeature ExtractionMinDistance MaxDistance errorSupervised ModelTraining process (using Weka)Bagging Classifier (JRip)Paraphrases Detection94Relation Weight (?
function)Antonym 1000Synonym 0Hyponym/ Hypernym100 if exist an antonymbefore, 30 if exist otherrelation before (exceptsynonym, hyponym,hypernym), 5 otherwise.Meber_Holonym/PartHolonym100 if exist an antonymbefore, 20 if exist ahyponym or a hypernym,10otherwise.Cause/ Entailment100 if exist an antonymbefore, 2 otherwise.Similar_To100 if exist an antonymbefore, 3 otherwise.Attribute100 if exist an antonymbefore, 8 otherwise.Also_See100 if exist an antonymbefore, 10 otherwise.Derivationaly_Related_Form100 if exist an antonymbefore, 5 otherwise.Domain_Of_Synset_Topic100 if exist an antonymbefore, 13 otherwise.Domain_Of_Synset_Usage100 if exist an antonymbefore, 60 otherwise.Member_Of_Domain_Topic100 if exist an antonymbefore, 13 otherwise.Member_Of_Domain_Usage100 if exist an antonymbefore, 60 otherwise.Other 100Table 1.
Most frequents relations with their weight.3.2 Semantic DistanceAs aforementioned, our distance depends oncalculating the similarity between sentences, basedon the analysis of WordNet relations, and we onlytook into account the most frequent ones.
Whensearching the shortest path between two WordNetsynsets, frequents relations were considered theones extracted according to the analysis made inthe training corpus, provided by SemEval-2013.The distance between two synsets is calculatedwith the relations found; and simply it is the sumof the weights assigned to each connection.????????
(?, ?)
=  ????????(?
?, ??
), ?
(?, ?)
(1)????????
(?, ?)
= ???(??
, ??
), ?
(?, ?)
(2)???(??
; ??)
= ?
?(???(?[?
], ?[?
+ 1]))?=??=0(3)?
= ???(??
; ??)
(4)Where ?
and ?
represents the i-th and j-th sense ofthe word; P and Q represents words collections; ?
?is the X-th word of ?
; ??
is the Y-th word of ?;????????
obtains a value that represents aminimal semantic distance across WordNet (Milleret al 2006) resource (this resource is involved intothe integrator resource, ISR-WN (Guti?rrez et al2011a; 2010a); ????????
the minimal semanticdistance between two words; ???
represents theminimal semantic distance between two sensescollections; ?
is a collection of synsets thatrepresents the minimal path between two synsetsusing BFS; ???
obtains semantic relation typesbetween two synsets; W is a functions that applythe rules described in Table 1.
The maximum andaverage distance is calculated in a similar fashionbut using the maximum and average instead of theminimum.3.3 Semantic AlignmentFirst, the two sentences are pre-processed withFreeling 2.2 and the words are classified accordingto their parts-of-speech.
Then, all senses of everyword are taken and treated as a group.
Distancebetween two groups will be the minimal distance(described in 3.1) between senses of any pair ofwords belonging to the group.In the example of Figure 2, Dist=280 is selectedfor the pair ?Balance-Culture?
(minimal cost).Following the explanation on section 3.1 weextract the features guided to measure the level ofproximity between both sentences.Figure 2.
Distance between ?Balance?
and ?Culture?.A maximum and average distance is calculated in asimilar fashion, but using the maximum andaverage instead of the minimum.4 Description of the training phaseFor the training process, we used a supervisedlearning framework (based on Weka4), includingall the training set (positive and negative instances)as a training corpus.
We conduct severalexperiments in order to select the correct classifier,the best result being obtained with a model basedon bagging (using JRip algorithm).
Finally, weused 10-fold cross validation technique with theselected classifier, obtaining a classification valueof 73.21%.4 http://prdownloads.sourceforge.net/weka/L mma: BalanceSense 1Sense 2Lemma: CultureSense 1Sense 233501030 280880Dist=280955 Results and discussionEPS task of SemEval-2013 offered many officialmeasures to rank the systems.
Some of them arethe following:o F-Measure (FM): Correct Response (CR),Instances correctly classified, True positives(TP), Instances correctly classified aspositive.
False Positives (FP), Instancesincorrectly classified as positive, TrueNegatives (TN), Instances correctlyclassified as negative, False Negatives (FN),Instances incorrectly classified as negative.Corpus FM CR TP FP TN FNEnglish 0.6892 2826 1198 325 1628 755Italian 0.6396 574 245 96 329 180Table 2.
Official SemEval 2013 results.The behavior of our system, for English andItalian corpus is shown in Table 2.The only thing that changes to process theItalian corpus is that Freeling is used as input toidentify Italian words and it returns the EnglishWN synsets.
The process continues in the sameway as English.Figure 3: Semantic Distance distribution betweennegative and positive instances.As shown in Table 2, our main drawback is toclassify positive instances.
Sometimes, the distancebetween positive phrases is very far.
This is due tothe relations found in the minimum path are verysimilar to the one found in other pairs of negativesinstances; this can be the cause of our MLSclassifies them as negatives (see Figure 3).Figure 3 shows a distributional graphics thattake a sample of 200 negative and positiveinstances.
The graphics illustrate how close to zerovalue the positive instances are, while thenegatives are far away from this value.
However,in the approximate range between 80 and 200, wecan see values of positive and negative instancespositioning together.
This can be the cause that ourMLS misclassified some positive instances asnegative.6 Conclusion and future workThis paper introduced a new framework for EPS,which depends on the extraction of several featuresfrom WordNet relations.
We have conducted thesemantic features extraction in a multidimensionalcontext using the resource ISR-WN(Guti?rrez etal., 2010a).Our semantic distance provides an appealingapproach for dealing with phrasal detection basedon WordNet relation.
Our team reached the sixthposition of ten runs for English corpus, with asmall difference of 0.07 points compared to thebest results with respect to accuracy parameter.Despite the problems caused by poorly selectedpositive instances, our distance (labeled as Our)obtained very similar results to those obtained bythe best team (labeled as First5), which indicatesthat our work is well underway (see Table 3 fordetails).Team accuracy recall precisionFirst 0.802611 0.751664 0.836944128Our 0.723502 0.613415 0.786605384Table 3.
Comparative results (English corpus).It is important to remark that our system hasbeen the only competitor to evaluate Italian texts.It has been possible due to our system includeFreeling in the preprocessing stage.Our future work will aim to resolve instancesmisclassified by our algorithm.
In addition, we willintroduce lexical substitutions (synonyms) toexpand the corpus, we will also apply conceptualsemantic similarity using relevant semantic trees(Guti?rrez et al 2010b; Guti?rrez et al 2011b).AcknowledgmentsThis research work has been partially funded bythe Spanish Government through the projectTEXT-MESS 2.0 (TIN2009-13391-C04), "An?lisisde Tendencias Mediante T?cnicas de Opini?nSem?ntica" (TIN2012-38536-C03-03) and?T?cnicas de Deconstrucci?n en la Tecnolog?as delLenguaje Humano?
(TIN2012-31224); and by theValencian Government through the projectPROMETEO (PROMETEO/2009/199).ReferencesAtserias, J.; B. Casas; E. Comelles; M. Gonz?lez; L.Padr?
and M. Padr?.
FreeLing 1.3: Syntactic and5 christian_wartena.
Team HsH.05001000Semantic Distance DistributionPositive Instances Negative Instances96semantic services in an open-source NLP library.Proceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC?06),2006.
48-55 p.Budanitsky, A. and G. Hirst Evaluating wordnet-basedmeasures of lexical semantic relatednessComputational Linguistics, 2006, 32(1): 13-47.Cormen, T. H.; C. E. Leiserson; R. L. Rivest and C.Stein.
Introduction to algorithms.
MIT press, 2001.0262032937.Dominey, P. F. Aspects of descriptive, referential, andinformation structure in phrasal semantics: Aconstruction-based model Interaction Studies, 2005,6(2): 287-310.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez.
Integration of semantic resources based onWordNet.
XXVI Congreso de la Sociedad Espa?olapara el Procesamiento del Lenguaje Natural,Universidad Polit?cnica de Valencia, Valencia,SEPLN 2010, 2010a.
161-168 p. 1135-5948.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez.
UMCC-DLSI: Integrative resource fordisambiguation task.
Proceedings of the 5thInternational Workshop on Semantic Evaluation,Uppsala, Sweden, Association for ComputationalLinguistics, 2010b.
427-432 p.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez Enriching the Integration of SemanticResources based on WordNet Procesamiento delLenguaje Natural, 2011a, 47: 249-257.Guti?rrez, Y.; S. V?zquez and A. Montoyo.
ImprovingWSD using ISR-WN with Relevant Semantic Treesand SemCor Senses Frequency.
Proceedings of theInternational Conference Recent Advances in NaturalLanguage Processing 2011, Hissar, Bulgaria,RANLP 2011 Organising Committee, 2011b.
233--239 p.Jiang, J. J. and D. W. Conrath Semantic similarity basedon corpus statistics and lexical taxonomy arXivpreprint cmp-lg/9709008, 1997.Leacock, C. and M. Chodorow Combining local contextand WordNet similarity for word sense identificationWordNet: An electronic lexical database, 1998,49(2): 265-283.Lin, D. An information-theoretic definition ofsimilarity.
Proceedings of the 15th internationalconference on Machine Learning, San Francisco,1998.
296-304 p.Mihalcea, R.; C. Corley and C. Strapparava.
Corpus-based and knowledge-based measures of textsemantic similarity.
Proceedings of the nationalconference on artificial intelligence, Menlo Park,CA; Cambridge, MA; London; AAAI Press; MITPress; 1999, 2006.
775 p.Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross andK.
Miller Introduction to WordNet: An On-lineLexical Database International Journal ofLexicography, 3(4):235-244., 1990.Miller, G. A.; C. Fellbaum; R. Tengi; P. Wakefield; H.Langone and B. R. Haskell.
WordNet a lexicaldatabase for the English language.
Cognitive ScienceLaboratory Princeton University 2006.Pedersen, T.; S. Patwardhan and J. Michelizzi.WordNet:: Similarity: measuring the relatedness ofconcepts.
Demonstration Papers at HLT-NAACL2004, Association for Computational Linguistics,2004.
38-41 p.Resnik, P. Using information content to evaluatesemantic similarity in a taxonomy arXiv preprintcmp-lg/9511007, 1995.Richardson, R.; A. F. Smeaton and J. Murphy.
UsingWordNet as a knowledge base for measuringsemantic similarity between words, Technical ReportWorking Paper CA-1294, School of ComputerApplications, Dublin City University, 1994.Wu, Z. and M. Palmer.
Verbs semantics and lexicalselection.
Proceedings of the 32nd annual meeting onAssociation for Computational Linguistics,Association for Computational Linguistics, 1994.133-138 p.97
