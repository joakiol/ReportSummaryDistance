A DEF IN ITE  CLAUSE VERSIONOF CATEGORIAL  GRAMMARRemo Pareschi,"Department of Computer and Information Science,University of Pennsylvania,200 S. 33 rd St., Philadelphia, PA 19104, t andDepartment of Artificial Intelligence andCentre for Cognitive Science,University of Edinburgh,2 Buccleuch Place,Edinburgh EH8 9LW, Scotlandremo(~linc.cis.upenn.eduABSTRACTWe introduce a first-order version of Catego-rial Grammar, based on the idea of encoding syn-tactic types as definite clauses.
Thus, we dropall explicit requirements of adjacency betweencombinable constituents, and we capture word-order constraints imply by allowing subformu-lae of complex types to share variables rangingover string positions.
We are in this way ableto account for constructiods involving discontin-uous constituents.
Such constructions axe difficultto handle in the more traditional version of Cate-gorial Grammar, which is based on propositionaltypes and on the requirement of strict string ad-jacency between combinable constituents.We show then how, for this formalism, parsingcan be efficiently implemented as theorem proving.Our approach to encoding types:as definite clausespresupposes a modification of standard Horn logicsyntax to allow internal implications in definiteclauses.
This modification is needed to account forthe types of higher-order functions and, as a con-sequence, standard Prolog-like Horn logic theoremproving is not powerful enough.
We tackle this* I am indebted to Dale Miller for help and advice.
Iam also grateful to Aravind Joshi, Mark Steedman, Davidx, Veir, Bob Frank, Mitch Marcus and Yves Schabes for com-ments and discussions.
Thanks are due to Elsa Grunter andAmy Feh.y for advice on typesetting.
Parts of this researchwere supported by: a Sloan foundation grant to the Cog-nitive Science Program, Univ.
of Pennsylvania; and NSFgrants MCS-8219196-GER, IRI-10413 AO2, ARO grantsDAA29-84-K-0061, DAA29-84-9-0027 and DARPA grantNOOO14-85-K0018 to CIS, Univ.
of Pezmsylvani&t Address for correspondenceproblem by adopting an intuitionistic treatmentof implication, which has already been proposedelsewhere as an extension of Prolog for implement-ing hypothetical reasoning and modular logic pro-gramming.1 In t roduct ionClassical Categorial Grammar (CG) \[1\] is an ap-proach to natural language syntax where all lin-guistic information is encoded in the lexicon, viathe assignment of syntactic types to lexical items.Such syntactic types can be viewed as expressionsof an implicational calculus of propositions, whereatomic propositions correspond to atomic types,and implicational propositions account for com-plex types.
A string is grammatical if and onlyif its syntactic type can be logically derived fromthe types of its words, assuming certain inferenceru les .In classical CG, a common way of encodingword-order constraints is by having two symmet-ric forms of "directional" implication, usually in-dicated with the forward slash / and the backwardslash \, constraining the antecedent of a complextype to be, respectively, right- or left-adjacent.
Aword, or a string of words, associated with a right-(left-) oriented type can then be thought of as aright- (left-) oriented function looking for an ar-gument of the type specified in the antecedent.
Aconvention more or less generally followed by lin-guists working in CG is to have the antecedent andthe consequent of an implication respectively on270the right and on tile left of the connective.
Thus,tile type-assignment (1) says that the ditransitiveverb put is a function taking a right-adjacent ar-gulnent of type NP, to return a function taking aright-adjacent argument of type PP, to return afunction taking a left-adjacent argument of typeNP, to finally return an expression of the atomictype S.(1) put :  ((b~xNP)/PP)/NPThe Definite Clause Grammar (DCG) framework\[14\] (see also \[13\]), where phrase-structure gram-mars can be encoded as sets of definite clauses(which are themselves a subset of Horn clauses),and the formalization of some aspects of it in \[15\],suggests a more expressive alternative to encodeword-order constraints in CG.
Such an alterna-tive eliminates all notions of directionality fromthe logical connectives, and any explicit require-ment of adjacency between functions and argu-ments, and replaces propositions with first-order?
formulae.
Thus, atomic types are viewed as atomicformulae obtained from two-place predicates overstring positions represented as integers, the firstand the second argument corresponding, respec-tively, to the left and right end of a given string.Therefore, the set of all sentences of length jgenerated from a certain lexicon corresponds tothe type S(0,j).
Constraints over the order ofconstituents are enforced by sharing integer in-dices across subformulae inside complex (func-tional) types.This first-order version of CG can be viewed as alogical reconstruction of some of the ideas behindthe recent trend of Categorial Unification Gram-mars \[5, 18, 20\] 1.
A strongly analogous develop-ment characterizes the systems of type-assignmentfor the formal anguages of Combinatory Logic andLambda Calculus, leading from propositional typesystems to the "formulae-as-types" slogan which isbehind the current research in type theory \[2\].
Inthis paper, we show how syntactic types can be en-coded using an extended version of standard Hornlogic syntax.2 Definite Clauses with In-ternal ImplicationsLet A and ---* be logical connectives for conjunc-tion and implication, and let V and 3 be the univer-1 Indeed, Uszkoreit \[18\] mentions the possibility of en-coding order constraints among constituents via variablesranging over string positions in the DCG style.sal and existential quantifiers.
Let A be a syntacticvariable ranging over the set of atoms, i. e. the setof atomic first-order formulae, and let D and G besyntactic variables ranging, respectively, over theset of definite clauses and the set of goal clauses.We introduce the notions of definite clause andof goal clause via the two following mutually re-cursive definitions for the corresponding syntacticvariables D and G:?
D:=AIG--AIVzDID1AD2?
G :=AIG1AG=I3~:GID~GWe call ground a clause not containing variables.We refer to the part of a non-atomic definite clausecoming on the left of the implication connectiveas to the body of the clause, and to the one onthe right as to the head.
With respect o standardHorn logic syntax, the main novelty in the defini-tions above is that we permit implications in goalsand in the bodies of definite clauses.
ExtendedHorn logic syntax of this kind has been proposedto implement hypothetical reasoning \[3\] and mod-ules \[7\] in logic programming.
We shall first makeclear the use of this extension for the purpose oflinguistic description, and we shall then illustrateits operational meaning.3 First-orderCategorial Grammar3.1 Def in i te  C lauses  as  TypesWe take CONN (for "connects") to be a three-place predicate defined over lexical items and pairsof integers, such that CONN(item, i , j)  holds ifand only if and only if i = j - 1, with the in-tuitive meaning that item lies between the twoconsecutive string positions i and j.
Then, amost direct way to translate in first-order logicthe type-assignment (1) is by the type-assignment(2), where, in the formula corresponding to the as-signed type, the non-directional implication con-nective --, replaces the slashes.
(2) put : VzVyYzVw\[CONN(put, y - 1, y) --*(NP(y, z) - -(PP(z, w) --(NP(z, y - 1) --*s(=, ~o))))\]271A definite clause equivalent of tile formula in (2)is given by the type-assignment (3)2 .
(3) put:  VzVyVzVw\[CONN(put, y - -  1, y) ANP(y, z) ^PP(z, w) AgP(z,  y - 1) --* S(x, w)\]Observe that the predicate CONNwill need alsoto be part of types assigned to "non-functional"lexical items.
For example, we can have for thenoun-phrase Mary the type-assignment (4).
(4) Mary : Vy\[OONN(Mary, y -  1,y) .-.-*NP(y - 1, y)\]3 .2  H igher -order  Types  and  In ter -na l  Imp l i ca t ionsPropositional CG makes crucial use of func-tions of higher-order type.
For example, the type-assignment (5) makes the relative pronoun whichinto a function taking a right-oriented functionfrom noun-phrases to sentences and returning arelative clause 3.
This kind of type-assignment hasbeen used by several linguists to provide attractiveaccounts of certain cases of extraction \[16, 17, 10\].
(5) which:  REL/(S/NP)In our definite clause version of CG, a similarassignment, exemplified by (6), is possible, since?
implications are allowed in the.
body of clauses.Notice that in (6) the noun-phrase needed to fillthe extraction site is "virtual", having null length.
(6) which: VvVy\[CONN(which, v - 1, v) ^(NP(y, y) --* S(v, y)) --*REL(v - 1, y)\]2 See \[2\] for a pleasant formal characterization of  first-order def in i te clauses as type declarations.aFor simplicity sake, we treat here relative clauses asconstituents of atomic type.
But in reality relative clausesare noun modifiers, that is, functions from nouns to nouns.Therefore, the propositional and the first-order atomic typefor relative clauses in the examples below should be thoughtof as shorthands for corresponding complex types.3.3 Ar i thmet ic  P red icatesThe fact that we quantify over integers allowsus to use arithmetic predicates to determine sub-sets of indices over which certain variables mustrange.
This use of arithmetic predicates charac-terizes also Rounds' ILFP notation \[15\], which ap-pears in many ways interestingly related to theframework proposed here.
We show here belowhow this capability can be exploited to accountfor a case of extraction which is particularly prob-lematic for bidirectional propositional CG.3.3.1 Non-per lphera l  Ext rac t ionBoth the propositional type (5) and the first-order type (6) are good enough to describe thekind of constituent needed by a relative pronounin the following right-oriented case of peripheralextraction, where the extraction site is located atone end of the sentence.
(We indicate the extrac-tion site with an upward-looking arrow.
)which \ [ I sha l lput  a book on T \]However, a case of non.peripheral extraction,where the extraction site is in the middle, suchaswhich \[ I shall put T on the table \]is difficult to describe in bidirectional proposi-tional CG, where all functions must take left- orright-adjacent arguments.
For instance, a solutionlike the one proposed in \[17\] involves permutingthe arguments of a given function.
Such an opera-tion needs to be rather cumbersomely constrainedin an explicit way to cases of extraction, lest itshould wildly overgenerate.
Another solution, pro-posed in \[10\], is also cumbersome and counterintu-itive, in that involves the assignment of multipletypes to wh-expressions, one for each site whereextraction can take place.On  the other hand, the greater expressive powerof first-order logic allows us to elegantly general-ize the type-assignment (6) to the type-assignment(7).
In fact, in (7) the variable identifying the ex-traction site ranges over the set of integers in be-tween the indices corresponding, respectively, tothe left and right end of the sentence on whichthe rdlative pronoun operates.
Therefore, such asentence can have an extraction site anywhere be-tween its string boundaries.272(7) which : VvVyVw\[CONN(which, v - 1, v) A(NP(y, y) --.
* S(v, w)) Av<yAy<w- .
*REL(v - 1, w) \]Non-peripheral extraction is but one example ofa class of discontinuous constituents, that is, con-stituents where the function-argument relation isnot determined in terms of left- or right-adjacency,since they have two or more parts disconnectedby intervening lexical material, or by internal ex-traction sites.
Extraposition phenomena, gap-ping constructions in coordinate structures, andthe distribution of adverbials offer other problem-atic examples of English discontinuous construc-tions for which this first-order framework seemsto promise well.
A much larger batch of simi-lar phenomena is offered by languages with freerword order than English, for which, as pointedout in \[5, 18\], classical CG suffers from an evenclearer lack of expressive power.
Indeed, Joshi \[4\]proposes within the TAG framework an attractivegeneral solution to word-order variations phenom-ena in terms of linear precedence r lations amongconstituents.
Such a solution suggests a similarapproach for further work to be pursued withinthe framework presented here.4 Theorem Prov ingIn propositional CG, the problem of determin-ing the type of a string from the types of itswords has been addressed either by defining cer-tain "combinatory" rules which then determine arewrite relation between sequences of types, or byviewing the type of a string as a logical conse-quence of the types of its words.
The first al-ternative has been explored mainly in Combina-tory Grammar \[16, 17\], where, beside the rewriterule of functional application, which was alreadyin the initial formulation of CG in \[1\], there arealso tim rules of functional composition and typeraising, which are used to account for extractionand coordination phenomena.
This approach of-fers a psychologically attractive model of parsing,based on the idea of incremental processing, butcauses "spurious ambiguity", that is, an almostexponential proliferation of the possible derivationpaths for identical analyses of a given string.
Infact, although a rule like functional compositionis specifically needed for cases of extraction andcoordination, in principle nothing prevents its useto analyze strings not characterized by such phe-nomena, which would be analyzable in terms offunctional application alone.
Tentative solutionsof this problem have been recently discussed in\[12, 19\].The second alternative has been undertaken inthe late fifties by Lambek \[6\] who defined a deci-sion procedure for bidirectional propositional CGin terms of a Gentzen-style sequent system.
Lam-bek's implicational calculus of syntactic types hasrecently enjoyed renewed interest in the works ofvan Benthem, Moortgat and other scholars.
Thisapproach can account for a range of syntactic phe-nomena similar to that of Combinatory Grammar,and in fact many of the rewrite rules of Combi-natory Grammar can be derived as theorems inthe calculus, tIowever, analyses of cases of extrac-tion and coordination are here obtained via infer-ences over the internal implications in the types ofhigher-order functio~ls.
Thus, extraction and coor-dination can be handled in an expectation-drivenfashion, and, as a consequence, there is no problemof spuriously ambiguous derivations.Our approach ere is close in spirit to Lambek'senterprise, since we also make use of a Gentzensystem capable of handling the internal implica-tions in the types of higher-order functions, butat the same time differs radically from it, sincewe do not need to have a "specialized" proposi-tional logic, with directional connectives and adja-cency requirements.
Indeed, the expressive powerof standard first-order logic completely eliminatesthe need for this kind of specialization, and at thesame time provides the ability to account for con-structions which, as shown in section 3.3.1, areproblematic for an (albeit specialized) proposi-tional framework.4.1 An Intuitionistic Exterision ofPrologThe inference system we are going to introducebelow has been proposed in \[7\] as an extension ofProlog suitable for modular logic programming.
Asimilar extension has been proposed in \[3\] to im-plement hypotethical reasoning in logic program-ming.
We are thus dealing with what can be con-sidered the specification of a general purpose logicprogramming language.
The encoding of a par-ticular linguistic formalism is but one other appli-cation of such a language, which Miller \[7\] showsto be sound and complete for intuitionistic logic,and to have a well defined semantics in terms of273Kripke models.4.1.1 Logic P rogramsWe take a logic program or, simply, a program79 to be any set of definite clauses.
We formallyrepresent the fact that a goal clause G is logicallyderivable from a program P with a sequent of theform 79 =~ G, where 79 and G are, respectively, theantecedent and the succedent of the sequent.
If 7 ~is a program then we take its substitution closure\[79\] to be the smallest set such that?
79 c_ \[79\]?
i f  O1 A D2 E \[7 ~\] then D1 E \[79\] and D2 E \[7 ~\]?
i fVzD E \[P\] then \[z/t\]D E \[7 ~\] for all terms t,where \[z/t\] denotes the result of substitutingt for free occurrences of t in D4.1.2 P roo f  RulesWe introduce now the  following proof rules,which define the notion of proof for our logic pro-gramrning language:(I) 79=G i faE \ [7  )\]( i i )  79 =~ G if G ---, A e \[7)\]7)=~A( I I I )~P =~ G~ A G2( IV)  79 = \[=/t\]c7~ =~ BzG7~U {O} =~ G(V) P ~ D--.
GIn the inference figures for rules ( I I )  - (V), thesequent(s) appearing above the horizontal line arethe upper sequent(s), while the sequent appearingbelow is the lower sequent.
A proof for a sequent7 ) =~ G is a tree whose nodes are labeled withsequents uch that (i) the root node is labeled with7 9 ~ G, (ii) the internal nodes are instances of oneof proof rules ( I I )  - (V) and (iii) the leaf nodes arelabeled with sequents representing proof rule (I).The height of a proof is the length of the longestpath from the root to some leaf.
The size of aproof is the number of nodes in it.Thus, proof rules ( I ) - (V)  provide the abstractspecification of a first-order theorem prover whichcan then be implemented in terms of depth-firstsearch, backtracking and unification like a Prologinterpreter.
(An example of such an implemen-tation, as a metainterpreter on top of Lambda-Prolog, is given in \[9\].)
Observe however thatan important difference of such a theorem proverfrom a standard Prolog interpreter is in the widerdistribution of "logical" variables, which, in thelogic programming tradition, stand for existen-tially quantified variables within goals.
Such vari-ables can get instantiated in the course of a Prologproof, thus providing the procedural ability to re-turn specific values as output of the computation.Logical variables play the same role in the pro-gramming language we are considering here; more-over, they can also occur in program clauses, sincesubformulae of goal clauses can be added to pro-grams via proof rule (V).4 .2  How St r ings  Def ine  P rogramsLet a be a string a, .
.
.
an of words from a lex-icon Z:.
Then a defines a program 79a = ra  tJ Aasuch that?
Fa={CONN(a i , i - l , i )  l l< i<n}?
Aa={Dla i :DEZ:and l< i<n}Thus, Pa just contains ground atoms encodingthe position of words in a.
A a contains instead allthe types assigned in the lexicon to words in a. Weassume arithmetic operators for addition, subtrac-tion, multiplication and integer division, and weassume that any program 79= works together withan infinite set of axioms ,4 defining the compari-son predicates over ground arithmetic expressions<, _<, >, _>.
(Prolog's evaluation mechanism treatsarithmetic expressions in a similar way.)
Then,under this approach a string a is of type Ga if andonly if there is a proof for the sequent 7)aU.4 ::~ Gaaccording to rules (I) - (V).4 .3  An  ExampleWe give here an example of a proof which deter-mines a corresponding type-assignment.
Considerthe stringwhom John lovesSuch a sentence determines a program 79 withthe following set F of ground atoms:{ CONN(whom, O, I),CONN(John, I, 2),CONN(loves, 2, 3)}274\,Ve assume lexical type assignments such thatthe remaining set of clauses A is as follows:{VxVz \ [CONN(whom,  x - 1, x) A(NP(y ,  y) --* S(x,  y)) --*REL(x  - 1, y)\],gx\ [CONN( John,  x - 1, x) -* NP(x  - 1, x)\],W:VyVz\[CONN(Ioves,  y - 1, y) ANP(y ,  z) A NV(x ,  y - 1) --~s(x, z)l}The clause assigned to the relative pronounwhom corresponds to the type of a higher-orderfunction, and contains an implication in its body.Figure 1 shows a proof tree for such a type-assignment.
The tree, which is represented asgrowing up from its root, has size 11, and height8.5 'S t ructura l  Ru lesWe now briefly examine the interaction of struc.tural rules with parsing.
In intuitionistic sequentsystems, structural rules define ways of subtract-ing, adding, and reordering hypotheses in sequentsduring proofs.
We have the three following struc-tural rules:?
Intercha~,ge, which allows to use hypothesesin any order?
Contraction, which allows to use a hypothesismore than once?
Thinning, which says that not all hypothesesneed to be used5.1 P rograms as Unordered  Sets  o fHypothesesAll of the structural rules above are implicit inproof rules ( I)-(V), and they are all needed to ob-tain intuitionistic soundness and completeness ain \[7\].
By contrast, Lambek's propositional calcu-lus does not have any of the structural rules; forinstance, Interchange is not admitted, since thehypotheses deriving the type of a given string mustalso account for the positions of the words to whichthey have been assigned as types, and must obeythe strict string adjacency requirement betweenfunctions and arguments of classical CG.
Thus,Lambek's calculus must assume ordered lists ofhypotheses, o as to account for word-order con-straints.
Under our approach, word-order con-straints are obtained declaratively, via sharing ofstring positions, and there is no strict adjacencyrequirement.
In proof-theoretical terms, this di-rectly translates in viewing programs as unorderedsets of hypotheses.5.2 T rad ing  Cont rac t ion  aga ins tDec idab i l i tyThe logic defined by rules ( I)-(V) is in generalundecidable, but it becomes decidable as soon asContraction is disallowed.
In fact, if a given hy-pothesis can be used at most once, then clearly thenumber of internal nodes in a proof tree for a se-quent 7 ~ =~ G is at most equal to the total numberof occurrences of--*, A and 3 in 7 ~ =~ G, since theseare the logical constants for which proof rules withcorresponding inference figures have been defined.Hence, no proof tree can contain infinite branchesand decidability follows.Now, it seems a plausible conjecture that theprograms directly defined by input strings as inSection 4.2 never need Contraction.
In fact, eachtime we use a hypothesis in the proof, either weconsume a corresponding word in the input string,or we consume a "virtual" constituent correspond-ing to a step of hypothesis introduction deter-mined by rule (V) for implications.
(Construc-tions like parasitic gaps can be accounted for by as-sociating specific lexical items with clauses whichdetermine the simultaneous introduction of gaps ofthe same type.)
If this conjecture can be formallyconfirmed, then we could automate our formalismvia a metalnterpreter based on rules (I)-(V), butimplemented in such a way that clauses are re-moved from programs as soon as they are used.Being based on a decidable fragment of logic, sucha metainterpreter would not be affected by thekind of infinite loops normally characterizing DCGparsing.5.3 Th inn ing  and  Vacuous  Abst rac -t ionThinning can cause problems of overgeneratiou,as hypotheses introduced via rule (V) may end upas being never used, since other hypotheses can beused instead.
For instance, the type assignment(7) which : VvVyVw\[CONN(which,  v - 1, v) A(gP(y ,  y) ~ S(v, w)) Av<_yAy<_w- - .275U {NP(3,3)} ~ CONN(John, \],2) (If)T'U {NP(3,3)} = NP(I,2) PU {NP(3,3)} = NP(3,3) (III)P U {NP(3, 3)} ~ CONN(Ioves, 2 3) 7 ) U {NP(3, 3)) =~ NP(1, 2) A NP(3, 3) (I I I)7 ) U {NP(3,3)} =# CONN(loves, 2,3) A NP(I,2) A NP(3, 3) (II)7)U {NP(3,3)} => S(1,3)7 ) => CONN(whom, O,1) P =~ NP(3,3) --* S(1,3) (V), (ziz)7) =# CONN(whom, O, I) A (NP(3, 3) -- S(I, 3)) (II)7) ~ REL(O, 3)Figure h Type derivation for whom John lovesREL(v-  1, w) \]can be used to account for tile well-formedness ofbothwhich \ [ I sha l lput  a book on r \]andwhich \[ I shall put : on the table \]but will also accept he ungrammaticalwhich \[ I shall put a bookon the table \]In fact, as we do not have to use all the hy-potheses, in this last case the virtual noun-phrasecorresponding to the extraction site is added tothe program but is never used.
Notice that ourconjecture in section 4.4.2 was that Contractionis not needed to prove the theorems correspond-ing to the types of grammatical strings; by con-trast, Thinning gives us more theorems than wewant.
As a consequence, eliminating Thinningwould compromise the proof-theoretic propertiesof (1)-(V) with respect to intuitionistic logic, andthe corresponding Kripke models semantics of ourprogramming language.There is however a formally well defined way toaccount for the ungrammaticaiity of the exampleabove without changing the logical properties ofour inference system.
We can encode proofs asterms of Lambda Calculus and then filter certainkinds of proof terms.
In particular, a hypothesisintroduction, determined by rule (V), correspondsto a step of A-abstraction, wllile a hypothesis elim-ination, determined by one of rules ( I ) - ( I I ) ,  cor-responds to a step of functional application andA-contraction.
Hypotheses which are introducedbut never eliminated result in corresponding casesof vacuous abstraction.
Thus, the three examplesabove have the three following Lambda encodingsof the proof of the sentence for which an extractionsite is hypothesized, where the last ungrammaticalexample corresponds to a case of vacuous abstrac-tion:?
Az put(\[a book\], \[on x\], I)?
Az put(x, \[on the table\], I)?
Az put(\[a book\], \[on the table\], I)Constraints for filtering proof terms character-ized by vacuous abstraction can be defined ina straightforward manner, particularly if we areworking with a metainterpreter implemented ontop of a language based on Lambda terms, such asLambda-Prolog \[8, 9\].
Beside the desire to main-tain certain well defined proof-theoretic and se-mantic properties of our inference system, thereare other reasons for using this strategy insteadof disallowing Thinning.
Indeed, our target hereseems specifically to be the elimination of vacuousLambda abstraction.
Absence of vacuous abstrac-tion has been proposed by Steedman \[17\] as a uni-versal property of human languages.
Morrill andCarpenter \[11\] show that other well-formednessconstraints formulated in different grammaticaltheories such as GPSG,  LFG and GB reduce tothis same property.
Moreover, Thinning gives usa straightforward way to account for situations oflexical ambiguity, where the program defined by acertain input string can in fact contain hypothe-ses which are not needed to derive the type of thestring.References\[1\] Bar-Hillel, Yehoslma.
1953.A Quasi-arithmetical Notation for SyntacticDescription.
Language.
29. pp47-58.\[2\] Huet, Gerard 1986.
Formal Structures forComputation and Deduction.
Unpublishedlecture notes.
Carnegie-Mellon University.276\[3\] Gabbay, D. M., and U. Reyle.
1984.
N-Prolog:An Extension of Prolog with lIypothetical Im-plications.
I The Journal of Logic Program-ruing.
1. pp319-355.\[4\] Joshi, Aravind.
1987.
Word.order Variationin Natural Language Generation.
In Proceed-ings of the National Conference on ArtificialIntelligence (AAAI 87), Seattle.\[5\] Karttunen, Lauri.
1986.
Radical Lexicalism.Report No.
CSLI-86-68.
CSLI, Stanford Uni-versity.\[6\] Lambek, Joachim.
1958.
The Mathematics ofSentence Structure.
American MathematicalMonthly.
65. pp363-386.\[7\] Miller, Dale.
1987.
A Logical Analysis of Mod.ules in Logic Programming.
To appear in theJournal of Logic Programming.\[8\] Miller; Dale and Gopalan Nadathur.
1986.Some Uses of Higher.order Logic in Com-putational Linguistics.
In Proceedlngs of the24th Annual Meeting of the Association forComputational Linguistics, Columbia Uni-versity.\[9\] Miller, Dale and Gopalan Nadathur.
1987.
ALogic Programming Approach to Manipulat-ing Formulas and Programs.
Paper presentedat the IEEE Fourth Symposium on Logic Pro-gramming, San Francisco.\[10\] Moortgat, Michael.
1987.
Lambek TheoremProving.
Paper presented at the ZWO work-shop Categorial Grammar: Its Current State.June 4-5 1987, ITLI Amsterdam.\[11\] Morrill, Glyn and Bob Carpenter 1987.Compositionality, Implicational Logic andTheories of Grammar.
Research PaperEUCCS/RP-11, University of Edinburgh,Centre for Cognitive Science.\[12\] Pareschi, Remo and Mark J. Steedman.
1987.A Lazy Way to Chart-parse with CategorialGrammars.
In Proceedings of the 25th An-nual Meeting of the Association for Compu-tational Linguistics, Stanford University.\[13\] Pereira, Fernando C. N. and Stuart M.Shieber.
1987.
Prolog and Natural LanguageAnalysis.
CSLI Lectures Notes No.
10.
CSLI,Stanford University.\[14\] Pereira, Fernando C. N. and David II.
D.Warren.
1980.
Definite Clauses for LanguageAnalysis.
Artificial Intelligence.
13. pp231-278.\[15\] Rounds, William C. 1987.
LFP: A Logic forLinguistic Descriptions and an Analysis of ltsComplexity.
Technical Report No.
9.
The Uni-versity of Michigan.
To appear in Computa-tional Linguistics.\[16\] Steedman, Mark J.
1985.
Dependency andCoordination in the Grammar of Dutch andEnglish.
Language, 61, pp523-568\[17\] Steedman, Mark J.
1987.
Combinatory Gram-mar and Parasitic Gaps.
To appear in Natu-?
rat Language and Linguistic Theory.\[18\] Uszkoreit, Hans.
1986.
Categorial" UnificationGrammar.
In Proceedings of the 11th Inter-national Conference of Computational Lin-guistics, Bonn.\[19\] Wittenburg, Kent.
1987.
Predictive Combina-tots for the Efficient Parsing of CombinatoryGrammars.
In Proceedings of the 25th An-nual Meeting of tile Association for Compu-tational Linguistics, Stanford University.\[20\] Zeevat, H., Klein, E., and J. Calder.
1987.
AnIntroduction to Unification Categorial Gram-mar.
In N. Haddock et al (eds.
), EdinburghWorking Papers in Cognitive Science, 1: Cat-egorial Grammar, Unification Grammar, andParsing.277
