Proceedings of the ACL 2010 Conference Short Papers, pages 49?54,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsThe Prevalence of Descriptive Referring Expressionsin News and NarrativeRaquel Herva?sDepartamento de Ingenieriadel Software e Inteligenc?
?a ArtificialUniversidad Complutense de MadridMadrid, 28040 Spainraquelhb@fdi.ucm.esMark Alan FinlaysonComputer Science andArtificial Intelligence LaboratoryMassachusetts Institute of TechnologyCambridge, MA, 02139 USAmarkaf@mit.eduAbstractGenerating referring expressions is a keystep in Natural Language Generation.
Re-searchers have focused almost exclusivelyon generating distinctive referring expres-sions, that is, referring expressions thatuniquely identify their intended referent.While undoubtedly one of their most im-portant functions, referring expressionscan be more than distinctive.
In particular,descriptive referring expressions ?
thosethat provide additional information not re-quired for distinction ?
are critical to flu-ent, efficient, well-written text.
We presenta corpus analysis in which approximatelyone-fifth of 7,207 referring expressions in24,422 words of news and narrative are de-scriptive.
These data show that if we areever to fully master natural language gen-eration, especially for the genres of newsand narrative, researchers will need to de-vote more attention to understanding howto generate descriptive, and not just dis-tinctive, referring expressions.1 A Distinctive FocusGenerating referring expressions is a key step inNatural Language Generation (NLG).
From earlytreatments in seminal papers by Appelt (1985)and Reiter and Dale (1992) to the recent setof Referring Expression Generation (REG) Chal-lenges (Gatt et al, 2009) through different corporaavailable for the community (Eugenio et al, 1998;van Deemter et al, 2006; Viethen and Dale, 2008),generating referring expressions has become oneof the most studied areas of NLG.Researchers studying this area have, almostwithout exception, focused exclusively on howto generate distinctive referring expressions, thatis, referring expressions that unambiguously iden-tify their intended referent.
Referring expres-sions, however, may be more than distinctive.
Itis widely acknowledged that they can be used toachieve multiple goals, above and beyond distinc-tion.
Here we focus on descriptive referring ex-pressions, that is, referring expressions that are notonly distinctive, but provide additional informa-tion not required for identifying their intended ref-erent.
Consider the following text, in which someof the referring expressions have been underlined:Once upon a time there was a man, who hadthree daughters.
They lived in a house andtheir dresses were made of fabric.While a bit strange, the text is perfectly well-formed.
All the referring expressions are distinc-tive, in that we can properly identify the referentsof each expression.
But the real text, the openinglines to the folktale The Beauty and the Beast, isactually much more lyrical:Once upon a time there was a rich merchant,who had three daughters.
They lived in avery fine house and their gowns were madeof the richest fabric sewn with jewels.All the boldfaced portions ?
namely, the choiceof head nouns, the addition of adjectives, the useof appositive phrases ?
serve to perform a descrip-tive function, and, importantly, are all unneces-sary for distinction!
In all of these cases, the au-thor is using the referring expressions as a vehi-cle for communicating information about the ref-erents.
This descriptive information is sometimesnew, sometimes necessary for understanding thetext, and sometimes just for added flavor.
Butwhen the expression is descriptive, as opposed todistinctive, this additional information is not re-quired for identifying the referent of the expres-sion, and it is these sorts of referring expressionsthat we will be concerned with here.49Although these sorts of referring expressionhave been mostly ignored by researchers in thisarea1, we show in this corpus study that descrip-tive expressions are in fact quite prevalent: nearlyone-fifth of referring expressions in news and nar-rative are descriptive.
In particular, our data,the trained judgments of native English speakers,show that 18% of all distinctive referring expres-sions in news and 17% of those in narrative folk-tales are descriptive.
With this as motivation, weargue that descriptive referring expressions mustbe studied more carefully, especially as the fieldprogresses from referring in a physical, immedi-ate context (like that in the REG Challenges) togenerating more literary forms of text.2 Corpus AnnotationThis is a corpus study; our procedure was there-fore to define our annotation guidelines (Sec-tion 2.1), select texts to annotate (2.2), create anannotation tool for our annotators (2.3), and, fi-nally, train annotators, have them annotate refer-ring expressions?
constituents and function, andthen adjudicate the double-annotated texts into agold standard (2.4).2.1 DefinitionsWe wrote an annotation guide explaining the dif-ference between distinctive and descriptive refer-ring expressions.
We used the guide when train-ing annotators, and it was available to them whileannotating.
With limited space here we can onlygive an outline of what is contained in the guide;for full details see (Finlayson and Herva?s, 2010a).Referring Expressions We defined referringexpressions as referential noun phrases and theircoreferential expressions, e.g., ?John kissed Mary.She blushed.?.
This included referring expressionsto generics (e.g., ?Lions are fierce?
), dates, times,and numbers, as well as events if they were re-ferred to using a noun phrase.
We included in eachreferring expression all the determiners, quan-tifiers, adjectives, appositives, and prepositionalphrases that syntactically attached to that expres-sion.
When referring expressions were nested, allthe nested referring expressions were also markedseparately.Nuclei vs. Modifiers In the only previous cor-pus study of descriptive referring expressions, on1With the exception of a small amount of work, discussedin Section 4.museum labels, Cheng et al (2001) noted that de-scriptive information is often integrated into refer-ring expressions using modifiers to the head noun.To study this, and to allow our results to be moreclosely compared with Cheng?s, we had our an-notators split referring expressions into their con-stituents, portions called either nuclei or modifiers.The nuclei were the portions of the referring ex-pression that performed the ?core?
referring func-tion; the modifiers were those portions that couldbe varied, syntactically speaking, independently ofthe nuclei.
Annotators then assigned a distinctiveor descriptive function to each constituent, ratherthan the referring expression as a whole.Normally, the nuclei corresponded to the headof the noun phrase.
In (1), the nucleus is the tokenking, which we have here surrounded with squarebrackets.
The modifiers, surrounded by parenthe-ses, are The and old.
(1) (The) (old) [king] was wise.Phrasal modifiers were marked as single modi-fiers, for example, in (2).
(2) (The) [roof] (of the house) collapsed.It is significant that we had our annotators markand tag the nuclei of referring expressions.
Chengand colleagues only mentioned the possibility thatadditional information could be introduced in themodifiers.
However, O?Donnell et al (1998) ob-served that often the choice of head noun can alsoinfluence the function of a referring expression.Consider (3), in which the word villain is used torefer to the King.The King assumed the throne today.
(3)I don?t trust (that) [villain] one bit.The speaker could have merely used him to re-fer to the King?the choice of that particular headnoun villain gives us additional information aboutthe disposition of the speaker.
Thus villain is de-scriptive.Function: Distinctive vs. Descriptive As al-ready noted, instead of tagging the whole re-ferring expression, annotators tagged each con-stituent (nuclei and modifiers) as distinctive or de-scriptive.The two main tests for determining descriptive-ness were (a) if presence of the constituent wasunnecessary for identifying the referent, or (b) if50the constituent was expressed using unusual or os-tentatious word choice.
If either was true, the con-stituent was considered descriptive; otherwise, itwas tagged as distinctive.
In cases where the con-stituent was completely irrelevant to identifyingthe referent, it was tagged as descriptive.
For ex-ample, in the folktale The Princess and the Pea,from which (1) was extracted, there is only oneking in the entire story.
Thus, in that story, theking is sufficient for identification, and thereforethe modifier old is descriptive.
This points out theimportance of context in determining distinctive-ness or descriptiveness; if there had been a room-ful of kings, the tags on those modifiers wouldhave been reversed.There is some question as to whether copularpredicates, such as the plumber in (4), are actuallyreferring expressions.
(4) John is the plumberOur annotators marked and tagged these construc-tions as normal referring expressions, but theyadded an additional flag to identify them as cop-ular predicates.
We then excluded these construc-tions from our final analysis.
Note that copularpredicates were treated differently from apposi-tives: in appositives the predicate was included inthe referring expression, and in most cases (again,depending on context) was marked descriptive(e.g., John, the plumber, slept.
).2.2 Text SelectionOur corpus comprised 62 texts, all originally writ-ten in English, from two different genres, newsand folktales.
We began with 30 folktales of dif-ferent sizes, totaling 12,050 words.
These textswere used in a previous work on the influence ofdialogues on anaphora resolution algorithms (Ag-garwal et al, 2009); they were assembled with aneye toward including different styles, different au-thors, and different time periods.
Following this,we matched, approximately, the number of wordsin the folktales by selecting 32 texts from WallStreet Journal section of the Penn Treebank (Mar-cus et al, 1993).
These texts were selected at ran-dom from the first 200 texts in the corpus.2.3 The Story WorkbenchWe used the Story Workbench application (Fin-layson, 2008) to actually perform the annotation.The Story Workbench is a semantic annotationprogram that, among other things, includes theability to annotate referring expressions and coref-erential relationships.
We added the ability to an-notate nuclei, modifiers, and their functions bywriting a workbench ?plugin?
in Java that couldbe installed in the application.The Story Workbench is not yet available to thepublic at large, being in a limited distribution betatesting phase.
The developers plan to release it asfree software within the next year.
At that time,we also plan to release our plugin as free, down-loadable software.2.4 Annotation & AdjudicationThe main task of the study was the annotation ofthe constituents of each referring expression, aswell as the function (distinctive or descriptive) ofeach constituent.
The system generated a first passof constituent analysis, but did not mark functions.We hired two native English annotators, neither ofwhom had any linguistics background, who cor-rected these automatically-generated constituentanalyses, and tagged each constituent as descrip-tive or distinctive.
Every text was annotated byboth annotators.
Adjudication of the differenceswas conducted by discussion between the two an-notators; the second author moderated these dis-cussions and settled irreconcilable disagreements.We followed a ?train-as-you-go?
paradigm, wherethere was no distinct training period, but ratheradjudication proceeded in step with annotation,and annotators received feedback during those ses-sions.We calculated two measures of inter-annotatoragreement: a kappa statistic and an f-measure,shown in Table 1.
All of our f-measures indicatedthat annotators agreed almost perfectly on the lo-cation of referring expressions and their break-down into constituents.
These agreement calcu-lations were performed on the annotators?
originalcorrected texts.All the kappa statistics were calculated for twotags (nuclei vs. modifier for the constituents, anddistinctive vs. descriptive for the functions) overboth each token assigned to a nucleus or modifierand each referring expression pair.
Our kappas in-dicate moderate to good agreement, especially forthe folktales.
These results are expected becauseof the inherent subjectivity of language.
Duringthe adjudication sessions it became clear that dif-ferent people do not consider the same information51as obvious or descriptive for the same concepts,and even the contexts deduced by each annotatorsfrom the texts were sometimes substantially dif-ferent.Tales Articles TotalRef.
Exp.
(F1) 1.00 0.99 0.99Constituents (F1) 0.99 0.98 0.98Nuc./Mod.
(?)
0.97 0.95 0.96Const.
Func.
(?)
0.61 0.48 0.54Ref.
Exp.
Func.
(?)
0.65 0.54 0.59Table 1: Inter-annotator agreement measures3 ResultsTable 2 lists the primary results of the study.
Weconsidered a referring expression descriptive ifany of its constituents were descriptive.
Thus,18% of the referring expressions in the corpusadded additional information beyond what was re-quired to unambiguously identify their referent.The results were similar in both genres.Tales Articles TotalTexts 30 32 62Words 12,050 12,372 24,422Sentences 904 571 1,475Ref.
Exp.
3,681 3,526 7,207Dist.
Ref.
Exp.
3,057 2,830 5,887Desc.
Ref.
Exp.
609 672 1,281% Dist.
Ref.
83% 81% 82%% Desc.
Ref.
17% 19% 18%Table 2: Primary results.Table 3 contains the percentages of descriptiveand distinctive tags broken down by constituent.Like Cheng?s results, our analysis shows that de-scriptive referring expressions make up a signif-icant fraction of all referring expressions.
Al-though Cheng did not examine nuclei, our resultsshow that the use of descriptive nuclei is small butnot negligible.4 Relation to the FieldResearchers working on generating referring ex-pressions typically acknowledge that referring ex-pressions can perform functions other than distinc-tion.
Despite this widespread acknowledgment,researchers have, for the most part, explicitly ig-nored these functions.
Exceptions to this trendTales Articles TotalNuclei 3,666 3,502 7,168Max.
Nuc/Ref 1 1 1Dist.
Nuc.
95% 97% 96%Desc.
Nuc.
5% 3% 4%Modifiers 2,277 3,627 5,904Avg.
Mod/Ref 0.6 1.0 0.8Max.
Mod/Ref 4 6 6Dist.
Mod.
78% 81% 80%Desc.
Mod.
22% 19% 20%Table 3: Breakdown of Constituent Tagsare three.
First is the general study of aggregationin the process of referring expression generation.Second and third are corpus studies by Cheng et al(2001) and Jordan (2000a) that bear on the preva-lence of descriptive referring expressions.The NLG subtask of aggregation can be usedto imbue referring expressions with a descriptivefunction (Reiter and Dale, 2000, ?5.3).
There is aspecific kind of aggregation called embedding thatmoves information from one clause to another in-side the structure of a separate noun phrase.
Thistype of aggregation can be used to transform twosentences such as ?The princess lived in a castle.She was pretty?
into ?The pretty princess lived ina castle?.
The adjective pretty, previously a cop-ular predicate, becomes a descriptive modifier ofthe reference to the princess, making the secondtext more natural and fluent.
This kind of ag-gregation is widely used by humans for makingthe discourse more compact and efficient.
In or-der to create NLG systems with this ability, wemust take into account the caveat, noted by Cheng(1998), that any non-distinctive information in areferring expression must not lead to confusionabout the distinctive function of the referring ex-pression.
This is by no means a trivial problem?
this sort of aggregation interferes with refer-ring and coherence planning at both a local andglobal level (Cheng and Mellish, 2000; Cheng etal., 2001).
It is clear, from the current state of theart of NLG, that we have not yet obtained a deepenough understanding of aggregation to enable usto handle these interactions.
More research on thetopic is needed.Two previous corpus studies have looked atthe use of descriptive referring expressions.
Thefirst showed explicitly that people craft descrip-tive referring expressions to accomplish different52goals.
Jordan and colleagues (Jordan, 2000b; Jor-dan, 2000a) examined the use of referring expres-sions using the COCONUT corpus (Eugenio etal., 1998).
They tested how domain and discoursegoals can influence the content of non-pronominalreferring expressions in a dialogue context, check-ing whether or not a subject?s goals led them to in-clude non-referring information in a referring ex-pression.
Their results are intriguing because theypoint toward heretofore unexamined constraints,utilities and expectations (possibly genre- or style-dependent) that may underlie the use of descriptiveinformation to perform different functions, and arenot yet captured by aggregation modules in partic-ular or NLG systems in general.In the other corpus study, which partially in-spired this work, Cheng and colleagues analyzeda set of museum descriptions, the GNOME cor-pus (Poesio, 2004), for the pragmatic functions ofreferring expressions.
They had three functionsin their study, in contrast to our two.
Their firstfunction (marked by their uniq tag) was equiv-alent to our distinctive function.
The other twowere specializations of our descriptive tag, wherethey differentiated between additional informationthat helped to understand the text (int), or ad-ditional information not necessary for understand-ing (attr).
Despite their annotators seeming tohave trouble distinguishing between the latter twotags, they did achieve good overall inter-annotatoragreement.
They identified 1,863 modifiers toreferring expressions in their corpus, of which47.3% fulfilled a descriptive (attr or int) func-tion.
This is supportive of our main assertion,namely, that descriptive referring expressions, notonly crucial for efficient and fluent text, are ac-tually a significant phenomenon.
It is interest-ing, though, that Cheng?s fraction of descriptivereferring expression was so much higher than ours(47.3% versus our 18%).
We attribute this sub-stantial difference to genre, in that Cheng stud-ied museum labels, in which the writer is space-constrained, having to pack a lot of informationinto a small label.
The issue bears further study,and perhaps will lead to insights into differencesin writing style that may be attributed to author orgenre.5 ContributionsWe make two contributions in this paper.First, we assembled, double-annotated, and ad-judicated into a gold-standard a corpus of 24,422words.
We marked all referring expressions,coreferential relations, and referring expressionconstituents, and tagged each constituent as hav-ing a descriptive or distinctive function.
We wrotean annotation guide and created software that al-lows the annotation of this information in free text.The corpus and the guide are available on-line in apermanent digital archive (Finlayson and Herva?s,2010a; Finlayson and Herva?s, 2010b).
The soft-ware will also be released in the same archivewhen the Story Workbench annotation applicationis released to the public.
This corpus will be usefulfor the automatic generation and analysis of bothdescriptive and distinctive referring expressions.Any kind of system intended to generate text ashumans do must take into account that identifica-tion is not the only function of referring expres-sions.
Many analysis applications would benefitfrom the automatic recognition of descriptive re-ferring expressions.Second, we demonstrated that descriptive refer-ring expressions comprise a substantial fraction(18%) of the referring expressions in news andnarrative.
Along with museum descriptions, stud-ied by Cheng, it seems that news and narrative aregenres where authors naturally use a large num-ber of descriptive referring expressions.
Given thatso little work has been done on descriptive refer-ring expressions, this indicates that the field wouldbe well served by focusing more attention on thisphenomenon.AcknowledgmentsThis work was supported in part by the AirForce Office of Scientific Research under grantnumber A9550-05-1-0321, as well as by theOffice of Naval Research under award numberN00014091059.
Any opinions, findings, and con-clusions or recommendations expressed in this pa-per are those of the authors and do not necessarilyreflect the views of the Office of Naval Research.This research is also partially funded the Span-ish Ministry of Education and Science (TIN2009-14659-C03-01) and Universidad Complutense deMadrid (GR58/08).
We also thank WhitmanRichards, Ozlem Uzuner, Peter Szolovits, PatrickWinston, Pablo Gerva?s, and Mark Seifter for theirhelpful comments and discussion, and thank ourannotators Saam Batmanghelidj and Geneva Trot-ter.53ReferencesAlaukik Aggarwal, Pablo Gerva?s, and Raquel Herva?s.2009.
Measuring the influence of errors induced bythe presence of dialogues in reference clustering ofnarrative text.
In Proceedings of ICON-2009: 7thInternational Conference on Natural Language Pro-cessing, India.
Macmillan Publishers.Douglas E. Appelt.
1985.
Planning English referringexpressions.
Artificial Intelligence, 26:1?33.Hua Cheng and Chris Mellish.
2000.
Capturing the in-teraction between aggregation and text planning intwo generation systems.
In INLG ?00: First interna-tional conference on Natural Language Generation2000, pages 186?193, Morristown, NJ, USA.
Asso-ciation for Computational Linguistics.Hua Cheng, Massimo Poesio, Renate Henschel, andChris Mellish.
2001.
Corpus-based np modifiergeneration.
In NAACL ?01: Second meeting ofthe North American Chapter of the Association forComputational Linguistics on Language technolo-gies 2001, pages 1?8, Morristown, NJ, USA.
Asso-ciation for Computational Linguistics.Hua Cheng.
1998.
Embedding new information intoreferring expressions.
In ACL-36: Proceedings ofthe 36th Annual Meeting of the Association for Com-putational Linguistics and 17th International Con-ference on Computational Linguistics, pages 1478?1480, Morristown, NJ, USA.
Association for Com-putational Linguistics.Barbara Di Eugenio, Johanna D. Moore, Pamela W.Jordan, and Richmond H. Thomason.
1998.
Anempirical investigation of proposals in collabora-tive dialogues.
In Proceedings of the 17th inter-national conference on Computational linguistics,pages 325?329, Morristown, NJ, USA.
Associationfor Computational Linguistics.Mark A. Finlayson and Raquel Herva?s.
2010a.
Anno-tation guide for the UCM/MIT indications, referringexpressions, and coreference corpus (UMIREC cor-pus).
Technical Report MIT-CSAIL-TR-2010-025,MIT Computer Science and Artificial IntelligenceLaboratory.
http://hdl.handle.net/1721.1/54765.Mark A. Finlayson and Raquel Herva?s.
2010b.UCM/MIT indications, referring expres-sions, and coreference corpus (UMIRECcorpus).
Work product, MIT Computer Sci-ence and Artificial Intelligence Laboratory.http://hdl.handle.net/1721.1/54766.Mark A. Finlayson.
2008.
Collecting semantics inthe wild: The Story Workbench.
In Proceedings ofthe AAAI Fall Symposium on Naturally-Inspired Ar-tificial Intelligence, pages 46?53, Menlo Park, CA,USA.
AAAI Press.Albert Gatt, Anja Belz, and Eric Kow.
2009.
TheTUNA-REG challenge 2009: overview and evalu-ation results.
In ENLG ?09: Proceedings of the 12thEuropean Workshop on Natural Language Genera-tion, pages 174?182, Morristown, NJ, USA.
Associ-ation for Computational Linguistics.Pamela W. Jordan.
2000a.
Can nominal expressionsachieve multiple goals?
: an empirical study.
In ACL?00: Proceedings of the 38th Annual Meeting on As-sociation for Computational Linguistics, pages 142?149, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Pamela W. Jordan.
2000b.
Influences on attribute se-lection in redescriptions: A corpus study.
In Pro-ceedings of CogSci2000, pages 250?255.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: the penn treebank.
Compu-tational Linguistics, 19(2):313?330.Michael O?Donnell, Hua Cheng, and Janet Hitze-man.
1998.
Integrating referring and informing inNP planning.
In Proceedings of COLING-ACL?98Workshop on the Computational Treatment of Nom-inals, pages 46?56.Massimo Poesio.
2004.
Discourse annotation andsemantic annotation in the GNOME corpus.
InDiscAnnotation ?04: Proceedings of the 2004 ACLWorkshop on Discourse Annotation, pages 72?79,Morristown, NJ, USA.
Association for Computa-tional Linguistics.Ehud Reiter and Robert Dale.
1992.
A fast algorithmfor the generation of referring expressions.
In Pro-ceedings of the 14th conference on Computationallinguistics, Nantes, France.Ehud Reiter and Robert Dale.
2000.
Building NaturalLanguage Generation Systems.
Cambridge Univer-sity Press.Kees van Deemter, Ielka van der Sluis, and Albert Gatt.2006.
Building a semantically transparent corpusfor the generation of referring expressions.
In Pro-ceedings of the 4th International Conference on Nat-ural Language Generation (Special Session on DataSharing and Evaluation), INLG-06.Jette Viethen and Robert Dale.
2008.
The use of spa-tial relations in referring expressions.
In Proceed-ings of the 5th International Conference on NaturalLanguage Generation.54
