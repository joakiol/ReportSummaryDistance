Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 771?776,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsExploiting Qualitative Information from Automatic Word Alignmentfor Cross-lingual NLP TasksJose?
G.C.
de SouzaFBK-irst,University of TrentoTrento, Italydesouza@fbk.euMiquel Espla`-GomisUniversitat d?AlacantAlacant, Spainmespla@dlsi.ua.esMarco TurchiFBK-irstTrento, Italyturchi@fbk.euMatteo NegriFBK-irstTrento, Italynegri@fbk.euAbstractThe use of automatic word alignment tocapture sentence-level semantic relationsis common to a number of cross-lingualNLP applications.
Despite its provedusefulness, however, word alignment in-formation is typically considered from aquantitative point of view (e.g.
the numberof alignments), disregarding qualitativeaspects (the importance of aligned terms).In this paper we demonstrate that integrat-ing qualitative information can bring sig-nificant performance improvements withnegligible impact on system complexity.Focusing on the cross-lingual textual en-tailment task, we contribute with a novelmethod that: i) significantly outperformsthe state of the art, and ii) is portable, withlimited loss in performance, to languagepairs where training data are not available.1 IntroductionMeaning representation, comparison and projec-tion across sentences are major challenges for avariety of cross-lingual applications.
So far, de-spite the relevance of the problem, research onmultilingual applications has either circumventedthe issue, or proposed partial solutions.When possible, the typical approach builds onthe reduction to a monolingual task, burdening theprocess with dependencies from machine transla-tion (MT) components.
For instance, in cross-lingual question answering and cross-lingual tex-tual entailment (CLTE), intermediate MT stepsare respectively performed to ease answer re-trieval/presentation (Parton, 2012; Tanev et al2006) and semantic inference (Mehdad et al2010).
Direct solutions that avoid such pivot-ing strategies typically exploit similarity measuresthat rely on bag-of-words representations.
As anexample, most supervised approaches to MT qual-ity estimation (Blatz et al 2003; Callison-Burchet al 2012) and CLTE (Wa?schle and Fendrich,2012) include features that consider the amount ofequivalent terms that are found in the input sen-tence pairs.
Such simplification, however, disre-gards the fact that semantic equivalence is not onlyproportional to the number of equivalent terms,but also to their importance.
In other words, in-stead of checking what of a given sentence can befound in the other, current approaches limit theanalysis to the amount of lexical elements theyshare, under the rough assumption that the morethe better.In this paper we argue that:(1) Considering qualitative aspects of word align-ments to identify sentence-level semantic relationscan bring significant performance improvementsin cross-lingual NLP tasks.
(2) Shallow linguistic processing techniques (of-ten a constraint in real cross-lingual scenarios dueto limited resources availability) can be leveragedto set up portable solutions that still outperformcurrent bag-of-words methods.To support our claims we experiment with theCLTE task, which allows us to perform exhaus-tive comparative experiments due to the availabil-ity of comparable benchmarks for different lan-guage pairs.
In the remainder of the paper, we:(1) Prove the effectiveness of our method overdatasets for four language combinations;(2) Assess the portability of our models across lan-guages in different testing conditions.2 Objectives and MethodWe propose a supervised learning approach foridentifying and classifying semantic relations be-tween two sentences T1 and T2 written in differentlanguages.
Beyond semantic equivalence, whichis relevant to applications such as MT quality es-771(a) (c)(b)Word alignmentmodel for L1-L2Parallel datafor L1-L2UnlabeledCLTE datafor L1-L2Word alignmentalgorithmCLTEannotationLearningalgorithmCLTE modelfor L1-L2LabeledCLTE datafor L1-L2Word alignmentmodel for L3-L4Parallel datafor L3-L4UnlabeledCLTE datafor L3-L4Word alignmentalgorithmCLTEannotationCLTE modelfor L1-L2Word alignmentmodel for L3-L4Parallel datafor L3-L4UnlabeledCLTE datafor L3-L4Word alignmentalgorithmCLTEannotationCLTE modelfor L1-L2CLTE modelfor L5-L6CLTE modelfor L7-L8CombinationFigure 1: System architecture in different training/evaluation conditions.
(a): parallel data and CLTElabeled data are available for language pair L1-L2.
(b): the L1-L2 CLTE model is used to cope with theunavailability of labeled data for L3-L4.
(c): the same problem is tackled by combining multiple models.timation (Mehdad et al 2012b),1 we aim to cap-ture a richer set of relations potentially relevant toother tasks.
For instance, recognizing unrelated-ness, forward and backward entailment relations,represents a core problem in cross-lingual docu-ment summarization (Lenci et al 2002) and con-tent synchronization (Monz et al 2011; Mehdadet al 2012a).
CLTE, as proposed within the Se-mEval evaluation exercises (Negri et al 2012;Negri et al 2013), represents an ideal frameworkto evaluate such capabilities.
Within this frame-work, our goal is to automatically identify the fol-lowing entailment relations between T1 and T2:forward (T1 ?
T2), backward (T1 ?
T2), bidi-rectional (T1 ?
T2) and no entailment.Our approach (see Figure 1) involves two corecomponents: i) a word alignment model, and ii) aCLTE classifier.
The former is trained on a par-allel corpus, and associates equivalent terms in T1and T2.
The information about word alignmentsis used to extract quantitative (amount and dis-tribution of the alignments) and qualitative fea-tures (importance of the aligned terms) to train theCLTE classifier.
Although in principle both com-ponents need training data (respectively a paral-lel corpus and labeled CLTE data), our goal is todevelop a method that is also portable across lan-guages.
To this aim, while the parallel corpus isnecessary to train the word aligner for any lan-guage pair we want to deal with, the CLTE clas-1A translation has to be semantically equivalent to thesource sentence.sifier can be designed to learn from features thatcapture language independent knowledge.2 Thisallows us to experiment in different testing con-ditions, namely: i) when CLTE training data areavailable for a given language pair (Figure 1a),and ii) when CLTE training data are missing, anda model trained on other language pairs has to bereused (Figure 1b-c).Features.
Considering word alignment informa-tion, we extract three different groups of features:AL, POS, and IDF.The AL group provides quantitative informa-tion about the aligned/unaligned words in eachsentence T?
of the pair.
These features are:1. proportion of aligned words in T?.
We usethis indicator as our baseline (B henceforth);2. number of sequences of unaligned words,normalized by the length of T?;3.
length of the longest a) sequence of alignedwords, and b) sequence of unaligned words,both normalized by the length of T?;4.
average length of a) the aligned word se-quences, and b) the unaligned word se-quences;5. position of a) the first unaligned word, andb) the last unaligned word, both normalizedby the lenght of T?;6.
proportion of word n-grams in T?
contain-ing only aligned words (the feature was com-2For instance, the fact that aligning all nouns and the mostrelevant terms in T1 and T2 is a good indicator of semanticequivalence.772puted separately for values of n = 1 .
.
.
5).The POS group considers the part of speech(PoS) of the words in T?
as a source of qualitativeinformation about their importance.
To computethese features we use the TreeTagger (Schmid,1995), manually mapping the fine-grained set ofassigned PoS labels into a more general set of tags(P ) based on the universal PoS tag set by Petrovet al(2012).
POS features differentiate betweenaligned words (words in T1 that are aligned to oneor more words in T2) and alignments (the edgesconnecting words in T1 and T2).
Features consid-ering the aligned words in T?
are:7. for each PoS tag p ?
P , proportion of alignedwords in T?
tagged with p;8. proportion of words in T1 aligned with wordswith the same PoS tag in T2 (and vice-versa);9. for each PoS tag p ?
P , proportion of wordsin T1 tagged as p which are aligned to wordswith the same tag in T2 (and vice-versa).Features considering the alignments are:10. proportion of alignments connecting wordswith the same PoS tag p;11. for each PoS tag p ?
P , proportion of align-ments connecting two words tagged as p.IDF, the last feature, uses the inverse docu-ment frequency (Salton and Buckley, 1988) as an-other source of qualitative information under theassumption that rare words (and, therefore, withhigher IDF) are more informative:12. summation of all the IDF scores of thealigned words in T?
over the summation ofthe IDF scores of all words in T?.3 ExperimentsOur experiments cover two different scenarios.First, the typical one, in which the CLTE modelis trained on labeled data for the same pair of lan-guages L1?L2 of the test set.
Then, simulatingthe less favorable situation in which labeled train-ing data for L1?L2 are missing, we investigate thepossibility to use existing CLTE models trained onlabeled data for a different language pair L3?L4.The SemEval 2012 CLTE datasets used in ourexperiments are available for four language pairs:Es?En, De?En, Fr?En, and It?En.
Each datasetwas created with the crowdsourcing-based methoddescribed in Negri et al(2011), and consists of1000 T1?T2 pairs (500 for training, 500 for test).To train the word alignment models we usedthe Europarl parallel corpus (Koehn, 2005), con-catenated with the News Commentary corpus3for three language pairs: De?En (2,079,049sentences), Es?En (2,123,036 sentences), Fr?En(2,144,820 sentences).
For It?En we only usedthe parallel data available in Europarl (1,909,115sentences) since this language pair is not coveredby the News Commentary corpus.
IDF values forthe words in each language were calculated on themonolingual part of these corpora, using the aver-age IDF value of each language for unseen terms.To build the word alignment models we used theMGIZA++ package (Gao and Vogel, 2008).
Ex-periments have been carried out with the hiddenMarkov model (HMM) (Vogel et al 1996) andIBM models 3 and 4 (Brown et al 1993).4 We alsoexplored three symmetrization techniques (Koehnet al 2005): union, intersection, and grow-diag-final-and.
A greedy feature selection process ontraining data, with different combinations of wordalignment models and symmetrization methods,indicated HMM/intersection as the best perform-ing combination.
For this reason, all our experi-ments use this setting.The SVM implementation of Weka (Hall etal., 2009) was used to build the CLTE model.5Two binary classifiers were trained to separatelycheck T1 ?
T2 and T1 ?
T2, mergingtheir output to obtain the 4-class judgments (e.g.yes/yes=bidirectional, yes/no=forward).3.1 Evaluation with CLTE training dataFigure 2 shows the accuracy obtained by the dif-ferent feature groups.6 For the sake of compari-son, state-of-the-art results achieved for each lan-guage combination at SemEval 2012 are also re-ported.
As regards Es?En (63.2% accuracy) andDe?En (55.8%), the top scores were obtained bythe system described in (Wa?schle and Fendrich,2012), where a combination of binary classifiersfor each entailment direction is trained with a mix-3http://www.statmt.org/wmt11/translation-task.html#download4Five iterations of HMM, and three iterations of IBMmodels 3 and 4 have been performed on the training corpora.5The polynomial kernel was used with parameters empir-ically estimated on the training set (C = 2.0, and d = 1)6In Figures 2 and 3, the ?*?
indicates statistically signif-icant improvements over the state of the art at p ?
0.05,calculated with approximate randomization (Pado?, 2006).773ture of monolingual (i.e.
with the input sentencestranslated in the same language using GoogleTranslate7) and cross-lingual features.
Althoughsuch system exploits word-alignment informationto some extent, this is only done at quantitativelevel (e.g.
number of unaligned words, percentageof aligned words, length of the longest unalignedsubsequence).
As regards It?En, the state of theart (56.6%) is represented by the system describedin (Jimenez et al 2012), which uses a pure pivot-ing method (using Google Translate) and adaptivesimilarity functions based on ?soft?
cardinality forflexible term comparisons.
The two systems ob-tained the same result on Fr?En (57.0%).505560657075Es-En De-En Fr-En It-EnAccuracy (%) ** * * * * **state-of-the-artBB+ALB+AL+IDFB+AL+POSB+AL+IDF+POSFigure 2: Accuracy obtained by each featuregroup on four language combinations.As can be seen in Figure 2, the combination ofall our features outperforms the state of the artfor each language pair.
The accuracy improve-ment ranges from 6.6% for Es?En (from 63.2% to67.4%) to 14.6% for De?En (from 55.8% to 64%).Except for Es?En, that has very competitive state-of-the-art results, the combination of AL with POSor IDF feature groups always outperforms the bestsystems.
Furthermore, the performance increasewith qualitative features (POS and IDF) shows co-herent trends across all language pairs.
It is worthnoting that, while we rely on a pure cross-lingualapproach, both the state-of-the-art CLTE systemsinclude features from the translation of T1 into thelanguage of T2.
For De?En, quantitative featuresalone achieve lower results compared to the otherlanguages.
This can be motivated by the higherdifficulty in aligning De?En pairs (this hypothesisis supported by the fact that the average numberof alignments per sentence pair is 18 for De?En,and >22 for the other combinations).
Neverthe-less, qualitative features lead to results comparable7http://translate.google.com/with the other language pairs.The selection of the best performing featuresfor each language pair produces further improve-ments of varying degrees in Es?En (from 67.4%to 68%), De?En (64% ?
64.8%) and It?En (63.4%?
66.8%), while performance remains stable forFr?En (63%).
All these configurations includethe IDF feature (12) and the proportion of alignedwords for each PoS category (7), proving the ef-fectiveness of qualitative word alignment features.The fact that HMM/intersection is the best com-bination of alignment model and symmetrizationmethod is interesting, since it contradicts the gen-eral notion that IBM models 3 and 4 perform bet-ter than HMM (Och and Ney, 2003).
A possibleexplanation is that, while word alignment modelsare usually trained on parallel corpora, the major-ity of CLTE sentence pairs are not parallel.
Inthis setting, where producing reliable alignmentsis more difficult, IBM models are less effective forat least two reasons.
First, including a word fertil-ity model, IBM 3 and 4 limit (typically to the halfof the source sentence length) the number of tar-get words that can be aligned with the null word.Therefore, when such limit is reached, these mod-els tend to force low probability, hence less reli-able, word alignments.
Second, in IBM model 4,the larger distortion limit makes it possible to aligndistant words.
In the case of non-parallel sen-tences, this often results in wrong or noisy align-ments that affect final results.
For these reasons,CLTE data seem more suitable for the simpler andmore conservative HMM model, and a precision-oriented symmetrization method like intersection.3.2 Evaluation without CLTE training dataThe goal of our second round of experiments is toinvestigate if, and to what extent, our approach canbe considered as language-independent.
Confirm-ing this would allow to reuse models trained fora given language pair in situations where CLTEtraining data is missing.
This is a rather realisticsituation since, while bitexts to train word alignersare easier to find, the availability of labeled CLTEdata is far from being guaranteed.Our experiments have been carried out, over thesame SemEval datasets, with two methods that donot use labeled data for the target language com-bination.
The first one (method b in Figure 1)uses a CLTE model trained for a language pairL1?L2 for which labeled training data are avail-774able, and applies this model to a language pairL3?L4 for which only parallel corpora are avail-able.
The second method (c in Figure 1) addressesthe same problem, but exploits a combination ofCLTE models trained for different language pairs.For each test set, the models trained for the otherthree language pairs are used in a voting scheme,in order to check whether they can complementeach other to increase final results.All the experiments have been performed usingthe best CLTE model for each language pair, com-paring results with those presented in Section 3.1.5055606570758085Es-En De-En Fr-En It-EnAccuracy (%) full sys.fullsys.fullsys.
fullsys.
***** * *state-of-the-artEs-EnDe-EnFr-EnIt-EnVotingFigure 3: Accuracy obtained by reusing CLTEmodels (alone and in a voting scheme).As shown in Figure 3, reusing models for a newlanguage pair leads to results that still outperformthe state of the art.6 Remarkably, when used forother language combinations, the Es?En, It?En,and Fr?En models always lead to results above,or equal to the state of the art.
For similar lan-guages such as Spanish, French, and Italian, theaccuracy increase over the state of the art is up to14.8% (from 56.6% to 65.0%) and 13.4% (from56.6% to 64.2%) when the Fr?En and Es?En mod-els are respectively used to label the It?En dataset.Although not always statistically significant andbelow the performance obtained in the ideal sce-nario where CLTE training data are available (fullsys.
), such improvements suggest that our featurescan be re-used, at least to some extent, across dif-ferent language settings.
As expected, the majorincompatibilities arise between German and theother languages due to the linguistic differencesbetween this language and the others.
However, itis interesting to note that: i) at least in one case(i.e.
when tested on It?En) the De?En model stillachieves results above the state of the art, and ii)on the De?En evaluation setting the worst model(Fr?En) still achieves state of the art results.The results obtained with the voting schemesuggest that our models can complement eachother when used on a new language pair.
Althoughstatistically significant only over It?En data, vot-ing results both outperform the state of the art andthe results achieved by single models.4 ConclusionWe investigated the usefulness of qualitative infor-mation from automatic word alignment to iden-tify semantic relations between sentences in dif-ferent languages.
With coherent results in CLTE,we demonstrated that features considering the im-portance of aligned terms can successfully inte-grate the quantitative evidence (number and pro-portion of aligned terms) used by previous su-pervised learning approaches.
A study on theportability across languages of the learned mod-els demonstrated that word alignment informationcan be exploited to train reusable models for newlanguage combinations where bitexts are availablebut CLTE labeled data are not.AcknowledgmentsThis work has been partially supported by the EC-funded projects CoSyne (FP7-ICT-4-248531) andMateCat (ICT-2011.4.2?287688), and by Span-ish Government through projects TIN2009-14009-C02-01 and TIN2012-32615.ReferencesJohn Blatz, Erin Fitzgerald, George Foster, SimonaGandrabur, Cyril Goutte, Alex Kulesza, AlbertoSanchis, and Nicola Ueffing.
2003.
Confidence Es-timation for Machine Translation.
Summer work-shop final report, JHU/CLSP.Peter F. Brown, Stephen A. Della Pietra, VincentJ.
Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation: Pa-rameter Estimation.
Computational Linguistics,19(2):263?311.Chris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 workshop on statistical ma-chine translation.
In Proceedings of the Sev-enth Workshop on Statistical Machine Translation(WMT?12), pages 10?51, Montre?al, Canada.Qin Gao and Stephan Vogel.
2008.
Parallel Implemen-tations of Word Alignment Tool.
In Software En-gineering, Testing, and Quality Assurance for Natu-ral Language Processing, pages 49?57, Columbus,Ohio, USA.775Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: an Up-date.
SIGKDD Explorations, 11(1):10?18.Sergio Jimenez, Claudia Becerra, and Alexander Gel-bukh.
2012.
Soft Cardinality + ML: Learning Adap-tive Similarity Functions for Cross-lingual TextualEntailment.
In Proceedings of the 6th InternationalWorkshop on Semantic Evaluation (SemEval 2012),pages 684?688, Montre?al, Canada.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne, andDavid Talbot.
2005.
Edinburgh System Descrip-tion for the 2005 IWSLT Speech Translation Evalu-ation.
In Proceedings of the International Workshopon Spoken Language Translation, Pittsburgh, Penn-sylvania, USA.Philip Koehn.
2005.
Europarl: a Parallel Corpus forStatistical Machine Translation.
In Proceedings ofMT Summit X, pages 79?86, Phuket, Thailand.Alessandro Lenci, Roberto Bartolini, Nicoletta Cal-zolari, Ana Agua, Stephan Busemann, EmmanuelCartier, Karine Chevreau, and Jose?
Coch.
2002.Multilingual summarization by integrating linguisticresources in the MLIS-MUSI Project.
In Proceed-ings of the Third International Conference on Lan-guage Resources and Evaluation (LREC?02), pages1464?1471, Las Palmas de Gran Canaria, Spain.Yashar Mehdad, Matteo Negri, and Marcello Federico.2010.
Towards Cross-Lingual Textual Entailment.In Proceedings of the Eleventh Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics (NAACL HLT 2010),pages 321?324, Los Angeles, California, USA.Yashar Mehdad, Matteo Negri, and Marcello Federico.2012a.
Detecting Semantic Equivalence and Infor-mation Disparity in Cross?lingual Documents.
InProceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics (ACL?12),pages 120?124, Jeju Island, Korea.Yashar Mehdad, Matteo Negri, and Marcello Fed-erico.
2012b.
Match without a Referee: EvaluatingMT Adequacy without Reference Translations.
InProceedings of the Machine Translation Workshop(WMT2012), Montre?al, Canada.Christoph Monz, Vivi Nastase, Matteo Negri, AngelaFahrni, Yashar Mehdad, and Michael Strube.
2011.CoSyne: a Framework for Multilingual ContentSynchronization of Wikis.
In Proceedings of Wik-iSym 2011, the International Symposium on Wikisand Open Collaboration, pages 217?218, MountainView, California, USA.Matteo Negri, Luisa Bentivogli, Yashar Mehdad,Danilo Giampiccolo, and Alessandro Marchetti.2011.
Divide and Conquer: Crowdsourcing the Cre-ation of Cross-Lingual Textual Entailment Corpora.In Proceedings of the 2011 Conference on EmpiricalMethods in Natural Language Processing (EMNLP2011), Edinburgh, Scotland.Matteo Negri, Alessandro Marchetti, Yashar Mehdad,Luisa Bentivogli, and Danilo Giampiccolo.
2012.Semeval-2012 Task 8: Cross-Lingual Textual En-tailment for Content Synchronization.
In Proceed-ings of the 6th International Workshop on Seman-tic Evaluation (SemEval 2012), pages 399?407,Montre?al, Canada.Matteo Negri, Alessandro Marchetti, Yashar Mehdad,Luisa Bentivogli, and Danilo Giampiccolo.
2013.Semeval-2013 Task 8: Cross-Lingual Textual En-tailment for Content Synchronization.
In Proceed-ings of the 7th International Workshop on SemanticEvaluation (SemEval 2013), Atlanta, GA.Franz J. Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Mod-els.
Computational Linguistics, 29(1):19?51.Sebastian Pado?, 2006.
User?s guide to sigf: Signifi-cance testing by approximate randomisation.Kristen Parton.
2012.
Lost and Found in Transla-tion: Cross-Lingual Question Answering with ResultTranslation.
Ph.D. thesis, Columbia University.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proceedingsof the Eight International Conference on LanguageResources and Evaluation (LREC?12), pages 2089?2096, Istanbul, Turkey.Gerard Salton and Christopher Buckley.
1988.Term-weighting Approaches in Automatic Text Re-trieval.
Information Processing and Management,24(5):513?523.Helmut Schmid.
1995.
Improvements in Part-of-Speech Tagging with an Application to German.
InProceedings of the ACL SIGDAT-Workshop, pages47?50, Dublin, Ireland.Hristo Tanev, Milen Kouylekov, Bernardo Magnini,Matteo Negri, and Kiril Simov.
2006.
Exploit-ing Linguistic Indices and Syntactic Structures forMultilingual Question Answering: ITC-irst at CLEF2005.
Accessing Multilingual Information Reposito-ries, pages 390?399.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based Word Alignment in Statisti-cal Translation.
In Proceedings of the 16th Inter-national Conference on Computational Linguistics(ACL?96), pages 836?841, Copenhagen, Denmark.Katharina Wa?schle and Sascha Fendrich.
2012.
HDU:Cross-lingual Textual Entailment with SMT Fea-tures.
In Proceedings of the 6th International Work-shop on Semantic Evaluation (SemEval 2012), pages467?471, Montre?al, Canada.776
