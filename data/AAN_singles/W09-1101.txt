Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), page 1,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsJoint Inference for Natural Language ProcessingAndrew McCallumDepartment of Computer ScienceUniversity of Massachusetts AmherstAmherst, MA 01002mccallum@cs.umass.eduAbstract of the Invited TalkIn recent decades, researchers in natural languageprocessing have made great progress on well-defined subproblems such as part-of-speech tagging,phrase chunking, syntactic parsing, named-entityrecognition, coreference and semantic-role label-ing.
Better models, features, and learning algorithmshave allowed systems to perform many of these taskswith 90% accuracy or better.
However, success in in-tegrated, end-to-end natural language understandingremains elusive.I contend that the chief reason for this failureis that errors cascade and accumulate through apipeline of naively chained components.
For exam-ple, if we naively use the single most likely outputof a part-of-speech tagger as the input to a syntacticparser, and those parse trees as the input to a coref-erence system, and so on, errors in each step willpropagate to later ones: each components 90% ac-curacy multiplied through six components becomesonly 53%.Consider, for instance, the sentence ?I know youlike your mother.?
If a part-of-speech tagger de-terministically labels ?like?
as a verb, then certainlater syntactic and semantic analysis will be blockedfrom alternative interpretations, such as ?I know youlike your mother (does).?
The part-of-speech tag-ger needs more syntactic and semantic informationto make this choice.
Consider also the classic exam-ple ?The boy saw the man with the telescope.?
Nosingle correct syntactic parse of this sentence is pos-sible in isolation.
Correct interpretation requires theintegration of these syntactic decisions with seman-tics and context.Humans manage and resolve ambiguity by uni-fied, simultaneous consideration of morphology,syntax, semantics, pragmatics and other contextualinformation.
In statistical modeling such unifiedconsideration is known as joint inference.
The needfor joint inference appears not only in natural lan-guage processing, but also in information integra-tion, computer vision, robotics and elsewhere.
All ofthese applications require integrating evidence frommultiple sources, at multiple levels of abstraction.
Ibelieve that joint inference is one of the most fun-damentally central issues in all of artificial intelli-gence.In this talk I will describe work in probabilisticmodels that perform joint inference across multiplecomponents of an information processing pipelinein order to avoid the brittle accumulation of errors.I will survey work in exact inference, variationalinference and Markov-chain Monte Carlo methods.We will discuss various approaches that have beenapplied to natural language processing, and hypoth-esize about why joint inference has helped in somecases, and not in others.I will then focus on our recent work at Univer-sity of Massachusetts in large-scale conditional ran-dom fields with complex relational structure.
In asingle factor graph we seamlessly integrate multiplesubproblems, using our new probabilistic program-ming language to compactly express complex, muta-ble variable-factor structure both in first-order logicas well as in more expressive Turing-complete im-perative procedures.
We avoid unrolling this graph-ical model by using Markov-chain Monte Carlo forinference, and make inference more efficient withlearned proposal distributions.
Parameter estimationis performed by SampleRank, which avoids com-plete inference as a subroutine by learning simplyto correctly rank successive states of the Markov-chain.Joint work with Aron Culotta, Michael Wick,Rob Hall, Khashayar Rohanimanesh, Karl Schultz,Sameer Singh, Charles Sutton and David Smith.1
