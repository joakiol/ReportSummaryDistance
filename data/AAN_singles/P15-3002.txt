Proceedings of the ACL-IJCNLP 2015 Student Research Workshop, pages 8?15,Beijing, China, July 28, 2015.c?2015 Association for Computational LinguisticsLeveraging Compounds to Improve Noun Phrase Translationfrom Chinese and GermanXiao PuIdiap Research Institute1920 MartignySwitzerlandxiao.pu@idiap.chLaura MascarellInstitute of ComputationalLinguistics, U. of Zurich8050 Zurich, Switzerlandmascarell@cl.uzh.chAndrei Popescu-BelisIdiap Research Institute1920 MartignySwitzerlandapbelis@idiap.chMark FishelInstitute of ComputationalLinguistics, U. of Zurich8050 Zurich, Switzerlandfishel@cl.uzh.chNgoc-Quang LuongIdiap Research Institute1920 MartignySwitzerlandnluong@idiap.chMartin VolkInstitute of ComputationalLinguistics, U. of Zurich8050 Zurich, Switzerlandvolk@cl.uzh.chAbstractThis paper presents a method to improvethe translation of polysemous nouns, whena previous occurrence of the noun asthe head of a compound noun phrase isavailable in a text.
The occurrences areidentified through pattern matching rules,which detect XY compounds followedclosely by a potentially coreferent oc-currence of Y , such as ?Nordwand .
.
.Wand?.
Two strategies are proposed toimprove the translation of the second oc-currence of Y : re-using the cached trans-lation of Y from the XY compound, orpost-editing the translation of Y usingthe head of the translation of XY .
Ex-periments are performed on Chinese-to-English and German-to-French statisticalmachine translation, over the WIT3 andText+Berg corpora respectively, with 261XY/Y pairs each.
The results suggest thatwhile the overall BLEU scores increaseonly slightly, the translations of the tar-geted polysemous nouns are significantlyimproved.1 IntroductionWords tend to be less ambiguous when consid-ered in context, which partially explains the suc-cess of phrase-based statistical machine transla-tion (SMT) systems.
In this paper, we take ad-vantage of this observation, and extend the dis-ambiguation potential of n-grams to subsequentoccurrences of their individual components.
Weassume that the translation of a noun-noun com-pound, noted XY , displays fewer ambiguitiesthan the translations of its components X and Y .Therefore, on a subsequent occurrence of the headofXY , assumed to refer to the same entity asXY ,we hypothesize that its previously-found transla-tion offers a better and more coherent translationthan the one proposed by an SMT system that isnot aware of the compound.Our claim is supported by results from ex-periments on Chinese-to-English (ZH/EN) andGerman-to-French (DE/FR) translation presentedin this paper.
In both source languages, noun-nouncompounds are frequent, and will enable us to dis-ambiguate subsequent occurrences of their head.For instance, in the example in Figure 1, theChinese compound ???
refers to ?high heels?,and the subsequent mention of the referent usingonly the third character (?)
should be translatedas ?heels?.
However, the character ?
by itselfcould also be translated as ?shoe?
or ?footwear?, asobserved with a baseline SMT system that is notaware of the XY/Y coreference.Although the XY/Y configuration may not bevery frequent in texts, errors in its translation areparticularly detrimental to the understanding of atext, as they often conceal the coreference linkbetween two expressions.
Moreover, as we willshow, such issues can be quite reliably corrected,and the proposed approach can later generalize toother configurations of noun phrase coreference.81.
CHINESE SOURCE SENTENCE ????????????????????
???????????????????2.
SEGMENTATION, POS TAGGING, IDENTIFICATION OF COMPOUNDS AND THEIR CO-REFERENCE?#PN  ?
?#VV  ???
?#AD  ?#VV  ?#AS  ?#CD  ?#CD  ??
?#NN  ?#DEG  ???
?#NN  ?#PU ?#AD  ??
?#AD  ?#PN  ?#VC  ?
?#CD  ?#M  ?#CD  ??
?#NN  ?
?#VA  ?#DEC  ?#NN  ?#PU3.
BASELINE TRANSLATION INTO ENGLISH (STATISTICAL MT) She thought since bought a pair of two inches high heel, ?but in fact it was a pair of three inches high shoes.4.
AUTOMATIC POST-EDITING OF ?THE BASELINE TRANSLATION ?USING COMPOUNDS She thought since bought a pair of two inches high heel, ?but in fact it was a pair of three inches high heel.5.
COMPARISON WITH A HUMAN REFERENCE TRANSLATION She thought she?d gotten a two-inch heel ?but she?d actually bought a three-inch heel.
?Figure 1: Compound post-editing method illustrated on ZH/EN.
The first translation of ???
into?heel?
enables the correct translation of the subsequent occurrence of ?
as ?heel?, by post-editing thebaseline output ?shoes?.The paper is organized as follows.
In Section 2we present the main components of our proposal:first, the rules for identifying XY/Y pairs, andthen two alternative methods for improving the co-herence of the translation of a subsequent mentionY , one based on post-editing and the other onebased on caching, which builds upon initial exper-iments presented by Mascarell et al.
(2014).
InSection 3, we present our experimental setting.
InSection 4, we evaluate our proposal on ZH/EN andDE/FR translation, demonstrating that the transla-tion of nouns is indeed improved, mainly by au-tomatic or human comparisons with the referencetranslation.
We conclude with a brief discussionof related studies (Section 5) and with perspectivesfor future work (Section 6).2 Description of the Method2.1 OverviewWe propose to use the translation of a compoundXY to improve the translation of a subsequent oc-currence of Y , the head of the XY noun phrase,in the following way, represented schematically inFigure 1 (details for each stage are given below).First, the presence of XY /Y patterns is detectedeither by examining whether a compound XY isfollowed by an occurrence of Y , or, conversely,by examining for each Y candidate whether it ap-pears as part of a previous compound XY .
Dis-tance constraints and additional filtering rules areimplemented to increase the likelihood that XYand Y are actually co-referent, or at least refer toentities of the same type.Second, each sentence is translated by a base-line SMT system, and the translation of the head Yof each compoundXY is identified using the wordalignment from the SMT decoder.
This transla-tion is used as the translation of a subsequent oc-currence of Y either by caching the correspond-ing source/target word pair in the SMT or by post-editing the baseline SMT output.
For instance, ifthe Chinese pair (??,?)
is identified, where thefirst compound can unambiguously be translatedinto English by ?vegetable?, then the translation ofa subsequent occurrence of?
is enforced to ?veg-etable?.
This has the potential to improve over thebaseline translation, because when considered in-dividually, ?
could also be translated as ?dish?,?greens?, ?wild herbs?, etc.2.2 Identifying XY/Y PairsChinese and German share a number of similar-ities regarding compounds.
Although Chinesetexts are not word-segmented, once this opera-tion is performed, multi-character words in whichall characters have individual meanings ?
such asthe above-mentioned??
(?vegetable?)
?
are fre-quent.
Similarly, in German, noun-noun com-pounds such as ?Bundesamt?
(?Bund?
+ ?Amt?, forFederal Bureau) or Nordwand (?Nord?
+ ?Wand?,for North face) are frequent as well.
Whilethe identification of XY noun-noun compoundsis straightforward with morpho-syntactic analysis9tools, the identification of a subsequent mentionof the head noun, Y , and especially the decisionwhether this Y refers or not to the same entityXY , are more challenging issues.
In other words,the main difficulty is to separate true XY/Y pairsfrom false positives.To detect truly coreferent XY/Y pairs we nar-row down the set of detected cases using hand-written rules that check the local context of Y .For example, only the cases where Y is precededby demonstrative pronouns (e.g.
?
or ?
mean-ing ?this?
and ?that?
in Chinese, or ?diese?
in Ger-man), possessive pronouns and determiners (?der?,?die?, ?das?
in German) are considered.
Sinceother words can occur between the two parts (likeclassifiers in Chinese or adjectives), there are ad-ditional distance constraints: the pronoun or de-terminer must be separated by fewer than threewords.
Since the rules use morphological infor-mation and word boundaries, they are preceded byword segmentation1and tagging2for Chinese andmorphological analysis for German.3For exam-ple, in the input sentence from Figure 1, we deter-mine that the noun phrase?
fits our condition forextraction as Y because as there are words beforeit which fulfill the condition for acceptance.2.3 Enforcing the Translation of YTwo language-independent methods have been de-signed to ensure that the translations of XY andY are a consistent: post-editing and caching.
Thesecond one builds upon an earlier proposal testedonly on DE/FR with subjective evaluations (Mas-carell et al., 2014).In the post-editing method, for each XY/Ypair, the translations of XY and Y by a baselineSMT system (see Section 3) are first identifiedthrough word alignment.
We verify if the trans-lations of Y in both noun phrases are identicalor different.
Both elements comprising the com-pound structure XY/Y are identified, for the stan-dard cases, with only one possible XY referring toone Y .
The translation of both words are providedby the baseline SMT system, and our system sub-sequently verifies if the translations of Y in bothnoun phrases are identical or different.
We keepthem intact in the first case, while in the second1Using the Stanford Word Segmenter available fromhttp://nlp.stanford.edu/software/segmenter.shtml.2Using the Stanford Log-linear Part-of-speech Tagger,http://nlp.stanford.edu/software/tagger.shtml.3Using Gertwol (Koskeniemmi and Haapalainen, 1994).case we replace the translation of Y by the transla-tion of XY or by its head noun only, if it containsseveral words.
In the example in Figure 1, XYis translated into ?high heel?
and Y into ?shoes?,which is a wrong translation of ?
in this context.Using the consistency constraint, our method post-edits the translation of Y replacing it with ?heel?,which is the correct word.Several differences from the ideal case pre-sented above must be handled separately.
First, itmay occur that several XY are likely co-referentwith the same Y .
In this case, if their transla-tions differ, given that we cannot resolve the co-reference, we do not post-edit Y .4If the trans-lations of the several occurrences of XY are thesame, but consist of one word, we still do not post-edit Y .
We only change it if the translations con-sist of several words, ensuring that XY is a com-pound noun phrase.
Second, if the compound XYis not translated (out-of-vocabulary word), we donot post-edit Y .5Third, sometimes the alignmentof Y is empty in the target sentence (alignment er-ror or untranslated word), in which case we applypost-editing as above on the word preceding Y , ifit is aligned.In the caching method (Mascarell et al., 2014),once an XY compound is identified, we obtainthe translation of the Y part of the compoundthrough the word alignment given by the SMTdecoder.
Next, we check that this translation ap-pears as a translation of Y in the phrase table, andif so, we cache both Y and the obtained transla-tion.
We then enforce the cached translation everytime a coreference Y to XY is identified.
Notethat this is different from the probabilistic cachingproposed by Tiedemann (2010), because in ourcase the cached translation is deterministically en-forced as the translation of Y .3 Experimental SettingsThe experiments are carried out on two differ-ent parallel corpora: the WIT3Chinese-Englishdataset (Cettolo et al., 2012) with transcriptsof TED lectures and their translations, and theText+Berg German-French corpus (Bubenhofer etal., 2013), a collection of articles from the year-4Upon manual examination, we found that using the mostrecent XY was not a reliable candidate for the antecedent.5In fact, we can use the translation of Y as a translationcandidate for XY .
Our observations show that this helps toimprove BLEU scores, but does not affect the specific scoringof Y in Section 4.10Sentences TokensZHTraining 188?758 19?880?790Tuning 2?457 260?770Testing 855 12?344DETraining 285?877 5?194?622Tuning 1?557 32?649Testing 505 12?499Table 1: Sizes of SMT data sets.books of the Swiss Alpine Club.
The sizes of thesubsets used for training, tuning and testing theSMT systems are given in Table 1.
The test setswere constructed by selecting all the sentences orfragments which contained the XY/Y pairs, iden-tified as above, to maximize their number in thetest data, given that they are not needed in thetraining/tuning sets, as the proposed methods arenot based on machine learning.The rules for selecting coreferent XY/Y pairsin Chinese identified 261 pairs among 192k sen-tences.
The rather low rate of occurrence (aboutone every 700 sentences) is explained by the strictconditions of the selection rules, which are de-signed to maximize the likelihood of coreference.In German, less restrictive rules selected 7,365XY/Y pairs (a rate of one every 40 sentences).Still, in what follows, we randomly selected 261XY/Y pairs for the DE/FR test data, to matchtheir number in the ZH/EN test data.Our baseline SMT system is the Moses phrase-based decoder (Koehn et al., 2007), trained overtokenized and true-cased data.
The language mod-els were built using SRILM (Stolcke et al., 2011)at order 3 (i.e.
up to trigrams) using the defaultsmoothing method (i.e.
Good-Turing).
Optimiza-tion was done using Minimum Error Rate Training(Och, 2003) as provided with Moses.The effectiveness of proposed systems is mea-sured in two ways.
First, we use BLEU (Pap-ineni et al., 2002) for overall evaluation, to verifywhether our systems provide better translation forentire texts.
Then, we focus on the XY/Y pairsand count the number of cases in which the trans-lations of Y match the reference or not, which canbe computed automatically using the alignments.However, the automatic comparison of a sys-tem?s translation with the reference is not entirelyinformative, because even if the two differ, the sys-tem?s translation can still be acceptable.
There-fore, we analyzed these ?undecided?
situationsmanually, with three human annotators (among theauthors of the paper).
The annotators rated sepa-rately the system?s translations of Y and the refer-ence ones as ?good?, ?acceptable?
or ?wrong?.4 Analysis of Results4.1 Automatic Comparison with a ReferenceThe BLEU scores obtained by the baseline SMT,the caching and post-editing methods, and an or-acle system are given in Table 2.
The scores arein the same range as the baseline scores found byother teams on these datasets (Cettolo et al., 2012,Table 7 for ZH/EN), and much higher on DE/FRthan ZH/EN.Our methods have a small positive effect onZH/EN translation, and a small negative effect onDE/FR one.
Given the sparsity of XY/Y pairswith respect to the total number of words, hencethe small number of changed words, these re-sults meet our prior expectations.
Indeed, we alsocomputed the oracle BLEU scores for both lan-guage pairs, i.e.
the scores when all Y members ofXY/Y pairs are (manually) translated exactly asin the reference (last line of Table 2).
These val-ues are only slightly higher than the other scores,showing that even a perfect translation of the Ynouns would only have a small effect on BLEU.ZH/EN DE/FRBASELINE 11.18 27.65CACHING 11.23 27.26POST-EDITING 11.27 27.48ORACLE 11.30 27.80Table 2: BLEU scores of our methods.We now turn to the reference-based evaluationof the translations of Y in the 261 XY/Y pairs,comparing the baseline SMT with each of ourmethods.
These results are represented as fourcontingency tables ?
two language pairs and twomethods against the baseline ?
gathered togetheras percentages in Table 3.
Among these values,we focus first on the total of pairs where one of oursystems agrees with the reference while the base-line system does not (i.e., improvements due tothe system), and the converse case (degradations).The higher the difference between the two values,the more beneficial our method.For ZH/EN and the post-editing system, amongthe 222 extracted pairs, there were 45 improve-ments (20.3%) of the system with respect to the11CACHING POST-EDITING= ref 6= ref = ref 6= refZH/EN BASELINE= ref 59.3 4.1 42.3 4.56= ref 13.8 22.8 20.3 32.9DE/FR BASELINE= ref 70.1 10.3 73.9 5.06= ref 4.3 15.2 3.5 17.5Table 3: Comparison of each approach with the baseline, for the two language pairs, in terms of Y nounswhich are identical or different from a reference translation (?ref?).
All scores are percentages of thetotals.
Numbers in bold are improvements over the baseline, while those in italics are degradations.baseline, and only 10 degradations (4.5%).
Therewere also 94 pairs (42.3%) for which the baselineand the post-edited system were equal to the ref-erence.
The remaining 73 pairs (32.9%) will beanalyzed manually in the next section.
Therefore,from a pure reference-based view, the post-editedsystem has a net improvement of 15.8% (absolute)over the baseline in dealing with the XY/Y pairs.A similar pattern is observed with the othermethod, namely caching, again on ZH/EN trans-lation: 13.8% improvements vs. 4.1% degrada-tions.
The difference (i.e.
the net improvement)is slightly smaller in this case with respect to thepost-editing method.For DE/FR translation, both methods appearto score fewer improvements than degradations.There are more than 70% of the pairs which aretranslated correctly by the baseline and by bothsystems, which indicates that the potential for im-provement is much smaller for DE/FR than forZH/EN.While the pattern of improvement betweenZH/EN and DE/FR is similar for post-editing andfor caching, for both language pairs the post-editing method has a larger difference betweenimprovements and degradations than the cachingmethod.
This can be explained by a lower cov-erage of the latter method, since it only enforcesa translation when it appears as one of the trans-lation candidates for Y in the phrase table (Mas-carell et al., 2014).4.2 Manual Evaluation of Undecided CasesWhen both the baseline and one of our systemsgenerate translations of Y which differ from thereference, it is not possible to compare the trans-lations without having them examined by humansubjects.
This was done for the 73 such casesof the ZH/EN post-editing system.
Three of theauthors, working independently, considered eachtranslation from each system (in separate batches)with respect to the reference one, and rated itsmeaning on a 3-point scale: 2 (good), 1 (accept-able) or 0 (wrong).
To estimate the inter-rateragreement, we computed the average absolute de-viation6and found a value of 0.15, thus denotingvery good agreement.
Below, we group ?2?
and?1?
answers into one category, called ?acceptable?,and compare them to ?0?
answers, i.e.
wrong trans-lations.When both the baseline and the post-editedtranslations of Y differ from the reference, theycan either be identical (49 cases) or different (24).In the former case, of course, neither of the sys-tems outperforms the other.
The interesting obser-vation is that the relatively high number of suchcases (49) is due to situations where the referencetranslation of noun Y is by a pronoun (40), whichthe systems have currently no possibility to gen-erate from a noun in the source sentence.
Manualevaluation shows that the systems?
translations arecorrect in 36 out of 40 cases.
This large numbershows that the ?quality?
of the systems is actu-ally higher than what can be inferred from Table 3only.
Conversely, in the 9 cases when the refer-ence translation of Y is not a pronoun, only abouthalf of the translations are correct.In the latter case, when baseline and post-editedtranslations differ from the reference and amongthemselves (24 cases), it is legitimate to ask whichof the two systems is better.
Overall, 10 baselinetranslations are correct and 14 are wrong, whereas23 post-edited translations are correct (or at leastacceptable) and only one is wrong.
The post-edited system thus clearly outperforms the base-line in this case.
Similarly to the observationabove, we note that among the 24 cases consideredhere, almost all (20) involve a reference translationof Y by a pronoun.
In these cases, the baseline6Average of13?3i=1|scorei?mean| over all ratings .12system translates only about half of them with acorrect noun (9 out of 20), while the post-editedsystem translates correctly 19 out of 20.5 Related WorkWe briefly review in this section several previousstudies from which the present one has benefited.Our idea is built upon the one-sense-per-discoursehypothesis (Gale et al., 1992) and its applicationto machine translation is based on the premise thatconsistency in discourse (Carpuat, 2009) is desir-able.
The initial compound idea was first pub-lished by Mascarell et al.
(2014), in which the co-reference of compound noun phrases in German(e.g.
Nordwand/Wand) was studied and used toimprove DE/FR translation by assuming that thelast constituent of the compound Y should sharethe same translation as that of Y in XY .Several other approaches focused on enforcingconsistent lexical choice.
Tiedemann (2010) pro-posed a cache-model to enforce consistent trans-lation of phrases across the document.
How-ever, caching is sensitive to error propagation, thatis, when a phrase is incorrectly translated andcached, the model propagates the error to the fol-lowing sentences.
Gong et al.
(2011) later ex-tended Tiedemann?s proposal by initializing thecache with phrase pairs from similar documentsat the beginning of the translation and by also ap-plying a topic cache, which was introduced to dealwith the error propagation issue.
Xiao et al.
(2011)defined a three step procedure that enforces theconsistent translation of ambiguous words, achiev-ing improvements for EN/ZH.
Ture et al.
(2012)encouraged consistency for AR/EN MT by intro-ducing cross-sentence consistency features to thetranslation model, while Alexandrescu and Kirch-hoff (2009) enforced similar translations to sen-tences having a similar graph representation.Our work is an instance of a recent trend aim-ing to go beyond sentence-by-sentence MT, by us-ing semantic information from previous sentencesto constrain or correct the decoding of the cur-rent one.
In this paper, we compared caching andpost-editing as ways of achieving this goal, buta document-level decoder such as Docent (Hard-meier et al., 2012) could be used as well.
In otherstudies, factored translation models (Koehn andHoang, 2007) have been used with the same pur-pose, by incorporating contextual information intolabels used to indicate the meaning of ambiguousdiscourse connectives (Meyer and Popescu-Belis,2012) or the expected tenses of verb phrase trans-lations (Loaiciga et al., 2014).
Quite naturally,there are analogies between our work and stud-ies of pronoun translation (Le Nagard and Koehn,2010; Hardmeier and Federico, 2010; Guillou,2012), with the notable difference that pronominalanaphora resolution remains a challenging task.Finally, our work and its perspectives contributeto the general objective of using discourse-levelinformation to improve MT (Hardmeier, 2014;Meyer, 2014).6 Conclusion and PerspectivesWe presented a method to enforce the consistenttranslation of coreferences to a compound, whenthe coreference matches the head noun of the com-pound.
Experimental results showed that baselineSMT systems often translate coreferences to com-pounds consistently for DE/FR, but much less sofor ZH/EN.
For a significant number of cases inwhich the noun phrase Y had multiple meanings,our system reduced the frequency of mistransla-tions in comparison to the baseline, and improvednoun phrase translation.In this work, we considered XY/Y pairs, hy-pothesizing that when they are coreferent, theyshould have consistent translations.
In the future,we will generalize this constraint to complex nounphrases which are not compounds.
More gener-ally, we will explore the encoding of coreferenceconstraints into probabilistic models that can becombined with SMT systems, so that coreferenceconstraints are considered in the decoding process.AcknowledgmentsThe authors are grateful for the support ofthe Swiss National Science Foundation (SNSF)through the Sinergia project MODERN: Model-ing Discourse Entities and Relations for Coher-ent Machine Translation, grant nr.
CRSII2 147653(www.idiap.ch/project/modern).ReferencesAndrei Alexandrescu and Katrin Kirchhoff.
2009.Graph-based learning for statistical machine trans-lation.
In Proceedings of the Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics (NAACL), pages 119?127, Boulder, Colorado.13Noah Bubenhofer, Martin Volk, David Klaper,Manuela Weibel, and Daniel W?uest.
2013.Text+Berg-korpus (release 147 v03).
Digitale Edi-tion des Jahrbuch des SAC 1864-1923, Echo desAlpes 1872-1924 und Die Alpen 1925-2011.Marine Carpuat.
2009.
One Translation per Discourse.In Proceedings of the Workshop on Semantic Evalu-ations: Recent Achievements and Future Directions(SEW), pages 19?27, Singapore.Mauro Cettolo, Christian Girardi, and Marcello Fed-erico.
2012.
WIT3: Web inventory of transcribedand translated talks.
In Proceedings of the 16thCon-ference of the European Association for MachineTranslation (EAMT), pages 261?268, Trento, Italy.William A Gale, Kenneth W Church, and DavidYarowsky.
1992.
One sense per discourse.
In Pro-ceedings of the Workshop on Speech and NaturalLanguage, pages 233?237.Zhengxian Gong, Min Zhang, and Guodong Zhou.2011.
Cache-based document-level statistical ma-chine translation.
In Proceedings of the 2011 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 909?919, Edinburgh.Liane Guillou.
2012.
Improving pronoun translationfor statistical machine translation.
In Proceedings ofEACL 2012 Student Research Workshop (13th Con-ference of the European Chapter of the ACL), pages1?10, Avignon, France.Christian Hardmeier and Marcello Federico.
2010.Modelling Pronominal Anaphora in Statistical Ma-chine Translation.
In Proceedings of Interna-tional Workshop on Spoken Language Translation(IWSLT), Paris, France.Christian Hardmeier, Joakim Nivre, and J?org Tiede-mann.
2012.
Document-Wide Decoding for Phrase-Based Statistical Machine Translation.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing and Natural LanguageLearning (EMNLP-CoNLL), Jeju, Korea.Christian Hardmeier.
2014.
Discourse in StatisticalMachine Translation.
PhD thesis, Uppsala Univer-sity, Sweden.Philipp Koehn and Hieu Hoang.
2007.
Factoredtranslation models.
In Proceedings of the JointConference on Empirical Methods in Natural Lan-guage Processing (EMNLP) and ComputationalNatural Language Learning (CONLL), pages 868?876, Prague, Czech Republic.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbs.
2007.
Moses:Open Source Toolkit for Statistical Machine Trans-lation.
In Proceedings of 45th Annual Meeting of theAssociation for Computational Linguistics (ACL),Demonstration Session, pages 177?180, Prague,Czech Republic.Kimmo Koskeniemmi and Mariikka Haapalainen.1994.
Gertwol?lingsoft oy.
Linguistische Veri-fikation: Dokumentation zur Ersten Morpholympics,pages 121?140.Ronan Le Nagard and Philipp Koehn.
2010.
Aidingpronoun translation with co-reference resolution.
InProceedings of the Joint 5th Workshop on Statisti-cal Machine Translation and Metrics (MATR), pages258?267, Uppsala, Sweden.Sharid Loaiciga, Thomas Meyer, and Andrei Popescu-Belis.
2014.
English-French Verb Phrase Align-ment in Europarl for Tense Translation Modeling.
InProceedings of the 9th international conference onLanguage Resources and Evaluation (LREC), Reyk-javik, Iceland.Laura Mascarell, Mark Fishel, Natalia Korchagina, andMartin Volk.
2014.
Enforcing consistent translationof German compound coreferences.
In Proceedingsof the 12th Konvens Conference, Hildesheim, Ger-many.Thomas Meyer and Andrei Popescu-Belis.
2012.
Us-ing sense-labeled discourse connectives for statisti-cal machine translation.
In Proceedings of the EACL2012 Joint Workshop on Exploiting Synergies be-tween IR and MT, and Hybrid Approaches to MT(ESIRMT-HyTra), pages 129?138, Avignon, France.Thomas Meyer.
2014.
Discourse-level Features forStatistical Machine Translation.
PhD thesis, EPFL,Lausanne.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedingsof the 41st Annual Meeting of the Association forComputational Linguistics (ACL), pages 160?167,Sapporo, Japan.Kishore Papineni, Salim Roukos, Todd Ard, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics (ACL).Andreas Stolcke, Jing Zheng, Wen Wang, and VictorAbrash.
2011.
SRILM at Sixteen: Update and Out-look.
In Proceedings of the IEEE Automatic SpeechRecognition and Understanding Workshop (ASRU),Waikoloa, Hawaii.J?org Tiedemann.
2010.
Context adaptation in statisti-cal machine translation using models with exponen-tially decaying cache.
In Proceedings of the 2010Workshop on Domain Adaptation for Natural Lan-guage Processing, pages 8?15, Uppsala, Sweden.Ferhan Ture, Douglas W. Oard, and Philip Resnik.2012.
Encouraging consistent translation choices.In Proceedings of the 2012 Conference of the North14American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies(NAACL-HLT), pages 417?426, Montr?eal, Canada.Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang.2011.
Document-level consistency verification inmachine translation.
In Proceedings of the 13th Ma-chine Translation Summit, pages 131?138, Xiamen,China.15
