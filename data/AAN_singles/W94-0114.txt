Statistical versus symbolic parsingfor captioned-information retrievalNeil C. RoweCode CS/Rp, Department of Computer ScienceNaval Postgraduate SchoolMonterey, CA USA 93943rowe@cs.nps.navy.mil1.
SummaryWe discuss implementation issues ofMARIE-l, a mostly symbolic parserfully implemented, and MARIE-2, amore statistical parser partially imple-mented.
They address a corpus of100,000 picture captions.
We argue thatthe mixed approach of MARIE-2 shouldbe better for this corpus because itsalgorithms (not data) are simpler.Subject areas: parser implementation,binary word correlation probabilities.2.
IntroductionOur MARIE project has been investigat-ing information retrieval of multimediadata using a new idea: putting primaryemphasis on caption processing.Although content analysis methods uchas substring searching for text mediaand shape matching for picture mediacan obviate captions, content analysisusually requires unacceptably-largeamounts of time at retrieval time.
Cap-tions can be cachings of the results ofcontent analysis, but they can alsoinclude auxiliary information like thedate or customer for a photograph.Since captions can be considerablysmaller than the media-data theydescribe, checking captions beforeretrieving media data can save time if itcan rule out many bad matches quickly,the idea of "information filters" (Belkinand Croft, 1992).However, caption processing does notnecessarily give faster multimediaretrieval.
The terms of the caption areoften synonyms or subterms of thosesupplied by a user during retrieval, so acomplete thesaurus of synonyms and acomplete type hierarchy of terms shouldbe used during information retrieval(Smith et al 1989).
Furthermore, toobtain high query recall and precision,natural-language processing of the cap-tions must be done to determine theword senses and how the words relate,to get beyond the well-known limits of112-2 -keyword matching (Krovetz and Croft,1992).
This additional processing couldbe slow, so the MARIE project is con-cerned with methods of improving itsefficiency in caption-based retrieval.This paper reports on an importantdirection that we have explored recently:mixing traditional symbolic parsing withprobabilistic ranking based on a res-tricted kind of statistical information.Whi le  the MARIE project is intendedfor multimedia information retrieval ingeneral, we have used as testbed thePhoto Lab of the Naval Air WarfareCenter (NAWC-WD), China Lake Cali-fornia USA.
This is a library ofapproximately 100,000 pictures and37,000 captions for those pictures.
Thepictures cover all activities of the center,including pictures of equipment, ests ofequipment, administrative documenta-tion, site visits, and public relations.With so many pictures, many of whichlooking virtually identical, captions areindispensable to find anything.
But theexisting computerized keyword systemfor finding pictures from their captionsis unhelpful, and is mostly ignoredbypersonnel.
(Rowe and Guglielmo, 1993)reports on MARIE-l, a prototype imple-mentation in Prolog that we developedfor them, a system that appears muchmore in the direction of what userswant.But MARIE-1 took a man-year to con-struct and only handled 220 pictures(averaging 20 words per caption) fromthe database.
To handle the full data-base, efficiency and implementation-difficulty concerns have becomeparamount.
MARIE-2, currently underdevelopment, will address these prob-lems by exploiting a large statistical-correlation database, allowing forsimpler parse rules and fewer semanticroutines.
This should make it run moreefficiently while being much easier toapply to the full captions database.
Thiswill provide an interesting test of statist-ical parsing ideas from an engineeringstandpoint.3.
Example captionsTo illustrate the problems posed by thecorpus, we present some example cap-tions.
All are single-case.an/apq-89 xan-1 radar set in noseof t-2 buckeye modified aircraftbu# 7074, for flight evaluation test.3/4 overall view of aircraft on run-way.This is typical of many captions: twonoun phrases, each terminated with aperiod, where the first describes thephotographic subject and the seconddescribes the picture itself.
Also typicalare the complex nominal-compoundstrings, "an/apq-89 xan-1 radar set" and"t-2 buckeye modified aircraft bu#7074".
Domain knowledge, or statisticsas we shall argue, is necessary to recog-nize "an/apq-89" as a radar type, "xan-I" a version number for that radar, "t-2"an aircraft ype, "buckeye" a slang addi-tional name for a T-2, "modified" a con-ventional adjective, and "bu# 7074" asan aircraft code ID.113-3 -program walleye, an/awg-16 firecontrol pod on a-4c bu# 147781aircraft, china lake on tail, fit test.3/4 front overall view and closeup1/4 front view of pod.This illustrates ome common domain-dependent noun-phrase syntax.
"A-4cbu# 147781" is a common pattem of<equipment-type> <prefix-code><code-number>, a pattern frequentenough to deserve its own grammarrule.
Similarly "an/awg-16 fire controlpod" is the common pattern of<equipment-name> <equipment-purpose> <equipment-type>, and "3/4front overall view" is of the form<view-qualifier> <view-qualifier><view-type>.graphics presentation tid progress76.
sea site update, wasp headdirector and hawk screech\[sunvisor radars, tdp portion only,excellent.This illustrates the need for domain-dependent lexicon information.
Here"wasp", "hawk", and "sun visor" shouldnot be interpreted in their commonEnglish word senses, but as specialequipment erms.
Furthermore, "pro-gress 76" means "progress in 1976", and"excellent" refers to the quality of thepicture.
And the "head director" is nota person but a guidance system, and the"sea site" is not in the sea but a dry lak-ebed flooded with water to a few inches.Such unusual word senses strongly callfor inference from domain-dependentstatistics.
They are also a good argu-ment lor natural-language processing forinforrnation retrieval instead of keywordmatching.aerial low oblique, looking s frominyodern rd at main gate downchina lake bl to bowman rd.
on l, bto t, water reservoirs, o f  crcl, pwcmpnd, vieweg school, capehart bhousing, burroughs hs, cimarrongardens, east r/c old duplex stor.lot.
on r, b to t, trngl, bar s motel,arrowsmith, comarco, hosp and onto bowman rd.This illustrates the problems with themisspellings and nonstandard abbrevia-tions in the captions.
"Trf crcl" is sup-posed to be "traffic circle", "trngr' is tri-angle, "capehart b" is "capehart base",but "b to t" is "bottom to top".
"Vieweg" which looks like a misspellingof "viewed" is actuaUy the correct nameof a former base commander, but "inyo-dem" which looks correct actually is amisspelling of "Inyokem", a nearbytown.
Such abbreviations and misspel-lings can only be found by reference toknown domain words and using heuris-tics.per-heps, parachute extractionrocket-helicopter escape propulsionsystem, test setup, 700# f inlauncher showing 50# deadweight,nylon strap, and parachute cannis-ter.This illustrates the difficulties of inter-preting the numerous acronyms in thecaptions.
Here the first word of theabove is an immediately-explained acro-nym; a careful search for such con-structs helps considerably, as often anacronym is explained in at least one114-4 -caption.
But even explained acronymscause difficulties.
We can generallytake the subject of the appositive phraseafter the acronym as the type of theacronym, "system" in this case, but howthe other words relate to it is compli-cated and less determined by conven-tional English syntax than the need toobtain a cute acronym.4.
Our approach to statistical parsingMARIE-1 uses the standard approach ofintelligent natural-language processingfor information retrieval (Grosz et al1987; Rau, 1988; Sembok and vanRijsbergen, 1990) of hand-coding oflexical and semantic information for thewords in a narrow domain.
We usedthe DBG software from Language Sys-tems, Inc. (in Woodland Hills, CA) tohelp construct he parser for MARIE-1.Nonetheless, considerable additionalwork was needed to adapt DBG to ourdomain.
Even though we focused on arandom sample of only 220 captions,they averaged 50 words in length andrequired a lexicon and type hierarchy of1000 additional words beyond the 1000we could use from the prototype DBGapplication for cockpit speech.
A largenumber of additional semantic rules hadto be written for the many long andcomplicated noun-noun sequences thathad no counterpart in cockpit speech.These required difficult debuggingbecause DBG's multiple-pass emanticprocessing is tricky to figure out, andthe inability of DBG to backtrack andfind a second interpretation meant thatwe could only find a maximum of onebug per run.
But hardest of all to usewere DBG's syntactic features.
Theserequired a grammar with fixed assignedprobabilities on each rule, which neces-sitated a delicate balancing act that con-sidered the entire corpus, to choosewhat was often a highly sensitivenumber.
The lack of context sensitivitymeant that this number had to pro-gramrned artificially for each rule toobtain adequate performance (for whichsome researchers have claimed success),instead of being taken from applicablestatistics on the corpus, which makesmore sense.
But this "programming"was more trial-and-error than anything.MARIE-I's approach would be unwork-able for the 29,538 distinct words in thefull 100,000-caption NAWC database.Statistical parsing has emerged in thelast few years as an alternative.
I tassigns probabilities of co-occurrence tosets of words, and uses these probabili-ties to guess the most likely interpreta-tion of a sentence.
The probabilitiescan be derived from statistics on acorpus, a representative s t of examplesentences, and they can capture finesemantic distinctions that would other-wise require additional lexicon informa-tion.Statistical parsing is especially wellsuited for information retrieval becausethe goal of the latter is to find data thatwill probably satisfy a user, but satisfac-tion is never guaranteed.
Also, goodinformation retrieval does not requirethe full natural-language understanding115-5 -that hand-tailored semantic routines pro-vide: Understanding of the wordsmatched is not generally helpful beyondtheir synonym, hierarchical type, andhierarchical part information.
Forinstance, the query "missile mounted onaircraft" should match all three of:--"sidewinder on f-18"--"sidewinder attached to wingpylon"--pylon mounted aim-9msidewinders"since "sidewinder" and "aim-9m" aretypes of missiles, "f-18" as a kind ofaircraft, and "on" and "attached" meanthe same thing as "mounted".
NAWC-WD captions are often imprecise withverbs, so detailed semantic analysis ofthem is usually fruitless.
Parsing is stillessential to connect related words in acaption, as to recognize the similar deepstructure of the three examples above.But a parser for information retrievalcan have fewer grammatical categoriesand fewer rules than one for fullnatural-language understanding.Creating the full synonym list, typehierarchy, and part hierarchy for appli-cations of the size of the NAWC-WDdatabase (42,000 words including wordsclosely related to those in the captions)is considerable work.
Fortunately, alarge part of this job for any Englishapplication has been already accom-plished in the Wordnet system (Miller eta l ,  1990), a large thesaurus ystem thatincludes this kind of information, plusrough word frequencies and morphologi-cal processing.
From Wordnet weobtained information for 6,843 wordsmentioned in the NAWC-WD captions(for 24,094 word-sense ntries), togetherwith 15,417 "alias" facts relating otherword senses to 24,094 as synonyms.
(The alias facts shortened the lexicon byabout 85%.)
This left 22,~95 words inthe captions that did not have availableWordnet data, for which we used avariety of methods to create lexiconentries.
The full breakdown of the lexi-con was:Number of distinct words: 29,538Recognized by Wordnet: 6,843--Morphological variants of abovewords: 2,134--Related superconcepts, wholes,aliases, and phrases recognized byWordnet: 12,294--Numbers: 3,718--Person names: 2,160--Place names: 246--Company names: 149--Words with unambiguousdefined-code prefixes: 2,987--Miscellaneous identifiable specialformats: 6,033--Identifiable misspellings: 826--Identifiable abbreviations: 928--Current domain-dependentexplicitly-defined words (mostlyfrom MARIE-l): 770--Current remaining unidentifiedwords (90% equipment names):4,215The special-format rules do things likeinterpret "BU# 462945" as an aircraftidentification umber and "02/21/93" asa date.
Misspellings and abbreviationswere obtained mostly automatically,with human checking, from rule-based116-6 -systemsdescr ibed in (Rowe andLaitinen, 1994).
The effort for lexicon-building, although it is not yet complete,was relatively modest (0.25 of a man-year) thanks to Wordnet, which suggestsgood portability.
Some of this successcan be attributed to the restrictions ofcaption semantics.We converted all this information to aQuintus Prolog format compatible withthe rest of MARIE-2, and used this inparsing and interpretation.
The basicmeaning assigned to a noun or verb isthat it is a subtype of the conceptdesigned by its name in the type hierar-chy, with additional pieces of meaningadded by its relationships (likemodification) to other words in the sen-tence.
For instance, for "big missile onstand", a representative meaning listcurrently obtained is:\[a kind_of(v3 ,projectile- 1 ),property(v3,big- 1),locationover(v3,v5),a_kind__of(v5,base-2)\]where v3 and v5 are variables and thenumbers after the hyphen indicate theword sense number.5.
Statistical parsing techniquesThis approach can be fast since we justsubstitute standard synonyms for thewords in a sentence, append the typeand relationship specifications for all thenouns; verbs, adjectives, and adverbs,and resolve references using the parsetree, to obtain a "meaning list" orsemantic graph, following the paradigmof (Covington, 1994) for the nonstatisti-cal aspects.
But this can still be slowbecause it would seem we need to findall the reasonable interpretations of asentence in order to rank them.
To sim-plify matters, we restricted the grammarto binary parse rules (context-free ruleswith one or two symbols for thereplacement).
The likelihood of aninterpretation can be found by assigningprobabilities to word senses and rules.If we could assume near-independenceof the probabilities of each part of thesentence, we could multiply them to getthe probability of the whole sentence(Fujisaki et al 1991).
This ismathematically equivalent to taking thesum of the logarithms of the probabili-ties, and hence a branch-and-boundsearch could be done to quickly find theN best parses of the a sentence.But words of sentences are obviouslynot often independent or near-independent.
Statistical parsing oftenexploits the probabilities of strings ofsuccessive words in a sentence (Jonesand Eisner, 1992).
However, withbinary parse rules, a simpler and moresemantic idea is to consider only theprobability of co-occurrence of the twosubparses.
For example, the probabilityof parsing "f-18 landing" by the rule"NP -> NP PARTICIPLEPHRASE"should include the likelihood of an F-18in particular doing a landing and thelikelihood of this syntactic structure.The co-occurrence probability for "f-18"and "land" is especially helpful becauseit is unexpectedly arge, since there areonly a few things in the world that land.117-7 -Estimates of co-occurrence probabilitiescan inherit in the type hierarchy (Rowe,1985).
So if we have insufficient statis-tics in our corpus about how often anF-18 lands, we may enough on howoften an aircraft lands; and assumingthat F-18s are typical of aircraft in thisrespect, we can estimate how often F-18s land.
The second word can be gen-eralized too, so we can use statistics on'T-18" and "moving", or both the wordscan be simultaneously generalized, sowe can use statistics on "aircraft" and"moving".
The idea is to find somestatistics that can be reliably used toestimate the co-occurrence probability ofthe words.
Each parse rule can haveseparate statistics, so the alternativeparse of "f-18 landing" by "NP ->ADJECTIVE GERUND" would beevaluated by separate statistics.To keep this number of possible co-occurrence probabilities manageable, itis important to restrict them to two-probability.
When parse rules recognizemultiword sequences as grammaticalunits, those sequences can be reduced to"headwords".
For instance, "the big f-18 from china lake landing at armitagefield" can also be parsed by "NP -> NPPARTICIPLEPHRASE" and the sameco-occurrence probability used, since"f-18" is the principal noun and henceheadword of the noun phrase "the bigf-18 from china lake", and "landing" isthe participle and hence headword of theparticipial phrase "landing at arrnitagefield".
We can get a measure of theinteraction of larger numbers of wordsby multiplying the probabilities for al lsuch binary nodes of the parse tree.This is not an independence assumptionanymore because an important word canappear as headword of many differentsyntactic units, and thus affect theoverall rating of a parse in many places.A big advantage for us of statisticalparsing is in identification of unknownwords.
As we noted earlier, our corpushas many equipment terms, geographicalnames, and names of people that are notcovered by Wordnet.
But for informa-tion retrieval, detailed understanding ofthese terms is usually not requiredbeyond recognizing their category, andthis can be inferred by co-occurrenceprobabilities.
For instance, in "person-nel mounting ghw-12 on an f-18","ghw-12" must be a piece of equipmentbecause of the high likelihoods of co-occurrence of equipment terms with"mount" and equipment terms with"on'.6.
More about the statistical databaseWe will obtain the necessary countsfrom running the parser on the 100,000captions.
Using branch-and-boundsearch, the parser will find what it con-siders the most likely parse; if this isincorrect, a human monitor will say soand force it to consider the second mostlikely parse, and so on.
Counts areincremented for each binary node in theparse tree, and also for all superconceptsof the words involved.
As counts accu-mulate, the system should graduallybecome more likely to guess the correct118-8 -parse on its first try.The statistical database for binary co-occurrence statistics will need carefuldesign because the data will be sparseand there will be many small entries.For instance, for the NAWC-WD cap-tions there are about 20,000 synonymsets about which we have lexicon infor-marion.
This means 200 million possi-ble co-occurrence pairs, but the total ofall their counts can only be 610,182, thetotal number of word instances in allcaptions.
Our counts database uses foursearch trees indexed on the first word,the part of speech plus word sense ofthe first word, the second word, and thepart of speech plus word sense of thesecond word.
Stonng counts rather thanprobabilities aves storage and reduceswork on update.
Various compressiontechniques can further reduce storage,but especially the elimination of datathat can be closely approximated fromother counts using sampling theory(Rowe, 1985).
For instance, if "f-18"occurs 10 times in the corpus, all kindsof aircraft occur 1000 times, and thereare 230 occurrences of aircraft landing,estimate the number of "f-18 landing"sin the corpus as 230 * 10 / 1000 = 2.3;if the actual count is within a standarddeviation of the Value, do not store it inthe database.
The standard deviationwhen n is the size of the subpopulation,N is the size of the population, and Athe count for the population, isqA (N-A )(N-n )/nN2(N-1) (Cochran, 1977).Such calculations require also "unary"counts stored with each word or stan-dard phrase, but there are far fewer ofthese: (While unary counts also directlyaffect the likelihood of a particular sen-tence, that effect can be ignored since itis constant over all sentence interpreta-tions.
)We need not store statistics for everyword in the statistical database.
Manywords and phrases used in are corpusare codes that appear rarely, like air-plane ID numbers and dates.
For suchconcepts, we only keep statistics on thesuperconcept, "ID number" and "date"for these examples.
Which concepts areto be handled this way is domain-dependent, but generally simple.7.
More about the restriction tobinary probabilitiesIt may seem inadequate to restrict co-occurrence probabilities to pairs ofheadwords.
We argue that while this isinadequate for general natural-languageprocessing, information retrieval in gen-eral and captions in particular areminimally affected.
That is because thesublanguages of such applications arehighly case-oriented, and cases arebinary.
So structures like subject-verbal-object can be reduced to verbal-subject and verbal-object cases;adjective 1-adjecfive2-noun can bereduced to two adjective-noun case rela-tionships, either separately with eachadjective or by reducing adjectivel-adjecrive2 to a composite concept i fadjective2 can be taken as a noun.Prepositional phrases would seem to betrouble, however, because the preposi-119-9 -tion simultaneously interacts with bothits subject and its object.
We handlethem by subclassifying prepositions aslocation, time, social, abstract, or mis-cellaneous, reflecting the main featuresthat affect compatibility with subjectsand objects.
Then, say, a parse of "air-craft at nawc" retrieves only a highcount if the preposition is a location andnot time preposition, and so permitscompatibility under those syntacticallyrestricted circumstances of "nawc" and"aircraft".Another objection raised to binary pro-babilities is the variety of nonlocalsemantic relationships the can occur indiscourse.
Captions at NAWC-WD areusually multi-sentence, and anaphora dooccur which can usually be resolved bysimple methods.
More difficult is theproblem of resolving multiple possibleword senses.
For "sidewinder onground", are we talking about the snakeor the missile?
(NAWC-WD captionsare all lower case.)
The proper interpre-tation depends on whether the previoussentence was "flora and fauna of thechina lake area" (NAWC-WD has manysuch pictures for public relations) or"loading sequence for a missile".
Wehave three answers to this challenge.First, most of the words that have manymultiple meanings in English areabstract or metaphorical, and notappropriate for use on captions.Second, when ambiguous words dooccur, the odds are good that someimmediate syntactic relationship willprovide the necessary clues to resolvingambiguity; for instance, both"sidewinder mounted" and "sidewindercoiled" are unambiguous when usingco-occurrence counts.
Third, even ifmultiple interpretations cannot be ruledout for a word, an information retrievalsystem can just try each, and take theunion of the results (i.e.
as a logical dis-junction); generally only one interpreta-tion will every match a query.
Notethat if count statistics are derived fromthe same corpus that is subsequentlyused for retrieval, as MARIE-2 intendsto do, the probabilities obtained fromour parse will be a rough estimate of theyield (selectivity) of each interpretation.8.
ReferencesBelkin, N. J. and Croft, W. B. Informa-tion filtering and information retrieval:two sides of the same coin?
Communi-cations of the ACM, 35, 12 (December1992), 29-38.Cochran, W. G. Sampling Techniques,third edition.
New York: Wiley, 1977.Covington, M. Natural language pro-cessing for Prolog programmers.
Engle-wood Cliffs, NJ: Prentice-Hall, 1994.Fujisaki, T., Jelinek, F., Cocke, J.,Black, E., and Nishino, T. A proba-bilistic parsing method for sentencedisambiguation.
In Current issues inparsing technology, ed.
Tomita, M.,Boston: Kluwer, 1991.Grosz, B., Appelt, D., Matin, P. andPereira, F. TEAM: An experiment in120- 10 -the design of transportable naturallanguage interfaces.
Artificial Intelli-gence, 32 (1987), 173-243.Jones, M. and Eisner, J.
A probablisticparser applied to software testing docu-ments.
Proceedings of the TenthNational Conference on Artificial Intelli-gence, San Jose, CA, July 1992, 323-328.Krovez, R. and Croft, W. B. Lexicalambiguity and information retrieval.ACM Transactions on Information Sys-terns, 10, 2 (April 1992), 115-141.Miller, G., Beckwith, R., Fellbaum, C.,Gross, D., and Miller, K. Five paperson Wordnet.
International Journal ofLexicography, 3 4 (Winter 1990).Rau, L. Knowledge organization andaccess in a conceptual information sys-tem.
Information Processing andManagement, 23, 4 (1988), 269-284.Rowe, N. Anfisampling for estimation:an overview.
IEEE Transactions onSoftware Engineering, SE-11, 10(October 1985), 1081-1091.Rowe, N. Inferring depictions innatural-language captions for efficientaccess to picture data.
Information Pro-cessing and Management, 30, 3 (1994),379-388.Rowe, N. and Guglielmo, E. Exploitingcaptions in retrieval of multimedia data.Information Processing and Manage-ment, 29, 4 (1993), 453-461.Rowe, N. and Laitinen, K. Semiau-tomatic deabbreviadon f technical text.Technical report, Computer Science,Naval Postgraduate School, April 1994.Sembok, T. and van Rijsbergen, C.SILOL: A simple logical-linguisticdocument retrieval system.
InformationProcessing and Management, 26, I(1990), 111-134.Smeaton, A. F. Progress in the applica-tion of natural anguage processing toinformation retrieval tasks.
The Com-puter Journal, 35, 3 (1992), 268-278.Acknowledgement: This work was spon-sored by DARPA as part of the 13 Pro-ject under AO 8939.121
