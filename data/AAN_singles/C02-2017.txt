Robust Interpretation of User Requests for Text Retrieval in a MultimodalEnvironmentAlexandra Klein and Estela Puig-Waldmu?llerAustrian Research Institute forArtificial IntelligenceSchottengasse 3A-1010 Vienna, Austriafalex, stellag@oefai.atHarald TrostDepartment of Medical Cybernetics andArtificial Intelligence, University of ViennaFreyung 6/2A-1010 Vienna, Austriaharald@ai.univie.ac.atAbstractWe describe a parser for robust and flexible inter-pretation of user utterances in a multi-modal sys-tem for web search in newspaper databases.
Userscan speak or type, and they can navigate and followlinks using mouse clicks.
Spoken or written queriesmay combine search expressions with browser com-mands and search space restrictions.
In interpretinginput queries, the system has to be fault-tolerant toaccount for spontanous speech phenomena as wellas typing or speech recognition errors which oftendistort the meaning of the utterance and are difficultto detect and correct.
Our parser integrates shallowparsing techniques with knowledge-based text re-trieval to allow for robust processing and coordina-tion of input modes.
Parsing relies on a two-layeredapproach: typical meta-expressions like those con-cerning search, newspaper types and dates are iden-tified and excluded from the search string to be sentto the search engine.
The search terms which areleft after preprocessing are then grouped accordingto co-occurrence statistics which have been derivedfrom a newspaper corpus.
These co-occurrencestatistics concern typical noun phrases as they ap-pear in newspaper texts.1 IntroductionIn this paper we describe a parser for robust andflexible interpretation of user utterances in a web-based multi-modal text retrieving system.
Theparser forms part of a system for web search in Aus-trian newspaper databases.
In this system, users canformulate queries or navigation commands using ut-terances in both spontaneous spoken or written lan-guage, and they can navigate and follow links usingmouse clicks.
Users are completely free in formu-lating their utterances and in the use and combina-tion of the input modes.
Typed and spoken utter-ances may contain combinations of query expres-sions, browser commands and search space restric-tions.
Users may search for texts with a specificdate, in a specific newspaper or in a specific sec-tion of a newspaper.
They may give complex con-text descriptions of the texts and they may refer topreviously found texts.
A dialogue manager storesactions and results from previous states and suppliesinformation in order to construct fully specified for-mal queries from underspecified user requests.In order to allow for this freedom in user be-haviour, flexible processing modules are needed.For every utterance, the parser and the dialoguemanager must come up with an adequate interpre-tation.
At the same time, in interpreting the in-put, they have to be robust and fault-tolerant.
Theyhave to cope with typical phenomena of sponta-neous speech like hesitation, correction and repe-tition.
There may be typographical errors in writteninput or ?
even more difficult to deal with ?
speechrecognition errors from the spoken queries.
Sucherrors often distort the meaning of the utterance andare difficult to detect and correct.In our interpretation component, shallow pars-ing techniques and knowledge-based text retrievalmethods are combined to allow for robust process-ing and coordination of input modes.
We employa two-layered approach.
The first layer serves toseparate structure from content, i.e., parts of utter-ances referring to browser commands and search re-strictions (temporal expressions, newspaper types orsections) are analyzed with a combination of key-word spotting and pattern recognition.
The under-lying assumption is that users will restrict them-selves to a rather small vocabulary and a limitedrange of expressions in expressing this sort of in-formation (this assumption is also confirmed by ourWizard-of-Oz experiments).
During this process,stop words (function words and other words typi-cally not contributing to the content of the query)are also removed.
The remaining words ?
which areassumed to describe the search content ?
are thengrouped according to co-occurrence statistics whichhave been derived from a newspaper corpus.
Whiletext retrieval with the help of linguistic process-ing has become rather common, multimodal inter-action with textual databases on the web is a fairlyrecent application of Natural Language Process-ing.
Experience from text retrieval shows that mostinformation is expressed in adjective-noun, noun-preposition-noun, and noun-verb groups (Grefen-stette, 1992).
In our specific domain, the third typecan be neglected, because verbs typically denote theaction ?
mostly search ?
which is already extractedin the first layer.
Thus, co-occurrence statistics con-sist of typical noun phrases as they appear in news-paper texts.2 Empirical evidence and userexperimentsIn order to assess user behaviour, we carriedout Wizard-of-Oz experiments (Fraser and Gilbert,1991).
Speech recognition and text retrieval weresimulated.
In different sessions the users interactedwith a number of versions of the system: single in-put mode versions and versions with combinationsof input modes.
Their performance in terms of num-ber of interactions as well as task completion timewas measured, and their comments regarding the in-terface and the (simulated) system were collectedin a questionnaire.
Users were grouped accordingto previous experience with search engines and theweb in general.
Our results show that both, be-ginners and advanced users, preferred multimodalinteraction over single input modes, and beginnersin particular were able to speed up task completiontimes significantly with the help of a combination ofspoken and written input with mouse clicks (Kleinet al, 2001).From these experiments, we also obtained a cor-pus of written and spoken utterances which wereconsidered in the further design of the system.
Thequeries which were posed by the users in spokenlanguage were recorded.
The recorded utteranceswere later read to a speech recognition system.
Thisgave us an impression of the number and type of er-rors to be expected in dealing with queries in spon-taneous speech.3 NL Text or Speech Input: LanguageAnalysisUsers can access articles with spoken or typed ut-terances.
Web queries may relate to the way someparticular piece of infomation is presented and whatthis information refers to.
They may also expressbrowser commands or a combination of browser andquery commands while referring either to structure(Search for Noll in the previous newspaper) or tocontent (Search for Noll in the sports?
section).1Within our application web queries may relate tothe way some particular piece of information is pre-sented (e.g.
the browser?s history about the accessedpages), and what this information refers to (e.g.
thesection a search string belongs to).
To successfullyinterpret such an utterance, one needs to analyze itsstructure to find out which of these command modesthe utterance can be assigned to.
This is done in atwo-step process.
First, each word is looked up in alexicon and assigned a semantic category.
Second,certain rules are applied to strings of these seman-tic categories.
As a result, commands and searchrestrictions are recognized and the rest of the utter-ance is passed to search expression interpretation.3.1 Keyword Spotting and SemanticClassificationWe will now describe in more detail how the user?sinput is parsed within the Natural Language In-terface, and structured into either search patterns?
consisting of search strings, sections, dates andtimeranges, that are understood by the search en-gine of the newspaper ?
or commands for the Javabrowser.
Structure is analyzed by a flexible bottom-up parser using a rule-based mechanism with simplesyntactic patterns.In the user?s query input, each word of the utteranceis looked up in a lexicon and - if found - assigned acorresponding semantic category.
This lexicon con-tains a small list of semantic categories, that we con-sider important for the interpretation of an utterancein the domain of searching articles and browsing.The lexicon assigns semantic classes for closed cat-egories that are: nouns denoting search, newspaper, section, linkslike ?Suche?
(search) or ?Artikel?
(article). nouns expressing a specific section like?Wirtschaft?
(economy). nouns expressing a specific page like ?Homepage?. temporal expressions and temporal prepositionslike ?Monat?
(month) and ?vor?
(ago).1We will use the italic font for language expressions and thetypewriter font for meta-language expressions. expressions indicating something new like in a?neue?
(new) search. adjectives and adverbs indicating direction in timeor space, like in ?letzte?
(previous) search or in?letzte?
(last) week. cardinal and ordinal numbers used in conjunctionwith temporal expressions and link expressions,like in ?zwei?
(two) years ago or when opening the?ersten?
(first) link. adverbs and connectives indicating constraints onsearch mode, like ?nur?
(only) and ?nicht?
(not). prepositions indicating whether the request was tobrowse or to search, cf ?zum Sport?
(to the sports?section) versus ?im Sport?
(within the sports?
sec-tion). stop words.All words found within the lexicon are replacedby their corresponding semantic classes, search ex-pressions are marked as such, and stop words aredeleted.We distinguish between semantic atoms and se-mantic classes: atoms by itself do not have a mean-ing that can be used for searching or browsing com-mands.
They have to be joined following a givenset of rules to form a semantic class.
To yieldsuch a class, rules are applied in ?
mostly ?
one tothree steps.
However, rules are not always neces-sary, a word may also be mapped onto a semanticclass right away.
Our lexicon has about 30 semanticatoms, from which about 40 semantic classes can beformed.
Certain patterns of semantic classes whichwe obtain through lexical look-up can be assignednew meanings via rules.
So, by composing the indi-vidual meanings, another more abstract meaning isdefined.
This compositional approach to interpreta-tion is supported by the layered approach.
The re-sult of this process is a list of chunks2, where stressis laid on the content words.
The advantage of con-centrating on chunks is ?
especially within German,a language with a relatively free word order ?
thatthe order in which chunks occur is much more flex-ible than the order of words within chunks.
Thisapproach might be too shallow for a deeper seman-tic analysis, but is sufficient for our needs.
So, e.g.2According to Abney (1991) a chunk is defined in terms ofmajor heads where a major head is any content word that doesnot appear between a function word f and the content wordf selects, OR a pronoun selected by a preposition.
[...] Thetypical chunk consists of a single content word surrounded bya constellation of function words, matching a fixed template.?letzte?
(last) plus a time expression would togetheryield the new meaning date -1w.
To overcomeambiguities and avoid potential rule conflicts, rulesspanning larger chunks have a higher priority andare thus preferred, such that ?zuru?ck zum Sport?
(back to sports) would win over ?zuru?ck?
(back).If no rules can be applied to a semantic class, it willbe ignored in the final interpretation.Summing up the process of the structure analysis,the partial analyses are stored, a sequence of partialanalyses from the set of rules is chosen, and thencombined to yield larger structures.3.2 Search String Filter: Extraction ofAdjective-Noun PairsIn the next step, the content of the query must be an-alyzed in more detail.
In this chapter we will explainhow content analysis is done in our application.From a corpus of Austrian newspaper texts,adjective-noun- and adjective-proper-name pairswere extracted and counted.
These pairs were storedand consulted in query interpretation.
Since thetexts are tagged manually, the lists of adjectives andnouns/proper names contain a considerable numberof errors.
Therefore it is necessary to use largeamounts of text; it may even be useful to eventu-ally introduce a threshold so that only adjective-noun/proper-name pairs which appear more thanonce or a certain number of times are considered.This of course can not prevent systematic taggingerrors.A robust stemming algorithm maps all adjective-noun/proper-name pairs to an approximate ?stem?,thus eliminating flectional forms which result inmorphological variation which is typical for theGerman language.
For the purpose of creating arepository of co-occurrence pairs, we do not careabout proper stemming.
Rather, it is our aim to mapvarious inflectional forms onto one base form.Spelling variations, numbers etc.
are smoothedas far as it is possible in automatic processing.
Forexample, ordinal numbers which are labelled as ad-jectives are reduced to a placeholder for numbers.Whenever a word is encountered in processingwhich can be considered an adjective, it is kept.Whenever the following word may be a noun or aproper name, it is checked whether the adjective-noun/proper-name combination is contained in therepository of adjective-noun/proper-name combina-tions which has previously been extracted from acorpus.
If the adjective-noun/proper-name combi-nation is found, it is passed on to the search engineas a query.
Whenever the combination has not oc-curred in the corpus, only the noun or proper nameis considered a key word.Again, inflectional variations as well as differentspellings etc.
are mapped onto base forms as faras possible.
The same stemming algorithm is usedwhich was employed in creating the repository ofadjective-noun/proper name pairs.
The robust (andrough) stemming and categorization algorithms pro-duce a certain amount of mistakes in the lists ofpairs as well as in the mapping process, but tak-ing into account larger text corpora evens out theseproblems as more text is processed.Our approach distinguishes noun phrases whichhave a record of co-occurrence from noun phraseswhich may be spontaneous expressions or modifica-tions or even errors created by users.
For example,the phrase ?europa?ische Staaten?
(European coun-tries) would be retained while ?beteiligte Staaten?
(participating countries) would be reduced to thenoun.
Some adjectives used in search expressionsserve to qualify the global search expression ratherthan the noun or proper name in quesion.
For ex-ample, a search for yesterday?s speech would onlyyield articles from the day after a speech, not aboutthe speech in general.4 Action History: Integration of theknowledge sourcesMultimodal dialogue requires a unified interpreta-tion of the involved knowledge sources, all inputmodes have to be considered.
The informationtransmitted needs to be interpreted within discoursecontext including previous user actions, possiblywith data coming from other input modes.After the analysis of the user utterance has beenperformed in the pattern-matching and the search-word-extraction modules, the computed meaning ofthe utterance has to been interpreted in the contextof the discourse sitiuation.
This concerns mostlythe history of previous queries.
Here, it is impor-tant to consult previous queries in all possible inputmodes (spoken, typed, mouse clicks).
Therefore, arecord of the action history is kept and consulted.All typed, written and spoken actions are assignedan entry in the action history where the main param-eters and their values are collected.With this contextual information, the meaning ofthe user?s utterance as the sum of the results of thecomponent analyses is computed in the global dis-course context.
Underspecified queries can be in-terpreted in the discourse contexts, and parametersare filled.
Thus, the results are combined into oneunambiguous command line.A powerful interaction control is necessary in or-der to recognize the user?s intent by comparing it towhat the system knows about the addressed entitiesand their relation to each other as well as to the datawhich are accessible at the specific moment in theinteraction.
The interface language between the lan-guage analysis module and the controller consists ofa fixed set of parameters, which are assigned appro-priate values: DIRECTIONthe direction for browsing (forward, backward) SECTIONthe section in the newspaper (politics, sports, ...) SEARCHSTRINGthe string which has to be searched by the newspa-per search engine DATEthe date when the article to be searched has ap-peared (also intervals) ZEITUNG (NEWSPAPER)the newspaper which is supposed to be searched OPENLINKthe link in a document which should be followed inthe browser OPENURLthe URL which is supposed to be opened by thebrowserThe outcome ?
or left-hand side ?
of a rule-basedsimplification can be divided into three commandtypes: Simple Search Command, New Search Com-mand: E.g.
?Suche nach Camilleri im Kulturres-sort?
(Search for Camilleri in the cultural section)or ?Neue Suche beginnen mit Krimis?
(Start a newsearch on thrillers). Complex Search Command: Search using the Ac-tion history.
E.g.
?Suche nach Christie im letztenRessort?
(Search for Christie in the previous sec-tion). Simple History Browsing Commands: NormalBrowsing using the Accessed Page History.
E.g.
?Zur na?chsten Seite gehen?
(Go to the next page). Complex History Browsing Commands: Browseusing the Action history.
E.g.
?Geh zum let-zten Ressort?
(Go to the last ressort) or ?Zuru?ckzur Suche mit Montalbano gehen?
(Go back to thesearch containing Montalbano). WWW Browsing: E.g.
?Geh zum heutigen Sport-bereich?
(Go to today?s sport section), ?den Stan-dard lesen?
(read the Standard) or ?Geh zur Home-page?
(Go home). Opening Link Command: E.g.
?den ersten Artikelo?ffnen?
(Open the first article)The action history browsing command refers tothe timeline and the point of reference of a brows-ing but also of a search command.
For instance,take an utterance, where someone wants to searchfor a topic but within a context that was defined inthe previous search.
For our application, we wouldfirst have to locate the user?s point of reference andthen execute her search command.
If there is nogiven reference, we assume by default that a newtime point is created in our time line.One such command could look like this: theutterance ?Ich suche etwas u?ber Highsmith imletzten Ressort?
(I am looking for somethingabout Highsmith within the previous section) wouldbe mapped to: DIRECTION 0, SECTION x(where x is the section of the action with in-dex -1), SEARCHSTRING Highsmith, TIMEnil, ZEITUNG nil.
We are not moving in thetimeline, instead we are adding a new search action,thus the direction is zero.
Anyway, the controllerhas to look up the action history to fill the value ofthe section.
The values of all empty parameters willbe filled with the values of the last actions, so in ourexample, these parameters have not been explicitlyfilled and remain empty (nil).5 Result: Translating into Http Request orBrowser CommandAfter the command has been processed by the con-trol module, it is either executed by the Java browseror translated into a GET method through an Httprequest to the newspaper?s archive database.
Theresulting articles are displayed in the Java browser,another search can be started by the user.6 ConclusionWe have presented an interpretation component fornatural language user input in a web-based multi-modal text retrieval system.
By applying well-known and simple methods from shallow parsingand knowledge-based text retrieval and integratingthem in a novel way we have succeeded in creatinga robust, flexible and efficient parser for our appli-cation.An important feature is the distinction betweenthose parts of utterances relating to structure andthose relating to content.
This is achieved by tak-ing advantage of the fact that only a limited vocab-ulary and set of expressions are used for the former.This allows us to employ simple rule-based tech-niques for their interpretation.
The identification ofthe content on the other hand is done with the helpof a co-occurrence repository, at the moment con-sisting of adjective-noun/proper name pairs.
In thefuture we will have to investigate whether search re-sults can be improved by inserting other combina-tions, like noun-preposition-noun triples.AcknowledgementsThis work was supported by the Austrian ScienceFund (FWF) under project number P-13704.
Finan-cial support for ?OFAI is provided by the AustrianFederal Ministry of Education, Science and Culture.ReferencesSteven Abney.
1991.
Parsing by chunks.
In RobertBerwick, Steven Abney, and Carol Tenny, editors,Principle-Based Parsing, Tu?bingen (Germany).Kluwer Academic Publishers.Norman M. Fraser and G. Nigel Gilbert.
1991.Simulating speech systems.
Computer Speechand Language, 5(1):81?99.Gregory Grefenstette.
1992.
Use of Syntactic Con-text to Produce Term Association Lists for TextRetrieval.
In N.J. Belkin, P. Ingwersen, and A.M.Pejtersen, editors, Proceedings of the 15th An-nual International ACM SIGIR Conference onResearch and Development in Information Re-trieval, pages 89?97, Copenhagen: Denmark.ACM Press.Alexandra Klein, Ingrid Schwank, MichelGe?ne?reux, and Harald Trost.
2001.
EvaluatingMultimodal Input Modes in a Wizard-of-OzStudy for the Domain of Web Search.
In AnnBlandford, Jean Vanderdonckt, and Phil Gray,editors, People and Computer XV ?
Interactionwithout Frontiers: Joint Proceedings of HCI2001 and IHM 2001, pages 475?483.
Springer:London, September.
