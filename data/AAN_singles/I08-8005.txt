Using Confidence Vector in Multi-Stage Speech RecognitionHyungbae Jeon, Kyuwoong Hwang, Hoon Chung, Seunghi Kim, Jun Park, Yunkeun LeeSpeech/Language Information Research CenterElectronics and Telecommunications Research Institute (ETRI)161 Gajeong-dong, Yuseong-gu, Daejeon, 305-350, Korea{hbjeon, kyuwoong, hchung, seunghi, junpark, yklee}@etri.re.krAbstractThis paper presents a new method of usingconfidence vector as an intermediate inputfeature for the multi-stage based speechrecognition.
The multi-stage based speechrecognition is a method to reduce the com-putational complexity of the decoding pro-cedure and thus accomplish faster speechrecognition.
In the multi-stage speech rec-ognition, however, the error of previousstage is transferred to the next stage.
Thistends to cause the deterioration of the over-all performance.
We focus on improvingthe accuracy by introducing confidencevector instead of phoneme which typicallyused as an intermediate feature between theacoustic decoder and the lexical decoder,the first two stages in the multi-stagespeech recognition.
The experimental re-sults show up to 16.4% error reductionrate(ERR) of word accuracy for  220k Ko-rean Point-of-Interest (POI) domain and29.6% ERR of word accuracy for hotel res-ervation dialog domain.1 IntroductionRecently, demand of fast and small size speechrecognition engine is increasing.
One example isthe mobile automatic speech translation device.
Toimplement the speech translation function, we needto integrate the speech recognition, the text transla-tion, and the speech synthesis modules all togetherinto a single device.
Another example is recogni-tion of Point-of-Interests (POIs) on navigation de-vice.
The number of POIs used in a commercialnavigation system is about several hundreds ofthousands to one million.
To make a fast and moreefficient speech recognition engine, many compu-tationally efficient methods were reported and mul-ti-stage speech recognition is one of competitiveapproaches [1][2].The multi-stage speech recognition completesrecognition procedure through sequential two stagedecoding, the acoustic decoding and the lexicaldecoding.
The optional rescoring stage can followthe lexical decoding, depending on the application.In the acoustic decoding stage, we find the pho-neme sequence which has the maximum likelihoodfor a sequence of input acoustic feature vector.
Inthe lexical decoding, we recover the optimal wordsequence whose phone sequence has a minimaledit distance from an input phoneme sequencefrom the acoustic decoding stage.Comparing to the one-stage speech recognition,the multi-stage speech recognition can significant-ly reduce computation load.
This is because thelexical decoding stage in the multi-stage speechrecognition is repeated for every phoneme in theinput phoneme sequence, while the lexical decod-ing stage in the one-stage speech recognition isrepeated for typically every ten milliseconds.Since the duration of a phoneme is up to severalhundred milliseconds, this computational saving isquite big, especially for cases with a large lexicalsearch space.
However, the multi-stage speech rec-ognition has a shortcoming that the overall perfor-mance is highly affected by accuracy level of thephoneme recognizer.
Moreover, the performanceof the phoneme recognizer is generally poor sinceit depends only on the acoustic feature without us-ing any higher level of information like a languagemodel.In this paper, we propose a new method of usinga confidence vector as an input feature for lexicaldecoding stage to improve performance of multi-stage speech recognition system.
For a phonemesegment, we introduce a confidence vector inwhich each element is defined as the likelihood ofeach phoneme for the given segment.
And, we usethis confidence vector as the input feature for thelexical decoder rather than just the phoneme se-quence as in the conventional multi-stage speechrecognition.
This means that more information istransferred from acoustic decoder to lexical decod-er.This paper is organized as follows.
At first, wepresent the structure of multi-stage speech recogni-tion in section 2.
In section 3, we describe the pro-posed method that uses confidence vector as aninput feature of lexical decoding.
In section 4, weexplain the experiment environment and results.Finally, we summarize our work in section 5.2 Multi-Stage Speech RecognitionMulti-stage speech recognition system is com-posed of acoustic decoder, lexical decoder and op-tional n-best rescoring [2][3].The purpose of acoustic decoding is to convertan input acoustic feature sequence into a corres-ponding phoneme sequence as correctly as possiblewhile minimizing the consumption of computa-tional power.
In most cases, CDHMM-based au-tomatic phone recognizer is used for acoustic de-coding.
In this work, we also used automatic phonerecognizer for the acoustic decoding, in whichCDHMMs corresponding to 46 Korean phonemesincluding silence are used and a finite state net-work representing Korean syllable compositionstructure is used for pronunciation model.The purpose of the lexical decoding is to recoveran optimal word sequence from input phonemesequence given as a result of acoustic decoding.Acoustic decoder may generate three types ofphone errors, substitution, insertion and deletionfor a reference phoneme due to inaccurate acousticmodeling, surrounding noises and so on.
We modelthese error patterns in the form of probabilistic editcost.
For each speech utterance in training DB, thelexical decoder aligns phoneme sequence from theacoustic decoder with the phoneme sequence ofreference words by dynamic time warping (DTW).By accumulating the alignment results for all theutterances in training DB, we obtain the substitu-tion probability of each phoneme.
While decoding,the cost at each node is derived from the substitu-tion probability of each phoneme.3 Confidence Vector Based ApproachIn this paper, we introduce a phoneme confidencevector as an input feature for lexical decoding.This confidence vector based approach comprisesfour stages, phoneme segmentation, confidencevector extraction, lexical decoding, n-bestrescoring.
Figure 1 illustrates a block diagram ofthe multi-stage speech recognition usingconfidence vector.Figure 1.
Block diagram of multi-stage speechrecognition using confidence vector.Firstly, the automatic phoneme recognizer findsoptimal phoneme boundary information for aninput utterance and then every acoustic likelihoodcorresponding to each of 46 Korean phoneme unitsis calculated for each segment, according to thephone segmentation result.
Secondly, we define theconfidence value for each phoneme at a givenphoneme segment as follows,?==Njjlikelihoodilikelihoodiconfidence1)()()(     (1)where confidence(i) means confidence value of i?thphoneme and N is the number of phonemes.Because lexical decoding is a sort of dynamicprogramming, we need to define a local match costto weight distance between two phonemes.
Forconfidence vector approach, we defined lexicalmodel as mean of confidence vectors of each pho-neme.
The cost of DTW is defined with mean ofconfidence vectors of reference phoneme and con-fidence vectors of input speech segment.
We usethree cost definitions that represent distance be-tween two confidence vectors.Figure 2.
An input feature for lexical decoding,phoneme sequence and confidence vectors3.1 Kullback-Leibler DivergenceKullback-Leibler divergence measures a differencebetween two probability distributions.
If we regardthe confidence vector as a probability distribution,we can define the difference as cost.
Equation 2 isa cost definition by Kullback-Leibler divergencefor reference phoneme ?p?.
( ) ( )( )?= ????????
?=Ni p imififpft1log)|(cos   (2)In equation 2, f(i) is confidence value of i?thphoneme and mp(i) is i?th value of mean vector ofphoneme ?p?.3.2 Weighted Sum of ConfidenceThe second definition of cost is weighted sum ofconfidence.
As weight values, mean of confidencevector that was previously trained is used.
Thisweighted sum of confidence corresponds to substi-tution probability with consideration of prior prob-ability distribution.
It takes ?log to make cost valuefrom probability.
Equation 3 is a cost definition byweighted sum of confidence.
( ) ( )( )??????
?-= ?=Nip ifimpft1log)|(cos   (3)In equation 3, weight term can be considered asloss term of minimum risk decoding [4].
If theweight value is loss quantity of decision to pho-neme ?p?
with confidence f(i), decision for mini-mum cost is identical to decision for minimum risk.3.3 Smoothing of ConfidenceEven though we use weighted sum of confidenceinstead of substitution probability of best phonesequence, the cost is highly sensitive to the resultof acoustic decoder.
To prevent extreme decisionof phoneme recognizer, we add smoothing parame-ters, ?
and ?, like equation 4. ?
and ?
are assignedto be less then 1 and this gives effect to emphasizesmall values of probability.
( ) ( )( )??????
?-= ?=Nip ifimpft1log)|(cosba(4)4 Experiment Results4.1 Experiment on POI domainTo evaluate the performance of the proposed algo-rithm, we performed experiments on Korean POItask domain which is an isolate word recognitioncomposed of 220k POI entries.
Test set compriseswith 7 speakers, each speaker makes 99 utterances,so total test set is 693 utterances.The speech signal was sampled at 16kHz, andthe frame length was 20ms with 10ms shift.
Eachspeech frame was parameterized as a 39-dimentional feature vector containing 12 Mel-Frequency Cepstral Coefficients (MFCCs), C0energy, their delta and delta-delta coefficients.
Inorder to evaluate the robustness of the proposedalgorithm on acoustically, lexically mismatchedcondition, we took the experiments in two differenttest environment where N-fold test means the testis done in lexically matched condition and opentest in acoustically and lexically mismatched con-dition.N-fold TestIn order to reflect phoneme error patterns to thelexical decoding, we used the phoneme result of 6speaker?s utterance to train lexical model.
We per-formed test for remained one speaker data, and wedid 7 times with different test speakers.
Each casetraining data of lexical model is 594 utterances andtest data is 99 utterances.
Lexical model is substi-tution probability or mean of confidence vector forreference phoneme.Because training data of lexical model has thesame vocabulary with test data and the same chan-nel condition, training of lexical model in N-foldtest can train error pattern of same vocabulary andenvironment condition.
Table 1 shows the result ofN-fold test experiment.
Conventional multi-stagespeech recognition method uses phoneme sequenceas an input feature for lexical decoding, and its per-formance is the lowest among the rest methods.Because the phoneme accuracy of acoustic decoderis about 60~70% for this open test set, the perfor-mance of conventional method is degraded.
If weuse confidence vector as input feature for lexicaldecoding, the performance is increased by almost10%.
This performance enhancement proves thatthe confidence vector contains more useful infor-mation at lexical decoding.
The cost definitionwith weighted sum of confidence has a similar per-formance with Kullback-Leibler divergence that isa well known distance measure.
Especially withsmoothing of confidence we get the best perfor-mance, but smoothing makes the search networkenlarge and slow down a little because smoothingreduces the differences between confidence vectors.LexicalFeatureCost DefinitionN-best Word Recog-nition Rate (%)1 5 10PhonemeSequence Substitution Prob.
64.5 75.6 78.6Confi-denceVectorKL Divergence 74.5 88.7 91.8Weighted sum ofConfidence 74.5 88.5 92.4Smoothing ofConfidence 78.8 90.9 93.8Table 1.
Word Recognition Rate of N-fold testLexical Model Training with Open setIn N-fold test, environment condition and errorpattern of certain vocabulary is trained althoughwe do not intend to do so.
For an open test, wetrained lexical model using word DB.
We usedETRI phonetically optimized word (POW) DBwhich has 92k utterances.Table 2 shows the results of open test experi-ments.
If we use phoneme sequence as input fea-ture for lexical decoder, performance is better thanN-fold test.
Because training DB for lexical modelis enlarged to 92k, substitution probability mightbe modeled correctly.
But confidence vector ap-proach shows some performance degradationsfrom N-fold test.
In N-fold test, the performance ishighly affected by the training of error pattern ofcertain vocabulary.
In open test, KL divergencehas better performance than cost definition byweighted sum of confidence in n-best aspect.
Andsmoothing method has the best performance.LexicalFeature Cost DefinitionN-best Word Recog-nition Rate (%)1 5 10PhonemeSequence Substitution Prob.
68.4 83.6 86.0Confi-denceVectorKL Divergence 71.4 86.6 90.9Weighted sum ofConfidence 71.3 83.8 87.2Smoothing ofConfidence 73.6 88.0 91.9Table 2.
Word Recognition Rate of Open testN-best RescoringN-best rescoring stage does one-pass search amongN-best result words.
We used 500-best result forN-best rescoring.
Table 3 shows the result of N-best rescoring.
In the N-best rescoring test we usedthe lexical model from POW DB.500-best performance of conventional multi-stage speech recognition system is 97.3%, andwhen we use confidence vector as input feature forlexical decoding with Kullback-Leibler divergencecost, our 500-best performance is 98.8% and 98.9%when we use weighted sum of confidence vector ascost.
When we use smoothing method, 500-bestperformance is 99.1%.
Since the performance ofN-best rescoring is highly dependent with 500-bestperformance, conventional multi-stage method hasthe worst rescoring performance.
Because 500-bestperformance of weighted sum of confidence andsmoothing method are similar, the performance ofN-best rescoring is almost same for these two costdefinitions.
If we use conventional one-pass de-coder, word recognition rate is 82.9%.
By N-bestrescoring we can achieves the same level of per-formance with the one-pass decoder.LexicalFeatureCost DefinitionN-best Word Recog-nition Rate (%)1 5 10PhonemeSequence Substitution Prob.
81.2 92.4 94.2Confi-denceVectorKL Divergence 82.0 94.2 95.5Weighted sum ofConfidence 83.2 94.5 95.9Smoothing of Con-fidence 82.0 94.5 95.8Table 3.
Word Recognition Rate of N-best Rescor-ingSpeed ImprovementBy dividing search procedure into acoustic andlexical parts, we can have the advantage of speed.In the acoustic decoder we used context-dependentmodel and a real-time factor of acoustic decoder is0.03 on 3G Hz Dual-core CPU machine.
Table 4shows the recognition speed of multi-stage speechrecognition system.
Multi-stage approach is about4-times faster than conventional one-pass decoder.If we use confidence vector as input feature forlexical decoding, we need additional amount ofcomputation to extract confidence values.
But thetotal speed is faster than conventional phonemesequence feature.
Since confidence vector featuremakes more discriminative cost in lexical decoding,the total number of active nodes of search networkis decreased and we can avoid increasing time.Decoder/Lexical Feature Real Time FactorOne-pass 1.16Multi-passPhoneme Sequence 0.29Confidence Vector 0.27Table 4.
Speed of multi-stage speech recognitionsystem4.2 Experiment on hotel reservation domainWe applied the proposed method to the dialogspeech recognition.
The acoustic decoder is sameas in the POI domain experiment.
The lexical de-coder searches the finite state network with class asits node which covers the 25,000 sentence tem-plates in the hotel reservation domain.
The testspeech data is composed of 2,161 sentences utteredby 50 speakers, which is covered by the sentencetemplates.
Table 5 shows that the use of the confi-dence vector is shown to be very effective, show-ing 29.6% error reduction rate to the conventionalmulti-stage method.
Also, the proposed approach isshown to be competitive to the one-stage speechrecognition while the execution speed is improvedmore than five times.Decoder/Lexical FeatureReal TimeFactorWord Accu-racy(%)One-Pass 1.17 95.90Multi-passSubstitution Prob.
0.33 95.71KL Divergence - 96.18Weighted sum ofConfidence 0.22 96.39Smoothing ofConfidence - 96.98Table 5.
Word accuracy and speed of multi-stagespeech recognition for hotel reservation domain5 ConclusionIn this paper, we proposed a new method of usingthe confidence vector as an input feature for lexicaldecoding in the multi-stage speech recognition.
Wealso introduced diverse cost definitions to measurethe difference between confidence vector and ref-erence vector.
By transferring more information inthe form of confidence vector to the lexical decod-ing, we can achieve better performance than theconventional method.
The experiment results showup to 16.4% ERR of word accuracy for  220k Ko-rean Point-of-Interest (POI) domain and 29.6%ERR of word accuracy for hotel reservation dialogdomain.Also, comparing to the one-pass decoder, theproposed method is shown to be far faster whilemaintaining competitive performance.
Thus, thismethod is appropriate to build an embedded speechrecognition engine on a mobile device.As a future research, we will investigate the pos-sibility of integrating the confidence vector ap-proach with a phoneme lattice as an input featurefor lexical decoding.
A plain phoneme lattice canconvey more information to lexical decoding, butmmay increase the computational complexitywithout any performance gain.
We expect its ad-vantage is maximized with combining the confi-dence vector approach.References[1] Victor Zue, James Glass, David Goodine, MichaelPhillips, and Stephanie Seneff.
The SUMMIT SpeechRecognition System: Phonological Modeling andLexical Access.
In Proc.
IEEE Int.
Conf.
Acoustics,Speech, Signal Processing, pp.
49-52, 1990.
[2] Hoon Chung, Ikjoo Chung.
Memory efficient andfast speech recognition system for low resource mo-bile devices.
In IEEE Transactions on ConsumerElectronics, Volume: 52, Issue: 3, pages 792 ?
796,2006.
[3] Hyungbae Jeon, Kyuwoong Hwang, Hoon Chung,Seunghi Kim, Jun Park, and Yunkeun Lee.
Multi-stage Speech Recognition for POI.
In Proc.
Confe-rence of Korean Society of Phonetic Sciences andSpeech Technology, pp.
131-134, 2007.
[4] Vaibhava Goel, Shankar Kuman, and William Byrne.Confidence Based Lattice Segmentation and Mini-mum Bayes-Risk Decoding.
In Proc.
Conference ofEurospeech, 2001.
