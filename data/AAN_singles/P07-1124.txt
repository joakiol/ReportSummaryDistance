Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 984?991,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsSentiment Polarity Identification in Financial News:A Cohesion-based ApproachAnn DevittSchool of Computer Science & Statistics,Trinity College Dublin, IrelandAnn.Devitt@cs.tcd.ieKhurshid AhmadSchool of Computer Science & Statistics,Trinity College Dublin, IrelandKhurshid.Ahmad@cs.tcd.ieAbstractText is not unadulterated fact.
A text canmake you laugh or cry but can it also makeyou short sell your stocks in company A andbuy up options in company B?
Research inthe domain of finance strongly suggests thatit can.
Studies have shown that both theinformational and affective aspects of newstext affect the markets in profound ways, im-pacting on volumes of trades, stock prices,volatility and even future firm earnings.
Thispaper aims to explore a computable metricof positive or negative polarity in financialnews text which is consistent with humanjudgments and can be used in a quantita-tive analysis of news sentiment impact on fi-nancial markets.
Results from a preliminaryevaluation are presented and discussed.1 IntroductionResearch in sentiment analysis has emerged to ad-dress the research questions: what is affect in text?what features of text serve to convey it?
how canthese features be detected and measured automati-cally.
Sentence and phrase level sentiment analy-sis involves a systematic examination of texts, suchas blogs, reviews and news reports, for positive,negative or neutral emotions (Wilson et al, 2005;Grefenstette et al, 2004).
The term ?sentimentanalysis?
is used rather differently in financial eco-nomics where it refers to the derivation of marketconfidence indicators from proxies such as stockprices and trading volumes.
There is a traditiongoing back to the Nobel Sveriges?Riksbank Laure-ates Herbert Simon (1978 Prize) and Daniel Kah-neman (2002 Prize), that shows that investors andtraders in such markets can behave irrationally andthat this bounded rationality is inspired by what thetraders and investors hear from others about the con-ditions that may or may not prevail in the markets.Robert Engle (2003 Prize) has given a mathematicaldescription of the asymmetric and affective impactof news on prices: positive news is typically relatedto large changes in prices but only for a short time;conversely the effect of negative news on prices andvolumes of trading is longer lasting.
The emergentdomain of sociology of finance examines financialmarkets as social constructs and how communica-tions, such as e-mails and news reports, may beloaded with sentiment which could distort markettrading (MacKenzie, 2003).It would appear that news affects the marketsin profound ways, impacting on volumes of trade,stock returns, volatility of prices and even futurefirm earnings.
In the domain of news impact analy-sis in finance, in recent years the focus has expandedfrom informational to affective content of text in aneffort to explain the relationship between text andthe markets.
All text, be it news, blogs, accountingreports or poetry, has a non-factual dimension con-veying opinion, invoking emotion, providing a nu-anced perspective of the factual content of the text.With the increase of computational power and lex-ical and corpus resources it seems computationallyfeasible to detect some of the affective content oftext automatically.
The motivation for the work re-ported here is to identify a metric for sentiment po-984larity which reliably replicates human evaluationsand which is readily derivable from free text.
Thisresearch is being carried out in the context of a studyof the impact of news and its attendant biases onfinancial markets, formalizing earlier multi-lingual,corpus-based empirical work that analysed changein sentiment and volume of news in large financialnews corpora (Ahmad et al, 2006).
A systematicanalysis of the impact of news bias or polarity onmarket variables requires a numeric value for senti-ment intensity, as well as a binary tag for sentimentpolarity, to identify trends in the sentiment indica-tor as well as turning points.
In this approach, thecontribution to an overall sentiment polarity and in-tensity metric of individual lexical items which are?affective?
by definition is determined by their con-nectivity and position within a representation of thetext as a whole based on the principles of lexical co-hesion.
The contribution of each element is there-fore not purely additive but rather is mitigated by itsrelevance and position relative to other elements.Section 2 sets out related work in the sentimentanalysis domain both in computational linguisticsand in finance where these techniques have beenapplied with some success.
Section 3 outlines thecohesion-based algorithm for sentiment polarity de-tection, the resources used and the benefits of usingthe graph-based text representation approach.
Thisapproach was evaluated relative to a small corpus ofgold standard sentiment judgments.
The derivationof the gold standard and details of the evaluation areoutlined in section 4.
The results are presented anddiscussed in section 5 and section 6 concludes witha look at future challenges for this research.2 Related Work2.1 Cognitive Theories of EmotionIn order to understand how emotion can be realisedin text, we must first have a notion of what emo-tion is and how people experience it.
Current cogni-tive theories of what constitutes emotion are dividedbetween two primary approaches: categorical anddimensional.
The Darwinian categorical approachposits a finite set of basic emotions which are expe-rienced universally across cultures, (e.g.
anger, fear,sadness, surprise (Ekman and Friesen, 1971)).
Thesecond approach delineates emotions according tomultiple dimensions rather than into discrete cate-gories.
The two primary dimensions in this accountare a good?bad axis, the dimension of valence orevaluation, and a strong-weak axis, the dimensionof activation or intensity (Osgood et al, 1957).
Thework reported here aims to conflate the evaluationand activation dimensions into one metric with thesize of the value indicating strength of activation andits sign, polarity on the evaluation axis.2.2 Sentiment AnalysisSentiment analysis in computational linguistics hasfocused on examining what textual features (lexi-cal, syntactic, punctuation, etc) contribute to affec-tive content of text and how these features can bedetected automatically to derive a sentiment metricfor a word, sentence or whole text.
Wiebe and col-leagues have largely focused on identifying subjec-tivity in texts, i.e.
identifying those texts which areaffectively neutral and those which are not.
Thiswork has been grounded in a strong human evalu-ative component.
The subjectivity identification re-search has moved from initial work using syntacticclass, punctuation and sentence position features forsubjectivity classifiers to later work using more lex-ical features like gradation of adjectives or word fre-quency (Wiebe et al, 1999; Wiebe et al, 2005).
Oth-ers, such as Turney (2002), Pang and Vaithyanathan(2002), have examined the positive or negative po-larity, rather than presence or absence, of affectivecontent in text.
Kim and Hovy (2004), among oth-ers, have combined the two tasks, identifying sub-jective text and detecting its sentiment polarity.
Theindicators of affective content have been drawn fromlexical sources, corpora and the world wide web andcombined in a variety of ways, including factor anal-ysis and machine learning techniques, to determinewhen a text contains affective content and what isthe polarity of that content.2.3 Sentiment and News Impact AnalysisNiederhoffer (1971), academic and hedge fund man-ager, analysed 20 years of New York Times head-lines classified into 19 semantic categories and on agood-bad rating scale to evaluate how the marketsreacted to good and bed news: he found that mar-kets do react to news with a tendency to overreactto bad news.
Somewhat prophetically, he suggests985that news should be analysed by computers to intro-duce more objectivity in the analysis.
Engle and Ng(1993) proposed the news impact curve as a modelfor how news impacts on volatility in the marketwith bad news introducing more volatility than goodnews.
They used the market variable, stock returns,as a proxy for news, an unexpected drop in returnsfor bad news and an unexpected rise for good news.Indeed, much early work used such market variablesor readily quantifiable aspects of news as a proxy forthe news itself: e.g.
news arrival, type, provenanceand volumes (Cutler et al, 1989; Mitchell and Mul-herin, 1994).
More recent studies have proceededin a spirit of computer-aided objectivity which en-tails determining linguistic features to be used toautomatically categorise text into positive or nega-tive news.
Davis et al(2006) investigate the effectsof optimistic or pessimistic language used in finan-cial press releases on future firm performance.
Theyconclude that a) readers form expectations regard-ing the habitual bias of writers and b) react morestrongly to reports which violate these expectations,strongly suggesting that readers, and by extensionthe markets, form expectations about and react to notonly content but also affective aspects of text.
Tet-lock (2007) also investigates how a pessimism fac-tor, automatically generated from news text throughterm classification and principal components analy-sis, may forecast market activity, in particular stockreturns.
He finds that high negativity in news pre-dicts lower returns up to 4 weeks around story re-lease.
The studies establish a relationship betweenaffective bias in text and market activity that marketplayers and regulators may have to address.3 Approach3.1 Cohesion-based Text RepresentationThe approach employed here builds on a cohesion-based text representation algorithm used in a newsstory comparison application described in (Devitt,2004).
The algorithm builds a graph representa-tion of text from part-of-speech tagged text withoutdisambiguation using WordNet (Fellbaum, 1998) asa real world knowledge source to reduce informa-tion loss in the transition from text to text-basedstructure.
The representation is designed within thetheoretical framework of lexical cohesion (Hallidayand Hasan, 1976).
Aspects of the cohesive struc-ture of a text are captured in a graph representationwhich combines information derived from the textand WordNet semantic content.
The graph structureis composed of nodes representing concepts in or de-rived from the text connected by relations betweenthese concepts in WordNet, such as antonymy or hy-pernymy, or derived from the text, such as adjacencyin the text.
In addition, the approach provides thefacility to manipulate or control how the WordNetsemantic content information is interpreted throughthe use of topological features of the knowledgebase.
In order to evaluate the relative contributionof WordNet concepts to the information content of atext as a whole, a node specificity metric was derivedbased on an empirical analysis of the distribution oftopological features of WordNet such as inheritance,hierarchy depth, clustering coefficients and node de-gree and how these features map onto human judg-ments of concept specificity or informativity.
Thismetric addresses the issue of the uneven populationof most knowledge bases so that the local idiosyn-cratic characteristics of WordNet can be mitigatedby some of its global features.3.2 Sentiment Polarity OverlayBy exploiting existing lexical resources for senti-ment analysis, an explicit affective dimension canbe overlaid on this basic text model.
Our approachto polarity measurement, like others, relies on a lex-icon of tagged positive and negative sentiment termswhich are used to quantify positive/negative senti-ment.
In this first iteration of the work, SentiWN(Esuli and Sebastiani, 2006) was used as it providesa readily interpretable positive and negative polarityvalue for a set of ?affective?
terms which conflatesOsgood?s (1957) evaluative and activation dimen-sions.
Furthermore, it is based on WordNet 2.0 andcan therefore be integrated into the existing text rep-resentation algorithm, where some nodes in the co-hesion graph carry a SentiWN sentiment value andothers do not.
The contribution of individual polar-ity nodes to the polarity metric of the text as a wholeis then determined with respect to the textual infor-mation and WN semantic and topological featuresencoded in the underlying graph representation ofthe text.
Three polarity metrics were implementedto evaluate the effectiveness of exploiting different986aspects of the cohesion-based graph structure.Basic Cohesion Metric is based solely on frequencyof sentiment-bearing nodes in or derived from thesource text, i.e.
the sum of polarity values for allnodes in the graph.Relation Type Metric modifies the basic metricwith respect to the types of WordNet relations in thetext-derived graph.
For each node in the graph, itssentiment value is the product of its polarity valueand a relation weight for each relation this node en-ters into in the graph structure.
Unlike most lexicalchaining algorithms, not all WordNet relations aretreated as equal.
In this sentiment overlay, the rela-tions which are deemed most relevant are those thatpotentially denote a relation of the affective dimen-sion, like antonymy, and those which constitute keyorganising principles of the database, such as hy-pernymy.
Potentially affect-effecting relations havethe strongest weighting while more amorphous rela-tions, such as ?also see?, have the lowest.Node Specificity Metric modifies the basic metricwith respect to a measure of node specificity calcu-lated on the basis of topographical features of Word-Net.
The intuition behind this measure is that highlyspecific nodes or concepts may carry more informa-tional and, by extension, affective content than lessspecific ones.
We have noted the difficulty of usinga knowledge base whose internal structure is not ho-mogeneous and whose idiosyncrasies are not quanti-fied.
The specificity measure aims to factor out pop-ulation sparseness or density in WordNet by evaluat-ing the contribution of each node relative to its depthin the hierarchy, its connectivity (branchingFactor)and its siblings:Spc = (depth+ln(siblings)?ln(branchingFactor))NormalizingFactor (1)The three metrics are further specialised accordingto the following two boolean flags:InText: the metric is calculated based on 1) onlythose nodes representing terms in the source text, or2) all nodes in the graph representation derived fromthe text.
In this way, the metrics can be calculatedusing information derived from the graph represen-tation, such as node specificity, without potentiallynoisy contributions from nodes not in the source textbut related to them, via relations such as hypernymy.Modifiers: the metric is calculated using all openclass parts of speech or modifiers alone.
On a cur-sory inspection of SentiWN, it seems that modifiershave more reliable values than nouns or verbs.
Thisoption was included to test for possible adverse ef-fects of the lexicon.In total for each metric there are four outcomes com-bining inText true/false and modifiers true/false.4 EvaluationThe goal of this research is to examine the relation-ship between financial markets and financial news,in particular the polarity of financial news.
The do-main of finance provides data and methods for solidquantitative analysis of the impact of sentiment po-larity in news.
However, in order to engage withthis long tradition of analysis of the instruments andrelated variables of the financial markets, the quan-titative measure of polarity must be not only easyto compute, it must be consistent with human judg-ments of polarity in this domain.
This evaluation isa first step on the path to establishing reliability fora sentiment measure of news.
Unfortunately, the fo-cus on news, as opposed to other text types, has itsdifficulties.
Much of the work in sentiment analy-sis in the computational linguistics domain has fo-cused either on short segments, such as sentences(Wilson et al, 2005), or on longer documents withan explicit polarity orientation like movie or prod-uct reviews (Turney, 2002).
Not all news items mayexpress overt sentiment.
Therefore, in order to testour hypothesis, we selected a news topic which wasconsidered a priori to have emotive content.4.1 CorpusMarkets react strongest to information about firmsto which they have an emotional attachment (Mac-Gregor et al, 2000).
Furthermore, takeovers andmergers are usually seen as highly emotive contexts.To combine these two emotion-enhancing factors,a corpus of news texts was compiled on the topicof the aggressive takeover bid of a low-cost airline(Ryanair) for the Irish flag-carrier airline (Aer Lin-gus).
Both airlines have a strong (positive and nega-tive) emotional attachment for many in Ireland.
Fur-thermore, both airlines are highly visible within thecountry and have vocal supporters and detractorsin the public arena.
The corpus is drawn from the987national media and international news wire sourcesand spans 4 months in 2006 from the flotation ofthe flag carrier on the stock exchange in Septem-ber 2006, through the ?surprise?
take-over bid an-nouncement by Ryanair, to the withdrawal of the bidby Ryanair in December 2006.14.2 Gold StandardA set of 30 texts selected from the corpus was anno-tated by 3 people on a 7-point scale from very pos-itive to very negative.
Given that a takeover bid hastwo players, the respondents were asked also to ratethe semantic orientation of the texts with respect tothe two players, Ryanair and Aer Lingus.
Respon-dents were all native English speakers, 2 female and1 male.
To ensure emotional engagement in the task,they were first asked to rate their personal attitude tothe two airlines.
The ratings in all three cases wereon the extreme ends of the 7 point scale, with verypositive attitudes towards the flag carrier and verynegative attitudes towards the low-cost airline.
Re-spondent attitudes may impact on their text evalu-ations but, given the high agreement of attitudes inthis study, this impact should at least be consistentacross the individuals in the study.
A larger studyshould control explicitly for this variable.As the respondents gave ratings on a ranked scale,inter-respondent reliability was determined usingKrippendorf?s alpha, a modification of the Kappacoefficient for ordinal data (Krippendorff, 1980).
Onthe general ranking scale, there was little agreement(kappa = 0.1685), corroborating feedback from re-spondents on the difficulty of providing a generalrating for text polarity distinct from a rating with re-spect to one of the two companies.
However, therewas an acceptable degree of agreement (Grove et al,1981) on the Ryanair and Aer Lingus polarity rat-ings, kappa = 0.5795 and kappa = 0.5589 respec-tively.
Results report correlations with these ratingswhich are consistent and, from the financial marketperspective, potentially more interesting.21A correlation analysis of human sentiment ratings withRyanair and Aer Lingus stock prices for the last quarter of 2006was conducted.
The findings suggest that stock prices were cor-related with ratings with respect to Aer Lingus, suggesting that,during this takeover period, investors may have been influencedby sentiment expressed in news towards Aer Lingus.
However,the timeseries is too short to ensure statistical significance.2Results in this paper are reported with respect to the4.3 Performance MetricsThe performance of the polarity algorithm was eval-uated relative to a corpus of human-annotated newstexts, focusing on two separate dimensions of polar-ity:1.
Polarity direction: the task of assigning a bi-nary positive/negative value to a text2.
Polarity intensity: the task of assigning a valueto indicate the strength of the negative/positivepolarity in a text.Performance on the former is reported using stan-dard recall and precision metrics.
The latter is re-ported as a correlation with average human ratings.4.4 BaselineFor the metrics in section 3, the baseline for compar-ison sums the SentiWN polarity rating for only thoselexical items present in the text, not exploiting anyaspect of the graph representation of the text.
Thisbaseline corresponds to the Basic Cohesion Metric,with inText = true (only lexical items in the text)and modifiers = false (all parts of speech).5 Results and Discussion5.1 Binary Polarity AssignmentThe baseline results for positive ratings, negative rat-ings and overall accuracy for the task of assigning apolarity tag are reported in table 1.
The results showType Precision Recall FScorePositive 0.381 0.7273 0.5Negative 0.667 0.3158 0.4286Overall 0.4667 0.4667 0.4667Table 1: Baseline resultsthat the baseline tends towards the positive end ofthe rating spectrum, with high recall for positive rat-ings but low precision.
Conversely, negative ratingshave high precision but low recall.
Figures 1 to 3illustrate the performance for positive, negative andoverall ratings of all metric?inText?Modifier combi-nations, enumerated in table 2, relative to this base-line, the horizontal.
Those metrics which surpassthis line are deemed to outperform the baseline.Ryanair ratings as they had the highest inter-rater agreement.9881 Cohesion 5 Relation 9 NodeSpec2 CohesionTxt 6 RelationTxt 10 NodeSpecTxt3 CohesionMod 7 RelationMod 11 NodeSpecMod4 CohesionTxtMod 8 RelationTxtMod 12 NodeSpecTxtModTable 2: Metric types in Figures 1-3Figure 1: F Score for Positive RatingsAll metrics have a bias towards positive ratingswith attendant high positive recall values and im-proved f-score for positive polarity assignments.The Basic Cohesion Metric marginally outperformsthe baseline overall indicating that exploiting thegraph structure gives some added benefit.
For theRelations and Specificity metrics, system perfor-mance greatly improves on the baseline for themodifiers = true options, whereas, when all partsof speech are included (modifier = false), perfor-mance drops significantly.
This sensitivity to inclu-sion of all word classes could suggest that modifiersare better indicators of text polarity than other wordclasses or that the metrics used are not appropriateto non-modifier parts of speech.
The former hypoth-esis is not supported by the literature while the latteris not supported by prior successful application ofthese metrics in a text comparison task.
In order toinvestigate the source of this sensitivity, we intend toexamine the distribution of relation types and nodespecificity values for sentiment-bearing terms to de-termine how best to tailor these metrics to the senti-ment identification task.A further hypothesis is that the basic polarity val-ues for non-modifiers are less reliable than for ad-jectives and adverbs.
On a cursory inspection of po-larity values of nouns and adjectives in SentiWN, itwould appear that adjectives are somewhat more re-liably labelled than nouns.
For example, crime andFigure 2: F Score for Negative Ratingssome of its hyponyms are labelled as neutral (e.g.forgery) or even positive (e.g.
assault) whereas crim-inal is labelled as negative.
This illustrates a keyweakness in a lexical approach such as this: over-reliance on lexical resources.
No lexical resource isinfallible.
It is therefore vital to spread the associ-ated risk by using more than one knowledge source,e.g.
multiple sentiment lexica or using corpus data.Figure 3: F Score for All Ratings5.2 Polarity Intensity ValuesThe results on the polarity intensity task parallel theresults on polarity tag assignment.
Table 3 sets outthe correlation coefficients for the metrics with re-spect to the average human rating.
Again, the bestperformers are the relation type and node specificitymetrics using only modifiers, significant to the 0.05level.
Yet the correlation coefficients overall are notvery high.
This would suggest that perhaps the re-lationship between the human ranking scale and theautomatic one is not strictly linear.
Although the hu-man ratings map approximately onto the automati-989cally derived scale, there does not seem to be a clearone to one mapping.
The section that follows discussthis and some of the other issues which this evalua-tion process has brought to light.Metric inText Modifier CorrelationBasic Cohesion No No 0.47**Yes No 0.42*No Yes 0.47**Yes Yes 0.47**Relation Type No No -0.1**Yes No -0.13*No Yes 0.5**Yes Yes 0.38*Node Specificity No No 0.00Yes No -0.03No Yes 0.48**Yes Yes 0.38*Table 3: Correlation Coefficients for human ratings.**.
Significant at the 0.01 level.
*.
Significant at the 0.05 level.5.3 IssuesThe Rating Scale and ThresholdingOverall the algorithm tends towards the positive endof the spectrum in direct contrast to human raterswith 55-70% of all ratings being negative.
Further-more, the correlation of human to algorithm ratingsis significant but not strongly directional.
It wouldappear that there are more positive lexical items intext, hence the algorithm?s positive bias.
Yet muchof this positivity is not having a strong impact onreaders, hence the negative bias observed in theseevaluators.
This raises questions about the scale ofhuman polarity judgments: are people more sensi-tive to negativity in text?
is there a positive baselinein text that people find unremarkable and ignore?To investigate this issue, we will conduct a compar-ative corpus analysis of the distribution of positiveand negative lexical items in text and their perceivedstrengths in text.
The results of this analysis shouldhelp to locate sentiment turning points or thresholdsand establish an elastic sentiment scale which allowsfor baseline but disregarded positivity in text.The Impact of the LexiconThe algorithm described here is lexicon-based, fullyreliant on available lexical resources.
However, wehave noted that an over-reliance on lexica has itsdisadvantages, as any hand-coded or corpus-derivedlexicon will have some degree of error or inconsis-tency.
In order to address this issue, it is neces-sary to spread the risk associated with a single lex-ical resource by drawing on multiple sources, as in(Kim and Hovy, 2005).
The SentiWN lexicon usedin this implementation is derived from a seed wordset supplemented WordNet relations and as such ithas not been psychologically validated.
For this rea-son, it has good coverage but some inconsistency.Whissel?s Dictionary of Affect (1989) on the otherhand is based entirely on human ratings of terms.It?s coverage may be narrower but accuracy mightbe more reliable.
This dictionary also has the advan-tage of separating out Osgood?s (1957) evaluativeand activation dimensions as well as an ?imaging?rating for each term to allow a multi-dimensionalanalysis of affective content.
The WN Affect lexi-con (Valitutti et al, 2004) again provides somewhatdifferent rating types where terms are classified interms of denoting or evoking different physical ormental affective reactions.
Together, these resourcescould offer not only more accurate base polarity val-ues but also more nuanced metrics that may bettercorrespond to human notions of affect in text.The Gold StandardSentiment rating evaluation is not a straight-forwardtask.
Wiebe et al(2005) note many of the difficul-ties associated human sentiment ratings of text.
Asnoted above, it can be even more difficult when eval-uating news where the text is intended to appear im-partial.
The attitude of the evaluator can be all im-portant: their attitude to the individuals or organi-sations in the text, their professional viewpoint as amarket player or an ordinary punter, their attitude touncertainty and risk which can be a key factor in theworld of finance.
In order to address these issues forthe domain of news impact in financial markets, theexpertise of market professionals must be elicited todetermine what they look for in text and what view-point they adopt when reading financial news.
Ineconometric analysis, stock price or trading volumedata constitute an alternative gold standard, repre-senting a proxy for human reaction to news.
For eco-nomic significance, the data must span a time periodof several years and compilation of a text and stock990price corpus for a large scale analysis is underway.6 Conclusions and Future WorkThis paper presents a lexical cohesion based met-ric of sentiment intensity and polarity in text andan evaluation of this metric relative to human judg-ments of polarity in financial news.
We are con-ducting further research on how best to capture apsychologically plausible measure of affective con-tent of text by exploiting available resources and abroader evaluation of the measure relative to humanjudgments and existing metrics.
This research is ex-pected to contribute to sentiment analysis in finance.Given a reliable metric of sentiment in text, whatis the impact of changes in this value on marketvariables?
This involves a sociolinguistic dimensionto determine what publications or texts best charac-terise or are most read and have the greatest influ-ence in this domain and the economic dimension ofcorrelation with economic indicators.ReferencesKhurshid Ahmad, David Cheng, and Yousif Almas.
2006.Multi?lingual sentiment analysis in financial news streams.In Proc.
of the 1st Intl.
Conf.
on Grid in Finance, Italy.David M. Cutler, James M. Poterba, and Lawrence H. Sum-mers.
1989.
What moves stock prices.
Journal of PortfolioManagement, 79:223?260.Angela K. Davis, Jeremy M. Piger, and Lisa M. Sedor.
2006.Beyond the numbers: An analysis of optimistic and pes-simistic language in earnings press releases.
Technical re-port, Federal Reserve Bank of St Louis.Ann Devitt.
2004.
Methods for Meaningful Text Representationand Comparison.
Ph.D. thesis, Trinity College Dublin.Paul Ekman and W. V. Friesen.
1971.
Constants across culturesin the face and emotion.
Journal of Personality and SocialPsychology, 17:124?129.Robert F. Engle and Victor K. Ng.
1993.
Measuring and test-ing the impact of news on volatility.
Journal of Finance,48(5):1749?1778.Andrea Esuli and Fabrizio Sebastiani.
2006.
Sentiwordnet: Apublicly available lexical resource for opinion mining.
InProceedings of LREC 2006.Christiane Fellbaum.
1998.
WordNet,an electronic lexicaldatabase.
MIT Press.Gregory Grefenstette, Yan Qu, James G. Shanahan, andDavid A. Evans.
2004.
Coupling niche browsers and affectanalysis for an opinion mining application.
In Proceedingsof RIAO-04, pages 186?194.William N. Grove, Nancy C. Andreasen, Patricia McDonald-Scott, Martin B. Keller, and Robert W. Shapiro.
1981.
Reli-ability studies of psychiatric diagnosis.
theory and practice.Archives of General Psychiatry, 38:408?413.Michael A. K. Halliday and Ruqaiya Hasan.
1976.
Cohesion inEnglish.
Longman.Soo-Min Kim and Eduard Hovy.
2004.
Determining the senti-ment of opinions.
In Proceedings of COLING 2004.Soo-Min Kim and Eduard Hovy.
2005.
Automatic detection ofopinion bearing words and sentences.
In Proc.
of IJCNLP-05, Jeju Island, Korea.Klaus Krippendorff.
1980.
Content Analysis: an Introductionto its Methodology.
Sage Publications, Beverly Hills, CA.Donald G. MacGregor, Paul Slovic, David Dreman, andMichael Berry.
2000.
Imagery, affect, and financial judg-ment.
The Journal of Psychology and Financial Markets,1(2):104?110.Donald MacKenzie.
2003.
Long-term capital management andthe sociology of arbitrage.
Economy and Society, 32:349?380.Mark L. Mitchell and J. Harold Mulherin.
1994.
The impact ofpublic information on the stock market.
Journal of Finance,49(3):923?950.Victor Niederhoffer.
1971.
The analysis of world events andstock prices.
Journal of Business, 44(2):193?219.Charles E. Osgood, George J. Suci, and Percy H. Tannenbaum.1957.
The Measurement of meaning.
University of IllinoisPress, Chicago, Ill.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002.Thumbs up?
Sentiment classification using machine learningtechniques.
In Proc.
of EMNLP-02, pages 79?86.Paul C. Tetlock.
2007.
Giving content to investor sentiment:The role of media in the stock market.
Journal of Finance.forthcoming.Peter D. Turney.
2002.
Thumbs up or thumbs down?
semanticorientation applied to unsupervised classification of reviews.In Proceedings of ACL?02, pages 417?424.Alessandro Valitutti, Carlo Strapparava, and Oliviero Stock.2004.
Developing affective lexical resources.
PsychNologyJournal, 2(1):61?83.Cynthia Whissell.
1989.
The dictionary of affect in language.In R. Plutchik and H. Kellerman, editors, Emotion: theoryresearch and experience, volume 4.
Acad.
Press, London.Janyce M. Wiebe, Rebecca F. Bruce, and Thomas P. O?Hara.1999.
Development and use of a gold-standard data set forsubjectivity classifications.
In Proceedings of ACL-99.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.
An-notating expressions of opinions and emotions in language.Language Resources and Evaluation, 39:165?210.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005.Recognizing contextual polarity in phrase-level sentimentanalysis.
In Proc.
of HLT/EMNLP-2005, pages 347?354.991
