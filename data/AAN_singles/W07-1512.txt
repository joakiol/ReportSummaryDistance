Proceedings of the Linguistic Annotation Workshop, pages 69?76,Prague, June 2007. c?2007 Association for Computational LinguisticsComputing translation units and quantifying parallelismin parallel dependency treebanksMatthias Buch-KromannISV Computational Linguistics GroupCopenhagen Business Schoolmbk.isv@cbs.dkAbstractThe linguistic quality of a parallel tree-bank depends crucially on the parallelismbetween the source and target language an-notations.
We propose a linguistic notionof translation units and a quantitative mea-sure of parallelism for parallel dependencytreebanks, and demonstrate how the pro-posed translation units and parallelism mea-sure can be used to compute transfer rules,spot annotation errors, and compare differ-ent annotation schemes with respect to eachother.
The proposal is evaluated on the100,000 word Copenhagen Danish-EnglishDependency Treebank.1 IntroductionParallel treebanks are increasingly seen as a valuableresource for many different tasks, including machinetranslation, word alignment, translation studies andcontrastive linguistics (C?mejrek et al, 2004; Cyrus,2006; Hansen-Schirra et al, 2006).
However, theusefulness of a parallel treebank for these purposesis directly correlated with the degree of syntacticparallelism in the treebank.
Some non-parallelismis inevitable because two languages always differwith respect to their syntactic structure.
But non-parallelism can also be the result of differences inthe linguistic analyses of the source text and targettext, eg, with respect to whether noun phrases areheaded by nouns or determiners, whether conjunc-tions are headed by the first conjunct or the coordi-nator, whether prepositions are analyzed as heads oradjuncts in prepositional phrases, etc.In this paper, we focus on parallel dependencytreebanks that consist of source texts and trans-lations annotated with dependency analyses andword-alignments.
These requirements are directlysatisfied by the analytical layer of the PragueCzech-English Dependency Treebank (C?mejrek etal., 2004) and by the dependency layer of theCopenhagen Danish-English Dependency Treebank(Buch-Kromann et al, 2007).
The requirements arealso indirectly satisifed by parallel treebanks with aconstituent layer and a word alignment, eg (Han etal., 2002; Cyrus, 2006; Hansen-Schirra et al, 2006;Samuelsson and Volk, 2006), since it is possibleto transform constituent structures into dependencystructures ?
a procedure used in the CoNLL sharedtasks in 2006 and 2007 (Buchholz and Marsi, 2006).Finally, it is worth pointing out that the requirementsare also met by any corpus equipped with two dif-ferent dependency annotations since a text is alwaystrivially word-aligned with itself.
The methods pro-posed in the paper therefore apply to a wide rangeof parallel treebanks, as well as to comparing twomonolingual treebank annotations with each other.The paper is structured as follows.
In section 2,we define our notions of word alignments and de-pendencies.
In section 3, we define our notion oftranslation units and state an algorithm for comput-ing the translation units in a parallel dependencytreebank.
Finally, in sections 4, 5 and 6, we demon-strate how translation units can be used to computetransfer rules, quantify parallelism, spot annotationerrors, and compare monolingual and bilingual an-notation schemes with respect to each other.69Complement roles Adjunct rolesaobj adjectival object appa parenthetical appositionavobj adverbial object appr restrictive appositionconj conjunct of coordinator coord coordinationdobj direct object list unanalyzed sequenceexpl expletive subject mod modifieriobj indirect object modo dobj-oriented modifierlobj locative-directional obj.
modp parenthetical modifiernobj nominal object modr restrictive modifiernuma additive numeral mods subject-oriented mod.numm multiplicative numeral name additional proper namepart verbal particle namef additional first namepobj prepositional object namel additional last namepossd possessed in genitives pnct punctuation modifierpred subject/object predicate rel relative clauseqobj quotation object title title of personsubj subject xpl explification (colon)vobj verbal objectFigure 1: The main dependency roles in the dependency framework Discontinuous Grammar.2 Word alignments and dependenciesIn our linguistic analyses, we will assume that aword alignment W ?W ?
encodes a translational cor-respondence between the word clusters W and W ?
inthe source text and target text, ie, the word align-ment expresses the human intuition that the subsetW of words in the source text corresponds roughlyin meaning or function to the subset W ?
of words inthe target text.
The translations may contain addi-tions or deletions, ie, W and W ?
may be empty.We also assume that a dependency edge g r?
?dencodes a complement or adjunct relation between aword g (the governor) and a complement or adjunctphrase headed by the word d (the dependent), wherethe edge label r specifies the complement or adjunctdependency role.1 As an illustration of how comple-ment and adjunct relations can be encoded by meansof dependency roles, the most important dependencyroles used in the dependency framework Discontin-uous Grammar (Buch-Kromann, 2006) are shown inFigure 1.
Finally, we will assume that the depen-dencies form a tree (or a forest).
The tree may benon-projective, ie, it may contain crossing branches(technically, a dependency g r?
?d is projective if1Following standard dependency theoretic assumptions, wewill assume the following differences between complement andadjunct relations: (a) complements are lexically licensed bytheir governor, whereas adjuncts license their adjunct governor;(b) in the functor-argument structure, complements act as ar-guments of their governor, whereas adjuncts act as modifiersof their governor; (c) a governor can have several adjuncts withthe same adjunct role, whereas no two complements of the samegovernor can have the same complement role.XXskalmustkunonlykoncentrereconcentratesigselfomaboutYYsubj vobjmod dobj pobj nobjX has to concentrate only on Ysubj dobj vobj pobjmod nobjFigure 2: Parallel dependency treebank analysiswith word alignment and two monolingual depen-dency analyses.and only if g is a transitive governor of all the wordsbetween g and d).Figure 2 shows an example of this kind of analy-sis, based on the annotation conventions used in Dis-continuous Grammar and the associated Copenha-gen Danish-English Dependency Treebank (Buch-Kromann et al, 2007).
In the example, word align-ments are indicated by lines connecting Danish wordclusters with English word clusters, and dependen-cies are indicated by means of arrows that pointfrom the governor to the dependent, with the de-pendency role written at the arrow tip.
For ex-ample, the Danish word cluster ?koncentrere sig?
(?concentrate self?)
has been aligned with the En-glish word ?concentrate?, and the English phrase70headed by ?on?
is analyzed as a prepositional ob-ject of the verb ?concentrate.?
In the Danish de-pendency analysis, the dependency between the ad-verbial ?kun?
(?only?)
and its prepositional gover-nor ?om?
(?about?)
is non-projective because ?om?does not dominate the words ?koncentrere?
(?con-centrate?)
and ?selv?
(?self?
).Dependency analyses differ from phrase-structureanalyses in that phrases are a derived notion: in a de-pendency tree, each word has a derived phrase thatconsists of all the words that can be reached from theword by following the arrows.
For example, the En-glish word ?concentrate?
heads the phrase ?concen-trate only on Y,?
and the Danish word ?om?
headsthe discontinuous phrase ?kun .
.
.
om Y.?If a parallel dependency analysis is well-formed,in a sense to be made clear in the following sec-tion, each alignment edge corresponds to what wewill call a translation unit.
Intuitively, given analigment edge W ?W ?, we can create the cor-responding translation unit by taking the sourceand target subtrees headed by the words in Wand W ?, deleting all parallel adjuncts of W ?W ?,and replacing all remaining parallel dependentsof W ?W ?
with variables x1, .
.
.
,xn and x?1, .
.
.
,x?n.The resulting translation unit will be denoted byT (x1, .
.
.
,xn)?T ?
(x?1, .
.
.
,x?n), where T and T ?
de-note the source and target dependency trees in thetranslation unit.
For convenience, we will some-times use vector notation and write T (x)?T ?(x?
)instead of T (x1, .
.
.
,xn)?T ?
(x?1, .
.
.
,x?n).
Dependen-cies are usually defined as relations between words,but by an abuse of terminology, we will say that aword d is a dependent of an alignment edge W ?W ?provided d is a dependent of some word in W ?W ?and d is not itself contained in W ?W ?.Figure 3 shows the six translation units that canbe derived from the parallel dependency analysis inFigure 2, by means of the procedure outlined above.Each translation unit can be interpreted as a bidi-rectional translation rules: eg, the second translationunit in Figure 3 can be interpreted as a translationrule stating that a Danish dependency tree with ter-minals ?x1 skal x2?
can be translated into an Englishdependency tree with terminals ?x?1 has to x?2?
wherethe English phrases x?1,x?2 are translations of the Dan-ish phrases x1,x2, and vice versa.In the following section, we will go deeper intoXXx1x1skalmustx2x2koncentrereconcentratesigselfx1x1kunonlyomaboutx1x1YYsubj vobj dobj pobj nobjX x1?
has to x2?
concentrate x1?
only on x1?
Ysubj dobj vobj pobj nobjFigure 3: The six translation units derived from theparallel dependency analysis in Figure 2.the definition and interpretation of these rules.
Inparticular, unlike the essentially context-free trans-lation rules used in frameworks such as (Quirk etal., 2005; Ding, 2006; Chiang, 2007), we will notassume that the words in the translation rules are or-dered, and that the translation rules can only be usedin a way that leads to projective dependency trees.3 Translation units within a simpledependency-based translation modelIn many parallel treebanks, word alignments andsyntactic annotations are created independently ofeach other, and there is therefore no guarantee thatthe word or phrase alignments coincide with anymeaningful notion of translation units.
To rectifythis problem, we need to define a notion of trans-lation units that links the word alignments and thesource and target dependency analysis in a meaning-ful way, and we need to specify a procedure for con-structing a meaningful set of word alignments fromthe actual treebank annotation.Statistical machine translation models often em-body an explicit notion of translation units.
How-ever, many of these models are not applicable toparallel treebanks because they assume translationunits where either the source text, the target textor both are represented as word sequences withoutany syntactic structure (Galley et al, 2004; Marcuet al, 2006; Koehn et al, 2003).
Other SMT modelsassume translation units where the source and tar-get language annotation is based on either context-free grammar (Yamada and Knight, 2001; Chiang,2007) or context-free dependency grammar (Quirket al, 2005; Ding, 2006).
However, since non-71projectivity is not directly compatible with context-free grammar, and parallel dependency treebankstend to encode non-projective dependencies directly,the context-free SMT models are not directly appli-cable to parallel dependency treebanks in general.But the context-free SMT models are an importantinspiration for the simple dependency-based trans-lation model and notion of translation units that wewill present below.In our translation model, we will for simplicity as-sume that both the source dependency analysis andthe target dependency analysis are unordered trees,ie, dependency transfer and word ordering are mod-elled as two separate processes.
In this paper, weonly look at the dependency transfer and ignore theword ordering, as well as the probabilistic modellingof the rules for transfer and word ordering.
There arethree kinds of translation rules in the model:A. Complement rules have the form T (x)?T ?(x?
)where T (x) is a source dependency tree with vari-ables x = (x1, .
.
.
,xn), T ?(x?)
is a target dependencytree with variables x?
= (x?1, .
.
.
,x?n), the words in Tare aligned to the words in T ?, and the variables xk,x?kdenote parallel source and target subtrees.
The rulestates that a source tree T (x) can be transferred intoa target tree T ?(x?)
by transferring the source sub-trees in x into the target subtrees in x?.B.
Adjunct rules have the form (x a?
?T (y))?(x?
a??
?T ?(y?))
where T (y) is a source dependencytree, T ?(y?)
is a target dependency tree, and x,x?
arevariables that denote parallel adjunct subtrees withadjunct roles a,a?, respectively.
The rule states thatgiven a translation unit T (y)?T (y?
), an a-adjunctof any word in T can be translated into an a?-adjunctof any word in T ?.2C.
Addition/deletion rules have the form T (y)?(x?
a??
?T ?(y?))
and (x a?
?T (y))?T ?(y?)
where x,x?are variables that denote adjunct subtrees, and a,a?are adjunct relations.
The addition rule states thatan adjunct subtree x?
can be introduced into the tar-get tree T ?
in a translation unit T (y)?T (y?)
withoutany corresponding adjunct in the source tree T .
Sim-ilarly, the deletion rule states that the adjunct subtree2In the form stated here, adjunct rules obviously overgener-ate because they do not place any restrictions on the words in T ?that the target adjunct can attach to.
In a full-fledged translationmodel, the adjunct rules must be augmented with a probabilisticmodel that can keep track of these restrictions.XXskalmustkunonlykoncentrereconcentratesigselfomaboutYYsubj mod vobj dobj pobj nobjX has to concentrate only on Ysubj dobj vobj pobjmod nobjFigure 4: Parallel dependency analysis that is in-compatible with our translation model.x in the source tree T does not have to correspond toany adjunct in the target tree T ?.3The translation model places severe restrictionson the parallel dependency annotations.
For exam-ple, the annotation in Figure 4 is incompatible withour proposed translation model with respect to theadjunct ?only?, since ?only?
attaches to the verb?skal/must?
in the Danish analysis, but attaches tothe preposition ?on?
in the English analysis ?
ie, itdoes not satisfy a requirement that follows implicitlyfrom the adjunct rule: that corresponding source andtarget adjunct governors must belong to the sametranslation unit.
In our example, there are two waysof rectifying the problem: we can (a) correct the de-pendency analysis as shown in Figure 2, or (b) cor-rect the word alignment as shown in Figure 5.It can be shown that our translation model trans-lates into the following four requirements on paral-lel analyses ?
ie, the requirements are necessaryand sufficient for ensuring that the linguistic anno-tations are compatible with our translation model.In the following, two words are said to be coalignedif they belong to the same alignment edge.
A de-pendency edge d r?
?g is called internal if d and gare coaligned, and external otherwise.
A word w iscalled singular if it fails to be coaligned with at leastone word in the other language.Requirement I.
The internal dependencies withina translation unit must form two connected trees.
Ie,3As with adjunct rules, addition/deletion rules obviouslyovergenerate, and must be augmented with probabilistic mod-els that keep track of the precise characteristics of the adjunctsubtrees that are added to or deleted from the parallel analyses.72XXskalmustkunonlykoncentrereconcentratesigselfomaboutYYsubj mod vobj dobj pobj nobjX has to concentrate only on Ysubj dobj vobj pobjmod nobjFigure 5: Making the analysis from Figure 4 com-patible with our translation model by changing thealignment edges.in an alignment W ?W ?, the internal dependencieswithin W must form a connected source tree, andsimilarly for W ?.Requirement II.
The external dependencies be-tween translation units must form an acyclic graph.Ie, in an alignment W ?W ?, no word w ?W can becoaligned with an external transitive dependent ofany word in W ?, and vice versa.Requirement III.
Parallel external governors mustbe aligned to each other.
Ie, if two nodes n,n?
arecoaligned with external governor edges n r?
?g andn?
r??
?g?, then g and g?
must be coaligned.Requirement IV.
The graph contains no singularexternal complements.
If the source word c is a com-plement of governor g and c is not coaligned to anytarget word, then c and g must be coaligned to eachother; and similarly for target complements.A graph that satisfies all four requirements is saidto be well-formed with respect to our translationmodel.
It can be shown that we can always trans-form an ill-formed graph G into a well-formed graphG?
by merging alignment edges; G?
is then called areduction of G, and a reduction with a minimal num-ber of mergings is called a minimal reduction of G.In a well-formed graph, we will refer to an align-ment edge and its associated source and target de-pendency tree as a translation unit.It can be shown that minimal reductions can becomputed by means of the algorithm shown in Fig-ure 6.4 The body of the for-loop in Figure 6 ensures4In the algorithm, G is viewed as a directed graph that con-tains the source and target dependencies, and alignment edgesprocedure minimal-reduction(graph G)merge each alignment edge in G with itself(ie, ensure int.
connectedness & ext.
acyclicity)for each W ?W ?
in bottom-up order domerge W ?W ?
with all of its externalsingular complementsmerge all external governors of W ?W ?return the modified graph GFigure 6: Algorithm for computing the minimal re-duction of a graph G.Requirements III (coaligned external governors) andIV (no singular complements), and the merging op-eration is designed so that it ensures Requirements I(internal connectedness) and II (acyclicity).5The ill-formed analysis in Figure 4 has the mini-mal reduction shown in Figure 2, whereas the anal-yses in Figure 2 and 5 are well-formed, ie, they aretheir own minimal reductions.
In the remainder ofthe paper, we will describe how minimal reductionsand translation units can be used for extracting trans-fer rules, detecting annotation errors, and comparingdifferent annotation schemes with each other.4 Extracting transfer rules andquantifying parallelismThe complement, adjunct, and addition/deletionrules in our simple dependency transfer model canbe read off directly from the minimal reductions.Figure 7 shows the three complement rules inducedfrom Figure 4 via the minimal reduction in Figure5.
Figure 8 (repeated from Figure 3) shows the sixcomplement rules induced from the alternative anal-ysis in Figure 2.We have tested the extraction procedure on alarge scale by applying it to the 100,000 wordCopenhagen Danish-English Dependency Treebank(Buch-Kromann et al, 2007).
Figure 9 shows thepercentage of translation units with size at least nW ?W ?
are viewed as short-hands for the set of all bidirectionaledges that link two distinct nodes in W ?W ?.5The merging operation performs three steps: (a) replacetwo alignment edges W1?W ?1 and W2?W ?2 with their unionW ?W ?
where W = W1?W2 and W ?
= W ?1?W ?2; (b) mergeW ?W ?
with the smallest set of nodes that turns W and W ?
intoconnected dependency trees; (c) merge W ?W ?
with all nodeson cycles that involve at least one node from W ?W ?.73XXx1x1skalmustkoncentrereconcentratesigselfomaboutx2x2YYsubj vobj dobj pobj nobjX   x1?
has to concentrate on x2?
Ysubj dobj vobj pobj nobjFigure 7: The three complement rules induced fromFigure 4 via the minimal reduction in Figure 5.XXx1x1skalmustx2x2koncentrereconcentratesigselfx1x1kunonlyomaboutx1x1YYsubj vobj dobj pobj nobjX x1?
has to x2?
concentrate x1?
only on x1?
Ysubj dobj vobj pobj nobjFigure 8: The six complement rules induced fromthe minimal reduction in Figure 2 (repeated fromFigure 3).translation unit size npercenttunits withsize ?
nnormal scale(solid line)logarithmic scale(dotted line)0%10%20%30%40%50%60%70%80%90%100%2 10 20 30 40 50100%10%1%0.1%0.01%0.001%Figure 9: The percentage of translation units in theCopenhagen Danish-English Dependency Treebankwith size at least n, plotted on normal and logarith-mic scales.in the parallel treebank, where the size of a transla-tion unit is measured as the number of nodes in theassociated complement transfer rule.
The extractedtransfer rules are useful for many purposes, includ-ing machine translation, lexicography, contrastivelinguistics, and translation studies, but describingthese applications is outside the scope of this paper.5 Spotting annotation errorsTo the human annotator who must check the word-aligned dependency analyses in a parallel depen-dency treebank, the analyses in Figure 2 and Fig-ure 4 look almost identical.
However, from the in-duced translation units and the associated comple-ment rules shown above, it would have been im-mediately obvious to the annotator that the analy-sis in Figure 2 is significantly better than the analy-sis in Figure 4.
This suggests that we can increasethe quality of the human annotation in parallel tree-bank projects by designing annotation tools that con-tinuously compute the induced translation units andpresent them visibly to the human annotator.From a linguistic point of view, it can be expectedthat errors in the dependency annotation will oftenshow up as non-parallelism that results in a largeinduced translation unit.
So in a parallel depen-dency treebank, we can identify the most egregiousexamples of non-parallelism errors automatically bycomputing the induced translation units, and sortingthem with respect to their size; the largest translationunits will then have a high probability of being theresult of annotation errors.To confirm our linguistic expectation that largetranslation units are often caused by annotation er-rors, we have selected a sample of 75 translationunits from the Copenhagen Danish-English Depen-dency Treebank, distributed more or less uniformlywith respect to translation unit size in order to ensurethat all translation unit sizes are sampled evenly.
Wehave then hand-checked each translation unit care-fully in order to determine whether the translationunit contains any annotation errors or not, giving usa data set of the form (C,N) where N is the sizeof the translation unit and C indicates whether thetranslation unit is correct (C = 1) or not (C = 0).Figure 10 shows our maximum likelihood estimateof the conditional probability P(C = 1|N = n) thata translation unit with size n is correct.6 From the6In order to estimate the conditional probability p(n) =P(C = 1|S = n) that a translation unit with size n is correct, wehave fitted p(n) to the parametric family p(n) = ?n?
by meansof conditional maximum likelihood estimation with conditionallikelihood L = ?75i=1 p(ni)ci(1?
p(ni))1?ci .
The resulting esti-74translation unit size nest.
percentcorrect tunitswith size = nnormal scale(solid line)logarithmic scale(dotted line)0%10%20%30%40%50%60%70%80%90%100%2 10 20 30 40 50100%10%1%0.1%0.01%0.001%Figure 10: The estimated percentage of translationunits with size n that are correct, plotted on normaland logarithmic scales.graph, we see that the correctness rate decreasesquickly with n. For example, only 55% of all trans-lation units with size 10 are correct, and only 13% ofall translation units with size 20 are correct.
Thus,the statistics confirm that large translation units areoften caused by annotation errors in the treebank,so focusing the effort on large translation units canmake the postediting more cost-efficient.
This alsosuggests that when developing algorithms for auto-matic annotation of parallel dependency treebanks,the algorithms can improve their accuracy by penal-izing large translation units.6 Comparing annotation schemesTranslation units can also be used to compare dif-ferent annotation schemes.
This is relevant in par-allel treebank projects where there are several pos-sible annotation schemes for one of the languages?
eg, because there is more than one treebank orrule-based parser for that language.
In this situa-tion, we have the freedom of choosing the anno-tation schemes for the source and target languagesso that they maximize the parallelism between thesource and target language annotations.
To make aninformed choice, we can create a small pilot paralleltreebank for each annotation scheme, and comparemates are ??
= 0.99 and ??
= 1.77 with confidence value 0.87, ie,if a data set D with the same translation unit sizes is generatedrandomly from the distribution p?
(n) = ??n??
, then the conditionallikelihood of D will be larger than the likelihood of our observeddata set in 87% of the cases.
This means that a two-sided testdoes not reject that the data are generated from the estimateddistribution p?
(n).the treebank annotations qualitatively by looking attheir induced translation units, and quantitatively bylooking at their average translation unit size.
Thebest choice of annotation schemes is then the com-bination that leads to the smallest and most sensibletranslation units.Since texts are always trivially word-aligned withthemselves, the same procedure applies to monolin-gual corpora where we want to compare two differ-ent dependency annotations with each other.
In thissetup, structural differences between the two mono-lingual annotation schemes will show up as largetranslation units.
While these structural differencesbetween annotation schemes could have been re-vealed by careful manual inspection, the automaticcomputation of translation units speeds up the pro-cess of identifying the differences.
The method alsosuggests that the conversion from one annotationscheme to another can be viewed as a machine trans-lation problem ?
that is, if we can create a machinetranslation algorithm that learns to translate fromone language to another on the basis of a paralleldependency treebank, then this algorithm can alsobe used to convert from one dependency annotationscheme to another, given a training corpus that hasbeen annotated with both annotation schemes.7 ConclusionIn this paper, we have addressed the problem thatthe linguistic annotations in parallel treebanks oftenfail to correspond to meaningful translation units,because of internal incompatibilities between the de-pendency analyses and the word alignment.
We havedefined a meaningful notion of translation units andprovided an algorithm for computing these transla-tion units from any parallel dependency treebank.Finally, we have sketched how our notion of trans-lation units can be used to aid the creation of par-allel dependency treebanks by using the translationunits as a visual aid for the human annotator, by us-ing translation unit sizes to identify likely annota-tion errors, and by allowing a quantitative and qual-itative comparison of different annotation schemes,both for parallel and monolingual treebanks.758 AcknowledgmentsThe work was supported by two grants fromthe Danish Research Council for the Humanities.Thanks to the anonymous reviewers for their help-ful comments.ReferencesMatthias Buch-Kromann, Ju?rgen Wedekind, and JakobElming.
2007.
The Copenhagen Danish-English De-pendency Treebank.
http://www.id.cbs.dk/?mbk/ddt-en.Matthias Buch-Kromann.
2006.
DiscontinuousGrammar.
A dependency-based model of humanparsing and language learning.
Dr.ling.merc.dissertation, Copenhagen Business School.http://www.id.cbs.dk/?mbk/thesis.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on Multilingual Dependency Parsing.
InProc.
CoNLL-2006.A.
Cahill, M. Burke, R. O?Donovan, J. van Genabith, andA.
Way.
2004.
Long-distance dependency resolutionin automatically acquired wide-coverage PCFG-basedLFG approximations.
In Proc.
of ACL-2004.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2).Martin C?mejrek, Jan Cur??
?n, Jir???
Havelka, Jan Hajic?, andVladislav Kubon?.
2004.
Prague Czech-English De-pendency Treebank.
Syntactically annotated resourcesfor machine translation.
In Proc.
LREC-2004.Lea Cyrus.
2006.
Building a resource for studying trans-lation shifts.
In Proc.
LREC-2006.Yuan Ding and Martha Palmer.
2005.
Machine transla-tion using Probabilistic Synchronous Dependency In-sertion Grammars.
In Proc.
ACL-2005.Yuan Ding.
2006.
Machine translation using Prob-abilistic Synchronous Dependency Insertion Gram-mars.
Ph.D. thesis, Univ.
of Pennsylvania.Michel Galley, Mark Hopkins, Kevin Knight, and DanielMarcu.
2004.
What?s in a translation rule?
In Proc.HLT/NAACL-2004.Chung-hye Han, Na-Rae Han, Eon-Suk Ko, and MarthaPalmer.
2002.
Development and evaluation of a Ko-rean treebank and its application to NLP.
In Proc.LREC-2002.Silvia Hansen-Schirra, Stella Neumann, and MihaelaVela.
2006.
Multi-dimensional annotation and align-ment in an English-German translation corpus.
InProc.
NLPXML-2006.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proc.HLT/NAACL-2003.Daniel Marcu, Wei Wang, Abdessamad Echihabi, andKevin Knight.
2006.
SPMT: Statistical machine trans-lation with syntactified target language phrases.
InProc.
EMNLP-2006.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Chris Quirk, Arul Menezes, and Colin Cherry.
2005.
De-pendency treelet translation: Syntactically informedphrasal SMT.
In Proc.
ACL-2005.Yvonne Samuelsson and Martin Volk.
2006.
Phrasealignment in parallel treebanks.
In Proc.
TLT-2006.K.
Uchimoto, Y. Zhang, K. Sudo, M. Murata, S. Sekine,and H. Isahara.
2004.
Multilingual aligned paralleltreebank corpus reflecting contextual information andits applications.
In Proc.
MLR-2004.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proc.
ACL-2001.76
