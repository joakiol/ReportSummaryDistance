Urdu and the Parallel Grammar ProjectMiriam ButtCent.
for Computational LinguisticsUMISTPO Box 88Manchester M60 1QD GBmutt@csli.stanford.eduTracy Holloway KingPalo Alto Research Center3333 Coyote Hill Rd.Palo Alto, CA 94304 USAthking@parc.comAbstractWe report on the role of the Urdu grammar in theParallel Grammar (ParGram) project (Butt et al,1999; Butt et al, 2002).1 The ParGram project wasdesigned to use a single grammar development plat-form and a unified methodology of grammar writ-ing to develop large-scale grammars for typologi-cally different languages.
At the beginning of theproject, three typologically similar European gram-mars were implemented.
The addition of two Asianlanguages, Urdu and Japanese, has shown that thebasic analysis decisions made for the European lan-guages can be applied to typologically distinct lan-guages.
However, the Asian languages required theaddition of a small number of new standard analy-ses to cover constructions and analysis techniquesnot found in the European languages.
With these ad-ditional standards, the ParGram project can now beapplied to other typologically distinct languages.1 IntroductionIn this paper, we report on the role of the Urdugrammar in the Parallel Grammar (ParGram) project(Butt et al, 1999; Butt et al, 2002).
The ParGramproject originally focused on three closely relatedEuropean languages: English, French, and German.Once grammars for these languages were estab-lished, two Asian languages were added: Japaneseand Urdu.2 Both grammars have been successfullyintegrated into the project.
Here we discuss the Urdugrammar and what special challenges it brought tothe ParGram project.
We are pleased to report thatcreating an Urdu grammar within the ParGram stan-dards has been possible and has led to typologicallyuseful extensions to the project.The ParGram project uses the XLE parser1We would like to thank Mary Dalrymple, Ron Kaplan, Hi-roshi Masuichi, and Tomoko Ohkuma for their comments.2Norwegian was also added at this time.and grammar development platform (Maxwelland Kaplan, 1993) to develop deep grammarsfor six languages.
All of the grammars use theLexical-Functional Grammar (LFG) formalismwhich produces c(onstituent)-structures (trees)and f(unctional)-structures (AVMs) as syntacticanalyses.LFG assumes a version of Chomsky?s UniversalGrammar hypothesis, namely that all languages aregoverned by similar underlying structures.
WithinLFG, f-structures encode a language universal levelof analysis, allowing for cross-linguistic parallelism.The ParGram project aims to test the LFG formal-ism for its universality and coverage limitations andto see how far parallelism can be maintained acrosslanguages.
Where possible, the analyses producedfor similar constructions in each language are paral-lel.
This parallelism requires a standard for linguisticanalysis.
In addition, the LFG theory itself limits theset of possible analyses, thus restricting the possibleanalyses to choose from.
The standardization of theanalyses has the computational advantage that thegrammars can be used in similar applications, andit can simplify cross-language applications (Frank,1999).The conventions developed within the ParGramgrammars are extensive.
The ParGram project dic-tates not only the form of the features used in thegrammars, but also the types of analyses that arechosen for constructions.
In addition, the XLE plat-form necessarily restricts how the grammars can bewritten.
In all cases, the Urdu grammar has success-fully, and straightforwardly, incorporated the stan-dards that were originally designed for the Europeanlanguages.
In addition, it has contributed to the for-mulation of new standards of analysis.
Below wediscuss several aspects of this: morphology, lexicon,and grammar development for the Urdu grammarwithin the ParGram project.2 MorphologyThe grammars in the ParGram project depend onfinite-state morphologies as input (Beesley andKarttunen, 2002).
Without this type of resource, itis difficult to build large-scale grammars, especiallyfor languages with substantial morphology.
Forthe original three languages, such morphologieswere readily available.
As they had been developedfor information extraction applications instead ofdeep grammar applications, there were some minorproblems, but the coverage of these morphologiesis excellent.
An efficient, broad-coverage mor-phology was also available for Japanese (Asaharaand Matsumoto, 2000) and was integrated into thegrammar.
This has aided in the Japanese grammarrapidly achieving broad coverage.
It has also helpedcontrol ambiguity because in the case of Japanese,the morphology determines the part of speech ofeach word in the string with very little ambiguity.While some morphological analyzers al-ready exist for Hindi,3 e.g., as part of thetools developed at the Language Technolo-gies Research Centre (LTRC), IIT Hyderabad(http://www.iiit.net/ltrc/index.html), they are notimmediately compatible with the XLE grammardevelopment platform, nor is it clear that themorphological analyses they produce conform tothe standards and methods developed within theParGram project.
As such, part of the Urdu projectis to build a finite-state morphology that will serveas a resource to the Urdu grammar and could beused in other applications.The development of the Urdu morphology in-volves a two step process.
The first step is to de-termine the morphological class of words and theirsubtypes in Urdu.
Here we hope to use existing re-sources and lexicons.
The morphological paradigmswhich yield the most efficient generalizations froman LFG perspective must be determined.
Once thebasic paradigms and morphological classes havebeen identified, the second step is to enter all wordsin the language with their class and subtype informa-tion.
These steps are described below.
Currently weare working on the first step; grant money is beingsought for further development.The finite-state morphologies used in the Par-Gram project associate surface forms of words witha canonical form (a lemma) and a series of morpho-logical tags that provide grammatical information3An on-line morphological analyzer is available at:http://ccat.sas.upenn.edu/plc/tamilweb/hindi.htmlabout that form.
An example for English is shownin (1) and for Urdu in (2).
(1) pushes: push +Verb +Pres +3sgpush +Noun +Pl(2) bOlA bOl +Verb +Perf +Masc +Sg(1) states the English surface form pushes can eitherbe the third singular form of the verb push or the plu-ral of the noun push.
(2) states that the Urdu surfaceform bOlA is the perfect masculine singular form ofthe verb bOl.The first step of writing a finite-state morphologyfor Urdu involves determining which tags are as-sociated with which surface forms.
As can be seenfrom the above examples, determining the part ofspeech (e.g., verb, noun, adjective) is not enough forwriting deep grammars.
For verbs, tense, aspect, andagreement features are needed.
For nouns, numberand gender information is needed, as well as infor-mation as to whether it is a common or proper noun.Furthermore, for a number of problematic morpho-logical phenomena such as oblique inflection onnominal forms or default agreement on verbs, themost efficient method of analyzing this part of themorphology-syntax interface must be found (Buttand Kaplan, 2002).After having determined the tag ontology, the pat-terns of how the surface forms map to the stem-tagsets must be determined.
For example, in English thestem-tag set dog +Noun +Pl corresponds to the sur-face form dogs in which an s is added to the stem,while box +Noun +Pl corresponds to boxes in whichan es is added.
At this point in time, the basic tag setfor Urdu has been established.
However, the mor-phological paradigms that correspond to these tagcombinations have not been fully explored.Once the basic patterns are determined, the sec-ond stage of the process begins.
This stage involvesgreatly increasing the coverage of the morphologyby adding in all the stems in Urdu and marking themfor which set of tags and surface forms they appearwith.
This is a very large task.
However, by usingfrequency lists for the language and existing lexi-cons,4 the most common words can be added first toobtain a major gain in coverage.In addition, a guesser can be added to guess wordsthat the morphology does not yet recognize (Chanod4A web search on Hindi dictionary results in severalpromising sites.and Tapanainen, 1995).
This guessing is based onthe morphological form of the surface form.
For ex-ample, if a form ending in A is encountered and notrecognized, it could be considered a perfect mascu-line singular form, similar to bOlA in (2).3 LexiconOne advantage of the fact that the XLE system in-corporates large finite-state morphologies is that thelexicons for the languages can then be relativelysmall.
This is because lexicons are not needed forwords whose syntactic lexical entry can be deter-mined based on their morphological analysis.
This isparticularly true for nouns, adjectives, and adverbs.Consider the case of nouns.
The Urdu morphol-ogy provides the following analysis for the propernoun nAdyA.
(3) nAdyA +Noun +Name +FemThe tags provide the information that it is a noun, inparticular a type of proper noun (Name), and is fem-inine.
The lexical entries for the tags can then pro-vide the grammar with all of the features that it needsto construct the analysis of nAdyA; this resulting f-structure analysis is seen in Figures 2 and 4.
Thus,nAdyA itself need not be in the lexicon of the gram-mar because it is already known to the morphologi-cal analyzer.Items whose lexical entry cannot be predictedbased on the morphological tags need explicit lex-ical entries.
This is the case for items whose subcat-egorization frames are not predictable, primarily forverbs.
Currently, the Urdu verb lexicon is hand con-structed and only contains a few verbs, generally onefor each subcategorization frame for use in grammartesting.
To build a broad-coverage Urdu grammar, amore complete verb lexicon will be needed.
To pro-vide some idea of scale, the current English verb lex-icon contains entries for 9,652 verbs; each of thesehas an average of 2.4 subcategorization frames; assuch, there are 23,560 verb-subcategorization framepairs.
However, given that Urdu employs produc-tive syntactic complex predicate formation for muchof its verbal predication, the verb lexicon for Urduwill be smaller than its English counterpart.
On theother hand, writing grammar rules for the productivecombinatorial possibilities between adjectives andverbs (e.g., sAf karnA ?clean do?=?clean?
), nouns andverbs (e.g., yAd karnA ?memory do?=?remember?
)and verbs and verbs (e.g., kHA lEnA ?eat take?=?eatup?)
is anticipated to require significant effort.There are a number of ways to obtain a broad-coverage verb lexicon.
One is to extract the informa-tion from an electronic dictionary.
This does not ex-ist for Urdu, as far as we are aware.
Another is to ex-tract it from Urdu corpora.
Again, these would haveto be either collected or created as part of the gram-mar development project.
A final way is to enter theinformation by hand, depending on native speakerknowledge and print dictionaries; this option is verylabor intensive.
Fortunately, work is being done onverb subcategorization frames in Hindi.5 We plan toincorporate this information into the Urdu grammarverb lexicon.4 GrammarThe current Urdu grammar is relatively small, com-prising 25 rules (left-hand side categories) whichcompile into a collection of finite-state machineswith 106 states and 169 arcs.
The size of the othergrammars in the ParGram project are shown in (4)for comparison.
(4)Language Rules States ArcsGerman 444 4883 15870English 310 4935 13268French 132 1116 2674Japanese 50 333 1193Norwegian 46 255 798Urdu 25 106 169It is our intent to drastically expand the Urdu gram-mar to provide broad-coverage on standard (gram-matical, written) texts.
The current size of the Urdugrammar is not a reflection of the difficulty of thelanguage, but rather of the time put into it.
Like theJapanese and Norwegian grammars, it is less thantwo years in development, compared with sevenyears6 for the English, French, and German gram-mars.
However, unlike the Japanese and Norwe-gian grammars, there has been no full-time gram-mar writer on the Urdu grammar.
Below we discussthe Urdu grammar analyses and how they fit into theParGram project standardization requirements.Even within a linguistic formalism, LFG for Par-Gram, there is often more than one way to ana-5One significant effort is the Hindi Verb Project run by Prof.Alice Davison at the University of Iowa; further information isavailable via their web site.6Much of the effort in the initial years went into developingthe XLE platform and the ParGram standards.
Due to these ini-tial efforts, new grammars can be developed more quickly.lyze a construction.
Moreover, the same theoreti-cal analysis may have different possible implemen-tations in XLE.
These solutions often differ in ef-ficiency or conceptual simplicity.
Whenever possi-ble, the ParGram grammars choose the same anal-ysis and the same technical solution for equivalentconstructions.
This was done, for example, with im-peratives.
Imperatives are assigned a null pronomi-nal subject within the f-structure and a feature indi-cating that they are imperatives.Parallelism, however, is not maintained at the costof misrepresenting the language.
Situations arise inwhich what seems to be the same construction indifferent languages cannot have the same analysis.An example of this is predicate adjectives (e.g., Itis red.).
In English, the copular verb is consideredthe syntactic head of the clause, with the pronounbeing the subject and the predicate adjective be-ing an XCOMP.
However, in Japanese, the adjectiveis the main predicate, with the pronoun being thesubject.
As such, these constructions receive non-parallel analyses.Urdu contains several syntactic constructionswhich find no direct correlate in the Europeanlanguages of the ParGram project.
Examples arecorrelative clauses (these are an old Indo-Europeanfeature which most modern European languageshave lost), extensive use of complex predication,and rampant pro-drop.
The ability to drop argu-ments is not correlated with agreement or casefeatures in Urdu, as has been postulated for Italian,for example.
Rather, pro-drop in Urdu correlateswith discourse strategies: continuing topics andknown background information tend to be dropped.Although the grammars do not encode discourseinformation, the Japanese grammar analyzes pro-drop effectively via technical tools made availableby the grammar development platform XLE.
TheUrdu grammar therefore anticipates no problemswith pro-drop phenomena.In addition, many constructions which are stal-warts of English syntax do not exist in Asian lan-guages.
Raising constructions with seem, for exam-ple, find no clear correlate in Urdu: the constructionis translated via a psych verb in combination witha that-clause.
This type of non-correspondence be-tween European and South Asian languages raiseschallenges of how to determine parallelism acrossanalyses.
A similar example is the use of expletives(e.g., There is a unicorn in the garden.)
which do notexist in Urdu.4.1 Existing Analysis StandardsWhile Urdu contains syntactic constructions whichare not mirrored in the European languages, it sharesmany basic constructions, such as sentential com-plementation, control constructions, adjective-nounagreement, genitive specifiers, etc.
The basic analy-sis of these constructions was determined in the ini-tial stage of the ParGram project in writing the En-glish, French, and German grammars.
These analy-sis decisions have not been radically changed withthe addition of two typologically distinct Asian lan-guages, Urdu and Japanese.The parallelism in the ParGram project is pri-marily across the f-structure analyses which encodepredicate-argument structure and other features thatare relevant to syntactic analysis, such as tense andnumber.7 A sample analysis for the sentence in (5)is shown in Figures 1 and 2.
(5) nAdyA kA kuttA AyANadya Gen.M.Sg dog.Nom come-Perf.M.Sg?Nadya?s dog came.
?The Urdu f-structure analysis of (5) is similar to thatof its English equivalent.
Both have a PRED for theverb which takes a SUBJ argument at the top levelf-structure.
This top level structure also has TNS-ASP features encoding tense and aspect information,as well as information about the type of sentence(STMT-TYPE) and verb (VTYPE); these same fea-tures are found in the English structure.
The analy-sis of the subject is also the same, with the posses-sive being in the SPEC POSS and with features suchas NTYPE, NUM, and PERS.
The sentence in (5) in-volves an intransitive verb and a noun phrase with apossessive; these are both basic constructions whoseanalysis was determined before the Urdu gram-mar was written.
Yet, despite the extensive differ-ences between Urdu and the European languages?indeed, the agreement relations between the genitiveand the head noun are complex in Urdu but not inEnglish?there was no problem using the standardanalysis for the Urdu construction.4.2 New Analysis StandardsAnalyses of new constructions have been added forconstructions found in the new project languages.7The c-structures are less parallel in that the languages differsignificantly in their word orders.
Japanese and Urdu are SOVwhile English is SVO.
However, the standards for naming thenodes in the trees and the types of constituents formed in thetrees, such as NPs, are similar.CS 1: ROOTSKPNPKPpossNPNnAdyAKposskANkuttAVCmainVmainVAyAFigure 1: C-structure tree for (5)"nAdyA kA kuttA AyA"?A<[14:kutt]>?PRED?kutt?PREDmassGRAINNTYPE?Nadya?PREDnamePROPERNTYPE+SPECIFICCASE gen, GEND fem, NMORPH nom, NUM sg, PERS 30POSSSPECCASE nom, GEND masc, NUM sg, PERS 314SUBJperfASPECTinflMTYPEVMORPHPASSIVE ,  decl, VFORM perf, VTYPE unacc34Figure 2: F-structure AVM for (5)These analyses have not only established new stan-dards within the ParGram project, but have alsoguided the development of the XLE grammar de-velopment platform.
Consider the analysis of casein Urdu.
Although the features used in the analysisof case were sufficient for Urdu, there was a prob-lem with implementing it.
In Urdu, the case mark-ers constrain the environments in which they occur(Butt and King, to appear).
For example, the ergativemarker ne only occurs on subjects.
However, not allsubjects are ergative.
To the contrary, subjects canoccur in the ergative, nominative, dative, genitive,and instrumental cases.
Similarly, direct objects canbe marked with (at least) an accusative or nomina-tive, depending on the semantics of the clause.
Min-imal pairs such as in (6) for subjects and (7) for ob-jects suggest a constructive (Nordlinger, 1998) ap-proach to case.
(6) a. rAm kH ?As-ARam.Nom cough-Perf.M.Sg?Ram coughed.?b.
rAm nE kH ?As-ARam=Erg cough-Perf.M.Sg?Ram coughed (purposefully).?
(7) a. nAdyA nE gArI calAyINadya=Erg car.Nom drive-Perf.F.Sghaibe.Pres.3.Sg?Nadya has driven a car.?b.
nAdyA nE gArI kO calAyANadya=Erg car=Acc drive-Perf.M.Sghaibe.Pres.3.Sg?Nadya has driven the car.
?We therefore designed the lexical entries for the casemarkers so that they specify information about whatgrammatical relations they attach to and what se-mantic information is needed in the clausal analysis.The lexical entry for the ergative case, for example,states that it applies to a subject.These statements require inside-out functionaluncertainty (Kaplan, 1988) which had not been usedin the other grammars.
Inside-out functional uncer-tainty allows statements about the f-structure thatcontains an item.
The lexical entry for nE is shownin (8).
(8) nE K @(CASE erg) line 1(SUBJ ($) ? )
line 2@VOLITION line 3In (8), the K refers to the part of speech (a caseclitic).
Line 1 calls a template that assigns the CASEfeature the value erg; this is how case is done inthe other languages.
Line 2 provides the inside-outfunctional uncertainty statement; it states that the f-structure of the ergative noun phrase, referred to as?, is inside a SUBJ.
Finally, line 3 calls a templatethat assigns the volitionality features associated withergative noun phrases.
The analysis for (9) is shownin Figures 3 and 4.
(9) nAdyA nE yassin ko mArANadya=Erg Yassin=Acc hit-Perf.M.Sg?Nadya hit Yassin.
?CS 1: ROOTSKPNPNnAdyAKnEKPNPNyassinKkOVCmainVmainVmArAFigure 3: C-structure tree for (9)"nAdyA nE yassin kO mArA"?hit<[0:Nadya], [16:Yassin]>?PRED?Nadya?PREDnamePROPERNTYPE+SPECIFICCASE erg, GEND fem, NUM sg, PERS 30SUBJ?Yassin?PREDnamePROPERNTYPE+SPECIFICCASE acc, GEND masc, NUM sg, PERS 316OBJperfASPECTinflMTYPEVMORPHGEND masc, NUM sg, PASSIVE ,  decl, VFORM perf, VTYPE agentive32Figure 4: F-structure AVM for (9)There are two intesting points about this analy-sis of case in Urdu.
The first is that although theUrdu grammar processes case differently than theother grammars, the resulting f-structure in Figure4 is similar to its counterparts in English, German,etc.
English would have CASE nom on the subject in-stead of erg, but the remaining structure is the same:the only indication of case is the CASE feature.
Thesecond point is that Urdu tested the application ofinside-out functional uncertainty to case both theo-retically and computationally.
In both respects, theuse of inside-out functional uncertainty has proven asuccess: not only is it theoretically desirable for lan-guages like Urdu, but it is also implementationallyfeasible, efficiently providing the desired output.Another interesting example of how Urdu has ex-tended the standards of the ParGram project comesfrom complex predicates.
The English, French, andGerman grammars do not need a complex predicateanalysis.
However, as complex predicates form anessential and pervasive part of Urdu grammar, it isnecessary to analyze them in the project.
At first, weattempted to analyze complex predicates using theexisting XLE tools.
However, this proved to be im-possible to do productively because XLE did not al-low for the manipulation of PRED values outside ofthe lexicon.
Given that complex predicates in Urduare formed in the syntax and not the lexicon (Butt,1995), this poses a significant problem.
The syntac-tic nature of Urdu complex predicate formation is il-lustrated by (10), in which the two parts of the com-plex predicate l?kh ?write?
and diya ?gave?
can beseparated.
(10) a.
[anjum nE] [saddaf kO] [ciTTHI]Anjum.F=Erg Saddaf.F=Dat note.F.Nom[likHnE dI]write-Inf.Obl give-Perf.F.Sg?Anjum let Saddaf write a note.?b.
anjum nE dI saddaf kO [ciTTHI likHnE]c. anjum nE [ciTTHI likHnE] saddaf kO dIThe manipulation of predicational structures in thelexicon via lexical rules (as is done for the Englishpassive, for example), is therefore inadequate forcomplex predication.
Based on the needs of the Urdugrammar, XLE has been modified to allow the anal-ysis of complex predicates via the restriction oper-ator (Kaplan and Wedekind, 1993) in conjunctionwith predicate composition in the syntax.
These newtools are currently being tested by the implementa-tion of the new complex predicates analysis.5 ScriptOne issue that has not been dealt with in the Urdugrammar is the different script systems used forUrdu and Hindi.
As seen in the previous discussionsand the Figures, transcription into Latin ASCII iscurrently used by the Urdu grammar.
This is not alimitation of the XLE system: the Japanese grammarhas successfully integrated Japanese Kana and Kanjiinto their grammar.The approach taken by the Urdu grammar is dif-ferent from that of the Japanese, largely because twoscripts are involved.
The Urdu grammar uses theASCII transcription in the finite-state morphologiesand the grammar.
At a future date, a component willbe built onto the grammar system that takes Urdu(Arabic) and Hindi (Devanagari) scripts and tran-scribes them for use in the grammar.
This compo-nent will be written using finite-state technology andhence will be compatible with the finite-state mor-phology.
The use of ASCII in the morphology al-lows the same basic morphology to be used for bothUrdu and Hindi.
Samples of the scripts are seen in(11) for Urdu and (12) for Hindi.
(11)(12)6 ConclusionThe ParGram project was designed to use a singlegrammar development platform and a unifiedmethodology of grammar writing to developlarge-scale grammars for typologically differentlanguages.
At the beginning of the project, threetypologically similar European grammars wereused to test this idea.
The addition of two Asianlanguages, has shown that the basic analysis de-cisions made for the European languages can beapplied to typologically distinct languages.
How-ever, the Asian languages required the addition of afew new standard analyses to the project to coverconstructions and analysis techniques not foundin the European languages.
With this new set ofstandards, the ParGram project can now be appliedto other typologically distinct languages.The parallelism between the grammars in the Par-Gram project can be exploited in applications usingthe grammars: the fewer the differences, the simplera multi-lingual application can be.
For example, atranslation system that uses the f-structures as inputand output can take advantage of the fact that similarconstructions have the same analysis (Frank, 1999).The standardization also aids further grammar de-velopment efforts.
Many of the basic decisions aboutanalyses and formalism have already been made inthe project.
Thus, the grammar writer for a new lan-guage can use existing technology to bootstrap agrammar for the new language and can parse equiv-alent constructions in the existing languages to seehow to analyze a construction.
This allows the gram-mar writer to focus on more difficult constructionsnot yet encountered in the existing grammars.ReferencesMasayuki Asahara and Yuji Matsumoto.
2000.
Ex-tended models and tools for high-performancepart-of-speech tagger.
In Proceedings of COL-ING.Kenneth Beesley and Lauri Karttunen.
2002.Finite-State Morphology: Xerox Tools andTechniques.
Cambridge University Press.
ToAppear.Miriam Butt and Ron Kaplan.
2002.
The mor-phology syntax interface in LFG.
Presented atLFG02, Athens, Greece; to appear in the proceed-ings (CSLI Publications).Miriam Butt and Tracy Holloway King.
to appear.The status of case.
In Veneeta Dayal and AnoopMahajan, editors, Clause Structure in South AsianLanguages.
Kluwer.Miriam Butt, Tracy Holloway King, Mar?
?a-EugeniaNin?o, and Fre?de?rique Segond.
1999.
A GrammarWriter?s Cookbook.
CSLI Publications.Miriam Butt, Helge Dyvik, Tracy Holloway King,Hiroshi Masuichi, and Christian Rohrer.
2002.The parallel grammar project.
In Proceedings ofCOLING 2002.
Workshop on Grammar Engi-neering and Evaluation.Miriam Butt.
1995.
The Structure of Complex Pred-icates in Urdu.
CSLI Publications.Jean-Pierrre Chanod and Pasi Tapanainen.
1995.Creating a tagset, lexicon, and guesser for aFrench tagger.
In Proceedings of the ACL SIG-DAT Workshop: From Texts To Tags.
Issues inMultilingual Language Analysis, pages 58?64.Anette Frank.
1999.
From parallel grammar devel-opment towards machine translation.
In Proceed-ings of MT Summit VII, pages 134?142.Ron Kaplan and Ju?rgen Wedekind.
1993.
Restric-tion and correspondence-based translation.
InProceedings of the Sixth European Conferenceof the Association for Computational Linguistics,pages 193?202.Ron Kaplan.
1988.
Correspondences and their in-verses.
Presented at the Titisee Workshop on Uni-fication Formalisms: Syntax, Semantics, and Im-plementation, Titisee, Germany.John T. Maxwell, III and Ron Kaplan.
1993.
Theinterface between phrasal and functional con-straints.
Computational Lingusitics, 19:571?589.Rachel Nordlinger.
1998.
Constructive Case: Evi-dence from Australian Languages.
CSLI Publica-tions.
