Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1105?1116,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsEnd-to-End Relation Extraction using LSTMson Sequences and Tree StructuresMakoto MiwaToyota Technological InstituteNagoya, 468-8511, Japanmakoto-miwa@toyota-ti.ac.jpMohit BansalToyota Technological Institute at ChicagoChicago, IL, 60637, USAmbansal@ttic.eduAbstractWe present a novel end-to-end neuralmodel to extract entities and relations be-tween them.
Our recurrent neural net-work based model captures both word se-quence and dependency tree substructureinformation by stacking bidirectional tree-structured LSTM-RNNs on bidirectionalsequential LSTM-RNNs.
This allows ourmodel to jointly represent both entities andrelations with shared parameters in a sin-gle model.
We further encourage detec-tion of entities during training and use ofentity information in relation extractionvia entity pretraining and scheduled sam-pling.
Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1%and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respec-tively.
We also show that our LSTM-RNN based model compares favorably tothe state-of-the-art CNN based model (inF1-score) on nominal relation classifica-tion (SemEval-2010 Task 8).
Finally, wepresent an extensive ablation analysis ofseveral model components.1 IntroductionExtracting semantic relations between entities intext is an important and well-studied task in in-formation extraction and natural language pro-cessing (NLP).
Traditional systems treat this taskas a pipeline of two separated tasks, i.e., namedentity recognition (NER) (Nadeau and Sekine,2007; Ratinov and Roth, 2009) and relationextraction (Zelenko et al, 2003; Zhou et al,2005), but recent studies show that end-to-end(joint) modeling of entity and relation is impor-tant for high performance (Li and Ji, 2014; Miwaand Sasaki, 2014) since relations interact closelywith entity information.
For instance, to learnthat Toefting and Bolton have an Organization-Affiliation (ORG-AFF) relation in the sentenceToefting transferred to Bolton, the entity informa-tion that Toefting and Bolton are Person and Orga-nization entities is important.
Extraction of theseentities is in turn encouraged by the presence ofthe context words transferred to, which indicate anemployment relation.
Previous joint models haveemployed feature-based structured learning.
Analternative approach to this end-to-end relation ex-traction task is to employ automatic feature learn-ing via neural network (NN) based models.There are two ways to represent relations be-tween entities using neural networks: recur-rent/recursive neural networks (RNNs) and convo-lutional neural networks (CNNs).
Among these,RNNs can directly represent essential linguis-tic structures, i.e., word sequences (Hammerton,2001) and constituent/dependency trees (Tai etal., 2015).
Despite this representation ability,for relation classification tasks, the previously re-ported performance using long short-term memory(LSTM) based RNNs (Xu et al, 2015b; Li et al,2015) is worse than one using CNNs (dos Santoset al, 2015).
These previous LSTM-based sys-tems mostly include limited linguistic structuresand neural architectures, and do not model entitiesand relations jointly.
We are able to achieve im-provements over state-of-the-art models via end-to-end modeling of entities and relations based onricher LSTM-RNN architectures that incorporatecomplementary linguistic structures.Word sequence and tree structure are known tobe complementary information for extracting rela-tions.
For instance, dependencies between words1105are not enough to predict that source and U.S.have an ORG-AFF relation in the sentence ?Thisis ...?, one U.S. source said, and the context wordsaid is required for this prediction.
Many tradi-tional, feature-based relation classification mod-els extract features from both sequences and parsetrees (Zhou et al, 2005).
However, previous RNN-based models focus on only one of these linguisticstructures (Socher et al, 2012).We present a novel end-to-end model to extractrelations between entities on both word sequenceand dependency tree structures.
Our model allowsjoint modeling of entities and relations in a sin-gle model by using both bidirectional sequential(left-to-right and right-to-left) and bidirectionaltree-structured (bottom-up and top-down) LSTM-RNNs.
Our model first detects entities and thenextracts relations between the detected entities us-ing a single incrementally-decoded NN structure,and the NN parameters are jointly updated usingboth entity and relation labels.
Unlike traditionalincremental end-to-end relation extraction models,our model further incorporates two enhancementsinto training: entity pretraining, which pretrainsthe entity model, and scheduled sampling (Ben-gio et al, 2015), which replaces (unreliable) pre-dicted labels with gold labels in a certain probabil-ity.
These enhancements alleviate the problem oflow-performance entity detection in early stagesof training, as well as allow entity information tofurther help downstream relation classification.On end-to-end relation extraction, we improveover the state-of-the-art feature-based model, with12.1% (ACE2005) and 5.7% (ACE2004) relativeerror reductions in F1-score.
On nominal relationclassification (SemEval-2010 Task 8), our modelcompares favorably to the state-of-the-art CNN-based model in F1-score.
Finally, we also ab-late and compare our various model components,which leads to some key findings (both positiveand negative) about the contribution and effec-tiveness of different RNN structures, input depen-dency relation structures, different parsing mod-els, external resources, and joint learning settings.2 Related WorkLSTM-RNNs have been widely used for sequen-tial labeling, such as clause identification (Ham-merton, 2001), phonetic labeling (Graves andSchmidhuber, 2005), and NER (Hammerton,2003).
Recently, Huang et al (2015) showed thatbuilding a conditional random field (CRF) layer ontop of bidirectional LSTM-RNNs performs com-parably to the state-of-the-art methods in the part-of-speech (POS) tagging, chunking, and NER.For relation classification, in addition to tra-ditional feature/kernel-based approaches (Zelenkoet al, 2003; Bunescu and Mooney, 2005), sev-eral neural models have been proposed in theSemEval-2010 Task 8 (Hendrickx et al, 2010),including embedding-based models (Hashimotoet al, 2015), CNN-based models (dos Santos etal., 2015), and RNN-based models (Socher et al,2012).
Recently, Xu et al (2015a) and Xu etal.
(2015b) showed that the shortest dependencypaths between relation arguments, which wereused in feature/kernel-based systems (Bunescuand Mooney, 2005), are also useful in NN-basedmodels.
Xu et al (2015b) also showed that LSTM-RNNs are useful for relation classification, but theperformance was worse than CNN-based models.Li et al (2015) compared separate sequence-basedand tree-structured LSTM-RNNs on relation clas-sification, using basic RNN model structures.Research on tree-structured LSTM-RNNs (Taiet al, 2015) fixes the direction of informationpropagation from bottom to top, and also cannothandle an arbitrary number of typed children as ina typed dependency tree.
Furthermore, no RNN-based relation classification model simultaneouslyuses word sequence and dependency tree informa-tion.
We propose several such novel model struc-tures and training settings, investigating the simul-taneous use of bidirectional sequential and bidi-rectional tree-structured LSTM-RNNs to jointlycapture linear and dependency context for end-to-end extraction of relations between entities.As for end-to-end (joint) extraction of relationsbetween entities, all existing models are feature-based systems (and no NN-based model has beenproposed).
Such models include structured pre-diction (Li and Ji, 2014; Miwa and Sasaki,2014), integer linear programming (Roth and Yih,2007; Yang and Cardie, 2013), card-pyramid pars-ing (Kate and Mooney, 2010), and global prob-abilistic graphical models (Yu and Lam, 2010;Singh et al, 2013).
Among these, structured pre-diction methods are state-of-the-art on several cor-pora.
We present an improved, NN-based alterna-tive for the end-to-end relation extraction.1106In 1909 ,Sidney Yateswas born in Chicago .B-PERL-PERword/POSembeddingsBi-LSTMhiddensoftmaxnsubjpass prep pobjYatesborninChicagoPHYSBi-TreeLSTMhiddensoftmaxSequence (Entity)Dependency (Relation)LSTM unitdropouttanhtanhdependency embeddingstanhlabel embeddingsembeddingsneural net / softmax??????Fig.
1: Our incrementally-decoded end-to-end relation extraction model, with bidirectional sequentialand bidirectional tree-structured LSTM-RNNs.3 ModelWe design our model with LSTM-RNNs that rep-resent both word sequences and dependency treestructures, and perform end-to-end extraction ofrelations between entities on top of these RNNs.Fig.
1 illustrates the overview of the model.
Themodel mainly consists of three representation lay-ers: a word embeddings layer (embedding layer),a word sequence based LSTM-RNN layer (se-quence layer), and finally a dependency subtreebased LSTM-RNN layer (dependency layer).
Dur-ing decoding, we build greedy, left-to-right entitydetection on the sequence layer and realize rela-tion classification on the dependency layers, whereeach subtree based LSTM-RNN corresponds toa relation candidate between two detected enti-ties.
After decoding the entire model structure, weupdate the parameters simultaneously via back-propagation through time (BPTT) (Werbos, 1990).The dependency layers are stacked on the se-quence layer, so the embedding and sequence lay-ers are shared by both entity detection and rela-tion classification, and the shared parameters areaffected by both entity and relation labels.3.1 Embedding LayerThe embedding layer handles embedding repre-sentations.
nw, np, ndand ne-dimensional vectorsv(w), v(p), v(d)and v(e)are embedded to words,part-of-speech (POS) tags, dependency types, andentity labels, respectively.3.2 Sequence LayerThe sequence layer represents words in a linear se-quence using the representations from the embed-ding layer.
This layer represents sentential con-text information and maintains entities, as shownin bottom-left part of Fig.
1.We represent the word sequence in a sentencewith bidirectional LSTM-RNNs (Graves et al,2013).
The LSTM unit at t-th word consists ofa collection of nls-dimensional vectors: an inputgate it, a forget gate ft, an output gate ot, a mem-ory cell ct, and a hidden state ht.
The unit re-ceives an n-dimensional input vector xt, the previ-ous hidden state ht?1, and the memory cell ct?1,and calculates the new vectors using the followingequations:it= ?
(W(i)xt+ U(i)ht?1+ b(i)), (1)ft= ?
(W(f)xt+ U(f)ht?1+ b(f)),ot= ?
(W(o)xt+ U(o)ht?1+ b(o)),ut= tanh(W(u)xt+ U(u)ht?1+ b(u)),ct= itut+ ftct?1,ht= ottanh(ct),where ?
denotes the logistic function,  denoteselement-wise multiplication, W and U are weightmatrices, and b are bias vectors.
The LSTM unitat t-th word receives the concatenation of wordand POS embeddings as its input vector: xt=[v(w)t; v(p)t].
We also concatenate the hidden statevectors of the two directions?
LSTM units corre-sponding to each word (denoted as??htand?
?ht) as1107its output vector, st=[??ht;?
?ht], and pass it to thesubsequent layers.3.3 Entity DetectionWe treat entity detection as a sequence labelingtask.
We assign an entity tag to each word us-ing a commonly used encoding scheme BILOU(Begin, Inside, Last, Outside, Unit) (Ratinov andRoth, 2009), where each entity tag represents theentity type and the position of a word in the entity.For example, in Fig.
1, we assign B-PER and L-PER (which denote the beginning and last wordsof a person entity type, respectively) to each wordin Sidney Yates to represent this phrase as a PER(person) entity type.We perform entity detection on top of the se-quence layer.
We employ a two-layered NN withan nhe-dimensional hidden layer h(e)and a soft-max output layer for entity detection.h(e)t= tanh(W(eh)[st; v(e)t?1] + b(eh))(2)yt= softmax(W(ey)h(e)t+ b(ey))(3)Here, W are weight matrices and b are bias vec-tors.We assign entity labels to words in a greedy,left-to-right manner.1During this decoding, weuse the predicted label of a word to predict thelabel of the next word so as to take label depen-dencies into account.
The NN above receives theconcatenation of its corresponding outputs in thesequence layer and the label embedding for its pre-vious word (Fig.
1).3.4 Dependency LayerThe dependency layer represents a relation be-tween a pair of two target words (correspondingto a relation candidate in relation classification) inthe dependency tree, and is in charge of relation-specific representations, as is shown in top-rightpart of Fig.
1.
This layer mainly focuses on theshortest path between a pair of target words in thedependency tree (i.e., the path between the leastcommon node and the two target words) sincethese paths are shown to be effective in relationclassification (Xu et al, 2015a).
For example, weshow the shortest path between Yates and Chicagoin the bottom of Fig.
1, and this path well capturesthe key phrase of their relation, i.e., born in.1We also tried beam search but this did not show improve-ments in initial experiments.We employ bidirectional tree-structured LSTM-RNNs (i.e., bottom-up and top-down) to representa relation candidate by capturing the dependencystructure around the target word pair.
This bidirec-tional structure propagates to each node not onlythe information from the leaves but also informa-tion from the root.
This is especially importantfor relation classification, which makes use of ar-gument nodes near the bottom of the tree, and ourtop-down LSTM-RNN sends information from thetop of the tree to such near-leaf nodes (unlike instandard bottom-up LSTM-RNNs).2Note that thetwo variants of tree-structured LSTM-RNNs byTai et al (2015) are not able to represent our tar-get structures which have a variable number oftyped children: the Child-Sum Tree-LSTM doesnot deal with types and the N -ary Tree assumesa fixed number of children.
We thus propose anew variant of tree-structured LSTM-RNN thatshares weight matrices Us for same-type childrenand also allows variable number of children.
Forthis variant, we calculate nlt-dimensional vectorsin the LSTM unit at t-th node with C(t) childrenusing following equations:it= ??
?W(i)xt+?l?C(t)U(i)m(l)htl+ b(i)?
?, (4)ftk= ??
?W(f)xt+?l?C(t)U(f)m(k)m(l)htl+ b(f)?
?,ot= ??
?W(o)xt+?l?C(t)U(o)m(l)htl+ b(o)?
?,ut= tanh?
?W(u)xt+?l?C(t)U(u)m(l)htl+ b(u)?
?,ct= itut+?l?C(t)ftlctl,ht= ottanh(ct),where m(?)
is a type mapping function.To investigate appropriate structures to repre-sent relations between two target word pairs, weexperiment with three structure options.
We pri-marily employ the shortest path structure (SP-Tree), which captures the core dependency pathbetween a target word pair and is widely used inrelation classification models, e.g., (Bunescu and2We also tried to use one LSTM-RNN by connecting theroot (Paulus et al, 2014), but preparing two LSTM-RNNsshowed slightly better performance in our initial experiments.1108Mooney, 2005; Xu et al, 2015a).
We also try twoother dependency structures: SubTree and Full-Tree.
SubTree is the subtree under the lowestcommon ancestor of the target word pair.
This pro-vides additional modifier information to the pathand the word pair in SPTree.
FullTree is the fulldependency tree.
This captures context from theentire sentence.
While we use one node type forSPTree, we define two node types for SubTree andFullTree, i.e., one for nodes on shortest paths andone for all other nodes.
We use the type mappingfunctionm(?)
to distinguish these two nodes types.3.5 Stacking Sequence and DependencyLayersWe stack the dependency layers (corresponding torelation candidates) on top of the sequence layer toincorporate both word sequence and dependencytree structure information into the output.
Thedependency-layer LSTM unit at the t-th word re-ceives as input xt=[st; v(d)t; v(e)t], i.e., the con-catenation of its corresponding hidden state vec-tors stin the sequence layer, dependency typeembedding v(d)t(denotes the type of dependencyto the parent3), and label embedding v(e)t(corre-sponds to the predicted entity label).3.6 Relation ClassificationWe incrementally build relation candidates usingall possible combinations of the last words of de-tected entities, i.e., words with L or U labels inthe BILOU scheme, during decoding.
For in-stance, in Fig.
1, we build a relation candidate us-ing Yates with an L-PER label and Chicago withan U-LOC label.
For each relation candidate, werealize the dependency layer dp(described above)corresponding to the path between the word pairp in the relation candidate, and the NN receives arelation candidate vector constructed from the out-put of the dependency tree layer, and predicts itsrelation label.
We treat a pair as a negative relationwhen the detected entities are wrong or when thepair has no relation.
We represent relation labelsby type and direction, except for negative relationsthat have no direction.The relation candidate vector is constructed asthe concatenation dp= [?hpA; ?hp1; ?hp2], where?hpAis the hidden state vector of the top LSTM3We use the dependency to the parent since the number ofchildren varies.
Dependency types can also be incorporatedinto m(?
), but this did not help in initial experiments.unit in the bottom-up LSTM-RNN (representingthe lowest common ancestor of the target wordpair p), and ?hp1, ?hp2are the hidden state vec-tors of the two LSTM units representing the firstand second target words in the top-down LSTM-RNN.4All the corresponding arrows are shown inFig.
1.Similarly to the entity detection, we employ atwo-layered NN with an nhr-dimensional hiddenlayer h(r)and a softmax output layer (with weightmatrices W , bias vectors b).h(r)p= tanh(W(rh)dp+ b(rh))(5)yp= softmax(W(ry)h(r)t+ b(ry))(6)We construct the input dpfor relation classifi-cation from tree-structured LSTM-RNNs stackedon sequential LSTM-RNNs, so the contributionof sequence layer to the input is indirect.
Fur-thermore, our model uses words for represent-ing entities, so it cannot fully use the entity in-formation.
To alleviate these problems, we di-rectly concatenate the average of hidden state vec-tors for each entity from the sequence layer tothe input dpto relation classification, i.e., d?p=[dp;1|Ip1|?i?Ip1si;1|Ip2|?i?Ip2si](Pair), whereIp1and Ip2represent sets of word indices in thefirst and second entities.5Also, we assign two labels to each word pair inprediction since we consider both left-to-right andright-to-left directions.
When the predicted labelsare inconsistent, we select the positive and moreconfident label, similar to Xu et al (2015a).3.7 TrainingWe update the model parameters includingweights, biases, and embeddings by BPTT andAdam (Kingma and Ba, 2015) with gradient clip-ping, parameter averaging, and L2-regularization(we regularize weights W and U , not the biasterms b).
We also apply dropout (Srivastava et al,2014) to the embedding layer and to the final hid-den layers for entity detection and relation classi-fication.We employ two enhancements, scheduled sam-pling (Bengio et al, 2015) and entity pretrain-ing, to alleviate the problem of unreliable pre-diction of entities in the early stage of training,4Note that the order of the target words corresponds to thedirection of the relation, not the positions in the sentence.5Note that we do not show this Pair in Fig.1 for simplic-ity.1109and to encourage building positive relation in-stances from the detected entities.
In scheduledsampling, we use gold labels as prediction in theprobability of ithat depends on the number ofepochs i during training if the gold labels are le-gal.
As for i, we choose the inverse sigmoid de-cay i= k/(k + exp(i/k)), where k(?
1) is ahyper-parameter that adjusts how often we use thegold labels as prediction.
Entity pretraining is in-spired by (Pentina et al, 2015), and we pretrainthe entity detection model using the training databefore training the entire model parameters.4 Results and Discussion4.1 Data and Task SettingsWe evaluate on three datasets: ACE05 and ACE04for end-to-end relation extraction, and SemEval-2010 Task 8 for relation classification.
We use thefirst two datasets as our primary target, and usethe last one to thoroughly analyze and ablate therelation classification part of our model.ACE05 defines 7 coarse-grained entity typesand 6 coarse-grained relation types between enti-ties.
We use the same data splits, preprocessing,and task settings as Li and Ji (2014).
We reportthe primary micro F1-scores as well as micro pre-cision and recall on both entity and relation extrac-tion to better explain model performance.
We treatan entity as correct when its type and the region ofits head are correct.
We treat a relation as correctwhen its type and argument entities are correct; wethus treat all non-negative relations on wrong en-tities as false positives.ACE04 defines the same 7 coarse-grained en-tity types as ACE05 (Doddington et al, 2004), butdefines 7 coarse-grained relation types.
We fol-low the cross-validation setting of Chan and Roth(2011) and Li and Ji (2014), and the preprocessingand evaluation metrics of ACE05.SemEval-2010 Task 8 defines 9 relation typesbetween nominals and a tenth type Other whentwo nouns have none of these relations (Hendrickxet al, 2010).
We treat this Other type as a nega-tive relation type, and no direction is considered.The dataset consists of 8,000 training and 2,717test sentences, and each sentence is annotated witha relation between two given nominals.
We ran-domly selected 800 sentences from the training setas our development set.
We followed the officialtask setting, and report the official macro-averagedF1-score (Macro-F1) on the 9 relation types.For more details of the data and task settings,please refer to the supplementary material.4.2 Experimental SettingsWe implemented our model using the cnn library.6We parsed the texts using the Stanford neural de-pendency parser7(Chen and Manning, 2014) withthe original Stanford Dependencies.
Based on pre-liminary tuning, we fixed embedding dimensionsnwto 200, np, nd, neto 25, and dimensions ofintermediate layers (nls, nltof LSTM-RNNs andnhe, nhrof hidden layers) to 100.
We initializedword vectors via word2vec (Mikolov et al, 2013)trained on Wikipedia8and randomly initialized allother parameters.
We tuned hyper-parameters us-ing development sets for ACE05 and SemEval-2010 Task 8 to achieve high primary (Micro- andMacro-) F1-scores.9For ACE04, we directly em-ployed the best parameters for ACE05.
The hyper-parameter settings are shown in the supplementarymaterial.
For SemEval-2010 Task 8, we also omit-ted the entity detection and label embeddings sinceonly target nominals are annotated and the task de-fines no entity types.
Our statistical significanceresults are based on the Approximate Randomiza-tion (AR) test (Noreen, 1989).4.3 End-to-end Relation Extraction ResultsTable 1 compares our model with the state-of-the-art feature-based model of Li and Ji (2014)10onfinal test sets, and shows that our model performsbetter than the state-of-the-art model.To analyze the contributions and effects of thevarious components of our end-to-end relation ex-traction model, we perform ablation tests on theACE05 development set (Table 2).
The perfor-mance slightly degraded without scheduled sam-pling, and the performance significantly degradedwhen we removed entity pretraining or removedboth (p<0.05).
This is reasonable because themodel can only create relation instances whenboth of the entities are found and, without theseenhancements, it may get too late to find some re-lations.
Removing label embeddings did not affect6https://github.com/clab/cnn7http://nlp.stanford.edu/software/stanford-corenlp-full-2015-04-20.zip8https://dumps.wikimedia.org/enwiki/20150901/9We did not tune the precision-recall trade-offs, but doingso can specifically improve precision further.10Other work on ACE is not comparable or performs worsethan the model by Li and Ji (2014).1110Corpus Settings Entity RelationP R F1 P R F1ACE05 Our Model (SPTree) 0.829 0.839 0.834 0.572 0.540 0.556Li and Ji (2014) 0.852 0.769 0.808 0.654 0.398 0.495ACE04 Our Model (SPTree) 0.808 0.829 0.818 0.487 0.481 0.484Li and Ji (2014) 0.835 0.762 0.797 0.608 0.361 0.453Table 1: Comparison with the state-of-the-art on the ACE05 test set and ACE04 dataset.Settings Entity RelationP R F1 P R F1Our Model (SPTree) 0.815 0.821 0.818 0.506 0.529 0.518?Entity pretraining (EP) 0.793 0.798 0.796 0.494 0.491 0.492*?Scheduled sampling (SS) 0.812 0.818 0.815 0.522 0.490 0.505?Label embeddings (LE) 0.811 0.821 0.816 0.512 0.499 0.505?Shared parameters (Shared) 0.796 0.820 0.808 0.541 0.482 0.510?EP, SS 0.781 0.804 0.792 0.509 0.479 0.494*?EP, SS, LE, Shared 0.800 0.815 0.807 0.520 0.452 0.484**Table 2: Ablation tests on the ACE05 development dataset.
* denotes significance at p<0.05, ** denotesp<0.01.Settings Entity RelationP R F1 P R F1SPTree 0.815 0.821 0.818 0.506 0.529 0.518SubTree 0.812 0.818 0.815 0.525 0.506 0.515FullTree 0.806 0.816 0.811 0.536 0.507 0.521SubTree (-SP) 0.803 0.816 0.810 0.533 0.495 0.514FullTree (-SP) 0.804 0.817 0.811 0.517 0.470 0.492*Child-Sum 0.806 0.819 0.8122 0.514 0.499 0.506SPSeq 0.801 0.813 0.807 0.500 0.523 0.511SPXu 0.809 0.818 0.813 0.494 0.522 0.508Table 3: Comparison of LSTM-RNN structures on the ACE05 development dataset.the entity detection performance, but this degradedthe recall in relation classification.
This indicatesthat entity label information is helpful in detectingrelations.We also show the performance without shar-ing parameters, i.e., embedding and sequence lay-ers, for detecting entities and relations (?Sharedparameters); we first train the entity detectionmodel, detect entities with the model, and builda separate relation extraction model using thedetected entities, i.e., without entity detection.This setting can be regarded as a pipeline modelsince two separate models are trained sequentially.Without the shared parameters, both the perfor-mance in entity detection and relation classifica-tion drops slightly, although the differences arenot significant.
When we removed all the en-hancements, i.e., scheduled sampling, entity pre-training, label embedding, and shared parameters,the performance is significantly worse than SP-Tree (p<0.01), showing that these enhancementsprovide complementary benefits to end-to-end re-lation extraction.Next, we show the performance with differ-ent LSTM-RNN structures in Table 3.
We firstcompare the three input dependency structures(SPTree, SubTree, FullTree) for tree-structuredLSTM-RNNs.
Performances on these three struc-tures are almost same when we distinguish thenodes in the shortest paths from other nodes,but when we do not distinguish them (-SP), theinformation outside of the shortest path, i.e.,1111FullTree (-SP), significantly hurts performance(p<0.05).
We then compare our tree-structuredLSTM-RNN (SPTree) with the Child-Sum tree-structured LSTM-RNN on the shortest path of Taiet al (2015).
Child-Sum performs worse than ourSPTree model, but not with as big of a decreaseas above.
This may be because the difference inthe models appears only on nodes that have multi-ple children and all the nodes except for the leastcommon node have one child.We finally show results with two counterpartsof sequence-based LSTM-RNNs using the short-est path (last two rows in Table 3).
SPSeq is a bidi-rectional LSTM-RNN on the shortest path.
TheLSTM unit receives input from the sequence layerconcatenated with embeddings for the surround-ing dependency types and directions.
We concate-nate the outputs of the two RNNs for the relationcandidate.
SPXu is our adaptation of the shortestpath LSTM-RNN proposed by Xu et al (2015b)to match our sequence-layer based model.11Thishas two LSTM-RNNs for the left and right sub-paths of the shortest path.
We first calculate themax pooling of the LSTM units for each of thesetwo RNNs, and then concatenate the outputs of thepooling for the relation candidate.
The compar-ison with these sequence-based LSTM-RNNs in-dicates that a tree-structured LSTM-RNN is com-parable to sequence-based ones in representingshortest paths.Overall, the performance comparison of theLSTM-RNN structures in Table 3 show that forend-to-end relation extraction, selecting the ap-propriate tree structure representation of the input(i.e., the shortest path) is more important than thechoice of the LSTM-RNN structure on that input(i.e., sequential versus tree-based).4.4 Relation Classification Analysis ResultsTo thoroughly analyze the relation classificationpart alone, e.g., comparing different LSTM struc-tures, architecture components such as hidden lay-ers and input information, and classification tasksettings, we use the SemEval-2010 Task 8.
Thisdataset, often used to evaluate NN models for rela-tion classification, annotates only relation-relatednominals (unlike ACE datasets), so we can focuscleanly on the relation classification part.11This is different from the original one in that we use thesequence layer and we concatenate the embeddings for the in-put, while the original one prepared individual LSTM-RNNsfor different inputs and concatenated their outputs.Settings Macro-F1No External Knowledge ResourcesOur Model (SPTree) 0.844dos Santos et al (2015) 0.841Xu et al (2015a) 0.840+WordNetOur Model (SPTree + WordNet) 0.855Xu et al (2015a) 0.856Xu et al (2015b) 0.837Table 4: Comparison with state-of-the-art modelson SemEval-2010 Task 8 test-set.Settings Macro-F1SPTree 0.851SubTree 0.839FullTree 0.829?SubTree (-SP) 0.840FullTree (-SP) 0.828?Child-Sum 0.838SPSeq 0.844SPXu 0.847Table 5: Comparison of LSTM-RNN structures onSemEval-2010 Task 8 development set.We first report official test set results in Ta-ble 4.
Our novel LSTM-RNN model is compara-ble to both the state-of-the-art CNN-based modelson this task with or without external sources, i.e.,WordNet, unlike the previous best LSTM-RNNmodel (Xu et al, 2015b).12Next, we compare different LSTM-RNN struc-tures in Table 5.
As for the three input de-pendency structures (SPTree, SubTree, FullTree),FullTree performs significantly worse than otherstructures regardless of whether or not we dis-tinguish the nodes in the shortest paths from theother nodes, which hints that the information out-side of the shortest path significantly hurts the per-formance (p<0.05).
We also compare our tree-structured LSTM-RNN (SPTree) with sequence-based LSTM-RNNs (SPSeq and SPXu) and tree-structured LSTM-RNNs (Child-Sum).
All theseLSTM-RNNs perform slightly worse than our SP-12When incorporating WordNet information into ourmodel, we prepared embeddings for WordNet hypernyms ex-tracted by SuperSenseTagger (Ciaramita and Altun, 2006)and concatenated the embeddings to the input vector (the con-catenation of word and POS embeddings) of the sequenceLSTM.
We tuned the dimension of the WordNet embeddingsand set it to 15 using the development dataset.1112Settings Macro-F1SPTree 0.851?Hidden layer 0.839?Sequence layer 0.840?Pair 0.844?Pair, Sequence layer 0.827?Stanford PCFG 0.844+WordNet 0.854Left-to-right candidates 0.843Neg.
sampling (Xu et al, 2015a) 0.848Table 6: Model setting ablations on SemEval-2010 development set.Tree model, but the differences are small.Overall, for relation classification, althoughthe performance comparison of the LSTM-RNNstructures in Table 5 produces different results onFullTree as compared to the results on ACE05 inTable 3, the trend still holds that selecting the ap-propriate tree structure representation of the inputis more important than the choice of the LSTM-RNN structure on that input.Finally, Table 6 summarizes the contributionof several model components and training set-tings on SemEval relation classification.
We firstremove the hidden layer by directly connectingthe LSTM-RNN layers to the softmax layers, andfound that this slightly degraded performance, butthe difference was small.
We then skip the se-quence layer and directly use the word and POSembeddings for the dependency layer.
Removingthe sequence layer13or entity-related informationfrom the sequence layer (?Pair) slightly degradedperformance, and, on removing both, the perfor-mance dropped significantly (p<0.05).
This indi-cates that the sequence layer is necessary but thelast words of nominals are almost enough for ex-pressing the relations in this task.When we replace the Stanford neural depen-dency parser with the Stanford lexicalized PCFGparser (Stanford PCFG), the performance slightlydropped, but the difference was small.
This in-dicates that the selection of parsing models isnot critical.
We also included WordNet, and thisslightly improved the performance (+WordNet),but the difference was small.
Lastly, for the gener-ation of relation candidates, generating only left-to-right candidates slightly degraded the perfor-13Note that this setting still uses some sequence layer in-formation since it uses the entity-related information (Pair).mance, but the difference was small and hence thecreation of right-to-left candidates was not critical.Treating the inverse relation candidate as a nega-tive instance (Negative sampling) also performedcomparably to other generation methods in ourmodel (unlike Xu et al (2015a), which showeda significance improvement over generating onlyleft-to-right candidates).5 ConclusionWe presented a novel end-to-end relation extrac-tion model that represents both word sequenceand dependency tree structures by using bidirec-tional sequential and bidirectional tree-structuredLSTM-RNNs.
This allowed us to represent bothentities and relations in a single model, achiev-ing gains over the state-of-the-art, feature-basedsystem on end-to-end relation extraction (ACE04and ACE05), and showing favorably compara-ble performance to recent state-of-the-art CNN-based models on nominal relation classification(SemEval-2010 Task 8).Our evaluation and ablation led to three keyfindings.
First, the use of both word sequenceand dependency tree structures is effective.
Sec-ond, training with the shared parameters improvesrelation extraction accuracy, especially when em-ployed with entity pretraining, scheduled sam-pling, and label embeddings.
Finally, the shortestpath, which has been widely used in relation clas-sification, is also appropriate for representing treestructures in neural LSTM models.AcknowledgmentsWe thank Qi Li, Kevin Gimpel, and the anony-mous reviewers for dataset details and helpful dis-cussions.ReferencesSamy Bengio, Oriol Vinyals, Navdeep Jaitly, andNoam Shazeer.
2015.
Scheduled sampling forsequence prediction with recurrent neural net-works.
arXiv preprint arXiv:1506.03099.Razvan C Bunescu and Raymond Mooney.
2005.A shortest path dependency kernel for relationextraction.
In Proceedings of the conferenceon Human Language Technology and Empiri-cal Methods in Natural Language Processing,pages 724?731.
ACL.1113Yee Seng Chan and Dan Roth.
2011.
Exploit-ing syntactico-semantic structures for relationextraction.
In Proceedings of the 49th An-nual Meeting of the Association for Computa-tional Linguistics: Human Language Technolo-gies, pages 551?560, Portland, Oregon, USA,June.
ACL.Danqi Chen and Christopher Manning.
2014.
Afast and accurate dependency parser using neu-ral networks.
In Proceedings of the 2014 Con-ference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 740?750,Doha, Qatar, October.
ACL.Massimiliano Ciaramita and Yasemin Altun.2006.
Broad-coverage sense disambiguationand information extraction with a supersensesequence tagger.
In Proceedings of the 2006Conference on Empirical Methods in NaturalLanguage Processing, pages 594?602, Sydney,Australia, July.
ACL.George Doddington, Alexis Mitchell, Mark Przy-bocki, Lance Ramshaw, Stephanie Strassel, andRalph Weischedel.
2004.
The automatic con-tent extraction (ace) program ?
tasks, data, andevaluation.
In Proceedings of the Fourth In-ternational Conference on Language Resourcesand Evaluation (LREC-2004), Lisbon, Portu-gal, May.
European Language Resources Asso-ciation (ELRA).Cicero dos Santos, Bing Xiang, and Bowen Zhou.2015.
Classifying relations by ranking withconvolutional neural networks.
In Proceedingsof the 53rd Annual Meeting of the Associationfor Computational Linguistics and the 7th In-ternational Joint Conference on Natural Lan-guage Processing (Volume 1: Long Papers),pages 626?634, Beijing, China, July.
ACL.Alex Graves and J?urgen Schmidhuber.
2005.Framewise phoneme classification with bidirec-tional lstm and other neural network architec-tures.
Neural Networks, 18(5):602?610.Alan Graves, Abdel-rahman Mohamed, and Ge-offrey Hinton.
2013.
Speech recognition withdeep recurrent neural networks.
In Acoustics,Speech and Signal Processing (ICASSP), 2013IEEE International Conference on, pages 6645?6649.
IEEE.James Hammerton.
2001.
Clause identificationwith long short-term memory.
In Proceedingsof the 2001 workshop on Computational Nat-ural Language Learning-Volume 7, page 22.ACL.James Hammerton.
2003.
Named entity recog-nition with long short-term memory.
In Wal-ter Daelemans and Miles Osborne, editors, Pro-ceedings of the Seventh Conference on Natu-ral Language Learning at HLT-NAACL 2003,pages 172?175.
ACL.Kazuma Hashimoto, Pontus Stenetorp, MakotoMiwa, and Yoshimasa Tsuruoka.
2015.
Task-oriented learning of word embeddings for se-mantic relation classification.
In Proceedingsof the Nineteenth Conference on ComputationalNatural Language Learning, pages 268?278,Beijing, China, July.
ACL.Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,Preslav Nakov, Diarmuid?O S?eaghdha, Sebas-tian Pad?o, Marco Pennacchiotti, Lorenza Ro-mano, and Stan Szpakowicz.
2010.
Semeval-2010 task 8: Multi-way classification of se-mantic relations between pairs of nominals.
InProceedings of the 5th International Workshopon Semantic Evaluation, pages 33?38, Uppsala,Sweden, July.
ACL.Zhiheng Huang, Wei Xu, and Kai Yu.
2015.
Bidi-rectional lstm-crf models for sequence tagging.arXiv preprint arXiv:1508.01991.Rohit J. Kate and Raymond Mooney.
2010.Joint entity and relation extraction using card-pyramid parsing.
In Proceedings of the Four-teenth Conference on Computational NaturalLanguage Learning, pages 203?212, Uppsala,Sweden, July.
ACL.Diederik Kingma and Jimmy Ba.
2015.
Adam:A method for stochastic optimization.
In ICLR2015, San Diego, CA, May.Qi Li and Heng Ji.
2014.
Incremental joint ex-traction of entity mentions and relations.
InProceedings of the 52nd Annual Meeting of theAssociation for Computational Linguistics (Vol-ume 1: Long Papers), pages 402?412, Balti-more, Maryland, June.
ACL.1114Jiwei Li, Thang Luong, Dan Jurafsky, and EduardHovy.
2015.
When are tree structures neces-sary for deep learning of representations?
InProceedings of the 2015 Conference on Empir-ical Methods in Natural Language Processing,pages 2304?2314, Lisbon, Portugal, September.ACL.Wei Lu and Dan Roth.
2015.
Joint mentionextraction and classification with mention hy-pergraphs.
In Proceedings of the 2015 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 857?867, Lisbon, Por-tugal, September.
ACL.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg SCorrado, and Jeff Dean.
2013.
Distributedrepresentations of words and phrases and theircompositionality.
In Advances in neural infor-mation processing systems, pages 3111?3119.Makoto Miwa and Yutaka Sasaki.
2014.
Model-ing joint entity and relation extraction with ta-ble representation.
In Proceedings of the 2014Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 1858?1869, Doha, Qatar, October.
ACL.David Nadeau and Satoshi Sekine.
2007.
A sur-vey of named entity recognition and classifica-tion.
Lingvisticae Investigationes, 30(1):3?26.Eric W. Noreen.
1989.
Computer-Intensive Meth-ods for Testing Hypotheses : An Introduction.Wiley-Interscience, April.Romain Paulus, Richard Socher, and Christo-pher D Manning.
2014.
Global belief re-cursive neural networks.
In Z. Ghahramani,M.
Welling, C. Cortes, N.D. Lawrence, andK.Q.
Weinberger, editors, Advances in Neu-ral Information Processing Systems 27, pages2888?2896.
Curran Associates, Inc.Anastasia Pentina, Viktoriia Sharmanska, andChristoph H. Lampert.
2015.
Curriculumlearning of multiple tasks.
In IEEE Confer-ence on Computer Vision and Pattern Recog-nition CVPR, pages 5492?5500, Boston, MA,USA, June.Lev Ratinov and Dan Roth.
2009.
Designchallenges and misconceptions in named en-tity recognition.
In Proceedings of the Thir-teenth Conference on Computational NaturalLanguage Learning (CoNLL-2009), pages 147?155, Boulder, Colorado, June.
ACL.Dan Roth and Wen-Tau Yih, 2007.
Global Infer-ence for Entity and Relation Identification via aLinear Programming Formulation.
MIT Press.Sameer Singh, Sebastian Riedel, Brian Martin, Ji-aping Zheng, and Andrew McCallum.
2013.Joint inference of entities, relations, and coref-erence.
In Proceedings of the 2013 work-shop on Automated knowledge base construc-tion, pages 1?6.
ACM.Richard Socher, Brody Huval, Christopher D.Manning, and Andrew Y. Ng.
2012.
Seman-tic compositionality through recursive matrix-vector spaces.
In Proceedings of the 2012 JointConference on Empirical Methods in NaturalLanguage Processing and Computational Natu-ral Language Learning, pages 1201?1211, JejuIsland, Korea, July.
ACL.Nitish Srivastava, Geoffrey Hinton, AlexKrizhevsky, Ilya Sutskever, and RuslanSalakhutdinov.
2014.
Dropout: A simple wayto prevent neural networks from overfitting.The Journal of Machine Learning Research,15(1):1929?1958.Kai Sheng Tai, Richard Socher, and Christo-pher D. Manning.
2015.
Improved semanticrepresentations from tree-structured long short-term memory networks.
In Proceedings of the53rd Annual Meeting of the Association forComputational Linguistics and the 7th Interna-tional Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages1556?1566, Beijing, China, July.
ACL.Paul J Werbos.
1990.
Backpropagation throughtime: what it does and how to do it.
Proceed-ings of the IEEE, 78(10):1550?1560.Kun Xu, Yansong Feng, Songfang Huang, andDongyan Zhao.
2015a.
Semantic relationclassification via convolutional neural networkswith simple negative sampling.
In Proceedingsof the 2015 Conference on Empirical Methodsin Natural Language Processing, pages 536?540, Lisbon, Portugal, September.
ACL.Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, HaoPeng, and Zhi Jin.
2015b.
Classifying re-lations via long short term memory networks1115along shortest dependency paths.
In Proceed-ings of the 2015 Conference on Empirical Meth-ods in Natural Language Processing, pages1785?1794, Lisbon, Portugal, September.
ACL.Bishan Yang and Claire Cardie.
2013.
Joint in-ference for fine-grained opinion extraction.
InProceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics (Vol-ume 1: Long Papers), pages 1640?1649, Sofia,Bulgaria, August.
ACL.Xiaofeng Yu and Wai Lam.
2010.
Jointly iden-tifying entities and extracting relations in ency-clopedia text via a graphical model approach.In Coling 2010: Posters, pages 1399?1407,Beijing, China, August.
Coling 2010 Organiz-ing Committee.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
The Journal of Machine LearningResearch, 3:1083?1106.GuoDong Zhou, Jian Su, Jie Zhang, and MinZhang.
2005.
Exploring various knowledge inrelation extraction.
In Proceedings of the 43rdAnnual Meeting of the Association for Compu-tational Linguistics (ACL?05), pages 427?434,Ann Arbor, Michigan, June.
ACL.A Supplemental MaterialA.1 Data and Task SettingsACE05 defines 7 coarse-grained entity types:Facility (FAC), Geo-Political Entities (GPE),Location (LOC), Organization (ORG), Person(PER), Vehicle (VEH) and Weapon (WEA), and6 coarse-grained relation types between enti-ties: Artifact (ART), Gen-Affiliation (GEN-AFF),Org-Affiliation (ORG-AFF), Part-Whole (PART-WHOLE), Person-Social (PER-SOC) and Physical(PHYS).
We removed the cts, un subsets, and useda 351/80/80 train/dev/test split.
We removed du-plicated entities and relations, and resolved nestedentities.
We used head spans for entities.
We fol-low the settings by (Li and Ji, 2014), and we didnot use the full mention boundary unlike Lu andRoth (2015).
We use entities and relations to referto entity mentions and relation mentions in ACEfor brevity.ACE04 defines the same 7 coarse-grained entitytypes as ACE05 (Doddington et al, 2004), but de-fines 7 coarse-grained relation types: PYS, PER-SOC, Employment / Membership / Subsidiary(EMP-ORG), ART, PER/ORG affiliation (Other-AFF), GPE affiliation (GPE-AFF), and Discourse(DISC).
We follow the cross-validation setting ofChan and Roth (2011) and Li and Ji (2014).
Weremoved DISC and did 5-fold CV on bnews andnwire subsets (348 documents).
We use the samepreprocessing and evaluation metrics of ACE05.SemEval-2010 Task 8 defines 9 relation typesbetween nominals ( Cause-Effect, Instrument-Agency, Product-Producer, Content-Container,Entity-Origin, Entity-Destination, Component-Whole, Member-Collection and Message-Topic),and a tenth type Other when two nouns have noneof these relations (Hendrickx et al, 2010).
Wetreat this Other type as a negative relation type,and no direction is considered.
The dataset con-sists of 8,000 training and 2,717 test sentences,and each sentence is annotated with a relation be-tween two given nominals.
We randomly selected800 sentences from the training set as our devel-opment set.
We followed the official task setting,and report the official macro-averaged F1-score(Macro-F1) on the 9 relation types.A.2 Hyper-parameter SettingsHere we show the hyper-parameters and the rangetried for the hyper-parameters in parentheses.Hyper-parameters include the initial learning rate(5e-3, 2e-3, 1e-3, 5e-4, 2e-4, 1e-4), the regular-ization parameter (1e-4, 1e-5, 1e-6, 1e-7), dropoutprobabilities (0.0, 0.1, 0.2, 0.3, 0.4, 0.5), the sizeof gradient clipping (1, 5, 10, 50, 100), scheduledsampling parameter k (1, 5, 10, 50, 100), the num-ber of epochs for training and entity pretraining (?100), and the embedding dimension of WordNethypernym (5, 10, 15, 20, 25, 30).1116
