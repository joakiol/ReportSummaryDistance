Proceedings of NAACL HLT 2007, pages 564?571,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsISP: Learning Inferential Selectional PreferencesPatrick Pantel?, Rahul Bhagat?, Bonaventura Coppola?,Timothy Chklovski?, Eduard Hovy?
?Information Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA{pantel,rahul,timc,hovy}@isi.edu?ITC-Irst and University of TrentoVia Sommarive, 18 ?
Povo 38050Trento, Italycoppolab@itc.itAbstractSemantic inference is a key componentfor advanced natural language under-standing.
However, existing collections ofautomatically acquired inference ruleshave shown disappointing results whenused in applications such as textual en-tailment and question answering.
This pa-per presents ISP, a collection of methodsfor automatically learning admissible ar-gument values to which an inference rulecan be applied, which we call inferentialselectional preferences, and methods forfiltering out incorrect inferences.
Weevaluate ISP and present empirical evi-dence of its effectiveness.1 IntroductionSemantic inference is a key component for ad-vanced natural language understanding.
Severalimportant applications are already relying heavilyon inference, including question answering(Moldovan et al 2003; Harabagiu and Hickl 2006),information extraction (Romano et al 2006), andtextual entailment (Szpektor et al 2004).In response, several researchers have created re-sources for enabling semantic inference.
Amongmanual resources used for this task are WordNet(Fellbaum 1998) and Cyc (Lenat 1995).
Althoughimportant and useful, these resources primarilycontain prescriptive inference rules such as ?X di-vorces Y ?
X married Y?.
In practical NLP appli-cations, however, plausible inference rules such as?X married Y?
?
?X dated Y?
are very useful.
This,along with the difficulty and labor-intensiveness ofgenerating exhaustive lists of rules, has led re-searchers to focus on automatic methods for build-ing inference resources such as inference rulecollections (Lin and Pantel 2001; Szpektor et al2004) and paraphrase collections (Barzilay andMcKeown 2001).Using these resources in applications has beenhindered by the large amount of incorrect infer-ences they generate, either because of altogetherincorrect rules or because of blind application ofplausible rules without considering the context ofthe relations or the senses of the words.
For exam-ple, consider the following sentence:Terry Nichols was charged by federal prosecutors for murderand conspiracy in the Oklahoma City bombing.and an inference rule such as:X is charged by Y ?
Y announced the arrest of X (1)Using this rule, we can infer that ?federal prosecu-tors announced the arrest of Terry Nichols?.
How-ever, given the sentence:Fraud was suspected when accounts were charged by CCMtelemarketers without obtaining consumer authorization.the plausible inference rule (1) would incorrectlyinfer that ?CCM telemarketers announced the ar-rest of accounts?.This example depicts a major obstacle to the ef-fective use of automatically learned inferencerules.
What is missing is knowledge about the ad-missible argument values for which an inferencerule holds, which we call Inferential SelectionalPreferences.
For example, inference rule (1)should only be applied if X is a Person and Y is aLaw Enforcement Agent or a Law EnforcementAgency.
This knowledge does not guarantee thatthe inference rule will hold, but, as we show in thispaper, goes a long way toward filtering out errone-ous applications of rules.In this paper, we propose ISP, a collection ofmethods for learning inferential selectional prefer-ences and filtering out incorrect inferences.
The564presented algorithms apply to any collection ofinference rules between binary semantic relations,such as example (1).
ISP derives inferential selec-tional preferences by aggregating statistics of in-ference rule instantiations over a large corpus oftext.
Within ISP, we explore different probabilisticmodels of selectional preference to accept or rejectspecific inferences.
We present empirical evidenceto support the following main contribution:Claim: Inferential selectional preferences can beautomatically learned and used for effectively fil-tering out incorrect inferences.2 Previous WorkSelectional preference (SP) as a foundation forcomputational semantics is one of the earliest top-ics in AI and NLP, and has its roots in (Katz andFodor 1963).
Overviews of NLP research on thistheme are (Wilks and Fass 1992), which includesthe influential theory of Preference Semantics byWilks, and more recently (Light and Greiff 2002).Rather than venture into learning inferentialSPs, much previous work has focused on learningSPs for simpler structures.
Resnik (1996), theseminal paper on this topic, introduced a statisticalmodel for learning SPs for predicates using an un-supervised method.Learning SPs often relies on an underlying set ofsemantic classes, as in both Resnik?s and our ap-proach.
Semantic classes can be specified manu-ally or derived automatically.
Manual collectionsof semantic classes include the hierarchies ofWordNet (Fellbaum 1998), Levin verb classes(Levin 1993), and FrameNet (Baker et al 1998).Automatic derivation of semantic classes can takea variety of approaches, but often uses corpusmethods and the Distributional Hypothesis (Harris1964) to automatically cluster similar entities intoclasses, e.g.
CBC (Pantel and Lin 2002).
In thispaper, we experiment with two sets of semanticclasses, one from WordNet and one from CBC.Another thread related to our work includes ex-tracting from text corpora paraphrases (Barzilayand McKeown 2001) and inference rules, e.g.TEASE1 (Szpektor et al 2004) and DIRT (Lin andPantel 2001).
While these systems differ in theirapproaches, neither provides for the extracted in-1 Some systems refer to inferences they extract as entail-ments; the two terms are sometimes used interchangeably.ference rules to hold or fail based on SPs.
Zanzottoet al (2006) recently explored a different interplaybetween SPs and inferences.
Rather than examinethe role of SPs in inferences, they use SPs of a par-ticular type to derive inferences.
For instance thepreference of win for the subject player, a nomi-nalization of play, is used to derive that ?win ?play?.
Our work can be viewed as complementaryto the work on extracting semantic inferences andparaphrases, since we seek to refine when a giveninference applies, filtering out incorrect inferences.3 Selectional Preference ModelsThe aim of this paper is to learn inferential selec-tional preferences for filtering inference rules.Let pi ?
pj be an inference rule where p is a bi-nary semantic relation between two entities x andy.
Let ?x, p, y?
be an instance of relation p.Formal task definition: Given an inference rulepi ?
pj and the instance ?x, pi, y?, our task is todetermine if ?x, pj, y?
is valid.Consider the example in Section 1 where wehave the inference rule ?X is charged by Y?
?
?Yannounced the arrest of X?.
Our task is to auto-matically determine that ?federal prosecutors an-nounced the arrest of Terry Nichols?
(i.e.,?Terry Nichols, pj, federal prosecutors?)
is validbut that ?CCM telemarketers announced the arrestof accounts?
is invalid.Because the semantic relations p are binary, theselectional preferences on their two arguments maybe either considered jointly or independently.
Forexample, the relation p = ?X is charged by Y?could have joint SPs:?Person, Law Enforcement Agent?
?Person, Law Enforcement Agency?
(2)?Bank Account, Organization?or independent SPs:?Person, *??
*, Organization?
(3)?
*, Law Enforcement Agent?This distinction between joint and independentselectional preferences constitutes the differencebetween the two models we present in this section.The remainder of this section describes the ISPapproach.
In Section 3.1, we describe methods forautomatically determining the semantic contexts ofeach single relation?s selectional preferences.
Sec-tion 3.2 uses these for developing our inferential565selectional preference models.
Finally, we proposeinference filtering algorithms in Section 3.3.3.1 Relational Selectional PreferencesResnik (1996) defined the selectional preferencesof a predicate as the semantic classes of the wordsthat appear as its arguments.
Similarly, we definethe relational selectional preferences of a binarysemantic relation pi as the semantic classes C(x) ofthe words that can be instantiated for x and as thesemantic classes C(y) of the words that can be in-stantiated for y.The semantic classes C(x) and C(y) can be ob-tained from a conceptual taxonomy as proposed in(Resnik 1996), such as WordNet, or from theclasses extracted from a word clustering algorithmsuch as CBC (Pantel and Lin 2002).
For example,given the relation ?X is charged by Y?, its rela-tional selection preferences from WordNet couldbe {social_group, organism, state?}
for X and{authority, state, section?}
for Y.Below we propose joint and independent mod-els, based on a corpus analysis, for automaticallydetermining relational selectional preferences.Model 1: Joint Relational Model (JRM)Our joint model uses a corpus analysis to learn SPsfor binary semantic relations by considering theirarguments jointly, as in example (2).Given a large corpus of English text, we firstfind the occurrences of each semantic relation p.For each instance ?x, p, y?, we retrieve the sets C(x)and C(y) of the semantic classes that x and y be-long to and accumulate the frequencies of the tri-ples ?c(x), p, c(y)?, where c(x) ?
C(x) andc(y) ?
C(y)2.Each triple ?c(x), p, c(y)?
is a candidate selec-tional preference for p. Candidates can be incorrectwhen: a) they were generated from the incorrectsense of a polysemous word; or b) p does not holdfor the other words in the semantic class.Intuitively, we have more confidence in a par-ticular candidate if its semantic classes are closelyassociated given the relation p. Pointwise mutualinformation (Cover and Thomas 1991) is a com-monly used metric for measuring this associationstrength between two events e1 and e2:2 In this paper, the semantic classes C(x) and C(y) are ex-tracted from WordNet and CBC (described in Section 4.2).
( )( ) ( )212121,log);(ePePeePeepmi =  (3.1)We define our ranking function as the strengthof association between two semantic classes, cx andcy3, given the relation p:( ) ( )( ) ( )pcPpcP pccPpcpcpmi yx yxyx,log; =  (3.2)Let |cx, p, cy| denote the frequency of observingthe instance ?c(x), p, c(y)?.
We estimate the prob-abilities of Equation 3.2 using maximum likeli-hood estimates over our corpus:( ) ??
?= ,, ,,ppcpcP xx( ) ??
?= ,, ,, pcppcP yy  ( ) ?
?= ,, ,,, p cpcpccP yxyx   (3.3)Similarly to (Resnik 1996), we estimate theabove frequencies using:( )??
?=?xcwx wCpwpc,,,,( )??
?=?ycwy wCwpcp,,,,( ) ( )???
?= yx cwcwyx wCwCwpwcpc21 , 2121 ,,,,where |x, p, y| denotes the frequency of observingthe instance ?x, p, y?
and |C(w)| denotes the numberof classes to which word w belongs.
|C(w)| distrib-utes w?s mass equally to all of its senses cw.Model 2: Independent Relational Model (IRM)Because of sparse data, our joint model can misssome correct selectional preference pairs.
For ex-ample, given the relationY announced the arrest of Xwe may find occurrences from our corpus of theparticular class ?Money Handler?
for X and ?Law-yer?
for Y, however we may never see both ofthese classes co-occurring even though they wouldform a valid relational selectional preference.To alleviate this problem, we propose a secondmodel that is less strict by considering the argu-ments of the binary semantic relations independ-ently, as in example (3).Similarly to JRM, we extract each instance?x, p, y?
of each semantic relation p and retrieve theset of semantic classes C(x) and C(y) that x and ybelong to, accumulating the frequencies of the tri-ples ?c(x), p, *?
and ?
*, p, c(y)?, wherec(x) ?
C(x) and c(y) ?
C(y).All tuples ?c(x), p, *?
and ?
*, p, c(y)?
are candi-date selectional preferences for p. We rank candi-dates by the probability of the semantic class giventhe relation p, according to Equations 3.3.3 cx and cy are shorthand for c(x) and c(y) in our equations.5663.2 Inferential Selectional PreferencesWhereas in Section 3.1 we learned selectionalpreferences for the arguments of a relation p, inthis section we learn selectional preferences for thearguments of an inference rule pi ?
pj.Model 1: Joint Inferential Model (JIM)Given an inference rule pi ?
pj, our joint modeldefines the set of inferential SPs as the intersectionof the relational SPs for pi and pj, as defined in theJoint Relational Model (JRM).
For example, sup-pose relation pi = ?X is charged by Y?
gives thefollowing SP scores under the JRM:?Person, pi, Law Enforcement Agent?
= 1.45?Person, pi, Law Enforcement Agency?
= 1.21?Bank Account, pi, Organization?
= 0.97and that pj = ?Y announced the arrest of X?
givesthe following SP scores under the JRM:?Law Enforcement Agent, pj, Person?
= 2.01?Reporter, pj, Person?
= 1.98?Law Enforcement Agency, pj, Person?
= 1.61The intersection of the two sets of SPs forms thecandidate inferential SPs for the inference pi ?
pj:?Law Enforcement Agent, Person?
?Law Enforcement Agency, Person?We rank the candidate inferential SPs accordingto three ways to combine their relational SP scores,using the minimum, maximum, and average of theSPs.
For example, for ?Law Enforcement Agent,Person?, the respective scores would be 1.45, 2.01,and 1.73.
These different ranking strategies pro-duced nearly identical results in our experiments,as discussed in Section 5.Model 2: Independent Inferential Model (IIM)Our independent model is the same as the jointmodel above except that it computes candidate in-ferential SPs using the Independent RelationalModel (IRM) instead of the JRM.
Consider thesame example relations pi and pj from the jointmodel and suppose that the IRM gives the follow-ing relational SP scores for pi:?Law Enforcement Agent, pi, *?
= 3.43?
*, pi, Person?
= 2.17?
*, pi, Organization?
= 1.24and the following relational SP scores for pj:?
*, pj, Person?
= 2.87?Law Enforcement Agent, pj, *?
= 1.92?Reporter, pj, *?
= 0.89The intersection of the two sets of SPs forms thecandidate inferential SPs for the inference pi ?
pj:?Law Enforcement Agent, *??
*, Person?We use the same minimum, maximum, and av-erage ranking strategies as in JIM.3.3 Filtering InferencesGiven an inference rule pi ?
pj and the instance?x, pi, y?, the system?s task is to determine whether?x, pj, y?
is valid.
Let C(w) be the set of semanticclasses c(w) to which word w belongs.
Below wepresent three filtering algorithms which range fromthe least to the most permissive:?
ISP.JIM, accepts the inference ?x, pj, y?
if theinferential SP ?c(x), pj, c(y)?
was admitted by theJoint Inferential Model for some c(x) ?
C(x) andc(y) ?
C(y).?
ISP.IIM.
?, accepts the inference ?x, pj, y?
if theinferential SPs ?c(x), pj, *?
AND ?
*, pj, c(y)?
wereadmitted by the Independent Inferential Modelfor some c(x) ?
C(x) and c(y) ?
C(y) .?
ISP.IIM.
?, accepts the inference ?x, pj, y?
if theinferential SP ?c(x), pj, *?
OR ?
*, pj, c(y)?
wasadmitted by the Independent Inferential Modelfor some c(x) ?
C(x) and c(y) ?
C(y) .Since both JIM and IIM use a ranking score intheir inferential SPs, each filtering algorithm canbe tuned to be more or less strict by setting an ac-ceptance threshold on the ranking scores or by se-lecting only the top ?
percent highest ranking SPs.In our experiments, reported in Section 5, wetested each model using various values of ?.4 Experimental MethodologyThis section describes the methodology for testingour claim that inferential selectional preferencescan be learned to filter incorrect inferences.Given a collection of inference rules of the formpi ?
pj, our task is to determine whether a particu-lar instance ?x, pj, y?
holds given that ?x, pi, y?holds4.
In the next sections, we describe our collec-tion of inference rules, the semantic classes usedfor forming selectional preferences, and evaluationcriteria for measuring the filtering quality.4 Recall that the inference rules we consider in this paper arenot necessary strict logical inference rules, but plausible in-ference rules; see Section 3.5674.1 Inference RulesOur models for learning inferential selectionalpreferences can be applied to any collection of in-ference rules between binary semantic relations.
Inthis paper, we focus on the inference rules con-tained in the DIRT resource (Lin and Pantel 2001).DIRT consists of over 12 million rules which wereextracted from a 1GB newspaper corpus (San JoseMercury, Wall Street Journal and AP Newswirefrom the TREC-9 collection).
For example, hereare DIRT?s top 3 inference rules for ?X solves Y?
:?Y is solved by X?, ?X resolves Y?, ?X finds a solution to Y?4.2 Semantic ClassesThe choice of semantic classes is of great impor-tance for selectional preference.
One importantaspect is the granularity of the classes.
Too generala class will provide no discriminatory power whiletoo fine-grained a class will offer little generaliza-tion and apply in only extremely few cases.The absence of an attested high-quality set ofsemantic classes for this task makes discoveringpreferences difficult.
Since many of the criteria fordeveloping such a set are not even known, we de-cided to experiment with two very different sets ofsemantic classes, in the hope that in addition tolearning semantic preferences, we might also un-cover some clues for the eventual decisions aboutwhat makes good semantic classes in general.Our first set of semantic classes was directly ex-tracted from the output of the CBC clustering algo-rithm (Pantel and Lin 2002).
We applied CBC tothe TREC-9 and TREC-2002 (Aquaint) newswirecollections consisting of over 600 million words.CBC generated 1628 noun concepts and these wereused as our semantic classes for SPs.Secondly, we extracted semantic classes fromWordNet 2.1 (Fellbaum 1998).
In the absence ofany externally motivated distinguishing features(for example, the Basic Level categories from Pro-totype Theory, developed by Eleanor Rosch(1978)), we used the simple but effective methodof manually truncating the noun synset hierarchy5and considering all synsets below each cut point aspart of the semantic class at that node.
To selectthe cut points, we inspected several different hier-archy levels and found the synsets at a depth of 45 Only nouns are considered since DIRT semantic relationsconnect only nouns.to form the most natural semantic classes.
Sincethe noun hierarchy in WordNet has an averagedepth of 12, our truncation created a set of con-cepts considerably coarser-grained than WordNetitself.
The cut produced 1287 semantic classes, anumber similar to the classes in CBC.
To properlytest WordNet as a source of semantic classes forour selectional preferences, we would need to ex-periment with different extraction algorithms.4.3 Evaluation CriteriaThe goal of the filtering task is to minimize falsepositives (incorrectly accepted inferences) andfalse negatives (incorrectly rejected inferences).
Astandard methodology for evaluating such tasks isto compare system filtering results with a goldstandard using a confusion matrix.
A confusionmatrix captures the filtering performance on bothcorrect and incorrect inferences:where A represents the number of correct instancescorrectly identified by the system, D represents thenumber of incorrect instances correctly identifiedby the system, B represents the number of falsepositives and C represents the number of falsenegatives.
To compare systems, three key meas-ures are used to summarize confusion matrices:?
Sensitivity, defined as CAA+ , captures a filter?sprobability of accepting correct inferences;?
Specificity, defined as DBD+ , captures a filter?sprobability of rejecting incorrect inferences;?
Accuracy, defined as DCBADA++++ , captures theprobability of a filter being correct.5 Experimental ResultsIn this section, we provide empirical evidence tosupport the main claim of this paper.Given a collection of DIRT inference rules ofthe form pi ?
pj, our experiments, using the meth-odology of Section 4, evaluate the capability of ourISP models for determining if ?x, pj, y?
holds giventhat ?x, pi, y?
holds.GOLD STANDARD1 01 A BSYSTEM0 C D5685.1 Experimental SetupModel ImplementationFor each filtering algorithm in Section 3.3, ISP.JIM,ISP.IIM.
?, and ISP.IIM.
?, we trained their probabil-istic models using corpus statistics extracted fromthe 1999 AP newswire collection (part of theTREC-2002 Aquaint collection) consisting of ap-proximately 31 million words.
We used the Mini-par parser (Lin 1993) to match DIRT patterns inthe text.
This permits exact matches since DIRTinference rules are built from Minipar parse trees.For each system, we experimented with the dif-ferent ways of combining relational SP scores:minimum, maximum, and average (see Section3.2).
Also, we experimented with various valuesfor the ?
parameter described in Section 3.3.Gold Standard ConstructionIn order to compute the confusion matrices de-scribed in Section 4.3, we must first construct arepresentative set of inferences and manually anno-tate them as correct or incorrect.We randomly selected 100 inference rules of theform pi ?
pj from DIRT.
For each pattern pi, wethen extracted its instances from the Aquaint 1999AP newswire collection (approximately 22 millionwords), and randomly selected 10 distinct in-stances, resulting in a total of 1000 instances.
Foreach instance of pi, applying DIRT?s inference rulewould assert the instance ?x, pj, y?.
Our evaluationtests how well our models can filter these so thatonly correct inferences are made.To form the gold standard, two human judgeswere asked to tag each instance ?x, pj, y?
as corrector incorrect.
For example, given a randomly se-lected inference rule ?X is charged by Y ?
Y an-nounced the arrest of X?
and the instance ?TerryNichols was charged by federal prosecutors?, thejudges must determine if the instance ?federalprosecutors, Y announced the arrest of X, TerryNichols?
is correct.
The judges were asked to con-sider the following two criteria for their decision:?
?x, pj, y?
is a semantically meaningful instance;?
The inference pi ?
pj holds for this instance.Judges found that annotation decisions can rangefrom trivial to difficult.
The differences often werein the instances for which one of the judges fails tosee the right context under which the inferencecould hold.
To minimize disagreements, the judgeswent through an extensive round of training.To that end, the 1000 instances ?x, pj, y?
weresplit into DEV and TEST sets, 500 in each.
Thetwo judges trained themselves by annotating DEVtogether.
The TEST set was then annotated sepa-rately to verify the inter-annotator agreement andto verify whether the task is well-defined.
Thekappa statistic (Siegel and Castellan Jr. 1988) was?
= 0.72.
For the 70 disagreements between thejudges, a third judge acted as an adjudicator.BaselinesWe compare our ISP algorithms to the followingbaselines:?
B0: Rejects all inferences;?
B1: Accepts all inferences;?
Rand: Randomly accepts or rejects inferences.One alternative to our approach is admit instanceson the Web using literal search queries.
We inves-tigated this technique but discarded it due to subtleyet critical issues with pattern canonicalization thatresulted in rejecting nearly all inferences.
How-ever, we are investigating other ways of using Webcorpora for this task.Table 1.
Filtering quality of best performing systems according to the evaluation criteria defined in Section 4.3 onthe TEST set ?
the reported systems were selected based on the Accuracy criterion on the DEV set.PARAMETERS SELECTED FROM DEV SETSYSTEMRANKING STRATEGY ?
(%)SENSITIVITY(95% CONF)SPECIFICITY(95% CONF)ACCURACY(95% CONF)B0 - - 0.00?0.00 1.00?0.00 0.50?0.04B1 - - 1.00?0.00 0.00?0.00 0.49?0.04Random - - 0.50?0.06 0.47?0.07 0.50?0.04ISP.JIM maximum 100 0.17?0.04 0.88?0.04 0.53?0.04ISP.IIM.?
maximum 100 0.24?0.05 0.84?0.04 0.54?0.04 CBCISP.IIM.?
maximum 90 0.73?0.05 0.45?0.06 0.59?0.04?ISP.JIM minimum 40 0.20?0.06 0.75?0.06 0.47?0.04ISP.IIM.?
minimum 10 0.33?0.07 0.77?0.06 0.55?0.04 WordNetISP.IIM.?
minimum 20 0.87?0.04 0.17?0.05 0.51?0.05?
Indicates statistically significant results (with 95% confidence) when compared with all baseline systems using pairwise t-test.5695.2 Filtering QualityFor each ISP algorithm and parameter combina-tion, we constructed a confusion matrix on the de-velopment set and computed the system sensitivity,specificity and accuracy as described in Section4.3.
This resulted in 180 experiments on the devel-opment set.
For each ISP algorithm and semanticclass source, we selected the best parameter com-binations according to the following criteria:?
Accuracy: This system has the best overall abil-ity to correctly accept and reject inferences.?
90%-Specificity: Several formal semantics andtextual entailment researchers have commentedthat inference rule collections like DIRT are dif-ficult to use due to low precision.
Many haveasked for filtered versions that remove incorrectinferences even at the cost of removing correctinferences.
In response, we show results for thesystem achieving the best sensitivity while main-taining at least 90% specificity on the DEV set.We evaluated the selected systems on the TESTset.
Table 1 summarizes the quality of the systemsselected according to the Accuracy criterion.
Thebest performing system, ISP.IIM.
?, performed  sta-tistically significantly better than all three base-lines.
The best system according to the 90%-Specificity criteria was ISP.JIM, which coinciden-tally has the highest accuracy for that model asshown in Table 16.
This result is very promisingfor researchers that require highly accurate infer-ence rules since they can use ISP.JIM and expect torecall 17% of the correct inferences by only ac-cepting false positives 12% of the time.Performance and Error AnalysisFigures 1a) and 1b) present the full confusion ma-trices for the most accurate and highly specific sys-tems, with both systems selected on the DEV set.The most accurate system was ISP.IIM.
?, which isthe most permissive of the algorithms.
This sug-6 The reported sensitivity of ISP.Joint in Table 1 is below90%, however it achieved 90.7% on the DEV set.gests that a larger corpus for learning SPs may beneeded to support stronger performance on themore restrictive methods.
The system in Figure1b), selected for maximizing sensitivity whilemaintaining high specificity, was 70% correct inpredicting correct inferences.Figure 2 illustrates the ROC curve for all oursystems and parameter combinations on the TESTset.
ROC curves plot the true positive rate againstthe false positive rate.
The near-diagonal line plotsthe three baseline systems.Several trends can be observed from this figure.First, systems using the semantic classes fromWordNet tend to perform less well than systemsusing CBC classes.
As discussed in Section 4.2, weused a very simplistic extraction of semanticclasses from WordNet.
The results in Figure 2serve as a lower bound on what could be achievedwith a better extraction from WordNet.
Upon in-spection of instances that WordNet got incorrectbut CBC got correct, it seemed that CBC had amuch higher lexical coverage than WordNet.
Forexample, several of the instances contained propernames as either the X or Y argument (WordNet haspoor proper name coverage).
When an argument isnot covered by any class, the inference is rejected.Figure 2 also illustrates how our three differentISP algorithms behave.
The strictest filters, ISP.JIMand ISP.IIM.
?, have the poorest overall perform-ance but, as expected, have a generally very lowrate of false positives.
ISP.IIM.
?, which is a muchmore permissive filter because it does not requireROC on the TEST Set00.10.20.30.40.50.60.70.80.910 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11-SpecificitySensitivityBaselines WordNet CBC ISP.JIM ISP.IIM.AND ISP.IIM.ORFigure 2.
ROC curves for our systems on TEST.GOLD STANDARD a)1 01 184 139SYSTEM0 63 114GOLD STANDARD b)1 01 42 28SYSTEM0 205 225Figure 1.
Confusion matrices for a) ISP.IIM.?
?
bestAccuracy; and b) ISP.JIM ?
best 90%-Specificity.570both arguments of a relation to match, has gener-ally many more false positives but has an overallbetter performance.We did not include in Figure 2 an analysis of theminimum, maximum, and average ranking strate-gies presented in Section 3.2 since they generallyproduced nearly identical results.For the most accurate system, ISP.IIM.
?, we ex-plored the impact of the cutoff threshold ?
on thesensitivity, specificity, and accuracy, as shown inFigure 3.
Rather than step the values by 10% as wedid on the DEV set, here we stepped the thresholdvalue by 2% on the TEST set.
The more permis-sive values of ?
increase sensitivity at the expenseof specificity.
Interestingly, the overall accuracyremained fairly constant across the entire range of?, staying within 0.05 of the maximum of 0.62achieved at ?=30%.Finally, we manually inspected several incorrectinferences that were missed by our filters.
A com-mon source of errors was due to the many incorrect?antonymy?
inference rules generated by DIRT,such as ?X is rejected in Y??
?X is accepted in Y?.This recognized problem in DIRT occurs becauseof the distributional hypothesis assumption used toform the inference rules.
Our ISP algorithms sufferfrom a similar quandary since, typically, antony-mous relations take the same sets of arguments forX (and Y).
For these cases, ISP algorithms learnmany selectional preferences that accept the sametypes of entities as those that made DIRT learn theinference rule in the first place, hence ISP will notfilter out many incorrect inferences.6 ConclusionWe presented algorithms for learning what we callinferential selectional preferences, and presentedevidence that learning selectional preferences canbe useful in filtering out incorrect inferences.
Fu-ture work in this direction includes further explora-tion of the appropriate inventory of semanticclasses used as SP?s.
This work constitutes a steptowards better understanding of the interaction ofselectional preferences and inferences, bridgingthese two aspects of semantics.ReferencesBarzilay, R.; and McKeown, K.R.
2001.Extracting Paraphrases from aParallel Corpus.
In Proceedings of ACL 2001. pp.
50?57.
Toulose,France.Baker, C.F.
; Fillmore, C.J.
; and Lowe, J.B. 1998.
The BerkeleyFrameNet Project.
In Proceedings of COLING/ACL 1998.  pp.
86-90.
Montreal, Canada.Cover, T.M.
and Thomas, J.A.
1991.
Elements of Information Theory.John Wiley & Sons.Fellbaum, C. 1998.
WordNet: An Electronic Lexical Database.
MITPress.Harabagiu, S.; and Hickl, A.
2006.
Methods for Using TextualEntailment in Open-Domain Question Answering.
In Proceedingsof ACL 2006.  pp.
905-912.
Sydney, Australia.Katz, J.; and Fodor, J.A.
1963.
The Structure of a Semantic Theory.Language, vol 39. pp.170?210.Lenat, D. 1995.
CYC: A large-scale investment in knowledgeinfrastructure.
Communications of the ACM, 38(11):33?38.Levin, B.
1993.
English Verb Classes and Alternations: A PreliminaryInvestigation.
University of Chicago Press, Chicago, IL.Light, M. and Greiff, W.R. 2002.
Statistical Models for the Inductionand Use of Selectional Preferences.
Cognitive Science,26:269?281.Lin, D. 1993.
Parsing Without OverGeneration.
In Proceedings ofACL-93.
pp.
112-120.
Columbus, OH.Lin, D. and Pantel, P. 2001.
Discovery of Inference Rules forQuestion Answering.
Natural Language Engineering 7(4):343-360.Moldovan, D.I.
; Clark, C.; Harabagiu, S.M.
; Maiorano, S.J.
2003.COGEX: A Logic Prover for Question Answering.
In Proceedingsof HLT-NAACL-03.
pp.
87-93.
Edmonton, Canada.Pantel, P. and Lin, D. 2002.
Discovering Word Senses from Text.
InProceedings of KDD-02.
pp.
613-619.
Edmonton, Canada.Resnik, P. 1996.
Selectional Constraints: An Information-TheoreticModel and its Computational Realization.
Cognition, 61:127?159.Romano, L.; Kouylekov, M.; Szpektor, I.; Dagan, I.; Lavelli, A.
2006.Investigating a Generic Paraphrase-Based Approach for RelationExtraction.
In EACL-2006.
pp.
409-416.
Trento, Italy.Rosch, E. 1978.
Human Categorization.
In E. Rosch and B.B.
Lloyd(eds.)
Cognition and Categorization.
Hillsdale, NJ: Erlbaum.Siegel, S. and Castellan Jr., N. J.
1988.
Nonparametric Statistics forthe Behavioral Sciences.
McGraw-Hill.Szpektor, I.; Tanev, H.; Dagan, I.; and Coppola, B.
2004.
Scalingweb-based acquisition of entailment relations.
In Proceedings ofEMNLP 2004. pp.
41-48.
Barcelona,Spain.Wilks, Y.; and Fass, D. 1992.
Preference Semantics: a family history.Computing and Mathematics with Applications, 23(2).
A shorterversion in the second edition of the Encyclopedia of ArtificialIntelligence, (ed.)
S. Shapiro.Zanzotto, F.M.
; Pennacchiotti, M.; Pazienza, M.T.
2006.
DiscoveringAsymmetric Entailment Relations between Verbs using SelectionalPreferences.
In COLING/ACL-06.
pp.
849-856.
Sydney, Australia.Figure 3.
ISP.IIM.?
(Best System)?s performancevariation over different values for the ?
threshold.ISP.IIM.OR (Best System)'s Performance vs. Tau-Thresholds0.20.30.40.50.60.70.80 10 20 30 40 50 60 70 80 90 100Tau-ThresholdsSensitivity Specificity Accuracy571
