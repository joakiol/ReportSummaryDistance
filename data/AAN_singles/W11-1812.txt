Proceedings of BioNLP Shared Task 2011 Workshop, pages 83?88,Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational LinguisticsOverview of the Entity Relations (REL) supporting task ofBioNLP Shared Task 2011Sampo Pyysalo?
Tomoko Ohta?
Jun?ichi Tsujii?
?Department of Computer Science, University of Tokyo, Tokyo, Japan?Microsoft Research Asia, Beijing, China{smp,okap}@is.s.u-tokyo.ac.jp, jtsujii@microsoft.comAbstractThis paper presents the Entity Relations(REL) task, a supporting task of the BioNLPShared Task 2011.
The task concerns the ex-traction of two types of part-of relations be-tween a gene/protein and an associated en-tity.
Four teams submitted final results for theREL task, with the highest-performing systemachieving 57.7% F-score.
While experimentssuggest use of the data can help improve eventextraction performance, the task data has sofar received only limited use in support ofevent extraction.
The REL task continues asan open challenge, with all resources availablefrom the shared task website.1 IntroductionThe BioNLP Shared Task 2011 (BioNLP ST?11)(Kim et al, 2011a), the follow-up event to theBioNLP?09 Shared Task (Kim et al, 2009), wasorganized from August 2010 (sample data release)to March 2011.
The shared task was divided intotwo stages, with supporting tasks carried out be-fore the main tasks.
The motivation for this tasksetup drew in part from analysis of the results of theprevious shared task, which suggested that eventsthat involve coreference or entity relations repre-sent particular challenges for extraction.
To help ad-dress these challenges and encourage modular ex-traction approaches, increased sharing of successfulsolutions, and an efficient division of labor, the twowere separated into independent supporting tasks onCoreference (CO) (Nguyen et al, 2011) and EntityRelations in BioNLP ST?11.
This paper presents theEntity Relations (REL) supporting task.2 Task SettingIn the design of the REL task, we followed the gen-eral policy of the shared task in assuming namedentity recognition (NER) as a given starting point:participants were provided with manually annotatedgold standard annotations identifying gene/proteinnames in all of the training, development, and finaltest data.
By limiting effects due to NER perfor-mance, the task remains more specifically focusedon the key challenge studied.Following the results and analysis from previousstudies (Pyysalo et al, 2009; Ohta et al, 2010), wechose to limit the task specifically to relations in-volving a gene/protein named entity (NE) and oneother entity.
Fixing one entity involved in each re-lation to an NE helps assure that the relations are?anchored?
to real-world entities, and the specificchoice of the gene/protein NE class further pro-vides a category with several existing systems andsubstantial ongoing efforts addressing the identifica-tion of those referents through named entity recog-nition and normalization (Leaman and Gonzalez,2008; Hakenberg et al, 2008; Krallinger et al, 2008;Morgan et al, 2008; Wermter et al, 2009).
Therecognition of biologically relevant associations ofgene/protein NEs is a key focus of the main eventextraction tasks of the shared task.
By contrast, inthe REL task setting, only one participant in eachbinary relation is a gene/protein NE, while the othercan be either a non-name reference such as promoteror the name of an entity not of the gene/protein type(e.g.
a complex).1 Motivated in part by the relativelylimited number of existing methods for the detec-1Pronominal references are excluded from annotation scope.83Figure 1: Simple REL annotation example showing aPROTEIN-COMPONENT (PR-CO) relation between ?hi-stone H3?
and ?lysine 9?.
An associated METHYLATIONevent and its arguments (shaded, not part of the REL tasktargets) shown for context.tion of such entity references, their detection is in-cluded in the task: participants must recognize thesesecondary entities in addition to extracting the rela-tions they participate in.
To limit the demands of thisNER-type task, these entities are not assigned spe-cific types but rather the generic type ENTITY, andexact matching of their boundaries is not required(see Section 4).The general task setting encompasses a rich setof potential relation extraction targets.
For the task,we aimed to select relations that minimize overlapbetween the targets of other tasks while maintain-ing relevance as a supporting goal.
As the maintasks primarily target events (?things that happen?
)involving change in entities, we chose to focus inthe REL task on what we have previously termed?static relations?
(Pyysalo et al, 2009), that is, rela-tions such as part-of that hold between entities with-out necessary implication of causality or change.
Aprevious study by Van Landeghem et al (2010) in-dicated that this class of relations may benefit eventextraction.
We based our choice of specific targetrelation on previous studies of entity relations do-main texts (Pyysalo et al, 2009; Ohta et al, 2010),which indicated that part-whole relations are by farthe most frequent class of relevant relations for thetask setting and proposed a classification of theserelations for biomedical entities.
We further foundthat ?
in terms of the taxonomy of Winston et al(1987) ?
object-component and collection-memberrelations account for the the great majority of part-of relations relevant to the domain.
For REL, wechose to omit collection-member relations in part tominimize overlap with the targets of the coreferencetask.
Instead, we focused on two specific types ofobject-component relations, that holding between agene or protein and its part (domain, regions, pro-moters, amino acids, etc.)
and that between a proteinItem Training Devel TestAbstract 800 150 260Word 176,146 33,827 57,256Protein 9,297 2,080 3,589Relation 1,857 480 497PROTEIN-COMPONENT 1,302 314 334SUBUNIT-COMPLEX 555 166 163Table 1: REL dataset statistics.and a complex that it is a subunit of.
Following thebiological motivation and the general practice in theshared task to term genes and gene products PRO-TEIN for simplicity, we named these two relationsPROTEIN-COMPONENT and SUBUNIT-COMPLEX.Figure 1 shows an illustration of a simple relationwith an associated event (not part of REL).
Eventswith Site arguments such as that shown in the figureare targeted in the GE, EPI, and ID tasks (Kim et al,2011b; Ohta et al, 2011; Pyysalo et al, 2011) thatREL is intended to support.3 DataThe task dataset consists of new annotations forthe GENIA corpus (Kim et al, 2008), building onthe existing biomedical term annotation (Ohta etal., 2002), the gene and gene product name annota-tion (Ohta et al, 2009) and the syntactic annotation(Tateisi et al, 2005) of the corpus.
The general fea-tures of the annotation are presented by Pyysalo etal.
(2009), describing a previous release of a subsetof the data.
The REL task annotation effort extendedthe coverage of the previously released annotation toall relations of the targeted types stated within sen-tence scope in the GENIA corpus.For compatibility with the BioNLP ST?09 and itsrepeat as the GE task in 2011 (Kim et al, 2011b),the REL task training/development/test set divisionof the GENIA corpus abstracts matches that of theBioNLP ST?09 data.
The statistics of the corpus arepresented in Table 1.
We note that both in terms oftraining examples and the data available in the givendevelopment set, the number of examples of thePROTEIN-COMPONENT relation is more than twicethat for SUBUNIT-COMPLEX.
Thus, at least formethods based on machine learning, we might gen-erally expect to find higher extraction performancefor the former relation.84NLP Extraction Other resourcesRank Team Org Word Parse Entities Relations Corpora Other1 UTurku 1BI Porter McCCJ + SD SVM SVM - -2 VIBGhent 1NLP, 1ML, 1BI Porter McCCJ + SD SVM SVM GENIA, PubMed word similarities3 ConcordU 2NLP - McCCJ + SD Dict Rules - -3 HCMUS 6L OpenNLP OpenNLP Dict Rules - -Table 2: Participants and summary of system descriptions.
Abbreviations: BI=Bioinformatician, NLP=NaturalLanguage Processing researcher, ML=Machine Learning researcher, L=Linguist, Porter=Porter stemmer,McCCJ=McClosky-Charniak-Johnson parser, SD=Stanford Dependency conversion, Dict=DictionaryUTurku VIBGhent ConcordU HCMUSPROTEIN-COMPONENT 50.90 / 68.57 / 58.43 47.31 / 36.53 / 41.23 23.35 / 52.05 / 32.24 20.96 / 21.63 / 21.29SUBUNIT-COMPLEX 48.47 / 66.95 / 56.23 47.85 / 38.12 / 42.43 26.38 / 39.81 / 31.73 4.91 / 66.67 / 9.14Total 50.10 / 68.04 / 57.71 47.48 / 37.04 / 41.62 24.35 / 46.85 / 32.04 15.69 / 23.26 / 18.74Table 3: Primary evaluation results for the REL task.
Results given as recall / precision / F-score.4 EvaluationThe evaluation of the REL task is relation-based anduses the standard precision/recall/F1-score metrics.Similarly to the BioNLP?09 ST and most of the 2011main tasks, the REL task relaxes the equality criteriafor matching text-bound annotations: for a submis-sion entity to match an entity in the gold referenceannotation, it is sufficient that the span of the sub-mitted entity (i.e.
its start and end positions in text)is entirely contained within the span of the gold an-notation.
This corresponds largely to the approxi-mate span matching criterion of the 2009 task (Kimet al, 2009), although the REL criterion is slightlystricter in not involving testing against an extensionof the gold entity span.
Relation matching is exact:for a submitted relation to match a gold one, both itstype and the related entities must match.5 Results5.1 ParticipationTable 2 summarizes the participating groups and ap-proaches.
We find a remarkable number of sim-ilarities between the approaches of the systems,with all four utilizing full parsing and a depen-dency representation of the syntactic analysis, andthe three highest-ranking further specifically thephrase structure parser of Charniak and Johnson(2005) with the biomedical domain model of Mc-Closky (2009), converted into Stanford Dependencyform using the Stanford tools (de Marneffe et al,2006).
These specific choices may perhaps be influ-enced by the success of systems building on themin the 2009 shared task (e.g.
Bjo?rne et al (2009)).While UTurku (Bjo?rne and Salakoski, 2011) andVIBGhent (Van Landeghem et al, 2011) furtheragree in the choice of Support Vector Machines forthe recognition of entities and the extraction of rela-tions, ConcordU (Kilicoglu and Bergler, 2011) andHCMUS (Le Minh et al, 2011) pursue approachesbuilding on dictionary- and rule-based extraction.Only the VIBGhent system makes use of resourcesexternal to those provided for the task, extractingspecific semantic entity types from the GENIA cor-pus as well as inducing word similarities from alarge unannotated corpus of PubMed abstracts.5.2 Evaluation resultsTable 3 shows the results of the REL task.
We findthat the four systems diverge substantially in termsof overall performance, with all pairs of systemsof neighboring ranks showing differences approach-ing or exceeding 10% points in F-score.
Whilethree of the systems notably favor precision over re-call, VIBGhent shows a decided preference for re-call, suggesting a different approach from UTurku indesign details despite the substantial similarities inoverall system architecture.
The highest-performing85system, UTurku, shows an F-score in the generalrange of state-of-the-art results in the main eventextraction task, which could be taken as an indica-tion that the reliability of REL task analyses createdwith presently available methods may not be highenough for direct use as a building block for themain tasks.
However, the emphasis of the UTurkusystem on precision is encouraging for such ap-plications: nearly 70% of the entity-relation pairsthat the system predicts are correct.
The two top-ranking systems show similar precision and recallresults for the two relation types.
The submission ofHCMUS shows a decided advantage for PROTEIN-COMPONENT relation extraction as tentatively pre-dicted from the relative numbers of training exam-ples (Section 3 and Table 1), but their rule-basedapproach suggests training data size is likely notthe decisive factor.
While the limited amount ofdata available prevents strong conclusions from be-ing drawn, overall the lack of correlation betweentraining data size and extraction performance sug-gests that performance may not be primarily limitedby the size of the available training data.6 DiscussionThe REL task was explicitly cast in a support rolefor the main event extraction tasks, and REL par-ticipants were encouraged to make their predictionsof the task extraction targets for the various maintask datasets available to main task participants.
TheUTurku team responded to this call for supportinganalyses, running their top-ranking REL task sys-tem on all main task datasets and making its outputavailable as a supporting resource (Stenetorp et al,2011).
In the main tasks, we are so far aware ofone application of this data: the BMI@ASU team(Emadzadeh et al, 2011) applied the UTurku RELpredictions as part of their GE task system for re-solving the Site arguments in events such as BIND-ING and PHOSPHORYLATION (see Figure 1).
Whilemore extensive use of the data would have been de-sirable, we find this application of the REL analysesvery appropriate to our general design for the role ofthe supporting and main tasks and hope to see othergroups pursue similar possibilities in future work.7 ConclusionsWe have presented the preparation, resources, re-sults and analysis of the Entity Relations (REL) task,a supporting task of the BioNLP Shared Task 2011involving the recognition of two specific types ofpart-of relations between genes/proteins and associ-ated entities.
The task was run in a separate earlystage in the overall shared task schedule to allowparticipants to make use of methods and analyses forthe task as part of their main task submissions.Of four teams submitting finals results, thehighest-performing system, UTurku, achieved a pre-cision of 68% at 50% recall (58% F-score), apromising level of performance given the relativenovelty of the specific extraction targets and theshort development period.
Nevertheless, challengesremain for achieving a level of reliability that wouldallow event extraction systems to confidently buildon REL analyses to address the main informationextraction tasks.
The REL task submissions, repre-senting four independent perspectives into the task,are a valuable resource for further study of both theoriginal task data as well as the relative strengths andweaknesses of the participating systems.
In futurework, we will analyse this data in detail to betterunderstand the challenges of the task and effectiveapproached for addressing them.The UTurku team responded to a call for sup-porting analyses by providing predictions from theirREL system for all BioNLP Shared Task main taskdatasets.
These analyses were adopted by at leastone main task participant as part of their system,and we expect that this resource will continue toserve to facilitate the study of the position of part-of relations in domain event extraction.
The RELtask will continue as an open shared challenge, withall task data, evaluation software, and analysis toolsavailable to all interested parties from http://sites.google.com/site/bionlpst/.AcknowledgmentsWe would like to thank the UTurku team for theirgenerosity with their time and tools in providingREL task analyses for all the BioNLP Shared Task2011 main task datasets.
This work was supportedby Grant-in-Aid for Specially Promoted Research(MEXT, Japan).86ReferencesJari Bjo?rne and Tapio Salakoski.
2011.
Generaliz-ing biomedical event extraction.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Extract-ing complex biological events with rich graph-basedfeature sets.
In Proceedings of the BioNLP 2009 Work-shop Companion Volume for Shared Task, pages 10?18, Boulder, Colorado, June.
Association for Compu-tational Linguistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 173?180.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
InProceedings of the Fifth International Conferenceon Language Resources and Evaluation (LREC?06),pages 449?454.Ehsan Emadzadeh, Azadeh Nikfarjam, and GracielaGonzalez.
2011.
Double layered learning for bio-logical event extraction from text.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.J.
Hakenberg, C. Plake, R. Leaman, M. Schroeder,and G. Gonzalez.
2008.
Inter-species normaliza-tion of gene mentions with GNAT.
Bioinformatics,24(16):i126.Halil Kilicoglu and Sabine Bergler.
2011.
Adapting ageneral semantic interpretation approach to biologicalevent extraction.
In Proceedings of the BioNLP 2011Workshop Companion Volume for Shared Task, Port-land, Oregon, June.
Association for ComputationalLinguistics.Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008.Corpus annotation for mining biomedical events fromliterature.
BMC Bioinformatics, 9(10).Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overviewof BioNLP?09 Shared Task on Event Extraction.In Proceedings of Natural Language Processing inBiomedicine (BioNLP) NAACL 2009 Workshop, pages1?9.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011a.
Overviewof BioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011b.
Overview of the Genia Eventtask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.M.
Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-abe, J. Wilbur, L. Hirschman, and A. Valencia.2008.
Evaluation of text-mining systems for biology:overview of the Second BioCreative community chal-lenge.
Genome biology, 9(Suppl 2):S1.Quang Le Minh, Son Nguyen Truong, and Quoc Ho Bao.2011.
A pattern approach for biomedical event anno-tation.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, Portland, Oregon,June.
Association for Computational Linguistics.R.
Leaman and G. Gonzalez.
2008.
Banner: an exe-cutable survey of advances in biomedical named en-tity recognition.
Pacific Symposium on Biocomputing,pages 652?663.David McClosky.
2009.
Any Domain Parsing: Auto-matic Domain Adaptation for Natural Language Pars-ing.
Ph.D. thesis, Department of Computer Science,Brown University.A.A.
Morgan, Z. Lu, X. Wang, A.M. Cohen, J. Fluck,P.
Ruch, A. Divoli, K. Fundel, R. Leaman, J. Haken-berg, et al 2008.
Overview of BioCreative II genenormalization.
Genome biology, 9(Suppl 2):S3.Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii.
2011.Overview of the Protein Coreference task in BioNLPShared Task 2011.
In Proceedings of the BioNLP 2011Workshop Companion Volume for Shared Task, Port-land, Oregon, June.
Association for ComputationalLinguistics.Tomoko Ohta, Yuka Tateisi, Hideki Mima, and Jun?ichiTsujii.
2002.
GENIA corpus: An annotated researchabstract corpus in molecular biology domain.
In Pro-ceedings of the Human Language Technology Confer-ence (HLT?02), pages 73?77.Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, YueWang, and Jun?ichi Tsujii.
2009.
IncorporatingGENETAG-style annotation to GENIA corpus.
InProceedings of BioNLP?09, pages 106?107.Tomoko Ohta, Sampo Pyysalo, Jin-Dong Kim, andJun?ichi Tsujii.
2010.
A re-evaluation of biomedicalnamed entity-term relations.
Journal of Bioinformat-ics and Computational Biology (JBCB), 8(5):917?928.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 Workshop87Companion Volume for Shared Task, Portland, Oregon,June.
Association for Computational Linguistics.Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, andJun?ichi Tsujii.
2009.
Static Relations: a Piecein the Biomedical Information Extraction Puzzle.In Proceedings of Natural Language Processing inBiomedicine (BioNLP) NAACL 2009 Workshop, pages1?9, Boulder, Colorado.
Association for Computa-tional Linguistics.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, TomokoOhta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011.BioNLP Shared Task 2011: Supporting Resources.
InProceedings of the BioNLP 2011 Workshop Compan-ion Volume for Shared Task, Portland, Oregon, June.Association for Computational Linguistics.Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, andJun?ichi Tsujii.
2005.
Syntax annotation for the GE-NIA corpus.
In Proceedings of IJCNLP?05, pages222?227.Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,and Yves Van de Peer.
2010.
Integration of static re-lations to enhance event extraction from text.
In Pro-ceedings of the 2010 Workshop on Biomedical NaturalLanguage Processing, pages 144?152.Sofie Van Landeghem, Thomas Abeel, Bernard De Baets,and Yves Van de Peer.
2011.
Detecting entity rela-tions as a supporting task for bio-molecular event ex-traction.
In Proceedings of the BioNLP 2011 Work-shop Companion Volume for Shared Task, Portland,Oregon, June.
Association for Computational Linguis-tics.J.
Wermter, K. Tomanek, and U. Hahn.
2009.
High-performance gene name normalization with GeNo.Bioinformatics, 25(6):815.Morton E. Winston, Roger Chaffin, and Douglas Her-rmann.
1987.
A taxonomy of part-whole relations.Cognitive Science, 11.88
