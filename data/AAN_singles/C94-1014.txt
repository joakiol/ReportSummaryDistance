A MATCI I ING TECHNIQUE IN  EXAMPLE, -BASED MACI I INE  TRANSLAT IONLambros  CRANIAS ,  Harr is  PAPAGEORGIOU,  Stel ios P IPER ID ISInstitute for Language and Speech Processing, GREECEStelios.
P iper id i~urokom.
ieABSTRACTThis paper addresses an important problem inExample-Based Machine Translation (EBMT), namelyhow to measure similarity between a sentence fragmentand a set of stored examples.
A new method isproposed that measures imilarity according to bothsurface structure and content.
A second contribution isthe use of clustering to make retrieval of the bestmatching example from the database more efficient.Results on a large number of test cases from theCELEX database are presented.1.
INTRODUCTIONEBMT is based on the idea of performingtranslation by imitating translation examples of similarsentences \[Nagao 84\].
In this type of translationsystem, a large amount of bi/multi-lingual translationexamples has been stored in a textual database andinput expressions are rendered in the target language byretrieving from the database that example which is mostsimilar to the input.There are three key issues which pertain toexample-based translation :?
establishment of correspondence b tween units in abi/multi-lingual text at sentence, phrase or word level?
a mechanism for retrieving from the database the unitthat best matches the input?
exploiting the retrieved translation example toproduce the actual translation of the input sentence\[Brown 91\] and \[Gale 91\] have prolx~Sed methodsfor establishing correspondence b tween sentences inbilingual corpora.
\[Brown 93\], \[Sadler 901 and \[Kaji92\] have tackled the problem of establishingcorrespondences between words and phrases inbilingual texts.The third key issue of EBMT, that is exploiting theretrieved translation example, is usually dealt with byintegrating into the system conventional MT techniques\[Kaji 92\], \[Sumita 91\].
Simple modifications of thetranslation proposal, such as word substitution, wouldalso be possible, provided that alignment of thetranslation archive at word level was awdlable.In establishing a mechanism for the best matchretrieval, which is the topic of this paper, the crucialtasks are: (i) determining whether the search is formatches at sentence or sub-sentence level, that isdetermining the "text unit", and (ii) the definition ofthe metric of similarity between two text units.As far as (i) is concerned, the olwious choice is touse as text unit the sentence.
This is because, not onlyare sentence Ixmndaries unambiguous hut alsotranslation propo~ls at sentence level is what atranslator is usually looking for.
Sentences can,however, be quite long.
And the longer they are, theless possible it is that they will have an exact match inthe translation archive, and the less flexible the EBMTsystem will be.On the other hand if the text unit is the sub-sentencewe lace one major problem, that is the possibility thatthe resulting translation of the whole sentence will beof low quality, due to Ixmndary friction and incorrectchunking.
In practice, EBMT systems that operate atsub-sentence l vel involve the dynamic derivation ofthe optimum length of segments of the input sentenceby analysing the available parallel corpora.
Thisrexluires a procedure for determining the best "cover"of an input text by segments of sentences contained inthe database \[Nirenburg 93\].
It is assumed that thetranslation of the segments of the database that coverthe input sentence is known.
What is needed, therefore,is a procedure lbr aligning parallel texts at sub-sentencelevel \[Kaji 921, \[Sadler 901.
If sub-sentence alignmentis available, the approach is fully automated but is quitevulnerable to the problem of luw quality as mentionedabove, as well as to ambiguity problems when theproduced segments are rather small.Despite the fact that almost all running EBMTsystems employ the sentence as the text unit, it isbelieved that the potential of EBMT lies on theexploitation of fragments of text snualler that sentencesand the combination of such fragments to produce thetranslation of whole sentences \[Sato 90\].
Automaticsub-sentential ignment is, however, a problem yet tobe solved.Turning to the definition of the metric of similarity,the requirement is usually twotold.
The similarity100metric applied to two sentences (by sentence from nowon we will refer to both sentence and sub-sentencefragmen0 should indicate how similar the comparedsentences are, and perhaps the parts of the two ~ntencesthat contributed to the similarity score.
The latter couldbe just a useful indication to the translator using theEBMT system, or a crucial functional factor of thesystem as will be later explained.The similarity metrics reported in the literature canbe characterised depending on the text patterns they areapplied on.
So, the word-based metrics compareindividual words of the two sentences in terms of theirmorphological paradigms, synonyms, hyperonyms,hyponyms, antonyms, pos tags... \[Nirenburg 93\] or usea semantic distance d (0~d<l) which is determinM bythe Most Specific Common Abstraction (MSCA)obtained from a thesaurus abstraction hierarchy \[Sumita91\].
Then, a similarity metric is devised, which reflectsthe similarity of two sentences, hy combining theindividual contributions towards similarity stemmingfrom word comparisons.The word-based metrics are the most tx)pular, butother approaches include syntax-rule driven metrics\[Sumita 88\], character-based metrics \[Sato 921 as wellas some hybrids \[Furuse 921.
The character-basedmetric has been applied to Japanese, taking advantage ofcertain characteristics of the Japanese.
The syntax-ruledriven metrics try to capture similarity of two sentencesat the syntax level.
This seems very promising, sincesimilarity at the syntax level, perhaps coupled by lexicalsimilarity in a hybrid configuration, would be the bestthe EBMT system could ofler as a translation propo~l.
'/'he real time feasibility of such a system is, however,questionable since it involves the complex task ofsyntactic analysis.In section II a similarity metric is proposed andanalysed.
The statistical system presented consists oftwo phases, tire 12arning and the decision nmking orRecognition phase, which are described in section I11.Finally, in section IV the experiment configuration isdiscussed and the results evaluated.I1.
TItE SIMILARITY METRICTo encode a ~ntence into a vector, we exploitinformation about the functional words/phrases (fws)appearing in it, as well as about the lemnms and pos(part-of speech) tags of the words aplrearing Iretwcenfws/phrases.
Based on tile combination of fws/phrasesdata and pos tags, a simple view of the surf~tce syntacticstructure of each sentence is obtained.To identify the fws/phrases in a given corpus thetollowing criteria are applied :?
fws introduce a syntactically standard behaviour?
most of the fws belong to closed classes.?
the semantic behaviour of fws is determined throughtheir context?
most of the fws determine phrase boundariesfws have a relatively high frequency in the corpusAccording to these criteria, prepositions,conjunctions, determiners, pronouns, certain adverbialsetc.
are regarded as fws.
Having identified the fws ofthe corpus we distinguish groups o f fws  on tire basis oftheir interchangeability n certain phrase structures.
Thegrouping eaters, also, for the multiplicity of usages of acertain word which has been identified as a fw, since afv?
can be a part of many different groups.
In this way,fws can serve the retrieval procedure with respect o thefollowing two levels of contribution towards thesinlilarity score of two sentences :Identity of fws of retrieved example and input (I)fws of retrieved example ~md input not identical hutlrelonging to tire same group (G)To obtain the lenmms and pos tags of the remainingwords in a sentence, we use a part-of-speech Taggerwith n(__2 disambiguation module, since tiffs would Iretime consuming and not 100% accurate.
Instead, weintroduce the concept of mnbiguity class (ac) and werepresent each non-fw by its ac and the correspondinglemnm(s) (for example, the unambiguous word "eat"would be represented by the ac which is the set {verb}and the lemnm "eat") (in English, foe an ambiguousword, the corresponding lcnnuas will usually beidentical.
But this is rarely true tot Greek).
Hence, tlletbllowing two levels of contribution to the similarityscore stem from non-fws :?
overlapping of tlre sets of possible lemmas of thetwo words (I,)?
overlapping of the ambiguity classes of the twowords (W)llence, each sentence of the source part of thetranslation archive is represented by a pattern, which isexpressed as an ordered series of tile above mentionedfeature components.A similarity metric is defined between two suchvectors, and is used in both the Learuing andRecognition phases.
Comparing a test vector against areference vector is, however, not straightfi)rward, sincethere are generally axis fluctuations between the vectors(not necessarily aligned vectors and of most probablydifferent length).
To overcome these problems we use atwo-level Dynamic Programming (DP) techniqueISakoe 78\], INey 84\].
The first level treats the matchesat fw level, while tile second is reached only in case of amatch in the first level, and is concerned with thelemmas and tags of the words within fw boundaries.Both levels utilise the ~me (DP) model which is nextdescribed.70/We have already referred to the (I) and (G)contributions to the similarity score due to fws.
But thisis not enough.
We should also take into account whetherthe fws appear in the same order in the two sentences,whether an extra (or a few) fws intervene in one of thetwo sentences, whether certain fws are missing ... Todeal with these problems, we introduce a yet thirdcontribution to the similarity score, which is negativeand is called penalty score (P).
So, as we are movingalong a diagonal of the xy-plane (corresponding tomatched fws), whenever a fw is mismatched, itproduces a negative contribution to the score along ahorizontal or vertical direction.
In figure 1 the allowabletransitions in the xy-plane are shown.P.
.
.
.Fig.
I, The DP allowable transitionsWhenever a diagonal transition is investigated, thesystem calls the second level DP-algorithm whichproduces a local additional score due to the potentialsimilarity of lemmas and tags of the words lyingbetween the corresponding fws.
This score is calculatedusing exactly the same DP-algorithm as the one treatingfws (allowing additions, deletions,...), provided that weuse (L), cr) and (PT) (a penalty score attributed to amismatch at the tag-level) in place of (I), (G) and (P)respectively.The outcome of the DP-algorithm is the similarityscore between two vectors which allows for differentlengths of the two sentences, imilarity of different partsof the two sentences (last part of one with the first partof the other) and finally variable number of additionsand deletions.
The score produced, corresponds to twocoherent parts of the two sentences under comparison.Emphasis should be given to the variable number ofadditions and deletions.
The innovation of the penaltyscore (which is in fact a negative score) provides thesystem with the flexibility to afford a different numberof additions or deletions depending on the accumulatedsimilarity score up to the point where these start.Moreover, the algorithm determines, through abacktracking procedure, the relevant parts of the twovectors that contributed to this score.
This is essentialfor the sentence segmentation described in the nextsection.It should also be noted that the similarity scoreproduced is based mainly on the surface syntax of thetwo sentences (as this is indicated by the fws and postags) and in the second place on the actual words of thetwo sentences.
This is quite reasonable, since the twosentences could have almost the same words in thesource language but no similarity at all in th~ source ortarget language (due to different word order, as well asdifferent word utilisation), while if they are similar interms of fws as well as in terms of the pos tags of thewords between fws, then the two sentences wouldahnost certainly be similar (irrelevant of a fewdifferences in the actual words) in the target language aswell (which is the objective).The DP-algorithm proposed seems to be tailored tothe needs of the similarity metric but there is yet a?
crucial set of parameters to be set, that is,~={I,G,P,L,T,PT}.
The DP-algorithm is just theframework for the utilisation of these parameters.
Thevalues of the parameters of A are set dynamicallydepending on the lengths of the sentences undercomparison.
1, G, L, T are set to values (I, G arenornudised by the lengths of the sentences in fws, whileL, T are normalised by the lengths of the blocks ofwords appearing between fws) which produce a 100%similarity score when the sentences are identical, whileP, PT reflect he user's choice of penalising an additionor deletion of a word (functional or not).I lL LEARNING AND RECOGNITION PIIASESIn the Learning phase, the modified k-meansclustering procedure \[Wilpon 8511 is applied to thesource part of the translation archive, aiming to produceclusters of sentences, each represented by its centreonly.
The algorithm produces the optimumsegmentation of the corpus into clusters (based on thesimilarity metric), and determines each cluster centre(which is just a sentence of the corpus) by using theminmax criterion.
The number of clusters can bedetermined automatically by the process, subject tosome cluster quality constraint (for example, minimumintra-cluster similarity), or alternatively can bedetermined externally based upon memory-spacerestrictions and speed requirements.Once the clustering procedure is terminated, a searchis nmde, among the sentences allocated to a cluster, tolocate second best (but good enough) nuttches to thesentences allocated to the remaining clusters.
If suchmatches are traced, the relevant sentences are segmentedand then the updated corpus is reclustered.
After anumber of iterations, convergence is obtained (no newsentence segments are created) and the whole clusteringprocedure is terminated.Although tile objective of a matching mechanismshould be to identify in a database the longest piece oftext that best matches the input, the rationale behindsentence segmentation is in this case self-evident.
It ishighly probable that a sentence is allocated to a clustercenter because of a good match due to a part of it, whiletile ten'mining part has nothing to do with the cluster towhich it will be allocated.
Hence, this part will remainhidden to an input sentence applied to the system at the702recognition phase.
On the other hand, it is also highlyprobable that a given input sentence does not, as awhole, match a corpus sentence, but rather differentparts of it match with segments belonging to differentsentences in the corpus.
Providing whole sentences astranslation proposals, having a part that matched withpart of the input sentence, would perhaps puzzle thetranslator instead of help him (her).But senten6e segmentation is not a straightforwardmatter.
We can not just segment a sentence at the limitsof the part that led to the allocation of the sentence to aspecific cluster.
This is because we need to know thetranslation of this part as well.
tlence, we shouldexpand the limits of the match to cover a "translatableunit" and then segment he sentence.
Autoumtic snb-sentential alignment (which would produce the"translatable units"), however, is not yet mature enoughto produce high fidelity results, l-lence, one resorts tothe use of senti-automatic methods (in our applicationwith the CELEX database, because of the certain formatin which the texts appear, a rough segmentation of thesentences is straightforward and can therefore beautomated).If alignment at sub-sentential level is not available,the segmentation of the sentences of the corpus is notpossible (it is absolutely pointless).
Then, the degree ofsuccess of the Learning ph&~ will depend on the lengthof the sentences contained in the corpus.
The longerthese sentences tend to be, the less successful theLearning pha~.
On the other hand, if alignment at sub-sentential level is available, we could just apply theclustering procedure to these segments.
But then, wemight end up with an uunecessary large number ofclusters and "sentences'.
This is becau~, in a specificcorpus quite a lot of these segments tend to appeartogether.
Hence, by clustering whole sentences and thensegmenting only in case of a good match with a part ofa sentence allocated to a different cluster, we can avoidthe overgeneration f clusters and segments.
When theiterative clustering procedure is finally terminated, the.sentences of the original corpus will have beensegmented to "translatable units" in an optimum way, sothat they are efficiently represented by a set of sentenceswhich are the cluster centres.In the Recognition p "lmse, the vector of the inlmtsentence is extracted and compared against the clustercentres.
Once the favourite cluster(s) is specified, thesearch space is limited to the sentences allocated to thatcluster only, and the same similarity metric is applied toproduce the best match available in the corpus.
If the.sentences in the translation archive have beensegmented, the problem is that, now, we do not knowwhat the "translatable units" of the inpot sentence are(since we do not know its target language quivalent).We only have potential "translatable unit" nmrkers.
Thisis not really a restriction, however, since by setting ahigh enough threshold for the nmtch with a segment(translatable piece of text) in the corpus, we can be surethat the part of the input sentence that contributed tothis good umtch, will also be translatable and we can,therefore, segment his palt.
This process continuesuntil the whole input sentence has been "covered" by.segments of the corpus.IV.
T I lE  API"LICATION - EVALUATIONThe development of the nmtching method presentedin this paper was part of the research work conductedunder the LRE I project TRANSLEARN.
The projectwill initially consider four languages: English, French,Greek and Portuguese.
The application on which we aredeveloping and testing the method is implemented onthe Greek-English language pair of records of theCELEX &ttabase, the computerised documentationsystem on Community Law, which is available in allCommunity languages.
The matching mechanism is, sofar, implemented on the Greek part, providing Englishtranslation proposals for Greek input sentences.
Thesentences contained in tile CELEX database tend to bequite long, but due to tile certain forn~d in which theyappear (corresponding to articles, regulations,...), wewere able to provide the Learning phase with somepotential segmentation points of these sentences in b~)thhmguages of the pair (these segmentation points are inc~ne-to-one correspondence across languages, yieldingthe "sub-sentence" alignment).In tagging the Greek part of the CELEX database wecame across 31 different ambiguity classes, which areutilised in the matching naechanism.
The identificationand grouping of the Greek fws was mainly done withthe help of statistical tools applied to the CELEXdatabase.We tested the system on 8,000 .sentences of theCELEX database.
We are presenting results on twoversions.
One of 80 clusters (which accounts for the 1%of the nnmber of the sentences of the corpus used)which resulted in 10,203 "sentences" (sentences orsegments) in 2 iterations, and one of 160 clusters whichresulted in 10,758 "sente,lces" in 2 iterations.
Toevaluate the system, we asked live translators to assigneach translation proposal of the system (in ourapplication these proposals ometimes refer to segmentsof the input ~ntence) to one of four categories :A : The proposal is the correct (or almost) translationB : The proposal is very helpful in order to produce thetranslationC: The proposal can help in order to produce tiletranslation.D : The proposal is of no use to the translator.We used as test suite 200 sentences of the CELEXdatabase which were not incltlded in the translationarchive.
The system proposed translations for 232"sentences" (segments or whole input sentences) in tile103former case and for 244 in the latter case.
The resultsare tabulated in table 1 (these results refer to the singlebest match located in the translation archive)Table 180 CLUS 160 CLUSA 220 (19%)B 464 {40%)C 209 08%)D 267 123%)1160244/20%)sl2142~),.245 (20%)219 I18%)1220The table shows that in the case of 160 clusters, (I)at 62 % the system will be very useful to the translator,and (2) some information can at least be obtained from82% of the retrievals.
In the case of 80 clusters theresults do not change significantly.
Hence, as far as thesimilarity mettle is concerned the results seem quitepromising (it should, however, be mentioned, that theCELEX database is quite suitable for EBMTapplications, due to its great degree of repetitiveness).On the other hand, the use of clustering of thecorpus dramatically decreases the response time of thesystem, compared to the alternative of searchingexhaustively through the corpus.
Other methods ibrlimiting the search space do exist (for example, usingfull-text retrieval based on content words), but arerather lossy, while clustering provides an effectivemeans of locating the best available match in the corpus(in ternts of the similarity metric employed).
This canbe seen in Table 2, where the column "MISSED"indicates the percentage of the input "sentences" forwhich the best match in the corpus was not located inthe favourite cluster, while the column "MISSED BY"indicates the average deviation of the located bestmatches from the actual best matches in the corpus forth~se cases.
"Fable 2MISSEO MtSSEO By80 clusters ' 10% 6.32 %160 chtsters 8.5 % 6.14 %In Table 1 as well as in Table 2 it can be seen that aquite important decrease in the number of clustersaffected the results only slightly.
This smalldeterioration i the performance of the system is due to"hidden" parts of sentences allocated to clusters (partsthat are not represented by the cluster centres).
Hence,the smaller the "sentences" contained in the databaseand the more the clusters, the better the performance ofthe proposed system.
The number of clusters, however,should be constrained for the search space to beeffectively limited.REFERENCES\[BROWN 91\] Brown P. F. et al (1991).
"AligningSentences in Parallel Corpora".
Proe.
of the 291hAnnual Meeting of the ACL, pp 169-176.\[BROWN 93\] Brown P. F. et al (June 1993).
"Themathematics of Statistical Machine Translation:Parameter Estinmtion".
Computational Lingu&tic:~', pp263-311.\[FURUSE 92\] Furuse O. and H. lida, (1992).
"Cooperation between Transfer and Analysis inExample-Based Framework".
Proc.
Coling, pp 645-651.\[GALE 91\] Gale W. A. and K. W. Church, (1991).
"A Program for Aligning Sentences in BilingualCorpora".
Proe.
of the 29th Annual Meeting of theACL., pp 177-184.\[KAJI 92\] Kaji H., Y. Kida and Y. Morimoto,(1992).
"Learning Translation Templates fromBilingual Text".
Proe.
Coling., pp 672-678.\[NAGAO 84\] Nagao M., (1984).
"A framework of amechanical translation between Japanese and Englishby analogy principle".
Artificial and HumanIntelligence, ed.
Elithorn A. attd Banerji R., North-tlolland, pp 173-180.\[NEY 84\] Ney H., (1984).
"The use of a One-stageDynamic Programming Algorithm for Connected WordRecognition".
IEEE wd.
ASSP-32, No 2.\[NIRENBURG 93\] Nirenburg S. et al (1993).
"TwoApproaches to Matching in Example-Based MachineTranslation".
Proc.
of TMI-93, Kyoto, Japan.\[SADLER 90\] Sadler V. and R. Vendehuans, (1990).
"Pilot Implementation of a Bilingual KnowledgeBank".
Proc.
ofColing, pp 449-451.\[SAKOE 78\] Sakoe H. and S. Chiba, (1978).
"Dynamic Programming Algorithm Optinfisation forSpoken Word Recognition".
IEEE Trans.
on ASSP,vol.
ASSP-26.\[SATO 90\] Sato S. and M. Nagao, (1990).
"TowardMemory-based Translation".
Proc.
~f Coling, pp 247-252.\[SATO 92\] Sato S., (1992).
"CTM: An Example-Based Translation Aid System".
Proc.
of Coling, pp1259-1263.\[SUMITA 88\] Sumita E. and Y. Tsutsumi, (1988).
"ATranslation Aid System Using Flexible Text RetrievalBased on Syntax-Matching".
7RL Research Report,Tol~3~o Research Laboratory, IBM.\[SUMITA 91\] Sumita E. and 1I.
Iida, (1991).
"Experiments and Prospects of Example-basedMachine Translation".
Proc.
of the 29th AnnualMeeting ~f the Association for ComputationalLinguistics, pp 185-192.\[WILPON 85\] Wilpon J. and L. Rabiner, (1985).
"AModified k-Means Clustering Algorithm tbr Use inIsolated Word Recognition".
IEEE vol.
ASSP-33, pp.587-594.104
