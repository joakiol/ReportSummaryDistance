Us ing  SGML as a Bas is  for Data - In tens ive  NLPDav id  McKe lv ie ,  Chr i s  Brew & Henry  ThompsonLanguage Technology Group, Human Communicat ion  Research Centre,University of Edinburgh, Edinburgh, ScotlandDavid .
McKelvie@ed.
ac.
uk ~z Chr i s .
Brew@ed.
ac.
uk & H. Thompson@ed.
ac .
ukAbst rac tThis paper describes the LT NSL sys-tem (McKelvie et al 1996), an architec-ture for writing corpus processing tools.This system is then compared with twoother systems which address similar is-sues, the GATE system (Cunningham etal, 1995) and the IMS Corpus Workbench(Christ, 1994).
In particular we addressthe advantages and disadvantages of anSGML approach compared with a non-SGMLdatabase approach.1 IntroductionThe theme of this paper is the design of softwareand data architectures for natural language process-ing using corpora.
Two major issues in corpus-basedNLP are: how best to deal with medium to largescale corpora often with complex linguistic annota-tions, and what system architecture best supportsthe reuse of software components in a modular andinterchangeable fashion.In this paper we describe the LT NSL system (McK-elvie et al 1996), an architecture for writing corpusprocessing tools, which we have developed in an at-tempt to address these issues.
This system is thencompared with two other systems which addresssome of the same issues, the GATE system (Cun-ningham et al 1995) and the IMS Corpus Work-bench (Christ, 1994).
In particular we address theadvantages and disadvantages of an SGML approachcompared with a non-SGML database approach.
Fi-nally, in order to back up our claims about he meritsof SGML-based corpus processing, we present a num-ber of case studies of the use of the LT NSL systemfor corpus preparation and linguistic analysis.2 The  LT  NSL  sys temLT NSL is a tool architecture for SGML-based pro-cessing of (primarily) text corpora.
It generalisesthe UNIX pipe architecture, making it possible touse pipelines of general-purpose tools to process an-notated corpora.
The original UNIX architecture al-lows the rapid construction of efficient pipelines ofconceptually simple processes to carry out relativelycomplex tasks, but is restricted to a simple model ofstreams as sequences ofbytes, lines or fields.
LT NSLlifts this restriction, allowing tools access to streamswhich are sequences oftree-structured text (a repre-sentation of SGML marked-up text).The use of SGML as an I /0  stream format betweenprograms has the advantage that SGML is a well de-fined standard for representing structured text.
Itsvalue is precisely that it closes off the option of aproliferation of ad-hoc notations and the associatedsoftware needed to read and write them.
The mostimportant reason why we use SGML for all corpus lin-guistic annotation is that it forces us to formally de-scribe the markup we will be using and provides oft-ware for checking that these markup invariants holdin an annotated corpus.
In practise this is extremelyuseful.
SGML is human readable, so that interme-diate results can be inspected and understood.
Italso means that it is easy for programs to access theinformation which is relevant to them, while ignor-ing additional markup.
A further advantage is thatmany text corpora re available in SGML, for exam-ple, the British National Corpus (Burnage&Dunlop,1992).The LT NSL system is released as C source code.The software consists of a C-language ApplicationProgram Interface (API) of function calls, and a num-ber of stand-alone programs which use this API.
Thecurrent release is known to work on UNIX (SunOS4.1.3, Solaris 2.4 and Linux), and a Windows-NTversion will be released uring 1997.
There is alsoan API for the Python programming language.One question which arises in respect to usingSGML as an I /O  format is: what about the cost of229parsing SGML?
Surely that makes pipelines too in-efficient?
Parsing SGML in its full generality, andproviding validation and adequate rror detectionis indeed rather hard.
For efficiency reasons, youwouldn't want to use long pipelines of tools, if eachtool had to reparse the SGML and deal with thefull language.
Fortunately, LT NSL doesn't requirethis.
The first stage of processing normalises theinput, producing a simplified, but informationallyequivalent form of the document.
Subsequent toolscan and often will use the LT NSL API which parsesnormalised SGML (henceforth NSGML) approximatelyten times more efficiently than the best parsers forfull SGML.
The API then returns this parsed SGMLto the calling program as data-structures.NSGML is a fully expanded text form of SGML in-formationally equivalent to the ESlS output of SGMLparsers.
This means that all markup minimisationis expanded to its full form, SGML entities are ex-panded into their value (except for SDATA entities),and all SGML names (of elements, attributes, etc) arenormalised.
The result is a format easily readable byhumans and programs.The LT NSL programs consist of mknsg, a programfor converting arbitrary valid SGML into normalisedSGML 1 , the first stage in a pipeline of LT NSL tools;and a number of programs for manipulating nor-malised SGML files, such as sggrep which finds SGMLelements which match some query.
Other of our soft-ware packages uch as LT POS (a part of speech tag-ger) and LT WB (Mikheev&Finch, 1997) also use theLT NSL library.In addition to the normalised SGML, the mknsgprogram writes a file containing a compiled formof the Document Type Definition (DTD) 2, whichLT NSL programs read in order to know what thestructure of their NSGML input or output is.How fast is it?
Processes requiring sequential ac-cess to large text corpora are well supported.
It isunlikely that LT NSL will prove the rate limiting stepin sequential corpus processing.
The kinds of re-peated search required by lexicographers are moreof a problem, since the system was not designedfor that purpose.
The standard istribution is fastenough for use as a search engine with files of up toseveral million words.
Searching 1% of the BritishNational Corpus (a total of 700,000 words (18 Mb))is currently only 6 times slower using LT NSL sggrepthan using fgl"ep, and sF~rre p allows more complexstructure-sensitive queries.
A prototype indexingmechanism (Mikheev&McKelvie, 1997), not yet in1Based on James Clark's SP parser (Clark, 1996).2SGML's way of describing the structure (or grammar)of the allowed markup in a document230the distribution, improves the performance ofLT NSLto acceptable l vels for much larger datasets.Why did we say "primarily for text corpora"?
Be-cause much of the technology is directly applicableto multimedia corpora such as the Edinburgh MapTask corpus (Anderson et al 1991).
There are toolswhich interpret SGML elements in the corpus text asoffsets into files of audio-data, allowing very flexi-ble retrieval and output of audio information usingqueries defined over the corpus text and its annota-tions.
The same could be done for video clips, etc.2.1 Hyper l ink ingWe are inclined to steer a middle course betweena monolithic omprehensive iew of corpus data, inwhich all possible views, annotations, tructuringsetc.
of a corpus component are combined in a sin-gle heavily structured ocument, and a massivelydecentralised view in which a corpus component isorganised as a hyper-document, with all its informa-tion stored in separate documents, utilising inter-document pointers.
Aspects of the LT NSL libraryare aimed at supporting this approach.
It is neces-sary to distinguish between files, which are storageunits, (SGML) documents, which may be composedof a number of files by means of external entity ref-erences, and hyper-documents, which are linked en-sembles of documents, using e.g.
HyTime or TEI(Sperberg-McQueen&Burnard, 1994) link notation.The implication of this is that corpus compo-nents can be hyper-documents, with low-density (i.e.above the token level) annotation being expressed in-directly in terms of links.
In the first instance, thisis constrained to situations where element contentat one level of one document is entirely composedof elements from another document.
Suppose, forexample, we already had segmented a file resultingin a single document marked up with SGML headersand paragraphs, and with the word segmentationmarked with <w> tags:<p id=~><w id=p4.wl>Time</w><w id=p4.w2>flies</w><w id=p4.w3>.</w><Ip>The output of a phrase-level segmentation mightthen be stored as follows:?
?<p id=p4><phr id=p4.phl type=n doe=file1 from='id p4.wl~><phr id=p4.ph2 type=v from=~id p4.w2~></p>Linking is specified using one of the available TEImechanisms.
Details are not relevant here, suffice itto say that doc=f i le l  resolves to the word level fileand establishes a default for subsequent links.
Ata minimum, links are able to target single elementsor sequences of contiguous elements.
LT NSL imple-ments a textual inclusion semantics for such links, in-serting the referenced material as the content of theelement bearing the linking attributes.
Although theexample above shows links to only one document, itis possible to link to several documents, e.g.
to aword document and a lexicon document:<word><source doc=filel from=~id p4.wl ~><lex doc=lexl from='id iex.40332'></word>Note that the architecture is recursive, in thate.g.
sentence-level segmentation could be expressedin terms of links into the phrase-level segmentationas presented above.The data architecture needs to address not onlymultiple levels of annotation but also alternative ver-sions at a given level.
Since our linking mechanismuses the SGML entity mechanism to implement theidentification of target documents, we can use theentity manager's catalogue as a means of managingversions.
For our example above, this means that theconnection between the phrase encoding documentand the segmented document would be in two steps:the phrase document would use a PUBL IC  identi-fier, which the catalogue would map to the particularfile.
Since catalogue ntries are interpreted by toolsas local to the directory where the catalogue itselfis found, this means that binding together groups ofalternative versions can be easily achieved by storingthem under the same directory.Subdirectories with catalogue fragments can thusbe used to represent both increasing detail of anno-tation and alternatives at a given level of annotation.Note also that with a modest extension of func-tionality, it is possible to use the data architecturedescribed here to implement patches, e.g.
to the to-kenisation process.
If alongside an inclusion seman-tics, we have a special empty element <repl> whichis replaced by the range it points to, we can producea patch file, e.g.
for a misspelled word, as follows(irrelevant details omitted):<nsl><!-- to get the original header--><repl doc=original from='id hdrl'><text><!-- the first swatch of unchanged text --><repl from= ~id pl~ to= ~ id p324~ ><!-- more unchanged text --><p ?d=p325><repl from='id p325.t1' to='id p325.t15'><!-- the correction itself --><corr sic='procede' resp='ispell~><token id=p325, t 16>proceed</t oken></corr><!-- more unchanged text--><repl from=~id p325.t17 ~ to=~id p325.t96 '><Ip><!-- the rest of the unchanged text--><repl from='id p326 ~ to=~id p402 ~></text></nsl>Whether such a patch would have knock-on effectson higher levels of annotation would depend, interalia, on whether a change in tokenisation crossed anyhigher-level boundaries.2.2 sggrep and the LT NSL query  languageThe ie I  provides the program(mer) with two alter-native views of the NSGML stream: an object streamview and a tree fragment view.
The first, lower levelbut more efficient, provides data structures and ac-cess functions such as GetNextBit  and Pr in tB i t ,where there are different ypes of B i t s  for start (orempty) tags with their attributes, text content, endtags, and a few other bits and pieces.The alternative, higher level, view, lets onetreat the NSGML input as a sequence of tree-fragments.
The API provides functions GetNextItemand Pr in t I tem to read and write the next com-plete SGML element.
It also provides functionalityGetNextQueryElement (infile, query, subquery,regexp,outfile) where query is an LT NSL querywhich allows one to specify particular elements onthe basis of their position in the document struc-ture and their attribute values.
The subquery andregexp allow one to specify that the matching ele-ment has a subelement matching the subquery withtext content matching the regular expression.
El-ements which do not match the query are passedthrough unchanged to outfile.
Under both mod-els, processing is essentially a loop over calls to theAPI, in each case choosing to discard, modify or out-put unchanged each Bit or Element.Rather than define the query language here (de-tails can be found in (McKelvie et al 1996)), we willjust provide an example.
The callGetNext QueryElement (inf ,".
*/TEXT/.
*/P","P/.
*/S", "th (eil ie)r", outf)would return the next <P> element dominatedanywhere by <TEXT> at any depth, with the <P>element satisfying the additional requirement thatit contain at least one <S> element at any depthwith text containing at least one instance of 'their'(possibly misspelt).2313 Comparisons with other systemsThe major alternative corpus architecture which hasbeen advocated is a database approach, where anno-tations are kept separately from the base texts.
Theannotations are linked to the base texts either bymeans of character offsets or by a more sophisticatedindexing scheme.
We will discuss two such systemsand compare them with the LT NSL approach.3.1 GATEThe GATE system (Cunningham et al 1995),currently under development at the University ofSheffield, is a system to support modular languageengineering.3.1.1 System componentsIt consists of three main components:?
GDM - an object oriented database for stor-ing information about the corpus texts.
Thisdatabase is based on the T IPSTER documentarchitecture (Grishman, 1995), and stores textannotations eparate from the texts.
Annota-tions are linked to texts by means of characteroffsets 3.?
Creole - A library of program and data resourcewrappers, that allow one to interface xternallydeveloped programs/resources into the GATEarchitecture.?
GGI - a graphical tool shell for describing pro-cessing algorithms and viewing and evaluatingthe results.A MUC-6 compatible information extraction sys-tem, VIE, has been built using the GATE architec-ture.3.1.2 Eva luat ionSeparating corpus text from annotations i a gen-eral and flexible method of describing arbitrarystructure on a text.
It may be less useful as a meansof publishing corpora nd may prove inefficient if theunderlying corpus is liable to change.Although T IPSTER lets one define annotationsand their associated attributes, in the present ver-sion (and presumably also in GATE) these defini-tions are treated only as documentation and arenot validated by the system.
In contrast, the SGMLparser validates its DTD, and hence provides omecheck that annotations are being used in their in-tended way.
SGML has the concept of content mod-els which restrict the allowed positions and nesting3More precisely, by inter byte locations.of annotations.
GATE allows any annotation any-where.
Although this is more powerful, i.e.
one is notrestricted to tree structures, it does make validationof annotations more difficult.The idea of having formalised interfaces for exter-nal programs and data is a good one.The GGI graphical tool shell lets one build,store, and recover complex processing specifications.There is merit in having a high level language tospecify tasks which can be translated automaticallyinto executable programs (e.g.
shell scripts).
This isan area that LT NSL does not address.3.1.3 Compar i son  wi th  LT NSLIn (Cunningham et al 1996), the GATE archi-tecture is compared with the earlier version of theLT NSL architecture which was developed in theMULTEXT project.
We would like to answer thesepoints with reference to the latest version of our soft-ware .It is claimed that using normalised SGML impliesa large storage overhead.
Normally however, nor-malised SGML will be created on the fly and passedthrough pipes and only the final results will need tobe stored.
This may however be a problem for verylarge corpora such as the BNC.It is stated that representing ambiguous or over-lapping markup is complex in SGML.
We do notagree.
One can represent overlapping markup inSGML in a number of ways.
As described above,it is quite possible for SGML to represent 'stand-off'annotation in a similar way to T IPSTER.
LT NSLprovides the hyperlinking semantics to interpret thisSGML.The use of normalised SGML and a compiled DTDfile means that the overheads of parsing SGML ineach program are small, even for large DTDs, suchas the TEI.LT NSL is not specific to particular applicationsor DTDs.
The MULTEXT architecture was tool-specific, in that its API defined a predefined set of ab-stract units of linguistic interest, words, sentences,etc.
and defined functions such as ReadSentence.That was because MULTEXT was undecided aboutthe format of its I/O.
LT NSL in contrast, since wehave decided on SGML as a common format, providesfunctions uch as GetNextItem which read the nextSGML element.
Does this mean the LT NSL architec-ture is application eutral?
Yes and no.Yes, because there is in principle no limit on whatcan be encoded in an SGML document.
In the TIP-STER architecture there is an architectural require-ment that all annotations be ultimately associatedwith spans of a single base text, but LT NSL imposes232no such requirement.
This makes it easier to be clearabout what happens when a different view is neededon fixed-format read-only information, or when itturns out that the read-only information should besystematically corrected.
The details of this are amatter of ongoing research, but an important moti-vation for the architecture of LT NSL is to allow suchedits without requiring that the read-only informa-tion be copied.No,  because in practice any corpus is encoded in away which reflects the assumptions of the corpus de-velopers.
Most corpora include a level of representa-tion for words, and many include higher level group-ings such as breath groups, sentences, paragraphsand/or documents.
The sample back-end tools dis-tributed with LT NSL reflect this fact.It is claimed that there is no easy way in SGML todifferentiate sets of results by who or what producedthem.
But, to do this requires only a convention forthe encoding of meta-information about text cor-pora.
For example, SGML DTDs such as the TEIinclude a 'resp' attribute which identifies who wasresponsible for changes.
LT NSL does not requiretools to obey any particular conventions for meta-information, but once a convention is fixed upon itis straightforward to encode the necessary informa-tion as SGML attributes.Unlike TIPSTER, LT NSL is not built around adatabase, so we cannot take advantage of built-inmechanisms for version control.
As far as corpusannotation goes, UNIX rcs, has proved an adequatesolution to our version control needs.
Alternatively,version control can be provided by means of hyper-linking.The GATE idea of providing formal wrappers forinterfacing programs is a good one.
In LT NSLthe corresponding interfaces are less formalised, butcan be defined by specifying the DTDs of a pro-gram's input and output files.
For example a part-of-speech tagger would expect <W> elements inside<S> elements, and a 'TAG' attribute on the output<W> elements.
Any input file whose DTD satisfiedthis constraint could be tagged.
SGML architecturalforms (a method for DTD subsetting) could providea method of formalising these program interfaces.As Cunningham et.
al.
say, there is no reason whythere could not be an implementation of LT NSLwhich read SGML elements from a database ratherthan from files.
Similarly, a T IPSTER architecturelike GATE could read SGML and convert it into itsinternal database.
In that case, our point wouldbe that SGML is a suitable abstraction for programsrather than a more abstract (and perhaps more lim-233ited) level of interface.
We are currently in discus-sion with the GATE team about how best to allowthe interoperability of the two systems.3.2 The  IMS Corpus  WorkbenchThe IMS Corpus Workbench (Christ, 1994) includesboth a query engine (CQP) and a Motif-based uservisualisation tool (xkwic).
CQP provides a query lan-guage which is a conservative xtension of famil-ia~ UNIX regular expression facilities 4.
XKWIC is auser interface tuned for corpus search.
As well asproviding the standard keyword-in-context facilitiesand giving access to the query language it gives theuser sophisticated tools for managing the query his-tory, manipulating the display, and storing searchresults.
The most interesting points of comparisonwith LT NSL are in the areas of query language andunderlying corpus representation.3.2.1 The  CQP mode lCQP treats corpora s sequences of attribute-valuebundles.
Each attribute 5 can be thought of as a totalfunction from corpus positions to attribute values.Syntactic sugar apart, no special status is given tothe attribute word.3.2.2 The  query  languageThe query language of IMS-CWB, which has theusual regular expression operators, works uniformlyover both attribute values and corpus positions.This regularity is a clear benefit o users, since onlyone syntax must be learnt.Expressions of considerable sophistication can begenerated and used successfully by beginners.
Con-sider:\[pos="DT" & word !="the"\] \[pos="JJ.*"\]?\[pos=0'N.
+"\]This means, in the context of the Penn treebanktagset, "Find me sequences beginning with deter-miners other than the, followed by optional adjec-tives, then things with nominal qualities".
The in-tention is presumably to find a particular sub-classof noun-phrases.The workbench as plainly achieved an extremelysuccessful generalisation of regular expressions, andone which has been validated by extensive use inlexicography and corpus-building.There is only limited access to structural infor-mation.
While it is possible, if sentence boundariesare marked in the corpus, to restrict the search to4Like LT NSL IMS-CWB is built on top of HenrySpencer's public domain regular expression package5In CQP terminology these are the "positionalattributes".within-sentence matches, there are few facilities formaking more refined use of hierarchical structure.The typical working style, if you are concerned withsyntax, is to search for sequences of attributes whichyou believe to be highly correlated with particularsyntactic structures.3.2.3 Data  representat ionCQP requires users to transform the corpora whichwill be searched into a fast internal format.
Thisformat has the following properties:.
Because of the central role of corpus position itis necessary to tokenise the input corpus, map-ping each word in the raw input to a set of at-tribute value pairs and a corpus position.?
There is a logically separate index for each at-tribute name in the corpus.?
CQP uses all integerised representation, i  whichcorpus items having the same value for an at-tribute are mapped into the same integer de-scriptor in the index which represents that at-tribute.
This means that the character data cor-responding to each distinct corpus token needonly be stored once.?
For each attribute there is an item list contain-ing the sequence of integer descriptors corre-sponding to the sequence of words in the corpus.Because of the presence of this list the storagecost of adding a new attribute is linear in thesize of the corpus.
If the new attribute weresparse, it would be possible to reduce the spacecost by switching (for that attribute) to a morespace efficient encoding 63.2.4 Evaluat ionThe IMS-CWB is a design dominated by the needfor frequent fast searches of a corpus with a fixed an-notation scheme.
Although disk space is now cheap,the cost of preparing and storing the indices for IMS-CWB is such that the architecture is mainly appro-priate for linguistic and lexicographic exploration,but less immediately useful in situations, such asobtain in corpus development, where there is a re-curring need to experiment with different or evolvingattributes and representational possibilities.Some support is provided for user-written tools,but as yet there is no published API to the poten-tially very useful query language facilities.
The in-dexing tools which come with IMS-CWB are less flexi-ble than those of LT NSL since the former must index61MS-CWB already supports compressed index files,and special purpose encoding formats would presumablysave even more space.on words, while the latter can index on any level ofthe corpus annotation.The query language of IMS-CWB is an elegant andorthogonal design, which we believe it would be ap-propriate to adopt or adapt as a standard for corpussearch.
It stands in need of extension to providemore flexible access to hierarchical structure ~.
Thequery language of LT NSL is one possible templatefor such extensions, as is the opaque but powerfultg rep  program (Pito, 1994) which is provided withthe Penn Treebank.4 Case  s tud ies4.1 Creat ion  of  marked-up  corporaOne application area where the paradigm of sequen-tial adding of markup to an SGML stream fits veryclosely, is that of the production of annotated cor-pora.
Marking of major sections, paragraphs andheadings, word tokenising, sentence boundary mark-ing, part of speech tagging and parsing are all taskswhich can be performed sequentially using only asmall moving window of the texts.
In addition, allof them make use of the markup created by earliersteps.
If one is creating an annotated corpus for pub-lic distribution, then SGML is (probably) the formatof choice and thus an SGML based NLP system suchas LT NSL will be appropriate.Precursors to the LT NSL so f tware  were used to an-notate the MLCC corpora used by the MULTEXTproject.
Similarly LT NSL has been used to recodethe Edinburgh MapTask corpus into SGML markup,a process which showed up a number of inconsis-tencies in the original (non-SGML) markup.
BecauseLT NSL allows the use of multiple I /O files (with dif-ferent DTDs), in (Brew&McKelvie, 1996) it was pos-sible to apply these tools to the task of finding trans-lation equivalencies between English and French.Using part of the MLCC corpus, part-of-speechtagged and sentence aligned using LT NSL tools, theyexplored various techniques for finding word align-ments.
The LT NSL programs were useful in eval-uating these techniques.
See also (Mikheev&Finch,1995), (Mikheev&Finch, 1997) for other uses of theLT NSL tools in annotating linguistic structures ofinterest and extracting statistics from that markup.4.2 T rans format ion  of  corpus  markupAlthough SGML is human readable, in practice oncethe amount of markup is of the same order of magni-7This may be a specialised need of academic linguists,and for many applications it is undoubtedly more im-portant to provide clean facilities for non-hierarchicalqueries but it seems premature to close off the optionof such access.234rude as the textual content, reading SGML becomesdifficult.
Similarly, editing such texts using a normaltext editor becomes tedious and error prone.
Thusif one is committed to the use of SGML for corpus-based NLP, then one needs to have specialised soft-ware to facilitate the viewing and editing of SGML.A similar problem appears in the database approachto corpora, where the difficulty is not in seeing theoriginal text, but in seeing the markup in relation-ship to the text.4.2.1 Batch transformationsTo address this issue LT NSL includes a num-ber of text based tools for the conversion of SGML:texton ly ,  sgmltrans and sgrpg.
With these toolsit is easy to select portions of text which are of inter-est (using the query language) and to convert heminto either plain text or another text format, such as1.4TEX or HTML.
In addition, there are a large num-ber of commercial and public domain software pack-ages for transforming SGML.
In the future, however,the advent of the DSSSL transformation language willundoubtably revolutionise this area.4.2.2 Hand correctionSpecialised editors for SGML are available, butthey are not always exactly what one wants, becausethey are too powerful, in that they let al markupand text be edited.
What is required for markupcorrection are specialised editors which only allow aspecific subset of the markup to be edited, and whichprovide an optimised user interface for this limitedset of edit operations.In order to support the writing of specialised ed-itors, we have developed a Python (vanRossum,1995) API for LT NSL, (Tobin&McKelvie, 1996).
Thisallows us to rapidly prototype editors using thePython/Tk  graphics package.
These editors can fitinto a pipeline of LT NSL tools allowing hand cor-rection or disambiguation of markup automaticallyadded by previous tools.
Using this heI we are devel-oping a generic SGML editor.
It is an object-orientedsystem where one can flexibly associate display andinteraction classes to particular SGML elements.
Al-ready, this generic editor has been used for a numberof tasks; the hand correction of part-of-speech tagsin the MapTask, the correction of turn boundariesin the Innovation corpus (Carletta et al 1996), andthe evaluation of translation equivalences betweenaligned multilingual corpora.We found that using this generic editor frameworkmade it possible to quickly write new editors for newtasks on new corpora.5 Conc lus ionsSGML is a good markup language for base level an-notations of published corpora.
Our experience withLT NSL has  shown that:?
It is a good system for sequential corpus pro-cessing where there is locality of reference.?
It provides a modular architecture which doesnot require a central database, thus allowingdistributed software development and reuse ofcomponents.?
It works with existing corpora without extensivepre-processing.?
It does support the Tipster approach of sep-arating base texts from additional markup bymeans of hyperlinks.
In fact SGML (HyTime)allows much more flexible addressing, not justcharacter offsets.
This is of benefit when work-ing with corpora which may change.LT NSL is not so good for:?
Applications which require a database ap-proach, i.e.
those which need to access markupat random from a text, for example lexico-graphic browsing or the creation of book in-dexes.?
Processing very large plain text or unnormalisedSGML corpora, where indexing is required, andgeneration of normalised files is a large over-head.
We are working on extending LT NSL inthis direction, e.g.
to allow processing of theBNC corpus in its entirety.In conclusion, the SGML and database approachesare optimised for different NLP applications andshould be seen as complimentary ather than as con-flicting.
There is no reason why one should not at-tempt to use the strengths of both the database andthe SGML stream approaches.
It is recommendedthat future work should include attention to allow-ing interfacing between both approaches.6 AcknowledgementsThis work was carried out at the Human Commu-nication Research Centre, whose baseline fundingcomes from the UK Economic and Social ResearchCouncil.
The LT NSL work began in the context ofthe LRE project MULTEXT with support from theEuropean Union.
It has benefited from discussionswith other MULTEXT partners, particularly ISSCOGeneva, and drew on work at our own institution by235Steve Finch and Andrei Mikheev.
We also wish tothank Hamish Cunningham and Oliver Christ foruseful discussions.Re ferencesA.
H. Anderson, M. Bader, E. G. Bard, E. H.Boyle, G. M. Doherty, S. C. Garrod, S. D. Isard,J.
C. Kowtko, J. M. McAllister, J. Miller, C. F.Sotillo, H. S. Thompson, and R. Weinert.
TheHCRC Map Task Corpus.
Language and Speech,34(4):351-366, 1991.C.
Brew and D. McKelvie.
1996.
"Word-pair extrac-tion for lexicography".
In Proceedings of NeM-LAP'96, pp 45-55, Ankara, Turkey.G.
Burnage and D. Dunlop.
1992.
"Encodingthe British National Corpus".
In 13th Interna-tional Conference on English Language researchon computerised corpora, Nijmegen.
Available athttp ://www.
sil.
org/sgml/bnc-encoding2, htmlSee also http://info, ox.
ac.
uk/bnc/J.
Carletta, H. Fraser-Krauss and S. Garrod.
1996.
"An Empirical Study of Innovation in Manufac-turing Teams: a preliminary report".
In Proceed-ings of the International Workshop on Commu-nication Modelling (LAP-96), ed.
J. L. G. Dietz,Springer-Verlag, Electronic Workshops in Com-puting Series.O.
Christ.
1994.
"A modular and flexible archi-tecture for an integrated corpus query system".In Proceedings of COMPLEX '94: 3rd Conferenceon Computational Lexicography and Text Research(Budapest, July 7-10, 1994), Budapest, Hungary.CMP-LG archive id 9408005J.
Clark.
1996 "SP: An SGML System Conformingto International Standard ISO 8879 - StandardGeneralized Markup Language".
Available fromhttp ://www.
j clark, com/sp/index, htm.R.
Grishman.
1995.
"TIPSTER Phase IIArchitecture Design Document Version 1.52".Technical Report, Dept.
of Computer Sci-ence, New York University.
Available athttp ://www.
cs.
nyu.
edu/t ipst erD.
McKelvie, H. Thompson and S. Finch.
1996.
"The Normalised SGML Library LT NSL ver-sion 1.4.6".
Technical Report, Language Technol-ogy Group, University of Edinburgh.
Available athttp ://www.
itg.
ed.
ac.
uk/software/nslA.
Mikheev and S. Finch.
1995.
"Towards a Work-bench for Acquisition of Domain Knowledge fromNatural Language".
In Proceedings ofthe SeventhConference of the European Chapter of the Asso-ciation for Computational Linguistics (EA CL '95).Dublin, Ireland.A.
Mikheev and S. Finch.
1997.
"A Workbench forFinding Structure in Texts".
in these proceedings.A.
Mikheev and D. McKelvie.
1997.
"IndexingSGML files using LT NSL".
Technical Report,Language Technology Group, University of Edin-burgh.R.
Pito.
1994.
"Tgrep Manual Page".
Availablefromhttp ://www.
idc.
upenn, edu/Idc/online/treebank/man/G.
van Rossum.
1995.
"Python Tutorial".
Availablefrom http://www .python.
org/C.
M. Sperberg-McQueen & L. Burnard, eds.
1994.
"Guidelines for Electronic Text Encoding and In-terchange".
Text Encoding Initiative, Oxford.R.
Tobin and D. McKelvie.
1996.
"ThePython Interface to the Normalised SGML Li-brary (PythonNSL)".
Technical Report, LanguageTechnology Group, University of Edinburgh.H.
Cunningham, Y. Wilks and R. J. Gaizanskas.1996.
"New Methods, Current Trends and Soft-ware Infrastructure for NLP".
In Proceedings ofthe Second Conference on New Methods in Lan-guage Processing, pages 283-298, Ankara, Turkey,March.H.
Cunningham, R. Gaizanskas and Y. Wilks.
1995.
"A General Architecture for Text Engineering(GATE) - a new approach to Language Engineer-ing R&D".
Technical Report, Dept of ComputerScience, University of Sheffield.
Available fromhttp ://www.
dcs.
shef.
ac.
uk/research/groups/nlp/gate/236
