Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 40?50,Dublin, Ireland, August 23-24 2014.An Iterative ?Sudoku Style?
Approach to Subgraph-basedWord Sense DisambiguationSteve L. ManionUniversity of CanterburyChristchurch, New Zealandsteve.manion@pg.canterbury.ac.nzRaazesh SainudiinUniversity of CanterburyChristchurch, New Zealandr.sainudiin@math.canterbury.ac.nzAbstractWe introduce an iterative approach tosubgraph-based Word Sense Disambigua-tion (WSD).
Inspired by the Sudoku puz-zle, it significantly improves the precisionand recall of disambiguation.
We describehow conventional subgraph-based WSDtreats the two steps of (1) subgraph con-struction and (2) disambiguation via graphcentrality measures as ordered and atomic.Consequently, researchers tend to focus onimproving either of these two steps indi-vidually, overlooking the fact that thesesteps can complement each other if theyare allowed to interact in an iterative man-ner.
We tested our iterative approachagainst the conventional approach for arange of well-known graph centrality mea-sures and subgraph types, at the sentenceand document level.
The results demon-strated that an average performing WSDsystem which embraces the iterative ap-proach, can easily compete with state-of-the-art.
This alone warrants further inves-tigation.1 IntroductionExplicit WSD is a two-step process of analysing aword?s contextual use then deducing its intendedsense.
When Kilgarriff (1998) established SEN-SEVAL, the collaborative framework and forum toevaluate WSD, unsupervised systems performedpoorly in comparison to their supervised counter-parts (Palmer et al., 2001; Snyder and Palmer,2004).
A review of the literature shows thereThis work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence de-tails: http://creativecommons.org/licenses/by/4.0/has been a healthy rivalry between the two, inwhich proponents of unsupervised WSD have longsought to vindicate its potential since two decadesago (Yarowsky, 1995) to even more recent times(Ponzetto and Navigli, 2010).As Pedersen (2007) rightly states, supervisedsystems are bound by their training data, andtherefore are limited in portability and flexibilityin the face of new domains, changing applications,or different languages.
This knowledge acquisi-tion bottleneck, coined by Gale et al.
(1992), canbe alleviated by unsupervised systems that exploitthe portability and flexibility of Lexical Knowl-edge Bases (LKBs).
As of 2007, SENSEVAL be-came SEMEVAL, offering a more diverse range ofsemantic tasks.
Unsupervised knowledge-basedWSD has since had its performance evaluated interms of granularity (Navigli et al., 2007), domain(Agirre et al., 2010), and cross/multi-linguality(Lefever and Hoste, 2010; Lefever and Hoste,2013; Navigli et al., 2013).
Results from thesetasks have demonstrated unsupervised systems arenow a competitive and robust alternative to super-vised systems, especially given the ever changingtask-orientated settings WSD is evaluated in.One such class of unsupervised knowledge-based WSD systems that we seek to improvein this paper constructs semantic subgraphs fromLKBs, and then runs graph-based centrality mea-sures such as PageRank (Brin and Page, 1998)over them to finally select the senses (as nodes)ranked as the most relevant.
This class is knownas subgraph-based WSD, characterised over thelast decade by performing the two key steps of (1)subgraph construction and (2) disambiguation viagraph centrality measures, in an ordered atomicsequence.
We refer to this characteristic as theconventional approach to subgraph-based WSD.We propose an iterative approach to subgraph-based WSD that allows for interaction betweenthe two major steps in an incremental manner40and demonstrate its effectiveness across a rangeof graph-based centrality measures and subgraphconstruction methods at the sentence and docu-ment levels of disambiguation.2 The Conventional Subgraph ApproachThe conventional approach to subgraph WSDfirstly benefits from some preprocessing, in whichwords in a sequenceW , are mapped to their lem-matisations1in a set L, such that (w1, ..., wm) 7?
{`1, ..., `m}.
This facilitates better lexical align-ment with the LKB to be exploited.
Let this LKBbe a large semantic graph G = (S, E), such thatS is a set of vertices representing all known wordsenses, and E be a set of edges defining seman-tic relationships that exist between senses.
Nowgiven we wish to disambiguate `i?
L, let R(`i)be a function that Retrieves from G, all the senses,{si,1, si,2, ..., si,k}, that `icould refer to, notingthat i is an anchor to the original word wi.2.1 Step 1: Subgraph ConstructionFor unsupervised subgraph-based WSD, the keypublications that have advanced the field broadlyconstruct subgraph, GL, as either a union of sub-tree paths, shortest paths, or local edges2.
Firstwe initialise GL, by setting SL:=?ni=1R(`i) andEL:= ?.
Next we add edges to EL, depending onthe desired subgraph type, by adding either the:(a) Subtree paths of up to length L, via a Depth-First Search (DFS) of G. In brief, for eachsense sa?
SL, if a new sense sb?
SL,i.e.
sb6= sa, is encountered along a pathPa?b= {{sa, s}, ..., {s?, sb}} with path-length |Pa?b| ?
L, then add Pa?bto GL.[cf.
Navigli and Velardi (2005), Navigli andLapata (2007), or Navigli and Lapata (2010)](b) Shortest paths, via a Breadth-First Search(BFS) of G. In brief, for each sense pairsa, sb?
SL, find the shortest path Pa?b={{sa, s}, ..., {s?, sb}}; if such a path Pa?bex-ists and (optionally) |Pa?b| ?
L, then addPa?bto GL[cf.
Agirre and Soroa (2008),Agirre and Soroa (2009), or Guti?rrez et al.
(2013)]1For a detailed explanation of the processes leading up tolemmatisation (and beyond), see Navigli (2009, p12)2?Local?
describes the local context, typically this is the 2or 3 words either side of a word, see Yarowsky (1993)(c) Local edges up to a local distance D. In brief,for each sense pair sa, sb?
SL, if the distancein the text |b ?
a| between the correspondingwords waand wbsatisfies |b ?
a| ?
D, thenadd edge {sa, sb} to GL(preferably with edge-weights).
[cf.
Mihalcea (2005) or Sinha andMihalcea (2007)] (Note that this subgraph is ahybrid, because only its vertices belong to G)In practice, subgraph edges may be directed,weighted, collapsed, or filtered.
However to keepthe distinctions between subgraph types simple,we do not include this in our formalisation.2.2 Step 2: DisambiguationTo disambiguate each lemma `i?
L, its cor-responding senses, R(`i) = {si,1, si,2, ..., si,k},are scored by a graph-based centrality measure ?,over subgraph GL, to estimate the most appropri-ate sense, s?i,?= arg maxsi,j?R(`i)?(si,j).
Theestimated sense s?i,?is then assigned to word wi.2.3 Algorithm for Conventional ApproachWith both steps formalised, we can now illus-trate the conventional subgraph approach in Algo-rithm 1.
Let L be taken as input, and let the disam-biguation resultsD = {s?1,?, ..., s?m,?}
be producedas output to assign toW = (w1, ..., wm).Algorithm 1: Conventional ApproachInput: LOutput: DD ?
?;GL?
ConstructSubGraph (L);foreach `i?
L dos?i,??
arg maxsi,j?R(`i)?
(si,j);put s?i,?in D;To begin with, D is initialised as an empty setand ConstructSubGraph(L) constructs oneof the three subgraphs described in section 2.1.Next for each `i?
L, by running a graph basedcentrality measure ?
over GL, the most appropriatesense s?i,?is estimated, and placed in set D. Effec-tively, L is a context window based on documentor sentence size, therefore this algorithm is runfor each context window division.
Note that Al-gorithm 1 would require a little extra complexityto handle local edge subgraphs, due to its contextwindow needing to satisfy L = {`i?D, ..., `i+D}.4171 6 4 978 1 2 61 6 9 8 49 7 2 58 4 3 2 96 9 1 53 5 2 8 61 31 2 345 67 8 91 2 345 67 8 91 2 345 67 8 9(a) 1stRow/Column Elimination71 6 4 978 1 2 61 6 9 8 49 7 2 58 4 3 2 96 9 1 53 5 2 8 68 1 31 2 345 67 8 91 2 345 67 8 9(b) 2ndRow/Column Elimination4 3 9 7 2 6 1 5 82 1 6 8 3 5 4 9 75 7 8 1 9 4 3 2 61 2 3 6 5 9 7 8 49 6 7 4 1 8 2 3 58 4 5 3 7 2 6 1 96 9 4 2 8 1 5 7 33 5 2 9 4 7 8 6 17 8 1 5 6 3 9 4 2(c) Row/Column/Box CompletionFigure 1: Iterative Solving of Sudoku Grids3 The Iterative Subgraph Approach3.1 What is Iterative WSD?The key observation to make about the conven-tional approach in Algorithm 1, is for input L,constructing subgraph GLand performing disam-biguation are two ordered atomic steps.
Noticethat there is no iteration between them, becausethe first step of subgraph construction is never re-visited for each L. For the conventional processto be iterative, then for `a, `b?
L a previous dis-ambiguation of `a, would need to influence a con-secutive disambiguation of `b, through an iterativere-construction of GLbetween each disambigua-tion.
This key difference illustrated by Figure 2, isthe level of iterative WSD we aspire to.LGL?Dconstructdisambiguate assign(a) Conventional ApproachLGL?Dconstructdisambiguateassignreconstruct(b) Interactively Iterative ApproachFigure 2: The Key Difference In ApproachIt is important to note, the term iterative can al-ready be found in WSD literature, therefore wetake the opportunity here to make a distinction.Firstly, a graph based centrality measure ?
maybe iterative, such as PageRank (Brin and Page,1998) or Hyperlink-Induced Topic Search (HITS)(Kleinberg, 1999).
In the experiments by Mihal-cea (2005) in which PageRank was run over localedge subgraphs (as described in 2.1 (c)), it is easyto perceive the WSD process itself as iterative.Iteration can again be taken further, as observedwith Personalised PageRank in which Agirre andSoroa (2009) apply the idea of biasing values inthe random surfing vector, v, (see (Haveliwala,2003)).
For their run labelled ?Ppr_w2w?, in or-der to avoid senses anchored to the same lemmaassisting each other?s ?
score, the random surfingvector v is iteratively updated as `ichanges, to en-sure context senses sa,j?
v such that a 6= i arethe only senses that receive probability mass.LGL?DconstructdisambiguateupdateassignFigure 3: Atomically Iterative ApproachIn summary, iteration in the literature either de-scribes ?
as being iterative or being iteratively ad-justed, both of which are contained in the disam-biguation step alone as shown in Figure 3.
This isiteration at the atomic level and should not be con-flated with the interactive level of iteration that wepropose as seen in Figure 2 (b).3.2 Iteratively Solving a Sudoku GridIn Figures 1 (a), (b), and (c), we observe the solv-ing of a Sudoku puzzle, in which the numbersfrom 1 to 9 must be assigned only once to eachcolumn, row, and 3x3 square.
Each time a numberis assigned and the Sudoku grid is updated, thisis an iteration.
For example, in the south westsquare of grid (a) (i.e.
Figure 1 (a)) unknowncells can be assigned {1, 4, 7, 8}.
Given that 1has already been assigned to the 7throw and the1stand 2ndcolumns, this singles it down to onecell it can be assigned to.
The iteration of grid42?
m b1 ??
m ?
?
?a1 ?
a2?
?
m ??
m ?
m??
?m b2?
?
?
(a) x2 Bi-semous Eliminations?
m b1 ?m ?
?
?
?a2 ??
mc2c1 ?
m ?
m?
?
??
?
?
?mc3?
?
?
?
(b) x1 Tri-semous Elimination?
m b1 ?m ?
?
??
?
?a2 ?d1 m c2?
?
?
m ?
m?
??
?
?
?
?m d2 d3 ??
?
?
?
d4(c) (?max)-semous CompletionFigure 4: Iterative Disambiguating of Subgraphs(a), now makes possible the iteration of grid (b) toeliminate the number 8 as the only possibility forits assigned cell.
This iterative process continuesuntil we reach the completed puzzle in grid (c).Therefore in WSD terminology, with each cell wedisambiguate, a new grid is constructed, in whichknowledge is passed on to each consecutive itera-tion.Continuing with this line of thought, each un-solved cell is ambiguous, with a degree of pol-ysemy ?, such that ?max?
9.
Again, the ini-tial Sudoku grid has pre-solved cells, of which aremonosemous.
This brings us to another key ob-servation.
Typically in Sudoku, it is necessary tosolve the least polysemous cells first, before youcan solve the more polysemous cells with a cer-tainty.
As the conventional approach exhibits noSudoku-like iteration, cells are solved without re-gard to the ?
value of the cell, or any interactiveexploitation of previously solved cells.3.3 Iteratively Constructing a SubgraphIn our ?Sudoku style?
approach, we propose dis-ambiguating each `iin order of increasing poly-semy ?, iteratively reconstructing subgraph GLtoreflect 1) previous disambiguations and 2) the ?value of lemmas being disambiguated in the cur-rent iteration.
This is illustrated in Figures 4 (a),(b), and (c) above.Let m-labelled vertices describe monosemouslemmas.
In graph (a) (i.e.
Figure 4) we observetwo bi-semous lemmas, a and b, in which our ar-bitrary graph-based centrality measure ?
has se-lected the second sense of a (i.e.
a2) and the firstsense of b (i.e.
b1) to be placed in D. For the nextiteration, you will notice the alternative senses fora and b are removed from GLfor the disambigua-tion of tri-semous lemma c. The second sense oflemma cmanages to be selected by ?with the helpof the previous disambiguation of lemma a. Thisinteractive and iterative process continues until wereach the most polysemous lemma, which in ourexample is d with ?max= 4 in graph (c).3.4 Algorithm for Iterative ApproachWe can formally describe what is happening inFigure 4 with Algorithm 2.
Effectively, this is arecreation of Algorithm 1, which highlights thedifferences in the conventional and iterative ap-proach.Algorithm 2: Iterative ApproachInput: LOutput: DD ?
GetMonosemous (L);A ?
?
;for ??
2 to ?maxdoA ?
AddPolysemous (L, ?);GL?
ConstructSubGraph (A,D);foreach `i?
A dos?i,??
arg maxsi,j?S(`i)?
(si,j);if s?i,?exists thenremove `ifrom A;put s?i,?in D;Firstly, as it reads GetMonosemous(L)places all the senses of the monosemous lemmasinto the set of disambiguated lemmas D. This isthe equivalent of copying out an unsolved Sudokugrid onto a piece of paper and adding in all theinitial hint numbers.
Next the set A which holdsall ambiguous lemmas of polysemy ?
?
is ini-tialised as an empty set.
Now we are ready toiterate through values of ?, beginning from thefirst iteration, by adding all bi-semous lemmas to43Awith the function AddPolysemous(L, ?
), no-tice ?
places a restriction on the degree of poly-semy a lemma `i?
L can have before being addedto A.We are now ready to create the first subgraph GLwith function ConstructSubGraph(A,D).This previously used function in Algorithm 1, isnow modified to take the ambiguous lemmas ofpolysemy ?
?
in set A and previously disam-biguated lemma senses in set D. The resultinggraph has a limited degree of polysemy and is con-structed based on previous disambiguations.From this point on the given graph centralitymeasure ?
is run over GL.
For the lemmas thatare disambiguated, they are removed from A andthe selected sense is added toD.
For those lemmasthat are not (i.e.
s?i,?does not exist3) they remain inA to be involved in reattempted disambiguationsin consecutive iterations.
As more lemmas are dis-ambiguated, it is more likely that previously diffi-cult to disambiguate lemmas become much easierto solve, just like at the end of a Sudoku puzzle itgets easier as you get closer to completing it.4 EvaluationsIn our evaluations we set out to understand a num-ber of aspects.
The first evaluation is a proof ofconcept, to understand whether an iterative ap-proach to subgraph WSD can in fact achieve betterperformance than the conventional approach.
Thesecond set of experiments seeks to understand howthe iterative approach works and the performancebenefits and penalties of implementing the itera-tive approach.
Finally the third experiment is anelementary attempt at optimising the iterative ap-proach to defeat the MFS baseline.4.1 LKB & DatasetFor an evaluation, we have chosen the multi-lingual LKB known as BabelNet (Navigli andPonzetto, 2012a).
It weaves together several otherLKBs, most notably WordNet (Fellbaum, 1998)and Wikipedia.
It also can be easily accessed withthe BabelNet API, of which we have built our codebase around.
All experiments are conducted onthe most recent SemEval WSD dataset, of whichis the SemEval 2013 Task 12 Multilingual WSD(English) data set.3This can happen if `idoes not map to any senses, oralternatively all the senses that are mapped to are filtered outof the subgraph before disambiguation (explained later).4.2 Graph Centrality Measures EvaluatedTo demonstrate the effectiveness of our iterativeapproach, we selected a range of WSD graph-based centrality measures often experimented within the literature.
Firstly ?
does not need to be acomplicated measure, this is demonstrated by thesuccess of ranking senses by their number of in-coming and outgoing edges.
Even though it is verysimple, it performs surprisingly well against othersfor both In-Degree (Navigli and Lapata, 2007) andOut-Degree (Navigli and Ponzetto, 2012a)Next we employ graph centrality measuresthat are primarily used to disambiguate the se-mantic web, such as PageRank (Brin and Page,1998), HITS Kleinberg (1999), and a personalisedPageRank (Haveliwala, 2003); which have sincebeen applied to WSD by Mihalcea (2005), Navigliand Lapata (2007), and Agirre and Soroa (2009)respectively.
We also include Betweeness Central-ity (Freeman, 1979) which is taken from the anal-ysis of social networks.These methods are well known and appliedacross many disciplines, therefore we will leave itto the reader to follow up on the specifics of thesegraph centrality measures.
However we do ex-plicitly define our last measure, Sum Inverse PathLength (Navigli and Ponzetto, 2012a; Navigli andPonzetto, 2012b) in Equation (1) which was de-signed with WSD in mind, thus is less well known.?
(s) =?p?Ps?c1e|p|?1(1)This measure scores a sense by summing up thescores of all paths that connect to other senses inGL(i.e.
senses that are not intermediate nodes, buthave a mapping back to a lemma in the contextwindow L).
In the words of Navigli and Ponzetto(2012a), Ps?cis the set of paths connecting sto other senses of context words, with |p| as thenumber of edges in the path p and each path isscored with the exponential inverse decay of thepath length.4.3 Experiment 1: Proof of Concept4.3.1 Experiment 1: SetupFor this experiment we simply set out to see howthe iterative approach performed compared to theconventional approach in a range of experimentalconditions.
Directed and unweighted subgraphswere used, namely subtree paths and shortest pathssubgraphs with L = 2.
To address the issue of44GL?Conventional Doc Iterative Doc ImprovementP R F P R F ?P ?R ?FSubTreePathsIn-Degree 61.70 55.51 58.44 65.39 63.74 64.55 +3.69 +8.23 +6.11Out-Degree 54.23 48.78 51.36 57.70 56.23 56.96 +3.47 +7.45 +5.60Betweenness Centrality 59.29 53.34 56.15 63.43 61.82 62.61 +4.14 +8.48 +6.46Sum Inverse Path Length 56.58 50.90 53.59 58.86 57.37 58.11 +2.28 +6.47 +4.52HITS(hub) 54.69 49.20 51.80 59.71 58.20 58.95 +5.02 +9.00 +7.15HITS(authority) 57.45 51.68 54.41 61.62 60.06 60.83 +4.17 +8.38 +6.42PageRank 60.09 54.06 56.91 64.07 62.44 63.24 +3.98 +8.38 +6.33ShortestPathsIn-Degree 63.06 56.08 59.36 65.36 63.06 64.19 +2.30 +6.98 +4.83Out-Degree 57.07 50.75 53.72 61.14 58.90 60.01 +4.07 +8.15 +6.29Betweenness Centrality 60.33 53.65 56.79 65.52 63.22 64.35 +5.19 +9.57 +7.56Sum Inverse Path Length 57.53 51.16 54.16 61.19 58.98 60.06 +3.66 +7.82 +5.90HITS(hub) 57.48 51.11 54.11 62.14 59.96 61.03 +4.66 +8.85 +6.92HITS(authority) 60.91 54.16 57.34 63.54 61.30 62.40 +2.63 +7.14 +5.06PageRank 61.14 54.37 57.55 65.25 62.96 64.09 +4.11 +8.59 +6.54Table 1: Improvements of using the Iterative Approach at the Document LevelGL?Conventional Sent Iterative Sent ImprovementP R F P R F ?P ?R ?FSubTreePathsIn-Degree 60.83 50.70 55.30 61.80 56.23 58.88 +0.97 +5.53 +3.58Out-Degree 56.18 46.82 51.07 59.64 54.11 56.74 +3.46 +7.29 +5.67Betweenness Centrality 59.40 49.51 54.01 61.66 56.08 58.74 +2.26 +6.57 +4.73Sum Inverse Path Length 56.68 47.23 51.52 59.45 54.00 56.60 +2.77 +6.77 +5.08HITS(hub) 55.49 46.25 50.45 59.51 54.06 56.65 +4.02 +7.81 +6.20HITS(authority) 56.80 47.34 51.64 60.30 54.84 57.44 +3.50 +7.50 +5.80PageRank 59.71 49.77 54.29 60.56 55.04 57.67 +0.85 +5.27 +3.38ShortestPathsIn-Degree 58.13 32.75 41.89 63.79 42.11 50.73 +5.66 +9.36 +8.84Out-Degree 54.64 30.78 39.38 61.79 40.66 49.05 +7.15 +9.88 +9.67Betweenness Centrality 57.94 32.64 41.76 64.11 42.32 50.98 +6.17 +9.68 +9.22Sum Inverse Path Length 55.65 31.35 40.11 62.39 41.02 49.50 +6.74 +9.67 +9.39HITS(hub) 56.11 31.61 40.44 62.74 41.28 49.80 +6.63 +9.67 +9.36HITS(authority) 55.74 31.40 40.17 62.74 41.28 49.80 +7.00 +9.88 +9.36PageRank 57.58 32.44 41.50 63.82 42.16 50.78 +6.24 +9.72 +9.28Table 2: Improvements of using the Iterative Approach at the Sentence Levelsenses anchored to the same lemma assisting eachother?s ?
score (as discussed in Section 3.1), theSENSE_SHIFTS filter that is provided by the Ba-belNet API was also applied.
This filter removesany path Pa?bsuch that sa, sb?
R(`i).
Disam-biguation was attempted at the document and sen-tence level, making use of the eight well-knowngraph centrality measures listed in section 4.2.
Forthis experiment no means of optimisation were ap-plied.
Therefore Personalised PageRank was notused, and traditional PageRank took on a uniformrandom surfing vector.
Default values of 0.85 and30 for damping factor and maximum iterationswere set respectively.4.3.2 Experiment 1: ObservationsFirst and foremost, it is clear from Table 1 and 2that the iterative approach outperforms the con-ventional approach, regardless of the subgraphused, level of disambiguation, or the graph central-ity measure employed.
Since no graph centralitymeasure or subgraph were optimised, let this ex-periment prove that the iterative approach has thepotential to improve any WSD system that imple-ments it.At the document level for both subgraphs the F-Scores were very close to the Most Frequent Sense(MFS) baseline for this task of 66.50.
It is noto-riously hard to beat and only one team (Guti?rrezet al., 2013) managed to beat it for this task.
Forall subtree subgraphs, we observe that In-Degree isclearly the best choice of centrality measure, whileHITS (hub) enjoys the most improvement.
Wealso observe that applying the iterative approachto Betweenness Centrality on shortest paths is agreat combination at both the document and sen-tence level, most probably due to the measure be-ing based on shortest paths.
Furthermore it is45worth noting, the results at the sentence level forall graph centrality measures on shortest path sub-graphs are quite poor, but highly improved, thisis likely to our restriction of L = 2 causing thesubgraphs to be much sparser and broken up intomany components.We also provide here an example from the dataset in which the incorrect disambiguation of thelemma cup via the conventional approach wascorrected by the iterative approach.
This exampleis the seventh sentence in the eleventh document(d011.s007).
Each word?s degree of polysemyis denoted in square brackets.
?Spanish [1]football players playing in the All-Star[4]League and in powerful [12]clubs of the [2]PremierLeague of [9]England are during the [5]year very ac-tive in [4]league and local [8]cup [7]competitions andthere are high-level [25]shocks in the [10]EuropeanCups and [2]European Champions League.
?The potential graph constructed from this sen-tence is illustrated in Figure 5 as a shortest pathssubgraph.
The darker edges portray the subgraphiteratively constructed up to a polysemy ?
?
8(in order to disambiguate cup), whereas the lighteredges portray the greater subgraph constructed ifthe conventional approach is employed.
Note thatalthough the lemma cup has eight senses, onlythree are shown due to the application of the previ-ously mentioned SENSE_SHIFTS filter.
The re-maining five senses of cup were filtered out sincethey were not able to link to a sense up to L = 2hops away that is anchored to an alterative lemma.?
cup#1 - A small open container usually used fordrinking; usually has a handle.?
cup#7 - The hole (or metal container in the hole)on a golf green.?
cup#8 - A large metal vessel with two handles thatis awarded as a trophy to the winner of a competi-tion.Given the context, the eighth sense of cup is thecorrect sense, the type we know as a trophy.
Forthe conventional approach, if ?
is a centrality mea-sure of Out-Degree then the eighth sense of cup iseasily chosen by having one extra outgoing edgethan the other two senses for cup.
Yet if ?
is a cen-trality measure of In-Degree or Betweenness Cen-trality, all three senses of cup now have the samescore, zero.
Therefore in our results the first senseis chosen which is incorrect.
On the other hand, if[8]cup#1handle#1[12]golf_club#2[4]league#2association#1[12]club#2[7]contest#1tournament#1[4]league#1[12]baseball_club#1baseball_league#1[9]England#1Australia#1[5]year#1[8]cup#7golf#1[8]cup#8monopoly#1[7]competition#1match#2sport#1[7]competition#3Figure 5: Conventional vs Iterative Subgraphthe subgraph was constructed iteratively with dis-ambiguation results providing feedback to consec-utive constructions, this could have been avoided.The shortest paths cup#1?handle#1?golf_club#2and cup#7?golf#1?golf_club#2 only exist becausethe sense golf_club#2 (anchored to the more poly-semous lemma club) is present, if it was not thenthe SENSE_SHIFTS filter would have removedthese alternative senses.
This demonstrates that ifthe senses of more polysemous lemmas are intro-duced into the subgraph too soon, they can inter-fere rather than help with disambiguation.Secondly with each disambiguation at lowerlevels of polysemy, a more stable context is con-structed to perform the disambiguation of muchmore polysemous lemmas later.
Therefore in Fig-ure 5 an iteratively constructed subgraph with cupalready disambiguated, would mean the other twosenses of cup would no longer be present.
This en-sures that club#2 (the correct answer) would havea much stronger chance of being selected thangolf_club#2, which would have only one incomingedge from handle#1.
Note the conventional ap-proach would lend golf_club#2 one extra incomingedge than club#2 has, which could be problematicif ?
is a centrality measure of In-Degree.460 10 20 30 4040506070Disambiguation Time (sec)F-Score(a) ?
= Betweenness Centrality0 10 20 30 4040506070Disambiguation Time (sec)F-Score(b) ?
= PageRankFigure 6: For each of the 13 documents, performance (F-Score) is plotted against time to disambiguate,for GL= Shortest Paths.
The squares (PageRank) and circles (Betweenness Centrality) plot the conven-tional approach.
The arrows show the effect caused by applying the iterative approach, with the arrowhead marking its F-Score and time to disambiguate.4.4 Experiment 2: Performance4.4.1 Experiment 2: SetupAn obvious caveat of the iterative approach is thatit requires the construction of several subgraphsas ?
increases, which of course will require extracomputation and time which is a penalty for theimproved precision and recall.
We decided to in-vestigate the extent to which this happens.
We se-lected Betweenness Centrality and PageRank fromExperiment 1, in which both use shortest path sub-graphs at the document level.
This is because a)they acquired good results at the document leveland b) with only 13 documents there are less datapoints on the plots making it easier to read as op-posed to the hundreds of sentences.4.4.2 Experiment 2: ObservationsFirstly from Figures 6(a) and (b) we see thatthere is a substantial improvement in F-Scorefor almost all documents, except for two for ?
=Betweenness Centrality and one for ?
= PageR-ank.
With some exceptions, for most documentsthe increased amount of time to disambiguate isnot unreasonable.
For this experiment, applyingthe iterative approach to Betweenness Centralityresulted in a mean 231% increase in processingtime, from 3.54 to 11.73 seconds to acquire amean F-Score improvement of +8.85.
Again forPageRank, a mean increase of 343% in processingtime, from 1.95 to 8.64 seconds to acquire aF-Score improvement of +7.16 was observed.We wanted to investigate why in some cases, theiterative approach can produce poorer results thanthe conventional approach.
We looked at aspectsof the subgraphs such as order, size, density, andnumber of components.
Eventually we came tothe conclusion that, just like in a Sudoku puzzle, ifthere are not enough hints to start with, the possi-bility of finishing the puzzle becomes slim.Therefore we suspected that if there were notenough monosemous lemmas, to construct the ini-tial GL, then the effectiveness of the iterative ap-proach could be negated.
It turns out, as observedin Figures 7(a) and (b) on the following page thatthis does effect the outcome.
On the horizontalaxis, document monosemy represents the percent-age of lemmas in a document, not counting dupli-cates, that are monosemous.
The vertical axis onthe other hand represents the difference in F-Scorebetween the conventional and iterative approach.Through a simple linear regression of the scatterplot, we observe an increased effectiveness of theiterative approach.
This observation is important,because a WSD system may decide on which ap-proach to use based on a document?s monosemy.With m representing document monosemy, and?F representing the change in F-Score inducedby the iterative approach, the slopes observed inFigures 7(a) and (b) are denoted by Equations (2)and (3) respectively.
?F = 0.53m?
0.11 (2)?F = 0.60m?
3.07 (3)475 10 15 20 25 30 3501020Document Monosemy (%)?F-Score(a) ?
= Betweenness Centrality5 10 15 20 25 30 3505101520Document Monosemy (%)?F-Score(b) ?
= PageRankFigure 7: Both PageRank (squares) and Betweenness Centrality (circles) are plotted.
Each data plotrepresents the change in F-Score when the iterative approach replaces the conventional approach withrespect to the monosemy of the document.4.5 Experiment 3: A Little OptimisationBriefly, we made an effort into optimising the iter-ative approach with subtree subgraphs, and com-pared these results with systems from SemEval2013 Task 12 (Navigli et al., 2013) in Table 3.Team System P R FUMCC-DLSI Run-2+68.50 68.50 68.50UMCC-DLSI Run-3+68.00 68.00 68.00UMCC-DLSI Run-1+67.70 67.70 67.70SUDOKU It-PPR[M]+67.41 67.30 67.36MACHINE MFS 66.50 66.50 66.50SUDOKU It-PPR[M] 67.20 65.49 66.33SUDOKU It-PR[U] 64.07 62.44 63.24SUDOKU It-PD 63.58 61.47 62.51DAEBAK!
PD+60.50 60.40 60.40GETALP BN-1+58.30 58.30 58.30SUDOKU PR[U] 60.09 54.06 56.91GETALP BN-2+56.80 56.80 56.80Table 3: Comparison to SemEval 2013 Task 12Firstly, we were able to marginally improve ouroriginal result as team DAEBAK!
(Manion andSainudiin, 2013), by applying the iterative ap-proach to our Peripheral Diversity centrality mea-sure (It-PD).
Next we tried Personalised PageRank(It-PPR[M]) with a surfing vector biased towardsonly Monosemous senses.
We also included reg-ular PageRank (It-/PR[U]) with a Uniform surfingvector as a reference point.
It-PPR[M] almost de-feated the MFS baseline of 66.50, but lacked re-call.
To rectify this, the MFS baseline was used asa back-off strategy (It-PPR[M]+)4, which then led4Note that plus+implies the use of a back-off strategy.to us beating the MFS baseline.
As for the otherteams, GETALP (Schwab et al., 2013) made useof an Ant Colony algorithm, while UMCC-DLSI(Guti?rrez et al., 2013) also made use of PPR,except they based the surfing vector on SemCor(Miller et al., 1993) sense frequencies, set L = 5for shortest paths subgraphs, and disambiguatedusing resources external to BabelNet.
Since theirimplementation of PPR beats ours, it would beinteresting to see how effective the iterative ap-proach could be on their results.5 Conclusion & Future WorkIn this paper we have shown that the iterative ap-proach can substantially improve the results ofregular subgraph-based WSD, even to the pointof defeating the MFS baseline without doing any-thing complicated.
This is regardless of the sub-graph, graph centrality measure, or level of disam-biguation.
This research can still be extended fur-ther, and we encourage other researchers to rethinktheir own approaches to unsupervised knowledge-based WSD, particularly in regards to the interac-tion of subgraphs and centrality measures.ResourcesCodebase and resources are at first author?s home-page: http://www.stevemanion.com.AcknowledgmentsThis research was completed with the help of theKorean Foundation Graduate Studies Fellowship:http://en.kf.or.kr/48ReferencesEneko Agirre and Aitor Soroa.
2008.
Using the Mul-tilingual Central Repository for Graph-Based WordSense Disambiguation.
In Proceedings of LREC,pages 1388?1392, Marrakech, Morocco.
EuropeanLanguage Resources Association.Eneko Agirre and Aitor Soroa.
2009.
PersonalizingPageRank for Word Sense Disambiguation.
In Pro-ceedings of the 12th Conference of the EuropeanChapter of the ACL, pages 33?41, Athens, Greece.Association for Computational Linguistics.Eneko Agirre, Oier Lopez De Lacalle, Christiane Fell-baum, Maurizio Tesconi, Monica Monachini, PiekVossen, and Roxanne Segers.
2010.
SemEval-2010Task 17: All-words Word Sense Disambiguation ona Specific Domain.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, pages75?80, Uppsala, Sweden.
Association for Computa-tional Linguistics.Sergey Brin and Lawrence Page.
1998.
The Anatomyof a Large-scale Hypertextual Web Search Engine.Computer Networks and ISDN Systems, 30:107 ?117.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA.Linton C. Freeman.
1979.
Centrality in Social Net-works Conceptual Clarification.
Social Networks,1(3):215?239.William A Gale, Kenneth W Church, and DavidYarowsky.
1992.
A Method for DisambiguatingWord Senses in a Large Corpus.
Computers and theHumanities, 26:415 ?
439.Yoan Guti?rrez, Antonio Fern?ndez Orqu?n, AndyGonz?lez, Andr?s Montoyo, Rafael Mu?oz, RainelEstrada, Dennys D Piug, Jose I Abreu, and RogerP?rez.
2013.
UMCC_DLSI: Reinforcing a Rank-ing Algorithm with Sense Frequencies and Multi-dimensional Semantic Resources to solve Multilin-gual Word Sense Disambiguation.
In Proceedings ofthe 7th International Workshop on Semantic Evalu-ation (SemEval 2013), in conjunction with the Sec-ond Joint Conference on Lexical and ComputationalSemantics (*SEM 2013), pages 241?249, Atlanta,Georgia.
Association for Computational Linguistics.T.H.
Haveliwala.
2003.
Topic-Sensitive Pagerank:A Context-Sensitive Ranking Algorithm for WebSearch.
IEEE Transactions on Knowledge and DataEngineering, 15(4):784?796.Adam Kilgarriff.
1998.
SENSEVAL: An Exercise inEvaluating Word Sense Disambiguation Programs.In Conference Proceedings of LREC, pages 581?585, Granada, Spain.Jon M. Kleinberg.
1999.
Authoritative Sources ina Hyperlinked Environment.
Journal of the ACM,46(5):604?632.Els Lefever and Veronique Hoste.
2010.
SemEval-2010 Task 3: Cross-lingual Word Sense Disam-biguation.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 82?87,Boulder, Colorado.
Association for ComputationalLinguistics.Els Lefever and Veronique Hoste.
2013.
SemEval-2013 Task 10: Cross-lingual Word Sense Disam-biguation.
In Proceedings of the 7th InternationalWorkshop on Semantic Evaluation (SemEval 2013),in conjunction with the Second Joint Conferenceon Lexical and Computational Semantics (*SEM2013), Atlanta, Georgia.
Association for Computa-tional Linguistics.Steve L. Manion and Raazesh Sainudiin.
2013.
DAE-BAK!
: Peripheral Diversity for Multilingual WordSense Disambiguation.
In Proceedings of the 7th In-ternational Workshop on Semantic Evaluation (Se-mEval 2013), in conjunction with the Second JointConference on Lexical and Computational Seman-tics (*SEM 2013), pages 250?254, Atlanta, Georgia.Association for Computational Linguistics.Rada Mihalcea.
2005.
Unsupervised Large-Vocabulary Word Sense Disambiguation withGraph-based Algorithms for Sequence Data Label-ing.
In Proceedings of the conference on HumanLanguage Technology and Empirical Methods inNatural Language Processing, pages 411?418, Van-couver, Canada.
Association for Computational Lin-guistics.George A. Miller, Claudia Leacock, Randee Tengi, andRoss T. Bunker.
1993.
A Semantic Concordance.
InProceedings of the Workshop on Human LanguageTechnology - HLT ?93, pages 303?308, Morristown,NJ, USA.
Association for Computational Linguis-tics.Roberto Navigli and Mirella Lapata.
2007.
GraphConnectivity Measures for Unsupervised WordSense Disambiguation.
In Proceedings of the 20thInternational Joint Conference on Artificial Intelli-gence (IJCAI), pages 1683?1688.Roberto Navigli and Mirella Lapata.
2010.
An Exper-imental Study of Graph Connectivity for Unsuper-vised Word Sense Disambiguation.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence,32(4):678 ?
692.Roberto Navigli and Simone Paolo Ponzetto.
2012a.BabelNet: The Automatic Construction, Evaluationand Application of a Wide-Coverage MultilingualSemantic Network.
Artificial Intelligence, 193:217?250.Roberto Navigli and Simone Paolo Ponzetto.
2012b.Joining Forces Pays Off: Multilingual Joint WordSense Disambiguation.
In Proceedings of the 2012Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning, pages 1399?1410, Jeju Island,Korea.
Association for Computational Linguistics.49Roberto Navigli and Paola Velardi.
2005.
Struc-tural Semantic Interconnections: A Knowledge-based Approach to Word Sense Disambiguation.IEEE Transactions on Pattern Analysis and MachineIntelligence, 27(7):1075?1086.Roberto Navigli, Kenneth C Litkowski, and Orin Har-graves.
2007.
SemEval-2007 Task 07: Coarse-Grained English All-Words Task.
In Proceedings ofthe 4th International Workshop on Semantic Evalu-ations, pages 30?35, Prague, Czech Republic.
Asso-ciation for Computational Linguistics.Roberto Navigli, David Jurgens, and Daniele Vannella.2013.
SemEval-2013 Task 12: Multilingual WordSense Disambiguation.
In Proceedings of the 7th In-ternational Workshop on Semantic Evaluation (Se-mEval 2013), in conjunction with the Second JointConference on Lexical and Computational Seman-tics (*SEM 2013).
Association for ComputationalLinguistics.Roberto Navigli.
2009.
Word Sense Disambiguation:A Survey.
ACM Computing Surveys, 41(2):10:1 ?10:69.Martha Palmer, Christiane Fellbaum, Scott Cotton,Lauren Delfs, and Hoa Trang Dang.
2001.
En-glish Tasks: All-Words and Verb Lexical Sample.
InProceedings of SENSEVAL-2 Second InternationalWorkshop on Evaluating Word Sense Disambigua-tion Systems, pages 21?24, Toulouse, France.
Asso-ciation for Computational Linguistics.Ted Pedersen.
2007.
Unsupervised Corpus-BasedMethods for WSD.
In Eneko Agirre and Philip Ed-monds, editors, Word Sense Disambiguation: Algo-rithms and Applications, chapter 6, pages 133?166.Springer, New York.Simone Paolo Ponzetto and Roberto Navigli.
2010.Knowledge-rich Word Sense Disambiguation Rival-ing Supervised Systems.
Proceedings of the 48thAnnual Meeting of the ACL, pages 1522?1531.Didier Schwab, Andon Tchechmedjiev, J?r?me Gou-lian, Mohammad Nasiruddin, Gilles S?rasset, andHerv?
Blanchon.
2013.
GETALP: Propagation ofa Lesk Measure through an Ant Colony Algorithm.In Proceedings of the 7th International Workshop onSemantic Evaluation (SemEval 2013), in conjunc-tion with the Second Joint Conference on Lexicaland Computational Semantics (*SEM 2013), pages232?240, Atlanta, Georgia.
Association for Compu-tational Linguistics.Ravi Sinha and Rada Mihalcea.
2007.
Unsuper-vised Graph-based Word Sense Disambiguation Us-ing Measures of Word Semantic Similarity.
In Pro-ceedings of the International Conference on Seman-tic Computing, pages 363 ?
369.
IEEE.Benjamin Snyder and Martha Palmer.
2004.
The En-glish All-Words Task.
In Proceedings of the ThirdInternational Workshop on the Evaluation of Sys-tems for the Semantic Analysis of Text, pages 41?43,Barcelona, Spain.
Association for ComputationalLinguistics.David Yarowsky.
1993.
One Sense Per Collocation.
InProceedings of the workshop on Human LanguageTechnology - HLT ?93, pages 266?271, Morristown,NJ, USA.
Association for Computational Linguis-tics.David Yarowsky.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.
InProceedings of the 33rd Annual Meeting of the ACL,pages 189?196, Cambridge, MA.
Association forComputational Linguistics.50
