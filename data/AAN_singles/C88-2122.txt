Generating Multimodal Output -Conditions, Advantages and ProblemsDagmar SCHMAUKS, Norbert REITHINGERSFB 314: KQnstliche Intelligenz - Wissensbasierte SystemeUniversit&t des Saarlandes, FB 10 - Informatik IVD-6600 Saarbr(Jcken 11Federal Republic of GermanyNet: schmauks@sbsvax.uucp, bert@sbsvax.uucpAbstractIn natural communication situations, multimodal referent specificationis frequent and efficient.
The linguistic component are deicticexpressions, e.g.
'this' and 'here'.
Extralinguistic devices in dialogs aredifferent body movements, mainly pointing gestures.
Their functionalequivalent in texts are means like arrows and indices.This paper has two intentions.
First, it discusses the advantages ofmultimodal reference in interhuman communication which motivate theintegration of extralinguistic "pointing" devices into NL dialog systems.The generation of multimodal output poses specific problems, whichhave no counterpart in the analysis of multimodal input.
The secondpart presents the strategy for generating multimodal output which hasbeen developed within the framework of the XTRA system (a NLaccess system to expert systems).
XTRA allows the combination ofverbal descriptions and pointing gestures in order to specify elementsof the given visual context, i.e.
a form displayed on the screen.
Thecomponent POPEL generates referential expressions which may beaccompanied by a pointing gesture.
The appearance of these gesturesdepends on several factors, e.g.
the type of referent (whether it is aregion or an entry of the form) and its complexity.AcknowledgementsThe work presented here is being supported by the German ScienceFoundation (DFG) in its Special Collaborative Program on AI andKnowledge-Based Systems (SFB 314), project N1 (XTRA).
We wouldlike to thank our colleagues of the XTRA project for their helpfulcomments on an earlier version of this paper.1.
IntroductionIn face-to-face communication, speech and communicative bodymovements are performed simultaneously.
A prime example ot thismu/lirnoda//ly are detctic actions which specify elements of a sharedvisual world by the combination of deictic expressions ('this', 'there'etc.)
and extralinguistic devices like pointing gestures.
The advantagesof this mu#imoda/ de/xis motivate the integration of extralinguisticmeans for referent specification into natural language (NL) dialogsystems.
Starting point of the following considerations is the systemXTRA, an NL access system for expert systems, which is underdevelopment at the University of SaarbrLicken.
In its current applicationdomain, it assists the user in filling out a tax form which is visible on thescreen.
Elements of this form can be specified not only by (typed)verbal descriptions, but also by combining descriptions and simulatedpointing gestures.
Some problems of rnu#imoda/input and solutions inXTRA have already been treated in detail (cf.
/AIIgayer, Reddig 86/,/AIIgayer et al 88/,/Schmauks 86a, 87/).Mu#/moda/ou/put is no simple mirror image of multimodal input.Rather, it has to deal with different problems the investigation of whichhas been missing till now (for a first impression see/Reithinger 87a/).Because of the novelty of the task, one cannot claim to offer ultimatesolutions.
Instead, we wish to outline several approaches for therealization of multimodality, present our strategy and give reasons forthe choice.In section 2, we present the means, conditions and advantages ofmultimodal deixis within natural communication situations.
Topics ofsection 3 are the different strategies for realizing multimodality in NLdialog systems and some of the problems arising.
Section 4 sketchesthe framework of the XTRA system and the types of gestures occuringin this domain.
Section 5 presents the generation component POPEU,focussing on its global strategy for generating multimodal output.Subtopics are POPEL's architecture and its methods for simulatingdifferent types of pointing gestures.
In section 6, some alternativestrategies for generating multimodal output are briefly discussed.1) POPEL is the acronym for Product~on Of \[Perhaps, Possible, ..}Eloquent Langu,~Te.5842.
Deixis in natural communi -cation situationsDeictic reference occurs in dialogs as well as in texts.
In bothsituations, the objects referred to can be linguistic entities (sentences,chapters eto.)
or non-linguistic objects (cats, tables etc.
), For thefollowing considerations, only those types of deixis are relevant whichspecify non-linguistic entities.
They can be performed by combininglinguistic expressions with extralinguistic devices.D/e/ogs are characterized by the possibility of turn-taking.
If bothparticipants are present, they can specify elements of their commonvisual world by combining deictic expressions and body movements,mainly peinting gestures, If a speaker can point to objects, s/he canuse shorter, ~impler and even referentially insufficient descriptions.
Inparticular, pointing facilitates reference if the speaker doesn't knowhow to describe the object in question, One example is the utteranceTHIS \[~'\]  is broken.while pointing at some part of the engine of one's car 2.Successful reference by pointing has some preconditions, for instancethe receiver's visual attention.
S/he has to face the speaker in order tonotice his/her gesture and then has to follow this gesture with his/hergaze.
The first step can fail by visual inattentiveness, the latter bywrong direction of gaze.
Feedback is received by speakers via twochannels.
On the one hand, a speaker controls the nonverbalreact/onof the receiver and can therefore immediately request attentiveness orcorrect a wrong direction of gaze.
On the other hand, s/he getsdelayed feedback by the verba/reaction.Communication by text normally implies a spatial and temporaldissocation of sender (-writer) and receiver (=reader).
Therefore, thesender can deicticel/.y refer only to non-!inguistic entities which arevisible also for the receiver.
This condition is fulfilled if the text iscombined with non-linguistic representations (pictures, diagrams,maps etc.).
In these cases, the sender can refer to elements of this'visual context' by combining linguistic expressions and extralinguisticmeans (arrows, indices etc.).
The latter represent a functionalequivalent to pointing gestures within dialogs and have the sameadvantages.
But, like the text itself, they don't require attentiveness onthe reader's side during the period of their production.3.
Deixis in NL dialog systemsThe type of dialog considered here is a consu#at/on o~;~/o#:' the system(= expert) assists the user (-  non-specialist) in filling out his/her taxform.
The system has not only more expert knowledge about thedomain, but also more knowledge concerning content and structure ofthe graphics displayed on the screen.Due to these differences in knowledge, the anaO/sis component has todeal with shortcomings in the user's input.
His/ber pointing gesturesmay be imprecise because s/he doesn't know the structure of thepresented graphics.
Ignorance of technical terms results in inadequatedescriptions.
In theses cases, additional knowledge sources areneeded for referent identification, e.g.
case frame analysis and dialogmemory (/AIIgayer, Reddig 86/, /AIIgayer et al 88/).
In contrast, thegenera/ion component can always produce precise pointing gesturesas well as exact descriptions.
But the latter capability may be in conflictwith the task of generating system reactions which are communicati-vely adequate.
If the user doesn't know certain technical terms, thenthe combination of underspecitied escription and precise gesture ismore comprehensible than a totally specified description.2) Pointing gestures are represented by the sign ' \[1~>'1Capital ~etters Ihlghllght he correlated phrese.Another problem is the different perceptual capabilities of user andsystem.
Humans are 'multichannet systems' which receive informationabout objects through a great variety of channels.
In contrast, theperceptible world of all systems developed to date is only a smallsubset of the user's world.
Normally, systems with more generalapplication domains are only able to process textual and graphicalinput.
In particular, these systems cannot "see" the user's nonverbalbehavior and therefore cannot request attention if necessary.
Also,wrong user reactions cannot serve as an indication of his/her visualinattentiveness, because they can be caused by several other factors.For example, It might be the case that the user has correctly identifiedthe field In question but enters a wrong amount because s/he hasconfused some technical terms.
During natural pointing, the soundwhich occurs when the speaker touches the form may cause thehearer to pay attention to his/her gestures.
But in the case of simulatedpointing, the generation of a specific audible signal in parallel to eachpointing gesture implies a rather "unnatural" situation.The design of multimodal interfaces is one central topic of recentresearch.
It has to be emphasized that the term 'multimodal input/output' covers a great variety of heterogeneous phenomena from themanipulation of simulated objects within an "artificial reality" (e.g.
theD#taG/ove, see/Zimmerman et al 87/) to the use of different pointingdevices.The goal 'multimodal referent specification' can be achieved by variousstrategies.
If one wants to s/~nu/ate nstuf#/po/'f/t/\[Ig, the pointing deviceshould correspond to natural gestures.
A touch-sensitive screen allowshighly natural gestures, but pointing by means of a so-called 'mousecursor' can also simulate some aspects of natural pointing.
The latterstrategy is chosen in the XTRA system.
If, in contrast, one wants tooffer function#/equ/v#/ents, here exists a great variety of devices.
It ispossible to adapt the extralinguistic deictic means which occur in texts,e.g.
arrows and indices.
Furthermore, the computer offers severalspecific devices, which have no model in natural pointing, such asIraming, highlighting or inverting the referent.
The choice depends onseveral factors, for example which types of objects are to be referredto.4.
Form deixis in XTRAThe given visual context of the XTRA system is the form displayed onthe screen.
In order to specify its elements, several types of pointingactions occur ( cf./AIIgayer 86/,/Schmauks 86a, 86b, 87/):?
Punctua/po/nt/ngindicates one singular point on the form andcan be produced in order to specify primitive objects, i.e.individual regions and individual entries.
Another possibility isthe reference to a complex region by pointing to a part of itCoam-pro-toto de/x/s).?
During non-punctua/po/nt/n#, the pointing device performs acomplex motion, e.g.
underlines an entry or gives the bordersof a larger region.?
Mu#/plepoin//ngmeans, that one utterance is accompanied bymore than one pointing gesture.
These complex pointingactions specify elements of sets, for example several instancesof one concept.One aim of XTRA is the use of multimodal referent specificationtechniques in input as well as in output.
Mu#imoda/input is performedby combining typed NL descriptions and simulated pointing gestures.The latter are currently realized by means of a mouse cursor.
Theysimulate natural pointing with regard to two aspects: the user canselect the accuracy of gesture, and the relation between the gestureand the object referred to depends on context /AIIgayer 86/.
Forexample, if the user points at a region which is already filled out,descriptor analysis is necessary in order to decide whether s/he refersto the region itself or to its actual entry.The generation component has to reckon with different problemsconcerning pointing actions.
If it also realizes gestures by movementsof a mouse cursor, their perception may be hampered by the user'svisual inattentiveness.
In the case of multiple pointing, for example,s/he might fail to notice one of the pointing gestures and consequentlymay not identify the referent.
This causes the whole utterance (e.g.
'THIS AMOUNT \[i\]~-\], you could also enter HERE \[o'>'\]') to becomnincomprehensible.5B55.
Generation of pointingactions with POPEL5.1 Architecture of POPELThe task of POPEL, the natural language generation component OfXTRA, is to select and verbalize those parts of the conceptualknowledge base that are to be uttered.
The structure of the componentfollows the well-known division into a "what-to-say" and a "how-to-say" part/McKeown 85/: POPEL-WHAT, which selects the content,and POPEL-HOW, which verba//~esit (cf./Reithinger 87b/).
Contrary tomost other systems, the information flow between these two sub-modules is not unidirectional from the selection part to the verbalisationpart.
Rather, both parts communicate while processing the output ofthe system (cf./How 87/).A second essential feature of POPEL's architecture is the parallelprocessing approach to generation: the different stages of selectingend realizing the output proceed in a parallel cascade.
In this way, it ispossible to go ahead with the selection processes inside POPEL-WHAT, while a previously selected part of the utterance is alreadyverbalized in POPEL-HOW.
As one consequence, restrictions to theselection arising out of the verbalization process can be taken intoaccount.Currently, a first prototype of POPEL is under development.
Theprocessor for the parallel cascade has already been implemented.
Theemphasis was placed on information propagation both upwards anddownwards and on the definition of the syntax and semantics of thetransition rules.
The next step will be the encoding of knowledge withinthis framework.
POPEL is implemented on a Symbolics 3640 Lispmachine running Zetalisp.5.2 Pointing gestures as specialcases of descriptions5.2.1 Selection of descriptionsSelection of descriptions is one essential interaction point between thetwo components.
Decisions which concern POPEL-WHAT are:?
"Givenness" of an object: the description of an objectdepends on whether that object is known in the (implicit otexplicit) context of the user, In general, POPEL-HOW selectsdefinite phrases for known objects and indefinite phrases forunknown objects, but the required knowledge as to "given-ness" is stored in the user model which is accessed byPOPEL-WHAT.?
"Pointability" of an object: the so called 'form hierarchy' repre-sents the structure of the form.
It links the regions of the formto the respective representations in the conceptual knowledge.If an object is selected for verbalization, the link from theconcept of the object to the form hierarchy provides theinformation that a pointing gesture can be generated.?
Situation-dependency of a description: the contextual know-ledge bases contain structure and content of the previousdialog.
They allow the determination of differently detaileddescriptions, depending on the current context, If necessary,meta-communicative or text-deictic attributes can be added.POPEL-HOW makes the following decisions:?
Generation of a description: whether an object in the concep-tual knowledge base is to be realized as a description dependson the language-related structure that has already beendetermined.?
Language-dependent constraints: the possible surface struc-tures remaining for a description depend on the extent towhich the sentence has already been verbalized.
In German,for instance, it is hardly possible to generate a pronominal NPif there is already a lexical NP or PP after the finite verb and thepronominal NP is to follow this phrase (cf./Enge182/).586The sequence of these decisions is intertwined.
For example, theinquiry of POPEL-WHAT, as to whether an object is available in thecontext makes sense only after POPEL-HOW has decided to generatea description at all (for an outline see/Reithinger 87a/).5.2.2 When to pointFrom the viewpoint of an NL dialog system, pointing actions aredescriptions which are accompanied by a pointing gesture.
They focusthe user's visual attention and can therefore localize visible objects.
Inthe XTRA domain, pointing actions can refer to three types of objects:?
A form region, e.g.
'You can enter your donations HERE Ion\].'?
An entr2;, e.g.
'THESE 350 DM \ [~\ ]  are travel expenses:'?
A correlated concept, e.g.
'Can I deduct SUCH DONATIONS\ [~\ ]?
'All elements of the form are in the shared visual context; therefore,they can be referred to by definite descriptions.
No serious problemsarise if an utterance is accompanied only by one pointing gesture.
Incontrast, the simulation of multiple pointing requires further considera-tions (cf.
section 4) and has therefore not been treated in this paper.If the system's reaction contains more than one description whichallows pointing, only one possibility will be realized.
The others arereduced to purely verbal descriptions.
The sentence (1) for exampleallows the reductions (la) and (t b):(1) THIS AMOUNT \[~'>.\], you have to enter HERE \[\[~','\].
(la) The donations of  ISDM, you have to enter HERE \[~.'\].
(lb) THIS AMOUNT \[Q:~'\], you have to enter///the//he"donations',Because sentence generation is performed incrementally, POPEL-WHAT doesn't know the whole content of the utterance at the momentit has to decide whether to use a pointing gesture or not.
Therefore, thedecisions have to be based on heuristics and may be "suboptimal".One of these heuristics is: do not use a pointing gesture if the object inquestion can also be specified by a short referential expression, forexample a pro-word.
Then the pointing gesture remains available toreduce a complex description if it follows in the same utterance.5.2.3 How to pointFollowing the simulation-oriented strategy of XTRA, pointing gesturesare realized by positioning a mouse cursor on the screen.
This is aclose approximation of the type of movements a human performswhen pointing with his/her finger.
Furthermore, different degrees ofaccuracy are simulated by different shapes of the cursor.
POPELperforms the pointing gesture parallel with verbalizing the correlatedphrase and presenting it on the screen.5.2.3.1 Punctual pointing gesturesDuring a punctualpointing esture, the cursor doesn't move on theform.
This type of gesture is used both for the localization of primitiveobjects as well as for pars-pro-toto deixis.
Because a gesture canrefer either to a field of the form or to its content (i.e.
a string in ourdomain), the linguistic information (e,g.
'this field' vs. 'this amount ofmoney') has to disambiguate between these possibilities.
A hand whichholds a pencil is used as the symbol for this type of gesture (see figure1/symbol A).
The exact position depends on the type of the object.
Thedefault strategy is as follows: if the pointing action refers to a field, thepencil is in the middle of  the fie/d, if it refers to an entry, the pencil isbelow the entf~, so that the symbol doesn't cover it.
Additionally, theuser model takes effect: if the user requested another position of thegesture repeatedly (e.g.
'Take away the finger, I cannot read thatl'), thepointing strategy has to be changed.Each time the speaker-hearer oles are reversed, the current pointingsymbol changes to a neutral symbol (i.e, the standard mouse cursor).In this way, the user's visual attention doesn't remain fixed to .thelocation of the last pointing gesture.
If the system generates a newpointing gesture, it first changes the neutral symbol into the choosenpointing symbol.
Then it moves the symbol to the new pointinglocation.
This method mimics the functionality of the movements of thehand during natural pointing, which already direct the heater's visualattention to the target location.61erbungskostenF~hrten  =wlxcher t  ~ohnu~ u:~d /~:t' l~e\[tx~%aetteAuf~/an~ungen fuer Fahrten rail a~ena~~ k4otorrad/ L~U:taa; amt~,Ke~n~e~chen ~ IMoped/ ~ i)t ~=?hl XYl.khlillll=l vgh aihdlltl~l " ~ " " V,~ ni~4l\[~lll= ~@ V.H.TI ~',I~, , Urld I~lhblh'J~dlyuhG i.
~ ' b | , t ) I c l  l i~f ?hl 3tll~dlc ~lCkSllhdA BFigure 1: Different ypes of pointing gesturesFurthermore, punctual pointing gestures are used to realize pars-pro-toto deixis, which refers to greater parts of the form.
In this casetoo, the ambiguity of the gesture has to be compensated by linguisticinformation.
In our domain, unambiguous descriptions are 'row' and'column'.
Ambiguous expressions like 'region' can be disambiguated byadditionally =taming the referent, e.g.
'the region of DEDUCTIBLES'.Delayed pe=ception of a punctual pointing gesture doesn't hamperreferent identification.
The pointing symbol changes only when the usertakes initiative in the dialog again.
Until then, the information of thegesture remains visually available.
There exists an equivalent in naturalpointing: it might happen that a speaker leaves his/her forefingerextended, until the dialog partner recognizes the gesture.5.2.3.2 Non-punctual pointing gesturesNon-punctual pointing, for example the encircling of a whole area,poses much greater problems.
After the movement of the cursorceased, the actual cursor position indicates only the final point of thegesture.
If the user was inattentive, s/he cannot reconstruct he courseof movement.
This loss of information can be partially avoided byproviding exact descriptions.Standard candidates for non-punctual pointing actions are compositeobjects, for example rows, columns or larger regions.
However, anon-punctual pointing gesture that has not been noticed does notdeliver any more information than the combination of punctualpam-pro-toto de/N/s and an exact linguistic description.Non-punctual pointing gestures can be realized by various means.
In afirst release of POPEL, the gesture is performed with another symbol(hand with stretched-out forefinger, see figure 1/symbol B).
Themovement should be both "natural" as well as relatively precise.Further research has to evaluate POPEL's current strategy with respectto various features, for example the efficiency of the pointing strategyand its acceptance by the user.6.
Alternative concepts formultimodal input/output andfuture requirementsIn the case of non-punctual and multiple pointing actions, the possibleinattentiveness of the user and the current "blindness" of the systemmay lead to a loss of infermation.
This danger increases with thetemporal complexity of the gestures.
The usage of "lasting" pointingtechniques would be one possibility of dealing with this problem.One strategy is to "freeze" the track of non-punctual pointinggestures.
This is similiar to underlining or encircling with a pencil.
Thetrack remains visible on the form until the next change in dialog control.One can imagine two variants of this strategy: the first is the successivedrawing of the line, which is simiUar to a human-made gesture.
Alsothe drawing speed could be adopted from natural drawing.
The secondvariant is to produce the whole line s/multaneous~But this keez/ng method has the essential shortcoming that theadditional ines muddle the screen.
Therefore, the functionally similarbut "unnatural" means of referent specification (framing, underlaying,blinking, inverting etc.)
seem to be more advantageous.
They preservethe form's structure since it is not blurred by additional lines.Furthermore, these methods specify form regions, i.e.
rectangularobjects, more exactly than circular lines.
On the other hand, however,this framing approach cannot simulate the context-dependency ofnatural pointing.One unsolved problem remains to be emphazised: all the aforemen-tioned methods a/onecannot solve the problems of multiple pointing.
Ifthe sequence of the gestures must be known in order to understandthe utterance, the frames etc.
have to be combined with additionalmeans.
One solution could be the adaptation of methods used in textsin order to refer to elements of graphics (e.g.
indices, cf.
section 2).A highly user-adapted generation of pointing actions would require thestorage of information about pointing in the user model.
On the onehand, these are facts about the user's pointing behavior, includingfrequency and accuracy of gestures and possible systematic deviations(e.g.
pointing consistently beside or below the intended referent).
Onthe other hand, the generation component has to take into account theuser's reaction to the system's point/n# actions.
If s/he repeatedlymisunderstands uch an action, the system has to modify its pointingstrategy and switch to the fixation method or to the framing approach,for example.587ReferencesAIIgayer, J.
(1986): Eine Graphikkomponente zur Integration vonZeigehandlungen i  natOrlichsprachllche KI-Systeme.
Proceedings der16.
GI-Jahrestagung.
Bedin: Springer.AIIgayer, J. and C. Reddig (1906): Processing Descriptionscontaining Words and Gestures - A System Architecture.
In: C,-R.Rollinger (Hrsg.
): GWAI/C)GA11986.
Berlin: Springer,AIIgayer, J., K. Harbusch, A. Kobs=, C. Reddig, N. Reithinger,D.
Schmauks (1988): XTRA - A Natural-Language Access System toExpert Systems.
Technical Report, SFB 314, FB InformaUk, Universit~ltdes Saarlandes, SaarbrOcken.Engel, U.
(1982): Syntax der deutschan Gegenwartssprache.
Berlin:Erich Schmidt.How,  ` E.H. (1987): Generating Natural Language Under PragmaticConstraints.
Ph.D. Dissertation, Yale University.McKeown, K.R.
(1985): Text generation.
Cambridge: CambridgeUniversity Press,Reithinger, N. (1987a): Generating Referring Expressions andPointing Gestures, In: G, Kempen (ed,): Natural Language Generation,Dordrecht: Kluwer.Reithinger, N. (1987b): Ein erster Blick auf POPEL - -  Wie wird wasgesagt?
In: K, Morik (ed.
): GWA187.
Berlin: Springer.Schmauks, D. (19868): Formulardeixls und ihre Simulation auf demBildschirm.
Ein Oberblick aus linguistischer Sicht.
Memo Nr.4, SFB 314,FB Informatik, Universit~t des Saarlandes, SaarbrOcken,Schmauks, D. (1986b): Form und Funktion von Zeigegesten.
Eininterdisziplin~irer Oberblick.
Report Nr.
10, SFB 314, FB Informatik,Universit~it des Saarlandes, SaarbrOckan,Schmauks, D. (1987): Natural and Simulated Pointing.
Proceedingsof the 3rd European ACL Conference, Kopenhagen, Denmark.
Also:Report Nr.
16, SFB 314, FB Informatik, Universit~tt des Saaflandes,Saarbr0cken.Zimmerman, T.G.
et el.
(1987): A Hand Gesture Interface Device.Prec.
CHr87 Human Factors in Computing Systems.
ACM, New York.~588
