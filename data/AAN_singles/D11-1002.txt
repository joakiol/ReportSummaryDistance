Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13?25,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsPredicting Thread Discourse Structure over Technical Web ForumsLi Wang,??
Marco Lui,??
Su Nam Kim,??
Joakim Nivre?
and Timothy Baldwin???
Dept.
of Computer Science and Software Engineering, University of Melbourne?
NICTA Victoria Research Laboratory?
Dept.
of Linguistics and Philology, Uppsala Universityli.wang.d@gmail.com, saffsd@gmail.com,sunamkim@gmail.com, joakim.nivre@lingfil.uu.se, tb@ldwin.netAbstractOnline discussion forums are a valuablemeans for users to resolve specific informationneeds, both interactively for the participantsand statically for users who search/browseover historical thread data.
However, the com-plex structure of forum threads can make itdifficult for users to extract relevant informa-tion.
The discourse structure of web forumthreads, in the form of labelled dependency re-lationships between posts, has the potential togreatly improve information access over webforum archives.
In this paper, we present thetask of parsing user forum threads to deter-mine the labelled dependencies between posts.Three methods, including a dependency pars-ing approach, are proposed to jointly clas-sify the links (relationships) between postsand the dialogue act (type) of each link.
Theproposed methods significantly surpass an in-formed baseline.
We also experiment with ?insitu?
classification of evolving threads, and es-tablish that our best methods are able to per-form equivalently well over partial threads ascomplete threads.1 IntroductionWeb user forums (or simply ?forums?)
are onlineplatforms for people to discuss information and ob-tain information via a text-based threaded discourse,generally in a pre-determined domain (e.g.
IT sup-port or DSLR cameras).
With the advent of Web2.0, there has been an explosion of web authorship inthis area, and forums are now widely used in variousareas such as customer support, community devel-opment, interactive reporting and online eduction.In addition to providing the means to interactivelyparticipate in discussions or obtain/provide answersto questions, the vast volumes of data contained inforums make them a valuable resource for ?supportsharing?, i.e.
looking over records of past user inter-actions to potentially find an immediately applica-ble solution to a current problem.
On the one hand,more and more answers to questions over a widerange of domains are becoming available on forums;on the other hand, it is becoming harder and harderto extract and access relevant information due to thesheer scale and diversity of the data.This research aims at enhancing information ac-cess and support sharing, by mining the discoursestructure of troubleshooting-oriented web user fo-rum threads.
Previous research has shown that sim-ple thread structure information (e.g.
reply-to struc-ture) can enhance tasks such as forum informationretrieval (Seo et al, 2009) and post quality assess-ment (Lui and Baldwin, 2009).
We aim to move be-yond simple threading, to predict not only the linksbetween posts, but also show the manner of eachlink, in the form of the discourse structure of thethread.
In doing so, we hope to be able to performricher visualisation of thread structure (e.g.
high-lighting the key posts which appear to have led toa successful resolution to a problem), and more fine-grained weighting of posts in threads for search pur-poses.To illustrate the task, we use an example thread,made up of 5 posts from 4 distinct participants, fromthe CNET forum dataset of Kim et al (2010b), asshown in Figure 1.
The discourse structure of thethread is modelled as a rooted directed acyclic graph13HTML Input Code...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go.
It will then redirect to the page ...User APost 1User BPost 2User CPost 3Re: html input codePart 1: create a form with a text field.
See ... Part 2: give it a Javascript actionasp.net c\# videoI?ve prepared for you video.link click ...Thank You!Thanks a lot for that ...
I have Microsoft Visual Studio 6, what program should I do this in?
Lastly, how do I actually include this in my site?
...A little more help... You would simply do it this way: ... You could also just ... An example of this is ...User APost 4User DPost 50+Question-Question2+Answer-Answer4+Answer-Answer1+Answer-Answer1+Answer-Confirmation3+Question-Add?Figure 1: A snippeted and annotated CNET thread(DAG) with a dialogue act label associated with eachedge of the graph.
In this example, UserA initiatesthe thread with a question (dialogue act = Question-Question) in the first post, by asking how to createan interactive input box on a webpage.
In response,UserB and UserC provide independent answers (di-alogue act = Answer-Answer).
UserA responds toUserC to confirm the details of the solution (dia-logue act = Answer-Confirmation), and at the sametime, adds extra information to his/her original ques-tion (dialogue act = Question-Add); i.e., this onepost has two distinct dependency links associatedwith it.
Finally, UserD proposes a different solutionagain to the original question.To predict thread discourse structure of this type,we jointly classify the links and dialogue acts be-tween posts, experimenting with a variety of su-pervised classification methods, namely dependencyparsing and linear-chain conditional random fields.In this, we build on the earlier work of Kim et al(2010b) who first proposed the task of thread dis-course analysis, but only carried out experiments onpost linking and post dialogue act classification asseparate tasks.
In addition to achieving state-of-the-art accuracy over the task, we carry out in-depthanalysis of classification effectiveness at differentthread depths, and establish that the accuracy of ourmethod over partial threads is equivalent to that overfull threads, indicating that the method is applica-ble to in-situ thread classification.
Finally, we in-vestigate the role of user-level features in discoursestructure analysis.2 Related WorkThis work builds directly on earlier work of a subsetof the authors (Kim et al, 2010b), whereby a novelpost-level dialogue act set was proposed, and usedas the basis for annotation of a set of threads takenfrom CNET.
In the original work, we proposed a setof novel features, which we applied to the separatetasks of post link classification and dialogue act clas-sification.
We later applied the same basic method-ology to dialogue act classification over one-on-onelive chat data with provided message dependencies(Kim et al, 2010a), demonstrating the generalisabil-ity of the original method.
In both cases, however,we tackled only a single task, either link classifica-tion (optionally given dialogue act tags) or dialogueact classification, but never the two together.
In thispaper, we take the obvious step of exploring jointclassification of post link and dialogue act tags, togenerate full thread discourse structures.Discourse disentanglement (i.e.
link classifica-tion) and dialogue act tagging have been studiedlargely as independent tasks.
Discourse disentangle-ment is the task of dividing a conversation thread(Elsner and Charniak, 2008; Lemon et al, 2002)or document thread (Wolf and Gibson, 2005) intoa set of distinct sub-discourses.
The disentangleddiscourse is sometimes assumed to take the form ofa tree structure (Grosz and Sidner, 1986; Lemon etal., 2002; Seo et al, 2009), an acyclic graph struc-ture (Rose?
et al, 1995; Schuth et al, 2007; Elsnerand Charniak, 2008; Wang et al, 2008; Lin et al,2009), or a more general cyclic chain graph struc-ture (Wolf and Gibson, 2005).
Dialogue acts areused to describe the function or role of an utterancein a discourse, and have been applied to the anal-ysis of mediums of communication including con-versational speech (Stolcke et al, 2000; Shriberg etal., 2004; Murray et al, 2006), email (Cohen et al,2004; Carvalho and Cohen, 2005; Lampert et al,2008), instant messaging (Ivanovic, 2008; Kim etal., 2010a), edited documents (Soricut and Marcu,2003; Sagae, 2009) and online forums (Xi et al,142004; Weinberger and Fischer, 2006; Wang et al,2007; Fortuna et al, 2007; Kim et al, 2010b).
For amore complete review of models for discourse dis-entanglement and dialogue act tagging, see Kim etal.
(2010b).Joint classification has been applied in a numberof different contexts, based on the intuition that itshould be possible to harness interactions betweendifferent sub-tasks to the mutual benefit of both.Warnke et al (1997) jointly performed segmenta-tion and dialogue act classification over a Germanspontaneous speech corpus.
In their approach, thepredictions of a multi-layer perceptron classifier ondialogue act boundaries were fed into an n-gramlanguage model, which was used for the joint seg-mentation and classification of dialogue acts.
Sut-ton and McCallum (2005) performed joint parsingand semantic role labelling (SRL), using the resultsof a probabilistic SRL system to improve the accu-racy of a probabilistic parser.
Finkel and Manning(2009) built a joint, discriminative model for pars-ing and named entity recognition (NER), address-ing the problem of inconsistent annotations acrossthe two tasks, and demonstrating that NER bene-fited considerably from the interaction with parsing.Dahlmeier et al (2009) proposed a joint probabilis-tic model for word sense disambiguation (WSD) ofprepositions and SRL of prepositional phrases (PPs),and achieved state-of-the-art results over both tasks.There has been a recent growth in user-levelresearch over forums.
Lui and Baldwin (2009)explored a range of user-level features, includingreplies-to and co-participation graph analysis, forpost quality classification.
Lui and Baldwin (2010)introduced a novel user classification task whereeach user is classified against four attributes: clar-ity, proficiency, positivity and effort.
User commu-nication roles in web forums have also been studied(Chan and Hayes, 2010; Chan et al, 2010).Threading information has been shown to en-hance retrieval effectiveness for post-level retrieval(Xi et al, 2004; Seo et al, 2009), thread-levelretrieval (Seo et al, 2009; Elsas and Carbonell,2009), sentence-level shallow information extrac-tion (Sondhi et al, 2010), and near-duplicate threaddetection (Muthmann et al, 2009).
These resultssuggest that the thread structural representation usedin this research, which includes both linking struc-ture and the dialogue act associated with each link,could potentially provide even greater leverage inthese retrieval tasks.Another related research area is post-level classi-fication, such as general post quality classification(Weimer et al, 2007; Weimer and Gurevych, 2007;Wanas et al, 2008; Lui and Baldwin, 2009), andpost descriptiveness in particular domains (e.g.
med-ical forums: Leaman et al (2010)).
It has beendemonstrated (Wanas et al, 2008; Lui and Bald-win, 2009) that thread discourse structure can signif-icantly improve the classification accuracy for post-level tasks.Initiation?response pairs (e.g.
question?answer,assessment?agreement, and blame?denial) from on-line forums have the potential to enhance threadsummarisation or automatically generate knowledgebases for Community Question Answering (cQA)services such as Yahoo!
Answers.
While initiation?response pair identification has been explored as apairwise ranking problem (Wang and Rose?, 2010),question?answer pair identification has been ap-proached via the two separate sub-tasks of ques-tion classification and answer detection (Cong et al,2008; Ding et al, 2008; Cao et al, 2009).
Ourthread discourse structure prediction task includesjoint classification of post roles (i.e.
dialogue acts)and links, and could potentially be performed at thesub-post sentence level to extract initiation?responsepairs.3 Task Description and Data SetThe main task performed in this research is jointclassification of inter-post links (Link) and dialogueacts (DA) within forum threads.
In this, we assumethat a post can only link to an earlier post (or a vir-tual root node), and that dialogue acts are labels onedges.
It is possible for there to be multiple edgesfrom a given post, e.g.
if a post both confirms the va-lidity of an answer and adds extra information to theoriginal question (as happens in Post4 in Figure 1).We experiment with two different approaches tojoint classification: (1) a linear-chain CRF overcombined Link/DA post labels; and (2) a depen-dency parser.
The joint classification task is a nat-ural fit for dependency parsing, in that the task isintrinsically one of inferring labelled dependencies15between posts, but it has a number of special prop-erties that distinguish it from standard dependencyparsing:strict reverse-chronological directionality: thehead always precedes the dependent, in termsof the chronological sequencing of posts.non-projective dependencies: threads can containnon-projective dependencies, e.g.
in a 4-postthread, posts 2 and 3 may be dependent onpost 1, and post 4 dependent on post 2; around2% of the threads in our dataset contain non-projective dependencies.multi-headedness: it is possible for a given post tohave multiple heads, including the possibilityof multiple dependency links to the same post(e.g.
adding extra information to a question[Question-Add] as well as retracting infor-mation from the original question [Question-Correction]); around 6% of the threads in ourdataset contain multi-headed dependencies.disconnected sub-graphs: it is possible for there tobe disconnected sub-graphs, e.g.
in instanceswhere a user hijacks a thread to ask theirown unrelated question, or submit an unrelatedspam post; around 2% of the threads in ourdataset contain disconnected sub-graphs.The first constraint potentially simplifies depen-dency parsing, and non-projective dependencies arerelatively well understood in the dependency parsingcommunity (Tapanainen and Jarvinen, 1997; Mc-Donald et al, 2005).
Multi-headedness and dis-connected sub-graphs pose greater challenges to de-pendency parsing, although there has been researchdone on both (McDonald and Pereira, 2006; Sagaeand Tsujii, 2008; Eisner and Smith, 2005).
Thecombination of non-projectivity, multi-headednessand disconnected sub-graphs in a single dataset,however, poses a challenge for dependency parsing.In addition to performing evaluation in batchmode over complete threads, we consider the task of?in situ thread classification?, whereby we predictthe discourse structure of a thread after each post.This is intended to simulate the more realistic set-ting of incrementally crawling/updating thread data,but needing to predict discourse structure for partialthreads.
We are interested in determining the rela-tive degradation in accuracy for in situ classificationvs.
batch classification.As our dataset, we use the CNET forum datasetof Kim et al (2010b),1 which contains 1332 an-notated posts spanning 315 threads, collected fromthe Operating System, Software, Hardware and WebDevelopment sub-forums of cnet.2 Each post is la-belled with one or more links (including the possi-bility of null-links, where the post doesn?t link toany other post), and each link is labelled with a di-alogue act.
The dialogue act set is made up of 5super-categories: Question, Answer, Resolution(confirmation of the question being resolved), Re-production (external confirmation of a proposed so-lution working) and Other.
The Question categorycontains 4 sub-classes: Question, Add, Confirma-tion and Correction.
Similarly, the Answer cate-gory contains 5 sub-classes: Answer, Add, Confir-mation, Correction and Objection.
For example,the label Question-Add signifies the Question su-perclass and Add subclass, i.e.
addition of extra in-formation to a question.
For full details of the dia-logue act tagset, see Kim et al (2010b).Dependency links are represented by their relativeposition in the chronologically-sorted list of posts,e.g.
1 indicates a link back to the preceding post,and 2 indicates a link back two posts.Unless otherwise noted, evaluation is over thecombined link and dialogue act tag, including thecombination of superclass and subclass for theQuestion and Answer dialogue acts.
For ex-ample, 1+Answer-Answer indicates a dependencylink back one post, which is an answer to a question.The most common label in the dataset is 1+Answer-answer (28.4%).4 Learners and Features4.1 LearnersTo predict thread discourse structure, we use a struc-tured classification approach ?
based on the find-ings of Kim et al (2010b) and Kim et al (2010a)?
and a dependency parser.
The structured clas-sification approach we experiment with is a linear-1Available from http://www.csse.unimelb.edu.au/research/lt/resources/conll2010-thread/2http://forums.cnet.com/16chain conditional random field learner (CRF: Laf-ferty et al (2001)), within which we explore twosimple approaches to joint classification, as is ex-plained in Section 5.1.
Dependency parsing (Ku?bleret al, 2009) is the task of automatically predictingthe dependency structure of a token sequence, inthe form of binary asymmetric dependency relationswith dependency types.Standardly, CRFs have been applied to tasks suchas part-of-speech tagging, named entity recognition,semantic role labelling and supertagging, where theindividual tokens are single words.
Similarly, de-pendency parsing is conventionally applied to sen-tences, with single-word tokens.
In our case, ourtokens are thread posts, with much greater scope forfeature engineering than single words, and techni-cal challenges in scaling the underlying implemen-tations to handle potentially much larger feature sets.As our learners, we deployed CRFSGD (Bot-tou, 2011) to learn the CRF, and MaltParser (Nivreet al, 2007) as our dependency parser.
CRFSGDuses stochastic gradient descent to efficiently solvethe convex optimisation problem, and scales well tolarge feature sets.
We used the default parameter set-tings for CRFSGD, with feature templates includ-ing all unigram features of the current token as wellas bigram features combining the previous output to-ken with the current token.MaltParser implements transition-based parsing,where no formal grammar is considered, and a tran-sition system, or state machine, is learned to map asentence onto its dependency graph.
One feature ofMaltParser that makes it well suited to our task isthat it is possible to define feature models of arbi-trary complexity for each token.
In presenting thethread data to MaltParser, we represent the null-link from the initial post of each thread, as well asany disconnected posts, as the root.To the best of our knowledge, there is no pastwork on using dependency parsing to learn threaddiscourse structure.
Based on extensive experimen-tation, we determined that the MaltParser configu-ration that obtains the best results for our task is theNivre algorithm in arc-standard mode (Nivre, 2003;Nivre, 2004), using LIBSVM (Chang and Lin, 2011)with a linear kernel as the learner, and a featuremodel with exhaustive combinations of features re-lating to the features and predictions of the first/topthree tokens from both ?Input?
and ?Stack?.3 Assuch, MaltParser is actually unable to predict anynon-projective structures, as experiments with algo-rithms supporting non-projective structures invari-ably led to lower results.
In our choice of parsing al-gorithm, we are also unable to detect posts with mul-tiple heads, but can potentially detect disconnectedsub-graphs.4.2 FeaturesThe features used in our classifiers are as follows:Structural Features:Initiator a binary feature indicating whether thecurrent post?s author is the thread initiator.Position the relative position of the current post,as a ratio over the total number of posts in thethread.Semantic Features:TitSim the relative location of the post which hasthe most similar title (based on unweighted co-sine similarity) to the current post.PostSim the relative location of the post whichhas the most similar content (based on un-weighted cosine similarity) to the current post.Punct the number of question marks (QuCount),exclamation marks (ExCount) and URLs(UrlCount) in the current post.UserProf the class distribution (in the trainingthread) of the author of the current post.These features are drawn largely from the workof Kim et al (2010b), with two major differences:(1) we do not use post context features because ourlearners (i.e.
CRFSGD and MaltParser) inherentlycapture Markov chains; and (2) our UserProf fea-tures are customised to the class set associated withthe task at hand, e.g.
the UserProf features for thestandalone linking task take the form of the link la-bels (and not dialogue act labels) of the posts by therelevant author in the training data.
Table 1 showsthe feature representation of the third post in a thread17Feature Value ExplanationInitiator 1.0 post from the initiatorExCount 4.0 4 exclamation marksQuCount 0.0 0 question marksUrlCount 0.0 0 URLsPosition 0.25 i?1n = 3?18PostSim 2.0 most similar to post 1TitSim 2.0 most similar to post 1UserProf ~x counts for posts of eachclass from the same authorin the training dataTable 1: The feature presentation of the third post in athread of length 8of length 8.
The values of each feature are scaled tothe range [0, 1] before being fed into the learners.We also experimented with other features,including raw bag-of-words lexical features,dimensionality-reduced lexical features (usingprincipal components analysis), and different postsimilarity measures such as longest common subse-quence (LCS) match.
While we were able to obtaingains in isolation, when combined with the otherfeatures, these features had no impact, and are thusnot included in the results presented in this paper.5 Classification MethodologyAll our experiments were carried out based on strati-fied 10-fold cross-validation, stratifying at the threadlevel to ensure that all posts from a given threadoccur in a single fold.
The results are primarilyevaluated using post-level micro-averaged F-score(F?
: ?
= 1), and additionally with thread-level F-score/classification accuracy (i.e.
the proportion ofthreads where all posts have been correctly classi-fied4), where space allows.
Statistical significanceis tested using randomised estimation (Yeh, 2000)with p < 0.05.
Initial experiments showed it ishard for learners to discover which posts have multi-ple links, largely due to the sparsity of multi-headedposts (which account for less than 5% of the totalposts).
Therefore, only the the most recent link for3http://maltparser.org/userguide.html#parsingalg4Classification accuracy = F-score at the thread-level, aseach thread is assigned a single label of correct or incorrect.each multi-headed post was included in training, butevaluation still considers all links.5.1 Joint classificationIn our experiments, we test two basic approaches tojoint classification for the CRF: (1) classifying theLink and DA separately, and composing the predic-tions to form the joint classification (Composition);and (2) combining the Link and DA labels into a sin-gle class, and applying the learner over the postswith the combined class (Combine).
Note thatComposition has the potential for mismatches inthe number of Link and DA predictions it gener-ates, causing complications in the class composition.Even if the same number of labels is predicted forboth Link and DA, if multiple tags are predicted inboth cases, we are left with the problem of determin-ing which link label to combine with which dialogueact label.
As such, we have our reservations aboutComposition, but as the CRF performs strict 1-of-n labelling, these are not issues in the experimentsreported herein.MaltParser natively handles the combination ofLink and DA in its dependency parsing formulation.5.2 In Situ Thread ClassificationOne of the biggest challenges in classifying the dis-course structure of a forum thread is that threadsevolve over time, as new posts are posted.
In or-der to capture this phenomenon, and compare theaccuracy of different models when applied to partialthread data (artificially cutting off a thread at postN ) vs. complete threads.5 This is done in the fol-lowing way: classification over the first two postsonly ([1, 2]), the first four posts ([1, 4]), the first sixposts ([1, 6]), the first eight posts ([1, 8]), and allposts ([all]).
In each case, we limit the test dataonly, meaning that the only variable in play is theextent of thread context used to learn the thread dis-course structure for the given set of posts.
We breakdown the results in each case into the indicated sub-threads, e.g.
we take the predictions for [all], andbreak them down into the results for [1, 2], [1, 4],[1, 6], [1, 8] and [all], for direct comparison with thepredictions over the respective sub-thread data.5In practice, completeness is defined at a given point in time,when the crawl was done, and it is highly likely that some of the?complete?
threads had extra posts after the crawl.18Method Link DAKim et al (2010b) .863 / .676 .751 / .543CRFSGD .891 / .727 .795 / .609Table 2: Post/thread-level component-wise classificationF-scores for Link and DA classes6 Experiments and Analysis6.1 Joint classificationAs our baseline for the task, we first use a sim-ple majority class classifier in the form of the sin-gle joint class of 1+Answer-Answer for all posts,which has a post-level F-score of 0.284.
A strongerbaseline is to classify all first posts as 0+Question-Question and all subsequent posts as 1+Answer-answer, which achieves a post-level F-score of0.515 (labelled as Heuristic).As described in Section 5.1, one approach to jointclassification with CRFSGD is to firstly conductcomponent-wise classification over Link and DAseparately, and compose the predictions.
The resultsfor the separate Link and DA classification tasks arepresented in Table 2, along with the best results forLink and DA classification from Kim et al (2010b).At the component-wise tasks, our method is superiorto Kim et al (2010b), based on a different learnerand slightly different feature set.Next, we compose the component-wise clas-sifications for the CRF into joint classifications(Composition).
We contrast this with the com-bined class approach for CRFSGD and MaltParser(jointly presented as Joint in Table 3).
With thecombined class results, we additionally ablate eachof the feature types from Section 4.2, and alsopresent results for a dummy model, where no fea-tures are provided and the prediction is based simplyon sequential priors (Dummy).
The results are pre-sented in Table 3, along with the Heuristic baselineresult.Several interesting things can be observed fromthe post-level F-score results in Table 3.
First, withno features (Dummy), while CRFSGD performsslightly worse than the Heuristic baseline, Malt-Parser significantly surpasses the baseline.
This isdue to the richer sequential context model of Malt-Parser.
Second, the single feature with the greatestimpact on results is UserProf, i.e.
user profile fea-Method CRFSGD MaltParserHeuristic .515?/ .311?Dummy .508?/ .394?
.533?/ .356?Composition .728?/ .553?
?Joint +ALL .756 / .578 .738 / .578?Initiator .745 / .569 .708?/ .534?
?Position .750 / .565 .736 / .568?PostSim .753 / .578 .737 / .568?TitSim .760 / .587 .734 / .571?Punct .745 / .571 .735 / .578?UserProf .672?/ .527?
.701?/ .536?Table 3: Post/thread-level Link-DA joint classification F-scores (???
signifies a significantly worse result than thatfor the same learner with ALL features)tures extracted from the training data; CRFSGD inparticular benefits from this feature.
We return to ex-plore this effect in Section 6.4.
Third, although theInitiator feature does not have much effect on CRF-SGD, it affects the performance of MaltParser sig-nificantly.
Further experiments shown that the com-bination of Initiator and UserProf is sufficient toachieve a competitive result (i.e.
0.731).
It thereforeseems that MaltParser is more robust than CRF-SGD, whose performance relies crucially on user-level features which must be learned from the train-ing data (i.e.
UserProf).Looking to the thread-level F-scores, we observesome interesting divergences from the post-level F-score results.
First, with no features (Dummy),CRFSGD significantly outperforms both the base-line and MaltParser.
This appears to be becauseCRFSGD performs particularly well over shortthreads (e.g.
of length 3 and 4), but worse overlonger threads.
Second, the best thread-level F-scores from CRFSGD (i.e.
0.587) and MaltParser(i.e.
0.578) are not significantly different, despite thediscrepancy in post-level F-score (where CRFSGDis markedly superior in this case).
With the extrafeatures, the performance of MaltParser on shortthreads appears to pick up noticeably, and the differ-ence in post-level predictions is over longer threads.If we evaluate the two models over DA super-classes only (ignoring mismatches at the subclasslevel for Question and Answer), the post-level F-scores for joint classification with ALL features forCRFSGD and MaltParser are 0.803 and 0.787, re-spectively.19Approaches Link DAComponent-wise .891 / .727?
.795 / .609CRFSGD decomp .893 / .749 .785 / .603MaltParser decomp .870?/ .730?
.766?/ .571?Table 4: Post/thread-level Link and DA F-scores fromcomponent-wise classification, and from Link-DA clas-sification decomposition (???
signifies a significantlyworse result than the best result in that column)Looking at the performance of CRFSGD (inCombine mode) and MaltParser on disconnectedsub-graphs, while both models did predict a smallnumber of non-initial posts with null-links (includ-ing MaltParser predicting 5 out of 6 posts in a sin-gle thread as having null-links), none were correct,and neither model was able to correctly predict anyof the 6 actual non-initial instances of null-links inthe dataset.Finally, we took the joint classification resultsfrom CRFSGD and MaltParser using ALL fea-tures, and decomposed the predictions into Link andDA.
The results are presented in Table 4, along withthe results for component-wise classification fromTable 2.
Somewhat surprisingly, the decomposedpredictions are mostly slightly worse than the re-sults for the component-wise classification, despiteachieving higher F-score for the joint classificationtask.
This is simply due to the combined methodtending to get both labels correct or both labelswrong, for a given post.6.2 Post Position-based Result BreakdownOne question in thread discourse structure classifica-tion is how accurate the predictions are at differentdepths in a thread (e.g.
the first two posts vs. the sec-ond two posts).
A breakdown of results across postsat different positions is presented in Figure 2.The overall trend for both CRFSGD and Malt-Parser is that it becomes increasingly hard to clas-sify posts as we continue through a thread, due togreater variability in discourse structure and greatersparsity in the data.
However, it is interesting to notethat the results for CRFSGD actually improve fromposts 7 and 8 ([7, 8]) to posts 9 and onwards ([9, ]).To further investigate this effect, we performed classdecomposition over the joint classification predic-tions, and performed a similar breakdown of posts[1,2] [3,4] [5,6] [7,8] [9,] All00.10.20.30.40.50.60.70.80.91PostsF ?CRFSGDMaltParserFigure 2: Breakdown of post-level Link-DA results forCRFSGD and MaltParser based on post position[1,2] [3,4] [5,6] [7,8] [9,] All00.51PostsF ?Decomposed LinkCRFSGDMaltParser[1,2] [3,4] [5,6] [7,8] [9,] All00.51PostsF ?Decomposed DACRFSGDMaltParserFigure 3: Breakdown of post-level Link and DA F-scorebased on the decomposition of CRFSGD and Malt-Parser classificationsfor Link and DA; the results are presented in Fig-ure 3.
It is clear that the anomaly for CRFSGDcomes from the DA component, due to there beinggreater predictability in the dialogue for final postsin a thread (users tend to confirm a successful reso-lution of the problem, or report on successful exter-nal reproduction of the solution).
MaltParser seemsless adept at identifying that a post is at the endof a thread, and predicting the dialogue act accord-ingly.
This observation is congruous with the find-ings of McDonald and Nivre (2007) that errors prop-agate, due to MaltParser?s greedy inference strat-egy.
The higher results for Link are to be expected,as throughout the thread, most posts tend to link lo-cally.20XXXXXXXXXTestB/down [1, 2] [1, 4] [1, 6] [1, 8] [All][1, 2] .947/.947 ?
?
?
?
[1, 4] .946/.947 .836/.841 ?
?
[1, 6] .946/.947 .840/.841 .800/.794 ?
?
[1, 8] .946/.947 .840/.841 .800/.794 .780/.769 ?
[All] .946/.946 .840/.838 .800/.791 .776/.767 .756/.738Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads ofdifferent lengths (indicated in the rows), broken down over different post extents (indicated in the columns)6.3 In Situ Structure PredictionAs described in Section 5.2, we simulate in situthread discourse structure prediction by removingdiffering numbers of posts from the tail of the thread,and applying the trained model over the resultantsub-threads.
The results for in situ classification arepresented in Table 5, with the rows indicating thesize of the test sub-thread, and the columns being abreakdown of results over different portions of theclassified thread.
The reason that we do not pro-vide numbers for all cells in the table is that the sizeof the test sub-thread determines the post extents wecan breakdown the results into, e.g.
we cannot returnresults for posts 1?4 ([1, 4]) when the size of the testthread was only two posts ([1, 2]).From the results, we can see that both CRFSGDand MaltParser are very robust when applied to par-tial threads, to the extent that we actually achievehigher results over shortened versions of the threadthan over the complete thread in some instances, al-though the only difference that is statistically signif-icant is over [1, 8] for CRFSGD, where the predic-tion over the partial thread is actually superior to thatover the complete thread.
From this, we can con-clude that it is possible to apply our method to partialthreads without any reduction in effectiveness rela-tive to classification over complete threads.
As such,our method is shown to be robust when applied toreal-time analysis of dynamically evolving threads.6.4 User profile feature analysisIn our experiments, we noticed that the user profilefeature (UserProf) is the most effective feature forboth CRFSGD and MaltParser.
To gain a deeperinsight into the behaviour of the feature, we binnedthe posts according to the number of times the authorhad posted in the training data, evaluated based on aBin uscore Posts Total Totalper user users postsHigh 224.6 251 1 251Medium 1?41.7 4?48 45 395Low 0 2?4 157 377Very Low 0 1 309 309Table 6: Statistics for the 4 groups of usersuser score (uscore) for each user:uscorei =?nij=1 spi,jniwhere ni is the number of posts by user i, and spi,j isthe number of posts by user i that occur as traininginstances for other posts by the same author.
uscorereflects the average training?test post ratio per userin cross-validation.
Note that as we include all postsfrom a given thread in a single partition during cross-validation, it is possible for an author to have posted4 times, but have a uscore of 0 due to those posts alloccurring in the same thread.We ranked the users in the dataset in descendingorder of uscore, sub-ranking on ni in cases of a tiein uscore.
The users were binned into 4 groupsof roughly equal post size.
The detailed statisticsare shown in Table 6, noting that the high-frequencybin (?High?)
contains posts from a single user.
Wepresent the post-level micro-averaged F-score forposts in each bin based on CRFSGD, with and with-out user profile features, in Figure 4.Contrary to expectation, the UserProf featureshave the greatest impact for users with fewer posts.In fact, a statistically significant difference was ob-served only for users with no posts in the trainingdata (uscore = 0), where the F-score jumped over10% in absolute terms for both the Low and VeryLow bins.
Our explanation for this effect is that the21High Median Low Very Low00.10.20.30.40.50.60.70.80.91User GroupF ?With UserProfWithout UserProfFigure 4: Post-level joint classification results for usersbinned by uscore, based on CRFSGD with and withoutUserProf features)lack of user profile information is predictive of thesort of posts we can expect from a user (i.e.
theytend to be newbie users, asking questions).7 Conclusions and Future WorkIn this research, we explored the joint classificationof web user forum thread discourse structure, in theform of a rooted directed acyclic graph over posts,with edges labelled with dialogue acts.
Three classi-fication approaches were proposed: separately pre-dicting Link and DA labels, and composing theminto a joint class; predicting a combined Link-DAclass using a structured classifier; and applying de-pendency parsing to the problem.
We found thecombined approach based on CRFSGD to performbest over the task, closely followed by dependencyparsing with MaltParser.We also examined the task of in situ classificationof dialogue structure, in the form of predicting thediscourse structure of partial threads, as contrastedwith classifying only complete threads.
We foundthat there was no drop in F-score over different sub-extents of the thread in classifying partial threads,despite the relative lack of thread context.In future work, we plan to delve further into de-pendency parsing, looking specifically at the impli-cations of multi-headedness and disconnected sub-graphs on dependency parsing.
We also intend tocarry out meta-classification, combining the predic-tions of CRFSGD and MaltParser.Our user profile features were found to be thepick of our features, but counter-intuitively, to bene-fit users with no posts in the training data, rather thanprolific users.
We wish to explore this effect further,including incorporating unsupervised user-level fea-tures into our classifiers.AcknowledgementsThe authors wish to acknowledge the developmentefforts of Johan Hall in configuring MaltParser tohandle numeric features, and be able to parse threadstructures.
NICTA is funded by the Australian gov-ernment as represented by Department of Broad-band, Communication and Digital Economy, and theAustralian Research Council through the ICT Centreof Excellence programme.ReferencesLe?on Bottou.
2011.
CRFSGD software.
http://leon.bottou.org/projects/sgd.Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, andCe Zhang.
2009.
The use of categorization infor-mation in language models for question retrieval.
InProceedings of the 18th ACM Conference on Informa-tion and Knowledge Management (CIKM 2009), pages265?274, Hong Kong, China.Vitor R. Carvalho and William W. Cohen.
2005.
Onthe collective classification of email ?speech acts?.
InProceedings of 28th International ACM-SIGIR Con-ference on Research and Development in InformationRetrieval (SIGIR 2005), pages 345?352.Jeffrey Chan and Conor Hayes.
2010.
Decomposing dis-cussion forums using user roles.
In Proceedings of theWebSci10: Extending the Frontiers of Society On-Line(WebSci10), pages 1?8, Raleigh, USA.Jeffrey Chan, Conor Hayes, and Elizabeth M. Daly.2010.
Decomposing discussion forums using userroles.
In Proceedings of the Fourth International AAAIConference on Weblogs and Social Media (ICWSM2010), pages 215?8, Washington, USA.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technology,2(3):27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.William W. Cohen, Vitor R. Carvalho, and Tom M.Mitchell.
2004.
Learning to classify email into?speech acts?.
In Proceedings of the 2004 Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP 2004), pages 309?316, Barcelona, Spain.Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song,and Yueheng Sun.
2008.
Finding question-answer22pairs from online forums.
In Proceedings of 31st Inter-national ACM-SIGIR Conference on Research and De-velopment in Information Retrieval (SIGIR?08), pages467?474, Singapore.Daniel Dahlmeier, Hwee Tou Ng, and Tanja Schultz.2009.
Joint learning of preposition senses and seman-tic roles of prepositional phrases.
In Proceedings ofthe 2009 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP 2009), pages 450?458,Singapore.
Association for Computational Linguistics.Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu.2008.
Using conditional random fields to extract con-text and answers of questions from online forums.
InProceedings of the 46th Annual Meeting of the ACL:HLT (ACL 2008), pages 710?718, Columbus, USA.Jason Eisner and Noah A. Smith.
2005.
Parsing with softand hard constraints on dependency length.
In Pro-ceedings of the Ninth International Workshop on Pars-ing Technology, pages 30?41, Vancouver, Canada.Jonathan L. Elsas and Jaime G. Carbonell.
2009.
Itpays to be picky: An evaluation of thread retrievalin online forums.
In Proceedings of 32nd Interna-tional ACM-SIGIR Conference on Research and De-velopment in Information Retrieval (SIGIR?09), pages714?715, Boston, USA.Micha Elsner and Eugene Charniak.
2008.
You talk-ing to me?
a corpus and algorithm for conversationdisentanglement.
In Proceedings of the 46th AnnualMeeting of the ACL: HLT (ACL 2008), pages 834?842,Columbus, USA.Jenny Rose Finkel and Christopher D. Manning.
2009.Joint parsing and named entity recognition.
In Pro-ceedings of Human Language Technologies: The 2009Annual Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL HLT 2009), pages 326?334, Boulder, Col-orado.
Association for Computational Linguistics.Blaz Fortuna, Eduarda Mendes Rodrigues, and NatasaMilic-Frayling.
2007.
Improving the classification ofnewsgroup messages through social network analysis.In Proceedings of the 16th ACM Conference on In-formation and Knowledge Management (CIKM 2007),pages 877?880, Lisbon, Portugal.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intention and the structure of discourse.
Compu-tational Linguistics, 12(3):175?204.Edward Ivanovic.
2008.
Automatic instant messagingdialogue using statistical models and dialogue acts.Master?s thesis, University of Melbourne.Su Nam Kim, Lawrence Cavedon, and Timothy Bald-win.
2010a.
Classifying dialogue acts in one-on-onelive chats.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing(EMNLP 2010), pages 862?871, Boston, USA.Su Nam Kim, Li Wang, and Timothy Baldwin.
2010b.Tagging and linking web forum posts.
In Proceedingsof the 14th Conference on Computational Natural Lan-guage Learning (CoNLL-2010), pages 192?202, Upp-sala, Sweden.Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.2009.
Dependency parsing.
Synthesis Lectures on Hu-man Language Technologies, 2(1):1?127.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.
In Pro-ceedings of the 18th International Conference on Ma-chine Learning, pages 282?289, Williamstown, USA.Andrew Lampert, Robert Dale, and Ce?cile Paris.
2008.The nature of requests and commitments in email mes-sages.
In Proceedings of the AAAI 2008 Workshop onEnhanced Messaging, pages 42?47, Chicago, USA.Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, An-nie Skariah, Jian Yang, and Graciela Gonzalez.
2010.Towards internet-age pharmacovigilance: Extractingadverse drug reactions from user posts in health-related social networks.
In Proceedings of the 2010Workshop on Biomedical Natural Language Process-ing (ACL 2010), pages 117?125, Uppsala, Sweden.Oliver Lemon, Alex Gruenstein, and Stanley Peters.2002.
Collaborative activities and multi-tasking in di-alogue systems.
Traitement Automatique des Langues(TAL), Special Issue on Dialogue, 43(2):131?154.Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang,Wei Wang, and Lei Zhang.
2009.
Modeling semanticsand structure of discussion threads.
In Proceedings ofthe 18th International Conference on the World WideWeb (WWW 2009), pages 1103?1104, Madrid, Spain.Marco Lui and Timothy Baldwin.
2009.
You are whatyou post: User-level features in threaded discourse.
InProceedings of the 14th Australasian Document Com-puting Symposium (ADCS 2009), Sydney, Australia.Marco Lui and Timothy Baldwin.
2010.
Classifyinguser forum participants: Separating the gurus from thehacks, and other tales of the internet.
In Proceedingsof the 2010 Australasian Language Technology Work-shop (ALTW 2010), pages 49?57, Melbourne, Aus-tralia.Ryan McDonald and Joakim Nivre.
2007.
Charac-terizing the errors of data-driven dependency parsingmodels.
In Proceedings of the 2007 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing (EMNLP-CoNLL 2007), pages 122?131, Prague,Czech Republic.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proceedings of the 11th Conference of23the European Chapter of the Association for Computa-tional Linguistics (EACL 2006), pages 81?88, Trento,Italy.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedings ofHuman Language Technology Conference and Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 523?530, Vancouver, Canada.Gabriel Murray, Steve Renals, Jean Carletta, and JohannaMoore.
2006.
Incorporating speaker and discoursefeatures into speech summarization.
In Proceedingsof the Main Conference on Human Language Technol-ogy Conference of the North American Chapter of theAssociation of Computational Linguistics, pages 367?374.Klemens Muthmann, Wojciech M. Barczyn?ski, FalkBrauer, and Alexander Lo?ser.
2009.
Near-duplicatedetection for web-forums.
In Proceedings of the 2009International Database Engineering & ApplicationsSymposium (IDEAS 2009), pages 142?151, Cetraro,Italy.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,and Erwin Marsi.
2007.
MaltParser: A language-independent system for data-driven dependency pars-ing.
Natural Language Engineering, 13(02):95?135.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies (IWPT03), pages 149?160, Nancy, France.Joakim Nivre.
2004.
Incrementality in determinis-tic dependency parsing.
In Proceedings of the ACLWorkshop Incremental Parsing: Bringing Engineer-ing and Cognition Together (ACL-2004), pages 50?57,Barcelona, Spain.Carolyn Penstein Rose?, Barbara Di Eugenio, Lori S.Levin, and Carol Van Ess-Dykema.
1995.
Discourseprocessing of dialogues with multiple threads.
In Pro-ceedings of the 33rd Annual Meeting of the Asso-ciation for Computational Linguistics, pages 31?38,Cambridge, USA.Kenji Sagae and Jun?ichi Tsujii.
2008.
Shift-reducedependency DAG parsing.
In Proceedings of the22nd International Conference on Computational Lin-guistics (COLING 2008), pages 753?760, Manchester,UK.Kenji Sagae.
2009.
Analysis of discourse structure withsyntactic dependencies and data-driven shift-reduceparsing.
In Proceedings of the 11th International Con-ference on Parsing Technologies (IWPT-09), pages 81?84, Paris, France.Anne Schuth, Maarten Marx, and Maarten de Rijke.2007.
Extracting the discussion structure in commentson news-articles.
In Proceedings of the 9th AnnualACM International Workshop on Web Information andData Management, pages 97?104, Lisboa, Portugal.Jangwon Seo, W. Bruce Croft, and David A. Smith.2009.
Online community search using thread struc-ture.
In Proceedings of the 18th ACM Conferenceon Information and Knowledge Management (CIKM2009), pages 1907?1910, Hong Kong, China.Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat, JeremyAng, and Hannah Carvey.
2004.
The ICSI meetingrecorder dialog act (MRDA) corpus.
In Proceedings ofthe 5th SIGdial Workshop on Discourse and Dialogue,pages 97?100, Cambridge, USA.Parikshit Sondhi, Manish Gupta, ChengXiang Zhai, andJulia Hockenmaier.
2010.
Shallow information ex-traction from medical forum data.
In Proceedings ofthe 23rd International Conference on ComputationalLinguistics (COLING 2010), Posters Volume, pages1158?1166, Beijing, China.Radu Soricut and Daniel Marcu.
2003.
Sentence leveldiscourse parsing using syntactic and lexical infor-mation.
In Proceedings of the 2003 Human Lan-guage Technology Conference of the North AmericanChapter of the Association for Computational Linguis-tics (HLT-NAACL 2003), pages 149?156, Edmonton,Canada.Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-beth Shriberg, Rebecca Bates, Daniel Jurafsky, PailTaylor, Rachel Martin, Carol Van Ess-Dykema, andMarie Meteer.
2000.
Dialogue act modeling forautomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26(3):339?373.Charles Sutton and Andrew McCallum.
2005.
Jointparsing and semantic role labeling.
In Proceedings ofthe Ninth Conference on Computational Natural Lan-guage Learning (CoNLL-2005), pages 225?228, AnnArbor, Michigan.
Association for Computational Lin-guistics.Pasi Tapanainen and Timo Jarvinen.
1997.
A non-projective dependency parser.
In Proceedings of theFifth Conference on Applied Natural Language Pro-cessing, pages 64?71, Washington, USA.Nayer Wanas, Motaz El-Saban, Heba Ashour, andWaleed Ammar.
2008.
Automatic scoring of onlinediscussion posts.
In Proceeding of the 2nd ACM work-shop on Information credibility on the web (WICOW?08), pages 19?26, Napa Valley, USA.Yi-Chia Wang and Carolyn P. Rose?.
2010.
Mak-ing conversational structure explicit: identification ofinitiation-response pairs within online discussions.
InHuman Language Technologies: The 2010 AnnualConference of the North American Chapter of the As-sociation for Computational Linguistics (NAACL HLT2010), pages 673?676.24Yi-Chia Wang, Mahesh Joshi, and Carolyn Rose?.
2007.A feature based approach to leveraging context forclassifying newsgroup style discussion segments.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics CompanionVolume Proceedings of the Demo and Poster Sessions(ACL 2007), pages 73?76, Prague, Czech Republic.Yi-Chia Wang, Mahesh Joshi, William W. Cohen, andCarolyn Rose?.
2008.
Recovering implicit threadstructure in newsgroup style conversations.
In Pro-ceedings of the Second International Conference onWeblogs and Social Media (ICWSM 2008), pages 152?160, Seattle, USA.V.
Warnke, R. Kompe, H. Niemann, and E. No?th.
1997.Integrated dialog act segmentation and classificationusing prosodic features and language models.
In Proc.Eurospeech, volume 1, pages 207?210.Markus Weimer and Iryna Gurevych.
2007.
Predictingthe perceived quality of web forum posts.
In Proceed-ings of the 2007 International Conference on RecentAdvances in Natural Language Processing (RANLP2007), pages 643?648, Borovets, Bulgaria.Markus Weimer, Iryna Gurevych, and Max Mu?hlha?user.2007.
Automatically assessing the post quality in on-line discussions on software.
In Proceedings of the45th Annual Meeting of the ACL: Interactive Posterand Demonstration Sessions, pages 125?128, Prague,Czech Republic.Armin Weinberger and Frank Fischer.
2006.
Aframework to analyze argumentative knowledge con-struction in computer-supported collaborative learn-ing.
Computers & Education, 46:71?95, January.Florian Wolf and Edward Gibson.
2005.
Representingdiscourse coherence: A corpus-based study.
Compu-tational Linguistics, 31(2):249?287.Wensi Xi, Jesper Lind, and Eric Brill.
2004.
Learningeffective ranking functions for newsgroup search.
InProceedings of 27th International ACM-SIGIR Con-ference on Research and Development in Informa-tion Retrieval (SIGIR 2004), pages 394?401.
Sheffield,UK.Alexander Yeh.
2000.
More accurate tests for the sta-tistical significance of result differences.
In Proceed-ings of the 18th International Conference on Compu-tational Linguistics (COLING 2000), pages 947?953,Saarbru?cken, Germany.25
