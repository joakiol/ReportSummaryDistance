Proceedings of the 43rd Annual Meeting of the ACL, pages 18?25,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsLogarithmic Opinion Pools for Conditional Random FieldsAndrew SmithDivision of InformaticsUniversity of EdinburghUnited Kingdoma.p.smith-2@sms.ed.ac.ukTrevor CohnDepartment of Computer Scienceand Software EngineeringUniversity of Melbourne, Australiatacohn@csse.unimelb.edu.auMiles OsborneDivision of InformaticsUniversity of EdinburghUnited Kingdommiles@inf.ed.ac.ukAbstractRecent work on Conditional RandomFields (CRFs) has demonstrated the needfor regularisation to counter the tendencyof these models to overfit.
The standardapproach to regularising CRFs involves aprior distribution over the model parame-ters, typically requiring search over a hy-perparameter space.
In this paper we ad-dress the overfitting problem from a dif-ferent perspective, by factoring the CRFdistribution into a weighted product of in-dividual ?expert?
CRF distributions.
Wecall this model a logarithmic opinionpool (LOP) of CRFs (LOP-CRFs).
We ap-ply the LOP-CRF to two sequencing tasks.Our results show that unregularised expertCRFs with an unregularised CRF undera LOP can outperform the unregularisedCRF, and attain a performance level closeto the regularised CRF.
LOP-CRFs there-fore provide a viable alternative to CRFregularisation without the need for hyper-parameter search.1 IntroductionIn recent years, conditional random fields (CRFs)(Lafferty et al, 2001) have shown success on a num-ber of natural language processing (NLP) tasks, in-cluding shallow parsing (Sha and Pereira, 2003),named entity recognition (McCallum and Li, 2003)and information extraction from research papers(Peng and McCallum, 2004).
In general, this workhas demonstrated the susceptibility of CRFs to over-fit the training data during parameter estimation.
Asa consequence, it is now standard to use some formof overfitting reduction in CRF training.Recently, there have been a number of sophisti-cated approaches to reducing overfitting in CRFs,including automatic feature induction (McCallum,2003) and a full Bayesian approach to training andinference (Qi et al, 2005).
These advanced meth-ods tend to be difficult to implement and are of-ten computationally expensive.
Consequently, dueto its ease of implementation, the current standardapproach to reducing overfitting in CRFs is the useof a prior distribution over the model parameters,typically a Gaussian.
The disadvantage with thismethod, however, is that it requires adjusting thevalue of one or more of the distribution?s hyper-parameters.
This usually involves manual or auto-matic tuning on a development set, and can be an ex-pensive process as the CRF must be retrained manytimes for different hyperparameter values.In this paper we address the overfitting problemin CRFs from a different perspective.
We factor theCRF distribution into a weighted product of indi-vidual expert CRF distributions, each focusing ona particular subset of the distribution.
We call thismodel a logarithmic opinion pool (LOP) of CRFs(LOP-CRFs), and provide a procedure for learningthe weight of each expert in the product.
The LOP-CRF framework is ?parameter-free?
in the sense thatit does not involve the requirement to adjust hyper-parameter values.LOP-CRFs are theoretically advantageous in thattheir Kullback-Leibler divergence with a given dis-tribution can be explicitly represented as a functionof the KL-divergence with each of their expert dis-tributions.
This provides a well-founded frameworkfor designing new overfitting reduction schemes:18look to factorise a CRF distribution as a set of di-verse experts.We apply LOP-CRFs to two sequencing tasks inNLP: named entity recognition and part-of-speechtagging.
Our results show that combination of un-regularised expert CRFs with an unregularised stan-dard CRF under a LOP can outperform the unreg-ularised standard CRF, and attain a performancelevel that rivals that of the regularised standard CRF.LOP-CRFs therefore provide a viable alternative toCRF regularisation without the need for hyperpa-rameter search.2 Conditional Random FieldsA linear chain CRF defines the conditional probabil-ity of a state or label sequence s given an observedsequence o via1:p(s |o) = 1Z(o) exp(T+1?t=1?k?k fk(st?1,st ,o, t))(1)where T is the length of both sequences, ?k are pa-rameters of the model and Z(o) is the partition func-tion that ensures (1) represents a probability distri-bution.
The functions fk are feature functions rep-resenting the occurrence of different events in thesequences s and o.The parameters ?k can be estimated by maximis-ing the conditional log-likelihood of a set of labelledtraining sequences.
The log-likelihood is given by:L (? )
= ?o,sp?
(o,s) log p(s |o;?
)= ?o,sp?(o,s)[T+1?t=1?
?
f(s,o, t)]?
?op?
(o) logZ(o;?
)where p?
(o,s) and p?
(o) are empirical distributionsdefined by the training set.
At the maximum like-lihood solution the model satisfies a set of featureconstraints, whereby the expected count of each fea-ture under the model is equal to its empirical counton the training data:1In this paper we assume there is a one-to-one mapping be-tween states and labels, though this need not be the case.Ep?
(o,s)[ fk]?Ep(s|o)[ fk] = 0, ?kIn general this cannot be solved for the ?k inclosed form so numerical routines must be used.Malouf (2002) and Sha and Pereira (2003) showthat gradient-based algorithms, particularly limitedmemory variable metric (LMVM), require muchless time to reach convergence, for some NLP tasks,than the iterative scaling methods (Della Pietra etal., 1997) previously used for log-linear optimisa-tion problems.
In all our experiments we use theLMVM method to train the CRFs.For CRFs with general graphical structure, calcu-lation of Ep(s|o)[ fk] is intractable, but for the linearchain case Lafferty et al (2001) describe an efficientdynamic programming procedure for inference, sim-ilar in nature to the forward-backward algorithm inhidden Markov models.3 Logarithmic Opinion PoolsIn this paper an expert model refers a probabilisticmodel that focuses on modelling a specific subset ofsome probability distribution.
The concept of com-bining the distributions of a set of expert models viaa weighted product has previously been used in arange of different application areas, including eco-nomics and management science (Bordley, 1982),and NLP (Osborne and Baldridge, 2004).In this paper we restrict ourselves to sequencemodels.
Given a set of sequence model experts, in-dexed by ?
, with conditional distributions p?
(s |o)and a set of non-negative normalised weights w?
, alogarithmic opinion pool 2 is defined as the distri-bution:pLOP(s |o) = 1ZLOP(o) ??
[p?
(s |o)]w?
(2)with w?
?
0 and ??
w?
= 1, and where ZLOP(o) isthe normalisation constant:ZLOP(o) = ?s??
[p?
(s |o)]w?
(3)2Hinton (1999) introduced a variant of the LOP idea calledProduct of Experts, in which expert distributions are multipliedunder a uniform weight distribution.19The weight w?
encodes our confidence in the opin-ion of expert ?
.Suppose that there is a ?true?
conditional distri-bution q(s | o) which each p?
(s | o) is attempting tomodel.
Heskes (1998) shows that the KL divergencebetween q(s | o) and the LOP, can be decomposedinto two terms:K(q, pLOP) = E ?A (4)= ?
?w?K (q, p?)??
?w?K (pLOP, p?
)This tells us that the closeness of the LOP modelto q(s | o) is governed by a trade-off between twoterms: an E term, which represents the closenessof the individual experts to q(s | o), and an A term,which represents the closeness of the individualexperts to the LOP, and therefore indirectly to eachother.
Hence for the LOP to model q well, we desiremodels p?
which are individually good models of q(having low E) and are also diverse (having large A).3.1 LOPs for CRFsBecause CRFs are log-linear models, we can seefrom equation (2) that CRF experts are particularlywell suited to combination under a LOP.
Indeed, theresulting LOP is itself a CRF, the LOP-CRF, withpotential functions given by a log-linear combina-tion of the potential functions of the experts, withweights w?
.
As a consequence of this, the nor-malisation constant for the LOP-CRF can be calcu-lated efficiently via the usual forward-backward al-gorithm for CRFs.
Note that there is a distinction be-tween normalisation constant for the LOP-CRF, ZLOPas given in equation (3), and the partition function ofthe LOP-CRF, Z.
The two are related as follows:pLOP(s |o) = 1ZLOP(o) ??
[p?
(s |o)]w?= 1ZLOP(o) ??[U?
(s |o)Z?
(o)]w?= ??
[U?
(s |o)]w?ZLOP(o)??
[Z?
(o)]w?where U?
= exp?T+1t=1 ?k ?
?k f?k(st?1,st ,o, t) and sologZ(o) = logZLOP(o)+??w?
logZ?
(o)This relationship will be useful below, when we de-scribe how to train the weights w?
of a LOP-CRF.In this paper we will use the term LOP-CRFweights to refer to the weights w?
in the weightedproduct of the LOP-CRF distribution and the termparameters to refer to the parameters ?
?k of eachexpert CRF ?
.3.2 Training LOP-CRFsIn our LOP-CRF training procedure we first trainthe expert CRFs unregularised on the training data.Then, treating the experts as static pre-trained mod-els, we train the LOP-CRF weights w?
to maximisethe log-likelihood of the training data.
This trainingprocess is ?parameter-free?
in that neither stage in-volves the use of a prior distribution over expert CRFparameters or LOP-CRF weights, and so avoids therequirement to adjust hyperparameter values.The likelihood of a data set under a LOP-CRF, asa function of the LOP-CRF weights, is given by:L(w) = ?o,spLOP(s |o;w) p?
(o,s)= ?o,s[ 1ZLOP(o;w) ??
p?
(s |o)w?]p?
(o,s)After taking logs and rearranging, the log-likelihood can be expressed as:L (w) = ?o,sp?(o,s)??w?
log p?
(s |o)?
?op?
(o) logZLOP(o;w)= ??w?
?o,sp?
(o,s) log p?
(s |o)+ ??w?
?op?
(o) logZ?(o)?
?op?
(o) logZ(o;w)For the first two terms, the quantities that are mul-tiplied by w?
inside the (outer) sums are indepen-dent of the weights, and can be evaluated once at the20beginning of training.
The third term involves thepartition function for the LOP-CRF and so is a func-tion of the weights.
It can be evaluated efficiently asusual for a standard CRF.Taking derivatives with respect to w?
and rear-ranging, we obtain:?L (w)?w?
= ?o,s p?
(o,s) log p?
(s |o)+ ?op?
(o) logZ?
(o)?
?op?(o)EpLOP(s|o)[?tlogU?
t(o,s)]where U?
t(o,s) is the value of the potential functionfor expert ?
on clique t under the labelling s for ob-servation o.
In a way similar to the representationof the expected feature count in a standard CRF, thethird term may be re-written as:??o?t?s?,s?
?pLOP(st?1 = s?,st = s?
?,o) logU?
t(s?,s?
?,o)Hence the derivative is tractable because we can usedynamic programming to efficiently calculate thepairwise marginal distribution for the LOP-CRF.Using these expressions we can efficiently trainthe LOP-CRF weights to maximise the log-likelihood of the data set.3 We make use of theLMVM method mentioned earlier to do this.
Wewill refer to a LOP-CRF with weights trained usingthis procedure as an unregularised LOP-CRF.3.2.1 RegularisationThe ?parameter-free?
aspect of the training pro-cedure we introduced in the previous section relieson the fact that we do not use regularisation whentraining the LOP-CRF weights w?
.
However, thereis a possibility that this may lead to overfitting ofthe training data.
In order to investigate this, wedevelop a regularised version of the training proce-dure and compare the results obtained with each.
We3We must ensure that the weights are non-negative and nor-malised.
We achieve this by parameterising the weights as func-tions of a set of unconstrained variables via a softmax transfor-mation.
The values of the log-likelihood and its derivatives withrespect to the unconstrained variables can be derived from thecorresponding values for the weights w?
.use a prior distribution over the LOP-CRF weights.As the weights are non-negative and normalised weuse a Dirichlet distribution, whose density functionis given by:p(w) = ?(??
??)??
?(??)
??
w??
?1?where the ??
are hyperparameters.Under this distribution, ignoring terms that areindependent of the weights, the regularised log-likelihood involves an additional term:??(??
?1) logw?We assume a single value ?
across all weights.
Thederivative of the regularised log-likelihood withrespect to weight w?
then involves an additionalterm 1w?
(?
?
1).
In our experiments we use thedevelopment set to optimise the value of ?
.
We willrefer to a LOP-CRF with weights trained using thisprocedure as a regularised LOP-CRF.4 The TasksIn this paper we apply LOP-CRFs to two sequencelabelling tasks in NLP: named entity recognition(NER) and part-of-speech tagging (POS tagging).4.1 Named Entity RecognitionNER involves the identification of the location andtype of pre-defined entities within a sentence and isoften used as a sub-process in information extrac-tion systems.
With NER the CRF is presented witha set of sentences and must label each word so as toindicate whether the word appears outside an entity(O), at the beginning of an entity of type X (B-X) orwithin the continuation of an entity of type X (I-X).All our results for NER are reported on theCoNLL-2003 shared task dataset (Tjong Kim Sangand De Meulder, 2003).
For this dataset the en-tity types are: persons (PER), locations (LOC),organisations (ORG) and miscellaneous (MISC).The training set consists of 14,987 sentences and204,567 tokens, the development set consists of3,466 sentences and 51,578 tokens and the test setconsists of 3,684 sentences and 46,666 tokens.214.2 Part-of-Speech TaggingPOS tagging involves labelling each word in a sen-tence with its part-of-speech, for example noun,verb, adjective, etc.
For our experiments we use theCoNLL-2000 shared task dataset (Tjong Kim Sangand Buchholz, 2000).
This has 48 different POStags.
In order to make training time manageable4,we collapse the number of POS tags from 48 to 5following the procedure used in (McCallum et al,2003).
In summary:?
All types of noun collapse to category N.?
All types of verb collapse to category V.?
All types of adjective collapse to category J.?
All types of adverb collapse to category R.?
All other POS tags collapse to category O.The training set consists of 7,300 sentences and173,542 tokens, the development set consists of1,636 sentences and 38,185 tokens and the test setconsists of 2,012 sentences and 47,377 tokens.4.3 Expert setsFor each task we compare the performance of theLOP-CRF to that of the standard CRF by defininga single, complex CRF, which we call a monolithicCRF, and a range of expert sets.The monolithic CRF for NER comprises a num-ber of word and POS tag features in a window offive words around the current word, along with aset of orthographic features defined on the currentword.
These are based on those found in (Curran andClark, 2003).
Examples include whether the cur-rent word is capitalised, is an initial, contains a digit,contains punctuation, etc.
The monolithic CRF forNER has 450,345 features.The monolithic CRF for POS tagging comprisesword and POS features similar to those in the NERmonolithic model, but over a smaller number of or-thographic features.
The monolithic model for POStagging has 188,448 features.Each of our expert sets consists of a number ofCRF experts.
Usually these experts are designed to4See (Cohn et al, 2005) for a scaling method allowing thefull POS tagging task with CRFs.focus on modelling a particular aspect or subset ofthe distribution.
As we saw earlier, the aim here isto define experts that model parts of the distributionwell while retaining mutual diversity.
The expertsfrom a particular expert set are combined under aLOP-CRF and the weights are trained as describedpreviously.We define our range of expert sets as follows:?
Simple consists of the monolithic CRF and asingle expert comprising a reduced subset ofthe features in the monolithic CRF.
This re-duced CRF models the entire distribution ratherthan focusing on a particular aspect or subset,but is much less expressive than the monolithicmodel.
The reduced model comprises 24,818features for NER and 47,420 features for POStagging.?
Positional consists of the monolithic CRF anda partition of the features in the monolithicCRF into three experts, each consisting only offeatures that involve events either behind, at orahead of the current sequence position.?
Label consists of the monolithic CRF and apartition of the features in the monolithic CRFinto five experts, one for each label.
For NERan expert corresponding to label X consistsonly of features that involve labels B-X or I-X at the current or previous positions, while forPOS tagging an expert corresponding to labelX consists only of features that involve labelX at the current or previous positions.
Theseexperts therefore focus on trying to model thedistribution of a particular label.?
Random consists of the monolithic CRF and arandom partition of the features in the mono-lithic CRF into four experts.
This acts as abaseline to ascertain the performance that canbe expected from an expert set that is not de-fined via any linguistic intuition.5 ExperimentsTo compare the performance of LOP-CRFs trainedusing the procedure we described previously to thatof a standard CRF regularised with a Gaussian prior,we do the following for both NER and POS tagging:22?
Train a monolithic CRF with regularisation us-ing a Gaussian prior.
We use the developmentset to optimise the value of the variance hyper-parameter.?
Train every expert CRF in each expert set with-out regularisation (each expert set includes themonolithic CRF, which clearly need only betrained once).?
For each expert set, create a LOP-CRF fromthe expert CRFs and train the weights of theLOP-CRF without regularisation.
We compareits performance to that of the unregularised andregularised monolithic CRFs.?
To investigate whether training the LOP-CRFweights contributes significantly to the LOP-CRF?s performance, for each expert set we cre-ate a LOP-CRF with uniform weights and com-pare its performance to that of the LOP-CRFwith trained weights.?
To investigate whether unregularised trainingof the LOP-CRF weights leads to overfitting,for each expert set we train the weights of theLOP-CRF with regularisation using a Dirich-let prior.
We optimise the hyperparameter inthe Dirichlet distribution on the developmentset.
We then compare the performance of theLOP-CRF with regularised weights to that ofthe LOP-CRF with unregularised weights.6 Results6.1 ExpertsBefore presenting results for the LOP-CRFs, webriefly give performance figures for the monolithicCRFs and expert CRFs in isolation.
For illustration,we do this for NER models only.
Table 1 shows Fscores on the development set for the NER CRFs.We see that, as expected, the expert CRFs in iso-lation model the data relatively poorly compared tothe monolithic CRFs.
Some of the label experts, forexample, attain relatively low F scores as they focusonly on modelling one particular label.
Similar be-haviour was observed for the POS tagging models.Expert F scoreMonolithic unreg.
88.33Monolithic reg.
89.84Reduced 79.62Positional 1 86.96Positional 2 73.11Positional 3 73.08Label LOC 41.96Label MISC 22.03Label ORG 29.13Label PER 40.49Label O 60.44Random 1 70.34Random 2 67.76Random 3 67.97Random 4 70.17Table 1: Development set F scores for NER experts6.2 LOP-CRFs with unregularised weightsIn this section we present results for LOP-CRFs withunregularised weights.
Table 2 gives F scores forNER LOP-CRFs while Table 3 gives accuracies forthe POS tagging LOP-CRFs.
The monolithic CRFscores are included for comparison.
Both tables il-lustrate the following points:?
In every case the LOP-CRFs outperform theunregularised monolithic CRF?
In most cases the performance of LOP-CRFsrivals that of the regularised monolithic CRF,and in some cases exceeds it.We use McNemar?s matched-pairs test (Gillickand Cox, 1989) on point-wise labelling errors to ex-amine the statistical significance of these results.
Wetest significance at the 5% level.
At this threshold,all the LOP-CRFs significantly outperform the cor-responding unregularised monolithic CRF.
In addi-tion, those marked with ?
show a significant im-provement over the regularised monolithic CRF.Only the value marked with ?
in Table 3 significantlyunder performs the regularised monolithic.
All othervalues a do not differ significantly from those of theregularised monolithic CRF at the 5% level.These results show that LOP-CRFs with unreg-ularised weights can lead to performance improve-ments that equal or exceed those achieved from aconventional regularisation approach using a Gaus-sian prior.
The important difference, however, is thatthe LOP-CRF approach is ?parameter-free?
in the23Expert set Development set Test setMonolithic unreg.
88.33 81.87Monolithic reg.
89.84 83.98Simple 90.26 84.22?Positional 90.35 84.71?Label 89.30 83.27Random 88.84 83.06Table 2: F scores for NER unregularised LOP-CRFsExpert set Development set Test setMonolithic unreg.
97.92 97.65Monolithic reg.
98.02 97.84Simple 98.31?
98.12?Positional 98.03 97.81Label 97.99 97.77Random 97.99 97.76?Table 3: Accuracies for POS tagging unregularisedLOP-CRFssense that each expert CRF in the LOP-CRF is un-regularised and the LOP weight training is also un-regularised.
We are therefore not required to searcha hyperparameter space.
As an illustration, to ob-tain our best results for the POS tagging regularisedmonolithic model, we re-trained using 15 differentvalues of the Gaussian prior variance.
With theLOP-CRF we trained each expert CRF and the LOPweights only once.As an illustration of a typical weight distributionresulting from the training procedure, the positionalLOP-CRF for POS tagging attaches weight 0.45 tothe monolithic model and roughly equal weights tothe other three experts.6.3 LOP-CRFs with uniform weightsBy training LOP-CRF weights using the procedurewe introduce in this paper, we allow the weights totake on non-uniform values.
This corresponds toletting the opinion of some experts take precedenceover others in the LOP-CRF?s decision making.
Analternative, simpler, approach would be to com-bine the experts under a LOP with uniform weights,thereby avoiding the weight training stage.
Wewould like to ascertain whether this approach willsignificantly reduce the LOP-CRF?s performance.As an illustration, Table 4 gives accuracies for LOP-CRFs with uniform weights for POS tagging.
A sim-ilar pattern is observed for NER.
Comparing thesevalues to those in Tables 2 and 3, we can see that inExpert set Development set Test setSimple 98.30 98.12Positional 97.97 97.79Label 97.85 97.73Random 97.82 97.74Table 4: Accuracies for POS tagging uniform LOP-CRFsgeneral LOP-CRFs with uniform weights, althoughstill performing significantly better than the unreg-ularised monolithic CRF, generally under performLOP-CRFs with trained weights.
This suggests thatthe choice of weights can be important, and justifiesthe weight training stage.6.4 LOP-CRFs with regularised weightsTo investigate whether unregularised training of theLOP-CRF weights leads to overfitting, we trainthe LOP-CRF with regularisation using a Dirich-let prior.
The results we obtain show that in mostcases a LOP-CRF with regularised weights achievesan almost identical performance to that with unreg-ularised weights, and suggests there is little to begained by weight regularisation.
This is probablydue to the fact that in our LOP-CRFs the numberof experts, and therefore weights, is generally smalland so there is little capacity for overfitting.
We con-jecture that although other choices of expert set maycomprise many more experts than in our examples,the numbers are likely to be relatively small in com-parison to, for example, the number of parameters inthe individual experts.
We therefore suggest that anyoverfitting effect is likely to be limited.6.5 Choice of Expert SetsWe can see from Tables 2 and 3 that the performanceof a LOP-CRF varies with the choice of expert set.For example, in our tasks the simple and positionalexpert sets perform better than those for the labeland random sets.
For an explanation here, we re-fer back to our discussion of equation (5).
We con-jecture that the simple and positional expert setsachieve good performance in the LOP-CRF becausethey consist of experts that are diverse while simulta-neously being reasonable models of the data.
The la-bel expert set exhibits greater diversity between theexperts, because each expert focuses on modelling aparticular label only, but each expert is a relatively24poor model of the entire distribution and the corre-sponding LOP-CRF performs worse.
Similarly, therandom experts are in general better models of theentire distribution but tend to be less diverse becausethey do not focus on any one aspect or subset of it.Intuitively, then, we want to devise experts that pro-vide diverse but accurate views on the data.The expert sets we present in this paper weremotivated by linguistic intuition, but clearly manychoices exist.
It remains an important open questionas to how to automatically construct expert sets forgood performance on a given task, and we intend topursue this avenue in future research.7 Conclusion and future workIn this paper we have introduced the logarithmicopinion pool of CRFs as a way to address overfit-ting in CRF models.
Our results show that a LOP-CRF can provide a competitive alternative to con-ventional regularisation with a prior while avoidingthe requirement to search a hyperparameter space.We have seen that, for a variety of types of expert,combination of expert CRFs with an unregularisedstandard CRF under a LOP with optimised weightscan outperform the unregularised standard CRF andrival the performance of a regularised standard CRF.We have shown how these advantages a LOP-CRF provides have a firm theoretical foundation interms of the decomposition of the KL-divergencebetween a LOP-CRF and a target distribution, andhow this provides a framework for designing newoverfitting reduction schemes in terms of construct-ing diverse experts.In this work we have considered training theweights of a LOP-CRF using pre-trained, static ex-perts.
In future we intend to investigate cooperativetraining of LOP-CRF weights and the parameters ofeach expert in an expert set.AcknowledgementsWe wish to thank Stephen Clark, our colleagues inEdinburgh and the anonymous reviewers for manyuseful comments.ReferencesR.
F. Bordley.
1982.
A multiplicative formula for aggregatingprobability assessments.
Management Science, (28):1137?1148.T.
Cohn, A. Smith, and M. Osborne.
2005.
Scaling conditionalrandom fields using error-correcting codes.
In Proc.
ACL2005.J.
Curran and S. Clark.
2003.
Language independent NERusing a maximum entropy tagger.
In Proc.
CoNLL-2003.S.
Della Pietra, Della Pietra V., and J. Lafferty.
1997.
Induc-ing features of random fields.
In IEEE PAMI, volume 19(4),pages 380?393.L.
Gillick and S. Cox.
1989.
Some statistical issues in thecomparison of speech recognition algorithms.
In Interna-tional Conference on Acoustics, Speech and Signal Process-ing, volume 1, pages 532?535.T.
Heskes.
1998.
Selecting weighting factors in logarithmicopinion pools.
In Advances in Neural Information Process-ing Systems 10.G.
E. Hinton.
1999.
Product of experts.
In ICANN, volume 1,pages 1?6.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Conditionalrandom fields: Probabilistic models for segmenting and la-beling sequence data.
In Proc.
ICML 2001.R.
Malouf.
2002.
A comparison of algorithms for maximumentropy parameter estimation.
In Proc.
CoNLL-2002.A.
McCallum and W. Li.
2003.
Early results for named entityrecognition with conditional random fields, feature inductionand web-enhanced lexicons.
In Proc.
CoNLL-2003.A.
McCallum, K. Rohanimanesh, and C. Sutton.
2003.
Dy-namic conditional random fields for jointly labeling multiplesequences.
In NIPS-2003 Workshop on Syntax, Semanticsand Statistics.A.
McCallum.
2003.
Efficiently inducing features of condi-tional random fields.
In Proc.
UAI 2003.M.
Osborne and J. Baldridge.
2004.
Ensemble-based activelearning for parse selection.
In Proc.
NAACL 2004.F.
Peng and A. McCallum.
2004.
Accurate information extrac-tion from research papers using conditional random fields.In Proc.
HLT-NAACL 2004.Y.
Qi, M. Szummer, and T. P. Minka.
2005.
Bayesian condi-tional random fields.
In Proc.
AISTATS 2005.F.
Sha and F. Pereira.
2003.
Shallow parsing with conditionalrandom fields.
In Proc.
HLT-NAACL 2003.E.
F. Tjong Kim Sang and S. Buchholz.
2000.
Introduction tothe CoNLL-2000 shared task: Chunking.
In Proc.
CoNLL-2000.E.
F. Tjong Kim Sang and F. De Meulder.
2003.
Introduction tothe CoNLL-2003 shared task: Language-independent namedentity recognition.
In Proc.
CoNLL-2003.25
