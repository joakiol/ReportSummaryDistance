Proceedings of the 43rd Annual Meeting of the ACL, pages 435?442,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsA Quantitative Analysis of Lexical Differences Between Genders inTelephone ConversationsConstantinos BoulisDepartment of Electrical EngineeringUniversity of WashingtonSeattle, 98195boulis@ee.washington.eduMari OstendorfDepartment of Electrical EngineeringUniversity of WashingtonSeattle, 98195mo@ee.washington.eduAbstractIn this work, we provide an empiri-cal analysis of differences in word usebetween genders in telephone conversa-tions, which complements the consid-erable body of work in sociolinguisticsconcerned with gender linguistic differ-ences.
Experiments are performed on alarge speech corpus of roughly 12000 con-versations.
We employ machine learn-ing techniques to automatically catego-rize the gender of each speaker given onlythe transcript of his/her speech, achiev-ing 92% accuracy.
An analysis of themost characteristic words for each genderis also presented.
Experiments reveal thatthe gender of one conversation side influ-ences lexical use of the other side.
A sur-prising result is that we were able to clas-sify male-only vs. female-only conversa-tions with almost perfect accuracy.1 IntroductionLinguistic and prosodic differences between gen-ders in American English have been studied fordecades.
The interest in analyzing the gender lin-guistic differences is two-fold.
From the scientificperspective, it will increase our understandingof language production.
From the engineeringperspective, it can help improve the performanceof a number of natural language processing tasks,such as text classification, machine translation orautomatic speech recognition by training better lan-guage models.
Traditionally, these differences havebeen investigated in the fields of sociolinguisticsand psycholinguistics, see for example (Coates,1997), (Eckert and McConnell-Ginet, 2003) orhttp://www.ling.lancs.ac.uk/groups/gal/genre.htmfor a comprehensive bibliography on language andgender.
Sociolinguists have approached the issuefrom a mostly non-computational perspective usingrelatively small and very focused data collections.Recently, the work of (Koppel et al, 2002) hasused computational methods to characterize thedifferences between genders in written text, suchas literary books.
A number of monologues havebeen analyzed in (Singh, 2001) in terms of lexicalrichness using multivariate analysis techniques.The question of gender linguistic differencesshares a number of issues with stylometry andauthor/speaker attribution research (Stamatatos etal., 2000), (Doddington, 2001), but novel issuesemerge with analysis of conversational speech, suchas studying the interaction of genders.In this work, we focus on lexical differences be-tween genders on telephone conversations and usemachine learning techniques applied on text catego-rization and feature selection to characterize thesedifferences.
Therefore our conclusions are entirelydata-driven.
We use a very large corpus created forautomatic speech recognition - the Fisher corpus de-scribed in (Cieri et al, 2004).
The Fisher corpus isannotated with the gender of each speaker makingit an ideal resource to study not only the character-istics of individual genders but also of gender pairsin spontaneous, conversational speech.
The size and435scope of the Fisher corpus is such that robust resultscan be derived for American English.
The compu-tational methods we apply can assist us in answer-ing questions, such as ?To which degree are gender-discriminative words content-bearing words??
or?Which words are most characteristic for males ingeneral or males talking to females?
?.In section 2, we describe the corpus we havebased our analysis on.
In section 3, the machinelearning tools are explained, while the experimen-tal results are described in section 4 with a specificresearch question for each subsection.
We concludein section 5 with a summary and future directions.2 The Corpus and Data PreparationThe Fisher corpus (Cieri et al, 2004) was used inall our experiments.
It consists of telephone con-versations between two people, randomly assignedto speak to each other.
At the beginning of eachconversation a topic is suggested at random from alist of 40.
The latest release of the Fisher collectionhas more than 16 000 telephone conversations av-eraging 10 minutes each.
Each person participatesin 1-3 conversations, and each conversation is an-notated with a topicality label.
The topicality labelgives the degree to which the suggested topic wasfollowed and is an integer number from 0 to 4, 0being the worse.
In our site, we had an earlier ver-sion of the Fisher corpus with around 12 000 con-versations.
After removing conversations where atleast one of the speakers was non-native1 and con-versations with topicality 0 or 1 we were left with10 127 conversations.
The original transcripts wereminimally processed; acronyms were normalized toa sequence of characters with no intervening spaces,e.g.
t. v. to tv; word fragments were converted tothe same token wordfragment; all words were lower-cased; and punctuation marks and special characterswere removed.
Some non-lexical tokens are main-tained such as laughter and filled pauses such as uh,um.
Backchannels and acknowledgments such asuh-huh, mm-hmm are also kept.
The gender distri-bution of the Fisher corpus is 53% female and 47%male.
Age distribution is 38% 16-29, 45% 30-49%and 17% 50+.
Speakers were connected at random1About 10% of speakers are non-native making this corpussuitable for investigating their lexical differences compared toAmerican English speakers.from a pool recruited in a national ad campaign.
Itis unlikely that the speakers knew their conversationpartner.
All major American English dialects arewell represented, see (Cieri et al, 2004) for more de-tails.
The Fisher corpus was primarily created to fa-cilitate automatic speech recognition research.
Thesubset we have used has about 17.8M words or about1 600 hours of speech and it is the largest resourceever used to analyze gender linguistic differences.In comparison, (Singh, 2001) has used about 30 000words for their analysis.Before attempting to analyze the gender differ-ences, there are two main biases that need to be re-moved.
The first bias, which we term the topic biasis introduced by not accounting for the fact that thedistribution of topics in males and females is uneven,despite the fact that the topic is pre-assigned ran-domly.
For example, if topic A happened to be morecommon for males than females and we failed to ac-count for that, then we would be implicitly buildinga topic classifier rather than a gender classifier.
Ourintention here is to analyze gender linguistic differ-ences controlling for the topic effect as if both gen-ders talk equally about the same topics.
The sec-ond bias, which we term speaker bias is introducedby not accounting for the fact that specific speakershave idiosyncratic expressions.
If our training dataconsisted of a small number of speakers appearingin both training and testing data, then we will beimplicitly modeling speaker differences rather thangender differences.To normalize for these two important biases, wemade sure that both genders have the same percentof conversation sides for each topic and there are8899 speakers in training and 2000 in testing with nooverlap between the two sets.
After these two steps,there were 14969 conversation sides used for train-ing and 3738 sides for testing.
The median length ofa conversation side was 954.3 Machine Learning Methods UsedThe methods we have used for characterizing thedifferences between genders and gender pairs aresimilar to what has been used for the task of textclassification.
In text classification, the objective isto classify a document ~d to one (or more) of T pre-defined topics y.
A number of N tuples (~dn, yn)436are provided for training the classifier.
A majorchallenge of text classification is the very high di-mensionality for representing each document whichbrings forward the need for feature selection, i.e.
se-lecting the most discriminative words and discardingall others.In this study, we chose two ways for characteriz-ing the differences between gender categories.
Thefirst, is to classify the transcript of each speaker, i.e.each conversation side, to the appropriate gendercategory.
This approach can show the cumulativeeffect of all terms on the distinctiveness of gendercategories.
The second approach is to apply featureselection methods, similar to those used in text cate-gorization, to reveal the most characteristic featuresfor each gender.Classifying a transcript of speech according togender can be done with a number of different learn-ing methods.
We have compared Support VectorMachines (SVMs), Naive Bayes, Maximum Entropyand the tfidf/Rocchio classifier and found SVMs tobe the most successful.
A possible difference be-tween text classification and gender classification isthat different methods for feature weighting may beappropriate.
In text classification, inverse documentfrequency is applied to the frequency of each termresulting in the deweighting of common terms.
Thisweighting scheme is effective for text classificationbecause common terms do not contribute to the topicof a document.
However, the reverse may be true forgender classification, where the common terms maybe the ones that mostly contribute to the gender cate-gory.
This is an issue that we will investigate in sec-tion 4 and has implications for the feature weightingscheme that needs to be applied to the vector repre-sentation.In addition to classification, we have applied fea-ture selection techniques to assess the discrimina-tive ability of each individual feature.
Informationgain has been shown to be one of the most success-ful feature selection methods for text classification(Forman, 2003).
It is given by:IG(w) = H(C) ?
p(w)H(C|w) ?
p(w?)H(C|w?
)(1)where H(C) = ?
?Cc=1 p(c) log p(c) denotes theentropy of the discrete gender category random vari-able C. Each document is represented with theBernoulli model, i.e.
a vector of 1 or 0 dependingif the word appears or not in the document.
We havealso implemented another feature selection mecha-nism, the KL-divergence, which is given by:KL(w) = D[p(c|w)||p(c)] =C?c=1p(c|w) logp(c|w)p(c)(2)In the KL-divergence we have used the multinomialmodel, i.e.
each document is represented as a vectorof word counts.
We smoothed the p(w|c) distribu-tions by assuming that every word in the vocabularyis observed at least 5 times for each class.4 ExperimentsHaving explained the methods and data that we haveused, we set forward to investigate a number ofresearch questions concerning the nature of differ-ences between genders.
Each subsection is con-cerned with a single question.4.1 Given only the transcript of a conversation,is it possible to classify conversation sidesaccording to the gender of the speaker?The first hypothesis we investigate is whether sim-ple features, such as counts of individual terms (un-igrams) or pairs of terms (bigrams) have differentdistributions between genders.
The set of possibleterms consists of all words in the Fisher corpus plussome non-lexical tokens such as laughter and filledpauses.
One way to assess the difference in theirdistribution is by attempting to classify conversationsides according to the gender of the speaker.
Theresults are shown in Table 1, where a number ofdifferent text classification algorithms were appliedto classify conversation sides.
14969 conversationsides are used for training and 3738 sides are usedfor testing.
No feature selection was performed; inall classifiers a vocabulary of all unigrams or bi-grams with 5 or more occurrences is used (20513 forunigrams, 306779 for bigrams).
For all algorithms,except Naive Bayes, we have used the tf?idf repre-sentation.
The Rainbow toolkit (McCallum, 1996)was used for training the classifiers.
Results showthat differences between genders are clear and thebest results are obtained by using SVMs.
The factthat classification performance is significantly abovechance for a variety of learning methods shows that437lexical differences between genders are inherent inthe data and not in a specific choice of classifier.From Table 1 we also observe that using bigramsis consistently better than unigrams, despite the factthat the number of unique terms rises from ?20Kto ?300K.
This suggests that gender differences be-come even more profound for phrases, a finding sim-ilar to (Doddington, 2001) for speaker differences.Table 1: Classification accuracy of different learn-ing methods for the task of classifying the transcriptof a conversation side according to the gender -male/female - of the speaker.Unigrams BigramsRocchio 76.3 86.5Naive Bayes 83.0 89.2MaxEnt 85.6 90.3SVM 88.6 92.54.2 Does the gender of a conversation sideinfluence lexical usage of the otherconversation side?Each conversation always consists of two peopletalking to each other.
Up to this point, we have onlyattempted to analyze a conversation side in isola-tion, i.e.
without using transcriptions from the otherside.
In this subsection, we attempt to assess thedegree to which, if any, the gender of one speakerinfluences the language of the other speaker.
Inthe first experiment, instead of defining two cate-gories we define four; the Cartesian product of thegender of the current speaker and the gender of theother speaker.
These categories are symbolized withtwo letters: the first characterizing the gender of thecurrent speaker and the second the gender of theother speaker, i.e.
FF, FM, MF, MM.
The task re-mains the same: given the transcript of a conver-sation side, classify it according to the appropriatecategory.
This is a task much harder than the bi-nary classification we had in subsection 4.1, becausegiven only the transcript of a conversation side wemust make inferences about the gender of the currentas well as the other conversation side.
We have usedSVMs as the learning method.
In their basic formu-lation, SVMs are binary classifiers (although therehas been recent work on multi-class SVMs).
We fol-lowed the original binary formulation and convertedthe 4-class problem to 6 2-class problems.
The finaldecision is taken by voting of the individual systems.The confusion matrix of the 4-way classification isshown in Table 2.Table 2: Confusion matrix for 4-way classificationof gender of both sides using transcripts from oneside.
Unigrams are used as features, SVMs as clas-sification method.
Each row represents the true cat-egory and each column the hypothesized category.FF FM MF MM F-measureFF 1447 30 40 65 .778FM 456 27 43 77 .074MF 167 25 104 281 .214MM 67 44 210 655 .638The results show that although two of the four cat-egories, FF and MM, are quite robustly detected theother two, FM and MF, are mostly confused with FFand MM respectively.
These results can be mappedto single gender detection, giving accuracy of 85.9%for classifying the gender of the given transcript (asin Table 1) and 68.5% for classifying the gender ofthe conversational partner.
The accuracy of 68.5% ishigher than chance (57.8%) showing that genders al-ter their linguistic patterns depending on the genderof their conversational partner.In the next experiment we design two binary clas-sifiers.
In the first classifier, the task is to correctlyclassify FF vs. MM transcripts, and in the secondclassifier the task is to classify FM vs. MF tran-scripts.
Therefore, we attempt to classify the genderof a speaker given knowledge of whether the con-versation is same-gender or cross-gender.
For bothclassifiers 4526 sides were used for training equallydivided among each class.
2558 sides were used fortesting of the FF-MM classifier and 1180 sides forthe FM-MF classifier.
The results are shown in Ta-ble 3.It is clear from Table 3 that there is a significantdifference in performance between the FF-MM andFM-MF classifiers, suggesting that people alter theirlinguistic patterns depending on the gender of theperson they are talking to.
In same-gender conver-sations, almost perfect accuracy is reached, indicat-ing that the linguistic patterns of the two genders be-438Table 3: Classification accuracies in same-genderand cross-gender conversations.
SVMs are used asthe classification method; no feature selection is ap-plied.Unigrams BigramsFF-MM 98.91 99.49FM-MF 69.15 78.90come very distinct.
In cross-gender conversationsthe differences become less prominent since clas-sification accuracy drops compared to same-genderconversations.
This result, however, does not re-veal how this convergence of linguistic patterns isachieved.
Is it the case that the convergence is at-tributed to one of the genders, for example malesattempting to match the patterns of females, or is itcollectively constructed?
To answer this question,we can examine the classification performance oftwo other binary classifiers FF vs. FM and MM vs.MF.
The results are shown in Table 4.
In both clas-sifiers 4608 conversation sides are used for training,equally divided in each class.
The number of sidesused for testing is 989 and 689 for the FF-FM andMM-MF classifier respectively.Table 4: Classifying the gender of speaker B givenonly the transcript of speaker A. SVMs are used asthe classification method; no feature selection is ap-plied.Unigrams BigramsFF-FM 57.94 59.66MM-MF 60.38 59.80The results in Table 4 suggest that both gendersequally alter their linguistic patterns to match theopposite gender.
It is interesting to see that the gen-der of speaker B can be detected better than chancegiven only the transcript and gender of speaker A.The results are better than chance at the 0.0005 sig-nificance level.4.3 Are some features more indicative ofgender than other?Having shown that gender lexical differences areprominent enough to classify each speaker accord-ing to gender quite robustly, another question iswhether the high classification accuracies can be at-tributed to a small number of features or are ratherthe cumulative effect of a high number of them.
InTable 5 we apply the two feature selection criteriathat were described in 3.Table 5: Effect of feature selection criteria on gen-der classification using SVM as the learning method.Horizontal axis refers to the fraction of the originalvocabulary size (?20K for unigrams, ?300K for bi-grams) that was used.1.0 0.7 0.4 0.1 0.03KL 1-gram 88.6 88.8 87.8 86.3 85.62-gram 92.5 92.6 92.2 91.9 90.3IG 1-gram 88.6 88.5 88.9 87.6 87.02-gram 92.5 92.4 92.6 91.8 90.8The results of Table 5 show that lexical differ-ences between genders are not isolated in a small setof words.
The best results are achieved with 40%(IG) and 70% (KL) of the features, using fewer fea-tures steadily degrades the performance.
Using the5000 least discriminative unigrams and Naive Bayesas the classification method resulted in 58.4% clas-sification accuracy which is not statistically betterthan chance (this is the test set of Tables 1 and 2 notof Table 4) .
Using the 15000 least useful unigramsresulted in a classification accuracy of 66.4%, whichshows that the number of irrelevant features is rathersmall, about 5K features.It is also instructive to see which features are mostdiscriminative for each gender.
The features thatwhen present are most indicative of each gender(positive features) are shown in Table 6.
They aresorted using the KL distance and dropping the sum-mation over both genders in equation (2).
Lookingat the top 2000 features for each number we ob-served that a number of swear words appear asmost discriminative for males and family-relationterms are often associated with females.
For ex-ample the following words are in the top 2000 (outof 20513) most useful features for males shit, bull-shit, shitty, fuck, fucking, fucked, bitching, bastards,ass, asshole, sucks, sucked, suck, sucker, damn, god-damn, damned.
The following words are in thetop 2000 features for females children, grandchild,439Table 6: The 10 most discriminative features foreach gender according to KL distance.
Words higherin the list are more discriminative.Male Femaledude husbandshit husband?sfucking refundingwife goodnesswife?s boyfriendmatt couponssteve craftsbass lindaben goshfuck cutechild, grandchildren, childhood, childbirth, kids,grandkids, son, grandson, daughter, granddaugh-ter, boyfriend, marriage, mother, grandmother.
Itis also interesting to note that a number of non-lexical tokens are strongly associated with a certaingender.
For example, [laughter] and acknowledg-ments/backchannels such as uh-huh,uhuh were inthe top 2000 features for females.
On the other hand,filled pauses such as uh were strong male indicators.Our analysis also reveals that a high number of use-ful features are names.
A possible explanation isthat people usually introduce themselves at the be-ginning of the conversation.
In the top 30 words pergender, names represent over half of the words formales and nearly a quarter for females.
Nearly athird were family-relations words for females, and17When examining cross-gender conversations, thediscriminative words were quite substantially differ-ent.
We can quantify the degree of change by mea-suring KLSG(w) ?KLCG(w) where KLSG(w) isthe KL measure of word w for same-gender con-versations.
The analysis reveals that swear termsare highly associated with male-only conversations,while family-relation words are highly associatedwith female-only conversations.From the traditional sociolinguistic perspective,these methods offer a way of discovering rather thantesting words or phrases that have distinct usagebetween genders.
For example, in a recent paper(Kiesling, in press) the word dude is analyzed asa male-to-male indicator.
In our work, the worddude emerged as a male feature.
As another ex-ample, our observation that some acknowledgmentsand backchannels (uh-huh) are more common for fe-males than males while the reverse is true for filledpauses asserts a popular theory in sociolinguisticsthat males assume a more dominant role than fe-males in conversations (Coates, 1997).
Males tendto hold the floor more than women (more filledpauses) and females tend to be more responsive(more acknowledgments/backchannels).4.4 Are gender-discriminative featurescontent-bearing words?Do the most gender-discriminative words contributeto the topic of the conversation, or are they simplefill-in words with no content?
Since each conversa-tion is labeled with one of 40 possible topics, we canrank features with IG or KL using topics instead ofgenders as categories.
In fact, this is the standardway of performing feature selection for text classi-fication.
We can then compare the performance ofclassifying conversations to topics using the top-Nfeatures according to the gender or topic ranking.The results are shown in Table 7.Table 7: Classification accuracies using topic- andgender-discriminative words, sorted using the infor-mation gain criterion.
When randomly selecting5000 features, 10 independent runs were performedand numbers reported are mean and standard devia-tion.
Using the bottom 5000 topic words resulted inchance performance (?5.0)Top 5K Bottom 5K Random 5KGender ranking 78.51 66.72 74.99?2.2Topic ranking 87.72 - 74.99?2.2From Table 7 we can observe that gender-discriminative words are clearly not the most rele-vant nor the most irrelevant features for topic clas-sification.
They are slightly more topic-relevantfeatures than topic-irrelevant but not by a signifi-cant margin.
The bottom 5000 features for gen-der discrimination are more strongly topic-irrelevantwords.These results show that gender linguistic differ-ences are not merely isolated in a set of words that440would function as markers of gender identity but arerather closely intertwined with semantics.
We at-tempted to improve topic classification by traininggender-dependent topic models but we did not ob-serve any gains.4.5 Can gender lexical differences be exploitedto improve automatic speech recognition?Are the observed gender linguistic differences valu-able from an engineering perspective as well?
Inother words, can a natural language processing taskbenefit from modeling these differences?
In this sub-section, we train gender-dependent language modelsand compare their perplexities with standard base-lines.
An advantage of using gender informationfor automatic speech recognition is that it can berobustly detected using acoustic features.
In Ta-bles 8 and 9 the perplexities of different gender-dependent language models are shown.
The SRILMtoolkit (Stolcke, 2002) was used for training the lan-guage models using Kneser-Ney smoothing (Kneserand Ney, 1987).
The perplexities reported includethe end-of-turn as a separate token.
2300 con-versation sides are used for training each one of{FF,FM,MF,MM} models of Table 8, while 7670conversation sides are used for training each one of{F,M} models of Table 9.
In both tables, the same1678 sides are used for testing.Table 8: Perplexity of gender-dependent bigram lan-guage models.
Four gender categories are used.Each column has the perplexities for a given test set,each row for a train set.FF FM MF MMFF 85.3 91.1 96.5 99.9FM 85.7 90.0 94.5 97.5MF 87.8 91.4 93.3 95.4MM 89.9 93.1 94.1 95.2ALL 82.1 86.3 89.8 91.7In Tables 8 and 9 we observe that we get lowerperplexities in matched than mismatched conditionsin training and testing.
This is another way to showthat different data do exhibit different properties.However, the best results are obtained by poolingall the data and training a single language model.Therefore, despite the fact there are different modes,Table 9: Perplexity of gender-dependent bigram lan-guage models.
Two gender categories are used.Each column has the perplexities for a given test set,each row for a train set.F MF 82.8 94.2M 86.0 90.6ALL 81.8 89.5the benefit of more training data outweighs the ben-efit of gender-dependent models.
Interpolating ALLwith F and ALL with M resulted in insignificant im-provements (81.6 for F and 89.3 for M).5 ConclusionsWe have presented evidence of linguistic differencesbetween genders using a large corpus of telephoneconversations.
We have approached the issue froma purely computational perspective and have shownthat differences are profound enough that we canclassify the transcript of a conversation side ac-cording to the gender of the speaker with accuracyclose to 93%.
Our computational tools have al-lowed us to quantitatively show that the gender ofone speaker influences the linguistic patterns of theother speaker.
Specifically, classifying same-genderconversations can be done with almost perfect accu-racy, while evidence of some convergence of maleand female linguistic patterns in cross-gender con-versations was observed.
An analysis of the fea-tures revealed that the most characteristic featuresfor males are swear words while for females arefamily-relation words.
Leveraging these differencesin simple gender-dependent language models is nota win, but this does not imply that more sophisti-cated language model training methods cannot help.For example, instead of conditioning every word inthe vocabulary on gender we can choose to do soonly for the top-N, determined by KL or IG.
Theprobability estimates for the rest of the words willbe tied for both genders.
Future work will examineempirical differences in other features such as dialogacts or turntaking.441ReferencesC.
Cieri, D. Miller, and K. Walker.
2004.
The Fishercorpus: a resource for the next generations of speech-to-text.
In 4th International Conference on LanguageResources and Evaluation, LREC, pages 69?71.J.
Coates, editor.
1997.
Language and Gender: AReader.
Blackwell Publishers.G.
Doddington.
2001.
Speaker recognition based onidiolectal differences between speakers.
In Proceed-ings of the 7th European Conference on Speech Com-munication and Technology (Eurospeech 2001), pages2251?2254.P.
Eckert and S. McConnell-Ginet, editors.
2003.
Lan-guage and Gender.
Cambridge University Press.G.
Forman.
2003.
An extensive empirical study of fea-ture selection metrics for text classification.
MachineLearning Research, 3:1289?1305.S.
Kiesling.
in press.
Dude.
American Speech.R.
Kneser and H. Ney.
1987.
Improved backing-off form-gram language modeling.
In Proc.
Intl.
Conf.
onAcoustics, Speech and Signal Processing (ICASSP),pages 181?184.M.
Koppel, S. Argamon, and A.R.
Shimoni.
2002.
Auto-matically categorizing written texts by author gender.Literary and Linguistic Computing, 17(4):401?412.A.
McCallum.
1996.
Bow: A toolkit for statistical lan-guage modeling, text retrieval, classification and clus-tering.
http://www.cs.cmu.edu/ mccallum/bow.S.
Singh.
2001.
A pilot study on gender differencesin conversational speech on lexical richness measures.Literary and Linguistic Computing, 16(3):251?264.E.
Stamatatos, N. Fakotakis, and G. Kokkinakis.
2000.Automatic text categorization in terms of genre andauthor.
Computational Linguistics, 26:471?495.A.
Stolcke.
2002.
An extensible language modelingtoolkit.
In Proc.
Intl.
Conf.
on Spoken Language Pro-cessing (ICSLP), pages 901?904.442
