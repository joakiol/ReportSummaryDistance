Multi-Document Summarization By Sentence ExtractionJade Goldstein* Vibhu Mittal t Jaime Carbonell* Mark Kantrowitztjade@cs.cmu.edu mittal@jprc.com jgc@cs.cmu.edu mkant@jprc.com*Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213U.S.A.tJust Research4616 Henry StreetPittsburgh, PA 15213U.S.A.AbstractThis paper discusses a text extraction approach to multi-document summarization that builds on single-documentsummarization methods by using additional, available in-,formation about the document set as a whole and therelationships between the documents.
Multi-documentsummarization differs from single in that the issuesof compression, speed, redundancy and passage selec-tion are critical in the formation of useful summaries.Our approach addresses these issues by using domain-independent techniques based mainly on fast, statisticalprocessing, a metric for reducing redundancy and maxi-mizing diversity in the selected passages, and a modularframework to allow easy parameterization for differentgenres, corpora characteristics and user requirements.1 IntroductionWith the continuing growth of online information, ithas become increasingly important to provide improvedmechanisms to find and present extual information ef-fectively.
Conventional IR systems find and rank docu-ments based on maximizing relevance to the user query(Salton, 1970; van Rijsbergen, 1979; Buckley, 1985;Salton, 1989).
Some systems also include sub-documentrelevance assessments and convey this information to theuser.
More recently, single document summarization sys-tems provide an automated generic abstract or a query-relevant summary (TIPSTER, 1998a).
i However, large-scale IR and summarization have not yet been truly in-tegrated, and the functionality challenges on a summa-rization system are greater in a true IR or topic-detectioncontext (Yang et al, 1998; Allan et al, 1998).Consider the situation where the user issues a searchquery, for instance on a news topic, and the retrieval sys-tem finds hundreds of closely-ranked documents in re-sponse.
Many of these documents are likely to repeatmuch the same information, while differing in certaini Most of these were based on statistical techniques applied to var-ious document entities; examples include frait, 1983; Kupiec et al,1995; Paice, 1990, Klavans and Shaw, 1995; MeKeown et al, 1995;Shaw, 1995; Aon?
et al, 1997; Boguraev and Kennedy, 1997; Hovyand Lin, 1997; Mitra et al, 1997; Teufel and Moens, 1997; Barzilayand Elhadad, 1997; Carbonell and Goldstein, 1998; Baldwin and Mor-tbn, 1998; Radev and McKeown, 1998; Strzalkowski etal., 1998).parts.
Summaries of the individual documents wouldhelp, but are likely to be very similar to each other, un-less the summarization system takes into account othersummaries that have already been generated.
Multi-document summarization - capable of summarizing ei-ther complete documents sets, or single documents in thecontext of previously summarized ones - are likely tobe essential in such situations.
Ideally, multi-documentsummaries should contain the key shared relevant infor-mation among all the documents only once, plus otherinformation unique to some of the individual documentsthat are directly relevant to the user's query.Though many of the same techniques used in single-document summarization can also be used in multi-document summarization, there are at least four signif-icant differences:1.
The degree of redundancy in information containedwithin a group of topically-related articles is muchhigher than the degree of redundancy within an arti-cle, as each article is apt to describe the main pointas well as necessary shared background.
Henceanti-redundancy methods are more crucial.2.
A group of articles may contain a temporal dimen-sion, typical in a stream of news reports about anunfolding event.
Here later information may over-ride earlier more tentative or incomplete accounts.3.
The compression ratio (i.e.
the size of the summarywith respect o the size of the document set) willtypically be much smaller for collections of dozensor hundreds of topically related documents thanfor single document summaries.
The SUMMACevaluation (TIPSTER, 1998a) tested 10% compres-sion summaries, but in our work summarizing 200-document clusters, we find that compression to the1% or 0.1% level is required.
Summarization be-comes significantly more difficult when compres-sion demands increase.4.
The co-reference problem in summarizationpresents even greater challenges for multi-document han for single-document summariza-tion (Baldwin and Morton, 1998).This paper discusses an approach to multi-documentsummarization that builds on previous work in single-40IiliiI!IiilII!II!I,Idocument summarization by using additional, availableinformation about the document set as a whole, the re-lationships between the documents, as well as individualdocuments.2 Background and Related WorkGenerating an effective summary requires the summa-rizer to select, evaluate, order and aggregate items ofinformation according to their relevance to a particularsubject or purpose.
These tasks can either be approx-imated by IR techniques or done in greater depth withfuller natural language processing.
Most previous workin summarization has attempted todeal with the issues byfocusing more on a related, but simpler, problem.
Withtext-span deletion the system attempts o delete "less im-portant" spans of text from the original document; thetext that remains is deemed a summary.
Work on auto-mated document summarization by text span extractiondates back at least to work at IBM in the fifties (Luhn,1958).
Most of the work in sentence xtraction appliedstatistical techniques (frequency analysis, variance anal-ysis, etc.)
to linguistic units such as tokens, names,anaphora, etc.
More recently, other approaches haveinvestigated the utility of discourse structure (Marcu,1997), the combination of information extraction andlanguage generation (Klavans and Shaw, 1995; McKe-own et al, 1995), and using machine learning to findpatterns in text (Teufel and Moens, 1997; Barzilay andElhadad, 1997; Strzalkowski et al, 1998).Some of these approaches tosingle document summa-rization have been extended to deal with multi-documentsummarization (Mani and Bloedern, 1997; Goldstein andCarbonell, 1998; TIPSTER, 1998b; Radev and McKe-own, 1998; Mani and Bloedorn, 1999; McKeown et al,.
!999; Stein et al, 1999).
These include comparing tem-plates filled in by extracting information - using special-ized, domain specific knowledge sources - from the doc-"ument, and then generating natural language summariesfrom the templates (Radev and McKeown, 1998), com--?
paring named-entities - extracted using specialized lists- between documents and selecting the most relevantsection (TIPSTER, 1998b), finding co-reference chainsin the document set to identify common sections of inter-est (TIPSTER, 1998b), or building activation etworksof related lexical items (identity mappings, synonyms,hypernyms, etc.)
to extract text spans from the documentset (Mani and Bloedern, 1997).
Another system (Stein etal., 1999) creates a multi-document summary from mul-tiple single document summaries, an approach that canbe sub-optimal in some cases, due to the fact that theprocess of generating the final multi-document summarytakes as input he individual summaries and not the com-plete documents.
(Particularly if the single-documentsummaries can contain much overlapping information.
)The Columbia University system (McKeown et al, 1999)creates amulti-document summary using machine learn-ing and statistical techniques to identify similar sections41and language generation to reformulate the summary.The focus of our approach is a multi-document systemthat can quickly summarize large clusters of similar doc-uments (on the order of thousands) while providing thekey relevant useful information or pointers to such in-formation.
Our system (1) primarily uses only domain-independent techniques, based mainly on fast, statisticalprocessing, (2) explicitly deals with the issue of reducingredundancy without eliminating potential relevant infor-mation, and (3) contains parameterized modules, so thatdifferent genres or corpora characteristics an be takeninto account easily.3 Requirements for Multi-DocumentSummarizationThere are two types of situations in which multi-document summarization would be useful: (1) the useris faced with a collection of dis-similar documents andwishes to assess the information landscape contained inthe collection, or (2) there is a collection of topically-related ocuments, extracted from a larger more diversecollection as the result of a query, or a topically-cohesivecluster.
In the first case, if the collection is large enough,it only makes ense to first cluster and categorize the doc-uments (Yang et al, 1999), and then sample from, orsummarize ach cohesive cluster.
Hence, a "summary"would constitute of a visualization of the informationlandscape, where features could be clusters or summariesthereof.
In the second case, it is possible to build a syn-thetic textual summary containing the main point(s) ofthe topic, augmented with non-redundant background in-formation and/or query-relevant elaborations.
This is thefocus of our work reported here, including the necessityto eliminate redundancy among the information contentof multiple related ocuments.Users' information seeking needs and goals varytremendously.
When a group of three people created amulti-document summarization of 10 articles about heMicrosoft Trial from a given day, one summary focusedon the details presented in court, one on an overall gistof the day's events, and the third on a high level view ofthe goals and outcome of the trial.
Thus, an ideal multi-document summarization would be able to address thedifferent levels of detail, which is difficult without natu-ral language understanding.
An interface for the summa-rization system needs to be able to permit he user to en-ter information seeking oals, via a query, a backgroundinterest profile and/or a relevance feedback mechanism.Following is a list of requirements for multi-documentsummarization:?
clustering: The ability to cluster similar documentsand passages to find related information.?
coverage: The ability to find and extract he mainpoints across documents.?
anti-redundancy: The ability to minimize redun-dancy between passages in the summary.*.
summary cohesion criteria: The ability to combinetext passages in a useful manner for the reader.-Thismay include:- document ordering: All text segments of high-est ranking document, hen all segments fromthe next highest ranking document, etc.- news-story principle (rank ordering):presentthe most relevant and diverse information firstso that the reader gets the maximal informationcontent even if they stop reading the summary.- topic-cohesion: Group together the passagesby topic clustering using passage similarity cri-teria and present the information by the cluster"centroid passage rank.- t ime line ordering: Text passages orderedbased on the occurrence of events in time.
* coherence: Summaries generated should be read-able and relevant to the user.. context: Include sufficient context so that the sum-mary is understandable to the reader.?
identification of source inconsistencies: Articles of-ten have errors (such as billion reported as million,etc.
); multi-document summarization must be ableto recognize and report source inconsistencies.?
summary updates: A new multi-document summarymust take into account previous ummaries in gen-erating new summaries.
In such cases, the systemneeds to be able to track and categorize vents.?
effective user interfaces:- Attributability: The user needs to be able toeasily access the source of a given passage.This could be the single document summary.- Relationship: The user needs to view relatedpassages to the text passage shown, which canhighlight source inconsistencies.- Source Selection: The user needs to be able to,- select or eliminate various sources.
For exam-ple, the user may want to eliminate informationfrom some less reliable foreign news reportingsources.- Context: The user needs to be able to zoomin on the context surrounding the chosen pas-sages.- Redirection: The user should be able to high-light certain parts of the synthetic summaryand give a command to the system indicatingthat these parts are to be weighted heavily andthat other parts are to be given a lesser weight.4 Types of Multi-Document SummarizersIn the previous ection we discussed the requirementsfor a multi-document summarization system.
Depend-ing on a user's information seeking goals, the user maywant to create summaries that contain primarily the com-mon portions of the documents (their intersection) or anoverview of the entire cluster of documents (a sampling.of the space that the documents span).
A user may alsowant to have a highly readable summary, an overview ofpointers (sentences or word lists) to further information,?
or a combination of the two.
Following is a list of  var-ious methods of creating multi-document summaries byextraction:1.
Summary from Common Sections of Documents:Find the important relevant parts that the cluster ofdocuments have in common (their intersection) anduse that as a summary.2.
Summary from Common Sections and Unique Sec-tions of Documents: Find the important relevantparts that the cluster of documents have in commonand the relevant parts that are unique and use that asa summary.3.
Centroid Document Summary: Create a single doc-ument summary from the centroid ocument in the?
cluster.4.
Centroid Document plus Outliers Summary: Cre-ate a single document summary from the centroiddocument in the cluster and add some representa-tion from outlier documents (passages or keywordextraction) to provide a fuller coverage of the docu-ment set.
25.
Latest Document plus Outliers Summary: Createa single document summary from the latest timestamped ocument in the cluster (most recent in-formation) and add some representation f outlierdocuments o provide a fuller coverage of the docu-ment set.6.
Summary from Common Sections and Unique Sec-tions of Documents with Time Weighting Factor:Find the important relevant parts that the cluster ofdocuments have in common and the relevant partsthat are unique and weight all the information bythe time sequence of the documents in which theyappear and use the result as a summary.
This al-lows the more recent, often updated information tobe more likely to be included in the summary.There are also much more complicated types of sum-mary extracts which involve natural anguage process-ing and/or understanding.
These types of summaries in-clude: (1) differing points of view within the documentcollection, (2) updates of information within the doc-ument collection, (3) updates of information from thedocument collection with respect o an already providedsummary, (4) the development of an event or subtopic of2This is similar to the approach ofTextwise fHPSTER, 1998b),whose multi-document summary consists of the most relevant para-graph and specialized word lists.42IIIIlIIIIIIian event (e.g., death tolls) over time, and (5) a compara-tive development of an event.Naturally, an ideal multi-document summary wouldinclude a natural language generation component to cre-ate cohesive readable summaries (Radev and McKeown,1998; McKeown et al, 1999).
Our current focus is onthe extraction of the relevant passages.5 System DesignIn the previous ections we discussed the requirementsand types of multi-document summarization systems.This section discusses our current implementation ofa multi-document summarization system which is de-signed to produce summaries that emphasize "relevantnovelty."
Relevant novelty is a metric for minimizing re-dundancy and maximizing both relevance and diversity.A first approximation tomeasuring relevant novelty is tomeasure relevance and novelty independently and pro-vide a linear combination as the metric.
We call this lin-ear combination "marginal relevance" .-- i.e., a text pas-sage has high marginal relevance if it is both relevant tothe query and useful for a summary, while having mini-mal similarity to previously selected passages.
Using thismetric one can maximize marginal relevance in retrievaland summarization, hence we label our method "maxi-mal marginal relevance" (MMR) (Carboneli and Gold-stein, 1998).The Maximal Marginal Relevance Multi-Document(MMR-MD) metric is defined in Figure 1.
Sirnl andSire2 cover some of the properties that we discussed inSection 3.
3: For Sirnl, the first term is the cosine similarity metricfor query and document.
The second term computes acoverage score for the passage by whether the passageis in one or more clusters and the size of the cluster.The third term reflects the information content of the pas-.sage by taking into account both statistical and linguis-tic features for summary inclusion (such as query expan-.sion, position of the passage in the document and pres-ence/absence of named-entities in the passage).
The finalterm indicates the temporal sequence of the document inthe collection allowing for more recent information tohave higher weights.For Sire2, the first term uses the cosine similarity met-ric to compute the similarity between the passage andpreviously selected passages.
(This helps the system tominimize the possibility of including passages similar toones already selected.)
The second term penalizes pas-sages that are part of clusters from which other passageshave already been chosen.
The third term penalizes doc-uments from which passages have already been selected;however, the penalty is inversely proportional to docu-ment length, to allow the possibility of longer documents3Sirnn and Sirn2 as previously defined in MMR for single-document summarization contained only the first term of each equa-tion:43contributing more passages.
These latter two terms allowfor a fuller coverage of the clusters and documents.Given the above definition, MMR-MD incrementallycomputes the standard relevance-ranked list- plus someadditional scoring factors - when the parameter A= 1, andcomputes a maximal diversity ranking among the pas-sages in the documents when A=0.
For intermediate val-ues of A in the interval \[0,1 \], a linear combination of bothcriteria is optimized.
In order to sample the informationspace in the general vicinity of the query, small values ofcan be used; to focus on multiple, potentially overlap-ping or reinforcing relevant passages, A can be set to avalue closer to 1.
We found that a particularly effectivesearch strategy for document retrieval is to start with asmall A (e.g., A = .3) in order to understand the informa-tion space in the region of the query, and then to focuson the most important parts using a reformulated query(possibly via relevance feedback) and a larger value of(e.g., A = .7) (Carboneli and Goldstein, 1998).Our multi-document summarizer works as follows:?
Segment he documents into passages, and indexthem using inverted indices (as used by the IRengine).
Passages may be phrases, sentences, n-sentence chunks, or paragraphs.?
Identify the passages relevant o the query usingcosine similarity with a threshold below which thepassages are discarded.?
Apply the MMR-MD metric as defined above.
De-pending on the desired length of the summary, se-lect a number of passages to compute passage re-dundancy using the cosine similarity metric and usethe passage similarity scoring as a method of clus-tering passages.
Users can select he number of pas-sages or the amount of compression.?
Reassemble the selected passages into a summarydocument using one of the summary-cohesion cri-teria (see Section 3).The results reported in this paper are based on the useof the SMART search engine (Buckley, 1985) to computecosine similarities (with a SMART weighting of lnn  forboth queries and passages), stopwords eliminated fromthe indexed ata and stemming turned on.6 DiscussionThe TIPSTER evaluation corpus provided several sets oftopical clusters to which we applied MMR-MD summa-rization.
As an example, consider a set of 200 apartheid-related news-wire documents from the Associated Pressand the Wall Street Journal, spanning the period from1988 to 1992.
We used the TIPSTER provided topic de-scription as the query.
These 200 documents were onan average 31 sentences in length, with a total of 6115sentences.
We used the sentence as our summary unit.Generating a summary 10 sentences long resulted in aMMR-MD ~ Arg max \[A(Siml (Pii, Q, Cij, Di, D)) - (1 - A) max Sirn2 (Pij, Pnm, C, S, Di))\]Pij ER\S t - P,=.. ESSire1 (P,.j, Q, Cij, Di, D) = wl *(Pij'Q)+w2*coverage(Pij, Cij)+wa*content(Pij)+w4*tirne_sequenee(Di, D)Sim2 ( Pij, Pare, C, S, Di ) = tOa * ( f f  i j  " Pnm) + rob * clusters_selected( (7ij, S) + we * documents_selected( Di , S)~ov~r~ge(Pi~,C) = ~ wk * IklkECi./eonlent(Pij) = ~ wtvp,(W)WEPijtirnesiarap( D,,a=tim, ) - timestamp( Di )time_sequ_ence ( Di, D) = timestamp( Dmaxtime ) - tiraestamp( D,nintime )clusters_selected(C~, S) = IC~ n L.J cv=lv,w:P,,,~ESdocuments_selected(Di, S) = ~ =whereSire1 is the similarity metric for relevance rankingSim~ is the anti-redundancy metricD is a document collectionP is the passages from the documents in that collection (e.g., ~ j  is passage j from document Di)Q is a query or user profileR = IR(D, P, Q, 8), i.e., the ranked list of passages from documents retrieved by an IR system, given D, P, Q and a' relevance threshold O, below which it will not retrieve passages (O can be degree of match or number of passages)._5" is the subset of passages in R already selectedR\S  is the set difference, i.e., the set of as yet unselected passages in R' C is the set of passage clusters for the set of documents(7vw is the subset of clusters of (7 that contains passage Pvw(7~ is the subset of clusters that contain passages from document D~Ikl is the number of passages in the individual cluster kIC~,~ N Cijl is the number of clusters in the intersection of (7,,,nand(Tijwi..are weights for the terms, which can be optimizedW is a word in the passage/~jtype is a particular type of word, e.g., city nameIOil is the length of document i.Figure l: Definition of multi-document summarization algorithm - MMR-MDiIIIiI!IIIi!isentence compression ratio of 0.2% and a character com-pression of 0.3%, approximately two orders of magni-tude different with compression ratios used in single doc-ument summarization.
The results of summarizing thisdocument set with a value of A set to I (effectively queryrelevance, but no MMR-MD) and A set to 0.3 (both queryrelevance and MMR-MD anti-redundancy) are shown inFigures 2 and 3 respectively.
The summary in Figure 2clearly illustrates the need for reducing redundancy andmaximizing novel information.Consider for instance, the summary shown in Figure 2.The fact that the ANC is fighting to overthrow the gov-44i.
wsJg10204-0176:1 CAPE TOWN, South Africa - President EW.
de Klerk's proposal to repeal the major pillarsof apartheid rew a generally positive response from black leaders, but African National Congress leader NelsonMandela called on the international community to continue conomic sanctions against South Africa until thegovernment takes further steps.2.
AP880803-0082:25 Three Canadian anti-apartheid groups issued a statement urging the government to severdiplomatic and economic links with South Africa and aid the African National Congress, the banned group fightingthe white-dominated government in South Africa.3.
AP880803-0080:25 Three Canadian anti-apartheid groups issued a statement urging the government to severdiplomatic and economic links with South Africa and aid the African National Congress, the banned group fightingthe white-dominated government in South Africa.4.
AP880802-0165:23 South Africa says the ANC, the main black group fighting to overthrow South Africa's whitegovernment, has seven major military bases in Angola, and the Pretoria government wants those bases closeddown.5.
AP880212-0060:14 ANGOP quoted the Angolan statement as saying the main causes of confict in the regionare South Africa's "illegal occupation" of Namibia, South African attacks against its black-ruled neighbors andits alleged creation of armed groups to carry out "terrorist a~tivities" in those countries, and the denial of politicalrights to the black majority in South Africa.6.
AP880823-0069:17 The ANC is the main guerrilla group fighting to overthrow the South African governmentand end apartheid, the system of racial segregation i which South Africa's black majority has no vote in nationalaffairs.7.
AP880803-0158:26 South Africa says the ANC, the main black group fighting to overthrow South Africa's white-led government, has seven major military bases in Angola, and it wants those bases closed down.8.
AP880613-0126:15 The ANC is fighting to topple the South African government and its policy of apartheid,under which the nation's 26 million blacks have no voice in national affairs and the 5 million whites control theeconomy and dominate government.9.
AP880212-0060:13 The African National Congress i the main rebel movement fighting South Africa's white-ledgovernment and SWAPO is a black guerrilla group fighting for independence for Namibia, which is administeredby South Africa.I0.
WSJ870129-0051:1 Secretary of State George Shultz, in a meeting with Oliver Tambo, head of the AfricanNational Congress, voiced concerns about Soviet influence on the black South African group and the ANC's useof violence in the struggle against apartheid.Figure 2: Sample multi-document summary with A = 1, news-story-principle ordering (rank order)?
ernment is mentioned seven times (sentences #2,-#4,#6-#9),"which constitutes 70% of the sentences in the sum-mary.
Furthermore, sentence #3 is an exact duplicate ofsentence #2, and sentence #7 is almost identical to sen-tence #4.
In contrast, the summary in Figure 3, generatedusing MMR-MD with a value of A set to 0.3 shows sig-nificant improvements in eliminating redundancy.
Thefact that the ANC is fighting to overthrow the govern-ment is mentioned only twice (sentences #3,#7), and oneof these sentences has additional information in it.
Thenew summary retained only three of  the sentences fromthe earlier summary.Counting clearly distinct propositions in both cases,yields a 60% greater information content for the MMR-MD case, though both summaries are equivalent inlength.When these 200 documents were added to a set of 4other topics of 200 documents, yielding a document-setwith 1000 documents, the query relevant multi-documentsummarization system produced exactly the same re-suits.We are currently working on constructing datasetsforexperimental evaluations of multi-document summariza-tion.
In order to construct these data sets, we attemptedto categorize user's information seeking goals for multi-document summarization (see Section 3).
As can be seenin Figure 2, the standard IR technique of using a query toextract relevant passages i no longer sufficient for multi-document summarization due to redundancy.
In addi-tion, query relevant extractions cannot capture temporalsequencing.
The data sets will allow us to measure theeffects of these, and other features, on multi-documentsummarization quality.Specifically, we are constructing sets of 10 documents,?
which either contain a snapshot of  an event from mul-tiple sources or the unfoldment of an event over time.45II 1.
WSJ870129-0051 1 Secretary of State George Shultz, in a meeting with Oliver Tambo, head of the African Na-tional Congress, voiced concerns about Soviet influence on the black South African group and the ANC's use ofviolence in the struggle against apartheid.2.
wsJgg0422-0133 44 (See related story: "ANC: Apartheid' s Foes - The Long Struggle: The ANC Is Banned,But It Is in the Hearts of a Nation's Blacks - -  In South Africa, the Group Survives Assassinations, GovernmentCrackdowns n The Black, Green and Gold" - WSJ April 22, 1988)3.
AP880803-0158 26 South Africa says the ANC, the main black group fighting to overthrow South Africa's white-led government, has seven major military bases in Angola, and it wants those bases closed own.4.
AP880919-0052  But activist clergymen from South Africa said the pontiff should have spoken out more force-fully against their white-minority government's policies of apartheid, under which 26 million blacks have no sayin national affairs.5.
AP890821-0092 10 Besides ending the emergency and lifting bans on anti- apartheid groups and individual ac-tivists, the Harare summit's conditions included the removal of all troops from South Africa's black townships,releasing all political prisoners and ending political trials and executions, and a government commitment tofreepolitical discussion.6.
wsJg00503-0041 1  Pretoria and the ANC remain'far ap~t ontheir vision s for a post-apartheid South Africa:The ANC wants a simple one-man, one-vote majority rule system, while the government claims that will lead toblack domination and insists on constitutional protection of the rights of minorities, including the whites.7.
WSJ900807-0037 1 JOHANNESBURG, South Africa - The African National Congress uspended its 30-yeararmed struggle against he whiie minority government, clearing the way for the start of negotiations over a newconstitution based on black-white power sharing.8.
WSJ900924-011920 The African National Congress, South Africa's main black liberation group, forged its sanc-tions strategy as a means of pressuring the government toabandon white-minority rule.9.
WSJ910702-0053 36 At a, meeting in South Africa this week, the African National Congress, the major blackgroup, is expected to take a tough line again st the white-rnn government.10.
wsJg10204-01761 CAPE TOWN, South Africa - President EW.
de Klerk's proposal to repeal the major pillarsof apartheid rew a generally positive response from black leaders, but African National Congress leader NelsonMandela called on the international community to continue conomic sanctions against South Africa until thegovernment takes further steps.Figure 3: Sample multi-document summary with A = 0.3, time-line orderingFrom these sets we are performing two types of exper-iments.
In the first, we are examining how users putsentences into pre-defined clusters and how they createsentence based multi-document summaries.
The resultwill also serve as a gold standard for system generatedsummaries - do our systems pick the same summary sen-tences as humans and are they picking sentences fromthe same clusters as humans?
The second type Of exper-iment is designed to determine how users perceive theoutput summary quality.
In this experiment, users areasked to rate the output sentences from the summarizeras good, okay or bad.
For the okay or bad sentences,they are asked to provide a summary sentence from thedocument set that is "better", i.e., that makes a better setof  sentences to represent the information content of  thedocument set.
We are comparing our proposed summa-rizer #6 in Section 4 to summarizer #1, the common por-tions of  the document sets with no anti-redundancy andsummarizer #3, single document summary of  a centroiddocument using our single document summarizer (Gold-stein et al, 1999).7 Conc lus ions  and  Future  WorkThis paper presented a statistical method of  generatingextraction based multi-document summaries.
I t  buildsupon previous work in single-document summarizationand takes into account some of the major differences be-tween single-document and multi-document summariza-tion: (i) the need to carefully eliminate redundant infor-mation from multiple documents, and achieve high com-pression ratios, (ii) take into account information aboutdocument and passage similarities, and weight differentpassages accordingly, and (iii) take temporal informationinto account.Our approach differs from others in several ways: itis completely domain-independent, is based mainly onfast, statistical processing, it attempts to maximize thenovelty of the information being selected, and different46IIIIII!I!I!
!IiII!I!II!IIgenres or corpora characteristics an be taken into ac-count easily.
Since our system is not based on the use ofsophisticated natural language understanding or informa-tion extraction techniques, ummaries lack co-referenceresolution, passages may be disjoint from one another,and in some cases may have false implicature.In future work, we will integrate work on multi-document summarization with work on clustering to pro-vide summaries for clusters produced by topic detectionand tracking.
We also plan to investigate how to gen-erate coherent temporally based event summaries.
Wewill also investigate how users can effectively use multi-document summarization through interactive interfacesto browse and explore large document sets.ReferencesJames Allan, Jaime Carbonell, George Doddington,,Jonathan Yamron, and Yiming Yang.
1998.
Topic de-tection and tracking pilot study: Final report.
In Pro-ceedings of the DARPA Broadcast News Transcriptionand Understanding Workshop.Chinatsu Aone, M. E. Okurowski, J. Gorlinsky, andB.
Larsen.
1997.
A scalable summarization sys-tem using robust NLP.
In Proceedings of theACL'97/EACL'97 Workshop on Intelligent ScalableText Summarization, pages 66-73, Madrid, Spain.Breck Baldwin and Thomas S. Morton.
1998.
Dy-namic coreference-based summarization.
I Proceed-ings of the Third Conference on Empirical Methods inNatural Language Processing (EMNLP-3), Granada,Spain, June.Regina Barzilay and Michael Elhadad.
1997.
Using lex-ical chains for text summarization.
In Proceedings ofthe ACL'97/EACL'97 Workshop on Intelligent Scal-able Text Summarization, pages 10-17, Madrid, Spain.Branimir Boguraev and Chris Kennedy.
1997.
Saliencebased content characterization f text documents.
InProceedings of the ACL'97/EACL'97 Workshop onIntelligent Scalable Text Summarization, pages 2-9,.Madrid, Spain.Chris Buckley.
1985.
Implementation f the SMART in-formation retrieval system.
Technical Report TR 85-686, Cornell University.Jaime G. Carbonell and Jade Goldstein.
1998.
Theuse of MMR, diversity-based reranking for reorderingdocuments and producing summaries.
In Proceedingsof SIGIR-98, Melbourne, Australia, August.Jade Goldstein and Jaime Carbonell.
1998.
The useof mmr and diversity-based reranking in documentreranking and summarization.
In Proceedings of the14th Twente Workshop on Language Technology inMultimedia Information Retrieval, pages 152-166,Enschede, the Netherlands, December.Jade Goldstein, Mark Kantrowitz, Vibhu O. Mittal, and?
Jaime G. Carbonell.
1999.
Summarizing Text Doc-uments: Sentence Selection and Evaluation Metrics.Irf Proceedings of the 22nd International ACM SIGIRConference on Research and Development in Informa-tion Retrieval (S1G1R-99), pages 121-128, Berkeley,CA.Eduard Hovy and Chin-Yew Lin.
1997.
Automated textsummarization i SUMMARIST.
In ACUEACL-97Workshop on Intelligent Scalable Text Summarization,pages 18-24, Madrid, Spain, July.Judith L. Klavans and James Shaw.
1995.
Lexical se-mantics in summarization.
I  Proceedings of the FirstAnnual Workshop of the IFIP Working Group FORNLP and KR, Nantes, France, April.Julian M. Kupiec, Jan Pedersen, and Francine Chen.1995.
A trainable document summarizer.
In Proceed-ings of the 18th Annual Int.
ACM/SIG1R Coaferenceon Research and Development in IR, pages 68-73,Seattle, WA, July.P.
H. Luhn.
1958.
Automatic reation of literature ab-stracts.
IBM Journal, pages 159-165.Inderjeet Mani and Eric Bloedern.
1997.
Multi-document summarization by graph search and merg-ing.
In Proceedings of AAA1-97, pages 622--628.AAAI.Inderjeet Mani and Eric Bloedom.
1999.
Summarizingsimilarities and differences among related ocuments.Information Retrieval, 1:35-67.Daniel'Marcu.
1997.
From discourse structures to textsummaries.
In Proceedings of the ACL'97/EACL'97Workshop on Intelligent Scalable Text Summarization,pages 82-88, Madrid, Spain.Kathleen McKeown, Jacques Robin, and Karen Kukich.1995.
Designing and evaluating a new revision-basedmodel for summary generation.
Info.
Proc.
and Man-agement, 31 (5).Kathleen McKeown, Judith Klavans, Vasileios Hatzivas-siloglou, Regina Barzilay, and Eleazar Eskin.
1999.Towards Multidocument Summarization by Reformu-lation: Progress and Prospects.
In Proceedings ofAAAI-99, pages 453--460, Orlando, FL, July.Mandar Mitra, Amit Singhal, and Chris Buckley.
1997.Automatic text summarization by paragraph extrac-tion.
In ACL/EACL-97 Workshop on Intelligent Scal-able Text Summarization, pages 31-36, Madrid, Spain,July.Chris D. Paice.
1990.
Constructing literature abstractsby computer: Techniques and prospects.
Info.
Proc.and Management, 26:171-186.Dragomir Radev and Kathy McKeown.
1998.
Generat-ing natural language summaries from multiple onlinesources.
Compuutational Linguistics.Gerald Salttm.
1970.
Automatic processing of foreignlanguage docuemnts.
Journal of American Society forInformation Sciences, 21:187-194.Gerald Salton.
1989.
Automatic Text Processing: TheTransformation, Analysis, and Retrieval of Informa-tion by Computer.
Addison-Wesley.47James Shaw.
1995.
Conciseness through aggregation itext generation.
In Proceedings of 33rd Associationfor Computational Linguistics, pages 329-331.Gees C. Stein, Tomek Strzalkowski, and G. BowdenWise.
1999.
Summarizing Multiple Documents Us-ing Text Extraction and Interactive Clustering.
In Pro-ceedings of PacLing-99: The Pacific Rim Conferenceon Computational Linguistics, pages 200-208, Water-loo, Canada.Tomek Strzalkowski, Jin Wang, and Bowden Wise.1998.
A robust practical text summarization system.In AAAI Intelligent Text Summarization Workshop,pages 26-30, Stanford, CA, March.J.
I. Tait.
1983.
Automatic Summarizing of EnglishTexts.
Ph.D. thesis, University of Cambridge, Cam-bridge, UK.Simone Teufel and Marc Moens.
1997.
Sentence x-traction as a classification task.
In ACL/EACL-97Workshop on Intelligent Scalable Text Summarization,pages 58-65, Madrid, Spain, July.TIPSTER.
1998a.
Tipster text phase III 18-month work-shop notes, May.
Fairfax, VA.TIPSTER.
1998b.
Tipster text phase III 24-month work-shop notes, October.
Baltimore, MD.Charles J. van Rijsbergen.
1979.
Information Retrieval.Butterworths, London.Yiming Yang, Tom Pierce, and Jaime 13.
Carbonell.1998.
A study on retrospective and on-line event de-tection.
In Proceedings of the 21th Ann lnt ACM SI-G1R Conference on Research and Development inIn-formation Retrieval (SIGIR'98), pages 28-36.:Yiming Yang, Jaime G. Carbonell, Ralf D. Brown,Tom Pierce, Brian T. Archibald, and Xin Liu.
1999.Learning approaches for topic detection and tracking.
news events.
IEEE Intelligent Systems, Special Issueon Applications of Intelligent Information Retrieval,14(4):32-43, July/August.48
