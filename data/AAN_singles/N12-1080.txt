2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 631?635,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsSummarization of Historical Articles Using Temporal Event ClusteringJames GungDepartment of Computer ScienceMiami UniversityOxford, Ohio 45056gungjm@muohio.eduJugal KalitaDepartment of Computer ScienceUniversity of ColoradoColorado Springs CO 80920jkalita@uccs.eduAbstractIn this paper, we investigate the use of tempo-ral information for improving extractive sum-marization of historical articles.
Our methodclusters sentences based on their timestampsand temporal similarity.
Each resulting clus-ter is assigned an importance score whichcan then be used as a weight in traditionalsentence ranking techniques.
Temporal im-portance weighting offers consistent improve-ments over baseline systems.1 IntroductionExtensive research has gone into determiningwhich features of text documents are useful for cal-culating the importance of sentences for extractivesummarization, as well as how to use these features(Gupta and Lehal, 2010).
Little work, however, hasconsidered the importance of temporal informationtowards single document summarization.
This islikely because many text documents have very fewexplicit time features and do not necessarily describetopics in chronological order.Historical articles, such as Wikipedia articles de-scribing wars, battles, or other major events, tend tocontain many explicit time features.
Historical arti-cles also tend to describe events in chronological or-der.
In addition, historical articles tend to focus on asingle central event.
The importance of other eventscan then be judged by their temporal distance fromthis central event.
Finally, important events in an ar-ticle will be described in greater detail, employingmore sentences than less important events.This paper investigates the value of a temporal-based score towards automatic summarization,specifically focusing on historical articles.
We in-vestigate whether or not such a score can be used asa weight in traditional sentence ranking techniquesto improve summarization quality.2 Related WorkEvent-based summarization is a recent approachto summary generation.
(Filatova and Hatzivas-siloglou, 2004) introduced atomic events, which arenamed entities connected by a relation such as a verbor action noun.
Events are selected for summary byapplying a maximum coverage algorithm to mini-mize redundancy while maintaining coverage of themajor concepts of the document.
(Vanderwende etal., 2004) identify events as triples consisting of twonodes and a relation.
PageRank is then used to de-termine the relative importance of these triples rep-resented in a graph.
Sentence generation techniquesare applied towards summarization.Limited work has explored the use of temporalinformation for summarization.
(Lim et al, 2005)use the explicit time information in the context ofmulti-document summarization for sentence extrac-tion and detection of redundant sentences, orderinginput documents by time.
They observe that impor-tant sentences tend to occur in in time slots contain-ing more documents and time slots occurring at theend and beginning of the documents set.
They se-lect topic sentences for each time slot, giving higherweights based on the above observation.
(Wu et al, 2007) extract event elements, the ar-guments in an event, and event terms, the actions.Each event is placed on a timeline divided into in-tervals consistent with the timespan of the article.Each element and event term receives a weight cor-responding to the total number of elements and eventterms located in each time interval the event elementor term occupies.
Each sentence is scored by the to-tal weight of event elements and terms it contains.Clustering of events based on time has also re-ceived little attention.
(Foote and Cooper, 2003) in-vestigate clustering towards organizing timestampeddigital photographs.
They present a method that first631calculates the temporal similarity between all pairsof photographs at multiple time scales.
These valuesare stored in a chronologically ordered matrix.
Clus-ter boundaries are determined by calculating noveltyscores for each set of similarity matrices.
These areused to form the final clusters.
We adopt this clus-tering method for clustering timestamped sentences.3 ApproachThe goal of our method is to give each sentencein an article a temporal importance score that canbe used as a weight in traditional sentence rankingtechniques.
To do this, we need to gain an ideaof the temporal structure of events in an article.
Ascore must then be assigned to each group corre-sponding to the importance of the group?s timespanto the article as a whole.
Each sentence in a partic-ular group will be assigned the same temporal im-portance score, necessitating the use of a sentenceranking technique to find a complete summary.3.1 Temporal Information ExtractionWe use Heideltime, a rule-based system thatuses sets of regular expressions, to extract explicittime expressions in the article and normalize them(Stro?tgen and Gertz, 2010).
Events that occur be-tween each Heideltime-extracted timestamp are as-signed timestamps consisting of when the priortimestamp ends and the subsequent timestamp be-gins.
The approach is naive and is described in(Chasin et al, 2011).
This method of temporal ex-traction is not reliable, but serves the purposes oftesting as a reasonable baseline for temporal extrac-tion systems.
As the precision increases, the perfor-mance of our system should also improve.3.2 Temporal ClusteringTo cluster sentences into temporally-relatedgroups, we adopt a clustering method proposed byFoote et al to group digital photograph collections.Inter-sentence similarity is calculated between ev-ery pair of sentences using Equation (1).SK(i, j) = exp(?|ti ?
tj |K)(1)The similarity measure is based inversely on thedistance between the central time of the sentences.Similarity scores are calculated at varying granular-ities.
If the article focuses on a central event thatFigure 1: Similarity matrices at varying k displayed asheat maps, darker representing more similar entriesoccurs over only a few hours, such as the assassi-nation of John F. Kennedy, the best clustering willgenerally be found from similarities calculated us-ing a smaller time granularity.
Conversely, articleswith central events spanning several years, such asthe American Civil War, will be clustered using sim-ilarities calculated at larger time granularities.The similarities are placed in a matrix and orga-nized chronologically in order of event occurrencetime.
In this matrix, entries close to the diagonalare among the most similar and the actual diagonalentries are maximally similar (diagonal entries cor-respond to similarities between the same sentences).To identify temporal event boundaries, (Foote andCooper, 2003) calculate novelty scores.
A checker-board kernel in which diagonal regions contain allpositive weights and off-diagonal regions contain allnegative weights is correlated along the diagonal ofthe similarity matrix.
The weights of each entry inthe kernel are calculated from a Gaussian functionsuch that the most central entries have the highest (orlowest in the off-diagonal regions) values.
The resultis maximized when the kernel is located on tempo-ral event boundaries.
In relatively uniform regions,the positive and negative weights cancel each otherout, resulting in small novelty scores.
Where thereis a gap in similarity, presumably at an event bound-ary, off diagonal squares are dissimilar, increasingthe novelty score.
In calculating novelty scores witheach set of similarity scores, we obtain a hierarchi-cal set of boundaries.
With each time granularity, wehave a potential clustering option.In order to choose the best clustering, we calcu-late a confidence score C for each boundary set,then choose the clustering with the highest score, assuggested in (Foote and Cooper, 2003).
This scoreis the sum of intercluster similarities (IntraS) be-tween adjacent clusters subtracted from the sum ofintracluster (InterS) similarities as seen in Equa-tion (4).
A high confidence score suggests low inter-632cluster similarity and high intracluster similarity.IntraS(BK)S =|Bk|?1?l=1bl+1?i,j=blSK(i, j)(bl+1 ?
bl)2(2)InterS(BK)S =|Bk|?2?l=1bl+1?i=blbl+2?j=bl+1SK(i, j)(bl+1 ?
bl)(bl+2 ?
bl+1)(3)CS(BK) = IntraS(BK)S ?
InterSBK)S (4)3.3 Estimating Clustering ParamatersHistorical articles describing wars generally havemuch larger timespans than articles describing bat-tles.
Looking at battles at a broad time granularityapplicable to wars may not produce a meaningfulclustering.
Thus, we should estimate the temporalstructure of each article before clustering.
The timegranularity for each clustering is controlled by thek parameter in the similarity function between sen-tences.
To find multiple clusterings, we start at abase k, then increment k by a multiplier for each newclustering.
We calculate the base k using the stan-dard deviation for event times in the article.
Mea-suring the spread of events in the article gives us anestimate of what time scale we should use.3.4 Calculating Temporal ImportanceWe use three novel metrics to calculate the impor-tance of a cluster towards a summary.
The first met-ric is based on the size of the cluster (Eqn 5).
Thisis motivated by the assumption that more importantevents will be described in greater detail, thus pro-ducing larger clusters.
The second metric (Eqn 6) isbased on the distance from the cluster?s centroid tothe centroid of the largest cluster, corresponding tothe central event of the article.
This metric is moti-vated by the assumption that historical articles havea central event which is described in the greatest de-tail.
The third metric is based on the spread of thecluster (Eqn 7).
Clusters with large spreads are un-likely to pertain to the same event, and should there-fore be penalized.Size(Ci) =|Ci||Cmax|(5)Sim(Ci) = exp(?|tCiCentroid ?
tMaxClusterCentroid|m)(6)Spread(Ci) = exp(?
?Cin ?
(tmax ?
tmin))(7)The parameters m and n serve to weight the impor-tance of these measures and are assigned based onthe spread of events in an article.
For n, we used thestandard deviation of event times in the article.
Form, we used the cluster similarity score from Equa-tion (4).
The three measures work in tandem to en-sure that the importance measure will be valid evenif the largest cluster does not correspond to the cen-tral event of the article.3.5 Final Sentence RankingEach sentence is assigned a temporal importanceweight equal to the importance score of the clus-ter to which it belongs.
To find a complete rankingof the sentences, we apply a sentence ranking tech-nique.
Any automatic summarization technique thatranks its sentences with numerical scores can poten-tially be augmented with our temporal importanceweight.
We multiply the base scores from the rank-ing by the associated temporal importance weightsfor each sentence to find the final ranking.WS(Vi) = (1?
d) (8)+d ?
?Vj?In(Vi)wj,i?vk?Out(Vj)wj,kWS(Vj)Like several graph-based methods for sentence rank-ing for summarization (e.g., (Erkan and Radev,2004)), we use Google?s PageRank algorithm(Equation 8) with a damping factor d of 0.85.Similarity(Si, Sj) =|{wk|wk ?
Si&wk ?
Sj}|log(|Si|) + log(|Sj |)(9)We use TextRank (Mihalcea and Tarau, 2004) inour experiments.
Our similarity measure is calcu-lated using the number of shared named entities andnouns between sentences as seen in equation 9.
Foridentification of named entities, we use StanfordNER (Finkel et al, 2005).
It is straightforward toweight the resulting TextRank scores for each sen-tence using their cluster?s temporal importance.4 Experimental ResultsWe test on a set of 13 Wikipedia articles describ-ing historical battles.
The average article length is189 sentences and 4,367 words.
The longest ar-ticle is 545 sentences and contains 11,563 words.The shortest article is 51 sentences and contains6331,476 words.
Each article has at least two human-annotated gold standard summaries.
Volunteerswere asked to choose the most important sentencesfrom each article.
We evaluate using ROUGE-2 bi-gram matching (Lin, 2004).4.1 ClusteringEach Wikipedia article contains a topic sentencestating the timespan of the main event in the article.This provides an easy way to determine whether aclustering is successful.
If the largest cluster con-tains the timespan of the main event described bythe topic sentence, we consider the clustering to besuccessful.
The articles vary greatly in length.
Also,the ratio of sentences with time features to sentenceswithout is considerably varied.
In 92% of the arti-cles, there were successful clusterings.
An exam-ple of an article that didn?t cluster is Nickel Grass,where the main event was divided into two clusters.It is of interest to note that this article had one oflowest time feature to sentence ratios, which possi-bly explains the poor clustering.4.2 Temporal Importance WeightingWe test our TextRank implementation with andwithout temporal importance weighting.We observe improvements in general using theTextRank system with temporal importance weight-ing.
The ROUGE-2 score increased by 15.72%across all the articles.
The lowest increase was0% and the highest was 128.86%.
The averageROUGE-2 scores were 0.2575 weighted and 0.2362unweighted, a statistically significant increase witha 95% confidence interval of 0.0066 to 0.0360.In particular, we see significant improvementsin articles that contain sentences TextRank rankedhighly but have events occurring at significantly dif-ferent times than the central event of the article.
Al-though the content of these sentences is highly re-lated to the rest of the article, they should not beincluded in the summary since their events happennowhere near the main event temporally.Our random ranking system, which randomlyassigns base importance scores to each sentence,observed only small improvements, of 4.27% onaverage, when augmented with temporal impor-tance weighting.
It is likely that additional human-annotated summaries are necessary for conclusiveresults.5 Conclusions and Future WorkThe novelty-based clustering method worked ex-tremely well for our purposes.
These results canlikely be improved upon using more advanced tem-poral extraction and interpolation methods, since weused a naive method for interpolating between timefeatures prone to error.
The temporal importanceweighting worked very well with TextRank and rea-sonably well with random ranking.It may also be fairly easy to predict the success ofusing this temporal weight a priori to summarizationof an article.
A small ratio of explicit time features tosentences (less than 0.15) indicates that the temporalinterpolation process may not be very accurate.
Thelinearity of time features is also a good indicationof the success of temporal extraction.
Finally, thespread of time features in an article is a clue to thesuccess of our weighting method.AcknowledgementsResearch reported here has been funded partiallyby NSF grants CNS-0958576 and CNS-0851783.ReferencesR.
Chasin, D. Woodward, and J. Kalita, 2011.
MachineIntelligence: Recent Advances, chapter Extracting andDisplaying Temporal Entities from Historical Articles.Narosa Publishing, Delhi.G.
Erkan and D.R.
Radev.
2004.
Lexrank: Graph-basedlexical centrality as salience in text summarization.
J.Artif.
Intell.
Res., 22:457?479.E.
Filatova and V. Hatzivassiloglou.
2004.
Event-basedextractive summarization.
In ACL Workshop on Sum-marization.J.R.
Finkel, T. Grenager, and C. Manning.
2005.
In-corporating non-local information into information ex-traction systems by gibbs sampling.
In ACL, pages363?370.J.
Foote and M. Cooper.
2003.
Media segmentation us-ing self-similarity decomposition.
In SPIE, volume5021, pages 167?175.V.
Gupta and G.S.
Lehal.
2010.
A survey of text sum-marization extractive techniques.
Journal of EmergingTechnologies in Web Intelligence, 2(3):258?268.J.M.
Lim, I.S.
Kang, J.H.
Bae, and J.H.
Lee.
2005.
Sen-tence extraction using time features in multi-documentsummarization.
Information Retrieval Technology,pages 82?93.634C.Y.
Lin.
2004.
Rouge: A package for automatic evalu-ation of summaries.
In Workshop on text summariza-tion, pages 25?26.R.
Mihalcea and P. Tarau.
2004.
Textrank: Bringingorder into texts.
In EMNLP, pages 404?411.J.
Stro?tgen and M. Gertz.
2010.
Heideltime: High qual-ity rule-based extraction and normalization of tempo-ral expressions.
In 5th International Workshop on Se-mantic Evaluation, pages 321?324.L.
Vanderwende, M. Banko, and A. Menezes.
2004.Event-centric summary generation.
Working notes ofDUC.M.
Wu, W. Li, Q. Lu, and K.F.
Wong.
2007.
Event-based summarization using time features.
Compu-tational Linguistics and Intelligent Text Processing,pages 563?574.635
