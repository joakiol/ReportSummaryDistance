Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 48?57,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsLemmatization and Morphosyntactic Tagging of Croatian and SerbianZ?eljko Agic??
Nikola Ljubes?ic??
Danijela Merkler?
?Department of Information and Communication Sciences?Department of LinguisticsFaculty of Humanities and Social Sciences, University of ZagrebIvana Luc?ic?a 3, 10000 Zagreb, Croatiazagic@ffzg.hr nljubesi@ffzg.hr dmerkler@ffzg.hrAbstractWe investigate state-of-the-art statisticalmodels for lemmatization and morphosyn-tactic tagging of Croatian and Serbian.The models stem from a new manuallyannotated SETIMES.HR corpus of Croa-tian, based on the SETimes parallel cor-pus.
We train models on Croatian textand evaluate them on samples of Croat-ian and Serbian from the SETimes corpusand the two Wikipedias.
Lemmatizationaccuracy for the two languages reaches97.87% and 96.30%, while full morphosyn-tactic tagging accuracy using a 600-tagtagset peaks at 87.72% and 85.56%, respec-tively.
Part of speech tagging accuraciesreach 97.13% and 96.46%.
Results indicatethat more complex methods of Croatian-to-Serbian annotation projection are not re-quired on such dataset sizes for these par-ticular tasks.
The SETIMES.HR corpus, itsresulting models and test sets are all madefreely available.1 IntroductionPart of speech tagging (POS tagging) is an natu-ral language processing task in which words areannotated with the corresponding grammatical cate-gories ?
parts of speech: verb, noun, adjective, pro-noun, etc.
?
in a given context.
It is also frequentlycalled morphosyntactic tagging (MSD tagging, i.e.,tagging with morphosyntactic descriptions), espe-cially when addressing highly inflected languages,for which the tagging process often includes as-signing additional subcategories to words, such asgender and case for nouns or tense and person forverbs.
POS/MSD tagging is a well-known task andan important preprocessing step in natural languageprocessing.
It is often preceded or followed bylemmatization ?
the process of mapping inflectedword forms to corresponding base forms or lemmas.State of the art in POS/MSD tagging and lemma-tization across languages is generally achieved ?both in terms of per token accuracy and speed androbustness ?
by statistical methods, which involvetraining annotation models on manually annotatedcorpora.In this paper, we investigate the possibility of uti-lizing statistical models trained on corpora of Croa-tian in lemmatization and MSD tagging of Croatianand Serbian.
We present a new manually annotatedcorpus of Croatian ?
the SETIMES.HR corpus.
Wetest a number of lemmatizers and MSD taggers onCroatian and Serbian test sets from two differentdomains and consider options of annotation trans-fer between the two languages.
We also outline afirst version of the Multext East v5 tagset and threeusable reductions of this tagset.
Special emphasisis given to rapid resource development and publicavailability of our research.
Thus, the SETIMES.HRcorpus, the test sets and the best lemmatization andMSD tagging models are made publicly available.1In the following section, we discuss related workon lemmatization and tagging of Croatian and Ser-bian.
We then present the SETIMES.HR corpus andthe test sets, selected lemmatizers and morphosyn-tactic taggers and the experimental method.
Finallywe provide a discussion of the evaluation resultsand indicate future work directions.2 Related workThe task of tagging English sentences with parts ofspeech is generally considered a closed issue.
Thisis due to the fact that, over the course of the past 11years, from (Brants, 2000) to (S?gaard, 2011), thecurrent state of the art in tagging English has im-proved by 1.04 ?
to 97.50% in terms of per tokenaccuracy.
This is, however, not the case for lan-guages with richer morphology and free sentence1http://nlp.ffzg.hr/resources/models/48word order, such as Croatian and Serbian.Current state of the art for statistical MSD tag-ging of Croatian is reported at 86.05% (Agic?
etal., 2008).
It involves a hidden Markov model tri-gram tagger CroTag, trained on the Croatia Weekly100 thousand wordform (100 kw) subcorpus ofCroatian newspaper text from Croatian NationalCorpus (Tadic?, 2009), manually MSD-tagged andlemmatized using the Multext East v3 tagset (MTEv3) (Erjavec, 2004) and Croatian LemmatizationServer (Tadic?, 2005) for guided annotation.
Thetagger is not publicly available.
Just recently, theCroatia Weekly corpus has been made publiclyavailable through META-SHARE.2 Another line ofresearch reports on a prototype constraint grammartagger for Croatian (Peradin and S?najder, 2012),which scores at 86.36% using a MTE-based tagset.This tagger is also not publicly available as it is inprototype stage and it currently does not analyzeout-of-vocabulary word forms.
The top score forlemmatizing Croatian text is reported at 96.96%by combining CroTag and Croatian MorphologicalLexicon (Agic?
et al 2009).
The lemmatizer is notpublicly available.Lemmatization and tagging of Serbian textwas recently addressed in (Gesmundo andSamardz?ic?, 2012a; Gesmundo and Samardz?ic?,2012b).
It involves BTagger, a combined bidirec-tional tagger-lemmatizer tool which implements alemmatization-as-tagging paradigm.
Models aretrained on the Serbian Multext East 1984 corpus,they are publicly available3 under a permissive li-cense, reaching overall accuracies of 97.72% forlemmatization and 86.65% for MSD tagging.
Itshould be noted, however, that BTagger evaluationin terms of spatial and temporal complexity was notdocumented and that the results provided for Ser-bian are obtained on specific in-domain data, i.e.,a corpus of fiction and are thus not directly com-parable to, e.g., results for Croatian on the CroatiaWeekly newspaper corpus.Other lines of research in Serbian lemmatizationand tagging exists.
Delic?
et al(2009) deals withtransformation-based tagging of Serbian text, butit does not provide state-of-the-art results or freelyavailable resources.
Rule-based approaches to pro-cessing Serbian using NooJ 4 and similar linguisticdevelopment environments have been thoroughly2http://metashare.elda.org/3https://github.com/agesmundo/BTagger4http://www.nooj4nlp.net/explored (Vitas et al 2003).
Several resources rel-evant for Serbian lemmatization and tagging areprovided to the public.
The Serbian version ofJules Verne 60 kw manually lemmatized and MTE-tagged corpus implements a small deviation fromMTE v4 and deals with specific fictional closed-vocabulary data.
SrpLemKor is a 3.7 Mw corpus ofSerbian newspaper text, automatically lemmatizedand POS-tagged using TreeTagger (Schmid, 1995)with a tagset of 16 POS tags.
A morphological dic-tionary of 85 thousand Serbian lemmas with sligtlydeviated MTE v4 tagset is available through NooJ.Public availability of these resources is enabledthrough META-SHARE, with somewhat more re-strictive licensing that involves non-commercialuse in all cases and for some of them it also im-poses no redistribution.Related work on lemmatizer and tagger compar-ison exists for many languages.
Restraining thesearch to closely related Slavic languages, exten-sive work in this domain has been done for Bul-garian (Georgiev et al 2012), Czech (Spoustova?et al 2007) and Slovene (Erjavec and Dz?eroski,2004; Rupnik et al 2008).
For Croatian, prelim-inary work on tagger evaluation for tagger votinghas been conducted (Agic?
et al 2010).3 SETIMES.HR corpusSETIMES.HR is a new manually lemmatized andMSD-tagged corpus of Croatian.
It is built on topof the SETimes parallel newspaper corpus involv-ing 10 languages from the SEE region,5 Croatianand Serbian included.
This initial dataset selectionwas deliberate in terms of enabling us with possibil-ity of cross-lingual annotation projection and othercross-lingual experiments.
SETIMES.HR was anno-tated by experts using the Croatian LemmatizationServer (HML)6 (Tadic?, 2005) to facilitate the pro-cess.
We made a number of changes to the initialannotation provided by human annotators.
Namely,HML provides MSD tags using an undocumentedalteration of the initial MTE tagset, which we cor-rected to conform entirely to the MTE v4 standard(Erjavec, 2012).
Also, for certain lemmas HMLprovides lemmatization with morphosemantic cuesencoded by lemma numbering ?
e.g.
biti1 (en.
tobe) and biti2 (en.
to beat) ?
which we omitted asthey are used only in the process of generating themorphological lexicon (Tadic?
and Fulgosi, 2003)5http://www.nljubesic.net/resources/corpora/setimes/6http://hml.ffzg.hr49Corpus Sent?s Tokens Types LemmasSETIMES.HR 4 016 89 785 18 089 8 930set.test.hr 100 2 297 1 270 991set.test.sr 100 2 320 1 251 981wiki.test.hr 100 1 887 1 027 802wiki.test.sr 100 1 953 1 055 795Table 1: Stats for SETIMES.HR and test setsand are thus not required for purposes of lemmati-zation and MSD tagging.
We make the resulting 90kw SETIMES.HR corpus, along with the four testsets, publicly available under the CC-BY-SA-3.0license.7 Corpus stats are given in Table 1.For purposes of this experiment, we propose analteration of the baseline MTE v4 tagset in formof a first version for the MTE v5 standard.8 Thebiggest changes in the new version are participal ad-jectives and adverbs moving from the verbal subset?
which was very complex in v4 ?
to the adjectivaland adverbial subsets.
Additionally, acronyms aremoved from the abbreviation subset to the nounsubset.
A general shrinking of the length of manytags was performed as well because from v4 on-wards the MTE standard does not require one tagsetfor all languages in the standard.
We also suggestthree reductions of the suggested MTE v5 tagset:1. without adjective definiteness (v5r1),2. without common (Nc) vs. proper (Np) distinc-tion for nouns (v5r2) and3.
without both (v5r3).Adjectival definiteness is a category which is easyto implement in a morphological lexicon, but isvery hard to distinguish in context as many of itsvariants are homographs.
We question the distinc-tion between common and proper nouns as wellsince they are contextually very hard to discrimi-nate.
On the other hand, some foreign proper nounsare inflected by specific paradigms and suffix triesused on unknown words could profit from this dis-tinction.
Stats for the MTE v5 and the reducedtagset versions in comparison with the baselineMTE v4 tagset version of SETIMES.HR are givenin Table 2.
They reflect the design choices wemade: MTE v5 has a comparable amount of tagsas MTE v4, gaining additional tags in the adjectivesubset, but losing tags in the verb and abbreviationsubsets, while the reductions subsequently lowerthe overall MSD tag count.7http://creativecommons.org/licenses/by-sa/3.0/8http://nl.ijs.si/ME/V5/msd/html/set.test wiki.testTagset SETIMES.HR hr sr hr srMTE v4 660 235 236 188 192MTE v5 663 233 234 192 195MTE v5r1 618 213 216 176 180MTE v5r2 634 216 217 178 181MTE v5r3 589 196 199 162 166Table 2: Tagset variation in tag counts4 Experiment setupIn this section, we define specific experiment goalsand the experiment design.
We also present thedatasets and tools used in the experiment.4.1 ObjectivesThe principal goal of this experiment is to provideprospective users with freely available ?
download-able, retrainable and usable, both for research pur-poses and for commercial use ?
state-of-the-artlemmatization and tagging modules for Croatianand Serbian.
An additional goal of our experi-ment is to inspect lemmatization and tagging toolsavailable under permissive licenses and give anoverview regarding their accuracy and time com-plexity when used on languages of morphologicalcomplexity such as Croatian and Serbian.Regarding the previously discussed constraintson existing corpora and tools for Croatian and Ser-bian tagging and lemmatization, our objective im-plies exclusive usage of the SETIMES.HR corpus inthe experiment.9 Since SETIMES.HR is part of theSETimes parallel corpus which, among other lan-guages, includes both Croatian and Serbian, manu-ally annotated SETIMES.HR text has a freely avail-able Serbian equivalent.
Our first course of actionwas thus to train a number of taggers and lemma-tizers on SETIMES.HR and test it on Croatian andSerbian held out text to verify state-of-the-art ac-curacy on Croatian text and to observe whetherthe expected decline in accuracy on Serbian text issubstantial or not.In case of substantial decrease in accuracy forlemmatizing and tagging Serbian using Croatianmodels, we designed multiple schemes for project-ing annotation from SETIMES.HR to its Serbian9Considering corpora of Croatian and Serbian stated inrelated work, we chose not to use non-MTE resources andcorpora of fiction as an experiment basis.
Importance of en-coding the full set of morphological features from the MTEtagset is illustrated by its benefits for dependency parsing ofCroatian (Agic?
and Merkler, 2013).50equivalent from the SETimes parallel corpus.
Thegeneral directions for identifying the bitext sub-set for annotation projection were using parallelsentences which have the highest longest commonsubsequence or using statistical machine transla-tion to produce Serbian sentences with minimumdifference to the Croatian counterpart.
Projectingtags on a bitext of high similarity would includeheuristics of annotating the variation with the samemorphosyntactic category if the variation was onetoken long or annotating it with the existing modelfor tagging if the variation was longer than that.Lemmatization of the single-token variation wouldbe reapplied if the token ending in both languageswas identical while other cases would be annotatedwith the existing lemmatization model.4.2 Experiment workflowWe do four batches of experiments:1. to identify the best available tool and underly-ing paradigm for lemmatization and taggingof both languages by observing overall accu-racy and execution time,2.
to establish the need for annotation projec-tion from Croatian SETIMES.HR corpus to itsSerbian counterpart,3.
to select the best of the proposed MTE-basedtagsets for both tasks and4.
to provide in-depth evaluation of the selectedtop-performing lemmatizer and tagger on bothlanguages by using the top-performing tagset.In the first experiment batch, we test the tools onlyon Croatian data from SETimes.
The second batchestablishes the need for ?
or needlessness of ?
an-notation projection for improved processing of Ser-bian text by testing the tools selected in the firstbatch on both languages.
The in-depth evaluationof the third and fourth experiment batch includes,for both languages and all test sets, observing theinfluence of tagset selection to overall accuracy andinvestigating tool performance in more detail.
Wemeasure precision, recall and F1 scores for selectedparts of speech and inspect lemmatization and tag-ging confusion matrices for detailed analysis andpossible prediction of tool operation in real-worldlanguage processing environments.We aim for the experiment to serve as underly-ing documentation for enabling prospective usersin implementing more complex natural languageprocessing systems for Croatian and Serbian by us-ing these resources.
Additionally, the overview ofthe usability of tools available is informative for re-searchers developing basic language technologiesfor other languages.
We test statistical significanceof observed differences in our results by using theapproximate randomization test.4.3 DatasetsAll models are trained on SETIMES.HR.
To atleast partially avoid the possible pitfall of exclu-sive in-domain testing, we define two test sets foreach language.
The first test set consists of 100Croatian-Serbian parallel sentence pairs taken byrandom sampling from the relative complementof the SETimes parallel corpus and SETIMES.HR.The second test set is taken from the Croatian andSerbian Wikipedia by manually selecting 20 match-ing Wikipedia articles and manually extracting 100approximate sentence pairs.
We chose manual overrandom sampling from Wikipedia to account forthe fact that a certain number of articles is virtu-ally identical between the two Wikipedias due tolanguage similarity and mutual copying betweenWikipedia users.
All four test sets were manuallyannotated using the same procedure that was usedfor SETIMES.HR.
The stats are given in Table 1.
Inaddition, we have verified the difference betweenlanguage test sets by measuring lexical coverageusing HML as a high-coverage morphological lex-icon of Croatian.
For the Croatian SETimes andWikipedia samples, we detected 5.2% and 3.9%out-of-vocabulary word forms and 11.40% and8.86% were observed for the corresponding Ser-bian samples, supporting well-foundedness of thetest sets in terms of maintaining the differencesbetween the two languages.4.4 Lemmatizers and taggersAs lemmatizers and taggers with permissive licens-ing schemes and documented cross-lingual state-of-the-art performance have become largely available,we chose not to implement our own but to obtain aset of tools and test them using our data, i.e., trainthem on the SETIMES.HR corpus and test themon Croatian and Serbian SETimes and Wikipediatest samples.
We selected the tools on the basis ofavailability and underlying stochastic paradigms asto identify the best tools and best paradigms.We tested hidden Markov model trigram taggersHunPos10 (Hala?csy et al 2007) and lemmatization-capable PurePos11 (Orosz and Nova?k, 2012),10https://code.google.com/p/hunpos/11https://github.com/ppke-nlpg/purepos51Tool Lem.
MSD Train (sec) Test (sec)BTagger 96.22 86.63 24 864.47 87.01CST 97.78 ?
1.80 0.03+ lex 97.04 ?
1.87 0.12HunPos ?
87.11 1.10 0.11+ lex ?
84.81 10.79 0.45PurePos 74.40 86.63 5.49 4.42SVMTool ?
84.99 1 897.08 3.28TreeTagger 90.51 85.07 7.49 0.19+ lex 94.12 87.01 17.48 0.31Table 3: Preliminary evaluationlemmatization-capable decision-tree-based Tree-Tagger12 (Schmid, 1995), support vector machinetagger SVMTool13 (Gime?nez and Ma`rquez, 2004)and CST?s14 data-driven rule-based lemmatizer (In-gason et al 2008).
Keeping in mind the previouslymentioned state-of-the-art scores on Serbian 1984corpus and statistical lemmatization capability, wealso tested BTagger (Gesmundo and Samardz?ic?,2012a; Gesmundo and Samardz?ic?, 2012b).
Sincesome lemmatizers and taggers are capable of usingan external morphological lexicon, we used a MTEv5r1 version of Apertium?s lexicon of Croatian15(Peradin and Tyers, 2012) where applicable.16 Alltools are well-documented and successfully appliedacross languages, as indicated in related work.5 Results and discussionA discussion of the experiment results follows inthe next four subsections.
Each subsection repre-sents one batch of experiments.
First we select thebest lemmatizer and tagger, next we check for aneed of annotation projection to the Serbian corpus,then the best MTE-based tagset using the best toolcombination.
Finally we provide a more detailedinsight into the results of the top-performing pairof selected tools and tagset.5.1 Tool selectionResults of the first experimental batch, consistingof testing the selected set of lemmatizers and tag-gers on the MTE v5r1 version of Croatian SETimestest set, are given in Table 3.
In terms of lemmati-12http://www.cis.uni-muenchen.de/ schmid/tools/TreeTagger/13http://www.lsi.upc.edu/ nlp/SVMTool/14http://cst.dk/online/lemmatiser/uk/15http://www.apertium.org/16As with already existing Croatian annotated corpora,HML is not fully MTE compliant.
For future work, we mightutilize a compliant version in our experiment and resultingmodels, being that its coverage is generally greater than theone of Apertium?s lexicon due to size difference.set.test wiki.testPOS hr sr hr srHunPos 97.04 95.47 94.25 96.46+ lex 96.60 95.09 94.62 95.58MSDHunPos 87.11 85.00 80.83 82.74+ lex 84.81 81.59 78.49 79.20Table 4: Overall tagging accuracy with and withoutthe inflectional lexiconset.test wiki.testModel hr sr hr srCST 97.78 95.95 96.59 96.30+ lex 97.04 95.52 96.38 96.61Table 5: Overall lemmatization accuracy with andwithout the inflectional lexiconzation and tagging accuracy as well as processingspeed in both training and testing, the top perform-ing tools are CST lemmatizer and HunPos tagger.Thus, we chose these two for further investigationin the following batches of experiments.
It shouldbe noted that, even though its performance is com-parable to the one of CST and HunPos, BTaggerwas not chosen for the other batches primarily be-cause of its temporal complexity, as it is orders ofmagnitude higher than for the selected tools.
Giventhat lemmatization and tagging are considered pre-requisites for further processing of text tata, thedata itself often being fed to these modules in largequantities (e.g., web corpora), we insist on the sig-nificance of temporal complexity in tool selection.The other results are comparable with previous re-search in tagging Croatian.
Where applicable, wetried assisting the tools by providing Apertium?slexicon as an optional input for improved lemma-tization and tagging.
Only TreeTagger lemmatiza-tion and tagging benefited from lexicon inclusion.However, it should be noted that TreeTagger imple-ments a very simple approach to lemmatization, asit only performs dictionary matching and does notlemmatize unknown words.
Inclusion of a largerlexicon such as HML might be more beneficial forall the tools.5.2 Annotation projectionHunPos tagging accuracy on all Croatian and Ser-bian test sets for both POS only and full MSD isgiven in Table 4 for the default variant and for the52Tagset set.test wiki.testPOS hr sr hr srMTE v4 96.08 94.61 93.96 95.85MTE v5 97.04 95.52 94.30 96.40MTE v5r1 97.04 95.47 94.25 96.46MTE v5r2 97.00 95.60 94.20 96.30MTE v5r3 97.13 95.56 94.09 96.15MSDMTE v4 86.24 83.45 80.45 81.98MTE v5 86.77 84.48 80.46 82.43MTE v5r1 87.11 85.00 80.83 82.74MTE v5r2 87.11 84.96 81.20 82.38MRE v5r3 87.72 85.56 81.52 82.79Table 6: HunPos POS and MSD tagging accuracyfor all tagsetsset.test wiki.testTagset hr sr hr srMTE v4 97.78 95.82 96.66 96.11MTE v5 97.82 95.86 96.81 96.30MTE v5r1 97.78 95.95 96.59 96.30MTE v5r2 97.87 95.99 96.75 96.20MTE v5r3 97.74 95.99 96.54 96.20Table 7: CST lemmatization accuracy for all tagsetsone using Apertium?s lexicon.
These results serveas the first decision point regarding the need forCroatian-to-Serbian annotation projection, the sec-ond one being the lemmatization scores in Table5.
Here we observed an unsubstantial decreasein POS and MSD tagging between Croatian andSerbian test sets ?
the observed difference is, infact, more substantial across domains than acrosslanguages.
Overall, Croatian and Serbian scoresdiffer less than 3%.
Results for Serbian Wikipediasample are even consistently better than for Croa-tian Wikipedia, emphasizing domain significanceover language difference.
The tagger does not ben-efit from the inclusion of the inflectional lexiconin POS tagging and it even incurs a substantial 2%to 4% penalty in MSD tagging.
Since such obser-vations were not made while including the lexiconwith the TreeTagger tool ?
which implements thesimplest form of dictionary lemmatization ?
weperformed a small results analysis and noticed anunnaturally high percentage of categories that areas expected present in the lexicon, but very rare inthe training corpus (like the vocative case) point-ing to a na?
?ve implementation of the procedure.Thus we chose not to use the lexicon in furtherobservations.
Lack of more substantial differencesTagsets v5 v5r1 v5r2 v5r3v4 0.268 <0.05 <0.05 <0.01v5 / <0.01 <0.05 <0.01v5r1 / / 0.877 <0.05v5r2 / / / <0.01Table 8: Statistical significance of differences infull MSD tagging between tagsets (p-values usingapproximate randomization)in tagging scores between Croatian and Serbianfor this specific test scenario implied no need forannotation projection.This is further supported by overall lemmatiza-tion scores in Table 5.
Even with the observedlexical differences between the languages, as weindicated in the description of the test sets by mea-suring lexical coverage using HML, the learnedCST lemmatizer rules are more robust consider-ing language alteration than the trigram taggingmodel of HunPos.
Lemmatization accuracy staysin the margins of approximately 97%?1% for bothlanguages.
Average accuracy on Croatian is lessthan 2% higher than for Serbian and the domainpatterns observed for tagging are also observed forlemmatization.
Benefits of an inflectional lexiconfor lemmatization are minor, if any, which can befollowed back to the small size of the lexicon andhigh quality of the CST lemmatizer.
On the con-trary, TreeTagger?s simple lemmatization does gainfour points by using the lexicon, but it initiallyperforms seven points worse than CST.5.3 Tagset selectionTables 6 and 7 show the influence of tagset de-sign on tagging and lemmatization accuracy.
Theyare accompanied by Table 8, i.e., results of testingstatistical significance of differences between thetagsets in the task of full MSD tagging from Table 6.Statistical significance is calculated with all testsets merged into one.
Differences in lemmatizationaccuracy are virtually non-existent regarding thetagset choice.
Full MSD tagging follows the usualpattern of inverse proportionality between tagsetsize and overall accuracy.
It should be noted thatMTE v5 accuracy is not significantly higher thanMTE v4 accuracy (p = 0.268), but we consider thenew tagset to be easier to use for humans since itstags are shortened by removing placehodlers forfeatures used in other MTE languages.
Consider-ing that only tagging accuracy using the MTE v5r3tagset is significantly better than tagging using all53Croatian SerbianPOS P R F1 P R F1Adj 94.33 90.14 92.19 94.34 93.98 94.1666.80 63.83 65.28 66.79 66.54 66.66Adv 84.56 82.73 83.63 82.57 73.77 77.9284.56 82.73 83.63 82.57 73.77 77.92Conj 95.29 93.82 94.55 97.92 95.29 96.5994.12 92.66 93.38 96.89 94.28 95.57Noun 95.70 96.34 96.02 95.42 96.59 96.0076.78 77.30 77.04 75.38 76.30 75.84Num 94.57 97.75 96.13 96.51 93.26 94.8691.30 94.38 92.81 94.19 91.01 92.57Prep 98.10 99.72 98.90 98.45 98.70 98.5795.93 97.52 96.72 94.30 94.55 94.42Pron 95.97 97.54 96.75 95.78 97.42 96.5981.85 83.20 82.52 81.43 82.83 82.12Verb 95.88 98.07 96.96 95.23 95.72 95.4793.81 95.96 94.87 93.36 93.84 93.60Table 9: Precision (P), recall (R) and F1 score forPOS only (1st column) and full MSD (2nd column)on Croatian and Serbianother suggested tagsets, we chose this tagset andtagging model for further observation of lemmatiza-tion and tagging properties in the remainder of thepaper.
Still, in this section, we present the resultson all tagsets to serve as underlying documentationof the observed differences, mainly because of thefact that only MTE v4 is officially supported atthis moment and MTE v5 is a newly-introducedprototype that displays better performance in thisspecific experiment.5.4 In-depth analysisIn Table 9 we merge SETimes and Wikipedia testsets by language and provide POS and MSD tag-ging precision, recall and F1 score for selectedCroatian and Serbian parts of speech.
In terms ofPOS only, the most difficult-to-tag part of speechis the adverb, followed by the adjective in bothCroatian and Serbian.
The other categories areconsistently POS-tagged with an F1 score of ap-proximately 95% or higher.
The decrease for ad-verbs and adjectives is somewhat more evident inprecision than in recall and the POS confusion ma-trix for both languages, given in Table 10, showsthat these two parts of speech are often mistakenfor each other by the tagger.
Regarding full MSDtagging using the MTE v5r3 tagset, for both lan-guages, the lowest F1 scores are observed for ad-jectives (approximately 66%), nouns (76%) andpronouns (82%).
This is most likely due to the factthat these parts of speech have the largest tagsetsubsets, making it easier for the tagger to get con-fused.17 Performance for other parts of speech issatisfactory, especially for verbs, keeping in mind,e.g., possible subsequent dependency parsing of thetwo languages.
The absolute difference betweenPOS and MSD tagging score is most substantialfor adjectives (approximately 27%), indicating thatcertain MSD features might be triggering the de-crease.
This is partially supported by our tagsetdesign investigation as dropping adjective definite-ness atribute yielded substantial overall taggingaccuracy increase when compared with the tagsetsin which this attribute is still encoded.In Table 10 we provide a part of speech confu-sion matrix for Croatian and Serbian on test setsmerged by language.
In Croatian test sets, the mostfrequent confusions are those between adjectivesand nouns (28.9%), nouns and verbs (14.5%), ad-jectives and adverbs (11.6%) and nouns and ad-verbs (6.9%).
In Serbian text, the tagger most fre-quently confuses nouns ?
for adjectives (21.1%),verbs (20%) and adverbs (16%).
Merging the testsets by language mostly evens out the tagging dif-ferences as there is a total of 173 MSD confusionsin Croatian test sets and only 3 more, i.e., 175 inthe Serbian test sets.POS scores for both languages neared the levelof human error in our experiment.
Keeping thatin mind, upon observing the confusion instancesthemselves, we spotted a confusion between adjec-tives and nouns (e.g.
names of countries (Hrvatska(en.
Croatia, Croatian)), homographic forms(strana (en.
foreign, side), svet (en.
world, holy))and confusion between adjectives and adverbs.
Ad-verbs and prepositions are sometimes confusedwith nouns, especially for nouns in instrumentalcase (e.g.
godinama (en.
year, yearly), tijekom(en.
duration, during)).
Conjuctions are at timesincorrently tagged because various words can havea conjuctional function, most frequently pronounsand adverbs: s?to (en.
what), kako (en.
how), kada(en.
when).
Interestingly, there is some confusionbetween nouns and verbs in Wikipedia test sets,while in SETimes test sets there are almost none.This confusion arises from the homographic forms?
e.g.
mora (en.
must, seas) ?
or from nouns with17There are 589 MTE v5r3 tags in SETIMES.HR.
Out ofthese, 164 are used for tagging adjectives, 42 for nouns and268 for pronouns, thus accounting for 80.47% of the tagset.There are also 50 verb tags.54POS Abbr Adj Adv Conj Noun Num Part Prep Pron Res VerbAbbr 0 0 0 1 3 0 0 0 0 0Adj 0 20 0 50 0 1 0 3 1 4Adv 0 10 9 12 0 0 2 0 0 2Conj 0 0 5 2 0 5 5 7 0 0Noun 0 37 28 0 4 0 1 5 7 25Num 2 4 0 0 2 0 0 0 0 0Part 0 0 0 3 0 0 0 0 0 3Prep 0 0 2 3 2 0 1 0 0 0Pron 0 2 1 9 3 0 1 0 0 1Res 0 0 1 0 4 0 0 2 0 0Verb 0 9 4 0 35 1 2 1 0 1Table 10: POS confusion matrix for Croatian (top right) and Serbian (bottom left)Figure 1: Learning curves for Croatian and Serbian lemmatization and taggingsuffixes -la and -lo, which are used for denotingparticiples in feminine and neuter gender, or withsuffix -ti, which is also a suffix for infinitive.Most MSD tag confusions arise from the fact thatthe same suffix can denote different cases in dif-ferent declensions.
We observed confused numberand gender category (mostly in adjectives in mas-culine and neuter gender), but the most frequentconfusion occurs for accusative forms in masculinegender, which have different suffixes when they de-note animacy (suffix is the same as in the genitivecase: pobjednika (en.
winner), kandidata (en.
can-didate)) and when they denote inanimacy (suffixis the same as in the nominative case: metak (en.bullet), bubnjar (en.
drummer)).In lemmatization, as in POS tagging, errors aregenerally very infrequent.
Some occur with adjec-tives, when an assigned lemma represents a definiteform of an adjective, instead of an indefinitive form(and less frequently vice versa).
Besides, adjec-tives are sometimes confused with adverbs (e.g.,target lemma is znac?ajno (en.
significantly), butthe lemma znac?ajan (en.
significant) is assigned,and vice versa).
Other less frequent examples in-clude cases in which the assigned lemma is not inits canonical form, but a case other than the nomi-native case, or when the assigned lemma is a wordstem.
A small number of errors also occurs dueto slight differences in Croatian and Serbian word-forms, e.g., when a Serbian nominative form is nota nominative form in Croatian (planeta as Serbiannominative and Croatian genitive, planet being theCroatian nominative).Figure 1 provides lemmatization, POS and MSDtagging learning curves for both languages onmerged test sets.
Apart from the slight differencein lemmatization scores in favor of Croatian, thelearning curves and overall scores on merged testsets are virtually identical.
The easiest task to learnis lemmatization while the most complex one isapplying MSD.6 Conclusions and future workIn this paper, we have addressed the issue of lemma-tization and morphosyntactic tagging of two gener-ally under-resourced languages, Croatian and Ser-bian.
Our goal was to provide the general publicwith freely available language resources and state-55of-the-art models for lemmatization and tagging ofthese two languages in terms of accuracy, robust-ness and speed.
We also aimed at using lemmati-zation and tagging as a platform for implicit com-parison of the two languages in natural languageprocessing terms, as to provide partial insight tohow difficult and lossy ?
or, more desireably, howeasy and straightforward ?
would it be to port lin-guistic resources and language processing toolsfrom one language to another.While developing the models, we completed aseries of experiments.
We used the Croatian textfrom the freely available SETimes parallel corpusto create a new manually lemmatized and mor-phosyntactically tagged corpus of Croatian ?
theSETIMES.HR corpus.
Beside the Multext East v4morphosyntactic tagset specification for Croatianwhich was used for initial corpus annotation, wedesigned and implemented a first version of theMultext East v5 tagset and its three reductions andapplied these to SETIMES.HR.
Using SETimesand Wikipedia as starting point resources, we cre-ated two gold standard test sets for each languagein order to test existing state-of-the-art lemmatiz-ers and taggers.
We ran preliminary tests on anumber of tools to select CST lemmatizer andHunPos tagger as tools of choice considering ob-served accuracy, training time and text processingtime.
In an in-depth evaluation of these tools, weobtained peak overall lemmatization accuracy of97.87% and 96.30% for Croatian and Serbian andfull morphosyntactic tagging accuracy of 87.72%and 85.56%, with basic part of speech tagging ac-curacy at 97.13% and 96.46%.
In this specific testscenario and with this specific training set, we haveshown the differences in results between Croatianand Serbian not to be significant enough to justifyan effort in more elaborate strategy of adaptingCroatian models to Serbian data ?
simply trainingthe models on Croatian text from SETIMES.HRcorpus and using them on Serbian text providedstate-of-the-art results in lemmatization and tag-ging, while maintaining and even topping previ-ously documented state of the art for Croatian.The SETIMES.HR corpus, Croatian and Serbiantest sets and top-performing lemmatization and tag-ging models are publicly available and freely down-loadable18 under the CC-BY-SA-3.0 license.Our future work plans include both enlargingand enhancing SETIMES.HR.
The presented learn-18http://nlp.ffzg.hr/resources/models/ing curves show significant room for improvementby annotating additional data.
The dataset aladyserves as a basis for the SETIMES.HR treebank ofCroatian (Agic?
and Merkler, 2013), implementinga novel dependency syntactic formalism and en-abling experiments with joint dependency parsingof Croatian and Serbian.
Should dependency pars-ing experiments show the need for more elaboratelanguage adaptation strategies, we will most likelyimplement them also on the level of lemmas andmorphosyntactic tags before addressing syntacticissues.
This will possibly be helped by statisticalmachine translation between Croatian and Serbianto enhance bitext similarity and empower projec-tion strategies.
An effort could be made to adaptexisting Croatian and Serbian resources and subse-quently to attempt achieving better lemmatizationand tagging performance by combining these withSETIMES.HR.
We will use the models presented inthis paper to annotate the web corpora of Croatianand Serbian (Ljubes?ic?
and Erjavec, 2011) ?
hrWaCand srWaC.AcknowledgementThe research leading to these results has re-ceived funding from the European Union Sev-enth Framework Programme FP7/2007-2013 un-der grant agreement n?
PIAP-GA-2012-324414(project Abu-MaTran).ReferencesZ?eljko Agic?
and Danijela Merkler.
2013.
Three Syn-tactic Formalisms for Data-Driven Dependency Pars-ing of Croatian.
In Text, Speech and Dialogue.
Lec-ture Notes in Computer Science.
Springer.Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.2008.
Improving Part-of-Speech Tagging Accuracyfor Croatian by Morphological Analysis.
Informat-ica, 32(4):445?451.Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.2009.
Evaluating Full Lemmatization of CroatianTexts.
In Recent Advances in Intelligent InformationSystems, pages 175?184.
Exit Warsaw.Z?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.2010.
Tagger Voting Improves MorphosyntacticTagging Accuracy on Croatian Texts.
In Proceed-ings of ITI, pages 61?66.Thorsten Brants.
2000.
TnT: A Statistical Part-of-Speech Tagger.
In Proceedings of ANLP, pages 224?231.56Vlado Delic?, Milan Sec?ujski, and Aleksandar Ku-pusinac.
2009.
Transformation-Based Part-of-Speech Tagging for Serbian Language.
In Proceed-ings of CIMMACS.Tomaz?
Erjavec and Sas?o Dz?eroski.
2004.
MachineLearning of Morphosyntactic Structure: Lemmatiz-ing Unknown Slovene Words.
Applied Artificial In-telligence, 18:17?41.Tomaz?
Erjavec.
2004.
MULTEXT-East Version 3:Multilingual Morphosyntactic Specifications, Lexi-cons and Corpora.
In Proceedings of LREC.Tomaz?
Erjavec.
2012.
MULTEXT-East: Morphosyn-tactic Resources for Central and Eastern EuropeanLanguages.
Language Resources and Evaluation,46(1):131?142.Georgi Georgiev, Valentin Zhikov, Kiril Simov, PetyaOsenova, and Preslav Nakov.
2012.
Feature-RichPart-of-speech Tagging for Morphologically Com-plex Languages: Application to Bulgarian.
In Pro-ceedings of EACL, pages 492?502.Andrea Gesmundo and Tanja Samardz?ic?.
2012a.
Lem-matisation as a Tagging Task.
In Proceedings ofACL.Andrea Gesmundo and Tanja Samardz?ic?.
2012b.
Lem-matising Serbian as Category Tagging with Bidirec-tional Sequence Classification.
In Proceedings ofLREC.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2004.
SVMTool:A general POS Tagger Generator Based on SupportVector Machines.
In Proceedings of LREC.Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.2007.
HunPos: An Open Source Trigram Tagger.In Proceedings of ACL, pages 209?212.Anton Karl Ingason, Sigru?n Helgado?ttir, Hrafn Lofts-son, and Eir?
?kur Ro?gnvaldsson.
2008.
A MixedMethod Lemmatization Algorithm Using a Hierar-chy of Linguistic Identities (HOLI).
In Proceedingsof GoTAL, pages 205?216.Nikola Ljubes?ic?
and Tomaz?
Erjavec.
2011. hrWaCand slWaC: Compiling Web Corpora for Croatianand Slovene.
In Text, Speech and Dialogue, pages395?402.
Springer.Gyo?rgy Orosz and Attila Nova?k.
2012.
PurePos ?An Open Source Disambiguator.
In Proceedings ofNLPCS.Hrvoje Peradin and Jan S?najder.
2012.
Towards aConstraint Grammar Based Morphological Taggerfor Croatian.
In Text, Speech and Dialogue, pages174?182.
Springer.Hrvoje Peradin and Francis M. Tyers.
2012.
A Rule-Based Machine Translation System from Serbo-Croatian to Macedonian.
In Proceedings ofFREERBMT12, pages 55?65.Jan Rupnik, Miha Grc?ar, and Tomaz?
Erjavec.
2008.Improving Morphosyntactic Tagging of SloveneLanguage Through Meta-Tagging.
Informatica,32(4):437?444.Helmut Schmid.
1995.
Improvements in Part-of-Speech Tagging With an Application to German.
InProceedings of ACL SIGDAT Workshop.Anders S?gaard.
2011.
Semi-Supervised CondensedNearest Neighbor for Part-of-Speech Tagging.
InProceedings of ACL-HLT, pages 48?52.Drahom?
?ra ?johanka?
Spoustova?, Jan Hajic?, JanVotrubec, Pavel Krbec, and Pavel Kve?ton?.
2007.The Best of Two Worlds: Cooperation of Statisticaland Rule-Based Taggers for Czech.
In Proceedingsof BSNLP, pages 67?74.Marko Tadic?
and Sanja Fulgosi.
2003.
Building theCroatian Morphological Lexicon.
In Proceedings ofEACL 2003 Workshop on Morphological Processingof Slavic Languages, pages 41?46.Marko Tadic?.
2005.
Croatian Lemmatization Server.Southern Journal of Linguistics, 29(1):206?217.Marko Tadic?.
2009.
New Version of the Croatian Na-tional Corpus.
After Half a Century of Slavonic Nat-ural Language Processing, pages 199?205.Dus?ko Vitas, Cvetana Krstev, Ivan Obradovic?,Ljubomir Popovic?, and Gordana Pavlovic?-Laz?etic?.2003.
An Overview of Resources and Basic Toolsfor Processing of Serbian Written Texts.
In Pro-ceedings of the Workshop on Balkan Language Re-sources, 1st Balkan Conference in Informatics.57
