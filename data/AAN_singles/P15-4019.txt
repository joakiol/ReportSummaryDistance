Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 109?114,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPEnd-to-end Argument Generation System in DebatingMisa Sato Kohsuke Yanai Toshihiko YanaseToshinori Miyoshi Makoto Iwayama Qinghua Sun Yoshiki NiwaHitachi Ltd. Research & Development Group1-280, Higashi-koigakubo, Kokubunji-shi, Tokyo 185-8601 Japan{misa.sato.mw, kohsuke.yanai.cs, toshihiko.yanase.gm,toshinori.miyoshi.pd, makoto.iwayama.nw,qinghua.sun.ap, yoshiki.niwa.tx}@hitachi.comAbstractWe introduce an argument generation sys-tem in debating, one that is based on sen-tence retrieval.
Users can specify a motionsuch as This house should ban gambling,and a stance on whether the system agreesor disagrees with the motion.
Then thesystem outputs three argument paragraphsbased on ?values?
automatically decidedby the system.
The ?value?
indicates atopic that is considered as a positive ornegative for people or communities, suchas health and education.
Each paragraphis related to one value and composed ofabout seven sentences.
An evaluation over50 motions from a popular debate web-site showed that the generated argumentsare understandable in 64 paragraphs out of150.1 IntroductionThis paper describes our end-to-end argumentgeneration system, developed to participate in En-glish debating games as an AI debater.
When usersgive a ?motion?
like This house should ban gam-bling and a ?stance?
on whether the system shouldagree or disagree with the motion, the system gen-erates argument scripts in the first constructiveround of a debate.Among NLP communities, interest is growingin argumentation, such as argumentation miningand claim detection (Levy et al., 2014; Mizuno etal., 2012; Park et al., 2014).
However, argumentgeneration is still as hard a task as other text gener-ation tasks; no standard methods or systems exist,as far as we know.We assume that argument generation systemsare helpful in a variety of decision-making situ-ations such as business, law, politics and medicalcare.
This is because people usually investigateexisting arguments on the Internet, newspapers, orresearch papers before reaching conclusions.
Inthis research, we focus on debating game stylebecause there is similarity in argument construc-tion between debating games and actual decision-making.The difficulty in argument generation is that ar-gument scripts have to be persuasive.
We ex-plain this need by comparing argument generationwith multi-document summarization.
In the twotasks, one practical approach is combining partialtexts retrieved from multiple documents.
Gener-ated scripts in both tasks should be natural andhave sufficient content.
Because the summariza-tion task is to generate summary scripts of multi-ple documents, the essential basis of its evaluationis coverage, that is, how much content in the origi-nal documents is included in the generated scripts.However, as the role of argument scripts is to per-suade people, persuasiveness is more importantthan coverage.We believe that the following three points arerequired to generate persuasive argument scripts:1.
Consistency with a given stance2.
Cause and effect relationships3.
Relevance to people?s valuesFor example, when debaters focus on an agreestance with a motion of This house should bangambling, one persuasive argument would discussthe negative effects of gambling.
To reach a dis-cussion about the negative effects under this con-dition, we need to consider the three points.1.
Consistency means that the stance of argu-ment scripts must be equal to the given stance andconsistent in the overall arguments.
For example,because the gambling motion implies the claimthat gambling is negative, the generated argumentshould include only negative aspects of gambling.2.
Causality makes argumentation persua-sive.
To capture causality, we focus on pro-moting/suppressing relationships.
Hashimoto et109Figure 1: Screenshot and Sample Input & Output Scriptal.
(2012) also showed that the relationships areuseful for causality extractions.
The claim gam-bling promotes negative issues would be persua-sive in an argumentation that agrees with a ban ongambling.3.
Values There are topics obviously consideredto be positive or negative and highly relevant topeople?s values.
For instance, health, educationand natural environment are considered to be pos-itive values, while crime, pollution and high costare considered to be negative.
It is possible to gen-erate scripts about negative effects by collectingpartial texts describing negative values linked togambling, such as crime.2 Overview2.1 Demo DescriptionVisitors will have the opportunity to select a mo-tion and a stance and to run the system to generateargument scripts automatically.Each argument script generated by the systemconsists of three topics corresponding to values,such as health, education and revenue.
This ap-proach comes from our observations that persua-sive arguments would be related to multiple val-ues.
Figure 1 shows the interface of the system andan example of generated argument scripts.
First,users give text scripts about the ?motion?
and se-lect the ?stance?
whether agree or disagree.
Inthe figure, the given motion is This house shouldban smoking in public spaces, and the given stanceis an agree side.
When users click the start but-ton, the system begins processing.
Users can seehow many sentences or documents are processedand how many sentences belong to each value inthe graphs in the upper right corner.
Finally, thesystem provides three generated paragraphs withtheir value titles such as poverty, pollution, anddisease while the generated argument scripts areread aloud by our text-to-speech system.2.2 System OverviewFigure 2 shows the overview of the system.As discussed above, the key of constructing ar-guments is to find positive/negative effects of a tar-get in the motion.
In this paper, we call the target?a motion keyphrase?.Positive/negative effects appear in the form ofaffect relationships like something affects some-thing.
Main elements of arguments are sentencesthat contain affect relationships whose subject isa motion keyphrase and whose object represents avalue.We have two types of affect predicates: affect+and affect?.
Affect+ means a promoting predi-cate such as create, enhance, expand, improve, in-crease.
On the other hand, affect?
means a sup-110Figure 2: System Overviewpressing predicate such as decrease, discourage,eliminate, limit, threaten.
The system stored theaffect relationships in text data as automaticallyadded annotations described in Section 4.Though the system consists of 21 algorithms,we describe four main components in this paper:(1) A motion analysis component decides amotion keyphrase and a polarity of argumentsto be generated.
(2) A value selection component decides mul-tiple values relevant to the given motion byretrieving sentences that contain affect rela-tionships.
(3) A sentence retrieval component retrievessentences relevant to each value from thestored text data.
(4) A sentence ordering and rephrasingcomponent combines and arranges the re-trieved sentences to construct natural argu-ment scripts.They are processed in a pipeline and some of thealgorithms are processed in parallel on a cluster of10 machines.
We describe key functions of thecomponents in Section 3.The system uses large text data from Gigawordcorpus (Napoles et al., 2012) and the annotationsto the text data.
The annotations are added auto-matically in a preprocessing step.
Section 4 de-scribes what kinds of annotations exploited in thesystem.
The text and annotation data are stored us-ing Cassandra1, which is an open-source databasemanagement system designed for handling largeamounts of data across commodity servers.
Theyare indexed into Solr2, open source enterprisesearch platform, that enables full-text search.2.3 EvaluationWe evaluated the generated argument scripts onthe basis of subjective evaluations.1Cassandra: http://cassandra.apache.org2Apache Solr: http://lucene.apache.org/solrTable 1: Evaluation ResultsEvaluation Score Num of paragraphs0: make-no-sense 861: understandable 382: +clear 163: +persuasive 104: +natural 0We used 50 motions from a popular debate web-site Debatabase3as inputs to the system.
Thesystem outputs three paragraphs per motion, andeach paragraph is composed of seven sentences,totaling 150 paragraphs for 50 motions.
The para-graphs are rated by authors on a five point scaleranging from 0 to 4.
Each evaluator judges 30paragraphs in 10 motions.
The paragraphs that donot include any claims or supporting evidence re-lated to the motion, are given a rating of 0 points.A 1 point rating is given when the argument is un-derstood by the evaluator, despite a number of ir-relevant sentences.
If more than four of the sevensentences in the paragraph are relevant to the givenmotion and consistent to the stance, it is given a 2point rating.
If the evaluator feels it is persuasive,it is given a 3 point rating.
When it satisfies theabove conditions and is presented as a natural ar-gument, it is given a 4 point rating.Table 1 shows the results.
We found that the ar-gumentations are understandable in 64 paragraphs(= 38+16+10+0) out of 150.3 Pipeline Components3.1 Motion Analysis ComponentIn the beginning of processing, the system an-alyzes the given motion text, and extracts akeyphrase, a motion polarity, a predicate, an at-titude, and contexts.
A predicate is a phrase whichgives positive/negative sign to a keyphrase, and an3Debatabase: http://idebate.org/debatabase111Table 2: Motion Analysis Resultsmotion keyphrase pol.
predicate attitude contextsThis house believes that casino is harmful for the city casino ?1 harmful believe the cityThis house would create a single EU army a single EU army +1 ?
create ?This house should ban gambling gambling ?1 ?
ban ?This house believes that assisted suicide should be legalized assisted suicide +1 ?
legalize ?Table 3: Motion Analysis Rules.
K = motion keyphrase, C = contexts.priority rule predicate instances1 K be modify-ed for C modify: good(+1), honor(+1), popular(+1), harmful(?1), negative(?1), weak(?1)2 affect K affect: create(+1), enhance(+1), increase(+1), cut(?1), discourage(?1), eliminate(?1)3 believe K believe: allow(+1), legalize(+1), permit(+1), support(+1), ban(?1), oppose(?1)4 K be believe-ed believe: allow(+1), legalize(+1), permit(+1), support(+1), ban(?1), oppose(?1).
.
.
.
.
.
.
.
.attitude is a predicate of this house.
Table 2 showsresults of motion analysis.To analyze a motion, the system has 22 ruleswith their priority.
Table 3 shows a part of therules.
The rules are applied in the order by theirpriority, until a motion keyphrase is extracted.Suppose that the given motion is This house be-lieves that casino is harmful for the city and thegiven stance is agree(+1) (corresponding to thefirst line of Table 2).
The first rule ?K be modify-ed for C?
in Table 3 matches the motion.
Asharmful is a modifying predicate, casinos is K andthe city is C. An attitude of this house is believe.A motion polarity is ?1 because of the negativepredicate harmful(?1).
In the same way, from thesecond to the fourth rules in Table 3 can analyzethe other three motion examples in Table 2.The system calculates an argument polarity bymultiplying the sign of the given stance and themotion polarity.
The system constructs argumentsthat discuss the motion keyphrase, in accordancewith the argument polarity.
For example, if thegiven stance is agree(+1) and the motion polarityis negative(?1), then the system decides an argu-ment polarity is ?1 and constructs arguments thatclaim ?the motion keyphrase is negative(?1)?.3.2 Value Selection ComponentThe value selection component decides multiplevalues relevant to the given motion by using avalue dictionary.
The value dictionary formulatesa set of values that represents what is importantin human?s life, what is harmful in communities,etc.
Each value is regarded as a viewpoint of thegenerated argument.Table 4 describes an example of the value dic-tionary.
As shown in Table 4, each value (e.g., dis-ease, investment) belongs to a field (e.g., health,economy, respectively), and has three attributes: avalue polarity, representative phrases, and contextphrases.
The value polarity +1(?1) means thatthe value is something good(bad).
The represen-tative phrases are linguistic expressions of the val-ues, and the numbers are their weights calculatedby IDF in Gigaword corpus.
The context phrasesare phrases that are likely to appear in neighborof the value in text documents.
They are used tosolve ambiguity of the linguistic expressions.
Thevalue dictionary of the current system contains 16fields and 61 values.The procedure of the value selection is below:Step 1 Retrieves sentences that contain affect re-lationships between the motion keyphraseand one of representative phrases in the valuedictionary.
For instance, it retrieves Gam-bling increases the number of crimes.Step 2 Calculates a polarity to the keyphrase ineach sentence, and filters out the sentenceswhere the polarity is not equivalent to the ar-gument polarity.
For instance, the polarity forGambling increases the number of crimes is?1 by multiplying +1 (increase in the affectdictionary) and?1 (crime in the value dictio-nary), which equals to the argument polarity.Step 3 Sums weights of found values and selectsthe top five values.The value dictionary was created manually.First, fields of the dictionary were determined bythe authors in reference to the roles of govern-ment agencies, and then value entries related toeach field were chosen manually fromDebatabase.Second, a rule-based extractor that extracts valuesdiscussed in a document was constructed using thedictionary, and the extractor applied to each docu-112Table 4: Value Dictionaryfield value polarity representative phrases context phraseseconomy investment +1 investment:27.8, development aid:48.2 asset, bank, capital, fund, profit, stock, ...finance cost ?1 expense:35.9, expenditure:55.7 budget, dollar, fuel, lower, price, share, ...finance income +1 revenue:35.4, wage:39.8 budget, company, earnings, higher, gain, ...health disease ?1 disease:36.6, complication:40.1 AIDS, Alzheimer, blood, cancer, death, ...safety crime ?1 crime:31.5, prostitution:56.2 arrest, gun, jail, kidnapping, victim, ...... ... ... ... ...ment in Debatabase.
Third, we manually addednew entries to the dictionary.
If a value is ex-tracted from a document, we extracted represen-tative/context phrases corresponding to the valuefrom the document.
If no value is extracted, weextracted new values that were contained in thedocument.
We continued these steps of classify-ing documents and adding entries to the dictionarylike a Bootstrapping method.3.3 Sentence Retrieval ComponentThis component retrieves sentences relevant toeach value from the stored text data.It first retrieves documents using a query com-posed of weighted phrases.
The retrieved docu-ments should contain both the motion keyphraseand more than one representative phrases of thedecided values.
While the motion keyphrasescan be replaced with their synonyms or hy-ponyms, their weights are smaller than the orig-inal keyphrases; those of synonyms are 0.75 andthose of hyponyms are 0.5.
The synonyms and hy-ponyms are acquired by WordNet (Miller, 1995).Because short documents don?t usually containsinformative scripts, the length of retrieved docu-ments are limited to more than 200 words.For example, when the motion keyphrase isgambling, a search query for a health value is(gambling#49.53 OR gaming#22.87)AND (health#27.48 OR disease#36.60OR addiction#52.39OR hospital#29.76)AND (length:[200 TO*]).The real numbers following sharp signs areweights of the former phrases, calculated by mul-tiplying the IDF of the phrase and a synonym orhyponym reduction rate.The retrieval step prefers sentences that containpromote/suppress relationships.
The polarities ofthe retrieved sentences must be equal to the argu-ment polarity.
The polarity of each sentence iscalculated by the product of the signs of relatedphrases, such as the predicate of the keyphrase,the promote/suppress verb, and the representativevalue phrase.
In the example of gambling ban(?1)decrease(?1) the number of crimes(?1), the po-larity of the sentence is ?1.The system uses about 10,000,000 newswiredocuments and retrieves 500 per value in this step.3.4 Sentence Ordering and RephrasingComponentThis component processes the sentence set of eachvalue separately.The sentence ordering step orders the retrievedsentences in the natural order in debating by themethod reported in (Yanase et al., 2015).
Themethod employs an assumpsion that a constructivespeech item in debating consists of a claim sen-tence and one or more supporting sentences, andthat the claim sentence lies in the first position ofthe paragraph.
The assumption is implemented astwo machine learning problems: claim sentenceselection and supporting sentence ordering.
Theclaim sentence selection problem is formulated asa binary-classification problem where a given sen-tence is a claim or not.
In the supporting sentenceordering problem, the method orders the other sen-tences on the basis of connectivity of pairs of sen-tences.
This problem is formulated as a rankingproblem, similarly to (Tan et al., 2013).
Featuresfor machine learning models in both problems areextracted not only from the sentences to be orderedbut also from the motion text.Finally, the rephrasing step trims or replacessurplus phrases referring to too many detailsfor argument scripts, such as dates and people?snames.
Several simple rules are used.4 Data Preprocessing: AnnotationsThe system adds annotations automatically in pre-processing into the stored text data by using dic-tionaries and syntax information by Stanford CoreNLP (Manning et al., 2014).
In the current system,about 250 million annotations are stored.
Users113can add the annotations manually.
A list of mainsemantic annotations is below:affect: promoting/suppressing relationships.For example, it adds an annotation of ?affect+:casino ?
the number of crimes?
into a textcasino increases the number of crimes.
The affectdictionary, which is manually created, contains608 positive phrases and 371 negative phrases.modify: phrases which gives positive/negativesign to words governed by them.
For example,it adds an annotation of ?modify?
: environment?into a text harmful environment.
The modificationdictionary contains 79 positive phrases and 134negative phrases.believe: relationships which represents attitudesof a subject to its object.
For example, it addsan annotation of ?believe?
: smoking?
into a textThe government bans smoking in public spaces be-cause of a negative believe phrase ban.
The be-lieve dictionary contains 30 positive phrases, 47negative phrases and 15 neutral phrases.5 Error AnalysisWe describe three major problems of the systemhere: (1) identification errors, (2) polarity errors,(3) motion format limitation.
(1) Identification errors occur on recognizinga motion keyphrase in text data on sentence re-trieval step.
The system can incorrectly retrievesentences including mentions whose expressionsare the same as or similar to the motion keyphrasebut different in their meanings.
In the screenshotof Figure 1, for example, although ?smoking?
inthe motion refers to ?tobacco smoking,?
the firstsentence in the pollution paragraph argues about?smoking caused by a fire.
?The identification problem is especially obvi-ous in the case a motion keyphrase forms a com-pound noun.
For instance, on the motion of ThisHouse should ban cosmetic surgery, it is not clearif surgery in some text is equal to cosmetic surgeryor not.
The errors would show requirements ofmore precise word sense disambiguation or coref-erence resolution among multiple documents.
(2) Polarity errors are not so rare.
Regarding thedisease paragraph in Figure 1, the second sentencewould contain an argument on the opposite stancein error.
(3) Motion format limitation is that the systemcan process only motions in formats which askpeople if its motion keyphrase should be banned orpermitted.
Representative examples of unaccept-able motions are comparison like This house be-lieves that capitalism is better than socialism andquestions of an adequate degree like This Houseshould lower the drinking age.6 ConclusionWe described a demonstration of our argumentgeneration system.
Our system can generate un-derstandable arguments on a given motion for agiven stance.
Our next work is to generate coun-terarguments, which argue against the opponents.AcknowledgmentsWe would like to thank Prof. Kentaro Inui fromTohoku University for valuable discussion.ReferencesChikara Hashimoto, Kentaro Torisawa and Stijn DeSaeger.
2012.
Excitatory or Inhibitory: A NewSemantic Orientation Extracts Contradiction andCausality from the Web, In Proceedings of EMNLP-CoNLL 2012, pages 619?630.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J. Bethard and David Mc-Closky.
2014.
The Stanford CoreNLP Natural Lan-guage Processing Toolkit, In Proceedings of ACL2014 System Demonstrations, pages 55?60.George A. Miller.
1995.
WordNet: A Lexical Databasefor English In Communications of the ACM, 38(11):pages 39?41.Joonsuk Park and Claire Cardie.
2014.
Identifying Ap-propriate Support for Propositions in Online UserComments In Proceedings of the First Workshop onArgumentation Mining, pages 29?38.Junta Mizuno, Eric Nichols, YotaroWatanabe and Ken-taro Inui.
2012.
Organizing Information on the Webthrough Agreement-Conflict Relation ClassificationIn Proceedings of the Eighth Asia Information Re-trieval Societies Conference , pages 126?137.Napoles, Courtney, Matthew Gormley and BenjaminVan Durme.
2012.
Annotated English GigawordLDC2012T21.
Web Download, Philadelphia: Lin-guistic Data Consortium.Ran Levy, Yonatan Bilu, Daniel Hershcovich, EhudAharoni and Noam Slonim.
2014.
Context Depen-dent Claim Detection In Proceedings of COLING2014: Technical Papers, pages 1489?1500.Jiwei Tan, XiaojunWan and Jianguo Xiao 2013.Learning to order natural language texts In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics, pages 87-91.Toshihiko Yanase, Toshinori Miyoshi, Kohsuke Yanai,Misa Sato, Makoto Iwayama, Yoshiki Niwa, PaulReisert and Kentaro Inui 2015.
Learning Sen-tence Ordering for Opinion Generation of DebateIn Proceedings of the 2nd Workshop on Argumenta-tion Mining, pages 94?103.114
