Ins ide-Outs ide  Es t imat ion  of  a Lexical ized PCFG for GermanFranz Beil, Glenn Carroll, Det lef  Prescher, Stefan Riezler and Mats RoothInstitut ffir Maschinelle Sprachverarbeitung, University of StuttgartAbstractThe paper describes an extensive xperiment ininside-outside estimation of a lexicalized proba-bilistic context free grammar for German verb-final clauses.
Grammar and formalism featureswhich make the experiment feasible are de-scribed.
Successive models are evaluated on pre-cision and recall of phrase markup.1 In t roduct ionCharniak (1995) and Carroll and Rooth (1998)present head-lexicalized probabilistic contextfree grammar formalisms, and show that theycan effectively be applied in inside-outside es-timation of syntactic language models for En-glish, the parameterization f which encodeslexicalized rule probabilities and syntacticallyconditioned word-word bigram collocates.
Thepresent paper describes an experiment where aslightly modified version of Carroll and Rooth'smodel was applied in a systematic experimenton German, which is a language with rich in-flectional morphology and free word order (orrather, compared to English, free-er phrase or-der).
We emphasize techniques which made itpractical to apply inside-outside estimation ofa lexicalized context free grammar to such alanguage.
These techniques relate to the treat-ment of argument cancellation and scrambledphrase order; to the treatment ofcase features incategory labels; to the category vocabulary fornouns, articles, adjectives and their projections;to lexicalization based on uninflected lemmatarather than word forms; and to exploitation ofa parameter-tying feature.2 Corpus  and morphologyThe data for the experiment is a corpus of Ger-man subordinate clauses extracted by regularexpression matching from a 200 million tokennewspaper corpus.
The clause length ranges be-tween four and 12 words.
Apart from infiniti-val VPs as verbal arguments, there are no fur-ther clausal embeddings, and the clauses donot contain any punctuation except for a ter-minal period.
The corpus contains 4128873 to-kens and 450526 clauses which yields an averageof 9.16456 tokens per clause.
Tokens are auto-matically annotated with a list of part-of-speech(PoS) tags using a computational morpholog-ical analyser based on finite-state technology(Karttunen et al (1994), Schiller and StSckert(1995)).A problem for practical inside-outside sti-mation of an inflectional language like Germanarises with the large number of terminal andlow-level non-terminal categories in the gram-mar resulting from the morpho-syntactic fea-tures of words.
Apart from major class (noun,adjective, and so forth) the analyser provides anambiguous word with a list of possible combina-tions of inflectional features like gender, person,number (cf.
the top part of Fig.
1 for an exam-ple ambiguous between ominal and adjectivalPoS; the PoS is indicated following the '+' sign).In order to reduce the number of parametersto be estimated, and to reduce the size of theparse forest used in inside-outside estimation,we collapsed the inflectional readings of adjec-tives, adjective derived nouns, article words, andpronouns to a single morphological feature (seeof Fig.
1 for an example).
This reduced the num-ber of low-level categories, as exemplified in Fig.2: das has one reading as an article and one asa demonstrative; westdeutschen has one readingas an adjective, with its morphological featureN indicating the inflectional suffix.We use the special tag UNTAGGED indicatingthat the analyser fails to provide a tag for theword.
The vast majority of UNTAGGED words areproper names not recognized as such.
Thesegaps in the morphology have little effect on ourexperiment.3 GrammarThe grammar is a manually developed headedcontext-free phrase structure grammar for Ger-man subordinate clauses with 5508 rules and269analyze> Deutschei.
deutsch'ADJ.Pos+NN.Fem.Akk.Sg2.
deutsch^ADJ.Pos+NN.Fem.Nom.Sg3.
deutsch^ADJ.Pos+NN.Masc.Nom.
Sg.
Sw4.
deutsch^ADJ.Pos+NN.Neut.Akk.Sg.
Sw5.
deutsch^ADJ.Pos+NN.Neut.Nom.
Sg.Sw6.
deutsch-ADJ.Pos+NN.NoGend.Akk.Pi.St7.
deutsch^ADJ.Pos+NN.NoGend.Nom.Pl.St8.
*deutsch+ADJ.Pos.Fem.Akk.Sg9.
*deutsch+ADJ.Pos.Fem.Nom.Sgi0.
*deutsch+ADJ.Pos.Masc.Nom.Sg.Swii.
*deutsch+ADJ.Pos.Neut.Akk.Sg.Sw12.
*deutsch+ADJ.Pos.Neut.Nom.Sg.
Sw13.
*deutsch+ADJ.Pos.NoGend.Akk.Pi.St14.
*deutsch+ADJ.Pos.NoGend.Nom.Pl.St==> Deutsche { ADJ.E, NNADJ.E }Figure 1: Collapsing Inflectional Featuresw~hrend { ADJ.Adv, ADJ.Pred, KOUS,APPR.Dat, APPR.Gen }sich { PRF.Z }das { DEMS.Z, ART.Def.Z }Preisniveau { NN.Neut.NotGen.
Sg }dem { DEMS.M, ART.Def.M }westdeutschen { ADJ.N }snn~dlere { VVFIN }{ PER }Figure 2: Corpus Clip562 categories, 209 of which are terminal cat-egories.
The formalism is that of Carroll andRooth (1998), henceforth C+R:mother -> non-heads head '  non-heads ( f req)The rules are head marked with a prime.
Thenon-head sequences may be empty, f req  is arule frequency, which is initialized randomly andsubsequently estimated by the inside outside-algorithm.
To handle systematic patterns re-lated to features, rules were generated by Lispfunctions, rather than being written directly inthe above form.
With very few exceptions (rulesfor coordination, S-rule), the rules do not havemore than two daughters.Grammar development is facilitated by achart browser that permits a quick and efficientdiscovery of grammar bugs (Carroll, 1997a).
Fig.3 shows that the ambiguity in the chart is quiteconsiderable even though grammar and corpusare restricted.
For the entire corpus, we com-puted an average 9202 trees per clause.
In thechart browser, the categories filling the cells in-dicate the most probable category for that spanwith their estimated frequencies.
The pop-upwindow under IP presents the ranked list of allpossible categories for the covered span.
Rules(chart edges) with frequencies can be viewedwith a further menu.
In the chart browser, colorsare used to display frequencies (between 0 and 1)estimated by the inside-outside algorithm.
Thisallows properties hared across tree analyses tobe checked at a glance; often grammar and es-timation bugs can be detected without mouseoperations.The grammar covers 88.5~o f the clauses and87.9% of the tokens contained in the corpus.Parsing failures are mainly due to UNTAGGEDwords contained in 6.6% of the failed clauses,the pollution of the corpus by infinitival con-structions (~1.3%), and a number of coordina-tions not covered by the grammar (~1.6%).3.1 Case features  and agreementOn nominal categories, in addition to the fourcases Nom, Gen, Dat, and Akk, case featureswith a disjunctive interpretation (such as Dirfor Nom or Akk) are used.
The grammar is writ-ten in such a way that non-disjunctive f aturesare introduced high up in the tree.
This resultsin some reduction in the size of the parse forest,and some parameter pooling.
Essentially the fullrange of agreement inside the noun phrase is en-forced.
Agreement between the nominative NPand the tensed verb (e.g.
in number) is not en-forced by the grammar, in order to control thenumber of parameters and rules.For noun phrases we employ Abney's chunkgrammar organization (Abney, 1996).
The nounchunk (NC) is an approximately non-recursiveprojection that excludes post-head complementsand (adverbial) adjuncts introduced higher thanpre-head modifiers and determiners but in-cludes participial pre-modifiers with their com-plements.
Since we perform complete contextfree parsing, parse forest construction, andinside-outside estimation, chunks are not moti-vated by deterministic parsing.
Rather, they fa-cilitate evaluation and graphical debugging, bytending to increase the span of constituents withhigh estimated frequency.270daEI:: i: i ::::: :(::: ~ :0,LXJ9 VPP.np.np;495 VPP.nn86 VPK.n%'?JZ VPP.dp.dp1743 VPP.d1556 VPP,nd.nd10Z$ VPPFigure 3: Chart browserWord-by-word gloss of the clause: 'that Sarajevo ver the airport with the essentials supplied will can'class # frame types VPA.na.na VPA.na.naVPA 15 n, na, nad, nai, nap, nar, nd, ndi, ~ndp, ndr, ni, nir, np, npr, nr / \ / \ NP.Nom VPA.na.a NP.Akk VPA.na.n VPP 13 d, di, dp, dr, i, ir, n, nd, ni, np, p,pr, r ~ / ~VPI 10 a, ad, ap, ar, d, dp, dr, p, pr, r NP.Akk VPA.na NP.Nom VPA.naVPK 2 i, nFigure 4: Number and types of verb framesFigure 5: Coding of canonical and scrambled ar-gument order3.2 Subcategor isat ion frames of verbsThe grammar distinguishes four subcategorisa-tion frame classes: active (VPA), passive (VPP),infinitival (VPI) frames, and copula construc-tions (VPK).
A frame may have maximally threearguments.
Possible arguments in the frames arenominative (n), dative (d) and accusative (a)NPs, reflexive pronouns (r), PPs (p), and infini-tival VPs (i).
The grammar does not distinguishplain infinitival VPs from zu-infinitival VPs.
Thegrammar is designed to partially distinguish dif-ferent PP frames relative to the prepositionalhead of the PP.
A distinct category for the spe-cific preposition becomes visible only when asubcategorized preposition s cancelled from thesubcat list.
This means that specific prepositionsdo not figure in the evaluation discussed below.The number and the types of frames in the dif-ferent frame classes are given in figure 4.German, being a language with comparativelyfree phrase order, allows for scrambling of ar-guments.
Scrambling is reflected in the particu-lar sequence in which the arguments of the verbframe are saturated.
Compare figure 5 for an ex-ample of a canonical subject-object order in anactive transitive frame and its scrambled object-subject order.
The possibility of scrambling verbarguments yields a substantial increase in thenumber of rules in the grammar (e.g.
102 com-binatorically possible argument rules for all inVPA frames).
Adverbs and non-subcategorizedPPs are introduced as adjuncts to VP categorieswhich do not saturate positions in the subcatframe.In earlier experiments, we employed a flatclausal structure, with rules for all permutationsof complements.
As the number of frames in-creased, this produced prohibitively many rules,particularly with the inclusion of adjuncts.4 ParametersThe parameterization is as in C+R, with onesignificant modification.
Parameters consist of(i) rule parameters, corresponding to right hand271sides conditioned by parent category and par-ent head; (ii) lexical choice parameters for non-head children, corresponding to child lemmaconditioned by child category, parent category,and parent head lemma.
See C+R or Charniak(1995) for an explanation of how such parame~ters define a probabilistic weighting of trees.
Thechange relative to C+R is that lexicalization isby uninflected lemma rather than word form.This reduces the number of lexical parameters,giving more acceptable model sizes and elimi-nating splitting of estimated frequencies amonginflectional forms.
Inflected forms are generatedat the leaves of the tree, conditioned on termi-nal category and lemma.
This results in a thirdfamily of parameters, though usually the choiceof inflected form is deterministic.A parameter pooling feature is used for argu-ment filling where all parent categories of theform VP.x.y are mapped to a category VP.x indefining lexical choice parameters.
The conse-quence is e.g.
that an accusative daughter of anominative-accusative verb uses the same lexicalchoice parameter, whether a default or scram-bled word order is used.
(This feature was usedby C?R for their phrase trigram grammar, notin the linguistic part of their grammar.)
Not alldesirable parameter pooling can be expressed inthis way, though; for instance rule parametersare not pooled, and so get split when the parentcategory bears an inflectional feature.5 Es t imat ionThe training of our probabilistic CFG proceedsin three steps: (i) unlexicalized training withthe supar parser, (ii) bootstrapping a lexical-ized model from the trained unlexicalized onewith the u l t ra  parser, and finally (iii) lexical-ized training with the hypar parser (Carroll,1997b).
Each of the three parsers uses the inside-outside algorithm, supar and u l t ra  use an un-lexicalized weighting of trees, while hypar uses alexicalized weighting of trees, u l t ra  and hyparboth collect frequencies for lexicalized rule andlexical choice events, while supar collects onlyunlexicalized rule frequencies.Our experiments have shown that training anunlexicalized model first is worth the effort.
De-spite our use of a manually developed grammarthat does not have to be pruned of superfluousrules like an automatically generated grammar,A B C1: 52.01992: 25.36523: 24.5905: :13: 24.287214: 24.286315: 24.286116: 24.286117: 24.28671: 53.7654 1: 49.81652: 26.3184 2: 23.10083: 25.5035 3: 22.4479: : : :55: 25.0548 70: 22.144556: 25.0549 80: 22.144357: 25.0549 90: 22.144358: 25.0549 95: 22.144359: 25.055 96: 22.1444Figure 6: Overtrainingon heldout data)(iteration: cross-entropythe lexicalized model is notably better whenpreceded by unlexicalized training (see also Er-san and Charniak (1995) for related observa-tions).
A comparison of immediate lexicalizedtraining (without prior training of an unlexical-ized model) and our standard training regimethat involves preliminary unlexicalized trainingspeaks in favor of our strategy (cf.
the differ-ent 'lex 0' and 'lex 2' curves in figures 8 and 9).However, the amount of unlexicalized traininghas to be controlled in some way.A standard criterion to measure overtrainingis to compare log-likelihood values on held-outdata of subsequent i erations.
While the log-likelihood value of the training data is theo-retically guaranteed to converge through sub-sequent iterations, a decreasing log-likelihoodvalue of the held-out data indicates over-training.
Instead of log-likelihood, we use theinversely proportional cross-entropy measure.Fig.
6 shows comparisons of different sizes oftraining and heldout data (training/heldout):(A) 50k/50k, (B) 500k/500k, (C) 4.1M/500k.The overtraining effect is indicated by the in-crease in cross-entropy from the penultimate tothe ultimate iteration in the tables.
Overtrainingresults for lexicalized models are not yet avail-able.However, a comparison of precision/recallmeasures on categories of different complexitythrough iterative unlexicalized training showsthat the mathematical criterion for overtrainingmay lead to bad results from a linguistic pointof view.
While we observed more or less con-verging precision/recall measures for lower levelstructures such as noun chunks, iterative unlexi-calized training up to the overtraining thresholdturned out to be disastrous for the evaluation ofcomplex categories that depend on almost the272"?
0 0 0 0 0 0- ooooo"= 0 0 0 0 0 0'.
O 0 0 0 0 00 0 00 0 0- -  ~ 0 0 0- -  0 0 000 00 00 00 00 000 0 00 0 0O.
00Figure 7: Chart browser for manual NC labellingOentire span of the clause.
The recognition of sub-categorization frames through 60 iterations ofunlexicalized training shows a massive decreasein precision/recall from the best to the last iter-ation, even dropping below the results with therandomly initialized grammar (see Fig.
9).5.1 Training regimeWe compared lexicalized training with respectto different starting points: a random unlexi-calized model, the trained unlexicalized modelwith the best precision/recall results, and an un-lexicalized model that comes close to the cross-entropy overtraining threshold.
The details ofthe training steps are as follows:(1) 0, 2 and 60 iterations of unlexicalized pars-ing with supar;(2) lexicalization with u l t ra  using the entirecorpus;(3) 23 iterations of lexicalized parsing withhypar.The training was done on four machines (two167 MHz UltraSPARC and two 296 MHz SUNWUltraSPARC-II).
Using the grammar describedhere, one iteration of supar on the entire corpustakes about  2.5 hours, lexicalization and  gen-erating an initial lexicalized mode l  takes morethan six hours, and  an iteration of lexicalizedparsing can be done in 5.5 hours.6 EvaluationFor the evaluation, a total of 600 randomly se-lected clauses were manually annotated by twolabelers.
Using a chart browser, the labellersfilled the appropriate cells with category namesof NCs and those of maximal VP projections(cf.
Figure 7 for an example of NC-labelling).Subsequent alignment of the labelers decisionsresulted in a total of 1353 labelled NC categories(with four different cases).
The total of 584 la-belled VP categories subdivides into 21 differ-ent verb frames with 340 different lemma heads.The dominant frames are active transitive (164occurrences) and active intransitive (117 occur-rences).
They represent almost half of the an-notated frames.
Thirteen frames occur less thanten times, five of which just once.6.1 Methodo logyTo evaluate iterative training, we extractedmaximum probability (Viterbi) trees for the 600clause test set in each iteration of parsing.
Forextraction of a maximal probability parse inunlexicalized training, we used Schmid's loparparser (Schmid, 1999).
Trees were mapped toa database of parser generated markup guesses,and we measured precision and recall againstthe manually annotated category names andspans.
Precision gives the ratio of correct guessesover all guesses, and recall the ratio of correctguesses over the number of phrases identified byhuman annotators.
Here, we render only the pre-cision/recall results on pairs of category namesand spans, neglecting less interesting measureson spans alone.
For the figures of adjusted re-call, the number of unparsed misses has beensubtracted from the number of possibilities.2730.88O.860 .840 .820 .80 .780 .760 .740 .720 .70 .680:::::::::::::::::::::: .....................................i /prec is ion  lex  02  - -  .
............. .. ....p rec i s ion  un lex  ......p rec i s ion  lax  O0 ........p rec i s ion  lex  60  ......reca l l  l ax  02  .......reca l l  un lax  .......reca l l  l ex  O0 ........reca l l  l ex  60  ........i , = , i i i i ,I0  20  30  40  50  60  70  80  90i te ra t ion  #Figure 8: Precision/recall measures on NC cases0.720 .70 .680 .660 .640 .62"~ 0 .
6~.
0 .580.560.540 .52.... ........... ... ....\\ \i Ii 0  20prec is ion  l ex  02  - - .p rac i s ion  un lax  ......p rec i s ion  lex  O0 ........ .p rec imion  lex  60  .......= = i50 40  50  60  70  80  90i te ra t ion  #Figure 9: Precision measures on all verb framesIn the following, we focus on the combinationof the best unlexicalized model and the lexical-ized model that is grounded on the former.6.2 NC Evaluat ionFigure 8 plots precision/recall for the trainingruns described in section 5.1, with lexicalizedparsing starting after 0, 2, or 60 unlexicalized it-erations.
The best results are achieved by start-ing with lexicalized training after two iterationsof unlexicalized training.
Of a total of 1353 an-notated NCs with case, 1103 are correctly recog-nized in the best unlexicalized model and 1112in the last lexicalized model.
With a numberof 1295 guesses in the unlexicalized and 1288guesses in the final lexicalized model, we gain1.2% in precision (85.1% vs. 86.3%) and 0.6%in recall (81.5% vs. 82.1%) through lexicalizedtraining.
Adjustment o parsed clauses yields88% vs. 89.2% in recall.
As shown in Figure 8,the gain is achieved already within the first it-eration; it is equally distributed between correc-tions of category boundaries and labels.The comparatively small gain with lexical-ized training could be viewed as evidence thatthe chunking task is too simple for lexical infor-mation to make a difference.
However, we findabout 7% revised guesses from the unlexicalizedto the first lexicalized model.
Currently, we donot have a clear picture of the newly introducederrors.The plots labeled "00" are results for lexi-calized training starting from a random initialgrammar.
The precision measure of the first lex-icalized model falls below that of the unlexi-calized random model (74%), only recoveringthrough lexicalized training to equalize the pre-cision measure of the random model (75.6%).This indicates that some degree of unlexicalizedinitialization is necessary, if a good lexica\]izedmodel is to be obtained.
(Skut and Brants, 1998) report 84.4% recalland 84.2% for NP and PP chunking without caselabels.
While these are numbers for a simplerproblem and are slightly below ours, they arefigures for an experiment on unrestricted sen-tences.
A genuine comparison has to await ex-tension of our model to free text.6.3 Verb Frame Evaluat ionFigure 9 gives results for verb frame recogni-tion under the same training conditions.
Again,we achieve best results by lexicalising the sec-ond unlexicalized model.
Of a total of 584 anno-tated verb frames, 384 are correctly recognizedin the best unlexicalized model and 397 throughsubsequent lexicalized training.
Precision for thebest unlexicalized model is 68.4%.
This is raisedby 2% to 70.4% through lexicalized training; re-call is 65.7%/68%; adjustment by 41 unparsedmisses makes for 70.4%/72.8% in recall.
Therather small improvements are in contrast o88 differences in parser markup, i.e.
15.7%, be-tween the unlexicalized and second lexicalizedmodel.
The main gain is observed within thefirst two iterations (cf.
Figure 9; for readability,we dropped the recall curves when more or lessparallel to the precision curves).Results for lexicalized training without priorunlexicalized training are better than in the NCevaluation, but fall short of our best results bymore than 2%.The most notable observation i  verb frameevaluation is the decrease of precision of framerecognition in unlexicalized training from thesecond iteration onward.
After several dozen it-2740.80 ,75~'~ 0 .70 .650 .60 .550.5FigureF .
f  - f ' / - "  .
.
.
.
.
.
.I p rec i s ion  lex  02  - -k\ p rec is ion  un lex  ...... "p rec is ion  lex  O0 ........' p rec i s ion  lex  60  ..............reca l l  un lex  .
.
.
.
.
.
.
\\, , " -~ .
.
.
.
.
.
.
.
.
; .
.
.
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
, ,  , , ,i 0  20  30  40  50  60  70  80  90i te ra t ion  #10: Precision measures on non-PP frameserations, results are 5% below a random modeland 14% below the best model.
The primaryreason for the decrease is the mistaken revi-sion of adjoined PPs to argument PPs.
E.g.the required number of 164 transitive framesis missed by 76, while the parser guesses 64VPt.nap frames in the final iteration againstthe annotator's baseline of 12.
In contrast, lexi-calized training generally stabilizes w.r.t, framerecognition results after only few iterations.The plot labeled "lex 60" gives precision for alexicalized training starting from the unlexical-ized model obtained with 60 iterations, whichmeasured by linguistic criteria is a very poorstate.
As far as we know, lexicalized EM esti-mation never recovers from this bad state.6.4 Eva luat ion  of non-PP  FramesBecause xamination of individual cases showedthat PP attachments are responsible for manyerrors, we did a separate valuation of non-PPframes.
We filtered out all frames labelled witha PP argument from both the maximal proba-bility parses and the manually annotated frames(91 filtered frames), measuring precision and re-call against the remaining 493 labeller anno-tated non-PP frames.For the best lexicalized model, we find some-what but not excessively better results thanthose of the evaluation of the entire set offrames.
Of 527 guessed frames in parser markup,382 are correct, i.e.
a precision of 72.5%.
Therecall figure of 77.5~0 is considerably bettersince overgeneration f 34 guesses is neglected.The differences with respect o different start-ing points for lexicalization emulate those in theevaluation of all frames.The rather spectacular looking precision andrecall differences in unlexicalized training con-firm what was observed for the full frameset.
From the first trained unlexicalized modelthroughout unlexicalized training, we find asteady increase in precision (70% first trainedmodel to 78% final model) against a sharp dropin recall (78% peek in the second model vs.50% in the final).
Considering our above re-marks on the difficulties of frame recognitionin unlexicalized training, the sharp drop in re-call is to be expected: Since recall measures thecorrect parser guesses against the annotator'sbaseline, the tendency to favor PP argumentsover PP-adjuncts leads to a loss in guesses whenPP-frames are abandoned.
Similarly, the rise inprecision is mainly explained by the decreas-ing number of guesses when cutting out non-PPframes.
For further discussion of what happenswith individual frames, we refer the reader to(Beil et al, 1998).One systematic result in these plots is thatperformance of lexicalized training stabilizes af-ter a few iterations.
This is consistent withwhat happens with rule parameters for individ-ual verbs, which are close to their final valueswithin five iterations.7 Conc lus ionOur principal result is that scrambling-stylefree-er phrase order, case morphology and sub-categorization, and NP-internal gender, num-ber and case agreement can be dealt with ina head-lexicalized PFCG formedism by meansof carefully designed categories and rules whichlimit the size of the packed parse forest and givedesirable pooling of parameters.
Hedging this,we point out that we made compromises in thegrammar (notably, in not enforcing nominative-verb agreement) in order to control the numberof categories, rules, and parameters.A second result is that iterative lexicalizedinside-outside stimation appears to ,be bene-ficial, although the precision/recall incrementsare small.
We believe this is the first substan-tial investigation of the utility of iterative lexi-calized inside-outside estimation of a lexicalizedprobabilistic grammar involving a carefully builtgrammar where parses can be evaluated by lin-guistic criteria.A third result is that using too many unlexi-calized iterations (more than two) is detrimen-tal.
A criterion using cross-entropy overtraining275on held-out data dictates many more unlexical-ized iterations, and this criterion is therefore in-appropriate.Finally, we have clear cases of lexicalizedEM estimation being stuck in linguistically badstates.
As far as we know, the model which gavethe best results could also be stuck in a compar-atively bad state.
We plan to experiment withother lexicalized training regimes, such as oneswhich alternate between different raining cor-pora.The experiments are made possible by im-provements in parser and hardware speeds, thecarefully built grammar, and evaluation tools.In combination, these provide a unique environ-ment for investigating training regimes for lexi-calized PCFGs.
Much work remains to be donein this area, and we feel that we are just begin-ning to develop understanding of the time courseof parameter estimation, and of the general effi-cacy of EM estimation of lexicalized PCFGs asevaluated by linguistic criteria.We believe our current grammar of Ger-man could be extended to a robust free-textchunk/phrase grammar in the style of the En-glish grammar of Carroll and Rooth (1998)with about a month's work, and to a free-textgrammar treating verb-second clauses and addi-tional complementation structures (notably ex-traposed clausal complements) with about oneyear of additional grammar development andexperiment.
These increments in the grammarcould easily double the number of rules.
How-ever this would probably not pose a problem forthe parsing and estimation software.Glenn Carroll, 1997b.
Manual pages for supar,u l t ra ,  hypar, and genDists.
IMS, StuttgartUniversity.E.
Charniak.
1995.
Parsing with context-freegrammars and word statistics.
Technical Re-port CS-95-28, Department of Computer Sci-ence, Brown University.M.
Ersan and E. Charniak.
1995.
A statisticalsyntactic disambiguation program and whatit learns.
TechnicM Report CS-95-29, Depart-ment of Computer Science, Brown University.Lauri Karttunen, Todd Yampol, and GregoryGrefenstette, 1994.
INFL Morphological An-alyzer~Generator 3.2.9 (3.
6.4).
Xerox Corpo-ration.Anne Schiller and Chris StSckert, 1995.
DMOR.IMS, Universit~t Stuttgart.Helmut Schmid, 1999.
Manual page for lopar.IMS, Universit~t Stuttgart.Wojciech Skut and Thorsten Brants.
1998.A maximum-entropy artiM parser for un-restricted text.
In Proceedings o/ the SixthWorkshop on Very Large Corpora, Montreal,Quebec.ReferencesSteven Abney.
1996.
Chunk stylebook.
Techni-cal report, SfS, Universit~t Tiibingen.Franz Beil, Glenn Carroll, Detlef Prescher, Ste-fan Riezler, and Mats Rooth.
1998.
Inside-outside estimation of a lexicalized PCFG forGerman.
-Gold-.
In Inducing Lexicons withthe EM Algorithm.
AIMS Report 4(3), IMS,Universit~t Stuttgart.Glenn Carroll and Mats Rooth.
1998.
Valenceinduction with a head-lexicalized PCFG.
InProceedings of EMNLP-3, Granada.Glenn Carroll, 1997a.
Manual pages for charge,hyparCharge, and tau.
IMS, Universit~tStuttgart.276
