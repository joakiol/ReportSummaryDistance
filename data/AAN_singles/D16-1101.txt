Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 987?992,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsNumerically Grounded Language Models for Semantic Error CorrectionGeorgios P. Spithourakis and Isabelle Augenstein and Sebastian RiedelDepartment of Computer ScienceUniversity College London{g.spithourakis, i.augenstein, s.riedel}@cs.ucl.ac.ukAbstractSemantic error detection and correction is animportant task for applications such as factchecking, speech-to-text or grammatical er-ror correction.
Current approaches gener-ally focus on relatively shallow semantics anddo not account for numeric quantities.
Ourapproach uses language models grounded innumbers within the text.
Such groundingsare easily achieved for recurrent neural lan-guage model architectures, which can be fur-ther conditioned on incomplete backgroundknowledge bases.
Our evaluation on clinicalreports shows that numerical grounding im-proves perplexity by 33% and F1 for semanticerror correction by 5 points when comparedto ungrounded approaches.
Conditioning on aknowledge base yields further improvements.1 IntroductionIn many real world scenarios it is important to de-tect and potentially correct semantic errors and in-consistencies in text.
For example, when clinicianscompose reports, some statements in the text maybe inconsistent with measurements taken from thepatient (Bowman, 2013).
Error rates in clinicaldata range from 2.3% to 26.9% (Goldberg et al,2008) and many of them are number-based errors(Arts et al, 2002).
Likewise, a blog writer maymake statistical claims that contradict facts recordedin databases (Munger, 2008).
Numerical conceptsconstitute 29% of contradictions in Wikipedia andGoogleNews (De Marneffe et al, 2008) and 8.8%of contradictory pairs in entailment datasets (Daganet al, 2006).Figure 1: Semantic error correction using language models.?EF?
is a clinical term and stands for ?ejection fraction?.These inconsistencies may stem from oversight,lack of reporting guidelines or negligence.
In factthey may not even be errors at all, but point to inter-esting outliers or to errors in a reference database.
Inall cases, it is important to spot and possibly correctsuch inconsistencies.
This task is known as semanticerror correction (SEC) (Dahlmeier and Ng, 2011).In this paper, we propose a SEC approach to sup-port clinicians with writing patient reports.
A SECsystem reads a patient?s structured background in-formation from a knowledge base (KB) and theirclinical report.
Then it recommends improvementsto the text of the report for semantic consistency.
Anexample of an inconsistency is shown in Figure 1.987The SEC system has been trained on a dataset ofrecords and learnt that the phrases ?non dilated?
and?severely dilated?
correspond to high and low val-ues for ?EF?
(abbreviation for ?ejection fraction?, aclinical measurement), respectively.
If the systemis then presented with the phrase ?non dilated?
inthe context of a low value, it will detect a seman-tic inconsistency and correct the text to ?severely di-lated?.Our contributions are: 1) a straightforward ex-tension to recurrent neural network (RNN) languagemodels for grounding them in numbers available inthe text; 2) a simple method for modelling text con-ditioned on an incomplete KB by lexicalising it; 3)our evaluation on a semantic error correction taskfor clinical records shows that our method achievesF1 improvements of 5 and 6 percentage points withgrounding and KB conditioning, respectively, overan ungrounded approach (F1 of 49%).2 MethodologyOur approach to semantic error correction (Figure 1)starts with training a language model (LM), whichcan be grounded in numeric quantities mentioned in-line with text (Subsection 2.1) and/or conditionedon a potentially incomplete KB (Subsection 2.2).Given a document for semantic checking, a hypoth-esis generator proposes corrections, which are thenscored using the trained language model (Subsec-tion 2.3).
A final decision step involves acceptingthe best scoring hypothesis.2.1 Numerically grounded language modellingLet {w1, ..., wT } denote a document, where wt isthe one-hot representation of the t-th token and Vis the vocabulary size.
A neural LM uses a ma-trix, Ein ?
RD?V , to derive word embeddings,ewt = Einwt.
A hidden state from the previous timestep, ht?1, and the current word embedding, ewt , aresequentially fed to an RNN?s recurrence function toproduce the current hidden state, ht ?
RD.
The con-ditional probability of the next word is estimated assoftmax(Eoutht), where Eout ?
RV?D is an outputembeddings matrix.We propose concatenating a representation, ent , ofthe numeric value of wt to the inputs of the RNN?srecurrence function at each time step.
Through thisFigure 2: A language model that is numerically grounded andconditioned on a lexicalised KB.
Examples of data in roundedrectangles.numeric representation, the model can generaliseto out-of-vocabulary numbers.
A straightforwardrepresentation is defining ent = float(wt), wherefloat(.)
is a numeric conversion function that returnsa floating point number constructed from the stringof its input.
If conversion fails, it returns zero.The proposed mechanism for numerical ground-ing is shown in Figure 2.
Now the probability ofeach next word depends on numbers that have ap-peared earlier in the text.
We treat numbers as aseparate modality that happens to share the samemedium as natural language (text), but can conveyexact measurements of properties of the real world.At training time, the numeric representations medi-ate to ground the language model in the real world.2.2 Conditioning on incomplete KBsThe proposed extension can also be used in con-ditional language modelling of documents given aknowledge base.
Consider a set of KB tuples accom-panying each document and describing its attributesin the form < attribute, value >, where attributesare defined by a KB schema.
We can lexicalise theKB by converting its tuples into textual statementsof the form ?attribute : value?.
An example ofhow we lexicalise the KB is shown in Figure 2.
Thegenerated tokens can then be interpreted for theirword embeddings and numeric representations.
This988train dev test#documents 11,158 1,625 3,220#tokens/doc all 204.9 204.4 202.2words 95.7% 95.7% 95.7%numeric 4.3% 4.3% 4.3%#uniquetokens all 18,916 6,572 9,515words 47.8% 58.25% 54.1%numeric 52.24% 41.9% 45.81%OOVrate all 5.0% 5.1% 5.2%words 3.4% 3.5% 3.5%numeric 40.4% 40.8% 41.8%Table 1: Statistics for clinical dataset.
Counts for non-numeric(words) and numeric tokens reported as percentage of counts forall tokens.
Out-of-vocabulary (OOV) rates are for vocabulary of1000 most frequent words in the train data.approach can incorporate KB tuples flexibly, evenwhen values of some attributes are missing.2.3 Semantic error correctionA statistical model chooses the most likely correc-tion from a set of possible correction choices.
If themodel scores a corrected hypothesis higher than theoriginal document, the correction is accepted.A hypothesis generator function, G, takes theoriginal document, H0, as input and generates aset of candidate corrected documents G(H0) ={H1, ...,HM}.
A simple hypothesis generator usesconfusion sets of semantically related words to pro-duce all possible substitutions.A scorer model, s, assigns a score s(Hi) ?
Rto a hypothesis Hi.
The scorer is based on a likeli-hood ratio test between the original document (nullhypothesis, H0) and each candidate correction (al-ternative hypotheses, Hi), i.e.
s(Hi) = p(Hi)p(H0) .
Theassigned score represents how much more probablea correction is than the original document.The probability of observing a document, p(Hi),can be estimated using language models, orgrounded and conditional variants thereof.3 DataOur dataset comprises 16,003 clinical records fromthe London Chest Hospital (Table 1).
Each patientrecord consists of a text report and accompanyingstructured KB tuples.
The latter describe 20 possiblenumeric attributes (age, gender, etc.
), which are alsodescription confusion setintensifiers (adv): non, mildly, severelyintensifiers (adj): mild, moderate, severeunits: cm, mm, ml, kg, bpmviability: viable, non-viablequartiles: 25, 50, 75, 100inequalities: <, >Table 2: Confusion sets.partly contained in the report.
On average, 7.7 tuplesare completed per record.
Numeric tokens constituteonly a small proportion of each sentence (4.3%), butaccount for a large part of the unique tokens vocab-ulary (>40%) and suffer from high OOV rates.To evaluate SEC, we generate a ?corrupted?dataset of semantic errors from the test part of the?trusted?
dataset (Table 1, last column).
We manu-ally build confusion sets (Table 2) by searching thedevelopment set for words related to numeric quanti-ties and grouping them if they appear in similar con-texts.
Then, for each document in the trusted testset we generate an erroneous document by samplinga substitution from the confusion sets.
Documentswith no possible substitution are excluded.
The re-sulting ?corrupted?
dataset is balanced, containing2,926 correct and 2,926 incorrect documents.4 Results and discussionOur base LM is a single-layer long short-term mem-ory network (LSTM, Hochreiter and Schmidhuber(1997) with all latent dimensions (internal matrices,input and output embeddings) set to D = 50.
Weextend this baseline to a conditional variant by con-ditioning on the lexicalised KB (see Section 2.2).We also derive a numerically grounded model byconcatenating the numerical representation of eachtoken to the inputs of the base LM model (see Sec-tion 2.1).
Finally, we consider a model that is bothgrounded and conditional (g-conditional).The vocabulary contains the V = 1000 most fre-quent tokens in the training set.
Out-of-vocabularytokens are substituted with <num unk>, if nu-meric, and <unk>, otherwise.
We extract thenumerical representations before masking, so thatthe grounded models can generalise to out-of-vocabulary numbers.
Models are trained to min-imise token cross-entropy, with 20 epochs of back-989model tokens PP APPbase LMall 14.96 22.11words 13.93 17.94numeric 72.38 2289.47conditionalall 14.52 21.47words 13.49 17.38numeric 74.48 2355.77groundedall 9.91 14.66words 9.28 11.96numeric 42.67 1349.59g-conditionalall 9.39 13.88words 8.80 11.33numeric 39.84 1260.28Table 3: Language modelling evaluation results on the test set.We report perplexity (PP) and adjusted perplexity (APP).
Bestresults in bold.propagation and adaptive mini-batch gradient de-scent (AdaDelta) (Zeiler, 2012).For SEC, we use an oracle hypothesis generatorthat has access to the groundtruth confusion sets (Ta-ble 2).
We estimate the scorer (Section 2.3) using thetrained base, conditional, grounded or g-conditionalLMs.
As additional baselines we consider a scorerthat assigns random scores from a uniform distribu-tion and always (never) scorers that assign the low-est (highest) score to the original document and uni-formly random scores to the corrections.4.1 Experiment 1: Numerically grounded LMWe report perplexity and adjusted perplexity (Ue-berla, 1994) of our LMs on the test set for all tokensand token classes (Table 3).
Adjusted perplexity isnot sensitive to OOV-rates and thus allows for mean-ingful comparisons across token classes.
Perplexi-ties are high for numeric tokens because they form alarge proportion of the vocabulary.
The groundedand g-conditional models achieved a 33.3% and36.9% improvement in perplexity, respectively, overthe base LM model.
Conditioning without ground-ing yields only slight improvements, because mostof the numerical values from the lexicalised KB areout-of-vocabulary.The qualitative example in Figure 3 demonstrateshow numeric values influence the probability of to-kens given their history.
We select a document fromthe development set and substitute its numeric val-Figure 3: Qualitative example.
Template document and docu-ment probabilities for<WORD>={?non?, ?mildly?, ?severely?
}and varying numbers.
Probabilities are renormalised over theset of possible choices.ues as we vary EF (the rest are set by solvinga known system of equations).
The selected ex-act values were unseen in the training data.
Wecalculate the probabilities for observing the docu-ment with different word choices {?non?, ?mildly?,?severely?}
under the grounded LM and find that?non dilated?
is associated with higher EF values.This shows that it has captured semantic dependen-cies on numbers.4.2 Experiment 2: Semantic error correctionWe evaluate SEC systems on the corrupted dataset(Section 3) for detection and correction.For detection, we report precision, recall and F1scores in Table 4.
Our g-conditional model achievesthe best results, a total F1 improvement of 2 pointsover the base LM model and 7 points over the bestbaseline.
The conditional model without ground-ing performs slightly worse in the F1 metric thanthe base LM.
Note that with more hypotheses therandom baseline behaves more similarly to always.Our hypothesis generator generated on average 12hypotheses per document.
The results of never arezero as it fails to detect any error.For correction, we report mean average precision(MAP) in addition to the same metrics as for detec-tion (Table 5).
The former measures the positionof the ranking of the correct hypothesis.
The al-ways (never) baseline ranks the correct hypothesisat the top (bottom).
Again, the g-conditional model990model P R F1random 50.27 90.29 64.58always 50.00 100.0 66.67never 0.0 0.0 0.0base LM 57.51 94.05 71.38conditional 56.86 94.43 70.98grounded 58.87 94.70 72.61g-conditional 60.48 95.25 73.98Table 4: Error detection results on the test set.
We report preci-sion (P), recall (R) and F1.
Best results in bold.yields the best results, achieving an improvement of6 points in F1 and 5 points in MAP over the baseLM model and an improvement of 47 points in F1and 9 points in MAP over the best baseline.
Theconditional model without grounding has the worstperformance among the LM-based models.5 Related WorkGrounded language models represent the relation-ship between words and the non-linguistic con-text they refer to.
Previous work grounds lan-guage on vision (Bruni et al, 2014; Socher et al,2014; Silberer and Lapata, 2014), audio (Kiela andClark, 2015), video (Fleischman and Roy, 2008),colour (McMahan and Stone, 2015), and olfactoryperception (Kiela et al, 2015).
However, no pre-vious approach has explored in-line numbers as asource of grounding.Our language modelling approach to SEC is in-spired by LM approaches to grammatical error de-tection (GEC) (Ng et al, 2013; Felice et al, 2014).They similarly derive confusion sets of semanticallyrelated words, substitute the target words with al-ternatives and score them with an LM.
Existing se-mantic error correction approaches aim at correct-ing word error choices (Dahlmeier and Ng, 2011),collocation errors (Kochmar, 2016), and semanticanomalies in adjective-noun combinations (Vecchiet al, 2011).
So far, SEC approaches focus onshort distance semantic agreement, whereas our ap-proach can detect errors which require to resolvelong-range dependencies.
Work on GEC and SECshows that language models are useful for error cor-rection, however they neither ground in numericquantities nor incorporate background KBs.model MAP P R F1random 27.75 5.73 10.29 7.36always 20.39 6.13 12.26 8.18never 60.06 0.0 0.0 0.0base LM 64.37 39.54 64.66 49.07conditional 62.76 37.46 62.20 46.76grounded 68.21 44.25 71.19 54.58g-conditional 69.14 45.36 71.43 55.48Table 5: Error correction results on the test set.
We report meanaverage precision (MAP), precision (P), recall (R) and F1.
Bestresults in bold.6 ConclusionIn this paper, we proposed a simple technique tomodel language in relation to numbers it refers to,as well as conditionally on incomplete knowledgebases.
We found that the proposed techniques lead toperformance improvements in the tasks of languagemodelling, and semantic error detection and correc-tion.
Numerically grounded models make it possibleto capture semantic dependencies of content wordson numbers.In future work, we will plan to apply numeri-cally grounded models to other tasks, such as nu-meric error correction.
We will explore alternativeways for deriving the numeric representations, suchas accounting for verbal descriptions of numbers.For SEC, a trainable hypothesis generator can po-tentially improve the coverage of the system.AcknowledgmentsThe authors would like to thank the anonymousreviewers for their insightful comments.
We alsothank Steffen Petersen for providing the dataset andadvising us on the clinical aspects of this work.This research was supported by the Farr Instituteof Health Informatics Research, an Allen Distin-guished Investigator award and Elsevier.ReferencesDanielle GT Arts, Nicolette F De Keizer, and Gert-JanScheffer.
2002.
Defining and improving data qualityin medical registries: a literature review, case study,and generic framework.
Journal of the American Med-ical Informatics Association, 9(6):600?611.991Sue Bowman.
2013.
Impact of Electronic HealthRecord Systems on Information Integrity: Quality andSafety Implications.
Perspectives in Health Informa-tion Management, page 1.Elia Bruni, Nam-Khanh Tran, and Marco Baroni.
2014.Multimodal distributional semantics.
J. Artif.
Intell.Res.
(JAIR), 49(1-47).Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The pascal recognising textual entailmentchallenge.
In Machine learning challenges.
evaluat-ing predictive uncertainty, visual object classification,and recognising tectual entailment, pages 177?190.Springer.Daniel Dahlmeier and Hwee Tou Ng.
2011.
CorrectingSemantic Collocation Errors with L1-induced Para-phrases.
In Proceedings of EMNLP, pages 107?117.Marie-Catherine De Marneffe, Anna N Rafferty, andChristopher D Manning.
2008.
Finding Contradic-tions in Text.
In ACL, volume 8, pages 1039?1047.Mariano Felice, Zheng Yuan, ?istein E Andersen, He-len Yannakoudakis, and Ekaterina Kochmar.
2014.Grammatical error correction using hybrid systemsand type filtering.
In CoNLL Shared Task, pages 15?24.Michael Fleischman and Deb Roy.
2008.
Grounded Lan-guage Modeling for Automatic Speech Recognition ofSports Video.
In Proceedings of ACL, pages 121?129.Saveli Goldberg, Andrzej Niemierko, and AlexanderTurchin.
2008.
Analysis of data errors in clinical re-search databases.
In AMIA.
Citeseer.Sepp Hochreiter and Ju?rgen Schmidhuber.
1997.
Longshort-term memory.
Neural computation, 9(8):1735?1780.Douwe Kiela and Stephen Clark.
2015.
Multi- andCross-Modal Semantics Beyond Vision: Groundingin Auditory Perception.
In Proceedings of EMNLP,pages 2461?2470.Douwe Kiela, Luana Bulat, and Stephen Clark.
2015.Grounding Semantics in Olfactory Perception.
In Pro-ceedings of ACL, pages 231?236.Ekaterina Kochmar.
2016.
Error Detection in ContentWord Combinations.
Ph.D. thesis, University of Cam-bridge, Computer Laboratory.Brian McMahan and Matthew Stone.
2015.
A bayesianmodel of grounded color semantics.
Transactions ofthe Association for Computational Linguistics, 3:103?115.Michael C Munger.
2008.
Blogging and political infor-mation: truth or truthiness?
Public Choice, 134(1-2):125?138.Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, ChristianHadiwinoto, and Joel Tetreault.
2013.
The CoNLL-2013 Shared Task on Grammatical Error Correction.In Hwee Tou Ng, Joel Tetreault, Siew Mei Wu, Yuan-bin Wu, and Christian Hadiwinoto, editors, Proceed-ings of the CoNLL: Shared Task, pages 1?12.Carina Silberer and Mirella Lapata.
2014.
Learn-ing Grounded Meaning Representations with Autoen-coders.
In Proceedings of ACL, pages 721?732.Richard Socher, Andrej Karpathy, Quoc V. Le, Christo-pher D. Manning, and Andrew Y. Ng.
2014.Grounded Compositional Semantics for Finding andDescribing Images with Sentences.
TACL, 2:207?218.Joerg Ueberla.
1994.
Analysing a simple languagemodel?
some general conclusions for language mod-els for speech recognition.
Computer Speech & Lan-guage, 8(2):153?176.Eva Maria Vecchi, Marco Baroni, and Roberto Zampar-elli.
2011.
(Linear) Maps of the Impossible: Captur-ing semantic anomalies in distributional space.
In Pro-ceedings of the Workshop on Distributional Semanticsand Compositionality, pages 1?9.Matthew D. Zeiler.
2012.
ADADELTA: An AdaptiveLearning Rate Method.
CoRR, abs/1212.5701.992
