Extracting Constraints on Word Usagefrom Large Text CorporaKathleen McKeown, Diane Litman, and Rebecca PassonneauDepartment of ComputerScience450 Computer Science BuildingColumbia UniversityPROJECT GOALSOur research focuses on the identification of word usageconstraints from large text corpora.
Such constraints areimportant for natural language systems, both for theproblem of selecting vocabulary for language generationand for disambiguating lexical meaning in interpretation.The first stage of our research involves the development ofsystems that can automatically extract such constraintsfrom corpora and empirical methods for analyzing text.Identified constraints will be represented in a lexicon thatwill be tested computationally as part of a natural anguagesystem.
We are also identifying lexical constraints formachine translation using the aligned Hansard corpus astraining data and are identifying many-to-many wordalignments.One primary class of constrmnts we will examine is lex-ical; that is, constraints on word usage arriving from col-locations (word pairs or phrases that commonly appeartogether).
We will also look at constraints deriving fromdomain scales, which influence use of scalar adjectives anddeterminers, constraints on temporal markers and tense,constraints on reference over text, and constraints on cuewords and phrases that may be used to convey explicitinformation about discourse structure.
We also plan to ex-amine corpora of prosodically labeled transcribed speechin order to identify intonational constraints on word usage.RECENT RESULTS?
Added syntactic parser to Xtract, a collocation extrac-tion system, to further filter collocations produced,eliminating those that are not consistently used in thesame syntactic relation.
This increased precision from40% to 80%.
Recall of this stage was evaluated at 94%.?
Developed and implemented a method for retrieving theelements of adjectival scales, using mutual informationbetween adjective-noun collocations and clustering tech-niques to group them.?
Designed a system to compile a list of candidate trans-lations between English and French words using anevaluation of mutual information between words in thealigned Hansard corpus.?
Performed empirical analysis of advising transcriptsidentifying a class of adjectives used evaluatively (asopposed to adjectives conveying objective information)and constraints on their use.
Developed and im-plemented new control tools in FUF to use lexical con-straints in text generation.?
Identified semantic and syntactic onstraints on histori-cal information in statistical reports through partiallyautomated analysis using Xtract ools.?
Completed an empirical study of discourse segmen-tation, assessing the ability of naive subjects to assignsegment boundaries based on the notion of intentionused in Grosz/Sidner's definition of discourse segment.?
Selected and obtained several corpora for analysis: theAP news wire (for finding scalar and other relations);the Brown corpus (for anaylzing temporal adverbs andmorphological units); and the Pear stories (for inves-tigating the role of tense, cue phrases, and intonation).PLANS FOR THE COMING YEARIn the area of machine translation, we are extending oursystem to identify collocations using Xtract in both theFrench and English corpora nd then produce a translationscore based on the mutual information of the individualwords they contain.
We will complete implementation fthis technique and evaluate it through large scale ex-perimentation.
We will improve the accuracy of ourmethod for retrieving scalar adjectives by experinaentingwith other clustering techniques and will begin looking atmethods for ordering the scales retrieved.
We are alsoapplying the technique used for adjectives to identify topi-cally related groups of nouns to aid identification of dis-course segments.
In addition, using the segment boun-daries found empirically as a baseline, we will developautomatic methods for identifying such boundaries, basedon the analysis of usage constraints on referring expres-sions, tense, and lexical cohesion.
We will evaluate preci-sion and recall of automatic segmentation methods.
Weare extending Xtract to find collocations between tensesand temporal adverbials.
Finally, we are also testing con-straints on evaluative adjectives and historical informationin a generation system.470
