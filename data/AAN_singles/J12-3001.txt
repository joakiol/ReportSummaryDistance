ObituaryVictor H. YngveW.
John Hutchins?Victor Yngve (5 July 1920 to 15 January 2012) was a major contributor in a number offields within computational linguistics: as the leading researcher in machine translation(MT) at the Massachusetts Institute of Technology (MIT), as editor of its first journal,as designer and developer of the first non-numerical programming language (COMIT),and as an influential contributor to linguistic theory.While still completing his Ph.D. on cosmic ray physics at the University of Chicagoduring 1950?1953, Yngve had an idea for using the newly invented computers totranslate languages.
He contemplated building a translation machine based on simpledictionary lookup.
At this time he knew nothing of the earlier speculations of WarrenWeaver and others (Hutchins 1997).
Then during a visit to Claude Shannon at BellTelephone Laboratories in early 1952 he heard about a conference on machine trans-lation to be held at MIT in June of that year.
He attended the opening public meetingand participated in conference discussions, and then, after Bar-Hillel?s departure fromMIT, he was appointed in July 1953 by Jerome Wiesner at the Research Laboratory forElectronics (RLE) to lead the MT research effort there.
(For a retrospective survey of hisMT research activities see Yngve [2000].
)Yngve, along with many others at the time, deprecated the premature publicityaround the Georgetown?IBM system demonstrated in January 1954.
Yngve was ap-palled to see research of such a limited nature reported in newspapers; his backgroundin physics required experiments to be carefully planned, with their assumptions madeplain, and properly tested and reviewed by other researchers.
He was determined toset the new field of MT on a proper scientific course.
The first step was a journal forthe field, to be named Mechanical Translation?the field became ?machine translation?in later years.
He found a collaborator for the journal in William N. Locke of the MITModern Languages department.
The aim was to provide a forum for information aboutwhat research was going on in the form of abstracts, and then for peer-reviewed articles.The first issue appeared in March 1954.Yngve?s first experiments at MIT in October 1953 were an implementation of hisearlier ideas on word-for-word translation.
The results of translating fromGermanwerepublished in the collection edited by Locke and Booth (Yngve 1955b).
One example ofoutput began:Die CONVINCINGe CRITIQUE des CLASSICALen IDEA-OF-PROBABILITY IS eineder REMARKABLEen WORKS des AUTHORs.
Er HAS BOTHen LAWe der GREATenNUMBERen ein DOUBLEes TO SHOWen: (1) wie sie IN seinem SYSTEM TOINTERPRETen ARE, (2) THAT sie THROUGH THISe INTERPRETATION NOT denCHARACTER von NOT-TRIVIALen DEMONSTRABLE PROPOSITIONen LOSen .
.
.?
Previously at the University of East Anglia, Norwich, UK.
E-mail: john@hutchinsweb.me.uk.?
2012 Association for Computational LinguisticsComputational Linguistics Volume 38, Number 3It was obvious that the output was poor, but nevertheless it appeared to be good enoughfor scientists with some knowledge of German grammar to read and extract relevantinformation.
Yngve concluded that word-for-word translation could be taken as a firstapproximation.
But amajor problemwas that manywords havemore than onemeaningout of context.Erwin Reifler had suggested the use of pre-editors who would annotate texts be-fore translation; and Victor Oswald proposed the use of microglossaries (dictionarieslimited to one specific narrow field) in order to reduce the number of homographs.But Yngve believed that the problem of multiple meanings could be resolved withsyntactic analysis.
Nonetheless, he rejected Bar-Hillel?s ?operational syntax?
put for-ward at the 1952 conference (and later known as categorical syntax) as too complex forlong sentences and too remote from traditional grammatical distinctions.
He had beenimpressed by the work of Bloomfield and Fries, and had become convinced that lin-guistics could provide stable and repeatable methods akin to the procedures of cosmicray physics.
Therefore, over the following years, he appointed a number of linguiststo the RLE staff, starting with Noam Chomsky in 1955, in order to undertake basicresearch.
He was disappointed, however, that most of the linguists he hired were moreinterested in pursuing their theoretical studies than in tackling the practical problemsof MT.Yngve?s approach to syntactic analysis was to begin with the identification andisolation of the different possible grammatical functions of words.
The aim was to setup mutually exclusive word-classes (i.e., one class for the noun function, another forthe verb function, and so on) The approach was to set up substitution frames to isolatecontexts.
Thus walkmay occur in the frame(1) The was enjoyableor in the frame(2) They home every day.Taking words from a corpus and testing in each frame produces a matrix of differentcontexts (substitution frames) and the words occurring in those contexts.
These wordsform a word-class and their frames form context classes.
As a result, each sentencesequence of word-classes would determine a unique sequence of context classes.
Analgorithm was proposed which searched left-to-right for the longest match for a se-quence of word-classes.
Sequences of word-classes formed phrases and clauses, so thealgorithmwas capable of looking also for phrase sequences.
On this basis, a table-drivenalgorithm for syntactic analysis was designed and implemented (Yngve 1955b).
Thisdemonstrated for the first time in MT the importance and practical value of separatingdescriptive linguistic information (in this case, words and contexts) and language-independent algorithmic procedures (searching andmatching).
The practice waswidelyadopted by other groups in MT and in computational linguistics.At the same time, work was going on at the RLE on investigations of coding andswitching theory and on Shannon?s information theory.
Yngve decided to investigateerror correcting properties of language (Yngve 1954).
Sequences of letters and wordsare not random but constrained by codes specifying which sequences are legitimate.Testing a text for deviations from randomness would help to reveal its structure.
A firststep would be the location of all occurrences of a given frequent word and the deter-mination of its effect on the occurrence of other frequent words in the neighborhood bycomparing their frequency of occurrence with what would be expected if they occurredat random.
For this investigation of what was to be called ?gap analysis?
(Yngve 1956)462Hutchins Obituarya computational experiment was conducted on a corpus of just 9,490 words.
First, themost frequent words were identified: the (599 instances), to (252), of (241), a (221), and(207), and in (162).
Then, the gaps between these words were determined (in numbersof intervening words).
In the case of of and the the gaps were one (the of ), two(the of ), three (the of ), and so on, with frequencies of 72, 31, and6, respectively.
These results pointed to syntactic constraints on constructions with ofand the.
Further results indicated that ?structures with the can be expected to have twoor three words, and constructions with and frequently involve at least fifteen words.
?Similar observations were that ?of is different from to in that it frequently follows a or thewith a gap of one or two.?
And so forth, in a procedure which has now become familiarin statistics-based computational linguistics.
Yngve was a pioneer.
Unfortunately, at thetime, these encouraging results could not be pursued because of the lack of large enoughcorpora in machine-readable form.The parallels between coding theory and linguistics suggested a two-stage modelfor machine translation, where speakers encode amessage that is decoded by a recipient(Yngve 1955a).
Between encoding and decoding there would be some representationof the ?message?
to be preserved in translation.
Further consideration recognized thatstructural representations of input would not be the same as those required for out-put, however.
Attention, therefore, focused on the transition stage where the meaningor message of the input language would be expressed and where choices would bemade for producing output sentence structure.
Thus the MIT group saw the need fora three-stage model: syntactic analysis, structure transfer, and synthesis?a model formany transfer-based MT systems in subsequent years.
Yngve?s model was, however,purely syntactic; no attempt was made at this time to include semantic information(Yngve 1957).At the same time as the development of the transfer model, Yngve and his col-leagues tackled the problem of how linguists could be productive in MT research.
Theydecided that what was needed was a programming system that accepted notationsof a kind familiar to linguists, rather than systems such as FORTRAN and COBOLdesigned for mathematicians and business applications.
Thus, in collaboration with theMIT Computation Center, they developed the first programming language designedspecifically for string-handling and pattern-matching, COMIT (Yngve 1961a, 1967).
Itwas ready for testing in late 1957?thus antedating by two years LISP, another program-ming language devised for linguistics applications.
COMIT was later used as a basis forthe SNOBOL language.The availability of COMITmeant that theMIT group could proceed further with thethree-stage model in the development of an algorithm for sentence production.
Initiallythe generative grammar of Chomsky seemed to be an ideal model.What was required inMT, however, was not the generation of all grammatical sentences from a given sourcebut particular specifiable sentences in context.
The rules of a grammar derived froma simple children?s story were written in COMIT in 1959 and tested in a program ofrandom sentence production (Yngve 1961b).
Its main objective, in which it succeeded,was to test the validity of the grammar rules, particularly rules for discontinuousconstructions and for coordination.One outcome of programming the sentence-production algorithmwith COMITwasthe ?depth hypothesis,?
for which Yngve is probably now best known (Yngve 1960a)both in linguistics and in computational linguistics.
The transformational approach hadalready been rejected because it required toomuch storage space.
The next question washow much storage (push-down store) was needed for discontinuous (left-branching)expansion and for regular (right-branching) expansion.
It was clear that right expansion463Computational Linguistics Volume 38, Number 3(or ?progressive?
application) was potentially infinite: the dog that worried the cat thatkilled the rat that ate the malt .
.
.
.
On the other hand, left expansion (or ?regressive?
appli-cation) was limited: the malt that the rat that the cat that the dog worried killed ate.
Yngvecalculated the maximum amount of extra temporary memory required to produce asentence (i.e., the number of unexpanded constituents at any one time [its depth]).
Hefound that in practice even very long sentences seldom had a depth of more than two orthree.
Sentences with depths of more than three, such as the ?regressive?
constructions,were often considered ungrammatical and/or unintelligible.
Yngve noted the relation-ship of this linguistic feature to the restrictions on immediate memory and processingidentified byMiller (1956).
Most languages includemechanisms for restricting the depthof regressive constructions, such as agglutination and compounding.The depth hypothesis accounted for and predicted many syntactic features of En-glish, including its historical changes, and also appeared to account for many featuresin other languages.
Yngve recognized that it arose from MT research and not fromlinguistic theory, however.
It was a hypothesis that needed to be tested against empiricalevidence.
Its significance for linguistics was widely recognized from the beginning, butit did not conform to the preconceptions of Chomskyan theory.
Although Chomskyhad championed the rigorous statement of theory and its strict application to linguisticmaterial without ad hoc adjustments (Chomsky 1957, page 5), he regarded the depthhypothesis not as a testable scientific hypothesis but as a rival linguistic theory.
ForYngve this attitude was unscientific.Throughout his time at MIT Yngve stressed the need for a ?basic, long-rangeapproach to translation?
and not to look for ?short-cut methods that might yield par-tially adequate translations at an early date?
(Yngve 1960b, page 183).
No working MTsystem emerged from MIT, therefore, but the quality of the research is incontestable.Apart from Yngve?s own contributions to many aspects of syntactic analysis (the three-stage transfer model, the depth hypothesis, and not least computer programming), hiscolleagues also made significant contributions in a variety of areas: grammar theory(Gilbert Harman and Kenneth Knowlton), semantics (Elinor Charney), logic and lan-guage (Jared Darlington), transfer and interlingua (Edward Klima), computer storage(William S. Cooper), Arabic translation (Arnold Satterthwait), and French translation(David Dinneen).
Citations for these contributions will be found in Yngve?s compre-hensive survey of MT research at MIT (Yngve 1967; see also Yngve 2000).By 1964, Yngve had come to the conclusion that ?work in mechanical translationhas come up against what we will call the semantic barrier .
.
.
we will only have ade-quate mechanical translations when the machine can ?understand?
what it is translatingand this will be a very difficult task indeed?
(Yngve 1964, page 279).
Understandinginvolved the background knowledge that people bring to the comprehension of com-munication.
He could see no solutions coming from linguistics.
For many years, Yngvehad grown increasingly doubtful about the health of linguistic science and consequentlyabout the feasibility of good quality MT in general.By 1965, funding for the MIT research group had ceased?perhaps in anticipationof the ALPAC report which had a major impact on the funding of all US researchgroups?and in that year Yngve went back to the University of Chicago as head ofthe Department of Library Sciences, Linguistics, and Behavioral Sciences.By this time, the journalMechanical Translation, which he had founded in 1954, wascoming to an end.
The aim had been to provide a public record of achievement inMT.
His ambitions for the journal could not be fulfilled, however, for various reasons.There were relatively few outstanding contributions submitted for publication; manyMT researchers were funded by government bodies, which required the submission of464Hutchins Obituaryfairly frequent reports, and these reports were distributed widely to other researchersand public institutions.
Researchers believed they had fulfilled their duties to publicizeresearch, and did not see the need to submit shorter articles to a peer-reviewed journalwhich would probably not appear for several months.
In addition the journal could notsurvive solely on subscription charges, and authors were asked to contribute a pagecharge towards publication costs, which they were reluctant to do.In June 1962, the Association for Machine Translation and Computational Linguis-tics was founded, with Yngve as its first president.
The inclusion of ?computationallinguistics?
in the title was indicative of the ever-expanding range of activities in thefield of natural language processing; MT was only part, and a diminishing proportion.The Association took over Yngve?s journal with a changed title, Mechanical Translationand Computational Linguistics, and Yngve remaining as editor.
Even with the inclusion ofmanymore articles in computational linguistics and significantly fewer inMT, however,the journal became ever more irregular and it was wound up in 1970.
In 1968 machinetranslation had already been dropped from the Association?s title.1From this time on, Yngve turned away from his MT interests to questions of lin-guistic theory that had been his increasing concern since the publication of his ?depthhypothesis.?
From 1965, Yngve published a series of papers devoted to the founda-tions of linguistic theory, many at the conferences of LACUS (Linguistic Association ofCanada and the United States).
Just as when he had founded theMechanical Translationjournal in 1954, he was determined to put studies of language on a sound scientificfooting.
His recurrent theme was the unscientific nature of current linguistics.
In thisperiod, he set forth the framework of what he called ?human linguistics?
(later ?hard-science linguistics?)
where the units being analyzed are not the traditional propertiesof sentences, verbs, noun phrases, gender, tense, phonemes, and so on, which, as hedemonstrated, are unfounded assumptions derived often from Greek philosophicalspeculations.
Instead the basic participants are communicating individuals and physicalobservable ?props?
(abstractions of relevant physical objects, clocks, doors), ?channels?of communication (sound waves, writing, signs), and ?settings?
(relevant aspects ofthe physical environment, ticket counters, rooms).
Yngve?s first attempt at summa-rizing and formulating his theory was published in his book, Linguistics as Science(Yngve 1986).Expansion and elaboration of his theoretical standpoint followed in further papersand were brought together in From Grammar to Science in 1996.
The opening chapters area cumulative rejection of all traditional and contemporary linguistics and philosophyof language (from the Greeks to Saussure, Bloomfield, Fries, Harris, Chomsky, andmany others), including a rejection of his own widely accepted ?depth hypothesis.
?The basic contention is that fundamental concepts of linguistics are intuitions and notbased on the observable behavior of people communicating.
Yngve describes a detailedcomprehensive program for a new foundation of linguistics in which ?we abandonthe unsupported assumptions of signs, words, meanings, and sentences?
and movecompletely into ?the world of sound waves and the people who speak and understandwhere we can test our theories and hypotheses against observations of the physicalreality all the way down to the basic assumptions of all science?
(Yngve 1996, page 308).He had not lost sight of computational treatments, and included (chapters 19 and 20)an implementable notation for representing and testing hypotheses.1 For Yngve?s reflections on these changes in MT and computational linguistics see Yngve (1982).465Computational Linguistics Volume 38, Number 3Yngve attracted the support and collaboration of a growing number of scholarssympathetic to his goal of a ?hard-science linguistics,?
and in 2004 a volume of essaysappeared dealing with a wide range of issues and topics under this title (Yngve andWa?sik 2004).
Yngve?s own contributions included an examination of communicationsin formal meetings and an essay on the foundations of a hard-science phonetics andphonology.
Others wrote about speech acts, anaphora, business negotiations, languagechange, educational discourse, communication in science, and much more.
The rangeof applications is impressive, but it is still too early to say what the future impact ofYngve?s ?hard science?
approach may have in the study of communication in all itsforms.
He was himself convinced that in this ?necessary reconstruction?
of linguisticson a truly scientific basis, ?computational linguistics is destined to play an essentialrole?
(Yngve 1982, page 94).Throughout his long career, Vic Yngve retained a modesty about his considerableachievements in machine translation and computational linguistics and a firm com-mitment to the highest standards of research practice which impressed everyone whoknew him.
He will probably be best remembered for his depth hypothesis, but his otherpapers on MT should continue to interest all who look for insights in the computationalanalysis of natural language?and not just for historical reasons.
His articles and bookson ?hard-science linguistics?
deserve to be essential reading for anyone reflecting uponthe foundations of linguistics, and indeed anyone concerned with the general health ofcurrent and future studies of language and communication.ReferencesChomsky, Noam.
1957.
Syntactic Structures.Mouton, The Hague.Hutchins, John.
1997.
From first conceptionto first demonstration: The nascent yearsof machine translation, 1947?1954.Machine Translation, 12:195?252.Miller, George A.
1956.
The magical numberseven, plus or minus two: Some limits inour capacity for processing information.Psychological Review, 63:81?97.Yngve, Victor H. 1954.
Language as an errorcorrecting code.
Quarterly Progress Report ofthe Research Laboratory of Electronics, MIT,Cambridge, MA, October 1953:35?36.Yngve, Victor H. 1955a.
Sentence-for-sentence translation.MechanicalTranslation, 2(2):29?37.Yngve, Victor H. 1955b.
Syntax and theproblem of multiple meaning.
InWilliam N. Locke and A. Donald Booth,editors,Machine Translation of Languages:Fourteen Essays.
Technology Press of theMassachusetts Institute of Technologyand Wiley, Cambridge, MA, andNew York, pages 208?226.Yngve, Victor H. 1956.
Gap analysis andsyntax.
IRE Transactions on InformationTheory, IT-2(3):106?112.Yngve, Victor H. 1957.
A frameworkfor syntactic translation.MechanicalTranslation, 4(3):59?65.Yngve, Victor H. 1960a.
A model andan hypothesis for language structure.Proceedings of the American PhilosophicalSociety, 104(5):444?466.Yngve, Victor H. 1960b.
Researchobjectives.
Quarterly ProgressReport of the Research Laboratory ofElectronics, MIT, Cambridge, MA,October 1960:183.Yngve, Victor H. 1961a.
The COMITsystem.
In H. P. Edmundson, editor,Proceedings of the National Symposiumon Machine Translation, pages 439?443,University of California, Los Angeles,February 2?5, 1960.
Prentice-Hall,Englewood Cliffs, NJ.Yngve, Victor H. 1961b.
Randomgeneration of English sentences.In 1961 International Conference onMachine Translation of Languages andApplied Language Analysis, pages 66?80.Teddington, Middlesex.Yngve, Victor H. 1964.
Implicationsof mechanical translation research.Proceedings of the American PhilosophicalSociety, 108(4):275?281.Yngve, Victor H. 1967.
MT at M.I.T.,1965.
In A. D. Booth, editor,MachineTranslation.
North-Holland, Amsterdam,pages 451?523.Yngve, Victor H. 1982.
Our doubleanniversary.
In Proceedings of the466Hutchins Obituary20th Annual Meeting of the Associationfor Computational Linguistics,pages 92?94.
Ontario.Yngve, Victor H. 1986.
Linguistics asa Science.
Indiana University Press,Bloomington.Yngve, Victor H. 1996.
From Grammar toScience: New Foundations for GeneralLinguistics.
John Benjamins,Amsterdam/Philadelphia.Yngve, Victor H. 2000.
Early research atM.I.T.
: In search of adequate theory.In W. John Hutchins, editor, EarlyYears in Machine Translation: Memoirsand Biographies of Pioneers.
JohnBenjamins, Amsterdam/Philadelphia,pages 39?72.Yngve, Victor H., and Zdzis?aw Wa?sik,editors.
2004.
Hard-science Linguistics.Continuum, London/New York.467
