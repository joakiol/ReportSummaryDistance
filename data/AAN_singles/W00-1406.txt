Towards the Generations.of Rebul;tals in a BayesianArgumentation SystemNatha l ie  J i tnah ,  Ingr id  Zukerman,  R ichard  McConachy  and  Sarah  GeorgeSchool  of  Computer  Sc ience and Sof tware  Eng ineer ingMonash  Un ivers i tyC layton ,  V ic tor ia  3800, AUSTRAL IAemaih {nj  i tnah ,  ingr id ,  r i cky ,  sarahg}@csse ,  monash ,  edu .
auAbst ractWe describe a mechanism which generates rebuttalsto a user's rejoinders in the context of argumentsgenerated from Bayesian etworks.
This mechanismis implemented in an interactive argumentation sys-tem.
Given an argument generated by the systemand an interpretation f a user's rejoinder, the gener-ation of the rebuttal takes into account the intendedeffect of the user's rejoinder, determined on a modelof the user's beliefs, and its actual effect, determinedon a model of the system's beliefs.
We consider threemain rebuttal strategies: refute the user's rejoinder,strengthen the argument goal, and dismiss the user'sline of reasoning.1 In t roduct ionDuring argumentation, conversational partners of-ten use expressions of doubt, such as "But the vic-tim was stabbed", and requests for the considera-tion of additional facts they consider elevant, suchas "What about the fingerprints found on the gun?
".In this paper, we describe a mechanism which gen-erates rebuttals to such rejoinders in the context ofarguments generated from Bayesian etworks (BNs)(Pearl, 1988).
This mechanism is implemented ina system called BIAS (Bayesian Interactive Argu-mentation System).
Given an argument producedby BIAS and a follow-up rejoinder posed by a user,our mechanisln generates a rebuttal on tim basis of aline of reasoning identified by BIAS from the user'srejoinder.
These capabilities constitute a significantstep towards allowing a user to interact freely withan argumentation system and to improve the expla-nation capability of Bayesian systems.Normal arguments are unconstrained in the sensethat they can use whatever means are available to?
justify a goal proposition:i,:"In'~conterast, rebuttalsare constrained, since they must address the pointthrough which the conversational partner attemptedto undermine or question a previous argument.
Toillustrate the operation of BIAS and its rebuttal ca-pability, consider the exchange in Figure 1, whichconsists of a preamble that contains background in-formation~ followed by an argument generated byBIAS, a user's rejoinder and BIAS' rebuttal.
1 Thedomain of implementation is a murder investigationwhere the question under consideration (the goalproposition) is "Did Mr Green murder Mr Body?
",and both the user and the system have access to evi-dence.
After the presentation of the argument whereBIAS contends Mr Green's possible innocence, 2 theuser presents a rejoinder which requests that BIASconsider a fact that was omitted from the argument:The \]found gun is available only to Mr Green.
BIASinfers from this rejoinder that the user is adding sup-port to Mr Green having the means to kill Mr Body,and hence to Mr Green's guilt, through the followingline of reasoning, which is determined as describedin (Zukerman et al, 2000): The gun being availableonly to Mr Green ~ The gun was fired by Mr GreenMr Green had the means to kill Mr Body -+ MrGreen killed Mr Body.
BIAS finds that it does notshare the user's belief in the rejoinder proposition,and that in addition, the effect of this proposition onthe goal is rather weak.
This prompts the genera-tion of a rebuttal of the form Deny-Dismiss-Follow,whereby the rejoinder proposition is denied, its effecton the goal proposition is dismissed, and its impli-cations are followed hypothetically until they breakdown due to the marginal effect of the rejoinder onMr Green's guilt.In the next section, we present our knowledge rep-resentation formalism, followed by an outline of ourprocedure for determining a user's line of reasoning.In Section 4, we describe our algorithm for rebuttalgeneration and discuss our results.
We then reviewrelated work and present concluding remarks.2 ' -  Knowledge Representat ionDuring the argumentation process, BIAS maintainstwo models of belief: a normative model and a usermodel,eaeh-of-which is-represented as a BN.
Thenormative model contains information gathered i-rectly by BIAS from the murder scenario, while theuser model stores propositions that are presumed to1The argument  and rebuttals hown in this paper are re-alized in English as described in (Zukerman et al, 1999).2The mechanism which generates this argument is de-scribed in (Zukerrnan et al, 1998).39Preamble:Mr.
Body was found.dead in his bedroom, which is in .the.seecond .story.
of.his.house.
Bul letwoundswere found in Mr.
Body's body.
The bedroom window was broken and broken glass was found insidethe window.
A gun was found on the premises, and some fingerprints were found on the gun.
Inaddition, inspection of the.
grounds revealed footprints in the garden and circular indentations in theground outside the bedroom window.BIAS' argument:Bullets being found in Mr Body's body implies Mr Body was almost certainly shot.
This implies hewas almost certainly murdered.Forensics matching the bullets with the found gun implies the gun is almost certainly the murderweapon.
Forensics matching the fingerprints,witth Mr.Gr.een implies_Mr Gregn~ probably fired the gun.This together with the gun almost certainly being the murder weapon implies Mr Green probablyfired the murder weapon, which implies he very probably had the means to murder Mr Body.The Bayesian Times reporting Mr Body took Mr Green's girlfriend implies Mr Green and Mr Bodypossibly were enemies, which implies Mr Green possibly had a motive to murder Mr Body.The neighbour eporting Mr Green not being in the garden at 11 implies Mr Green very probablywasn't in the garden at 11.Forensics reporting the time of death being 11 and the forensic analysis of the time of death beingreliable implies the time of death was probably 11, which together with Mr Green very probably notbeing in the garden at 11 implies he probably wasn't in the garden at the time of death.
This implieshe probably didn't have the opportunity to murder Mr Body.Even though Mr Green very probably had the means to murder Mr Body and he possibly had amotive to murder Mr Body, Mr Green probably not having the opportunity to murder Mr Bodyimplies he probably didn't murder Mr Body.User 's  re jo inder:  Consider that the found gun is available only to Mr Green.BIAS' rebuttal:Actually, it is very improbable that the found gun is available only to Mr Green.
However, even if itwas available only to Mr Green, this would have only a small effect on the likelihood that Mr Greenmurdered Mr Body.
This is for the following reason.The found gun being available only to Mr Green implies it is more likely that Mr Green fired the gun,making it almost certain.
This implies it is more likely that he fired the murder weapon, making italmost certain, which implies it is even more likely that he had the means to murder Mr Body.
Thisimplies it is only slightly more likely that he murdered Mr Body.Figure 1: Sample Argument, Rejoinder and Rebuttalbe believed by the user.
These propositions may beobtained from a variety of sources, e.g., they mayhave been inspected by the user in the murder sce-nario (by means of a WWW interface), or appear inBIAS' previous arguments or the user's rejoinders.Arguments generated by BIAS are represented bymeans of an Argument Graph - a sub-network ofthe normative model BN which ideally also containsnodes from the user model BN.The interpretation process, where BIAS identifiesthe reasoning path intended by the user, takes placein the user model; since ,BIAS tries, to .%nake sense"-of what the user is saying according to the system'sview of the user's beliefs (Zukerman et al, 2000).In contrast, the processes for generating the initialargument and the rebuttals consult both tile usermodel and the normative model to produce argu-ments that rely on beliefs held by both BIAS andtile user if possible.
Further, during rebuttal gener-ation, the choice of a rebuttal strategy depends onthe intended effect of the user's argument (accordingto the user model) and its actual effect (accordingto the normative model).3 Determin ing  a User ' s  L ine  o fReason ingOur procedure for recognizing a user's intended lineof reasoning from his/her rejoinder eceives two in-puts: a linguistic clue ("but" or "consider") and arejoinder proposition (R), e.g., "but Mr Green wasin the garden"~..It then-finds paths in the user modelBN that connect R to the goal proposition (Zuker-man et al, 2000).
During this process, BIAS copeswith inference patterns that are different from itsown by allowing inferred paths to contain a small"gap" composed of propositions that did not ex-ist previously in the user model.
Figure 2(a) il-lustrates an Argument Graph, a rejoinder R, and40(a) Argument Graph and userPathM~ I ')A(c) Dismiss userPath:R = userVal has small effect on Gfor BIASFigure 2: Sample Argumentpath R-I-M-E-A-G between them (composed of greynodes).
This path, called userPath, represents theline of reasoning intended by the user.
The gap inthis path contains nodes I and M (in italics), whichmeans that the user inferred E directly from R.Each path is assigned a score based on the fol-lowing factors: the impact of R on BIAS' argu-ment along this path, whether path nodes are inthe user's attentional focus, and BIAS' confidence inthis path (determined from the information sourceof the nodes in this path, e.g., whether the user hasseen the propositions in the path, asserted a be-lief about them or read them in BIAS' arguments).BIAS then selects the highest-scoring path.
If sev-eral paths have a high score, the user is asked tochoose one of them.
Typically,-BIAS returns a singlepath, and sometimes it returns two or three paths.Hence, presenting them to the user for selection is areasonable course of action.4 Rebut ta l  Generat ionGiven a user's rejoinder proposition R, we considerthree main types of rebuttals: (1) refute R, (2) dis-(b) Refute R:R = userVal has large effect on G;BIAS and the user disagree on R- i - .
_@(d) Strengthen G:R = userVal has large effect on G;BIAS and the user agree on RGraph and Rejoinder Strategiesmiss the line of reasoning intended by the user (user-Path), and (3) strengthen the argument goal G. Di-agrammatic representations of these rebuttal strate-gies and abridged versions of their applicability con-ditions appear in Figure 2(b-d).
These conditions,which are specified in the following sections, dependoil (1) whether the rejoinder affects the system's ar-gument directly or indirectly, (2) the beliefs in R inthe normative and user models, and (3) the impactof R on the goal proposition along userPath in thenormative and user models.4.1 Refute  the rejoinderThis strategy consists of generating an argumentagainst he user's belief in the rejoinder propositionR.
This strategy.isapplicable under the followingconditions: .
.
.
.
.
.
(R1) The beliefs in R in the user model and thenormative model differ significantly (the user'sbelief in R contradicts BIAS' belief); and(R2) Either(a) R was stated or implied in BIAS' argument(R appears in the Argument Graph), or41(b) The belief in R stated by the user has asignificant.effect on.
the goal G in ,the nor-mative model in the same direction as itseffect on G in the user model.For example, if the user's rejoinder to the argu-ment in Figure 1 was "But Mr Green and Mr Bodywere not enemies", then conditions R1 and R2awould be satisfied, since the rejoinder directly con-tradicts what was stated by BIAS in the argument.If the user's rejoinder was "But the neighbour sawMr Green shoot ..Mr, Body~!-i.~then :.conditions-,R1and R2b would be satisfied, since an inference fromthis rejoinder contradicts BIAS' belief in Mr Green'slack of opportunity to kill Mr Body (and conse-quently in Mr Green's guilt).
The argument schemafor the refute the rejoinder strategy and a samplerebuttal produced with this schema are shown inFigure 3. a The sub-argument that argues againstthe rejoinder proposition is generated by activatingour Bayesian argument generator (Zukerman et al,1998) with the proposition Mr Green and Mr Bodywere enemies as the goal.
In this case, the belief inthe rejoinder node resulting from the sub-argumentdiffers from that stated in the initial argument, ow-ing to the additional information included in thesub-argument.
Hence, the implications from the re-joinder node are followed.
The procedure for follow-ing these implications is described in Section 4.2.4.2 Dismiss the user's line of reasoningThis strategy consists of showing the user howhis/her argument fails to achieve its intended ef-fect.
We distinguish between concessive and con-tradictory dismissals.
The former is used when thesystem agrees with the rejoinder proposition R, andthe latter when the system disagrees with R. Thisstrategy is applicable under the following condition:(D) R does not significantly affect the belief in Gin the normative model.This condition is illustrated by the rejoinder to theargument in Figure 1, "Consider that the found gunwas available only to Mr Green", which purports toincrease the belief in Mr Green's means to kill MrBody, and hence Mr Green's guilt.
However, sincethis increment is quite small, BIAS adopts the dis:.missal strategy, which follows the effect of the user'srejoinder through the user's line of reasoning, point-ing out how the effect of the rejoinder differs from itsintended effect.
It is worth noting that the main dif-ference between a dismissal and a strengthening ofthe goal is that BIAS decides to generate a dismissalwhen its current beliefs are sufficient to invalidatethe user's line of reasoning, whereas it decides toaThe rejoinders shown in this paper are posed by the userimmediately after the argument in Figure 1.Refute R:t .
Deny, the behef in"R stated by the'user.2.
Present a sub-argument for the normativebelief in R.3.
If R is not in the Argument Graph or thebelief in R as a result of the sub-argumentdiffers from that originally stated by BIAS,then follow the effect of R along userPathup to the first node in the Argument Graph... .
vchose belief.is, the ~ same.as ..that stated inthe initial argument.Rejoinder:But Mr Green and Mr Body were not enemies.Rebuttal :Actually, it is quite likely that Mr Green andMr Body were enemies.
This is for the followingreason.The forensic analysis of the blue paint beingreliable and forensics having found some bluepaint which they estimate is one week old im-plies a blue car was here last week.
This to-gether with Mr Green having a blue car impliesMr Green's car was almost certainly here lastweek, which implies Mr Green almost certainlyvisited Mr Body last week.The neighbour being sober implies she is veryprobably reliable.
This together with the neigh-bour reporting Mr Green arguing with Mr Bodylast week implies the neighbour very probablyheard Mr Green arguing with Mr Body lastweek, which together with Mr Green almostcertainly visiting Mr Body last week implies healmost certainly argued with Mr Body.The Bayesian Times reporting Mr Body tookMr Green's girlfriend implies Mr Body prob-ably seduced Mr Green's girlfriend.
This to-gether with Mr Green almost certainly arguingwith Mr Body implies Mr Green and Mr Bodyprobably were enemies.Let's now go back to the main argument.Mr Green and Mr Body probably being enemiesimplies it is more likely that Mr Green had amotive to murder Mr Body, making it ratherlikely.
This implies it is only slightly more likelythat he murdered Mr Body.Figure 3: Refute the rejoinder Schema nd Examplestrengthen the goal when additional information isrequired to defeat he impact of the user's rejoinder.Our algorithm for dismissing the user's line of rea-soiling follows userPath until it reaches a point wherethe user's line of reasoning fails, i.e., it has no ef-fect on a proposition on userPath in tile ArgumentGraph.
It is necessary for the rebuttal to reach the42Argument Graph even if the failure of the rejoinderoccurs earlier in userPathrbecause the user's ~ejoin= .der refers to the argument, hence at least one propo-sition in the argument must be mentioned when ad-dressing the impact of this rejoinder.The user's line of reasoning may fail due to thefollowing factors: (1) s/he did not consider propo-sitions that have a significant effect on the propo-sitions in userPath; or (2) his/her belief in one ormore of the propositions /he did consider differssignificantly from thatSn t.he normative model, .andthis proposition has a substantial ~effect on a pr,515o--::sition in userPath.
Propositions of the first type areincluded in a set called SIGneighbours, and proposi-tions of the second type are included in DIFFneigh-bouts.
Our dismissal algorithm calls our Bayesian ar-gument generator to generate sub-arguments for thepropositions in DIFFneighbours, but simply presentsthe propositions in SIGneighbours without arguingfor them.A lgor i thm DismissUserReasoning( userPath)Let userPath be composed of propositionsR=Po--+ PI ~ P2--+...--+ Pr,=G.1.
For i= l tondo:(a) Set SIGneighbours(Pi) to the nodes thatare linked to Pi in the normative model butnot in the user model and have a significanteffect on the belief in Pi.
(b) If the belief in Pi in the user modeldiffers significantly from the belief inPi in the normative model, then setDIFFneighbours(Pi) to the nodes that arelinked to Pi in both the user model and thenormative model and which have a differ-ent belief in the user model from that inthe normative model.
(c) For each node Pj E DIFFneighbours(Pi)generate a sub-argument for the normativebelief in Pj.2.
Present.
the resulting rebuttal using the appro-priate schema, DismissContradict or Dismiss-Concede (Figures 4 and 5 and respectively).Our concessive schema differs fi'om our contradic-tory" schema in two respects.
Firstly,, the former ac-knowledges the user's rejoinder, while the latter de-nies it.
In addition, the concessive schema followsthe user's line of reasoning-starting,from the nor-mative belief in the rejoinder proposition (which isclose to the belief indicated by the user), while thecontradictory" schema follows a hypothetical line ofreasoning starting from the user's belief in the re-joinder proposition (which differs substantially fromthe normative belief).
In both cases the user's lineof reasoning fizzles out, due to its small effect on theDismissContradict userPath:...... t".-Deny -tiie~betiefdn.
~ - stated .
.
.
.
.
.
.
.
.
.
.
.
.
.
-'by the user,"and dismiss its hypothetical effect on thegoal proposition.2.
Present he sub-arguments for the nodes inDIFFneighbours.3.
FollowPath userPath from the rejoinderproposition to the goal.Fo l lowPath  userPathFor i :-= 0 to:.n.X-~:t.,.
(whe/'e'n is-i;h&i4umber ofnodes in userPath) do:1.
If Pi+l is not in the Argument Graph orDIFFneighbours(Pi+l)?O, then present animplication from Pi to Pi+l which includesthe nodes linked to Pi+l in the user modelplus the nodes in SIGneighbours(Pi+l ).Else present an implication which reflectsonly the relative impact of Pi on Pi+l.2.
If the resulting belief in Pi+l is the sameas that stated in the initial argument, thenstop.Figure 4: DismissContradict Schema and Follow-Path Proceduregoal according to the normative model irrespectiveof its truth value.Both schemas follow userPath from tile rejoinderproposition to the goal using procedure FollowPath(Figure 4).
This procedure distinguishes betweenpropositions in userPath for which the main influ-encing factors (DIFFneighbours and SIGneighbours)should be presented, and those which require onlyinformation regarding the relative impact of the pre-ceding proposition in userPath.
The latter proposi-tions are characterized as follows: (1) they appearin the Argument Graph; and (2) the user's beliefs inthe nodes outside userPath that have a significanteffect on these propositions are consistent with thenormative beliefs in these nodes.
For instance, therebuttal in Figure 1~ which is generated by means ofthe DismissContradict schema, presents the relativeinfluence of Mr Green fired the gun on Mr Greenfired the murder weapon, since the user and BIAShold consistent beliefs regarding the gun being themurder weapon.? "
To iltustratte"t.he operation 'Of t-he dismissal algo-rithm, let us consider the rejoinder "But the time ofdeath was 11", which yields the following line of rea-soning: The time of death was 11 (~ Mr Green wasin the garden at 11) ~ Mr Green was in the .qardenat the time of death + Mr Green had the opportu-nity to kill Mr Body ---+ Mr Green killed Mr Body.DIFFneighbours includes only one proposition, Mr43DismissConcede userPath:1.
Acknowledge.the,belief"in'-R stated bytheuser, and dismiss its effect on the goalproposition.2.
Present he sub-arguments for the nodes inDIFFneighbours.3.
FollowPath userPath from the rejoinderproposition to the goal.Rejoinder: But the time of death was 11.Rebuttal: -: .
.
.
.
.
.
.
.
.
.Indeed, it is quite likely but not entirely certainthat the time of death was 11.
However, thishas only a small effect on the likelihood thatMr Green murdered Mr Body.I will show that Mr Green almost certainlywasn't in the garden at 11.Mr Green's witness not being related to MrGreen implies she is very probably reliable.This together with Mr Green's witness report-ing Mr Green being at the football at 10:30implies Mr Green was almost certainly at thefootball at 10:30.The neighbour being sober implies she is almostcertainly reliable.
This together with the neigh-bour reporting Mr Green not being in the gar-den at 11 implies the neighbour never saw MrGreen in the garden at 11, which together withMr Green almost certainly being at the footballat 10:30 implies he almost certainly wasn't inthe garden at 11.Let's now go back to the main argument.Even though the time of death was probably11, Mr Green almost certainly not being in thegarden at 11 implies it is only slightly less likelythat he was in the garden at the time of death.This implies it is only slightly less likely thathe had the opportunity to murder Mr Body,which implies it is only slightly less likely thathe murdered Mr Body.Figure 5: DismissConcede Schema and ExampleGreen was in the garden at 11, since the belief in itin the normative model differs from that in the usermodel, thereby prompting the generation of a sub-argument for this proposition..
This sub-argumentis stronger than that incorporated in the initial ar-gument, yielding a belief in Mr  Green.being in thegarden at 11 that is lower than the belief indicatedin the original argument, which in turn reduces thebelief in Mr Green being in the garden at the time ofdeath, Mr Green having the opportunity to kill MrBody, and Mr Green actually nmrdering Mr Body.The resulting rebuttal, which is presented by meansof the DismissConcede schema, appears in Figure 5.4.3 Strengthen the goal: .
:This: strategy, consist~-of.germrafing a stronger argu-ment for the original goal proposition G, bringing tobear information that did not appear in the initialargument (either because BIAS was unaware of itor because BIAS chose to exclude it from the argu-ment).
This strategy is applicable under the follow-ing conditions:(G1) The beliefs in R in the normative and usermodels are consistent; and(G2) Rhas  a=Substantia\] detrimentgI effect on thebelief in G in the normative model.
This changein belief should be in the same direction as thechange occurring in the user model.These conditions represent a situation where thesystem did not take into account a particular fact,but when this fact comes to its attention the sys-tem realizes the effect of this fact on the goal.
Forinstance, if the user discovers new evidence thatplaces Mr Green in the garden at 11, a rejoinderwhich presents this proposition will increase the be-lief in Mr Green's opportunity to kill Mr Body alongthe following line of reasoning: Mr Green was inthe garden at 11 -+ Mr Green was in the garden atthe time of death --+ Mr Green had the opportunityto kill Mr Body ~ Mr Green killed Mr Body.
Inthis case, BIAS tries to strengthen the argument forMr Green's innocence by arguing separately againstpropositions along this line of reasoning (other thanthe rejoinder node, which is true in this example).If no sub-argument can be generated for these nodesor the generated sub-arguments do not significantlyaffect the goal, then BIAS agrees with the user.Our algorithm for strengthening the goal searchesalong userPath for propositions that have been af-fected by the rejoinder, but that will reinforce BIAS'goal proposition if their belief is changed.
It thentries to generate sub-arguments that change the be-liefs in these propositions.
In order to localize theeffect of the user's rejoinder, the search and sub-argument generation processes tart at R and pro-ceed towards the goal.
The presentation of the re-buttal is also done in this order, using a procedurewhich is similar to the FollowPath procedure de-scribed in Section 4.2.A lgor i thm StrengthenGoal( userPath)Let userPath be composed of propositionsR=Po---~ Pi ~ P2-+.
.
.
-~  Pn=G.1.
For i = 1 to n, while the belief in G is not asintended by BIAS, do:(a) Determine which belief in Pi will move thebelief in G in the normative model in thedirection intended by BIAS.
(b) If this belief in Pi differs from the currentbelief in Pi, then44i.
Generate a sub-argument for the de-sired belief in Pi.ii.
If the sub-argument yields a significantchange in the belief in Pi or in the be-lief in G then store the sub-argument inSubAG(P~).2.
Present he resulting rebuttal (composed of theuser's line of reasoning and intervening sub-arguments) using the StrengthenGoal schemain  Figure 6.To illustrate the operation of this algorithm, letus reconsider the rejoinder "Consider Mr Green wasin the garden at 11", and let us assume that the re-joinder proposition is true.
Inspection of the prop-ositions affected by this rejoinder eveals that if MrGreen was not in the garden at the time of death,then the belief in the goal would be closer to thatintended by BIAS.
However, an argument for thisproposition cannot be generated.
Hence, BIAS pro-ceeds to the next proposition, Mr Green had the op-portunity to murder Mr Body, and calls our Bayesianargument generator to generate an argument hatcontradicts this proposition.
The Bayesian genera-tor produces an argument which reduces the beliefin this proposition.
However, this belief cannot bereduced to the extent hat it exculpates Mr Green.Thus, BIAS attempts to generate an argument forthe goal node (by trying to reduce the belief in MrGreen's means and motive to kill Mr Body).
How-ever, this attempt also fails, leaving BIAS with amoderate belief in Mr Green's guilt.
4It is important o note that although BIAS' im-mediate objective is to strengthen its belief in thegoal proposition, its primary purpose is to "tell thetruth" to the best of its knowledge (which may con-tradict its initial beliefs), rather than to win the ar-gument at all costs.
Our algorithm supports thisattitude by retaining any sub-argument which hasa significant impact on the goal or on a proposi-tion on userPath.
We use this disjunctive conditionon impacts in order to address a situation where aproposition Pj on userPath has been affected by asub-argument, but does not affect the goal becauseof an inaccurate belief in aproposition Pk which ap-pears later on userPath:(recalt that the propositionsare inspected from R towards the goal).
However,S t rengthenGoa l  userPath:.... t-.
~Aekn0wledge~the.~etief.in'-R stated"by the"user, and set lastProposition to R.2.
Until the goal proposition is reached o:(a) If after lastProposition there is aproposition Pi EuserPath for whicha sub-argument was generated(SubAG(Pi)?
0), theni.
Follow userPath from lastProposi-tion-to-Pi.
.
.
.
.ii.
Present he sub-argument for Pi.iii.
Set lastProposition to Pi.
(b) Else follow the remainder of userPath.Figure 6: Strengthen the goal Schema5 Re la ted  ResearchOur research builds on work described in (Zukermanet al, 1998), which generated arguments from BNs,and (Zukerman et al, 1999), which enabled a userto explore the impact of different propositions onthe generated arguments.
The former system onlygenerated arguments, while the latter received in-structions from a user (through a menu) about mod-ifications to be performed to a previously generatedargument, e.g., including or excluding a proposition,and then generated a new argument in response tothese instructions.
Neither of these systems gener-ates rebuttals which take into account a user's in-tentions, as done by BIAS.Several researchers have dealt with different as-pects of argumentation; e.g., (Flowers et al, 1982;Quilici, 1992; Chu-Carroll and Carberry, 1995; Car-berry and Lambert, 1999).
Like BIAS, the systemdescribed in Carberry and Lambert (1999) combinedlinguistic and contextual knowledge to recognize auser's intentions from rejoinders.
However, theirsystem did not generate rebuttals.
Chu-Carroll andCarberry (1995) provided a comprehensive approachfor proposal evaluation which focused on dialoguestrategies rather than argumentation strategies.
Inadditiom they considered exchanges where each par-ticipant utters one or two propositions in each con-versational turn.
In contrast, we focus on strategiesfor the generation of extended probabilistie rebuttalsto individual rejoinders.
In the future, our strategiesonce a sub-argument for Patispresented, then Pj af,: ;, ?will be~'e0mbined with.
'dialbgue stra~gies in a corn-fects the goal.
If BIAS accepted only sub-argumentsfor propositions which have a significant impact onthe goal, then in this case it would miss the oppor-tunity to strengthen the goal.1The resulting argument has not been included owing tospace limitations,plete argumentation system.Flowers et al (1982) presented a partial theoryof argumentation which advocated the combinationof distinct knowledge sources; their implementationfocused on recognizing and providing episodic justi-fications to historical events.
Our focus oil the gen-eration of rebuttals in the context of BNs allows us45to provide an operational definition for the broadargumentation strategies discussed in the l i terature,e.g., attack the main point directly or attack the-supporting evidence (Flowers et al, 1982).
5The argumentation system described in (Quilici,1992) used a plan-based model of the user's beliefs torecognize the justification for-a user's proposal andprovide its own justifications.
However, the rebut-tals generated by this system were based on a singlestrategy: applying backwards chaining using a set ofjustification rules.
This strategy is a special case ofthe more general rebuttal Schemas presented here.6 Conclusion and Future WorkWe have offered a mechanism for generating rebut-tals to a user's rejoinders in the context of argu-ments generated by a Bayesian argumentation sys-tem.
We have implemented three main argumenta-tion strategies: refuting the rejoinder, strengtheningthe argument goal, and dismissing the user's line ofreasoning.
For each strategy we have identified ap-plicability conditions, proposed a procedure whichdetermines the information to be included in a re-buttal, and defined a presentation schema.An interesting area of future research pertainsto the omission of information from an argument.There are different ypes of information which maybe omitted from an argument, such as (1) easilyinferred information and information which has asmall effect on the argument; (2) information whichis required for representational reasons, but makesthe resulting argument more confusing; (3) proba-bilistic information which, although correct, makesthe resulting argument more tedious; and (4) pre-viously stated information.
Our previous researchdeals with the first type of information (Zukermanet al, 1998), and in this paper we have identifiedsome conditions for the omission of previously statedinformation when expressing the relative impact ofa proposition.
Another factor that affects the onfis-sion of information is the trade off between accuracyand conciseness.
The omission of information affectsthe belief in the conclusion(s) presented in an argu-ment.
Stating beliefs that differ from a system's ownbeliefs may cause the system to appear inconsistentor even deceitful, while presenting all the relevantfactors may yield a verbose argument.
A mecha-nism which addresses these issues will support hegeneration of better arguments and rebuttals.The evaluation of Chis.
xeseareh,encompassessev-eral components: (1) the WWW interface, (2) thepath-finding mechanism, and (3) the rebuttal-generation mechanism.
A preliminary evaluation of5\Ve do not handle the "attack the claim that the evidencelcives support for the main point" strategy, as this involvesinferring Conditional Probability Matrices for the user model,which is outside the scope of this research.
-the path-finding mechanism has yielded encourag-ing results (Zuke~man e~ al.,: 2000).
: Two.types ofevaluation are envisaged for the rebuttal-generationmechanism.
A whole-system evaluation, where usersinteract freely with BIAS, may be used to deter-mine whether users are satisfied with the system asa whole.
In contrast, a specific evaluation of rebut-tals would be restricted to showing users rejoinder-rebuttal pairs (after showing an initial argument),and eliciting the users' reactions regarding the ap-propriateness of the rebuttals.7 AcknowledgmentsThis work was supported in part by Australian Re-search Council grant A49927212.ReferencesCarberry, S. and Lambert, L. (1999).
A pro-cess model for recognizing communicative actsand modeling negotiation subdialogues.
Compu-tational Linguistics, 25(1):1-53.Chu-Carroll, J. and Carberry, S. (1995).
Generat-ing information-sharing subdialogues in expert-user consultation.
In IJCAI95 - Proceedings ofthe Fourteenth International Joint Conference onArtificial Intelligence, pages 1243-1250.Flowers, M., McGuire, R., and Birnbaum, L. (1982).Adversary arguments and the logic of personalattack.
In Strategies for Natural Language Pro-cessing, pages 275-294.
Lawrence Erlbaum Asso-ciates, Hillsdale, New Jersey.Pearl, J.
(1988).
Probab:ilistic Reasoning in Intelli-gent Systems.
Morgan Kaufmann Publishers, SanMateo, California.Quilici, A.
(1992).
Arguing about planning al-ternatives.
In COLING-92 - Pwceedings of theFourteenth International Conference on Computa-tional Linguistics, pages 906-910, Nantes, France.Zukerman, I., Jitnah, N., McConachy, R., andGeorge, S. (2000).
Recognizing intentions from re-joinders in a Bayesian interactive argumentationsystem.
To appear in PRICAI2000 - Proceedingsof the Sixth Pacific Rim International Conferenceon Artificial InteUigence, Melbourne, Australia.Zukerman, I., McConachy, R., and Korb, K.
B.(1998).
Bayesian reasoning in an abductive mech-anism for argument generation-and analysis.
InAAAI98 - Proceedings of the Fifteenth NationalConference on Artificial Intelligence, pages 833-.838,, Madison~-;Wisconsin.
.Zukerman, I., McConachy, R., K0rb, K. B., andPickett, D. A.
(1999).
Exploratory interactionwith a Bayesian argumentation system.
In IJ-CAI99 - Proceedings of the Sixteenth Inter~m-tional Joint Conference on Artificial Intelligence,pages 1294-1299, Stockholm, Sweden.46
