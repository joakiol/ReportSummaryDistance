Proceedings of the 8th International Conference on Computational Semantics, pages 222?234,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsDisambiguation of Polysemous Verbsfor Rule-based InferencingFabienne Martin, Dennis Spohr, and Achim SteinInstitut fu?r Linguistik/RomanistikUniversita?t Stuttgart, Germanyfirstname.lastname@ling.uni-stuttgart.deAbstractWe present an approach to disambiguating verb senses which differw.r.t.
the inferences they allow.
It combines standard ontological toolsand formalisms with a formal semantic analysis and is hence moreformalised and more detailed than existing lexical semantic resourceslike WordNet and FrameNet [Fellbaum, 1998, Baker et al, 1998].
Theresource presented here implements formal semantic descriptions ofverbs in the Web Ontology Language (OWL) and exploits its reasoningpotential based on Description Logics (DL) for the disambiguation ofverbs in context, since before the correct sense of a verb can be reliablydetermined, its syntactic arguments have to be disambiguated first.
Wepresent details on this process, which is based on a mapping from theFrench EuroWordNet [Vossen, 1998] to SUMO [Niles and Pease, 2003].Moreover, we focus on the selectional restrictions of verbs w.r.t.
theontological type of their arguments, as well as their representation asnecessary and sufficient conditions in the TBox.
After a DL reasonerhas identified the verb sense on the basis of these conditions, we makeuse of the more expressive Semantic Web Rule Language to calculatethe inferences that are permitted on the selected interpretation.1 IntroductionVerbs raise a number of challenges for computational linguistic applications,two of which will be addressed in this paper.
Firstly, a lot of them arehighly polysemous, which makes a careful disambiguation a prerequisite forthe application of semantic web technologies.
As an example, the sameFrench verb encourager is normally translated by three different verbs inGerman, as illustrated in (1)-(3):222(1) Un terroriste a encourage?1ma voisine a` poser une bombe dans la cave.A terrorist has encouraged my neighbour to place a bomb in the basement.Ein Terrorist hat meine Nachbarin ermutigt, eine Bombe im Keller zu legen.
(2) La lettre a encourage?2ma voisine a` poser une bombe dans la cave.The letter has encouraged my neighbour to place a bomb in the basement.Der Brief hat meine Nachbarin dazu bewegt, eine Bombe im Keller zu legen.
(3) Le gouvernement a encourage?3la recherche sur les armes biologiques.The government has encouraged research on biological weapons.Die Regierung hat die Erforschung biologischer Waffen angeregt.Note that (1) differs from (2) only by the ontological category of thesubject, which is a human entity in (1) and a non-human1one in (2).
Onthe other hand, (3) differs from the previous two in that its object is a non-human entity (while the object denotes a human in (1) and (2)), and in thatit does not take an infinitival complement.
The second challenge concernsthe computation and the weighting of the inferences triggered by verbs.
Thecontrast between (1) and (2) offers a striking example: while the interpreterof (2) can take for granted that a bomb was placed, it can only be guessedthat it was possible in (1).
It is crucial to note that subtle differences likethese do exist in French, which is further exemplified by the fact that (1) canbe continued by the sentence ..., mais elle ne l?a pas fait.
(?..., but she [theneighbour] didn?t do it.?
), whereas (2) cannot (cf.
Mari and Martin [2007]).Following Bhatt [1999], let us call ?actuality entailment?
(ae) the entail-ment triggered by (2) ?
and to which the interpreter assigns the probability1 ?
that an event satisfying the infinitival complement took place, and ?weakinference?
the one triggered by (1) ?
and to which the interpreter assigns aprobability p between 0 and 1.
Furthermore, we will say that when the aeis triggered, the verb instantiates its ?implicative reading?.2Note that the presence of the non-human subject in (2) is only a neces-sary condition to trigger the ae (and consequently the implicative reading).For the ae to arise, the tense of the sentence has to be of a certain kind aswell (i.e.
a perfective tense, e.g.
the passe?
compose?
in French).
The inter-action between lexical semantics and information pertaining to the textuallevel like tense and aspect must then be modelled appropriately to capturethe facts.1The fact that letters are generally written by humans is of no relevance here.2The terminology is borrowed from [Karttunen, 1971].
Note however that verbs likeencourager differ from what Karttunen originally calls ?implicative verbs?
(e.g.
re?ussir a`,?manage to?
), because the latter trigger an ae with any kind of tenses.223A model which allows to identify and weigh appropriately the inferencestriggered by verbs like encourager is highly desirable, since, first of all, verbsof the same class are pervasive in the lexicon and heavily present in officialtexts.3Secondly, rating accurately the inference that an event described by aconstituent took place is central for text understanding and summarisation.As it is more convenient to present the implementation through a specificreading of a polysemous verb, we will firstly detail the lexical semantics ofa specific interpretation of the verb encourager, namely the one translatedby the German verb (zu etwas) bewegen and selected in (2).In (1) and (2), encourager is a psychological verb in that it denotes anaction or a state likely to trigger a certain psychological change of state ofthe entity denoted by the object y (henceforth labelled ?Experiencer?).
Thiscannot be the case in (3), since a non-animate object (as research) cannotexperience a psychological state or process.
Rather, encourager denotes in(3) an action of the subject which is likely ?to be good for the developmentof?
the object.
The evaluative component of this reading is the reason whywe propose to call this reading the ?axiological reading?
of encourager.Under the reading instantiated in (2), encourager is analysed here asmeaning something like to be in a state with the goal that y wants to P,or, if y already has this desire, that y wants to P more than previously.Want(s, d, t, P ) describes the state of wanting P at a degree d at a time t.P stands here for a three-place relation.
(4) encourager2?
?s?y?x?P [Theme(s, x) ?
Target(s, y) ?
Goal(s, P2) ?
P2=[?s1?d1?t?d2?s2Want(s1, d1, P, t) ?Want(s2, d2, P, tr) ?
t > tr?
d2> d1?Experiencer(s1, y) ?Experiencer(s2, y)]]Plan of the paper.
Section 2 discusses the model, focussing on selectionalrestrictions and formalisation of inference rules.
Section 3 shows how theseare applied to (2) in order to disambiguate the verb and its arguments, andto calculate the inferences based on this selection.
We conclude in Section4 with the advantages of our approach over existing lexical resources.2 Implementation of the ModelIn the following, we will describe how we model the inference triggers justmentioned as well as semantic representations like the one in (4) using OWL3Examples of verbs displaying the alternation between (1) and (2) (thus triggeringinferences of different strength in the two places) are autoriser a` P ?to authorize to P ?,aider a` P, ?to help to P ?, or exiger que P, ?to demand that P ?.224DL and the more expressive Semantic Web Rule Language (SWRL).42.1 Encoding of selectional argument restrictionsAs mentioned above, the primary triggers for selecting one sense over an-other is the presence (or absence) of syntactic arguments as well as theirontological type.
For example in (2), the fact that (i) encourager subcate-gorises an infinitive, (ii) the subject is inanimate, and (iii) the direct objectis animate, determine the sense of encourager in this sentence.
To make thisinformation available and processable, we use a straightforward encoding ofthese triggers as conditions on class definitions (see also Franconi [2003]),based on concepts of the Suggested Upper Merged Ontology5(SUMO; Nilesand Pease [2003]).In particular, the different senses of a verb are modelled as subclasses of ageneral class that denotes an underspecified representation of the verb.
How-ever, the different verb senses do only subclass this generic representation inthe lexicon, not in the concept hierarchy, since verb senses very frequentlydenote different concepts that are not subsumed by a common concept.
Inour concrete example, we assume 3 different senses of encourager in ourlexicon, which differ w.r.t.
to their axiomatic definition.
(5) below showsthe definition of the sense of encourager corresponding to the one in (2)above.
(5) encourager2 ?
encourager?obj(Agent ?
SocialRole) ?
?obj(Agent ?
SocialRole)?subj(?Agent) ?
?subj(?Agent)?
1 xcompPred owl:ThingThe first line of this definition states that encourager2 is a subclass ofthe underspecified encourager.
The subsequent line requires that there bevalues of the obj property which are either of type Agent or SocialRole, andfurther that all values of the obj property have to be within this set of Agentsor SocialRoles.
For capturing the inanimacy of the subject of encourager,the next line indicates that the values of the subj property may not be oftype Agent, and finally, the last line says that the xcompPred property (i.e.the main predicate of the embedded infinitive) has to have at least one value.The general motivation for this encoding, which views the contextualtriggers discussed above as necessary and sufficient conditions, is that a4See http://www.w3.org/TR/owl-ref/ and http://www.w3.org/Submission/SWRL/.5The reasons for using SUMO classes will become evident in Section 3.1 below.225reasoner can infer ?
on the basis of a particular setting of contextual param-eters (i.e.
property values) ?
the specific type of an instance of the genericencourager.
In the following, we will discuss the inference rules that areattached to each sense class, and which are evoked once a specific sense hasbeen determined.2.2 Inference rulesAs was mentioned above, the different senses of encourager do not onlydiffer w.r.t.
to the necessary and sufficient conditions that are used to classifythem, but also w.r.t.
the inferences they allow.
In our model, such inferencesare encoded in the form of SWRL rules (see e.g.
O?Connor et al [2005]), asthey require inference capacities which go beyond the scope of the inventoryprovided by OWL DL.
The SWRL rule that corresponds to the semanticdescription of encourager2given in (4) is shown in Table 1 below, with therule body in lines 1 to 8 and the rule head in lines 9 to 30.The first line represents the configuration in which the rule applies, i.e.an instance of encourager2 with grammatical subject and object.
Lines 2to 8 make use of the SWRL extensions built-ins6defined within the Prote?ge?ontology editor [Knublauch et al, 2004] in order to create instances thatare to be inserted into the representation, based on the analysis in (4).
Inlines 9 to 11, the grammatical subject is asserted as the theme of the statedenoted by encourager, the grammatical object as target, and, as goal, theproposition that the degree of y wanting to ?place a bomb?
is now greaterthan it was at a previous point in time.
The two ?wanting?
states that arepart of this proposition (lines 12 and 13) are described in lines 14 to 17 and18 to 21, where the ?wanted?
object corresponds to the embedded infinitive7.Lines 22 and 23 state that the previous degree of wanting is greater thanthe current one (note that the reference time tr is not a variable), and thatthe grammatical object y is the experiencer of both wanting states.
Finally,lines 26 to 30 classify the remaining instances created in the rule body.Although the rule appears to be quite specifically tailored to the par-ticular use of encourager2, large parts of it can be re-used for senses ofother verbs within this group of psychological verbs, while other parts canbe parametrised to cover verbs of other groups.
For example, the syntacticsetting (cf.
line 1) is applicable to any transitive verb, while the assignment6See http://protege.cim3.net/cgi-bin/wiki.pl?SWRLExtensionsBuiltIns; thebuilt-in function createOWLThing has been replaced with cOT in the table.7Note that the four-place predicate Want(s, d, P, t) in (4) has been decomposed into asequence of two-place predicates indicating the degree, time, and object of the ?wanting?.2261 syntactic configuration required for appli-cation of ruleencourager2(?s) ?subj(?s,?x) ?
obj(?s,?y) ?2 create previous state of wanting swrlx:cOT(?s1,?s) ?3 create current state of wanting swrlx:cOT(?s2,?s) ?4 create proposition corresponding to em-bedded infinitiveswrlx:cOT(?p,?s1) ?5 create the proposition that is the goal ofencouragerswrlx:cOT(?p2,?s) ?6 create previous degree of wanting swrlx:cOT(?d1,?s1) ?7 create current degree of wanting swrlx:cOT(?d2,?s2) ?8 create previous time swrlx:cOT(?t,?s)?9 assert grammatical subject as theme ofencouragertheme(?s,?x) ?10 assert grammatical object as target ofencouragertarget(?s,?y) ?11 assert proposition as goal of encourager goal(?s,?p2) ?12 assert that previous state is part of thepropositionhasPart(?p2,?s1) ?13 assert that current state is part of thepropositionhasPart(?p2,?s2) ?14 assert previous state of wanting WANTING(?s1) ?15 assert previous degree of wanting degree(?s1,?d1) ?16 assert object of wanting object(?s1,?p) ?17 assert time of previous wanting time(?s1,?t) ?18 assert current state of wanting WANTING(?s2) ?19 assert current degree of wanting degree(?s2,?d2) ?20 assert object of wanting object(?s2,?p) ?21 assert reference time as time current ofwantingtime(?s2,tr) ?22 assert that time of previous wanting is be-fore reference timebefore(?t,tr) ?23 assert that current degree of wanting isgreater than previousgreaterThan(?d2,?d1) ?24 assert grammatical object as experiencer ofprevious wantingexperiencer(?s1,?y) ?25 assert grammatical object as experiencer ofcurrent wantingexperiencer(?s2,?y) ?26 assert proposition Proposition(?p) ?27 assert proposition Proposition(?p2) ?28 assert degree Degree(?d1) ?29 assert degree Degree(?d2) ?30 assert time Time(?t)Table 1: SWRL rule implementing the description of encourager2in (4)227of semantic roles (lines 9 to 11), the specification of the involved states (orevents) in lines 14 to 21 and 24 to 25, as well as the more specific temporaland degree assertions in lines 22 to 23 can be parametrised to suit otherverb senses.
For instance, the semantics of verbs like inviter a` P (?to inviteto P ?
), inciter a` P (?to incite to P ?
), pousser a` P (?push to P ?)
and othersalso involve a comparison between different degrees of wanting P associatedto different states.
One possibility to achieve parametrisation is to storeinformation on these individual segments as property values for the senseclasses.
These are read out by an external application and re-inserted intothe model in the form of a SWRL rule.
This way, it is not necessary to storeinference rules for every single word sense, but to have only a small set ofgenerally applicable static rules in the model, while specific ones applyingin a given discourse are created dynamically using externally completed ruletemplates.3 Disambiguation and Calculation of InferencesIn order to select the correct reading of a verbal predicate in a sentencelike (2) and, moreover, to generate the appropriate semantic representationon the basis of this choice, our system passes a number of distinct analy-sis steps.
Basically, the system receives input from a syntactic parser andtries to determine the correct senses of both the verbal predicate and itssyntactic arguments, before calculating the inferences permitted on this in-terpretation.
The process is summarised in Figure 1.For the scope of this paper, we will ignore details on the syntactic analysisthat precedes the semantic processing steps, and instead assume a syntacticparser which returns output like the one depicted in Figure 1, providinginformation on the predicate (encourager), its syntactic arguments (lettre,voisin and the infinitival complement), its modal context (e.g.
embeddingunder pouvoir, ?can, be able to?
), and the tense in which the predicate isused.
These context features are crucial for determining the inferences thatmay be drawn, and thus play an important role in the semantic processingsteps which build on the syntactic analysis (see below).3.1 Disambiguation of the predicate and its argumentsBefore the correct sense of the verbal predicate can be selected, its syntacticarguments have to be disambiguated first.
In order to achieve this, we applya methodology that has been presented in [Spohr, 2008], which is very muchin line with standard approaches to word-sense disambiguation (see e.g.228AgentSocialRole...Group...0.39570.3610...0.2315...0.03690.0369...?0.0066...GovernmtGov.Orga....Text...encourager1encouragerobj (?Agent)obj (?Agent)= 0 xcompPred owl:ThingAE>encouragerobj (Agent    SocialRole)obj (Agent    SocialRole)subj (Agent    SocialRole)subj (Agent    SocialRole)1 xcompPred owl:ThingAAEE>encouragerobj (Agent    SocialRole)obj (Agent    SocialRole)subj (?Agent)subj (?Agent)1 xcompPred owl:ThingAAEESubjectSUMO?EuroWordNet?MappingOutput of syntactic parser...tense = perfectivexcomp.pred = poserobj = voisinsubj = lettrepred = encouragerObjectSelectional preference lists3encouragerencourager2 encouragerReasonerFigure 1: Schema of the process of determining the intended sense ofencourager in (2) from syntactically parsed input[Schulte im Walde, 2008] for a recent account of related work in this field).The major difference is that it makes use of ontological categories based ona mapping between the French EuroWordNet ?
a lexical semantic resourcefor French (EWN; see e.g.
Vossen [1998]) ?
and the Suggested Upper MergedOntology (SUMO; Niles and Pease [2003]).
By applying this methodologyto a verb like encourager, we obtain lists of selectional preferences w.r.t.
tothe ontological types of its subject and object (see top righthand corner ofFigure 1).
For the actual disambiguation, the different senses of the subject(lettre in the present case) are looked up in the SUMO-EWN mapping, andthe sense scoring highest in the corresponding selectional preference list isselected.
The words are then asserted as instances of the respective class (inthis example Text for lettre and SocialRole for voisin) in the model.The disambiguation of the arguments is not a deterministic process.However, when viewed from the abstract level of SUMO concepts, the sensesdistinguished in EWN are often still closely related so that their distinctionshave no impact on the interpretation of the verb and thus the selection ofthe appropriate sense.
E.g., although the three senses of lettre in EWNmap onto two SUMO concepts (Text and Character), they are still sub-sumed under the common class ContentBearingPhysical, which suffices toselect the correct sense of encourager irrespective of the particular senseof lettre.
Thus, even though arguments may be disambiguated towardsthe wrong sense, the interpretation of the verb stays the same and the in-ferences drawn on the basis of this selection remain unaffected.
Once the229arguments have been disambiguated, they are linked to the instance repre-senting encourager.
The intermediate ABox obtained from the operationsso far looks as follows.
(6) encourager( s) ?
subj( s, lettre) ?
obj( s, voisin) ?
Text(lettre) ?SocialRole(voisin)The next step consists in determining the correct sense of encourager.As mentioned in Section 2 above, selectional restrictions have been imple-mented as necessary and sufficient conditions on class definitions, whichallows a reasoner to infer the type of the instance on the basis of theseconditions.
With the configuration in (6), the reasoner8correctly infers theinstance of encourager as being of the more specific type encourager2, asthis is the only class satisfying the condition of having a subject that is notan Agent, while having an object either of type Agent or SocialRole (cf.Figure 1).3.2 Calculation of inferencesThe assertion of encourager2( s) in combination with subj( s, lettre) ?obj( s, voisin) causes the SWRL rule in Table 1 above to fire, so that theinferences can be calculated and inserted into the ABox.
For this task weused version 7 of the Jess rule engine9.
The result of the rule application isillustrated in Figure 2 and represents all assertions made on the basis of theinput sentence (2).10The logical form of the graph is given below.
(7) encourager2( s)?
theme( s, lettre) ?
target( s, voisin) ?
goal( s, p2)?hasPart( p2, s1)?WANTING( s1)?degree( s1, d1)?object( s1, p)?time( s1, t)?hasPart( p2, s2)?WANTING( s2)?degree( s2, d2)?object( s2, p)?
time( s2, tr)?before( t, tr)?greaterThan( d2, d1)?experiencer( s1, voisin)?experiencer( s2, voisin)?Proposition( p)?
Proposition( p2) ?Degree( d1) ?Degree( d2) ?
T ime( t)After the application of this rule, we can execute the rule correspondingto the representation of the embedded infinitive, which is triggered by the useof the perfective tense in sentence (2).
In order to avoid repetition, we willrestrict ourselves to presenting only those statements that are introduced8We have used the Pellet OWL DL reasoner (http://pellet.owldl.com/).9See http://www.jessrules.com/.10The visualisation of the graph has been done using the Prote?ge?
Jambalaya plug-in(see http://www.thechiselgroup.org/jambalaya).230Figure 2: Model after execution of the SWRL rule in Table 1by the embedded infinitive.
Again, a certain sense of poser is instantiatedin the lexicon, which then triggers the application of an inference rule11.
(8) poser2( e) ?MOV ING( e) ?
agent( e, voisin) ?
theme( e, bombe) ?Weapon(bombe) ?
inside( s3, cave) ?
Artifact(cave) ?
theme( s3, bombe) ?outside( s4, cave)?theme( s4, bombe)?time( s4, t2)?time( e, t3)?before( t2, t3)?cause( e, s3)The interpretation of this logical form is that a ?moving?
event e tookplace that causes the bombe, which was outside of the basement at a previousstate s4, to be inside the basement at a state s3.
Moreover, this event eis linked to the representation given in (7) as being a part of the propositionp.
As a result, the model captures appropriately the fact that in sentence(2), the verb encourager instantiates what we called its implicative reading.11Weapon and Artifact are SUMO concepts subsuming the senses of bombe and cave.2314 ConclusionWe have presented an approach to modelling polysemous verbs using stan-dard formalisms such as OWL and SWRL.
We have shown how the disam-biguation of the verbs and their arguments can be performed in this setting,and how inferences can be calculated and inserted into a representation thatcan be interpreted by tools developed in the context of the Semantic Web.One of the advantages of our approach is that fine-grained sense distinc-tions based on contextual features enable accurate annotation of particularsenses, and with it the calculation of inferences allowed by the respectivesense.
Moreover, the resource combines formal semantics with up-to-datetechnology for semantic processing and is thus more formalised and detailedthan existing lexical semantic resources.
WordNet [Fellbaum, 1998], for ex-ample, distinguishes three senses of to encourage (1.
?support, back up?, 2.?inspire, animate...?, 3.
?induce, stimulate...?
), without accounting for thedifference between implicative and non-implicative readings: the examplesshow clearly that both are subsumed by sense 3 (e.g.
?The ads induced me tobuy a VCR?
vs. ?My children finally got me to buy a computer?).
FrameNet[Baker et al, 1998] contains only one sense of to encourage, which it asso-ciates with the Attempt Suasion frame.
This frame corresponds to thenon-implicative reading (definition: ?The Speaker expresses through lan-guage his wish to get the Addressee to act.
There is no implication thatthe Addressee forms an intention to act, let alne acts.?
), whereas e.g.
Sua-sion implies that the Addressee forms an intention or accepts some content.However, encourage is neither associated with this latter frame, nor witha frame implying an action.
Moreover, it does not emphasise the contex-tual parameters mentioned above (e.g.
the presence of arguments and theirontological type), which trigger certain interpretations and are crucial fordetermining the sense of a verb as well as its inferences.
More closely relatedis VerbNet [Kipper Schuler, 2005], though the major difference lies in theformal semantic description that is the output of our analysis.Although the system is ?
due to lack of coverage ?
not in a state of beingapplied to sophisticated reasoning tasks such as the RTE challenge [Daganet al, 2005], the inclusion of the contained knowledge into existing systemsdesigned for such tasks seems very promising.
The RTE challenge consists indetermining, given two text fragments, whether one text fragment is entailedby the other.
In our examples, the hypothesis ?A bomb has been placed.
?can only be inferred from sentence (2), not from (1).
This shows that greatdetail in the semantic description is a definite asset and an important stepbeyond the information contained in existing lexical semantic resources.232AcknowledgementsThis work has been done within the project ?Polysemy in a ConceptualSystem?
(SFB 732, project B5), funded by the German Research Foundation.ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.
The BerkeleyFrameNet project.
In Proceedings of COLING/ACL, Montreal, 1998.Rajesh Bhatt.
Covert Modality in Non-Finite Contexts.
PhD thesis, Uni-versity of Pennsylvania, 1999.Ido Dagan, Oren Glickman, and Bernardo Magnini.
The PASCAL Recognis-ing Textual Entailment Challenge.
In Proceedings of the PASCAL Chal-lenges Workshop on RTE, Southampton, UK, 2005.Christiane Fellbaum, editor.
WordNet ?
An Electronic Lexical Database.MIT Press, Cambridge, MA, USA, 1998.Enrico Franconi.
Natural Language Processing.
In The Description LogicHandbook: Theory, Implementation and Applications.
CUP, 2003.Lauri Karttunen.
Implicative verbs.
Language, 47:340?358, 1971.Karin Kipper Schuler.
VerbNet: A Broad-Coverage, Comprehensive VerbLexicon.
PhD thesis, University of Pennsylvania, 2005.Holger Knublauch, Mark A. Musen, and Alan L. Rector.
Editing descriptionlogic ontologies with the Prote?ge?
OWL plugin.
In Proceedings of DL 2004,Whistler, BC, 2004.Alda Mari and Fabienne Martin.
Tense, abilities and actuality entailment.In Maria Aloni, Paul Dekker, and Floris Roelofsen, editors, Proceedingsof the Sixteenth Amsterdam Colloquium, pages 151?156, 2007.Ian Niles and Adam Pease.
Linking Lexicons and Ontologies: MappingWordNet to the Suggested Upper Merged Ontology.
In Proceedings ofIKE ?03, Las Vegas, NV, 2003.Martin O?Connor, Holger Knublauch, Samson Tu, Benjamin Grosof, MikeDean, William Grosso, and Mark Musen.
Supporting Rule System Inter-operability on the Semantic Web with SWRL.
In Proceedings of the 4thInternational Semantic Web Conference, Galway, Ireland, 2005.233Sabine Schulte im Walde.
The Induction of Verb Frames and Verb Classesfrom Corpora.
In Corpus Linguistics.
An International Handbook, volume29.1 of Handbooks of Linguistics and Communication Science, pages 952?971.
Mouton de Gruyter, Berlin, 2008.Dennis Spohr.
Extraction of Selectional Preferences for French using aMapping from EuroWordNet to the Suggested Upper Merged Ontology.In Proceedings of the 4th Global WordNet Conference, Szeged, Hungary,2008.Piek Vossen, editor.
EuroWordNet: A Multilingual Database with LexicalSemantic Networks.
Kluwer Academic Publishers, 1998.234
