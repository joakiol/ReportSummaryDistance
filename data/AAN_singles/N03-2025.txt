Bootstrapping for Named Entity Tagging Using Concept-based SeedsCheng Niu, Wei Li, Jihong Ding, Rohini K. SrihariCymfony Inc.600 Essjay Road, Williamsville, NY 14221.
USA.
{cniu, wei, jding, rohini}@cymfony.comAbstractA novel bootstrapping approach toNamed Entity ?NE?tagging using con-cept-based seeds and successive learnersis presented.
This approach only requiresa few common noun or pronoun seedsthat correspond to the concept for the tar-geted NE, e.g.
he/she/man/woman forPERSON NE.
The bootstrapping proce-dure is implemented as training two suc-cessive learners.
First, decision list is usedto learn the parsing-based NE rules.
Then,a Hidden Markov Model is trained on acorpus automatically tagged by the firstlearner.
The resulting NE system ap-proaches supervised NE performance forsome NE types.1 OverviewRecognizing and classifying proper names is afundamental task for information extraction.
Threetypes of proper names are defined in the MessageUnderstanding Conference (MUC) Named Entity(NE) standards, namely, PERSON (PER),ORGANIZATION (ORG), and LOCATION(LOC).
[MUC-7 1998]There is considerable research on NE taggingusing supervised machine learning [e.g.
Bikel et al1997; Borthwick 1998].
To overcome the knowl-edge bottleneck of supervised learning, unsuper-vised machine learning has been applied to NE.
[Cucchiarelli & Velardi 2001] discussed boostingthe performance of an existing NE tagger by unsu-pervised learning based on parsing structures.
[Cucerzan & Yarowsky 1999], [Collins & Singer1999] and [Kim et al 2002] presented varioustechniques using co-training schemes for NE ex-traction seeded by a small list of proper names orhand-crafted NE rules.
NE tagging has two tasks:(i) NE chunking; (ii) NE classification.
Parsing-supported unsupervised NE learning systems in-cluding ours only need to focus on NE classifica-tion, assuming the NE chunks have beenconstructed by the parser.This paper presents a new bootstrapping ap-proach using successive learning and concept-based seeds.
The successive learning is as follows.First, parsing-based NE rules are learned with highprecision but limited recall.
Then, these rules areapplied to a large raw corpus to automatically gen-erate a tagged corpus.
Finally, a high-performanceHMM-based NE tagger is trained using this cor-pus.Unlike co-training, our bootstrapping does notinvolve iterative learning between the two learners,hence it suffers little from error propagation whichis commonly associated with iterative learning.To derive the parsing-based learner, the systemonly requires a few common noun or pronounseeds that correspond to the concept for the tar-geted NE, e.g.
he/she/man/woman for PERSONNE.
Such concept-based seeds share grammaticalstructures with the corresponding NEs, hence aparser is utilized to support bootstrapping.
Sincepronouns and common nouns occur more oftenthan NE instances, the parsing-based NE rules canbe learned in one iteration to avoid iterative learn-ing.The benchmarking shows that this system ap-proaches the performance of supervised NE tag-gers for two of the three proper name NE types inMUC, namely, PER NE and LOC NE.
This ap-proach also supports tagging user-defined NEtypes.2 ImplementationFigure 1 shows the overall system architecture.Before the bootstrapping is started, a large rawtraining corpus is parsed.
The bootstrapping ex-periment reported in this paper is based on a cor-pus containing ~100,000 news articles and totally~88,000,000 words.
The parsed corpus is savedinto a repository, which supports fast retrieval bykeyword based indexing scheme.Repository(parsed corpus)Decision ListNE LearningHMMNE LearningConcept-based Seedsparsing-based NE rulestraining corpusbased on tagged NEsNE tagging using   parsing-based rulesNETaggerBootstrapping ProcedureBootstrapping ProcedureFigure 1.
Bootstrapping System ArchitectureThe unsupervised bootstrapping is performed asfollows:1.
User provides concept-based seeds;2.
Retrieve parsing structures involving con-cept-based seeds from the repository to traina decision list for NE classification;3.
Apply the learned rules to the NE candidatesretrieved from the repository;4.
Construct an NE annotated corpus using thetagged proper names and their neighboringwords;5.
Train an HMM based on the annotated cor-pus.A parser is necessary for concept-based NEbootstrapping.
This is due to the fact that concept-based seeds only share pattern similarity with thecorresponding NEs at structural level, not at stringsequence level.
In fact, the anaphoric function ofpronouns and common nouns to represent antece-dent NEs indicates the substitutability of propernames by the noun phrases headed by the corre-sponding common nouns or pronouns.
For exam-ple, this man can substitute the proper name JohnSmith in almost all structural patterns.Five binary dependency relationships decodedby our parser are used for parsing-based NE rulelearning:  (i) a Has_Predicate(b): from logical sub-ject a to verb b; (ii) a Object_Of(b): from logicalobject a to verb b; (iii) a Has_Amod(b): from nouna to its adjective modifier b; (iv) a Possess(b):from the possessive noun-modifier a to head nounb; (v) a IsA(b):  equivalence relation (includingappositions)  from one NP a to another NP b.The concept-based seeds used in the experi-ments are: (i) he, she, his, her, him, man, womanfor PER; (ii) city, province, town, village for LOC;(iii) company, firm, organization, bank, airline,army, committee, government, school, universityfor ORG.From the parsed corpus in the repository, all in-stances (821,267) of the concept-based seeds in-volved in the five dependency relations areretrieved.
Each seed instance was assigned a con-cept tag corresponding to NE.
For example, eachinstance of he is marked as PER.
The instanceswith concept tagging plus their associated parsingrelationships are equivalent to an annotated NEcorpus.
Based on this training corpus, the DecisionList Learning algorithm [Segal & Etzioni 1994] isused.
The accuracy of each rule was evaluated us-ing Laplace smoothing as follows,No.category  NEnegativepositive1positive+++=accuracyAs the PER tag dominates the corpus due to thehigh occurrence frequency of he and she, learningis biased towards PER as the answer.
To correctthis bias, we employ the following modificationscheme for instance count.
Suppose there are a to-tal of PERN  PER instances, LOCN  LOC instances,ORGN ORG instances, then in the process of ruleaccuracy evaluation, the involved instance countfor any NE type will be adjusted by the coefficientNEORGLOCPERminN) , N, N(N .A total of 1,290 parsing-based NE rules, shownin samples below, are learned, with accuracyhigher than 0.9.Possess(wife)   PERHas_Predicate(divorce)  PERObject_Of(deport)  PERPossess(mayor)  LOCHas_AMod(coastal)  LOCPossess(ceo)  ORGHas_AMod(non-profit)  ORGHas_AMod(non-governmental)  ORG???
?Due to the unique equivalence nature of the IsArelation, we add the following IsA-based rules tothe top of the decision list: IsA(seed) tag of theseed, e.g.
IsA(man)  PERThe parsing-based first learner is used to tag araw corpus.
First, we retrieve all the named entitycandidates associated with at least one of the fiveparsing relationships from the repository.
Afterapplying the decision list to the retrieved 1,607,709NE candidates, 33,104 PER names, 16,426 LOCnames, and 11,908 ORG names are tagged.
In or-der to improve the bootstrapping performance, weuse the heuristic one tag per domain for multi-word NE in addition to the one sense per discourseprinciple [Gale et al1992].
These heuristics arefound to be very helpful in both increasing positiveinstances (i.e.
tag propagation) and decreasing thespurious instances (i.e.
tag elimination).
The tagpropagation/elimination scheme is adopted from[Yarowsky 1995].
After this step, a total of367,441 proper names are classified, including134,722 PER names, 186,488 LOC names, and46,231 ORG names.The classified proper name instances lead to theconstruction of an automatically tagged trainingcorpus, consisting of the NE instances and theirtwo (left and right) neighboring words within thesame sentence.In the final stage, a bi-gram HMM is trainedbased on the above training corpus.
The HMMtraining process follows [Bikel 1997].3 BenchmarkingWe used the same blind testing corpus of 300,000words containing 20,000 PER, LOC and ORG in-stances to measure performance degradation ofunsupervised learning from the existing supervisedNE tagger (Table 1, P for Precision, R for Recall, Ffor F-measure and F/D for F-measure degradation).Table 1: Supervised-to-Unsupervised NE DegradationSupervised NE Unsupervised NETYPE P R F P R F F/DPER 92.3% 93.1% 92.7% 86.6% 88.9% 87.7% 5.0%LOC 89.0% 87.7% 88.3% 82.9% 81.7% 82.3% 6.0%ORG 85.7% 87.8% 86.7% 57.1% 48.9% 52.7% 34.0%The performance for PER and LOC are above80%, and approaching the performance of super-vised learning.
The reason of the unsatisfactoryperformance of ORG (52.7%) is not difficult tounderstand.
There are numerous sub-types of ORGthat cannot be represented by the less than a dozenconcept-based seeds used for this experiment.In addition to the key NE types in MUC, wealso tested this method for recognizing user-defined NE types.
We use the following concept-based seeds for PRODUCT (PRO) NE: car, truck,vehicle, product, plane, aircraft, computer, soft-ware, operating system, database, book, platform,network.
Table 2 shows the benchmarks forPRODUCT tagging.Table 2: Performance for PRODUCT NETYPE PRECISION RECALL F-MEASUREPRODUCT 67.27% 72.52% 69.80%ReferencesBikel, D. M. 1997.
Nymble: a high-performance learn-ing name-finder.
Proceedings of ANLP?97, 194-201,Morgan Kaufmann Publishers.Borthwick, A. et al 1998.
Description of the MENEnamed Entity System.
Proceedings of MUC-7.Collins, M. and Y.
Singer.
1999.
Unsupervised Modelsfor Named Entity Classification.
Proceedings of theJoint SIGAT Conference on EMNLP andVLC.
??
?Association for Computational    Linguis-tics, 1999.Cucchiarelli, A. and P. Velardi.
2001.
UnsupervisedNamed Entity Recognition Using Syntactic and Se-mantic Contextual Evidence.
Computational Linguis-tics, Volume 27, Number 1, 123-131.Cucerzan, S. and D. Yarowsky.
1999.
Language    Inde-pendent Named Entity Recognition CombiningMorphological and Contextual Evidence.
Proceed-ings of the Joint SIGDAT Conference on    EMNLPand VLC, 90-99.Gale, W., K. Church, and D. Yarowsky.
1992.
OneSense Per Discourse.
Proceedings of the 4th DARPASpeech and Natural Language Workshop.
233-237.Kim, J., I. Kang, and K. Choi.
2002.
UnsupervisedNamed Entity Classification Models and their En-sembles.
Proceedings of COLING 2002.MUC-7, 1998.
Proceedings of the Seventh MessageUnderstanding Conference (MUC-7), published onthe website http://www.muc.saic.com/Segal, R. and O. Etzioni.
1994.
Learning decision listsusing homogeneous rules.
Proceedings of the 12thNational Conference on Artificial Intelligence.Yarowsky, David.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Method.
Pro-ceedings of ACL 1995.
