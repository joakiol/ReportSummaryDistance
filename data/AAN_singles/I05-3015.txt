Some Studies on Chinese Domain Knowledge Dictionary and ItsApplication to Text ClassificationJingbo ZhuNatural Language Processing LabInstitute of Computer Software & TheoryNortheastern University, Shenyangzhujingbo@mail.neu.edu.cnWenliang ChenNatural Language Processing LabInstitute of Computer Software & TheoryNortheastern University, ShenyangChenwl@mail.neu.edu.cnAbstractIn this paper, we study some issues onChinese domain knowledge dictionaryand its application to text classificationtask.
First a domain knowledge hierar-chy description framework and ourChinese domain knowledge dictionarynamed NEUKD are introduced.
Second,to alleviate the cost of construction ofdomain knowledge dictionary by hand,we use a boostrapping-based algorithmto learn new domain associated termsfrom a large amount of unlabeled data.Third, we propose two models (BOTWand BOF) which use domain knowl-edge as textual features for text catego-rization.
But due to limitation of size ofdomain knowledge dictionary, we fur-ther study machine learning techniqueto solve the problem, and propose aBOL model which could be consideredas the extended version of BOF model.Na?ve Bayes classifier based on BOWmodel is used as baseline system in thecomparison experiments.
Experimentalresults show that domain knowledge isvery useful for text categorization, andBOL model performs better than otherthree models, including BOW, BOTWand BOF models.1 IntroductionIt is natural for people to know the topic of thedocument when they see some specific words inthe document.
For example, when we read anews, if title of the news includes a word ???
(Yao Ming)?, as we know, ???
(Yao Ming)?
isa famous China basketball athlete in US NBAgame, so we could recognize the topic of thedocument is about ???
,??
(Basketball,Sports)?
with our domain knowledge.
In thispaper, we call the specific word ???
(YaoMing)?
as a Domain Associated Term (DAT).
ADAT is a word or a phrase (compound words)that enable humans to recognize intuitively atopic of text with their domain knowledge.
Infact, domain knowledge is a kind of common-sense knowledge.
We think that domain knowl-edge is very useful for text understanding tasks,such as text classification, document summariza-tion, and information retrieval.In previous literatures, some researchersused knowledge bases for text understandingtasks(Scott et al, 1998), such as WordNet forEnglish and HowNet for Chinese.
We know thatWordNet and HowNet are lexical and semanticknowledge resources.
Other researchers tried touse commonsense knowledge such as field-associated terms for text understanding tasks(M.Fuketa et al, 2000, Sangkon Lee and MasamiShishibori, 2002).
But the problem of limitationof size of such knowledge base is still a key bot-tleneck for using domain knowledge dictionaryfor text understanding tasks, and how to solve itis an ongoing research focus.In the following content, we try to give an-swers to four questions: 1)What is our Chinesedomain knowledge dictionary NEUKD?
2)Howto learn DATs from a large amount of unlabelleddata?
3)How to use the Chinese domain knowl-edge dictionary NEUKD for text classification?4)Due to the problem of limitation of size ofdomain knowledge dictionary, how to solve the110problem and improve performance of text classi-fication using domain knowledge dictionary?2 Domain Knowledge DictionaryWe first introduce briefly domain knowledgehierarchy description framework (DKF) whichincludes three levels: Domain Level (DL), Do-main Feature Level (DFL) and Domain Associ-ated Term Level (DATL).
The DL is the toplevel which defines many domains, such as ???
(Sports)?, ???
(Military Affairs)?.
The DFLis the second level which defines many domainfeatures.
A domain defined in the DL has a lot ofdomain features defined in the DFL.
Forexample, domain ???
(Military Affairs)?
hasmany domain features, such as ???
(ArmyFeature)?, ???
(Weapon Feature)?
and ???
(War Feature)?.
The DATL is the third levelwhich defines many domain associated terms.Many domain associated terms could indicate asame domain feature defined in the DFL.
Forexample, some domain associated terms, such assome domain associated terms, such as ?????
(Mid-East War)?, ??????
(Iraq War)?and ??????
(Afghanistan War)?, indicatedomain feature ???
(War)?.Since 1996 we employed a semi-automaticmachine learning technique to acquire domainknowledge from a large amount of labeled andunlabeled corpus, and built a general-purposedomain knowledge dictionary named NEUKDaccording to the domain knowledge hierarchydescription framework(Zhu Jingbo et al, 2002).Items defined in the NEUKD include domainassociated term, domain feature and domain.Currently 40 domains, 982 domain features andmore than 610,000 domain associated terms aredefined in the NEUKD.
Some instances ofNEUKD are given in Table 1.
Because the sizeof NEUKD is limited, so in following contentwe will study machine learning techniques tosolve the problem of using NEUKD for textclassification task.Domain Associated Terms Domain Features Domain??
(Yao Ming)?
?, ???
(Basketball, Athlete)??
(Sports )????
(The Sanxia project)????
(Irrigation Project)??
(Irrigation Works)??
(Match Season)??(Match)??
(Sports )????
(Arsenal Team)??(Football)??(Sports)??????
(Industrial and commercial bank of China)??(Bank)??
(Finance)Table 1.
Some instances defined in the NEUKD3 Bootstrapping-based DAT LearningAlgorithmTo extend domain knowledge dictionary, in thispaper, we will use a feature learning algorithmbased on bootstrapping (FLB)(Zhu Jingbo et al,2004) to learning new DATs.
In the FLB learn-ing procedure, some seed words are given inadvance.
In fact, seed words are some importantDATs.
For example, ten seed words of domain???(finance)?
are??
(stock), ??(finance),??
(loan), ??
(stock), ??
(finance and eco-nomics), ??
(bank), ??
(tax), ??
(foreignexchange), ??
(investment) and ??
(stockmarket).The FLB learning procedure is described asfollows:z Initialization: Use a small number of seedwords initialize DAT setz Iterate Bootstrapping:?
Candidate DAT Learner: Learn somenew DATs as candidate DATs fromunlabeled data.?
Evaluation: Score all candidate DATs,and select top-n best DATs as newseed words, and add them into DAT set.In the beginning of algorithm, all words ex-cept stopwords in the unlabeled corpus could be111considered as candidate DATs.
In fact, we canregard bootstrapping as iterative clustering.
Inthe evaluation step of FLB algorithm, RlogFmetric method(Ellen Riloff, Rosie Jones, 1999)is used as evaluation function which assigns ascore to a word(candidate DAT).
The score of aword is computed as:iii RXwFLogwM u ),()( 2            (1)Where F(wi,X) is the frequency of co-occurrenceof word wi and X (set of seed words) in the samesentence, F(wi) is the frequency of wi in the cor-pus, and Ri=F(wi,X)/F(wi).
The RlogF metrictries to strike a balance between reliability andfrequency: R is high when the word is highlycorrelated with set of seed words, and F is highwhen the word and X highly co-occur in thesame sentence.In the experiments, we use the corpus from1996-1998 People?s Daily as unlabeled datawhich has about 50 million words.
For domain???
(finance)?, we select ten seed wordsshown in above example, the bootstrapping-based DAT learning algorithm obtains 65% pre-cision performance within top-1000 new learnedDATs according to human judgment.4 Domain Knowledge based Text Clas-sificationIn this paper, na?ve Bayes(NB) model(McCallum and K.Nigam, 1998) is used to buildtext classifier.
We want to study how to use ourChinese domain knowledge dictionary NEUKDto improve text categorization.4.1 BOW ModelThe most commonly used document representa-tion is the so called vector space model(G.Saltonand M.J.McGill, 1983).
In the vector spacemodel, documents are represented by vectors ofterms (textual features, e.g.
words, phases, etc.
).Conventional bag-of-words model (BOW) usescommon words as textual features.
In the com-parison experiments, we use the BOW model asbaseline NB system.4.2 BOTW ModelAs above mentioned, more than 610000 domainassociated terms (DATs) are defined in theNEUKD, such as ???
(Yao Ming) ?, ?????
(The Sanxia project)?, and ???????
(Industrial and commercial bank of China)?shown in table 1.
We use domain associatedterms and common words as textual features,called BOTW models (short for bag-of-termsand words model).
For example, in the previousexamples, the DAT ?????
(The Sanxia pro-ject, Sanxia is a LOCATION name of China)?can be used as a textual feature in BOTW model.But in BOW model(baseline system) we con-sider two common words ???
(The Sanxia)?and ???(project)?
as two different textual fea-tures.4.3 BOF ModelSimilar to BOTW model, we use domain fea-tures as textual features in the NB classifier,called BOF model (short for bag-of-featuresmodel).
In BOF model, we first transform allDATs into domain features according to defini-tions in the NEUKD, and group DATs withsame domain features as a cluster, called TopicCluster.
For Examples, Topic Cluster ???(sports)?
includes some DATs, such as ???
(match season)?, ?????
(Arsenal)?, ????
(Olympic Games)?, ????
(Table Tennis)?,???
(Yao Ming)?.
In BOF model, we use topicclusters as textual features for text categorization.Also the classification computation procedure ofBOF model is same as of BOW model.4.4 BOL ModelTo solve the problem of the limitation ofNEUKD, in this paper, we propose a machinelearning technique to improve BOF model.
Thebasic ideas are that we wish to learn new DATsfrom pre-classified documents, and group theminto the predefined topic clusters which areformed and used as textual features in BOFmodel discussed in section 4.3.
Then these newtopic clusters could be used as textual featuresfor text categorization.
We call the new model asBOL model(short for bag-of-learned featuresmodel) which could be consider as an extendedversion of BOF model.First we group all DATs originally defined inNEUKD into a lot of topic clusters as describedin BOF model, which are used as seeds in fol-lowing learning procedure.
Then we group otherwords (not be defined in NEUKD) into thesetopic clusters.
The Learning algorithm is de-scribed as following:- Preprocessing: Text segmentation, extract-ing candidate words, and sort the candidatewords by CHI method.
As above mentioned,all candidate words except stopwords which112are not defined in NEUKD will be groupedinto topic clusters in this process.- Initialization: These words, which are de-fined in NEUKD, are first added to corre-sponding topic clusters according to theirassociated domain features, respectively.- Iteration: Loop until all candidate wordshave been put into topic clusters:?
Measure similarity of a candidate wordand each topic cluster, respectively.?
Put the candidate word into the mostsimilar topic cluster(Note that a wordcan only be grouped into one cluster).The important issue of above procedures ishow to measure the similarity between a wordand a topic cluster.
Chen Wenliang et.
al.
(2004)proposed a measure for word clustering algo-rithm used in text classification.
So in this paper,we use Chen?s measure to measure the similaritybetween a word and a topic cluster in abovelearning algorithm.
The similarity of a word wtand a topic cluster fj is defined as| |1( )( ( , ) ( , ))( ) ( )( )( ) | |t t t j j t jt jt LiiS w w w f f w fN w N fwN f WO [ [O?
 ??
(2)Where( )( , )( ) ( )( ( | ) || ( | ))( )( , )( ) ( )( ( | ) || ( | ))tt t jt jt t jjj t jt jj t jP ww w fP w P fD P C w P C w fP ff w fP w P fD P C f P C w f[[?
u ??
u ?Where we define the distribution P(C|wt) as therandom variable over classes C, and its distribu-tion given a particular word wt.
N(fi) denote thenumber of words in the topic cluster fi, W is thelist of candidate words.To describe how to estimate distributionP(C|f) , we first assume that in the beginning oflearning procedure, only a word w1 is includedin topic cluster f1, we could say that P(C|f1) =P(C|w1).
When a new word w2 is added intotopic cluster f1, we could get a new topic clusterf2.
How to estimate the new distribution P(C|f2)is key step, where f2=w2?f1.
We could use thefollowing formula (3) to estimate distributionP(C|f2) =P(C|w2?f1).
Similarly, we could knowif the new word wn is added into topic cluster fn-1to form a new topic cluster fn, we also could es-timate P(C|fn)=P(C|wn?fn-1) following this way,and so on.2 2 1222 1112 1( | ) ( | )( ) ( | )( ) ( )( ) ( | )( ) ( )P C f P C w fP w P C wP w P fP f P C fP w P f? (3)We turn back the question about how to meas-ure the difference between two probabilitydistributions.
Kullback-Leibler divergence isused to do this.
The KL divergence between twoclass distributions induced by wt and ws is writ-ten as| |1( ( | ) || ( | ))( | )( | ) log( )( | )t sCj tj tj j sD P C w P C wP c wP c wP c w?
(4)In preprocessing step, the CHI statistic meas-ures the lack of independence of feature t andcategory c.D)B)(CD)(AC)(B(ABC)-N(ADc)2(t,2 FWhere t refers to a feature and c refers to a cate-gory, A is the number of times t and c co-occur,B is the number of times t occurs without c, C isthe number of times c occurs without t, D is thenumber of times neither c nor t co-occur, and Nis the total number of documents.5 Experimental ResultsIn this paper, we use na?ve Bayes for classifyingdocuments.
Here we only describe multinomialna?ve Bayes briefly since full details have beenpresented in the paper(McCallum and K.Nigam,1998).
The basic idea in na?ve Bayes approachesis to use the joint probabilities of words andcategories to estimate the probabilities of catego-ries when a document is given.
Given a docu-ment d for classification, we calculate theprobabilities of each category c as follows:( | )| |1( ) ( | )( | ) ( )( | )( ) ( | )!iN t dTii iP c P d cP c d P dP t cP c N t dv ?Where N(ti|d) is the frequency of word ti indocument d, T is the vocabulary and |T| is the113size of T, ti is the ith word in the vocabulary, andP(ti|c) thus represents the probability that a ran-domly drawn word from a randomly drawndocument in category c will be the word ti.In the experiments, we use NEU_TC dataset(Chen Wenliang et.
al.
2004) to evaluate theperformance of baseline NB classifier and ourclassifiers.
The NEU_TC data set contains Chi-nese web pages collected from web sites.
Thepages are divided into 37 classes according to?Chinese Library Categorization?(CLCEB,1999).
It consists of 14,459 documents.
We donot use tag information of pages.
We use thetoolkit CipSegSDK(Yao Tianshun et.
al.
2002)for word segmentation.
We removed all wordsthat had less than two occurrences.
The resultingvocabulary has about 60000 words.In the experiments, we use 5-fold cross vali-dation where we randomly and uniformly spliteach class into 5 folds and we take four folds fortraining and one fold for testing.
In the cross-validated experiments we report on the averageperformance.
For evaluating the effectiveness ofcategory assignments by classifiers to docu-ments, we use the conventional recall, precisionand F1 measures.
Recall is defined to be the ra-tio of correct assignments by the system dividedby the total number of correct assignments.
Pre-cision is the ratio of correct assignments by thesystem divided by the total number of the sys-tem?s assignments.
The F1 measure combinesrecall (r) and precision (p) with an equal weightin the following form:prrpprF 2),(1In fact, these scores can be computed for thebinary decisions on each individual categoryfirst and then be averaged over categories.
Theway is called macro-averaging method.
Forevaluating performance average across class, weuse the former way called micro averagingmethod in this paper which balances recall andprecision in a way that gives them equal weight.The micro-averaged F1 measure has been widelyused in cross-method comparisons.To evaluate the performance of these fourmodels based on NB classifier, we construct foursystems in the experiments, including BOW,BOTW, BOF and BOL classifier.
CHI measureis used to feature selection in all text classifiers.Figure 1.
Experimental results of BOW, BOTW, BOF, BOL classifiersIn figure 1, we could find that BOTW classi-fier always performs better than BOW classifierwhen the number of features is larger than about500.
From comparative experimental results ofBOTW and BOW classifiers, we think that do-main associated items are a richer and more pre-cise representation of meaning than commonwords.
Because the total number of domain fea-tures in NEUKD is only 982, in figure 1 we findthe maximum number of features (domain fea-114tures) for BOF and BOL classifier is less than1000.
When the number of features is between200 and 1000, BOF classifier performs betterthan BOW and BOTW classifiers.
It is also ob-vious that BOL classifier always performs betterthan other three classifiers when the number offeatures is less than 1000.
As above mentioned,in BOL model, we use a machine learning tech-nique to solve the problem of limitation of sizeof NEUKD, and group rest 65.01% words intopredefined topic clusters as textual features inBOL model.
So the classifier based on BOLmodel can yield better performance than BOFmodel.6 Conclusions and Future WorkIn this paper, we first introduce our Chinese do-main knowledge dictionary NEUKD.
To allevi-ate the cost of construction of domainknowledge dictionary by hand, we propose aboostrapping-based algorithm to learn new do-main associated terms from a large amount ofunlabeled data.
This paper studies how to im-prove text categorization by using domainknowledge dictionary.
To do it, we propose twomodels using domain knowledge as textual fea-tures.
The first one is BOTW model which usesdomain associated terms and common words astextual features.
The other one is BOF modelwhich uses domain features as textual features.But due to limitation of size of domain knowl-edge dictionary, many useful words are lost inthe training procedure.
We study and use a ma-chine learning technique to solve the problem toimprove knowledge-based text categorization,and propose a BOL model which could be con-sidered as the extension version of BOF model.Comparison experimental results of those fourmodels (BOW, BOTW, BOF and BOL) showthat domain knowledge is very useful for im-proving text categorization.
In fact, a lot ofknowledge-based NLP application systems haveto face the problem of limitation of size ofknowledge bases.
Like our work discussed inthis paper, we think that using machine learningtechniques is a good way to solve such problem.In the future work, we will study how to applythe domain knowledge to improve other text un-derstanding tasks, such as information retrieval,information extraction, topic detection and track-ing (TDT).AcknowledgementsThis research was supported in part by the Na-tional Natural Science Foundation of China &Microsoft Research Asia (No.
60203019), theKey Project of Chinese Ministry of Education(No.
104065), and the National Natural ScienceFoundation of China (No.
60473140).ReferencesChen Wenliang, Chang Xingzhi, Wang Huizhen, ZhuJingbo, and Yao Tianshun.
2004.
AutomaticWord Clustering for Text Categorization UsingGlobal Information.
First Asia Information Re-trieval Symposium (AIRS 2004), LNCS, Beijing,pp.1-6CLCEB.
1999.
China Library Categorization Edito-rial Board.
China Library Categorization (The 4thed.)
(In Chinese), Beijing, Beijing Library Press.Ellen Riloff, Rosie Jones.
1999.
Learning Dictionar-ies for Information Extraction by Multi-LevelBootstrapping, Proceedings of the Sixteenth Na-tional Conference on Artificial Intelligence.G.Salton and M.J.McGill, 1983.
An introduction tomodern information retrieval, McGraw-Hill.McCallum and K.Nigam.
1998.
A Comparison ofEvent Models for na?ve Bayes Text Classification,In AAAI-98 Workshop on Learning for Text Cate-gorization.M.
Fuketa, S.Lee, T.Tsuji, M.Okada and J. Aoe.
2000.A document classification method by using fieldassociated words.
International Journal of Infor-mation Sciences.
126(1-4), p57-70Sangkon Lee, Masami Shishibori.
2002.
Passage seg-mentation based on topic matter, Internationaljournal of computer processing of oriental lan-guages, 15(3), p305-339.Scott, Sam?Stan Matwin.
1998.
Text classificationusing WordNet hypernyms.
Proceedings of theCOLING/ACL Workshop on Usage of WordNet inNatural Language Processing Systems, Montreal.Yao Tianshun, Zhu Jingbo, Zhang li, and Yang Ying,2002.
Natural Language Processing- research onmaking computers understand human languages,Tsinghua University Press, (In Chinese).Zhu Jingbo and Yao Tianshun.
2002.
FIFA-basedText Classification, Journal of Chinese Informa-tion Processing, V16, No3.
(In Chinese)Zhu Jingbo, Chen Wenliang, and Yao Tianshun.
2004.Using Seed Words to Learn to Categorize ChineseText.
Advances in Natural Language Processing:4th International Conference (EsTAL 2004),pp.464-473115
