Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 165?173,October 25, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsA Large Scale Arabic Sentiment Lexiconfor Arabic Opinion MiningGilbert Badaro, Ramy Baly, Hazem HajjElectrical and Computer Engineering DepartmentAmerican University of Beirut, Lebanon{ggb05,rgb15,hh63}@aub.edu.lbNizar HabashComputer Science DepartmentNew York University Abu Dhabi, UAEnizar.habash@nyu.eduWassim El-HajjComputer Science DepartmentAmerican University of Beirut, Lebanonwe07@aub.edu.lbAbstractMost opinion mining methods in Englishrely successfully on sentiment lexicons,such as English SentiWordnet (ESWN).While there have been efforts towardsbuilding Arabic sentiment lexicons, theysuffer from many deficiencies: limitedsize, unclear usability plan given Ara-bic?s rich morphology, or non-availability publicly.
In this paper, weaddress all of these issues and producethe first publicly available large scaleStandard Arabic sentiment lexicon (Ar-SenL) using a combination of existing re-sources: ESWN, Arabic WordNet, andthe Standard Arabic Morphological Ana-lyzer (SAMA).
We compare and com-bine two methods of constructing thislexicon with an eye on insights for Ara-bic dialects and other low resource lan-guages.
We also present an extrinsicevaluation in terms of subjectivity andsentiment analysis.1 IntroductionOpinion mining refers to the extraction of sub-jectivity and polarity from text (Pang and Lee,2005).
With the growing availability and popu-larity of opinion rich resources such as onlinereview sites and personal blogs, opinion miningis capturing the interest of many researchers dueto its significant role in helping people maketheir decisions (Taboada et al., 2011).
Someopinion mining methods in English rely on theEnglish lexicon SentiWordnet (ESWN) (Esuliand Sebastiani, 2006; Baccianella et al., 2010)for extracting word-level sentiment polarity.Some researchers used the stored positive ornegative connotation of the words to combinethem and derive the polarity of the text (Esuliand Sebastiani, 2005).Recently, special interest has been given tomining opinion from Arabic texts, and as a re-sult, there has also been interest in developing anArabic Lexicon for word-level sentiment evalua-tion.
The availability of a large scale Arabicbased SWN is still limited (Alhazmi et al., 2013;Abdul-Mageed and Diab, 2012; Elarnaoty et al.,2012).
In fact, there is no publicly available largescale Arabic sentiment lexicon similar to ESWN.Additionally there are limitations with existingArabic lexicons including deficiency in coveringthe correct number and type of lemmas.In this paper, we propose to address these chal-lenges, and create a large-scale sentiment lexiconbenefiting from available Arabic lexica.
Wecompare two methods with an eye towards creat-ing such resources for other Arabic dialects andlow resource languages.
One lexicon is createdby matching Arabic WordNet (AWN) (Black etal., 2006) to ESWN.
This path relies on the ex-istence of a wordnet, a rather expensive resource;while the second lexicon is developed by match-ing lemmas in the SAMA (Graff et al., 2009)lexicon to ESWN directly.
This path relies on theexistence of a mere dictionary, still expensive butmore likely available than a wordnet.
Finally, thecombination of the two lexicons is used to createthe proposed large-scale Arabic Sentiment Lexi-con (ArSenL).
Each lemma entry in the lexiconhas three scores associated with the level ofmatching for each of the three sentiment labels:positive, negative, and objective.The paper is organized as follows.
A literaturereview presented in section 2 is conducted onwork that involved developing multilingual lexi-165cal resources.
In section 3, the steps followed tocreate ArSenL are detailed.
Extrinsic evaluationof ArSenL is discussed in section 4.
In section 5,we conclude our work and outline possible ex-tensions.2 Literature ReviewThere have been numerous efforts for creatingsentiment lexica in English and Arabic.
Esuli andSebastiani (2006) introduced English Senti-WordNet (ESWN), a resource that associatessynsets in the English WordNet (EWN) withscores for objectivity, positivity, and negativity.ESWN has been widely used for opinion miningin English (Denecke, 2008; Ohana and Tierney,2009).
Staiano and Guerini (2014) introducedDepecheMood, a 37K entry lexicon assigningemotion scores to words.
This lexicon was creat-ed automatically by harvesting social media dataand affective annotated data.In the context of developing sentiment lexicaand resources for Arabic, Abdul-Mageed et al.
(2011) evaluated the use of an adjective polaritylexicon on a manually annotated portion of thePenn Arabic Treebank.
They describe the pro-cess of creating the adjective polarity lexicon(named SIFAAT) in Abdul-Mageed and Diab(2012) using a combination of manual and auto-matic annotations.
The manual annotation con-sisted of extracting 3,982 Arabic adjectives fromthe Penn Arabic Tree (part 1) and manually la-beling them into three tags: positive, negative orneutral.
The automated annotation relied on theautomatic translation of the ESWN synsets andglosses using Google translate.
More recently,Abdul-Mageed and Diab (2014) extended theirlexicons creating SANA, a subjectivity and sen-timent lexicon for Arabic.
SANA combines dif-ferent pre-existing lexica and involves extensivemanual annotation, automatic machine transla-tion and statistical formulation based on point-wise mutual information.
The process also in-volved gloss matching across several resourcessuch as THARWA (Diab et al., 2014) and SA-MA (Graff et al., 2009).
SANA included 224,564entries which cover Modern Standard Arabic(MSA) as well as Egyptian and Levantine dia-lects.
These entries are not distinct and possessmany duplicates.
Through these different publi-cations, the authors heavily rely on two types oftechniques: manual annotations, which can berather expensive (yet accurate) and automatictranslation which is cheap (but very noisy sincethe Arabic output is not diacritized and no POSinformation was used).
Their SANA lexicon hasa mix of lemmas and inflected forms, many ofwhich are not diacritized.
This is not a problemin itself, but it limits the usability of the resource.That said, we use their annotated PATB corpusand SIFAAT lexicon for evaluating our lexicon.We focus on these two resources because theywere manually created and are of good quality.Alhazmi et al.
(2013) linked the Arabic Word-Net to ESWN through the provided synset offsetinformation.
Their approach had limited cover-age (~10K lemmas only) and did not define aprocess for using the lexicon in practical applica-tion given Arabic?s complex morphology.
Fur-thermore it is not yet publicly available and wasnot evaluated in the context of an application.In addition to English and Arabic sentimentlexica development, recent efforts were put todevelop a multilingual sentiment lexicon.
Chenand Skienna (2014) proposed an automatic ap-proach for creating sentiment lexicons for 136major languages that include Arabic by integrat-ing several resources to create a graph acrosswords in different languages.
The resources usedwere Wiktionary, Machine translation (Google),Transliteration and WordNet.
They created linksacross 100,000 words by retrieving five binaryfields using the above four resources.
Then usinga seed list obtained from Liu?s English lexicon(2010) the sentiment labels are propagated basedon the links in the developed graph.
The result-ing Arabic sentiment lexicon which is of smallsize was compared to SIFAAT (Abdul-Mageedand Diab, 2012).We are inspired by these efforts for Arabic sen-timent lexicon creation.
We extend them bycomparing different methods for creating such aresource with implications for other languages.Our lexicon is not only large-scale with highcoverage and high accuracy, but it is also public-ly available.
Finally, our lemma-based lexicon islinked to a morphological analyzer for ease ofuse in conjunction with Arabic lemmatizer suchas MADA (Habash and Rambow, 2005).3 Approaches to Lexicon CreationWe define our target Arabic Sentiment Lexicon(or ArSenL) as a resource, pairing Arabic lem-mas used in the morphological analyzer SAMAwith sentiment scores such as those used inESWN (positive, negative and neutral scores).We briefly describe next the different resourceswe use, followed by two methods for creatingArSenL: using an existing Arabic WordNet orusing English glosses in a dictionary.1663.1 ResourcesWe rely on four existing resources to create Ar-SenL: English WordNet (EWN), Arabic Word-Net (AWN), English SentiWordNet (ESWN) andSAMA.
A high level summary of characteristicsis shown in Table 1.Lexicon Language Sentiment  #Synsets #LemmasEWN English No ~90K ~120KAWN Arabic No ~10K ~7KESWN English Yes ~90K ~120KSAMA Arabic-EnglishNo N/A ~40KArSenL Arabic Yes 157,969 28,760Table 1.
The different resources used to build ArSenL.The English WordNet (EWN) (Miller et al.,1990) is perhaps one of the most used resourcesfor English NLP.
Several offset-linked versionsof EWN have been released (2.0, 2.1, 3.0 and3.1).
The offset is a unique identifier for a synsetin EWN.
EWN includes a dictionary augmentedwith lexical relations (synonymy, antonymy,etc.)
and part-of-speech (POS) tags.Arabic WordNet (AWN 2.0) (Black et al.,2006) was part of a Global WordNet projectwhose aim was to develop WordNets similar toEWN but for different languages.
AWN entriesare connected by offsets to EWN 2.0.
AWN doesnot include Arabic examples or glosses as EWN,but include POS tags.English SentiWordNet (ESWN 3.0) (Esuliand Sebastiani, 2006) is a large-scale EnglishSentiment lexicon that provides for each synsetin EWN 3.0 three sentiment scores whose sum isequal to 1: Pos, Neg, and Obj.
ESWN has thesame offset mappings of EWN across its differ-ent versions.Standard Arabic Morphological Analyzer(SAMA 3.1) (Graff et al., 2009) is a commonlyused morphological analyzer for Arabic.
Eachlemma has a POS tag and English gloss.
Theanalyzer produces for a given word all of its pos-sible readings out of context.3.2 Arabic WordNet-based ApproachIn this approach, we rely on the existence of arichly annotated resource, namely a wordnet,which is aligned to the ESWN.
For Arabic, thisapproach requires two steps: mapping AWN toESWN and mapping SAMA to AWN.
The map-ping between AWN to EWSN provides us withthe sentiment scores and the mapping betweenAWN and SAMA provides us with the correctlemma forms for the words in AWN.
We refer tothe resulting lexicon as ArSenL-AWN.Mapping AWN to ESWN.
The entries in thevarious Wordnet resources we use are nicelylinked through offsets to allow backward com-patibility and linkage (see Figure 1).
Figure 1shows the connection with a walking examplefor the word ?????
$aEor1 ?hair?.
We use the avail-able offset maps to link synsets in AWN 2.0 tothose in ESWN 3.0 and thus are able to assignsentiment scores to the AWN 2.0 entries.
Wemake use of sense map files provided by Word-Net that connect its three different versions 2.0,2.1 and 3.0.
Since some of the offsets were usedto refer to different entries in WordNet, POS tagswere also checked to validate the mapping.
Theprocess of aligning AWN to ESWN yielded veryreliable links.We manually checked each of the 9,692 terms inAWN and their ESWN English complements.Out of the 9,692, there were only 9 AWN wordsthat did not match with anything in ESWN; and48 entries in AWN that had no lemmas to startwith although they were linked to ESWN.
Theseterms were dropped for the next processing per-formed.
Thus, this technique only allowed us toline 9,635 synsets corresponding to 6,967 Arabiclemmas.
Through this process, we noticed thatthere were no sense map files for adjectives inWordNet which limited the mappings performedin this approach to nouns and verbs only.Mapping SAMA to AWN.
The alignment ofArabic lemmas in SAMA and AWN is compli-cated due to several issues:a. SAMA and AWN do not always agree onlemma orthography, e.g., long vowel A is rep-resented as A in SAMA and aA in AWN, andthe two resources do not always agree onHamzated Alif forms (Habash, 2010).
The is-sue of Hamzated Alif is solved by replacing itin both resources by the letter A.
The defini-tion of lemmas varies between the two, e.g.,SAMA does not use the definite article innouns, and uses the stem of the 3rd personmasculine singular verb (as opposed to fullform): katab not kataba ?to write?.b.
AWN has multi-word lemmas, which SAMAlacks.1 Arabic transliteration is provided in the BuckwalterScheme (Buckwalter, 2004).167AWN 2.0 EWN 2.0 EWN 2.1 EWN 3.0 ESWN 3.0Extract SentimentScoresn  04952502 Hair n  4952502 05192227 0525479505254795Pos = 0.25Neg = 0Obj = 0.75Figure 1.
Steps to map AWN 2.0 to ESWN 3.0 with a walking example for the word ?????
$aEor ?hair?.To address these issues, we first exclude the mul-ti-word lemmas in AWN, which account for1,695 lemmas out of 6,967 (24%).
Of the rest,exact matching against SAMA yields pairings for1,736 lemmas.
After applying a set of ortho-graphic and lemma-form normalization rules asindicated in Table 2, exact matching yields addi-tional 1927 lemma matches.
Finally, we back offto using the SAMA morphological analyzer onAWN terms and selecting the lemma with thelowest edit distance.
This step adds 1,094 lemmamatches.
Overall, 7,326 synsets entries corre-sponding to 5,002 lemmas in AWN are linked to4,507 lemmas in SAMA.
The linked lemmas ac-count for 95% of all single word lemmas inAWN, but only correspond to 12% of SAMAlemmas.
Moreover, we manually validated themapping between SAMA and AWN lemmas,specifically the ones that were mapped usingSAMA back off with minimum edit distancecomputation.
10% were not correct matches.
Wecorrected them and created a gold reference forthe lexicon, which we use in the evaluation sec-tion.
In Table 3, we report some entries that weremapped wrongly between AWN and SAMA andwhich were removed from the lexicon.In AWNAfterModificationExampleaA A (struggle)kifaAH ?
kifAHIf (pos = = vand lemmaends with a)Remove ?a?
(circulate)$aAEa ?$aAEIf lemmaends with KReplace K byiy(past)mADK ?
mADiyTable 2.
Summary of modifications performed toAWN lemmas in order to match them to SAMA.Examples of entries in ArSenL-AWN are shownin Table 4.
Each row represents a field in Ar-SenL-AWN.
AWN-Offset represents the offsetof the Arabic word in AWN 2.0.
SWN-Offset isthe mapped SWN 3.0 entry?s offset.
The AWNlemma is the lemma form that is found in AWN2.0 and SAMA lemma field is its correspondinglemma in SAMA form after performing thecleanup.
Positive and negative score fields arethe ones retrieved from SWN 3.0.
The confi-dence is a percentage that represents our confi-dence in the entry.AWN Offset 114276721 112853471 200548789SWN Offset 15133621 13619764 00564300POS tag N n vAWN Lemma >amad_n1AR AlgaAluwn_n1AR Haloma>a_v1ARSAMA Lemma >amobiyr_1 gAliy_1 Halum-u_1Positive Score 0 0 0Negative Score 0 0 0Confidence 100 100 100English Gloss Duration gallon hydrolizeTable 3.
Examples of entries that were mapped incorrectly from AWN to SAMA168SAMAESWNArSenllex:|riq_1 gloss:insomniac pos:adja 00187176 0 0.625watchful#2 sleepless#1insomniac#1 experiencing oraccompanied by sleeplessness;"insomniac old people";"insomniac nights";"lay sleepless all night";"twenty watchful, weary, tediousnights"- Shakespearen 10208748 0.125 0sleepless_person#1insomniac#1 someone who cannot sleepNA;10208748;n;NA;|riq_1;0.125;0;100NA;00187176;a;NA;|riq_1;0;0.625;100Figure 2.
Steps to map SAMA to ESWN 3.0 with a walking example for the word ??
?.Since AWN was connected to SWN through adirect mapping all the entries of ArSenL-AWNwere assigned 100% confidence.
In table 5, row3 summarizes the numbers obtained through theautomated process and row 7, the results ob-tained after manual correction.AWN Offset 100392523 201014980SWN Offset 00410247 01048569POS tag n vAWN Lemma EaAdap_n1AR SaAHa_v2ARSAMA Lem-maEAdap_1 SAH-i_1Positive Score 0.25 0Negative Score 0.125 0Confidence 100 100English Gloss habit, custom,practicescream, callTable 4.
Examples of entries in ArSenL-AWN.3.3 English Gloss-based ApproachIn this approach, we make use of the Englishglosses associated with the SAMA lemma en-tries.
For each entry, we find the synset inESWN with the highest overlap in SAMA Eng-lish glosses.
A walking example of the describedmethod is shown in Figure 2.
The recall of theSAMA gloss is used as a confidence measure ofthe mapping.
We refer to the resulting lexicon asArSenL-Eng.Each lemma in SAMA is appended with a glosslist that varies in size from 1 up to 6 words.
Let ndenote the number of words available in thegloss list.
We first attempt to match all the wordsin the list to the glosses of each entry in ESWN.If one or more matches are found, the scores areretrieved and a new entry in SAMA is processedas described.
In case there were no matches, wetry to find an overlap between a combination ofn-1 words of the SAMA gloss list and the glossesof ESWN.
If one or more matches are found, thescores are retrieved and each match is recordedin ArSenL-Eng.
Again, if no matches were ob-tained, the same process is repeated for the com-bination of n-2 words of the SAMA gloss list.Lexicon #Lemmas #Related SynsetsAutomatic ProcessArSenL-AWN 4,507 7,326ArSenL-Eng 28,540 150,700ArSenL-Union 28,812 158,026Manual CorrectionArSenL-AWN 4,492 7,269ArSenL-Union 28,780 157,969Table 5.
Sizes of the created sentiment lexica.This procedure is followed until we span all thewords in the gloss list.
As the number of wordsused in the combination to check for overlap be-tween the two resources decreases, the confi-dence percentage decreases.
In ArSenL-Eng, theconfidence measure is equal to the ratio of thenumber of words overlapping between SAMAand ESWN over the total number of words avail-able in the gloss list of the corresponding SAMAentry.
Besides checking the overlap of glosses,POS tags are also used to make sure that verbsare not mapped to nouns and vice versa.
Thistechnique results in mapping 150,700 ESWN169synsets corresponding to 28,540 distinct lemmasin SAMA (76%).
The validation of ArSenL-Engwas performed (a) automatically by using Ar-SenL-AWN and (b) manually by randomly vali-dating 400 distinct lemmas.
For the automatedpart, we check for each common lemma betweenthe two lexicons if the sentiment scores match.
Atotal of 3,833 lemmas (out of 4,507) from Ar-SenL-AWN were matched in ArSenL-Eng.Thus, we can inspect that the precision of theremaining scores is of 85%.
For the manual vali-dation, we check if the meaning of the SAMAlemma corresponds to the one in ESWN.
70% ofthe 400 randomly selected lemmas were accu-rately mapped to ESWN.
The main issue of theremaining 30% is the unavailability of enoughglosses per SAMA lemma, which makes theconnection weaker.
This approach did not in-volve manual correction and the lemma numbersare reported in row 4 of Table 5 along with theircorresponding number of related synsets.3.4 Combining the Two ApproachesWe combine the two lexica created above by tak-ing their union.
We refer to the resulting lexiconas ArSenL.
The details of the sizes of the threelexica are shown in Table 5.The union of the two lexicons consisted of com-bining the two resources and adding a field in thelexicon to distinguish the original source of theentry.
For instance, an entry from the first ap-proach, i.e.
ArSenL-AWN, will have an AWNoffset while an entry in ArSenL-Eng will havethe same field set to N.A (Not Available).
Fur-thermore, due to manual correction performed toArSenL-AWN, the gold version of the union lex-icon includes 28,780 lemmas with the corre-sponding number of 157,969 synsets.A public interface to browsing ArSenL is availa-ble at http://oma-project.com.
The interface al-lows the user to search for an Arabic word.
Theoutput would show the different scores for theArabic word along with the corresponding sen-timent scores, English glosses and examples thathelp in disambiguating different sentiment scoresfor the same Arabic lemma.
Work is also beingdone to allow searching for English words andfinding the corresponding Arabic words.
Snap-shot of the homepage is shown in Figure 3.4 EvaluationWe conduct an extrinsic evaluation to comparethe different versions of ArSenL on the task ofsubjectivity and sentiment analysis (SSA).
Wealso compare the performance of the SIFAATlexicon (Abdul-Mageed et al., 2011) discussed inSection 2.Experimental Settings We perform our experi-ments on the same corpus used by Abdul-Mageed et al.
(2011).
The corpus consists of 400documents form the Penn Arabic Treebank (part1 version 3) that are gold segmented and lemma-tized.
The sentences are tagged as objective, sub-jective-positive, subjective-negative and subjec-tive-neutral.Figure 3.
Homepage of the lexicon interface andsnapshots of examples searched through the interface.Positive, negative and objective scores are representedin green, red and gray respectively.We use nonlinear SVM implementation inMATLAB, with the radial basis function (RBF)kernel, to evaluate the different lexicons in thecontext of SSA.
The classification model is de-veloped in two steps.
In the first step, the kernelparameters (kernel?s width ?
and regularizationparameter ?)
are selected, and in the second stepthe classification model is developed and evalu-170ated based on the selected parameters.
To decideon the choice of RBF kernel parameters, we usethe first 80% of the dataset to tune the kernel pa-rameters to the values that produce the best F1-score using 5-fold cross-validation.
The resultingparameters are then used to develop and evaluatethe SVM model using 5-fold cross-validation onthe whole dataset.Two experiments were conducted to evaluate theimpact of the different lexicons on opinion min-ing.
The first experiment considers subjectivityclassification where sentences are classified aseither subjective or objective.
In this experiment,the SVM kernel parameters were tuned to max-imize the F1-score for predicting subjective sen-tences.
The second experiment considers senti-ment classification, where only subjective sen-tences are classified as either positive or negative.Subjective-neutral sentences are ignored.
In thisexperiment, the classifier?s parameters are tunedto maximize the average F1-score of positive andnegative labels.
We report the performancemeasures of the individual classes, as well astheir average.For baseline comparison, the majority class ischosen in each of the experiments, where all sen-tences are assigned to the majority class.
Forsubjective versus objective baseline classification,all sentences were classified as subjective sincethe majority (55.1%) of the sentences were sub-jective.
To further emphasize the importance ofdetecting subjectivity, we chose the F1-score forsubjective as baseline.
For positive versus nega-tive baseline classification, all sentences wereclassified as negative since the majority (58.4%)of the dataset was annotated as negative.
Theresulting baseline performance measures are cap-tured in Table 6, and serve as basis for compari-son with our developed models.
For the subjec-tive versus objective the baseline F1-score is71.1%, and for positive versus negative, thebaseline F1-score is averaged as 36.9%.Features We train the SVM classifier using sen-tence vectors consisting of three numerical fea-tures that reflect the sentiments expressed in eachsentence, namely positivity, negativity and ob-jectivity.
The value of each feature is calculatedby matching the lemmas in each sentence to eachof the lexicons separately: ArSenL-AWN, Ar-SenL-Eng, ArSenL-Union and SIFAAT.
Thecorresponding scores are then accumulated andnormalized by the length of the sentence.
Weremove all stop words in the process.
For wordsthat occur in the lexicon multiple times, the aver-age sentiment score is used.
It is worth notingthat the choice of aggregation for the differentscores and the choice of nonlinear SVM wasconcluded after a set of experiments, but not re-ported in the paper.
In this regards, we conducteda suite of experiments to evaluate the impact ofusing: (a) linear versus Gaussian nonlinear SVMkernels, (b) normalization based on sentencelength, (c) normalization using z-score versus not,and (d) using the confidence score from the lexi-cons.
Our best results across the different config-urations reflected the best results with the non-linear Gaussian RBF kernels, with sentencelength-based normalization and without confi-dence weighting.Base-lineArSenLSifaatAWN Eng UnionCoverage % NA 56.6 88.8 89.9 32.1SubjectiveF1 71.1 71.2 72.1 72.3 66Pre 55.1 58.1 58.5 58.3 61.5Rec 100 92 93.9 95.1 71.4PositiveF1 0 52.9 59.7 61.6 55.4Pre 0 44.7 55 55.2 51.8Rec 0 64.8 65.6 70.1 60.2NegativeF1 73.7 55 65.1 67.3 63Pre 58.4 67 70.7 75.6 67.6Rec 100 46.9 60.6 61 59.4Average  F1(Pos/Neg)36.9 53.9 62.4 64.5 59.2Table 6.
Results of extrinsic evaluation.
Numbers thatare highlighted reflect the best performances obtainedby the lexicons, without considering the baselineResults Three evaluations were conducted tocompare the performances of the developed sen-timent lexicons.
The results of the experimentsare shown in Table 6.
First, we evaluate the cov-erage of the different lexicons.
We define cover-age as the percentage of lemmas (excluding stopwords) covered by each lexicon.
ArSenL-AWNand SIFAAT have lower coverage than the Ar-SenL-Eng lexicon.
The union lexicon has thehighest coverage.
This is normally due to thelarger number of lemmas included in the Englishand union lexicons, as shown in Table 5.In subjectivity classification, ArSenL lexiconsperform better than the majority baseline andoutperform SIFAAT in terms of F1-score.
Over-all, the developed ArSenL-Union gives the bestperformance among all lexicons.
The only ex-ception of better performance for SIFAAT forsubjectivity is in terms of precision, which is as-sociated with a much lower recall resulting in anF1-score that is lower than that of ArSenL?s.171Similarly, sentiment classification experimentreveals that ArSenL lexicons produce results thatare consistently better than SIFAAT and the ma-jority baseline.
The ArSenL-Union lexicon out-performs all lexicons in all measures withoutexceptions.In summary, it can be observed that the English-based lexicon produces results that are superiorto the AWN-based lexicon.
Combining both re-sources, through the union, allows further im-provement in SSA performance.
It is also worthnoting that the English and union lexicons con-sistently outperform SIFAAT despite the factthat the latter was manually derived from thesame corpus we are using for evaluation.
Weclose by showing examples of ArSenL in Table 7.The lemmas are in their Buckwalter (2004) for-mat for easier integration in any NLP task.
Theword NA stands for Not Applicable.
In the casewhere AWN Offset is NA and AWN lemma isNA, this means that the entry is retrieved fromArSenL-Eng.
Otherwise, the entries are fromArSenL-AWN.
The additions to the lemmas suchas ?_v1AR?
, ?_n1AR?, ?_1?
or ?_2?
can bedropped when data processing is performed.They were kept for easier retrieval in the originalsources (AWN and SAMA).
We added the ?Eng-lish Gloss?
field for easier understanding of theArabic word in the table.
Moreover, it can beseen that only positive and negative scores arereported in the lexicon since the objective scorecan be easily derived by subtracting the sum ofpositive and negative scores from 1.5 Conclusion and Future WorkWe create a large sentiment lexicon for Arabicsentiments using different approaches linking toESWN.
We compared the two methods.
Ourresults show that using English-based linkingproduces, on average, superior performance incomparison to using the WordNet-based ap-proach.
A union of the two resources is betterthan either and outperforms a high-quality manu-ally-derived adjective sentiment lexicon for Ara-bic.In the future, we plan to make use of this lexiconto develop more powerful SSA systems.
We alsoplan to extend the effort to Arabic dialects andother languages.6 AcknowledgmentsThis work was made possible by NPRP 6-716-1-138 grant from the Qatar National ResearchFund (a member of Qatar Foundation).
Thestatements made herein are solely the responsi-bility of the authors.
Nizar Habash performedmost of his contribution to this paper while hewas at the Center for Computational LearningSystems at Columbia University.AWNOffsetSWNOffsetPOStagAWN Lemma SAMALemmaPositiveScoreNegativeScoreConfi-denceEnglishGlossNA 04151581 n NA $A$ap_1 0 0 100 screenNA 01335458 a NA $ATir_1 0.75 0 33 smart;brightNA 05820620 n NA $Ahidap_1 0 0 50 proofNA 00792921 v NA $Al-u_1 0 0 50 liftNA 01285136 a NA $Amix_1 0.75 0 33 superiorNA 04730580 n NA danA'ap_1 0.222 0.778 33 inferiorityNA 01797347 v NA Hazin-a_1 0 0.5 50 sorrowNA 00811421 a NA sAxin_1 0.75 0.125 50 hotNA 07527352 n NA faraH_1 0.5 0.25 33 joyNA 00064787 a NA Hasan_1 0.625 0 100 good200300610 00310386 v <izodahara_v1AR {izodahar_1 0.125 0 100 flourish200844607 00873682 v >a$oEara_v1AR >a$oEar_1 0 0 100 notify201766276 01819147 v >aHobaTa_v1AR >aHobaT_1 0.125 0.5 100 discourage114279405 15136453 n nahaAr_n1AR nahAr_2 0 0 100 day100059106 00064504 n najaAH_n1AR najAH_2 0.625 0 100 success113808178 14646610 n naykl_n1AR niykol_1 0 0 100 nickle104540432 04748836 n tabaAyun_n1AR tabAyun_1 0.25 0.625 100 difference200705236 00729378 v tasaA'ala_v1AR tasA'al_1 0.375 0 100 wonderNA 01983162 a NA $ariyf_2 1 0 67 respectableNA 05144663 n NA $ariyr_1 0 0.75 33 evilTable 7.
Samples of ArSenL showing entries originating from ArSenL-Eng and ArSenL-AWN.172ReferencesAbdul-Mageed, M., Diab, M. and Korayem, M.(2011).
Subjectivity and sentiment analysis ofmodern standard Arabic.
In Proceedings of the49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technol-ogies: short papers-Volume 2.
Association forComputational Linguistics.Abdul-Mageed, M., & Diab, M. (2012).
Towardbuilding a large-scale Arabic sentiment lexicon.
InProceedings of the 6th International GlobalWordNet Conference (pp.
18-22).Abdul-Mageed, M., & Diab, M. (2014) SANA: ALarge Scale Multi-Genre, Multi-Dialect Lexiconfor Arabic Subjectivity and Sentiment Analysis.
InProceedings of the Language Resources and Eval-uation Conference (LREC), Reykjavik, IcelandAlhazmi, S., Black, W., & McNaught, J.
(2013).
Ara-bic SentiWordNet in Relation to SentiWordNet 3.0.2180-1266, 4(1), 1-11.Baccianella, S., Esuli, A., & Sebastiani, F. (2010,May).
SentiWordNet 3.0: An Enhanced LexicalResource for Sentiment Analysis and Opinion Min-ing.
In LREC (Vol.
10, pp.
2200-2204).Black, W., Elkateb, S., & Vossen, P. (2006).
Introduc-ing the Arabic wordnet project.
In In Proceedingsof the third International WordNet Conference(GWC-06).Buckwalter, T. 2004.
Buckwalter Arabic morphologi-cal analyzer version 2.0.
LDC catalog numberLDC2004L02, ISBN 1-58563-324-0Chen, Y., & Skienna, S. (2014).
Building SentimentLexicons for All Major Languages.
In Proceedingsof the 52nd Annual Meeting of the Association forComputational Linguistics (Short Papers) (pp.383-389).
2014 Association for ComputationalLinguistics.Denecke, K. (2008, April).
Using sentiwordnet formultilingual sentiment analysis.
In Data Engineer-ing Workshop, 2008.
ICDEW 2008.
IEEE 24th In-ternational Conference on (pp.
507-512).
IEEE.Diab, M., Al-Badrashiny, M., Aminian, M., Attia, M.,Dasigi, P., Elfardy, H., Eskander, R., Habash, N.,Hawwari, A., & Salloum, W. (2014).
Tharwa: ALarge Scale Dialectal Arabic - Standard Arabic -English Lexicon.
In Proceedings of the LanguageResources and Evaluation Conference (LREC),Reykjavik, Iceland.Elarnaoty, M., AbdelRahman, S., & Fahmy, A.
(2012).A Machine Learning Approach for Opinion HolderExtraction in Arabic Language.
InternationalJournal of Artificial Intelligence & Applications,3(2).Esuli, A., & Sebastiani, F. (2005).
Determining thesemantic orientation of terms through gloss classi-fication.
In Proceedings of the 14th ACM interna-tional conference on Information and knowledgemanagement (pp.
617-624).
ACM.Esuli, A., & Sebastiani, F. (2006).
Sentiwordnet: Apublicly available lexical resource for opinion min-ing.
In Proceedings of LREC (Vol.
6, pp.
417-422).Graff, D., Maamouri, M., Bouziri, B., Krouna, S.,Kulick, S., & Buckwalter, T. (2009).
Standard Ar-abic Morphological Analyzer (SAMA) Version 3.1,2009.
Linguistic Data Consortium LDC2009E73.Habash, N., & Rambow, O., (2005).
Arabic tokeniza-tion, part-of-speech tagging and morphologicaldisambiguation in one fell swoop.
Proceedings ofthe 43rd Annual Meeting on Association for Com-putational Linguistics.
Association for Computa-tional Linguistics.Habash, N. (2010).
Introduction to Arabic naturallanguage processing.
Synthesis Lectures on HumanLanguage Technologies, 3(1), 1-187.Liu, B.
(2010).
Sentiment Analysis and Subjectivity.Handbook of Natural Language Proccessing,2:568.Maamouri, M., Bies, A., Buckwalter, T., & Mekki, W.(2004, September).
The penn arabic treebank:Building a large-scale annotated arabic corpus.
InNEMLAR Conference on Arabic Language Re-sources and Tools (pp.
102-109).Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D.,& Miller, K. J.
(1990).
Introduction to wordnet: Anon-line lexical database.
International journal oflexicography, 3(4), 235-244.Ohana, B., & Tierney, B.
(2009, October).
Sentimentclassification of reviews using SentiWordNet.
In9th.
IT & T Conference (p. 13).Pang, B., & Lee, L. (2004, July).
A sentimental edu-cation: Sentiment analysis using subjectivity sum-marization based on minimum cuts.
In Proceedingsof the 42nd annual meeting on Association forComputational Linguistics (p. 271).
Associationfor Computational Linguistics.Pang, B., & Lee, L. (2005, June).
Seeing stars: Ex-ploiting class relationships for sentiment categori-zation with respect to rating scales.
In Proceedingsof the 43rd Annual Meeting on Association forComputational Linguistics (pp.
115-124).
Associa-tion for Computational Linguistics.Staiano, J., & Guerini, M. (2014).
DepecheMood: aLexicon for Emotion Analysis from Crowd-Annotated News.
arXiv preprint arXiv:1405.1605.Taboada, M., Brooke, J., Tofiloski, M., Voll, K., &Stede, M. (2011).
Lexicon-based methods for sen-timent analysis.
Computational linguistics, 37(2),267-307.173
