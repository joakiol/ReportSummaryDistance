Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 43?48,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsA Probabilistic Setting and Lexical Cooccurrence Modelfor Textual EntailmentOren Glickman and Ido DaganDepartment of Computer ScienceBar Ilan University{glikmao,Dagan}@cs.biu.ac.ilAbstractThis paper proposes a general probabilis-tic setting that formalizes a probabilisticnotion of textual entailment.
We furtherdescribe a particular preliminary modelfor lexical-level entailment, based ondocument cooccurrence probabilities,which follows the general setting.
Themodel was evaluated on two applicationindependent datasets, suggesting the rele-vance of such probabilistic approaches forentailment modeling.1 IntroductionMany Natural Language Processing (NLP)applications need to recognize when the meaningof one text can be expressed by, or inferred from,another text.
Information Retrieval (IR), QuestionAnswering (QA), Information Extraction (IE), textsummarization and Machine Translation (MT)evaluation are examples of applications that needto assess this semantic relationship between textsegments.
The Textual Entailment Recognitiontask (Dagan et al, 2005) has recently been pro-posed as an application independent framework formodeling such inferences.Within the textual entailment framework, a textt is said to entail a textual hypothesis h if the truthof h can be inferred from t. Textual entailment cap-tures generically a broad range of inferences thatare relevant for multiple applications.
For example,a QA system has to identify texts that entail a hy-pothesized answer.
Given the question "Does JohnSpeak French?
", a text that includes the sentence"John is a fluent French speaker" entails the sug-gested answer "John speaks French."
In manycases, though, entailment inference is uncertainand has a probabilistic nature.
For example, a textthat includes the sentence "John was born inFrance."
does not strictly entail the above answer.Yet, it is clear that it does increase substantially thelikelihood that the hypothesized answer is true.The uncertain nature of textual entailment callsfor its explicit modeling in probabilistic terms.
Wetherefore propose a general generative probabilisticsetting for textual entailment, which allows a clearformulation of concrete probabilistic models forthis task.
We suggest that the proposed setting mayprovide a unifying framework for modeling uncer-tain semantic inferences from texts.An important sub task of textual entailment,which we term lexical entailment, is recognizing ifthe lexical concepts in a hypothesis h are entailedfrom a given text t, even if the relations which holdbetween these concepts may not be entailed from t.This is typically a necessary, but not sufficient,condition for textual entailment.
For example, inorder to infer from a text the hypothesis "Chryslerstock rose," it is a necessary that the concepts ofChrysler, stock and rise must be inferred from thetext.
However, for proper entailment it is furtherneeded that the right relations hold between theseconcepts.
In this paper we demonstrate the rele-vance of the general probabilistic setting for mod-eling lexical entailment, by devising a preliminarymodel that is based on document co-occurrenceprobabilities in a bag of words representation.Although our proposed lexical system is rela-tively simple, as it doesn?t rely on syntactic orother deeper analysis, it nevertheless was amongthe top ranking systems in the first RecognisingTextual Entailment (RTE) Challenge (Glickman etal., 2005a).
The model was evaluated also on anadditional dataset, where it compares favorablywith a state-of-the-art heuristic score.
These resultssuggest that the proposed probabilistic frameworkis a promising basis for devising improved modelsthat incorporate richer information.432 Probabilistic Textual Entailment2.1 MotivationA common definition of entailment in formal se-mantics (Chierchia.
and McConnell-Ginet, 1990)specifies that a text t entails another text h (hy-pothesis, in our terminology) if h is true in everycircumstance (possible world) in which t is true.For example, in examples 1 and 3 from Table 1we?d assume humans to agree that the hypothesisis necessarily true in any circumstance for whichthe text is true.
In such intuitive cases, textual en-tailment may be perceived as being certain, or, tak-ing a probabilistic perspective, as having aprobability of 1.In many other cases, though, entailment infer-ence is uncertain and has a probabilistic nature.
Inexample 2, the text doesn?t contain enough infor-mation to infer the hypothesis?
truth.
And in exam-ple 4, the meaning of the word hometown isambiguous and therefore one cannot infer for cer-tain that the hypothesis is true.
In both of thesecases there are conceivable circumstances forwhich the text is true and the hypothesis false.
Yet,it is clear that in both examples, the text does in-crease substantially the likelihood of the correct-ness of the hypothesis, which naturally extends theclassical notion of certain entailment.
Given thetext, we expect the probability that the hypothesisis indeed true to be relatively high, and signifi-cantly higher than its probability of being truewithout reading the text.
Aiming to model applica-tion needs, we suggest that the probability of thehypothesis being true given the text reflects an ap-propriate confidence score for the correctness of aparticular textual inference.
In the next sub-sections we propose a concrete probabilistic settingthat formalizes the notion of truth probabilities insuch cases.2.2 A Probabilistic SettingLet T denote a space of possible texts, and t?T aspecific text.
Let H denote the set of all possiblehypotheses.
A hypothesis h?H is a propositionalstatement which can be assigned a truth value.
Fornow it is assumed that h is represented as a textualstatement, but in principle it could also be ex-pressed as a formula in some propositional lan-guage.A semantic state of affairs is captured by amapping from H to {0=false, 1=true}, denoted byw: H ?
{0, 1} (called here possible world, follow-ing common terminology).
A possible world wrepresents a concrete set of truth value assignmentsfor all possible propositions.
Accordingly, W de-notes the set of all possible worlds.2.2.1 A Generative ModelWe assume a probabilistic generative model fortexts and possible worlds.
In particular, we assumethat texts are generated along with a concrete stateof affairs, represented by a possible world.
Thus,whenever the source generates a text t, it generatesalso corresponding hidden truth assignments thatconstitute a possible world w.The probability distribution of the source, overall possible texts and truth assignments T ?
W, isassumed to reflect inferences that are based on thegenerated texts.
That is, we assume that the distri-bution of truth assignments is not bound to reflectthe state of affairs in a particular "real" world, butonly the inferences about propositions' truth whichare related to the text.
In particular, the probabilityfor generating a true hypothesis h that is not relatedat all to the corresponding text is determined bysome prior probability P(h).
For example, h="Parisis the capital of France" might have a prior smallerthan 1 and might well be false when the generatedtext is not related at all to Paris or France.
In fact,we may as well assume that the notion of textualentailment is relevant only for hypotheses forwhich P(h) < 1, as otherwise (i.e.
for tautologies)there is no need to consider texts that would sup-port h's truth.
On the other hand, we assume thatthe probability of h being true (generated within w)would be higher than the prior when the corre-sponding t does contribute information that sup-ports h's truth.example text hypothesis1 John is a French Speaker2 John was born in France John speaks French3 Harry's birthplace is Iowa4 Harry is returning to his Iowa hometown  Harry was born in IowaTable 1: example sentence pairs44We define two types of events over the prob-ability space for T ?
W:I) For a hypothesis h, we denote as Trh the randomvariable whose value is the truth value assigned toh in a given world.
Correspondingly, Trh=1 is theevent of h being assigned a truth value of 1 (true).II) For a text t, we use t itself to denote also theevent that the generated text is t (as usual, it isclear from the context whether t denotes the text orthe corresponding event).2.3 Probabilistic textual entailmentdefinitionWe say that a text t probabilistically entails a hy-pothesis h (denoted as t ?
h) if t increases the like-lihood of h being true, that is, if P(Trh = 1| t) >P(Trh  = 1) or equivalently if the pointwise mutualinformation, I(Trh=1,t), is greater then 0.
Onceknowing that t?h, P(Trh=1| t) serves as a probabil-istic confidence value for h being true given t.Application settings would typically requirethat P(Trh = 1| t) obtains a high value; otherwise,the text would not be considered sufficiently rele-vant to support h's truth (e.g.
a supporting text inQA or IE should entail the extracted informationwith high confidence).
Finally, we ignore here thecase in which t contributes negative informationabout h, leaving this relevant case for further in-vestigation.2.4 Model PropertiesIt is interesting to notice the following propertiesand implications of our model:A) Textual entailment is defined as a relationshipbetween texts and propositions whose representa-tion is typically based on text as well, unlike logi-cal entailment which is a relationship betweenpropositions only.
Accordingly, textual entail-ment confidence is conditioned on the actual gen-eration of a text, rather than its truth.
Forillustration, we would expect that the text ?Hisfather was born in Italy?
would logically entailthe hypothesis ?He was born in Italy?
with highprobability ?
since most people who?s father wasborn in Italy were also born there.
However weexpect that the text would actually not probabilis-tically textually entail the hypothesis since mostpeople for whom it is specifically reported thattheir father was born in Italy were not born inItaly.1B) We assign probabilities to propositions (hy-potheses) in a similar manner to certain probabil-istic reasoning approaches (e.g.
Bacchus, 1990;Halpern, 1990).
However, we also assume a gen-erative model of text, similar to probabilistic lan-guage and machine translation models, whichsupplies the needed conditional probability distri-bution.
Furthermore, since our conditioning is ontexts rather than propositions we do not assumeany specific logic representation language for textmeaning, and only assume that textual hypothesescan be assigned truth values.C) Our framework does not distinguish betweentextual entailment inferences that are based onknowledge of language semantics (such as mur-dering ?
killing) and inferences based on domainor world knowledge (such as live in Paris ?
livein France).
Both are needed in applications and itis not clear at this stage where and how to putsuch a borderline.D) An important feature of the proposed frame-work is that for a given text many hypotheses arelikely to be true.
Consequently, for a given text tand hypothesis h, ?hP(Trh=1|t) does not sum to 1.This differs from typical generative settings forIR and MT (Ponte and croft, 1998; Brown et al,1993), where all conditioned events are disjointby construction.
In the proposed model, it israther the case that P(Trh=1|t) + P(Trh=0|t) = 1, aswe are interested in the probability that a singleparticular hypothesis is true (or false).E) An implemented model that corresponds to ourprobabilistic setting is expected to produce anestimate for P(Trh = 1| t).
This estimate is ex-pected to reflect all probabilistic aspects involvedin the modeling, including inherent uncertainty ofthe entailment inference itself (as in example 2 ofTable 1), possible uncertainty  regarding the cor-rect disambiguation of the text (example 4), aswell as probabilistic estimates that stem from theparticular model structure.3 A Lexical Entailment ModelWe suggest that the proposed setting above pro-vides the necessary grounding for probabilistic1This seems to be the case, when analyzing the results of en-tering the above text in a web search engine.45modeling of textual entailment.
Since modeling thefull extent of the textual entailment problem isclearly a long term research goal, in this paper werather focus on the above mentioned sub-task oflexical entailment - identifying when the lexicalelements of a textual hypothesis h are inferredfrom a given text t.To model lexical entailment we first assume thatthe meanings of the individual content words in ahypothesis can be assigned truth values.
One pos-sible interpretation for such truth values is thatlexical concepts are assigned existential meanings.For example, for a given text t, Trbook=1 if it can beinferred in t?s state of affairs that a book exists.Our model does not depend on any such particularinterpretation, though, as we only assume that truthvalues can be assigned for lexical items but do notexplicitly annotate or evaluate this sub-task.Given this setting, a hypothesis is assumed to betrue if and only if all its lexical components aretrue as well.
This captures our target perspective oflexical entailment, while not modeling here otherentailment aspects.
When estimating the entailmentprobability we assume that the truth probability ofa term u in a hypothesis h is independent of thetruth of the other terms in h, obtaining:P(Trh = 1| t) = ?u?hP(Tru=1|t)P(Trh = 1) = ?u?hP(Tru=1) (1)In order to estimate P(Tru=1|v1, ?, vn) for agiven word u and text t={v1, ?, vn}, we furtherassume that the majority of the probability masscomes from a specific entailing word in t:)|1(max)|1( vutvu TTrtTr =?==?
?
(2)where Tv denotes the event that a generated textcontains the word v. This corresponds to expectingthat each word in h will be entailed from a specificword in t (rather than from the accumulative con-text of t as a whole2).
Alternatively, one can view(2) as inducing an alignment between terms in theh to the terms in the t, somewhat similar to align-ment models in statistical MT (Brown et al, 1993).Thus we propose estimating the entailmentprobability based on lexical entailment probabili-ties from (1) and (2) as follows:??
?
=?==?
hu vutvh TTrtTr )|1(max)|1(  (3)2Such a model is proposed in (Glickman et al, 2005b)3.1 Estimating Lexical EntailmentProbabilitiesWe perform unsupervised empirical estimation ofthe lexical entailment probabilities, P(Tru=1|Tv),based on word co-occurrence frequencies in a cor-pus.
Following our proposed probabilistic model(cf.
Section  2.2.1), we assume that the domaincorpus is a sample generated by a language source.Each document represents a generated text and a(hidden) possible world.
Given that the possibleworld of the text is not observed we do not knowthe truth assignments of hypotheses for the ob-served texts.
We therefore further make the sim-plest assumption that all hypotheses statedverbatim in a document are true and all others arefalse and hence P(Tru=1|Tv) = P(Tu |Tv).
This simpleco-occurrence probability, which we denote aslexical entailment probability ?
lep(u,v), is easilyestimated from the corpus based on maximum like-lihood counts:vvuvunnTTrvulep ,)|1(),( ?=?=(4)where nv is the number of documents containingword v and nu,v is the number of documents con-taining both u and v.Given our definition of the textual entailmentrelationship (cf.
Section  2.3) for a given word v weonly consider for entailment words u for whichP(Tru=1|Tv)> P(Tru=1) or based on our estimations,for which nu,v/nu > nv/N (N is total number ofdocuments in the corpus).We denote as tep the textual entailment probabilityestimation as derived from (3) and (4) above:?
?
?= hu tv vulephttep ),(max),(  (5)3.2 Baseline modelAs a baseline model for comparison, we use ascore developed within the context of text summa-rization.
(Monz and de Rijke, 2001) propose mod-eling the directional entailment between two textst1, t2 via the following score:????
?=221)()(),( )(21twttwwidfwidfttentscore(6)where idf(w) = log(N/nw), N is total number ofdocuments in corpus and nw is number of docu-46ments containing word w.  A practically equivalentmeasure was independently proposed in the con-text of QA by (Saggion et al, 2004)3.
This baselinemeasure captures word overlap, considering onlywords that appear in both texts and weighs thembased on their inverse document frequency.4 The RTE challenge datasetThe RTE dataset (Dagan et al, 2005) consistsof sentence pairs annotated for entailment.
Fo thisdataset we used word cooccurrence frequenciesobtained from a web search engine.
The details ofthis experiment are described in Glickman et al,2005a.
The resulting accuracy on the test set was59% and the resulting confidence weighted scorewas 0.57.
Both are statistically significantly betterthan chance at the 0.01 level.
The baseline model(6) from Section  3.2, which takes into account onlyterms appearing in both the text and hypothesis,achieved an accuracy of only 56%.
Although ourproposed lexical system is relatively simple, as itdoesn?t rely on syntactic or other deeper analysis,it nevertheless was among the top ranking systemsin the RTE Challenge.5 RCV1 datasetIn addition to the RTE dataset we were interestedin evaluating the model on a more representativeset of texts and hypotheses that better correspondsto applicative settings.
We focused on the informa-tion seeking setting, common in applications suchas QA and IR, in which a hypothesis is given and itis necessary to identify texts that entail it.An annotator was asked to choose 60 hypothe-ses based on sentences from the first few docu-ments in the Reuters Corpus Volume 1 (Rose et al,2002).
The annotator was instructed to choose sen-tential hypotheses such that their truth could easilybe evaluated.
We further required that the hypothe-ses convey a reasonable information need in such away that they might correspond to potential ques-tions, semantic queries or IE relations.
Table 2shows a few of the hypotheses.In order to create a set of candidate entailingtexts for the given set of test hypotheses, we fol-lowed the common practice of WordNet based ex-3(Saggion et al, 2004) actually proposed the above score withno normalizing denominator.
However for a given hypothesisit results with the same ranking of candidate entailing texts.pansion (Nie and Brisebois, 1996; Yang and Chua,2002).
Using WordNet, we expanded the hypothe-ses?
terms with morphological alternations andsemantically related words4.For each hypothesis stop words were removedand all content words were expanded as describedabove.
Boolean Search included a conjunction ofthe disjunction of the term?s expansions and wasperformed at the paragraph level over the fullReuters corpus, as common in IR for QA.
Since wewanted to focus our research on semantic variabil-ity we excluded from the result set paragraphs thatcontain all original words of the hypothesis or theirmorphological derivations.
The resulting datasetconsists of 50 hypotheses and over a million re-trieved paragraphs (10 hypotheses had only exactmatches).
The number of paragraphs retrieved perhypothesis range from 1 to 400,000.55.1 EvaluationThe model?s entailment probability, tep, was com-pared to the following two baseline models.
Thefirst, denoted as base, is the na?ve baseline inwhich all retrieved texts are presumed to entail thehypothesis with equal confidence.
This baselinecorresponds to systems which perform blind ex-pansion with no weighting.
The second baseline,entscore, is the entailment score (6) from  3.2.The top 20 best results for all methods weregiven to judges to be annotated for entailment.Judges were asked to annotate an example as trueif given the text they can infer with high confi-dence that the hypothesis is true (similar to theguidelines published for the RTE Challenge data-set).
Accordingly, they were instructed to annotatethe example as false if either they believe the hy-pothesis is false given the text or if the text is unre-lated to the hypothesis.
In total there were 1683text-hypothesis pairs, which were randomly di-vided between two judges.
In order to measureagreement, we had 200 of the pairs annotated byboth judges, yielding a moderate agreement (aKappa of 0.6).4The following WordNet relations were used: Synonyms, seealso, similar to, hypernyms/hyponyms, meronyms/holonyms,pertainyms, attribute, entailment, cause and domain5The dataset is available at:http://ir-srv.cs.biu.ac.il:64080/emsee05_dataset.zip475.2 Resultsbase entscore tepprecision 0.464 0.568 0.647cws 0.396 0.509 0.575Table 2: ResultsTable 2 includes the results of macro averaging theprecision at top-20 and the average confidenceweighted score (cws) achieved for the 50 hypothe-ses.
Applying Wilcoxon Signed-Rank Test, ourmodel performs significantly better (at the 0.01level) than entscore and base for both precision andcws.
Analyzing the results showed that many ofthe mistakes were not due to wrong expansion butrather to a lack of a deeper analysis of the text andhypothesis (e.g.
example 3 in Table 2).
Indeed thisis a common problem with lexical models.
Incor-porating additional linguistic levels into the prob-abilistic entailment model, such as syntacticmatching, co-reference resolution and word sensedisambiguation, becomes a challenging target forfuture research.6 ConclusionsThis paper proposes a generative probabilistic set-ting that formalizes the notion of probabilistic tex-tual entailment, which is based on the conditionalprobability that a hypothesis is true given the text.This probabilistic setting provided the necessarygrounding for a concrete probabilistic model oflexical entailment that is based on document co-occurrence statistics in a bag of words representa-tion.
Although the illustrated lexical system isrelatively simple, as it doesn?t rely on syntactic orother deeper analysis, it nevertheless achieved en-couraging results.
The results suggest that such aprobabilistic framework is a promising basis forimproved implementations incorporating deepertypes of knowledge and a common test-bed formore sophisticated models.AcknowledgmentsThis work was supported in part by the IST Pro-gramme of the European Community, under thePASCAL Network of Excellence, IST-2002-506778.
This publication only reflects the authors'views.
We would also like to thank Ruthie Mandeland Tal Itzhak Ron for their annotation work.ReferencesFahiem Bacchus.
1990.
Representing and Reasoningwith Probabilistic Knowledge, M.I.T.
Press.Peter F. Brown, Vincent J. Della Pietra, Stephen A.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation: Pa-rameter Estimation.
Computational Linguistics,19(2):263?311.Chierchia, Gennaro, and Sally McConnell-Ginet.
2001.Meaning and grammar: An introduction to seman-tics, 2nd.
edition.
Cambridge, MA: MIT Press.Ido Dagan, Oren Glickman and Bernardo Magnini.2005.
The PASCAL Recognising Textual EntailmentChallenge.
In Proceedings of the PASCAL Chal-lenges Workshop for Recognizing Textual Entail-ment.
Southampton, U.K.Oren Glickman, Ido Dagan and Moshe Koppel.
2005a.Web Based Probabilistic Textual Entailment,PASCAL Challenges Workshop for RecognizingTextual Entailment.Oren Glickman, Ido Dagan and Moshe Koppel.
2005b.A Probabilistic Classification Approach for LexicalTextual Entailment, Twentieth National Conferenceon Artificial Intelligence (AAAI-05).Joseph Y. Halpern.
1990.
An analysis of first-order lo-gics of probability.
Artificial Intelligence 46:311-350.Christof Monz, Maarten de Rijke.
2001.
Light-WeightEntailment Checking for Computational Semantics.In Proc.
of the third workshop on inference in com-putational semantics (ICoS-3).Jian-Yun Nie and Martin Brisebois.
1996.
An InferentialApproach to Information Retrieval and Its Implemen-tation Using a Manual Thesaurus.
Artificial Intelli-gence Revue 10(5-6): 409-439.Jay M. Ponte, W. Bruce Croft, 1998.
A Language Mod-eling Approach to Information Retrieval.
SIGIR con-ference on Research and Development in InformationRetrieval.Tony G. Rose, Mary Stevenson, and Miles Whitehead.2002.
The Reuters Corpus volume 1 - from yester-day?s news to tomorrow?s language resources.
ThirdInternational Conference on Language Resources andEvaluation (LREC).Hui Yang and Tat-Seng Chua.
2002.
The integration oflexical knowledge and external resources for ques-tion answering.
The eleventh Text REtrieval Confer-ence (TREC-11).48
