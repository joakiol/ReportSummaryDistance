Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 77?86,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsTree-based Hybrid Machine TranslationAndreas KirkedalCentre for Computational Modelling of languageInstitute for International Language Studies and Computational LinguisticsCopenhagen Business Schoolask.isv@cbs.dkAbstractI present an automatic post-editing ap-proach that combines translation systemswhich produce syntactic trees as output.The nodes in the generation tree and target-side SCFG tree are aligned and formthe basis for computing structural similar-ity.
Structural similarity computation alignssubtrees and based on this alignment, sub-trees are substituted to create more accu-rate translations.
Two different techniqueshave been implemented to compute struc-tural similarity: leaves and tree-edit dis-tance.
I report on the translation quality ofa machine translation (MT) system whereboth techniques are implemented.
The ap-proach shows significant improvement overthe baseline for MT systems with limitedtraining data and structural improvementfor MT systems trained on Europarl.1 IntroductionStatistical MT (SMT) and rule-based MT(RBMT) have complimentary strengths andcombining their output can improve translationquality.
The underlying models in SMT lacklinguistic sophistication when compared toRBMT systems and there is a trend towardsincorporating more linguistic knowledge bycreating hybrid systems that can exploit thelinguistic knowledge contained in hand-craftedrules and the knowledge extracted from largeamounts of text.Hierarchical phrases (Chiang, 2005) are en-coded in a tree structure just as linguistic trees.Most RBMT systems also encode the analysis ofa sentence in a tree.
The rules generating hierar-chical trees are inferred from unlabeled corporaand RBMT systems use hand-crafted rules basedin linguistic knowledge.
While the trees are gen-erated differently, alignments between nodes andsubtrees in the generation phase can be computed.Based on the computed alignments, substitutioncan be performed between the trees.The automatic post-editing approach proposedin this paper is based on structural similarity.The tree structures are aligned and subtree sub-stitution based on the similarity of subtrees per-formed.
This knowledge-poor approach is com-patible with the surface-near nature of SMT sys-tems, does not require other information thanwhat is available in the output, and ensures thatthe approach is generic so it can, in principle, beapplied to any language pair.2 Hybrid Machine TranslationHybrid machine translation (HMT) is a paradigmthat seeks to combine the strengths of SMTand RBMT.
The different approaches have com-plementary strengths and weaknesses (Thurmair,2009) which have led to the emergence of HMTas a subfield in machine translation research.The strength of SMT is robustness - i.e.
it willalways produce an output - and fluency due to theuse of language models.
A weakness of SMT isthe lack of explicit linguistic knowledge, whichmake translation phenomena requiring such infor-mation, e.g.
long-distance dependencies, difficultto handle.RBMT systems translate more accurately incases without parse failure, since they can takemore information into account e.g.
morpholog-ical, syntactic or semantic information, whereSMT only uses surface forms.
RBMT often suf-fer from lack of robustness when parsing fails and77Figure 1: Hybrid system architecture.in lexical selection in transfer.
RBMT systems arealso very costly to build, and maintenance and de-velopment can be very complex e.g.
due to theinterdependency of rules.The post-editing approach attempts to incorpo-rate the linguistic knowledge encoded in target-side dependency trees into hierarchical trees pro-duced by an SMT system.2.1 Related workSystem combinations by coupling MT systemsserially or in parallel have been attempted beforee.g.
via hypothesis selection (Hildebrand and Vo-gel, 2008), by combining translation hypotheseslocally using POS tags (Federmann et al, 2010)or by statistical post-editing (SPE) (Simard et al,2007).
In hypothesis selection approaches, a num-ber of MT systems produce translations for an n-best list and use a re-ranking module to rescorethe translations.
Using this approach, the best im-provements are achieved with a large number ofsystems running in parallel and this is not feasiblein a practical application, mostly due to the com-putational resources required by the componentsystems.
The translations will also not be betterthan the one produced by the best component sys-tem.
Tighter integration of rule-based and statisti-cal approaches have also been proposed: Addingprobabilities to parse trees, pre-translation wordreordering, enriching the phrase table with outputphrases from a rule-based system (Eisele et al,Jeg [jeg] 1S NOM @SUBJ #1->2arbejder [arbejde] <mv> V PR AKT @FS-STA #2->0hjemme [hjemme] <aloc> ADV LOC @<ADVL #3->2.
[.]
PU @PU #4->0Figure 2: Disambiguated CG representation for I workat home.
Dependency annotation is indicated by the#-character.2008), creating training data from RBMT systemsetc.
The factored translation models also presenta way to integrate rule-based parsing systems.The automatic post-editing approach proposedhere does not exactly fit the classification of par-allel coupling approaches in Thurmair (2009).Other coupling architectures with post-editingwork on words or phrases and generate confu-sion networks or add more information to iden-tify substitution candidates, while the units fo-cused on here are graphs and no additional infor-mation is added to the MT output.
This approachdoes select a skeleton upon which transformationsare conducted as in Rosti et al (2007) and re-quires the RBMT system to generate a target sidelanguage analysis which must be available to thepost-editing systems, but does not require a newsyntactic analysis of noisy MT output.
The archi-tecture of the hybrid system used in this paper isparallel coupling with post-editing.
A diagram ofthe implemented systems can be seen in Figure 1.The dark grey boxes represent pre-existing mod-ules and open source software and the light greyboxes represent the additional modules developedto implement the post-editing approach.2.2 RBMT ComponentThe Danish to English translation engine inGramTrans (Bick, 2007) is called through an API.The output is a constraint grammar (CG) analysison the target language side after all transfer andtarget side transformation rules have been applied.Example output is shown in Figure 2.
In the anal-ysis, dependency information is provided and theyform the basis for creating the tree used for struc-tural similarity computation.
Part-of-speech tags,source and target surface structure, sentence po-sition and dependency information are extractedfrom the CG analysis.GramTrans is created to be robust and produceas many dependency markings as possible to beused in later translation stages.
Errors in the as-signment of functional tags propagate to the de-pendency level and can result in markings thatwill produce a dependency tree and a number of78unconnected subgraphs with circularities.
Thispresents a problem if the dependency markingsare the basis for creating a dependency tree be-cause it is not straight-forward to reattach a sub-graph correctly, when the grammatical tags can-not be relied upon.2.3 SMT ComponentA CKY+ algorithm for chart decoding is imple-mented in Moses (Koehn et al, 2007) for tree-based models and is used as the SMT componentsystem in this paper.Hierarchical phrases are phrases that can con-tain subphrases, i.e.
a hierarchical phrase containsnon-terminal symbols.
An example rule fromDanish to English:X1 i ?vrigt X2 ??
moreover, X1 X2Xn is a nonterminal and the subscript identi-fies how the nonterminals are aligned.
The hierar-chical phrases are learned from bitext with unan-notated data and are formally productions froma synchronous context-free grammar (SCFG) andcan be viewed as a move towards syntax-basedSMT (Chiang, 2005).
Since hierarchical phrasesare not linguistic, Chiang makes a distinction be-tween linguistically syntax-based MT and for-mally syntax-based MT where hierarchical mod-els fall in the latter category because the struc-tures they are defined over are not linguisticallyinformed, i.e.
unannotated bitexts.A hierarchical model is based on a SCFG andthe elementary structures are rewrite rules:X ??
?
?, ?,?
?As above, X is a nonterminal, ?
and ?
are bothstrings of terminals and nonterminals and ?
is a1-to-1 correspondence between nonterminals in ?and ?.
As in shown previously, the convention isto use subscripts to represent ?.To maintain the advantage of the phrase-basedapproach, glue rules are added to the rules that areotherwise learned from raw data:S ??
?S1X2, S1X2?S ??
?X1, X1?Only these rewrite rules contain the nontermi-nal S. These rules are added to give the modelFigure 3: The matching process.the option of combining partial hypotheses seri-ally and they make the hierarchical model as ro-bust as the traditional phrase-based approaches.The Moses chart decoder was modified to out-put trace information from which the n-best hier-archical trees can be reconstructed.
The trace in-formation contains the derivations which producethe translation hypotheses.The sentence?aligned Danish-English part ofEuroparl (Koehn, 2005) was used for training,and to tune parameters with MERT, the test setfrom the NAACL WMT 2006 was used (Koehnand Monz, 2006).
GIZA++ aligns hierarchicalphrases which were extracted by Moses to traina translation model and a language model wastrained with SRILM (Stolcke, 2002).
Moses wastrained using the Experimental Management Sys-tem (EMS) (Koehn, 2010) and the configurationfollowed the standard guidelines in the syntax tu-torial.1 To train SRILM, the English side of Eu-roparl was used.3 Matching ApproachThe post-editing approach relies on structuresoutput by the component systems.
It is neces-sary to find similar structures to perform subtreesubstitution.
Matching structures is a problem inseveral application areas such as semantic web,schema and ontology integration, query media-tion etc.
Structures include database schemas, di-rectories, diagrams and graphs.
Shvaiko and Eu-zenat (2005) provide a comprehensive survey ofmatching techniques.The matching operation determines an align-ment between two structures and an alignment isa set of matching elements.
A matching elementis a quintuple: ?id, e, e?, n,R?
:id Unique id.e, e?
Elements from different structures.n Confidence measure.1http://www.statmt.org/moses/?n=Moses.SyntaxTutorial79satonmatthecattheSXXmattheSXonsatSXXcattheFigure 4: The refined alignment from dependency tree to hierarchical tree.R The relation holding between the elements.The resources that can be used in the match-ing process are shown in Figure 3. o and o?
arethe structures to be matched, A is an optional ex-isting alignment, r is external resources, p is pa-rameters, weights and thresholds and A?
is the setof matching elements created by the process.
Inthis paper, only matching elements with an equiv-alence relation (=) are used.The returned alignment can be a new alignmentor a refinement of A. o will be a dependency treeand o?
the hierachical trees from the SMT com-ponent system.
To compute the initial alignmentA between hierarchical and dependency trees, thesource to target language phrase alignment outputby the component systems is used.
So the initialalignment between leaf nodes in target-side treesare computed over the alignment to the sourcelanguage.An important decision regarding this hybrid ap-proach is how to compute the alignment and thesize of the substituted subtrees.
Irrespective ofwhich technique is chosen to compute structuralsimilarity, the resulting alignment should be re-fined to contain matching elements between inter-nal nodes as shown in Figure 4.3.1 Alignment ChallengesThe change made to the chart decoder to outputthe n-best trace information is simple and does notoutput the alignment information.
Currently, thetree extraction module computes an alignment be-tween the source and target language phrases.The segmentation of words into phrases doneby Moses does not always correspond to theword-based segmentation required by the CGparser; phrases recognised by the CG parser rarelycorrespond to phrases in Moses and the hierarchi-cal phrase alignment is not easy to handle.Aligning hierarchical phrases like (a) in Figure5 is not complicated.
The ordering is identicaland the Danish word offentligg?res is aligned towill be published.
The numbers 1-3 refer to thealignment of non-terminal nodes based on phrasepositions.It is more complicated to align (b) in Figure5.
There are two methods of handling this type ofalignment appropriate for the component systems.Because there are an equal number of tokens inthe English phrase and Danish phrase, aligningthe tokens 1-1 monotonically would be a solutionthat, in this case, results in a correct alignment.Another approach relies on weak word reorder-ing between Danish and English and would alignfindes with there are.
This reduces the align-ment problem to aligning vi der with we.
In thiscase, the alignment is noisy, but usable for creat-ing matching elements.
Both approaches are im-plemented in the hybrid system and the first ap-proach supercedes the second due to the advan-tage of correlating with the CG approach.An initial element-level alignment betweennodes in a dependency tree and a hierarchical treeis computed over the source language and cre-ates a set of matching elements containing alignednodes.3.2 Alignment RefinementBetween a dependency and an hierarchical tree,an element-level alignment needs to be refined to80(a) offentligg?res X : X -> will be published X : 1-3(b) vi X der X findes : X -> X, we X there are : 1-3 3-0Figure 5: Simplified example of a simple alignment.a structure-level alignment similar to the one inFigure 4.Not all matching elements in an initial align-ment should be refined e.g.
if both nodes in amatching element are leaf nodes, no refinementis needed.
Criteria for selecting initial matchingelements for refinement are needed.In the RBMT output, there are no indications ofwhere the parser encountered problems.
If a sur-face form is an out-of-vocabulary (OOV) word,the morphological analyser is used to assign a lex-ical category based on the word form, hypothesiseadditional tags based on the analysis and proceedwith parsing.
In the SMT output, an OOV markeris appended to a surface form to indicate that theword has not been translated.
The marker gives anindication of where enriching a hierarchical treewith RBMT output can result in improvement oftranslation quality.Based on these observations, hierarchical treesare chosen to function as skeletons.
Substi-tuting dependency subtrees into a hierarchicaltree is more straightforward than using depen-dency trees as skeletons.
It was not possible toidentify head-dependent relations based solely onthe information contained in hierarchical subtreeswhile removing subtrees from hierarchical treesand inserting dependency subtrees does not de-stroy linguistic information in the tree and depen-dency subtrees can easily be transformed into ahierarchical-style subtree.Leaves Based on the OOV marker, a matchingtechnique based on leaf nodes is implemented torefine matching elements and based on this align-ment, substitute hierarchical subtrees with depen-dency subtrees.The dependency subtree is identified by collect-ing all descendants of a node.
The descendantsare handled as leaf nodes because both leaf andnonterminal nodes contain surface forms in a de-pendecy tree.The dependency trees provided by GramTransare not always projective.
Subtrees may not rep-resent a continuous surface structure and a con-tinuous subtree must be isolated before an align-ment between subtrees can be found because thehierarchical trees resemble phrase structure treesand discontinuous phrases are handled using gluerules.To identify the corresponding subtree in the hi-erarchical tree, the matching elements that containthe nodes in the dependency subtree are collectedand a path from each leaf node to the root node iscomputed.
The intersection of nodes is retrievedand the root node of the subtree identified as thelowest node present in all paths.
It is not alwayspossible to find a common root node besides theroot node of the entire tree.
To prevent the loss ofa high amount of structural information, the rootnode cannot be replaced or deleted.3.3 Substitution based on an edit scriptAn algorithm for computing structural similarityis the Tree Edit Distance (TED) algorithm, whichcomputes how many operations are necessary fortransforming one tree into another tree.
FollowingZhang and Shasha (1989) and Bille (2005), theoperations are defined on nodes and the trees areordered, labelled trees.
There are 3 different editoperations:rename Change the label of a node in a tree.delete Remove a node n from a tree.
Insert thechildren of n as children of the parent of n sothe sequence of children are preserved.
Thedeleted node may not be the root node.insert Insert a node as the child of a node n ina tree.
A subsequence of children of n areinserted as children of the new node so thesequence of children are preserved.
An in-sertion is the inverse operation of a deletion.A cost function is defined for each operation.The goal is to find the sequence of edit operationsthat turns a tree T1 into another tree T2 with min-imum cost.
The sequence of edit operations iscalled an edit script and the cost of the optimaledit script is the tree edit distance.The cost functions should return a distancemetric and satisfy the following conditions:1.
?(i?
j) ?
0 and ?(i?
i) = 0812.
?(i?
j) = ?
(j ?
i)3.
?(i?
k) ?
?(i?
j) + ?
(j ?
k)?
is the cost of an edit operation.The edit distance mapping is a representationof an edit script.
A rename operation is repre-sented as (i1 ?
j2) where the subscript denotesthat the nodes i and j belong to different trees.
(i1 ?
) represents a deletion and ( ?
j2) aninsertion.The cost of an edit distance mapping is givenby:?
(M) =?(i,j)?M?(i?
j)+?i?T1?(i?
)+?j?T2?(?
j)j ?
T2 means j is in the set of nodes in T2.It is important to note that the trees are orderedtrees.
The unordered version of the tree edit dis-tance problem is NP-hard, while polynomial algo-rithms based on dynamic programming exist forordered trees.The algorithm does not require an input align-ment or external resources.
The cost functionsfor deletion, insertion and renaming must be de-fined on the information present in the nodes anda unique id must be assigned to the nodes.
This idis assigned by traversing the tree depth-first andassigning an integer as id.
The algorithm visitseach node in the trees in post order and determinesbased on the cost assigned by the cost functions,which edit operation should be performed.To generate matching elements that aligndependency nodes to nonterminal hierarchicalnodes, cost functions for edit operations are mod-ified to assign a lower cost to rename operationswhere one of the nodes is a hierarchical nonter-minal node.
If two nodes have the same targetand source phrase, a rename operation does notincur any cost and neither does the renaming ofuntranslated phrases.
This ensures that matchingelements from the initial alignment that does notrequire refinement are not altered.
Also, if thesource is the same and the difference in sentenceposition is no more than five, the renaming costis reduced.
Experiments showed that a windowof five words was necessary to account for differ-ences in sentence position and prevent alignmentto nodes later in the sentence with the same sourcephrase.This technique is independent of the OOVmarker and creates a structure-level alignment.The substitutions performed can be of very highquality but some untranslated words might not behandled.
If the system finds any OOV words inthe hierachical tree after substitution, a renameoperation is carried out on the node.The extracted matching elements are noisy be-cause they rely on the noisy source to target lan-guage alignment and the RBMT engine can alsoproduce an inaccurate translation making the sub-stitution counter-productive.
Further limitationson the cost functions become too restrictive andproduce too few matching elements.
To avoidsome of the noise, all permutations of applyingsubstitutions based on the edit script are gener-ated, re-ranked and the highest scoring hypothesischosen as the translation.3.4 GenerationTo ensure that the surface string generated fromthe newly created tree will have the correct wordordering, the dependency subtree is transformedbefore being inserted into the hierarchical tree.To create the insertion tree, the dependency nodesare inserted as leaf nodes of a dummy node.
Thedummy node is inserted before the root node ofthe aligned hierarchical subtree and the informa-tion on the root node copied to the new node.Subsequently, the hierarchical nodes are removedfrom the tree.
If both nodes in a matching elementare leaf nodes, the hierarchical node is relabeledwith information from the dependency node.4 ExperimentsThe experiments have been conducted betweenDanish and English.
The language model trainedwith EMS is used to re-rank translation alterna-tives.
BLEU (Papineni et al, 2002), TER (Snoveret al, 2006) and METEOR (Banerjee and Lavie,2005) scores will be reported.4.1 Experimental SetupTwo sets of five experiments have been con-ducted.
The first set of experiments use the initial100,000 lines from Europarl for training Mosesand the second set of experiments use the full Eu-roparl corpus of ca.
1.8 mio sentences.
The SMTbaseline is the hierarchical version of Moses.TED Skeleton Selection The impact of choos-ing the translation hypothesis with a minimal edit82Metrics: BLEU TER METEORRBMT baseline 19.35 64.54 53.19SMT baseline 30.16 (22.63) 57.16 (63.10) 59.51 (50.72)Lexical substitution 30.53 (25.28) 56.40 (60.56) 61.22 (57.24)Leaves technique 29.06 (21.96) 57.96 (64.80) 60.09 (54.32)TED skeleton(any bias) 30.16 (22.63) 57.08 (62.98) 59.46 (50.75)TED-R 1-best 29.78 (25.16) 57.25 (60.51) 59.87 (57.31)TED-R skeleton(any bias) 29.99 (25.18) 56.72 (60.44) 60.79 (57.34)Table 1: Automatic evaluation.
100k experiments in parenthesesdistance to the dependency tree from the rule-based system is investigated.
In one setting, thecost functions adhere to the constrictions of com-puting a distance metric.
Two settings test theimpact of biasing the insertion and deletion costfunctions to assign a lower cost to inserting/delet-ing nonterminals, i.e.
turning the dependency treeinto the hierarchical tree and vice versa.TED is computed for 20 translation hypothesesand the best performing setting reported.Leaves An experiment using the leaves tech-nique has been conducted.
The experiment is per-formed using the best hypothesis from Moses andalso using TED to chose the most structurally sim-ilar skeleton.
The best setting will be reported.Lexical substitution To be able to compare amore naive approach, subtree substitution basedon the initial element-level alignment betweenleaf nodes is used.
In this approach, a subtree isone node.
The technique is identical to using theRBMT lexicon to lookup untranslated words andinserting them in the translation.TED-R An experiment where the mappingsthat represent a rename operation, which are pro-duced during TED computation, are extracted andused as matching elements is conducted.
Map-ping elements containing only punctuation or theroot node of either tree are discarded.
All com-binations of substitutions based on the extractedmatching elements are performed and the highestranking hypothesis according to a language modelis chosen as the final translation.The extracted matching elements may not in-corporate all the untranslated nodes.
All untrans-lated nodes are subsequently translated using lexi-cal substitution as mentioned above.
The subtreesinserted into the hierarchical tree will undergo thesame transformation as the subtrees inserted usingthe leaves technique.This experiment is evaluated using both the 1-best hierarchical tree as skeleton and choosing theskeleton using TED.
All three settings are testedand the best performing experiment reported.4.2 EvaluationThe results of the automatic evaluation can beseen in Table 1.
Skeleton indicates that TED wasused to pick the hierarchical tree.
The best evalu-ations are in bold.100k The RBMT baseline is outperformed byall hybrid configurations, though it does have ahigher METEOR score than the SMT baselineand skeleton selection.
Lexical substitution andTED-R obtains an increase of ca.
2.5 BLEU, 4TER and 4 METEOR points over the best base-line scores.
The leaves technique decreases themetrics except for METEOR and the skeleton se-lection only shows an insignificant improvement.Europarl Only lexical substitution improve allmetrics over the baseline.
Using the leaves tech-nique again results in a decrease in BLEU andTER, but improves METEOR.
The impact ofskeleton selection is similar to previous experi-ments, but the use of skeleton selection in TED-Rhas become larger.Manual Evaluation The evaluators rank 20sentences randomly extracted from the test set ona scale from 1-5 with 5 being the best and it is pos-sible to assign the same score to multiple transla-tion alternatives.
This evaluation was inspired bythe sentence ranking evaluation in Callison-Burchet al (2007).
The five sentences to be evaluatedwill come from the RBMT and SMT baselines,lexical substitution, leaves technique and TED-R skeleton and the evaluators are 5 Danes whohave studied translation with English as secondlanguage and 3 native English speakers.The baseline systems make up 85% of the low-est ranking.
The distribution between systems ismore even for the second lowest ranking with thebaselines only accounting for 52.6%.
In the mid-dle ranking, the top scorer is lexical substitution83System 1 2 3 4 5 Avg.
rankSMT 53 64 30 12 1 2.025RBMT 14 48 61 29 8 2.806Lex.
sub.
3 33 63 58 3 3.156Leaves 6 33 61 55 5 3.125TED-R 3 35 46 55 21 3.35Table 2: Rankings from the manual evaluation of thesecond set of experiments.with a small margin to the RBMT baseline andthe leaves technique.
The many assignments ofrank 3 could indicate that many of the transla-tions produced can be used for gisting, i.e.
getan impression of what information the source textconveys, but not enough to give a complete under-standing, but can also be a result of being the mid-dle value and chosen when the evaluators are indoubt.
Lexical substitution is also the top scorer inthe second-best ranking, followed closely by theother hybrid configurations and the hybrid sys-tems account for 80.3% of the second-best rank-ings.
TED-R recieves more top rankings thanthe other systems combined (55.3%).
The RBMTbaseline achieves second-most top-rankings.
Thiscan be attributed to the cases where the rules didnot encounter unknown words and created veryaccurate translations, as is the hallmark of RBMT.5 DiscussionIt is not surprising that lexical substitutionachieves a significant increase in all metrics.
Theapproach only translates untranslated words usingthe RBMT lexicon.
This can improve the transla-tion or, because of noisy matching elements, in-troduce wrong words but the penalty incurred foruntranslated words and wrongly translated wordsis the same if the number of tokens is similar.
Fur-ther, lexical substitution does not rely on struc-tural similarity and can avoid the potential sourcesof errors encountered at a later processing stage.Skeleton selection has little impact on the met-rics and distinct derivations can result in the samesurface structure, giving the same scores, but it isevident that finding the most similar tree improvessubstitution.The improvements observed in the 100k exper-iments are not evident in the metrics when thefull Europarl data is used.
The more powerfulSMT system is able to handle more translationsbut manual evaluation reveals a distribution wherethe majority of rankings for the baseline systemsSMT ( COM ( 1999 ) 493 - C5-0320baseline / 1999 - 1999 / 2208 ( COS ) )Leaves ( came ( 1999 ) 493 -C5-0320/1999-1999/2208 ( COM COS) ) - C5-0320 / 1999 - 1999 / 2208 (TED-R ( COM ( 1999 ) 493 -C5-0320/1999-1999/2208/ 1999 - 1999 / 2208 ( COS ) )Table 3: Substitution of numbers.are in the lower half and rankings for the hy-brid systems tend more towards the mid-to-upperrankings, with TED-R having more distributionaround the second-best and highest score.
Thisindicates that the approach creates more accuratetranslations.The leaves technique consistently underper-forms lexical substitution, but manual evaluationshows a high correlation between the two meth-ods and their average ranks are similar.
TED-Ris ranked higher than the leaves technique in themetrics and manual evaluation also ranks TED-R higher than lexical substitution.
This suggeststhat the extra surface structure removed is notpresent in the reference translation and that TED-R is a better implementation of the post-editingapproach.Subtree substitution, whether using leaves orTED, does not handle parentheses, hyphens andnumbers well.
The structure severely degradeswhen performing substitution near these environ-ments.
The example in Table 3 shows the er-rors made by the substitution algorithm.
An en-tire subphrase is duplicated using the leaves tech-nique which introduces an opening parenthesiswith no closing counterpart and includes the erro-neous translation came, while TED-R duplicates /1999 - 1999 / 2208.The reason for these wayward substitutions canbe found in the dependency tree.
The matchingparentheses are not part of the same subtree andthis is the root cause of the problem.
The leavestechnique is very sensitive to these errors andthere is no easy way to prevent spurious parenthe-ses from being introduced.
Re-ranking in TED-R could filter these hypotheses out, but becausethe re-ranking module cannot model this depen-dency, the sentences with these errors are not al-ways discarded.
In the manual evaluation cam-paign, the sentence from Table 3 was includedin the sample sentences.
It would seem that themany evaluators did not view this error as impor-84tant or it was ignored.
It would be impossible tofind the referenced Council decision based on thetranslations and dates or monetary amounts mightchange drastically, which would not be acceptableif the translated text should be ready for publish-ing after translation.
For gisting, where the userknows that the translation is not perfect, this mayconstitute less of a problem.6 Future workThe initial alignment is based on the source to tar-get language alignment.
In the RBMT module, itis mostly word-based while in Moses, the align-ment must be recomputed due to the simplicityof the modification and that the Moses chart de-coder cannot output word alignment.
The mod-elling only handles alignment crossing one non-terminal and reduces alignment problems to thesecases by assuming a weak reordering.Future work should include extracting the wordalignment from the SMT system to improvesource to target language alignment.
The MT de-coder Joshua can output complete derivations in-cluding word-based alignment which would elim-inate the need to recompute source to target lan-guage alignment which currently produces noisymatching elements.
Experiments using a differ-ent RBMT engine should also be conducted.
TheRBMT module does not always produce one com-plete tree structure for a sentence and the reattach-ment algorithm handles this by adding any addi-tional graphs to the root node of the tree structure.A RBMT engine that produces complete deriva-tions is likely to improve the translation quality.This will require different tree extraction modulesfor Joshua and the RBMT engine, but otherwisethe system can be reused as is.6.1 Languages and formalismsThe chosen languages are closely related Ger-manic languages.
While the results seem promis-ing, the applicability of the approach shouldbe tested on a more distant language pair, e.g.Chinese-English or Russian-English if you wishto preserve the possibility of using METEORfor evaluation, but any distant pair for which anRBMT system exists can be used ?
provided atree output is available.The implementation substitutes dependencysubtrees into a hierarchical CFG-style tree.
A sec-ond test of the hybridisation approach is to com-bine systems where the structures are not as di-verse.
Hierarchical systems are derived from aSCFG so a RBMT system based on a CFG for-malism such as LUCY, could be used to test thegenerality of the hybridisation approach.As the TED-R approach does not rely on mark-ers for OOV words, an implementation where hi-erarchical subtrees are inserted into the RBMToutput should also be conducted.
The problemof inserting CFG-style subtrees into a dependencytree and generating the correct surface structuremust be resolved or a different RBMT systemwhich produce CFG-style trees implemented.The implementation of the leaves technique re-lies on the diversity of the tree structures, i.e.
thatthere are element-level similarities between hier-archical leaf nodes and both terminal and non-terminal dependency nodes and that the subtreerooted in a dependency node can be aligned toa hierarchical subtree.
The refinement methodwould have to be altered.
The relations and chil-dren techniques (Shvaiko and Euzenat, 2005) aregood candidates for similar tree structures.A change of formalism would not require alter-ations of the tree edit distance approach, as longas the structures are in fact tree structures.7 ConclusionThe post-editing approach proposed in this pa-per combines the strengths of statistical and rule-based machine translation and improve transla-tion quality, especially for the least accurate trans-lations.
The structural and knowledge-poor ap-proach is novel and has not been attempted before.It exploits structural output to create hybrid trans-lations and uses the linguistic knowledge encodedin structure and on nodes to improve the transla-tion candidates of hierarchical phrase-based MTsystems.Automatic evaluation shows a significant in-crease over the baselines when training data islimited and also improvement in TER and ME-TEOR for lexical substitution and TED-R with aSMT system trained on the Europarl corpus.Manual evaluation on test data shows that hy-brid translations were generally ranked higher, in-dicating that the hybrid approach produces moreaccurate translations.85ReferencesS.
Banerjee and A. Lavie.
2005.
METEOR: An auto-matic metric for MT evaluation with improved cor-relation with human judgments.
Intrinsic and Ex-trinsic Evaluation Measures for Machine Transla-tion and/or Summarization, page 65.E.
Bick.
2007.
Dan2eng: Wide-coverage danish-english machine translation.
Proceedings of Ma-chine Translation Summit XI, pages 37?43.P.
Bille.
2005.
A survey on tree edit distance andrelated problems.
Theoretical computer science,337(1-3):217?239.C.
Callison-Burch, C. Fordyce, P. Koehn, C. Monz,and J. Schroeder.
2007.
(Meta-) evaluation of ma-chine translation.
In Proceedings of the SecondWorkshop on Statistical Machine Translation, pages136?158.
Association for Computational Linguis-tics.D.
Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceed-ings of the 43rd Annual Meeting on Association forComputational Linguistics, pages 263?270.
Associ-ation for Computational Linguistics.A.
Eisele, C. Federmann, H. Uszkoreit, H. Saint-Amand, M. Kay, M. Jellinghaus, S. Hunsicker,T.
Herrmann, and Y. Chen.
2008.
Hybrid ma-chine translation architectures within and beyondthe EuroMatrix project.
In Proceedings of the 12thannual conference of the European Association forMachine Translation (EAMT 2008), pages 27?34.C.
Federmann, A. Eisele, H. Uszkoreit, Y. Chen,S.
Hunsicker, and J. Xu.
2010.
Further experimentswith shallow hybrid mt systems.
In Proceedingsof the Joint Fifth Workshop on Statistical MachineTranslation and MetricsMATR, pages 77?81.
Asso-ciation for Computational Linguistics.A.S.
Hildebrand and S. Vogel.
2008.
Combinationof machine translation systems via hypothesis se-lection from combined n-best lists.
In MT at work:Proceedings of the Eighth Conference of the Asso-ciation for Machine Translation in the Americas,pages 254?261.
Citeseer.P.
Koehn and C. Monz.
2006.
Manual and automaticevaluation of machine translation between europeanlanguages.
In Proceedings of the Workshop on Sta-tistical Machine Translation, pages 102?121.
Asso-ciation for Computational Linguistics.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, et al 2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,pages 177?180.
Association for Computational Lin-guistics.P.
Koehn.
2005.
Europarl: A parallel corpus for statis-tical machine translation.
In MT summit, volume 5.Citeseer.P.
Koehn.
2010.
An experimental management sys-tem.
The Prague Bulletin of Mathematical Linguis-tics, 94(-1):87?96.K.
Papineni, S. Roukos, T. Ward, and W.J.
Zhu.
2002.BLEU: a method for automatic evaluation of ma-chine translation.
In Proceedings of the 40th annualmeeting on association for computational linguis-tics, pages 311?318.
Association for ComputationalLinguistics.A.V.I.
Rosti, N.F.
Ayan, B. Xiang, S. Matsoukas,R.
Schwartz, and B. Dorr.
2007.
Combining out-puts from multiple machine translation systems.
InHuman Language Technologies 2007: The Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics; Proceedings ofthe Main Conference, pages 228?235.P.
Shvaiko and J. Euzenat.
2005.
A survey of schema-based matching approaches.
Journal on Data Se-mantics IV, pages 146?171.M.
Simard, N. Ueffing, P. Isabelle, R. Kuhn, et al2007.
Rule-based translation with statisticalphrase-based post-editing.
In ACL 2007 SecondWorkshop on Statistical Machine Translation.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, andJ.
Makhoul.
2006.
A study of translation edit ratewith targeted human annotation.
In Proceedings ofAssociation for Machine Translation in the Ameri-cas, pages 223?231.
Citeseer.A.
Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of the interna-tional conference on spoken language processing,volume 2, pages 901?904.
Citeseer.Gregor Thurmair.
2009.
Comparing different archi-tectures of Hybrid Machine Translation systems.
InProceedings of the MT Summit XII, pages 340?347.K.
Zhang and D. Shasha.
1989.
Simple fast algo-rithms for the editing distance between trees andrelated problems.
SIAM J.
Comput., 18(6):1245?1262.86
