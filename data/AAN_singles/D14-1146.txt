Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1396?1404,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsDevice-Dependent Readability for Improved Text UnderstandingA-Yeong Kim Hyun-Je Song Seong-Bae Park Sang-Jo LeeSchool of Computer Science and EngineeringKyungpook National UniversityDaegu, 702-701, Korea{aykim,hjsong,sbpark}@sejong.knu.ac.kr, sjlee@knu.ac.krAbstractReadability is used to provide users with high-quality service in text recommendation or textvisualization.
With the increasing use of hand-held devices, reading device is regarded asan important factor for readability.
There-fore, this paper investigates the relationshipbetween readability and reading devices suchas a smart phone, a tablet, and paper.
We sug-gest readability factors that are strongly relatedwith the readability of a specific device byshowing the correlations between various fac-tors in each device and human-rated readabil-ity.
Our experimental results show that eachdevice has its own readability characteristics,and thus different weights should be imposedon readability factors according to the devicetype.
In order to prove the usefulness of theresults, we apply the device-dependent read-ability to news article recommendation.1 IntroductionReadability is a function that maps a given text into areadability score by considering ?how easily the text isread and understood?
(Richards et al., 1992; Zamanianand Heydari, 2012).
Normally, the readability score isformulated as a combination of various factors.
Thesefactors reflect the easiness and understanding of thetext and include text presentation format, font size, av-erage ratio of annotated images, and sentence length(Hasegawa et al., 2008; Kitson, 1927; Ma et al., 2012;?Oquist, 2006).
Therefore, readability can be used toprovide satisfiable services in text recommendation ortext visualization.The study on readability has begun in the educationfield to measure the level of a text.
With the successof using readability in education (Franc?ois and Fairon,2012; Heilman et al., 2008; Ma et al., 2012), read-ability has been used in a range of domains recently.For example, in document retrieval, readability is usedto provide documents to non-expert users so that theycan read the retrieved documents easily (Jameel et al.,2012; Yan et al., 2006).
In text mining, readability hasbeen employed to analyze the characteristics of text.Especially, Hillbom showed the differences in readabil-ity between broadsheet newspapers and tabloids thatshare a similar political stance (Hillbom, 2009).There is one important issue of readability that hasnot been studied in natural language processing.
It is areading device.
That is, previous studies focused onlyon text printed on paper.
However, with the increasinguse of hand-held devices, people in these days use var-ious reading devices such as a tablet and a smart phoneas well as a paper.
Readability score can be differentaccording to the device type, because each device hasits own idiosyncrasy.
For example, assume that a sys-tem recommends the same news article to both user Awho reads it in her smart phone and user B who readsit on paper.
Although both users read the same article,user A might believe that her article is more difficult toread than user B because of the screen size of her smartphone.This paper explores the relationship between readingdevices and readability.
For this purpose, we first inves-tigate whether readability changes according to devicetype or not.
Then, we analyze which readability fac-tors are affected by reading devices.
To see the rela-tionship between readability factors and devices, var-ious well-known readability factors are computed fornews articles collected from an Internet portal.
At thesame time, the readability of each article is also man-ually rated.
When the readability is rated manually, itis done three times for different reading devices of asmart phone, a tablet, and paper.
The factors that af-fect the readability actually in each device are foundout through the correlations between the factors and themanually-labeled readability.
Some factors are impor-tant to the readability of smart phone, but insignificantto that of paper.
Therefore, we discover the importanceof each readability factor for each device by analyzingthe correlations.The usefulness of the device-dependent readabilityis proven by applying it to news article recommenda-tion.
That is, different importance weights for read-ability factors are considered according to device typewhen recommending news articles.
Our experimentalresults show that the performance of news article rec-ommendation gets best when the device used for read-ing news articles is identical to the device used for mea-suring readability.
Therefore, it is essential to considerdifferent importance weights according to device type1396in news article recommendation.
It also proves thatthe proposed device-dependent readability reflects thecharacteristics of reading devices well.The rest of this paper is organized as follows.
Wefirst review related studies on readability.
Next, weintroduce various readability factors and propose thedevice-dependent readability.
Then, the news articlerecommendation using the device-dependent readabil-ity is explained.
This recommendation is prepared toprove the usefulness of the device-dependent readabil-ity.
In the experiments, we present the experimentalresults on the relationship between reading devices andreadability.
We also describe the experiments on newsrecommendation using the device-dependent readabil-ity and present their results.
Finally, we summarize ourresearch.2 Related workThe history of readability studies began in the 1800s.Early studies focused on the frequency of easy words,sentence length, and word length (Huld?en, 2004).Flesch designed a formula to calculate ?reading ease?using only the average word length and sentence length(Flesch, 1948).
He adjusted the relative importancebetween word length and sentence length using 100words selected randomly from a corpus.
This formulais called the Flesch-Kincaid formula, and is generallyused in measuring the readability of a textbook (Kin-caid et al., 1975).
Dale and Chall (1949) defined a listof 3,000 easy words.
Then, they used the average sen-tence length and the percentage of words not includedin the list.
These studies simply used superficial fac-tors, and thus do not reflect syntactic factors.Recent studies on readability use various factors in-cluding syntactic ones, and combine them to producea highly predictive model of readability.
Franc?ois andFaircon (2012) proposed a readability formula with 46textual factors for French as a foreign language.
Thefactors represent lexical, syntactic, and semantic char-acteristics of sentences, and the specificities of French.They are extracted from 28 French Foreign Language(FFL) textbooks written for adults learning FFL.
On theother hand, Pitler and Nenkova (2008) showed the rela-tion between readability factors and readability.
Theyused human ratings from the Wall Street Journal cor-pus, and computed the correlations between the read-ability factors and the average human ratings.
Accord-ing to their results, the average number of verb phrasesin a sentence, the number of words in an article, thelikelihood of the vocabulary, and the likelihood of thediscourse relations are highly correlated with humanratings.
However, these studies did not consider thereading devices, but focused on how well a text is writ-ten.
Since the readability can be differentiated accord-ing to reading device, a reading device should be con-sidered when computing the readability of a given text.To the best of our knowledge, there are few studieson the readability on mobile devices that do not con-sider language-related aspects.
Most studies on mobiledevices focused on the development of new text formatand layout to help users read documents easily.
?Oquist(2006) proposed a new text presentation format calledthe dynamic Rapid Serial Visual Presentation.
Accord-ing to his experimental results, this format helps to re-duce eye movements.
On the other hand, Hasegawaet al.
(2008) evaluated the readability of documentson mobile devices with regard to screen and font size.They reported that the readability is improved when thecharacters are vertically enlarged.
Readability on mo-bile devices is not reflected only by the visualizationfactors, but also by textual factors.
Therefore, this pa-per explores the readability factors that reflect the lexi-cal and grammatical complexity of text and are affectedby reading devices.3 Readability FactorsTable 1 lists the readability factors used in this paper.Basically, they are based on the factors proposed byPitler and Nenkova (2008).
However, some factors areexcluded and some new factors are added.
This is be-cause some of their factors are computationally infeasi-ble and language-dependent.
As a result, we have thir-teen readability factors.
These readability factors aredivided into four types: superficial, lexical, syntacticfactors, and lexical cohesion.3.1 Superficial FactorsSuperficial factors were used in most early readabilitystudies (Dale and Chall, 1949; Flesch, 1948; Kincaid etal., 1975), and reflect the construction of a text.
We in-vestigate four factors: text length (TL), sentence length(SL), average number of words per sentence (WS), andaverage number of characters per word (CW).
Sincelonger text is perceived as ?harder-to-read?
than shortone, these factors are all reciprocally related with read-ability.The first two factors are related to length.
TL countsthe number of characters in a text, whereas SL com-putes the number of sentences.
When a writer attemptsto write many topics in a text, she tends to use manykinds of words simultaneously.
As a result, the text be-comes longer and more complex.
Such long length oftext disturbs a reader?s comprehension of the text, andthen it is more difficult for the reader to read the text(Heilman et al., 2008).WS counts the average number of words per sen-tence, and CW reflects the average number of charactersper word.
When they are large, the sentence is diffi-cult to read, which leads to difficulties in understandingthe text.
Especially, CW reflects compound nouns andtechnical words.
For instance, compound nouns in Ko-rean are usually long, because there is no spacing be-tween words in a compound noun.
For example, let usconsider a compound noun, ?Daehanmingukjungboo,?which means the Korean government.
Actually thiscompound noun consists of two independent nouns.1397Type of Factors Abbr.
DescriptionSuperficial factorsTL The number of characters in a textSL The number of sentences in a textWS Average number of words per sentenceCW Average number of characters per wordLexical factor LL Article likelihood estimated by language modelSyntactic factorsPTD Average parse tree depths per sentenceNP Average number of noun phrases per sentenceVP Average number of verb phrases per sentenceSBAR Average number of subordinate clauses per sentenceLexical cohesionCOS Average cosine similarity between pairs of adjacent sentencesWO Average word overlap between pairs of adjacent sentencesNPO Average word overlap over noun and pronoun onlyPRP Average number of pronouns per sentenceTable 1: Description of readability factorsOne is ?Daehanminguk?
meaning Korea and the otheris ?Jungboo?
meaning a government.
The two are con-catenated to form a compound noun and become a longsingle word.
In addition, many difficult words such asdomain-specific terms tend to be long.
Such lengthywords make it difficult to read a text.3.2 Lexical FactorLexical factor determines whether a given text con-sists of frequent words.
Texts that express a new trendin various fields often use many newly coined words.Such neologisms make it difficult to read and under-stand a text.
Therefore, an easily-understandable textis composed of widely-used words rather than unusualwords.In order to compute the use of frequent words in atext, a unigram language model is used as in the workof Pitler and Nenkova (2008).
In this model, the loglikelihood of text t is computed by?w?tC(w) ?
logP (w|B).
(1)where P (w|B) is the probability of a word w accordingto a background corpus B, and C(w) is the number oftimes that w appears in t.This factor examines the familiarity of the wordsused in the text.
The more frequently a word appearsin the background corpus, the more familiar it is re-garded.
The frequency of a word w is then reflectedinto P (w|B) computed from the independent back-ground corpus B.
Therefore, the factor LL is positivelyrelated with readability.3.3 Syntactic FactorsSyntactic factors reflect sentence complexity directlythat affects human processing of a sentence.
We con-sider the average parse tree depth per sentence (PTD),the average number of noun phrases per sentence (NP),the average number of verb phrases per sentence (VP),and the average number of subordinate clauses per sen-tence (SBAR) as syntactic factors.
These four factorswere defined by Schwarm and Ostendorf (2005).A reader regards a text as difficult when the sen-tences in the text have large parse tree depths or manysubordinate clauses.
Thus, PTD and SBAR are relatednegatively with readability.
On the other hand, the re-lationship of NP and VP to readability are not one way.The large number of noun phrases in a text requiresa reader to remember more items (Barzilay and Lap-ata, 2008; Pitler and Nenkova, 2008).
However, it alsomakes the text more interesting.
The texts written foradults actually contain more entities than those writ-ten for children (Barzilay and Lapata, 2008).
The sameis true for VP.
The large number of verb phrases in asentence makes the sentence more complex.
However,people feel that a text is more easier to comprehendwhen related clauses are grouped together (Bailin andGrafstein, 2001).3.4 Lexical CohesionLexical cohesion denotes how the sentences in a textare semantically connected.
People usually bring con-tinuous sentences into their mind at the same time, andinterpret them as a single unit (Okazaki et al., 2005).
Inother words, a reader prefers text whose sentences aresmoothly connected to text whose sentences are inde-pendent of one another.
Therefore, sentence continuityplays a primary role in understanding an entire text.In the classic study of cohesion, various uses ofcohesive elements such as pronouns, definite articles,and topic continuity have been discussed (Halliday andHasan, 1976).
This paper uses the average cosine sim-ilarity (COS), word overlap (WO), word overlap overjust nouns and pronouns (NPO) between pairs of adja-cent sentences, and the average number of pronouns persentence (PRP).
COS, WO, and NPO are superficial mea-sures of topic continuity, whereas PRP is an indicativefeature of sentence continuity.
High values for thesefactors imply that the sentences in the text are relatedsomehow.
Therefore, these factors are believed to berelated positively with readability.13983.5 Measurement of ReadabilityWhen a reading device d is given, the readability oftext t, represented as R(t|d), is formulated as a com-bination of readability factors with their correspondingweight in the device.
We assume that wi|d, the weightof a readability factor fi, is dependent on the readingdevice d. Following the previous work of Pitler andNenkova (2008), we also assume that each readabil-ity factor affects readability independently.
Therefore,readability is calculated as a weighted linear sum of allreadability factors.
That is, R(t|d) is computed byR(t|d) =?i?{1,2,...,M}wi|d?
fi(t) (2)where M is the number of readability factors.Each weight wi|dis determined from a set of newsarticles T .
We collected a large number of news arti-cles from an Internet news portal.
The readability ofeach article was manually labeled.
This is done threetimes, since we have three different devices of a smartphone, a tablet, and paper.
Since human rating of eacharticle t ?
T is available for each device, wi|d?s canbe estimated by linear regression.
These weights aredifferent according to the devices.4 News Article Recommendation byDevice-Dependent ReadabilityThe fact that the weights wi|din Equation (2) are differ-ent for each device d implies that the readability mea-surement should be different depending on the devicetype.
In order to see the usefulness of this device-dependent readability, we apply it to news article rec-ommendation.
News article recommendation aims toprovide a user with news articles that interest the user.Thus, it selects a few articles that meet user preferencefrom a gigantic amount of news events.
Various meth-ods have reported notable results in news article rec-ommendation (Das et al., 2007; Li et al., 2010; Liu etal., 2010).
In addition, with the recent interest in hand-held devices, the demand for news recommendation onhand-held devices is increasing.
However, there hasbeen, at least as far as we know, no study on the read-ability of hand-held devices.Device-dependent readability is reflected into newsarticle recommendation through a re-ranking frame-work.
Figure 1 depicts the overall process of suggest-ing news articles for a specific device with the device-dependent readability.
The point of this figure is tomeasure how appropriate a news article is for a spe-cific reading device.
For this, a news recommendationsystem first chooses a set of news articles from a newsrepository based on its own criterion.
Then, we re-rankthem by the device-dependent readability to obtain thefinal set of ranked news articles for the device.Formally, a news article recommendation ranks a setof articles, A = {a1, a2, ..., am}, where airepresentsthe i-th article.
The order between ranks a1a2Min Max AverageArticle length 68 610 346.5# of sentences 1 14 6.24# of words per sentence 8 33 16.93# of words per article 17 178 99.34Table 2: Statistics of the news article data...  amshould be satisfied by the criterion of therecommendation system.
That is, assuming that thesystem has a score function score(ai), score(ai) >score(aj) has to be met if aiaj.
Then, the topk(k ?
m) articles of A by the score function are sug-gested as appropriate news articles.
After that, the se-lected articles are re-ranked by another criterion, thedevice-dependent readability.
That is, the final rank ofan article within the selected set is determined by an-other function, rerank.
Since this function has to re-flect the device-dependent readability, it takes two pa-rameters.
One is an article, and the other is a devicetype.
The re-rank function is modeled asrerank(a, d) = R(a|d)=?i?{1,2,...,M}wi|d?
fi(a).
(3)As a result, the readability-based re-ranking modulesuggests the news articles based on how easily the ar-ticles are read on a specific reading device.
Note thateven the same article would be ranked differently ac-cording to the device type because the article is re-ranked by the device-dependent readability.
At last, thetop k?(k??
k) re-ranked articles among them are sug-gested as final news articles.5 Experiments5.1 Experiments on Readability Factors5.1.1 Experiment SettingsFor the experiments of analyzing relationship betweenreadability factors and readability, we collected a Ko-rean news corpus from Naver News1.
This corpus con-tains news articles from June 10, 2013 to June 25,2013.
We selected 74 articles randomly from the cor-pus which were used for readability formula and show-ing the relationships between readability factors.
Allselected articles belong to one of three categories: ?Pol-itics?, ?Entertainment?, and ?Sports?.
A set of these 74news articles becomes T , and is used to compute theweights in Equation (2).
Table 2 describes a simplestatistics of the selected news articles.
The shortest ar-ticle consists of 68 characters, whereas the longest onehas 610 characters.
The average length of article is346.5.
The shortest article is written in one sentence,and the longest has 14 sentences.
One article has ap-proximately 6.24 sentences on average.
In addition, the1A Korean news portal of which web address ishttp://news.naver.com.1399NewsRepositoryDevicedependentre-rankingNewsArticlesNewsRecommendationSystemReadabilityFigure 1: Overall process of re-ranking news articles based on device-dependent readabilitynumber of words per sentence ranges from 8 to 33, andthe average is 16.93.
The minimum number of wordsin an article is 17, and the maximum number of wordsis 178.
An article is composed of 99.34 words on aver-age.In order to compute the lexical factor LL by Equa-tion (1), a background corpus B is required.
Since thiscorpus should be independent from the news articlesexplained above, the Naver News is adopted again togenerate B.
For the background corpus B, we col-lected news articles from January 1, 2013 to September6, 2013, but excluded the articles from June 10 to June25, because they are already used.
This corpus consistsof 298,729 articles with 3,264,104 distinct words.The readability score for each article was manuallylabeled by three undergraduate students.
To investigatethe relationship between reading devices and readabil-ity, each article was read using three different readingdevices.
The Galaxy Note 1 with a 5-inch screen isused as the smart phone, Galaxy Tab 10.1 with a 10.1-inch screen is used as the tablet, and A4-size paperis used for the paper.
That is, the human annotatorsread and rated 74 articles per device.
The order of thedevices where the annotators evaluated readability issmart phone, tablet, and paper.
This order was main-tained for all the experiments.
All aspects but contenttexts were under control.
For instance, font = ?Gothic,12 pt?
(this is most commonly used font and size thatmost Korean web pages and textbooks use), font color= ?black?, alignment = ?both?
were used for all threedevices.
In addition, the non-content aspects were ex-actly same for devices because the annotators of read-ability and the recommended articles shared the read-ing devices.
Although these aspects affect readabilityand many previous studies already proved it, it is notour concern.
We only attempt to capture how read-Reading device Min Max AverageSmart phone 1.67 5 3.423 ?
0.741Tablet 1.33 5 3.531 ?
0.837Paper 2 5 3.360 ?
0.594Table 3: Readability scores given by human annotatorsability is affected by the content in different types ofdevices.Human annotators can remember the content ofnews articles when they read articles with three de-vices.
The human annotators were asked to read andevaluate many articles within a relatively short period.Therefore, before the main experiments, we performeda pilot experiment on the memory effects of previouslyread articles and verified it empirically.
We hired threeundergraduate students who were not involved in ourmain experiments.
The students read the same 250 ar-ticles four times, and these also come from Naver Newscorpus which are not included the previous 74 articles.After their first reading, they read the articles again in3, 7, and 14 days later.
After 3 days, two students re-membered the articles somewhat, but one student re-membered them vaguely.
Since they almost forgot thearticles after 7 days, we placed 7 days interval betweendevices.The readability score of an article was rated by theannotators using the questions in the work of Pitler andNenkova (2008).
We use only two of the questions,while they used four questions for the annotators.
Theirquestions are intended to measure the extent of howwell a text is written, how it fits together, how easyit is to understand, and how interesting it is.
We canconsider ?well-written?
and ?fit-together?
as a syntac-tic perspective, whereas ?easy to understand?
and ?in-teresting?
belong to a content perspective.
For such a1400Smart phone Tablet PaperFactor Value Factor Value Factor ValueSL -0.394 SL -0.370 NP 0.298TL -0.293 WS 0.321 WS 0.278WS 0.288 LL 0.253 LL 0.268LL 0.249 NP 0.240 VP 0.244Table 4: Pearson correlation coefficients of importantreadability factorsreason, four questions can be summarized in two ques-tions.
The two questions used are?
How well-written is this article??
How interesting is this article?For these two questions, each annotator assigns a scorebetween 1 and 5 to each article.
Here, 1 point meansthat the article is worst and 5 point implies that it isbest.
A readability score of one human annotator iscomposed with the average of two questions (well-written, interesting).
We used the average of three hu-man annotators?
readability scores in our experiments.Table 3 shows the readability scores of the articles foreach device.
According to this table, the readabilityscore ranges from 1.67 to 5 for the smart phone, 1.33to 5 for the tablet, and ranges from 2 to 5 for the paper.The average readability is 3.423 for the smart phone,3.531 for the tablet, and 3.360 for the paper.
To seethe inter-judge agreement among annotators, the Kappacoefficient (Fleiss, 1971) is used.
The Kappa valuesfor the ?smart phone?, ?tablet?, and ?paper?
are 0.342,0.333, and 0.361, respectively.
All these values corre-spond to fair agreement.5.1.2 Experimental ResultsIn order to see the importance of each factor in a spe-cific device, we adopt the Pearson correlation coeffi-cients between readability factors and reading devices.Table 4 lists the four most important factors in eachdevice and their Pearson correlation coefficients.
Espe-cially, p-value is smaller than 0.05 for all factors in thistable.For the smart phone, SL, the number of sentences ina text, is the most important readability factor.
Its cor-relation with the smart phone is -0.394.
TL, the numberof characters, is the second important factor and has anegative correlation of -0.293.
These results imply thatreaders are negatively sensitive to the length of an arti-cle because of the small display size of a smart phone.That is, in the smart phone, longer articles are recog-nized as difficult to read compared to shorter ones.
Thenumber of words per sentence, WS, is the third impor-tant factor with correlation of 0.288.
The log-likelihoodof an article, LL, is also positively related with the read-ability, which proves that widely-used words make iteasy to understand an article.
The top three factors aresuperficial with regard to text length.
Therefore, the su-perficial factors are more important than other types offactors for the smart phone.SL is the most critical readability factor even for thetablet.
It affects readability with high correlation of -0.370.
The second important factor is WS with correla-tion of 0.321.
Both of these factors are superfical.
Thethird important factor, LL, is positively related withreadability as expected.
The fourth factor that affectsreadability is the number of noun phrases, NP.
It is nat-ural for NP to be positively related with the readability.Finally, for the paper, NP is most strongly related toreadability with correlation of 0.298.
The second im-portant factor is WS, whose correlation is 0.278.
LL isthe third important factor and shows a positive relation-ship.
Note that WS and LL are important readabilityfactors for all devices.
The next important readabil-ity factor for the paper is the average number of verbphrases (VP).
The articles with many noun phrases andverb phrases are perceived as easier-to-read for the pa-per.
Note that the importance of superficial factors islimited for the paper.
We expected that WS is negativelyrelated, but, it is positively related with readability forall three devices.
The reason for this could be that theannotators thought the articles with higher WS are moreinteresting.The important factors for the smart phone are differ-ent from those for the paper.
On the other hand, thetablet shares many factors with both the smart phoneand the paper.
Because the screen size of a tablet issimilar to the size of an A4 paper, the tablet and the pa-per share readability factors.
However, length-relatedfactors play a more important role than syntactic fac-tors in the smart phone because a smart phone has asmaller screen.5.2 Experiments on News Recommendation5.2.1 Experiment SettingsExperiments for news article recommendation wereperformed to see the effectiveness of device-dependentreadability.
The process of news recommendation withdevice-dependent readability is as follows.
For a spe-cific device,1.
Select top-k news articles from a news repositoryby the criterion of the recommendation system.2.
Re-rank the k articles by the readability of the de-vice using Equation (3).3.
Select top-k?news articles by the new rank.4.
Human annotators read and rate the k?articleswith the device.5.
Compare the ranks of k?articles by device-dependent readability with those by human rat-ings.Since we have three types of devices, this process isperformed three times with a different device.The news articles from September 10, 2013 toSeptember 12, 2013 collected from Naver News were1401Min Max AverageArticle length 277 6,077 990.68# of sentences 4 199 22.85# of words per sentence 4 100 15.73# of words per article 71 2,034 301.61Table 5: Statistics of news data for recommendationReading device Min Max AverageSmart phone 1 5 3.513 ?
0.962Tablet 1 5 3.344 ?
0.852Paper 1 5 3.250 ?
0.907Table 6: Scores of news articles by human annotatorsin news recommendationused as the news repository.
The number of times thata news article was actually read by its anonymous read-ers at the portal site is used as the criterion for the rec-ommendation system.
Since this criterion is providedon a daily basis and news articles were collected forthree days, the process explained above is performedthree times.
The top twenty articles were selected bythe criterion every day.
That is, k = 20.
Table 5 showsthe statistics of the total 60 articles.
The shortest arti-cle consists of 277 characters, and the longest articlehas 6,077 characters.
On average, an article is writ-ten with 990.68 characters.
The minimum number ofsentences in an article is 4, and the maximum numberof sentences is 199.
An article is composed of 22.85sentences on average.
The average number of words ina sentence is 15.73, whereas a sentence length rangesfrom 4 to 100 words.
The shortest article has 71 words,and the longest article has 2,034 words.
One article hasapproximately 301.61 words on average.Three human annotators labeled the scores of thenews articles manually.
The annotators were the samepersons who labeled the readability scores.
Similar tothe previous experiments, 7 days intervals was placedamong devices to reduce the memory effect.
The sametwo questions used in the previous section were usedagain for this experiment.
The annotators assigned ascore between 1 and 5 to every article for each ques-tion.
The final score of an article was obtained by aver-aging six scores (two questions from three annotators).Table 6 summarizes the scores of the articles by thehuman annotators.
As shown in this table, the articlescores vary for all reading devices.
The average scoresfor smart phone, tablet, and paper are 3.513, 3.344,and 3.250 respectively.
The Kappa value for the ?smartphone?
is 0.402, and that for both the ?tablet?
and the?paper?
is 0.393.
Thus, the value of ?smart phone?
fallsinto moderate agreement, whereas those of the ?tablet?and ?paper?
correspond to fair agreement.
The perfor-mance of the news article recommendation is evaluatedwith the Normalized Discounted Cumulative Gain attop P (NDCG@P ) (J?arvelin and Kek?al?ainen, 2002).Figure 2: NDCG@k?scores with various k?for thesmart phone.Figure 3: NDCG@k?scores with various k?for thetablet.5.2.2 Experimental ResultsFor the a baseline criterion, we use the news articlerecommendation system in Naver, which recommendsnews article by the number of article hits.
Figures 2 to 4show the NDCG@k?scores with 1 ?
k??
10 for thethree devices.
Each graph in these figures compares theperformance of various devices when the readabilityfor a specific device is used.
That is, Figure 2 depictsthe NDCG@k?scores for the recommended news arti-cles when the articles are shown in the smart phone, thetablet, and the paper respectively.
In computing theirNDCG@k?scores, the news articles are re-ranked byreadability for the smart phone.
Therefore, in this fig-ure we expect that the NDCG@k?score for using thesmart phone is higher than those for using the tablet andpaper.
In the same way, Figure 3 and Figure 4 comparethe NDCG@k?scores when the readabilities for thetablet and paper are used.In all three graphs, the best news recommendationperformance is achieved when the device used to read1402Figure 4: NDCG@k?scores with various k?for thepaper.news articles is the same as the device used for read-ability.
In Figure 2, the use of the smart phone outper-forms those of other devices when k??
6.
This provesthat the quality of highly ranked news articles is muchbetter for the smart phone than for other devices, whenthe readability for smart phone is used.Figure 3 shows the NDCG@k?scores for using var-ious devices when the news articles are re-ranked byreadability for the tablet.
In this figure, the use ofthe tablet as a reading device is better than using thesmart phone or the paper.
The performance differenceis largest at k?= 3.
The difference becomes smalleras k?increases up to 10, but the performance of tabletis still higher than those of others.
In Figure 2 and 3,when k?= 1, the baseline outperforms other devices.We believe this happens because the baseline choosesnews articles by user-hit.
Therefore, many articles rec-ommended by the baseline are interesting because peo-ple tend to click more often when an article is inter-esting.
As noted, readability reflects users?
interests,which leads to high performance of the baseline.
Theperformance of paper is best in Figure 4, since the ar-ticles are re-ranked by the readability for paper.
Paperoutperforms all other devices for all k?s.
Note that theperformances of the baseline are always lowest regard-less of reading device.From all results above, we can infer that the use ofdevice-dependent readability is helpful to news articlerecommendation.
This is because the readability fac-tors that affect the readers of news articles are differentaccording to the reading device.
Therefore, it is im-portant to reflect the characteristics of a reading devicewhen recommending news articles.6 ConclusionIn this paper, we have proposed a device-dependentreadability.
Since a reading device is one of the mostimportant features of readability, different weights havebeen assigned to the readability factors according to de-vice type.
We have shown that the important readabil-ity factors are distinct according to the reading deviceby investigating the correlation between the readabilityfactors and the reading device.
Through the correlation,we found that tablet shares many important factors withboth smart phone and paper.The experiments on the news articles collected froman Internet portal proved that readability is actually af-fected by the reading device.
In addition, the validity ofthe device-dependent readability was shown by apply-ing it to the news article recommendation.
The newsarticles were first ranked by the criterion of the recom-mendation system.
Then, they were re-ranked by thedevice-dependent readability.
Our experiments showedthat the recommendation performance of the re-rankedarticles gets best when the device used for readability isthe same as the reading device.
These two types of ex-periments proved the importance and effectiveness ofthe device-dependent readability.AcknowledgmentsThis work was supported by the IT R&D program ofMSIP/KEIT (10044494, WiseKB: Big data based self-evolving knowledge base and reasoning platform) andthe Industrial Strategic Technology Development Pro-gram (10035348, Development of a Cognitive Planningand Learning Model for Mobile Platforms) funded bythe Ministry of Knowledge Economy(MKE, Korea).ReferencesAlan Bailin and Ann Grafstein.
2001.
The linguisticassumptions underlying readability formulae: A cri-tique.
Language & Communication, 21(3):285?301.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Compu-tational Linguistics, 34(1):1?34.Edgar Dale and Jeanne Chall.
1949.
The concept ofreadability.
Elementary English, 26(1):19?26.Abhinandan Das, Mayur Datar, Ashutosh Garg, andShyam Rajaram.
2007.
Google news personaliza-tion: scalable online collaborative filtering.
In Pro-ceedings of the 16th International Conference onWorld Wide Web, pages 271?280.Joseph Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological bulletin,76(5):378?382.Rudolph Flesch.
1948.
A new readability yardstick.Journal of Applied Psychology, 32(3):221?233.Thomas Franc?ois and C?edrick Fairon.
2012.
AnAI readability formula for French as a foreign lan-guage.
In Proceedings of the 2012 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning,pages 466?477.1403Michael Halliday and Ruqaiya Hasan.
1976.
Cohesionin English.
Longman Group Ltd.Satoshi Hasegawa, Kazuhiro Fujikake, Masako Omori,and Masaru Miyao.
2008.
Readability of charac-ters on mobile phone liquid crystal displays.
In-ternational Journal of Occupational Safety and Er-gonomics (JOSE), 14(3):293?304.Michael Heilman, Kevyn Collins-Thompson, andMaxine Eskenazi.
2008.
An analysis of statisticalmodels and features for reading difficulty prediction.In Proceedings of the Third Workshop on InnovativeUse of NLP for Building Educational Applications,pages 71?79.Kristina Hillbom.
2009.
Newspaper Readability: aBroadsheet vs. a Tabloid.
Ph.D. thesis, University ofG?avle.M?ans Huld?en.
2004.
Linguistic complexity intwo major american newspapers and the associatedpress newswire, 1900?2000.
Master?s thesis,?AboAkademi University.Shoaib Jameel, Wai Lam, and Xiaojun Qian.
2012.Ranking text documents based on conceptual dif-ficulty using term embedding and sequential dis-course cohesion.
In Proceedings of the The 2012IEEE/WIC/ACM International Joint Conferences onWeb Intelligence and Intelligent Agent Technology-Volume 01, pages 145?152.Kalervo J?arvelin and Jaana Kek?al?ainen.
2002.
Cu-mulated gain-based evaluation of IR techniques.ACM Transactions on Information Systems (TOIS),20(4):422?446.J.
Peter Kincaid, Robert Fishburne Jr., Richard Rogers,and Brad Chissom.
1975.
Derivation of new read-ability formulas (automated readability index, fogcount and flesch reading ease formula) for navy en-listed personnel.
Technical report, DTIC Document.Harry Kitson.
1927.
The mind of the buyer.
MacMil-lan Company.Lihong Li, Wei Chu, John Langford, and Robert E.Schapire.
2010.
A contextual-bandit approach topersonalized news article recommendation.
In Pro-ceedings of the 19th International Conference onWorld Wide Web, pages 661?670.Jiahui Liu, Peter Dolan, and Elin R. Pedersen.
2010.Personalized news recommendation based on clickbehavior.
In Proceedings of the 15th InternationalConference on Intelligent User Interfaces, pages 31?40.Yi Ma, Eric Fosler-Lussier, and Robert Lofthus.
2012.Ranking-based readability assessment for early pri-mary children?s literature.
In Proceedings of the2012 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 548?552.Naoaki Okazaki, Yutaka Matsuo, and MitsuruIshizuka.
2005.
Improving chronological orderingof sentences extracted from multiple newspaper ar-ticles.
ACM Transactions on Asian Language Infor-mation Processing (TALIP), 4(3):321?339.Gustav?Oquist.
2006.
Evaluating readability on mo-bile devices.
Ph.D. thesis, Uppsala University.Emily Pitler and Ani Nenkova.
2008.
Revisiting read-ability: A unified framework for predicting text qual-ity.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages186?195.Jack Richards, John Platt, Heidi Platt, and ChristopheCandlin.
1992.
Longman Dictionary of LanguageTeaching and Applied Linguistics, volume 78.
Long-man London.Sarah Schwarm and Mari Ostendorf.
2005.
Readinglevel assessment using support vector machines andstatistical language models.
In Proceedings of the43rd Annual Meeting on Association for Computa-tional Linguistics, pages 523?530.Xin Yan, Dawei Song, and Xue Li.
2006.
Concept-based document readability in domain specific infor-mation retrieval.
In Proceedings of the 15th ACM In-ternational Conference on Information and Knowl-edge Management, pages 540?549.Mostafa Zamanian and Pooneh Heydari.
2012.
Read-ability of texts: State of the art.
Theory and Practicein Language Studies, 2(1):43?53.1404
