Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 91?99,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsAn improved corpus of disease mentions in PubMed citationsRezarta Islamaj Do?an Zhiyong LuNational Center for Biotechnology Information National Center for Biotechnology Information8600 Rockville Pike 8600 Rockville PikeBethesda, MD 20894, USA Bethesda, MD 20894, USARezarta.Islamaj@nih.gov Zhiyong.Lu@nih.govAbstractThe latest discoveries on diseases and their di-agnosis/treatment are mostly disseminated inthe form of scientific publications.
However,with the rapid growth of the biomedical litera-ture and a high level of variation and ambigui-ty in disease names, the task of retrievingdisease-related articles becomes increasinglychallenging using the traditional keyword-based approach.
An important first step forany disease-related information extractiontask in the biomedical literature is the diseasemention recognition task.
However, despitethe strong interest, there has not been enoughwork done on disease name identification,perhaps because of the difficulty in obtainingadequate corpora.
Towards this aim, we creat-ed a large-scale disease corpus consisting of6900 disease mentions in 793 PubMed cita-tions, derived from an earlier corpus.
Our cor-pus contains rich annotations, was developedby a team of 12 annotators (two people perannotation) and covers all sentences in aPubMed abstract.
Disease mentions are cate-gorized into Specific Disease, Disease Class,Composite Mention and Modifier categories.When used as the gold standard data for astate-of-the-art machine-learning approach,significantly higher performance can be foundon our corpus than the previous one.
Suchcharacteristics make this disease name corpusa valuable resource for mining disease-relatedinformation from biomedical text.
The NCBIcorpus is available for download athttp://www.ncbi.nlm.nih.gov/CBBresearch/Fellows/Dogan/disease.html.1 IntroductionIdentification of biomedical entities has been anactive area of research in recent years (Rinaldi etal., 2011, Smith et al, 2008, Yeh et al, 2005).
Au-tomatic systems, both lexically-based and machinelearning-based, have been built to identify medi-cally relevant concepts and/or their relationships.Biomedical entity recognition research covers notonly gene/protein mention recognition (Tanabe etal., 2005, Campos et al, 2012), but also other med-ically relevant concepts such as disease names,chemical/drug names, treatments, procedures etc.Systems capable of achieving high performance onthese tasks are highly desirable as entity recogni-tion precedes all other information extraction andtext mining tasks.Disease information is sought very frequently inbiomedical search engines.
Previous PubMed logusage analysis (Islamaj Dogan et al, 2009) hasshown that disease is the most frequent non-bibliographic information requested from PubMedusers.
Furthermore, disease information was oftenfound to be queried together with Chemical/Drugor Gene/Protein information.
Automatic recogni-tion of disease mentions therefore, is essential notonly for improving retrieval of relevant documents,but also for extraction of associations between dis-eases and genes or between diseases and drugs.However, prior research shows that automatic dis-ease recognition is a challenging task due to varia-tions and ambiguities in disease names (Leaman etal., 2009, Chowdhury and Lavelli 2010).Lexically-based systems of disease name recog-nition, generally refer to the Unified Medical Lan-guage System (UMLS) (Burgun and Bodenreider912008).
UMLS is a comprehensive resource of med-ically relevant concepts and relationships andMETAMAP(Aronson and Lang 2010) is an exam-ple of a natural language processing (NLP) systemthat provides reliable mapping of the text of a bio-medical document to UMLS concepts and theirsemantic types.Machine learning systems, on the other hand,have been employed in order to benefit from theflexibility they allow over the rule-based and otherstatistical systems.
However, machine learningsystems are strongly dependent on the data availa-ble for their training; therefore a comprehensivecorpus of examples representing as many varia-tions as possible of the entity of interest is highlyfavorable.To our best knowledge, there is one corpus ofdisease mentions in MEDLINE citations developedby Leaman et al, 2009.
This corpus, AZDC cor-pus, was inspired by the work of Jimeno et al,2008 and its overall characteristics are given inTable 1.
This corpus has been the study of at leasttwo different groups in building automatic systemsfor disease name recognition in biomedical litera-ture (Leaman et al, 2009, Chowdhury and Lavelli,2010).
They both reported F-scores around 80% in10-fold cross-validation experiments.One common encountered difficulty in this do-main is the fact that ?disease?
as a category has avery loose definition, and covers a wide range ofconcepts.
?Disease?
is a broadly-used term thatrefers to any condition that causes pain, suffering,distress, dysfunction, social problems, and/ordeath.
In UMLS, the ?disease?
concept is coveredby twelve different semantic types as shown inTable 2.
The disease definition issue has been dis-cussed extensively in other studies (Neveol et al,2009, Neveol and Lu 2012).Disease mentions are also heavily abbreviated inbiomedical literature (Yeganova et al, 2010).
The-se abbreviations are not always standard; the sameabbreviated form may represent different definingstrings in different documents.
It is therefore, un-clear whether these ambiguities could be resolvedby an abbreviation look-up list from UMLS Me-tathesaurus and other available databases.In this study, we present our efforts in improv-ing the AZDC corpus by building a richer, broaderand more complete disease name corpus.
TheNCBI corpus reflects a more representative viewof what constitutes a disease name as it combinesthe decisions of twelve annotators.
It also providesfour different categories of disease mentions.
Ourwork was motivated by the following observations:?
The need of a pool of experts:The AZDC corpus is the work of one annota-tor.
While in terms of consistency this is gen-erally a good thing, a pool of annotatorsguarantees a more representative view of theentity to be annotated and an agreement be-tween annotators is preferred for categorieswith loose definitions such as ?disease?.Moreover, this would ensure that there wouldbe fewer missed annotations within the corpus.?
The need of annotating all sentences in adocument:The AZDC corpus has disease mention annota-tions of selected sentences in a collection ofPubMed abstracts.
In order to be able to per-form higher level text mining tasks that ex-plore relationships between diseases and othertypes of information such as genes or drugs,the disease name annotation has to include allsentences, as opposed to selected ones.Our work is also related to other corpus annota-tion projects in the biomedical domain (Grouin etal., 2011, Tanabe at al., 2005, Thompson et al,2009, Neveol at al., 2009, Chapman et al, 2012).These studies generally agree on the need of multi-ple experienced annotators for the project, the needof detailed annotation guidelines, and the need oflarge scale high-quality annotation corpora.
Theproduction of such annotated corpora facilitates thedevelopment and evaluation of entity recognitionand information extraction systems.2 MethodsHere we describe the NCBI corpus, and its annota-tion process.
We discuss the annotation guidelinesand how they evolved through the process.2.1 The NCBI disease corpusThe AZDC corpus contains 2,783 sentences cho-sen from 793 PubMed abstracts.
These selectedTable 1 AZDC corpus characteristicsCharacteristics of the corpusSelected abstracts 793Sentences 2,783Sentences with disease mentions 1,757Total disease mentions 3,22492sentences were annotated for disease mentions,resulting in 1,202 unique mentions and 3,224 totalmentions.
The NCBI corpus starts with this origi-nal corpus; however, it is expanded to cover all thesentences in all the 793 PubMed abstracts.2.2 Annotation guidelinesOne fundamental problem in corpus annotation isthe definition of what constitutes an entity to betagged.
Following the lead of the AZDC annota-tions, the group of annotators working on theNCBI corpus decided that a textual string would beannotated as a disease mention if it could bemapped to a unique concept in the UMLS Me-tathesaurus, if it corresponded to at least one of thesemantic types listed in Table 2, and if it containedinformation that would be helpful to physiciansand health care professionals.Annotators were invited to use their commonknowledge, use public resources of the NationalLibrary of Medicine such as UMLS or PubMedHealth, Disease Ontology (Warren et al, 2006) andWikipedia and consider the viewpoint of an aver-age user trying to find information on diseases.Initially, a set of 20 randomly chosen PubMedabstracts was used as a practice set for the devel-opment of annotation guidelines.
After each anno-tator worked individually on the set, the resultswere shared and discussed among all annotators.The final annotation guidelines are summarizedbelow and also made available at the corpus down-load website.What to annotate?1.
Annotate all specific disease mentions.A textual string referring to a disease name mayrefer to a Specific Disease, or a Disease Class.Disease mentions that could be described as afamily of many specific diseases were annotatedwith an annotation category called DiseaseClass.
The annotation category Specific Diseasewas used for those mentions which could belinked to one specific definition that does not in-clude further categorization.e.g.
<Specific Disease> Diastrophic dysplasia</> is an <Disease Class> autosomal recessivedisease</> characterized by short stature, veryshort limbs and joint problems that restrict mo-bility.2.
Annotate contiguous text strings.A textual string may refer to two or more sepa-rate disease mentions.
Such mentions are anno-tated with the Composite Mention category.e.g.
The text phrase ?Duchenne and Beckermuscular dystrophy?
refers to two separate dis-eases.
If this phrase is separated into two strings:?Duchenne?
and ?Becker muscular dystrophy?,it results in information loss, because the word?Duchenne?
on its own is not a disease mention.3.
Annotate disease mentions that are used asmodifiers for other conceptsA textual string may refer to a disease name, butit may not be a noun phrase and this is better ex-pressed with the Modifier annotation category.e.g.
: Although this mutation was initially de-tected in four of 33 <Modifier> colorectal can-cer </> families analysed from eastern England,more extensive analysis has reduced the fre-quency to four of 52 English <Modifier>HNPCC </> kindreds analysed.4.
Annotate duplicate mentions.Table 2 The set of UMLS semantic types that collectively cover concepts of the ?disease?
categoryUMLS sematic types Disease name exampleAcquired Abnormality Hernia, Varicose VeinsAnatomical Abnormality Bernheim aneurysm,  Fistula of thoracic ductCongenital Abnormality Oppenheim's Disease, Ataxia TelangiectasiaCell or Molecular Dysfunction Uniparental disomy, Intestinal metaplasiaDisease or Syndrome   Acute pancreatitis, Rheumatoid ArthritisExperimental Model of Disease Collagen-Induced Arthritis, Jensen SarcomaInjury or Poisoning Contusion and laceration of cerebrumMental or Behavioral Dysfunction Schizophrenia, anxiety disorder, dementiaNeoplastic Process Colorectal Carcinoma, Burkitt LymphomaPathologic Function Myocardial degeneration, Adipose Tissue AtrophySign or Symptom Back Pain, Seizures, Skeletal muscle paralysisFinding Abnormal or prolonged bleeding time93For each sentence in the PubMed abstract and ti-tle, the locations of all disease mentions aremarked, including duplicates within the samesentence.5.
Annotate minimum necessary span of text.The minimum span of text necessary to includeall the tokens expressing the most specific formof the disease is preferred.
For example, in caseof the phrase ?insulin-dependent diabetes melli-tus?, the disease mention including the wholephrase was preferred over its substrings such as?diabetes mellitus?
or ?diabetes?.6.
Annotate all synonymous mentions.Abbreviation definitions such as ?Huntingtondisease?
(?HD?)
are separated into two annotat-ed mentions.What not to annotate?1.
Do not annotate organism names.Organism names such as ?human?
were exclud-ed from the preferred mention.
Viruses, bacteria,and other organism names were not annotatedunless it was clear from the context that the dis-ease caused by these organisms is discussed.e.g.
Studies of biopsied tissue for the presenceof <Specific Disease> Epstein-Barr virus</> and<Specific Disease> cytomegalovirus </> werenegative.2.
Do not annotate gender.Tokens such as ?male?
and ?female?
were onlyincluded if they specifically identified a newform of the disease, for example ?male breastcancer?.3.
Do not annotate overlapping mentions.For example, the phrase ?von Hippel-Lindau(VHL) disease?
was annotated as one single dis-ease mention.4.
Do not annotate general terms.Very general terms such as: disease, syndrome,deficiency, complications, abnormalities, etc.were excluded.
However, the terms cancer andtumor were retained.5.
Do not annotate references to biologicalprocesses.For example, terms corresponding to biologicalprocesses such as ?tumorigenesis?
or ?cancero-genesis?.6.
Do not annotate disease mentions inter-rupted by nested mentions.Basically, do not break the contiguous textrule.
E.g.
WT1 dysfunction is implicated in bothneoplastic (Wilms tumor, mesothelioma, leuke-mia, and breast cancer) and nonneoplastic (glo-merulosclerosis) disease.In this example, the list of all disease mentionsincludes: ?neoplastic disease?
and ?nonneo-plastic disease?
in addition to the underlinedmentions.
However, they were not annotated inour corpus, because other tokens break up thephrase.2.3 Annotators and the annotation processThe annotator group consisted of 12 people withbackground in biomedical informatics research andexperience in biomedical text corpus annotation.The 793 PubMed citations were divided into setsof 25 PubMed citations each.
Every annotatorworked on 5 or 6 sets of 25 PubMed abstracts.
Thesets were divided randomly among annotators.Each set was shared by two people to annotate.
Toavoid annotator bias, pairs of annotators were cho-sen randomly for each set of 25 PubMed abstracts.As illustrated in Figure 1, first, each abstractwas pre-annotated using our in-house-developedCRF disease mention recognizer trained on theAZDC corpus.
This process involved a 10-foldFigure 1.
The annotation process94cross-validation scheme, where all sentences fromthe same PubMed abstract were assigned to thesame split.
The learning was performed on 9-foldsand then, the PubMed abstracts assigned to the10th fold were annotated for disease mentions on asentence-by-sentence basis.Annotation Phase I consisted of each pre-annotated abstract in the corpus being read andreviewed by two annotators working independent-ly.
Annotators could agree with the pre-annotation,remove it, or adjust its text span.
Annotators couldalso add new annotations.
After this initial roundof annotations, a summary document was createdhighlighting the agreement and differences be-tween two annotators in the annotations they pro-duced for each abstract.
This constituted the end ofphase I.
The pair of annotators working on thesame set at this stage was given the summary doc-ument and their own annotations of Phase I.In annotation Phase II, each annotator examinedand edited his or her own annotations by reviewingthe different annotations reported in the Phase Isummary document.
This resulted in a new set ofannotations.
After this round, a second summarydocument highlighting the agreement and differ-ences between two annotators was created for eachpair of annotators to review.After phase II, each pair of annotators organizedmeetings where they reviewed, discussed and re-solved their differences.
After these meetings, areconciled set of annotations was produced foreach PubMed abstract.
The final stage of the anno-tation process consisted of the first author goingover all annotated segments and ensuring that an-notations were consistent both in category and intext span across different abstracts and differentannotation sets.
For example if the phrase ?classi-cal galactosemia?
was annotated in one abstract asa Specific Disease mention, all occurrences of thatphrase throughout the corpus should receive con-sistent annotation.
Identified hard cases were dis-cussed at a meeting where all annotators werepresent and a final decision was made to reconciledifferences.
The final corpus is available at:http://www.ncbi.nlm.nih.gov/CBBresearch/Fellows/Dogan/disease.htmlFigure 2.
NCBI corpus annotation software.
Each annotator selects a PubMed ID from the currentworking set, and is directed to this screen.
Annotation categories are: Specific Disease (highlighted inyellow), Disease Class (green), Composite Mention (blue), or Modifier (purple).
To annotate a diseasemention in text, annotators highlight the phrase and click on the appropriate label on top of the editorscreen.
To delete a disease mention, annotators highlight the phrase and click on the Clear label on topof the editor.
Annotators can retrieve the last saved version of their annotations for each particulardocument by clicking on ?Last Saved?
button.
Annotators save their work by clicking on Submit but-ton at the bottom of editor screen.952.4 Annotation softwareAnnotation was done using a web interface (theprototype of PubTator (Wei et al, 2012)), asshown in Figure 2.
Each annotator was able to loginto the system and work independently.
The sys-tem allowed flexibility to make annotations in thedefined categories, modify annotations, correct thetext span, delete as well as go back and review theprocess as often as needed.
At the end of each an-notation phase, annotators saved their work, andthe annotation results were compared to findagreement and consistency among annotations.2.5 Annotation evaluation metricsWe measured the annotators?
agreement at phase Iand II of the annotation process.
One way to meas-ure the agreement between two annotators is tomeasure their observed agreement on the sample ofannotated items, as specified in Equation (1).Agreement statistics are measured for each an-notator pair, for each shared annotation set.
Then,for each annotator pair the average agreement sta-tistic is computed over all annotation sets sharedbetween the pair of annotators.
The final agree-ment statistic reflects the average and standard de-viation computed over all annotator pairs.
This isrepeated for both phases.Agreement between two annotators is measuredon two levels: one, both annotators tag the sameexact phrase based on character indices as a dis-ease mention, and two, both annotators tag thesame exact phrase based on character indices as adisease mention of the same category.2.6  Application of the NCBI corpusTo compare the two disease corpora with regard totheir intended primary use in training and testingmachine learning algorithms, we performed a 10-fold cross validation experiment with BANNER(Leaman et al 2009).
We evaluated BANNER per-formance and compared Precision, Recall and F-score values for BANNER when trained and testedon AZDC corpus and the NCBI disease name cor-pus, respectively.
In these experiments, diseasementions of all categories were included and arediscussed in the Results section.To compare the effect of improvement in dis-ease name recognition, the different disease cate-gory annotations present in the NCBI corpus wereFigure 3 Inter-annotator annotation consistency measured at the span and span-category levelTable 3 The annotation results and corpus characteristicsCharacteristics of the corpus NCBI corpus AZDCAnnotators 12 1Annotated sentences in citation ALL SelectedPubMed Citations 793 793Sentences 6,651 2,784Sentences with disease annotations 3,752 1,757Total disease mentions 6,900 3,228Specific Disease 3,924 -Disease Class 1029 -Modifier 1,774 -Composite Mention 173 -96Table 4 NCBI corpus as training, development and testing sets for disease name recognitionCorpus Characteristics  Training set Development set Test setPubMed Citations 593 100 100Total disease mentions 5148 791 961Specific Disease 2959 409 556Disease Class 781 127 121Modifier 1292 218 264Composite Mention 116 37 20flattened into only one single category.
This madethe NCBI corpus compatible with the AZDC cor-pus.3 Results and Discussion3.1 Results of Inter-Annotator AgreementFigure 3 shows the inter-annotator agreement re-sults after Phase I and Phase II of the annotations.These statistics show a good agreement betweenannotators, especially after phase II of annotations.In particular, both span-consistency measure andspan-category consistency measure is above 80%after phase II.
These values show that our corpusreflects a high quality of annotations and that ourtwo-stage annotation steps are effective in improv-ing corpus consistency.3.2 Agreement between automatic pre-annotation and final annotation resultsIn our previous work (Neveol et al 2009) we haveshown that automatic pre-annotation is found help-ful by most annotators in assisting large-scale an-notation projects with regard to speeding up theannotation time and improving annotation con-sistency while maintaining the high quality of thefinal annotations.
Thus, we again used pre-annotation in this work.
To demonstrate that hu-man annotators were not biased towards the com-puter-generated pre-annotation, we compared thefinal annotation with the pre-annotation results.There are a total of 3295 pre-annotated diseasementions: 1750 were found also in the final corpuswhile the remaining 1545 were either modified ordeleted.
Furthermore, the final corpus consists ofadditional 3605 new annotations.
Overall, theagreement between pre-annotation and final anno-tation results is only 35%.3.3 Statistics of the NCBI disease corpusAfter two rounds of annotation, several annotatormeetings and resolving of inconsistencies, theNCBI corpus contains 793 fully annotated PubMedcitations for disease mentions which are dividedinto these categories: Specific Disease, DiseaseClass, Composite Mention and Modifier.
As shownin Table 3, the NCBI corpus contains more than6K sentences, of which more than half contain dis-ease mentions.
There are 2,161 unique diseasementions total, which can be divided into thesecategories: 1,349 unique Specific Disease men-tions, 608 unique Disease Class mentions, 121unique Composite Disease mentions, and 356unique Modifier disease mentions.
The NCBI dis-ease name corpus is available for download andcan be used for development of disease namerecognition tools, identification of Composite Dis-ease Mentions, Disease Class or Modifier diseasemention in biomedical text.3.4 Characteristics of the NCBI corpusThis annotation task was initially undertaken forpurposes of creating a larger, broader and morecomplete corpus for disease name recognition inbiomedical literature.The NCBI corpus addresses the inconsistenciesof missed annotations by using a pool of expertsfor annotation and creating the annotation envi-ronment of multiple discussions and multiplerounds of annotation.
The NCBI corpus addressesthe problem of recognition of abbreviated diseasementions by delivering annotations for all sentenc-es in the PubMed abstract.
Processing all sentencesin a document allows for recognition of an abbre-viated form of a disease name.
An abbreviatedterm could be tagged for later occurrences withinthe same document, if an abbreviation definition isrecognized in one of the preceding sentences.NCBI corpus provides a richer level of annota-tions characterized by four different categories ofdisease mentions: Specific Disease, Disease Class,(1)s2Annotation12100  ????
sAn otationAgreementyConsistenc97Composite Mention and Modifier.
Specific Diseasementions could be linked to one specific definitionwithout further categorization, allowing for futurenormalization tasks.
Composite Disease Mentionsidentify intricate lexical strings that express two ormore disease mentions, allowing for future naturallanguage processing tasks to look at them moreclosely.
Modifier disease mentions identify non-noun phrase mentions, again useful for other textmining tasks.Finally, the corpus can be downloaded and usedfor development and testing for disease namerecognition and other tasks.
To facilitate futurework, we have divided the corpus into training,development and testing sets as shown in Table 4.3.5 The NCBI corpus as training data fordisease mention recognitionWe replicated the BANNER experiments by com-paring their cross-validation results on the originalcorpus (AZDC) and on the NCBI corpus.
Our re-sults reveal that BANNER achieves significantlybetter performance on the NCBI corpus: a 10%increase in F-score from 0.764 to 0.840.
Table 5shows detailed results for BANNER processing inprecision, recall and F-score, for both corpora.In addition, we performed BANNER experi-ments on the newly divided NCBI corpus with thefollowing results: BANNER achieves an F-score of0.845 on a 10 fold cross-validation experiment onthe NCBI training set, an F-score of 0.819 whentested on the NCBI development set, after trainedon the NCBI training set, and an F-score of 0.818when tested on NCBI test set, after trained onNCBI training set.3.6 Limitations of this workThe NCBI corpus was annotated manually, thusthe tags assigned were judgment calls by humanannotators.
Annotation guidelines were establishedprior to the annotation process and they were re-fined during the annotation process, however greyareas still remained for which no explicit ruleswere formulated.
In particular, inclusion of qualita-tive terms as part of the disease mention is a matterof further investigation as illustrated by the follow-ing example:?
Acute meningococcal pericarditis ?
Consti-tutes a disease mention and, exists as aseparate concept in UMLS, however?
Acute Neisseria infection ?
May or maynot include the descriptive adjective.Similarly:?
Classical galactosemia ?
Includes the de-scriptive adjective, because it correspondsto a particular form of the disease.?
Inherited spinocerebellar ataxia ?
May ormay not include the descriptive adjective.Names containing conjunctions are difficult totag.
Although it might seem excessive to require anamed entity recognizer to identify the whole ex-pression for cases such as:?
Adenomatous polyps of the colon and rec-tum,?
Fibroepithelial or epithelial hyperplasias,?
Stage II or stage III colorectal cancer,The NCBI disease name corpus rectifies this sit-uation by annotating them as Composite Mentiondisease name category, thus, allowing for futureNLP application to develop more precise methodsin identifying these expressions.Moreover, sentences which contained nesteddisease names require further attention, as the cur-rent annotation rule of annotating only contiguousphrases cannot select the outer mentions.Finally, our current annotation guideline re-quires that only one of the four categories be as-signed to each disease mention.
This is not idealbecause a disease mention may actually fit morethan one category.
For instance, a mention can betagged as both ?Modifier?
and ?Disease Class?.
Inpractice, for obtaining consistent annotations, thepriority was given in the order of ?Modifier?,?Composite Mention?, ?Disease Class?, and ?Spe-cific Disease?
when more than one category deemsappropriate.
This aspect should be addressed atfuture work.4 ConclusionsWe have described the NCBI disease name corpusof tagged disease mentions in 793 PubMed titlesand abstracts.
The corpus was designed to captureTable 5 BANNER evaluation results on AZDC(original) corpus and on the NCBI corpus.CRF-orderCorpus Precision Recall F-score1 AZDC 0.788 0.743 0.7641 NCBI 0.859 0.824 0.8402 AZDC 0.804 0.752 0.7762 NCBI 0.857 0.820 0.83898disease mentions in the most common sense of theword, and is particularly relevant for biomedicalinformation retrieval tasks that involve diseases.Annotations were performed for all sentences in adocument, facilitating the future applications ofcomplex information retrieval tasks connectingdiseases to treatments, causes or other types of in-formation.
Annotation guidelines were designedwith the goal of allowing flexible matching toUMLS concepts, while retaining true meaning ofthe tagged concept.
A more detailed definition onwhat constitutes a disease name, accompanied withadditional annotation rules, could help resolvesome existing inconsistencies.
The current corpusis reviewed several times by several annotators anddescribes a refined scale of annotation categories.It allows the separate definition and annotation ofComposite mentions, Modifiers and distinguishesbetween Disease Class mentions versus SpecificDiseases.
The corpus is available for download1.AcknowledgmentsFunding: This research was supported by the IntramuralResearch Program of the NIH, National Library of Med-icine.We sincerely thank Robert Leaman and Graciela Gon-zalez for their help with BANNER, and the whole teamof 12 annotators for their time and expertise on annota-tion of this corpus.ReferencesAronson, A., Lang, F. 2010.
An overview of MetaMap:historical perspective and recent advances.
J Am MedInform Assoc, 17(3): 229-236.Burgun, A., Bodenreider, O.
2008.
Accessing and inte-grating data and knowledge for biomedical research.Yearb Med Inform, 91-101.Campos, D., Matos, S., Lewin, I., Oliveira, J., Rebholz-Schuhmann, D. 2012.
Harmonisation of gene/proteinannotations: towards a gold standard MEDLINE.
Bi-oinformatics, 1;28(9):1253-61Chapman, W.W., Savova, G.K., Zheng, J., Tharp, M.,Crowley, R. 2012.
Anaphoric reference in clinical re-ports: Characteristics of an annotated corpus.
J Bio-med InformChowdhury, F.M., Lavelli, A.
2010.
Disease mentionrecognition with specific features.
BioNLP, 91-98.Grouin, C., Rosset.
S., Zweigenbaum, P., Fort, K., Gali-bert, O., Quintard, L. 2011.
Proposal for an extension1http://www.ncbi.nlm.nih.gov/CBBresearch/Fellows/Dogan/disease.htmlof traditional named entities: From guidelines toevalua-tion, an overview.
5th law workshop, 92-100.Islamaj Dogan, R., Murray, G. C., Neveol, A., Lu, Z.2009.
Understanding PubMed user search behaviorthrough log analysis.
Database (Oxford): bap018.Jimeno,A., Jimnez-Ruiz, E., Lee, V., Gaudan, S., Ber-langa,R., Reholz-Schuhmann, D.2008.
Assessment ofdisease named entity recognition on a corpus of an-no-tated sentences.
BMC Bioinformatics, 9(S-3).Leaman, R., Miller, C., Gonzalez, G. 2009.
EnablingRecognition of Diseases in Biomedical Text withMa-chine Learning: Corpus and Benchmark.
Sympo-sium on Languages in Biology and Medicine, 82-89.Neveol, A., Li, J., Lu, Z.
2012.
Linking Multiple Dis-ease-related resources through UMLS.
ACM Interna-tional Health Informatics.Neveol, A., Islamaj Dogan, R., Lu, Z.
2011.
Semi-automatic semantic annotation of PubMed Queries: astudy on quality, efficiency, satisfaction.
J BiomedInform, 44(2):310-8.Rinaldi, F., Kaljurand, K., S?tre, R. 2011.
Terminologi-cal resources for text mining over biomedical scien-tific literature.
Artificial intelligence in medicine52(2)Smith L., Tanabe L.K., Ando R.J., Kuo C.J., Chung I.F.,Hsu C.N., Lin Y.S., Klinger R., Friedrich C.M.,Ganchev K., Torii M., Liu H., Haddow B., StrubleC.A., Povinelli R.J., Vlachos A., Baumgartner W.A.Jr., Hunter L., Carpenter B., Tsai R.T., Dai H.J., LiuF., Chen Y., Sun C., Katrenko S., Adriaans P.,Blaschke C., Torres R., Neves M., Nakov P., DivoliA., Ma?a-L?pez M., Mata J., Wilbur W.J.2008.Overview of BioCreative II gene mentionrecognition.
Genome Biology, 9 Suppl 2:S2.Tanabe, L., Xie, N., Thom, L., Matten, W., Wilbur, W.J.2005.
GENETAG: a tagged corpus for gene /proteinnamed entity recognition.
BMC Bioinformatics, 6:S3.Thompson, P., Iqbal, S.A., McNaught, J., Ananiadou, S.2009.
Construction of an annotated corpus to supportbiomedical information extraction.
BMC Bioinfor-matics, 10:349.Warren A., Kibbe J.D.O., Wolf W.A., Smith M.E., Zhu L.,Lin S., Chisholm R., Disease Ontology.
2006Wei C., Kao, H., Lu, Z., 2012.
PubTator: A PubMed-like interactive curation system for document triageand literature Curation.
In proceedings of BioCrea-tive workshop, 145-150.Yeganova, L., Comeau, D.C., Wilbur, W.J.
2011.
Ma-chine learning with naturally labeled data for identi-fying abbreviation definitions.
BMC Bioinformatics.S3:S6Yeh, A., Morgan, A., Colosime, M., Hirschman, L.2005.
BioCreAtIvE Task 1A: gene mention findingevaluation.
BMC Bioinformatics, 6(Suppl 1):S299
