Towards a Bootstrapping Frameworkfor Corpus Semantic TaggingRoberto Basili, Michelangelo Della Rocca, Maria Teresa PazienzaDipartimento di Informatica, Sistemi e Produzione,Universita' di Roma, Tor Vergata (ITALY){bas ili, dellaroc, pazienza}@inf o. ut ovrm.
itAbstractAvailability of source information for se-mantic tagging (or disambignating) wordsin corpora is problematic.
A framework toproduce a semantically tagged corpus in adomain specific perspective using as sourcea general purpose taxonomy (i.e.
Word-Net) is here proposed.
The tag set is de-rived from higher level Wordnet synsets.
Amethodology aiming to support semanticbootstrapping in a NLP application is de-fined.
Results from large scale experimentsare reported 1.1 IntroductionLexical Acquisition (LA) processes strongly rely onbasic assumptions embodied by the source informa-tion and training examples.
Several approaches toLA rely on some forms of declarative descriptions ofsource data: bracketed or POS tagged corpora arejust examples.
Many authors claim that class-basedmethods are more robust against data sparsenessproblems (Dagan,1994), (Pereira, 1993), (Brown etal.,1992).
Other works (Basili et al,1993a, 1996)demonstrated that a variety of lexical acquisitionmethods over small size corpora are viable when-ever a domain specific semantic bias is available:using high level semantic lasses (rather than sim-ple words) increase the robustness of the proba-bility driven methods, usually affected by coverageand data sparseness problems.
Furthermore, domainspecific semantic lasses add expressivity to the un-derlying statistical acquisition model (Basili et al,1996): this saves the knowledge ngineer from hav-ing to deal with mysterious scores with no linguisticflavor.
Semantic data possess an explanatory powerthat is truly required in specific knowledge domains.1 This work has been partially supported by the EspritLRE project n. 2110 - ECRANModeling semantic information is much more cor-pus and domain dependent than POS or syntactictagging.
Bracketed corpora are core components ofan underlying grammatical knowledge to which re-suits of different inductive methods equivalently re-fer.
Such equivalence is no longer valid for seman-tic tagging when corpora (as well as underlying do-mains) change.
In order to design tagging capabili-ties at a semantic level, it is more important to de-sign adaptation capabilities to process a given corpusin a domain driven fashion.
Tagging is a dynamicprocess that aims to produce a core semantic infor-mation to support several induction processes overthe same domain.Availability of source information to support anytagging activity is problematic: general purposesources (e.g.
MRDs  and static Lexical KnowledgeBases) may be too generic and worsen the induc-tion quality, while specific domain sources are usu-ally absent.
Although semantic information is cru-cial to the induction of most lexical knowledge, ac-cessing it is often impossible.
As gold standards arefairly questionable, it is necessary to rely on sourcesthat are as much systematic as possible and adapt-ing their description to the underlying corpus.
Thewidespread diffusion of WordNet, and its large scaleas well, have motivated in several recent studies tostart using it as a common source and adapt it forthe purpose of the target LA task.In this framework, we consider tagging as a pro-cess carried out in two phases: (1) selection of thesemantic tag system specific to the domain (tnningWordnet); (2) use of the specific lassification to tagthe corpus in v/vo.2 Semantically-driven I duction ofLexical InformationSeveral phenomena have been (more or less success-fully) modeled in the LA literature:66?
Acquisition of word taxonomies from a cor-pus by means of syntactic (Hindle,1990)(Pereira et al,1993) as well semantic (Basili etal.,1993a,1996) evidence?
Probability driven PP-disambignation (Hindleand Rooths,1993), (Basili et ai.,1993c), (Brilland Resnik,1994) ,(Resnik,1995), (Frank,1995),(Collins and Brooks,1995).
Some of these meth-ods rely on semantic classes in order to improverobustness.?
Verb Argument Structure derivation.
Many se-lectional constraints in argumental informationhave a semantic nature (e.g.
?
animate), like in(Resnik and BriU,1994) (Resnik,1995) or (Basiliet ai.,1996)Semantic tagging is thus crucial to all the aboveactivities.
We propose the following strategy:1.
Tune a predefined (general) classificatoryframework using as source an untagged corpus2.
Tag the corpus within the defined model even-tually adjusting some of the tuning choices;3.
Use tagged (i.e.
semantically t ped) contexts toderive a variety of lexical information (e.g.
verbargument structures, PP-disambignation rules,ooo)The design of the overall process requires a set ofmodeling principles:1. to focus on the suitable tag system2.
to customize the classification to a corpus3.
to tag the corpus correspondingly.3 Tun ing  a C lass i f icat ion FrAmeworkto  a DomainThe wide-spectrum classification adopted withinWordNet is very useful on a purely linguistic ground,but creates unacceptable noise in NLP applications.In a corpus on Remote Sensing (RSD) 2, for example,we computed an average ambiguity of 4,76 senses(i.e.
Wordnet syasets).
Table 1 counts the WNsynsets of some of the most ambiguous verbs foundin our RSD corpus.Several problems are tackled when a domaindriven approach is used.
First, ambiguity of words2The t11.1ng phase has been evaluated over differentcorpora but results will be discussed over a collection-of publications on Remote Sensing, sized about 350.000words.Table h RSD verbs with the highest initial polysemy\] verb \] WN senses~ive 34run 34break 29cut  25take 23make 21~o 20pass 20set  20draw 19ra ise 18is reduced in a specific domain, and enumeration fall their senses is unnecessary.
Second, some wordsfunction as sense primers for others.
Third, raw con-texts of words provide a significant bundle of infor-mation able to guide disambignation.
Applying se-mantic disambignation as soon as possible is usefulto improve later LA and other linguistic tasks.
Ouraim is thus to provide a systematic bootstrappingframework in order to:?
Assign sense tags to words?
Induce class-based models from the source cor-pus?
Use the class-based modesl (that have a seman-tic nature) within a NLP application.The implemented system, called GODoT (Gen-eral purpose Ontology Disambignation a d Tuning),has two main components: a classifier C-GODoT,that tunes WordNet o a given domain, and WSD-GODoT that locally disambignates and tags thesource corpus contexts.
The Lexical Knowledge base(i.e.
WordNet) and the (POS tagged) source corpusaxe used to select relevant words in each semanticclass.
The resulting classification ismore specific tothe sublanguage as the exhaustive enumeration ofgeneral-purpose word senses has been tackled, andpotential new senses have been introduced.
Thetuned hierarchy is then used to guide the disam-biguation task over local contexts thus producinga final sense tagged corpus from the source data.Class-based models can be derived according to thetags appropriate in the corpus and used to derivelexical information according to generalized colloca-tions.3.1 A semantic tag system for nouns andverbsExperimentally it has been observed that sense def-initions in dictionaries might not capture the do-main specific use of a verb (Basili et al 1995).
Thisstrongly motivated our approach mainly based onthe assumption that the corpus itself, rather thandictionary definitions, could be used to derive disam-biguation hints.
One such approach isundertaken i67(Yarowsky 1992), which inspired our tuning method,although objectives and methods of our classifier (C-GODoT)  are slightly different.First, the aim is to tune an e~isting word hierarchyto an application domain, rather than selecting thebest category for a word occurring in a context.Second, since the training is performed on an unbal-anced corpus (and also for verbs, that notoriouslyexhibit more fuzzy contexts), we introduced localtechniques to reduce spurious contexts and improvereliability.Third, since we expect also domain-specific sensesfor a word, during the classification phase we do notmake any initial hypothesis on the subset of consis-tent categories of a word.Finally, we consider globally all the contexts inwhich a given word is encountered in a corpus, andcompute a (domain-specific) probability distributionover its expected senses (i.e.
hierarchy nodes)A domain specific semantics i obtained throughthe selection of the suitable high level synsets inthe Wordnet hierarchy.
A different methodologicalchoice is required for verbs and nouns.
As, Word-Net hyperonimy hierarchy is rather bushy and dis-omogeneous, we considered inappropriate, asinitialclassification, the WordNet lot~est level synsets.
Amore efficient choice is selecting the topmost synsets,called unique beginners, thus eliminating branches ofthe hierarchy, rather than leaves.
This is reasonablefor nouns, (only 25 unique beginners), but it seemsstill inappropriate for verbs, that have hundreds ofunique beginners (about 208).
We hence decidedto adopt as initial classification for verbs the 15 se-manticaliy distinct categories (verb semantic fields)in WordNet.
The average ambiguity of verbs amongthese categories i 3.5 for our sample in the RSD.
Asimilar value is the ambiguity of nouns in the set oftheir unique beginners.
The first columns in Tables2 and 3 report the semantic lasses for nouns andverbs.3.2 Tuning verbs and noun~Given the above reference tag system, our methodworks as follows:?
Step 1.
Select the most typical words in eachcategory;?
Step 2.
Acquire the collective contexts of thesewords and use them as a (distributional) de-scription of each category;?
Step 3.
Use the distributional descriptions toevaluate the (corpus-dependent) membership ofeach word to the different categories.68Step 1 is carried out detecting the more significant(and less ambiguous) words in any class (semanticfields of verbs and unique beginners for nouns): anyof these sets is called kernel of the correspondingclass.
Rather than training the classifier on all theverbs or noun in the learning corpus, we select onlya subset of prototypical words for each category.
Wecall these words w the salient words of a categoryC.
We define the typicality Tw(C) of w in C, as:Tw(C) = N ,c Nw (1)where:N~ is the total number of synsets of a word w, i.e.
allthe WordNet synonymy sets including w.N.c is the number of synsets of w that belong to the se-mantic ategory C, i.e.
synsets indexed with C in Word-Net.The typicality depends only on WordNet.
A typ-ical verb for a category C is one that is either nonambiguously assigned to C in WordNet, or that hasmost of its senses (syneets) in C.The synonymy Sto of w in C, i.e.
the degree of syn-onymy showed by words other than w in the synsetsof the class C in which w appears, ismodeled by thefollowing ratio:S~(C) = O~,c o,  (2)where:O~ is the number of words in the corpus that appear inat least one of the synsets of w.Ow,c is the number of words in the corpus appearing inat least one of the synsets of w, that belong to C.The synonymy depends both on WordNet and onthe corpus.
A verb with a high degree of synonymyin C is one with a high number of synonyms in thecorpus, with reference to a specific sense (synset)belonging to C. Salient verbs for C are frequent,typical, and with a high synonymy in C. The salientwords to, for a semantic ategory C, are thus identi-fied maximizing the following function, that we callSCOre:Score.
(C) = oa .
x T.(C) x S.(C) (3)where OAw are the absolute occurrences of w inthe corpus.
The value of Score depends both on thecorpus and on WordNet.
OAw depends obviouslyon the corpus.The kernel of a category kernel(C), is the set ofsalient verbs w with a "high" Scorew(C).
In Table2 and 3 the kernel words for both noun and verbclasses are reported.
The typicality of the wordsin the Remote Sensing domain is captured (in thetables some highest relevance words in the classesare reported).
This is exactly what is needed as asemantic domain bias of the later classification pro-cess.Step 2 uses the kernel words to build (as in(Yarowsky,1992)) a probabilistic model of a class:distributions of class relevance of the surroundingterms in typical contexts for each class are built.In Step 3 a words (verb or noun) is assigned toa class according to the contexts in which it ap-pears: collective contexts are used contemporarily,as what matters here is domain specific class mem-bership and not contextual sense disambiguation.Many contexts may cooperate to trigger a given classand several classifications may arise when differentcontexts uggest independent classes.
For a givenverb or noun w, and for each category C, we evaluatethe following function, that we call Domain Sense(DSense(w, C)):1 DSenseCw, C) = -~ ~ Y(k, C) (4)kwhereY(k, c) = c) x Pr(C) (5)w~Ekwhere k's are the contexts of w, and w I is a genericword in k.In (5), Pr(C) is the (not uniform) probability of aclass C, given by the ratio between the number ofcollective contexts for C 3 and the total number ofcollective contexts.The t~ning phase has been evaluated over theRSD corpus, and the resulting average ambiguityof a representative sample of 826 RSD verbs is 2.2,while the corresponding initial WordNet ambiguitywas 3.5.
For the intrinsic difficulty of deciding theproper domain classes for verbs we designed twotests.
In the first ambiguous verbs in WordNet havebeen evaluated: the automatic classification is com-pared with the WordNet initial description.
A recall(shared classes) of 41% denotes a very high com-pression (i.e.
reduction in the number of senses)with a corresponding precision of 82% that indicatea good agreement between WordNet and the systemclassifications: many classes are pruned out (lowerrecall) but most of the remaining ones axe amongthe initial ones.
A second test has been carried outon WordNet unambiguous verbs (e.g.
fie.z, convoy,... ).
For such verbs a recall of 91% is obtained overtheir unique (and confirmed) senses.
These resultsshow that tuning a classification using word contextsSthose collected around the kernel verbs of Cis enough precise to be used in a semantic bootstrap-ping perspective and by its nature it can be used ona large scale.3.3 T~gging verbs and no~_lns in a corpusAfter the tuning phase local tagging is obtained in asimilar fashion: given a context k for a word w andthe set of the proposed classes {C1,C2,...Cn) forw, a tag C E (C1,C2,...Cn} is assigned tow in kitf adherence of k to the probabilistic model of C isover a given threshold and it is maximal.The WSD algorithm (WSD-GODoT) can besketched as follows:I.
Let k be a context of a noun/verb to in thesource corpus and {Ci,C2, ...,C,} be the set of do-main specific classifications of w, as they have beenpre-selected by C-GODoT;2.
For each class Ci, the normalized contextualsense, NCS, is given by:NCS(k, w, Ci) = Y(k, Ci) - Pc, (6)where Y(k, Ci) is defined as in (5), and #c,,ac~ are the mean and standard deviation of theDsense(w, Ci) over the set of kernel words w in Ci.3.
The sense C that to assumes in the context k isexpressed by:Sense(w,k) =Cif\[ NCS(k,w,C)= maxc,(NCS(k,w,C~)); (7)Experimentation has been carried out over set of1,000 disambiguated contexts of about 97 verbs ran-domly extracted fzom RSD.
All these 97 verbs whereambiguous, with an average of 2.3 semantic lassesper verb persisting ambiguity, even after the seman-tic tuning phase.
Recall and Precision have beenmeasured against amanual classification carried outby three human judges (about 70% cases receivedthe same tag by all the judges, this suggesting a cer-tain complexity ot the task).
In 98.74% of cases thetagging system selected one tag.
A recall of 85.97%has been obtained.
Precision is of about 62.19%.Comparing these figures with related works isvery diflqcult, due to the differences in the under-lying semantic type systems and mainly to the va-riety of information used by the different meth-ods.
(McRoy,1992) (and recently (Wilks and Steven-son,1997) described a word sense disambiguationmethods based on multiple models, acting over dif-ferent linguistic levels (e.g.
MRD senses, POS tags,69corpus contexts).
Our methodology is less demand-ing from the point of view of the required source in-formation and possibly should be compared againstone only of the levels mentioned in these works.
(Resnik,1995) reports a human precision of about67% but on a noun disambiguation task carried outat the level of true WordNet ,,tenses (i.e.
synsets):this task seems fairly more complex than ours as weestimated an average of 2.9 synsets per noun on aset of 100 nouns of the RSD.
However one of the re-suits of our method is also to eliminate most of thesesenses from the hierarchy, during the tuning phase,so that precision of the two method cannot be di-rectly compared.
Exhaustive xperimental data onnouns are not yet available.
However the significantresults obtained for verbs are important, as severalauthors (e.g.
(Yarowsky,1992)) report verb as a cat-egory that is more problematic than noun for contextdriven classification tasks.4 D iscuss ionThe relevance of word classes for a variety of lexi-cal acquisition tasks has been described in severalworks.
In (Brown et al,1993) class-based languagemodels for text processing are described.
Classesare derived by pure collocational nalysis of corpora.Approaches of this type aim to improve the statis~tical significance of probability estimations, tacldethe data sparseness problems and reduce the num-ber of the model parameters.
The derived clustersare very interesting but are not amenable for a directlinguistic analysis.
Difficulties in interpreting dataderived from numerical c uster analysis emerge alsoin other studies (e.g.
(Pereira et al,1993)) where ad-ditional work is required to assign asuitable me~nlugto groups of words.
The essential difficulty in sep-arating word senses, when conflating data are de-rived from distinct senses, is due to the fact thatsimple collocations are often the surface results ofindependent linguistic phenomena.
Collocationallyderived lexical constraints (as in the strong tea vs.powerful tea example given in (Smadja,1989)) maybe very different from other types of relations, likeverb-argument relations.
In this case, in fact a sta-tistical significant relationship s not to be detectedbetwen verb and its lexical arguments, but betweenthe verb and a whole class of words that play, in fact,the role of such arguments.
For example, in the RSDcorpus the verb catalogue appears 33 times.
It takesas a direct object the word information only once,that is an evidence too small to support any proba-bilistic induction.
Information indeed is a typicalabstraction that can be catalogued.
There is no hopefor any inductive method making use of simple lex-70ical collocations instead of class based collocations(e.g.
abstraction) to acquire nogh evidence of mostof the phenomena.Class methods based on taxonomic informationmay provide more comprehensive information for alarger number of lexical acquisition tasks.
In PP-disambiguation tasks everal works based on bi-gramstatistics collected over syntactic data (e.g.
Hin-dle and Rooths,1993) show evident limitations incoverage and efficacy to deal with complex forms.In (Franz,1995) weak performances are reported forambiguities with more that two attachment sites.These last are very frequent in a language like Ital-ian where prepositional phrases play a role similarto English compounds.
Class-based approaches (e.g.
(Basili et al,1993) and (Brill and Resnik, 1994) aremore promising: the implied clustering also tack-les the data sparseness difficulties, but mainly theyproduce selectional constraints hat have a direct se-mantic interpretation.
Smaller training data set canbe used and also unknown collocates are deal with,if they are able to trigger the proper semantic gen-eralizations.The method proposed in this paper suggests andprovides evidences that processing a corpus, first,to tune a general purpose taxonomy to the under-lying domain and, then, sense disambiguating wordoccurrences according to the derived semantic las-sification is feasible.
The reference information (i.e.the Wordnet axonomy) isa well-known sharable re-source with an explicit semantics (i.e.
the hyperon-imy/hyponimy hierarchy): this has a beneficial ef-fect on the possibility to extract further lexical phe-nomenon (e.g.
PP disambiguation rules) with a di-rect semantic interpretation.
Let for example:Future Earth observation satellite systems for world-udde high resolution observation purposes require satel-lites in low Earth orbits, supplemented by geostationaryrelay satellites to ensure intermediate data transmissionfrom LEO to ground.be a potential source document, aken form ourRSD domain.
Given a preliminary customization fthe Wordnet hirerachy, according to the set of ker-nel verbs and nouns exemplified in Tables 2 and 3,the described methods allow to apply local semantictaggin to the set of verbs and nouns in the docu-ment.
Some vrbs/nouns are no longer ambiguous inthe domain: their unique tag is retained.
For the re-maining ambiguous words the local disambiguationmodel is applied (by (7).
The tagged version of thesource document results as follows:Future Earth/LO observation/AC satellite/OB sys-tems/CO for worldwide high resolution/AT observa-tion/AC purposes/MT require/CG satstlites/OB in lowEarth/LO orbits/SA, supplemented/CT by geostation-ary relay/OB satellites/OB to ensure/CG interme.diate data/GR transmission/AC from LEO/AR toground/LOC.
4The data now available for any lexical acquisitiontechniques are not only bigrams or trigrams, or syn-tactic collocations (like those derived by a robustparser (as in (Grishman and Sterling,1994) or (Basiliet al 1994)) but also disambignated semantic tagsfor co-occurring words.
For example, for the verbrequire, we extract the following syntactic colloca-tions from the source document:V_N (systems/CO, require/CG)N_V (require/CG, satellites/0B)These data support several inductions.
First, se-mantic tags allow to cluster togheter source syntac-tic collocations according to similar classifications.Other occurrence of the verb require, as they havebeen found in the RSD corpus are:V_N (model/CO, require/CG)N_V (require/CG, satellites/OB)V_N(process/CO, require/CG)N_V(require/CG, sensors/OB)V_N (satellite/0B, require/CG)N_V (requSre/CG, beam-antenna/0B) ...When arguments are assigned with the same tags(e.g.
OB for the direct objets) basic instances can begeneralized into selectional rules: a typical structureinduced from the reported instances i  thus(require(Subj /\[+COor + OB\])(Obj/\[+OBl)) (8)where explicit semantic selectional restrictions(+OB)  for syntactic arguments (e.g.
Obj) are ex-pressed.
A method for deriving a verb subcatego-rization lexicon from a corpus, according to an exam-ple based learning technique applied to robust pars-ing data is described in (Basili et alforthcoming).Availability of explicit semantic tags (like OB) al-lows to derive semantic selectional constraints as in(8).
Further induction would allow to assign the-matic descriptions to arguments in order to extend(8) in:(require( Subj /Theme/\[ +CO\])(Obj/r.nst,'ument/\[+OB\])) (9Previous work on the acquisition of high level se-mantic relations is described in (Basili et al,1993b),where the feasibility of the derivation of lexical se-mantic relations from several corpora and domains4The reported tags are as in Tables 2 and 3.71has been studied.
Interesting results on applicabil-ity of semantic filtering to synt~tic data, for thepurpose of acquiring verb argument information isreported in (Dorr and Jones,1996).
Semantic infor-mation greatly improve the precision of a verb syn-tactic classification.The proposed tag system (e.g.
Wordnet high levelclasses) has several advantages.
First it puts somelimit to enumeration of word senses, thus keepinglimited the search space of any generalization pro-cess.
Learning methods are usually search algo-rithms through concept spaces.
The larger is the setof basic classes, the larger is the size of the searchspace.
It is questionalble how expressive is the re-suiting tag system.
Previous research in ARIOSTO(Basili et al1996a) demonstrated the feasibility ofcomplex corpus driven acquisition based on highlevel semantic classes for a variety of lexical phenom-ena.
A naive semantic type system allows a numberof lexical phenomena to be captured with a minimalhuman intervention.
As an example acquisition ofverb hierarchies according to verb thematic descrip-tion is described in (Basili et al,1996b).
Wheneveran early tuning of the potetial semantic classes of agiven verb in a corpus has been applied and localdisambiguation has been carried out as corpus se-mantic annotation, more precise verb clustering canbe applied:* first, local ambiguities have been removed ur-ing corpus tagging,second, clustering is applied with an intra-classes strategy and not over the whole set ofverbs.
First, a set of thematic verb instancesfrom source sentences are collected for eachgiven semantic class, so that social verbs aretaken separate from change or cognition verbs.Then, separate hirarchies can be generated foreach semantic lass, in order to have a fully do-main driven taxonomic description within gen-eral classes , e.g.
social, for which a generalagreement exists.
Later reasoning processescould thus exploit general primitives augmentedwith domain specific lexico-semantic phenom-ena.5 ConclusionsIn this paper a framework to bootstrapping lexi-cal acqusition in a given domain has been outlined.A source semantic tag system is proposed able toguarantee an explicit semantic description of lexicalphenomena, with a minimal size in order to mini-rnize the complexity of the inductive algorithms.
Amethodology to customize the general purpose tagsystem (i.e.
the high level chases of the Wordnethierarchy) to a domain is described and a seman-tic disambiguation model to semantically tag sourceraw texts is defined.
The result is a semanticallyannotated corpus where lexical phenomena can bestudied with a reduced ambiguity.
Experimental ev-idences for verb and nouns tagging in different do-mains have been outlined and extensive data fromaremote sensing (medium size) corpus have been re-ported.
Implications of the proposed semantic tag-ging for typical exical acquisition tasks (e.g.
deriva-tion of PP-disambiguation rules or verb argumentstructures) have been discussed.
Further research inassessing the semantic tagging evaluation, customiz-ing the lexical acquisition models to the proposed se-mantic type system and evaluating extensively theacquisition results are on going.REFERENCESBasili et al 1993a.
Basili R., M.T.
Pazienza, P.
Velardi.
"What can be learned from raw text?".
Vol.
8:Machine Translation.Basili et al 1993b.
Basili It., M.T.
Pazienza, P. Ve-lardi.
"Acquisition of selectional patterns in sub-languages".
Vol.
8: Machine Translation.Basili et al 1993c.
Basili R., M.T.
Pazienza, P.
Velardi.
"Semi-antomatic Extraction of Linguistic Informa-tion for Syntactic Disambiguation".
Vo1.7:339-364:Applied Artificial Intelligence.Basili et al 1995a.
Basili R., M.T.
Pazienza, P.
Velardi.
"A context driven conceptual c ustering method forverb classification", in Corpus Linguistics for Lexi-cal Acquisition, B. Boguraev & J Pustejovsky Eds.,MIT press, 1996.Basili et al 1995b.
Basili It., M. Della Rocca,M.T.
Pazienza, P. Velardi.
"Contexts and cate-gories: tuning a general purpose verb classificationto sublanguages'.
Proceeding of RANLP95, TzigovChark, Bulgaria, 1995.Basili et al1996a.
Basili R., M.T.
Pazienza, P.
Velardi.
"An Empirical Symbolic Approach to Natural Lan-guage Processing".
To appear in Artificial Intelli-gence, Vol.85, August 1996.Basili et al1996b.
Basili R., M.T.
Pazienza, P.
Velardi.
"A Context Driven Conceptual Clustering Methodfor Verb Classification", in Corpus Proce-~sing forLexical Acquisition, J. Pustejovsky and B. Bogu-raev Eds., MIT Press 1996.Beckwith et al1991.
Beckwith I%., C. Fellbaum, D.Gross, G. Miller.
"WordNet: A Lexical DatabaseOrganized on Psycholingnistic Principles, in LexicalAcquisition: Exploting On-Line Resources to Builda Lexicon".
U. Zernik Ed.
& Lawrenc~ErlbaumAss.72Brill and Kesnik, 1994.
E. Brill, P. Resnik, "A Itule-Based Approach to Prepositional Phrase Attach-ment Disambiguation', in Proc.
of COLING 1994,Kyoto, Japan;Brown et a!.1992.
P.F.
Brown, P. deSouza, R.L.
Mer-cer, V.J.
Della Pietra, J. C. Lai, "Class-Based n-gram Models of Natural Lauguage", in Computa-tional Linguistics, Vol.
18, n. 4, 1992.Collins and Brooks,1995.
Collins M. and Brooks J.,Prepositional Phase Attachment trough a Backed-off Model, 3rd.
Workshop on Very Large Corpora,MT, 1995Dagan et al1994.
Dagau I., Pereira F., LeeL.
"Similarly-based Estimation of Word Co-occurrences Probabilities ".
Proc.
of ACL, LasCruces, New Mexico, USA, 1994.Dorr and Jones,1996.
B.J.
Doff, D. Jones, "Acquisitionof Semantic Lexicons: Using Word Sense Disam-biguation to Improve Precision", in Proc.
of ACLSIGLEX Workshop "Breadth and Depth of Seman-tic Lexicons n, 28 June 1996, University of Califor-nia, Santa Cruz, USA.Pranz,1995.
Franz A., A statistical approach to learningprepositional phrase attachment disambiguation , iProc.
of IJCAI Workshop on New Approaches to Leaming for Natural Language Processing, Montreal1995.Grishman and Sterling,1994.
R. Grishman, J. Sterling,Generalizing Automatically Generated SelectionalPatterns, in Proc.
of COLING 1994, Kyoto, Japan.Hindle and Rooth,1993.
Hindle D. and Rooth M., Struc-tural Ambiguity and Lexical Relations, Computa-tional Linguistics, 19(1): 103-120.McRoy,1992.
McRoy S., "Using Multiple KnowledgeSources for Word Sense Discrimination" Computa-tional Linguistics, vol.
18, n. 1, March 1992, 1-30.Pereira et al 1993.
Pereira F., N. Tishby, L. Lee.
"Dis-tributional Clustering of English Verbs".
Proc.
ofACL, Columbus, Ohio, USA, 1994.Resnik,1995, P. Resnik "Disambiguating oun groupingswith respect o WordNet senses" in Proceeding ofthe ACL Third Workshop on Very Large Corpora,June 30, 1995, MIT, Cambridge, MA.Yarowsky, D. 1992.
"Word-Sense disambiguation usingstatistical models of Roget's categories trained onlarge corpora".
Nantes: Proceedings of COLING92.Table 2: Semantic Classes and (some) kernel elements for RSD verbsI C l~ (Tag)change (CH)cognition (CG).communication (CM)competition (CP)consumption (CS)contact (CT)creation (CR)emotion (EM)motion (MO)perception (PC)possession (PS)social (SO)stative (ST)weather (WE)Kernel verbsacquire, emit, generate, covercalibrate, reduce, increase, measure, coordinateestimate, study, select, compare, plot, identif#record, count, indicate, investigate, determinebase, point, level, protect, encounter, deploysample, provide, supply, base, host, utilizefunction, operate, filter, segment, line, describedesign, plot, create, generate, program, simulatelike, desire, heat, burst, shock, controlwell, flow, track, pulse, assess, rotate,sense, monitor, display, detect, observe, showprovide, account, assess, obtain, contribute, derivee~periment, include, manage, implement, estconsist, correlate, depend, include, involve, e~istscintillate, radiate, flareTable 3: Semantic Classes and (some) kernel elements for RSD nouns\[ Class (Tag) Kernel Nounsact (AC)an~ (AN)art~fact (AR)attribute (AT)body (BO)cognition (CO)communication (CMM)event (EV)feeling (FE)food (FO)group (GR)location (LO)motive (MT)object (OB)person (PE)phenomenon (PH)plant (PL)possession (PO)process (PR)quantity (QU)relation (RE)shape (SH)state (SA)substance (SB)time (TM)experiment, record, calibration, measurement, sensing, services, usewhale, chlorophyll, fur, beluga, goslingtape, spacecraft, radar, file, network, radio, pi=el, filter, camera,density, energy, accuracy, temperature, measurement, magnitude, intensity,limb, water, plasma, region, lineamentparameter, method, coordinate, study, imagery, temperatureinformation, catalog, channels, number, description, summary, signalwaves, spin, earthquake, noise, orbit, result, pulse, rotationshock, gravity, identification, sensitivity, concernice, table, potato, fish, boarddata, field, gala=y, cluster, set, subset, forest, masses, vegetationlongitude, field, range, plot, latitude, profile, zenith, terrain, ionospherepurposeelectron, ion, sea, ocean, cloud, sky, planet, satellite, cometuser, author, experimenter, investigator, computer, researcher, pioneerultraviolet, rainfall, z-ray, energy, result, microwavegalaxy, azis, tree, pollen, composite, cropcoverage, residual, rate, list, resource, fee, record, costprocessing, flow, period, evaporation, cooling, absorption, emissionz, ram, kin, p, reflectance, coe~icent, inchaltitude, mapping, ratio, map, spectrum, average, correlationazimuth, vector, surface, region, zone, angle, starhumidity, moisture, potential, orbit, climate, atmosphere, polarization, dependenceparticle, plasma, ozone, al, proton, ice, helium, gasday, time, hour, khz, year, month, phase, period73
