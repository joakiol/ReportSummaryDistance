Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 162?165,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsLikey: Unsupervised Language-independent Keyphrase ExtractionMari-Sanna Paukkeri and Timo HonkelaAdaptive Informatics Research CentreAalto University School of Science and TechnologyP.O.
Box 15400, FI-00076 AALTO, Finlandmari-sanna.paukkeri@tkk.fiAbstractLikey is an unsupervised statistical ap-proach for keyphrase extraction.
Themethod is language-independent and theonly language-dependent component isthe reference corpus with which the doc-uments to be analyzed are compared.In this study, we have also used an-other language-dependent component: anEnglish-specific Porter stemmer as a pre-processing step.
In our experimentsof keyphrase extraction from scientificarticles, the Likey method outperformsboth supervised and unsupervised baselinemethods.1 IntroductionKeyphrase extraction is a natural language pro-cessing task for collecting the main topics of adocument into a list of phrases.
Keyphrases aresupposed to be available in the processed docu-ments themselves, and the aim is to extract thesemost meaningful words and phrases from the doc-uments.
Keyphrase extraction summarises thecontent of a document as few phrases and thusprovides a quick way to find out what the docu-ment is about.
Keyphrase extraction is a basic textmining procedure that can be used as a groundfor other, more sophisticated text analysis meth-ods.
Automatically extracted keyphrases may beused to improve the performance of informationretrieval, automatic user model generation, docu-ment collection clustering and visualisation, sum-marisation and question-answering, among others.This article describes the participation of theLikey method in the Task 5 of the SemEval 2010challenge, automatic keyphrase extraction fromscientific articles (Kim et al, 2010).1.1 Related workIn statistical keyphrase extraction, many variationsfor term frequency counts have been proposed inthe literature including relative frequencies (Dam-erau, 1993), collection frequency (Hulth, 2003),term frequency?inverse document frequency (tf-idf) (Salton and Buckley, 1988), among others.Additional features to frequency that have beenexperimented are e.g., relative position of the firstoccurrence of the term (Frank et al, 1999), im-portance of the sentence in which the term oc-curs (HaCohen-Kerner, 2003), and widely stud-ied part-of-speech tag patterns, e.g.
Hulth (2003).Matsuo and Ishizuka (2004) present keyword ex-traction method using word co-occurrence statis-tics.
An unsupervised keyphrase extractionmethod by Liu et al (2009) uses clustering to findexemplar terms that are then used for keyphraseextraction.
Most of the presented methods requirea reference corpus or a training corpus to producekeyphrases.
Statistical keyphrase extraction meth-ods without reference corpora have also been pro-posed, e.g.
(Matsuo and Ishizuka, 2004; Bracewellet al, 2005).
The later study is carried out forbilingual corpus.2 DataThe data used in this work are from the SemEval2010 challenge Task 5, automatic keyphrase ex-traction from scientific articles.
The data consistof train, trial, and test data sets.
The number ofscientific articles and the total number of word to-kens in each of the original data sets (before pre-processing) are given in Table 1.Three sets of ?correct?
keyphrases are pro-vided for each article in each data set: reader-assigned keyphrases, author-provided keyphrases,and a combination of them.
All reader-assignedkeyphrases have been extracted manually fromthe papers whereas some of author-provided162Data set Articles Word tokenstrain 144 1 159 015trial 40 334 379test 100 798 049Table 1: Number of scientific articles and totalnumber of word tokens in the data sets.keyphrases may not occur in the content.
Thenumbers of correct keyphrases in each data set areshown in Table 2.Data set Reader Author Combinedtrain 1 824 559 2 223trial 526 149 621test 1 204 387 1 466Table 2: Number of correct answers in reader, au-thor, and combined answer sets for each data set.More detailed information on the data set canbe found in (Kim et al, 2010).3 MethodsLikey keyphrase extraction approach comesfrom the tradition of statistical machine learn-ing (Paukkeri et al, 2008).
The method hasbeen developed to be as language-independent aspossible.
The only language-specific componentneeded is a corpus in each language.
This kindof data is readily available online or from othersources.Likey selects the words and phrases that bestcrystallize the meaning of the documents by com-paring ranks of frequencies in the documents tothose in the reference corpus.
The Likey ra-tio (Paukkeri et al, 2008) for each phrase is de-fined asL(p, d) =rankd(p)rankr(p), (1)where rankd(p) is the rank value of phrase p indocument d and rankr(p) is the rank value ofphrase p in the reference corpus.
The rank val-ues are calculated according to the frequencies ofphrases of the same length n. If the phrase p doesnot exist in the reference corpus, the value of themaximum rank for phrases of length n is used:rankr(p) = max rankr(n) + 1.
The Likey ra-tio orders the phrases in a document in such a waythat the phrases that have the smallest ratio are thebest candidates for being a keyphrase.As a post-processing step, the phrases of lengthn > 1 face an extra removal process: if one ofthe words composing the phrase has a rank of lessthan a threshold ?
in the reference corpus, thephrase is removed from the keyphrase list.
Thisprocedure excludes phrases that contain functionwords such as ?of?
or ?the?.
As another post-processing step, phrases that are subphrases ofthose that have occurred earlier on the keyphraselist are removed, excluding e.g.
?language model?if ?unigram language model?
has been already ac-cepted as a keyphrase.3.1 Reference corpusLikey needs a reference corpus that is seen as asample of the general language.
In the presentstudy, we use a combination of the English part ofEuroparl, European Parliament plenary speeches(Koehn, 2005) and the preprocessed training set asthe reference corpus.
All XML tags of meta infor-mation are excluded from the Europarl data.
Thesize of the Europarl corpus is 35 800 000 wordsafter removal of XML tags.3.2 PreprocessingThe scientific articles are preprocessed by remov-ing all headers including the names and addressesof the authors.
Also the reference section is re-moved from the articles, as well as all tables, fig-ures, equations and citations.
Both scientific arti-cles and the Europarl data is lowercased, punctua-tion is removed (the hyphens surrounded by wordcharacters and apostrophes are kept) and the num-bers are changed to <NUM> tag.The data is stemmed with English Porter stem-mer implementation provided by the challenge or-ganizers, which differs from our earlier experi-ments.3.3 BaselinesWe use three baseline methods for keyphrase ex-traction.
The baselines use uni-, bi-, and trigramsas candidates of keyphrases with tf-idf weight-ing scheme.
One of the baselines is unsuper-vised and the other two are supervised approaches.The unsupervised method is to rank the candidatesaccording to their tf-idf scores.
The supervisedmethods are Na?
?ve Bayes (NB) and Maximum En-tropy (ME) implementations from WEKA pack-age1.1http://www.cs.waikato.ac.nz/?ml/weka/1634 ExperimentsWe participated the challenge with Likey results ofthree different parameter settings.
The settings aregiven in Table 3.
Likey-1 has phrases up to 3 wordsand Likey-2 and Likey-3 up to 4 words.
The thresh-old value for postprocessing was selected againstthe trial set, with ?
= 100 performing best.
Itis used for Likey-1 and Likey-2.
Also a bit largerthreshold ?
= 130 was tried for Likey-3 to excludemore function words.Repr.
n ?Likey-1 1?3 100Likey-2 1?4 100Likey-3 1?4 130Table 3: Different parametrizations for Likey: n-gram length and threshold value ?.An example of the resulting keyphrases ex-tracted by Likey-1 from the first scientific arti-cle in the test set (article C-1) is given in Ta-ble 4.
Also the corresponding ?correct?
answers inreader-assigned and author-provided answer setsare shown.
The keyphrases are given in stemmedversions.
Likey keyphrases that can be found in thereader or author answer sets are emphasized.Likey-1 uddi registri, proxi registri, servicdiscoveri, grid servic discoveri, uddi kei, uniquuddi kei, servic discoveri mechan, distributhash tabl, web servic, dht, servic name, webservic discoveri, local proxi registri, local uddiregistri, queri multipl registriReader grid servic discoveri, uddi, distributweb-servic discoveri architectur, dht base uddiregistri hierarchi, deploy issu, bamboo dhtcode, case-insensit search, queri, longest availprefix, qo-base servic discoveri, autonomcontrol, uddi registri, scalabl issu, soft stateAuthor uddi, dht, web servic, grid comput,md, discoveriTable 4: Extracted keyphrases by Likey-1 from ar-ticle C-1 and the corresponding correct answers inreader and author answer sets.The example shows clearly that many of the ex-tracted keyphrases contain the same words thatcan be found in the correct answer sets but thelength of the phrases vary and thus they cannot becounted as successfully extracted keyphrases.The results for the three different Likeyparametrizations and the three baselines are givenin Table 5 for reader-assigned keyphrases and Ta-ble 6 for the combined set of reader and author-assigned keyphrases.
The evaluation is conductedby calculating precision (P), recall (R) and F-measure (F) for top 5, 10, and 15 keyphrase candi-dates for each method, using the reader-assignedand author-provided lists as correct answers.
Thebaseline methods are unsupervised tf-idf and su-pervised Na?
?ve Bayes (NB) and Maximum Entropy(ME).Likey-1 performed best in the competition andis thus selected as the official result of Likey in thetask.
Anyway, all Likey parametrizations outper-form the baselines, Likey-1 having the best pre-cision 24.60% for top-5 candidates in the readerdata set and 29.20% for top-5 candidates in thecombined data set.
The best F-measure is obtainedwith Likey-1 for top-10 candidates for both readerand combined data set: 16.24% and 17.11%,respectively.
Likey seems to produce the bestkeyphrases in the beginning of the keyphrase list:for reader-assigned keyphrases the top 5 keyphraseprecision for Likey-1 is 6.8 points better thanthe best-performing baseline tf-idf and the cor-responding F-measure is 4.0 points better.
Forthe combined set, the numbers are 7.2 and 3.7points, respectively.
The difference decreases forthe larger keyphrase sets.5 Conclusions and discussionThis article describes our submission to SemEval2010 Task 5, keyphrase extraction from scien-tific articles.
Our unsupervised and language-independent method Likey uses reference corpusand is able to outperform both the unsupervisedand supervised baseline methods.
The best resultsare obtained with the top-5 keyphrases: precisionof 24.60% with reader-assigned keyphrases and29.20% with the combination of reader-assignedand author-provided keyphrases.There are some keyphrases in the answer setsthat our method does not find: due to the com-paratively large threshold value ?
many phrasesthat contain function words, e.g.
?of?, cannot befound.
We also extract keyphrases of maximumlength of three or four words and thus cannot findkeyphrases longer than that.
The next step of thisresearch would be to take these problems into ac-count.164Method Top 5 candidates Top 10 candidates Top 15 candidatesP % R % F % P % R % F % P % R % F %Likey-1 24.60 10.22 14.44 17.90 14.87 16.24 13.80 17.19 15.31Likey-2 23.80 9.88 13.96 16.90 14.04 15.34 13.40 16.69 14.87Likey-3 23.40 9.72 13.73 16.80 13.95 15.24 13.73 17.11 15.23tf-idf 17.80 7.39 10.44 13.90 11.54 12.61 11.60 14.45 12.87NB 16.80 6.98 9.86 13.30 11.05 12.07 11.40 14.20 12.65ME 16.80 6.98 9.86 13.30 11.05 12.07 11.40 14.20 12.65Table 5: Results for Likey and the baselines for the reader data set.
The best precision (P), recall (R) andF-measure (F) are highlighted.Method Top 5 candidates Top 10 candidates Top 15 candidatesP % R % F % P % R % F % P % R % F %Likey-1 29.20 9.96 14.85 21.10 14.39 17.11 16.33 16.71 16.52Likey-2 28.40 9.69 14.45 19.90 13.57 16.14 15.73 16.10 15.91Likey-3 28.00 9.55 14.24 19.60 13.37 15.90 16.07 16.44 16.25tf-idf 22.00 7.50 11.19 17.70 12.07 14.35 14.93 15.28 15.10NB 21.40 7.30 10.89 17.30 11.80 14.03 14.53 14.87 14.70ME 21.40 7.30 10.89 17.30 11.80 14.03 14.53 14.87 14.70Table 6: Results for Likey and the baselines for the combined (reader+author) data set.
The best precision(P), recall (R) and F-measure (F) are highlighted.AcknowledgementsThis work was supported by the Finnish GraduateSchool in Language Studies (Langnet) funded byMinistry of Education of Finland.ReferencesDavid B. Bracewell, Fuji Ren, and Shingo Kuriowa.2005.
Multilingual single document keyword ex-traction for information retrieval.
In Proceedings ofNLP-KE?05.Fred Damerau.
1993.
Generating and evaluatingdomain-oriented multi-word terms from text.
In-formation Processing and Management, 29(4):433?447.Eibe Frank, Gordon W. Paynter, Ian H. Witten, CarlGutwin, and Craig G. Nevill-Manning.
1999.Domain-specific keyphrase extraction.
In Proceed-ings of IJCAI?99, pages 668?673.Yaakov HaCohen-Kerner.
2003.
Automatic extrac-tion of keywords from abstracts.
In V. Palade, R.J.Howlett, and L.C.
Jain, editors, KES 2003, LNAI2773, pages 843?849.
Springer-Verlag.Anette Hulth.
2003.
Improved automatic keyword ex-traction given more linguistic knowledge.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 216?223.Su Nam Kim, Alyona Medelyan, Min-Yen Kan, andTimothy Baldwin.
2010.
SemEval-2010 Task 5:Automatic Keyphrase Extraction from Scientific Ar-ticles.
In Proceedings of the ACL 2010 Workshop onEvaluation Exercises on Semantic Evaluation (Se-mEval 2010).
to appear.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In MT Summit 2005.Zhiyuan Liu, Peng Li, Yabin Zheng, and MaosongSun.
2009.
Clustering to find exemplar terms forkeyphrase extraction.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, pages 257?266, Singapore, Au-gust.
Association for Computational Linguistics.Yutaka Matsuo and Mitsuru Ishizuka.
2004.
Key-word extraction from a single document using wordco-occurrence statistical information.
InternationalJournal on Artificial Intelligence Tools, 13(1):157?169.Mari-Sanna Paukkeri, Ilari T. Nieminen, Matti Po?lla?,and Timo Honkela.
2008.
A language-independentapproach to keyphrase extraction and evaluation.
InColing 2008: Companion volume: Posters, pages83?86, Manchester, UK, August.
Coling 2008 Or-ganizing Committee.Gerard Salton and Chris Buckley.
1988.
Term weight-ing approaches in automatic text retrieval.
Informa-tion Processing and Management, 24(5):513?523.165
