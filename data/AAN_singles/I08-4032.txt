A Chinese Word Segmentation System Based on Cascade ModelZhang JianfengSchool of Computer and InformationTechnology, Shanxi UniversityZhangjianfeng83@163.comZheng JiahengSchool of Computer and InformationTechnology, Shanxi Universityjhzheng@sxu.edu.cnZhang HuSchool of Computer and InformationTechnology, Shanxi Universityzhanghu@sxu.edu.cnTan HongyeSchool of Computer and InformationTechnology, Shanxi UniversityHytan_2006@126.comAbstractThis paper introduces the system of WordSegmentation and analyzes its evaluationresults in the Fourth SIGHAN Bakeoff1 .
Anovel method has been used in the system,which main idea is: firstly, the mainproblems of WS have been classified, andthen a cascaded model has been used togradually optimize the system.
The core ofthis WS system is the segmentation ofambiguous words and the internalinformation extraction of unknown words.The experiments show that the performanceis satisfying, with the RIV-measure 96.8%in NCC open test in the SIGHAN bakeoff2007.1  IntroductionChinese Word Segmentation is a fundamental taskfor some Chinese NLP tasks, such as ma chinetranslation, speech recognition and informationretrieval etc.
However, the current performance ofWS is not satisfying.
In WS the disambiguationprocessing and unknown words recognition are the1 This research was partially supported by the National NaturalScience Foundation of China No.
60473139, the NationalNatural Science Foundation of China No.
60775041and theNatural Science Foundation of Shanxi Province No.
20051034.two difficult problems.
So, we aim at the solutionof the both problem in our WS system.
Weparticipated the SIGHAN bakeoff 2007 evaluation,and a cascade model has been used in the processof word segmentation.
In the WS system, the coremodules are the segmentation of ambiguous wordsand the extraction of internal information ofunknown words.2 System Description IntroductionFigure1 shows the workflow of our WS system.The system is made up of the following modules:small sentences segmentation, disambiguation, andunknown words recognition.Figure 1 Segmentation System based on cascademodel175Sixth SIGHAN Workshop on Chinese Language ProcessingIn fact, ambiguities may appear between twolexical words or between a lexical word and anunknown word.
Based on the observation, thedisambiguation processing is prior to the unknownword recognition in the system.2.1 DisambiguationWe classify the ambiguities into two categories: oneis true-ambiguity, the other is pseudo-ambiguity.And the process of the true-ambiguity is thedisambiguation emphasis.According to the NCC training corpus, we buildpseudo-ambiguity database.
For pseudo-ambiguity,disambiguation can be realized through matchingagainst the database.We get al ambiguities from the training corpus.Pseudo-ambiguity can be solved by finding thedatabase of pseudo-ambiguities which built on thebase of the analyses of NCC corpus.For true-ambiguities, we also build a database anduse a statistical model to disambiguate.Based on the examination of the database ofambiguities, we find that true-ambiguities appear inthe two cases: ( ?1 both frequencies of twosegmentations of ambiguities are low, or the gapbetween the two frequencies is too large; (2) bothfrequencies of two segmentations of ambiguities arehigh.
For the former case, the segmentation formcorresponding to the lower frequency is saved in thedatabase.
For the latter case, both segmentations andtheir context are saved in the database.
And thesystem will choose the appropriate segmentationaccording to the statistic model.The statistic model can be represented as thefollowing formulas:)|(maxarg xypyy=30( | ) ( , ) ( , )iji jp y x bi f x y p x y==?
?,( , )( , )( , )x X y Yfreq x yp x yfreq x y?
?= ?Among the formulas, x is the context, and y isthe segmentation form, fi(x,y) is the featurefunctions, p(x,y) is the empirical probability, and biis the impact factor of the feature function, whosevalue is determined according to the TongyiciCilin 2 .
Here, (x,y) can considers not only the2 HIT IR-Lab Tongyici Cilin (Extended)neighboring words but also the semanticinformation of the neighboring words.The impact factor bi is defined as follows:Let ( ), ( )p pre S t next S?
?
, soWhere pre(S) is the set of the ambiguity S?senvironment which is consist of former word;next(S) is the set of the ambiguity S?s environmentwhich is consist of latter word; p is the formerword of the current ambiguity, n is the latter wordof the current ambiguity.In the model the synonym is defined as:Let s1 and s2 are both words.
If the first threebits of s1?s code in Tongyici Cilin are same withthe first three bits of s2?s code in Tongyici Cilin, s1is the synonym of s2, or s2 is the synonym of s1.2.2 Unknown Words RecognitionIn the process of unknown words recognition, weconsider not only the inner information of unknownwords, but also the environment of unknown words.
(1) Related definition (productivity): Productivityis the weight which measures the single character?slocation in the whole word.If Ai is a single character, ti is the tag of Ai?slocation, let ti {B?
, M, S}, PAi(ti) is the productivityof the single character Ai in the location ti, whichwe can write as follows:( , )( )( , )iii iA ii it Tcount A tP tcount A t?= ?
(2)The inner information of unknown wordsmainly refer to the frequent of each character asword?s begin, middle and end, as show in Table 1.Word Tag FreqA1 B/M/E 447/26/3A2 B/M/E 2/0/0A3 B/M/E 979/76/206???
???
??
?Table1 inner information of unknown words33 A1, A2, A3 represent the single character of Chinese.
B, M,E represent respectively current character as the word?s head,middle and end.176Sixth SIGHAN Workshop on Chinese Language ProcessingIn the process of abstracting the exteriorinformation, we have analyzed the tagged corpusand found that feature words have an importanteffect on the unknown words recognition, such as:predicate, post, specific behavior verb, etc.For example:Post: chairman, prime minister, etc.Job?reporter, singer, writer, etc.Appellation?comrade, sir, miss, etc.Specific behavior verb?
say, think, nominate,investigate, etc.The process of unknown words recognition:?A1 A2 A3A4 A5A6?..?
is the disambiguationresults, if single character of A2 has PA2(B)>0.35and PA2(M) >0.35 or PA2(E) >0.35, A1 A2 have thepossibility to be an unknown words.
After that, wefilter it using the exterior information in order toimprove Roov.3 Performance and analysisThe performance of our system in the SIGHANbakeoff 2007 is presented in table 2.OPEN R P F POOV RIVNCC 94.5 92.6 93.5 71.6 96.9Table 2 NCC test in SIGHAN bakeoff 2007 (%)Our system has better performance in terms ofRiv measure which attributed to the module ofdisambiguation.
However, because the unsuitablethreshold choice leads lots words combinedincorrectly, the Roov measure is lower.4 ConclusionsIn this paper we use a cascade model to finish WStask and the system achieves a good performanceon Riv measure.
It indicates that this method isfeasible and effective.
However, the shortcoming ofthe system is that the method of unknown wordsrecognition hasn?t got ideal performance which willbe our future research focus.ReferencesMaosong Sun, Jiayan Zou, etc.
1999 .The Role of HighFrequent Maximal Crossing Ambiguities in ChineseWord Segmentation.
Journal of Chinese ofInformation Processing, 13(1):27-37Kaiying Liu.
2000.
Automatic Chinese WordSegmentation and POS Tagging.
Business PublishingHouse.
Beijing.Luo Zhiyong, Song Rou.
2006.
Disambiguation in aModern Chinese General-Purpose WordSegmentation System.
Journal of Computer Researchand Development, 6:1122-1128.Huang Changning, Zhao Hai.
2006.
Character-BasedTagging: A New Method for Chinese WordSegmentation.
Frontiers of Chinese InformationProcessing: 53-63.Linxin, NetEase.
2006.
Automatic Chinese WordSegmentation.
Proceedings of the Fifth SIGHANWorkshop on Chinese Language Processing, Sydney:193?196.Wu Liu, Heng Li.
2006.
France Telecom R&D BeijingWord Segmenter for Sighan Bakeoff2006.Proceedings of the Fifth SIGHAN Workshop onChinese Language Processing, Sydney: 193?196.177Sixth SIGHAN Workshop on Chinese Language Processing
