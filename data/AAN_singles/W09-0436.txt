Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 215?223,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsDisambiguating ?DE?
for Chinese-English Machine TranslationPi-Chuan Chang, Dan Jurafsky, and Christopher D. ManningComputer Science Department, Stanford UniversityStanford, CA 94305pichuan,jurafsky,manning@stanford.eduAbstractLinking constructions involving { (DE) are ubiq-uitous in Chinese, and can be translated into En-glish in many different ways.
This is a major sourceof machine translation error, even when syntax-sensitive translation models are used.
This paperexplores how getting more information about thesyntactic, semantic, and discourse context of usesof { (DE) can facilitate producing an appropriateEnglish translation strategy.
We describe a finer-grained classification of { (DE) constructions inChinese NPs, construct a corpus of annotated ex-amples, and then train a log-linear classifier, whichcontains linguistically inspired features.
We use theDE classifier to preprocess MT data by explicitlylabeling { (DE) constructions, as well as reorder-ing phrases, and show that our approach providessignificant BLEU point gains on MT02 (+1.24),MT03 (+0.88) and MT05 (+1.49) on a phrased-based system.
The improvement persists when a hi-erarchical reordering model is applied.1 IntroductionMachine translation (MT) from Chinese to En-glish has been a difficult problem: structural dif-ferences between Chinese and English, such asthe different orderings of head nouns and rela-tive clauses, cause BLEU scores to be consis-tently lower than for other difficult language pairslike Arabic-English.
Many of these structuraldifferences are related to the ubiquitous Chinese{(DE) construction, used for a wide range ofnoun modification constructions (both single wordand clausal) and other uses.
Part of the solutionto dealing with these ordering issues is hierarchi-cal decoding, such as the Hiero system (Chiang,2005), a method motivated by {(DE) exampleslike the one in Figure 1.
In this case, the transla-tion goal is to rotate the noun head and the preced-ing relative clause around{(DE), so that we cantranslate to ?
[one of few countries]{ [have diplo-matic relations with North Korea]?.
Hiero canlearn this kind of lexicalized synchronous gram-mar rule.But use of hierarchical decoders has not solvedthe DE construction translation problem.
We ana-lyzed the errors of three state-of-the-art systems(the 3 DARPA GALE phase 2 teams?
systems),and even though all three use some kind of hier-archical system, we found many remaining errorsrelated to reordering.
One is shown here:h?
?
?X { ?
?local a bad reputation DE middle schoolReference: ?a local middle school with a bad reputation?Team 1: ?a bad reputation of the local secondary school?Team 2: ?the local a bad reputation secondary school?Team 3: ?a local stigma secondary schools?None of the teams reordered ?bad reputation?and ?middle school?
around the{.
We argue thatthis is because it is not sufficient to have a for-malism which supports phrasal reordering, but itis also necessary to have sufficient linguistic mod-eling that the system knows when and how muchto rearrange.An alternative way of dealing with structuraldifferences is to reorder source language sentencesto minimize structural divergence with the targetlanguage, (Xia and McCord, 2004; Collins et al,2005; Wang et al, 2007).
For example Wang etal.
(2007) introduced a set of rules to decide ifa{(DE) construction should be reordered or notbefore translating to English:?
For DNPs (consisting of?XP+DEG?):?
Reorder if XP is PP or LCP;?
Reorder if XP is a non-pronominal NP?
For CPs (typically formed by ?IP+DEC?):?
Reorder to align with the ?that+clause?structure of English.Although this and previous reordering work hasled to significant improvements, errors still re-main.
Indeed, Wang et al (2007) found that theprecision of their NP rules is only about 54.6% ona small human-judged set.One possible reason the{(DE) construction re-mains unsolved is that previous work has paid in-sufficient attention to the many ways the {(DE)construction can be translated and the rich struc-tural cues to the translation.
Wang et al (2007),for example, characterized {(DE) into only two215??
4 ?
?8 ?
?b { ?j ) ? Aozhou shi yu Beihan you bangjiao DE shaoshu guojia zhiyi .Australia is with North Korea have diplomatic relations that few countries one of .Australia is one of the few countries that have diplomatic relations with North Korea.Figure 1: An example of the DE construction from (Chiang, 2005)classes.
But our investigation shows that there aremany strategies for translating Chinese [A { B]phrases into English, including the patterns in Ta-ble 1, only some involving reversal.Notice that the presence of reordering is onlyone part of the rich structure of these examples.Some reorderings are relative clauses, while othersinvolve prepositional phrases, but not all preposi-tional phrase uses involve reorderings.
These ex-amples suggest that capturing finer-grained trans-lation patterns could help achieve higher accuracyboth in reordering and in lexical choice.In this work, we propose to use a statistical clas-sifier trained on various features to predict for agiven Chinese {(DE) construction both whetherit will reorder in English and which constructionit will translate to in English.
We suggest that thenecessary classificatory features can be extractedfrom Chinese, rather than English.
The {(DE)in Chinese has a unified meaning of ?noun mod-ification?, and the choice of reordering and con-struction realization are mainly a consequence offacts of English noun modification.
Nevertheless,most of the features that determine the choice ofa felicitous translation are available in the Chi-nese source.
Noun modification realization hasbeen widely studied in English (e.g., (Rosenbach,2003)), and many of the important determinativeproperties (e.g., topicality, animacy, prototypical-ity) can be detected working in the source lan-guage.We first present some corpus analysis charac-terizing different DE constructions based on howthey get translated into English (Section 2).
Wethen train a classifier to label DEs into the 5 dif-ferent categories that we define (Section 3).
Thefine-grained DEs, together with reordering, arethen used as input to a statistical MT system (Sec-tion 4).
We find that classifying DEs into finer-grained tokens helps MT performance, usually atleast twice as much as just doing phrasal reorder-ing.2 DE classificationThe Chinese character DE serves many differentpurposes.
According to the Chinese Treebank tag-ging guidelines (Xia, 2000), the character can betagged as DEC, DEG, DEV, SP, DER, or AS.
Sim-ilar to (Wang et al, 2007), we only consider themajority case when the phrase with {(DE) is anoun phrase modifier.
The DEs in NPs have apart-of-speech tag of DEC (a complementizer ora nominalizer) or DEG (a genitive marker or anassociative marker).2.1 Class DefinitionThe way we categorize the DEs is based on theirbehavior when translated into English.
This is im-plicitly done in the work of Wang et al (2007)where they use rules to decide if a certain DE andthe words next to it will need to be reordered.
Inthis work, we categorize DEs into finer-grainedcategories.
For a Chinese noun phrase [A { B],we categorize it into one of these five classes:1.
A BIn this category, A in the Chinese side is trans-lated as a pre-modifier of B.
In most of thecases A is an adjective form, like Example 1.1in Table 1 or the possessive adjective exam-ple in Example 1.2.
Compound nouns whereA becomes a pre-modifier of B also fit in thiscategory (Example 1.3).2.
B preposition AThere are several cases that get translated intothe form B preposition A.
For example, the of-genitive in Example 2.1 in Table 1.Example 2.2 shows cases where the ChineseA gets translated into a prepositional phrasethat expresses location.When A becomes a gerund phrase and an ob-ject of a preposition, it is also categorized inthe B preposition A category (Example 2.3).3.
A ?s BIn this class, the English translation is an ex-plicit s-genitive case, as in Example 3.1.
Thisclass occurs much less often but is still in-teresting because of the difference from theof-genitive.4.
relative clauseWe include the obvious relative clause caseslike Example 4.1 where a relative clause is216introduced by a relative pronoun.
We also in-clude reduced relative clauses like Example4.2 in this class.5.
A preposition BThis class is another small one.
The Englishtranslations that fall into this class usuallyhave some number, percentage or level wordin the Chinese A.Some NPs are translated into a hybrid of these cat-egories, or just don?t fit into one of the five cate-gories, for instance, involving an adjectival pre-modifier and a relative clause.
In those cases, theyare put into an ?other?
category.12.2 Data annotation of DE classesIn order to train a classifier and test its per-formance, we use the Chinese Treebank 6.0(LDC2007T36) and the English Chinese Trans-lation Treebank 1.0 (LDC2007T02).
The wordalignment data (LDC2006E93) is also used toalign the English and Chinese words betweenLDC2007T36 and LDC2007T02.
The overlap-ping part of the three datasets are a subset of CTB6files 1 to 325.
After preprocessing those threesets of data, we have 3253 pairs of Chinese sen-tences and their translations.
In those sentences,we use the gold-standard Chinese tree structure toget 3412 Chinese DEs in noun phrases that wewant to annotate.
Among the 3412 DEs, 530 ofthem are in the ?other?
category and are not usedin the classifier training and evaluation.
The statis-tics of the five classes are:1.
A B: 693 (24.05%)2.
B preposition A: 1381 (47.92%)3.
A ?s B: 91 (3.16%)4. relative clause: 669 (23.21%)5.
A preposition B: 48 (1.66%)3 Log-linear DE classifierIn order to see how well we can categorize DEs innoun phrases into one of the five classes, we train alog-linear classifier to classify each DE accordingto features extracted from its surrounding context.Since we want the training and testing conditionsto match, when we extract features for the classi-fier, we don?t use gold-standard parses.
Instead,we use a parser trained on CTB6 excluding files1-325.
We then use this parser to parse the 32531The ?other?
category contains many mixed cases thatcould be difficult Chinese patterns to translate.
We will leavethis for future work.5-class Acc.
(%) 2-class Acc.
(%)baseline - 76.0DEPOS 54.8 71.0+A-pattern 67.9 83.7+POS-ngram 72.1 84.9+Lexical 74.9 86.5+SemClass 75.1 86.7+Topicality 75.4 86.9Table 2: 5-class and 2-class classification accuracy.
?base-line?
is the heuristic rules in (Wang et al, 2007).
Others arevarious features added to the log-linear classifier.Chinese sentences with the DE annotation and ex-tract parse-related features from there.3.1 Experimental settingFor the classification experiment, we exclude the?other?
class and only use the 2882 examples thatfall into the five pre-defined classes.
To evalu-ate the classification performance and understandwhat features are useful, we compute the accuracyby averaging five 10-fold cross-validations.2As a baseline, we use the rules introduced inWang et al (2007) to decide if the DEs require re-ordering or not.
However, since their rules onlydecide if there is reordering in an NP with DE,their classification result only has two classes.
So,in order to compare our classifier?s performancewith the rules in Wang et al (2007), we have tomap our five-class results into two classes.
Wemapped our five-class results into two classes.
Sowe mapped B preposition A and relative clauseinto the class ?reordered?, and the other threeclasses into ?not-reordered?.3.2 Feature EngineeringTo understand which features are useful for DEclassification, we list our feature engineering stepsand results in Table 2.
In Table 2, the 5-class ac-curacy is defined by:(number of correctly labeled DEs)(number of all DEs)?100The 2-class accuracy is defined similarly, but itis evaluated on the 2-class ?reordered?
and ?not-reordered?
after mapping from the 5 classes.The DEs we are classifying are within an NP;we refer to them as [A { B]NP.
A includes allthe words in the NP before{; B includes all thewords in the NP after{.
To illustrate, we will usethe following NP:[[8)!L]A{ [=?
?6)]B]NP2We evaluate the classifier performance using cross-validations to get the best setting for the classifier.
The proofof efficacy of the DE classifier is MT performance on inde-pendent data in Section 4.2171.
A B1.1.
??(excellent)/{(DE)/??
(geographical)/G(qualification)?
?excellent geographical qualifications?1.2.
??(our)/{(DE)/??(financial)/Z(risks)?
?our financial risks?1.3.
?4(trade)/{(DE)/?Vu(complement)?
?trade complement?2.
B preposition A2.1.
=?(investment)/??(environment)/{(DE)/??(improvement)?
?the improvement of the investment environment?2.2.
?
?(Chongming county)/(inside)/{(DE)/\?(organization)?
?organizations inside Chongming county?2.3.
(one)/?
(measure word)/?(observe)/?)(China)/=?
(market)/{(DE)/BB(small)/	=(window)?
?a small window for watching over Chinese markets?3.
A ?s B3.1.
)(nation)/{(DE)/w(macro)/?(management)?
?the nation ?s macro management?4.
relative clause4.1.
?
)(China)/X(cannot)/	?(produce)/(and)/?(but)/i(very)/?(need)/{(DE)/?(medicine)?
?medicine that cannot be produced by China but is urgently needed?4.2.
i?
(foreign business)/=?(invest)/?(enterprise)/?z(acquire)/{(DE)/|?(RMB)/TQ(loan)?
?the loans in RMB acquired by foreign-invested enterprises?5.
A preposition B5.1.
??
?y(more than 40 million)/??
(US dollar)/{(DE)/??(product)?
more than 40 million US dollars in productsTable 1: Examples for the 5 DE classesto show examples of each feature.
The parse struc-ture of the NP is listed in Figure 2.
(NP(NP (NR 8)))(CP(IP(VP(ADVP (AD !
))(VP (VA L))))(DEC {))(NP (NN =?)
(NN ?6)))))))Figure 2: The parse tree of the Chinese NP.DEPOS: part-of-speech tag of DESince the part-of-speech tag of DE indicates itssyntactic function, it is the first obvious featureto add.
The NP in Figure 2 will have the fea-ture ?DEC?.
This basic feature will be referred toas DEPOS.
Note that since we are only classifyingDEs in NPs, ideally the part-of-speech tag of DEwill either be DEC or DEG as described in Section2.
However, since we are using automatic parsesinstead of gold-standard ones, the DEPOS featuremight have other values than just DEC and DEG.From Table 2, we can see that with this simple fea-ture, the 5-class accuracy is low but at least betterthan simply guessing the majority class (47.92%).The 2-class accuracy is still lower than using theheuristic rules in (Wang et al, 2007), which is rea-sonable because their rules encode more informa-tion than just the POS tags of DEs.A-pattern: Chinese syntactic patternsappearing before{Secondly, we want to incorporate the rules in(Wang et al, 2007) as features in the log-linearclassifier.
We added features for certain indicativepatterns in the parse tree (listed in Table 3).1.
A is ADJP:true if A+DE is a DNP which is in the form of ?ADJP+DEG?.2.
A is QP:true if A+DE is a DNP which is in the form of ?QP+DEG?.3.
A is pronoun:true if A+DE is a DNP which is in the form of ?NP+DEG?, andthe NP is a pronoun.4.
A ends with VA:true if A+DE is a CP which is in the form of ?IP+DEC?, andthe IP ends with a VP that?s either just a VA or a VP precededby a ADVP.Table 3: A-pattern featuresFeatures 1?3 are inspired by the rules in (Wanget al, 2007), and the fourth rule is based on theobservation that even though the predicative ad-jective VA acts as a verb, it actually corresponds toadjectives in English as described in (Xia, 2000).3We call these four features A-pattern.
Our exam-ple NP in Figure 2 will have the fourth feature?A ends with VA?
in Table 3, but not the otherthree features.
In Table 2 we can see that afteradding A-pattern, the 2-class accuracy is alreadymuch higher than the baseline.
We attribute thisto the fourth rule and also to the fact that the clas-sifier can learn weights for each feature.43Quote from (Xia, 2000): ?VA roughly corresponds to ad-jectives in English and stative verbs in the literature on Chi-nese grammar.
?4We also tried extending a rule-based 2-class classifierwith the fourth rule.
The accuracy is 83.48%, only slightlylower than using the same features in a log-linear classifier.218POS-ngram: unigrams and bigrams of POS tagsThe POS-ngram feature adds all unigrams and bi-grams in A and B.
Since A and B have differentinfluences on the choice of DE class, we distin-guish their ngrams into two sets of features.
Wealso include the bigram pair across DE which getsanother feature name for itself.
The example NPin Figure 2 will have these features (we use b toindicate boundaries):?
POS unigrams in A: ?NR?, ?AD?, ?VA??
POS bigrams in A: ?b-NR?, ?NR-AD?, ?AD-VA?, ?VA-b??
cross-DE POS bigram: ?VA-NN??
POS unigram in B: ?NN??
POS bigrams in B: ?b-NN?, ?NN-NN?, ?NN-b?The part-of-speech ngram features add 4.24%accuracy to the 5-class classifier.Lexical: lexical featuresIn addition to part-of-speech features, we alsotried to use features from the words themselves.But since using full word identity resulted in asparsity issue,5 we take the one-character suffix ofeach word and extract suffix unigram and bigramfeatures from them.
The argument for using suf-fixes is that it often captures the larger category ofthe word (Tseng et al, 2005).
For example, ?)
(China) and8) (Korea) share the same suffix), which means ?country?.
These suffix ngramfeatures will result in these features for the NP inFigure 2:?
suffix unigrams: ?
)?, ?!
?, ?L?, ?{?,??
?, ?)??
suffix bigrams: ?b-)?, ?)-!
?, ?
!-L?,?L-{?, ?{-?
?, ?
?-)?, ?
)-b?Other than the suffix ngram, we also add threeother lexical features: first, if the word before DEis a noun, we add a feature that is the conjunc-tion of POS and suffix unigram.
Secondly, an?NR only?
feature will fire when A only consists ofone or more NRs.
Thirdly, we normalize differentforms of ?percentage?
representation, and add afeature if they exist.
This includes words that startwith ??I??
or ends with the percentage sign?%?.
The first two features are inspired by the factthat a noun and its type can help decide ?B prep A?versus ?A B?.
Here we use the suffix of the noun5The accuracy is worse when we tried using the wordidentity instead of the suffix.and the NR (proper noun) tag to help capture itsanimacy, which is useful in choosing between thes-genitive (the boy?s mother) and the of-genitive(the mother of the boy) in English (Rosenbach,2003).
The third feature is added because many ofthe cases in the ?A preposition B?
class have a per-centage number in A.
We call these sets of featuresLexical.
Together they provide 2.73% accuracy im-provement over the previous setting.SemClass: semantic class of wordsWe also use a Chinese thesaurus, CiLin, to look upthe semantic classes of the words in [A { B] anduse them as features.
CiLin is a Chinese thesauruspublished in 1984 (Mei et al, 1984).
CiLin is or-ganized in a conceptual hierarchy with five levels.We use the level-1 tags which includes 12 cate-gories.6 This feature fires when a word we look uphas one level-1 tag in CiLin.
This kind of featureis referred to as SemClass in Table 2.
For the ex-ample in Figure 2, two words have a single level-1 tag: ?!?
(most) has a level-1 tag K7 and ?=??
(investment) has a level-1 tag H8.
?8)?
and??6)?
are not listed in CiLin, and ?L?
hasmultiple entries.
Therefore, the SemClass featuresare: (i) before DE: ?K?
; (ii) after DE: ?H?Topicality: re-occurrence of nounsThe last feature we add is a Topicality feature,which is also useful for disambiguating s-genitiveand of-genitive.
We approximate the feature bycaching the nouns in the previous two sentences,and fire a topicality feature when the noun appearsin the cache.
Take this NP in MT06 as an example:?8??8{??S,?
?For this NP, all words before DE and after DEappeared in the previous sentence.
Therefore thetopicality features ?cache-before-DE?
and ?cache-after-DE?
both fire.After all the feature engineering above, thebest accuracy on the 5-class classifier we haveis 75.4%, which maps into a 2-class accuracy of86.9%.
Comparing the 2-class accuracy to the(Wang et al, 2007) baseline, we have a 10.9%absolute improvement.
The 5-class accuracy andconfusion matrix is listed in Table 4.?A preposition B?
is a small category and is themost confusing.
?A ?s B?
also has lower accuracy,and is mostly confused with ?B preposition A?.6We also tried adding more levels but it did not help.7K is the category??
(auxiliary) in CiLin.8H is the category??
(activities) in CiLin.219real?
A ?s B AB A prep.
B B prep.
A rel.
clauseA ?s B 168 36 0 110 0AB 48 2473 73 227 216A prep.
B 0 18 46 23 11B prep.
A 239 691 95 5915 852rel.
clause 0 247 26 630 2266Total 455 3465 240 6905 3345Accuracy(%) 36.92 71.37 19.17 85.66 67.74Table 4: The confusion matrix for 5-class DE classificationThis could be due to the fact that there are somecases where the translation is correct both ways,but also could be because the features we addedhave not captured the difference well enough.4 Machine Translation Experiments4.1 Experimental SettingFor our MT experiments, we used a re-implementation of Moses (Koehn et al, 2003), astate-of-the-art phrase-based system.
The align-ment is done by the Berkeley word aligner (Lianget al, 2006) and then we symmetrized the wordalignment using the grow-diag heuristic.
For fea-tures, we incorporate Moses?
standard eight fea-tures as well as the lexicalized reordering model.Parameter tuning is done with Minimum ErrorRate Training (MERT) (Och, 2003).
The tun-ing set for MERT is the NIST MT06 data set,which includes 1664 sentences.
We evaluate theresult with MT02 (878 sentences), MT03 (919sentences), and MT05 (1082 sentences).Our MT training corpus contains 1,560,071 sen-tence pairs from various parallel corpora fromLDC.9 There are 12,259,997 words on the Englishside.
Chinese word segmentation is done by theStanford Chinese segmenter (Chang et al, 2008).After segmentation, there are 11,061,792 wordson the Chinese side.
We use a 5-gram languagemodel trained on the Xinhua and AFP sections ofthe Gigaword corpus (LDC2007T40) and also theEnglish side of all the LDC parallel data permissi-ble under the NIST08 rules.
Documents of Giga-word released during the epochs of MT02, MT03,MT05, and MT06 were removed.To run the DE classifier, we also need to parsethe Chinese texts.
We use the Stanford Chineseparser (Levy and Manning, 2003) to parse the Chi-nese side of the MT training data and the tuningand test sets.9LDC2003E07, LDC2003E14, LDC2005E83,LDC2005T06, LDC2006E26, LDC2006E85, LDC2006E85,LDC2005T34, and LDC2005T344.2 Baseline ExperimentsWe have two different settings as baseline exper-iments.
The first is without reordering or DE an-notation on the Chinese side; we simply align theparallel texts, extract phrases and tune parameters.This experiment is referred to as BASELINE.
Also,we reorder the training data, the tuning and thetest sets with the NP rules in (Wang et al, 2007)and compare our results with this second baseline(WANG-NP).The NP reordering preprocessing (WANG-NP)showed consistent improvement in Table 5 on alltest sets, with BLEU point gains ranging from0.15 to 0.40.
This confirms that having reorder-ing around DEs in NP helps Chinese-English MT.4.3 Experiments with 5-class DE annotationWe use the best setting of the DE classifier de-scribed in Section 3 to annotate DEs in NPs in theMT training data as well as the NIST tuning andtest sets.10 If a DE is in an NP, we use the annota-tion of{AB,{AsB,{BprepA,{relc, or{AprepBto replace the original DE character.
Once we havethe DEs labeled, we preprocess the Chinese sen-tences by reordering them.11 Note that not all DEsin the Chinese data are in NPs, therefore not allDEs are annotated with the extra labels.
Table6 lists the statistics of the DE classes in the MTtraining data.class of{(DE) counts percentage{AB 112,099 23.55%{AprepB 2,426 0.51%{AsB 3,430 0.72%{BprepA 248,862 52.28%{relc 95,134 19.99%{ (unlabeled) 14,056 2.95%total number of{ 476,007 100%Table 6: The number of different DE classes labeled for theMT training data.After this preprocessing, we restart the wholeMT pipeline ?
align the preprocessed data, extractphrases, run MERT and evaluate.
This setting isreferred to as DE-Annotated in Table 5.4.4 Hierarchical Phrase Reordering ModelTo demonstrate that the technique presented hereis effective even with a hierarchical decoder, we10The DE classifier used to annotate the MT experimentwas trained on all the available data described in Section 2.2.11Reordering is applied on DNP and CP for reasons de-scribed in Wang et al (2007).
We reorder only when the{is labeled as{BprepA or{relc.220BLEUMT06(tune) MT02 MT03 MT05BASELINE 32.39 32.51 32.75 31.42WANG-NP 32.75(+0.36) 32.66(+0.15) 33.15(+0.40) 31.68(+0.26)DE-Annotated 33.39(+1.00) 33.75(+1.24) 33.63(+0.88) 32.91(+1.49)BASELINE+Hier 32.96 33.10 32.93 32.23DE-Annotated+Hier 33.96(+1.00) 34.33(+1.23) 33.88(+0.95) 33.01(+0.77)Translation Error Rate (TER)MT06(tune) MT02 MT03 MT05BASELINE 61.10 63.11 62.09 64.06WANG-NP 59.78(?1.32) 62.58(?0.53) 61.36(?0.73) 62.35(?1.71)DE-Annotated 58.21(?2.89) 61.17(?1.94) 60.27(?1.82) 60.78(?3.28)Table 5: MT experiments of different settings on various NIST MT evaluation datasets.
We used both the BLEU and TERmetrics for evaluation.
All differences between DE-Annotated and BASELINE are significant at the level of 0.05 with theapproximate randomization test in (Riezler and Maxwell, 2005)conduct additional experiments with a hierarchi-cal phrase reordering model introduced by Galleyand Manning (2008).
The hierarchical phrase re-ordering model can handle the key examples of-ten used to motivated syntax-based systems; there-fore we think it is valuable to see if the DE an-notation can still improve on top of that.
In Ta-ble 5, BASELINE+Hier gives consistent BLEU im-provement over BASELINE.
Using DE annotationon top of the hierarchical phrase reordering mod-els (DE-Annotated+Hier) provides extra gain overBASELINE+Hier.
This shows the DE annotation canhelp a hierarchical system.
We think similar im-provements are likely to occur with other hierar-chical systems.5 Analysis5.1 Statistics on the Preprocessed DataSince our approach DE-Annotated and one of thebaselines (WANG-NP) are both preprocessing Chi-nese sentences, knowing what percentage of thesentences are altered will be one useful indicatorof how different the systems are from the baseline.In our test sets, MT02 has 591 out of 878 sentences(67.3%) that have DEs under NPs; for MT03 it is619 out of 919 sentences (67.4%); for MT05 it is746 out of 1082 sentences (68.9%).
This showsthat our preprocessing affects the majority of thesentences and thus it is not surprising that prepro-cessing based on the DE construction can make asignificant difference.5.2 Example: how DE annotation affectstranslationOur approach DE-Annotated reorders the Chinesesentence, which is similar to the approach pro-posed by Wang et al (2007) (WANG-NP).
How-ever, our focus is on the annotation on DEs andhow this can improve translation quality.
Table 7shows an example that contains a DE constructionthat translates into a relative clause in English.12The automatic parse tree of the sentence is listedin Figure 3.
The reordered sentences of WANG-NPand DE-Annotated appear on the top and bottom inFigure 4.
For this example, both systems decideto reorder, but DE-Annotated had the extra informa-tion that this { is a {relc.
In Figure 4 we cansee that in WANG-NP, ?{?
is being translated as?for?, and the translation afterwards is not gram-matically correct.
On the other hand, the bottomof Figure 4 shows that with the DE-Annotated pre-processing, now ?{relc?
is translated into ?whichwas?
and well connected with the later translation.This shows that disambiguating{ helps in choos-ing a better English translation.
(IP(NP (NN ??
))(VP(ADVP (AD ))(VP (VV N?
)(IP(VP (VV z)(NP(QP (CD )(CLP (M P)))(CP(IP(VP (VV ?
)(NP(NP (NN ??
)(CC Z)(NN &J) (NN I))(ADJP (JJ ?
))(NP (NN '?
)))))(DEC {))(NP (NN ?) (NN ??)
(NN 0?
)))))))(PU ))Figure 3: The parse tree of the Chinese sentence in Table 7.12In this example, all four references agreed on the relativeclause translation.
Sometimes DE constructions have multi-ple appropriate translations, which is one of the reasons whycertain classes are more confusable in Table 4.221Chinese ??
 N?
z [ P ?
??
Z &J I ?
'?
]A { [? ??
0?
]B Ref 1 biagi had assisted in drafting [an employment reform plan]B [that was strongly opposed by the laborunion and the leftists]A .Ref 2 biagi had helped in drafting [a labor reform proposal]B [that provoked strong protests from labor unionsand the leftists]A .Ref 3 biagi once helped drafting [an employment reform scheme]B [that was been strongly opposed by thetrade unions and the left - wing]A .Ref 4 biagi used to assisted to draft [an employment reform plan]B [which is violently opposed by the tradeunion and leftest]A .Table 7: A Chinese example from MT02 that contains a DE construction that translates into a relative clause in English.
The[]A []B is hand-labeled to indicate the approximate translation alignment between the Chinese sentence and English references.???
?
??
??
???
?
??
??
?
??
???
??
?
??
??
?biagi had helped draft employmenta reform plan for is strongly opposed by trade unions and left - wing activists .???
?
??
??
??
?
???
??
???relc??
???
?biagi had helped draft a reform plan for employment , which was strongly opposed by trade unions and left - wing activists???
?Figure 4: The top translation is from WANG-NP of the Chinese sentence in Table 7.
The bottom one is from DE-Annotated.In this example, both systems reordered the NP, but DE-Annotated has an annotation on the{.6 ConclusionIn this paper, we presented a classification of Chi-nese {(DE) constructions in NPs according tohow they are translated into English.
We appliedthis DE classifier to the Chinese sentences of MTdata, and we also reordered the constructions thatrequired reordering to better match their Englishtranslations.
The MT experiments showed our pre-processing gave significant BLEU and TER scoregains over the baselines.
Based on our classifica-tion and MT experiments, we found that not onlydo we have better rules for deciding what to re-order, but the syntactic, semantic, and discourseinformation that we capture in the Chinese sen-tence allows us to give hints to the MT systemwhich allows better translations to be chosen.AcknowledgmentsThe authors would like to thank Michel Galleyand Daniel Cer for useful discussions and techni-cal help, and Spence Green for his comments onan earlier draft of the paper.
This work is fundedby a Stanford Graduate Fellowship to the first au-thor and gift funding from Google for the project?Translating Chinese Correctly?.ReferencesPi-Chuan Chang, Michel Galley, and Christopher D.Manning.
2008.
Optimizing Chinese word segmen-tation for machine translation performance.
In Pro-ceedings of the Third Workshop on Statistical Ma-chine Translation, pages 224?232, Columbus, Ohio,June.
Association for Computational Linguistics.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of ACL, pages 263?270, Ann Arbor, Michi-gan, June.
Association for Computational Linguis-tics.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In ACL ?05: Proceedings of ACL, pages531?540, Morristown, NJ, USA.
Association forComputational Linguistics.Michel Galley and Christopher D. Manning.
2008.
Asimple and effective hierarchical phrase reorderingmodel.
In Proceedings of EMNLP, pages 847?855,Honolulu, Hawaii, October.
Association for Compu-tational Linguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proc.of NAACL-HLT.Roger Levy and Christopher Manning.
2003.
Is itharder to parse Chinese, or the Chinese treebank?In Proceedings of ACL, pages 439?446, Morristown,NJ, USA.
Association for Computational Linguis-tics.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of HLT-NAACL,pages 104?111, New York City, USA, June.
Associ-ation for Computational Linguistics.Jia-ju Mei, Yi-Ming Zheng, Yun-Qi Gao, and Hung-Xiang Yin.
1984.
TongYiCi CiLin.
Shanghai: theCommercial Press.Franz Josef Och.
2003.
Minimum error rate trainingfor statistical machine translation.
In ACL.222Stefan Riezler and John T. Maxwell.
2005.
On somepitfalls in automatic evaluation and significance test-ing for MT.
In Proceedings of the ACL Workshopon Intrinsic and Extrinsic Evaluation Measures forMachine Translation and/or Summarization, pages57?64, Ann Arbor, Michigan, June.
Association forComputational Linguistics.Anette Rosenbach.
2003.
Aspects of iconicity andeconomy in the choice between the s-genitive andthe of-genitive in English.
Topics in English Lin-guistics, 43:379?412.Huihsin Tseng, Dan Jurafsky, and Christopher D. Man-ning.
2005.
Morphological features help pos tag-ging of unknown words across language varieties.In Proc.
of the Fourth SIGHAN Workshop on Chi-nese Language Processing.Chao Wang, Michael Collins, and Philipp Koehn.2007.
Chinese syntactic reordering for statisticalmachine translation.
In Proceedings of EMNLP-CoNLL, pages 737?745, Prague, Czech Republic,June.
Association for Computational Linguistics.Fei Xia and Michael McCord.
2004.
Improvinga statistical MT system with automatically learnedrewrite patterns.
In Proceedings of Coling 2004,pages 508?514, Geneva, Switzerland, Aug 23?Aug27.
COLING.Fei Xia.
2000.
The part-of-speech tagging guidelinesfor the Penn Chinese Treebank (3.0).223
