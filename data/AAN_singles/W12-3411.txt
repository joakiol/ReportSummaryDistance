Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 78?88,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsKorean Treebank Transformation for Parser TrainingDongHyun ChoiDept.
of Computer ScienceKAISTKoreacdh4696@world.kaist.ac.krJungyeul ParkLes Editionsan Amzer VakFrancepark@amzer-vak.frKey-Sun ChoiDept.
of Computer ScienceKAISTKoreakschoi@cs.kaist.ac.krAbstractKorean is a morphologically rich language inwhich grammatical functions are marked byinflections and affixes, and they can indicategrammatical relations such as subject, object,predicate, etc.
A Korean sentence could bethought as a sequence of eojeols.
An eo-jeol is a word or its variant word form ag-glutinated with grammatical affixes, and eo-jeols are separated by white space as in En-glish written texts.
Korean treebanks (Choiet al, 1994; Han et al, 2002; Korean Lan-guage Institute, 2012) use eojeol as their fun-damental unit of analysis, thus representingan eojeol as a prepreterminal phrase insidethe constituent tree.
This eojeol-based an-notating schema introduces various complex-ity to train the parser, for example an en-tity represented by a sequence of nouns willbe annotated as two or more different nounphrases, depending on the number of spacesused.
In this paper, we propose methods totransform eojeol-based Korean treebanks intoentity-based Korean treebanks.
The methodsare applied to Sejong treebank, which is thelargest constituent treebank in Korean, and thetransformed treebank is used to train and testvarious probabilistic CFG parsers.
The experi-mental result shows that the proposed transfor-mation methods reduce ambiguity in the train-ing corpus, increasing the overall F1 score upto about 9 %.1 IntroductionThe result of syntactic parsing is useful for manyNLP applications, such as named entity recogni-tion (Finkel and Manning, 2009), semantic role la-beling (Gildea and Jurafsky, 2002), or sentimentalanalysis (Nasukawa and Yi, 2003).
Currently mostof the state-of-the-art constituent parsers take statis-tical parsing approach (Klein and Manning, 2003;Bikel, 2004; Petrov and Klein, 2007), which usemanually annotated syntactic trees to train the prob-abilistic models of each consituents.Even though there exist manually annotated Ko-rean treebank corpora such as Sejong Treebank (Ko-rean Language Institute, 2012), very few researchprojects about the Korean parser, especially usingphrase structure grammars have been conducted.
Inthis paper, we aim to transform the treebank so that itcould be better used as training data for the already-existing English constituent parsers.Most of Korean treebank corpora use eojeols astheir fundamental unit of analysis.
An eojeol isa word or its variant word form agglutinated withgrammatical affixes, and eojeols are separated bywhite space as in English written texts (Choi et al,2011).
Figure 1 is one of the example constituenttree from the Sejong Treebank.
As can be observed,an eojeol is always determined as a prepretermi-nal phrase 1.
But this kind of bracketing guidelinecould cause ambiguities to the existing algorithmsfor parsing English, because: (1) English does nothave the concept of ?eojeol?, and (2) an eojeolcan contain two or more morphemes with differentgrammatical roles.
For example, Korean case par-1A node is a prepreterminal if all the children of this nodeare preterminals (Part-Of-Speech tags such as NNP and JKG).Preterminal is defined to be a node with one child which is itselfa leaf (Damljanovic et al, 2010).78Figure 1: An example constituent tree and morphological analysis result from the Sejong treebankticles (?josa?)
are normally written inside the sameeojeol with their argument nouns, but the whole eo-jeol is always considered as a prepreterminal nounphrase in the Korean treebank, as can be seen in theeojeol Ungaro-GA.
Considering that the case parti-cles in Korean play important role in determiningthe syntactic structure of a sentence, this could causeloss of information during the training phase.
More-over, Emanuel Ungaro is considered as two differentnoun phrases, because they simply belong to the twodifferent eojeols (that is, a space exists between eo-jeols Emanuel and Ungaro-GA).In this paper, we propose methods to refine theSejong treebank which is currently the largest Ko-rean treebank corpus.
The methods are aimed at de-creasing the ambiguities during the training phaseof parsers, by separating phrases which are inte-grated into the same prepreterminal phrase due tothe reason that they happen to be in the same eojeol,and integrating phrases into the same prepretermi-nal phrase which are separated because they hap-pen to be in different eojeols.
The refined datasetsare trained and tested against three state-of-the-artparsers, and the evaluation results for each datasetare reported.In section 2, the work about Korean parsers arebriefly introduced.
Sejong treebank is describedwith more detailed explanation in section 3, whilethe methods to transform the treebank are introducedin section 4.
In section 5 the evaluation results of thetransformed treebank using the three existing state-of-the-art parsers are introduced with an error report,and we discuss conclusions in section 6.2 Related WorkThere were some trials to build Korean constituentparsers, but due to the lack of appropriate corpusthose trials were not able to acheive a good re-sult.
(Smith and Smith, 2004) tried to build a Ko-rean parser by bilingual approach with English, andachieved labeled precision/recall around 40 % forKorean.
More recently, (Park, 2006) tried to extracttree adjoining grammars from the Sejong treebank,and (Oh et al, 2011) build a system to predict aphrase tag for each eojeol.Due to the partial free word order and case pari-cles which can decide the grammatical roles of nounphrases, there exist some works to build statisticaldependency parsers for Korean.
(Chung, 2004) pre-sented a dependency parsing model using surfacecontextual model.
(Choi and Palmer, 2011) con-verted the Sejong treebank into the dependency tree-bank, and applied the SVM algorithm to learn thedependency model.79NNG General noun IC Interjection JKQ Quotational CP XSV Verb DSNNP Proper noun MM Adnoun JX Auxiliary PR XSA Adjective DSNNB Bound noun MAG General adverb JC Conjunctive PR XR Base morphemeNP Pronoun MAJ Conjunctive adverbEP Prefinal EM SN NumberNR Numeral JKS Subjective CP EF Final EM SL Foreign wordVV Verb JKC Complemental CP EC Conjunctive EM SH Chinese wordVA Adjective JKG Adnomial CP ETN Nominalizing EM NF Noun-like wordVX Auxiliary predicateJKO Objective CP ETM Adnominalizing EMNV Verb-like wordVCP Copula JKB Adverbial CP XPN Noun prefix NA Unknown wordVCN Negation adjective JKV Vocative CP XSN Noun DS SF,SP,SS,SE,SO,SWTable 1: POS tags used in Sejong treebank (CP: case particle, EM: ending marker, DS: derivational suffix, PR: particle,SF SP SS SE SO: different types of punctuations, SW: currency symbols and mathematical symbols.
Table borrowedfrom (Choi and Palmer, 2011))Apart from the Sejong Treebank, there are fewother Korean treebanks available.
The KAIST tree-bank (Choi et al, 1994) contains constituent treesabout approximately 30K sentences from newspa-pers, novels and textbooks.
Also, the Penn Ko-rean Treebank (Han et al, 2002) contains 15Kconstituent trees constructed from the sentences ofnewswire and military domains.
The proposedmethods are evaluated using the Sejong treebank be-cause it is the most recent and the largest Koreantreebank among those which is currently available.3 Sejong TreebankThe Sejong treebank is the largest constituenttreebank in Korean.
It contains approximately45K manually-annotated constituent trees, and theirsources cover various domains including newspa-pers, novels and cartoon texts.
Figure 1 shows anexample of the Sejong constituent tree.The tree consists of phrasal nodes and their func-tional tags as described in table 2.
Each eojeolcould contain one or more morphemes with differentPOS tags (Table 1 shows the POS tagset).
In mostcases, eojeols are determined by white spaces.
Asstated in its bracketing guidelines, the Sejong tree-bank uses eojeols as its fundamental unit of analy-sis 2.
This means that an eojeol is always treated asone prepreterminal phrase.
This could cause confu-sions to the training system, because an eojeol couldcontain many morphemes which have very different2The bracketing guidelines could be requested from the Se-jong project, but available only in Koreangrammatical roles, as can be seen in the exampleof Ungaro-GA - word Ungaro is a noun, where thenominative case particle GA suggests that this eojeolis used as a subject.Table 2 shows phrase tags and functional tagsused to construct the Sejong treebank.
Some phrasesare annotated with functional tags to clarify theirgrammatical role inside the sentence.
There arethree special phrase tags beside those in table 2:X indicates phrases containing only case particlesor ending markers, L and R indicate left and rightparenthesis.Phrase-level tags Functional tagsS Sentence SBJ SubjectQ Quotative clause OBJ ObjectNP Noun phrase CMP ComplementVP Verb phrase MOD ModifierVNP Copula phrase AJT AdjunctAP Adverb phrase CNJ ConjunctiveDP Adnoun phrase INT VocativeIP Interjection phrasePRN parentheticalTable 2: Phrase tags used in Sejong treebank.4 Transforming Methods: fromEojeol-based to Entity-basedIn this section, we describe the methods to transformthe annotation schema of the Korean treebank fromeojeol-based to entity-based using the examples ofthe Sejong treebank.4.1 Method 1: POS Level PreprocessingBefore starting the actual transforming process, thesystem first detects emails, phone numbers and dates80based on their unique POS patterns.
If the systemdetects a sequence of morphemes matching with oneof predefined POS patterns inside an eojeol, then itgroups those morphemes into one entity and tags itas a noun.
This procedure aims to reduce the ambi-guity of the corpus by reducing many miscellaneousmrophemes which in fact forms one phone num-ber, email address or date information into one en-tity.
Figure 2 shows an example of an eojeol whosefive morphemes toghether represent one date, and itstransformation result.Figure 2: Example of an eojeol containing date: five mor-phemes are merged into one morpheme representing date.Also, the morphemes representing chinese char-acters (POS: SH) and other foreign characters (POS:SL) are considered as nouns, since they are normallyused to rewrite Korean nouns that have their foreignorigin such as Sino-Korean nouns.4.2 Method 2: Detecting NPs inside an EojeolAlthough an eojeol is considered to be one prepreter-minal phrase as a whole, many eojeols contain sep-arated noun components inside them.
For exam-ple, a noun phrase Ungaro-GA in Figure 3 con-sists of a separated noun component Ungaro in it,plus josa GA.
The system separates noun compo-nents from other endings and case particles, createsa new phrase containing those words and tags it asan NP.
By doing so, the boundaries of the NP aremore clarified - before transforming prepreterminalNPs could contain case particles and endings, butafter the transformation it is not possible.
Also theinternal syntactic structures of phrases are revealed,providing more information to the parser.4.3 Method 3: Finding Arguments of JosaIn this step, the system tries to find out the actual ar-gument of each josa.
For example, in figure 4 theFigure 3: Detecting NP inside an eojeol: Case of a verbphraseactual argument of the nominative josa GA is thewhole person name Emanuel Ungaro, not only Un-garo.
The system tries to find out the actual argu-ment of each josa by using a rather simple heuristic:1.
Traverse the constituent parse tree in bottom-up, right-to-left manner.2.
If a phrase node is NP, its parent is also NP, and it directlydominates josa(s), then:(a) Create a new NP.
(b) Attach the node to that NP, except the josa(s).
(c) Attach all the other children of the parent node to thenewly-created NP.
(d) Remove all the children of the parent, and attach thenew NP and remaining josa part to the parent node.3.
After the procedure ends, find and remove redundant NPs,if exist.Figure 4: Example of applying the transformation heuris-ticMethod 3 is dependent on method 2, since method2 first determines boundary of NPs which do not in-clude any case particles.4.4 Method 4: Integrating a Sequence ofNouns into One NPSome of entities represented as sequences of nounsare considered as two or more separated noun81phrases since their components belong to the dif-ferent eojeols.
This could be problematic becausean entity could sometimes be written without anywhitespace between its component nouns.
Figure 5shows one of the case: person name Emanuel Un-garo is considered as two separated NPs since thereexists a whitespace between a noun Emanual and anoun Ungaro.
In this step, we aim to solve this prob-lem.Figure 5: Integrating sequence of nouns representing oneentity into one prepreterminal noun phraseThe system finds out an NP which has two NPchildren which dominates only the noun pretermi-nal children.
If the system finds such an NP, then itremoves NP children and attaches their children di-rectly to the found NP.
Figure 5 shows an applicationexample of the method.This method is dependent on method 3, since thismethod assumes that an NP with its parent also NPdoes not have any case particles - which cannot behold if method 3 is not applied.4.5 Method 5: Dealing with NounConjunctionsThe system tries to enumerate the noun conjunc-tions, rather than expressing those conjunctions inbinary format.
Current Sejong treebank expressesnoun conjunctions in binary format - that is, to ex-press the constituent tree for noun conjunctions, thenonterminal node has one NP child on its left whichcontains information about the first item of the con-junction, and the rest of conjunctions are expressedon the right child.
Figure 63 shows an example ofthe Sejong constituent tree expressing the noun con-junctions, and its transformed version.3Mike-WA (CNJ) Speaker-GA (NOM) Jangchak-DOI-UHIT-DA.
(?Microphone and speaker are installed.?
)Figure 6: Enumerating Noun ConjunctionsBy converting noun conjunctions into rather the?enumerated?
forms, two benefits could be gained:first, the resultant constituent tree will resemblemore to the Penn-treebank constituent trees.
Sincemost of the existing English parsers are trained onthe Penn Treebank, we can expect that the enumer-ated form of conjunctions will more ?fit?
to thoseparsers.
Second, the conjunctions are expressed inmuch more explicit format, so the human users canmore easily understand the conjunctive structures in-side the constituent trees.4.6 Method 6: Re-tagging Phrase TagsIn this step, the system re-tags some of phrase tagsto clarify their types and to decrease training ambi-guities.
For example, a noun phrase with and with-out case particles should be distinguished.
The sys-tem re-tags those noun phrases with case particles toJSP 4 to distinguish them from the pure noun phraseswhich consist of only nouns.
Also, VP-MOD andVNP-MOD are re-tagged to DP, since they have verysimilar lexical formats with existing DPs.
NP-MODis converted into JSP-MOD - most of them consistof a NP with josa JKG, forming possesive cases.
S-MOD remains as S-MOD if its head is JSP-MOD:4It stands for a ?Josa Phrase?.82otherwise, it is also re-tagged to a DP.
Figure 75shows a re-tagging example.Figure 7: Example of retagging phrase tags: VP-MOD toDP, NP-MOD to JSP-MOD, and NP-SBJ to JSP-SBJ.5 EvaluationsIn this section, several experiment results using thestandard F1 metric (2PR/(P + R)) are introducedto show the effect of each transforming method, andthe most frequently shown error cases are explained.5.1 Experiments using the Sejong TreebankThe proposed transformation methods are applied tothe Sejong treebank, and the converted treebanks areused to train and test three different well-known sta-tistical parsers, namely Stanford parser (Klein andManning, 2003), Bikel-Collins parser (Bikel, 2012)and Berkeley parser (Petrov et al, 2006).
To figureout the effect of each method, all six methods aresequentially applied one by one, and each version ofthe treebank is used to train and test each parser.
Thebaseline treebank is the original Sejong treebankwithout any transformations.
For the Korean headword extraction which will be used during parsing,the head percolation rule of (Choi and Palmer, 2011)is adapted.
According to that paper, particles andendings were the most useful morphemes to deter-mine dependencies between eojeols.
Based on theobservation, their rules are changed so that they givethe best priorities on those morphemes.
We usethe preprocessing method described in (Park, 2006)for training trees.
It replaces symboles with Penn-Treebank-like tags and corrects wrong morpheme5See Figure 1 for its transcription and translation.boundary marks within the eojeol.
Methods are ap-plied cumulatively; for example, symbol ?M 1-6?means the version of a treebank to which method1, 2, 3, 4, 5 and 6 are applied cumulatively.6System Corpus P R F1Stan.Baseline 67.88% 61.77% 64.69%M 1 68.34% 61.93% 64.98%M 1-2 71.78% 67.50% 69.58%M 1-3 71.28% 67.91% 69.56%M 1-4 71.06% 67.08% 69.01%M 1-5 71.35% 67.27% 69.26%M 1-6 75.85% 72.07% 73.92%Bikel.Baseline 74.81% 70.39% 72.53%M 1 74.87% 70.45% 72.59%M 1-2 77.05% 73.84% 75.41%M 1-3 75.87% 72.88% 74.34%M 1-4 75.33% 72.10% 73.68%M 1-5 75.29% 72.18% 73.70%M 1-6 73.70% 71.05% 72.35%Berk.Baseline 75.25% 72.72% 73.96%M 1 74.54% 71.97% 73.23%M 1-2 77.27% 75.05% 76.14%M 1-3 75.60% 73.19% 74.38%M 1-4 75.69% 73.32% 74.49%M 1-5 76.53% 74.30% 75.40%M 1-6 78.60% 76.03% 77.29%Table 3: Evaluation results of parsers, with various trans-formed versions of the Sejong treebank.Table 3 shows the experimental results on eachversion of the treebanks using each parser.
Sincethe corpus covers various domains (i.e.
the style ofsentences is not homogeneous.
), we perform 10-foldcross-validation for our experiments.
Stan.
rep-resents Stanford parser, Bikel.
represents Bikel-Collins parser, and Berk.
means Berkeley parser.For the Berkeley parser, we set the number of itera-tion as two for latent annotations.
In this set of ex-periments, only phrase tags are the target of trainingand testing, not including functional tags.As can be observed from the evaluation result, theperformance is improved due to methods 2 and 6are quite big compared to the effect of other four6As pointed out by reviewers, we are planning the reversibil-ity of transformations to be evaluated on the same trees formeaning comparison.83System Corpus P R F1Stan.Baseline 71.48% 69.40% 70.43%M 1 71.89% 69.75% 70.81%M 1-2 75.90% 73.44% 74.65%M 1-3 72.32% 69.76% 71.02%M 1-4 72.37% 69.97% 71.16%M 1-5 72.80% 70.28% 71.52%M 1-6 72.32% 69.81% 71.05%Bikel.Baseline 69.65% 66.80% 68.19%M 1 69.73% 66.97% 68.32%M 1-2 74.33% 71.90% 73.09%M 1-3 63.94% 64.57% 64.25%M 1-4 63.95% 65.04% 64.49%M 1-5 64.09% 65.05% 64.57%M 1-6 62.94% 64.16% 63.54%Berk.Baseline 76.82% 75.28% 76.04%M 1 76.73% 75.06% 75.89%M 1-2 79.59% 77.91% 78.74%M 1-3 75.24% 72.16% 73.67%M 1-4 75.02% 73.01% 74.00%M 1-5 75.58% 73.61% 74.58%M 1-6 74.37% 71.93% 73.13%Table 4: Evaluation results of parsers, with phrase tagsand functional tags together as learning target.methods.
Especially, the performance increase dueto the method 6 strongly suggests that Sejong phrasetagsets are not enough to distinguish the types ofphrases effectively.
Except those two methods,only the method 5 increases the overall performanceslightly, and methods 1, 3 and 4 do not have anysignificant effect on the performance or even some-times decrease the overall performance.Although the usage of functional tags is differentfrom that of phrase tags, the Sejong treebank hasa very rich functional tag set.
Considering the re-sults of the previous experiments, it is highly likelythat some of phrasal information is encoded into thefunctional tags.
To prove that, another set of experi-ments is carried out.
In this time, parsers are trainednot only on phrase tags but also on functional tags.Table 4 shows the evaluation results.As can be observed, by keeping functional tagsto train and test parsers, the baseline performanceincreases 3 to 6 % for the Stanford and Berkeleyparsers.
Only the performance of the Bikel parseris decreased - it is highly possible that the parserfails to find out the appropriate head word for eachpossible tag, because the number of possible tags isincreased greatly by using the functional tags alongwith the phrase tags.In both set of experiments, the method 3 decreasesthe overall performance.
This strongly suggests thatfinding the actual argument of josa directly is quite achallenging work.
The performance drop is consid-ered mainly because the branching problem at thehigher level of the constituent tree is counted twicedue to the josa.5.2 Experiments using the Penn KoreanTreebankTo show the effect of the transformation methodsmore clearly, the Penn Korean Treebank (Han et al,2002) is used as another treebank for experimen-tation: (Chung et al, 2010) describes about majordifficulties of parsing Penn Korean Treebank.
Thesame three parsers are trained and tested using thetreebank.
Due to the different annotation guidelinesand different tagsets, transformation methods 1, 5and 6 cannot be applied on the treebank.
Thus, onlymethod 2, 3 and 4 are used to transform the treebank.Table 5 shows the evaluation results.System Corpus P R F1Stan.Baseline 82.84% 80.28% 81.54%M 2 85.29% 83.25% 84.26%M 2-3 84.52% 82.71% 83.61%M 2-4 84.52% 82.92% 83.72%Bikel.Baseline 81.49% 78.20% 79.81%M 2 75.82% 74.47% 75.13%M 2-3 73.50% 69.66% 71.53%M 2-4 73.45% 69.66% 71.51%Berk.Baseline 85.11% 81.90% 83.47%M 2 83.40% 81.04% 82.20%M 2-3 82.36% 80.52% 81.43%M 2-4 82.97% 81.28% 82.12%Table 5: Evaluation on Penn Korean Treebank.The overall performance of training the Penn Ko-rean treebank is higher than that of the Sejong tree-bank.
There could be two possible explanations.First one is, since the Penn Korean treebank triesto follow English Penn treebank guidelines as much84as possible, thus annotation guidelines of the Ko-rean Penn treebank could be much ?familiar?
to theparsers than that of the Sejong treebank.
The secondexplanation is, since the domain of the Penn Koreantreebank is much more restricted than that of the Se-jong treebank, the system could be trained for thespecific domain.
The best performance was gainedwith the Stanford parser, with the treebank trans-formed by method 2.
Actually, (Chung et al, 2010)also investigated parsing accuracy on the Penn Ko-rean treebank; the direct comparison could be verydifficult because parsing criteria is different.5.3 Error AnalysisIn this section, some of the parsing error cases arereported.
Berkeley parser trained with the Sejongtreebank is used for error analysis.
Both phrase tagsand functional tags are used to train and test the sys-tem.5.3.1 Locating Approximate Positions ofErrorsAs the first step to analyze the errors, we tried tofigure out at which points of the constituent tree er-rors frequently occur ?
do the errors mainly occur atthe bottom of the trees?
Or at the top of the trees?If we can figure out approximate locations of errors,then the types of errors could be predicted.Figure 8: Example of assigning levels to each phrasalnode.To define the level of each nonterminal node ofthe constituent tree, the following rules are used:?
The level of prepreterminal node is 0.?
The levels of other phrasal nodes are definedas: the maximal level of their children + 1.?
Once the levels of all the phrasal nodes are cal-culated, normalize the levels so that they havethe values between 0 and 1.Figure 8 shows an example of constituent treewith levels assigned to its phrasal nodes.
All theprepreterminal nodes have level value 0, and the top-most node has level 1.Figure 9: Performance of the system on each level of theparse treeOnce the levels are assigned to each constituenttree, only those constituents with levels larger thanor equal to the predefined threshold ?
are used toevaluate the system.
?
are increased from 0 to 1 withvalue 0.01.
Higher ?
value means that the system isevaluated only for those constituents positioned atthe top level of the constituent tree.Figure 9 shows the evaluation results.
X-axis rep-resents the value of ?, and Y-axis represents the F1-score.
As can be observed, most of the errors oc-cur at the mid-level of the constituent trees.
Also,the effects of some methods are explicitly shownon the graph.
For example, method 2 greatly in-creases the performance at low level of the con-stituent tree, suggesting improved consistency in de-temining prepreterminal NP nodes.
Also, it is shownthat the proposed methods does not affect the perfor-mance of mid-level and top-level constituent deci-sions - this suggests that the future works should bemore focused on providing more information aboutthose mid-level decision to the treebank annotation.85Figure 10: Example of NP boundary detection error.
Partof parse tree as well as name of the enumerated productsare omitted to more clearly show the example itself.5.3.2 Frequent Error CasesIn this section, four major parsing error cases aredescribed.Detecting Boundaries of NP.
Although themethod 4 tries to find and gather the sequence ofnouns which actually belong to one NP, it missessome of the cases.
Figure 10 shows such example.Some parts of the tree are omitted using the notation?...?
to show the example more simply.
Although itis counted as the parser error, the result of the parseris more likely to be an answer - the number of thoseproducts is 8, not their action.
The Sejong treebanktree is annotated in that way because the number ?8?and bound noun Gae (?unit?
), representing as units,are separated by a space.
To detect such kind of sep-arated NPs and transform them into one NP will beour next task.Finding an AppropriateModifee.
Some phrasesmodifying other phrases were failed to find their ap-propriate modifees.
Figure 11 shows an example ofsuch kind of error case.Detecting an Appropriate Subject of the Sen-tence.
This case frequently occurs when a sentenceis quotated inside the other sentence.
In this case,the subject of quotated sentence is often consideredas the subject of the whole sentence, because thequotated sentences in Korean are usually first statedFigure 11: Example of a phrase (JSP-AJT) which failedto find its right modifee.and then the subject of the whole sentence shows up.Figure 12 shows an example of the erroneously de-tected subject.The Wrongly-tagged Topmost Node.
Some ofSejong treebank trees have phrases which are nottagged as S as their topmost nodes.
This could causeconfusion during the training.
Figure 13 shows suchexample.6 Conclusion and Future WorkAlthough there exist some manually-annotatedlarge-enough constituent treebanks such as Sejongtreebank, it was hard to apply the algorithms for En-glish parsers to Korean treebanks, because they wereannotated in eojeol-based scheme, which conceptdoes not exist in English.
In this paper, we showedthe possibility of acquiring good training and testingresults with the existing parsers trained using the ex-isting Korean treebanks, if it undergoes some simpletransforming procedures.
The error analysis resultshows that, indeed the proposed method improvesthe performance of parser at the lower level of con-stituent tree.86Figure 12: Example of a wrongly-detected subject.Although there exists a performance gain due tothe transforming methods, there are still many gapsfor improvement.
The evaluation results and er-ror analysis results suggests the need to define thephrase tagset of Sejong treebank in more detail.Also, the transforming methods themselves are notperfect yet - we believe still they could be improvedmore to increase consistency of the resultant tree-banks.We will continuously develop our transformingmethods to improve the parsing result.
Furthermore,we are planning to investigate methods to determinethe appropriate ?detailedness?
of phrase tag set, sothat there are no missing information due to toosmall number of tags as well as no confusion dueto too many tags.AcknowledgementThis research was supported by Basic ScienceResearch Program through the National ResearchFoundation of Korea (NRF) funded by the Ministryof Education, Science and Technology (No.
2011-Figure 13: Example of the wrongly-tagged topmost node.Some trees in the treebank have Non-S topmost phrasenodes.0026718)ReferencesDan Bikel.
2004.
On the Parameter Space of GenerativeLexicalized Statistical Parsing Models.
Ph.D. thesis,University of Pennsylvania.Dan Bikel.
2012.
Bikel parser.
http://www.cis.upenn.edu/?dbikel/software.html.Jinho D. Choi and Martha Palmer.
2011.
Statistical de-pendency parsing in Korean: From corpus generationto automatic parsing.
In The Second Workshop on Sta-tistical Parsing of Morphologically Rich Languages,pages 1?11.Key-Sun Choi, Young S. Han, Young G. Han, and Oh W.Kwon.
1994.
KAIST tree bank project for Korean:Present and future development.
In Proceedings ofthe International Workshop on Sharable Natural Lan-guage Resources, pages 7?14.Key-Sun Choi, Isahara Hitoshi, and Maosong Sun.
2011.Language resource management ?
word segmentationof written texts ?
part 2: Word segmentation for Chi-nese, Japanese and Korean.
In ISO 24614-2.
ISO.Tagyoung Chung, Matt Post, and Daniel Gildea.
2010.Factors affecting the accuracy of korean parsing.
InProceedings of the NAACL HLT 2010 First Workshopon Statistical Parsing of Morphologically-Rich Lan-guages, pages 49?57, Los Angeles, CA, USA, June.Association for Computational Linguistics.87Hoojung Chung.
2004.
Statistical Korean DependencyParsing Model based on the Surface Contextual Infor-mation.
Ph.D. thesis, Korea University.Danica Damljanovic, Milan Agatonovic, and HamishCunningham.
2010.
Identification of the question fo-cus: Combining syntactic analysis and ontology-basedlookup through the user interaction.
In Proceedings of7th Language Resources and Evaluation Conference(LREC), pages 361?368.Jenny Rose Finkel and Christopher D. Manning.
2009.Joint parsing and named entity recognition.
In NAACL?09 Proceedings of Human Language Technologies:The 2009 Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics, pages 326?334.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic la-beling of semantic roles.
Computational Linguistics,28(3):245?288.Chung-Hye Han, Na-Rae Han, Eon-Suk Ko, Heejong Yi,and Martha Palmer.
2002.
Penn Korean treebank:Development and evaluation.
In Proceedings of the16th Pacific Asia Conference on Language, Informa-tion and Computation.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stMeeting of the Association for Computational Linguis-tics, pages 423?430.Korean Language Institute.
2012.
Sejong treebank.http://www.sejong.or.kr.Tetsuya Nasukawa and Jeonghee Yi.
2003.
Sentimentanalysis: capturing favorability using natural languageprocessing.
In Proceedings of the 2nd internationalconference on Knowledge capture, pages 70?77.Jin Young Oh, Yo-Sub Han, Jungyeul Park, and Jeong-Won Cha.
2011.
Predicting phrase-level tags usingentropy inspired discriminative models.
In 2011 Inter-national Conference on Information Science and Ap-plications (ICISA), pages 1?5.Jungyeul Park.
2006.
Extraction of tree adjoining gram-mars from a treebank for Korean.
In Proceedings ofthe 21st International Conference on computationalLinguistics and 44th Annual Meeting of the Associa-tion for Computational Linguistics: Student ResearchWorkshop, pages 73?78.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Human Language Tech-nologies 2007: The Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics; Proceedings of the Main Conference, pages404?411, Rochester, New York, April.
Association forComputational Linguistics.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and in-terpretable tree annotation.
In Proceedings of theCOLING-ACL 2006, pages 433?440.David A. Smith and Noah A. Smith.
2004.
Bilingualparsing with factored estimation: Using English toparse Korean.
In Proceedings of the EMNLP, pages49?56.88
