Splitting Long or Ill-formed Inputfor Robust Spoken-language TranslationOsamu FURUSE t, Setsuo  YAMADA,  Kazuh ide  YAMAMOTOATR Interpreting Telecommunications Research Laboratories2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0288, Japanfuruse~cslab, kecl.
ntt.
co. jp, {syamada, yamamoto}@itl, atr.
co. jpAbst rac tThis paper proposes an input-splitting methodfor translating spoken-language which includesmany long or ill-formed expressions.
The pro-posed method splits input into well-balancedtranslation units based on a semantic distancecalculation.
The splitting is performed ur-ing left-to-right parsing, and does not degradetranslation efficiency.
The complete translationresult is formed by concatenating the partialtranslation results of each split unit.
The pro-posed method can be incorporated into frame-works like TDMT, which utilize left-to-rightparsing and a score for a substructure.
Experi-mental results show that the proposed methodgives TDMT the following advantages: (1) elim-ination of null outputs, (2) splitting of utter-ances into sentences, and (3) robust translationof erroneous peech recognition results.1 In t roduct ionA spoken-language translation system requiresthe ability to treat long or ill-formed input.
Anutterance as input of a spoken-language trans-lation system, is not always one well-formedsentence.
Also, when treating an utterance inspeech translation, the speech recognition resultwhich is the input of the translation component,might be corrupted even though the input utter-ance is well-formed.
Such a misrecognized resultcan cause a parsing failure, and consequently, notranslation output would be produced.
Further-more, we cannot expect hat a speech recogni-tion result includes punctuation marks such asa comma or a period between words, which areuseful information for parsing.
1As a solution for treating long input, long-sentence splitting techniques, uch as that oftCurrent affiliation is NTT  Communicat ion ScienceLaboratories.1 Punctuat ion marks are not used in translation inputin this paper.Kim (1994), have been proposed.
These tech-niques, however, use many splitting rules writ-ten manually and do not treat ill-formed in-put.
Wakita (1997) proposed a robust transla-tion method which locally extracts only reliableparts, i.e., those within the semantic distancethreshold and over some word length.
Thistechnique, however, does not split input intounits globally, or sometimes does not outputany translation result.This paper proposes an input-splittingmethod for robust spoken-language translation.The proposed method splits input into well-balanced translation units based on a seman-tic distance calculation.
The complete trans-lation result is formed by concatenating thepartial translation results of each split unit.The proposed method can be incorporated intoframeworks that utilize left-to-right parsing anda score for a substructure, In fact, it hasbeen added to Transfer-Driven Machine Trans-lation (TDMT), which was proposed for efficientand robust spoken-language translation (Fu-ruse, 1994; Furuse, 1996).
The splitting is per-formed during TDMT's left-to-right chart pars-ing strategy, and does not degrade translationefficiency.
The proposed method gives TDMTthe following advantages: (1) elimination of nulloutputs, (2) splitting of utterances into sen-tences, and (3) robust translation of erroneousspeech recognition results.In the subsequent sections, we will first out-line the translation strategy of TDMT.
Then,we will explain the framework of our split-ting method in Japanese-to-English (JE) andEnglish-to-Japanese (E J) translation.
Next, bycomparing the TDMT system's performance b -tween two sets of translations with and with-out using the proposed method, we will demon-strate the usefulness of our method.4212 Trans la t ion  s t ra tegy  of  TDMT2.1 Trans fer  knowledgeTDMT produces a translation result by mim-icking the example judged most semanticallysimilar to the input string, based on the ideaof Example-Based MT.
Since it is difficult tostore enough example sentences to translate v-ery input, TDMT performs the translation bycombining the examples of the partial expres-sions, which are represented by transfer knowl-edge patterns.
Transfer knowledge in TDMT iscompiled from translation examples.
The fol-lowing EJ transfer knowledge xpression indi-cates that the English pattern "X at Y" corre-sponds to several possible Japanese xpressions:X at Y => yt de X t ((present, conference)..),V ni X ~ ((stay, hotel)..),}'I wo X I ((look, it)..)The first possible translation pattern is "V deX", with example set ((present, conference)..).We will see that this pattern is likely to be se-lected to the extent hat the input variable bind-ings are semantically similar to the sample bind-ings, where X ="present" and Y ="conference".X' is the transfer esult of X.The source expression of the transfer knowl-edge is expressed by a constituent boundarypattern, which is defined as a sequence thatconsists of variables and symbols representingconstituent boundaries (Furuse, 1994).
A vari-able corresponds to some linguistic constituent.A constituent boundary is expressed by eithera functional word or a part-of-speech bigrammarker.
In the case that there is no func-tional surface word that divides the expressioninto two constituents, a part-of-speech bigramis employed as a boundary marker, which is ex-pressed by hyphenating the parts-of-speech of aleft-constituent's last word and that of a right-constituent's first word.For instance, the expression "go to Kyoto" isdivided into two constituents, "go" and "Kyoto'.The preposition "to" can be identified as a con-stituent boundary.
Therefore, in parsing "go toKyoto", we use the pattern "X to Y".The expression "I go" can be divided intotwo constituents "f '  and "go", which are a pro-noun and a verb, respectively.
Since there isno functional surface word between the twoconstituents, pronoun-verb can be inserted as aboundary marker into "I go", giving "I pronoun-verb go", which will now match the generaltransfer knowledge pattern "X pronoun-verb Y'.2.2 Left - to- r ight  pars ingIn TDMT, possible source language structuresare derived by applying the constituent bound-ary patterns of transfer knowledge source partsto an input string in a left-to-right fashion (Fu-ruse, 1996), based on a chart parsing method.An input string is parsed by combining activeand passive arcs shifting the processed stringleft-to-right.
In order to limit the combina-tions of patterns during pattern application,each pattern is assigned its linguistic level, andfor each linguistic level, we specify the linguisticsublevels permitted to be used in the assignedvariables.I X pronoun-verb Y X pronoun-verb YI # I II I go(a) (b) (c)X pronoun-verb YXto  Y I IX to Y I I I X to YI f  go Kyoto I Igo ~ go Kyoto(d) (e) (f)Figure 1: Substructures for "I go to Kyoto"Figure 1 shows the substructures for each pas-sive arc and each active arc in "I go to Kyoto".A processed string is indicated by "~".
A pas-sive arc is created from a content word shown in(a), or from a combination of patterns for whichall of the variables are instantiated, like (c), (e),and (f).
An active arc, which corresponds to anincomplete substructure, is created from a com-bination of patterns ome of which have unin-stantiated variables as right-hand neighbors tothe processed string, like (b) and (d).If the processed string creates a passive arc fora substring and the passive arc satisfies the left-most part of an uninstantiated variable in thepattern of active arcs for the left-neighboringsubstring, the variable is instantiated with thepassive arc.
Suppose that the processed stringis "Kyoto" in "I go to Kyoto".
The passive arc(e) is created, and it instantiates Y of the ac-tive arc (b).
Thus, by combining (b) and (e),the structure of "I go to Kyoto" is composed like(f).
If a passive arc is generated in such op-eration, the creation of a new arc by variableinstantiation is repeated.
If a new arc can nolonger be created, the processed string is shifted422to the right-neighboring string.
If the whole in-put string can be covered with a passive arc, theparsing will succeed.2.3 D isambiguat ionThe left-to-right parsing determines the beststructure and best transferred result locally byperforming structural disambiguation using se-mantic distance calculations, in parallel withthe derivation of possible structures (Furuse,1996).
The best structure is determined whena relative passive arc is created.
Only thebest substructure is retained and combined withother arcs.
The best structure is selected bycomputing the total sum of all the possiblecombinations of the partial semantic distancevalues.
The structure with the smallest to-tal distance is chosen as the best structure.The semantic distance is calculated accordingto the relationship of the positions of the words'semantic attributes in the thesaurus (Sumita,1992).3 Sp l i t t ing  s t ra tegyIf the parsing of long or ill-formed input is onlyundertaken by the application of stored pat-terns, it often fails and generates no results.Our strategy to parse such input, is to split theinput into units each of which can be parsed andtranslated, and is explained as items (A)-(F) inthis section.3.1 Concatenat ion  of ne ighbor ingsubst ructuresThe splitting is performed uring left-to-rightparsing as follows:(A) Neighboring passive arcs can create alarger passive arc by concatenating them.
(B) A passive arc which concatenates neigh-boring passive arcs can be further concate-nated with the right-neighboring passivearc.These items enable two neighboring substruc-tures to compose a structure ven if there is nostored pattern which combines them.
Figure 2shows structure composition from neighboringsubstructures based on these items, a, ~3, and7 are structures of neighboring substrings.
Thetriangles express substructures composed onlyfrom stored patterns.
The boxes express sub-structures produced by concatenating eighbor-ing substructures.
~ is composed from its neigh-boring substructures, i.e., a and 8.
In addition,e is composed from its neighboring substruc-tures, i.e., ~f and 7.Figure 2: Structure from split substructuresItems (A) and (B) enable such a colloquialutterance as (1) to compose a structure by split-ting, as shown in Figure 3.
(1) "Certainly sir for how many people please"Figure 3: Structure for (1)3.2 Spl i tt ing input  into wel l - formedparts  and i l l - formed partsItem (C) splits input into well-formed parts andill-formed parts, and enables parsing in suchcases where the input is ill-formed or the trans-lation rules are insufficient.
The well-formedparts can be applied patterns or they can con-sist of one content word.
The ill-formed parts,which consist of one functional word or onepart-of-speech bigram marker, are split from thewell-formed parts.
(c) In addition to content words, boundarymarkers, namely, any functional wordsand inserted part-of-speech bigram mark-ers, also create a passive arc and composea substructure.
(2) "They also have tennis courts too plus a disco"(3) "Four please two children two adults"Suppose that the substrings of utterance (2),"they also have tennis courts too" and "a disco",can create apassive arc, and that the system hasnot yet learned a pattern to which preposition"plus" is relevant, such as "X plus Y" or "plusX' .Also, suppose that the substrings of utterance(3), "four please" and "two children two adults",can create a passive arc, that part-of-speech423bigram marker "adverb-numeral' is inserted be-tween these substrings, and that the systemdoes not know pattern "X adverb-numeral Y" tocombine a sentence for X and a noun phrase forY.By item (C), utterances (2) and (3) can beparsed in these situations as shown in Figure 4.Figure 4: Structures for (2) and (3)3.3 S t ruc ture  pre ferenceAlthough the splitting strategy improves ro-bustness of the parsing, heavy dependence onthe splitting strategy should be avoided.
Sincea global structure has more syntactic and se-mantic relations than a set of fragmental ex-pressions, in general, the translation of a globalexpression tends to be better than the transla-tion of a set of fragmental expressions.
Accord-ingly, the splitting strategy should be used as abackup function.Figure 5 shows three possible structures for"go to Kyoto".
(a) is a structure relevant o pat-tern "X to Y" at the verb phrase level.
In (b),the input string is split into two substrings, "go"and "to Kyoto".
In (c), the input string is splitinto three substrings, "go", "to", and "Kyoto".The digit described at the vertex of a triangleis the sum of distance values for that strucure.Among these three, (a), which does not usesplitting, is the best structure.
Item (D) is regu-lated to give low priority to structures includingsplit substructures.
(D) When a structure is composed by splitting,a large distance value is assigned.In the TDMT system, the distance value ineach variable varies from 0 to 1.
We experimen-tally assigned the distance value of 5.00 to oneapplication of splitting, and 0.00 to the struc-ture including only one word or one part-of-(a)/ , ,9, .33 \[(b)0.00 0.00 .0.00(c)Figure 5: Structures for "go to Kyoto"speech bigram marker.
2Suppose that substructures in Figure 5 areassigned the following distance values.
The to-tal distance value of (a) is 0.33.
The splittingis applied to (b) and (c), once and twice, re-spectively.
Therefore, the total distance valueof (b) is 0.00+0.33+5.00x 1=5.33, and that of (c)is 0.00+0.00+0.00+5.00x2=10.00.
(a) is selectedas the best structure because it gives the small-est total distance value.3.4 Trans lat ion  outputThe results gained from a structure correspond-ing to a passive arc can be transferred and apartial translation result can then be generated.The translation result of a split structure isformed as follows:(E) The complete translation result is formedby concatenating the partial translation re-sults of each split unit.A punctuation mark such as "," can be in-serted between partial translation results tomake the complete translation result clear, al-though we cannot expect punctuation i  an in-put utterance.
The EJ translation result of ut-terance (1) is as follows:certainly sir I for how many people pleaseh~ai , nan-nin ~desukaStrings such as functional words and part-ohspeech bigram markers have no target expres-sion, and are transferred as follows:2These values are tentatively assigned through com-paring the splitting performance for some values, and areeffective only for the present TDMT system.424Table 1: Effect of splitting on translation performanceoutput rate (%) parsing success rate/%) output understandability (%)w/o splitting w/splitting w/o w/ w/o w/JE 95.8 100 75.5 76.7 71.8 75.9EJ 94.2 100 75.0 76.0 81.0 84.0JK 83.4 100 68.3 71.2 80.4 94.5KJ 66.7 100 54.1 56.4 64.1 90.5(F) A string which does not have a target ex-pression, is transferred to a string as "..",which means an incomprehensible part.The EJ translation results of utterances (2)and (3) are as follows.
"r' denotes a splittingposition.they also have tennis courts too I plus la discodouyouni tenisu-kooto ga mata ari-masu, .., disukofour please ladverb-numeral Itwo children two adultsI Ifuta~ otona futari yon o-negai-shi masu, .. ,kodomo4 E f fec t  o f  sp l i t t ingThe splitting strategy based on items (A)-(F)in Section 3 can be introduced to frameworkssuch as TDMT, which utilize left-to-right pars-ing and a score for a substructure.
We discussthe effect of splitting by showing experimentalresults of the TDMT system's JE, E J, Japanese-to-Korean ( Jg),  and Korean-to-Japanese (gJ)translations.
3 The TDMT system, whosedomain is travel conversations, presently cantreat multi-lingual translation.
The present vo-cabulary size is about 13,000 words in JE andJK, about 7,000 words in EJ, and about 4,000words in KJ.
The number of training sentencesis about 2,900 in JE and EJ, about 1,400 in JK,and about 600 in KJ.4.1 Nu l l -output  e l im inat ionIt is crucial for a machine translation system tooutput some result even though the input is ill-formed or the translation rules are insufficient.Items (C) and (D) in Section 3, split input intowell-formed parts and ill-formed parts so thatweU-formed parts can cover the input as widelyas possible.
Since a content word and a patternt in  the experimental results referred to later in thissection, the input does not consist of strings but of cor-rect morpheme sequences.
This enables us to focus onthe evaluation of our splitting method by excluding caseswhere the morphological nalysis fails.can be assigned some transferred results, sometranslation result can be produced if the inputhas at least one well-formed part.Table 1 shows how the splitting improves thetranslation performance of TDMT.
More than1,000 sentences, i.e., new data for the system,were tested in each kind of translation.
Therewas no null output, and a 100 % output ratein every translation.
So, by using the splittingmethod, the TDMT can eliminate null outputunless the morphological analysis gives no re-sult or the input includes no content word.
Thesplitting also improves the parsing success rateand the understandability of the output in everytranslation.The output rates of the JK and KJ transla-tions were small without splitting because theamount of sample sentences i  less than that forthe JE and EJ translations.
However, the split-ting compensated for the shortage of samplesentences and raised the output rate to 100 %.Since Japanese and Korean are linguisticallyclose, the splitting method increases the under-standable results for JK and KJ translationsmore than for JE and EJ translations.4.2 Ut terance  sp l i t t ing into sentencesIn order to gain a good translation result foran utterance including more than one sentence,the utterance should be split into proper sen-tences.
The distance calculation mechanismaims to split an utterance into sentences cor-rectly.
(4) "Yes that will be fine at five o'clock we will re-move the bea~'For instance, splitting is necessary to trans-late utterance (4), which includes more than onesentence.
The candidates for (4)'s structure areshown in Figure 6.
The total distance valueof (a) is 0.00+1.11+5.00?1=6.11, that of (b) is0.00+0.00+1.11+5.00?2=11.11, and that of (c) is0.83+0.00+0.42+5.00?2=11.25.
As (a) has thesmallest otal distance, it is chosen as the beststructure, and this agrees with our intuition.425(a)(b)(c)Figure 6: Structures for (4)We have checked the accuracy of utterancesplitting by using 277 Japanese utterances and368 English utterances, all of which includedmore than one sentence.
Table 2 shows the suc-cess rates for splitting the utterances into sen-tences.
Although TDMT can also use the pat-tern "X boundary Y" in which X and Y are atthe sentence level to split the utterances, theproposed splitting method increases the successrates for splitting the utterances in both lan-guages.Table 2: Success rates for splitting utterancesw/o splitting w/ splittingJapanese 75.8 83.8English 59.2 69.34.3 Translat ion after speech recognit ionSpeech recognition sometimes produces inaccu-rate results from an actual utterance, and erro-neous parts often provide ill-formed translationinputs.
However, our splitting method can alsoproduce some translation results from such mis-recognized inputs and improve the understand-ability of the resulting speech-translation.Table 3 shows an example of a JE translationof a recognition result including a substitutionerror.
The underlined words are misrecognizedparts.
"youi(preparation)" in the utterance is re-placed with "yom'(postposition)".Table 4 shows an example of a JE translationof a recognition result including an insertion er-ror.
"wo" has been inserted into the utteranceafter speech recognition.
The translation of thespeech recognition result, is the same as thatof the utterance xcept for the addition of "..";".." is the translation result for "wo", which isa postposition mainly signing an object.Table 5 shows an example of the EJ trans-lation of a recognition result including a dele-tion error.
"'s" in the utterance is deleted afterspeech recognition.
In the translation of thisresult, ".." appears instead of "wa", which isa postposition signing topic.
".." is the trans-lation for marker "pronoun-adverb", which hasbeen inserted between "that" and "a//".
Therecognition result is split into three parts "yesthat", "pronoun-adverb", and "all correct".
Al-though the translations in Tables 3, 4, and5 might be slightly degraded by the splitting,the meaning of each utterance can be commu-nicated with these translations.We have experimented the effect of split-ting on JE speech translation using 47 erro-neous recognition results of Japanese utter-ances.
These utterances have been used as ex-ample utterances by the TDMT system.
There-fore, for utterances correctly recognized, thetranslations of the recognition results shouldsucceed.
The erroneous recognition results werecollected from an experimental base using themethod of Shimizu (1996).Table 6 shows the numbers of sentences ateach level based on the extent that the mean-ing of an utterance can be understood from thetranslation result.
Without the splitting, only19.1% of the erroneous recognition results arewholly or partially understandable.
The split-ting method increases this rate to 57.4%.
Fail-ures in spite of the splitting are mainly causedby the misrecognition f key parts such as pred-icates.Table 6: Translation after erroneous recognitionwholly understandablepartiallyunderstandablemisunderstood, ornever understandablenull outputw/o splitting w/splitting6 (12.8%) 15 (31.9%)3 (6.3%) 12 (25.5%)6 (12.8%) 20 (42.6%)32 (68.1%) 0 (0.0%)4.4 Translation t imeSince our splitting method is performed underleft-to-right parsing, translation efficiency is not426Table 3: Substitution error in JE translationI translation i put I TDMT system's translation result Iutterance I Chousyokn o go yoni wa deki masu garecognition result I Chousyoku no go yori wa deki masu gaI We can prepare breakfast.
IBreakfast .
.
.
.
.
.
.
.
we can do.Table 4: Insertion error in JE translationI translation i put I TDMT system's translation result Ii utterance I Sore'o h"s  o,  esu I is a rese o"on  ecesso ' Irecognition result Soreto w_go yoyaku ga hitsuyou desu ka And .. is a reservation ecessary?Table 5: Deletion error in EJ translationI I translation i put I TDMT system's translation result II utterance \[ Yesthat'sallcorrect\[ Haisorewamattakutadashiidesn.
Irecognition result Yes that all correct Hai sore .. mattaku tadashii desu.a serious problem.
We have compared EJ trans-lation times in the TDMT system for two cases.One was without the splitting method, and theother was with it.
Table 7 shows the translationtime of English sentences with an average in-put length of 7.1 words, and English utterancesconsisting of more than one sentence with anaverage input length of 11.4 words.
The trans-lation times of the TDMT system written inLISP, were measured using a Sparcl0 worksta-tion.Table 7: Translation time of EJinput w/o splitting w/splittingsentence 0.35sec 0.36secutterance 0.60sec 0.61secThe time difference between the two situa-tions is small.
This shows that the translationefficiency of TDMT is maintained even if thesplitting method is introduced to TDMT.5 Conc lud ing  remarksWe have proposed an input-splitting methodfor translating spoken-language which includesmany long or ill-formed expressions.
Experi-mental results have shown that the proposedmethod improves TDMT's performance with-out degrading the translation efficiency.
Theproposed method is applicable to not onlyTDMT but also other frameworks that uti-lize left-to-right parsing and a score for asubstructure.
One important future researchgoal is the achievement of a simultaneous in-terpretation mechanism for application to apractical spoken-language translation system.The left-to-right mechanism should be main-tained for that purpose.
Our splitting methodmeets this requirement, and can be applied tomulti-lingual translation because of its universalframework.ReferencesO.
Furuse and H. Iida.
1994.
ConstituentBoundary Parsing for Example-Based Ma-chine Translation.
In Proc.
of Coling '94,pages 105-111.O.
Furuse and H. Iida.
1996.
IncrementalTranslation Utilizing Constituent BoundaryPatterns.
In Proc.
of Coling '96, pages 412-417.Y.B.
Kim and T. Ehara.
1994.
An Auto-matic Sentence Breaking and Subject Supple-ment Method for J /E  Machine Translation(in Japanese).
In Transactions of Informa-tion Processing Society of Japan, Vol.
35, No.6, pages 1018-1028.T.
Shimizu, H. Yamamoto, H. Masataki,S.
Matsunaga, and Y. Sagisaka.
1996.
Spon-taneous Dialogue Speech Recognition us-ing Cross-word Context Constrained WordGraphs.
In Proc.
of ICASSP '96, pages 145-148.E.
Sumita and H. Iida.
1992.
Example-BasedTransfer of Japanese Adnominai Particlesinto English.
IEICE Transactions on Infor-mation and Systems, E75-D, No.
4, pages585-594.Y.
Wakita, J. Kawai, and H. Iida.
1997.
Cor-rect parts extraction from speech recognitionresults using semantic distance calculation,and its application to speech translation.
InProc.
of ACL//EACL Workshop on SpokenLanguage Translation, pages 24-31.427
