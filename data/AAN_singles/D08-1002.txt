Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 11?20,Honolulu, October 2008. c?2008 Association for Computational LinguisticsIt?s a Contradiction?No, it?s Not:A Case Study using Functional RelationsAlan Ritter, Doug Downey, Stephen Soderland and Oren EtzioniTuring CenterDepartment of Computer Science and EngineeringUniversity of WashingtonBox 352350Seattle, WA 98195, USA{aritter,ddowney,soderlan,etzioni}@cs.washington.eduAbstractContradiction Detection (CD) in text is adifficult NLP task.
We investigate CDover functions (e.g., BornIn(Person)=Place),and present a domain-independent algorithmthat automatically discovers phrases denotingfunctions with high precision.
Previous workon CD has investigated hand-chosen sentencepairs.
In contrast, we automatically harvestedfrom the Web pairs of sentences that appearcontradictory, but were surprised to find thatmost pairs are in fact consistent.
For example,?Mozart was born in Salzburg?
does not con-tradict ?Mozart was born in Austria?
despitethe functional nature of the phrase ?was bornin?.
We show that background knowledgeabout meronyms (e.g., Salzburg is in Austria),synonyms, functions, and more is essential forsuccess in the CD task.1 Introduction and MotivationDetecting contradictory statements is an importantand challenging NLP task with a wide range ofpotential applications including analysis of politi-cal discourse, of scientific literature, and more (deMarneffe et al, 2008; Condoravdi et al, 2003;Harabagiu et al, 2006).
De Marneffe et al present amodel of CD that defines the task, analyzes differenttypes of contradictions, and reports on a CD system.They report 23% precision and 19% recall at detect-ing contradictions in the RTE-3 data set (Voorhees,2008).
Although RTE-3 contains a wide variety ofcontradictions, it does not reflect the prevalence ofseeming contradictions and the paucity of genuinecontradictions, which we have found in our corpus.1.1 Contradictions and World KnowledgeOur paper is motivated in part by de Marneffe et al?swork, but with some important differences.
First,we introduce a simple logical foundation for the CDtask, which suggests that extensive world knowl-edge is essential for building a domain-independentCD system.
Second, we automatically generate alarge corpus of apparent contradictions found in ar-bitrary Web text.
We show that most of these appar-ent contradictions are actually consistent statementsdue to meronyms (Alan Turing was born in Londonand in England), synonyms (George Bush is mar-ried to both Mrs. Bush and Laura Bush), hypernyms(Mozart died of both renal failure and kidney dis-ease), and reference ambiguity (one John Smith wasborn in 1997 and a different John Smith in 1883).Next, we show how background knowledge enablesa CD system to discard seeming contradictions andfocus on genuine ones.De Marneffe et al introduced a typology of con-tradiction in text, but focused primarily on contra-dictions that can be detected from linguistic evi-dence (e.g.
negation, antonymy, and structural orlexical disagreements).
We extend their analysis toa class of contradictions that can only be detectedutilizing background knowledge.
Consider for ex-ample the following sentences:1) ?Mozart was born in Salzburg.
?2) ?Mozart was born in Vienna.
?3) ?Mozart visited Salzburg.
?4) ?Mozart visited Vienna.
?Sentences 1 & 2 are contradictory, but 3 & 4 arenot.
Why is that?
The distinction is not syntactic.Rather, sentences 1 and 2 are contradictory because11the relation expressed by the phrase ?was born in?can be characterized here as a function from peo-ple?s names to their unique birthplaces.
In contrast,?visited?
does not denote a functional relation.1We cannot assume that a CD system knows, inadvance, all the functional relations that might ap-pear in a corpus.
Thus, a central challenge for afunction-based CD system is to determine which re-lations are functional based on a corpus.
Intuitively,we might expect that ?functional phrases?
such as?was born in?
would typically map person namesto unique place names, making function detectioneasy.
But, in fact, function detection is surprisinglydifficult because name ambiguity (e.g., John Smith),common nouns (e.g., ?dad?
or ?mom?
), definite de-scriptions (e.g., ?the president?
), and other linguisticphenomena can mask functions in text.
For example,the two sentences ?John Smith was born in 1997.?and ?John Smith was born in 1883.?
can be viewedas either evidence that ?was born in?
does not de-note a function or, alternatively, that ?John Smith?is ambiguous.1.2 A CD System Based on FunctionsWe report on the AUCONTRAIRE CD system, whichaddresses each of the above challenges.
First, AU-CONTRAIRE identifies ?functional phrases?
statis-tically (Section 3).
Second, AUCONTRAIRE usesthese phrases to automatically create a large cor-pus of apparent contradictions (Section 4.2).
Fi-nally, AUCONTRAIRE sifts through this corpus tofind genuine contradictions using knowledge aboutsynonymy, meronymy, argument types, and ambi-guity (Section 4.3).Instead of analyzing sentences directly, AUCON-TRAIRE relies on the TEXTRUNNER Open Informa-tion Extraction system (Banko et al, 2007; Bankoand Etzioni, 2008) to map each sentence to one ormore tuples that represent the entities in the sen-tences and the relationships between them (e.g.,was born in(Mozart,Salzburg)).
Using extracted tu-ples greatly simplifies the CD task, because nu-merous syntactic problems (e.g., anaphora, rela-tive clauses) and semantic challenges (e.g., quantifi-cation, counterfactuals, temporal qualification) are1Although we focus on function-based CD in our case study,we believe that our observations apply to other types of CD aswell.delegated to TEXTRUNNER or simply ignored.
Nev-ertheless, extracted tuples are a convenient approxi-mation of sentence content, which enables us to fo-cus on function detection and function-based CD.Our contributions are the following:?
We present a novel model of the ContradictionDetection (CD) task, which offers a simple log-ical foundation for the task and emphasizes thecentral role of background knowledge.?
We introduce and evaluate a new EM-style al-gorithm for detecting whether phrases denotefunctional relations and whether nouns (e.g.,?dad?)
are ambiguous, which enables a CD sys-tem to identify functions in arbitrary domains.?
We automatically generate a corpus of seem-ing contradictions from Web text, and reporton a set of experiments over this corpus, whichprovide a baseline for future work on statisticalfunction identification and CD.
22 A Logical Foundation for CDOn what basis can a CD system conclude that twostatements T and H are contradictory?
Logically,contradiction holds when T |= ?H .
As de Marneffeet al point out, this occurs when T and H containantonyms, negation, or other lexical elements thatsuggest that T and H are directly contradictory.
Butother types of contradictions can only be detectedwith the help of a body of background knowledgeK: In these cases, T and H alone are mutually con-sistent.
That is,T |=\ ?H ?H |=\ ?TA contradiction between T and H arises only inthe context of K. That is:((K ?
T ) |= ?H) ?
((K ?H) |= ?T )Consider the example of Mozart?s birthplace inthe introduction.
To detect a contradiction, a CDsystem must know that A) ?Mozart?
refers to thesame entity in both sentences, that B) ?was born in?denotes a functional relation, and that C) Vienna andSalzburg are inconsistent locations.2The corpus is available at http://www.cs.washington.edu/research/aucontraire/12Of course, world knowledge, and reasoning abouttext, are often uncertain, which leads us to associateprobabilities with a CD system?s conclusions.
Nev-ertheless, the knowledge base K is essential for CD.We now turn to a probabilistic model that helpsus simultaneously estimate the functionality of re-lations (B in the above example) and ambiguity ofargument values (A above).
Section 4 describes theremaining components of AUCONTRAIRE.3 Detecting Functionality and AmbiguityThis section introduces a formal model for comput-ing the probability that a phrase denotes a functionbased on a set of extracted tuples.
An extracted tupletakes the form R(x, y) where (roughly) x is the sub-ject of a sentence, y is the object, and R is a phrasedenoting the relationship between them.
If the re-lation denoted by R is functional, then typically theobject y is a function of the subject x.
Thus, our dis-cussion focuses on this possibility, though the anal-ysis is easily extended to the symmetric case.Logically, a relation R is functional in a vari-able x if it maps it to a unique variable y:?x, y1, y2 R(x, y1) ?
R(x, y2) ?
y1 = y2.
Thus,given a large random sample of ground instances ofR, we could detect with high confidence whether Ris functional.
In text, the situation is far more com-plex due to ambiguity, polysemy, synonymy, andother linguistic phenomena.
Deciding whether R isfunctional becomes a probabilistic assessment basedon aggregated textual evidence.The main evidence that a relation R(x, y) is func-tional comes from the distribution of y values fora given x value.
If R denotes a function and x isunambiguous, then we expect the extractions to bepredominantly a single y value, with a few outliersdue to noise.
We aggregate the evidence that R islocally functional for a particular x value to assesswhether R is globally functional for all x.We refer to a set of extractions with the samerelation R and argument x as a contradiction setR(x, ?).
Figure 1 shows three example contradic-tion sets.
Each example illustrates a situation com-monly found in our data.
Example A in Figure 1shows strong evidence for a functional relation.
66out of 70 TEXTRUNNER extractions for was born in(Mozart, PLACE) have the same y value.
An am-biguous x argument, however, can make a func-tional relation appear non-functional.
Example Bdepicts a distribution of y values that appears lessfunctional due to the fact that ?John Adams?
refersto multiple, distinct real-world individuals with thatname.
Finally, example C exhibits evidence for anon-functional relation.A.
was born in(Mozart, PLACE):Salzburg(66), Germany(3), Vienna(1)B. was born in(John Adams, PLACE):Braintree(12), Quincy(10), Worcester(8)C. lived in(Mozart, PLACE):Vienna(20), Prague(13), Salzburg(5)Figure 1: Functional relations such as example A have adifferent distribution of y values than non-functional rela-tions such as C. However, an ambiguous x argument as inB, can make a functional relation appear non-functional.3.1 Formal Model of Functions in TextTo decide whether R is functional in x for all x,we first consider how to detect whether R is lo-cally functional for a particular value of x.
The localfunctionality of R with respect to x is the probabil-ity that R is functional estimated solely on evidencefrom the distribution of y values in a contradictionset R(x, ?
).To decide the probability that R is a function, wedefine global functionality as the average local func-tionality score for each x, weighted by the probabil-ity that x is unambiguous.
Below, we outline an EM-style algorithm that alternately estimates the proba-bility that R is functional and the probability that xis ambiguous.Let R?x indicate the event that the relation R islocally functional for the argument x, and that x islocally unambiguous for R. Also, let D indicatethe set of observed tuples, and define DR(x,?)
as themulti-set containing the frequencies for extractionsof the form R(x, ?).
For example the distribution ofextractions from Figure 1 for example A isDwas born in(Mozart,?)
= {66, 3, 1}.Let ?fR be the probability that R(x, ?)
is locallyfunctional for a random x, and let ?f be the vectorof these parameters across all relations R. Likewise,?ux represents the probability that x is locally unam-biguous for random R, and ?u the vector for all x.13We wish to determine the maximum a pos-teriori (MAP) functionality and ambiguity pa-rameters given the observed data D, that isarg max?f ,?u P (?f ,?u|D).
By Bayes Rule:P (?f ,?u|D) =P (D|?f ,?u)P (?f ,?u)P (D)(1)We outline a generative model for the data,P (D|?f ,?u).
Let us assume that the event R?x de-pends only on ?fR and ?ux , and further assume thatgiven these two parameters, local ambiguity and lo-cal functionality are conditionally independent.
Weobtain the following expression for the probabilityof R?x given the parameters:P (R?x|?f ,?u) = ?fR?uxWe assume each set of data DR(x,?)
is gener-ated independently of all other data and parameters,given R?x.
From this and the above we have:P (D|?f ,?u) =?R,x(P (DR(x,?
)|R?x)?fR?ux+P (DR(x,?)|?R?x)(1?
?fR?ux))(2)These independence assumptions allow us to ex-press P (D|?f ,?u) in terms of distributions overDR(x,?)
given whether or not R?x holds.
We use theURNS model as described in (Downey et al, 2005)to estimate these probabilities based on binomialdistributions.
In the single-urn URNS model that weutilize, the extraction process is modeled as draws oflabeled balls from an urn, where the labels are eithercorrect extractions or errors, and different labels canbe repeated on varying numbers of balls in the urn.Let k = maxDR(x,?
), and let n =?DR(x,?
);we will approximate the distribution over DR(x,?
)in terms of k and n. If R(x, ?)
is locally func-tional and unambiguous, there is exactly one cor-rect extraction label in the urn (potentially repeatedmultiple times).
Because the probability of correct-ness tends to increase with extraction frequency, wemake the simplifying assumption that the most fre-quently extracted element is correct.3 In this case, kis the number of correct extractions, which by the3As this assumption is invalid when there is not a uniquemaximal element, we default to the prior P (R?x) in that case.URNS model has a binomial distribution with pa-rameters n and p, where p is the precision of the ex-traction process.
If R(x, ?)
is not locally functionaland unambiguous, then we expect k to typically takeon smaller values.
Empirically, the underlying fre-quency of the most frequent element in the?R?x casetends to follow a Beta distribution.Under the model, the probability of the evidencegiven R?x is:P (DR(x,?
)|R?x) ?
P (k, n|R?x) =(nk)pk(1?
p)n?kAnd the probability of the evidence given ?R?x is:P (DR(x,?
)|?R?x) ?
P (k, n|?R?x)=(nk) ?
10p?k+?f?1(1?p?
)n+?f?1?kB(?f ,?f )dp?=(nk)?(n?
k + ?f )?
(?f + k)B(?f , ?f )?
(?f + ?f + n)(3)where n is the sum over DR(x,?
), ?
is the Gammafunction and B is the Beta function.
?f and ?f arethe parameters of the Beta distribution for the ?R?xcase.
These parameters and the prior distributionsare estimated empirically, based on a sample of thedata set of relations described in Section 5.1.3.2 Estimating Functionality and AmbiguitySubstituting Equation 3 into Equation 2 and apply-ing an appropriate prior gives the probability of pa-rameters ?f and ?u given the observed data D.However, Equation 2 contains a large product ofsums?with two independent vectors of coefficients,?f and ?u?making it difficult to optimize analyti-cally.If we knew which arguments were ambiguous,we would ignore them in computing the function-ality of a relation.
Likewise, if we knew which rela-tions were non-functional, we would ignore them incomputing the ambiguity of an argument.
Instead,we initialize the ?f and ?u arrays randomly, andthen execute an algorithm similar to Expectation-Maximization (EM) (Dempster et al, 1977) to arriveat a high-probability setting of the parameters.Note that if ?u is fixed, we can compute the ex-pected fraction of locally unambiguous arguments xfor which R is locally functional, using DR(x?,?)
and14Equation 3.
Likewise, for fixed ?f , for any givenx we can compute the expected fraction of locallyfunctional relations R that are locally unambiguousfor x.Specifically, we repeat until convergence:1.
Set ?fR =1sR?x P (R?x|DR(x,?
))?ux for all R.2.
Set ?ux =1sx?R P (R?x|DR(x,?
))?fR for all x.In both steps above, the sums are taken over onlythose x or R for which DR(x,?)
is non-empty.
Also,the normalizer sR =?x ?ux and likewise sx =?R ?fR.As in standard EM, we iteratively update our pa-rameter values based on an expectation computedover the unknown variables.
However, we alter-nately optimize two disjoint sets of parameters (thefunctionality and ambiguity parameters), rather thanjust a single set of parameters as in standard EM.Investigating the optimality guarantees and conver-gence properties of our algorithm is an item of futurework.By iteratively setting the parameters to the expec-tations in steps 1 and 2, we arrive at a good settingof the parameters.
Section 5.2 reports on the perfor-mance of this algorithm in practice.4 System OverviewAUCONTRAIRE identifies phrases denoting func-tional relations and utilizes these to find contradic-tory assertions in a massive, open-domain corpus oftext.AUCONTRAIRE begins by finding extractions ofthe form R(x, y), and identifies a set of relationsR that have a high probability of being functional.Next, AUCONTRAIRE identifies contradiction setsof the form R(x, ?).
In practice, most contradictionsets turned out to consist overwhelmingly of seem-ing contradictions?assertions that do not actuallycontradict each other for a variety of reasons thatwe enumerate in section 4.3.
Thus, a major chal-lenge for AUCONTRAIRE is to tease apart whichpairs of assertions in R(x, ?)
represent genuine con-tradictions.Here are the main components of AUCONTRAIREas illustrated in Figure 2:Extractor: Create a set of extracted assertions Efrom a large corpus of Web pages or other docu-ments.
Each extraction R(x, y) has a probability pFigure 2: AUCONTRAIRE architectureof being correct.Function Learner: Discover a set of functional re-lations F from among the relations in E .
Assign toeach relation in F a probability pf that it is func-tional.Contradiction Detector: Query E for assertionswith a relation R in F , and identify sets C of po-tentially contradictory assertions.
Filter out seemingcontradictions in C by reasoning about synonymy,meronymy, argument types, and argument ambigu-ity.
Assign to each potential contradiction a proba-bility pc that it is a genuine contradiction.4.1 Extracting Factual AssertionsAUCONTRAIRE needs to explore a large set offactual assertions, since genuine contradictions arequite rare (see Section 5).
We used a set of extrac-tions E from the Open Information Extraction sys-tem, TEXTRUNNER (Banko et al, 2007), which wasrun on a set of 117 million Web pages.TEXTRUNNER does not require a pre-defined setof relations, but instead uses shallow linguistic anal-ysis and a domain-independent model to identifyphrases from the text that serve as relations andphrases that serve as arguments to that relation.TEXTRUNNER creates a set of extractions in a sin-gle pass over the Web page collection and providesan index to query the vast set of extractions.Although its extractions are noisy, TEXTRUNNERprovides a probability that the extractions are cor-15rect, based in part on corroboration of facts fromdifferent Web pages (Downey et al, 2005).4.2 Finding Potential ContradictionsThe next step of AUCONTRAIRE is to find contra-diction sets in E .We used the methods described in Section 3 toestimate the functionality of the most frequent rela-tions in E .
For each relation R that AUCONTRAIREhas judged to be functional, we identify contradic-tion sets R(x, ?
), where a relation R and domain ar-gument x have multiple range arguments y.4.3 Handling Seeming ContradictionsFor a variety of reasons, a pair of extractionsR(x, y1) and R(x, y2) may not be actually contra-dictory.
The following is a list of the major sourcesof false positives?pairs of extractions that are notgenuine contradictions, and how they are handledby AUCONTRAIRE.
The features indicative of eachcondition are combined using Logistic Regression,in order to estimate the probability that a given pair,{R(x, y1), R(x, y2)} is a genuine contradiction.Synonyms: The set of potential contradictionsdied from(Mozart,?)
may contain assertions thatMozart died from renal failure and that he died fromkidney failure.
These are distinct values of y, butdo not contradict each other, as the two terms aresynonyms.
AUCONTRAIRE uses a variety of knowl-edge sources to handle synonyms.
WordNet is a re-liable source of synonyms, particularly for commonnouns, but has limited recall.
AUCONTRAIRE alsoutilizes synonyms generated by RESOLVER (Yatesand Etzioni, 2007)?
a system that identifies syn-onyms from TEXTRUNNER extractions.
Addition-ally, AUCONTRAIRE uses edit-distance and token-based string similarity (Cohen et al, 2003) betweenapparently contradictory values of y to identify syn-onyms.Meronyms: For some relations, there is no con-tradiction when y1 and y2 share a meronym,i.e.
?part of?
relation.
For example, in the setborn in(Mozart,?)
there is no contradiction be-tween the y values ?Salzburg?
and ?Austria?, but?Salzburg?
conflicts with ?Vienna?.
Although thisis only true in cases where y occurs in an up-ward monotone context (MacCartney and Manning,2007), in practice genuine contradictions betweeny-values sharing a meronym relationship are ex-tremely rare.
We therefore simply assigned contra-dictions between meronyms a probability close tozero.
We used the Tipster Gazetteer4 and WordNetto identify meronyms, both of which have high pre-cision but low coverage.Argument Typing: Two y values are not contra-dictory if they are of different argument types.
Forexample, the relation born in can take a date or alocation for the y value.
While a person can beborn in only one year and in only one city, a per-son can be born in both a year and a city.
To avoidsuch false positives, AUCONTRAIRE uses a sim-ple named-entity tagger5 in combination with largedictionaries of person and location names to as-sign high-level types (person, location, date, other)to each argument.
AUCONTRAIRE filters out ex-tractions from a contradiction set that do not havematching argument types.Ambiguity: As pointed out in Section 3, false con-tradictions arise when a single x value refers to mul-tiple real-world entities.
For example, if the con-tradiction set born in(John Sutherland, ?)
includesbirth years of both 1827 and 1878, is one of these amistake, or do we have a grandfather and grandsonwith the same name?
AUCONTRAIRE computes theprobability that an x value is unambiguous as partof its Function Learner (see Section 3).
An x valuecan be identified as ambiguous if its distribution ofy values is non-functional for multiple functional re-lations.If a pair of extractions, {R(x, y1), R(x, y2)}, doesnot fall into any of the above categories and R isfunctional, then it is likely that the sentences under-lying the extractions are indeed contradictory.
Wecombined the various knowledge sources describedabove using Logistic Regression, and used 10-foldcross-validation to automatically tune the weightsassociated with each knowledge source.
In addi-tion, the learning algorithm also utilizes the follow-ing features:?
Global functionality of the relation, ?fR?
Global unambiguity of x, ?ux4http://crl.nmsu.edu/cgi-bin/Tools/CLR/clrcat5http://search.cpan.org/?simon/Lingua-EN-NamedEntity-1.1/NamedEntity.pm16?
Local functionality of R(x, ?)?
String similarity (a combination of token-basedsimilarity and edit-distance) between y1 and y2?
The argument types (person, location, date, orother)The learned model is then used to estimate howlikely a potential contradiction {R(x, y1), R(x, y2)}is to be genuine.5 Experimental ResultsWe evaluated several aspects of AUCONTRAIRE:its ability to detect functional relations and to de-tect ambiguous arguments (Section 5.2); its preci-sion and recall in contradiction detection (Section5.3); and the contribution of AUCONTRAIRE?s keyknowledge sources (Section 5.4).5.1 Data SetTo evaluate AUCONTRAIRE we used TEXTRUN-NER?s extractions from a corpus of 117 million Webpages.
We restricted our data set to the 1,000 mostfrequent relations, in part to keep the experimentstractable and also to ensure sufficient statistical sup-port for identifying functional relations.We labeled each relation as functional or not,and computed an estimate of the probability it isfunctional as described in section 3.2.
Section 5.2presents the results of the Function Learner on thisset of relations.
We took the top 2% (20 relations)as F , the set of functional relations in our exper-iments.
Out of these, 75% are indeed functional.Some examples include: was born in, died in, andwas founded by.There were 1.2 million extractions for all thou-sand relations, and about 20,000 extractions in 6,000contradiction sets for all relations in F .We hand-tagged 10% of the contradiction setsR(x, ?)
where R ?
F , discarding any sets with over20 distinct y values since the x argument for thatset is almost certainly ambiguous.
This resulted in adata set of 567 contradiction sets containing a totalof 2,564 extractions and 8,844 potentially contradic-tory pairs of extractions.We labeled each of these 8,844 pairs as contradic-tory or not.
In each case, we inspected the originalsentences, and if the distinction was unclear, con-sulted the original source Web pages, Wikipedia ar-ticles, and Web search engine results.In our data set, genuine contradictions over func-tional relations are surprisingly rare.
We found only110 genuine contradictions in the hand-tagged sam-ple, only 1.2% of the potential contradiction pairs.5.2 Detecting Functionality and AmbiguityWe ran AUCONTRAIRE?s EM algorithm on thethousand most frequent relations.
Performance con-verged after 5 iterations resulting in estimates of theprobability that each relation is functional and eachx argument is unambiguous.
We used these proba-bilities to generate the precision-recall curves shownin Figure 3.The graph on the left shows results for function-ality, while the graph on the right shows precision atfinding unambiguous arguments.
The solid lines areresults after 5 iterations of EM, and the dashed linesare from computing functionality or ambiguity with-out EM (i.e.
assuming uniform values of ?c whencomputing ?f and vice versa).
The EM algorithmimproved results for both functionality and ambigu-ity, increasing area under curve (AUC) by 19% forfunctionality and by 31% for ambiguity.Of course, the ultimate test of how well AUCON-TRAIRE can identify functional relations is how wellthe Contradiction Detector performs on automati-cally identified functional relations.5.3 Detecting ContradictionsWe conducted experiments to evaluate how wellAUCONTRAIRE distinguishes genuine contradic-tions from false positives.The bold line in Figure 4 depicts AUCONTRAIREperformance on the distribution of contradictionsand seeming contradictions found in actual Webdata.
The dashed line shows the performance of AU-CONTRAIRE on an artificially ?balanced?
data setthat we constructed to contain 50% genuine contra-dictions and 50% seeming ones.Previous research in CD presented results onmanually selected data sets with a relatively bal-anced mix of positive and negative instances.
AsFigure 4 suggests, this is a much easier problem thanCD ?in the wild?.
The data gathered from the Webis badly skewed, containing only 1.2% genuine con-tradictions.17FunctionalityRecallPrecision0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0AuContraireNo IterationAmbiguityRecallPrecision0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0AuContraireNo IterationFigure 3: After 5 iterations of EM, AUCONTRAIRE achieves a 19% boost to area under the precision-recall curve(AUC) for functionality detection, and a 31% boost to AUC for ambiguity detection.RecallPrecision0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Web DistributionBalanced DataFigure 4: Performance of AUCONTRAIRE at distinguish-ing genuine contradictions from false positives.
The boldline is results on the actual distribution of data from theWeb.
The dashed line is from a data set constructed tohave 50% positive and 50% negative instances.5.4 Contribution of Knowledge SourcesWe carried out an ablation study to quantify howmuch each knowledge source contributes to AU-CONTRAIRE?s performance.
Since most of theknowledge sources do not apply to numeric argu-ment values, we excluded the extractions where yis a number in this study.
As shown in Figure 5,performance of AUCONTRAIRE degrades with noknowledge of synonyms (NS), with no knowledgeof meronyms (NM), and especially without argu-ment typing (NT).
Conversely, improvements to anyof these three components would likely improve theperformance of AUCONTRAIRE.The relatively small drop in performance fromno meronyms does not indicate that meronyms arenot essential to our task, only that our knowledgesources for meronyms were not as useful as wehoped.
The Tipster Gazetteer has surprisingly lowcoverage for our data set.
It contains only 41% ofthe y values that are locations.
Many of these arematches on a different location with the same name,which results in incorrect meronym information.
Weestimate that a gazetteer with complete coveragewould increase area under the curve by approxi-mately 40% compared to a system with meronymsfrom the Tipster Gazetteer and WordNet.AuContraire NS NM NTPercentage AUC020406080100Figure 5: Area under the precision-recall curve for thefull AUCONTRAIRE and for AUCONTRAIRE with knowl-edge removed.
NS has no synonym knowledge; NM hasno meronym knowledge; NT has no argument typing.To analyze the errors made by AUCONTRAIRE,we hand-labeled all false-positives at the point ofmaximum F-score: 29% Recall and 48% Precision.18Figure 6 reveals the central importance of worldknowledge for the CD task.
About half of the errors(49%) are due to ambiguous x-arguments, which wefound to be one of the most persistent obstacles todiscovering genuine contradictions.
A sizable por-tion is due to missing meronyms (34%) and missingsynonyms (14%), suggesting that lexical resourceswith broader coverage than WordNet and the TipsterGazetteer would substantially improve performance.Surprisingly, only 3% are due to errors in the extrac-tion process.Extraction Errors (3%)Missing Synonyms (14%)Missing Meronyms (34%)Ambiguity (49%)Figure 6: Sources of errors in contradiction detection.All of our experimental results are based on theautomatically discovered set of functions F .
Wewould expect AUCONTRAIRE?s performance to im-prove substantially if it were given a large set offunctional relations as input.6 Related WorkCondoravdi et al (2003) first proposed contradictiondetection as an important NLP task, and Harabagiuet al (2006) were the first to report results on con-tradiction detection using negation, although theirevaluation corpus was a balanced data set builtby manually negating entailments in a data setfrom the Recognizing Textual Entailment confer-ences (RTE) (Dagan et al, 2005).
De Marneffe etal.
(2008) reported experimental results on a contra-diction corpus created by annotating the RTE datasets.RTE-3 included an optional task, requiring sys-tems to make a 3-way distinction: {entails, contra-dicts, neither} (Voorhees, 2008).
The average per-formance for contradictions on the RTE-3 was preci-sion 0.11 at recall 0.12, and the best system had pre-cision 0.23 at recall 0.19.
We did not run AUCON-TRAIRE on the RTE data sets because they containedrelatively few of the ?functional contradictions?
thatAUCONTRAIRE tackles.
On our Web-based datasets, we achieved a precision of 0.62 at recall 0.19,and precision 0.92 at recall 0.51 on the balanced dataset.
Of course, comparisons across very differentdata sets are not meaningful, but merely serve to un-derscore the difficulty of the CD task.In contrast to previous work, AUCONTRAIRE isthe first to do CD on data automatically extractedfrom the Web.
This is a much harder problem thanusing an artificially balanced data set, as shown inFigure 4.Automatic discovery of functional relations hasbeen addressed in the database literature as Func-tional Dependency Mining (Huhtala et al, 1999;Yao and Hamilton, 2008).
This focuses on dis-covering functional relationships between sets of at-tributes, and does not address the ambiguity inherentin natural language.7 Conclusions and Future WorkWe have described a case study of contradiction de-tection (CD) based on functional relations.
In thiscontext, we introduced and evaluated the AUCON-TRAIRE system and its novel EM-style algorithmfor determining whether an arbitrary phrase is func-tional.
We also created a unique ?natural?
data setof seeming contradictions based on sentences drawnfrom a Web corpus, which we make available to theresearch community.We have drawn two key lessons from our casestudy.
First, many seeming contradictions (approx-imately 99% in our experiments) are not genuinecontradictions.
Thus, the CD task may be muchharder on natural data than on RTE data as sug-gested by Figure 4.
Second, extensive backgroundknowledge is necessary to tease apart seeming con-tradictions from genuine ones.
We believe that theselessons are broadly applicable, but verification ofthis claim is a topic for future work.AcknowledgementsThis research was supported in part by NSF grantsIIS-0535284 and IIS-0312988, ONR grant N00014-08-1-0431 as well as gifts from the Utilika Founda-tion and Google, and was carried out at the Univer-sity of Washington?s Turing Center.19ReferencesM.
Banko and O. Etzioni.
2008.
The tradeoffs betweentraditional and open relation extraction.
In Proceed-ings of ACL.M.
Banko, M. Cafarella, S. Soderland, M. Broadhead,and O. Etzioni.
2007.
Open information extractionfrom the Web.
In Procs.
of IJCAI.W.W.
Cohen, P. Ravikumar, and S.E.
Fienberg.
2003.A comparison of string distance metrics for name-matching tasks.
In IIWeb.Cleo Condoravdi, Dick Crouch, Valeria de Paiva, Rein-hard Stolle, and Daniel G. Bobrow.
2003.
Entailment,intensionality and text understanding.
In Proceedingsof the HLT-NAACL 2003 workshop on Text meaning,pages 38?45, Morristown, NJ, USA.
Association forComputational Linguistics.I.
Dagan, O. Glickman, and B. Magnini.
2005.
ThePASCAL Recognising Textual Entailment Challenge.Proceedings of the PASCAL Challenges Workshop onRecognising Textual Entailment, pages 1?8.Marie-Catherine de Marneffe, Anna Rafferty, andChristopher D. Manning.
2008.
Finding contradic-tions in text.
In ACL 2008.A.P.
Dempster, N.M. Laird, and D.B.
Rubin.
1977.
Max-imum likelihood from incomplete data via the EM al-gorithm.
Journal of the Royal Statistical Society Se-ries B, 39(1):1?38.D.
Downey, O. Etzioni, and S. Soderland.
2005.
A Prob-abilistic Model of Redundancy in Information Extrac-tion.
In Procs.
of IJCAI.Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.2006.
Negation, contrast and contradiction in text pro-cessing.
In AAAI.Yka?
Huhtala, Juha Ka?rkka?inen, Pasi Porkka, and HannuToivonen.
1999.
TANE: An efficient algorithm fordiscovering functional and approximate dependencies.The Computer Journal, 42(2):100?111.B.
MacCartney and C.D.
Manning.
2007.
Natural Logicfor Textual Inference.
In Workshop on Textual Entail-ment and Paraphrasing.Ellen M. Voorhees.
2008.
Contradictions and justifica-tions: Extensions to the textual entailment task.
InProceedings of ACL-08: HLT, pages 63?71, Colum-bus, Ohio, June.
Association for Computational Lin-guistics.Hong Yao and Howard J. Hamilton.
2008.
Mining func-tional dependencies from data.
Data Min.
Knowl.
Dis-cov., 16(2):197?219.A.
Yates and O. Etzioni.
2007.
Unsupervised resolutionof objects and relations on the Web.
In Procs.
of HLT.20
