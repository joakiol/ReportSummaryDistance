Building a Web-based parallel corpus and filtering out machine-translated textAlexandra Antonova, Alexey MisyurevYandex16, Leo Tolstoy St., Moscow, Russia{antonova, misyurev}@yandex-team.ruAbstractWe describe a set of techniques that havebeen developed while collecting paralleltexts for Russian-English language pair andbuilding a corpus of parallel sentences fortraining a statistical machine translationsystem.
We discuss issues of verifyingpotential parallel texts and filtering outautomatically translated documents.
Finallywe evaluate the quality of the 1-million-sentence corpus which we believe may be auseful resource for machine translationresearch.1 IntroductionThe Russian-English language pair is rarely usedin statistical machine translation research, becausethe number of freely available bilingual corpora forRussian-English language pair is very smallcompared to European languages.
Availablebilingual corpora1 often belong to a specific genre(software documentation, subtitles) and requireadditional processing for conversion to a commonformat.
At the same time many Russian websitescontain pages translated to or from English.Originals or translations of these documents canalso be found in the Internet.
By our preliminaryestimates these bilingual documents may yieldmore than 100 million unique parallel sentences1e.g.
http://opus.lingfil.uu.se/while it is still a difficult task to find and extractthem.The task of unrestricted search of paralleldocuments all over the Web including content-based search is seldom addressed by researchers.At the same time the properties of the set ofpotential parallel texts found in that way are notwell investigated.
Building a parallel corpus ofhigh quality from that kind of raw data is notstraightforward because of low initial precision,frequent embedding of nonparallel fragments inparallel texts, and low-quality parallel texts.
In thispaper we address the tasks of verification ofparallel documents, extraction of the best parallelfragments and filtering out automatically translatedtexts.Mining parallel texts from a big documentcollection usually involves three phases:?
Detecting a set of potential paralleldocument pairs with fast but low-precisionalgorithms?
Pairwise verification procedure?
Further filtering of unwanted texts, e.g.automatically translated textsFinding potential parallel texts in a collection ofweb documents is a challenging task that does notyet have a universal solution.
There exist methodsbased on the analysis of meta-information (Ma andLiberman, 1999; Resnik, 2003; Mohler andMihalcea, 2008, Nadeau and Foster 2004), such asURL similarity, HTML markup, publication dateand time.
More complicated methods are aimed at136Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 136?144,49th Annual Meeting of the Association for Computational Linguistics,Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguisticsdetecting potential parallel texts by their content.In this case mining of parallel documents in theInternet can be regarded as the task of near-duplicate detection (Uszkoreit et al, 2010).
All ofthe above mentioned approaches are useful as eachof them is able to provide some document pairsthat are not found by other methods.In our experiments, fast algorithms of the firstphase classify every pair of documents as parallelwith very low precision, from 20% to 0.001%.That results in a huge set of candidate pairs ofdocuments, for which we must decide if they areactually parallel or not.
For example, if we need toget 100 000 really parallel documents we shouldcheck from 500 thousand to 100 million pairs.
Thelarge number of pairwise comparisons to be madeimplies that the verification procedure must be fastand scalable.
Our approach is based on a sentence-alignment algorithm similar to (Brown et al, 1991;Gale and Church, 1993; Chen, 1993; Moore 2002;Ma, 2006) but it is mainly aimed at achieving highprecision rather than high recall.
The algorithm isable to extract parallel fragments from comparabledocuments, as web documents often are not exactlyparallel.
The similarity estimate relies onprobabilistic dictionary trained on initial parallelcorpus and may improve when the corpus grows.Due to growing popularity of machinetranslation systems, Russian websites are beingincreasingly filled with texts that are translatedautomatically.
According to selective manualannotation the share of machine translation amongthe texts that have passed the verificationprocedure is 25-35%.
Machine-translatedsentences  often demonstrate better wordcorrespondence than human-translated sentencesand are easier to align, but the longer phrasesextracted from them are likely to be unnatural andmay confuse the statistical translation system at thetraining stage.
The large share of automaticallytranslated data decreases the value of the corpus,especially if it is intended for research.
Also it willmake it difficult to outperform the translationquality of the system which generated thosesentences.To the best of our knowledge, there is noexisting research concerning the task of filteringout machine translation.
Our filtering method isbased on a special decoding algorithm thattranslates sentence-aligned document and thenscores the output against the reference documentwith BLEU metric.
This method allows reducingthe number of automatically translated texts to 5%in the final corpus.Our final goal is to build a quality corpus ofparallel sentences appropriate for training astatistical machine translation system.
We evaluatethe 1-million-sentence part of our corpus bytraining a phrase-based translation system (Koehnet al, 2007) on these sentences and compare theresults with the results of training on noisy data,containing automatically translated texts as its part.The rest of the paper is organized as follows:Section 2 provides an overview of the systemarchitecture and addresses specific problems at thepreparatory stage.
Section 3 describes thesentence-alignment algorithm and the pairwiseverification procedure.
The algorithm makes use ofstatistical dictionaries trained beforehand.
InSection 4 we discuss the problem of filtering outautomatically translated texts.
In Section 5 weevaluate the quality of the final parallel corpus andprovide some statistical information aboutRussian-English language pair.
We conclude inSection 6 with short summary remarks.2 System descriptionThe corpus building procedure includes severalstages represented in Figure 1.
Initial trainingprovides bilingual probabilistic dictionaries whichare used in sentence alignment and verification ofpotential parallel texts.
We used Russian/Englishcorrespondent pages from a number of bilingualweb-sites of good quality.
We performed robustalignment based on sentence lengths as in (Galeand Church, 1993).
The obtained probabilisticdictionaries were gradually improved in a sort of abootstrapping procedure when the corpus sizeincreased.Our main source of Web documents are webpages from search engine database with theirtextual contents already extracted and sentenceboundaries detected.
Nevertheless documents ofteninclude sentences that are site-specific and carrysome meta-information, advertising, or just somenoise.
When often repeated such sentences mayconfuse statistical training, so we choose to deletesubsequent sentences that have been encounteredrecently.137Figure 1.
Corpus building procedure.In morphologically rich languages nouns, verbsand adjectives have many different forms in text,which complicates statistical training, especiallywhen the initial collection is comparatively small.At the same time, the task of sentence alignmentrelies on robust algorithms which allow for somedata simplification.
Word stemming, truncation ofword endings and lemmatization may be used toreduce the data sparseness problem when dealingwith morphologically rich languages.
The accuratelemmatization algorithms for Russian language arecomplicated and comparatively slow because theyshould resolve morphological ambiguity as manyword forms have more than one possible lemma.We chose a simple and fast algorithm ofprobabilistic lemmatization where a word is alwaysassigned the most frequent of its possible lemmas.There are several reasons why it is appropriate forthe task of sentence and word alignment:?
The algorithm runs almost as fast as theword truncation method, and in most casesit yields correct lemmas.?
Most of the information is contained inlow-frequency words and those are usuallyless ambiguous than the frequent words.?
Individual mistakes in lemmatization donot necessarily result in wrong similarityestimation for the whole sentence.3 Verification of potential paralleldocumentsPotential parallel documents are a pair of texts;each of them represents the textual content of someHTML page.
The size of texts may vary fromseveral sentences to several thousand sentences.Our approach to the task of verification ofpotential parallel documents is motivated by theproperties of the set of potential parallel texts,which is the output of different search algorithmsincluding unrestricted content-based search overthe Web.The first problem is that most of the potentialparallel texts on the Web, even if they prove tohave parallel fragments, often contain non-parallelfragments as well, especially at the beginning or atthe end.
Since the parallel fragment can be locatedanywhere in the document pair, the verificationalgorithm performs exhaustive dynamicprogramming search within the entire documentand not only within a fixed width band around themain diagonal.
Our similarity measure reliesheavily on features derived from the sentencealignment of the best parallel fragment and doesnot utilize any information from the rest of the text.We allow that the parallel fragment begins andends anywhere in the text and also it is possible toskip one or several sentences without breaking thefragment.We have also considered the possibility thatdocuments can contain more than one parallelfragment separated by greater non-parallelfragments.
Though such documents do exist, thecontribution of lesser parallel fragments to parallelcorpus is insignificant compared to much simplercase where each pair of documents can containonly one parallel fragment.The second problem of the input data is lowinitial precision of potential parallel texts and thefact that there are many comparable but notparallel texts.
It is worth noting that the marginaland joint probabilities of words and phrases in the138set of documents with similar content may differsubstantially from the probabilities obtained fromthe parallel corpus of random documents.
For thisreason we cannot completely rely on statisticalmodels trained on the initial parallel corpus.
It isimportant to have a similarity measure that allowsfor additional adjustment in order to take intoaccount the probability distributions in thepotential parallel texts found by different searchalgorithms.The third problem is the large number ofpairwise comparisons to be made.
It requires thatthe verification procedure must be fast andscalable.
Due to the fact that the system usesprecomputed probabilistic dictionaries, each pair ofdocuments can be processed independently andthis stage fits well into the MapReduce framework(Dean and Ghemawat, 2004).
For example,verification of 40 million pairs of potential paralleltexts took only 35 minutes on our 250-nodecluster.The algorithm of verifying potential paralleldocuments takes two texts as input and tries to findthe best parallel fragment, if there is any, byapplying a dynamic programming search ofsentence alignment.
We use sentence-alignmentalgorithm for handling four tasks:?
Search of parallel fragments in pairs?
Verification of parallel document pairs?
Search of per-sentence alignment?
Filtering out sentences that are notcompletely parallelEach sentence pair is scored using a similaritymeasure that makes use of two sources of priorstatistical information:?
Probabilistic phrase dictionary, consistingof phrases up to two words?
Empirical distribution of lengths ofRussian/English parallel sentencesBoth have been obtained using initial parallelcorpus.
In a sort of bootstrapping procedure onecan recalculate that prior statistical information assoon as a bigger parallel corpus is collected andthen realign the input texts.The algorithm neither attempts to find a wordalignment between two sentences, nor it tries totranslate the sentence as in (Uszkoreit et al,2010).
Instead, it takes account of all phrases fromprobabilistic dictionary that are applicable to agiven pair of sentences disregarding position in thesentence or phrase intersection.
Our probabilisticdictionar?
consists of 70?000 phrase translations of1 or 2 words.Let S and T be the set of source/target parts ofphrases from a probabilistic dictionary, andTSE ??
- the set of ordered pairs, representingthe source-target dictionary entries ?
?ts, .
Let thesource sentence contain phrases SS ?0 and thetarget sentence contain phrases TT ?0 .
Then thesimilarity between the two sentences is estimatedby taking the following factors into account:?
?
?tsp | , ?
?stp | , translation probabilities;?
TS lenlen , , length of source and targetsentences;?
?
?TS lenlenp ,log ?
, the empiricaldistribution of length correspondencebetween source and target sentences.The factors are log-linearly combined and thefactor weights are tuned on the small developmentset containing 700 documents.
We choose theweights so that the result of comparison ofnonparallel sentences is usually negative.
As aresult of the search procedure we choose a parallelfragment with the biggest score.
If that score isabove a certain threshold the parallel fragment isextracted, otherwise the whole document isconsidered to be nonparallel.Relative sentence order is usually preserved inparallel texts, though some local transformationsmay have been introduced by the translator, suchas sentence splitting, merge or swap.
Thoughsentence-alignment programs usually try to detectsome of those transformations, we decided toignore them for several reasons:?
Split sentences are not well suited to traina phrase-based translation system.?
One part of a split sentence can still bealigned with its whole translation as one-to-one correspondence.?
Cases of sentence swap are too rare tojustify efforts needed to detect them.1394 Filtering out machine translationAfter the verification procedure and sentence-alignment procedure our collection consists ofsentence-aligned parallel fragments extracted frominitial documents.
A closer look at the parallelfragments reveals that some texts contain mistakestypically made by machine translation systems.
Itis undesirable to include such documents into thecorpus, because a phrase-based translation systemtrained on this corpus may learn a great deal ofbadly constructed phrases.The output of a rule-based system can berecognized without even considering its sourcetext, as having no statistical information to rely on,the rule-based systems tend to choose the safestway of saying something, which leads touncommonly frequent use of specific words andphrases.
The differences in n-gram distributionscan be captured by comparing the probabilitiesgiven by two language models: one trained on acollection of the outputs of a rule-based system andthe other ?
on normal texts.Our method of filtering out statistical machinetranslation is based on the similarity of algorithmsof building phrase tables in the existing SMTsystems.
Those systems also have restrictions onreordering of words.
Therefore their output isdifferent from human translation, and thisdifference can be measured and serve as anindicator of a machine translated text.
We designeda special version of phrase-based decodingalgorithm whose goal was not just translate, but toprovide a translation as close to the reference aspossible while following the principles of phrase-based translation.
The program takes two sentence-aligned documents as an input.
Prior to translatingeach sentence, a special language model is builtconsisting of n-grams from the reference sentence.That model serves as a sort of soft constraint on theresult of translation.
The decoder output is scoredagainst reference translation with the BLEU metric(Papineni et al, 2002) - we shall call it r-bleu forthe rest of this section.
The idea is that the higher isr-bleu, the more likely the reference is statisticaltranslation itself.The program was implemented based on thedecoder of the statistical phrase-based translationsystem.
The phrase table and the factor weightswere not modified.
Phrase reordering was notallowed.
The phrase table contained 13 millionphrases.
The language model was modified in thefollowing way.
We considered only n-grams nolonger than 4 words and only those that could befound in the reference sentence.
The languagemodel score for each n-gram depended only on itslength.We evaluated the method efficiency as follows.A collection of 245 random parallel fragments hasbeen manually annotated as human or machinetranslation.There are some kinds of typical mistakesindicating that the text is generated by a machinetranslation system.
The most indicative mistake iswrong lexical choice, which can be easilyrecognized by a human annotator.
Additionalevidence are cases of incorrect agreement orunnatural word order.
We considered onlyfragments containing more than 4 parallelsentences, because it was hard to identify theorigin of shorter fragments.
The annotationprovided following results:?
150 documents - human translation (64%of sentences)?
55 documents - English-Russian machinetranslation (22% of sentences)?
32 documents - Russian-English machinetranslation (12% of sentences)?
8 documents - not classified (2% ofsentences)Sometimes it was possible for a humanannotator to tell if a translation has been made by arule-based or phrase-based translation system, butgenerally it was difficult to identify reliably theorigin of a machine translated text.
Also therewere a number of automatically translated textswhich had been post-edited by humans.
Such textsoften preserved unnatural word order and in thatcase they were annotated as automaticallytranslated.The annotation quality was verified by cross-validation.
We took 27 random documents out of245 and compared the results of the annotationwith those performed by another annotator.
Therewas no disagreement in identifying the translationdirection.
There were 4 cases of disagreement inidentifying automatic translation: 3 cases of post-edited machine translation and 1 case of verbatimhuman translation.
We realized that in case of post-140edited machine translation the annotation wassubjective.
Nevertheless, after the question wasdiscussed we decided that the initial annotationwas correct.
Table 1 represents the results of theannotation along with the range of r-bleu score.r-bleu Human Automatic0 - 5 0 05-10 252 010-15 899 015-20 1653 020-25 1762 025-30 1942 15430-35 1387 53835-40 494 96340-45 65 131145-50 76 87150-55 23 65855-60 0 73Total 8553 4568Table 1.
Number of parallel sentences inhuman/machine translated documents dependingon the range of r-bleu score.Let maxhC denote the total number of sentencesin all documents which were annotated as humantranslation.
In our case 8553max ?hC .
LethC denote the number of sentences in humantranslated documents with a r-bleu beyond certainthreshold, and mtC  ?
the number of sentences inautomatically translated documents with a r-bleubeyond the same threshold.
Then recall(R) andprecision(P) are defined asmaxhh CCR ?
, ?
?mthh CCCP ??
.For example, if we discard documents with r-bleu > 33.0, we get R = 90.1, P = 94.1.
Figure 2illustrates the dependency between theseparameters.The evaluation showed that parallel documentsthat have been translated automatically tend to gethigher r-bleu scores and may be filtered out withreasonable precision and recall.
As it is shown inTable 1, the total rate of machine translatedsentence pairs is about 35% before the filtration.According to manual evaluation (see section 5,Table 4), this rate is reduced down to 5% in thefinal corpus.Figure 2.
Dependency between r-bleu score andrecall(R)/precision(P) rates of filtering procedure.We chose the BLEU criterion partly due to itsrobustness.
For the English-Russian language pairit yielded satisfactory results.
We believe that ourapproach is applicable to many other languagepairs as well, probably except the pairs oflanguages with similar word order.
For thoselanguages some other metric is possibly neededtaking into account properties of particularlanguage pair.
We expect that the r-bleu thresholdalso depends on the language pair and has to be re-estimated.5 Corpus of parallel sentencesAfter we choose a threshold value of the r-bleucriterion, we remove texts with the r-bleu scorehigher than the threshold from our collection ofparallel fragments.
Then we extract parallelsentences from the remaining texts in order to get acorpus of parallel sentences.Sentences inside parallel fragments undergosome additional filtering before they can beincluded into the final corpus.
We discard sentencepairs for which a similarity score is below a giventhreshold, or word-length ratio is less than ?.
It isalso useful to drop sentences whose English partcontains Cyrillic symbols as those are extremelyunlikely to be seen in original English texts andtheir presence usually means that the text is a resultof machine translation or some sort of spam.
All141sentence pairs are lowercase and distinct.Sentences of more than 100 words have beenexcluded from the corpus.In the rest of this section we estimate the qualityof a 1-million-sentence part of the final parallelcorpus that we are going to share with the researchcommunity.
The corpus characteristics arerepresented in Table 2 and examples of parallelsentences are given in Table 3.English RussianSentences 1`022`201Distinct sentences 1`016`580 1`013`426Words 27`158`657 25`135`237Distinct words 323`310 651`212Av.
Sent.
Len 26.5 24.6Table 2.
Corpus characteristics: number of parallelsentences, distinct sentences, words2, distinctwords and average sentence length in words.We evaluate corpus quality in two ways:?
Selecting each 5000-th sentence pair fromthe corpus and manually annotating thesentences as parallel or not.
The results ofthe manual annotation are represented inTable 4.?
Training a statistical machine translationsystem on the corpus and testing its outputwith BLEU metricWe trained two phrase-based translationsystems3.
The first system was trained on 1 millionrandom sentences originated in the documentswhich were human translations according to our r-bleu criterion.
The other system was trained on thesame corpus except that 35% of sentences werereplaced to random sentences taken fromdocuments which had been previously excluded asautomatically translated.
We reserved each 1000-thsentence from the first ?clean?
corpus as test data.We get word-alignment by running Giza++ (Och etal., 2000) on lemmatized texts.
The phrase-tabletraining procedure and decoder are the parts ofMoses statistical machine translation system(Koehn et al, 2007).
The language model has been2Punctuation symbols are considered as separate words.3http://www.statmt.org/moses/trained on target side of the first corpus using SRILanguage Modeling Toolkit (Stolcke, 2002).?
2004 ??????
???????????
??
????
????????????
?????????
????????
?, ??????????????????
??
????
??????
?.in 2004 maidan became-famous over allworld due-to orange revolution , which took-place at this place .in 2004, maidan became famous all over theworld because the orange revolution wascentered here.????????
?
??????
?, ???
????
????????????????????
?, ???
??
??????
??????????????????
?, - ??????
???
?.stories about peoples , whose language so-much imperfect , that it should be-suppliedgestures-with , - pure myths .tales about peoples whose language is sodefective that it has to be eked out by gesture,are pure myths.?????????
?????
?????
???
???????????
?, ?????
???
?????????
??????????????
???????
????
!the-rest-of time let they be open , so-that allinhabitants universe-of could see you !the rest of the time, let the doors be open sothat all the residents of the universe may haveaccess to see you."?
???????????
????
??????.
"i control my destiny.
"i control my own destiny.Table 3.
Sample parallel sentences.Parallel 169Parallel including non-parallelfragments19Non-parallel 6English-Russian automatic 4translation7Russian-English automatictranslation3Total sentences 204Table 4.
Results of manual annotation of 204sample sentences from the corpus.4Sentences containing mistakes typical for MT systemswere annotated as automatic translations.142We tested both Russian-to-English and English-to-Russian translation systems on 1022 testsentences varying the language model order fromtrigram to 5-gram.
We have not tuned the weightson the development set of sentences, because webelieve that in this case the quality of translationwould depend on the degree of similarity betweenthe test and development sets of sentences and itwould make our evaluation less reliable.
In allexperiments we used default Moses parameters,except that the maximum reordering parameter wasreduced to 3 instead of 6.
The results arerepresented in Table 5.Ru-En / +mt En-Ru / +mt3-gram 20.97 / +0.06 16.35 / -0.104-gram 21.04 / -0.13 16.33 / -0.135-gram 21.17 / -0.06 16.42 / -0.16OnlineA5 25.38 21.01OnlineB6 23.86 16.56Table 5.
BLEU scores measured on 1022 testsentences depending on the order of languagemodel.
The column +mt shows relative change inBLEU score of the s?stem trained on ?mt-nois?
?data.The overall system performance can beimproved by tuning and/or training a biggerlanguage model, but our goal is only to show towhat extent the corpus itself is suitable for trainingstatistical machine translation system.
Onlinetranslation systems have been tested on the sametest set, except that the input was detokenized andthe output was lowercased.
The online translationcould have been better if the input text was in itsoriginal format - not lowercased.6 ConclusionWe have described our approaches to mainproblems faced when building a parallel Russian-English corpus from the Internet.We have proposed a method of filtering outautomatically translated texts.
It allowed us toreduce the rate of sentence pairs that originate frommachine translated documents from 35% to 5%.The approach relies on general properties of the5http://translate.google.ru/6http://www.microsofttranslator.com/state-of-the-art statistical translation systems andtherefore is applicable to many other languagepairs.We presented results of evaluation of theresulting Russian-English parallel corpus.
Webelieve that the 1-million-sentence Russian-English corpus of parallel sentences used in thispaper is a useful resource for machine translationresearch and machine translation contests.ReferencesBrown, P.F., Lai, J.C., Mercer, R.L.
1991.
AligningSentences in Parallel Corpora.
Proceedings of the29th Annual Meeting of the Association forComputational Linguistics, Berkeley, California169?176.Chen, S.F.
1993.
Aligning sentences in bilingualcorpora using lexical information.
Conference of theAssociation for Computational Linguistics,Columbus, Ohio, 9-16.Dean, J. and Ghemawat, S. 2004.
MapReduce:Simplified data processing on large clusters.
InProceedings of the Sixth Symposium on OperatingSystem Design and Implementation (San Francisco,CA, Dec. 6?8).
Usenix Association.Gale, W. A., & Church, K. W. 1993.
A program foraligning sentences in bilingual corpora.Computational Linguistics, 19(3), 75-102.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation, AnnualMeeting of the Association for ComputationalLinguistics (ACL), demonstration session, Prague,Czech Republic, June.Xiaoyi Ma and Mark Liberman.
1999.
BITS: A methodfor bilingual text search over the web.
Proceedings ofthe Machine Translation Summit VII.Xiaoyi Ma.
2006.
Champollion: A Robust Parallel TextSentence Aligner.
LREC 2006: Fifth InternationalConference on Language Resources and Evaluation.Michael Mohler and Rada Mihalcea.
2008.
BABYLONParallel Text Builder: Gathering Parallel Texts forLow-Density Languages.
Proceedings of theLanguage Resources and Evaluation Conference.Moore, Robert C., 2002.
Fast and Accurate SentenceAlignment of Bilingual Corpora.
MachineTranslation: From Research to Real Users143(Proceedings, 5th Conference of the Association forMachine Translation in the Americas, Tiburon,California), Springer-Verlag, Heidelberg, Germany,135-244.David Nadeau and George Foster, 2004.
Real-timeidentification of parallel texts from bilingualnewsfeed.
Computational Linguistic in the North-East (CLiNE 2004): 21-28.Franz Josef Och, Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
Proceedings of the38th Annual Meeting of the Association forComputational Linguistics, pp.
440-447, Hongkong,China, October.Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings ofthe 40th Annual Meeting of the Association forComputational Linguistics (ACL), pages 311?318,Philadelphia, PA, USA.Resnik, Philip and Noah A. Smith.
2003.
The web as aparallel corpus.
Computational Linguistics, 29:349?380.Andreas Stolcke.
2002.
SRILM?an extensiblelanguage modeling toolkit.
Proceedings ICSLP, vol.2, pp.
901?904, Denver, Sep.Jakob Uszkoreit, Jay Ponte, Ashok Popat and MosheDubiner.
2010.
Large Scale Parallel DocumentMining for Machine Translation.
Coling144
