Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 1?8,NAACL-HLT, Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsApplying POMDPs to Dialog Systems in the Troubleshooting DomainJason D. WilliamsAT&T Labs ?
Research180 Park Ave, Building 103Florham Park, NJ 07932jdw@research.att.comAbstractThis paper reports on progress applyingpartially observable Markov decision pro-cesses (POMDPs) to a commercial dia-log domain: troubleshooting.
In the trou-bleshooting domain, a spoken dialog sys-tem helps a user to fix a product such asa failed DSL connection.
Past work hasargued that a POMDP is a principled ap-proach to building spoken dialog systemsin the simpler slot-filling domain; this pa-per explains how the POMDPs formula-tion can be extended to the more complextroubleshooting domain.
Results from di-alog simulation verify that a POMDP out-performs a handcrafted baseline.1 IntroductionIn the troubleshooting domain, a spoken dialog sys-tem (SDS) helps a user to restore a malfunction-ing product such as a DSL connection to a work-ing state.
Building dialog systems for this domainpresents several new challenges.
First, the user maymake mistakes such as misinterpreting the meaningof a status light or pressing the wrong button, so evenif no speech recognition errors are made, the user?sresponse may be misleading.
Next, in addition to thespeech recognizer, input is also received from run-ning network tests such as pinging the user?s DSLmodem.
Input from both sources may contain er-rors, and a dialog system must cope with conflict-ing information from two channels.
In sum, the dia-log system never knows the true state of the productnor the user?s true actions, yet must still instruct theuser to successfully restore the product to a workingstate.Dialog models which explicitly model uncertaintyhave been shown to significantly outperform base-line models which do not, primarily because theycope better with conflicting evidence introduced byspeech recognition errors (Roy et al, 2000; Zhanget al, 2001; Williams and Young, 2007).
However,past work has been confined to slot-filling tasks andhas not tackled the troubleshooting domain.
Con-versely, dialog systems for troubleshooting in theliterature have not attempted to model uncertaintydirectly (Grosz and Sidner, 1986; Lochbaum, 1998).The contribution of this paper is to show howto model a troubleshooting spoken dialog systemas a partially observable Markov decision process(POMDP).
We argue that past work in the gen-eral troubleshooting literature represents simplifica-tions or special cases of a POMDP, then we showhow a troubleshooting POMDP can be combinedwith a dialog system POMDP to create a unifiedframework that admits global optimization.
Exper-iments with simulated users show how the POMDPformulation effectively balances diagnostic actions(such as a network test) with communicative ac-tions (such as giving the user instructions), and howthe POMDP formulation outperforms a hand-craftedbaseline both in terms of efficiency and task comple-tion.This paper is organized as follows.
Section 2 re-views POMDPs, the general troubleshooting prob-lem, and POMDP-based spoken dialog systems;section 3 explains how these two POMDPs can becombined to model a troubleshooting spoken dialogsystem; sections 4-5 present results from simulation;and section 6 concludes.2 BackgroundA POMDP is a model for control when there is un-certainty in the effects of actions and in the state1of the environment.
Formally, a POMDP P is de-fined as a tuple P = (S,A,T,R,O,Z, ?, b0) whereS is a set of states s describing the environment withs ?
S; A is a set of actions a ?
A which operateon the environment; T defines a transition proba-bility P (s?|s, a); R defines the expected (immedi-ate, real-valued) reward r(s, a) ?
<; O is a setof observations o ?
O which describe the state ofthe environment; Z defines an observation proba-bility P (o?|s?, a); ?
is a geometric discount factor0 ?
?
?
1; and b0 is an initial belief state, definedbelow.The POMDP operates as follows.
At each time-step, the environment is in some unobserved states.
Since s is not known exactly, a distribution overpossible states called a belief state b is maintainedwhere b(s) indicates the probability of being in aparticular state s, with b0 denoting the initial beliefstate.
Based on b, a control algorithm (also called apolicy) selects an action a, receives a reward r, andthe environment transitions to (unobserved) state s?,where s?
depends only on s and a.
The environmentthen generates an observation o?
which is dependenton s?
and a.
At each time-step, b is updated asb?(s?)
= ?
?
P (o?|s?, a)?sP (s?|s, a)b(s) (1)where ?
is a normalization constant (Kaelbling etal., 1998).
The process of maintaining b at eachtime step is called belief monitoring.
The cumula-tive, infinite-horizon, discounted reward is called thereturn and written V =?
?t=0 ?tr(st, at), where stand at indicate the state of the environment and theaction taken at time t, respectively.
The goal of thecontrol algorithm is to choose actions that maximizethe expected return E[V ] given b and the POMDPparameters P, and the process of searching for sucha control algorithm is called optimization.2.1 Troubleshooting as a POMDPThe goal of the general (non-dialog) problem of au-tomated troubleshooting is for a control algorithm tofix a product by taking a sequence of diagnosis andrepair actions.
Different actions have different relia-bilities and different costs, and the aim is to find thesequence that minimizes the total cost.
Since the ac-tions are not completely reliable, the true state of theTimestep n Timestep n+1x'amy'r'xamyr'Figure 1: Influence diagram depiction of automatedtroubleshooting.
Round nodes represent randomvariables, shaded nodes are unobservable and clearnodes are observable.
Arcs show conditional depen-dence.
Squares indicate actions, selected by the pol-icy.
Diamonds indicate real-valued rewards.product can?t be known with certainty: for example,an instrument may provide a faulty reading.Formalizing this, a product has some hidden statex, which is usually decomposed into componentsx = (x1, x2, .
.
.
, xn).
A control algorithm takesaction am, which changes the state of x accordingto P (x?|x, am).
The product then produces an ob-servation y according to P (y?|x?, am).
Replacingcost with reward, the control algorithm receives re-ward r(x, am) and the goal is to find the sequenceof actions which maximizes the cumulative sum ofreward.
When viewed in this way, automated trou-bleshooting can be readily viewed as a POMDP(Shakeri et al, 1997).
Figure 1 shows the automatedtroubleshooting task as an influence diagram.Although POMDPs are an elegant model for trou-bleshooting, they are also notoriously difficult tooptimize and much of the troubleshooting litera-ture seeks appropriate constraints which render theoptimization tractable, such as assuming that eachaction affects at most one product state compo-nent, that actions have deterministic effects, and thatthere is only fault present (Heckerman et al, 1995).More recently, advances in the POMDP literaturehave radically increased the scalability of optimiza-tion algorithms: for example, Poupart optimizes asubstantial network troubleshooting problem cast asa generic POMDP (Poupart and Boutilier, 2004).Viewing troubleshooting as a generic POMDP in-creases the scope of admissible troubleshootingtasks, and as will be discussed in section 3, this viewalso allows the uncertainty in the product state to beexplicitly modelled in a spoken dialog system.22.2 Spoken dialog as a POMDPPast work has argued that POMDPs represent a prin-cipled approach to modelling (non-troubleshooting)spoken dialog systems (Roy et al, 2000; Zhang etal., 2001; Williams and Young, 2007).
The intu-ition is that a user?s goals and actions form the un-observed state and the (possibly erroneous) ASRresult forms the observation.
The SDS-POMDPmodel (Williams and Young, 2007) formalizes thisby decomposing the POMDP state variable s intothree components, s = (su, au, d).
The componentsu gives the user?s goal, such as a complete travelitinerary in a travel reservation task.
The componentau gives the most recent user action (communicativeintent), such as stating a place the user would like totravel to.
Finally the component d records relevantdialog history, such as the grounding status of a slot.None of these components is observable directly bythe dialog system and the SDS-POMDP belief stateis formed of a distribution over these componentsb(su, au, d).
The POMDP action a corresponds tothe dialog system action am, such as asking the userwhere they want to go to.
Finally, the POMDP ob-servation o is set to (a?u, c), where a?u is the hypoth-esis of the user?s action (communicative intent) pro-vided by the speech recognition and understandingprocess, and c is the confidence score.
Figure 2shows the SDS-POMDP model as an influence di-agram, and also shows the conditional dependenciesassumed in the SDS-POMDP model.3 Troubleshooting SDS-POMDP modelIn this section, we develop a statistical model of atroubleshooting dialog system.
The formulation be-gins by taking the union of the state spaces of thedialog POMDP and the troubleshooting POMDP,(su, au, d, x), and making two modifications.
First,it is assumed that the user?s goal su is known andconstant (i.e., to fix the product), and as such doesnot need to be included.
Second, the user?s actionau is decomposed into two components: atsu denotestroubleshooting actions that are directed toward theproduct, such as turning a modem on or off, enteringa user name or just observing the status lights; andacomu denotes communicative actions to the dialogsystem such as saying ?green?
or ?yes?.
Reorder-c, auaudsuamrc, auaud'suamr'Timestep n Timestep n+1~ ~'''' 'Figure 2: SDS-POMDP model shown as an influ-ence diagram.
The dotted box refers to all of the(hidden) POMDP state components.ing, the combined POMDP state has components:s = (atsu , x, acomu , d).
(2)Next, the combined observation is formed of theunion of the observations from the dialog and trou-bleshooting POMDPs:o = (a?comu , c, y).
(3)Finally, since the POMDP may choose only one ac-tion at each time-step, the POMDP action is simplyam.Substituting eq.
2 into the POMDPtransition function P (s?|s, a) yieldsP (atsu?, x?, acomu ?, d?|atsu , x, acomu , d, am) and isdecomposed as follows.
First, it is assumed thatthe user?s troubleshooting action atsu ?
depends onlyon the system?s action am, the previous productstate x and the dialog history d. Next, it is as-sumed that the product state x?
depends only onthe previous product state x, and the most recentuser?s and dialog system?s troubleshooting actionsatsu ?
and am.
Further, the user?s communicativeaction acomu ?
depends only on the most recent user?stroubleshooting action atsu ?, product state x?, dialoghistory d and system action am.
Finally, the dialoghistory component d?
is a function of the previousdialog history d and the most recent user and dialogsystem actions atsu ?, acomu ?, and am.
With theseassumptions, the combined transition function is:P (atsu?, x?, acomu ?, d?|atsu , x, acomu , d, am) ?P (atsu ?|x, d, am) ?
P (x?|x, am, atsu ?
)?P (acomu ?|d, am, atsu ?, x?
)?P (d?|d, am, atsu ?, x?, acomu ?
)(4)3Timestep n Timestep n+1x'amauy'aur'xamauyaurd'dc,au~comcom com'ts ts''c,au~com'Figure 3: Influence diagram of a troubleshootingspoken dialog system.Substituting eq.
3 into the POMDPobservation function P (o?|s?, a) yieldsP (a?comu ?, c?, y?|atsu ?, x?, acomu ?, d?, am).
It is assumedthat the ASR hypothesis a?comu ?
and confidence scorec?
depend only on the user?s speech in acomu ?
andthat the result of the troubleshooting test (conductedby the dialog system) y?
depends only on the stateof the product x?
and the dialog system?s action am:P (a?comu ?, c?, y?|atsu ?, x?, acomu ?, d?, am) ?P (a?comu ?, c?|acomu ?)
?
P (y|am, x?
)(5)An influence diagram of the model is shown in Fig-ure 3.At runtime, a belief state (i.e., distribution)is maintained over the POMDP state variables,b(atsu , x, acomu , d).
Based on this belief state the pol-icy chooses an action am and receives observation(a?comu ?, c?, y?).
The belief state is updated by apply-ing Eq 1, and the cycle repeats.The user action models P (atsu ?|x, d, am) andP (acomu ?|d, am, atsu ?, x?)
indicate how users arelikely to respond in troubleshooting dialogs and canbe estimated from annotated dialog data.
The prod-uct models P (x?|x, am, atsu ?)
and P (y?|am, x?)
in-dicate how user and dialog system actions changethe state of the product and the reliability of tests,and these can be estimated by interviewing domainexperts or by examining logs of product perfor-mance.
As in the SDS-POMDP model, the di-alog history model P (d?|d, am, acomu ?, x?, atsu ?)
canbe handcrafted so as to incorporate features fromthe dialog history which the dialog designer be-lieves are important, such as appropriateness or no-tions of grounding.
The ASR confusion modelP (a?comu ?, c?|acomu ?)
can be estimated from speechrecognition data or derived analytically.
The re-ward function can include distinct costs for differ-ent diagnostic tests, dialog actions, and for success-ful/unsuccessful task completion.
It is not specifiedexplicitly here since it depends on the application.4 Illustration: DSL-1To illustrate the general framework, we first createda very simple troubleshooting spoken dialog systemcalled DSL-1.
Table 1 shows the values for all ofthe variables.
In DSL-1, the are just 2 possible prob-lems: no-power and no-network.The conditional probability tables composing themodel were handcrafted based on conversationswith troubleshooting experts and past experiencewith spoken dialog systems.
For example, the modelof user?s troubleshooting action assumes that theuser performs the correct action with p = 0.9,doesn?t understand with p = 0.05, and performs anincorrect action with p = 0.05.
The model of theuser?s communicative action assumes that the userprovides correct (but possibly incomplete) informa-tion with p = 0.9, and remains silent with p = 0.1.The model of the product was designed such thatthe user?s check-power and check-network actionsare always effective, but if power is restored theremay still be no-network with p = 0.2.The model of the speech recognition and under-standing process uses a concept error rate of 30%,where errors are uniformly distributed, and no con-fidence scores are used.
For example, when theuser expresses the concept all-ok, it will be recog-nized correctly 70% of the time, and will be mis-recognized as no-power 5% of the time, as no-network 5% of the time, etc.
The model for y in-dicates how reliable the ping action is, set with aparameter perr: for example if perr = 0.1, the resultof a ping test will be incorrect 10% of the time.
Inthe experiments below, the value of perr is varied toexplore how the POMDP policy trades off betweenthe ping action and communicative actions.The reward function provides +100 for takingthe end-call action when the connection is working,?100 for taking the done action when the connec-tion isn?t working, and ?1 for any communicativeor test action.
The dialog continues until the dialog4Variable Valuesatsu {check-power, check-network, observe, do-nothing, dont-understand}State x {all-ok, no-power, no-network}Components d {start, not-done, done}acomu {no-power, no-network, power-ok, all-ok, silent, didnt-understand}Observation a?comu (same set as acomu )Components y {ping-ok, no-response}Action am {ping, ask-working-ok, req-check-power, req-check-network, end-call}Table 1: Variable values in the DSL-1 simple troubleshooting example.system takes the done action, at which point the di-alog is over.4.1 ResultsThe POMDP was optimized using a standard algo-rithm from the literature (Spaan and Vlassis, 2005).This algorithm optimizes the policy at a discrete setof belief points; as more points are added, the qual-ity of the resulting policy improves at the expenseof more computation.
We found that 300 beliefpoints achieved asymptotic performance.
A modelwas constructed for values of perr ranging from 0.0to 0.5; each model was optimized and then evaluatedusing 5000 simulated dialogs.Results are shown in Figures 4 and 5.
In eachfigure the x-axis is the accuracy of the ping action:perr = 0% indicates that the ping action is entirelyreliable and perr = 50% indicates that the ping ac-tion returns useless noise.
In Figure 4, the y-axisshows average return, and in Figure 5, the solid lineshows the task completion rate and the dotted lineshows the average dialog length.
The error bars in-dicate the 95% confidence interval.As the error rate for the ping action increases from0% to 20%, the average dialog length increases from5.1 turns to 6.5 turns, and the successful task com-pletion rate falls from 100.0% to 98.9%.
These fig-ures then remain broadly constant from 20% to 50%.In other words, as errors in the ping action increase,dialogs become longer and occasionally the systemfails to fix the connection.
Inspecting the dialogtranscripts showed that at perr = 0%, the policyrelies on the ping action to judge whether the con-nection is working.
As perr increases, the policydecreasingly employs the ping diagnostic action infavor of the ask-working-ok communicative actionuntil perr = 20%, at which point the ping action is84858687888990919293940% 5% 10%15%20%25%30%35%40%45%50%p err  (ping error rate)AveragereturnFigure 4: Error rate of the ping action vs. rewardgained per dialog.
As the error rate of the ping ac-tion is increased, performance declines until the er-ror rate reaches 20%, at which point the system nolonger uses the ping action.not used at all.
At this point the planning process hasdetermined that the ping action doesn?t help producebetter dialogs than just interacting with the caller,and the performance from 20% to 50% is constant.1These experiments confirm that, for a very sim-ple troubleshooting dialog system in simulation, thePOMDP approach is able to synthesize noisy infor-mation gained from communicative and test actionsinto one unified belief while the underlying, hiddenproduct state is changing.
This is an important re-sult because past work that has applied POMDPsto dialog systems has employed a single modality(communicative actions), and have largely had fixedpersistent state.
Even so, this illustration is muchtoo small to be of practical use, and relies entirelyon hand-crafted models of the dynamics.
In the nextsection a model of realistic scale is presented withtransition dynamics estimated from real conversa-1The variations in performance between 20% and 50% aredue to sampling in the optimization algorithm.598.3%98.7%99.1%99.5%99.9%0% 5% 10%15%20%25%30%35%40%45%50%p err  (ping error rate)Taskcopmletionrate(%)55.45.86.26.67Averagedialoglength(turns)Task completion rate Average dialog lengthFigure 5: Error rate of the ping action vs. success-ful task completion rate and average dialog length.The left y axis and the solid line show the task com-pletion rate, and the right y axis and the dotted lineshow the average dialog length in number of turns.tional data.5 Illustration: DSL-2In this section we present a second POMDP-basedtroubleshooting dialog system called DSL-2 whichcaptures many of the properties of a real-worldDSL troubleshooting task.
Approximately 100 tele-phone calls between (human) DSL support agentsand customers were monitored, and the observationsof these conversations guided creation of the dia-log system, including typical problems, agent in-structions, and user responses.
The product state Xwas decomposed into 19 components which track,for example, whether there are any outages re-ported, whether the DSL modem is switched on, andwhether the username has been entered correctly inthe DSL configuration.
Seven of these componentscan cause the connection to fail: (1) router pow-ered off or crashed, (2) an upstream network crash,(3) a service outage, (4-6) a wrong username, pass-word, or connection type entered in the DSL modemconfiguration, and (7) an unknown root cause whichcan?t be fixed by the dialog system.
Some of theproblems can only be identified or fixed by the dia-log system (such as a service outage or an upstreamnetwork crash), and the rest only by the user (such asa router being off or wrong username entered).
Theproblems may occur in any combination: for exam-ple, there may be a service outage while the user?spassword is entered incorrectly.
The system actionset (Am) consisted of 18 actions such as asking theuser to turn the modem on, providing the correctusername, checking whether any outages have beenreported, and rebooting the upstream network inter-face.
The user?s troubleshooting action set Atsu con-sisted of 12 actions such as turning the modem onor off, opening the DSL configuration screen, enter-ing a password, and attempting to surf to a website.The user?s communicative action set Acomu consistedof 11 actions such as saying the color of a light (e.g.,?red?
or ?green?
), yes and no, back-channel, silence,and an ?out-of-grammar?
action which accounts foruser speech which cannot be recognized.The conditional probability tables for each of theproduct components were handcrafted based on in-terviews with DSL technicians and are almost alldeterministic.
For example, if the DSL modemis powered on, the power light will always be on.Next a subset of the agent/user telephone calls weretranscribed and annotated with simple dialog acts,and from these the two user models were estimated.Smoothing was applied so that the models allow forthe user to take any action at any point in the dia-log.
Concept recognition errors were generated withp = 0.30, and confidence scores were drawn froman exponential distribution such that (at an equal er-ror rate confidence threshold) about half of the con-cept errors could be identified.
The reward func-tion provides +100 for ending the dialog having cor-rectly identified (and if possible resolved) the rootcauses, ?100 for ending the dialog with unidenti-fied or unresolved root causes, and ?1 for any otheraction.
If a dialog ran for more than 100 turns, it wasconsidered a failure and terminated.We created a state-based dialog manager by hand(called HC) which broadly reflects the agents?
trou-bleshooting practices and which serves as our base-line.
HC consisted of 19 dialog states, where eachstate specified an action am to take (for example toask the user to turn the modem on), and observationsfrom the speech recognizer a?comu or troubleshootingtests y may cause transitions between dialog states.HC first asks the user to power cycle the modem,then checks for outages and ?resets?
the upstreamnetwork interface, then verifies that the username,password, and network type are configured correctlyon the router.
After each step HC checks if the con-nection is working by asking if the network lightis green, pinging the modem, then asking the user6POMDP HC HC(0)CER 30% 30% 0%N 500 500 500TCR 96.1% 78.0% 88.6%Length 19.9 76.5 48.5Return 73.3 8.13 48.8Table 2: Results for the POMDP and hand-crafteddialog managers.
CER is concept error rate; TCR istask completion rate; Length is measured in turns.to open a web browser; if any one of these testsfails, troubleshooting resumes, and if they all suc-ceed then HC ends the dialog.
If an outage is de-tected, HC says this and exits, and if the connectionstill isn?t working at the end of the dialog then HCescalates the call to a (human) technician.
In generalwhen HC receives an unexpected answer or confi-dence score below the equal-error rate threshold, ittreats this as a likely speech recognition error andremains in the same dialog state.Next, optimization was performed as described in(Williams et al, 2005).
This technique takes as in-put a POMDP model and a state-based dialog con-troller, and produces an improved dialog controller.Space limitations prevent a full description here; theintuition is that the algorithm uses the POMDP be-lief state at runtime to ?rewire?
the dialog controllerto achieve an improvement in reward.
Because thisoptimization algorithm improves a standard state-based dialog controller (in this case the HC base-line), it provides an indication of the value of addingthe POMDP machinery.5.1 Results and discussionFirst, 500 simulated dialogs were run with thePOMDP, and then 500 simulated dialogs were runwith the HC baseline controller.
Finally, as a fur-ther comparison, the ASR simulation was changedso that no ASR errors were made, and HC wasrun for 500 dialogs in this configuration, which wecall HC(0).
Results are shown in Table 2.
All ofthe observed differences are statistically significant(p  0.01).In the presence of speech recognition errors, thePOMDP produces dialogs which are significantlyshorter and more successful than HC.
Moreover, thePOMDP, which faced ASR errors, also outperformsHC(0), which did not.
Examination of the dialogtranscripts found that the main source of failure forHC(0) was exceeding 100 turns.
In other words,quantitatively, the POMDP is both more robust toASR errors and (independent of ASR errors) moreefficient.The dialog transcripts were inspected to deter-mine qualitatively how the POMDP attained betterperformance.
An example is shown in Table 3.
Atthe start of the conversation, the belief (probability)that the connection is working p(allOk) is 56% andthe belief that the power to the DSL modem is onp(pwrOn) is 98.0% (these are 2 of the 19 compo-nents in the product state x).
As the dialog pro-gresses, belief monitoring updates these to accountfor the evidence received.
For example, the unsuc-cessful ping in S1 causes p(allOk) to drop from 56%to 14%.
The belief monitoring process also natu-rally makes use of indirect evidence ?
for example,in U14 the user indicates the network light is ?red?
:since the network light will only be on if the powerto the DSL modem is on, this causes an increase inthe belief that the power is on, from 99.1% to 99.8%.The key benefit of the POMDP approach is thatthe dialog manager can exploit the belief state tomake better progress in the face of low-confidenceor even nonsensical replies, without sacrificing over-all task completion.
For example, in S1 through S9the POMDP policy differs from the baseline con-troller: the baseline controller would have ignoredthe lower-confidence recognitions in U4 and U8, butthe POMDP policy moves ahead.
When the policyreceives a nonsensical reply, for example in U6, itreverts back to an earlier stage of the troubleshoot-ing procedure it had previously skipped.
This latterbehavior ensures that omitting steps to move fasterthrough the procedure doesn?t ultimately sacrificetask completion.6 ConclusionsThis paper has shown how a spoken dialog systemfor troubleshooting can be cast as a POMDP.
Thetroubleshooting domain has important differences topast applications of the POMDP approach and thetwo illustrations provided in this paper support ourclaim that, at least in dialog simulation, the advan-tages of POMDPs apply to this domain.After finishing simulation experiments, we in-7stalled DSL-2 into a real dialog system, and foundthat belief monitoring runs slower than real-time.We subsequently developed a method to addressthis, which we will report on separately in the fu-ture, and are now preparing for a pilot study withreal users.ReferencesBJ Grosz and CL Sidner.
1986.
Attention, intentions,and the structure of discourse.
Computational Lin-guistics, 12(3):175?204.D Heckerman, JS Breese, and K Rommelse.
1995.Decision-theoretic troubleshooting.
Communicationsof the ACM, 38(3):49?57.L Kaelbling, ML Littman, and AR Cassandra.
1998.Planning and acting in partially observable stochasticdomains.
Artificial Intelligence, 101.KE Lochbaum.
1998.
A collaborative planning modelof intentional structure.
Computational Linguistics,24(4):525?572.P Poupart and C Boutilier.
2004.
VDCBPI: an ap-proximate scalable algorithm for large scale POMDPs.In Proc Advances in Neural Information ProcessingSystems 17 (NIPS), Vancouver, Canada, pages 1081?1088.N Roy, J Pineau, and S Thrun.
2000.
Spoken dialogmanagement for robots.
In Proc Association for Com-putational Linguistics (ACL), Hong Kong.M Shakeri, KR Pattipati, V Raghavan, A Patterson-Hine,and DL Iverson.
1997.
Multiple fault isolation inredundant systems.
Technical Report NCC2-5123,NASA Ames.MTJ Spaan and N Vlassis.
2005.
Perseus: randomizedpoint-based value iteration for POMDPs.
Journal ofArtificial Intelligence Research, 24:195?220.JD Williams and SJ Young.
2007.
Partially observablemarkov decision processes for spoken dialog systems.Computer Speech and Language, 21(2):393?422.JD Williams, P Poupart, and SJ Young.
2005.
Partiallyobservable Markov decision processes with continu-ous observations for dialogue management.
In ProcSIGdial Workshop on Discourse and Dialogue, Lis-bon.B Zhang, Q Cai, J Mao, and B Guo.
2001.
Planningand acting under uncertainty: A new model for spokendialogue system.
In Proc Conf on Uncertainty in Ar-tificial Intelligence (UAI), Seattle, Washington, pages572?579.ID p(allOk) p(pwrOn) Transcript*S1 56% 98.0% I?m going to try pinging your DSL modem from here.S2 - - There was no response so it seems your connection isn?t working yet.
*S3 14% 96.1% Please turn the DSL modem on.U4 - - ok [ok, 0.004]*S5 30% 96.4% What color is the network light on the DSL modem?U6 - - dontunderstand [no, 0.052]*S7 30% 93.8% Please turn the DSL modem on.U8 - - dontunderstand [ok, 0.454]*S9 31% 99.1% I?m going to check if there are any outages reported, just a moment.S10 - - There are no outages reported.S11 39% 99.1% I?m going to try resetting your connection from here, just a moment.S12 - - Ok, that has been done.S13 48% 99.1% What color is the network light on the DSL modem?U14 - - red [red, 0.678]S15 3% 99.8% Please open the DSL configuration screen.... ... ... ...Table 3: Fragment of a conversation with the POMDP dialog manager.
Asterisks (*) indicate transitionsnot in the baseline dialog manager.
p(allOk) shows the probability that DSL connectivity is working andp(pwrOn) shows the probability that the power to the DSL modem is on, according to the POMDP beliefstate.
The simulated user?s communicative actions are shown in italics, followed by the [concept,confidence score] produced by the ASR simulation.8
