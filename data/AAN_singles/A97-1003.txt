High Performance Segmentation of Spontaneous SpeechUsing Part of Speech and Trigger Word InformationMarsa l  Gava ldh  K laus  ZechnerInteract ive Systems Labs.
Interact ive Systems Labs.Language Technologies Inst i tute  Comp.
Ling.
P rogramSchool of Computer  Science Depar tment  of Phi losophyCarnegie Mellon Univers i ty Carnegie Mellon UniversityP i t tsburgh,  PA 15213, USA P i t tsburgh,  PA 15213, USAmarsa l+@cs,  cmu.
edu zechner+?andrew,  cmu.
eduGregory  A is tComp.
Ling.
P rogramDepar tment  of Phi losophyCarnegie Mellon Univers i tyP i t tsburgh,  PA 15213, USAa is t+@andrew,  cmu.
eduAbst rac tWe describe and experimentally evaluatean efficient method for automatically de-termining small clause boundaries in spon-taneous peech.
Our method applies an ar-tificial neural network to information aboutpart of speech and trigger words.We find that with a limited amount of data(less than 2500 words for the training set),a small sliding context window (+/ -3  to-kens) and only two hidden units, the neuralnet performs extremely well on this task:less than 5% error rate and F-score (com-bined precision and recall) of over .85 onunseen data.These results prove to be better than thosereported earlier using different approaches.1 I n t roduct ionIn the area of machine translation, one important in-terface is that between the speech recognizer and theparser.
In the case of human-to-human dialogues,the speech recognizer's output is a sequence of turns(a contiguous egment of a single speaker's utter-ance) which in turn can consist of multiple clauses.Lavie et al (1996) discuss that using smaller unitsrather than whole turns can greatly facilitate thetask of the parser since it reduces the complexity ofits input.The problem is thus how to correctly segment anutterance into clauses.The segmentation procedure described in Lavieet al (1996) uses a combination of acoustic infor-mation, statistical calculation of boundary-trigrams,some highly indicative keywords and also someheuristics from the parser itself.Stolcke and Shriberg (1996) studied the relevanceof several word-level features for segmentation per-formance on the Switchboard corpus (see Godfreyet al (1992)).
Their best results were achieved byusing part of speech n-grams, enhanced by a coupleof trigger words and biases.12Another, more acoustics-based approach for turnsegmentation is reported in Takagi and Itahashi(1996).Palmer and Hearst (1994) used a neural networkto find sentence boundaries in running text, i.e.
todetermine whether aperiod indicates end of sentenceor end of abbreviation.
The input to their network isa window of words centered around a period, whereeach word is encoded as a vector of 20 reals: 18 val-ues corresponding to the word's probabilistic mem-bership to each of 18 classes and 2 values represent-ing whether the word is capitalized and whether itfollows a punctuation mark.
Their best result of98.5% accuracy was achieved with a context of 6words and 2 hidden units.In this paper we bring their idea to the realm ofspeech and investigate the performance of a neuralnetwork on the task of turn segmentation using partsof speech, indicative keywords, or both of these fea-tures to hypothesize segment boundaries.2 Data  preparat ionFor our experiments we took as data the first 1000turns (roughly 12000 words or 12 full dialogues) oftranscripts from the Switchboard corpus in a versionthat is already annotated for parts of speech (e.g.noun, adjective, personal pronoun, etc.
).The definition of a small clause which we wantedthe neural network to learn the boundaries of isas follows: Any finite clause that contains an in-flected verbal form and a subject (or at least eitherof them, if not possible otherwise).
However, com-mon phrases uch as good bye, and stuff like that,etc.
are also considered small clauses.Preprocessing the data involved (i) expansion ofsome contracted forms (e.g.
l 'm -+ I am), (ii) correc-tion of frequent agging errors, and (iii) generationof segment boundary candidates using some simpleheuristics to speed up manual editing.Thus we obtained a total of 1669 segment bound-aries, which means that on average approximatelyafter every seventh token (i.e.
14% of the text) thereis a segment boundary.3 Features and input encoding3.1 FeaturesThe transcripts are tagged with part of speech(POS) data from a set of 39 tags 1 and were pro-cessed to extract trigger words, i.e.
words that arefrequently near small clause boundaries (<b>).
Twoscores were assigned to each word w in the transcriptaccording to the following formulae:scorepre(W) = C(w<b>) /5(w<b>\]w)scorepost(W) ---- C(<b>w) /5(<b>w\[w)where C is the number of times w occurred asthe word (before/after) a boundary, and /5 is theBayesian estimate for the probability that a bound-ary occurs (after/before) w.This score is thus high for words that are likely(based on/5) and reliable (based on C) predictors ofsmall clause boundaries.The pre- and post-boundary trigger words werethen merged and the top 30 selected to be used asfeatures for the neural network.3.2 Input encodingThe information generated for each word consistedof a data label (a unique tracking number, the actualword, and its part of speech), a vector of real valuesxl, ..., xc and a label ( '+ '  or ' - ' )  indicating whethera segment boundary had preceded the word in theoriginal segmented corpus.The real numbers xl,  ..., xc are the values given asinput to the first layer of the network.
We testedthree different encodings:1.
Boolean encoding of POS: xi (1 < i < c = 39)is set to 0.9 if the word's part of speech is thei th part of speech, and to 0.1 otherwise.2.
Boolean encoding of triggers: xi (1 < i < c =30) is set to 0.9 if the word is the ith trigger,and to 0.1 otherwise.3.
Concatenation of boolean POS and trigger en-codings (c = 39 + 30 = 69).4 The  neura l  networkWe use a fully connected feed-forward three-layer(input, hidden, and output) artificial neural net-work and the standard backpropagation algorithmto train it (with learning rate ~/= 0.3 and momen-tum ~ = 0.3).Given a window size of W and c features per en-coded word, the input layer is dimensioned to c ?
Wunits, that is W blocks of c units.The number of hidden units (h) ranged in our ex-periments from 1 to 25.1The tagset is based on the standard tagsets of thePenn Treebank and the Brown Corpus.130.80.6ca0.40.200i itraining - -validationtest .
.
.
.
.'
; ' ' 3'o 5 1 1 20 25epochs35Figure 1: Training the neural network.
(Net withPOS and trigger encoding, W = 6, h = 2, 0 = 0.7)As for the output layer, in all the experimentsit was fixed to a single output unit which indicatesthe presence or absence of a segment boundary justbefore the word currently at the middle of the win-dow.
The actual threshold to decide between seg-ment boundary and no segment boundary is the pa-rameter 0 which we varied from 0.1 to 0.9.The data was presented to the network by sim-ulating a sliding window over the sequence of en-coded words, that is by feeding the input layer withthe c ?
W encodings of, say, words wi.. .wi+w-1 andthen, as the next input to the network, shifting thevalues one block (c units) to the left, thereby admit-ting from the right the c values corresponding to theencoding of wi+w.
Note that at the beginning ofeach speaker turn or utterance the first c x (w  _ 1)input units need be padded with a "dummy" value,so that the first word can be placed just before themiddle of the window.
Symmetrically, at the end ofeach turn, the last c ?
(w _ 1) input units are alsopadded.5 Resu l ts  and d iscuss ionWe created two data sets for our experiments, allfrom randomly chosen turns from the original data:(i) the "small" data set (a 20:20:60(%) split be-tween training, validation, and test sets), and (ii)the "large" data set (a 60:20:20(%) split).First, we ran 180 experiments on the "small"data set, exhaustively exploring the space definedby varying the following parameters:* encoding scheme: POS only, triggers only, POSand triggers.
* window size: W E {2, 4, 6, 8}?
number of hidden units: h E {2, 10, 25}?
output threshold: 0 E { 0.1, 0.3, 0.5, 0.7, 0.9 }10.80.60.40.200!
i i ,both POS and triggers - -POSonlytriggers only0:2 0:, 018 0:sprecisionFigure 2: Precision vs. recall tradeoff.
(On unseendata, net with W = 6, h = 2, 0.1 < 0 < 0.9)10.8F) 0.60.4, , , , , ,both POS and triggers - -POSonlytriggers only0.20 J a 0, o2 013 0', 0s 0:0 0'7 08 0,thresholdFigure 3: F-scores as a function of the output unitthreshold 0.
(On unseen data, net with W = 6,h=2)Precision (number of correct boundaries foundby the neural network divided by total number ofboundaries found by the neural network), recall(number of correct boundaries found by the neu-ral network divided by true number of boundaries2.
p rec i s ion ,  reca l l  in the data) and F-score (defined as precision+recall /were computed for each training, validation and testsets.To be fair, we chose to take the epoch with themaximum F-score on the validation set as the bestconfiguration of the net, and we report results fromthe test set only.
Figure 1 shows a typical train-ing/learning curve of a neural network.The best performance was obtained using a netwith 2 hidden units, a window size of 6 and the out-put unit threshold set to 0.7.
The following resultswere achieved.14Icl ssi cati?nr t?lpr?cisi?nlrec lllFsc?rel0 8  O.845 0.860 0.852Some general trends are observed:?
As the window size gets larger, the performanceincreases, but it seems to peak at around size 6.?
Fewer hidden units yield better results; gener-ally we get the best results for just two hiddenunits.?
The global performance as measured by the pro-portion of correct classifications (i.e.
both '+'and ' - ' )  increases as the F-score increases.?
High performance (correct classifications >95%,F-score >0.85) is easily achieved.?
The optimal threshold for a high F-score lies inthe 0.5 </9 < 0.7 interval.?
Varying the threshold leads to a tradeoff of pre-cision vs. recall.To illustrate the last point, we present a graphthat shows a comparison between the three encod-ing methods used, for a window size of 6 (Figure 2).The combined method is only slightly better thanthe POS method, but they both are clearly superiorto the trigger-word method.
Still it is interestingto note that quite a reasonable performance can beobtained just by looking at the 30 most indicativepre- and post-boundary trigger-words.
Noteworthyis also the behavior of the precision-recall curves:with our method a high level of recall can be main-tained even as the output threshold is increased toaugment precision.In Figure 3, we plot the F-score against he thresh-old.
Whereas for the encodings POS only and POSand triggers, the peaks are in the region between0.5 and 0.7, for the triggers only encoding, the bestF-scores are achieved between 0.3 and 0.5.We also ran another 30 experiments with the"large" data set focusing on the region defined by theparameters that achieved the best results in the pre-ceding experiments (i.e.
window size 6 or 8, thresh-old between 0.5 and 0.7, number of hidden units be-tween 1 and 10).
Under these constraints, F-scoresvary slightly, always remaining between .85 and .88for both validation and test sets.Within this region, therefore, several neural netsyield extremely good performance.While Lavie et al (1996) just report an im-provement in the end-to-end performance of theJANUS speech-to-speech translation system when us-ing their segmentation method but do not give de-tails the performance of the segmentation methoditself, Stolcke and Shriberg (1996) are more explicitand provide precision and recall results.
MoreoverLavie et al (1996) deal with Spanish input whereasStolcke and Shriberg (1996), like us, drew their datafrom the Switchboard corpus.Type Harmfu l?
Reason  Contextfalse positive no trigger wordfalse positive yes non-clausal andfalse negative yes speech repairfalse positive ?
trigger wordfalse positive yes non-clausal andfalse negative yes speech repairfalse positive no CORRECTfalse negative no CORRECTfalse negative yes embedded relative clausefalse positive no trigger wordto work <b> and* when I hadwork off * and on<b> but * and they arehe you know * gets to a certainif you like trip * and fall or something<b> we * that's been<b> but i think * its relevance<b> and she * she wasinto nursing homes * die very quicklywait lists * and allTable 1: Sample of misclassif ications (on unseen data,  net with encoding of POS and triggers, W --- 6, h = 2,0 = 0.7).
False positive indicates an instance where the net hypothesizes a boundary  where there is none.False negat ive indicates an instance where the net fails to hypothesize a boundary  where there is one.
A'<b>' indicates a smal l  clause boundary.
A '* '  indicates the locat ion of the error.Thus here we compare our approach with that  ofStolcke and Shriberg (1996).
They tra ined on 1.4mil l ion words and in their  best system, achieved pre-cision .69 and recall .85 (which corresponds to anF-score of .76).
We tra ined on 2400 words (i.e.
over500 t imes less t ra in ing data) ,  and we achieved anF-score of .85 (i.e.
a 12% improvement) .6 Error analysisTable 1 shows 10 representat ive errors that  one ofthe best performing neural  network made on the testset.
25 randomly  selected errors were used to do theerror analysis,  which consisted of 14 false posit ivesand 11 false negatives.
8 of the errors were errors weconsidered to be harmful  to the parser,  3 were errorsof unknown harmfulness,  and the remain ing 14 wereconsidered harmless.Of the harmful  errors, three were due to the wordand being used as a conjunct ion in a non-clausalcontext,  two were due to a fai lure to detect  a speechrepair,  and one was due to an embedded relat iveclause (most people that move into nursing homes* die very quickly).The network was also 'able to correctly identifysome mistagged ata  (marked as CORRECT in Ta-ble 1).These results suggest that  adding features rele-vant to speech repairs (such as whether words wererepeated) or features relevant to detect ing the useof and as a non-clausal conjunct might  be useful inachieving better  accuracy.7 Conc lus ionWe have shown that  using neural  networks for auto-mat ica l ly  segmenting turns in conversat ional  speechinto smal l  clauses reaches a level of less than 5% errorrate and achieves good precis ion/recal l  performanceas measured by an F-score of more than .85.These results outperform those obta ined by othermethods  as reported in the l i terature.15Future work on this problem includes issues suchas opt imiz ing the set of POS tags, adding acous-t ic /prosodic  features to the neural  network, and us-ing it for pro-drop languages like Spanish to as-sess the relat ive impor tance  of POS vs. tr igger wordweights and to examine the performance of the sys-tem for languages where POS tags may not be asinformative as they are for English.8 AcknowledgementsThe work reported in this paper was funded in part bygrants from ATR - Interpreting Telecommunications Re-search Laboratories of Japan, the US Department of De-fense, and the Verbmobil Project of the Federal Republicof Germany.This material is based on work supported under a Na-tional Science Foundation Graduate Fellowship.
Anyopinions, findings, conclusions or recommendations ex-pressed in this publication are those of the author(s) anddo not necessarily reflect the views of the National Sci-ence Foundation.ReferencesJ.
J. Godfrey, E. C. Holliman, and J. McDaniel.
1992.SWITCHBOARD: telephone speech corpus for researchand development.
In Proceedings of the ICASP-92,vol.
I, pp.
517-520.A.
Lavie, D. Gates, N. Coccaro, and L. Levin.
1996.Input segmentation of spontaneous speech in JANUS:a speech-to-speech translation system.
In Proceedingsof the ECAI-96.D.
D. Palmer and M. A. Hearst.
1994.
Adaptive sen-tence boundary disambiguation.
In Proceedings of theANLP-94.A.
Stolcke and E. Shriberg.
1996.
Automatic linguisticsegmentation of conversational speech.
In Proceedingsof the ICSLP-96, pp.
1005-1008.K.
Takagi and S. Itahashi.
1996.
Segmentation of spo-ken dialogue by interjections, disfluent utterances andpauses.
In Proceedings of the ICSLP-96, pp.
697-700.
