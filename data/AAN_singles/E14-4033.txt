Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 169?173,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsData Driven Language Transfer HypothesesBen SwansonBrown UniversityProvidence, RIchonger@cs.brown.eduEugene CharniakBrown UniversityProvidence, RIec@cs.brown.eduAbstractLanguage transfer, the preferential secondlanguage behavior caused by similaritiesto the speaker?s native language, requiresconsiderable expertise to be detected byhumans alone.
Our goal in this work is toreplace expert intervention by data-drivenmethods wherever possible.
We define acomputational methodology that producesa concise list of lexicalized syntactic pat-terns that are controlled for redundancyand ranked by relevancy to language trans-fer.
We demonstrate the ability of ourmethodology to detect hundreds of suchcandidate patterns from currently availabledata sources, and validate the quality ofthe proposed patterns through classifica-tion experiments.1 IntroductionThe fact that students with different native lan-guage backgrounds express themselves differ-ently in second language writing samples hasbeen established experimentally many times over(Tetreault et al., 2013), and is intuitive to mostpeople with experience learning a new language.The exposure and understanding of this processcould potentially enable the creation of secondlanguage (L2) instruction that is tailored to the na-tive language (L1) of students.The detectable connection between L1 and L2text comes from a range of sources.
On one end ofthe spectrum are factors such as geographic or cul-tural preference in word choice, which are a pow-erful L1 indicator.
On the other end lie linguisticphenomena such as language transfer, in which thepreferential over-use or under-use of structures inthe L1 is reflected in the use of corresponding pat-terns in the L2.
We focus on language transfer inthis work, based on our opinion that such effectsare more deeply connected to and effectively uti-lized in language education.The inherent challenge is that viable languagetransfer hypotheses are naturally difficult to con-struct.
By the requirement of contrasting differentL1 groups, hypothesis formulation requires deepknowledge of multiple languages, an ability re-served primarily for highly trained academic lin-guists.
Furthermore, the sparsity of any particularlanguage pattern in a large corpus makes it diffi-cult even for a capable multilingual scholar to de-tect the few patterns that evidence language trans-fer.
This motivates data driven methods for hy-pothesis formulation.We approach this as a representational problem,requiring the careful definition of a class of lin-guistic features whose usage frequency can be de-termined for each L1 background in both L1 andL2 text (e.g.
both German and English writtenby Germans).
We claim that a feature exhibitinga sufficiently non-uniform usage histogram in L1that is mirrored in L2 data is a strong languagetransfer candidate, and provide a quantified mea-sure of this property.We represent both L1 and L2 sentences in auniversal constituent-style syntactic format andmodel language transfer hypotheses with con-tiguous syntax sub-structures commonly knownas Tree Substitution Grammar (TSG) fragments(Post and Gildea, 2009)(Cohn and Blunsom,2010).
With these features we produce a conciseranked list of candidate language transfer hypothe-ses and their usage statistics that can be automati-cally augmented as increasing amounts of data be-come available.1692 Related WorkThis work leverages several recently released datasets and analysis techniques, with the primarycontribution being the transformations necessaryto combine these disparate efforts.
Our analy-sis methods are closely tied to those describedin Swanson and Charniak (2013), which con-trasts techniques for the discovery of discrimina-tive TSG fragments in L2 text.
We modify andextend these methods to apply to the universal de-pendency treebanks of McDonald et al.
(2013),which we will refer to below to as the UTB.
Bilin-gual lexicon construction (Haghighi et al., 2008)is also a key component, although previous workhas focused primarily on nouns while we focus onstopwords.
We also transform the UTB into con-stituent format, in a manner inspired by Carrolland Charniak (1992).There is a large amount of related research inNative Language Identification (NLI), the task ofpredicting L1 given L2 text.
This work has culmi-nated in a well attended shared task (Tetreault etal., 2013), whose cited report contains an excellentsurvey of the history of this task.
In NLI, however,L1 data is not traditionally used, and patterns arelearned directly from L2 text that has been anno-tated with L1 labels.
One notable outlier is Brookeand Hirst (2012), which attempts NLI using onlyL1 data for training using large online dictionar-ies to tie L2 English bigrams and collocations topossible direct translations from native languages.Jarvis and Crossley (2012) presents another set ofstudies that use NLI as a method to form languagetransfer hypotheses.3 MethodologyThe first of the four basic requirements of our pro-posed method is the definition of a class of featuresF such that a single feature F ?
F is capableof capturing language transfer phenomenon.
Thesecond is a universal representation of both L1 andL2 data that allows us to count the occurrences ofany F in an arbitrary sentence.
Third, as any suf-ficiently expressive F is likely to be very large, amethod is required to propose an initial candidatelist C ?
F .
Finally, we refine C into a ranked listH of language transfer hypotheses, where H hasalso been filtered to remove redundancy.In this work we define F to be the set of TreeSubstitution Grammar (TSG) fragments in ourdata, which allows any connected syntactic struc-ture to be used as a feature.
As such, our universalrepresentation of L1/L2 data must be a constituenttree structure of the general form used in syntacticparsing experiments on the Penn Treebank.
TheUTB gets us most of the way to our goal, defininga dependency grammar with a universal set of partof speech (POS) tags and dependency arc labels.Two barriers remain to the use of standard TSGinduction algorithms.
The first is to define a map-ping from the dependency tree format to con-stituency format.
We use the following depen-dency tree to illustrate our transformation.ROOT DT NN VBZ PRPThe poodle chews itrootdetnsubjdobjUnder our transformation, the above dependencyparse becomesROOTrootVBZ-LnsubjNN-LdetDTtheNNpoodleVBZchewsVBZ-RdobjPRPitWe also require a multilingual lexicon in the formof a function ML(w) for each language L thatmaps words to clusters representing their meaning.In order to avoid cultural cues and reduce noisein our mapping, we restrict ourselves to clustersthat correspond to a list of L2 stopwords.
Any L2words that do not appear on this list are mappedto the unknown ?UNK?
symbol, as are all for-eign words that are not good translations of anyL2 stopword.
Multiple words from a single lan-guage can map to the same cluster, and it is worthnoting that this is true for L2 stopwords as well.To determine the mapping functions MLwetrain IBM translation models in both directions be-tween the L2 and each L1.
We create a graph inwhich nodes are words, either the L2 stopwords orany L1 word with some translation probability to170or from one of the L2 stopwords.
The edges in thisgraph exist only between L2 and L1 words, andare directed with weight equal to the IBM model?stranslation probability of the edge?s target givenits source.
We construct MLby removing edgeswith weight below some threshold and calculatingthe connected components of the resulting graph.We then discard any cluster that does not containat least one word from each L1 and at least one L2stopword.To propose a candidate list C, we use the TSGinduction technique described in Swanson andCharniak (2013), which simultaneously inducesmultiple TSGs from data that has been partitionedinto labeled types.
This method permits linguisti-cally motivated constraints as to which grammarsproduce each type of data.
For an experimentalsetup that considers n different L1s, we use 2n+1data types; Figure 1 shows the exact layout usedin our experiments.
Besides the necessary n datatypes for each L1 in its actual native language formand n in L2 form, we also include L2 data fromL2 native speakers.
We also define 2n + 1 gram-mars.
We begin with n grammars that can eachbe used exclusively by one native language datatype, representing behavior that is unique to eachnative language (grammars A-C in Figure 1) .
Thisis done for the L2 as well (grammar G).
Finally,we create an interlanguage grammar for each ofour L1 types that can be used in derivation of bothL1 and L2 data produced by speakers of that L1(grammars D-F).The final step is to filter and rank the TSG frag-ments produced in C, where filtering removes re-dundant features and ranking provides some quan-tification of our confidence in a feature as a lan-guage transfer hypothesis.
Swanson and Char-niak (2013) provides a similar method for pure L2data, which we modify for our purposes.
For re-dundancy filtering no change is necessary, and weuse their recommended Symmetric Uncertaintymethod.
For a ranking metric of how well a frag-ment fits the profile of language transfer we adoptthe expected per feature loss (or risk) also de-scribed in their work.
For an arbitrary feature F ,this is defined asR(F ) =1|TF|?t?TFPF(L 6= L?t)where TFis the subset of the test data that containsthe feature F , and L?tis the gold label of test da-L2DataL1DataDE DEFR FRES ESENABCDEFGFigure 1: The multi-grammar induction setup usedin our experiments.
Squares indicate data types,and circles indicate grammars.
Data type labelsindicate the native language of the speaker, and allL2 data is in English.tum t. While in their work the predictive distribu-tion PF(L) is determined by the observed countsof F in L2 training data, we take our estimatesdirectly from the L1 data of the languages understudy.
This metric captures the extent to which theknowledge of a feature F ?s L1 usage can be usedto predict its usage in L2.The final result is a ranked and filtered list of hy-potheses H .
The elements of H can be subjectedto further investigation by experts and the accom-panying histogram of counts contains the relevantempirical evidence.
As more data is added, theuncertainty in the relative proportions of these his-tograms and their corresponding R is decreased.One additional benefit of our method is that TSGinduction is a random process, and repeated runsof the sampling algorithm can produce differentfeatures.
Since redundancy is filtered automati-cally, these different feature lists can be combinedand processed to potentially find additional fea-tures given more computing time.4 ResultsLimited by the intersection of languages acrossdata sets, we take French, Spanish, and Germanas our set of L1s with English as the L2.
We usethe UTB for our native language data, which pro-vides around 4000 sentences of human annotatedtext for each L1.
For our L2 data we use the ETSCorpus of Non-Native English (Blanchard et al.,2013), which consists of over 10K sentences perL1 label drawn from TOEFLrexam essays.
Fi-171nally, we use the Penn Treebank as our source ofnative English data, for a total of seven data types;four in English, and one in each L1.When calculating metrics such as redundancyand R(F ) we use all available data.
For TSGsampling, we balance our data sets to 4000 sen-tences from each data type and sample using theEnbuske sampler that was released with Swansonand Charniak (2013).
To construct word clusters,we use Giza++ (Och and Ney, 2003) and train onthe Europarl data set (Koehn, 2005), using .25 asa threshold for construction on connected compo-nents.We encourage the reader to peruse the full listof results1, in which each item contains the infor-mation in the following example.advclVERB-LmarkVERB110VERB-RES DE FRL1 4.2 0.0 0.0L2 2.3 0.3 0.3This fragment corresponds to an adverbialclause whose head is a verb in the cluster 110,which contains the English word ?is?
and its vari-ous translations.
This verb has a single left depen-dent, a clause marker such as ?because?, and atleast one right dependent.
Its prevalence in Span-ish can explained by examining the translations ofthe English sentence ?I like it because it is red?.ES Me gusta porque es rojo.DE Ich mag es, weil es rot ist.FR Je l?aime parce qu?il est rouge.Only in the Spanish sentence is the last pronoundropped, as in ?I like it because is red?.
Thisobservation, along with the L1/L2 profile whichshows the count per thousand sentences in eachlanguage provides a strong argument that this pat-tern is indeed a form of language transfer.Given our setup of three native languages, a fea-ture with R(F ) < .66 is a candidate for languagetransfer.
However, several members of our filteredlist have R(F ) > .66, which is to say that their1bllip.cs.brown.edu/download/interlanguage corpus.pdf0.340.360.380.40.420.440  10  20  30  40  50  60  70  80  90Classification Accuracy(%)Sentences Per Test CaseFigure 2: Creating test cases that consist of sev-eral sentences mediates feature sparsity, providingclear evidence for the discriminative power of thechosen feature set.L2 usage does not mirror L1 usage.
This is to beexpected in some cases due to noise, but it raisesthe concern that our features withR(F ) < .66 arealso the result of noise in the data.
To address this,we apply our features to the task of cross languageNLI using only L1 data for training.
If the varia-tion ofR(F ) around chance is simply due to noisethen we would expect near chance (33%) classifi-cation accuracy.
The leftmost point in Figure 2shows the initial result, using boolean features ina log-linear classification model, where a test caseinvolves guessing an L1 label for each individualsentence in the L2 corpus.
While the accuracydoes exceed chance, the margin is not very large.One possible explanation for this small marginis that the language transfer signal is sparse, as itis likely that language transfer can only be used tocorrectly label a subset of L2 data.
We test this bycombining randomly sampled L2 sentences withthe same L1 label, as shown along the horizontalaxis of Figure 2.
As the number of sentences usedto create each test case is increased, we see an in-crease in accuracy that supports the argument forsparsity; if the features were simply weak predic-tors, this curve would be flat.
The resulting marginis much larger, providing evidence that a signifi-cant portion of our features with R(F ) < .66 arenot selected due to random noise in R and are in-deed connected to language transfer.The number and strength of these hypotheses iseasily augmented with more data, as is the numberof languages under consideration.
Our results alsomotivate future work towards automatic genera-tion of L1 targeted language education exercises,and the fact that TSG fragments are a componentof a well studied generative language model makesthem well suited to such generation tasks.172ReferencesDaniel Blanchard, Joel Tetreault, Derrick Higgins,Aoife Cahill, and Martin Chodorow.
2013.
Toefl11:A corpus of non-native english.
Technical report,Educational Testing Service.Julian Brooke and Graeme Hirst.
2012.
Measur-ing Interlanguage: Native Language Identificationwith L1-influence Metrics.
In Proceedings of theEighth International Conference on Language Re-sources and Evaluation (LREC-2012), pages 779?784, Istanbul, Turkey, May.
European Language Re-sources Association (ELRA).
ACL Anthology Iden-tifier: L12-1016.Glenn Carroll and Eugene Charniak.
1992.
Two exper-iments on learning probabilistic dependency gram-mars from corpora.
Technical Report CS-92-16,Brown University, Providence, RI, USA.Trevor Cohn and Phil Blunsom.
2010.
Blocked infer-ence in bayesian tree substitution grammars.
pages225?230.
Association for Computational Linguis-tics.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In ACL, pages 771?779.Scott Jarvis and Scott Crossley, editors.
2012.
Ap-proaching Language Transfer Through Text Classi-fication: Explorations in the Detection-based Ap-proach, volume 64.
Multilingual Matters Limited,Bristol, UK.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
MT Summit.Ryan T. McDonald, Joakim Nivre, YvonneQuirmbach-Brundage, Yoav Goldberg, Dipan-jan Das, Kuzman Ganchev, Keith Hall, Slav Petrov,Hao Zhang, Oscar T?ackstr?om, Claudia Bedini,N?uria Bertomeu Castell?o, and Jungmee Lee.
2013.Universal dependency annotation for multilingualparsing.
In ACL (2), pages 92?97.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Comput.
Linguist., 29(1):19?51, March.Matt Post and Daniel Gildea.
2009.
Bayesian learningof a tree substitution grammar.
In Proceedings of theACL-IJCNLP 2009 Conference Short Papers, pages45?48.
Association for Computational Linguistics.Ben Swanson and Eugene Charniak.
2013.
Extractingthe native language signal for second language ac-quisition.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 85?94, Atlanta, Georgia, June.
As-sociation for Computational Linguistics.Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language identi-fication shared task.
In Proceedings of the EighthWorkshop on Innovative Use of NLP for BuildingEducational Applications, Atlanta, GA, USA, June.Association for Computational Linguistics.173
