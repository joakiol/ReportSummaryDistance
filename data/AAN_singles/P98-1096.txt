Robust Interaction through Partial Interpretation and DialogueManagementArne  JSnsson  and Lena  StrSmb~ick*Depar tment  of Computer  and Informat ion ScienceLinkSping University, S - 58183 LinkSping, Swedenemail: arj@ida.liu.se lestr@ida.liu.seAbst rac tIn this paper we present results on developing ro-bust natural language interfaces by combining shal-low and partial interpretation with dialogue manage-ment.
The key issue is to reduce the effort neededto adapt the knowledge sources for parsing and in-terpretation to a necessary minimum.
In the paperwe identify different types of information and presentcorresponding computational models.
The approachutilizes an automatically generated lexicon which isupdated with information from a corpus of simulat-ed dialogues.
The grammar is developed manuallyfrom the same knowledge sources.
We also presentresults from evaluations that support he approach.1 In t roduct ionRelying on a traditional deep and completeanalysis of the utterances in a natural lan-guage interface requires much effort on buildinggrammars and lexicons for each domain.
An-alyzing a whole utterance also gives problemswith robustness, since the grammars need tocope with all possible variations of an utter-ance.
In this paper we present results on devel-oping knowledge-based natural anguage inter-faces for information retrieval applications uti-lizing shallow and partial interpretation.
Simi-lar approaches are proposed in, for instance, thework on flexible parsing (Carbonell and Hayes,1987) and in speech systems (cf.
(Sj51anderand Gustafson, 1997; Bennacef et al, 1994)).The interpretation is driven by the informationneeded by the background system and guidedby expectations from a dialogue manager.The analysis is done by parsing as smallparts of the utterance as possible.
The infor-mation needed by the interpretation module,i.e.
grammar and lexicon, is derived from thedatabase of the background system and infor-mation from dialogues collected in Wizard of" Authors  are in alphabetical  orderOz-experiments.
We will present what types ofinformation that are needed for the interpreta-tion modules.
We will also report on the sizesof the grammars and lexicon and results fromapplying the approach to information retrievalsystems.2 D ia logue  managementPartial interpretation is particularly well-suitedfor dialogue systems, as we can utilize informa-tion from a dialogue manager on what is ex-pected and use this to guide the analysis.
Fur-thermore, dialogue management allows for focustracking as well as clarification subdialogues tofurther improve the interaction (JSnsson, 1997).In information retrieval systems a commonuser initiative is a request for domain conceptinformation from the database; users specify adatabase object, or a set of objects, and askfor the value of a property of that object or setof objects.
In the dialogue model this can bemodeled in two focal parameters: Objects relat-ed to database objects and Properties modelingthe domain concept information.
The Proper-ties parameter models the domain concept ina sub-parameter termed Aspect which can bespecified in another sub-parameter termed Val-ue.
The specification of these parameters inturn depends on information from the user ini-tiative together with context information andthe answer from the database system.
The ac-tion to be carried out by the interface for task-related questions depends on the specificationof values passed to the Objects and Propertiesparameters (JSnsson, 1997).We can also distinguish two types of infor-mation sources utilized by the dialogue manag-er; the database with task information, T, orsystem-related information about the applica-tion, S.5903 Types  o f  in fo rmat ionWe can identify different ypes of informationutilized when interpreting an utterance in anatural language interface to a database sys-tem.
This information corresponds to the in-formation that needs to be analyzed in user-utterances.Domain  concepts  are concepts about whichthe system has information, mainly conceptsfrom the database, T, but also synonyms to suchconcepts acquired, for instance, from the infor-mation base describing the system, S.In a database query system users also oftenrequest information by relating concepts andobjects, e.g.
which one is the cheapest.
Wecall this type of language constructions relation-al e~pressions.
The relational expressions canbe identified from the corpus.Another common type of expressions arenumbers.
Numbers can occur in various forms,such as dates, object and property values.Set  operat ions .
It is necessary to distinguishutterances uch as: show all cars costing lessthan 70 000 from which of these costs less than70 000.
The former should get al cars costingless than 70 000 whereas the latter should uti-lize the set of cars recorded as Objects by thedialogue manager.
In some cases the user usesexpressions such as remove all cars more expen-sire than 70 000, and thus is restricting a set bymentioning the objects that should be removed.In teract iona l  concepts .
This class of con-cepts consists of words and phrases that concernthe interaction such as Yes, No, etc (cf.
(Byronand Heeman, 1997)).Task /System express ions.
Users can use do-main concepts uch as explain, indicating thatthe domain concept is not referring to a requestfor information from the database, T, but in-stead from the system description, S.When acquiring information for the interpreter,three different sources of information can be uti-lized: 1) background system information, i.e.the database, T, and the information describ-ing the background system's capabilities, S, 2)information from dialogues collected with usersof the system, and 3) common sense and priorknowledge on human-computer interaction andnatural language dialogue.
The various infor-mation sources can be used for different pur-poses (JSnsson, 1993).4 The  in terpreta t ion  modu leThe approach we are investigating relies on an-alyzing as small and crucial parts of the ut-terances as possible.
One of the key issues isto find these parts.
In some cases an analy-sis could consist of one single domain or inter-actional concept, but for most cases we needto analyze small sub-phrases of an utterance toget a more reliable analysis.
This requires flex-ibility in processing of the utterances and is afurther development of the ideas described inStrSmb~ick (1994).
In this work we have cho-sen to use PATR-II but in the future construc-tions from a more expressive formalism such asEFLUF (StrSmb~ck, 1997) could be needed.Flexibility in processing is achieved by one ex-tension to ordinary PATR and some additionsto a chart parser environment.
Our version ofPATR allows for a set of unknown words with-in phrases.
This gives general grammar ules,and helps avoiding the analysis to be stuck incase of unknown words.
In the chart parsingenvironment it is possible to define which of theinactive edges that constitute the result.The grammar is divided into five grammarmodules where each module corresponds tosome information requested by the dialoguemanager.
The modules can be used indepen-dently from each other.Domain  concepts  are captured using twogrammar modules.
The task of these grammarsis to find keywords or sub-phrases in the expres-sions that correspond to the objects and prop-erties in the database.
The properties can beconcept keywords or relational expressions con-taining concept keywords.
Numbers are typedaccording to the property they describe, e.g.40000 denote a price.To simplify the grammars we only requirethat the grammar recognizes all objects andproperties mentioned.
The results of theanalyses are filtered through the heuristics thatonly the most specific objects are presented tothe dialogue manager.Set operat ions .
This grammar module591provides a marker to tell the dialogue man-ager what type of set operation the initiativerequests, new, old or restrict.
The user'sutterance is searched for indicators of any ofthese three set operators.
If no indicators arefound we will assume that the operator is old.The chart is searched for the first and largestphrase that indicates a set operator.Recognizing interactional ut terances .Many interactional utterances are not nec-essary to interpret for information retrievalsystems, such as Thank you.
However, Yes/No-expressions are important.
They can berecognized by looking for one of the keywordsyes or no.
One example of this is the utteranceNo, just the medium sized cars as an answer toif the user wants to see all cars in a large table.The Yes/No-grammar can conclude that it isa no answer and the property grammar willrecognize the phrase medium sized cars.System/Task  recogni t ion .
Utterancesasking for information about a concept, e.g.Explain the numbers for rust, can be distin-guished from utterances requesting informationacquired from the background system How rustprone are these cars by defining keywords witha special meaning, such as explain.
If any ofthese keywords are found in an utterance thedialogue manager will interpret he question assystem-related.
If not it will assume that thequestion is task-related.5 An  exampleTo illustrate the behaviour of the system con-sider an utterance such as show cars costing lessthan 100000 crowns.
The word cars indicatesthat the set operator is new.
The relationalexpression will be interpreted by the grammarrules:relprop -> property :0 p roper t ies  = I p roper t ies  .re lp rop  -> proper ty  comp g lue  ent i ty  :0 p roper t ies  = 1 proper t ies  :0 p roper t ies  = 2 proper t ies  :0 p roper t ies  = 4 proper t ies  :0 p roper t ies  va lue arg = 4 va lue  .This results in two analyses \[Aspect: price\]and \[Aspect: price, Value: \[Relation: less, Arg:100000\]\] which, when filtered by the heuristics,present he latter, the most specific analysis, tothe dialogue manager.
The dialogue managerinspects the result and as it is a valid databaserequest forwards it to the background system.However, too many objects satisfy the requestand the dialogue manager initiates a clarifica-tion request o the user to further specify therequest.
The user responds with remove audi1985 and 1988.
The keyword remove triggersthe set operator estrict and the objects are in-terpreted by the rules:ob ject  -> manufacturer :0 ob jec t  = 1 ob jec t  .ob ject  -> manufacturer * 2 year  :0 ob jec t  = 1 ob jec t  :0 ob jec t  year  = 2 year  .This results in three objects \[Manufacturer:audi\], \[Manufacturer: audi, Year: 1985\] and\[Manufacturer: audi, Year: 1988\].
When filteredthe first interpretation is removed.
This is in-tegrated by the dialogue manager to providea specification on both Objects and Propertieswhich is passed to the background system anda correct response can be provided.6 Empi r i ca l  ev idence  for  theapproachIn this section we present results on partial in-terpretation i for a natural language interface forthe CARS-application; a system for typed inter-action to a relational database with informationon second hand cars.
The corpus contains 300utterances from 10 dialogues.
Five dialoguesfrom the corpus were used when developing theinterpretation methods, the Development set,and five dialogues were used for evaluation, theTest set.6.1 Resu l tsThe lexicon includes information on what typeof entity a keyword belongs to, i.e.
Objectsor Properties.
This information is acquired au-tomatically from the database with synonymsadded manually from the background systemdescription.The automatically generated lexicon of con-cepts consists of 102 entries describing Objects1Resu l ts  on  d ia logue  management  has  been  presentedin J Snsson  (1997).592Table 1: Precision and recall for the grammarsYes/No S/T SetDevel.
set 100% 100% 97,5%Test set 100% 91,7% 86,1%ObjectsFully PartialRecall Precision Recall PrecisionDevel.
set 100% 98% 100% 98%Test set 94,1% 80% 100% 85%PropertiesFully PartialRecall Precision Recall PrecisionDevel.
set 97% 97% 99% 100%Test set 59,6% 73,9% 73,7% 91,3%and Properties.
From the system description i -formation base 23 synonyms to concepts in thedatabase were added to the lexicon.
From theDevelopment set another 7 synonyms to con-cepts in the database, 12 relational concepts and7 markers were added.The five grammars were developed manuallyfrom the Development set.
The object gram-mar consists of 5 rules and the property gram-mar consists of 21 rules.
The grammar usedfor finding set indicators consists of 13 rules.The Yes/No grammar and System/Task gram-mar need no grammar rules.
The time for devel-oping these grammars i estimated to a coupleof days.The obtained grammars and the lexicon of to-tally 151 entries were tested on both the Devel-opment set and on the five new dialogues in theTest set.
The results are presented in table 1.
Inthe first half of the table we present the numberof utterances where the Yes/No, System/Taskand Set parameters were correctly classified.
Inthe second we present recall and precision forObjects and Properties.We have distinguished fully correct inter-pretations from partially correct.
A partiallycorrect interpretation provides information onthe Aspect but might fail to consider Value-restrictions, e.g.
provide the Aspect value pricebut not the Value-restriction cheapest to an ut-terance such as what is the price of the cheapestvolvo.
This is because cheapest was not in thefirst five dialogues.The majority of the problems are due to suchmissing concepts.
We therefore added informa-tion from the Test set.
This set provided anoth-er 4 concepts, 2 relational concepts, and I mark-Table 2: Precision and recall when conceptsfrom the test set were addedPropertiesFully PartialRecall Precision Recall PrecisionTest set 92,3% 79,5% 93,8% 90,6%er and led us to believe that we have reached afairly stable set of concepts.
Adding these rela-tional and domain concepts increased the cor-rect recognition of set operations to 95,8%.
Italso increased the numbers for Properties recalland precision, as seen in table 2.
The other re-sults remained unchanged.To verify the hypothesis that the concepts areconveyed from the database and a small numberof dialogues, we analyzed another 10 dialoguesfrom the same setting but where the users knowthat a human interprets their utterance.
Fromthese ten dialogues only another 3 concepts and1 relational concept were identified.
Further-more, the concepts are borderline cases, such asmapping the concept inside measurement ontothe database property coupd, which could wellresult in a system-related answer if not addedto the lexicon.As a comparison to this a traditional non-partial PATR-grammar, developed for goodcoverage on only one of the dialogues consists ofabout 200 rules.
The lexicon needed to cover allten dialogues consists of around 470 words, tocompare with the 158 of the lexicon used here.The principles have also been evaluated ona system with information on charter trips tothe Greek archipelago, TRAVEL.
This corpuscontains 540 utterances from 10 dialogues.
Theinformation base for TRAVEL consists of textsfrom travel brochures which contains a lot ofinformation.
It includes a total of around 750different concepts.
Testing this lexicon on thecorpus of ten dialogues 20 synonyms were found.When tested on a set of ten dialogues collectedwith users who knew it was a simulation (cf.
theCARS corpus) another 10 synonyms were found.Thus 99% of the concepts utilized in this part ofthe corpus were captured from the informationbase and the first ten dialogues.
This clearlysupports the hypothesis that the relevant con-cepts can be captured from the background sys-tem and a fairly small number of dialogues.For the TRAVEL application we have also es-593timated how many of the utterances in the cor-pus that can be analyzed by this model.
90,4%of the utterances can easily be captured by themodel.
Of the remaining utterances 4,3% arepartly outside the task of the system and a stan-dard system message would be a sufficient re-sponse.
This leaves only 4,8% of the utterancesthat can not be handled by the approach.6.2 DiscussionWhen processing data from the dialogues wehave used a system for lexical error recov-ery, which corrects user mistakes uch as mis-spellings, and segmentation errors.
This systemutilizes a trained HMM and accounts for mosterrors (Ingels, 1996).
In the results on lexicaldata presented above we have assumed a systemfor morphological nalysis to handle inflectionsand compounds.The approach does not handle anaphora.This can result in erroneous responses, for in-stance, Show rust .for the mercedes will interpretthe mercedes as a new set of cars and the answerwill contain all mercedeses not only those in theprevious discourse.
In the applications studiedhere this is not a serious problem.
However,for other applications it can be important ohandle such expressions correctly.
One possiblesolution is to interpret definite form of objectdescriptions as a marker for an old set.The application of the method have only uti-lized information acquired from the database,from information on the system's capabilitiesand from corpus information.
The motivationfor this was that we wanted to use unbiasedinformation sources.
In practice, however, onewould like to augment this with common senseknowledge on human-computer interaction asdiscussed in JSnsson (1993).7 Conc lus ionsWe have presented a method for robust inter-pretation based on a generalization f PATR-IIwhich allows for generalization f grammar rulesand partial parsing.
This reduces the sizes ofthe grammar and lexicon which results in re-duced development time and faster computa-tion.
The lexical entries corresponding to en-tities about which a user can achieve informa-tion is mainly automatically created from thebackground system.
Furthermore, the systemwill be fairly robust as we can invest time onestablishing a knowledge base corresponding tomost ways in which a user can express a domainconcept.AcknowledgmentsThis work results from a number of projects on de-velopment of natural language interfaces supportedby The Swedish Transport & Communications Re-search Board (KFB) and the joint Research Pro-gram for Language Technology (HSFR/NUTEK).We are indebted to Hanna Benjaminsson a d MagueHansen for work on generating the lexicon and de-veloping the parser.Re ferencesS.
Bennacef, H. Bonneau-Maynard, J. L. Gauvin,L.
Lamel, and W. Minker.
1994.
A spoken lan-guage system for information retrieval.
In Pro-ceedings of ICLSP'9g.Donna K. Byron and Peter A. Heeman.
1997.
Dis-course marker use in task-oriented spoken dialog.In Proceedings of Eurospeech'97, Rhodes, Greece,pages 2223-2226.Jaime G. Carbonell and Philip J. Hayes.
1987.
Ro-bust parsing using multiple construction-specificstrategies.
In Leonard Bolc, editor, Natural Lan-guage Parsing Systems, pages 1-32.
Springer-Verlag.Peter Ingels.
1996.
Connected text recognition us-ing layered HMMs and token passing.
In K. Oflaz-er and H. Somers, editors, Proceedings of theSecond Conference on New Methods in LanguageProcessing, pages 121-132, Sept.Arne JSnsson.
1993.
A method for development ofdialogue managers for natural language interfaces.In Proceedings of the Eleventh National Confer-ence of Artificial Intelligence, Washington DC,pages 190-195.Arne JSnsson.
1997.
A model for habitable andefficient dialogue management for natural an-guage interaction.
Natural Language Engineering,3(2/3):103-122.K?re SjSlander and Joakim Gustafson.
1997.
An in-tegrated system for teaching spoken dialogue sys-tems technology.
In Proceedings of Eurospeech '97,Rhodes, Greece, pages 1927-1930.Lena StrSmb/ick.
1994.
Achieving flexibility in uni-fication formalisms.
In Proceedings of 15th Int.Conf.
on Computational Linguistics (Coling'94),volume II, pages 842-846, August.
Kyoto, Japan.Lena StrSmb~ick.
1997.
EFLUF - an implementa-tion of a flexible unification formalism.
In Procof ENVGRAM - Computational Environmentsfor Practical Grammar Development, Processingand Integration with other NLP modules., July.Madrid, Spain.594
