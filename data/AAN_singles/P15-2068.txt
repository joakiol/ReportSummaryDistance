Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 414?418,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsIWNLP: Inverse Wiktionary for Natural Language ProcessingMatthias Liebeck and Stefan ConradInstitute of Computer ScienceHeinrich-Heine-University D?usseldorfD-40225 D?usseldorf, Germany{liebeck,conrad}@cs.uni-duesseldorf.deAbstractNowadays, there are a lot of natural lan-guage processing pipelines that are basedon training data created by a few experts.This paper examines how the prolifera-tion of the internet and its collaborativeapplication possibilities can be practicallyused for NLP.
For that purpose, we ex-amine how the German version of Wik-tionary can be used for a lemmatizationtask.
We introduce IWNLP, an open-source parser for Wiktionary, that reim-plements several MediaWiki markup lan-guage templates for conjugated verbs anddeclined adjectives.
The lemmatizationtask is evaluated on three German corporaon which we compare our results with ex-isting software for lemmatization.
WithWiktionary as a resource, we obtain a highaccuracy for the lemmatization of nounsand can even improve on the results ofexisting software for the lemmatization ofnouns.1 IntroductionWiktionary is an internet-based dictionary and the-saurus that lists words, inflected forms and rela-tions (e.g.
synonyms) between words.
Just asWikipedia, Wiktionary uses MediaWiki as a plat-form but focuses on word definitions and theirmeaning, rather than explaining each word in de-tail, as Wikipedia does.
The dictionary containsarticles, which can each list multiple entries fordifferent languages and multiple parts of speech.For instance, the English word home has entries asa noun, verb, adjective and as an adverb.Each article is rendered by the MediaWiki en-gine from a text-based input, which uses the Me-diaWiki syntax and relies heavily on the use oftemplates.
The articles are editable by everyone,Table 1: Declension of the German noun Turm(tower)Case Singular PluralNominative der Turm die T?urmeGenitive des Turmes der T?urmedes TurmsDative dem Turm den T?urmendem TurmeAccusative den Turm die T?urmeeven by unregistered users.
Although vandalism ispossible, most of the vandalized entries are iden-tified by other users who watch a list of the lat-est changes and subsequently revert these entriesto previously correct versions.
All text contentis licensed under the Creative Commons License,which makes it attractive for academic use.There are currently 111 localized versions ofWiktionary, which contain more than 1000 arti-cles1.
A localized version can establish own rulesvia majority votes and public opinion.
For exam-ple, the German version of Wiktionary2currentlyenforces a 5-source-rule, which requires that eachentry that is not listed in a common dictionary isdocumented by at least 5 different sources.
TheGerman version of Wiktionary has grown over thelast years and currently contains almost 400000 ar-ticles3.
Each word is listed with its part-of-speechtag, among other information.
If a word is in-flectable (nouns, verbs, adjectives, pronouns andarticles are inflectable in the German language),all inflected forms are also enumerated.
Table 1shows the declension of the noun Turm (tower).Wiktionary provides information that can be usedas a resource for Natural Language Processing(NLP), for instance for part-of-speech tagging, forlemmatization and as a thesaurus.1https://meta.wikimedia.org/wiki/Wiktionary2https://de.wiktionary.org3https://de.wiktionary.org/wiki/Wiktionary:Meilensteine414The rest of the paper is structured as follows:Section 2 gives on overview of previous applica-tions of Wiktionary for natural language process-ing purposes.
Section 3 outlines the basic steps ofparsing Wiktionary.
The use of Wiktionary as alemmatizer is evaluated in section 4 and comparedwith existing software for lemmatization.
Finally,we conclude in chapter 5 and outline future work.2 Related WorkThe closest work to ours is JWKTL (Zesch et al,2008).
JWKTL is a Wiktionary parser that wasoriginally developed for the English and the Ger-man version of Wiktionary, but it now also sup-ports Russian.
Our work differs from JWKTL, be-cause we currently focus more on inflections in theGerman version than JWKTL.
Therefore, we havea larger coverage of inflections, because we addi-tionally reimplemented several templates from thenamespace Flexion.
Also, we have an improvedhandling of special syntactic cases, as comparedto JWKTL.Wiktionary has previously been used for sev-eral NLP tasks.
The use of the German editionas a thesaurus has been investigated by Meyerand Gurevych (2010).
The authors compared thesemantic relations in Wiktionary with GermaNet(Hamp and Feldweg, 1997) and OpenThesaurus(Naber, 2005).Smedt et al (2014) developed a part-of-speechtagger based on entries in the Italian version ofWiktionary.
They achieved an accuracy of 85,5 %with Wiktionary alone.
By using morphologicaland contextual rules, they improve their taggingto an accuracy of 92,9 %.
Li et al (2012) alsoused Wiktionary to create a part-of-speech tagger,which is based on a hidden Markov model.
Theirevaluation of 9 different languages shows an aver-age accuracy of 84,5 %, with English having thebest result with an accuracy of 87,1 %.3 Parsing WiktionaryThere are multiple ways to parse Wiktionary.
It ispossible to crawl all existing articles from the on-line servers.
To reduce stress from the servers andto easily reproduce our parsing results, we parsethe latest of the monthly XML dumps4from Wik-tionary.
For this paper, we use the currently latestdump 20150407.4http://dumps.wikimedia.org/dewiktionary/We iterate over every article in the XML dumpand parse articles which contain German word en-tries.
These articles can be separated into twogroups: the ones in the main namespace (with-out any preceding namespace, like ?namespace:?
)and the ones in the namespace Flexion.
First, wedescribe how we parse the articles in the mainnamespace.
An article can contain entries for mul-tiple languages.
Therefore, we divide its text con-tent into language blocks (== heading ==) and skipnon-German language blocks.
Afterward, we ex-tract one or more entries (=== heading ===) fromeach German language block.
If an article listsmore than one entry with the same name, its wordforms will be different from each other.
For in-stance, the German word Mutter5, contains an en-try for mother and for nut, which have differentplural forms.
We parse the part-of-speech tag foreach entry.
If a word is inflectable, we will alsoparse its inflections, which are listed in a key-value-pair template.
Depending on the part-of-speech tag, different templates are used in Wik-tionary for which we use different parsers.
Weprovide parsers for nouns, verbs, adjective andpronouns.
The key-value-template for the adjec-tive gelb (yellow) is displayed in Figure 1.== gelb ({{Language|German}}) ===== {{POS|Adjective|German}} ==={{German Adjective Overview|Positive=gelb|Comparative=gelber|Superlative=am gelbsten}}Figure 1: Adjective template for the word gelb(yellow), with keywords translated into EnglishAt this point, we should point out that the inflec-tions for verbs and adjectives in the main names-pace are only a small portion of all possible inflec-tions.
For example, a verb in the main namespaceonly lists one inflection for the past tense (firstperson singular), while other possible past tenseforms are not listed.Fortunately, it is possible that a verb or an ad-jective has an additional article in the namespaceFlexion, where all inflections are listed.
However,the parsing of these inflections is more challeng-ing, because the articles use complex templates.5https://de.wiktionary.org/wiki/Mutter415Although the parsing of the parameters for thetemplates remains the same, it is more difficultto retrieve the rendered output by the MediaWikiengine (and thus the inflections) from these tem-plates, because it is very rare that inflections arelisted as a key-value-pair.
Instead, these templatesrequire principal parts, which are combined withsuffixes.
The users of Wiktionary have createdtemplates, that take care of special cases, for in-stance for a verb conjugation, where the suffix?est?
is added to a verb stem instead of ?st?, if thelast character of a verb stem is a ?t?.
Wiktionaryuses a MediaWiki extension called ParserFunc-tions, which allows the use of control flows, likeif-statements and switch statements.
Special casesfor the conjugation of verbs and the declension ofadjectives are covered by a nested control flow.We have analyzed these templates and reimple-mented the template of the adjectives and the mostfrequently used templates for verbs into IWNLPas C# code.
In total, Wiktionary currently contains3705 verb conjugations in the Flexion namespace,which use several templates.
We have limited ourimplementation to the three most used verb con-jugation templates (weak inseparable (51,4 %), ir-regular (27,2 %), regular (12,4 %)).Altogether, we have extracted 74254 differentwords and 281457 different word forms.
To re-duce errors while parsing, we have written morethan 150 unit tests to ensure that our parser oper-ates as accurate as possible on various notationsand special cases.
During the development ofIWNLP, we have manually corrected more than200 erroneous Wiktionary articles, which con-tained wrong syntax or false content.
To guaranteethat we didn?t worsen the quality of these articles,we?ve consulted experienced Wiktionary users be-fore performing these changes.Our parser and its output will be made availableunder an open-source license.64 LemmatizationWiktionary can be used as a resource for multi-ple NLP tasks.
Currently, we are interested in us-ing Wiktionary as a resource for a lemmatizationtask, where we want to determine a lemma for agiven inflected form.
For each lemma, Wiktionarylists multiple inflected forms.
As outlined in sec-tion 3, we have parsed the inflected forms for eachlemma.
For our lemmatization task, we inverse6http://www.iwnlp.comthis mapping to retrieve a list of possible lem-mas for a given inflection, hence our project nameIWNLP.
For example, we use the information pre-sented in Table 1 to retrieve T?urme 7?
Turm.
Foreach lemma l in Wiktionary, we have also addeda mapping l 7?
l. Our mapping will also be avail-able via download.It is possible, that an inflected form maps tomore than one lemma.
For instance, the wordKohle maps to Kohle (coal) and Kohl (cabbage).In total, our mapping contains 2035 words, whichmap to more than one lemma.With this paper, we want to evaluate how goodWiktionary performs in a lemmatization task.
Ad-ditionally, we want to validate our assumption,that by first looking up word forms and their lem-mas in Wiktionary, we should be able to improvethe performance of existing software for lemmati-zation.Therefore, we evaluate IWNLP and existingsoftware on three German corpora, which listwords and their lemmas: TIGER Corpus (Brantset al, 2004), Hamburg Dependency Treebank(HDT) (Foth et al, 2014) and T?uBa-D/Z (Telljo-hann et al, 2012) release 9.1.
The TIGER Cor-pus consists of 50472 sentences from the Germannewspaper Frankfurter Rundschau.
The HamburgDependency Treebank (part A) contains 101981sentences from the German IT news site Heise on-line.
The T?uBa-D/Z corpus comprises of 85358sentences from the newspaper die tageszeitung(taz).
Each word in these corpora is listed with itspart-of-speech tag from the STTS tagset (Schilleret al, 1999).
We evaluate the lemmatization fornouns (POS tag NN), verbs (POS tags V*) and ad-jectives (POS tags ADJA and ADJD).
Due to thelow amount of different articles and pronouns inthe German language, we ignore them in our eval-uation.In our experiments, we look up the nouns, verbsand adjectives from each corpus in IWNLP.
If wemap a word form to more than one lemma inIWNLP, we treat this case as if there would be noentry for this particular word form in IWNLP.
Thesame policy is applied in all of our experiments.We preserve case sensitivity, which worsens ourresults slightly.
In a modification, that we namekeep, we assume that a word w will be its ownlemma, if w does not have an entry in the map-ping.
IWNLP is compared with a mapping7ex-7http://www.danielnaber.de/morphologie/index en.html416MethodTIGER Corpus T?uBa-D/Z HDTNoun Verb Adj Noun Verb Adj Noun Verb AdjIWNLP 0,734 0,837 0,633 0,720 0,809 0,567 0,607 0,864 0,613IWNLP + keep 0,894 0,854 0,692 0,897 0,827 0,650 0,647 0,882 0,699Morphy 0,196 0,713 0,531 0,181 0,671 0,490 0,163 0,675 0,475Morphy + keep 0,857 0,962 0,763 0,860 0,916 0,744 0,619 0,963 0,735Mate Tools ?
?
?
0,926 0,927 0,852 0,639 0,971 0,712TreeTagger 0,860 0,974 0,867 0,848 0,930 0,832 0,611 0,977 0,687IWNLP + Mate Tools ?
?
?
0,943 0,929 0,841 0,653 0,976 0,751Morphy + Mate Tools ?
?
?
0,918 0,932 0,837 0,627 0,974 0,744IWNLP + TreeTagger 0,888 0,969 0,869 0,879 0,927 0,795 0,641 0,973 0,724Morphy + TreeTagger 0,859 0,970 0,810 0,843 0,926 0,787 0,602 0,968 0,713Table 2: Lemmatization accuracy for nouns, verbs and adjectives in all three corporatracted from Morphy (Lezius et al, 1998), a toolfor morphological analysis.For our comparison with existing software, thatcan be used for lemmatization, we have chosenMate Tools (Bj?orkelund et al, 2010) and Tree-Tagger (Schmid, 1994), which both accept token-based input.The results of our experiments are shown in Ta-ble 2.
In a direct comparison between IWNLP andMorphy, IWNLP outperforms Morphy in the ba-sic variant in all POS tags across all corpora.
Withthe modification keep, the results of IWNLP andMorphy improve.
IWNLP + keep is still superiorfor nouns, but Morphy + keep achieves better re-sults for verbs and adjectives.
The results fromMate Tools on the TIGER Corpus are excludedfrom Table 2 because Mate Tools was trained onthe TIGER Corpus and, therefore, cannot be eval-uated on it.
The direct comparison of Mate Toolsand TreeTagger shows that Mate Tools achievesan accuracy that is at least 2 % better in four of thesix cases.
In the other two cases, TreeTagger onlyperforms slightly better.For the lemmatization of nouns, IWNLP is ableto improve on the results of Mate Tools and Tree-Tagger across all three corpora.
In total, IWNLPenhances the results of Mate Tools in five of thesix test cases.
Surprisingly, the additional lookupof word forms in IWNLP and Morphy can impairthe accuracy for verbs and adjectives.
In our futurework, we will systematically analyze which wordsare responsible for worsening the results, correcttheir Wiktionary articles and improve our lookupin IWNLP.The overall bad performance for the lemmatiza-tion of nouns in the HDT corpus can be explainedby the gold lemmas for compound nouns, whichare often defined as the last word in the compoundnoun.
For instance, HDT defines that Freiheit(freedom) is the gold lemma for Meinungsfreiheit(freedom of speech).5 ConclusionWe have presented IWNLP, a parser for the Ger-man version of Wiktionary.
The current focus ofthe parser lies in the extraction of inflected forms.They have been used to construct a mapping frominflected forms to lemmas, which can be utilizedin a lemmatization task.
We evaluated our IWNLPlemmatizer on three German corpora.
The resultsfor the lemmatization of nouns show that IWNLPoutperforms existing software on the TIGER Cor-pus and can improve their results on the T?uBa-D/Zand the HDT corpora.
However, we have also dis-covered that we still need to improve IWNLP toget better results for the lemmatization of verbsand adjectives.
We will try to resolve the correctlemma for an inflected form if multiple lemmasare possible.Additionally, IWNLP will be extended to parsehyponyms and hypernyms for nouns.
We plan tocompare the use of Wiktionary as thesaurus withGermaNet (Hamp and Feldweg, 1997).We expect that the presented results for thelemmatization task will improve with every newmonthly dump if Wiktionary continues to growand improve through a community effort.AcknowledgmentsThis work is part of the graduate school NRWFortschrittskolleg Online-Partizipation.
We thank417the Wiktionary user Yoursmile for his help.ReferencesAnders Bj?orkelund, Bernd Bohnet, Love Hafdell, andPierre Nugues.
2010.
A High-Performance Syn-tactic and Semantic Dependency Parser.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics: Demonstrations, COL-ING ?10, pages 33?36.
Association for Computa-tional Linguistics.Sabine Brants, Stefanie Dipper, Peter Eisenberg, Sil-via Hansen-Schirra, Esther K?onig, Wolfgang Lezius,Christian Rohrer, George Smith, and Hans Uszko-reit.
2004.
TIGER: Linguistic Interpretation of aGerman Corpus.
Research on Language and Com-putation, 2(4):597?620.Kilian A. Foth, Arne K?ohn, Niels Beuck, and WolfgangMenzel.
2014.
Because Size Does Matter: TheHamburg Dependency Treebank.
In Proceedings ofthe Ninth International Conference on Language Re-sources and Evaluation (LREC-2014), pages 2326?2333.Birgit Hamp and Helmut Feldweg.
1997.
GermaNet -a Lexical-Semantic Net for German.
In Proceedingsof ACL workshop Automatic Information Extractionand Building of Lexical Semantic Resources for NLPApplications, pages 9?15.Wolfgang Lezius, Reinhard Rapp, and Manfred Wet-tler.
1998.
A Freely Available Morphological Ana-lyzer, Disambiguator and Context Sensitive Lemma-tizer for German.
In Proceedings of the 17th Inter-national Conference on Computational Linguistics -Volume 2, COLING ?98, pages 743?748.
Associa-tion for Computational Linguistics.Shen Li, Jo?ao V. Grac?a, and Ben Taskar.
2012.
Wiki-lySupervised Part-of-speech Tagging.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, EMNLP-CoNLL ?12,pages 1389?1398.
Association for ComputationalLinguistics.Christian M. Meyer and Iryna Gurevych.
2010.
WorthIts Weight in Gold or Yet Another Resource - AComparative Study of Wiktionary, OpenThesaurusand GermaNet.
In Computational Linguistics andIntelligent Text Processing, 11th International Con-ference, CICLing 2010, volume 6008 of LectureNotes in Computer Science, pages 38?49.
Springer.Daniel Naber.
2005.
OpenThesaurus: ein offenesdeutsches Wortnetz.
In Sprachtechnologie, mo-bile Kommunikation und linguistische Ressourcen:Beitr?age zur GLDV-Tagung 2005 in Bonn, pages422?433.
Peter-Lang-Verlag.Anne Schiller, Simone Teufel, Christine St?ockert, andChristine Thielen.
1999.
Guidelines f?ur das Taggingdeutscher Textcorpora mit STTS (kleines und gro?esTagset).
Technical report, Universit?at Stuttgart, Uni-versit?at T?ubingen.Helmut Schmid.
1994.
Probabilistic Part-of-SpeechTagging Using Decision Trees.
In Proceedings ofthe International Conference on New Methods inLanguage Processing.Tom De Smedt, Fabio Marfia, Matteo Matteucci, andWalter Daelemans.
2014.
Using Wiktionary toBuild an Italian Part-of-Speech Tagger.
In Natu-ral Language Processing and Information Systems- 19th International Conference on Applications ofNatural Language to Information Systems, NLDB2014, volume 8455 of Lecture Notes in ComputerScience, pages 1?8.
Springer.Heike Telljohann, Erhard W. Hinrichs, Sandra K?ubler,Heike Zinsmeister, and Kathrin Beck.
2012.
Style-book for the T?ubingen Treebank of Written Ger-man (T?uBa-D/Z).
Technical report, University ofT?ubingen.Torsten Zesch, Christof M?uller, and Iryna Gurevych.2008.
Extracting Lexical Semantic Knowledge fromWikipedia and Wiktionary.
In Proceedings of theSixth International Conference on Language Re-sources and Evaluation (LREC?08).
European Lan-guage Resources Association.418
