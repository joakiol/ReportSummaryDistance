Coling 2010: Poster Volume, pages 1426?1434,Beijing, August 2010Cross-Lingual Induction for Deep Broad-Coverage Syntax: A CaseStudy on German ParticiplesSina Zarrie?
Aoife Cahill Jonas Kuhn Christian RohrerInstitut fu?r Maschinelle Sprachverarbeitung (IMS), University of Stuttgart{zarriesa,cahillae,jonas.kuhn,rohrer}@ims.uni-stuttgart.deAbstractThis paper is a case study on cross-lingualinduction of lexical resources for deep,broad-coverage syntactic analysis of Ger-man.
We use a parallel corpus to in-duce a classifier for German participleswhich can predict their syntactic category.By means of this classifier, we induce aresource of adverbial participles from ahuge monolingual corpus of German.
Weintegrate the resource into a German LFGgrammar and show that it improves pars-ing coverage while maintaining accuracy.1 IntroductionParallel corpora are currently exploited in a widerange of induction scenarios, including projectionof morphologic (Yarowsky et al, 2001), syntactic(Hwa et al, 2005) and semantic (Pado?
and Lap-ata, 2009) resources.
In this paper, we use cross-lingual data to learn to predict whether a lexi-cal item belongs to a specific syntactic categorythat cannot easily be learned from monolingual re-sources.
In an application test scenario, we showthat this prediction method can be used to obtaina lexical resource that improves deep, grammar-based parsing.The general idea of cross-lingual induction isthat linguistic annotations or structures, which arenot available or explicit in a given language, canbe inferred from another language where these an-notations or structures are explicit or easy to ob-tain.
Thus, this technique is very attractive forcheap acquisition of broad-coverage resources, asis proven by the approaches cited above.
More-over, this induction process can be attractive forthe induction of deep (and perhaps specific) lin-guistic knowledge that is hard to obtain in a mono-lingual context.
However, this latter perspectivehas been less prominent in the NLP communityso far.This paper investigates a cross-lingual induc-tion method based on an exemplary problem aris-ing in the deep syntactic analysis of German.
Thisshowcase is the syntactic flexibility of Germanparticiples, being morphologically ambiguous be-tween verbal, adjectival and adverbial readings,and it is instructive for several reasons: first, thephenomenon is a notorious problem for linguisticanalysis and annotation of German, such that stan-dard German resources do not represent the under-lying analysis.
Second, in Zarrie?
et al (2010),we showed that integrating the phenomenon ofadverbial participles in a naive way into a broad-coverage grammar of German leads to significantparsing problems, due to spurious ambiguities.Third, it is completely straightforward to detectadverbial participles in cross-lingual data since inother languages, e.g.
English or French, adverbsare often morphologically marked.In this paper, we use instances of adverbiallytranslated participles in a parallel corpus to boot-strap a classifier that is able to identify an ad-verbially used participle based on its monolingualsyntactic context.
In contrast to what is commonlyassumed, we show that it is possible to detect ad-verbial participles using only a relatively narrowcontext window.
This classifier enables us to iden-tify an occurence of an adverbial participle inde-pendently of its translation in a parallel corpus,going far beyond the induction methodology inZarrie?
et al (2010).
By means of the participleclassifier, we can extract new types of adverbialparticiples from a larger corpus of German news-paper text and substantially augment the size ofthe resource extracted only on Europarl data.
Fi-nally, we integrate this new resource into the Ger-man LFG grammar and show that it improves cov-erage without negatively affecting performance.1426The paper is structured as follows: in Sec-tion 2, we describe the linguistic and computa-tional problems related to the parsing of adver-bial participles in German.
Section 3 introducesthe general idea of using the translation data tofind instances of different participle categories.
InSection 4, we illustrate the training of the clas-sifier, evaluating the impact of the context win-dow and the quality of the training data obtainedfrom cross-lingual text.
In Section 5, we apply theclassifier to new, monolingual data and describethe extension of the resource for adverbial partici-ples.
Section 6 evaluates the extended resource bymeans of parsing experiments using the GermanLFG grammar.2 The ProblemIn German, past perfect participles are ambiguouswith respect to their morphosyntactic category.
Asin other languages, they can be used as part ofthe verbal complex (Example (1-a)) or as adjec-tives (Example (1-b)).
Since German adjectivescan generally undergo conversion into adverbs,participles can also be used adverbially (Example(1-c)).
The verbal and adverbial participle formsare morphologically identical.
(1) a. Sie haben das Experiment wiederholt.
?They have repeated the experiment.?b.
Das wiederholte Experiment war erfolgreich.
?The repeated experiment was succesful.?c.
Sie haben das Experiment wiederholt abge-brochen.
?They cancelled the experiment repeatedly.
?Moreover, German adjectival modifiers can begenerally used as predicatives that can be eitherselected by a verb (Example (2-a)) or that can oc-cur as free predicatives (Example (2-b)).
(2) a. Er scheint begeistert von dem Experiment.
?He seems enthusiastic about the experiment.?b.
Er hat begeistert experimentiert.
?He has experimented enthusiastic.
?Since predicative adjectives are not inflected,the surface form of a German participle is ambigu-ous between a verbal, predicative or adverbial use.2.1 Participles in the German LFGIn order to account for sentences like (1-c), an in-tuitive approach would be to generally allow foradverb conversion of participles in the grammar.However, in Zarrie?
et al (2010), we show thatsuch a rule can have a strong negative effect onthe overall performance of the parsing system, de-spite the fact that it produces the desired syntac-tic and semantic analysis for specific sentences.This problem was illustrated using a German LFGgrammar (Rohrer and Forst, 2006) constructed aspart of the ParGram project (Butt et al, 2002).The grammar is implemented in the XLE, a gram-mar development environment which includes avery efficient LFG parser and a stochastic dis-ambiguation component which is based on a log-linear probability model (Riezler et al, 2002).In Zarrie?
et al (2010), we found that thenaive implementation of adverbial participles inthe German LFG, i.e.
in terms of a general gram-mar rule that allows for participles-adverb conver-sion, leads to spurious ambiguities that misleadthe disambiguation component of the grammar.Moreover, the rule increases the number of time-outs, i.e.
sentences that cannot be parsed in a pre-defined amount of time (20 seconds).
Therefore,we observe a drop in parsing accuracy althoughgrammar coverage is improved.
As a solution, weinduced a lexical resource of adverbial participlesbased on their adverbial translations in a paral-lel corpus.
This resource, comprising 46 partici-ple types, restricts the adverb conversion such thatmost of the spurious ambiguities are eliminated.To assess the impact of specific rules in a broad-coverage grammar, possibly targeting medium-to-low frequency phenomena, we have established afine-grained evaluation methodology.
The chal-lenge posed by these low-frequent phenomena istypically two-fold: on the one hand, if one takesinto account the disambiguation component of thegrammar and pursues an evaluation of the mostprobable parses on a general test set, the newgrammr rule cannot be expected to show a positiveeffect since the phenomenon is not likely to occurvery often in the test set.
On the other hand, if oneis interested in a linguistically precise grammar,it is very unsatisfactory to reduce grammar cov-erage to statistically frequent phenomena.
There-fore, we combined a coverage-oriented evaluationon specialised testsuites with a quantitative evalu-ation including disambiguation, making sure that1427the increased coverage does not lead to an overalldrop in accuracy.
The evaluation methodolgy willalso be applied to evaluate the impact of the newparticiple resource, see Section 6.2.2 The Standard Flat Analysis of ModifiersThe fact that German adjectival modifiers can gen-erally undergo conversion into adverbs withoutovert morphological marking is a notorious prob-lem for the syntactic analysis of German: thereare no theoretically established tests to distinguishpredicative adjectives and adverbials, see Geuder(2004).
For this reason, the standard German tagset assigns a uniform tag (?ADJD?)
to modifiersthat are morphologically ambiguous between anadjectival and adverbial reading.
Moreover, inthe German treebank TIGER (Brants et al, 2002)the resulting syntactic differences between the tworeadings are annotated by the same flat structurethat does not disambiguate the sentence.Despite certain theoretical problems related tothe analysis of German modifiers, their interpre-tation in real corpus sentences is often unambigu-ous for native speakers.
As an example, considerexample (3) from the TIGER treebank.
In thesentence, the participle unterschrieben (signed)clearly functions as a predicative modifier of thesentence?s subject.
The other, theoretically possi-ble reading where the participle would modify theverb send is semantically not acceptable.
How-ever, in TIGER, the participle is analysed as anADJD modifier attached under the VP node whichis the general analysis for adjectival and adverbialmodifiers.
(3) DieItsollteshouldunterschriebensignedantodietheLeitungadministrationzuru?ckgesandtsent backwerden.be.
?It should be sent back signed to the administation.
?Sentence (4) (also taken from TIGER) illus-trates the case of an adverbial participle.
In thisexample, the reading where angemessen (ade-quately) modifies the main verb is the only onethat is semantically plausible.
In the treebank, theparticiple is tagged as ADJD and analysed as amodifier in the VP.
(4) DerThemenschlichehumanGeistmindla??tletssichitselfrechnerischcomputationallynichtnotangemessenadequatelysimulieren.simulate.
?The human mind cannot be adequately simulated in acomputational way.
?The flat annotation strategy adopted for modi-fiers in the standard German tag set and in the tree-bank TIGER entails that instances of adverbs (andadverbial participles) cannot be extracted from au-tomatically tagged, or parsed, text.
Therefore,it would be very hard to obtain training mate-rial from German resources to train a system thatautomatically identifies adverbially used partici-ples.
However, the intuition corroborated by theexamples presented in this section is that the struc-tures can actually be disambiguated in many cor-pus sentences.In the following sections, we show how we ex-ploit parallel text to obtain training material forlearning to predict occurences of adverbial par-ticiples, without any manual effort.
Moreover, bymeans of this technique, we can substantially ex-tend the grammatical resource for adverbial par-ticiples compared to the resource that can be di-rectly extracted from the parallel text.3 Participles in the Parallel CorpusThe intuition of the cross-lingual induction ap-proach is that adverbial participles can easily beextracted from parallel corpora since in other lan-guages (such as English or French) adverbs areoften morphologically marked and easily labelledby statistical PoS taggers.
As an example, con-sider sentence (5) extracted from Europarl, wherethe German participle versta?rkt is translated by anEnglish adverb (increasingly).
(5) a. NichtNotohnewithoutGrundreasonsprechenspeakwirweversta?rktincreasinglyvomof aEuropaEuropederof theRegionen.Regions.b.
It is not without reason that we increasingly speakin terms of a Europe of the Regions.The idea is to project specific morphologicalinformation about adverbs which is overt in lan-guages like English onto German where adverbscannot be directly extracted from tagged data.While this idea might seem intuitively straightfor-1428ward, we also know that translation pairs in paral-lel data are not always lingusitically parallel, andas a consequence, word-alignment is not alwaysreliable.
To assess the impact of non-parallelismin adverbial translations of German participles,we manually annotated a sample of 300 transla-tions.
This data also constitutes the basis for theexperiments reported in Section 4.3.1 DataOur experiments are based on the same data as in(Zarrie?
et al, 2010).
For convenience, we pro-vide a short description here.We limit our investigations to non-lexicalisedparticiples occuring in the Europarl corpus andnot yet recorded as adverbs in the lexicon of theGerman LFG grammar (5054 participle types intotal).
Given the participle candidates, we ex-tract the set of sentences that exhibit a word align-ment between a German participle and an English,French or Dutch adverb.
The word alignmentshave been obtained with GIZA++.
The extrac-tion yields 27784 German-English sentence pairsconsidering all alignment links, and 5191 sen-tence pairs considering only bidirectional align-ments between a participle and an English adverb.3.2 Systematic Non-ParallelismFor data exploration and evaluation, we anno-tated 300 participle alignments out of the 5191German-English sentences (with a bidirectionalparticiple-adverb alignment).
We distinguish thefollowing annotation categories: (i) parallel trans-lation, adverb information can be projected, (ii)incorrect alignment, (iii) correct alignment, buttranslation is a multi-word expression, (iv) correctalignment, but translation is a paraphrase (possi-bly involving a translation shift).Parallel Cases In our annotated sample of En-glish adverb - German participle pairs, 43%1 ofthe translation instances are parallel in the sensethat the overt adverb information from the Englishside can be projected onto the German participle.This means that if we base the induction technique1The diverging figures we report in Zarrie?
et al (2010)were due to a small bug in the script and it does not affect theoverall interpretation of the data.on word-alignments alone, its precision would berelatively low.Non-Parallel Cases Taking a closer look at thenon-parallel cases in our sample (57% of thetranslation pairs), we find that 47% of this set aredue to incorrect word alignments.
The remain-ing 53% thus reflect regular cases of non-paralleltranslations.
A typical configuration which makesup 30% of the the non-parallel cases is exempli-fied in (6) where the German main verb vorlegenis translated by the English multiword expressionput forward.
(6) a. Wir haben eine Reihe von Vorschla?gen vorgelegt.b.
We have put forward a number of proposals.An example for the general paraphrase or trans-lation shift category is given in Sentence (7).Here, the translational correspondence betweengekommen (arrived) and the adverb now is dueto language-specific, idiomatic realisations of anidentical underlying semantic concept.
The para-phrase translations make up 23% of the non-parallel cases in the annotated sample.
(7) a. DieThatZeittimeistisnochyetnichtnotgekommenarrived..b.
That time is not now .Furthermore, it is noticeable that the cross-lingual approach seems to inherently factor outthe ambiguity between predicative and adverbialparticiples.
In our annotated sample, there are nopredicative participles that have been translated byan English adverb.3.3 Filtering MechanismsThe data analysis in the previous section, show-ing only 43% of parallel cases in English adverbtranslations for German participles, mainly con-firms other studies in annotation projection whichfind that translational correspondences only allowfor projection of linguistic analyses in a more orless limited proportion (Yarowsky et al, 2001;Hwa et al, 2005; Mihalcea et al, 2007).In previous studies on annotation projection,quite distinct filtering methods have been pro-posed: in Yarowsky et al (2001), projection er-rors are mainly attributed to word alignment er-rors and filtered based on translation probabilities.1429Hwa et al (2005) find that errors in the projec-tion of syntactic relations are also due to system-atic grammatical divergences between languagesand propose correcting these errors by means ofspecific, manually designed filters.
Bouma et al(2008) make similar observations to Hwa et al(2005), but try to replace manual correction rulesby filters from additional languages.In Zarrie?
et al (2010), we compared a num-ber of filtering techniques on our participle data.The 300 annotated translation instances are usedas a test set for evaluation.
In particular, wehave established that a combination of syntacticdependency-based filters and multilingual filterscan very accurately separate non-parallel transla-tions from parallel ones where the adverb infor-mation can be projected.
In Section 4, we showthat these filtering techniques are also very usefulfor removing noise from the training material thatwe use to build a classifier.4 Bootstrapping a German ParticipleClassifier from Crosslingual DataIn the previous section, we have seen that Germanadverbial participles can be easily found in cross-lingual text by looking at their translations in alanguage that morphologically marks adverbials.In previous work, we exploited this observationby directly extracting types of adverbial partici-ples based on word alignment links and the filter-ing mechanisms mentioned in Section 3.
How-ever, this method is very closely tied to data inthe parallel corpus, which only comprises around5000 participle-adverb translations in total, whichresults in 46 types of adverbial participles after fil-tering.
Thus, we have no means of telling whetherwe would discover new types of adverbial partici-ples in other corpora, from different domains toEuroparl.
As this corpus is rather small and genrespecific, it even seems very likely that one couldfind additional adverbial participles in a biggercorpus.
Moreover, we cannot be sure that certainadverbial participles have systematically diverg-ing translations in other languages, due to cross-lingual lexicalisation differences.
Generally, it isnot clear whether we have learned something gen-eral about the syntactic phenomenon of adverbialparticiples in German or whether we have just ex-tracted a small, corpus-dependent subset of theclass of adverbial participles.In this section, we use instances of adverbiallytranslated participles as training material for aclassifier that learns to predict adverbial partici-ples based on their monolingual syntactic context.Thus, we exploit the translations in the parallelcorpus as a means of obtaining ?annotated?
or dis-ambiguated training data without any manual ef-fort.
During training, we only consider the mono-lingual context of the participle, such that the fi-nal application of the classifier is not dependenton cross-lingual data anymore.4.1 Context-based Identification ofAdverbial ParticiplesGiven the general linguistic problems related toadverbial participles (see Section 2), one couldassume that it is very difficult to identify themin a given context.
To assess the general dif-ficulty of this syntactic problem, we run a firstexperiment comparing a grammar-based identifi-cation method against a classifier that only con-siders relatively narrow morpho-syntactic context.For evaluation, we use the 300 annotated partici-ple instances described in Section 3.
This testset divides into 172 negative instances, i.e.
non-adverbial participles, and 128 positive instances.We report accuracy of the identification method,as well as precision and recall relating to the num-ber of correctly predicted adverbial participles.For the grammar-based identification, we usethe German LFG which integrates the lexicalresource for adverbial participles established in(Zarrie?
et al, 2010).
We parse the 300 Europarlsentences and check whether the most probableparse proposed by the grammar analyses the re-spective participle as an adverb or not.
The gram-mar obtains a complete parse for 199 sentencesout of the test set and we only consider these inthe evaluation.
The results are given in Table 1.The high precision and accuracy of thegrammar-based identification of adverbial partici-ples suggests that in a lot of sentences, the adver-bial analysis is the only possible reading, i.e.
theonly analysis that makes the sentence grammati-cal.
But of course, we have substantially restrictedthe adverb participle-conversion in the grammar,1430Training Data Precision Recall AccuracyGrammar 97.3 90.12 94.97Classifier Unigram 87.10 84.38 87.92Classifier Bigram 88.28 88.28 89.93Classifier Trigram 89.60 87.5 90.27Table 1: Evaluation on 300 participle instancesfrom Europarlso that it does not propose adverbial analyses forparticiples that are very unlikely to function asmodifiers of verbs.For the classifier-based identification, we usethe adverbially translated participle tokens in ourEuroparl data (5191 tokens in total) as trainingmaterial.
We remove the 300 test instances fromthis training set, and then divide it into a set ofpositive and negative instances.
To do this, weuse the filtering mechanisms already proposed inZarrie?
et al (2010).
These filters apply on thetype level, such that we first identify the positivetypes (46 total) and then use all instances of thesetypes in the 4891 sentences as positive instancesof adverbial participles (1978 instances).
The re-maining sentences are used as negative instances.For the training of the classifier, we usemaximum-entropy classification, which is alsocommonly used for the general task of tagging(Ratnaparkhi, 1996).
In particular, we use theopen source TADM tool for parameter estimation(Malouf, 2002).
The tags of the words surround-ing the participles are used as features in the clas-sification task.
We explore different sizes of thecontext window, where the trigram window is themost succesful (see Table 1).
Beyond the trigramwindow, the results of the classifier start decreas-ing again, probably because of too many mislead-ing features.
Generally, this experiment showsthat the grammar-based identification is more pre-cise, but that the classifier still performs surpris-ingly well.
Compared to the results from thegrammar-based identification, the high accuracyof the classifier suggests that even the narrow syn-tactic contexts of adverbial vs. non-adverbial par-ticiples are quite distinct.4.2 Designing Training Data for ParticipleClassificationThere are several questions related to the designof the training data that we use to build our clas-sifier.
First, it is not clear how many negativeinstances are helpful for learning the adverbial -non-adverbial distinction.
In the above experi-ment, we simply use the instances that do not passthe cross-lingual filters.
In this section, we exper-iment with an augmented set of negative instancesthat was also obtained by extracting German par-ticiple that are bi-directionally aligned to an En-glish participle in Europarl.
This is based on theassumption that these participles are very likelyto be verbal.
Second, it is not clear whether wereally need the filtering mechanisms proposed inZarrie?
et al (2010) and whether we could im-prove the classifier by training it on a larger setof positive instances.
Therefore, we also experi-ment with two further sets of positive instances:one where we used all participles (not necessarilybidirectionally) aligned to an adverb, one wherewe only use the bidirectional alignments.
The re-sults obtained for the different sizes of positiveand negative instance sets are given in Table 2.The picture that emerges from the results in Ta-ble 2 is very clear: the stricter the filtering of thetraining material (i.e.
the positive instances) is,the better the performance of the classifier.
Thefact that we (potentially) loose certain positive in-stances in the filtering does not negatively impacton the classifier which substantially benefits fromthe fact that noise gets removed.
Moreover, wefind that if the training material is appropriatelyfiltered, adding further negative instances does nothelp improving the accuracy.
By contrast, if wetrain on a noisy set of positive instances, the clas-sifier benefits from a larger set of negative in-stances.
However, the positive effect that we getfrom augmenting the non-filtered training data isstill weaker than the positive effect we get fromthe filtering.5 Induction of Adverbial Participles onMonolingual DataGiven the classifier from Section 4 that predictsthe syntactic category of a participle instance1431Training Data Pos.
Instances Neg.
Instances Precision Recall AccuracyNon-Filtered Instances (all alignments) 27.184 10.000 43.10 100 43.10Non-Filtered Instances (all alignments) 27.184 50.000 74.38 92.97 83.22Non-Filtered Instances (symm.
alignments) 4891 10.000 78.08 89.06 84.56Non-Filtered Instances (symm.
alignments) 4891 50.000 82.31 83.59 85.23Filtered Instances 1978 10.000 91.60 85.16 90.27Filtered Instances 1978 50.000 90.83 77.34 86.91Table 2: Evaluation on 300 participle instances from Europarlbased on its monolingual syntactic context, wecan now detect new instances or types of adver-bial participles in any PoS-tagged German corpus.In this section, we investigate whether the classi-fier can be used to augment the resource of ad-verbial participles directly induced from Europarlwith new types.5.1 Data ExtractionWe run our extraction experiment on the HugeGerman Corpus (HGC), a corpus of 200 millionwords of newspaper and other text.
This corpushas been tagged with TreeTagger (Schmid, 1994).For each of the 5054 participle candidates, we ex-tract all instances from the HGC which have notbeen tagged as finite verbs (at most 2000 tokensper participle).
For each participle token, we alsoextract its syntactic context in terms of the 3 pre-ceding and the 3 following tags.
For classification,we use only those participles that have more than50 instances in the corpus (2953 types).In contrast to the cross-lingual filtering mech-anisms developed in Zarrie?
et al (2010) whichoperate on the type-level, the classifier makes aprediction for every token of a given participlecandidate.
Thus, for each of the participle can-didates, we obtain a percentage of instances thathave been classified as adverbs.
As we would ex-pect, the percentage of adverbial instances is verylow for most of the participles in our candidate set:for 75% of the 2953 types, the percentage is below5%.
This result confirms our initial intuition thatthe property of being used as an adverb is stronglylexically restricted to a certain class of participles.5.2 EvaluationSince we know that the classifier has an accu-racy of 90% on the Europarl data, we only con-sider participles as candidates for adverbs wherethe classifier predicted more than 14% adverbialinstances.
This leaves us with a set of 210 partici-ples, which comprises 13 of the original 46 par-ticiples extracted from Europarl, meaning we havediscovered 197 new adverbial participle types.We performed a manual evaluation of 50 ran-domly selected types out of the set of 197 newparticiple types.
Therefore, we looked at the in-stances and their context which the classifier pre-dicted to be adverbial.
If there was at least one ad-verbial instance among these, the participle typewas evaluated as correctly annotated by the clas-sifier.
By this means, we find that 76% of the par-ticiples were correctly classified.This evaluation suggests that the accuracy ofour classifier which we trained and tested on Eu-roparl data is lower on the HGC data.
The rea-son for this drop in performance will be explainedin the following Section 5.3.
However, assumingan accuracy of 76%, we have discovered 150 newtypes of adverbial participles.
We argue that this isa very satisfactory result given that we have not in-vested any manual effort into the annotation or ex-traction of adverbial participles.
This results alsomakes clear that the previous resource we inducedon Europarl data, comprising only 46 participletypes, was a very limited one.5.3 Error AnalysisTaking a closer look at the 12 participle candi-dates that the classifier incorrectly labels as adver-bial, we observe that their adverbially classifiedinstances are mostly instances of a predicative use.This means that our Europarl training data doesnot contain enough evidence to learn the distinc-tion between adverbial and predicative participles.This is not surprising since the set of negativeinstances used for training the classifier mainlycomprises verbal instances of participles.
More-over, the syntactic contexts and constructions inwhich some predicatives and adverbials are used1432Grammar Prec.
Rec.
F-Sc.
Timein sec46 Part-Adv 84.12 78.2 81.05 665243 Part-Adv 84.12 77.67 80.76 665Table 3: Evaluation on 371 TIGER sentencesare very similar.
Thus, in future work, we willhave to include more data on predicatives (whichis more difficult to obtain) and analyse the syntac-tic contexts in more detail.6 Assessing the Impact of ResourceCoverage on Grammar-based ParsingIn this section, we evaluate the classifier-based in-duction of adverbial participles from a grammar-based perspective.
We integrate the entire set ofinduced adverbial participles (46 from Europarland 197 from the HGC) into the German LFGgrammar.
As a consequence, the grammar al-lows the adverb conversion for 243 lexical par-ticiple types.
We use the evaluation methodolgyexplained in Section 2.First, we conduct an accuracy-oriented evalua-tion on the standard TIGER test set.
We compareagainst the German LFG that only integrates thesmall participle resource from Europarl.
The re-sults are given in Table 3.
The difference betweenthe 46 Part-Adv and 243 Part-Adv resource is notstatistically signficant.
Thus, the larger participleresource has no overall negative effect on the pars-ing performance.
As established by an automaticupperbound evaluation in Zarrie?
et al (2010),we cannot not expect to find a positive effect inthis evaluation because the phenomenon does notoccur in the standard test set.To show that the augmented resource indeedimproves the coverage of the grammar, we builta specialised testsuite of 1044 TIGER sentencesthat contain an instance of a participle from theresource.
Since this testsuite comprises sen-tences from the training set, we can only reporta coverage-oriented evaluation here, see Table 4.The 243 Part-Adv increases the coverage by 8%on the specialised testsuite.Moreover, we manually evaluated 20 sentencescovered by the 243-Part-Adv grammar and notby 46-Part-Adv as to whether they contain a cor-rectly analysed adverbial participle.
In two sen-Grammar ParsedSent.StarredSent.Time-outsTimein secNo Part-Adv 665 315 64 303346 Part-Adv 710 269 65 3118243 Part-Adv 767 208 69 3151Table 4: Performance on the specialised TIGERtest set (1044 sentences)tences, the grammar obtained an adverbial analy-sis for clearly predicative modifiers, based on theenlarged resource.
In three different sentences, itwas difficult to decide whether the participle actsas an adverb or a predicative.
In the remaining 15sentences, the grammar established the the correctanalysis of a clearly adverbially used participle.7 ConclusionWe have proposed a cross-lingual inductionmethod to automatically obtain data on adverbialparticiples in German.
We exploited this cross-lingual data as training material for a classifier thatlearns to predict the syntactic category of a partici-ple from its monolingual syntactic context.
Sincethis category is usually not annotated in Germanresources and hard to describe in theory, the find-ing that adverbial participles can be predicted rel-atively precisely is of general interest for theo-retic and computational approaches to the syntac-tic analysis of German.We showed that, in order to obtain an accurateparticiple classifier, the quality of the training ma-terial induced from the parallel corpus is of crucialimportance.
By applying the filtering techniquesfrom Zarrie?
et al (2010), the accuracy of theclassifier increases between 5% and 7%.
In futurework, we plan to include more data on predicativeparticiples to learn a more accurate distinction be-tween predicative and adverbial participles.Finally, we used the participle classifier to ex-tract a lexical resource of adverbial participles forthe German LFG grammar.
In comparison to therelatively small resource of 46 types that can bedirectly induced from Europarl, we discovered alarge number of new participle types (197 typesin total).
In a parsing experiment, we showed thatthis much bigger resource does not negatively im-pact on parsing performance and improves gram-mar coverage.1433ReferencesBouma, Gerlof, Jonas Kuhn, Bettina Schrader, andKathrin Spreyer.
2008.
Parallel LFG Grammarson Parallel Corpora: A Base for Practical Trian-gulation.
In Butt, Miriam and Tracy HollowayKing, editors, Proceedings of the LFG08 Confer-ence, pages 169?189, Sydney, Australia.
CSLI Pub-lications, Stanford.Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The TIGERTreebank.
In Proceedings of the Workshop on Tree-banks and Linguistic Theories.Butt, Miriam, Helge Dyvik, Tracy Holloway King, Hi-roshi Masuichi, and Christian Rohrer.
2002.
TheParallel Grammar Project.Geuder, Wilhelm.
2004.
Depictives and transpar-ent adverbs.
In Austin, J. R., S. Engelbrecht,and G. Rauh, editors, Adverbials.
The Interplay ofMeaning, Context, and Syntactic Structure, pages131?166.
Benjamins.Hwa, Rebecca, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Nat.
Lang.
Eng., 11(3):311?325.Malouf, Robert.
2002.
A comparison of algorithmsfor maximum entropy parameter estimation.
In Pro-ceedings of the Sixth Conference on Natural Lan-guage Learning (CoNLL-2002), pages 49?55.Mihalcea, Rada, Carmen Banea, and Jan Wiebe.2007.
Learning multilingual subjective languagevia cross-lingual projections.
In Proceedings ofthe Association for Computational Linguistics (ACL2007), pages 976?983, Prague.Pado?, Sebastian and Mirella Lapata.
2009.
Cross-lingual annotation projection of semantic roles.Journal of Artificial Intelligence Research, 36:307?340.Ratnaparkhi, Adwait.
1996.
A maximum entropymodel for part-of-speech tagging.
In Proceedingsof EMNLP 96, pages 133?142.Riezler, Stefan, Tracy Holloway King, Ronald M. Ka-plan, Richard Crouch, John T. Maxwell, and MarkJohnson.
2002.
Parsing the Wall Street Journalusing a Lexical-Functional Grammar and Discrim-inative Estimation Techniques .
In Proceedings ofACL 2002.Rohrer, Christian and Martin Forst.
2006.
Improvingcoverage and parsing quality of a large-scale LFGfor German.
In Proceedings of LREC-2006.Schmid, Helmut.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of In-ternational Conference on New Methods in Lan-guage Processing.Yarowsky, David, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analy-sis tools via robust projection across aligned cor-pora.
In Proceedings of HLT 2001, First Interna-tional Conference on Human Language TechnologyResearch.Zarrie?, Sina, Aoife Cahill, Jonas Kuhn, and ChristianRohrer.
2010.
A Cross-Lingual Induction Tech-nique for German Adverbial Participles.
In Pro-ceedings of the 2010 Workshop on NLP and Lin-guistics: Finding the Common Ground, ACL 2010,pages 34?42, Uppsala, Sweden.1434
