Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 11?20,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsAutomatic diagnosis of understanding of medical wordsNatalia GrabarCNRS UMR 8163 STLUniversit?e Lille 359653 Villeneuve d?Ascq, Francenatalia.grabar@univ-lille3.frThierry HamonLIMSI-CNRS, BP133, OrsayUniversit?e Paris 13Sorbonne Paris Cit?e, Francehamon@limsi.frDany AmiotCNRS UMR 8163 STLUniversit?e Lille 359653 Villeneuve d?Ascq, Francedany.amiot@univ-lille3.frAbstractWithin the medical field, very specializedterms are commonly used, while their un-derstanding by laymen is not always suc-cessful.
We propose to study the under-standability of medical words by laymen.Three annotators are involved in the cre-ation of the reference data used for trainingand testing.
The features of the words maybe linguistic (i.e., number of characters,syllables, number of morphological basesand affixes) and extra-linguistic (i.e., theirpresence in a reference lexicon, frequencyon a search engine).
The automatic cate-gorization results show between 0.806 and0.947 F-measure values.
It appears thatseveral features and their combinations arerelevant for the analysis of understandabil-ity (i.e., syntactic categories, presence inreference lexica, frequency on the generalsearch engine, final substring).1 IntroductionThe medical field has deeply penetrated our dailylife, which may be due to personal or familyhealth condition, watching TV and radio broad-casts, reading novels and journals.
Nevertheless,the availability of this kind of information does notguarantee its correct understanding, especially bylaymen, such as patients.
The medical field has in-deed a specific terminology (e.g., abdominoplasty,hepatic, dermabrasion or hepatoduodenostomy)commonly used by medical professionals.
Thisfact has been highlighted in several studies dedi-cated for instance to the understanding of pharma-ceutical labels (Patel et al., 2002), of informationprovided by websites (Rudd et al., 1999; Berlandet al., 2001; McCray, 2005; Oregon Evidence-based Practice Center, 2008), and more generallythe understanding between patients and medicaldoctors (AMA, 1999; McCray, 2005; Jucks andBromme, 2007; Tran et al., 2009).We propose to study the understanding of wordsused in the medical field, which is the first step to-wards the simplification of texts.
Indeed, beforethe simplification can be performed, it is neces-sary to know which textual units may show under-standing difficulty and should be simplified.
Wework with data in French, such as provided byan existing medical terminology.
In the remain-der, we present first some related work, especiallyfrom specialized fields (section 2).
We then intro-duce the linguistic data (section 4) and methodol-ogy (section 5) we propose to test.
We present anddiscuss the results (section 6), and conclude withsome directions for future work (section 7).2 Studying the understanding of wordsThe understanding (of words) may be seen as ascale going from I can understand to I cannot un-derstand, and containing one or more intermediatepositions (i.e., I am not sure, I have seen it be-fore but do not remember the meaning, I do notknow but can interpret).
Notice that it is also re-lated to the ability to provide correct explanationand use of words.
As we explain later, we con-sider words out of context and use a three-positionscale.
More generally, understanding is a complexnotion closely linked to several other notions stud-ied in different research fields.
For instance, lex-ical complexity is studied in linguistics and givesclues on lexical processes involved, that may im-pact the word understanding (section 2.1).
Workin psycholinguistics is often oriented on study ofword opacity and the mental processes involved intheir understanding (Jarema et al., 1999; Libben etal., 2003).
Readability provides a set of methodsto compute and quantify the understandability ofwords (section 2.3).
The specificity of words tospecialized areas is another way to capture theirunderstandability (section 2.2).
Finally, lexical11simplification aims at providing simpler words tobe used in a given context (section 2.3).2.1 LinguisticsIn linguistics, the question is closely related to lex-ical complexity and compoundings.
It has beenindeed observed that at least five factors, linguis-tic and extra-linguistic, may be involved in the se-mantic complexity of the compounds.
One factoris related to the knowledge of the components ofthe complex words.
Formal (how the words, suchas a?erenchyme, can be segmented) and seman-tic (how the words can be understood and used)points of view can be distinguished.
A secondfactor is that complexity is also due to the vari-ety of morphological patterns and relations amongthe components.
For instance, ?erythrocyte (erythro-cyte) and ovocyte (ovocyte) instantiate the [N1N2]pattern in which N2 (cyte) can be seen as a con-stant element (Booij, 2010), although the relationsbetween N1 and N2 are not of the same type inthese two compounds: in ?erythrocyte, N1 ?erythr(o)denotes a property of N2 (color), while in ovo-cyte, N1 ovo (egg) corresponds to a specific de-velopment stage of female cells.
Another factorappears when some components are polysemous,within a given field (i.e., medical field) or acrossthe fields.
For instance, a?er(o) does not alwaysconvey the same meaning: in a?eroc`ele, a?er- de-notes ?air?
(tumefaction (c`ele) formed by an air in-filtration), but not in a?erasth?enie, which refers toan asthenia (psychic disorder) observable amongjet pilots.
Yet another factor may be due to the dif-ference in the order of components: according towhether the compounding is standard (in French,the main semantic element is then on the left, suchas in pneu neige (snow tyre), which is fundamen-tally a pneu (tyre)) or neoclassical (in French, themain semantic element is then on the right, such as?erythrocyte, which is a kind of cyte cell / corpusclewith red color).
It is indeed complicated for a userwithout medical training to correctly interpret aword that he does not know and for which he can-not reuse the existing standard compounding pat-terns.
This difficulty is common to all Roman lan-guages (Iacobini, 2003), but not to Germanic lan-guages (L?udeling et al., 2002).
Closely related isthe fact that with neoclassical compounds, a givencomponent may change its place according to theglobal semantics of the compounds, such as path-in pathology, polyneuropathe, cardiopathy.
Fi-nally, the formal similarity between some deriva-tion processes (such as the derivation in -oide, likein lipoid) and neoclassical compounding (such as-ase in lipase), which apply completely differentinterpretation patterns (Iacobini, 1997; Amiot andDal, 2005), can also make the understanding moredifficult.2.2 TerminologyIn the terminology field, the automatic identifica-tion of difficulty of terms and words remains im-plicit, while this notion is fundamental in termi-nology (W?uster, 1981; Cabr?e and Estop`a, 2002;Cabr?e, 2000).
The specificity of terms to a givenfield is usually studied.
The notion of understand-ability can be derived from it.
Such studies canbe used for filtering the terms extracted from spe-cialized corpora (Korkontzelos et al., 2008).
Thefeatures exploited include for instance the pres-ence and the specificity of pivot words (Drouinand Langlais, 2006), the neighborhood of the termin corpus or the diversity of its components com-puted with statistical measures such as C-Value orPageRank (Daille, 1995; Frantzi et al., 1997; May-nard and Ananiadou, 2000).
Another possibility isto check whether lexical units occur within refer-ence terminologies and, if they do, they are con-sidered to convey specialized meaning (Elhadadand Sutaria, 2007).2.3 NLP studiesThe application of the readability measures is an-other way to evaluate the complexity of words andterms.
Among these measures, it is possible to dis-tinguish classical readability measures and com-putational readability measures (Franc?ois, 2011).Classical measures usually rely on number of let-ters and/or of syllables a word contains and onlinear regression models (Flesch, 1948; Gunning,1973), while computational readability measuresmay involve vector models and a great variabil-ity of features, among which the following havebeen used to process the biomedical documentsand words: combination of classical readabilityformulas with medical terminologies (Kokkinakisand Toporowska Gronostaj, 2006); n-grams ofcharacters (Poprat et al., 2006), manually (Zhenget al., 2002) or automatically (Borst et al., 2008)defined weight of terms, stylistic (Grabar et al.,2007) or discursive (Goeuriot et al., 2007) fea-tures, lexicon (Miller et al., 2007), morphologi-cal features (Chmielik and Grabar, 2011), combi-12Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%)1.
I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27)2.
I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2)3.
I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71)Total annotations 29,641 29,641 29,641 22,925 28,763Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2and A3), and in the derived datasets unanimity and majority.nations of different features (Wang, 2006; Zeng-Treiler et al., 2007; Leroy et al., 2008).Specific task has been dedicated to the lexi-cal simplification within the SemEval challenge in20121.
Given a short input text and a target wordin English, and given several English substitutesfor the target word that fit the context, the goalwas to rank these substitutes according to how?simple?
they are (Specia et al., 2012).
The par-ticipants applied rule-based and/or machine learn-ing systems.
Combinations of various featureshave been used: lexicon from spoken corpusand Wikipedia, Google n-grams, WordNet (Sinha,2012); word length, number of syllables, latent se-mantic analysis, mutual information and word fre-quency (Jauhar and Specia, 2012); Wikipedia fre-quency, word length, n-grams of characters and ofwords, random indexing and syntactic complexityof documents (Johannsen et al., 2012); n-gramsand frequency from Wikipedia, Google n-grams(Ligozat et al., 2012); WordNet and word fre-quency (Amoia and Romanelli, 2012).3 Aims of the present studyWe propose to investigate how the understandabil-ity of French medical words can be diagnosed withNLP methods.
We rely on the reference annota-tions performed by French speakers without medi-cal training, which we associate with patients.
Theexperiments performed rely on machine learningalgorithms and a set of 24 features.
The medicalwords studied are provided by an existing medicalterminology.4 Linguistic data and their preparationThe linguistic data are obtained from the medicalterminology Snomed International (C?ot?e, 1996).This terminology?s aim is to describe the wholemedical field.
It contains 151,104 medical termsstructured into eleven semantic axes such as dis-1http://www.cs.york.ac.uk/semeval-2012/orders and abnormalities, procedures, chemicalproducts, living organisms, anatomy, social sta-tus, etc.
We keep here five axes related to themain medical notions (disorders, abnormalities,procedures, functions, anatomy).
The objectiveis not to consider axes such as chemical products(trisulfure d?hydrog`ene (hydrogen sulfide)) and livingorganisms (Sapromyces, Acholeplasma laidlawii)that group very specific terms hardly known bylaymen.
The 104,649 selected terms are tokenizedand segmented into words (or tokens) to ob-tain 29,641 unique words: trisulfure d?hydrog`enegives three words (trisulfure, de, hydrog`ene).This dataset contains compounds (abdominoplas-tie (abdominoplasty), dermabrasion (dermabrasion)),constructed (cardiaque (cardiac), acineux (acinic),lipo?
?de (lipoid)) and simple (acn?e (acne), fragment(fragment)) words.
These data are annotated bythree speakers 25-40 year-old, without medicaltraining, but with linguistic background.
We ex-pect the annotators to represent the average knowl-edge of medical words amongst the population asa whole.
The annotators are presented with a list ofterms and asked to assign each word to one of thethree categories: (1) I can understand the word;(2) I am not sure about the meaning of the word;(3) I cannot understand the word.
The assumptionis that the words, which are not understandable bythe annotators, are also difficult to understand bypatients.
These manual annotations correspond tothe reference data (Table 1).5 MethodologyThe proposed method has two aspects: gener-ation of the features associated to the analyzedwords and a machine learning system.
The mainresearch question is whether the NLP methodscan distinguish between understandable and non-understandable medical words and whether theycan diagnose these two categories.135.1 Generation of the featuresWe exploit 24 linguistic and extra-linguistic fea-tures related to general and specialized languages.The features are computed automatically, and canbe grouped into ten classes:Syntactic categories.
Syntactic categories andlemmas are computed by TreeTagger (Schmid,1994) and then checked by Flemm (Namer, 2000).The syntactic categories are assigned to wordswithin the context of their terms.
If a given wordreceives more than one category, the most fre-quent one is kept as feature.
Among the maincategories we find for instance nouns, adjectives,proper names, verbs and abbreviations.Presence of words in reference lexica.
We ex-ploit two reference lexica of the French language:TLFi2and lexique.org3.
TLFi is a dictionary of theFrench language covering XIX and XX centuries.It contains almost 100,000 entries.
lexique.org is alexicon created for psycholinguistic experiments.It contains over 135,000 entries, among which in-flectional forms of verbs, adjectives and nouns.
Itcontains almost 35,000 lemmas.Frequency of words through a non specializedsearch engine.
For each word, we query theGoogle search engine in order to know its fre-quency attested on the web.Frequency of words in the medical terminology.We also compute the frequency of words in themedical terminology Snomed International.Number and types of semantic categories asso-ciated to words.
We exploit the information on thesemantic categories of Snomed International.Length of words in number of their charactersand syllables.
For each word, we compute thenumber of its characters and syllables.Number of bases and affixes.
Each lemmais analyzed by the morphological analyzer D?erif(Namer and Zweigenbaum, 2004), adapted to thetreatment of medical words.
It performs the de-composition of lemmas into bases and affixesknown in its database and it provides also seman-tic explanation of the analyzed lexemes.
We ex-ploit the morphological decomposition informa-tion (number of affixes and bases).Initial and final substrings of the words.
Wecompute the initial and final substrings of differ-ent length, from three to five characters.2http://www.atilf.fr/3http://www.lexique.org/Number and percentage of consonants, vowelsand other characters.
We compute the number andthe percentage of consonants, vowels and othercharacters (i.e., hyphen, apostrophe, comas).Classical readability scores.
We apply two clas-sical readability measures: Flesch (Flesch, 1948)and its variant Flesch-Kincaid (Kincaid et al.,1975).
Such measures are typically used for eval-uating the difficulty level of a text.
They exploitsurface characteristics of words (number of char-acters and/or syllables) and normalize these valueswith specifically designed coefficients.5.2 Machine learning systemThe machine learning algorithms are used to studywhether they can distinguish between words un-derstandable and non-understandable by laymenand to study the importance of various features forthe task.
The functioning of machine learning al-gorithms is based on a set of positive and nega-tive examples of the data to be processed, whichhave to be described with suitable features suchas those presented above.
The algorithms can thendetect the regularities within the training dataset togenerate a model, and apply the generated modelto process new unseen data.
We apply various al-gorithms available within the WEKA (Witten andFrank, 2005) platform.The annotations provided by the three annota-tors constitute our reference data.
We use on thewhole five reference datasets (Table 1): 3 sets ofseparate annotations provided by the three anno-tators (29,641 words each); 1 unanimity set, onwhich all the annotators agree (n=22,925); 1 ma-jority set, for which we can compute the major-ity agreement (n=28,763).
By definition, the twolast datasets should present a better coherence andless annotation ambiguity because some ambigui-ties have been resolved by unanimity or by major-ity vote.5.3 EvaluationThe inter-annotator agreement is computed withthe Cohen?s Kappa (Cohen, 1960), applied to pairsof annotators, which values are then leveraged toobtain the unique average value; and Fleiss?
Kappa(Fleiss and Cohen, 1973), suitable for processingdata provided by more than two annotators.
Theinterpretation of the scores are for instance (Landisand Koch, 1977): substantial agreement between0.61 and 0.80, almost perfect agreement between0.81 and 1.00.14With machine learning, we perform a ten-foldcross-validation, which means that the evaluationtest is performed ten times on different randomlygenerated test sets (1/10 of the whole dataset),while the remaining 9/10 of the whole dataset isused for training the algorithm and creating themodel.
In this way, each word is used during thetest step.
The success of the applied algorithms isevaluated with three classical measures: R recall,P precision and F F-measure.
In the perspectiveof our work, these measures allow evaluating thesuitability of the methodology to the distinctionbetween understandable and non-understandablewords and the relevance of the chosen features.The baseline corresponds to the assignment ofwords to the biggest category, e.g., I cannot under-stand, which represents 66 to 74%, according todatasets.
We can also compute the gain, which isthe effective improvement of performance P giventhe baseline BL (Rittman, 2008):P?BL1?BL.6 Automatic analysis ofunderstandability of medical words:Results and DiscussionWe address the following aspects: annotations(inter-annotator agreement, assignment of wordsto three categories), quantitative results providedby the machine learning algorithms, impact of theindividual features on the distinction between cat-egories, and usefulness of the method.6.1 Annotations and inter-annotatoragreementThe time needed for performing the manual ref-erence annotations depends on annotators andranges from 3 to 6 weeks.
The annotation resultspresented in Table 1 indicate that the annotators1 and 2 often provide similar results on their un-derstanding of the medical words, while for thethird annotator the task appears to be more difficultas he indicates globally a higher number of non-understandable words.
The non-understandablewords are the most frequent for all annotators andcover 66 to 70% of the whole dataset.
The inter-annotator agreement shows substantial agreement:Fleiss?
Kappa 0.735 and Cohen?s Kappa 0.736.This is a very good result, especially when work-ing with linguistic data for which the agreement isusually difficult to obtain.The evolution of annotations per category (Fig-ure 1), such as provided by the annotators, can dis-050001000015000200000  5000  10000  15000  20000  25000Number in eachcategoryWordsI cannot understandI can understandI am not sureA1A2A3Figure 1: Evolution of the annotations within thereference data.tinguish easily between the three categories: (1)the most frequently chosen category is I cannotunderstand and it grows rapidly with new words;(2) the next most frequently chosen category is Ican understand, although it grows more slowly;(3) the third category, which gathers the words onwhich the annotators show some hesitation, is verysmall.
Given the proximity between the lines ineach category, we can conclude that the annota-tors have similar difficulties in understanding thewords from the dataset.6.2 Quantitative results obtained withmachine learningP R FJ48 0.876 0.889 0.881RandomForest 0.880 0.892 0.884REPTree 0.874 0.890 0.879DecisionTable 0.872 0.891 0.880LMT 0.876 0.895 0.884SMO 0.858 0.876 0.867Table 2: Performance obtained on the majoritydataset with various algorithms.We tested several machine learning algorithmsto discover which of them are the most suitableto the task at hand.
In Table 2, with results com-puted on the majority dataset, we can observe thatthe algorithms provide with similar performance(between 0.85 and 0.90 P and R).
In the remain-ing of the paper, we present results obtained withJ48 (Quinlan, 1993).
Table 3 shows P , R andF values for the five datasets: three annotators,majority and unanimity datasets.
We can observe15that, among the three annotators, it is easier toreproduce the annotations of the third annotator:we gain then 0.040 with F comparing to the twoother annotators.
The results become even betterwith the majority dataset (F=0.881), and reach Fup to 0.947 on the unanimity dataset.
As we ex-pected, these two last datasets present less annota-tion ambiguity.
The best categorization results areobserved with I can understand and I cannot un-derstand categories, while the I am not sure cate-gory is poorly managed by machine learning algo-rithms.
Because this category is very small, the av-erage performance obtained on all three categoriesremains high.A1 A2 A3 Una.
Maj.P 0.794 0.809 0.834 0.946 0.876R 0.825 0.826 0.862 0.949 0.889F 0.806 0.814 0.845 0.947 0.881Table 3: J48 performance obtained on five datasets(A1, A2, A3, unanimity and majority).In Table 4, we indicate the gain obtained by J48compared to baseline: it ranges from 0.13 to 0.20,which is a good improvement, despite the cate-gory I am not sure that is difficult to discriminate.We also indicate the accuracy obtained on thesedatasets.A1 A2 A3 Una.
Maj.BL 0.66 0.67 0.70 0.74 0.71F 0.806 0.814 0.845 0.947 0.881gain 0.14 0.13 0.14 0.20 0.16Acc.
0.825 0.826 0.862 0.948 0.889Table 4: Gain obtained for F by J48 on fivedatasets (A1, A2, A3, unanimity and majority).6.3 Impact of individual features onunderstandability of medical wordsTo observe the impact of individual features, wedid several iterations of experiments during whichwe incrementally increased the set of features: westarted with one feature and then, at each iteration,we added one new feature, up to the 24 featuresavailable.
We tried several random orders.
Thetest presented here is done again on the majoritydataset.
Figures 2 present the results obtained interms of P , R and F .
Globally, we can observethat some features show positive impact while oth-ers show negative or null impact:0.50.60.70.80.915  10  15  20PerformanceFeature subsetsPOS?taginitial substringsfinal substringsword length reference lexicaweb frequencyPrecisionRecallF?measureFigure 2: Impact of individual features.?
with the syntactic categories (POS-tags)alone we obtain P and R between 0.65 and0.7.
The performance is then close to thebaseline performance.
Often, proper namesand abbreviations are associated with thenon-understandable words.
There is no dif-ference between TreeTagger alone and thecombination of TreeTagger with Flemm;?
the initial and final substrings have positiveimpact.
Among the final substrings, thosewith three and four characters (ie, -omie of-tomie (meaning cut), -phie of -rraphie (mean-ing stitch), -?emie (meaning blood)) show posi-tive impact, but substrings with five charac-ters have negative impact and the previouslygained improvement is lost.
We may con-clude that the five-character long final sub-strings may be too specific;?
the length of words in characters have neg-ative impact on the categorization results.There seems to be no strong link between thisfeature and the understanding of words: shortand long words may be experienced as bothunderstandable or not by annotators;?
the presence of words in the reference lexica(TLFI and lexique.org) is beneficial to bothprecision and recall.
We assume these lexicamay represent common lexical competenceof French speakers.
For this reason, wordsthat are present in these lexica, are also easierto understand;?
the frequencies of words computed througha general search engine are beneficial.16Words with higher frequencies are often as-sociated with a better understanding, al-though the frequency range depends on thewords.
For instance, coccyx (coccyx) or drain(drain) show high frequencies (1,800,000 and175,000,000, respectively) and they belongindeed to the I can understand category.Words like colique (diarrhea) or clitoridien(clitoral) show lower frequencies (807,000 and9,821, respectively), although they belong tothe same category.
On contrary, other wordswith quite high frequencies, like coagulase(coagulase), clivage (cleavage) or douve (fluke)(655,000, 1,350,000 and 1,030,000, respec-tively) are not understood by the annotators.According to these experiments, our results pointout that, among the most efficient features, we canfind syntactic categories, presence of words in thereference lexica, frequencies of words on Googleand three- and four-character end substring.
Incomparison to the existing studies, such as thosepresented during the SemEval challenge (Speciaet al., 2012), we propose to exploit a more com-plete set of features, several of which rely on theNLP methods (e.g., syntactic tagging, morpholog-ical analysis).
Especially the syntactic tagging ap-pears to be salient for the task.
In comparison towork done on general language data (Gala et al.,2013), our experiment shows better results (be-tween 0.825 and 0.948 accuracy against 0.62 ac-curacy in the cited work), which indicates that spe-cialized domains have indeed very specific words.Additional tests should be performed to obtain amore detailed impact of the features.6.4 Usefulness of the methodWe applied the proposed method to words fromdischarge summaries.
The documents are pre-processed according to the same protocol and thewords are assigned the same features as previ-ously (section 5).
The model learned on the una-nimity set is applied.
The results are shown inFigure 3.
Among the words categorized as non-understandable (in red and underlined), we find:?
abbreviations (NIHSS, OAP, NaCl, VNI);?
technical medical terms (hypoesth?esie(hypoesthesia), par?esie (paresia), throm-bolyse (thrombolysis), iatrog`ene (iatrogenic),oxyg?enoth?erapie (oxygen therapy), d?esaturation(desaturation));Figure 3: Detection of non-understandable wordswithin discharge summaries.?
medication names (CALCIPARINE);In the example from Figure 3, three types of errorscan be distinguished when common words are cat-egorized as non-understandable:?
inflected forms of words (suites (conse-quences), cardiologiques (cardiological));?
constructed forms of words (thrombolys?e(with thrombolysis));?
hyphenated words (post-r?eanimation (postemergency medical service)).Notice that in other processed documents, othererrors occur.
For instance, misspelled words andwords that miss accented characters (problemeinstead of probl`eme (problem), realise instead ofr?ealis?e (done), particularite instead particularit?e(particularity)) are problematic.
Another type of er-rors may occur when technical words (e.g.
pro-lapsus (prolapsus), paroxysme (paroxysm), tricuspide(tricuspid)) are considered as understandable.Besides, only isolated words are currently pro-cessed, which is the limitation of the currentmethod.
Still, consideration of complex medi-cal terms, that convey more complex medical no-tions, should also be done.
Such terms may indeedchange the understanding of words, as in these ex-amples: AVC isch?emique (ischemic CVA (cerebrovas-cular accident)), embolie pulmonaire basale droite(right basal pulmonary embolism), d?esaturation `a 83 %17(desaturation at 83%), anticoagulation curative (cu-rative anticoagulation).
In the same way, numericalvalues may also arise misunderstanding of medi-cal information.
Processing of these additional as-pects (inflected and constructed forms of words,hyphenated or misspelled words, complex termscomposed with several words and numerical val-ues) is part of the future work.6.5 Limitations of the current studyWe proposed several experiments for analyzingthe understandability of medical words.
We triedto analyze these data from different points of viewto get a more complete picture.
Still, there aresome limitations.
These are mainly related to thelinguistic data and to their preparation.The whole set of the analyzed words is large:almost 30,000 entries.
We assume it is possi-ble that annotations provided may show someintra-annotator inconsistencies due for instance tothe tiredness and instability of the annotators (forinstance, when a given unknown morphologicalcomponents is seen again and again, the meaningof this component may be deduced by the anno-tator).
Nevertheless, in our daily life, we are alsoconfronted to the medical language (our personalhealth or health of family or friend, TV and ra-dio broadcast, various readings of newspapers andnovels) and then, it is possible that the new med-ical notions may be learned during the annotationperiod of the words, which lasted up to four weeks.Nevertheless, the advantage of the data we havebuilt is that the whole set is completely annotatedby each annotator.When computing the features of the words, wehave favored those, which are computed at theword level.
In the future work, it may be interest-ing to take into account features computed at thelevel of morphological components or of complexterms.
The main question will be to decide howsuch features can be combined all together.The annotators involved in the study have atraining in linguistics, although their relation withthe medical field is poor: they have no specifichealth problems and no expertise in medical ter-minology.
We expect they may represent the av-erage level of patients with moderate health lit-eracy.
Nevertheless, the observed results may re-main specific to the category of young people withlinguistic training.
Additional experiments are re-quired to study this aspect better.7 Conclusion and Future researchWe proposed a study of words from the medi-cal field, which are manually annotated as under-standable, non-understandable and possibly un-derstandable to laymen.
The proposed approachis based on machine learning and a set with 24features.
Among the features, which appear to besalient for the diagnosis of understandable words,we find for instance the presence of words in thereference lexica, their syntactic categories, their fi-nal substring, and their frequencies on the web.Several features and their combinations can be dis-tinguished, which shows that the understandabilityof words is a complex notion, which involves sev-eral linguistic and extra-linguistic criteria.The avenue for future research includes for in-stance the exploitation of corpora, while currentlywe use features computed out of context.
Weassume indeed that corpora may provide addi-tional relevant information (semantic or statistical)for the task aimed in this study.
Additional as-pects related to the processing of documents (in-flected and constructed forms of words, hyphen-ated or misspelled words, complex terms com-posed with several words and numerical values) isanother perspective.
Besides, the classical read-ability measures exploited have been developedfor the processing of English language.
Workingwith French-language data, we should use mea-sures, which are adapted to this language (Kandeland Moles, 1958; Henry, 1975).
In addition, wecan also explore various perspectives, which ap-pear from the current limitations, such as comput-ing and using features computed at different levels(morphological components, words and complexterms), applying other classical readability mea-sures adapted to the French language, and addingnew reference annotations provided by laymenfrom other social-professional categories.AcknowledgmentsThis work is performed under the grantANR/DGA Tecsan (ANR-11-TECS-012) andthe support of MESHS (COMETE project).
Theauthors are thankful to the CHU de Bordeaux formaking available the clinical documents.ReferencesAMA.
1999.
Health literacy: report of the councilon scientific affairs.
Ad hoc committee on health lit-18eracy for the council on scientific affairs, AmericanMedical Association.
JAMA, 281(6):552?7.D Amiot and G Dal.
2005.
Integrating combiningforms into a lexeme-based morphology.
In Mediter-ranean Morphology Meeting (MMM5), pages 323?336.M Amoia and M Romanelli.
2012.
Sb: mmsystem -using decompositional semantics for lexical simpli-fication.
In *SEM 2012, pages 482?486, Montr?eal,Canada, 7-8 June.
Association for ComputationalLinguistics.GK Berland, MN Elliott, LS Morales, JI Algazy,RL Kravitz, MS Broder, DE Kanouse, JA Munoz,JA Puyol, M Lara, KE Watkins, H Yang, andEA McGlynn.
2001.
Health information on the in-ternet.
accessibility, quality, and readability in en-glish ans spanish.
JAMA, 285(20):2612?2621.Geert Booij.
2010.
Construction Morphology.
OxfordUniversity Press, Oxford.A Borst, A Gaudinat, C Boyer, and N Grabar.
2008.Lexically based distinction of readability levels ofhealth documents.
In MIE 2008.
Poster.MT Cabr?e and R Estop`a.
2002.
On the units of spe-cialised meaning uses in professional com- muni-cation.
In International Network for Terminology,pages 217?237.TM Cabr?e.
2000.
Terminologie et linguistique: lathorie des portes.
Terminologies nouvelles, 21:10?15.J Chmielik and N Grabar.
2011.
D?etection de lasp?ecialisation scientifique et technique des docu-ments biom?edicaux gr?ace aux informations mor-phologiques.
TAL, 51(2):151?179.Jacob Cohen.
1960.
A coefficient of agreementfor nominal scales.
Educational and PsychologicalMeasurement, 20(1):37?46.RA C?ot?e, 1996.
R?epertoire d?anatomopathologie de laSNOMED internationale, v3.4.
Universit?e de Sher-brooke, Sherbrooke, Qu?ebec.B Daille.
1995.
Rep?erage et extraction de terminologiepar une approche mixte statistique et linguistique.Traitement Automatique des Langues (T.A.L.
), 36(1-2):101?118.P Drouin and P Langlais.
2006. valuation du potentielterminologique de candidats termes.
In JADT, pages379?388.N Elhadad and K Sutaria.
2007.
Mining a lexiconof technical terms and lay equivalents.
In BioNLP,pages 49?56.JL Fleiss and J Cohen.
1973.
The equivalence ofweighted kappa and the intraclass correlation coef-ficient as measures of reliability.
Educational andPsychological Measurement, 33:613?619.R Flesch.
1948.
A new readability yardstick.
Journalof Applied Psychology, 23:221?233.T Franc?ois.
2011.
Les apports du traitements automa-tique du langage la lisibilit du franais langue tran-gre.
Phd thesis, Universit Catholique de Louvain,Louvain.KT Frantzi, S Ananiadou, and J Tsujii.
1997.
Auto-matic term recognition using contextual clues.
InMULSAIC IJCAI, pages 73?79.N Gala, T Franc?ois, and C Fairon.
2013.
Towards afrench lexicon with difficulty measures: NLP help-ing to bridge the gap between traditional dictionariesand specialized lexicons.
In eLEX-2013.L Goeuriot, N Grabar, and B Daille.
2007.
Car-act?erisation des discours scientifique et vulgaris?e enfranc?ais, japonais et russe.
In TALN, pages 93?102.N Grabar, S Krivine, and MC Jaulent.
2007.
Classifi-cation of health webpages as expert and non expertwith a reduced set of cross-language features.
InAMIA, pages 284?288.R Gunning.
1973.
The art of clear writing.
McGrawHill, New York, NY.G Henry.
1975.
Comment mesurer la lisibilit.
Labor,Bruxelles.C Iacobini.
1997.
Distinguishing derivational pre-fixes from initial combining forms.
In First mediter-ranean conference of morphology, Mytilene, Islandof Lesbos, Greece, septembre.C Iacobini, 2003.
Composizione con elementi neoclas-sici, pages 69?96.Gonia Jarema, Cline Busson, Rossitza Nikolova,Kyrana Tsapkini, and Gary Libben.
1999.
Process-ing compounds: A cross-linguistic study.
Brain andLanguage, 68(1-2):362?369.SK Jauhar and L Specia.
2012.
Uow-shef: Sim-plex ?
lexical simplicity ranking based on contextualand psycholinguistic features.
In *SEM 2012, pages477?481, Montr?eal, Canada, 7-8 June.
Associationfor Computational Linguistics.A Johannsen, H Mart?
?nez, S Klerke, and A S?gaard.2012.
Emnlp@cph: Is frequency all there is to sim-plicity?
In *SEM 2012, pages 408?412, Montr?eal,Canada, 7-8 June.
Association for ComputationalLinguistics.R Jucks and R Bromme.
2007.
Choice of wordsin doctor-patient communication: an analysis ofhealth-related internet sites.
Health Commun,21(3):267?77.L Kandel and A Moles.
1958.
Application de lindicede flesch la langue franaise.
Cahiers tudes deRadio-Tlvision, 19:253?274.19JP Kincaid, RP Jr Fishburne, RL Rogers, andBS Chissom.
1975.
Derivation of new readabil-ity formulas (automated readability index, fog countand flesch reading ease formula) for navy enlistedpersonnel.
Technical report, Naval Technical Train-ing, U. S. Naval Air Station, Memphis, TN.D Kokkinakis and M Toporowska Gronostaj.
2006.Comparing lay and professional language in cardio-vascular disorders corpora.
In Australia Pham T.,James Cook University, editor, WSEAS Transactionson BIOLOGY and BIOMEDICINE, pages 429?437.I Korkontzelos, IP Klapaftis, and S Manandhar.
2008.Reviewing and evaluating automatic term recogni-tion techniques.
In GoTAL, pages 248?259.JR Landis and GG Koch.
1977.
The measurement ofobserver agreement for categorical data.
Biometrics,33:159?174.G Leroy, S Helmreich, J Cowie, T Miller, andW Zheng.
2008.
Evaluating online health informa-tion: Beyond readability formulas.
In AMIA 2008,pages 394?8.Gary Libben, Martha Gibson, Yeo Bom Yoon, and Do-miniek Sandra.
2003.
Compound fracture: The roleof semantic transparency and morphological head-edness.
Brain and Language, 84(1):50?64.AL Ligozat, C Grouin, A Garcia-Fernandez, andD Bernhard.
2012.
Annlor: A na?
?ve notation-system for lexical outputs ranking.
In *SEM 2012,pages 487?492.A L?udeling, T Schmidt, and S Kiokpasoglou.
2002.Neoclassical word formation in german.
Yearbookof Morphology, pages 253?283.D Maynard and S Ananiadou.
2000.
Identifying termsby their family and friends.
In Proceedings of COL-ING 2000, pages 530?536, Saarbrucken, Germany.A McCray.
2005.
Promoting health literacy.
J of AmMed Infor Ass, 12:152?163.T Miller, G Leroy, S Chatterjee, J Fan, and B Thoms.2007.
A classifier to evaluate language specificity ofmedical documents.
In HICSS, pages 134?140.Fiammetta Namer and Pierre Zweigenbaum.
2004.Acquiring meaning for French medical terminology:contribution of morphosemantics.
In Annual Sym-posium of the American Medical Informatics Asso-ciation (AMIA), San-Francisco.F Namer.
2000.
FLEMM : un analyseur flexionnel dufranc?ais `a base de r`egles.
Traitement automatiquedes langues (TAL), 41(2):523?547.Oregon Evidence-based Practice Center.
2008.
Bar-riers and drivers of health information technologyuse for the elderly, chronically ill, and underserved.Technical report, Agency for healthcare research andquality.V Patel, T Branch, and J Arocha.
2002.
Errors in inter-preting quantities as procedures : The case of phar-maceutical labels.
International journal of medicalinformatics, 65(3):193?211.M Poprat, K Mark?o, and U Hahn.
2006.
A lan-guage classifier that automatically divides medicaldocuments for experts and health care consumers.In MIE 2006 - Proceedings of the XX InternationalCongress of the European Federation for MedicalInformatics, pages 503?508, Maastricht.JR Quinlan.
1993.
C4.5 Programs for Machine Learn-ing.
Morgan Kaufmann, San Mateo, CA.R Rittman.
2008.
Automatic discrimination of genres.VDM, Saarbrucken, Germany.R Rudd, B Moeykens, and T Colton, 1999.
AnnualReview of Adult Learning and Literacy, page ch 5.H Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of the Inter-national Conference on New Methods in LanguageProcessing, pages 44?49, Manchester, UK.R Sinha.
2012.
Unt-simprank: Systems for lexicalsimplification ranking.
In *SEM 2012, pages 493?496, Montr?eal, Canada, 7-8 June.
Association forComputational Linguistics.L Specia, SK Jauhar, and R Mihalcea.
2012.
Semeval-2012 task 1: English lexical simplification.
In *SEM2012, pages 347?355.TM Tran, H Chekroud, P Thiery, and A Julienne.
2009.Internet et soins : un tiers invisible dans la relationm?edecine/patient ?
Ethica Clinica, 53:34?43.Y Wang.
2006.
Automatic recognition of text diffi-culty from consumers health information.
In IEEE,editor, Computer-Based Medical Systems, pages131?136.I.H.
Witten and E. Frank.
2005.
Data mining: Practi-cal machine learning tools and techniques.
MorganKaufmann, San Francisco.Eugen W?uster.
1981.
L?tude scientifique gnrale de laterminologie, zone frontalire entre la linguistique, lalogique, l?ontologie, l?informatique et les sciencesdes choses.
In G. Rondeau et H. Felber, editor,Textes choisis de terminologie, volume I. Fonde-ments thoriques de la terminologie, pages 55?114.GISTERM, Universit de Laval, Qubec.
sous la di-rection de V.I.
Siforov.Q Zeng-Treiler, H Kim, S Goryachev, A Keselman,L Slaugther, and CA Smith.
2007.
Text charac-teristics of clinical reports and their implications forthe readability of personal health records.
In MED-INFO, pages 1117?1121, Brisbane, Australia.W Zheng, E Milios, and C Watters.
2002.
Filteringfor medical news items using a machine learning ap-proach.
In AMIA, pages 949?53.20
