A NATUWAL LANGUAGE INTERFACE USING A WORLD MODELYoshio Izumida, Hiroshi Ishikawa, Toshiaki Yoshino,Tadashi Hoshiai, and Akifumi MakinouchiSoftware LaboratoryFujitsu Laboratories Ltd.1015 kamikodanaka, Nakahara-ku, Kawasaki, 211, JapanABSTRACTDatabases are nowadays used by varied anddiverse users, many of whom are unfamiliar withthe workings of a computer, but who, nevertheless,want to use those databases more easily.
Risingto meet this demand, authors are developing aJapanese language interface, called KID, as adatabase front-end system.
KID incorporates aworld model representing application and databaseknowledge to help make databases easier to use.KID has the following features: (I) parserextendability and robustness, (2) independencefrom the application domain, (3) ease of knowledgeediting, (4) independence from the database.
Thispaper focuses on the first three features.
KIDhas already been applied to the fields of housing,sales, and drug testing, thus confirming itstransportability and practicality.INTRODUCTIONKID (Knowledge-based Interface to Databases) isa Japanese-language database interface (Izumida,84).
KID has the following four features.Extendab i l i ty  and robustnessNatural language sentences employ a widevariety of expressions.
A parser must always beextended to understand new sentences.
A parserwhich can understand one set of sentences is oftenincapable of understanding another set ofsentences.
In KID, parsing rules are grouped intopackets and the parsing mechanism is simple, thusmaking KID highly extendable.
The system must berobust, in order to handle conversationalsentences, which often contain errors andellipses.
To interpret these ill-formedsentences, semantic interpretation must play aleading role.
KID has an integrated knowledgebase called the world model.
The world modelrepresents the semantic model of the domain of thediscourse in an object-oriented manner.
Severalsystems (e.g., Ginsparg, 83) use a semantic modelto interpret ill-formed sentences, but the use ofthe semantic model is unclear.
We have made thesemantic interpretation rules clear according tothe structure of the world model and syntacticinformation of the input sentences.
This helpsthe parsing of ill-formed sentences.Independence from the app l i ca t ion  domainThe system must be easily adaptable todifferent applications.
The domain-dependentknowledge must be separate from the domain-independent knowledge.
In many systems (e.g.,Waltz, 78 and Hendrix, 78), the domain-dependentknowledge is embedded within the parsing rules,thus reducing the system's transportability.
InKID, the domain-dependent knowledge is integratedinto the world model separately, therefore givingKID high transportability.Ease o f  knowledge ed i t ingThe world model contains various kinds ofknowledge, and the editing of this knowledge mustbe easy to accommodate various levels of users.KID provides users with the world model editor,this having a separate user interface for eachuser level.
The world model editor makes thecustomization and extension of the KID systemeasy.Independence from the  databaseThe system must be able handle changes in thedatabase system and schema easily.
In TEAM(Gross, 83), the schema information is separate,but the user must be familiar with the databaseschema such as files and fields.
In KID, themapping information between the model of thedomain and the database schema is described in theworld model, so the user does not have to worryabout any changes in the database schema.Knowledge of the query language of a databasesystem is represented separately as productionrules.
Thus, the user only has to change theserules if there are changes in the database system.In this paper we will focus on the first threefeatures of KID.
Firstly, we will explain theworld model, then the overall structure of theKID, the morphological analyzer (required toprocess Japanese-language sentences), the model-based parser, semantic interpretation and the flowof the parsing process, knowledge for customizingKID and, lastly, the evaluation of KID and itsresults.WORLD NODELThe world model represents the user's image ofthe application domain.
The user's image does notmatch the database schema, because the databaseschema reflects the storage structure of the dataand the performance consideration of the databasesystem.
The world model represents the user'simage as classes and relationships between them.205%Retailer'nameLocationCormuodityCommodity'sname/I!
', >\\\RetailerSalesFixedprice///SalesquantityIIQ : Class~_ : Attribute relationship-------,~ : Super-sub relationshipFigure I.
Part of the world model for sales.A class is represented as an object in theobject-oriented programming sense (Bobrow, 81),which describes a thing or event in the domain.There are only two types of relationship;attribute relationship and super-sub relationship.This model matches the user's image and is verysimple, so design and editing of the model iseasy.Figure I shows the part of the world model fora sales domain.
The commodity class has twoattribute classes, commodity's name and fixedprice.
The beer and whisky classes are subclassesof the commodity class and inherit its attributes.Figure 2 shows a part of the definition of thesales class.
The internal representation of aclass object is a frame expression.
A slotrepresents a relationship to another class using a$class facet and mapping information to thedatabase schema using a Sstorage facet.
The valueof a Sstorage facet denotes the class name whichhas mapping information.
The sales class has fourattribute classes: RETAILER, COMMODITY, SALES?RICE, and SALES QUANTITY.
An object may alsoinclude the method for handling data within it.The system allows the user to define lexicalinformation in the world model.
For example, thenoun 'commodity' corresponds to the commodityclass.
The verb 'sell' and the noun 'sale' bothcorrespond to the sales class.
The verb 'locate'SALESRETAILER $class RETAILER$storage SALES RETAILER STORAGECOMMODITY $class COMMODITY --$storage SALES COMMODITY STORAGEPRICE $class SALES--PRICE --Sstorage SALES--PRICE STORAGEQUANTITY $class SALESZQUANTI-TY$storage SALES_QUANTITY_STORAGEFigure 2.
Internal representation of a class.corresponds to the arc between the relation andlocation classes.
Lexical information isphysically stored in the word dictionary.
Thedictionary is represented as a table of therelational database system.
Figure 3 shows partof the dictionary.
The dictionary consists of aheadword, an identifier, a part of speech, parsinginformation and other fields.
The correspondenceto the world model is represented in the OBJECTfeature of the PARSE field.
The verb also has itscase frame information in the PARSE field.
Allthe information relating to a specific domain isstored in the world model, so the user need onlycreate the world model to customize KID to aspecific application.
This results intransportability of the system.206HEADWORD IDENTIFIER POS PARSESHOUHIN N (OBJECT COMMODITY)(commodity)(sell)ft~DHANBAI-SURURE-RUWONOVBAUX-VBAUXAUX(OBJECT SALES) CLASS(CASE ((RETAILER *GA *WA(SALESQUANTITY NP)))(P *WO)(e *NO)Figure 3.
Word dictionary.LrWorld model editorMorphological ~ ~analyzer2 ;based l---------RetrieverREALMModelingsystemWorldmodelDBMSFigure 4.
System configuration.SYSTEM CONFIGURATIONKID is the front-end system of the databasemanagement system, the configuration being shownin Figure 4.
The user enters a query via Japaneseword processing terminal.
Since a Japanese-language sentence is not separated into words, themorphological analyzer segments the sentence toget the list of words, using the word dictionary.The model-based parser analyzes the word list, andsemantically interprets it, using the world modelas a basis.
The result is the "meaning structure"consisting of the parsed tree and the relevantpart of the world model representing the meaningof the input query.
The retriever generates theJapanese-language paraphrase from the meaningstructure and outputs it to the user terminal forconfirmation.
Then, the retriever translates themeaning structure into the query language of thetarget database management system and executes it.The result is displayed on the user terminal.
Theworld model is managed by the modeling system,REALM (REAL world Modeling system), and is editedby the world model editor.MORPHOLOGICAL ANALYZERA Japanese-language sentence is not separatedinto words.
The system must segment a sentenceinto its component words.
The morphological207His behav ior  was ch i ld i sh .?
?
?
??
?
@ @his behav ior  was I ch i ld i shLo?i nd icat ion  of l i feFigure 5.
An example of morphological analysis.analyzer performs this segmentation.
KID selectsthe segmentation candidate with the least numberof 'bunsetsu'.
We believe this method to be thebest method for segmenting a Japanese-languagesentence (Yoshimura, 83).
This method uses abreadth-first search of a candidate word graph.Since many candidate words are generated by thismethod, the performance of the segmentation is notso good.
We use the optimum graph searchalgorithm, called A* (Nilssen, 80), to search thecandidate word graph.Figure 5 shows an example of morphologicalanalysis.
This sentence has three possiblesegmentations.
The first line is the correctsegmentation, having the least number of'bunsetsu'.
The algorithm A* estimates the numberof bunsetsu in the whole sentence at each node ofthe candidate word graph, and selects the nextsearch path.
This method eliminates uselesssearching of the candidate graph.
In Figure 5,the circled numbers denote the sequence of thegraph search.The morphological analyzer segments a sentenceusing connection information for each word.
Theconnection information depends on the part ofspeech.
Detailed classification of words leads tocorrect segmentation.
However, it is difficultfor an end-user perform this kind ofclassification.
Thus, we classify words into twocategories: content words and function words.Content words are nouns, verbs, adjectives, andadverbs, which depend on the application.
Theyare classified roughly.
Function words includeauxiliaries, conjunctions, and so on, which areindependent of the domain.
They are classified indetail.
It is easy for the user to roughlyclassify content words.
This morphologicalanalyzer segments sentences precisely andefficiently, and generates a word list.
This wordlist is then passed to the model-based parser.MODEL BASED PARSERIn its first phase the parser generates'bunsetsu' from the word list.
The parsersyntactically analyzes the relationship betweenthese 'bunsetsu'.
At the same time, the parsersemantically checks and interprets therelationships, based on the world model.
'Bunsetsu' sequences of a Japanese-languagesentence are relatively arbitrary.
Andconversational sentences may include errors andellipses, therefore the parser must be robust, inorder to deal with these ill-formed sentences.These factors suggest that semantic interpretationshould play an important role in the parser.The basic rules of semantic interpretation arethe identification rule and the connection rule.These rules check the relationship between theclasses which correspond to the 'bunsetsu' andinterpret the meaning of the unified 'bunsetsu'.The identification rule corresponds to a super-subrelationship.
If two classes, corresponding toiIisales price is 2000 yenFigure 6.
An example of the identification rule.iretaiier name /Figure 7.
An example of the connection rule.208two phrases, are connected by a super-subrelationship, this rule selects the subclass asthe meaning of the unified phrase, because thesubclass has a more specific and restrictedmeaning than the super class.
Figure 6 shows anexample of the identification rule.
In thisexample, the phrase 'sales price' corresponds tothe sales price class, and '2000 yen' correspondsto the price class.
The identification ruleselects the sales price class as the unifiedmeaning.
The connection rule corresponds to anattribute relationship.
If two classes areconnected by an attribute relationship, this ruleselects the root class of the relation as themeaning of the unified class, because the rootclass clarifies the semantic position of the leafclass in the world model.
Figure 7 shows anexample of the connection rule.
In this example,the phrase 'retailer' corresponds to the retailerclass, and 'name' corresponds to the name class.The connection rule selects the retailer class asthe unified meaning.Bunsetsu generationIdentificationConnectionFigure 8.
Parsing process.Figure 8 shows the parsing process of themodel-based parser.
In each process, inputsentences are scanned from left to right.
In thefirst phase, 'bunsetsu' are generated from theword list.
At the same time the parser attachesthe object which is instanciated from thecorresponding class to each 'bunsetsu' Thefollowing identification and connection phasesperform semantic interpretation using theseinstance objects, and determines the relationshipbetween phrases.
The identification process andconnection process are executed repeatedly untilall the relationship between phrases have beendetermined.
The identification process haspriority over the connection process, because asuper-sub relationship represents a same conceptgeneralization hierarchy and has strongerconnectivity than an attribute relationship, thelatter representing a property relation betweendifferent concepts.
This parsing mechanism isvery simple, allowing the user to expand eachprocess easily.
Each process consists of a numberof production rules, which are grouped intopackets according to the relevant syntacticpatterns.
Each packet has an execution priorityaccording to the syntactic connectivity of eachpattern.
Thus the identification or addition ofthe rules are localized in the packet concernedwith the modification.
This simple parsingmechanism and the modular construction of theparsing rules contribute to the expandability ofthe parser.Figures 9 and 10 show an example of parsing.This query means 'What is the name of the retailerin Geneva who sells commodity A?'.
Themorphological analyzer segments the sentence, andthe model-based parser generates the phrases inthe parentheses.
The identification process isnot applied to these phrases, because there is nosuper-sub relationship between them.
Next, themodel-based parser applies the connection process.The phrase 'Geneva' can modify the phrase'commodity A' syntactically, but not semantically,because the corresponding classes, "Location" and"Commodity", do not have an attributerelationship.
The phrase 'commodity A' can modifythe phrase 'to sell' both semantically and(Geneva) (commodity A) (to sell) (retai ler) (name)S(Sales)C(Sales)M(Sales ~ Commodity ~C-S(Retailer)C(Sales)M(Sales ~ Commodity ~ C-name)Retailer)Figure 9.
An example of parsing (I).209(geneva) (commodity A) (to sell) (retailer) (name)C(Sales) ~ /M(Sales ~ Commodity ~ C-name ~ ~.~/Retailer ?
Location)S(Name)C(Sales)M(Sales ~ Commodity ~ C-name)~Retailer ~ Location)R-name)Figure 10.
An example of parsing (2).syntactically, because the classes "Commodity" and"Sales" have an attribute relationship.
In thiscase, the predicate connection rule is applied,generating the unified phrase, node I.
The parseruses these three kinds of objects to check theconnectivity.
The syntactic object S representsthe syntactic center of the unified phrase.
Inthe Japanese-language the last phrase of theunified phrase is syntactically dominant.
Theconceptual object represents the semantic centerof the unified phrase, and is determined by theidentification and connection rule.
The meaningobjects M represent the meaning of the unifiedphrase using the sub-network of the world model.The predicate connection rule determines the salesclass to be the conceptual object of node I,because the sales class is the root class of theattribute relationship.
The meaning objects areSales --> Commodity --> Commodity name.
Thepredicate connection rule also generates nounphrase node 2 and the S,C,and M of the node isdetermined as described in Figure 9.
Next, thenoun phrase connection rule is applied.
This ruleis applied to a syntactic pattern such as a nounphrase with a postposition 'no' followed by a nounphrase with any kind of postposition.
The phrase'Geneva' and the unified phrase 3 are unified tonode 3 by the noun phrase connection rule (seeFigure 10).
This rule also generates node 4.
Themeaning of this sentence is that of node 4.Errors or ellipses of postposition, such asno or ga , are handled by packets which dealwith the syntactic pattern.
On the other hand,ellipses are handled by the special packets whichdeal with non-unified phrases based on the worldmodel.
These special packets have a lowerpriority than the standard packets.
Differentlevels of robustness can be achieved by using thesuitable packet for dealing with errors orellipses ?CUSTORIZATIONTo customize the KID system to a specificapplication domain, the user has to performseveral domain-dependent tasks.
First, the usermakes a class network for the domain either fromqueries, which we call a top-down approach, orfrom the database schema, a bottom-up approach.Then, the user assigns words to the classes orattributes of the class network.
Lastly, the userdescribes mapping information between classes andthe database schema within the classes.The world model editor supports thesecustomization processes.
The world model editorhas three levels of user interface, in order toassist various users in editing the world model(see Figure 11).
The first level is aconstruction description level, in which the usermakes a structure of a class network.
The secondlevel is a word assignment level, in which theuser assigns words to classes or attributes.These two levels are provided for end-users.
Thethird level is a class- or word-contentsdescription level.
This level is provided formore sophisticated users, who understand theinternal knowledge representation.
The worldmodel editor enables users to navigate any of theinterface levels.
Various users can edit theknowledge, according to their own particular view.Thus, knowledge base editing is made easier.EVALUATIONWe have applied KID to three differentapplications; housing, sales, and new drug tests.Figure 12 shows a result of an evaluation of KID.The target domain is a new drug test.
We prepared400 sentences for the evaluation.
In a littleless than a month, 91% of the sentences had beenaccepted.
We decided a sentence is accepted, ifthe sentence is correctly analyzed and the correctdata is retrieved from the database.
We dividedthe 4OO sentences into four groups and performed ablind test and a full capability test for eachgroup, in stages.
In the blind test, sentencesare tested without changing any knowledge of thesystem.
In the full capability test, we make allpossible extensions or modifications to accept thesentences.
The acceptance ratio of the blind testis improving, so we believe KID will soon becomeavailable for practical use.210/ \!
!Lmmm//mJConstruction descriptionWord assignmentWord contents descriptionClass contents descriptiono\ ] .009080706050403020i0Figure 11.
The world model editor.3rd?
2nd 95Domain: New drug tes tTota l  400 sentencesAccepted 91%I \] i I I Ii 5 IO 15 20 25Elapsed time (days)Figure 12.
Evaluation of KID.9895211CONCLUSIOHSIn this paper, the three features of theJapanese-language interface KID were described.KID has both a simple mechanism of parsing andmodularized grammar rules, so the parser is highlyextendable.
The semantic interpretation has clearprinciples based on the structure of the worldmodel and syntactic information of the inputsentence.
Thus, the different levels ofrobustness are achieved by the adequate portion ofthe parser for dealing with the errors orellipses.
The world model integrates the domain-dependent knowledge separately.
The user only hasto customize the world model to a specificapplication.
This customization is supported bythe world model editor which provides variouslevels of user interfaces to make the world modelediting easy for various users.KID is now implemented as a front-end systemfor the relational database system (Makinouchi,83).
KID is implemented in Utilisp (Chikayama,81), a dialect of Lisp.
The morphologicalanalyzer is 0.7 ksteps, the model-based parser is2.3 ksteps, and retriever is 2.2 ksteps.
Thegrammatical rule is 2.7 kstepe written in a ruledescription language, and is made up of 70packets.
KID uses several tools and utilities.The modeling system REALM is 2 ksteps, the worldmodel editor is 1.3 ksteps, the window system is1.7 ksteps, and the knowledge-based programmingsystem, Minerva, is 3.5 ksteps.We have several plans for future development.We will expand the system to accept not onlyretrieval sentences but also insertion, deletion,update, statistical analysis, and graphicoperation.
The parser coverage will be extendedto accept wider expressions, including parallelphrases and sentences.ACKNONLEDGERENTSTo Mr. Tatsuya Hayashi, Manager of the SoftwareLaboratory we express our gratitude for giving usan opportunity to make these studies.REFERENCESBobrow, D. G., Stefik, M., The LOOPS Manual: AData Oriented and Object Oriented ProgrammingSystem for Interlisp, Xerox Knowledge-BasedVLSI Design Group Memo, 1981, KB-VLSL-81-13.Chikayama, T., Utilisp Manual, METR 81-6,Mathematical Engineering Section, University ofTokyo, 1981.Ginsparg, J. M., A Robust Portable NaturalLanguage Data Base Interface, Proc.
Conf.Applied Natural Language Processing, 1983,pp.25-30.Grosz, B. J., TEAM: A Transportable Natural-Language Interface System, Proc.
Conf.
AppliedNatural Language Processing, 1983, pp.39-45.Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D.,Slocum, J., Developing a Natural LanguageInterface to Complex Data, ACM TODS, Vcl.
3,No.
2, 1978, pp.
I05-147.Izumida, Y. et al, A Database Retrieval SystemUsing a World Model, Symposium on DatabaseSystem, 43-2, Information Processing Society ofJapan, 1984 \[in Japanese\].Makinouchi, A. et al, Relational DatabeseManagement System RDB/VI, Transactions ofInformation Processing Society of Japan, Vol.24, No.
I, 1983, pp.47-55 \[in Japanesel.Nilssen, N. J., Principles of ArtificialIntelligence, Tioga, 1980.Waltz, D. L., An English Language QuestionAnswering System for a Large RelationalDatabase, Communication of the ACM, 1978,27(7), pp.526-539.Yoshimura, K., Hitaka, T., Yoshida, S.,Morphological Analysis of Non-marked-offJapanese Sentences by the Least BUNSETSU'SNumber Method, Transactions of InformationProcessing Society of Japan~ Vol.
24, No.
I,1983, pp.40-46 \[in Japanese\].212
