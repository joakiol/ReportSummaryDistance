Proceedings of the ACL 2010 Conference Short Papers, pages 109?114,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsCollocation Extraction beyond the Independence AssumptionGerlof BoumaUniversita?t Potsdam, Department LinguistikCampus Golm, Haus 24/35Karl-Liebknecht-Stra?e 24?2514476 Potsdam, Germanygerlof.bouma@uni-potsdam.deAbstractIn this paper we start to explore two-partcollocation extraction association measuresthat do not estimate expected probabili-ties on the basis of the independence as-sumption.
We propose two new measuresbased upon the well-known measures ofmutual information and pointwise mutualinformation.
Expected probabilities are de-rived from automatically trained AggregateMarkov Models.
On three collocation goldstandards, we find the new association mea-sures vary in their effectiveness.1 IntroductionCollocation extraction typically proceeds by scor-ing collocation candidates with an association mea-sure, where high scores are taken to indicate likelycollocationhood.
Two well-known such measuresare pointwise mutual information (PMI) and mu-tual information (MI).
In terms of observing a com-bination of words w1, w2, these are:i(w1, w2) = logp(w1, w2)p(w1) p(w2), (1)I (w1, w2) =?x?{w1,?w1}y?
{w2,?w2}p(x, y) i(x, y).
(2)PMI (1) is the logged ratio of the observed bi-gramme probability and the expected bigrammeprobability under independence of the two wordsin the combination.
MI (2) is the expected outcomeof PMI, and measures how much information of thedistribution of one word is contained in the distribu-tion of the other.
PMI was introduced into the collo-cation extraction field by Church and Hanks (1990).Dunning (1993) proposed the use of the likelihood-ratio test statistic, which is equivalent to MI up toa constant factor.Two aspects of (P)MI are worth highlighting.First, the observed occurrence probability pobs iscompared to the expected occurrence probabilitypexp.
Secondly, the independence assumption un-derlies the estimation of pexp.The first aspect is motivated by the observa-tion that interesting combinations are often thosethat are unexpectedly frequent.
For instance, thebigramme of the is uninteresting from a colloca-tion extraction perspective, although it probably isamongst the most frequent bigrammes for any En-glish corpus.
However, we can expect to frequentlyobserve the combination by mere chance, simplybecause its parts are so frequent.
Looking at pobsand pexp together allows us to recognize these cases(Manning and Schu?tze (1999) and Evert (2007) formore discussion).The second aspect, the independence assump-tion in the estimation of pexp, is more problem-atic, however, even in the context of collocationextraction.
As Evert (2007, p42) notes, the assump-tion of ?independence is extremely unrealistic,?
be-cause it ignores ?a variety of syntactic, semanticand lexical restrictions.?
Consider an estimate forpexp(the the).
Under independence, this estimatewill be high, as the itself is very frequent.
However,with our knowledge of English syntax, we wouldsay pexp(the the) is low.
The independence assump-tion leads to overestimated expectation and the thewill need to be very frequent for it to show up as alikely collocation.
A less contrived example of howthe independence assumption might mislead collo-cation extraction is when bigramme distribution isinfluenced by compositional, non-collocational, se-mantic dependencies.
Investigating adjective-nouncombinations in a corpus, we might find that beigecloth gets a high PMI, whereas beige thought doesnot.
This does not make the former a collocation ormultiword unit.
Rather, what we would measure isthe tendency to use colours with visible things andnot with abstract objects.
Syntactic and semantic109associations between words are real dependencies,but they need not be collocational in nature.
Be-cause of the independence assumption, PMI andMI measure these syntactic and semantic associa-tions just as much as they measure collocationalassociation.
In this paper, we therefore experimen-tally investigate the use of a more informed pexp inthe context of collocation extraction.2 Aggregate Markov ModelsTo replace pexp under independence, one mightconsider models with explicit linguistic infor-mation, such as a POS-tag bigramme model.This would for instance give us a more realisticpexp(the the).
However, lexical semantic informa-tion is harder to incorporate.
We might not knowexactly what factors are needed to estimate pexpand even if we do, we might lack the resourcesto train the resulting models.
The only thing weknow about estimating pexp is that we need moreinformation than a unigramme model but less thana bigramme model (as this would make pobs/pexpuninformative).
Therefore, we propose to use Ag-gregate Markov Models (Saul and Pereira, 1997;Hofmann and Puzicha, 1998; Rooth et al, 1999;Blitzer et al, 2005)1 for the task of estimating pexp.In an AMM, bigramme probability is not directlymodeled, but mediated by a hidden class variable c:pamm(w2|w1) =?cp(c|w1)p(w2|c).
(3)The number of classes in an AMM determines theamount of dependency that can be captured.
In thecase of just one class, AMM is equivalent to a uni-gramme model.
AMMs become equivalent to thefull bigramme model when the number of classesequals the size of the smallest of the vocabular-ies of the parts of the combination.
Between thesetwo extremes, AMMs can capture syntactic, lexical,semantic and even pragmatic dependencies.AMMs can be trained with EM, using no moreinformation than one would need for ML bigrammeprobability estimates.
Specifications of the E- andM-steps can be found in any of the four papers citedabove ?
here we follow Saul and Pereira (1997).
Ateach iteration, the model components are updated1These authors use very similar models, but with differingterminology and with different goals.
The term AMM is usedin the first and fourth paper.
In the second paper, the modelsare referred to as Separable Mixture Models.
Their use incollocation extraction is to our knowledge novel.according to:p(c|w1)?
?w n(w1, w)p(c|w1, w)?w,c?
n(w1, w)p(c?|w1, w), (4)p(w2|c)?
?w n(w,w2)p(c|w,w2)?w,w?
n(w,w?)p(c|w,w?
), (5)where n(w1, w2) are bigramme counts and the pos-terior probability of a hidden category c is esti-mated by:p(c|w1, w2) =p(c|w1)p(w2|c)?c?
p(c?|w1)p(w2|c?).
(6)Successive updates converge to a local maximumof the AMM?s log-likelihood.The definition of the counterparts to (P)MI with-out the independence assumption, the AMM-ratioand AMM-divergence, is now straightforward:ramm(w1, w2) = logp(w1, w2)p(w1) pamm(w2|w1), (7)damm(w1, w2) =?x?{w1,?w1}y?
{w2,?w2}p(x, y) ramm(x, y).
(8)The free parameter in these association measures isthe number of hidden classes in the AMM, that is,the amount of dependency between the bigrammeparts used to estimate pexp.
Note that AMM-ratioand AMM-divergence with one hidden class areequivalent to PMI and MI, respectively.
It can beexpected that in different corpora and for differ-ent types of collocation, different settings of thisparameter are suitable.3 Evaluation3.1 Data and procedureWe apply AMM-ratio and AMM-divergence tothree collocation gold standards.
The effectivenessof association measures in collocation extraction ismeasured by ranking collocation candidates afterthe scores defined by the measures, and calculat-ing average precision of these lists against the goldstandard annotation.
We consider the newly pro-posed AMM-based measures for a varying numberof hidden categories.
The new measures are com-pared against two baselines: ranking by frequency(pobs) and random ordering.
Because AMM-ratioand -divergence with one hidden class boil downto PMI and MI (and thus log-likelihood ratio), theevaluation contains an implicit comparison with110these canonical measures, too.
However, the re-sults will not be state-of-the-art: for the datasetsinvestigated below, there are more effective extrac-tion methods based on supervised machine learning(Pecina, 2008).The first gold standard used is the Germanadjective-noun dataset (Evert, 2008).
It contains1212 A-N pairs taken from a German newspapercorpus.
We consider three subtasks, depending onhow strict we define true positives.
We used thebigramme frequency data included in the resource.We assigned all types with a token count ?5 to onetype, resulting in AMM training data of 10k As,20k Ns and 446k A-N pair types.The second gold standard consists of 5102 Ger-man PP-verb combinations, also sampled fromnewspaper texts (Krenn, 2008).
The data con-tains annotation for support verb constructions(FVGs) and figurative expressions.
This resourcealso comes with its own frequency data.
After fre-quency thresholding, AMMs are trained on 46kPPs, 7.6k Vs, and 890k PP-V pair types.Third and last is the English verb-particle con-struction (VPC) gold standard (Baldwin, 2008),consisting of 3078 verb-particle pairs and annota-tion for transitive and intransitive idiomatic VPCs.We extract frequency data from the BNC, follow-ing the methods described in Baldwin (2005).
Thisresults in two slightly different datasets for the twotypes of VPC.
For the intransitive VPCs, we trainAMMs on 4.5k Vs, 35 particles, and 43k pair types.For the transitive VPCs, we have 5k Vs, 35 parti-cles and 54k pair types.All our EM runs start with randomly initializedmodel vectors.
In Section 3.3 we discuss the impactof model variation due to this random factor.3.2 ResultsGerman A-N collocations The top slice in Ta-ble 1 shows results for the three subtasks of theA-N dataset.
We see that using AMM-based pexpinitially improves average precision, for each taskand for both the ratio and the divergence measure.At their maxima, the informed measures outper-form both baselines as well as PMI and MI/log-likelihood ratio (# classes=1).
The AMM-ratio per-forms best for 16-class AMMs, the optimum forAMM-divergence varies slightly.It is likely that the drop in performance for thelarger AMM-based measures is due to the AMMslearning the collocations themselves.
That is, theAMMs become rich enough to not only capturethe broadly applicative distributional influences ofsyntax and semantics, but also provide accuratepexps for individual, distributionally deviant combi-nations ?
like collocations.
An accurate pexp resultsin a low association score.One way of inspecting what kind of dependen-cies the AMMs pick up is to cluster the data withthem.
Following Blitzer et al (2005), we take the200 most frequent adjectives and assign them tothe category that maximizes p(c|w1); likewise fornouns and p(w2|c).
Four selected clusters (out of16) are given in Table 2.2 The esoteric class 1 con-tains ordinal numbers and nouns that one typicallyuses those with, including references to temporalconcepts.
Class 2 and 3 appear more semanticallymotivated, roughly containing human and collec-tive denoting nouns, respectively.
Class 4 showsa group of adjectives denoting colours and/or po-litical affiliations and a less coherent set of nouns,although the noun cluster can be understood if weconsider individual adjectives that are associatedwith this class.
Our informal impression from look-ing at clusters is that this is a common situation: asa whole, a cluster cannot be easily characterized,although for subsets or individual pairs, one canget an intuition for why they are in the same class.Unfortunately, we also see that some actual collo-cations are clustered in class 4, such as gelbe Karte?warning?
(lit.
: ?yellow card?)
and dickes Auto ?big(lit.
: fat) car?.German PP-Verb collocations The second slicein Table 1 shows that, for both subtypes of PP-Vcollocation, better pexp-estimates lead to decreasedaverage precision.
The most effective AMM-ratioand -distance measures are those equivalent to(P)MI.
Apparently, the better pexps are unfortunatefor the extraction of the type of collocations in thisdataset.The poor performance of PMI on these data ?clearly below frequency ?
has been noticed beforeby Krenn and Evert (2001).
A possible explanationfor the lack of improvement in the AMMs lies inthe relatively high performing frequency baselines.The frequency baseline for FVGs is five times the2An anonymous reviewer rightly warns against sketchingan overly positive picture of the knowledge captured in theAMMs by only presenting a few clusters.
However, the clus-tering performed here is only secondary to our main goalof improving collocation extraction.
The model inspectionshould thus not be taken as an evaluation of the quality of themodels as clustering models.111# classes1 2 4 8 16 32 64 128 256 512 Rnd FrqA-Ncategory 1 ramm 45.6 46.4 47.6 47.3 48.3 48.0 47.0 46.1 44.7 41.9 30.1 32.2damm 42.3 42.9 44.4 45.2 46.1 46.5 45.0 46.3 45.5 45.5category 1?2 ramm 55.7 56.3 57.4 57.5 58.1 58.1 57.7 56.9 55.7 52.8 43.1 47.0damm 56.3 57.0 58.1 58.4 59.8 60.1 59.3 60.6 59.2 59.3category 1?3 ramm 62.3 62.8 63.9 64.0 64.4 62.2 62.2 62.7 62.4 60.0 52.7 56.4damm 64.3 64.7 65.9 66.6 66.7 66.3 66.3 65.4 66.0 64.7PP-Vfigurative ramm 7.5 6.1 6.4 6.0 5.6 5.4 4.5 4.2 3.8 3.5 3.3 10.5damm 14.4 13.0 13.3 13.1 12.2 11.2 9.0 7.7 6.9 5.7FVG ramm 4.1 3.4 3.4 3.0 2.9 2.7 2.2 2.1 2.0 2.0 3.0 14.7damm 15.3 12.7 12.6 10.7 9.0 7.7 3.4 3.2 2.5 2.3VPCintransitive ramm 9.3 9.2 9.0 8.3 5.5 5.3 4.8 14.7damm 12.2 12.2 14.0 16.3 6.9 5.8transitive ramm 16.4 14.8 15.2 14.5 11.3 10.0 10.1 20.1damm 19.6 17.3 20.7 23.8 12.8 10.1Table 1: Average precision for AMM-based association measures and baselines on three datasets.Cl Adjective Noun1 dritt ?third?, erst ?first?, fu?nft ?fifth?, halb ?half?, kommend?next?, laufend ?current?, letzt ?last?, nah ?near?, paar ?pair?,vergangen ?last?, viert ?fourth?, wenig ?few?, zweit ?sec-ond?Jahr ?year?, Klasse ?class?, Linie ?line?, Mal ?time?, Monat?month?, Platz ?place?, Rang ?grade?, Runde ?round?, Saison?season?, Satz ?sentence?, Schritt ?step?, Sitzung ?session?, Son-ntag ?Sunday?, Spiel ?game?, Stunde ?hour?, Tag ?day?, Woche?week?, Wochenende ?weekend?2 aktiv ?active?, alt ?old?, ausla?ndisch ?foreign?, betroffen?concerned?, jung ?young?, lebend ?alive?, meist ?most?,unbekannt ?unknown?, viel ?many?Besucher ?visitor?, Bu?rger ?citizens?, Deutsche ?German?, Frau?woman?, Gast ?guest?, Jugendliche ?youth?, Kind ?child?, Leute?people?, Ma?dchen ?girl?, Mann ?man?, Mensch ?human?, Mit-glied ?member?3 deutsch ?German?, europa?isch ?European?, ganz ?whole?,gesamt ?whole?, international ?international?, national ?na-tional?, o?rtlich ?local?, ostdeutsch ?East-German?, privat?private?, rein ?pure?, sogenannt ?so-called?, sonstig ?other?,westlich ?western?Betrieb ?company?, Familie ?family?, Firma ?firm?, Gebiet?area?, Gesellschaft ?society?, Land ?country?, Mannschaft?team?, Markt ?market?, Organisation ?organisation?, Staat?state?, Stadtteil ?city district?, System ?system?, Team ?team?,Unternehmen ?enterprise?, Verein ?club?, Welt ?world?4 blau ?blue?, dick ?fat?, gelb ?yellow?, gru?n ?green?, linke?left?, recht ?right?, rot ?red?, schwarz ?black?, white ?wei?
?Auge ?eye?, Auto ?car?, Haar ?hair?, Hand ?hand?, Karte ?card?,Stimme ?voice/vote?Table 2: Selected adjective-noun clusters from a 16-class AMM.random baseline, and MI does not outperform it bymuch.
Since the AMMs provide a better fit for themore frequent pairs in the training data, they mightend up providing too good pexp-estimates for thetrue collocations from the beginning.Further investigation is needed to find outwhether this situation can be ameliorated and, ifnot, whether we can systematically identify forwhat kind of collocation extraction tasks using bet-ter pexps is simply not a good idea.English Verb-Particle constructions The lastgold standard is the English VPC dataset, shownin the bottom slice of Table 1.
We have only usedclass-sizes up to 32, as there are only 35 particletypes.
We can clearly see the effect of the largestAMMs approaching the full bigramme model asaverage precision here approaches the random base-line.
The VPC extraction task shows a differencebetween the two AMM-based measures: AMM-ratio does not improve at all, remaining below thefrequency baseline.
AMM-divergence, however,shows a slight decrease in precision first, but endsup performing above the frequency baseline for the8-class AMMs in both subtasks.Table 3 shows four clusters of verbs and par-ticles.
The large first cluster contains verbs thatinvolve motion/displacement of the subject or ob-ject and associated particles, for instance walkabout or push away.
Interestingly, the descriptionof the gold standard gives exactly such cases asnegatives, since they constitute compositional verb-particle constructions (Baldwin, 2008).
Classes 2and 3 show syntactic dependencies, which helps112Cl Verb Particle1 break, bring, come, cut, drive, fall, get, go, lay, look, move, pass, push,put, run, sit, throw, turn, voice, walkacross, ahead, along, around, away, back, back-ward, down, forward, into, over, through, together2 accord, add, apply, give, happen, lead, listen, offer, pay, present, refer,relate, return, rise, say, sell, send, speak, writeastray, to3 know, talk, tell, think about4 accompany, achieve, affect, cause, create, follow, hit, increase, issue,mean, produce, replace, require, sign, supportbyTable 3: Selected verb-particle clusters from an 8-class AMM on transitive data.collocation extraction by decreasing the impact ofverb-preposition associations that are due to PP-selecting verbs.
Class 4 shows a third type of distri-butional generalization: the verbs in this class areall frequently used in the passive.3.3 Variation due to local optimaWe start each EM run with a random initializa-tion of the model parameters.
Since EM finds localrather than global optima, each run may lead todifferent AMMs, which in turn will affect AMM-based collocation extraction.
To gain insight intothis variation, we have trained 40 16-class AMMson the A-N dataset.
Table 4 gives five point sum-maries of the average precision of the resulting40 ?association measures?.
Performance varies con-siderably, spanning 2?3 percentage points in eachcase.
The models consistently outperform (P)MI inTable 1, though.Several techniques might help to address thisvariation.
One might try to find a good fixed way ofinitializing EM or to use EM variants that reducethe impact of the initial state (Smith and Eisner,2004, a.o.
), so that a run with the same data andthe same number of classes will always learn (al-most) the same model.
On the assumption that anaverage over several runs will vary less than indi-vidual runs, we have also constructed a combinedpexp by averaging over 40 pexps.
The last columnVariation in avg precisionmin q1 med q3 max CombA-Ncat 1 ramm 46.5 47.3 47.9 48.4 49.1 48.4damm 44.4 45.4 45.8 46.1 47.1 46.4cat 1?2 ramm 56.7 57.2 57.9 58.2 59.0 58.2damm 58.1 58.8 59.2 59.4 60.4 60.0cat 1?3 ramm 63.0 63.7 64.2 64.6 65.3 64.6damm 65.2 66.0 66.4 66.6 67.6 66.9Table 4: Variation on A-N data over 40 EM runsand result of combining pexps.in Table 4 shows this combined estimator leads togood extraction results.4 ConclusionsIn this paper, we have started to explore collocationextraction beyond the assumption of independence.We have introduced two new association measuresthat do away with this assumption in the estima-tion of expected probabilities.
The success of usingthese association measures varies.
It remains to beinvestigated whether they can be improved more.A possible obstacle in the adoption of AMMs incollocation extraction is that we have not providedany heuristic for setting the number of classes forthe AMMs.
We hope to be able to look into thisquestion in future research.
Luckily, for the AN andVPC data, the best models are not that large (in theorder of 8?32 classes), which means that model fit-ting is fast enough to experiment with different set-tings.
In general, considering these smaller modelsmight suffice for tasks that have a fairly restricteddefinition of collocation candidate, like the tasksin our evaluation do.
Because AMM fitting is un-supervised, selecting a class size is in this respectno different from selecting a suitable associationmeasure from the canon of existing measures.Future research into association measures thatare not based on the independence assumption willalso include considering different EM variants andother automatically learnable models besides theAMMs used in this paper.
Finally, the idea of us-ing an informed estimate of expected probabilityin an association measure need not be confinedto (P)MI, as there are many other measures thatemploy expected probabilities.AcknowledgementsThis research was carried out in the context ofthe SFB 632 Information Structure, subproject D4:Methoden zur interaktiven linguistischen Korpus-analyse von Informationsstruktur.113ReferencesTimothy Baldwin.
2005.
The deep lexical acquisitionof english verb-particle constructions.
ComputerSpeech and Language, Special Issue on MultiwordExpressions, 19(4):398?414.Timothy Baldwin.
2008.
A resource for evaluating thedeep lexical acquisition of English verb-particle con-structions.
In Proceedings of the LREC 2008 Work-shop Towards a Shared Task for Multiword Expres-sions (MWE 2008), pages 1?2, Marrakech.John Blitzer, Amir Globerson, and Fernando Pereira.2005.
Distributed latent variable models of lexicalco-occurrences.
In Tenth International Workshop onArtificial Intelligence and Statistics.Kenneth W. Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicog-raphy.
Computational Linguistics, 16(1):22?29.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Computational Lin-guistics, 19(1):61?74.Stefan Evert.
2007.
Corpora and collocations.
Ex-tended Manuscript of Chapter 58 of A. Lu?deling andM.
Kyto?, 2008, Corpus Linguistics.
An InternationalHandbook, Mouton de Gruyter, Berlin.Stefan Evert.
2008.
A lexicographic evaluation of Ger-man adjective-noun collocations.
In Proceedings ofthe LREC 2008 Workshop Towards a Shared Taskfor Multiword Expressions (MWE 2008), pages 3?6,Marrakech.Thomas Hofmann and Jan Puzicha.
1998.
Statisti-cal models for co-occurrence data.
Technical report,MIT.
AI Memo 1625, CBCL Memo 159.Brigitte Krenn and Stefan Evert.
2001.
Can we dobetter than frequency?
a case study on extracting PP-verb collocations.
In Proceedings of the ACL Work-shop on Collocations, Toulouse.Brigitte Krenn.
2008.
Description of evaluation re-source ?
German PP-verb data.
In Proceedings ofthe LREC 2008 Workshop Towards a Shared Taskfor Multiword Expressions (MWE 2008), pages 7?10, Marrakech.Chris Manning and Hinrich Schu?tze.
1999.
Foun-dations of Statistical Natural Language Processing.MIT Press, Cambridge, MA.Pavel Pecina.
2008.
A machine learning approach tomultiword expression extraction.
In Proceedings ofthe LREC 2008 Workshop Towards a Shared Taskfor Multiword Expressions (MWE 2008), pages 54?57, Marrakech.Mats Rooth, Stefan Riester, Detlef Prescher, Glenn Car-rol, and Franz Beil.
1999.
Inducing a semanticallyannotated lexicon via em-based clustering.
In Pro-ceedings of the 37th Annual Meeting of the Associ-ation for Computational Linguistics, College Park,MD.Lawrence Saul and Fernando Pereira.
1997.
Aggre-gate and mixed-order markov models for statisticallanguage processing.
In Proceedings of the SecondConference on Empirical Methods in Natural Lan-guage Processing, pages 81?89.Noah A. Smith and Jason Eisner.
2004.
Anneal-ing techniques for unsupervised statistical languagelearning.
In Proceedings of the 42nd Annual Meet-ing of the Association for Computational Linguis-tics.114
