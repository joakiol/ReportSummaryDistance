Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 666?674,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsMIX Is Not a Tree-Adjoining LanguageMakoto KanazawaNational Institute of Informatics2?1?2 Hitotsubashi, Chiyoda-kuTokyo, 101?8430, Japankanazawa@nii.ac.jpSylvain SalvatiINRIA Bordeaux Sud-Ouest, LaBRI351, Cours de la Libe?rationF-33405 Talence Cedex, Francesylvain.salvati@labri.frAbstractThe language MIX consists of all strings overthe three-letter alphabet {a, b, c} that containan equal number of occurrences of each letter.We prove Joshi?s (1985) conjecture that MIXis not a tree-adjoining language.1 IntroductionThe languageMIX = {w ?
{a, b, c}?
| |w|a = |w|b = |w|c }has attracted considerable attention in computationallinguistics.1 This language was used by Bach (1981)in an exercise to show that the permutation closureof a context-free language is not necessarily context-free.2 MIX may be considered a prototypical exam-ple of free word order language, but, as remarked byBach (1981), it seems that no human language ?hassuch complete freedom for order?, because ?typi-cally, certain constituents act as ?boundary domains?for scrambling?.
Joshi (1985) refers to MIX as rep-resenting ?an extreme case of the degree of freeword order permitted in a language?, which is ?lin-guistically not relevant?.
Gazdar (1988) adopts asimilar position regarding the relation between MIX1If w is a string and d is a symbol, we write |w|d to mean thenumber of occurrences of d in w. We will use the notation |w| todenote the length of w, i.e., the total number of occurrences ofsymbols in w.2According to Gazdar (1988), ?MIX was originally de-scribed by Emmon Bach and was so-dubbed by students inthe 1983 Hampshire College Summer Studies in Mathematics?.According to Bach (1988), the name MIX was ?the happy in-vention of Bill Marsh?.and natural languages, noting that ?it seems ratherunlikely that any natural language will turn out tohave a MIX-like characteristic?.It therefore seems natural to assume that lan-guages such as MIX should be excluded from anyclass of formal languages that purports to be a tightformal characterization of the possible natural lan-guages.
It was in this spirit that Joshi et al (1991)suggested that MIX should not be in the class of so-called mildly context-sensitive languages:?
[mildly context-sensitive grammars] cap-ture only certain kinds of dependencies,e.g., nested dependencies and certain lim-ited kinds of cross-serial dependencies(for example, in the subordinate clauseconstructions in Dutch or some variationsof them, but perhaps not in the so-calledMIX (or Bach) language) .
.
.
.
?Mild context-sensitivity is an informally defined no-tion first introduced by Joshi (1985); it consists ofthe three conditions of limited cross-serial depen-dencies, constant growth, and polynomial parsing.The first condition is only vaguely formulated, butthe other two conditions are clearly satisfied by tree-adjoining grammars.
The suggestion of Joshi et al(1991) was that MIX should be regarded as a vio-lation of the condition of limited cross-serial depen-dencies.Joshi (1985) conjectured rather strongly that MIXis not a tree-adjoining language: ?TAGs cannot gen-erate this language, although for TAGs the proof isnot in hand yet?.
An even stronger conjecture wasmade by Marsh (1985), namely, that MIX is not an666indexed language.3 (It is known that the indexedlanguages properly include the tree-adjoining lan-guages.)
Joshi et al (1991), however, expressed amore pessimistic view about the conjecture:?It is not known whether TAG .
.
.
cangenerate MIX.
This has turned out to bea very difficult problem.
In fact, it isnot even known whether an IG [(indexedgrammar)] can generate MIX.
?This open question has become all the more press-ing after a recent result by Salvati (2011).
This re-sult says that MIX is in the class of multiple context-free languages (Seki et al, 1991), or equivalently,languages of linear context-free rewriting systems(Vijay-Shanker et al, 1987; Weir, 1988), which hasbeen customarily regarded as a formal counterpartof the informal notion of a mildly context-sensitivelanguage.4 It means that either we have to aban-don the identification of multiple context-free lan-guages with mildly context-sensitive languages, orwe should revise our conception of limited cross-serial dependencies and stop regarding MIX-likelanguages as violations of this condition.
Surely, theresolution of Joshi?s (1985) conjecture should cru-cially affect the choice between these two alterna-tives.In this paper, we prove that MIX is not a tree-adjoining language.
Our proof is cast in terms of theformalism of head grammar (Pollard, 1984; Roach,1987), which is known to be equivalent to TAG(Vijay-Shanker and Weir, 1994).
The key to ourproof is the notion of an n-decomposition of a stringover {a, b, c}, which is similar to the notion of aderivation in head grammars, but independent of anyparticular grammar.
The parameter n indicates howunbalanced the occurrence counts of the three let-ters can be at any point in a decomposition.
We first3The relation of MIX with indexed languages is also of in-terest in combinatorial group theory.
Gilman (2005) remarksthat ?it does not .
.
.
seem to be known whether or not theword problem of Z ?
Z is indexed?, alluding to the languageO2 = {w ?
{a, a?, b, b?}?
| |w|a = |w|a?, |w|b = |w|b?
}.
Since O2 andMIX are rationally equivalent, O2 is indexed if and only if MIXis indexed (Salvati, 2011).4Joshi et al (1991) presented linear context-free rewritingsystems as mildly context-sensitive grammars.
Groenink (1997)wrote ?The class of mildly context-sensitive languages seems tobe most adequately approached by LCFRS.
?show that if MIX is generated by some head gram-mar, then there is an n such that every string in MIXhas an n-decomposition.
We then prove that if everystring in MIX has an n-decomposition, then everystring in MIX must have a 2-decomposition.
Finally,we exhibit a particular string in MIX that has no 2-decomposition.
The length of this string is 87, andthe fact that it has no 2-decomposition was first ver-ified by a computer program accompanying this pa-per.
We include here a rigorous, mathematical proofof this fact not relying on the computer verification.2 Head GrammarsA head grammar is a quadruple G = (N,?, P, S),where N is a finite set of nonterminals, ?
is a fi-nite set of terminal symbols (alphabet), S is a distin-guished element of N, and P is a finite set of rules.Each nonterminal is interpreted as a binary predicateon strings in ??.
There are four types of rules:A(x1x2y1, y2)?
B(x1, x2),C(y1, y2)A(x1, x2y1y2)?
B(x1, x2),C(y1, y2)A(x1y1, y2x2)?
B(x1, x2),C(y1, y2)A(w1,w2)?Here, A, B,C ?
N, x1, x2, y1, y2 are variables, andw1,w2 ?
?
?
{?
}.5 Rules of the first three types arebinary rules and rules of the last type are terminat-ing rules.
This definition of a head grammar actu-ally corresponds to a normal form for head gram-mars that appears in section 3.3 of Vijay-Shankerand Weir?s (1994) paper.6The rules of head grammars are interpreted as im-plications from right to left, where variables can beinstantiated to any terminal strings.
Each binary5We use ?
to denote the empty string.6This normal form is also mentioned in chapter 5, section 4of Kracht?s (2003) book.
The notation we use to express rulesof head grammars is borrowed from elementary formal sys-tems (Smullyan, 1961; Arikawa et al, 1992), also known asliteral movement grammars (Groenink, 1997; Kracht, 2003),which are logic programs over strings.
In Vijay-Shanker andWeir?s (1994) notation, the four rules are expressed as follows:A?
C2,2(B,C)A?
C1,2(B,C)A?
W(B,C)A?
C1,1(w1 ?
w2)667rule involves an operation that combines two pairsof strings to form a new pair.
The operation in-volved in the third rule is known as wrapping; theoperations involved in the first two rules we call leftconcatenation and right concatenation, respectively.If G = (N,?, P, S) is a head grammar, A ?
N, andw1,w2 ?
?
?, then we say that a fact A(w1,w2) isderivable and write `G A(w1,w2), if A(w1,w2) canbe inferred using the rules in P. More formally, wehave `G A(w1,w2) if one of the following conditionsholds:?
A(w1,w2)?
is a terminating rule in P.?
`G B(u1, u2), `G C(v1, v2), and there is a bi-nary rule A(?1, ?2) ?
B(x1, x2),C(y1, y2) inP such that (w1,w2) is the result of substitut-ing u1, u2, v1, v2 for x1, x2, y1, y2, respectively,in (?1, ?2).The language of G isL(G) = {w1w2 | `G S(w1,w2) }.Example 1.
Let G = (N,?, P, S), where N ={S, A, A?,C,D, E, F}, ?
= {a, a?, #}, and P consists ofthe following rules:S(x1y1, y2x2)?
D(x1, x2),C(y1, y2)C(?, #)?D(?, ?
)?D(x1y1, y2x2)?
F(x1, x2),D(y1, y2)F(x1y1, y2x2)?
A(x1, x2), E(y1, y2)A(a, a) ?E(x1y1, y2x2)?
D(x1, x2), A?
(y1, y2)A?
(a?, a?
)?We have L(G) = {w#wR | w ?
D{a,a?}
}, where D{a,a?
}is the Dyck language over {a, a?}
and wR is the re-versal of w. All binary rules of this grammar arewrapping rules.If `G A(w1,w2), a derivation tree for A(w1,w2) isa finite binary tree whose nodes are labeled by factsthat are derived during the derivation of A(w1,w2).A derivation tree for A(w1,w2) represents a ?proof?of `G A(w1,w2), and is formally defined as follows:?
If A(w1,w2)?
is a terminating rule, then a treewith a single node labeled by A(w1,w2) is aderivation tree for A(w1,w2).S(aaa?a?aa?, #a?aa?a?aa)D(aaa?a?aa?, a?aa?a?aa)F(aaa?a?, a?a?aa)A(a, a) E(aa?a?, a?a?a)D(aa?, a?a)F(aa?, a?a)A(a, a) E(a?, a?
)D(?, ?)
A?
(a?, a?
)D(?, ?)A?
(a?, a?
)D(aa?, a?a)F(aa?, a?a)A(a, a) E(a?, a?
)D(?, ?)
A?
(a?, a?
)D(?, ?
)C(?, #)Figure 1: An example of a derivation tree of a head gram-mar.?
If `G A(w1,w2) is derived from `G B(u1, u2)and `G C(v1, v2) by some binary rule, then abinary tree whose root is labeled by A(w1,w2)and whose immediate left (right) subtree is aderivation tree for B(u1, u2) (for C(v1, v2), re-spectively) is a derivation tree for A(w1,w2).If w ?
L(G), a derivation tree for w is a derivationtree for some S(w1,w2) such that w1w2 = w.Example 1 (continued).
Figure 1 shows a derivationtree for aaa?a?aa?#a?aa?a?aa.The following lemma should be intuitively clearfrom the definition of a derivation tree:Lemma 1.
Let G = (N,?, P, S) be a head grammarand A be a nonterminal in N. Suppose that w ?L(G) has a derivation tree in which a fact A(v1, v2)appears as a label of a node.
Then there are stringsz0, z1, z2 with the following properties:(i) w = z0v1z1v2z2, and(ii) `G A(u1, u2) implies z0u1z1u2z2 ?
L(G).Proof.
We can prove by straightforward inductionon the height of derivation trees that wheneverA(v1, v2) appears on a node in a derivation tree forB(w1,w2), then there exist z0, z1, z2, z3 that satisfyone of the following conditions:(a) w1 = z0v1z1v2z2, w2 = z3, and `G A(u1, u2)implies `G B(z0u1z1u2z2, z3).
(b) w1 = z0, w2 = z1v1z2v2z3, and `G A(u1, u2)implies `G B(z0, z1u1z2u2z3).668(c) w1 = z0v1z1, w2 = z2v2z3, and `G A(u1, u2)implies `G B(z0u1z1, z2u2z3).We omit the details.
We call a nonterminal A of a head grammarG use-less if A does not appear in any derivation trees forstrings in L(G).
Clearly, useless nonterminals can beeliminated from any head grammar without affectingthe language of the grammar.3 Decompositions of Strings in MIXHenceforth, ?
= {a, b, c}.
Let Z denote the set of in-tegers.
Define functions ?1, ?2 : ??
?
Z, ?
: ??
?Z ?
Z by?1(w) = |w|a ?
|w|c,?2(w) = |w|b ?
|w|c,?
(w) = (?1(w), ?2(w)).Clearly, we have ?
(a) = (1, 0), ?
(b) = (0, 1), ?
(c) =(?1,?1), andw ?
MIX iff ?
(w) = (0, 0).Note that for all strings w1,w2 ?
?
?, ?
(w1w2) =?(w1)+?(w2).
In other words, ?
is a homomorphismfrom the free monoid ??
to Z ?
Z with addition asthe monoid operation and (0, 0) as identity.Lemma 2.
Suppose that G = (N,?, P, S) is a headgrammar without useless nonterminals such thatL(G) ?
MIX.
There exists a function ?G : N ?
Z ?Z such that `G A(u1, u2) implies ?
(u1u2) = ?G(A).Proof.
Since G has no useless nonterminals, foreach nonterminal A of G, there is a derivation treefor some string in L(G) in which A appears in a nodelabel.
By Lemma 1, there are strings z0, z1, z2 suchthat `G A(u1, u2) implies z0u1z1u2z2 ?
L(G).
SinceL(G) ?
MIX, we have ?
(z0u1z1u2z2) = (0, 0), andhence?
(u1u2) = ??(z0z1z2).
A decomposition of w ?
??
is a finite binary treesatisfying the following conditions:?
the root is labeled by some (w1,w2) such thatw = w1w2,?
each internal node whose left and right childrenare labeled by (u1, u2) and (v1, v2), respectively,is labeled by one of (u1u2v1, v2), (u1, u2v1v2),(u1v1, v2u2).?
each leaf node is labeled by some (s1, s2) suchthat s1s2 ?
{b, c}?
?
{a, c}?
?
{a, b}?.Thus, the label of an internal node in a decomposi-tion is obtained from the labels of its children by leftconcatenation, right concatenation, or wrapping.
Itis easy to see that ifG is a head grammar over the al-phabet ?, any derivation for w ?
L(G) induces a de-composition ofw.
(Just strip off nonterminals.)
Notethat unlike with derivation trees, we have placed nobound on the length of a string that may appear ona leaf node of a decomposition.
This will be conve-nient in some of the proofs below.When p and q are integers, we write [p, q] for theset { r ?
Z | p ?
r ?
q }.
We call a decomposition ofw an n-decomposition if each of its nodes is labeledby some (v1, v2) such that ?
(v1v2) ?
[?n, n]?
[?n, n].Lemma 3.
If MIX = L(G) for some head grammarG = (?,N, P, S), then there exists an n such that eachw ?
MIX has an n-decomposition.Proof.
We may suppose without loss of generalitythat G has no useless nonterminal.
Since MIX =L(G), there is a function ?G satisfying the conditionof Lemma 2.
Since the set N of nonterminals of Gis finite, there is an n such that ?G(A) ?
[?n, n] ?
[?n, n] for all A ?
N. Then it is clear that a derivationtree for w ?
L(G) induces an n-decomposition ofw.
If w = d1 .
.
.
dm ?
?m, then for 0 ?
i ?
j ?
m,we write w[i, j] to refer to the substring di+1 .
.
.
djof w. (As a special case, we have w[i, i] = ?.)
Thefollowing is a key lemma in our proof:Lemma 4.
If each w ?
MIX has an n-decomposition, then each w ?
MIX has a 2-decomposition.Proof.
Assume that each w ?
MIX has an n-decomposition.
Define a homomorphism ?n : ??
???
by?n(a) = an,?n(b) = bn,?n(c) = cn.669Clearly, ?n is an injection, and we have ?
(?n(v)) =n ?
?
(v) for all v ?
?
?.Let w ?
MIX with |w| = m. Then w?
= ?n(w) ?MIX and |w?| = mn.
By assumption, w?
has an n-decomposition D. We assign a 4-tuple (i, j, k, l) ofnatural numbers to each node of D in such a waythat (w?
[i, j],w?
[k, l]) equals the label of the node.This is done recursively in an obvious way, start-ing from the root.
If the root is labeled by (w1,w2),then it is assigned (0, |w1|, |w1|, |w1w2|).
If a node isassigned a tuple (i, j, k, l) and has two children la-beled by (u1, u2) and (v1, v2), respectively, then the4-tuples assigned to the children are determined ac-cording to how (u1, u2) and (v1, v2) are combined atthe parent node:u1 u2 v1 v2i j k li + |u1| i + |u1u2|u1 u2 v1 v2i j k lk + |u2| k + |u2v1|u1 v1 v2 u2i j k li + |u1| k + |v2|Now define a function f : [0,mn] ?
{ kn | 0 ?k ?
m } byf (i) =????????????????????????
?i if n divides i,n ?
bi/nc if n does not divide i andw?
[i ?
1, i] ?
{a, b},n ?
di/ne if n does not divide i andw?
[i ?
1, i] = c.Clearly, f is weakly increasing in the sense that i ?
jimplies f (i) ?
f ( j).
LetD?
be the result of replacingthe label of each node inD by(w?
[ f (i), f ( j)],w?
[ f (k), f (l)]),where (i, j, k, l) is the 4-tuple of natural numbers as-signed to that node by the above procedure.
It is easyto see that D?
is another decomposition of w?.
Notethat since each of f (i), f ( j), f (k), f (l) is an integralmultiple of n, we always have(w?
[ f (i), f ( j)],w?
[ f (k), f (l)]) = (?n(u), ?n(v))for some substrings u, v of w. This implies that forh = 1, 2,?h(w?
[ f (i), f ( j)]w?
[ f (k), f (l)])is an integral multiple of n.Claim.
D?
is a 2n-decomposition.We have to show that every node label (v1, v2) in D?satisfies ?
(v1v2) ?
[?2n, 2n] ?
[?2n, 2n].
For h =1, 2, define ?h : [0,mn] ?
[0,mn]?
Z as follows:?h(i, j) =????????h(w?
[i, j]) if i ?
j,??h(w?
[ j, i]) otherwise.Then it is easy to see that for all i, j, i?, j?
?
[0,mn],?h(i?, j?)
= ?h(i?, i) + ?h(i, j) + ?h( j, j?
).Inspecting the definition of the function f , we cancheck that?h( f (i), i) ?
[0, n ?
1]always holds.
Suppose that (i, j, k, l) is assignedto a node in D. By assumption, we have?h(w?
[i, j]w?
[k, l]) ?
[?n, n], and?h(w?
[ f (i), f ( j)]w?
[ f (k), f (l)])= ?h(w?
[ f (i), f ( j)]) + ?h(w?
[ f (k), f (l)])= ?h( f (i), f ( j)) + ?h( f (k), f (l))= ?h( f (i), i) + ?h(i, j) + ?h( j, f ( j))+ ?h( f (k), k) + ?h(k, l) + ?h(l, f (l))= ?h( f (i), i) + ?h(w?
[i, j]) + ?h( j, f ( j))+ ?h( f (k), k) + ?h(w?
[k, l]) + ?h(l, f (l))= ?h(w?
[i, j]w?
[k, l]) + ?h( f (i), i) + ?h( f (k), k)+ ?h( j, f ( j)) + ?h(l, f (l))?
{ p + q1 + q2 + r1 + r2 | p ?
[?n, n],q1, q2 ?
[0, n ?
1], r1, r2 ?
[?n + 1, 0] }= [?3n + 2, 3n ?
2].Since ?h(w?
[ f (i), f ( j)]w?
[ f (k), f (l)]) must be an in-tegral multiple of n, it follows that?h(w?
[ f (i), f ( j)]w?
[ f (k), f (l)]) ?
{?2n,?n, 0, n, 2n}.This establishes the claim.670We have shown that each node ofD?
is labeled bya pair of strings of the form (?n(u), ?n(v)) such that?
(?n(u)?n(v)) ?
{?2n,?n, 0, n, 2n} ?
{?2n,?n, 0, n, 2n}.Now it is easy to see that inverting the homomor-phism ?n at each node of D?
(?n(u), ?n(v)) 7?
(u, v)gives a 2-decomposition of w. 4 A String in MIX That Has No2-DecompositionBy Lemmas 3 and 4, in order to prove that there is nohead grammar for MIX, it suffices to exhibit a stringin MIX that has no 2-decomposition.
The followingis such a string:z = a5b14a19c29b15a5.In this section, we prove that the string z has no 2-decomposition.7It helps to visualize strings in MIX as closedcurves in a plane.
If w is a string in MIX, by plottingthe coordinates of ?
(v) for each prefix v of w, we canrepresent w by a closed curve C together with a mapt : [0, |w|] ?
C. The representation of the string z isgiven in Figure 2.Let us call a string w ?
{a, b, c}?
such that ?
(w) ?
[?2, 2] ?
[?2, 2] long if w contains all three letters,and short otherwise.
(If ?
(w) < [?2, 2] ?
[?2, 2],then w is neither short nor long.)
It is easy to seethat a short string w always satisfies|w|a ?
4, |w|b ?
4, |w|c ?
2.The maximal length of a short string is 6.
(For ex-ample, a4c2 and b4c2 are short strings of length 6.
)We also call a pair of strings (v1, v2) long (or short)if v1v2 is long (or short, respectively).According to the definition of an n-decomposition, a leaf node in a 2-decomposition7This fact was first verified by the computer program ac-companying this paper.
The program, written in C, imple-ments a generic, memoized top-down recognizer for the lan-guage {w ?
MIX | w has a 2-decomposition }, and does not relyon any special properties of the string z.0 519 38678287 a5b14a19c29b15a5Figure 2: Graphical representation of the string z =a5b14a19c29b15a5.
Note that every point (i, j) on the di-agonal segment has i > 7 or j < ?2.must be labeled by a short pair of strings.
We calla 2-decomposition normal if the label of everyinternal node is long.
Clearly, any 2-decompositioncan be turned into a normal 2-decomposition bydeleting all nodes that are descendants of nodeswith short labels.One important property of the string z is the fol-lowing:Lemma 5.
If z = x1vx2 and ?
(v) ?
[?2, 2]?
[?2, 2],then either v or x1x2 is short.Proof.
This is easy to see from the graphical rep-resentation in Figure 2.
If a substring v of z has?
(v) ?
[?2, 2] ?
[?2, 2], then the subcurve corre-sponding to v must have initial and final coordi-nates whose difference lies in [?2, 2] ?
[?2, 2].
Ifv contains all three letters, then it must contain asa substring at least one of ba19c, ac29b, and cb15a.The only way to satisfy both these conditions is tohave the subcurve corresponding to v start and endvery close to the origin, so that x1x2 is short.
(Notethat the distance between the coordinate (5, 0) corre-sponding to position 5 of z and the diagonal segmentcorresponding to the substring c29 is large enoughthat it is impossible for v to start at position 5 andend in the middle of c29 without violating the condi-tion ?
(v) ?
[?2, 2] ?
[?2, 2].)
Lemma 5 leads to the following observation.
Letus call a decomposition of a string concatenation-free if each of its non-leaf labels is the wrapping ofthe labels of the children.671Lemma 6.
If z has a 2-decomposition, then z has anormal, concatenation-free 2-decomposition.Proof.
Let D be a 2-decomposition of z. Withoutloss of generality, we may assume that D is nor-mal.
Suppose that D contains a node ?
whose la-bel is the left or right concatenation of the labelsof its children, (u1, u2) and (v1, v2).
We only con-sider the case of left concatenation since the caseof right concatenation is entirely analogous; so wesuppose that the node ?
is labeled by (u1u2v1, v2).It follows that z = x1u1u2x2 for some x1, x2, andby Lemma 5, either u1u2 or x1x2 is short.
If u1u2is short, then the left child of ?
is a leaf becauseD is normal.
We can replace its label by (u1u2, ?
);the label (u1u2v1, v2) of ?
will now be the wrapping(as well as left concatenation) of the two child la-bels, (u1u2, ?)
and (v1, v2).
If x1x2 is short, then wecan combine by wrapping a single node labeled by(x1, x2) with the subtree ofD rooted at the left childof ?, to obtain a new 2-decomposition of z.
In ei-ther case, the result is a normal 2-decomposition ofz with fewer instances of concatenation.
Repeat-ing this procedure, we eventually obtain a normal,concatenation-free 2-decomposition of z.
Another useful property of the string z is the fol-lowing:Lemma 7.
Suppose that the following conditionshold:(i) z = x1u1v1yv2u2x2,(ii) x1yx2 is a short string, and(iii) both ?
(u1u2) and ?
(v1v2) are in [?2, 2] ?
[?2, 2].Then either (u1, u2) or (v1, v2) is short.Proof.
Suppose (u1, u2) and (v1, v2) are both long.Since (u1, u2) and (v1, v2) must both contain c, eitheru1 ends in c and v1 starts in c, or else v2 ends in cand u2 starts in c.Case 1. u1 ends in c and v1 starts in c. Since(v1, v2) must contain at least one occurrence of a,the string v1yv2 must contain cb15a as a substring.a5b14 a19 c29 b15 a5v1yv2Since x1yx2 is short, we have |y|b ?
4.
It follows that|v1v2|b ?
11.
But v1yv2 is a substring of c28b15a5,so |v1v2|a ?
5.
This clearly contradicts ?
(v1v2) ?
[?2, 2] ?
[?2, 2].Case 2. v2 ends in c and u2 starts in c. In thiscase, cb15a5 is a suffix of u2x2.
Since x1yx2 is short,|x2|a ?
4.
This means that cb15a is a substring of u2and hence |u2|b = 15.a5b14 a19 c29 b15 a5u2 x2v1yv2u1On the other hand, since (v1, v2) must contain at leastone occurrence of b, the string v1yv2 must containba19c as a substring.
This implies that |u1u2|a ?
10.But since |u2|b = 15, we have |u1u2|b ?
15.
Thisclearly contradicts ?
(u1u2) ?
[?2, 2] ?
[?2, 2].
We now assume that z has a normal,concatenation-free 2-decomposition D and de-rive a contradiction.
We do this by followinga certain path in D. Starting from the root, wedescend in D, always choosing a non-leaf child, aslong as there is one.
We show that this path willnever terminate.The i-th node on the path will be denoted by?i, counting the root as the 0-th node.
The la-bel of ?i will be denoted by (wi,1,wi,2).
With eachi, we associate three strings xi,1, yi, xi,2 such thatxi,1wi,1yiwi,2xi,2 = z, analogously to Lemma 1.
Since?
(wi,1wi,2) ?
[?2, 2] ?
[?2, 2] and ?
(z) = (0, 0), wewill always have ?
(xi,1yixi,2) ?
[?2, 2] ?
[?2, 2].Initially, (w0,1,w0,2) is the label of the root ?0 andx0,1 = y0 = x0,2 = ?.
If ?i is not a leaf node, let(ui,1, ui,2) and (vi,1, vi,2) be the labels of the left andright children of ?i, respectively.
If the left childis not a leaf node, we let ?i+1 be the left child,in which case we have (wi+1,1,wi+1,2) = (ui,1, ui,2),xi+1,1 = xi,1, xi+1,2 = xi,2, and yi+1 = vi,1yvi,2.
Oth-erwise, ?i+1 will be the right child of ?i, and wehave (wi+1,1,wi+1,2) = (vi,1, vi,2), xi+1,1 = xi,1ui,1,xi+1,2 = ui,2xi,2, and yi+1 = yi.The path ?0, ?1, ?2, .
.
.
is naturally divided intotwo parts.
The initial part of the path consists ofnodes where xi,1yixi,2 is short.
Note that x0,1y0x0,2 =?
is short.
As long as xi,1yixi,2 is short, (wi,1,wi,2)must be long and ?i has two children labeledby (ui,1, ui,2) and (vi,1, vi,2).
By Lemma 7, either(ui,1, ui,2) or (vi,1, vi,2) must be short.
Since the length672of z is 87 and the length of a short string is at most 6,exactly one of (ui,1, ui,2) and (vi,1, vi,2) must be long.We must eventually enter the second part ofthe path, where xi,1yixi,2 is no longer short.
Let?m be the first node belonging to this part of thepath.
Note that at ?m, we have ?
(xm,1ymxm,2) =?
(xm?1,1ym?1xm?1,2) + ?
(v) for some short string v.(Namely, v = um?1,1um?1,2 or v = vm?1,1vm?1,2.
)Lemma 8.
If u and v are short strings and ?
(uv) ?
[?2, 2]?
[?2, 2], then |uv|d ?
4 for each d ?
{a, b, c}.Proof.
Since u and v are short, we have |u|a ?4, |u|b ?
4, |u|c ?
2 and |v|a ?
4, |v|b ?
4, |v|c ?
2.
Itimmediately follows that |uv|c ?
4.
We distinguishtwo cases.Case 1.
|uv|c ?
2.
Since ?
(uv) ?
[?2, 2] ?
[?2, 2],we must have |uv|a ?
4 and |uv|b ?
4.Case 2.
|uv|c ?
3.
Since |u|c ?
2 and |v|c ?
2,we must have |u|c ?
1 and |v|c ?
1.
Also, ?
(uv) ?
[?2, 2] ?
[?2, 2] implies that |uv|a ?
1 and |uv|b ?
1.Since u and v are short, it follows that one of thefollowing two conditions must hold:(i) |u|a ?
1, |u|b = 0 and |v|a = 0, |v|b ?
1.
(ii) |u|a = 0, |u|b ?
1 and |v|a ?
1, |v|b = 0.In the former case, |uv|a = |u|a ?
4 and |uv|b = |v|b ?4.
In the latter case, |uv|a = |v|a ?
4 and |uv|b =|u|b ?
4.
By Lemma 8, the number of occurrences of eachletter in xm,1ymxm,2 is in [1, 4].
This can only be ifxm,1xm,2 = aj,ym = ckbl,for some j, k, l ?
[1, 4].
This means that the string zmust have been split into two strings (w0,1,w0,2) atthe root of D somewhere in the vicinity of position67 (see Figure 2).It immediately follows that for all i ?
m, wi,1 isa substring of a5b14a19c28 and wi,2 is a substring ofb14a5.
We show by induction that for all i ?
m, thefollowing condition holds:(?)
ba19c17 is a substring of wi,1.The condition (?)
clearly holds for i = m. Now as-sume (?).
Then (wi,1,wi,2) is long, and ?i has left andright children, labeled by (ui,1, ui,2) and (vi,1, vi,2), re-spectively, such that wi,1 = ui,1vi,1 and wi,2 = vi,2ui,2.We consider two cases.Case 1. ui,1 contains c. Then ba19c is a substringof ui,1.
Since ui,2 is a substring of b14a5, it cannotcontain any occurrences of c. Since ?1(ui,1ui,2) ?
[?2, 2], it follows that ui,1 must contain at least 17occurrences of c; hence ba19c17 is a substring of ui,1.Since (ui,1, ui,2) is long, (wi+1,1,wi+1,2) = (ui,1, ui,2).Therefore, the condition (?)
holds with i+ 1 in placeof i.Case 2. ui,1 does not contain c. Then (ui,1, ui,2) isshort and (wi+1,1,wi+1,2) = (vi,1, vi,2).
Note that vi,1must contain at least 17 occurrences of c, but vi,2 isa substring of b14a5 and hence cannot contain morethan 14 occurrences of b.
Since ?2(vi,1vi,2) ?
[?2, 2],it follows that vi,1 must contain at least one occur-rence of b.
Therefore, ba19c17 must be a substringof vi,1 = wi+1,1, which shows that (?)
holds with i+1in place of i.We have proved that (?)
holds for all i ?
m. It fol-lows that for all i, ?i has two children and hence ?i+1is defined.
This means that the path ?0, ?1, ?2, .
.
.is infinite, contradicting the assumption that D is a2-decomposition of z.We have proved the following:Lemma 9.
There is a string in MIX that has no 2-decomposition.Theorem 10.
There is no head grammar G such thatL(G) = MIX.Proof.
Immediate from Lemmas 3, 4, and 9.
ReferencesSetsuo Arikawa, Takeshi Shinohara, and Akihiro Ya-mamoto.
1992.
Learning elementary formal systems.Theoretical Computer Science, 95(1):97?113.Emmon Bach.
1981.
Discontinuous constituents in gen-eralized categorial grammars.
In Victoria Burke andJames Pustejovsky, editors, Proceedings of the 11thAnnual Meeting of the North East Linguistic Society,pages 1?12.Emmon Bach.
1988.
Categorial grammars as theoriesof language.
In Richard T. Oehrle, Emmon Bach, andDeirdre Wheeler, editors, Categorial Grammars andNatural Language Structures, pages 17?34.
D. Reidel,Dordrecht.673Gerald Gazdar.
1988.
Applicability of indexed gram-mars to natural languages.
In U. Reyle and C. Rohrer,editors,Natural Language Parsing and Linguistic The-ories, pages 69?94.
D. Reidel Publishing Company,Dordrecht.Robert Gilman.
2005.
Formal languages and their ap-plication to combinatorial group theory.
In Alexan-dre V. Borovik, editor, Groups, Languages, Algo-rithms, number 378 in Contemporary Mathematics,pages 1?36.
American Mathematical Society, Provi-dence, RI.Annius V. Groenink.
1997.
Mild context-sensitivity andtuple-based generalizations of context-free grammar.Linguistics and Philosophy, 20:607?636.Aravind K. Joshi, Vijay K. Shanker, and David J. Weir.1991.
The converence of mildly context-sensitivegrammar formalisms.
In Peter Sells, Stuart M.Shieber, and ThomasWasow, editors, Foundational Is-sues in Natural Language Processing, pages 31?81.The MIT Press, Cambridge, MA.Aravind K. Joshi.
1985.
Tree-adjoining grammars: Howmuch context sensitivity is required to provide reason-able structural descriptions?
In David Dowty, LauriKarttunen, and Arnold M. Zwicky, editors, NaturalLanguage Parsing, pages 206?250.
Cambridge Uni-versity Press, Cambridge.Markus Kracht.
2003.
The Mathematics of Language,volume 63 of Studies in Generative Grammar.
Mou-ton de Gruyter, Berlin.William Marsh.
1985.
Some conjectures on indexedlanguages.
Paper presented to the Association forSymbolic Logic Meeting, Stanford University, July15?19.
Abstract appears in Journal of SymbolicLogic 51(3):849 (1986).Carl J. Pollard.
1984.
Generalized Phrase StructureGrammars, Head Grammars, and Natural Language.Ph.D.
thesis, Department of Linguistics, Stanford Uni-versity.Kelly Roach.
1987.
Formal properties of head gram-mars.
In Alexis Manaster-Ramer, editor, Mathematicsof Language, pages 293?347.
John Benjamins, Ams-terdam.Sylvain Salvati.
2011.
MIX is a 2-MCFL and the wordproblem in Z2 is captured by the IO and the OI hierar-chies.
Technical report, INRIA.Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context free gram-mars.
Theoretical Computer Science, 88(2):191?229.Raymond M. Smullyan.
1961.
Theory of Formal Sys-tems.
Princeton University Press, Princeton, NJ.K.
Vijay-Shanker and D. J. Weir.
1994.
The equivalenceof four extensions of context-free grammars.
Mathe-matical Systems Theory, 27:511?546.K.
Vijay-Shanker, David J. Weir, and Aravind K. Joshi.1987.
Characterizing structural descriptions producedby various grammatical formalisms.
In 25th AnnualMeeting of the Association for Computational Linguis-tics, pages 104?111.David J. Weir.
1988.
Characterizing Mildly Context-Sensitive Grammar Formalisms.
Ph.D. thesis, Univer-sity of Pennsylvania, Philadephia, PA.674
