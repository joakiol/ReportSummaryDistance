Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 553?563,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSummarization of Multi-Document Topic Hierarchies using SubmodularMixturesRamakrishna B BairiIITB-Monash Research AcademyIIT BombayMumbai, 40076, Indiabairi@cse.iitb.ac.inRishabh IyerUniversity of WashingtonSeattle, WA-98175, USArkiyer@u.washington.eduGanesh RamakrishnanIIT BombayMumbai, 40076, Indiaganesh@cse.iitb.ac.inJeff BilmesUniversity of WashingtonSeattle, WA-98175, USAbilmes@uw.eduAbstractWe study the problem of summarizingDAG-structured topic hierarchies over agiven set of documents.
Example appli-cations include automatically generatingWikipedia disambiguation pages for aset of articles, and generating candidatemulti-labels for preparing machine learn-ing datasets (e.g., for text classification,functional genomics, and image classi-fication).
Unlike previous work, whichfocuses on clustering the set of documentsusing the topic hierarchy as features, wedirectly pose the problem as a submodularoptimization problem on a topic hierarchyusing the documents as features.
Desirableproperties of the chosen topics includedocument coverage, specificity, topicdiversity, and topic homogeneity, each ofwhich, we show, is naturally modeled bya submodular function.
Other information,provided say by unsupervised approachessuch as LDA and its variants, can also beutilized by defining a submodular functionthat expresses coherence between thechosen topics and this information.
We usea large-margin framework to learn convexmixtures over the set of submodularcomponents.
We empirically evaluate ourmethod on the problem of automaticallygenerating Wikipedia disambiguationpages using human generated clusteringsas ground truth.
We find that our frame-work improves upon several baselinesaccording to a variety of standard evalua-tion metrics including the Jaccard Index,F1 score and NMI, and moreover, can bescaled to extremely large scale problems.1 IntroductionSeveral real world machine learning applicationsinvolve hierarchy based categorization of topicsfor a set of objects.
Objects could be, e.g., aset of documents for text classification, a set ofgenes in functional genomics, or a set of imagesin computer vision.
One can often define a naturaltopic hierarchy to categorize these objects.
Forexample, in text and image classification problems,each document or image is assigned a hierarchyof labels ?
a baseball page is assigned the labels?baseball?
and ?sports.?
Moreover, many of theseapplications, naturally have an existing topichierarchy generated on the entire set of objects(Rousu et al, 2006; Barutcuoglu et al, 2006; lingZhang and hua Zhou, 2007; Silla and Freitas, 2011;Tsoumakas et al, 2010).Given a DAG-structured topic hierarchy and asubset of objects, we investigate the problem offinding a subset of DAG-structured topics that areinduced by that subset (of objects).
This problemarises naturally in several real world applications.For example, consider the problem of identifyingappropriate label sets for a collection of articles.Several existing text collection datasets such as 20Newsgroup1, Reuters-215782work with a prede-fined set of topics.
We observe that these topicnames are highly abstract3for the articles catego-rized under them.
On the other hand, techniquesproposed by systems such as Wikipedia Miner(Milne, 2009) and TAGME (Ferragina and Scaiella,2010) generate several labels for each article in thedataset that are highly specific to the article.
Col-lating all labels from all articles to create a label1http://qwone.com/?jason/20Newsgroups/2http://www.daviddlewis.com/resources/testcollections/reuters21578/3Topic Concept is more abstract than the topic Sciencewhich is more abstract than the topicChemistry553... ?
?...
?
?...
?
?...
?
?Populated placeMalus(Eudicot genera,Plants and Pollinators,?
)Cashew Apple (Ediblenuts,Trees of Brazil,?
)Hedge Apple (Trees ofUS, Maclura,..)Apple Corps(Companiesof UK, Companiesestablisted in 1968,?
)Apple Inc(Companiesin California, Companiesestablisted in 1996,Hardware Companies,?
)Apple Bank (Banks inNew Your, Banks ofUSA,?
)The Apple (1980 films,English languagefilms,?
)Apple Albums (1990debut Albums, Englishlanguage albums, Mercuryrecords,?
)Apple Band (Englishrock music groups,Musical groups fromLondon,?
)Apple Records(Scotish music groups)Apple Oklahoma(Unincorporatedcommunities)Apple River (Villagesin Illions)Apple Valley (Citiesin California)Apple Store (Electroniccompanies of Us, Videogame retailers,?
)HP Apple (HPmicroprocessors, HPcalculators)Apple Daily (Nextmedia, Publicationsestablished in 1995)Apple Novel (2007novels, Novels ofEngland, debut novel)Apple Key (Mac OS,Computer keys)Apple Card Game(Point trick games)CompaniesFilmsPlacesTechnologyMusicRootPlantsPlants and PollinatorsEdible NutsTrees of BrazilCompanies of UKBanks in New York1980 filmsApple HardwareHP MicroprocessorsTropical TreesComputer HardwareCompanies by yearFilms by countryOperating SystemsHP ProductsPublicationsBooksApple Computer(Apple hardware,Microelectronics,?)...
?
?...
?
?Trees by countryTrees of USRetail CompaniesCompanies ofCaliforniaCities in CaliforniaAlbums by languageEnglish Albums... ?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?...
?
?
... ?
?...
?
?...
?
?...
?
?...
?
?Documents associated with fine-grained (near leaf level) topicsNovelsTechnologyApple computerApple KeyApple StoreHP ApplePlantsMalusCashew AppleHedge AppleCompaniesApple corpsApple Inc.Apple bankPlacesApple OklahomaApple RiverApple ValleyMusicFilmsThe AppleOtherApple Card gameApple DailyApple NovelApple AlbumsApple BandApple RecordsInput documents on 'Apple' with fine grained(near leaf level) topic assignmentTopic DAGOutput Disambiguation page for 'Apple' withdocuments grouped under summary topics... ?
?Topic... ?
?Summary TopicParent-Child relation Ancestor-Descendant relation Topic-Object associationDocuments notgrouped underany summarytopicDocument NameFine-grained topicsFigure 1: Topic Summarization overview.
On the left, we show many documents related to Apple.
In themiddle, a Wikipedia category hierarchy shown as a topic DAG, links these documents at the leaf level.
Onthe right, we show the output of our summarization process, which creates a set of summary topics (Plants,Technology, Companies, Films, Music and Places in this example) with the input documents classifiedunder them.set for the dataset can result in a large number oflabels and become unmanageable.
Our proposedtechniques can summarize such large sets of labelsinto a smaller and more meaningful label sets usinga DAG-structured topic hierarchy.
This also holdsfor image classification problems and datasets likeImageNet (Deng et al, 2009).
We use the termsummarize to highlight the fact that the smaller la-bel set semantically covers the larger label set.
Forexample, the topics Physics, Chemistry, and Math-ematics can be summarized into a topic Science.A particularly important application of our work(and the one we use for our evaluations in Section 4)is the following: Given a collection of articles span-ning different topics, but with similar titles, auto-matically generate a disambiguation page for thosetitles using the Wikipedia category hierarchy4as atopic DAG.
Disambiguation pages5on Wikipediaare used to resolve conflicts in article titles that oc-cur when a title is naturally associated with multi-ple articles on distinct topics.
Each disambiguationpage organizes articles into several groups, wherethe articles in each group pertain only to a specifictopic.
Disambiguations may be seen as paths in ahierarchy leading to different articles that arguablycould have the same title.
For example, the titleApple6can refer to a plant, a company, a film, a4http://en.wikipedia.org/wiki/Help:Categories5http://en.wikipedia.org/wiki/Wikipedia:Disambiguation6http://en.wikipedia.org/wiki/Apple_(disambiguation)television show, a place, a technology, an album, arecord label, and a newspaper daily.
The problemthen, is to organize the articles into multiple groupswhere each group contains articles of similar nature(topics) and has an appropriately discerned groupheading.
Figure 1 describes the topic summariza-tion process for creation of the disambiguation pagefor ?Apple?.All the above mentioned problems can be mod-eled as the problem of finding the most representa-tive subset of topic nodes from a DAG-Structuredtopic hierarchy.
We argue that many formulationsof this problem are natural instances of submodularmaximization, and provide a learning frameworkto create submodular mixtures to solve this prob-lem.
A set function f (.)
is said to be submodularif for any element v and sets A ?
B ?
V \ {v},where V represents the ground set of elements,f (A ?
{v})?
f (A) ?
f (B ?
{v})?
f (B).
This iscalled the diminishing returns property and states,informally, that adding an element to a smallerset increases the function value more than addingthat element to a larger set.
Submodular func-tions naturally model notions of coverage and di-versity in applications, and therefore, a numberof machine learning problems can be modeled asforms of submodular optimization (Kempe et al,2003; Krause and Guestrin, 2005; Narasimhan andBilmes, 2004; Iyer et al, 2013; Lin and Bilmes,2012; Lin and Bilmes, 2010).
In this paper, weinvestigate structured prediction methods for learn-554ing weighted mixtures of submodular functions tosummarize topics for a collection of objects us-ing DAG-structured topic hierarchies.
Throughoutthis paper we use the terms ?topic?
and ?category?interchangeably.1.1 Related WorkTo the best of our knowledge, the specific problemwe consider here is new.
Previous work on identi-fying topics can be broadly categorized into one ofthe following types: a) cluster the objects and thenidentify names for the clusters; or b) dynamicallyidentify topics (including hierarchical) for a set ofobjects.
LDA (Blei et al, 2003) clusters the docu-ments and simultaneously produces a set of topicsinto which the documents are clustered.
In LDA,each document may be viewed as a mixture of var-ious topics and the topic distribution is assumedto have a Dirichlet prior.
LDA associates a groupof high probability words to each identified topic.A name can be assigned to a topic by manuallyinspecting the words or using additional algorithmslike (Mei et al, 2007; Maiya et al, 2013).
LDAdoes not make use of existing topic hierarchies andcorrelation between topics.
The Correlated TopicModel (Blei and Lafferty, 2006) induces a correla-tion structure between topics by using the logisticnormal distribution instead of the Dirichlet.
An-other extension is the hierarchical LDA (Blei etal., 2004), where topics are joined together in ahierarchy by using the nested Chinese restaurantprocess.
Nonparametric extensions of LDA includethe Hierarchical Dirichlet Process (Teh et al, 2006)mixture model, which allows the number of top-ics to be unbounded and learnt from data and theNested Chinese Restaurant Process which allowstopics to be arranged in a hierarchy whose structureis learnt from data.
In each of these approaches,unlike our proposed approach, an existing topichierarchy is not used, nor is any additional object-topic information leveraged.The pachinko allocation model (PAM)(Li andMcCallum, 2006) captures arbitrary, nested, andpossibly sparse correlations between topics using aDAG.
The leaves of the DAG represent individualwords in the vocabulary, while each interior noderepresents a correlation among its children, whichmay be words or other interior nodes (topics).
PAMlearns the probability distributions of words in atopic, subtopics in a topic, and topics in a document.We cannot, however, generate a subset of topicsfrom a large existing topic DAG that can act assummary topics, using PAM.HSLDA (Perotte et al, 2011) introduces a hierar-chically supervised LDA model to infer hierarchi-cal labels for a document.
It assumes an existinglabel hierarchy in the form of a tree.
The modelinfers one or more labels such that, if a label l isinferred as relevant to a document, then all the la-bels from l to the root of the tree are also inferredas relevant to the document.
Our approach differsfrom HSLDA since: (1) we use the label hierarchyto infer a set of labels for a group of documents; (2)we do not enforce the label hierarchy to be a treeas it can be a DAG; and (3) generalizing HSLDAto use a DAG structured hierarchy and infer labelsfor a group of documents (e.g., combining into onebig document) also may not help in solving ourproblem.
HSLDA will apply all the relevant labelsto the documents as per the classifier that it learnsfor every label.
Moreover, the ?root?
label is al-ways applied and it is very likely that many labelsnear the top level of the label hierarchy are alsoclassified as relevant to the group of documents.Wei and James (Bi and Kwok, 2011) presenta hierarchical multi-label classification algorithmthat can be used on both tree and DAG structuredhierarchies.
They formulate a search for the opti-mal consistent multi-label as the finding of the bestsubgraph in a tree/DAG.
In our approach, we as-sume, individual documents are already associatedwith one or more topics and we find a consistentlabel set for a group of documents using the DAGstructured topic hierarchy.Medelyan et al (Medelyan et al, 2008) andFerragina et al (Ferragina and Scaiella, 2010) de-tect topics for a document using Wikipedia articlenames and category names as the topic vocabulary.These systems are able to extract signals from a textdocument and identify Wikipedia articles and/orcategories that optimally match the document andassign those article/category names as topics for thedocument.
When run on a large collection of docu-ments, these approaches generate enormous num-bers of topics, a problem our proposed approachaddresses.1.2 Our ContributionsWhile most prior work discussed above focuseson the underlying set of documents, (e.g., byclustering documents), we focus directly on thetopics.
In particular, we formulate the problemas subset selection on the set of topics withina DAG while simultaneously considering thedocuments to be categorized.
Our method canscale to the colossal size of the DAG (1 milliontopics and 3 million correlation links betweentopics in Wikipedia).
Moreover, our approach can555naturally incorporate outputs from many of theaforementioned algorithms.
Our approach is basedon submodular maximization and mixture learning,which has been successfully used in applicationssuch as document summarization (Lin, 2012) andimage summarization (Tschiatschek et al, 2014),but has never been applied to topic identificationtasks or, more generally, DAG summarization.We introduce a family of submodular functionsto identify an appropriate set of topics from a DAGstructured hierarchy of topics for a group of docu-ments.
We characterize this topic appropriatenessthrough a set of desirable properties such as cov-erage, diversity, specificity, clarity, and relevance.Each of the submodular function components weconsider are monotone, thereby ensuring a near op-timal performance obtainable via a simple greedyalgorithm for optimization.7.
We also show howour technique naturally embodies outputs of otheralgorithms such as LDA, clustering, and classifi-cations.
Finally, we utilize a large margin formu-lation for learning mixtures of these submodularfunctions, and show how we can optimally learnthem from training data.Our approach demonstrates how to utilize thefeatures collectively in the document space and thetopic space to infer a set of topics.
From an em-pirical perspective, we introduce and evaluate ourapproach on a dataset of around 8000 disambigua-tions that was extracted from Wikipedia and subse-quently cleaned using the methods described in theexperimentation section.
We show that our learn-ing framework outperforms many of the baselines,and is practical enough to be used on large corpora.2 Problem FormulationLetG (V,E) be the DAG structured topic hierarchywith V topics.
These topics are observed to have aparent child (isa) relationship forming a DAG.
LetD be the set of documents that are associated withone or more of these topics.
The middle portionof Figure 1 depicts a topic hierarchy with associ-ated documents.
The association links between thedocuments and topics can be hard or soft.
In caseof a hard link, a document is attached to a set oftopics.
Examples include multi-labeled documents.In case of a soft link, a document is associated witha topic with some degree of confidence (or prob-ability).
Furthermore, if a document is attachedto a topic t, we assume that all the ancestor top-ics of t are also relevant for that document.
This7A simple greedy algorithm (Nemhauser et al, 1978) ob-tains a 1 ?
1/e approximation guarantee for monotone sub-modular function maximizationassumption has been employed in earlier works(Blei et al, 2004; Bi and Kwok, 2011; Rousu etal., 2006) as well.
Given a budget of K, our objec-tive is to choose a set of K topics from V , whichbest describe the documents in D. The notion ofbest describing topics is characterized through a setof desirable properties - coverage, diversity, speci-ficity, clarity, relevance and fidelity - that K topicshave to satisfy.
The submodular functions that weintroduce in the next section ensure these proper-ties are satisfied.
Formally, we solve the followingdiscrete optimization problem:S??
argmaxS?V :|S|?K?iwifi(S) (1)where, fiare monotone submodular mixture com-ponents andwi?
0 are the weights associated withthose mixture components.
Set S?is the summarytopics scored best.It is easy to find massive (i.e., size in the order ofmillion) DAG structured topic hierarchies in prac-tice.
Wikipedia?s category hierarchy consists ofmore than 1M categories (topics) arranged hierar-chically.
In fact, they form a cyclic graph (Zeschand Gurevych, 2007).
However, we can convert itto a DAG by eliminating the cycles as describedin the supplementary material.
YAGO (Suchaneket al, 2007) and Freebase (Bollacker et al, 2008)are other instances of massive topic hierarchies.The association of the documents with the existingtopic hierarchy is also well studied.
Systems suchas WikipediaMiner (Milne, 2009), TAGME (Fer-ragina and Scaiella, 2010) and several annotationsystems such as (Dill et al, 2003; Mihalcea andCsomai, 2007; Bunescu and Pasca, 2006) attachtopics from Wikipedia (and other catalogs) to thedocuments by establishing the hard or soft linksmentioned above.Our goal is the following: Given a (ground set)collection V of topics organized in a pre-existinghierarchical DAG structure, and a collection D ofdocuments, chose a size K ?
Z+representativesubset of topics.
Our approach is distinct fromearlier work (e.g., (Kanungo et al, 2002; Blei etal., 2003)) where typically only a set of documentsis classified and categorized in some way.
We nextprovide a few definitions needed later in the paper.Definition 1: Transitive Cover ?
): A topic t issaid to cover a set of documents ?
(t), called thetransitive cover of the topic t, if for all documentsi ?
?
(t), either i is associated directly with topict or with any of the descendant topics of t in thetopic DAG.
A natural extension of this definition toa set of topics T is defined as ?
(T ) = ?t?T?
(t).556Definition 2: Truncated Transitive Cover (??
):This is a transitive cover of topic t, but with thelimitation that the path length between a docu-ment and the topic t is not more than ?.
Hence,|??
(t)| ?
|?
(t)|.While our problem is closely related to cluster-ing approaches, which consider the set of docu-ments directly, there are some crucial differences.In particular, we focus on producing a clustering ofdocuments where clusters are encouraged to honora pre-defined DAG structured topic hierarchy.
Ex-isting agglomerative clustering algorithms focusingon the coverage of documents may not produce thedesired clustering.
To understand this, consider sixdocuments d1, d2 .
.
.
d6 to be grouped into threeclusters.
There may be multiple ways to do this de-pending upon multiple aggregation paths present inthe topic DAG: ((d1, d2), (d3, d4), (d5, d6)) or ((d1,d2, d3), (d4, d5), (d6)) or ((d1, d2, d3, d4), (d5),(d6)) or something else.
Hence, we need morestringent measures to prefer one clustering overthe others.
Our work addresses this with a varietyof quality criteria (coverage, diversity, specificity,clarity, relevance and fidelity, which are explainedlater in this paper) that are organically derived fromwell established submodular functions.
And, mostimportantly, we learn the right mixture of thesequalities to be enforced from the data itself.
Fur-thermore, our approach also generalizes these clus-tering approaches, since one of the components inour mixture of submodular functions is defined viathese unsupervised approaches, and maps a givenclustering to a set of topics in the hierarchy.3 Submodular Components andLearningSummarization is the task of extracting informationfrom a source that is both small in size but stillrepresentative.
Our problem is different fromtraditional summarization tasks since we have anunderlying DAG as a topic hierarchy that we wishto summarize in response to a subset of documents.Thus, a critical part of our problem is to take thegraph structure into account while creating thesummaries.
Below, we identify properties we wishour summaries to posses.Coverage: A summary set of topics shouldcover most of the documents.
A document is saidto be covered by a topic if there exists a path fromthe topic, going through intermediary descendanttopics, to the document, i.e., the document is withinthe transitive cover of the topic.Diversity: Summaries should be as diverse aspossible, i.e., each summary topic should covera unique set of documents.
When a document iscovered by more than one topic, that document isredundantly covered, e.g., ?Finance?
and ?Banking?would be unlikely members of the same summary.Summary qualities also involve ?quality?notions, including:Specificity/Clarity/Relevance/Coherence:These quality measures help us choose a set oftopics that are neither too abstract nor overlyspecific.
They ensure that the topics are clearand relevant to the documents that they represent.When additional information such as clustering(from LDA or other sources) and tagging (manual)documents is available, these quality criteriaencourage the chosen topics to show resemblance(coherence) to those clustering/tagging in terms oftransitive cover of documents they produce.In the below, we define a variety of submodularfunctions that capture the above properties, and wethen describe a large margin learning frameworkfor learning convex mixtures of such components.3.1 Submodular Components3.1.1 Coverage Based FunctionsCoverage components capture ?coverage?
of a setof documents.Weighted Set Cover Function: Given a set ofcategories, S ?
V , define ?
(S) as the set of docu-ments covered ?
for each topic s ?
S, ?
(s) ?
Drepresents the documents covered by topic s and?
(S) = ?s?S?(s).
The weighted set cover func-tion, defined as f(S) =?d??
(S)wd= w(?
(S)),assigns weights to the documents based ontheir relative importance (e.g., in Wikipediadisambiguation, the different documents could beranked based on their priority).Feature-based Functions: This class offunction represents coverage in feature space.Given a set of categories S ?
V , and a set offeatures U , define mu(S) as the score associatedwith the set of categories S for feature u ?
U .The feature set could represent, for example, thedocuments, in which case mu(S) represents thenumber of times document u is covered by theset S. U could also represent more complicatedfeatures.
For example, in the context of Wikipediadisambiguation, U could represent TFIDF featuresover the documents.
Feature based are thendefined as f(S) =?u?U?
(mu(S)), where ?
isa concave (e.g., the square root) function.
Thisfunction class has been successfully used in severalapplications (Kirchhoff and Bilmes, 2014; Wei etal., 2014a; Wei et al, 2014b).5573.1.2 Similarity based FunctionsSimilarity functions are defined through a simi-larity matrix S = {sij}i,j?V.
Given categoriesi, j ?
V , similarity sijin our case can be definedas sij= |?(i)??
(j)|, i.e the number of documentscommonly covered by both i and j.Facility Location: The facility location func-tion, defined as f(S) =?i?Vmaxj?Ssij, is anatural model for k-medoids and exemplar basedclustering, and has been used in several summariza-tion problems (Tschiatschek et al, 2014; Wei et al,2014a).Penalty based diversity: A similarity ma-trix may be used to express a form of coverageof a set S but that is then penalized with a re-dundancy term, as in the following difference:f(S) =?i?V,j?Ssij?
?
?i?S?j?S,si,j(Linand Bilmes, 2011)).
Here ?
?
[0, 1].
This functionis submodular, but is not in general monotone, andhas been used in document summarization (Lin andBilmes, 2011), as a dispersion function (Borodinet al, 2012), and in image summarization (Tschi-atschek et al, 2014).3.1.3 Quality Control (QC) FunctionsQC functions ensure a quality criteria is met by aset S of topics.
We define the quality score of theset S as Fq(S) =?s?Sfq(s), where fq(s) isthe quality score of topic s for quality q. Therefore,Fq(S) is a modular function in S. We investigatethree types of quality control functions: TopicSpecificity, Topic Clarity, and Topic Relevance.Topic Specificity: The farther a topic is fromthe root of the DAG, the more specific it becomes.Topics higher up in the hierarchy are abstract andless specific.
We therefore prefer topics low in theDAG, but lower topics also have less coverage.
Wedefine fspecificity(s) = shwhere shis the height oftopic s in the DAG.
The root topic has height zeroand the ?height?
increases as we move down theDAG in Figure 1.Topic Clarity: Topic clarity is the fraction ofdescendant topics that cover one or more docu-ments.
If a topic has many descendant topics thatdo not cover any documents, it has less clarity.
For-mally, fclarity(s) =?t?descendants(s)J?
(t)>0K|descendants(s)|, where JKis the indicator function.Topic Relevance: A topic is considered to bebetter related to a document if the number of hopsneeded to reach the document from that topic islower.
Given any set A ?
D of document, andany topic s ?
V , we can define frelevance(s|A) =argmin?{?
: A ?
??
(s)}.QC Functions As Barrier Modular Mixtures:We introduce a modular function for every QCfunction as followsf?specificity(s) ={1 if the height of topic s is at least ?0 otherwisefor every possible value of ?.
This creates a sub-modular mixture with as many components as thenumber of possible values of ?.
In our experimentswith Wikipedia, we had ?
varying from 1 to 120stepping by 1, adding 120 modular mixture compo-nents.
Similarly, we define,f?clarity(s) ={1 if the clarity of topic s is at least ?0 otherwisefor every possible (discretized to make it count-ably finite) value of ?.
And,f?relevance(s) = fcov(s|??
(s)), where fcov() isthe coverage submodular function and s|X indi-cates coverage of a topic s over a set of documentsX .
All these functions (modular and submodularterms) are added as mixture components in ourlearning framework to learn suitable weights forthem.
We then use these weights in our inferenceprocedure to obtain a subset of topics as describedin 3.2.
We show from our experiments that thisapproach performs better than all other approachesand baselines.3.1.4 Fidelity FunctionsA function representing the fidelity of a set S toanother reference setR is one that gets a large valuewhen the set S represents the setR.
Such a functionscores inferred topics high when it resembles areference set of topics and/or item clusters.
Thereference set in this case can be produced fromother algorithms such as k-means, LDA and itsvariants or from a manually tagged corpus.
Nextwe describe one such fidelity function.Topic Coherence: This function scores a setof topics S high when the transitive cover (Def-inition 1) produced by the topics in S resemblesthe clusters of documents produced by an externalsource (k-means, LDA or manual).
Given an exter-nal source that clusters the documents, producing Tclusters L1, L2, ..., LT(for T topics), topic coher-ence is defined as: f(S) =?t?Tmaxk?Swk,twhere wk,t= harmonic mean(wpk,t, wrk,t) andwpk,t=|?(k)?Lt||?
(k)|and wrk,t=|?(k)?Lt||Lt|.
Note that,wpk,t?
0 and wrk,t?
0 are the precision on recallof the resemblance and wk,tis the F1 measure.
Ifthe transitive cover of topics in S resembles thereference clusters Ltexactly, we attain maximumcoherence (or fidelity).
As the resemblance dimin-ishes, the score decreases.
The above function f(S)is monotone submodular.5583.1.5 Mixture of Submodular Components:Given the different classes of submodular functionsabove, we construct our submodular scoring func-tions Fw(?)
as a convex combinations of these dif-ferent submodular functions f1, f2, .
.
.
, fm, above.In other words,Fw(S) =m?i=1wifi(S), (2)where w = (w1, .
.
.
, wm), wi?
0,?iwi= 1.The components fiare submodular and assumed tobe normalized: i.e., fi(?)
= 0, and fi(V ) = 1 formonotone functions and maxA?Vfi(A) ?
1 fornon-monotone functions.
A simple way to normal-ize a monotone submodular function is to definethe component as fi(S)/fi(V ).
This ensures thatthe components are compatible with each other.Obviously, the merit of the scoring function Fw(?
)depends on the selection of the components.3.2 Large Margin LearningWe optimize the weights w of the scoring func-tion Fw(?)
in a large-margin structured predictionframework.
In this setting, we assume we havetraining data in the form of pairs of a set of docu-ments, and a human generated summary as a setof topics.
For example, in the case of Wikipediadisambiguation, we use the human generated dis-ambiguation pages as the ground truth summary.We represent the set of ground-truth summaries asS = {S1, S2, ?
?
?
, SN}.
In large margin training,the weights are optimized such that ground-truthsummaries S are separated from competitor sum-maries by a loss-dependent margin:Fw(S) ?
Fw(S?)
+ L(S?
), ?S ?
S, S??
Y \ S, (3)where L(?)
is the loss function, and where Yis a structured output space (for example Yis the set of summaries that satisfy a certainbudget B, i.e., Y = {S??
V : |S?| ?
B}).We assume the loss to be normalized,0 ?
L(S?)
?
1, ?S??
V , to ensure that mixtureand loss are calibrated.
Equation (3) can be statedas Fw(S) ?
maxS??Y[Fw(S?)
+ L(S?)]
,?S ?
Swhich is called loss-augmented inference.
Weintroduce slack variables and minimize theregularized sum of slacks (Lin and Bilmes, 2012):minw?0,?w?1=1?S?S[maxS??Y[Fw(S?)
+ L(S?)]?
Fw(S)]+?2?w?22, (4)where the non-negative orthant constraint, w ?
0,ensures that the final mixture is submodular.
Notea 2-norm regularizer is used on top of a 1-normconstraint ?w?1= 1 which we interpret as a priorto encourage higher entropy, and thus more diversemixture distributions.
Tractability depends on thechoice of the loss function.
The parameters ware learnt using stochastic gradient descent as in(Tschiatschek et al, 2014).3.3 Loss FunctionsA natural choice of loss functions for our case canbe derived from cluster evaluation metrics.
Everyinferred topic s induces a subset of documents,namely the transitive cover ?
(s) of s. We comparethese clusters with the clusters induced from thetrue topics in the training set and compute the loss.In this paper, we use the Jaccard Index (JI) as aloss function.
Let S be the inferred topics and Tbe the true topics.
The Jaccard loss is defined asLjaccard(S, T ) = 1 ?1k?s?Smaxt?T|?(s)??(t)||?(s)??
(t)|,where k = |S| = |T | is the number of topics.When the clustering produced by the inferred andthe true topics are similar, Jaccard loss is 0.
Whenthey are completely dissimilar, the loss is maxi-mum, i.e., 1.
Jaccard loss is a modular function.3.4 Inference Algorithm: GreedyHaving learnt the weights for the mixturecomponents, the resulting function Fw(S) =?mi=1wifi(S) is a submodular function.
In thecase when the individual components are them-selves monotone (all our functions in fact are),Fw(S) can be optimized by the accelerated greedyalgorithm (Minoux, 1978).
Thanks to submodu-larity, we can obtain near optimal solutions veryefficiently.
In case the functions are all monotonesubmodular, we can guarantee that the solution iswithin 1?
1/e factor from the optimal solution.4 Experimental ResultsTo validate our approach, we make use ofWikipedia category structure as a topic DAG andapply our technique to the task of automaticgeneration of Wikipedia disambiguation pages.We pre-processed the category graph to elimi-nate the cycles in order to make it a DAG.
EachWikipedia disambiguation page is manually createdby Wikipedia editors by grouping a collection ofWikipedia articles into several groups.
Each groupis then assigned a name, which serves as a topic forthe group.
Typically, a disambiguation page segre-gates around 20-30 articles into 5-6 groups.
Ourgoal is to measure how accurately we can recre-ate the groups for a disambiguation page and labelthem, given only the collection of articles men-tioned in that disambiguation page (when actualgroupings and labels are hidden).5594.1 DatasetsWe parsed the contents of Wikipedia disambigua-tion pages and extracted disambiguation pagenames, article groups and group names.
We col-lected about 8000 disambiguation pages that hadat least four groups on them.
Wikipedia categorystructure is used as the topic DAG.
We eliminatedfew administrative categories such as ?Hidden Cat-egories?, ?Articles needing cleanup?, and the like.The final DAG had about 1M topics and 3M links.4.2 Evaluation MetricsEvery group of articles on the Wikipedia disam-biguation page is assigned a name by the editors.Unfortunately, these names may not correspond tothe Wikipedia category (topic) names.
For exam-ple, one of the groups on the ?Matrix?
disambigua-tion page has a name ?Business and government?and there is no Wikipedia category by that name.However, the group names generated by our (andbaseline) method are from the Wikipedia categories(which forms our topic DAG).
In addition, therecan be multiple relevant names for a group.
Forexample, a group on a disambiguation page maybe called ?Calculus?, but an algorithm may rightlygenerate ?Vector Calculus?.
Hence we cannot eval-uate the accuracy of an algorithm just by matchingthe generated group names to those on the disam-biguation page.
To alleviate this problem, we adoptcluster-based evaluation metrics.
We treat everygroup of articles generated by an algorithm under atopic for a disambiguation page as a cluster of arti-cles.
These are considered as inferred clusters for adisambiguation page.
We compare them against theactual grouping of articles on the Wikipedia disam-biguation page by treating those groups as true clus-ters.
We can now adopt Jaccard Index, F1-measure,and NMI (Normalized Mutual Information) basedcluster evaluation metrics described in (Manninget al, 2008).
For each disambiguation page in thetest set, we compute every metric score and thenaverage it over all the disambiguation pages.4.3 Methods ComparedWe validated our approach by comparing againstseveral baselines described below.
We also com-pared two variations of our approach as describednext.
For each of these cases (baselines and twovariations) we generated and compared the metrics(Jaccard Index, F1-measure and NMI) as describedin the previous section.KMdocs: K-Means algorithm run on articles asTF-IDF vectors of words.
The number of clus-ters K is set to the number of true clusters on theWikipedia disambiguation page.KMeddocs: K-Medoids algorithm with articlesas TF-IDF vectors of words.
The number of clus-ters are set as in KMdocs.KMedtopics: K-Medoids run on topics as TF-IDF vectors of words.
The words for each topicis taken from the articles that are in the transitivecover of the topic.LDAdocs: LDA algorithm with the number oftopics set to the number of true clusters on theWikipedia disambiguation page.
Each article isthen grouped under the highest probability topic.SMMLcov: This is the submodular mixturelearning case explained in section 3.1.5.
Here weconsider a mixture of all the submodular functionsgoverning coverage, diversity, fidelity and QC func-tions.
However, we exclude the similarity basedfunctions described in section 3.1.2.
Coveragebased functions have a time complexity of O (n)whereas similarity based functions are O(n2).
Byexcluding similarity based functions, we can com-pare the quality of the results with and withoutO(n2) functions.
We learn the mixture weightsfrom the training set and use them during infer-ence on the test set to subset K topics through thesubmodular maximization (Equation 1).SMMLcov+sim: This case is similar to SMMLcovexcept that, we include similarity based submodu-lar mixture components.
This makes the inferencetime complexity O(n2).We do not compare against HSLDA, PAM andfew other techniques cited in the related work sec-tions because they do not produce a subset of Ksummary topics ?
these are not directly compara-ble with our work.4.4 Evaluation ResultsWe show that the submodular mixture learningand maximization approaches, i.e., SMMLcovandSMMLcov+simoutperform other approaches in vari-ous metrics.
In all these experiments, we performed5 fold cross validation to learn the parameters from80% of the disambiguation pages and evaluated onthe rest of the 20%, in each fold.In Figure 2a we summarize the results of thecomparison of the methods mentioned above onJaccard Index, F1 measure and NMI.
Our pro-posed techniques SMMLcovand SMMLcov+simout-perform other techniques consistently.In Figures 2b and 2c we measure the numberof test instances (i.e., disambiguation queries) inwhich each of the algorithms dominate (win) inevaluation metrics.
In 60% of the disambiguationqueries, SMMLcovand SMMLcov+simapproaches56000.10.20.30.40.50.60.7JIF1NMIJI/F1/NMI(a) Comparingmetricswithbaselines010203040506070JIF1NMIWin%(b) Winning percentages ofSMML covagainstother methods010203040506070JIF1NMIWin%(c) Winning percentages ofSMML cov+simagainstother methodsKMdocsKMed docsKMed topicsLDAdocsSMML covSMML cov+simFigure 2: Comparison of techniquesproduce higher JI, F1 and NMI than all other meth-ods.
This indicates that the clusters of articles pro-duced by our technique resembles the clusters ofarticles present on the disambiguation page betterthan other techniques.From Figures 2b and 2c it is clear thatO (n) timecomplexity based submodular mixture functions(SMMLcov) perform on par with O(n2)basedfunctions (SMMLcov+sim), but at a greatly reducedexecution time, demonstrating the sufficiency ofO (n) functions for our task.
On the average, foreach disambiguation query, SMMLcovtook around40 seconds (over 1M topics and 3M edges DAG) toinfer the topics, whereas SMMLcov+simtook around35 minutes.
Both these experiments were carriedon a machine with 32 GB RAM, Eight-Core AMDOpteron(tm) Processor 2427.5 ConclusionsWe investigated a problem of summarizing topicsover a massive topic DAG such that the summaryset of topics produced represents the objects inthe collection.
This representation is characterizedthrough various classes of submodular (and mono-tone) functions that captured coverage, similarity,diversity, specificity, clarity, relevance and fidelityof the topics.
Currently we assume that the numberof topics K is given as an input to our algorithm.
Itwould be an interesting future problem to estimatethe value of K automatically in our setting.
As fu-ture work, we also plan to extend our techniques toproduce a hierarchical summary of topics and scaleit across heterogeneous collection of objects (fromdifferent domains) to bring all of them under thesame topic DAG and investigate interesting casesthereon.Acknowledgements: This material is basedupon work supported by the National Science Foun-dation under Grant No.
IIS-1162606, and by aGoogle, a Microsoft, and an Intel research award.Rishabh Iyer acknowledges support from the Mi-crosoft Research Ph.D Fellowship.ReferencesZafer Barutcuoglu, Robert E. Schapire, and Olga G.Troyanskaya.
2006.
Hierarchical multi-label pre-diction of gene function.
Bioinformatics, 22(7):830?836, April.W.
Bi and J. T. Kwok.
2011.
Multi-label classificationon tree-and DAG-structured hierarchies.
In ICML.ICML.561David M. Blei and John D. Lafferty.
2006.
Correlatedtopic models.
In In Proceedings of the 23rd Interna-tional Conference on Machine Learning, pages 113?120.
MIT Press.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
J. Mach.
Learn.Res., 3:993?1022, March.David M. Blei, Thomas L. Griffiths, Michael I. Jordan,and Joshua B. Tenenbaum.
2004.
Hierarchical topicmodels and the nested chinese restaurant process.
InAdvances in Neural Information Processing Systems,page 2003.
MIT Press.Kurt Bollacker, Colin Evans, Praveen Paritosh, TimSturge, and Jamie Taylor.
2008.
Freebase: Acollaboratively created graph database for structur-ing human knowledge.
In Proceedings of the 2008ACM SIGMOD International Conference on Man-agement of Data, SIGMOD ?08, pages 1247?1250,New York, NY, USA.
ACM.Allan Borodin, Hyun Chul Lee, and Yuli Ye.
2012.Max-sum diversification, monotone submodularfunctions and dynamic updates.
In Proceedingsof Principles of Database Systems, pages 155?166.ACM.Razvan Bunescu and Marius Pasca.
2006.
Using en-cyclopedic knowledge for named entity disambigua-tion.
In Proceedings of the 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics (EACL-06), Trento, Italy, pages 9?16, April.Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,and Li Fei-Fei.
2009.
Imagenet: A large-scale hi-erarchical image database.
In Computer Vision andPattern Recognition, 2009.
CVPR 2009.
IEEE Con-ference on, pages 248?255.
IEEE.Stephen Dill, Nadav Eiron, David Gibson, DanielGruhl, R. Guha, Anant Jhingran, Tapas Kanungo,Sridhar Rajagopalan, Andrew Tomkins, John A.Tomlin, and Jason Y. Zien.
2003.
Semtag andseeker: Bootstrapping the semantic web via auto-mated semantic annotation.
In Proceedings of the12th International Conference on World Wide Web,WWW ?03, pages 178?186, New York, NY, USA.ACM.Paolo Ferragina and Ugo Scaiella.
2010.
Tagme:On-the-fly annotation of short text fragments (bywikipedia entities).
In Proceedings of the 19thACM International Conference on Information andKnowledge Management, CIKM ?10, pages 1625?1628, New York, NY, USA.R.
Iyer, S. Jegelka, and J. Bilmes.
2013.
Fastsemidifferential-based submodular function opti-mization.
ICML.Tapas Kanungo, David M. Mount, Nathan S. Ne-tanyahu, Christine D. Piatko, Ruth Silverman, An-gela Y. Wu, Senior Member, and Senior Mem-ber.
2002.
An efficient k-means clustering algo-rithm: Analysis and implementation.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence,24:881?892.D.
Kempe, J. Kleinberg, and E. Tardos.
2003.
Maxi-mizing the spread of influence through a social net-work.
In SIGKDD.Katrin Kirchhoff and Jeff Bilmes.
2014.
Submodular-ity for data selection in machine translation.
Octo-ber.A.
Krause and C. Guestrin.
2005.
Near-optimal non-myopic value of information in graphical models.In Proceedings of Uncertainity in Artificial Intelli-gence.
UAI.Wei Li and Andrew McCallum.
2006.
Pachinko allo-cation: Dag-structured mixture models of topic cor-relations.
In Proceedings of the 23rd InternationalConference on Machine Learning, ICML ?06, pages577?584, New York, NY, USA.
ACM.H.
Lin and J. Bilmes.
2010.
Multi-document summa-rization via budgeted maximization of submodularfunctions.
In NAACL.Hui Lin and Jeff Bilmes.
2011.
A class of submodularfunctions for document summarization.
In The 49thMeeting of the Assoc.
for Comp.
Ling.
Human Lang.Technologies (ACL/HLT-2011), Portland, OR, June.H.
Lin and J. Bilmes.
2012.
Learning mixtures of sub-modular shells with application to document summa-rization.
In Conference on Uncertainty in ArtificialIntelligence (UAI), page 479490.Hui Lin.
2012.
Submodularity in Natural LanguageProcessing: Algorithms and Applications.
Ph.D.thesis, University of Washington, Dept.
of EE.Min ling Zhang and Zhi hua Zhou.
2007.
Ml-knn: Alazy learning approach to multi-label learning.
PAT-TERN RECOGNITION, 40:2007.Arun S. Maiya, John P. Thompson, Francisco Loaiza-Lemos, and Robert M. Rolfe.
2013.
Exploratoryanalysis of highly heterogeneous document collec-tions.
In Proceedings of the 19th ACM SIGKDDInternational Conference on Knowledge Discoveryand Data Mining, KDD ?13, pages 1375?1383, NewYork, NY, USA.
ACM.Christopher D. Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York,NY, USA.Olena Medelyan, Ian H. Witten, and David Milne.2008.
Topic indexing with Wikipedia.
In Proceed-ings of the Wikipedia and AI workshop at AAAI-08.AAAI.562Qiaozhu Mei, Xuehua Shen, and ChengXiang Zhai.2007.
Automatic labeling of multinomial topic mod-els.
In Proceedings of the 13th ACM SIGKDD Inter-national Conference on Knowledge Discovery andData Mining, KDD ?07, pages 490?499, New York,NY, USA.
ACM.Rada Mihalcea and Andras Csomai.
2007.
Wikify!
:Linking documents to encyclopedic knowledge.
InProceedings of the Sixteenth ACM Conference onConference on Information and Knowledge Manage-ment, CIKM ?07, pages 233?242, New York, NY,USA.
ACM.David Milne.
2009.
An open-source toolkit for min-ing wikipedia.
In In Proc.
New Zealand ComputerScience Research Student Conf, page 2009.Michel Minoux.
1978.
Accelerated greedy algo-rithms for maximizing submodular set functions.
InJ.
Stoer, editor, Optimization Techniques, volume 7of Lecture Notes in Control and Information Sci-ences, chapter 27, pages 234?243.
Springer BerlinHeidelberg, Berlin/Heidelberg.Mukund Narasimhan and Jeff Bilmes.
2004.
PAC-learning bounded tree-width graphical models.
InUncertainty in Artificial Intelligence: Proceedingsof the Twentieth Conference (UAI-2004).
MorganKaufmann Publishers, July.George L Nemhauser, Laurence A Wolsey, and Mar-shall L Fisher.
1978.
An analysis of approximationsfor maximizing submodular set functionsi.
Mathe-matical Programming, 14(1):265?294.Adler J. Perotte, Frank Wood, Noemie Elhadad, andNicholas Bartlett.
2011.
Hierarchically supervisedlatent dirichlet alocation.
In John Shawe-Taylor,Richard S. Zemel, Peter L. Bartlett, Fernando C. N.Pereira, and Kilian Q. Weinberger, editors, NIPS,pages 2609?2617.Juho Rousu, Craig Saunders, Sndor Szedmk, and JohnShawe-Taylor.
2006.
Kernel-based learning of hier-archical multilabel classification models.
Journal ofMachine Learning Research, 7:1601?1626.Jr.
Silla, CarlosN.
and AlexA.
Freitas.
2011.
A surveyof hierarchical classification across different applica-tion domains.
Data Mining and Knowledge Discov-ery, 22(1-2):31?72.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: A core of semantic knowl-edge.
In Proceedings of the 16th International Con-ference on World Wide Web, WWW ?07, pages 697?706, New York, NY, USA.
ACM.Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, andDavid M. Blei.
2006.
Hierarchical dirichlet pro-cesses.
Journal of the American Statistical Associ-ation, 101(476):1566?1581.Sebastian Tschiatschek, Rishabh Iyer, Hoachen Wei,and Jeff Bilmes.
2014.
Learning Mixtures of Sub-modular Functions for Image Collection Summariza-tion.
In Neural Information Processing Systems(NIPS).Grigorios Tsoumakas, Ioannis Katakis, and IoannisVlahavas.
2010.
Mining multi-label data.
In OdedMaimon and Lior Rokach, editors, Data Mining andKnowledge Discovery Handbook, pages 667?685.Springer US.Kai Wei, Rishabh Iyer, and Jeff Bilmes.
2014a.
Fastmulti-stage submodular maximization.
In ICML.Kai Wei, Yuzong Liu, Katrin Kirchhoff, Chris Bartels,and Jeff Bilmes.
2014b.
Submodular subset selec-tion for large-scale speech training data.
Proceed-ings of ICASSP, Florence, Italy.Torsten Zesch and Iryna Gurevych.
2007.
Analy-sis of the wikipedia category graph for nlp applica-tions.
In Proceedings of the TextGraphs-2 Workshop(NAACL-HLT), pages 1?8, Rochester, April.
Associ-ation for Computational Linguistics.563
