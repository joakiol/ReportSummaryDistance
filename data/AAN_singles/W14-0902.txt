Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLfL) @ EACL 2014, pages 11?16,Gothenburg, Sweden, April 27, 2014.c?2014 Association for Computational LinguisticsComputational analysis to explore authors?
depiction of charactersJoseph BullardDept.
of Computer ScienceRochester Institute of Technologyjtb4478@cs.rit.eduCecilia Ovesdotter AlmDept.
of EnglishRochester Institute of Technologycoagla@rit.eduAbstractThis study involves automatically identi-fying the sociolinguistic characteristics offictional characters in plays by analyz-ing their written ?speech?.
We discussthree binary classification problems: pre-dicting the characters?
gender (male vs.female), age (young vs. old), and socio-economic standing (upper-middle class vs.lower class).
The text corpus used isan annotated collection of August Strind-berg and Henrik Ibsen plays, translatedinto English, which are in the public do-main.
These playwrights were chosen fortheir known attention to relevant socio-economic issues in their work.
Linguis-tic and textual cues are extracted from thecharacters?
lines (turns) for modeling pur-poses.
We report on the dataset as wellas the performance and important featureswhen predicting each of the sociolinguis-tic characteristics, comparing intra- andinter-author testing.1 IntroductionA speech community has sociolinguistic proper-ties.
Social variables influencing verbal inter-action include, for example, geographical back-ground, gender, age, ethnicity, and class.
Writ-ers and playwrights, in turn, use their knowledgeof social verbal markers to generate credible andcompelling characters.
The focus of this study isthe creation of an annotated dataset and computa-tional model for predicting the social-biographicalaspects of fictional characters based on featuresof their written ?speech?
in dramatic plays.
Theplays used here are authored by August Strind-berg and Henrik Ibsen, two Scandinavian play-wrights known for creating characters and storiesthat acted as social commentary and were contro-versial when they were first written.
These authorsare also recognized for their contributions in shap-ing modern drama.
Their attention to social issuesmakes these plays and characters highly relevantin constructing such a model to shed light on howthese authors?
translated texts portray social vari-ables.
Interlocutors?
social attributes (such as theirgender, age, social class, and ethnicity) are knownto correlate with language behavior, and they tapinto dimensions of language behavior that are ofcentral interest to the humanities.
For instance,anecdotal evidence suggests that large-scale cor-pus analysis can show how society collectively as-cribes certain roles to male versus female referentsin text (cf.
Lindquist, 2009).Studying these authors and texts from the pointof view of corpus-oriented computational soci-olinguistics can also help us examine the authors?differences in production, descriptively.
This isuseful as a complementary approach to the moretraditional close reading methodology common inliterary research, through which their texts areusually approached.
On a broader scale, the studycan contribute valuable insights to a theory of lin-guistic text criticism.
These authors are part of aglobal literary canon, and their plays are arguablymore often performed in translation than in theirScandinavian originals.
Accordingly, we focus onanalyzing texts translated into English.We focus on sociolinguistic characteristics thatare assigned to each character and that can bedescribed as translating into three binary classifi-cation problems: predicting the characters?
gen-der (male vs. female), age (young vs. old), andsocioeconomic standing or class (upper-middleclass vs. lower class).
The text corpus isannotated by assigning each of the charactersthat match specified criteria a value in each ofthe characteristics.
We do this at the charac-ter level, joining all dialogic lines of a charac-ter into one instance.
The work was accom-plished through the use of computational tools11for natural language processing, including Python(http://www.python.org/), the Natural LanguageToolkit (http://www.nltk.org/) for part of the pre-processing, and the scikit-learn machinelearning library for the computational modeling.Translated texts that reside in the public do-main were collected from the Gutenberg Archive(http://www.gutenburg.org/wiki/Main Page/).2 Previous WorkA pilot study by Hota et al.
(2006) on automaticgender identification in Shakespeare?s texts, aswell as a few primarily gender-oriented studiessurveyed in Garera and Yarowsky (2009), have setthe stage for further inquiry.
The latter study ex-panded on previous work by exploring three at-tributes: gender, age, and native/non-native speak-ers.
There have been previous avenues of re-search into categorizing speakers based on differ-ent individual sociolinguistic factors.
However,not many studies have attempted this categoriza-tion with fictional characters.
Literary texts arecomplex, reflecting authors?
decision-making andcreative processes.
From the perspective of digi-tal humanities, such a focus complements compu-tational sociolinguistic modeling of contemporaryuser-generated text types (such as emails, or blogs(Rosenthal and McKeown, 2011)).
As Lindquist(2009) points out, social data for interlocutors isless often attached to openly available linguisticcorpora, and interest is strong in developing cor-pus methods to help explore social language be-havior (see Lindquist (2009) and Baker (2010)).Previous investigation into social dimensions oflanguage has established strong links between lan-guage and social attributes of speech communi-ties (for an overview, see Mesthrie et al.
(2009)).However, such inquiry has generally had a firmfoundation in field-based research and has usuallyfocused on one or just a few linguistic variables(such as how the pronunciation of certain soundsaligns with social stratification (Labov, 1972)).Moreover, previous scholarship has chiefly fo-cused on the spoken rather than the written mode.Garera and Yarowsky (2009) and Boulis and Os-tendorf (2005) take into account the interlocutors?speech for analysis.
In contrast, we experimentwith the challenge of using only sociolinguisti-cally relevant knowledge coded in the text of char-acters?
lines.
Thus, our approach is more simi-lar to Hota et al.
?s (2006) work on Shakespeare.The characters?
lines do not include the metadataneeded for considering spoken features, since usu-ally these are added at the discretion of the per-former.
This may make our problem more chal-lenging, since some of these indicators may bereliable for identifying gender, such as backchan-nel responses and affirmations from females, andassertively ?holding the floor?
with filled pausesfrom males (Boulis and Ostendorf, 2005).
More-over, there are prosodic features that clearly dif-fer between males and females due to physicalcharacteristics (e.g.
F0, predominant for pitch per-ception).
We do not take advantage of acous-tic/prosodic cues in this work.
Our text is alsoartificial discourse, as opposed to natural speech;therefore these characters?
lines may rather ex-press how writers choose to convey sociolinguisticattributes of their characters.In terms of features, we have explored observa-tions from previous studies.
For instance, com-mon lexical items have been shown successful,with males tending to use more obscenities, espe-cially when talking to other males (Boulis and Os-tendorf, 2005), and females tending to use morethird-person pronouns.
Phrases also tended to bemore useful than unigrams, though whether thecommonly-used words tend to be content-bearingremains a question according to Boulis and Os-tendorf (2005).
Tackling another form of text,Kao and Jurafksy (2012) examined the statisti-cal properties of 20th century acknowledged ver-sus amateur poets in terms of style and contentsubstance, finding, for example, that lexical afflu-ence and properties coherent with imagism, as anaesthetic theorized ideal, distinguished contempo-rary professionals?
poetics, while sound phenom-ena played a lesser role, and amateurs preferredthe use of more explicit negative vocabulary thanprofessionals.
In our study, we focus on data col-lection, corpus analysis, and exploratory experi-mentation with classification algorithms.3 DataThe texts used were freely available transcriptionsfrom the Gutenberg Archive.
English transla-tions of public-domain plays by August Strindbergand Henrik Ibsen were collected from the archive,from various translators and years of release.
Asnoted above, these plays are often performed inEnglish, and we assume that the translations willconvey relevant linguistic cues, as influenced by12Strindberg Ibsen Total# of plays 11 12 23# of characters 65 93 158# of lines 6555 12306 18861Table 1: Distribution of plays, characters, andlines between Strindberg and Ibsen in the dataset.Character Gender Age ClassChristine Female Young UpperJean Male Young LowerMiss Julia Female Young LowerTable 2: Example annotations from Miss Julia.authors, as well as translators.
We assume thatthe translators intended to replicate as closely aspossible the voice of the original author, as this isgenerally the function of literary translation, butwe recognize the potential for loss of information.The texts were minimally pre-processed (suchas removing licensing and introduction text), leav-ing only the written lines-to-be-spoken of the char-acters.
Each character?s lines were automaticallyextracted and aggregated using a Python script.Characters should have a significant number oflines (equal to or greater than fifteen in his or herrespective play) to be considered.1We also recordmetadata per character, such as the play title, theplay translator, and the URL of the original playtext on Gutenberg.
The basic characteristics of theresulting dataset are shown in Table 1.In terms of annotation, characters from eachplay were annotated by a third party and assignedcharacteristics primarily according to the plot de-scriptions on Wikipedia of their respective plays oforigin.
The characteristics considered were gen-der (male vs. female), age (young vs. old), and so-cioeconomic standing or class (upper-middle classvs.
lower class).
For example, for age, characterswith children are considered old, and those chil-dren are considered young.
A childless characterwhose peers have children or who has experiencedlife-changing events typically associated with age(e.g.
widows/widowers) is also old, unless sepa-rately noted otherwise.
The gender annotationswere validated by a project-independent person1The only exception to this rule is Mrs. X from Strind-berg?s The Stronger.
She has only 11 separate ?lines?, butalso has the only speaking part for the entire play, which is asingle act of substantial length.
We also note that while an adhoc threshold for lines was used, future work could exploreprincipled ways to set it.Attribute Annotation Strindberg IbsenGender Male / Female 42 / 23 61 / 32Age Old / Young 46 / 19 61 / 32Class Upper / Lower 57 / 8 83 / 10Table 3: Character attribute distributions for gen-der, age, and class for each author.in Scandinavia (Swedish native speaker) based onher knowledge of Scandinavian naming conven-tions.
Example character annotations for Strind-berg?s well-known naturalistic play Miss Julia (orMiss Julie) are shown in Table 2.
As seen in Table3, the imbalance of class labels presents the great-est problem for our model.
Baselines of 88% and89% upper class for Strindberg and Ibsen, respec-tively, indicate that there may be less informationto be extracted for class.4 ModelsHere we describe the design and performance ofcomputational models for predicting a character?sgender, age, and class for Strindberg and Ibsen,yielding six models in total.
Logistic regression,implemented in Python with the scikit-learnmachine learning library (Pedregosa et al., 2011),is used for all classification models.4.1 Feature ExtractionMany features were examined, some inspiredby previous analyses in the literature, such astype-token ratio, subordinate clauses, and wh-questions, as well as some exploratory features,such as honorific terms of address.
A full listof the features examined is shown in Table 4.All features were automatically extracted usingPython.
We use honorifics here to mean com-mon formal terms of address during the time pe-riod (sir, madam, lord, Mr., Mrs., etc.).
It seemsintuitive that such terms may be used differentlybased on class or possibly age (e.g.
lower classusing more higher terms of address when speakingto their superiors).
We use family words to meananything that indicates a familial relationship (fa-ther, daughter, nephew, etc.).
The use of suchwords may be affected by gender roles (Hota et al.,2006).
Part-of-speech tagging was accomplishedusing the Natural Language Toolkit (NLTK) (Birdet al., 2009).13Linguistic featuresFamily wordsHonorificsPronouns 1stPronouns 2ndPronouns 3rdPronouns allWh- questionsType-token ratioDeterminersAdjectivesPrepositionsFor/withModalsPersonal pronounsNouns singularNouns pluralVerbs pastVerbs past part.Verbs sing.
pres.
non-3rdMean line lengthNumber of lines% short lines (?5 words)Table 4: List of linguistic features examined forthe models.
All features, with the exception of thelast three in the right column, were measured onceas raw counts and once as the fraction of the over-all words for a given character.4.2 Cross-Author ValidationWe compared translations of Strindberg and Ib-sen?s use of language to convey sociolinguisticattributes.
This was done for each of the threeattributes of interest (gender, age, and class) bytraining one model for each author, then using it toclassify the other author?s characters.
We accom-plish this by defining a cross-author validationprocedure, a variation of the standard k-fold cross-validation procedure in which the trained model ineach fold is used to predict both its own test setand the test set of the other author.
This proce-dure is explained visually in Figure 1.
The pro-cedure is especially interesting as these two au-thors were contemporaries and dealt with topics ofsocial commentary in their works, although fromtheir own perspectives.The results of cross-author validation are shownin Table 5 as a matrix where the row is the au-thor used for training, the column is the authorused for testing, and the value inside a cell isthe average accuracy over all iterations of cross-author validation.
Majority class baselines are alsoshown.
As expected, the models for each author?stexts were better at predicting themselves than theother author, with a couple of exceptions.
Forage, the Strindberg-trained model was still able toimprove on Ibsen?s baseline, but not vice versa.One possible explanation could be that commonfeatures between their depictions of age might bemore useful for one author than the other.
An-other interesting exception is in the class modelsTestTestISTrainTrainFigure 1: Example of one fold of cross-authorvalidation for Strindberg (S) and Ibsen (I).
Ar-rows indicate testing.
Each author has its own 5-fold cross-validation, but in each fold, the trainedmodel is tested on both its own test set and the testset of the other author.Gender Age ClassS I S I S IStrindberg (S) 68 60 74 70 89 90Ibsen (I) 61 67 70 74 91 90Baseline 65 66 71 66 88 89Table 5: Results of cross-author validation (seeFigure 1).
Rows are the author used for training,columns are the author used for testing, and thevalue in the cell is the average accuracy over 500iterations of 5-fold cross-validation.
Accuraciesabove majority class baselines are shown in bold.for both authors, which performed slightly abovehigh baselines for the opposite authors as well astheir own.
While class improvements are recog-nizably marginal (and not claimed to be signifi-cant), these results might indicate that the two au-thors?
translated texts are using similar character-istics to convey social class of their characters.
It isimportant to note that the baselines for class wereextremely high, making prediction of this attributemore difficult.
At least in the intra-author testing,the gender and age models were generally able toimprove accuracy over their respective baselinesmore so than the class models, with age being thebest overall.4.3 Comparison of Useful FeaturesSince the experimentation used a linear model(logistic regression), we can inspect the coeffi-cients/weights of a trained classifier to determinewhich features contributed particularly to the clas-sification.
The absolute value of a coefficient in-dicates how influential its feature is, and the sign(+/-) of the coefficient indicates which class thefeature is associated with.
During cross-author14Strindberg IbsenGender Pronouns 3rdHonorificsDeterminersFemaleFemaleMalePronouns 3rdFamily wordsModalsFemaleFemaleMaleAge Nouns singularFamily wordsModalsOldYoungYoungFamily wordsVerbs sing.
pres.
non-3rdPrepositionsYoungYoungOldClass For/withVerbs past part.HonorificsLowerUpperLowerFor/withHonorificsNouns singularLowerLowerLowerTable 6: Most useful features for gender, age, and class for each author, determined by examining thecoefficients of classifiers that performed above baseline during cross-author testing.
The pairs in thetable consist of a linguistic feature and the label indicated by more frequent use of that feature (e.g.
forStrindberg, third-person pronoun usage contributed to predicting gender, with greater usage indicating afemale character).
Features marked in bold are shared between authors for a given attribute.validation, if the trained classifier for a given foldperformed above the baseline of its own test set,then we record its three most heavily weighted fea-tures.
At the end, we have a tally of which fea-tures most often appeared in the top three featuresfor such better-performing classifiers.
We can usethis to compare which features were more consis-tently involved for each author and attribute pair,as shown in Table 6.Some of the useful features are more intuitivethan others.
For example, as mentioned in anearlier section, it seems reasonable that familywords may relate to depictions of gender rolesof the time period in which the plays were writ-ten, with women being expected to take on so-cial roles more confined to the home.
This ap-pears to be true for Ibsen, but not for Strindberg.We also see family words suggesting young char-acters for both authors?
texts.
It seems intuitivethat authors may have chosen to depict children asspending more time around family members, in-cluding using family terminology as terms of ad-dress.
The use of honorifics is also as predictedearlier in the paper: lower class characters usemore higher terms of address, presumably wheninteracting with their superiors.
Another inter-esting result is the frequency of third-person pro-nouns being the most useful predictor of gender,indicating female characters for both authors.
Pos-sibly, women may have spoken more about otherpeople than men did in these texts.Some other results are not as easy to explain.For example, the use of the prepositions for andwith was consistently the most useful predictor oflower class characters (which could explain whythe models performed comparably on opposite au-thors in Table 5).
An interesting result was themore frequent use of singular, present tense, non-third person verbs among young characters in theIbsen texts.
This suggests that young charactersused more verbs centered around I and you in thepresent tense.
One possible explanation is thatchildren were depicted as being more involved intheir own personal world, speaking less about peo-ple they were not directly interacting with in agiven moment.5 ConclusionWe have presented a dataset of translated plays byAugust Strindberg and Henrik Ibsen, along withcomputational models for predicting the sociolin-guistic attributes of gender, age, and social classof characters using the aggregation of their tex-tual lines-to-be-spoken.
We compared the per-formance and important features of the models inboth intra- and inter-author testing using a cross-author validation procedure, finding that modelsgenerally performed above challenging baselinesfor their own authors, but less so for the other,as one would expect.
The exception was the so-cial class variable, which was consistently slightlyabove baseline regardless of the author used fortesting.
While this could indicate that the trans-lated Strindberg and Ibsen texts conveyed socialclass using similar linguistic cues, this remains atopic for future exploration, given the class im-balance for that attribute.
We also examine someindicative features for each attribute and authorpair, identifying similarities and differences be-15tween the depictions in each set of texts.
This anal-ysis supported the trends seen in the cross-authortesting.Future work would include exploring other au-thors and literary genres, or extending the scopeto non-literary domains.
When expanding thisinitial work to larger datasets, there is an op-portunity to better understand the intricacies ofperformance through other metrics (e.g.
preci-sion, recall).
There is certainly much opportu-nity to expand sociolinguistic features on fictionaltexts and to explore other potentially simpler ormore advanced modeling frameworks.
Alterna-tives for assigning annotation of sociolinguisticvariables, such as socioeconomic standing, alsodeserve further attention.
Additionally, it wouldbe interesting to verify the preservation of linguis-tic/sociolinguistic cues in translation by repeatingthis work using different translations of the sametexts.AcknowledgementsWe thank the Swedish Institute (http://eng.si.se)for partially supporting this work.
We also thankthe reviewers for valuable comments that wereconsidered in the revision of this paper.ReferencesPaul Baker.
2010.
Sociolinguistics and Corpus Lin-guistics.
Edinburgh University Press, Edinburgh.Steven Bird, Ewan Klein, and Edward Loper.
2009.Natural Language Processing with Python ?
An-alyzing Text with the Natural Language Toolkit.O?Reilly Media, Sebastopol.Constantinos Boulis and Mari Ostendorf.
2005.
Aquantitative analysis of lexical differences betweengenders in telephone conversations.
In Proceedingsof the 43rd Annual Meeting of the ACL, pages 435?442, Ann Arbor, MI, USA, June.Nikesh Garera and David Yarowsky.
2009.
Modelinglatent biographic attributes in conversational genres.In Proceedings of the 47th Annual Meeting of theACL and 4th IJCNLP of the AFNLP, pages 719?718,Suntec, Singapore, August.Sobhan Raj Hota, Shlomo Argamon, and RebeccaChung.
2006.
Gender in Shakespeare: Automaticstylistics gender character classification using syn-tactic, lexical and lemma features.
In Digital Hu-manities and Computer Science (DHCS 2006).Justine Kao and Dan Jurafsky.
2012.
A computationalanalysis of style, affect, and imagery in contempo-rary poetry.
In Workshop on Computational Linguis-tics for Literature, pages 8?17, Montr?eal, Canada,June 8.William Labov.
1972.
Sociolinguistic Patterns.
Uni-versity of Pennsylvania Press, Philadelphia, PA.Hans Lindquist.
2009.
Corpus Linguistics and the De-scription of English.
Edinburgh University Press,Edinburgh.Rajend Mesthrie, Joan Swann, Anna Deumert, andWilliam Leap.
2009.
Introducing Sociolinguistics(2nd ed.).
Jon Benjamins, Amsterdam.Fabian Pedregosa, Gael Varoquaux, Alexandre Gram-fort, Vincent Michel, Bertrand Thirion, OlivierGrisel, Mathieu Blondel, Peter Prettenhofer, RonWeiss, Vincent Dubourg, Jake Vanderplas, Alexan-dre Passos, David Cournapeau, Matthieu Brucher,Matthieu Perrot, and Edouard Duchesnay.
2011.Scikit-learn: Machine learning in Python.
Journalof Machine Learning Research, 12:2825?2830.Sara Rosenthal and Kathleen McKeown.
2011.
Ageprediction in blogs: A study of style, content, andonline behavior in pre- and post-social media gen-erations.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics, pages 763?772, Portland, Oregon, June 19-24.16
