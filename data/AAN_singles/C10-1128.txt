Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1137?1145,Beijing, August 2010Towards a Unified Approach to Simultaneous Single-Document andMulti-Document SummarizationsXiaojun WanInstitute of Compute Science and TechnologyThe MOE Key Laboratory of Computational LinguisticsPeking Universitywanxiaojun@icst.pku.edu.cnAbstractSingle-document summarization and multi-document summarization are very closely re-lated tasks and they have been widely investi-gated independently.
This paper examinesthe mutual influences between the two tasksand proposes a novel unified approach to si-multaneous single-document and multi-document summarizations.
The mutual influ-ences between the two tasks are incorporatedinto a graph model and the ranking scores of asentence for the two tasks can be obtained ina unified ranking process.
Experimental re-sults on the benchmark DUC datasets demon-strate the effectiveness of the proposed ap-proach for both single-document and multi-document summarizations.1 IntroductionSingle-document summarization aims to pro-duce a concise and fluent summary for a singledocument, and multi-document summarizationaims to produce a concise and fluent summaryfor a document set consisting of multiple relateddocuments.
The two tasks are very closely re-lated in both task definition and solution method.Moreover, both of them are very important inmany information systems and applications.
Forexample, given a cluster of news articles, amulti-document summary can be used to helpusers to understand the whole cluster, and a sin-gle summary for each article can be used to helpusers to know the content of the specified article.To date, single-document and multi-documentsummarizations have been investigated exten-sively and independently in the NLP and IRfields.
A series of special conferences or work-shops on automatic text summarization (e.g.SUMMAC, DUC, NTCIR and TAC) have ad-vanced the technology and produced a couple ofexperimental online systems.
However, the twosummarization tasks have not yet been simulta-neously investigated in a unified framework.Inspired by the fact that the two tasks are veryclosely related and they can be used simultane-ously in many applications, we believe that thetwo tasks may have mutual influences on eachother.
In this study, we propose a unified ap-proach to simultaneous single-document andmulti-document summarizations.
The mutualinfluences between the two tasks are incorpo-rated into a graph-based model.
The rankingscores of sentences for single-document summa-rization and the ranking scores of sentences formulti-document summarization can boost eachother, and they can be obtained simultaneouslyin a unified graph-based ranking process.
To thebest of our knowledge, this study is the first at-tempt for simultaneously addressing the twosummarization tasks in a unified graph-basedframework.
Moreover, the proposed approachcan be easily adapted for topic-focused summa-rizations.Experiments have been performed on both thesingle-document and multi-document summari-zation tasks of DUC2001 and DUC2002.
Theresults demonstrate that the proposed approachcan outperform baseline independent methodsfor both the two summarization tasks.
The twotasks are validated to have mutual influences oneach other.The rest of this paper is organized as follows:Section 2 introduces related work.
The details ofthe proposed approach are described in Section3.
Section 4 presents and discusses the evalua-tion results.
Lastly we conclude our paper inSection 5.11372 Related WorkDocument summarization methods can be eitherextraction-based or abstraction-based.
In thissection, we focus on extraction-based methods.Extraction-based methods for single-document summarization usually assign a sali-ency score to each sentence in a document andthen rank and select the sentences.
The score isusually computed based on a combination ofstatistical and linguistic features, such as termfrequency, sentence position, cue words andstigma words (Luhn, 1969; Edmundson, 1969;Hovy and Lin, 1997).
Machine learning tech-niques have also been used for sentence extrac-tion (Kupiec et al, 1995; Conroy and O?Leary,2001; Shen et al, 2007; Li et al, 2009).
Themutual reinforcement principle has been ex-ploited to iteratively extract key phrases andsentences from a document (Zha, 2002; Wan etal, 2007a).
Wan et al (2007b) propose the Col-labSum algorithm to use additional knowledgein a cluster of documents to improve singledocument summarization in the cluster.In recent years, graph-based ranking methodshave been investigated for document summari-zation, such as TextRank (Mihalcea and Tarau,2004; Mihalcea and Tarau, 2005) and LexPag-eRank (ErKan and Radev, 2004).
Similar toPageRank (Page et al, 1998), these methodsfirst build a graph based on the similarity rela-tionships between the sentences in a documentand then the saliency of a sentence is determinedby making use of the global information on thegraph recursively.
The basic idea underlying thegraph-based ranking algorithm is that of ?vot-ing?
or ?recommendation?
between sentences.Similar methods have been used for genericmulti-document summarization.
A typicalmethod is the centroid-based method (Radev etal., 2004).
For each sentence, the method com-putes a score based on each single feature (e.g.cluster centroids, position and TFIDF) and thenlinearly combines all the scores into an overallsentence score.
Topic signature is used as anovel feature for selecting important content inNeATS (Lin and Hovy, 2002).
Various sentencefeatures have been combined by using machinelearning techniques (Wong et al, 2008).
Apopular way for removing redundancy betweensummary sentences is the MMR algorithm (Car-bonell and Goldstein, 1998).
Themes (or topics,clusters) in documents have been discovered andused for sentence selection (Harabagiu and La-catusu, 2005).
Hachey (2009) investigates theeffect of various source document representa-tions on the accuracy of the sentence extractionphase of a multi-document summarization task.Graph-based methods have also been used torank sentences in a document set.
The methodsfirst construct a graph to reflect sentence rela-tionships at different granularities, and thencompute sentence scores based on graph-basedlearning algorithms.
For example, Wan (2008)proposes to use only cross-document relation-ships for graph building and sentence ranking.Cluster-level information has been incorporatedin the graph model to better evaluate sentences(Wan and Yang, 2008).For topic-focused multi-document summari-zation, many methods are extensions of genericsummarization methods by incorporating theinformation of the given topic or query into ge-neric summarizers.
In recent years, a few novelmethods have been proposed for topic-focusedsummarization (Daum?
and Marcu, 2006; Wanet al, 2007c; Nastase 2008; Li et al, 2008;Schilder and Kondadadi, 2008; Wei et al, 2008).The above previous graph-based summariza-tion methods aim to address either single-document summarization or multi-documentsummarization, and the two summarization taskshave not yet been addressed in a unified graph-based framework.3 The Unified Summarization Ap-proach3.1 OverviewGiven a document set, in which the whole docu-ment set and each single document in the set arerequired to be summarized, we use local sali-ency to indicate the importance of a sentence ina particular document, and use global saliencyto indicate the importance of a sentence in thewhole document set.In previous work, the following two assump-tions are widely made for graph-based summari-zation models:Assumption 1: A sentence is locally impor-tant in a particular document if it is heavilylinked with many locally important sentences inthe same document.1138Assumption 2: A sentence is globally impor-tant in the document set if it is heavily linkedwith many globally important sentences in thedocument set.The above assumptions are the basis for Pag-eRank-like algorithms for single documentsummarization and multi-document summariza-tion, respectively.
In addition to the above twoassumptions, we make the following two as-sumptions to consider the mutual influences be-tween the two summarization tasks:Assumption 3: A sentence is locally impor-tant in a particular document, if it is heavilylinked with many globally important sentencesin the document set.The above assumption is reasonable becausethe documents in the set are relevant and theglobally important information in the documentset will be expressed in many single documents.Therefore, if a sentence is salient in the wholedocument set, the sentence may be salient in aparticular document in the set.Assumption 4: A sentence is globally impor-tant in the document set, if it is heavily linkedwith many locally important sentences.The above assumption is reasonable becausethe documents in the set are relevant and theglobally important information in the whole setis the aggregation of the locally important in-formation in each single document.
Therefore, ifa sentence is salient in a particular document,the sentence has the potential to be salient in thewhole document set.In brief, the local saliency and global saliencyof a sentence can mutually influence and boosteach other: high local saliency will lead to highglobal saliency, and high global saliency willlead to high local saliency.Based on the above assumptions, our pro-posed approach first builds affinity graphs (eachgraph is represented by an affinity matrix) toreflect the different kinds of relationships be-tween sentences, respectively, and then itera-tively computes the local saliency scores and theglobal saliency scores of the sentences based onthe graphs.
Finally, the algorithm converges andthe local saliency score and global saliencyscore of each sentence are obtained.
The sen-tences with high local saliency scores in a par-ticular document are chosen into the summary ofthe single document, and the sentences withhigh global saliency scores in the set are choseninto the summary of the document set.Note that for both summarization tasks, afterthe saliency scores of sentences have been ob-tained, the greedy algorithm used in (Wan et al,2007c) is applied to remove redundancy andfinally choose both informative and novel sen-tences into the summary.3.2 Algorithm DetailsFormally, the given document set is denoted asD={di|1?i?m}, and the whole sentence set isdenoted as S={si|1?i?n}.
We let Infosingle(si)denote the local saliency score of sentence si in aparticular document d(si)?D, and it is used toselect summary sentences for the single docu-ment d(si).
And we let Infomulti(si) denote theglobal saliency score of sentence si in the wholedocument set D,  and it is used to select sum-mary sentences for the document set D.The four assumptions in Section 3.1 can berendered as follows:??
j jglejiAigle sInfoWsInfo )()()( sinsin  (1)??
j jmultijiBimulti sInfoWsInfo )()()(  (2)??
j jmultijiCigle sInfoWsInfo )()()(sin  (3)??
j jglejiDimulti sInfoWsInfo )()()( sin  (4)where WA, WB, WC, WD are n?n affinity matricesreflecting the different kinds of relationshipsbetween sentences in the document set, where nis the number of all sentences in the documentset.
The detailed derivation of the matrices willbe presented later.After fusing the above equations, we can ob-tain the following unified forms:??
?+=j jmultijiCj jglejiAiglesInfoWsInfoWsInfo)()()1()()()( sinsin??
(5)??
?+=j jglejiDj jmultijiBimultisInfoWsInfoWsInfo)()()1()()()(sin??
(6)However, the above summarization methodignores the feature of sentence position, whichhas been validated to be very important fordocument summarizations.
In order to incorpo-rate this important feature, we add one priorscore to each computation as follows:)()()()()()(sinsinsiniglej jmultijiCj jglejiAiglespriorsInfoWsInfoWsInfo?++=?????
(7)1139)()()()()()(sin imultij jglejiDj jmultijiBimultispriorsInfoWsInfoWsInfo?++=?????
(8)where ?, ?, ??
[0,1] specify the relative contri-butions to the final saliency scores from the dif-ferent factors, and we have ?+?+?=1.
pri-orsingle(si) is the prior score for the local saliencyof sentence si, and here priorsingle(si)  is com-puted based on sentence position of si in the par-ticular document d(si).
priormulti(si) is the priorscore for the global saliency of sentence si, andwe also compute priormulti(si) based on sentenceposition of si.We use two column vectorsur =[Infosingle(si)]n?1 and vr =[Infomulti(si)]n?1 todenote the local and global saliency scores of allthe sentences in the set, respectively.
And thematrix forms of the above equations are as fol-lows:gleTT ??
?CA sinpvWuWu rrrr ++=   (9)multiTT ??
?DBpuWvWv rrrr ++=    (10)where1sinsin )]([ ?= niglegle spriorpr and1)]([ ?= nimultimulti spriorprare the prior column vec-tors.The above matrices and prior vectors are con-structed as follows, respectively:WA: This affinity matrix aims to reflect thelocal relationships between sentences in eachsingle document, which is defined as follows:Otherwise   0,ji  and)d( )d( if  ),,()(cos?????
?==jijiineijAsssssimW(11)where d(si) refers to the document containingsentence si.
simcosine(si,sj) is the cosine similaritybetween sentences si and sj.jijijiine sssssssim rrrr?
?=),(cos(12)where isr  and jsr are the corresponding term vec-tors of si and sj.
Note that we have (WA)ij = (WA)ji,and we have (WA)ii =0 to avoid self loops.We can see that the matrix contains only thewithin-document relationships between sen-tences.WB: This affinity matrix aims to reflect theglobal relationships between sentences in thedocument set, which is defined as follows:Otherwise   0,)d( )d( if  ),,()( cos???
?=jijiineijBsssssimW(13)We can see that the matrix contains only thecross-document relationships between sentences.We do not include the within-document sen-tence relationships in the matrix because it hasbeen shown that the cross-document relation-ships are more appropriate to reflect the globalmutual influences between sentences than thewithin-document relationships in (Wan, 2008).WC: This affinity matrix aims to reflect thecross-document relationships between sentencesin the document set.
However, the relationshipsin this matrix are used for carrying the influ-ences of the sentences in other documents on thelocal saliency of the sentences in a particulardocument.
If we directly use Equation (13) tocompute the matrix, the mutual influenceswould be overly used.
Because other documentsmight not be sampled from the same generativemodel as the specified document, we probablydo not want to trust them so much as the speci-fied document.
Thus a confidence value is usedto reflect out belief that the document is sampledfrom the same underlying model as the specifieddocument.
Heuristically, we use the cosine simi-larity between documents as the confidencevalue.
And we use the confidence value as thedecay factor in the matrix computation as fol-lows:Otherwise   0,)d( )d( if)),(),((),()(coscos??????
?= jijiinejiineijc sssdsdsimsssimW(14)WD: This affinity matrix aims to reflect thewithin-document relationships between sen-tences.
Thus we have WD=WA, which means thatthe global saliency score of a sentence is influ-enced only by the local saliency scores of thesentences in the same document, without con-sidering the sentences in other documents.Note that the above four matrices are symmet-ric and we can replace TAW , TBW , TCW and TDWby WA, WB, WC and WD in Equations (9) and(10), respectively.priorsingle(si): It is computed under the as-sumption that the first sentences in a documentare usually more important than other sentences.1)(15.0)(sin++=iigle spositionsprior(15)where position(si) returns the position number ofsentence si in its document d(si).
For example, if1140si is the first sentence in its document, position(si)is 1.The  prior weight is then normalized by:?= i igleigleigle spriorspriorsprior)()()(sinsinsin(16)priormulti(si): We also let the prior weight re-flect the influence of sentence position.
)()( sin igleimulti spriorsprior =  (17)And then the prior weight is normalized in thesame way.The above definitions are for generic docu-ment summarizations and the above algorithmcan be easily adapted for topic-focused summa-rizations.
Given a topic q, the only change forthe above computation is priormulti(si).
The topicrelevance is incorporated into the prior weight asfollows:),()( cos qssimsprior iineimulti =  (18)?= i imultiimultiimulti spriorspriorsprior)()()(   (19)In order to solve the iterative problem definedin Equations (9) and (10), we let TT ]  [ Tvur rrr = ,T]  [ TmultiTsingle ppprrr ?
?= ,????????=TBTDTCTAWWWWW???
?, andthen the iterative equations correspond to thefollowing linear system:prWr rrr +=  (20)prWI rr =?
)(  (21)To guarantee the solution of the above linearsystem, W is normalized by columns.
If all theelements of a column are zero, we replace theelements with 1/(2n), where 2n equals to theelement number of the column.
We then multi-ply W by a decay factor ?
(0<?<1) to scale downeach element in W, but remain the meaning ofW.
Here, ?
is empirically set to 0.61.
Finally,Equation (21) is rewritten as follows:prWI rr =??
)( ?
(22)Thus, the matrix (I-?W) is a strictly diago-nally dominant matrix and the solution of thelinear system exists and we can apply the Gauss-Seidel method used in (Li et al, 2008) to solvethe linear system.
The GS method is a well-know method for numeric computation in1  In our pilot study, we can observe good performancewhen ?
is in a wide range of [0.4, 0.8].mathematics and the details of the method isomitted here.4 Empirical Evaluation4.1 Dataset and Evaluation MetricGeneric single-document and multi-documentsummarizations have been the fundamental tasksin DUC 2001 and DUC 2002 (i.e.
tasks 1 and 2in DUC 2001 and tasks 1 and 2 in DUC 2002),and we used the two datasets for evaluation.DUC2001 provided 309 articles, which weregrouped into 30 document sets.
Generic sum-mary of each article was required to be createdfor task 1, and generic summary of each docu-ment set was required to be created for task 2.The summary length was 100 words or less.DUC 2002 provided 59 document sets consist-ing of 567 articles (D088 is excluded from theoriginal 60 document sets by NIST) and genericsummaries for each article and each documentset with a length of approximately 100 wordswere required to be created.
The sentences ineach article have been separated and the sen-tence information has been stored into files.
Thesummary of the two datasets are shown in Table1.DUC 2001 DUC 2002Task Tasks 1, 2 Tasks 1, 2Number of documents 309 567Number of clusters 30 59Data source TREC-9 TREC-9summary length 100 words 100 wordsTable 1.
Summary of datasetsWe used the ROUGE toolkit2  (Lin and Hovy,2003) for evaluation, which has been widelyadopted by DUC for automatic summarizationevaluation.
It measured summary quality bycounting overlapping units such as the n-gram,word sequences and word pairs between thecandidate summary and the reference summary.The ROUGE toolkit reported separate recall-oriented scores for 1, 2, 3 and 4-gram, and alsofor longest common subsequence co-occurrences.
We showed three of the ROUGEmetrics in the experimental results: ROUGE-1(unigram-based), ROUGE-2 (bigram-based),and ROUGE-W (based on weighted longestcommon subsequence, weight=1.2).
In order totruncate summaries longer than the length limit,2 We used ROUGEeval-1.4.2 in this study.1141we used the ?-l 100?
option in ROUGE toolkit.We also used the ?-m?
option for word stem-ming.4.2 Evaluation Results4.2.1 System ComparisonIn the experiments, the combination weight ?
forthe prior score is fixed at 0.15, as in the PageR-ank algorithm.
Therefore, we have ?+?=0.85.Here, we use ?/(?+?)
to indicate the relativecontributions of the first two parts in Equations(9) and (10).
We empirically set ?/(?+?
)=0.4 inthe experiments.
The proposed unified approach(i.e.
UnifiedRank) is compared with a few base-line approaches and the top three participatingsystems.The graph-based baselines for single-document summarization are described as fol-lows:BasicRank: This baseline approach adoptsthe basic PageRank algorithm to rank sentencesbased on all sentence relationships in a singledocument, similar to previous work (Mihalceaand Tarau, 2004).PositionRank: This baseline approach im-proves the basic PageRank algorithm by usingthe position weight of a sentence as the priorscore for the sentence.
The position weight of asentence is computed by using Equation (15).CollabRank1: This baseline approach is the?UniformLink(Gold)?
approach proposed in(Wan et al 2007b).
It uses a cluster of multipledocuments to improve single document summa-rization by constructing a global affinity graph.CollabRank2: This baseline approach is the?UnionLink(Gold)?
approach proposed in (Wanet al 2007b).The graph-based baselines for multi-document summarization are described as fol-lows:BasicRank: This baseline approach adoptsthe basic PageRank algorithm to rank sentencesbased on all sentence relationships in documentset.
Both within-document and cross-documentsentence relationships are used for constructingthe affinity graph.PositionRank: Similarly, this baseline ap-proach improves the basic PageRank algorithmby using the position weight of a sentence as theprior score for the sentence.TwoStageRank: This baseline approach lev-erages the results of single document summari-zation for multi-document summarization.
Itfirst computes the score of each sentence withineach single document by using the PositionRankmethod, and then computes the final score ofeach sentence within the document set by con-sidering the document-level sentence score asthe prior score in the improved PageRank algo-rithm.The top three systems are the systems withhighest ROUGE scores, chosen from the partici-pating systems on each task, respectively.
Ta-bles 2 and 3 show the comparison results forsingle-document summarization on DUC2001and DUC2002, respectively.
Tables 4 and 5show the comparison results for multi-documentsummarization on DUC2001 and DUC2002,respectively.
In the tables, SystemX (e.g.
Sys-tem28, SystemN) represents one of the top per-forming systems.
The systems are sorted by de-creasing order of the ROUGE-1 scores.For single-document summarization, the pro-posed UnifiedRank approach always outper-forms the four graph-based baselines over allthree metrics on both two datasets.
The per-formance differences are all statistically signifi-cant by using t-test (p-value<0.05).
TheROUGE-1 score of UnifiedRank is higher thanthat of the best participating systems and theROUGE-2 and ROUGE-W scores of Unifie-dRank are comparable to that of the best partici-pating systems.For multi-document summarization, the pro-posed UnifiedRank approach outperforms all thethree graph-based baselines over all three met-rics on the DUC2001 dataset, and it outperformsthe three baselines over ROUGE-1 andROUGE-W on the DUC2002 dataset.
In particu-lar, UnifiedRank can significantly outperformBasicRank and TwoStageRank over all threemetrics on the DUC2001 dataset (t-test, p-value<0.05).
Moreover, the ROUGE-1 andROUGE-W scores of UnifiedRank are higherthan that of the best participating systems andthe ROUGE-2 score of UnifiedRank is compa-rable to that of the best participating systems.The results demonstrate that the single-document and multi-document summarizationscan benefit each other by making use of the mu-tual influences between the local saliency and1142global saliency of the sentences.
Overall, theproposed unified graph-based approach is effec-tive for both single document summarizationand multi-document summarization.
However,the performance improvement for single-document summarization is more significantthan that for multi-document summarization,which shows that the global information in adocument set is very beneficial to summariza-tion of each single document in the documentset.System ROUGE-1 ROUGE-2 ROUGE-WUnifiedRank 0.45377 0.17649 0.14328CollabRank2 0.44038 0.16229 0.13678CollabRank1 0.43890 0.16213 0.13676PositionRank 0.43596 0.15936 0.13684BasicRank 0.43407 0.15696 0.13629Table 2.
Comparison results for single-documentsummarization on DUC20013System ROUGE-1 ROUGE-2 ROUGE-WUnifiedRank 0.48478 0.21462 0.16877System28 0.48049 0.22832 0.17073System21 0.47754 0.22273 0.16814CollabRank1 0.47187 0.20102 0.16318CollabRank2 0.47028 0.20046 0.16260PositionRank 0.46618 0.19853 0.16180System31 0.46506 0.20392 0.16162BasicRank 0.46261 0.19457 0.16018Table 3.
Comparison results for single-documentsummarization on DUC2002System ROUGE-1 ROUGE-2 ROUGE-WUnifiedRank 0.36360 0.06496 0.10950PositionRank 0.35733 0.06092 0.10798BasicRank 0.35527 0.05608 0.10641TwoStageRank 0.35221 0.05500 0.10515SystemN 0.33910 0.06853 0.10240SystemP 0.33332 0.06651 0.10068SystemT 0.33029 0.07862 0.10215Table 4.
Comparison results for multi-documentsummarization on DUC2001System ROUGE-1 ROUGE-2 ROUGE-WUnifiedRank 0.38343 0.07855 0.12341PositionRank 0.38056 0.08238 0.12292TwoStageRank 0.37972 0.08166 0.12261BasicRank 0.37595 0.08304 0.12173System26 0.35151 0.07642 0.11448System19 0.34504 0.07936 0.11332System28 0.34355 0.07521 0.10956Table 5.
Comparison results for multi-documentsummarization on DUC20023 The summarization results for participating systems onDUC2001 are incomplete.4.2.2 Influences of Combination WeightIn the above experiments, the relative contribu-tions from the first two parts in Equations (9)and (10) are empirically set as ?/(?+?)=0.4.
Inthis section, we investigate how the relative con-tributions influence the summarization perform-ance by varying ?/(?+?)
from 0 to 1.
A smallvalue of ?/(?+?)
indicates that the contributionfrom the same kind of saliency scores of the sen-tences is less important than the contributionfrom the different kind of saliency scores of thesentences, and vice versa.
Figures 1-8 show theROUGE-1 and ROUGE-W curves for single-document summarization and multi-documentsummarization on DUC2001 and DUC2002,respectively.For single document summarization, verysmall value or very large value for ?/(?+?)
willlower the summarization performance values onthe two datasets.
The results demonstrate thatboth the two kinds of contributions are impor-tant to the final performance of single documentsummarization.For multi-document summarization, a rela-tively large value (?0.4) for ?/(?+?)
will lead torelatively high performance values on theDUC2001 dataset, but a very large value for?/(?+?)
will decrease the performance values.On the DUC2002 dataset, a relatively smallvalue (?0.4) will lead to relatively high per-formance values, but a very small value for?/(?+?)
will decrease the performance values.Though the trends of the curves on theDUC2001 and DUC2002 datasets are not veryconsistent with each other, the results show thatboth the two kinds of contributions are benefi-cial to the final performance of multi-documentsummarization.5 Conclusion and Future WorkIn this study, we propose a novel unified ap-proach to simultaneous single-document andmulti-document summarization by making usingof the mutual influences between the two tasks.Experimental results on the benchmark DUCdatasets show the effectiveness of the proposedapproach.In future work, we will perform comprehen-sive experiments for topic-focused document1143summarizations to show the robustness of theproposed approach.DUC20010.4440.4460.4480.450.4520.4540.4560.4580 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-1Figure 1.
ROUGE-1 vs. combination weight for sin-gle-document summarization on DUC2001DUC20010.140.14050.1410.14150.1420.14250.1430.14350.1440.14450 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-WFigure 2.
ROUGE-W vs. combination weight forsingle-document summarization on DUC2001DUC20020.4740.4760.4780.480.4820.4840.4860 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-1Figure 3.
ROUGE-1 vs. combination weight for sin-gle-document summarization on DUC2002DUC20020.1640.1650.1660.1670.1680.1690.170 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-WFigure 4.
ROUGE-W vs. combination weight forsingle-document summarization on DUC2002DUC20010.340.3450.350.3550.360.3650.370 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-1Figure 5.
ROUGE-1 vs. combination weight formulti-document summarization on DUC2001DUC20010.1020.1040.1060.1080.110.1120.1140 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-WFigure 6.
ROUGE-W vs. combination weight formulti-document summarization on DUC2001DUC20020.3740.3760.3780.380.3820.3840.3860 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-1Figure 7.
ROUGE-1 vs. combination weight formulti-document summarization on DUC2002DUC20020.120.1210.1220.1230.1240.1250 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?/(?+?
)ROUGE-WFigure 8.
ROUGE-W vs. combination weight formulti-document summarization on DUC2002AcknowledgmentsThis work was supported by NSFC (60873155),Beijing Nova Program (2008B03) and NCET(NCET-08-0006).1144ReferencesJ.
Carbonell, J. Goldstein.
1998.
The Use of MMR,Diversity-based Reranking for Reordering Docu-ments and Producing Summaries.
In Proceedingsof SIGIR1998, 335-336.J.
M. Conroy, D. P. O?Leary.
2001.
Text Summariza-tion via Hidden Markov Models.
In Proceedingsof SIGIR2001, 406-407.H.
Daum?
and D. Marcu.
2006.
Bayesian query-focused summarization.
In Proceedings of ACL-06.H.
P. Edmundson.
1969.
New Methods in AutomaticAbstracting.
Journal of the Association for com-puting Machinery, 16(2): 264-285.G.
ErKan, D. R. Radev.
2004.
LexPageRank: Pres-tige in Multi-Document Text Summarization.
InProceedings of EMNLP2004.B.
Hachey.
2009.
Multi-document summarisationusing generic relation extraction.
In Proceedingsof EMNLP2009.S.
Harabagiu and F. Lacatusu.
2005.
Topic themesfor multi-document summarization.
In Proceed-ings of SIGIR-05.E.
Hovy, C. Y. Lin.
1997.
Automated Text Summari-zation in SUMMARIST.
In Proceeding ofACL?1997/EACL?1997 Worshop on IntelligentScalable Text Summarization.J.
Kupiec, J. Pedersen, F. Chen.
1995.
A.TrainableDocument Summarizer.
In Proceedings ofSIGIR1995, 68-73.W.
Li, F. Wei, Q. Lu and Y.
He.
2008.
PNR2: rank-ing sentences with positive and negative rein-forcement for query-oriented update summariza-tion.
In Proceedings of COLING-08.L.
Li, K. Zhou, G.-R. Xue, H. Zha, Y. Yu.
2009.Enhancing diversity, coverage and balance forsummarization through structure learning.
In Pro-ceedings of WWW-09.C..-Y. Lin and E.. H. Hovy.
2002.
From Single toMulti-document Summarization: A PrototypeSystem and its Evaluation.
In Proceedings ofACL-02.C.-Y.
Lin and E.H. Hovy.
2003.
Automatic Evalua-tion of Summaries Using N-gram Co-occurrenceStatistics.
In Proceedings of HLT-NAACL -03.H.
P. Luhn.
1969.
The Automatic Creation of litera-ture Abstracts.
IBM Journal of Research and De-velopment, 2(2).R.
Mihalcea, P. Tarau.
2004.
TextRank: BringingOrder into Texts.
In Proceedings of EMNLP2004.R.
Mihalcea and P. Tarau.
2005.
A language inde-pendent algorithm for single and multiple docu-ment summarization.
In Proceedings of IJCNLP-05.V.
Nastase.
2008.
Topic-driven multi-documentsummarization with encyclopedic knowledge andspreading activation.
In Proceedings of EMNLP-08.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1998.The pagerank citation ranking: Bringing order tothe web.
Technical report, Stanford Digital Librar-ies.D.
R. Radev, H. Y. Jing, M. Stys and D. Tam.
2004.Centroid-based summarization of multiple docu-ments.
Information Processing and Management,40: 919-938.F.
Schilder and R. Kondadadi.
2008.
FastSum: fastand accurate query-based multi-document sum-marization.
In Proceedings of ACL-08: HLT.D.
Shen, J.-T. Sun, H. Li, Q. Yang, and Z. Chen.2007.
Document Summarization using Condi-tional Random Fields.
In Proceedings ofIJCAI2007.X.
Wan.
2008.
Using Only Cross-Document Rela-tionships for Both Generic and Topic-FocusedMulti-Document Summarizations.
InformationRetrieval, 11(1): 25-49.X.
Wan and J. Yang.
2008.
Multi-document summa-rization using cluster-based link analysis.
In Pro-ceedings of SIGIR-08.X.
Wan, J. Yang and J. Xiao.
2007a.
Towards anIterative Reinforcement Approach for Simultane-ous Document Summarization and Keyword Ex-traction.
In Proceedings of ACL2007.X.
Wan, J. Yang and J. Xiao.
2007b.
CollabSum:Exploiting Multiple Document Clustering for Col-laborative Single Document Summarizations.
InProceedings of SIGIR2007.X.
Wan, J. Yang and J. Xiao.
2007c.
Manifold-ranking based topic-focused multi-documentsummarization.
In Proceedings of IJCAI-07.F.
Wei, W. Li, Q. Lu and Y.
He.
2008.
Query-sensitive mutual reinforcement chain and its ap-plication in query-oriented multi-document sum-marization.
In Proceedings of SIGIR-08.K.-F. Wong, M. Wu and W. Li.
2008.
Extractivesummarization using supervised and semi-supervised learning.
In Proceedings of COLING-08.H.
Y. Zha.
2002.
Generic Summarization and Key-phrase Extraction Using Mutual ReinforcementPrinciple and Sentence Clustering.
In Proceedingsof SIGIR2002, 113-120.1145
