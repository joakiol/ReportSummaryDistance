Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 524?533,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsAutomatic Analysis of Rhythmic Poetrywith Applications to Generation and TranslationErica GreeneHaverford College370 Lancaster Ave.Haverford, PA 19041ericagreene@gmail.comTugba BodrumluDept.
of Computer ScienceUniv.
of Southern CaliforniaLos Angeles, CA 90089bodrumlu@cs.usc.eduKevin KnightInformation Sciences InstituteUniv.
of Southern California4676 Admiralty WayMarina del Rey, CA 90292knight@isi.eduAbstractWe employ statistical methods to analyze,generate, and translate rhythmic poetry.
Wefirst apply unsupervised learning to revealword-stress patterns in a corpus of raw poetry.We then use these word-stress patterns, in ad-dition to rhyme and discourse models, to gen-erate English love poetry.
Finally, we trans-late Italian poetry into English, choosing tar-get realizations that conform to desired rhyth-mic patterns.1 IntroductionWhen it comes to generating creative language (po-ems, stories, jokes, etc), people have massive advan-tages over machines:?
people can construct grammatical, sensible ut-terances,?
people have a wide range of topics to talkabout, and?
people experience joy and heart-break.On the other hand, machines have some minor ad-vantages:?
a machine can easily come up with a five-syllable word that starts with p and rhymeswith early, and?
a machine can analyze very large online textrepositories of human works and maintainthese in memory.In this paper we concentrate on statistical methodsapplied to the analysis, generation, and translationof poetry.
By analysis, we mean extracting patternsfrom existing online poetry corpora.
We use thesepatterns to generate new poems and translate exist-ing poems.
When translating, we render target textin a rhythmic scheme determined by the user.Poetry generation has received research attentionin the past (Manurung et al, 2000; Gervas, 2001;Diaz-Agudo et al, 2002; Manurung, 2003; Wongand Chun, 2008; Tosa et al, 2008; Jiang and Zhou,2008; Netzer et al, 2009), including the use ofstatistical methods, although there is a long wayto go.
One difficulty has been the evaluation ofmachine-generated poetry?this continues to be adifficulty in the present paper.
Less research efforthas been spent on poetry analysis and poetry trans-lation, which we tackle here.2 TermsMeter refers to the rhythmic beat of poetic text whenread aloud.
Iambic is a common meter that soundslike da-DUM da-DUM da-DUM, etc.
Each da-DUM is called a foot.
Anapest meter sounds likeda-da-DUM da-da-DUM da-da-DUM, etc.Trimeter refers to a line with three feet, pentame-ter to a line with five feet, etc.
Examples include:?
a VE-ry NAS-ty CUT (iambic trimeter)?
shall I com-PARE thee TO a SUM-mer?sDAY?
(iambic pentameter)?
twas the NIGHT before CHRIST-mas andALL through the HOUSE (anapest tetrame-ter)Classical English sonnets are poems most oftencomposed of 14 lines of iambic pentameter.5243 AnalysisWe focus on English rhythmic poetry.
We definethe following analysis task: given poetic lines ina known meter (such as sonnets written in iambicpentameter), assign a syllable-stress pattern to eachword in each line.
Making such decisions is part ofthe larger task of reading poetry aloud.
Later in thepaper, we will employ the concrete statistical tablesfrom analysis to the problems of poetry generationand translation.We create a test set consisting of 70 lines fromShakespeare?s sonnets, which are written in iambicpentameter.
Here is an input line annotated withgold output.shall i compare thee to a summers day| | /\ | | | /\ |S S* S S* S S* S S* S S*S refers to an unstressed syllable, and S* refers toa stressed syllable.
One of the authors created gold-standard output by listening to Internet recordingsof the 70 lines and marking words according to thespeaker?s stress.
The task evaluation consists of per-word accuracy (how many words are assigned thecorrect stress pattern) and per-line accuracy (howmany lines have all words analyzed perfectly).This would seem simple enough, if we are armedwith something like the CMU pronunciation dictio-nary: we look up syllable-stress patterns for eachword token and lay these down on top of the se-quence S S* S S* S S* S S* S S*.
However, thereare difficulties:?
The test data contains many words that are un-known to the CMU dictionary.?
Even when all words are known, many linesdo not seem to contain 10 syllables.
Somelines contain eleven words.?
Spoken recordings include stress reversals,such as poin-TING instead of POIN-ting.?
Archaic pronunciations abound, such asPROV-ed (two syllables) instead of PROVED(one syllable).?
In usage, syllables are often subtracted (PRIS-ner instead of PRIS-o-ner), added (SOV-e-reign instead of SOV-reign), or merged.?
Some one-syllable words are mostly stressed,and others mostly unstressed, but the dictio-e ?
P(m|e) ?
mFigure 1: Finite-state transducer (FST) for mapping se-quences of English words (e) onto sequences of S* and Ssymbols (m), representing stressed and unstressed sylla-bles.nary provides no guidance.
When we gener-ate rhythmic text, it is important to use one-syllable words properly.
For example, wewould be happy for an iambic generator tooutput big thoughts are not quite here, but notquite big thoughts are not here.Therefore, we take a different tack and apply un-supervised learning to acquire word-stress patternsdirectly from raw poetry, without relying on a dic-tionary.
This method easily ports to other languages,where dictionaries may not exist and where mor-phology is a severe complication.
It may also beused for dead languages.For raw data, we start with all Shakespeare son-nets (17,134 word tokens).
Because our learning isunsupervised, we do not mind including our 70-linetest set in this data (open testing).Figures 1 and 2 show a finite-state transducer(FST) that converts sequences of English words tosequences of S* and S symbols.
The FST?s transi-tions initially map each English word onto all out-put sub-sequences of lengths 1 to 4 (i.e., S, S*, S-S,S-S*, S*-S, S*-S*, S-S-S, .
.
. )
plus the sequencesS-S*-S-S*-S and S*-S-S*-S-S*.
Initial probabilitiesare set to 1/32.
The FST?s main loop allows it toprocess a sequence of word tokens.
If the same wordappears twice in a sequence, then it may receive twodifferent pronunciations, since the mapping is prob-abilistic.
However, a token?s syllable/stress patternis chosen independently of other tokens in the se-quence; we look at relaxing this assumption later.We next use finite-state EM training1 to train themachine on input/output sequences such as these:from fairest creatures we desire increaseS S* S S* S S* S S* S S*but thou contracted to thine own bright eyesS S* S S* S S* S S* S S*1All operations in this paper are carried out with the genericfinite-state toolkit Carmel (Graehl, 1997).
For example, thetrain-cascade command uses EM to learn probabilities in an ar-bitrary FST cascade from end-to-end input/output string pairs.525Figure 2: An efficient FST implementing P(m|e).
This machine maps sequences of English words onto sequences ofS* and S symbols, representing stressed and unstressed syllables.
Initially every vocabulary word has 32 transitions,each with probability 1/32.
After EM training, far fewer transitions remain.526Figure 3: An FST that accepts any of four input metersand deterministically normalizes its input to strict iambicpentameter.
We call this FST norm.e ?
P(m|e) ?
m ?
norm ?
mFigure 4: FST cascade that encodes a loose interpretationof iambic pentameter.
The norm FST accepts any of fournear-iambic-pentameter sequences and normalizes theminto strict iambic pentameter.Note that the output sequences are all the same,representing our belief that each line should be readas iambic pentameter.2 After we train the FST,we can use Viterbi decoding to recover the highest-probability alignments, e.g.
:from fairest creatures we desire increase| | /| \ | /\ /\S S* S S* S S* S S* S S*but thou contracted to thine own bright eyes| | /| \ | | | | |S S* S S* S S* S S* S S*Note that the first example contains an error?thewords fairest and creatures should each be read withtwo syllables.
There are many such errors.
We nextimprove the system in two ways: more data and bet-ter modeling.First, we augment the Shakespeare sonnets withdata from the website sonnets.org, increasing thenumber of word tokens from 17,134 to 235,463.
Thesonnets.org data is noisier, because it contains somenon-iambic-pentameter poetry, but overall we findthat alignments improve, e.g.
:from fairest creatures we desire increase| /\ /\ | /\ /\S S* S S* S S* S S* S S*Second, we loosen our model.
When we listen torecordings, we discover that not all lines are read SS* S S* S S* S S* S S*.
Indeed, some lines in ourdata contain eleven words?these are unexplainableby the EM training system.
We also observe that2We can augment the data with lines of poetry written inmeters other than iambic pentameter, so long as we supply thedesired output pattern for each input line.Training Training Test token Test linedata tokens accuracy accuracyShakespeare 17,134 82.3% 55.7%sonnets.org 235,463 94.2% 81.4%Figure 5: Analysis task accuracy.poets often use the word mother (S* S) at the begin-nings and ends of lines, where it theoretically shouldnot appear.Two well-known variations explain these facts.One is optional inversion of the first foot (S S*?
S* S).
Second is the optional addition of aneleventh unstressed syllable (the feminine ending).These variations yield four possible syllable-stresssequences:S S* S S* S S* S S* S S*S* S S S* S S* S S* S S*S S* S S* S S* S S* S S* SS* S S S* S S* S S* S S* SWe want to offer EM the freedom to analyze linesinto any of these four variations.
We therefore con-struct a second FST (Figure 3), norm, which mapsall four sequences onto the canonical pattern S S*S S* S S* S S* S S*.
We then arrange both FSTsin a cascade (Figure 4), and we train the wholecascade on the same input/output sequences as be-fore.
Because norm has no trainable parameters, wewind up training only the lexical mapping parame-ters.
Viterbi decoding through the two-step cascadenow reveals EM?s proposed internal meter analysisas well as token mappings, e.g.
:to be or not to be that is the question| | | | | | | | | /\S S* S S* S S* S S* S S* S| | | | | | | | | |S S* S S* S S* S S* S S*Figure 5 shows accuracy results on the 70-line testcorpus mentioned at the beginning of this section.Over 94% of word tokens are assigned a syllable-stress pattern that matches the pattern transcribedfrom audio.
Over 81% of whole lines are alsoscanned correctly.
The upper limit for whole-linescanning under our constraints is 88.6%, because11.4% of gold outputs do not match any of the fourpatterns we allow.We further obtain a probabilistic table of wordmappings that we can use for generation and trans-527P(S* S S* | altitude) = 1.00P(S* S | creatures) = 1.00P(S* S | pointed) = 0.95P(S S* | pointed) = 0.05P(S* S | prisoner) = 0.74P(S* S S* | prisoner) = 0.26P(S* S | mother) = 0.95P(S* | mother) = 0.03P(S S* | mother) = 0.02Figure 6: Sample learned mappings between words andsyllable-stress patterns.word P(S* | word) P(S | word)a 0.04 0.96the 0.06 0.94their 0.09 0.91mens 0.10 0.90thy 0.10 0.90be 0.48 0.52me 0.49 0.51quick 0.50 0.50split 0.50 0.50just 0.51 0.49food 0.90 0.10near 0.90 0.10raised 0.91 0.09dog 0.93 0.07thought 0.95 0.05Figure 7: Sample mappings for one-syllable words.lation tasks.
Figure 6 shows a portion of this table.Note that P(S S* | mother) has a very small proba-bility of 0.02.
We would incorrectly learn a muchhigher value if we did not loosen the iambic pen-tameter model, as many mother tokens occur line-initial and line-final.Figure 7 shows which one-syllable words aremore often stressed (or unstressed) in iambic pen-tameter poetry.
Function words and possessives tendto be unstressed, while content words tend to bestressed, though many words are used both ways.This useful information is not available in typicalpronunciation dictionaries.Alignment errors still occur, especially in noisyP(m) ?
m ?
P(e|m) ?
e ?
P(e) ?
eFigure 8: Finite-state cascade for poetry generation.portions of the data that are not actually written iniambic pentameter, but also in clean portions, e.g.
:the perfect ceremony of loves rite| /\ /|\ | | /\S S* S S* S S* S S* S S*The word ceremony only occurs this once in thedata, so it is willing to accept any stress pattern.While rite is correctly analyzed elsewhere as a one-syllable word, loves prefers S*, and this overwhelmsthe one-syllable preference for rite.
We can blameour tokenizer for this, as it conflates loves and love?s,despite the fact that these words have different stressprobabilities.4 GenerationFigure 8 shows our concept of generation as a cas-cade of weighted FSTs.P(m) is a user-supplied model of desiredmeters?normally it deterministically generates asingle string of S* and S symbols.
(The user alsosupplies a rhyme scheme?see below).P(e|m) is the reverse of Section 3?s P(m|e), be-ing a model of word selection.
Its generative storyis: (1) probabilistically select n tokens (n = 1 to 5)from the input, (2) probabilistically select a word wthat realizes that n-token sequence, and (3) recurseuntil the input is consumed.
Instead of asking howa given word is likely to be pronounced (e.g., S orS*), we now ask how a given stress-pattern (e.g., Sor S*) is likely to be realized.
This model is trainedwith the same method described in Section 3 and isaugmented with the CMU pronunciation dictionary.Finally, P(e) is a word-trigram model built from a10,000-line corpus of 105 English love poems.We select the first line of our poem from the FSTcascade?s 100,000-best list, or by hand.
To gener-ate each subsequent line, we modify the cascade andrun it again.
The first modification is to incorporatea discourse model.
From our poetry corpus, we esti-mate a word?s unigram probability given the wordson the previous line, via IBM Model 1 (Brown etal., 1993).
We modify P(e) by interpolating in theseprobabilities.
Second, we check if any previous line528The women of the nightAgain and all the wayLike a mouse in the whiteNot the heart of the day.- - -Of the bed to trust meAround her twists the stringBut i will not tell theeFire changes everything.- - -A son of the right hand confinesHis uncle could have broken inTowards the high bank and the pinesUpon the eyes and i have been- - -Into one of her hundred year oldOr the house in a house in a coldThe first time she met himLike a mouse in the dimFor me to the moon and when i told- - -Into one of them some years beforeHis own man or the house in a moreThe moon and when the dayInto one of the wayWith the breath from the first timeshe sworeFigure 9: Sample poems generated with a weighted FSTcascade.w1, w2, ...wn needs to be rhymed with, according tothe user-supplied scheme.
If so, we build an addi-tional FST that accepts only strings whose final wordrhymes with wn.
This is a reasonable approach,though it will not, for example, rhyme ...tar me with...army.
We say two non-identical words rhyme iftheir phoneme strings share a common suffix that in-cludes the last stressed vowel.Figure 9 shows several poems that we automati-cally generate with this scheme.5 TranslationAutomatically generated poetry can sound goodwhen read aloud, but it often has a ?nonsense?
feel toit.
According to (Gervas, 2010), creative-languageresearchers interested in realization and surface lan-guage statistics (?how to say?)
have tended to grav-itate to poetry generation, while researchers inter-ested in characters, goals, and story-line (?what tosay?)
have tended to gravitate to prose story genera-tion.Translation provides one way to tie things to-i ?
P(e|i) ?
e ?
P(m|e) ?
m ?
P(m) ?
mFigure 10: Finite-state cascade for poetry translation.gether.
The source language provides the input(?what to say?
), and the target language can beshaped to desired specifications (?how to say?).
Forexample, we may want to translate Italian sonnetsinto fluent English iambic pentameter.
This is cer-tainly a difficult task for people, and one which isgenerally assumed to be impossible for computers.Here we investigate translating Dante?s DivineComedy (DC) from Italian into English by machine.The poem begins:nel mezzo del cammin di nostra vitami ritrovai per una selva oscurache la via diritta era smarrita.DC is a long sequence of such three-line stan-zas (tercets).
The meter in Italian is hendecasyl-labic, which has ten syllables and ensures threebeats.
Dante?s Italian rhyme scheme is: ABA, BCB,CDC, etc, meaning that lines 2, 4, and 6 rhyme witheach other; lines 5, 7, and 9 rhyme with each other,and so forth.
There is also internal rhyme (e.g.,diritta/smarrita).Because DC has been translated many timesinto English, we have examples of good outputs.Some translations target iambic pentameter, but eventhe most respected translations give up on rhyme,since English is much harder to rhyme than Italian.Longfellow?s translation begins:midway upon the journey of our lifei found myself within a forest darkfor the straightforward pathway hadbeen lost.We arrange the translation problem as a cascadeof WFSTs, as shown in Figure 10.
We call our Ital-ian input i.
In lieu of the first WFST, we use thestatistical phrase-based machine translation (PBMT)system Moses (Koehn et al, 2007), which generatesa target-language lattice with paths scored by P(e|i).We send this lattice through the same P(m|e) devicewe trained in Section 3.
Finally, we filter the result-ing syllable sequences with a strict, single-path, de-terministic iambic pentameter acceptor, P(m).3 Our3It is also possible to use a looser iambic P(m) model, asdescribed in Section 3.529Parallel Italian/English DataCollection Word count (English)DC-train 400,670Il Fiore 25,995Detto Damare 2,483Egloghe 3,120Misc.
557Europarl 32,780,960English Language Model DataCollection Word count (English)DC-train 400,670poemhunter.com 686,714poetry.eserver.orgpoetrymountain.compoetryarchive.org 58,739everypoet.com 574,322sonnets.org 166,465Europarl 32,780,960Tune and Blind Test Data (4 reference)Collection Word count (Italian)DC-tune 7,674DC-test 2,861Figure 11: Data for Italian/English statistical translation.finite-state toolkit?s top-k paths represent the trans-lations with the highest product of scores P(e|i) ?P(m|e) ?
P(m).In general, the P(e|i) and P(m|e) models fighteach other in ranking candidate outputs.
In exper-iments, we find that the P(e|i) preference is some-times so strong that the P(m|e) model is pushedinto using a low-probability word-to-stress mapping.This creates output lines that do not scan easily.
Wesolve this problem by assigning a higher weight tothe P(m|e) model.4Figure 11 shows the data we used to train thePBMT system.
The vast majority of parallel Ital-ian/English poetry is DC itself, for which we havefour English translations.
We break DC up into DC-train, DC-tune, and DC-test.
We augment our targetlanguage model with English poetry collected frommany sources.
We also add Europarl data, which4We set this weight manually to 3.0, i.e., we raise all prob-abilities in the P(m|e) model to the power of 3.0.
Setting theweight too high results in lines that scan very well, but whosetranslation quality is low.Original:nel mezzo del cammin di nostra vitami ritrovai per una selva oscurache la via diritta era smarrita.Phrase-based translation (PBMT):midway in the journey of our lifei found myself within a forest darkfor the straight way was lost.PBMT + meter model:midway upon the journey of our lifei found myself within a forest darkfor the straightforward pathway had been lost.Figure 12: Automatic translation of lines from Dante?sDivine Comedy.
In this test-on-train scenario, the ma-chine reproduces lines from human translations it hasseen.is out of domain, but which reduces the unknownword-token rate in DC-test from 9% to 6%, and theunknown word-type rate from 22% to 13%.We first experiment in a test-on-train scenario,where we translate parts of DC that are in our train-ing set.
This is a normal scenario in human poetrytranslation, where people have access to previoustranslations.Figure 12 shows how we translate the first linesof DC, first using only PBMT, then using the fullsystem.
When we use the full system, we not onlyget an output string, but also the system?s intendedscan, e.g.
:midway upon the journey of our life/\ /\ | /\ | | |S S* S S* S S* S S* S S*The machine?s translation here is the same asLongfellow?s, which is in the training data.
In othercases, we observe the machine combining existingtranslations, e.g.
:i: bedi la bestia per cu io mi volsiI5: behold the beast that made me turn asideH1: BEHOLD THE BEAST for which i have turned backH2: you see the beast THAT MADE ME TURN ASIDEH3: see the beast that forced me to turn backH4: look at the beast that drove me to turn backI5 refs to the machine?s iambic pentameter transla-530tion, while H1-4 refer to human translations.
Themachine also creates new translations:i: diro?
de laltre cose chi vho scorteI5: i shall explain the other things i sawH1: speak will i of the other things i saw thereH2: ill also tell THE OTHER THINGS I SAWH3: i will recount the other things i sawH4: i here will tell the other things i sawWe can further change the target meter to any-thing we desire.
To obtain iambic tetrameter (4-beat)translations, we delete the last two transitions of theP(m) model.
We then get:I4: in our life the journey wayi found myself deep on dark woodthat lost straightforward pathway had.ah how to say the what is hardthis forest savage rough and sternthe very thought renews the fear.Translations and scans are uneven, but we havesignificant flexibility.
We can even request transla-tions that avoid the English letter A, by adding a fil-ter to the end of the FST cascade, obtaining:I5: in midst upon the journey of our lifei found myself within the wood obscure<fail>To steer clear of the adjective dark in the secondline, the system switches from forest to wood, soobtain a proper scan.
The third line fails becauseall paths through the translation lattice contain an Asomewhere.Translating blind-test data proves to be more dif-ficult.
We hold out Canto XXXI of DC?s Paradisosection for testing.
Figure 13 shows a portion ofthe translation results.
The MT system handles un-known Italian words by passing them through to theoutput.
The P(m|e) meter model cannot processthose words, accounting for the I5 failure rate.Here, we get a first look at statistical MT trans-lating poetry into rhythmic structures?as with allMT, there are successes and problems, and certainlymore to do.6 Future WorkWe plan to release all our of data in useful, processedform.
Below we list directions for future research.In general, we see many interesting paths to pursue.Analysis.
Proper use of one-syllable words re-mains tricky.
Lines coming out of generationOriginal:in forma dunque di candida rosami si mostrava la milizia santache nel suo sangue cristo fece sposama laltra che volando vede e cantala gloria di colui che la nnamorae la bonta?
che la fece cotantaHuman translation:in fashion then as of a snow white rosedisplayed itself to me the saintly hostwhom christ in his own blood had made his bridebut the other host that flying sees and singsthe glory of him who doth enamour itand the goodness that created it so noblePhrase-based translation (PBMT):in the form so rose candidai now was shown the militia holythat in his blood christ did bridebut the other that flying sees and singsthe glory of him that the nnamoraand the goodness that the made cotantaPBMT + meter model:<fail>i now was shown the holy soldierythat in his blood he married jesus christbut flying sees and sings the other which<fail><fail>Figure 13: Automatic translation of blind-test data fromDante?s Divine Comedy.531and translation do not always scan naturally whenread aloud by a person.
We trace such errors tothe fact that our lexical probabilities are context-independent.
For example, we have:P(S | off) = 0.39P(S* | off) = 0.61When we look at Viterbi alignments from theanalysis task, we see that when off is preceded bythe word far, the probabilities reverse dramatically:P(S | off, after far) = 0.95P(S* | off, after far) = 0.05Similarly, the probability of stressing at is 40%in general, but this increases to 91% when the nextword is the.
Developing a model with context-dependent probabilities may be useful not only forimproving generation and translation, but also forimproving poetry analysis itself, as measured by an-laysis task accuracy.Other potential improvements include the use ofprior knowledge, for example, taking word lengthand spelling into account, and exploiting incompletepronunciation dictionary information.Generation.
Evaluation is a big open problem forautomatic poetry generation?even evaluating hu-man poetry is difficult.
Previous suggestions for au-tomatic generation include acceptance for publica-tion in some established venue, or passing the Tur-ing test, i.e., confounding judges attempts to distin-guish machine poetry from human poetry.
The Tur-ing test is currently difficult to pass with medium-sized Western poetry.Translation.
The advantage of translation overgeneration is that the source text provides a coherentsequence of propositions and images, allowing themachine to focus on ?how to say?
instead of ?whatto say.?
However, translation output lattices offerlimited material to work with, and as we dig deeperinto those lattices, we encounter increasingly disflu-ent ways to string together renderings of the sourcesubstrings.An appealing future direction is to combine trans-lation and generation.
Rather than translatingthe source text, a program may instead use thesource text for inspiration.
Such a hybrid trans-lation/generation program would not be bound totranslate every word, but rather it could more freelycombine lexical material from its translation tableswith other grammatical and lexical resources.
In-terestingly, human translators sometimes work thisway when they translate poetry?many excellentworks have been produced by people with very littleknowledge of the source language.Paraphrasing.
Recently, e?f translation tableshave been composed with f?e tables, to makee?e tables that can paraphrase English into English(Bannard and Callison-Burch, 2005).
This makes itpossible to consider statistical translation of Englishprose into English poetry.AcknowledgmentsThis work was partially supported by NSF grant IIS-0904684.ReferencesC.
Bannard and C. Callison-Burch.
2005.
Paraphrasingwith bilingual parallel corpora.
In Proc.
ACL.P.
Brown, V. Della Pietra, S. Della Pietra, and R. Mercer.1993.
The mathematics of statistical machine trans-lation: Parameter estimation.
Computational linguis-tics, 19(2).B.
Diaz-Agudo, P. Gervas, and P. A. Gonzalez-Calero.2002.
Poetry generation in COLIBRI.
In Proc.
EC-CBR.P.
Gervas.
2001.
An expert system for the composition offormal Spanish poetry.
Journal of Knowledge-BasedSystems, 14:200?1.P.
Gervas.
2010.
Engineering linguistic creativity: Birdflight and jet planes.
Invited talk, CALC-10.J.
Graehl.
1997.
Carmel finite-state toolkit.http://www.isi.edu/licensed-sw/carmel.L.
Jiang and M. Zhou.
2008.
Generating Chinese cou-plets using a statistical MT approach.
In Proc.
COL-ING.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: open source toolkit forstatistical machine translation.
In Proc.
ACL.H.
Manurung, G. Ritchie, and H. Thompson.
2000.
To-wards a computational model of poetry generation.
InProc.
AISB?00 Symposium on Creative and CulturalAspects and Applications of AI and Cognitive Science.H.
Manurung.
2003.
An evolutionary algorithm ap-proach to poetry generation.
Ph.D. thesis, Universityof Edinburgh.Y.
Netzer, D. Gabay, Y. Goldberg, and M. Elhadad.
2009.Gaiku : Generating Haiku with word associations532norms.
In Proc.
NAACL Workshop on ComputationalApproaches to Linguistic Creativity.N.
Tosa, H. Obara, and M. Minoh.
2008.
Hitch Haiku:An interactive supporting system for composing Haikupoem.
In Proc.
International Conference on Enter-tainment Computing.M.
T. Wong and A. H. W. Chun.
2008.
Automatic Haikugeneration using VSM.
In Proc.
ACACOS.533
