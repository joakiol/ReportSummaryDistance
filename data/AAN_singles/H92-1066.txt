RAPID MATCH TRAIN INGFOR LARGE VOCABULARIESLarry Gillick, Barbara Peskin, and Robert RothDragon Systems, Inc.320 Nevada StreetNewton, Massachusetts 02160ABSTRACTThis paper describes a new algorithm for building rapidmatch models for use in Dragon's continuous peech recog-nizer.
Rather than working from a single representative tokenfor each word, the new procedure works directly from a setof trained hidden Markov models.
By simulated traversalsof the HMMs, we generate a collection of sample tokens foreach word which are then averaged together to build newrapid match models.
This method enables us to constructmodels which better reflect the true variation in word occur-rences and which no longer require the extensive adaptationneeded in our original method.
In this preliminary report,we outline this new procedure for building rapid match mod-els and report results from initial testing on the Wall StreetJournal recognition task.1.
INTRODUCTIONIn this paper, we report on a new algorithm for build-ing rapid match (prefiltering) models for Dragon's con-tinuous speech recognizer.
The rapid match module isintended to supply the recognizer with a relatively shortlist of word candidates at every point where the recog-nizer hypothesizes a new word may begin.
To accomplishthis, the rapid match module performs a quick but veryapproximate calculation using a short interval of acousticdata -  usually no more than 240 milliseconds of speech -and passes on to the recognizer a list of word candidateswhich can then be analyzed in detail.When the rapid match module for Dragon's continuousspeech recognizer was first presented nearly two yearsago \[1\], we evaluated its performance on a test corpus ofmammography reports involving a vocabulary of under1,000 words.
At that time, the performance of the mod-ule was more than adequate to meet the demands of thisrecognition task.
But as we move to larger vocabularies,the demands on rapid match have become greater at thesame time that its role in recognition has become morecrucial: if we hope to approach anything like real-timerecognition on a large-vocabulary task using moderatelypriced personal computers, the recognizer can entertain*This work was sponsored by the Defense Advanced ResearchProjects Agency and was monitored by the Space and Naval War-fare Systems Command under contract N00039-86-C-0307.word hypotheses for only a tiny fraction of its completevocabulary.
Thus, not only must prefiltering providemodels for more words, but those models must be capa-ble of making finer distinctions.Until now, we had been generating rapid match modelsbased on a single artificially constructed token represent-ing the "average" behavior of each word.
But workingfrom a single token made it impossible to adequatelymodel potential variability, and extensive adaptation ofthe models was necessary both to estimate variances andto adjust model parameters to new speakers.
In ournew training procedure, we instead build word modelsdirectly from hidden Markov models for each speaker'svocabulary.
As reported below, these new models haveallowed us to significantly improve prefiltering perfor-mance.After a brief review of the rapid match module in thenext section, we go on to describe in detail our new pro-cedure for building rapid match models.
Results frompreliminary testing of these models using the Wall StreetJournal recognition task are reported in section 4.
Weclose with a discussion of the future directions we hopeto explore.2.
REV IEW OF THERAP ID  MATCH MODULEThe main job of the rapid match module is to providethe recognizer with a short list of words that may be-gin at any particular time by looking at speech databeginning at that time and extending only a brief pe-riod into the future.
To accomplish this, we first con-struct "smooth frames" of speech by taking a (possiblyweighted) average of several frames of acoustic data.
Forour continuous peech recognition, we have been usingthree smooth frames of information, each obtained byaveraging together four successive 20-millisecond framesof speech.
Such smooth frames have the dual benefit ofcondensing the acoustic information into a much smallernumber of parameters and doing so in a way that re-duces the sensitivity to potential variation in phonemeduration.
The number of speech frames used in calcu-328lating a smooth frame, the number of smooth frames,and the offset from one smooth frame to the next are alladjustable parameters in the rapid match module.As the smooth frames are computed, they are scoredagainst models for word start clusters, which are groupsof words whose beginnings are acoustically similar.These word start groups are formed automatically usinga specialized clustering algorithm starting from smoothmodels for the words in the vocabulary.
Clearly, thisclustering of words into acoustically-similar groupings -a step performed uring the rapid match training - re-sults in further efficiencies at recognition time.
Eachword start cluster is represented by a sequence of prob-ability distributions, one for each smooth frame of themodel.
We currently assume that each probability den-sity is a product of double exponential distributions, onecorresponding to each of the smoothed acoustic param-eters.
Thus each smooth frame of a word start modelis determined by a collection of (mean, deviation)-pairs.We reduce run-time calculations still further by allowingseveral word start clusters to share the same probabilitydensities for some of their smooth frames.
This secondlevel of clustering, like the first, is performed automat-ically as part of the training process and results in acollection of "position clusters" used for the spelling ofall word start groups.Each word of the vocabulary may belong to several dif-ferent word start clusters, depending on the contextin which the word finds itself.
We currently generatefour models for each word, based on whether the wordemerges from silence or speech and whether it is followedby silence or speech.
The number of smooth frames rep-resenting a word start group is determined by the lengthsof its members.
In our current implementation, mostwords have models filling all three smooth frames, butsome very short words (most commonly function wordslike "the", "to", and "of' when embedded in continuousspeech) receive models with fewer frames.During recognition, as smooth frames are generated fromincoming acoustic data, they are scored against he var-ious word start clusters using the negative log likelihoodfor the probability models for each group.
The score fora word start group is computed as an average over thescores from each of the smooth frames in its model.
Forevery word start group scoring within a certain thresh-old, the words belonging to the group are looked up,possible duplicates are removed, and a language modelscore for each word is added to its word start score.
Thelist of all words whose combined score falls within a sec-ond threshold is then passed on to the recognizer for amore complete analysis.For more detaiis on the rapid match module, consult \[1\].3.
BU ILDING BETTER MODELSThe process of creating word start groups begins fromsample tokens for the words in the recognizer's vocab-ulary.
The speech frames are averaged together intosmooth frames, just as in the rapid match recognitionprocess, and these smoothed versions are then clusteredinto word start groups.Until now, this process began from a single token repre-senting the "average" behavior of each word.
Dragon'sword models are built up from basic building blockscalled phonemes-in-context, or PICs.
The representa-tive tokens used by the rapid matcher were constructedby concatenating PIC tokens built by means of a lin-ear alignment routine.
Through linear stretching andshrinking operations, examples of the desired phonemewere normalized to a common length and then the acous-tic parameters averaged together on a frame-by-framebasis.
(See \[2\] for a more detailed description of PICmodels and the construction of aligned tokens.)
Unfor-tunately, in the course of alignment, any usable informa-tion about the variability of frame parameters i lost.Although the models formed in this way were sufficientfor a task like the marnrnography study, the strategysuffers from three main deficiencies:Because ach wordthere is no way toparameters.
Suchduring adaptationmodel is based on a single token,measure the variability of modelestimates must be incorporatedof the models.Because the token is constructed from a linear align-ment of phonemic units, the model rigidly expects aparticular phoneme in a particular frame and so isrelatively intolerant of variation in phoneme dura-tion.
While the alignment process involves blendingdifferent behaviors within the phonemic unit, therepresentation does not allow for mixing frames in-volving different PICs.
Averaging together severalsuccessive acoustic frames to create the "smoothframes" used in rapid match softens this effect, butcannot eliminate it.Finally, because the token is based on the referencespeaker's models, extensive adaptation is necessaryto adjust the model parameters to other speakers.And while adaptation can successfully modify valuesfor the (mean, deviation)-pairs representing wordstart clusters, it cannot alter the spelling of wordstart clusters by position clusters nor the assignmentof words to word start groups.
Both of these steps329are performed once and for all based On the referencespeaker's models.Our new method for building rapid match models over-comes these difficulties by working directly from HMMsrepresenting the words for each speaker's vocabulary.In the new rapid match training, we begin from thephonemic spelling of each word and, using the speaker'sown models, unpack the sequence of nodes representingeach PIC.
We then generate a collection of sample to-kens by simulated traversals of this node sequence.
Ateach node, we determine the duration of the stay by arandom draw from a double exponential duration dis-tribution and then, for each of the resulting number offrames, generate parameter values by independent drawsfrom the output distribution for the node.
The result-ing collection of sample tokens exhibits all the variabil-ity one would expect o see in actual occurrences of theword.
These tokens are then converted to their smoothedforms, the smoothed versions averaged together smoothframe by smooth frame to obtain both means and devi-ations for the new word model, and the usual clusteringalgorithm can then be followed.Of course, the sample tokens generated by independentdraws from the output distributions are probably notthemselves accurate representations of actual word oc-currences; we would expect a high degree of correlationbetween successive frames in actual speech.
But becausethese samples are processed through two rounds of aver-aging - the first combining successive acoustic framesinto a single smooth frame and the second averagingsmooth frames from the many sample tokens - we expectthe resulting means to be fairly well estimated.
On theother hand, our assumption of independence of framesprobably leads to an underestimate of the true framedeviations.
For example, in the extreme (and purely hy-pothetical) case that the four successive acoustic frameswere in fact identical in actual speech, our random drawswould underestimate he deviations by a factor of two.In general, we expect o be off by a considerably smallerfactor, but we have found that performance of our newmodels is improved if we scale up all our estimated e-viations by a factor in the range 1.3-1.5.4.
IN IT IAL  RESULTS ON THEWALL  STREET JOURNAL TASKOur goal is to ensure that the correct word candidateis returned by the rapid matcher in the list of the top100-200 words.
We do not require that it be the highestranked - the recognizer will do the hard work of analyz-ing the top candidates in detail - but it is essential thatthe correct candidate not be excluded from this analysis.Therefore, our evaluation of the new rapid match train-ing program concentrates on performance in this range.In order to assess how close we've come to meetingour goal, we have been using an evaluation packagewhich ranks the word candidates nominated by the rapidmatcher in any given speech frame.
By running the rec-ognizer in a mode where it knows the correct ranscrip-tion for a text, we can obtain a segmentation of each ut-terance, marking the frame in which each word is mostlikely to begin.
We then use the evaluation package tolook at what rank the correct word has in the list ofcandidates passed on to the recognizer in that frame.To provide an initial reading on the new rapid matchtraining and to help set clustering thresholds, we firstlooked at its performance on the mammography task.While we did not expect the new routine to improvenoticeably on our earlier performance - it was, after all,a relatively easy task involving a limited vocabulary andrecorded by our reference speaker - it was reassuringto find that the new routine, like the old, returned thecorrect word in the list of the top 100 candidates over99% of the time for a test set roughly 4300 words long,and by the top 200 words, the correct candidate failedto appear on the list only about 1 time in 1000.We then moved on to the more challenging Wall StreetJournal task.
Here we built new rapid match models forthe 5K verbalized punctuation vocabulary for 5 of our12 speakers, ranging from our worst performer to ourbest, and compared them to the original models whichhad already been adapted to each speaker.
(For a de-scription of our overall performance on the Wall StreetJournal task, see the companion article \[3\].)
The resultsare summarized in Table 1, which reports what percentof the time the correct word was included in the wordcandidate list returned by rapid match, as a function ofthe length of the list.
The test sets involved about 40sentences totaling somewhat over 700 words per speaker.They were drawn from the 5K verbalized punctuationspeaker-dependent Wall Street Journal corpus.
In allcases the new models improved significantly over the old,usually cutting the error rate by 25-50%.Although the new training method obviates the need foradaptation of models, we were curious about whetheradaptation would further improve the performance ofthe rapid match system.
We therefore have begun ex-perimenting with adapting our new rapid match models.Preliminary results indicate that we can expect to gainabout another percentage point improvement even aftera single round of adaptation.
A sample is given in Table2, for speaker 00A.We have also begun building new rapid match models for330speaker \ [ l i s t \ [I.D.
length10000A 15020025010000C 1502OO250100001 15020025O100203 1502OO25O100432 1502O0250old newmodels models75.3 82.182.4 86.984.5 90.587.2 91.979.3 83.285.6 88.488.5 90.489.8 91.988.2 92.890.8 94.293.0 95.294.5 95.985.4 91.889.3 93.991.0 95.292.1 95.987.6 92.491.5 94.893.5 96.794.6 97.5Table 1: Percentage of time correct word returned byrapid match, by list length, for Wall Street Journal 5Ktask.the 20K vocabulary.
Results for a sampling of speakerson the 20K task are given in Table 3.
Clearly the dif-ficulty of the rapid match task grows significantly withvocabulary size.
However, it should be noted that whilethe job of creating sufficiently good models grows enor-mously as the vocabulary grows, the burden at recogni-tion time does not: the number of word start clustersgrows much more slowly than the vocabulary size bothbecause we allow the clustering thresholds to increasegradually with vocabulary size and because large vocab-ularies permit more sharing of cluster models.
For ex-ample, the number of word start clusters for the mam-mography task (with a vocabulary of 860 words) wasabout 1500, for the 5K Wall Street Journal task about5000 clusters, and for the 20K vocabulary about 6000clusters.
(Recall that each word is given four context-determined models, so the actual number of word modelsis four times the vocabulary size.
)A word should be said about the relationship betweenresults on these evaluation tests and actual recognitionperformance.
We have found that even if a word has apoor rank in the frame in which the recognizer ideallyexpects the word to begin, a good score in a neighbor-ing frame will often allow the recognizer to get the wordlist I beforelength adaptation100 82.1150 86.9200 90.5250 91.9afteradaptation83.988.390.892.7Table 2: Effect of one round of adaptation on rapidmatch models for 00A.right.
On the other hand, if a word fails to be passed onto the recognizer within a small window around the opti-mal word start, performance will suffer.
Being deprivedof the correct word, the recognizer is forced to follow afalse path through the web of sentence hypotheses, usu-ally resulting in two or three word errors.
Thus, evensmall improvements to the rapid match module can havea significant impact at recognition time.
As an exampleof the relationship between the rapid match evaluationresults and actual recognition performance, Table 4 givesrapid match results for both old and new training modelsfor our in-house speaker SAL on the Wall Street Journal5K test set, along with word error rates in the relatedrecognition tests.list I speakerlength 00A \[ 203 \[ 432200 77.5 90.2 90.1400 84.0 93.7 93.0600 87.2 95.0 94.5800 89.5 96.0 95.51000 91.4 96.8 96.6Table 3: Percentage of time correct word returned byrapid match, for Wall Street Journal 20K task.5.
FUTURE PLANSThe work described above is only the beginning of a long-term project to improve the performance of Dragon'srapid match algorithm for continuous peech recogni-tion.
Most immediately, we plan to work at tuning themany parameters involved in rapid match training.
Inthe results cited above, we deliberately chose parametersettings as close as possible to those used in our originaltraining routine, using, for example, three smooth framesof length four with each of the four acoustic frames givenequal weight.
But there is no reason to believe that thesevalues optimize performance.
In our isolated word rec-ognizer, in contrast, rapid match uses five smooth frames331Rapid Match Perrorrnancelist oldlength models100 83.1200 90.0300 92.0400 93.3500 94.1newmodels91.194.996.697.498.1Recognition ResultsOLD MODELSavg#words  word error avg#wordsreturned rate returned122 17.1 106161 13.2 140236 11.4 207348 10.6 305458 9.4 400NEW MODELSword errorrate10.59.47.87.27.0Table 4: Comparison of rapid match performance andrecognition results.REFERENCES1.
L. Gilhck and R. Roth, "A Rapid Match Algorithmfor Continuous Speech Recognition," Proceedings ofDARPA Speech and Natural Language Workshop, Hid-den Valley, Pennsylvania, June 1990, pp.
170-172.2.
P. Bamberg amd L. Gilfick, "Phoneme-in-Context Mod-eling for Dragon's Continuous Speech Recognizer," Pro-ceedings of DARPA Speech and Natural Language Work-shop, Hidden Valley, Pennsylvania, June 1990, pp.
163-169.3.
J. Baker et al, "Large Vocabulary Recognition of WallStreet Journal Sentences at Dragon Systems," this Pro-ceedings.4.
L. Bahl, R. Bakis, P.V.
deSouza, and R.L.
Mercer, "Ob-taining Candidate Words by Polling in a Large Vocab-ulary Speech Recognition System," ICASSP 88, NewYork City, April 1988.5.
X.L.
Aubert, "Fast Look-Ahead Pruning Strategies inContinuous Speech Recognition," ICASSP 89, Glasgow,May 1989.6.
L. Bahl, P.S.
Gopalakrishnan, D. Kanevsky, D. Na-hamoo, "Matrix Fast Match: A Fast Method for Iden-tifying a Short List of Candidate Words for Decoding,"ICASSP 89, Glasgow, May 1989.computed from overlapping windows of length six withweighting coefficients 1, 4, 6, 6, 4, 1.
We plan to ex-periment with different window sizes and weights, withspecial attention to the benefits of reading more deeplyinto a word.In the past year, Dragon has moved from its original setof 8 signal-processing parameters to a set of 32, adding12 cepstral and 12 difference cepstral parameters.
Therapid match models described above used only the origi-nal 8 parameters, but we should be able to improve per-formance by using information from all 32.
To keep therecognition-time computation low, we plan to exploreways of distilling the 32 parameters down to a smallbut effective collection of smooth parameters, possiblyby means of principal component techniques.
We havealso begun using tied mixture models for our continu-ous speech recognition (see \[3\]) and the token generationwhich forms the heart of our new training strategy mustbe modified to work for these distributions.
We also hopeto move from the naive hypothesis of the independenceof adjacent speech frames to a token generation systemcapable of incorporating trends across frames.We are encouraged by the significant gains produced bythe first stages of our new rapid match training programand look forward to further improvements as these ad-ditional features are incorporated.332
