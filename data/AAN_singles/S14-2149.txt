Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 838?842,Dublin, Ireland, August 23-24, 2014.XRCE: Hybrid Classification for Aspect-based Sentiment AnalysisCaroline Brun, Diana Nicoleta Popa, Claude RouxXerox Research Centre Europe6, chemin de Maupertuis38240 Meylan, France{caroline.brun, diana.popa, claude.roux}@xrce.xerox.comAbstractIn this paper, we present the system wehave developed for the SemEval-2014Task 4 dedicated to Aspect-Based Senti-ment Analysis.
The system is based ona robust parser that provides informationto feed different classifiers with linguis-tic features dedicated to aspect categoriesand aspect categories polarity classifica-tion.
We mainly present the work whichhas been done on the restaurant domain1for the four subtasks, aspect term and cat-egory detection and aspect term and cate-gory polarity.1 IntroductionAspect Based Sentiment Analysis aims at discov-ering the opinions or sentiments expressed by auser on the different aspects of a given entity ((Huand Liu, 2004); (Liu, 2012)).
A wide range ofmethods and techniques have been proposed to ad-dress this task, among which systems that use syn-tactic dependencies to link source and target of theopinion, such as in (Kim and Hovy, 2004), (Bloomet al., 2007), or (Wu et al., 2009).
We have devel-oped a system that belongs to this family, (Brun,2011), as we believe that syntactic processing ofcomplex phenomena (negation, comparison, ...)is a crucial step to perform aspect-based opinionmining.
In this paper, we describe the adaptationswe have made to this system for SemEval, and theway it is applied to category and polarity classifi-cation.This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/1We have not performed any domain adapation for thelaptop corpus and only submitted a run for the subtask 1, termdetection.2 Description of the SystemIn this section, we describe the different compo-nents of the system.2.1 Existing SystemIn order to tackle the Semeval?14 Task 4, (Pon-tiki et al., 2014), we used our existing aspect-based opinion detection system.
The opinion de-tection system we built relies on a robust deepsyntactic parser, (Ait-Mokhtar et al., 2001), as afundamental component, from which semantic re-lations of opinion are calculated.
Parsing hereincludes tokenization, morpho-syntactic analysis,tagging which is performed via a combination ofhand-written rules and HMM, Named Entity De-tection, chunking and finally, extraction of depen-dency relations between lexical nodes.
These re-lations are labeled with deep syntactic functions.More precisely, a predicate (verbal or nominal) islinked with what we call its deep subject (SUBJ-N), its deep object (OBJ-N), and modifiers.
Inaddition, the parser calculates more sophisticatedand complex relations using derivational morpho-logic properties, deep syntactic properties (subjectand object of infinitives in the context of controlverbs), and some limited lexical semantic coding.Syntactic relations already extracted by ageneral dependency grammar, lexical informationabout word polarities, sub categorization informa-tion and syntactic dependencies are all combinedwithin our robust parser to extract the semanticrelations.
The polarity lexicon has been builtusing existing resources and also by applyingclassification techniques over large corpora, whilethe semantic extraction rules are handcrafted, see(Brun, 2011) and (Brun, 2012) for the completedescription of these different components.
Thesystem outputs a semantic dependency calledSENTIMENT which can be binary, i.e.
linkingopinionated terms and their targets, or unary,i.e.
just the polar term in case the target of the838opinion hasn?t been detected.
For example, whenparsing I was highly disappointed by their serviceand food., the systems outputs the followingdependencies:SUBJ N(disappointed,food)SUBJ N(disappointed,service)OBJ N(disappointed,I)MANNER PRE(disappointed,highly)SENTIMENT NEGATIVE(disappointed,service)SENTIMENT NEGATIVE(disappointed,food)In this system, aspects terms are not explic-itly extracted, however all non-polar arguments ofthe SENTIMENT dependency are potential aspectterms.
Moreover, this system considers only posi-tive and negative opinions, but does not cover theneutral and conflict polarities.2.2 System AdaptationThe opinion detection system described in theprevious section has been adapted for the Se-mEval2014 Task4, in two ways: some lexical ac-quisition has been performed in order to detect theterms of the domain, and some rules have been de-veloped to detect multi-word terms and to outputsemantic dependencies associating their polarityto terms and categories.2.2.1 Lexical Enrichment and TermDetectionAs said before, the existing system encodes a rea-sonable amount of polar vocabulary.
However, asthe task implies domain knowledge to detect theterms, we have first extracted the terms from thetraining corpus and encoded their words into ourlexicons, assigning to them the semantic featuresfood, service, ambiance and price.
We have thenextended the list with Wordnet synonyms.
To im-prove coverage, we have also extracted and fil-tered food term lists from Wikipedia pages and en-coded them.
More precisely, the list of food termshas been extracted from the Wikipedia ?Food Por-tal?, from the category ?Lists of foods?2.
At theend of this process, our lexicon has the followingcoverage: Polar words: 1265 negative, 1082 posi-tive and Domain words: 761 food words, 31 pricewords, 105 ambiance words, 42 service words.In order to detect the terms, some local grammarrules (based on regular expressions) have been de-veloped taking into account the lexical semantic2http://en.wikipedia.org/wiki/Category:Lists of foodsinformation encoded in the previous step.
Theserules detect the multi-words terms, e.g.
pas-trami sandwiches, group them under the appropri-ate syntactic category (noun, verb) and associatethem with the corresponding lexical semantic fea-ture, food, service, ambiance, price.
In addition tothis, in order to prepare the aspect category clas-sification (c.f.
section 2.3.3), a layer of semanticdependencies has been added to the grammar: Ifa domain term is detected in a sentence, a unarydependency corresponding to its category (FOOD,SERVICE, PRICE, AMBIANCE) is built.2.2.2 Grammar Adaptation for PolarityDetectionThe English grammar, which had been previouslydeveloped to detect sentiments, has also beenadapted in order to extract the opinions associatedto the terms and categories detected at the previousstep.If an aspect term is the second argument of aSENTIMENT relation, 2 dependencies, one for theterm (OPINION ON TERM) and one for the corre-sponding category (OPINION ON CATEGORY) arebuilt.
They inherit the polarity (positive or nega-tive) of the SENTIMENT dependency.
If these de-pendencies target the same term and category andif they have opposite polarity, they are modified inorder to bear the feature ?conflict?.Then, if a sentence contains a term andif no SENTIMENT dependency has been de-tected, the OPINION ON TERM and OPIN-ION ON CATEGORY are created with the polarity?neutral?.
Finally, if no terms have been de-tected in a sentence, there are two cases: (1)a SENTIMENT dependency has been detectedsomewhere in the sentence, the dependencyOPINION ON CATEGORY(anecdote/misc), iscreated with the corresponding polarity (positiveor negative); (2) no SENTIMENT dependencyhas been detected, the dependency OPIN-ION ON CATEGORY(anecdote/misc), is createdwith polarity ?neutral?.The dependency OPINION ON TERM links theterms to their polarities in the sentences and servesas input for the subtasks 1 and 3.2.3 Classification2.3.1 KiF (Knowledge in Frame)The whole system, training and prediction, hasbeen implemented in KiF (Knowledge in Frame),a script language that has been implemented into839the very fabric of the rule-based Xerox Incremen-tal Parser (XIP).
KiF offers a very simple way tohybridize a rule-based parser with machine learn-ing technique.
For instance, a KiF function, whichevaluates a set a features to predict a class, can becalled from a rule, which could then be fired alongthe output of that function.
KiF is a multi-threadedprogramming language, which is available for allplatforms (Windows, Mac OS, Linux).
It pro-vides all the necessary objects (strings, containersor classes) and many encapsulations of dynamiclibraries from different C programs such as classi-fiers (liblinear and libsvm), database (SQLite), orXML (libxml2), which can be loaded on the fly.All internal XIP linguistic structures are wrappedup into KiF objects.
For example, linguistic fea-tures are available as maps, which can be modi-fied and re-injected into their own syntactic nodes.The language syntax is a mix between Java (typesare static) and Python (in the way containers arehandled), but provides many implicit conversionsto avoid code overloading with too many func-tions.
KiF allows for an efficient integration ofall aspects of linguistic analysis into a very sim-ple framework, where XML documents can be an-alyzed and modified both with linguistic parsingand classifiers into a few hundred lines of code.2.3.2 General MethodologyWe focus on four main tasks: detecting the as-pect terms and aspect categories and their corre-sponding polarities.
While the detection of aspectterms and their corresponding polarities occurs atthe grammar level, for the detection of aspect cate-gories and their corresponding polarities we makeuse of the liblinear library (Fan et al., 2008) totrain our models.
We train one classifier for detect-ing the categories and further, for each categorywe train a separate classifier for detecting the po-larities corresponding to that particular category.For both settings, we use 10-fold cross-validation.The two modules for aspect category classificationand aspect category polarity classification are de-scribed in details further.2.3.3 Aspect Category ClassificationThe sentence classification module is used to as-sign aspect categories to sentences.
For each sen-tence, the module takes as input features the bagof words in the sentence as well as the informationprovided by the syntactic parser.
The output con-sists of a list of categories corresponding to eachsentence.In the pre-processing stage stop words are re-moved (determinants, conjunctions).
Further, weuse the L2-regularized logistic regression solverfrom the liblinear library to train a model.
Thefeatures considered are the word lemmas from thesentence along with their frequencies (term fre-quency).
Apart from this, the information pro-vided by the rule based component is also takeninto account to increase the term frequency forterms belonging to the detected categories.Such information can consist of: dependenciesdenoting the category to which a detected aspectterm belongs (Food, Service, Price, Ambiance)and dependencies denoting the opinions on thedetected aspect terms and categories (OPIN-ION ON CATEGORY, OPINION ON TERM).
Forexample for the following sentence: ?Fab-ulous service, fantastic food, and a chilledout atmosphere and environment?, the salientdependencies produced by the syntactic parser are:FOOD(food), AMBIANCE(atmosphere),SERVICE(service), AMBIANCE(environment),OPINION ON CATEGORY POSITIVE(food),OPINION ON CATEGORY POSITIVE(service),OPINION ON CATEGORY POSITIVE(ambiance),OPINION ON TERM POSITIVE(food),OPINION ON TERM POSITIVE(service),OPINION ON TERM POSITIVE(atmosphere).This yields the following features having anincrease in their frequencies: food (+3), service(+3), atmosphere (+2), environment (+1), am-biance (+1).Once the logistic regression is performed, eachcategory is predicted with a certain probability.Since in one sentence there may be entities that re-fer to different categories, we set a threshold withrespect to the probability values to be taken intoaccount.
We have tried different approaches to setthis threshold.
The best results on the training andtrial data were obtained with a threshold of 0.25,(i.e.
we kept only the categories with a probabilityover 0.25).2.3.4 Aspect Category Polarity ClassificationThe approach to predict the polarity for each cate-gory is similar to the one predicting the categoriesfor each sentence, with some differences as willbe further detailed.
The classification uses for fea-tures, the bag of words (term frequency), but also840the polarity provided by XIP by the following de-pendencies: OPINION ON CATEGORY and SEN-TIMENT.
Whenever these dependencies are de-tected, a feature is added to the classification ofthe form polarity category.
Thus for the previ-ous example sentence: Fabulous service, fantasticfood, and a chilled out atmosphere and environ-ment, the additional dependencies considered areSENTIMENT POSITIVE(atmosphere, chilled out),SENTIMENT POSITIVE(food, fantastic), SENTI-MENT POSITIVE(service, Fabulous).
After map-ping back the terms to their corresponding cate-gories, the added features are: positive ambiance,positive food and positive service.
Since the de-pendency OPINION ON CATEGORY is also de-tected by the parser for these categories, eachof the above mentioned features will have a fre-quency of 2 in this case.
Moreover, the polarityalone is also added as a feature.
The training isperformed using the L2-regularized L2-loss sup-port vector classification solver from the same li-brary (liblinear) and a model is generated for eachcategory.
Thus, depending on the categories de-tected within a certain sentence, the correspond-ing model is used to make the prediction regardingtheir polarities.
The classifier?s output representsthe predicted polarity for one given category.3 EvaluationThe corpus used for evaluating the system con-tains 800 sentences, 1134 aspect term occurrences,1025 aspect category occurrences, 5 different as-pect categories and 555 distinct aspect terms.
Allthese belong to the restaurant domain.3.1 Terms and Category DetectionWhen evaluating aspect terms and aspect cate-gories detection, three measures were taken intoaccount: precision, recall and the f1-measure.For both aspect term extraction and aspect cat-egory detection, the baseline methodologies arepresented in (Pontiki et al., 2014).
Table 1 showsthe results obtained using our approach as com-pared to the baseline for aspect term detection,whereas Table 2 outlines the results regarding as-pect category detection in terms of the previouslymentioned measures.Furthermore, it is interesting to notice the in-crease in performance obtained by combining thebag-of-words features with the output of the parseras opposed to just using the bag-of words.
TheseMethod Precision Recall F-MeasureBaseline 0.627329 0.376866 0.470862XRCE 0.862453 0.818342 0.839818Table 1: Aspect term detection.Method Precision Recall F-MeasureBaseline 0.637500 0.483412 0.549865BOW 0.77337 0.799024 0.785988XRCE 0.832335 0.813658 0.822890Table 2: Aspect category detection.differences are outlined for aspect category detec-tion in Table 2, where BOW denotes the systemusing the same settings, but just the bag-of-wordsfeatures and XRCE denotes the submitted systemwhere the bag-of-words features are augmentedwith parser output features.For both tasks of aspect term and aspect cate-gory detection, our system clearly outperforms thebaseline, resulting in being ranked among the first3 in the competition for the restaurant corpus.3.2 Terms and Category Polarity DetectionSimilarly, Table 3 shows the results in terms ofaccuracy on aspect term polarity detection and onaspect category polarity detection.
Here, baselinemethodologies are similar to the ones used for as-pect category detection and also described in (Pon-tiki et al., 2014).
Again, our system ranks high inthe competition, achieving an overall accuracy of0.77 for aspect term polarity detection and 0.78 foraspect category polarity detection.
Furthermore, acomparison is also made between the current sys-tem and one that, using the same settings, wouldnot take into account the features provided by theparser (BOW).
The results emphasize the impor-tance of using the merged version.Method Task AccuracyBaseline Term polarity 0.552239XRCE Term polarity 0.776895Baseline Category polarity 0.563981BOW Category polarity 0.681951XRCE Category polarity 0.781463Table 3: Aspect term and aspect category polarity.841Label Precision Recall F-measureconflict NaN 0 NaNnegative 0.7857 0.7296 0.7566neutral 0.5833 0.3214 0.4145positive 0.7998 0.9272 0.8588Table 4: Aspect term polarity (2).Label Precision Recall F-measureconflict 0.5333 0.1538 0.2388negative 0.726 0.6802 0.7023neutral 0.5119 0.4574 0.4831positive 0.8343 0.9117 0.8713Table 5: Aspect category polarity (2).3.3 Error AnalysisThe results obtained with our system are unar-guably competitive, but some remarks can bemade regarding the most frequent causes of er-rors.
In the task of aspect category classification,the choice of the threshold (0.25) may have con-stituted a factor impacting the performance.
Inthe task of aspect term detection, the lexical cov-erage is one of the factors to explain the differencein performance between training/trial data and testdata.Table 4 contains the results obtained in termsof precision, recall and F-measure for each of thepossible polarities for terms (positive, negative,neutral and conflict) and similarly does Table 5for category polarities.
In both cases we notice aclear decrease for these measures when predictingthe conflict and neutral classes, with a higher de-crease in the case of aspect term polarity detection.This can be explained by the fact that the syntacticparser was primarily customized to detect the neg-ative and positive labels.
This obviously had animpact on the final results as the information fromthe parser constituted some of the input featuresfor the classification.4 ConclusionThe combination of a symbolic parser, customizedwith specialized lexicons, with SVM classifiersproved to be an interesting platform to implementa category/polarity detection system.
The sym-bolic parser on the one hand provides a versatilearchitecture to add lexical and multi-words infor-mation, augmented with specific rules, in order tofeed classifiers with high quality features.
How-ever, some work will be needed to improve per-formances on the neutral and conflict polarities,which rely less on specific words, than on a moreglobal interpretation of the content.AcknowledgementsWe would like to thank the Semeval task 4organizers, as well as our colleague, VassilinaNikoulina, for her help on this project.ReferencesSalah Ait-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2001.
A multi-input dependency parser.
InIWPT.Kenneth Bloom, Navendu Garg, and Shlomo Argamon.2007.
Extracting appraisal expressions.
In In HLT-NAACL 2007, pages 308?315.Caroline Brun.
2011.
Detecting opinions using deepsyntactic analysis.
In RANLP, pages 392?398.Caroline Brun.
2012.
Learning opinionated patternsfor contextual opinion detection.
In COLING, pages165?174.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
Journal of Ma-chine Learning Research, 9:1871?1874.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In KDD, pages 168?177.Soo-Min Kim and Eduard Hovy.
2004.
Determin-ing the sentiment of opinions.
In Proceedings ofthe 20th International Conference on ComputationalLinguistics, COLING ?04, Stroudsburg, PA, USA.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Synthesis Lectures on Human Language Tech-nologies.
Morgan & Claypool Publishers.Maria Pontiki, Dimitrios Galanis, John Pavlopou-los, Harris Papageorgiou, Ion Androutsopoulos, andSuresh Manandhar.
2014.
Semeval-2014 task 4:Aspect based sentiment analysis.
In InternationalWorkshop on Semantic Evaluation (SemEval).Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.2009.
Phrase dependency parsing for opinion min-ing.
In EMNLP, pages 1533?1541.
ACL.842
