Head-Driven Generation with HPSGGraham Wi lcock*Centre  for Computat iona l  LinguisticsUnivers i ty  of Manchester  Inst i tuteof Science and TechnologyPO Box 88, Manchester  M60 1QDUni ted K ingdomgraham?ccl, umi st. ac.
ukYu j i  MatsumotoGraduate  School of In format ion ScienceNara Inst i tute  of Science and Technology8916-5 Takayama,  Ikoma, Nara  630-01Japanmatsu~is, aist-nara, ac.
j pAbst ractAs HPSG is head-driven, with clear semantic heads,semantic head-driven generation should be simple.We adapt van Noord's Prolog generator for use withan HPSG grammar in ProFIT.
However, quantifiersand context factors are difficult to include in head-driven generation.
We must adopt recent heoreticalproposals for lexicalized scoping and context.
Withthese revisions, head-driven generation with HPSGis not so simple, but it is possible.1 In t roduct ionA natural approach to generation with Head-drivenPhrase Structure Grammar (Pollard and Sag, 1994)is to use a head-driven algorithm.
HPSG is head-driven not only syntactically, but also semantically.While the Head Feature Principle requires identityof major syntactic features between a phrase andits syntactic head daughter, the Semantics Principle(in various formulations) requires identity of majorsemantic features between a phrase and its seman-tic head daughter.
Since the semantic head is veryclearly defined in HPSG, semantic head-driven gen-eration should be easy to implement.Efficient head-driven generation algorithms, suchas BUG, SHD and CSHD, have been presented asProlog algorithms for use with DCG grammars.
InSection 2 we briefly describe how an HPSG grammarcan be implemented as a PSG with typed featurestructures, which can be compiled into a DCG bythe ProFIT system.
In this way, HPSG grammarscan be used with the existing Prolog algorithms.Such a combination of head-driven grammar andhead-driven generator works well if the semantics istrictly head-driven.
However, in Section 3 we showthat if we implement the HPSG textbook semantics,with quantifier storage and contextual backgroundconditions, the notion of semantic head becomes un-clear and this approach no longer works.
In fact,head-driven generation of even simple phrases uch" Visiting researcher of Sharp Corporation, Japan.as "Kim walks" (Chapter 1 of the HPSG textbook)raises fundamental difficulties.To use a semantic head-driven algorithm, we mustadopt recent HPSG proposals to put quantifier storeand contextual background inside semantic heads.We summarize these proposals in Section 4, andshow how they can be implemented in the ProFITHPSG grammar.
We conclude that head-driven gen-eration with HPSG is possible, but there are somedifficulties in implementing this approach.2 Head-Dr iven  Generat ionWe assume that generation starts from logical forms,which may be represented for HPSG as typed featurestructures.
Logical form is not a separate linguisticlevel in HPSG, but is equated with semantic ontent.In this section, we take the starting logical form forgeneration to be a semantic feature structure whichwill be identical to the CONTENT feature of thetop-level HPSG sign to be generated.2.1 Semantic headsHead-driven generation algorithms are based on theidea that most grammar ules have a semantic headdaughter whose logical form is identical to the logi-cal form of the mother.
The bottom-up generation(BUG) algorithm of van Noord (1990) requires everyrule to have such a head (except lexical entries).
Thesemantic head-driven (SHD) algorithm of Shieber ethi.
(1990) relaxes this, dividing rules into chain ruleswith such a head (processed bottom-up), and non-chain rules (processed top-down).
The chart-basedsemantic head-driven (CSHD) algorithm 1of Harunoet al (1996) increases efficiency by using a chart toeliminate recomputation of partial results.Head-driven bottom-up generation is efficient asit is geared both to the input logical form (head-driven) and to lexical information (bottom-up).
Itis good for HPSG, which is highly lexicalist and has1For simplicity we illustrate the approach with BUG.
AProFIT/HPSG framework using the CSHD algorithm is de-scribed by Wilcock and Matsumoto (1996).1393'HFP' := synsem!loc!cat!head!HF khd_dtr!synsem!loc!cat!head!HF.
'SemP' := synsem!loc!cont!Cont khd_dtr!synsem!loc!cont!Cont.
'SemP'(adjunct) := synsem!loc!cont!Contadj_dtr!synsem!loc!cont!Cont.hd_ph := <hd_ph k @'HFP' ksynsem!loc!cat!val!comps!
Q.hd_nexus_ph := <hd nexus_ph k @hd ph k @'SemP'.hdsub j_ph  := <hd_subj_ph k @hd_nexus_ph k@'VALP'(spr) k @'VALP'(comps)synsem!loc!cat!val!subj!\[\].hd_comp_ph := <hd_comp_ph k @hd_nexus_ph k@'VALP'(subj) & @'VALP'(spr).
@hd_subj_phk phon!PO-PNhd_dtr!
(Head ksynsem!loc!ca~!val!subj!\[S\]) ksubj_dtr!
(Subj k synsem!S)---> \[Head & <phrase k phon!PI-PN,Subj k <phrase k phon!P0-Pl\].
@hd_comp_phk phon!P0-PN khd_dtr!
(Head &synsem!loc!cat!val!comps!\[C\]) kcomp_dtrs!\[Comp k synsem!C\]---> \[Head & <word a phon!P0-Pl,Comp a <phrase k phon!PI-PN\].Figure 1: Principles, Phrase Types, Schemataa clear definition of semantic head: in head-adjunctphrases, the adjunct daughter is the semantic head;in other headed phrases, the syntactic head daughteris the semantic head.
In both cases, the SemanticsPrinciple basically requires the content of the seman-tic head to be identical to the content of the mother.If we ignore coordinate structures, and if we equatelogical form with semantic ontent for now, then allHPSG grammar ules are SHD chain rules, meetingthe requirement of the BUG algorithm.2.2 HPSG in P roF ITProFIT: Prolog with Features, Inheritance and Tem-plates (Erbach, 1995) is an extension of Prolog whichsupports inheritance-based typed feature structures.The type hierarchy is declared in a signature, whichdefines subtypes and appropriate features of everytype.
Terms with typed feature structures can thenbe used alongside normal terms.
Using the signaturedeclarations, the ProFIT system compiles the typedfeature structures into normal Prolog terms, whichcan be compiled by the Prolog system.Figure 1 shows some implementation details.
Weuse ProFIT templates (defined by ':=') for princi-pies such as the Head Feature Principle ('HFP')and Semantics Principle ('SemP').
Templates areexpanded where they are invoked (by @'HFP' or@'SemP').
The type hierarchy includes the phrasetype hierarchy of Sag (1997).
As ProFIT does notsupport dynamic constraints, we use templates tospecify phrasal constraints.
For example, for head-nexus phrases, the hd__nexus_ph template specifiesthe <hd_nexus_ph type, invokes general constraintson headed phrases (such as HFP) by @hd_ph, andinvokes the Semantics Principle by @'SetuP'.Immediate dominance schemata are implementedas PSG rules, using schematic categories word andphrase, not traditional categories (NP, VP  etc).
Tosimplify the generator, the semantic head is first inthe list of daughters.
Linear precedence is speci-fied by the PHON strings, implemented as Prologdifference lists.
Example rules for Head-Subject andHead-Complements Schemata are shown in Figure 1.2.3 HPSG Interface for BUG1van Noord (1990) implements the BUG algorithmas BUGI  in Prolog.
For HPSG, we add the ProFITinterface in Figure 2.
Templates identify the headfeatures (HF) and logical form (LF), and keep thealgorithm independent from HPSG internal details.Note that link, used by van Noord (1990) to im-prove the efficiency of the algorithm, is replaced bythe HPSG Head Feature Principle.hf(HF) := synsem!loc!cat!head!HF.If(LF) := synsem!loc!cont!LF.predict_word(@If(LF) k @hf(HF), Word ) :-lex( Word t @If(LF) k @hf(HF) ).predict_rule(Head,Mother,Others,@hf(HF)) :-( Mother k @hf(HF) ---> \[HeadJOthers\] ).generate(LF, Sign, String) :-bugl( Sign k phon!String-\[\] k @If(LF) )./* BUGI: van Noord 1990 */bugl(Node) : -predict_word(Node, Smal l ) ,connect(Smal l ,  Node).connect(Node, Node).connect(Small, Big) :-predict-rule(Small'Middle'Others'Big)'gen_ds(0thers),connect(Middle, Big).gen_ds(Q).gen_ds(\[Node~Nodes\]) :-bug1(Node),gen_ds(Nodes).Figure 2: ProFIT/HPSG Interface for BUG11394S"PHON (she, saw, Kim)\[see-rel\]CONT \[\] SEERSEEN\[NAME KimN-PCONT \] INDEX \[\]BACKGR {~}VP'PHON (saw, Kim>\]CONT \[\] |BACKGR {gl} JV NP"PHON (saw>\] \[PHON \]CONT \[\] / \] CONTIINDEX \[\] IBACKGR {}J \[BACKGR {~)JFigure 3: Contextual Background (Phrasal Amalgamation)3 Quant i f ie rs  and  ContextHead-driven generation as in Section 2 works fine ifthe semantics is strictly head-driven.
All semanticinformation must be inside the CONTENT feature,and cannot be distributed in other features uch asQSTORE or BACKGR.
When an NP is assigned tothe semantic role of a verb, the whole of the NP'sCONTENT must be assigned, not only its INDEX.This differs significantly from HPSG theory.3.1 Quanti f ier Storage and Retr ievalThere is a complication in Pollard and Sag (1994)caused by the use of Cooper storage to handle scopeambiguities.
While scoped quantifiers are includedin the QUANTS list within CONTENT, unscopedquantifiers are stored in the QSTORE set outsideCONTENT.
So logical form for generation eeds toinclude QSTORE as well as CONTENT.In this approach, a quantifier may be retrieved atany suitable syntactic node.
A quantifier etrievedat a particular node is a member of the QSTOREset (but not the QUANTS list) of some daughter ofthat node.
Due to the retrieval it is a member ofthe QUANTS list (but not the QSTORE set) of themother node.
Pollard and Sag (1994) define a mod-ified Semantics Principle to cater for this, but theeffect of retrieval on QSTORE and QUANTS meansthat the mother and the semantic head daughtermust have different logical forms.
The daughter isthe semantic head by the HPSG definition, but notas required by the generation algorithm.3.2 Contextual  BackgroundIn addition to semantic content, natural languagegeneration requires presuppositions and other prag-matic and discourse factors.
In HPSG, such factorsare part of CONTEXT.
To specify these factors forgeneration, the usual approach is to include them inthe logical form.
So logical form needs to includeCONTEXT as well as CONTENT and QSTORE.This extended logical form is defined for BUG1 byreplacing the ProFIT template for 'lf(LF)' shown inFigure 2 with the new template in Figure 4.lf(ct!CT ~ qs!OS ~ cx!CX) :=synsem!loc!
(cont!CT & qstore!QS & conx!CX).Figure 4: Extending the Logical FormHowever, head-driven generation does not workwith this inclusive logical form, given the theory ofPollard and Sag (1994).
Even if we ignore quantifierretrieval and look at a very simple sentence, there isa fundamental difficulty with CONTEXT.Figure 3, from Wilcock (1997), shows the HPSGanalysis of she saw Kim.
Note that she has a non-empty BACKGR set (shown by tag \[\]), stating apragmatic requirement that the referent is female.1395This background condition is part of CONTEXT,and is passed up from NP to S by the Principle ofContextual Consistency.
Similarly, Kim has a back-ground condition (shown by tag \[\]) that the referentbears this name.
This is also passed from NP to VP,and from VP to S.S, VP and V share the same CONTENT (shownby tag ill).
If logical form is restricted to seman-tic content as in Figure 2, then V is the semantichead of VP and VP is the semantic head of S, notonly in terms of the HPSG definition but also interms of the BUG algorithm.
In this case, saw canbe found immediately by predict_word in BUG1.But if we extend logical form as in Figure 4, to in-clude the context factors required for adequate re-alization, it is clear from Figure 3 that S does nothave the same logical form as VP, and VP does nothave the same logical form as V, as their BACKGRsets differ.
Therefore, although V is still the seman-tic head of VP according to the HPSG definition,it is not the semantic head according to the BUGalgorithm.
Similarly, VP is still the semantic headof S for HPSG, but it is not the semantic head forBUG.
In this case, predicl;_word cannot find any se-mantic head word in the lexicon, and BUG1 cannotgenerate the sentence.4 Revising the GrammarIf we include unscoped quantifiers and contextualbackground in logical form, we see that there are twodifferent definitions of "semantic head": the HPSGdefinition based on adjunct daughter or syntactichead daughter, and the BUG algorithm definitionbased on identity of logical forms.
However, recentproposals for changes in HPSG theory suggest thatthe two notions of semantic head can be broughtback together.4.1 Lexical amalgamat ion i  HPSGIn Pollard and Sag (1994), QSTORE and BACKGRsets are phrasally amalgamated.
The Quantifier In-heritance Principle requires a phrase's QSTORE tobe the set union of the QSTOREs of all daughters,minus any quantifiers in the phrase's RETRIEVEDlist.
The Principle of Contextual Consistency re-quires a phrase's BACKGR to be the set union ofthe BACKGR sets of all the daughters.It has recently been proposed that these setsshould be lezically amalgamated.
A syntactic headword's arguments are now lexically specified in itsARGUMENT-STRUCTURE list.
The word's set-valued features can therefore be defined in terms ofthe amalgamation f the set-valued features of itsarguments.Lexical amalgamation of quantifier storage wasproposed by Pollard and Yoo (1995).
They changeQSTORE into a local feature which can be includedin the features ubcategorized for by a lexical head,and can therefore be lexically amalgamated in thehead.
A phrase no longer inherits unscoped quan-tifiers directly from all daughters, instead they areinherited indirectly via the semantic head daughter.Lexical amalgamation of CONTEXT, proposedby Wilcock (1997), follows the same approach.
AsCONTEXT is a local feature, it can be subcatego-rized for by a head word and lexically amalgamatedin the head by means of a BACKGR amalgamationconstraint.
Instead of a phrase inheriting BACKGRconditions directly from all daughters by the Prin-ciple of Contextual Consistency, they are inheritedindirectly via the "contextual head" daughter whichis the same as the semantic head daughter.4.2 Lexical amalgamat ion i  P roF ITIn the ProFIT implementation, QSTORE sets andBACKGR sets are Prolog difference lists.
Lexicalamalgamation f both sets is shown in Figure 5,the lexical entry for the verb "saw".
The subject'sBACKGR set B0-B1 and the object's BACKGR setB1-BN are amalgamated in the verb's BACKGR setB0-BN.
The subject and object QSTORE sets, Q0-Q1 and Q1-QN, are similarly amalgamated in theverb's QSTORE Q0-QN.lex( phon!\[sawlX\]-X & @verb &synsem!loc!(cat!
(head!<verb &val!
(subj!\[@np &loc!
(cat!head!case!<nomcont!index!Subj &conx!backgr!BO-Bl &qstore!QO-Ql)\] &comps!\[@np &loc!
(cat!head!case!<acccont!index!Objconx!backgr!Bi-BN &qstore!QI-QN)\])) &cont!nuc!
(seer!Subj & seen!Obj) &conx!backgr!BO-BNqstore!QO-QN) ).Figure 5: Lexical amalgamationThe basic Semantics Principle, for semantic on-tent only, was implemented bythe ProFIT templates'SemP' and 'SemP'(adjunct) asshown in Figure 1.In order to include unscoped quantifiers and back-ground conditions in logical form, as in Figure 4,and still make it possible for the logical form ofa phrase to be identical to the logical form of its1396semantic head, the Semantics Principle is replacedand extended.
As proposed by Wilcock (1997), weneed three principles: Semantic Head InheritancePrinciple (SHIP), Quantifier Inheritance Principle(QUIP), and Contextual Head Inheritance Princi-ple (CHIP).
These are implemented by templates asshown in Figure 6 (only the non-adjunct forms areshown).
To include the three principles in the gram-mar, the template for hd_nexus_ph in Figure 1 isextended as shown in Figure 6.
'SHIP' := synsem!loc!cont!Cont &hd_dtr!synsem!loc!cont!Cont.
'QUIP' := synsem!loc!qstore!QS khd_dtr!synsem!loc!qstore!QS.
'CHIP' := synsem!loc!conx!Conx khd_dtr!synsem!loc!conx!Conx.hd_nexus_ph := <hd_nexus_ph & @hd_ph k@'SHIP' & @'QUIP' & Q'CHIP ' ,Figure 6: Inheritance of Logical FormWith these revisions, it is possible to includeunscoped quantifiers and background conditions inthe starting logical form, and perform head-drivengeneration successfully using the BUG1 generator.However, there remain various technical difficultiesin this implementation.
The ProFIT system doesnot support either dynamic constraint checking orset-valued features.
The methods hown (templateexpansion and difference lists) are only partial sub-stitutes for the required facilities.5 ConclusionThe combination of a head-driven HPSG grammarwith a head-driven generation algorithm is a natu-ral approach to surface realization.
We showed howvan Noord's BUG1 generator can easily be adaptedfor use with an HPSG grammar implemented inProFIT, and that this works well if the semantics istrictly head-driven.
However, while the apparentlyclear definition of semantic head in HPSG shouldmake semantic head-driven generation easy to imple-ment, we found that if we implement the full HPSGtextbook semantics, with quantifier storage and con-textual background conditions, the notion of seman-tic head becomes unclear.
Surprisingly, this naturalapproach does not work, even for simple examples.In order to use semantic head-driven generationalgorithms with HPSG, we must adopt recent pro-posals to include quantifier storage and contextualbackground inside semantic heads by means of lex-ical amalgamation.
We showed how the grammarin ProFIT can be extended with these proposals.We therefore conclude that head-driven generationwith HPSG is indeed a feasible approach to surfacerealization, although there are some technical diffi-culties.AcknowledgementsWe are grateful to Mr Yoshikazu Nakagawa of SharpCorporation for making our collaboration possible.Re ferencesGregor Erbach.
1995.
ProFIT: Prolog with Fea-tures, Inheritance, and Templates.
In SeventhConference of ~he European Chapter of the Asso-ciation for Computational Linguistics, pages 180-187, Dublin.Masahiko Haruno, Yasuharu Den, and Yuji Matsu-moto.
1996.
A chart-based semantic head drivengeneration algorithm.
In G. Adorni and M. Zock,editors, Trends in Natural Language Generation:An Artificial Intelligence Perspective, pages 300-313.
Springer.Carl Pollard and Ivan A.
Sag.
1994.
Head-drivenPhrase Structure Grammar.
CSLI Publicationsand University of Chicago Press.Carl Pollard and Eun Jung Yoo.
1995.
Quantifiers,wh-phrases and a theory of argument selection.Tiibingen HPSG workshop.Ivan A.
Sag.
1997.
English relative clause construc-tions.
Journal of Linguistics, 33(2):431-484.Stuart M. Shieber, Gertjan van Noord, Fer-nando C.N.
Pereira, and Robert C. Moore.
1990.Semantic head-driven generation.
ComputationalLinguistics, 16(1):30-42.Gertjan van Noord.
1990.
An overview of head-driven bottom-up generation.
In R. Dale, C. Mel-lish, and M. Zock, editors, Current Researchin Natural Language Generation, pages 141-165.Academic Press.Graham Wilcock and Yuji Matsumoto.
1996.
Re-versible delayed lexical choice in a bidirectionalframework.
In 16th International Conference onComputational Linguistics (COLING-96), pages758-763, Copenhagen.Graham Wilcock.
1997.
Lexicalization of Context.4th International Conference on HPSG, Ithaca.
Toappear in G. Webelhuth, J.-P. Koenig and A. Kat-hol, editors, Lexical and Constructional Aspects ofLinguistic Explanation.
CSLI Publications.1397
