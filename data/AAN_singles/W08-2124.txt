CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 188?192Manchester, August 2008A Joint Model for Parsing Syntactic and Semantic DependenciesXavier Llu?
?s and Llu?
?s M`arquezTALP Research Centre ?
Software Department (LSI)Technical University of Catalonia (UPC){xlluis,lluism}@lsi.upc.eduAbstractThis paper describes a system that jointlyparses syntactic and semantic dependen-cies, presented at the CoNLL-2008 sharedtask (Surdeanu et al, 2008).
It combinesonline Peceptron learning (Collins, 2002)with a parsing model based on the Eisneralgorithm (Eisner, 1996), extended so asto jointly assign syntactic and semantic la-bels.
Overall results are 78.11 global F1,85.84 LAS, 70.35 semantic F1.
Official re-sults for the shared task (63.29 global F1;71.95 LAS; 54.52 semantic F1) were sig-nificantly lower due to bugs present at sub-mission time.1 IntroductionThe main goal of this work was to construct a jointlearning architecture for syntactic-semantic pars-ing and to test whether the syntactic and semanticlayers can benefit each other from the global train-ing and inference.All the components of our system were builtfrom scratch for this shared task.
Due to strongtime limitations, our design decisions were biasedtowards constructing a simple and feasible system.Our proposal is a first order linear model that re-lies on an online averaged Perceptron for learning(Collins, 2002) and an extended Eisner algorithmfor the joint parsing inference.Systems based on Eisner algorithm (Carreras etal., 2006; Carreras, 2007) showed a competitiveperformance in the syntactic parsing of the Englishlanguage in some past CoNLL shared tasks.
Also,c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.we believe that extending the Eisner algorithm tojointly parse syntactic and semantic dependenciesit is a natural step to follow.Note that syntactic and semantic tasks are re-lated but not identical.
Semantic dependencies cantake place between words loosely related by thesyntactic structure.
Another difficulty is that stateof the art SRL systems (Surdeanu et al, 2007)strongly rely on features extracted from the syn-tactic tree.
The joint model grows syntactic andsemantic structures at the same time, so featuresextracted from the syntactic tree (e.g., a syntacticpath between a modifier and a distant predicate)are not available or expensive to compute withinthe Eisner algorithm.
We overcome this problemagain with a very simple (though not elegant) solu-tion, consisting of introducing a previous syntacticparsing step.2 System architectureThis section briefly describes the main componentsof our system: 1) Preprocessing, 2) Syntactic pars-ing, 3) Predicate identification, 4) Joint syntactic-semantic parsing, and 5) Postprocessing.In preprocessing, the training corpus is traversedand feature extraction performed.
Main featuresare borrowed from pre-existing well-known sys-tems (see next subsection).
The initial syntacticparsing is based on an Eisner parser trained withPerceptron and it is merely intended to allow theextraction of syntactic-based features for all thefollowing phases (which share exactly the samefeature set extracted from these parse trees).
Pred-icate identification recognizes predicates by apply-ing SVM classifiers1and a set of simple heuristicrules.
The joint syntactic-semantic parsing phase1We used SVM-light (see www.joachims.org for details).188is the core module of this work.
It simultaneouslyderives the syntactic and semantic dependenciesby using a first order Eisner model, extended withsemantic labels and trained with averaged Percep-tron.
Finally, postprocessing simply selects themost frequent sense for each predicate.2.1 Preprocessing and feature extractionAll features in our system are calculated in the pre-processing phase.
We use the features describedin McDonald et al (2005) and Carreras et al(2006) as input for the syntactic parsing phase, ex-cept for the dynamic features from Carreras et al(2006).
The joint syntactic-semantic parser usesall the previous features and also specific featuresfor semantic parsing from Xue and Palmer (2004)and Surdeanu et al (2007).
The features have beenstraightforwardly adapted to the dependency struc-ture used in this shared task, by substituting anyreference to a syntactic constituent by the head ofthat constituent.
About 5M features were extractedfrom the training corpus.
The number of featureswas reduced to ?222K using a frequency thresh-old filter.
A detailed description of the feature setcan be found at Llu?
?s (Forthcoming 2008).2.2 Syntactic parsingOur system uses the Eisner algorithm combinedwith an online averaged Pereceptron.
We definethe basic model, which is also the starting pointfor the joint model.
Let L be the set of syntacticlabels, x = x1, .
.
.
, xna sentence with n words,and Y(x) the set of all possible projective depen-dency trees for x.A dependency tree y ?
Y(x) is a labeled treewith arcs of the form ?h,m, l?
that is rooted onan artificial node, 0, added for this purpose.
Thehead, h, and modifier, m, for a dependency indexwords in the sentence and can take values in 0 ?h ?
n and 1 ?
m ?
n. l ?
L is the label of thedependency.The dependency parser (dp) is interested in find-ing the best scored tree for a given sentence x:dp(x,w) = argmaxy?Y(x)score tree(y, x,w)Using an arc-based first order factorization, thefunction score tree(y, x,w) is defined as the sum-mation of scores of the dependencies in y:??h,m,l?
?yscore(?h,m, l?
, x,w) ,where w is the weight vector of the parser, com-puted using an online perceptron.
The weight vec-tor w can be seen as a concatenation of |L| weightvectors of d components, one for each of the la-bels: w = (w(1), .
.
.
,w(l), .
.
.
,w(|L|)).
A func-tion ?
is assumed to extract features from a de-pendency ?h,m, l?
and from the whole sentence x.This function represents the extracted features as ad-dimensional vector.With all these elements, the score of a depen-dency ?h,m, l?
is computed as a linear function:score(?h,m, l?
, x,w) = ?
(?h,m, l?
, x) ?w(l)2.3 Predicate identificationWe identified as verb predicates all verbs exclud-ing the auxiliaries and the verb to be.
These simplerules based on the POS and lemma of the tokensare enough to correctly identify almost all verbpredicates.
With regard to noun predicates, we di-rectly identified as predicates the lemmas whichappeared always as predicates with a minimum fre-quency in the training corpus.
The remaining nounpredicates were identified by a degree-2 polyno-mial SVM.
This classifier was trained with thesame features used in subsequent phases, but ex-cluding those requiring identified predicates.2.4 Joint syntactic and semantic ParsingThe previously described basic parsing model willbe extended to jointly assign semantic dependencylabels.
Let S be the set of semantic labels.
Notethat at this point, a sentence x has a set of q wordsalready identified as predicates.
We will refer tothem as p1, .
.
.
, pq, where pi?
{1, .
.
.
, n}.
Weconsider that each dependency has a set of se-mantic tags lsem p1, .
.
.
, lsem pqone for each sen-tence predicate pi.
Also, we consider an extrano-argument label in the set of semantic labels S.Thus, an extended dependency dsis defined as:ds=?h,m, lsyn, lsem p1, .
.
.
, lsem pq?,where lsyndenotes the syntactic label for the de-pendency.Again, the best parse tree is that maximizing thescore of a first order factorization:dp(x,w, y?)
= argmaxy?Y(x)score tree(y, x,w, y?
)score tree(y, x,w, y?)
==??h,m,l?
?yscore(?h,m, l?
, x,w, y?)
,189where the dependency label is now extended tol = ?lsyn, lsem p1, .
.
.
, lsem pq?
and y?denotes theprecomputed syntax tree.
The score of a syntactic-semantic dependency is:score(?h,m, l?
, x,w, y?
)=syntactic score (h,m, lsyn, x,w)+sem score(h,m, lsem p1, .
.
.
, lsem pq, x,w, y?
)The syntactic score is computed as described in thebasic model.
Finally, the semantic scoring func-tion computes the semantic score as the sum of thesemantic scores for each predicate semantic label:sem score(h,m, lsem p1, .
.
.
, lsem pq, x,w, y?
)=?lsem pi?sem(?h,m, lsem pi?
, x, y?)
?w(lsem pi)qNote that each sentence x has a different numberof predicates q.
To avoid an excessive weight ofthe semantic component in the global score and abias towards sentences with many predicates, thescore is normalized by the number of predicates inthe sentence.Figure 1 shows an example of a sen-tence fragment with syntactic and seman-tic dependencies.
The three predicatesof the sentence are already identified:{p1= completed, p2= announced, p3=acquisition}.
All dependencies are of theform d = ?h,m, lsyn, lsem p1, lsem p2, lsem p3?.Note that semantic labels express semanticrelations between a modifier and a predicatethat can be anywhere in the sentence.
Thesemantic labeling is not restricted to predicatesthat are the head of the modifier.
In this ex-ample, the correct output for the dependencypreviously-announced is h = announced,m = previously, lsyn= AMOD, lsem p1= null,lsem p2= AM-TMP, lsem p3= null.The above described factorization allows theparser to simultaneously assign syntactic andsemantic labels and also to maximize a jointsyntactic-semantic score of the tree.
Note that thesemantic scoring function ?semextracts featuresfrom the modifier, the head and the predicate of theparsed dependencies.
The proposed model allowsto capture interactions between syntax and seman-tics not only because the syntactic and semanticscores are combined but also because the semanticscoring function relies on features extracted fromthe head-modifier-predicate relations.
Thus, thesemantic scoring function depends on the syntacticdependency being built, and, in reverse, the seman-tic score can modify the dependency chosen.Regarding implementation issues, note that wecompute |L|+ |S| ?
q scores to assign q + 1 labelsto a given dependency.
The scores are computedindependently for each label.
Otherwise, interac-tions among these labels, would raise the num-ber of possible combined labels to an exponentialnumber, |L| ?
|S|q, making the exhaustive evalu-ation infeasible in practice.
Also related to effi-ciency, we apply syntactic and semantic filters inorder to reduce the number of score evaluations.In particular, the set of assignable labels is filteredby the POS of the head and modifier (discardingall labels not previously seen in the training corpusbetween words with the same POS).
Another fil-ter removes the core arguments not present in theframe file of each predicate.
This strategy allowedus to significantly improve efficiency without anyloss in accuracy.2.5 PostprocessA simple postprocess assigns the most frequentsense to each identified predicate.
Frequencieswere computed from the training corpus.
Ex-periments performed combining the best and sec-ond output of the joint parser and enforcing do-main constraints via ILP (Punyakanok et al, 2004)showed no significant improvements.3 Experiments and ResultsAll the experiments reported here were done usingthe full training corpus, and results are presentedon the development set.
The number of featuresused by the syntactic parser is ?177K.
The jointparser uses?45K additional features for recogniz-ing semantic dependencies.Figure 2 shows the learning curves from epoch1 to 17 for several subsystems and variants.
Morespecifically, it includes LAS performance on syn-tactic parsing, both for the individual parser andfor the syntactic annotation coming from the jointsyntactic-semantic parser.
For the latter, also theF1score on semantic dependencies and globalF1results are presented.
We can observe thatthe syntactic LAS scores for the syntactic andjoint parsers are very similar, showing that thereis no loss in syntactic performance when usingthe joint syntactic-semantic strategy.
Overall re-190SBJ, A0, _, A0OBJ, _, _, SuNMOD, _, _, _ AMOD, _, AM-TMP, _ NMOD, _, _, _OBJ, A1, A1, _Figure 1: Syntactic and semantic dependencies.sults are quite stable from epoch 4 (syntax slightlydecreases but semantics slightly increases).
Theoverall results on the test set (78.11 global F1,85.84 LAS, 70.35 semantic F1) were computed byusing 5 epochs of training, the optimal on the de-velopment set.68707274767880828486246810121416LAS single synLAS syn joint F1 semjointF1 global jointFigure 2: Learning curves for the syntactic-onlyand joint parsers.The global F1result on the WSJ test corpus is79.16, but these results drop 9.32 F1points onthe out-of-domain Brown corpus.
Also, a signif-icant performance drop is observed when mov-ing from verb argument classification (74.58 F1,WSJ test) to noun argument classification (56.65F1, WSJ test).
Note that the same features wereused for training noun and verb argument classi-fiers.
These results point out that there is room forimprovement on noun argument classification.
Fi-nally, a comparison to a simple equivalent pipelinearchitecture, consisting of applying the syntacticbase parser followed by an independent classifica-tion of semantic dependencies (using exactly thesame features) revealed that the joint model out-performed the pipeline by 4.9 F1points in the an-notation of semantic dependencies.Regarding efficiency, the proposed architectureis really feasible.
About 0.7GB of memory is re-quired for the syntactic parser and 1.5GB for thejoint parser.
Most of these memory needs are dueto the filters used.
The filters allowed for a reduc-tion of the computational cost by a factor of 5 withno loss in accuracy.
These filters have almost noeffect on the theoretical upper bound discardingthe correct labels for only 0.2% of the syntactic de-pendencies and 0.44% of the semantic argumentsin the development corpus.
The semantic exten-sion of the Eisner algorithm requires only a newtable with backpointers for each predicate.
Using asingle processor of an amd64 Athlon x2 5000+, thesyntactic parser can be trained at 0.2 s/sentence,and the joint parser at 0.3 s/sentence.
Efficiency attest times is only slightly better.4 DiscussionWe have presented a novel joint approach to per-form syntactic and semantic parsing by extend-ing Eisner?s algorithm.
Our model allows to cap-ture syntactic-semantic interactions as the com-puted syntactic-semantic score is globally opti-mized.
The computational cost of the new settingis admissible in practice, leading to fairly efficientparsers, both in time and memory requirements.Results obtained with the presented joint ap-proach are promising, though not outstanding inthe context of the CoNLL-2008 shared task.
Webelieve that there is room for substantial improve-ment since many of the current system components191are fairly simple.
For instance, higher order ex-tensions to the Eisner algorithm and well-knowntricks for dealing with non-projective structurescan be incorporated in our model.
Also, we planto incorporate other subtasks in the training of thejoint model, such as predicate identification and ar-gument recognition.One of the potential drawbacks of our currentapproach is the need for a syntactic parsing pre-ceding the joint model.
This previous parse issimply included to permit the extraction of syntaxbased features.
These features (including the syn-tactic path) could be dynamically computed whenperforming the joint parsing in the cases in whichthe predicate coincides with the head of the modi-fier being processed.
These cases account for only63.6% of the training corpus arguments.
If a pred-icate is located in a sibling sentence span, the dy-namic programming algorithm has not yet chosenwhich of the possible spans will be included inthe final parse tree.
Also, the predicate can belocated at a lower level within the current span.These cases would require to recompute the scoreof the current span because syntactic path featuresare not available.
The resulting cost would be pro-hibitive and approximate search needed.
Our pre-vious parsing phase is just an efficient and simplesolution to the feature extraction problem in thejoint model.As previously seen, the joint model showed asimilar syntactic performance and clearly bettersemantic performance than an equivalent pipelinesystem, showing that some degree of syntactic-semantic overlap is exploitable.
Regarding the for-mer, there is only a moderate degree (63.6%) ofdirect overlap between the syntactic head-modifierand semantic predicate-modifier relations.
If thesemantic score is highly dependent on a correcthead the resulting increased score could benefit thechoosing of a correct dependency.
Otherwise, jointscores can introduce a significant amount of noise.All in all, further research is required in this direc-tion.AcknowledgementsThis research has been partially funded by theSpanish Ministry of Education and Science,projects Trangram (TIN2004-07925-C03-02) andOpenMT (TIN2006-15307-C03-02).ReferencesCarreras, Xavier, Mihai Surdeanu, and Llu?
?s M`arquez.2006.
Projective dependency parsing with percep-tron.
In Proceedings of the 10th Conference on Com-putational Natural Language Learning (CoNLL-2006).Carreras, Xavier.
2007.
Experiments with a higher-order projective dependency parser.
In Proceedingsof the 11th Conference on Computational NaturalLanguage Learning (CoNLL-2007).Collins, Michael.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof the ACL-02 conference on Empirical methods innatural language processing.Eisner, Jason M. 1996.
Three new probabilistic mod-els for dependency parsing: An exploration.
In Pro-ceedings of the 16th International Conference onComputational Linguistics (COLING-96).Llu?
?s, Xavier.
Forthcoming 2008.
Joint learning ofsyntactic and semantic dependencies.
Master?s the-sis, Technical University of Catalonia (UPC).McDonald, Ryan, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL-2005).Punyakanok, Vasin, Dan Roth, Wen-tau Yih, and DavZimak.
2004.
Semantic role labeling via integer lin-ear programming inference.
In Proceedings of Col-ing 2004.Surdeanu, Mihai, Llu?
?s M`arquez, Xavier Carreras, andPere R. Comas.
2007.
Combination strategies forsemantic role labeling.
Journal of Artificial Intelli-gence Research.Surdeanu, Mihai, Richard Johansson, Adam Meyers,Llu?
?s M`arquez, and Joakim Nivre.
2008.
TheCoNLL-2008 shared task on joint parsing of syntac-tic and semantic dependencies.
In Proceedings ofthe 12th Conference on Computational Natural Lan-guage Learning (CoNLL-2008).Xue, Nianwen and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Proceedingsof the Empirical Methods in Natural Language Pro-cessing (EMNLP-2004).192
