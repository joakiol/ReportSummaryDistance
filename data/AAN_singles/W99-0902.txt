The applications of unsupervised learning to Japanesegrapheme-phoneme alignmentTimothy Baldwin and Hozumi TanakaTokyo Institute of Technology{tim, tanaka}?cs, titech, ac.
jpAbstractIn this paper, we adapt the TF-IDF model to theJapanese grapheme-phoneme alignment task, byway of a simple statistical model and an incremen-tal learning method.
In the incremental learningmethod, grapheme-phoneme alignment paradigmsare disambiguated one at a time according to therelative plausibility of the highest scoring align-ment schema, and the statistical model is re-trainedaccordingly.
On limited evaluation, the learningmethod achieved an accuracy of 93.28%, represent-ing a slight improvement over a baseline rule-basedmethod.1 IntroductionThe objective of this paper is to analyse the appli-cability of statistical and learning methods to au-tomated grapheme-phoneme alignment in Japanese,without reliance on pre-annotated training data orany form of supervision.
The two principal modelsproposed herein are a simple statistical model non-reliant on learning techniques, and an incrementallearning method deriving therefrom, incorporatingautomated "pseudo-supervision" drawing on prioralignments.
The incremental learning method se-lects a single alignment candidate to accept at eachiteration, and adjusts the statistical model accord-ingly to aid in the subsequent disambiguation ofresidue G-P tuples.Grapheme-phoneme ("G-B") alignment is definedas the task of maximally segmenting a graphemecompound into morpho-phonic units, and aligningeach unit to the corresponding substring in thephoneme compound (Bilac et al, 1999).
Its mainuse is in portrayal of the phonological interactionbetween adjoining grapheme segments, and alsoimplicit description of the range of readings eachgrapheme segment can take.
We further suggest thata large-scale database of maximally aligned G-P tu-ples has applications within the more conventionaltask of G-P translation (Klatt, 1987; Huang et al,1994; Divay and Vitale, 1997).Our particular interest in developing a databaseof G-P tuples is to apply it in the development ofa kanji tester which can dynamically predict plausi-bly incorrect readings for a given grapheme string.For this purpose, we require as great a coverage ofgrapheme strings as possible, and the proposed sys-tem has thus been designed to exhaustively align theinput set of G-P tuples, sacrificing precision for 100%recall.
'Grapheme string' in this research refers to themaximal kanji representation of a given word orcompound, and 'phoneme string' refers to the kana(hiragana and/or katakana) mora correlate.
1 By'maximal'  segmentation is meant hat the graphemestring must be segmented to the degree that eachsegment corresponds to a self-contained componentof the phonemic description of that compound, andthat no segment can be further segmented into align-ing sub-segments.
The statement of 'maximality' ofsegmentation is qualified by the condition that eachsegment must constitute a morpho-phonic unit, inthat for conjugating parts-of-speech, namely verbsand adjectives, the conjugating suffix must be con-tained in the same segment as the stem.By way of illustration of the alignment process,let us consider the example of the verb ka-n-sya-su-ru i~--~-su-ru\] "to thank/be thankful",2 a por-tion ot the 35 member alignment paradigm for whichis given in Fig.
1.
The importance of maximalityof alignment is observable by way of align35, whichconstitutes a legal (under-)alignment of the correctsolution in align1.
Here, there is scope for furthersegmentation, as evidenced by the replaceability ofby its phoneme content of ka-n in isolation of(producing the string ka-n-=~-su-ru).
Thus, we areable to discount align35 on the grounds of it beingnon-maximal.
That a segment exists between syaand su-ru, on the other hand, is a result of su-rubeing a light verb and hence an independent mor-pheme.The overall alignment procedure is depicted in1Our description of kana as phoneme units represents aslight abuse of terminology, inthat individual kana charactersare uniquely associated with a broad phonetic transcriptionpotentially extending over multiple phones.
Note, however,that in abstracting away to this meta-phonemic representa-tion, we are freed from consideration oflow-level phonologicalconcerns uch as phoneme connection constraints.2So as to make this paper as accessible as possible to read-ers not familiar with Japanese, hiragana nd katakana char-acters have been transliterated into Latin script throughoutthis paper and are essentially treated as being identical.
Thegraphemic kanji character set, on the other, has been providedin its original form to give the reader afeel for the significanceof the kana-kanji dichotomy.
For both the grapheme andphoneme strings, character boundaries are indicated by "-"and segment boundaries (which double as character bound-aries) indicated by "?
".~ (~-~ (~su-ruka-n (~) sya (~) su-ru(~ -~ -su-ru~ o ?
o  ~ka (~) n-sya-su-ru:~--~ ~.~ su-ru \]i \ /ka-n (~) sya-su-ru.
o o~--~-su-ruka-n-sya-su-rual ign I al ign i al ignj align35Figure 1: Candidate alignments for ~-~-su-ru \[ka-n-sya-su-ru\] "to thank/be thankful"Fig.
2.
Within input set ?, the system proceedsby first generating an exhaustive listing of all align-ment candidates (PSseg)-{GSseg) for each G-P tuplei.
This alignment paradigm is pruned through ap-plication of a series of constraints, and either of thetwo proposed alignment selection methods is thenapplied to identify a single most plausible alignmentfrom each alignment paradigm.
Both the simple sta-tistical model ("method-l ')  and incremental learn-ing method ("method-2") rely on a slightly mod-ified form of the TF-IDF model.
In the case ofmethod-l, statistical analysis is applied to the fullrange of alignment paradigms in ?
and all align-ment paradigms are disambiguated in parallel.
Formethod-2, we commence identically to method-l, butsingle out an alignment paradigm to disambiguate ateach iteration, and incrementally adjust the statisti-cal model based on both the reduced ?
and the ex-panded w. As such, the principal difference betweenthe two methods can be stated as statistical feedbackfrom w to ~, in method-2, but not in method-1.Disambiguated tuple\[(G~eg ~ ~PSseg ) ~StatisticalInput set/ feedback Solutionresidue set(method-2)Figure 2: An outline of the systemIn the remainder of this paper, we first present hemethodology used to derive all legal alignments fora given G-P tuple (Section 2), then give full detailsof both the simple statistical method and incremen-tal learning method (Section 3), before evaluatingthe various methods against a baseline rule-basedmethod (Section 4).
Finally, in Section 5, we con-sider additional applications of the basic methodol-ogy proposed here.2 The grapheme-phonemealignment processGrapheme-phoneme alignment is performed as afour-stage process: (a) detection of lexical alterna-tions and removal of lexical alternates from the in-put, (b) determination of all possible G-P alignmentschemas, (c) pruning of alignments through phono-logical constraints, and (d) scoring of all final candi-date alignments, and determination of the final so-lution accordingly.2 .1 Lex ica l  a l te rnat ionLexical alternation is defined as the condition ofthere being multiple lexical spell-outs for a givenphonetic ontent, M1 sharing the same basic seman-tics and kanji component.
For Japanese, this canarise as a result of the replaceability of kanji andtheir corresponding kana (i.e.
maze-gaki, as seenabove for ka-n-sya-su-ru), or alternatively for okuri-gana.
Okurigana comprise a (generally) inflectingkana suffix to a kanji stem, where the combination ofthe kanji stem and okurigana form a single morpho-phonic segment; an example of okurigana is seen forthe ru of ~-ru \[o-ku-ru\] "to send", with inflects tore in the imperative, for example.
Okurigana-basedlexical alternation occurs when phonetic content isconflated with or prised apart from the stem kanji,by way of okurigana optionality.
An example of thisoccurs for the verb ka-wa-ru "to change", lexicalis-able either as ~2-ru or ~.-wa-ru, with the underlinedwa conflating with the kanji stem of ~.
in the for-mer (basic) case for the same phonetic ontent.
Notethat okurigana never occur as alternating prefixes tokanji.Detection of okurigana alternates is achieved byway of analysing the graphemic form of G-P tu-ples sharing the same phonetic content, and align-ing the graphemic omponent of each such corre-sponding tuple to determine kanji correspondence.All instances of okurigana-based lexical alternationare clustered together, and alternates of the 'basic'form removed from input.
The basic form is definedas that with maximal phonemic onflation, that isminimal kana content in the grapheme string.
In thisway, we can: (a) enforce consistency of analysis forall okurigana alternates, (b) apply alignment con-straints across the full set of lexical alternates, and(c) avoid having multiple realisations of the samebasic item in our system data.
See (Baldwin andTanaka, 1999) for further details.2.2 Grapheme-phoneme a l te rnat ionG-P alignment can be subdivided into the three sub-tasks of (i) segmenting the grapheme string intomorpho-phonic units, (ii) aligning each graphemesegmentation to compatible segmentation(s) of thephoneme string, and (iii) pruning off illegal align-ments through the application of a series of phono-logical constraints.The first stage of the alignment process is togenerate all possible segmentations GSse~ for thegrapheme string GS, by optionally placing a de-limiter between adjacent characters (and implicitlyplacing delimiters at the beginning and end of boththe grapheme and phoneme strings for all segmen-tation candidates).
Note that individual kana andkanji characters are atomic, according to lexical con-straint h<l) Segment boundaries can only exist at characterboundaries.
(characters are indivisible)Next, the following axioms of alignment are ap-plied in determining possible alignments (GSseg)-(PSseg) for each grapheme segmentation candidateGSseg.
(al) The alignment must comprise an isomorphism.
(full G-Pcoverage, no overlap in alignment)(a2) No crossing over of alignment is permitted.
(strict linearity of alignment)Constraint al gives rise to the property that de-limiters in the phonemic string must constitutephoneme segment boundaries, that is lead from onephoneme segment directly into the next, as segmentsmust be strictly adjacent (there can be no unalignedsubstrings of the grapheme or phoneme string andno overlap of segmentation).
Constraint a2 furthergives us the property that segments must be orderedidentically in the grapheme and phoneme strings.We are now at the stage of having exhaustivelyg.enerated all lexicaily plausible alignments for ag*ven G-P tuple, such as given in Fig.
1 for ka-n-sya-su-ru.2.3 Const ra in t -based  a l ignmentprun ingThe final step in alignment is to disallow all align-ments (PSseg)-(GSseg) which contravene any ofthe following phonological constraints, applicableto grapheme segmentation ("G"), phoneme segmen-tation ("e"), and/or grapheme-phoneme alignment("G-P"), respectively:(Pl) A demarkation i script form indicates a seg-ment boundary, except for the case of kanji-hiragana boundaries.
\[G\](P2) Graphemic kana must align with a direct kanaequivalent in the phoneme string.
\[G-P\](P3) Intra-syllabic segments cannot exist for kanastrings \[G,P\](P4) The length of a kanji substring must be equalto or less than the syllable length of the corre-sponding phoneme substring.
\[G-P\]Constraint Pl produces the result that a segmentboundary must exist at every changeover betweenhiragana nd katakana, or kanji and katakana, andfrom hiragana to kanji.
The exceptional treatment ofkanji-hiragana changeovers is designed to facilitatethe recognition of full verb and adjective morpho-phonic units, as these two parts-of-speech involveconjugating kana suffices and also the potential forfurigana-based lexical alternation.
Note that foralign1 in Fig.
1, we do in fact have a segment bound-ary at the kanji-hiragana changeover -~?su.Constraint P2 polices the essentially phonemic na-ture of kana, in disallowing alignment of kana seg-ments of non-corresponding phonetic ontent.
In thecase of Fig.
1, P2 would lead to the disallowance ofalignj due to the alignment of (...?su-ru)-(...?sya-su-r?~).Constraint P3, applicable to both grapheme andphoneme segmentation, i troduces the notion thatalignment operates on the syllable- rather thancharacter-level.
While single kan~ characters gen-erally function as individual syllables, stand-alonevowel and consonant kana can form syllable clusterswith immediately preceding kana, as occurs for ka-nin ka-n-sya-su-ru.
Here, we would disallow a seg-ment boundary to exist between ka and n, and assuch prune off aligni in Fig.
1.Finally, P4 requires that each kanji character leadsto a phoneme substring at least one syllable inlength, irrespective ofwhether that single kanji com-prises the head of a morpho-phonic unit or combineswith adjoining kanji to form a multiple-graphemesegment.
A two kanji segment is required, therefore,to align with a phoneme substring at least two syl-lables in length.
~-=~ could thus not align with themono-syllabic ka-n, leading once again to the prun-ing of alignj.Note, there also exists scope to apply intra-segmental phonological constraints such as Lyman'sLaw (It6 and Mester, 1995, p. 819), which is left asan item for future research.3 Scoring methodThe scoring method utilised in this research for bothmethod-1 and method-2 is an adaptation of the TF-IDF model (Salton and Buckley, 1990), best knownin the context of term weighting for information re-trieval ("IR") tasks.
The main differences betweenour usage of the TF-IDF model and standard usagewithin IR circles, come in the counting of frequen-cies (method-1 and method-2) and the incrementalupdating of the statistical model/weighting of termsaccording to system "conviction" (method-2).That we should require a special means of count-ing frequencies i a direct consequence of the twoproposed methods dynamically determining segmen-tation schemas as a component ofthe alignment pro-cess.
We integrate the segmentation a d alignmentprocesses by taking the frequency of occurrence of agiven segment as the number of G-P tuples for which11freq((g,p)) =\[{(GS, PS) : 3pvar E phon_var(p) ~ ( .
.
.QgQ ...)-(...QpvarQ ...)E { (GSs~g)-(PSseg) } }}1" i i+ l  i i+ lt f-id\]((g,p, ctxt)) = freq((g,p)) - 1 + a log ( ~eq((g,p)) )freq( (g) ) kfreq( g,p, ctxt) - 1 + aO?
( (; ,p) ) idff ( (g, ; ,ctxt)  )(1)(2)that segment iscontained in the alignment paradigmin an identical lexical context.By adopting this approach of alignment potential-based frequency, we do not discount he possibilityof any alignment licenced by the constraints givenabove, but at the same time are unable to com-mit ourselves to any alignment schema we believeis correct.
In method-2, therefore, we combine theexistential-based statistical modelling of method-1for non-disambiguated alignment paradigms (?
inFig.
2), with a means of dynamically updating thestatistical model based on selectively disambiguatedalignment paradigms (w in Fig.
2).Alignment paradigms are selected for disambigua-tion based on the degree of discrimination betweenthe top- and second-ranking alignment schemas,and term frequencies found in solution alignmentsin w weighted above those found in the alignmentparadigms of ?.
Note that by disambiguating aparticular alignment paradigm, we are both iden-tifying that alignment schema we believe to be cor-rect, and disallowing all alternate alignments.
Assuch, updating of the statistical model reflects on allterms contained in the original alignment paradigm,both through the weighting up of terms containedin the accepted alignment schema, and the removalof terms contained in rejected alignment schemas.This results in a rescoring of all alignments contain-ing affected terms.3.1 Why t f - id f?The applicability of the TF-IDF model to G-P align-ment can be understood intuitively by consideringeach grapheme segment type as a document, he as-sociated phonemic segments across all G-P tuples asterms, and the left and right graphemic/phonemiccontexts of the current grapheme/phoneme strings,as the document context.The TF-IDF model maximallyweights terms whichoccur frequently within a given document (TF)but relatively infrequently within other documents(IDF).
For G-P alignment, we maximally weightreadings (aligned phoneme strings) which co-occurfrequently with a given grapheme string, but areobserved infrequently in the given lexical context.That is, we score up terms which occur with highrelative frequency and maximum diversity of lexicalcontext, and score down terms which either occurinfrequently or occur only in restricted lexical con-texts.
In this way, we are able to penalise under-alignment by way of a diminished IDF score (as thesame under-alignment candidate will generally existfor most other instances of that same basic G-P tu-ple), and at the same time penalise over-alignmentby way of a diminished TF score (as the given over-alignment will be reproducible for only a small com-ponent of instances of either the same grapheme orphoneme string).
By calculating individual TF-IDFscores for each each aligned segment and combin-ing them to produce a single overall score for thealignment, we are able to balance up selection of theoptimal overall alignment for the tuple.A subtle advantage in using the TF-IDF model inthe manner proposed here is that it has no sense of"appropriate" segment size.
While single charactersprovide a lower bound on segment size and the fullstring in question provides a dynamic upper bound,our only constraint within these bounds is that seg-ment size must follow character boundaries.
In thegiven context of Japanese G-P alignment, it com-monly occurs that both phoneme and grapheme seg-ments extend over multiple characters (for the 5000member test data used for evaluation purposes, theaverage phoneme and grapheme segment sizes were1.93 and 1.20 characters, respectively).
Indeed, de-spite the general perception of grapheme segments ascontaining a single kanji, multiple kanji were foundin grapheme segments for 0.9% of G-P tuples in thetest data (see below), including instances of the typefFg-\[\] \[ki-nS\] "yesterday" and ~-:;" \[na-su\] "egg-plant".
The TF-IDF model can handle such examplesbecause of the scarcity of alignment candidates shar-ing any of the unit-kanji readings produced throughsegmentation f such grapheme strings.
That is, wewould not expect to locate the partial alignment(...?-T'?...)-(...?su?...
), for example, with signif-icant frequency in the remainder of the alignmentdata, whereas we may find the partial alignment(...?~-:~?...)-(...?na-su?...)
elsewhere.
Even ifthere were only one instance of this alignment typein the system data, the combination of the dimin-ished scores for (...?~?...)-(...?na?...)
and(...?-Y=?...)-(...?su?...)
would lead to an overall TF-IDFscore for the associated segmentation well below theTF-based score for the full string-based alignment(see below).3.2 Count ing  f requenc iesTo be able to apply the basis of the TF-IDF model,we first need to have some means of calculating termfrequencies.
Given that both methods are designedto operate independently of annotated training data,we have no means of bootstrapping the system.
33Not strictly true, as there are a significant number ofG-P tuples where the alignment constraints produce full dis-12Term frequencies are thus defined to be an indicationof the number of G-P tuples for which the full align-ment paradigm contains the given term, withoutconsideration ofwhether that instance occurs withina correct alignment or not.
This can be representedas in equation (1), in the case offreq((g,p)), where pis the phoneme string aligning with grapheme string9 and phon_var(p) describes the set of phonologicalalternates of p.Phonological alternates are predictable instancesof phonological lternation from a base form p, withthe most widespread types of phonological alterna-tion being "sequential voicing" (Tsujimura, 1996,54-63) and gemination; if no method were providedto cluster frequencies for phonological lternates to-gether, data sparseness and skewing of the statisticalmodel would inevitably result.
The current systemhas no way of predicting exactly what form of phono-logical alternation is likely to occur in what lexicalcontext.
One observation which can be made, how-ever, is that phonological lternation affects only thephoneme string, and occurs only at the interface be-tween adjacent phoneme segments on a single sylla-ble level.
It is thus possible to establish phonologicalequivalence classes at the unit syllable level, and usethese to determine the maximum scope of phonolog-ical alternation which could realistically be expectedof a given phoneme string.Formally, for a given phoneme string p = sl s2...Snaligning with grapheme string g, where each siis a syllable unit, we thus generate a regularexpression of all plausible phonological alterna-tions {8a18b\]...}S2...{8ot18j31...}, where (SalSbI...} andSa \]s~\]...} are the phonological equivalence classesr Sl and sn respectively.
For example, given thephoneme string ka-ku, we would generate the string-level equivalence class {ka\[ga}{ku\[gu\]?
}, 4 where theka/ga and ku/gu unit grapheme alternations are at-tributable to sequential voicing, and the ku/?
alter-nation to gemination.The frequencies of all phonological alternationssubsumed by the string-level equivalence class arethen combined within freq((g,p)).
We are able tohandle phonological lternation within the bounds ofthe original statistical formulation by virtue of thefact that the grapheme string is unchanged underphonological alternation, and as such the combinedfrequencies of alternates can never exceed the fre-quency of the associated grapheme string segment.This guarantees a tf value in the range \[0, 1\].3 .3  The  mod i f ied  t f - id f  mode lOur interpretation of the TF-IDF model is givenin equation (2), where g is a grapheme unit, p aphoneme unit and ctxt some lexical context for (g, p)within the current alignment; \[req((g}), freq((g,p})and freq((g,p, ctxt)) are the frequencies of occur-rence of g, the tuple (g,p), and the tuple (g,p) in lex-ical context ctxt, respectively.
The subtractions by afactor of one are designed to remove from calculationthe single occurrences of (g, p) and (g, p, ctxt) in theambiguation - see Section 4.4Here, ?
designates the head of a long consonant, alsoindicated by/Q/ in  phonological theory.current alignment, and c~ is an additive smoothingconstant, where 0 < c~ < 1.Consideration of lexical context for a given tuple(g,Pl is four-fold, made up of the single characterimmediately adjacent o g in the graphe~-  s t~and single syllable immediately adjacent o p in thephoneme string, for both the left and right direc-tions.
In the case that (g,Pl is a prefix of the overallG-P string pair, we disregard left lexical context andsimply score according to t\], that is the ratio of oc-currence of g with reading p, for the two left contextscores.
Correspondingly in the case of (g,p) beinga suffix, we disregard right context.
The four resul-tant scores are then combined by taking the arith-metic mean.
In the case of full-string unit alignment,therefore, the overall score becomes tf((g,p)).The overall score for the current alignment("align_score") is determined by way of the arith-metic mean of the averaged scores for each seg-ment pairing, with the exception of full kana-basedgrapheme segments which are removed from compu-tation altogether.3 .4  Verb /ad jec t ive  con jugat ionThere is one remaining form of commonly-occurringalternation which cannot be resolved easily withinthe confines of the TF- IDF model.
This is ver-bal/adjectival conjugation, and is difficult to copewith given the existing statistical formulation be-cause it occurs concurrently at both the graphemeand phoneme levels (i.e.
we have no immediate ceil-ing on combined frequencies as was the case forphonological alternation).
We model conjugation-based alternation by postulating verb paradigmsbased on conjugational analysis of the kana suffixto a given stem (Baldwin, 1998).
This postula-tion of verb paradigms is performed independentof any static verb dictionary, and is achieved sim-ply by clustering legal verb stem-inflectional suffixsegments according to verb stem and conjugationalclass.
For example, for the aligned segment (~-< )-(to-ku I (which constitutes the non-past form ofthe verb tok(-u) "to undo"), conjugational analy-sis would reveal the possibility, of the segment beingcomprised of the verb stem of ~ and inflectional suf-fix of kw.
Subsequent analysis of the corpus may wellunearth what constitute conjugates of the same verbpostulate, in to-ki, for example.
This could then becomplemented by consideration of phonological al-ternation as above, to produce the verb paradigm( toku, doku, toki, dokz).To be able to combine scoring of verb conjugatesof the same verb paradigm within the original for-mulation (i.e.
TF), we now require some base form ofthe verb which is guaranteed to occur with at leastthe same frequency as all its alternates, and henceconstrain the value of TF to the range \[0, 1\].For method-l, it is possible to consider the(invariant) verb stem as the base form of theverb.
5 In equation (2), we thus replace freq((g)) byfreqy_ 1 ((g)), that is the frequency of the graphemiccomponent of verb stem g (irrespective of whether5Although discussion here refers exclusively to verbs, (con-jugating) adjectives are handled in exactly the same manner.13or not it is contained within a recognised conju-gation of the verb, and also irrespective of whatphoneme segment it aligns with), and in equation(1), phon_var(p) becomes the augmented set of allphonological alternates of all conjugations of theverb p. Scoring is now carried out by way of the sim-ple TF model, without recourse to IDF.
This designdecision was made based on the observation that in-herent delimitation of verb conjugates is providedthrough inflection-based analysis, such that there islittle danger of under- or over-aligning the segmentin question.This leaves us in the position of having two sepa-rate means of scoring verb conjugate postulates, onevia the basic TF-IDF formulation described in Sec-tion 3.3, and one through the TF-based conjugationmodel described in the above paragraph.
In cases ofsuch analytical ambiguity, there is potential for theverb conjugate-based analysis to be either wrong orunder-scored ue to data sparseness.
Rather thanestablishing a fixed precedence between the two re-sulting scores, therefore, we take the maximum ofthem as the overall score for the segment in ques-tion, and do not commit ourselves apriori to eitheranalysis.This completes the formulation of method-1.
6In method-2, on the other hand, we are unable tofound our frequency count on the base form of theverb, as the whole verb conjugate constitutes a sin-gle morpho-phonic segment for disambiguated align-ments.
As such, no instance of the verb stem can befound as an individual segment.
We thus modifyour definition of freq((g)) somewhat to freqy_2((g)):the frequency of all G-P tuples for which there is analignment candidate containing a conjugate xistingin the same inflection paradigm as g. While thisprovides us with a ceiling for the raw frequenciesof verbs and adjectives, weighting up of verb conju-gates found in solution set w (see below) allows forthe possibility of a TF score greater than 1.
To avoidthis situation, we multiply the maximum conjugatefrequency by the solution weighting factor sw\] (seebelow), guaranteeing that the TF value for conjugat-ing segments i always in the range \[0, 1\].
In practice,this means that the score for a given verb inflectionis initialised to c~ and tends to converge to either swf '0 (in the case of the postulated verb paradigm beingrejected for each conjugate instance), or 1 (in thecase of it being accepted).3 .5  Incrementa l ly  learn ing  w i thmethod-2We are now in the position of being able to setmethod-2 running, and the only remaining consid-eration is exactly how we should select which align-ment paradigm to disambiguate at each iteration,and how to implement he incrementality of thelearning method.Selection of the alignment paradigm for disam-biguation is achieved through the application of adiscriminative metric.
Two metrics were tentatively6For discussion of further variations on raethod-1, see(Baldwin and Tanaka, 1999).trialled for this purpose.
The first consists of thesimple ratio dml -- ~ between the highest and sec- 82ond highest ranking scores sl and s2 ("the odds ra-tio"), in the manner of (Dagan and Ital, 1994).
Thesecond discriminative metric (dm2) is a slight vari-ation on this whereby we take the log of the ratioof the highest ranking score to the second rankingscore ("the log odds ratio"), and multiply it by thehighest ranking score, i.e.
sl log ~.
The G-P tuples 82contained in ?
are ranked in descending order ac-cording to the particular discriminative metric ofuse, and the G-P tuple with the highest rank (i.e.with greatest system "conviction" in the top-rankingalignment candidate) is disambiguated based on thetop-scoring alignment candidate.The first discriminative metric is heuristic, andbased on the intuition that we are after maxi-mum disparity in score between the first and sec-ond ranked candidates.
The second discriminativemetric, on the other hand, is designed to balance upmaximisation of both sl and the relative disparitybetween sl and s2.
Note that, unlike Dagan and Itai(1994), we give no consideration to statistical confi-dence as we are after 100% recall, whatever the costto precision.To this point, the only difference over method-1 isthe sequence in which solutions are output.
How-ever, by singling out a G-P alignment candidate ofmaximum discrimination on each iteration, it nowbecomes possible to refine the statistical model bytraining it on aligned output (i.e.
G-P tuples storedin w in Fig.
2), hence: (a) alleviating statistics deriv-ing from less-plausible alignments, and (b) weight-ing up term frequencies found in final disambiguatedalignments.
Neither of these processes are possibleunder the simple statistical model as all alignmentsare processed in parallel, and the system is unable tocommit itself to the plausibility of any given align-ment in scoring others.The weighting up of terms found in solution align-ments is achieved through the use of two weightingfactors on term frequencies, one for terms found incandidate alignments (?)
and one for terms foundin solution alignments (w), namely the candidateweighting \]actor (cw\]) and solution weighting \]actor(sw\]), respectively; naturally, 0 < a < cwf < sw\].4 Eva luat ionAs a test set, a set of 5000 G-P tuples was randomlyextracted from the EDICT English-Japanese dictio-nary 7 and Shinmeikal Japanese dictionary (Naga-sawa, 1981) and each tuple annotated with its align-ment for evaluation purposes.
So as to be ableto properly evaluate the success of application ofthe alignment constraints, we further augmented theoriginal 5000 G-P tuples with 1403 lexical alternatesthereof (so as to provide full scope for constraint-based pruning).
Our motivation in using this limiteddata set was to be able to run method-2 to comple-tion and attain empirically comparable results forthe two proposed methods.7 ftp ://ftp.
cc.monash, edu.
au/pub/nihongo14In evaluation, method-1 was used withthe c~ smoothing constant set variously to{0.25,0.05,0.001,0.0001}.
For method-2, cwfand swf were fixed at 0.5 and 1.0 respectively, andc~ set variously to {0.05, 0.0001} for discriminativemetric dml, and {0.25, 0.05, 0.001} for dm2.By way of a baseline for evaluation, we used therule-based method proposed by Bilac et al (1999),which achieved an alignment accuracy of 92.90%when run over the full dictionary file of 59744 entriesand empirically evaluated on the same 5000-tupledata set as was used for method-1 and method-2.Note that the Bilac system requires a training set ofstandard readings for each unit kanji and also a verbconjugational dictionary, whereas both our proposedmethods have no reliance on external evidence.
It isalso worth emphasising that our methods were heav-ily handicapped over the rule-based method, in thatthey were not able to apply statistics derived fromthe remaining 52744 entries in refining their respec-tive statistical models.
However, in terms of empir-ical evaluation of the three methods, the respectivesystem accuracies are directly comparable.Baseline - -Method.
1 "X*Method-2 (drn ~, cwf=0.5, swf= 1) "'~-"Method.2 (din2, cwf=0.5, swf=l )?
.
- .
-?
.
.
.
.
.
.
.
.
.
.
?~90o~875 , * t0.06 0001 0.0001O~X"0.25Figure 3: Accuracies of the different methodsAs evidenced in Fig.
3, method-1 achieved a max-imum accuracy of 86.74% (with a = 0.0001), signif-icantly below that of the baseline method.
Basedon the curve for method-l, it would appear that themethod performs best with infinitesimally small avalues.
This perhaps points to limitations in our"plus constant a" smoothing methodology.
In starkcontrast, method-2, achieved a maximum accuracyof 93.28% (using dm2, with a = 0.05), just out-stripping the baseline method despite its handicapin terms of diversity of input data.
Little differ-ence was seen between accuracies for discriminativemetrics din1 and din2, although din2 generally per-formed marginally better.
For the given cwf andtwf values, it would appear that an a value around0.05 is optimal, providing an interesting comparisonwith the seemingly asymptotic nature of the method-1 curve.
While we are unable to present he resultshere, varying the relative values of cwf and twf pro-duced little difference over the accuracies in Fig.
3,for comparative a values.The most common type of system error formethod-1 was under-alignment (where the correctalignment is properly subsumed by the system align-ment).
That the system accuracy increases with di-minishing a value is a result of decreases in under-alignment outweighing increases in over-alignmentand over-segmentation on conjugating morphemes.For method-2, the greatest single error type is over-segmentation f conjugating morphemes (principallyverbs), accounting for 58.95% of all errors for dm2with a set to 0.001.
It would appear that forrelatively larger values of a, instances of under-alignment increase, and for relatively smaller val-ues of a, instances of over-alignment and over-segmentation i crease.So as to get an insight into its true potential, weredid evaluation of method-l, over the full dictionaryset this time with a set to 0.05 (using the same 5000tuples for evaluation as before).
This produced anaccuracy of 93.96%, pointing to the potential for aeven higher accuracy for method-2 over the full dic-tionary set.Analysis of the effectiveness of the lexical andphonological constraints indicated that we are ableto reduce the cardinality of alignment by almost75%, from 13.80 to 4.10, on average.
Indeed, fulldisambiguation was possible for 603 of the 5000 en-tries (including 480 singleton entries).
Importantly,there were no instances of the correct alignment be-ing pruned due to over-constraint.
The individualconstraints were activated with the frequencies in-dicated below, with constraints higher in the tabletaking precedence over those lower in the table inthe case of a given alignment violating more thanone constraint.
(1)(pl)(p2)Times activated Relative freq.of application18481 34.41%9076 16.90%11383 21.19%9292 17.30%14297 26.62%7 ~.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Discrirninative__1100I \  .....
I, "', 94O ~  ~603 1483 2362 Output  no .
3242 4121Figure 4: The relation between mean accuracy anddiscriminative value for method-2To further examine the correspondence b tweenthe size of the discriminative ratio and system accu-racy for method-2, we plotted both the system accu-racy and discriminative value against he rank of sys-15tem output (Fig.
4 - based on dm2 with a = 0.05).Here, we disregard all alignments where constraintsproduced full disambiguation (603 instances), suchthat the rank of the first statistically disambiguatedinput is 604.
The indicated accuracies and discrimi-native values are averaged over discrete corridors of220 entries centering on the given output ranks.Looking to the results, it is important firstly to no-tice that we realise an accuracy of 100% in the initialstages of output (up to rank 1703), which progres-sively degrades down to 92.38% over the final corri-dor with zero discriminative.
Note also that whereasthe discriminative curve is monotonically decreasingwhen averaged over the given corridor, in practice lo-cal maximums do exist, attributable to the situationwhere re-training of the statistical model producesinflation of the maximum discriminative value.5 Other appl ications of thisresearchOther than the constraints described in Section 2and frequency determination techniques, the pro-posed methodology is theoretically scalable to anydomain where two streams of chunked informationrequire alignment.
This suggests applications to theextraction of translation pairs from aligned bilin-gual corpora (Gale and Church, 1991; Kupiec, 1993;Smadja et al, 1996), where the system input wouldbe made up of aligned strings (generally sentences)in the two languages.
Given that we can devise someway of creating an alignment paradigm between thetwo input segments, it is possible to apply the scor-ing and learning methods proposed herein in theirexisting forms.
Note, however, that in the case oftranslation pair extraction, there is a real possibil-ity of the alignment mapping being many-to-many,and crossing over of alignment is expected to occurreadily.
In fact, it may occur that there is a residueof unaligned segments in either or both languages,as could easily occur if one language included zeroanaphora.
It may, therefore, be desirable to applya dynamic threshold on the discriminative ratio (cf.
(Dagan and Itai, 1994)) to accept only those trans-lation pairs with sufficiently high statistical confi-dence, for example.6 ConclusionIn this paper, we proposed an adaptation of theTF-IDF model to Japanese grapheme-phoneme align-ment.
We then went on to extend the basic statis-tical method to devise a fully unsupervised learn-ing method, by way of a two discrimination-basedmetrics and incremental refinement of the statis-tical model.
Experimentation suggested that theproposed learning method marginally outperformsboth a baseline rule-based method and the non-incremental statistical method.Items of future research include expanding eval-uation of the incremental learning method to thefull dictionary file used in this research, as well asto other Japanese dictionaries/genres and other lan-guages.AcknowledgementsThe authors would like to thank Assoc.
Prof.Noguchi, Assoc.
Prof. Tokunaga, Masahiro Ueki,Christoph Neumann and two anonymous reviewersfor their insightful comments on earlier versions ofthis paper.
We also pay tribute to the heroic ef-forts of Slaven Bilac in implementing the rule-basedversion of the system.ReferencesT.
Baldwin and H. Tanaka.
1999.
Automated Japanesegrapheme-phoneme alignment.
In Proceedings ofthe International Conference on Cognitive Science,Tokyo.
(to appear).T.
Baldwin.
1998.
The Analysis of Japanese RelativeClauses.
Master's thesis, Tokyo Institute of Technol-ogy.S.
Bilac, T. Baldwin, and H. Tanaka.
1999.
IncrementalJapanese grapheme-phoneme alignment.
In Informa-tion Processing Society of Japan SIG Notes, volume99-NL-209, pages 47-54.I.
Dagan and A. Itai.
1994.
Word sense disambiguationusing a second language monolingual corpus.
Compu-tational Linguistics, 20(4):563-96.M.
Divay and A.J.
Vitale.
1997.
Algorithmsfor grapheme-phoneme translation for English andFrench: Applications for database searches and speechsynthesis.
Computational Linguistics, 23(4):495-523.W.A.
Gale and K.W.
Church.
1991.
Identifying wordcorrespondences in parallel texts.
In Proceedings ofthe Fourth DARPA Speech and Natural LanguageWorkshop, pages 152-7.
Morgan Kaufmann.C.B.
Huang, M.A.
Son-Bell, and D.M.
Baggett.
1994.Generation of pronunciations from orthographies us-ing transformation-based error-driven learning.
InProc.
of the International Conference on Speech andLanguage Processing, pages 411-4.J.
It6 and R. Armin Mester.
1995.
Japanese phonology.In J.A.
Goldsmith, editor, The Handbook of Phono-logical Theory, chapter 29, pages 817-38.
Blackwell.D.H.
Klatt.
1987. Review of text to speech conversionfor English.
Journal of the Acoustic Society of Amer-ica, 82(3):737-793.J.
Kupiec.
1993.
An algorithm for finding noun phrasecorrespondences in bilingual corpora.
In Proceedingsof the 31st Annual Meeting off the ACL, pages 17-22.K.
Nagasawa, editor.
1981.
Shinmeikai Dictionary.
San-seido Publishers.G.
Salton and C. Buckley.
1990.
Improving retrieval per-formance by relevance f edback.
Journal of the Amer-ican Society for Information Science, 41(4):288-97.F.
Smadja, K.R.
McKeown, and V. Hatzivassiloglou.1996.
Translating collocations for bilingual lexicons:A statistical approach.
Computational Linguistics,22(1):1-38.N.
Tsujimura.
1996.
An Introduction to Japanese Lin-guistics.
Blackwell.16
