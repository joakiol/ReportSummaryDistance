iNeATS: Interactive Multi-Document SummarizationAnton Leuski, Chin-Yew Lin, Eduard HovyUniversity of Southern CaliforniaInformation Sciences Institute4676 Admiralty Way, Suite 1001Marina Del Rey, CA 90292-6695{leuski,cyl,hovy}@isi.eduAbstractWe describe iNeATS ?
an interactivemulti-document summarization systemthat integrates a state-of-the-art summa-rization engine with an advanced user in-terface.
Three main goals of the sys-tem are: (1) provide a user with controlover the summarization process, (2) sup-port exploration of the document set withthe summary as the staring point, and (3)combine text summaries with alternativepresentations such as a map-based visual-ization of documents.1 IntroductionThe goal of a good document summary is to providea user with a presentation of the substance of a bodyof material in a coherent and concise form.
Ideally, asummary would contain only the ?right?
amount ofthe interesting information and it would omit all theredundant and ?uninteresting?
material.
The qualityof the summary depends strongly on users?
presentneed ?
a summary that focuses on one of several top-ics contained in the material may prove to be eithervery useful or completely useless depending on whatusers?
interests are.An automatic multi-document summarizationsystem generally works by extracting relevant sen-tences from the documents and arranging them in acoherent order (McKeown et al, 2001; Over, 2001).The system has to make decisions on the summary?ssize, redundancy, and focus.
Any of these deci-sions may have a significant impact on the qualityof the output.
We believe a system that directly in-volves the user in the summary generation processand adapts to her input will produce better sum-maries.
Additionally, it has been shown that usersare more satisfied with systems that visualize theirdecisions and give the user a sense of control overthe process (Koenemann and Belkin, 1996).We see three ways in which interactivity andvisualization can be incorporated into the multi-document summarization process:1. give the user direct control over the summariza-tion parameters such as size, redundancy, andfocus of the summaries.2.
support rapid browsing of the document set us-ing the summary as the starting point and com-bining the multi-document summary with sum-maries for individual documents.3.
incorporate alternative formats for organizingand displaying the summary, e.g., a set of newsstories can be summarized by placing the sto-ries on a world map based on the locations ofthe events described in the stories.In this paper we describe iNeATS (InteractiveNExt generation Text Summarization) which ad-dresses these three directions.
The iNeATS systemis built on top of the NeATS multi-document sum-marization system.
In the following section we givea brief overview of the NeATS system and in Sec-tion 3 describe the interactive version.2 NeATSNeATS (Lin and Hovy, 2002) is an extraction-based multi-document summarization system.
It isamong the top two performers in DUC 2001 and2002 (Over, 2001).
It consists of three main com-ponents:Content Selection The goal of content selection isto identify important concepts mentioned ina document collection.
NeATS computes thelikelihood ratio (Dunning, 1993) to identify keyconcepts in unigrams, bigrams, and trigramsand clusters these concepts in order to identifymajor subtopics within the main topic.
Eachsentence in the document set is then ranked, us-ing the key concept structures.
These n-gramkey concepts are called topic signatures.Content Filtering NeATS uses three different fil-ters: sentence position, stigma words, and re-dundancy filter.
Sentence position has beenused as a good important content filter sincethe late 60s (Edmundson, 1969).
NeATS ap-plies a simple sentence filter that only retainsthe N lead sentences.
Some sentences startwith conjunctions, quotation marks, pronouns,and the verb ?say?
and its derivatives.
Thesestigma words usually cause discontinuities insummaries.
The system reduces the scores ofthese sentences to demote their ranks and avoidincluding them in summaries of small sizes.
Toaddress the redundancy problem, NeATS uses asimplified version of CMU?s MMR (Goldsteinet al, 1999) algorithm.
A sentence is added tothe summary if and only if its content has lessthan X percent overlap with the summary.Content Presentation To ensure coherence of thesummary, NeATS pairs each sentence with anintroduction sentence.
It then outputs the finalsentences in their chronological order.3 Interactive SummarizationFigure 1 shows a screenshot of the iNeATS system.We divide the screen into three parts correspondingto the three directions outlined in Section 1.
Thecontrol panel displays the summarization parame-ters on the left side of the screen.
The documentpanel shows the document text on the right side.
Thesummary panel presents the summaries in the mid-dle of the screen.3.1 Controlling Summarization ProcessThe top of the control panel provides the user withcontrol over the summarization process.
The first setof widgets contains controls for the summary size,sentence position, and redundancy filters.
The sec-ond row of parameters displays the set of topic sig-natures identified by the iNeATS engine.
The se-lected subset of the topic signatures defines the con-tent focus for the summary.
If the user enters a newvalue for one of the parameters or selects a differentsubset of the topic signatures, iNeATS immediatelyregenerates and redisplays the summary text in thetop portion of the summary panel.3.2 Browsing Document SetiNeATS facilitates browsing of the document set byproviding (1) an overview of the documents, (2)linking the sentences in the summary to the originaldocuments, and (3) using sentence zooming to high-light the most relevant sentences in the documents.The bottom part of the control panel is occupiedby the document thumbnails.
The documents are ar-ranged in chronological order and each document isassigned a unique color to paint the text backgroundfor the document.
The same color is used to drawthe document thumbnail in the control panel, to fillup the text background in the document panel, and topaint the background of those sentences in the sum-mary that were collected from the document.
Forexample, the screenshot shows that a user selectedthe second document which was assigned the or-ange color.
The document panel displays the doc-ument text on orange background.
iNeATS selectedthe first two summary sentences from this document,so both sentences are shown in the summary panelwith orange background.The sentences in the summary are linked to theoriginal documents in two ways.
First, the docu-ment can be identified by the color of the sentence.Second, each sentence is a hyperlink to the docu-ment ?
if the user moves the mouse over a sentence,the sentence is underlined in the summary and high-lighted in the document text.
For example, the firstsentence of the summary is the document sentenceFigure 1: Screenshot of the iNeATS system.highlighted in the document panel.
If the user clickson the sentence, iNeATS brings the source documentinto the document panel and scrolls the window tomake the sentence visible.The relevant parts of the documents are illumi-nated using the technique that we call sentencezooming.
We make the text color intensity of eachsentence proportional to the relevance score com-puted by the iNeATS engine and a zooming parame-ter which can be controlled by the user with a sliderwidget at the top of the document panel.
The higherthe sentence score, the darker the text is.
Conversely,sentences that blend into the background have a verylow sentence score.
The zooming parameter con-trols the proportion of the top ranked sentences vis-ible on the screen at each moment.
This zoomingaffects both the full-text and the thumbnail docu-ment presentations.
Combining the sentence zoom-ing with the document set overview, the user canquickly see which document contains most of therelevant material and where approximately in thedocument this material is placed.The document panel in Figure 1 shows sentencesthat achieve 50% on the sentence score scale.
We seethat the first half of the document contains two blacksentences: the first sentence that starts with ?US In-surers...?, the other starts with ?President George...?.Both sentences have a very high score and they wereselected for the summary.
Note, that the very firstsentence in the document is the headline and it is notused for summarization.
Note also that the sentencethat starts with ?However,...?
scored much lowerthan the selected two ?
its color is approximatelyhalf diluted into the background.There are quite a few sentences in the second partof the document that scored relatively high.
How-ever, these sentences are below the sentence positioncutoff so they do not appear in the summary.
We il-lustrate this by rendering such sentences in slantedstyle.3.3 Alternative SummariesThe bottom part of the summary panel is occupiedby the map-based visualization.
We use BBN?sIdentiFinder (Bikel et al, 1997) to detect the namesof geographic locations in the document set.
Wethen select the most frequently used location namesand place them on world map.
Each location is iden-tified by a black dot followed by a frequency chartand the location name.
The frequency chart is a barchart where each bar corresponds to a document.The bar is painted using the document color and thelength of the bar is proportional to the number oftimes the location name is used in the document.The document set we used in our example de-scribes the progress of the hurricane Andrew and itseffect on Florida, Louisiana, and Texas.
Note thatthe source documents and therefore the bars in thechart are arranged in the chronological order.
Thename ?Miami?
appears first in the second document,?New Orleans?
in the third document, and ?Texas?
isprominent in the last two documents.
We can makesome conclusions on the hurricane?s path throughthe region ?
it traveled from south-east and made itslanding somewhere in Louisiana and Texas.4 DiscussionThe iNeATS system is implemented in Java.
It usesthe NeATS engine implemented in Perl and C. Itruns on any platform that supports these environ-ments.
We are currently working on making the sys-tem available on our web site.We plan to extend the system by adding temporalvisualization that places the documents on a timelinebased on the date and time values extracted from thetext.We plan to conduct a user-based evaluation of thesystem to compare users?
satisfaction with both theautomatically generated summaries and summariesproduced by iNeATS.ReferencesDaniel M. Bikel, Scott Miller, Richard Schwartz, andRalph Weischedel.
1997.
Nymble: a high-performance learning name-finder.
In Proceedings ofANLP-97, pages 194?201.Ted E. Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Computational Lin-guistics, 19(1):61?74.H.
P. Edmundson.
1969.
New methods in automatic ex-traction.
Journal of the ACM, 16(2):264?285.Jade Goldstein, Mark Kantrowitz, Vibhu O. Mittal, andJaime G. Carbonell.
1999.
Summarizing text docu-ments: Sentence selection and evaluation metrics.
InResearch and Development in Information Retrieval,pages 121?128.Jurgen Koenemann and Nicholas J. Belkin.
1996.
A casefor interaction: A study of interactive information re-trieval behavior and effectivness.
In Proceedings ofACM SIGCHI Conference on Human Factors in Com-puting Systems, pages 205?212, Vancouver, BritishColumbia, Canada.Chin-Yew Lin and Eduard Hovy.
2002.
From singleto multi-document summarization: a prototype sys-tem and it evaluation.
In Proceedings of the 40thAnniversary Meeting of the Association for Computa-tional Linguistics (ACL-02), Philadelphia, PA, USA.Kathleen R. McKeown, Regina Barzilay, David Evans,Vasileios Hatzivassiloglou, Barry Schiffman, and Si-mone Teufel.
2001.
Columbia multi-document sum-marization: Approach and evaluation.
In Proceed-ings of the Workshop on Text Summarization, ACM SI-GIR Conference 2001.
DARPA/NIST, Document Un-derstanding Conference.Paul Over.
2001.
Introduction to duc-2001: an intrin-sic evaluation of generic news text summarization sys-tems.
In Proceedings of the Workshop on Text Summa-rization, ACM SIGIR Conference 2001.
DARPA/NIST,Document Understanding Conference.
