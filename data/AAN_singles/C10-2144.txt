Coling 2010: Poster Volume, pages 1256?1264,Beijing, August 2010Extraction of Multi-word Expressions from Small Parallel CorporaYulia TsvetkovDepartment of Computer ScienceUniversity of Haifayulia.tsvetkov@gmail.comShuly WintnerDepartment of Computer ScienceUniversity of Haifashuly@cs.haifa.ac.ilAbstractWe present a general methodology for ex-tracting multi-word expressions (of vari-ous types), along with their translations,from small parallel corpora.
We auto-matically align the parallel corpus and fo-cus on misalignments; these typically in-dicate expressions in the source languagethat are translated to the target in a non-compositional way.
We then use a largemonolingual corpus to rank and filter theresults.
Evaluation of the quality of the ex-traction algorithm reveals significant im-provements over na?
?ve alignment-basedmethods.
External evaluation shows animprovement in the performance of ma-chine translation that uses the extracteddictionary.1 IntroductionMulti-word Expressions (MWEs) are lexicalitems that consist of multiple orthographic words(e.g., ad hoc, by and large, New York, kick thebucket).
MWEs are numerous and constitute asignificant portion of the lexicon of any naturallanguage.
They are a heterogeneous class of con-structions with diverse sets of characteristics, dis-tinguished by their idiosyncratic behavior.
Mor-phologically, some MWEs allow some of theirconstituents to freely inflect while restricting (orpreventing) the inflection of other constituents.
Insome cases MWEs may allow constituents to un-dergo non-standard morphological inflections thatthey would not undergo in isolation.
Syntactically,some MWEs behave like words while other arephrases; some occur in one rigid pattern (and afixed order), while others permit various syntactictransformations.
Semantically, the compositional-ity of MWEs is gradual, ranging from fully com-positional to idiomatic (Bannard et al, 2003).Because of their prevalence and irregularity,MWEs must be stored in lexicons of natural lan-guage processing applications.
Handling MWEscorrectly is beneficial for a variety of applications,including information retrieval, building ontolo-gies, text alignment, and machine translation.Identifying MWEs and extracting them fromcorpora is therefore both important and difficult.In Hebrew (which is the subject of our research),this is even more challenging due to two reasons:the rich and complex morphology of the language;and the dearth of existing language resources, inparticular parallel corpora, semantic dictionariesand syntactic parsers.We propose a novel algorithm for identifyingMWEs in bilingual corpora, using automatic wordalignment as our main source of information.
Incontrast to existing approaches, we do not limitthe search to one-to-many alignments, and pro-pose an error-mining strategy to detect misalign-ments in the parallel corpus.
We also consult alarge monolingual corpus to rank and filter outthe expressions.
The result is fully automatic ex-traction of MWEs of various types, lengths andsyntactic patterns, along with their translations.We demonstrate the utility of the methodology onHebrew-English MWEs by incorporating the ex-tracted dictionary into an existing machine trans-lation system.The main contribution of the paper is thus anew alignment-based algorithm for MWE extrac-tion that focuses on misalignments, augmented byvalidating statistics computed from a monolingualcorpus.
After discussing related work, we detail inSection 3 the methodology we propose.
Section 4provides a thorough evaluation of the results.
Wethen extract translations of the identified MWEsand evaluate the contribution of the extracted dic-tionary in Section 5.
We conclude with sugges-tions for future research.12562 Related WorkEarly approaches to identifying MWEs concen-trated on their collocational behavior (Church andHanks, 1989).
Pecina (2008) compares 55 dif-ferent association measures in ranking GermanAdj-N and PP-Verb collocation candidates.
Thiswork shows that combining different collocationmeasures using standard statistical classificationmethods improves over using a single collocationmeasure.
Other results (Chang et al, 2002; Villav-icencio et al, 2007) suggest that some collocationmeasures (especially PMI and Log-likelihood) aresuperior to others for identifying MWEs.
Soon,however, it became clear that mere co-occurrencemeasurements are not enough to identify MWEs,and their linguistic properties should be exploitedas well (Piao et al, 2005).
Hybrid methods thatcombine word statistics with linguistic informa-tion exploit morphological, syntactic and seman-tic idiosyncrasies to extract idiomatic MWEs.Semantic properties of MWEs can be usedto distinguish between compositional and non-compositional (idiomatic) expressions.
Katz andGiesbrecht (2006) and Baldwin et al (2003) useLatent Semantic Analysis for this purpose.
Theyshow that compositional MWEs appear in con-texts more similar to their constituents than non-compositional MWEs.
Van de Cruys and Vil-lada Moiro?n (2007) use unsupervised learningmethods to identify non-compositional MWEs bymeasuring to what extent their constituents can besubstituted by semantically related terms.
Suchtechniques typically require lexical semantic re-sources that are unavailable for Hebrew.An alternative approach to using semantics cap-italizes on the observation that an expressionwhose meaning is non-compositional tends to betranslated into a foreign language in a way thatdoes not result from a combination of the literaltranslations of its component words.
Alignment-based techniques explore to what extent wordalignment in parallel corpora can be used to dis-tinguish between idiomatic expressions and moretransparent ones.
A significant added value ofsuch works is that MWEs can thus be both iden-tified in the source language and associated withtheir translations in the target language.Villada Moiro?n and Tiedemann (2006) focuson Dutch expressions and their English, Spanishand German translations in the Europarl corpus(Koehn, 2005).
To extract the candidates, they usesyntactic properties (based on full parsing of theDutch text) and statistical association measures.This approach requires syntactic resources that areunavailable for Hebrew.Some recent works concentrate on exploit-ing translational correspondences of MWEs from(small) parallel corpora.
MWE candidates andtheir translations are extracted as a by-product ofautomatic word alignment of parallel texts.
Un-like Villada Moiro?n and Tiedemann (2006), whouse aligned parallel texts to rank MWE candi-dates, Caseli et al (2009) actually use them toextract the candidates.
After the texts are word-aligned, Caseli et al (2009) extract sequences oflength 2 or more in the source language that arealigned with sequences of length 1 or more in thetarget.
Candidates are then filtered out of this set ifthey comply with pre-defined part-of-speech pat-terns, or if they are not sufficiently frequent in theparallel corpus.
Even with the most aggressive fil-tering, precision is below 40% and recall is ex-tremely low (F-score is below 10 for all experi-ments).
Our setup is similar, but we extract MWEcandidates from the aligned corpus in a very dif-ferent way; and we use statistics collected from amonolingual corpus to filter and rank the results.Zarrie?
and Kuhn (2009) also use aligned par-allel corpora but only focus on one-to-many wordalignments.
To restrict the set of candidates, theyfocus on specific syntactic patterns as determinedby parsing both sides of the corpus (again, us-ing resources unavailable to us).
The results showhigh precision but very low recall.3 MethodologyWe propose an alternative approach to existingalignment-based techniques for MWE extraction.Using a small bilingual corpus, we extract MWEcandidates from noisy word alignments in a novelway.
We then use statistics from a large mono-lingual corpus to rank and filter the list of candi-dates.
Finally, we extract the translation of candi-date MWEs from the parallel corpus and use themin a machine translation (MT) system.12573.1 MotivationParallel texts are an obvious resource from whichto extract MWEs.
By definition, idiomatic ex-pressions have a non-compositional meaning, andhence may be translated to a single word (or toan expression with a different meaning) in a for-eign language.
The underlying assumption ofalignment-based approaches to MWE extractionis that MWEs are aligned across languages in away that differs from compositional expressions;we share this assumption.
However, existing ap-proaches focus on the results of word alignmentin their quest for MWEs, and in particular con-sider 1:n and n:m alignments as potential areasin which to look for MWEs.
This is problematicfor two reasons: first, word alignment algorithmshave difficulties aligning MWEs, and hence 1:nand n:m alignments are often noisy; while theseenvironments provide cues for identifying MWEs,they also include much noise.
Second, our exper-imental scenario is such that our parallel corpus isparticularly small, and we cannot fully rely on thequality of word alignments, but we have a bilin-gual dictionary that compensates for this limita-tion.
In contrast to existing approaches, then, wefocus on misalignments: we trust the quality of1:1 alignments, which we verify with the dictio-nary; and we search for MWEs exactly in the ar-eas that word alignment failed to properly align,not relying on the alignment in these cases.Moreover, in contrast to existing alignment-based approaches, we also make use of a largemonolingual corpus from which statistics on thedistribution of word sequences in Hebrew aredrawn.
This has several benefits: of course, mono-lingual corpora are easier to obtain than parallelones, and hence tend to be larger and provide moreaccurate statistics.
Furthermore, this provides val-idation of the MWE candidates that are extractedfrom the parallel corpus: rare expressions thatare erroneously produced by the alignment-basedtechnique can thus be eliminated on account oftheir low frequency in the monolingual corpus.Specifically, we use pointwise mutual informa-tion (PMI) as our association measure.
While PMIhas been proposed as a good measure for identi-fying MWEs, it is also known not to discriminateaccurately between MWEs and other frequent col-locations.
This is because it promotes collocationswhose constituents rarely occur in isolation (e.g.,typos and grammar errors), and expressions con-sisting of some word that is very frequently fol-lowed by another (e.g., say that).
However, suchcases do not have idiomatic meanings, and henceat least one of their constituents is likely to have a1:1 alignment in the parallel corpus; we only usePMI after such alignments have been removed.An added value of our methodology is the au-tomatic production of an MWE translation dictio-nary.
Since we start with a parallel corpus, wecan go back to that corpus after MWEs have beenidentified, and extract their translations from theparallel sentences in which they occur.Finally, alignment-based approaches can besymmetric, and ours indeed is.
While our mainmotivation is to extract MWEs in Hebrew, a by-product of our system is the extraction of EnglishMWEs, along with their translations to Hebrew.This, again, contributes to the task of enrichingour existing bilingual dictionary.3.2 ResourcesOur methodology is in principle language-independent and appropriate for medium-densitylanguages (Varga et al, 2005).
We assume thefollowing resources: a small bilingual, sentence-aligned parallel corpus; large monolingual cor-pora in both languages; morphological processors(analyzers and disambiguation modules) for thetwo languages; and a bilingual dictionary.
Ourexperimental setup is Hebrew-English.
We usea small parallel corpus (Tsvetkov and Wintner,2010) consisting of 19,626 sentences, mostly fromnewspapers.
The corpus consists of 271,787 En-glish tokens (14,142 types) and 280,508 Hebrewtokens (12,555 types), and is similar in size to thatused by Caseli et al (2009).We also use data extracted from two mono-lingual corpora.
For Hebrew, we use themorphologically-analyzed MILA corpus (Itai andWintner, 2008) with part-of-speech tags producedby Bar-Haim et al (2005).
This corpus is muchlarger, consisting of 46,239,285 tokens (188,572types).
For English we use Google?s Web 1T cor-pus (Brants and Franz, 2006).Finally, we use a bilingual dictionary consist-1258ing of 78,313 translation pairs.
Some of the en-tries were collected manually, while others areproduced automatically (Itai and Wintner, 2008;Kirschenbaum and Wintner, 2010).3.3 Preprocessing the corporaAutomatic word alignment algorithms are noisy,and given a small parallel corpus such as ours,data sparsity is a serious problem.
To minimizethe parameter space for the alignment algorithm,we attempt to reduce language specific differencesby pre-processing the parallel corpus.
The impor-tance of this phase should not be underestimated,especially for alignment of two radically differentlanguages such as English and Hebrew (Dejean etal., 2003).Hebrew,1 like other Semitic languages, has arich, complex and highly productive morphology.Information pertaining to gender, number, defi-niteness, person, and tense is reflected morpho-logically on base forms of words.
In addition,prepositions, conjunctions, articles, possessives,etc., may be concatenated to word forms as pre-fixes or suffixes.
This results in a very large num-ber of possible forms per lexeme.
We therefore to-kenize the parallel corpus and then remove punc-tuation.
We analyze the Hebrew corpus morpho-logically and select the most appropriate analysisin context.
Adopting this selection, the surfaceform of each word is reduced to its base form,and bound morphemes (prefixes and suffixes) aresplit to generate stand-alone ?words?.
We also to-kenize and lemmatize the English side of the cor-pus, using the Natural Language Toolkit package(Bird et al, 2009).Then, we remove some language-specific dif-ferences automatically.
We remove frequent func-tion words: in English, the articles a, an and the,the infinitival to and the copulas am, is and are; inHebrew, the accusative marker at.
These forms donot have direct counterparts in the other language.For consistency, we pre-process the monolin-gual corpora in the same way.
We then computethe frequencies of all word bi-grams occurring ineach of the monolingual corpora.1To facilitate readability we use a transliteration of He-brew using Roman characters; the letters used, in Hebrewlexicographic order, are abgdhwzxTiklmns?pcqrs?t.3.4 Identifying MWE candidatesThe motivation for our MWE identification algo-rithm is the assumption that there may be threesources to misalignments (anything that is nota 1:1 word alignment) in parallel texts: eitherMWEs (which trigger 1:n or n:m alignments);or language-specific differences (e.g., the sourcelanguage lexically realizes notions that are re-alized morphologically, syntactically or in someother way in the target language); or noise (e.g.,poor translations, low-quality sentence alignment,and inherent limitations of word alignment algo-rithms).This motivation induces the following algo-rithm.
Given a parallel, sentence-aligned corpus,it is first pre-processed as described above, to re-duce the effect of language-specific differences.We then use Giza++ (Och and Ney, 2003) to word-align the text, employing union to merge the align-ments in both directions.
We look up all 1:1 align-ments in the dictionary.
If the pair exists in ourbilingual dictionary, we remove it from the sen-tence and replace it with a special symbol, ?
*?.Such word pairs are not parts of MWEs.
If thepair is not in the dictionary, but its alignment scoreis very high (above 0.5) and it is sufficiently fre-quent (more than 5 occurrences), we add the pairto the dictionary but also retain it in the sentence.Such pairs are still candidates for being (parts of)MWEs.Example 1 Figure 1-a depicts a Hebrew sentencewith its word-by-word gloss, and its English trans-lation in the parallel corpus.
Here, bn adm ?per-son?
is a MWE that cannot be translated literally.After pre-processing (Section 3.3), the English isrepresented as ?and i tell her keep away from per-son?
(note that to and the were deleted).
The He-brew, which is aggressively segmented, is repre-sented as in Figure 1-b.
Note how this reduces thelevel of (morphological and orthographic) differ-ence between the two languages.
Consequently,Giza++ finds the alignment depicted in Figure 1-c. Once 1:1 alignments are replaced by ?
*?, thealignment of Figure 1-d is obtained.If our resources were perfect, i.e., if word align-ment made no errors, the dictionary had perfectcoverage and our corpora induced perfect statis-1259a.
wamrti lh lhzhr mbn adm kzhand-I-told to-her to-be-careful from-child man like-this?and I told her to keep away from the person?b.
w ani amr lh lhzhr m bn adm k zhand I tell to-her to-be-careful from child man like thisc.
w ani amr lh lhzhr m bn adm k zhand I told her keep away from person {} {}d. * * * * lhzhr * bn adm k zh* * * * keep away * personFigure 1: Example sentence pair (a); after pre-processing (b); after word alignment (c); and after 1:1alignments are replaced by ?*?
(d)tics, then all remaining text (other than the spe-cial symbol) in the parallel text would be part ofMWEs.
In other words, all sequences of remain-ing source words, separated by ?
*?, are MWE can-didates.
As our resources are far from perfect, fur-ther processing is required in order to prune thesecandidates.
For this, we use association measurescomputed from the monolingual corpus.3.5 Ranking and filtering MWE candidatesThe algorithm described above produces se-quences of Hebrew word forms (free and boundmorphemes produced by the pre-processing stage)that are not 1:1-aligned, separated by ?*?s.
Eachsuch sequence is a MWE candidate.
In order torank the candidates we use statistics from a largemonolingual corpus.
We do not rely on the align-ments produced by Giza++ in this stage.We extract all word bi-grams from the remain-ing candidates.
Each bi-gram is associated with itsPMI-based score,2 computed from the monolin-gual corpus.
Interestingly, about 20,000 candidateMWEs are removed in this stage because they donot occur at all in the monolingual corpus.We then experimentally determine a threshold(see Section 4).
A word sequence of any lengthis considered MWE if all the adjacent bi-grams it2PMIk is a heuristic variant of the PMI measure, pro-posed and studied by Daille (1994), where k, the exponent, isa frequency-related factor, used to demote collocations withlow-frequency constituents.
The value of the parameter k canbe chosen freely (k > 0) in order to tune the properties of thePMI to the needs of specific applications.
We conducted ex-periments with k = 0, 0.1, ... , 3 and found k = 2.7 to give thebest results for our application.contains score above the threshold.
Finally, werestore the original forms of the Hebrew wordsin the candidates, combining together bound mor-phemes that were split during pre-processing; andwe restore the function words.
Many of thecandidate MWEs produced in the previous stageare eliminated now, since they are not genuinelymulti-word in the original form.Example 2 Refer back to Figure 1-d.
The se-quence bn adm k zh is a MWE candidate.
Twobi-grams in this sequence score above the thresh-old: bn adm, which is indeed a MWE, and k zh,which is converted to the original form kzh and ishence not considered a candidate.
We also con-sider adm k, whose score is low.
Note that thesame aligned sentence can be used to induce theEnglish MWE keep away, which is aligned to asingle Hebrew word.3.6 ResultsAs an example of the results obtained with thissetup, we list in Table 1 the 15 top-ranking ex-tracted MWEs.
For each instance we list an indi-cation of the type of MWE: person name (PN),geographical term (GT), noun-noun compound(NNC) or noun-adjective combination (N-ADJ).Of the top 100 candidates, 99 are clearly MWEs,3including mzg awir (temper-of air) ?weather?,kmw kn (like thus) ?furthermore?, bit spr (house-of book ) ?school?, s?dh t?wph (field-of flying)?airport?, ts?wmt lb (input-of heart) ?attention?,ai aps?r (not possible) ?impossible?
and b?l ph3This was determined by two annotators.1260(in-on mouth ) ?orally?.
Longer MWEs includeba lidi biTwi (came to-the-hands-of expression)?was expressed?
; xzr ?l ?cmw (returned on itself )?recurred?
; ixd ?m zat (together with it) ?in ad-dition?
; and h?crt hkllit s?l haw?m (the general as-sembly of the UN ) ?the UN general assembly?.Hebrew Gloss Typexbr hknst MP NNCtl abib Tel Aviv GTgws?
qTip Gush Katif NNC-GTawpir pins Ophir Pines PNhc?t xwq Legislation NNCaxmd Tibi Ahmad Tibi PNzhwh glawn Zehava Galon PNras?
hmms?lh Prime Minister NNCabs?lwm wiln Avshalom Vilan PNbr awn Bar On PNmair s?Trit Meir Shitrit PNlimwr libnt Limor Livnat PNhiw?c hms?pTi Attorney General N-ADJtwdh rbh thanks a lot N-ADJrcw?t ?zh Gaza Strip NNC-GTTable 1: Results: extracted MWEs4 EvaluationMWEs are notoriously hard to define, and noclear-cut criteria exist to distinguish betweenMWEs and other frequent collocations.
In orderto evaluate the utility of our methodology, we con-ducted three different types of evaluations that wedetail below and in Section 5.First, we use a small annotated corpus ofHebrew noun-noun constructions that was madeavailable to us (Al-Haj and Wintner, 2010).
Thecorpus consists of 463 high-frequency bi-grams ofthe same syntactic construction; of those, 202 aretagged as MWEs (in this case, noun compounds)and 258 as non-MWEs.
This corpus consolidatesthe annotation of three annotators: only instanceson which all three agreed were included.
Since itincludes both positive and negative instances, thiscorpus facilitates a robust evaluation of precisionand recall.
Of the 202 positive examples, only 121occur in our parallel corpus; of the 258 negativeexamples, 91 occur in our corpus.
We thereforelimit the discussion to those 212 examples whoseMWE status we can determine, and ignore otherresults produced by the algorithm we evaluate.On this corpus, we compare the performanceof our algorithm to four baselines: using onlyPMI to rank the bi-grams in the parallel cor-pus; using PMI computed from the monolingualcorpus to rank the bi-grams in the parallel cor-pus; and using Giza++ 1:n alignments, rankedby their PMI (with bi-grams statistics computedonce from parallel and once from monolingualcorpora).
?MWE?
refers to our algorithm.
Foreach of the above methods, we set the thresholdat various points, and count the number of trueMWEs above the threshold (true positives) and thenumber of non-MWEs above the threshold (falsepositives), as well as the number of MWEs andnon-MWEs below the threshold (false positivesand true negatives, respectively).
From these fourfigures we compute precision, recall and their har-monic mean, f -score, which we plot against (thenumber of results above) the threshold in Figure 2.Clearly, the performance of our algorithm is con-sistently above the baselines.Second, we evaluate the algorithm on addi-tional datasets.
We compiled three small corporaof Hebrew two-word MWEs.
The first corpus,PN, contains 785 person names (names of Knessetmembers and journalists), of which 157 occur inthe parallel corpus.
The second, Phrases, consistsof 571 entries beginning with the letter x from adictionary of Hebrew phrases (Rosenthal, 2009),and a set of 331 idioms we collected from internetresources.
Of those, 154 occur in the corpus.
Thethird set, NN, consists of the positive examples inthe annotated corpus of noun-noun constructionsdescribed above.Since we do not have negative examples forthese sets, we only evaluate recall, using a thresh-old reflecting 2750 results.
For each of thesedatasets, we report the number of MWEs in thedataset (which also occur in the parallel corpus,of course) our algorithm detected.
We comparein Table 2 the recall of our method (MWE) toGiza++ alignments, as above, and list also theupper bound (UB), obtained by taking all above-threshold bi-grams in the corpus.1261Figure 2: Evaluation results compared with baselines: noun-noun compoundsMethod PN Phrases NN# % # % # %UB 74 100 40 100 89 100MWE 66 89.2 35 87.5 67 75.3Giza 7 9.5 33 82.5 37 41.6Table 2: Recall evaluation5 Extraction of MWE translationsAn obvious benefit of using parallel corpora forMWE extraction is that the translations of ex-tracted MWEs are available in the corpus.
We usea na?
?ve approach to identify these translations.
Foreach MWE in the source-language sentence, weconsider as translation all the words in the target-language sentence (in their original order) thatare aligned to the word constituents of the MWE,as long as they form a contiguous string.
Sincethe quality of word alignment, especially in thecase of MWEs, is rather low, we remove ?trans-lations?
that are longer than four words (these aremost often wrong).
We then associate each ex-tracted MWE in Hebrew with all its possible En-glish translations.The result is a bilingual dictionary contain-ing 2,955 MWE translation pairs, and also 355translation pairs produced by taking high-quality1:1 word alignments (Section 3.4).
We usedthe extracted MWE bilingual dictionary to aug-ment the existing (78,313-entry) dictionary of atransfer-based Hebrew-to-English statistical ma-chine translation system (Lavie et al, 2004b).
Wereport in Table 3 the results of evaluating the per-formance of the MT system with its original dic-tionary and with the augmented dictionary.
Theresults show a statistically-significant (p < 0.1)improvement in terms of both BLEU (Papineni etal., 2002) and Meteor (Lavie et al, 2004a) scores.Dictionary BLEU MeteorOriginal 13.69 33.38Augmented 13.79 33.99Table 3: External evaluationAs examples of improved translations, a sen-tence that was originally translated as ?His teach-ers also hate to the Zionism and besmirch hisHRCL and Gurion?
(fully capitalized words in-dicate lexical omissions that are transliterated bythe MT system) is translated with the new dic-tionary as ?His teachers also hate to the Zionismand besmirch his Herzl and David Ben-Gurion?
;a phrase originally translated as ?when so?
is nowproperly translated as ?likewise?
; and several oc-currences of ?down spring?
and ?height of spring?are corrected to ?Tel Aviv?.12626 ConclusionWe described a methodology for extracting multi-word expressions from parallel corpora.
The al-gorithm we propose capitalizes on semantic cuesprovided by ignoring 1:1 word alignments, andviewing all other material in the parallel sentenceas potential MWE.
It also emphasizes the impor-tance of properly handling the morphology andorthography of the languages involved, reducingwherever possible the differences between themin order to improve the quality of the alignment.We use statistics computed from a large mono-lingual corpus to rank and filter the results.
Weused the algorithm to extract MWEs from a smallHebrew-English corpus, demonstrating the abilityof the methodology to accurately extract MWEsof various lengths and syntactic patterns.
We alsodemonstrated that the extracted MWE bilingualdictionary can improve the quality of MT.This work can be extended in various ways.While several works address the choice of asso-ciation measure for MWE identification and fordistinguishing between MWEs and other frequentcollocations, it is not clear which measure wouldperform best in our unique scenario, where candi-dates are produced by word (mis)alignment.
Weintend to explore some of the measures discussedby Pecina (2008) in this context.
The algorithmused for extracting the translations of candidateMWEs is obviously na?
?ve, and we intend to ex-plore more sophisticated algorithms for improvedperformance.
Also, as our methodology is com-pletely language-symmetric, it can be used to pro-duce MWE candidates in English.
In fact, we al-ready have such a list of candidates, whose qual-ity we will evaluate in the future.
Finally, as ourmain motivation is high-precision, high-recall ex-traction of Hebrew MWEs, we develop other, non-alignment-based approaches to the task (Al-Hajand Wintner, 2010), and would like to explore theutility of combining different approaches to thesame task under a unified framework.
We are ac-tively pursuing these research directions.AcknowledgmentsThis research was supported by THE ISRAELSCIENCE FOUNDATION (grants No.
137/06,1269/07).
We are grateful to Hassan Al-Haj forproviding the noun compound annotated corpusand to Gennadi Lembersky for his help with themachine translation system.ReferencesAl-Haj, Hassan and Shuly Wintner.
2010.
Identify-ing multi-word expressions by leveraging morpho-logical and syntactic idiosyncrasy.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics (COLING 2010), August.Baldwin, Timothy, Colin Bannard, Takaaki Tanaka,and Dominic Widdows.
2003.
An empirical modelof multiword expression decomposability.
In Pro-ceedings of the ACL 2003 workshop on Multiwordexpressions, pages 89?96.
Association for Compu-tational Linguistics.Bannard, Colin, Timothy Baldwin, and Alex Las-carides.
2003.
A statistical approach to the seman-tics of verb-particles.
In Francis Bond, Anna Ko-rhonen, Diana McCarthy and Aline Villavicencio,editors, Proceedings of the ACL 2003 Workshop onMultiword Expressions: Analysis, Acquisition andTreatment, pages 65?72.Bar-Haim, Roy, Khalil Sima?an, and Yoad Winter.2005.
Choosing an optimal architecture for segmen-tation and POS-tagging of Modern Hebrew.
In Pro-ceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, pages 39?46,Ann Arbor, Michigan, June.
Association for Com-putational Linguistics.Bird, Steven, Ewan Klein, and Edward Loper.2009.
Natural Language Processing with Python.O?Reilly Media, Sebastopol, CA.Brants, Thorsten and Alex Franz.
2006.
Web 1T 5-gram version 1.1.
LDC Catalog No.
LDC2006T13.Caseli, Helena, Aline Villavicencio, Andre?
Machado,and Maria Jose?
Finatto.
2009.
Statistically-drivenalignment-based multiword expression identifica-tion for technical domains.
In Proceedings of theWorkshop on Multiword Expressions: Identifica-tion, Interpretation, Disambiguation and Applica-tions, pages 1?8, Singapore, August.
Associationfor Computational Linguistics.Chang, Baobao, Pernilla Danielsson, and WolfgangTeubert.
2002.
Extraction of translation unit fromChinese-English parallel corpora.
In Proceedingsof the first SIGHAN workshop on Chinese languageprocessing, pages 1?5, Morristown, NJ, USA.
As-sociation for Computational Linguistics.1263Church, Kenneth.
W. and Patrick Hanks.
1989.
Wordassociation norms, mutual information and lexicog-raphy (rev).
Computational Linguistics, 19(1):22?29.Daille, Be?atrice.
1994.
Approche mixte pourl?extraction automatique de terminologie : statis-tiques lexicales et filtres linguistiques.
Ph.D. thesis,Universite?
Paris 7.Dejean, Herve, Eric Gaussier, Cyril Goutte, and KenjiYamada.
2003.
Reducing parameter space forword alignment.
In Proceedings of the HLT-NAACL2003 Workshop on Building and using parallel texts,pages 23?26, Morristown, NJ, USA.
Association forComputational Linguistics.Itai, Alon and Shuly Wintner.
2008.
Language re-sources for Hebrew.
Language Resources and Eval-uation, 42:75?98, March.Katz, Graham and Eugenie Giesbrecht.
2006.
Au-tomatic identification of non-compositional multi-word expressions using latent semantic analysis.
InProceedings of the Workshop on Multiword Expres-sions: Identifying and Exploiting Underlying Prop-erties, pages 12?19, Sydney, Australia, July.
Asso-ciation for Computational Linguistics.Kirschenbaum, Amit and Shuly Wintner.
2010.
Ageneral method for creating a bilingual translitera-tion dictionary.
In Proceedings of The seventh in-ternational conference on Language Resources andEvaluation (LREC-2010), May.Koehn, Philipp.
2005.
Europarl: A parallel corpusfor statistical machine translation.
In Proceedingsof the MT Summit X, Phuket, Thailand.Lavie, Alon, Kenji Sagae, and Shyamsundar Jayara-man.
2004a.
The significance of recall in automaticmetrics for mt evaluation.
In Frederking, Robert E.and Kathryn Taylor, editors, AMTA, volume 3265 ofLecture Notes in Computer Science, pages 134?143.Springer.Lavie, Alon, Shuly Wintner, Yaniv Eytani, Erik Peter-son, and Katharina Probst.
2004b.
Rapid prototyp-ing of a transfer-based Hebrew-to-English machinetranslation system.
In Proceedings of TMI-2004:The 10th International Conference on Theoreticaland Methodological Issues in Machine Translation,Baltimore, MD, October.Och, Franz Josef and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Papineni, Kishore, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for auto-matic evaluation of machine translation.
In ACL?02: Proceedings of the 40th Annual Meeting onAssociation for Computational Linguistics, pages311?318, Morristown, NJ, USA.
Association forComputational Linguistics.Pecina, Pavel.
2008.
A machine learning approachto multiword expression extraction.
In Proceedingsof the LREC Workshop Towards a Shared Task forMultiword Expressions.Piao, Scott Songlin, Paul Rayson, Dawn Archer, andTony McEnery.
2005.
Comparing and combining asemantic tagger and a statistical tool for mwe extrac-tion.
Computer Speech and Language, 19(4):378?397.Rosenthal, Ruvik.
2009.
Milon HaTserufim (Dic-tionary of Hebrew Idioms and Phrases).
Keter,Jerusalem.
In Hebrew.Tsvetkov, Yulia and Shuly Wintner.
2010.
Automaticacquisition of parallel corpora from websites withdynamic content.
In Proceedings of The seventh in-ternational conference on Language Resources andEvaluation (LREC-2010), May.Van de Cruys, Tim and Begon?a Villada Moiro?n.
2007.Semantics-based multiword expression extraction.In Proceedings of the Workshop on A BroaderPerspective on Multiword Expressions, pages 25?32, Prague, Czech Republic, June.
Association forComputational Linguistics.Varga, Da?niel, Pe?ter Hala?csy, Andra?s Kornai, ViktorNagy, La?szlo?
Ne?meth, and Viktor Tro?n.
2005.
Par-allel corpora for medium density languages.
In Pro-ceedings of RANLP?2005, pages 590?596.Villada Moiro?n, Begon?a and Jo?rg Tiedemann.
2006.Identifying idiomatic expressions using automaticword alignment.
In Proceedings of the EACL 2006Workshop on Multi-word-expressions in a multilin-gual context.
Association for Computational Lin-guistics.Villavicencio, Aline, Valia Kordoni, Yi Zhang, MarcoIdiart, and Carlos Ramisch.
2007.
Validation andevaluation of automatically acquired multiword ex-pressions for grammar engineering.
In Proceed-ings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 1034?1043.Zarrie?, Sina and Jonas Kuhn.
2009.
Exploit-ing Translational Correspondences for Pattern-Independent MWE Identification.
In Proceedingsof the Workshop on Multiword Expressions: Identi-fication, Interpretation, Disambiguation and Appli-cations, pages 23?30, Singapore, August.
Associa-tion for Computational Linguistics.1264
