Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 125?128,Prague, June 2007. c?2007 Association for Computational LinguisticsCU-COMSEM: Exploring Rich Features for Unsupervised Web Per-sonal Name DisambiguationYing ChenCenter for Spoken Language ResearchUniversity of Colorado at Boulderyc@colorado.eduJames MartinDepartment of Computer ScienceUniversity of Colorado at BoulderJames.Martin@colorado.eduAbstractThe increasing number of web sources isexacerbating the named-entity ambiguityproblem.
This paper explores the use ofvarious token-based and phrase-based fea-tures in unsupervised clustering of webpages containing personal names.
Fromthese experiments, we find that the use ofrich features can significantly improve thedisambiguation performance for web per-sonal names.1 IntroductionAs the sheer amount of web information expandsat an ever more rapid pace, the named-entity am-biguity problem becomes more and more seriousin many fields, such as information integration,cross-document co-reference, and question an-swering.
Individuals are so glutted with informa-tion that searching for data presents real problems.It is therefore crucial to develop methodologiesthat can efficiently disambiguate the ambiguousnames from any given set of data.In the paper, we present an approach that com-bines unsupervised clustering methods with richfeature extractions to automatically cluster re-turned web pages according to which named en-tity in reality the ambiguous personal name in aweb page refers to.
We make two contributions toapproaches to web personal name disambiguation.First, we seek to go beyond the kind of bag-of-words features employed in earlier systems(Bagga & Baldwin, 1998; Gooi & Allan, 2004;Pedersen et al, 2005), and attempt to exploit deepsemantic features beyond the work of Mann &Yarowsky (2003).
Second, we exploit some fea-tures that are available only in a web corpus, suchas URL information and related web pages.The paper is organized as follows.
Section 2 in-troduces our rich feature extractions along withtheir corresponding similarity matrix learning.
InSection 3, we analyze the performance of our sys-tem.
Finally, we draw some conclusions.2 MethodologyOur approach follows a common architecture fornamed-entity disambiguation: the detection ofambiguous objects, feature extractions and theircorresponding similarity matrix learning, and fi-nally clustering.Given a webpage, we first run a modified Beau-tiful Soup1 (a HTML parser) to extract a clean textdocument for that webpage.
In a clean text docu-ment, noisy tokens, such as HTML tags and javacodes, are removed as much as possible, and sen-tence segmentation is partially done by followingthe indications of some special HTML tags.
Forexample, a sentence should finish when it meets a?<table>?
tag.
Then each clean document contin-ues to be preprocessed with MXTERMINATOR(a sentence segmenter), 2  the Penn Treebank to-kenization,3 a syntactic phrase chunker (Hacioglu,2004), and a named-entity detection and co-reference system for the ACE project4 called EX-1 http://www.crummy.com/software/BeautifulSoup2http://www.id.cbs.dk/~dh/corpus/tools/MXTERMINATOR.html3 http://www.cis.upenn.edu/~treebank/tokenization.html4 http://www.nist.gov/speech/tests/ace125ERT5 (Hacioglu et al 2005; Chen & Hacioglu,2006).2.1 The detection of ambiguous objectsFor a given ambiguous personal name, for eachweb page, we try to extract all mentions of theambiguous personal name, using three possiblevarieties of the personal name.
For example, thethree regular expression patterns for ?AlexanderMarkham?
are ?Alexander Markham,?
?Markham,Alexander,?
and ?Alexander .\.
Markham?
(?.\.
?can match a middle name).
Web pages withoutany mention of the ambiguous personal name ofinterest are discarded and receive no furtherprocessing.Since it is common for a single document tocontain one or more mentions of the ambiguouspersonal name of interest, there is a need to definethe object to be disambiguated.
Here, we adoptthe policy of ?one person per document?
(all men-tions of the ambiguous personal name in one webpage are assumed to refer to the same personalentity in reality) as in Bagga & Baldwin (1998),Mann & Yarowsky (2003) and Gooi & Allan(2004).
We therefore define an object as a singleentity with the ambiguous personal name in agiven web page.
This definition of the object(document-level object) might be mistaken, be-cause the mentions of the ambiguous personalname in a web page may refer to multiple entities,but we found that this is a rare case (most of thosecases occur in genealogy web pages).
On the otherhand, a document-level object can include muchinformation derived from that web page, so that itcan be represented by rich features.Given this definition of an object, we define atarget entity as an entity (outputted from theEXERT system) that includes a mention of theambiguous personal name.
Then, we define a localsentence as a sentence that contains a mention ofany target entity.2.2 Feature extraction and similarity matrixlearningMost of the previous work (Bagga & Baldwin,1998; Gooi & Allan; 2004; Pedersen et al, 2005)uses token information in the given documents.
Inthis paper, we follow and extend their work espe-cially for a web corpus.
On the other hand, com-5 http://sds.colorado.edu/EXERTpared to a token, a phrase contains more informa-tion for named-entity disambiguation.
Therefore,we explore some phrase-based information in thispaper.
Finally, there are two kinds of feature vec-tors developed in our system: token-based andphrase-based.
A token-based feature vector iscomposed of tokens, and a phrase-based featurevector is composed of phrases.2.2.1 Token-based featuresThere is a lot of token information available in aweb page: the tokens occurring in that web page,the URL for that web page, and so on.
Here, foreach web page, we tried to extract tokens accord-ing to the following schemes.Local tokens (Local): the tokens occurring in thelocal sentences in a given webpage;Full tokens (Full): the tokens occurring in a givenwebpage;URL tokens (URL): the tokens occurring in theURL of a given webpage.
URL tokenizationworks as follows: split a URL at ?:?
and ?.
?, andthen filter out stop words that are very common inURLs, such as ?com,?
?http,?
and so on;Title tokens in root page (TTRP): the title tokensoccurring in the root page of a given webpage.Here, we define the root page of a given webpageas the page whose URL is the first slash-demarcated element (non-http) of the URL of thegiven webpage.
For example, the root page of?http://www.leeds.ac.uk/calendar/court.htm?
is?www.leeds.ac.uk?.
We do not use all tokens inthe root page because there may be a lot of noisyinformation.Although Local tokens and Full tokens oftenprovide enough information for name disambigua-tion, there are some ambiguity cases that can besolved only with the help of information beyondthe given web page, such as URL tokens andTTRP tokens.
For example, in the web page?Alexander Markham 009,?
there is not sufficientinformation to identify the ?Alexander Markham.
?But from its URL tokens (?leeds ac uk calendarcourt?)
and the title tokens in its root page (?Uni-versity of Leeds?
), it is easy to infer that this?Alexander Markham?
is from the University ofLeeds, which can totally solve the name ambigu-ity.Because of the noisy information in URL to-kens and TTRP tokens, here we combine themwith Local tokens, using the following policy: for126each URL token and TTRP token, if the token isalso one of the Local tokens of other web pages,add this token into the Local token list of the cur-rent webpage.
We do the same thing with Fulltokens.Except URL tokens, the other three kinds oftokens?Local tokens, Full tokens and TTRP to-kens?are outputted from the Penn Treebank to-kenization, filtered by a stop-word dictionary, andrepresented in their morphological root form.
Buttokens in web pages have special characteristicsand need more post-processing.
In particular, atoken may be an email address or a URL that maycontain some useful information.
For example,?charlotte@la-par.org?
indicates the ?CharlotteBergeron?
who works for PAR (the Public AffairsResearch Council) in LA (Los Angeles).
To cap-ture the fine-grained information in an email ad-dress or a URL, we do deep tokenization on thesetwo kinds of tokens.
For a URL, we do deep to-kenization as URL tokenization; for an email ad-dress, we split the email address at ?@?
and ?.
?,then filter out the stop words as in URL tokeniza-tion.So far, we have developed two token-based fea-ture vectors: a Local token feature vector and aFull token feature vector.
Both of them may con-tain URL and TTRP tokens.
Given feature vectors,we need to find a way to learn the similarity ma-trix.
Here, we choose the standard TF-IDF methodto calculate the similarity matrix.2.2.2 Phrase-based featuresSince considerable information related to the am-biguous object resides in the noun phrases in aweb page, such as the person?s job and the per-son?s location, we attempt to capture this nounphrase information.
The following section brieflydescribes how to extract and use the noun phraseinformation.
For more detail, see Chen & Martin(2007).Contextual base noun phrase feature: Withthe syntactic phrase chunker, we extract all basenoun phrases (non-overlapping syntactic phrases)occurring in the local sentences, which usuallyinclude some useful information about the am-biguous object.
A base noun phrase of interestserves as an element in the feature vector.Document named-entity feature: Given theEXERT system, a direct and simple way to usethe semantic information is to extract all namedentities in a web page.
Since a given entity can berepresented by many mentions in a document, wechoose a single representative mention to repre-sent each entity.
The representative mention isselected according to the following ordered pref-erence list: longest NAME mention, longestNOMINAL mention.
A representative mentionphrase serves as an element in a feature vector.Given a pair of feature vectors consisting ofphrase-based features, we need to choose a simi-larity scheme to calculate the similarity matrix.Because of the word-space delimiter in English,the feature vector comprises phrases, so that asimilarity scheme for phrase-based feature vectorsis required.
Chen & Martin (2007) introduced oneof those similarity schemes, ?two-levelSoftTFIDF?.
First, a token-based similarityscheme, the standard SoftTFIDF (Cohen et al,2003), is used to calculate the similarity betweenphrases in the pair of feature vectors; in the sec-ond phase, the standard SoftTFIDF is reformu-lated to calculate the similarity for the pair ofphrased-based feature vectors.First, we introduce the standard SoftTFIDF.
Ina pair of feature vectors S and T, S = (s1, ?
, sn )and T = (t1, ?
, tm).
Here, si (i = 1?n) and tj (j =1?m) are substrings (tokens).
Let CLOSE(?
; S;T)be the set of substrings w ?
S such that there issome v?
T satisfying dist(w; v) > ?.
The Jaro-Winkler distance function (Winkler, 1999) isdist(;).
For w?
CLOSE(?
; S;T), let D(w; T) =);(max vwdistTv?
.
Then the standard SoftTFIDFis computed as)D( )V( )V()( SoftTFIDF);;(w, Tw, Tw, SS,TTSCLOSEw??=?
?
?
)(IDF log  1)  (TF log  )(V' ww,Sw, S ?+=?
?= S w, Sw, Sw, Sw2)( V)(  V  )( V                  ,where TFw,S is the frequency of substrings w in S,and IDFw is the inverse of the fraction of docu-ments in the corpus that contain w. To computethe similarity for the phrase-based feature vectors,in the second step of ?two-level SoftTFIDF,?
thesubstring w is a phrase and dist is the standardSoftTFIDF.So far, we have developed several feature mod-els and learned the corresponding similarity ma-127trices, but clustering usually needs only oneunique similarity matrix.
In the results reportedhere, we simply combine the similarity matrices,assigning equal weight to each one.2.3 ClusteringAlthough clustering is a well-studied area, a re-maining research problem is to determine the op-timal parameter settings during clustering, such asthe number of clusters or the stop-threshold, aproblem that is important for real tasks and that isnot at all trivial.
Because currently we focus onlyon feature development, we choose agglomerativeclustering with a single linkage, and simply use afixed stop-threshold acquired from the trainingdata.3 PerformanceOur system performs very well for the SemevalWeb People corpus, and Table 1 shows theperformances.
There are two results in Table 1:One is gotten from the evaluation of SemevalWeb People Track (SemEval), and the other isevaluated with B-cubed evaluation (Bagga andBaldwin, 1998).
Both scores indicate that webpersonal name disambiguation needs more effort.Purity InversePurityF(?=0.5)F(?=0.2)SemEval 0.72 0.88 0.78 0.83Precision Recall F(?=0.5)F(?=0.2)B-cubed 0.61 0.83  0.70 0.77Table 1  The performances of the test data4 ConclusionOur experiments in web personal name disam-biguation extend token-based information to aweb corpus, and also include some noun phrase-based information.
From our experiment, we firstfind that it is not easy to extract a clean textdocument from a webpage because of much noisyinformation in it.
Second, some common toolsneed to be adapted to a web corpus, such as sen-tence segmentation and tokenization.
Many NLPtools are developed for a news corpus, whereas aweb corpus is noisier and often needs some spe-cific processing.
Third, in this paper, we use someURL information and noun phrase information ina rather simple way; more exploration is needed inthe future.
Besides the rich feature extraction, wealso need more work on similarity combinationand clustering.AcknowledgementsSpecial thanks are extended to Praful Mangalathand Kirill Kireyev.ReferencesJ.
Artiles, J. Gonzalo.
and S. Sekine.
2007.
The SemE-val-2007 WePS Evaluation: Establishing a bench-mark for the Web People Search Task.
In Proceed-ings of Semeval 2007, Association for Computa-tional Linguistics.A.
Bagga and B. Baldwin.
1998.
Entity?based Cross?document Co?referencing Using the Vector SpaceModel.
In 17th COLING.Y.
Chen and K. Hacioglu.
2006.
Exploration ofCoreference Resolution: The ACE Entity Detectionand Recognition Task.
In 9th International Confer-ence on TEXT, SPEECH and DIALOGUE.Y.
Chen and J. Martin.
2007.
Towards Robust Unsu-pervised Personal Name Disambiguation.
EMNLP.W.
Cohen, P. Ravikumar, S. Fienberg.
2003.
A Com-parison of String Metrics for Name-Matching Tasks.In IJCAI-03 II-Web Workshop.C.
H. Gooi and J. Allan.
2004.
Cross-DocumentCoreference on a Large Scale Corpus.
NAACLK.
Hacioglu, B. Douglas and Y. Chen.
2005.
Detectionof Entity Mentions Occurring in English and Chi-nese Text.
Computational Linguistics.K.
Hacioglu.
2004.
A Lightweight Semantic ChunkingModel Based On Tagging.
In HLT/NAACL.B.
Malin.
2005.
Unsupervised Name Disambiguationvia Social Network Similarity.
SIAM.G.
Mann and D. Yarowsky.
2003.
Unsupervised Per-sonal Name Disambiguation.
In Proc.
of CoNLL-2003, Edmonton, Canada.T.
Pedersen, A. Purandare and A. Kulkarni.
2005.Name Discrimination by Clustering Similar Con-texts.
In Proc.
of the Sixth International Conferenceon Intelligent Text Processing and ComputationalLinguistics, pages 226-237.
Mexico City, Mexico.W.
E. Winkler.
1999.
The state of record linkage andcurrent research  problems.
Statistics of Income Di-vision, Internal Revenue Service Publication R99/04.128
