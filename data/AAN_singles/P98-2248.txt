Target Word Selection as Proximity in Semantic SpaceScot t  McDona ldCentre for Cognitive Science, University of Edinburgh2 Buccleuch Place, Edinburgh EH8 9LW, Scotlandscottm~cogsci, ed.
ac.
ukAbstractLexical selection is a significant problem for wide-coverage machine translation: depending on thecontext, agiven source language word can often betranslated into different target language words.
Inthis paper I propose a method for target wordselection that assumes the appropriate ranslation ismore similar to the translated context than are thealternatives.
Similarity of a word to a context isestimated using a proximity measure in corpus-derived "semantic space".
The method is evaluatedusing an English-Spanish parallel corpus ofcolloquial dialogue.1 IntroductionWhen should Spanish detener translate toEnglish arrest and when to stop?
This paper ex-plores the problem of lexical selection inmachine translation (MT): a given sourcelanguage (SL) word can often be translated intodifferent arget language (TL) words, dependingon the context.Translation is difficult because the conceptualmapping between languages is generally notone-to-one; e.g.
Spanish reloj maps to bothwatch and clock.
A SL word might be trans-latable by more than one TL option, where thechoice is based on stylistic or pragmatic ratherthan semantic riteria.
Alternative TL choicesalso exist for SL words that are ambiguous fromthe monolingual point of view; e.g.
English firmcan be translated by Spanish f irme, estricto,s61ido or compa~ia.1.1 Semantic Space ModelsIn this paper I take a statistical approach to lex-ical selection, under the working assumption thatthe translated linguistic context can provide suf-ficient information for choosing the appropriatetarget.
I define the appropriate target as thecandidate "closest" in meaning to the local TLcontext, where local context refers to a windowof words centered on the "missing" TL item.To estimate the similarity in meaning betweena word and the bag of words forming a context,the semantic properties of words are first repres-ented as their patterns of co-occurrence in alarge corpus.
Viewing a word as a vector in highdimensional "semantic space" allows distribu-tional similarity (or "semantic distance") to bemeasured using a standard vector similaritymetric.
The assumption that distributional simi-larity corresponds to the psychological conceptof semantic relatedness has proved useful in NLP(e.g.
Schtitze, 1992), and for psycholinguisticmodelling (e.g.
Landauer & Dumais, 1997).One way to estimate the semantic distancebetween a local discourse context and a targetword is to measure the proximity between thecentroid vector created from the words in thecontext and the target word vector.
Thisapproach was used successfully by Schiitze(1992) in a small-scale word sense disambi-guation experiment.
However, in this approachthe distributional properties of the words makingup the local context are not taken into account.The centroid method establishes one position(the mean) on each dimension to use in the dist-ance estimate, without considering the variabilityof the values on all dimensions.
If there is a largeamount of noise in the context (semanticallyirrelevant words), the centroid is influencedequally by these words as by words that are rele-vant to the correct arget.
Weighting the dimen-sions of the space according to variability allowsa semantic distance measure to be influenced lessby irrelevant dimensions (Kozimo & Ito, 1995).It is clear that this method relies on thehypothesis that the region of semantic spacedefined by the translated context "overlaps" toa greater degree with the preferred target thanwith the alternative choices.
The main purpose ofthe present investigation was to determine theextent hat this hypothesis was supported.1.2 Related WorkDagan and Itai (1994) have also addressed thelexical selection problem from the TL point ofview.
Their algorithm uses information aboutlocal co-occurrence probabilities for all possibleTL pairs of words that can result fromtranslating each pair of words (verb/noun plusargument/modifier) in the SL sentence, and only1496makes a decision if the preference is statisticallysignificant.
In work aimed at lexical choice ingeneration, Edmonds (1997) uses informationabout significant local co-occurrences to choosewhich of a set of synonyms i  most typical in agiven context.
The present paper differs fromthese approaches in that local co-occurrencebehaviour is not considered relevant, but ratheran estimate of semantic relatedness between theTL context and each candidate translation.2 ExperimentTo assess the proposed semantic distance (SD)method for target word selection, I used anEnglish-Spanish parallel corpus I for testing andevaluation.
Several features of  a real MT systemwere incorporated in order that the experimentmimic the type of information available to thelexical selection component.
Investigation wasrestricted to the translation of content words:common ouns, verbs, adjectives and adverbs.2.1 Materials and ProcedureThe test corpus was an English language moviescript that had been translated into Spanish on aline-by-line basis.
A random sample of 170 lineswas extracted from the Spanish half of thecorpus, and each content :word in this SLsubcorpus was looked up in the online version ofLangenscheidt's New College English-SpanishBilingual Dictionary.
2 Experimental items werechosen and a bilingual lexicon (see Figure 1)formed from the information in the dictionary,subject o the following constraints:?
The SL word had two or more potentialtranslations.?
A potential translation was defined as a listedtranslation matching the SL word in POS class(and for verbs, in valency).
This simulates theinformation available from parsing or tagging.?
Only word-to-word translations wereconsidered.
Multi-word units in the SL text orlisted as a translation were excluded.?
Very low frequency SL words and listedtranslations (a lexeme frequency of less than1/million in the 10M word spoken part of theBritish National Corpus \[BNC\]) were excluded.tThe English half of the corpus consisted of the closed-caption text incorporated with the video release ofFearless (Warner Bros/Spring Creek Productions, 1993).The parallel corpus was provided by TCCCommunications Corporation, Victoria, BC, Canada.2http : //www.
gmsmuc, de/english/look, htmldetener ~ stop arrest detain delay holdmejorar ~ improve increaseprecio ~ price cost value worthFigure 1.
Example bilingual lexical entries.The translations given in the parallel corpus for13 SL items were not listed in Langenscheidt's.This was due to the directionality of bilingualdictionaries - entries are created from the TLpoint of view - and the fact that the direction oforiginal translation was opposite to that used forbuilding the testing lexicon.
These translationswere incorporated into the bilingual lexicon.
Atotal of 99 experimental items were compiled.For each SL item, the corresponding TLtranslation was located in the parallel corpus andall TL content words within a +25 word windowwere extracted to form the local discoursecontext.
Co-occurrence vectors for eachlemmatised context word meeting the frequencythreshold were created from a lemmatisedversion of the spoken part of the BNC.
Vectorswere constructed by advancing a window of +3words through the corpus, and for each wordrecording the number of times each of 446index words occurred within the window.
Thisprocedure produced a 446-dimension semanticspace.
Finally, co-occurrence counts werereplaced with their log-likelihood values, whicheffectively normalizes the vectors.
Parametersettings were taken from McDonald (1997).Vectors for the translation candidates werecreated using exactly the same method.Compared to a practical MT system, the lexicalselection simulation makes several simplifyingassumptions.
For one, two or more items in thesame SL sentence are treated as if all other itemsare already correctly translated.
Secondly, theuse of forward context means that a word is leftuntranslated until a prespecified number offollowing words are translated.
Finally, thebilingual exicon listed 4.2 translation candidatesper entry on average.
Many of the alternativescould be described as stylistic variants, and mightnot be present in an actual MT lexicon.2.2 Calculating Semantic DistanceThe proximity of each translation candidate tothe bag of words forming the local TL contextwas measured as described below, and the"closest" target was chosen.
The method forscaling each dimension of the space was adaptedfrom Kozimo and Ito (1995) in order to de-emphasize dimensions irrelevant o the local1497context.
If the variability of vector component iis high, then this dimension is considered to beless relevant than a component with lowervariability, and the semantic distance measureshould take this into account.The relevance r i for each dimension is definedas the ratio of the standard eviation si of thedistribution formed by dimension i, for all localcontext words LC, over the maximum standarddeviation Smax for LC:sir i=SmaxFor each candidate translation t the vectorrepresenting each word c in LC is moved to anew position in the space according to a functionof r and its current distance from t:c '=c i+r i ( t i - c i )If r is large, then any difference in the value ofcomponent i between t and LC is made lessprominent than if r is small.
Finally, semanticdistance is calculated as the mean cosine of theangle between target and each word c in LC:1 ~cos( t , c ' )  SD(t, LC) = iL~c,~Lc2.3 Results and DiscussionPerformance was evaluated against the actualEnglish translation aligned with each Spanishitem.
Two baseline measures were used forcomparison: accuracy expected by randomselection, and word frequency (WF; selection ofthe translation candidate with the highest corpusfrequency).
The semantic distance method made57/99 correct choices (57.6%) whereas thefrequency method bettered it slightly, choosingthe aligned translation 59 times (59.6%).Expected chance performance was 22.9%.
Ofthe errors made by WF, SD corrected 15%, andWF corrected 19% of the SD method's errors.In about one-quarter of the errors made by theSD method, the selected candidate and the"correct" translation seemed equally acceptablein the context.
This can be seen more clearly inan example TL context for trabajo (Figure 2).There appears to be little information availablein the context in order to prefer work over theclosely related job.Performance was assessed at the level of 100%applicability - the SD method was used for everyitem.
Future work will investigate the use of aconfidence estimate: if the evidence forSL:TL:Ud.
es muy ded icado  a su trahaJo.... to go back to the office.what's your name?i 'm john wilkenson.why were you on the plane?on business.you' re  very  commit ted to your  <X).you go ahead and f inish your  story,please.we were taking a vacat ion--my sister, me, and our kids.you know--no husbands.we saw ...Figure 2.
Example discourse context for alignmenttrabajo~work.
X indicates the target word position.preferring one candidate over another is weak,an alternative selection method should be used.3 ConclusionA preliminary investigation of a method forlexical selection in MT was presented.
Theassumption that the preferred translation of atranslationally ambiguous SL word is the oneclosest in semantic distance to its translatedcontext gave encouraging results, taking intoaccount he impoverished nature of the infor-mation available in spoken language context.AcknowledgementsThis work was supported by awards fromNSERC Canada nd the ORS scheme, and in partby ESRC grant #R000237419.
Thanks to ChrisBrew and Mirella Lapata for valuable comments.ReferencesDagan, I.
& A. Itai.
1994.
Word sense disambiguationusing a second language monolingual corpus.Computational Linguistics, 20:563-596.Edmonds, P. 1997.
Choosing the word most typical incontext using a lexical co-occurrence n twork.
InProceedings of the 35th ACU8th EACL, Madrid.Kozima, H. & A. Ito.
1995.
Context-sensitivemeasurement of word distance by adaptive scaling of asemantic space.
In Proceedings of RANLP-95, pages161-168, Tzigov Chark, Bulgaria.Landauer, T. K. & S. T. Dumais.
1997.
A solution toPlato's problem: the Latent Semantic Analysis theoryof acquisition, induction, and representation fknowledge.
Psychological Review, 104:211-240.McDonald, S. 1997.
Exploring the validity of corpus-derived measures of semantic similarity.
Paperpresented atthe 9th Annual CCS/I-ICRC PostgraduateConference, University of Edinburgh.Schtitze, H. 1992.
Dimensions of meaning.
InProceedings of Supercomputing '92, pages 787-796,New York: Association for Computing Machinery.1498
