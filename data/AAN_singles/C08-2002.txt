Coling 2008: Companion volume ?
Posters and Demonstrations, pages 7?10Manchester, August 2008Distilling Opinion in Discourse: A Preliminary StudyNicholas Asher and Farah BenamaraIRIT-CNRS Toulouse,France{asher, benamara}@irit.frYvette Yannick MathieuLLF-CNRS Paris,Franceyannick.mathieu@linguist.jussieu.frAbstractIn this paper, we describe a preliminarystudy for a discourse based opinion cate-gorization and propose a new annotationschema for a deep contextual opinion anal-ysis using discourse relations.1 IntroductionComputational approaches to sentiment analysiseschew a general theory of emotions and focuson extracting the affective content of a text fromthe detection of expressions of sentiment.
Theseexpressions are assigned scalar values, represent-ing a positive, a negative or neutral sentiment to-wards some topic.
Using information retrieval, textmining and computational linguistic techniques to-gether with a set of dedicated linguistic resources,one can calculate opinions exploiting the detected?bag of sentiment words?.
Recently, new meth-ods aim to assign fine-grained affect labels basedon various psychological theories?e.g., the MPQAproject (Wiebe et al, 2005) based on literary the-ory and linguistics and work by (Read et al, 2007)based on the Appraisal framework (Martin andWhite, 2005).We think there is still room for improvement inthis field.
To get an accurate appraisal of opin-ion in texts, NLP systems have to go beyond pos-itive/negative classification and to identify a widerange of opinion expressions, as well as how theyare discursively related in the text.
In this paper,we describe a preliminary study for a discoursebased opinion categorization.
We propose a newannotation schema for a fine-grained contextualc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.opinion analysis using discourse relations.
Thisanalysis is based on a lexical semantic analysis ofa wide class of expressions coupled together withan analysis of how clauses involving these expres-sions are related to each other within a discourse.The aim of this paper is to establish the feasibil-ity and stability of our annotation scheme at thesubsentential level and propose a way to use thisscheme to calculate the overall opinion expressedin a text on a given topic.2 A lexical semantic analysis of opinionexpressionsWe categorize opinion expressions using a typol-ogy of four top-level categories (see table 1): RE-PORTING expressions, which provide an evalu-ation of the degree of commitment of both theholder and the subject of the reporting verb, JUDG-MENT expressions, which express normative eval-uations of objects and actions, ADVISE expres-sions, which express an opinion on a course of ac-tion for the reader, and SENTIMENT expressions,which express feelings (for a more detailed de-scription of our categories see (Asher et al 2008)).Our approach to categorize opinions uses thelexical semantic research of (Wierzbicka, 1987),(Levin, 1993) and (Mathieu, 2004).
From theseclassifications, we selected opinion verb classesand verbs which take opinion expressions withintheir scope and which reflect the holder?s com-mitment on the opinion expressed.
We removedsome verb classes, modified others and merged re-lated classes into new ones.
Subjective verbs weresplit into these new categories which were then ex-tended by adding nouns and adjectives.Our classification is the same for French and En-glish.
It differs from psychologically based classi-fications like Martin?s Appraisal system : in ours7Groups SubGroups ExamplesReportinga) Inform inform, notify, explainb) Assert assert, claim, insistc) Tell say, announce, reportd) Remark comment, observe, remarke) Think think, reckon, considerf) Guess presume, suspect, wonderJudgmentg) Blame blame, criticize, condemnh) Praise praise, agree, approvei) Appreciation good, shameful, brilliantAdvisej) Recommend advise, argue fork) Suggest suggest, proposel) Hope wish, hopeSentimentm) Anger/CalmDown irritation, angern) Astonishment astound, daze, impresso) Love, fascinate fascinate, captivatep) Hate, disappoint demoralize, disgustq) Fear fear, frighten, alarmr) Offense hurt, chocks) Sadness/Joy happy, sadt) Bore/entertain bore, distractionu) Touch disarm, move, touchTable 1: Top-Level opinion categories.the contents of the JUDGMENT and SENTIMENTcategories are quite different, and more detailedfor SENTIMENT descriptions with 14 sub-classes.Ours is also broader: the REPORTING and the AD-VISE categories do not appear as such in the Ap-praisal system.
In addition, we choose not to buildour discourse based opinion categorization on thetop of MPQA (Wiebe et al 2005) for two reasons.First, we suggest a more detailed analysis of pri-vate states by defining additional sets of opinionclasses such as HOPES and RECOMMENDATIONS.We think that refined categories are needed to builda more nuanced appraisal of opinion expressionsin discourse.
Second, text anchors which corre-spond to opinion in MPQA are not well definedsince each annotator is free to identify expressionboundaries.
This is problematic if we want to in-tegrate rhetorical structure into opinion identifica-tion task.
MPQA often groups discourse indica-tors (but, because, etc.)
with opinion expressionsleading to no guarantee that the text anchors willcorrespond to a well formed discourse unit.3 Towards a Discursive Representation ofOpinion ExpressionsRhetorical structure is an important element in un-derstanding opinions conveyed by a text.
The fol-lowing simple examples drawn from our Frenchcorpus show that discourse relations affect thestrength of a given sentiment.
S1 : [I agree withyou]aeven if I was shocked and S2 : Buy the DVD,[you will not regret it]b.
Opinions in S1 and S2are positive but the contrast introduced by even inS1decreases the strength of the opinion expressedin (a) whereas the explanation provided by (b) inS2 increases the strength of the recommendation.Using the discourse theory SDRT (Asher and Las-carides, 2003) as our formal framework, our fouropinion categories are used to label opinion ex-pressions within a discourse segment.
For exam-ple, there are three opinion segments in the sen-tence S3: [[It?s poignant]d, [sad]e]gand at thesame time [horrible]fWe use five types of rhetorical relations: CON-TRAST, CORRECTION, SUPPORT, RESULT andCONTINUATION (For a more detailed descriptionsee (Asher et al 2008)).
Within a discourse seg-ment, negations were treated as reversing the po-larities of the opinion expressions within theirscope.
Conditionals are hard to interpret becausethey affect the opinion expressed within the conse-quent of a conditional in different ways.
For exam-ple, conditionals,expressions of ADVISE can blockthe advice or reverse it.
Thus if you want to wasteyou money, buy this movie will be annotated as arecommendation not to buy it.
On the other hand,conditionals can also strengthen the recommenda-tion as in if you want to have good time, go andsee this movie.
We have left the treatment of con-ditionals as well as disjunctions for future work.3.1 Shallow Semantic RepresentationIn order to represent and evaluate the overallopinion of a document, we characterize discoursesegments using a shallow semantic representa-tion using a feature structure (FS) as describedin (Asher et al 2008).
Figure 1 shows the dis-cursive representation of the review movie S4:[This film is amazing.]a.
[[One leaves not com-pletely convinced]b.1, but [one is overcome]b.2].
[[It?s poignant]c.1, [sad]c.2] and at the same time[horrible]c.3].
[Buy it]d. [You won?t regret it]e.Figure 1: Discursive representation of S4.Once we have constructed the discursive repre-sentation of a text, we have to combine the dif-ferent FS in order to get a general representation8that goes beyond standard positive/negative repre-sentation of opinion texts.
In this section, we firstexplain the combination process of FS.
We thenshow how an opinion text can be summarized us-ing a graphical representation.The combination of low-level FS is performedin two steps: (1) combine the structures relatedby coordinating relations (such as CONTRAST andCONTINUATION).
In figure 1, this allows to buildfrom the segments b.1 and b.2 a new FS ; (2) com-bine the strutures related via subordinating rela-tions (such as SUPPORT and RESULT) in a bottomup way.
In figure 1, the FS of the segment a is com-bined with the structure deduced from step 1.
Dur-ing this process, a set of dedicated rules is used.The procedure is formalized as follows.
Let a, b betwo segments related by the rhetorical relation Rsuch as: R(a, b).
Let Sa, Sbbe the FS associatedrespectively to a and b i.e Sa: [category : [groupa:subgroupa],modality : [polarity : pa, strength : sa] ?
?
?
]and Sb: [category : [groupb: subgroupb], modality :[polarity : pb, strength : sb] ?
?
?]
and let S : [category :[group],modality : [polarity : p, strength : s] ?
?
?]
bethe FS deduced from the combination of SaandSb.
Some of our rules are:CONTINUATIONS strengthen the polarity of thecommon opinion.
One of the rule used is: if(groupa= groupb) and (subgroupa6= subgroupb)) thenif ((pa= neutral) and (pb6= neutral)) then group =groupaand p = pband s = max(sa, sb), as in movingand sad news.For CONTRAST, let OWibe the set of opinionwords that belongs to a segment Si.
We have forOWa= ?
and OWb6= ?
: group = groupb, p = pbands = sb+ 1, as in I don?t know a lot on Edith Piaf?slife but I was enthraled by this movie.Finally, an opinion text is represented by a graphG = (?,?)
such as:?
?
= H ?
T is the set of nodes where :H = {hoi/hoiis an opinion holder} and T ={toi: value/toiis a topic and value is a FS}, such as :value = [Polarity : p, Strength : s,Advice : a], where:p = {positive, negative, neutral} and s, a = {0, 1, 2}.?
?
= ?H?
?T?
?H?Twhere: ?H={(hi, hj)/hi, hj?
H} means that two top-ics are related via an ELABORATION relation.This holds generally between a topic and asubtopic, such as a movie and a scenario ; ?T={(ti, tj, type)/ti, tj?
T and type = support/contrast}means that two holders are related via a CON-TRAST (holders hiand hjhave a contrasted opin-ion on the same topic) or a SUPPORT relation(holders share the same point of view) ; and?H?T= {(hi, tj, type)/hi?
H and tj?
T and type =attribution/commitment} means that an opinion to-wards a topic tjis attributed or committed to aholder hi.
For example, in John said that the filmwas horrible, the opinion is only attributed to Johnbecause verbs from the TELL group do not con-vey anything about the author view.
However, inJohn infomed the commitee that the situation washorrible, the writer takes the information to be es-tablished.
The figure 2 below shows the generalrepresentation of the movie review S4.Figure 2: General representation of S4.4 Annotating Opinion Segments:Experiments and Preliminary ResultsWe have analyzed the distribution of our categoriesin three different types of digital corpora, eachwith a distinctive style and audience : movie re-views, Letters to the Editor and news reports inEnglish and in French.
We randomly selected 150articles for French corpora (around 50 articles foreach genre).
Two native French speakers anno-tated respectively around 546 and 589 segments.To check the cross linguistic feasability of gener-alisations made about the French data, we also an-notated opinion categories for English.
We haveannotated around 30 articles from movie reviewsand letters.
For news reports, the annotation in En-glish was considerably helped by using texts fromthe MUC 6 corpus (186 articles), which were an-notated independently with discourse structure bythree annotators in the University of Texas?s DIS-COR project (NSF grant, IIS-0535154); the anno-tation for our opinion expressions involved a col-lapsing of structures proposed in DISCOR.The annotation methodology is described in(Asher et al 2008).
For each corpus, annotatorsfirst begin to annotate elementary discourse seg-ments, define its shallow representation and finally,connect the identified segments using the set ofrhetorical relations we have identified.
A segmentis annotated only if it explicitly contains an opin-ion word that belong to our lexicon or if it bears arhetorical relation to an opinion segment.9The average distribution of opinion expressionsin our corpus across our categories for each lan-guage is shown in table 2.
The annotation of moviereviews was very easy.
The opinion expressionsare mainly adjectives and nouns.
We found an av-erage of 5 segments per review.
Opinion words inLetters to the Editor are adjectives and nouns butalso verbs.
We found an average of 4 segments perletter.
Finally, opinions in news documents involveprincipally reported speech.
As we only annotatedsegments that clearly expressed opinions or wererelated via one of our rhetorical relations to a seg-ment expressing an opinion, our annotations typ-ically only covered a fraction of the whole docu-ment.
This corpus was the hardest to annotate andgenerally contained lots of embedded structure in-troduced by REPORTING type verbs.To compute the inter-annotator agreements(IAA) we did not take into account the opinionholder and the topic as well as the polarity and thestrength because we chose to focus, at a first step,only on agreements on opinion categorization, seg-ment idendification and rhetorical structure detec-tion.
We computed the agreements only on theFrench corpus.
The French annotators performeda two step annotation where an intermediate anal-ysis of agreement and disagreement between thetwo annotators was carried out.
This analysis al-lowed each annotator to understand the reason ofsome annotation choices.
Using the Kappa mea-sure, the IAA on opinion categorization is 95% formovie reviews, 86% for Letters to the Editors and73% for news documents.Annotators had good agreement concerningwhat the basic segments were (82%), which showsthat the discourse approach in sentiment analysisis easier compared to the lexical task where an-notators have low agreements on the identificationof opinion tokens.
The principal sources of dis-agreement in the annotation process came fromannotators putting opinion expressions in differentcategories (mainly between PRAISE/BLAME groupand APPRECIATION group, such as shame) and thechoice of rhetorical relations.
Nevertheless, by us-ing explicit discourse connectors, we were ableto get relatively high agreement on the choice ofrhetorical relations.
We also remained quite un-sure how to distinguish between the reporting ofneutral opinions and the reporting of facts.
Themain extension of this work are to (1) deepen ouropinion typology, specifically to include modalsGroups Movie (%) Letters (%) News (%)French English French English French EnglishReporting 2.67 2.12 14.80 13.34 43.91 42.85a 0 0 0.71 1.33 4.02 4.76b 0.53 0 0 4 5.83 0c 0 0 1.79 0 4.51 35.71d 0.88 0 2.17 0 11.82 0e 1.33 0 10.12 6.67 5.89 1.34f 0 2.12 0 1.34 11.77 0Judgment 60.53 40.52 52.50 73.34 39.23 33.34g 0.54 0 6.32 26.66 13.69 16.67h 2.45 2.12 7.54 20 1.81 4.76i 54.49 38.29 33.48 26.87 23.72 11.90Advise 6.92 10.63 10.05 13.34 7.27 9.52j 6.26 8.51 0.70 5.33 1.37 0k 0.66 2.12 3.94 1.33 3.61 0l 0 0 5.38 6.67 2.28 9.52Sentiment 27.30 34.04 33.08 2.67 11.35 16.67m 0.54 0 3.23 0 0,90 0n 2.23 6.38 3.96 2.66 0,90 7.14o 7.38 4.25 3.74 0 1,87 9.52p 4.97 2.12 5.03 0 2,72 0q 2.23 0 5.03 0 1,86 0r 0.89 0 7.17 0 2,28 0s 3.79 4.25 2.87 0 0.88 0t 1.33 14.9 0 0 0 0u 4.46 2.12 2.15 2.12 0 0Table 2: Average distribution of our categories.and moods like the subjunctive, and to (2) providea deep semantic representation that associates foreach category of opinion a lambda term involvingthe proferred content and a lambda term for thepresuppositional content of the expression, if it hasone.
In terms of automatization, we plan to exploita syntactic parser to get the argument structure ofverbs and then a discourse segmenter like that de-veloped in the DISCOR project, followed by thedetection of discourse relations using cue words.ReferencesAsher N. and Benamara F. and Mathieu Y.Y.
2008.
Catego-rizing Opinions in Discourse.
ECAI08.Asher N. and Lascarides A.
2003.
Logics of Conversation.Cambridge University Press.Levin B.
1993.
English Verb Classes and Alterna-tions: APreliminary Investigation.
University of Chicago PressMartin J.R and White P.R.R.
2005.
Language of Evaluation:Appraisal in English.
Palgrave Macmillan.Mathieu Y. Y.
2004.
A Computational Semantic Lexiconof French Verbs of Emotion.
In Shanahan, G., Qu, Y.,Wiebe, J.
(eds.
): Computing Attitude and Affect in Text.Dordrecht.Read J., Hope D. and Carroll J.
2007.
Annotating Expres-sions of Appraisal in English.
The Linguistic AnnotationWorkshop, ACL 2007.Wiebe J., Wilson T. and Cardie C. 2005.
Annotating Expres-sions of Opinions and Emotions in Language.
LanguageResources and Evaluation 1(2).Wierzbicka A.
1987.
Speech Act Verbs.
Sydney: AcademicPress.10
