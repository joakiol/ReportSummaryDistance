Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97?103,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsSmoothing a Lexicon-based POS Tagger for Arabic and HebrewSaib Mansour Khalil Sima'an Yoad WinterComputer Science, Technion ILLC Computer Science, TechnionHaifa, 32000, Israel  Universiteit van Amsterdam Haifa, 32000, IsraelAmsterdam, The Netherlands and Netherlands Institute for Ad-vanced StudyWassenaar, The Netherlandssaib@cs.technion.ac.il simaan@science.uva.nl winter@cs.technion.ac.ilAbstractWe propose an enhanced Part-of-Speech(POS) tagger of Semitic languages thattreats Modern Standard Arabic (hence-forth Arabic) and Modern Hebrew(henceforth Hebrew) using the sameprobabilistic model and architectural set-ting.
We start out by porting an existingHidden Markov Model POS tagger forHebrew to Arabic by exchanging a mor-phological analyzer for Hebrew withBuckwalter's (2002) morphological ana-lyzer for Arabic.
This gives state-of-the-art accuracy (96.12%), comparable to Ha-bash and Rambow?s (2005) analyzer-based POS tagger on the same Arabicdatasets.
However, further improvementof such analyzer-based tagging methods ishindered by the incomplete coverage ofstandard morphological analyzer (BarHaim et al, 2005).
To overcome this cov-erage problem we supplement the outputof Buckwalter's analyzer with syntheti-cally constructed analyses that are pro-posed by a model which uses characterinformation (Diab et al, 2004) in a waythat is similar to Nakagawa's (2004) sys-tem for Chinese and Japanese.
A versionof this extended model that (unlike Naka-gawa) incorporates synthetically con-structed analyses also for known wordsachieves 96.28% accuracy on the standardArabic test set.1 IntroductionPart-of-Speech tagging for Semitic languages hasbeen an active topic of research in recent years.
(Diab et al, 2004; Habash and Rambow, 2005;Bar-Haim et al, 2005) are some examples for thisline of work on Modern Standard Arabic and Mod-ern Hebrew.
POS tagging systems aim at classify-ing input sequences of lexemes by assigning eachsuch sequence a corresponding sequence of mostprobable POS tags.
It is often assumed that foreach input lexeme there is a set of a priori possiblePOS tag categories, or a probability function overthem, and the tagger has to choose from this lim-ited set of candidate categories.
We henceforth usethe term lexicon to refer to the set of lexemes in alanguage and the mapping that assigns each ofthem candidate POS tags, possibly with additionalprobabilities.Two ways to obtain a lexicon can be distin-guished in recent works on POS tagging in Semiticlanguages.
Data-driven approaches like (Diab et al2004) employ the lexicon only implicitly whenextracting features on possible POS tags from an-notated corpora that are used for training the POStagger.
Lexicon-based approaches (Habash andRambow, 2005; Bar-Haim et al, 2005) use a lexi-con that is extracted from a manually constructedmorphological analyzer (Buckwalter 2002 andSegal 2001 respectively).In this paper we show that although lexicon-based taggers for Arabic and Hebrew may initiallyoutperform data-driven taggers, they do not ex-haust the advantages of data-driven approaches.97Consequently, we propose a hybrid model of data-driven methods and lexicon-based methods, andshow its advantages over both models, in a waythat is reminiscent of Nakagawa's (2004) resultsfor Chinese and Japanese.As a first step, we develop a Part-of-Speech tag-ger that treats Arabic and Hebrew using the sameprobabilistic model and architectural setting.
Westart out from MorphTagger, a lexicon-based tag-ger for Hebrew developed by Bar-Haim et al(2005), which uses standard Hidden MarkovModel techniques.
We port the existingMorphTagger implementation to Arabic by ex-changing Segal's (2001) morphological analyzerwith Buckwalter's (2002) morphological analyzer,and then training the tagger on the Arabic Tree-bank (Maamouri et al, 2001).
Remarkably, thisgives state-of-the-art accuracy (96.12%) on thesame Arabic datasets as Habash and Rambow(2005).
To the best of our knowledge, this is thefirst time the same POS tagging architecture isused both for Arabic and Hebrew texts with com-parable accuracy.Despite the initial advantages of this setting, ourempirical study shows that in both languages, fur-ther improvement in accuracy is hindered by theincompleteness of the morphological analyzer.
By"incompleteness" we refer not only to the well-studied problem of unknown words (out-of-vocabulary).
Our results show that for both Arabicand Hebrew, a more serious problem involveswords for which the analyzer provides a set ofanalyses that does not contain the correct one.
Wefind out that this is the case for 3% of the words inthe development set.
This obviously sets an upperbound on tagger accuracy using methods that arepurely based on a manually constructed lexicon.We refer to this problem as the "incomplete lexi-con" problem.We focus on devising a solution to the incom-plete lexicon problem by smoothing.
We supple-ment the output of Buckwalter's analyzer withsynthetically constructed analyses that are pro-posed by a model which uses character information(Diab et al, 2004) in a way that is similar to Naka-gawa's (2004) system for Japanese.
Unlike Naka-gawa's method, however, our smoothing methodincorporates synthetically constructed analysesalso for known words, though only when all avail-able taggings of the sentence have low probabili-ties according to our model.
A version of thisextended model achieves a modest improvement(96.28%) in accuracy over the baseline on thestandard Arabic test set.This paper is structured as follows.
In section  2we start with a brief discussion of previous work.Section  3 describes our adaptation of Bar Haim etal.
?s POS tagging system to Arabic.
In section  4we show that an architecture like Bar Haim et al?s,which relies on a morphological analyzer, is likelyto suffer from coverage problems under any con-figuration where it is used as a stand-alone.
In sec-tion  5 we present our new architecture and themethod of combining the models.
Section  6 con-cludes.2 Relation to Previous WorksQuite a few works have dealt with extending agiven POS tagger, mainly by smoothing it usingextra-information about untreated words.
For ex-ample, (Church, 1988) uses the simple heuristic ofpredicting proper nouns from capitalization.
Thismethod is not applicable to Arabic and Hebrew,which lack typographical marking of proper nouns.More advanced methods like those described byWeischedel et al (1993) incorporate the treatmentof unknown words within the probability model.Weischedel et al use derivational and inflectionalendings to infer POS tags of unknown words.
Na-kagawa (2004) addresses the problem of unknownwords for Japanese and Chinese, and uses a hybridmethod of word-level and character-level informa-tion.
In his model, Nakagawa uses character in-formation (only) when handling unknown words,claiming that in word-level methods informationabout known words helps to achieve higher accu-racy compared to character-level models.
On theother hand, when it comes to unknown words, Na-kagawa uses a character-level method, which ishypothesized to be more robust in such cases thanword-level methods.Virtually all works that dealt with coverageproblems of POS taggers have concentrated on theproblem of ?unknown?
words ?
words that have noanalysis in the initial tagging system.
However, inthe context of analyzer-based tagging systems, wealso have to deal with the problem of ?known?words that miss the correct analysis in the morpho-logical analyzer.
In the Arabic and Hebrew data-sets we have examined, this problem is moresevere than the unknown words problem.
Unlike98previous works, we propose to smooth the word-segment driven model also for ?known?
words.
Toavoid overgeneration, this is done only when alltaggings of the sentence have low probability.3 Adapting a Hebrew POS-tagger toArabicBar Haim et al's (2005) POS tagging system,MorphTagger, was developed initially for Hebrew.Our work is mainly developed for Arabic andtested over Arabic data.
Due to the similarity in themorphological processes in Hebrew and Arabicand the generality of Bar Haim et al's architecture,the adaptation process was fairly simple.
However,as far as we know this is the first implementationof a unified model for Arabic and Hebrew thatachieves state-of-the-art accuracy.
MorphTaggerrequires two components: a morphological ana-lyzer to produce a set of analyses for every lexeme,and a POS tagged corpus for acquiring an HMMdisambiguator.
The HMM disambiguator assigns aprobability to every pair xxxxx, wherenn www ...11 =  is a sentence and nn ttt ...11 =  a corre-sponding sequence of POS tags hypothesized bythe analyzer.
This probability is approximated in astandard HMM fashion:1 1 1 1 1 1 21( , ) ( ) ( | ) ( | , ) ( | )nn n n n ni i i i iiP w t P t P w t P t t t P w t?
?== =?For an input sentence nw1 , the pair  xxxxx withthe highest probability is selected.
The language( ),|( 21 ??
iii tttP ) and lexical ( )|( ii twP ) models'parameters are estimated from the tagged corpusby Maximum-Likelihood Estimator (MLE) fol-lowed by Katz backoff smoothing for the languagemodel and Add-?
smoothing for the lexical model,where a small ?=1 count is given to analyzes pro-vided by the analyzer but not found in the trainingcorpus.
Furthermore, MorphTagger employs anarray of other smoothing techniques explained inBar Haim et al (2005).Our implementation of MorphTagger for Arabicwas developed using Buckwalter?s (2002) Mor-phological Analyzer v1.0 (BMA1.0), and the Ara-bic Treebank part 1 v2.0 (ATB1), Part 2 v2.0(ATB2) and Part 3 v1.0 (ATB3).
The ATB waschosen not only because of its size and comprehen-siveness, but also because Buckwalter?s analyzerwas developed in accordance with the ATB, whichmakes the task of combining information fromboth sources easier.
In all our experiments we use atag-set of 24 tags which was mapped from theoriginal tag-set (191 tags in ATB1) using the map-ping script of the ATB distribution.To check the ambiguity level and the difficultyof the task at hand, we ran BMA1.0 over a testingset extracted from ATB1.
The average number ofanalyses per word is 1.83, and the average numberof segmentations per word is 1.2, however, the taskof disambiguating Arabic is still not easy, as 46%of the data is ambiguous.
Those results are compa-rable to the results of Bar Haim et al for Hebrew,according to which the average number of analysesper word is 2.17 with 1.25 segmentations on aver-age per word, and 54% of the words are ambigu-ous.The performance of MorphTagger over Arabicwas measured using the same test settings of Diabet al (2004).
Habash and Rambow (2005) use adifferent test setting drawn from ATB1.
Althoughwe could not reproduce the exact setting of Habashand Rambow, comparison to their reported accu-racy is still quite telling due to the similarity of thedata.
The comparison between the accuracy of thethree systems is summarized in Table 1.
The re-sults in this table were obtained using the correct(?gold?)
segmentation and applying the standard F-measure for POS tagging accuracy.
The result ofDiab et al was reproduced on their setting, and theresult of Habash and Rambow is as reported intheir paper.System Tagging accuracyMorphTagger 96.12Diab et al 95.81Habash and Rambow 97.5Table 1 - Comparison between systems over ATB1The result achieved by MorphTagger slightlyexceeds Diab et al?s result (on the same test set-ting) and is slightly inferior to Habash and Ram-bow?s reported result.
Overall, it is an encouragingresult that the MorphTagger system that was de-veloped for Hebrew could be easily ported to Ara-bic and yield state-of-the-art results.In Table 2, we present the accuracies achievedfor MorphTagger on a cross validated, 10-fold test,including the standard deviation results in paren-theses.
The results are reported both for gold-segmentation (GS) and without GS.nn tw 11 ,nn tw 11 ,99Test setting Accuracy per word (%) F?=1 per Word-segment (%)Segmentation Tagging Segmentation TaggingGS 10094.89(0.62)10095.436(0.53)without GS 99.015 (0.24)94.374(0.64)98.854 (0.28)94.727(0.56)Table 2 - MorphTagger performance cross validatedNote that by tagging accuracy per word wemean the percentage of words correctly segmentedand tagged.
The tagging F-measure is calculated inthe standard way, counting the correctly taggedword-segments and dividing it by the number of"gold" word-segments for recall, and further by thenumber of outputted word-segments for precision.Analyzing the POS tagging errors of MorphTag-ger, we found that about 2.8% of the words inATB1 were not correctly analyzed by the morpho-logical analyzer.
Such ?incomplete lexicon?
prob-lems inevitably lead to tagging errors inMorphTagger?s architecture.
This problem is moreserious still on data taken from ATB2 and ATB3,where respectively 4.5% and 5.3% of the data ledto ?incomplete lexicon?
problems.
We concludethat a morphological analyzer can be used to im-prove upon Diab et al?s results, as done in Habashand Rambow and in our straightforward applica-tion of MorphTagger to Arabic.
However, thismethod still suffers from considerable coverageproblems, which are discussed in the followingsection.4 Coverage of Morphological Analysisfor ArabicIn order to analyze the coverage problem, wetested the coverage of BMA1.0 over parts of theATB which were composed from articles taken ondifferent periods of times.
The results are summa-rized in Table 3.
The schema of the table includes,for each part of the ATB: (i) the number of tokensthat include at least one Arabic character (hence-forth ?Arabic words?1); (ii) Out-of-Vocabulary(OOV) words, unanalyzed by BMA1.0; (iii) thepercentage of proper nouns (NNP) out of the OOVwords; (iv) the number of ?no correct?
words ?1 This definition of Arabic words is taken from Buckwalter'sanalyzer.words for which BMA1.0 found at least one solu-tion but the correct analysis according to the ATBwas not among them; and (v,vi,vii) the number ofproper nouns (NNP), nouns (NN) and adjectives(JJ) from "no correct".
A problem that is unique tothe ATB is that some words in the corpus were notmanually annotated and were given the NO_FUNCtag.
Those words are counted as Arabic words, butare ignored in the rest of the statistics of Table 3.The noticeable difference in OOV words be-tween ATB1 and ATB2/ATB3 is expected, be-cause the lexicon of BMA1.0 was developed usinginformation extracted from ATB1.
ATB2 andATB3, which were developed after BMA1.0 wasreleased (using a more advanced version of Buck-walter's analyzer), show a different picture.
Inthose two parts the OOV problem is not too hard: aheuristic that would assign NNP to each OOVword would be sufficient in most of the cases.However, the ?No Correct?
problem is more diffi-cult: NNPs account for 5% in ATB2 and 18% inATB3 of these words, which are mostly dominatedby missing adjectives and missing nouns (54%jointly in ATB2 and 37% jointly in ATB3).Taken together, the OOV problem and the ?NoCorrect?
problem mean that more than 5% of thewords in ATB2 and ATB3 cannot be tagged cor-rectly using BMA1.0 unless further data are addedto those provided by the morphological analyzer.
Asimilar coverage result was reached for Hebrew byBar Haim et al, using a morphological analyzer forHebrew (Segal, 2001).
Bar Haim et al report thatfor about 4% of the Hebrew words in their corpus,the correct analysis was missing.
From these datawe conclude that on top of systems like the onesproposed by Bar Haim et al and Habash and Ram-bow,   we   need   to   enhance   the   morphologicalanalyzer using additional analyses.100ATBpartArabicwordsOOV NNP ofOOVNo Correct NNP of NoCorrectNN of NoCorrectJJ of NoCorrect1 123798 126(0.11%)21(16.67%)3369(2.82%)0 517(15.35%)980(29.09%)2 125729 958(0.77%)497(51.88%)5663(4.53%)282(4.98%)1254(22.14%)1818(32.1%)3 293026 6405(2.2%)5241(81.83%)15484(5.32%)2864(18.5%)2238(14.45%)3494(22.57%)Table 3 - Coverage of Buckwalter's Analyzer5 Smoothing Using a Data-driven Charac-ter-based ModelSo far we have shown that POS tagging modelsthat use a morphological analyzer achieve highaccuracy but suffer from coverage problems thatcan not be solved by a simple heuristic.
On theother hand, models that use character-based infor-mation are likely to make relatively good predic-tions for words that are out of the vocabulary of themorphological analyzer.
We hypothesize that thismay be especially true for Semitic languages, dueto their rich and systematic pattern (template) para-digms.
Such patterns add constant characters toroot characters, and features of substrings of wordsmay therefore help in predicting POS tags fromthose patterns.Our baseline models for the experiments areMorphTagger with a NNP heuristic (MorphTag-ger+NNP) and ArabicSVM (Diab et al's system).As we have already reported in section  3,MorphTagger+NNP achieved 96.12% tagging ac-curacy and ArabicSVM achieved 95.87% over thesame testing data used by Diab et al One simplehybrid model would be adding the analyses pro-duced by the SVM to the morphological analyzeranalyses and disambiguate these analyses usingMorphTagger's HMM.
This system has improvedaccuracy ?
it achieved accuracy of 96.18%, higherthan both of the base models.The problem with such model is over-generationof the SVM: when checked over ATB1 and ATB2,40% of the new analyses introduced by the SVMare correct analyses, and 60% are wrong.
To avoidthis problem, we suggest conditioning the additionof SVM analyses on the sentence's tagging prob-ability calculated by the HMM model.
This is justi-fied due to the fact that there is correlation betweenthe probability of the tagging of a sentence givenby a language model and the accuracy of the tag-ging.
The relation is shown in Figure 1.7580859095100-800 -700 -600 -500 -400 -300 -200 -100 0normalized log(P(s))accuracyFigure 1 Probability VS AccuracyFigure 1 shows the relation between the accu-racy of the tagging and the normalized logarithmicprobability of the tagging.
We normalize the prob-ability of the tagging by the sentence length aslonger sentences usually have lower probabilities.Following the previous conclusions, we proposea hybrid model which adds the analyses of theSVM only in cases where the tagging probabilityby the basic MorphTagger system is lower than anempirically calculated threshold.
If the HMM isconfident about the tagging it produces, the prob-ability of the tagging will be high enough to passthe threshold, and then the tagging will be output-ted without adding the SVM analyses which mightadd  noise  to  the  morphological  analyzer  output.
Ageneral algorithm is shown in Figure 2.101Figure 2 - Enhanced Tagging AlgorithmNote that in the algorithm, a new (word, tag)pair introduced by the morphological analyzer orby the character model does not appear in thetagged corpus, therefore a small count ?=1 is givenin such cases.
This method can be improved fur-ther, especially for the analyses produced by thedata-driven character-based method.The accuracy we obtained using this system was96.28% which shows slight improvement over theprevious simple hybrid system.
Examining the er-rors in the simple hybrid method and the condi-tioned method, we see that the improvement is notsmooth: the conditioned model includes errorswhich did not exist in the simple model.
These er-rors occur when correct analyses of the character-based model were discarded.
In general, however,the conditioned method chooses more correctanalyses.
It should be noted that adding the charac-ter-based model analyses boosted the coveragefrom 97% to 98%, but the accuracy did not im-prove to the same level.
The main cause for this isthe weak relation between the probability of a sen-tence and the accuracy.
As it is difficult to modelthis relation, we believe that more time should beinvested to improve the HMM probabilities espe-cially for the character model analyses, which canboost the chances of choosing good analyses.6 Conclusions and Future WorkThis paper demonstrates that it is possible to suc-cessfully port a POS tagger originally built for He-brew to Arabic using a morphological analyzer anda tagged corpus.
The POS tagger (calledMorphTagger) achieves state-of-the-art resultsboth on Hebrew and Arabic.
Despite this positiveresult we find that further improvement of accu-racy is hindered by the coverage of the morpho-logical analyzer.
Contrary to earlier work on POStagging, the problem turns out not so much in un-known (OOV) lexemes as much as in known lex-emes for which the correct tag is missing.
Weshowed empirical evidence that this problem arisesfor the available treebanks and morphological ana-lyzers for both Arabic and Hebrew.
We propose anapproach that smoothes a given lexical model (ob-tained from a morphological analyzer and an anno-tated corpus) by adding synthetically constructedanalyses, obtained from a POS tagger that com-bines character-level information.
Unlike earlierwork, we apply this smoothing only when theprobabilistic model assigns probabilities lowerthan a threshold to all possible POS taggings of theinput sentence.
This way we obtain moderate im-provement in Arabic POS tagging.The problem of missing lexeme-POS pairs inPOS taggers for Semitic languages is more severethan in languages like English.
We conjecture thatthis is because of the more complex morphology ofSemitic languages.In future work it might be worthwhile to con-sider morphological processes that are more com-plex than the standard affixation(suffixing/prefixing) processes in order to general-ize better over cases in the training data.
Such ageneralization may provide better coverage of lex-eme-POS pairs and would increase the upperbound on accuracy.Given a sentence s, perform the following steps:1.
Produce analyses for each word in s using the morphological analyzercombined with the corpus analyses.2.
Calculate lexical and contextual probabilities using available annotatedcorpora (using Maximum Likelihood Estimation).3.
Run Viterbi's Algorithm for HMM disambiguation, and calculate a rankof the tagging which is composed from the probability given by themodel and the length of the sentence.4.
If [rank>threshold] output tagging.4'.
[Otherwise] run the character based model over the sentence and add thenew analyses generated.5'.
Combine the analyses generated by the morphological analyzer and thecharacter-based model, update the lexical probabilities and rerun themodel.102ReferencesRoy Bar Haim, Khalil Sima?an and Yoad Winter.
2005.Choosing an Optimal Architecture for Segmentationand POS-Tagging of Modern Hebrew.
ACL Work-shop on Computational Approaches to Semitic Lan-guages.
A revised and extended version to appear inJournal of Natural Language Engineering.Eric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a casestudy in part of speech tagging.
In ComputationalLinguistics 21, pages 543-565.Tim Buckwalter.
2002.
Arabic Morphological AnalyzerVersion 1.0.
Linguistic Data Consortium, Universityof Pennsylvania.Kenneth W. Church.
1988.
A stochastic parts programand noun phrase parser for unrestricted text.
Pro-ceedings of the second conference on Applied naturallanguage processing, Pages 136-143.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004.Automatic Tagging of Arabic Text: From Raw Text toBase Phras e Chunks.
In HLT-NAACL: Short Pa-pers, pages 149-152.Nizar Habash and Owen Rambow.
2005.
Arabic To-kenization, Part-of-Speech Tagging and Morphologi-cal Disambiguation in One Fell Swoop.
InProceedings of the 43rd Annual Meeting of the As-sociation for Computational Linguistics, pages 573-580, Ann Arbor.Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-sama Emam, and Hany Hassan.
2003.
Languagemodel based Arabic word segmentation.
In ACL,pages 399-406.Mohamed Maamouri and Ann Bies.
2004.
Developingan Arabic treebank: Methods, guidelines, proce-dures, and tools.
In Proceedings of the Workshop onComputational Approaches to Arabic Script-basedLanguages (COLING), Geneva.Christopher D. Manning and Hinrich Sch?tze.
1999.Foundations of Statistical Natural Language Proc-essing.
The MIT press, Cambridge, Massachusetts.Tetsuji Nakagawa.
2004.
Chinese and Japanese wordsegmentation using word-level and character-levelinformation.
In Proceedings of the 20th InternationalConference on Computational Linguistics, pages466-472, Geneva.Erel Segal.
2001.
Hebrew morphological analyzer forHebrew undotted texts.
Master's thesis, ComputerScience Department, Technion, Haifa, Israel.Ralph Weischedel, Marie Meteer, Richard Schwartz,Lance Ramshaw and Jeff Palmucci.
1993.
Copingwith Ambiguity and Unknown Words through Prob-abilistic Models.
Computational Linguistics (Specialissue on using large corpora: II) volume 19, pages361-382.103
