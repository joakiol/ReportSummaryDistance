Labeling Corrections and Aware Sitesin Spoken Dialogue SystemsJulia Hirschbergy and Marc Swertsz and Diane Litmanyy AT&T Labs{Research z IPO, Eindhoven, The Netherlands,Florham Park, NJ, 07932 USA and CNTS, Antwerp, Belgiumfjulia/dianeg@research.att.com m.g.j.swerts@tue.nlAbstractThis paper deals with user correc-tions and aware sites of system er-rors in the TOOT spoken dialoguesystem.
We rst describe our cor-pus, and give details on our proced-ure to label corrections and awaresites.
Then, we show that correc-tions and aware sites exhibit someprosodic and other properties whichset them apart from `normal' utter-ances.
It appears that some correc-tion types, such as simple repeats,are more likely to be correctly recog-nized than other types, such as para-phrases.
We also present evidencethat system dialogue strategy aectsusers' choice of correction type, sug-gesting that strategy-specic meth-ods of detecting or coaching users oncorrections may be useful.
Awaresites tend to be shorter than otherutterances, and are also more dif-cult to recognize correctly for theASR system.1 IntroductionCompared to many other systems, spokendialogue systems (SDS) tend to have morediculties in correctly interpreting user in-put.
Whereas a car will normally go left ifthe driver turns the steering wheel in thatdirection or a vacuum cleaner will start work-ing if one pushes the on-button, interactionsbetween a user and a spoken dialogue systemare often hampered by mismatches betweenthe action intended by the user and the actionexecuted by the system.
Such mismatchesare mainly due to errors in the AutomaticSpeech Recognition (ASR) and/or the Nat-ural Language Understanding (NLU) com-ponent of these systems.
To solve these mis-matches, users often have to put considerableeort in trying to make it clear to the systemthat there was a problem, and trying to cor-rect it by re-entering misrecognized or misin-terpreted information.
Previous research hasalready brought to light that it is not alwayseasy for users to determine whether their in-tended actions were carried out correctly ornot, in particular when the dialogue systemdoes not give appropriate feedback about itsinternal representation at the right moment.In addition, users' corrections may miss theirgoal, because corrections themselves are moredicult for the system to recognize and in-terpret correctly, which may lead to so-calledcyclic (or spiral) errors.
That correctionsare dicult for ASR systems is generally ex-plained by the fact that they tend to be hyper-articulated | higher, louder, longer .
.
.
thanother turns (Wade et al, 1992; Oviatt et al,1996; Levow, 1998; Bell and Gustafson, 1999;Shimojima et al, 1999), where ASR modelsare not well adapted to handle this specialspeaking style.The current paper focuses on user correc-tions, and looks at places where people rstbecome aware of a system problem (\awaresites").
In other papers (Swerts et al, 2000;Hirschberg et al, 2001; Litman et al, 2001),we have already given some descriptive stat-istics on corrections and aware sites and wehave been looking at methods to automatic-ally predict these two utterance categories.One of our major ndings is that prosody,which had already been shown to be a goodpredictor of misrecognitions (Litman et al,2000; Hirschberg et al, 2000), is also useful tocorrectly classify corrections and aware sites.In this paper, we will elaborate more on theexact labeling scheme we used, and add fur-ther descriptive statistics.
More in particular,we address the question whether there is muchvariance in the way people react to system er-rors, and if so, to what extent this variancecan be explained on the basis of particularproperties of the dialogue system.
In the fol-lowing section we rst provide details on theTOOT corpus that we used for our analyses.Then we give information on the labels forcorrections and aware sites, and on the actuallabeling procedure.
The next section givesthe results of some descriptive statistics onproperties of corrections and aware sites andon their distributions.
We will end the paperwith a general discussion of our ndings.2 The data2.1 The TOOT corpusOur corpus consists of dialogues between hu-man subjects and TOOT, a spoken dialoguesystem that allows access to train informationfrom the web via telephone.
TOOT was col-lected to study variations in dialogue strategyand in user-adapted interaction (Litman andPan, 1999).
It is implemented using anIVR (interactive voice response) platform de-veloped at AT&T, combining ASR and text-to-speech with a phone interface (Kamm etal., 1997).
The system's speech recognizer isa speaker-independent hidden Markov modelsystem with context-dependent phone modelsfor telephone speech and constrained gram-mars dening vocabulary at any dialoguestate.
The platform supports barge-in.
Sub-jects performed four tasks with one of severalversions of the system that diered in termsof locus of initiative (system, user, or mixed),conrmation strategy (explicit, implicit, ornone), and whether these conditions couldbe changed by the user during the task (ad-aptive vs. non-adaptive).
TOOT's initiativeSystem Initiative, Explicit ConrmationT: Which city do you want to go to?U: Chicago.S: Do you want to go to Chicago?U: Yes.User Initiative, No ConrmationS: How may I help you?U: I want to go to Chicago from Baltimore.S: On which day of the week do you wantto leave?U: I want a train at 8:00.Mixed Initiative, Implicit ConrmationS: How may I help you?U: I want to go to Chicago.S: I heard you say go to Chicago.Which city do you want to leave from?U: Baltimore.Figure 1: Illustrations of various dialoguestrategies in TOOTstrategy species who has control of the dia-logue, while TOOT's conrmation strategyspecies how and whether TOOT lets the userknow what it just understood.
The fragmentsin Figure 1 provide some illustrations of howdialogues vary with strategy.
Subjects were39 students; 20 native speakers and 19 non-native, 16 female and 23 male.
Dialogueswere recorded and system and user behaviorlogged automatically.
The concept accuracy(CA) of each turn was manually labeled.
Ifthe ASR correctly captured all task-relatedinformation in the turn (e.g.
time, departureand arrival cities), the turn's CA score was1 (semantically correct).
Otherwise, the CAscore reected the percentage of correctly re-cognized task information in the turn.
Thedialogues were also transcribed and automat-ically scored in comparison to the ASR re-cognized string to produce a word error rate(WER) for each turn.
For the study describedbelow, we examined 2328 user turns (all userinput between two system inputs) from 152dialogues.2.2 Dening Corrections and AwareSitesTo identify corrections1in the corpus two au-thors independently labeled each turn as towhether or not it constituted a correction ofa prior system failure (a rejection or CA er-ror, which were the only system failure sub-jects were aware of) and subsequently de-cided upon a consensus label.
Note that muchof the discrepancies between labels were dueto tiredness or incidental sloppiness of indi-vidual annotators, rather than true disagree-ment.
Each turn labeled `correction' was fur-ther classied as belonging to one of the fol-lowing categories: REP (repetition, includ-ing repetitions with dierences in pronunci-ation oruency), PAR (paraphrase), ADD(task-relevant content added, OMIT (contentomitted), and ADD/OMIT (content both ad-ded and omitted).
Repetitions were furtherdivided into repetitions with pronunciationvariation (PRON) (e.g.
yes correcting yeah),and repetitions where the correction was pro-nounced using the same pronunciation as theoriginal turn, but this distinction was di-cult to make and turned out not to be useful.User turns which included both correctionsand other speech acts were so distinguished bylabeling them \2+".
For user turns contain-ing a correction plus one or more additionaldialogue acts, only the correction is used forpurposes of analysis below.
We also labeled asrestarts user corrections which followed non-initial system-initial prompts (e.g.
\How mayI help you?"
or \What city do you want togo to?
"); in such cases system and user es-sentially started the dialogue over from thebeginning.
Figure 2 shows examples of eachcorrection type and additional label for cor-rections of system failures on I want to goto Boston on Sunday.
Note that the utter-ance on the last line of this gure is labeled2+PAR, given that this turn consist of twospeech acts: the goal of the no-part of this1The labels discussed in this section for correctionsand aware sites may well be related to more generaldialogue acts, like the ones proposed by (Allen andCore, 1997), but this needs to be explored in moredetail in the future.turn is to signal a problem, whereas the re-mainder of this turn serves to correct a priorerror.Corr Type CorrectionREP I want to go to Boston on SundayPAR To Boston on SundayOMIT I want to go to BostonADD To Boston on Sunday at 8pmADD/ I want to arrive Sunday at 8pmOMIT2+PAR No, to Boston on SundayFigure 2: Examples of Correction TypesEach correction was also indexed with anidentier representing the closest prior turnit was correcting, so that we could investigate\chains" of corrections of a single failed turn,by tracing back through subsequent correc-tions of that turn.
Figure 3 shows a fragmentof a TOOT dialogue with corrections labeledas discussed above.We also identied aware sites in our cor-pus | turns where a user, while interact-ing with a machine, rst becomes aware thatthe system has misrecognized a previous userturn.
For our corpus, we tried to determ-ine whether there was some evidence in theuser turn indicating that the user had be-come aware of a mistake in the system's un-derstanding of a previous user turn, and, ifso, which previous turn had occasioned thaterror.
Note that such aware sites may ormay not also be corrections (another type ofpost-misrecognition turn), since a user maynot immediately provide correcting informa-tion.
Also, it may take a while before theuser is able to notice a system error.
Fig-ure 4 shows an example that illustrates casesin which both the user's awareness and cor-rection of a misrecognition occur in the sameturn (e.g.
turns 1159 and 1160, after sys-tem prompts for information already given inturn 1158).
It also illustrates cases in whichaware sites and corrections occur in dierentturns.
For example, after the immediate ex-plicit system conrmation of turn 1162, theuser rst becomes aware of the system errorsTurn Turn ID Corr of Corr TypeS: On which day of the week do you want to leave?S: Sorry, I didn't hear anything from you.Please tell me your departure date.U: Um tomorrow 776 NA NAS: You can say the departure date.
For example,you can say today or tomorrow.
Or you can sayMonday, Tuesday, Wednesday...U: Tomorrow 777 776 REPS: You can say the departure date.
For example,you can say today or tomorrow.
Or you can sayMonday, Tuesday, Wednesday, Thursday, Friday...U: Saturday 778 777 PARS: Do you want to leave on Saturday?U: Yes 779 NA NAS: What time do you want to leave?U: Eight o'clock A M 780 NA NAS: Do you want to leave around 10:00pm?U: Eight o'clock 781 780 OMITS: Do you want to leave around 10:00pm?U: No 782 NA NAS: What time do you want to leave?U: 8:00am 783 781 ADDFigure 3: Toot Dialogue Fragment with Correction Labels(turn 1163), then separately corrects them(turn 1164).
When no immediate conrm-ation of an utterance occurs (as with turn1158), it may take several turns before theuser becomes aware of any misrecognition er-rors.
For example, it is not until turn 1161that the user rst becomes aware of the er-ror in date and time from 1158; the user thencorrects the error in 1162.
Of all turns inour corpus, 13% represent cases of turns thatare only corrections, 14% are only aware sites,and 16% are turns where aware sites and cor-rections co-occur.
Also, note that turns 1162and 1164 in this dialogue fragment representcases of restarts after a system-initial, non-initial prompt (\How may I help you?
").3 Characteristics of correctionsand aware sites in TOOT3.1 CorrectionsWe identied 29% of the turns in the corpusas corrections.
These were a serious prob-lem for the system, being misrecognized interms of transcription error about twice asoften (61%) as non-corrections (33%) and interms of concept error in 53% of cases for cor-rections compared with 21% concept error fornon-corrections.Corrections diered from non-correctionsin other ways as well, which are suggest-ive of how they might be identied by anSDS.
We have previously discussed the pros-odic and acoustic dierences between correc-tions and non-correction (Swerts et al, 2000;Hirschberg et al, 2001).
In particular, inline with previous studies, we found that cor-rections more often tend to be hyperarticu-lated (longer, louder, with great pitch excur-sions,...) than other turns.
More recently wehave also discovered dierences in other di-mensions.First, corrections appear to be longer thannon-corrections in numbers of words, whenwe examine actual human transcriptions ofTurn Turn ID Aware of Corr ofS: How may I help you?U: Get me the train to New York City fromBaltimore on Sunday at eight thirty pm 1158 NA NAS: Which city do you want to go to?U: New York City 1159 1158 1158S: Which city do you want to leave from?U: Baltimore 1160 1158 1158S: Do you want me to nd the trains fromBaltimore to New York City today at anytime now?U: No 1161 1158 NAS: How may I help you?U: Get me the train to New York City fromBaltimore on Sunday at eight thirty pm 1162 NA 1158S: Do you want me to nd the trains fromBaltimore to New York City today at anytime now?U: No 1163 1162 NAS: How may I help you?U: Get me the train on Sunday at eight thirty pm 1164 NA 1162Figure 4: Dialogue Fragment with Aware and Correction Labels.them, both in absolute terms (T=17.68;df=2326; p=0) and also controlling forspeaker (T=5.32; df=38; p=0).
Even theASR hypotheses show this dierence, withhypotheses of corrections being longer in ab-solute terms (T=13.72; df=2326; p=0) andacross speakers (T=5.18; df=38; p=0).Of the correction types we labeled, thelargest number were REPs and OMITs, asshown in Table 1, which shows over-all dis-tribution of correction types, and distribu-tions for each type of system failure corrected.Table 1 shows that 39% of TOOT correctionswere simple repetitions of the previously mis-recognized turn.
While this strategy is oftensuboptimal in correcting ASR errors (Levow,1998), REPs (45% error) and OMITs (52% er-ror) were better recognized than ADDs (90%error) and PARs (72% error).
Thus, over-all, users tend to have a preference for correc-tion types that are more likely to be succes-ful.
That REPs and OMITs are more oftencorrectly recognized can be linked to the ob-servation that they tend to be realized withprosody which is less marked than the pros-ody on ADDs and PARs.
Table 2 shows thatREPs and OMITs are closer to normal utter-ances in terms of their prosodic features thanADDs, which are considerably higher, longerand slower.
This is in line with our previousobservations that marked settings for theseprosodic features more often lead to recogni-tion errors.What the user was correcting also inu-enced the type of correction chosen.
Table1 shows that corrections of misrecognitions(Post-Mrec) were more likely to omit inform-ation present in the original turn (OMITs),while corrections of rejections (Post-Rej) weremore likely to be simple repetitions.
Thelatter nding is not surprising, since the re-jection message for tasks was always a closeparaphrase of \Sorry, I can't understandyou.
Can you please repeat your utterance?
"However, it does suggest the surprising powerof system directions, and how important it isto craft prompts to favor the type of correc-tion most easily recognized by the system.Corrections following system restartsdiered in type somewhat from other correc-tions, with more turns adding new materialto the correction and fewer of them repeatingADD ADD/OMIT OMIT PAR REPAll 8% 2% 32% 19% 39%% Mrec(WER) 90% 93% 52% 72% 45%% Mrec(CA) 88% 71% 47% 65% 45%Post-Mrec 7% 3% 40% 18% 32%Post-Rej 6% 0% 7% 28% 59%Table 1: Distribution of Correction TypesFeature Normal ADD ADD/OMIT OMIT PAR REPF0max (Hz) 219.4 286.3 252.9 236.7 252.1 239.9rmsmax 1495.0 1868.1 2646.3 1698.0 1852.4 2024.6dur (s) 1.4 6.8 4.1 2.3 4.7 2.5tempo (sylls/s) 2.5 1.7 1.6 2.9 2.1 2.3Table 2: Averages for dierent prosodic features of dierent Correction Typesthe original turn.Dialogue strategy clearly aected the typeof correction users made.
For example, usersmore frequently repeat their misrecognizedutterance in the SystemExplicit condition,than in the MixedImplicit or UserNoConrm;the latter conditions have larger proportionsof OMITs and ADDs.
This is an importantobservation given that this suggests that somedialogue strategies lead to correction types,such as ADDs, which are more likely to bemisrecognized than correction types elicitedby other strategies.As noted above, corrections in the TOOTcorpus often take the form of chains of correc-tions of a single original error.
Looking backat Figure 3, for example, we see two chainsof corrections: In the rst, which begins withthe misrecognition of turn 776 (\Um, tomor-row"), the user repeats the original phraseand then provides a paraphrase (\Saturday"),which is correctly recognized.
In the second,beginning with turn 780, the time of depar-ture is misrecognized.
The user omits someinformation (\am") in turn 781, but withoutsuccess; an ADD correction follows, with thepreviously omitted information restored, inturn 783.
Elsewhere (Swerts et al 2000),we have shown that chain position has an in-uence on correction behaviour in the sensethat more distant corrections tend to be mis-recognized more often than corrections closerto the original error.3.2 Aware Sites708 (30%) of the turns in our corpus werelabeled aware sites.
The majority of theseturns (89%) immediately follow the systemfailures they react to, unlike the more com-plex cases in Figure 4 above.
If a systemwould be able to detect aware sites with areasonable accuracy, this would be useful,given that the system would then be able tocorrectly guess in the majority of the casesthat the problem occurred in the precedingturn.
Aware turns, like corrections, tend tobe misrecognized at a higher rate than otherturns; in terms of transcription accuracy, 50%of awares are misrecognized vs. 35% of otherturns, and in terms of concept accuracy, 39%of awares are misrecognized compared to 27%of other turns.
In other words, both typesof post-error utterances, i.e., corrections andaware sites, share the fact that they tend tolead to additional errors.
But whereas wehave shown above that for corrections this isprobably caused by the fact that these utter-ances are uttered in a hyperarticulated speak-ing style, we do not nd dierences in hyper-articulation between aware sites and `normalutterances' (T= 0.9085; df=38; p=0.3693).This could mean that these sites are real-ized in a speaking style which is not per-ceptibly dierent from normal speaking styleADD ADD/OMIT OMIT PAR REPMixedExplicit 1 0 4 1 4MixedImplicit 16 8 58 44 64MixedNoConrm 0 0 2 0 1SystemExplicit 2 2 8 31 67SystemImplicit 0 1 18 0 20SystemNoConrm 0 0 5 0 4UserExplicit 0 0 0 1 1UserImplicit 1 0 4 3 6UserNoConrm 31 3 116 47 98Table 3: Number of Correction Types for dierent dialogue strategiesSingle no Other TurnsAware site 162 546Not Aware site 122 1498Table 4: Distribution of single no utterancesand other turns for aware sites versus otherutteranceswhen judged by human labelers, but whichis still suciently dierent to cause problemsfor an ASR system.In terms of distinguishing features whichmight explain or help to identify these turns,we have previously examined the acousticand prosodic features of aware sites (Lit-man et al, 2001).
Here we present someadditional features.
Aware sites appear tobe signicantly shorter, in general, thanother turns, both in absolute terms and con-trolling for speaker variation, and whetherwe examine the ASR transcription (absolute:T=4.86; df=2326; p=0; speaker-controlled:T=5.37; df=38; p=0) or the human one (ab-solute: T=3.45; df=2326; p<.0001; speaker-controlled: T=4.69; df=38; p=0).
A sizablebut not overwhelming number of aware sitesin fact consist of a simple negation (i.e., a vari-ant of the word `no') (see Table 4).
This atthe same time shows that a simple no-detectorwill not be sucient as an indicator of awaresites (see also (Krahmer et al, 1999; Krahmeret al, to appear)), given that most aware sitesare more complex than that, such as turns1159 and 1160 in the example of Figure 4.More concretely, Table 4 shows that a singleno would correctly predict that the turn is anaware site with a precision of only 57% and arecall of only 23%.4 DiscussionThis paper has dealt with user corrections andaware sites of system errors in the TOOTspoken dialogue system.
We have describedour corpus, and have given details on our pro-cedure to label corrections and aware sites.Then, we have shown that corrections andaware sites exhibit some prosodic and otherproperties which set them apart from `normal'utterances.
It appears that some correctiontypes, such as simple repeats, are more likelyto be correctly recognized than other types,such as paraphrases.
We have also presen-ted evidence that system dialogue strategyaects users' choice of correction type, sug-gesting that strategy-specic methods of de-tecting or coaching users on corrections maybe useful.
Aware sites tend to be shorter thanother utterances, and are also more dicultto recognize correctly for the ASR system.In addition to the descriptive study presen-ted in this paper, we have also tried to auto-matically predict corrections and aware sitesusing the machine learning program RIP-PER (Cohen, 1996).
These experiments showthat corrections and aware sites can be clas-sied as such automatically, with a consider-able degree of accuracy (Litman et al, 2001;Hirschberg et al, 2001).
Such classication,we believe, will be especially useful in error-handling for SDS.
If aware sites are detect-able, they can function as backward-lookingerror-signaling devices, making it clear to thesystem that something has gone wrong inthe preceding context, so that, for example,the system can reprompt for information.
Inthis way, they are similar to what othershave termed `go-back' signals (Krahmer etal., 1999).
Aware sites can also be used asforward-looking signals, indicating upcomingcorrections or more drastic changes in user be-havior, such as complete restarts of the task.Given that, in current systems, both correc-tions and restarts often lead to recognition er-ror (Swerts et al, 2000), aware sites may beuseful in preparing systems to deal with suchproblems.
An accurate detection of turns thatare corrections may trigger the use of speciallytrained ASR models to better recognize cor-rections, or can be used to change dialoguestrategy (e.g.
from user or mixed initiative tosystem initiative after errors).ReferencesJ.
Allen and M. Core.
1997.
Dialogue markup inseveral layers.
Draft contribution for the Dis-course Resource Initiative.L.
Bell and J. Gustafson.
1999.
Repetitionand its phonetic realizations: Investigating aSwedish database of spontaneous computer-directed speech.
In Proceedings of ICPhS-99,San Francisco.
International Congress of Phon-etic Sciences.W.
Cohen.
1996.
Learning trees and rules withset-valued features.
In 14th Conference of theAmerican Association of Articial Intelligence,AAAI.J.
Hirschberg, D. Litman, and M. Swerts.
2000.Generalizing prosodic prediction of speech re-cognition errors.
In Proceedings of the SixthInternational Conference on Spoken LanguageProcessing, Beijing.J.
Hirschberg, D. Litman, and M. Swerts.
2001.Identifying user corrections automatically inspoken dialogue systems.
In Proceedings ofNAACL-2001, Pittsburgh.C.
Kamm, S. Narayanan, D. Dutton, and R.Ritenour.
1997.
Evaluating spoken dialoguesystems for telecommunication services.
InProc.
EUROSPEECH-97, Rhodes.E.
Krahmer, M. Swerts, M. Theune, and M. Wee-gels.
1999.
Error spotting in human-machine interactions.
In Proceedings ofEUROSPEECH-99.E.
Krahmer, M. Swerts, M. Theune, and M. Wee-gels.
to appear.
The dual of denial: Two usesof disconrmations in dialogue and their pros-odic correlates.
Accepted for Speech Commu-nication.G.
Levow.
1998.
Characterizing and recogniz-ing spoken corrections in human-computer dia-logue.
In Proceedings of the 36th Annual Meet-ing of the Association of Computational Lin-guistics, COLING/ACL 98, pages 736{742.D.
Litman, J. Hirschberg, and M. Swerts.
2000.Predicting automatic speech recognition per-formance using prosodic cues.
In Proceedingsof NAACL-00, Seattle, May.D.
Litman, J. Hirschberg, and M. Swerts.
2001.Predicting User Reactions to System Error.
InProceedings of ACL-01, Toulouse, July.D.
Litman and S. Pan.
1999.
Empirically eval-uating an adaptable spoken dialogue system.In Proceedings tth International conference onUser Modeling.S.
L. Oviatt, G. Levow, M. MacEarchern, andK.
Kuhn.
1996.
Modeling hyperarticulatespeech during human-computer error resolu-tion.
In Proceedings of ICSLP-96, pages 801{804, Philadelphia.A.
Shimojima, K. Katagiri, H. Koiso, andM.
Swerts.
1999.
An experimental study onthe informational and grounding functions ofprosodic features of Japanese echoic responses.In Proceedings of the ESCA Workshop on Dia-logue and Prosody, pages 187{192, Veldhoven.M.
Swerts, D. Litman, and J. Hirschberg.
2000.Corrections in spoken dialogue systems.
In Pro-ceedings of the Sixth International Conferenceon Spoken Language Processing, Beijing.E.
Wade, E. E. Shriberg, and P. J.
Price.
1992.User behaviors aecting speech recognition.
InProceedings of ICSLP-92, volume 2, pages 995{998, Ban.
