Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 104?111,New York, June 2006. c?2006 Association for Computational LinguisticsAlignment by AgreementPercy LiangUC BerkeleyBerkeley, CA 94720pliang@cs.berkeley.eduBen TaskarUC BerkeleyBerkeley, CA 94720taskar@cs.berkeley.eduDan KleinUC BerkeleyBerkeley, CA 94720klein@cs.berkeley.eduAbstractWe present an unsupervised approach tosymmetric word alignment in which twosimple asymmetric models are trainedjointly to maximize a combination ofdata likelihood and agreement betweenthe models.
Compared to the stan-dard practice of intersecting predictions ofindependently-trained models, joint train-ing provides a 32% reduction in AER.Moreover, a simple and efficient pair ofHMM aligners provides a 29% reductionin AER over symmetrized IBM model 4predictions.1 IntroductionWord alignment is an important component of acomplete statistical machine translation pipeline(Koehn et al, 2003).
The classic approaches to un-supervised word alignment are based on IBM mod-els 1?5 (Brown et al, 1994) and the HMM model(Ney and Vogel, 1996) (see Och and Ney (2003) fora systematic comparison).
One can classify thesesix models into two groups: sequence-based models(models 1, 2, and HMM) and fertility-based models(models 3, 4, and 5).1 Whereas the sequence-basedmodels are tractable and easily implemented, themore accurate fertility-based models are intractableand thus require approximation methods which are1IBM models 1 and 2 are considered sequence-based modelsbecause they are special cases of HMMs with transitions that donot depend on previous states.difficult to implement.
As a result, many practition-ers use the complex GIZA++ software package (Ochand Ney, 2003) as a black box, selecting model 4 asa good compromise between alignment quality andefficiency.Even though the fertility-based models are moreaccurate, there are several reasons to consider av-enues for improvement based on the simpler andfaster sequence-based models.
First, even withthe highly optimized implementations in GIZA++,models 3 and above are still very slow to train.
Sec-ond, we seem to have hit a point of diminishing re-turns with extensions to the fertility-based models.For example, gains from the new model 6 of Ochand Ney (2003) are modest.
When models are toocomplex to reimplement, the barrier to improvementis raised even higher.
Finally, the fertility-basedmodels are asymmetric, and symmetrization is com-monly employed to improve alignment quality byintersecting alignments induced in each translationdirection.
It is therefore natural to explore modelswhich are designed from the start with symmetry inmind.In this paper, we introduce a new method for wordalignment that addresses the three issues above.
Ourdevelopment is motivated by the observation that in-tersecting the predictions of two directional modelsoutperforms each model alone.
Viewing intersec-tion as a way of finding predictions that both modelsagree on, we take the agreement idea one step fur-ther.
The central idea of our approach is to not onlymake the predictions of the models agree at test time,but also encourage agreement during training.
Wedefine an intuitive objective function which incor-104porates both data likelihood and a measure of agree-ment between models.
Then we derive an EM-likealgorithm to maximize this objective function.
Be-cause the E-step is intractable in our case, we usea heuristic approximation which nonetheless workswell in practice.By jointly training two simple HMM models, weobtain 4.9% AER on the standard English-FrenchHansards task.
To our knowledge, this is the lowestpublished unsupervised AER result, and it is com-petitive with supervised approaches.
Furthermore,our approach is very practical: it is no harder toimplement than a standard HMM model, and jointtraining is no slower than the standard training oftwo HMM models.
Finally, we show that wordalignments from our system can be used in a phrase-based translation system to modestly improve BLEUscore.2 Alignment models: IBM 1, 2 and HMMWe briefly review the sequence-based word align-ment models (Brown et al, 1994; Och and Ney,2003) and describe some of the choices in ourimplementation.
All three models are generativemodels of the form p(f | e) = ?a p(a, f | e),where e = (e1, .
.
.
, eI) is the English sentence,f = (f1, .
.
.
, fJ) is the French sentence, and a =(a1, .
.
.
, aJ ) is the (asymmetric) alignment whichspecifies the position of an English word aligned toeach French word.
All three models factor in thefollowing way:p(a, f | e) =J?j=1pd(aj | aj?
, j)pt(fj | eaj ), (1)where j?
is the position of the last non-null-alignedFrench word before position j.2The translation parameters pt(fj | eaj ) are pa-rameterized by an (unsmoothed) lookup table thatstores the appropriate local conditional probabilitydistributions.
The distortion parameters pd(aj = i?
|aj?
= i) depend on the particular model (we writeaj = 0 to denote the event that the j-th French word2The dependence on aj?
can in fact be implemented as afirst-order HMM (see Och and Ney (2003)).is null-aligned):pd(aj =0 | aj?= i) = p0pd(aj = i?
6= 0 | aj?= i) ?(1?
p0) ?????
?1 (IBM 1)c(i?
?b jIJ c) (IBM 2)c(i?
?i) (HMM),where p0 is the null-word probability and c(?)
con-tains the distortion parameters for each offset argu-ment.
We set the null-word probability p0 = 1I+1depending on the length of the English sentence,which we found to be more effective than using aconstant p0.In model 1, the distortion pd(?
| ?)
specifies a uni-form distribution over English positions.
In model2, pd(?
| ?)
is still independent of aj?
, but it can nowdepend on j and i?
through c(?).
In the HMM model,there is a dependence on aj?
= i, but only throughc(i?
i?
).We parameterize the distortion c(?)
using a multi-nomial distribution over 11 offset buckets c(?
?5), c(?4), .
.
.
, c(4), c(?
5).3 We use three sets ofdistortion parameters, one for transitioning into thefirst state, one for transitioning out of the last state,and one for all other transitions.
This works betterthan using a single set of parameters or ignoring thetransitions at the two ends.3 Training by agreementTo motivate our joint training approach, we firstconsider the standard practice of intersecting align-ments.
While the English and French sentencesplay a symmetric role in the word alignment task,sequence-based models are asymmetric: they aregenerative models of the form p(f | e) (E?F), orp(e | f) (F?E) by reversing the roles of source andtarget.
In general, intersecting the alignment predic-tions of two independently-trained directional mod-els reduces AER, e.g., from 11% to 7% for HMMmodels (Table 2).
This suggests that two modelsmake different types of errors that can be eliminatedupon intersection.
Figure 1 (top) shows a commontype of error that intersection can partly remedy.
In3For each sentence, the probability mass of each of the twoend buckets c(?
?5) or c(?
5) is uniformly divided amongthose valid offsets.105Independenttrainingwedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.wedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.wedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.E?F: 84.2/92.0/13.0 F?E: 86.9/91.1/11.5 Intersection: 97.0/86.9/7.6Jointtrainingwedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.wedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.wedeemed itinadvisabletoattendthemeetingandsoinformedcojo .nousneavonspascrubondeassistera`lare?unionetenavonsinforme?lecojoenconse?quence.E?F: 89.9/93.6/8.7 F?E: 92.2/93.5/7.3 Intersection: 96.5/91.4/5.7Figure 1: An example of the Viterbi output of a pair of independently trained HMMs (top) and a pair ofjointly trained HMMs (bottom), both trained on 1.1 million sentences.
Rounded boxes denote possiblealignments, square boxes are sure alignments, and solid boxes are model predictions.
For each model, theoverall Precision/Recall/AER on the development set is given.
See Section 4 for details.this example, COJO is a rare word that becomes agarbage collector (Moore, 2004) for the models inboth directions.
Intersection eliminates the spuriousalignments, but at the expense of recall.Intersection after training produces alignmentsthat both models agree on.
The joint training pro-cedure we describe below builds on this idea by en-couraging the models to agree during training.
Con-sider the output of the jointly trained HMMs in Fig-ure 1 (bottom).
The garbage-collecting rare word isno longer a problem.
Not only are the individualE?F and F?E jointly-trained models better thantheir independently-trained counterparts, the jointly-trained intersected model also provides a signifi-cant overall gain over the independently-trained in-tersected model.
We maintain both high precisionand recall.Before we introduce the objective function forjoint training, we will write the two directional mod-els in a symmetric way so that they share the same106alignment spaces.
We first replace the asymmetricalignments a with a set of indicator variables foreach potential alignment edge (i, j): z = {zij ?
{0, 1} : 1 ?
i ?
I, 1 ?
j ?
J}.
Each z can bethought of as an element in the set of generalizedalignments, where any subset of word pairs may bealigned (Och and Ney, 2003).
Sequence-based mod-els p(a | e, f) induce a distribution over p(z | e, f)by letting p(z | e, f) = 0 for any z that does notcorrespond to any a (i.e., if z contains many-to-onealignments).We also introduce the more compact notationx = (e, f) to denote an input sentence pair.
Weput arbitrary distributions p(e) and p(f) to removethe conditioning, noting that this has no effect onthe optimization problem in the next section.
Wecan now think of the two directional sequence-basedmodels as each inducing a distribution over thesame space of sentence pairs and alignments (x, z):p1(x, z; ?1) = p(e)p(a, f | e; ?1)p2(x, z; ?2) = p(f)p(a, e | f ; ?2).3.1 A joint objectiveIn the next two sections, we describe how to jointlytrain the two models using an EM-like algorithm.We emphasize that this technique is quite generaland can be applied in many different situationswhere we want to couple two tractable models overinput x and output z.To train two models p1(x, z; ?1) and p2(x, z; ?2)independently, we maximize the data likelihood?x pk(x; ?k) =?x?z pk(x, z; ?k) of each modelseparately, k ?
{1, 2}:max?1,?2?x[log p1(x; ?1) + log p2(x; ?2)] .
(2)Above, the summation over x enumerates the sen-tence pairs in the training data.There are many possible ways to quantify agree-ment between two models.
We chose a particularlysimple and mathematically convenient measure ?the probability that the alignments produced by thetwo models agree on an example x:?zp1(z | x; ?1)p2(z | x; ?2).We add the (log) probability of agreement to thestandard log-likelihood objective to couple the twomodels:max?1,?2?x[log p1(x; ?1) + log p2(x; ?2) +log?zp1(z | x; ?1)p2(z | x; ?2)].
(3)3.2 Optimization via EMWe first review the EM algorithm for optimizing asingle model, which consists of iterating the follow-ing two steps:E : q(z;x) := p(z | x; ?
),M : ??
:= argmax?
?x,zq(z;x) log p(x, z; ?
).In the E-step, we compute the posterior distributionof the alignments q(z;x) given the sentence pair xand current parameters ?.
In the M-step, we use ex-pected counts with respect to q(z;x) in the maxi-mum likelihood update ?
:= ?
?.To optimize the objective in Equation 3, we canderive a similar and simple procedure.
See the ap-pendix for the derivation.E: q(z;x) := 1Zxp1(z | x; ?1)p2(z | x; ?2),M: ??
= argmax?
?x,zq(z;x) log p1(x, z; ?1)+?x,zq(z;x) log p2(x, z; ?2),where Zx is a normalization constant.
The M-stepdecouples neatly into two independent optimizationproblems, which lead to single model updates usingthe expected counts from q(z;x).
To compute Zx inthe E-step, we must sum the product of two modelposteriors over the set of possible zs with nonzeroprobability under both models.
In general, if bothposterior distributions over the latent variables zdecompose in the same tractable manner, as inthe context-free grammar induction work of Kleinand Manning (2004), the summation could becarried out efficiently, for example using dynamicprogramming.
In our case, we would have to sumover the set of alignments where each word inEnglish is aligned to at most one word in Frenchand each word in French is aligned to at most one107word in English.
Unfortunately, for even verysimple models such as IBM 1 or 2, computing thenormalization constant over this set of alignmentsis a #P -complete problem, by a reduction fromcounting matchings in a bipartite graph (Valiant,1979).
We could perhaps attempt to compute q us-ing a variety of approximate probabilistic inferencetechniques, for example, sampling or variationalmethods.
With efficiency as our main concern, weopted instead for a simple heuristic procedure byletting q be a product of marginals:q(z;x) :=?i,jp1(zij | x; ?1)p2(zij | x; ?2),where each pk(zij | x; ?k) is the posterior marginalprobability of the (i, j) edge being present (or ab-sent) in the alignment according to each model,which can be computed separately and efficiently.Now the new E-step only requires simplemarginal computations under each of the mod-els.
This procedure is very intuitive: edges onwhich the models disagree are discounted in the E-step because the product of the marginals p1(zij |x; ?1)p2(zij | x; ?2) is small.
Note that in general,this new procedure is not guaranteed to increase ourjoint objective.
Nonetheless, our experimental re-sults show that it provides an effective method ofachieving model agreement and leads to significantaccuracy gains over independent training.3.3 PredictionOnce we have trained two models, either jointlyor independently, we must decide how to combinethose two models to predict alignments for new sen-tences.First, let us step back to the case of one model.Typically, the Viterbi alignment argmaxz p(z | x)is used.
An alternative is to use posterior decoding,where we keep an edge (i, j) if the marginal edgeposterior p(zij | x) exceeds some threshold 0 < ?
<1.
In symbols, z = {zij = 1 : p(zij = 1 | x) ?
?
}.4Posterior decoding has several attractive advan-tages over Viterbi decoding.
Varying the threshold?
gives a natural way to tradeoff precision and re-call.
In fact, these posteriors could be used more di-4See Matusov et al (2004) for an alternative use of thesemarginals.rectly in extracting phrases for phrase-based trans-lation.
Also, when we want to combine two mod-els for prediction, finding the Viterbi alignmentargmaxz p1(z | x)p2(z | x) is intractable forHMM models (by a reduction from quadratic as-signment), and a hard intersection argmaxz1 p1(z1 |x) ?
argmaxz2 p2(z2 | x) might be too sparse.On the other hand, we can threshold the product oftwo edge posteriors quite easily: z = {zij = 1 :p1(zij = 1 | x)p2(zij = 1 | x) ?
?
}.We noticed a 5.8% relative reduction in AER (forour best model) by using posterior decoding with avalidation-set optimized threshold ?
instead of usinghard intersection of Viterbi alignments.4 ExperimentsWe tested our approach on the English-FrenchHansards data from the NAACL 2003 Shared Task,which includes a training set of 1.1 million sen-tences, a validation set of 37 sentences, and a test setof 447 sentences.
The validation and test sentenceshave been hand-aligned (see Och and Ney (2003))and are marked with both sure and possible align-ments.
Using these alignments, alignment error rate(AER) is calculated as:(1?
|A ?
S|+ |A ?
P ||A|+ |S|)?
100%,where A is a set of proposed edges, S is the suregold edges, and P is the possible gold edges.As a preprocessing step, we lowercased all words.Then we used the validation set and the first 100 sen-tences of the test set as our development set to tuneour models.
Lastly, we ran our models on the last347 sentences of the test set to get final AER results.4.1 Basic resultsWe trained models 1, 2, and HMM on the Hansardsdata.
Following past work, we initialized the trans-lation probabilities of model 1 uniformly over wordpairs that occur together in some sentence pair.Models 2 and HMM were initialized with uni-form distortion probabilities and model 1 translationprobabilities.
Each model was trained for 5 itera-tions, using the same training regimen as in Och andNey (2003).108Model Indep.
Joint Reduction10K sentencesModel 1 27.4 23.6 13.8Model 2 18.2 14.9 18.5HMM 12.1 8.4 30.6100K sentencesModel 1 21.5 19.2 10.9Model 2 13.1 10.2 21.7HMM 8.0 5.3 33.11.1M sentencesModel 1 20.0 16.5 17.5Model 2 11.4 9.2 18.8HMM 6.6 5.2 21.5Table 1: Comparison of AER between independentand joint training across different size training setsand different models, evaluated on the developmentset.
The last column shows the relative reduction inAER.Table 1 shows a summary of the performance ofindependently and jointly trained models under var-ious training conditions.
Quite remarkably, for alltraining data sizes and all of the models, we seean appreciable reduction in AER, especially on theHMM models.
We speculate that since the HMMmodel provides a richer family of distributions overalignments than either models 1 or 2, we can learnto synchronize the predictions of the two models,whereas models 1 and 2 have a much more limitedcapacity to synchronize.Table 2 shows the HMM models compared tomodel 4 alignments produced by GIZA++ on the testset.
Our jointly trained model clearly outperformsnot only the standard HMM but also the more com-plex IBM 4 model.
For these results, the thresholdused for posterior decoding was tuned on the devel-opment set.
?GIZA HMM?
and ?HMM, indep?
arethe same algorithm but differ in implementation de-tails.
The E?F and F?E models benefit a greatdeal by moving from independent to joint training,and the combined models show a smaller improve-ment.Our best performing model differs from standardIBM word alignment models in two ways.
First andmost importantly, we use joint training instead ofModel E?F F?E CombinedGIZA HMM 11.5 11.5 7.0GIZA Model 4 8.9 9.7 6.9HMM, indep 11.2 11.5 7.2HMM, joint 6.1 6.6 4.9Table 2: Comparison of test set AER between vari-ous models trained on the full 1.1 million sentences.Model I+V I+P J+V J+P10K sentencesModel 1 29.4 27.4 22.7 23.6Model 2 20.1 18.2 16.5 14.9HMM 15.2 12.1 8.9 8.4100K sentencesModel 1 22.9 21.5 18.6 19.2Model 2 15.1 13.1 12.9 10.2HMM 9.2 8.0 6.0 5.31.1M sentencesModel 1 20.0 19.4 16.5 17.3Model 2 12.7 11.4 11.6 9.2HMM 7.6 6.6 5.7 5.2Table 3: Contributions of using joint training versusindependent training and posterior decoding (withthe optimal threshold) instead of Viterbi decoding,evaluated on the development set.independent training, which gives us a huge boost.The second change, which is more minor and or-thogonal, is using posterior decoding instead ofViterbi decoding, which also helps performance formodel 2 and HMM, but not model 1.
Table 3 quan-tifies the contribution of each of these two dimen-sions.Posterior decoding In our results, we have tunedour threshold to minimize AER.
It turns out thatAER is relatively insensitive to the threshold as Fig-ure 2 shows.
There is a large range from 0.2 to 0.5where posterior decoding outperforms Viterbi de-coding.Initialization and convergence In addition to im-proving performance, joint training also enjoys cer-tain robustness properties.
Specialized initializationis absolutely crucial for an independently-trained109024681012140  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9PerformancePosterior threshold100-Precision100-RecallAERViterbi AERFigure 2: The precision, recall, and AER as thethreshold is varied for posterior decoding in a jointlytrained pair of HMMs.HMM model.
If we initialize the HMM model withuniform translation parameters, the HMM convergesto a completely senseless local optimum with AERabove 50%.
Initializing the HMM with model 1 pa-rameters alleviates this problem.On the other hand, if we jointly train two HMMsstarting from a uniform initialization, the HMMsconverge to a surprisingly good solution.
On the fulltraining set, training two HMMs jointly from uni-form initialization yields 5.7% AER, only slightlyhigher than 5.2% AER using model 1 initialization.We suspect that the agreement term of the objectiveforces the two HMMs to avoid many local optimathat each one would have on its own, since these lo-cal optima correspond to posteriors over alignmentsthat would be very unlikely to agree.
We also ob-served that jointly trained HMMs converged veryquickly?in 5 iterations?and did not exhibit over-fitting with increased iterations.Common errors The major source of remainingerrors are recall errors that come from the shortcom-ings of the HMM model.
The E?F model gives 0probability to any many-to-one alignments and theF?E model gives 0 probability to any one-to-manyalignments.
By enforcing agreement, the two mod-els are effectively restricted to one-to-one (or zero)alignments.
Posterior decoding is in principle ca-pable of proposing many-to-many alignments, butthese alignments occur infrequently since the poste-riors are generally sharply peaked around the Viterbialignment.
In some cases, however, we do get one-to-many alignments in both directions.Another common type of errors are precision er-rors due to the models overly-aggressively prefer-ring alignments that preserve monotonicity.
OurHMM model only uses 11 distortion parameters,which means distortions are not sensitive to the lex-ical context of the sentences.
For example, in onesentence, le is incorrectly aligned to the as a mono-tonic alignment following another pair of correctlyaligned words, and then the monotonicity is brokenimmediately following le?the.
Here, the model isinsensitive to the fact that alignments following arti-cles tend to be monotonic, but alignments precedingarticles are less so.Another phenomenon is the insertion of ?steppingstone?
alignments.
Suppose two edges (i, j) and(i+4, j+4) have a very high probability of being in-cluded in an alignment, but the words between themare not good translations of each other.
If the inter-vening English words were null-aligned, we wouldhave to pay a big distortion penalty for jumping 4positions.
On the other hand, if the edge (i+2, j+2)were included, that penalty would be mitigated.
Thetranslation cost for forcing that edge is smaller thanthe distortion cost.4.2 BLEU evaluationTo see whether our improvement in AER also im-proves BLEU score, we aligned 100K English-French sentences from the Europarl corpus andtested on 3000 sentences of length 5?15.
UsingGIZA++ model 4 alignments and Pharaoh (Koehnet al, 2003), we achieved a BLEU score of 0.3035.By using alignments from our jointly trained HMMsinstead, we get a BLEU score of 0.3051.
While thisimprovement is very modest, we are currently inves-tigating alternative ways of interfacing with phrasetable construction to make a larger impact on trans-lation quality.5 Related WorkOur approach is similar in spirit to co-training,where two classifiers, complementary by the virtueof having different views of the data, are trainedjointly to encourage agreement (Blum and Mitchell,1998; Collins and Singer, 1999).
One key difference110in our work is that we rely exclusively on data like-lihood to guide the two models in an unsupervisedmanner, rather than relying on an initial handful oflabeled examples.The idea of exploiting agreement between two la-tent variable models is not new; there has been sub-stantial previous work on leveraging the strengthsof two complementary models.
Klein and Man-ning (2004) combine two complementary mod-els for grammar induction, one that models con-stituency and one that models dependency, in a man-ner broadly similar to the current work.
Aside frominvestigating a different domain, one novel aspect ofthis paper is that we present a formal objective and atraining algorithm for combining two generic mod-els.6 ConclusionWe have described an efficient and fully unsuper-vised method of producing state-of-the-art wordalignments.
By training two simple sequence-basedmodels to agree, we achieve substantial error re-ductions over standard models.
Our jointly trainedHMM models reduce AER by 29% over test-timeintersected GIZA++ model 4 alignments and alsoincrease our robustness to varying initialization reg-imens.
While AER is only a weak indicator of finaltranslation quality in many current translation sys-tems, we hope that more accurate alignments caneventually lead to improvements in the end-to-endtranslation process.Acknowledgments We thank the anonymous re-viewers for their comments.ReferencesAvrim Blum and Tom Mitchell.
1998.
Combining Labeledand Unlabeled Data with Co-training.
In Proceedings of theCOLT 1998.Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra,and Robert L. Mercer.
1994.
The Mathematics of StatisticalMachine Translation: Parameter Estimation.
ComputationalLinguistics, 19:263?311.Michael Collins and Yoram Singer.
1999.
Unsupervised Mod-els for Named Entity Classification.
In Proceedings ofEMNLP 1999.Abraham Ittycheriah and Salim Roukos.
2005.
A maximumentropy word aligner for arabic-english machine translation.In Proceedings of HLT-EMNLP.Dan Klein and Christopher D. Manning.
2004.
Corpus-BasedInduction of Syntactic Structure: Models of Dependency andConstituency.
In Proceedings of ACL 2004.Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003.
Sta-tistical Phrase-Based Translation.
In Proceedings of HLT-NAACL 2003.E.
Matusov, Zens.
R., and H. Ney.
2004.
Symmetric wordalignments for statistical machine translation.
In Proceed-ings of the 20th International Conference on ComputationalLinguistics, August.Robert C. Moore.
2004.
Improving IBM Word AlignmentModel 1.
In Proceedings of ACL 2004.Robert C. Moore.
2005.
A discriminative framework for bilin-gual word alignment.
In Proceedings of EMNLP.Hermann Ney and Stephan Vogel.
1996.
HMM-Based WordAlignment in Statistical Translation.
In COLING.Franz Josef Och and Hermann Ney.
2003.
A Systematic Com-parison of Various Statistical Alignment Models.
Computa-tional Linguistics, 29:19?51.Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
2005.
ADiscriminative Matching Approach to Word Alignment.
InProceedings of EMNLP 2005.L.
G. Valiant.
1979.
The complexity of computing the perma-nent.
Theoretical Computer Science, 8:189?201.Appendix: Derivation of agreement EMTo simplify notation, we drop the explicit referenceto the parameters ?.
Lower bound the objective inEquation 3 by introducing a distribution q(z;x) andusing the concavity of log:Xxlog p1(x)p2(x)Xzp1(z | x)p2(z | x) (4)?Xx,zq(z;x) log p1(x)p2(x)p1(z | x)p2(z | x)q(z;x) (5)=Xx,zq(z;x) log p1(z | x)p2(z | x)q(z;x) + C (6)=Xx,zq(z;x) log p1(x, z)p2(x, z) + D, (7)where C depends only on ?
but not q and D de-pends only q but not ?.
The E-step chooses q givena fixed ?
to maximize the lower bound.
Equation 6is exactly?x?KL(q||p1p2) + C , which is maxi-mized by setting q proportional to p1p2.
The M-stepchooses ?
given a fixed q.
Equation 7 decomposesinto two separate optimization problems.111
