Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 21?24,Rochester, April 2007. c?2007 Association for Computational LinguisticsExploiting Event Semantics to Parse the Rhetorical Structure ofNatural Language TextRajen SubbaDepartment of Computer ScienceUniversity of Illinois at ChicagoChicago, IL 60613rsubba@cs.uic.eduAbstractPrevious work on discourse parsing hasmostly relied on surface syntactic and lex-ical features; the use of semantics is lim-ited to shallow semantics.
The goal of thisthesis is to exploit event semantics in orderto build discourse parse trees (DPT) basedon informational rhetorical relations.
Ourwork employs an Inductive Logic Pro-gramming (ILP) based rhetorical relationclassifier, a Neural Network based dis-course segmenter, a bottom-up sentencelevel discourse parser and a shift-reducedocument level discourse parser.1 IntroductionDiscourse is a structurally organized set of coher-ent text segments.
The minimal unit of discourse iscalled an elementary discourse unit (EDU).
An EDUor a span of EDUs constitute a segment.
When weread text, we automatically assign rhetorical (coher-ence) relations to segments of text that we deem tobe related.
Consider the segmented text below:(Example 1) [Clean the walls thoroughly(1a)] [and allow themto dry.
(1b)] [If the walls are a dark color,(2a)] [applyprimer.
(2b)] [Put a small amount of paste in the painttray;(3a)] [add enough water(4a)] [to thin the paste toabout the consistency of cream soup.
(4b)]It is plausible to state that the rhetorical relationbetween (1a) and (1b) is preparation:act.
We canalso posit that the relation act:goal holds between(4a) and (4b).
Figure 1 shows the complete annota-tion of the full text.
Now, if we were to reorder thesesegments as [(1b), (4a), (2a), (4b), (3a), (2b), (1a)],the text would not make much sense.
Therefore, itis imperative that the contiguous spans of discoursebe coherent for comprehension.
Rhetorical relationshelp make the text coherent.Rhetorical relations based on the subject matterof the segments are called informational relations.A common understanding in discourse study is thatinformational relations are based on the underlyingcontent of the text segments.
However, previouswork (Marcu, 2000; Polanyi et al, 2004; Soricutand Marcu, 2005; Sporleder and Lascarides, 2005)in discourse parsing has relied on syntactic and lex-ical information, and shallow semantics only.The goal of this thesis is to build a computa-tional model for parsing the informational structureof instructional text that exploits ?deeper seman-tics?, namely event semantics.
Such discourse struc-tures can be useful for applications such as informa-tion extraction, question answering and intelligenttutoring systems.
Our approach makes use of a neu-ral network discourse segmenter, a rhetorical rela-tion classifier based on ILP and a discourse pars-ing model that builds sentence level DPTs bottom-up and document level DPTs using a shift-reduceparser.In section 2, we describe how we collected ourdata.
In section 3, we present our automatic dis-course segmenter.
Section 4 details our discourseparsing model based on event semantics followed bythe conclusion in section 5.21Figure 1: Discourse Annotation for Example 12 Data CollectionOur work calls for the use of a supervised machinelearning approach.
Therefore, we have manually an-notated a corpus of instructional text with rhetoricalrelations and event semantic information.
We usedan existing corpus on home repair manuals (5Mb).12.1 Manual Discourse AnnotationIn order to carry out the manual discourse anno-tation, a coding scheme was developed based onMarcu (1999) and RDA (Moser et al, 1996).
Theannotated data consists of 5744 EDUs and 5131 re-lations with a kappa value of 0.66 on about 26% ofthe corpus.
We analyzed a total of 1217 examplesto determine whether a cue phrase was present ornot.
Only 523 examples (43%) were judged to besignalled.
Furthermore, discourse cues can be am-biguous with regard to which relation they signal.In order to account for cases where discourse cuesare not present and to resolve such ambiguities, weintend to exploit event semantics.2.2 Semi-Automatic Event SemanticAnnotationInformational relations describe how the content oftwo text segments are related.
Therefore, it makesintuitive sense that verb semantics can be useful indetermining these relations.2 In Subba et al (2006),1The corpus was collected opportunistically off the internetand from other sources, and originally assembled at the Infor-mation Technology Research Institute, University of Brighton.2Especially in instructional manuals where the meaning ofmost sentences is centered on verbs.we integrated LCFLEX (Rose and Lavie, 2000) withVerbNet (Kipper et al, 2000) and CoreLex (Buite-laar, 1998) to compositionally build verb basedevent semantic representations of our EDUs.VerbNet groups together verbs that undergo thesame syntactic alternations and share similar seman-tics.
It accounts for about 4962 distinct verbs clas-sified into 237 main classes.
The semantic infor-mation is described in terms of an event that is de-composed into four stages, namely start, during, endand result.
Semantic predicates like motion and to-gether describe the participants of an event at var-ious stages.
CoreLex provides meaning represen-tations for about 40,000 nouns that are compatiblewith VerbNet.The parser was used to semi-automatically anno-tate both our training and test data.
Since the outputof the parser can be ambiguous with respect to theverb sense, we manually pick the correct sense.33 Automatic Discourse SegmentationThe task of the discourse segmenter is to segmentsentences into EDUs.
In the past, the problemof sentence level discourse segmentation has beentackled using both symbolic methods (Polanyi et al,2004; Huong et al, 2004) as well as statistical mod-els (Soricut and Marcu, 2003; Marcu, 2000) thathave exploited syntactic and lexical features.We have implemented a Neural Network model3In addition, the parser generates semantic representationsfor fragments of the sentence to handle ungrammatical sen-tences, etc.22for sentence level discourse segmentation that usessyntactic features and discourse cues.
Our modelwas trained and tested on RST-DT (2002) andachieves a performance of up to 86.12% F-Score,which is comparable to Soricut and Marcu (2003).We plan to use this model on our corpus as well.4 Discourse ParsingOnce the EDUs have been identified by the dis-course segmenter, the entire discourse structure oftext needs to be constructed.
This concerns deter-mining which text segments are related and what re-lation to assign to those segments.
Our discourseparsing model consists of a rhetorical relation clas-sifier, a sentence level discourse parser and a docu-ment level discourse parser.4.1 Rhetorical Relation ClassifierIn a preliminary investigation (Subba et al, 2006),we modeled the problem of identifying rhetorical re-lations as a classification problem using rich verb se-mantics only.Most of the work in NLP that involves learn-ing has used more traditional machine learningparadigms like decision-tree algorithms and SVMs.However, we did not find them suitable for our datawhich is represented in first order logic (FOL).
Wefound Progol (Muggleton, 1995), an ILP system, ap-propriate for our needs.
The general problem spec-ification for Progol (ILP) is given by the followingposterior sufficiency property:B ?
H |= EGiven the background knowledge B and the ex-amples E, Progol finds the simplest consistent hy-pothesis H, such that B and H entails E. The richverb semantic representation of pairs of EDUs formthe background knowledge and the manually anno-tated rhetorical relations between the pairs of EDUsserve as the positive examples.4 An A*-like searchis used to search for the most probable hypothesis.Given our model, we are able to learn rules such asthe ones given in Figure 2.
Due to the lack of spacewe only explain RULE1 here.
RULE1 states that4The output from the parser was further processed into def-inite clauses.
Positive examples are represented as ground unitclauses.RULE1:relation(EDU1,EDU2,?before:after?)
:- motion(EDU1,event0,during,C),location(EDU2,event0,start,C,D).RULE2:relation(EDU1,EDU2,?act:goal?)
:- cause(EDU1,C,event0),together(EDU1,event0,end,physical,F,G),cause(EDU2,C,event0).Figure 2: Examples of Rules learned by Progolthere is a theme (C) in motion during the event inEDU1 (the first EDU) and that C is located in loca-tion D at the start of the event in EDU2 (the secondEDU).We trained our classifier on 423 examples andtested it on 85 examples.5 A majority function base-line performs at a 51.7 F-Score.
Our model outper-forms this baseline with an F-Score of 60.24.Relation Precision Recall F-Scoregoal:act 31.57 26.08 28.57step1:step2 75 75 75before:after 54.5 54.5 54.5criterion:act 71.4 71.4 71.4Total 61.7 58.8 60.24Table 1: Rhetorical Relation Classifier ResultThis study has shown that it is possible to learnrules from FOL semantic representations using In-ductive Logic Programming to classify rhetorical re-lations.
However, it is not yet clear how useful eventsemantics is for discourse parsing.
In the future, weintend to extend our model to incorporate syntacticand lexical information as well.
Such an extensionwill allow us to assess the contribution of event se-mantics.4.2 Building Discourse Parse TreesIn addition to extending the rhetorical relation clas-sifier, our future work will involve building the dis-course parse tree at the sentence level and at the doc-ument level.
At the document level, the input willbe the sentence level discourse parse trees and theoutput will be the discourse structure of the entire5For this preliminary experiment, we decided to use onlythose relation sets that had more than 50 examples and thosethat were classified as goal:act, step1:step2, criterion:act or be-fore:after23document.When combining two text segments, promotionsets that approximate the most important EDUs ofthe text segments will be used.
As a starting point,we propose to build sentence level DPTs bottom-up.EDUs that are subsumed by the same syntactic con-stituent (usually an S, S-Bar, VP) will be combinedtogether into a larger text segment recursively untilthe the DPT at the root level has been constructed.At the document level, the DPT will be built us-ing a shift-reduce parser as in Marcu (2000).
How-ever, unlike Marcu (2000), there will only be oneshift and one reduce operation.
The reduce oper-ation will be determined by the rhetorical relationclassifier and an additional module that will deter-mine all the possible attachment points for an in-coming sentence level DPT.
An incoming sentencelevel DPT may be attached to any node on the rightfrontier of the left DPT.
Lexical cohesion will beused to rank the possible attachment points.
For bothsentence level discourse parsing and document leveldiscourse parsing, the rhetorical relation classifierwill be used to determine the informational relationbetween the text segments.5 ConclusionIn conclusion, this thesis will provide a computa-tional model for parsing the discourse structure oftext based on informational relations.
Our approachexploits event semantic information of the EDUs.Hence, it will provide a measurement of how helpfulevent semantics can be in uncovering the discoursestructure of text.
As a consequence, it will also shedsome light on the coverage of the lexical resourceswe are using.
Other contributions of our work in-clude a parser that builds event semantic represen-tations of sentences based on rich verb semanticsand noun semantics and a data driven automatic dis-course segmenter that determines the minimal unitsof discourse.ReferencesBuitelaar, P.: CoreLex: Systematic Polysemy and Under-specification.
Ph.D. thesis, Computer Science, Bran-deis University, February 1998.Huong Le Thanh, G. A. and Huyck., C.: Automated dis-course segmentation by syntactic information and cuephrases.
International Conference on Artificial Intelli-gence and Applications, 2004.Kipper, K., H. T. D. and Palmer., M.: Class-based con-struction of a verb lexicon.
AAAI-2000, Proceedingsof the Seventeenth National Conference on ArtificialIntelligence, 2000.Livia Polanyi, Christopher Culy, M. H. v. d. B. G. L. T.and Ahn., D.: Sentential structure and discourse pars-ing.
ACL 2004, Workshop on Discourse Annotation,2004.Marcu, D.: Instructions for Manually Annotating theDiscourse Structures of Texts.
Technical Report, Uni-versity of Southern California, 1999.Marcu, D.: The theory and practice of discourse parsingand summarization.
Cambridge, Massachusetts, Lon-don, England, MIT Press, 2000.Moser, M. G., Moore, J. D., and Glendening, E.: In-structions for Coding Explanations: Identifying Seg-ments, Relations and Minimal Units.
University ofPittsburgh, Department of Computer Science, 1996.Muggleton., S. H.: Inverse entailment and progol.In New Generation Computing Journal, 13:245?286,1995.Rose?, C. P. and Lavie., A.: Balancing robustness and ef-ficiency in unification-augmented context-free parsersfor large practical applications.
In Jean-Clause Junquaand Gertjan van Noord, editors, Robustness in Lan-guage and Speech Technology, 2000.RST-DT.
: Rst discourse treebank.
Linguistic Data Con-sortium., 2002.Sporleder, C. and Lascarides., A.: Exploiting linguisticcues to classify rhetorical relations.
Recent Advancesin Natural Language Processing, 2005.Soricut, R. and Marcu., D.: Sentence level discourseparsing using syntactic and lexical information.
Pro-ceedings of the HLT and NAACL Conference, 2003.Subba, R., Di Eugenio, B., E. T.: Building lexicalresources for princpar, a large coverage parser thatgenerates principled semantic representations.
LREC2006, 2006.Subba, R., Di Eugenio, B., S. N. K.: Learning FOLrules based on rich verb semantic representations toautomatically label rhetorical relations.
EACL 2006,Workshop on Learning Structured Information in Nat-ural Language Applications, 2006.Wellner, B., Pustejovsky, J., C. H. R. S. and Rumshisky.,A.
: Classification of discourse coherence rela-tions: An exploratory study using multiple knowledgesources.
SIGDIAL Workshop on Discourse and Dia-logue, 2006.24
