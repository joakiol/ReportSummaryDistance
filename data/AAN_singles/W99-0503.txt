Supervised Learning of Lexical Semantic Verb ClassesUsing Frequency DistributionsSuzanne StevensonRutgers  Umvers l tysuzanne?cs  ru tgers  eduPaola MerloUmverslty of Genevamerlo?lettres unlge chNatalia KariaevaRutgers Umversltykar laeva@rc l  ru tgers  eduKamin WhitehouseRutgers Umversltykamlnw?rcl rutgers eduAbstractVve zeport a number of computatmnal ex-periments m supervised learning whosegoal Is to automatmally classify a set ofverbs into lexmal semanUc classes, basedon frequency dlstnbutmn approxlmatmnsof grammatical features extracted from avery large annotated corpus DlstnbuUonsof five syntactic features that approximatetranmUvlty alternatmns and thematic roleassignments are sufficient to reduce errorrate by 56% over chance We concludethat corpus data is a usable repository ofverb class mformatmn, and that corpus-driven extraction of grammaUcal featuresIs a promising methodology for automatmlexmal acqum,Uon1 IntroductionRecent years have witnessed a shift in grammar de-velopment methodology, from crafting large gram-mars, to annotation of corpora Correspondingly,there has been a change from developing rule-basedparsers to developing statmUcal methods for reduc-ing grammatmal knowledge from annotated corpusdata The shift has mostly occurred because build-mg w~de-coverage rammars is ume-consummg, er-ror prone, and difficult The same can be said forcrafting the rich lexlcal representatmns that are acentral component of hngmstlc knowledge, and re-search m automaUc lexmal acquisition has soughtto address this ((Doff and Jones, 1996, Dorr, 1997),among others) Yet there have been few attempts tolearn fine-grained lexical classifications from the sta-tlsUcal analysis of dlstnbutmnal data, analogouslyto the induction of syntacUc knowledge (though see,e g ,  (Brent, 1993, Klavans and Chodorow, 1992,Resmk, 1992)) In this paper, we propose such a~approach for the automaUc classfficauon of ~erbsinto lexlcal semantic lasses lWe can express the Issues raised by this apploachas follows1 Whmh hngulstlc dlstmcUons among \[exlcslclasses can we expect to find m a corpus ~2 How easily can we extract he frequency distri-butions that approximate he relevant hngmstlcproperttes?3 Which frequency dlstnbuUons work best to dis-tinguish the verb classes ~In exploring these quesUons, we focus on verb clas-slficaUon for several reasons Verbs are very impor-tant sources of knowledge in many language ngi-neering tasks, and the relationships among verbs ap-pear to play a major role m the orgamzatmn and useof this knowledge Knowledge about verb classes iscrucml for lex,cal acqmsltton m support of languagegeneration and machine translatmn (Dolt, 1997) anddocument cl~sfficatmn (Klavans and Kan, 1998),yet manual classfficauon of large numbers of verbs isa difficult and resource intensive task (Levm, 1993Miller et al, 1990, Dang et a l ,  1998)To address these issues, we suggest hat one cantram an automatic lassffier for verbs on the basts ofstaUstmal approxlmaUons to verb dlatheses We usedlatheses--alternatmns  the expression of the ar-guments of the verb--following Levm and Dorr, fortwo reasons Fnst, verb dlatheses are syntacuc ues1 We are aware that a dlstnbutmnal pproach rests onone strong assumptmn regarding the nature of the repre-sentatmns under study semantic notmns and syntacucnotmns are correlated, at least m part This assurapuonis under debate (Bnscoe and Copestake, 1995, Levm,1993, Dorr and Jones, 1996, Dorr, 1997), but we adopt~t here without further dlscussmn15 ' ?to semantic lasses, hence they can be more easilycaptured by corpus-based techniques Second, usingverb d~atheses reduces no,se There ~s a certain con-sensus (Bnscoe and Copestake, 1995, Pustejovsky,1995, Palmer, 1999) that verb dmtheses are regularsense extensmns Hence focussing on thin type ofclassfficatmn allows one to abstract from the prob-lem of word sense dmamb,guatmn a d treat remduald~fferences m word senses as no~se m the classffica-tmn taskWe present an m-depth case study, m which weapply machine learning techmques to automaUcallyclassify a set of verbs based on d~stnbutmns of gram-maucal indicators of dmtheses, extracted from avery large corpus We look at three very mterest-mg classes of verbs unergaUves, unaccusauves, andobJect-drop verbs (Levm, 1993) These are Interest-mg classes because they all parUcapate m the trans~-uvlty alternatmn, and they are minimal parrs - thatas, a small number of well-defined mtmctmns d~ffer-entmte their trans,tlve/mtranmUve behavmr Thus,we expect the differences m their dmtnbuttons to besmall, entailing a fine-grained lscr,mmaUon taskthat prowdes a challenging testbed for automaticclassfficatmnThe specffic theoretical questmn we mvesUgate ~swhether the factors underlying the verb class dm-tmctmns are reflected m the statmttcal dmtnbutmnsof lex~cal features related to dmtheses presented bythe md,v~dual verbs m the corpus In doing th~s, weaddress the questmns above by determining what arethe lexmal features that could d~stmgmsh t e behav-tor of the classes of verbs w~th respect o the relevantdmtheses, ~hmh of those features can be gleanedfrom the corpus, and which of those, once the sta-Ustmal dmtnbutmns are available, can be used suc-cessfully by an automatic lassifierIn m~ttal work (Stevenson and Merlo, 1999), ~efound that hngmstlcally motivated features that d~s-tmgmsh the verb classes can be extracted from anannotated, and m one case parsed, corpus Thesefeatures are sufficient to almost halve the errorrate compared to chance (45% reductmn) m auto-maUc verb classtficaUon, suggesting that d~stnbu-Uonal data prowdes knowledge useful to the class~-ficaUon of verbs The focus of our original stud~was tho demonstration m prmctple of l~a.nmg verbclasses from frequency d~stnbutmns ofsyntactm fea-tures, and an analysm of the relaUve contrtbutmn ofthe various features to learmng Th~s paper turnsto the nnportant next steps of rephcatmg our find-rags using other training methods and learning al-gorithms, and analyzing the performance on each oftbe three classes of verbs This more detailed anal-ys~s of accuracy within each class m turn leads tothe development of a new dlstrtbutmnal feature m-tended to improve dlscnmmabthty among t~o of theclasses The addltmn of the ne~ feature successfullyreduces the error rate of out mltml results m classl-ficatmn by 19%, for a 56% overall reductmn m errorrate compared to chance2 Determin ing  the  FeaturesIn this sectmn, we present mouvatmn for the mttmlfeatures that we mvesUgated m terms of their rolem learmng the verb classes We first present thehngmstlcally den~ed features then turn to e~tdencefrom experimental psychohngutstlcs to e\tend theset of potentially relevant features2.1 Features  of  the  Velb  ClassesThe three verb classes under mvesugatmn - unerga-Uves, unaccusaUves, and object-drop -differ m theproperties of their translttve/mtranslhve a\[terna-Uons, which are exemphfied belowUnergaUve(la) The horse raced past the barn(lb) The jockey raced the horse past the barnWnaccusatave(2a) The butter melted m the pan(2b) The cook melted the butter m the panObJect-drop(3a) The boy washed the hall(3b) The boy washedThe sentences m (1) use an unergatwe velb.
,accdUnergatlves are mttansluve actmn verbs whose tran-sttlve form is the causattve counterpart of the m-transluve form Thus, the subject of the intransi-tive (la) becomes the object of the translh~e (lb)(Brousseau and Rltter 1991, Hale and ke~set 1993Levm and Rappaport Ho~,av, 1995) The sentencesm (2) use an unaccusaUve verb, melted Lnac-cusatlves are intransitive change of state ~et bs (2a)hke unergauves, the translu~e counterpart for the.,everbs ts also causative (2b) The sentence~ m (3)use an object-dtop verb washed, the~e ','elt:,~ haxe anon-causaU~e tran'~ltl~,e/intransltl~,,e al\[eln?ltton in~ hlch the object is sm~pl~ opttonalBoth unergauves and unaccusatl~es \[la~e acausattve trans~u~e form, but differ m the semanucroles that they assign to the paructpants m the e~entdescribed In an mtranstUve unetgaUve, the ',ubjectts an 4.gent Ithe doer of the e~ent), and m an Intran-sitive unaccusaUve, the subject ts a Theme (~ome-thing affected by the e~ent) The role assignments othe corresponding semanuc arguments of the ttan-s~u~e forms--I e ,  the dnect objects--a~e the ~ame16with the addition of a Causal Agent (the causer ofthe event) as subject in both cases Object-dropverbs simply assign Agent to the subject and Themeto the optional objectWe expect the differing semantic role assignmentsof the verb classes to be reflected m their syntac-tic behavior, and consequently in the distributionaldata we collect from a corpus The three classes canbe characterized by their occurrence in two alter-nations the transittve/mtrans~tive alt rnation andthe causative alternation Unergatives are distin-guished from the other classes m being rare in thetransitive form (see (Stevenson and Merlo, 1997) foran explanation of this fact) Both unergatives andunaccusatives are dlstmgmshed from obJect-drop mbeing causative in their transitive form, and sun-darly we expect this to be reflected in amount ofdetectable causative use Furthermore, since thecaus&tlve is a transitive use, and the transitive use ofunergatlves i expected to be rare, causativity shouldprimarily distinguish unaccusatlves from object-drops In conclusion, we expect he defining featuresof the verb classes--the intransitive/transitive andcausative ~lternatlons--to lead to distributional dif-ferences m the observed usages of the verbs in thesealternations2 2 Psychollngmst~cally Relevant  FeaturesThe verbs under study not only differ in theirthematic properties, they also differ in their pro-cessmg properties Because these verbs can occurboth in a trans~tive and an intransitive form, theyhave been particularly studied in the context of themare verb/reduced relative (MV/I:tR) ambiguity il-lustrated below (Bever, 1970)The horse raced past the barn fellThe verb ~aced can be interpreted as either a pasttense main verb, or as a past participle w~thm a re-duced relative clause (l e , the horse \[that was\] racedpast the barn) Because fell is the main verb, the le-duced relative lnterpretatmn of raced is required fora coherent analysis of the complete sentence Butthe main verb interpretation of raced is so stronglypreferred that people experience great difficulty atthe verb fell, unable to integrate it with the inter-pretation that has been developed to that pointHowever, the reduced relative interpretation is notdifficult for all verbs, as in the follo~mg exampleThe boy washed in the tub was angryThe difference in ease of interpreting the lesolu-tions of this ambiguity has been shown to be sen-sitive to both frequency differentials (MacDonald1994, Trueswell, 1996) and to verb class d~stmctmns(Stevenson and Merlo, 1997, Flhp et al, 1999)Consider the features that d~stmguish t e t~o res-olutions of the M\ , /RR ambiguityMV The horse raced past the barn quicklyRR The horse raced past the barn fellIn the main verb resolution, the ambiguous ~erbraced is used in its intransitive form, while in the re-duced relative, it is used in its transitive, causativeform These features correspond irectly to thedefining alternations of the three verb classes un-der study (intransitive/transitive, causative) ~,ddl-tionally, we see that other related features to theseusages erve to distinguish the two resolutions of theambiguity The mare verb form Is active and a mareverb part-of-speech (labeled as VBD by automaticPOS taggers), by contrast, the reduced relative foimis passive and a past partic~ple (tagged as \ BN)Since these features (active/passive and VBD/VBN)are related to the intransitive/transitive alteination,we expect them to also exhibit d~stributloaal differ-ences among the verb classes Specifically, ~e expectthe unergatives to yield a higher proportion of act~ eand "vBD usage, since, as noted above, the transitiveuse of unergatwes i rare3 Frequency Distributions of theFeaturesWe assume that currently available large cotpoLaare a reasonable approximation to language (Pul-lum, 1996) Using a combined corpus of 65-mllhonwords, we measured the relative frequenc) distribu-tions of the four linguistic features (VBD/~ BN ac-tive/passive, Intransitive/transitive, causative/non-causative) over a sample of verbs from the three lex-tcal semantic lasses3 1 Mater ia l s~e chose a set of 20 verbs from each class based pll-maidy on the classfficatlon of verbs m (Le~ m 1993)(see Appendl~ ~) The uneigatlves ale maanei oImotion verbs The unaccusatl~es ale ~erbs of~haageof state The object-drop verbs are unspecified ob-ject alternation verbs The ~e~bs ~ere sele~Led floraLenin's classes based on their absolute fiequenc}Ful thermore, they do not generally sho~ ma~l~ e de-paitures from the intended verb sense m the cotpu~(Though note that there are only 19 unaccu~atlxesbecause ,zpped, ~hlch ~as initially counted m theunaccusatives, was then excluded from the aaal~-sis as It occurred mostly in a different usage m thecorpus, as a velb plus paltlcle ) Most of the vetb~can occur m the transitive and in the passive Each~erb presents the ~ame folm m the simple pa~t andm the past palticlple In order to smlphf~ the ~ouat-17mg procedure, we made the assumptron that countson this single verb form would approximate he dis-tribution of the features across all forms of the verbMost counts were performed on the tagged versronof the Brown Corpus and on the portion of the WallStreet Journal distmbuted by the ACL/DCI (years1987, 1988, 1989), a combined corpus m excess of65 mdhon words, with the exceptmn of causatrv-lty which was counted only for the 1988 year of theWSJ, a corpus of 29 million words3 2 MethodWe counted the occurrences of each verb token ina transrtlve or mt~ansltr~e use (INTR), m an activeor passive use (ACT), rn a past pamcrple or smaplepast use (VBD), and in a causative or non-causativeuse (CAUS) More precrsely, features were countedas followsINTR a verb occurrence was counted as transrtlveif rmmediately followed by a nominal group, else rtwas counted as mtransitrveACT mare verbs (tagged VBD) were counted asactrve, participles (tagged V BN) counted as actrve ffthe closest preceding auxiliary was have, as passiveff the closest preceding auxiliary was beVBD occurrences tagged VBD were simple past,VBN were past participle(Each of the above three counts was normalizedover all occurrences of the verb, yielding a singlerelative frequency measure for each verb for that fea-ture )CAUS The causative feature was approximated bythe followmg steps Frrst, for each verb, all cooc-currmg subjects and objects were extracted froma parsed corpus (Colhns, 1997) Then the propor-tmn of overlap between the two multrsets of nounswas calculated, meant to capture the causative al-ternation, ~here the subject of the mtransrtrve canoccur as the object of the trans~trve Vve defineoverlap as the largest multiset of elements belong-mg to both the subjects and the object multisets,eg {a,a,a,b}(3 {a} = {a,a,a} The proportronis the ratio between the o~erlap and the sum of thesubject and object multrsets (For example, for therumple sets above, the ratio would be 3/5 or 60 )All ra~ and normahzed corpus data ale a~adablefrom the authors, and more detarl concerning datacollectron can be found m (Stevenson and Merto,1999)4 Exper iments  in  Verb  C lass i f i ca t ionThe frequency drstnbutrons of the verb alternatmnfeatures yield a vector for each verb that representsthe relative frequency values for the verb on eachdrmensron, the set of 59 vectors constrtute the datafor our machine learmng experimentsTemplate \[verb, VBD, ACT, INTR, CADS, class\]Example \[opened, 79, 91, 31, 16, unacc\]Our goal was to determine whether automatm clas-sfficatlon techniques could determine the class of averb from the distributional propertms representedm this vectorIn related work (Stevenson and Merlo, 1999) ~edescribe initial unsupervised and supervised lealnmgexperiments on this data, and discuss the contllbu-tlon of the four different features (the frequenc.~ dis-tributions) to accurac~ m verb classfficatlon In thzspaper, we extend the work in several ~ays Fu~t, ~ereport further analysis of rephcauons of our mmalsupervised learning results Next, we demonstratesrmdar performance using different training methodsand learning algorithms, mdmatmg that the perfor-mance rs Independent of the particular learning ap-proach Furthermore, these addrtronal e~penmentsallow us to evaluate the performance separately oneach of the three verb classes Finally, based on tinsevaluation, we suggest a new feature to better drs-tmgmsh the thematic propertms of the classes, andpresent experimental results howing that its use rm-proves our original accuracy rate4.1 In i tml  Exper imentsImtial experiments were carried out using a decrsrontree induction algorithm, the C5 0 system avadablefrom ht tp / /www rulequest corn/ (Qumlan, 1992),to automatmally create a classfficatron program floraa training set of verb vectois with known classffica-tron 2 In our earhei experiments ~e ran \[0-foldcross-vahdatrons repeated 10 times hele ~e repeatthe ctoss-vahdatrons 50 tmles, and the numbeis te-polted are averages over all the tuns 3Table 1 shows the results of our experiments onthe four features we counted m the corpora (x BDACT, INTR, CAUS), as well as all three-feature subsetsof those four The basehne (chance) performance mth~s task rs 33 8%, since thele are 59 ~ectors and~The s~stem generates both declsmn trees aml rulesets for use m classfficatmn Since the d~fferencc m pet-formance between the t~o zs ne~er s~gmficant ~xe repoKthere Jab the results using the extracted rules The rulesprovide a confidence level foz each classfficatmn ~ hmhIs unavailable with the decmon tree data structure3A 10-fold cross-vahdatmn means that the s~stemrandomly d~vldes the data into 10 parts, and runs 10t~mes on a different 90%-tralmng-data/10%-test_dataspht, ymldmg an average accuracy and standard enorTh~s procedure is then repeated for 50 different randomdlvlsmns of the_ data and accurac3 and standard eIrorare agam averaged across the 50 runs18Features Acc% SE%VBD ACT INTR CAUS 63 7 0 6VBD INTR CAUS 62 7 0 6ACT INTR CAUS 59 9 0 5VBD ACT CAUS 56 8 0 5VBD ACT INTR 54 5 0 5f ,Table 1 Percentage Accuracy (Acc%) and StandardError (SE%) of C5 0 (33 8% baselrne)3 possible classes (That is, assigning one of thetwo most common classes--of 20 verbs each--to allcases would ymld 20 out of 59 correct, or 33 8% ) Asseen m the table, classrficatmn based on the four fea-tures performs at 63 7%, or 30% over chance Thetrue mean of the sample cross-vahdatlons lies wd, hmplus or remus two standard errors of the reportedmean (dr=49, t=2 01, p< 05) In all cases, the rangeis plus or mmus I0  or 12, yreldmg a very nat-row predrcted accuracy range Furthermore, we per-formed t-tests comparing the results of the 50 cross-vahdatmns for each of the different feature subsetsAll pairs were srgmficantly different (p< 05) exceptfor the results using all four features (first row m thetable) and those excluding ACT (second row m thetable) We conclude that all features except ACTcontribute posrtlvely to classrficatmn performance,and that ACT does not degrade performance In ourrephcatrons, then, we focus on all four features4 2 Rephcatmn wi th  Di f ferent  T ra in ing  andLearn ing  MethodsThere are conceptual and practical reasons for in-vestigating the performance of other training ap-proaches and learning algorithms applied to our verbdistribution data Conceptually, it is desrrable toknow whether a particular learning algorithm ortraining techmque affects the level of performancePractically, drfferent methods enable us to evalu-ate more easily the performance of the classificationmethod within each verb class (When we run re-peated cross-validations with t keg.C5 0..system, wedon't have access to the accuracy rage for each class,the system only outputs an overall mean error rate )To preview, we find that the different raining andlearning methods we tried all, gave similar perfor-mance to our original results, and m addltron al-lowed us to evaluate the accuracy wlthrn each verbclassIn one set of experiments, we used the same C5 0system, but employed a training and testing method-ology that used a single hold-out case We heldout a single verb vector, trained on the remaining,58 cases, then tested the resulting classffier on theII Classes\[\[ All ClassesI Unergatv~eUnaccusatweI ObjectDropPercent ~ccuracy61 075 057 950 0Table 2 Percentage Accuracy of C5 0 With SingleHold-Out Trainingsingle hold-out case, and recorded the collect andassigned classes for that verb Tius was then ze-peated for each of the 59 verbs This approach ~raidsboth an overall accuracy rate (when the results areaveraged across all 59 trials), as well as pio~ldmgthe data necessary for determining accuracy fol eachverb class (because we have the classification of eachverb when It is the test case) The results ale pre-sented m Table 2 The overall accuracy IS a little lessthan that achieved with the 10-fold cross-validationmethodology (61 0% versus 63 7%) However, wecan see clearly now that the unergatlve verbs atedassffied with much greater accuracy (75%), Mulethe unaccusatwe and obJect-drop verbs are classifiedwith much lower accuracy (57 9% and 50% respec-trvely) The distributional features we have appearto be much better at dmtmgmshmg unergatwes thanunaccusatlve or obJect-drop verbsTo test thrs drrectly under our original t iammgassumptrons, we ran two different experiments, u~-mg 10-fold cross-vahdation repeated 10 time~ Thefirst experiment tested the abdit:~ of the classifier todistinguish between unergatlves and the other t~overb types, wrthout having to distinguish bct~eenthe latter two The data included the 20 unerga-rive ,,erbs and a random sample of 10 unaccusataveand 10 obJect-drop verbs, 10 different random ~am-pies were selected to form 10 such data sets Inthese data sets, the ~erbs were labeled as unerga-tire or "of;her" The baseline (chance) classzficatmnaccuracy for this data is 50%, the mean accmac~achmved across all data sets was 78 5% (standard el-lot 0 8%), a srzable improvement o~er chance Thesecond expeim~ent ~as intended to det, etmme ho~well the classifier can dlstmgm~h.unaccusatl~e fromobject-drop verbs The data consisted of one ~etthat included all the unaccusative and object-dropverbs, with no unergatives Because there ate onlyi9 unaceusauve verbs, the basehne accuracy late is51% (20/39), here the classifier achieved an accuracyonly slightly above chance, at 58 3% (standard elror1 8%) These results, summarized in Table 3 clearlyconfirm the higher accuracy of classifying uneigatlvoverbs with the current feature setThis pattern of results ~as repeated under a ~oi319Classes Acc% SE% \[IUnergatlve vs Other 78 5 0 8 \]Unaccusatlve vs ObjectDrop 58 3 1 8 ITable 3 Percentage Accuracy (Ace%) and StandardError (SE%) of C5 0 (50-51% baseline)II Cl es \[PCA%\[ FMP% II\[l All Classes \[ 65 0 1 63 9 IIUnergatlve 85 0 71 7Unaccusative 60 0 55 0ObjectDrop 50 0 65 0Table 4 Percentage Accuracy of PCA (PCA%) andFeature Map (FMP%) Neural Networksdifferent ype of learning algorithm as well We per-formed a set of neural network experiments, usingNeuroSolutlons 3 0 (see ht tp / /www nd corn), andreport here on the networks that achieve the bestperformance on our data These are principal com-ponents analysis and automatic feature map net-works, which are essentially feed-forward percep-trons with pre-processmg units that transform theexisting features rata a more useful format In ourtests, both methods performed best overall whenthere were no hidden layer units, and the networkswere trained for 1000 epochs The mean accuracyrates of 10-fold cross-validations with these param-eter settings are summarized in Table 4 Again, theoverall percentage accuracy is in the low sixties, withbetter performance on the unergattves than on theother two verb classes, the difference was particu-larly striking with the PCA networks This overallpattern doesn't change with further training, in fact,training up to 10,000 epochs resulted in very lowaccuracy (of 45%) for either unaccusatives, object-drops, or bothTo summarize, following a different training ap-proach with C5 0 (the single hold-out method), andapplying very different learning approaches (twokinds of neural networks), resulted in mmllai o~er-all performance to our original C5 0 results Thisindicates that the accurac3 achieved is at lea.stsomewhat independent of specific learning or train-Ing techniques Moreover, these different methods,along with experiments directly testing unergativeversus unaccusatlve/object-drop classification, allowus to examine more closely where the resulting clas-sifters have the most serious problems In all cases,the accuracy is best for unergattves, and the accu-racy of unaccusatives, object-drops, or both, is de-graded If this performance is indeed a reliable mdi-ClassesUnerg vs UnaccUaerg vs ObjDropUnacc vs ObjDropI vBo I AcT I INTR I CAI'S IIns  ns  ** **** p< 001** p< 01* p_< 05as non-significantTable 5 Significance Levels of T-Tests ComparingFeature Values Between Verb Classescation of the inherent dtscnmmabd~ty of tile dastn-butlonal data, then we must examine more closelythe properties of the data itself to understand (andpotentially improve) the performance4 3 Dsscr lmmatmg Unaccusat ive  andOb Ject -Drop  VerbsTo understand why the data discriminates unerga-ttves reasonably well, but not unaccusatlves andobject-drops, we need to directly test the discnm-inabil ityof the features across the classes We do soby using t-tests to compare the values of the differ-ent features--VBD, ACT, INTR., CAUS--for unergattveand unaccusattve verbs, unergatlve and object-dropverbs, and unaccusatlve and object-drop verbs Ineach case, the t-test is giving the likelihood that thetwo sets of values--e g ,  the VBD feature values forunergatives and for unaccusatives--are dra~n fromdifferent populations Table 5 shows that all sets offeatures are significantly different for unergatlve andunaccusattve verbs, and for unergattve and object-drop verbs Ho~ever, only INTR.
and CAUS ate slg-mficantly different for unaccusattve and object-dtopverbs, indicating that we need additional featulesthat have different values across these two classesIn Section 2 1, we noted the differing semantic roleasmgnments for the verb classes, and hypothesizedthat these differences would affect the expression ofsyntactic features that ate countable in a corpusFor example, the c ~bs feature approximates sen\]an-tic role reformation b.~ encoding the oxerlap beh~eennouns that can occur m the ~ubject and object po-sitions of a cau~ative xetb Here x~e suggest anotherfeature, that of ammacy of subject, that is intendedto distinguish nouns that receive an Agent role florathose that receive a Theme role Recall that object-drop verbs assign Agent to their subject in both thetransitive and intransitive alternations, while unac-cusattves assign Agent to their subject only in thetransitive, and Theme m the intransitive We expectthen that object-drop verbs will occur more oftenwith an animate subject Note again that ~e are20II Features \[Acc% SE% III VBD ACT INTR CAUS I 63 7 0 6 \]VBD ACT INTR CAUS PRO 70 7 0 4Table 6 Percentage Accuracy (Acc%) and StandardError (SE%) of C5 0, W~th and W~thout New PROFeature, All Verb Classes (33 8% basehne)making use of frequency dmtnbutmns--the clatm ~snot that only Agents can be ammate, but rather thatnouns that receive the Agent role will more often beammate than nouns that receive the Theme roleA problem w~th a feature hke ammacy ~s that ~trequires etther manual determmatmn of the antmacyof extracted subjects, or reference to an on-hne re-source such as WordNet for determining ammacyTo approximate ammacy w~th a feature that can beextracted automatically, and w~thout reference to aresource external to the corpus, we instead countpronouns (other than ~t) m subject positron Theassumptmn ~s that the words I, we, you, she, he,and they most often refer to ammate ent~tms Thevalues for the new feature, P~.O, were determinedby automatmally extracting all subject/verb tuplesincluding our 59 examples verbs (from the WSJ88parsed corpus), and computing the ratm of occur-rences of pronouns to all subjectsWe again apply t-tests to our new data to deter-mine whether the sets of PRo values d~ffer acrossthe verb classes Interestingly, we find that the Prtovalues for unaccusat~ve rbs (the only class to as-s~gn Theme role to the sub tect m one of tts alterna-tmns) are s~gmficantly dtffe~ent from those for bothunergatlve and object-drop verbs (p< 05) More-over, the PRo values for unergat~ve and object-dropverbs (whose subjects are Agents m bo~h alterna-tmns) are not s~gmficantly d~fferent Th~s patternconfirms the abd~ty of the feature to capture thethematm d~stmctmn between unaccusat~ve rbs andthe other two classesTable 6 shows the result of applying C5 0 (10-foldeross-vahdatmn repeated 50 t~mes) to the three-x~ayclassfficatmn task using the PRo feature m conjunc-tmn w~th the four previous features ~.ccuracy ran-proves to over 70%, a teductmn m the error rate ofalmost 20% due to th~s single nex~ feature Mote-over, classifying the unaccusat~ve an2 object-dropverbs using the new feature m conjunctmn w~th theprevmus four leads to accuracy of over 68% (com-pared to 58% w~thout PRo) We conclude that thisfeature ~s ~mportant in d~stmgmshlng unaccusat~veand object-drop verbs, and hkely contributes to thetmprovement m the three-way classtficatton becauseof th~s Future work wdl examine the performancew~thm the verb classes of th~s new set of features tosee whether accuracy has also tmproved for unerga-tire verbs5 ConclusionsIn thin paper, we have presented an m-depth casestudy, m whmh we investigate varmus machine learn-mg techmques to automatically classify a set ofverbs, based on dlstnbutmnal features extractedfrom a very large corpus Results show that a smallnumber of hngmstlcally motivated grammatical fea-tures are sufficmnt o reduce the error rate by motethan 50% over chance, acluevmg a 70% acctuacyrate m a three-way classfficatmn task Tins leadsus to conclude that corpus data is a usable reposi-tory of verb class mformatmn On one hand ~e ob-serve that semantlc propemes of verb classes (suchas causatlvlty, or ammacy of subject) may be use-fully approximated through countable syntactic fea-tures Even with some noise, lexmal propertms arereflected m the corpus robustly enough to positivelycontribute m classlficatmn On the other hand, how-ever, we remark that deep hngumtm analysis cannotbe ehmmated- -m our approach, it is embedded mthe selection of the features to count We also thinkthat using hngumtlcally motivated features makesthe approach very effective and easdy scalable wereport a 56% reductmn m error rate, w~th only fivefeatures that are relatwely straightforward tocountAcknowledgementsThis research was partly sponsored by the S~ lss Na-tmnal Scmnce Foundatmn, under fello~slup 8210-46569 to Paola Merlo, by the US Natmnal ScmnceFoundatmn, under grants #9702331 and #9818322to $uzanne Stevenson, and by the Infotmatton Sci-ences Councd of Rutgers Umverslty ~,~,e thankMartha Palmer for getting us started on tlus ~orkand Mmhael Colhns for gwmg us access to the out-put of his parser We gratefully acknowledge thehelp of Ixlva Dickinson, ~ho calculated no~mahza-tmns of the corpus dataAppend ix  AThe une~gatx~es are manner of morton ~erbs jumptdrushed, malched, leaped floated, laced, huslwd uan-dered, vaulted, paraded, galloped, gl,ded, hzked hoppedjogged, scooted, ncurlzed, ~kzpped, hptoed, trottedThe unaccusau~es are verbs of change of stateopened, exploded, flooded, dzs~olved, cracked, hardenedbozled, melted, .fractured, ,ol,dzfied, collapsed cooledfolded, w~dened, changed, clealed, dzwded, ~,mmeredstabdzzedThe object-dlop verbs are unspecffied object altel-natron verbs played, painted, k,cked, carved, reaped,washed, danced, yelled, typed, kmtted bolrowed mhet-21tted, organtzed, rented, sketched, cleaned, packed, stud-ted, swallowed, calledReferencesThomas G Bever 1970 The cogmtwe basis for hngms-tlc structure In J R Hayes, e&tor, Cognttson andthe Development of Language John Wdey, New YorkMichael Brent 1993 From grammar to le~con Un-supervmed learmng of \[ex~cal syntax ComputationalLinguistics, 19(2) 243-262Edward Bnscoe and Ann Copestake 1995 Lex~cal rulesm the TDFS framework Techmcal report, Acquflex-I I Working" PapersAnne-Marm Brousseau and Ehzabeth R~tter 1991 Anon-umfied analysis of agent~ve verbs In West CoastConference on Formal Lmgutstzcs, number 20, pages53-64M~chael John Colhns 1997 Three generaUve, lexa-cahsed models for statistical parsmg In Proc of the~5th Annual Meeting of the ACL, pages 16-23Hoa Trang Dang, Kann K~pper, Martha Palmer, andJoseph Rosenzwe~g 1998 Investtgatmg regular senseextenmons based on mteresecttve Levm classes InProc of the 361h Annual Meeting of the ACL andthe 171h \[nternatwnal Conference on ComputatwnalL,ngu,st,cs (COLING-A CL '98), pages 293-299, Mon-treal, Canada Umvers~t6 de MontrealBonme Dorr and Doug Jones 1996 Role of word sensed~samb~guatmn  lexacal acqms~tmn Predmtmg se-mantics from syntactic ues In Proc of the 161h In-ternattonal Conference on Computat*onal Lmgutsttcs,pages 322-327, Copenhagen, DenmarkBonnie Dorr 1997 Large-scale chctmnary constructmnfor foreign language tutonng and mterhngual machinetranslatmn Machine Translatton, 12 1-55Hana Fd~p M~chael Tanenhaus, Greg Carlson, Paul AI-lopenna, and Joshua Blatt 1999 Reduced rela-tives judged hard require constraint-based analysesIn P Merlo and S Stevenson, echtors, Sentence Pro-cessmg and the Lextcon Formal, Computational, andEzpertmental Perspectives, John Benjamms, HollandKen Hale and Jay Keyser 1993 On argument struc-ture and the lexacal representatmn of s:~ ntact~c rela-tmns In K Hale and J Keyser, editors, The t',ewfrom Budding ~0, pages 53-110 MIT PressJuchth L Ixlavans and Martin Chodorow 1992 De-grees of stat~vlty The lexacal representatmn of verbaspect In Proceedmg~ ofthe Fourteenth InternationalConference on Computahonal Lmgmst,csJuchth Ixlavans and Mm-Yen Kan 1998 Role of ~erbsm document analysis In Proc of the 361h AnnualMeeting of the ACL and the 171h \[nternatzonal Con-ference on Computational Lmgutsttcs ( C O L L'v G- 4 C L'98), pages 680-686, Montreal, Canada Umvers~te deMontrealBeth Levm and/Vlalka Rappapti(t'Hovav 1995 (Jnac-cusatwlty MIT Press, Cambridge, MABeth Le~m 1993 Enghsh Verb Clas~e~ and 4lterna-twns Chacago Umvers~ty Press, Chicago, ILMaryellen C MacDonald 1994 Probablhstlc con-stramts and syntactic amblgtuty resolution Languageand Cognltzve Processes, 9(2) 157-201Paola Merlo and Suzanne Stevenson 1998 What gram-mars tell us about corpora the case of reduced rela-tive clauses In P1oceedmgs of the Slzth Workshop onVery Large Corpora, pages 134-142, Montreal, CAGeorge Miller, R Beckw~th, C Fellbaum, D Gross, andIx I~hller 1990 Fwe papers on Wordnet Techmcalreport, Cogmtzve Scmnce Lab, Princeton Ual~erstt~Martha Palmer 1999 Coasmtent criteria for sense dis-tmctmns Computmg \]or the HamamttesFernando Perelra, Naftah Tlshby, and Ldhan Lee 1993Dlstrabutmnal clustering of enghsh words \[n Proc ofthe 31th 4nnual Meeting of the 4CL, pages 183-190Fernando Perexra, Ido Dagan, and Lalhan Lee 1997Slmdanty-based methods for word sense dlsamblgua-tmn In Proc of the 35th Annual Meeting of the4 CL and the 8th Conf of the E 4 CL (A CL/EA CL '97)pages 56 -63Geoffrey K Pullum 1996 Learnabthty, hyperlearn-rag, and the poverty of the sttmulus In Jan John-son, Matthew L Jute, and Jen L Moxley, editors,~nd Annual Meeting of the Berkeley Lmgutstzcs So-ctety General Sesston and Parasesswn on the Role ofLearnabdzty m Grammatzcal Theory, pages 498-513,Berkeley, Cahforma Berkeley Linguistics SocmtyJames Pustejovsky 1995 The Generatwe Lexicon MITPressJ Ross Qumlan 1992 C$ 5 Programs fo~ MachineLearning Series m Machme Learning Morgan Ixauf-mann, San Mateo, C 4.Phdlp Resnik 1992 Vv'ordnet and dmtnbutmnal anal-ysis a class-based approach to lex~cal dlsco~er~In 4 44 I  Workshop m Statz~tzcally-ba~ed NLP Tech-ntqu_e~, pages 56-64Doug Roland and Dan Juxafsk:~ 1998 How ~ed~ subcat-egonzatmn fiequencms are affected b~ corpu~ choiceIn Proc of the ~6th 4nnual I\[eetmg of the 4CL, \Ion-treal, CASuzanne Stevenson and Paola \lerlo 1997 Lexlcalstructure and parsing comple~lt~ Language and ('og-mtwe Proce~e~, 12(2/3) 3t9-399Suzarme Stevenson and Paola Merlo 1999 4.utomaucverb classfficatton using distmbutmns of grammaticalfeatures In Proc of the 9th Conference of the Eu-ropean Chapter of the A CL, Bergen, Norway, pages45-52John Trueswell 1996 The role of lexlcal frequencym syntacuc amblgmty resolutmn J of Memory andLanguage, 35 566-585
