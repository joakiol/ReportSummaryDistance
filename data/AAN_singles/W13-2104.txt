Proceedings of the 14th European Workshop on Natural Language Generation, pages 30?39,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsEnhancing the Expression of Contrastin the SPaRKy Restaurant CorpusDavid M. Howcroft and Crystal Nakatsu and Michael WhiteDepartment of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USA{howcroft,cnakatsu,mwhite}@ling.osu.eduAbstractWe show that Nakatsu & White?s (2010)proposed enhancements to the SPaRKyRestaurant Corpus (SRC; Walker et al2007) for better expressing contrast do in-deed make it possible to generate bettertexts, including ones that make effectiveand varied use of contrastive connectivesand discourse adverbials.
After first pre-senting a validation experiment for natu-ralness ratings of SRC texts gathered usingAmazon?s Mechanical Turk, we presentan initial experiment suggesting that suchratings can be used to train a realizationranker that enables higher-rated texts to beselected when the ranker is trained on asample of generated restaurant recommen-dations with the contrast enhancementsthan without them.
We conclude with adiscussion of possible ways of improvingthe ranker in future work.1 IntroductionTo lessen the need for handcrafting in developinggeneration systems, Walker et al(2007) extendedthe overgenerate-and-rank methodology (Langk-ilde and Knight, 1998; Mellish et al 1998; Walkeret al 2002; Nakatsu and White, 2006) to complexinformation presentation tasks involving variationin rhetorical structure.
They illustrated their ap-proach by developing SPaRKy (Sentence Planningwith Rhetorical Knowledge), a sentence plannerfor generating restaurant recommendations andcomparisons in the context of the MATCH (Mul-timodal Access To City Help) system (Walker etal., 2004), and showed that SPaRKY can producetexts comparable to those of MATCH?s template-based generator.Despite the evident importance of expressingcontrast clearly in making comparisons amongrestaurants, Nakatsu (2008) surprisingly foundthat most of the examples involving contrastiveconnectives in the SPaRKy Restaurant Corpus(SRC) received low ratings by the human judges.Even though the low ratings were not necessarilydirectly attributable to the use of a contrastive con-nective in many cases, Nakatsu conjectured thatthe large proportion of low-rated examples con-taining contrastive connectives would make it dif-ficult to train a ranker to learn to use contrastiveconnectives effectively without augmenting thecorpus with better examples of contrast.
Sub-sequently, Nakatsu and White (2010) proposeda set of enhancements to the SRC intended tobetter express contrast?including ones employ-ing multiple connectives in the same clause thatare problematic for RST (Mann and Thompson,1988)?and showed how they could be generatedwith Discourse Combinatory Categorial Grammar(DCCG), an extension of CCG (Steedman, 2000)designed to enable multi-sentence grammar-basedgeneration.
However, Nakatsu and White did notevaluate empirically whether these contrast en-hancements were successful.In this paper, we show that Nakatsu &White?s (2010) proposed SRC contrast enhance-ments do indeed make it possible to generate bet-ter texts: in particular, we present an initial ex-periment that shows that the oracle best restau-rant recommendations including the contrast en-hancements have significantly higher human rat-ings for naturalness than comparable texts withoutthese enhancements, and which suggests that evena basic n-gram ranker trained on the enhancedrecommendations can select texts with higher rat-ings.
The paper is structured as follows.
InSection 2, we review Nakatsu & White?s pro-posed enhancements to the SRC for better express-ing contrast?including the use of structural con-nectives together with discourse adverbials?andhow they can be generated with DCCG.
In Sec-30tion 3, we first present a validation experimentshowing that naturalness ratings gathered on Ama-zon?s Mechanical Turk (AMT) are comparable tothose for the same texts in the original SRC; then,we present our method of generating and selectinga sample of new restaurant recommendation textswith and without the contrast enhancements forrating on AMT.
In Section 4, we describe how wetrained discriminative n-gram rankers using crossvalidation on the gathered ratings.
In Section 5,we present the oracle and cross validation resultsin terms of mean scores of the top-ranked text.
InSection 6, we analyze how the individual contrastenhancements affected the naturalness ratings anddiscuss issues that may be still hampering natu-ralness.
Finally, in Section 7, we conclude witha summary and a discussion of possible ways ofcreating improved rankers in future work.2 Enhancing Contrast with DiscourseCombinatory Categorial GrammarFigure 1 (Nakatsu, 2008) shows examples fromthe SRC where some of the SPaRKy realizationsare clearly more natural than others.
In Nakatsu?sexperiments, she found that the use of contrastiveconnectives was negatively correlated with humanratings, and that an n-gram ranker learned to dis-prefer texts containing these connectives.
In an-alyzing these unexpected results, Nakatsu notedtwo factors that appeared to hamper the natural-ness of the contrastive connective usage.
First,consistent with Grote et als (1995) observationthat however and on the other hand (unlike but andwhile) signal that the clause they attach to is themore important one, we might expect realizationsto be preferred when these connectives appearwith the more desirable of the contrasted qualities.Such preferences do indeed appear to be presentin the SRC: for example, in Figure 1, alts 8 &13?where the better property is ordered second?are rated highly, while alts 7 & 11?where thebetter property is ordered first?are rated poorly.Nakatsu further observed that in human-authoredcomparisons, when the second clause expressesthe lesser property, it is often qualified by onlyor just; consistent with this observation, alts 7 &11 do seem to improve with the inclusion of thesemodifiers.The second factor noted by Nakatsu that maycontribute to the awkwardness of however and onthe other hand is that both of these connectivesseem to be rather ?grand?
for the rather simplecontrasts in Figure 1, and may sound more natu-ral when used with heavier arguments.Based on these observations, Nakatsu andWhite (2010) proposed a set of enhancements tothe SRC, all of which are exemplified in Figure 2.1The enhancements include (i) optional summarystatements that give an overall assessment of eachrestaurant based on the average of their propertyvalues, thereby allowing contrasts to be expressedover larger text spans; (ii) adverbial modifiersonly, just and merely to express a lesser value ofa given property than one mentioned earlier;2(iii)the modifers also and too to signal the repetitionof the same value for a given property (Strieg-nitz, 2004); and (iv) contrastive connectives fordifferent properties of the same restaurant, exem-plified here by the contrast between decent decorand mediocre food quality for Bienvenue.In the text plan in Figure 2, <1>?<4> cor-respond to the propositions in the original SRCtext plan and (1?)?(2?)
are the new summary-levelpropositions.
Following Webber et al(2003),Nakatsu and White (2010) take only, merely, just,also, and too to be discourse adverbials, whosediscourse relations are allowed to cut across theprimary tree structure established by the other re-lations in the figure.
Note that in addition to go-ing beyond RST?s limitation to tree-structured dis-courses, the example also contains clauses em-ploying multiple discourse connectives, where oneis a structural connective (such as however orwhile) and the other is a discourse adverbial.To realize such texts, Nakatsu & White intro-duce Discourse Combinatory Categorial Grammar(DCCG), an extension of CCG (Steedman, 2000)to the discourse level.
DCCG follows DiscourseLexicalized Tree Adjoining Grammar (Webber,2004) in providing a lexicalized treatment of struc-tural connectives and discourse adverbials, but dif-fers in doing so in a single CCG, rather than sep-arate sentence-level and discourse-level grammarswhose interaction is not straightforward.
As such,DCCG requires no changes to the OpenCCG real-izer (White, 2006b; White, 2006a; White and Ra-1In the text, words intended to help indicate similaritiesand contrasts are italicized.
Note that we have added overalland on the whole to the summary statements to better indicatetheir summarizing role.2The second value must be a less extreme one on the sameside of the scale; in principle, it could be merely poor ratherthan horrible, but such low attribute values did not occur inthe corpus.31Strategy Alt # Rating Rank Realization3 3 7 Sonia Rose has very good decor but Bienvenue has decent decor.7 1 16 Sonia Rose has very good decor.
On the other hand, Bienvenue has decent decor.8 4.5 13 Bienvenue has decent decor.
Sonia Rose, on the other hand, has very good decor.C2 10 4.5 5 Bienvenue has decent decor but Sonia Rose has very good decor.11 1 12 Sonia Rose has very good decor.
However, Bienvenue has decent decor.13 5 14 Bienvenue has decent decor.
However, Sonia Rose has very good decor.14 5 3 Sonia Rose has very good decor while Bienvenue has decent decor.15 4 4 Bienvenue has decent decor while Sonia Rose has very good decor.17 1 15 Bienvenue?s price is 35 dollars.
Sonia Rose?s price, however, is 51 dollars.
Bienvenue has decent decor.However, Sonia Rose has very good decor.Figure 1: Some alternative [Alt] realizations of SPaRKy sentence plans from a COMPARE-2 [C2] plan, with averagedhuman ratings [Rating] (5 = highest rating) and ranks assigned by the n-gram ranker [Rank] (1 = top ranked).tion, the SPaRKy sentence plan generator adds theINFER relation to assertions whose relations werenot specified by the content planner.During the sentence planning phase, SPaRKy or-ders the clauses and combines them using randomlyselected clause-combining operations.
During thisprocess, a clause-combining operation may insert 1of 7 connectives according to the RST relation thatholds between two discourse units (i.e.
insertingsince or because for a JUSTIFY relation; and, how-ever, on the other hand, while, or but for a CON-TRAST relation; or and for an INFER relation).After each sentence plan is generated, it is real-ized by the RealPro surface realizer and the result-ing realization is rated by two judges on a scale of1-5, where 5 is highly preferred.
These ratings arethen averaged, producing a range of 9 possible rat-ings from {1, 1.5, ..., 5}.2.2 Ratings/Connectives CorrelationFrom the ratings of the examples in Figure 1, wecan see that some of the SPaRKy sentence plan re-alizations seem more natural than others.
Upon fur-ther analysis, we noticed that utterances containingmany contrastive connectives seemed less preferredthan those with fewer or no contrastive connectives.To quantify this observation, we calculated the av-erage number of connectives (aveci) used per real-ization with rating i, using aveci= Totalci/Nri,where Totalciis the total number of connectives inrealizations with rating i, and Nriis the number ofrealizations with rating i.We use Pearson?s r to calculate each correlation(in each case, df = 7).
For both COMPARE strategies(represented in Figure 2(a) and 2(b)), we find a sig-nificant negative correlation for the average numberof connectives used in realizations with a given rat-ing (C2: r =  0.97, p < 0.01; and C3: r =  0.93,p < 0.01).
These correlations indicate that judges?ratings decreased as the average frequency of theconnectives increased.Further analysis of the individual correlationsused in the comparative strategies show that there isa significant negative correlation for however (C2:r =  0.91, p < 0.01; and C3: r =  0.86,p < 0.01) and on the other hand (C2: r =  0.89,p < 0.01; and C3: r =  0.84, p < 0.01) in bothCOMPARE strategies.
In addition, in COMPARE-3,the frequencies of while and but are also signifi-cantly and strongly negatively correlated with thejudges?
ratings (r =  0.86, p < 0.01 and r = 0.90, p < 0.01, respectively), though there is nosuch correlation between the use of these connec-tives and their ratings in COMPARE-2.Added together, all the contrastive connectivesshow strong, significant negative correlations be-tween their average frequencies and judges?
ratingsfor both comparative strategies (C2: r =  0.93,p < 0.01; C3:r =  0.88, p < 0.01).Interestingly, unlike in the COMPARE strategies,there is a positive correlation (r = 0.73, p > 0.05)between the judges?
ratings and the average fre-quency of all connectives used in the RECOMMENDstrategy (see Figure 2(c)).
Since this strategy onlyuses and, since, and because and does not utilize anycontrastive connectives, this gives further evidencethat only contrastive connectives are dispreferred.2.3 N-gram Ranker and FeaturesTo acertain whether these contrastive connectivesare being learned by the ranker, we re-implementedthe n-gram ranker using SVM-light (Joachims,77Figure 1: Some alternative (Alt) realizatio s of SPaRKy se tence plans from a COMPARE2 (C2) plan,with averaged human ratings (Rating; 5 = highest rating) and ranks (Rank; 1 = top ranked) assigned byan n-gram ranker (Nakatsu, 2008)Generating with Discourse Combinatory Categorial Grammar / 53contrastgggggggggggggggggWWWWWWWWWWWWWWWWWevidencelllllllllLLLLLLLevidencelllllllllLLLLLLLnucleus:(1?)assert-summary(mod:good)inferoooooooOOOOOOOOnucleus:(2?
)assert-summary(mod:mediocre){infer|contrast}ooooooooOOOOOOOOnucleus:<1>assert-com-decor(mod:decent)nucleus:<3>assert-com-food-quality (mod:very good)YYnucleus:<2>assert-com-decor(mod:decent)nucleus:<4>assert-com-food-quality (mod:mediocre)bb bbmerelyadditivemerelyFIGURE 31 SPaRKy tp-tree altered with new relations and summarystatements, corresponding to Example 50.in bold font.
Lastly, the connectives also and only, which represent theadditional relatio s, additive and merely, respectively, are indicatedin small caps.
(50) (1?
): Soni Ros is a good restaurant.<1>: It has decent decor and<3>: very good food quality.(2?
): However, Bienvenue is just a mediocre restaurant.<2>: While it also has decent decor,<4>: it only has mediocre food quality.7 Related WorkIn terms of its discourse theoretical basis, DCCG is most closely re-lated to D-LTAG.
In general, as Webber (2006) observes, discoursegrammars vary in their theoretical style, from wholly based on de-pendency relations (e.g.
Halliday and Hasan 1976) to adherence to acompletely constituent-based model (e.g.
Rhetorical Structure Theory[RST], Mann and Thompson 1988; Linguistic Discourse Model, Polanyi1988, Polanyi and van den Berg 1996).
Dependency-based discoursetheories are advantageous because they allow discourse relations to ex-ist between non-adjacent discourse units, lifting restrictions on whichclauses can serve as discourse arguments of a given relation.
Compu-(1?
): Sonia Rose is a good restaurant overall.<1>: It has decent decor and<3>: very good food quality.(2?
): However, Bienvenue is just a mediocrerestaurant on the whole.<2>: While it also has decent decor,<4>: it only has mediocre food quality.Figure 2: Modified SPaRKy text plan for text with new relations and summary statements intended toenhance contrast (Nakatsu and White, 2010)32Generating with Discourse Combinatory Categorial Grammar / 25ot1h, A. however, B. otoh, C. however, D.tsot1htshowevertsotohtshoweverTC TCtsCUE\?tsCUEtsCUE\?tsCUE< <tsot1htsotohTCtsnil/?tsotoh>tsnilTCturnnilFIGURE 16 A DCCG derivation of nested contrast relationsReturning now to the intrasentential conjunctions that express con-trast, their categories remain the same as in the preceding section, ex-cept for the addition of the requirement that they combine with clauseshaving nil values for the cue feature:(39) a.
{while, but } ` se,nil\?se1,nil\?punc,/?se2,nil:@e(contrast-rel ^ hArg1ie1^ hArg2ie2)b. while ` se,nil/?se2,nil/?punc,/?se1,nil:@e(contrast-rel ^ hArg1ie1^ hArg2ie2)Since these categories do not need to look outside the sentence to findboth of their discourse arguments, they do not change the cue valuesof their result categories.To conclude this section, we address the question of whether it is anecessary move to employ unary type-changing rules in order to handleintersentential discourse connectives in CCG.
As noted in the precedingsection, the lexicalized categories for connectives o?ered therein suggestthat there is no problem in principle with devising a purely lexicalizedapproach to discourse connectives; accordingly, the cue threading ap-proach presented in this section appears to yield grammars with cov-erage equivalent to purely lexicalized alternatives.
Nevertheless, as wehave seen, the purely lexicalized approach leads to a proliferation of lex-ical category ambiguity, and while lexical rules might be employed tosystematically assign the necessary lexical categories, the cue threadingapproach is clearly more economical.
Similar considerations led Hock-enmaier and Steedman (2002, 2007) to make extensive use of type-changing rules in their broad coverage grammar of English, indicatingthat such rules have an important role to play in practical grammars.Hockenmaier and Steedman further argued that the formal power ofthe system is una?ected as long as (i) only a finite number of unaryrules are employed and (ii) the rules are designed so that they cannotrecursively apply to their own output, as is the case here.Figure 3: DCCG derivation of nested contrast re-lations (Nakatsu and White, 2010)26 / LiLT volume 4, issue 1 September 2010it also as poor decornp sCUE\np/?
(sCUE\np) snil\npnom>snil\npnom<snilFIGURE 17 A DCCG derivation of a clause including the discourseadverbial also.5.3 Discourse Adverbials and Anaphora ResolutionUnlike structural connectives, which find their discourse arguments viacue threading, discourse adverbials find one argument syntactically,and the other through anaphora resolution.
To illustrate how DCCGaccomplishes this, consider (1) from Section 2, repeated below:(1) b1: Bienven e is a mediocre restaurant.h1: It has poor decor and mediocre food quality.b3: However, Sonia Rose is a good restaurant.h2: While it also has poor decor,h3: it has excellent food quality.As illustrated by the derivation of the clause for h2in Figure 17, the pre-verbal modifier category for also in (40c) below takes a VP categoryse,CUE\np as its argument and returns a VP category as its result,adding an additive relation to the semantics.
(40) a. also ` se,CUE/?se,CUE/?punc,:@e(hModi(a ^ additive-rel ^ hArg1ie1))b. also ` se,CUE\?se,CUE\?punc,:@e(hModi(a ^ additive-rel ^ hArg1ie1))c. also ` se,CUE\np/?
(se,CUE\np) :@e(hModi(a ^ additive-rel ^ hArg1ie1))Since discourse adverbials such as also do not necessarily find their dis-course arguments in structurally adjacent text segments, they do notuse cue threading.
Instead, the cue value on discourse adverbials is leftunderspecfied, as seen in all the lexical entries for also in (40).
Theseunderspecified values then unify with the cue value of the input cat-egory, threading any undischarged structural connectives through.
Inthis way, a discourse adverbial and a structural connective can appearon the same clause (e.g.
However, Bienvenue also has good decor).In our example, the underspecified cue value of the argument cate-gory in (40c) is unified with the nil cue value from the input categoryFigure 4: DCCG derivation of a clause withthe discourse adverbial also (Nakatsu and White,2010)jkumar, 2009) in order to generate texts that varyin size fro single sen ences to entire paragraphs.In DCCG, the technique of cue threa i g isused to all w structural connectives?includingpaired ones such as on the one hand .
.
.
on theother hand?to project beyond the sentence level,while allowing no more than one to be active ata time.
In this way, structural connectives canbe nested, as sketched in Figu e 3, but cannotcross.
In the figure, the value of the cue featur foreach text segment (ts) is shown (where ot1h andotoh abbreviate on the one hand and on the otherh nd); th se cue values can be propagated througha derivation, allowing the discourse relations toproject, but must be discharged (to nil) in a com-plete d rivation, thereby nsuring that the intendeddiscourse relations are actually realized.
By con-trast, discourse adverbials introduce their relationsanaphorically and are transparent to cue thread-ing, as sketched in Figure 4, making u of typicaladverb categories syntactically.
See Nakatsu andWhite (2010) for further details.3 Crowd Sourcing RatingsTo collect human judgements from a diverse groupof speakers of US English, we used Amazon?sMechanical Turk service (AMT) to run two ex-periments.
In the first experiment, subjects ratedthe naturalness of 174 passages used in Walker etal.
?s (2007) study.
As detailed in Section 5, thisvalidation experiment confirmed that the judge-ments collected on AMT correlate with those ofthe raters in Walker et als (2007) study.
Our sec-ond experiment collected ratings on 300 passagesrealized with modifications for better contrast ex-pression (WITHMODS) and 300 passages withoutthese modifications (NOMODS), both realized us-ing OpenCCG.
While this does not admit a directcomparison to the realizations produced by Walkeret al(2007), this controls for differences betweenthe generators other than the variable of interest:the contrastive enhancements.
In addition to thesematerials, five passages from the SRC were seenby all subjects to control for anomalous subject be-havior.3.1 Survey FormatEach survey used demographic questions to de-termine the native speaker status of the subject.Instructions for completing comprehension ques-tions and rating realizations followed the demo-graphic questions.3Each subject saw fifteen stim-uli, each consisting of a sample user query and thetarget passage as in Figure 5.
After reading thestimulus, the subject answered a yes-or-no com-prehension question (see ?3.2).
Finally the subjectrated the naturalness of the passage on a seven-point Likert scale ranging from very unnatural tovery natural.
At the survey?s conclusion, the sub-ject could offer free-form feedback, explain theirr sponses, or ask questions of the researchers.
Theaverage completion time across all experimentswas about ten minutes.Passage selection is detailed in ?3.3 and ?3.4.3.2 Quality ControlWe used three strategies to filter out low-qualityresponses from AMT subjects.Comprehension Questions A template-basedyes-or-no question (exemplified in Figure 5) fol-lowed each passage.
Subjects who answered lessthan 75% of these questions correctly were re-jected and not paid, in accordance with the pro-tocol approved by our human subjects reviewboard.
Responses from three subjects were ex-cluded from analysis on this basis.Uniform Ratings When a subject gave thesame rating for all passages in a given survey (andin disagreement with other subjects), we took thisto mean that the subject was paying attention only3These materials, along with the generated passagesand their ratings are available at http://www.ling.ohio-state.edu/?mwhite/data/enlg13/.33Figure 5: Sample survey stimulus and comprehension questionMethod # subjects excludedComprehension Questions 3Uniform Answers 1SAME5 0Native Speaker Status 2Table 1: Number of subjects excluded based onquality control measures or native language.to the comprehension questions that ensured pay-ment.
Only one subject was excluded on this ba-sis, though they were still paid for answering thecomprehension questions correctly.SAME5 Passages Five passages were chosenfrom the original SRC realizations for which theoriginal ratings (from Walker et al2007) wereidentical for both judges.
The passages were se-lected such that the first and third authors of thispaper agreed with the general valence and rela-tive rankings of the passages.
That is, we tooktwo unambiguously bad realizations, two unam-biguously good realizations, and one realizationnear the middle of the spectrum to represent a goldstandard for rating to compare subjects against.
Ifany subject?s ratings on these five passages wereclear outliers, we could remove that subject?s datafor anomalous behavior, but this measure provedunnecessary for the subjects in the present study.3.3 Validating AMTData Selection In this experiment, we sampled174 of the 1757 realizations from the SRC ratedby subjects A and B in Walker et als (2007) ex-periment.The SRC realizations were divided randomlyinto two groups.
Within one group, realizationswere labelled by subject A?s rating for that real-ization.
Subject B?s rating was used for the othergroup.
Taking the poles of the rating scale and itsmidpoint, the realizations were further partitionedinto six sets: realizations rated 1, 3, and 5 by sub-ject A and realizations rated 1, 3, and 5 by subjectB.
This division of the data ensured that the re-alizations used would cover the full spectrum ofratings while being representative of the SRC rat-ings with respect to, e.g., inter-annotator ratingscorrelations.From each of these six sets, we chose 10 COM-PARE2, 10 COMPARE3, and 10 RECOMMEND re-alizations,4each of these groups representing adifferent realization task in the SRC.
The COM-PARE2 and COMPARE3 tasks involved the com-parison of two restaurants or three or more restau-rants, respectively.
In the RECOMMEND context,the sytem had to generate a recommendation for asingle restaurant.Subject Demographics Thirty-six subjects re-sponded to this survey initially, but one was re-jected based on a failure to answer the compre-hension questions and data from another had to beexcluded for non-native speaker status.
Two addi-tional subjects were recruited to replace their data.This resulted in a subject pool with a mean age(std.
dev.)
of 34.67 (9.35) years.
Twenty-four sub-jects identified as female and twelve identified asmale.
Each subject received $2.50 for the survey,estimated to take approximately 20 minutes.3.4 Rating OpenCCG RealizationsData Selection We selected 15 content plans(CPs) from the SRC where the use of the con-trastive modifiers was licensed: five COMPARE2,five COMPARE3, and five RECOMMEND CPs.Each of the 112 textplans (TPs) that produced4Except that subject A used the rating ?5?
less than subjectB.
To compensate, we used as many 5-point ratings as wereavailable from subject A and then filled in the remainder ofthe 10 slots with realizations rated ?4?.
We mirrored theseselections in the data from subject B for consistency.34the SRC realizations for these CPs was then pre-processed for realization in OpenCCG both withcontrast enhancements (WITHMODS) and withoutthem (NOMODS).Both structural choices and ordering choicesare encoded in these TPs.5Structural choices in-clude decisions about how to group the restau-rant properties to be expressed, such as decidingwhether to describe one restaurant in its entiretyand then the other (i.e.
a serial structure) or al-ternating between one restaurant and the other, di-rectly contrasting particular attributes (i.e.
a back-and-forth structure).
Ordering choices fixed theorder of presentation of restaurant attributes in se-rial plans and the order of presentation of attributecontrasts in back-and-forth plans.
As discussed in?6, there turn out to be interesting interactions be-tween these aggregation choices and the contrastenhancements, interactions which we did not ex-plore directly in this experiment.Processing each TP produced a different LF foreach possible combination of aggregation choicesand contrastive modifications, resulting in approx-imately 41k logical forms (LFs) for the TPs WITH-MODS and 88k LFs for the TPs with NOMODS.6Each realization received two language model(LM) scores, one based on the semantic classesused during realization (LMSC) and one based onthe Gigaword corpus (LMGW).
LMSCused a tri-gram model over modified texts based on the SRCwhere specific entities (e.g.
restaurant names likeCaffe Buon Gusto) were replaced with their se-mantic class (e.g.
RESTAURANT).
The LM scoreswere normalized by CP, such that the scores for agiven CP summed to 1 in each LM.
These werethen linearly combined with weights slightly pre-ferring the LMSCscore to produce a combinedLM score for each realization.Sampling then proceeded without replacement,weighted by the combined LM score for each real-ization.
For the NOMODS sample, 20 realizationswere chosen this way, but, in the WITHMODS sam-ple, a series of regular expression filters were usedto ensure adequate representation of the modifica-tions in the surveys.
These filters selected (without5This differs from Walker et al(2007), wherein reorder-ings were allowed in mapping from tp-trees to sp-trees andd-trees.6In future work we will explore a probabilistic rather thanexhaustive mapping algorithm to produce only LFs that aremore likely to result in more fluent realizations?not unlikethe weighted aggregation done by Walker et als (2007) sen-tence plan generator.replacement) 10 realizations such that every con-trastive modification licensed by a particular CPwas represented, leaving 10 realizations to be se-lected by weighted sampling without replacement.This process resulted in 300 passages in each ofthe two conditions (WITHMODS, NOMODS): 20realizations for each of the 15 CPs.
Each surveyincluded 5 realizations WITHMODS paired by CPwith 5 realizations with NOMODS as well as theSAME5 realizations.
As noted earlier, pairing real-izations in this way helps to control for differencesin the variety of aggregation choices and surfacerealizations used in the SRC as opposed to ourSRC-inspired grammar for OpenCCG.Subject Demographics Sixty-eight subjectsresponded to these 180 surveys initially.
Subjectswere allowed to complete up to six distinct sur-veys.
One subject?s data was excluded for non-native status and another?s was excluded on thebasis of uniform ratings (as detailed in ?3.2).
Tocompensate for the eight surveys completed bythese subjects and ten surveys mistakenly admin-istered in draft format, we recollected data for 18of the 180 surveys.
This resulted in a final pool of80 subjects with an average (std.
dev.)
age 37.15(13.5) years.
Forty identified as female, thirty-nine identified as male, and one identified as non-gendered.Because subjects in the validation study com-pleted the survey in about 10 minutes on averagewith a standard deviation of about 5 minutes, wescaled the pay to $2.00 per survey in this experi-ment.
Since subjects could participate in this ex-periment multiple times, they could receive up to$12.00 for their contribution.4 Training a Text RankerTo perform the ranking, we trained a basic n-gram ranker using SVMlightin preference rankingmode.7We used the average ratings obtained in ?3as target value.The feature set was composed of 2 types of fea-tures.
The first feature type are the two languagemodel scores from ?3.4, LMSCand LMGW.
Thesecond feature type consisted of n-gram counts.We indexed the unigrams and bigrams in each cor-pus and used each as a feature whose value was thenumber of times it appeared in a given realization.We trained the ranker on, and extracted n-gram7SVMlightis an implementation of support vector ma-chines by (Joachims, 2002).3512345671 2 3 4 5Average rating from Walker et al(2007)Average ratingfrom AMTsubjectsFigure 6: Average ratings from our experimentand Walker et al(2007), accompanied by a lineof best fit.
Jitter (0.1) applied to each point mini-mizes overlap.features from, 3 different corpora drawn from thedata selection in ?3.4.
The first corpus contains299 selections WITHMODS (1 selection was dis-carded for only being rated once), the second cor-pus contains 300 selections with NOMODS, andthe third corpus contains BOTH of the first two cor-pora combined.To train and test the ranker, we performed 15-fold cross-validation on each corpus.
Within eachtraining fold, we had 14 training examples, corre-sponding to 14 CPs.
Each training example con-sisted of all of a given CP?s realizations and theirratings.
After training, the realizations for the re-maining CP were ranked.In order to evaluate the ranker, we used theTopRank metric (Walker et al 2007).
For eachof the ranked CP realization sets, we extracted thetarget values (i.e.
the average rating given by sub-jects) of the highest ranked realization.
We thenaveraged the target scores of all of the top-rankedrealizations across the 15 training folds to producethe Top Rank metric.
The oracle best score isthe score of the highest rated realization, as de-termined by the average score assigned to that re-alization by the subjects.5 ResultsValidation Figure 6 shows the correlation be-tween the average ratings of our subjects on AMTand the average ratings assigned by subjects A andB in Walker et al(2007).
This correlation was0.31 (p < 0.01, Kendall?s tau), while the corre-lation between subjects A and B was only 0.28BOTH WITHMODS NOMODShuman 6.61 (0.28) 6.46 (0.43) 6.49 (0.26)bigram 6.00 (0.58) 5.62 (0.83) 5.51 (1.02)Table 2: TopRank scores and standard deviationsfor the oracle (human) & bigram (bigram) ranks.
(p < 0.01, Kendall?s tau).
On this basis we con-clude that using AMT workers as subjects to ratesentences for their naturalness is at least as rea-sonable as having two expert annotators labellingrealizations for their overall quality.SAME5 Comparison There was no signifi-cant difference (p = 0.16, using Welch?s t-test)between the scores given to the SAME5 stimuliin the two experiments,8indicating that subjectsused the rating scale similarly in both experiments.The mean ratings for the rest of the validation re-alizations was 5.31 (1.43) and the mean for theOpenCCG-based realizations in the ranking exper-iment was 4.96 (1.51), which is significantly loweraccording to Welch?s t-test (p < 0.01).
This high-lights the underlying differences between the twogeneration systems, validating our choice to useOpenCCG for both the WITHMODS and NOMODSrealizations to better examine the impact of thecontrast enhancements.Ranking Table 2 reports the oracle results,along with our ranker?s results, using the TopRankmetric.
Most indicative of the benefit of the con-trastive enhancements is the performance of theoracle score for the BOTH (6.61) condition com-pared to the NOMODS condition (6.49), which issignificantly higher according to a paired t-test(p = 0.01).We also found that the bigram ranker with theaveraged raw ratings was better at predicting thetop rank of the combined (BOTH) corpus (6.00 vs.oracle-best of 6.61) than either of the other two,and better on the WITHMODS condition (5.62)than on the NOMODS condition (5.51).
However,a two-tailed t-test revealed that the difference wasnot quite signficant between BOTH and NOMODSat the conventional level (p = 0.06), though thep-value did meet the 0.1 threshold sometimes em-ployed in small-scale experiments.
The perfor-mance of the different rankers, as compared to theoracle scores, can be seen in Figure 7.These preliminary results with a simple ranker8Validation experiment mean (std.
dev.)
4.89 (1.79) ver-sus 5.10 (1.75) in the ranking experiment.3634567human bigramMethodTopRankCorpusbothwithModsnoModsFigure 7: TopRank scores for each of the rankerswith standard error bars.are promising, motivating future work on improv-ing the ranker in addition to enlarging the dataset.6 DiscussionTo assess the impact of the enhancement options,we performed a linear regression between thecontrast-related patterns we used for data selec-tion and the normalized ratings, with scikit-learn?simplementation of the Bayesian Ridge method ofregularizing weights.9In looking at examples,we found that the number of discourse adverbialsappeared to be a factor, so we then added thesecounts as features.
The coefficients and corpuscounts appear in Table 3.
The results show thatthe discourse adverbials were effective some ofthe time, especially when used sparingly and inconjunction with while.
The ?heavier?
contrastiveconnectives however and on the one/other handwere dispreferred, perhaps in part because theyended up appearing too often with small, single-restaurant contrasts, as there were relatively fewexamples of summary statements, most of whichwere somewhat disfluent due to a medial choicefor overall / on the whole.Table 4 shows examples that illustrate both suc-cesses and remaining issues.
At the top, two pairsof examples are given where the normalized av-erage ratings are higher with the inclusion of justand only, and where the rating drops off greatlywhen however is used with a lesser value and noadverbial of this kind, as expected.
At the bottom,the first example shows one instance where the useof multiple adverbials is dispreferred.
A possible9http://scikit-learn.org/stable/modules/linear_model.htmlpattern coeff count| disc advb | = 1 0.23 102while 0.19 38also has 0.13 47has .
.
.
too 0.12 39has only 0.09 43while .
.
.disc advb 0.09 16contrastive .
.
.
overall 0.07 8has just 0.04 46however .
.
.disc advb 0.03 4but -0.03 20, however , -0.05 10only has -0.06 30has merely -0.11 46on the whole -0.14 33just has -0.16 29merely has -0.16 8| disc advb | = 2 -0.18 32. however , -0.21 64on the other hand -0.21 40| disc advb | >= 3 -0.27 50overall -0.29 34on the one hand -0.36 22Table 3: Coefficients of linear regression betweencontrast-related patterns and normalized ratings,along with pattern counts, where disc adv is oneof just, only, merely, also, too and contrastive isone of while, however, on the one/other handfactor here may be that in addition to there beingseveral similar adverbials in a row, they all involvelong-distance antecedents, which may be difficultto process.
Finally, the last example shows a real-ization that receives a relatively high rating despitethe use of two adverbials; note, however, that sincethis passage uses a back-and-forth text plan, theantecedents of the adverbials are all very local.10Turning to the survey feedback, many subjectsprovided insightful comments regarding the task.The most frequent comment pointed out that ourcomprehension questions sometimes precipitateda false implicature: when asked if a restaurant haddecent decor, subjects commented that they feltthat answering ?no?
meant implying that it hadterrible decor.
Similar problems occurred when arestaurant had, e.g., very good decor and the sub-jects were asked if it had good decor.
Despite oc-casional deviations from our intended exact-matchinterpretation of these questions, no subjects wereexcluded for scoring too low as a result of this.10As one reviewer points out, there?s also an interaction be-tween how attributes are aggregated and the ability to expresscontrast.
For example, contrasting the attributes for which arestaurant scores highly with those for which it scores poorlyrequires the aggregation of attributes with like valence, as in?This restaurant has superb decor and very good service butonly mediocre food quality.?
Our future work on aggregationwill explore this interaction as well.37Strategy Mods?
Rating RealizationC2 Y 1.13 Da Andrea?s price is 28 dollars.
Gene?s?s price is 33 dollars.
Da Andrea has very goodfood quality while Gene?s has just good food quality.C2 N 0.73 Da Andrea?s price is 28 dollars.
Gene?s?s price is 33 dollars.
Da Andrea has very goodfood quality while Gene?s has good food quality.C2 Y 1.04 Da Andrea?s price is 28 dollars.
Gene?s?s price is 33 dollars.
Da Andrea has very goodfood quality.
However, Gene?s has only good food quality.C2 N -0.63 Da Andrea?s price is 28 dollars.
Gene?s?s price is 33 dollars.
Da Andrea has very goodfood quality.
However, Gene?s has good food quality.C3 Y -1.85 Daniel and Jo Jo offer exceptional value among the selected restaurants.
Daniel, on thewhole, is a superb restaurant.
Daniel?s price is 82 dollars.
Daniel has superb decor.
It hassuperb service and superb food quality.
Jo Jo, overall, is an excellent restaurant.
Jo Jo?sprice is 59 dollars.
Jo Jo just has very good decor.
It just has excellent service.
It hasmerely excellent food quality.C2 Y 1.12 Japonica?s price is 37 dollars while Dojo?s price is 14 dollars.
Japonica has excellent foodquality while Dojo has merely decent food quality.
Japonica has decent decor.
Dojo hasonly mediocre decor.Table 4: Examples illustrating successful and problematic contrast enhancementsIn order to elicit rankings at a variety of pointson the naturalness scale, our selection included anumber of realizations with lower quality over-all, which subjects picked up on.
For example,one subject commented that, ?Repeatedly usingthe name of each restaurant over and over in sim-ple sentences make[s] almost all of these excerptssound horrifyingly awkward,?
while another ob-served, ?The constant [use] of more sentences, in-stead of using conjunction words .
.
.
makes it seemas if the system is rambling and lost in though[t]process.
?Several subjects also pointed out that it wouldbe more natural to discuss the cost of an averagemeal at a restaurant than to state that a restau-rant?s price is some particular number of dollars.Though these domain-specific lexical preferencesare tangential to the focus of this paper, they sug-gest that exploring options to expand the rangeof realizations for more naturally expressing theseproperties might be a fruitful direction for futurework.In addition to expressing an explicit prefer-ence for serial rather than back-and-forth text-plans, subjects also commented that higher levelcontrastive adverbials like however work betterwhen they are used sparingly at a high level, rein-forcing the findings in our regressions.
We also re-ceived suggestions for future work improving theexpression of contrast: some subjects suggestedthat using better and worse to make explicit com-parisons between restaurants would improve thenaturalness, and one subject suggested explicitlystating which restaurant is (say) the cheapest as inWhite et al(2010).7 Conclusions and Future WorkIn this paper, we have shown using ratings gath-ered on AMT that Nakatsu & White?s (2010) pro-posed enhancements to the SPaRKy RestaurantCorpus (Walker et al 2007) for better express-ing contrast do indeed make it possible to generatebetter texts, and an initial experiment suggestedthat even a basic n-gram ranker can do so automat-ically.
A regression analysis further revealed thatwhile using a few discourse adverbials sparinglywas effective, using too many discourse adverbialshad a negative impact, with antecedent distancepotentially an important factor.
In future work, weplan to improve upon this basic n-gram ranker totake these observations into account and validatethese initial findings on a larger dataset.
In the pro-cess we will explore the interaction between con-trast expression and aggregation and seek to bet-ter model the felicity conditions for ?weighty?
toplevel adverbials such as however.AcknowledgmentsThis work was supported in part by NSF grantIIS-1143635.
Special thanks to the anonymousreviewers, the Clippers computational linguisticsdiscussion group at Ohio State, and to Mark Dras,Francois Lareau, and Yasaman Motazedi at Mac-quarie University.ReferencesBrigitte Grote, Nils Lenke, and Manfred Stede.
1995.Ma(r)king concessions in English and German.
InProc.
of the Fifth European Workshop on NaturalLanguage Generation.38Thorsten Joachims.
2002.
Optimizing search enginesusing clickthrough data.
In Proc.
KDD.Irene Langkilde and Kevin Knight.
1998.
The practi-cal value of n-grams in generation.
In Proc.
INLG-98.William C. Mann and Sandra A. Thompson.
1988.Rhetorical Structure Theory: Towards a functionaltheory of text organization.
TEXT, 8(3):243?281.Chris Mellish, Alistair Knott, Jon Oberlander, andMick O?Donnell.
1998.
Experiments using stochas-tic search for text planning.
In Proc.
INLG-98.Crystal Nakatsu and Michael White.
2006.
Learningto say it well: Reranking realizations by predictedsynthesis quality.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and 44th Annual Meeting of the Association forComputational Linguistics, pages 1113?1120, Syd-ney, Australia, July.
Association for ComputationalLinguistics.Crystal Nakatsu and Michael White.
2010.
Generat-ing with discourse combinatory categorial grammar.Linguistic Issues in Language Technology, 4(1):1?62.Crystal Nakatsu.
2008.
Learning contrastive connec-tives in sentence realization ranking.
In Proceedingsof the 9th SIGdial Workshop on Discourse and Dia-logue, pages 76?79, Columbus, Ohio, June.
Associ-ation for Computational Linguistics.Mark Steedman.
2000.
The Syntactic Process.
MITPress.Kristina Striegnitz.
2004.
Generating Anaphoric Ex-pressions ?
Contextual Inference in Sentence Plan-ning.
Ph.D. thesis, University of Saalandes & Uni-versit de Nancy.Marilyn A. Walker, Owen C. Rambow, and Monica Ro-gati.
2002.
Training a sentence planner for spo-ken dialogue using boosting.
Computer Speech andLanguage, 16:409?433.M.
A. Walker, S. J. Whittaker, A. Stent, P. Mal-oor, J. D. Moore, M. Johnston, and G Vasireddy.2004.
Generation and evaluation of user tailored re-sponses in multimodal dialogue.
Cognitive Science,28(5):811?840.M.
Walker, A. Stent, F. Mairesse, and Rashmi Prasad.2007.
Individual and domain adaptation in sentenceplanning for dialogue.
Journal of Artificial Intelli-gence Research (JAIR), 30:413?456.Bonnie Webber, Matthew Stone, Aravind Joshi, andAlistair Knott.
2003.
Anaphora and discourse struc-ture.
Computational Linguistics, 29(4).Bonnie Webber.
2004.
D-LTAG: Extending lex-icalized TAG to discourse.
Cognitive Science,28(5):751?779.Michael White and Rajakrishnan Rajkumar.
2009.Perceptron reranking for CCG realization.
In Pro-ceedings of the 2009 Conference on Empirical Meth-ods in Natural Language Processing, pages 410?419, Singapore, August.
Association for Computa-tional Linguistics.Michael White, Robert A. J. Clark, and Johanna D.Moore.
2010.
Generating tailored, comparative de-scriptions with contextually appropriate intonation.Computational Linguistics, 36(2):159?201.Michael White.
2006a.
CCG chart realization fromdisjunctive logical forms.
In Proc.
INLG-06.Michael White.
2006b.
Efficient Realization of Coor-dinate Structures in Combinatory Categorial Gram-mar.
Research on Language and Computation,4(1):39?75, June.39
