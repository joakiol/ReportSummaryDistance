Recovering From Parser Failures: A HybridStatistical/Symbolic ApproachCarolyn Penstien Ros&Computational Linguistics ProgramCarnegie Mellon Universitycprose@Ic l ,  cmu.
eduAlex WaibelDept.
of Computer ScienceCarnegie Mellon Universityahw@cs ,  cmu.
eduAbstractW~ describe an implementation of a hybrid statisti-cal/symbolic approach to repairing parser failures in aspeech-to-speech translation system.
I We describe arnodale which takes as input a fragmented parse and ree-turas a repaired meaning representation.
It negotiateswith the speaker about what the complete meaning ofthe utterance is by generating hypotheses about howto fit.
the fragments of the partial parse together intoa colwrcnt meaning representation.
By drawing uponboth statistical and symbolic information, it constrainsits rcpair hypotheses to those which are both likely andmeaningful.
Because it updates its statistical modelduring use, it improves its performance over time.IntroductionNatural language processing of spontaneous speech isparticularly difficult because it contains false starts, outof vocabulary words, and ungrammatical constructions.lleca,se of this, it is unreasonable to hope to be ableto write a grammar which will cover all of the phenom-ena which a parser is likely to encounter in a practicalspeech translation system.
In this paper we describean implementation of a hybrid statistical/symbolic ap-proach to recovering from parser failures in the contextof a speech-to-speech translation system of significantscope (vocabulary size of 996, word recognition accu-racy 60 %, grammar size on the order of 2000 rules).The domain which the current system focuses on is thescheduling domain where two speakers attempt o set~i) a meeting.over the phone.Because this is an interlingua-based translation sys-tem, the goal of the analysis tage of the translation pro-ccss is to map the utterance in the source language ontoa f<.at.re-structure representation called an interlinguawhich represents meaning in a language-independentway.
(This approach extends to other feature structurebased meauistg representations a well.)
If the parser1'l'hc research described in this paper was sponsored byI1.~ Ih'partmeat ofthe Navy, Office of Naval Reseaxch, grant//.
N01)()14-93.1-0806.
The ideas described in this paper do.-I..f,ce.~sarily rellcct the position or the policy of the gov-,.r.m~l~t,, aad ao official elldorsement should be inferred.cannot derive a complete analysis for an utterance, itderives a partial parse by skipping over portions of theutterance in order to find a subset which can parse.
Italso returns an analysis for the skipped portions whichcan be used to rebuild the meaning of the input utter-ance.
The goal of our repair module is to interactivelyreconstruct the meaning of the full utterance by gen-erating predictions about the way the fragments canfit together and checking them with the user.
In thisway it negotiates with the user in order to recover themeaning of the user's utterance.The repair module described in this paper uses bothsymbolic and statistical information in order to recon-struct the speaker's meaning from the partial analy-sis which the parser produces.
It generates predic-tions based on constraints from a specification of theinterlingua representation a d from mutual informationstatistics extracted from a corpus of naturally occurringscheduling dialogues.
Mutual information is intuitivelya measure of how strongly associated two concepts are.Although the syntactic structure of the input utter-ance certainly plays an important role in determiningthe meaning of an utterance, it is possible with theuse of the interlingua specification to reason about themeaning of an utterance when only partial structuralinformation is available.
This can be accomplished byfitting the partial features structures together againstthe mold of the interlingua specification.
During theparsing process, two structural representations are gen-erated, one which is a tree-like structure generated fromthe structure of the context-free portion of the parsinggrammar rules, and one which is a feature-structuregenerated from the unification portion of the parsinggrammar rules.
There is a many-to-one mapping be-tween tree-structures and feature-structures.
Both ofthese structures are important in the repair process.The repair process is analogous in some waysto fit-ting pieces of a puzzle into a mold which contains recep-tacles for particular shapes.
The interlingua specifica-tion is like the mold with receptacles of different shapes,making it possible to compute all of the ways partialanalyses can fit together in order to create a structurewhich is valid for that interlingua.
B .
t  the number of104ways it is possible to do this are so numerous that thebrute force method is computationally intractable.
Mu-tual information statistics are used to guide the search.These mutual information statistics encode regularitiesin the types of fillers which tend to occur in particularslots and which feature structures associated with par-ticular non-terminal symbols in the parsing grammartend to be used in a particular way in the interlinguarepresentation.
By drawing upon both statistical andsymbolic sources of information, the repair module canconstrain its repair predictions to those which are bothlikely and meaningful.One advantage to the design of this module is thatit draws upon information sources which were alreadypart of the system before the introduction of the repairmodule.
Most of the additional information which themodule needs was trained automatically with statisticaltechniques.
The advantage to such a design is thatthe module can be easily ported to different domainswith minimal additional effort.
Another strength isthatthe statistical model the repair module makes use ofcontinually adapts during use.
This is desirable in astatistical pproach in order to overcome problems withunbalanced training sets or training sets which are toosmall eading to over-fitting.Mot ivat ionThe overwhelming majority of research in sym-bolic approaches to handling ill-formed input has fo-cused on flexible parsing strategies.
Jerry Hobbs\[Hobbs et a1.1991\], David McDonald \[McDonald1993\],Jaime Carbonell \[Carbonell et al1984\], Wayne Ward\[Woszcyna et al1993\], Jill Lehman \[Lehman1989\], andAlon Lavie \[Lavie and Tomita1993\] have all developedtypes of flexible parsers.
Hobbs and McDonald eachemploy grammar-specific heuristics which are subopti-mal since they fall short of being completely general.Ward and Carbonell take a pattern matching approachwhich is not specific to any particular grammar but thestructure of the output representation is not optimalfor an application where the output representation isdistinct from the structure of the parse, e. g. a featurestructure, as in an interlingua-based machine transla-tion system.Both Lehman and Lavie take an approach which isindependent of any particular grammar and makes itpossible to generate an output representation which isdistinct from the structure of the parse.
Lehman's least..deviant-first parser can accommodate a wide range ofrepairs of parser failures.
But as it adds new rules toits grammar in order to accommodate idiosyncratic lan-guage patterns it quickly becomes intractable for mul-tiple users.
Also, because it does not make use of anystatistical regularities, it has to rely on heuristics to de-termine which repair to try first.
Lavie's approach is avariation on Tomita's Generalized LR parser which canidentify and parse the maximal subset of the utterancewhich is grammatical ccording to its parsing rammar.He uses a statistical model to rank parses ill order todeal with the extraordinary amount of ambiguity a.~so-elated with flexible parsing algorithms.
Ills solution isa general one.
The weakness of this approach is thatpart of the original meaning of the utterance may bethrown away with the portions of the utterance whichwere skipped in order to find a subset which can parse.From a different angle, Gorin has demonstrated thatit is possible to successfully build speech applicationswith a purely statistical pproach.
He makes use of sta-tistical correlations between features in the input andthe output which purely symbolic approaches do not ingeneral make use of.
The evidence provided by eachfeature combines in order to calculate the output whichhas the most cumulative evidence.
In Gorin's approach,the goal is not to derive any sort of structural represen-tation of the input utterance.
It is merely to map theset of words in the input utterance onto some systemaction.
If the goal is to map the input onto a meaningrepresentation, as is the case in an interlingua-basedmachine translation project, the task is more complex.The set of possible meaning representations even in arelatively small domain such a scheduling is so largethat such an approach does not seem practical in itspure form.
But if the input features encode structuraland semantic information, the same idea can be usedto generate repair hypotheses.The repair module described in this paper buildsupon Lavie's and Gorin's approaches, reconstructingthe meaning of the original utterance by combining thefragments returned from the parser, and making use ofstatistical regularities in order to naturally determinewhich combination totry first.
In our approach we haveattempted to abstract away from any particular gram-mar in order to develop a module which could be easilyported to other domains and other languages.
Our ap-proach allows the system to recover from parser failuresand adapt without adding any extra rules to the gram-mar, allowing it to accommodate multiple users withoutbecoming intractable.Given a maximum of 10 questions to ask the user, itcan raise the accuracy of the parser (point value derivedfrom automatically comparing enerated feature struc-tures to hand-coded ones) from 52% to 64% on speechdata and from 68% to 78% on transcribed ata.
GivezJa maximum of 25 questions, it can raise the accuracyto 72% on speech-data and 86% on transcribed ata.Symbo l i c  In fo rmat ionThe system which this repair module was designed for isan interlingua-based machine-translation system.
Thismeans that the goal of the analysis tage is to map theinput utterance onto a language-independent r presen-tation of meaning called an interlingua.
Currently, theparsing grammar which is used is a semantic grammarwhich maps the input utterance directly onto the inter-lingua representation.
Although the goal of an inter-lingua is to be language independent, most iaterlingua.s105are domain dependent.
Although this may seem like adisadvantage, it actually makes it possible for domainknowledge to be used to constrain the set of meaning-ful interlingua structures for that domain which is par-ticuiarly useful for constraining the set of possible re-pairs which can be hypothesized.
The domain whichth~ current system focuses on is the scheduling domainwhere two speakers attempt o set up a meeting overI, he phone.The interlingua is a hierarchical feature-structurerepresentation.
Each level of an interlingua structurecontains a frame name which indicates which concept isrepresented at that level, such as *busy or *free.
Eachframe is associated with a set of slots which can befilled either by an atomic value or by another feature-structure.
At the top level, additional slots are addedfor the sentence-type and the speech-act.
Sentence-typeroughly corresponds to mood, i.e.
*state is assigned todeclarative sentences and *query-if is assigned to yes/noquestions.
The speech-act indicates what function theutterance performs in the discourse context.
See sampleiuterliugua structure in Figure 1.
((SPEECH-ACT (*MULTIPLE**STATE-CONSTRAINT *REJECT))(SENTENCE-TYPE *STATE)(FRAME *BUSY)(WHO ((FRAME *I)))(WItEN((FRAME *SPECIAL-TIME)(NAME WEEK)(SPECIFIER (*MULTIPLE* ALL-RANGENEXT)))))Figure 1: Sample inter l ingua representat ion re-turned by the parser for 'Tm busy all nextThe interlingua specification determines the set ofpossible interlingua structures.
This specification isoneof the key symbolic knowledge sources used for generat-ing repair hypotheses.
It is composed of BNF-like ruleswhich specify subsumption relationships between typesof feature-structures and other types or between typesof feature-structures and a feature-structure specifica-tion.A fi~ature-structure specification is a feature-structure who's slots are filled in with types ratherthan with atomic values or feature-structures.
Feature-structure specifications are the leaves of the subsump-tiou hh'rarchy of iuteriingua Specification types.S ta t i s t i ca l  Knowledgelutuitiw~ly, repair hypotheses are generated by comput-ing t,hc mutual information between semantic grammarmm-termlnal symbo|s and types in the interlingua spec-flication and also between slot/type pairs and types(< TEMPORAL > -- < S IMPLE  - T IME >< INTERVAL >< SPECIAL  - T IME >< RELAT IVE  - T IME >< EVENT-  T IME >< T IME - L IST  >)Figure 2: SAmple interl ingua specif ication rule forexpressing a subsumpt ion relat ionship betweentype < TEMPORAL > and more specific tempo-ral types.
(< BUSY > = ((frame *busy)(topic < FRAME >)I who < FRAME >) why < FRAME >) (when < TEMPORAL >)(how-long < LENGTH >)(degree \[degree\])))Figure 3: Sample interHngua specif ication rule forexpressing a subsumpt ion relat ionship betweenthe type < BUSY > and the feature-st ructurespecification for the frame *busy.which are likely to be fillers of that slot.
Mutual infor-mation is roughly a measure of how strongly associatedtwo concepts are.
It is defined by the following formula:log\[ P (  ck Ivm)/P(cD\]where ck is the kth element of the input vector and vrnis the mth element of the output vector.Based on Gorin's approach, statistical knowledge inour repair module is stored in a set of networks withweights which correspond to the mutual informationbetween an input unit and an output unit.
Gorin's net-work formalism is appealing because it can be trainedboth off-line with examples and on-line during use.
An-other positive aspect of Gorin's mutual information et-work architecture is that rather than provide a sin-gle hypothesis about the correct output, it provides aranked set of hypotheses so if the user indicates thatit made the wrong decision, it has a natural way ofdetermining what to try next.
It is also possible to in-troduce new input units at any point in the trainingprocess.
This allows the system to learn new wordsduring use.
They will be skipped by the parser, but therepair module can treat them like parser non-terminalsymbols and learn how to map them onto interlinguarepresentations.
This gives the system the additionalability to handle nil parses.
It treats each word in theinput utterance as a chunk and proceeds as usual.
(Achunk is the Repair Module's internal representation fa skipped portion of the input utterance.
)Our implementation of the repair module has codefor generating and training five instavtiations ofGorin's106network architecture, ach used in a different way in therepair process.The first network is used for generating a set of hy-pothesized types for chunks with feature structures thathave no type in the interlingua specification.
The parseassociated with these chunks is most commonly a singlesymbol dominating a single word.
This symbol is usedto compute a ranked set of likely types this symbol islikely to map onto based on how much mutual informa-tion it has with each one.
In the case that this is a newsymbol which the net has no information about yet,it will return a ranked list of types based on how fre-quently those types are the correct output.
This effectfalls naturally out of the mutual information equation.The second network is used for calculating what typesare likely fillers for particular frame slot pairs, e. g. aslot associated with a particular frame.
This is used forgenerating predictions about likely types of fillers whichcould be inserted in the current interlingua structure.This information can help the repair module interpretchunks with uncertain types in a top-down fashion.The third network is similar to the first network ex-cept that it maps collections of parser non-terminalsymbols onto types in the interlingua specification.
Itis used for guessing likely top level semantic frames forsentences and for building larger chunks out of collec-tions of smaller ones.The fourth network is similar to the third exceptinstead of mapping collections of parser non-terminalsymbols onto types in the interlingua specification, itmaps them onto sentence types (see discussion on in-terlingua representation).
This is used for guessing thesentence type after a new top level semantic frame hasbeen select.ed.The fifth and final network maps a boolean value ontoa ranked set of frame slot pairs.
This is used for gener-ating a ranked list of slots which are likely to be filled.This network complements he second network.
A com-bination of these two networks yields a list of slots whichare likely to be filled along with the types they are likelyto be filled with.My implementation of the mutual information et-works allows for a mask to filter out irrelevant hypothe-ses so that only the outputs which are potentially rele-vant at a give time will be returned.The Repair Process: DetailedDescriptionIn this section I give a detailed high-level description ofthe operation of the Repair Module.Sys tem Arch i tec tureThe heart of the Repair Module, see Figure 5, is theHypothesis Generation Module whose purpose it is togenerate repair hypotheses which axe instructions for re-constructing the speaker's meaning by performing oper-ations on the Chunk Structure of the parse.
The ChunkStructure represents he relationships between tile par-tial analysis and the analysis for each skipped segm~ntof the utterance.
See Figure 4.Speaker's Utterance: ~l~esday afternoon the ~tJtthwould be okay for me though.Speech Hypothes is  From the Recognizer: Tues-day afternoon the ninth be okay for me that.Partial Ananlysis:((sentence-type *fragment)(when ((frame *simple-time)(time-of-day afternoon)(day-of-week Tuesday)(day 9)))Paraphrase of partial  analysis: Tuesday afterimoonthe ninthSkipped Portions:1.
((value be))2.
((frame *free) (who ((frame *i))) (good-bad +))3.
((frame *that))Figure 4: Sample Part ia l  ParseThe Initialization module builds this structure fromthe fragmented analysis returned by the parser.
It iu-serfs this structure into the Dynamic Repair Memorystructure which serves as a blackboard for communi-cation between modules.
The Dynamic Repair Mem-ory also contains lots for tile current repair hypothesisand the status of that hypothesis, i.e.
test, pass, fail.There are essentially four types of repair hypothesesthat the Hypothesis Generation Module can generate.These are guessing the top level semantic frame for theinterlingua structure of the sentence, guessing the sen-tence type, combining chunks into larger chunks, andinserting chunks into the current interlingua structure.The Hypothesis Generation Module has access toeight different strategies for generating repair hypothe-ses.
The strategy determines which of the four typesof hypotheses it should generate on each iteration.
Ametn-strategy selects which strategy to employ in agiven case.Once the hypothesis is generated, it is sent to theQuestion Generation Module which generates a ques-tion for the user to check whether the hypothesis iscorrect.
After the user responds, the status of the hy-07 mRepair ModuleEiI,'igurc 5: Repair  Module  System Arehitechturepothesis is noted in the Dynamic Repair Memory and ifthe response was positive, the Interlingua Update Mod-ule makes the specified repair and updates the DynamicRepair Memory structure.
It is the Interlingua UpdateModule which uses these hypotheses to actually makethe repairs in order to derive the complete meaning rep-resentation for the utterance from the partial analysisand the analysis for the skipped portions.If the status indicates that the speaker's response wasnegative, the Hypothesis Generation Module will sug-gest an alternative repair hypothesis which is possiblesince the mutual information ets return a ranked listof predictions rather than a single one.
In this waythe repair module negotiates with the speaker aboutwhat was meant until an acceptable interpretation canhe constructed.
See Figure 6.
When the goal returnspositive, the networks are reinforced with the new in-formation so they can improve their performance overtime.The  Three  Quest ionsThe eight strategies are generated by all possible waysol's~,h,cting either l,op-down or bottom-up as the answerto I.hr~'e questions.The first, question is, "What will be the top level se-nmutic frame?".
The top-down approach is to keep thepartial analysis returned by the parser as the top levelstructure thereby accepting the top level frame in thepartial analysis returned by the parser as representingthe gist.
of tile meaning of tile sentence.
The bottom-upInterlingua Representation:((sentence-type *state)(frame *free)(who ((frame *i)))(when ((frame *simple-time)(time-of-day afternoon)(day-of-week Tuesday)(day 9))))Paraphrase: I am free Tuesday afternoon the ninth.Figure 6: Complete Meaning Representat ion  Af-ter Repairapproach is to assume that the partial analysis returnedby the parser is merely a portion of the meaning of thesentence which should fit into a slot inside of some othertop level semantic frame.
This is the ease in the exam-pie in Figure 4.If bottom-up is selected, a new top level semanticframe is chosen by taking the set of all parser non-terminal symbols in the tree structure for the partialanalysis and from each skipped segment and comput-ing the mutual information between that set and eachinterlingua specification type.
This gives it a rankedset of possible types for the top level interlingua struc-ture.
The interlingua specification rule for the selectedtype would then become the template for fitting in theinformation extracted from the partial analysis as wellas from the skipped portions of the utterance.
See Fig-ure 7.
If a new top-level frame was guessed, then a newsentence-type must also be guessed.
Similar to guessinga top level frame, it computes the mutual informationbetween the same set of parser non-terminal symbolsand the set of sentence-types.The second question is, "How will constituents bebuilt?".
The top-down approach is to assume that ameaningful constituent to insert into the current inter-lingua structure for the sentence can be found by sim-ply looking at available chunks and portions of thosechunks.
See Figure 8.
The bottom-up approach is toassume that a meaningful chunk can be constructed bycombining chunks into larger chunks which incorporatetheir meaning.
The process of generating predictionsabout how to combine chunks into larger chunks is sim-ilar to guessing a top-level frame from the utteranceexcept that only the parser non-terminal symbols forthe segments in question are used to make the compu-tation.The third question is, "What will drive the searchprocess?".
The bottom-up approach is to generate pre-dictions of where to insert chunks by looking at thechunks themselves and determining where in the inter-lingua structure they might fit in.
See Figure 9.The top-down approach is to look at the interlinguastructure, determine what slot is likely to be filled in,108Question: What will be the top level structure?Answer: Try Bottom-Up.Question: How will constituents be built?Answer: Try Top-Down.Hypothesis:  (top-level-frame ((frame-name *free)))Question: Is your sentence mainly about someone be-ing free?User Response: Yes.New Current  Inter l ingua Structure:((frame *free))Skipped Portions:1.
((value be))2.
((frame *free) (who ((frame *i))) (good-bad +))3.
((frame *that))4.
((frame *simple-time) (time-of-day afternoon) (day-of-week Tuesday) (day 9))Figure 7: The First Questionand look for a chunk which might fill that slot.
SeeFigure I0.The difference between these Strategies is primar-ily in the ordering of hypotheses.
But there is alsosome difference in the breadth of the search space.The bottom-up approach will only generate hypothe-ses about chunks which it has.
And if there is somedoubt about What the type of a chunk is, only a finitenumber of possibilities will be tested, and none of thesemay match something which can be inserted into one ofthe available slots.
The top-down approach generatesits predictions based on what is likely to fit into avail-able slots in the current interlingua structure.
It firsttries to find a likely filler which matches a chunk whichhas a definite type, but in the absence of this eventual-ity, it will assume that a chunk with no specific type iswhatever type it guesses can fit into a slot.
And if theuser confirms that this slot should be filled with thistype, it will learn the mapping between the symbols inthat chunk and that type.
Learning new words is morelikely to occur with the top-down approach than withthe bottom-up approach.The meta-strategy answers these questions, selectingthe strategy to employ at a given time.
Once a strategyis selected, it continues until it either makes a repairor cannot generate anymore questions given the cur-rent state of the Dynamic Repair Memory.
Also, oncethe first question is answered, it is never asked againAvailable Chunks:1.
((value be))2.
((frame *free) (who ((frame *i))) (good-bad +))3.
((frame *that))4.
((frame *simple-time) (time-of-day afternoon) (day-of-week Tuesday) (day 9))Constituents:1.
((frame *simple-time) (time-of-day afternoon) (day-of-week Tuesday) (day 9))2.
((frame *free) (who ((frame *i))) (good-bad +))3.
((frame *i)) ,~4.
((frame *that))5.
((value be))Figure 8: The Second Quest ionsince once the top level frame is confirmed, it can bedepended upon to be correct.The recta-strategy attempts to answer the first ques-tion at the beginning of the search process.
If the wholeinput utterance parses or the parse quality indicated bythe parser is good and the top level frame guessed asmost likely by the mutual information ets matches theone chosen by the parser, it assumes it should take tiletop-down approach.
If the parse quality is bad, it as-sumes it should guess a new top level frame, but it doesnot remove the current top level frame from its list ofpossible top level frames.
In all other cases, it confirmswith the user whether the top level frame selected bythe parser is the correct one and if it is not, then itproceeds through its list of hypotheses until it locatesthe correct op level frame.Currently, the meta heuristic always answers the sec-ond question the same way.
Preliminary results indi-cated that in the great majority of cases, the repairmodule was more effective when it took the top downapproach.
It is most often the case that the chunkswhich are needed can be located within the structuresof the chunks returned by the parser without combin-ing them.
And even when it is the case that chunksshould be combined in order to form a chunk which fitsinto the current interlingua structure, the same effectcan be generated by mapping the top level structure ofthe would be combined chunk onto an available chunkwith an uncertain type and then inserting the wouht bc109Question: What will drive the search process?Answer: Try Bottom-Up.Current Const i tuent:((frame *simple-time)(tim(~-of-day afternoon)(day-of-week Tuesday)(,lay 9)))Hypothesis:(frame-slot ((frame-name *free)(when ((frame *simple-time) ,(time-of-day afternoon)(day*of-week Tuesday)(day 9)))))Question: Is Tuesday afternoon the ninth the time ofbeing free in your sentence?User Response: Yes.New Current  Inter l ingua Structure:((sentence-type *state)(frame *free)(when ((frame *simple-time)(time-of-day afternoon)(day-of-week Tuesday)(day 0))))Figure 9: The Thi rd  Quest ion - Part  1constituent chunks into this hypothesized chunk later.Preliminary tests indicated that the option of combin-ing chunks only yielded an increase in accuracy in about1% of the 129 cases tested.
Nevertheless, it would beideal for the meta heuristic to sense when it is likely tobe useful to take this approach, no matter how infre-quent.
This will be a direction for future research.The third question is answered by taking the bottom-up approach early, considering only chunks with a def-inite type and then using a top down approach for thed u ration of the repair process for the current interlinguaM,rl l( ' | , l lre.The linal task of the met, a heuristic is for it to decidewhen to stop asking questions.
Currently it does thiswhen there are no open slots or it has asked some ar-I,itrary maximum uumber~of questions.
An importantdire('i.h,n of fnture research is to find a better way ofd,mlg this.
Currently, the repair module asks primar-Question: What will drive the search process?Answer: Try Top-Down.Current Slot: whoHypothesis:  (frame-slot ((frame-name *free) (who((frame *i)))))Question: Is it "I" who is being free in your sentence?User Response: Yes.New Current Interlingua Structure:((sentence-type *state)(frame *free)(who ((frame *i)))(when ((frame *simple-time)(time-of-day afternoon)(day-of-week Tuesday)(day 0))))Figure 10: The Third Question - Part 2ily useful questions (yielding an increase in accuracy)early (within the first 5 or 10 questions) and then pro~ceeds to ask a lot of irrelevant questions.
But I have notfound an optimal maxhr~m number of questions.
If thenumber of questions is too small, it will not be able tolearn some new input patterns and sometimes fails torecover information it would have been able to recoverhad it been allowed to ask a few more questions.
Butif the number is too large, it is unnecessarily annoyingfor the user, particularly in cases where the importantinformation was recovered early in the process.User  In teract ionUser interaction is an essentiM part  of our pproach.The ideal in speech-to-speech translation has been di-rect through-put from input speech to output speech.But this leaves the speaker with no idea of what thesystem understood from what was said or what is ul-timately communicated to the other speaker.
This isparticularly a problem with flexible parsing techniqueswhere the parser must take some liberties in finding aparse for ill-formed input.Because our Hypothesis Generation Module makeshypotheses about local repairs, the questions generatedfocus on local information in the meaning representa-tion of the sentence.
For instance, rather than con-firm global meaning represenations a  in , "Did youmean to say X?
", it confirms local information as in, "Istwo o'clock the time of being busy in your sentence?
"which confirms that the representation for "two o'clock"should be inserted into the when slot in the *busy frame.10ResultsFigure 11 displays the relative performance of the eightstrategies compared to the meta strategy on speechdata.I &Nii &m1J " I ~ k ' "  IFigure 11: Results from All Strategies on SpeechDataGiven a maximum of 10 questions to ask the user,the repair module can raise the accuracy of the parser(point value derived from automatically comparing en-erated feature structures to hand-coded ones) from 52%to 64% on speech data and from 68% to 78% on tran-scribed data.
Given a maximum of 25 questions, it canraise the accuracy to 72% on speech-data and 86% ontranscribed ata.Conc lus ions  and  Future  D i rec t ionsThis document describes an approach to interactive re-pair of fragmented parses in the context of a speech-to-speech translation project of significant scale.
It makesit possible to use symbolic knowledge sources to the ex-tent that they are available and uses statistical knowl-edge to fill in the gaps.
This gives it the ability to keepthe preciseness of symbolic approaches wherever possi-ble as well as the robustness of statistical approacheswherever symbolic knowledge sources are not available.It is a general approach which applies regardless of howdegraded the input is, even if the sentence completelyfails to parse.The primary weakness of this approach is that it, re-lies too heavily on user interaction.
One goal of futureresearch will be to look into various ways of reducingthis burden on the user.
The following is a list of po-tential avenues of exploration:1.
Reduce unnecessary positive confirmations by devel-oping a reliable confidence measure.2.
Use contextual knowledge and possibly some domainknowledge to eliminate hypotheses which don't makesense.3.
Develop heuristics for rejecting sentences which areout of domain.4.
Introduce a mechanism for enforcing global con-stralnts, i. e. agreement, and other selectional restric-tions.Re ferences\[Carbonell et a1.1984\] Jaime G. Carbonell, Philip J.Hayes.
1984.
Recovery Strategies for Parsing Extra-grammatical Language.
Teeh.
Rep. 84-107, School ofComputer Science, Carnegie Mellon University.\[Gertner and Gorin1993\] A. N. Gertner, A. L. Gorin.1993.
Adaptive Language Acquisition for an Air-line Information Subsystem.
In Neural Networks forSpeech and Vision Applications.\[Bobbs et a1.1991\] Jerry R. Bobbs, Douglas E. Appelt,John Bear.
1991.
Robust Processing of Real-WorldNatural-Language T xts.
In unknown conference pro-ceedings.
SRI International.\[Lavie and Tomita1993\] Alon Lavie, Massaru qbmita.1993.
GLR* - An Efficient Noise-Skipping ParsingAlgorithm For Context-Free Grammars.
In Proceed-ings of the 8rd International Workshop on ParsingTechnologies.\[Lehman1989\] Jill Fain Lehman.
1989.
Self-ExtendingNatural Language Interfaces.
PhD Dissertation,School of Computer Science, Carnegie Mellon Uni-versity.\[McDonald1993\] David McDonald.
1993.
The Inter-play of Syntactic and Semantic Node Labels in Par-tial Parsing.
In Proceedings of the 3rd InternationalWorkshop on Parsing Technologies.\[Woszcyna et a1.1993\] M. Woszcyna, N. Coccaro,A.
Eisele, A. Lavie, A. McNalr, T. Polzin, I. Rogina,C.
P. RosE, T. Sloboda, M. Tomita, J. Tsutsumi,N.
Waibel, A. Waibel, W. Ward.
1993.
Recent Ad-vances in JANUS: A Speech Translation System.
InProceedings of the ARPA Human Languages Tech-nology Workshop.111
