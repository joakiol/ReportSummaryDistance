Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 126?134,ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational LinguisticsA Semantic Feature for Statistical Machine TranslationRafael E. Banchs Marta R. Costa-juss?Institute for Infocomm Research Barcelona Media Innovation Centre1 Fusionopolis Way, 21-01, Singapore 138632 Av.
Diagonal 177, planta 9, 08018 Barcelonarembanchs@i2r.a-star.edu.sg marta.ruiz@barcelonamedia.orgAbstractA semantic feature for statistical machine trans-lation, based on Latent Semantic Indexing, isproposed and evaluated.
The objective of theproposed feature is to account for the degree ofsimilarity between a given input sentence andeach individual sentence in the training dataset.This similarity is computed in a reduced vector-space constructed by means of the Latent Se-mantic Indexing decomposition.
The computedsimilarity values are used as an additional fea-ture in the log-linear model combination ap-proach to statistical machine translation.
In ourimplementation, the proposed feature is dy-namically adjusted for each translation unit inthe translation table according to the current in-put sentence to be translated.
This model aimsat favoring those translation units that were ex-tracted from training sentences that are seman-tically related to the current input sentencebeing translated.
Experimental results on aSpanish-to-English translation task on the Biblecorpus demonstrate a significant improvementon translation quality with respect to a baselinesystem.1 IntroductionIn recent years, the statistical approach to machinetranslation has gained a lot of attention from boththe scientific and the commercial perspective.
Thishas basically been a consequence of the increasingavailability of bilingual training material as well asthe increasing storage and processing capabilitiesof current computational systems, which have al-lowed for the construction of machine translationsystems with general-public acceptance quality.For several reasons, the most prominent statisti-cal machine translation paradigm currently used isthe phrase-based approach (Koehn et al, 2003),which has been derived from the IBM?s word-based approach originally proposed in the early90?s (Brown et al, 1993).
This original approachwas heavily rooted on the noisy-channel modelframework, which, in our view, continues to playan important role in the fundamental conception ofcurrent statistical machine translation.While one of the major assumptions of thenoisy-channel model approach is the independencebetween decoding and source language probabili-ties, there exists strong evidence on the importantrole played by source language structure and con-text within the task of human translation (Padilla &Bajo, 1998).
In this sense, the inability of main-stream statistical machine translation to tackle withsource-context information in a reliable way hasbeen already recognized as a major drawback ofthe statistical approach, whereas the use of source-context information has been proven to be effec-tive in the case of example-based machine transla-tion (Carl & Way, 2003).
In this regard, attemptsfor incorporating source-context information intothe phrase-based machine translation frameworkhave been already reported (Carpuat & Wu, 2007;Carpuat & Wu, 2008; Haque et al, 2009; Espa?a-Bonet et al, 2009; Haque et al, 2010; Costa-juss?& Banchs, 2010).
However, as far as we know, notranscendental improvements in performance havebeen achieved or, at least, reported yet.In this work, we elaborate deeper on the ideaswe have recently presented and discussed in Costa-juss?
& Banchs (2010), where we used a similaritymetric between the source sentence to be translatedand all the sentences in the training set as an addi-126tional feature in the log-linear combination (Och &Ney, 2002) of models of a phrase-based translationsystem.
Such a feature, which is dynamic in thesense that depends on the input sentence to betranslated, is intended to favor those translationunits which were extracted from training sentencesthat are similar to the current input sentence overthose translation units which were extracted fromdifferent or unrelated sentences.
Different from ouroriginal methodology, where sentence similaritieswere assessed over a term-document matrix repre-sentation for words and statistical classes of words,here we compute sentence similarities in a low-dimensional vector space constructed by means ofLatent Semantic Indexing (Landauer et al, 1998).The rest of the paper is organized as follows.Section 2 presents an overview of some recent ap-proaches attempting to introduce source-contextinformation into the statistical machine translationframework.
Then, section 3 introduces the meth-odology that is proposed and evaluated in thiswork, and section 4 focuses on some implementa-tion issues.
Section 5 describes the experimentalsettings and results.
Section 6 presents a manualevaluation of a selected sample of system transla-tions and discusses the most relevant findings andobservations.
Finally, section 7 presents the mostrelevant conclusions of this work and providesguidelines for further research in this area.2 Related WorkSeveral attempts for incorporating source-contextinformation into the statistical machine translationframework have been reported in the literature dur-ing the last few years.
Without attempting to becomprehensive, we provide a brief overlook ofsome of the most sounded recent works within thisarea which are relevant to the phrase-based statisti-cal machine translation approach.
For a more com-prehensive review of the state-of-the-art, the readercan refer to Haque et al (2010).On the one hand, there are some semantic ap-proaches.
In Carpuat & Wu (2007), for instance,word sense disambiguation techniques are intro-duced into statistical machine translation; and inCarpuat & Wu (2008), dynamically-built context-dependant phrasal translation lexicons are shownto be more useful for phrase-based machine trans-lation than conventional static phrasal translationlexicons, which ignore all contextual information.On the other hand, there are approaches whichuse machine learning techniques.
In Haque et al(2009), different syntactic and lexical features areproposed for incorporating information about theneighbouring words; and in Espa?a-Bonet et al(2009), local classifiers are trained, using linguisticand context information, to translate a phrase.Finally, our recent approach, which is inspiredon information retrieval techniques for measuringthe source-context similarity between the inputsentence to be translated and the original trainingmaterial, was presented in Costa-juss?
& Banchs(2010).
As our present methodology is closely re-lated to this approach, more details are provided inthe following section.3 Proposed MethodologyAs already mentioned, the methodology proposedand evaluated in this work is based on the source-context similarity approach we presented in Costa-juss?
& Banchs (2010).
Different from that work,here we introduce the use Latent Semantic Index-ing (Landauer et al, 1998) to construct a vector-space model representation of the data collection ina reduced-dimensionality space before computingsource sentence similarities.
First, in subsection3.1, we review the source-context similarity ap-proach.
Then, in subsection 3.2 we present the ba-sics of Latent Semantic Indexing.3.1 The Source-Context Similarity ApproachThe method we proposed in Costa-juss?
& Banchs(2010) introduces and extended concept of transla-tion unit or phrase by defining a tuple of three ele-ments: phrase-source-side, phrase-target-side, andsource-context:TU = {PSS ||| PTS ||| SC} .
(1)In the most simplistic approach, the source-context element of a given translation unit can beapproximated by the complete source sentence thetranslation unit was originally extracted from.
Toillustrate this point, consider the following conven-tional translation unit {vino|||wine} which has beenextracted from the training sentence sus ojos est?nbrillantes por el vino y sus dientes blancos por laleche (his eyes shall be red with wine and his teethwhite with milk).
According to (1), the extendedtranslation unit TU is defined as {vino|||wine|||sus127ojos est?n brillantes por el vino y sus dientes blan-cos por la leche}.
Notice that, from this definition,identical source-target phrase pairs that have beenextracted from different training sentences are re-garded as different translation units!According to this definition, the relatedness ofcontexts between any translation unit and an inputsentence to be translated can be computed bymeans of some distance or similarity metric over asemantic space representation for sentences.
Thisidea is implemented in practice by means of thefollowing dynamic feature function:F(TU,IN) = SIM(TU,IN) = SIM(SC,IN) , (2)where TU refers to a given translation unit, IN re-fers to the input sentence to be translated, SC refersto the source-context component of translation unitTU (which in our implementation is the sourcetraining sentence which the translation unit wasextracted from), and SIM is a similarity metric overa given model space.As implied in (2), the source-context feature tobe implemented consists of a similarity measure-ment between the input sentence to be translatedIN and the source-context component SC of theavailable translation units.In Costa-juss?
& Banchs (2010), we used thecosine of the angle between vectors in a term-sentence matrix representation (Salton et al, 1975)for computing the source-context similarity featuredescribed in (2).
In this work, we use Latent Se-mantic Indexing (Landauer et al, 1998) for pro-jecting the term-sentence matrix representationinto a low-dimensional space and use the cosine ofthe angle between vectors in the resulting reducedspace for computing the source-context similarityfeature.
With this, we expect to reduce the noiseresulting from data sparseness problems in theoriginal full-dimensional representation.To better illustrate the concepts discussed here,let us consider the Spanish word vino and the cor-responding English translations for its two senses:wine and came.
Both translations can be automati-cally inferred from training data; and Table 1 illus-trates the resulting probability values derived forboth senses of the Spanish word vino from the ac-tual training dataset used in this work (a detaileddescription of the dataset is given in section 5).Notice from the table, how in general the mostprobable sense of vino in our considered dataset iswine.
This actually happens because the Englishword wine is always related to the Spanish wordvino, whereas the English word came can refer tomany different inflections of the same Spanishword: vine, viniste, vino, vinimos, vinieron, etc.phrase ?
(f|e) lex(f|e) ?
(e|f) lex(e|f){vino|||wine} 0.665198 0.721612 0.273551 0.329431{vino|||came} 0.253568 0.131398 0.418478 0.446488Table 1: Actual probability values for the two pos-sible translations of the Spanish word vino.The idea of the proposed source-context featureis to use the contextual similarity between the inputsentence to be translated and the sentences in thetraining dataset as an additional source of informa-tion that should be helpful during decoding.Consider for instance the following two sen-tences corresponding to the wine sense of vino:SC1: No hab?is comido pan ni tomado vino ni licor , para que se-p?is que yo soy Jehovah vuestro Dios .
(Ye have not eaten bread ,neither have ye drunk wine or strong drink : that ye might knowthat I am the Lord your God .
)SC2: Cuando fue divulgada esta orden , los hijos de Israel dieronmuchas primicias de grano , vino nuevo , aceite , miel y de todoslos frutos de la tierra .
(And as soon as the commandment cameabroad , the children of Israel brought in abundance the firstfruitsof corn , wine , and oil , and honey , and of all the increase of thefield .
)and the following two sentences corresponding tothe came sense of vino:SC3: Al tercer d?a vino Jeroboam con todo el pueblo a Roboam ,como el rey hab?a hablado diciendo : Volved a m?
al tercer d?a .
(So Jeroboam and all the people came to Rehoboam the third day ,as the king had appointed , saying , Come to me again the thirdday .
)SC4: Ella vino y ha estado desde la ma?ana hasta ahora .
No havuelto a casa ni por un momento .
(She came , and hath continuedeven from the morning until now , that she tarried a little in thehouse .
)As the context for a given word is generally de-termined by its surrounding words, we should beable to infer the correct sense for the word vino ina new Spanish sentence by considering its similar-ity to sentences SC1, SC2, SC3 and SC4.
Now, sup-pose we want to translate the following two inputsentences into English:IN1: Hasta que yo venga y os lleve a una tierra como la vuestra ,tierra de grano y de vino , tierra de pan y de vi?as , tierra de aceitede olivo y de miel .
(Until I come and take you away to a land likeyour own land , a land of corn and wine , a land of bread andvineyards , a land of oil olive and of honey .
)128IN2: Cuando amanec?a , la mujer vino y cay?
delante de la puertade la casa de aquel hombre donde estaba su se?or , hasta que fuede d?a .
(Then came the woman in the dawning of the day , and felldown at the door of the man 's house where her lord was , till itwas light .
)We can select the appropriate sense for vino ineach case by considering the sentence similaritybetween each of these two sentences and ?training?sentences SC1, SC2, SC3 and SC4.
The actual similar-ity values are presented in Table 2.SC1 SC2 SC3 SC4sense {vino|||wine} {vino|||came}IN1 0.0636 0.2666 0.0351 0.0310IN2 0.0023 0.0513 0.0888 0.0774Table 2: Actual similarity values between inputand training sentences containing the word vino.As seen from the table, the source-context simi-larity feature is actually giving preference to thephrase pair {vino|||wine} in the case of input sen-tence IN1 and to {vino|||came} in the case of IN2.Notice that more than one similarity value is gen-erally available for each phrase pair.
In our pro-posed implementation, the largest similarity valueis the one that is retained.
More details on how wecompute these sentence similarities are given in thefollowing subsection.3.2 Latent Semantic IndexingLatent Semantic Indexing (Landauer et al, 1998)can be regarded as the text mining equivalent ofPrincipal Component Analysis (Pearson, 1901).Both methods are based on the singular value de-composition (SVD) of a matrix (Golub & Kahan,1965), according to which a rectangular matrix Xof dimensions MxN can be factorized as follows:X = U ?
VT , (3)where U and V are unitary matrices of dimensionsMxM and NxN, respectively, and ?
is a diagonalmatrix containing the singular values associated tothe decomposition.According to Landauer et al (1998), a low-dimensional representation of a given documentvector x can be obtained by means of the SVD de-composition depicted in (3) as follows:yT = xT UMxL , (4)where y is the L-dimensional document vector cor-responding to the projection of an M-dimensionaldocument vector x, and UMxL is a matrix contain-ing the L first column vectors of the unitary matrixU obtained from (3).Finally, the feature F(TU,IN) described in (2) isimplemented as the internal product between nor-malized versions of the vector projections obtainedin (4).
In our case, a vector-space model represen-tation is constructed for sentences, instead ofdocuments, and the source-context similarity val-ues between translation units and input sentencesare computed accordingly:F (TU, IN) = (5)<scT UMxL / |scTUMxL| , inT UMxL / |inTUMxL|>While the value of M is given by the vocabularysize in the data collection under consideration, se-veral implementation questions arise regarding themost appropriate values for N (amount of sen-tences to be used for estimating the projection op-erator U) and L (the dimensionality of the reducedspace).
These and other implementation issues arediscussed in detail in the following section.4 Implementation IssuesThis section discusses some important implemen-tation issues that have to be dealt with in order toimplement and evaluate the proposed approach.First, in subsection 4.1, the problem of implement-ing a dynamic feature in a standard phrase-basedmachine translation framework is discussed.
Then,in subsections 4.2 and 4.3, the problems of deter-mining the amount of data required for estimatingthe Latent Semantic Indexing projection operatorand the most appropriate dimensionality size forthe reduced space representation are discussed.4.1 Implementing a Dynamic FeatureAs defined in (2), the value of the proposed source-context similarity feature depends on each individ-ual input sentence to be translated by the system.This definition implies a major difference betweenthis feature and other conventional phrase-basedtranslation features: it is a dynamic feature in thesense that it cannot be computed in advance beforethe input sentences to be translated are known.This on-the-fly requirement, along with the ex-tended translation unit definition presented in (1),129makes it not possible to directly implement theproposed methodology within a standard phrase-based machine translation framework such asMOSES (Koehn et al, 2007).
As it is not our in-tention to develop a customized decoding tool forimplementing and testing our proposed feature, wefollowed or previous implementation of an off-lineversion of the proposed methodology (Costa-juss?& Banchs, 2010), which, although very inefficientin the practice, allows us to evaluate the impact ofthe source-context feature on a state-of-the-artphrase-based translation system.According to this, our practical implementationis a follows:?
Two sentence similarity matrices are com-puted: one between sentences in the devel-opment and training sets, and the otherbetween sentences in the test and trainingdatasets.?
Each matrix entry mij should contain thesimilarity score between the ith sentence inthe training set and the jth sentence in thedevelopment (or test) set.?
For each sentence s in the test and develop-ment sets, a phrase list LS of all potentialphrases that can be used during decoding isextracted from the aligned training set.?
The corresponding source-context similarityvalues are assigned to each phrase in lists LSaccording to values in the correspondingsimilarity matrices.?
Each phrase list LS is collapsed into a phrasetable TS by removing repetitions (when re-moving repeated entries in the list, the larg-est value of the source-context similarityfeature is retained).?
Each phrase table is completed by addingstandard feature values (which are computedin the standard manner).?
MOSES is used on a sentence-per-sentencebasis, using a different translation table foreach development (or test) sentence.4.2 Dataset for Latent Semantic IndexingAnother important implementation issue that re-quires attention is the computation of the SingularValue Decomposition described in (3).
Ideally, theterm-sentence matrix X to be decomposed shouldinclude all available data, i.e.
training, develop-ment and test sentences; however, in the practice,this is not possible because of two reasons.
First,the sizes of typical datasets and vocabularies usedin statistical machine translation systems are largeenough to make Singular Value Decompositionunfeasible from a computational point of view 1 .Second, in a practical application system, the ?testset?
is actually unknown during the system con-struction and training phases.
In this way, a realis-tic implementation should be able to work withpreviously unseen data.In order to overcome the problem of applyingthe Singular Value Decomposition described in (3)to the full term-sentence matrix of all availabledata, we implemented an approximated procedure.In our approximation, we compute the similaritymatrix between two set of sentences as the averageof several similarity matrices that are computedover reduced space projections estimated with dif-ferent random samples of the training data sen-tences.
In this way, our source-context similarityfeature, previously defined in (5), becomes:F (TU, IN) ?
(6)1/K ?k <scTUkMxL/|scTUkMxL| , inTUkMxL/|inTUkMxL|>where UkMxL refers to a projection operator that hasbeen computed by means of the Singular ValuedDecomposition of a term-sentence matrix Xk con-structed with a random sample of N sentences.Note that a total of K different similarity scores areaveraged in (6).In order to evaluate the variability of the similar-ity values estimated by this approximation, severalexperiments were conducted for different values ofN and L, where the variance of the estimates overK=10 different realizations were computed.
Figure1 shows the resulting standard deviations for simi-larity values estimated for different values of Lwhen varying N (upper panel), and for differentvalues of N when varying L (lower panel).As seen from the figure, the range 500<N<1000seems to constitute a good compromise betweenthe size of selected random sentence sets and theobserved variability for similarity value estimates,as it provides a significant reduction in the com-puted standard deviations with respect to N=100,and not important improvement is observed when1 Even in the case of a small dataset such as the one consid-ered here (see details in section 5) the Singular Value Decom-position of the full term-sentence matrix can take severalweeks to be completed in and standard Linux-based server.130N>1000.
According to this, we selected N=1000for our proposed approximation described in (6).Figure 1: Standard deviations (STD) for similarityvalues between development and test datasets (de-scribed in section 5) estimated for different valuesof L when varying N (upper panel), and for differ-ent values of N when varying L (lower panel).
Inall cases K=10.4.3 Reduced Space DimensionalityThe third and final implementation issue to be dis-cussed is the selection of the reduced space dimen-sionality.
It have been reported in the literature thatdimensionality reduction, by means of Latent Se-mantic Indexing, into the range between 100 and1000 provides good space representations for wordand sentence association applications (Landauer etal., 1998).
Although it is reasonable to assume thiscondition to be valid also for the application underconsideration, we conducted a more detailed ex-ploratory analysis for selecting the dimensionalityL to be used in our experiments.First, we studied the distributions of context-similarity values computed according to (6) overthe available data.
Figure 2 shows the average dis-tributions of similarities between sentences in thedevelopment and training datasets (see data de-scription in section 5) at different dimensionalityvalues.
As can be seen from the figure, a dimen-sionality value of L=100 exhibits a very nice dis-tribution of similarity values; however, accordingto the results depicted in Figure 1 (lower panel),the variability of estimates for such a low dimen-sionality is relatively high.
On the other hand, no-tice again from Figure 2, how a much largerdimensionality value such as L=5000 already startsto exhibit a distribution of similarities that is heav-ily biased towards the low similarity region.
Ac-cording to this result, and taking also into accountthe results in Figure 1, we finally decided settingthe dimensionality of the reduced space to L=500.Figure 2: Average distributions of similarity valuesbetween development and training sentences com-puted at different dimensionality values.
For allcases presented here N=500 and K=10.5 Experimental WorkThis section describes the experimental work con-ducted to evaluate the incidence of the proposedsource-context similarity feature on translationquality for a state-of-the-art phrase-based statisticalmachine translation.
First, subsection 5.1 describesthe dataset and experimental setting.
Then, subsec-tion 5.2 presents and discusses the results.5.1 Experimental SettingThe proposed methodology is evaluated on the Bi-ble dataset (Chew et al, 2006) Spanish-to-Englishtranslation task, using the MOSES framework asbaseline phrase-based statistical machine transla-tion system (Koehn et al, 2007).
Table 3 presentsthe main statistics of the bilingual corpus used.dataset lang.
sentences tokens vocab av.
lenghtTrain Spa 28,887 781,113 28,178 27Train Eng 28,887 848,776 13,126 29Test Spa 500 13,312 2,879 27Test Eng 500 14,562 2,156 29Dev Spa 500 13,170 2,862 26Dev Eng 500 14,537 2,095 29Table 3: Main statistics of the bilingual corpus un-der consideration (number of sentences, tokens,vocabulary, and average sentence length)Regarding the baseline system, we used the de-fault parameters of MOSES, which include the131grow-final-diagonal alignment symmetrisation, thelexicalized reordering, a 5-gram language modelusing Kneser-Ney smoothing, and phrases up tolength 10, among others.
The optimization wasdone using the standard MERT procedure (Och &Ney, 2002).5.2 Experimental ResultsTable 4 presents the translation BLEU, measuredover the development and test sets, for three differ-ent system implementations: the baseline system, asecond system implementing the source-contextsimilarity feature over the full-dimensional vectorspace (FVS), just as we implemented it in Costa-juss?
& Banchs (2010), and a third system imple-menting the source-context similarity feature basedon Latent Semantic Indexing (LSI).Development TestBaseline 39.92 38.92Source-context (FVS) 40.61 39.43Source-context (LSI) 40.80 39.86Table 4: BLEU scores over development and testdatasets corresponding to three system implemen-tations: baseline, and source-context similarity fea-ture at full-dimensional vector space (FVS) and bymeans of Latent Semantic Indexing (LSI).As seen from the table, the system implementingthe Latent Semantic Indexing based source-contextsimilarity feature outperforms the baseline systemby almost one absolute BLEU point, and the full-dimensional vector space system by some less thana half absolute BLEU point.
An analysis of signifi-cance (Koehn, 2004) showed that the differencesamong the systems are statistically significant.A more comprehensive manual analysis of boththe baseline and source-context LSI system outputswas required to better asses the incidence of theimplemented source-context similarity feature onthe generated translations.
The result of this analy-sis is presented in the following section.6 Manual EvaluationThis section presents and discusses the results of amanual evaluation that was conducted over a sam-ple set of translations.
Previous to the manualevaluation, we performed a sentence-based auto-matic evaluation using BLEU for the 500 sen-tences in the test dataset.
We obtained that ourproposed approach is better than the baseline sys-tem in 208 sentences, while the baseline is betterthan our system in 173 sentences and the remain-ing 119 had the same BLEU scores.Some output sentences were randomly selected,regardless of which system performed better, forconducting a manual inspection.
From these sen-tences, we have extracted some segments that illus-trate specific cases in which our proposed source-context feature is actually helping to select a bettertranslation unit according to the context of the in-put sentence being translated.
Five of these seg-ments are presented in Table 5, where the relevantfragments within the segments are shown in bold.Example 1source No des sue?o a tus ojos ni dejes dormitar tus p?rpa-dos .reference Give not sleep to thine eyes , nor slumber to thineeyelids .baseline Not sleep in thy sight , Let neither slumber thyeyelids .LSI-contextGive not sleep to thine eyes neither slumber , Letthine eyelids .Example 2source Entonces ellos se acercaron , echaron mano a Jes?sy le prendieron ?reference Then came they , and laid hands on Jesus , and tookhim ?baseline And they came near , and cast hand to Jesus , andtook him ?LSI-contextAnd they came near , and laid hands on Jesus , andtook him ?Example 3source Y al tercer d?a , he aqu?
que un hombre vino delcampamento de Sa?l ?reference It came even to pass on the third day , that , behold , aman came out of the camp from Saul ?baseline And the third day , behold , a man wine of the campof Saul ?LSI-context And the third day , behold , there came a man of thecamp of Saul ?Example 4source ?
sed confortados ; sed de un mismo sentir ?reference ?
be of good comfort , be of one mind ?baseline ?
thirst confortados ; thirst of one mind 's sake ?LSI-context ?
be ye confortados : be ye of one mind 's sake ?Example 5source ?
seg?n sus familias , seg?n sus idiomas , en susterritorios y en sus naciones .reference ?
after their families , after their tongues , in theircountries , and in their nations .baseline ?
according to their families , after their tongues , intheir coasts , and in their nations .LSI-context ?
after their families , after their tongues , in theirlands , and in their nations .Table 5: Sample segments where the LSI-basedsource-context feature has helped to accomplishbetter translation unit selections.132As seen from the table, the LSI-based source-context system is clearly accomplishing more ap-propriate unit selections.
However, in most of thecases this does not imply either a better overalltranslation or a closer match to the available refer-ence translation.
This can explain the relative lowBLEU gain achieved by the method.Similarly, we also extracted some segments thatillustrate specific cases in which our proposedsource-context feature fails in helping to select abetter translation unit.
Table 6 presents four ofthese cases.Example 1source ?
yo he sido enviado con malas noticias para ti .reference ?
for I am sent to thee with heavy tidings .baseline ?
for I have sent with evil tidings unto thee .LSI-context ?
I am sent with evil tidings unto thee .Example 2source ?
heredad de Jehovah son los hijos ; recompensa esel fruto del vientre .reference ?
children are an heritage of the Lord : and the fruitof the womb is his reward .baseline ?
the inheritance of the Lord , are the children ;reward is the fruit of the belly .LSI-context ?
the inheritance of the Lord are the children , andreward is the fruit of the belly .Example 3source ?
y que hab?a enaltecido su reino por amor a supueblo Israel .reference ?
and that he had exalted his kingdom for hispeople Israel 's sake .baseline ?
and for his kingdom was lifted up his peopleIsrael .LSI-context ?
and for his kingdom was lifted up unto hispeople Israel .Example 4source Y suceder?
que a causa de la abundancia de leche ,comer?
leche cuajada ?reference And it shall come to pass , for the abundance ofmilk that he shall eat butter ?baseline And it shall come to pass , that by reason of themultitude of milk , shall eat with milk cuajada ?LSI-context And it shall come to pass by reason of the multitudeof milk , and shall eat with milk cuajada ?Table 6: Sample segments where the LSI-basedsource-context feature has failed to accomplishbetter translation unit selections.In the latter examples in Table 6, the proposedsource-context feature is clearly failing to providebetter lexical selections.
In some cases, this seemsto be due to the lack of enough source-context in-formation in the input sentence to be translated.However, in other cases, it is because the source-context feature alone is not able to compensate thesystem?s bias towards more frequent translations.7 Conclusions and Future WorkA new semantically-motivated feature for statisti-cal machine translation based on Latent SemanticIndexing has been proposed and evaluated.
Theobjective of the proposed feature is to account forthe degree of similarity between a given input sen-tence and each individual sentence in the trainingdataset.
This similarity is computed in a reducedvector-space constructed by means of the LatentSemantic Indexing decomposition.The computed similarity values are used as anadditional feature in the log-linear model combina-tion approach to statistical machine translation.
Inour implementation, the proposed feature is dy-namically adjusted for each translation unit in thetranslation table according to the current input sen-tence to be translated.Experimental results on a Spanish-to-Englishtranslation task on the Bible corpus showed sig-nificant improvements of almost 1 and 0.5 absoluteBLEU points with respect to a baseline system anda similar system evaluating sentence similarity atthe full-dimensional vector space, respectively.
Amanual evaluation revealed that the proposed fea-ture is actually helping the translation system toperform a better selection of translation units on asemantic basis.As future work, we intend to evaluate differentassociation and distance metrics, as well as to ex-tend the current notion of source-context from theinput sentence to be translated to any other kind ofavailable information beyond the input sentencelimits.
Similarly, different paradigms of semanticspace representations, including those statisticallymotivated, will be studied and evaluated.Implementation issues are also to be revisitedfor better evaluating the impact of both the amountof training data and the dimensionality of the re-duced space on the method?s performance.
Finally,an on-line version of the method must be imple-mented in order to be able to evaluate the proposedmethodology over larger data collections.AcknowledgmentsThe authors would like to thank the Institute forInfocomm Research, as well as Barcelona MediaInnovation Centre and the Juan de la Cierva fel-lowship program, for their support and permissionto publish this work.133ReferencesBrown, P., Della-Pietra, S., Della-Pietra, V., Mercer, R.(1993) The Mathematics of Statistical MachineTranslation: Computational Linguistics 19(2), 263--311Carl, M., Way, A.
(2003) Recent Advances in Example-Based Machine Translation.
Kluwer AcademicCarpuat, M., Wu, D. (2007) How Phrase Sense Disam-biguation Outperforms Word Sense Disambiguationfor Statistical Machine Translation.
In: 11th Interna-tional Conference on Theoretical and MethodologicalIssues in Machine Translation.
SkovdeCarpuat, M., Wu, D. (2008) Evaluation of Context-Dependent Phrasal Translation Lexicons for Statisti-cal Machine Translation.
In: 6th International Con-ference on Language Resources and Evaluation(LREC).
MarrakechChew, P. A., Verzi, S. J., Bauer, T. L., McClain, J. T.(2006) Evaluation of the Bible as a Resource forCross-Language Information Retrieval.
In: Workshopon Multilingual Language Resources and Interopera-bility, pp.
68--74, SydneyCosta-juss?, M. R., Banchs, R.E.
(2010) A Vector-Space Dynamic Feature for Phrase-Based StatisticalMachine Translation.
Journal of Intelligent Informa-tion SystemsEspa?a-Bonet, C., Gimenez, J., Marquez, L. (2009)Discriminative Phrase-Based Models for Arabic Ma-chine Translation.
ACM Transactions on Asian Lan-guage Information Processing Journal (Special Issueon Arabic Natural Language Processing)Golub, G. H., Kahan, W. (1965) Calculating the Singu-lar Values and Pseudo-Inverse of a Matrix.
Journal ofthe Society for Industrial and Applied Mathematics:Numerical Analysis 2(2), 205--224Haque, R., Naskar, S. K., Ma, Y., Way, A.
(2009) UsingSupertags as Source Language Context in SMT.
In:13th Annual Conference of the European Associationfor Machine Translation, pp.
234--241.
BarcelonaHaque, R., Naskar, S. K., van den Bosh, A., Way, A.
(2010) Supertags as Source Language Context in Hi-erarchical Phrase-Based SMT.
In: 9th Conference ofthe Association for Machine Translation in theAmericas (AMTA)Koehn, P., Och, F. J., Marcu, D. (2003) StatisticalPhrase-Based Translation.
In: Human LanguageTechnology Conference and Conference on Empiri-cal Methods in Natural Language Processing (HLT-EMNLP), pp.
48--54.
EdmontonKoehn, P. (2004) Statistical Significance Test for Ma-chine Translation Evaluation.
In: Conference on Em-pirical Methods in Natural Language Processing(EMNLP)Koehn, P., Hoang, H., Birch, A., Callison-Burch, C.,Federico, M., Bertoldi, N., Cowan, B., Shen, W.,Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin,A., Herbst, E. (2007) Moses: Open Source Toolkitfor Statistical Machine Translation.
In: 45th AnnualMetting of the Association for Computational Lin-guistics, pp.
177--180.
PragueLandauer, T. K., Laham, D., Foltz, P. (1998) LearningHuman-Like Knowledge by Singular Value Decom-position: A Progress Report.
In: Conference on Ad-vances in Neural Information Processing Systems,pp.
45--51.
DenverLandauer, T. K., Foltz, P.W., Laham, D. (1998) Intro-duction to Latent Semantic Analysis.
DiscourseProcesses 25, 259--284Och, F. J., Ney, H. (2002) Discriminative Training andMaximum Entropy Models for Statistical MachineTranslation.
In: 40th Annual Meeting of the Associa-tion for Computational Linguistics, pp.
295--302Padilla, P., Bajo, T. (1998) Hacia un Modelo de Memo-ria y Atenci?n en la Interpretaci?n Simult?nea.
Quad-erns: Revista de Traducci?
2, 107--117Pearson, K. (1901) On Lines and Planes of Closest Fitto Systems of Points in Space.
Philosophical Maga-zine 2(6), 559--572Salton, G., Wong, A., Yang, C. S. (1975) A VectorSpace Model for Automatic Indexing.
Communica-tions of the ACM 18(11), 613--620134
