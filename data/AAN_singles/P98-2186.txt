Part of Speech Tagging Using a Network of Linear SeparatorsDan Roth  and Dmi t ry  ZelenkoDepartment of Computer ScienceUniversity of Illinois at Urbana-Charnpaign1304 W Springfield Ave., Urbana, IL @1801{danr, zelenko}@cs, uiuc.
eduAbstractWe present an architecture and an on-line learningalgorithm and apply it to the problem of part-of-speech tagging.
The architecture presented, SNOW,is a network of linear separators in the feature space,utilizing the Winnow update algorithm.Multiplicative weight-update algorithms uch asWinnow have been shown to have exceptionally goodbehavior when applied to very high dimensionalproblems, and especially when the target conceptsdepend on only a small subset of the features in thefeature space.
In this paper we describe an architec-ture that utilizes this mistake-driven algorithm formulti-class prediction - selecting the part of speechof a word.
The experimental nalysis presented hereprovides more evidence to that these algorithms aresuitable for natural anguage problems.The algorithm used is an on-line algorithm: everyexample is used by the algorithm only once, and isthen discarded.
This has significance in terms of ef-ficiency, as well as quick adaptation to new contexts.We present an extensive xperimental study of ouralgorithm under various conditions; in particular, itis shown that the algorithm performs comparably tothe best known algorithms for POS.1 In t roduct ionLearning problems in the natural language do-main often map the text to a space whose di-mensions are the measured features of the text,e.g., its words.
Two characteristic properties ofthis domain are that its dimensionality is veryhigh and that both the learned concepts andthe instances reside very sparsely in the featurespace.
In this paper we present a learning algo-r ithm and an architecture with properties uit-able for this domain.The SNOW algorithm presented here buildson recently introduced theories of multiplicativeweight-updating learning algorithms for linearfunctions.
Multiplicative weight-updating al-gorithms such as Winnow (Littlestone, 1988)and Weighted Majority (Littlestone and War-muth, 1994) have been studied extensively inthe COLT literature.
Theoretical analysis hasshown that they have exceptionally good be-havior in the presence of irrelevant attributes,noise, and even a target function changing intime (Littlestone, 1988; Littlestone and War-muth , 1994; Herbster and Warmuth, 1995).Only recently have people started to testthese claimed abilities in applications.
Weaddress these claims empirically by applyingSNOW to one of the fundamental disambigua-tion problems in natural language: part-ofspeech tagging.Part of Speech tagging (POS) is the problemof assigning each word in a sentence the part ofspeech that it assumes in that sentence.
Theimportance of the problem stems from the factthat POS is one of the first stages in the processperformed by various natural language relatedprocesses such as speech, information extractionand others.The architecture presented here, SNOW, isa Sparse Network Of Linear separators whichutilizes the Winnow learning algorithm.
A tar-get node in the network corresponds to a can-didate in the disambiguation task; all subnet-works learn autonomously from the same datain an online fashion, and at run time, they com-pete for assigning the correct meaning.
A sim-ilar architecture which includes an additionallayer is described in (Golding and Roth, 1998).The POS problem suggests a special challengeto this approach.
First, the problem is a multi-class prediction problem.
Second, determiningthe POS of a word in a sentence may dependon the POS of its neighbors in the sentence,but these are not known with any certainty.
Inthe SNOW architecture, we address these prob-lems by learning at the same time and from the1136same input, a network of many classifiers.
Eachsub-network is devoted to a single POS tag andlearns to separate its POS tag from all others.At run time, all classifiers are applied simulta-neously and compete for deciding the POS ofthis word.We present an extensive set of experimentsin which we study some of the properties thatSNOWexhibits on this problem, as well as com-pare it to other algorithms.
In our first ex-periment, for example, we study the quality ofthe learned classifiers by, artificially, supplyingeach classifier with the correct POS tags of itsneighbors.
We show that under these conditionsour classifier is almost perfect.
This observa-tion motivates an improvement in the algorithmwhich aims at trying to gradually improve theinput supplied to the classifier.We then perform a preliminary study of learn-ing the POS tagger in an unsupervised fashion.We show that we can reduce the requirementsfrom the training corpus to some degree, but donot get good results, so far, when it is trainedin a completely unsupervised fashion.Unlike most of the algorithms tried on thisand other disambiguation tasks, SNOW is anonline learning algorithm.
That is, duringtraining, every example is used once to updatethe learned hypothesis, and is then discarded.While on-line learning algorithms may be at dis-advantage because they see each example onlyonce, the algorithms are able to adapt o testingexamples by receiving feedback after prediction.We evaluate this claim for the POS task, anddiscover that indeed, allowing feedback whiletesting, significantly improves the performanceof SNOWon this task.Finally, we compare our approach to a state-of-the-art agger, based on Brill's transforma-tion based approach; we show that SNOW-based taggers already achieve results that arecomparable to it, and outperform it, when weallow online update.Our work also raises a few methodologicalquestions with regard to the way we measurethe performance of algorithms for solving thisproblem, and improvements hat can be madeby better defining the goals of the tagger.The paper is organized as follows.
We startby presenting the SNOW approach.
We thendescribe our test task, POS tagging, and theway we model it, and in Section 5 we describeour experimental studies.
We conclude by dis-cussing the significance of the approach to fu-ture research on natural anguage inferences.In the discussion below, s is an input example,zi's denote the features of the example, and c, trefer to parts of speech from a set C of possiblePOS tags.2 The  SNOW ApproachThe SNOW (Sparse Network Of Linear sepa-rators) architecture is a network of thresholdgates.
Nodes in the first layer of the networkrepresent the input features; target nodes (i.e.,the correct values of the classifier) are repre-sented by nodes in the second layer.
Links fromthe first to the second layer have weights; eachtarget node is thus defined as a (linear) functionof the lower level nodes.For example, in POS, target nodes corre-spond to different part-of-speech tags.
Each tar-get node can be thought of as an autonomousnetwork, although they all feed from the sameinput.
The network is sparse in that a targetnode need not be connected to all nodes in theinput layer.
For example, it is not connectedto input nodes (features) that were never activewith it in the same sentence, or it may decide,during training, to disconnect i self from someof the irrelevant input nodes, if they were notactive often enough.Learning in SNOW proceeds in an on-line fashion.
Every example is treated au-tonomously by each target subnetworks.
It isviewed as a positive example by a few of theseand a negative xample by the others.
In theapplications described in this paper, every la-beled example is treated as positive by the tar-get node corresponding to its label, and as neg-ative by all others.
Thus, every example isused once by all the nodes to refine their def-inition in terms of the others and is then dis-carded.
At prediction time, given an input sen-tence s = (Zl, z2, .
.
.zm),  (i.e., activating a sub-set of the input nodes) the information propa-gates through all the competing subnetworks;and the one which produces the highest activ-ity gets to determine the prediction.A local learning algorithm, Littlestone's Win-now algorithm (Littlestone, 1988), is used ateach target node to learn its dependence on1137other nodes.
Winnow has three parameters: athreshold 0, and two update parameters, a pro-motion parameter c~ > 1 and a demotion pa-rameter 0 < /3 < 1.
Let ~4= {ix, .
.
.
, im} bethe set of active features that are linked to (aspecific) target node.The algorithm predicts 1 (positive) iff~'\]ie~4wi > 0, where wl is the weight on theedge connecting the ith feature to the targetnode.
The algorithm updates its current hy-pothesis (i.e., weights) only when a mistakeis made.
If the algorithm predicts 0 and thereceived label is 1 the update is (promotion)Vi E .A, wi +-- ~ ?
wi.
If the algorithm predicts1 and the received label is 0 the update is (de-motion) Vi E ~4, wi +--/3 ?
wi.
For a study of theadvantages of Winnow, see (Littlestone, 1988;Kivinen and Warmuth, 1995).3 The  POS Prob lemPart of speech tagging is the problem of iden-tifying parts of speech of words in a pre-sented text.
Since words are ambiguous interms of their part of speech, the correct partof speech is usually identified from the con-text the word appears in.
Consider for ex-ample the sentence The can will rust.
Bothcan and rust can accept modal-verb, normand verb as possible POS tags (and a fewmore); rust can be tagged both as noun andverb.
This leads to many possible POS tag-ging of the sentence one of which, determiner,noun, modal-verb, verb, respectively, is cor-rect.
The problem has numerous applicationin information retrieval, machine translation,speech recognition, and appears to be an im-portant intermediate stage in many natural lan-guage understanding related inferences.In recent years, a number of approaches havebeen tried for solving the problem.
The mostnotable methods are based on Hidden MarkovModels(HMM)(Kupiec, 1992; Schiitze, 1995),transformation rules(Brill, 1995; Brill, 1997),and multi-layer neural networks(Schmid, 1994).HMM taggers use manually tagged trainingdata to compute statistics on features.
Forexample, they can estimate lexical probabili-ties Prob(wordlta9) and contextual probabili-ties Prob( tag lprev ious  n tags).
On the testingstage, the taggers conduct a search in the spaceof POS tags to arrive at the most probable POSlabeling with respect o the computed statistics.That is, given a sentence, the taggers assign inthe sentence a sequence of tags that maximizethe product of lexical and contextual probabil-ities over all words in the sentence.Transformation based learning(TBL) (Brill,1995) is a machine learning approach for rulelearning.
The learning procedure is a mistake-driven algorithm that produces a set of rules.The hypothesis of TBL  is an ordered list oftransformations.
A t ransformation is a rulewith an antecedent t and a consequent c E C.The antecedent t is a condition on the input sen-tence.
For example, a condition might be thepreced ing  word tag  is  t. That is, applyingthe condition to a sentence s defines a featuret(s) E jr.
Phrased differently, the applicationof the condition to a given sentence s, checkswhether the corresponding feature is active inthis sentence.
The condition holds if and onlyif the feature is active in the sentence.The TBL hypothesis i  evaluated as follows:given a sentence s, an initial labeling is assignedto it.
Then, each rule is applied, in order, to thesentence.
If the condition of the rule applies,the current label is replaced by the label in theconsequent.
This process goes on until the lastrule in the list is evaluated.
The last labeling isthe output of the hypothesis.In its most general setting, the TBL hypoth-esis is not a classifier (Brill, 1995).
The reasonis that, in general, the truth value of the condi-tion of the ith rule may change while evaluatingone of the preceding rules.
For example, in partof speech tagging, labeling a word with a part ofspeech changes the conditions of the followingword that depend on that part of speech(e.g.,the preceding word tag is t).TBL uses a manually-tagged corpus for learn-ing the ordered list of transformations.
Thelearning proceeds in stages, where on each stagea transformation is chosen to minimize the num-ber of mislabeled words in the presented cor-pus.
The transformation is then applied, andthe process is repeated until no more mislabel-ing minimization can be achieved.For example, in POS, the consequence of atransformation labels a word with a part ofspeech.
(Brill, 1995) uses lexicon for initial an-notation of the training corpus, where each wordin the lexicon has a set POS tags seen for the1138word in the training corpus.
Then a search inthe space of transformations is conducted to de-termine a transformation that most reduces thenumber of wrong tags for the words in the cor-pus.
The application of the transformation tothe initially labeled produces another labeling ofthe corpus with a smaller number of mistakes.Iterating this procedure leads to learning an or-dered list of transformation which can be usedas a POS tagger.There have been attempts to apply neuralnetworks to POS tagging(e.g.,(Schmid, 1994)).The work explored multi-layer network archi-tectures along with the back-propagation algo-r ithm on the training stage.
The input nodesof the network usually correspond to the tags ofthe words surrounding the word being tagged.The performance of the algorithms i  compara-ble to that of HMM methods.In this paper, we address the POS problemwith no unknown words (the closed world as-sumption) from the standpoint of SNOW.
Thatis, we represent a POS tagger as a network oflinear separators and use Winnow for learningweights of the network.
The SNOW approachhas been successfully applied to other prob-lems of natural language processing(Goldingand Roth, 1998; Krymolowski and Roth, 1998;Roth, 1998).
However, this problem offers ad-ditional challenges to the SNOW architectureand algorithms.
First, we are trying to learna multi-class predictor, where the number ofclasses is unusually large(about 50) for suchlearning problems.
Second, evaluating hypoth-esis in testing is done in a presence of attributenoise.
The reason is that input features of thenetwork are computed with respect o parts ofspeech of words, which are initially assignedfrom a lexicon.We address the first problem by restrictingthe parts of speech a tag for a word is selectedfrom.
Second problem is alleviated by perform-ing several labeling cycles on the testing corpus.4 The  Tagger  NetworkThe tagger network consists of a collection oflinear separators, each corresponds to a distinctpart of speech 1 .
The input nodes of the net-work correspond to the features.
The featuresare computed for a fixed word in a sentence.
We1The 50 parts are taken from the WSJ corpususe the following set of features2:(1) The preceding word is tagged c.(2) The following word is tagged e.(3) The word two before is tagged c.(4) The word two after is tagged c.(5) The preceding word is tagged c and the fol-lowing word is tagged t.(6) The preceding word is tagged c and the wordtwo before is tagged t.(7) The following word is tagged c and the wordtwo after is tagged t.(8) The current word is w.(9) The most probable part of speech for thecurrent word is c.The most probable part of speech for a wordis taken from a lexicon.
The lexicon is a list ofwords with a set of possible POS tags associatedwith each word.
The lexicon can be computedfrom available labeled corpus data, or it can rep-resent the a-priori information about words inthe language.Training of the SNOW tagger network pro-ceeds as follows.
Each word in a sentence pro-duces an example.
Given a sentence, featuresare computed with respect o each word therebyproducing a positive examples for the part ofspeech the word is labeled with, and the nega-tive examples for the other parts of speech.
Thepositive and negative xamples are presented tothe corresponding subnetworks, which updatetheir weights according to Winnow.In testing, this process is repeated, producinga test example for each word in the sentence.
Inthis case, however, the POS tags of the neigh-boring words are not known and, therefore, themajority of the features cannot be evaluated.We discuss later various ways to handle thissituation.
The default one is to use the base-line tags - the most common POS for this wordin the training lexicon.
Clearly this is not ac-curate, and the classification can be viewed asdone in the presence of attribute noise.Once an example is produced, it is then pre-sented to the networks.
Each of the subnet-works is evaluated and we select the one withthe highest level of activation among the separa-tors corresponding to the possible tags for thecurrent word.
After every prediction, the tagoutput by the SNOW tagger for a word is usedfor labeling the word in the test data.
There-~The features I-8 are part of (Brill, 1995) features1139fore, the features of the following words will de-pend on the output ags of the preceding words.5 Exper imenta l  Resu l t sThe data for all the experiments was extractedfrom the Penn Treebank WSJ corpus.
Thetraining and test corpus consist of 600000 and150000, respectively.
The first set of experi-ment uses only the SNOW system and eval-uate its performance under various conditions.In the second set SNOW is compared with anaive Bayes algorithm and with Brill's TBL,all trained and tested on the same data.
Wealso compare with Baseline which simply as-signs each word in the test corpus its most com-mon POS in the lexicon.
Baseline performanceon our test corpus is 94.1%.A lexicon is computed from both the train-ing and the test corpus.
The lexicon has 81227distinct words, with an average of 2.2 possiblePOS tags per word in the lexicon.5.1 Investigating SNO WWe first explore the ability of the network toadapt to new data.
While online algorithms areat a disadvantage - each example is processedonly once before being discarded - they have theadvantage of (in principle) being able to quicklyadapt to new data.
This is done within SNOWby allowing it to update its weights in test mode.That is, after prediction, the network receives alabel for a word, and then uses the label forupdating its weights.In test mode, however, the true tag is notavailable to the system.
Instead, we used asthe feedback label the corresponding baselinetag taken from the lexicon.
In this way, thealgorithm never uses more information than isavailable to batch algorithms tested on the samedata.
The intuition is that, since the baselineitself for this task is fairly high, this informa-tion will allow the tagger to better tolerate newtrends in the data and steer the predictors in theright direction.
This is the default system thatwe call SNOW in the discussion that follows.Another policy with on-line algorithms is tosupply it with the true feedback, when it makesa mistake in testing.
This policy (termed adp-SNOW) is especially useful when the test datacomes from a different source than the train-ing data, and will allow the algorithm to adaptto the new context.
For example, a languageacquisition system with a tagger trained on ageneral corpus can quickly adapt to a specificdomain, if allowed to use this policy, at leastoccasionally.
What we found surprising is thatin this case supplying the true feadback didnot improve the performance of SNOW signifi-cantly.
Both on-line methods though, performsignificantly better than if we disallow on-lineupdate, as we did for noadp-SNOW.
The re-sults, presented in table 1, exhibit the advan-tage of using an on-line algorithm.96.5 97.13 97.2Table 1: Effect o f  adaptat ion :  Per-formance of the tagger network with noadaptation(noadp-SNOW), baseline adap-tation(SNOH0, and true adaptation(adp-SNOW).One difficulty in applying the SNOW ap-proach to the POS problem is the problem ofattribute noise alluded to before.
Namely, theclassifiers receive a noisy set of features as in-put due to the attribute dependence on (un-known) tags of neighboring words.
We addressthis by studying quality of the classifier, whenit is guaranteed to get (almost) correct input.Table 2 summarizes the effects of this noise onthe performance.
Under SNOW we give the re-sults under normal conditions, when the the fea-tures of the each example are determined basedon the baseline tags.
Under SNOW-i-cr we de-termine the features based on the correct tags,as read from the tagged corpus.
One can seethat this results in a significant improvement,indicating that the classifier learned by SNOWis almost perfect.
In normal conditions, though,it is affected by the attribute noise.Baseline\[SNOW+crISNOW \[94.t 98.8 97.13 _lTable 2: Qua l i ty  of  classifier" The SNOWtagger was tested with correct initial tags(SNOW+cr) and, as usual, with baseline basedinitial tags.Next, we experimented with the sensitivity ofSNOW to several options of labeling the train-ing data.
Usually both features and labels ofthe training examples are computed in terms of1140correct parts of speech for words in the trainingcorpus.
We call the labeling Semi-supervisedwhen we only require the features of the train-ing examples to be computed in terms of themost probable pos for words in the training cor-pus, but the labels still correspond to the correctparts of speech.
The labeling is Unsupervisedwhen both features and labels of the trainingexamples are computed in terms of most prob-able POS of words in the training corpus.i Baseline \[S OW uns J S OW ss I94.1 94.3 97.13 97.13Table 3: Effect o f  superv is ion .
Performanceof SNOW with unsupervised (SNOW+uns),semi-supervised (SNOW+ss) and normal modeof supervised training.It is not surprising that the performance ofthe tagger learned in an semi-supervised fash-ion is the same as that of the one trained fromthe correct corpus.
Intuitively, since in the teststage the input to the classifier uses the base-line classifier, in this case there is a better fitbetween the data supplied in training (with acorrect feedback!)
and the one used in testing.5.2 Comparat ive  StudyWe compared performance of the SNOW tag-ger with one of the best POS taggers, based onBrill's TBL, and with a naive Bayes (e.g.,(Dudaand Hart, 1973) based tagger.
We used thesame training and test sets.
The results aresummarized in table 4.\[ BaselinelNB I TBL I SNOWladp-SNOW I94.1 96 97.15 97.13 97.2Table 4: Compar i son  of  tagg ing  perfor -mance ,In can be seen that the TBL tagger andSNOW perform essentially the same.
However,given that SNOW is an online algoril:hm, wehave tested it also in its (true feedback) adap-tive mode, where it is shown to outperformthem.
It is interesting to note that a simpleminded NB method also performs quite well.Another important point of comparison isthat the NB tagger and the SNOW taggers aretrained with the features described in section 4.TBL, on the other hand, uses a much largerset of features.
Moreover, the learning andtagging mechanism in TBL relies on the inter-dependence between the produced labels andthe features.
However, (Ramshaw and Marcus,1996) demonstrate that the inter-dependenceimpacts only 12% of the predictions.
Since theclassifier used in TBL without inter-dependencecan be represented as a linear separator(Roth,1998), it is perhaps not surprising that SNOWperforms as well as TBL.
Also, the success of theadaptive SNOWtaggers shows that we can alle-viate the lack of the inter-dependence by adap-tation to the testing corpus.
It also highlightsimportance of relationship between a tagger anda corpus.5.3 Alternative Performance MetricsOut of 150000 words in the test corpus usedabout 65000 were non-ambiguous.
That is, theycan assume only one POS.
Incorporating thesein the performance measure is somewhat mis-leading since it does not provide a good measureof the classifier performance.Table 5: Per fo rmance  for ambiguouswords.Sometimes we may be interested in determin-ing POS classes of words rather than simplyparts of speech.
For example, some natural an-guage applications may require identifying thata word is a noun without specifying the exactnoun tag for the word(singular, plular, proper,etc.).
In this case, we want to measure perfor-mance with respect o POS classes.
That is, ifthe predicted part of speech for a word is in thesame class with the correct tag for the word,then the prediction is termed correct.Out of 50 POS tags we created 12POS classes: punctuation marks, determin-ers, preposition and conjunctions, existentials"there", foreign words, cardinal numbers andlist markers, adjectives, modals, verbs, adverbs,particles, pronouns, nouns, possessive ndings,interjections.
The performance results for theclasses are shown in table 5.3.In analyzing the results, one can see thatmany of the mistakes of the tagger are "within"classes.
We are currently exploring a few is-sues that may allow us to use class information,within SNO W, to improve tagging accuracy.
In114196.2 97 97.95 97.95 98Table 6: Per fo rmance  for POS classes.particular, we can incorporate POS classes intoour SNOW tagger network.
We can create an-other level of output nodes.
Each of the nodeswill correspond to a POS class and will be con-nected to the output nodes of the POS tags inthe class.
The update mechanism of networkwill then be made dependent on both class andtag prediction for a word.6 Conc lus ionA Winnow-based network of linear separatorswas shown to be very effective when applied toPOS tagging.
We described the SNOW archi-tecture and how to use it for POS tagging andfound that although the algorithm is an on-linealgorithm, with the advantages this carries, itsperformance is comparable to the best taggersavailable.This work opens a variety of questions.
Someare related to further studying this approach,based on multiplicative update algorithms, andusing it for other natural anguage problems.More fundamental, we believe, are thosethat are concerned with the general earningparadigm the SNOW architecture proposes.A large number of different kinds of ambigu-ities are to be resolved simultaneously in per-forming any higher level natural anguage infer-ence (Cardie, 1996).
Naturally, these processes,acting on the same input and using the same"memory", will interact.
In SNO W, a collectionof classifiers are used; all are learned from thesame data, and share the same "memory".
Inthe study of SNOWwe embark on the study ofsome of the fundamental issues that are involvedin putting together a large number of classifiersand investigating the interactions among them,with the hope of making progress towards usingthese in performing higher level inferences.Re ferencesE.
Brill.
1995.
Transformation-based rror-driven learning and natural anguage process-ing: A case study in part of speech tagging.Computational Linguistics, 21 (4) :543-565.E.
Brill.
1997.
Unsupervised learning of dis-ambiguation rules for part of speech tagging.In Natural Language Processing Using VeryLarge Corpora.
Kluwer Academic Press.C.
Cardie, 1996.
Embedded Machine LearningSystems for natural language processing: Ageneral framework, pages 315-328.
Springer.R.
Duda and P. Hart.
1973.
Pattern Classifica-tion and Scene Analysis.
Wiley.A.
R. Golding and D. Roth.
1998.
A winnowbased approach to context-sensitive spellingcorrection.
Machine Learning.
Special issueon Machine Learning and Natural Language;.
Preliminary version appeared in ICML-96.M.
Herbster and M. Warmuth.
1995.
Trackingthe best expert.
In Proc.
12th InternationalConference on Machine Learning, pages 286-294.
Morgan Kaufmann.J.
Kivinen and M. Warmuth.
1995.
Exponenti-ated gradient versus gradient descent for lin-ear predictors.
In Proceedings of the AnnualA CM Syrup.
on the Theory of Computing.Y.
Krymolowski and D. Roth.
1998.
Incorpo-rating knowledge in natural language learn-ing: A case study.
COLING-ACL Workshop.J.
Kupiec.
1992.
Robust part-of-speech tag-ging using a hidden makov model.
ComputerSpeech and Language, 6:225-242.N.
Littlestone and M. K. Warmuth.
1994.
Theweighted majority algorithm.
Informationand Computation, 108(2):212-261.N.
Littlestone.
1988.
Learning quickly whenirrelevant attributes abound: A new lin-ear threshold algorithm.
Machine Learning,2(4) :285-318, April.L.
A. Ramshaw and M. P. Marcus.
1996.
Ex-ploring the nature of transformation-basedlearning.
In J. Klavans and P. Resnik, ed-itors, The Balancing Act: Combining Sym-bolic and Statistical Approaches to Language.MIT Press.D.
Roth.
1998.
Learning to resolve natural an-guage ambiguities: A unified approach.
InProc.
National Conference on Artificial Intel-ligence.H.
Schmid.
1994.
Part-of-speech tagging withneural networks.
In COLING-94.H.
Schfitze.
1995.
Distributional part-of-speechtagging.
In Proceedings of the 7th Conferenceof the European Chapter of the Associationfor Computational Linguistics.1142
