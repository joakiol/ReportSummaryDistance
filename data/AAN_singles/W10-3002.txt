Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 13?17,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsA Cascade Method for Detecting Hedges and their Scope in NaturalLanguage TextBuzhou Tang, Xiaolong Wang, Xuan Wang, Bo Yuan, Shixi FanKey Laboratory of Network Oriented Intelligent ComputationHarbin Institute of Technology Shenzhen Graduate SchoolShenzhen, Guangdong, China{tangbuzhou,yuanbo.hitsz}@gmail.com{wangxl,wangxuan,fanshixi}@insun.hit.edu.cnAbstractDetecting hedges and their scope in nat-ural language text is very important forinformation inference.
In this paper,we present a system based on a cascademethod for the CoNLL-2010 shared task.The system composes of two components:one for detecting hedges and another onefor detecting their scope.
For detectinghedges, we build a cascade subsystem.Firstly, a conditional random field (CRF)model and a large margin-based model aretrained respectively.
Then, we train an-other CRF model using the result of thefirst phase.
For detecting the scope ofhedges, a CRF model is trained accordingto the result of the first subtask.
The ex-periments show that our system achieves86.36% F-measure on biological corpusand 55.05% F-measure on Wikipedia cor-pus for hedge detection, and 49.95% F-measure on biological corpus for hedgescope detection.
Among them, 86.36%is the best result on biological corpus forhedge detection.1 IntroductionHedge cues are very common in natural languagetext.
Vincze et al (2008) report that 17.70% ofthe sentences in the abstract section and 19.94% ofsentences in the full paper section contain hedgeson BioScope corpus.
As Vincze et al (2008)suggest that information that falls in the scopeof hedges can not be presented as factual in-formation.
Detecting hedges and their scope innatural language text is very important for in-formation inference.
Recently, relative researchhas received considerable interest in the biomed-ical NLP community, including detecting hedgesand their in-sentence scope in biomedical texts(Morante and Daelemans, 2009).
The CoNLL-2010 has launched a shared task for exploiting thehedge scope annotated in the BioScope (Vincze etal., 2008) and publicly available Wikipedia (Gan-ter and Strube, 2009) weasel annotations.
Theshared task contains two subtasks (Farkas et al,2010): 1. learning to detect hedges in sentences onBioScope and Wikipedia; 2. learning to detect thein-sentence scope of these hedges on BioScope.In this paper, we present a system based on acascade method for the CoNLL-2010 shared task.The system composes of two components: onefor detecting hedges and another one for detect-ing their scope.
For detecting hedges, we builda cascade subsystem.
Firstly, conditional ran-dom field (CRF) model and a large margin-basedmodel are trained respectively.
Then, we trainanother CRF model using the result of the firstphase.
For detecting the scope of hedges, a CRFmodel is trained according to the result of the firstsubtask.
The experiments show that our systemachieves 86.36% F-measure on biological corpusand 55.05% F-measure on Wikipedia corpus forhedge detection, and 49.95% F-measure on bio-logical corpus for hedge scope detection.
Amongthem, 86.36% is the best result on biological cor-pus for hedge detection.2 System DescriptionAs there are two subtasks, we present a systembased on a cascade supervised machine learningmethods for the CoNLL-2010 shared task.
The ar-chitecture of our system is shown in Figure 1.The system composes of two subsystems fortwo subtasks respectively, and the first subsystemis a two-layer cascaded classifier.2.1 Hedge DetectionThe hedges are represented by indicating whethera token is in a hedge and its position in theCoNLL-2010 shared task.
Three tags are used for13Figure 1: System architecturethis scheme, where O cue indicates a token out-side of a hedge, B cue indicates a token at thebeginning of a hedge and I cue indicates a to-ken inside of a hedge.
In this subsystem, we dopreprocessing by GENIA Tagger (version 3.0.1)1at first, which does lemma extraction, part-of-speech (POS), chunking and named entity recog-nition (NER) for feature extraction.
For the out-put of GENIA Tagger, we convert the first charof a lemma into lower case and BIO chunk taginto BIOS chunk tag, where S indicates a tokenis a chunk, B indicates a token at the beginningof a chunk, I indicates a token inside of a chunk,and O indicates a token outside of a chunk.
Thena two-layer cascaded classifier is built for pre-diction.
There are a CRF classifier and a largemargin-based classifier in the first layer and a CRFclassifier in the second layer.In the first layer, the following features are usedin our system:?
Word andWord Shape of the lemma: we usedthe similar scheme as shown in (Tsai et al,2005).1http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/?
Prefix and Suffix with length 3-5.?
Context of the lemma, POS and the chunk inthe window [-2,2].?
Combined features including L0C0, LiP0and LiC0, where ?1 ?
i ?
1 L denotes thelemma of a word, P denotes a POS and Cdenotes a chunk tag.?
The type of a chunk; the lemma and POS se-quences of it.?
Whether a token is a part of the pairs ?neither... nor?
and ?either ... or?
as both tokens of apair are always labeled with the same tag.?
Whether a token can possibly be classifiedinto B cue, I cue or O cue; its lemma, POSand chunk tag for each possible case: thesefeatures are extracted according to a dictio-nary extracted from training corpus, whichlists all possible hedge tag for each word inthe training corpus.In the second layer, we used some featuresabout the result of the last layer besides those men-tioned above.
They are listed as follow:?
The lemma and POS sequences of the hedgepredicted by each classifier.?
The times of a token classified into B cue,I cue and O cue by the first two classifiers.?
Whether a token is the last token of the hedgepredicted by each classifier.2.2 Hedge Scope DetectionWe follow the way of Morante and Daelemans(2009) to represent the scope of a hedge, whereF scope indicates a token at the beginning of ascope sequence, L scope indicates a token at thelast of a scope sequence, and NONE indicatesothers.
In this phase, we do preprocessing byGDep Tagger (version beta1)2 at first, which doeslemma extraction, part-of-speech (POS), chunk-ing, named entity recognition (NER) and depen-dency parse for feature extraction.
For the out-put of GDep Tagger, we deal with the lemma andchunk tag using the same way mentioned in thelast section.
Then, a CRF classifier is built for pre-diction, which uses the following features:2http://www.cs.cmu.edu/ sagae/parser/gdep14?
Word.?
Context of the lemma, POS, the chunk, thehedge and the dependency relation in thewindow [-2,2].?
Combined features including L0C0,L0H0, L0D0, LiP0, PiC0,PiH0, CiH0,PiD0,CiD0, where ?1 ?
i ?
1 L denotesthe lemma of a word, P denotes a POS, Cdenotes a chunk tag, H denotes a hedge tagand D denotes a dependency relation tag.?
The type of a chunk; the lemma and POS se-quences of it.?
The type of a hedge; the lemma, POS andchunk sequences of it.?
The lemma, POS, chunk, hedge and depen-dency relation sequences of 1st and 2nd de-pendency relation edges; the lemma, POS,chunk, hedge and dependency relation se-quences of the path from a token to the root.?
Whether there are hedges in the 1st, 2nd de-pendency relation edges or path from a tokento the root.?
The location of a token relative to the nega-tion signal: previous the first hedge, in thefirst hedge, between two hedge cues, in thelast hedge, post the last hedge.At last, we provided a postprocessing systemfor the output of the classifier to build the com-plete sequence of tokens that constitute the scope.We applied the following postprocessing:?
If a hedge is bracketed by a F scope and aL scope, its scope is formed by the tokens be-tween them.?
If a hedge is only bracketed by a F scope, andthere is no L scope in the sentence, we searchthe first possible word from the end of thesentence according to a dictionary, which ex-tracted from the training corpus, and assign itas L scope.
The scope of the hedge is formedby the tokens between them.?
If a hedge is only bracketed by a F scope, andthere are at least one L scope in the sentence,we think the last L scope is the L scope of thehedge, and its scope is formed by the tokensbetween them.?
If a hedge is only bracketed by a L scope,and there is no F scope in the sentence, wesearch the first possible word from the begin-ning of the sentence to the hedge according tothe dictionary, and assign it as F scope.
Thescope of the hedge is formed by the tokensbetween them.?
If a hedge is only bracketed by a L scope,and there are at least one F scope in the sen-tence, we search the first possible word fromthe hedge to the beginning of the sentence ac-cording to the dictionary, and think it as theF scope of the hedge.
The scope of the hedgeis formed by the tokens between them.?
If a hedge is bracketed by neither of them, weremove it.3 Experiments and ResultsTwo annotated corpus: BioScope and Wikipediaare supplied for the CoNLL-2010 shared task.
TheBioScope corpus consists of two parts: biologicalpaper abstracts and biological full papers, and itis used for two subtasks.
The Wikipedia corpus isonly used for hedge detection.
The detailed infor-mation of these two corpora is shown in Table 1and Table 2, respectively.Abstracts Papers Test#Documents 1273 9 15#Sentences 11871 2670 5003%Hedge sent.
17.70 19.44 15.75#Hedges 2694 682 1043#AvL.
of sent.
30.43 27.95 31.30#AvL.
of scopes 17.27 14.17 17.51Table 1: The detailed information of BioScopecorpus.
?AvL.?
stands for average length.Train Test#Documents 2186 2737#Sentences 11111 9634%Hedge sentences 22.36 23.19#Hedges 3133 3143#AvL.
of sentences 23.07 20.82Table 2: The detail information of Wikipedia cor-pus.
?AvL.?
stands for average length.In our experiments, CRF++-0.533 implemen-3http://crfpp.sourceforge.net/15tation is employed to CRF, and svm hmm 3.104implementation is employed to the large marginmethod.
All parameters are default except C(the trade-off between training error and margin,C=8000, for selecting C, the training corpus is par-titioned into three parts, two of them are used fortraining and the left one is used as a developmentdataset) in svm hmm.
Both of them are state-of-the-art toolkits for the sequence labeling problem.3.1 Hedge DetectionWe first compare the performance of each singleclassifier with the cascaded system on two corporain domain, respectively.
Each model is trained bywhole corpus, and the performance of them wasevaluated by the official tool of the CoNLL-2010shared task.
There were two kinds of measure:one for sentence-level performance and anotherone for cue-match performance.
Here, we onlyfocused on the first one, and the results shown inTable 3.Corpus System Prec.
Recall F1CRF 87.12 86.46 86.79BioScope LM 85.24 87.72 86.46CAS 85.03 87.72 86.36CRF 86.10 35.77 50.54Wikipedia LM 82.28 41.36 55.05CAS 82.28 41.36 55.05Table 3: In-sentence performance of the hedgedetection subsystem for in-domain test.
?Prec.
?stands for precision, ?LM?
stands for large mar-gin, and ?CAS?
stands for cascaded system.From Table 3, we can see that the cascaded sys-tem is not better than other two single classifiersand the single CRF classifier achieves the best per-formance with F-measure 86.79%.
The reason forselecting this cascaded system for our final sub-mission is that the cascaded system achieved thebest performance on the two training corpus whenwe partition each one into three parts: two of themare used for training and the left one is used fortesting.For cross-domain test, we train a cascaded clas-sifier using BioScope+Wikipedia cropus.
Table 4shows the results.As shown in Table 5, the performance of cross-domain test is worse than that of in-domain test.4http://www.cs.cornell.edu/People/tj/svm light/svm-hmm.htmlCorpus Precision Recall F1BioScope 89.91 73.29 80.75Wikipedia 81.56 40.20 53.85Table 4: Results of the hedge detection for cross-domain test.
?LM?
stands for large margin, and?CAS?
stands for cascaded system.3.2 Hedge Scope DetectionFor test the affect of postprocessing for hedgescope detection, we test our system using two eval-uation tools: one for scope tag and the other onefor sentence-level scope (the official tool).
In or-der to evaluate our system comprehensively, fourresults are used for comparison.
The ?gold?
is theperformance using golden hedge tags for test, the?CRF?
is the performance using the hedge tagsprediction of single CRF for test, the ?LM?
is theperformance using the hedge tag prediction of sin-gle large margin for test, and ?CAS?
is the per-formance of using the hedge tag prediction of cas-caded subsystem for test.
The results of scope tagand scope sentence-level are listed in Table 5 andTable 6, respectively.
Here, we should notice thatthe result listed here is different with that submit-ted to the CoNLL-2010 shared task because someerrors for feature extraction in the previous systemare revised here.HD tag Precision Recall F1F scope 92.06 78.83 84.94gold L scope 80.56 68.67 74.14NONE 99.68 99.86 99.77F scope 78.83 66.89 72.37CRF L scope 72.52 60.50 65.97NONE 99.56 99.75 99.65F scope 77.25 67.57 72.09LM L scope 72.33 61.41 66.42NONE 99.56 99.73 99.31F scope 77.32 67.86 72.29CAS L scope 72.00 61.29 66.22NONE 99.57 99.73 99.65Table 5: Results of the hedge scope tag.
?HD?stands for hedge detection subsystem we used,?LM?
stands for large margin, and ?CAS?
standsfor cascaded system.As shown in Table 5, the performance ofL scope is much lower than that of F scope.Therefore, the first problem we should solve is16HD subsystem Precision Recall F1gold 57.92 55.95 56.92CRF 52.36 48.40 50.30LM 51.06 48.89 49.95CAS 50.96 48.98 49.95Table 6: Results of the hedge scope in-sentence.?HD?
stands for hedge detection subsystem weused, ?LM?
stands for large margin, and ?CAS?stands for cascaded system.how to improve the prediction performance ofL scope.
Moreover, compared the performanceshown in Table 5 and 6, about 15% (F1 of L scopein Table 5 - F1 in Table 6) scope labels are mis-matched.
An efficient postprocessing is needed todo F-L scope pair match.As ?CRF?
hedge detection subsystem is bet-ter than the other two subsystems, our systemachieves the best performance with F-measure50.30% when using the ?CRF?
subsystem.4 ConclusionsThis paper presents a cascaded system for theCoNLL-2010 shared task, which contains twosubsystems: one for detecting hedges and an-other one for detecting their scope.
Althoughthe best performance of hedge detection subsys-tem achieves F-measure 86.79%, the best per-formance of the whole system only achieves F-measure 50.30%.
How to improve it, we thinksome complex features such as context free gram-mar may be effective for detecting hedge scope.In addition, the postprocessing can be further im-proved.AcknowledgmentsWe wish to thank the organizers of the CoNLL-2010 shared task for preparing the datasetsand organizing the challenge shared tasks.We also wish to thank all authors supply-ing the toolkits used in this paper.
Thisresearch has been partially supported by theNational Natural Science Foundation of China(No.60435020 and No.90612005), National 863Program of China (No.2007AA01Z194) and theGoal-oriented Lessons from the National 863 Pro-gram of China (No.2006AA01Z197).ReferencesRicha?rd Farkas, Veronika Vincze, Gyo?rgy Mo?ra, Ja?nosCsirik, Gyo?rgy Szarvas.
2010.
The CoNLL-2010Shared Task: Learning to Detect Hedges and theirScope in Natural Language Text.
In Proceedings ofthe Fourteenth Conference on Computational Nat-ural Language Learning (CoNLL-2010): SharedTask, pages 1?12, Uppsala, Sweden, July.
Associ-ation for Computational Linguistics.Viola Ganter and Michael Strube.
2009.
Findinghedges by chasing weasels: Hedge detection usingwikipedia tags and shallow linguistic features.
InProceedings of the ACL-IJCNLP 2009 ConferenceShort Papers, pages 173?176, Suntec, Singapore,August.
Association for Computational Linguistics.Roser Morante andWalter Daelemans.
2009.
Learningthe scope of hedge cues in biomedical texts.
In Pro-ceedings of the BioNLP 2009 Workshop, pages 28?36, Boulder, Colorado, June.
Association for Com-putational Linguistics.Tzong-Han Tsai, Chia-Wei Wu, and Wen-Lian Hsu.2005.
Using Maximum Entropy to Extract Biomed-ical Named Entities without Dictionaries.
In Sec-ond International Joint Conference on Natural Lan-guage Processing, pages 268?273.Veronika Vincze, Gyo?rgy Szarvas, Richa?rd Farkas,Gyo?rgy Mo?ra, and Ja?nos Csirik.
2008.
The Bio-Scope corpus: biomedical texts annotated for uncer-tainty, negation and their scopes.
BMC Bioinformat-ics, 9(Suppl 11):S9.17
