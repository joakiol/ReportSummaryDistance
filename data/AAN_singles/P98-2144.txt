HPSG-Style Underspecified Japanese Grammarwith Wide CoverageMITSUISHI  Yutaka  t, TORISAWA Kentaro  t, TSUJ I I  Jun ' i ch i  t*tDepar tment  of Information ScienceGraduate School of Science, University of Tokyo**CCL, UMIST,  U.K.Abst rac tThis paper describes a wide-coverage Japanesegrammar based on HPSG.
The aim of this workis to see the coverage and accuracy attain-able using an underspecified grammar.
Under-specification, allowed in a typed feature struc-ture formalism, enables us to write down awide-coverage grammar concisely.
The gram-mar we have implemented consists of only 6 IDschemata, 68 lexical entries (assigned to func-tional words), and 63 lexical entry templates(assigned to parts of speech (BOSs)) .
Further-more.
word-specific constraints such as subcate-gorization of verbs are not fixed in the gram-mar.
However.
this granllnar call generate parsetrees for 87% of the 10000 sentences in theJapanese EDR corpus.
The dependency accu-racy is 78% when a parser uses the heuristicthat every bunsetsu 1 is attached to the nearestpossible one.1 In t roduct ionOur purpose is to design a practical Japanesegrammar based on HPSG (Head-driven PhraseStructure Grammar) (Pollard and Sag, 1994),with wide coverage and reasonable accuracy forsyntactic structures of real-world texts.
In thispaper, "coverage" refers to the percentage ofinput sentences for which the grammar eturnsat least one parse tree, and "accuracy" refers tothe percentage of bunsetsus which are attachedcorrectly.To realize wide coverage and reasonable ac-curacy, the following steps had been taken:A) At first we prepared a linguistically validbut coarse grammar with wide coverage.B) We then refined the grammar in regard toaccuracy, using practical heuristics whichare not linguistically motivated.As for A), the first grammar we have con-structed actually consists of only 68 lexical en-* This research is partially founded by the project ofJSPS ( JSPS-RFTF96P00502).1A bunsetsu is a common unit when syntactic struc-tures in Japanese are discussed.tries (LEs) for some functional words 2, 63 lex-ical entry templates (LETs) for POSs 3, and 6ID schemata.
Nevertheless, the coverage of ourgrammar was 92% for the Japanese corpus inthe EDR Electronic Dictionary (EDR, 1996),mainly due to underspecification, which is al-lowed in HPSG and does not always require de-tailed grammar descriptions.As for B), in order to improve accuracy, thegrammar should restrict ambiguity as much aspossible.
For this purpose, the grammar needsmore constraints in itself.
To reduce ambiguity,we added additional feature structures whichmay not be linguistically valid but be empir-ically correct, as constraints to i) the originalLFs and LETs, and ii) the ID schemata.The rest of this paper describes the archi-tecture of our Japanese grammar (Section 2).refinement of our grammar (Section 3), exper-imental results (Section 4).
and discussion re-garding errors (Section 5).2 Arch i tec ture  o f  JapaneseGrammarIn this section we describe the architecture ofthe HPSG-style Japanese grammar we have de-veloped.
In the HPSG framework, a grammarconsists of (i) immediate dominance schemata(ID schemata), (ii) principles, and (iii) lexi-cal entries (LEs).
All of them are representedby typed feature structures (TFSs) (Carpen-ter, 1992), the fundamental data structures ofHPSG.
ID schemata, corresponding to rewrit-ing rules in CFG, are significant for construct-ing syntactic structures.
The details of our IDschemata re discussed in Section 2.1.
Princi-ples are constraints between mother and daugh-ter feature structures.
4 LEs, which compose thelexicon, are detailed constraints on each word.In our grammar, we do not always assign LEsto each word.
Instead, we assign lexical entry2A functional word is assigned one or more LEs.SA POS is also assigned one or more LETs.4We omit further explanation about principles heredue to limited space.876Schema name ExplanationApplied when a predicate subcategorizes apnrase.
Head-complement schemaHead-relative schema Applied when a relative clause modifies aphrase.Head-marker schema Applied when a marker like a postpositionmarks a phrase.Head-adjacent schema Applied when a suffix attaches to a wordor a compound word.Head-compound schema Applied when a compound word isconstructed.Head-modifier schema Applied when a phrase modifies another orwhen a coordinate structure is constructed.1~ xampleKare ga hashiru.he-sUBJ run'He runs.
'Aruku hitobito.walk people'People who walk.
'KanoJo ga.she -SUBJ'She ....'Iku darou.Go will?
.. will go.,Shizen Gengo.natural language'Natural anguage.
'Yukkuri tobu.,slo.w\]lYy flY?
..
slowly.
'Table 1: ID schemata in our grammartemplates (LETs) to POSs.
The details of ourLEs and LETs are discussed in Section 2.2.2.1 ID SchemataOur grammar includes the 6 ID schemata shownin Table 1.
Although they are similar to theones used for English in standard HPSG, thereis a fundamental difference in the treatment ofrelative clauses.
Our grammar adopts the head-relative schema to treat relative clauses insteadof the head-filler schema.
More specifically, ourgrammar does not have SLASH features and doesnot use traces.
Informally speaking, this is be-cause SLASH features and traces are really nec-essary only when there are more than one verbbetween the head and the filler (e.g., Sentence(1)) .
But such sentences are rare in real-worldcorpora in Japanese.
Just using a Head-relativeschema makes our grammar simpler and thusless ambiguous.
(1) Taro ga aisuru to iu onna.-SUBJ love -QUOTE say woman'The woman who Taro says that he loves.
'2.2 Lexical Entries (LEs) and LexicalEntry Templates (LETs)Basically, we assign LETs to POSs.
For ex-ample, common nouns are assigned one LET,which has general constraints that they can becomplements of predicates, that they can be acompound noun with other common ouns, andso on.
However, we assign LEs to some singlefunctional words which behave in a special way.For example, the verb 'suru' can be adjacent osome nouns unlike other ordinary verbs.
Thesolution we have adopted is that we assign aspecial LE to the verb 'suru'.Our lexicon consists of 68 LEs for some func-tional words, and 63 LETs for POSs.
A func-tional word is assigned one or more LEs, and aPOS is also assigned one or more LETs.3 Ref inement  o f  our  GrammarOur goal in this section is to improve accuracywithout losing coverage.
Constraints to improveaccuracy can also be represented by TFSs andbe added to the original grammar componentssuch as ID schemata, LEs, and LETs.The basic idea to improve accuracy is that in-cluding descriptions for rare linguistic phenom-ena might make it more difficult for our systemto choose the right analyses.
Thus, we abandonsome rare linguistic phenomena.
This approachis not always linguistically valid but at least ispractical for real-world corpora.In this section, we consider some frequentlinguistic phenomena, nd explain how we dis-carded the treatment of rare linguistic phenom-ena in favor of frequent ones, regarding threecomponents: (i) the postposition 'wa', (ii) rela-tive clauses and commas and (iii) nominal suf-fixes representing time.
The way how we aban-don the treatment of rare linguistic phenomenais by introducingaddit ional constraints in fea-ture structures.
Regarding (i) and (ii), we intro-duce 'pseudo-principles', which are unified withID schemata in the same way principles are uni-fied.
Regarding (iii), we add some feature struc-tures to LEs/LETs.3.1 Postposit ion 'Wa'The main usage of the postposition 'wa' is di-vided into the following two patternsS:?
If two PPs with the postposition 'wa' ap-pear consecutively, we treat the first PP as5These patterns are almost similar to the ones in(Kurohashi and Nagao, 1994).877(a) (b)*......... 1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(~) ........ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
l ' I '(c) (d)*......... l ........ T ........ (i) ........I ............ i !
.
.
.
.
l_-.
* .
.
.
.
.
.
.
.
.
.
.
; *------'t----4 .
.
.
.
.
.
.
'-" I .
.
.
.
.
.
.  '
- '1Figure 1: (a) Correct / (b) incorrect parse tree forSentence (2); (c) correct / (d) incorrect parse treefor Sentence (3)a complement of a predicate just before thesecond PP.?
Otherwise, PP  with the postposit ion 'wa' istreated as the complement of the last pred-icate in the sentence.Sentences (2) and (3) are examples for thesepatterns, respectively.
The parse tree for Sen-tence (2) corresponds to Figure l(a).
but not toFigure l(b).
and the parse tree for Sentence (3)corresponds to Figure l(c).
but not to Figurel(d).
(2) Taro wa iku a ika nai.
-TOPICgO ~ut Jiro wa -TOPIC go -NEG'Though Tarogoes, Jiro does not go.
"(3) Tokai wa hito ga ookute sawagashii.city -TOPIC people -SUBJ many noisy'A city is noisy because there are ninny people.
'Although there are exceptions to the abovepatterns (e.g., Sentence (4) & Figure (2)) ,  theyare rarely observed in real-world corpora.
Thus,we abandon their treatment.
(4) Ude wa nai ga, konjo ga aru.ability -TOPIC missing but guts -SUaJ exist'Though he does not have ability, he has guts.
'To deal with the characteristic of 'wa', we in-t roduced the WA feature and the P_WA feature.Both of them are binary features as follows:Feature Value MeaningWA +/ -  The phrase contains a/no 'wa'.P_WA +/ -  The PP is/isn't marked by 'wa'.We then introduced a 'pseudo-principle' for 'wa'in a disjunctive form as below6:(A) When applying head-complement schema,also apply:6ga_hc and ~a_l'm are DCPs, which are also executedwhen the pseudo-principle is applied./Chil~ .
.
.
.
1 " tt&x g~., ko u.Figure 2: Correct parse tree for Sentence (4).._ho(N El Dwhere.a_hc(-, --, --).
.a_hc(+, --, 4-).
.a_hc(-, +, +).
(B) When applying head-modifier schema, alsoapply:wherewa_h~(-,-).
.a_hm(-, +).
.~_hm(+, ).... and so on.This treatment prunes the parse trees like thosein Figure l(b, d) as follows:?
Figure l(b)l) At (:~), the head-complement schemashould be applied, and (A) of the 'pseudo-principle should also be applied.2) Since the phrase 'iku kedo ashita wa ikanai' contains a 'wa', \ [ \ ]  is +.3) Since the PP  'Kyou wa' is marked by 'wa',\[-3\] is +.4) .a_hc(\[~\], \ [~  \[\]-\]) fails.?
Figure l(d)1) At (#) ,  the head-modifier schema shouldbe applied, and (B) of the 'pseudo-principle' should also be applied.2) Since the phrase ' Tokai wa hito ga ookute'contains a 'wa', E / i s  +.3) Since the phrase 'sawagashii' contains no'wa', \[-~ is --.4) .._hm(E\], D fails.3.2 Re lat ive  C lauses and  CommasRelative clauses have a tendency to contain nocommas.
In Sentence (5), the PP 'Nippon de,'is a complement of the main verb 'atta', not acomplement of 'umareta' in the relative clause(Figure 3(a) ), though 'Nippon de' is preferredto 'urnaveta' if the comma after 'de' does notexist (Figure 3(b) ).
We, therefore, abandonthe treatment of relative clauses containing a878(a)I +-- -?
.
.
.
.
?'
l .
.
.
.
?
.
.
.
.
.
.
?
T , i .
.
.
, l , .  '
una.re~a, a.ka ha.n 3.
LI tL  l i ppon(b)/I ?
...... ?
.....
?.........
!........
!i .
.
.
.
.
1 .
.
.
.
.
i II .
.
.
.
.
.
.
.
.
.
.
I 1l i ppo .
J'+ ,ai~ia umLrcta  + JcachLn  i at taFigure 3: (a) Correct parse tree for Sentence (5);(b) correct parse tree for comma-removed Sentence(5)comma.
(5) Nippon de, saikin umareta akachanJapan -LOC recently be-born-PAST babyni atta.-GOAL meet-PAST'ill Japan I met a baby who was born recently.
'To treat such a tendency of relative clauses.we first introduced the TOUTEN feature 7.
TheTOUTEN feature is a binary feature which takes+/ -  if the phrase contains a/no comma.
Wethen introduced a 'pseudo-principle' for relativeclauses as follows:(A) When applying head-relative schema, alsoapply:\[ DTRSlNH.DTRITOUTE  - \](B) When applying other ID schemata, thispseudo-principle has no effect.This is to make sure that parse trees for relativeclauses with a comma cannot be produced.3.3 Nomina l  Suff ixes Represent ingT ime and  CommasNoun phrases (NPs) with nominal suffixes suchas nen (year), gatsu (month),  and ji (hour) rep-resent information about time.
Such NPs aresometimes used adverbially, rather than nomi-nally.
Especially NPs with such a nominal suffixand comma are often used adverbially (Sentence(6) & Figure 4(a) ), while general SPs  with acomma are used in coordinate structures (Sen-tence (7) & Figure 4(b) ).
(6) 1995 nen, jishin ga okita.year earthquake -SUBJ Occur-PASTAn earthquake occurred in 1995.rA touten stands for a comma in Japanese.
(a) (b)....... 1 .
.
.
.
.
.
.
.
.
.
.
l ....I ' ' \] .....
?--?---?
?-?-?
?.?-?
?--?--?19~ I?
\[ ji,tin gla ok ,a.
|,Ito.
l a  i i ta non,Figure 4: (a, b) Correct parse trees for Sentences(6) and (7) respectively(7) Kyoto, Nara ni itta.-GOAL gO-PASTI went to Kyoto and-Nara.In order to restrict the behavior of NPs withnominal t ime suffixes and commas to adverbialusage only, we added the following constraint tothe LE of a comma, constructing a coordinatestructure:\[ MARK \[SYN\[LOCAL\[N-SUFFIX - \]This prohibits an NP with a nominal suffix frombeing marked by a comma for coordination.4 Exper imentsWe implemented our parser and grammar inLiLFeS (Makino et al, 1998) s, a feature-structure description language developed by ourgroup.
We tested randomly selected 10000 sen-tences fi'om the Japanese EDR corpus (EDR,1996).
Tile EDR Corpus is a Japanese versionof treebank with morphological, structural, andsemantic information.
In our experiments, weused only the structural information, that is,parse trees.
Both the parse trees in our parserand the parse trees in the EDR Corpus are firstconverted into bunsetsu dependencies, and theyare compared when calculating accuracy.
Notethat the internal structures of bunsetsus, e.~.structures of compound nouns, are not consid-ered in our evaluations.~re evaluated the following grammars: (a) theoriginal underspecified grammar,  (b) (a) + con-straint for wa-marked PPs, (c) (a) + constraintfor relative clauses with a comma, (d) (a) + con-straint for nominal t ime suffixes with a comma,and (e) (a) + all the three constraints.
We eval-uated those grammars by the following threemeasurements:Coverage  The percentage of the sentencesthat generate at least one parse tree.Par t ia l  Accuracy  The percentage of the cor-rect dependencies between bunsetsus (ex-cepting the last obvious dependency) forthe parsable sentences.Tota l  Accuracy  The percentage of the correctdependencies between bunsetsus (exceptingthe last dependency) over all sentences.8LiLFeS will soon be published on its horn?page,http://www, is.
s. u-tokyo, ac.
j p/'mak/lilfes/879Coverage(a) 91.87%(b) 88.37%(c) 90.75%(d) 91.87%(e) 87.37%PartialAccuracy74.20%77.50%74.98%74.41%77.77%TotalAccuracy72.61%74.65%73.11%72.80%74.65%Table 2: Experimental results for 10000 sentencesfrom the Japanese EDR Corpus: (a-e) are grammarsrespectively corresponding to Section 2 (a), Section2 + Subsection 3.1 (b), Section 2 + Subsection 3.2(c), Section 2 + Subsection 3.3 (d), and Section 2 +Section 3 (e).When calculating to ta l  accuracy,  the depen-dencies for unparsable sentences are predictedso that every bunsetsu is attached to the near-est bunsetsu.
In other words, to ta l  accuracycan be regarded as a weighted average of partialaccuracy and baseline accuracy.Table 2 lists the results of our experiments.Comparison of the results between (a) and (b-d) shows that all the three constraints improvepart ia l  accuracy  and tota l  accuracy  withlittle coverage loss.
And grammar (e) using thecombination of the three constraints still workswith no side effect.We also measured average parsing time persentence for the original grammar (a) and thefully augmented grammar (e).
The parser weadopted is a naive CKY-style parser.
Table 3gives the average parsing time per sentence forthose 2 grammars.
Pseudo-principles and fur-ther constraints on LEs/LETs also make pars-ing more time-efficient.
Even though they aresometimes considered to be slow in practical ap-plication because of their heavy feature struc-tures, actually we found them to improve speed.In (Torisawa and Tsujii, 1996), an efficientHPSG parser is proposed, and our preliminaryexperiments show that the parsing time of theeffident parser is about three times shorter thanthat of the naive one.
Thus, the average parsingtime per sentence will be about 300 msec., andwe believe our grammar will achive a practicalspeed.
Other techniques to speed-up the parserare proposed in (Makino et al, 1998).5 Discuss ionThis section focuses on the behavior of commas.Out of randomly selected 119 errors in experi-ment (e), 34 errors are considered to have beencaused by the insufficient treatment of commas.Especially the fatal errors (28 errors) oc-curred due to the nature of commas.
To put itAverage parsing time per sentence1277 (msec)838 (msec)(a)mTable 3: The average parsing time per sentencein another way, a phrase with a comma, some-times, is attached to a phrase farther than thenearest possible phrase.
In (Kurohashi and Na-gao, 1994), the parser always attaches a phrasewith a comma to the second nearest possiblephrase.
We need to introduce such a constraintinto our grammar.Though the grammar (e) had the pseudo-principle prohibiting relative clauses containingcommas, there were still 6 relative clauses con-taining commas.
This can be fixed by investi-gating the nature of relative clauses.6 Conc lus ion  and  Future  WorkWe have introduced an underspecified Japanesegrammar using the HPSG framework.
Thetechniques for improving accuracy were easy toinclude into our grammar due to the HPSGframework.
Experimental results have shownthat our grammar has wide coverage with rea-sonable accuracy.Though the pseudo-principles and furtherconstraints on LEs/LETs that we have intro-duced contribute to accuracy, they are toostrong and therefore cause some coverage loss.One way we could prevent coverage loss is byintroducing preferences for feature structures.ReferencesBob Carpenter.
1992.
The Logic of Typed Fea-ture Structures.
Cambridge University Press.EDR (Japan Electronic Dictionary Research In-stitute, Ltd.).
1996.
EDR electronic dictio-nary version 1.5 technical guide.Sadao Kurohashi and Makoto Nagao.
1994.
Asyntactic analysis method of long japanesesentences based on the detection of conjunc-tive structures.
Computational Linguistics,20(4):507-534.Takaki Makino, Minoru Yoshida, Kentaro Tori-sawa, and Tsujii Jun'ichi.
1998.
LiLFeS - to-wards a practical HPSG parser.
In COLING-A CL '98, August.Carl Pollard and Ivan A.
Sag.
1994.
Head-Driven Phrase Structure Grammar.
The Uni-versity of Chicago Press.Kentaro Torisawa and Jun'ichi Tsujii.
1996.Computing phrasal-signs in HPSG prior toparsing.
In COLING-96, pages 949-955, Au-gust.880
