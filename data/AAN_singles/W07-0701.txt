Proceedings of the Second Workshop on Statistical Machine Translation, pages 1?8,Prague, June 2007. c?2007 Association for Computational LinguisticsUsing Dependency Order Templates to Improve Generality inTranslationArul Menezes and Chris QuirkMicrosoft ResearchOne Microsoft Way, Redmond, WA 98052, USA{arulm, chrisq}@microsoft.comAbstractToday's statistical machine translationsystems generalize poorly to newdomains.
Even small shifts can causeprecipitous drops in translation quality.Phrasal systems rely heavily, for bothreordering and contextual translation, onlong phrases that simply fail to match out-of-domain text.
Hierarchical systemsattempt to generalize these phrases buttheir learned rules are subject to severeconstraints.
Syntactic systems can learnlexicalized and unlexicalized rules, but thejoint modeling of lexical choice andreordering can narrow the applicability oflearned rules.
The treelet approach modelsreordering separately from lexical choice,using a discriminatively trained ordermodel, which allows  treelets to applybroadly, and has shown bettergeneralization to new domains, but suffersa factorially large search space.
Weintroduce a new reordering model basedon dependency order templates, and showthat it outperforms both phrasal and treeletsystems on in-domain and out-of-domaintext, while limiting the search space.1 IntroductionModern phrasal SMT systems such as (Koehn etal., 2003) derive much of their power from beingable to memorize and use long phrases.
Phrasesallow for non-compositional translation, localreordering and contextual lexical choice.However the phrases are fully lexicalized, whichmeans they generalize poorly to even slightly out-of-domain text.
In an open competition (Koehn &Monz, 2006) systems trained on parliamentaryproceedings were tested on text from 'newscommentary' web sites, a very slightly differentdomain.
The 9 phrasal systems in the English toSpanish track suffered an absolute drop in BLEUscore of between 4.4% and 6.34% (14% to 27%relative).
The treelet system of Menezes et al(2006) fared somewhat better but still suffered anabsolute drop of 3.61%.Clearly there is a need for approaches withgreater powers of generalization.
There aremultiple facets to this issue, including handling ofunknown words, new senses of known words etc.In this work, we will focus on the issue ofreordering, i.e.
can we learn how to transform thesentence structure of one language into thesentence structure of another, in a way that is nottied to a specific domain or sub-domains, orindeed, sequences of individual words.An early attempt at greater generality in apurely phrasal setting was the alignment templateapproach (Och & Ney 2004); newer approachesinclude formally syntactic (Chiang 2005), andlinguistically syntactic approaches (Quirk et al2005), (Huang et al 2006).
In the next section, weexamine these representative approaches to thereordering problem.2 Related WorkOur discussion of related work will be groundedin the following tiny English to Spanish example,where the training set includes:a very old bookun libro m?s  antiguoa  book  very old1the old manel  hombre viejothe man    oldit is very importantes muy  importanteis very important1 English gloss of Spanish sentences in italics.1and the test sentence and reference translation area very old manun hombre muy  viejoa  man    very oldNote that while the first training pair has thecorrect structure for the test sentence, most of thecontextually correct lexical choices come fromthe other two pairs.2.1 Phrasal translation, Alignment templatesThe relevant phrases (i.e.
those that match the testsentence) extracted from these training pairs areshown in Table 2.1.
Only phrases up to size 3 areshown.
The ones in italics are 'correct' in that theycan lead to the reference translation.
Note thatnone of the multi-word phrases lead to thereference, so the local reordering often capturedin the phrasal model is no help at all in orderingthis sentence.
The system is unable to learn thecorrect structure from the first sentence becausethe words are wrong, and from the secondsentence even though the phrase old man has theright words in the right order, it does not lead tothe reference translation because the translation ofvery cannot be inserted in the right place.a unvery m?sold antiguovery old m?s antiguoold viejoman hombreold man hombre viejovery muyTable 2.1: Relevant extracted phrasesLooking at this as a sparse data issue we mightsuspect that generalization could solve theproblem.
The alignment template approach (Och& Ney, 2004) uses word classes rather thanlexical items to model phrase translation.
Yet thisapproach loses the advantage of context-sensitivelexical selection: the word translation modeldepends only on the word classes to subcategorizefor translations, which leads to less accuratelexical choice in practice (Zens & Ney, 2004).2.2 Hierarchical translationHierarchical systems (Chiang, 2005) induce acontext-free grammar with one non-terminaldirectly from the parallel corpus, with theadvantage of not requiring any additionalknowledge source or tools, such as a treebank or aparser.
However this can lead to an explosion ofrules.
In order to make the problem tractable andavoid spurious ambiguity, Chiang restricts thelearned rules in several ways.
The mostproblematic of these is that every rule must haveat least one pair of aligned words, and thatadjacent non-terminals are not permitted on thesource side.
In Table 2.2 we show the additionalhierarchical phrases that would be learned fromour training pairs under these restrictions.
Againonly those applicable to the test sentence areshown and the 'correct' rules, i.e.
those that lead tothe reference, are italicized.X1 old X1 antiguovery X1 m?s X1very old X1 X1 m?s antiguoX1 old X2 X2 X1 antiguovery X1 X2 X2 m?s X1X1 man hombre X1old X1 X1 viejoX1 old man X1 hombre viejoX1 very X1 muyvery X2 muy X2X1 very X2 X1 muy X2Table 2.2: Additional hierarchical phrasesNote that even though from the first pair, we learnseveral rules with the perfect reordering for thetest sentence, they do not lead to the referencebecause they drag along the contextually incorrectlexical choices.
From the second pair, we learn arule (X1 old man) that has the right contextualword choice, but  does not lead to the reference,because the paucity of the grammar's single non-terminal causes this rule to incorrectly imply thatthe translation of very be placed before hombre.2.3 Constituency tree transductionAn alternate approach is to use linguisticinformation from a parser.
Transduction rulesbetween Spanish strings and English trees can belearned from a word-aligned parallel corpus withparse trees on one side (Graehl & Knight, 2004).Such rules can be used to translate from Spanishto English by searching for the best Englishlanguage tree for a given Spanish language string(Marcu et al, 2006).
Alternately English treesproduced by a parser can be transduced to2Spanish strings using the same rules (Huang et al,2006).
Translation rules may reach beyond onelevel in the syntax tree; this extended domain oflocality allows many phenomena including bothlexicalized and unlexicalized rules.
Howeverreordering and translation are modeled jointly,which may exacerbate data sparsity.
Furthermoreit forces the system to pick between unlexicalizedrules that capture reordering and lexicalized rulesthat model context-sensitive translation.For instance, the following rules can beextracted from the first sentence of the corpus:r1: un x1 x2 ?
NP(DT(a) ADJP:x2 NN:x1)r2: x1 x2 ?
ADJP(RB:x1 JJ:x2)Although together they capture the necessaryreordering for our test sentence pair, they do notallow for context sensitive translations of theambiguous terms very and old; each must beselected independently.
Disappointingly, nosingle constituency tree transduction rule derivedfrom this corpus translates old man as hombreviejo in a single step on the test sentence: thesyntactic structures are slightly different, but thedifference is sufficient to prevent matching.
2Again we note that phrases provide utility bycapturing both reordering and context.
While xRS2 Marcu et al (2006) and Zollmann et al (2006) recognizethis problem and attempt to alleviate it by grafting surfacephrases into constituency trees by various methods.rules provide an elegant and powerful model ofreordering, they come with a potential cost incontext-sensitive translation.2.4 Dependency treelet translationWe previously described (Quirk et al 2005) alinguistically syntax-based system that parses thesource language, uses word-based alignments toproject a target dependency tree, and extractspaired dependency tree fragments (treelets)instead of surface phrases.
In contrast to the xRSapproach, ordering is very loosely coupled withtranslation via a separate discriminatively traineddependency tree-based order model.
The switchto a dependency parse also changes theconditioning information available for translation:related lexical items are generally adjacent, ratherthan separated by a path of unlexicalized non-terminals.
In effect, by using a looser matchingrequirement, treelets retain the context-sensitivelexical choice of phrases: treelets must only be aconnected subgraph of the input sentence to beapplicable; some children may remain uncovered.Figure 2.2 shows source dependency parsesand projected target dependencies for our trainingdata; Figure 2.3 shows the treelet pairs that thissystem would extract that match the inputa very old bookDT RB JJ NNADJPNPun libro m?s antiguothe old manDT JJ NNNPel hombre viejoit is very importantPN VB RB JJADJPVPSes muy importanteFigure 2.1:  Constituency parsesFigure 2.2: Dependency trees for training pairsFigure 2.3: Relevant extracted treelets3sentence (treelets of size 1 are not shown).
Thesecond treelet supplies the order of viejo withrespect to its head, and unlike the case with xRSrules, we can use this to make the correctcontextual word choice.
The difference is thatbecause xRS rules provide both reordering andword choice, each rule must match all of thechildren at any given tree node.
On the otherhand, treelets are allowed to match more loosely.The translations of the unmatched children (unand muy in this case) are placed by exploring allpossible orderings and scoring them with bothorder model and language model.
Although thiseffectively decouples lexical selection fromordering, it comes at a huge cost in search spaceand translation quality may suffer due to searcherror.
However, as mentioned in Section 1, thisapproach is able to generalize better to out-of-domain data than phrasal approaches.
Koehn andMonz (2006) also include a human evaluation, inwhich this system ranked noticeably higher thanone might have predicted from its BLEU score.3 Dependency Order TemplatesThe Dependency Order Templates approachleverages the power of the xR rule formalism,while avoiding the problems mentioned in Section2.3, by constructing the rules on the fly from twoseparately matched components: (a) Dependencytreelet translation pairs described in Section 2.4that capture contextual lexical translations but areunderspecified with respect to ordering, and (b)Order templates, which are unlexicalized rules(over dependency, rather than constituency trees)that capture reordering phenomena.Formally, an order template is an unlexicalizedtransduction rule mapping dependency treescontaining only parts of speech to unlexicalizedtarget language trees (see Figure 4.1b).Given an input sentence, we combine relevanttreelet translation pairs and order templates toconstruct lexicalized transduction rules for thatsentence, and then decode using standardtransduction approaches.
By keeping lexical andordering information orthogonal until runtime, wecan produce novel transduction rules not seen inthe training corpus.
This allows greatergeneralization capabilities than the constituencytree transduction approaches of Section 2.3.As compared to the treelet approach describedin Section 2.4, the generalization capability issomewhat reduced.
In the treelet system allreorderings are exhaustively evaluated, but thesize of the search space necessitates tight pruning,leading to significant search error.
By contrast, inthe order template approach we consider onlyreorderings that are captured in some ordertemplate.
The drastic reduction in search spaceleads to an overall improvement, not only indecoding speed, but also in translation quality dueto reduced search error.3.1 Extracting order templatesFor each pair of parallel training sentences, weparse the source sentence, obtain a sourcedependency tree, and use GIZA++ wordalignments to project a target dependency tree asdescribed in Quirk et al (2005).Given this pair of aligned source and targetdependency trees, we recursively extract oneorder template for each pair of aligned non-leafsource and target nodes.
In the case of multi-wordalignments, all contiguous 3  aligned nodes areadded to the template.
Next we recursively addchild nodes as follows: For each node in thetemplate, add all its children.
For each such child,if it is aligned, stop recursing, if it is unaligned,recursively add its children.On each template node we remove the lexicalitems; we retain the part of speech on the sourcenodes (we do not use target linguistic features).We also keep node alignment information4.
Theresulting aligned source and target sub-graphscomprise the order template.
Figure 4.1b lists theorder templates extracted from the training pairsin Figure 2.1 that capture all the patternsnecessary to correctly reorder the test sentence.4 DecodingDecoding is treated as a problem of syntax-directed transduction.
Input sentences aresegmented into a token stream, annotated withpart-of-speech information, and parsed into3 If a multi-word alignment is not contiguous in either sourceor target dependency tree no order template is extracted.4 If a source or target node aligns to a tree node outside thetemplate, the template breaks phrasal cohesion and iscurrently discarded.
We intend to address these 'structuraldivergence' patterns in future work.4unlabeled dependency trees.
At each node in theinput dependency tree we first find the set ofmatching treelet pairs: A pair matches if its sourceside corresponds to a connected subgraph of theinput tree.
Next we find matching ordertemplates: order templates must also match aconnected subgraph of the input tree, but inaddition, for each input node, the template mustmatch either all or none of its children 5 .Compatible combinations of treelets and ordertemplates are merged to form xR rules.
Finally,we search for the best transduction according tothe constructed xR rules as scored by a log-linearcombination of models (see Section 5).4.1 CompatibilityA treelet and an order template are consideredcompatible if the following conditions are met:The treelet and the matching portions of thetemplate must be structurally isomorphic.
Everytreelet node must match an order template node.Matching nodes must have the same part ofspeech.
Unaligned treelet nodes must match anunaligned template node.
Aligned treelet nodesmust match aligned template nodes.
Nodes thatare aligned to each other in the treelet pair mustmatch template nodes that are aligned to eachother.4.2 Creating transduction rulesGiven a treelet, we can form a set of treetransduction rules as follows.
We iterate overeach source node n in the treelet pair; let s be thecorresponding node in the input tree (identifiedduring the matching).
If, for all children of s thereis a corresponding child of n, then this treeletspecifies the placement of all children and nochanges are necessary.
Otherwise we pick atemplate that matched at s and is compatible withthe treelet.
The treelet and template are unified toproduce an updated rule with variables on thesource and target sides for each uncovered childof s. When all treelet nodes have been visited, weare left with a transduction rule that specifies thetranslation of all nodes in the treelet and containsvariables that specify the placement of all5 This is so the resulting rules fit within the xR formalism.
Ateach node, a rule either fully specifies its ordering, ordelegates the translation of the subtree to other rules.uncovered nodes.
Due to the independence ofordering and lexical information, we may producenovel transduction rules not seen in the trainingcorpus.
Figure 4.1 shows this process as it appliesto the test sentence in Section 2.If, at any node s, we cannot find a matchingtemplate compatible with the current treelet, wecreate an artificial source order template, whichsimply preserves the source language order in thetarget translation.
We add a feature function thatcounts the number of such templates and train itsweight during minimum error rate training.4.3 Transduction using xR rulesIn the absence of a language model or othercontextually dependent features, finding thehighest scoring derivation would be a simpledynamic program (Huang et al 2006) 6.Howeverexact search using an ?
-gram language modelleads to split states for each ?
-gram context.Instead we use an approximate beam searchmoving bottom-up in the tree, much like a CKYparser.
Candidates in this search are derivationswith respect to the transducer.Each transduction rule ?
has a vector ofvariables ???,?
???
.
Each variable is associatedwith an input node ????.
For each input node ?,we keep a beam of derivations ????.
Derivationsare represented as a pair ?
?, ??
where ?
is atransduction rule and ?
?
??
is a vector with oneinteger for each of the ?
variables in ?
.
Theinterpretation is that the complete candidate canbe constructed by recursively substituting for each6 Like Chiang (2005) we only search for the yield of the mostlikely derivation, rather than the most likely yield.Figure 4.1: Merging templates and treelets5???
?
???
????
the candidate constructed fromthe ??
th entry in the beam ????????
?.Figure 4.2 describes the transduction process.Since we approach decoding as xR transduction,the process is identical to that of constituency-based algorithms (e.g.
Huang and Chiang, 2007).There are several free parameters to tune:?
Beam size ?
Maximum number of candidatesper input node (in this paper we use 100)?
Beam threshold ?
maximum range of scoresbetween top and bottom scoring candidate(we use a logprob difference of 30)?
Maximum combinations considered ?
Tobound search time, we can stop after aspecified number of elements are popped offthe priority queue (we use 5000)5 ModelsWe use all of the Treelet models we described inQuirk et al (2005) namely:?
Treelet table with translation probabilitiesestimated using maximum likelihood, withabsolute discounting.?
Discriminative tree-based order model.?
Forward and backward lexical weighting,using Model-1 translation probabilities.?
Trigram language model using modifiedKneser-Ney smoothing.?
Word and phrase count feature functions.In addition, we introduce the following:?
Order template table, with templateprobabilities estimated using maximumlikelihood, with absolute discounting.?
A feature function that counts the number ofartificial source order templates (see below)used in a candidate.The models are combined in a log-linearframework, with weights trained using minimumerror rate training to optimize the BLEU score.6 ExperimentsWe evaluated the translation quality of the systemusing the BLEU metric (Papineni et al, 2002).We compared our system to Pharaoh, a leadingphrasal SMT decoder (Koehn et al, 2003), andour treelet system.
We report numbers for Englishto Spanish.6.1 DataWe used the Europarl corpus provided by theNAACL 2006 Statistical Machine Translationworkshop.
The target language model was trainedusing only the target side of the parallel corpus.The larger monolingual corpus was not utilized.The corpus consists of European Parliamentproceedings, 730,740 parallel sentence pairs ofEnglish-Spanish, amounting to about 15M wordsin each language.
The test data consists of 2000sentences each of development (dev),development-test (devtest) and test data (test)from the same domain.
There is also a separate setof 1064 test sentences (NC-test) gathered from"news commentary" web sites.6.2 TrainingWe parsed the source (English) side of the corpususing NLPWIN, a broad-coverage rule-basedparser able to produce syntactic analyses atvarying levels of depth (Heidorn, 2002).
For thepurposes of these experiments we used adependency tree output with part-of-speech tagsand unstemmed, case-normalized surface words.For word alignment we used GIZA++, under atraining regimen of five iterations of Model 1,five iterations of HMM, and five iterations ofModel 4, in both directions.
The forward andbackward alignments were symmetrized using atree-based heuristic combination.
The wordGetTranslationBeam(?)
// memoizedprioq ?
?beam ?
?for ?
?
???
?Enqueue(prioq, ?
?, ?
?, EarlyScore(?
?, ??
))while Size(prioq) ?
0?
?, ??
?
PopBest(prioq)AddToBeam(beam, ?
?, ?
?, TrueScore(?
?, ??
))for ?
in 1. .
|?|Enqueue(prioq, ?
?, ?
?
???,EarlyScore(?
?, ?
?
???
))return beamEarlyScore(?
?, ??)?
?
RuleScore(?
)for ?
in 1. .
|?|?
?
InputNode(GetVariable (?, ?
))beam ?
GetTranslationBeam(?)?
?
?
?TrueScore(GetNthEntry(beam, ??
))return ?Figure 4.2: Beam tree transduction6alignments and English dependency tree wereused to project a target tree.
From the aligned treepairs we extracted a treelet table and an ordertemplate table.The comparison treelet system was identicalexcept that no order template model was used.The comparison phrasal system wasconstructed using the same GIZA++ alignmentsand the heuristic combination described in (Och& Ney, 2003).
Except for the order models(Pharaoh uses a penalty on the deviance frommonotone), the same models were used.All systems used a treelet or phrase size of 7and a trigram language model.
Model weightswere trained separately for all 3 systems usingminimum error rate training to maximize BLEU(Och, 2003) on the development set (dev).
Somedecoder pruning parameters were tuned on thedevelopment test (devtest).
The test and NC-testdata sets were not used until final tests.7 ResultsWe present the results of our system comparisonsin Table 7.1 and Figure 7.1 using three differenttest sets: The in-domain development test data(devtest), the in-domain blind test data (test) andthe out-of-domain news commentary test data(NC-test).
All differences (except phrasal vs.template on devtest), are statistically significant atthe p>=0.99 level under the bootstrap resamplingtest.
Note that while the systems are quitecomparable on the in-domain data, on the out-of-domain data the phrasal system's performancedrops precipitously, whereas the performance ofthe treelet and order template systems drops muchless, outperforming the phrasal system by 2.7%and 3.46% absolute BLEU.devtest test NC-testPhrasal 0.2910 0.2935 0.2354Treelet 0.2819 0.2981 0.2624Template 0.2896 0.3045 0.2700Table 7.1: System Comparisons across domainsFurther insight may be had by comparing therecall 7  for different n-gram orders (Table 7.2).The phrasal system suffers a greater decline in thehigher order n-grams than the treelet and template7 n-gram precision cannot be directly compared across outputfrom different systems due to different levels of 'brevity'systems, indicating that latter show improvedgenerality in reordering.1gm 2gm 3gm 4gmTest Phrasal 0.61 0.35 0.23 0.15treelet 0.62 0.36 0.23 0.15template 0.62 0.36 0.24 0.16NC-test phrasal 0.58 0.30 0.17 0.10treelet 0.60 0.33 0.20 0.12template 0.61 0.34 0.20 0.13Table 7.2: n-gram recall across domains7.1 Treelet vs. Template systemsAs described in Section 3.1, the order templatesrestrict the broad reordering space of the treeletsystem.
Although in theory this might excludereorderings necessary for some translations, Table7.3 shows that in practice, the drastic search spacereduction allows the decoder to explore a widerbeam and more rules, leading to reduced searcherror and increased translation speed.
(The topKparameter is the number of phrases explored foreach span, or rules/treelets for each input node.
)DevtestBLEUSents.per secPharaoh, beam=100, topK=20 0.2910 0.94Treelet, beam=12, topK=5 0.2819 0.21Template, beam=100, topK=20 0.2896 0.56Table 7.3: Performance comparisonsBesides the search space restriction, the othersignificant change in the template system is toinclude MLE template probabilities as anFigure 7.1: In-domain vs. Out-of-domain BLEU232425262728293031development in-domain out-of-domainPhrasal Treelet Order Template7additional feature function.
Given that thetemplate system operates over rules where theordering is fully specified, and that most treetransduction systems use MLE rule probabilitiesto model both lexical selection and reordering,one might ask if the treelet system'sdiscriminatively trained order model is nowredundant.
In Table 7.4 we see that this is not thecase.8 (Differences are significant at p>=0.99.
)devtest test NC-testMLE model only 0.2769 0.2922 0.2512Discriminative andMLE models0.2896 0.3045 0.2700Table 7.4: Templates and discriminative order modelFinally we examine the role of frequencythresholds in gathering templates.
In Table 7.5 itmay be seen that discarding singletons reducesthe table size by a factor of 5 and improvestranslation speed with negligible degradation inquality.devtestBLEUNumber oftemplatesSentencesper sec.No threshold 0.2898 752,165 0.40Threshold=1 0.2896 137,584 0.56Table 7.5: Effect of template count cutoffs8 Conclusions and Future WorkWe introduced a new model of Dependency OrderTemplates that provides for separation of lexicalchoice and reordering knowledge, thus allowingfor greater generality than the phrasal and xRSapproaches, while drastically limiting the searchspace as compared to the treelet approach.
Weshowed BLEU improvements over phrasal of over1% in-domain and nearly 3.5% out-of-domain.
Ascompared to the treelet approach we showed animprovement of about 0.5%, but a speedup ofnearly 3x, despite loosening pruning parameters.Extraposition and long distance movement stillpose a serious challenge to syntax-based machinetranslation systems.
Most of the today's searchalgorithms assume phrasal cohesion.
Even if oursearch algorithms could accommodate suchmovement, we don't have appropriate models to8 We speculate that other systems using transducers withMLE probabilities may also benefit from additionalreordering models.account for such phenomena.
Our system alreadyextracts extraposition templates, which are a stepin the right direction, but may prove too sparseand brittle to account for the range of phenomena.ReferencesChiang, David.
A hierarchical phrase-based model forstatistical machine translation.
ACL 2005.Galley, Michel, Mark Hopkins, Kevin Knight, and DanielMarcu.
What?s in a translation rule?
HLT-NAACL 2004.Graehl, Jonathan and Kevin Knight.
Training TreeTransducers.
NAACL 2004.Heidorn, George.
?Intelligent writing assistance?.
In Dale etal.
Handbook of Natural Language Processing, MarcelDekker.
(2000)Huang, Liang, Kevin Knight, and Aravind Joshi.
StatisticalSyntax-Directed Translation with Extended Domain ofLocality.
AMTA 2006Huang, Liang and David Chiang.
Faster Algorithms forDecoding with Integrated Language Models.
ACL 2007(to appear)Koehn, Philipp, Franz Josef Och, and Daniel Marcu.Statistical phrase based translation.
NAACL 2003.Koehn, Philipp and Christof Monz.
Manual and automaticevaluation of machine translation between europeanlanguages.
Workshop on Machine Translation, NAACL2006.Marcu, Daniel, Wei Wang, Abdessamad Echihabi, and KevinKnight.
SPMT: Statistical Machine Translation withSyntactified Target Language Phrases.
EMNLP-2006.Menezes, Arul, Kristina Toutanova and Chris Quirk.Microsoft Research Treelet translation system: NAACL2006 Europarl evaluation.
Workshop on MachineTranslation, NAACL 2006Och, Franz Josef and Hermann Ney.
A systematiccomparison of various statistical alignment models,Computational Linguistics, 29(1):19-51 (2003).Och, Franz Josef.
Minimum error rate training in statisticalmachine translation.
ACL 2003.Och, Franz Josef and Hermann Ney: The AlignmentTemplate Approach to Statistical Machine Translation.Computational Linguistics 30 (4): 417-449 (2004)Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-JingZhu.
BLEU: a method for automatic evaluation ofmachine translation.
ACL 2002.Quirk, Chris, Arul Menezes, and Colin Cherry.
DependencyTree Translation: Syntactically informed phrasal SMT.ACL 2005Zens, Richard and Hermann Ney.
Improvements in phrase-based statistical machine translation.
HLT-NAACL 20048
