Lexical cltoice in context: generating procedural textsAgn6s Tntin l, Richard Kitu-edgel)6partetnent tie lingnislique,Universit6 de MontrdalC.I'.
6128, Sacc "A",Montrdal P.Q.
If3C 3J7 CanadaAbstractThis paper shows how lexical choice during text generationdepemls on linguistic context.
We argue that muking c(Irrectlexieal choice in rite textual context requires distinguishingproperties of concepts, which are ntme or less independent offile language, from language-specific representations of textwhere lexemes and their semantic and symantic relations arerepresented.
In particular, l.exical Fnnctions are well-suited totormalizing anaphoric lexical links in text, including theintroduction of superordinates.
This sheds new light on thenotion of "basic level", which has recently been applied tolexieM selection in genaration.
Some consh'aints governing ritegeneration of lexical nnd grammatical naphora re proposedfor procedural text, using examples front tim sublanguage ofrecipes.O.
IntroductionLexical choice cannot be made dining text generationwifltottt taking into account he linguistic context, boththe lexical context of inmmdiately surrounding wordsand rite larger textual context.a) Lexical context consists of the words (or lather, thelexicnl specifications of nascent words) that enter intosyntactic relations with the lexical item being generated.This intrn-clausal context is crncial lor lk)rmnlatingcollocational constraints, which restrict ways ofexpressing a preci~ meaning to certain lexical items, lotexample as in expressions like pay attention, receiveattention or narrow escape.
The importance ofeollocational constraiuts hlts IR3en emphasized in theliterature on text generation aud inachine translation(Bateman & Wanner 1990, lordanskaja et al 1991,Nirenbnrg & Nirenbnrg 1988, Held & Raab 1989).b) Textual conlext consists of the linguistic content ofprevious and subsequent clauses.
This context is tilescope for cohesive links (ttalliday & Hasan 1976) withthe lexical items m be generated in the current clause.The gn'eat majority of cohesivc links are anaphoric innature 2.
A textnal element T is an attaphor with reslmctto an antecexlent A (previtmsly introdacexl in the text) ifthe semantic or referential interpretation of T ~ dependson the interpretation of A.
When genmating auallhttrs, itis Iberefot~ the previotts context hat ntust bc taken inloacconn\[, ItS ill:I) Now in Centre National d'Etudes des T61dcommunications,LAA/SLC\]AIA, Route de Trdgnstel BP 40 22301 l..unifionCddex, Frmice.2) In the case of ca!alphorn, as in rite following sentence,If you want o, peel and chop the lualatoes.tile subsequent context mr,st be taken into account.3) Reference of a textual elemeut is file association betweantextual eleme, nt and extra-linguistic reality.
(1) ihel)am tile carrots, the celery mid the asparagus.Cook tile vegetables in I~iling wat,~" for ten minutes.Two textual clement are coreferential if they t-eli:r to thesame exlralinguistic reality.
Coreierential elentenls inour examples are often written ill italics, or indicated byidentical snbsctipts.Faihue Rt ch~.R)se all appropriate anaphoric expressiondaring generation typically lcads to awkward ornnacceptable t xt such as (2):(2) a. l:'repme the t:aTmts, the celery and the asparagus.b.
Cook tile caners, the celcly and tile aslmragos in N)ilingwateLc.
Take tile carrots, tile celery and the asparagus otlt at'teltell ninltltes.Ill this paper, we examine the mechanisms requiredfox' making natural lexical choice as a lunetion ofpreceding text tlud its reference to extralingttistic objtx:lsor concepts.
In particular, we are interested ill lexicalanal)hera, wllere open-class lexical items or exl)ressionsprovide a coroference link to one or nlore snch items illpreceding clanses.
For example, ill (1) vegetables i alexicat corefercntial anaphor of the carrots, the celeryand the asparagus..ht what fallows, we ainl to show that correctlexicalization in context reqnires access to both thectntcepnml relmence and the linguistic prolmrties ofpreceding text.
For it pipelined generation architcctmcwhich \[naps froln abstract representation levels towardstext, this implies distinguishing atconceptual level, moreor less independent of the language, ti'oln language-specific representation levels which encode lexemes andthe grammatical relation between thenl.
In particular, weillustrate the paradignlatic Lexical l 'unctkms (hereafterl,Fs) of Mel 'cnk's Explanatory CombinatorialDictionary (hereafter F, CD) (Mel%nk et al 1988;Mel',Suk & Polgn~re 1987).1.
Varieties of lexical anapboraBeft)re reviewing conshaints on tile introduction oflexical anal)hera during generation, we give examples ofinlportant YlmS of cm'eferential naphoric links 4.We consider an anallher 10 13(3 lexical only if we canestablish a semantic link between the attaphor and itsantecedent.
Therefore, in the following example:(3) Edith Cresson arrived Monday ut 9:00.
At 11:00, thePrbne Miniater of France gave a pxess conference.4) We will not treat here non -comlErantial anaphora like:Marie threw away all her old dre~es because she wantedto buy lleV?
Ollt2S.ActTzs DE COLING-92, NANTt'S, 23-28 Ao~r 1992 7 6 3 l'rttx:.
OF COLIN(;-92, NAt, arES, AU(;.
23-28, 1992Prime Minister of France is a cognitive coreferentialanaphor of Edith Cresson, but not a lexical one becausethe coreferential link between the two phrases is basedon world knowledge, and not on linguistic semantics.One type of coreferential lexical anaphora is called"reiteration" by Halliday & Hasan (1976) with threesubtypes: exact repetition, illusWated by (4b), synonymsubstitution (4b'), and superordinate substitution (4b").We can add to this group partial repetition (4b"'):(4) a.
1 bottle of light red bordeaux.b.
Pour the light red bordeaux on the meat.b'.
Pour the lieht red bordeaux wine on the meat.b".
Pour the ~ oct the meat.b'".
Pour the ~ on the meat.Nominalization provides another way of introducing acoreferential link to a previous verb:(5) Cook the rabbit for two hours.Ten minutes before the end of cooking, add the spices.Coreferential lexical links can also be establishedbetween an action and its result.
(6) Meanwhile.
mix the egg yolki with the sugarj.Pour the milk on the mixturei+ j.In this example, mixture has no direct semantic link withits antecedents egg yolk and sugar.
The link appearsindirectly through the verb mix.Another type of lexical anaphora occurs with nounsdenoting typical actants of an antecedent verb:(7) Marga i was lecturing to third year students k. The lecturer iwas very interesting and the audience k quite attentive.In this case, lecturer is linked coreferentially withMarga because it is the "agent noun" of lecture, whileaudience is the corresponding "patient noun", and iscoreferential with third year students.These examples illustrate some of the diversity oflexico-semantic resources needed to build coreferentiallinks in text.
Text generation therefore requires a lexiconwhich gives access to the full range of such resourcesfrom the "viewpoint" of the antecedent lexeme.
As seenin the next section, LFs provide an appropriate accessmechanism for choosing the correct anaphor.2.
Lexical Functions of the ECD for creatinglexical anaphoraLexical Functions of the ECD provide a formalismrepresenting many common instances of coreferentialanaphora.
Formally defined, a Lexical Function f is acorrespondence b tween a lexical item L, called the keyword of f, and a set of lexical items f(L) - the values of f(Mel '~uk & Zholkovskij  1970, Mel '~uk 1988b).Approximately sixty standard Lexical Functions havebeen defined (for a recent description of LFs in the ECDin English, see Mel'~uk & Polgu~re 1987).
They can bedivided into two subsets: syntagmat ic  LFs  andparad igmat ic  LFs .- Syntagmat ic  o r  co l locat iona l  LFs  are used to linkunpredictable xical cooccurrences in texts between thekey word and its values through a specific semanticrelation.
Typical examples of syntagmatic LFs are Oper i(semantically empty verb which takes the i-th arrant 5ofthe key word as its subject and the key word as its directobject), like Operl(attention) = pay, Oper2(attention) =receive or Magn(escape) = narrow.
These examplesshow that these LFs convey eooccurrence r lations.-Parad igmat ic  LFs are used to express semanticrelations in the lexicon between the key word of the LFand its values, but not cooccurrence relations.
Typicalexamples are Sl(lecture ) = lecturer (Sl:Noun of thefirst typical actant), Sloc (box) = ring (Sloc: Noun oftypical place), So(buy) = purchase (So: Derived noun).Some paradigmatic LFs can be used to analyse orgenerate l xical coreference r lations:- Syn: synonym- ConvUkl: conversive- aener: generic word- St: typical noun for the i-th actant- Slratr: noun for typical instrument- Sm~: noun for typical means- Site: noun for typical place- Sr~: noun for typical result- Stood: noun for typical mod~- S a : name of actionSyn(callhlg) = vocationConv32 t 4(sell) = buyGener(apple) = fruitSI (lecture) = lecturerSinsn(palnt) =brushSmed(ltolsalt ) = saltSlo~(box) ~ringS~(mix) = mixtureStood(write) = writingS0(buy ) = purchaseRelations encoded by these LFs can appear in d i rec teoreferential  relations in texts when the value of thefunction and the key word maintain a semanticrelationship directly formalizable through a LF such asSres, Gener, Syn and Convijkl, as in:(8) Gener(lamb) = meatBuy lamb.
Be sure the meat is very fresh.LFs can be used to formalize ind i rect  iexiealcore ference  when coreference xists between lexicalitems and a dependent.
The dependent may be an actantas in (7) (lecturer, the Sl(lecture) is coreferential withthe fn'st actant Marga of lecture whereas audience, theS2(lecture) is coreferential with the second actant oflecture), or an adverbial, as in the following example:(9) Sloc(patiner ) = patinoireMarguerite t Jean ant patin6 sur le canali Rideau.Cene patinoire i fait 8km de long.\[Marguerite end Jean skated on the Rid~au Canal.
This"skating rink" is 8 km long.\]In (9), patinoire, Sloc(patiner) is coreferential withcanal Rideau.Moreover, LFs can be combined, as we see in thefollowing table:5)In the ECD, lecture will be described as a noun which hasthree syntactic actants: X's (actant I) lecture to Y (arrant II) onZ (arrant III), for example Jean's (actant I) lecture to third yearstudents (actant II) on semantic causality (actant I1\]).ACRES nE COLING-92.
NAm'ES, 23-28 AOfn" 1992 7 6 4 PROC.
OF COLING-92, NXlSrrES, AUG. 23-28, 1992key wurd values LFs oreumposlthmnf Lb'GenerGenerOellerGenerGenerS3mConY3214SOSOGeuer o GenerGeIler o SynGener o Conv3214Gener o S OSO o Conv3124ConY3214 oS0achat \[lmrclu~se\]vente Isale\]transaction Ideal\]auto \[car\]voiture lear\]voiture lcarlacheter \[buy\]acheter \[buy\]vendre lsell\]achat \[purchase\]auto \[carlvente \[sale\]acheter \[buy\]achetcr \[buy\]acheter \[buy\]transaction \[deal\]transaction Ideal\]action \[action\]v6hicule \[vehicle\]v6hicule \[vehicle\]auto tear\]v enth'e \[sell\]achat \[purchase\]vente lsale\]action \[acthl(livghicule \[vehicle\]trm~sactiou Ideal\]uausaction Ideal\]vente I sale\]vente \[s~de\]=Table 1: LFs aud compositions of LFs fltr directcoreference linksThe following facts should be notcxl about compositions:Compos i t ion  is not commutat ive .
Thus,So(Conv3214(aeheter)) = Conv3214(So(acheter)) =vente but Gener(So(acheter)) ~ S0(Gener(acheter))because Gener(acheter) does not have a value.- Some compositions are reducible.
For example, the LFSyn plays a transparent role in composition.In the perspective of text generation, this formalismappears very interesting for building coreferentialexpressions.
To point back to a referent alreadyintroduced, LFs and compositions of I,Fs offer manypossible ways for lexicalizing a given relerent.
Forexample, let us suppo~ that after having introduced thefollowing sentence,(10) a. L~fisser &uver laviande.
\[Let he meat stema.\]we have to refer again to the action la viande Ftuve.
Wecould try to use a noutinalization (So).
But, as fltere is nonominalization for the verb Ftuver, we could use insteadthe nomina l i za t ion  o f  the gener ic  term,So(Gener(dtuver)) = cuisa~n.
We could thus produce thefollowing sentence:(11 ) b.
A la fin de la cuisson, ajouter les cpiees\[At ile end of cooking, add the spices\]In the next section, we will examine the case of acomplex lexical anaphor: file superordilmte rm.3.
Superord inates  and  bas ic  nounsThe use of superordinate terms as anaphors raisesseveral interesting questions.First, to the extent hat a generic concept (for two ormore specific concepts) has a simple expression in alanguage, this is not necessarily the same term as thesuperordinate t rm (for the term corresponding to thespecific concepts).
For example, from a conceptual pointof view, knife and scissors are "cutting instruments".Nevertheless, it is not possible to naturally stthstitutecutting instrument for knife and scissors, as in:(12) a.
Use a knife mid scissors to cut up the duck,b.?
If you don't have these cutting instruments, pull theduck apart.ACIES DE COLING-92, NANTES, 23-28 AO~f 1992 7 6 5There is no consistently used term 12tr expressing tilegeneric concept of knife or scissors.
~lltis can be cuttinginstruments as well as instruments for cutting or cuttingutensils.
Whether or uot such  a teNll exisLs varies amonglauguages.
For example, in Mandarin Chinese, file termd~o is fidly accepted as a superordinate rm to point tothe Chinese equivalents of  knife aml scissors.
IllEnglish, a term like vegetable is the superordiuate ofcarrot, tomalo Or cucumber because it is consistentlyused for tlte~ previous words in texts.This entails that choice of snperordinate terms aslexical auaphors cannot be made at tile conceptual levelalone.Moreover, saperordinate terms call often bc: lnorceasily nsed to lexiealize reference to a uon-homegeueousset of elements than for reference to a single element orhomogcueous ~t,  as illustrated in (13) and (14):(13) a.
Put tile carrots ill to boiling water.b.
?
Remove the vegetables after l0 mimnes.
(14) a.
Throw the carrots, the leeks altd Ihe lx~tatoes in toboiling water.b.
Remove tile vegetables after l0 minutes.However, the ease with which a snperordinale can beused depends ou rite particular noun.
For example, inFrench, viande \[meatl can be snbsituted for bleuf Ibeefleven ill singular:(15) a. Menre le b~euf hcuire dmls l'eau I~ouillante.IPut the t~_ef in the I~iling waterlb.
Retirer la viande ml bout de 20 minutes.\[Remove the meat aftc'r 20 minutes\]This somewhat suri)rising i)henomenon can be analysedwith the help of the notion of basic level object proposedby Roseh et al (1976).
The imlx)rtance of the basic leveldistinction for text generation has recently been shownby Reiter (1990).
Rosch et al demonstrated that thetaxonomy of concepts could be organized using astnlcture with three levels: superordiuate, haste andsubordinate.
They define the basic level as follows:"basic objects a~e the most inclusive categories whosemembers: (a) possess ignificant numbers of attributes incmmnon, (b) have motor programs which are similar toone another, (c) have similar shapes, and (d) can beidentified from averaged shapes of members of theclass" (Rosch et al 1976: 382)It has been shown that lexemes correspomling to basiclevel objects seem to be the most natural terms tointroduce referents already idcntified.
For example, ifone wants to refer to some champignons de Paris\[button mushrootos\], one would prctk:r to call themchampignons \[nmshrooms\], provided that there is nopotcntial amttiguity with auy other mushrooms.Champignons de Paris would sccm too specific in thiscontext and vegetables would seem too vague.
Thischoice is not made randomly: champignon is the nouncorresponding to the highest basic level coucept todesignate these objects.
This would explain why in (15),one can refer to b~eufwith the superordinate viande.Nevertheless, rite notion of basic level object does notalways seem well suited to explain phenomena such asthat observed in (15).
For example, it seems that theconcept "volatile" \["fowl"\] fits perfectly the four criteriagiven by Rosch.
But, volatile \[fowll does not seem aPROC.
ol; C{1LIN(;-92, NANTES, AUG. 23-28, 1992natural French term for referring to a chicken,particularly in the sublangtmge of recitees.It is also problematic that the naming of basic levelobjects varies a great deal among languages.
Forexample, in Mandarin Chinese, the most natural term todesignate a knife when there is no ambiguity is the termd~o , which corresponds to "cutting instrument" inEnglish.
We could argue that conceptual representationdiffers with the mother tongue of the speaker (which isplausible, without joining the debate about language andthought) and that the lexicon reflects the conceptualviews.
Nevertheless, this position does not solve theproblem of terms like volaille, a unuatural term for abasic level object.It is significant hat this position creates practicalproblems for text generation: if conceptualrepresentation is reflected too closely in the choice oflexemes, this representation cannot be used as aninterliugua for multilingual generation or machinetranslation.In the light of this evidence, we have decidcd in favorof a strict theoretical separation between conceptualrepresentation a d lexical representation.
We believethat an appropriate couceptual representation can beused for multilingual generation because it is a nonlinguistic generalization above specific lexicalrepresentations.
We therefore distinguish the notion ofbasic level object, which belongs to cognitive science,from the notion of basic noun, which is a linguisticnotion 6.
We consider "viande" and "volatile" to be basiclevel objects while only viande is a basic noun.For lexical choice in text generation, we thus have todistinguish two very different processes:- Superordination should be used to introduce a nounwhich points back to a set of different nouns.
This is thecase in {carrots, leeks, cucumber} --> vegetables.
Thisprocess obeys a principle of economy.- Basic denomination is used to introduce the mostnatural term for a given referent or a set of referents.This process obeys a principle of "naturalness": itintroduces the most closely basic noun that correspondsto the concept o be lexicalized.
Basic denomination isoften used in texts like recipes: objects are firstintroduced with extreme precision and subsequentlyreferred to with the basic term.4.
Knowledge sources  fo r  determin ingl ex ica l  anaphorsIn the course of our work, we have proposed a seriesof algorithms for generating rammatical nd lexicalanaphora in procedural texts (Turin 1992).
Contrary tolexical anaphora, grammatical naphora makes use ofclosed lexical classes (determiners, pronouns and a fewspecial verbs) as well as ellipsis.These algorithms are derived from an empirical studyof French recipes, using a representative corpus of over16,000 words.
Recipes serve as a good prototype ofprocedural texts for assembling complex objects fromparts.
Even this modest corpus presents a wide variety oflexical and grammatical naphora which are typical ofassembly instructions.6) Wierzbicka (1985) has shown in lexicographic descriptionsthat he nantes of (words for) basic level objects have specialsemantic properties.,We describe below some of the knowledge sourcesand organization eeded to generate lexical andgrammatical naphora.
For lack of space, however, weleave out the model of state change management (neededto describe recipe ingredients being mixed together andtransformed (Kosseim 1992)), a~ld the focus model used.4.1 InputWe limit our scope to the linguistic part of generation;therefore, we assume that onr input is the ontput of a textplanner, which has already grouped actions intodiscourse structures as proposed by Grosz and Sidner(1986) and (Dale 1988), The input is thus a sequence ofactions and states in which participants (ingredients,instruments and agent) are represented by indices.4.2 Dictionary of conceptsThe dictionary of concepts has been inspired byNirenburg and Raskin 1987; concepts are mainlysubdivided into actions or objects.
We have added acategory of properties, needed to describe relationsbetween concepts (e.g., temporal limit) or attributes (e.g.size).Relations between concepts are isa, part-o for result,the latter one useftd in a domain where state changes arefrequent.
Thus, one can relate the action "cut" to theconcept "piece" which is the result of "cut".
Thedictiouary of concepts is not a copy of the language andthere are Concepts without any correspondinglexicalization.
Taxonomic organization is fimetional anddepends greatly on the field for which it has beenestablished.
In other words, our description of conceptshas limited value outside the domain of recipes.4.3 Dict ionary o f  lexical  entriesThe representation of lexical entries is stronglyinfhlenced by tile ECD (Mel'~uk & Folgu&e 1987,Mel'~uk et al 1988).
Two parts of tile entry areparticularly interesting for our topic: the semantic zoneand the LF zone.The semantic zone contains four types of information:- Tile semantic field to which the lexeme belongs.
Forexample, the verb simmer would have feature/cook/.- The mass/count feature.- The "basicness" feature, if the lexical item is a noun,indicates whether or not the noun is a basic noun.- The key word(s) for which the lexeme can be a value.For example, for the lexeme mixture, it will be statedthat it is the Sres of mix.In the LF :,.one, we simply enumerate he values of thelexical item as a key word.
For example, the entry forthe verb hacher \[chop\] may contain, among manyothers, hachis (Sres(hacher)) and hacho i r(Smed(hacher) ).5, Const ra in ts  fo r  generat ing  anaphorsWe now turn to the constraints which apply to thechoice of grammatical or lexical anaphors during textgeneration.
Our aim here is to generate the mostappropriate anaphor with respect to the textual context.To determine what is appropriate, we have used anempirical approach, rather than appeal to generalprinciples uch as Gricean conversational maxims (seeReiter 1990a & Dale 1988 for use of these notions forlexical choice in text generation).
A detailedACRES DE COLING-92, NANTES, 23-28 not'rr 1992 7 6 6 Paoc.
OF COLING-92, NANTES, AUG. 23-28, 1992examinatiou of our corpus of cooking recipes has sttowuthat anaphora is not governed so muct, by sU'ict rnlcs asby tendencies.
Thus, in a given context, a set of possibleanaphors can "compete" for selection.
When choosingfrom multiple possibilities we flavor ttte most"economical" anaphor, i.e., the due which conveys theleast information 7.Space limitations prevent a complete discussion of allfactors required for an anaphor choice algorithm (seeTutin 1992).
Here we give the most ilnporfantconstrai,~ts on choice among the principal anaphoricdevices s.The selection of an anaphoric device Ires two slages:?
First, at choice is made among of grammatical devices(e.g.
personal pronoun, verb complement ellipsis,coreferential definite NP, demonstrative NP).?
Then, if a lexical NP has been chosen, the corrcctlexical eataphor is determined.5.1 Grammatical  naphnrnThe introduction of a given grammatical naphordepends mainly on 4 kinds of paranmtcrs: a) theconceptual nature of referents, b) distance In antecedentand discourse structure, c) focaliz~'~tion a d d) potentialambiguity.We briefly review these different parameters tor eachtype of grammatical anaphor: verbal complementellipsis, persomtl prolmml, demonstrative NP,corefereutial definite NP.Verbal complement ellipsis as in the followingexaraple is very widespread in recipes, and characteristicof procedural instructions in general.
(16) Prepare the carrots, the celery and the asparagus.
Cookin the boiling water and take O out after 10 minutes.Verbal complement ellipsis is generally used todesignate a heterogeneous .set of objects, coutrary topersonal pronouns.
"llm distance from the antecedent canbe quite far bat focalization coustraints, in particularglobal focus - defined as the subset of the most salientitems - play a determining role for the production of thisanaphor.A personal prononn must nalne an object or a set ofsimilar objects.
It is governed by very strong localityconstraints (Hobbs 1978) and, as previously noted ill theliterature, personal pronouns often mainlain the tlmntaticcontinuity (Van Dijk & Kintseh 1983), i.e.
pronoun isthe local focus (what the clause is about) of both theprevious and the current clauses.
In fact, local focusgenerally supplies enough information for the healrer tocorrectly interpret the pronoun (as emphasized by Grosz,Joshi & Weinstein 1983), even if it is morphologicallyambiguous.Choice of a demonstrative NP does not depend ou theconceptual nature of the referent, which may be eitherthe local focus or the global focus.
Its contrastivefunctions with respect to personal pronouns and definiteNPs are rather complex.
Since demonstratives are7) Anaphoric devices thus have a default (strict) order ofpriority for application.8) We omit the realization constraints, such as the fact thatcertain verbs do not allow their complements to bepronominalized.infrequent in onr corpus, lbey are not treated furllterhere.Fur a definite NP, there is no conceptual iestriction onthe refm'ent.
A definite NP can be introduced atsubstaulial distance from its textual antecedent, andtypically dnes not occl,r in the following clan.~,especially if the antecedent was the local focus of itsclause and there is no potential ambiguity 9 .For each NP to be generated, potential ambiguitymust be taken into account.
This has to tlo with lexiealchoice.
For example, choice of an anlbignons NP such as& vin \[the wiue\] must be blocked if there is white wineand red wine in the context.
The context in which theanaphoric NP must be distinctive depends on theannphor chosen: it is tile preceding sentence fordemonstrative NP while, for definite NP, a larger contextnmst be taken in account lO,5.2 Lexical amlphoruWe now tun, to the constraints on choice of lexicalanaphoL When the grammatical mechanism chosen tklrexprc.ssing atnaphora involves a corellareutial (definite orden:tonstrative) lcxical NP, these c(mstraiuts conic intoplay to pick the most appropriate lexical form.
Theanaphoric lexical devices presented here for recipesconstitute only a subset of those that conld appear in thelanguage as a whole.
Nevertheless, we hylX)thesize thatthe COl)ceptual and linguistic onstraints governing theirusage are generalizable to other kinds of text.
Lexicalanaphora differs significantly on this point fromgrammatical naphora, whnse constraints, like discoursestructure or focalization, vary greatly according to ritekiud of text.
Therefilrc, while a giveu kind of text mightuse only a subset of possible lexieal auaphoric devices,these devices are governed by the mtme constraints in allkinds of texts.
For exautple, typical result mention (m/x --> mixture) is widespread in procedural texts butconstradltS governing thCnl are tile same ill ally kind oflext.
lu contrast, it appears that tile constraints governingusage of granlmalical naphoric devices, anti even thedevices thenlselves, are much more depenttent on thevariety of text.Given that a lexica\] NP has been chosen, as thegeneral type of anaphoric device, two kinds ofconstraints, conceptual nd linguistic, apply to select hethe specific kind(s) of lexical aUalthora which may bensed.
In case of anthiguity, i.e.
if file NP produced is notdistinctive, addilional processing will t'.c requirexl.Conceptual Cmlslraittts concern mainly:The state of the object .
l,'or example, all objectwhose state is being transfonued by an action should berelcrenced via its resulting state.- Groupings of ohjects: is the referent to be generateda set of identical objects, a heterogenous set, ahomogenous sct or a single element?
A heterogenons setis composed of elements which just have no close9) For example, die definite NP hi file second clause is ra)t verynatural in French:Marie a rencontr6 un charcufier.
~ _ ?
I  f~it on tr~sbun pht&\[Marie met a porkbutcher.
~ I i ~  makes verygo~,d l~ .
l10) For recipes, we use Date's (1988) proposal to take thewhole text as context, since it is usually short.
This would ofCoIIrSe not he satisfactory hlr longer texts,ACRES DE COLING-92, NANTES, 23-28 AO~r 1992 7 6 7 PROC.
O1~ COLING-92.
NANn.:S.
AU?;.
23-28, 1992gener ic  concepts  in common,  such as,{ "salt" ,"knife" ,"table"}.Linguist ic constraints involve mostly the lexicalform and relative order of the coreferential NPs thathave been lexicalized in the preceding text.
Therefore,we do take advantage of referents already lexiealized inthe previous context (which must be stacked for beingavailable when lexicalizing).The following properties are examined:- The linguistic form of antecedent NP: is it a singlenoun, a compound noun or a complex NP?- The existence of a lexico-semantic association for theantecedent like the generic term or the typical result(which can mostly be formalized through a LF).- The "basicness" of the head word of the antecedent NP.Ambigu i ty  const ra in ts  are used to check if thelexicalization is not ambiguous.If a unique object or a set of identical objects can notbe lexicalized in a non ambiguous way, we lexicalize itthe same way it has been first introduced in the text(Initial strict repetition).
We use this ad hoc strategybecause first mention of a referent is generally the mostaccurate.
Of course, this would not always be theminimal distinguishing description (Dale 1988), but asReiter (1990a) points out, determining a minimaldistinguishing description may require overly complexprocessing.In case of potential ambiguity for a set ofheterogeneous objects, we use "complex coordination".With this process, we regroup first the first levelsuperordinates and apply the other devices to theremaining list of objects 11.Table 2 shows several important kinds of lexicalanaphoric devices, with their associated conceptual,linguistic and non ambiguity conditions.Concepicual Properties Linguistic Non ambiguity "Lexleal anaphor Properties Constraints ExamplesUnique object'or set of Antecedent is a 'single No instance previously lapin-->lapin \[rabi~it\] Strict RepetitionInitial Strict Repetitionidentical objectsUnique object or set ofnoun (or fixed compo-und) and is a basic nounintroduced has the samerepetitionNo constraints Tile other devices are A small rabbit ... theidentical objects ambiguous rabbit --> the small rabbitPartial Repetition Unique object or set of Antecedent is a not fixed No previously introduced petit lapin \[small rabbit\]identical objects compound (except "part- NP has the same partial --> lapinof" types) and the NP repetitionhead is a basic nt~unSuperordlnatlon Set' of objects having a\[ Nominal heads of ante- No previously introduced {carottes, poireaux,close common genericl cedents have the same NP has the sameconcept common superordinate, supemrdinate termLF: GenerBasic Denomination Umque Object or set of Nominal head of NP is No previously introducedidentical objects not a basic noun NP has the same basicdenominationN?mlnallzatl?n Action '" No constraintsObject(s) having been, affected by a strongtransformationSet of different objectswhich have no commongenetic onceptTypical Result MentionAntecedent verb can benominalized or super-ordinate of antecedentverb can be nominalized.LFs: S o or S O o GenerThere is a result noun forfile actants having beenaf fected by thetranformation.LF: S,,~No element of thecoord inat ion  isambiguousComplexCoordinationNo previously introducedNP has tbe same resultmentionNo constraintstomates} \[carrots, leeks,tomatoes\] -->16~umes \[vegetables\]petites girolles\[small chanterellesl -->ehampignons\[mushrooms\]faire cuire le poulet\[cook the chicken\] --> lacuisson du poulet \[thecooking of the chicken\]mtlanger les patates i\[mix the potatoes i \] --> lemtlange i \[the mixmrei\]{petit lapin, grosseschanterelles } \[smallrabbit, big chanterelles\]--> le lapin et les cham-pignons \[le lapin et leschampignons\]Table 2: Constraints governing the introduction of lexical anaphora11) We choose here to apply supe~ordination separately to eachinstance: we do not allow regroupings of elements forsuperordinatinn or typical result mendon because, as Kosseimhas noticed, we would have to process all the subsets togenerate correct lexicalizatinns.AcrEs DE COLING-92, NANTES, 23-28 hO~" 1992 7 6 8 Paoc.
OF COL1NG-92, NANTES, AUO.
23-2g, 1992ConclusionIn this tmper, we have described some of the problemsraised making lexical choice in textual context, inparticular for coreferential lexical anaphora.
We haveshowed that paradigmatic Lexical Functions are wellsuited for creating lexical coreferential links.
We havealso distinguished the selection tff superordinate rm,which is used to point back to a set of different words,from selection of basic denomination, which is usetl toname in the most natural way a concept alreadyintroduced by a previous noun.A series of constraiuts has been formulated which canbe implemented in an algorithm for selecting amongnatural grammatical nd lexical anaphors in proceduraltexts.
Most of these algorithms have been implementedby Kosseim 1992.
The generator uses Prolog antispecifically Definite Clause Grammar (DCG) to producetext.We find that determination f grammatical anaphomis more dependent on the genre and sublanguage than islexical anaphora, which appears governed by fairlygeneral constraints.
However, morn work needs to bedone to check these results in other precedural texts, andthen more broadly in less similar text types, Also, itwould be interesting to see to what extent anaphoricexpressions hare common constraints with deicticexpressions for which the context of interpretation is notthe previous text, but the extra-linguistic ontext~AcknowledgementsWe would like to thank Guy Lapalme, Igor Mel'~uk,Alain Polgu~re, Marga Alonso Ramos and Xiaobo Renfor fruitful discussions and helpful suggestions.
Specialthanks to Le'fla Kosseim, who collaborated in thisresearch and with whom we shared many interestingdiscussions.
The work reported in this paper wassupported by a Government of Canada Award.ReferencesBateman J.
A.
& L.Wanner (1990).
Lexical CooccurrenceRelations in Text Generation, in Proceedings of the FifthInternational Workshop on Natural Language Generation,Dawson, Pennsylvania, 31-38.Dale, R. (1988).
Generating Referring Expressions in aDomain of Objects and Processes, Ph..D. thesLs, University ofEdinburgh.Dtcary M. & G. Lapalme (1990).
An Editor for theExplanatory Dictionary of Contemporary French (DECFC),ComputationalLinguistics, 163, 145-154.Grosz B.J., Joshi A., Weinstein S. (1983).
Providing aUnified Account of Definite Noun Phrases in Discourse, inProceedings of the 21st Annual Meeting of the ACL, MIT,Cambridge, Mass., 15-17 june, 1983, 44,49.Grosz B.J.
& C. Sidner (1986).
Attention, Intentions and theStructure of Discourse, Computational Linguistics, 12, 175-204.Halliday M.A.K & R. Hasan (1976).
Cohesion in EnglishLondon, Longman.Heid U.
& S. R~b (1989).
Collocations in MultilingualGeneration, i  Proceedings of FACL, 130-136.Hobbs J.
(1978).
Resolving Pronoun References, Lingua,44, 311-338.Iordanskaja L., R. Kittredge & A. Polgu\[re (1991).
LexicalSelection and Paraphrase in a Meaning-Text Generation Modelin C.L.
Paris, W. R. Swartout & W.C. Mann eds.,NaturalLanguage Generation in Artificial Intelligence andComputational Linguistics, 293 -312.Kosseim L. (1992), G~n~.ration automatique de proc~dgscoh~sifv darts les recettes de cuisine, M.Sc.
thesis, Dtpartementd'informatique et de recherche op&ationnalle, tJniversit6 deMonutal.McDonald D. (1991).
On the Place of Words In lheGeneration Process in C.L.
Paris, W. R. Swastout & W.C.Mann eds.,Natural Language Generation in ArtificialIntelligence arm Computational Linguistics, 229-247.Mel'fiuk LA.
et al (1988a).
Dictionnaire Explicatif etCombinatoire du Franga~ Conternporain.
Recherches Lexico-sbnantiques.
11.
Montrtal, Presses de l'Universit~ de Montrtal.Mel'~'uk I.
(1988b).
Paraphrase etlexique dans la ThtorieSens-Texte, Cahiers de Lexicologie LII, 5-50 et LIlI, 5-53.Mel'c'uk I.
& A. Polgu&e (1987) A Formal Lexicon ill theMeaning-Text Theory (or how to do Lexica with Words),Computational Linguistics, 13, 3"4, 1987, 261-275.Mel'cuk 1.
& Zholkovsky, D (1970).
Sur la synthtses6mmltique, TA.
Informationa', 2 1-85.Nirenbnrg S. & I. Nirenburg (1988).
A Framework forLexical Selection in Natural Language Generation, inProceedings of COLING 88, Budapest, 471 "475.Nirenburg S. & V. Raskin (1987).
The Subworld ConceptLexicon and the Lexicon Management System, ComputationalLinguistics, 13,3"4, 276-289.Reiter E.B.
(1990a).
Generating Appropriate NaturalLanguage Object Descriptions, Ph.D.
Thesis., llarvardUniversity.Reiter E.B.
(1990b) A New Model for Lexical Choice forOpen-Class Words, in Proceedings of the Fifth haernatio~gdWorkshop on Natural Language Generation, Linden HallConference Center, Dawson, Pennsylvania, 23-30.Rosch E., C. B. Mervis, W. 1).
Wayne, D. M. Jolmson & P.Boyes-Braen (1976).
Basic Objects in Natural Categories,Cogr,;tive Psychology 8, 382,439.Sidner C. (1983).
Focusing in the Comprehension ofDefinite Anaphora, in M. Brady & R. Berwickeds.,Computational Models of DL~course, Cambridge (UK.
),Cambridge University Press, 267-33f).Tutin A.
(1992) Etude des anaphores grammaticales etlexicales dane la perspective de la g~t~ration automatiquedarts des textes de procedures, Ph.D. Thesis, IMpartement delinguistique, Universit6 de Montrtal.Wierzbicka A.
(1985).
Lexicography and conceptualanalysis, Ann Arbor (Mich.), Keroma Publishers inc.ACRES DE COLING-92, NAmeS, 23-28 Aou'r 1992 7 6 9 PRoc.
o1: COLING-92, NANTES, AUG. 23-28, 1992
