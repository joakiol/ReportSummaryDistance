Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 754?764,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsCorrecting Preposition Errors in Learner English Using Error CaseFrames and Feedback MessagesRyo Nagata1?Mikko Vilenius2Edward Whittaker31Konan University / Kobe, Japan2The Japan Institute for Educational Measurement, Inc. / Tokyo, Japan3Inferret Limited / Northampton, Englandnagata-acl@hyogo-u.ac.jp.AbstractThis paper presents a novel frameworkcalled error case frames for correctingpreposition errors.
They are case framesspecially designed for describing and cor-recting preposition errors.
Their most dis-tinct advantage is that they can correct er-rors with feedback messages explainingwhy the preposition is erroneous.
This pa-per proposes a method for automaticallygenerating them by comparing learner andnative corpora.
Experiments show (i) au-tomatically generated error case framesachieve a performance comparable to con-ventional methods; (ii) error case framesare intuitively interpretable and manuallymodifiable to improve them; (iii) feedbackmessages provided by error case framesare effective in language learning assis-tance.
Considering these advantages andthe fact that it has been difficult to providefeedback messages by automatically gen-erated rules, error case frames will likelybe one of the major approaches for prepo-sition error correction.1 IntroductionThis paper presents a novel framework for correct-ing preposition errors.
Its most significant advan-tage over previous methods is that it can providelearners with feedback messages, that is, explana-tory notes describing why the detected preposi-tion is erroneous and should be corrected as in-dicated, as shown in Fig.
1.
Despite the fact thatappropriate feedback messages are essential inlanguage learning assistance (Ferris and Roberts,2001; Robb et al, 1986), which is one of the im-mediate applications of grammatical error correc-?Part of this work was performed while the author was avisiting researcher at LIMSI, Orsay (France).Target sentence:  In the univerysity, I studied English in the morning.Error: correct preposition atFeedback message:Though both at and in are prepositions of place, at is used to denote the place (university) to which the person belongs and where  the learning activities  take place.Target sentence:  When the day is holiday, I go to shopping, singing in Karaoke and talking in cafe.
Error: remove toFeedback message:Go directly takes the activity  without a preposition when it means traveling to a place in order to take part in an activity  by go and ?ing,        e.g.,  I went shopping.
Similar expressions: go swimming, go fishing, go sightseeingFigure 1: Error correction and feedback messagesprovided by the proposed method.tion, almost all previous methods are incapable ofproviding feedback messages.Grammatical error correction has been inten-sively studied in recent years.
Current methodsmostly exploit machine learning-based classifiersto correct target errors; examples are errors in ar-ticle (Han et al, 2006; Nagata et al, 2006; Ro-zovskaya and Roth, 2011), preposition (Chodorowet al, 2007; Felice and Pulman, 2008; Rozovskayaand Roth, 2011; Tetreault et al, 2010), andtense (Nagata and Kawai, 2011; Tajiri et al, 2012),to name a few.
Recently, Wu and Ng (2013) andRozovskaya and Roth (2013) proposed methodsfor simultaneously correcting multiple types of er-rors using integer linear programming.
Anothermajor approach is to use a language model (LM)for predicting correct words or phrases for a givencontext.
Some researchers (Brockett et al, 2006;Yoshimoto et al, 2013) use statistical machinetranslation (SMT) for the same purpose, whichcan be regarded as the mixture of a classifier andan LM.
With these diverse techniques, correctionperformance has dramatically improved against awide variety of target errors.As noted above, however, one of the cruciallimitations of these previous methods is that they754are not capable of providing feedback messages.They are not suitable for generating open-classtext such as feedback messages by their nature.Some researchers (Kakegawa et al, 2000; McCoyet al, 1996) made an attempt to develop hand-crafted rules for correcting errors with feedbackmessages.
However, this approach encounters thetremendous difficulty of covering a wide variety oferrors using hand-crafted rules.In view of this background, this paper presents anovel error correction framework called error caseframes an example of which is shown in Fig.
2.They are case frames specially designed for de-scribing and correcting errors in preposition at-tached to a verb; the reader may be able to see thatit describes preposition errors such as *John oftengoes shopping to the market with his family.
andthat the preposition to should be replaced with at.This paper proposes a method for automaticallygenerating them by comparing learner and nativecorpora.
Achieving a comparable correction per-formance, they have the following two advantagesover the conventional approaches: (i) they are in-tuitively interpretable and manually modifiable toenrich them; (ii) they are capable of providingfeedback messages.The rest of this paper is structured as fol-lows.
Sect.
2 introduces the definition of error caseframes.
Sect.
3 discusses the method for generat-ing error case frames.
Sect.
4 describes how to cor-rect preposition errors with feedback messages byerror case frames.
Sect.
5 describes experimentsconducted to evaluate error case frames.
Sect.
6discusses the experimental results.2 Error Case FrameAn error case frame consists of a verb, cases, anda feedback message as shown in Fig.
21.
The fol-lowing explains error case frames in detail basedon this example; occasionally consulting it mayhelp understanding the following sections.An error case frame always has a verb.
In Fig.
2,the verb is go.Cases are arguments the verb takes in an errorcase frame.
A case consists of a case tag and caseelements.
A case tag and case elements describe,respectively, the role that the case plays in the er-ror case frame and a set of words that are allowed1Fig.
2 shows an example of error case frames for illus-tration purposes.
They are formally expressed in a machine-readable format such as XML.goFeedback messageTo mean traveling to a place in order to take part in an activity, go takes at, in, or on depending on the activity.
For example, the activity shoppingtakes place at a store (not  shopping  to a store),    and thus go shopping at a store.cf.
We went  sightseeing in Baltimore.Preposition casePrep_dobj: {shopping} *Prep_to: {store,market}  ?
Prep_at(Prep_with: {family})Basic caseSubj: {PERSON}verbcase elementcase tagcasesFigure 2: Example of an error case frame.to appear as the argument.
For instance, in Fig.
2,?Subj: {PERSON}?
is a case where its case tagand element are ?Subj:?
and ?{PERSON},?
re-spectively, denoting that a person such as Johnplays a role of the subject of the verb.
Note thattokens in all upper case such as ?PERSON?
referto a group of words such as {john,he,?
?
? }
in thispaper.Cases are classified into two categories: basicand preposition cases.
Basic cases are either a sub-ject or a particle, whose case tags are ?Subj:?
and?Ptr:?, respectively.
The ?Subj:?
case is obliga-tory while the ?Ptr:?
is optional.
Preposition casescorrespond to the prepositions the verb takes as itsarguments.
Its case tag has the form of ?Prep x?where x ranges over the target prepositions.
Itshould be emphasized that direct and indirect ob-jects are included in the preposition cases for effi-ciency; their case tags are denoted as ?Prep dobj?and ?Prep iobj?, respectively.
Preposition casesare classified into those obligatory and optional.Optional here means that the verb can constitutea sentence with or without the preposition.
Op-tional prepositions are written in parentheses as in?
(Prep with:{family})?.Preposition cases describe the informationabout an error.
An error case frame is constrainedto contain only one erroneous preposition case.
Itis marked with the symbol ?*?.
So, the preposi-tion case ?
*Prep to:{store,market}?
is erroneousin Fig.
2.
The correct preposition is described af-ter the symbol ???
as in ??
Prep at?.Error case frames are furnished with feedbackmessages.
Unlike verbs and cases, which are au-tomatically filled based on corpus data, they aremanually edited.
A human annotator interpretserror case frames and adds explanatory notes tothem.
This may seem time-consuming.
How-755ever, the editing is far more efficient than manuallycreating correction rules with feedback messagesfrom scratch because error case frames are highlyabstracted as explained in Sect.
3.
Above all, it is asignificant advantage over the previous classifier-/LM-based methods considering that there existsno effective technique for augmenting these meth-ods with feedback messages.3 Generating Error Case FramesThe method proposed here exploits two sourcesof corpus data: native and learner corpora.
Caseframes (error case frames without the informationabout an error and a feedback message) can beautomatically extracted from parsed sentences asKawahara and Uchimoto (2008) show.
The pro-posed method generates error case frames by com-paring case frames generated from the learner cor-pus with those from the native corpus.
The basicapproach is to extract, as error case frames, caseframes which appear in the learner corpus but notin the native corpus.
However, this approach is sosimple that it extracts undesirable false error caseframes which do not actually correspond to prepo-sition errors.
To overcome the problem, the fol-lowing procedures are applied:(1) Filtering input sentences(2) Extracting case frames(3) Recognizing optional cases(4) Grouping case frames(5) Selecting candidate error case frames(6) Determining correct prepositions(7) Enriching error case frames(8) Manually editing error case frames(1) Filtering input sentences: This is a pre-process to filter out unsuitable input sentences forcase frame generation.
Accurate parsing is es-sential for accurate case frame generation.
Pars-ing errors tend to occur in longer sentences.
Toreduce parsing errors, Kawahara and Uchimoto(2008) propose filtering out sentences which arelonger than 20 words.
We adopt this filtering inour method.
We also filter out sentences contain-ing commas, which often introduce complex struc-tures.
We apply the filtering pre-process only tothe native corpus; the availability of learner cor-pora is still somewhat limited and therefore we useall the sentences available in the learner corpus forbetter coverage of preposition errors.
(2) Extracting case frames: This procedurecan be viewed as a slot filling task where thegoFeedback messagePreposition casePrep_dobj: {shopping} Prep_to: {market}Basic caseSubj: {PERSON}Input: John went shopping to the market.wentJohn shoppingsubj dobjprep_toDependency parsePERSONmapping to sensemarketthedetCase framegostemmingFigure 3: Example of case frame extraction.slots are the verb and the cases in a case frame.To achieve this, the corpus data are first parsedby a parser.
Then, for each verb, the predicate-argument structures are extracted from the parsesas shown in Fig.
3.
Here, only head words are ex-tracted as arguments.
They are reduced to theirbase form when extracted.
Certain classes ofwords are replaced with their corresponding sense(e.g., John to PERSON); the mapping betweenwords and their senses is shown in Appendix A.In the case of the learner corpus, mis-spelt wordsare automatically corrected using a spell-checker.Finally, a case frame is created by filling its slotswith the extracted predicate-argument structures.Hereafter, case frames generated from the nativeand learner corpora will be referred to as the na-tive and learner case frames, respectively.
(3) Recognizing optional cases: it is crucialfor generating flexible error case frames to recog-nize optional preposition cases.
Optional preposi-tion cases are determined by the following heuris-tic rules: (a) Objects are always obligatory; (b)The number of obligatory preposition cases (ex-cept objects) is at most one; (c) Prepositions ap-pearing left of the verb are optional; (d) Preposi-tions appearing right of the verb are optional ex-cept the one which is nearest to the verb.
Rule (a)states that objects are always recognized as oblig-atory2.
Rule (b) constrains an error case frame tohave at most one obligatory preposition.
Certainverbs sometimes have more than one obligatorypreposition as in range from A to B.
However, thelarge majority of verbs satisfy rule (b).
Rule (c)states that prepositions appearing left of the verb2A sentence can be constituted without objects as in Wesing.
Rule (a) always mistakenly recognizes such objects asobligatory.
However, preposition errors never appear in sen-tences consisting of no object nor prepositions, and thus, theobjects mistakenly recognized as obligatory never cause anyproblems in preposition error correction in practice.756in the input sentence are optional preposition casesas in In the morning, he went shopping.
Rule (c)is based on the assumption that obligatory casesare tied to the verb more strongly than optionalcases.
In other words, obligatory cases cannoteasily change their position.
Conversely, optionalcases have more freedom of their position, whichenables them to appear left of a verb.
Admittedly,obligatory prepositions can appear left of a verbas in To school, he went in certain circumstancessuch as in poetry.
However, this usage is not sofrequent in corpora normally used as training datasuch as newspaper articles.
Rule (d), together withrule (b), states that if more than one prepositionappears right of the verb, the one nearest to theverb is obligatory and the rest are optional.
Rule(d) is based on the same reasoning as in rule (c).Optional preposition cases are sometimes deter-mined naturally by comparing two case frames.In this case, one of them must consist of onlythe object(s) as its preposition case(s) as in ?
[goSubj:{PERSON} Prep dobj:{shopping} ].?
Then,the other case frame must consist of the same verb,the same basic cases, and the same object(s).
Theonly difference between them is preposition cases(except the object(s)) (e.g., [go Subj:{PERSON}Prep dobj:{shopping} Prep at:{market} ]).
Thecase frame only with the object(s) proves the otherto be valid without the preposition case(s).
Thus,these preposition cases are recognized as optional(e.g., [go Subj:{PERSON} Prep dobj:{shopping}(Prep at:{market}) ]).
(4) Grouping case frames: Similar case framesin the native case frames are grouped into one,which will play an important role in (7) Enrichingerror case frames.
Case frames comprising sim-ilar cases tend to denote similar usage of a verb.Considering this, case frames are merged into oneif they consist of the same verb, the same basiccases, and the same case tags of the obligatorypreposition cases.
The grouping procedure is illus-trated in Fig.
4.
When preposition cases are oblig-atory in one case frame and optional in the other,the discrepancy is resolved by setting the prepo-sition case to optional in the merged case frame.Note that this grouping procedure is not applied tothe learner case frames so that erroneous usages inthe learner case frames do not propagate to other(correct) learner case frames.
(5) Selecting candidate error case frames:Candidates for error case frames are selected fromthe learner case frames.
If a learner case framedoes not match, ignoring optional prepositioncases, any native case frame, it is selected as acandidate for an error case frame on the assump-tion that case frames corresponding to erroneoususages do not appear in the native corpus.Alternatively, an error-annotated learner cor-pus can be used to select error case frames; sim-ply extracting case frames of which preposition ismarked as an error gives error case frames.
In thiscase3, procedure (6) may be omitted and proce-dure (7) is directly applied after procedure (5).
(6) Determining correct prepositions: Now,correct prepositions for the candidate error caseframes are explored.
Each case tag of the prepo-sition cases in a candidate is replaced, one at atime, with one of the other target prepositions.This replacement can be interpreted as error cor-rection.
Take as an example the following can-didate error case frame: [go Subj:{PERSON}Prep dobj:{shopping} Prep to:{market} ].
Re-placing the case tag ?Prep to?
with ?Prep at?
cor-responds to correct expressions such as John of-ten goes shopping at the market.
Note that re-placing a direct object with one of the preposi-tions corresponds to correcting an omission er-ror as in ?Prep dobj?
with ?Prep to?
in ?
[goSubj:{PERSON} Prep dobj:{market} ]?.
Simi-larly, replacing a preposition with an object cor-responds to correcting an extra-preposition er-ror (e.g., ?Prep to?
with ?Prep dobj?
in ?
[goSubj:{PERSON} Prep to:{shopping} ])?.To examine whether each correction is validor not, the native case frames are again used; ifthe replaced case frame matches one of the na-tive case frames, the correction is determined tobe valid.
Here, we define the match as the twocase frames consisting of the same verb, the samebasic cases, the same obligatory preposition cases,and the same preposition case to which the cor-rection is applied (if it is an optional one).
If thecondition is satisfied, the information on the errorand correction is added to the candidate error caseframe.
If a valid correction is found, the candi-date is determined to be a valid error case frame.In total, their validity is double-checked, once in(5) and once in (6), by comparing them with the3We do not make use of error-annotated learner corpora inthis paper in order to reveal how well the proposed methodsperform without such corpora.
In practice, one can use error-annotated learner corpora together with raw learner corporato achieve better performance.757goFeedback messagePreposition casePrep_dobj: {shopping} Prep_at: {store}(Prep_with:   {family} )Basic caseSubj: {PERSON}goFeedback messagePreposition casePrep_dobj: {shopping} Prep_at: {store,market}(Prep_with:   {family} )Basic caseSubj: {PERSON}goFeedback messagePreposition casePrep_dobj: {shopping} Prep_at: {market}Basic caseSubj: {PERSON}Figure 4: Example of grouping case frames.native case frames.
(7) Enriching error case frames: The gener-ated error cases are limited in error coverage be-cause the procedures so far solely rely on prepo-sition errors appearing in the learner corpus.
Inother words, it is impossible to generate error caseframes corresponding to preposition errors whichdo not appear in the learner corpus.
To overcomethis limitation, the generated error case frames areenriched using the native case frames.
For each er-ror case frame, we already know the correspond-ing native (thus, correct) case frame, which is ob-tained in (6).
The corresponding native case frameis normally much richer in preposition cases be-cause of the optional cases and grouping givenby procedures (3) and (4), as shown at the top ofFig.
5.
These additional cases are useful to enricherror case frames.For the preposition case which is determinedto be erroneous, its correct preposition is foundin the error case frame (e.g., ??
Prep at?
at thetop-left of Fig.
5).
Also, its correct prepositioncase is found in the corresponding native caseframe (e.g., ?Prep at:{market,store}?
at thetop-right).
Replacing the case element of theerroneous case by one of the case elements ofthe correct preposition case gives a new can-didate for an error case frame (e.g., replacingmarket of ?
*Prep to:{market}?
by store gives?
[go Subj:{PERSON} Prep dobj:{shopping}*Prep to:{store} ].?
It should be emphasized thatthis new error case frame is still a candidate at thispoint and the usage might be correct.
To verifyif it really describes an erroneous prepositionuse, the native case frames are searched for; ifit matches one of them, that means that the useof the preposition actually appears in the nativegoFeedback messagePreposition casePrep_dobj: {shopping} *Prep_to:  {market} ?
Prep_atBasic caseSubj: {PERSON}Error case frame goFeedback messagePreposition casePrep_dobj: {shopping} Prep_at: {market,store}(Prep_with:   {family} )Basic caseSubj: {PERSON}Native case frameVerificationgoFeedback messagePreposition casePrep_dobj: {shopping} *Prep_to:       {market,store} ?
Prep_at(Prep_with:   {family})Basic caseSubj: {PERSON}Expanded error case frameFigure 5: Enriching an error case frame.corpus.
Therefore, it should be discarded.
Onlyif a match is not found, is the case element addedto the erroneous preposition case in the originalerror case frame.
This process is illustrated in thebox denoted as Verification in Fig.
5.For the other preposition cases which are not er-roneous, the enriching procedure is much simpler.They are simply added to the error case frame asshown in Fig.
5.
One thing we should take careof is that there might be a discrepancy in obliga-tory/optional between the cases of the error caseframe and the native case frame.
This discrepancyis solved by setting the preposition case in the er-ror case frame to optional.
The resulting expandederror case frame after procedure (7) is shown atthe bottom of Fig.
5 where the enriched cases areshown in red.
(8) Manually Editing Error Case Frames:The most important editing is the addition of feed-back messages.
A human annotator interprets thegenerated error case frames and adds explanatorynotes to them.
Although this basically requiresmanual editing, part of feedback messages can beautomatically created to facilitate the procedure.For example, example sentences corresponding toan error case frame can be automatically addedto it, whether correct or error examples, becausethe original sentences from which the (error) caseframes extracted are available in the native andlearner corpora.
Besides, setting a variable tothe feedback message allows it to be adaptable tocorrection results as shown in Fig.
6.
In Fig.
6,XPrep tois a variable.
It is replaced with oneof the case elements of ?Prep to:?
depending oncorrection results.
Also, it will be beneficial tolink similar error case frames each other, whichallows the user to obtain additional information.758goFeedback messageTo mean traveling to a place in order to take part in an activity, go takes at, in, or on depending on the activity.
For example, the activity shoppingtakes place at a _ (not  shopping  to a	_ ), and thus go shopping at 		_ .cf.
We went  sightseeing in Baltimore.Preposition casePrep_dobj: {shopping} *Prep_to: {store,market}  ?
Prep_at(Prep_with: {family})Basic caseSubj: {PERSON}verbcase elementcase tagcasesFigure 6: Error case frame with a variable.For example, the example error case frame inFig.
6 may be linked to similar case frames such as?
[ go Subj:{PERSON} Prep dobj:{sightseeing}*Prep to:{Baltimore} ?
Prep in ].?
One can re-trieve similar error case frames from the generatederror case frames where the similarity betweentwo error case frames are defined by the overlapin the verb, the basic cases, and the case tags ofthe preposition cases.The generated error case frames may be furtheredited to enrich them.
As we can see in Fig.
5, thegenerated error case frames are easy to interpret.This property enables us to manually edit them toenrich their preposition cases.
For example, onemight add a case element such as supermarket tothe preposition case ?Prep to:{market,store}?
inthe example error case frame.
Conversely, onemight discard unnecessary case elements, cases,or even error case frames.4 Correcting Preposition ErrorsPreposition errors are corrected by applying thegenerated error case frames to the target text.
Caseframes are first extracted from the target text by thesame procedures (2) and (3) in Sect.
3.
Then, eachextracted case frame is examined if it matches oneof the error case frames.
If a match is found, thepreposition is detected as an error and the correctpreposition is suggested with the feedback mes-sage according to the matched error case frame.The match between a case frame and an error caseframe is defined in the exact same manner as inprocedure (4) in Sect.
3.
Sometimes, a case framematches more than one error case frame suggest-ing different corrections.
In this case, the mostfrequent correction among the candidates is cho-sen to correct the error, which was applied in theevaluation described in Sect.
54.One of the advantages of error case frames isthat they do not require an error-annotated corpusas explained in the previous section.
This meansthat the target text itself can be used as part of alearner corpus for generating error case frames atthe time of error correction.
Applying procedures(2) to (7) to the target text generates additional er-ror case frames5.
Although feedback messages arenot available in these additional error case frames,they are still useful for improving correction per-formance, especially in recall.
Hereafter, this wayof error case frame generation will be referred toas active generation.A pre-experiment using a development data setrevealed that there were some preposition errorsfor which error case frames were not generatedeven though the corresponding erroneous and cor-rect preposition usages appeared in the learner andnative corpora, respectively.
They are prepositionerrors where the preposition is incorrectly usedwith an adverb as in *John went to there.
To beprecise, they are either an adverb denoting a place(e.g., there) with a preposition concerning a place(at, in, on, and to) or a noun denoting time, fre-quency, and duration with a preposition concern-ing time, frequency, and duration (at, for, in, andon).
In the native corpus, these adverbs or nounsare correctly used without a preposition and thusthey are not recognized as a prepositional phraseby a parser.
Therefore, corresponding native caseframes are never found for these types of errorsin procedure (6), and in turn error case frames arenever generated for them.Considering that they are limited in numberbecause they are independent of verbs and ba-sic cases, we decided to manually create er-ror case frames describing these types of er-rors.
In these error case frames, the verband the basic cases are filled with ANY denot-ing any word.
The preposition cases are man-ually filled based on the linguistic knowledgeknown as absence of preposition (Quirk et al,1985).
For example, an error case frame forthe above error would be ?
[ANY Subj:{ANY}*Prep to:{here,somewhere,there}?
Prep dobj ].
?Certain errors involve a phrase such as *John goesshopping in every morning.
To handle these cases,4Ties are broken by random selection.5Recall that procedure (1) is only applied to the nativecorpus.759these manually created error case frames are al-lowed to have phrases as their case elements (e.g.,[ANY Subj:{ANY} *Prep in:{every morning} ?Prep dobj ]).5 EvaluationWe evaluated the proposed method from twopoints of view: correction performance and use-fulness of feedback messages.
We measured cor-rection performance by recall, precision, and F -measure.
In the evaluation on usefulness of feed-back messages, three human raters (a teacher ofEnglish at college and two who have a masterdegree in TESOL) separately examined whethereach feedback message was useful for learning thecorrect usage of the preposition.
We defined use-fulness by the ratio of feedback messages evalu-ated as useful to the total number of feedback mes-sages.We used the following data sets in the evalua-tion.
We selected the Konan-JIEM (KJ) learnercorpus (Nagata et al, 2011) as the target texts.
TheKJ learner corpus is fully annotated with grammat-ical errors.
In addition, it includes error correc-tion results of several benchmark systems.
Thismeans that one can directly compare correctionresults of a new method with those of the bench-mark systems, which reveals where the method isstrong and weak compared to the benchmark sys-tems.
The KJ corpus consists of training and testsets.
We used the training set to generate error caseframes and evaluated correction performance onthe test set.
In addition to these data sets, we cre-ated a development set, which we had collectedto develop the proposed method.
We did not useit in the final evaluation.
As a native corpus, weused the EDR corpus (Japan electronic dictionaryresearch institute Ltd, 1993), the Reuters-21578corpus6, and the LOCNESS corpus7.
We usedthe lexicalized dependency parser in the StanfordStatistical Natural Language Parser (ver.2.0.3) (deMarneffe et al, 2006) to obtain parses for the datasets.
Table 1 shows the statistics on the data sets.Using these data sets, we implemented threeversions of the proposed method.
The first onewas based on error case frames generated from thetraining set of the KJ corpus.
The second one wasthe first one with active generation.
To implement6Reuters-21578, Distribution 1.0, http://www.research.att.com/?lewis7http://www.uclouvain.be/en-cecl.htmlName # of tokens # of errorsKJ training 22,701 327KJ test 8,065 131Dev.
set 47,217 774EDR 1,745,863 ?Reuters 28,431,228 ?LOCNESS 294,325 ?Table 1: Statistics on the data sets for evaluation.the third one, we manually edited the error caseframes of the first version to remove unnecessaryerror case frames and case elements (but no addi-tion) and to add feedback messages to them.
Af-ter this, active generation was applied to augmentthe edited error case frames.
In implementing theproposed methods, we selected as target preposi-tions the ten most frequent prepositions, the sameas in previous work (Rozovskaya and Roth, 2011):about, at, by, for, from, in, of , on, to, with.For comparison, we selected two conventionalmethods.
One was the best-performing sys-tem among the benchmark systems, which is theclassifier-based method (Sakaguchi et al, 2012)which had participated in the HOO 2012 sharedtask (Dale et al, 2012).
The other was the SMT-based method (Yoshimoto et al, 2013) which wasthe best-performing system in preposition errorcorrection in the CoNLL 2013 shared task (Ng etal., 2013).
In addition, we evaluated performanceof hybrid methods combining the correction re-sults of the third version of the proposed methodwith those of the classifier-/SMT-based method;we simply took the union of the two.Table 2 shows the evaluation results.
The sim-ple error case frame-based method achieves an F -measure of 0.189.
It improves recall when com-bined with active generation, which shows theeffectiveness of active generation for augment-ing error case frames.
It further improves pre-cision without decreasing recall by manual edit-ing; note that manual editing was only appliedto the error case frames generated from the train-ing data but not to those generated by active gen-eration.
The performance is comparable to bothclassifier-/SMT-based methods.
The hybrid meth-ods achieve the best performances in F -measure.In the usefulness evaluation, the third version ofthe proposed method was able to provide 20 feed-back messages for the target texts.
The three hu-man raters evaluated 80%, 80%, and 85% of the760Method R P FECF 0.107 0.823 0.189ECF with AG 0.130 0.680 0.218ME-ECF with AG 0.130 0.708 0.219Classifier-based 0.167 0.310 0.217SMT-based 0.115 0.385 0.176Classifier hybrid 0.235 0.369 0.287SMT hybrid 0.191 0.446 0.267ECF: Error Case Frame, ME-ECF: ManuallyEdited Error Case Frame, AG: Active GenerationTable 2: Correction performance in recall (R),precision (P ), and F -measure (F ).20 feedback messages as useful (82% on average).The agreement among the raters was ?
= 0.67 inFleiss?s ?.6 DiscussionAs the experimental results show, the proposedmethod achieves a comparable correction perfor-mance with the classifier-/SMT-based methods.
Acloser look at the correction results reveals the dif-ferences in correction tendencies between thesemethods, which explains well why the hybridmethods achieve better performance.One of the tendencies is that the proposedmethod performs better on preposition errorswhere relatively wider contexts are requiredto correct them.
Error case frames naturallyexploit wider contexts based on the caseswhich are extracted by parsing.
In contrast,classifier-/SMT-based methods rely on narrowercontexts such as a few words surrounding thepreposition in question.
Take as an example thefollowing sentence which appeared in the testset: *In the univerysity, I studied English in themorning8.
To confirm that the preposition Inis erroneous requires the verb studied and theobject English.
The proposed method successfullycorrected this error by the error case frame ?
[studySubj:{PERSON} Prep dobj:{english,math,?
?
?
}*Prep in:{university} ?
at ]?
in the evaluation.This would be difficult for methods relying ononly a few words surrounding the preposition In.It is also difficult for classifier-/SMT-basedmethods to correct missing preposition errors.Classifier-based methods need to be informed of8The word univerysity is a mis-spelt word of university.Note that mis-spelt words are automatically corrected by aspell-checker when case frames are extracted.the position of the preposition to predict a cor-rect preposition.
Because the position of a miss-ing preposition is implicit, classifier-based meth-ods would have to make a prediction at everysingle position between words, which would beinefficient.
Because of this, the classifier-basedmethod used in the evaluation (and often otherclassifier-based methods) excludes missing prepo-sition errors from its target.
SMT-based methodsdo not perform well either on missing prepositionerrors because of the fact that they implicitly, butnot directly, handle missing preposition errors.
Incontrast, error case frames directly model miss-ing prepositions by treating objects as one of thepreposition cases (i.e., Prep dobj).Grammatical errors other than preposition er-rors influence both the proposed and classifier-/SMT-based methods, but differently.
Grammat-ical errors appearing around the preposition inquestion seem to influence the previous methodsmore significantly than the proposed method be-cause they rely on words surrounding the prepo-sition.
On the other hand, structural errors suchas errors in voice tend to degrade performance ofthe proposed method.
For instance, if an error invoice occurs as in *I excited this, correctly, I wasexcited by this, error case frames are not properlyapplied.The precisions of the proposed methods arehigh compared to those of the previous methods.To be precise, the number of false positives is onlyseven in the third version of the proposed method.Out of seven, four false positives are due to prob-lems with the used error case frames themselves.Two are the influence of other grammatical errors(e.g., *I like to look beautiful view.
was correctedas look at beautiful view by the proposed methodbut as see beautiful view in the error annotation).Unlike false positives, it is difficult to preciselypoint out causes for false negatives, which ofteninvolve several factors.
One cause which is theo-retically clear is errors in preposition attached toa noun phrase (NP), which amounts to 11 % ofall false negatives.
Since error case frames de-scribe errors in preposition attached to a verb, theydo not target these types of errors.
Extending er-ror case frames to general frames might overcomethis limitation, which will require further investi-gation.
Similarly, error case frames are not gener-ated for preposition errors where prepositions areincorrectly used with words other than a noun as761in *make me to happy (5 % of all).
Although er-ror case frames can describe these types of errors,case frames are not extracted for their correspond-ing correct usages from the native corpus.
Thisis because the word in question (e.g., happy) cor-rectly appears without the erroneous preposition inthe native corpus, and thus it is not recognized asa preposition case.
This means that a correspond-ing correct case frame is never found for any er-ror of these types in the generation procedure (6).Accordingly, error case frames are never gener-ated for these types of errors.
The most influen-tial cause of false negatives, which is also a majorcause of false negatives in the previous methods,is other grammatical errors (at least 22 % of all).One of such errors is errors in voice as already ex-plained (4%).
Another is the omission of the ob-ject of a verb (4%).
In these cases, even if an ap-propriate error case frame exists, it is not appliedbecause of the grammatical error.In addition to correction performance, errorcase frames are effective in providing feedbackmessages; Fig.
1 (on the first page) shows excerptsof the feedback messages provided in the evalua-tion.
The evaluation shows that 82% of the pro-vided feedback messages were actually rated asuseful for language learning on average (the restwere mostly evaluated as not-useful due to falsepositive corrections).
With the feedback messagesof error case frames, we now have the follow-ing three choices as the way of error correction:(a) just indicating the correct preposition (as inprevious methods); (b) indicating the correctionpreposition with a feedback message; (c) display-ing only a feedback message.
In (a), the learnermight just copy the correct preposition to correcthis or her writing, which would result in little orno learning effect.
This suggests that the ultimategoal of grammatical error correction for languagelearning assistance is not to correct all errors in thegiven text but to maximize learning effect for thelearner.
(b) might give a similar result because thelearner can copy the correct preposition withoutreading the feedback message.
In (c), the learnerhas to actually read and understand the feedbackmessage to select the correct preposition.
Takingthese into consideration, (c) will likely give thelearner better learning effect than the other two.Therefore, we propose applying the feedback (c)to language learning assistance.
To the best of ourknowledge, it is only the error case frame-basedmethod that is capable of this manner of error cor-rection.7 ConclusionsThis paper presented a novel framework callederror case frames for correcting preposition er-rors with feedback messages.
The evaluationshowed that (i) automatically generated error caseframes achieve a performance comparable to con-ventional methods; (ii) they are intuitively in-terpretable and manually modifiable to improvethem; (iii) feedback messages provided by errorcase frames are effective in language learning as-sistance.
Considering these advantages and thefact that it has been difficult to provide feedbackmessages by automatically generated rules, errorcase frames will likely be one of the major ap-proaches for preposition error correction.Appendix A.
Sense mappingThe following list shows the mapping betweenwords and senses developed based on the Word-Net (Miller, 1995) and GSK dictionary of placesand facilities (2nd Ed.)9.
Each line consists of atoken for a sense, its definition, examples of itsmember.
DRINK (drink): tea, coffeeFOOD (food): cake, sandwichMONTH (names of months): January, FebruaryMINST (musical instruments): guitar, pianoPERSON (persons): John, hePLACE (place names): Canada, ParisSPORT (sports): football, tennisSPORTING (sporting activities): swimmingWEEK (the days of the week): MondayVEHICLE (vehicles): train, busAcknowledgmentsWe would like to thank Daisuke Kawahara for hisadvice on case frame generation.
We also wouldlike to thank Keisuke Sakaguchi and Mamoru Ko-machi for providing the authors with their systemoutputs.
Finally, we would acknowledge the helpfrom the members of the ILES group at LIMSI,Orsay (France) where the first author performedpart of this work.
This work was partly supportedby Kaken Grant-in-Aid for Young Scientists (B)(26750091).9GSK dictionary of places and facilities second edi-tion: http://www.gsk.or.jp/en/catalog/gsk2012-c/762ReferencesChris Brockett, William B. Dolan, and Michael Ga-mon.
2006.
Correcting ESL errors using phrasalSMT techniques.
In Proc.
of 21th InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for Computa-tional Linguistics, pages 249?256, Sydney, Aus-tralia, July.Martin Chodorow, Joel R. Tetreault, and Na-Rae Han.2007.
Detection of grammatical errors involvingprepositions.
In Proc.
of 4th ACL-SIGSEM Work-shop on Prepositions, pages 25?30.Robert Dale, Ilya Anisimoff, and George Narroway.2012.
HOO 2012: A report on the preposition anddeterminer error correction shared task.
In Proc.
7thWorkshop on Building Educational Applications Us-ing NLP, pages 54?62.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProc.
of 5th International Conference on LanguageResources and Evaluation, pages 449?445.Rachele De Felice and Stephen G. Pulman.
2008.A classifier-based approach to preposition and de-terminer error correction in L2 English.
In Proc.of 22nd International Conference on ComputationalLinguistics, pages 169?176.Dana Ferris and Barrie Roberts.
2001.
Error feed-back in L2 writing classes: How explicit does itneed to be?
Journal of Second Language Writing,10(3):161?184.Na-Rae Han, Martin Chodorow, and Claudia Leacock.2006.
Detecting errors in English article usage bynon-native speakers.
Natural Language Engineer-ing, 12(2):115?129.Japan electronic dictionary research institute Ltd.1993.
EDR electronic dictionary specificationsguide.
Japan electronic dictionary research instituteltd.Jun?ichi Kakegawa, Hisayuki Kanda, Eitaro Fujioka,Makoto Itami, and Kohji Itoh.
2000.
Diagnosticprocessing of Japanese for computer-assisted secondlanguage learning.
In Proc.
of 38th Annual Meet-ing of the Association for Computational Linguis-tics, pages 537?546.Daisuke Kawahara and Kiyotaka Uchimoto.
2008.
Amethod for automatically constructing case framesfor English.
In Proc.
of 6th International Confer-ence on Language Resources and Evaluation.Kathleen F. McCoy, Christopher A. Pennington, andLinda Z. Suri.
1996.
English error correction: Asyntactic user model based on principled ?mal-rule?scoring.
In Proc.
of 5th International Conference onUser Modeling, pages 69?66.George A. Miller.
1995.
WordNet: A lexicaldatabase for English.
Communications of the ACM,38(11):39?41.Ryo Nagata and Atsuo Kawai.
2011.
Exploiting learn-ers?
tendencies for detecting English determiner er-rors.
In Lecture Notes in Computer Science, volume6882/2011, pages 144?153.Ryo Nagata, Atsuo Kawai, Koichiro Morihiro, andNaoki Isu.
2006.
A feedback-augmented methodfor detecting errors in the writing of learners of En-glish.
In Proc.
of 44th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 241?248.Ryo Nagata, Edward Whittaker, and Vera Shein-man.
2011.
Creating a manually error-tagged andshallow-parsed learner corpus.
In Proc.
of 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages1210?1219.Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, ChristianHadiwinoto, and Joel Tetreault.
2013.
The CoNLL-2013 shared task on grammatical error correction.In Proc.
17th Conference on Computational NaturalLanguage Learning: Shared Task, pages 1?12.Randolph Quirk, Sidney Greenbaum, Geoffrey Leech,and Jan Svartvik.
1985.
A Comprehensive Gram-mar of the English Language.
Longman, New York.Thomas Robb, Steven Ross, and Ian Shortreed.
1986.Salience of feedback on error and its effect on EFLwriting quality.
TESOL QUARTERY, 20(1):83?93.Alla Rozovskaya and Dan Roth.
2011.
Algorithmselection and model adaptation for ESL correctiontasks.
In Proc.
of 49th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 924?933.Alla Rozovskaya and Dan Roth.
2013.
Joint learningand inference for grammatical error correction.
InProc.
of Conference on Empirical Methods in Natu-ral Language Processing, pages 791?802.Keisuke Sakaguchi, Yuta Hayashibe, Shuhei Kondo,Lis Kanashiro, Tomoya Mizumoto, Mamoru Ko-machi, and Yuji Matsumoto.
2012.
NAIST at theHOO 2012 shared task.
In Proc.
of 7th Workshop onthe Innovative Use of NLP for Building EducationalApplications, pages 281?288.Toshikazu Tajiri, Mamoru Komachi, and Yuji Mat-sumoto.
2012.
Tense and aspect error correctionfor ESL learners using global context.
In Proc.
of50th Annual Meeting of the Association for Compu-tational Linguistics (Volume 2: Short Papers), pages198?202.Joel Tetreault, Jennifer Foster, and Martin Chodorow.2010.
Using parse features for preposition selectionand error detection.
In Proc.
of 48nd Annual Meet-ing of the Association for Computational LinguisticsShort Papers, pages 353?358.763Yuanbin Wu and Hwee Tou Ng.
2013.
Grammaticalerror correction using integer linear programming.In Proc.
of 51st Annual Meeting of the Associationfor Computational Linguistics, pages 1456?1465.Ippei Yoshimoto, Tomoya Kose, Kensuke Mitsuzawa,Keisuke Sakaguchi, Tomoya Mizumoto, YutaHayashibe, Mamoru Komachi, and Yuji Matsumoto.2013.
NAIST at 2013 CoNLL grammatical errorcorrection shared task.
In Proc.
of 17th Confer-ence on Computational Natural Language Learn-ing: Shared Task, pages 26?33.764
