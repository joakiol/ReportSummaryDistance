Knowledge Extraction Using Dynamical Updating of RepresentationALDO DRAGONID.E.I.T., Universit?
Politecnica delle MarcheVia Brecce BiancheAncona, Italy, 60131dragon@inform.unian.itGUIDO TASCINID.E.I.T., Universit?
Politecnica delle MarcheVia Brecce BiancheAncona, Italy, 60131tascini@inform.unian.itLUIGI LELLAD.E.I.T., Universit?
Politecnica delle MarcheVia Brecce BiancheAncona, Italy, 60131l.lella@inform.unian.itWILLIAM GIORDANOD.E.I.T., Universit?
Politecnica delle MarcheVia Brecce BiancheAncona, Italy, 60131AbstractWe present a system that extracts knowledgefrom the textual content of documents.The acquired knowledge is represented throughan associative network, that is dynamicallyupdated by the integration of a contextualizedstructure representing the content of the newanalysed document.Grounded on the basis of ?long term workingmemory?
theory by W. Kintsch and K.A.
Ericsson,our system makes use of a scale free graph modelto update the final knowledge representation.This knowledge acquisition system has beenvalidated by first experimental results.1 IntroductionFrom an historical perspective, four types ofknowledge representation schemas are worth to beconsidered (W.Kintsch, 1998).
?Feature systems?
(J.J. Katz, J.A.
Fodor, 1963)have been developed in philosophy and linguisticsand became very popular especially in psychology.This representation aimed at finding a limited setof basic semantic characteristics that, combined bymeans of particular composition rules, couldexpress complex concepts.
It was a very simplerepresentation system but conceptual relationswere not considered.
Furthermore the definedfeatures did not change with the context and thegoals that had to be achieved.
?Associative networks?
consider also semanticrelations between concepts.
Knowledge isrepresented by a network of concepts bounded bymore or less strong associations.
This formalism isbolstered by a lot of experimental data, forexample by word priming experiments (D.E.Meyer, R.W.
Schvaneveldt, 1971).
But networkswhose links are not labelled are not veryexpressive.
?Semantic networks?
(A.M. Collins, M.R.Quillian, 1969) are an evolution of associativenetworks.
Concepts continue to be symbolized bynodes, but these are linked by labeled arcs (IS-A,PART-OF etc.).
In this way well ordered concepthierarchies can be defined and the hereditariness ofproperties is allowed.
?Schemas?, ?frames?
and ?scripts?
are structuresfor coordinating concepts that belong to the sameevent or superstructure.
Classical examples ofthese formalisms are the ?room frame?
of Minsky(M. Minsky, 1975) and the restaurant script ofSchank and Abelson (R.C.
Schank, R.P.
Abelson,1977).The problem with these representation forms isthat they are static.
In fact human mind generatescontextualized structures, that are adapted to theparticular context of use.
?Networks of propositions?
(or ?knowledgenets?,  W.Kintsch, 1998) are an alternativeformalism that combines and extends theadvantages of the representation forms that havebeen introduced so far.The predicate-argument schema can beconsidered as the fundamental linguistic unitespecially in the representation of textual content.Atomic propositions consist of a relational term(the predicate) and one or more arguments.Networks of propositions link these atomicpropositions through weighted and not labeledarcs.
According to this formalism the meaning of anode is given by its position in the net.From a psychologic point of view only the nodesthat are active (i.e.
that are maintained in theworking memory) contribute to specify the senseof a node.
Hence the meaning of a concept is notpermanent and fixed but is built every time in theworking memory by the activation of a certainsubset of propositions in the neighbour of the nodethat represents the concept.
The context of use(objectives, accumulated experiences, emotionaland situational state etc.)
determines which nodeshave to be activated.For the definition of retrieval modalitiesEricsson and Kintsch has introduced the concept oflong term working memory (LTWM) (W.Kintsch,V.L.
Patel, K.A.Ericsson, 1999).
They noticed thatsome cognitive tasks, as textual comprehension,cannot be explained only using the concept ofworking memory.
Given the strict limits ofcapacity of the short term memory (STM) and ofthe working memory (WM), tasks that require anenormous employment of resources cannot becarried out.The theory of long term working memoryspecifies under which conditions the capacity ofWM can be extended.
The LTWM is involved onlyin the execution of well known tasks and actions,that belong to a particular cognitive domain thathas been well experienced.
In these cases theworking memory can be subdivided in a short termpart (STWM) that has a limited capacity and aLTWM that is a part of the long term memoryrepresented by the network of propositions.
Thecontent of STWM automatically generates theLTWM.
In particular objects present in the STWMare linked to other objects in the LTM by fixed andstable memory structures (retrieval cues).2 Implementation of the Kintsch-EricssonmodelThe approach of the network of propositionsyielded two project problems.
The creation of theLTWM and the activation of LTM nodes, i.e.
thecreation of the retrieval cues.Kintsch has developed two methods for thedefinition of the LTWM.The first, defined with Van Dijk (T.A.
van Dijk,W.
Kintsch, 1983), is a manual technique thatstarts from the propositions present in the text(micropropositions) and using some organizingrules arrives to the definition of macropropositionsand macrostructures and even to the definition ofLTWM.The second is based on the latent semantic analysis(LSA) (T.K.
Landauer, P.W.
Foltz, D. Laham,1998).
This technique can infer, from the matrix ofco-occurrence rates of the words, a semantic spacethat reflects the semantic relations between wordsand phrases.
This space has typically 300-400dimensions and allows to represent words, phrasesand entire texts in a vectorial form.
In this way thesemantic relation between two vectors can beestimated by their cosine (a measure that accordingto Kintsch can be interpreted as a correlationcoefficient).This latter solution to the problem of thedefinition of LTWM puts a great and inevitabletechnical problem.
How many objects must beretrieved from the semantic space for every wordpresent in the text ?
In some cases, when thetextbase, i.e.
the representation obtained directlyfrom the text, is sufficiently expressed, theretrieval of knowledge from the LTM is notnecessary.
In other cases a correct comprehensionof the text (or the relative situation model) requiresthe retrieval of knowledge from the LTM.After the creation of the LTWM the integrationprocess begins i.e.
the activation of the nodescorrespondent to the meaning of the phrase.Kintsch uses a diffusion of activation pocedure thatis a simplified version of the one developed byMcClelland and Rumelhart (J.L.
McClelland, D.E.Rumelhart, 1986).
Firstly an activation vector isdefined whose elements are indexed over thenodes of LTWM.
Any element?s value is ?1?
or?0?
depending on the presence or the absence ofthe corresponding node in the analyzed phrase (i.e.in the STWM).
This vector is multiplied by thematrix of the correlation rates (the weights of thelinks of the LTWM) and the resulting vector isnormalized.
This becomes the new activationvector that must be multiplied again by the matrixof the correlation rates.
This procedure goes onuntil the activation vector becomes stable.
Afterthe integration process, the irrelevant nodes aredeactivated and only those that represent thesituation model remain activated.2.1 An alternative representation of theKintsch-Ericsson modelThe adoption of a network of propositions for theknowledge representation presents certainly greatadvantages in comparison with the classicformalisms.
While semantic networks, frames andscripts organize knowledge in a more ordered andlogical way, the networks of propositions aredefinitely more disorganized and chaotic, butpresent the not negligible advantage that arecapable to vary dynamically not only in time, onthe basis of the past experiences, but also on thebasis of the perceived context.But the technique worked out by Kintsch andEricsson for the definition of LTWM presentssome limits.
Retrieving knowledge from thesemantic space is only the first.
Another problem isthe evolution of the LTWM.
The position occupiedby a word in the LTWM is determined by theexperience, i.e.
its past use and this should be alifetime experience.
But this kind of knowledgecannot be reached practically and Kintsch resortsto the use of a dictionary for the definition of thesemantic space that represents the LTWM.Furthermore the construction-integration processdoes not always assure the semanticdisambiguation of the analysed phrase (W.Kintsch,1998).The use of an external dictionary, as WordNet,(G. A. Miller, 1993) and of particulardisambiguation procedures can overcome the lasttwo limits.Instead the first problem can be fully solved onlyby dropping the intermediate representation of thesemantic space and by developing new methodsfor the direct formation of networks of conceptsand propositions.Let us describe now the system for the automaticacquisition of the knowledge that we developed onthe basis of the LTWM model of Kintsch-Ericsson.The lack of adequate textual parsers able toconvert the paragraphs of a text in thecorrespondent atomic propositions has driven us todevelop, at least in this initial phase of our project,simple dynamic models of associative networks.Figure 1: A possibile architecture of a system forthe dynamical acquisition of knowledge from arepository of documents.The part of the document that is analysed (thecontent of the buffer) must be codified on the basisof the context before being elaborated by theworking memory block.
The context represents thetheme, the subject of the processed text and for itscorrect characterization not only the informationpresent in the document must be considered, butalso the one that can be retrieved from the structurerepresenting the knowledge accumulated duringthe analysis of the previous documents presentedto the system (Long Term Memory).For the implementation of the working memoryblock, self organizing networks with suitableprocedures for the labeling of their nodes could beused, but this solution requires a lot ofcomputational time, especially for the analysis ofentire repositories of documents.So we considered alternative models based onthe theory of scale free graphs (R.Albert,A.L.Barabasi, 2001) for the implementation of anassociative network.The graph theory dealed with regular graphsuntill the 50s.
Subsequently random graphs wereintroduced (P.Erdos, A.Renyi, 1959).
They werethe first simple forms of complex graphs that hadever been studied.Their model started with a network made by Nisolated nodes.
Successively each pair of nodescould be connected with a probability p, leading toa graph having approximately pN(N-1)/2 links.But this model was still far from real networkspresent in nature and artificial systems.
Soscientists defined other models characterized by anhigher complexity level.The actual models have three main features.First their ?small world?
structure.
That meansthere is a relatively short path between any twonodes (D.J.Watts, S.H.Strogatz, 1998).Second their inherent tendency to cluster that isquantified by a coefficient that was introduced byWatts and Strogatz.
Given a node i of ki degree i.e.having ki edges which connect it to ki other nodes,if those make a cluster, they can establish ki(ki-1)/2edges at best.
The ratio between the actual numberof edges and the maximum number gives thecluster coefficient of node i.
The clusteringcoefficient of the whole network is the average ofthe all individual clustering coefficients.
In arandom graph the clustering coefficient is C = p. Inreal networks the clustering coefficient is muchlarger than p.Actual graph models are also characterized by aparticular degree distribution.
While in a randomgraph the majority of the nodes haveapproximately the same degree close to theaverage degree, the degree distribution P(k) of areal network has a power-law tail P(k)~k-?.
For thisreason these networks are called ?scale free?
(R.Albert, A.L.Barabasi, 2000).Recently it has been found that humanknowledge seems to be structured as a scale freegraph (M.Steyvers, J.Tenenbaum, 2001).Representing words and concepts with nodes,some of these (hubs) establish much more linkscompared with the other ones.In table 2 are reported the average shortest pathlength, the clustering coefficient and the power lawexponent of two different types of semanticnetworks.AveragepathlengthClusteringcoefficientPowerlawexponentWordNet 10.56 0.0265 3.11RogetThesaurus5.60 0.875 3.19Table 1: General characteristics of somesemantic networks.This particular conformation seems to optimizethe communication between nodes.
Thanks to thepresence of the hubs, every pair of nodes can beconnected by a low number of links in comparisonwith a random network with the same dimensions.The definition and the eventual updating of a scalefree network does not require a lot of time and theexecution of particular processes, as the diffusionof the activation signal, is very fast.The textual analysis is performed through thefollowing steps.The new text is analysed paragraph byparagraph.
The buffer contains not only the wordsof the paragraph analysed, but also words retrievedfrom the long term memory using the diffusion ofthe activation procedure (the activation signalstarts from the nodes in the LTM that representsthe words in the paragraph).
Theoretically, thebuffer should contain also the words activatedduring the analysis of the previous paragraph, butthis aspect has not been considered for itscomputational complexity.
The buffer, the workingmemory and the activated part of the LTM blockcan be compared (but they are not the samestructure) to the LTWM defined by Kintsch andEricsson.During the acquisition of the content of theparagraph a stoplist of words that must not beconsidered (as articles, pronouns etc.)
is used.For any word in the text, the paragraphs where ithas appeared (or where it has been inserted afterthe retrieval procedure) are stored.
When the entiretext has been parsed and the data of all the N notfiltered words have been memorized, the formationof the network of concepts in the working memorybegins.
The model adopted is similar to the onedefined by Bianconi and Barabasi (G.Bianconi,A.Barabasi, 2001).
The process starts with a netconsisting of N disconnected nodes.At every step t=1..N each node (associated toone of the N words) establishes a link with other Munits (M=5).
If j is the selected unit, the probabilitythat this node establishes a link with the unit i is:1 1 ...i iiN NU kPU k U k=+ +where ki is the degree of the unit i 1, i.e.
thenumber of links established by it, while Ui is thefitness value associated to the node, and it can becomputed as the ratio between the number ofparagraphs that contain both i and j and the numberof paragraphs that contain either i or j.LTM is an associative network that is updatedwith the content of the WM.
Whenever a link ofthe WM corresponds to a link present in the LTM,the weight of this one is increased by ?1?.Example :The WM links ?Hemingway?
to ?writer?.In the LTM ?Hemingway?
is linked to ?writer?with weight ?7?
and to ?story?
with weight ?4?.In the updated LTM ?Hemingway?
is linked to?writer?
with weight ?8?
and to ?story?
withweight ?4?
(unchanged).To perform the diffusion of the activation signalall the weights must be normalized.
In this case?Hemingway?
must be linked to ?writer?
withweight 8/(8+4) and to ?story?
with weight 4/(8+4).Since the scale free network that represents thecontent of the WM is used to update the content ofLTM, this associative networks should take theform of a scale free graph.
Unfortunately themodalities of evolution of the LTM does not allowthe definition of a simple equivalent mathematicmodel, that is necessary to make useful previsionsabout its evolution.In the scale free graph models proposed byliterature at each temporal step M new nodes areadded to the graph, with M defined beforehand.These M nodes generally establish M links with Mold units of the network.
In the system that wehave developed, after the analysis of a newdocument the links related to an unknown numberof nodes of the LTM network are updated on thebasis of the content of the WM.
This numberdepends on the analysed document because it is thenumber of the words that have not been filtered bythe stoplist.Another important difference with other scalefree models presented in literature (S.N.Dorogovtsev, J.F.F.
Mendes, 2001) is theparticular fitness function that is used.
Thisfunction does not depend on a single node but onthe considered pair of nodes.
If this value ischoosen as proportional to the weights of the LTMassociative network, the fitness value of a word isnot constant but depends on the other word thatcould be linked to it.
For example the noun?house?
should present for the link with ?door?
a1 Each node is connected to itself by a loop.fitness value greater than the ones presented for thelinks with ?person?
and ?industry?.3 Evaluation of the WM blockTo test the validity of the scale free graph modeladopted for the WM, we gave 100 files of theReuters Corpus2 as input to the system disablingthe retrieval of information from the LTM.Two versions of the model have been tested, onewith bidirectional links and the other with directedlinks (in this case we considered ki = ki(IN) + ki(OUT)).In  fig.
2 (http://www.deit.univpm.it/~dragoni/downloads/scale_free.jpg) an example of anetwork with bidirectional links is represented.Please notice that the economic bias of thearticles justifies the presence of hubs as ?interestrate?, ?economy?, etc., while other frequent wordsas ?child?, ?restaurant?, etc.
establish less link withthe others.Figure 2: A network with bidirectional linksobtained with the analysis of 100 files of theReuters Corpus.Fig.3 reports the average path length betweeneach pair of nodes, the clustering coefficient andthe degrees distribution of the nodes of theobtained networks.2 Reuters Corpus, Volume 1, English language, 1996-08-20 to 1997-08-19, http://about.reuters.com/researchandstandards/corpus.Figure 3: Comparison of average path lengths ofdifferent types of networks.The tendency of the average path length is clear.The trend related to the random graphs, having thesame dimensions of the considered scale freegraphs, has an higher slope.
This result confirmsthe one obtained by Bianconi and Barabasireported in fig.4.Figure 4: Comparison of average path lengths ofdifferent types of networks (Bianconi-Barabasimodel).Fig.5 shows that the clustering coefficient of thescale free graph model has an higher order ofmagnitude in comparison with the one computedfor the random networks.
Even this result isconfirmed by the one obtained by Bianconi andBarabasi (fig.6).Figure 5: Comparison of clustering coefficientsof different types of networks.Figure 6: Comparison of clustering coefficientsof different types of networks (Bianconi-Barabasimodel).Fig.
7 reports the degrees distribution of thegraph with bidirectional links.00,10,20,30,40,50 20 40 60kP(k)Figure 7: Degree distribution of a graph withM=5 and bidirectional links.Fig.
8 highlights the trend by redrawing thegraphic using the logarithmic coordinates.-3-2,5-2-1,5-1-0,500,8 1 1,2 1,4 1,6 1,8LOG(k)LOG[P(k)]Figure 8: Previous graphic in logaritmiccoordinates.The degree distribution decays as P(k) ?
k-G withG = 3.2657.The degree distribution of a graph with directedlinks is reported below.00,050,10,150,20,250,30,350,40 10 20 30 40kP(k)Figure 9: Degree distribution of a graph withM=5 and directed links.Fig.
10 redraws the previous graphic using thelogarithmic coordinates.
The power law trend has acoefficient  G = 2.3897.-3-2,5-2-1,5-1-0,500,5 1 1,5 2LOG(k)LOG[P(k)]Figure 10: Degree distribution of a graph withM=5 and directed links.4 Evaluation of the LTM blockIn order to evaluate the learning capabilities ofthe system, we applied it on a medical article.
Thesections of the paper have been presentedseparately as independent texts regarding the sametopic.
This choice has been imposed by thenecessity to enable also the retrieval of informationfrom LTM.As expected, the resulting LTM network was atypical scale-free graph (tab.
2).M Averagepath lengthAveragedegreeClusteringcoefficient1 2.559 5.95 0.322902 2.499 6.50 0.337583 2.267 8.30 0.454284 2.255 9.50 0.430995 2.232 9.85 0.43151Table 2: LTM with 40 nodesThe analysis has been repeated 30 timesexamining the coherence rate of each resultingLTM representation.The coherence measure is based on a kind oftransitivity assumption, i.e.
if two concepts havesimilar relationships with other concepts, then thetwo concepts should be similar.The coherence rate is obtained by correlating theLTM ratings given for each item in a pair with allof the other concepts3.
Its value can be correctlycomputed only producing symmetric versions ofthe LTM data.The average coherence rate was 0.45, indicatingthat the system has conceptualized the termsaccording to a precise inner schema.3 All the operations described in this section areperformed by the software PCKNOT 4.3, a product ofInterlink Inc.To evaluate the correctness of this schema weare going to compare the obtained LTMrepresentations with experimental data obtainedfrom a group of human subjects.
The subjects willbe asked to read the same medical article examinedby the system, assigning a rate of similarity to eachpair of words that has been considered by thesystem.
A Pathfinder analysis (R.W.
Schvaneveldt,F.T.
Durso, D.W. Dearholt, 1985.)
will beperformed on the relatedness matrices provided byhuman subjects and the LTM matrices in order toextract the so called ?latent semantic?, i.e.
otherimplicit relations between words.
The obtainedmatrices will be compared using a similarity ratedetermined by the correspondence of links in thetwo types of networks.5 Future workSome important considerations can be made onthe overall structure of the system.The absence of an external feedback does notguarantee the correspondence between the LTMand the form of representation that must bemodelled ( the knowledge of an organization, theknowledge of a working group, the knowledge of asingle user ).
A possible external feedback couldbe based on the evaluation of the performances ofthe system in the execution of particular tasks asthe retrieval or the filtering of documents.
Forexample the acceptance or the rejection of thedocuments selected by the system could bereflected in the updating modality of the LTM.
Inthe first case the content of the WM could be usedto strenghten the links in the LTM or to create newones (as explained previously), in the second casethe content of the WM could be used to weaken ordelete the links in the LTM.During the formation of the network in the WMthe information about the weights of the links inLTM is not considered explicitly.
Even if theweights can condition the retrieval of theinformation from the LTM, they could also modifythe value of the fitness function used for thecomputation of the probability of the creation ofnew links in the WM.Furthermore, the association of an age to thelinks of the LTM could guarantee more plasticityto its structure.
Also the ages could be used in thecomputation of the fitness values, for example inaccordance with the modalities suggested byDorogovtsev (S.N.
Dorogovtsev, J.F.F.
Mendes,2000).We think that our knowledge acquisition systemcan be effectively used for the semanticdisambiguation, that is the first phase of theanalysis in the most recent systems for theextraction of ontologies from texts (R. Navigli, P.Velardi, A. Gangemi, 2003).As a further development, we are thinking ofextracting from our representation form a simpletaxonomy of concepts using techniques for theextraction of subsumption and equivalencerelations.
These techniques are based on theelaboration of the correlations between conceptsexpressed as fuzzy relations.
A taxonomicalrepresentation can be considered as an importantstep towards the creation of an ontologicalrepresentation.
In this way our system could beused to model the user knowledge representing itin an ontological form.6 ConclusionsA new system for the automatic acquisition ofthe knowledge has been presented.
It is based onthe concept of long term working memorydeveloped by Kintsch and Ericsson.The system updates an associative network(LTM) whose structure varies dynamically in timeon the basis of the textual content of the analyzeddocuments.
During the analysis of each newdocument the LTM can be queried by the simpleprocedure of the diffusion of the activation signaldeveloped by Kintsch and Ericsson.
In this way thecontext of the document can be easily and exactlyidentified.To reduce the computational time we haveimplemented the WM block with a scale free graphmodel.
The obtained network is used to update thecontent of the LTM.Some analyses have been performed over theWM model developed.
The results have confirmedthat the network evolves as a scale free graph.Also the LTM graphs seems to keep the scalefree features, and their coherence rate indicates thatthe system conceptualizes the terms according to aprecise inner schema.Now we are considering alternative models forthe WM that use much more information present inthe LTM and that guarantee more plasticity to itsstructure.
We are also going to compare the LTMgraphs with the knowledge structures obtained bythe Pathfinder analysis computed over theassociations provided by a group of humansubjects.7 AcknowledgementThe authors are grateful to Prof. Ignazio Licata(Istituto di Cibernetica Non-Lineare per lo Studiodei Sistemi Complessi, Marsala(TP) - Italy) forhelpful discussions, comments and criticisms.ReferencesR.Albert, A. Barabasi.
2000.
Topology of evolvingnetworks: Local events and universality.
Phys.Rev.
Lett.
85, p.5234.R.
Albert, A. Barabasi.
2001.
Statistical Mechanicsof Complex Networks.
Rev.
Mod.
Phys., no.74,pp.47-97.G.
Bianconi, A. Barabasi.
2001.
Bose-EinsteinCondensation in Complex Networks.
Phys.
Rev.Lett., vol.
86, no.
24.A.M.
Collins, M.R.
Quillian.
1969.
Retrieval fromsemantic memory.
Journal of Verbal Learningand Verbal Behaviour, 8, pp.240-247.S.N.
Dorogovtsev, J.F.F.
Mendes.
2000.
Evolutionof reference networks with aging, arXiv: cond-mat/0001419.S.N.
Dorogovtsev, J.F.F.
Mendes.
2001.
Evolutionof networks.
arXiv: cond-mat/0106144,submitted to Adv.
Phys.P.Erdos, Renyi A.. 1959.
On Random Graphs.Publ.
Math.
Debrecen 6, p. 290.J.J.
Katz, J.A.
Fodor.
1963.
The structure ofsemantic theory.
Language, 39, pp.170-210.W.
Kintsch.
1998.
Comprehension.
A Paradigmfor Cognition.
Cambridge University Press.W.
Kintsch.
1998.
The Representation ofKnowledge in Minds and Machines.
InternationalJournal of Psychology, 33(6), pp.411-420.W.
Kintsch, V.L.
Patel, K.A.Ericsson.
1999.
Therole of long-term working memory in textcomprehension.
Psychologia, 42, pp.186-198.T.K.
Landauer, P.W.
Foltz, D. Laham.
1998.
AnIntroduction to Latent Semantic Analysis.Discourse Processes, 25, pp.259-284.J.L.
McClelland, D.E.
Rumelhart.
1986.
Paralleldistributed processing.
Cambridge, MA: MITPress.D.E.Meyer, R.W.
Schvaneveldt.
1971.
Facilitationin recognizing pairs of words: Evidence of adependence between retrieval operations.Journal of Experimental Psychology, 90, pp.227-234.G.
A. Miller.
1993.
Five papers on WordNet.Cognitive Science Laboratory Report 43.M.
Minsky.
1975.
A framework for representingknowledge.
In P.H.
Winston (Ed.
), Thepsychology of computer vision.
New York:McGraw-Hill.R.
Navigli, P. Velardi, A. Gangemi.
2003.Ontology Learning and Its Application toAutomated Terminology Translation.
IEEEIntelligent Systems, January/February 2003, pp.22-31.R.C.
Schank, R.P.
Abelson.
1977.
Scripts, plans,goals, and understanding.
Hillsdale, NJ:Erlbaum.R.W.
Schvaneveldt, F.T.
Durso, D.W. Dearholt.1985.
Pathfinder: Scaling with networkstructures.
Memorandum in Computer andCognitive Science, MCCS-85-9, ComputingResearch Laboratory.
Las Cruces: New MexicoState University.M.
Steyvers, J. Tenenbaum.
2001.
The Large-Scalestructure of Semantic Networks.
Working draftsubmitted to Cognitive Science.T.A.
van Dijk, W. Kintsch.
1983.
Strategies ofdiscourse comprehension.
New York: AcademicPress.D.J.
Watts, S.H.
Strogatz.
1998.
Collectivedynamics of ?small-world?
networks.
Nature, vol.393, pp.
440-442.
