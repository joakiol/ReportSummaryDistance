Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 534?543,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsThe Importance of Rule Restrictions in CCGMarco KuhlmannDept.
of Linguistics and PhilologyUppsala UniversityUppsala, SwedenAlexander KollerCluster of ExcellenceSaarland UniversitySaarbr?cken, GermanyGiorgio SattaDept.
of Information EngineeringUniversity of PaduaPadua, ItalyAbstractCombinatory Categorial Grammar (CCG)is generally construed as a fully lexicalizedformalism, where all grammars use one andthe same universal set of rules, and cross-linguistic variation is isolated in the lexicon.In this paper, we show that the weak gener-ative capacity of this ?pure?
form of CCG isstrictly smaller than that of CCG with gram-mar-specific rules, and of other mildly con-text-sensitive grammar formalisms, includ-ing Tree Adjoining Grammar (TAG).
Ourresult also carries over to a multi-modalextension of CCG.1 IntroductionCombinatory Categorial Grammar (CCG) (Steed-man, 2001; Steedman and Baldridge, 2010) is anexpressive grammar formalism with formal rootsin combinatory logic (Curry et al, 1958) and linksto the type-logical tradition of categorial grammar(Moortgat, 1997).
It has been successfully used fora wide range of practical tasks, such as data-drivenparsing (Hockenmaier and Steedman, 2002; Clarkand Curran, 2007), wide-coverage semantic con-struction (Bos et al, 2004), and the modelling ofsyntactic priming (Reitter et al, 2006).It is well-known that CCG can generate lan-guages that are not context-free (which is neces-sary to capture natural languages), but can stillbe parsed in polynomial time.
Specifically, Vijay-Shanker and Weir (1994) identified a version ofCCG that is weakly equivalent to Tree AdjoiningGrammar (TAG) (Joshi and Schabes, 1997) andother mildly context-sensitive grammar formalisms,and can generate non-context-free languages suchas anbncn.
The generative capacity of CCG is com-monly attributed to its flexible composition rules,which allow it to model more complex word ordersthat context-free grammar can.The discussion of the (weak and strong) gener-ative capacity of CCG and TAG has recently beenrevived (Hockenmaier and Young, 2008; Koller andKuhlmann, 2009).
In particular, Koller and Kuhl-mann (2009) have shown that CCGs that are pure(i.e., they can only use generalized compositionrules, and there is no way to restrict the instancesof these rules that may be used) and first-order(i.e., all argument categories are atomic) can notgenerate anbncn.
This shows that the generativecapacity of at least first-order CCG crucially relieson its ability to restrict rule instantiations, and is atodds with the general conception of CCG as a fullylexicalized formalism, in which all grammars useone and the same set of universal rules.
A questionthen is whether the result carries over to pure CCGwith higher-order categories.In this paper, we answer this question to the pos-itive: We show that the weak generative capacity ofgeneral pure CCG is still strictly smaller than thatof the formalism considered by Vijay-Shanker andWeir (1994); composition rules can only achievetheir full expressive potential if their use can berestricted.
Our technical result is that every lan-guage L that can be generated by a pure CCG hasa context-free sublanguage L0  L such that everystring in L is a permutation of a string in L0, andvice versa.
This means that anbncn, for instance,cannot be generated by pure CCG, as it does nothave any (non-trivial) permutation-equivalent sub-languages.
Conversely, we show that there are stilllanguages that can be generated by pure CCG butnot by context-free grammar.We then show that our permutation languagelemma also holds for pure multi-modal CCG asdefined by Baldridge and Kruijff (2003), in whichthe use of rules can be controlled through the lex-icon entries by assigning types to slashes.
Sincethis extension was intended to do away withthe need for grammar-specific rule restrictions, itcomes as quite a surprise that pure multi-modal534CCG in the style of Baldridge and Kruijff (2003) isstill less expressive than the CCG formalism usedby Vijay-Shanker and Weir (1994).
This means thatword order in CCG cannot be fully lexicalized withthe current formal tools; some ordering constraintsmust be specified via language-specific combina-tion rules and not in lexicon entries.
On the otherhand, as pure multi-modal CCG has been success-fully applied to model the syntax of a variety ofnatural languages, another way to read our resultsis as contributions to a discussion about the exactexpressiveness needed to model natural language.The remainder of this paper is structured as fol-lows.
In Section 2, we introduce the formalismof pure CCG that we consider in this paper, andillustrate the relevance of rule restrictions.
We thenstudy the generative capacity of pure CCG in Sec-tion 3; this section also presents our main result.
InSection 4, we show that this result still holds formulti-modal CCG.
Section 5 concludes the paperwith a discussion of the relevance of our findings.2 Combinatory Categorial GrammarWe start by providing formal definitions for cat-egories, syntactic rules, and grammars, and thendiscuss the relevance of rule restrictions for CCG.2.1 CategoriesGiven a finite set A of atomic categories, the set ofcategories over A is the smallest set C such thatA  C , and .x=y/; .xny/ 2 C whenever x; y 2 C .A category x=y represents a function that seeks astring with category y to the right (indicated by theforward slash) and returns a new string with cat-egory x; a category xny instead seeks its argumentto the left (indicated by the backward slash).
Inthe remainder of this paper, we use lowercase sans-serif letters such as x; y; z as variables for categor-ies, and the vertical bar j as a variable for slashes.In order to save some parentheses, we understandslashes as left-associative operators, and write acategory such as .x=y/nz as x=ynz.The list of arguments of a category c is definedrecursively as follows: If c is atomic, then it has noarguments.
If c D xjy for some categories x and y,then the arguments of c are the slashed category jy,plus the arguments of x.
We number the argumentsof a category from outermost to innermost.
Thearity of a category is the number of its arguments.The target of a category c is the atomic categorythat remains when stripping c of its arguments.x=y y ) x forward application >y xny ) x backward application <x=y y=z ) x=z forward harmonic composition >Bynz xny ) xnz backward harmonic composition <Bx=y ynz ) xnz forward crossed composition >By=z xny ) x=z backward crossed composition <BFigure 1: The core set of rules of CCG.2.2 RulesThe syntactic rules of CCG are directed versionsof combinators in the sense of combinatory logic(Curry et al, 1958).
Figure 1 lists a core set ofcommonly assumed rules, derived from functionalapplication and the B combinator, which modelsfunctional composition.
When talking about theserules, we refer to the premise containing the argu-ment jy as the primary premise, and to the otherpremise as the secondary premise of the rule.The rules in Figure 1 can be generalized intocomposition rules of higher degrees.
These aredefined as follows, where n  0 and ?
is a variablefor a sequence of n arguments.x=y y? )
x?
generalized forward composition >ny?
xny ) x?
generalized backward composition <nWe call the value n the degree of the compositionrule.
Note that the rules in Figure 1 are the specialcases for n D 0 and n D 1.Apart from the core rules given in Figure 1, someversions of CCG also use rules derived from the Sand T combinators of combinatory logic, calledsubstitution and type-raising, the latter restrictedto the lexicon.
However, since our main point ofreference in this paper, the CCG formalism definedby Vijay-Shanker and Weir (1994), does not usesuch rules, we will not consider them here, either.2.3 Grammars and DerivationsWith the set of rules in place, we can define apure combinatory categorial grammar (PCCG) asa construct G D .A;?
;L; s/, where A is an alpha-bet of atomic categories, s 2 A is a distinguishedatomic category called the final category, ?
is afinite set of terminal symbols, and L is a finite rela-tion between symbols in ?
and categories over A,called the lexicon.
The elements of the lexicon Lare called lexicon entries, and we represent themusing the notation  ` x, where  2 ?
and xis a category over A.
A category that occurs in alexicon entry is called a lexical category.535A derivation in a grammar G can be represen-ted as a derivation tree as follows.
Given a stringw 2 ?, we choose a lexicon entry for each oc-currence of a symbol in w, line up the respectivelexical categories from left to right, and apply ad-missible rules to adjacent pairs of categories.
Afterthe application of a rule, only the conclusion isavailable for future applications.
We iterate thisprocess until we end up with a single category.
Thestring w is called the yield of the resulting deriva-tion tree.
A derivation tree is complete, if the lastcategory is the final category of G. The languagegenerated by G, denoted by L.G/, is formed bythe yields of all complete derivation trees.2.4 Degree RestrictionsWork on CCG generally assumes an upper boundon the degree of composition rules that can be usedin derivations.
We also employ this restriction, andonly consider grammars with compositions of somebounded (but arbitrary) degree n  0.1 CCG withunbounded-degree compositions is more express-ive than bounded-degree CCG or TAG (Weir andJoshi, 1988).Bounded-degree grammars have a number ofuseful properties, one of which we mention here.The following lemma rephrases Lemma 3.1 inVijay-Shanker and Weir (1994).Lemma 1 For every grammar G, every argumentin a derivation ofG is the argument of some lexicalcategory of G.As a consequence, there is only a finite numberof categories that can occur as arguments in somederivation.
In the presence of a bound on the degreeof composition rules, this implies the following:Lemma 2 For every grammar G, there is a finitenumber of categories that can occur as secondarypremises in derivations of G.Proof.
The arity of a secondary premise c can bewritten as mC n, where m is the arity of the firstargument of the corresponding primary premise,and n is the degree of the rule applied.
Since eachargument is an argument of some lexical categoryof G (Lemma 1), and since n is assumed to bebounded, both m and n are bounded.
Hence, thereis a bound on the number of choices for c. Note that the number of categories that can occuras primary premises is generally unbounded evenin a grammar with bounded degree.1For practical grammars, n  4.2.5 Rule RestrictionsThe rule set of pure CCG is universal: the differ-ence between the grammars of different languagesshould be restricted to different choices of categor-ies in the lexicon.
This is what makes pure CCGa lexicalized grammar formalism (Steedman andBaldridge, 2010).
However, most practical CCGgrammars rely on the possibility to exclude or re-strict certain rules.
For example, Steedman (2001)bans the rule of forward crossed composition fromhis grammar of English, and stipulates that the ruleof backward crossed composition may be appliedonly if both of its premises share the common tar-get category s, representing sentences.
Exclusionsand restrictions of rules are also assumed in muchof the language-theoretic work on CCG.
In partic-ular, they are essential for the formalism used inthe aforementioned equivalence proof for CCG andTAG (Vijay-Shanker and Weir, 1994).To illustrate the formal relevance of rule restric-tions, suppose that we wanted to write a pure CCGthat generates the languageL3 D f anbncn j n  1 g ,which is not context-free.
An attempt could beG1 D .f s; a; b; c g; f a; b; c g; L; s/ ,where the lexicon L is given as follows:a ` a , b ` s=cna , b ` b=cna ,b ` s=c=bna , b ` s=c=bna , c ` c .From a few sample derivations like the one givenin Figure 2a, we can convince ourselves that G1generates all strings of the form anbncn, for anyn  1.
However, a closer inspection reveals that italso generates other, unwanted strings?in partic-ular, strings of the form .ab/ncn, as witnessed bythe derivation given in Figure 2b.Now suppose that we would have a way to onlyallow those instances of generalized composition inwhich the secondary premise has the form b=c=bnaor b=cna.
Then the compositionsb=c=b b=cb=c=c >1 and s=c=b b=cs=c=c >1would be disallowed, and it is not hard to seethat G1 would generate exactly anbncn.As we will show in this paper, our attempt tocapture L3 with a pure CCG grammar failed notonly because we could not think of one: L3 cannotbe generated by any pure CCG.536a...................aa...........aa...ab...s=c=bnab.......b=c=bnab...............b=cnac.......................cc...........................cc...............................c<0s=c=b>3s=c=c=bna<0s=c=c=b>2s=c=c=cna<0s=c=c=c>0s=c=c>0s=c>0s(a) Derivation of the string aaabbbccc.a...........ab...........s=c=bnaa...ab...b=c=bnaa...ab...b=cnac...........cc...................cc.......................c<0s=c=b<0b=c=b<0b=c>1b=c=c>0b=c>1s=c=c>0s=c>0s(b) Derivation of the string abababccc.Figure 2: Two derivations of the grammar G1.3 The Generative Capacity of Pure CCGWe will now develop a formal argument showingthat rule restrictions increase the weak generativecapacity of CCG.
We will first prove that pure CCGis still more expressive than context-free grammar.We will then spend the rest of this section workingtowards the result that pure CCG is strictly lessexpressive than CCG with rule restrictions.
Ourmain technical result will be the following:Theorem 1 Every language that can be generatedby a pure CCG has a Parikh-equivalent context-freesublanguage.Here, two languages L and L0 are called Parikh-equivalent if every string in L is the permutationof a string in L0 and vice versa.3.1 CFG ?
PCCGProposition 1 The class of languages generatedby pure CCG properly includes the class of context-free languages.Proof.
To see the inclusion, it suffices to note thatpure CCG when restricted to application rules isthe same as AB-grammar, the classical categorialformalism investigated by Ajdukiewicz and Bar-Hillel (Bar-Hillel et al, 1964).
This formalism isweakly equivalent to context-free grammar.To see that the inclusion is proper, we can goback to the grammarG1 that we gave in Section 2.5.We have already discussed that the language L3 isincluded inL.G1/.
We can also convince ourselvesthat all strings generated by the grammar G1 havean equal number of as, bs and cs.
Consider nowthe regular language R D abc.
From our ob-servations, it follows that L.G1/\R D L3.
Sincecontext-free languages are closed under intersec-tion with regular languages, we find that L.G1/can be context-free only if L3 is.
Since L3 is notcontext-free, we therefore conclude that L.G1/ isnot context-free, either.
Two things are worth noting.
First, our result showsthat the ability of CCG to generate non-context-freelanguages does not hinge on the availability of sub-stitution and type-raising rules: The derivationsof G1 only use generalized compositions.
Neitherdoes it require the use of functional argument cat-egories: The grammarG1 is first-order in the senseof Koller and Kuhlmann (2009).Second, it is important to note that if the com-position degree n is restricted to 0 or 1, pure CCGactually collapses to context-free expressive power.This is clear for n D 0 because of the equivalenceto AB grammar.
For n D 1, observe that the arityof the result of a composition is at most as high as537that of each premise.
This means that the arity ofany derived category is bounded by the maximalarity of lexical categories in the grammar, whichtogether with Lemma 1 implies that there is onlya finite set of derivable categories.
The set of allvalid derivations can then be simulated by a con-text-free grammar.
In the presence of rules withn  2, the arities of derived categories can growunboundedly.3.2 Active and Inactive ArgumentsIn the remainder of this section, we will developthe proof of Theorem 1, and use it to show that thegenerative capacity of PCCG is strictly smaller thanthat of CCG with rule restrictions.
For the proof,we adopt a certain way to view the informationflow in CCG derivations.
Consider the followinginstance of forward harmonic composition:a=b b=c ) a=cThis rule should be understood as obtaining its con-clusion a=c from the primary premise a=b by theremoval of the argument =b and the subsequenttransfer of the argument =c from the secondarypremise.
With this picture in mind, we will viewthe two occurrences of =c in the secondary premiseand in the conclusion as two occurrences of oneand the same argument.
Under this perspective,in a given derivation, an argument has a lifespanthat starts in a lexical category and ends in oneof two ways: either in the primary or in the sec-ondary premise of a composition rule.
If it endsin a primary premise, it is because it is matchedagainst a subcategory of the corresponding second-ary premise; this is the case for the argument =bin the example above.
We will refer to such argu-ments as active.
If an argument ends its life in asecondary premise, it is because it is consumed aspart of a higher-order argument.
This is the casefor the argument =c in the secondary premise ofthe following rule instance:a=.b=c/ b=c=d ) a=d(Recall that we assume that slashes are left-associ-ative.)
We will refer to such arguments as inactive.Note that the status of an argument as either activeor inactive is not determined by the grammar, butdepends on a concrete derivation.The following lemma states an elementary prop-erty in connection with active and inactive argu-ments, which we will refer to as segmentation:Lemma 3 Every category that occurs in a CCGderivation has the general form a?
?, where a is anatomic category, ?
is a sequence of inactive argu-ments, and ?
is a sequence of active arguments.Proof.
The proof is by induction on the depth of anode in the derivation.
The property holds for theroot (which is labeled with the final category), andis transferred from conclusions to premises.
3.3 TransformationThe fundamental reason for why the example gram-mar G1 from Section 2.5 overgenerates is that inthe absence of rule restrictions, we have no meansto control the point in a derivation at which a cat-egory combines with its arguments.
Consider theexamples in Figure 2: It is because we cannot en-sure that the bs finish combining with the other bsbefore combining with the cs that the undesirableword order in Figure 2b has a derivation.
To putit as a slogan: Permuting the words allows us tosaturate arguments prematurely.In this section, we show that this property appliesto all pure CCGs.
More specifically, we show that,in a derivation of a pure CCG, almost all activearguments of a category can be saturated beforethat category is used as a secondary premise; atmost one active argument must be transferred tothe conclusion of that premise.
Conversely, anyderivation that still contains a category with at leasttwo active arguments can be transformed into anew derivation that brings us closer to the specialproperty just characterized.We formalize this transformation by means of asystem of rewriting rules in the sense of Baader andNipkow (1998).
The rules are given in Figure 3.
Tosee how they work, let us consider the first rule, R1;the other ones are symmetric.
This rules states that,whenever we see a derivation in which a categoryof the form x=y (here marked as A) is combinedwith a category of the form y?=z (marked as B),and the result of this combination is combined witha category of the form z(C), then the resultingcategory can also be obtained by ?rotating?
the de-rivation to first saturate =z by combining B with C,and only then do the combination with A.
When ap-plying these rotations exhaustively, we end up witha derivation in which almost all active arguments ofa category are saturated before that category is usedas a secondary premise.
Applying the transform-ation to the derivation in Figure 2a, for instance,yields the derivation in Figure 2b.We need the following result for some of thelemmas we prove below.
We call a node in a deriv-538A x=y B y?=zx?=z C zx?R1H) x=yy?=z zy?x?B y?=z A xnyx?=z C zx?R2H)y?=z zy?xnyx?C zA x=y B y?nzx?nzx?R3H) x=yzy?nzy?x?C zB y?nz A xnyx?nzx?R4H)zy?nzy?xnyx?Figure 3: Rewriting rules used in the transformation.
Here,represents a (possibly empty) sequence ofarguments, and ?
represents a sequence of arguments in which the first (outermost) argument is active.ation critical if its corresponding category containsmore than one active argument and it is the second-ary premise of a rule.
We say that u is a highestcritical node if there is no other critical node whosedistance to the root is shorter.Lemma 4 If u is a highest critical node, then wecan apply one of the transformation rules to thegrandparent of u.Proof.
Suppose that the category at u has the formy?=z, where =z is an active argument, and the firstargument in ?
is active as well.
(The other possiblecase, in which the relevant occurrence has the formy?nz, can be treated symmetrically.)
Since u is asecondary premise, it is involved in an inference ofone of the following two forms:x=y y?=zx?=zy?=z xnyx?=zSince u is a highest critical node, the conclusionof this inference is not a critical node itself; inparticular, it is not a secondary premise.
Therefore,the above inferences can be extended as follows:x=y y?=zx?=z zx?y?=z xnyx?=z zx?These partial derivations match the left-hand side ofthe rewriting rules R1 and R2, respectively.
Hence,we can apply a rewriting rule to the derivation.
We now show that the transformation is well-defined, in the sense that it terminates and trans-forms derivations of a grammar G into new deriva-tions of G.Lemma 5 The rewriting of a derivation tree endsafter a finite number of steps.Proof.
We assign natural numbers to the nodesof a derivation tree as follows.
Each leaf nodeis assigned the number 0.
For an inner node u,which corresponds to the conclusion of a composi-tion rule, let m; n be the numbers assigned to thenodes corresponding to the primary and second-ary premise, respectively.
Then u is assigned thenumber 1C 2mCn.
Suppose now that we have as-sociated premise A with the number x, premise Bwith the number y, and premise C with the num-ber z.
It is then easy to verify that the conclusionof the partial derivation on the left-hand side ofeach rule has the value 3 C 4x C 2y C z, whilethe conclusion of the right-hand side has the value2C 2x C 2y C z.
Thus, each step decreases thevalue of a derivation tree under our assignment bythe amount 1C 2x.
Since this value is positive forall choices of x, the rewriting ends after a finitenumber of steps.
To convince ourselves that our transformation doesnot create ill-formed derivations, we need to showthat none of the rewriting rules necessitates the useof composition operations whose degree is higherthan the degree of the operations used in the ori-ginal derivation.Lemma 6 Applying the rewriting rules from thetop down does not increase the degree of the com-position operations.Proof.
The first composition rule used in the left-hand side of each rewriting rule has degree j?j C 1,the second rule has degree jj; the first rule used inthe right-hand side has degree jj, the second rulehas degree j?jC jj.
To prove the claim, it sufficesto show that jj  1.
This is a consequence of thefollowing two observations.1.
In the category x?, the arguments inoccuron top of the arguments in ?, the first of which isactive.
Using the segmentation property stated inLemma 3, we can therefore infer thatdoes notcontain any inactive arguments.5392.
Because we apply rules top-down, premise Bis a highest critical node in the derivation (byLemma 4).
This means that the category atpremise C contains at most one active argument;otherwise, premise C would be a critical nodecloser to the root than premise B.
We conclude that, if we rewrite a derivation d of Gtop-down until exhaustion, then we obtain a newvalid derivation d 0.
We call all derivations d 0 thatwe can build in this way transformed.
It is easy tosee that a derivation is transformed if and only if itcontains no critical nodes.3.4 Properties of Transformed DerivationsThe special property established by our transform-ation has consequences for the generative capacityof pure CCG.
In particular, we will now show thatthe set of all transformed derivations of a givengrammar yields a context-free language.
The cru-cial lemma is the following:Lemma 7 For every grammar G, there is somek  0 such that no category in a transformedderivation of G has arity greater than k.Proof.
The number of inactive arguments in theprimary premise of a rule does not exceed the num-ber of inactive arguments in the conclusion.
Ina transformed derivation, a symmetric propertyholds for active arguments: Since each second-ary premise contains at most one active argument,the number of active arguments in the conclusionof a rule is not greater than the number of act-ive arguments in its primary premise.
Taken to-gether, this implies that the arity of a category thatoccurs in a transformed derivation is bounded bythe sum of the maximal arity of a lexical category(which bounds the number of active arguments),and the maximal arity of a secondary premise(which bounds the number of inactive arguments).Both of these values are bounded in G. Lemma 8 The yields corresponding to the set ofall transformed derivations of a pure CCG form acontext-free language.Proof.
Let G be a pure CCG.
We construct a con-text-free grammar GT that generates the yields ofthe set of all transformed derivations of G.As the set of terminals of GT , we use the set ofterminals ofG.
To form the set of nonterminals, wetake all categories that can occur in a transformedderivation of G, and mark each argument as either?active?
(C) or ?inactive?
( ), in all possible waysthat respect the segmentation property stated inLemma 3.
Note that, because of Lemma 7 andLemma 1, the set of nonterminals is finite.
As thestart symbol, we use s, the final category of G.The set of productions of GT is constructed asfollows.
For each lexicon entry  ` c of G, we in-clude all productions of the form x !
 , where xis some marked version of c. These productionsrepresent all valid guesses about the activity of thearguments of c during a derivation of G. The re-maining productions encode all valid instantiationsof composition rules, keeping track of active andinactive arguments to prevent derivations with crit-ical nodes.
More specifically, they have the formx?
!
x=yC y?
or x?
!
y?
xnyC ,where the arguments in the y-part of the secondarypremise are all marked as inactive, the sequence ?contains at most one argument marked as active,and the annotations of the left-hand side nonter-minal are copied over from the corresponding an-notations on the right-hand side.The correctness of the construction ofGT can beproved by induction on the length of a transformedderivation of G on the one hand, and the length ofa derivation of GT on the other hand.
3.5 PCCG ?
CCGWe are now ready to prove our main result, repeatedhere for convenience.Theorem 1 Every language that can be generatedby a pure CCG grammar has a Parikh-equivalentcontext-free sublanguage.Proof.
Let G be a pure CCG, and let LT be theset of yields of the transformed derivations of G.Inspecting the rewriting rules, it is clear that everystring of L.G/ is the permutation of a string in LT :the transformation only rearranges the yields.
ByLemma 8, we also know that LT is context-free.Since every transformed derivation is a valid deriv-ation of G, we have LT  L.G/.
As an immediate consequence, we find:Proposition 2 The class of languages generatedby pure CCG cannot generate all languages thatcan be generated by CCG with rule restrictions.Proof.
The CCG formalism considered by Vijay-Shanker and Weir (1994) can generate the non-con-text-free language L3.
However, the only Parikh-equivalent sublanguage of that language isL3 itself.From Theorem 1, we therefore conclude that L3cannot be generated by pure CCG.
540In the light of the equivalence result establishedby Vijay-Shanker and Weir (1994), this means thatpure CCG cannot generate all languages that canbe generated by TAG.4 Multi-Modal CCGWe now extend Theorem 1 to multi-modal CCG.We will see that at least for a popular versionof multi-modal CCG, the B&K-CCG formalismpresented by Baldridge and Kruijff (2003), theproof can be adapted quite straightforwardly.
Thismeans that even B&K-CCG becomes less express-ive when rule restrictions are disallowed.4.1 Multi-Modal CCGThe term ?multi-modal CCG?
(MM-CCG) refers toa family of extensions to CCG which attempt tobring some of the expressive power of CategorialType Logic (Moortgat, 1997) into CCG.
Slashes inMM-CCG have slash types, and rules can be restric-ted to only apply to arguments that have slashesof the correct type.
The idea behind this extensionis that many constraints that in ordinary CCG canonly be expressed in terms of rule restrictions cannow be specified in the lexicon entries by givingthe slashes the appropriate types.The most widely-known version of multi-modalCCG is the formalism defined by Baldridge andKruijff (2003) and used by Steedman and Baldridge(2010); we refer to it as B&K-CCG.
This formalismuses an inventory of four slash types, f?;;?
;  g,arranged in a simple type hierarchy: ?
is the mostgeneral type,  the most specific, and  and ?
arein between.
Every slash in a B&K-CCG lexicon isannotated with one of these slash types.The combinatory rules in B&K-CCG, given inFigure 4, are defined to be sensitive to the slashtypes.
In particular, slashes with the types ?
and can only be eliminated by harmonic and crossedcompositions, respectively.2 Thus, a grammarwriter can constrain the application of harmonicand crossed composition rules to certain categor-ies by assigning appropriate types to the slashesof this category in the lexicon.
Application rulesapply to slashes of any type.
As before, we callan MM-CCG grammar pure if it only uses applic-ation and generalized compositions, and does notprovide means to restrict rule applications.2Our definitions of generalized harmonic and crossed com-position are the same as the ones used by Hockenmaier andYoung (2008), but see the discussion in Section 4.3.x=?y y ) x forward applicationy xn?y ) x backward applicationx=?y y=?z? )
x=?z?
forward harmonic compositionx=y ynz? )
xnz?
forward crossed compositionyn?z?
xn?y ) xn?z?
backward harmonic compositiony=z?
xny ) x=z?
backward crossed compositionFigure 4: Rules in B&K-CCG.4.2 Rule Restrictions in B&K-CCGWe will now see what happens to the proof of The-orem 1 in the context of pure B&K-CCG.
Thereis only one point in the entire proof that could bedamaged by the introduction of slash types, andthat is the result that if a transformation rule fromFigure 3 is applied to a correct derivation, then theresult is also grammatical.
For this, it must notonly be the case that the degree on the compositionoperations is preserved (Lemma 6), but also thatthe transformed derivation remains consistent withthe slash types.
Slash types make the derivationprocess sensitive to word order by restricting theuse of compositions to categories with the appropri-ate type, and the transformation rules permute theorder of the words in the string.
There is a chancetherefore that a transformed derivation might notbe grammatical in B&K-CCG.We now show that this does not actually happen,for rule R3; the other three rules are analogous.Using s1; s2; s3 as variables for the relevant slashtypes, rule R3 appears in B&K-CCG as follows:zx=s1y yjs2w?ns3zxjs2w?ns3zxjs2w?R3H) x=s1yzyjs2w?ns3zyjs2w?xjs2w?Because the original derivation is correct, we knowthat, if the slash of w is forward, then s1 and s2 aresubtypes of ?
; if the slash is backward, they aresubtypes of .
A similar condition holds for s3 andthe first slash in; ifis empty, then s3 can beanything because the second rule is an application.After the transformation, the argument =s1y isused to compose with yjs2w?.
The direction ofthe slash in front of the w is the same as before,so the (harmonic or crossed) composition is stillcompatible with the slash types s1 and s2.
Ananalogous argument shows that the correctness ofcombining ns3z withcarries over from the left tothe right-hand side.
Thus the transformation mapsgrammatical derivations into grammatical deriva-tions.
The rest of the proof in Section 3 continuesto work literally, so we have the following result:541Theorem 2 Every language that can be generatedby a pure B&K-CCG grammar contains a Parikh-equivalent context-free sublanguage.This means that pure B&K-CCG is just as unableto generate L3 as pure CCG is.
In other words,the weak generative capacity of CCG with rulerestrictions, and in particular that of the formalismconsidered by Vijay-Shanker and Weir (1994), isstrictly greater than the generative capacity of pureB&K-CCG?although we conjecture (but cannotprove) that pure B&K-CCG is still more expressivethan pure non-modal CCG.4.3 Towards More Expressive MM-CCGsTo put the result of Theorem 2 into perspective, wewill now briefly consider ways in which B&K-CCGmight be modified in order to obtain a pure multi-modal CCG that is weakly equivalent to CCG inthe style of Vijay-Shanker and Weir (1994).
Sucha modification would have to break the proof inSection 4.2, which is harder than it may seem atfirst glance.
For instance, simply assuming a morecomplex type system will not do it, because thearguments ns3z and =s1y are eliminated using thesame rules in the original and the transformed deriv-ations, so if the derivation step was valid before, itwill still be valid after the transformation.
Instead,we believe that it is necessary to make the composi-tion rules sensitive to the categories inside ?
andinstead of only the arguments ns3z and =s1y, andwe can see two ways how to do this.First, one could imagine a version of multi-modal CCG with unary modalities that can be usedto mark certain category occurrences.
In such anMM-CCG, the composition rules for a certain slashtype could be made sensitive to the presence orabsence of unary modalities in ?.
Say for instancethat the slash type s1 in the modalized version ofR3 in Section 4.2 would require that no category inthe secondary argument is marked with the unarymodality ??, but ?
contains a category markedwith ??.
Then the transformed derivation wouldbe ungrammatical.A second approach concerns the precise defin-ition of the generalized composition rules, aboutwhich there is a surprising degree of disagreement.We have followed Hockenmaier and Young (2008)in classifying instances of generalized forwardcomposition as harmonic if the innermost slash ofthe secondary argument is forward and crossed ifit is backward.
However, generalized forward com-position is sometimes only accepted as harmonicif all slashes of the secondary argument are for-ward (see e.g.
Baldridge (2002) (40, 41), Steedman(2001) (19)).
At the same time, based on the prin-ciple that CCG rules should be derived from proofsof Categorial Type Logic as Baldridge (2002) does,it can be argued that generalized composition rulesof the form x=y y=znw ) x=znw, which wehave considered as harmonic, should actually beclassified as crossed, due to the presence of a slashof opposite directionality in front of the w. Thisdefinition would break our proof.
Thus our res-ult might motivate further research on the ?correct?definition of generalized composition rules, whichmight then strengthen the generative capacity ofpure MM-CCG.5 ConclusionIn this paper, we have shown that the weak generat-ive capacity of pure CCG and even pure B&K-CCGcrucially depends on the ability to restrict the ap-plication of individual rules.
This means that theseformalisms cannot be fully lexicalized, in the sensethat certain languages can only be described byselecting language-specific rules.Our result generalizes Koller and Kuhlmann?s(2009) result for pure first-order CCG.
Our proofis not as different as it looks at first glance, astheir construction of mapping a CCG derivation toa valency tree and back to a derivation provides adifferent transformation on derivation trees.
Ourtransformation is also technically related to the nor-mal form construction for CCG parsing presentedby Eisner (1996).Of course, at the end of the day, the issue that ismore relevant to computational linguistics than aformalism?s ability to generate artificial languagessuch as L3 is how useful it is for modeling naturallanguages.
CCG, and multi-modal CCG in partic-ular, has a very good track record for this.
In thissense, our formal result can also be understood asa contribution to a discussion about the expressivepower that is needed to model natural languages.AcknowledgmentsWe have profited enormously from discussions withJason Baldridge and Mark Steedman, and wouldalso like to thank the anonymous reviewers for theirdetailed comments.542ReferencesFranz Baader and Tobias Nipkow.
1998.
Term Rewrit-ing and All That.
Cambridge University Press.Jason Baldridge and Geert-Jan M. Kruijff.
2003.Multi-modal Combinatory Categorial Grammar.In Proceedings of the Tenth Conference of theEuropean Chapter of the Association for Compu-tational Linguistics (EACL), pages 211?218, Bud-apest, Hungary.Jason Baldridge.
2002.
Lexically Specified Deriva-tional Control in Combinatory Categorial Grammar.Ph.D.
thesis, University of Edinburgh.Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir.1964.
On categorial and phrase structure gram-mars.
In Language and Information: Selected Es-says on their Theory and Application, pages 99?115.Addison-Wesley.Johan Bos, Stephen Clark, Mark Steedman, James R.Curran, and Julia Hockenmaier.
2004.
Wide-coverage semantic representations from a CCGparser.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COL-ING), pages 176?182, Geneva, Switzerland.Stephen Clark and James Curran.
2007.
Wide-coverage efficient statistical parsing with CCGand log-linear models.
Computational Linguistics,33(4).Haskell B. Curry, Robert Feys, and William Craig.1958.
Combinatory Logic.
Volume 1.
Studies inLogic and the Foundations of Mathematics.
North-Holland.Jason Eisner.
1996.
Efficient normal-form parsingfor combinatory categorial grammar.
In Proceed-ings of the 34th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 79?86,Santa Cruz, CA, USA.Julia Hockenmaier and Mark Steedman.
2002.
Gen-erative models for statistical parsing with Combin-atory Categorial Grammar.
In Proceedings of the40th Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 335?342, Phil-adelphia, USA.Julia Hockenmaier and Peter Young.
2008.
Non-localscrambling: the equivalence of TAG and CCG revis-ited.
In Proceedings of the 9th Internal Workshop onTree Adjoining Grammars and Related Formalisms(TAG+9), T?bingen, Germany.Aravind K. Joshi and Yves Schabes.
1997.
Tree-Adjoining Grammars.
In Grzegorz Rozenberg andArto Salomaa, editors, Handbook of Formal Lan-guages, volume 3, pages 69?123.
Springer.Alexander Koller and Marco Kuhlmann.
2009.
De-pendency trees and the strong generative capacity ofCCG.
In Proceedings of the Twelfth Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL), pages 460?468, Athens,Greece.Michael Moortgat.
1997.
Categorial type logics.
InHandbook of Logic and Language, chapter 2, pages93?177.
Elsevier.David Reitter, Julia Hockenmaier, and Frank Keller.2006.
Priming effects in combinatory categorialgrammar.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 308?316, Sydney, Australia.Mark Steedman and Jason Baldridge.
2010.
Combin-atory categorial grammar.
In R. Borsley and K. Bor-jars, editors, Non-Transformational Syntax.
Black-well.
Draft 7.0, to appear.Mark Steedman.
2001.
The Syntactic Process.
MITPress.K.
Vijay-Shanker and David J. Weir.
1994.
The equi-valence of four extensions of context-free grammars.Mathematical Systems Theory, 27(6):511?546.David J. Weir and Aravind K. Joshi.
1988.
Combinat-ory categorial grammars: Generative power and rela-tionship to linear context-free rewriting systems.
InProceedings of the 26th Annual Meeting of the As-sociation for Computational Linguistics, pages 278?285, Buffalo, NY, USA.543
