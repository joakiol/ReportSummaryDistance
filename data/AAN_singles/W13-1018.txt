Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 126?131,Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational LinguisticsSemantic Roles for Nominal Predicates: Building a Lexical ResourceAshwini Vaidya and Martha Palmer and Bhuvana NarasimhanDept of LinguisticsInstitute of Cognitive ScienceUniversity of Colorado, BoulderBoulder, CO 80309{vaidyaa, mpalmer, narasimb}@colorado.eduAbstractThe linguistic annotation of noun-verb com-plex predicates (also termed as light verb con-structions) is challenging as these predicatesare highly productive in Hindi.
For semanticrole labelling, each argument of the noun-verbcomplex predicate must be given a role la-bel.
For complex predicates, frame files needto be created specifying the role labels foreach noun-verb complex predicate.
The cre-ation of frame files is usually done manually,but we propose an automatic method to expe-dite this process.
We use two resources forthis method: Hindi PropBank frame files forsimple verbs and the annotated Hindi Tree-bank.
Our method perfectly predicts 65% ofthe roles in 3015 unique noun-verb combi-nations, with an additional 22% partial pre-dictions, giving us 87% useful predictions tobuild our annotation resource.1 IntroductionAhmed et al(2012) describe several types of com-plex predicates that are found in Hindi e.g.
morpho-logical causatives, verb-verb complex predicates andnoun-verb complex predicates.
Of the three types,we will focus on the noun-verb complex predicatesin this paper.
Typically, a noun-verb complex pred-icate chorii ?theft?
karnaa ?to do?
has two compo-nents: a noun chorii and a light verb karnaa givingus the meaning ?steal?.
Complex predicates 1 maybe found in English e.g.
take a walk and many otherlanguages such as Japanese, Persian, Arabic andChinese (Butt, 1993; Fazly and Stevenson, 2007).1They are also otherwise known as light verb, support verbor conjunct verb constructions.The verbal component in noun-verb complexpredicates (NVC) has reduced predicating power(although it is inflected for person, number, and gen-der agreement as well as tense-aspect and mood) andits nominal complement is considered the true pred-icate, hence the term ?light verb?.
The creation ofa lexical resource for the set of true predicates thatoccur in an NVC is important from the point of viewof linguistic annotation.
For semantic role labellingin particular, similar lexical resources have been cre-ated for complex predicates in English, Arabic andChinese (Hwang et al 2010).1.1 BackgroundThe goal of this paper is to produce a lexical re-source for Hindi NVCs.
This resource is in the formof ?frame files?, which are directly utilized for Prop-Bank annotation.
PropBank is an annotated cor-pus of semantic roles that has been developed forEnglish, Arabic and Chinese (Palmer et al 2005;Palmer et al 2008; Xue and Palmer, 2003).
InHindi, the task of PropBank annotation is part of alarger effort to create a multi-layered treebank forHindi as well as Urdu (Palmer et al 2009).PropBank annotation assumes that syntacticparses are already available for a given corpus.Therefore, Hindi PropBanking is carried out on topof the syntactically annotated Hindi DependencyTreebank.
As the name suggests, the syntactic rep-resentation is dependency based, which has severaladvantages for the PropBank annotation process (seeSection 3).The PropBank annotation process for Hindi fol-lows the same two-step process used for other Prop-Banks.
First, the semantic roles that will occur witheach predicate are defined by a human expert.
Then,126these definitions or ?frame files?
are used to guidethe annotation of predicate-argument structure in agiven corpus.Semantic roles are annotated in the form of num-bered arguments.
In Table 1 PropBank-style seman-tic roles are listed for the simple verb de;?to give?
:de.01 ?to give?Arg0 the giverArg1 thing givenArg2 recipientTable 1: A frame fileThe labels ARG0, ARG1 and ARG2 are always de-fined on a verb-by-verb basis.
The description atthe verb-specific level gives details about each num-bered argument.
In the example above, the num-bered arguments correspond to the giver, thing givenand recipient.
In the Hindi treebank, which consistsof 400,000 words, there are nearly 37,576 predi-cates, of which 37% have been identified as complexpredicates at the dependency level.
This implies thata sizeable portion of the predicates are NVCs, whichmakes the task of manual frame file creation timeconsuming.In order to reduce the effort required for manualcreation of NVC frame files, we propose a novel au-tomatic method for generating PropBank semanticroles.
The automatically generated semantic roleswill be used to create frame files for each com-plex predicate in the corpus.
Our method accuratelypredicts semantic roles for almost two thirds ofthe unique nominal-verb combinations, with around20% partial predictions, giving us a total of 87% use-ful predictions.For our implementation, we use linguistic re-sources in the form of syntactic dependency labelsfrom the treebank.
In addition we also have manu-ally created, gold standard frame files for Hindi sim-ple verbs2.
In the following sections we provide lin-guistic background, followed by a detailed descrip-tion of our method.
We conclude with an error anal-ysis and evaluation section.2http://verbs.colorado.edu/propbank/framesets-hindi/2 The Nominal and the Light VerbSemantic roles for the arguments of the light verb aredetermined jointly by the noun as well as the lightverb.
Megerdoomian (2001) showed that the lightverb places some restrictions on the semantic role ofits subject in Persian.
A similar phenomenon maybe observed for Hindi.
Compare example 1 with ex-ample 2 below:(1) Raam-neRam-ergcycle-kiicycle-genchoriitheftkiido.prf?Ram stole a bicycle?
(2) aajTodaycycle-kiicycle-genchoriithefthuiibe.pres?Today a bicycle was stolen?PropBank annotation assumes that sentences inthe corpus have already been parsed.
The annotationtask involves identification of arguments for a givenNVC and the labelling of these arguments with se-mantic roles.
In example 1 we get an agentive sub-ject with the light verb kar ?do?.
However, when itis replaced by the unaccusative ho ?become?
in Ex-ample 2, then the resulting clause has a theme argu-ment as its subject.
Note that the nominal chorii inboth examples remains the same.
From the pointof view of PropBank annotation, the NVC choriikii will have both ARG0 and ARG1, but chorii huiiwill only have ARG1 for its single argument cycle.Hence, the frame file for a given nominal must makereference to the type of light verb that occurs with it.The nominal as the true predicate also contributesits own arguments.
In example 3, which shows a full(non-light) use of the verb de ?give?, there are threearguments: giver(agent), thing given(theme) and re-cipient.
In contrast the light verb usage zor de ?em-phasis give; emphasize?, seen in example 4, has alocative marked argument baat par ?matter on?
con-tributed by the nominal zor ?emphasis?.
(3) Raam-neRam-ergMohan koMohan-datkitaabbookdiigive.prf?Ram gave Mohan a book?
(4) Ram neRam-ergisthisbaatmatterparloczoremphasisdiyaagive.prf?Ram emphasized this matter?127As both noun and light verb contribute to the se-mantic roles of their arguments, we require linguis-tic knowledge about both parts of the NVC.
Thesemantic roles for the nominal need to specify theco-occurring light verb and the nominal?s argumentroles must also be captured.
Table 2 describes thedesired representation for a nominal frame file.Frame file for chorii-n(oun)chorii.01: theft-n light verb: kar?do; tosteal?Arg0 person who stealsArg1 thing stolenchorii.02 : theft-n light verb: ho?be/become; to getstolen?Arg1 thing stolenTable 2: Frame file for predicate noun chorii ?theft?
withtwo frequently occurring light verbs ho and kar.
If otherlight verbs are found to occur, they are added as addi-tional rolesets as chorii.03, chorii.04 and so on.This frame file shows the representation of a nom-inal chorii ?theft?
that can occur in combination witha light verb kar ?do?
or ho ?happen?.
For eachcombination, we derive a different set of PropBankroles: agent and patient for chorii.01 and theme forchorii.02.
Note that the nominal?s frame actuallycontains the roles for the combination of nominaland light verb, and not the nominal alone.Nominal frame files such as these have alreadybeen defined for English PropBank.3 However, forEnglish, many nominals in NVCs are in fact nom-inalizations of full verbs, which makes it far easierto derive their frame files (e.g.
walk in take a walkis a full verb).
For Hindi, this is not the case, anda different strategy needs to be employed to derivethese frames automatically.3 Generating Semantic RolesThe Hindi Treebank has already identified NVCcases by using a special label pof or ?part-of?.
TheTreebank annotators apply this label on the basis ofnative speaker intuition.
We use the label given bythe Treebank as a means to extract the NVC cases(the issues related to complex predicate identifica-tion are beyond the scope of this paper).
Once this3http://verbs.colorado.edu/propbank/framesets-noun/extraction step is complete, we have a set of nomi-nals and a corresponding list of light verbs that occurwith them.In Section 2, we showed that the noun as wellas the light verb in a sentence influence the type ofsemantic roles that will occur.
Our method buildson this idea and uses two resources in order to de-rive linguistic knowledge about the NVC: PropBankframe files for simple verbs in Hindi and the HindiTreebank, annotated with dependency labels.
Thenext two sections describe the use of these resourcesin some detail.3.1 Karaka to PropBank MappingThe annotated Hindi Treebank is based on a depen-dency framework (Begum et al 2008) and has avery rich set of dependency labels.
These labels(also known as karaka labels) represent the relationsbetween a head (e.g.
a verb) and its dependents (e.g.arguments).
Using the Treebank we extract all thedependency karaka label combinations that occurwith a unique instance of an NVC.
We filter themto include argument labels and discard those labelsthat are usually used for adjuncts.
We then calculatethe most frequently occurring combination of labelsthat will occur with that NVC.
Finally, we get a tu-ple consisting of an NVC, a set of karaka argumentlabels that occur with it and a count of the numberof times that NVC has occurred in the corpus.
Thekaraka labels are then mapped onto PropBank la-bels.
We reproduce in Table 3 the numbered argu-ments to karaka label mapping found in Vaidya etal., (2011).PropBank label Treebank labelArg0 (agent) k1 (karta); k4a (experiencer)Arg1 (theme,patient)k2 (karma)Arg2 (beneficiary) k4 (beneficiary)Arg2-ATR(attribute) k1s (attribute)Arg2-SOU(source) k5 (source)Arg2-GOL(goal) k2p (goal)Arg3 (instrument) k3 (instrument)Table 3: Mapping from Karaka labels to PropBank3.2 Verb FramesOur second resource consists of PropBank framesfor full Hindi verbs.
Every light verb that occurs in128Hindi is also used as a full verb, e.g.
de ?give?
inTable 1 may be used both as a ?full?
verb as well asa ?light?
verb.
As a full verb, it has a frame file inHindi PropBank.
The set of roles in the full verbframe is used to generate a ?canonical?
verb framefor each light verb.
The argument structure of thelight verb will change when combined with a nom-inal, which contributes its own arguments.
How-ever, as a default, the canonical argument structurelist captures the fact that most kar ?do?
light verbsare likely to occur with the roles ARG0 and ARG1respectively or that ho ?become?, an unaccusativeverb, occurs with only ARG1.3.3 ProcedureOur procedure integrates the two resources de-scribed above.
First, the tuple consisting of karakalabels for a particular NVC is mapped to PropBanklabels.
But many NVC cases occur just once in thecorpus and the karaka label tuple may not be veryreliable.
Hence, the likelihood that the mapped tu-ple accurately depicts the correct semantic frame isnot very high.
Secondly, Hindi can drop manda-tory subjects or objects in a sentence e.g., (vo) ki-taab paRegaa; ?
(He) will read the book?.
These arenot inserted by the dependency annotation (Bhatiaet al 2010) and are not easy to discover automati-cally (Vaidya et al 2012).
We cannot afford to ig-nore any of the low frequency cases as each NVCin the corpus must be annotated with semantic roles.In order to get reasonable predictions for each NVC,we use a simple rule.
We carry out a mapping fromkaraka to PropBank labels only if the NVC occurs atleast 30 times in the corpus.
If the NVC occurs fewerthan 30 times, then we use the ?canonical?
verb list.4 EvaluationThe automatic method described in the previous sec-tion generated 1942 nominal frame files.
In or-der to evaluate the frame files, we opted for man-ual checking of the automatically generated frames.The frame files were checked by three linguists andthe checking focused on the validity of the seman-tic roles.
The linguists also indicated whether an-notation errors or duplicates were present.
Therewas some risk that the automatically derived framescould bias the linguists?
choice of roles as it isquicker to accept a given suggestion than proposean entirely new set of roles for the NVC.
As wehad a very large number of automatically gener-ated frames, all of which would need to be checkedmanually anyway, practical concerns determined thechoice of this evaluation.After this process of checking, the total numberof frame files stood at 1884.
These frame files con-sisted of 3015 rolesets i.e.
individual combinationsof a nominal with a light verb (see Table 2).
Theoriginal automatically generated rolesets were com-pared with their hand corrected counterparts (i.e.manually checked ?gold?
rolesets) and evaluated foraccuracy.
We used three parameters to compare thegold rolesets with the automatically generated ones:a full match, partial match and no match.
Table 4shows the results derived from each resource (Sec-tion 3) and the total accuracy.Type of Match Full Partial None ErrorsKaraka Mapping 25 31 4 0Verbal Frames 1929 642 249 143Totals 1954 673 245 143% Overall 65 22 8 5Table 4: Automatic mapping results, total frames=3015The results show that almost two thirds of the se-mantic roles are guessed correctly by the automaticmethod, with an additional 22% partial predictions,giving us a total of 87% useful predictions.
Only8% show no match at all between the automaticallygenerated labels and the gold labels.When we compare the contribution of the karakalabels with the verb frames, we find that the verbframes contribute to the majority of the full matches.The karaka mapping contributes relatively less asonly 62 NVC types occur more than 30 times inthe corpus.
If we reduce our frequency requirementfrom of 30 to 5, the accuracy drops by 5%.
The bulkof the cases are thus derived from the simple verbframes.
We think that the detailed information inthe verb frames, such as unaccusativity contributestowards generating the correct frame files.It is interesting to observe that nearly 65% accu-racy can be achieved from the verbal informationalone.
The treebank has two light verbs that occurwith high frequency i.e.
kar ?do?
and ho ?become?.These combine with a variety of nominals but per-129Light verb Full (%) None (%) TotalUses*kar?do?
64 8 1038ho ?be/become?
81 3 549de ?give?
55 34 157A ?come?
31 42 36Table 5: Light verbs ?do?
and ?be/become?
vs. ?give?
and?come?.
*The unique total light verb usages in the corpusform more consistently than light verbs such as de?give?
or A ?come?.
The light verb kar adds inten-tionality to the NVC, but appears less often with aset of semantic roles that are quite different fromits original ?full?
verb usage.
In comparison, thelight verbs such as de ?give?
show far more varia-tion, and as seen from Table 4, will match with au-tomatically derived frames to a lesser extent.
Theset of nominals that occur in combination with kar,usually seem to require only a doer and a thingdone.
Borrowed English verbs such dijain?design?or Pona?phone?
will appear preferentially with karin the corpus and as they are foreign words they donot add arguments of their own.One of the advantages of creating this lexical re-source is the availability of gold standard frame filesfor around 3000 NVCs in Hindi.
As a next step, itwould be useful to use these frames to make somehigher level generalizations about these NVCs.
Forexample, much work has already been done on au-tomatic verb classification for simple predicates e.g.
(Merlo and Stevenson, 2001; Schulte im Walde,2006), and perhaps such classes can be derived forNVCs.
Also, the frame files do not currently addressthe problem of polysemous NVCs which could ap-pear with a different set of semantic roles, which willbe addressed in future work.AcknowledgmentsI am grateful to Archna Bhatia and Richa Srishti fortheir help with evaluating the accuracy of the nom-inal frames.
This work is supported by NSF grantsCNS-0751089, CNS-0751171, CNS-0751202, andCNS-0751213.ReferencesTafseer Ahmed, Miriam Butt, Annette Hautli, and Se-bastian Sulger.
2012.
A reference dependency bankfor analyzing complex predicates.
In Proceedings ofthe Eight International Conference on Language Re-sources and Evaluation (LREC?12.Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti MisraSharma, Lakshmi Bai, and Rajeev Sangal.
2008.
De-pendency Annotation Scheme for Indian Languages.In Proceedings of The Third International Joint Con-ference on Natural Language Processing (IJCNLP).Hyderabad, India.Archna Bhatia, Rajesh Bhatt, Bhuvana Narasimhan,Martha Palmer, Owen Rambow, Dipti Misra Sharma,Michael Tepper, Ashwini Vaidya, and Fei Xia.
2010.Empty Categories in a Hindi Treebank.
In Proceed-ings of the 7th International Conference on LanguageResources and Evaluation (LREC?10), pages 1863?1870.Miriam Butt.
1993.
The Light Verb Jungle.
In G. Aygen,C.
Bowers, and C. Quinn, editors, Harvard WorkingPapers in Linguistics: Papers from the GSAS/DudleyHouse workshop on light verbs, volume 9.Afsaneh Fazly and Suzanne Stevenson.
2007.
Au-tomatic Acquisition of Knowledge about MultiwordPredicates.
In Proceedings of PACLIC 19, the 19thAsia-Pacific Conference on Language, Informationand Computation.Jena D. Hwang, Archna Bhatia, Claire Bonial, AousMansouri, Ashwini Vaidya, Nianwen Xue, and MarthaPalmer.
2010.
PropBank Annotation of MultilingualLight Verb Constructions.
In Proceedings of the Lin-guistic Annotation Workshop held in conjunction withACL-2010.Karine Megerdoomian.
2001.
Event Structure and Com-plex Predicates in Persian.
Canadian Journal of Lin-guistics, 46:97?125.Paola Merlo and Suzanne Stevenson.
2001.
AutomaticVerb Classification Based on Statistical Distributionsof Argument Structure.
Computational Linguistics,27(3):373?408.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated corpus ofsemantic roles.
Computational Linguistics, 31(1):71?106.Martha Palmer, Olga Babko-Malaya, Ann Bies, MonaDiab, Mohammed Maamouri, Aous Mansouri, andWajdi Zaghouani.
2008.
A pilot Arabic PropBank.In Proceedings of the 6th International Language Re-sources and Evaluation.Martha Palmer, Rajesh Bhatt, Bhuvana Narasimhan,Owen Rambow, Dipti Misra Sharma, and Fei Xia.2009.
Hindi Syntax: Annotating Dependency, Lexical130Predicate-Argument Structure, and Phrase Structure.In Proceedings of ICON-2009: 7th International Con-ference on Natural Language Processing, Hyderabad.Sabine Schulte im Walde.
2006.
Experiments on the Au-tomatic Induction of German Semantic Verb Classes.Computational Linguistics, 32(2):159?194.Ashwini Vaidya, Jinho D. Choi, Martha Palmer, and Bhu-vana Narasimhan.
2011.
Analysis of the Hindi propo-sition bank using dependency structure.
In Proceed-ings of the 5th Linguistic Annotation Workshop - LAWV ?11.Ashwini Vaidya, Jinho D. Choi, Martha Palmer, and Bhu-vana Narasimhan.
2012.
Empty Argument Insertionin the Hindi PropBank.
In Proceedings of the EighthInternational Conference on Language Resources andEvaluation - LREC-12, Istanbul.Nianwen Xue and Martha Palmer.
2003.
Annotating thePropositions in the Penn Chinese Treebank.
In Pro-ceedings of the 2nd SIGHAN workshop on Chineselanguage processing, SIGHAN?03, pages 47?54.131
