Construction of Conceptual Graph representation of textsSvetlana HensmanDepartment of Computer ScienceUniversity College DublinBelfield, Dublin 4svetlana.damianova@ucd.ieAbstractThis paper describes a system for construct-ing conceptual graph representation of text byusing a combination of existing linguistic re-sources (VerbNet and WordNet).
We use a two-step approach, by firstly identifying the seman-tic roles in a sentence, and then using theseroles, together with semi-automatically com-piled domain-specific knowledge to constructthe conceptual graph representation.1 IntroductionThe problem of automatic acquisition of knowledge is aninteresting and challenging one and has been tackled bylinguists for some time.This paper describes a system for automatic concep-tual graph acquisition using a combination of linguisticresources, such as VerbNet and WordNet, together withsemi-automatically compiled domain-specific knowl-edge.Such semantic information has a number of possi-ble applications.
One possible application is in thearea of information retrieval/extraction for enhancing thesearch methods and for providing more precise searchresults.
Another application is in question-answeringsystems, allowing users to communicate with the sys-tem in natural language (English) and translating theirqueries/responses into a machine-understandable repre-sentation.We use conceptual graphs (CGs) (Sowa, 1984), aknowledge-representation formalism based on semanticnetworks and the existential graphs of C. S. Peirce.
Thereis a defined mapping between a conceptual graph and acorresponding first-order logical formula, although con-ceptual graphs also allow for representation of temporaland non-monotonic logics, thus exceeding the expressivepower of FOL.One of the first systems for the generation of concep-tual graph representation of text is described in (Sowa andWay, 1986).
It uses a lexicon of canonical graphs that rep-resent valid (possible) relations between concepts.
Thesecanonical graphs are then combined to build a conceptualgraph representation of a sentence.Veraldi at al.
(1988) describe a prototype of a semanticprocessor for Italian sentences.
It uses a lexicon of about850 word-sense definitions, each including 10-20 surfacesemantic patterns (SSPs).
Each SSP represents both us-age information and semantic constrains and is manuallyacquired.There are also systems aimed at extracting partialknowledge from texts, by either filling semantic tem-plates (Hobbs et al, 1996) or by generation of a set oflinguistic patterns for information extraction (Harabagiuand Maiorano, 2000), to name few.The following section describes the general overviewof the system, together with the documents we used totest our algorithms.
Section 3 describes the semantic roleidentification module, Section 4 outlines the algorithmfor constructing the conceptual graph representation ofa sentence.
The experiments that we performed are de-scribed in Section 5, while in Section 6 we draw someconclusions and outline ongoing and future work.2 System overviewWe use a two-step approach for conceptual graph repre-sentation of texts: first, by using VerbNet and WordNet,we identify the semantic roles in a sentence, and second,using these semantic roles and a set of syntactic/semanticrules we construct a conceptual graph.The general architecture of the system is representedin Figure 1.To apply our algorithms we use documents from twocorpora in different domains.
The first corpus is the freelyavailable Reuters-21578 text categorization test collec-tion (Reuters, 1987).
The other corpus we use is the col-lection of aviation incident reports provided by the IrishAir Accident Investigation Unit (AAIU) (2004) .Figure 1: General architecture for the graph constructionAll documents are converted to XML format and sen-tential boundaries are identified.
The documents are thenparsed using Eugene Charniak?s maximum entropy in-spired parser (Charniak, 2000).
This probabilistic parserproduces Penn tree-bank style trees and achieves 90.1%average accuracy for sentences not exceeding 40 wordslong and 89.5% for sentences with length under 100words when trained and tested on the Wall Street Jour-nal treebank.3 Semantic role identificationThe problem of automatic semantic role identification isan important part of many natural language processingsystems and while recent syntactic parsers can correctlylabel over 95% of the constituents of a sentence, findinga representation in terms of semantic roles is still unsat-isfactory.There are number of quite different existing ap-proaches for identifying semantic roles.
The traditionalparsing approaches, such as HPSG grammars and Lexi-cal functional grammars, to a certain extent all suggest se-mantic relationships corresponding to the syntactic ones.They rely strongly on manually-developed grammars andlexicons, which must encode all possible realisations ofthe semantic roles.
Developing such grammars is a time-consuming and tedious process and such systems usuallywork well within limited domains only.The data-driven approach is an alternative approach,based on filling semantic templates.
Applying sucha model to information extraction, in AutoSlog Riloff(1993) builds a list of patterns for filling in semantic slotsin a specific domain, as well as a method for automaticacquisition of case frames (Riloff and Schmelzenbach,1998).
In the domain of the Air Traveler InformationSystem, Miller at al.
(1996) apply statistical methods tocompute the probability of a constituent in order to fill ina semantic slot within a semantic frame.Gildea and Jurafsky (2000, 2002) describe a statisticalapproach for semantic role labelling using data collectedfrom FrameNet.
They investigate the influence of thefollowing features for identification of a semantic role:phrase type, grammatical function (the relationship of theconstituent to the rest of the sentence), position in the sen-tence, voice and head word, as well as a combination offeatures.
They also describe a model for estimating theprobability a phrase to be assigned a specific semanticrole.The approach we propose for semantic role identifica-tion uses information about each verb?s behaviour, pro-vided in VerbNet, and the WordNet taxonomy when de-ciding whether a phrase can be a suitable match for a se-mantic role.VerbNet (Kipper et al, 2000) is a computational verblexicon, based on Levin?s verb classes (Levin, 1993), thatcontains syntactic and semantic information for Englishverbs.
Each VerbNet class defines a list of members, a listof possible thematic roles, and a list of frames (patterns)of how these semantic roles can be realized in a sentence.WordNet (Fellbaum, 1998) is an English lexicaldatabase containing about 120 000 entries of nouns,verbs, adjectives and adverbs, hierarchically organized insynonym groups (called synsets), and linked with rela-tions, such as hypernym, hyponym, holonym and others.The algorithm for semantic role identification of a sen-tence that we propose consists of the following threesteps:1.
Firstly, for each clause in the sentence we identifythe main verb and build a sentence pattern using theparse tree;2.
Secondly, for each verb in the sentence we extracta list of possible semantic frames from VerbNet, to-gether with selectional restrictions for each semanticrole;3.
Thirdly, we match the sentence pattern to each ofthe available semantic frames, taking into accountthe semantic role?s constraints.
As a result we arepresented with a list of all possible semantic role as-signments, from which we have to identify the cor-rect one.These steps are described in more detail in the follow-ing sub-sections.3.1 Constructing sentence patterns for the verbs ina sentenceAs mentioned earlier, during the pre-processing stage weproduce a parse tree for each sentence using the Char-niak parser.
From this parse tree for each clause of thesentence we construct a sentence pattern, which is a flatparse representation that identifies the main verb and theother main categories of the clause.
For example, fromthe parse tree for the sentenceUSAir bought Piedmont for 69 dlrs cash persharewe construct the following pattern:NP VERB(buy) NP PPAs a sentence can have subordinate clauses, we mayhave more than one syntactic pattern per sentence.
Eachsuch pattern is processed individually.3.2 Extracting VerbNet semantic role framesEach verb can be described in VerbNet as a member ofmore than one class (for example the verb make is listedas a member of the verb classes dub-29.3 and build-26.1,each of which correspond to different verb senses), andtherefore the list of its possible semantic frames is a com-bination of the semantic frames defined in each of theclasses in which it participates (currently we do not dis-tinguish between different verb senses and therefore donot process the WordNet sense information attached toeach verb class member).We extract all the semantic frames in a class and con-siders them to be possible semantic frames for each ofthe verbs that are members of this class.
For example, forall the verbs that are members of the VerbNet class get-13.5.1 (including the verb buy) we extract the semanticframes shown in Figure 2.Agent V Theme (1)Agent V Theme Prep(from) Source (2)Agent V Theme Prep(for) Beneficiary (3)Agent V Beneficiary Theme (4)Agent V Theme Prep(for) Asset (5)Asset V Theme (6)Figure 2: Semantic frames and selectional restrictions ex-tracted for the verbs in class get-13.5.1The verb classes also define a list of selectional con-straints each semantic roles should satisfy.
For example,the roles defined in the VerbNet class get-13.5.1 shouldsatisfy the restrictions shown in Figure 3.Some frames define additional restrictions local to theframe.
In this case these restrictions are combined withthe restrictions defined in the frames.Agent[+animate OR +organization]Theme[]Source[+concrete]Beneficiary[+animate OR +organization]Asset[+currency]Figure 3: Selectional constraints for the semantic rolesdefined in class get-13.5.13.3 Matching algorithmThe matching algorithm matches the sentence patternagainst each of the possible semantic role frames ex-tracted from VerbNet.
We independently match the con-stituents before and after the verb in the sentence patternto the semantic roles before and after the verb in the se-mantic role frame.If the number of the available constituents in the sen-tence pattern is less than the number of the required slotsin the frame, the match fails.If there is more than one constituent available to fill aslot in a semantic frame, they are assigned priorities usingheuristic rules.
For example, in the cases where we havea choice of a few possible role fillers for the Agent, ahigher weight is given to noun phrases, especially if theyare marked as proper nouns (NNP) or contain at least oneproper noun.If, for a semantic frame, we find a constituent for eachof the semantic role slots that complies with the selec-tional constraints, the algorithm considers this a possiblematch.
Currently, if the algorithm returns more than onematch, we manually select the best one.3.4 Selectional constraints checkThe selectional constraints check verifies if a candidateconstituent for a thematic role fulfills the selectional con-straints assigned to this role.
For example, a commonrequirement for a constituent to fill the role of Agent is tobe of type animate or organization.The selectional constraints check is implemented us-ing one or combination of the following techniques: hy-pernym relations defined in WordNet, pattern matchingtechniques, syntactic rules and some heuristics.For example, the restriction machine is a type restric-tion and is fulfilled if the word represented by the con-stituent is a member of a synset that is a hyponym of thesynset containing the word machine.Other restrictions, like infinitival and sentential, are re-solved only by checking the syntactic parse structure ofthe parse tree.Restrictions such as animate and organization are re-solved by applying a combination of the synset hierarchyin WordNet and pre-compiled lists of organization andpersonal names, and if no satisfactory answer is found,using heuristics to identify if the phrase contains propernouns.We also check for a suitable preposition before the con-stituent to be matched.
For example, for the frameAgent V Topic Prep(to) Recipientthe constituent filling the semantic role of Recipientshould be a prepositional phrase headed by the preposi-tion to (e.g.
Bob said a few words to Mary).4 Building conceptual graphsThe previous section describes the process of identify-ing the semantic roles of the constituents in a sentence.These roles are used to build a conceptual graph represen-tation of the sentence by applying series of transforma-tions, starting with more generic concepts and relationsand replacing them with more specific ones.The conceptual graph is built through the followingsteps:  Step 1 ?
For each of the constituents of the sentencewe build a conceptual graph representationEach phrase (part of the sentence) should be repre-sented by a conceptual graph.
This is done recur-sively by analysing the syntactical structure of thephrase.  Step 2 ?
Link all the conceptual graphs representingthe constituents in a single graphAll the conceptual graphs built during the previ-ous step are attached to the concept representing theverb, thus creating a conceptual graph representa-tion for the complete sentence.  Step 3 ?
Resolve the unknown relationsThis step attempts to identify all generic labels as-signed during the previous two steps.
This is doneby using a list of relation correction rules.Each of these steps are described in more detail in thefollowing sub-sections.4.1 Building a conceptual graph representation of aphraseThis step involves building a conceptual graph for aphrase.
Our general assumption is that each lexeme in thesentence is represented using a separate concept, there-fore all nouns, adjectives, adverbs and pronouns are rep-resented using concepts, while the determiners and num-bers are used as a referent of the relevant concept (thusfurther specifying the concept).Here we will outline the process of building a concep-tual graph for a phrase depending on the part of speechcategory of the phrase.4.1.1 Noun phrasesThe list of some of the most common syntactic patternsfor noun phrases is shown in Table 1.Syntactic pattern % AAIU % Reuters(1) NP -  DT NN 20.42% 9.10%(2) NP -  NP PP 12.99% 14.17%(3) NP -  DT JJ NN 5.32% 2.49%(4) NP -  NN 5.18% 4.01%(5) NP -  NNP 4.59% 6.09%(6) NP -  PRP 3.57% 4.47%(7) NP -  NNP NNP 3.22% 2.15%(8) NP -  CD NNS 2.88% 1.81%(9) NP -  DT NN NN 2.20% 1.17%(10) NP -  NP SBAR 0.88% 1.29%Table 1: A list of some of the most common syntacticpatterns for noun phrasesEach of these cases is resolved individually.
For exam-ple, for pattern (1) we create a concept for the NN with areferent, corresponding to the type of the determiner (anexistential quantifier referent if the word marked as DTis the, a defined quantifier if the word is every, or noneif the word is a).
For pattern (3) we create concepts rep-resenting the adjective and the noun and link them by anAttribute relation.
Pattern (10) represents phrases wherethe noun is further specified by the SBAR (for example,The co-pilot, who was acting as a main pilot, landed theplane.)
For these patterns a conceptual graph is built forthe SBAR and the head concept, which could be a WHNPphrase (e.g.
which or who) or WHADVP (e.g.
where) isreplaced by the concept, created for the NP (also see Ta-ble 3).4.1.2 Prepositional phrasesThe conceptual graph representation of propositionalphrases, similarly on the noun phrases, depends on theirsyntactic structure.
A list of the most common syntacticpatterns for prepositional phrases is shown in Table 2.Syntactic pattern % AAIU % Reuters(1) PP -  IN NP 77.99% 82.57%(2) PP -  TO NP 13.81% 8.81%Table 2: A list of the most common syntactic patterns forprepositional phrasesThe two most common patterns consist of a preposi-tion followed by a noun phrase.
For such prepositionalphrases we construct a conceptual graph representing thenoun phrase.
We also keep track of the preposition head-ing the prepositional phrase, as it is used to mark the re-lation between this phrase and the rest of relevant phrasesin the sentence.4.1.3 Subordinate clausesThe list of the most common syntactic patterns forphrases representing subordinate clauses (and marked asSBAR) is shown in Table 3.Syntactic pattern % AAIU % Reuters(1) SBAR -  IN S 52.76% 24.33%(2) SBAR -  WHNP S 18.90% 12.57%(3) SBAR -  WHADVP S 12.60% 2.53%(4) SBAR -  S 3.94% 56.34%Table 3: A list of the most common syntactic patterns forsubordinate phrasesFor all these cases the embedded clause S is treatedas an independent sentence, and we recursively create aconceptual graph for it.
To link the resulting graph to themain graph we either use a relation with label related tothe preposition marked as IN (in case (1)) or by replac-ing the concept representing the WHNP or the WHADVPnode with the concept representing the node it refers to.4.2 Attaching all constituents to the verbAfter building separate graphs for each of the con-stituents, we link them together in a single conceptualgraph.
As each of them describe some aspect of the con-cept represented with the verb, we link them to that con-cept.
Here we use the term main node to denote the node(concept) in the conceptual graph representing the headof the constituent.
We identify the head using syntacticinformation about the constituent.
For example, if theconstituent is a noun phrase consisting of a noun phrase,followed by a prepositional phrase, its head is the head ofthe noun phrase and the PP is a modifier.
Alternatively,if the constituent is a noun phrase that consists of an ad-jective followed by a noun, the noun is the head and theadjective is a modifier.If the constituent already has a semantic role attachedto it, the same relation is used when constructing theconceptual graph between the CG representing the con-stituent and the verb.If the constituent does not have any semantic roles at-tached to it, a relation with a generic label is used.
Usinga generic type of relation allows us to build the structureof the CG, concentrating on the concepts involved, and toresolve the remaining relations later.
If the constituent isnot a propositional phrase (this includes NP, SBAR, etc.
),we use a generic label REL.If the constituent is a prepositional phrase (PP) headedwith a proposition prep, we use a generic label REL prep.For example, for the phrase a flight from Dublin we createa concept of a flight and a concept of a city, called Dublinand link them with a generic relation REL from.4.3 Resolving unknown relationsThis is the final step in the conceptual graph construction,where we resolve the unknown (generic) relations in theconceptual graph.We keep a database of most common syntactic reali-sation of relations between concepts with specific types.Figure 4 shows some of the relation correction rules weuse for the documents in the AAIU corpus.
The leftpart of the rule represents the two concepts linked with ageneric relation, while the right side represents this graphafter the correction.
For example, the first pattern statesthat if in our graph there are concepts Runway and Air-port linked with relation REL at, we replace the relationwith Location.Runway REL at Airport -  Runway Location AirportFlight REL from Airport -  Flight Source AirportFlight REL from City -  Flight Source CityFlight REL to Airport -  Flight Destination AirportFlight REL to City -  Flight Destination CityFlight REL for Airport -  Flight Destination AirportFlight REL for City -  Flight Destination CityLand REL on Runway -  Land Destination RunwayRoute REL from City -  Route Source CityRoute REL to City -  Route Destination CityFigure 4: A sample list of relation correction rulesBuilding the relation correction rules database isa challenging task.
Currently, the process is semi-automated by scanning the corpus for commonly occur-ring syntactic patterns.
Such patterns are then manuallyevaluated and the semantic relations are identified.Here is an example of applying a relation correctionrule: for the NP the flight from Dublin on step 2 we createthe conceptual graph[FLIGHT:*a]-  (REL from)-  [City:Dublin]Using the correction rule 3 we substitute the relationREL from with Source to produce the graph[FLIGHT:*a]-  (Source)-  [City:Dublin]This is an useful approach for resolving relations be-tween nouns, as no such information is available in Verb-Net.5 Experimental resultsWe currently are in the process of testing and tuning oursystem.
We have some preliminary results for the per-formance of the semantic role annotation module, bothon Reuters news articles and AAIU reports.
The tests onthe Reuters documents are performed on a quarter of theavailable corpus (reut2-003.sgm) and for the AAIU doc-uments on the reports from years 1998, 1999 and 2000.The coverage (the percentage of the verbs in the cor-pus that have a VerbNet description) of VerbNet for bothcorpora is relatively low: 66% for Reuters and 53% forthe AAIU.To evaluate the performance of the semantic role la-belling algorithm we randomly selected 1% of the verbsfrom each corpus and manually analysed the assigned se-mantic roles.
Our tests show that the semantic roles arecorrectly identified in 39% of cases in Reuters corpus and35% of the cases in the AAIU reports, which is 59% and66% respectively of the verbs present in VerbNet (the per-centage of the correctly identified out of all that are cov-ered by VerbNet).We are currently extending the coverage of VerbNet bymanually identifying frames present in the corpora andnot included in VerbNet, which we believe should signif-icantly increase the performance.6 ConclusionsIn this paper we described an approach for constructingconceptual graphs for English sentences, using syntacticand semantic information from VerbNet and WordNet, aswell as some domain-specific knowledge.
We tested thesemantic role labeling algorithm on parts of Reuters cor-pus and on Irish Air Accident reports.
The achieved ac-curacy is strongly influenced by the lack of VerbNet de-scription of many verbs present in the corpora, as well asthe lack of semantic frames for the verb sense.The work on the system is ongoing and the effortsare continuing to implement a verb sense disambiguationcomponent and to test the conceptual graph constructionmodule.7 AcknowledgmentsThis work is developed as part of the INTINN project,funded under the Enterprise Ireland Informatics ResearchInitiative.
I would also like to thank my supervisor, JohnDunnion, and the anonymous reviewers for their usefulcomments.ReferencesAir Accident Investigation Unit.
2004.
Irish Air Ac-cident Investigation Unit Reports.
Available online:(http://www.aaiu.ie/).Eugene Charniak.
2000.
A Maximum-Entropy-InspiredParser.
In Proceedings of NAACL-2000, pages 132?139.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, May.Daniel Gildea and Daniel Jurafsky.
2000.
Automatic La-beling of Semantic Roles.
In Proceedings of 38th An-nual Conference of the Association for ComputationalLinguistics (ACL-00), pages 512?520, Hong Kong,October.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic La-beling of Semantic Roles.
Computational Linguistics,28(3):245?288.Sanda Harabagiu and Steven Maiorano.
2000.
Acqui-sition of linguistic patterns for knowledge-based in-formation extraction.
In Proceedings of LREC-2000,Athens, June.Jerry Hobbs, Douglas Appelt, John Bear, David Israel,Megumi Kameyama, Mark Stickel, and Mabry Tyson.1996.
FASTUS: A cascaded finite-state transducer forextracting information from natural-language text.
InIn Finite State Devices for Natural Language Process-ing, Cambridge, MA.
MIT Press.Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-Based Construction of a Verb Lexicon.In Proceedings of Seventeenth National Conference onArtificial Intelligence (AAAI-2000), pages 691 ?
696,Austin, TX, July 30 - August 3.Beth Levin.
1993.
English Verb Classes And Alterna-tions: A Preliminary Investigation.
The University ofChicago Press.Scott Miller, David Stallard, Robert Bobrow, and RichardSchwartz.
1996.
A fully statistical approach to nat-ural language interfaces.
In Proceedings of the 34thAnnual Meeting of the Association for ComputationalLinguistics, pages 55?61, Santa Cruz, CA, June.
Mor-gan Kaufmann Publishers, Inc.Reuters.
1987.
Reuters-21578 Text CategorizationCollection.
Available online: (http://kdd.ics.uci.edu/-databases/reuters21578/reuters21578.html).Ellen Riloff and Mark Schmelzenbach.
1998.
An Empir-ical Approach to Conceptual Case Frame Acquisition.In Proceedings of the Sixth Workshop on Very LargeCorpora.Ellen Riloff.
1993.
Automatically Constructing a Dictio-nary for Information Extraction Tasks.
In Proceedingsof the Eleventh National Conference on Artificial In-telligence (AAAI-93), pages 811?816.
AAAI Press/TheMIT Press.John F. Sowa and Eileen C. Way.
1986.
Implementinga semantic interpreter using conceptual graphs.
IBMJournal of Research and Development, 30(1):57?69,January.John F. Sowa.
1984.
Conceptual Structures: InformationProcessing in Mind and Machine.
Addison-Wesley,Reading, M.Paola Velardi, Maria Teresa Pazienza, and MarioDe?Giovanetti.
1988.
Conceptual graphs for the anal-ysis and generation of sentences.
IBM Journal of Re-search and Development, 32(2):251?267, March.
